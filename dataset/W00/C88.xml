<?xml version="1.0" encoding="UTF-8"?>
	<volume id="C88">

		<paper id="2152">
			<definition id="0">
				<sentence>I will VP , where VP is some verb phrase describing some action , is sincere if the speaker 's intentions SA are modified to be in accord with the meaning of the sentence .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">intentions SA are modified to be in accord with the meaning of the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Classical non-situational semantics of basic sentences did not differentiate the meanings of sentences except indirectly through differences in the content and form of the truth conditions .</sentence>
				<definiendum id="0">Classical non-situational</definiendum>
				<definiens id="0">semantics of basic sentences did not differentiate the meanings of sentences except indirectly through differences in the content and form of the truth conditions</definiens>
			</definition>
			<definition id="2">
				<sentence>Y represents the cp 's evaluation and focus on situations .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">the cp 's evaluation and focus on situations</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus Prag takes a given sttb~'epresentational state such as I in R and transtblzns itinte a new substate I ' = Prag ( a ) ( I ) .</sentence>
				<definiendum id="0">Prag</definiendum>
				<definiens id="0">takes a given sttb~'epresentational state such as I in R and transtblzns itinte a new substate I ' = Prag ( a )</definiens>
			</definition>
			<definition id="4">
				<sentence>For any formula a in L , Prag ( a ) : Rep ~ Rep is a function that distributes over the representational state R E Rep subject to the constraints that for all I ( INF , S E INT , and V E VAL , then Prag ( a ) ( I ) E INF , Prag ( a ) ( S ) E INT , and Prag ( a ) ( V ) E VAL , respectively .</sentence>
				<definiendum id="0">Rep</definiendum>
				<definiens id="0">a function that distributes over the representational state R E Rep subject to the constraints that for all I ( INF , S E INT , and V E VAL , then Prag ( a ) ( I ) E INF , Prag ( a ) ( S ) E INT</definiens>
				<definiens id="1">a ) ( V ) E VAL , respectively</definiens>
			</definition>
			<definition id="5">
				<sentence>The hearer A knows u if a holds in all the worlds in I. Thus , A comes to know that a as a result of receiving and interpreting the message a. Prag acts on the intentional substates as follows : Prag ( a A 13 ) ( S ) = Prag ( a ) ( S ) N Prag ( 13 ) ( S ) Prag ( u V ~ ) ( S ) -Prag ( o ) ( S ) U Prag ( ~ ) ( S ) Prag ( -7 a ) ( S ) = S Prag ( u ) ( S ) Prag ( a h=~ l } ) ( S ) - { n : for all H e n * and there exist times to , t ' ~ TP where Holds ( u , H , to ) and Holds ( 13 , H , t ' ) and to &lt; t ' } Prag ( o while 13 ) ( S ) = { n : for all H e n* , exists t , t ' e TP such that Holds ( a , H , t ) and Holds ( a , H , t ' ) and t ' contains t } .</sentence>
				<definiendum id="0">Prag</definiendum>
				<definiens id="0">o ) ( S ) U Prag ( ~ ) ( S ) Prag ( -7 a ) ( S ) = S Prag ( u ) ( S</definiens>
			</definition>
			<definition id="6">
				<sentence>Let fa = Prag ( a ) the interpretation of a. To describe the act of saying a we introduce another operator , acts is the operator giving the infomation that a was just said .</sentence>
				<definiendum id="0">Prag</definiendum>
				<definiens id="0">the operator giving the infomation that a was just said</definiens>
			</definition>
			<definition id="7">
				<sentence>~a is the time operator that shifts time according to how long it took to say u .</sentence>
				<definiendum id="0">~a</definiendum>
				<definiens id="0">the time operator that shifts time according to how long it took to say u</definiens>
			</definition>
			<definition id="8">
				<sentence>Remark : The speaker commits himself to following those strategies that insure the propositional content of a , i.e. , all the worlds in each .</sentence>
				<definiendum id="0">Remark</definiendum>
				<definiens id="0">The speaker commits himself to following those strategies that insure the propositional content of a</definiens>
			</definition>
</paper>

		<paper id="2090">
</paper>

		<paper id="2159">
			<definition id="0">
				<sentence>Zero pronoun is defined as an obligatory case noun phrase that is not expressed in the utterance but can be understood through other utterances in the discourse , context , or out-of-context knowledge .</sentence>
				<definiendum id="0">Zero pronoun</definiendum>
				<definiens id="0">an obligatory case noun phrase that is not expressed in the utterance but can be understood through other utterances in the discourse , context , or out-of-context knowledge</definiens>
			</definition>
			<definition id="1">
				<sentence>The TOPIC is a FOOT feature that derives from the lexical description of wa .</sentence>
				<definiendum id="0">TOPIC</definiendum>
				<definiens id="0">a FOOT feature that derives from the lexical description of wa</definiens>
			</definition>
			<definition id="2">
				<sentence>The leaf node is a C whose TOP value is a stack with all the topics in the sentence , and each non-terminal node C has a TOP stack containing that of the immediately dominated C minus the first member .</sentence>
				<definiendum id="0">leaf node</definiendum>
				<definiens id="0">a stack with all the topics in the sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>This lexical description is embedded into the total zero pronoun identification mechanism by revising TSIJ : lopic Supplementation Principle ( 2nd Version ) whose SLASH value is a set { P1 ... .. Pn } , the gEM of each of P1 ... .. Pn is set to one oft1 ... .. tin , without the SEM of two Ps assigned to tim stone t , if the two are unifiable .</sentence>
				<definiendum id="0">Pn</definiendum>
				<definiens id="0">a set { P1 ... .. Pn } , the gEM of each of P1 ... ..</definiens>
			</definition>
</paper>

		<paper id="2107">
			<definition id="0">
				<sentence>, ( i.e. what is looked for in the problem ) , and ~ ( i.e. the equation ( s\ ] , relating the unknown ( s\ ] , or variables , to the givenfs ) , or constants , in the problem ) .</sentence>
				<definiendum id="0">~</definiendum>
				<definiens id="0">s\ ] , or variables , to the givenfs ) , or constants , in the problem )</definiens>
			</definition>
			<definition id="1">
				<sentence>Ths pFu~sss includes the reprsssstatisn sff the ' dis~ouvsQ st~'uctur'e into a ssqusncs o~ '' slsmsntar .</sentence>
				<definiendum id="0">Ths pFu~sss</definiendum>
				<definiens id="0">includes the reprsssstatisn sff the ' dis~ouvsQ st~'uctur'e into a ssqusncs o~ '' slsmsntar</definiens>
			</definition>
</paper>

		<paper id="1070">
			<definition id="0">
				<sentence>~ ' -- ~rejected Filter ( I ) \ ] F-S : iltor ( ) 1 \ [ Improper Grammar / 7 Well-formed error corection failure ( relatively ill-formed } ( absolutely ill-formed ) &lt; ~ &lt; ~ &lt; ~ ~ @ : sentence ~ &gt; ~ number in Table1 Figure 1 Two-level filter Filter ( I ) is a context~free grammar .</sentence>
				<definiendum id="0">Filter</definiendum>
				<definiens id="0">a context~free grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>( T f-name ) = i { values } T is a meta : variable as well as LFG notation and `` fname '' is a functional name of the interpretation schema .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">a meta : variable as well as LFG notation and `` fname '' is a functional name of the interpretation schema</definiens>
			</definition>
			<definition id="2">
				<sentence>-FORM &amp; COMP ) = k { ( f2 DET-NOUN ) , ( f2 DET-ADJ-NOUN ) } Interpretation Schemata Grammar rule ~ ) ( T DET~NOUN ) =I { \ [ DET\ ] , \ [ NOUN\ ] } Rule ( I ) ( 2 ) ( ~ ( I ' DET-AI ) J-NOUN ) =i { \ [ DET\ ] , \ [ A1 ) J\ ] , \ [ NOUN\ ] } Rule ( 3 ) ( 4 ) ( ~ ( t'I SUBJ &amp; V-FORM ) =i { \ [ NP : f2\ ] , \ [ VERB3\ ] } Rule ( 6 ) ( 8 ) ( .4 ) ( fl SUBJ &amp; A-FORM ) =i { \ [ NP : f2\ ] , \ [ AUX\ ] } Rule ( '/ ) ( f~ AUX &amp; V-FORM ) = d\ [ AUXI , \ [ VERB3\ ] } Rule ( 7 ) ( fl SUBJ &amp; V-FORM &amp; COMP ) = i { \ [ NP : f~\ ] , \ [ VERB-be\ ] , \ [ NP : fs\ ] } Rule ( 8 ) knterpretation Schemata with condition Gramlnar rule ~ ) ( f2 CASE ) = i.~ CON { \ [ NP : f ?</sentence>
				<definiendum id="0">-FORM</definiendum>
				<definiens id="0">f2\ ] , \ [ AUX\ ] } Rule ( '/ ) ( f~ AUX &amp; V-FORM ) = d\ [ AUXI</definiens>
			</definition>
			<definition id="3">
				<sentence>@ This schema checks whether verb form ( V-FORM ) is a proper titan for auxiliary verb .</sentence>
				<definiendum id="0">V-FORM )</definiendum>
				<definiens id="0">a proper titan for auxiliary verb</definiens>
			</definition>
			<definition id="4">
				<sentence>L_A Conditions NUM SPEC1 From noun From noun PL the PL a PL an PL ~D SG a/the SG a/the SG a/the SG an\ ] the SG an\ ] the SG an\ ] the SG X Result SPEC I SPEC Frem dot ~-I the `` I O *I O a i a the I the - '' I a an , an the I the -I an I X Rule B in Table E. ( 3 ) Compare ' ( gn word ) == an ' with ' ( t SeEC ) =an ' .</sentence>
				<definiendum id="0">PL a PL</definiendum>
				<definiens id="0">an PL ~D SG a/the SG a/the SG a/the SG an\ ] the SG an\ ] the SG an\ ] the SG X Result SPEC I SPEC</definiens>
			</definition>
			<definition id="5">
				<sentence>Actually t , his system was ilscd by junior high school st , dents° We collected mistakes and then ted back to th , ; system° This ~Lystem is one of applications of this \ ] Yamework in a limited d ( m ) aii ) .</sentence>
				<definiendum id="0">~Lystem</definiendum>
				<definiens id="0">junior high school st , dents° We collected mistakes and then ted back to th</definiens>
			</definition>
</paper>

		<paper id="2148">
			<definition id="0">
				<sentence>R-Edge ( e ) return~ true iff e is an ~~ Edge .</sentence>
				<definiendum id="0">R-Edge ( e</definiendum>
			</definition>
			<definition id="1">
				<sentence>DelEdge ( dt~e ) returns dependency tree dt '' without edge e ( edge e is ' removed fro~ dr ) .</sentence>
				<definiendum id="0">DelEdge ( dt~e )</definiendum>
				<definiens id="0">returns dependency tree dt '' without edge e ( edge e is ' removed fro~ dr )</definiens>
			</definition>
</paper>

		<paper id="2113">
			<definition id="0">
				<sentence>An FST , M , is a pair &lt; NC~ , Z &gt; where N ~ is a set of start state urines and Z is a set of states .</sentence>
				<definiendum id="0">FST , M ,</definiendum>
				<definiendum id="1">N ~</definiendum>
				<definiendum id="2">Z</definiendum>
			</definition>
			<definition id="1">
				<sentence>A state Z i ~ Z is a triple &lt; N , T , A &gt; where N is the name of the state , T is an ordered sequence of transitions Ti , l &lt; i &lt; n , n = ITI and A is the truth value T if the state is au accepting state and the troth value F if it is a nonaceepting state. ( The notion of final state is not relevant here. Only the accepting/nonaccepting distinction is important. ) A transition T i ~ T is a pair &lt; ~i , Ni &gt; where q5 i is a transition pair &lt; ~x , ~0~ &gt; .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">T</definiendum>
				<definiens id="0">a triple &lt; N , T , A &gt; where</definiens>
				<definiens id="1">the name of the state</definiens>
				<definiens id="2">an ordered sequence of transitions Ti , l &lt; i &lt; n , n = ITI</definiens>
				<definiens id="3">a pair &lt; ~i</definiens>
			</definition>
			<definition id="2">
				<sentence>An element of a transition pair is either a phoneme , a phoneme class name , the symbol = or the empty string e. A phoneme is a character and is a member of the alphabet set .</sentence>
				<definiendum id="0">element of a transition pair</definiendum>
				<definiens id="0">a character and is a member of the alphabet set</definiens>
			</definition>
			<definition id="3">
				<sentence>A phoneme class is a set of phonemes .</sentence>
				<definiendum id="0">phoneme class</definiendum>
				<definiens id="0">a set of phonemes</definiens>
			</definition>
			<definition id="4">
				<sentence>&lt; = , e. &gt; is of type 535 The type intersection of a set of transition pairs { ~i I l &lt; i &lt; n } is n O'ff¢ , ~ ) where n x is a partial function from pairs of u'ansition i=I types to transition types as defined below. `` q n ' `` t 2 if x~ n , ' x 2 e TYP `` ~a n `` ~ = undefined otherwise n , ~ ' is defined as follows. ( 1 ) ocn x ' =:13 = ( a.\ [ 3 ) ' ( 2 ) ~.= n./ ( &amp; .~ ) ' = ( a.~ ) ' ( 3 ) =.f~ % ' ( cc\ [ ~ ) ' = ( a.D ' ( 4 ) tx.D n , ~ ' ( a.\ [ 3 ) ' = a.~ ( 5 ) a.\ [ ~ % ' c~.l~ = a.~ ( 6 ) =.= nx ' a.L3 = ot.13 ( 7 ) c~.= n.~ ' a.l~ = a.I 3 ( 8 ) =.1~ % ' c~.~ = a.l~ ( 9 ) a.~ c~ ' ~i.~ , = 5.~/c~ '' a.\ [ ~ An unprimed type `` c indicates that the transition type is supported. A primed type q : ' indicates that the transition type is unsupported. That is , there have been no e.x , x.e or x.x types in tim set of intersected types that produced the primed type. ( 1 ) is the origin of unsupported types. ( 2 ) and ( 3 ) state that neither ct.= nor =.ct can support a transition. ( 4 ) states that an unprimed type supports the corresponding primed type. ( 5 ) states that the intm'section of two identical .types is the same type. ( 6 ) States that the intersection of =.= and any type is that type. ( 7 ) and ( 8 ) state that the intersection of either =.o~ or co.= and a supported type is a supported type. ( 9 ) states that n , c ' is commutative and that the commutative closure of ( 1 ) - ( 8 ) also holds. A set of transition pairs { cI ) i } which subsmne ( 1 '' 5 t is licensed w.r.t. ( I ) t if LICENSED ( { Oi } , Ot ) holds. LICENSED ( { Oi } , O t ) if n , t'ffOi ) e TYP and ( nx'c ( Oi ) e { x.x x.e e.x } or n , ~x ( Oi ) e { ( x.x ) ' , =.= , =.x x.= } and Ot = &lt; ¢'¢ &gt; ) This definition implements the `` daisywheel '' .</sentence>
				<definiendum id="0">n x</definiendum>
				<definiens id="0">c~ ' ~i.~ , = 5.~/c~ '' a.\ [ ~ An unprimed type `` c indicates that the transition type is supported. A primed type q : ' indicates that the transition type is unsupported. That is , there have been no e.x , x.e or x.x types in tim set of intersected types that produced the primed type. ( 1 ) is the origin of unsupported types. ( 2 ) and ( 3 ) state that neither ct.= nor =.ct can support a transition. ( 4 ) states that an unprimed type supports the corresponding primed type. ( 5 ) states that the intm'section of two identical .types is the same type. ( 6 ) States that the intersection of =.= and any type is that type. ( 7 ) and ( 8 ) state that the intersection of either =.o~ or co.= and a supported type is a supported type. ( 9 ) states that n , c ' is commutative and that the commutative closure of ( 1 ) - ( 8 ) also holds. A set of transition pairs { cI ) i } which subsmne ( 1 '' 5 t is licensed w.r.t. ( I ) t if LICENSED ( { Oi } , Ot ) holds. LICENSED ( { Oi } , O t ) if n , t'ffOi ) e TYP and ( nx'c ( Oi ) e { x.x x.e e.x } or n , ~x ( Oi ) e { ( x.x ) ' , =.= , =.x x.= } and Ot = &lt; ¢'¢ &gt; ) This definition implements the `` daisywheel ''</definiens>
			</definition>
			<definition id="5">
				<sentence>ACCEPTS ( M , N , Ot , O , N ' ) if M = &lt; Net , Z &gt; and Z i = &lt; N , T , A &gt; e Z and 3T k = &lt; Ok , Nk &gt; e~ P ( T ) ) Ok subsumes Ot and = &lt; , I , j , Nj &gt; P ( r ) 1Sj &lt; k and ~j subsumes • r ( ACCEPTS replaces the more usual state transition function ft. ) P ( T ) is a total function that takes the transition sequence T as argument and returns a transition sequence T ' containing the same set of elements as T with the following ordering of the elements of T'. All =.= transitions follow all non-=.= transitions. All =.~ or f~.= transitions precede all =.= transitions and follow all other transitions. Relative ordering of transitions in T ' is as in T otherwise. The definition above implies that transition precedence is by citation order with two exceptions. All transition pairs which have non-= first and second elements take precedence over any pairs of the form &lt; o~ , = &gt; and &lt; = , a &gt; and all non- &lt; = , = &gt; transition pairs take precedence over a transition pair of the form &lt; = , = &gt; .</sentence>
				<definiendum id="0">ACCEPTS</definiendum>
				<definiendum id="1">P ( T )</definiendum>
				<definiens id="0">a total function that takes the transition sequence T as argument and returns a transition sequence T ' containing the same set of elements as T with the following ordering of the elements of T'. All =.= transitions follow all non-=.= transitions. All =.~ or f~.= transitions precede all =.= transitions and follow all other transitions. Relative ordering of transitions in T ' is as in T otherwise. The definition above implies that transition precedence is by citation order with two exceptions. All transition pairs which have non-= first and second elements take precedence over any pairs of the form &lt; o~ , = &gt; and &lt; = , a &gt; and all non- &lt; = , = &gt; transition pairs take precedence over a transition pair of the form &lt; = , = &gt;</definiens>
			</definition>
			<definition id="6">
				<sentence>The cross product of two transition seqnences T 1 and T 2 is a sequence T t x 'I'~ = &lt; T ' , _ &lt; &gt; where T ' is tile set defined below and - &lt; is a total ordering. T ' = { T k \ [ T i e T 1 and Tj e T 2 and T k = T i n Tj is defined } . &lt; can be any total ordering which satisfies the following partial ordering on T ' : VT m ~ T ' 9 V m=T in~I iandr iE r landTje T e VT e T ' -9 T n=T oc3 TpandT O c T 1 andTp ~ T 2 ( Ill &lt; n go- ) , -7 ( o &lt; i and p _ &lt; j ) and-1 ( o - &lt; i and p &lt; j ) ) In particular , the ordering of tile following sequence satisfies the partial order : &lt; T &lt; III &gt; '' '' T &lt; l , n &gt; ... T &lt; m , l &gt; T &lt; m , n &gt; &gt; where T &lt; i , j &gt; names tile intersection of the transitions T i ~ T l and Tj e T 2 , m = IWl\ [ and n = IT2\ ] , The intersection T i c5 Tj of two transitions T i = &lt; t~i , Ni &gt; and Tj = &lt; ( bj,5 &gt; is &lt; tl ) i ( 5 q ) '.l ' &lt; Ni'Nj &gt; &gt; ' If ( 1 ) i = .</sentence>
				<definiendum id="0">&lt;</definiendum>
				<definiens id="0">a sequence T t x 'I'~ = &lt; T ' , _ &lt; &gt; where T ' is tile set defined below and -</definiens>
				<definiens id="1">a total ordering. T ' = { T k \ [</definiens>
				<definiens id="2">&lt; i and p _ &lt; j ) and-1 ( o - &lt; i and p &lt; j ) ) In particular , the ordering of tile following sequence satisfies the partial order : &lt; T &lt; III &gt; '' '' T &lt; l , n &gt; ... T &lt; m , l &gt; T &lt; m , n &gt; &gt; where T &lt; i</definiens>
			</definition>
			<definition id="7">
				<sentence>&lt; ( zi , \ [ ~i &gt; and ( l ) j = &lt; ~ , \ [ 3j &gt; then • i ( -i ~j is defined as follows &lt; a i n cry , ~i n \ [ 3i &gt; if ~ ( d ) i ) c~ ' x ( Oj ) a 7'YP 4~ i n cI~ ) = undefined otherwise The intersection of two phoneme pair elements x and y is defined as follows x ny= x ifx =y x ify = = y ifx = = x if y is a phoneme class and x c : y y ifx is a phoneme class and y ~ x x ¢~ y if both x and y are phoneme classes undefined otherwise The composite FST is nondeterministic with respect to ~ ; and the set of start states and is deterministic otherwise .</sentence>
				<definiendum id="0">y y ifx</definiendum>
				<definiendum id="1">FST</definiendum>
				<definiens id="0">follows &lt; a i n cry , ~i n \ [ 3i &gt; if ~ ( d ) i ) c~ ' x ( Oj ) a 7'YP 4~ i n cI~ ) = undefined otherwise The intersection of two phoneme pair elements x and y is defined as follows x ny= x ifx =y x ify = = y ifx = = x if y is a phoneme class and x c</definiens>
				<definiens id="1">a phoneme class and y ~ x x ¢~ y if both x and y are phoneme classes undefined otherwise The composite</definiens>
			</definition>
			<definition id="8">
				<sentence>If Z i = &lt; Ni ' , TI , Ai &gt; and Ej = &lt; Nj ' , T2 , Aj &gt; and T i E T 1 and Tj T 2 then the composition T i * Tj of two transitions T i = &lt; Oi , Ni &gt; and Tj = &lt; ~j , Nj &gt; is defined by r , *~= &lt; &lt; = , = &gt; , &lt; NvNj &gt; &gt; &lt; &lt; ~ , I3 &gt; , ~/vF &gt; &lt; &lt; a , ~ &gt; .</sentence>
				<definiendum id="0">Tj</definiendum>
				<definiendum id="1">I3 &gt;</definiendum>
				<definiens id="0">T i E T 1 and Tj T 2 then the composition T i * Tj of two transitions T i = &lt; Oi , Ni &gt; and</definiens>
			</definition>
			<definition id="9">
				<sentence>Karttunen , L. ( 1983 ) KIMMO : A general morphological processor .</sentence>
				<definiendum id="0">KIMMO</definiendum>
				<definiens id="0">A general morphological processor</definiens>
			</definition>
			<definition id="10">
				<sentence>Koskenniemi , K. ( 1983 ) Two-level morphology : A general computational model for word-form recognition and production .</sentence>
				<definiendum id="0">Two-level morphology</definiendum>
				<definiens id="0">A general computational model for word-form recognition and production</definiens>
			</definition>
</paper>

		<paper id="2105">
			<definition id="0">
				<sentence>Abstract : A new type of abstract automaton is introduced , and both formal and linguistic implications are discussed , most importantly a new possibility of proving certain formal properties of ( natural ) languages and their grammars ( such as context-freeness ) and of refinement of the Chomsky hierarchy .</sentence>
				<definiendum id="0">Abstract</definiendum>
				<definiens id="0">properties of ( natural ) languages and their grammars ( such as context-freeness ) and of refinement of the Chomsky hierarchy</definiens>
			</definition>
			<definition id="1">
				<sentence>ic strncture , on condition that the computation was successful , i.e. the word represented by the input list was in the language defined by the automaton , all nondeterministic decisions of the automaton were correct ( the automaton `` guessed '' what to do ) and , hence , the computation finished in an accepting configuration .</sentence>
				<definiendum id="0">ic strncture</definiendum>
				<definiens id="0">the word represented by the input list was in the language defined by the automaton , all nondeterministic decisions of the automaton were correct ( the automaton `` guessed '' what to do ) and , hence , the computation finished in an accepting configuration</definiens>
			</definition>
</paper>

		<paper id="1033">
			<definition id="0">
				<sentence>*//is the set of individuals * The following holds : every accomplishment x is assigned exactly one start-event x I and either one stop-event x 2 or one cul-event x2 , every activity x is assigned exactly one start-event x I and one stop-event ~ , every achievement x is assigned exactly one cul-event x2 , whereby tile assignment of secondary events to primary events , in combination with conditions about the relations &lt; , o can be graphically illustrated as follows : x x 6 Acc , or x 6 Act : ... ... ... x I x 2 tx 1 &lt; x2 &amp; x 1 ox &amp; x2 ox &amp; ( VyEEUSUP ( 7 '' ) ( y &lt; x ~- &gt; y &lt; Xl ) &amp; ( x &lt; y &lt; - &gt; x2 &lt; y ) ) ) 161 x × EAch : ... . x Z ( x2ox &amp; ( VyEEUSUP ( T ) ( x &lt; y &lt; - &gt; x2 &lt; y ) ) ) * The secondary events are considered as atomic : VxESecev , y , z~EUSUP ( T ) : ~ ( yox &amp; zox &amp; y &lt; z ) The axiom s A1 A6 , extended to all temporal units of the domain , hold for the relations &lt; , o , such that it follows that , with the inclusion of the linearity axiom : A7 Vx , yEEUsUP ( T ) : ( x &lt; y ; xoy ; y &lt; x ) o has the characteristic of being an equivalence relation , restricted to the secondary events. One can thus define : Vx , yESecev : x=py &lt; - &gt; xoy This allows the abbreviation `` x &lt; p y '' for elements of Secev with `` x &lt; y '' or `` x =p y '' . */7 , G are interpretation functions , such that F assigns every n-ary relation R a function over P ( T ) , which assigns every i E P ( T ) a subset of U n G assigns every n~ary relation R a set of n+l-tupels out ofExU n * b is a function which assigns in a one-to-one-correspondence every state s E S a pair &lt; i , &lt; R , Ul , ,.. , un &gt; &gt; with &lt; ul , ... , Un &gt; ~ F ( R ) ( i ) * In addition , the following correlation principle should hold : For every n-ary verb R and every n+l-tupel &lt; e , ul , ... , Un &gt; E G ( R ) there exists a state s E S and an interval i E P ( T ) such that b ( s ) = &lt; i , &lt; R ' , ul , ... , Un &gt; &gt; and either `` i c d ( e ) '' or `` i &lt; d ( e ) '' , whereby R ' represents the progressive variant ProgR of R. On the other hand , there should exist for every R ' , which is the progressive variant of an R and which is assigned an s by b , an n+ltupel E G ( R ) with the corresponding ordering and individual relations .</sentence>
				<definiendum id="0">yESecev</definiendum>
				<definiens id="0">tile assignment of secondary events to primary events , in combination with conditions about the relations &lt;</definiens>
				<definiens id="1">y &lt; x ~- &gt; y &lt; Xl ) &amp; ( x &lt; y &lt; - &gt; x2 &lt; y )</definiens>
				<definiens id="2">atomic : VxESecev , y , z~EUSUP ( T ) : ~ ( yox &amp; zox &amp; y &lt; z ) The axiom s A1 A6 , extended to all temporal units of the domain , hold for the relations &lt; , o , such that it follows that , with the inclusion of the linearity axiom : A7 Vx , yEEUsUP ( T ) : ( x &lt; y ; xoy ; y &lt; x ) o has the characteristic of being an equivalence relation</definiens>
				<definiens id="3">assigns every n-ary relation R a function over P ( T ) , which assigns every i E P ( T ) a subset of U n G assigns every n~ary relation R a set of n+l-tupels out ofExU n * b is a function which assigns in a one-to-one-correspondence every state s E S a pair &lt; i , &lt; R , Ul , ,.. , un &gt; &gt; with &lt; ul , ...</definiens>
				<definiens id="4">ul , ... , Un &gt; E G ( R ) there exists a state s E S and an interval i E P ( T ) such that b ( s ) = &lt; i , &lt; R ' , ul , ...</definiens>
				<definiens id="5">the progressive variant of an R and which is assigned an s by b , an n+ltupel E G ( R ) with the corresponding ordering and individual relations</definiens>
			</definition>
			<definition id="1">
				<sentence>These possible characteristics of a text should be reflected by the different possibilities of assigning an embedding function relative to a DRS in a model M. We therefore require for a function f , which maps discourse referents of a DRS K onto entities in an expanded point-event structure with a domain of individuals , in addition to the usual features/eL Reyle/ , the following : M I=f , K start ( e ) &lt; end ( e ) iff startM ( f ( e ) ) &lt; M endM ( f ( e ) ) and either endM ( f ( e ) ) E Stop M or endM ( f ( e ) ) E Cul M In addition the DRS construction algorithm must contain the rule : For all e E Ace , e ' E E U S U P ( T ) : end ( e ) &lt; p e ' - &gt; end ( e ) ~ Cnl If one requires , as in the correlation principle , that every state introduced by the progressive of an accomplishment verb be contained by an event , then the question whether e has a culmination ( that is , represents a true accomplishment ) or just a stop-point ( that is , corresponds to the activity reading of an accomplishment ) , is transformed into the question of the existence of the corresponding f. Compat~ to this end the analogous approach in/Schulz/ .</sentence>
				<definiendum id="0">K start</definiendum>
				<definiens id="0">maps discourse referents of a DRS K onto entities in an expanded point-event structure with a domain of individuals</definiens>
			</definition>
			<definition id="2">
				<sentence>K is a set of DRSs .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">a set of DRSs</definiens>
			</definition>
			<definition id="3">
				<sentence>f is an embedding function of a DRS K in an intensional model if f maps/ all individual reference markers of U k onto elements of U Uw , all event reference markers of U k onto elements of U Ew , all state reference markers of U k onto elements of U Sw , all DRS reference markers of U k onto elements of K , all n-place condition reference markers of U k onto n-ary predicative DRS 's in K '' , all belief reference markers of U k onto sets of `` delineated DRS 's '' in K ' .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">DRS K</definiendum>
				<definiens id="0">U k onto sets of `` delineated DRS 's '' in K '</definiens>
			</definition>
			<definition id="4">
				<sentence>The system considered here allows a solely partial ordering of events anti states on the representational level , which can be completed on the basis of world knowledge stored in a data base , with respect to the ordering and the dassiflcation into Aktionsarteu .</sentence>
				<definiendum id="0">level</definiendum>
				<definiens id="0">can be completed on the basis of world knowledge stored in a data base</definiens>
			</definition>
</paper>

		<paper id="2150">
			<definition id="0">
				<sentence>3 If we reconstruct directed labeled connected rooted aeyelic graphs ( DAGs ) as transition graphs of connected rooted acyelic finite state automata , whose leaves ( states without leaving transitions ) are labeled by a partial function rrt with atoms of a set A ( 4 ) = ( Q , L,6 , qo , A , m ) ) , s then we can state the definition of the derivability relation A~ as follows .</sentence>
				<definiendum id="0">qo</definiendum>
				<definiens id="0">directed labeled connected rooted aeyelic graphs ( DAGs ) as transition graphs of connected rooted acyelic finite state automata , whose leaves ( states without leaving transitions</definiens>
			</definition>
			<definition id="1">
				<sentence>J is a node of c ' , not contained in c , the value of q~ is 6~* ( q~ , q ) and the value of q~ for p is 6* ( qo , P ) , then the value of qV for , ~ .</sentence>
				<definiendum id="0">J</definiendum>
				<definiens id="0">a node of c '</definiens>
			</definition>
			<definition id="2">
				<sentence>The positive part ( compleleness ) , which requires that the input structure ( 4 ) in ) is subsumed by the derived structure ( 4 ) , ) ( 4 ) i , , E 4 ) , ) , can be made explicit by two kinds of constraints : existential constraints , which demand that COMPa : all paths of the input structure are derived , and reentrancy constraints , whicb demand that COMPb : all reentraueies of the input strneture are derived ) 2 Tim negative part ( coherence ) which demands that COH : the derived structure is subsumed by the input structure ( 4 ) , , L ( bl , ) ensures that the f-structure of the generated string is the unique minimal structure that satisfies the completeness constraints expressed by the input structure .</sentence>
				<definiendum id="0">positive part</definiendum>
				<definiens id="0">requires that the input structure ( 4 ) in ) is subsumed by the derived structure ( 4 ) , ) ( 4 ) i , , E 4 ) , ) , can be made explicit by two kinds of constraints : existential constraints , which demand that COMPa : all paths of the input structure are derived , and reentrancy constraints</definiens>
				<definiens id="1">bl , ) ensures that the f-structure of the generated string is the unique minimal structure that satisfies the completeness constraints expressed by the input structure</definiens>
			</definition>
			<definition id="3">
				<sentence>/~ DEFINITION 2.2 A terminal string s is gencn~ble from an input structure ~n ( r¢ ( ~b~n , s ) ) iffthere is a sequence We ... wn such that o Wo = ( cs , ~ , ¢S , ¢~ , h~s ) and o for allw~ = ( c , ~ , ~ , ~ , h~ ) , w~+~ = { d , ~b ' , ~ ' , ~n , h ~ ' ) ( 0 &lt; _ i &lt; n ) there is a generator rule V -- * ( cr , ~r , ~r , C~ ) and V is the label of a leaf/~ of c o the substructure rooted by h # ( ~b~ ) is ( aside from the +-labels ) an extension of ~ o for all ( j p ) =~ ( i q ) etc. in C~ , 6~ , , ( h4 ' ( ~bp .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the label of a leaf/~ of c o the substructure rooted by h # ( ~b~ ) is ( aside from the +-labels ) an extension of ~ o for all ( j p ) =~ ( i q</definiens>
			</definition>
			<definition id="4">
				<sentence>is isomorphic to ~ { n ( h~ is an isomorphism ) s is the terminal string of the c-structure ofwn .</sentence>
				<definiendum id="0">h~</definiendum>
				<definiens id="0">the terminal string of the c-structure ofwn</definiens>
			</definition>
			<definition id="5">
				<sentence>According to condition ( ** ) , the generator constructed by the algorithm for an ( extended ) LFG is a parser or transducer for well-formed semantic structures which , in principle , constructs for an input structure all sentences which have this structure as its semantic structure , analogously to section 2 .</sentence>
				<definiendum id="0">LFG</definiendum>
				<definiens id="0">a parser or transducer for well-formed semantic structures which , in principle</definiens>
			</definition>
			<definition id="6">
				<sentence>i~there is a sequence To ... wn such that o Wo = ( cs , ~s , ¢S , Ces ) and o for all ¢0~ = ( c , ~ , ¢ , c+ ) , ~+~ = ( e ' , ~ ' , ¢ ' , c '' ' ) ( 0 &lt; i &lt; ~ ) there i~ arule V -- + ( c , , % , ¢LCg ) and V is a label of a leaf it of c c ' is the result of expanding it in e by cr ~/~ is the minimal extension of • which results from • by unifying @ , .</sentence>
				<definiendum id="0">i~there</definiendum>
				<definiendum id="1">V</definiendum>
				<definiendum id="2">cr ~/~</definiendum>
				<definiens id="0">a label of a leaf it of c c</definiens>
				<definiens id="1">the minimal extension of • which results from • by unifying @ ,</definiens>
			</definition>
			<definition id="7">
				<sentence>DEFINITION 3.2 A terminal string s is generable from an input structure ~C~n under a constraint set C eel ' ( F~ ( Z~ , , s , C~e~ ' ) ) iff there is a sequence wQ ... w. such that o w0 = ( as , ~t , cs , ~ , , , h~ , C $ ) and ° for all wi = ( c , @ , dp , Ein , ha , C¢ ) , w , +l = ( d , q2 ' , ~b ' , ~in , ha~ , C ¢ ' ) ( 0 &lt; i &lt; u ) there is a generator rule V ~ ( er , qlr , ¢ '' , Ch and V is a label of a leaf p of c o the substructure rooted by h~ ( ~ ( ¢t~ , o ' ) ) is ( apart from the +labels ) an extension of li\ ] r ( the substructure of @ , rooted by ~ , ( q~ , a ) ) o for all pure semantic constraints ( j a p ) =c ( i a q ) etc. in C~r for which ~f ( ~b,4 , a ) and 6 ( ¢v.i , a ) is defined , 8 '' , ( h a ( ~ ( 5,4 , a ) ) , p ) ~t. ( h~ ( ~ ( ¢~ .</sentence>
				<definiendum id="0">dp</definiendum>
				<definiendum id="1">Ch</definiendum>
				<definiendum id="2">V</definiendum>
				<definiens id="0">a generator rule V ~ ( er , qlr , ¢ '' ,</definiens>
				<definiens id="1">a label of a leaf p of c o the substructure rooted by h~ ( ~ ( ¢t~ , o '</definiens>
				<definiens id="2">a ) ) o for all pure semantic constraints ( j a p ) =c ( i a q ) etc. in C~r for which ~f ( ~b,4 , a</definiens>
			</definition>
			<definition id="8">
				<sentence>SThis preflxi~ procedure rune analogously for all other types of constraints , in LFG there are constrMats of the form ( v p ) =c ( P q ) , ( v p ) , ( v p ) : c z and their negations ( ~ mid ~ , are node indices , q and p are sequences of attellmtea and z is an atomic value ) .</sentence>
				<definiendum id="0">constraints</definiendum>
				<definiendum id="1">z</definiendum>
			</definition>
			<definition id="9">
				<sentence>University of Michigan , Arm Arbor 1987 \ [ Kasper/Reunds 86\ ] Kasper , R.T. , Rounds , W. : A Logical Semantics for Feature Stntctures .</sentence>
				<definiendum id="0">W.</definiendum>
			</definition>
			<definition id="10">
				<sentence>In : Proceedings o\ ] COI , ING 86 , Bonn 1986 \ [ Wedeldnd 88\ ] Wedekind , J. : A Concept of Derivation for LFG .</sentence>
				<definiendum id="0">J.</definiendum>
				<definiens id="0">A Concept of Derivation for LFG</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>i ) where M is the total length of the French text , and M ( f ' ) is the number of occurrences off t in that text ( as before ) .</sentence>
				<definiendum id="0">M</definiendum>
				<definiens id="0">the total length of the French text</definiens>
				<definiens id="1">the number of occurrences off t in that text ( as before )</definiens>
			</definition>
			<definition id="1">
				<sentence>A good starting point is as follows : A. Make Q ( ejle , ) = l/K , where K is the size of the English vocabulary .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the size of the English vocabulary</definiens>
			</definition>
			<definition id="2">
				<sentence>( ii ) Compute the mutual information values l ( e , ; f ) by formula ( Y2 ) , and for each f find the 20 words e , for which I ( e , ; f ) is largest .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">for which I ( e , ;</definiens>
			</definition>
			<definition id="3">
				<sentence>To find fixed locutions in English , we can use the final probabilities QL and QR obtained by tile method of the previous section to compute mutual informations between primary and secondary word pairs , QR ( e ' I e ) IR ( e ; e r ) = log -- - ( 5.3 ) P ( e ' ) and QL ( e ' I e ) 1L ( e~ ; e ) = log P ( e ' ) where P ( e ' ) = C ( e ' ) /N is the relative frequency of occurrence of the secondary word e ' in the English text ( C ( e ' ) denotes the number of occurrences of e ' in the text of size N ) , and QR and QL are the average secondary generation probabilities , QR ( e'\ ] e ) = ZQR ( e ' , i\ ] e ) ( 5,4 ) i and Ql .</sentence>
				<definiendum id="0">QR</definiendum>
				<definiendum id="1">QR</definiendum>
				<definiens id="0">probabilities QL and QR obtained by tile method of the previous section to compute mutual informations between primary and secondary word pairs</definiens>
				<definiens id="1">e ' ) where P ( e ' )</definiens>
				<definiens id="2">the number of occurrences of e ' in the text of size N ) , and</definiens>
			</definition>
			<definition id="4">
				<sentence>lation tO select the correct 'sense ' of a Iocutioll is to eonsh uct a contextual glossary based on a probability of the form P ( el J ; g'IFI ) where e and f are English anrl French locutions , ; tnd q , ilq denotes a 'lexical ' equivalence class of the scalence F The tu , ; t of class membership woukl typically depend on tilt pre~ : ence of SOIIIC contbination of words in F. The choice of an app ; opriate eqtfivalcncc chtssification schenlc would , of course , be . '</sentence>
				<definiendum id="0">ilq</definiendum>
				<definiens id="0">to eonsh uct a contextual glossary based on a probability of the form P ( el J ; g'IFI ) where e and f are English anrl French locutions</definiens>
			</definition>
			<definition id="5">
				<sentence>Mercer : A maximum likelihood approach to contimlous speech recognition , IEEE Traosaclioos on Pattern Analysis and Machine Intelligence , PAM I-5 ( 2 ) : 179-190 , March 1983 .</sentence>
				<definiendum id="0">Mercer</definiendum>
				<definiens id="0">A maximum likelihood approach to contimlous speech recognition</definiens>
			</definition>
</paper>

		<paper id="1037">
</paper>

		<paper id="2156">
			<definition id="0">
				<sentence>Vagueness plays an important role in our communication in that it allows us to transfer partial information .</sentence>
				<definiendum id="0">Vagueness</definiendum>
				<definiens id="0">plays an important role in our communication in that it allows us to transfer partial information</definiens>
			</definition>
			<definition id="1">
				<sentence>The move/~ = ( Ax , A~ ) at each step is given as follows : • ~ = ( Az , A~ ) = K. ( OP\ ] Ox , OPy ) ~ where K is a positive constant .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">a positive constant</definiens>
			</definition>
			<definition id="2">
				<sentence>dvo = V ( I~ co~ 20 + 1~ sh 0 cos 0 ) up , = c ( 1 : sin o cos o + 1~ sin ~o ) where , C is a positive co.rant , and / = ( f. , \ ] , ) is a virtual force from other constraints .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a virtual force from other constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>SPRINT determines the temporary position of objects from the root of the dependency network .</sentence>
				<definiendum id="0">SPRINT</definiendum>
				<definiens id="0">determines the temporary position of objects from the root of the dependency network</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>UCG is one of several recent grammar formalisms \ [ Calder et al. 86 , Karttunen 86 , Pollard 85\ ] which are highly lexicalist , i.e. rules of syntactic combination are not a language-specific component of the grammar , but are very general in character , and combinatory information is primarily associated with lexical items .</sentence>
				<definiendum id="0">UCG</definiendum>
			</definition>
			<definition id="1">
				<sentence>namely , `` possible translation '' ( which is symmetric } , and `` best translation '' given the current context and much extra-linguistic knowledge ( which is not symmetric } .</sentence>
				<definiendum id="0">extra-linguistic knowledge</definiendum>
				<definiens id="0">symmetric } , and `` best translation '' given the current context</definiens>
			</definition>
			<definition id="2">
				<sentence>The use of Isomorphic Grammars is another way of being explicit about this , tuning the grammars themselves rather than their inputs/outputs , which offers a greater possibility of bi-directionality than the transfer approach .</sentence>
				<definiendum id="0">Isomorphic Grammars</definiendum>
				<definiens id="0">another way of being explicit about this , tuning the grammars themselves rather than their inputs/outputs , which offers a greater possibility of bi-directionality than the transfer approach</definiens>
			</definition>
			<definition id="3">
				<sentence>Landsbergen assumes the existence of compositional grammars for two languages , that is , grammars in which i ) basic expressions correspond to semantic primitives and ii ) each syntactic rule that builds up a complex linguistic expreaqion from simpler ones is paired with a semantic rule that builds the meaning of the complex expression from the meanings of the simpler ones .</sentence>
				<definiendum id="0">Landsbergen</definiendum>
				<definiens id="0">assumes the existence of compositional grammars for two languages , that is , grammars in which i ) basic expressions correspond to semantic primitives and ii</definiens>
			</definition>
			<definition id="4">
				<sentence>Unification Gategorinl Grarimaar is such a formalism , which combines a categorial treatment of syntax with semantics similar to Kamp 's : Vliscourse Representation \ [ Kamp 81\ ] .</sentence>
				<definiendum id="0">Unification Gategorinl Grarimaar</definiendum>
			</definition>
			<definition id="5">
				<sentence>Features are indicated by the operator A. A category is either a basic category , or of the form A/B , where A is ~ category and B is a sign .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">a sign</definiens>
			</definition>
			<definition id="6">
				<sentence>Since events , states etc. are primitive semantic objects , InL permits a first order treatment of modifiers .</sentence>
				<definiendum id="0">InL</definiendum>
				<definiens id="0">primitive semantic objects</definiens>
			</definition>
			<definition id="7">
				<sentence>Unification ensures for instance that predicates have argu .</sentence>
				<definiendum id="0">Unification</definiendum>
				<definiens id="0">ensures for instance that predicates have argu</definiens>
			</definition>
			<definition id="8">
				<sentence>As was mentioned , monolinguM UCG signs consist of four features : Phonology , Syntax , Semantics , and Order .</sentence>
				<definiendum id="0">monolinguM UCG</definiendum>
				<definiens id="0">signs consist of four features : Phonology , Syntax , Semantics , and Order</definiens>
			</definition>
			<definition id="9">
				<sentence>That the semantics of SL and TL signs unify is a necessary condition for them to stand in the relation of translation equivalence .</sentence>
				<definiendum id="0">TL signs unify</definiendum>
				<definiens id="0">a necessary condition for them to stand in the relation of translation equivalence</definiens>
			</definition>
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>x ) I I ( ReCap ( ~ I 2 ) ) ( ICat N=ROOT ) ( ~um SG ) I I 3 ( ICat N-ENDING ) ( Hum SG ) | : ( ReCap ( + 1 4 ) ) ( ICat N-ROOT ) ( Hum PL ) | 5 ( Ieat N-ENDING ) ( N.m PL ) \ ] examples \ [ Liliputl-o~raat , MinisendeL Riesewischlauch \ [ __ Fig .</sentence>
				<definiendum id="0">ICat N=ROOT )</definiendum>
				<definiendum id="1">Ieat N-ENDING</definiendum>
				<definiens id="0">ICat N-ENDING ) ( Hum SG ) | : ( ReCap ( + 1 4 ) ) ( ICat N-ROOT )</definiens>
			</definition>
			<definition id="1">
				<sentence>The window composition provides for the definition of compositional rules and constituents ( affixes ) .</sentence>
				<definiendum id="0">window composition</definiendum>
				<definiens id="0">provides for the definition of compositional rules and constituents ( affixes )</definiens>
			</definition>
			<definition id="2">
				<sentence>In the case of non-composed words , for example , Word Mm\ ] ager may simply navigate in the tree which structures the Inflectional rules ( specified in the window inflection ) , posing questions according to the structuring criteria .</sentence>
				<definiendum id="0">Inflectional rules</definiendum>
				<definiens id="0">specified in the window inflection</definiens>
			</definition>
</paper>

		<paper id="1047">
			<definition id="0">
				<sentence>For instance , passing the dislocated element bound by 'Who/ ' into $ 1 and passing it into S , are both O.K. , because S~ is the cmnplement of 'know ' and S~ is the complement of 'that ' ( whether you might employ a transformational account or such theories as GPSG , HPSG , and LFG . )</sentence>
				<definiendum id="0">S~</definiendum>
				<definiens id="0">the complement of 'that ' ( whether you might employ a transformational account or such theories as GPSG , HPSG , and LFG</definiens>
			</definition>
			<definition id="1">
				<sentence>In ( 9 ) , Sa is the complement of 'claim ' .</sentence>
				<definiendum id="0">Sa</definiendum>
				<definiens id="0">the complement of 'claim '</definiens>
			</definition>
			<definition id="2">
				<sentence>/Mills 1986/ Mills , A.E. : The Acquisition of Gender : A Study of English and German , in Springer Series in Language and Communication , Springer-Verlag , Berlin Heiderberg .</sentence>
				<definiendum id="0">A.E.</definiendum>
				<definiens id="0">The Acquisition of Gender : A Study of English and German</definiens>
			</definition>
</paper>

		<paper id="2125">
			<definition id="0">
				<sentence>Scholars have for centuries been trying to find universally valid semantic atoms ( or primitives ) , but none of the many systems suggested has met with acknowledgement or proved applicable on any wider scale .</sentence>
				<definiendum id="0">Scholars</definiendum>
				<definiens id="0">have for centuries been trying to find universally valid semantic atoms ( or primitives</definiens>
			</definition>
			<definition id="1">
				<sentence>Metataxis is contrastive dependency syntax for translation .</sentence>
				<definiendum id="0">Metataxis</definiendum>
			</definition>
</paper>

		<paper id="1056">
			<definition id="0">
				<sentence>Jackendoff , R. , X-bar Syntax : A study of Phrase Structure .</sentence>
				<definiendum id="0">X-bar Syntax</definiendum>
				<definiens id="0">A study of Phrase Structure</definiens>
			</definition>
</paper>

		<paper id="2153">
			<definition id="0">
				<sentence>Machine readable dictionaries ( MRDs ) contain knowledge about language and the world essential for tasks in natural language processing ( NLP ) .</sentence>
				<definiendum id="0">Machine readable dictionaries</definiendum>
				<definiens id="0">MRDs ) contain knowledge about language and the world essential for tasks in natural language processing</definiens>
			</definition>
			<definition id="1">
				<sentence>Approach III employs the most hand-coding because it develops and builds lexical entries for a very carefully controlled defining vocabulary of 3,600 word senses ( 1,200 words ) .</sentence>
				<definiendum id="0">III</definiendum>
				<definiens id="0">employs the most hand-coding because it develops and builds lexical entries for a very carefully controlled defining vocabulary of 3,600 word senses ( 1,200 words )</definiens>
			</definition>
			<definition id="2">
				<sentence>Localist approaches assume symbolic network representations whose nodes are word senses and whose arcs are weights that indicate the relatedness of the word senses at the ends of the arcs .</sentence>
				<definiendum id="0">Localist approaches</definiendum>
				<definiens id="0">assume symbolic network representations whose nodes are word senses and whose arcs are weights that indicate the relatedness of the word senses at the ends of the arcs</definiens>
			</definition>
			<definition id="3">
				<sentence>LDOCE is a full-sized dictionary designed for learners of English as a second language that contains over 55,000 entries in book 'form and 41,100 entries in machinereadable form ( a type-setting tape ) .</sentence>
				<definiendum id="0">LDOCE</definiendum>
				<definiens id="0">a full-sized dictionary designed for learners of English as a second language that contains over 55,000 entries in book 'form and 41,100 entries in machinereadable form ( a type-setting tape )</definiens>
			</definition>
			<definition id="4">
				<sentence>The three CRL approaches all fall within the general position on computational semantics outlined above and are extensions of fairly !</sentence>
				<definiendum id="0">CRL</definiendum>
				<definiens id="0">approaches all fall within the general position on computational semantics outlined above</definiens>
			</definition>
			<definition id="5">
				<sentence>Co-occurrence data for the LDOCE controlled vocabulary has been collected .</sentence>
				<definiendum id="0">Co-occurrence data</definiendum>
				<definiens id="0">for the LDOCE controlled vocabulary has been collected</definiens>
			</definition>
			<definition id="6">
				<sentence>Plate , Tony ( 1987 ) FWCON : A l~sign for the Simtdation of Coxmec .</sentence>
				<definiendum id="0">FWCON</definiendum>
			</definition>
</paper>

		<paper id="2096">
</paper>

		<paper id="2123">
			<definition id="0">
				<sentence>The description of language consists of an analysis on three levels : ECS ( Eurotra-Constituent-Structure ) which describes language according to part/whole relations and word order , ERS ( Eurotra-Relational-Structure ) which describes language in terms of syntactic functions and IS ( Interface Structure ) which describes language according to deep syntactic relations enriched by semantic information such as semantic features for characterizing lexical units .</sentence>
				<definiendum id="0">description of language</definiendum>
				<definiens id="0">consists of an analysis on three levels : ECS ( Eurotra-Constituent-Structure ) which describes language according to part/whole relations and word order , ERS ( Eurotra-Relational-Structure ) which describes language in terms of syntactic functions and IS ( Interface Structure ) which describes language according to deep syntactic relations enriched by semantic information such as semantic features for characterizing lexical units</definiens>
			</definition>
			<definition id="1">
				<sentence>The CAT-formalism is the linguistic tool for the description of language .</sentence>
				<definiendum id="0">CAT-formalism</definiendum>
				<definiens id="0">the linguistic tool for the description of language</definiens>
			</definition>
			<definition id="2">
				<sentence>A translation-b-rule ( t-rule ) consists of a left hand side ( Ihs ) which defines a representation , in our case it would unify with the ECS-strueture in ( 2 ) ( b ) , and a right hand side ( rhs ) which defines a dominance and precedence relationship between the items represented by the variables ( capitals ) .</sentence>
				<definiendum id="0">translation-b-rule ( t-rule</definiendum>
				<definiens id="0">defines a dominance and precedence relationship between the items represented by the variables ( capitals )</definiens>
			</definition>
			<definition id="3">
				<sentence>While a configurational desoription consists in mapping given configurations onto a canonical schema , the x-bar schema , by explaining configurations which do not fit into x-bar as having 590 undergone movement transformations , a functional description consists in a mapping of phrase structures onto functional structures .</sentence>
				<definiendum id="0">configurational desoription</definiendum>
				<definiens id="0">consists in mapping given configurations onto a canonical schema , the x-bar schema , by explaining configurations which do not fit into x-bar as having 590 undergone movement transformations , a functional description consists in a mapping of phrase structures onto functional structures</definiens>
			</definition>
			<definition id="4">
				<sentence>These two rules are : TI : Verb fronting and T2 : Topicalization where COMP2 is the landing site for the finite verb and COMP1 thb landing site for X-double-bar .</sentence>
				<definiendum id="0">COMP2</definiendum>
				<definiens id="0">the landing site for the finite verb</definiens>
			</definition>
			<definition id="5">
				<sentence>A major part of every valency theory is the design of a test which is meant to determine the difference of complement and modifier .</sentence>
				<definiendum id="0">major part of every valency theory</definiendum>
				<definiens id="0">the design of a test which is meant to determine the difference of complement and modifier</definiens>
			</definition>
			<definition id="6">
				<sentence>( 31 ) unde f gov subj obj topic ( i ) I I I I kaufen mann e ( i ) haus ( 30 ) creates an empty np-slot which has to be interpreted as one of the b-rule slots subj , obj or obj2 in ( 10 ) .</sentence>
				<definiendum id="0">unde f gov subj obj topic</definiendum>
				<definiens id="0">mann e ( i ) haus ( 30 ) creates an empty np-slot which has to be interpreted as one of the b-rule slots subj , obj or obj2 in ( 10 )</definiens>
			</definition>
</paper>

		<paper id="1077">
			<definition id="0">
				<sentence>Formally , an intension is a mapping that associates with eve , y possible world ( actually , with indices that identify possible worlds ) a denotation , where a denotation is a set of entities ( individuals , relations , functions ) .</sentence>
				<definiendum id="0">intension</definiendum>
				<definiens id="0">a mapping that associates with eve , y possible world</definiens>
				<definiens id="1">a set of entities ( individuals , relations , functions )</definiens>
			</definition>
			<definition id="1">
				<sentence>On the contrary , we could assume that `` a dog like Ross 's '' is right only in this world ( in any world she wants the same kind of dog , which is the same as the kind of dog that Ross owns in this world ) or in every world ( whichever is the kind of dog Ross owns , in any world , Nadilt wants to have one of the same kind ) .</sentence>
				<definiendum id="0">whichever</definiendum>
				<definiens id="0">the same as the kind of dog that Ross owns in this world ) or in every world</definiens>
			</definition>
			<definition id="2">
				<sentence>The GULL ( General Understander of Likely Languages ) system works on the Italian language and is based on production nfles .</sentence>
				<definiendum id="0">GULL</definiendum>
				<definiens id="0">General Understander of Likely Languages ) system works on the Italian language</definiens>
			</definition>
			<definition id="3">
				<sentence>Tim semantic representation built by the interpreter consists in need of keeping apart the entity that partecipates in the main predication and the way it is defined .</sentence>
				<definiendum id="0">interpreter</definiendum>
				<definiens id="0">consists in need of keeping apart the entity that partecipates in the main predication and the way it is defined</definiens>
			</definition>
			<definition id="4">
				<sentence>A Context Space is a subplane of the CP , which contains a set of nodes and of arc connecting them .</sentence>
				<definiendum id="0">Context Space</definiendum>
				<definiens id="0">a subplane of the CP , which contains a set of nodes and of arc connecting them</definiens>
			</definition>
			<definition id="5">
				<sentence>The COUNP ( COUNmrPart ) arc specifies the seeping of nodes in the semantic representation : an mv COUNP that connects a node NI in a CS ( say CS1 ) m another node ( say N2 ) external to CS1 states that N2 is a countt .</sentence>
				<definiendum id="0">COUNP ( COUNmrPart ) arc</definiendum>
				<definiendum id="1">N2</definiendum>
				<definiens id="0">specifies the seeping of nodes in the semantic representation : an mv COUNP that connects a node NI in a CS ( say CS1 ) m another node</definiens>
				<definiens id="1">a countt</definiens>
			</definition>
			<definition id="6">
				<sentence>Generally , the search for tile correct referent in the discourse history is led by the presence of a RAS in the RP and by its incoming ( I-OF or SAME ) and outcoming ( a DEF-AS arc which connects it with the representation of the referent 's description ) arcs .</sentence>
				<definiendum id="0">outcoming</definiendum>
				<definiens id="0">a DEF-AS arc which connects it with the representation of the referent 's description ) arcs</definiens>
			</definition>
			<definition id="7">
				<sentence>NAME 8~ 7 ~P r ROSS -'qEJ Fig.2 -Basic ambiguous representation of the sentence `` Nadia wants a dog like Ross 's '' .</sentence>
				<definiendum id="0">Nadia</definiendum>
				<definiens id="0">wants a dog like Ross 's ''</definiens>
			</definition>
			<definition id="8">
				<sentence>_ k ... . -- -- , , , £m WHIS N4 @ Fig.4 -Representation in the CP of the opaque attributive reading of the sentence `` Nadia wants a dog like Ross 's .</sentence>
				<definiendum id="0">Nadia</definiendum>
				<definiens id="0">wants a dog like Ross 's</definiens>
			</definition>
			<definition id="9">
				<sentence>\ [ Kro , ffeld 86\ ] A.Kronfeld : Donnellan 's Distinction and a Colnpnta\ [ Lesmo &amp; Torasso 83\ ] L.Lesmo , P.Torasso : A Flexible Natural Language Parser Based on a Two-level Representation of Syntax : .</sentence>
				<definiendum id="0">P.Torasso</definiendum>
				<definiens id="0">A Flexible Natural Language Parser Based on a Two-level Representation</definiens>
			</definition>
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>The acoustic t ) art is a speech synthesiser which may be based on the production of allophones or diphones .</sentence>
				<definiendum id="0">acoustic t ) art</definiendum>
				<definiens id="0">a speech synthesiser which may be based on the production of allophones or diphones</definiens>
			</definition>
			<definition id="1">
				<sentence>Difficulties remain , however , with foreign words and a pathological class of word forms with more than one possible syllabification , e.g. balletic may be hyphenated ba/let-je ( small ballet ) and bal-le-tje ( small ball ) .</sentence>
				<definiendum id="0">bal-le-tje</definiendum>
				<definiens id="0">with foreign words and a pathological class of word forms with more than one possible syllabification</definiens>
			</definition>
			<definition id="2">
				<sentence>Morphological analysis consists of two stages : segmentation and parsing .</sentence>
				<definiendum id="0">Morphological analysis</definiendum>
				<definiens id="0">consists of two stages : segmentation and parsing</definiens>
			</definition>
</paper>

		<paper id="2091">
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>I I I. FREl ) 9 : A RUG grammar for Finnish ( 4 ) rACC -- -~ ~ , NIMATE -- F : ASE -- PRT CAT -- N COUNT -- F , DEF -- F , HEAD -- On\ ] -IND -- F ~NUMBER -- SG \PRT -- T qeft -- ~ % x -- -lunta read ing -- -- SameClause -- \ [ \ ] right -- -- NON E stem -- lumiNEXT -- ~COMP -- -NONE kHEAD -- -NONE i oB , -q I VFORM -- FIN comb1 -- NONE l lex -- sataa reading -- -- SameClause -- \ [ \ ] right -- -NONE stem -- sataFUNCTION -- -ADV H EAD -- ~ left -- -NONE lex -- aina reading -- -- SameClause-\ [ \ ] right -- -~ stem -- aina\ ] .03 FRED9 can be seen as an attempt to cast some of the granunatical ideas implicit in the procedural parser FPARSE of/Karlsson 1986/into a declarative form .</sentence>
				<definiendum id="0">RUG grammar</definiendum>
				<definiens id="0">FIN comb1 -- NONE l lex -- sataa reading -- -- SameClause -- \ [ \ ] right -- -NONE stem -- sataFUNCTION -- -ADV H EAD -- ~ left -- -NONE lex -- aina reading -- -- SameClause-\ [ \ ] right -- -~ stem -- aina\</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>~ : ; ; : i 'm 't &lt; lit ; y cau C2C , ~ ! '~ ~q } ~\ ] i : C0t\ ] I~JA~lid i\ ] il , S ~ ) y tlle\ ] lisi : ivt ; s Of I/so tile : J~Ggi~G . ( 'acflity~ ; ' ; td~MA is ~ @ it .h'~tc , two _~ogical pa~ls , though they ace ck~scly rob'rEdo h~ ttw. fi~'gt pa~.l a user ~al~ c.r , &lt; : at , :~ a set of cove. , . ' sy.a~hoJ : ~ , /~. s ; ~.4~x~r~tie~d i'onnalism has beta , defined ~ ) ~x , - ; pt ; ' , :i~'yi~g c : ovcr symbols iu a hJeraccificaJ way : rc.cm ' sive\ ] y - : ; ; ; ts : d i~.b~ ; h. ; ~my be put imo lists , th , :at sw. : h li~ : ts t ; e e : :ch~dex ! from oih~r lists k~ , &lt; : p , ; : eKy the fm~ { set of wordc|as~es co~/tai , .a ; d \ ] ~_ a ee~tail~ Cover sy~fl~ol , ( sc ; e al ; pelldix for ~totatiorO } h : i.el~ , , ; 3 rebels can be defined for ¢ : ach dimetlsiou. ( called `` scope ? ' ) of a erm~sitlo.u matrix stsparately , i.e. one dan defiiie a specific cov~r symb¢fi or~iy :2~x c.g , ~f~e first position h~ a transitioa t : ~d~ ' or triple.. , ¢~.licr .o s~.~t of cover symbols has bee~ defi~icd v. con , &lt; ; iste~ey ~ : h~ ; ck is mad % to ellslll=ethat tm wordeqaas &lt; , ; ~/l~l'~ ) ol be\ ] \ [ o~ll~s tD zalol'e thaii olle ( : over syl~lI } ol. A &lt; ' : el o\ [ ' cover symbol d , ~fh~itions ix cal ! ~ : d a `` mapping '' . .A. mapping has to b , ' : co~s/stei~t but no~ ~ec ( : ssmily eomplete~ Lo. rmt ovecy woidcla.sg my.st belong to ; ome dover symbol. Dift'e.rettt st. is of mappings crux be m~aged together as long as fl~ey stay eca~sistemo ~n lhe ~ : eeol~d pa~ of tl~c system a m , ; cr can create and marfipulak~ ~nmsMo~ probabfliiy mat.Goes with the help of a map.ph~g. Mais : h : Es &lt; : m~ b. : ~ cr~afed i_'xom ! shelled iext : in tiff ' &lt; : case the sy : ' , ~cm win , ~mbsm~e wordeJm ; se~ i-~ tlieir respective ( : ov~. ; r syl~l~2o\ [ s a~ld wo~.dcJassi : s llOt behmgirig to a*~y covey , ~p/nfi.x~\ ] w.~. e.~i , .~. , d '/ ! .w , ~.m.~tri~. , i , ~ ih'is we/ti : e : a : ,dy.a ; d text is ~ , ~o ! res~'rb : tcd , vdih x , &gt; ; F ' : .</sentence>
				<definiendum id="0">td~MA</definiendum>
				<definiendum id="1">ovcr symbols</definiendum>
				<definiens id="0">d i~.b~ ; h. ; ~my be put imo lists , th , :at sw. : h li~ : ts t</definiens>
				<definiens id="1">p , ; : eKy the fm~ { set of wordc|as~es co~/tai</definiens>
				<definiens id="2">a~ld wo~.dcJassi : s llOt behmgirig to a*~y covey</definiens>
			</definition>
</paper>

		<paper id="2115">
			<definition id="0">
				<sentence>hnplementations of this paradigm are | ) eing carried out by the author hy means of the translator generator SYGMART ( see /Chauch6/ , /Chauch~ , 1974/ and /Rolf , 1985/ ) , which pernfits the linguist to implement whatever he wants in the field of MT in an efficient way on a wide range of computers ( t¥om Atari1040STf via SUN 's to IBM VM/CMS mainframes ) .</sentence>
				<definiendum id="0">translator generator SYGMART</definiendum>
				<definiens id="0">pernfits the linguist to implement whatever he wants in the field of MT in an efficient way on a wide range of computers ( t¥om Atari1040STf via SUN 's to IBM VM/CMS mainframes )</definiens>
			</definition>
			<definition id="1">
				<sentence>The analysing stage comprises all stages which belong to morphof ogy~ surface grammar and possibly a large number of matters that belong to the field of semazatic interpretation ( see /Bakel , 1984/ ) .</sentence>
				<definiendum id="0">analysing stage</definiendum>
				<definiens id="0">comprises all stages which belong to morphof ogy~ surface grammar and possibly a large number of matters that belong to the field of semazatic interpretation</definiens>
			</definition>
			<definition id="2">
				<sentence>&amp; GRAM : NPCONS ( E ) .</sentence>
				<definiendum id="0">GRAM</definiendum>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>L lntroduetl , on Uniiieation C~tcgo~q_al Grammm ' ( UCG ) comlfines the syntactic insights of C~tegori~ll Grammar with the semantic insights of Discourse Rep , :escntafion Theory ( DRT , Kamp 1981 ) .</sentence>
				<definiendum id="0">Rep</definiendum>
				<definiens id="0">the syntactic insights of C~tegori~ll Grammar with the semantic insights of Discourse</definiens>
			</definition>
			<definition id="1">
				<sentence>'G , we employ three primitive categories : nomts ( tmun ) , sentences ( sent ) md noun phrases ( ltp ) These primitive categories i 'IIm work described here is SUl ) portexl by the EEC ESPRIT projec P393 ACORD : the Cons|ruction and Interrogation of Knowledge Bases asia Natural L~mguag ( ~ Text and Graphics .</sentence>
				<definiendum id="0">md noun phrases</definiendum>
				<definiens id="0">the Cons|ruction and Interrogation of Knowledge Bases asia Natural L~mguag ( ~ Text and Graphics</definiens>
			</definition>
			<definition id="2">
				<sentence>( 3 ) \ [ Index\ ] Formula Expression Sort a. \ [ el WALK ( e , x ) walk event b. Ix\ ] STUDENT ( x ) student singular object c. \ [ x\ ] \ [ PARK ( y ) , \ [ x\ ] \ [ IN ( x , y ) , MAN ( x ) \ [ I man in a park singular object d. \ [ m\ ] BUTlER ( m ) butter mass object e. \ [ s\ ] STAY ( s , x ) stay state We may write UCG rules as simple relations between signs .</sentence>
				<definiendum id="0">STUDENT</definiendum>
				<definiens id="0">( x ) student singular object c. \ [ x\ ] \ [ PARK ( y ) , \ [ x\ ] \ [ IN ( x , y ) , MAN ( x ) \ [ I man in a park singular object d. \ [ m\ ] BUTlER ( m ) butter mass object e. \ [ s\ ] STAY ( s , x</definiens>
			</definition>
			<definition id="3">
				<sentence>Amsterdam : Mathematical Centre Tracts .</sentence>
				<definiendum id="0">Amsterdam</definiendum>
				<definiens id="0">Mathematical Centre Tracts</definiens>
			</definition>
</paper>

		<paper id="1030">
			<definition id="0">
				<sentence>Rather than having a number of components of rules that are applied ( serially ) to linguistic input by a general process , WEP considers the words themselves as active agents ( word experts ) that interact with each other and with other knowledge sources in order to find the meaning of a fraQT~ent of text .</sentence>
				<definiendum id="0">WEP</definiendum>
			</definition>
			<definition id="1">
				<sentence>The `` analysis process '' consists of the collection of currently active experts tha\ [ + try to establish new concepts .</sentence>
				<definiendum id="0">analysis process ''</definiendum>
				<definiens id="0">consists of the collection of currently active experts tha\ [ + try to establish new concepts</definiens>
			</definition>
			<definition id="2">
				<sentence>Tests consist of a framespecification and an attribute-condltion .</sentence>
				<definiendum id="0">Tests</definiendum>
			</definition>
			<definition id="3">
				<sentence>The Parallel Expert Parser tries to present a truly distributed and parallel model of NLU with clearly defined experts on different levels , hierarchically conceived expert frames and rigidly restricted communication protocols .</sentence>
				<definiendum id="0">Parallel Expert Parser</definiendum>
				<definiens id="0">tries to present a truly distributed and parallel model of NLU with clearly defined experts on different levels , hierarchically conceived expert frames and rigidly restricted communication protocols</definiens>
			</definition>
			<definition id="4">
				<sentence>SMALL~ S.L. ( 1980 ) Word Expert Parsing : a Theory of Distributed Word-Based Natural Language Understanding .</sentence>
				<definiendum id="0">SMALL~ S.L.</definiendum>
			</definition>
</paper>

		<paper id="2165">
</paper>

		<paper id="2106">
			<definition id="0">
				<sentence>ruth conditions for a typical generic proposition can be formulated as follows ( 26 ) A ~eneric proposition with the subject s and the predicate P is t1~e if and only if for any xC-~ E s ( where E s is the extension of the general 'term s ) it is u s u a 1 1 y the case that P ( s ) is true° The meaning of usually\ [ can be described in the sa~e way as the meaning of other words is described in lexical semantics .</sentence>
				<definiendum id="0">E s</definiendum>
				<definiens id="0">the extension of the general 'term s ) it is u s u a 1 1 y the case that P ( s</definiens>
			</definition>
</paper>

		<paper id="2126">
			<definition id="0">
				<sentence>Speakers do so by attempting to get their listeners to construct an appropriate model : a discourse model .</sentence>
				<definiendum id="0">Speakers</definiendum>
				<definiens id="0">do so by attempting to get their listeners to construct an appropriate model : a discourse model</definiens>
			</definition>
			<definition id="1">
				<sentence>~ ACTION Withiu this view , `` an \ [ EVENT\ ] that is also an \ [ ACTION\ ] involves a character with a special rolethe one who is performing the \ [ ACTION\ ] , '' called the \ [ ACTOR\ ] ( p. 180 ) .</sentence>
				<definiendum id="0">ACTION\ ]</definiendum>
				<definiens id="0">involves a character with a special rolethe one who is performing the \ [ ACTION\ ] , '' called the \ [ ACTOR\ ] ( p. 180 )</definiens>
			</definition>
			<definition id="2">
				<sentence>\ [ type ( Mary , control-W , e ) A present ( e ) \ ] , meaning that E is an entity describable as 'the event in which Mary types control-W ' .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">an entity describable as 'the event in which Mary types control-W '</definiens>
			</definition>
			<definition id="3">
				<sentence>Generalization is defined as follows : Given an event description E1 and an event description E2 , 5As pointed out by \ [ Sidner 1982\ ] , referring expressions specify discourse entities ; referring expressions may co-specO~y the same discourse entity ; discourse entities represent objects or events in the world and people refer to objects and events in the world when they use referring expressions .</sentence>
				<definiendum id="0">Generalization</definiendum>
				<definiens id="0">follows : Given an event description E1 and an event description E2 , 5As pointed out by \ [ Sidner 1982\ ] , referring expressions specify discourse entities ; referring expressions may co-specO~y the same discourse entity ; discourse entities represent objects or events in the world and people refer to objects and events in the world when they use referring expressions</definiens>
			</definition>
			<definition id="4">
				<sentence>Generation is defined as follows : If an agent performs one action and thereby , without any effort on his/her part , does another , then we can say that his/her performance of the former action `` generated '' the performance of the latter .</sentence>
				<definiendum id="0">Generation</definiendum>
				<definiens id="0">If an agent performs one action</definiens>
			</definition>
</paper>

		<paper id="1078">
			<definition id="0">
				<sentence>For example , I can count the set of first-division footballers , Liverpool United is a subset of first division footballers , so I can count the set of Liverpool United players .</sentence>
				<definiendum id="0">Liverpool United</definiendum>
			</definition>
			<definition id="1">
				<sentence>For classes the pro-petty is that the relation highlights a subset of the class ( in tile `` is a member '' example this subset is ' { x } ) and for actions the property is that the relation s~ccities a p , 'u'ticular instance ( though possibly hypothetical ) of an action in which a certain condition hohls .</sentence>
				<definiendum id="0">pro-petty</definiendum>
				<definiens id="0">the relation highlights a subset of the class</definiens>
				<definiens id="1">the relation s~ccities a p , 'u'ticular instance ( though possibly hypothetical ) of an action in which a certain condition hohls</definiens>
			</definition>
</paper>

		<paper id="2110">
			<definition id="0">
				<sentence>~ In this section we have presented five types of relational nominals ( nominalizations , primitive relationals , primitive figure-grounds , double figure-grounds , and artifactual nominals ) , showing how they exhibit subtle but productive polysemous behavior .</sentence>
				<definiendum id="0">relational nominals</definiendum>
				<definiens id="0">primitive relationals , primitive figure-grounds , double figure-grounds , and artifactual nominals ) , showing how they exhibit subtle but productive polysemous behavior</definiens>
			</definition>
			<definition id="1">
				<sentence>The L-system is the particuhuorganization that the lexicon assumes independently of the conceptual system .</sentence>
				<definiendum id="0">L-system</definiendum>
				<definiens id="0">the particuhuorganization that the lexicon assumes independently of the conceptual system</definiens>
			</definition>
			<definition id="2">
				<sentence>The C-system is the organization of the concepts themselves and not the language .</sentence>
				<definiendum id="0">C-system</definiendum>
				<definiens id="0">the organization of the concepts themselves and not the language</definiens>
			</definition>
			<definition id="3">
				<sentence>The important thixa5 to note about this representation is that it predicates two distinct types of information over two different but rein , ted arguments , x and y ; inanely , that a door~ for example 4 is defined in terms of both the concrete object whi ( : h is artiNet ( the figure ) , and the space in the absence of this object ( the inverted-figure ) .</sentence>
				<definiendum id="0">artiNet</definiendum>
				<definiens id="0">the figure</definiens>
			</definition>
			<definition id="4">
				<sentence>Lexieal selection can be defined as the mapping from such representation of an event variable for the verb .</sentence>
				<definiendum id="0">Lexieal selection</definiendum>
				<definiens id="0">the mapping from such representation of an event variable for the verb</definiens>
			</definition>
</paper>

		<paper id="2108">
			<definition id="0">
				<sentence>~'mrk a+ Fl : ; l ) o¢ langnage developed hy the Prague research droop /~tgali ot alo 19691° This ~trati+icational de+ `` + eriptit'+n dividP+s the relatioi+ betmeen tile meaning and J~ : u phom : ,l : ical ( graphemic ) empressio~ into 5 l\ [ , +vei~ tecLogt+ah~illa~ieg ( levm+l o+ US+st abbrev , TR ) + , + : mr+ar : e synkam ( SR ) + ( neP'pfie/r+ic5 ( HR ) '+ phnnemics , ~nd phnnetit : ts ( graphmaics } , , Eact+ ef the ievel~ is interpreted a~ a set , o.i r'ep~esentations ~ach o~ ~hich { lilly d~scribes a sen .</sentence>
				<definiendum id="0">J~</definiendum>
				<definiens id="0">the relatioi+ betmeen tile meaning and</definiens>
			</definition>
			<definition id="1">
				<sentence>Jn the +r+ph the , CB ( P~ ) ilodes depelld nl+i their governor fro~ tht+ left ( ri+jhi : ) + `` i'lPe C+ &lt; Nit ) preperty o+ a node ~ is related ne ! y tn } ( its { , If , uhito tile topic and feces ef the sentence are global terms /~gall et al. 1986 , Itaji { : ev~ 1988/ , Prototypically , C } t ( N~ ) nodes beloe~l te tile topic ( focus ) ~ althoegh \ [ ; ~ node~ can alsn beloe~ t { + the topic ; ~nd N ) ~ oedes to the topic. Any nodI~ gen { ~ratml by ti i~ a ~r.,4plex teraiiral , ~iyE~hol e , ~ the ~. ; hapa ( a~ , tiRa ) ~ ahere ~ stands for a lexicai ( meanin U ) Hnit belonging to a certaie t+ord cl~s~s ( CL : j+t~ - : ~ogo Verb , Nets+ utl ; + , ~c &lt; t , ~ ) , and GRa is a .s~h~et o+ uram~+tt~er4e+ ( =valoe~ o+ +3rich eategt+r'ies a~++ de+Inltenemr++ number ' am1 ~s¢\ ] \ [ : \ ] t : :~ prepo~.i~ , itolie , ~ith ilo|~ri~ ov ~L , i+~h~+ , aspeet ~ed tloda\ ] it , y ~Jith v~.v'b~ ) appropriat~ for EL~f , ; .giJ tJutpo~ : stri~a\ ] o~ B re'tit ? Co'iS tl+u d~.p~if+den~ : V ' , +tr'~Jc'~i'~ ; ~L+ ; ~ '' the corr~pt~udtllg ~ ( It &amp; HICL. % '' tile ~ovt~FtJor 3~ , g~yg ph ? .E ( ? ~\ ] ~\ ] ~ ; i'L~ dopehdent d~ught~r nodm+~ the K~ ~led~ +~wt~c : i~ U f+hi : ! Nb onc , ,~ o. Llie ~ame level o { ' eLqbeddinijo ' ( hLz~e , k ~ ~\ ] ~ L , ¢ k ~ ~ ~ \ ] daoghter node~ ~rB ordered C~CCori ; lttPg to $ .i~K~3~in~i ~ ( : ~ . dynalaic i~il ; q+t ~.1~ otle~ eactt I ; ~ ( t:4 ) ~l ~ , he~hter ~tNi @ b~ : :~ 9 E~m~ddered le , ++~ ( morel dy~a~ic ~hal~ it~ ~.i~v~r~lP~ \ [ ~\ ] ~ m\ ] ilu~+~ bE+iiiu ~uhject to ~h~ ~y~temic order~+tj ~ ( ~u~ , ~ ! *ieitlon heloolo Such at+ approach re.*lt.++cts the rh : ++~u~. o- ; : ~a~i~ml : ~ or aetiv+~tion in the +++took ~t-i k~ , i~ul~ii ! \ ] c. , th ! ~ speaker i~ a~sotaed to ~h~r~ ~ith tilE ' ii~t~F~fY d~riu~ thK discottrse /R ' , g~ll 1986/. E : ! ? ml+~+e , + l '' i , z aeanino of thu ~nteoce ( l ) ~ane and ay brnther~ ~ho t : reatc~d a ~.~.~iiy~ ~iv'u in ~oston is geoerated hy G a~ ~tdlot+~r , 1 &lt; ( X~+ tier I } ) .3Bland ( ( cr+ear4~ +GRt v'ea£e } ' ( &lt; ~ht~ , \ [ JR++~b o ) &gt; ++ !</sentence>
				<definiendum id="0">CB</definiendum>
				<definiendum id="1">beloe~l te tile topic</definiendum>
				<definiendum id="2">GRa</definiendum>
				<definiendum id="3">.giJ tJutpo~</definiendum>
				<definiens id="0">a .s~h~et o+ uram~+tt~er4e+</definiens>
			</definition>
			<definition id="2">
				<sentence>mbul i~ that use stored at the accessible end of PSo Before the definition o~ th~ defining fuection F of G the meaning of uther symbols used ie preseet~d~ V ( the ~ord clare o~ the lexical unit of v ) and N denote the ~ord class of verbs and nouns~ respectiv~ly~ ~ ~ are variables for a word class ; ~ymbol C stauds ( symbols g~ ~ ' stand ) for complex nonterminal symbuls of the shape K~ , ~h~re ~ ~ ( ~ = 0 ) t ioe~ C stands ( U~ D ' stand ) fur the complex symbols ebich repreeent ( do nnt represent ) the CA 's wltuse lae~hers are just being derived or expanded~ denotes a eequence of elements of ~ stands for a symbol of the shape ~ Jff on the left= haud side of the same rule the variable k h~s the value 8 { etherwlse m stands for an empty sequence~ stands ~or 0 iff h~ on the loft-hand side o¢ the ~a~e rule has the value to otherwise ~ etands for i~ the priam and bar sy~ibols ( e.g. ~ ' , ~ ) have a similar meaning mS their simpla counterparts ( ioe~ g ) ( here it ~eaes that al~o ~ ~e { 0~1 } ) o If a superscript or a subscript uf a wriabln lias the va~ue 0 , it may be absent in the notation used .</sentence>
				<definiendum id="0">expanded~</definiendum>
				<definiens id="0">use stored at the accessible end of PSo Before the definition o~ th~ defining fuection F of G the meaning of uther symbols used ie preseet~d~ V ( the ~ord clare o~ the lexical unit of v ) and N denote the ~ord class of verbs and nouns~ respectiv~ly~ ~ ~ are variables for a word class ; ~ymbol C stauds ( symbols g~ ~ ' stand</definiens>
				<definiens id="1">U~ D ' stand ) fur the complex symbols ebich repreeent ( do nnt represent ) the CA 's wltuse lae~hers are just being derived or</definiens>
				<definiens id="2">a eequence of elements of ~ stands for a symbol of the shape ~ Jff on the left= haud side of the same rule the variable k h~s the value 8 { etherwlse m stands for an empty sequence~ stands ~or 0 iff h~ on</definiens>
				<definiens id="3">a similar meaning mS their simpla counterparts ( ioe~ g ) ( here it ~eaes that al~o ~ ~e { 0~1 } ) o If a superscript or a subscript uf a wriabln lias the va~ue 0 , it may be absent in the notation used</definiens>
			</definition>
			<definition id="3">
				<sentence>F is the defining function of 6 , It has two parts= ( able II and Limiting Cundltions~ i.eo conditions limitleg tbe possibility of using individual rsles as given in Table 1~o F consists of 14 ( schemes of ) rules denuted l.A , loBi213~4iSi6oA,6 .</sentence>
				<definiendum id="0">F</definiendum>
				<definiendum id="1">parts=</definiendum>
			</definition>
			<definition id="4">
				<sentence>Co Each rule consists of the loft aud the right part .</sentence>
				<definiendum id="0">rule</definiendum>
				<definiens id="0">consists of the loft aud the right part</definiens>
			</definition>
</paper>

		<paper id="1044">
			<definition id="0">
				<sentence>The status 'in tootis ' is a necessary condition for unstressed pronomlnals and also for zero anaphora ( cf. Gundel 1978b ) .</sentence>
				<definiendum id="0">status 'in tootis</definiendum>
			</definition>
			<definition id="1">
				<sentence>1976 ) was a videotaped episode of The McLaughlin Group ( initial transcript obtained from the Federal News Service ) .</sentence>
				<definiendum id="0">McLaughlin Group</definiendum>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>Feature Graphs and Abstract Data Types : A Unifying Approach Christoph BEIERLE and Udo PLETAT IBM Deutschland GmbH Science and Technology LILOG P.O. Box 80 08 80 7000 Stuttgart 80 , West Germany ( electronic mail on EARN/BITNET : BEIERLE at DS # LILOG , PLETAT at DS # LILOG ) Abstract : Feature graphs appearing in unification -- based grammar formalisms and algebraic specifications of abstract data types ( ADTs ) are both used for defining a collection of objects together with functions between these object sets .</sentence>
				<definiendum id="0">Unifying Approach Christoph BEIERLE</definiendum>
				<definiendum id="1">EARN/BITNET</definiendum>
				<definiens id="0">graphs appearing in unification -- based grammar formalisms and algebraic specifications of abstract data types ( ADTs</definiens>
			</definition>
			<definition id="1">
				<sentence>A s.~gt_ure is a pair Z = &lt; S , O &gt; where S is a set of sorts and O = &lt; O &gt; a family of sets of ~erators w.r.t. S. We write op : s~ ... s~ - &gt; s for an operator whose i-th argument is of sort s~ and which delivers a result of sort s. The well-fermed terms w.r.t. Z and S-sorted variables V form an S-indexed family Tz ( V ) , and an equation over ~ and V is of the form i = r where 1 and r are terms of the same sort .</sentence>
				<definiendum id="0">s.~gt_ure</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">V</definiendum>
				<definiens id="0">a set of sorts</definiens>
				<definiens id="1">terms w.r.t. Z and S-sorted variables V form an S-indexed family Tz ( V ) , and an equation over ~ and</definiens>
			</definition>
			<definition id="2">
				<sentence>An al~ @ hraic ~gcifiqation is a pair SP = &lt; Z , E &gt; where Z is a signature and E is a set of equations over Z and some family of variables V. Besides these syntactical concepts of ADT specifications we provide the basic semantical concepts of heterogenous algebras : Given a signature ~ = &lt; S , O &gt; , a ~-algebra A consists of a family of sets A = &lt; A , &gt; ... . and for each operator op e O ... . there is a function opA : A , -- - &gt; A~ .</sentence>
				<definiendum id="0">al~ @ hraic ~gcifiqation</definiendum>
				<definiendum id="1">Z</definiendum>
				<definiendum id="2">E</definiendum>
				<definiens id="0">a signature</definiens>
				<definiens id="1">a set of equations over Z and some family of variables V. Besides these syntactical concepts of ADT specifications we provide the basic semantical concepts of heterogenous algebras</definiens>
			</definition>
			<definition id="3">
				<sentence>Theorem : For each algebraic specification SP = &lt; ~ , E &gt; there is an initial algebra Tsp satisfying the equations in E. T~ , is the so-called ~uotient term alqebr ~ consisting of congruence classes obtained by factorization according to the equations in E of constant terms over Z. The initial algebra Tsp is 'the ADT specified by SP .</sentence>
				<definiendum id="0">Theorem</definiendum>
				<definiens id="0">the so-called ~uotient term alqebr ~ consisting of congruence classes obtained by factorization according to the equations in E of constant terms over Z. The initial algebra Tsp is 'the ADT specified by SP</definiens>
			</definition>
			<definition id="4">
				<sentence>We assume that ATOMS is the set of all atomic values and FEATURES is set of all features occuring in the feature graphs ; both sets may be infinite in general .</sentence>
				<definiendum id="0">ATOMS</definiendum>
				<definiens id="0">the set of all atomic values</definiens>
			</definition>
			<definition id="5">
				<sentence>Theorem : The fgspeei ficaT-ion SP is constant consistent , constant/complex consistent , or acyclic iff the initial algebra Ts~ , has the respective property .</sentence>
				<definiendum id="0">Theorem</definiendum>
				<definiens id="0">constant consistent , constant/complex consistent , or acyclic iff the initial algebra Ts~ , has the respective property</definiens>
			</definition>
			<definition id="6">
				<sentence>\ ] where : r , r ' , i , i '' ~ T~ ( { x } ) , and p ~ Features ( Z ) * Theorem : For every fg-specification completion procedure CP SP the • terminates on input SP = &lt; Z , E &gt; delivers as output a fg-specification SP '' = &lt; Z , E ' &gt; and SP and SP'are equivalent in the sense of E* = ( E ' ) * , i. e. E and E '' have the same deductive closure .</sentence>
				<definiendum id="0">p ~ Features</definiendum>
				<definiens id="0">output a fg-specification SP '' = &lt; Z , E ' &gt; and SP and SP'are equivalent in the sense of E* = ( E ' ) *</definiens>
			</definition>
			<definition id="7">
				<sentence>( in preparat : ion ) \ [ BPu 88\ ] Beierle , C. , Pletat , U. , Uszkoreit , If. : An Algebraic Characterization of STUF .</sentence>
				<definiendum id="0">If.</definiendum>
				<definiens id="0">An Algebraic Characterization of STUF</definiens>
			</definition>
			<definition id="8">
				<sentence>\ [ Ka a6\ ] Kasper , R.T. , Rounds , W.C. : A logical semantics for feature structures .</sentence>
				<definiendum id="0">W.C.</definiendum>
				<definiens id="0">A logical semantics for feature structures</definiens>
			</definition>
</paper>

		<paper id="2116">
			<definition id="0">
				<sentence>Thus a language in a model theory of discourse particles will consist in a pair : L= &lt; SP , DP &gt; SP is a set of sentence pairs sp , the individual con ~ stants , and DP is a set of discourse particles dp including the empty particle dpO , the predicates ; and for any dp and sp , dp ( sp ) , the application of dp on sp , is to represent the occurrence of dp in sp .</sentence>
				<definiendum id="0">DP &gt; SP</definiendum>
				<definiendum id="1">DP</definiendum>
				<definiens id="0">a set of sentence pairs sp , the individual con ~ stants</definiens>
				<definiens id="1">a set of discourse particles dp including the empty particle dpO , the predicates ; and for any dp and sp , dp ( sp ) , the application of dp on sp , is to represent the occurrence of dp in sp</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus the model in the theory will consist in a triple : M = &lt; DR , S , h &gt; DR is a set of discourse relations , # is , ~n assignm~n¢ ; mapping constants , i.e. sentence pair~ , onto member ' : , of DR , and I~ is an interpretation mapping predicate ; : , i.e. discourse particles , onto subsets o~ DR. The , d~ , notation of any element of DP dp is defined as Lhe s~ of discourse relations b ( dp ) .</sentence>
				<definiendum id="0">DR</definiendum>
				<definiendum id="1">I~</definiendum>
				<definiens id="0">Thus the model in the theory will consist in a triple : M = &lt; DR , S , h &gt;</definiens>
				<definiens id="1">a set of discourse relations , # is , ~n assignm~n¢ ; mapping constants , i.e. sentence pair~ , onto member ' : , of DR , and</definiens>
			</definition>
			<definition id="2">
				<sentence>A complete response consists in a sentence sequence .</sentence>
				<definiendum id="0">complete response</definiendum>
				<definiens id="0">consists in a sentence sequence</definiens>
			</definition>
			<definition id="3">
				<sentence>Response rules , evaluating original queries and perceived and received substitute queries ( alternatives in the sentence context ) in terms of database facts or meaning postulates .</sentence>
				<definiendum id="0">Response rules</definiendum>
				<definiens id="0">evaluating original queries and perceived and received substitute queries ( alternatives in the sentence context ) in terms of database facts or meaning postulates</definiens>
			</definition>
			<definition id="4">
				<sentence>PASSAT uses total ellipsis throughout = though not on deliberation , but by necessity .</sentence>
				<definiendum id="0">PASSAT</definiendum>
				<definiens id="0">uses total ellipsis throughout = though not on deliberation , but by necessity</definiens>
			</definition>
</paper>

		<paper id="2157">
			<definition id="0">
				<sentence>NA ; R ( a national anthem ) and ~\ [ ~'~~ ( to play ) ' and ' NAg ( ( a state ) aud ~ .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">a national anthem</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>The E-Framework consists of just two formal devices , namely a generator and a translator .</sentence>
				<definiendum id="0">E-Framework</definiendum>
				<definiens id="0">consists of just two formal devices , namely a generator and a translator</definiens>
			</definition>
</paper>

		<paper id="2111">
			<definition id="0">
				<sentence>Aadersson , A Theory of Language Learning Based on General Learning Principles , Proc .</sentence>
				<definiendum id="0">Aadersson</definiendum>
			</definition>
</paper>

		<paper id="1039">
			<definition id="0">
				<sentence>, or , again more formally , ( WANT USER ( KNOW USER ( IMPLIES P2 PLY ) ) , where P2 denotes the desolving event and P1 the fee paying .</sentence>
				<definiendum id="0">WANT USER ( KNOW USER</definiendum>
				<definiendum id="1">P2</definiendum>
				<definiens id="0">the desolving event</definiens>
			</definition>
			<definition id="1">
				<sentence>3 the variable A1 denotes the assertion as an action with agent USER and propositional content P1 .</sentence>
				<definiendum id="0">A1</definiendum>
			</definition>
			<definition id="2">
				<sentence>251 258 Ellman 83 : J. Ellman : An Indirect Approach to Types of Speech Acts , in : Proc .</sentence>
				<definiendum id="0">J. Ellman</definiendum>
			</definition>
</paper>

		<paper id="2138">
			<definition id="0">
				<sentence>Graph-Structured Stack Tonrita \ [ 11 , 12\ ] Introduced a generalized LR parsing algorithm , which is an LR parsing algorithm generalized to handle arbitrary context-free grammars with the graph-structured stack , The standard ( not generalized ) LR parsing algorithm is one of the most efficient parsing algodlhms .</sentence>
				<definiendum id="0">Graph-Structured Stack Tonrita</definiendum>
				<definiens id="0">arbitrary context-free grammars with the graph-structured stack</definiens>
				<definiens id="1">one of the most efficient parsing algodlhms</definiens>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>The apparent complexities lie in the combination of these multiple strategies to produce syntactically , semantically arid pragmatically sound anaphoric resolutions .</sentence>
				<definiendum id="0">apparent complexities</definiendum>
				<definiens id="0">lie in the combination of these multiple strategies to produce syntactically , semantically arid pragmatically sound anaphoric resolutions</definiens>
			</definition>
			<definition id="1">
				<sentence>The topicalization strategy may be stated as follows : Search first a syntactically topiealized part of the candidate antecedent clause ( or clauses ) for the referent of the anaphor .</sentence>
				<definiendum id="0">topicalization strategy</definiendum>
				<definiens id="0">stated as follows : Search first a syntactically topiealized part of the candidate antecedent clause ( or clauses</definiens>
			</definition>
			<definition id="2">
				<sentence>Human judgements correlate very well in terms of identifying the same referent as that suggested by the system in the 49 unique cases .</sentence>
				<definiendum id="0">Human judgements</definiendum>
				<definiens id="0">correlate very well in terms of identifying the same referent as that suggested by the system in the 49 unique cases</definiens>
			</definition>
			<definition id="3">
				<sentence>The anaphor resolver operates post facto on the set of instantiated semantic case frames and syntactic trees , attempting to resolve anaphors in the parse of the newest sentence using earlier parses ( semantic and syntactic ) as context to mine for candidate referents .</sentence>
				<definiendum id="0">anaphor resolver</definiendum>
				<definiens id="0">operates post facto on the set of instantiated semantic case frames and syntactic trees , attempting to resolve anaphors in the parse of the newest sentence using earlier parses ( semantic and syntactic ) as context to mine for candidate referents</definiens>
			</definition>
			<definition id="4">
				<sentence>; sentence 6 : The doctor gave John a glass of water ( SENT6 ( IS-A *GIVE ) ( : TIME *PAST ) ( : AGENT *DOCTOR ) ( : OBJECT OBJECT6 ) ( : RECIPIENT *JOHN ) ) ( *DOCTOR ( IS-A *PERSON ) ) \ [ unb~own gender\ ] ( OBJECT6 ( IS-A *DRINKING-WATER ) ( : AMOUNT GLASS i ) ) ( * JOHN ( IS-A *PERSON ) ( : GENDER M ) ( : NUMBER *SINGULAR ) ) frame = ( : RECIPIENT *JOHN ) No referents for definite NP frame = ( : OBJECT OBJECT6 ) No referents for definite NP frame = ( : AGENT *DOCTOR ) No referents for definite NP \ [ the frames are unchanged after resolution\ ] ; sentence 7 : John drank it \ [ it=glass of water\ ] ( SENT7 ( IS-A *INGEST-FOOD ) ( : TIME *PAST ) ( : AGENT eJOHN ) ( : OBJECT OBJECTT ) ) ( * JO~L~ ( TS-A *PERSON ) ( : GENDER M ) ( : NUMBER *SXNGULAR ) ) ( OBJECTS !</sentence>
				<definiendum id="0">TIME *PAST )</definiendum>
				<definiendum id="1">IS-A *PERSON )</definiendum>
				<definiens id="0">IS-A *INGEST-FOOD ) ( : TIME *PAST ) ( : AGENT eJOHN ) ( : OBJECT OBJECTT</definiens>
			</definition>
			<definition id="5">
				<sentence>The XCALIBUR Project , A Natural Language Interface to Expert Systems and Data Bases .</sentence>
				<definiendum id="0">XCALIBUR Project</definiendum>
			</definition>
</paper>

		<paper id="2143">
			<definition id="0">
				<sentence>Then CAT ( the set of all categories ) is t_he induotive closure of BASCAT under ( ~NN , i.e~ the smallest set such that ( i ) BASCAT is a subset of CAT , and ( ii ) if X , Y are manbez~ ; of CAT and I is a msmber of CDNN , tt~n ( xlY ) is a ~ of CAT .</sentence>
				<definiendum id="0">CAT</definiendum>
				<definiens id="0">the set of all categories</definiens>
				<definiens id="1">a subset of CAT</definiens>
				<definiens id="2">a ~ of CAT</definiens>
			</definition>
			<definition id="1">
				<sentence>In the case of right division , % h8 argument has to be found to fk~ right of the ~ category , whereas in the case of left division , the argument l~as to be found % 0 ths left 5 o 'f1~e produc t o~ive '* ' is % 0 be interpreted as a c~x~atenation operator , i.e. a prock~ category ( X'Y ) is to be associated with an expression which is the ooncatenati~ of an expression of category X and an expressi~ of categozy Y in that o~der .</sentence>
				<definiendum id="0">X'Y )</definiendum>
				<definiens id="0">a c~x~atenation operator</definiens>
			</definition>
			<definition id="2">
				<sentence>Axloms and Ja~ference rules ( I ) ~ ~ of L are sequ~ts of t~ fo~n X = &gt; X. ( 2 ) Inference rules of L : X , Y and Z are categories , B , T , Q , u , V are sequences of categories , where P , T and Q are , % on-eai0ty .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">categories , B , T , Q , u</definiens>
			</definition>
</paper>

		<paper id="1082">
			<definition id="0">
				<sentence>N T -max\ [ 2 ; 'c ( xi , p ) + maxZdep ( w I j_1 , Xj , piY1 , j , p ) \ ] ( I ) p j : :l `` Y j=l ' where I~j. &lt; N , 1Kp~M , N is the number of input phrases , M is the maximum number of phonetic recognition candidates for each phrase , Xj , p is a candidate of the j~th input phrase with the p-th best phonetic likelihood , and c ( xj , p ) is its phonetic likelihood ( positive value ) . Also , Xi , j , p is a phrase sequence with one phrase candidate for each i-th to j-th input phrase and whose last phrase is Xj , p. Yi , j , p is one of the dependency structures of Xi , j , p , wi , j_ I is the set of phrases that modify Xj , p in the sequence Xi , j , p. Here , dep ( w , xlY ) is the linguistic likelihood ( negatiw ! value ) of dependency relationships between w and x taking Y into account. Namely , the first item of the teem on the right in Eq. ( I ) is the summation of phonetic likelihoods of the hypothesized sentence composed of its phrase sequence , and the second item is the summation of linguistic likelihood. Maximizing Eq. ( 1 ) gives the sentence and the dependency structure of it as speech recognition and t~dersta~ling results. Because dependency structure grammar is compatible with case grammar\ [ 8\ ] , the linguistic semantic likelihood ( dep ) of the dependency structure is easily provided using case structure. The following are example : ~ of items for evaluating dependency relationships : the disagreement between the semantic primitives of the modifier and that requested by the modificant , the lack of the ob\ ] .igatory case phrase requested by the modificant , and the existence of differenb phrases with the same case and modifying the same phrase. The likelihood values for these items are given heuristically. To so\ ] re equation ( I ) , a fast parsing algorithm using breadth-first search and beam search was developed. This algorithm deals with higher linguistic or semantic processing such as the case structure.. Although this algorithm offers sub-optimal solutions , it is practical because it requires less processing than depth-first search. The breadth-first algorithm is formulated as order of candidates 1 2 ... ... M x\ [ , l Xl , 2 Xl , ~4 I 1 2 x2,1 x2 , 2 / x3 , I xs , 2 x3 , MJ B Fig. 2. A matrix of phrase candidates input utterance : number N-1 follows. First , dep ( w , xlY ) can obviously be divided into two terms. dep ( wl , j-1 , Xj , plYl , j , p ) = E dep1 ( x , Xj , p ) + dep2 ( Y1 , j , p , Xj , p ) ( 2 ) x Cw I , j-1 where depl is the likelihood associated with dependency relationships of only the modifier and modificant phrases , and dep2 is the likelihood associated with Y1 , j , p. An example of dependency relationships is shown in Fig. 3. Eqs. ( I ) and ( 2 ) give the objective function 's wtlue S ( 1 , Xj , p ) of a phrase sequence including the top phrase to Xj , p in the sentence as : S ( 1 , Xj , p ) = J J J Z C ( Xh , p ) + ~ ~ dep1 ( x , xh , p ) +Edep2 ( Y 1 , h , p , xh , p ) ( 3 ) h : :1 h=1 xCw I , h-1 h=1 On the other hand , the value of a phrase sequence not including the top phrase ( i¢I ) is defined as : D ( i , Xj , p ) = j j j-1 _Z C ( Xh , p ) + Z Z depl ( X , Xh , p ) + Z dep2 ( Y i , h , p , xh , p ) h : : i h=i xCwi , h_ I h=i ( ~ ) Tim main difference between Eqs. ( 3 ) and ( 4 ) is that phrase sequence wh , F I i I I E ( A , E , F ) depl ( F , G ) depl ( E , G depl ( A , G ' , '.-t dep2 ( YA , G dep ( wA , p. G i YA , G =dep2 ( YA.G ' G ) +dspl ( F , G ) +depl ( E. G ) +depl ( A , G ) Fig. 3. Illustration of dependency relationships 403 dep2 ( Yi , j , p , Xj , p ) is not evaluated in Eq. ( 4 ) . Using notation S and D , the recurrence relation among the objective functions are derived. This is shown in Fig. 4. The recurrence relation are transforms into the following equations using beam search. S ( 1 , Xj , p , r ) = rth-max\ [ S ( 1 , Xk , q , rl ) + D ( k+1 , Xj , p , r2 ) k , q , rl , r2 + dep1 ( Xk , q , Xj , p ) + dep2 ( Y1 , j , p , Xj , p ) , if i=I ( 5 ' ) D ( i , xj , p , r ) = rth-max\ [ S ( i , Xk , q , rl ) + D ( k+1 , Xj , p , r2 ) k , q , rl , r2 + dep1 ( xk , q , Xj , p ) 4 dep2 ( Yi , k , q , Xk , q ) , if i~I ( 6 ' ) where i~k~j-1 , 1~q~M , and 1~r , rl , r2 &lt; _L. Here , r , rl and r2 indicate the rank of beam , L is the maximum number of beams , S ( 1 , Xj , p , r ) and D ( i , xj , p , r ) are the r-th value of the element whose phrase sequence is Xi , j , p and the dependency structure is Yi , j , p. ilere , rth-max\ [ \ ] is a function for deriving the r-th best value. When Eq. ( 5 ' ) or ( 6 ' ) is calculated , Yi , j , p is stored for use in the later stage of evaluating dep2. Initial values are given as follows. S ( 1 , Xl , p,1 ) = C ( Xl , p ) + dep2~1,1 , p , Xl , p ) , if i=1 ( top phrase ) ( 7 ) D ( i , Xi , p,1 ) = e ( Xi , p ) , if i~I ( not top phrase ) ( 8 ) After calculating the recurrence relation , the value of the objective functions is obtained , T = max\ [ S ( 1 , XN , p,1 ) \ ] , ( 9 ) P where 1~p~M. The best sentenc~ and its dependency structure are given through YI , N , p where p maximizes Eq. ( 9 ) . The parsing table is shown in Fig. 5 and the parsing algorithm is shown in Table I. In Fig. 5 , the first row corresponds to S , and others correspond to D. The phrase sequence for first to N-th phrase corresponds to the right-most top cell. Each cell is composed of ML sub-cells. Arrows show the sequence of calculating the recurrence relation. The processing amount order for this algorithm is O ( N3M2L2 ) . Comparing the theoretical amount of processing for these two parsing algorithms , the breadth-first parsing algorithm clearly requires much less processingthanthe depth-first parsing algorithm. The amount of processing for each parsing algorithm is shown in Fig. 6. To pre-select the phrase hypotheses for the speech recognition , the predictor is devised\ [ 9\ ] , using prediction rules created by integrating connection rules and dependency structures of phrases. These rules are described with rewriting rules : ( Xi , j ) - &gt; ( Xi , k ) ( Xk+1 , j ) where Xi , j is the phrase sequence for the i-th to jth phrase .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">M</definiendum>
				<definiendum id="2">Xj , p</definiendum>
				<definiendum id="3">j_ I</definiendum>
				<definiendum id="4">xlY )</definiendum>
				<definiendum id="5">dep2</definiendum>
				<definiendum id="6">top phrase</definiendum>
				<definiendum id="7">i¢I</definiendum>
				<definiendum id="8">L</definiendum>
				<definiendum id="9">p maximizes Eq.</definiendum>
				<definiendum id="10">parsing table</definiendum>
				<definiens id="0">'c ( xi , p ) + maxZdep ( w I j_1 , Xj , piY1 , j , p ) \ ] ( I ) p j</definiens>
				<definiens id="1">the number of input phrases</definiens>
				<definiens id="2">the maximum number of phonetic recognition candidates for each phrase ,</definiens>
				<definiens id="3">a candidate of the j~th input phrase with the p-th best phonetic likelihood , and c ( xj , p ) is its phonetic likelihood ( positive value ) . Also , Xi , j , p is a phrase sequence with one phrase candidate for each i-th to j-th input phrase and whose last phrase is Xj , p. Yi , j , p is one of the dependency structures of Xi , j , p , wi ,</definiens>
				<definiens id="4">the set of phrases that modify Xj , p in the sequence Xi , j</definiens>
				<definiens id="5">the linguistic likelihood</definiens>
				<definiens id="6">the summation of phonetic likelihoods of the hypothesized sentence composed of its phrase sequence</definiens>
				<definiens id="7">the summation of linguistic likelihood. Maximizing Eq. ( 1 ) gives the sentence and the dependency structure of it as speech recognition</definiens>
				<definiens id="8">the disagreement between the semantic primitives of the modifier and that requested by the modificant , the lack of the ob\ ] .igatory case phrase requested by the modificant , and the existence of differenb phrases with the same case and modifying the same phrase. The likelihood values for these items are given heuristically. To so\ ] re equation ( I ) , a fast parsing algorithm using breadth-first search</definiens>
				<definiens id="9">A matrix of phrase candidates input utterance : number N-1 follows. First , dep ( w , xlY ) can obviously be divided into two terms. dep ( wl , j-1 , Xj , plYl , j , p ) = E dep1 ( x , Xj , p ) + dep2 ( Y1 , j , p , Xj , p ) ( 2 ) x Cw I , j-1 where depl is the likelihood associated with dependency relationships of only the modifier and modificant phrases</definiens>
				<definiens id="10">the likelihood associated with Y1 , j</definiens>
				<definiens id="11">the objective function 's wtlue S ( 1 , Xj , p ) of a phrase sequence including the top phrase to Xj , p in the sentence as : S ( 1 , Xj , p ) = J J J Z C ( Xh , p ) + ~ ~ dep1 ( x , xh , p ) +Edep2 ( Y 1 , h , p , xh , p ) ( 3 ) h : :1 h=1 xCw I , h-1 h=1 On the other hand , the value of a phrase sequence not including the</definiens>
				<definiens id="12">D ( i , Xj , p ) = j j j-1 _Z C ( Xh , p ) + Z Z depl ( X , Xh , p ) + Z dep2 ( Y i , h , p , xh , p ) h : : i h=i xCwi , h_ I h=i ( ~ ) Tim main difference between Eqs. ( 3 ) and ( 4 ) is that phrase sequence wh , F I i I I E ( A , E , F ) depl ( F , G ) depl ( E , G depl ( A , G ' , '.-t dep2 ( YA , G dep ( wA , p. G i YA , G =dep2 ( YA.G ' G ) +dspl ( F , G ) +depl ( E. G ) +depl ( A , G ) Fig. 3. Illustration of dependency relationships 403 dep2 ( Yi , j , p , Xj , p ) is not evaluated in Eq. ( 4 ) . Using notation S and D , the recurrence relation among the objective functions are derived. This is shown in Fig. 4. The recurrence relation are transforms into the following equations using beam search. S ( 1 , Xj , p , r ) = rth-max\ [ S ( 1 , Xk , q , rl ) + D ( k+1 , Xj , p , r2 ) k , q , rl , r2 + dep1 ( Xk , q , Xj , p ) + dep2 ( Y1 , j , p , Xj , p</definiens>
				<definiens id="13">p , r ) = rth-max\ [ S ( i , Xk , q , rl ) + D ( k+1 , Xj , p , r2 ) k , q , rl , r2 + dep1 ( xk , q , Xj , p ) 4 dep2 ( Yi , k , q , Xk , q ) , if i~I ( 6 ' ) where i~k~j-1 , 1~q~M , and 1~r , rl , r2 &lt; _L. Here , r , rl and r2 indicate the rank of beam ,</definiens>
				<definiens id="14">the maximum number of beams , S ( 1 , Xj , p , r ) and D ( i , xj , p , r ) are the r-th value of the element whose phrase sequence is Xi , j , p and the dependency structure is Yi , j , p. ilere , rth-max\ [ \ ] is a function for deriving the r-th best value. When Eq. ( 5 ' ) or ( 6 ' ) is calculated , Yi , j , p is stored for use in the later stage of evaluating dep2. Initial values are given as follows. S ( 1 , Xl , p,1 ) = C ( Xl , p ) + dep2~1,1 , p , Xl , p ) , if i=1 ( top phrase ) ( 7 ) D ( i , Xi , p,1 ) = e ( Xi , p ) , if i~I ( not top phrase ) ( 8 ) After calculating the recurrence relation , the value of the objective functions is obtained</definiens>
				<definiens id="15">pre-select the phrase hypotheses for the speech recognition , the predictor is devised\ [ 9\ ] , using prediction rules created by integrating connection rules and dependency structures of phrases. These rules are described with rewriting rules : ( Xi , j ) - &gt; ( Xi , k ) ( Xk+1 , j ) where Xi , j is the phrase sequence for the i-th to jth phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>The acoustic processing stage consists of a feature extraction part and a phoneme recognition part\ [ 10,11\ ] .</sentence>
				<definiendum id="0">acoustic processing stage</definiendum>
			</definition>
			<definition id="2">
				<sentence>The linguistic processing stage consists of a phrase recognition patti11\ ] , a parsing part ( a dependency relationship analysis part ) , and a phrase prediction part .</sentence>
				<definiendum id="0">linguistic processing stage</definiendum>
				<definiens id="0">consists of a phrase recognition patti11\ ] , a parsing part ( a dependency relationship analysis part ) , and a phrase prediction part</definiens>
			</definition>
			<definition id="3">
				<sentence>The processing order is O ( NSM2L2 ) , which is practical amount of computation , where N is the number of detected phrase boundaries in the uttered sentence , M is the maximum number of phonetic recognitio~ candidates for each phrase segment f~em one boundsry to the next boundary , and L is the maximum number of beams .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">M</definiendum>
				<definiendum id="2">L</definiendum>
				<definiens id="0">the number of detected phrase boundaries in the uttered sentence</definiens>
				<definiens id="1">the maximum number of phonetic recognitio~ candidates for each phrase segment f~em one boundsry to the next boundary</definiens>
				<definiens id="2">the maximum number of beams</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>The context is represented by a special object , the discourse state ( DS ) , the description of which encodes the contextual information that the system currently has available .</sentence>
				<definiendum id="0">discourse state ( DS</definiendum>
				<definiens id="0">encodes the contextual information that the system currently has available</definiens>
			</definition>
			<definition id="1">
				<sentence>The analysis of an utterance would be incomplete if it does not include a classification of the utterance , as well as the discourse objects that fulfils the roles of Speaker and Addressee .</sentence>
				<definiendum id="0">analysis of an utterance</definiendum>
				<definiens id="0">the discourse objects that fulfils the roles of Speaker and Addressee</definiens>
			</definition>
			<definition id="2">
				<sentence>The prototype for this type may be assigned the following set of constraints ( as one alternative ) : ( 11 ) __ &amp; Directive Type ; Speaker ; I Addressee ; lAction ; ( ~ MOOD ) = IMPERATIVE= ( DS SPEAKER ) = ( DS ADDRESSEE ) ~=~ In order to distinguish objects being described from objects being constituted w~ distinguish two modes of correspondence .</sentence>
				<definiendum id="0">constraints</definiendum>
				<definiens id="0">DS ADDRESSEE ) ~=~ In order to distinguish objects being described from objects being constituted w~ distinguish two modes of correspondence</definiens>
			</definition>
			<definition id="3">
				<sentence>The f-structure is a syntactic structure , which means that it must be a minimal structure satisfying the constraints induced by the c-structure .</sentence>
				<definiendum id="0">f-structure</definiendum>
				<definiens id="0">structure satisfying the constraints induced by the c-structure</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , we get the following conditions on proper correspondence between d-structures and f-structures : ( 1 ) A d-structure , 6 , and an f-structure , ¢ , are corresponding properly in descriptive mode , only if ( a ) 6 ( Type ) ~ g ( ¢ ( LEX ) ) , where g is the function defined by the lexeme dictionary ; ( b ) There is a prototype , /'/ , for 6 ( Type ) such that ( i ) 6 satisfies the conditions '' of // , and ( ii ) Cesta is a minimalHfo structure satisfying all functional constraints reduced by r the role attributes at top level of 6 .</sentence>
				<definiendum id="0">g</definiendum>
				<definiens id="0">the following conditions on proper correspondence between d-structures and f-structures : ( 1 ) A d-structure , 6 , and an f-structure , ¢ , are corresponding properly in descriptive mode</definiens>
				<definiens id="1">Type ) ~ g ( ¢ ( LEX ) )</definiens>
				<definiens id="2">the function defined by the lexeme dictionary ; ( b ) There is a prototype , /'/ , for 6 ( Type ) such that ( i ) 6 satisfies the conditions '' of // , and ( ii ) Cesta is a minimalHfo structure satisfying all functional constraints reduced by r the role attributes at top level of 6</definiens>
			</definition>
</paper>

		<paper id="1062">
			<definition id="0">
				<sentence>A vocnet graph U = &lt; A , N , C ' , C '' &gt; quadruple , where is a A is an alphabet of a t o m s a , b ; c , ... N is a set of n o d e s h , i , j , k , .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">a set of n o d e s h , i , j , k ,</definiens>
			</definition>
			<definition id="1">
				<sentence>o. C ' and C '' are mappings of A into N ~N. We define C ( x ) = C ' ( x ) u C '' ( x ) as the set of c a t e g o r i e s of `` the atom x. We define tile product C 4 o C~ of two category sets C~ and C~ as C~ o C~ = { ( i , j ) IBk ( i , k ) e C~^ ( k~ j ) ¢ C~I and the category set for a string ~ : x ~ as c ( ~ ) = C ( x ) o c ( ~ ) We shall say that the atom x C o nn e c t s the set M1 to the set M2 in U iff either M2 is the set of all j for which there is a node i in MI such that ( i , j ) ~ C ' ( x ) r or M2 is the set of all j for which there is a node i in M1 such that ( i , j ) ~ C '' ( x ) .</sentence>
				<definiendum id="0">C (</definiendum>
				<definiendum id="1">M2</definiendum>
				<definiens id="0">x ) = C ' ( x ) u C '' ( x ) as the set of c a t e g o r i e s of `` the atom x. We define tile product C 4 o C~ of two category sets C~ and C~</definiens>
				<definiens id="1">k~ j ) ¢ C~I and the category set for a string ~ : x ~ as c ( ~ ) = C ( x ) o c ( ~ ) We shall say that the atom x C o nn e c t s the set M1 to the set M2 in U iff either M2 is the set of all j for which there is a node i in MI such that ( i , j ) ~ C ' ( x ) r or</definiens>
			</definition>
			<definition id="2">
				<sentence>The vocnet may contain special e x i t c h e c k e r s. An exit checker is a dummy zone , consisting of exactly one node connected to itself by an arrow in C ' for each atom in A. By using exit checkers , local conditions for zones can be accounted for in the target conditions for the whole vocnet° The exit checkers , in a way , will then fre~ , ze the zone exit conditions so that they remain accessible for verification when the whole graph has been passed through .</sentence>
				<definiendum id="0">exit checker</definiendum>
				<definiens id="0">a dummy zone , consisting of exactly one node connected to itself by an arrow in</definiens>
			</definition>
			<definition id="3">
				<sentence>QI ( M ) is the frozen version of PI ( M ) , with fl , f2 , ... , substituting El , E2 , ... The vocnet graphs U1 and U2 have thus been integrated as zones into the new vocnet graph .</sentence>
				<definiendum id="0">QI</definiendum>
				<definiens id="0">the frozen version of PI ( M ) , with fl , f2 , ... , substituting El</definiens>
			</definition>
			<definition id="4">
				<sentence>Here , ~ PI ( M ) are the frozen stratified target conditions of GI .</sentence>
				<definiendum id="0">PI</definiendum>
				<definiens id="0">the frozen stratified target conditions of GI</definiens>
			</definition>
			<definition id="5">
				<sentence>Given one vocnet G1 ( say for words beginning with a prefix ) and another vocnet G2 ( say for prefixes and prefix sequences ) , we search a vocnet G ( say for words stripped of their prefixes ) such that ~ &amp; L ( G\ ] iff ~4a~A2 ( ~ &amp; L ( GI ) A 0~2C-L ( G2 ) A The following vocnet G will satsify our requirement : G = &lt; UI , S , PI &gt; where S is the union of all sets M ~NI for which S1 is connected to M in G1 by some string contained in L ( G2 ) .</sentence>
				<definiendum id="0">0~2C-L</definiendum>
				<definiendum id="1">G2</definiendum>
				<definiendum id="2">S</definiendum>
				<definiens id="0">say for words beginning with a prefix ) and another vocnet G2 ( say for prefixes and prefix sequences ) , we search a vocnet G ( say for words stripped of their prefixes</definiens>
				<definiens id="1">the union of all sets M ~NI for which S1</definiens>
			</definition>
			<definition id="6">
				<sentence>By p a r a s i t e s of a language L we shall mean strings which are not members of L nor substrings of members of L. Clearly , if with the vocnet G tile set C ( ~ ) is empty , ~ is a parasite of L ( G ) ~ 4 , is not a member nor will it become a member whatever is appended at either end .</sentence>
				<definiendum id="0">C ( ~</definiendum>
				<definiens id="0">t e s of a language L we shall mean strings which are not members of L nor substrings of members of L. Clearly , if with the vocnet G tile set</definiens>
			</definition>
</paper>

		<paper id="2084">
			<definition id="0">
				<sentence>Lexical transfer is the point of transition between an unchangeable source text ( a rook ) and an infinite array of target texts ( a hard place to find an acceptable one ) .</sentence>
				<definiendum id="0">Lexical transfer</definiendum>
				<definiens id="0">the point of transition between an unchangeable source text ( a rook ) and an infinite array of target texts ( a hard place to find an acceptable one )</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>More precisely , the rule allows the pair /a : b/ ( lexical /a/ corresponding to surface /b/ ) to occur in the context given and , unless there are other rules licensing the pair in other contexts , the context given is the only place where that correspondence is allowed .</sentence>
				<definiendum id="0">context given</definiendum>
				<definiens id="0">b/ ( lexical /a/ corresponding to surface /b/ ) to occur in the context given</definiens>
			</definition>
			<definition id="1">
				<sentence>\ [ 8\ ] Koskenniemi , Kimlr ) o ( 1983 ) Two-level Morphology : A General Computational Model for Word-form Recognition and Production .</sentence>
				<definiendum id="0">Two-level Morphology</definiendum>
			</definition>
</paper>

		<paper id="2104">
			<definition id="0">
				<sentence>( 9 ) a. V.~ { \ [ AGR NP ( there , \ [ PLUR Z\ ] } \ ] } , ~r\ [ 221 , NP { \ [ PLUR 4 } b , VP { \ [ AGR NP { there , \ [ PLUR /'\ ] } , pas } H b2\ ] , ( NP { \ [ PRF , P by\ ] } : ) ( 10 ) a. VP ( +it } -- ' -- - &gt; H \ [ 4/4\ ] , NP , S { +R } b. VP { +it , pas\ ] H\ [ Zl4\ ] , S { +R } , ( NP { \ [ PREP by\ ] } ) One more such example can be constructed if we apply the Extraposition Metarule ( tl ) to the rule ( 12 ) a and let the Passive Metarule ( 8 ) apply to the result , as sketched in ( 12 ) a , b , Co ( 11 ) Extraposltlon Metarule ~ ( \ [ AGR S\ ] } -- -- -- &gt; W x2 { lAiR ~P { it\ ] \ ] } -- - % w , s ( 12 ) a. VP { \ [ AGR S\ ] } ... . *Hb0\ ] , NP That Lee was elected bothered Kim .</sentence>
				<definiendum id="0">Passive Metarule</definiendum>
				<definiens id="0">11 ) Extraposltlon Metarule ~ ( \ [ AGR S\ ] } -- -- -- &gt; W x2 { lAiR ~P { it\ ] \ ] } -- - % w , s ( 12 ) a. VP { \ [ AGR S\ ] } ... . *Hb0\ ] , NP That Lee was elected bothered Kim</definiens>
			</definition>
			<definition id="1">
				<sentence>Adding the syntactic function feature to `` the GPSG ( mete ) grammar goes in certain aspects in parallel with the independently motivated efforts to eliminate metarules from GPSG altogether and/or to shift their work to lexical redundancy rules , e.g. ( Pollard,85 ) , ( Kilbury,86 ) .</sentence>
				<definiendum id="0">GPSG ( mete ) grammar</definiendum>
				<definiens id="0">goes in certain aspects in parallel with the independently motivated efforts to eliminate metarules from GPSG altogether and/or to shift their work to lexical redundancy rules</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>&lt; dyHab\ ] et~ ~re iirll ; di. &lt; -icu~. &lt; ~ed explicitly in refills ; o£ rm. , . ; ei ; , \ [ ) e*tk and ( xlda in th\ ] .q rood\ [ el , Rath ( ntheist : fgubStfHCttlres and \ [ ; lie phonotactlc and all.ophfmic r-uies which depeild t~n i ; h ( : lli ilre implicit in the net ; wolk. The s ; trucLuYe. &lt; - , , \ ] lewev ( w , can be derived immediately from the t.optlkogy ot the llet , wtl\ [ \ ] i a~ , reple : senl.ed ill o \ [ ; rtsfl. % iLiun ilia # tiara , Ti~h~ IK~I ; WII\ [ k \ [ L ; l C fel-f l~. ( 1 tCI as a phi } llQl , ac { ; i G ueL. All.rlphontc CfUlStlsint , ~il were tiletl introduced a~ ; ; piarl ; of the : input ; ~ : qr ) ecifications , Each tiansitkm \ [ n I ; he phunl ! tacCtc fleL moiK ! h : i , a phonemic : :gegmenf Tin ! ativclnta { ~'~ # ef~ th ( 3 \ [ ' ( ~atuve \ [ ) llll ( i\ ] f ! reprl~ae.ntatlon is tilat t~el { me.nt~ ; can be viewc~d in t ( .'r/tl : ; ( if natural classes , which * ; i mpli fie. &lt; ; the netw ( ir-k con , ~dderably , The tlYtll.~xit\ [ on \ ] abel.if ; tilt ' the afar ; work consJ.. ' ; t of a pail '' ef feature bundles each containing O-l'eatl/l-es , One of the , ~ ; e blnldle5 repFesellts Jilpllt .'xpecifications and the ether output specifications ; both are in geueral undevspecified , Fer example , the bundle i : lf G features which de~icribeL ; lille veicelesu plosive con.'~onants is { \ [ cent\ ] , \ [ -voice\ ] , \ [ seal , \ [ stYtdi ) , } lowever , where we need I ; o dealt ilia the aspiral ; ed allophones ef the v\ [ lice\ ] ess plosives the w~viant feaLur'e \ [ t asp\ ] must be addc~l : { \ [ cent } , 107 \ [ voice\ ] , \ [ son\ ] , \ [ strid\ ] , \ [ + asp\ ] ) . Therefore when a particular transition in the network is responsible for remevin 5 this allophonic information the input transition specification is { \ [ cent\ ] , \ [ voice\ ] , \ [ s~bn\ ] , \ [ strid\ ] , \ [ + asp\ ] ) , and the output transition specification is { \ [ cent\ ] , \ [ ~voice\ ] , \ [ son\ ] , \ [ strid\ ] } ( see Fig.l ) . When this phonotactic net is interpreted by a particular parser the phonetic input is generally a string ef fu\ ] ly specifl~xl feature bundles *~nd in order to u'~e the output for recognition purposes the phonemic output will also be fully specified. It i. % here that unification plays an important role. indeed the features themselves may not be recosnisable. This facility is advantageous for workin~ with feature detectors at the front end as it is still possible to analyse what is known. Thls , of course , leads to underspecifk~l output which may be used in connection with a lexicon for recol { nltlon hypothesisin 5 . In such cases the underspecified output , althoush representin~ classes of phonemes in the various positions , will only allow those combinations of such classes which actually exist , thus llmltJng ' possibilities available for hypothesis. Thus it is not necessary to check the lexicon for forms which accordln 5 to the rules of the language can not exist. l TS OTS Voice voic~ son son strld stri asp f~ % t % j Fig. 1 , Tran~it\ [ un acceptln~ voiceless ospirated ploslvos ~ ; hen attemptin 5 to traverse the network the fully specified input feature bundle must unify with the input transition speelflcatlon ( in terms of C-features ) of the current transition. If unification succeeds , the fully specific4 output bundle must contain the output transition specifications together with all those features from the fully specified input bundle not contained in the input transition specification. In set the\ [ ~retic terms , let us call the fully specified input feature bundle lnFB , the input and output transition specifications ITS and OTS respectively ; if unification of InFB with ITS succeeds , the fully specified output bundle OutFB is OTS ~ ( InFB / ITS ) . The phonetic input feature bundles may be also underspecified however. This allows for circumstances where the values of some features may not be known or Church discusses a number of factors , most of which date back to work by Morris Halle and are discussed by Chomsky and Halle /1960/ , which must be taken into consideration when desl6ning the model I1983:1281 length , idiosyncratic systematic gaps , voicing assimilation , place assimi\ ] .atien and dissimilation , sonority. These can all be incorporated very easily into the network. The fact that languages restrict sound combinations ( Jdiosyncratlc gaps ) and the length of initlal/flnal consonant clusters is in any case the basis on which this network is constructed. Decreasing sonority from the nucleus of the syllable towards the margins would seem to be a matter of having \ [ son\ ] as a C-feature and adjusting the value at the appropriate transition. With re~ard to phonotactic constraints , the C-. features on the transition labels may have variable values. In other words we may cater for the fact that all initial /s/ in Bn~lish may not be followed by voiced plosives by havin 5 as input specifications for one of its followln~ transitions the C-features { \ [ voc\ ] , \ [ ~ cent\ ] , \ [ ~ voice\ ] , \ [ o son\ ] , \ [ strid\ ] ) ( see Fig.2 ) . ~ here must have the same value in the three cases , this value bein~ assigned durin } ~ unification. Unification would fall in this case for voiced plosives as they would be specified for the feature~ { \ [ reel , \ [ -cont\ ] , \ [ + voice\ ] , \ [ son\ ] , \ [ strld\ ] } . A further convention is Introduced , *tamely that once a feature has been specified on a particular transition it remains until it is eKplicitly altered , ell a subsequent transition. In this way vowel harmony may be incorporated into such a network whereby the vowel sDeeificatlons would remain for subsequent transitions since they would not be relevant for intervenin~ consonants. 108 I `` l'~q OT~I i , I voc wlc atrid strld r~ c~mt cx conL viii ( ; ( } ~cll c ; ~ 5\ [ ) II \ [ ; uii % ~- , % ; % j Fig. 2 ' hdtial /t~/ , l~ly not Im f ( } llclwed by voiced plo~ ; lve~3 in } { llgll~ih. ( 1 { ; I and /~/ ~tv ( ~ abbrevl~ltlrm~ ; ftlr fully specified fetltuie bund I ~t ; ) It shoal ( l be clear also that feature bundle representation together with unification is an elegant way of dealing with assimilation , dissimilation and neutrallsation. Assimilation and dissimilation are dealt with by Chomsky and l { aile /1968/ in terms of variables a. ~\ ] feature cfK~.fficients and it is this , method which has been incorporated into the network here. So for example , in eases of voice assimilation , the fe/Iture \ [ voice\ ] may be checked using a variable , say \ [ a volc~\ ] . Therefore , where the particular input segment ha~ the feature \ [ + voice\ ] , unification assigns the value + to the undefin£Rl variable ¢~ permanently , and slmilaFly in the case of a negative value. This newly found value together with the attribute will then be a ( k-feature in the input specification for the following I ransltion unless exp\ ] icltly changed on that transition. This is a type of feature-passlng technique : ~imilar to that employed in unificationbased syn'i ; actlc theories , but essentially simpler , slnce it is nsn-recurslve. Transltion weighting is also very important in this model , St\ ] kirk /1980/ emphasil~es that it is all very well to cater for collocational restrictions but other constraining principles such as maxlmising snoots should also ) be incorporated into a syllable parser. Thus ironed\ ] ions are weighted in such a way that the most preferred path out of the network is sought. 'Early closure ' /Kimball 1973/ : for example , which seeks the shorte~ ; t path out of the network , is equivalent to the maxima\ [ onset principle. Str~s re~yllablflcatlon is simllar\ ] y dealt with using weighting. Thus , such constraints are incorporated into the network in a simple and principled fashitm. Up to now we have \ ] men discussing the representation level , namely the phons\ ] attic net envisaged as a syllable template. The phonotacU.c net in hhls case was for English but it should be. clear that this representation may he used for other languages , dialects sr codes. Since the phenol~ctic net is a network of transduction relations between allophone and phoneme it should be both apeech analysia and synthesis. to note at this stage however , that level we are not re'~ ; tricte~ to what we employ. The phonotactic net may a usefu\ [ tool for It is important on the processing parsing algorithm be interpretu~ : l by any one of a number ~ff par , '~ing procedure. % . The .~ ; trategy emphJyed ( i.e. depth-first , breadth first , hast fir.~t , ioskahead etc. ) is~ a\ ] .so totally independent of the repve~.~entation. In the mode\ ] , deacrib ( M here the aim wa~ to use the simplest formalism pcJssible. Thus the parsing and translation processes are undertaken by a deptl &gt; first nondeterministi .</sentence>
				<definiendum id="0">trategy emphJyed</definiendum>
				<definiens id="0">~ed explicitly in refills</definiens>
				<definiens id="1">an elegant way of dealing with assimilation , dissimilation</definiens>
				<definiens id="2">a type of feature-passlng technique : ~imilar to that employed in unificationbased syn'i ; actlc theories , but essentially simpler , slnce it is nsn-recurslve. Transltion weighting is also very important in this model</definiens>
				<definiens id="3">seeks the shorte~</definiens>
			</definition>
			<definition id="1">
				<sentence>`` Functional Unification Grammar : A fo : cmalism for machine translation '' .</sentence>
				<definiendum id="0">Functional Unification Grammar</definiendum>
				<definiens id="0">A fo : cmalism for machine translation ''</definiens>
			</definition>
</paper>

		<paper id="1058">
			<definition id="0">
				<sentence>Note as well that this is not 'bottom-up ' parsing in the usual sense either , since where more than one possibility is logically available , the parser makes no attempt to represent them all and cull out tlte false positives later on ; there is a strict principle of 'altruism avoidance ' ( that is , never undertaking computational effort without a guaranteed payoff ) which compels the parser to give no answer at all during lThe approach described in Sampson 1986 , while quite different in its actual character , is nonetheless similar in spirit to what we are proposing .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">makes no attempt to represent them all and cull out tlte false positives later on ; there is a strict principle of 'altruism avoidance ' ( that is , never undertaking computational effort without a guaranteed payoff ) which compels the parser to give no answer at all during lThe approach described in Sampson 1986 , while quite different in its actual character</definiens>
			</definition>
			<definition id="1">
				<sentence>( 4 ) POSITION CONSTRAINT ( Kac 1978 , 1985 ) If a coordinating conjunction conjoins expressions X and Y , it lies somewhere between X and Y. Applied late in Attack : ( 5 ) MAIN PREDICATE CONSTRAINT There is at least one predicate in every sentence which is not subordinate to any other predicate in that sentence .</sentence>
				<definiendum id="0">POSITION CONSTRAINT</definiendum>
				<definiens id="0">at least one predicate in every sentence which is not subordinate to any other predicate in that sentence</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>A TAG comprises of two kinds of elementary trees : initial trees ( a ) , which are complete structures , usually rooted in S , with preterminals on all their leaves , and auxiliary trees ( fl ) , which are constrained to have exactly one leaf node labeled with a non-terminal of the same category as their root node .</sentence>
				<definiendum id="0">TAG</definiendum>
				<definiens id="0">comprises of two kinds of elementary trees : initial trees ( a ) , which are complete structures , usually rooted in S , with preterminals on all their leaves</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , Jean voit un canard , which is a free sentence , is a tree of depth 1 : ( NP ( V NP ) ) , whereas Jean chasse le canard , with the meaning of to hunt , has a frozen verb-determiner combination , and is represented by a tree of depth 2 : ( NP ( V ( D N ) ) ) .</sentence>
				<definiendum id="0">Jean voit un canard</definiendum>
				<definiens id="0">a free sentence</definiens>
				<definiens id="1">V NP ) ) , whereas Jean chasse le canard , with the meaning of to hunt , has a frozen verb-determiner combination</definiens>
			</definition>
</paper>

		<paper id="1079">
			<definition id="0">
				<sentence>But a definition of lexical coverage consists in more than just defining the vocabulary : it also consists in defining the content of the dictionary , the number of readings to be distinguished , the feature system to be used .</sentence>
				<definiendum id="0">lexical coverage</definiendum>
				<definiens id="0">consists in more than just defining the vocabulary : it also consists in defining the content of the dictionary , the number of readings to be distinguished , the feature system to be used</definiens>
			</definition>
</paper>

		<paper id="1049">
			<definition id="0">
				<sentence>A parser is an algorithm that assigns a structural description to a string according to a grammar .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">an algorithm that assigns a structural description to a string according to a grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>The possibility and necessity of complements depend on the lexical meaning of words , i.e. a word which denotes a relationship asks for entities which it relates , a word which denotes a modification asks for an entity which it modifies etc .</sentence>
				<definiendum id="0">necessity of complements</definiendum>
			</definition>
			<definition id="2">
				<sentence>Complex categories are sets of parameters ( attributes ) and values ( features ) .</sentence>
				<definiendum id="0">Complex categories</definiendum>
				<definiens id="0">sets of parameters ( attributes ) and values ( features )</definiens>
			</definition>
			<definition id="3">
				<sentence>A slot is a description of the head of a tree that fits into another tree .</sentence>
				<definiendum id="0">slot</definiendum>
				<definiens id="0">a description of the head of a tree that fits into another tree</definiens>
			</definition>
</paper>

		<paper id="2147">
			<definition id="0">
				<sentence>Grammars ( FTAG ) The linguistic theory underlying TAG 's is centered around the factorization of reeursion and localization of dependencies into the elementary trees .</sentence>
				<definiendum id="0">Grammars</definiendum>
			</definition>
			<definition id="1">
				<sentence>IIence , in an initial tree corresponding to a simple sentence , wc can state that the main verb and the subject NP ( which are part of the same initial tree ) share the agreement feature .</sentence>
				<definiendum id="0">IIence</definiendum>
				<definiens id="0">in an initial tree corresponding to a simple sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>e where e is a term in FSTR which involves the variable ~ .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">a term in FSTR which involves the variable ~</definiens>
			</definition>
			<definition id="3">
				<sentence>Any expression e ( which is not a hmction ) can be thought w~ upward closed subset of F ( the set of partial functions which satisfy the description el .</sentence>
				<definiendum id="0">expression e</definiendum>
				<definiens id="0">the set of partial functions which satisfy the description el</definiens>
			</definition>
</paper>

		<paper id="2160">
			<definition id="0">
				<sentence>Some simple examples have been presented using quite simple transformations : in the case of ambiguous PP attachment there are two possibilities : ( 1 ) the PP modifies a noun phrase and this could be made explicit by using a relative pronoun ; ( 2 ) the PP modifies the sentence and it can be moved ahead of it .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">modifies the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>\ [ Zajac 86a\ ] ZAJAC R. , SCSL : a linguistic specification language for Mr , COLING-86 .</sentence>
				<definiendum id="0">SCSL</definiendum>
				<definiens id="0">a linguistic specification language for Mr</definiens>
			</definition>
</paper>

		<paper id="1057">
			<definition id="0">
				<sentence>Indeed , the abstraction hierarchy allows a way to provide for the creativity of language without explicit rules .</sentence>
				<definiendum id="0">abstraction hierarchy</definiendum>
				<definiens id="0">allows a way to provide for the creativity of language without explicit rules</definiens>
			</definition>
</paper>

		<paper id="1053">
			<definition id="0">
				<sentence>In te~ ms of its general structure , our translation model may be viewed as being composed of three abstract relations : ( i ) the source analysis/synthesis relation : anasynt s ( TS , SurfSyn S , Sent S ) which defines a set of welloformed triples , where T. S is a scarce language text , SnffSy~t.S and and Sem_S are mspcclivcly a surface syntactic strnctaru and a semantic structure for this text , both being source language dependent ; ( ii ) the target analysis\ ] synthesis relation : attasyntt ( T_T , SurfSyn_T , Sem T ) which is the attalogue of anasynt_ s tbr the target hmgtmge ; and ( iii ) the tnmsfe , r relation : tr ( Sent .</sentence>
				<definiendum id="0">Sent S )</definiendum>
				<definiendum id="1">T. S</definiendum>
				<definiendum id="2">synthesis relation</definiendum>
				<definiens id="0">being composed of three abstract relations : ( i ) the source analysis/synthesis relation : anasynt s ( TS</definiens>
				<definiens id="1">a scarce language text</definiens>
			</definition>
			<definition id="1">
				<sentence>S , Sere_T ) which defines a set of couples , whore Seres and ScmT arc respectively source and target senmntic structures that are considered to be translationally equivalent .</sentence>
				<definiendum id="0">Sere_T )</definiendum>
				<definiens id="0">defines a set of couples</definiens>
			</definition>
			<definition id="2">
				<sentence>c ) increase { MOVEMENT , EVENT } ( inv-l ) ( 31 ( i ) ~ '' ~ ' '' ~ 9 * ( PRICE-MEASURE , MEASURE ) lastweek ~ 5 % { PERCENTAGE , INCREMENT ) { WEEK , TIME-POINT ) p~'ice / ~ { PRICE , MEASURE-FUNCTION } ( i ) ( inv-l ) hog At { LOCATIVE , STATE ) ( COMMODITY } I ( 2 ) saska~tcheLvan ( MARKET , LOCATION } The checking of this structure then involves looking for : a validating schema for 'lastweek ' , in this case the schema TIME-POINT ( EVENT ) a validating schema for 'increase ' , in this case the schema MOVEMENT ( MEASURE-FUNCTION , INCREMENT , MEASURE ) a validating schema for 'At ' , in this case the schema AT ( PRICE , MARKET ) As we have seen , the transfer component implements a relation between two language-dependent semantic structures .</sentence>
				<definiendum id="0">schema TIME-POINT</definiendum>
				<definiendum id="1">schema AT</definiendum>
				<definiens id="0">the transfer component implements a relation between two language-dependent semantic structures</definiens>
			</definition>
</paper>

		<paper id="2133">
			<definition id="0">
				<sentence>is : SCORE ( Xo ) = SCsyn\ [ Xl ... Xn\ ] * SCsem\ [ ( XI , KI ( XI ) , KC ( XI ) ) ... ( Xn , KI ( Xn ) , KC ( Xn ) ) \ ] In the above , Xo ( i , j ) is a subtree made up of terminals X1 to Xnl i to j are the word index in the sentence ; and SCORE is the score of the subtree Xo .</sentence>
				<definiendum id="0">SCORE</definiendum>
			</definition>
			<definition id="1">
				<sentence>SCsyn is the ttnweighted syntax score .</sentence>
				<definiendum id="0">SCsyn</definiendum>
				<definiens id="0">the ttnweighted syntax score</definiens>
			</definition>
			<definition id="2">
				<sentence>KI is defined as the knowledge about the inherent properties of the nodes .</sentence>
				<definiendum id="0">KI</definiendum>
			</definition>
			<definition id="3">
				<sentence>And KC is the well-formedness condition , either syntactic or semantic , of the Xi under the given syntactic construction .</sentence>
				<definiendum id="0">KC</definiendum>
				<definiens id="0">the well-formedness condition , either syntactic or semantic , of the Xi under the given syntactic construction</definiens>
			</definition>
			<definition id="4">
				<sentence>log ( S~ ( Xo ) ) = log ( SCsyn ) + log ( SCsem ) In order to obtain the score without excessive c~irputation and complicated algorithal , the probability model is probably one of the most c~n and promising approach .</sentence>
				<definiendum id="0">log</definiendum>
				<definiens id="0">S~ ( Xo ) ) = log ( SCsyn ) + log ( SCsem ) In order to obtain the score without excessive c~irputation</definiens>
			</definition>
</paper>

		<paper id="2093">
</paper>

		<paper id="1040">
			<definition id="0">
				<sentence>Each KS owns the syntactic and semantic competence necessary to perform a well-formed interpretation of a fragment of the input .</sentence>
				<definiendum id="0">KS</definiendum>
				<definiens id="0">owns the syntactic and semantic competence necessary to perform a well-formed interpretation of a fragment of the input</definiens>
			</definition>
			<definition id="1">
				<sentence>The Composition part represents a way of grouping a phrase having a MOUNT type header satisfying the Activation Condition and a phrase having a RIVER type header .</sentence>
				<definiendum id="0">Composition part</definiendum>
				<definiens id="0">represents a way of grouping a phrase having a MOUNT type header satisfying the Activation Condition and a phrase having a RIVER type header</definiens>
			</definition>
			<definition id="2">
				<sentence>The Meaning part allows to generate the meaning representation starting 197 0F-24 \ [ TO-HAVE-SOURCE\ ] -- * ( AGNT : Oompulsory ) -- + RIVER -- ~ ( LOC : Compulsory ) -- ~ \ [ MOUNT\ ] DR-12.1 VERB ( prop ) = NOUN ( interr-indlr-loe ) &lt; GOVERNOR &gt; NOUN ( subJ ) ; ; Features and Agreements &lt; GOVERNOR &gt; ( MOOD ind ) ( TENSE pres ) ( NUMBER _x ) ... . NOUN-I ... . NOUN-2 ( NUMBER _x ) ... . DR-12.2 VERB ( prop ) = NOUN ( interr-indir-loc ) &lt; GOVERNOR &gt; PROP-NOUN ( ~ubJ ) DeIKS KS-24.12 ; ; Composition TO-HAVE-SOURCE = MOUNT &lt; HEADER &gt; RIVER ; ; Constraints &lt; HEADER &gt; -MOUNT ( ( H-cat VERB ) ( S-eat NOUN ) ( H-feat MOOD ind TENSE pre ... . ) ... ) &lt; HEADER &gt; -RIVER ... ... ... ... ... ; ; Header Activation Condition ACTION ( TO-HAVE-SOURCE ) ; ; Meaning ( TO-HAVE-SOURCE I * agnt i los 0 ) Figure 1 : A caseframe ( expressed in CG notation ) , two dependency rules and a corresponding KS .</sentence>
				<definiendum id="0">Meaning part</definiendum>
				<definiendum id="1">MOOD ind ) ( TENSE</definiendum>
				<definiendum id="2">Header Activation Condition ACTION</definiendum>
				<definiendum id="3">Meaning</definiendum>
				<definiendum id="4">A caseframe</definiendum>
				<definiens id="0">prop ) = NOUN ( interr-indir-loc ) &lt; GOVERNOR &gt; PROP-NOUN ( ~ubJ ) DeIKS KS-24.12 ; ; Composition TO-HAVE-SOURCE = MOUNT &lt; HEADER &gt; RIVER ; ; Constraints &lt; HEADER &gt; -MOUNT ( ( H-cat VERB ) ( S-eat NOUN ) ( H-feat MOOD ind TENSE pre ...</definiens>
			</definition>
			<definition id="3">
				<sentence>SYNAPSIS is an evolution of the parser included in the SUSY system for understanding speech and described in \ [ Poesio 87\ ] .</sentence>
				<definiendum id="0">SYNAPSIS</definiendum>
				<definiens id="0">an evolution of the parser included in the SUSY system for understanding speech and described in \</definiens>
			</definition>
</paper>

		<paper id="2124">
			<definition id="0">
				<sentence>J.D. : Each unit implements a simple numerical function , sometimes a simple combination of several functions computing input from several sites of incoming activation .</sentence>
				<definiendum id="0">J.D.</definiendum>
				<definiens id="0">Each unit implements a simple numerical function , sometimes a simple combination of several functions computing input from several sites of incoming activation</definiens>
			</definition>
			<definition id="1">
				<sentence>P.D. : The system is a shared memory system .</sentence>
				<definiendum id="0">P.D.</definiendum>
			</definition>
			<definition id="2">
				<sentence>A.Y. : The interaction between units involves message passing .</sentence>
				<definiendum id="0">A.Y.</definiendum>
				<definiens id="0">The interaction between units involves message passing</definiens>
			</definition>
			<definition id="3">
				<sentence>We run the spreadsheet in the computation-mode : iterative , columnwise , which defines the sequential simulation .</sentence>
				<definiendum id="0">columnwise</definiendum>
				<definiens id="0">defines the sequential simulation</definiens>
			</definition>
			<definition id="4">
				<sentence>A.Y. : We designed an object-oriented concurrent language called ABCL/I and program parsers in this language .</sentence>
				<definiendum id="0">A.Y.</definiendum>
				<definiens id="0">We designed an object-oriented concurrent language called ABCL/I and program parsers in this language</definiens>
			</definition>
			<definition id="5">
				<sentence>Ingestion consists of co-occurrence rules .</sentence>
				<definiendum id="0">Ingestion</definiendum>
				<definiens id="0">consists of co-occurrence rules</definiens>
			</definition>
			<definition id="6">
				<sentence>J.D. : Fixed-length context-free grammar .</sentence>
				<definiendum id="0">J.D.</definiendum>
				<definiens id="0">Fixed-length context-free grammar</definiens>
			</definition>
			<definition id="7">
				<sentence>H.S. : Syntax and phonology as a part of a lexical access system .</sentence>
				<definiendum id="0">H.S.</definiendum>
				<definiens id="0">a part of a lexical access system</definiens>
			</definition>
</paper>

		<paper id="1055">
			<definition id="0">
				<sentence>CONCRETION is the process of developing a specific interpretation by combining various levels of conceptual information .</sentence>
				<definiendum id="0">CONCRETION</definiendum>
				<definiens id="0">the process of developing a specific interpretation by combining various levels of conceptual information</definiens>
			</definition>
			<definition id="1">
				<sentence>Concretion Mlows the language analyzer to develop a sufficiently specific representation without excessive computation or brittle interpretation rules .</sentence>
				<definiendum id="0">Concretion</definiendum>
				<definiens id="0">Mlows the language analyzer to develop a sufficiently specific representation without excessive computation or brittle interpretation rules</definiens>
			</definition>
			<definition id="2">
				<sentence>In each of the examples , the italicized word or phrase represents a vague , ambiguous , or metaphorical verb sense .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">a vague , ambiguous , or metaphorical verb sense</definiens>
			</definition>
			<definition id="3">
				<sentence>In all cases , concretion re ( tuires four ingredients : * An instantiated concept to be specialized e A linguistic or conceptual `` trigger '' e A target concept type o A conceptual relation between source and target For example , in John cut the salami , the concept to be concreted is cutting , the trigger is the combination of cutting with ediblc-obloid or some such~ the target concept is slicing ( indicated by the trigger ) , and the relation is subcategorization , or DOMINATEs .</sentence>
				<definiendum id="0">trigger</definiendum>
				<definiens id="0">indicated by the trigger )</definiens>
			</definition>
			<definition id="4">
				<sentence>A general VIEW of action as transfer-event relates giving ( which is a tranffer-event to kissing ( which is an action ) , and also the recipient of the giving to the conceptual object of the action .</sentence>
				<definiendum id="0">general VIEW of action</definiendum>
				<definiens id="0">an action ) , and also the recipient of the giving to the conceptual object of the action</definiens>
			</definition>
			<definition id="5">
				<sentence>CONCRETION is the assumption-based part of semantic interpretation .</sentence>
				<definiendum id="0">CONCRETION</definiendum>
				<definiens id="0">the assumption-based part of semantic interpretation</definiens>
			</definition>
</paper>

		<paper id="2120">
			<definition id="0">
				<sentence>The Semantics attribute records a logical formula representing the meaning of the discourse constituent unit that it is associated with .</sentence>
				<definiendum id="0">Semantics attribute</definiendum>
				<definiens id="0">records a logical formula representing the meaning of the discourse constituent unit that it is associated with</definiens>
			</definition>
			<definition id="1">
				<sentence>The Discourse Referents Set records the entities introduced in the discourse unit that it is associated with .</sentence>
				<definiendum id="0">Discourse Referents Set</definiendum>
				<definiens id="0">records the entities introduced in the discourse unit that it is associated with</definiens>
			</definition>
			<definition id="2">
				<sentence>The grammar consists of rules which descdbe how to build up various kinds of structurally different discourse constituent units .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiens id="0">consists of rules which descdbe how to build up various kinds of structurally different discourse constituent units</definiens>
			</definition>
			<definition id="3">
				<sentence>Under this category we include rhetorical coordinations ( the counterparts of the rhetorical subordinations ) , and adjacency pairs which are concerned with the interactiona/dimension of the discourse ( we include question~answer pairs and request~response pairs ) .</sentence>
				<definiendum id="0">rhetorical coordinations</definiendum>
				<definiens id="0">the counterparts of the rhetorical subordinations ) , and adjacency pairs which are concerned with the interactiona/dimension of the discourse ( we include question~answer pairs and request~response pairs )</definiens>
			</definition>
			<definition id="4">
				<sentence>All clue-words ( push-markers , pop-markers , interruption-markers ) are treated as independent units , separate from the sentences that they precede or follow .</sentence>
				<definiendum id="0">All clue-words</definiendum>
				<definiens id="0">independent units , separate from the sentences that they precede or follow</definiens>
			</definition>
			<definition id="5">
				<sentence>The granularity of this `` unpredictability without misunderstanding '' seems to be the clause or sentence level• We therefore postulate an incremental left-to-right parsing process at this level of granularity , which operates in essentially deterministic mode .</sentence>
				<definiendum id="0">granularity</definiendum>
				<definiens id="0">operates in essentially deterministic mode</definiens>
			</definition>
			<definition id="6">
				<sentence>The Linguistic Discourse Model : Towards A Formal Theory of Discourse Structure .</sentence>
				<definiendum id="0">Linguistic Discourse Model</definiendum>
			</definition>
			<definition id="7">
				<sentence>What the Speaker Means : The Recognition of Speakers ' Plans in Discourse .</sentence>
				<definiendum id="0">Speaker Means</definiendum>
				<definiens id="0">The Recognition of Speakers ' Plans in Discourse</definiens>
			</definition>
</paper>

		<paper id="2100">
			<definition id="0">
				<sentence>NI~S is a dislributed natural language generation system featuring a blackboard-type control structure .</sentence>
				<definiendum id="0">NI~S</definiendum>
				<definiens id="0">a dislributed natural language generation system featuring a blackboard-type control structure</definiens>
			</definition>
			<definition id="1">
				<sentence>qbe following is a sample input tlmt will allow D\ [ OG~qI~S tO produce the sentence The basic IBM personal computer XT consists of a system unit and a keyboard ( ( iI ) clause\ ] . )</sentence>
				<definiendum id="0">qbe following</definiendum>
			</definition>
			<definition id="2">
				<sentence>( make-frame toss ( is-token-of ( value throw ) ) ( direction ( value up ) ( importance 3 ) ) ( altitude ( value high ) ( importance 3 ) ) ( velocity ( value low ) ( importance 9 ) ) ( object ( value coin ) ( lexeme ( value `` toss '' ) ) ( syntactic-info ( lexical-class verb ) ( verb-type transitive ) ( morph regular ) ( para-collocation ( antonym catch ) ( synonym cast propel toss fling hurl pitch pass ) ) ) ( make-frame new ( is-token-of ( value age .</sentence>
				<definiendum id="0">morph regular ) ( para-collocation</definiendum>
				<definiens id="0">synonym cast propel toss fling hurl pitch pass</definiens>
			</definition>
			<definition id="3">
				<sentence>Meaning Text Models : A Recent Trend iu Soviet Linguistics .</sentence>
				<definiendum id="0">Meaning Text Models</definiendum>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>Stylistic component : A part of a stylistic constituent , e.g. , a phrase or clause .</sentence>
				<definiendum id="0">Stylistic component</definiendum>
				<definiens id="0">A part of a stylistic constituent , e.g. , a phrase or clause</definiens>
			</definition>
			<definition id="1">
				<sentence>Stylistic shape : A stylistic component usually regarded as stylistically expressive , .</sentence>
				<definiendum id="0">Stylistic shape</definiendum>
			</definition>
			<definition id="2">
				<sentence>Interval : The stylistic distance or difference between any two shapes in a stylistic constituent .</sentence>
				<definiendum id="0">Interval</definiendum>
				<definiens id="0">The stylistic distance or difference between any two shapes in a stylistic constituent</definiens>
			</definition>
			<definition id="3">
				<sentence>Counterpoise : A stylistic texture containing an offset , a shape which perturbs the stylistic balance by disturbing the canonical order .</sentence>
				<definiendum id="0">Counterpoise</definiendum>
				<definiens id="0">A stylistic texture containing an offset , a shape which perturbs the stylistic balance by disturbing the canonical order</definiens>
			</definition>
			<definition id="4">
				<sentence>Resolution -- ~ ( Initial Discord ) + , ( Medial Discord ) + , Final Concord Dissolution -- -- 4 Initial qMedial Concord , Final Discord Initial qMedial Concord -- + Diasehematic ... ( i.e. , diaschcmatic for some initial portion ) Final Concord -- -+ ... Diaschcmatic Initial Discord -- ~ Discordant Major , ( Dependent clause ) * t ( Discordant dependent clause ) + , Major , ( Dependent clause ) * Medial Counterpoise -- -~ ( VOC ) , Co , mterpoisal S , P , ( C ) , ( A ) + Medial Discord IS-A Medial Counterpoise with Counterpoisal S = Discordant Counterpoisal S Final Discord -- ~ ... Discordant Major Diaschematie -- -+ Simple Concordant Sentence Cycle -- -+ x + , Major , y+ where x and y are instances of Dependent clauses and are in the same stylistic equivalence class .</sentence>
				<definiendum id="0">P ,</definiendum>
				<definiens id="0">Medial Discord ) + , Final Concord Dissolution -- -- 4 Initial qMedial Concord , Final Discord Initial qMedial Concord -- + Diasehematic ... ( i.e. , diaschcmatic for some initial portion ) Final Concord -- -+ ... Diaschcmatic Initial Discord -- ~ Discordant Major</definiens>
				<definiens id="1">Dependent clause ) * Medial Counterpoise -- -~ ( VOC ) , Co , mterpoisal S ,</definiens>
				<definiens id="2">A ) + Medial Discord IS-A Medial Counterpoise with Counterpoisal S = Discordant Counterpoisal S Final Discord -- ~ ... Discordant Major Diaschematie -- -+ Simple Concordant Sentence Cycle -- -+ x + , Major , y+ where x and y are instances of Dependent clauses and are in the same stylistic equivalence class</definiens>
			</definition>
			<definition id="5">
				<sentence>And , in this example , we see imitative postnmdification : Silvia , a commanding woman in her 50 's , a shrew falsely mellowed by religion , promptly organiaed prayer sessions on the lines of Tupperware meetings \ [ adapted from Manch151 Sentence -- * Complete \ ] Incomplete* Simple Concordant Sentence IS-A Sentence with only Complete = Simple Concordant Complete Complete ~ ( Dependent clause ) * , Major , ( Dependent clause ) * I Minor Simple Concordant Complete ~ Simple Concordant Major , ( Concordant dependent clause ) * Major ~ ( Conjunction ) * , ( A ) * , ( C ) , ( VOC ) , S , P , ( C ) , ( A ) + Simple Concordant Major -- ~ ( Conjunction ) * , Simple Concordant S , P , ( Simple Concordant C ) , ( Concordant A ) Discordant Major ( Conjunction ) * , ( Discordant A ) + , ( C ) , ( VOC ) , S , P , ( C ) , ( A ) + ( Conjunction ) * , ( A ) * , ( C ) , ( VOC ) , ( AuxVerb ) + , ( C ) , S , P , ( C ) , ( A ) + ( Conjunction ) * , ( A ) * , ( C ) , ( VOC ) , P , S , ( C ) , ( A ) + Discordant A ~ Disjunct or Antijunct adverb I Disjunct or Antijunct adverbial construction I Disjunct or Antijunct dependent \ [ adverbial\ ] clause S ~ Nominal group I Pronoun I Dependent \ [ noun\ ] clause Simple Concordant S IS-A S with only ( ( Nominal group -- Simple Concordant Nominal group ) I Pronoun ) Counterpoisal S IS-A S with only Nominal group = Counterpoisal Nominal group Discordant Counterpoisal S IS-A Counterpoisal S with Nominal group = Discordant Counterpoisal Nominal group Nominal group ~ ( Premodificationa ) Noun ( Postmodification ) * I Pronoun Simple Concordant Nominal group IS-A Nominal group with ( Premodificationn -- = Simple Concordant Premodificationn ) and ( Postmodification = ( Simple Concordant Postmodification ) Counterpoisal Nominal group IS-A Nominal group with Postmodification = ( Counterpoisal Postmodification ) + Discordant Counterpoisal Nominal group IS-A Counterpoisal Nominal group with Postmodification = ( Discordant Counterpoisal Postmodification ) + Simple Concordant Premodification IS-A Premodification with only Adjunct or Conjunct Premodification Postmodification~ Adjunct Postmodificationn -- ~ Dependent \ [ relative\ ] clause \ ] Nominal relative clause I Adjunct dependent \ [ adverbial\ ] clause Conjunct Postmodificationn -- 4 Non-finite construction I Conjunct dependent \ [ adverbial\ ] clause I Nominal `` that '' clause I Preposition* + Nominal group Disjunct Postmodificationn -- -- * Verbless clause \ [ Disjunct dependent \ [ adverbial\ ] clause Antijunct Postmodificationn ~ Adjective Simple Concordant Postmodification -- ~ Adjunct or Conjunct Postmodification ( Imitative Postmodification ) \ ] Imitative Postmodification Imitative Postmodification x , ( Conjunction ) , y , ( Conjunction ) , ( z ) where z , y , z are instances of Postmodification and are not instances of Antijunct Postmodification and arc in the same stylistic equivalence class .</sentence>
				<definiendum id="0">P , ( Simple Concordant C</definiendum>
				<definiendum id="1">Discordant</definiendum>
				<definiens id="0">A ) + Simple Concordant Major -- ~ ( Conjunction ) * , Simple Concordant S ,</definiens>
				<definiens id="1">A ) + , ( C ) , ( VOC ) , S , P , ( C ) , ( A ) + ( Conjunction ) * , ( A ) * , ( C ) , ( VOC ) , ( AuxVerb ) +</definiens>
				<definiens id="2">A ) + ( Conjunction ) * , ( A ) * , ( C</definiens>
				<definiens id="3">] clause Simple Concordant S IS-A S with only ( ( Nominal group -- Simple Concordant Nominal group ) I Pronoun ) Counterpoisal S IS-A S with only Nominal group = Counterpoisal Nominal group Discordant Counterpoisal S IS-A Counterpoisal S with Nominal group = Discordant Counterpoisal Nominal group Nominal group ~ ( Premodificationa ) Noun ( Postmodification ) * I Pronoun Simple Concordant Nominal group IS-A Nominal group with ( Premodificationn -- = Simple Concordant Premodificationn ) and ( Postmodification = ( Simple Concordant Postmodification ) Counterpoisal Nominal group IS-A Nominal group with Postmodification = ( Counterpoisal Postmodification ) + Discordant Counterpoisal Nominal group IS-A Counterpoisal Nominal group with Postmodification = ( Discordant Counterpoisal Postmodification ) + Simple Concordant Premodification IS-A Premodification with only Adjunct or Conjunct Premodification Postmodification~ Adjunct Postmodificationn -- ~ Dependent \ [ relative\ ] clause \ ] Nominal relative clause</definiens>
				<definiens id="4">] clause I Nominal `` that '' clause I Preposition* + Nominal group Disjunct Postmodificationn -- -- * Verbless clause \ [ Disjunct dependent \ [ adverbial\ ] clause Antijunct Postmodificationn ~ Adjective Simple Concordant Postmodification -- ~ Adjunct or Conjunct Postmodification ( Imitative Postmodification ) \ ] Imitative Postmodification Imitative Postmodification x , ( Conjunction ) , y , ( Conjunction ) , ( z ) where z , y , z are instances of Postmodification and are not instances of Antijunct Postmodification and arc in the same stylistic equivalence class</definiens>
			</definition>
</paper>

		<paper id="2142">
			<definition id="0">
				<sentence>~lb understand this , a system has to have a lot of real world knowl-edge which is not so closely related with hotel reservation tasks , such as ( 1 ) Roppongi is a special region in ~lbkyo where many discothetques exist ( 2 ) In order to go to some place , it is preferable to stay at a hotel near to the place ( 3 ) If something is preferable , the client tend to ... .. etc .</sentence>
				<definiendum id="0">Roppongi</definiendum>
				<definiens id="0">a special region in ~lbkyo</definiens>
			</definition>
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>The model is summariscd by the for , nula DUR = \ [ ( INHDUR MINDUR ) *PRCNT\ ] /100 + MINDUR where INHDUR is the inherent segment du , 'ation ill lns , MINDUR is the minimuln duration of a segment if stressed and PRCNT is the percentage shortening determined by the rules . '</sentence>
				<definiendum id="0">INHDUR</definiendum>
				<definiendum id="1">MINDUR</definiendum>
				<definiendum id="2">PRCNT</definiendum>
				<definiens id="0">the inherent segment du , 'ation ill lns</definiens>
				<definiens id="1">the minimuln duration of a segment if stressed and</definiens>
			</definition>
</paper>

		<paper id="2095">
</paper>

		<paper id="1063">
			<definition id="0">
				<sentence>Many computational linguists have found systemic grammar ( SG ) to be quite useful , because it provides an explicit representation of features that determine how a sentence functions in the context of communication .</sentence>
				<definiendum id="0">systemic grammar ( SG )</definiendum>
				<definiens id="0">explicit representation of features that determine how a sentence functions in the context of communication</definiens>
			</definition>
			<definition id="1">
				<sentence>Systemic l ; nguistics builds on the foundation of Hailiday 's con .</sentence>
				<definiendum id="0">nguistics</definiendum>
				<definiens id="0">builds on the foundation of Hailiday 's con</definiens>
			</definition>
			<definition id="2">
				<sentence>Using the feature description logic ( FDL ) of Kasper and Rounds \ [ Kasper 86\ ] , the types of formula used to define a grammar include : 1 NIL denoting no i~formatloa ; a where a E A , to describe atomic values ; l : ~b where I E L and ~ E FDL~ to describe structures in which the feature labeled by l has a value described by ~ ; ql or l : ANY where l E L , to describe a sliructure in which I has a substantive ( non-NIL I value ; &lt; p &gt; where p E L* , to describe a structure that shares a common value with the path p ; \ [ ~bl ... ~\ ] where ~b~ E FDL , denoting conjunction ; { ~bl ... ~b , ~ } where ~b~ E FDL , denoting disjunction ; ~1 -- * ~ where ~b~ E FDL , denoting classical implication .</sentence>
				<definiendum id="0">FDL</definiendum>
				<definiens id="0">where p E L* , to describe a structure that shares a common value with the path p</definiens>
			</definition>
			<definition id="3">
				<sentence>Rank : Clause Mood-type : Imperative NONFINITIVE : \ [ Form : Stem \ ] 1 Mood-type : Indicative SUBJECT : \ [ Case : Nominative \ ] pattern : ( .</sentence>
				<definiendum id="0">Rank</definiendum>
				<definiens id="0">Clause Mood-type : Imperative NONFINITIVE : \ [ Form : Stem \ ] 1 Mood-type : Indicative SUBJECT : \ [</definiens>
			</definition>
</paper>

		<paper id="2085">
			<definition id="0">
				<sentence>CONSISTENCY CONSTRAINTS Consistency constraints to be used as a basis for diagnosing students ' faults are expressed in a quite common way as binary predicates which hold over structured feature sets of syntactically related word forms ( source and destination ) .</sentence>
				<definiendum id="0">CONSISTENCY CONSTRAINTS Consistency constraints</definiendum>
				<definiens id="0">hold over structured feature sets of syntactically related word forms ( source and destination )</definiens>
			</definition>
			<definition id="1">
				<sentence>ERROR SELECTION Error selection is an integral part of several steps of the diagnosis procedure .</sentence>
				<definiendum id="0">ERROR SELECTION Error selection</definiendum>
				<definiens id="0">an integral part of several steps of the diagnosis procedure</definiens>
			</definition>
</paper>

		<paper id="2154">
			<definition id="0">
				<sentence>DLT is a concentrated high-tech effort to attain a product line of language translation modules in the 1990s .</sentence>
				<definiendum id="0">DLT</definiendum>
				<definiens id="0">a concentrated high-tech effort to attain a product line of language translation modules in the 1990s</definiens>
			</definition>
</paper>

		<paper id="1064">
			<definition id="0">
				<sentence>\ ] Koskenniemi , Kirmno ( 1983 ) Two-Level Morphology : A General Computational Method for Word-Form Recognition and Production .</sentence>
				<definiendum id="0">Two-Level Morphology</definiendum>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>elaborated i~ the English-to-Czech NT system ( el° Kirschner,82 ) o The transducing dictions ... . ry , based on algorithmic handling of the regular productive international affixes ( with exceptions listed in the main dictionary ) and of the orthographic and similar differences , can be illustrated by the following : as with the suffixes -gig ( mental , , '' assembly '' ) -- ~ , .</sentence>
				<definiendum id="0">English-to-Czech NT system</definiendum>
				<definiens id="0">productive international affixes ( with exceptions listed in the main dictionary ) and of the orthographic and similar differences</definiens>
			</definition>
</paper>

		<paper id="2098">
			<definition id="0">
				<sentence>D2 ) of LDOCE/RDB DF to leave completely and fQr ever desert to leave ( a relation o~ I~iend ) in a though~ less or cruel way to give up , esp .</sentence>
				<definiendum id="0">D2</definiendum>
				<definiens id="0">a relation o~ I~iend ) in a though~ less or cruel way to give up , esp</definiens>
			</definition>
			<definition id="1">
				<sentence>In the following part of this s &amp; tion , the comparison betwee~ semantic markers of LDOCE and the thesaurus constrn &amp; ed ti : o~ , ~he definitions of nouns in LDOCE is discussed ikon~ ~ ; he view Table 8 : Semantic Markers in Box Code of Nouns and their Frequency ( Part ) type of ( : ode A Animal B Female Animal C Concrete D Male Animal E 'S ' + 'L ' F Female tluman G Gas It ltuma~ I Inanimate J Movable K Male ( 'D ' + 'M ' ) L Liquid M Male Human N Not Movable O 'A ' + 'II ' P Plant Q Animate R Female ( 'B ' + 'P ) S Solid T Abstract U Collective + '0 ' V 'P ' + 'A ' W 'T ' + T X 'T ' + 'H ' Y 'T ' + 'Q ' Z UNMARKED o..</sentence>
				<definiendum id="0">P Plant Q Animate R Female</definiendum>
				<definiens id="0">Semantic Markers in Box Code of Nouns and their Frequency ( Part ) type of ( : ode A Animal B Female Animal C Concrete D Male Animal E 'S '</definiens>
			</definition>
</paper>

		<paper id="1060">
			<definition id="0">
				<sentence>This notation is straightforwardly extended to allow for strings of symbols , as illustrated in expressions such as ( I '' co , ~w ( re , l ) above , lfx=sy is a string composedofan irfitial symbol s followed by a ( possibly empty ) suffix stringy , then ( 2 ) ( fxI~ ( ( fs ) y ) ( f~ ) =-/ ' , where c is the empty string .</sentence>
				<definiendum id="0">fxI~</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">a string composedofan irfitial symbol s followed by a ( possibly empty ) suffix stringy</definiens>
			</definition>
			<definition id="1">
				<sentence>A specification for '' a broader class of topiealization sentences might be ( 1 ' TOPIC ) = { T COMP* GF ) , where GF denotes the set of primitive grammatical functions { SUFU , OgJ , OBJY , XCOMP , ... } .</sentence>
				<definiendum id="0">GF</definiendum>
				<definiens id="0">the set of primitive grammatical functions { SUFU , OgJ , OBJY , XCOMP , ... }</definiens>
			</definition>
			<definition id="2">
				<sentence>All interactions of the strings in a and 13 that lead through states q and r , respectively , are covered by the following possibilities : ( 9 ) ( a ) Strings fi'om a are prefixes of strings fiom 13 : ( f aCIPrefix ( ~ , r ) ) = va A ( v ( ~ Suffix ( 13 , r ) ) = uf~ ( b ) Strings fi'om 13 are prefixes of strings from a : ( f \ [ ff/Prefix ( a , q ) ) = ell A ( v~ Suffix ( a , q ) ) = u a ( c ) Strings have a common prefix and then diverge on some sa and sl~ in Z : ( f Prefix ( n , q ) NPrefix ( \ [ J , r ) ) == gqv A \ [ ( g'q , r , % Suffix ( u,8~ , ( q , so ) ) ) = vQ A ( g , q , , .</sentence>
				<definiendum id="0">c ) Strings</definiendum>
				<definiens id="0">n , q ) NPrefix ( \ [ J , r ) ) == gqv A \</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally , we observe that there is a specialization of the Free operator that applies when an uncertainty interacts with several non uncertainty equations ( equations whose attribute expressions have singleton First set : ; ) , instead of separating one interaction flxun the uncertainty with each application of Fl'eo , the Itncertainty is divided in a single step into u minimum nmuber of disjunctive possibilities eacilef which interacts with just one of the .</sentence>
				<definiendum id="0">operator</definiendum>
				<definiendum id="1">Itncertainty</definiendum>
				<definiens id="0">applies when an uncertainty interacts with several non uncertainty equations ( equations whose attribute expressions have singleton First set : ; ) , instead of separating one interaction flxun the uncertainty with each application of Fl'eo , the</definiens>
			</definition>
</paper>

		<paper id="2164">
			<definition id="0">
				<sentence>This can be schematized as follows : Teacher : sets the task and presents the learning material Student : analyzes the data ; Teacher : provtdes a set of examples ; Student : practices ; Teacher : asks questions to test the gained knowledge ; Student : answers the questions ; Teacher : evaluates the answers , provides feedback ( explanations ) and organizes future data as a function of actual performance Student : integrates the feedback into the knowledge base and corrects misconceptions ; As one can see , the information flow here is entirely teacher-controlled .</sentence>
				<definiendum id="0">Teacher</definiendum>
				<definiendum id="1">Student</definiendum>
				<definiendum id="2">Student</definiendum>
				<definiendum id="3">Teacher</definiendum>
				<definiendum id="4">information flow</definiendum>
				<definiens id="0">analyzes the data ;</definiens>
				<definiens id="1">answers the questions ;</definiens>
				<definiens id="2">integrates the feedback into the knowledge base and corrects misconceptions</definiens>
			</definition>
			<definition id="1">
				<sentence>As long as the learne~ '' does not go beyond the informaBon given ( the concrete word level ) , he can not transfer the gained knowledge to similar situations , because the perception of similarity presupposes abstraction .</sentence>
				<definiendum id="0">informaBon given</definiendum>
				<definiens id="0">the concrete word level</definiens>
			</definition>
			<definition id="2">
				<sentence>-V-neg no la lul prdsonta paa Dontt introduce her to him g ) neg-IO-DO'-V-llog no me la prdeente pan Dealt Introduce her to me h ) Ileq-DO-V-nl~g.'pp -- ro 1|o Ine prdflento pail b ella Doltlt h~troduce me tO her i t n~g-Io~v-lmg-pp-Io lie lut parle pa~ de mol Do n't tell her about me S : subject , DO : direct object , IO : indirect object , pp : preposition , nag : negation , V : verb As one can see from tile data , pronoun &lt; onstructions in French can be fairly complex ( 4 ) . This complexity is due to : * the number of features necessary to determine word order or morphology : PART OF SPEECH : ( noun , pronoun ) ie parle ~ ( noun ) je klJ , parle ( pronoun ) SYNTACTIC FUNt.7 '' ION ( subject , direct object , indirect object ) il 6erit h Pierre ~subject ) Paul llli derit ( redirect object ) SENTENCE-TYPE : ( declarative , interrogative , command ) tu m~ le donnes ? ( interrogative ) donne-It ~ ! ( command ) NEGATION : ( , yes , no ) oonnes-le alfi ! ( positive ) ne ~ le donnes pasI ( .negative ) COMMUNICATIVE-ROLES : ( I , you , tie ) je te LE donne ( IO = je LE llli donne ( IO = ~o~ ) NUMBER : ( singular , plural , indefinite ) je te 1~ garde ( singular ) je te Its garde ( plural ) je t'gn garde ( indefinite ) GENDER : ( male , female ) je lg vois ( male ) je la vois ( female ) VERB CONSTRUCTION : { type of complement ( DO vs IO ) , pJpe at preposition , reflexivity ) je vois_Mane -- &gt; je la vois ( direct object ) je parle ~t Marie -- &gt; je 1~ parle ( indirect object ) SEMANTIC FEATURES : ( animate , inanimate ) il m'emm6ne ~ ~ -- &gt; il m ' ~ emm6ne il me pr6sente ~t sa ~ -- &gt; il me pr6sente ~t * the structure of these features : if one compares ( a ) and ( e ) , one will notice that the form of the indirect object ( lui vs ella ) depends on the value of the direct object ( horizontal dependancy ) ; * the inte~ependance of syntax and morphology : practically all variables , except NUMBER and GENDER are relevant both for ~ntax and morphology .</sentence>
				<definiendum id="0">DO</definiendum>
				<definiens id="0">subject , direct object , indirect object ) il 6erit h Pierre ~subject</definiens>
				<definiens id="1">direct object ) je parle ~t Marie -- &gt; je 1~ parle ( indirect object</definiens>
				<definiens id="2">if one compares ( a ) and ( e ) , one will notice that the form of the indirect object ( lui vs ella ) depends on the value of the direct object ( horizontal dependancy ) ; * the inte~ependance of syntax and morphology : practically all variables , except NUMBER and GENDER are relevant both for ~ntax and morphology</definiens>
			</definition>
			<definition id="3">
				<sentence>This latter kind of knowledge could be expressed as : R3 : if PART OF SPEECH : pronoun &amp; SYNTACTIC FUNGI'ION : direct object &amp; GENDER : female then PRONOUN : la else if GENDER : male then PRONOUN : le In the next question he is concerned with the relevancy of NUMBER .</sentence>
				<definiendum id="0">SYNTACTIC FUNGI'ION</definiendum>
				<definiendum id="1">GENDER</definiendum>
				<definiens id="0">direct object &amp;</definiens>
			</definition>
			<definition id="4">
				<sentence>Parsers analyze sentences and assign them descriptions on various levels such as : part of speech , syntacti~ function , case-roles and so forth .</sentence>
				<definiendum id="0">Parsers</definiendum>
				<definiens id="0">analyze sentences and assign them descriptions on various levels such as : part of speech</definiens>
			</definition>
</paper>

		<paper id="1075">
			<definition id="0">
				<sentence>The notation used is V for the set of nonterminal , \ ] E for the set of terminals , YI for the rules , and for the initial nonterminal .</sentence>
				<definiendum id="0">YI</definiendum>
				<definiens id="0">the set of nonterminal , \ ] E for the set of terminals</definiens>
			</definition>
			<definition id="1">
				<sentence>The meaning of an item U = ( ( p A i ) ( q n j ) ) is the following : • there are computations of the PDT on the given input sentence that reach a configuration pt where the state is p , the stack top is A and the last symbol scanned is xi ; • the next stack symbol is then B and , for all these computations , it was last on top in a configuration p where the state was q and the last symbol scanned was xj ; • the rule sequences in l-I* derivable from U in the grammar are exactly those sequences output by the above defined comput~ : tions of the PDT between configurations p and p~ .</sentence>
				<definiendum id="0">meaning of an item U</definiendum>
				<definiendum id="1">stack top</definiendum>
			</definition>
</paper>

		<paper id="1036">
			<definition id="0">
				<sentence>Tile approach lends support to the views of Lakoff and Johnson ( 1980 ) that metonymy and metaphor are quite different phenomena , that metonymy is a means by which one entity stands for another , whereas metaphor is a way in which one entity is viewed as another .</sentence>
				<definiendum id="0">metonymy</definiendum>
				<definiens id="0">Tile approach lends support to the views of Lakoff and Johnson ( 1980 ) that metonymy and metaphor are quite different phenomena</definiens>
				<definiens id="1">a way in which one entity</definiens>
			</definition>
			<definition id="1">
				<sentence>CS is a recently proposed domain-independent semantics for natural language processing which is , in many respects , a developmenl of Preference Semantics ( Wilks 1973 , 1975a , 1975b ) .</sentence>
				<definiendum id="0">CS</definiendum>
				<definiens id="0">a recently proposed domain-independent semantics for natural language processing</definiens>
			</definition>
			<definition id="2">
				<sentence>The second component of CS is the process of collation .</sentence>
				<definiendum id="0">CS</definiendum>
				<definiens id="0">the process of collation</definiens>
			</definition>
			<definition id="3">
				<sentence>Tile third component of CS is the semantic vector which is a form of representation , along with sense-fi'ames ; but sense-frames represent knowledge , whereas semantic vectors represent coherence .</sentence>
				<definiendum id="0">Tile third component of CS</definiendum>
				<definiens id="0">the semantic vector which is a form of representation</definiens>
			</definition>
			<definition id="4">
				<sentence>The fourth component of CS is the process of screening .</sentence>
				<definiendum id="0">CS</definiendum>
				<definiens id="0">the process of screening</definiens>
			</definition>
			<definition id="5">
				<sentence>The discovered metonymic inference is that johann_sebastian bacti ( the Artist ) composes musical pieces ( the Artform ) .</sentence>
				<definiendum id="0">metonymic inference</definiendum>
				<definiendum id="1">Artist )</definiendum>
			</definition>
			<definition id="6">
				<sentence>The successful metonymic inference is as follows : ( a ) johann_sebastian_bach ( the Artist ) is a composerl , ( b ) composers compose1 musical pieces ( the Artform ) .</sentence>
				<definiendum id="0">Artist )</definiendum>
			</definition>
</paper>

		<paper id="2145">
			<definition id="0">
				<sentence>Extension reidentifies an identified element and impl~elative unaffectedness by the identification situation ; cancellation signalizes the complement of an originally identified set , and objec~ tiveness indicates that the referent can be at any frcm the element initially identified .</sentence>
				<definiendum id="0">Extension</definiendum>
				<definiendum id="1">cancellation</definiendum>
				<definiens id="0">reidentifies an identified element and impl~elative unaffectedness by the identification situation ;</definiens>
				<definiens id="1">signalizes the complement of an originally identified set</definiens>
			</definition>
			<definition id="1">
				<sentence>Dim '' says that there is a subset of elements in the speech situation which have a property in common .</sentence>
				<definiendum id="0">Dim</definiendum>
				<definiens id="0">a subset of elements in the speech situation which have a property in common</definiens>
			</definition>
			<definition id="2">
				<sentence>Singulative identificational extension ( ext '' ' ) will mean that the referent has alr~n identified and is , in synchronization with this original identification , reidentifiable an indefinite number of times .</sentence>
				<definiendum id="0">Singulative identificational extension</definiendum>
				<definiens id="0">alr~n identified and is , in synchronization with this original identification , reidentifiable an indefinite number of times</definiens>
			</definition>
			<definition id="3">
				<sentence>The reflexive ( personal ) pronoun reminds the audience of the existence of a person in an exclusive narrated situation ( plur '' ' ) and says that this referent is nothing new in the speech situation -it is not a person mentioned for the first time .</sentence>
				<definiendum id="0">reflexive ( personal ) pronoun</definiendum>
				<definiens id="0">reminds the audience of the existence of a person in an exclusive narrated situation ( plur '' '</definiens>
			</definition>
</paper>

		<paper id="1081">
			<definition id="0">
				<sentence>The metaphor consists of the source , target and the set of associations linking them .</sentence>
				<definiendum id="0">metaphor</definiendum>
			</definition>
			<definition id="1">
				<sentence>KODIAK is an extended semantic net language in the spirit of KL-ONE ( Braehman 1985 ) .</sentence>
				<definiendum id="0">KODIAK</definiendum>
			</definition>
			<definition id="2">
				<sentence>A metaphor-map is a kind of VIEW relation whose aspectuals specify con'esponding source and target concepts .</sentence>
				<definiendum id="0">metaphor-map</definiendum>
				<definiens id="0">a kind of VIEW relation whose aspectuals specify con'esponding source and target concepts</definiens>
			</definition>
			<definition id="3">
				<sentence>A VIEW is a primitive KODIAK relation that permits a limited inheritance between concepts without requiring a strict ISA relationship .</sentence>
				<definiendum id="0">VIEW</definiendum>
				<definiens id="0">a primitive KODIAK relation that permits a limited inheritance between concepts without requiring a strict ISA relationship</definiens>
			</definition>
			<definition id="4">
				<sentence>A component-map relation is a kind of component-association relation that holds between a metaphor-sense and a metaphormap .</sentence>
				<definiendum id="0">component-map relation</definiendum>
				<definiens id="0">a kind of component-association relation that holds between a metaphor-sense and a metaphormap</definiens>
			</definition>
			<definition id="5">
				<sentence>The act-upon-as-transfer map is a map representing a general metaphor that allows abstract events with participants to be viewed as transfer-events where some participant receives or donates some metaphorical object .</sentence>
				<definiendum id="0">act-upon-as-transfer map</definiendum>
				<definiens id="0">a map representing a general metaphor that allows abstract events with participants to be viewed as transfer-events where some participant receives or donates some metaphorical object</definiens>
			</definition>
</paper>

		<paper id="1069">
			<definition id="0">
				<sentence>~l~is reduction is a generalization of harmony processes which are common in certain families of natur ' , d languages .</sentence>
				<definiendum id="0">~l~is reduction</definiendum>
				<definiens id="0">a generalization of harmony processes</definiens>
			</definition>
			<definition id="1">
				<sentence>In these languages , stem ( mad affix ) vowels must agree ill one or more of the following distinctive features : o Front/back vowels ( palatal , velar harmony ) , eg .</sentence>
				<definiendum id="0">o Front/back vowels</definiendum>
				<definiens id="0">palatal , velar harmony ) , eg</definiens>
			</definition>
			<definition id="2">
				<sentence>o Rounded/tmrounded vowels ( labial harmony ) , eg .</sentence>
				<definiendum id="0">Rounded/tmrounded vowels</definiendum>
				<definiens id="0">labial harmony ) , eg</definiens>
			</definition>
			<definition id="3">
				<sentence>Karttunen , L. , Koskenniemi , K. , and Kaplan , R. , 1987 , `` A Compiler for Two-level Phonological Rules , '' in Dalrymple , M. , Kaplan , R. , Karttunen , L. , Koskenniemi , K. , Shaio , S. , and Wescoat , M. , `` Tools for Morphological Analysis , '' Report No .</sentence>
				<definiendum id="0">Wescoat</definiendum>
				<definiens id="0">Two-level Phonological Rules , '' in Dalrymple , M. , Kaplan , R. , Karttunen , L. , Koskenniemi , K. , Shaio , S. , and</definiens>
			</definition>
			<definition id="4">
				<sentence>Koskenniemi , K. , 1983 , `` Two-Level Morphology : A General Computational Model for Word-Form Recognition and Production , '' Publications No. 11 , University of Helsinki , Dept of General Linguistics , Hallituskatu 11-33 , SF00100 Helsinki 10 , Finland .</sentence>
				<definiendum id="0">Two-Level Morphology</definiendum>
				<definiens id="0">A General Computational Model for Word-Form Recognition</definiens>
			</definition>
</paper>

		<paper id="2088">
			<definition id="0">
				<sentence>If the t ) oint of the paraphrase is to clarify the original texi , its in a natural language ( NL ) interface to a database ( DB ) or cx~rt system application , then disambiguating the que W and choosing more precise lcxical items ( perhaps closer to the structure of the actual Dt3 , expert system , o1 ' other underlying application ) are essential strategies .</sentence>
				<definiendum id="0">oint of the paraphrase</definiendum>
				<definiens id="0">a natural language ( NL ) interface to a database ( DB ) or cx~rt system application , then disambiguating the que W and choosing more precise lcxical items</definiens>
			</definition>
			<definition id="1">
				<sentence>IRUS-II ( TM ) IRUS-Iltm ( Weischedel , et al. 1987 ) is a robnst NL understanding system that interfaces to a variety of underlying systems , such as DB management systems , expert systems and other application programs .</sentence>
				<definiendum id="0">IRUS-II ( TM ) IRUS-Iltm ( Weischedel</definiendum>
				<definiens id="0">a robnst NL understanding system that interfaces to a variety of underlying systems</definiens>
			</definition>
			<definition id="2">
				<sentence>These modules simultaneously parse an English text into a syntactic structural description and construct a formal semantic representation of its meaning in a higher order intensional logic language called the World Model Language ( WML ) .</sentence>
				<definiendum id="0">World Model Language ( WML</definiendum>
				<definiens id="0">an English text into a syntactic structural description and construct a formal semantic representation of its meaning in a higher order intensional logic language called the</definiens>
			</definition>
			<definition id="3">
				<sentence>The stntcture is populated with model level objects ( i.e. ti'om the applications program ) and `` discourse objects '' ( compositional objects created for 1the particulac utterance ) and the ~elations between these objects .</sentence>
				<definiendum id="0">model level objects</definiendum>
				<definiens id="0">the applications program ) and `` discourse objects '' ( compositional objects created for 1the particulac utterance</definiens>
			</definition>
			<definition id="4">
				<sentence>At each node , the mapping process chooses the linguistic resource ( lexical item , syntactic relation such as restrictive modifim , etc. ) that is to realize the object which is the content of that node .</sentence>
				<definiendum id="0">linguistic resource</definiendum>
				<definiens id="0">to realize the object which is the content of that node</definiens>
			</definition>
			<definition id="5">
				<sentence>MUMBLE-86 handles the realization of the elements in the input specification ( e.g. choosing between the ships ate assigned , which are assigned , or assigned depending on whether the linguistic context requires a fldl clause , postmodifier , or premodifier ) , the positioning of elements in the text ( e.g. choosing where to place an adverbial phrase ) , and the necessary morphological operations ( e.g. subject-verb agreement ) .</sentence>
				<definiendum id="0">MUMBLE-86 handles the realization of the elements</definiendum>
				<definiens id="0">a fldl clause , postmodifier , or premodifier ) , the positioning of elements in the text ( e.g. choosing where to place an adverbial phrase )</definiens>
			</definition>
			<definition id="6">
				<sentence>The first operator in a WML represents the speech act of the utterance .</sentence>
				<definiendum id="0">WML</definiendum>
				<definiens id="0">the speech act of the utterance</definiens>
			</definition>
			<definition id="7">
				<sentence>While in some cases this direct translation of the WML produces an acceptable phrase , in other cases the results are less desirable .</sentence>
				<definiendum id="0">WML</definiendum>
				<definiens id="0">produces an acceptable phrase</definiens>
			</definition>
			<definition id="8">
				<sentence>Thus , the Parlance paraphrases incortyorate references to specific fields and values in the underlying data base system .</sentence>
				<definiendum id="0">Parlance</definiendum>
				<definiens id="0">paraphrases incortyorate references to specific fields and values in the underlying data base system</definiens>
			</definition>
</paper>

		<paper id="2128">
			<definition id="0">
				<sentence>A prediction item ( or , simply , a prediction ) is an item with identical start and end positions .</sentence>
				<definiendum id="0">prediction item</definiendum>
				<definiens id="0">an item with identical start and end positions</definiens>
			</definition>
			<definition id="1">
				<sentence>Dn 0 = mgu ( B~ , B ' ) \ [ j , B'O ~ DIO ' '' DuO , j\ ] where B~ is a aonterminal with a bounded subset of the information of B. This inference rule is the one actually used in the implemented system .</sentence>
				<definiendum id="0">B~</definiendum>
				<definiens id="0">a aonterminal with a bounded subset of the information of B. This inference rule is the one actually used in the implemented system</definiens>
			</definition>
			<definition id="2">
				<sentence>Perhaps the most immediate problem raised by the methodology for generation introduced in this paper is the strong requirement of semantic monotonicity , which serves as yet another instance of the straitjacket of compositionality , The semantic-monotonicity constraint allows the goal logical form to be systematically decomposed so that a. dynamic-programming generation process can be indexed by the parts of the decomposition ( the subformulas ) , just as the constraint of string concatenation in context-free grammars allows a goal sentence to be systematically decomposed so that a dynamic-programming parsing process can be indexed by the subparts of that decomposition ( the 14Such a proof is currently in preparation .</sentence>
				<definiendum id="0">semantic monotonicity</definiendum>
				<definiendum id="1">generation process</definiendum>
				<definiens id="0">the constraint of string concatenation in context-free grammars allows a goal sentence to be systematically decomposed so that a dynamic-programming parsing process can be indexed by the subparts of that decomposition</definiens>
			</definition>
			<definition id="3">
				<sentence>The central problem in either case , then~ is discovery of a logical language which exactly and uniquely represents all the meaning distinctions of natural language utterances and no others .</sentence>
				<definiendum id="0">then~</definiendum>
				<definiens id="0">discovery of a logical language which exactly and uniquely represents all the meaning distinctions of natural language utterances and no others</definiens>
			</definition>
			<definition id="4">
				<sentence>PHRED : a generator for natural language interfaces .</sentence>
				<definiendum id="0">PHRED</definiendum>
			</definition>
</paper>

		<paper id="2130">
			<definition id="0">
				<sentence>APT : A System to Direct and Control Natural Language Generation .</sentence>
				<definiendum id="0">APT</definiendum>
				<definiens id="0">A System to Direct and Control Natural Language Generation</definiens>
			</definition>
</paper>

		<paper id="1061">
</paper>

		<paper id="2087">
			<definition id="0">
				<sentence>A period P is a segment of time with a certain length , such as YEAR , MONTH , DAY , WEEK , HOUR , MINUTE , SECOlqD .</sentence>
				<definiendum id="0">period P</definiendum>
				<definiens id="0">a segment of time with a certain length , such as YEAR , MONTH , DAY , WEEK , HOUR , MINUTE , SECOlqD</definiens>
			</definition>
			<definition id="1">
				<sentence>A l ) eri~×l Pi is a subperiod of a pecind P iff 1 '' can be seen as consisting of a number of periods Pi that togeflmr exhaust I ' .</sentence>
				<definiendum id="0">Pi</definiendum>
				<definiens id="0">a subperiod of a pecind P iff 1 '' can be seen as consisting of a number of periods Pi that togeflmr exhaust I '</definiens>
			</definition>
			<definition id="2">
				<sentence>The expression nasta jul ( next Christmas ) is analogous to nasta torsdag .</sentence>
				<definiendum id="0">expression nasta jul</definiendum>
				<definiens id="0">analogous to nasta torsdag</definiens>
			</definition>
			<definition id="3">
				<sentence>Tht : first version of CI , OCKWISE consists of a parser , based on finite ~ ' ; tatc machinery , and a 'temporal expert ' that will make use of its knowledge about temporal phases and periods and infer temporal information that is missing explicitly in the expressicms .</sentence>
				<definiendum id="0">Tht</definiendum>
				<definiendum id="1">OCKWISE</definiendum>
				<definiens id="0">consists of a parser</definiens>
			</definition>
</paper>

		<paper id="1065">
			<definition id="0">
				<sentence>START rearranges the elements of the parse tree it constructs into embedded ternary expressions ( T-expressions ) by tying together the three most salient parameters of a sentence , the subject , the object , and the relation between them , &lt; subject relation object &gt; .</sentence>
				<definiendum id="0">START</definiendum>
				<definiens id="0">rearranges the elements of the parse tree it constructs into embedded ternary expressions ( T-expressions ) by tying together the three most salient parameters of a sentence , the subject , the object , and the relation between them , &lt; subject relation object &gt;</definiens>
			</definition>
			<definition id="1">
				<sentence>In both sentences , the gift is the transferred object , Paul is the recipient of this object , and Mary is the agent of the transfer~ despite different syntactic realizations of some of these arguments .</sentence>
				<definiendum id="0">Paul</definiendum>
				<definiendum id="1">Mary</definiendum>
				<definiens id="0">the transferred object ,</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , the Present S-rule used in the backward mode does not trigger when sentence ( 27 ) is read and T-expression ( 28 ) is produced by START .</sentence>
				<definiendum id="0">Present S-rule</definiendum>
				<definiens id="0">used in the backward mode does not trigger when sentence ( 27 ) is read and T-expression ( 28 ) is produced by START</definiens>
			</definition>
			<definition id="3">
				<sentence>The surprise example shows how the addition of information about semantic class membership to verb entries allows the system to handle a particular phenomenon ( or lexieal property ) common to all verbs in a particular class , with the help of a single S-rule .</sentence>
				<definiendum id="0">surprise example</definiendum>
				<definiens id="0">shows how the addition of information about semantic class membership to verb entries allows the system to handle a particular phenomenon</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , the children 's disappointment means that the children experienced disappointment ( passive interpretation ) , not that they caused disappointment ( active interpretation ) .</sentence>
				<definiendum id="0">disappointment</definiendum>
				<definiens id="0">the children experienced disappointment ( passive interpretation ) , not that they caused disappointment ( active interpretation )</definiens>
			</definition>
			<definition id="5">
				<sentence>lashing variable , Z constants , or predicates ) , and then builds trod general\zes the S -- rule automatically .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiens id="0">constants , or predicates</definiens>
			</definition>
</paper>

		<paper id="2131">
			<definition id="0">
				<sentence>From ERS to IS , our FOCUS feature and its value would simply be carried over , which is a natural consequence of the fact that information about focus and presupposition is semantic information based on information from the constituent structure level .</sentence>
				<definiendum id="0">presupposition</definiendum>
				<definiens id="0">semantic information based on information from the constituent structure level</definiens>
			</definition>
			<definition id="1">
				<sentence>London : Frances Pinter Winograd .</sentence>
				<definiendum id="0">London</definiendum>
				<definiens id="0">Frances Pinter Winograd</definiens>
			</definition>
</paper>

		<paper id="1083">
			<definition id="0">
				<sentence>Then AG1 AG/G 2 /~2~ AG1 =dr ~ f , g , pf~ t.e. is the formulao which results by substitution of ~ for G~g , \ ] AG2 A G { G 2 /~2 t =df i f , glW9~* ( b ) Let K R be e functor or e FV of e wellformed part of A Gl ( AG2 ) , end let this wsll=~ : ormed pert be more complex than a formule of the form G 2 With re4~6Plqt ° spect to all well-formed parts of A GI ( A G2 ) I generate the formulae A GEl and A GE2 by substitution of the functor indicated by the flret component of the mainFV of the first argument of K 2 for this mstn-FV , and by substitution of the functot Indicated by the second component of the matn-FV of the second argument of K 2 for thla matn-FV .</sentence>
				<definiendum id="0">GI</definiendum>
				<definiens id="0">the formulao which results by substitution of ~ for G~g , \ ] AG2 A G { G 2 /~2 t =df i f , glW9~* ( b ) Let K R be e functor or e FV of e wellformed part of A Gl</definiens>
				<definiens id="1">A G2 ) I generate the formulae A GEl and A GE2 by substitution of the functor indicated by the flret</definiens>
			</definition>
</paper>

		<paper id="1038">
			<definition id="0">
				<sentence>Decision making in connectionist models such as these is distributed anti consists in selections made from sets of mutually inhibiting candidate items which are activated on the basis of input features .</sentence>
				<definiendum id="0">Decision</definiendum>
				<definiens id="0">consists in selections made from sets of mutually inhibiting candidate items which are activated on the basis of input features</definiens>
			</definition>
			<definition id="1">
				<sentence>A generalized utterance ( GU ) is a schema ( implemented as a network fragment ) associating a morphosyntactic pattern with a semantic content and possibly contextual factors .</sentence>
				<definiendum id="0">generalized utterance ( GU )</definiendum>
				<definiens id="0">a schema ( implemented as a network fragment ) associating a morphosyntactic pattern with a semantic content and possibly contextual factors</definiens>
			</definition>
			<definition id="2">
				<sentence>Tile figalre includes some sequence connections and the WTA network which represents the competition between the OBJEC % REFERENCE and RECIPIENT-REFERENCE constituents for the position following the VERB .</sentence>
				<definiendum id="0">WTA network</definiendum>
				<definiens id="0">represents the competition between the OBJEC % REFERENCE and RECIPIENT-REFERENCE constituents for the position following the VERB</definiens>
			</definition>
			<definition id="3">
				<sentence>Since humanness is a default property of the RECIPIF , NT of an ABS'IRACI'-TRANSFER , Ibis last node is connected to the RECIPIENT node , which can now fin. , sending activation ill turn eventually to tilt RECIPIENT-REFERENCE/start node in the *SEND schema .</sentence>
				<definiendum id="0">NT</definiendum>
				<definiens id="0">can now fin. , sending activation ill turn eventually to tilt RECIPIENT-REFERENCE/start node in the *SEND schema</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>an , let us associate the set of interva\ ] s i j , O~i~j~n. w ( i j } denotes the substring ai ... a3 of w if i &lt; o , 6 otherwise. The root , or equtva\ ] ently the M\ ] o\ ] e tree , corresponds to w = wl0n ) . Each \ ] ear corresponds to some substring w ( i j ) , of length 0 or 1 ( we may extend this to any lengtm if terminals are allowed to be themselves Strings Then , the correspondence is such that any internal node of the tree , or equivalently each tree `` complete '' m breadth and depth , COrrespondS tO w ( i.j ) , iff its m daughters ( or ' its m immediate subtrees ) , in order ' , correspond to a sequence w { iL_jl ) , ... , w ( im gm\ ] , such that i1=i , jm=j , and jk=ik*l for O &lt; k &lt; m. This type of correspondence is `` prooectwe '' It has however Peer\ ] argued that classical phrase structure trees are maaequate for '' charaoterising syntactic representations in genera\ ] , especially in the ease of so-oat\ ] ed `` discontinuous '' constttuents. Here are some examples. ( 1 ) John Z lkiL_\ [ k~C~ , of course , ~j~. ( 2 ) He ~ the ball £/ { Q. ( 3 ) Je ~ le lui al ~ donn @ . ( I did not give it to him ) According tO ( McOawley 82 ) , sentence ( 1 ) contains a verb phrase `` talked about politics '' , wlnich is divided by the adverbial phrase `` of course '' , which modifies the # ~ole sentence , end not only the verbal kernel ( or the verbal phrase , in ChomsKy 's terminology ) . Sentence ( 2 ) contains the particle `` up '' , whtoh ls separated from its verb `` picKed '' by `` the ball '' , In sentence ( 3 ) , the discontinuous negation `` ne.. , pas '' overlaps with the composed form of the verb `` ai ... donn~ '' . Moreover , i { a sentence in active voice ls to be represented in a standard order ( subject verb object complement ) , this sentence contains two displaced elements , namely the object `` le '' and the complement `` lui '' . ( McCawley 82 ) and later ( Bunt &amp; al 87 } have argued that `` meaningful '' representations of sentences ( 2 ) and ( 3 ) should be the following phrase structure trees , ( 4 ) and ( 5 ) , respectively. 59 + ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... . + S ( 4 ) S ( 5 ) ! ! ! I I ! ! ! ! VP ! ! ~ ! ! ! I I ! ! ! ! ! V I __ ! ! NP ! VP ! ) NP ! ! I I ~1 I ; I I I I ! ! ! ! ! ! ! ! ! I ! ! ! V ADVP PP He picked the bali upl ! ! ! ! ~ I ! ! ! ! ! ! ! ! ! John talked of course about politics I ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... . ÷ Figure l : Examples of discontinuous phrase structure trees Along the same line , and taking into consideration the displaced elements , a `` meaningful '' representation for sentence ( 3 ) would be tree ( 6 ) . + ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. S ( 6 ) NP ! VP i ! ! ! ! I V NP NP ! ! ! ! ! I ! ! ! ! ! ! NEG ! ! ! ! ! ~ ! ! ! ! ! de ne le lui ai pas donne ÷ ... ... . ~ ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. Figure 2 : Example of discontinuity and displacement here , the correspondence is establ iehed between a node ( or equivalently the complete suDtree rooted at a node ) and a sequence of intervals. If a displacement arises , ee in ( 3 ) , the left-to-right order of nodes in the tree may be incompatible with the order of the corresponding sequences of intervals in the strtng ( the considered ordering is the natural lexioographic extension ) . Rather than to introduce the awkward notion of `` discontinuous '' tree , as above , with intersecting branches , we suggest to keep the tree diagrams in thelr usual form and to show the string separately. For sentence ( 3 ) , then , we get the following diagram. . ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... . ! S ( '/ ) q ! ! ! I ! NP NEG __.VP _ ! ! ! ! ! ! I ! Je ne pas V NP NP ! : : : ! ! ! I ! . : : : ... ... ... ... ... ... ai ... ... .. donne le lul ! : : : : : : ' , ! : : ... ... ... ... ... ... .. : ... ... .. : ... ... ... ... ... . : ... ... ... ... ... . : : ! : : : ... ... ... . : ... ... .. : ... ... ... ... ... . : ... ... ... ... ... ... ... ... ... . : \ ] , : ' : : : : ! de ne le lui ai bae donn6 + ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... . Figure 3 : Separation of a string and its `` dlsoontlnou8 '' PS tree NOw , as before , the root of the tree still corresponds to w=w ( 0_n\ ] , and a leaf corresponds to an interval of length O or 1 ( or more , see above ) . But an internal node with m daughters corresponds to a sequence of intervals , ~hich ' is the `` union '' of the m sequences corresponding to Its daughters. More precisely , a `` sequence '' of Intervals is a llst of the form S = w { il_jl ) ... .. wlip_jp } , in order ( Ik &lt; Ik+1 for O &lt; K &lt; p ) and without overlapping ( jk &lt; ik+1 for O &lt; k &lt; p ) . Its union ( denoted by `` + '' ) with an interval I = w ( i j } is the smallest list containing all elements of S and of I. For example , S+I is : S itself , if there is a k such that ik &lt; t and j_ &lt; jk ; S , augmented with wii J } inserted in the proper place , if j &lt; il or jp &lt; i or there is a k &lt; p such that Jk &lt; i and j &lt; i K* 1 ; 60 w { ll_jl } ... .. w { tq_jq } .w { i_Jr } ... .. w ( lp_jp } , if there are q and r such that Jq &lt; t~lq+l and tr~j~jr ( other cases are analogous ) , In classical dependency trees , elements of the represented string appear on the nodes of the tree , with no auxiliary symbols , except a `` dummy node '' , often indicated by `` = '' , which serves to separate the left daughters from the right daughters. There are two aspects in the correspondence. First , a node corresponds to an element of the string , usually an interval of length 1. Second , the complete subtree rooted at a node corresponds to the tnterval union of the intervals corresponding tO the node and to Its subtree. These intervals may not overlap. The string can be produced from the tree by an tnorder traversal ( one starts from the root , and , at any node , one traverses ftrst the trees rooted at the left daughters , then the node , then the trees rooted at the right daughters , reeursively ) . Sentences ( 1 ) and ( 2 ) might be represented by trees ( 8 ) and ( 9 ) below. + ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ÷ ! talked ( 8 ) picked ( 9 ) ! ! ! I ! ! t ! ~ ! ! ! ! ! I ! John ' of__ about He = _ball up ! ISUBJ : ADVS I OBJ1 ! SUBJ : l OBJ1PTC ! : : ! ! ! ! : : ! ! : ! : : = course = politics : : the `` : ! : : : : : ... . : ; : DES : : t ; : : : : : . . : . : ! : : : : : : Hi picked the bail up ' • , , : , , ! IJohn taiKed of course about polltics ! ÷ ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ÷ Figure 4 : Examples of classical dependency trees \ ] n those trees , the discontinuities shov ; n tn the PS trees ( 4 ) and ( 5 ) have disappeared. We have shown on some nodes the syntactic functions usually attached to the edges. There may be some discussion on the structures produced. For example , some linguists would rather '' see `` politics '' dominating `` about '' . This tS not our '' tOpiC here , but we wtll use this other possibility in a later diagram. For the moment , note that discontinuity does not always disappear in dependency trees. Here is an example corresponding to sentence ( 3 ) . + ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. I aonn6 ( 10 ) I ! ! ! ! ! I I ! I de ne le Jut at = ISUBJ NEG OBJ1 OBJ2 AUX : : ! ! : : : : = pa8 : : : : : NEG2. , .. : ... ... ... . : ... ... ... . : ... ... ... . : : : : : : ; : • : , , : : . j ; ne le 1 ; t at pas d &amp; n6 Figure 5 : Example of a `` dtsoonttnous '' dependency tree Let us now take a simple example from the area of programming languages , ~¢nioh $ he~ an abstract tree associated to an assignment , ~here some elements of the string are `` missing '' in the tree , and where a node oorreeponds to a `` discontinuous '' substring ( a sequence of intervals ) . ÷ ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... . ! if then_else ( 01+2_3+6_7 ) ( 11 ) ! i ! ! ! ! ! ok = : ( 4 5 ) = : ( 8_9 ) ! 12 _ ! i f ! ! ! ! ! a x `` ( 10 11 ) x ! 56 34 ! ? _8 ! a + ( 13_14 ) ! 910 ! ! ! ! ! b 0 ! 12_13 1415 ! ! if ok then x : = a else x : = a ~ ( b + e ) ! ! 01_23456 '' /_89_10 1_12_13_14_15_16 ÷ ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... Figure 6 : Example of `` abstract '' tree for a formal language expression Here , we have shown the correspondence between nodes and sequences. The parentheses are mlsstng in the tree , wtqich means that the sequence corresponding to the subtree rooted at node `` + '' is more than the union of the sequences oorrespondfng to its subtrees. However , there is no overlapping between sequences corresponding to independent nodes or suPtrees. Anoeher remark is that the elements appearing on the nodes are not always identical with elements of the represented string. FOr example , we have replaced `` : = '' by `` =. `` ~nd the ( discontinuous ) substring `` if then else '' by `` if thE.m else '' , in a usual fashion. In `` predicate-argument structures '' , it is usual to construct a unique node for a compound predicate , in the same ~ ; pirit as the `` if_then_else '' operator above , With sentences ( 1 ) and ( 2 ) , for example , we could get trees ( 12 ) and ( 13 ) below. Beside the logical relation ( argument place ) or the semantic relation , the nodes must also contain some other information , like tense , person , etc , , ~hich is not sho~n here. ! __~ ! I I ! ! ! ! I I ! John of course politics He ___ball I ! ARGO ESTII~ __ ARG1 ARGO ! ARe1 I ! 0 1 2 4 \ [ 5_6 0 1 the 3 4 I ! about 2_3 I TOPIC ! ! 4_5 He picked the ball up I ! 01 2345 I t I ! John talked of course about poltttcs I ! 0 I 23 4 .5__6 I ÷ ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. ÷ Figure ? ; Examples of predteate-argumont trees We now come to Situations where overlapping occurs , and ~r } re It ts natural to consider `` tnooaplete '' subtree8 corresl ) ondtng to `` dlsco~ttnous '' groups. Thhl occurs frequently in eases of coordination with elision , as tn : `` John and Mary give Paul and Ann trousers and Cresses. '' In order to simplify the trees , ~ abstract this by the f { ) rma\ ] language { an v bn on t n &gt; O } , and propose the two i : rees ( 14 ) and ( 15 ) below for the string `` a a v b b c c '' ( also written a. 1 a.2 v b. 1 b.2 e.l c.2 to sl~L } w the positions ) as more `` natural '' representations than i : he syntactic tree derived from a context-sensitive grammar in normal form for this language ( all rules are of the form `` 1A r -- ~ 1 u r '' , 1 and r being the left and right ~ : ontext , respectively ) .</sentence>
				<definiendum id="0">, w</definiendum>
				<definiendum id="1">S+I</definiendum>
				<definiens id="0">if terminals are allowed to be themselves Strings Then , the correspondence is such that any internal node of the tree , or equivalently each tree `` complete '' m breadth and depth , COrrespondS tO w ( i.j ) , iff its m daughters ( or ' its m immediate subtrees ) , in order ' , correspond to a sequence w { iL_jl ) , ...</definiens>
				<definiens id="1">contains a verb phrase `` talked about politics '' , wlnich is divided by the adverbial phrase `` of course '' , which modifies the # ~ole sentence , end not only the verbal kernel ( or the verbal phrase , in ChomsKy 's terminology )</definiens>
				<definiens id="2">a sentence in active voice ls to be represented in a standard order ( subject verb object complement ) , this sentence contains two displaced elements</definiens>
				<definiens id="3">Examples of discontinuous phrase structure trees Along the same line , and taking into consideration the displaced elements</definiens>
				<definiens id="4">the correspondence is establ iehed between a node ( or equivalently the complete suDtree rooted at a node ) and a sequence of intervals. If a displacement arises , ee in</definiens>
				<definiens id="5">a llst of the form S = w { il_jl ) ... .. wlip_jp } , in order ( Ik &lt; Ik+1 for O &lt; K &lt; p ) and without overlapping ( jk &lt; ik+1 for O &lt; k &lt; p ) . Its union ( denoted by `` + ''</definiens>
				<definiens id="6">the smallest list containing all elements of S and of I. For example ,</definiens>
				<definiens id="7">a k such that ik &lt; t and j_ &lt; jk ; S , augmented with wii J } inserted in the proper place</definiens>
				<definiens id="8">other cases are analogous ) , In classical dependency trees , elements of the represented string appear on the nodes of the tree , with no auxiliary symbols , except a `` dummy node '' , often indicated by `` = '' , which serves to separate the left daughters from the right daughters. There are two aspects in the correspondence. First , a node corresponds to an element of the string , usually an interval of length 1. Second , the complete subtree rooted at a node corresponds to the tnterval union of the intervals corresponding tO the node and to Its subtree. These intervals may not overlap. The string can be produced from the tree by an tnorder traversal ( one starts from the root , and , at any node , one traverses ftrst the trees rooted at the left daughters , then the node , then the trees rooted at the right daughters</definiens>
				<definiens id="9">Examples of classical dependency trees \ ] n those trees , the discontinuities shov ; n tn the PS trees ( 4 ) and ( 5 ) have disappeared. We have shown on some nodes the syntactic functions usually attached to the edges. There may be some discussion on the structures produced. For example</definiens>
				<definiens id="10">an example corresponding to sentence ( 3 ) . +</definiens>
				<definiens id="11">parentheses are mlsstng in the tree , wtqich means that the sequence corresponding to the subtree rooted at node `` + '' is more than the union of the sequences oorrespondfng to its subtrees. However , there is no overlapping between sequences corresponding to independent nodes or suPtrees. Anoeher remark is that the elements appearing on the nodes are not always identical with elements of the represented string. FOr example</definiens>
				<definiens id="12">usual to construct a unique node for a compound predicate , in the same ~</definiens>
				<definiens id="13">the logical relation ( argument place ) or the semantic relation , the nodes must also contain some other information</definiens>
				<definiens id="14">predteate-argumont trees We now come to Situations where overlapping occurs , and ~r } re It ts natural to consider `` tnooaplete '' subtree8 corresl ) ondtng to `` dlsco~ttnous '' groups. Thhl occurs frequently in eases of coordination with elision , as tn : `` John and Mary give Paul and Ann trousers and Cresses. '' In order to simplify the trees , ~ abstract this by the f { ) rma\ ] language { an v bn on t n &gt; O }</definiens>
				<definiens id="15">a a v b b c c '' ( also written a. 1 a.2 v b. 1 b.2 e.l c.2 to sl~L } w the positions ) as more `` natural '' representations than i : he syntactic tree derived from a context-sensitive grammar in normal form for this language ( all rules are of the form</definiens>
			</definition>
			<definition id="1">
				<sentence>A SSTC iS ~ if STREE ( NI ) and STREE ( N2 ) have an empty intersection If N1 and N2 are independent ; SNODE ( N1 ) and STREE ( N2 ) have an empty intersection if N2 is a daughter of NI .</sentence>
				<definiendum id="0">SSTC iS</definiendum>
				<definiendum id="1">STREE</definiendum>
				<definiens id="0">an empty intersection If N1 and N2 are independent</definiens>
			</definition>
			<definition id="2">
				<sentence>The axioms are all pairs ( X , Y ( $ F ) ) , where X is an unbounded string variable , Y a starting node ( standing for SENTENCE , or TITLE , for example ) , and SF is an unbounded forest variable .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">TITLE</definiendum>
				<definiendum id="2">SF</definiendum>
				<definiens id="0">an unbounded forest variable</definiens>
			</definition>
</paper>

		<paper id="1051">
			<definition id="0">
				<sentence>\ [ R ( ml\ ] ( EXIST ) ( m parameter ) The strip-rules state the following : a sentence uttered by the speaker , N , where N is O or P ( column 1 ) , can be criticised by the other party ( N* ) as defined in cohu-nn 2 .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">a sentence uttered by the speaker</definiens>
			</definition>
			<definition id="1">
				<sentence>parties ( B and W ) changing roles ( tile boxed-in part of file tableau ) .</sentence>
				<definiendum id="0">parties</definiendum>
				<definiens id="0">tile boxed-in part of file tableau )</definiens>
			</definition>
			<definition id="2">
				<sentence>It is possible to give a simple translation for p &gt; &gt; q in terms of F and -~ where the formula on the opponent side is F~q -- ~ ( p q ) .</sentence>
				<definiendum id="0">opponent side</definiendum>
				<definiens id="0">a simple translation for p &gt; &gt; q in terms of F and -~ where the formula on the</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>I I Generator I ,1 t i i -Figure 1 : The LFG-System in Koblenz Design The Koblenzer LFG-Parser-Generator is an interactive system , designed to create and to test grammars for natural languages according to the linguistic philosophy of the LFG as conceived in Bresnan und Kaplan ( 1982 ) .</sentence>
				<definiendum id="0">Koblenzer LFG-Parser-Generator</definiendum>
				<definiens id="0">an interactive system , designed to create and to test grammars for natural languages according to the linguistic philosophy of the LFG as conceived in Bresnan und Kaplan ( 1982 )</definiens>
			</definition>
</paper>

		<paper id="2086">
			<definition id="0">
				<sentence>Being implied by a natural language sentence and the natural ( or preferred ) interpretation of its simple negation is the primary quality that qualifies an inference as a presupposition .</sentence>
				<definiendum id="0">negation</definiendum>
				<definiens id="0">a natural language sentence and the natural ( or preferred ) interpretation of its simple</definiens>
			</definition>
			<definition id="1">
				<sentence>quppoMtions rising Default R.ulos A no , 'mal default ~*ule is a rule of inference denoted fl ( Y ) where a ( Y ) mM fl ( x ' ) are a.1\ ] first order formulae whose fl'ee variables are among those of .</sentence>
				<definiendum id="0">Y ) mM fl</definiendum>
				<definiens id="0">a.1\ ] first order formulae whose fl'ee variables are among those of</definiens>
			</definition>
			<definition id="2">
				<sentence>The meaning of the utterance is then a function of the inierencing process on I~Bl-1 U { I &lt; su } . The default rules require some extra informa* : ion to guard against misuse of the default rules. This information is a conjunct in the prerequisite of the default rule. Except for this technical aspect this extra intbrmation plays no role. Since it creates long default rules , i have tell it out of all the examples. For further details see/Mercer /.987/. Whenever the discussion concerns the default logic approach , I will assnme that the speaker 's utterance has undergone the first phase of the interpretation process which generates a semantic representation ( logical form ) of the sentence uttered. This , ; entantic representation The verb believe sholdd be t~kea to lm ? &amp; lt first order dctiw~ble or conjectured from the default theory. will be a well-formed sentence in a first order $ 4 modal language containing a countably intinite set of predicate syntbols , constant symbols , and variable symbols , plus the logical symbols A , V , D , - , Ks , ~nd Ps. The last two symbols , called modal operators , are to be interpreted as 'the speaker knows that ' and 'for all the speaker knows , it is possible that ' , respectively. Although there is no general method known to generate this representation , some generM rules ( : an be followed. Any sentence with an explicit negation is translated into the widely seeped negation of its affirmative counterpart. Any compound sentence is mapped clause by clause into a logical form , each clause being treated as a sentence. Complex Sentences The concept discussed herein -using default logic to derive presuppositions -is strongly influenced by Gazdar 's method. I will present the representation of presuppositions in following sections with little explanation. For a complete discussion of how presul ) postions are represented by default rules in a default theory together with how default logic proof theory captures Gazdar 's idea of presuppositions being consistent with a context see/Mercer and Reiter 1982/or /Mercer 1987/. Another influence is the use of clausal implicatnres in connection with deriving presuppositions fl'om complex sentences , tu the default logic approach the clausal implicatures are used to control the division of the original theory into its first order cases. The clausal implicatures are derived fi'om the natural language sentence according to Gaz , dar 's formal treatment of Grice 's converss tional principles ( /Griee 1975/ ) . The sentence uttered by a speaker commits the speaker not only to the truth of the sentelme but also to the possibility of its clauses ( its parts ) . So in tlm case of the speaker uttering 'A or B ' or 'if A then B ' , unless tlmre is background knowledge or there are linguistic reasons to prevent it , the speaker b ; committed to PsA , Ps- , A , PsB , aud Ps , '~B. These implicatures will provide the means to restrict the division of the theory representing the utterance into its cases. Becmtse default logic proof theory does ) tot display any analogue to the law of the excluded middle ( the antecedents of tim default : rules nrust be provable and there is no equivalent to the deduction theorem ) and because presuppositions do arise from the clauses of complex sentences , some form of analysis by eases is required. Since a statement is provable in a case anMysis only if it is provable in all cases , the choice of cases is critical. As in the case of a tirst order theory , too few cases would allow inappropriate statenmuts to Ire proved. In addition because of the non-monotonic nature of default logic , having too many casts could prevent al ) propriate statements being proved. In general the choice of cases must reflect two principles. Since the case analysis is a proof theoretic analogue of the model theoretic law of the excluded middle , each ease must completely determine the truth values of each of the disjunets found in the statement to which case analysis is being applied. Also , since the case analysis is justified solely on linguistic grounds ( see /Mercer 1987/ for further discussion ) , the cases must reflect this linguistic situation. 3'o justify a. case , the possibility of the statement that distinguishes the case must 1re provable t¥om the original default theory. Since none of the modM statements take part in the proofs , they are left out of the cases. An example should clarify these ideas. Example Suppose the sentence 'A or B ' is uttered. '\ ] ? he default theory repre.senting this utterance would be T = { Ks ( A V B ) , PsA , Ps- , A , PsB , Ps- , B , al , • • • , cx , ~ , 61 , .. , , ~/~ } 421 where ax , ... , a , represent the appropriate first order statements and $ 1 , . •. , ~n represent the appropriate default rules. Since A A-~B and -~A A B completely determine ( that is , determine the truth values of both ) A and B , and since the statements Ps ( A ^ -~B ) and Ps ( '~A A B ) can be derived , A ^ -~B and -~A ^ B distinguish the two cases. Note that although PsA , Ps'~A , PsB , Ps'~B are all derivable , none of A , -~A , B , -~B are candidates for distinguishing a case because , individually , none of them completely determine the truth values of both A and B. Ilence the two cases of the original theory , T , are Tc~s~x = { A A `` nB , al ... .. an , 61 ... .. 6n } Tease '' , = { ~A ^ B , al , ... , an , ~'1 , • .. , ~ ' , ~ } The simple negated sentence , an example of which is presented in section 2.3.1 , is just a special instance of the case analysis procedure. In the simple negated sentence , -~X ( which is represented as Ks-~X ) , the possibility of the only case ( distinguished by -~X ) can be proved using the utterance and the theorem ~Ks~X FPs-~X. Presuppositions Definition 1 A sentence ex is a presupposition of an utterance u , represented by the default theories Auc~.~t ... .. Aua ... . 2 , if and only /f A , c~ , ~-A a for all i and a e Th ( CONSEQUENTS { D } ) , but Au ~/ o~ and Au \ [ /A . , ~3. This definition can be loosely paraphrased as : ifa is in the logical closure of the default consequents and is provable from the utterance , and all proofs require the invocation of a default rule and in the case of multiple extension default theories , a is in all extensions , then a is a presupposition of the utterance. The previous approaches which have been mentioned above rely on two ideas. Firstly , presuppositions are generated from positive and negative presuppositional environments , if these environments occur in the surface sentence. Secondly , a number of different methods , collectively called projection methods , are used to screen out those potential presuppositions which are not to be projected. A brief description of Soames ' method is given in section 4.1. The default logic theory described in detail in/Mercer 1987 , 1988/ approaches the problem of presupposition-generation from the level of logical representation. Presuppositions are generated from the logical representation if negated presuppositional environments occur in the logical representation of the natural language sentence or some logical form which can be derived from this representation. Malay of the results that the modified projection methods achieve are just proof theoretic results in the default logic approach to natural language ~For purposes of this definition , the only defaults in each Auco , o i a~e the presupposition generating defaults. In reality the default theory would contain many other kinds of defaults. The definition would have to be changed so that the proof of c~ , requires the invocation of a presupposition generating default , and that a E Th ( CONSEQUENTS { D ' } ) , where D ' is the set of presupposition generating defaults ~All of the examples presented in this paper deal with default theories having single extensions. In those theories which have multiple extensions , some way of stating that a presupposition is in all extensions is required. Since extensions of normal default theories are orthogonal , if An has multiple extensions then there exists a sentence fl such that Au I-A fl and Au V-a ~/ ? . I will call this situation being split along the fl-dimensiom If the extensions do not split along the ~-dimension then either ~ is in all extensions or a is in no extension. So if Au f-a ~ ( which means that at least one extension contains ~ ) and Au V/a ~a ( which means that no extension contains ~a , which means that the extensions do not split on the a-dimension ) then ~ is in all extensions. 422 presuppositions. In addition , once the logical representation of sentential adverbs is presented , it will be shown that the solution to the problem of presuppositions derived from sentential adverbs is again obtained in the default logic approach without any modifications. The two sentential adverbs that will be presented are those found in the examples given in/Soames 1982/ : 'too ' and 'again'. Becanse one of the defining properties of a presuppositional environment is indio caring positive to the negation test 4 , I will first look at each when there is a negation present. The interesting property displayed by sentential adverbs is that in addition to any interaction between negation and the underlying form , there is also an interaction between negation and the adverb. This interaction can be captured in two different logical representations. The sentential adverbs have the added complication that they can take any part of the sentence as their focus of the adverb. The focus of the adverb will be capitalized. Although the verb of the sentence can be focussed , a presentation of this particular focus would require an event-based representation. I do not discuss this focus in the following. However , it , too , would behave analogously. The representations of 'kick too ' are shown in ( 3 ) and ( 4 ) . These two representations convey the different foci of the adverb , 'too ' , the subject and the object of 'kick ' , respectively. I will be only interested in the representation which focuses on the subject , that is ( 3 ) . The explanation for presuppositions that arise from the adverb focussing on the object is similar to the discussion presented below. ( 3 ) ~/xVy.KICK-SUBJ-TOO ( x , y ) =KICK ( x , y ) ^ ~z.KfCK ( z , y ) A x # z ( 4 ) VxVy.KICK-OBJ-TOO ( x , y ) =KICE ( x , y ) ^ 3~.ICICK ( ~ , ~ ) ^ y # z Sentential adverbs have a most peculiar attribute when they interact with natural language negation. The adverb can be either inside or outside the scope of the negation. Sentences ( 5 ) and ( 6 ) point out the two possible interpretations in the case of 'too'. One particularly interesting phenomenon is that all of the possible scopes of the negation and the adverb may not occur in surface form. For instance , ( 6 ) would normally be uttered as 'BILL did n't kick the ball , either.'. I will use the incorrect surface form in the examples , however. The italicized portions of the sentences indicate the portion which is in the scope of 'too'. ( 5 ) is to be interpreted as : Although someone else kicked the ball , Bill didn't. ( 6 ) is to be interpreted as : Both Bill and someone else did not kick the ball. ( 5 ) BILL did n't kick the ball , too. ( 6 ) BILL did n't kick the ball , too. The representations for the unnegated 'BILL kicked the ball , too. ' and the sentences ( 5 ) and ( 6 ) are shown in ( 7 ) - ( 9 ) , respectively. As proposed in /Kempson 1975/ , /Wilson 1975/ , and implemented in /Mercer 1987/ , the representation of the simple negation of the sentence 'BILL kicked the ball , too. ' is just the wide-scoped negation as shown in ( 8 ) . I have shown the right-hand side equivalents of the appropriate representations so that I can contrast the two different uegatlons. ( 7 ) KICK ( Bill , ball ) A 3x.KICK ( x , ball ) A x ~ Bill 4A positive indication to the negation test means that a sentence , 8 , containing the purported presuppositionai environment and the preferred interpretation of not S both have the same inferences arising from the environment in question. ( 8 ) - , \ [ KICIt ( Bill , ball ) A -lx.KIClf ( x , ball ) A x ¢ Bill\ ] ( 9 ) -~KIG'l ( ( Bill , ball ) A Hx ... ~KICK ( x , ball ) A x ~ Bill What is important for tile presuppositional analysis is that only ( 8 ) can be a candidate for the negation test. One of the prerequisites of this test is that the supposed presuppositional environment is within the scope of the logical negation in the logical representation of the sentence. The logical representation of ( 9 ) does not meet this requirement. The situation for the sententia| adverb , 'again ' , is somewhat similar to that described above for 'too'. The adverb can be inside or outside the scope of the negation. Accordingty~ the adverbs found in ( 10 ) and ( 11 ) are the presupl ) ositional and non-presuppositional enviromnents with respect to the positive sentence 'Fred called again , '. ( 10 ) is to be interpreted as : At some time in the past Fred called and during some interwl of time which is important to the context in which the sentence is uttered , Fred did n't call. ( 11 ) is to be the following interpretation : At some time in the past Fred did n't call and during some interval of time which is important to the context in which tile sentence is u~tered , Fred did n't call. ( 10 ) I , 'RED did n't call again. ( 11 ) FRED di &amp; ~'t call again. Th.e representation for 'call , again ' is shown in ( 12 ) 5. ( 12 ) VxVyVz.CALL-HUBJ~A GAIN ( x , y , z ) =CALL ( x , y , z ) A 3tl. CALL ( x , y , tt ) A tl &lt; z The representations for the unuegated 'FRED called again. ' and the sentences ( 1 ( t ) and ( 11 ) are shown in ( 13 ) - ( 15 ) , respectively. As in the case of 'too ' , the representation of the simple negation of the sentence 'Fb~ED called again. ' is just the wide-scoped negation as shown in ( 1+1 ) . i have shown the right~hand side equiwdeuts of the appropriate representations so that I can contrast the two difihrent negations. ( 13 ) CALL ( Fred , you , t ) A :3tj .CALL ( 16~d , you , h ) A tl &lt; t ( 1.4 ) - , \ [ CAL t , ( 1 , Yed , you , t ) A i~tt. CAI , L ( Ft~d , you , 11 ) A t 1 &lt; t\ ] ( 15 ) - , CALL ( I ; Yed , you , t ) h ~tl.'- , CALL ( Fred , you , h ) A tl &lt; t As in the case for 'too ' , the only representation of 'again ' that sanctions the use of presuppositioual machinery is ( 14 ) s. tential Adverbs Now I ca~ turn to these sententiM adverbs occurring in more complex situations~ in particular , examples similar to those provided in /Soaanes 1982/. The two examples shown in ( 1.6 ) and ( 17 ) are the kinds of situations which prove difficult for all projection methods. ( 16 ) if JOHN kicked the ball , then BILL kicked the ball , too. ( 17 ) If Fred called yesterday , then he will call again , SThis representation conveys only oac foci of the adverb , 'again ' , in this c~e , the subject. The object of 'calP , which in this case weald have to be recovered from cow , textual cues ( it would pt'obably be 'yon ' or 'us ' , though it could bc a ihird party ) can be focussed as well. Since the discussion is similar to that given for ~too ~ , I will omit it. SThis is of coarse with cespect to the ~eutence represented by ( 13 ) . Tile method proposed in /Soames ( 1982 ) / is based upon the belief that the two major competing strategies for determining presuppositions ( /Karttunen and Peters 1979/and/Gazdar 1979/ ) succeed in those situations in which the other one fails. 7 Tile proposed solution is to synthesize the two filtering strategies so that all the unwanted potential presuppositions are screened out. The synthesis is performed in the following manner. First the potentialpresuppositionsofthe sentence are computed. Essentially , the potential presuppositions are all of tile presuppositions of the individual clauses of the sentence if the clauses were in isolation. The remaining potential presuppositions are those potential presuppositions which are not contextually or eonversationMly cancelled. This step is basically Gazdar~s method for generating the presuppositions of the sentence. The next step is to use these remaining potential presuppositions in the projection phase which is basically the one proposed by Karttunen and Peters. Since all of the examples that Mlow deal only with qf ... then ' sentences , I will provide only the projection rule for this kind of sentence. 8 If S : ='If A then B ' , then the actual presuppositions of S are those entailed by A P ^ ( Ar 79 B y ) where eP represents the actual presupposition of ¢. A further aspect of this rule is that if A T D B P is true only for truthconditional reasons or is a logically valid statement , then this part of the conjunct is ignored. Otherwise , the 'A T D ' is dropped giviug A P A B P as tlle presupposition of the sentence 5'. This projection method can be applied to a variety of examples. Since I am concerned only with the characteristics of the presuppositional environment 'too ' in these examples only those potential presuppositions that are relevant will be mentioned in the anMysis. ( 16 ) has the following properties. No potential presuppositions are derived from the antecedent clause. A T 79 B P = John kicked the ball D somebody ( ~ Bill ) kicked the ball Since A T D B p is logically valid it is ignored , tIence ( 16 ) has no actual presuppositions. Similar analyses give no presupposition for ( 18 ) and the pre , mpposi.tion 'Somebody ( ~ John ) kicked the ball. ' for ( 19 ) . ( 18 ) BILL kicked the ball , too , if JOIIN kicked the ball. ( 19 ) If JOIIN kicked the ball too , then BILL kicked the ball Ia order to generate no presuppositions for ( 20 ) , /So~mes 1979/ requires an extra rule and a somewhat suspect method of interpretation. A description of the extra rule is not needed here. tiowever , a quick look at the accompanying method of interpretation is of some importance. In order for the extra rule to work properly , the clause B in the sentence 'BifA ' must tirst be interpreted am an assertion. This error is undone when the 'if A ' portion is heard. But what is important is the appropriate presuppositions have been c ; mcelled by this point , tIowever , it seems that stress patterns on the llnal word of B when uttered as a sentence and when uttered as the lirst clause of 'BifA ' differ. Hence no hearer would interpret B as an assertion. Without this peculiar interpretation , Soames ' method can not correctly generate the presuppositions for ( 20 ) . ( 20 ) BILL ldcked the ball , if JOIIN kicked the ball ~oo. ~/Mercer 1987/ shows th~tt there are situations not covered ly the anion ot thcsc two methods. aThis rule is a slightly simplified version of the one given in/So , .mcs 1982/. It is sufficient for this discussion. 423 The default rule schemata which capture the presuppositionai inferences for the adverbs , 'too ' and 'again ' , are ( 21 ) and ( 22 ) , respectively. In the case of 'kick too ' and 'call again ' the appropriate instances of these schemata are shown in ( 23 ) and ( 24 ) , respectively. ( 21 ) `` ~\ [ ¢ ( x , y ) A3z.¢ ( z , y ) Ax # z\ ] :3Z.¢ ( z , y ) Ax # z 3z.¢ ( z , y ) A x # ( 22 ) J¢ ( x , y , t ) A 3t'.¢ ( x , y , t ' ) A t &lt; t'\ ] : 3t'.¢ ( x , y , t ' ) ^ t ! &lt; ~t ( 23 ) 3t'.¢ ( x , y , t ' ) A t t &lt; t -.KICK-SUBJTOO ( x.y ) : 3z.KICK ( z , y ) /~ x # z 3z.KICK ( z , y ) h x # z - , CALL-SUBJ-AGAIN ( x , y , t ) : 3t'.CALL ( x , y , t ' ) ^ t ' &lt; t ( 24 ) 3t'. CALL ( x , y , t ' ) A t ' &lt; t Given simple statements such as those in ( 25 ) and ( 26 ) the preferred interpretations can be derived from the representation of the sentence and the appropriate default rules. I have shown the representation for ( 25 ) in ( 27 ) . The preferred interpretation of ( 25 ) is shown in ( 28 ) . Similar representations can be derived for the preferred interpretation of ( 26 ) . ( 25 ) Bill did n't kick the ball , too. ( In the sense of ( 5 ) . ) ( 26 ) Fred did n't call again. ( In the sense of ( 10 ) . ) ( 27 ) - , KICK ( Bill , ball ) V Vz.-~KICK ( z , ball ) v Bill = z ( 28 ) - , KICK ( Bill , ball ) A 3z.KICK ( z , bail ) A Bill # z Each of the sentences ( 16 ) - ( 20 ) requires a case analysis. The representation of 'if a then b ' is not equivalent to a D b. However a D b can be derived fi'om standard representations for 'if a then b ' such as Stalnaker 's conditional logic representation , a &gt; b ( /Stalnaker 1968/ ) .</sentence>
				<definiendum id="0">meaning of the utterance</definiendum>
				<definiendum id="1">default rules</definiendum>
				<definiendum id="2">generM rules</definiendum>
				<definiendum id="3">^ -~B</definiendum>
				<definiendum id="4">sentence ex</definiendum>
				<definiendum id="5">3x.KICK</definiendum>
				<definiendum id="6">-lx.KIClf</definiendum>
				<definiendum id="7">Hx ... ~KICK</definiendum>
				<definiendum id="8">eP</definiendum>
				<definiens id="0">a function of the inierencing process on I~Bl-1 U { I &lt; su }</definiens>
				<definiens id="1">generates a semantic representation ( logical form ) of the sentence uttered. This</definiens>
				<definiens id="2">language containing a countably intinite set of predicate syntbols , constant symbols , and variable symbols , plus the logical symbols A , V , D , - , Ks , ~nd Ps. The last two symbols , called modal operators , are to be interpreted as 'the speaker knows that ' and 'for all the speaker knows</definiens>
				<definiens id="3">an be followed. Any sentence with an explicit negation is translated into the widely seeped negation of its affirmative counterpart. Any compound sentence is mapped clause by clause into a logical form</definiens>
				<definiens id="4">clausal implicatures are derived fi'om the natural language sentence according to Gaz , dar 's formal treatment of Grice 's converss tional principles ( /Griee 1975/ ) . The sentence uttered by a speaker commits the speaker not only to the truth of the sentelme but also to the possibility of its clauses ( its parts ) . So in tlm case of the speaker uttering 'A or B ' or 'if A then B '</definiens>
				<definiens id="5">A V B ) , PsA , Ps- , A , PsB , Ps- , B , al , • • • , cx , ~ , 61 , .. , , ~/~ } 421 where ax , ... , a</definiens>
				<definiens id="6">a number of different methods , collectively called projection methods</definiens>
				<definiens id="7">the logical representation if negated presuppositional environments occur in the logical representation of the natural language sentence or some logical form which can be derived from this representation. Malay of the results that the modified projection methods</definiens>
				<definiens id="8">requires the invocation of a presupposition generating default , and that a E Th ( CONSEQUENTS { D ' } )</definiens>
				<definiens id="9">means that no extension contains ~a , which means that the extensions do not split on the a-dimension</definiens>
				<definiens id="10">to be interpreted as : Although someone else kicked the ball , Bill didn't. ( 6 ) is to be interpreted as : Both Bill and someone else did not kick the ball. ( 5 ) BILL did n't kick the ball</definiens>
				<definiens id="11">the presupl ) ositional and non-presuppositional enviromnents with respect to the positive sentence 'Fred called again , '. ( 10 ) is to be interpreted as : At some time in the past Fred called and during some interwl of time which is important to the context in which the sentence is uttered</definiens>
				<definiens id="12">='If A then B ' , then the actual presuppositions of S are those entailed by A P ^ ( Ar 79 B y ) where</definiens>
				<definiens id="13">no actual presuppositions. Similar analyses give no presupposition for ( 18 ) and the pre , mpposi.tion 'Somebody ( ~ John ) kicked the ball. ' for ( 19 ) . ( 18 ) BILL kicked the ball , too , if JOIIN kicked the ball. ( 19 ) If JOIIN kicked the ball too , then BILL kicked the ball Ia order to generate no presuppositions for ( 20 )</definiens>
				<definiens id="14">stress patterns on the llnal word of B when uttered as a sentence and when uttered as the lirst clause of 'BifA ' differ. Hence no hearer would interpret B as an assertion. Without this peculiar interpretation</definiens>
			</definition>
</paper>

		<paper id="1045">
			<definition id="0">
				<sentence>, symbol N ( positive integers ) , indexes and are used here in the same way as in the formal grammar theory ; the symbol exp ( A ) denotes the set of all subsets of A , e denotes an empty string .</sentence>
				<definiendum id="0">symbol N</definiendum>
				<definiendum id="1">symbol exp ( A )</definiendum>
				<definiendum id="2">e</definiendum>
				<definiens id="0">an empty string</definiens>
			</definition>
			<definition id="1">
				<sentence>A pair ( w , i ) ~ D is called a dictionary entry , w is a lexical unit and i is called pattern number .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">a lexical unit and i is called pattern number</definiens>
			</definition>
			<definition id="2">
				<sentence>The quintuple ( A , V , K , t , R ) where t is a mapping t : V ~ &gt; exp ( A* ) assigni , ~g types to variables , R is a finite 'set of rules ( I , H , u , v , C ) , where I ~ N is is a finite set ( of labels ) , C ~ ( N u { 0 } 7 is a finite set ( of continuations ) , H n K is a set of meanings belongin~ to a particular rule from R , u , v E ( A u V ) - , is called a controlled rewriting system ( ORS ) | all variables from the left-hand side ( u ) must be present on the right-hand side ( v ) and vice versa ( rule symmetry according to variables ) .</sentence>
				<definiendum id="0">V , K</definiendum>
				<definiendum id="1">t</definiendum>
				<definiendum id="2">R</definiendum>
				<definiens id="0">a mapping t : V ~ &gt; exp ( A* ) assigni , ~g types to variables</definiens>
				<definiens id="1">a finite 'set of rules ( I , H , u , v</definiens>
				<definiens id="2">a finite set ( of labels</definiens>
			</definition>
			<definition id="3">
				<sentence>Me say that w ~an be directly rewritten in the state ( i0G ) to z with a continuation ( i ' , G ' ) according to meanings F ( written as w ( i , G ) = &gt; \ [ T , F\ ] ~ ( i ' , G ' ) ) , if there exist such rule ( l , H , u , v , C ) E R and such simple substitution q on T , that i ~ I , i ' s C , H n F , G = G ' , H , d ( u ) = w and d ( v ) = z , where d is the substitution derived from q. Relation = &gt; ~\ [ T , F\ ] is defined as the reflexive and transitive closure of = &gt; iT , F\ ] .</sentence>
				<definiendum id="0">H n F , G</definiendum>
				<definiendum id="1">d</definiendum>
				<definiens id="0">w ~an be directly rewritten in the state ( i0G ) to z with a continuation ( i ' , G ' ) according to meanings F ( written as w ( i , G ) = &gt; \ [ T , F\ ] ~ ( i ' , G ' ) ) , if there exist such rule ( l , H , u , v</definiens>
				<definiens id="1">the substitution derived from q. Relation = &gt; ~\ [ T , F\ ] is defined as the reflexive and transitive closure of = &gt; iT</definiens>
			</definition>
			<definition id="4">
				<sentence>`` To use a meaning k '' means here that th , :~re is some rule ( l , H , u , v , C ) applied in the ~ourse of derivation from w ( i , F ) to z ( O , ( ) ) such that k E H. Such meaning can then be removed from G when constructing G ' ( see Def~ 7 ) ; meanings not from H can not .</sentence>
				<definiendum id="0">:~re</definiendum>
				<definiendum id="1">F )</definiendum>
				<definiens id="0">some rule ( l , H , u , v , C ) applied in the ~ourse of derivation from w ( i ,</definiens>
			</definition>
			<definition id="5">
				<sentence>He say that under ~he condition ( i ' , G ' ) it is possible to directly analyse a string z to w with a continuation ( i , G ) ( we write z ( i ' , G ' ) = &lt; \ [ T\ ] w ( i , G ) ) , if there exists a rule ( I , H , u , v , C ) E R and a simple substitution q on T such that i E I , i ' E C , G = G ' u H , d ( u ) = w a d ( v ) = z , where d is the generalized substitution derived from q. A relation `` it is possible to analyze '' ( = &lt; ~\ [ T\ ] ) is defined as a reflexive and transitive closure of = &lt; \ [ T\ ] .</sentence>
				<definiendum id="0">d</definiendum>
				<definiens id="0">under ~he condition ( i ' , G ' ) it is possible to directly analyse a string z to w with a continuation ( i , G ) ( we write z ( i ' , G ' ) = &lt; \ [ T\ ] w ( i , G ) ) , if there exists a rule ( I , H , u , v , C ) E R and a simple substitution q on T such that i E I , i ' E C , G = G ' u H</definiens>
				<definiens id="1">the generalized substitution derived from q. A relation `` it is possible to analyze ''</definiens>
			</definition>
			<definition id="6">
				<sentence>Then z E pi ( F , w ) , where pi is a pattern by T ( see Def .</sentence>
				<definiendum id="0">pi</definiendum>
				<definiens id="0">a pattern by T ( see Def</definiens>
			</definition>
			<definition id="7">
				<sentence>forms ) The CRS : CRS T = ( A , V , K , t , R ) : A = { a , ~ , b , c , ~ , ... , z , ~ , # } ( # means word separator ) K = { sg , pl , comp , sup , neg , masc , nom , acc } V = { - , LIM } t ( - ) = A~| t ( L ) = { 1 , z } ; t ( M ) = { m , n , v } R = { ( see fig .</sentence>
				<definiendum id="0">masc</definiendum>
				<definiens id="0">CRS T = ( A , V , K , t , R ) : A = { a , ~ , b , c , ~ , ... , z</definiens>
			</definition>
			<definition id="8">
				<sentence>EBSAT VII ( 1982 ) : Pk~rpheiic ~nalysis of Czech Prague 1982 EBSAT VI ( 19811 = Lexical Input Data for EKperim4wnts Nith Czech~ Prahs 1981 Koskennlemi , K. ( 1983 ) , T~o-level morphology , Univ. of Helsinki , Dept. of Sen. Linguistics , Publications No. 11 Haji~ , J. , Olive , K. ( 1986 ) = Projekt ~eskoruske~ho strojovLiho pr~ekladu , ( A Project of Czech to Russian MT System ) , in= Proceedings of SOFSEM'86 , Liptovsk~ JAn Kirschner , Z. ( 1983 ) = IIGSRII= ( A Nethod of Automatic Extraction of Significant Terms from Texts ) , EIM~T X Kirschner , Z. ( 1987 ) = Kirschnert Z.= APd % C3-2 : An English , to-Czech Machine Translation System , EBSAT X I I X Kay , M. ( 1987 ) = Non-Cones , erie , ire Finite ~ .</sentence>
				<definiendum id="0">IIGSRII=</definiendum>
				<definiendum id="1">EIM~T X Kirschner , Z.</definiendum>
				<definiens id="0">An English , to-Czech Machine Translation System</definiens>
			</definition>
</paper>

		<paper id="1072">
			<definition id="0">
				<sentence>3,0 The Architecture of NAS NAS consists of four major subsystems , viz. , a stream filter , a lexical scanner , a parser , and a semantic processor or filter working sequentially as listed .</sentence>
				<definiendum id="0">NAS NAS</definiendum>
			</definition>
			<definition id="1">
				<sentence>~e output of this processor ( and NAS ) is a classification or index of a story consisting of one or mor~ ) general concepts and their designators .</sentence>
				<definiendum id="0">NAS )</definiendum>
			</definition>
			<definition id="2">
				<sentence>The most concrete level consists of names which enter into an index whenever present in a story .</sentence>
				<definiendum id="0">most concrete level</definiendum>
				<definiens id="0">consists of names which enter into an index whenever present in a story</definiens>
			</definition>
			<definition id="3">
				<sentence>1~e action slot is a list of one or more synonomous words or phrases that denote an action or the `` doing '' component of a concept .</sentence>
				<definiendum id="0">1~e action slot</definiendum>
				<definiens id="0">a list of one or more synonomous words or phrases that denote an action or the `` doing '' component of a concept</definiens>
			</definition>
			<definition id="4">
				<sentence>The more general notion of Strikes and Lockouts appears as a frame in the concept base of the form : ( 2 ) Strikes and Lockouts Action : plan , participate Agent : employee Object : strike where the action slot consists of Rlan and i~ and the agent slot is of type employee of which Kroundworkers is so marked .</sentence>
				<definiendum id="0">agent slot</definiendum>
				<definiens id="0">a frame in the concept base of the form : ( 2 ) Strikes and Lockouts Action : plan , participate Agent : employee Object : strike where the action slot consists of Rlan and i~ and the</definiens>
			</definition>
			<definition id="5">
				<sentence>'or example , Yen is a low-level designator word and it is also semantically marked as currency .</sentence>
				<definiendum id="0">Yen</definiendum>
				<definiens id="0">a low-level designator word and it is also semantically marked as currency</definiens>
			</definition>
</paper>

		<paper id="2162">
			<definition id="0">
				<sentence>Accordingly , Corinne is file subject of % oming over '' .</sentence>
				<definiendum id="0">Corinne</definiendum>
				<definiens id="0">file subject of % oming over ''</definiens>
			</definition>
			<definition id="1">
				<sentence>The answer Jack is a cat is satisfactory , provided the listener knows that a cat is a mammal and a mammal is an animate .</sentence>
				<definiendum id="0">answer Jack</definiendum>
				<definiens id="0">a cat is satisfactory , provided the listener knows that a cat is a mammal and a mammal is an animate</definiens>
			</definition>
			<definition id="2">
				<sentence>Figure 1 : The Hierarchy for Complement-Taking Verbs 7~7 Each node in this hierarchy , denoted for reference purposes by a mnemonic word , is actually a full-fledged lexical phrase-an association of a syntactic pattern with its conceptual meaning .</sentence>
				<definiendum id="0">Hierarchy</definiendum>
				<definiens id="0">a full-fledged lexical phrase-an association of a syntactic pattern with its conceptual meaning</definiens>
			</definition>
			<definition id="3">
				<sentence>There are two discrepancies : ( a ) this sentence includes a direct object ( the chairman ) , and ( b ) Frank is not the subject of the complement as prescribed in phrase Pl .</sentence>
				<definiendum id="0">direct object</definiendum>
			</definition>
			<definition id="4">
				<sentence>verb Z : aet concept : X communicate that act Z can achieve a goal G of X This generalized phrase simply states the meaning of ask , namely `` X communicates that act Z can achieve a goal of X '' , regardless of ~ ) whoJi~ the object of the communication act , and ( b ) who egeeuteS the act Z. ( b ) The general EQUI-rule ( P4 and PS ) : Semantic properties can be generalized across complement-taking verbs : pattern : X : person V : verb Z : act concept : X is the subject of the embedded act Z pattern : X : person V : verb Y : person Z : aet concept : Y is the subject of the embedded act Z These phrases dictate the default identity of the implicit subject in complement-taking verbs : it is either the object , or the subject ( if an object does not exist ) of the embedding phrase .</sentence>
				<definiendum id="0">PS )</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">aet concept : X communicate that act Z can achieve a goal G of X This generalized phrase simply states the meaning of ask , namely `` X communicates that act Z can achieve a goal of X ''</definiens>
				<definiens id="1">the object of the communication act</definiens>
				<definiens id="2">Semantic properties can be generalized across complement-taking verbs : pattern : X : person V : verb Z : act concept : X is the subject of the embedded act Z pattern : X : person V : verb Y</definiens>
				<definiens id="3">the subject of the embedded act Z These phrases dictate the default identity of the implicit subject in complement-taking verbs : it is either the object , or the subject ( if an object does not exist ) of the embedding phrase</definiens>
			</definition>
			<definition id="5">
				<sentence>pattern : X : person V : verb Y : person Z : infinitive-aet concept : Y communicated Z to Y Phrase P6 implies that ( 1 ) X communicated an act Z to Y , and ( 2 ) Z is a hypothetical act .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiens id="0">a hypothetical act</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>We shall call X'-structures ( middle level in the maximal projections ) as `` groups '' : a group contains an overt or an empty head , wrapped by its specifiers ( denoted Specif ) and modifiers ( denoted Modif ) but without argument ( s ) ( ds~ noted Arg ) .</sentence>
				<definiendum id="0">middle level</definiendum>
			</definition>
			<definition id="1">
				<sentence>Tensed Verbal Group ( TVG ) is V ' with the ( morphologic or syntactic ) feature of being tensed .</sentence>
				<definiendum id="0">TVG</definiendum>
				<definiens id="0">V ' with the ( morphologic or syntactic ) feature of being tensed</definiens>
			</definition>
			<definition id="2">
				<sentence>Non-tensed Verbal Group ( NVG ) is V ' with the ( morphologic ) feature of being untensed .</sentence>
				<definiendum id="0">Non-tensed Verbal Group ( NVG</definiendum>
				<definiens id="0">V ' with the ( morphologic ) feature of being untensed</definiens>
			</definition>
			<definition id="3">
				<sentence>ECP abbreviates the Empty Category Principle .</sentence>
				<definiendum id="0">ECP</definiendum>
			</definition>
			<definition id="4">
				<sentence>( 4 ) The overt or empty ( PRO ) subject is considered as a special argument of the tensed ( S ) or un -tensed ( NP ) maximal projections of V° ( 5 ) In the hypotheses ( 4 ) and ( 2 ) the traditional , formal VP is dissolved into S or complex , vet -bal NP° ( 6 ) The phenomena of binding and bounding are easier remarked and solved this way .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">a special argument of the tensed ( S ) or un -tensed (</definiens>
			</definition>
</paper>

		<paper id="2112">
			<definition id="0">
				<sentence>But the examples that Tennant gives for conceptual completeness presupposition , reference to discourse objects -seem to be 530 part of a continuum with topics like ellipsis and anaphora , which are more clearly linguistic .</sentence>
				<definiendum id="0">Tennant</definiendum>
				<definiens id="0">gives for conceptual completeness presupposition , reference to discourse objects -seem to be 530 part of a continuum with topics like ellipsis and anaphora</definiens>
			</definition>
			<definition id="1">
				<sentence>The Sourcebook consists of a large set of these exemplars a~td a conceptual taxonomy of the types of issues represented in the database .</sentence>
				<definiendum id="0">Sourcebook</definiendum>
				<definiens id="0">consists of a large set of these exemplars a~td a conceptual taxonomy of the types of issues represented in the database</definiens>
			</definition>
			<definition id="2">
				<sentence>The Sourcebook provides a structural representation of the coverage that can be expected of a natural language system .</sentence>
				<definiendum id="0">Sourcebook</definiendum>
				<definiens id="0">provides a structural representation of the coverage that can be expected of a natural language system</definiens>
			</definition>
			<definition id="3">
				<sentence>A process evahlation includes questions of efficiency , perspicuity and conceptual coverage in the sense of Tennant .</sentence>
				<definiendum id="0">process evahlation</definiendum>
				<definiens id="0">includes questions of efficiency , perspicuity and conceptual coverage in the sense of Tennant</definiens>
			</definition>
			<definition id="4">
				<sentence>Competence and Perfor- : mance in the Design of Natural Language Systems .</sentence>
				<definiendum id="0">Competence</definiendum>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>Thus Kaplan 's Grammar-writer 's Workbench is an implementation of a particular linguistic theory ( Lexical Functional Grammar ; , Kaplan and Bresnan , 1982 ) ; similarly , Evans ' ProGram incorporated an early version of Generalized Phrase Structure Grammar ( GPSG , Gazdar and Pullum , 1982 ) , whilst PATR-II is a `` virtual linguistic machine '' , developed by Shieber as a tool for experimenting with a variety of syntactic theories .</sentence>
				<definiendum id="0">Workbench</definiendum>
				<definiens id="0">an implementation of a particular linguistic theory ( Lexical Functional Grammar ; , Kaplan and Bresnan , 1982 ) ; similarly , Evans ' ProGram incorporated an early version of Generalized Phrase Structure Grammar ( GPSG</definiens>
			</definition>
			<definition id="1">
				<sentence>Tire user interface consists of a comntalld line inteqgreter , a number of special puqmse viewing modules for recta-grammatical constructs , and a component for displaying parse trees on non-graphics terminals .</sentence>
				<definiendum id="0">Tire user interface</definiendum>
				<definiens id="0">consists of a comntalld line inteqgreter , a number of special puqmse viewing modules for recta-grammatical constructs</definiens>
			</definition>
			<definition id="2">
				<sentence>Grosz , B. , D. Appelt , M. Douglas &amp; F. Pelcira ( 1987 ) `` II~ , AM : An experiment in the design of transportable natural language interfaces ' , Artificial Intelligence , vol .</sentence>
				<definiendum id="0">AM</definiendum>
			</definition>
</paper>

		<paper id="1067">
			<definition id="0">
				<sentence>that the missing information required for automatic understanding ( or desambiguation ) of natural language ( NL ) is supposed to be supplied by a computer model of the knowledge correspomding to the universe of discourse .</sentence>
				<definiendum id="0">NL</definiendum>
				<definiens id="0">supposed to be supplied by a computer model of the knowledge correspomding to the universe of discourse</definiens>
			</definition>
			<definition id="1">
				<sentence>APAC32 is a descendant of the Montreal TAUM series .</sentence>
				<definiendum id="0">APAC32</definiendum>
			</definition>
			<definition id="2">
				<sentence>The absence of any accomplished model of the universe of discourse and the temporary abandonment ( for technical reasons ) of any device alowing the involvement of hypersentential context in the analysis have , of course , endowed the system with a typical probabilistic character .</sentence>
				<definiendum id="0">temporary abandonment</definiendum>
				<definiens id="0">technical reasons ) of any device alowing the involvement of hypersentential context in the analysis have , of course , endowed the system with a typical probabilistic character</definiens>
			</definition>
			<definition id="3">
				<sentence>2o3~o The basic dictionary information in APAC32 is a complex which consist~ of two main parts= information conce1~ ing the source language and that pe~=~ raining to the target language° These structures can be separated~ ~hey have been put together whenever pos~ sible with respect to the efficiency of the system° The internal structure of both these parts is almost the same and can be briefly described as follows : ca~egorial information~ le~ , xical value~ , pa~adigmatic information~ pointers to parallelmeanings , valen~ oy frame , combinatory frame ( preposi~ tional , phrasal9 special~liaison , etc. , patterns ) , terminological spe~ cifications , special syntactic inforo~ mation , semantic features~ Extensive though this apparatus may be , it should be stated that theze are still possibilities ~ and a need~ of course to add further data° For lack of space , let us confine ourselves to three poi~ts only® 2~3.1~I. The apparatus of semantic featu~'e~ consists of four &amp; lasses of feaotures : a ) features concerning the text vs. metatext structure~ b ) general semantic features~ c ) domain specific features , and d ) features concerni~ terminologi~cal status° The number of features is limited for reasons of which the most important is that excessive detailedness leads to unwanted ~i~ gidity .</sentence>
				<definiendum id="0">Extensive</definiendum>
				<definiens id="0">a complex which consist~ of two main parts= information conce1~ ing the source language and that pe~=~ raining to the target language° These structures</definiens>
				<definiens id="1">almost the same and can be briefly described as follows : ca~egorial information~ le~ , xical value~</definiens>
				<definiens id="2">tional , phrasal9 special~liaison , etc. , patterns ) , terminological spe~ cifications , special syntactic inforo~ mation , semantic features~</definiens>
				<definiens id="3">consists of four &amp; lasses of feaotures : a ) features concerning the text vs. metatext structure~ b ) general semantic features~ c ) domain specific features , and d ) features concerni~ terminologi~cal status° The number of features is limited for reasons of which the most important is that excessive detailedness leads to unwanted ~i~ gidity</definiens>
			</definition>
</paper>

		<paper id="2101">
			<definition id="0">
				<sentence>AKer processing the wrong parts in the current transfer ~tage , PECOF updates the intermediate forms of the following stages of the original MT system output based on the corrections performed in the current stage .</sentence>
				<definiendum id="0">PECOF</definiendum>
				<definiens id="0">updates the intermediate forms of the following stages of the original MT system output based on the corrections performed in the current stage</definiens>
			</definition>
			<definition id="1">
				<sentence>( I ) Analysis of the corrected parts by using the reverse MT system PECOF ( 2 ) Identification of the part to be corrected in the database ( 3 ) Correction of the part of database or documentation of the corrected patterns which can not be completely identified Fig.3 The main functions of PECOF In order to keep lexical information of the words appearing in the source language sentences till the end of correcting , PECOF needs some record type database .</sentence>
				<definiendum id="0">PECOF</definiendum>
				<definiens id="0">of the part to be corrected in the database ( 3 ) Correction of the part of database or documentation of the corrected patterns which can not be completely identified Fig.3 The main functions of PECOF In order to keep lexical information of the words appearing in the source language sentences till the end of correcting ,</definiens>
			</definition>
			<definition id="2">
				<sentence>If the same intermediate form is obtained , PECOF stops the transfer by the reverse MT system and begins to backtrack .</sentence>
				<definiendum id="0">PECOF</definiendum>
				<definiens id="0">stops the transfer by the reverse MT system and begins to backtrack</definiens>
			</definition>
			<definition id="3">
				<sentence>478 More precisely , PECOF identifies the irrelevant part of the intermediate form of the original MT system by comparing it with that of the corrected results given by the reverse MT system and corrects the data and the applied conditions in the database according to the procedures determined from the difference patterns .</sentence>
				<definiendum id="0">PECOF</definiendum>
				<definiens id="0">identifies the irrelevant part of the intermediate form of the original MT system by comparing it with that of the corrected results given by the reverse MT system and corrects the data and the applied conditions in the database according to the procedures determined from the difference patterns</definiens>
			</definition>
			<definition id="4">
				<sentence>If the reasoning of corrections is given in a form of the conflicting words and the associated information as mentioned in section 3.2 , PECOF examines the data to be corrected mid the irrelevant applied conditions by referring to the syntactic and semantic attributes of the conflicting words , and corrects the data and the applied condition to be more relevant by refining unifying or replacing the old conditions .</sentence>
				<definiendum id="0">PECOF</definiendum>
				<definiens id="0">examines the data to be corrected mid the irrelevant applied conditions by referring to the syntactic and semantic attributes of the conflicting words</definiens>
			</definition>
			<definition id="5">
				<sentence>If the correction in postediting lacks detailed information about wrong translation and confident reasons necessary for correcting the database , PECOF arranges the related parts of corrections of the corresponding original target and source expressions , classifies them by some attributes of the error patterns and adds them to a document of error patterns .</sentence>
				<definiendum id="0">PECOF</definiendum>
				<definiens id="0">arranges the related parts of corrections of the corresponding original target and source expressions , classifies them by some attributes of the error patterns and adds them to a document of error patterns</definiens>
			</definition>
			<definition id="6">
				<sentence>The occurrence of some syntactic errors and their corrections in the target language expressions can be detected when some parts of the target language expressions are corrected though the intermediate forms are the same as those of the corrected expressions except for some syntactic term expressions° Let us describe the rewriting rules of a noun phrase as follows : RR : ADJP ( Rewriting Rule : ADJective Phrases ) &lt; NP ( nl { v } ( PRED : . , OBJ : n2 , .. ) ) &gt; : := &lt; NPI ( nl ) &gt; &lt; PREP &gt; &lt; NP ( n2 ) &gt; &lt; NP ( nl ( PRED : v , KI : . , K2 : n2 , ... ) ) &gt; : : = &lt; NPI ( nl ) &gt; &lt; INF ( PRED : v , KI : nl , K2. : n2 , ... ) &gt; 1 2 ( 3 ) The above expressions are useful for transformation between sentences and the intermediate expressions in parsing and generation of sentences , In the rewriting rule expressions , ni ( i-l,2 ) and v are a noun term and a verb term respectively , nl { v } means that nl is a noun term derived from a verb term .</sentence>
				<definiendum id="0">OBJ</definiendum>
				<definiens id="0">a noun term derived from a verb term</definiens>
			</definition>
			<definition id="7">
				<sentence>&lt; : NP ( t ) &gt; and &lt; INF ( t ) &gt; denote the non-ternfinal sym~ bolz of ~z noun phrase and an infinitive phrase correspondirq~ to a term expression o1 ' an intermediate form t. The symbol * denotes the term prefixed to a frame which includes and modifies the symbol * .</sentence>
				<definiendum id="0">symbol *</definiendum>
				<definiens id="0">the term prefixed to a frame which includes and modifies the symbol *</definiens>
			</definition>
			<definition id="8">
				<sentence>Furthermore , suppose that a postedltor replaces the equivalent tll ' by t13 ' under a condition that the word tl is accompanied with a word t23 of a casecategory label K2-C23 and C23 is a subcategory name of C21 .</sentence>
				<definiendum id="0">C23</definiendum>
				<definiens id="0">a subcategory name of C21</definiens>
			</definition>
			<definition id="9">
				<sentence>Then , the equivalent applied condition ( 9.1 ) of the word tl of the word dictionary are replaced as follows : HEADWORD : t 1 EQUIV : t 11 ' , COND : ( K1-CI : t 1 , K2- { C21-C23 } , ... ) , ( 9.3 ) EQUIV : tl3 ' , COND : ( KI-C l : t I , K2-C23 , ... ) , ( 9.4 ) If t13 ' is the same as t12 ' , ( 9.4 ) and ( 9.2 ) are unified as follows : EQUIV : tl2 ' , COND : ( K1-Chtl , l¢2- { C22 ~C23 } , ... ) , ( 9.5 ) where { Ci±Cj ) denotes the union or the difference set of the sets expressed by tim category names Ci and cj .</sentence>
				<definiendum id="0">COND</definiendum>
				<definiendum id="1">COND</definiendum>
				<definiens id="0">9.1 ) of the word tl of the word dictionary are replaced as follows : HEADWORD : t 1 EQUIV : t 11 ' ,</definiens>
				<definiens id="1">the union or the difference set of the sets expressed by tim category names Ci and cj</definiens>
			</definition>
			<definition id="10">
				<sentence>( 7 ) Nishida F. , Fujita Y. and Takamatsu S. ( 1986 ) 'Construction of a Modular and Portable Machine Translation System . '</sentence>
				<definiendum id="0">'Construction</definiendum>
				<definiens id="0">of a Modular and Portable Machine Translation System</definiens>
			</definition>
</paper>

		<paper id="1073">
			<definition id="0">
				<sentence>The results are network-like structures consistq ing of conditions only on the level of the sets X , E , L and T. ACT ( x ) Is\ ] | e is an action of x. HAVE ( x , y ) \ [ e\ ] , e is a state , that involves x 's having ( owning , ... ) of yo NOT ( A ) \ [ e\ ] $ a condition , that implies ~ .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">network-like structures consistq ing of conditions only on the level of the sets X , E , L and T. ACT ( x ) Is\ ] | e is an action of x. HAVE ( x , y ) \ [ e\ ] ,</definiens>
			</definition>
			<definition id="1">
				<sentence>CH~NGEi ( A1 , A2 ) \ [ e\ ] : ( ~ is a path ) A ( init ( e ) = el ) ^ ( fin ( e ) = e2 ) A ( ~21 ( AI , NOT ( A~ ) ) \ [ e~ ^ ET ' ( Aj , NOT ( AI ) ) \ [ ej\ ] ( el = ep ) A ( e~ = e a ) This preserves the semantic emphasis on A i and allows a new index for the second ~\ ] T. From this rule one obtains the conditions for B~O 1 ( A ) = CHANGE 1 ( NOT ( A ) , A ) ( =CFASE ( NOT ( A ) ) ) B\ ] 6C2 ( A ) = CHANGE2 ( NOT ( A ) , A ) ( usual BEC ( A ) ) .</sentence>
				<definiendum id="0">CH~NGEi</definiendum>
				<definiendum id="1">NOT</definiendum>
				<definiendum id="2">A ) , A )</definiendum>
				<definiens id="0">a path</definiens>
			</definition>
			<definition id="2">
				<sentence>o ) is an i~herent occurrence of B , and the predicate A yleids the principal insiantia~ion of B , then the uppermost predicate of A is an inherent occurrence° The Inheren~ occurrences are closed bottomup : if : In B ( ° .</sentence>
				<definiendum id="0">A</definiendum>
				<definiens id="0">an i~herent occurrence of B , and the predicate A yleids the principal insiantia~ion of B , then the uppermost predicate of</definiens>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>METAL is a Cha~t'opar~erHdrivan Phi : ass Stru ( : tuz'e based MT system , which reflects the classic MT scheme o~f Analysis , Transfer and Generation phases .</sentence>
				<definiendum id="0">METAL</definiendum>
			</definition>
			<definition id="1">
				<sentence>During the Analysis Phase , METAL builds from each input sou : , : 'ce imlsusse sentence one or more structural descriptions { henceforth trees ) , consisting of nodes , which in turn consist of a number of Feature-Value pairs ( henceforth f~v-pairs ) , ) in the Transfer Phase , the trees obtained in the analysis are converted into equivalent trees adapted to the target language needs .</sentence>
				<definiendum id="0">METAL</definiendum>
			</definition>
			<definition id="2">
				<sentence>Two tasks central to the Transfer Process are the Feature Traffic ( i.e. , , hich f-v-pairs need to be sent up and down in which moment , and from which node to which node/s ) , and the handling of Control Dependences ( i.e. , which child node of one analysis tree or sub-trme \ [ henceforth local tree\ ] must be transferred first , in order for other slbling nodes to be able to be rightly transferred ) .</sentence>
				<definiendum id="0">Feature Traffic</definiendum>
				<definiens id="0">f-v-pairs need to be sent up and down in which moment , and from which node to which node/s ) , and the handling of Control Dependences ( i.e. , which child node</definiens>
			</definition>
			<definition id="3">
				<sentence>A local tree is a part of a structural description which is currently being dealt with by the particular rule which is under consideration .</sentence>
				<definiendum id="0">local tree</definiendum>
				<definiens id="0">a part of a structural description which is currently being dealt with by the particular rule which is under consideration</definiens>
			</definition>
			<definition id="4">
				<sentence>Head Node \ [ HN\ ] : * In case Control Dependences ( see below ) exist within the current local tree , the Head Node is the controller node .</sentence>
				<definiendum id="0">Head Node</definiendum>
				<definiens id="0">the controller node</definiens>
			</definition>
			<definition id="5">
				<sentence>This is the case of German 1~s bearing different adjeotlval inflexions depending both upon the gender of the noun and upon the type of determiner ( weak/strong adjective declension ) How to deal with local trees with more than am ; Uead Node ( coordinate structures , for ~mtanee ) .</sentence>
				<definiendum id="0">; Uead Node</definiendum>
				<definiens id="0">weak/strong adjective declension ) How to deal with local trees with more than am</definiens>
			</definition>
</paper>

		<paper id="1043">
			<definition id="0">
				<sentence>The linguistic databases consist of a'letter-tree structured lexicon with annc~ tated feature lists and a FST which is constructed from a set of morphophonological rules .</sentence>
				<definiendum id="0">linguistic databases</definiendum>
				<definiens id="0">consist of a'letter-tree structured lexicon with annc~ tated feature lists and a FST which is constructed from a set of morphophonological rules</definiens>
			</definition>
			<definition id="1">
				<sentence>A FST is a special kind of finite automaton which operates simultaneously on an input and an output tape such that it inspects two symbols at a time .</sentence>
				<definiendum id="0">FST</definiendum>
				<definiens id="0">a special kind of finite automaton which operates simultaneously on an input and an output tape such that it inspects two symbols at a time</definiens>
			</definition>
			<definition id="2">
				<sentence>Some rewriting rules ~ ~ O Ilt -- + mm • Corresponding automaton fragment ( ( s~art all ( `` a ... . o '' stl ( ( tompus imperf ) ( group 1 ) ) ) ... ) ( st1 nil ( `` m '' `` ~ '' st2 ( ( group 1 ) ) ) ) ( st2 nil ( `` &gt; '' `` en &gt; '' end ( ( pers 1 ) ( num sing ) ( mode indic ) ) ) ... ) ( end t ) ) This automaton fragment generates `` &lt; kam &gt; '' with the feature list ( ( tempus import ) ( group 1 ) ( hUm sing ) ( mode indic ) ( pets 1 ) ) t rein the infinitive form `` &lt; kommen &gt; ' .</sentence>
				<definiendum id="0">num sing )</definiendum>
				<definiens id="0">generates `` &lt; kam &gt; '' with the feature list ( ( tempus import ) ( group 1 ) ( hUm sing ) ( mode indic ) ( pets 1 ) ) t rein the infinitive form `` &lt; kommen &gt; '</definiens>
			</definition>
			<definition id="3">
				<sentence>The , ; hell consists of five basic parts ( placed in order of tile way they are called when the algorithm 9ene~*ttes forms ) : generic symbol ; it is realized by a simple function .</sentence>
				<definiendum id="0">hell</definiendum>
			</definition>
</paper>

		<paper id="1066">
			<definition id="0">
				<sentence>The use of CCRs leads to syntactic descriptions formulated entirely with restrictive statements .</sentence>
				<definiendum id="0">CCRs</definiendum>
				<definiens id="0">leads to syntactic descriptions formulated entirely with restrictive statements</definiens>
			</definition>
			<definition id="1">
				<sentence>Pure CF grammars consist solely of warrants , while GPSG is a mixed system .</sentence>
				<definiendum id="0">GPSG</definiendum>
			</definition>
			<definition id="2">
				<sentence>GPSG categories are defined restrictively with Feature Cooccurrence Restrictions and Feature Specification Defaults after the space of categories under consideration is defined by the language-independent notion of category itself ; properties of LTs , however , are defined with both warrants ( in the form of ID rules and r~mtarules ) and with restrictions ( in the form of LP statements and the Feature Instantiation Principles ) .</sentence>
				<definiendum id="0">GPSG categories</definiendum>
			</definition>
			<definition id="3">
				<sentence>A sentence is recognized if its analysis produces an item of the form &lt; O , n , S , c~ , 13 , O &gt; , where n is the sentence length and • is the empty clause set .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the empty clause set</definiens>
			</definition>
			<definition id="4">
				<sentence>The function of the predictor is to introduce new active edges in the chart .</sentence>
				<definiendum id="0">function of the predictor</definiendum>
				<definiens id="0">to introduce new active edges in the chart</definiens>
			</definition>
			<definition id="5">
				<sentence>The variables L , L\ ] , and L2 designate difference lists for the input string as in Definite Clause Grammars , while RCat is the category assigned to the analyzed string .</sentence>
				<definiendum id="0">RCat</definiendum>
				<definiens id="0">the category assigned to the analyzed string</definiens>
			</definition>
			<definition id="6">
				<sentence>Lexical entries are represented in the form lex ( W0rd , Cat ) and rules with rule ( LHS , RHS ) , whereby LH8 is a single category and RHS a list of categories .</sentence>
				<definiendum id="0">LH8</definiendum>
				<definiens id="0">a single category and RHS a list of categories</definiens>
			</definition>
</paper>

		<paper id="2166">
			<definition id="0">
				<sentence>Ccmsider the design fer one sense of the verb `` bring '' : -- Lcxicai Systems Analysis ( MORPH ( INFLECTION ( PAST brought ) ) ) ( PASTPART brought ) ) ) ( PIION ( AXNT ) ) ( SYNTACTIC ( CONSTRUCTION ( MWESTART ) ) ) ( INHERENT ( INF ) ) ) ( IRREG ) ) ) ( NUMBER ( PLUR ) ) ) ( SUBCAT ( DITRAN ) ) ) ( NPING ) ) ) ( NPTOV ) ) ) ( TRAN ) ) ) ( TENSE ( PRES ) ) ) ( SYSTEM ( STORED ) ) ~-Br : mdeis Verb Lexico .</sentence>
				<definiendum id="0">MORPH ( INFLECTION</definiendum>
				<definiendum id="1">) ) ( PIION</definiendum>
				<definiendum id="2">AXNT ) ) ( SYNTACTIC ( CONSTRUCTION</definiendum>
				<definiendum id="3">MWESTART ) ) ) ( INHERENT</definiendum>
				<definiendum id="4">IRREG ) ) ) ( NUMBER ( PLUR ) ) ) ( SUBCAT</definiendum>
				<definiendum id="5">TRAN ) ) ) ( TENSE</definiendum>
				<definiens id="0">( PAST brought ) ) ) ( PASTPART brought )</definiens>
			</definition>
			<definition id="1">
				<sentence>The two morphological features ( MORPH ) give the irregular inflectional attribute-value pairs for the past and past participial forms of the verb ( PAST brought ) and ( PASTPART brought ) .</sentence>
				<definiendum id="0">MORPH</definiendum>
			</definition>
			<definition id="2">
				<sentence>There are ten fields of information in the Box Codes giving such information as register ( e.g. informal ) , or dialect ( e..</sentence>
				<definiendum id="0">dialect</definiendum>
				<definiens id="0">information in the Box Codes giving such information as register ( e.g. informal ) , or</definiens>
			</definition>
			<definition id="3">
				<sentence>MeCord , Michael C. and Susanne Wolff ( 1987 ) `` The Lexicon and Morphology for LMT , A Ih'olog-Based MT System '' IBM Research Report , Number : RC 13403 McCord , Michael C. ( 1988 ) `` Design of LMT : A l'rolog-Based Machine Translation System '' IBM Report Number : RC 13536 Merriam ( 1963 ) Websters Seventh New Collegiate Dictionary G. &amp; C. Merriam , Springfield , Massachusetts .</sentence>
				<definiendum id="0">Ih'olog-Based MT System</definiendum>
				<definiens id="0">A l'rolog-Based Machine Translation System</definiens>
			</definition>
</paper>

		<paper id="2092">
</paper>

		<paper id="1052">
			<definition id="0">
				<sentence>Roughly , a presupposition is a proposition that is conveyed by a sentence or utterance 2 but is not part of the main point , and must be consistent with the established context in order for that sentence or utterance to be felicitous .</sentence>
				<definiendum id="0">presupposition</definiendum>
			</definition>
</paper>

		<paper id="1080">
			<definition id="0">
				<sentence>~ ... w~ , 1 &lt; _k. &lt; _m~n Ae VNu { &lt; NOI~ &gt; , &lt; NOP-SE &gt; , &lt; NOP-/LSE &gt; } 392 where VN is the set of the non -- terminal symbols of the grammar .</sentence>
				<definiendum id="0">VN</definiendum>
				<definiens id="0">the set of the non -- terminal symbols of the grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>The rules are the following : ( defrule NPRule ; NP -- &gt; Determiner Noun ( STATUS active ) ( CNTXTLORNOPR NIL ) ( PRODUCTION ( NP ( Determiner Noun ) ) ) ( SYN-TESTS T ) ( SEM-TESTS T ) ( SYN-ACTIONS ( ralsef `` ( * DefiniteneSS Determiner ) ; raise the values of the specified features from the ; son node into the parent node `` ( * * Noun ) l } } ; second * means all features of the son node ; first * means the storing of the features as they are ; in the son node into the parent node ( defrule VPRule ; VP -- &gt; Verb NP NP ( STATUS active ) ( CNTXTLORN OPR NIL ) ( PRODUCTION ( Via ( Verb NP NP ) ) ) ( SYN-TESTS T ) ( SEM-TESTS T ) ( SYN-ACTIONS { raiser `` ( * * Verb ) ; all features of the Verb node are ; copied in the parent node ( ( Object Definiteness ) Definiteness NP ) ; lst NP `` ( ( Object Number ) Number NP ) `` ( ( Object Predicate } Predicate NP ) `` ( ( Object-2 Definiteness ) Definiteness NP 2 } ; 2nd NP `` ( ( Object-2 Number } Number NP 2 ) `` ( ( Object-2 Predicate ) Predicate NP 2 ) } ) ) ( defrule TOPRule ; S -- - &gt; NP VP ( STATUS active } ( CNTXTLORNOPR NIL ) ( PRODUCTION ( S ( NP VP ) ) ) ( SYN-TESTS T ) ( SEM-TESTS T ) ( SYN-ACTIONS { ralaef `` ( { Subject Definiteness ) Definiteness NP ) `` ( { Subject Number ) Number NP ) `` { ( Subject Predicate } Predicate NP ) `` { * * vP } } ) \ [ SEM-ACTIONS { put-sem-val ; stores the EVALuation of the following ; expression as the semantic value of the ; parent node S 39g ( append ( getf-pn `` Predicate ) { getf-pn `` { Subject Predicatel } ( getl-pn `` ( Object Predicate ) ) ( getf-pn `` ( Object-2 Predicate ) ) ) ) ) ) ; getf-pn gets feature values from the parent node The graph built by the parser applying these rules to the sentence 'a girl handed the baby the toys ' is equivalent to the e-structure built by the corresponding LFG as shown in/Wlnograd 1983/ .</sentence>
				<definiendum id="0">CNTXTLORNOPR NIL )</definiendum>
				<definiendum id="1">lst NP `` ( ( Object Number</definiendum>
				<definiens id="0">the storing of the features as they are ; in the son node into the parent node ( defrule VPRule ; VP -- &gt; Verb NP NP ( STATUS active ) ( CNTXTLORN OPR NIL ) ( PRODUCTION ( Via ( Verb NP NP ) ) ) ( SYN-TESTS T ) ( SEM-TESTS T ) ( SYN-ACTIONS { raiser</definiens>
				<definiens id="1">Object-2 Predicate ) Predicate NP 2 ) } ) ) ( defrule TOPRule ; S -- - &gt; NP VP ( STATUS active } ( CNTXTLORNOPR NIL ) ( PRODUCTION ( S ( NP VP ) ) ) ( SYN-TESTS T ) ( SEM-TESTS T ) ( SYN-ACTIONS { ralaef `` ( { Subject Definiteness ) Definiteness NP</definiens>
			</definition>
			<definition id="2">
				<sentence>If IL-Name is the name of an IL , and G-Name is the name of a grammar which defines a particular language through a dictionary and a set of CGU rules , then the pair &lt; IL-Name , G-Name &gt; defines an 1LA inside the SIS : this application is a task performed by that particular IL .</sentence>
				<definiendum id="0">IL-Name</definiendum>
				<definiendum id="1">G-Name</definiendum>
				<definiendum id="2">SIS</definiendum>
				<definiens id="0">the name of a grammar which defines a particular language through a dictionary and a set of CGU rules , then the pair &lt; IL-Name , G-Name &gt; defines an 1LA inside the</definiens>
			</definition>
			<definition id="3">
				<sentence>In fact , the grammar of an ILA defines a language which can be used by the user for sending to the system his requests so that are caught by the parsing system and immediately satisfied .</sentence>
				<definiendum id="0">ILA</definiendum>
				<definiens id="0">defines a language which can be used by the user for sending to the system his requests so that are caught by the parsing system and immediately satisfied</definiens>
			</definition>
			<definition id="4">
				<sentence>SIS is structured in 2 main ILs : the Kenael Interface Level ( K.I.L. ) and the Natural Language IL ( N.L.I.L ) .</sentence>
				<definiendum id="0">SIS</definiendum>
			</definition>
			<definition id="5">
				<sentence>The SAIL Interfacing System : a Framework for the Development of Natural Language Grannnars and Applications .</sentence>
				<definiendum id="0">SAIL Interfacing System</definiendum>
				<definiens id="0">a Framework for the Development of Natural Language Grannnars and Applications</definiens>
			</definition>
			<definition id="6">
				<sentence>DIAGRAIVI : A grammar for dialogues .</sentence>
				<definiendum id="0">DIAGRAIVI</definiendum>
				<definiens id="0">A grammar for dialogues</definiens>
			</definition>
</paper>

		<paper id="1015">
</paper>

		<paper id="1068">
			<definition id="0">
				<sentence>I , Introduction Dialog is a bilateral process the par ~ ticipants of which communicate each other messages concerning the surrounding world .</sentence>
				<definiendum id="0">Introduction Dialog</definiendum>
				<definiens id="0">a bilateral process the par ~ ticipants of which communicate each other messages concerning the surrounding world</definiens>
			</definition>
			<definition id="1">
				<sentence>CC consists of the alternate turn-takings of the communicants though not every such sequence forms a CC .</sentence>
				<definiendum id="0">CC</definiendum>
				<definiens id="0">consists of the alternate turn-takings of the communicants though not every such sequence forms a CC</definiens>
			</definition>
			<definition id="2">
				<sentence>We can bring forth the following types of P-parametres : assessments ( rational evaluations and those of pleasantness ) ; knowled~e ( also skills , experience ) ; intorests ; requirements ( wishes , needs , among them a need fop communication ) .</sentence>
				<definiendum id="0">requirements (</definiendum>
				<definiens id="0">wishes , needs , among them a need fop communication )</definiens>
			</definition>
			<definition id="3">
				<sentence>The communicative cycle proceeds as follows ( participants A and B , A is the initiator of communication , G is the com~ municative goal of A ) .</sentence>
				<definiendum id="0">G</definiendum>
				<definiens id="0">the initiator of communication</definiens>
			</definition>
</paper>

		<paper id="1050">
			<definition id="0">
				<sentence>We could re-phrase 9 as 10 ) H x : H Y : ( hit ( x , Y ) A X=iota Z : Y=iota W : \ [ hunter ( Z ) A shot at ( Z , Y ) \ ] A \ [ lion ( W ) ^ chased ( W , X ) \ ] ) The other examples , 3 and 4 , woul d then become 11 ) 3 x : ~ Y : ( hit ( X , Y ) ^ X= iota Z : \ [ hunter ( Zl ^ shot at ( Z , iota W : \ [ lion ( W ) A chasedlW , Z ) \ ] ) \ ] ^ Y= iota V : \ [ lion ( V l ^ chased ( V , X ) \ ] l 12 ) 3 X : -q Y : ( hit ( X , Y ) A X = iota Z : \ [ hnnter ( Z ) ^ shot_at ( Z , Y ) \ ] A Y= iota W : \ [ lion ( W ) A chased ( W , iota V : \ [ hunter ( V ) ^ shot_at ( V , W ) \ ] ) \ ] ) But in cases 11 and 12 part of the expression must be repeated , namely the one stating the uniqueness of the hnnter-chasing lion , and of the lion-shooting bunter , respectively .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiens id="0">X= iota Z : \ [ hunter ( Zl ^ shot at ( Z , iota W : \ [ lion ( W ) A chasedlW , Z ) \ ] ) \ ] ^ Y= iota V : \ [ lion ( V l ^ chased ( V , X</definiens>
				<definiens id="1">A chased ( W , iota V : \ [ hunter ( V ) ^ shot_at ( V , W ) \ ] ) \ ] ) But in cases 11 and 12 part of the expression must be repeated , namely the one stating the uniqueness of the hnnter-chasing lion , and of the lion-shooting bunter , respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>McCawley ( McCawley 19 '' 10 ) , for instance , argues ( for other reasons ) , that the semantic representation of sentences should not be east in terms of First Order Logic , but rather in terms of the overall proposition of a sentence plus referential indices .</sentence>
				<definiendum id="0">McCawley</definiendum>
				<definiens id="0">for instance , argues ( for other reasons ) , that the semantic representation of sentences should not be east in terms of First Order Logic , but rather in terms of the overall proposition of a sentence plus referential indices</definiens>
			</definition>
			<definition id="2">
				<sentence>The X2 on the level of the proposition , i.e. `` hit ( ... , X2 ) '' is clearly outside the scope of the `` almotntion '' defining its value , and so we would expect it to remain unbound alter the annotation itself has been evaluated .</sentence>
				<definiendum id="0">X2 )</definiendum>
				<definiens id="0">alter the annotation itself has been evaluated</definiens>
			</definition>
			<definition id="3">
				<sentence>Sdcond , wllen any definite UOHU phrase ( fnl\ [ noah phrase or pronoun ) Ilas iomld tilt ton'oct discourse rcfercllt , it drags it into the DRS umler couslruclion .</sentence>
				<definiendum id="0">Sdcond</definiendum>
				<definiens id="0">wllen any definite UOHU phrase ( fnl\ [ noah phrase or pronoun</definiens>
			</definition>
</paper>

		<paper id="2137">
			<definition id="0">
				<sentence>( 1987b ) Direct Memory Access Translation : A Theory of Translation .</sentence>
				<definiendum id="0">Direct Memory Access Translation</definiendum>
			</definition>
</paper>

		<paper id="1071">
			<definition id="0">
				<sentence>Here G denotes the set of all parts of speech , gj denotes a particular part of speech , and g ( Wi ) denotes the part of speech catego~7 t6 which word W i belongs ( abbreviated to gi from now on ) ; f denotes a frequency calculated from the training text .</sentence>
				<definiendum id="0">G</definiendum>
				<definiendum id="1">f</definiendum>
				<definiens id="0">the set of all parts of speech , gj denotes a particular part of speech , and g ( Wi ) denotes the part of speech catego~7 t6 which word W i belongs ( abbreviated to gi from now on</definiens>
			</definition>
			<definition id="1">
				<sentence>when the word has two or more po~ible tags , the tag choasn is the one which makes the largest contribution to ~he word 's probability ( i.e. which gives rise to the largczt component in the summation on pg .</sentence>
				<definiendum id="0">tag choasn</definiendum>
				<definiens id="0">makes the largest contribution to ~he word 's probability ( i.e. which gives rise to the largczt component in the summation on pg</definiens>
			</definition>
</paper>

		<paper id="1034">
			<definition id="0">
				<sentence>We use YACC /Johnson 1983/ , a LALR ( 1 ) parsing table generator available in UNIX to automatically generate the parsing table which drives the general parsing procedure .</sentence>
				<definiendum id="0">YACC /Johnson 1983/</definiendum>
				<definiens id="0">a LALR ( 1 ) parsing table generator available in UNIX to automatically generate the parsing table which drives the general parsing procedure</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>A formal language is a subset of the set of all strings in .</sentence>
				<definiendum id="0">formal language</definiendum>
				<definiens id="0">a subset of the set of all strings in</definiens>
			</definition>
			<definition id="1">
				<sentence>The Knacks The Domain The Environment o The Hypotheses The Learner The Crileriony Figure 1 : A Learning Model complexity by requiring that the learner converge in time polynomial , but on the other hand relaxes the criterion of what constitutes a 'correct ' grammar by employing an approximate , and probabilistic notion of correctness , or aecraey to be'precise .</sentence>
				<definiendum id="0">Learning Model complexity</definiendum>
				<definiens id="0">probabilistic notion of correctness , or aecraey to be'precise</definiens>
			</definition>
			<definition id="2">
				<sentence>A learning function is said to polynomially learn a collection of languages just in case it is computable in time polynomial ill the length of the input sample , and for an arbitrary degrees of accuracy e and confidence 5 , its output on a sample produced by the environment by the manner described above for any language L in that collection , will be an e-approximation of the unknown language L with confidence probability at least 1 -a , no matter what the unknown distribution is , as long as the number of strings in the sample exceeds p ( e -~ , 5 -~ , size ( L ) ) for some fixed plynomial p. Here , grammar G is an e-approximation of language L , if the probability distribution over the symmetric difference 6 of L and I , ( G ) is at most e. Blumer et al. \ [ 5\ ] have shown an extremely interesting result revealing a connection between reliable data compression and polynomial learnability .</sentence>
				<definiendum id="0">learning function</definiendum>
				<definiens id="0">computable in time polynomial ill the length of the input sample , and for an arbitrary degrees of accuracy e</definiens>
				<definiens id="1">the number of strings in the sample exceeds p ( e -~ , 5 -~ , size ( L ) ) for some fixed plynomial p. Here , grammar G is an e-approximation of language L , if the probability distribution over the symmetric difference 6 of L and I , ( G ) is at most e. Blumer et al. \ [ 5\ ] have shown an extremely interesting result revealing a connection between reliable data compression and polynomial learnability</definiens>
			</definition>
			<definition id="3">
				<sentence>VLE£ VS C graph ( L ) if size ( L ) = n and \ ] S I= m then A ( S ) is consistent with S and A ( S ) ) e 7~I ( , ~ , m ) and .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">e 7~I</definiendum>
				<definiens id="0">consistent with S and A ( S ) )</definiens>
			</definition>
			<definition id="4">
				<sentence>( v ) Ra is a finite set of rewriting rules : R &lt; ~ C { ( A , a } I A e Y , 'N &amp; a C T~u { . }</sentence>
				<definiendum id="0">Ra</definiendum>
				<definiens id="0">a finite set of rewriting rules : R &lt; ~</definiens>
			</definition>
			<definition id="5">
				<sentence>If we now define a hierarchy of languages generated by subclasses of RNRG 's with bounded ranks , context fi'ee languages ( ( ' , FL ) and tree adjoining languages ( TAt ) constitute the first two members of the hierarchy .</sentence>
				<definiendum id="0">FL</definiendum>
				<definiens id="0">a hierarchy of languages generated by subclasses of RNRG 's with bounded ranks , context fi'ee languages ( ( ' ,</definiens>
			</definition>
			<definition id="6">
				<sentence>Then , the degree of locality oft , written locality ( r ) , is d4ned as follows , locality ( r ) = card { ( p , q , ,t ) I there is an edge in r from a node labeled with p to another labeled with q , and is itself labeled with 77 } The degree of locality of a gramm , ~r is the maximum of those of all its derivations .</sentence>
				<definiendum id="0">~r</definiendum>
				<definiens id="0">an edge in r from a node labeled with p to another labeled with q , and is itself labeled with 77 } The degree of locality of a gramm</definiens>
			</definition>
</paper>

		<paper id="2158">
			<definition id="0">
				<sentence>This scheme is shown to he fast ( 0 ( n , h ) time for the first complete parse tree , where n is the length of an input sentence and h is the height of the parse tree ) and useful in various modes of parsing such as on-line parsing , overlap parsing , on-line unparsing , pipe-lining to semantics processing , etc .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the length of an input sentence and h is the height of the parse tree</definiens>
			</definition>
			<definition id="1">
				<sentence>Agents It should be clear from the previous subsection that a set of context-free grammar rules ( even a singleton grammar ) is represented as a network of computing agents each of which acts for an occurrence of a non-terminal or terminal symbol in a grammar rule .</sentence>
				<definiendum id="0">context-free grammar rules</definiendum>
				<definiens id="0">a network of computing agents each of which acts for an occurrence of a non-terminal or terminal symbol in a grammar rule</definiens>
			</definition>
			<definition id="2">
				<sentence>s -- &gt; NP vP ( 2 ) s -- &gt; s PP ( 3 ) NP -- &gt; DET N ( 4 ) PP -- &gt; PREP NP ( 5 ) A white box corresponds to the computing agent acting for a symbol in the right-hand side of a grammar rule and a dark box corresponds to the computing agent acting for the non-terminal symbol in the left-hand side of a grammar rule .</sentence>
				<definiendum id="0">PREP NP</definiendum>
				<definiens id="0">PP ( 3 ) NP -- &gt; DET N ( 4 ) PP -- &gt;</definiens>
				<definiens id="1">the computing agent acting for the non-terminal symbol in the left-hand side of a grammar rule</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , ill Rule ( 1 ) , VP is Type-l , V is Type-2 , and NP is Type-3 .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiendum id="1">NP</definiendum>
				<definiens id="0">Type-l , V is Type-2 , and</definiens>
			</definition>
			<definition id="4">
				<sentence>In the case where no right-adjacent symbol exits in the grammar rule , ( which means that the symbol occurrence A3 is acting for is the right-most right symbol in the glamrnar rule ) , A3 sends the concatenated trees to the Type -- 1 computing agent acting for the left symbol of the grammar rule .</sentence>
				<definiendum id="0">A3</definiendum>
				<definiens id="0">the right-most right symbol in the glamrnar rule</definiens>
			</definition>
			<definition id="5">
				<sentence>The simulation program preserves the original network structure of objects ( i.e. , computing agents in the scheme ) of the parsing program .</sentence>
				<definiendum id="0">simulation program</definiendum>
				<definiens id="0">preserves the original network structure of objects ( i.e. , computing agents in the scheme</definiens>
			</definition>
			<definition id="6">
				<sentence>The initial result of our simulation is that the first complete parse tree is produced from the network in 0 ( n.h ) time , measuring from the beginning of feeding an input string to the network , where n is the length of the input string and h is the height of the parse tree ( not the height of .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the length of the input string and h is the height of the parse tree ( not the height of</definiens>
			</definition>
</paper>

		<paper id="2163">
			<definition id="0">
				<sentence>NMG is a system for employing truth maintenance in text comprehension .</sentence>
				<definiendum id="0">NMG</definiendum>
				<definiens id="0">a system for employing truth maintenance in text comprehension</definiens>
			</definition>
			<definition id="1">
				<sentence>PAR is a DCG-style parser \ [ Pereira80\ ] , implemented as a forward-chaining theorem prover .</sentence>
				<definiendum id="0">PAR</definiendum>
				<definiens id="0">a DCG-style parser \ [ Pereira80\ ] , implemented as a forward-chaining theorem prover</definiens>
			</definition>
			<definition id="2">
				<sentence>Part ( b ) describes the parse after the rest of the sentence ( 10b ) has been read .</sentence>
				<definiendum id="0">Part ( b )</definiendum>
				<definiens id="0">describes the parse after the rest of the sentence ( 10b ) has been read</definiens>
			</definition>
			<definition id="3">
				<sentence>In stage ( b ) too there are two orthogonal activities : ( 1 ) PAR constructs new dependencies : The by-clause following sold justifies the inhibitive port of ( rl ) ; the same by-clause also justifies an alternative role for sold 0/P ) , as a passive voice verb ; this fact plus the by-clause itself add up to a relative clause ( Re ) ; RC joins the old noun-phrase ( NP ) to form a composite nounphrase ( CNP ) ; CNP now joins a new verb-phrase O/P ) in forming a new ~ntence ( S ) .</sentence>
				<definiendum id="0">RC</definiendum>
				<definiens id="0">the old noun-phrase ( NP ) to form a composite nounphrase ( CNP )</definiens>
			</definition>
			<definition id="4">
				<sentence>( b ) Retraction and Refinement : A main objective in text processing , required for left-to-right parsing , has been parsing by refinement .</sentence>
				<definiendum id="0">Refinement</definiendum>
				<definiens id="0">A main objective in text processing</definiens>
			</definition>
			<definition id="5">
				<sentence>Wilensky , R. and Y. Arens , `` PHRAN : A Knowledge-Based Approach to Natural Language Analysis , '' in Proceedings 18th Annual Meeting of the Asosciation for Computational Linguistics , Philadelphia , PA ( 1980 ) .</sentence>
				<definiendum id="0">PHRAN</definiendum>
				<definiens id="0">A Knowledge-Based Approach to Natural Language Analysis</definiens>
			</definition>
</paper>

		<paper id="1059">
			<definition id="0">
				<sentence>An Automatic Telephone Interpretation system is a facility which enables a person speaking in one language to communicate readily by telephone with someone speaking another .</sentence>
				<definiendum id="0">Automatic Telephone Interpretation system</definiendum>
				<definiens id="0">a facility which enables a person speaking in one language to communicate readily by telephone with someone speaking another</definiens>
			</definition>
			<definition id="1">
				<sentence>sition 'temoto ' ( hand ) , 'aida ' ( between ) pronoun 'doko ' ( where ) time thee 'jikan ' ( time ) , 'ima ' , ( now ) 'ato ' ( after ) pronoun I 'itsu ' , ( when ) 'nanji ' ( what time ) number amount I 'ninzuu ' ( the number of people ) unlt I 'en ' ( yen ) , 'doru ' ( dollar ) cost \ ] 'tourokuryou ' ( registration fee ) price I 'muryou ' ( free ) , 'ikura ' ( how much ) act 'sanka ' ( par ticipation ) , 'yotei ' ( plan ) diverse 'nani ' ( what ) , 'hoka ' ( else ) These valency patterns are obtained from the valency patterns of predicates ( obtained from dialogues collected for the task of inquiries about an international conference ) .</sentence>
				<definiendum id="0">'aida '</definiendum>
				<definiens id="0">diverse 'nani ' ( what ) , 'hoka ' ( else ) These valency patterns are obtained from the valency patterns of predicates ( obtained from dialogues collected for the task of inquiries about an international conference )</definiens>
			</definition>
</paper>

		<paper id="2136">
			<definition id="0">
				<sentence>XG is the exte~tded ver .</sentence>
				<definiendum id="0">XG</definiendum>
				<definiens id="0">the exte~tded ver</definiens>
			</definition>
			<definition id="1">
				<sentence>np ( G , X , Z ) : ~ ' link ( rip , G ) , ( p -- l ) goal ( vp , X , Y ) , s ( G , Y , Z ) .</sentence>
				<definiendum id="0">np</definiendum>
			</definition>
			<definition id="2">
				<sentence>The predicate goal_x is an extended version of the predicate gord in the BUP system , which pops up the slash category from the X \ ] is~ when the t , .</sentence>
				<definiendum id="0">goal_x</definiendum>
				<definiens id="0">an extended version of the predicate gord in the BUP system , which pops up the slash category from the X</definiens>
			</definition>
			<definition id="3">
				<sentence>Bup : a bottom-up parser embedded in I~olog .</sentence>
				<definiendum id="0">Bup</definiendum>
				<definiens id="0">a bottom-up parser embedded in I~olog</definiens>
			</definition>
</paper>

		<paper id="2089">
			<definition id="0">
				<sentence>In NL processing the calculus of Time and Aspect is a complex thing where almost all elements of the sentence are concerned .</sentence>
				<definiendum id="0">Aspect</definiendum>
				<definiens id="0">a complex thing where almost all elements of the sentence are concerned</definiens>
			</definition>
</paper>

		<paper id="2146">
			<definition id="0">
				<sentence>Sound-to-spelling transcription : a computer simulation .</sentence>
				<definiendum id="0">Sound-to-spelling transcription</definiendum>
				<definiens id="0">a computer simulation</definiens>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>IM'I/EC is an English-Chinese machine translation system ~ , hich integrates some outstanding features of the case grammar end semantic grammar lnto a uniform frame , LISeS various kuowledgo In the disamblguation , and tries to modify the object language by itself .</sentence>
				<definiendum id="0">IM'I/EC</definiendum>
				<definiens id="0">an English-Chinese machine translation system</definiens>
			</definition>
			<definition id="1">
				<sentence>Dynamic Interactive Learning ( DIL ) : Whenever the system encounters c sentence out of its processing range , it produces various possible translations for each segment of the sentence and interacts with human beings when necessary to select on appropriate translation of the segment and combine them to get o correct translation of the sentence .</sentence>
				<definiendum id="0">Dynamic Interactive Learning</definiendum>
				<definiens id="0">produces various possible translations for each segment of the sentence and interacts with human beings when necessary to select on appropriate translation of the segment and combine them to get o correct translation of the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , ( 1 ) ( `` s ) - &gt; ( verb - ) I ( def ( `` ) , SV ) ( 2 ) ( `` s ) - &gt; ( noun * ) I ( clef ( * ) , PN ) ( 3 ) ( -1 `` 2 ) - &gt; ( word -1 ) ( word `` 2 ) 1 ( ( def ( morpholog v w1 ) , def ( morphologv `` 2 ) ) , CaM ) Here , * , -1 and *2 are variables Indlcating that it con be bounded to any sub-character string of the word to be analyzed , def ( X ) is the definition of X in the IMT-KB , SV , PN , cam are surface 'features of the word .</sentence>
				<definiendum id="0">def ( X )</definiendum>
				<definiendum id="1">SV , PN</definiendum>
				<definiens id="0">variables Indlcating that it con be bounded to any sub-character string of the word to be analyzed</definiens>
				<definiens id="1">the definition of X in the IMT-KB ,</definiens>
			</definition>
			<definition id="3">
				<sentence>Rule ( I ) Indlcotes that when the last character of the surface form of a word is 's ' and the remained character string * in the word is o verb , then its surface feature is the slngulor verb form ( SV ) of the verb * .</sentence>
				<definiendum id="0">SV</definiendum>
				<definiens id="0">the last character of the surface form of a word is 's ' and the remained character string * in the word is o verb</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , it applies morphology rules to analyze the word ~1 and *2 , and returns the value of ( ( f ( morphology -1 ) , f ( morphology w2 ) ) , COM ) as result , Suppose that , SX indicates that X is o variable , # X returns the character llst of X , &amp; X returns the lost character of X , &gt; X returns the first part of rule X or the first element of a list , &lt; X returns the remained port of X which ( &gt; X '' &lt; X o X ) , f ( X , V ) returns the first different item palr of X ond Y , lookup ( X ) looks up the dictionary and returns the deflnltlon of the word X , search ( X ) returns the morphology rules which leclu-. des character X , check ( X ) tests whether two elements of the item pair X is uniflable or nag , null ( x ) tests whether llst X IS empty , apply ( g , x ) returns the result of g ( X ) , t ( X ) tests whether result X needs further onolysls and performs recurslve analysis when necessary. The algorithm for morphology analysis and diction-erv retrievlnq is as follow. INITIALIZE $ X &lt; # word ; SP &lt; search ( &amp; SX ) ; $ P &lt; $ PU search ( &gt; $ X ) ; $ result &lt; ( ) ; for $ rule m SP do { MATCH SPAT &lt; = &gt; Srule ; $ COND &lt; &gt; '' &lt; $ rule ; $ RES &lt; &lt; = &lt; $ rule ; Loop $ patr &lt; -f ( SPAT , SX ) ; if ( null ( $ polr ) ) goto TEST ; if ( not ( check ( $ pair ) ) ) break ; SPAT &lt; $ PAT~ Spelt ; iPAIR .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">X , V</definiendum>
				<definiens id="0">returns the lost character of X</definiens>
				<definiens id="1">looks up the dictionary and returns the deflnltlon of the word X , search ( X ) returns the morphology rules which leclu-. des character X</definiens>
			</definition>
			<definition id="5">
				<sentence>, , p ( w~z. # ( Here , P ( w ) is the word w itself or its property , t is the current onalysls position which initial veluo is ~ , I is the expects|lee length defined by the user ) end order them by means of the phrase ending post-tlons n= , n~ ... .. n~ from lerger to smeller .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">P ( w )</definiendum>
				<definiens id="0">the word w itself or its property , t is the current onalysls position which initial veluo is ~ , I is the expects|lee length defined by the user ) end order them by means of the phrase ending post-tlons n= , n~ ... .. n~ from lerger to smeller</definiens>
			</definition>
			<definition id="6">
				<sentence>When o specific semantic identifier is concerned , the semontlc , processlng mechanisms first finds the key word which con match the semantic identifier from the sentence , such as word wlth tlme , plaoe properties , then get the phrase which comprises the key word in the sentence , and return the phrase as the value of the identifier .</sentence>
				<definiendum id="0">processlng mechanisms</definiendum>
				<definiens id="0">the semantic identifier from the sentence , such as word wlth tlme , plaoe properties , then get the phrase which comprises the key word in the sentence , and return the phrase as the value of the identifier</definiens>
			</definition>
			<definition id="7">
				<sentence>There are also three possible categories of distant contextual relations appeared in o sentence , X ... W \ [ m\ ] - &gt; ( W = &gt; C~ ) W ... Y \ [ n\ ] - &gt; ( W = &gt; C~ ) X ... W ... Y \ [ m , n\ ] - &gt; ( W = &gt; C~ ) Here , X , V , W , C have the same meanings as in the ( 2 ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">distant contextual relations appeared in o sentence , X ... W \ [ m\ ] - &gt; ( W = &gt; C~ ) W ... Y \ [ n\ ] - &gt; ( W = &gt; C~ ) X ... W ... Y \ [ m , n\ ] - &gt; ( W = &gt; C~ ) Here ,</definiens>
			</definition>
			<definition id="8">
				<sentence>\ [ 18\ ] Rod Johnson , Maghi Kinq , end Louis des Tombe , EUROTRA : A multilingual system under development , CL , V01.11 , No.2-3 , p155-169,1985 .</sentence>
				<definiendum id="0">EUROTRA</definiendum>
				<definiens id="0">A multilingual system under development</definiens>
			</definition>
</paper>

		<paper id="1076">
			<definition id="0">
				<sentence>NOSVO is sensitive to the old/flew ( i.e. given/new ) contrasts in a discourse ( Chafe 1974 , 1976 ; ttajicov~ and Vbrov~ 19811 and file syntactic structures that allow a writer , or sI~aker , to begin a sentence with old information , NOSVO organizes the semantic content of pirxlicates to produce an old information first ordering .</sentence>
				<definiendum id="0">NOSVO</definiendum>
				<definiens id="0">to begin a sentence with old information</definiens>
				<definiens id="1">the semantic content of pirxlicates to produce an old information first ordering</definiens>
			</definition>
			<definition id="1">
				<sentence>The former process , takes less concentration by the listet , er ( Green 1980 ) , If we model human mcm ( ny , specifically lexical access , as a sp : , : cading- .</sentence>
				<definiendum id="0">former process</definiendum>
				<definiens id="0">takes less concentration by the listet</definiens>
			</definition>
			<definition id="2">
				<sentence>4,2°3 The Discom°se Ba~e Searcher The Oiseourse Base Searcher searches the discourse to determine whether any of the input predicate arguments in the predicate have been previously introduced into the discour. ; e. If an antecedent ( s ) is found the link is recorded and the whole predicate , with highlighted old infonaaation , is sent to the LiHguistic Converter and Category Analyzer ( l , C~CA ) .</sentence>
				<definiendum id="0">Oiseourse Base Searcher</definiendum>
				<definiens id="0">searches the discourse to determine whether any of the input predicate arguments in the predicate have been previously introduced into the discour.</definiens>
			</definition>
</paper>

		<paper id="2149">
			<definition id="0">
				<sentence>FIG violates common assumptions about the roles of modularity and grammar in generator design .</sentence>
				<definiendum id="0">FIG</definiendum>
				<definiens id="0">violates common assumptions about the roles of modularity and grammar in generator design</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus FIG is an incremental generator .</sentence>
				<definiendum id="0">FIG</definiendum>
				<definiens id="0">an incremental generator</definiens>
			</definition>
			<definition id="2">
				<sentence>Representation Characteristics : A single semantic network represents world knowledge and language knowledge .</sentence>
				<definiendum id="0">Representation Characteristics</definiendum>
			</definition>
			<definition id="3">
				<sentence>Much more could be said about the exact activation algorithm , the representation of constructions , the role of link weights , the use of instantiation for utterances involving more than one occurrence of a word , and so on .</sentence>
				<definiendum id="0">instantiation</definiendum>
				<definiens id="0">for utterances involving more than one occurrence of a word</definiens>
			</definition>
			<definition id="4">
				<sentence>Constmctiun Grammar is a theory of syntax currently being developed at Berkeley .</sentence>
				<definiendum id="0">Constmctiun Grammar</definiendum>
				<definiens id="0">a theory of syntax currently being developed at Berkeley</definiens>
			</definition>
			<definition id="5">
				<sentence>Each construction represents a pairing of a syntactic pattern with a meaning structure .</sentence>
				<definiendum id="0">construction</definiendum>
				<definiens id="0">a pairing of a syntactic pattern with a meaning structure</definiens>
			</definition>
			<definition id="6">
				<sentence>FIG is `` unified '' in two senses : all knowledge is part of one network , and information propagates freely by means of spreading activation .</sentence>
				<definiendum id="0">FIG</definiendum>
				<definiens id="0">`` unified '' in two senses : all knowledge is part of one network , and information propagates freely by means of spreading activation</definiens>
			</definition>
			<definition id="7">
				<sentence>Appelt , Douglas E. , TELEGRAM : A Grammar Formalism for Language Planning , Proceedings of th e 8th International Joint Conference on Artificial Intelligence , Karlsmhe , West Germany , ( 1983 ) , pp .</sentence>
				<definiendum id="0">TELEGRAM</definiendum>
				<definiens id="0">A Grammar Formalism for Language Planning</definiens>
			</definition>
			<definition id="8">
				<sentence>Jacobs , Paul S. , PHRED : A generator for natural language interfaces , Report CSD 85/198 , University of California , Berkeley , 1985 .</sentence>
				<definiendum id="0">PHRED</definiendum>
				<definiens id="0">A generator for natural language interfaces</definiens>
			</definition>
</paper>

		<paper id="2103">
			<definition id="0">
				<sentence>*UNIX is a Trademark of AT &amp; T Bell Laboratories Focusing on the parsing of English , the paper discusses the concept of parsing using global information in Section 2 , the realization of the parsing method as an ATN in Section 3 and the conclusion in Section 4 .</sentence>
				<definiendum id="0">*UNIX</definiendum>
				<definiens id="0">a Trademark of AT &amp; T Bell Laboratories Focusing on the parsing of English</definiens>
			</definition>
			<definition id="1">
				<sentence>The top-down depth-first search like ATN takes klCn time\ [ Aho 1972\ ] , where C is a constant , n is the number of input words , and k 1 is a coefficient which is determined by time taken for the traversal of one arc .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">k 1</definiendum>
				<definiens id="0">a constant</definiens>
				<definiens id="1">a coefficient which is determined by time taken for the traversal of one arc</definiens>
			</definition>
			<definition id="2">
				<sentence>TAURAS : The Toshiba Machine Translation System .</sentence>
				<definiendum id="0">TAURAS</definiendum>
				<definiens id="0">The Toshiba Machine Translation System</definiens>
			</definition>
</paper>

		<paper id="2141">
			<definition id="0">
				<sentence>: to be ~ttached , the churl parser in a/~eneral foJm does not atttmh 6 } ~3 them'in { mediately , but registers them in Agenda , A scheduler decides which arc in Agenda is to be attchcd next .</sentence>
				<definiendum id="0">scheduler</definiendum>
				<definiens id="0">decides which arc in Agenda is to be attchcd next</definiens>
			</definition>
			<definition id="1">
				<sentence>ht KGW-t-p , we use an Agenda°like list ( S-listsuspending list ) but unlike the Agenda in the active chart parser , it only keeps tile arcs which will be tried after the prelerred ones fail .</sentence>
				<definiendum id="0">Agenda°like list</definiendum>
				<definiens id="0">S-listsuspending list ) but unlike the Agenda in the active chart parser , it only keeps tile arcs which will be tried after the prelerred ones fail</definiens>
			</definition>
			<definition id="2">
				<sentence>We call the leftmost constituent of the remainders the waili'ng constiluenL Note that the waiting constituents of PPTs in G ( i ) are to be filled by inactive t'PTs with starting vertex i. ( 5 ) pairs of a larger PPT which incorporates c-PPT as the leftmost constituent and the rule which ww~J used to create the larger PPT .</sentence>
				<definiendum id="0">PPTs</definiendum>
				<definiens id="0">a larger PPT which incorporates c-PPT as the leftmost constituent and the rule which ww~J used to create the larger PPT</definiens>
			</definition>
			<definition id="3">
				<sentence>&lt; Fs in the u-*h retrial phase. 'We a ! so have to perform tile New Rule Appliealio'~ , , operation of the basic cycle , because the reachability cmtdi ; imi may change , ltowever , it rn ; ~y happen that the some rules have already applied to the PP'Fs iti the Ibrmer trials. In this ease , because each PI'T keeps ~ list o\ [ pairs of the larger PPTs and the rules ( see Iteclio'a 3 ) , we call reuse the larger lq ) 'l 's and avoid creating new PPTs in tile u..lh retriM phase. I~t order to minimize the redundaut processings in the retrial phases , Pi , ,nd ( / -- flavors provide ditlierent slots for PPTs created , in the u.4h trill and for those created in the former trials ( sec l , 'ig.3 ) . '1'1 , ( : analysis proceeds in the retrial phases in exactly the s~me way as in the first trail , but the duplication of operation : : ~re carefully avoided° ( 1 ) I'-l~ ' I a so r iloT.i-p|ii , ti : ll0 , ..ps the Inactive PP-f~.liiatailces created II1 the II~ : th retrial , ) halle. re -- ppts : kueps the , Inactive PPT -- I , ~tance , s uhlcli aro gro~n Is the s..th ratrlal I } hast~. Ilut tho saale Pl'~'~iilSialleOS Ilavo beuli created Is tho rotifer trial phases. uld-gi*ts : l~ool ) s tlio l.aetlw ) PP'l'~lltstianea~ ere , sled 1tl llio ( oi'i¢te , t trial plia~o~. ( ; ~ ) ( I-F I a , /or n~w -- ppl~ : ilO~l~S lho actlw t~P'f-.iilStallCoS ¢l'~alod Ill tll { i n-th retrial plisso+ olli-pptl~ : k~ar~ps th0 active PPl'-tastaseos cl0atcti lit , tie , for~er trial pllsses. Fit~.a internal Slraetare.s of the P-'~'lavor anti the t ; .-Flavbr S ~i'k ) x~scssal ; of Px~efex.ence i~ , uXes and ~he FV Calcuiati ( m in the basic cycle , for eadt PPT in P ( i , j ) , the SBC creates a set of new PP'Ps which ' , corporate the PPT. These new PP't 's represent different hypotheses b~se ( l on the same l ) ottom.-up evidence , the incorporated PP'j'. The PR , ( II computes the PVs ( plausibility vMues ) of these dif fereat hypotheses by invoking a package of preferet , ce rules. A rule package is defined for computing the l'Vs of larger PI'Ts incorpratiug the same inactive PPT. That is , ~ rule package is delined for each syntactic category ( noutermit~u.l ) of a PPT to be iitcorporated. A set of rules tot PP-attachment , tbr examt. { ! e , are defined in a package which is iuvoked when the incorporated PPT is a prepositional phrase. hi order to compute PVs , we can refer ia preference rains to various sorts of inibrmatiou as follows ( we use lree and TI~EE for the incorporated PI'T and the iacorprating I'PT , respectively ) . ( ! i : ) the top node of tree ( 2 ) the top node of TREE ( 3 ) eonstitnents o1 : TREE already incorporated ( the left brothers of tree in TIIEE ) ( 4 ) sequence of active PI'Ts which eventually predict Tlg15'l ' ; ( uote that each PPT keeps the larger PPTs which will incorprate the PPT when it is completed ar.e Seclio~ 3 ) ( 5 ) lexieal inh ) rma , tion of words which appear in the right unanalyzed portion of sentences ( look-ahead ) ( 4 ) and ( ~ ) indicate the global nature o\ [ prefer ( race rules of I~ ( gW-/'p in the sense thr~t tit ( . ' l'Vs of TREEs ~Lre eompttt¢~d ant ouly from the coast ' , seats of TREEs but also l'ront their suroundiag contexts ( l ) 'igA ) . Fig.4 lcx ) k ahead ( 5 ) IllfOYuiltJoll referred ~n Pre\ [ et-elrc ( ! Rule.~ ; Fig.5 shows the tbrmat of preference rules. \ [ IncompatibleGases\ ] enmnerates different relationships between tree and 5l'I\ [ I~,15 ' • in the package for l'P-.attaehment , we mmmerate as iucompat-ible cases different types of PP-attachments such as PPs filling one of tile valences of verbs , PPs as adjuncts , etc. A set of , Independent-Evidences\ ] is defined lot e~ , .cll incompatible case. Wheli a set of created PPTs with the same incorporated PP'I ' are given , the PRC ilivokes a package , and for each created PI'T , it determines which e : eclusive ease matches with it. Then , the set of iudepeudenl evidences h ) r the case is ew~luatcd. Each independent evidence is expressed it , a condition-w*lue pair and , if the condition matches with the created PPT , it returns the specified value. The PRO gets a set of values from the independent evidences , each of which is a primitive PV based o , t a certain aspect of the PPT such as semantic intimacy of words , welbtbrmedness of syntactic trees , etc. By combining the values with a certain function ( currently~ we use simple addition as this 685 function ) , the PRC determines the PV for the incorporation of tree into TREE. ( PRUI , E : CAT { one of the syntactic Categories } : TYPE Inon-head. |lead } Depending on whether tile category is the ~awl~al bar-leveI ( head ) or not. ? i~o~5 ; ; ~ Ti~ : ? -~sE ... ... ... ... ... ... ... ... ... ... ... ... ( : tree-cond ( ( eonditlon of ¢asel } ) : independent-evidences l lcondition of ovidnacell Ivalue } ) ( condition of ovidenceZ } Ival~le\ ] ) { condition of evidence3 } ( value } ) : tree-toad ( Icondltion of case2 } ) : independent-evidences Fig. 5 Format of the Preference Rules Tile actual PV of tile created PPT is deterilniued by tile combination of ( 1 ) PV in the above which is given to the combination of tree and TREE ( 2 ) PV of tree ( 3 ) PV of TREE : TREE has already incorporated left constituents and have accumulated their PVs ( 4 ) PV of the larger PPTs which incorporate TREE when it is completed Though oue can consider any functions for integrating the above set of PVs , we use simple addition in the present experiments. And we do not use ( 4 ) ( the PV from top-down ) in this addition. In the present experilnent~ after the PRC computes the PVs of larger PPTs incorporating the same PPT , the scheduler suspends PPTs which have low PVs cornpared with the most preferable PPT. That is , if the difference between the highest PV and the PV of a PPT exceeds a certain ( predetermined ) threshold , the PPuC suspends the PPT. We conducted various experiments by using KGW+p. In this section , we will show the experiment of disambiguating sentences containing the word that. That can be taken as a pronoun , a detenninner , a relative pronoun , a complementizer , a noun as an antecedent of a relative clause , a conjunction for an appositional clause or adverbial clause , an adverb , etc. The followings are examples we realize as preference rules in the experiment. ( Note that , in the present experiment , the PVs 6iven by independent evidences are classified into 5 ranks , most preferred ( +2 ) , more preferred ( +1 ) , neutral ( 0 ) , less preferred ( -1 ) aud least preferred ( -2 ) ) . 686 ( prul e : cat , that : type head : t ncor~oatt b| e-cases ( ( I ncomp-case : U'ee-cond ( : node-test ( = hi. cat gtthat ) ) : e~ist=9oal ( : cg ( =cat ~tbatc ) : bg ( ( : Cat Ympt ) ( : node , -test ( n~ember abs ~el f. nst : m ) ) 1 : ~J ( : cat Xnpl ) ) : t ndepeedent-evl donees ( ( 1 od=evt : vtype sere ( tr , con~-ca~e : value +1 ) ) } : tree-Good ( : node , -test ( ~ .Lode ~4*that ) ) : exist-goal ( : cg ( : cat gthatc ) : bg ( ( : cat ~.*v ) ) : n~g ( : cat ~ , vp ) ) : trtdependenL-evldennes ( ( |ed-~v| : vtype S~ ( t ncolro-case : val oe `` } 1 ) ) ) : tree-cond ( : node~test ( . re. cat ~4*IHATa ) ) : exist*goal ( : cg ( : cat % advc ) : bg ( ( : cat ~sdec ) ( rhode-test ( . aeiF. so ¢ ) ) ) : ~J ( : cat ~sdec ) ) t t ndepend~ot-evl dencus ( ( I ndevi : vt~oe prg ( tncomp-cese : value +1 ) ) ) : tree-cond ( : node~teat ( n ) , cat g*ceotdet ) ) : tndependenL-evidene~s ( ( Ind-ev| vtype pr 9 : value -2 ) ) ) Fig.6 Ex~nple of Preference Rules ( 1 ) Nouns such as fact , news , etc. are often collocated with appositional clauses. When the head of a noun phrase preceding that is one of su &amp; nouns , the apposilional clause interpolation is more preferred. ( 2 ) Wheat the verb in the sentence is one of the verbs subcategorized by that-clause , the complemeMizer ino terpretation is most preferrred. ( 3 ) When the word so or such appears iu the preceding part of the sentence , tile adverbial phrase interprelation is most preferred. ( 4 ) PP.-attachments over clauses are less preferred. ( 5 ) Omission of relative pronouns is less preferred. ( 6 ) The pronoun and determiner interprelaliou of that are less preferred in written texts. ( 7 ) Different usages of a verb have different preferences. The verb to fell , for example , has five usages , 'to tell sth to *b ' , 'to tell slh ' , 'to tell sb sth ' , 'to tell sb lhaf-cl ' and 'to tell'. The last usage ( the intransitive usage ) has the least preference. etc. An example of actuM preference rules is given in Fig. 6. The sentences in the following are used in the experinmr , t. For 1 and 2 , the SBC generates seven descriptions as follows , ( a ) \ [ s ' '' \ [ vp tell \ [ npthe \ [ n 1 fact lapp-el that sulfuric ..\ ] \ ] \ ] \ ] \ ] ( l ) ) \ [ o ... \ [ vptell \ [ npthe fact~ \ [ that ca that sulfuric '..\ ] l\ ] ( c ) C..\ [ vpteU \ [ npthe fact \ [ rel_cl\ [ npthat sulfmic\ ] ..\ ] \ ] \ [ npthe metallll ( d ) \ [ s `` '' \ [ vp teu \ [ np the \ [ npl fact \ [ app-cl \ [ np that sulfuric\ ] ..\ ] \ ] \ ] \ ] t ( e ) \ [ \ [ tell\ [ the fact\ ] \ [ \ [ that sulfurm\ ] \ ] \ ] \ ] s ' '' vp np ' that-el np ' `` `` '' ( 0\ [ .~ ... \ [ vptell \ [ npthe fact \ [ rel_clthat sulfuric ..\ ] \ ] \ ] \ [ npthe metal\ ] \ ] \ ] ' ( g ) \ [ s ' '' \ [ vp tell \ [ np tile fact \ [ app_clthat sulfuric ..\ ] \ ] \ [ npthe metal\ ] \ ] \ ] ( c ) ( g ) are rated low because they contain less preferred co , ,-structions. \ ] ~klr example , ( c ) contains tile ommision of a l'elative pronoun , the determiner interpretation of that , a PP-attachment over a clause ( the phrase lhe metal ) , etc. As tl , e result , ( c ) be-. comes tile least preferred one among the interpretations. ( a ) and ( b ) are most prelL &gt; rable for 1 and 2 , respectively .</sentence>
				<definiendum id="0">SBC</definiendum>
				<definiendum id="1">PPT</definiendum>
				<definiendum id="2">PPs</definiendum>
				<definiendum id="3">) : trtdependenL-evldennes</definiendum>
				<definiens id="0">perform tile New Rule Appliealio'~ , , operation of the basic cycle , because the reachability cmtdi ; imi may change</definiens>
				<definiens id="1">the larger lq ) 'l 's and avoid creating new PPTs in tile u..lh retriM phase. I~t order to minimize the redundaut processings in the retrial phases , Pi , ,nd ( / -- flavors provide ditlierent slots for PPTs created , in the u.4h trill and for those created in the former trials ( sec l , 'ig.3 ) . '1'1 , ( : analysis proceeds in the retrial phases in exactly the s~me way as in the first trail , but the duplication of operation : : ~re carefully avoided° ( 1 ) I'-l~ ' I a so r iloT.i-p|ii , ti : ll0 , ..ps the Inactive PP-f~.liiatailces created II1 the II~ : th retrial , ) halle. re -- ppts : kueps the , Inactive PPT -- I , ~tance , s uhlcli aro gro~n Is the s..th ratrlal I } hast~. Ilut tho saale Pl'~'~iilSialleOS Ilavo beuli created Is tho rotifer trial phases. uld-gi*ts : l~ool ) s tlio l.aetlw ) PP'l'~lltstianea~ ere , sled 1tl llio ( oi'i¢te , t trial plia~o~. ( ; ~ ) ( I-F I a , /or n~w -- ppl~ : ilO~l~S lho actlw t~P'f-.iilStallCoS ¢l'~alod Ill tll { i n-th retrial plisso+ olli-pptl~ : k~ar~ps th0 active PPl'-tastaseos cl0atcti lit , tie , for~er trial pllsses. Fit~.a internal Slraetare.s of the P-'~'lavor anti the t ; .-Flavbr S ~i'k ) x~scssal ; of Px~efex.ence i~</definiens>
				<definiens id="2">creates a set of new PP'Ps which ' , corporate the PPT. These new PP't 's represent different hypotheses b~se ( l on the same l ) ottom.-up evidence , the incorporated PP'j'. The PR , ( II computes the PVs ( plausibility vMues ) of these dif fereat hypotheses by invoking a package of preferet , ce rules. A rule package is defined for computing the l'Vs of larger PI'Ts incorpratiug the same inactive PPT. That is , ~ rule package is delined for each syntactic category ( noutermit~u.l ) of a PPT to be iitcorporated. A set of rules tot PP-attachment , tbr examt. { ! e , are defined in a package which is iuvoked when the incorporated</definiens>
				<definiens id="3">a prepositional phrase. hi order to compute PVs , we can refer ia preference rains to various sorts of inibrmatiou as follows ( we use lree and TI~EE for the incorporated PI'T and the iacorprating I'PT , respectively</definiens>
				<definiens id="4">the top node of tree ( 2 ) the top node of TREE ( 3 ) eonstitnents o1 : TREE already incorporated ( the left brothers of tree in TIIEE ) ( 4 ) sequence of active PI'Ts which eventually predict Tlg15'l ' ; ( uote that each PPT keeps the larger PPTs which will incorprate the PPT when it is completed ar.e Seclio~ 3 ) ( 5 ) lexieal inh ) rma , tion of words which appear in the right unanalyzed portion of sentences ( look-ahead ) ( 4 ) and ( ~ ) indicate the global nature o\ [ prefer ( race rules of I~ ( gW-/'p in the sense thr~t tit</definiens>
				<definiens id="5">PPs filling one of tile valences of verbs</definiens>
				<definiens id="6">adjuncts , etc. A set of , Independent-Evidences\ ] is defined lot e~ , .cll incompatible case. Wheli a set of created PPTs with the same incorporated PP'I ' are given , the PRC ilivokes a package , and for each created PI'T , it determines which e : eclusive ease matches with it. Then , the set of iudepeudenl evidences h ) r the case is ew~luatcd. Each independent evidence is expressed it , a condition-w*lue pair and , if the condition matches with the created PPT , it returns the specified value. The PRO gets a set of values from the independent evidences , each of which is a primitive PV based o , t a certain aspect of the PPT such as semantic intimacy of words , welbtbrmedness of syntactic trees , etc. By combining the values with a certain function ( currently~ we use simple addition as this 685 function ) , the PRC determines the PV for the incorporation of tree into TREE. ( PRUI , E : CAT { one of the syntactic Categories } : TYPE Inon-head. |lead }</definiens>
				<definiens id="7">tree-cond ( ( eonditlon of ¢asel } ) : independent-evidences l lcondition of ovidnacell Ivalue } ) ( condition of ovidenceZ } Ival~le\ ] ) { condition of evidence3 } ( value } ) : tree-toad ( Icondltion of case2 } ) : independent-evidences Fig. 5 Format of the Preference Rules Tile actual PV of tile created PPT is deterilniued by tile combination of ( 1 ) PV in the above which is given to the combination of tree and TREE ( 2 ) PV of tree ( 3 ) PV of TREE : TREE has already incorporated left constituents and have accumulated their PVs ( 4 ) PV of the larger PPTs which incorporate TREE when it is completed Though oue can consider any functions for integrating the above set of PVs</definiens>
				<definiens id="8">the present experilnent~ after the PRC computes the PVs of larger PPTs incorporating the same PPT , the scheduler suspends PPTs which have low PVs cornpared with the most preferable PPT. That is , if the difference between the highest PV and the PV of a PPT exceeds a certain ( predetermined ) threshold , the PPuC suspends the PPT.</definiens>
				<definiens id="9">preference rules in the experiment. ( Note that , in the present experiment , the PVs 6iven by independent evidences are classified into 5 ranks , most preferred ( +2 ) , more preferred ( +1 )</definiens>
				<definiens id="10">node-test ( = hi. cat gtthat ) ) : e~ist=9oal ( : cg ( =cat ~tbatc ) : bg ( ( : Cat Ympt ) ( : node</definiens>
				<definiens id="11">cat gthatc ) : bg ( ( : cat ~.*v ) ) : n~g ( : cat ~ , vp )</definiens>
				<definiens id="12">node~test ( . re. cat ~4*IHATa ) ) : exist*goal ( : cg ( : cat % advc ) : bg ( ( : cat ~sdec ) ( rhode-test ( . aeiF. so ¢ ) ) ) : ~J ( : cat ~sdec )</definiens>
				<definiens id="13">node~teat ( n ) , cat g*ceotdet ) ) : tndependenL-evidene~s ( ( Ind-ev| vtype pr 9 : value -2 ) ) ) Fig.6 Ex~nple of Preference Rules ( 1 ) Nouns such as fact , news , etc. are often collocated with appositional clauses. When the head of a noun phrase preceding that is one of su &amp; nouns , the apposilional clause interpolation is more preferred. ( 2 ) Wheat the verb in the sentence is one of the verbs subcategorized by that-clause , the complemeMizer ino terpretation is most preferrred. ( 3 ) When the word so or such appears iu the preceding part of the sentence , tile adverbial phrase interprelation is most preferred. ( 4 ) PP.-attachments over clauses</definiens>
				<definiens id="14">the intransitive usage ) has the least preference. etc. An example of actuM preference rules is given in Fig. 6. The sentences in the following are used in the experinmr , t. For 1 and 2 , the SBC generates seven descriptions as follows , ( a ) \ [ s ' '' \ [ vp tell \ [ npthe \ [ n 1 fact lapp-el that sulfuric ..\ ] \ ] \ ] \ ] \ ] ( l ) ) \ [ o ... \ [ vptell \ [ npthe fact~ \ [ that ca that sulfuric '..\ ] l\ ] ( c ) C..\ [ vpteU \ [ npthe fact \ [ rel_cl\ [ npthat sulfmic\ ] ..\ ] \ ] \ [ npthe metallll ( d ) \ [ s `` '' \ [ vp teu \ [ np the \ [ npl fact \ [ app-cl \ [ np that sulfuric\ ] ..\ ] \ ] \ ] \ ] t ( e ) \ [ \ [ tell\ [ the fact\ ] \ [ \ [ that sulfurm\ ] \ ] \ ] \ ] s ' '' vp np ' that-el np ' `` `` '' ( 0\ [ .~ ... \ [ vptell \ [ npthe fact \ [ rel_clthat sulfuric ..\ ] \ ] \ ] \ [ npthe metal\ ] \ ] \ ] ' ( g ) \ [ s ' '' \ [ vp tell \ [ np tile fact \ [ app_clthat sulfuric ..\ ] \ ] \ [ npthe metal\ ] \ ] \ ] ( c ) ( g ) are rated low because they contain less preferred co , ,-structions. \ ] ~klr example , ( c ) contains tile ommision of a l'elative pronoun , the determiner interpretation of that , a PP-attachment over a clause ( the phrase lhe metal ) , etc. As tl , e result , ( c ) be-. comes tile least preferred one among the interpretations. ( a ) and ( b ) are most prelL &gt; rable for 1 and 2 , respectively</definiens>
			</definition>
			<definition id="4">
				<sentence>'Phe scheduler , which is a kind of demo 's watching the SBC , loosely controls the whole parsing process by utilizing PVs ( Plausibility Values ) given by the PRC ( Preference Rating Con &gt; ponent ) .</sentence>
				<definiendum id="0">'Phe scheduler</definiendum>
				<definiens id="0">a kind of demo 's watching the SBC</definiens>
			</definition>
			<definition id="5">
				<sentence>The PRC uses the preference type of knowledge to compute the PVs .</sentence>
				<definiendum id="0">PRC</definiendum>
				<definiens id="0">uses the preference type of knowledge to compute the PVs</definiens>
			</definition>
</paper>

		<paper id="2144">
			<definition id="0">
				<sentence>Kamp , Rohrer , Partee ) descriptive typological studies ( cf. Comrie ) As a starting point I take the temporal structure &lt; T , &lt; , ca &gt; , where T is a set of intervals , &lt; is a binary relation that linearly orders time ( precedence ) , and n is a binary operation on intervals ( intersection ) .</sentence>
				<definiendum id="0">T</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">a set of intervals</definiens>
				<definiens id="1">a binary relation that linearly orders time ( precedence ) , and</definiens>
				<definiens id="2">a binary operation on intervals</definiens>
			</definition>
			<definition id="1">
				<sentence>-~- &gt; The intersection of two intervals is that subpart of the intervals which they have in common : I J InJ Given the temporal structure &lt; T , &lt; , n &gt; , the number of possible relations between intervals can be determined in a principled way : for any ordered pair of intervals ( I and J ) , it will be the case that either I ca J = O and then &lt; ( l , J ) or &gt; ( I , J ) I -- ~-~ -- ~ ( preceed ) J I -- ~-~ -- - &gt; ( follow ) J or InJ¢ : O andthen It~J=l and lnJ=J I = ( I , J ) ... ... .. ~ -- -~ J ( identity ) or InJ=l and lnJc : J I c ( I ' , J ) = -- &gt; J @ art-of ) o1 '' I ~ J ¢ : I and I n J = J I ~ ( l , J ) ... . ~ -- -- 4 J ( inclusion ) 699 or l c3 J : / : l and l ¢~ J ¢ J I &lt; &lt; ( I , J ) - .</sentence>
				<definiendum id="0">InJ Given</definiendum>
				<definiens id="0">the temporal structure &lt; T , &lt; , n &gt; , the number of possible relations between intervals can be determined in a principled way : for any ordered pair of intervals ( I</definiens>
			</definition>
			<definition id="2">
				<sentence>Tense meanings will be defined as relations between a time of reference and a time of speech : Rel ( R , S ) .</sentence>
				<definiendum id="0">Tense meanings</definiendum>
			</definition>
			<definition id="3">
				<sentence>The former is a possible me , 'ming in languages which make a basic distinction between Future ( { post } ) and non-Fut~e ( { ante , simul } ) ; the latter is a possible meaning in languages which make a basic distinction between Past ( { ante } ) and non-Past ( { post , simul } ) .</sentence>
				<definiendum id="0">non-Fut~e</definiendum>
				<definiendum id="1">non-Past</definiendum>
				<definiens id="0">a possible me , 'ming in languages which make a basic distinction between Future ( { post }</definiens>
				<definiens id="1">a possible meaning in languages</definiens>
			</definition>
			<definition id="4">
				<sentence>tions can he assigned to file tense forms one can make nse of a grammatie , 'dity test : a tense from X can have a meaning Y ( where Y is any of { simultaneous , anterior , posterior } ) , if and only if it can be combined with a deictic adverbial of type Y. The application of this test to English the following results : Er~glish : and French yields French : Present -4 { post , simul } Past ~-~ { ~nte } Future ~ { post } Conditional ~-~ 0 PrEsent ~ { post , simul } Futur ~ { post } lmparfalt -- ~ { ante } Condifionnel -- ~ 0 Pas~ -- o { ante } The conditional tenses get the value O since they do not have a temporal meaning in single isolated clauses ( cf. The model presented so far is useftd for the analysis of isolated clauses .</sentence>
				<definiendum id="0">'dity test</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">any of { simultaneous , anterior , posterior }</definiens>
			</definition>
			<definition id="5">
				<sentence>br English , the set of aspectual auxiliaries can be defined as follows : aspect O ¢5 have O f~ be have be O be have be l ; br French , aspect lonn -- ) ( have+papa ) ( be+prpa ( go+to-int ) ) f~ = Simple rain O = Perfect have rained O = Progressive be mining O =Perf Progr have been raining go = Go be going to rain go = Perfect Go have been going to rain the definition looks as follows : lbrm -- &gt; \ [ avoir/~tre+papaaller+inf \ ] O = Simple pleuvoir avoir/~tre = Compost avoir plu aller = Futur proche aller pleuvoir As tor the assignment of meanings to the auxiliaries I will follow the same procedure as for the tense meanings .</sentence>
				<definiendum id="0">aspectual auxiliaries</definiendum>
				<definiens id="0">the definition looks as follows : lbrm -- &gt; \ [ avoir/~tre+papaaller+inf \ ] O = Simple pleuvoir avoir/~tre = Compost avoir plu aller = Futur proche aller pleuvoir As tor the assignment of meanings to the auxiliaries I will follow the same procedure as for the tense meanings</definiens>
			</definition>
			<definition id="6">
				<sentence>The meaning of an aspect form is an element of the power set of possible aspect meanings .</sentence>
				<definiendum id="0">meaning of an aspect form</definiendum>
				<definiens id="0">an element of the power set of possible aspect meanings</definiens>
			</definition>
			<definition id="7">
				<sentence>Eurotra is a transfer based system .</sentence>
				<definiendum id="0">Eurotra</definiendum>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>After the first work on machine-readable dictiona , 'ies ( MRI ) s ) in the seventies ( see Olney 1972 , Sherman 1974 ) , and with the recent development oI~the concept of'a lexical database ( l.l ) B ) in which interaction , flexibility and multidiinensionality can be achieved , but everything must be explicitly stated in advance ( see e.g. Amsler 1980 , Byrd 1983 , Calzolari 1982 , Michiels 1980 ) , a new possibility which is now emerging is that o1 '' a procedural exploitation of the lull range of semantic intbrmation implicitly contained in MRI ) s ( see Wilks 1987 , Binot 1987 , Alshawi forthcoming , Calzolari forthcoming ) .</sentence>
				<definiendum id="0">Calzolari forthcoming</definiendum>
				<definiens id="0">l.l ) B ) in which interaction , flexibility</definiens>
			</definition>
			<definition id="1">
				<sentence>The disambiguator consists partly in rules generally valid for Italian , based on the immediate right and left context , and partly in ad hoc rules written for the particular syntax used in lexicographic definitions .</sentence>
				<definiendum id="0">disambiguator</definiendum>
				<definiens id="0">consists partly in rules generally valid for Italian , based on the immediate right and left context , and partly in ad hoc rules written for the particular syntax used in lexicographic definitions</definiens>
			</definition>
			<definition id="2">
				<sentence>Entry ( EDITORE ) Def I che o chi stampa e pubblica libri , periodici musica , a scopo commerciale } F che ) L ( che , \ [ 'PR ' , \ [ 'NN'\ ] \ ] ) F o ) L ( o , \ [ 'C ' , \ [ ' '\ ] \ ] ) F chi ) L ( chi , \ [ 'PR ' , \ [ 'NS'\ ] \ ] ) F stampa ) L ( stampare , \ [ 'VTP ' , \ [ 'S31P'\ ] \ ] ) E e ) L ( e , \ [ 'CC ' , \ [ ' '\ ] \ ] ) F pubbl ica ) L ( pubblicare , \ [ 'VT ' , \ [ 'S31P'\ ] \ ] ) F libri ) L \ [ fibre , \ [ 'SW , \ [ 'MP'\ ] \ ] ) P , ) F periodici ) L ( periodico , \ [ 'SM ' , \ [ 'MP'\ ] \ ] ) e ( o ) L ( o , \ [ 'C ' , \ [ ' '\ ] \ ] ) F ( musica ) L ( musica , \ [ 'SF ' , \ [ 'FS'\ ] \ ] ) P ( , ) F ( a ) L ( a , \ [ 'E ' , \ [ ' '\ ] \ ] ) F ( scopo ) L ( seopo , \ [ 'SM ' , \ [ 'MS'\ ] \ ] ) F ( eommerciale ) L ( commerciale , \ [ 'A ' , \ [ 'NS '\ ] \ ] ) ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... Fig .</sentence>
				<definiendum id="0">Entry</definiendum>
				<definiens id="0">F libri ) L \ [ fibre</definiens>
			</definition>
			<definition id="3">
				<sentence>I'heretbre , after the first stage , the system consists of patterns augmented with conditioning rules which will then drive subsequent runnings of tile procedure ( \ [ br those cases which are lexically or grammatically conditioned ) .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of patterns augmented with conditioning rules which will then drive subsequent runnings of tile procedure ( \ [ br those cases which are lexically or grammatically conditioned )</definiens>
			</definition>
</paper>

		<paper id="2140">
			<definition id="0">
				<sentence>For syntactic reasons , its filler must be the head of the superordinated PP/NP `` Stoffe '' o The semantic restriction of the SUBJ slot is MATERIAL which is compatible with the noun `` Stoffe '' , so the slot may be filled ( note that SUBJ is the transformed syntactic /'estriction which had been DOBJ before the passive transformation had taken place ) o Thus , a third constituent has been added to the pool of collected constituents° The global control structure ce*rtinues by processing the next entry , the representation of the word `` bezieht '' , which is a finite verb and has to be at the second position according to German grammar° It is set aside for later processing and a special state is entered , knowing that exactly one constituent has been left over° The PP/NP `` in Wien '' is processed , and a corresponding casef~ame is created .</sentence>
				<definiendum id="0">MATERIAL</definiendum>
				<definiendum id="1">SUBJ</definiendum>
				<definiens id="0">the transformed syntactic /'estriction which had been DOBJ before the passive transformation had taken place</definiens>
				<definiens id="1">a finite verb and has to be at the second position according to German grammar° It is set aside for later processing and a special</definiens>
			</definition>
</paper>

		<paper id="1074">
			<definition id="0">
				<sentence>Abstracts : SAG~ ( Sentence Analysis and GEneration system ) is an operational parsing and generating system .</sentence>
				<definiendum id="0">GEneration system )</definiendum>
				<definiens id="0">an operational parsing and generating system</definiens>
			</definition>
			<definition id="1">
				<sentence>~endo ronoun handling par o and generatio ~th~ ° ~guh~ic ~brmation ~ needed for reference x~so\ ] utlOno The ehsracteristic~ stored for each token are the tm~t ~mnber within the dialogue ( ~ turn ie over whenever one of the two locutors ha~ fiuished speaking ) , the sentence number within the tm~n~ the locutor ( during pa~sing , the locutor is the ~mer , where~ during gen~ation , ~t is the system ) , the type of the token ( entity or relation ) ~ and the linguistic ¢xpregsion ( noun phrase , pronoun , demormtrative pronoun , clause ) .</sentence>
				<definiendum id="0">locutor</definiendum>
				<definiendum id="1">~t</definiendum>
				<definiens id="0">the system</definiens>
			</definition>
			<definition id="2">
				<sentence>\ [ Danlos 87a\ ] Laurence Danlos , A French and English Syntactic Gomponent for Generation , Natural Language Generation : New R.ssults in Artificial Intelligence , Psychology and Linguistics , Kempen G. ed , Dortrecht/Boston , Martinus Nijhoff Publishers , 1987 .</sentence>
				<definiendum id="0">Laurence Danlos</definiendum>
				<definiens id="0">A French and English Syntactic Gomponent for Generation</definiens>
			</definition>
			<definition id="3">
				<sentence>\ [ Jacobs 85\ ] Paul S. Jacobs , PHRED : A Generator for Natural Language Interfaces , Computational Linguistics , Vol .</sentence>
				<definiendum id="0">PHRED</definiendum>
				<definiens id="0">A Generator for Natural Language Interfaces</definiens>
			</definition>
</paper>

		<paper id="2118">
			<definition id="0">
				<sentence>The penultimate phoneme /a/in `` ebaitaai '' , for example , is an extra phoneme .</sentence>
				<definiendum id="0">penultimate phoneme /a/in</definiendum>
				<definiens id="0">an extra phoneme</definiens>
			</definition>
			<definition id="1">
				<sentence>The Generalized LR parsing algorithm is a table driven shift-reduce parsing algorithm that can handle arbitrary context-free grammars in polynomial time .</sentence>
				<definiendum id="0">Generalized LR parsing algorithm</definiendum>
				<definiens id="0">a table driven shift-reduce parsing algorithm that can handle arbitrary context-free grammars in polynomial time</definiens>
			</definition>
			<definition id="2">
				<sentence># 32 &gt; U &lt; B-9 # 2 &gt; ( ( MOOD ( ( ROOT DEC ) ) ) ( OBJ-CRSE O ) ( SUBJ-CRSE GR ) ( CRUS @ TIUE - ) ( PRSBIUE m ) ( SUBCRT TRRMO ) ( SEM *MRKE -- CLERM248 ) ( TIME ( ( ROOT ( *OR* PRESEMT FUTURE ) ) ) ) ( CRT U ) ( ROOT RI~FIU ) ) T Command : I ~-~- ; ; , ,-w~ : -- -- -~ , I I I I I I II Dynamic Lisp Listener 12 Sample Run 1 25 : `` KURI*RKOOIRTEIRU= ' ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...</sentence>
				<definiendum id="0">MOOD</definiendum>
				<definiens id="0">CRUS @ TIUE - ) ( PRSBIUE m ) ( SUBCRT TRRMO ) ( SEM *MRKE -- CLERM248 ) ( TIME ( ( ROOT ( *OR* PRESEMT FUTURE ) ) ) ) ( CRT U ) ( ROOT RI~FIU ) ) T Command : I ~-~- ; ;</definiens>
			</definition>
			<definition id="3">
				<sentence>-18 # O &gt; R &lt; 18-19 # 2 &gt; B &lt; 2 @ -21 # 9 &gt; R &lt; 22-23 # 32 &gt; 0 &lt; 23-24 # -10 &gt; T &lt; 24-25 # 31 &gt; E &lt; 26-27 # 30 &gt; I &lt; 28-29 # 36 &gt; R &lt; 30-31 # 31 &gt; U &lt; 32-33 # 29 &gt; ( ( MOOD ( ( ROOT DEC ) ) ) ( SEM *HRUE-R-BTIFFMESE1268 ) ( OBJ ( ( : HH - ) ( OROE OR ) ( SEM *MECK ) ( ROOT KUBI ) ) ) ( CRUSRTIUE - ) ( OBJ-ORBE OR ) ( SUBJ-CRSE OR ) ( PRSSIVE - ) ( BUBORT STRT ) ( TIME ( ( ROOT ( *ORs PREOEMT FUTURE ) ) ) ) ( PROOREGBIUE * ) ( ORT U ) ( ROOT KOMRBRRU ) ) 2 : ( 372 ) K &lt; 2-3 # 28 &gt; 0 &lt; 4-5 # 10 &gt; R &lt; 6- ?</sentence>
				<definiendum id="0">BUBORT STRT ) ( TIME ( ( ROOT</definiendum>
				<definiens id="0">MOOD ( ( ROOT DEC ) ) ) ( SEM *HRUE-R-BTIFFMESE1268 ) ( OBJ ( ( : HH - )</definiens>
			</definition>
			<definition id="4">
				<sentence>T ) ( BEM *HRUE-R-BTIFFMESS214 ) ( TIME ( ( ROOT ( *OR* PRESEHT FUTURE ) ) ) ) ( PROGRESSIVE ÷ ) ( CRI U ) ( ROOT KOHRBRRU ) ) 2 : ( 372 ) K &lt; 2-9 # 28 &gt; 0 &lt; 4-5fllO &gt; R &lt; 6-7 # 31 &gt; E ( B-9 # 2 &gt; G ( 18-11 # 33 &gt; R ( 12-19 # 32 &gt; K ( 14-15 # 28 &gt; 0 &lt; 16-17424 &gt; M &lt; l~-lB # @ &gt; R &lt; 18-19 # 2 &gt; B ( 28-21~9 &gt; R &lt; 22-23f102 ) Q &lt; 23-24 # -18 &gt; T &lt; 24-25 # 31 &gt; E &lt; 2G-27 # OO &gt; I &lt; 28-29 # 3 @ &gt; R &lt; 30-31 # 31 &gt; U &lt; 32-OO # ~ &gt; ( ( MOOD ( ( ROOT DEC ) ) ) ( OUBJ ( ( : NH - ) ( CRBE OR ) ( ROOT KORE ) ) ) ( BUBJ-CRSE OR ) ( OBJ-CRBE OR ) ( CRUBRTIUE - ) ( PRBBIUE - ) ( SUBCRT ETRT ) ( SEM *HRUE-R-BTIFFMERB214 ) ( TIME ( ( ROOT ( *OR* PREBEHT FUTURE ) ) ) ) ( PROgREBSIYE ÷ ) ( CRT U ) ( ROOT KO~RBRRU ) ) 4 : ( 279 ) K &lt; 2-3 # 28 &gt; U ( 4-5 # 29 &gt; B &lt; 6-7 # 5 &gt; I &lt; B-O # Og &gt; G &lt; 1 @ -11 # 33 &gt; R¢12-18M32 &gt; K &lt; 14-15 # 28 &gt; 0 ( 16-17 # 24 &gt; N &lt; 17-18 # g &gt; R &lt; 18-19 # 2 &gt; B &lt; 28-21 # 9 &gt; ' R &lt; 22-23 # 32 &gt; Q &lt; 23-24 # -19 &gt; T &lt; 24-25 # 31 &gt; R &lt; 26-27 # G &gt; ( ( MOOD ( ( ROOT DEC ) ) ) ( SEM *HRUE-R-BTIFFMEBB1264 ) ( OBJ ( ( : HH - ) ( SRSE OR ) ( SEN ~HEOK ) ( ROOT KUBI ) ) ) ( CRUORTIUE - ) ( OBJ-CROE GO ) ( SUBJ-CRSE DR ) ( PRBBIVE - ) ( BUBCRT STRT ) ( TIME ( ( ROOT PRST ) ) ) ( ORT V ) ( ROOT KOWRBRRU ) ) 5 : ( 256 ) K &lt; 2-3 # 28 &gt; 0 &lt; 4-5 # 1D &gt; R &lt; 6-7 # 31 &gt; E &lt; 8-9 # 2 &gt; g &lt; 18-11 # 33 &gt; R ( 12-13 # 32 &gt; K &lt; 14-15 # 28 &gt; 0 &lt; 16-17 # 24 &gt; M &lt; 1~-18 # 8 &gt; R &lt; 10-19 # 2 &gt; B &lt; 20-21 # 9 &gt; R &lt; 22-23 # 32 &gt; O &lt; 23-24 # -10 &gt; T &lt; 24-25 # 31 &gt; R &lt; 26-2 ?</sentence>
				<definiendum id="0">T ) ( BEM *HRUE-R-BTIFFMESS214 )</definiendum>
				<definiendum id="1">MOOD ( ( ROOT DEC ) ) ) ( OUBJ</definiendum>
				<definiens id="0">NH - ) ( CRBE OR ) ( ROOT KORE ) ) ) ( BUBJ-CRSE OR ) ( OBJ-CRBE OR ) ( CRUBRTIUE - ) ( PRBBIUE - ) ( SUBCRT ETRT ) ( SEM *HRUE-R-BTIFFMERB214 ) ( TIME ( ( ROOT ( *OR* PREBEHT FUTURE ) ) ) ) ( PROgREBSIYE ÷ ) ( CRT U ) ( ROOT KO~RBRRU )</definiens>
				<definiens id="1">HH - ) ( SRSE OR ) ( SEN ~HEOK ) ( ROOT KUBI ) ) ) ( CRUORTIUE - ) ( OBJ-CROE GO ) ( SUBJ-CRSE DR ) ( PRBBIVE - )</definiens>
			</definition>
			<definition id="5">
				<sentence># G &gt; ( ( HOOD ( ( ROOT DEC ) ) ) ( OBJ ( ( : WH - ) ( CRBE GR ) ( ROOT KORE ) ) ) ( CRUBRTIVE - ) ( OBJ-ORBE OR ) ( OUBJ-CRBE OR ) ( PRSSIVE - ) ( BUBORT BTRT ) ( SEM *HRUE-R-BTIFFMEBSOB ) ( TIME ( ( ROOT PRST ) ) ) ( CRT V ) ( ROOT KOMRBRRU ) ) 5 : ( 258 ) K &lt; 2-3 # 20 &gt; 0 &lt; 4-5 # 10 &gt; R &lt; S-7 # 51 &gt; E &lt; B-9 # 2 &gt; O &lt; 10-11 # 33 &gt; R ( 12-13 # 32 &gt; K &lt; 14-15 # 28 &gt; 0 &lt; 16-17 # 24 &gt; M &lt; 17-16 # O ) R &lt; lB-19 # 2 &gt; B &lt; 28-21 # 9 &gt; R &lt; 22-23 # 32 &gt; O &lt; 23-24 # -18 &gt; T ( 24-25 # 51 &gt; R &lt; 26-2 ?</sentence>
				<definiendum id="0">HOOD ( ( ROOT DEC ) ) ) ( OBJ</definiendum>
				<definiens id="0">WH - ) ( CRBE GR ) ( ROOT KORE ) ) ) ( CRUBRTIVE - ) ( OBJ-ORBE OR ) ( OUBJ-CRBE OR ) ( PRSSIVE - ) ( BUBORT BTRT ) ( SEM *HRUE-R-BTIFFMEBSOB ) ( TIME ( ( ROOT PRST ) ) ) ( CRT V ) ( ROOT KOMRBRRU</definiens>
			</definition>
			<definition id="6">
				<sentence># fi &gt; ( ( MOOD ( ( ROOT DEC ) ) ) ( BUBJ ( ( : HH - ) ( CROE SO ) ( ROOT ~DRE ) ) ) ( BUBJ-CRBE OR ) ( OBJ-CRBE OR ) ( CRUORTIVE - ) ( PRBBIVE - ) ( BUBCRT OTRT ) ( SEM *HRVE-R-BTIFFMESBOB ) ( TIME ( ( ROOT PRST ) ) ) ( CRTrf~/ ) ( ROOT KOWRBRRU ) ) 7 : ( 232 ) K &lt; 2-3 # 2B &gt; 0 &lt; 4-5 # 10 &gt; R &lt; 6-7~31 ) E &lt; B-9 # 2 &gt; G &lt; lS-11 # 33 &gt; R &lt; 12-13 # B2 &gt; K &lt; 14-15 # 28 &gt; 0 &lt; 16-17 # 24 &gt; N &lt; 26-21 # 5 &gt; R &lt; 22-23 # 32 &gt; 1 &lt; 26-27 # 7 &gt; ( ( MOOD ( ( ROOT DEC ) ) ) ( BUBJ ( ( : NH - ) ( ORSE OR ) ( ROOT KORE ) ) ) ( SUBJ-CRGE OR ) ( CAUSATIVE - ) ( PROBIVE - ) ( OUBCRT INTRRNB ) ( SEM *PTRRHSBBO ) ( TIME ( ( ROOT PRESENT ) ) ) ( MEORTION ( ( ROOT HITEI ) ) ) ( CRT V ) ( ROOT KURU ) ) **MORE**I I !</sentence>
				<definiendum id="0">MOOD ( ( ROOT DEC ) ) ) ( BUBJ</definiendum>
				<definiendum id="1">ROOT KORE ) ) ) ( SUBJ-CRGE OR )</definiendum>
				<definiens id="0">MOOD ( ( ROOT DEC ) ) ) ( BUBJ ( ( : HH - ) ( CROE SO ) ( ROOT ~DRE ) ) ) ( BUBJ-CRBE OR ) ( OBJ-CRBE OR ) ( CRUORTIVE - ) ( PRBBIVE - ) ( BUBCRT OTRT ) ( SEM *HRVE-R-BTIFFMESBOB ) ( TIME ( ( ROOT PRST ) ) ) ( CRTrf~/ ) ( ROOT KOWRBRRU</definiens>
			</definition>
</paper>

		<paper id="2161">
			<definition id="0">
				<sentence>This delimitation consists in the localisation of a referent in the speech or textual context or the non-linguistic situation or in relation to the presupposed knowledge of the hearer or reader ( only the first of these functions , and this again in a rather restricted way , may be represented in the EUROTRA system ) .</sentence>
				<definiendum id="0">delimitation</definiendum>
				<definiens id="0">consists in the localisation of a referent in the speech or textual context or the non-linguistic situation or in relation to the presupposed knowledge of the hearer or reader</definiens>
			</definition>
			<definition id="1">
				<sentence>The German noun in this case is `` count '' , `` individual '' , `` discontinuous '' , that is `` atomic '' in the case of a oneelement set and `` discrete '' in the case of a set which has • more than one element .</sentence>
				<definiendum id="0">German noun</definiendum>
				<definiens id="0">atomic '' in the case of a oneelement set and `` discrete '' in the case of a set which has • more than one element</definiens>
			</definition>
			<definition id="2">
				<sentence>In this representation the ENTITYnode is the axiom and each node is subspecified either by a disjunction of features , which we represent by the solidlined edges , or by a conjunction of features which we indicate by the `` + '' marked edges .</sentence>
				<definiendum id="0">ENTITYnode</definiendum>
				<definiens id="0">the axiom and each node is subspecified either by a disjunction of features , which we represent by the solidlined edges , or by a conjunction of features which we indicate by the `` + '' marked edges</definiens>
			</definition>
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>The movement transformation is one of the major problems encountered in natural language processing .</sentence>
				<definiendum id="0">movement transformation</definiendum>
				<definiens id="0">one of the major problems encountered in natural language processing</definiens>
			</definition>
			<definition id="1">
				<sentence>( l &lt; j &lt; n ) is , a lexical terminal or J J _ . a phrasal non-terrmnal. ( b ) c ( Arg ) -- &gt; Cl ( Argl ) , C2 ( Arg2 ) , ... , ei ( Argi ) , trace ( TraceArg ) , c ( i+ I ) ( Argo+ 1 ) ) , ' '' , cn ( Argn ) '' where the definitions of c ( Arg ) and cj ( Argj ) ( l &lt; j &lt; n ) are the same as above , trace ( 'rraceArg ) is a virtual non-terminal. The special case i=O is common. For example , a noun phrase is topicalized from a subject position. It is represented as s - &gt; trace , np .</sentence>
				<definiendum id="0">cj</definiendum>
			</definition>
			<definition id="2">
				<sentence>A sample grammar GBLG1 for Chinese shown below introduces lhe uses of the formalism : ( rl ) slbm ' ( slbar ( Topie , S ) ) -- &gt; topic ( Topic ) &lt; &lt; &lt; traeeT ( Topic ) , s ( S ) .</sentence>
				<definiendum id="0">sample grammar GBLG1</definiendum>
				<definiens id="0">s ( S )</definiens>
			</definition>
			<definition id="3">
				<sentence>For a phrasal non-terminal X , a virtual non-terminal Y and a transitive relation TR , X TRY if ( 1 ) X is the rule head of a grammar rule , and Y is an element in its rule body , or ( 2 ) X is the rule head of a grammar rule , a phrasal non-terminal I in its rule body , and I TR Y , or ( 3 ) there exists a sequence of phrasal non-terminals I 1 , 12 ... .. I n , such that X TR I I TR 12 TR ... TR I n. The transitive relation TR is also a dominate relation .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiendum id="2">X</definiendum>
				<definiens id="0">an element in its rule body</definiens>
			</definition>
			<definition id="4">
				<sentence>The c-command theory is embedded implicitly in the GBLGs if ~very grammar rules satisfy the following property : for a rule X 0 -- &gt; X1 , X2 , ... , X m where X i is a terminal or a non-terminal , la i ~ m , if Xi= ( A &lt; &lt; &lt; B ) then there must exist some Xj ( i &lt; j &lt; m ) ; such that Xj dominates the virtual non-terminal B in other grammar rule. That is , Xj TR B. The phrasal non-terminal X 0 is the first branching node that dominates A and Xj , and thus also dominates B. Therefore , A c-commands B. Xi= ( B &gt; &gt; &gt; A ) has the similar behavior .</sentence>
				<definiendum id="0">X i</definiendum>
				<definiens id="0">for a rule X 0 -- &gt; X1 , X2 , ... , X m where</definiens>
				<definiens id="1">a terminal or a non-terminal</definiens>
				<definiens id="2">the first branching node that dominates A and Xj , and thus also dominates B. Therefore , A c-commands B. Xi= ( B &gt; &gt; &gt; A ) has the similar behavior</definiens>
			</definition>
			<definition id="5">
				<sentence>A A trace ( the empty constituent ) Fio .</sentence>
				<definiendum id="0">A trace</definiendum>
			</definition>
			<definition id="6">
				<sentence>When c is a bounding node , e.g. rule ( r4 ) , the information is used to check the x-list transferred up .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">a bounding node , e.g. rule ( r4 ) , the information is used to check the x-list transferred up</definiens>
			</definition>
			<definition id="7">
				<sentence>3°3.2 The leftward movement grammar rules The leftward movement grammar rnles can be generalized as below : c ( Arg ) o- &gt; c 1 ( Arg 1 ) , c2 ( Arg2 ) ... .. ci ( Argi ) &lt; &lt; &lt; trace ( TraceArg ) , c ( i+ 1 ) ( Arg ( i+ 1 ) ) ... .. cn ( Argn ) . The rule ( rl ) is an example. Its translation is shown as follows : cl ( G , Argl , H1 , X1 , X ) : goal ( c2 , Arg2 , H2 , X1 , X2 ) , goal ( ci , Argi , Hi , X ( i-1 ) , Xi ) , goal ( c0+l ) , Arg ( i+l ) , H ( i+l ) , Xi , X ( i+l ) ) , goal ( cn , Argn , Hn , X ( n1 ) , Xn ) , merge ( \ [ H ( i+l ) ... .. Hn\ ] , T1 ) , cuLtrace ( x ( trace ( TraceArg ) , Bound , left ) , T1 , T2 ) , merge ( \ [ H1 , H2 , ... Hi , T2\ ] , H ) , c ( G , Arg , H , Xn , X ) . Comparing this translation with that of general grammar rules , we can find a new predicate cut_ .trace is added. The cut trace implements tile c-command principle , and its definition i~. cnLtrace ( Trace , \ [ Y , X\ ] , \ [ Y 1 , X\ ] ) : ( var ( Y ) , ! , ( l'race=x ( TraceIn fo , Bound , left ) , ! ; fail ) ; cut traceaux ( Trace , Y , Y1 ) ) . cnLtraceaux ( Trace , \ [ TracelXs\ ] , Xs ) : ! . cut traceaux ( Trace , \ [ HIX\ ] , \ [ HIY\ ] ) : ( vat ( X ) , ! , ( Trace=x ( TraceInfo , Bound , left ) , ! ; fail ) ; cut_traceaux ( Tracc , X , Y ) ) . The cut trace tries to retract a trace from x-list if a movement exists. ~landarin Chinese has many specific features that oilier languages do not have. For example , topic-comment structure does not always involve movement transformation. The first cut traeeauz chmse matches the trace information with the x-list ~ransferred f , 'om the bottom on its right part. The second cut traceatrc tells us that if the expected leftward trace can not ma~h one of the elements in the x-list , then it will be drop out. The x-list is not changed and transferred up. The concept is demonstrated in Fig. 4. It also explains why we can detect grammar errors before parsing. In summary , each movement non-terminal is decomposed into a phrasal non-terminal and a vimml non-.tet~ninal. The phrasal non-terminal is translated the 'same as before. The vktual non-terminal is represented as x ( tr ace ( l YaceA r g ) , Bound , left ) in this case , however , cut_trace is involved instead of merge. Because we treat the leftward and the rightward movement grammar rules in a uniform way , the translation algorithm of both are similar. The rightward movement gr~n~nar ruks are wifll the following format : c ( Arg ) -- &gt; c l ( Arg l ) , C2 ( Arg2 ) ... .. lxace ( TraceArg ) &gt; &gt; &gt; ci ( Argi ) , c ( i+l ) ( Arg ( i+l ) ) , ' '' , cn ( Argn ) '' The rule ( r9 ) is an example .</sentence>
				<definiendum id="0">Arg</definiendum>
				<definiendum id="1">Arg</definiendum>
				<definiendum id="2">rule</definiendum>
				<definiendum id="3">Hi , X</definiendum>
				<definiendum id="4">Arg ( i+l</definiendum>
				<definiendum id="5">Arg</definiendum>
				<definiens id="0">x ( trace ( TraceArg ) , Bound , left ) , T1 , T2 ) , merge ( \ [ H1 , H2 , ... Hi</definiens>
			</definition>
			<definition id="8">
				<sentence>\ [ 2 \ ] Yuji Matsumoto , Hozumi Tanaka , et al. , `` BUP : A Bottom-Up Parser Embedded in Prolog , '' New Generation Computing , Vol .</sentence>
				<definiendum id="0">BUP</definiendum>
			</definition>
			<definition id="9">
				<sentence>\ [ 4 \ ] Yuji Matsumoto , Hozurni Tanaka , and Masaki Kiyono , `` BUP : A Bottom-Up Parsing System for Natural Languages , '' in Warren , D.H.D. and M. Canegham ( eds . )</sentence>
				<definiendum id="0">BUP</definiendum>
				<definiens id="0">A Bottom-Up Parsing System for Natural Languages , '' in Warren</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>The grammars consist of actual sets of ID rules , LP statements , FCRs , and the lexicon .</sentence>
				<definiendum id="0">grammars</definiendum>
				<definiens id="0">consist of actual sets of ID rules , LP statements , FCRs , and the lexicon</definiens>
			</definition>
			<definition id="1">
				<sentence>The most problematic case is the order in which the HFC and the CAP have to be applied : • the HFC seems to presuppose the effects of the CAP ( and of the FFP ) because it must not force feature specifications that are excluded by the CAP on categories in local trees ; • the CAP presupposes the FlEC in the sense that it is based on semantic types , which are dependent on HEAD features , the distribution of which is in turn governed by the HFC .</sentence>
				<definiendum id="0">most problematic case</definiendum>
				<definiens id="0">the order in which the HFC and the CAP have to be applied : • the HFC seems to presuppose the effects of the CAP ( and of the FFP ) because it must not force feature specifications that are excluded by the CAP on categories in local trees ; • the CAP presupposes the FlEC in the sense that it is based on semantic types</definiens>
			</definition>
			<definition id="2">
				<sentence>An FCR applies to a category C iff C is an extension of cat1 .</sentence>
				<definiendum id="0">FCR</definiendum>
				<definiens id="0">an extension of cat1</definiens>
			</definition>
</paper>

		<paper id="2109">
			<definition id="0">
				<sentence>In this ease the new illocutionary plan IP ' is : &lt; g ( PUT ) , g ( ADRESSEE ) , ( ( - , ch , m , mp ) ( OBJECT ) ) , ( ( ch , -m ) ( GOAL ) &gt; .</sentence>
				<definiendum id="0">PUT</definiendum>
				<definiens id="0">g ( ADRESSEE ) , ( ( - , ch , m , mp ) ( OBJECT ) ) , ( ( ch , -m ) ( GOAL ) &gt;</definiens>
			</definition>
</paper>

		<paper id="2127">
			<definition id="0">
				<sentence>The alphabet consists of structured symbols which are sets of pairs ( feature , value ) .</sentence>
				<definiendum id="0">alphabet</definiendum>
			</definition>
			<definition id="1">
				<sentence>tense is a feature with the properties pluperfect , imperfect , perf , pros , fut specifying the time of a verb .</sentence>
				<definiendum id="0">tense</definiendum>
				<definiens id="0">a feature with the properties pluperfect , imperfect , perf , pros , fut specifying the time of a verb</definiens>
			</definition>
			<definition id="2">
				<sentence>Semantic properties of categories are equally characterized by features and : formally these `` semantic '' features are not distinguished from `` syntactic '' features ; e.g. animate is a semantic feature whose values are + and and which belongs to : nouns , durative and static and action are features which classify verbs .</sentence>
				<definiendum id="0">e.g. animate</definiendum>
			</definition>
			<definition id="3">
				<sentence>Then we define a predicate unify ( a , b , r , e ) where r is the result of the unification and e is the set consisting of all the pairs of value sets for which a and b !</sentence>
				<definiendum id="0">predicate unify</definiendum>
				<definiendum id="1">r</definiendum>
				<definiendum id="2">e</definiendum>
				<definiens id="0">the set consisting of all the pairs of value sets for which a and b</definiens>
			</definition>
			<definition id="4">
				<sentence>contained in the symmetrical difference between a and b. r = { f ( v ) : f ( v ) ~ a ÷ b or ( fE d ( a ) c~ d ( b ) and v=a ( f ) c~ b ( f ) whenever a ( f ) n b ( f ) ~ } ( denotes the symmetrial difference between sets ) e= { f ( v ) : f ( v ) ~ a ÷ b or ( fEd ( a ) c~ d ( b ) and a ( f ) n b ( f ) =z and v= &lt; a ( f ) , b ( f ) &gt; ) } The unification is defined on sets of complex symbols .</sentence>
				<definiendum id="0">b</definiendum>
				<definiens id="0">the symmetrial difference between sets ) e= { f</definiens>
				<definiens id="1">a ) c~ d ( b ) and a ( f ) n b ( f ) =z and v= &lt; a ( f )</definiens>
			</definition>
			<definition id="5">
				<sentence>The noun Lehrer ( teacher ) has the representation nl= { \ [ Gender ( masc ) , case ( neg ( genitive } } , number ( singular ) \ ] , \ [ Gender ( masc ) , case ( neg ( dative ) ) , number ( plural ) \ ] } unification ( c , nf , r , e ) evaluates tO r = { \ [ Art-cat ( def ) , Gender ( masc ) , case ( genitive ) , number ( Plural ) \ ] ' \ [ Art-cat ( clef } , Gender ( masc } , case ( nominative ) , number ( singular ) I } e = { \ [ Art-cat ( def ) , Gender ( masc ) , case ( &lt; genitive , neg ( genitive } } , number ( &lt; plu ml , sing ular &gt; ) \ ] , \ [ Art-cat ( def ) , Gender ( &lt; fem , masc &gt; ) , case ( genitive } , number ( &lt; slngular , plural &gt; ) \ ] , \ [ Art-cat ( def ) , Gender ( &lt; fem , masc &gt; ) , case ( dative ) , number ( singular ) \ ] , \ [ Art-cat ( def ) , Gender ( masc ) , case ( nominative ) , number ( &lt; singular , plural &gt; ) \ ] } Example 2 : The noun Kind ( child ) ilas ihe representation n2 = { Gender ( neutr ) , case ( neg ( genitive ) ) , number ( singular ) } u nification ( c , n2 , r , e ) gives r =1~ e = { \ [ Art-cat ( def ) , Gender ( neutr ) , case ( &lt; genitive , neg ( genitive ) &gt; ) , number ( &lt; plural , singular &gt; ) \ ] , \ [ Art-cat ( clef ) , Gender ( &lt; fem , neutr &gt; ) , case ( dative ) , number ( singular ) \ ] , \ [ Art-cat ( def ) , Gender ( &lt; masc , neutr &gt; ) i case ( nominative ) , number ( singular ) \ ] } , Feature grammars are defined as formal grammars manipulating strings of complex symbols and the derivability concept is modified according to the structures of the complex symbols .</sentence>
				<definiendum id="0">Feature grammars</definiendum>
				<definiens id="0">the representation nl= { \ [ Gender ( masc ) , case ( neg ( genitive } } , number ( singular ) \ ] , \ [ Gender ( masc ) , case ( neg ( dative ) ) , number ( plural ) \ ] } unification ( c , nf , r , e ) evaluates tO r = { \ [ Art-cat ( def ) , Gender ( masc ) , case ( genitive ) , number ( Plural ) \ ] ' \ [ Art-cat ( clef } , Gender ( masc } , case ( nominative ) , number ( singular ) I } e = { \ [ Art-cat ( def ) , Gender ( masc ) , case ( &lt; genitive , neg ( genitive } } , number ( &lt; plu ml , sing ular &gt; ) \ ] , \ [ Art-cat ( def ) , Gender ( &lt; fem , masc &gt; ) , case ( genitive } , number ( &lt; slngular , plural &gt; ) \ ] , \ [ Art-cat ( def ) , Gender ( &lt; fem , masc &gt; ) , case ( dative ) , number ( singular ) \ ] , \ [ Art-cat ( def ) , Gender ( masc ) , case ( nominative ) , number ( &lt; singular , plural &gt; ) \ ] } Example 2 : The noun Kind ( child ) ilas ihe representation n2 = { Gender ( neutr ) , case ( neg ( genitive ) ) , number ( singular ) } u nification ( c , n2 , r , e ) gives r =1~ e = { \ [ Art-cat ( def ) , Gender ( neutr ) , case ( &lt; genitive , neg ( genitive ) &gt; ) , number ( &lt; plural , singular &gt; ) \ ] , \ [ Art-cat ( clef ) , Gender ( &lt; fem , neutr &gt; ) , case ( dative ) , number ( singular ) \ ] , \ [ Art-cat ( def ) , Gender ( &lt; masc , neutr &gt; ) i case ( nominative ) , number ( singular ) \ ] }</definiens>
			</definition>
			<definition id="6">
				<sentence>GOtter has the representation n = { \ [ Gender ( masc ) , case ( nag ( dative ) ) , number ( plural ) \ ] } .</sentence>
				<definiendum id="0">GOtter</definiendum>
				<definiens id="0">dative ) ) , number ( plural ) \ ] }</definiens>
			</definition>
			<definition id="7">
				<sentence>unification ( a , n , r , e ) gives r : { \ [ Art-cat ( def ) , Gender ( masc ) , case ( genitive ) , number ( plural ) \ ] } and e = { \ [ Art-cat ( def ) , Gender ( &lt; fem , masc &gt; ) , case ( genitive ) , number ( &lt; slngular , plural &gt; ) \ ] , \ [ Art-cat ( def ) , Gender ( masc ) , case ( nominative ) , number ( &lt; singular , plural &gt; ) \ ] } Der GtJtter is the subject of the sentence and the expected case is the nominative , tier GtJtter is genitive plural and this is the error signalled ( disagreement on the case ) .</sentence>
				<definiendum id="0">Gender ( masc</definiendum>
				<definiens id="0">nominative ) , number ( &lt; singular , plural &gt; ) \ ] } Der GtJtter is the subject of the sentence</definiens>
			</definition>
			<definition id="8">
				<sentence>freeze is a predefined predicate of PROLOG II \ [ ProloglA\ ] .</sentence>
				<definiendum id="0">freeze</definiendum>
			</definition>
			<definition id="9">
				<sentence>`` default ( p , q ) '' is a predefined predicate of PROLOG II first evaluating all possibilities for p , and only when none of these succeeds is q evaluated , sem-err produces an explanation of the type : arbeiten requires a human subject , Heft is not human but an written object .</sentence>
				<definiendum id="0">default</definiendum>
				<definiens id="0">a predefined predicate of PROLOG II first evaluating all possibilities for p</definiens>
			</definition>
			<definition id="10">
				<sentence>( 10 ) *Er schreibt dem Heft ( He writes to the notebook ) ; The error could be analysed as a semantic error ( schreiben requires a human dative object ) or as a low leVel syntactic error ( schreiben requires the preposition an ) .</sentence>
				<definiendum id="0">schreiben</definiendum>
				<definiens id="0">requires a human dative object</definiens>
			</definition>
			<definition id="11">
				<sentence>WEISCHEDEL R.M. and SONDHEIMER N.K. : Meta-rules as a Basis for Processing Ill-formed Input .</sentence>
				<definiendum id="0">SONDHEIMER N.K.</definiendum>
			</definition>
</paper>

		<paper id="1054">
			<definition id="0">
				<sentence>FLUSH combines a hierarchical phrasal lexicon \ [ Wilensky and Arens , 1980 , Jacobs , 1985 , Dyer and Zernik , 1986\ ] with declarative relations between language and meaning \ [ Jacobs and Rau , 1985\ ] .</sentence>
				<definiendum id="0">FLUSH</definiendum>
				<definiens id="0">with declarative relations between language and meaning \ [</definiens>
			</definition>
			<definition id="1">
				<sentence>The lexical relation to-pmod represents this linguistic category , and constrains how it can be used in a surface structure , based on its membership in the more general rood-tel ( modifying relation ) category .</sentence>
				<definiendum id="0">lexical relation to-pmod</definiendum>
				<definiens id="0">represents this linguistic category , and constrains how it can be used in a surface structure</definiens>
			</definition>
			<definition id="2">
				<sentence>FLUSH : a flexible lexicon design .</sentence>
				<definiendum id="0">FLUSH</definiendum>
				<definiens id="0">a flexible lexicon design</definiens>
			</definition>
			<definition id="3">
				<sentence>Ace : associating language with meaning .</sentence>
				<definiendum id="0">Ace</definiendum>
			</definition>
</paper>

		<paper id="2097">
			<definition id="0">
				<sentence>WIA is a weight of link from B and C to A. The input to the A unit is as follows .</sentence>
				<definiendum id="0">WIA</definiendum>
				<definiens id="0">a weight of link from B and C</definiens>
			</definition>
			<definition id="1">
				<sentence>Before a human has read a whole sentence , or even if he/she reads only few words , he/she predicts a complete or fairly large part of parse tree of possible sentence , This is why we adopt this low threshold strategy of requests sending .</sentence>
				<definiendum id="0">he/she</definiendum>
				<definiens id="0">predicts a complete or fairly large part of parse tree of possible sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>I~ln wl\ [ o /P3~ De~t `` ~ '' N Comp~S/NP I I i i\ the ~ who NP~VP/NP ... .. i i I I t h__£e ~ chased Figure 9o A parse tree ( connected network ) just after `` The man who the girl who the dog chased '' 5o Gard~ , n path sentences If there are more than one possible syntactic structures for the input sentence , the CM parser makes more than one parse tree networks corresponding to them in a parsing process .</sentence>
				<definiendum id="0">I~ln wl\</definiendum>
				<definiens id="0">The man who the girl who the dog chased '' 5o Gard~ , n path sentences If there are more than one possible syntactic structures for the input sentence , the CM parser makes more than one parse tree networks corresponding to them in a parsing process</definiens>
			</definition>
			<definition id="3">
				<sentence>ie\ ] Parsing : A Strongly Interactive Model of Natural Language Interpretation '' , Cognitive Science 9 , pp.51-74</sentence>
				<definiendum id="0">Parsing</definiendum>
				<definiens id="0">A Strongly Interactive Model of Natural Language Interpretation ''</definiens>
			</definition>
</paper>

		<paper id="1046">
			<definition id="0">
				<sentence>In addition , /r/was paired with all # VP sequences in the Word-lexicon where V is any word-initial vowel and P is any phoneme .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">any word-initial vowel</definiens>
			</definition>
			<definition id="1">
				<sentence>In order to account for the assimilation of alveolars to bilabials preceding bilabials , all PPt # sequences ( where P is any phoneme and Pt is one of /t , d , n/ ) were extracted from the Word-lexicon .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">Pt</definiendum>
				<definiens id="0">any phoneme and</definiens>
			</definition>
			<definition id="2">
				<sentence>Phonemic transcriptions ( excluding stress or boundary symbols ) were made hy a trained phonetician of 145 sentences produced by one lip speaker. '</sentence>
				<definiendum id="0">Phonemic transcriptions</definiendum>
			</definition>
</paper>

		<paper id="1048">
			<definition id="0">
				<sentence>Introduction Parsing natural language utterances can be considered a search t , roblem , which is characterized by the application of a set of operators ( i.e. the grammar rules ) onto the input data ( phrase to be processed ) in order to yield a ~ ) nal state ( derivation tree ) .</sentence>
				<definiendum id="0">roblem</definiendum>
				<definiens id="0">is characterized by the application of a set of operators ( i.e. the grammar rules ) onto the input data ( phrase to be processed</definiens>
			</definition>
			<definition id="1">
				<sentence>239 The strategies we used are defined as explicated in ( IiI ) , where AE means overall weight of the incoming active edge , GR weight of the grammar arc , SIE span of the inactive edge , SP span of the active edge to be continued with the inactive edge , IL items left .</sentence>
				<definiendum id="0">AE</definiendum>
				<definiens id="0">means overall weight of the incoming active edge , GR weight of the grammar arc , SIE span of the inactive edge , SP span of the active edge to be continued with the inactive edge , IL items left</definiens>
			</definition>
			<definition id="2">
				<sentence>In : Bresnan , J.W. ( ed ) : 'The Mental Representation of Grammatical Relations '' , Cambridge/Mass , The MIT Press , 1982 , 727-796 Frazier , L. , Fodor , J.D. , `` The Sausage Machine : A New Two-Stage Parsing Model '' .</sentence>
				<definiendum id="0">Sausage Machine</definiendum>
				<definiens id="0">'The Mental Representation of Grammatical Relations ''</definiens>
			</definition>
			<definition id="3">
				<sentence>Robinson , J. , `` DIAGRAM : A Grammar for Dialogues '' .</sentence>
				<definiendum id="0">DIAGRAM</definiendum>
				<definiens id="0">A Grammar for Dialogues ''</definiens>
			</definition>
</paper>

		<paper id="2114">
			<definition id="0">
				<sentence>A CS is a way of representing the communicative exchange together with its context .</sentence>
				<definiendum id="0">CS</definiendum>
			</definition>
			<definition id="1">
				<sentence>In Barwise and Perry 's ( \ ] .985 ) notation this would be given as : \ [ x I In S : a-tourist , x , yes\ ] where S is the set of situation-types in which a tourist is involved .</sentence>
				<definiendum id="0">S</definiendum>
			</definition>
			<definition id="2">
				<sentence>As has been pointed out in the description of the dialogue structures , the topmost element of the structural hierarchy ( the CSS ) contains a pointer into a structure representing the purpose of the CSS .</sentence>
				<definiendum id="0">structural hierarchy</definiendum>
				<definiendum id="1">CSS )</definiendum>
				<definiens id="0">contains a pointer into a structure representing the purpose of the CSS</definiens>
			</definition>
</paper>

		<paper id="1042">
			<definition id="0">
				<sentence>Ills system follows the Conceptual Processing model , and is not Transfer-based , hence the emphasis there is on deep Analysis and Generation .</sentence>
				<definiendum id="0">Ills system</definiendum>
				<definiens id="0">follows the Conceptual Processing model</definiens>
			</definition>
			<definition id="1">
				<sentence>'lhe lexicon lookup phase , which takes place before phrase structure transformations , gets as its input the internal data representation provided by the SL parser ( PEG \ [ Jensen 86\ ] , in out prototype ) .</sentence>
				<definiendum id="0">SL parser</definiendum>
				<definiens id="0">takes place before phrase structure transformations , gets as its input the internal data representation provided by the</definiens>
			</definition>
			<definition id="2">
				<sentence>In terms of the lexicon specification language and the attributes used by the PEG parser , the rule looks as follows : If ( CN has Postbrother ( ( CAT NP ) ( ANIMATE + ) ) ) Then &lt; Put ( HEB `` 13 p~nnn '' ) ; &gt; ; The put instruction attaches the tlebrew translation as a feature on the current node ( CN is the default node assumed when no explicit node name is specified for put ) .</sentence>
				<definiendum id="0">CN</definiendum>
				<definiens id="0">a feature on the current node</definiens>
			</definition>
			<definition id="3">
				<sentence>Finish Ideally , the feature OBJECT could be defined as part of the information provided by the parser .</sentence>
				<definiendum id="0">OBJECT</definiendum>
				<definiens id="0">part of the information provided by the parser</definiens>
			</definition>
			<definition id="4">
				<sentence>The case where this verb appears in an active voice and forms part of the verb-particle construction `` allow for '' are identified by searching the tree for the preposition `` for '' which may be the head of a possibly nonadjacent PP : has Son name-2C ( CAT PREP ) ( base `` for '' ) ) ) ) Then &lt; Put ( IlEB `` l~a'~na np'~ '' ) ; Put in name-2 ( 11EB `` '' ) ; end ; &gt; ; @ Example : Ron allowed for the results .</sentence>
				<definiendum id="0">verb-particle construction</definiendum>
				<definiens id="0">an active voice and forms part of the</definiens>
			</definition>
			<definition id="5">
				<sentence>tlptJ `` consists of two words which have individual verb and noun entries in the TL lexicon .</sentence>
				<definiendum id="0">tlptJ ``</definiendum>
				<definiens id="0">consists of two words which have individual verb and noun entries in the TL lexicon</definiens>
			</definition>
			<definition id="6">
				<sentence>The different mechanisms presented above provide , in fact , various levels of characterization of the relation between a given verb and a noun ( or an NP ) to which it refers : subcategorization requirement for the very existence of a noun ( NP ) in a given position ( e.g. as a direct object ) ; a more constricting requi~ement for the existence of a noun with specified semantic features ( defined as such , or by means of lists , in the SL lexicon ) ; and a particular requirement for the existence of a specific noun ( or group of nouns ) .</sentence>
				<definiendum id="0">specific noun</definiendum>
				<definiens id="0">The different mechanisms presented above provide , in fact , various levels of characterization of the relation between a given verb and a noun</definiens>
				<definiens id="1">a direct object</definiens>
			</definition>
			<definition id="7">
				<sentence>Bold letters denote non-terminal constructs , normal letters denote terminals ( keywords ) .</sentence>
				<definiendum id="0">Bold letters</definiendum>
				<definiens id="0">denote non-terminal constructs , normal letters denote terminals ( keywords )</definiens>
			</definition>
			<definition id="8">
				<sentence>instruction = = end ; I goto ( label ) ; I put \ [ in u-name\ ] ( allowed-attribute value ) ; I call function-name ( parameter-list ) ; I if ( condition ) then &lt; instruction + &gt; \ [ else &lt; instruction + &gt; \ ] ; function-name = = user-delined-\ [ unction-name \ [ pre-defined-\ [ unction-name user-defined-function = = define user-delined-\ [ unetion-name In-statement + finish hi-statement = = \ [ label : \ ] \ [ n-instruction fn-instruction = = goto ( label ) ; I return ( true ) ; I return ( false ) ; I call pre-defined-function-name ( parameter-list ) ; I if ( condition ) then &lt; \ [ n-instructio n + &gt; \ [ else &lt; \ [ n-instruction + &gt; \ ] ; condition = = call fimction-name I simple-pattern \ [ not ( condition ) L ( condition ) and ( condition ) I ( condition ) or ( condition ) simple-pattern = = n-name ( attribute-pair + ) I n-name has \ [ no \ ] relation pattern pattern-condition = = node has \ [ no \ ] relation pattern node : = \ [ n-name\ ] ( attribute-pair + ) I n-name relation : = \ [ first\ ] prebrother I \ [ first\ ] postbrother I \ [ first\ ] son i father I ancestor \ [ \ [ last\ ] prebrother \ [ \ [ last\ ] postbrother \ [ \ [ last\ ] son I descendent I relative pattern = = simple-pattern-condition { ( pattern-condition ) I ( pattern \ [ not\ ] before pattern ) I ( pattern \ [ not\ ] after pattern ) simple-pattern-condition = = node I ( node , ) + node \ [ ( node or node ) \ ] ( node and node ) u-name = = main I cn \ ] name parameter-list = = nil i parameter + attribute-pair = = ( attribute-name value + ) value = = string \ [ key I ( value + ) label : = Ilanle access-key = = lexical item followed by part of speech .</sentence>
				<definiendum id="0">I return</definiendum>
				<definiens id="0">attribute-pair + ) I n-name has \ [ no \ ] relation pattern pattern-condition = = node has \ [ no \ ] relation pattern node : = \ [ n-name\ ] ( attribute-pair +</definiens>
				<definiens id="1">pattern = = simple-pattern-condition { ( pattern-condition ) I ( pattern \ [ not\ ] before pattern ) I ( pattern \ [ not\ ] after pattern ) simple-pattern-condition = = node I ( node , ) + node \ [ ( node or node ) \ ] ( node and node ) u-name = = main I cn \ ] name parameter-list = = nil i parameter + attribute-pair = = ( attribute-name value + ) value = = string \ [ key I ( value + ) label : = Ilanle access-key = = lexical item followed by part of speech</definiens>
			</definition>
			<definition id="9">
				<sentence>ADJ @ The funclion N-of-ADJ returns a True/False value @ The parameter P refers to a feature that can get +/values If ( CN has Ancestor ( A ( ( CAT AJP ) ) has Postbrother F ( ( CAT NP NOUN ) ( P + ) ) ) ) Then &lt; Return ( True ) ; &gt; ; @ John is an old and valued friend .</sentence>
				<definiendum id="0">funclion N-of-ADJ</definiendum>
				<definiens id="0">a feature that can get +/values If ( CN has Ancestor ( A ( ( CAT AJP ) ) has Postbrother F ( ( CAT NP NOUN ) ( P +</definiens>
			</definition>
</paper>

		<paper id="2134">
			<definition id="0">
				<sentence>In this case an admissible solution is a division , vu C=A , The objective function reflects the fact that letters of the same class co-occur rather rarely whereas letters of different classes co-occur relatively more often ; it is formulated as follows : Here f ( li,1 j ) denotes the frequency of letters I i and lj .</sentence>
				<definiendum id="0">admissible solution</definiendum>
				<definiendum id="1">vu C=A</definiendum>
				<definiendum id="2">objective function</definiendum>
				<definiens id="0">reflects the fact that letters of the same class co-occur rather rarely whereas letters of different classes co-occur relatively more often ; it is formulated as follows : Here f ( li,1 j ) denotes the frequency of letters I i and lj</definiens>
			</definition>
			<definition id="1">
				<sentence>The objective function is set up by ascribing to each morpheme a certain number q ( m ) which is great when m consists of the letters which predict each other stronger than they predict the letters of the neighbouring morphemes .</sentence>
				<definiendum id="0">objective function</definiendum>
				<definiens id="0">is set up by ascribing to each morpheme a certain number q ( m ) which is great when m consists of the letters which predict each other stronger than they predict the letters of the neighbouring morphemes</definiens>
			</definition>
			<definition id="2">
				<sentence>A number of sx-periments have been carried out ; the best results have been obtained with the help of the following function : f2 ( aXb ) q ( m ) = q ( aXb ) = max ( f ( ax ) , f ( Xb ) ) max ( f ( slbx ) , f ( yaXb ) ) x , y Here f denotes the frequency of a string , a is the initial , b is the final letter of m , y is a letter which precedes m , x is a letter which follows it , X is a string .</sentence>
				<definiendum id="0">number of sx-periments</definiendum>
				<definiendum id="1">b</definiendum>
				<definiendum id="2">y</definiendum>
				<definiendum id="3">X</definiendum>
				<definiens id="0">the best results have been obtained with the help of the following function : f2 ( aXb ) q ( m ) = q ( aXb ) = max ( f ( ax ) , f ( Xb ) ) max ( f ( slbx ) , f ( yaXb ) ) x , y Here f denotes the frequency of a string</definiens>
				<definiens id="1">the final letter of m</definiens>
				<definiens id="2">a letter which precedes m , x is a letter which follows it ,</definiens>
				<definiens id="3">a string</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>We assume a probabilistic context-free grammar G= &lt; VN , VT , R , S &gt; : VN denotes the nonterminal vocabulary Nonterminals are denoted by A , B , C ... . strings of these by X , Y , Z..</sentence>
				<definiendum id="0">VN</definiendum>
				<definiens id="0">a probabilistic context-free grammar G= &lt; VN , VT , R , S &gt;</definiens>
			</definition>
			<definition id="1">
				<sentence>lexical categories by P , Q ... . VT denotes the terminal vocabulary terminals ( words ) denoted by a , b , c ... .. strings of both types of symbols are denoted by w , x , y , z .</sentence>
				<definiendum id="0">VT</definiendum>
				<definiens id="0">the terminal vocabulary terminals ( words ) denoted by a , b , c ... .. strings of both types of symbols are denoted by w</definiens>
			</definition>
			<definition id="2">
				<sentence>R denotes the set of rules { R1 , R2 ... .. Ri } with each rule having the format Ri = &lt; Ai - &gt; Xi , qi &gt; where qi indicates the a-priori 172 Z p ( xi a Q Yi &lt; -TiS ) probability for the application of this i rule , ,c.~ , ~ .</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">qi</definiendum>
				<definiendum id="2">-TiS ) probability</definiendum>
				<definiens id="0">the set of rules { R1 , R2 ... .. Ri } with each rule having the format Ri = &lt; Ai - &gt; Xi</definiens>
				<definiens id="1">xi a Q Yi &lt;</definiens>
			</definition>
			<definition id="3">
				<sentence>Consequently , the a-posteriori probability that the lexical category Q immediately follows the word `` a '' can be calculated as p ( S &lt; xaQy ) : p ( wj a Pj zj &lt; -TjS ) J All derivations appearing on the right side are minimal derivations for the substring `` aQ '' or `` aPj '' and the Pj 's range ow~r all lexical categories in G ( In the formula , of course , we assume p ( waPz &lt; -S ) = 0 if the substring `` alP '' is n't derivable in G ) . This formula reflects the common probabilistic assumption that the derivation probability of a substring is the sum of all distinct alternative derivation probabilities of this string ( if there is more than one possibility ) . The following toy grammar is designed to demonstrate the formalism. That it generates many unwanted sentences need not concern us here. Our grammar has the following rules S - &gt; # NP V NP # , 1.0 NP - &gt; Q N , 0.7 NP - &gt; Q , 0.3 Lexical rules N- &gt; board 0.2 V- &gt; board 0.3 N- &gt; boards 0.2 V- &gt; boards 0.3 N- &gt; men 0.3 V- &gt; boarded 0.3 N- &gt; man 0.3 V- &gt; man 0.1 Q- &gt; some 0.4 0- &gt; the 0.6 Let us assume the word `` board '' has been recognized somewhere in the input stream ( but not at its end ) .</sentence>
				<definiendum id="0">a-posteriori probability</definiendum>
				<definiendum id="1">substring</definiendum>
				<definiens id="0">p ( S &lt; xaQy ) : p ( wj a Pj zj &lt; -TjS ) J All derivations appearing on the right side are minimal derivations for the substring `` aQ '' or</definiens>
				<definiens id="1">the common probabilistic assumption that the derivation probability of a</definiens>
				<definiens id="2">designed to demonstrate the formalism. That it generates many unwanted sentences need not concern us here. Our grammar has the following rules S - &gt; # NP V NP # , 1.0 NP - &gt; Q N , 0.7 NP - &gt; Q , 0.3 Lexical rules N- &gt;</definiens>
			</definition>
			<definition id="4">
				<sentence>depart V ( I '' PRED ) = '' DEPART &lt; ( I '' SUBJ ) ( tOBLLOC ) &gt; '' ( $ OBLLOC OBJ PCASE ) = Goal This entry predicts a subject and an oblique object which denotes a goal ( like in `` depart ... for ... '' or `` depart ... to ... '' ) .</sentence>
				<definiendum id="0">depart V</definiendum>
				<definiens id="0">a subject and an oblique object which denotes a goal ( like in `` depart ... for ... '' or `` depart ... to ... '' )</definiens>
			</definition>
			<definition id="5">
				<sentence>arrive V ( ~PRED ) = '' ARRIVE &lt; ( i '' SUBL ) ( I'OBLLOC ) &gt; '' ( 1 '' OBLLOC OBJ PCASE ) = Source a t P-loc ( 1 '' PRED ) = `` AT &lt; ( '\ [ ' OBJ ) &gt; '' ( 1 ' OBJ PEASE ) = Loe to P-Ioc ( I '' PRED ) = `` TO &lt; ( 'I '' OBJ ) &gt; '' ( 1 '' OBJ PCASE ) = Goal for P-loc ( 1 '' PRED ) = `` FOR &lt; ( 1 ' OBJ ) &gt; '' ( 1 ' OBJ PCASE ) = Goal where approach ( `` semantic grammars '' ) and a purely surface oriented word order approach .</sentence>
				<definiendum id="0">arrive V</definiendum>
				<definiens id="0">P-loc ( 1 '' PRED ) = `` FOR &lt; ( 1 ' OBJ ) &gt; '' ( 1 ' OBJ PCASE ) = Goal where approach ( `` semantic grammars '' ) and a purely surface oriented word order approach</definiens>
			</definition>
			<definition id="6">
				<sentence>We showed tile usefulness of a probabilistic lexical functional grammar for a speech recognition system by demonstrating its two relatively independent constraining and predicting mechanisms : the constraining power of a contextfree grammar ( which allows global predictions from a global point of view ) and of valencyoriented lexicon ( which allows bottom-up predictions from a local point of view ) .</sentence>
				<definiendum id="0">contextfree grammar</definiendum>
				<definiens id="0">showed tile usefulness of a probabilistic lexical functional grammar for a speech recognition system by demonstrating its two relatively independent constraining and predicting mechanisms : the constraining power of a</definiens>
			</definition>
</paper>

		<paper id="2129">
			<definition id="0">
				<sentence>The story understanding mechanism reads a natural language story and creates its scenario for realistic graphic animations .</sentence>
				<definiendum id="0">story understanding mechanism</definiendum>
				<definiens id="0">reads a natural language story and creates its scenario for realistic graphic animations</definiens>
			</definition>
			<definition id="1">
				<sentence>SDA consists of three modules : 1 ) story understanding ; 2 ) stage directing ; 3 ) action generating .</sentence>
				<definiendum id="0">SDA</definiendum>
			</definition>
			<definition id="2">
				<sentence>Pre-condition is the constraint to be satisfied just before the act of a verb .</sentence>
				<definiendum id="0">Pre-condition</definiendum>
				<definiens id="0">the constraint to be satisfied just before the act of a verb</definiens>
			</definition>
			<definition id="3">
				<sentence>Post-conditlon is the state to be achieved just after the act of a verb .</sentence>
				<definiendum id="0">Post-conditlon</definiendum>
				<definiens id="0">the state to be achieved just after the act of a verb</definiens>
			</definition>
			<definition id="4">
				<sentence>The story understanding mechanism reads a natural language story and creates its scenario for realistic graphic animations .</sentence>
				<definiendum id="0">story understanding mechanism</definiendum>
				<definiens id="0">reads a natural language story and creates its scenario for realistic graphic animations</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>However , if there is a \ [ dir-object\ ] synthesized as the Ppv = : 1o , the pronouns gli or le amalgamate with this Ppv and both become glie : Diedi il libro a Maria -- &gt; Le diedi il iibro ( I gave the book to Mary -- &gt; I gave the book to her ) Diedi il libro a Ugo -- &gt; Gll diedi il libro ( i gave the book to Ugo -- &gt; I gave the book to him ) I1 libro , la diedi a ( Maria + Ugo ) -- &gt; Glielo diedi ( The book , I gave it to ( Mary + Ugo ) -- &gt; I gave it to her/him ) antecedents of the foreseen pronoun A token , which does not refer to the speaker ( s ) or hearer ( s ) , eollrespends to a morphological antecedent of the foreseen pronoun if it has been previously synthesized as a nominal phrase whose morphological features ( i.e. gender and number ) are compatible with the form of the foreseen prunoun .</sentence>
				<definiendum id="0">token</definiendum>
				<definiens id="0">a nominal phrase whose morphological features</definiens>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>Introduction Binding is a component subtheory of Governmentbinding which applies in the derivation of the logical form of utterances from their surface rcpresentation .</sentence>
				<definiendum id="0">Introduction Binding</definiendum>
				<definiens id="0">a component subtheory of Governmentbinding which applies in the derivation of the logical form of utterances from their surface rcpresentation</definiens>
			</definition>
			<definition id="1">
				<sentence>Chomsky ( 1981 ) assumes a Free Indexing rule which appfies at LF and assigns ( randomly ) a referential index to every NP in tim input structure .</sentence>
				<definiendum id="0">Free Indexing rule</definiendum>
				<definiens id="0">appfies at LF and assigns ( randomly</definiens>
			</definition>
			<definition id="2">
				<sentence>The local domain of a node a is the subtree dominated by MGC ( a ) , where MGC ( ~ ) , the minimal governing category of a , denotes the maximal projection # nearest to ¢z such that /~ dominates a , and /~ has an accessible Subject , and /L dominates a governor ~ of a ( to ) For nodes a and \ [ 1 , a e-commands \ [ I if the firsi ; branching node dominating a also dominates ft .</sentence>
				<definiendum id="0">local domain of a node a</definiendum>
				<definiendum id="1">MGC</definiendum>
			</definition>
			<definition id="3">
				<sentence>The formulation of the rule relies crucially on the following hypothesis : For every NP node in an S-Structure , it is possible to define two sets of nominal expressions AAS and PAS , which contain , respectively , potential anaphoric and pronominal antecedents .</sentence>
				<definiendum id="0">PAS</definiendum>
				<definiens id="0">contain , respectively , potential anaphoric and pronominal antecedents</definiens>
			</definition>
			<definition id="4">
				<sentence>The function se &amp; ct-from takes an ordered set as argument and selects ( arbitrarily ) the 125 first element that morphologically agrees with the NP2 ( J2 ) Binding Rule : NP .</sentence>
				<definiendum id="0">ct-from</definiendum>
				<definiens id="0">takes an ordered set as argument and selects</definiens>
			</definition>
			<definition id="5">
				<sentence>node The main component of the Binding rule consists of the attribution rules that define the values of the AAS and PAS sets at each node .</sentence>
				<definiendum id="0">Binding rule</definiendum>
				<definiens id="0">consists of the attribution rules that define the values of the AAS and PAS sets at each node</definiens>
			</definition>
			<definition id="6">
				<sentence>Reflndex represents the referential index of the NP with which it is associated .</sentence>
				<definiendum id="0">Reflndex</definiendum>
				<definiens id="0">the referential index of the NP with which it is associated</definiens>
			</definition>
			<definition id="7">
				<sentence>NPs are ordered in the AAS in such way that the most recently found NP is ranked first ( AAS is a stack , or ordered set ) .</sentence>
				<definiendum id="0">AAS</definiendum>
				<definiens id="0">a stack , or ordered set )</definiens>
			</definition>
			<definition id="8">
				<sentence>AGR &gt; is a member of PAS , but not AAS .</sentence>
				<definiendum id="0">AGR &gt;</definiendum>
				<definiens id="0">a member of PAS , but not AAS</definiens>
			</definition>
			<definition id="9">
				<sentence>`` Global Storage Cells for Attributes in an Attribute Grammar . ''</sentence>
				<definiendum id="0">Global Storage Cells for Attributes</definiendum>
			</definition>
</paper>

		<paper id="2121">
			<definition id="0">
				<sentence>This tree rewriting grammar consists of a set of trees that are not restricted to be of depth one ( as in CFGs ) .</sentence>
				<definiendum id="0">tree rewriting grammar</definiendum>
			</definition>
			<definition id="1">
				<sentence>A Tree Adjoining Grammar is a tree-based system that consists of .</sentence>
				<definiendum id="0">Tree Adjoining Grammar</definiendum>
			</definition>
			<definition id="2">
				<sentence>Grammar rules defined by the linguistic theory are not the same as the rules used by the parser -- let us refer to them as parser rules .</sentence>
				<definiendum id="0">Grammar rules</definiendum>
				<definiens id="0">the linguistic theory are not the same as the rules used by the parser -- let us refer to them as parser rules</definiens>
			</definition>
			<definition id="3">
				<sentence>One can encode the grammar in TAG as follows : S S A B A A A A a x a y Suppose that the heads of the initial trees are respectively x and y and that a is the head of both auxiliary 581 trees .</sentence>
				<definiendum id="0">S S A B A A A A</definiendum>
				<definiens id="0">a x a y Suppose that the heads of the initial trees are respectively x and y and that a</definiens>
			</definition>
			<definition id="4">
				<sentence>The grammar can be thought as a five-tuple ( VN , ~ , O , S , Lex ) where : • VN is a finite set of non-terminal symbols , • ~ is a finite set of alphabet symbols , • O is the set of trees constructed with P , * and VN ( the elements of Z* having ranked 0 ) .</sentence>
				<definiendum id="0">VN</definiendum>
				<definiendum id="1">O</definiendum>
				<definiens id="0">the set of trees constructed with P , * and VN ( the elements of Z* having ranked 0 )</definiens>
			</definition>
			<definition id="5">
				<sentence>• Lex is the lexicon , i.e. a function from lexical items to finite subsets of O : P ? '</sentence>
				<definiendum id="0">Lex</definiendum>
				<definiens id="0">the lexicon</definiens>
			</definition>
			<definition id="6">
				<sentence>\ ] where a is a tree , dot is the address of the dot in the tree , side is the side of the symbol the dot is on ( left or right ) , pos is the position of the dot ( above or below ) , star is an address in a and l , f~ , fr , star , t~ , b~ are indices of positions in the input string .</sentence>
				<definiendum id="0">dot</definiendum>
				<definiendum id="1">star</definiendum>
				<definiens id="0">the side of the symbol the dot is on ( left or right</definiens>
			</definition>
			<definition id="7">
				<sentence>• Suppose that the auxiliary tree that we left-predicted has been recognized as far as its foot , then the Left Completor tries to recognize what was pushed under the foot .</sentence>
				<definiendum id="0">Left Completor</definiendum>
				<definiens id="0">tries to recognize what was pushed under the foot</definiens>
			</definition>
			<definition id="8">
				<sentence>• The Substitution Predictor performs the same operations as Earley 's original predictor .</sentence>
				<definiendum id="0">Substitution Predictor</definiendum>
				<definiens id="0">performs the same operations as Earley 's original predictor</definiens>
			</definition>
			<definition id="9">
				<sentence>• If the tree that we predicted for substitution has been totally recognized , the Substitution Completor tries to recognize the rest of the tree in which we predicted a substitution .</sentence>
				<definiendum id="0">Substitution Completor</definiendum>
				<definiens id="0">tries to recognize the rest of the tree in which we predicted a substitution</definiens>
			</definition>
</paper>

		<paper id="2151">
			<definition id="0">
				<sentence>ID rules are tuples of the form ( ( mother ) -- - ) ( daughters ) ) , for example ( S ~ { NP , VP } ) , where ( daughters ) is a multi-set of categories which can be dominated by the category ( mother ) .</sentence>
				<definiendum id="0">ID rules</definiendum>
				<definiens id="0">tuples of the form ( ( mother ) -- - ) ( daughters ) ) , for example ( S ~ { NP , VP } ) , where ( daughters ) is a multi-set of categories which can be dominated by the category ( mother )</definiens>
			</definition>
			<definition id="1">
				<sentence>C is the category traditionally called a nominative NP .</sentence>
				<definiendum id="0">C</definiendum>
			</definition>
			<definition id="2">
				<sentence>cat ( E ( f ) ) ^ C ( f ) ~_ E ( f ) Definition : unifiable Two categories A and B are unifiable ( A II B ) ¢ : ~ V f ~ F : ~spec ( A ( f ) ) v ~spec ( B ( f ) ) v ( ( atom ( A ( f ) ) A atom ( B ( t ) ) ) ~ ( Aft ) = B ( f ) ) ) v ( ( cat ( A ( f ) ) A cat ( B ( f ) ) ) ~ ( Aft ) ld B ( f ) ) ) The FCRs in the constructive version of GPSG are not only predicates on categories , they are also modified to become more functional by instantiating variable feature values if necessary .</sentence>
				<definiendum id="0">atom</definiendum>
				<definiens id="0">unifiable ( A II B ) ¢ : ~ V f ~ F : ~spec ( A ( f ) ) v ~spec</definiens>
			</definition>
			<definition id="3">
				<sentence>FCRs are implications of the form ( n , A D B ) .</sentence>
				<definiendum id="0">FCRs</definiendum>
			</definition>
			<definition id="4">
				<sentence>Definition : projection The projection • ~ ID × LT is a relation from the set ID of ID rules to the set LT of local trees .</sentence>
				<definiendum id="0">Definition</definiendum>
			</definition>
			<definition id="5">
				<sentence>D ( _ , _ , l ) ) , ( 2 , ( d , + , _ ) D ( _ , _,2 ) ) } Suppose that the feature f2 is an agreement feature and that a local tree t which is a projection of this ID rule has been constructed , then the Agreement Principle ( AP ) forces X = Y = Z and therefore the AP has to consider three cases 6 : 1 ) If at least two values are instantiated with different values then the AP has to reject t ( thepredicative view of the F1Ps which is still preserved in the constructive version of GPSG ) .</sentence>
				<definiendum id="0">f2</definiendum>
			</definition>
			<definition id="6">
				<sentence>Vp is the specified feature value of the LP statement which will become applicable to the corresponding daughters of the subtree if the values V t of all tuples in LPc ( id ) are specified and equal to their corresponding values Vp .</sentence>
				<definiendum id="0">Vp</definiendum>
			</definition>
			<definition id="7">
				<sentence>The set of all LP constraints LPc ( 0 ) for the'local tree in which C~ is the mother category is ¢1 LPc ( 0 ) = { LPc ( i , j ) \ [ 1 &lt; i &lt; j &lt; n } u ; L. ) 4 eval_lp ( LPc ( i ) ) where eval_lp ( LPc ( i ) ) is the evaluation of the LP constraints of the subtree in which the daughter ~ is the root category .</sentence>
				<definiendum id="0">eval_lp</definiendum>
				<definiens id="0">the root category</definiens>
			</definition>
			<definition id="8">
				<sentence>Computing the set of constraints FCR c For all categories C\ [ where 0 &lt; i &lt; n in a local tree t the set APP ( i ) of all numbers of FCRs which may still be applicable to Q is computed as follows : 1 ) 3 ( k , A D B ) ~ FCR : A E Q A -~ ( B \ [ 3 C D =~ C I not legal 2~V ( k ) A ~ B ) ~ FCR : ALJq ^ A~ qA ( -~ ( B L\ ] q ) v ( ( B LJ CD ^ ( B ~ q ) ) ) ~ q legal and k ~ AFP ( i ) 3 ) V ( k , A ~ B ) ~ FCR : ~ ( A LJ q ) v ( A _E C ) ^ B II q ) q is legal and APP ( i ) = { } The set of all FCR constraints FCRc ( 0 ) for the local tree in which C8 is the mother category is 11 FCRc ( 0 ) = { ( C8 ) APP ( 0 ) ) } u .</sentence>
				<definiendum id="0">D B ) ~ FCR</definiendum>
				<definiendum id="1">k , A ~ B</definiendum>
				<definiens id="0">A E Q A -~</definiens>
			</definition>
			<definition id="9">
				<sentence>L ) eval fcr ( FCRc ( i ) ) where eval fcr ( FCRc ( 1 ) ) is the evaluation of the FCR constraints from the subtree in which the daughter q is the root category .</sentence>
				<definiendum id="0">eval fcr</definiendum>
				<definiens id="0">the evaluation of the FCR constraints from the subtree in which the daughter q is the root category</definiens>
			</definition>
			<definition id="10">
				<sentence>Ci is a copy of a category of the subtree in which C 8 is the root category and APP ( i ) includes the numbers of all FCRs which may still be applied to C i if particular feature values of this category are going to be instantiated .</sentence>
				<definiendum id="0">Ci</definiendum>
				<definiens id="0">a copy of a category of the subtree in which C 8 is the root category and APP ( i ) includes the numbers of all FCRs which may still be applied</definiens>
			</definition>
			<definition id="11">
				<sentence>These constraints are combined with the LP constraints resulting fl'om the evaluation of the LP constraints on the subtrees of the daughters , to form the entire set of LP constraints LPc ( 0 ) on the subtree in which C/~ is the root category which is then also propagated to the mother .</sentence>
				<definiendum id="0">LP constraints</definiendum>
			</definition>
</paper>

		<paper id="2135">
			<definition id="0">
				<sentence>A readability formula predicts the difficulty of a document that may result from its writing style , but not from its content , organization , or format .</sentence>
				<definiendum id="0">readability formula</definiendum>
				<definiens id="0">predicts the difficulty of a document that may result from its writing style , but not from its content , organization , or format</definiens>
			</definition>
			<definition id="1">
				<sentence>We will call such a series a run , i.e. , a run is a maximal string that consists of only one type of characters .</sentence>
				<definiendum id="0">run</definiendum>
				<definiens id="0">a maximal string that consists of only one type of characters</definiens>
			</definition>
			<definition id="2">
				<sentence>A principal component is a linear combination of the variables .</sentence>
				<definiendum id="0">principal component</definiendum>
			</definition>
			<definition id="3">
				<sentence>Cloze procedure judges the relative reading difficulty of texts to a particular population .</sentence>
				<definiendum id="0">Cloze procedure</definiendum>
				<definiens id="0">judges the relative reading difficulty of texts to a particular population</definiens>
			</definition>
</paper>

		<paper id="2117">
			<definition id="0">
				<sentence>R is a condition which has to be coherent with the current world .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">a condition which has to be coherent with the current world</definiens>
			</definition>
			<definition id="1">
				<sentence>consistentw ( S ) is a predicate which is true if in world W the statement S is consistent .</sentence>
				<definiendum id="0">consistentw ( S )</definiendum>
				<definiens id="0">a predicate</definiens>
			</definition>
			<definition id="2">
				<sentence>( b ) Let W '' be an extension of W such that W N W n is a set of right irrelevant statements then : by defw , A B ==~ by defw A B ( downward rightmonotonicity , noted MON.L ) .</sentence>
				<definiendum id="0">W</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">a set of right irrelevant statements then : by defw , A B ==~ by defw A B ( downward rightmonotonicity , noted MON.L )</definiens>
			</definition>
			<definition id="3">
				<sentence>Here is another restricted transitivity pattern : • ( by-def X ( is B ) ) A ( ( no B ) C ) ~ ( by-clef A -I C ) .</sentence>
				<definiendum id="0">X</definiendum>
			</definition>
			<definition id="4">
				<sentence>The reverse pattern : ( by-def A B ) A ( by-defX ' C ) ~ by-def A ( B A C ) where A ' is a copy of A with different variables , also holds but it is somewhat weaker in the sense that the denotation of B A C ill W is included in the denotation of B in W and in that of C in W. Thus , the same remark as for the previous pattern holds : the determiner at the origin of the default rule in the pre~rdses is not preserved and another context-dependent determiner can be more appropriate , depending on how much the default has been weaken , i.e. on how much the number of exceptions to the default rule has increased .</sentence>
				<definiendum id="0">context-dependent determiner</definiendum>
				<definiens id="0">a copy of A with different variables</definiens>
			</definition>
</paper>

		<paper id="2094">
</paper>

		<paper id="2122">
			<definition id="0">
				<sentence>The component POPEL generates referential expressions which may be accompanied by a pointing gesture .</sentence>
				<definiendum id="0">component POPEL</definiendum>
				<definiens id="0">generates referential expressions which may be accompanied by a pointing gesture</definiens>
			</definition>
			<definition id="1">
				<sentence>1 ) POPEL is the acronym for Product~on Of \ [ Perhaps , Possible , .</sentence>
				<definiendum id="0">POPEL</definiendum>
			</definition>
			<definition id="2">
				<sentence>Humans are 'multichannet systems ' which receive information about objects through a great variety of channels .</sentence>
				<definiendum id="0">Humans</definiendum>
				<definiens id="0">receive information about objects through a great variety of channels</definiens>
			</definition>
</paper>

		<paper id="1014">
</paper>

		<paper id="2132">
			<definition id="0">
				<sentence>Deeodifying the vocal signal is a process that must take into account phenomena such as the eoarticulatory processes typical of continuous speech and the presence of many sources of variability of the signal ( anatomic characteristics of the speaker , emission speed , prosody and so on ) .</sentence>
				<definiendum id="0">vocal signal</definiendum>
			</definition>
			<definition id="1">
				<sentence>... . Vt n , with for i=O , n-1 ti &lt; ti+i where for every vertex arrives or leaves at least one lexical edge. It just does not matter if the final analysis will not `` make use '' of all the vertices in the chart. We then define four different rules for introducing a new edge in the chart : The first rule says , roughly , that if you are trying to build the same thing from the left and from the right you should unify your efforts. 537 A-A Rule : If we have two active edges Ai and A2 , with to ( A 1 ) = from ( A2 ) rule ( A1 ) = rule ( A2 ) toposition ( A 1 ) = fromposition ( A2 ) and A1 is locally leftward largest and A2 is locally rightward largest , then we can introduce a new active edge A3 into the chart with from ( A3 ) = from ( A1 ) , to ( A3 ) = to ( A2 ) , rule ( A3 ) = rule ( A1 ) , fromposition ( A3 ) = fromposition ( A ! ) , toposition ( A3 ) =toposition ( A2 ) , sub-inactives ( A3 ) = concat ( sub-inactives ( Al ) , sub-inactives ( A2 ) ) , where concat is the usual string concatenation operator. If fromposition ( Al ) =0 and toposition ( A2 ) =n , number of symbols in the right hand side of rule ( A1 ) , an inactive edge I is introduced instead , with from ( I ) =from ( Al ) , to ( I ) =to ( A2 ) and cat ( I ) equal to the left hand side of rule ( AlL We also maintain the usual edge combination rule , with the extension to the two directions. A-I Rule : Given an active edge A and an inactive edge I with from ( I ) =to ( A ) , and , having named i toposition ( A ) , with i¢ n ( the number of symbols in the right hand side of the rule ) , cat ( I ) = Ci +1 , i + 1-th symbol of the right hand side of rule ( A ) , then a new edge E can be added to the chart , with from ( E ) =from ( A ) , to ( E ) =to ( I ) , and , if i+l=n was the last symbol in rule ( A ) and fromposition ( A ) =0 , E will be an inactive edge with cat ( E ) equal to the left hand side of rule ( A ) , if not it will be an active edge with rule ( E ) = rule ( A ) and fromposition ( E ) = fromposition ( A ) , toposition ( E ) = i + 1. Similarly , if to ( I ) =from ( A ) , and having named i fromposition ( A ) , i¢ 0 , cat ( I ) = Ci-I , i-l-th symbol of the right handside of rule ( A ) , then a new edge E can be added to the chart , with from ( E ) = from ( I ) , to ( E ) = to ( A ) , and , if i1 = 0 and toposition ( A ) is equal to the length of the right handside of rule ( A ) , E will be an inactive edge with cat ( E ) equal to the left handside of rule ( A ) , if not , it will be an active edge with rule ( E ) =rule ( A ) , fromposition ( E ) =i-1 , toposition ( E ) = toposition ( A ) . Let us now recall our classification of word hypotheses into three classes , say a , b , c , in relation ~ their scores. As stated earlier , we consider word hypotheses of class a the islands for our process. The algorithm will proceed outward from the islands and bottom-up when a 638 constituent including an island ( however far inside the structure ) is completed. Let us say that an edge has another feature , called withisland , a boolean that is originally true for lexical edges of class a and false for the others , and during the process is propagated to any new edge that `` includes '' an edge with withisland = true. We can now state the I/bu Rule : When an inactive edge I , with .withisland ( I ) =true , is introduced in the chart , a new active edge is introduced for every rule R in the grammar that includes on its right hand side the symbol cat ( I ) and in relation to R for every position i such that cat ( I ) is the i + 1-th symbol on the right hand side of R. Let us denote such a generic active edge as A ; its characteristics will be from ( A ) = from ( I ) , to ( A ) -t0 ( I ) , rule ( A ) = R , fromposition ( A ) = i , toposition ( A ) = i + 1 , sub-inactives = list ( I ) . We have also the usual top-down rule , rivisited consistently with our approach : A/td Rule : When an active edge A is added to the chart , if from the vertex to ( A ) only edges with withisland=false leave rightward , then introduce a cycling active edge on to ( A ) for every rule that has on the left handside the symbol that comes after the position toposition ( A ) for rule rule ( A ) , unless there is already an active edge with that rule or an inactive edge with that category. Do likewise on the other vertex. The meaning of the presence of both the I/bu and the A/td rules is that the process will be a bottom-up one , starting from the islands. When a point is met where only class b words are found , hypotheses of the presence of certain constituents , according to the `` island '' constraints , are introduced in the form of cycling active edges. This topdown operation will ensure that the parser is led by the most consolidated fragments. Every time we introduce a new active edge A we must perform a redundancy check to ensure that we do not build , not only now , but also in the forseeable future , anything that has already been built. r/Check : A new active edge A can be inserted in the chart unless from the vertex from ( A ) there is an active edge A ' leaving rightward with rule ( A ' ) = rule ( A ) , fromposition ( A ' ) =fromposition ( A ) and sub-inaetives ( A ' ) including as an initial substring sub-inactives ( A ) . Similarly , A can be inserted in the chart unless from the vertex to ( A ) there is an active edge A ' leaving leftward with rnle ( A ' ) =rule ( A ) , toposition ( A ' ) =topos~tion ( /k ) and sub-inactives ( A ' ) including as a final substring subinactives ( A ) . It is conw~nient that the above rules be applied in the given order so as to minimize the effort. As regards the question of control , it seems reasonable that all edge building tasks originated by an island should be carried on in the first place , and the actions resulting from l~redictions over class b hypotheses be carried out later , in order to avoid an explosion of fuzzy edges in the chart. Still , it is clear that , because of the nature of the algorithm , after the introduction of an edge of the second type , an edge building action originated by an island can take place again. With this in mind we introduce two agendas , a-agenda , where tasks of building edges with withisland -- -true are added and b-agenda where the other tasks are added. Task execution is constrained only by the discipline that a task in b-agenda can be executed only if a-agenda is empty. At the beginning of the process a-agenda is filled with all the tasks originated by the class a word hypothese : ~. class a words : MILAN , BOSS class b words : THE WANTS AN IMMEDIATE CALL TO rules : 1 ) S- &gt; NPVNPPP 2 ) S- &gt; NPVP 3 ) NP &gt; ProperN 4 ) NP &gt; DET N 5 ) NP &gt; DET ADJ N 6 ) PP- &gt; PREPNP 7 ) VP - &gt; V NP We shall insert inactive edges in the lower side of the sentence and active edges in the upper side of the sentence .</sentence>
				<definiendum id="0">concat</definiendum>
				<definiendum id="1">fromposition</definiendum>
				<definiendum id="2">toposition</definiendum>
				<definiendum id="3">fromposition</definiendum>
				<definiendum id="4">toposition</definiendum>
				<definiendum id="5">position toposition</definiendum>
				<definiendum id="6">fromposition</definiendum>
				<definiendum id="7">toposition</definiendum>
				<definiens id="0">If we have two active edges Ai and A2 , with to ( A 1 ) = from ( A2 ) rule ( A1 ) = rule ( A2 ) toposition ( A 1 ) = fromposition ( A2 ) and A1 is locally leftward largest and A2 is locally rightward largest , then we can introduce a new active edge A3 into the chart with from ( A3 ) = from ( A1 ) , to ( A3 ) = to ( A2 ) , rule ( A3 ) = rule ( A1 ) , fromposition ( A3 ) = fromposition ( A ! ) , toposition ( A3 ) =toposition ( A2 ) , sub-inactives ( A3 ) = concat ( sub-inactives ( Al ) , sub-inactives ( A2 ) )</definiens>
				<definiens id="1">the usual string concatenation operator. If fromposition ( Al ) =0 and toposition ( A2 ) =n , number of symbols in the right hand side of rule ( A1 ) , an inactive edge I is introduced instead</definiens>
				<definiens id="2">the number of symbols in the right hand side of the rule</definiens>
				<definiens id="3">an active edge with rule ( E ) = rule ( A ) and fromposition ( E ) = fromposition ( A ) , toposition ( E ) = i + 1. Similarly , if to ( I ) =from ( A ) , and having named i fromposition ( A ) , i¢ 0 , cat ( I ) = Ci-I , i-l-th symbol of the right handside of rule</definiens>
				<definiens id="4">an active edge with rule ( E ) =rule ( A ) , fromposition ( E ) =i-1 , toposition ( E ) = toposition ( A )</definiens>
				<definiens id="5">originally true for lexical edges of class a and false for the others , and during the process is propagated to any new edge that `` includes '' an edge with withisland = true. We can now state the I/bu Rule : When an inactive edge I , with .withisland ( I ) =true , is introduced in the chart , a new active edge is introduced for every rule R in the grammar that includes on its right hand side the symbol cat</definiens>
				<definiens id="6">A/td Rule : When an active edge A is added to the chart</definiens>
				<definiens id="7">A new active edge A can be inserted in the chart unless</definiens>
				<definiens id="8">VP - &gt; V NP We shall insert inactive edges in the lower side of the sentence and active edges in the upper side of the sentence</definiens>
			</definition>
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>It uses independent feature processing modules in configurations which allow Parallell , Sequential , Incremental ( PSI ) or Parallel , Hierarchical , Incremental ( PHI ) processing of phonetic data by the modules , with linguistically relevant output ( in this case , prosodic categories such as pitch accent ) .</sentence>
				<definiendum id="0">Incremental ( PHI</definiendum>
				<definiens id="0">) processing of phonetic data by the modules , with linguistically relevant output</definiens>
			</definition>
			<definition id="1">
				<sentence>At tile top is a representation of two digitised sigaal parameters .</sentence>
				<definiendum id="0">tile top</definiendum>
				<definiens id="0">a representation of two digitised sigaal parameters</definiens>
			</definition>
			<definition id="2">
				<sentence>`` CheOPS : an object-oriented system in PROLOG . ''</sentence>
				<definiendum id="0">CheOPS</definiendum>
				<definiens id="0">an object-oriented system in PROLOG</definiens>
			</definition>
</paper>

		<paper id="2139">
</paper>

		<paper id="2099">
			<definition id="0">
				<sentence>What `` relatively monolithic '' means is the subject of much of the rest of the paper ; at this point , we simply say that the DS remains the same as long as the deictic center does not undergo drastic changes in space , time , perspective or composition , while the beginning of a new DS is accompanied/signaled by a discontinuity in one or several of these parameters .</sentence>
				<definiendum id="0">DS</definiendum>
				<definiens id="0">the deictic center does not undergo drastic changes in space , time , perspective or composition , while the beginning of a new</definiens>
			</definition>
			<definition id="1">
				<sentence>We thus have three kinds of entities organized into three kinds of structures : linearly ordered stretches of text forming the Linear Text Structure ( LTS ) ; the Event-Situation Structure ( ESS , ef .</sentence>
				<definiendum id="0">Event-Situation Structure</definiendum>
				<definiens id="0">kinds of entities organized into three kinds of structures : linearly ordered stretches of text forming the Linear Text Structure ( LTS ) ; the</definiens>
			</definition>
			<definition id="2">
				<sentence>Webber 1987b ) , representing the narrative 's unfolding contents ; and the Current Focus Space , which is a collection of focusing mechanisms ( including the deictic center ) that together represent the `` attentional state '' ( Grosz &amp; Sidner 1986 ) of the system .</sentence>
				<definiendum id="0">Current Focus Space</definiendum>
				<definiens id="0">a collection of focusing mechanisms ( including the deictic center</definiens>
			</definition>
			<definition id="3">
				<sentence>The story consists of descriptions of situation , ; evolving or persisting in time .</sentence>
				<definiendum id="0">story</definiendum>
				<definiens id="0">consists of descriptions of situation , ; evolving or persisting in time</definiens>
			</definition>
			<definition id="4">
				<sentence>Wiebe &amp; Rapaport ( 1988 ) and Wiebe ( in progress ) present an outline of a detailed computational investigation of narrative perspecfive and reference .</sentence>
				<definiendum id="0">Wiebe (</definiendum>
				<definiens id="0">in progress ) present an outline of a detailed computational investigation of narrative perspecfive and reference</definiens>
			</definition>
			<definition id="5">
				<sentence>Plot nnits : A narrative summ .</sentence>
				<definiendum id="0">Plot nnits</definiendum>
				<definiens id="0">A narrative summ</definiens>
			</definition>
</paper>

		<paper id="2155">
			<definition id="0">
				<sentence>The Aidtrans Japanese-to-English prototype ( implemented in C , and running on a Sharp Unix-based microcomputer ) is an implementation of a comprehensive , highly detailed and sophisticated algorithmic grammar of Japanese developed by Dr. Jiri Jelinek as a teaching tool for rapid intensive instruction in technical Japanese ( Jelinek 1978 ) .</sentence>
				<definiendum id="0">Aidtrans Japanese-to-English prototype (</definiendum>
				<definiens id="0">implemented in C , and running on a Sharp Unix-based microcomputer</definiens>
				<definiens id="1">an implementation of a comprehensive</definiens>
			</definition>
			<definition id="1">
				<sentence>A text-type-specific linear predictive model is the basis for determining priorities or preferences among the possibilities .</sentence>
				<definiendum id="0">text-type-specific linear predictive model</definiendum>
			</definition>
</paper>

		<paper id="2102">
			<definition id="0">
				<sentence>The CME ( Consistency Maintenm~ce Engixtc ) is a component of the httegrated pa : rsmg ( mghte 4B2 re~ ; ponsib\ ] e fl ) r maintaining consistency among beliefs .</sentence>
				<definiendum id="0">CME ( Consistency Maintenm~ce Engixtc )</definiendum>
				<definiens id="0">a component of the httegrated pa : rsmg ( mghte 4B2 re~ ; ponsib\ ] e fl ) r maintaining consistency among beliefs</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus in figure 1 , E0 is the root node , and it represents an environmnet without any assumption .</sentence>
				<definiendum id="0">E0</definiendum>
				<definiens id="0">the root node</definiens>
			</definition>
			<definition id="2">
				<sentence>Following this anMysis , the PSE makes the assumptions to the integrated parsing engine : @ toord-1 ( t~ke the sequence ~KA t as a word ) : ~-~ probability 1/3 .</sentence>
				<definiendum id="0">PSE</definiendum>
			</definition>
</paper>

		<paper id="2119">
			<definition id="0">
				<sentence>E : `` Tapazole is a drug that decreases the function of the thyroid . ''</sentence>
				<definiendum id="0">E</definiendum>
			</definition>
			<definition id="1">
				<sentence>, % 1 : tfde~tifieation Many naturally occurring definitions contain au Identification component , identification consists ( ff ideutifying the entity beiug described as a member ( d a generic class in a hierarchicMly structured knowledge base ~for example , E : `` Amaretto is a liqueur . ''</sentence>
				<definiendum id="0">Amaretto</definiendum>
				<definiens id="0">tfde~tifieation Many naturally occurring definitions contain au Identification component , identification consists ( ff ideutifying the entity beiug described as a member ( d a generic class in a hierarchicMly structured knowledge base ~for example</definiens>
			</definition>
			<definition id="2">
				<sentence>569 An Operation response consists of a description of how something works .</sentence>
				<definiendum id="0">Operation response</definiendum>
			</definition>
			<definition id="3">
				<sentence>Significance reflects where the proposition fits into the system 's model of the user 's goals and possible plans for accomplishing them ( relevance ) and what information in the generalization hierarchy has been marked as known by the user ( familiarity ) .</sentence>
				<definiendum id="0">Significance</definiendum>
				<definiens id="0">reflects where the proposition fits into the system 's model of the user 's goals and possible plans for accomplishing them ( relevance ) and what information in the generalization hierarchy has been marked as known by the user</definiens>
			</definition>
</paper>

		<paper id="2167">
			<definition id="0">
				<sentence>A directed graph consists of a set of nodes and arcs connecting a pair of nodes .</sentence>
				<definiendum id="0">directed graph</definiendum>
			</definition>
			<definition id="1">
				<sentence>2~ % intra -- nede action is one relating to only one node eogo ; @ X : T = T + \ [ t \ ] ; Add a value t to the set-type attribute q ' of nede @ X .</sentence>
				<definiendum id="0">nede action</definiendum>
				<definiens id="0">one relating to only one node eogo ; @ X : T = T + \</definiens>
			</definition>
			<definition id="2">
				<sentence>HICATS/JE : A Japanese-to-English Machine Translation System Based on Se~ntics , Mac/line Translation SLmmdt .</sentence>
				<definiendum id="0">HICATS/JE</definiendum>
			</definition>
			<definition id="3">
				<sentence>Rete : A Fast Algoritl~n for the Many Pattern / Many Object Pattern Match Problems Artificial Intelligence0 Vol .</sentence>
				<definiendum id="0">Rete</definiendum>
				<definiens id="0">A Fast Algoritl~n for the Many Pattern / Many Object Pattern Match Problems Artificial Intelligence0 Vol</definiens>
			</definition>
</paper>

	</volume>
