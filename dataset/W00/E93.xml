<?xml version="1.0" encoding="UTF-8"?>
	<volume id="E93">

		<paper id="1066">
			<definition id="0">
				<sentence>Turkish is an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words .</sentence>
				<definiendum id="0">Turkish</definiendum>
				<definiens id="0">an agglutinative language with word structures formed by productive affixations of derivational and inflectional suffixes to root words</definiens>
			</definition>
			<definition id="1">
				<sentence>Morphemes added to a root word or a stem can convert the word from a nominal to a verbal structure or vice-versa , or can create adverbial constructs .</sentence>
				<definiendum id="0">Morphemes</definiendum>
				<definiens id="0">added to a root word or a stem can convert the word from a nominal to a verbal structure or vice-versa , or can create adverbial constructs</definiens>
			</definition>
</paper>

		<paper id="1043">
			<definition id="0">
				<sentence>Morphophonology : Phonological alterations occuring in the process of combination .</sentence>
				<definiendum id="0">Morphophonology</definiendum>
				<definiens id="0">Phonological alterations occuring in the process of combination</definiens>
			</definition>
			<definition id="1">
				<sentence>The lexical level consists of a sequence of morphs as found in the lexicon ; the surface level is the form found in the actual text/utterance .</sentence>
				<definiendum id="0">lexical level</definiendum>
				<definiendum id="1">surface level</definiendum>
				<definiens id="0">the form found in the actual text/utterance</definiens>
			</definition>
			<definition id="2">
				<sentence>This complex feature UMLAUT consists of a feature for each class , which takes as value + or and one feature value for the recording of actual occurrence of umlaut : LrMLAUT : `` VALUE : binary\ ] PL-UML : binary\ ] LICH-UML : binary I ISCH-UML : binaryJ The value of the feature UMLAUT\ [ VALUE is set by the morphological filter of the two-level rule triggering umlaut , i.e. , if an umlaut is found it is set to + otherwise to - .</sentence>
				<definiendum id="0">VALUE</definiendum>
				<definiens id="0">takes as value + or</definiens>
			</definition>
			<definition id="3">
				<sentence>A iezeme lexicon contains the lexemes , i.e. stem morphs and derivational endings ( because of their word-forming capacity ) .</sentence>
				<definiendum id="0">iezeme lexicon</definiendum>
				<definiens id="0">contains the lexemes , i.e. stem morphs and derivational endings ( because of their word-forming capacity )</definiens>
			</definition>
			<definition id="4">
				<sentence>single-ster~ Figure 9 : 'PHON : trEt \ [ O T '' V\ ] \ ] STEM : tret ) ' \ [ HEAD : verb CAT : \ [ sunoAT : ( NP\ [ SVBJ\ ] , SYNSEM : \ [ REL : fret ' CONT : IAGENT : \ [ ~persor LTO : ~to-loc Lexical entry for verb treten ( preliminary version ) 374 single .</sentence>
				<definiendum id="0">SYNSEM</definiendum>
				<definiens id="0">'PHON : trEt \ [ O T '' V\ ] \ ] STEM : tret ) ' \ [ HEAD : verb CAT : \ [ sunoAT : ( NP\ [ SVBJ\ ] ,</definiens>
			</definition>
</paper>

		<paper id="1058">
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>The way out of this problem is the relationship between the 'non-fiat ' categorisation strategy and Cutbased proofs , to illustrate which , note that if there were derivable categorisations , x ' and yl of the subexpressions , which combined to give z , then L ( /'\ ) + Cut ~x , y : =~ z : ( 1 ) Y ==~ y , x I , yl ==~ z Cut Cut x , y =C. z So parsing with an L ( / , \ ) grammar comes to deciding the derivability of Xl , ... , xo = : ~ s , where xi are the categories of the lexical items .</sentence>
				<definiendum id="0">Cutbased proofs</definiendum>
				<definiendum id="1">xi</definiendum>
				<definiens id="0">combined to give z , then L ( /'\ ) + Cut ~x , y : =~ z : ( 1 ) Y ==~ y , x I , yl ==~ z Cut Cut x</definiens>
			</definition>
			<definition id="1">
				<sentence>Belonging to Lambek grammar proper is a part assigning some category to the strings to be coordinated , and then lying without Lambek grammar , a coordination schema , such as x , and , x : :~ x. 121 To overcome these deficits in coverage , I have proposed a polymorphic extension of the calculus .</sentence>
				<definiendum id="0">Lambek grammar proper</definiendum>
				<definiens id="0">a part assigning some category to the strings to be coordinated</definiens>
			</definition>
			<definition id="2">
				<sentence>Note ( s\np ) \ ( ( s\np ) /s ) : X. 2The ( VR ) given is a cut-down version of the 'official ' version , which allows a change of bound variable np , s\np ~ X nP , ( s\np ) /s , X =~s s\np =~ . ''</sentence>
				<definiendum id="0">VR</definiendum>
				<definiens id="0">a cut-down version of the 'official ' version , which allows a change of bound variable np</definiens>
			</definition>
			<definition id="3">
				<sentence>One hopes then that : ( i ) the set of so-defined deduction trees for a given sequent , r , is finite ( ii ) there is some easy to check property , P , of these trees such that the existence of a P-tree in the set would be equivalent to L ( / , \ , v ) ~-r. Now , if we were considering the combination of first-order quantification with the Lambek calculus , this strategy works , but whether it works for n ( /'\ , v ) remains unknown .</sentence>
				<definiendum id="0">Lambek calculus</definiendum>
			</definition>
			<definition id="4">
				<sentence>The 'substitute an unknown ' rewrite reading of ( VL ) defines only finitely many deduction trees for a sequent , r. However , these so-defined deduction trees for r do not cover all the possible palterns for a proof of r : unlike g ( / , \'v~ ) , there are rules that build complexity in the places in categories where a bound variable can occur .</sentence>
				<definiendum id="0">VL</definiendum>
				<definiens id="0">build complexity in the places in categories where a bound variable can occur</definiens>
			</definition>
			<definition id="5">
				<sentence>For each of the V~ sequents , the minimum number of steps there can be between the conclusion of the ( VL ) step and the V~ sequent is the length of the paths to the associated occurrence of the bound variable in the quantified category .</sentence>
				<definiendum id="0">sequent</definiendum>
				<definiens id="0">the length of the paths to the associated occurrence of the bound variable in the quantified category</definiens>
			</definition>
			<definition id="6">
				<sentence>On the basis of these observations , I suggest the following decision procedure : 6 Definition 1 ( Decision procedure ) Where A , r vary over possibly empty sequences of sequents , let a rewrite procedure 7~ be defined as follows from 0 by some rule of L ( /'\'v ) other than O/L ) where X is an unknown , and there are no other unknowns in A , U , VZ .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">Decision procedure ) Where A , r vary over possibly empty sequences of sequents , let a rewrite procedure 7~ be defined as follows from 0 by some rule of L ( /'\'v ) other than O/L ) where</definiens>
				<definiens id="1">an unknown</definiens>
			</definition>
			<definition id="7">
				<sentence>w , T : :~ y , F. A , U , x , V ~ w , T : :~ y , r must have a shortest accepting rewrite of length &lt; l , so by induction there is a substitution such that L ( / , \ , v ) ~-sub ( A ) , sub ( U , x , V =~ w ) , sub ( T : :V y ) , sub ( r ) .</sentence>
				<definiendum id="0">sub</definiendum>
				<definiendum id="1">:V y</definiendum>
				<definiens id="0">:~ y , F. A , U , x</definiens>
			</definition>
</paper>

		<paper id="1051">
			<definition id="0">
				<sentence>In addition , classes of built-in predicates over finite domain variables exist for : ( 1 ) arithmetic and symbolic constraints ( basic constraints for domain variables ) , ( 2 ) choice predicates ( help making choices ) , ( 3 ) higher order predicates ( providing optimisation methods for combinatorial problems using depth-first and branch and bound strategies ) and ( 4 ) extra-logical predicates ( for help in debugging processes ) .</sentence>
				<definiendum id="0">basic constraints</definiendum>
				<definiens id="0">help making choices</definiens>
			</definition>
			<definition id="1">
				<sentence>Minimize is one of CHIP 's optimisation built-in predicates .</sentence>
				<definiendum id="0">Minimize</definiendum>
				<definiens id="0">one of CHIP 's optimisation built-in predicates</definiens>
			</definition>
			<definition id="2">
				<sentence>Cost is a domain variable whose domain is constrained to an arithmetic term .</sentence>
				<definiendum id="0">Cost</definiendum>
			</definition>
			<definition id="3">
				<sentence>After functionword-deletion the program is given the following set of words : bank arrange overdraft account These are processed according to their stemmed sense definitions in LDOCE , represented as Prolog database structures such as : ba~k ( \ [ \ [ bank , land , along , side , river , lake\ ] , \ [ bank , earth , heap , field , garden , make , border , division\ ] , \ [ bank , mass , snow , cloud , mud\ ] , \ [ bank , slope , make , bend , road , race , track , safer , car , go , round\ ] , \ [ bank , sandbank\ ] , \ [ bank , car , aircraft , move , side , higher , other , make , turn\ ] , \ [ bank , row , oar , ancient , boat , key , typewriter\ ] , \ [ bank , place , money , keep , pay , demand , relate , activity , go\ ] , \ [ bank , place , something , hold , ready , use , organic , product , human , origin , medical , use\ ] , \ [ bank , person , keep , supply , money , piece , payment , use , game , chance\ ] , \ [ bank , win , money , game , chance\ ] , \ [ bank , put , keep , money , bank\ ] , \ [ keep , money , state , bank\ ] J ) .</sentence>
				<definiendum id="0">field</definiendum>
				<definiens id="0">make , bend , road , race , track , safer , car</definiens>
				<definiens id="1">typewriter\ ] , \ [ bank , place , money , keep , pay , demand , relate , activity</definiens>
			</definition>
			<definition id="4">
				<sentence>This suggests a dramatic reduction on the search space ; CHIP offers all the necessary arithmetic and symbolic facilities for the implementation .</sentence>
				<definiendum id="0">CHIP</definiendum>
				<definiens id="0">offers all the necessary arithmetic and symbolic facilities for the implementation</definiens>
			</definition>
			<definition id="5">
				<sentence>In Pathfinder associative networks : studies in knowledge organisation , R. Schvaneveldt ( ed ) , Norwood , NJ : Ablex , 1990 .</sentence>
				<definiendum id="0">Schvaneveldt</definiendum>
				<definiens id="0">studies in knowledge organisation</definiens>
			</definition>
</paper>

		<paper id="1038">
			<definition id="0">
				<sentence>A metrical line is defined as a line plus a government relation on that line : Definition 2 ( Metrical line ) A metrical line MLi is a pair &lt; Li , P~ &gt; , where Li is a line Ri is a relation on Li and an element of { -~i , &gt; -i , -- , i , ~-'i , '~i } ZThat is , if we follow the current tradition rather than HV .</sentence>
				<definiendum id="0">metrical line</definiendum>
				<definiendum id="1">metrical line MLi</definiendum>
				<definiendum id="2">Li</definiendum>
				<definiens id="0">a line plus a government relation on that line : Definition 2 ( Metrical line</definiens>
				<definiens id="1">a pair &lt; Li , P~ &gt; , where</definiens>
				<definiens id="2">a line Ri is a relation on Li and an element of { -~i , &gt; -i , -- , i</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , the Continuous Column Constraint , which plays a crucial role as an independent stipulation in \ [ Hayes , 1991\ ] can be derived from definition 6 as a theorem : ( 4 ) Continuous Column Constraint ( CCC ) : A grid containing a column with a mark on layer ( =our metrical line ) n+l and no mark on layer n is ill-formed .</sentence>
				<definiendum id="0">Continuous Column Constraint</definiendum>
			</definition>
			<definition id="2">
				<sentence>This Binary Constituency Hypothesis can be formulated by replacing definition 2 : Definition 12 A metrical line MLI is a pair &lt; Li , Ri &gt; , where Li is a line Ri is a relation on Li and an element of { ~i , ~i } In this section , we will try to see in how much bracketed grids and trees are really different formal systerns , i.e. to what extent one can say things in one formalism that are impossible to state in the other .</sentence>
				<definiendum id="0">Binary Constituency Hypothesis</definiendum>
				<definiendum id="1">MLI</definiendum>
				<definiendum id="2">Li</definiendum>
				<definiens id="0">a pair &lt; Li</definiens>
				<definiens id="1">a relation on Li and an element</definiens>
			</definition>
			<definition id="3">
				<sentence>First recall the standard definition of a tree ( we cite from \ [ Partee et al. , 1990\ ] ) 5 : Definition 13 ( Tree ) A ( constituent structure ) tree is a mathematical configuration &lt; N , Q , D , P , L &gt; , where N is a finite set , the set of nodes Q is a finite set , the set of labels D is a weak partial order in N × N , the dominance relation P is a strict partial order in N x N , the precedence relation L is a function from N into Q , the labeling function and such that the following conditions hold : ( a ) 3a E N : V/~ G N : \ [ &lt; a , /~ &gt; E O\ ] ( Single root condition ) ( b ) W , a ~ N : \ [ ( &lt; ~ , ~ &gt; ~ PV &lt; a , ~ &gt; E P ) ¢* ( &lt; a , /~ &gt; ¢ D^ &lt; /~ , a &gt; ¢ D ) \ ] ( Exclusivity condition ) ( c ) Va , ~,7,6 : \ [ ( &lt; ot , /~ &gt; E PA &lt; a,7 &gt; E DA &lt; 8 , 6 &gt; E D ) ~ &lt; 7 , 6 &gt; E P\ ] ( Nontangling condition ) It is clear that bracketed grids and trees have structures which can not be compared immediately .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">precedence relation L</definiendum>
				<definiens id="0">a finite set</definiens>
				<definiens id="1">V/~ G N : \ [ &lt; a</definiens>
			</definition>
			<definition id="4">
				<sentence>Bracketed grids are pairs consisting of a set of complex objects ( the lines ) and one total ordering relation defined on those objects ( the above relation ) .</sentence>
				<definiendum id="0">Bracketed grids</definiendum>
				<definiens id="0">pairs consisting of a set of complex objects ( the lines</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>We plan a two-stage architecture for LEXTER-K , that is , ( 1 ) the extraction of the terminology of the subject field , by a robust grammatical analysis ( LEXTER ) , ( 2 ) the syntactic analysis of the sentences by a parser using this terminology .</sentence>
				<definiendum id="0">LEXTER</definiendum>
				<definiens id="0">a two-stage architecture for LEXTER-K , that is , ( 1 ) the extraction of the terminology of the subject field , by a robust grammatical analysis (</definiens>
			</definition>
			<definition id="1">
				<sentence>( 2 ) At the parsing stage , LEXTER parses the maximal-length noun phrases ( henceforth MLNP ) in order to generate sub-groups , in addition to the MLNP , which are likely terminological units by virtue of their grammatical structure and their position in the MLNP .</sentence>
				<definiendum id="0">LEXTER</definiendum>
				<definiendum id="1">maximal-length noun phrases</definiendum>
				<definiendum id="2">generate sub-groups</definiendum>
				<definiendum id="3">MLNP</definiendum>
				<definiens id="0">likely terminological units by virtue of their grammatical structure and their position in the MLNP</definiens>
			</definition>
			<definition id="2">
				<sentence>Closed Yesterday and Closed Minds : Asking the Right Questions of the Corpus To Distinguish Thematic from Sentential Relations .</sentence>
				<definiendum id="0">Closed Minds</definiendum>
				<definiens id="0">Asking the Right Questions of the Corpus To Distinguish Thematic from Sentential Relations</definiens>
			</definition>
</paper>

		<paper id="1033">
			<definition id="0">
				<sentence>Misunderstandings occur when agents differ in their beliefs about what has been said or why .</sentence>
				<definiendum id="0">Misunderstandings</definiendum>
				<definiens id="0">occur when agents differ in their beliefs about what has been said or why</definiens>
			</definition>
			<definition id="1">
				<sentence>£ includes an infinite number of variables and function symbols of every sort and arity .</sentence>
				<definiendum id="0">£</definiendum>
				<definiens id="0">includes an infinite number of variables and function symbols of every sort and arity</definiens>
			</definition>
			<definition id="2">
				<sentence>/ : Th includes all the sorts , terms , functions , and predicates of / : ; however , / : Tit lacks explicit quantification , distinguishes facts from defaults , and associates with each default a priority value .</sentence>
				<definiendum id="0">Th</definiendum>
				<definiens id="0">includes all the sorts , terms , functions , and predicates of /</definiens>
			</definition>
			<definition id="3">
				<sentence>278 where p is a priority value , d is an atomic symbol with only free variables as arguments , and w is a wtf .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">a priority value , d is an atomic symbol with only free variables as arguments</definiens>
			</definition>
			<definition id="4">
				<sentence>If Y : is the set of facts and AP is the set of defaults with priority p , then an expression DEFAULT ( p , d ) : w asserts that d E A p and ( d D w ) E .</sentence>
				<definiendum id="0">AP</definiendum>
				<definiendum id="1">DEFAULT</definiendum>
				<definiens id="0">the set of facts</definiens>
				<definiens id="1">the set of defaults with priority p , then an expression</definiens>
			</definition>
			<definition id="5">
				<sentence>Utterance interpretation is the complementary ( abductive ) process of attributing to the speaker communicative and interactional goals by attributing to him or her a discourse-level form that provides a reasonable explanation for an observed utterance in the current context .</sentence>
				<definiendum id="0">Utterance interpretation</definiendum>
				<definiens id="0">the complementary ( abductive ) process of attributing to the speaker communicative and interactional goals by attributing to him or her a discourse-level form that provides a reasonable explanation for an observed utterance in the current context</definiens>
			</definition>
			<definition id="6">
				<sentence>We assume that an agent 's beliefs and goals are given explicitly by statements of the form believe ( S , P ) and hasGoal ( S , P , TS ) , respectively , where S is an agent , P is a supposition and TS is a turn sequence .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">P</definiendum>
				<definiendum id="2">TS</definiendum>
				<definiens id="0">an agent</definiens>
				<definiens id="1">a supposition and</definiens>
			</definition>
			<definition id="7">
				<sentence>Turn sequences are characterized by the following three relations : • tumOr ( is , t ) holds if and only if t is a turn in the sequence ts ; • succ ( tj , tl , ts ) holds if and only if turnO\ ] ( ts , ti ) , turnOf ( ts , tj ) , tj follows ti in ts , and there is no t~ such that turnOf ( ts , tk ) , suce ( tk , ti , ts ) , and succ ( tj , tk , ts ) ; • focus ( ts , t ) holds ift is a distinguished turn upon which the sequence is focused ; normally this is the last turn of ts .</sentence>
				<definiendum id="0">suce</definiendum>
				<definiendum id="1">t ) holds ift</definiendum>
				<definiens id="0">a turn in the sequence ts ; • succ ( tj , tl , ts</definiens>
				<definiens id="1">ts , tj ) , tj follows ti in ts</definiens>
			</definition>
			<definition id="8">
				<sentence>It is represented as a set of statements of the form expressed ( P , T ) or expressedNot ( P , T ) where P is a simple supposition and T is a turn .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">a simple supposition</definiens>
				<definiens id="1">a turn</definiens>
			</definition>
			<definition id="9">
				<sentence>DEFAULT ( 1 , aetivationp ersists ( p , t ) ) : active ( p , tsi ) A sueeessorTS ( tsnow , tsi ) A foeus ( tsno~ , t ) D adive ( p , ts .</sentence>
				<definiendum id="0">sueeessorTS</definiendum>
			</definition>
			<definition id="10">
				<sentence>The predicate expectedReply is a default .</sentence>
				<definiendum id="0">expectedReply</definiendum>
				<definiens id="0">a default</definiens>
			</definition>
			<definition id="11">
				<sentence>`` If agent $ 1 intends that agent S $ perform the action A~ and A2 is the expected reply to the action A1 , and it would be coherent for SI to perform A1 , then $ 1 should do so . ''</sentence>
				<definiendum id="0">A2</definiendum>
				<definiens id="0">the expected reply to the action A1 , and it would be coherent for SI to perform A1</definiens>
			</definition>
			<definition id="12">
				<sentence>Assuming T1 is a pretelling , just prior to T3 , Russ 's model of the discourse corresponds to the following : expressed ( do ( m , pretell ( m , r , w ) ) , 1 ) expressed ( knowref ( m , w ) , 1 ) expressed ( knowsBetterItef ( m , r , w ) , 1 ) expressed ( intend ( m , do ( m , informref ( m , r , w ) ) ) , 1 ) expressed ( intend ( m , knowref ( r , w ) ) , 1 ) expressed ( do ( r , askref ( r , m , w ) ) , 2 ) expressedNot ( knowref ( r , w ) , 2 ) expressed ( intend ( r , knowref ( r , w ) ) , 2 ) expressed ( intend ( r , do ( m , informref ( m , r , w ) ) ) , 2 ) T3 does not demonstrate acceptance because inform ( m , r , not ( knowref ( m , w ) ) ) is not coherent with this interpretation of the discourse .</sentence>
				<definiendum id="0">T1</definiendum>
				<definiendum id="1">informref</definiendum>
				<definiendum id="2">knowref ( r , w )</definiendum>
				<definiendum id="3">askref</definiendum>
				<definiens id="0">a pretelling , just prior to T3</definiens>
			</definition>
			<definition id="13">
				<sentence>lexpectation ( do ( a , testref ( a , b , d ) ) , and ( knowref ( b , d ) , and ( knowlf ( b , p ) , and ( pred ( p , X ) , pred ( d , X ) ) ) , do ( b , asklf ( b , a , p ) ) ) The condition of this rule requires that B believe he knows the referent of description d and that p asserts that the described property holds of the referent that he knows .</sentence>
				<definiendum id="0">lexpectation</definiendum>
				<definiens id="0">the described property holds of the referent that he knows</definiens>
			</definition>
</paper>

		<paper id="1065">
			<definition id="0">
				<sentence>INSYST ( INserter SYSTem ) , we describe here , can efficiently insert lexical items under the appropriate nodes in hierarchies .</sentence>
				<definiendum id="0">INSYST</definiendum>
				<definiens id="0">items under the appropriate nodes in hierarchies</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>By a signature ( £ , S ) is meant a pair of non-empty sets L : and S , the set of arc labels and the set of sorts respectively .</sentence>
				<definiendum id="0">S )</definiendum>
				<definiens id="0">meant a pair of non-empty sets L : and S , the set of arc labels and the set of sorts respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>A feature structure is a triple ( W , { Rt } tez : , V ) , where W is a non-empty set ( the set of nodes ) ; each Rz is a binary relation on W that is also a partial function ; and V ( the valuation ) is a function which assigns each propositional symbol p E S a subset of W. Note that as we have defned them features structures are merely multimodal Kripke models , 4 and we often refer to feature structures as models in what follows .</sentence>
				<definiendum id="0">feature structure</definiendum>
				<definiendum id="1">W</definiendum>
				<definiendum id="2">Rz</definiendum>
				<definiendum id="3">V</definiendum>
				<definiens id="0">a non-empty set ( the set of nodes</definiens>
				<definiens id="1">a binary relation on W that is also a partial function</definiens>
				<definiens id="2">a function which assigns each propositional symbol p E S a subset of W.</definiens>
			</definition>
			<definition id="2">
				<sentence>Of course , if this is all we do we trivialise the satisfiability problem : it is immediate by induction on the structure of negation free wffs ¢ , that every negation free L KR~ wff is satisfied in the following model : M = ( { w } , { Rt } tec , V ) where Rz = { ( w , w ) } for all/E/~ , and Y ( p ) = { w } for all propositional variables p. So we have regained decidability , but in a very uninteresting way .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">immediate by induction on the structure of negation free wffs ¢ , that every negation free L KR~ wff is satisfied in the following model : M = ( { w }</definiens>
			</definition>
			<definition id="3">
				<sentence>Lemma 3.1 Let a be any wff containing no logical connectives apart from V and A. Then in any extensional model , c~ is satisfied at at most m nodes , where m is the number of distinct sort symbols in a. Proof : By induction on the construction of a. \ [ \ ] The importance of this lemma is that it gives us an upper bound on the number of nodes at which the antecedents ai of the constraints permitted in our fragment can be satisfied .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">any wff containing no logical connectives apart from V and A. Then in any extensional model</definiens>
			</definition>
			<definition id="4">
				<sentence>The nodes of M ( henceforth W ) , play the role of points in a grid , R , is the right successor relation , and Ru is the upward successor relation .</sentence>
				<definiendum id="0">Ru</definiendum>
				<definiens id="0">the right successor relation , and</definiens>
				<definiens id="1">the upward successor relation</definiens>
			</definition>
			<definition id="5">
				<sentence>Define : ¢9ri d = ( TrUe ~ ( , ) ( U ) ~ , ~ ( u ) ( r ) ) .</sentence>
				<definiendum id="0">Define</definiendum>
				<definiens id="0">¢9ri d = ( TrUe ~ ( , ) ( U ) ~</definiens>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>MOI_USC ( \ [ Cahill , 1990a\ ] , \ [ Cahill , 1990b\ ] , \ [ Cahill and Gazdar , 1990\ ] ) , is a formal language for defining morphological alternations as mappings between sequences of tree-structured syllables .</sentence>
				<definiendum id="0">MOI_USC</definiendum>
				<definiens id="0">a formal language for defining morphological alternations as mappings between sequences of tree-structured syllables</definiens>
			</definition>
			<definition id="1">
				<sentence>We can define the value of the voicing feature of the coda in the past tense form to be dependent on the values of all four of these features : &lt; val voice coda past &gt; == &lt; coda_change `` &lt; val fric coda pres &gt; '' ~This is the peak of the final syllable in all cases .</sentence>
				<definiendum id="0">~This</definiendum>
				<definiens id="0">the peak of the final syllable in all cases</definiens>
			</definition>
</paper>

		<paper id="1040">
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>The primitive alphabet of the language LT ( Prop ) contains the following items : two constant symbols s and t , some truth functionally adequate collection of Boolean operators , 2 two unary modalities ~ and T , a binary modality : :~ , a modality of arbitrary positive arity • , the left bracket ( and the right bracket ) .</sentence>
				<definiendum id="0">primitive alphabet of the language LT</definiendum>
			</definition>
			<definition id="1">
				<sentence>We regard finite trees T as quadruples of the form ( F , &gt; , O , root ) , where r is a finite set of nodes , &gt; is the 'Mother of ' relation between nodes ( 'u &gt; v ' means 'u is the mother of v ' ) , O ( C_ r ) is the set of terminal nodes and root is the root node of the tree .</sentence>
				<definiendum id="0">r</definiendum>
				<definiens id="0">quadruples of the form ( F , &gt; , O , root )</definiens>
				<definiens id="1">the set of terminal nodes and root is the root node of the tree</definiens>
			</definition>
			<definition id="2">
				<sentence>As for the precedence ordering , we define : Definition 2.1 ( Finite ordered trees ) A finite ordered tree is a pair O = IT , A ) where T is a tree ( I ' , &gt; , ( 9 , root ) and A is a function assigning to each node u in F a finite sequence of nodes of F. For all nodes u • I ' , 2 ( u ) must satisfy two constraints .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">a tree ( I '</definiens>
			</definition>
			<definition id="3">
				<sentence>Next , we define a model M to be a pair ( O , V ) where O is a finite ordered tree ( T , ) ~ ) and V is a function from Prop to the powerset of r. That is , V assigns to each propositional symbol a set of nodes .</sentence>
				<definiendum id="0">O</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">a finite ordered tree ( T</definiens>
				<definiens id="1">a function from Prop to the powerset of r. That is , V assigns to each propositional symbol a set of nodes</definiens>
			</definition>
			<definition id="4">
				<sentence>Given any model M and any node u of M , the satisfaction relation M , u ~ ¢ , ( that is , the model M satisfies ¢ at node u ) is defined as follows : M , u~p iff ueV ( p ) , for all p E Prop M , u ~ s iff u = root M , u~t iff uEO M , u~-~¢ iff not M , u~¢ M , u ~¢A¢ iff M , u~¢ and M , u ~ ¢ M , u~¢ iff BC•r ( u &gt; C and M , u ' ~ ¢ ) M , u~T¢ iff 3u ' •F ( u ' &gt; u and M , u ' ~ ¢ ) M , u ~¢=~¢ iff Vu ' • r ( M , ul ~ ¢ implies M , u ' ~ ¢ ) M , u ~ * ( ¢1 , ... , ¢k ) iff length ( A ( u ) ) = k and M , ) t ( u ) ( i ) ~ ¢i , for all 1 &lt; i &lt; k ( In the satisfaction clause for e , ~ ( u ) ( i ) denotes the ith element of the sequence assigned to u by ~ . )</sentence>
				<definiendum id="0">, u~¢ iff BC•r</definiendum>
				<definiens id="0">any node u of M , the satisfaction relation M , u ~ ¢ , ( that is , the model M satisfies ¢ at node u ) is defined as follows : M , u~p iff ueV ( p ) , for all p E Prop M , u ~ s iff u = root M , u~t iff uEO M , u~-~¢ iff not M , u~¢ M , u ~¢A¢ iff M , u~¢ and M , u ~ ¢ M</definiens>
				<definiens id="1">u &gt; C and M , u ' ~ ¢ ) M , u~T¢ iff 3u ' •F ( u ' &gt; u and M , u ' ~ ¢ ) M , u ~¢=~¢ iff Vu ' • r ( M , ul ~ ¢ implies M , u ' ~ ¢ ) M , u ~ * ( ¢1 , ... , ¢k ) iff length ( A ( u ) ) = k and M , ) t ( u ) ( i ) ~ ¢i , for all 1 &lt; i &lt; k ( In the satisfaction clause for e , ~ ( u ) ( i ) denotes the ith element of the sequence assigned to u by ~</definiens>
			</definition>
			<definition id="5">
				<sentence>Consider the context free phrase structure grammar G = ( S , N , T , P ) where S is the start symbol of G ; where N , the set of non-terminal symbols , is { S , NP , VP , N , V , DET , CONJ } ; where T , the set of terminal symbols , is { the , a , man , woman , donkey , beat , stroke , and , but } ; and where P , the set of productions , is : S , NP VP\ [ S CONJS NP ) DET N VP ~ V NP N , man JwomauJ donkey V ~ beat \ [ stroke D ET ) the \ [ a CONJ , and I but Let 's consider how to capture the parse trees of this grammar by means of constraints formulated in L T. The first step is to fix our choice of Prop .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the start symbol of G</definiens>
				<definiens id="1">the set of terminal symbols , is { the , a , man , woman , donkey , beat , stroke</definiens>
			</definition>
			<definition id="6">
				<sentence>Now , for the final step : let eG be eP A dr. That is , eG expresses both the productions P of G and the universal facts about parse tree structure .</sentence>
				<definiendum id="0">eG</definiendum>
				<definiens id="0">expresses both the productions P of G and the universal facts about parse tree structure</definiens>
			</definition>
			<definition id="7">
				<sentence>Thus it is unsurprising that the semantics of L F is given in terms of feature structures : Definition 4.1 ( Feature structures ) A feature structure of signature ( ~ , ,4 ) is a triple F of the form ( W , { RI } /el : , V ) , where W is a nonempty set , called the set of points ; for all f 6 ~ ' , R !</sentence>
				<definiendum id="0">W</definiendum>
			</definition>
			<definition id="8">
				<sentence>is a binary relation on W that is a partial function ; and V is a function that assigns to each propositional symbol ( that is , each ~ 6 ,4 ) , a subset of W. 7 \ [ \ ] Our satisfaction definition for L F wffs is as follows .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">a function that assigns to each propositional symbol</definiens>
			</definition>
			<definition id="9">
				<sentence>For any F = ( W , { Rl } yey , V ) and any point w 6 W : F , w ~ a iff w 6 V ( ~ ) , for all a fi ,4 F , w ~ -~¢ iff not F , w ~ ¢ F , w~¢A¢ iff F , w~¢ and F , w~¢ F , w ~ ( f ) ¢ iff 3w ' ( wRlw ' and F , w ' ~ ¢ ) With L F and its semantics defined , we are ready to define a language for talking about trees decorated with feature structures : the language LT ( LF ) , that is , the language L T layered over the language L F. That is , we choose Prop to be L F and then make the L T wffs on top of this base in the usual way .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">L F. That</definiendum>
				<definiens id="0">a language for talking about trees decorated with feature structures : the language LT ( LF ) , that is , the language L T layered over the language</definiens>
			</definition>
			<definition id="10">
				<sentence>Definition 4.2 ( Feature decorated trees ) By a ( finite ordered ) feature structure decorated tree ( of signature ( Yr , A ) ) is meant a triple ( O , D , d ) where O is a finite ordered tree , D is a function that assigns to each node u of O a feature structure ( of signature ( , A ) ) , and d is a function that assigns to each node u of O a point of D ( u ) .</sentence>
				<definiendum id="0">Yr</definiendum>
				<definiendum id="1">O</definiendum>
				<definiendum id="2">D</definiendum>
				<definiendum id="3">d</definiendum>
				<definiens id="0">a finite ordered tree</definiens>
				<definiens id="1">a function that assigns to each node u of O a feature structure ( of signature ( , A ) ) , and</definiens>
			</definition>
			<definition id="11">
				<sentence>The wffs of the language LT ( L F ) ( of signature ( ~ , ~4 ) ) axe defined as follows .</sentence>
				<definiendum id="0">The wffs of the language LT</definiendum>
				<definiens id="0">L F ) ( of signature ( ~ , ~4 ) ) axe defined as follows</definiens>
			</definition>
			<definition id="12">
				<sentence>In what follows , we show how LT ( L F ) can be used to model some of these admissibility conditions on local trees : section 5.2.1 shows how to model phrase structure restrictions and section 5.2.2 concentrates on FCRs .</sentence>
				<definiendum id="0">LT</definiendum>
				<definiens id="0">local trees : section 5.2.1 shows how to model phrase structure restrictions and section 5.2.2 concentrates on FCRs</definiens>
			</definition>
			<definition id="13">
				<sentence>As the name indicates , I ( mmediate ) D ( ominance ) statements encode immediate dominance restrictions on local trees ( for instance , the ID rule A -- * B , C licenses any local tree consisting of a mother node labeled with category A and exactly two daughter nodes labeled with 11For a more precise formulation of the constraints on tree admissibility , see \ [ Gazdar et al. 1985 , page 100\ ] .</sentence>
				<definiendum id="0">C</definiendum>
			</definition>
			<definition id="14">
				<sentence>We capture the FFP by means of the following schema : ( FOOT ) ~b =~I~ ( FOOT ) ~b. This says that for any node u , if the information ~b is reachable by making a FOOT transition in the feature structure associated with u , then it must also be possible to obtain the information ~b by making a FOOT transition in the feature structure associated with the mother of u. That is , FOOT information percolates up the tree .</sentence>
				<definiendum id="0">~b =~I~</definiendum>
				<definiens id="0">the information ~b by making a FOOT transition in the feature structure associated with the mother of u. That is , FOOT information percolates up the tree</definiens>
			</definition>
			<definition id="15">
				<sentence>Controller and controllee are defined as follows : 14 A category C is controlled by another category C ~ in a constituent Co if one of the following situations obtains at a semantic level : either C is a functor that applies to C ~ to yield a Co , or else there is a control mediator C '' which combines with C and C ~ in that order to yield a Co. \ [ Gazdar et al. 1985 , page 87\ ] Further , a control mediator is a head category whose semantic type is ( VP , ( NP , VP ) ) where VP denotes the type of an intransitive verb phase and NP that of a generalised quantifier .</sentence>
				<definiendum id="0">semantic level</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">control mediator</definiendum>
				<definiendum id="3">NP , VP ) ) where VP</definiendum>
				<definiens id="0">14 A category C is controlled by another category C ~ in a constituent Co if one of the following situations obtains at a</definiens>
				<definiens id="1">a functor that applies to C ~ to yield a Co , or else there is a control mediator C '' which combines with C and C ~ in that order to yield a Co. \ [ Gazdar et al. 1985 , page 87\ ] Further , a</definiens>
			</definition>
</paper>

		<paper id="1042">
			<definition id="0">
				<sentence>Generalizing to stacks of unlimited size , the partition of a stack among the inheriting subconstituents K 1 and K 2 of a constituent K 0 is as in ( 3 ) ( 3 ) K0 It 1 , ... , tj , tj+l , ... , tk\ ] / \ Klltl , ... , tjl K2ltj+l , ... , tkl 358 If the generalization in ( 3 ) is tenable , the extension of context-free grmnmars ( Vijay-Shanker and Weir , 1991 , call the resulting formalism `` linear indexed granunar '' ( LIG ) ) discussed by Gazdar in ( Gazdar , 1988 ) , in which stacks are exclusively passed over to a single daughter ( as in ( 3.1 ) ) , is too weak .</sentence>
				<definiendum id="0">Vijay-Shanker</definiendum>
				<definiens id="0">tj , tj+l , ... , tk\ ] / \ Klltl , ... , tjl K2ltj+l , ... , tkl 358 If the generalization in ( 3 ) is tenable , the extension of context-free grmnmars</definiens>
			</definition>
			<definition id="1">
				<sentence>A DI-grammar is a 5-tupel G = ( N , T , F , P , S ) , where N , T , S are as usual , F is a alphabet of indices , P is a set of rules of the following form 1 ) ( a ) A -- &gt; o~ ( b ) A -- &gt; aBf~ ( c ) Af- &gt; o~ , ( A , BeN ; o~ , Be ( N~T ) * ; feF ) The relation `` = &gt; '' or `` directly derives '' is defined as follows : 2 ) o~ = &gt; 1 ) if either i ) = 5A/ndex ?</sentence>
				<definiendum id="0">DI-grammar</definiendum>
				<definiendum id="1">F</definiendum>
				<definiendum id="2">P</definiendum>
				<definiens id="0">a 5-tupel G = ( N , T , F , P , S ) , where N , T , S are as usual ,</definiens>
				<definiens id="1">a alphabet of indices</definiens>
				<definiens id="2">a set of rules of the following form 1 ) ( a ) A -- &gt; o~</definiens>
			</definition>
			<definition id="2">
				<sentence>, 8 , y e ( NF*uT ) * , indexeF* , AeN , A -- ) BIB2 ... B n is a rule of form 1 ) ( a ) 8 = 8BlindexlB2index2 ... BnindexnT or ii ) o~ = 8A/ndex y , 8 , T e ( NF*wT ) * , index eF* , AeN , A -- ) B 1 .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a rule of form 1 ) ( a ) 8 = 8BlindexlB2index2 ... BnindexnT or ii ) o~ = 8A/ndex y , 8 , T e ( NF*wT ) * , index eF* , AeN , A -- ) B 1</definiens>
			</definition>
			<definition id="3">
				<sentence>B n is a rule of form 1 ) ( b ) , fEF B = 5Blindexl ... Bkfindexk ... Bnindexn7 or iii ) ct = 8Afindex y ,8 , ?</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a rule of form 1 ) ( b )</definiens>
			</definition>
			<definition id="4">
				<sentence>e ( NF*vT ) * , index eF* , AeN , Af -- * B1B2 ... B n is a rule of form 1 ) ( c ) , feF B = 8BlindexlB2index2 ... Bnindexny ( * ) and index = indexlindex2 ... index n , and for B i e T : index i = ~ O.e. the empty word ) ( o~a ) The reflexive and transitive closure *= &gt; of = &gt; is defined as usual .</sentence>
				<definiendum id="0">e ( NF*vT ) *</definiendum>
				<definiendum id="1">B n</definiendum>
				<definiens id="0">a rule of form 1 ) ( c ) , feF B = 8BlindexlB2index2 ... Bnindexny ( * ) and index = indexlindex2 ... index n , and for B i e T : index i = ~ O.e. the empty word ) ( o~a ) The reflexive and transitive closure *= &gt; of = &gt;</definiens>
			</definition>
			<definition id="5">
				<sentence>But L2 is an indexed language , since it is generated by the indexed grammar G 2 = ( { S , A , D } , { a } , { f , g } , R 2 , S ) , where R 2 = { S -- ~Ag , A -- - &gt; Af , A -- - &gt; D , Df -- ~ DD , Dg -- ~ a } .</sentence>
				<definiendum id="0">L2</definiendum>
				<definiens id="0">an indexed language</definiens>
			</definition>
			<definition id="6">
				<sentence>L 3 is a DI-language , since it is generated by the DIgrammar G3 - ( { S , M , Z } , { a , b , \ [ , \ ] } , { f , g } , R3 , S ) where R3 = { S ~ aSfa , M ~ \ [ M\ ] , Zf ~ Za , Zg ~ Zb , S -- -~bSgb , M -- -~MM , Zf -- ~ a , Zg -- ~ b S -- - &gt; M , M -- ~ Z } e.g , abb\ [ b\ [ ab\ ] \ ] bba ( • L3 ) is derived as follows : S ~ aSfa ~ abSg/ba ~ abbSgg/bba ~ abbMgg/bba abb\ [ Mgg\ ] \ ] bba = abb\ [ MgMg/\ ] bba ( here the index `` ggf ' has been distributed ) ~ abb\ [ ZgMgl\ ] bba abb\ [ bMg/\ ] bba ~ abb\ [ b\ [ Mg/\ ] \ ] bba ~ abb\ [ b\ [ Zg/\ ] \ ] bba abblb\ [ Zfo\ ] \ ] bba ~ abblb\ [ ab\ ] \ ] bba .</sentence>
				<definiendum id="0">M</definiendum>
				<definiens id="0">a DI-language , since it is generated by the DIgrammar G3 - ( { S , M , Z } , { a , b , \ [ , \ ] }</definiens>
			</definition>
			<definition id="7">
				<sentence>Consequently , ft has to be deleted on every such path Pj , before the appropriate indices become accessible , i.e. we get for every j with 0 &lt; j &lt; n : ajE'jft '' \ ] = &gt; ujRjt j t , ,Jyj =* = &gt; yjqtfto\ ] , ( Bj , Rj , Cj eN , xj , o F* , ft Thus , for n &gt; lN\ [ in ( 8 ) ( INI the cardinality of the nonterminal alphabet N of G I , ignoring , as before the constant amount of parenthesis-storing in nonterminals ) because of \ [ { Cj ; 0 &lt; j &lt; n } l=n the node-label Cj\ [ fto \ ] occurs twice on two different paths branching off from Pt , i.e. there exist p , q ( 0_ &lt; p &lt; q &lt; n ) such that : Mnftcr = + = &gt; UpRp\ [ xpftO\ ] vqRq\ [ Xq fto\ ] y and = = &gt; ypC\ [ fto\ ] z p = + = &gt; ypZZp Rp\ [ xpfto \ ] * Rq\ [ zqftO \ ] = * = &gt; yqC\ [ fto\ ] _Zo = + = &gt; yqZZq , .</sentence>
				<definiendum id="0">INI</definiendum>
				<definiens id="0">the cardinality of the nonterminal alphabet N of G I , ignoring</definiens>
			</definition>
			<definition id="8">
				<sentence>Now , the GC-CCG given by f ( ~ ) = { # } f ( al ) = { SDU # , SDG # , # /X/ # , # /X~ # } f ( a ) = { A , XkA } fCol ) = { S/Y/ # , S/Y~ # , # /YI # , # /~ # } f ( b ) = { B , YxB } f ( D = { K } f ( \ ] ) = { # / # kK , ~ # ~Z } generates a language Lc , which when intersected with the regular set { a , b } + { \ [ , \ ] , a 1 , b 1 } + { a , b } + yields a language Lp which is for similar reasons as L 3 not even an indexed language .</sentence>
				<definiendum id="0">language Lp</definiendum>
				<definiens id="0">a language Lc , which when intersected with the regular set { a</definiens>
			</definition>
			<definition id="9">
				<sentence>N ( D ) or the language accepted by empty stack by D is defined as follows N ( D ) = { w ; weT* &amp; ( q , w # , l , $ ^Z0 # ) I'D* ( q , w # , lwl+l , $ ^ # ) To illustrate , the DI-automaton DI 3 accepting L 3 by empty stack is specified : DI 3 = ( q ( state for pda-mode ) , ( QF = ) { q~qM , qz , q $ } ( states for stack reading mode ) , ( '/'= ) { a , b , \ [ , \ ] } ( -- -input alphabet ) , ( G= ) { S , M , Z , a , b , \ [ , \ ] , } ( -- tape symbols for Ixtamode ) , ( l= ) { f , g } ( -- tape symbols representing indices ) , 5 , S , S , ¢ , # ) where for every x e T : 8 ( q , x , $ S ) = { ( q , O , SaSfa ) , ( q , O , $ bSgb ) , ( q , O , CM ) , ) , ( for the G3-ndes : S -- ~ aSfa , S ~bSgb , S ~ M ) 8 ( q , x , $ M ) = ( ( q , O , S\ [ MJ ) , ( q , O , SMM ) , ( q , O , SZ ) , } , 363 ( for : M-+\ [ M\ ] , M-+MM , M -- -~Z ) 8 ( q , x , $ x ) = { ( q,1 , $ ) } ( i.e. : if input symbol x = `` predicted '' terminal symbol x , then shift input-tape one step ( `` 1 '' ) and delete successful prediction '' ( replace Sx by $ ) ) 8 ( q , x , $ Z ) contains { ( qz , 0 , $ ) } , ( i.e. : change into stack reading mode in order to find indices belonging to the nonterminal Z ) 5 ( qz , x , $ Y ) = 5 ( qz , x , Y ) contain { ( qz , O,1 ) } ( for every x T , Y ~/ ) ( i.e.seek first index-symbol belonging to Z inside the stack ) 5 ( qz , x , $ J9 = { ( qz , o , $ $ Za¢ ) , ( qz , O , $ $ a¢ ) ) , 5 ( qz , x , Sg ) = { ( qz , O , SSZb¢ ) , ( qz , 0 , $ $ b¢ ) } , 5 ( qz , xJ ) = { ( q , x , $ Za¢ ) , ( q , x , SAC ) } , 5 ( qz , x , g ) = { ( q , x , SZb¢ ) , ( q , x , Sb¢ ) } , ( i.e. simulate the index-rules Zf~Za , Zf~a by creation of embedded stacks ) 5 ( q , x , S¢ ) = { ( q , O ) } , ( i.e. delete empty sub-stack ) 8 ( q , x , Y ) = { ( q , O , -1 ) } ( forx ~ T , Y ~ G-~g } ) ( i.e. move to top of ( sub- ) stack ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">q</definiendum>
				<definiens id="0">states for stack reading mode</definiens>
				<definiens id="1">-input alphabet ) , ( G= ) { S , M , Z , a , b , \ [ , \ ] , } ( -- tape symbols for Ixtamode ) , ( l= ) { f , g } ( -- tape symbols representing indices</definiens>
				<definiens id="2">if input symbol x = `` predicted '' terminal symbol x</definiens>
			</definition>
			<definition id="10">
				<sentence>The following theorem expresses the equivalence of DIgrammars and DI-automata ( 11 ) DI-THEOREM : L is a Dl-language ( i.e. L is generated by a Dl-grammar ) if and only if L is accepted by a Dl-automaton .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">Dl-language</definiendum>
				<definiens id="0">a</definiens>
			</definition>
			<definition id="11">
				<sentence>As the restriction on the form of the rules is reminiscent of the Chomsky normal form for contextfree grammars ( CFG ) , the grammars in the subclass will be called DI-Chomsky normal form ( DI-CNF ) grammars A DI-grammar G= ( N , T , F , P , S ) is a DI-CNF grammar ff and only ff each rule in P is of one of the following forms where A , B , C~N- { S } , feF , aeT , S -- , a , ff 6~ L ( G ) , ( a ) A -- , BC , ( b ) A-BfC , ( c ) A-+BCf , ( d ) Af -- ) BC , ( e ) Af -- , a , ( 0 A- &gt; a The question whether the class of languages generated by DI-CNF grammars is a proper or improper subclass of the DI-languages will be left open .</sentence>
				<definiendum id="0">CFG</definiendum>
				<definiendum id="1">DI-grammar G=</definiendum>
				<definiendum id="2">feF</definiendum>
				<definiens id="0">one of the following forms where A , B , C~N- { S } ,</definiens>
				<definiens id="1">a ) A -- , BC , ( b ) A-BfC , ( c ) A-+BCf , ( d ) Af -- ) BC , ( e ) Af -- , a , ( 0 A- &gt; a The question whether the class of languages generated by DI-CNF grammars is a proper or improper subclass of the DI-languages will be left open</definiens>
			</definition>
			<definition id="12">
				<sentence>p2 &lt; q2 &lt; _k , and if ql &lt; P2 , then X= , else X= ( C , f t , u , v ) for some CEN , fteF , u , v ( Pl &lt; UgVg ql ) then Zi , j : =Zi , jw { &lt; A , fl , ( B2 , f2 , P2 , q3 ) , ( A2 , fok+l , j ) &gt; } else if &lt; Bl , fl , - , - &gt; eLpl , ql Zij : =Zijw { &lt; A , fl , ( A~ , fc , k+ 1 , j ) , ( A 2 , fc , k + I d ) &gt; } &lt; Cl , f3 , - , - &gt; ¢Lsl , tl 366 then Zsl , tl : = Zsl , tlw { &lt; C l , f3 , ( A 2 , fc , k + l j ) , - &gt; } The pointer ( A2 , fc , k+lj ) in the new entry of Zij points to the cell of the node where the end of stack of the newly created node with noterminal A can be found .</sentence>
				<definiendum id="0">P2</definiendum>
				<definiendum id="1">&gt; eLpl , ql Zij</definiendum>
				<definiens id="0">A 2 , fc , k + l j )</definiens>
			</definition>
</paper>

		<paper id="1030">
			<definition id="0">
				<sentence>SDRT ( Asher 1993 ) takes the basic building blocks of discourse structure to be propositions with a dynamic content , which are represented as DaSs -- the representation scheme in Kamp 's ( 1981 ) DRT .</sentence>
				<definiendum id="0">SDRT ( Asher 1993 )</definiendum>
				<definiens id="0">takes the basic building blocks of discourse structure to be propositions with a dynamic content</definiens>
			</definition>
			<definition id="1">
				<sentence>In SDRT , an NL text is represented by an SDRS , which is a pair of sets containing respectively : the DgSs or SDgSS representing respectively sentences or text segments , and discourse relations between them .</sentence>
				<definiendum id="0">SDRS</definiendum>
			</definition>
			<definition id="2">
				<sentence>DICE provides the means to infer from the reader 's knowledge resources which discourse relation should be used to do attachment .</sentence>
				<definiendum id="0">DICE</definiendum>
			</definition>
			<definition id="3">
				<sentence>1 The Nixon Diamond provides the key to text incoherence ( Lascarides and Asher , 1991 ) .</sentence>
				<definiendum id="0">Nixon Diamond</definiendum>
			</definition>
			<definition id="4">
				<sentence>DICE represents temporal information in two places : first , in the DRS representing a sentence ; and second , in the discourse relations .</sentence>
				<definiendum id="0">DICE</definiendum>
				<definiens id="0">temporal information in two places : first , in the DRS representing a sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>tanation ( a./3 ) Now Background and the Greeting Law apply , and one infers Background ( a , /3 ) and Explanation ( a , /3 ) .2 So the consequent state of the greeting is in force when Max stands up , and the greeting explains why Max stood up .</sentence>
				<definiendum id="0">Explanation</definiendum>
				<definiens id="0">in force when Max stands up , and the greeting explains why Max stood up</definiens>
			</definition>
			<definition id="6">
				<sentence>The embedded DRS ff in the embedding tree for fl represents the subVRS that characterizes the event of working hard introduced by the pluperfect .</sentence>
				<definiendum id="0">subVRS</definiendum>
				<definiens id="0">characterizes the event of working hard introduced by the pluperfect</definiens>
			</definition>
			<definition id="7">
				<sentence>Plausible contrast is defined with respect to CE : A plausibly contrasts with B if the KB entails A &gt; - , B or B &gt; - , A. In our example ( 14 ) above , the theme of a that is maximal with respect to supporting Contrast under the mapping of nodes suggested below is lazy ( el , j ) while the corresponding theme of ff is work-hard ( e2 , j ) .</sentence>
				<definiendum id="0">work-hard</definiendum>
				<definiens id="0">A plausibly contrasts with B if the KB entails A &gt; - , B or B &gt; -</definiens>
			</definition>
			<definition id="8">
				<sentence>First we consider the lexical information in a. Pustejovsky 's ( 1991 ) representation of lexical entries for artifacts 255 e , t , z , p , so , tO hold ( e , t ) t - &lt; now ring ( telephone , e ) say ( z , p , so ) hold ( so , to ) ~J , Elaboration pC_ W , S , t t husband ( w , d ) `` : \ [ ='- '' I \ [ eat-too-many-oysters ( w , e ) hold ( s , t ' ) t t ~ now t ' -4 to Figure 1 : The SDRS representing Text ( 6 ) includes a representation of their telic roles , which intuitively define the purpose of the artifact .</sentence>
				<definiendum id="0">p</definiendum>
			</definition>
			<definition id="9">
				<sentence>This motivates Caenepeel 's Axiom below : it states that a pluperfect sentence 7 by default identifies the proposition p in the propositional attitude ~b invoked by a : • Caenepeel 's Axiom : ( r , a , 7 ) A PP ( 7 ) A ~ ( a , p ) &gt; 7 identifies p Now consider the reasoning behind attaching 7 to the preceding open constituent a. The rules that apply are Narration , States Overlap , COT and Caenepeel 's Axiom .</sentence>
				<definiendum id="0">PP</definiendum>
			</definition>
			<definition id="10">
				<sentence>Nothing in the reader 's KB conflicts with the consequent of Caenepeel 's Axiom , and so its consequent is inferred ; i.e. , 7 identifies p. CCT conflicts with Narration , and so Upp ( a , 7 ) is inferred by the Penguin Principle .</sentence>
				<definiendum id="0">so Upp</definiendum>
				<definiens id="0">identifies p. CCT conflicts with Narration , and</definiens>
			</definition>
			<definition id="11">
				<sentence>Elaboration ( a,8 ) entails a # 8 by Elaboration 's semantics in SDRT .</sentence>
				<definiendum id="0">Elaboration ( a,8 )</definiendum>
				<definiens id="0">entails a # 8 by Elaboration 's semantics in SDRT</definiens>
			</definition>
			<definition id="12">
				<sentence>Narration imposes precedence relations between the consequent states , and so the textual order of the events matches their temporal order .</sentence>
				<definiendum id="0">Narration</definiendum>
				<definiens id="0">imposes precedence relations between the consequent states , and so the textual order of the events matches their temporal order</definiens>
			</definition>
			<definition id="13">
				<sentence>Thus DICE provides the means to solve the Interaction Problem .</sentence>
				<definiendum id="0">DICE</definiendum>
			</definition>
</paper>

		<paper id="1034">
			<definition id="0">
				<sentence>A 'tuple ' operation introduced in \ [ Solias , 1992\ ] is defined as a mode of prosodic combination which has associated projection functions , and consequently can support a property of unique prosodic decomposability .</sentence>
				<definiendum id="0">'tuple ' operation</definiendum>
				<definiens id="0">a mode of prosodic combination which has associated projection functions , and consequently can support a property of unique prosodic decomposability</definiens>
			</definition>
			<definition id="1">
				<sentence>The category formulas are freely generated from atomic category formulas ( e.g. N for referring nominals , S for sentences , CN for common nouns , ... ) by binary operators \ ( 'under ' ) , / ( 'over ' ) and • ( 'product ' ) .</sentence>
				<definiendum id="0">CN</definiendum>
				<definiens id="0">common nouns , ... ) by binary operators \ ( 'under '</definiens>
			</definition>
			<definition id="2">
				<sentence>The interpretation is in semigroups , i.e. algebras ( L , + ) where + is a binary operation satisfying the associativity axiom sl + ( s~ + s3 ) = ( sl + s2 ) + s3 .</sentence>
				<definiendum id="0">interpretation</definiendum>
				<definiendum id="1">i.e. algebras</definiendum>
				<definiendum id="2">+</definiendum>
				<definiens id="0">a binary operation satisfying the associativity axiom sl + ( s~ + s3 ) = ( sl + s2 ) + s3</definiens>
			</definition>
			<definition id="3">
				<sentence>Each category formula A is interpreted as a subset D ( A ) of L. Given such a mapping for atomic category formulas it is extended to the compound category formulas thus : D ( A\B ) = { sirs ' ~ D ( A ) , s ' + s E D ( B ) } ( 1 ) D ( B/A ) - { slVd E D ( A ) , s + s ' E D ( B ) } D ( A*B ) = { sl + s213Sl e D ( A ) , s2 e D ( B ) } In general we may define L in terms of a semigroup algebra ( L* , + , t ) where f E L is an identity element , i.e. an element such that s + t = t + s -s ; then L is L* { t } .</sentence>
				<definiendum id="0">f E L</definiendum>
				<definiens id="0">s ' + s E D ( B ) } ( 1 ) D ( B/A ) - { slVd E D ( A ) , s + s ' E D ( B ) } D</definiens>
				<definiens id="1">an identity element</definiens>
			</definition>
			<definition id="4">
				<sentence>The notation P ( A ) represents an antecedent containing a subpart A. a. ~ .</sentence>
				<definiendum id="0">notation P ( A )</definiendum>
				<definiens id="0">an antecedent containing a subpart A. a. ~</definiens>
			</definition>
			<definition id="5">
				<sentence>A sequent has the form zi : A1 , ... , xn : An : :~ ¢ : A where n &gt; 0 , no semantic variable is associated with more than one category formula , and ¢ is a typed lambda term over ( free ) variables { xl , ... , x , } .</sentence>
				<definiendum id="0">¢</definiendum>
				<definiens id="0">A where n &gt; 0 , no semantic variable is associated with more than one category formula , and</definiens>
				<definiens id="1">a typed lambda term over ( free ) variables { xl , ... , x , }</definiens>
			</definition>
			<definition id="6">
				<sentence>nB , A : :~ 7 ( c ) : C F =V a : A A : :V B : B an R r , A : , .</sentence>
				<definiendum id="0">nB</definiendum>
				<definiens id="0">c ) : C F =V a : A A : :V B : B an R r</definiens>
			</definition>
			<definition id="7">
				<sentence>The prosodic interpretation for the discontinuity operators is to be as follows : D ( BTA ) = { s\ [ Vs ' e D ( A ) , ls + s ' + 2s e D ( B ) } ( 15 ) D ( BIA ) = { siVa ' e D ( A ) , ls ' + s + 28 ' G D ( B ) } D ( A ® B ) = { 181 + 82 + 282\ [ 81 • D ( A ) ,82 • D ( B ) } It can be seen that the operators are the residuation divisions with respect to a binary prosodic operation I defined by szIs2 = 181 + s2 + 281 just as the Lambek operators are the residuation divisions with respect to + .</sentence>
				<definiendum id="0">prosodic interpretation for the discontinuity operators</definiendum>
				<definiens id="0">to be as follows : D ( BTA ) = { s\ [ Vs ' e D ( A ) , ls + s ' + 2s e D ( B ) } ( 15 ) D ( BIA ) = { siVa ' e D ( A ) , ls ' + s + 28 ' G D ( B ) } D ( A ® B ) = { 181 + 82 + 282\ [ 81 • D</definiens>
			</definition>
			<definition id="8">
				<sentence>Quantifying-in allows a quantifier phrase to apply as a semantic functor to its sentential context .</sentence>
				<definiendum id="0">Quantifying-in</definiendum>
				<definiens id="0">allows a quantifier phrase to apply as a semantic functor to its sentential context</definiens>
			</definition>
			<definition id="9">
				<sentence>This constituent is essentially TV\S but with a feature 293 a-a : N =~a-a : N c-c : PP =~c-c : PP /L f-f : PP/N , a-a : N ~f+a- ( fa ) : PP f-f : PP/N , a-a : N =~f+a+t- ( fa ) : PPTrt f-f : PP/N =~ ( f , t ) -~a ( fa ) : PPTN j-j : N =~j-j : N k-k : S =~k-k : S \L h-h : PP =~h-h : PP j-j : N , i-i : N\S =~j+i- ( ij ) : S j-j : N , w-w : ( N\S ) /PP , h-h : PP =~j+w+h- ( ( wh ) j ) : S/L j-j : N , w-w : ( N\S ) /PP , h-h : PP =~j+w+h+t- ( ( wh ) j ) : STR j-j : N , w-w : ( N\S ) /PP =¢ , ( j+w , t ) - ) , h ( ( wh ) j ) : STPP g-g : R =~g-g : R/L d-d : R/ ( STPP ) , j-j : N , w-w : ( N\S ) /PP =~d+ ( j+w , t ) - ( d ) , h ( ( wh ) j ) ) : R IL f-f : PP/N , o-o : ( R/ ( SI '' PP ) ) I ( PPTN ) , j-j : N , w-w : ( N\S ) /PP =~f+o+t+ ( j+w , t ) - ( ( o~a ( fa ) ) ~h ( ( wh ) j ) ) : R m f-f : PP/N , o-o : ( R/ ( STPP ) ) I ( PPTN ) , j-j : N , w-w : ( N\S ) /PP =~f+o+ ( j+w , t ) - ( ( o ) , a ( fa ) ) ) ~h ( ( wh ) j ) ) : R Figure 4 : Derivation for 'for whom John works ' both blocking ordinary application , and licensing coordination with a left hand conjunct of the same category .</sentence>
				<definiendum id="0">PP/N =~</definiendum>
				<definiendum id="1">N\S =~j+i-</definiendum>
				<definiendum id="2">PP =~j+w+h-</definiendum>
				<definiens id="0">S/L j-j : N , w-w : ( N\S ) /PP , h-h : PP =~j+w+h+t- ( ( wh ) j ) : STR j-j : N , w-w : ( N\S ) /PP =¢ , ( j+w , t ) - ) , h ( ( wh ) j ) : STPP g-g : R =~g-g</definiens>
			</definition>
			<definition id="10">
				<sentence>In this scheme , X is the category of the resulting coordinate structure and Y is the category of the gapped materiM .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">the category of the gapped materiM</definiens>
			</definition>
			<definition id="11">
				<sentence>R s-s : TV= } s-s : TV j-j : N , I-hN=~ ( j , I ) -As ( ( sl ) j ) : SI '' TV ®R j-j : N= } -j-j : N n-n : S=~n-n : S I-hN=M-I : N j-j : N , g-g : N\S =~j+g- ( gj ) : S.fL L j-j : N , H : TV , l-hN= &gt; j+s+l- ( As ( ( sl ) j ) , s ) : ( S } TV ) ®TV f-f : S=~f-f : S '\L j-j : N , s-s : TV , l-h N , e-e : ( ( STTV ) ®TV ) \S=~j+s+l+e- ( e ( As ( ( sl ) j ) , s ) ) : S j-j : N , s-s : TV , l-h N , e-e : ( ( STTV ) ( DTV ) \S= &gt; j+s+I+e- ( e ( As ( ( sl ) j ) , s ) ) : S p -- p : N= : &gt; p-p : N c-c : N=~c- .</sentence>
				<definiendum id="0">TV j-j</definiendum>
				<definiendum id="1">H</definiendum>
				<definiens id="0">sl ) j ) , s ) ) : S j-j</definiens>
			</definition>
			<definition id="12">
				<sentence>c : N n-n : S=~n-n : S \L c-c : N , y-y : N\S=~c+y- ( yc ) : S /L c-c : N , p-p : N , w-w : TV=~c+w+p- ( ( wp ) c ) : S TR c-c : N , p-p : N= &gt; ( c , p ) -Aw ( ( wp ) c ) : STTV '/L j-j : N , s-s : TV , l-hN , a-a : ( ( Sq ) TV ) \S ) / ( STTV ) , c-c : N , p-p : N=~j+s+l+a+ ( c , p ) - ( ( aAw ( ( wp ) c ) ) ( As ( ( sl ) j ) , s ) ) : S Figure 5 : Derivation for 'John studies logic ; and Charles , phonetics ' categorial grammar by a proper treatment of discon• tinuity .</sentence>
				<definiendum id="0">TV=~c+w+p- (</definiendum>
				<definiendum id="1">N= &gt;</definiendum>
				<definiendum id="2">p ) -Aw ( ( wp ) c )</definiendum>
				<definiens id="0">N=~j+s+l+a+ ( c , p ) - ( ( aAw ( ( wp ) c ) ) ( As ( ( sl ) j ) , s ) ) : S Figure 5 : Derivation for 'John studies logic ; and Charles , phonetics ' categorial grammar by a proper treatment of discon• tinuity</definiens>
			</definition>
</paper>

		<paper id="1044">
			<definition id="0">
				<sentence>378 A signature E is a collection of function symbols , each of which has a fixed arity .</sentence>
				<definiendum id="0">signature E</definiendum>
				<definiens id="0">a collection of function symbols</definiens>
			</definition>
			<definition id="1">
				<sentence>The term algebra T ( E , 1 ) ) is defined as the inductive closure of l ; under ~ .</sentence>
				<definiendum id="0">term algebra T</definiendum>
				<definiens id="0">the inductive closure of l ; under ~</definiens>
			</definition>
			<definition id="2">
				<sentence>An equational specification is a pair ( ~ , ,~ ) where ~ is a signature and E is a set of equations s = t of terms s , t E T ( ~,12 ) .</sentence>
				<definiendum id="0">equational specification</definiendum>
				<definiendum id="1">~</definiendum>
				<definiendum id="2">E</definiendum>
				<definiens id="0">a signature</definiens>
			</definition>
			<definition id="3">
				<sentence>A E-algebra .4 is a model for a set of equations E over T ( ~ , N ) , written as .4 ~ £ , if every equation of ~ holds in A. A ( E , g ) -algebra is a ~-algebra that is a model for £ .</sentence>
				<definiendum id="0">E-algebra .4</definiendum>
				<definiens id="0">a model for a set of equations E over T ( ~</definiens>
			</definition>
			<definition id="4">
				<sentence>The equational specification Ev~ is defined as follows ( where V ( F = G ) denotes the set of variables occurring in F = G ) : ( F=G ) lx*'-Vkz\ ] mD FI~*-vkxl=G\ [ x* '' Vkx\ ] ( F=G ) v/ , =O UzCV ( F=o ) ( F=G ) \ [ z*-Vk*\ ] £vk -- D UEE~r Ev~ To give a concrete example of these definitions , let E consist of the following two equations : x+y = y+x x+ ( y+z ) = ( x+y ) +z Then ~ contains these two : Ajz+Ajy = Ajy + Ajx A~x+ ( A~y+Aiz ) = ( Ajx+A~y ) +A~z whereas gw is comprised of five equations in all : Vkz+Y = y+~7kz z+Wky = VkY+X w~+ ( y+z ) = ( wx+y ) +z x+ ( Vky+z ) = ( x+Wy ) +z x+ ( y+Vkz ) = ( x+y ) +Vkz We will call a term equation resource-preserving if each variable occurs the same number of times on both sides of the equality sign .</sentence>
				<definiendum id="0">equational specification Ev~</definiendum>
			</definition>
			<definition id="5">
				<sentence>Its carrier is the set S/ -- , where = is the equivalence relation defined by r _-A iff VA : r F A ¢~ A F A. The -- -- equivalence class containing F will be denoted as \ [ r\ ] .</sentence>
				<definiendum id="0">equivalence class</definiendum>
				<definiens id="0">the set S/ -- , where = is the equivalence relation defined by r _-A iff VA : r F A ¢~ A F A. The -- --</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>Anne owns a lot of parrots .</sentence>
				<definiendum id="0">Anne</definiendum>
				<definiens id="0">owns a lot of parrots</definiens>
			</definition>
			<definition id="1">
				<sentence>The NPs in the a ) -examples should be interpreted as 'the one and only set X such that all members x E X -- ~ Pred ( X ) ' , rather than 'there is a set X etc ' .</sentence>
				<definiendum id="0">Pred</definiendum>
				<definiens id="0">'the one and only set X such that all members x E X -- ~</definiens>
			</definition>
			<definition id="2">
				<sentence>( 25 ) The embedding function f uniquely verifies the DRS K in M iff : f verifies the conditions in M and Vh \ [ Vx • rm ( K ) =¢ , h ( x ) C f ( x ) \ ] Note that uniqueness is a property of closed off discourses ( or discourse units ) .</sentence>
				<definiendum id="0">C f</definiendum>
				<definiens id="0">the DRS K in M iff : f verifies the conditions in M and Vh \ [ Vx • rm ( K ) =¢ , h ( x )</definiens>
				<definiens id="1">a property of closed off discourses ( or discourse units )</definiens>
			</definition>
</paper>

		<paper id="1046">
			<definition id="0">
				<sentence>CG parsing consists of the following sequential modules : • Preprocessing and morphological analysis • Disambiguation of morphological ( e.g. part-ofspeech ) ambiguities • Mapping of syntactic functions onto morphological categories • Disambiguation of syntactic functions Here we shall be concerned only with disambiguation of morphological ambiguities this module , along with the TWOL-style morphological description ENGTWOL , is the most mature part of the ENGCG system .</sentence>
				<definiendum id="0">CG parsing</definiendum>
			</definition>
			<definition id="1">
				<sentence>Therefore the FS rules need not concern themselves with more than one unambiguous , though potentially unacceptable , sentence reading at a time , and this improves parsing accuracy .</sentence>
				<definiendum id="0">FS</definiendum>
				<definiens id="0">rules need not concern themselves with more than one unambiguous , though potentially unacceptable , sentence reading at a time</definiens>
			</definition>
			<definition id="2">
				<sentence>hnplication rules express distributions in a straightforward , positive fashion , and usually they are very compact : several dozens of CG rules that express bits and pieces of the same grammatical phenomenon can usually be expressed with one or two transparent finite-state rules .</sentence>
				<definiendum id="0">hnplication rules</definiendum>
				<definiens id="0">several dozens of CG rules that express bits and pieces of the same grammatical phenomenon can usually be expressed with one or two transparent finite-state rules</definiens>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>~ , In ( 1 ' ) every pair of parentheses encompasses a dependent item ( i.e. corresponds to an edge of the linearized dependency tree ) , the indices of parentheses denote kinds of dependency ( valency slots , or theta roles and adjuncts ) : Act stands for Actor ( underlying Subject ) , Appurt for Appurtenance ( Possessivity in a broader sense ) , Obj for Objective ( underlying ~Object ) , Loc for Locative , Gener for the General Relationship ( of an adjunct to its head ) ; the other indices denote values of morphological categories ( Perfect , Indefiniteness ) and of adverbial prepositions ( in , on ) , Rel denotes a relative pronoun ( here 178 deleted on the surface ) .</sentence>
				<definiendum id="0">Rel</definiendum>
				<definiens id="0">an edge of the linearized dependency tree ) , the indices of parentheses denote kinds of dependency ( valency slots , or theta roles and adjuncts</definiens>
				<definiens id="1">a relative pronoun ( here 178 deleted on the surface )</definiens>
			</definition>
			<definition id="1">
				<sentence>A general procedure for determining the topic-focus articulation in such languages can then be formulated as follows : ( i ) All complementations ( participants and adverbials , or arguments and adjuncts ) preceding the verb are contextually bound .</sentence>
				<definiendum id="0">complementations</definiendum>
				<definiens id="0">participants and adverbials , or arguments and adjuncts ) preceding the verb are contextually bound</definiens>
			</definition>
</paper>

		<paper id="1067">
			<definition id="0">
				<sentence>The possible roots and the suffixes following them are temporarily stored , and H01y0ft0 performs the morphological synthesis on the basis of the new ( synonym ) root and the internal code of the stored suffix sequence .</sentence>
				<definiendum id="0">H01y0ft0</definiendum>
				<definiens id="0">performs the morphological synthesis on the basis of the new ( synonym ) root and the internal code of the stored suffix sequence</definiens>
			</definition>
			<definition id="1">
				<sentence>Both the thesaurus and the morphologicaVgenerator ( as a stand-alone tool ) are fully implemented for Hungarian .</sentence>
				<definiendum id="0">morphologicaVgenerator</definiendum>
				<definiens id="0">a stand-alone tool</definiens>
			</definition>
			<definition id="2">
				<sentence>The synonym system consists of 40.000 headwords , the stem dictionary of the morphological analyzer/generator contains 80.000 stems , suffix dictionaries contain all the inflectional suffixes and the productive derivational morphemes of present-day Hungarian .</sentence>
				<definiendum id="0">synonym system</definiendum>
				<definiens id="0">consists of 40.000 headwords , the stem dictionary of the morphological analyzer/generator contains 80.000 stems , suffix dictionaries contain all the inflectional suffixes and the productive derivational morphemes of present-day Hungarian</definiens>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>The implementation consists of a syntax module which outputs parse trees , a semantic module mapping parse trees to DPL representations , a representation processor which determines truth conditions , falsity conditions and presupposition failure conditions , and an evaluator of these conditions in a database model .</sentence>
				<definiendum id="0">implementation</definiendum>
				<definiens id="0">consists of a syntax module which outputs parse trees , a semantic module mapping parse trees to DPL representations , a representation processor which determines truth conditions , falsity conditions and presupposition failure conditions , and an evaluator of these conditions in a database model</definiens>
			</definition>
			<definition id="1">
				<sentence>A4 = ( M , II , where M is the domain and I the interpretation function for a set of constants and relation symbols be Kiven .</sentence>
				<definiendum id="0">M</definiendum>
			</definition>
			<definition id="2">
				<sentence>( ( rlz : Wa~ ; Mz ) =~ ( ty : Hyz ; Lyx ) ) T 4-~ \ [ ~x : Wx ; Mx\ ] ( ~y : ttyx ; Lyx ) T ~-+ \ [ rlx : Wx\ ] \ [ Mz\ ] ( *y : I'lyz ) ( Ly~ ) T ~-* Vx\ [ Wx\ ] \ [ Mx\ ] ( Ly : Hyx } ( Lyx ) T Vx ( Wx ~ ( Mx -~ ( : JIy ( I-Iy~c ) -tA By ( I-Iyx ) ( Lyx ) T ) ) ) , - , Vx ( W2 : .</sentence>
				<definiendum id="0">I'lyz )</definiendum>
				<definiens id="0">] ( Ly : Hyx } ( Lyx ) T Vx ( Wx ~ ( Mx -~ ( : JIy ( I-Iy~c ) -tA By ( I-Iyx ) ( Lyx ) T ) )</definiens>
			</definition>
			<definition id="3">
				<sentence>Like Lambda Prolog \ [ 7\ ] , GSdel is a typed language : it is necessary to declare the type and domain of all functions and predicates ( polymorphism is allowed , however ) .</sentence>
				<definiendum id="0">GSdel</definiendum>
				<definiens id="0">a typed language : it is necessary to declare the type and domain of all functions and predicates</definiens>
			</definition>
			<definition id="4">
				<sentence>The main module takes a sentence or text as input and produces a report containing the sentence , the parse tree , the DPL program it gets translated into , and the preconditions .</sentence>
				<definiendum id="0">main module</definiendum>
				<definiens id="0">takes a sentence or text as input and produces a report containing the sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>GSdel ( as all logic programming languages ) has these features built in , which makes it very easy to implement a parser for a simple fragment like ours .</sentence>
				<definiendum id="0">GSdel</definiendum>
				<definiens id="0">makes it very easy to implement a parser for a simple fragment like ours</definiens>
			</definition>
			<definition id="6">
				<sentence>The parsing of a sentence consists of three steps : * generate a list of categories corresponding to the sequence of words , • reduce the list of categories , • test if you have a sentence else retrace your steps and try again .</sentence>
				<definiendum id="0">parsing of a sentence</definiendum>
				<definiens id="0">consists of three steps : * generate a list of categories corresponding to the sequence of words , • reduce the list of categories</definiens>
			</definition>
			<definition id="7">
				<sentence>• Fpreeexist ( pi , phi ) is the expression ( ( ~r ) ta ) • Fprecuniv ( pi , phi ) is the expression ( \ [ ~r\ ] ia ) • Fpar ( pi , phi ) is the expression ( -~ ( Tr ) taA-~\ [ Tr\ ] ~ ) .</sentence>
				<definiendum id="0">phi )</definiendum>
				<definiens id="0">the expression ( \ [ ~r\ ] ia</definiens>
			</definition>
			<definition id="8">
				<sentence>( 28 ) Jan is a bachelor .</sentence>
				<definiendum id="0">Jan</definiendum>
				<definiens id="0">a bachelor</definiens>
			</definition>
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>Part-of is a relation 6 which holds between situations .</sentence>
				<definiendum id="0">Part-of</definiendum>
				<definiens id="0">a relation 6 which holds between situations</definiens>
			</definition>
			<definition id="1">
				<sentence>For example : Sin our formal treatment we will in fact treat &lt; ! as a type , but this is a technical detail. We will continue to refer to the ' &lt; 1 relation ' rather than the ' &lt; 1 type ' , as the former conveys a clearer meaning. 7Actually there are eases where a progressive does not convey backgrounding , but we will not discuss them here. They involve 'at the same time ' and are discussed in ~Glasbey , ms1 ) . °See ( Glasbey , ms1 , Glasbey , ms2 ) for details. 159 ( la ) Emily climbed Ben Nevis in July. ( If ) Fiona was climbing Snowdon then. ( la , lf ) can either mean that Fiona 's climb took place in July , or that it temporally included Emily 's climb. World knowledge or context may sometimes favour one reading or the other. This analysis of sentence-final 'then ' has important consequences for theories of temporal reference. It shows that , whatever theoretical framework is employed , it is necessary to distinguish in some way between temporal discourse referents which are introduced into the discourse via explicit mention of a time , and those which are introduced via the inference of a time from the mention of an event or state. We explMn below a means of making this distinction in an ST/DlZT framework , and describe a computational implementation which embodies the distinction , s The fragment contains sequences of sentences of a type similar to the ones given in Section 1. It includes sentence-final 'then ' , together with other temporal adverbials such as for-adverbials , frame adverbials ( e.g , 'in July ' ) and completive/n-adverbials ( e.g. , 'in two hours ' ) . Sentence-initial 'then ' and sentencefinal 'at the time ' and 'at the same time ' are also included , although we do not discuss their analysis here. There is a range of verbs , transitive and intransitive , with various aspectual characteristics , and a range of noun types including count nouns , mass nouns , bare plurals , definite and indefinite NPs. Progressives are also included. We are thus concerned not merely with the analysis of 'then ' but with matters of aspectual composition/modification and the distribution of temporal adverbials. Space does not permit us to describe the full system in detail. We will concentrate here on those parts of it that are particularly relevant to the analysis of 'then'. As the system is concerned with temporal matters , we have not built into it a treatment of pronominal anaphora. However , it is designed in such a way , as will shortly become clear , that it could be extended without undue difficulty to include pronoun anaphora , using a treatment based on that in ( Johnson and Klein , 1986 ) . The system parses sequences of sentences and produces representations for the required readings for SWe discuss in ( Glasbey , msl ) how 'at the time ' behaves similarly to the part-of use of 'then ' ( but conveys only backgrounding and not elaboration ) , while 'at the same time ' appears to be acceptable in cases where the second eventuality is not a part of the first , i.e. , where it can be seen as forming a distinct or separate event. These are also included in the implemented grammar , but their treatment is not described here. sentence-final 'then'. It is based on a situationtheoretic grammar developed in ( Cooper , 1991 ) and its computational implementation ProSit ( Cooper , msl ) . ProSit is a definite clause grammar ( DCG ) with features. It parses single sentences and constructs syntactic and semantic representations expressed in situation-theoretic terms. We have extended it firstly to deal with sentences containing a range of tense and aspect constructions which were not present in Cooper 's original fragment , and secondly to allow the processing of discourse. To enable us to do the former , we have built aspectual composition into the grammar using a theoretical approach based upon ( Krifka , 1991 ) and described below. In order to process discourse , we have employed the technique known as 'threading ' , used by Johnson and Klein ( 1986 ) , whereby discourse referents are carried from left to right among the constituents of a sentence , and from one sentence to the next. Extended Kamp Notation The grammar is expressed in a combined DRT/situation theoretic formalism , employing the Extended Kamp Notation ( EKN ) developed in ( Barwise and Cooper , forthcoming ) . These authors use a box notation for situation-theoretic objects such as infons , situations and propositions , based upon the graphical notation of DRT ( Kamp and Reyle , forthcoming ) . However , in EKN the boxes directly represent semantic objects , in contrast to DRT where the discourse representation structures ( DRSs ) are expressions of a language which require interpretation in a model. Nevertheless , EKN boxes look rather like DRSs. One important difference , however , is that EKN boxes may contain situations. In situation theory , infons ( which can be thought of as items of information or `` possible facts '' ) are supported by situations , which are parts of the world as individuated by agents. An infon consists of a relation 1° with its argument roles filled by objects which may be individuals , parameters or other situation-theoretic objects. Propositions in EKN include objects of the form : sl climb ( X , Y ) which is the proposition that a situation S supports an infon climb ( X , Y ) . 11 Situation-theoretic objects may have restrictions imposed on them. A proposition with restrictions is shown in Figure 1. The box in Figure 1 denotes an object only if the restrictions are true , i.e. , in the above case , if X is 1°Relations are primitives in situation theory. llS , X and Y are parameters , denoted by capital letters in situation theory. A parameter is a partially-specified object. 160 s -- \ ] climb ( X , Y ) RI named ( X , 'Emily ' ) named ( Y , 'Ben Nevis ' ) Figure 1 : An EKN restricted proposition. rl - , ~ S , r~ -- + X , r3 -- + Y , r4 -+ R sl climb ( X , Y ) al named ( X , 'Emily ' ) named ( Y , 'Ben Nevis ' ) Figure 2 : An EKN proposition abstract or 'type'. anchored to an individual named 'Emily ' and Y to an individual named 'Ben Nevis'. R is the resource situation supporting information about the naming of individuals ) 2 A proposition containing parameters is known as a parametric proposition. It is possible to abstract ( simultaneously ) over one or more parameters of a parametric proposition to give a type of the form shown in Figure 2. Once a parameter has been abstracted over , it effectively `` disappears '' and is no longer present in the type. What remains is the `` role '' corresponding to the abstracted parameter. These roles may be indexed however we choose ( for example , by the natural numbers , by rl to r , as above , or by utterance situations as in ( Cooper , 1991 ) ) . Cooper ( ms2 ) , in the development of situationtheoretic DRT ( STDRT ) , sees a DRS as equivalent to the situation-theoretic type obtained by abstracting over the parameters of a proposition. The roles of such a type are equivalent to DRT discourse referents , and the infons correspond to the conditions of the `` main '' situationJ 3 Processing of Sentences The system parses both individual sentences and sequences of sentences forming a discourse. For a sentence such as : ( lc ) Emily climbed Ben Nevis. it produces a syntactic parse tree , together with a semantic representation in the form of a DRS/type as shown in Figure 3. The DRS/type is shown in slightly simplified form here. It will also contain in12See ( Cooper , forthcoming ) for further explanation. lsOf course there are no precise DRT equivalents of the situation and the restrictions. r , -- &gt; S , r2 -- ~X , rz -+ Y , r4 -+R , rs -+T sl climb ( X , Y ) RI I i named ( X , 'Emily ' ) named ( Y , 'Ben Nevis ' ) Sl occ-time ( S , T ) , \ ] i Figure 3 : DRS/type for ( lc ) .</sentence>
				<definiendum id="0">ProSit</definiendum>
				<definiens id="0">Sin our formal treatment we will in fact treat &lt; ! as a type , but this is a technical detail. We will continue to refer to the ' &lt; 1 relation ' rather than the ' &lt; 1 type ' , as the former conveys a clearer meaning. 7Actually there are eases where a progressive does not convey backgrounding , but we will not discuss them here. They involve 'at the same time ' and are discussed in ~Glasbey , ms1 ) . °See ( Glasbey , ms1 , Glasbey , ms2 ) for details. 159 ( la ) Emily climbed Ben Nevis in July. ( If ) Fiona was climbing Snowdon then. ( la , lf ) can either mean that Fiona 's climb took place in July , or that it temporally included Emily 's climb. World knowledge or context may sometimes favour one reading or the other. This analysis of sentence-final 'then ' has important consequences for theories of temporal reference. It shows that , whatever theoretical framework is employed , it is necessary to distinguish in some way between temporal discourse referents which are introduced into the discourse via explicit mention of a time , and those which are introduced via the inference of a time from the mention of an event or state. We explMn below a means of making this distinction in an ST/DlZT framework , and describe a computational implementation which embodies the distinction , s The fragment contains sequences of sentences of a type similar to the ones given in Section 1. It includes sentence-final 'then ' , together with other temporal adverbials such as for-adverbials , frame adverbials ( e.g , 'in July ' ) and completive/n-adverbials ( e.g. , 'in two hours ' ) . Sentence-initial 'then ' and sentencefinal 'at the time ' and 'at the same time ' are also included , although we do not discuss their analysis here. There is a range of verbs , transitive and intransitive , with various aspectual characteristics , and a range of noun types including count nouns , mass nouns , bare plurals , definite and indefinite NPs. Progressives are also included. We are thus concerned not merely with the analysis of 'then ' but with matters of aspectual composition/modification and the distribution of temporal adverbials. Space does not permit us to describe the full system in detail. We will concentrate here on those parts of it that are particularly relevant to the analysis of 'then'. As the system is concerned with temporal matters , we have not built into it a treatment of pronominal anaphora. However , it is designed in such a way , as will shortly become clear , that it could be extended without undue difficulty to include pronoun anaphora , using a treatment based on that in ( Johnson and Klein , 1986 ) . The system parses sequences of sentences and produces representations for the required readings for SWe discuss in ( Glasbey , msl ) how 'at the time ' behaves similarly to the part-of use of 'then ' ( but conveys only backgrounding and not elaboration ) , while 'at the same time ' appears to be acceptable in cases where the second eventuality is not a part of the first , i.e. , where it can be seen as forming a distinct or separate event. These are also included in the implemented grammar , but their treatment is not described here. sentence-final 'then'. It is based on a situationtheoretic grammar developed in ( Cooper , 1991 ) and its computational implementation ProSit ( Cooper , msl ) .</definiens>
			</definition>
			<definition id="2">
				<sentence>Alternatively , we may characterise it in Krifka 's terms as having the property +Q ( quantized ) or -CUM ( non-cumulative ) , which are equivalent to the lack of a natural endpoint or culmination .</sentence>
				<definiendum id="0">property +Q</definiendum>
				<definiendum id="1">non-cumulative )</definiendum>
				<definiens id="0">equivalent to the lack of a natural endpoint or culmination</definiens>
			</definition>
</paper>

		<paper id="1059">
			<definition id="0">
				<sentence>Introduction \ [ Trans ( ( Pref * DELAS ) c~ SaC ) c~ Rules\ ] u \ [ rans ( Pref • DELAFA ) ~ Rules ) o ( Id ( Pref• DELAF ) \ ] 2 This operation leads to the transducer of 1.3Mb with a look-up procedure of 1,100 words per second , a sample of which is given in the following figure : We fhst built the transducer representing all the entries of DELAF along with their inflectionnal code .</sentence>
				<definiendum id="0">Introduction \ [ Trans ( ( Pref * DELAS</definiendum>
				<definiendum id="1">Id</definiendum>
				<definiens id="0">the transducer of 1.3Mb with a look-up procedure of 1,100 words per second , a sample of which is given in the following figure : We fhst built the transducer representing all the entries of DELAF along with their inflectionnal code</definiens>
			</definition>
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>\ [ Halliday and Hasan , 1976\ ] Lexical cohesion is the relationship between words , classified as follows : Molly likes cats .</sentence>
				<definiendum id="0">Lexical cohesion</definiendum>
			</definition>
			<definition id="1">
				<sentence>The similarity between words is a mapping a : Lx L -- -* \ [ 0 , 1\ ] , where L is a set of words ( or lexicon ) .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">a set of words</definiens>
			</definition>
			<definition id="2">
				<sentence>Similarity between words can be defined by either a syntagmatic or a paradigmatic relation .</sentence>
				<definiendum id="0">Similarity between words</definiendum>
				<definiens id="0">either a syntagmatic or a paradigmatic relation</definiens>
			</definition>
			<definition id="3">
				<sentence>LDV consists of 2,851 words ( as the headwords in LDOCE ) based on the survey of restricted vocabulary \ [ West , 1953\ ] .</sentence>
				<definiendum id="0">LDV</definiendum>
			</definition>
			<definition id="4">
				<sentence>Gloss~me is a closed subsystem of English .</sentence>
				<definiendum id="0">Gloss~me</definiendum>
			</definition>
			<definition id="5">
				<sentence>A r~f~rant of a node consists of several subrdfdrants correspond to the units of Giossdme .</sentence>
				<definiendum id="0">r~f~rant of a node</definiendum>
				<definiens id="0">consists of several subrdfdrants correspond to the units of Giossdme</definiens>
			</definition>
			<definition id="6">
				<sentence>Appendix B gives the details of the spreading activation .</sentence>
				<definiendum id="0">Appendix B</definiendum>
				<definiens id="0">gives the details of the spreading activation</definiens>
			</definition>
			<definition id="7">
				<sentence>Obviously , both ~r ( W , w ) and a ( w , W ) , where W is an extra word and w is not , are also computable .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">an extra word</definiens>
			</definition>
			<definition id="8">
				<sentence>Paradigme is the small and complete network for measuring the similarity .</sentence>
				<definiendum id="0">Paradigme</definiendum>
				<definiens id="0">the small and complete network for measuring the similarity</definiens>
			</definition>
			<definition id="9">
				<sentence>The meaning of a phrase , sentence , or text should be represented as pattern changing in time , though what we need is static and paradigmatic relation .</sentence>
				<definiendum id="0">meaning of a phrase</definiendum>
				<definiens id="0">pattern changing in time</definiens>
				<definiens id="1">static and paradigmatic relation</definiens>
			</definition>
			<definition id="10">
				<sentence>The similarity between words is computed by spreading activation on the semantic network Paradigme which is systematically constructed from a subset of the English dictionary LDOCE .</sentence>
				<definiendum id="0">Paradigme</definiendum>
				<definiens id="0">computed by spreading activation on the semantic network</definiens>
			</definition>
			<definition id="11">
				<sentence>Appendix B. Function of Paradigme Spreading Activation Rules Each node Pi of the semantic network Paradigme computes its activity value vi ( T+ 1 ) at time T+I as follows : v ' ( T+ l ) = ¢ ( R~ ( T ) + R~ ( T ) ) 2 + e~ ( T ) , where R/ ( T ) and R~ ( T ) are activity ( at time T ) collected from the nodes referred in the r~f6rant and r~f~r~ respectively ; q ( T ) E \ [ 0 , 1\ ] is activity given from outside ( at time T ) ; the output function ¢ limits the value to \ [ 0,1\ ] .</sentence>
				<definiendum id="0">R/</definiendum>
				<definiens id="0">R~ ( T ) are activity ( at time T ) collected from the nodes referred in the r~f6rant and r~f~r~ respectively ; q ( T ) E \ [ 0</definiens>
			</definition>
			<definition id="12">
				<sentence>R/ ( T ) is activity of the most plausible subr~fdrant in Pi , defined as follows : re ( T ) = S { m ( T ) , m = argmaxj { hij .</sentence>
				<definiendum id="0">R/ ( T</definiendum>
				<definiens id="0">activity of the most plausible subr~fdrant in Pi , defined as follows : re ( T ) = S { m ( T )</definiens>
			</definition>
			<definition id="13">
				<sentence>Sii ( T ) is the sum of weighted activity of the nodes referred in the j-th subr~f~rant of P { , defined as follows : S , i ( T ) = ~ tijk .</sentence>
				<definiendum id="0">Sii ( T )</definiendum>
				<definiens id="0">the sum of weighted activity of the nodes referred in the</definiens>
			</definition>
			<definition id="14">
				<sentence>a~k ( T ) , where t~k is thickness of the/~-th link ofri , and a~k is activity ( at time T ) of the node referred by the k-th link of ri .</sentence>
				<definiendum id="0">t~k</definiendum>
				<definiens id="0">activity ( at time T ) of the node referred by the k-th link of ri</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>Under such a grammar , a discourse constituent is either a discourse relation , a clause or a discourse relation together with one or more discourse constituent ( s ) .</sentence>
				<definiendum id="0">discourse constituent</definiendum>
			</definition>
			<definition id="1">
				<sentence>IN and OUT are attributes which represent the flow of anaphoric information , that is , IN represents the in-going context ( where a context is a sequence of potential antecedents i.e. a sequence of VP categories ) and OUT , the out-going context .</sentence>
				<definiendum id="0">IN</definiendum>
				<definiendum id="1">context</definiendum>
				<definiens id="0">the in-going context ( where a</definiens>
			</definition>
			<definition id="2">
				<sentence>£ : consists of the wffs described by the following syntax : wff ~ { term , formula , polarity : rel : \ [ Wffl ... wffn\ ] term -- * { variable , constant } formula -- * polarity : predicate : \ [ argl .</sentence>
				<definiendum id="0">£</definiendum>
				<definiens id="0">consists of the wffs described by the following syntax : wff ~ { term , formula , polarity : rel : \ [ Wffl ... wffn\ ] term -- * { variable , constant } formula -- * polarity : predicate : \ [ argl</definiens>
			</definition>
			<definition id="3">
				<sentence>The first elliptical VP is the perfective auxiliary has and thus subcategorises for a past participle whereas the second ellipsis consists of copula be and thus selects a predicative phrase .</sentence>
				<definiendum id="0">elliptical VP</definiendum>
				<definiens id="0">the perfective auxiliary has and thus subcategorises for a past participle whereas the second ellipsis consists of copula be and thus selects a predicative phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>Correspondingly , the antecedent VPs are ( 1 ) a predicative phrase ( lucky ) and ( 2 ) a past participle ( ordered his software from a house that can help ) .</sentence>
				<definiendum id="0">predicative phrase</definiendum>
				<definiens id="0">ordered his software from a house that can help )</definiens>
			</definition>
			<definition id="5">
				<sentence>( 11 ) illustrates a case where parallelism constrains the choice of an alternative semantic representation with the result that the a-clauses semantics is represented by a wff of the form -- ( p A -- q ) rather than the canonical semantic translation for discourses of the form If P , Q i.e. p -- -* q. Example ( 12 ) provides one more illustration of the interaction of syntax with discourse in determining multiple VPE resolution whereas example ( 13 ) illustrates a simple case of discourse parallelism .</sentence>
				<definiendum id="0">parallelism</definiendum>
			</definition>
			<definition id="6">
				<sentence>The second column ( Canonical LF ) indicates the `` canonical '' semantic representations ( or Logical Forms ) of aand e-clauses : a-clauses are represented by capital letter abbreviations which are mnemonic for their propositional content , whereas the semantics of elliptical clauses is represented by 0i where i reflects surface ordering .</sentence>
				<definiendum id="0">Canonical LF )</definiendum>
				<definiens id="0">indicates the `` canonical '' semantic representations ( or Logical Forms ) of aand e-clauses : a-clauses are represented by capital letter abbreviations which are mnemonic for their propositional content</definiens>
			</definition>
			<definition id="7">
				<sentence>Monostratality ( i.e the fact that different levels of linguistic information can be stated within a category ) is another important aspect of the model in that it allows for different knowledge sources to interact in determining VPE acceptability and resolution .</sentence>
				<definiendum id="0">Monostratality</definiendum>
				<definiens id="0">different knowledge sources to interact in determining VPE acceptability and resolution</definiens>
			</definition>
			<definition id="8">
				<sentence>More generally , it can be argued that VPE is a phenomenon which simultaneously involves phonology , syntax , semantics and discourse ( cf. \ [ Lappin and McCord 1990\ ] , \ [ Gardent 1991\ ] ) .</sentence>
				<definiendum id="0">VPE</definiendum>
				<definiens id="0">a phenomenon which simultaneously involves phonology , syntax , semantics and discourse ( cf. \ [</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>A subtree of a tree T is a connected subgraph S of T such that for every node in S holds that if it has daughter nodes , then these are equal to the daughter nodes of the corresponding node in T. It is trivial to see that a subuee is also a tree .</sentence>
				<definiendum id="0">subtree of a tree T</definiendum>
				<definiens id="0">a connected subgraph S of T such that for every node in S holds that if it has daughter nodes</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>The semantic projection of an f-structure , written with a subscript ~r , is a representation of the meaning of that f-structure .</sentence>
				<definiendum id="0">semantic projection of an f-structure</definiendum>
				<definiens id="0">a representation of the meaning of that f-structure</definiens>
			</definition>
			<definition id="1">
				<sentence>The expression ( MODS T ) denotes an f-structure through which there is a path MODS leading to T. For example , if T is the f-structure labeled f5 above , then ( MODS T ) is the f-structure labeled f4 , and ( MODS T ) a is the semantic projection of f4Thus , the lexical entry for obviously specifies the semantic representation of the f-structure that it modifies , an f-structure in which it is properly contained .</sentence>
				<definiendum id="0">MODS T )</definiendum>
			</definition>
			<definition id="2">
				<sentence>The composition level is the rules , often not stated in any formal system , that say what pattern of applications to do to assemble the constituent meanings .</sentence>
				<definiendum id="0">composition level</definiendum>
				<definiens id="0">the rules , often not stated in any formal system , that say what pattern of applications to do to assemble the constituent meanings</definiens>
			</definition>
			<definition id="3">
				<sentence>The composition level relies on function application in the semantic level to assemble meanings .</sentence>
				<definiendum id="0">composition level</definiendum>
				<definiens id="0">relies on function application in the semantic level to assemble meanings</definiens>
			</definition>
</paper>

		<paper id="1061">
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>A bilingual term list is a list associating source language terms with a ranked list of target language terms .</sentence>
				<definiendum id="0">bilingual term list</definiendum>
				<definiens id="0">a list associating source language terms with a ranked list of target language terms</definiens>
			</definition>
			<definition id="1">
				<sentence>Latent semantic indexing is a vector model , where a term-document matrix is transformed to a space of much less dimensions using a technique called singular value decomposition .</sentence>
				<definiendum id="0">Latent semantic indexing</definiendum>
				<definiens id="0">a vector model , where a term-document matrix is transformed to a space of much less dimensions using a technique called singular value decomposition</definiens>
			</definition>
			<definition id="2">
				<sentence>The methods consist of a linguistic term extraction phase and a statistic translation selection phase .</sentence>
				<definiendum id="0">methods</definiendum>
			</definition>
</paper>

		<paper id="1054">
			<definition id="0">
				<sentence>The tool identifies the changes between the two versions of the source language ( SL ) text and retrieves appropriate sentences from the target language ( TL ) text .</sentence>
				<definiendum id="0">tool</definiendum>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>DATR is a formal language in which the such relationships and generalisations can be simply stated .</sentence>
				<definiendum id="0">DATR</definiendum>
				<definiens id="0">a formal language in which the such relationships and generalisations can be simply stated</definiens>
			</definition>
			<definition id="1">
				<sentence>DATR has certain desirable formM and computational properties .</sentence>
				<definiendum id="0">DATR</definiendum>
			</definition>
			<definition id="2">
				<sentence>DATR is designed specifically for one , and offers more flexibility in the representation of exceptions and subregularities .</sentence>
				<definiendum id="0">DATR</definiendum>
				<definiens id="0">designed specifically for one , and offers more flexibility in the representation of exceptions and subregularities</definiens>
			</definition>
			<definition id="3">
				<sentence>DATR allows different kinds of information to be inherited from different places , and also allows generalisations to be overridden by either idiosyncratic facts or subregularities .</sentence>
				<definiendum id="0">DATR</definiendum>
				<definiens id="0">allows different kinds of information to be inherited from different places</definiens>
			</definition>
			<definition id="4">
				<sentence>List termination involves a measure of ingenuity , in order that nil is the value of &lt; syn subzat re &gt; and &lt; sem args re &gt; at VERB and &lt; syn subcat re re &gt; and &lt; sere args re re &gt; at TRANSITIVE , but nowhere else : 3 VERB : &lt; sere args &gt; == ARG : &lt; &gt; &lt; syn subcat &gt; ffi= COMP : &lt; &gt; .</sentence>
				<definiendum id="0">List termination</definiendum>
				<definiens id="0">3 VERB : &lt; sere args &gt; == ARG : &lt; &gt; &lt; syn subcat &gt; ffi= COMP : &lt; &gt;</definiens>
			</definition>
			<definition id="5">
				<sentence>To request information about a non-base form , we start the query path with alt x , where x is a label identifying the alternation under consideration .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">a label identifying the alternation under consideration</definiens>
			</definition>
			<definition id="6">
				<sentence>Bake is a cooking verb , and cooking verbs are , in the base case , transitive change-of-state verbs .</sentence>
				<definiendum id="0">Bake</definiendum>
				<definiens id="0">a cooking verb</definiens>
			</definition>
			<definition id="7">
				<sentence>Alternation behaviour is a major source of evidence as to how a verb should be classified , and grammaticality judgements are premised upon the patterns a competent speaker has frequently encountered in their experience of the language .</sentence>
				<definiendum id="0">Alternation behaviour</definiendum>
				<definiens id="0">a major source of evidence as to how a verb should be classified</definiens>
			</definition>
			<definition id="8">
				<sentence>In James Pustejovsky and Sabine Bergler , editors , Lexical semantics and knowledge representation : ACL SIGLEX Workshop , Berkeley , California , 1991 .</sentence>
				<definiendum id="0">Lexical</definiendum>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>The Context Feature Structure System ( CFS ) \ [ BSttcher and KSnyves-Tdth , 1992\ ] is a unification based system which evaluates feature structures with distributed disjunctions and dynamically definable types for structure inheritance .</sentence>
				<definiendum id="0">Context Feature Structure System ( CFS</definiendum>
				<definiens id="0">a unification based system which evaluates feature structures with distributed disjunctions and dynamically definable types for structure inheritance</definiens>
			</definition>
			<definition id="1">
				<sentence>Discussion : E.g. for the term f : t '' t lIt d2 dl ( dl -- ~ 2 , d2 ~ 1 ) is a specializer but not a context .</sentence>
				<definiendum id="0">Discussion</definiendum>
				<definiens id="0">a specializer but not a context</definiens>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>For example , the source clause in example ( 1 ) would have derivations that ( at some level ) lead to the following two interpretations : John has the property P where : ( 6 ) P = likes John 's mother ( 7 ) P = likes his own mother These two properties lead to the same reading for the source clause .</sentence>
				<definiendum id="0">John</definiendum>
				<definiens id="0">has the property P where : ( 6 ) P = likes John 's mother ( 7 ) P = likes his own mother These two properties lead to the same reading for the source clause</definiens>
			</definition>
			<definition id="1">
				<sentence>\ [ 1991\ ] ( henceforth DSP ) give an account of ellipsis resolution based on an equational analysis utilizing higher-order unification .</sentence>
				<definiendum id="0">DSP )</definiendum>
				<definiens id="0">give an account of ellipsis resolution based on an equational analysis utilizing higher-order unification</definiens>
			</definition>
			<definition id="2">
				<sentence>In particular , we work though the derivation of example ( 32 ) that leads to reading ( 33 ) , the reading that is problematic for identity-of-relations analyses : ( 33 ) John realizes that John is a fool , but Bill does not realize that Bill is a fool , even though Bill 's wife realizes Bill is a fool .</sentence>
				<definiendum id="0">Bill</definiendum>
				<definiens id="0">a fool , but Bill does not realize that Bill is a fool , even though Bill 's wife realizes</definiens>
				<definiens id="1">a fool</definiens>
			</definition>
			<definition id="3">
				<sentence>206 ( 35 ) es : \ [ predicate : realize polarity : negative agent : Bill theme : e4 : \ [ predicate : be agent : agent ( el ) be_pred : fool \ ] \ ] Reading : Bill does not realize that Bill is a fool The clause represented by ( 35 ) is the source for the elided third clause .</sentence>
				<definiendum id="0">realize polarity</definiendum>
				<definiens id="0">negative agent : Bill theme : e4 : \ [ predicate : be agent : agent ( el</definiens>
			</definition>
			<definition id="4">
				<sentence>The representation for the source clause is : ( 55 ) el : \ [ predicate : revise agent : John theme : \ [ obj : paper poss : agent ( el ) \ ] \ ] We add the temporal modifier , parallel event structure , and role fillers for the representation of the first elided clause : ( 56 ) ex : \ [ predicate : revise agent : John theme : \ [ obj : paper poss : agent ( el ) \ ] time : \ [ relation : before obj : e2 : \ [ predicate : revise agent : teacher theme : \ ] \ ] \ ] The filler of the theme role in the representation for the source event contains a link to that , so there are two options .</sentence>
				<definiendum id="0">revise agent</definiendum>
				<definiens id="0">before obj : e2 : \ [ predicate : revise agent</definiens>
			</definition>
			<definition id="5">
				<sentence>First , the theme may be referred to , yielding the strict reading : ( 57 ) el : \ [ predicate : revise agent : John theme : \ [ obj : paper poss : agent ( el ) \ ] time : \ [ relation : before obj : e2 : \ [ predicate : revise agent : teacher theme : theme ( et ) \ ] \ ] \ ] Reading : The teacher revised John 's paper Alternatively , the theme may be copied , yielding the sloppy reading : ( 58 ) el : \ [ predicate : revise agent : John theme : \ [ obj : paper poss : agent ( el ) \ ] time : \ [ relation : before obj : e2 : \ [ predicate : revise agent : teacher theme : \ [ obj : paper poss : agent ( e2 ) \ ] \ ] \ ] Reading : The teacher revised the teacher 's paper We now consider the readings for the second ellipsis .</sentence>
				<definiendum id="0">teacher theme</definiendum>
				<definiendum id="1">Reading</definiendum>
				<definiens id="0">yielding the strict reading : ( 57 ) el : \ [ predicate : revise agent : John theme : \ [ obj : paper poss : agent ( el ) \ ] time : \ [ relation : before obj : e2 : \ [ predicate : revise agent</definiens>
				<definiens id="1">( 58 ) el : \ [ predicate : revise agent : John theme : \ [ obj : paper poss : agent ( el ) \ ] time : \ [ relation : before obj : e2 : \ [ predicate : revise agent : teacher theme : \ [ obj : paper poss : agent ( e2 ) \ ] \ ] \ ]</definiens>
			</definition>
			<definition id="6">
				<sentence>Referring to both of the roles containing links to a source event results in the all-strict reading : ( 59 ) ca : \ [ predicate : revise agent : Bill theme : theme ( et ) time : \ [ relation : before obj : e4 : \ [ predicate : revise agent : teacher theme : theme ( e~ ) \ ] \ ] \ ] Reading : Bill revised John 's paper before the teacher revised John 's paper In the second possibility , both roles can be copied , resulting in the all-sloppy reading : ( 60 ) ca : \ [ predicate : revise agent : Bill theme : \ [ obj : paper poss : agent ( ca ) \ ] time : \ [ relation : before obj : e4 : \ [ predicate : revise agent : teacher theme : theme ( ca ) \ ] \ ] \ ] Reading : Bill revised Bill 's paper before the teacher revised Bill 's paper Third , the poss role of the theme role of el may be copied and the theme role of e2 may be referred to : ( 61 ) ca : \ [ predicate : revise agent : Bill theme : \ [ obj : paper poss : agent ( ez ) \ ] time : \ [ relation : before obj : e4 : \ [ predicate : revise agent : teacher theme : theme ( e2 ) \ ] \ ] \ ] Reading : Bill revised Bill 's paper before the teacher revised John 's paper Finally , the poss role of the theme role of el may be referred to and the theme role of e2 may be copied : ( 62 ) ca : \ [ predicate : revise agent : Bill theme : theme ( el ) time : \ [ relation : before obj : e4 : \ [ predicate : revise agent : teacher theme : theme ( ea ) \ ] \ ] \ ] Reading : Bill revised John 's paper before the teacher revised John 's paper Note that the reading ( 62 ) is the same as the strict/strict reading in ( 59 ) .</sentence>
				<definiendum id="0">teacher theme</definiendum>
				<definiens id="0">revise agent : Bill theme : \ [ obj : paper poss : agent ( ca ) \ ] time : \ [ relation : before obj : e4 : \ [ predicate : revise agent</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>int ( T ) is the set of interior nodes ofT .</sentence>
				<definiendum id="0">int ( T )</definiendum>
				<definiens id="0">the set of interior nodes ofT</definiens>
			</definition>
			<definition id="1">
				<sentence>~ X is called the lower and T z the upper cone of z. If R C_ 7 '2 is a binary relation we write Rx = { ylxRy } and call Rz the R-domaln of z. A function f : T ~ T is called monotone if z &lt; y implies f ( x ) &lt; f ( y ) , increasing if z &lt; _ f ( x ) for all x , and strictly increasing if z &lt; f ( z ) for all x &lt; r. Definition 1 A binary relation R C T 2 is called a command relation ( CR for short ) iff there exists a function fR : T ~ T such that ( 1 ) , ( ~ ) and ( 8 ) hold ; R is called monotone if in addition it satisfies ( 4 ) and tight if it satisfies ( 5 ) in addition to ( 1 ) ( 3 ) . fR is called the associated function of R. ( 1 ) Rr = ~fR ( x ) ( 2 ) z &lt; fR ( z ) for all z &lt; r ( 3 ) fRO ' ) = , '' ( 4 ) z &lt; y implies fR ( z ) &lt; fR ( Y ) ( 5 ) x &lt; fR ( y ) impZies fR ( x ) &lt; _ fR ( y ) . ( 1 ) expresses that fR ( z ) represents R ; ( 2 ) and ( 3 ) express that fR must be strictly increasing. If ( 4 ) holds , fR is monotone. A tight relation is monotone ; for if z _ &lt; y and y &lt; r then y &lt; fR ( Y ) and so z &lt; fR ( Y ) ; whence fR ( z ) _ &lt; fR ( Y ) by ( 5 ) . For some reason \ [ Barker and Pullum , 1990\ ] do not count monotonicity as a defining property of CRs even though there is no known command relation that fails to be monotone. Given a set P _C T we can define a function gp by ( t ) gp ( z ) = min { yly • P , y &gt; z } We put minO = r ; thus gp ( r ) = r. Let zPy iff y &lt; gp ( z ) , gp is the associated function of P , a relation commonly referred to as P-command .</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">fR</definiendum>
				<definiendum id="2">gp</definiendum>
				<definiens id="0">a binary relation we write Rx = { ylxRy } and call Rz the R-domaln of z. A function f : T ~ T is called monotone if z &lt; y implies f ( x ) &lt; f ( y ) , increasing if z &lt; _ f ( x ) for all x</definiens>
			</definition>
			<definition id="2">
				<sentence>If gp and gq are associated functions , then gp • go = gPnq denotes the associated function of the ( tight ) join .</sentence>
				<definiendum id="0">gPnq</definiendum>
				<definiens id="0">the associated function of the ( tight ) join</definiens>
			</definition>
			<definition id="3">
				<sentence>Then Ro ( SNT ) = ( RoS ) N ( RoT ) , ( SNT ) o R= ( So R ) N ( T o R ) .</sentence>
				<definiendum id="0">SNT</definiendum>
			</definition>
			<definition id="4">
				<sentence>Then xSy , xTy , hence x ( S M T ) y. Moreover , yRz , from which x ( ( S N T ) o R ) z. • Definition 7 A distributoid is a structure fO = ( D , N , U , o ) such thai ( 1 ) ( D , n , u ) is a distributive lattice , ( 2 ) o an associative operation and ( 3 ) o distributes both over M and U. Theorem 8 The monotone CRs over a given tree form a distributoid denoted by ~Diz ( T ) .</sentence>
				<definiendum id="0">distributoid</definiendum>
				<definiens id="0">from which x ( ( S N T ) o R</definiens>
				<definiens id="1">a distributive lattice , ( 2 ) o an associative operation</definiens>
			</definition>
			<definition id="5">
				<sentence>A labelling is a function £ : T ~ L. £ is called full if ~ ( z ) is an atom of £ or 0 for every z. If either ~ ( z ) = a = 0or 0 &lt; £ ( x ) &lt; a we say that zisof category a. Labelled trees are generated by boolean grammars .</sentence>
				<definiendum id="0">labelling</definiendum>
				<definiens id="0">an atom of £ or 0 for every z. If either ~ ( z</definiens>
			</definition>
			<definition id="6">
				<sentence>A boolean grammar is defined as a triple 6 = ( ~ , ~ , R ) where R is a finite subset of ( L { 0 } ) x L + and ~ • L { 0 } .</sentence>
				<definiendum id="0">boolean grammar</definiendum>
				<definiens id="0">a triple 6 = ( ~ , ~ , R ) where R is a finite subset of ( L { 0 } ) x L + and ~ • L { 0 }</definiens>
			</definition>
			<definition id="7">
				<sentence>Hence ~v maps all nearness terms into tight generable relations .</sentence>
				<definiendum id="0">Hence ~v</definiendum>
				<definiens id="0">maps all nearness terms into tight generable relations</definiens>
			</definition>
			<definition id="8">
				<sentence>where n is the number of atoms of 2 .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of atoms of 2</definiens>
			</definition>
			<definition id="9">
				<sentence>What we keep to distinguish grammars is the directed graph on the atoms of ~ induced by the unary reduct of G. Let us denote this graph by Gpb ( G ) .</sentence>
				<definiendum id="0">grammars</definiendum>
				<definiens id="0">the directed graph on the atoms of ~ induced by the unary reduct</definiens>
			</definition>
			<definition id="10">
				<sentence>Let Sf ( ~ ) denote the set of subformulas of ~ and Sf ( e ) the set of subformulas of ¢ .</sentence>
				<definiendum id="0">Sf</definiendum>
				<definiens id="0">the set of subformulas of ~ and Sf ( e ) the set of subformulas of ¢</definiens>
			</definition>
			<definition id="11">
				<sentence>Now let y , z be two points from S such that y &lt; z and for all u such that y &lt; u &lt; z u~S. Let ul andu2 be two points such that y &lt; ul &lt; us &lt; z and such that ul and us have the same label. We construct a new labelled tree U by dropping all nodes from ul up until the node immediately below us. The following holds of the new model. ( i ) It is a tree generated by G and ( ii ) 6u ( 0 ) x ~ 6u ( e ) x. Namely , if w - &lt; ul then £ ( ul ) -- - , £ ( w ) is a transition of G , hence £ ( u2 ) -- , t ( w ) is a transition of G as well because l ( ul ) £ ( u2 ) ; and so ( i ) is proved. For ( ii ) it is enough to prove that for all ~ E Sf ( D ) 0 Sf ( ¢ ) the value f~ ( z ) in the new model is the same as the value fs ( z ) in the old model. ( Identification is possible , because these points have not been dropped. ) This is done by reduction on the structure of g. Suppose then that 0 = IJ A and f~ ( z ) -fb ( z ) as well as f~ ( z ) = fe ( z ) ; then f~ ( x ) = min { f~ ( z ) , f~ ( z ) } = min { fb ( z ) , fe ( z ) } = fg ( z ) . And similarly for g = b V ~. By the normal form theorem we can assume 0 to be a disjunction of conjunctions of chains , so by the previous reductions it remains to treat the case where g is a chain. Hence let i~ = dot. We assume f ; ( z ) -re ( x ) -- -- : y. Let z : = f~ ( z ) . Then if y &lt; r , y &lt; z and else y = z. By construction , z is the first node above y to be of category a and z E S , by which z is not dropped. In the reduced model , z is again the first node of category a above y , and so f~ ( z ) -f~ ( y ) = z , which had to be shown. Assume now that we have a tree of minimal size generated by G in which/~ = e does not hold. Then ify , z E S such that y &lt; z but for no u E S y &lt; u &lt; z , then in between y and z all nodes have different labels. Thus , in between y and z sit no more points than there are atoms in £. Let this number be n ; then our model has size &lt; n • S. Now if we want to decide whether or not ~ = ¢ is in Eq ( G ) , all we have to do is to first generate all possible branches of trees 245 of length at most n x ( ~Sf ( O ) + ~Sf ( c ) ) + 2 and check the equation on them. If it holds everywhere , then indeed 0 = e is valid in all trees because otherwise we would have found a countermodel of at most this size. Theorem 14 It is decidable whether or not ~ ¢ E Eq ( O ) . • These theorems tell us that there is nothing dangerous in using domains in grammar as concerns the question whether the predictions made by this theory can effectively be computed ; that is , as ! ong as one sticks to the given format of domain constructions , it is decidable whether or not a given grammatical theory makes a certain prediction about domains. The aim set by our theory is to reduce all possible nearness conditions of grammar to some restrictions involving command relations. Thus we treat not only binding theory or case theory but also restrictions on movement. Even though \ [ Barker and Pullum , 1990\ ] did not think of movement and subjacency as providing cases for command relations , the fact that nearness conditions are involved clearly indicates that the theory should have something to say about them. However , there are various obstacles to a direct implementation. The theory of command relations is not directly compatible with standard nearness relations in G8. A command relation as defined here depends in its size only of the isomorphism type of the linear structure above the node z. So , typical definitions such as those involving the notions of being governed , being bound , having an accessible subject fail to be of the kind proposed here because they involve a node that stands in relation of c-command rather than domination. Nevertheless , if 6B would be spelt out fully into a boolean grammar , far more labels have to be used than appear usually on trees displayed in GB books. The reason is that while context-free grammars by definition allow no context to rule the structure of a local tree , in GB the whole tree is implicitly treated as a context. But if it is true that the context for a node reduces to nodes that are ccommanding , it is enough to add for certain primitive labels X another label QX which translates as one of my daughters is X. Here , QX is not necessarily understood to be a new label but a specific label that guarantees one of the daughters to be of category X. However , 'modals ' such as Q are somewhat whimsical creatures. Sometimes , QX is an already existing category , for example Q|P can ( with the exception of exceptional case marking constructions ) he equated with C'. On other occasions , however , we need to incorporate them into our grammar ; prominent modals are SLASH : X , which has the meaning somewhere below me is a gap of category X and AGR : X which says this sentence has a subject of category X. If a context-free rendering of phrase structure is done properly ( as for example in \ [ Gazdar et aL , 1985\ ] ) a single entry such as V must be split into a vast number of different symbols so we can reasonably assume that our grammar is rich enough to have all the QX for the X we need ; otherwise they must be added artificially. In that case many of the standard nearness relations can be directly encoded using command relations. A second problem concerns the role of adjunction in the definition of subjacency. If the domain of movement for a node ( that is , the domain within which the antecedent has to be found ) is tight , then no iteration of movement leads to escaping the original domain. So , the domain for movement must be large. But it can not be too large either because we loose the necessity of free escape hatches ( spec of comp , for example ) . The typical definitions of subjacency lead to domains that are just about right in size. However , the dilemma must be solved that after moving to spec of comp , an element can move higher than it could from its original position. Different solutions have been offered. The most simple is standard 2-node subjacency which is KOMMAND o KOMMAND. This domain indeed allows this type of cyclical movement ; cyclic movement from spec of comp to spec of comp is possible but only to the next spec of comp. However , due to it 's shortcomings , this notion has been criticised ; moreover , it has been felt that 1-node subjacacency should be superior , largely because of the slogan 'grammar does not count'. Yet , tight domains do n't do the jobs and so tricks have been invented. \ [ Chomsky , 1986\ ] formulated rather small domains but included a mechanism to escape them by creating 'grey zones ' in which elements are neither properly dominated by a node nor in fact properly non-dominated. This idea has caught on ( for example in \ [ Sternefeld , 1991\ ] ) but has to be treated cautiously as even the simplest notions such as category , node etc. receive new interpretations because nodes are not necessarily identical with occurrences of categories as before. A reduction to standard notions should certainly be possible and desired without necessarily banning adjunction. As \ [ Koster , 1986\ ] observed , grammatical relations are typically relations between a dependent element and an antecedent or : I I R \ [ Koster , 1986\ ] notes four conditions on such configurations. a. obligatoriness 246 b. uniqueness of the antecedent c. c-command of the antecedent d. locality If these conditions are met then this relation has the effect share property This has to be understood as follows. ( a. ) and ( b. ) express nothing but that 6 needs one and only one antecedent. This antecedent , a , must c-command 6. Finally , ( d. ) states that a must be found in some local domain of 6. Of course , this domain is language specific as well as specific to the syntactic construction , i. e. the category of 6 and c~. Likewise , the property to be shared depends on the category of a and 6. The locality restriction expresses that a is found within the R-domain of 6. This relation R is in the unmarked case defined as follows. Definition 15 a is locally accessible I to 6 if c~ &lt; _ 1~ , where fl is the least maximal projection containing 6 and a governor of 6. \ [ Koster , 1986\ ] assumes that greater domains are formed by licensed extensions. These extensions are marked constructions ; while all languages agree on the local accessibility 1 as the minimal domain within which antecedents must be found , larger domains may also exist but their size is language and construction specific. Nevertheless , the variation is limited. There are only three basic types , namely locally accessible i for i = 1 , 2 , 3. Definition 16 a is locally accessible 2 to 6 if ot &lt; _ ~ , where 1~ is the least maximal projection containing 6 , a governor for 6 and some opacity element w. a is locally accessible z to &amp; if there is a sequence ~i , 1 &lt; n , such that \ [ 31 is locally accessible 2 from &amp; and ~i+1 is locally accessible 2 from ~i. The opacity elements are drawn from a rather limited list. Such elements are tense , mood etc. A well-known example are Icelandic reflexives whose domain is the smallest indicative sentence. Matrix The local accessibility relations certainly are command relations in our sense. The real problem is whether they are definable using primitive labels of the grammar. In particular the recursiveness of the third accessibility makes it unlikely that we can find a definition in terms of A , V , o. Yet , if it were really an arbitrary iteration of the second accessibility relation it would be completely trivial , because any iteration of a command relation over a tree is the total relation over the tree. Hence , there must be something non-trivial about this domain ; indeed , the iteration is stopped if the outer/~ is ungoverned. This is the key to a non-iterative definition of the third accessibility relation. Let us assume for simplicity that there is a single type of governors denoted by GOV and that there is a single type of opacity element denoted by OP.Y , The first hurdle is the clarification of government. Normally , government requires a governing element , i.e. an element of category GOV that is close in some sense. How close , is not clarified in \ [ Koster , 1986\ ] . Clearly , by penalty of providing circular definitions , closeness can not be accessibility1 ; really , it must be an even smaller domain. Let us assume for simplicity that it is sisterhood. If then we introduce the modal tX to denote one of my sisters is of category X , being governed is equal to being of category tGOV. Likewise we will assume that the opacity element must be in c-command relation to 6. We are now ready to define the three accessibility relations , which we denote by LA 1 , LA 2 and LA 3. LA 1 = ®GOV* BAR:2 AQGOV o BAR:2 LA z = ®GOV* ®OPY• BAR:2 A®GOV • QOPY o BAR:2 A®GOV o QOPY • BAR:2 A®GOV o QOPY o BAR:2 LA s = ®GOV • QOPY • BAR:2 •-IIGOV A ( ~GOV • ( ~OPY o BAR:2 • -tGOV A®GOV o ~OPY • BAR:2 • -tGOV A®GOV o ®OPY o BAR:2 • -tlGOV ( Observe that • binds stronger than o. ) For a proof consider a point z of a labelled tree T. Let g denote the smallest node dominating both x and its governor and let m be the smallest maximal projection of 9. Then x &lt; g _ &lt; m. So two cases arise , namely g = m and g &lt; rn. In each cases LA 1 picks the right node. Likewise , if o denotes the smallest element containing x and a opacity element that c-commands z , then x &lt; o. Three cases are conceivable , o &lt; g , o = g and o &gt; g. However , if government can take place only under sisterhood , o &lt; g can not occur .</sentence>
				<definiendum id="0">QX</definiendum>
				<definiendum id="1">fl</definiendum>
				<definiendum id="2">•-IIGOV A ( ~GOV •</definiendum>
				<definiens id="0">y , z be two points from S such that y &lt; z and for all u such that y &lt; u &lt; z u~S. Let ul andu2 be two points such that y &lt; ul &lt; us &lt; z and such that ul and us have the same label. We construct a new labelled tree U by dropping all nodes from ul up until the node immediately below us. The following holds of the new model. ( i ) It is a tree generated by G and ( ii ) 6u ( 0 ) x ~ 6u ( e ) x. Namely , if w - &lt; ul then £ ( ul ) -- - , £ ( w ) is a transition of G , hence £ ( u2 ) -- , t ( w ) is a transition of G as well because l ( ul ) £ ( u2 ) ; and so ( i ) is proved. For ( ii ) it is enough to prove that for all ~ E Sf ( D ) 0 Sf ( ¢ ) the value f~ ( z ) in the new model is the same as the value fs ( z ) in the old model. ( Identification is possible , because these points have not been dropped. ) This is done by reduction on the structure of g. Suppose then that 0 = IJ A and f~ ( z ) -fb ( z ) as well as f~ ( z ) = fe ( z ) ; then f~ ( x ) = min { f~ ( z ) , f~ ( z ) } = min { fb ( z ) , fe ( z ) } = fg ( z ) . And similarly for g = b V ~. By the normal form theorem we can assume 0 to be a disjunction of conjunctions of chains , so by the previous reductions it remains to treat the case where g is a chain. Hence let i~ = dot. We assume f ; ( z ) -re ( x ) -- -- : y. Let z : = f~ ( z ) . Then if y &lt; r , y &lt; z and else y = z. By construction , z is the first node above y to be of category a and z E S , by which z is not dropped. In the reduced model , z is again the first node of category a above y , and so f~ ( z ) -f~ ( y ) = z , which had to be shown. Assume now that we have a tree of minimal size generated by G in which/~ = e does not hold. Then ify , z E S such that y &lt; z but for no u E S y &lt; u &lt; z , then in between y and z all nodes have different labels. Thus , in between y and z sit no more points than there are atoms in £. Let this number be n ; then our model has size &lt; n • S. Now if we want to decide whether or not ~ = ¢ is in Eq ( G ) , all we have to do is to first generate all possible branches of trees 245 of length at most n x ( ~Sf ( O ) + ~Sf ( c ) ) + 2 and check the equation on them. If it holds everywhere , then indeed 0 = e is valid in all trees because otherwise we would have found a countermodel of at most this size. Theorem 14 It is decidable whether or not ~ ¢ E Eq ( O ) . • These theorems tell us that there is nothing dangerous in using domains in grammar as concerns the question whether the predictions made by this theory can effectively be computed ; that is , as ! ong as one sticks to the given format of domain constructions , it is decidable whether or not a given grammatical theory makes a certain prediction about domains. The aim set by our theory is to reduce all possible nearness conditions of grammar to some restrictions involving command relations. Thus we treat not only binding theory or case theory but also restrictions on movement. Even though \ [ Barker and Pullum , 1990\ ] did not think of movement and subjacency as providing cases for command relations , the fact that nearness conditions are involved clearly indicates that the theory should have something to say about them. However , there are various obstacles to a direct implementation. The theory of command relations is not directly compatible with standard nearness relations in G8. A command relation as defined here depends in its size only of the isomorphism type of the linear structure above the node z. So , typical definitions such as those involving the notions of being governed , being bound , having an accessible subject fail to be of the kind proposed here because they involve a node that stands in relation of c-command rather than domination. Nevertheless , if 6B would be spelt out fully into a boolean grammar , far more labels have to be used than appear usually on trees displayed in GB books. The reason is that while context-free grammars by definition allow no context to rule the structure of a local tree , in GB the whole tree is implicitly treated as a context. But if it is true that the context for a node reduces to nodes that are ccommanding , it is enough to add for certain primitive labels X another label QX which translates as one of my daughters is X. Here , QX is not necessarily understood to be a new label but a specific label that guarantees one of the daughters to be of category X. However , 'modals ' such as Q are somewhat whimsical creatures. Sometimes ,</definiens>
				<definiens id="1">an already existing category , for example Q|P can ( with the exception of exceptional case marking constructions ) he equated with C'. On other occasions , however , we need to incorporate them into our grammar ; prominent modals are SLASH : X , which has the meaning somewhere below me is a gap of category X and AGR : X which says this sentence has a subject of category X. If a context-free rendering of phrase structure is done properly ( as for example in \ [ Gazdar et aL , 1985\ ] ) a single entry such as V must be split into a vast number of different symbols so we can reasonably assume that our grammar is rich enough to have all the QX for the X we need ; otherwise they must be added artificially. In that case many of the standard nearness relations can be directly encoded using command relations. A second problem concerns the role of adjunction in the definition of subjacency. If the domain of movement for a node ( that is , the domain within which the antecedent has to be found ) is tight , then no iteration of movement leads to escaping the original domain. So , the domain for movement must be large. But it can not be too large either because we loose the necessity of free escape hatches ( spec of comp , for example ) . The typical definitions of subjacency lead to domains that are just about right in size. However , the dilemma must be solved that after moving to spec of comp , an element can move higher than it could from its original position. Different solutions have been offered. The most simple is standard 2-node subjacency which is KOMMAND o KOMMAND. This domain indeed allows this type of cyclical movement ; cyclic movement from spec of comp to spec of comp is possible but only to the next spec of comp. However , due to it 's shortcomings , this notion has been criticised ; moreover , it has been felt that 1-node subjacacency should be superior , largely because of the slogan 'grammar does not count'. Yet , tight domains do n't do the jobs and so tricks have been invented. \ [ Chomsky , 1986\ ] formulated rather small domains but included a mechanism to escape them by creating 'grey zones ' in which elements are neither properly dominated by a node nor in fact properly non-dominated. This idea has caught on ( for example in \ [ Sternefeld , 1991\ ] ) but has to be treated cautiously as even the simplest notions such as category , node etc. receive new interpretations because nodes are not necessarily identical with occurrences of categories as before. A reduction to standard notions should certainly be possible and desired without necessarily banning adjunction. As \ [ Koster , 1986\ ] observed , grammatical relations are typically relations between a dependent element and an antecedent or : I I R \ [ Koster , 1986\ ] notes four conditions on such configurations. a. obligatoriness 246 b. uniqueness of the antecedent c. c-command of the antecedent d. locality If these conditions are met then this relation has the effect share property This has to be understood as follows. ( a. ) and ( b. ) express nothing but that 6 needs one and only one antecedent. This antecedent , a , must c-command 6. Finally , ( d. ) states that a must be found in some local domain of 6. Of course , this domain is language specific as well as specific to the syntactic construction , i. e. the category of 6 and c~. Likewise , the property to be shared depends on the category of a and 6. The locality restriction expresses that a is found within the R-domain of 6. This relation R is in the unmarked case defined as follows. Definition 15 a is locally accessible I to 6 if c~ &lt; _ 1~</definiens>
				<definiens id="2">the least maximal projection containing 6 and a governor of 6. \ [ Koster , 1986\ ] assumes that greater domains are formed by licensed extensions. These extensions are marked constructions ; while all languages agree on the local accessibility 1 as the minimal domain within which antecedents must be found , larger domains may also exist but their size is language and construction specific. Nevertheless , the variation is limited. There are only three basic types</definiens>
				<definiens id="3">if ot &lt; _ ~ , where 1~ is the least maximal projection containing 6 , a governor for 6 and some opacity element w. a is locally accessible z to &amp; if there is a sequence ~i , 1 &lt; n , such that \ [ 31 is locally accessible 2 from &amp; and ~i+1 is locally accessible 2 from ~i. The opacity elements are drawn from a rather limited list. Such elements are tense , mood etc. A well-known example are Icelandic reflexives whose domain is the smallest indicative sentence. Matrix The local accessibility relations certainly are command relations in our sense. The real problem is whether they are definable using primitive labels of the grammar. In particular the recursiveness of the third accessibility makes it unlikely that we can find a definition in terms of A , V , o. Yet , if it were really an arbitrary iteration of the second accessibility relation it would be completely trivial , because any iteration of a command relation over a tree is the total relation over the tree. Hence , there must be something non-trivial about this domain ; indeed , the iteration is stopped if the outer/~ is ungoverned. This is the key to a non-iterative definition of the third accessibility relation. Let us assume for simplicity that there is a single type of governors denoted by GOV</definiens>
				<definiens id="4">the clarification of government. Normally , government requires a governing element , i.e. an element of category GOV that is close in some sense. How close , is not clarified in \ [ Koster , 1986\ ] . Clearly , by penalty of providing circular definitions , closeness can not be accessibility1 ; really , it must be an even smaller domain. Let us assume for simplicity that it is sisterhood. If then we introduce the modal tX to denote one of my sisters is of category X , being governed is equal to being of category tGOV. Likewise we will assume that the opacity element must be in c-command relation to 6. We are now ready to define the three accessibility relations , which we denote by LA 1 , LA 2 and LA 3. LA 1 = ®GOV* BAR:2 AQGOV o BAR:2 LA z = ®GOV* ®OPY• BAR:2 A®GOV • QOPY o BAR:2 A®GOV o QOPY • BAR:2 A®GOV o QOPY o BAR:2 LA s = ®GOV • QOPY • BAR:2</definiens>
				<definiens id="5">binds stronger than o. ) For a proof consider a point z of a labelled tree T. Let g denote the smallest node dominating both x and its governor and let m be the smallest maximal projection of 9. Then x &lt; g _ &lt; m. So two cases arise , namely g = m and g &lt; rn. In each cases LA 1 picks the right node. Likewise , if o denotes the smallest element containing x and a opacity element that c-commands z , then x &lt; o. Three cases are conceivable , o &lt; g , o = g and o &gt; g. However , if government can take place only under sisterhood , o &lt; g can not occur</definiens>
			</definition>
</paper>

		<paper id="1036">
			<definition id="0">
				<sentence>The polynomial time complexity is established by using a graph-structured stack , which is a generalization of the notion of parse stack , in which pointers are used to connect stack elements .</sentence>
				<definiendum id="0">graph-structured stack</definiendum>
				<definiens id="0">a generalization of the notion of parse stack , in which pointers are used to connect stack elements</definiens>
			</definition>
			<definition id="1">
				<sentence>Instead , Lang uses the abstract notion of a table to store information , without trying to find the best implementation for this table .</sentence>
				<definiendum id="0">Lang</definiendum>
				<definiens id="0">uses the abstract notion of a table to store information , without trying to find the best implementation for this table</definiens>
			</definition>
			<definition id="2">
				<sentence>Items consist of a rule in which a dot has been inserted somewhere in the right side to separate the members which have been recognized from those which have not .</sentence>
				<definiendum id="0">Items</definiendum>
				<definiens id="0">consist of a rule in which a dot has been inserted somewhere in the right side to separate the members which have been recognized from those which have not</definiens>
			</definition>
			<definition id="3">
				<sentence>A goal element g contains for every nonterminal A such that A L* P for some P in g a value NODE ( g , A ) , which is the node representing some derivation of A found at the current input position , provided such a derivation exists , and NODE ( 9 , A ) is NIL otherwise .</sentence>
				<definiendum id="0">)</definiendum>
				<definiendum id="1">NODE</definiendum>
				<definiens id="0">the node representing some derivation of A found at the current input position , provided such a derivation exists , and</definiens>
			</definition>
			<definition id="4">
				<sentence>In a straightforward implementation , the relation /* is recorded by means of one large s ' x s boolean matrix , where s is the number of nonterminals in the grammar , and s ' is the number of elements in GOAL .</sentence>
				<definiendum id="0">s</definiendum>
				<definiens id="0">the number of nonterminals in the grammar , and s ' is the number of elements in GOAL</definiens>
			</definition>
			<definition id="5">
				<sentence>We furthermore need a list of all rules A -- * X a for each terminal and nonterminal X. A small optimization of top-town filtering ( see also Section 6 ) can be achieved by grouping the rules in these lists according to the left sides A. Note that the storage of the relation Z* is the main obstacle to a linear-sized parser .</sentence>
				<definiendum id="0">relation Z*</definiendum>
			</definition>
			<definition id="6">
				<sentence>Hidden left recursion is a special case of left recursion where the fact is `` hidden '' by an emptygenerating nonterminal .</sentence>
				<definiendum id="0">Hidden left recursion</definiendum>
				<definiens id="0">a special case of left recursion where the fact is `` hidden '' by an emptygenerating nonterminal</definiens>
			</definition>
			<definition id="7">
				<sentence>We generalize the relation i so that B L A if and only if there is a rule A -~ p B fl , where p is a ( possibly empty ) sequence of grammar symbols such that /~ -- * e. Clause lb is eliminated and to compensate this , Clauses la and 3 are modified so that they take into account prefixes of right sides which generate the empty string : la .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">generate the empty string : la</definiens>
			</definition>
			<definition id="8">
				<sentence>¢= 1 • Create an edge from el to g • iff~ = e then o REDUCE ( el ) elself/~ = t7 , where t is a terminal then o Inezt ~ Inezt U { el } elself ~ = B7 , where B is a nonterminal then o MAKE_GOAL ( B , el ) /* cf. Clause 5 */ MAKE_GOAL ( A , el ) : • if there is a goal element g in Fnext containing goals in class \ [ A\ ] then o Add goal A to g ( provided it is not already there ) else o Create goal element g consisting of A o Add g to Fnezt • Create an edge from A in g to el Figure 3 : The generalized LC parsing algorithm 310 REDUCE ( el ) : • Assume the label of el is \ [ A ~ a .</sentence>
				<definiendum id="0">B</definiendum>
				<definiendum id="1">MAKE_GOAL</definiendum>
				<definiens id="0">a nonterminal then o MAKE_GOAL ( B , el ) /* cf. Clause 5 */</definiens>
			</definition>
			<definition id="9">
				<sentence>More precisely , the number of nodes in a parse forest is O ( nP+l ) , where p is the length of the right side of the longest rule .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the length of the right side of the longest rule</definiens>
			</definition>
</paper>

		<paper id="1064">
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>, ( A DPL ) ( : Ix A ) DPL = : r `` -'~ • A DPL The negation -- , p of a program p is the dynamic logic test ( \ [ p\ ] ± ) ?</sentence>
				<definiendum id="0">DPL )</definiendum>
				<definiendum id="1">DPL</definiendum>
				<definiens id="0">The negation -- , p of a program p is the dynamic logic test</definiens>
			</definition>
			<definition id="1">
				<sentence>The programs are then closed under sequential composition ( interpreted as relational composition ) fp ( p ; p ' ) g iff fp ( p ) h and hp ( p ' ) g for some h , non-deterministic choice ( interpreted as union ) f p ( p + p ' ) g iff f p ( p ) g or hp ( p ' ) g , and Kleene star ( interpreted as the reflexive transive closure ) .</sentence>
				<definiendum id="0">Kleene star</definiendum>
				<definiens id="0">closed under sequential composition ( interpreted as relational composition</definiens>
			</definition>
			<definition id="2">
				<sentence>This approach , going back at least to Nelson \ [ 17\ ] ( a particularly appropriate reference , given its connection with Kleene \ [ 14\ ] ) , treats positive and negative information in a nearly symmetric fashion ; on formulas in ~ without an occurrence of : :~ , the function , ~N. is the identity .</sentence>
				<definiendum id="0">~N.</definiendum>
				<definiens id="0">treats positive and negative information in a nearly symmetric fashion ; on formulas in ~ without an occurrence of : :~ , the function</definiens>
			</definition>
			<definition id="3">
				<sentence>Furthermore , were it not for : V , our translation -~ would map formulas in ( ~ to programs interpreted as binary relations on So = { s \ [ s is a function from a finite subset of X to IMI } , where X is the full set of marked an unmarked variables X = XoUYUZ .</sentence>
				<definiendum id="0">X</definiendum>
			</definition>
			<definition id="4">
				<sentence>Taking the `` the formal semantics apparatus '' to be dynamic logic , DPL treats existential variables through random assignments .</sentence>
				<definiendum id="0">DPL</definiendum>
				<definiens id="0">treats existential variables through random assignments</definiens>
			</definition>
</paper>

		<paper id="1047">
			<definition id="0">
				<sentence>( 1 ) arrived : V , ( T PrtED ) = `` arrive ( SUDJ ) ' ( a T REL ) -- -arrive ( a T AaQ1 ) = a ( T sunJ ) Within the domain of translation , Wedekind \ [ 1988\ ] , and Sadler and Thompson \ [ 1991\ ] recognized some problems of the correspondence approach which concern data of head .</sentence>
				<definiendum id="0">Sadler</definiendum>
				<definiens id="0">arrive ( SUDJ ) ' ( a T REL ) -- -arrive ( a T AaQ1 ) = a ( T sunJ ) Within the domain of translation</definiens>
			</definition>
			<definition id="1">
				<sentence>Intuitively , the semantic argument ( ArtG 1 ) of the adverb corresponds to the information coded in the partim f-structure ( 3 ) , which comprises only the information concerning the subject and the predicate of the sentence .</sentence>
				<definiendum id="0">semantic argument</definiendum>
				<definiens id="0">comprises only the information concerning the subject and the predicate of the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Proceeding from an initial mapping of a given fstructure f into an empty semantic structure the interpretation works top-down according to the following two principles : If trg is defined and h is a substructure ( h = ( g A ) ) or an element of a set-value of g ( h E ( g A ) ) and ( A1 ) TY ( g ) r and TY ( h ) = { r ' , r ) then ( i ) ( g A ) = h `` -+ ( fig FU ) `` trh A ( fig ARG ) -- -~ a ( g\A ) A TY ( g\A ) = r ' , ( ii ) h e ( g A ) -- -* ( # g FU ) - '' ah A ( ag ARG ) = a ( g\ ( A h ) ) A TY ( g\ ( A h ) ) = v ' , ( A2 ) TY ( g ) = v A TY ( h ) = r -- -* ~9 = ah .</sentence>
				<definiendum id="0">h</definiendum>
				<definiendum id="1">TY</definiendum>
				<definiendum id="2">ah A ( ag ARG</definiendum>
				<definiendum id="3">h ) ) A TY</definiendum>
				<definiens id="0">a substructure ( h = ( g A ) ) or an element of a set-value of g ( h E ( g A )</definiens>
				<definiens id="1">g A ) = h `` -+ ( fig FU ) `` trh A ( fig ARG</definiens>
			</definition>
			<definition id="3">
				<sentence>and depict the decomposition of the f-structure as a graph where each subtree dominated by a branching node represents the partial f-structure which comprises the attribute-value paths contained in that subtree .</sentence>
				<definiendum id="0">branching node</definiendum>
				<definiens id="0">comprises the attribute-value paths contained in that subtree</definiens>
			</definition>
			<definition id="4">
				<sentence>In detail the algorithm works as follows• If TY ( f ) = r the algorithm starts from the initial assignment ~rf = fr and proceeds top-down according to the following principles : If ag is defined and h is a substructure ( h = ( 9 A ) ) or an element of a set-value of g ( h E ( g A ) ) , YY ( h ) = ( rn , ( 'rn-1 ... ( T1 , 7 '' ) .</sentence>
				<definiendum id="0">YY</definiendum>
				<definiens id="0">a substructure ( h = ( 9 A ) ) or an element of a set-value of g ( h E ( g A ) ) ,</definiens>
			</definition>
			<definition id="5">
				<sentence>Since all free grammatical functions ( ADJ ) are homogeneous functors ( argument and value are of the same type ) and it is clear from the c-structure rules which type of argument they modify ( a modifier on S-level is either a sentence or predicate modifier , 409 etc. ) , f-structures with free functions can also be ensured to be interpreted .</sentence>
				<definiendum id="0">ADJ</definiendum>
				<definiendum id="1">S-level</definiendum>
			</definition>
			<definition id="6">
				<sentence>These principles constrain the interpretation of the f-structures and their parts if special conditions are satisfied .</sentence>
				<definiendum id="0">parts</definiendum>
				<definiens id="0">if special conditions are satisfied</definiens>
			</definition>
			<definition id="7">
				<sentence>Lexical-Functional Grammar : A Formal System for Grammatical Representation .</sentence>
				<definiendum id="0">Lexical-Functional Grammar</definiendum>
				<definiens id="0">A Formal System for Grammatical Representation</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>The parser is a bottom-up active chart parser without prediction , in which the addition of an active item based on a rule R is considered whenever an inactive item H is entered into the chart which matches the head of R. More precisely , if item ( Cat , \ [ \ ] , B , E ) is derived , and there is a rule LHS -- * D1 , ... , Dh-1 , Ca~ , Dh+l , ... . Dn and there are inactive items matching D1 ... Dh-1 , ranging from B0 to B , an iIem ( LHS , Dh+I..</sentence>
				<definiendum id="0">iIem</definiendum>
				<definiens id="0">a bottom-up active chart parser without prediction , in which the addition of an active item based on a rule R is considered whenever an inactive item H is entered into the chart which matches the head</definiens>
			</definition>
			<definition id="1">
				<sentence>Secondly , the head-driven chart parser is an active chart parser ( i.e. it also stores partial analyses of phrases ) ; 1 the second author prefers to write the second rule as Val .</sentence>
				<definiendum id="0">head-driven chart parser</definiendum>
				<definiens id="0">an active chart parser</definiens>
			</definition>
			<definition id="2">
				<sentence>The active chart parser ( act ) is the same as the head-chart parser , but now it is assumed that for each rule the left-most daughter is the head ( active chart ) .</sentence>
				<definiendum id="0">active chart parser</definiendum>
				<definiens id="0">active chart )</definiens>
			</definition>
			<definition id="3">
				<sentence>The inactive chart parser ( inact ) is a version of the headcorner parser where each right-most daughter is assumed to be the head of the rule .</sentence>
				<definiendum id="0">inactive chart parser</definiendum>
				<definiens id="0">a version of the headcorner parser where each right-most daughter is assumed to be the head of the rule</definiens>
			</definition>
			<definition id="4">
				<sentence>head_corner ( Small , Qi , Q2 , Goal , PO , P , E0 , E ) : rule ( Small , Mid , Left , Right ) , left ( Left , QO , Q1 , E0 ) , right ( Right , ~2 , Q , E ) , hc_table ( Mid , QO , Q , Goal , PO , P ) , head_corner ( Mid , QO , Q , Goal , PO , P , EO , E ) .</sentence>
				<definiendum id="0">head_corner</definiendum>
				<definiens id="0">Small , Qi , Q2 , Goal , PO , P , E0 , E</definiens>
			</definition>
</paper>

		<paper id="1053">
			<definition id="0">
				<sentence>We take a tree T to be a structure ( N , &gt; ) , where N is a set of nodes and &gt; stands for dominance , a binary relation on N. We say that nodes a and b are connected iff a &gt; b V b &gt; a V a = b. We define the relation of immediate dominance ~between two nodes a and b as a &gt; b A ~3c : a &gt; c A c &gt; b. Dominance is an irreflexive partial order relation satisfying the axioms ( 1 -- 3 ) .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
			<definition id="1">
				<sentence>443 ( 4 ) aRb ~-* a , b unconnected ^ I { c I B ( c , b ) ^ - , e &gt; a } l &lt; n Balanced relations like government require a definition in terms of two BC-definable relations : Rl ( a , b ) and R2 ( b , a ) .</sentence>
				<definiendum id="0">Rl</definiendum>
				<definiens id="0">{ c I B ( c , b ) ^ - , e &gt; a } l &lt; n Balanced relations like government require a definition in terms of two BC-definable relations</definiens>
			</definition>
			<definition id="2">
				<sentence>def is a variable ranging over the given definitions .</sentence>
				<definiendum id="0">def</definiendum>
			</definition>
			<definition id="3">
				<sentence>( 27 ) B ( c , b ) ~ 3def : \ [ Ll ( C ) A c &gt; b\ ] V ILl ( c ) A I ( c , b , B , L2 ) \ ] V \ [ Ll ( c ) A c &gt; b A - , I ( c , b , B , L2 ) \ ] We only take into account nodes c that separate a from b in the sense that they sit on the ancestor line of b but not on that of a ( see also the restrictions of 4 and 5 ) .</sentence>
				<definiendum id="0">V ILl ( c ) A I</definiendum>
				<definiens id="0">c , b , B , L2 ) \ ] V \ [ Ll ( c ) A c &gt; b A - , I ( c , b</definiens>
			</definition>
			<definition id="4">
				<sentence>( 28 ) xNy A y &gt; _b A `` - , y &gt; _a -- -* ( B ( y , b ) V ( I ( y , b , B , L ) A -~L ( y ) ) *-* I ( x , b , B , L ) ) In parsing , an unbounded dependency ( formally , a relation R ) is triggered by a node nl ( e.g. because it lacks a 0-role or can not take up a 0-role assigned to it ) and successfully terminates when a corresponding node n2 is found ( that can supply the missing 0-role or absorb a superfluous 0-role ) .</sentence>
				<definiendum id="0">unbounded dependency</definiendum>
				<definiens id="0">y , b</definiens>
				<definiens id="1">a relation R ) is triggered by a node nl</definiens>
			</definition>
			<definition id="5">
				<sentence>IP refutes the hypothesis that IP* is the deepest embedded tensed IP , and it turns out to be this IP as soon as the variable is found .</sentence>
				<definiendum id="0">IP</definiendum>
				<definiens id="0">refutes the hypothesis that IP* is the deepest embedded tensed IP , and it turns out to be this IP as soon as the variable is found</definiens>
			</definition>
</paper>

		<paper id="1060">
</paper>

		<paper id="1052">
			<definition id="0">
				<sentence>7Here L stands for the list of complements subcategorized by the lower verb .</sentence>
				<definiendum id="0">7Here L</definiendum>
				<definiens id="0">the list of complements subcategorized by the lower verb</definiens>
			</definition>
</paper>

		<paper id="1055">
			<definition id="0">
				<sentence>Lexical items correspond to configurations of concepts and roles ( not just to single concepts , as it is usually done in generation ) , and the option finder determines the set of all items that can cover a part of the input proposition ( represented as LOOM instances ) .</sentence>
				<definiendum id="0">option finder</definiendum>
				<definiens id="0">determines the set of all items that can cover a part of the input proposition</definiens>
			</definition>
			<definition id="1">
				<sentence>The front-end of this system has been implemented by extending the PENMAN sentence generator so that it can choose words on the basis of a distance function that compares the feature/value pairs of lexical entries ( of synonyms ) with a target specification .</sentence>
				<definiendum id="0">PENMAN sentence generator</definiendum>
				<definiens id="0">compares the feature/value pairs of lexical entries ( of synonyms</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>The Formulator-internal stimulus is an effect of the constraints of rapid , incremental utterance production ; in particular , it causes the Formulat* The research reported in this paper is carried out in the research project `` Sprachproduktion : von konzeptueller Struktur und Kontext zur prosodischen Realisierung der Bedeutung '' at the University of Hamburg .</sentence>
				<definiendum id="0">Formulator-internal stimulus</definiendum>
				<definiens id="0">an effect of the constraints of rapid , incremental utterance production</definiens>
			</definition>
			<definition id="1">
				<sentence>The SYNPHONICS ( `` Syntactic and Phonological Realization of Incrementally Generated Conceptual Structures '' ) approach , which subscribes to a cognitive science perspective on language processing , aims at linking psycholinguistic insights into the nature of the human natural language production process with well-established assumptions in theoretical and computational linguistics concerning the representation and processing of grammatical knowledge .</sentence>
				<definiendum id="0">SYNPHONICS</definiendum>
			</definition>
			<definition id="2">
				<sentence>More specifically , the SYNPHONICS Formulator uses a grammar for German in the mold of Head-driven Phrase Structure Grammar ( HPSG ; Pollard &amp; Sag 1987 , 1992 ) .</sentence>
				<definiendum id="0">SYNPHONICS Formulator</definiendum>
				<definiens id="0">uses a grammar for German in the mold of Head-driven Phrase Structure Grammar ( HPSG</definiens>
			</definition>
			<definition id="3">
				<sentence>Unlike deduction-based approaches to natural language generation in computational linguistics ( e.g. , Shieber et al. 1990 ) , however , the SYNPHONICS approach involves a detailed and transparent process model , with sub-processes being explicitly specified at any point in the overall process .</sentence>
				<definiendum id="0">SYNPHONICS approach</definiendum>
				<definiens id="0">involves a detailed and transparent process model , with sub-processes being explicitly specified at any point in the overall process</definiens>
			</definition>
			<definition id="4">
				<sentence>The SYNPHONICS Formulator , which is a formulation component for German sentence production , consists of three sub-components : the semantic encoder , which transforms the conceptual input structure CS into an abstract semantic representation SR ( cf. Bierwisch &amp; Schreuder 1992 ) ; the syntactic encoder , which , on the basis of SR , selects lexical items and forms an abstract syntactic representation ; the phonological encoder , which forms an abstract phonological representation .</sentence>
				<definiendum id="0">SYNPHONICS Formulator</definiendum>
				<definiendum id="1">SR</definiendum>
				<definiendum id="2">phonological encoder</definiendum>
				<definiens id="0">a formulation component for German sentence production , consists of three sub-components : the semantic encoder , which transforms the conceptual input structure CS into an abstract semantic representation</definiens>
				<definiens id="1">the syntactic encoder , which , on the basis of SR , selects lexical items and forms an abstract syntactic representation ; the</definiens>
				<definiens id="2">forms an abstract phonological representation</definiens>
			</definition>
			<definition id="5">
				<sentence>Argument attraction is a mechanism that affects only the argument structure of the governed verb , but does not affect the primary link between semantic roles and arguments .</sentence>
				<definiendum id="0">Argument attraction</definiendum>
				<definiens id="0">a mechanism that affects only the argument structure of the governed verb , but does not affect the primary link between semantic roles and arguments</definiens>
			</definition>
			<definition id="6">
				<sentence>The Subcategorization Principle handles the arguments of the verbal complex in the usual way .</sentence>
				<definiendum id="0">Subcategorization Principle</definiendum>
				<definiens id="0">handles the arguments of the verbal complex in the usual way</definiens>
			</definition>
			<definition id="7">
				<sentence>V/T PHON : `` Peter gebissen wird '' 1 SUBCAT &lt; &gt; NP \ ] PHON : `` peter '' SUBCAT &lt; &gt; TYPE : structural CASE : LVALUE : nominative V/T V VPHON : `` gebissen werd- '' l suBcA ' &lt; BL ( X~KED-ARG : IT\ ] \ [ ~HON : `` gebis sen UBCAT~/PD wird '' I I T I PHON : 'present tense ' 1 SUBCAT &lt; \ [ ~\ ] • V \ [ SUBCAT : \ [ ~\ ] \ ] &gt; Fimire 3 : Structural Description of a Passive Sentence We note in passing that the theory makes the correct predictions for German impersonal passives , i.e. , passives without nominatively marked NPs , such as Hier wird getanzt \ [ ~ere be ( 3 sg ) danced'\ ] , Den M~mnern wird geholfen \ [ 'the men ( dat pl ) be ( 3 sg ) helped ~\ ] and Der Opfer wird gedacht \ [ 'the victims ( gen pl ) be ( 3 sg ) remembered'\ ] .</sentence>
				<definiendum id="0">V/T PHON</definiendum>
				<definiendum id="1">gen pl</definiendum>
				<definiens id="0">Structural Description of a Passive Sentence We note in passing that the theory makes the correct predictions for German impersonal passives</definiens>
			</definition>
			<definition id="8">
				<sentence>The fh-St is a stimulus external to the linguistic system ; the second is a stimulus internal to the linguistic system .</sentence>
				<definiendum id="0">fh-St</definiendum>
				<definiens id="0">a stimulus external to the linguistic system</definiens>
			</definition>
			<definition id="9">
				<sentence>The Functional Inspector completes the categorial requirements of the situation type increment , which actually calls for a verbal category , by initiating a call to the appropriate auxiliary ( i.e. , werden ) .</sentence>
				<definiendum id="0">Functional Inspector</definiendum>
				<definiens id="0">completes the categorial requirements of the situation type increment</definiens>
			</definition>
			<definition id="10">
				<sentence>Following the above mentioned integration heuristic , the Integrator inserts the phrase corresponding to the Reid into the most prominent syntactic position , where it receives the nominative case by the structural Case Principle .</sentence>
				<definiendum id="0">Integrator</definiendum>
				<definiens id="0">inserts the phrase corresponding to the Reid into the most prominent syntactic position</definiens>
			</definition>
			<definition id="11">
				<sentence>The Formulator has a number of language-system internal devices at its command to cope with the material delivered by the Conceptualizer .</sentence>
				<definiendum id="0">Formulator</definiendum>
				<definiens id="0">a number of language-system internal devices at its command to cope with the material delivered by the Conceptualizer</definiens>
			</definition>
			<definition id="12">
				<sentence>Paper presented at the Workshop German Grammar in HPSG , Saarbr~icken , August 8.-9. , 1991 .</sentence>
				<definiendum id="0">Paper</definiendum>
				<definiens id="0">presented at the Workshop German Grammar in HPSG</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>The third argument consists of the parameters Input Character , Direction , Offset , and the fourth refers ( for nouns ) to the characters for the output word .</sentence>
				<definiendum id="0">third argument</definiendum>
				<definiens id="0">consists of the parameters Input Character , Direction , Offset , and the fourth refers ( for nouns ) to the characters for the output word</definiens>
			</definition>
			<definition id="1">
				<sentence>KIMMO : A twolevel morphological analyzer .</sentence>
				<definiendum id="0">KIMMO</definiendum>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>For a given path p the proper parts of x can be mutually localized wrt a linear order &lt; p. This gives us a new constraint for AMORPHOUS when P is applied to objects : AMORPHOUS ( P ) =~ Vx ( P ( x ) =¢ , -~3z ' , p ( x ' E A E • x '' % E • x ' _ % Linguistically , the predicate AMORPHOUS is associated with partitive and indefinite plural determiners. It is interesting to note that such NPs have a characteristic property : they may not occur as the subjects of predication s ( 27 ) * Du pain est toujours boa h manger ( Of the ) bread is always good to eat ( 28 ) ? ? Des livres sont toujours utiles ( Of the ) books are always useful ( 29 ) ? ? Do pain m'a rdconfortd ( Of the ) bread cheered me up ( 30 ) ? ? Des livres m'ont beaucoup aidd ( Of the ) books were of great help to me If there is no equivalent operator on verbal predicates , it follows that they can not be amorphous. If additional evidence confirms this line of reasoning , it suggests that , in spite of strong aspectual similarities between verbal and nominal predicates ( e.g. \ [ Bach , 1986 ; Krifka , 1992\ ] ) i some important distinction ( s ) must be made. It is easy to see now why the meaning of commencer requires that the complement be bounded. As a function on events , commencer returns the initial part of its argument ( or is undefined ) : we will associate to commencer the function first_part_of = ~e ( I P ( e ) ) , IP being the initial point of the event e. As a function on objects 4 , first_part_of returns the initial 3see \ [ Galmiche , 1986\ ] on the role of contextual factors. use of commencer as `` be the first part of '' , to which we return in the last section. part of any event which is associated with the object by the interpretive procedure described in section 4. This procedure exploits the fact that there is a morphism between parts of objects and parts of time , as noted in \ [ Krifka , 1992\ ] . It requires that the beginning of the event correspond to the `` initial '' part with respect to some order , usually spatial. Since amorphous objects have no initial part the procedure fails , even if a plausible event has been found ( e.g. manger for commencer dn fromage ) . For each object x , we must have an event e and a path p in x such that the models ( O~ , &lt; p ) and ( Te , &lt; ) , where O~ and Te are the restrictions of O and T to x and e , are isomorphic. Then ( by basic model theory ) they are elementarily equivalent , and e satisfies AMORPHOUS , which means that e has not initial point and that first_part_of is undefined for e. It follows that commencer can not apply to amorphous predicates , which lack any initial part. The second constraint on the complement of commencer in its coercion use is interpretive : the reconstructed event is an event in which the object denoted by the NP is controlled by the entity denoted by the subject of commencer. This results from two factors : ( i ) the subject of commencer retains the interpretation which it has when the complement is an NP of type e , and ( ii ) there is nothing to construct the event from , except the NP of type o itself. The controller of an event is the entity which triggers and causally maintains it ( for a general analysis of control , causality and related notions see \ [ Brennenstuhl , 1982 ; Croft , 1991\ ] ) . When the complement NP denotes an event , the subject is an intentional controller of the event , as the following observations indicate. First , this NP must denote an event , that is , an entity which allows for a controller : nominals denoting psychological states and properties are excluded 5 ( 31 ) * Ace moment Jean a commencd an grand mdpris pour les politicien At that moment John began a great contempt for politicians ( 32 ) * Jean a commencd une honn~tetd remarqnable John has begun a remarkable honesty Second , it is not enough that the subject denote the initiator of the event , who simply triggers it , or the inanimate cause. It must be a full-fledged intentional controller. Thus ( 33 ) is not acceptable , since the referee signals the beginning of a match , even has the power to stop it , but does not control its development 5There is a restricted dass of complements , denoting common diseases as in commencer une grippe , un rhume , with which the subject is not interpreted as a controller. This seems to be a marginal use which we leave aside here. 172 ( 33 ) ? ? L'arbitre a commencg le match a 14 heures The referee began the match at 14 h ( 34 ) Les gquipes oat commencg le match fi 14 heures. The teams began the match at 14 h Similarly , ( 35 ) isodd , although the acid is considered as the cause of the event. ( 35 ) * L 'acide a commencg la destruction du marbre The acid has begun the destruction of the marble Furthermore , it is not enough that the subject be the controller of some process related with the main event. For instance , commencer la conf # rence ( to begin the lecture ) may not be understood as `` to begin to listen to the lecture '' , it means `` to begin to deliver the lecture '' : listening to a lecture is an activity , of which the agent may be said to be the controller , but it does not causally impinge on the process of lecturing itself. It should be noted that these restrictions do NOT characterize commencer when it takes a verbal complement. The subject does not have to be an intentional controller , and may even be non-referential as in l'acide a commencg it attaquer ( corrode ) le marbre or il a commencg it pleuvoir ( it began to rain ) . Turning now to the coercion interpretation , we see that it is necessary , but not sufficient , to say that the subject is interpreted as the controller of some event in which the object is involved. For instance , the two following interpretations are excluded : ( i ) the interpretation in which the object undergoes a change of position under the action of the controller : commencer la pierre , la voiture ( the stone , car ) may not mean `` to begin to move the stone , to drive the ear '' . Yet , moving an object and driving a car are causal processes , causally controlled by human beings. ( it ) The interpretation in which the subject changes its position along a path denoted by the complement ; in Dowty 's terms ( \ [ Dowty , 1991\ ] ) , the complement can not be an `` incremental path '' : commencer ie tunnel , le dgsert de Gobi ( the tunnel , the desert of Gobi ) do not mean `` to begin to go through the tunnel , the desert of Gobi '' . Thus , it would be a mistake to simply state that the reconstructed event is any event associated with the object ( as in the qualia structure for instance ) , even adding the condition that the subject of commencer must be a controller. The complement does not get a default interpretation either. In this ease one would expect the patient interpretation , given that the subject is a controller , which is a strong form of agentivity. But the interpretations in ( i ) and ( it ) are instances of what Dowty calls the `` protopatient '' interpretation. The requirement is stronger : not only must the subject be a controller of the event , it must control the object itself. Driving a ear , rolling a stone , going through a tunnel , or crossing a desert do not affect the object in any significant way. In fact this requirement follows directly from the semantics of commencer and the only information which is available , that is , the type of the object. The subject may be a controller in an event thoroughly constructed from an NP of type o only if it controls the object. When this obtains , the event is in most cases a modification of the object. The object comes into being ( commencer une maison = `` to begin to build a house '' ) , is consumed ( commencer le vin= `` to begin to drink the wine '' ) , or undergoes a definite change of state ( commencer la salle de bains = `` to begin to paint/clean the bathroom '' ) . In other words , we accept that the information associated With the lexical items in the qualia structure helps to specify the interpretation in a given context , as mentionned above , but it does not contribute to the semantics of the construction itself. The only information which contributes to the semantics is borne by the lexical iten commencer : ( i ) commencer is a `` function '' which applies to an event and returns its initial part , ( it ) the subject of commencer with an NP complement is the controller of the event , ( iii ) the event is denoted by the complement e or constructed by isomorphism from the complement o. However , there is a class of objects which seem to raise difficulties. We have considered material objects ; there are also objects which me may call informational , and which occur as complements of commencer. At first sight , their interpretation does not involve a modification. Such are a book , a list , a story , a student 's paper , a magazine , a listing , etc. Consider ( 1 ) again. As noted in \ [ Pustejovsky , 1991\ ] commencer le livre/to begin the book does not only mean `` to begin to write the book '' but also `` to begin to read the book '' , an activity which is not immediately seen as an event of modification of the book. This example contrasts with commencer une symphonic/to begin a symphony which may mean `` to begin to compose/perform a symphony '' , not to `` to begin to listen to a symphony '' . The problem is the following : why does the book allow the interpretation `` to read '' while the symphony does not allow the interpretation `` to listen '' ? We propose that in fact `` to read a book '' is a modification of the book while `` to listen to a symphony '' is '' not a modification of the symphony : there is no parallelism between reading and listening. Reading is a process by which the reader interprets an organized sequence of signs , thus adding to the material object a new informational layer. This layer does not exist independently of the reading operation , which is totally controlled by the reader. On the other hand , listening does not modify the music : nmsical sounds are not signs , they are stimuli , i.e. they provoke reactions but are not systematically associated with information according to some definite set of rules ( at least in our culture ) . The difference between material modification and informational modification is that in the first case the result is objectivized , while it is internal in the latter. 173 Our treatment is twofold. On one hand , we propose lexical descriptions in accordance with the preceding analysis , which do not use type change and contain an abstract pattern , allowing for coercion interpretation. On the other hand , we must make sure that our approach meets basic requirements of computational tasks. Coercion phenomena can raise problems for understanding or generation systems , since they need to interpolate predicates to issue correct interpretations or syntactic forms ( \ [ Gerstl , 1992\ ] ) . An understanding system should be able to interpret a sentence like Jean prit ses pinceauz et commenfa la porte ( John took his paint-brushes and began the door ) as `` John took his brushes and began to paint the door '' . Similarly , a generation system should be able to contract commencer ~ life le livre into commencer le livre. We will briefly address here the problem of matching potential paraphrases with a phrase of form commencer + NP. For instance , a sound system should accept to match commencer la porte and commencer peindre la porte ( to paint the door ) , while it should forbid the pairing of commencer le t~l @ hone with commencer ~ ntiliser le t~l @ hone ( to begin to use the telephone ) . Our pairing system will use the type constraints present in the descriptions of the lexical items which allow for coercion interpretation , and supposes that the candidate verbs are already there. A more ambitious system would start from a phrase commencer + NP and retrieve all the candidate verbs ( e.g. the candidate phrase peindre from the phrase commencer la porte ) . Using HPSG-style feature structures , we propose the two following descriptions of commencer with a nominal complement : CAT SUBJ COMP CONT CAT SUBJ COMP CONT commencer1 NP NP OUTP Ie ( z ) ) ~ ) ARG \ [ ~ T 0. RELN ' T ~r ARG2 ARG 1 ' 0.1 ARG 2 ' 0 '' 2 commencer2 v &gt; NP REL I INP OUTP ARG I \ [ ~ T ~x ARG2 12\ [ I '' 0.2 The type of IP is e -- ~ c A o -- * o. The function ~b is ~zC { y : y = ZPCz ) A y = \ [ ~ ) ) In this structure the atomic arguments of relations are typed ( sorted ) .</sentence>
				<definiendum id="0">Des livres sont toujours utiles</definiendum>
				<definiendum id="1">complement</definiendum>
				<definiendum id="2">controller of an event</definiendum>
				<definiendum id="3">NP</definiendum>
				<definiendum id="4">problem</definiendum>
				<definiendum id="5">listening. Reading</definiendum>
				<definiendum id="6">rules</definiendum>
				<definiens id="0">a linear order &lt; p. This gives us a new constraint for AMORPHOUS when P is applied to objects : AMORPHOUS ( P ) =~ Vx ( P ( x ) =¢ , -~3z ' , p ( x ' E A E • x '' % E • x ' _ % Linguistically , the predicate AMORPHOUS is associated with partitive and indefinite plural determiners. It is interesting to note that such NPs have a characteristic property : they may not occur as the subjects of predication s ( 27 ) * Du pain est toujours boa h manger</definiens>
				<definiens id="1">Of the ) books were of great help to me If there is no equivalent operator on verbal predicates , it follows that they can not be amorphous. If additional evidence confirms this line of reasoning , it suggests that , in spite of strong aspectual similarities between verbal and nominal predicates ( e.g. \ [</definiens>
				<definiens id="2">easy to see now why the meaning of commencer requires that the complement be bounded. As a function on events , commencer returns the initial part of its argument ( or is undefined ) : we will associate to commencer the function first_part_of = ~e ( I P ( e ) ) , IP being the initial point of the event e. As a function on objects 4 , first_part_of returns the initial 3see \ [ Galmiche , 1986\ ] on the role of contextual factors. use of commencer as `` be the first part of '' , to which we return in the last section. part of any event which is associated with the object by the interpretive procedure described in section</definiens>
				<definiens id="3">no initial part the procedure fails , even if a plausible event has been found ( e.g. manger for commencer dn fromage ) . For each object x</definiens>
				<definiens id="4">the restrictions of O and T to x and e , are isomorphic. Then ( by basic model theory ) they are elementarily equivalent , and e satisfies AMORPHOUS , which means that e has not initial point and that first_part_of is undefined for e. It follows that commencer can not apply to amorphous predicates</definiens>
				<definiens id="5">an event in which the object denoted by the NP is controlled by the entity denoted by the subject of commencer. This results from two factors : ( i ) the subject of commencer retains the interpretation which it has when the</definiens>
				<definiens id="6">the entity which triggers and causally maintains it ( for a general analysis of control , causality and related notions see \ [ Brennenstuhl , 1982 ; Croft , 1991\ ] ) . When the complement</definiens>
				<definiens id="7">an entity which allows for a controller : nominals denoting psychological states and properties are excluded 5 ( 31 ) * Ace moment Jean a commencd an grand mdpris pour les politicien At that moment John began a great contempt for politicians ( 32 ) * Jean a commencd une honn~tetd remarqnable John has begun a remarkable honesty Second , it is not enough that the subject denote the initiator of the event , who simply triggers it , or the inanimate cause. It must be a full-fledged intentional controller. Thus ( 33 ) is not acceptable , since the referee signals the beginning of a match , even has the power to stop it , but does not control its development 5There is a restricted dass of complements , denoting common diseases as in commencer une grippe , un rhume , with which the subject is not interpreted as a controller. This seems to be a marginal use</definiens>
				<definiens id="8">the cause of the event. ( 35 ) * L 'acide a commencg la destruction du marbre The acid has begun the destruction of the marble Furthermore , it is not enough that the subject be the controller of some process related with the main event. For instance , commencer la conf # rence ( to begin the lecture ) may not be understood as `` to begin to listen to the lecture '' , it means `` to begin to deliver the lecture '' : listening to a lecture is an activity , of which the agent may be said to be the controller , but it does not causally impinge on the process of lecturing itself. It should be noted that these restrictions do NOT characterize commencer when it takes a verbal complement. The subject does not have to be an intentional controller</definiens>
				<definiens id="9">necessary , but not sufficient , to say that the subject is interpreted as the controller of some event in which the object is involved. For instance , the two following interpretations are excluded : ( i ) the interpretation in which the object undergoes a change of position under the action of the controller : commencer la pierre , la voiture ( the stone , car ) may not mean `` to begin to move the stone , to drive the ear '' . Yet , moving an object and driving a car are causal processes , causally controlled by human beings. ( it ) The interpretation in which the subject changes its position along a path denoted by the complement ; in Dowty 's terms</definiens>
				<definiens id="10">a class of objects which seem to raise difficulties. We have considered material objects ; there are also objects which me may call informational , and which occur as complements of commencer. At first sight , their interpretation does not involve a modification. Such are a book , a list , a story , a student 's paper , a magazine , a listing , etc. Consider ( 1 ) again. As noted in \ [ Pustejovsky , 1991\ ] commencer le livre/to begin the book does not only mean `` to begin to write the book '' but also `` to begin to read the book '' , an activity which is not immediately seen as an event of modification of the book. This example contrasts with commencer une symphonic/to begin a symphony which may mean `` to begin to compose/perform a symphony ''</definiens>
				<definiens id="11">a process by which the reader interprets an organized sequence of signs , thus adding to the material object a new informational layer. This layer does not exist independently of the reading operation , which is totally controlled by the reader. On the other hand , listening does not modify the music : nmsical sounds are not signs , they are stimuli , i.e. they provoke reactions but are not systematically associated with information according to some definite set of</definiens>
				<definiens id="12">requirements of computational tasks. Coercion phenomena can raise problems for understanding or generation systems , since they need to interpolate predicates to issue correct interpretations or syntactic forms ( \ [ Gerstl , 1992\ ] ) . An understanding system should be able to interpret a sentence like Jean prit ses pinceauz et commenfa la porte ( John took his paint-brushes and began the door ) as `` John took his brushes and began to paint the door ''</definiens>
				<definiens id="13">paraphrases with a phrase of form commencer + NP. For instance , a sound system should accept to match commencer la porte and commencer peindre la porte ( to paint the door ) , while it should forbid the pairing of commencer le t~l @ hone with commencer ~ ntiliser le t~l @ hone ( to begin to use the telephone ) . Our pairing system will use the type constraints present in the descriptions of the lexical items which allow for coercion interpretation , and supposes that the candidate verbs are already there. A more ambitious system would start from a phrase commencer + NP and retrieve all the candidate verbs ( e.g. the candidate phrase peindre from the phrase commencer la porte ) . Using HPSG-style feature structures</definiens>
				<definiens id="14">commencer with a nominal complement : CAT SUBJ COMP CONT CAT SUBJ COMP CONT commencer1 NP NP OUTP Ie ( z ) ) ~ ) ARG \ [ ~ T 0. RELN ' T ~r ARG2 ARG 1 ' 0.1 ARG 2 ' 0 '' 2 commencer2 v &gt; NP REL I INP OUTP ARG I \ [ ~ T ~x ARG2 12\ [ I '' 0.2 The type of IP is e -- ~ c A o -- * o. The function ~b is ~zC { y : y = ZPCz ) A y = \ [ ~</definiens>
			</definition>
			<definition id="1">
				<sentence>pattern h ~1 = animate , ~2 = e A bounded , ~ = execute pattern 2 : ~1 = animate , ~2 = material A bounded , = modify A intentional pattern 3 : ~1 = human , el2 = info A sequential A bounded , a = signprocess pattern 4 : ~1 = oVe , a2 = alAsequentialAbounded , = positional A part_of The type hierarchy is as follows ( T denotes the top of the lattice ) : T &gt; o , e , property o &gt; material , info , animate animate &gt; _ human e &gt; _ control control &gt; _ execute , modify modify &gt; _ produce , internal_change , sign_process property &gt; _ amorphous , positional , sequential , part_of , intentional The hierarchy obeys the constraint - , ( e A o ) = - .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the top of the lattice ) : T &gt; o , e , property o &gt; material , info , animate animate &gt; _ human e &gt; _ control control &gt; _ execute , modify modify &gt; _ produce</definiens>
			</definition>
			<definition id="2">
				<sentence>The input to the procedure is a pair ( H1 , H2 ) where H1 is the value of ARG2 in commencerl and H2 is a \ [ RELN uTa3 \ ] structure of form : ARG 1 u ' T a4 ARC2 u '' T as corresponding to the semantic part of a full lexical description for a a verb .</sentence>
				<definiendum id="0">H1</definiendum>
				<definiendum id="1">H2</definiendum>
				<definiens id="0">the value of ARG2 in commencerl</definiens>
			</definition>
			<definition id="3">
				<sentence>A temptative list for commencer is : Verbs = ( consommer , ranger , construire , ddtruire , rdparer , life , interpr6ter , exdcuter , crder ) Nouns = ( nourriture , boisson , texte , lieu , appareil , b~timent , veuvre , matidre ) Starting from a pair ( commencer + NP , V ) we may obtain a first rough diagnosis by searching the Verbs and Nouns lists for NP and V , or hyperonyms of them , as indicated in dictionaries like \ [ du Chazaud , 1989 ; Delas and Demon , 1989\ ] .</sentence>
				<definiendum id="0">temptative list for commencer</definiendum>
				<definiens id="0">Verbs = ( consommer , ranger , construire , ddtruire , rdparer , life , interpr6ter , exdcuter</definiens>
				<definiens id="1">Nouns lists for NP and V , or hyperonyms of them , as indicated in dictionaries like \ [ du Chazaud</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>Grapheme-to-phoneme conversion is a central task in any text-to-speech ( reading aloud ) system .</sentence>
				<definiendum id="0">Grapheme-to-phoneme conversion</definiendum>
			</definition>
			<definition id="1">
				<sentence>In cases where phonemes correspond to grapheme clusters ( i.e. there is an alignment problem of grapheme strings with their corresponding phoneme strings ) , as is the case in , e.g. , &lt; schoenen &gt; ( shoes ) /sXuno/ , one grapheme of that cluster is algorithmically mapped to the phoneme , and the remaining graphemes are mapped to phonetic nulls , represented by hyphens .</sentence>
				<definiendum id="0">grapheme clusters</definiendum>
				<definiens id="0">an alignment problem of grapheme strings with their corresponding phoneme strings</definiens>
				<definiens id="1">the case in , e.g. , &lt; schoenen &gt; ( shoes ) /sXuno/ , one grapheme of that cluster is algorithmically mapped to the phoneme</definiens>
			</definition>
			<definition id="2">
				<sentence>IBL is a framework and methodology for incremental supervised machine learning .</sentence>
				<definiendum id="0">IBL</definiendum>
			</definition>
			<definition id="3">
				<sentence>The distinguishing feature of IBL is the fact that no explicit abstractions are constructed on the basis of the training examples during the training phase .</sentence>
				<definiendum id="0">distinguishing feature of IBL</definiendum>
			</definition>
			<definition id="4">
				<sentence>In learning linguistic mappings ( a noisy domain ) , learning in IBL often is helped by forgetting poorly performing or unrepresentative training items .</sentence>
				<definiendum id="0">linguistic mappings</definiendum>
			</definition>
			<definition id="5">
				<sentence>When using a Euclidean distance metric ( geometrical distance between two patterns in pattern space ) , all features are interpreted as being equally important .</sentence>
				<definiendum id="0">Euclidean distance metric</definiendum>
				<definiens id="0">geometrical distance between two patterns in pattern space</definiens>
			</definition>
			<definition id="6">
				<sentence>The test file consists of 1,971 words from various sources : newspaper text , compounds , and lowfrequency words .</sentence>
				<definiendum id="0">test file</definiendum>
				<definiens id="0">consists of 1,971 words from various sources : newspaper text , compounds , and lowfrequency words</definiens>
			</definition>
			<definition id="7">
				<sentence>As mentioned earlier , Instance-Based Learning is a form of case-based reasoning : a set of exemplars ( cases ) and a similarity metric are used to make decisions about unseen cases .</sentence>
				<definiendum id="0">Instance-Based Learning</definiendum>
				<definiens id="0">a form of case-based reasoning : a set of exemplars ( cases ) and a similarity metric are used to make decisions about unseen cases</definiens>
			</definition>
			<definition id="8">
				<sentence>Earlier work on the application of Memory-Based Reasoning ( \ [ Stanfill and Waltz , 1986 ; Stanfill , 1987\ ] ) ( another form of casebased reasoning ) to the phonemisation problem using the NetTalk data ( MBRTalk ) , showed a better performance than NetTalk itself ( \ [ Sejnowski and Rosenberg , 1987\ ] ) , however at the cost of an expensive , domain-dependent computational measure of dissimilarity that seems to be computationally feasible only when working on a massive parallel computer like the Connection Machine .</sentence>
				<definiendum id="0">Memory-Based Reasoning</definiendum>
				<definiendum id="1">MBRTalk</definiendum>
				<definiens id="0">an expensive , domain-dependent computational measure of dissimilarity that seems to be computationally feasible only when working on a massive parallel computer like the Connection Machine</definiens>
			</definition>
</paper>

		<paper id="1062">
</paper>

		<paper id="1037">
			<definition id="0">
				<sentence>A discourse segment is defined as a set of sentences which appear in some region of text and which is delimited by a topic-particle wa .</sentence>
				<definiendum id="0">discourse segment</definiendum>
				<definiens id="0">a set of sentences which appear in some region of text and which is delimited by a topic-particle wa</definiens>
			</definition>
			<definition id="1">
				<sentence>c+ denotes one or more occurrences of clause , C* zero or more occurrences of clause , and N ( pp : wa ) denotes a wa-marked nominal ; pp : wa specifies that the attribute pp ( for postposition ) has wa for the value.3Let us define discourse segment by : 2 \ [ Hobbs , to appear\ ] talks about the cognitive economy in understanding discourse : it says in effect that coherence is the result of minimizing the number of entities in discourse .</sentence>
				<definiendum id="0">N ( pp</definiendum>
				<definiens id="0">one or more occurrences of clause , C* zero or more occurrences of clause</definiens>
				<definiens id="1">a wa-marked nominal ; pp : wa specifies that the attribute pp ( for postposition ) has wa for the value.3Let us define discourse segment by : 2 \ [ Hobbs , to appear\ ] talks about the cognitive economy in understanding discourse : it says in effect that coherence is the result of minimizing the number of entities in discourse</definiens>
			</definition>
			<definition id="2">
				<sentence>The rule set 6 enforces unification between the head value and the morph value , morph represents the morphology of the nominal ; thus morph : taro specifies that the associated nominal has the morphology `` taro '' .</sentence>
				<definiendum id="0">morph</definiendum>
				<definiens id="0">the morphology of the nominal</definiens>
			</definition>
			<definition id="3">
				<sentence>Here are the facts : ( a ) zero anaphora occurring within the quotation ( internal anaphora ) are coreferential either with Taro or with Masako ; ( b ) those occurring outside ( external anaphora ) , however , all refer to chichioya ; ( c ) chichioya has an anaphoric link which crosses over the entire quotation ; ( d ) syntactically , the quoted portion functions as a complement for the verb -to itta .</sentence>
				<definiendum id="0">c ) chichioya</definiendum>
				<definiens id="0">a ) zero anaphora occurring within the quotation ( internal anaphora ) are coreferential either with Taro or with Masako ; ( b ) those occurring outside ( external anaphora )</definiens>
				<definiens id="1">has an anaphoric link which crosses over the entire quotation ; ( d ) syntactically , the quoted portion functions as a complement for the verb -to itta</definiens>
			</definition>
			<definition id="4">
				<sentence>The literature suggest that in the written language , texts , i.e. , cohesive discourses , are marked through a variety of linguistic and nonlinguistic means : non-alphanumeric characters ( quotation marks , brackets , parentheses ) , graphic devices t indentation , tabulation , itemization ) , and so on Nunberg , 1990 ; Halliday and I-Iassan , 1990\ ] .</sentence>
				<definiendum id="0">cohesive discourses</definiendum>
				<definiens id="0">non-alphanumeric characters ( quotation marks , brackets , parentheses ) , graphic devices t indentation , tabulation , itemization )</definiens>
			</definition>
</paper>

		<paper id="1070">
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>2 ) Let us assume the property true for ~ which links y , -B , z and for ct which links x and +A. -B , as a unit , is an alternating negative tree and +A is an alternating positive tree .</sentence>
				<definiendum id="0">+A</definiendum>
				<definiens id="0">the property true for ~ which links y , -B , z and for ct which links x</definiens>
			</definition>
			<definition id="1">
				<sentence>a rules : \ [ L/q : if x -- - &gt; A translates into 13 and y B z -- &gt; C translates into y , y B/A x z translates into l\ ] ~r y \ [ L\\ ] : y x AkB z translates into 13 @ 1 7 \ [ R/\ ] : translates into tr ( a ) where ~ is the translation ofA x -- - &gt; B \ [ R\\ ] : translates into tl ( cx ) .0 Remark : this translation is not a one-to-one mapping , because several deductions can be translated into the same connection graph .</sentence>
				<definiendum id="0">Remark</definiendum>
				<definiens id="0">if x -- - &gt; A translates into 13 and y B z -- &gt; C translates into y</definiens>
			</definition>
			<definition id="2">
				<sentence>In the second case , when removing it , we get two connection graphs ct and \ [ 3 which correspond , by induction hypothesis , respectively to x -- - &gt; A and y B z -- - &gt; C. Definition 5 : given a connection graph G , we call interval every set of integers \ [ i , j\ ] ( ie : { x ; i &lt; x &lt; j } such that i and j are indices associated with ending points of an external link ( and i &lt; j ) . Two intervals \ [ i , j\ ] and \ [ i ' , j'\ ] do not overlap if and only if : • \ [ i , j\ ] n \ [ i ' , j'\ ] = gl or • \ [ i , j\ ] D \ [ i ' , jq and i ~ i ' and j ~ : j ' or • \ [ i ' , j'\ ] D \ [ i , j\ ] and i ¢ i ' and j ¢ j ' Given a family I of intervals , we say that it satisfies the Non Overlapping Condition ( NOC ) if it does not contain any pair of intervals which overlap. Theorem 1 : in a well numbered connection graph G , the family of intervals associated with all the external links satisfies NOC. Proof : easy , by induction. &lt; ) Theorem 2 : in a connection graph G , the positive root is connected by an external link either to a negative vertex in the same tree ( just below it ) or to a negative root. external links and type 2 links Theorem 3 : Let G be a connection graph. Let L1 be the set of its type 1 links. G-L1 is connected and acyclic ( it is a tree ) . Proof : a type 2 link connects two connection graphs for the first time they meet and a type 1 link does neither connect two graphs , nor modify the topology of type 2 links and external links. 0 Theorem 4 : for every i in a connection graph G , let ( ~ ( i ) be the node linked to i by an external link , ~ is a one-to-one mapping from S onto S. Proof : trivial by induction. 0 2-11 Strong connectivity Definition 6 : given a graph G , a spanning tree of G is defined as a tree on the complete set of nodes of G. A tree is said to be alternating on L2 u E , if each of its paths from the root to a leaf is alternatively composed by L2-edges and E-edges. Theorem 5 : every connection graph G admits an alternating spanning tree with the positive root of G as the root. Proof'. • true for any axiom , • Let us assume it is true for tx and 7. Then by ( la ) and fro ) : • by induction hypothesis , there is a path from the root of +C to the root of -B which is alternating. Since it arrives at a negative vertex , its last link can not be of type 2 , then it is an external link. • There is also a path from the root of +A to any leaf of the spanning tree of ix , which is alternating. Since it comes from a positive vertex , it can not begin with a type 2 link , hence it begins with an extrernal link. Thus , by inserting a type 2 link between the external link arriving at -B and the external link starting from +A , we get a path starting from the positive root of +C and arriving at any leaf of ct , inserted into 7 , which is alternating. Therefore , there is an alternating path from the positive root of +C to any leaf of ct0 ) 7. Let us assume now it is true for ct which links -A , x and +B. The transformation t r or t I does not modify the set of paths starting from the positive root of +B. 0 Definition 7 : a node in a connection graph G will be said strongly connected to another node in the same graph if they are connected by an alternating path. Definition 8 : a link will be said to be strong if its two ends are srongly connected. Theorem 6 : in a connection graph G , every type 1 link is strong. Proof : this is shown when installing a new type 1 link. Such an installation does not modify the topology of G-L1. The previous graph ( before applying t 1 or t r ) was necessarily a connection graph. Thus by Theorem 5 , it was scanned by an alternating spanning nee with as root the positive root of the graph. This tree is preserved by t I or t r , it contained an alternating path connecting the two vertices which are now linked by a type 1 link. 0 As a matter of recapitulation , we enumerate now the following properties , satisfied by any connection graph. • one-to-one mapping by external links ( CG0 ) • positive root property + uniqueness of the positive root ( CG1 ) • non-overlapping condition ( CG2 ) • strong connectivity ( CG3 ) • connectivity and acyclicity on L2 u E ( CG4 ) • alternating spanning tree ( CGS ) • G-E is a set of well numbered alternating trees ( CG6 ) Proposition 6 : CG5is a consequence of CG0 , CG1 , CG3 , CG4. 272 Proof : By CG4 , G-L1 is a tree on S , it is therefore a spanning tree of G. Let us consider a path ~ from the positive root +b ( which is the root of the positive tree +B , and which is unique according to CG1 ) to a leaf a. We must notice that a can not be positive , because if it was , it would necessarily be an end of a type 2 link and this type 2 link would be the last edge on the path a , but by CG0 , it would be linked by an external link to another node and thus it would not be a leaf. Thus , a is necessarily negative , and we can write -a instead of a. If -a is isolated ( as a negative root of a negative tree ) , we can remove the last external link and the type 2 link before the last , we are led to the same problem : a path c ' arriving at a negative leaf , but or ' is shorter than ~. If -a is not isolated , it is necessarily the end of a type 1 link , but by CG3 , there is an alternating path joining -a and the positive node +c which is the other end. Removing this path and the type 2 link arriving at +c , we still get the same problem of a path c ' arriving at a negative node , but again a ' is shorter than g. We can proceed like that until we have a mere external link between the positive root +b and a vertex -b. In this case , the path is obviously alternate. Definition 9 : Let -A1 , -A2 ... .. -An , +B a sequence of alternating trees on the set S of signed vertices. We call Well Linked Graph on \ [ -A1 , -A2 ... .. -An , +B\ ] the result of adding external links in order that CG0 , CG1 , CG2 , CG3 , CG4 are satisfied. Proposition 7 : every connection graph is a well linked graph. Proof : obvious according to the previous §.0 Theorem 7 : every well linked graph is a connection graph. ( ie : every well linked graph could be obtained by the inductive construction of a connection graph , with the sequence of alternating trees as G-E ) . Proof : given a WLG on I-A1 , -A2 ... .. -An , +B\ ] , it has a unique positive root +b ( the root of +B ) . Thus it satisfies the property of uniqueness of the positive root. Let us assume there is a type 1 link from +b , then let us remove : • if it is left-oriented : the leftmost one • if it is right-oriented : the rightmost one. Let us assume for instance that it is left-oriented : • The tree below this link may be moved towards the left end of the sequence of trees by the inverse of the construction rule ( IIa ) . This move preserves the topological structure of EuL2 , therefore , CG1 , CG3 and CG4 are preserved. This move implies a renumbering but it does not destroy the non-overlapping property. Thus CG2 is preserved. CG0 is trivially preserved. The argument is similar for a right-oriented link. Thus after this removal , we keep a WLG. Let us assume now there is no type 1 link from +b. Then there is an external link which links +b to a vertex -b situated among the negative trees. If -b is not related to another node , we get an elementary WLG : -b ... . +b , which is obviously a connection graph. If -b is related to another node , then by CG5 , either -b is a leaf , or it is the starting point of a type 2 link. Let us assume -b is a leaf ( of a non atomic tree ) , then -b is linked by a type 1 link to a vertex +a ( and not to +b since we have assumed there is no longer type 1 link from +b ) . Because of CG3 , -b and +a are connected by an alternating path on EuL2 , thus -b is necessarily the starting point of a type 2 link , but in this case , -b is not a leaf. Therefore -b is not a leaf and it is the starting point of a type 2 link. Let +c the other end of this link. • Let us assume that this link is left-oriented : we remove the leftmost one if many. In this case , the scanning tree is broken into two parts and the connection graph is also separated into two pieces. One contains +b , the other contains +c. Let us consider the first one : • it keeps CG3 and CG4 : for example CG3 : let us consider a type 1 link situated in this part. It does not come from +b since we have assumed there is no longer type 1 link from +b. its ends are linked by an alternating path. Let us assume that the removed type 2 link belonged to this path. By removing it , we get either a single external link : -b ... ... +b , but such a piece does not contain any type 1 link , or another kind of graph. If we want this graph has a type 1 link , it necessarily must contain another type 2 link starting from -b , and arriving , say , at +d , But an alternating path between two ends of a type 1 link can neither arrive by an external link at -b since -b is already connected by such a link to the positive root +b ( and we have assumed there is no type 1 link attached to +b ) , nor pass through +d since , in this case , the path would have two consecutive type 2 links , which contradicts the definition of an alternating path. Therefore , the removed type 2 link can not be on the alternating path linking the ends of a type 1 link in this part of the graph. Finally , no alternating path in the first component is destroyed by this removal , among all the alternating paths connecting ends of type 1 links. Let us consider the second one : let us consider a type 1 link situated in this part and let us assume that its ends are linked by an alternating path passing through the removed type 2 link. The proof is the same as previously : the path can neither arrive at -b by an external link nor by a type 2 link. Moreover , it has one and only one positive root +c , because it does not contain +b , and +c is necessarily linked by an external link to either a negative root or a negative vertex just below it ( if not , there would be a type 1 link +x -- c , with -c externally linked to +c , the alternating path from -c to +x would thus necessarily pass through +c and -b , which is impossible according to the first part of the proof ) . 273 When all the type 2 links attached to -b are removed , there remains only the external link -b ... . +b which is a WLG , and we can perform this decomposition for each part resulting from a previous step. It would then be possible to reconstruct the graph accordint to the induction schemes ( I ) and ( II ) , starting only from axioms. Corollary : well linked graphs are sound and complete with respect to the calculus A. linked graph An alternating tree was defined by a set of signed vertices and a set of typed links which link them. We are now adding two new kinds of entity in order to facilitate tree-encoding. Let us assign to each vertex in a sequence of trees \ [ -A1 , -A2 ... .. -An , +B\ ] a colour ( originally unknown and represented by a free variable X ) in order that : a ) two nodes linked by a type 2 link have same colours b ) two nodes which are not linked or which are linked by a type-1 link have not the same colours ( X ~ Y ) . Proposition 8 : for every connection graph G with set of type 1 links L1 , the connectivity and acyclicity of G -L1 translates into : every external link links two nodes having differents colours. After linking by an external link , the two colours are equalized ( X = Y ) . Anticolours are assigned to nodes in an alternating tree in order that : a ) two nodes linked by a type 1 link have same anticolour , b ) if a positive node receives an anticolour a , ( by ( a ) or by an external link ) , the negated anticolour 9ct is transmitted to all other positive nodes having same colour. Rule : 1 ) When joining two nodes by an external link , which are associated with different ( positive ) anticolours tx and 13 , ¢t and ~ are said to be equalized , that means : put in a same multi-set. 2 ) When joining a node having a negated anticolour 913 to a node having a colour X by an external link , the anticolour -- ,13 is transmitted to the colour X as a label. 3 ) When linking two ends of a type 1 link by external links , the two occurrences of the same ( positive ) anticolour tx must meet only one colour , or two colours which have been already equalized and such that one of the two is not labelled by a negated anticolour 913 if 13 is an anticolour already equalized to ix. Proposition 9 : in a connection graph G , the strong connectivity translates into : the anticolour proper to a type 1 link meets only one colour ( or colours which have been equalized ) . Corollary : Every connection graph verifies : CGO , CGI , CG2 , CG3 ' , CG4 ' , CG5 ' , CG6 where : CG3 ' is the condition on unifying anti-colours , CG4 ' the conditions on colours , CG5 ' the fact that any connection graph is monocoloured. Definition 9 : We call a category any set of 6-tuples each consisting in : • a label taken from an alphabet A , • a sign ( + or - ) • an index ( integer ) , • a colour ( free variable ) • an anticolour ( free variable of a second sort ) • the indication of being a root if it is the case. Definition 10 : We call an ordered category a category where 6-tuples are ordered according to their index. Proposition 10 : each alternating tree has one and only one encoding into an ordered category. Examples : -a ( l~-b s s s o_d translates into : { &lt; + , b , I , X , U , _ &gt; , &lt; - , d,2 , Y , U , _ &gt; , &lt; + , c,3 , X , ~U , &gt; , &lt; - , a,4 , X , _ , r &gt; } -- a ( ~b ( ~c translates into : { &lt; + , b , I , X , gU , _ &gt; , &lt; - , d,2 , Y , U , &gt; , &lt; + , c,3 , X , U , _ &gt; , &lt; - , a,4 , X , _ , r &gt; } Definition 11 : two 6-tuples are said to be mergeable if : • they have same literal label , • they have opposite signs , • they have different colours , • if one of them has an anticolour ~ , the other must not have a colour which has been labelled by a negated anticolour -- ,13 such that ~ and 13 have already been equalized , in a same multiset .</sentence>
				<definiendum id="0">-b</definiendum>
				<definiendum id="1">CG4</definiendum>
				<definiens id="0">correspond , by induction hypothesis , respectively to x -- - &gt; A and y B z -- - &gt; C. Definition 5 : given a connection graph G , we call interval every set of integers \ [ i , j\ ] ( ie : { x ; i &lt; x &lt; j } such that i and j are indices associated with ending points of an external link ( and i &lt; j ) . Two intervals \ [ i , j\ ] and \ [ i ' , j'\ ] do not overlap if and only if : • \ [ i , j\ ] n \ [ i ' , j'\ ] = gl or • \ [ i , j\ ] D \ [ i ' , jq and i ~ i ' and j ~ : j ' or • \ [ i ' , j'\ ] D \ [ i , j\ ] and i ¢ i ' and j ¢ j ' Given a family I of intervals , we say that it satisfies the Non Overlapping Condition ( NOC ) if it does not contain any pair of intervals which overlap. Theorem 1 : in a well numbered connection graph G , the family of intervals associated with all the external links satisfies NOC. Proof : easy , by induction. &lt; ) Theorem 2 : in a connection graph G , the positive root is connected by an external link either to a negative vertex in the same tree ( just below it ) or to a negative root. external links and type 2 links Theorem 3 : Let G be a connection graph. Let L1 be the set of its type 1 links. G-L1 is connected and acyclic ( it is a tree ) . Proof : a type 2 link connects two connection graphs for the first time they meet and a type 1 link does neither connect two graphs , nor modify the topology of type 2 links and external links. 0 Theorem 4 : for every i in a connection graph G , let ( ~ ( i ) be the node linked to i by an external link , ~ is a one-to-one mapping from S onto S. Proof : trivial by induction. 0 2-11 Strong connectivity Definition 6 : given a graph G , a spanning tree of G is defined as a tree on the complete set of nodes of G. A tree is said to be alternating on L2 u E , if each of its paths from the root to a leaf is alternatively composed by L2-edges and E-edges. Theorem 5 : every connection graph G admits an alternating spanning tree with the positive root of G as the root. Proof'. • true for any axiom , • Let us assume it is true for tx and 7. Then by ( la ) and fro ) : • by induction hypothesis , there is a path from the root of +C to the root of -B which is alternating. Since it arrives at a negative vertex</definiens>
				<definiens id="1">an external link. • There is also a path from the root of +A to any leaf of the spanning tree of ix , which is alternating. Since it comes from a positive vertex , it can not begin with a type 2 link , hence it begins with an extrernal link. Thus , by inserting a type 2 link between the external link arriving at -B and the external link starting from +A , we get a path starting from the positive root of +C and arriving at any leaf of ct , inserted into 7 , which is alternating. Therefore , there is an alternating path from the positive root of +C to any leaf of ct0 ) 7. Let us assume now it is true for ct which links -A , x and +B. The transformation t r or t I does not modify the set of paths starting from the positive root of +B. 0 Definition 7 : a node in a connection graph G will be said strongly connected to another node in the same graph if they are connected by an alternating path. Definition 8 : a link will be said to be strong if its two ends are srongly connected. Theorem 6 : in a connection graph G , every type 1 link is strong. Proof : this is shown when installing a new type 1 link. Such an installation does not modify the topology of G-L1. The previous graph ( before applying t 1 or t r ) was necessarily a connection graph. Thus by Theorem 5 , it was scanned by an alternating spanning nee with as root the positive root of the graph. This tree is preserved by t I or t r , it contained an alternating path connecting the two vertices which are now linked by a type 1 link. 0 As a matter of recapitulation , we enumerate now the following properties , satisfied by any connection graph. • one-to-one mapping by external links ( CG0 ) • positive root property + uniqueness of the positive root ( CG1 ) • non-overlapping condition ( CG2 ) • strong connectivity ( CG3 ) • connectivity and acyclicity on L2 u E ( CG4 ) • alternating spanning tree ( CGS ) • G-E is a set of well numbered alternating trees ( CG6 ) Proposition 6 : CG5is a consequence of CG0 , CG1 , CG3 , CG4. 272 Proof : By CG4 , G-L1 is a tree on S , it is therefore a spanning tree of G. Let us consider a path ~ from the positive root +b ( which is the root of the positive tree +B , and which is unique according to CG1 ) to a leaf a. We must notice that a can not be positive</definiens>
				<definiens id="2">the last edge on the path a , but by CG0 , it would be linked by an external link to another node and thus it would not be a leaf. Thus , a is necessarily negative , and we can write -a instead of a. If -a is isolated ( as a negative root of a negative tree</definiens>
				<definiens id="3">a path c ' arriving at a negative leaf , but or ' is shorter than ~. If -a is not isolated</definiens>
				<definiens id="4">the same problem of a path c ' arriving at a negative node , but again a ' is shorter than g. We can proceed like that until we have a mere external link between the positive root +b and a vertex -b. In this case , the path is obviously alternate. Definition 9 : Let -A1 , -A2 ... .. -An , +B a sequence of alternating trees on the set S of signed vertices. We call Well Linked Graph on \ [ -A1 , -A2 ... .. -An , +B\ ] the result of adding external links in order that CG0 , CG1 , CG2 , CG3 , CG4 are satisfied. Proposition 7 : every connection graph is a well linked graph. Proof : obvious according to the previous §.0 Theorem 7 : every well linked graph is a connection graph. ( ie : every well linked graph could be obtained by the inductive construction of a connection graph , with the sequence of alternating trees as G-E ) . Proof : given a WLG on I-A1 , -A2 ... .. -An , +B\ ] , it has a unique positive root +b ( the root of +B ) . Thus it satisfies the property of uniqueness of the positive root. Let us assume there is a type 1 link from +b , then let us remove : • if it is left-oriented : the leftmost one • if it is right-oriented : the rightmost one. Let us assume for instance that it is left-oriented : • The tree below this link may be moved towards the left end of the sequence of trees by the inverse of the construction rule ( IIa ) . This move preserves the topological structure of EuL2 , therefore , CG1 , CG3 and CG4 are preserved. This move implies a renumbering but it does not destroy the non-overlapping property. Thus CG2 is preserved. CG0 is trivially preserved. The argument is similar for a right-oriented link. Thus after this removal</definiens>
				<definiens id="5">an external link which links +b to a vertex -b situated among the negative trees. If -b is not related to another node</definiens>
				<definiens id="6">a leaf ( of a non atomic tree ) , then -b is linked by a type 1 link to a vertex +a</definiens>
				<definiens id="7">at +d , But an alternating path between two ends of a type 1 link can neither arrive by an external link at -b since -b is already connected by such a link to the positive root +b</definiens>
				<definiens id="8">contradicts the definition of an alternating path. Therefore , the removed type 2 link can not be on the alternating path linking the ends of a type 1 link in this part of the graph. Finally , no alternating path in the first component is destroyed by this removal , among all the alternating paths connecting ends of type 1 links. Let us consider the second one : let us consider a type 1 link situated in this part and let us assume that its ends are linked by an alternating path passing through the removed type</definiens>
				<definiens id="9">the same as previously : the path can neither arrive at -b by an external link nor by a type 2 link. Moreover , it has one and only one positive root +c , because it does not contain +b , and +c is necessarily linked by an external link to either a negative root or a negative vertex just below it ( if not , there would be a type 1 link +x -- c , with -c externally linked to +c , the alternating path from -c to +x would thus necessarily pass through +c and -b , which is impossible according to the first part of the proof ) . 273 When all the type 2 links attached to -b are removed , there remains only the external link -b ... . +b which is a WLG , and we can perform this decomposition for each part resulting from a previous step. It would then be possible to reconstruct the graph accordint to the induction schemes ( I ) and ( II ) , starting only from axioms. Corollary : well linked graphs are sound and complete with respect to the calculus A. linked graph An alternating tree was defined by a set of signed vertices and a set of typed links which link them. We are now adding two new kinds of entity in order to facilitate tree-encoding. Let us assign to each vertex in a sequence of trees \ [ -A1 , -A2 ... .. -An , +B\ ] a colour ( originally unknown and represented by a free variable X ) in order that : a ) two nodes linked by a type 2 link have same colours b ) two nodes which are not linked or which are linked by a type-1 link have not the same colours</definiens>
				<definiens id="10">for every connection graph G with set of type 1 links L1 , the connectivity and acyclicity of G -L1 translates into : every external link links two nodes having differents colours. After linking by an external link , the two colours are equalized ( X = Y ) . Anticolours are assigned to nodes in an alternating tree in order that : a ) two nodes linked by a type 1 link have same anticolour , b ) if a positive node receives an anticolour a , ( by ( a ) or by an external link ) , the negated anticolour 9ct is transmitted to all other positive nodes having same colour. Rule : 1 ) When joining two nodes by an external link , which are associated with different ( positive ) anticolours tx and 13 , ¢t and ~ are said to be equalized , that means : put in a same multi-set. 2 ) When joining a node having a negated anticolour 913 to a node having a colour X by an external link , the anticolour -- ,13 is transmitted to the colour X as a label. 3 ) When linking two ends of a type 1 link by external links , the two occurrences of the same ( positive ) anticolour tx must meet only one colour , or two colours which have been already equalized and such that one of the two is not labelled by a negated anticolour 913 if 13 is an anticolour already equalized to ix. Proposition 9 : in a connection graph G , the strong connectivity translates into : the anticolour proper to a type 1 link meets only one colour ( or colours which have been equalized ) . Corollary : Every connection graph verifies : CGO , CGI , CG2 , CG3 ' , CG4 ' , CG5 ' , CG6 where : CG3 ' is the condition on unifying anti-colours , CG4 ' the conditions on colours , CG5 ' the fact that any connection graph is monocoloured. Definition 9 : We call a category any set of 6-tuples each consisting in : • a label taken from an alphabet A , • a sign ( + or - ) • an index ( integer ) , • a colour ( free variable ) • an anticolour ( free variable of a second sort ) • the indication of being a root if it is the case. Definition 10 : We call an ordered category a category where 6-tuples are ordered according to their index. Proposition 10 : each alternating tree has one and only one encoding into an ordered category. Examples : -a ( l~-b s s s o_d translates into : { &lt; + , b , I , X , U , _ &gt; , &lt; - , d,2 , Y , U , _ &gt; , &lt; + , c,3 , X , ~U , &gt; , &lt; - , a,4 , X , _ , r &gt; } -- a ( ~b ( ~c translates into : { &lt; + , b , I , X , gU , _ &gt; , &lt; - , d,2 , Y , U , &gt; , &lt; + , c,3 , X , U , _ &gt; , &lt; - , a,4 , X , _ , r &gt; } Definition 11 : two 6-tuples are said to be mergeable if : • they have same literal label , • they have opposite signs , • they have different colours , • if one of them has an anticolour ~ , the other must not have a colour which has been labelled by a negated anticolour -- ,13 such that ~ and 13 have already been equalized , in a same multiset</definiens>
			</definition>
			<definition id="3">
				<sentence>Each link is a node of the chart ( in consequence , the chart has no more than n 2 nodes , where n is the number of nodes on the reading tape R ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a node of the chart ( in consequence , the chart has no more than n 2 nodes</definiens>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>DICE permits us to model the interactions between linguistic knowledge ( LK ) and WK which lead to the assignment of discourse coherence relations between propositions introduced by text segments , and temporal-causal relations between the eventualities they denote .</sentence>
				<definiendum id="0">DICE</definiendum>
				<definiens id="0">permits us to model the interactions between linguistic knowledge ( LK ) and WK which lead to the assignment of discourse coherence relations between propositions introduced by text segments , and temporal-causal relations between the eventualities they denote</definiens>
			</definition>
			<definition id="1">
				<sentence>We will therefore suggest that the primary proposal , where accommodation involves discourse attachment , must leave room for the possibility that presupposed eventualities can be directly added to a discourse context , without any discourse relations being involved .</sentence>
				<definiendum id="0">accommodation</definiendum>
				<definiens id="0">a discourse context , without any discourse relations being involved</definiens>
			</definition>
			<definition id="2">
				<sentence>Accommodation is achieved through adding the presuppositional material to part of the discourse context ; this process is subject to certain informal heuristic constraints .</sentence>
				<definiendum id="0">Accommodation</definiendum>
				<definiens id="0">subject to certain informal heuristic constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>DICE is a logical theory of discourse attachment , which explains how to infer which discourse relation to use .</sentence>
				<definiendum id="0">DICE</definiendum>
				<definiens id="0">a logical theory of discourse attachment , which explains how to infer which discourse relation to use</definiens>
			</definition>
			<definition id="4">
				<sentence>But the Revolt Law entails the opposite .</sentence>
				<definiendum id="0">Revolt Law</definiendum>
				<definiens id="0">entails the opposite</definiens>
			</definition>
			<definition id="5">
				<sentence>On the other hand , even when accommodation by discourse attachment succeeds , there is no guarantee that the text is coherent ; presupposition accommodation is a necessary , but insufficient , part of the process of discourse structure retreival .</sentence>
				<definiendum id="0">presupposition accommodation</definiendum>
				<definiens id="0">a necessary , but insufficient , part of the process of discourse structure retreival</definiens>
			</definition>
</paper>

		<paper id="1057">
			<definition id="0">
				<sentence>Xuxen is a spelling checker/corrector for Basque which is going to be comercialized next year .</sentence>
				<definiendum id="0">Xuxen</definiendum>
				<definiens id="0">a spelling checker/corrector for Basque which is going to be comercialized next year</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>As regards the source formalisms we have attempted migrations of descriptions in HPSG ( which uses fullytyped feature structures and has a strong 'non-derivational ' flavour ) , ETS ( an untyped stratificational formalism which essentially uses rewrite rules for feature structures and has run-time non-monotonic devices ) and LFG ( which is an un-typed constraint and CF-PSG based formalism with extensions such as existential , negative and global well-formedness constraints ) .</sentence>
				<definiendum id="0">ETS (</definiendum>
				<definiendum id="1">LFG</definiendum>
				<definiens id="0">an untyped stratificational formalism which essentially uses rewrite rules for feature structures and has run-time non-monotonic devices</definiens>
			</definition>
			<definition id="1">
				<sentence>2 As regards the 'style ' and expressivity of source formalisms , we have carried out migrations from HPSG , which uses fully-typed feature structures and a variety of richly expressive devices , from ETS grammars and lexicons 3 ( ETS is an untyped stratificational formalism essentially using rewrite rules for feature structures ) , and from an LFG grammar 4 ( LFG is a standard untyped AVS formalism with some extensions , with a CFG backbone ) .</sentence>
				<definiendum id="0">ETS</definiendum>
				<definiendum id="1">LFG</definiendum>
				<definiens id="0">uses fully-typed feature structures and a variety of richly expressive devices</definiens>
			</definition>
			<definition id="2">
				<sentence>ALEP is CF-PSG rule based and supports feature structures which are typed and simple inheritance between types .</sentence>
				<definiendum id="0">ALEP</definiendum>
				<definiens id="0">CF-PSG rule based and supports feature structures which are typed and simple inheritance between types</definiens>
			</definition>
			<definition id="3">
				<sentence>Complex structured types and simple inheritance relations are defined by the user in a type system specification .</sentence>
				<definiendum id="0">Complex</definiendum>
				<definiens id="0">structured types and simple inheritance relations are defined by the user in a type system specification</definiens>
			</definition>
			<definition id="4">
				<sentence>LFG is an untyped constraint-based linguistic forrealism with rich expressive devices built around a CFG backbone .</sentence>
				<definiendum id="0">LFG</definiendum>
			</definition>
</paper>

		<paper id="1063">
			<definition id="0">
				<sentence>Examples of the collocational structures we have in mind are strong criticism ( as an adjective-noun combination ) and give a demonstration ( as a verb-noun combination ) .</sentence>
				<definiendum id="0">strong criticism</definiendum>
				<definiens id="0">an adjective-noun combination ) and give a demonstration ( as a verb-noun combination )</definiens>
			</definition>
</paper>

		<paper id="1039">
			<definition id="0">
				<sentence>The `` strategic '' phase is one in which the content of the utterance is planned , including the division into theme and rheme , and the assignment of contrastive focus .</sentence>
				<definiendum id="0">strategic '' phase</definiendum>
				<definiens id="0">one in which the content of the utterance is planned</definiens>
			</definition>
			<definition id="1">
				<sentence>The point for present purposes is that the partition of the sentence into the object and a non-standard constituent S : include ' z ' widgels'/NP : z makes this theory structurally and semantically perfectly suited to the demands of intonation , as exhibited in example ( 1 ) .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">the partition of the sentence into the object and a non-standard constituent</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>224 The hypothesizing procedure ( hypo_proc ) works for each category CatA as follows ( See also Figure 3 ) : hypo_proc ( CatA ) begin if ( CatA is a failed category ) then foreach i ( CatA ==~ CatBil + ... + CatBin ) ... ...</sentence>
				<definiendum id="0">CatA</definiendum>
				<definiens id="0">a failed category ) then foreach i ( CatA ==~ CatBil + ... + CatBin</definiens>
			</definition>
			<definition id="1">
				<sentence>( 2 ) if ( CatBij is a failed category ) then HYPO ( left_recursive_rule ( eat Bij_ x ) ) ... ...</sentence>
				<definiendum id="0">CatBij</definiendum>
				<definiens id="0">a failed category</definiens>
			</definition>
			<definition id="2">
				<sentence>( 4 ) end endif if ( CatA is a non-lexical category ) then HYPO ( rule : CatA =~ CatC1 + ... + CatCz ) ... ...</sentence>
				<definiendum id="0">CatA</definiendum>
				<definiens id="0">a non-lexical category ) then HYPO ( rule : CatA =~ CatC1 + ... + CatCz</definiens>
			</definition>
			<definition id="3">
				<sentence>GRHP hypothesizes a set of new rules which collect sequences of successful categories starting at the same word position into the same failed category .</sentence>
				<definiendum id="0">GRHP</definiendum>
				<definiens id="0">hypothesizes a set of new rules which collect sequences of successful categories starting at the same word position into the same failed category</definiens>
			</definition>
			<definition id="4">
				<sentence>® Rule : colonp = &gt; pp -* Rule : np = &gt; np , pp Rule : s = &gt; np , pp , vp Rule : vp = &gt; pp , vp Lexical Entry : v = &gt; \ [ in\ ] Instead of the removed pl~attachment rule , 'nhead ==~ nhead + pp ' , GRHP generates a new pp-attachment rule , 'rip =~ .</sentence>
				<definiendum id="0">GRHP</definiendum>
			</definition>
			<definition id="5">
				<sentence>-~ Lexical Entry : n = &gt; \ [ 'BMW'\ ] GRHP generates the correct hypothesis which assigns the expected lexical category to the unSample \ ] \ ] Number of Hypotheses I Sentence Nit LE FD Total ( 3 ) \ [ 1 28 I 2 I 311 331 , ( 4 ) ) ) 58\ ] 9 I 5li 721 ( 5 ) II O l 11 oil 1l ( 8 ) s 2 1 11 NR : New Rule LE : New Lexical Entry FD : Feature Disagreement Table 2 : Number of Hypotheses registered word .</sentence>
				<definiendum id="0">GRHP</definiendum>
				<definiens id="0">generates the correct hypothesis which assigns the expected lexical category to the unSample \ ] \ ] Number of Hypotheses</definiens>
				<definiens id="1">New Rule LE : New Lexical Entry FD : Feature Disagreement Table 2 : Number of Hypotheses registered word</definiens>
			</definition>
</paper>

		<paper id="1050">
			<definition id="0">
				<sentence>involves applying the quantified NP every woman to the PDRS , visualized in DRS ( 16 ) : ( 16 ) P1 X1 woman ( xl ) I X2 -- * PI ( xI , x2 ) : Yl Y2 cat ( y~ ) like ( yl , y2 ) Of interest here is that the argument of P1 is the member of the antecedent DRS : xl .</sentence>
				<definiendum id="0">P1</definiendum>
				<definiendum id="1">DRS</definiendum>
				<definiens id="0">the member of the antecedent</definiens>
			</definition>
			<definition id="1">
				<sentence>The reading of ( 26 ) where John , the teacher , and Bill all revised John 's paper , is translated in a DRS with the presupposition that John possesses a paper 428 accommodated to the main DRS. The reading where John and Bill revised their own papers before the teacher revised John 's paper , causes accommodation twice , once for John possesses a paper and once for Bill possesses a paper .</sentence>
				<definiendum id="0">John</definiendum>
				<definiendum id="1">Bill</definiendum>
				<definiens id="0">all revised John 's paper , is translated in a DRS with the presupposition that John possesses a paper 428 accommodated to the main DRS. The reading where John and Bill revised their own papers before the teacher revised John 's paper , causes accommodation twice</definiens>
			</definition>
			<definition id="2">
				<sentence>The PROLOO-implementation is a natural language processing system which parses simple discourses , The way DRSs are constructed in this system will be discussed concisely .</sentence>
				<definiendum id="0">PROLOO-implementation</definiendum>
				<definiens id="0">a natural language processing system which parses simple discourses</definiens>
			</definition>
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>Restriction is a new operator in the f-structure description language notated by \ and with the following ( partial ) definition : Figure 3 .</sentence>
				<definiendum id="0">Restriction</definiendum>
				<definiens id="0">a new operator in the f-structure description language notated by \ and with the following</definiens>
			</definition>
			<definition id="1">
				<sentence>Structural correspondences for complex predicate AnjuL-ne ERG ~~ RED x-write &lt; SUBJ , OBJ , OBJ2~ ~UBJ Anjum ~BJ2 Saddaf S ~BJ letter xat lik ne le~er-NOM write 0 ~F~EL let \ ] | I ARG1 /ll , RG3 BEt L LARG2 letterJJ 197 ( 12 ) If f is an f-structure and a is an attribute : f~a = flDom ( t % { a } = { &lt; S , v &gt; E fl s~a } The restriction of a given f-structure f by a particular attribute a is the f-structure that results from deleting a and its value from f. If f is the f-structure in ( 13a ) , then the f-structure in ( 13b ) is f~SUBJ : ~RED kicq ( 13 ) ( a ) f= ISUB J John I LOBJ balll ( b ) f\SUBJ -- -~RED kick '' l LOBJ bal II Restriction is a designator analogous to ordinary function-application in that it provides a way of referring to elements of f-structure space by virtue of their relations to other f-structures .</sentence>
				<definiendum id="0">Structural correspondences</definiendum>
				<definiens id="0">f~a = flDom ( t % { a } = { &lt; S , v &gt; E fl s~a } The restriction of a given f-structure f by a particular attribute a</definiens>
				<definiens id="1">a designator analogous to ordinary function-application in that it provides a way of referring to elements of f-structure space by virtue of their relations to other f-structures</definiens>
			</definition>
			<definition id="2">
				<sentence>A lexical redundancy rule can be introduced to systematically modify the lexical entries for normal verbs like likhne to make them suitable for combination with a light-verb : ( 15 ) ( ~ SUBJ ) -- * ( T OBJ2 ) o 1 ' -- * o\ [ 1 ' \SUBJ\ ] This rule replaces all references to the grammatical function SUBJ with OBJ2 , thus avoiding conflict with the SUBJ introduced by the light verb , and it replaces all occurrences of the term o 1 ' with the term o\ [ 1 ' kSUBJ\ ] .</sentence>
				<definiendum id="0">lexical redundancy rule</definiendum>
				<definiens id="0">the grammatical function SUBJ with OBJ2 , thus avoiding conflict with the SUBJ introduced by the light verb</definiens>
			</definition>
			<definition id="3">
				<sentence>If f designates the f-structure in ( 18b ) and j and o designate the f-structures corresponding to the adverbs just and obviously , then the constraints ( 23a , b ) describe the outermost REL and ARG1 configuration in ( 19a ) and ( 23c , d ) describe the next level of semantic embedding : ( 23 ) ( a ) ( OfREL ) = ( oo REL ) ( b ) ( of ARGI ) -- -- o\ [ f\ &lt; CADJ o &gt; \ ] ( c ) ( o~\ &lt; ADJo &gt; \ ] REL ) -- -- ( oj REL ) ( d ) ( o~\ &lt; CADJ o &gt; \ ] ARG1 ) =o\ [ f\ &lt; ADJ o j &gt; \ ] = O~ADJ\ ] The innermost proposition can be described by interpreting ( or redundantly rewriting ) a T in the cedescription equations in the fall lexical entry as o\ [ ~ ~kDJ\ ] , that is , by interpreting the a specifications for all basic predicates as characterizing the semantics of an unmodified f-structure .</sentence>
				<definiendum id="0">ARG1</definiendum>
				<definiendum id="1">innermost proposition</definiendum>
				<definiens id="0">a ) ( OfREL ) = ( oo REL ) ( b ) ( of ARGI ) -- -- o\ [ f\ &lt; CADJ o &gt; \ ] ( c ) ( o~\ &lt; ADJo &gt; \ ] REL ) -- -- ( oj REL ) ( d ) ( o~\ &lt; CADJ o &gt; \ ]</definiens>
				<definiens id="1">the a specifications for all basic predicates as characterizing the semantics of an unmodified f-structure</definiens>
			</definition>
			<definition id="4">
				<sentence>( b ) I. s , o , ly 11 R61 EL ~EL walk~JJ LARGt John Assuming some suitable marking of the differences among adverbs , perhaps based on the semantic typing discussed by Wedekind and Kaplan ( 1993 ) , this structure is defined by the additional description-by-analysis rule ( 28 ) : ( 28 ) For fan f-structure , gE ( f ADJ ) , and g a VP adverb , ( of REL ) = og ( of REL ARG1 ) = o\ [ f\ &lt; ADJg &gt; REL\ ] o\ [ f\ &lt; ADJ g &gt; \ ] \ REL = o\ [ f~REL\ ] The restriction operator and the description-by-analysis rule ( 24 ) provide an account of adverbial modification that is motivated purely on the basis of monolingual linguistic argumentation .</sentence>
				<definiendum id="0">gE ( f ADJ</definiendum>
				<definiens id="0">some suitable marking of the differences among adverbs , perhaps based on the semantic typing discussed by Wedekind</definiens>
				<definiens id="1">the additional description-by-analysis rule ( 28 ) : ( 28 ) For fan f-structure</definiens>
				<definiens id="2">og ( of REL ARG1 ) = o\ [ f\ &lt; ADJg &gt; REL\ ] o\ [ f\ &lt; ADJ g &gt; \ ] \ REL = o\ [ f~REL\ ] The restriction operator and the description-by-analysis rule ( 24 ) provide an account of adverbial modification</definiens>
			</definition>
</paper>

		<paper id="1048">
			<definition id="0">
				<sentence>Homogeneity Problem REFERENTIAL HOMOGENEITY is the conjunction of the properties of REFERENTIAL DIVISIVENESS and REFERENTIAL CUMULATIVITY .</sentence>
				<definiendum id="0">Homogeneity Problem REFERENTIAL HOMOGENEITY</definiendum>
				<definiens id="0">the conjunction of the properties of REFERENTIAL DIVISIVENESS and REFERENTIAL CUMULATIVITY</definiens>
			</definition>
			<definition id="1">
				<sentence>comp ( e ) ( ea ) -- * comp ( rt ( e ) ) ( rt ( el ) ) Fourth , as a correlate of referential divisiveness , we assume that the set of individuals composed of a given kind is closed under the part-of relation ; that is , whenever an individual y= is composed of a certain kind z , then all subparts Yl of y~ are also composed of z , as shown in ( 11 ) .</sentence>
				<definiendum id="0">comp ( e )</definiendum>
				<definiens id="0">a correlate of referential divisiveness , we assume that the set of individuals composed of a given kind is closed under the part-of relation</definiens>
			</definition>
			<definition id="2">
				<sentence>\ [ Individual ( e ) Individual ( rs ( e ) ) A Individual ( z ) \ ] Meaning postulate ( 16 ) states that if A ( z ) holds of an eventuality e , where A ranges over run e , ooze ~ , etc. , then e is an event ( an individual eventuality ) if and only if its spatial trace rs ( e ) is an individual trajectory and x is a thing ( i.e. , an individual material ) .</sentence>
				<definiendum id="0">Individual</definiendum>
				<definiens id="0">if A ( z ) holds of an eventuality e , where A ranges over run e , ooze ~ , etc.</definiens>
				<definiens id="1">an individual trajectory</definiens>
			</definition>
			<definition id="3">
				<sentence>comp ( g ( slime ' ) ) ( z ) ^ ( 21 ) amt ( x ) = liters ' ( 2 ) ^ ooze ' ( z ) ( e ) ^ into ' ( the ' ( urn ' ) ) ( n ( e ) ) Now , if we assume a sortal meaning postulate for into analogous to that of to , then it follows from the sortal requirements on p and comp that ( 20 ) can only describe processes , whereas ( 21 ) can only describe events .</sentence>
				<definiendum id="0">comp ( g</definiendum>
				<definiens id="0">follows from the sortal requirements on p and comp that ( 20 ) can only describe processes</definiens>
			</definition>
</paper>

		<paper id="1045">
			<definition id="0">
				<sentence>A tag is defined by a finite set of elementary trees that are composed by means of the operations of tree adjunction and substitution .</sentence>
				<definiendum id="0">tag</definiendum>
				<definiens id="0">a finite set of elementary trees that are composed by means of the operations of tree adjunction and substitution</definiens>
			</definition>
			<definition id="1">
				<sentence>384 Definition 2.1 A tag , G , is denoted G= ( V , , VT , S , I , A ) where Vjv is a finite set of nonterminals symbols , VT is a finite set of terminal symbols , S E V/v is the start symbol , I is a finite set of initial trees , A is a finite set of auxiliary trees .</sentence>
				<definiendum id="0">Vjv</definiendum>
				<definiendum id="1">VT</definiendum>
				<definiendum id="2">S E V/v</definiendum>
				<definiens id="0">a finite set of nonterminals symbols</definiens>
				<definiens id="1">a finite set of terminal symbols</definiens>
			</definition>
			<definition id="2">
				<sentence>An auxiliary tree is a tree that has a leaf node ( the foot node ) that is labeled by the same nonterminal that labels the root node .</sentence>
				<definiendum id="0">auxiliary tree</definiendum>
				<definiens id="0">a tree that has a leaf node ( the foot node ) that is labeled by the same nonterminal that labels the root node</definiens>
			</definition>
			<definition id="3">
				<sentence>An elementary node address is a pair comprising of the name of the elementary tree to which the node belongs and the address of the node within that tree .</sentence>
				<definiendum id="0">elementary node address</definiendum>
				<definiens id="0">a pair comprising of the name of the elementary tree to which the node belongs and the address of the node within that tree</definiens>
			</definition>
			<definition id="4">
				<sentence>Pl ) = oa ( 7 , p. Pl ) , In general , if p is the address of a node in 7 then &lt; 7 , P &gt; denotes the elementary node address of the node that contributes to its presence , and hence its label and constraints .</sentence>
				<definiendum id="0">P &gt;</definiendum>
				<definiens id="0">the elementary node address of the node that contributes to its presence , and hence its label and constraints</definiens>
			</definition>
			<definition id="5">
				<sentence>Definition 3.1 A LIG , G , is denoted G = ( Vjv , VT , VI , S , P ) where Vlv is a finite set of nonterminals , VT is a finite set of terminals , VI is a finite set of indices ( stack symbols ) , S • VN is the start symbol , and P is a finite set of productions .</sentence>
				<definiendum id="0">Vlv</definiendum>
				<definiendum id="1">VT</definiendum>
				<definiendum id="2">VI</definiendum>
				<definiendum id="3">VN</definiendum>
				<definiendum id="4">P</definiendum>
				<definiens id="0">a finite set of nonterminals</definiens>
				<definiens id="1">a finite set of terminals</definiens>
				<definiens id="2">a finite set of indices ( stack symbols</definiens>
				<definiens id="3">the start symbol</definiens>
				<definiens id="4">a finite set of productions</definiens>
			</definition>
			<definition id="6">
				<sentence>The general form of a lig production is : A\ [ oo a\ ] -- -* TB\ [ oo a'\ ] T ' where A , B e VN , a , a ' G VI* and T , T ' G ( Vc ( C ) U VT ) * .</sentence>
				<definiendum id="0">B e VN</definiendum>
				<definiens id="0">a ' G VI* and T , T ' G ( Vc ( C ) U VT ) *</definiens>
			</definition>
			<definition id="7">
				<sentence>-- , BC is a production in Go that is used in the first step of a derivation of the substring ai+l..</sentence>
				<definiendum id="0">BC</definiendum>
			</definition>
			<definition id="8">
				<sentence>Additionally , G~ includes the production ( a~ , k , k + l ) -- , a~ for each 1 &lt; k &lt; n. Note that the number of nonterminals in the shared forest grammar , Gw , is O ( n 2 ) and the number of productions is O ( n re+l ) where Iw I = n and m is the maximum number of nonterminals in the right-hand-side of a production in Go .</sentence>
				<definiendum id="0">G~</definiendum>
				<definiendum id="1">m</definiendum>
				<definiens id="0">includes the production ( a~ , k , k + l ) -- , a~ for each 1 &lt; k &lt; n. Note that the number of nonterminals in the shared forest grammar</definiens>
				<definiens id="1">the maximum number of nonterminals in the right-hand-side of a production in Go</definiens>
			</definition>
			<definition id="9">
				<sentence>where S is the start symbol of Gw .</sentence>
				<definiendum id="0">S</definiendum>
			</definition>
			<definition id="10">
				<sentence>A tag derivation can be seen as a traversal over the elementary trees beginning at the root of one of the initial trees .</sentence>
				<definiendum id="0">tag derivation</definiendum>
			</definition>
			<definition id="11">
				<sentence>such that the left sibling ti1 is on the spine or neither child is on the spine , P includes the production ( / , p , q ) \ [ oo .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">includes the production ( / , p , q ) \ [ oo</definiens>
			</definition>
			<definition id="12">
				<sentence>Case 4a : When ti is a node where fl can be adjoined and ti~ is the root node of/~ P includes the production ( T , p , q ) \ [ oo ti\ ] -- ~ ( T , p , q ) \ [ oo r/ti'\ ] for each p , q E Q. Note that the adjunction node ti has been pushed below the new node rf on the stack .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiens id="0">the root node of/~ P includes the production ( T , p , q ) \ [ oo ti\ ] -- ~ ( T , p</definiens>
			</definition>
			<definition id="13">
				<sentence>recover ( ( C , / '' ) b ) Case 3 : If there is some production p = Al\ [ OO t/l\ ] -- -* B\ [ oo 1'\ ] • P such that either n &gt; 1 and A2 • 6 ( B , l ' ) ( where T2 = ( A2 , t/2 ) ) or n = 1 and a • 6 ( B , l ' ) then output p. recover ( ( B , l ' ) T2 . . . Tna ) Case 4a : If there is some production p = Ax\ [ oo 71\ ] ~ B\ [ oo y21'\ ] inP such that C • 6 ( B , l ~ ) for some C • VN and A2 • 6 ( C , th ) and either n &gt; 1 and T~ = ( A2 , t/z ) or n = 1 and a • 6 ( C , t/l ) then output p. recover ( ( B , l ' ) ( C , t/l ) T2 . . . T , a ) Case 4b : If there is a production p = Al\ [ oo t/2t/1\ ] -- -* A~\ [ oo y~\ ] • P such that n &gt; 1 and T2 = ( Az , y2 ) then output p. recover ( T2 ... T , ) Given the form of the nonterminals and productions of Gto we can see that the complexity of extracting a parse as above is dominated by the complexity by Case 4a which takes O ( n 4 ) time .</sentence>
				<definiendum id="0">recover ( ( C</definiendum>
				<definiendum id="1">B</definiendum>
				<definiens id="0">C , th ) and either n &gt; 1 and T~ = ( A2 , t/z ) or n = 1 and a • 6 ( C , t/l ) then output p. recover ( ( B , l ' ) ( C , t/l ) T2 . .</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>MORPA is a fully implemented parser developed for use in a text-to-speech conversion system .</sentence>
				<definiendum id="0">MORPA</definiendum>
				<definiens id="0">a fully implemented parser developed for use in a text-to-speech conversion system</definiens>
			</definition>
			<definition id="1">
				<sentence>MORPA is a MORphological PArser developed for use in the text-to-speech conversion system for Dutch , SPRAAKMAKER \ [ van Leeuwen and te Lindeft , 1993\ ] .</sentence>
				<definiendum id="0">MORPA</definiendum>
				<definiens id="0">a MORphological PArser developed for use in the text-to-speech conversion system for Dutch</definiens>
			</definition>
			<definition id="2">
				<sentence>Finally , MORPA sees to it that words belonging to minor lexical categories ( such as determiners , pronouns , conjunctions , etc. ) are not recognised as word parts .</sentence>
				<definiendum id="0">MORPA</definiendum>
				<definiens id="0">such as determiners , pronouns , conjunctions , etc. ) are not recognised as word parts</definiens>
			</definition>
			<definition id="3">
				<sentence>As shown in ( 7 ) , first verbal prefixation yields the verbal stem verdraag ( tolerate ) , then adjectival suffixation yields the adjective verdraagzaam ( tolerant ) , adjectival prefixation yields the adjective onverdraagzaam ( intolerant ) and , finally , nominal suffixation yields the noun onverdraagzaamheid ( intolerance ) : ( 7 ) N A A\N A/A A heid on V V\A V/V V zaam I I ver draag Also , the level module rules out the analysis in ( 5c ) : the nominal suffix -ing must not be attached before the verbal prefix be- .</sentence>
				<definiendum id="0">adjective verdraagzaam</definiendum>
				<definiendum id="1">adjective onverdraagzaam</definiendum>
				<definiendum id="2">nominal suffixation</definiendum>
				<definiens id="0">the nominal suffix -ing must not be attached before the verbal prefix be-</definiens>
			</definition>
			<definition id="4">
				<sentence>Let G be any non-terminal symbol of the grammar ; n ( G ) the number of productions rewriting G and P ( ilG ) the probability that the ith of these productions takes place , then ( 10 ) P ( iIG ) = n ( G ) It is assumed that for all i -1 , 2 ... . , n ( G ) , P ( iIG ) is a positive number and that ~iP ( ilG ) -1 .</sentence>
				<definiendum id="0">~iP</definiendum>
				<definiens id="0">any non-terminal symbol of the grammar ; n ( G ) the number of productions rewriting G and P ( ilG ) the probability that the ith of these productions takes place</definiens>
				<definiens id="1">a positive number</definiens>
			</definition>
			<definition id="5">
				<sentence>187 MORPA 's grammar comprises three different types of production rules : ( 11 ) a w ~ T b T -- ~ N1 N2 c N -- -- *M In ( 11 ) w is the start symbol for words 9 , T any member of the set of atomic categories which are possible top nodes : 7= { n , v , a , ... } , N any member of the set of non-terminals containing both atomic and functor categories : Af = { n , n/v , v\n , v , . . . } , 7C .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">the start symbol for words 9 , T any member of the set of atomic categories which are possible top nodes : 7= { n , v , a</definiens>
			</definition>
</paper>

		<paper id="1068">
			<definition id="0">
				<sentence>The most powerful disambiguation tool is the exploitation Of typing constraints associated with the database itself .</sentence>
				<definiendum id="0">most powerful disambiguation tool</definiendum>
				<definiens id="0">the exploitation Of typing constraints associated with the database itself</definiens>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>COOL is a working system that was developed for ESTRATO ( EScuela de TRAductores de TOledo ) , a joint project of the Center for Machine Translation at CMU and Union Electrica Fenosa , an electric utility company in Madrid , Spain .</sentence>
				<definiendum id="0">COOL</definiendum>
				<definiens id="0">a working system that was developed for ESTRATO</definiens>
			</definition>
			<definition id="1">
				<sentence>ESTRATO consists of several modules from the KANT MT system \ [ Mitamura et al. , 1991\ ] as well as morphological analysis and phrasal recognition modules and the TWS authoring environment\ [ Nirenburg et ai. , 1992\ ] .</sentence>
				<definiendum id="0">ESTRATO</definiendum>
				<definiens id="0">consists of several modules from the KANT MT system \ [ Mitamura et al. , 1991\ ] as well as morphological analysis</definiens>
			</definition>
			<definition id="2">
				<sentence>As shown in figure 1 , every ESTRATO run-time module uses a different lexical or semantic knowledge source , which differs in content as well as format .</sentence>
				<definiendum id="0">ESTRATO run-time module</definiendum>
				<definiens id="0">uses a different lexical or semantic knowledge source , which differs in content as well as format</definiens>
			</definition>
			<definition id="3">
				<sentence>A-COOL produces the central lexical and template semantic databases from the initial lexical feature files , which the linguist and domain expert can then modify .</sentence>
				<definiendum id="0">A-COOL</definiendum>
				<definiens id="0">produces the central lexical and template semantic databases from the initial lexical feature files</definiens>
			</definition>
			<definition id="4">
				<sentence>COOL maintains consistency in the knowledge sources and makes it easy to add lexical databases for new modules .</sentence>
				<definiendum id="0">COOL</definiendum>
				<definiens id="0">maintains consistency in the knowledge sources and makes it easy to add lexical databases for new modules</definiens>
			</definition>
			<definition id="5">
				<sentence>Once the run-time knowledge sources for the various NLP modules have been acquired , maintaining consistency among the lexical and semantic files ( phrasal-noun list , glossary , morpho-syntactic lexicons , word-to-concept mappings and the semantic concepts ) is difficult .</sentence>
				<definiendum id="0">run-time knowledge sources</definiendum>
				<definiens id="0">the lexical and semantic files ( phrasal-noun list , glossary , morpho-syntactic lexicons , word-to-concept mappings and the semantic concepts</definiens>
			</definition>
			<definition id="6">
				<sentence>A-COOL allows the semi-automatic creation of NLP lexical knowledge from lexicographic information supplied by a non-linguist .</sentence>
				<definiendum id="0">A-COOL</definiendum>
				<definiens id="0">allows the semi-automatic creation of NLP lexical knowledge from lexicographic information supplied by a non-linguist</definiens>
			</definition>
			<definition id="7">
				<sentence>Maintenance M-COOL allows the linguist to keep just one source for Spanish lexical information and one source for English lexical information ( the central lexical frame ( SEMANTIC-RULE rule3 LHS ( action physical ) RHS ( is-a physical-event ) ) Figure 6 : A-COOL rule to place a semantic frame in the IS-A hierarchy ( MAKE-FRAME +W-SP-FUNCIONAR-V-2 ( COMP-TYPE no ) ( CAT v ) ( STEM-CHANGE no ) ( TRANS intrans ) ( IS-A +u-spanish-intrans-verb ) ( CLASS agent ) ( HEAD *work-funcionar ) ( ROOT `` funcionar '' ) ) ( MAKE-FRA~ +W-EN-WORK-V-1 ( ROOT `` work '' ) ( HEAD *work-funcionar ) ( COMP-TYPE no ) ( CLASS agent ) ( IS-A +w-english-verb ) ( TRANS intrans ) ( CAT V ) ) ( MAKE-FRAME *WORK-FUNCIONAR ( IS-A device-event ) ( GOAL *none* ) ( LOCATION building place ... ) ( INSIDE-OF *cabinet-armario ... ) ) Figure 7 : Lexical and Semantic frame entries generated by A-COOL and used as input to M-COOL .</sentence>
				<definiendum id="0">Maintenance M-COOL</definiendum>
				<definiendum id="1">IS-A +u-spanish-intrans-verb )</definiendum>
				<definiendum id="2">HEAD *work-funcionar )</definiendum>
				<definiens id="0">allows the linguist to keep just one source for Spanish lexical information and one source for English lexical information ( the central lexical frame</definiens>
				<definiens id="1">CLASS agent ) ( HEAD *work-funcionar ) ( ROOT `` funcionar ''</definiens>
				<definiens id="2">COMP-TYPE no ) ( CLASS agent ) ( IS-A +w-english-verb ) ( TRANS intrans ) ( CAT V ) ) ( MAKE-FRAME *WORK-FUNCIONAR ( IS-A device-event ) ( GOAL *none* ) ( LOCATION building place ... ) ( INSIDE-OF *cabinet-armario ... )</definiens>
			</definition>
			<definition id="8">
				<sentence>FRULEKIT is an efficient CommonLisp pattern matcher with several extensions over oPs-5 .</sentence>
				<definiendum id="0">FRULEKIT</definiendum>
				<definiens id="0">an efficient CommonLisp pattern matcher with several extensions over oPs-5</definiens>
			</definition>
			<definition id="9">
				<sentence>Nouns ( CAT N ) contain agreement ( MAKE-FRAME+W-EN-GO-OFF-V-I ( ROOT `` go '' ) ( HEAD *work-ftmcionar ) ( PATTERN ( agent ( is-a *alarm-alarma ) ) ) ( SEM-DOMAIN `` mech/tech '' ) ( COMP-TYPE no ) ( CLASS agent ) ( IS-A +w-english-verb ) ( TRANS intrans ) ( IRREGULARS ( past `` went '' ) ( pastpart `` gone '' ) ) ( PARTICLE off ) ( CAT V ) ) Figure 8 : Alternative English lexical entry for *WORKFUNCIONAR ( GENDER and NUMBER ) count/mass ( COUNT ) and a trinary distinction of ANIMACY ( human , animal , non-living ) .</sentence>
				<definiendum id="0">Nouns</definiendum>
				<definiendum id="1">) ( TRANS intrans ) ( IRREGULARS</definiendum>
				<definiens id="0">CAT N ) contain agreement ( MAKE-FRAME+W-EN-GO-OFF-V-I ( ROOT `` go '' ) ( HEAD *work-ftmcionar ) ( PATTERN ( agent ( is-a *alarm-alarma ) ) ) ( SEM-DOMAIN `` mech/tech '' ) ( COMP-TYPE no ) ( CLASS agent ) ( IS-A +w-english-verb</definiens>
			</definition>
			<definition id="10">
				<sentence>+w-sp-Spanish-verb : head =head : root =root : class =class : sem-map =sem ) ( current-file : value Spanish-lexical-analysis ) : RHS ( cool-output ' ( : root ( gen-frame-name =verb ) : cat V : head =head : class =class : sem =sem ) ) ) Figure 9 : M-COOL rule \ ] or generating run-time lexical mapping data .</sentence>
				<definiendum id="0">class =class</definiendum>
				<definiendum id="1">RHS</definiendum>
			</definition>
</paper>

		<paper id="1069">
			<definition id="0">
				<sentence>The ENGTWOL morphological analyser is a 55,000 entry Koskenniemi-style morphological description of English that assigns all recognised input word forms with all possible morphological readings as a disjunctive list .</sentence>
				<definiendum id="0">ENGTWOL morphological analyser</definiendum>
				<definiens id="0">a 55,000 entry Koskenniemi-style morphological description of English that assigns all recognised input word forms with all possible morphological readings as a disjunctive list</definiens>
			</definition>
			<definition id="1">
				<sentence>The parser computes the intersection of the sentence automaton and all rule automata ; the intersection is the parse of the sentence .</sentence>
				<definiendum id="0">intersection</definiendum>
				<definiens id="0">the parse of the sentence</definiens>
			</definition>
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>349 Semantic Analyses of Dimensional Adjectives Formal interpretations of ( 3 ) a. Positive amount ( length ( board ) ) { 'q / r -- } Nc ( length ( board ) ) b. Comparative amount ( length ( board ) ) { -q / F ) amount ( width ( table ) ) c. Equative amount ( length ( board ) ) ~ amount ( width ( table ) ) d. Measurement amount ( length ( board ) ) = ( 50 , cm ) Table 1 : Non-compositional approach a. Positive amount ( length ( board ) ) { 'q / r } D + We ( length ( board ) ) b. Comparative amount ( length ( board ) ) { ~ / f- } D rl : amount ( width ( table ) ) c. Equative amount ( length ( board ) ) ~_ n x amount ( width ( table ) ) d. Measm-ement amount ( length ( board ) ) ) = ( 50 , em ) Table 2 : Compositional approach determining that short conference describes a duration but short stick describes the length of the stick 's elongated axis .</sentence>
				<definiendum id="0">Comparative amount</definiendum>
				<definiens id="0">table ) ) c. Equative amount ( length ( board ) ) ~_ n x amount ( width ( table ) ) d. Measm-ement amount</definiens>
			</definition>
			<definition id="1">
				<sentence>A constraint is a formula over parameters in X in some accepted notation ( e.g. X1 x X2 = ) ( 3 or p _ &lt; -XI + X2 + ) ( 3 &lt; _ q ) .</sentence>
				<definiendum id="0">constraint</definiendum>
				<definiens id="0">a formula over parameters in X in some accepted notation ( e.g. X1 x X2 = ) ( 3 or p _ &lt; -XI + X2 + )</definiens>
			</definition>
			<definition id="2">
				<sentence>A constraint system C = ( X , C , L / consists of a set X of parameters , a set C of constraints over X , and a labelling L for X. Semantics A valuation V for X is a function from the parameters to reals .</sentence>
				<definiendum id="0">L /</definiendum>
			</definition>
			<definition id="3">
				<sentence>A constraint C i denotes the largest set of valuations that are consistent with the relation expressed by Cj ; call this set V ( Cj ) .</sentence>
				<definiendum id="0">constraint C i</definiendum>
			</definition>
			<definition id="4">
				<sentence>Constraint propagation separates a stage of assimilation , during which intervals are tightened , from querying , during which the tightened values are reported .</sentence>
				<definiendum id="0">Constraint propagation</definiendum>
				<definiens id="0">separates a stage of assimilation , during which intervals are tightened</definiens>
			</definition>
			<definition id="5">
				<sentence>VIV ( Cn ) nV ( LI ) C_ V ( L ) for every labelling L returned by the algorithm , where { el , ... , Ca } is the set of constraints in the system and L1 is the initial labelling .</sentence>
				<definiendum id="0">VIV</definiendum>
				<definiendum id="1">... , Ca }</definiendum>
				<definiendum id="2">L1</definiendum>
				<definiens id="0">the set of constraints in the system</definiens>
				<definiens id="1">the initial labelling</definiens>
			</definition>
			<definition id="6">
				<sentence>For a refinement operator R , let OUT ( R ) be the bound affected by R , and let ARGS ( R ) be the set of bounds other than OUT ( R ) that enter into the computation of OUT ( R ) .</sentence>
				<definiendum id="0">OUT</definiendum>
				<definiendum id="1">R</definiendum>
			</definition>
			<definition id="7">
				<sentence>Thus the dependence relation is the transitive and reflexive closure of the immediate precedence relation .</sentence>
				<definiendum id="0">dependence relation</definiendum>
				<definiens id="0">the transitive and reflexive closure of the immediate precedence relation</definiens>
			</definition>
</paper>

	</volume>
