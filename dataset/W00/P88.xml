<?xml version="1.0" encoding="UTF-8"?>
	<volume id="P88">

		<paper id="1025">
			<definition id="0">
				<sentence>3 , the VERB is the main head of the sentence ; the head of the noun phrase preceding the main verb is the NOUN representing the term `` oPerations '' , etc .</sentence>
				<definiendum id="0">VERB</definiendum>
				<definiens id="0">the main head of the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Two different frequency criteria are important in phrase weighting : The frequency of occurrence of a construct in a given document , or document section , known as the term frequency ( tf ) The number of documents , or document sections , in which a given construct occurs , known as the document frequency ( df ) .</sentence>
				<definiendum id="0">document frequency</definiendum>
				<definiens id="0">important in phrase weighting : The frequency of occurrence of a construct in a given document , or document section , known as the term frequency ( tf ) The number of documents , or document sections , in which a given construct occurs</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>( Brackets have been added to indicate discourse segments .</sentence>
				<definiendum id="0">Brackets</definiendum>
			</definition>
			<definition id="1">
				<sentence>BI : That 's where they wait out the long Antarctic winter .</sentence>
				<definiendum id="0">BI</definiendum>
				<definiens id="0">That 's where they wait out the long Antarctic winter</definiens>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>In *the Centre for Computational Linguistics , University of Manchester Institute of Science and Technology , England **UNIX is a trademark of AT &amp; T Bell Laboratories .</sentence>
				<definiendum id="0">England **UNIX</definiendum>
			</definition>
			<definition id="1">
				<sentence>( In these and subsequent examples , E : indicates English input , J : Japanese input , and T : translation .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">indicates English input</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>The collective/distributive distinction raises an important issue : how to treat the semantics of plural NPs uniformly .</sentence>
				<definiendum id="0">collective/distributive distinction</definiendum>
				<definiens id="0">raises an important issue : how to treat the semantics of plural NPs uniformly</definiens>
			</definition>
			<definition id="1">
				<sentence>Scha 's `` Distributive , Collective , and Cumulative Quantification '' ( 'DCC ' ) showed that this approach , while plausible for intransitive verbs , breaks down for the two-argument case of transitive verbs \ [ 7\ ] .</sentence>
				<definiendum id="0">Cumulative Quantification</definiendum>
			</definition>
			<definition id="2">
				<sentence>The following is a list of sentences paired with their translations under this scheme : The boys walk WALK ( BOYS ) Each boy walks Vx e BOYS ' : WALK ( x ) The boys gather GATHER ( BOYS ) The squares contain the circles CONTAIN ( SQUARES , CIRCLES ) For `` the '' + plural NP 's we thus obtain analyses which are , though not incorrect , perhaps more vague than one would desire .</sentence>
				<definiendum id="0">WALK ( BOYS</definiendum>
				<definiens id="0">a list of sentences paired with their translations under this scheme</definiens>
			</definition>
			<definition id="3">
				<sentence>Ambiguity and Discourse Effects The final problem for the treatment in `` DCC '' has to do with the meaning postulates themselves .</sentence>
				<definiendum id="0">Ambiguity</definiendum>
			</definition>
			<definition id="4">
				<sentence>EFL includes a descriptive constant for each word in the lexicon , however many senses that word may have .</sentence>
				<definiendum id="0">EFL</definiendum>
				<definiens id="0">includes a descriptive constant for each word in the lexicon</definiens>
			</definition>
			<definition id="5">
				<sentence>Hence EFL is an ambiguous logical language ; in technical terms this means either that the language has a model-theory that assigns multiple denotations to a single expression \ [ 5\ ] , or that its expressions are viewed as schemata which abbreviate sets of possible instance-expressions .</sentence>
				<definiendum id="0">Hence EFL</definiendum>
				<definiens id="0">an ambiguous logical language</definiens>
			</definition>
			<definition id="6">
				<sentence>We can now define the function TO-WML , which takes an EFL expression and produces a set of WML expressions without EFL constants .</sentence>
				<definiendum id="0">function TO-WML</definiendum>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>41 In seeking to provide TEL1 with general capabilities for comparatives , our primary goals have been to formulate cross-categorial techniques that treat the comparativizations of different syntactic elements ( e.g. adjectives , quantifiers , and measure nouns ) with the same mechanisms ; to allow comparatives to be composed with themselves ( e.g. `` at least 3 more than 3 times as many ' ) and with other syntactic features ( e.g. wh elements ) ; to be faithful to what is known from work in theoretical linguistics ; we draw from Bresnan ( 1973 ) , Cushing ( 1982 ) , Dik ( 1980 ) , Jackendoff ( 1977 ) , Sells ( 1985 ) , and Winograd ( 1983 ) ; to account for as many of the specific cases of comparatives found in the literatureof implemented NL processors as possible .</sentence>
				<definiendum id="0">Winograd</definiendum>
				<definiens id="0">treat the comparativizations of different syntactic elements ( e.g. adjectives , quantifiers , and measure nouns ) with the same mechanisms</definiens>
			</definition>
			<definition id="1">
				<sentence>-4 , -er/flum\ [ less/thu\ [ ss/us where ( ... ) denotes optionality ; `` / '' indicates `` agreement '' between comparative particles ; and &lt; Etcx &gt; accounts for items parallel to those in the matrix clause in which the comparative occurs ( e.g. `` cars that are longer than the Regal ( is ( wide ) ) ' ) .</sentence>
				<definiendum id="0">... )</definiendum>
				<definiens id="0">denotes optionality ; `` / '' indicates `` agreement '' between comparative particles ; and &lt; Etcx &gt; accounts for items parallel to those in the matrix clause in which the comparative occurs ( e.g. `` cars that are longer than the Regal ( is ( wide ) ) ' )</definiens>
			</definition>
			<definition id="2">
				<sentence>2 A ) ) ) ) ( CAR { = CENTURY ) ) ( ADJ WIDE ) ) ) Next , user-defined meanings of words and phrases are looked up 4 and the comparati~zafion operations described in Section 6 are performed , yielding Algebraic-Logical Fon~ ( SET ( CAR Pl ) ( ~ ( Length-of-Car PI ) ( + 20 ( ~ 2 ( Width-of-Car CENTURY\ ] Finally , this representation is converted into the executable expression indicated by lrmal Executable Exprossiee : ( SUBSET ( X ( Pl ) ( ~ ( KSV PI eS { LENGTH } ) ( ÷ 20 ( 2 ( KSV @ I ( CENTURY } BS { WIDTH } ) ) ) ) ( KI @ F { CAR } ) ) ) where KSV and KI are primitive retrieval functions of the Kandor back-end ; @ I { ... } , @ F { ... } and @ S { ... } are Lisp objects respectively denoting instances , frames , and slots in Kandor 's taxonomic knowledge base ; and &gt; I &gt; / is a coercion routine supplied by TELI to accommodate backend retrieval system that produce numbers in disguise ( e.g. a Lisp object or a singleton set ) on which the standard Lisp functions would choke .</sentence>
				<definiendum id="0">SET ( CAR Pl )</definiendum>
				<definiens id="0">CAR { = CENTURY ) ) ( ADJ WIDE ) ) ) Next , user-defined meanings of words and phrases are looked up 4 and the comparati~zafion operations described in Section 6 are performed</definiens>
				<definiens id="1">expression indicated by lrmal Executable Exprossiee : ( SUBSET ( X ( Pl ) ( ~ ( KSV PI eS { LENGTH } )</definiens>
				<definiens id="2">primitive retrieval functions of the Kandor back-end ; @ I { ... } , @ F { ... } and @ S { ... } are Lisp objects respectively denoting instances , frames , and slots in Kandor 's taxonomic knowledge base</definiens>
				<definiens id="3">a coercion routine supplied by TELI to accommodate backend retrieval system that produce numbers in disguise ( e.g. a Lisp object or a singleton set ) on which the standard Lisp functions would choke</definiens>
			</definition>
			<definition id="3">
				<sentence>In the case at hand , the second argument of &gt; I &gt; ~ is constant , so it is evaluated , producing Optimized Executable Exlmressiee : ( SUBSET ( A ( Pl ) ( ~ &gt; / ( KSV P1 @ S { LENGTH } ) 158 ) ) ( KI BF { CAR } ) ) A second example , which illustrates a comparative extended tint-order language discussed in Ballard and Stumberger ( 1987 ) .</sentence>
				<definiendum id="0">SUBSET</definiendum>
			</definition>
			<definition id="4">
				<sentence>For example , if `` large car '' has been defined as a car whose length exceeds 190 inches , thetl , letting `` A '' denote a noun phrase complement , some examples are t0q kMq~r tim 180 hm : l~ leqcr tlam A no lealger than A twice as leog as A twide 3 laches mora thaa twi~ as long as A Lesgth ( x ) ; ~ 190 Lcegth ( x ) &gt; 18o Leq~ ( x ) &gt; Leq~ ( A ) Le , t.m ( x ) ~ Le~mCA ) Leqpm ( x ) ~ 2 • Wldth ( A ) Length ( x ) &gt; 3 + 2 , Length ( A ) where each of these right-hand-sides is the body of a one-place predicate whose single variable is x. As a second example , comparative quantifiers such as `` more than 6 '' are handled by an identical process l° , as indicated by Ii x has -- any y , .</sentence>
				<definiendum id="0">Wldth ( A ) Length ( x</definiendum>
				<definiens id="0">a car whose length exceeds 190 inches , thetl , letting `` A '' denote a noun phrase complement , some examples are t0q kMq~r tim 180 hm : l~ leqcr tlam A no lealger than A twice as leog as A twide 3 laches mora thaa twi~ as long as A Lesgth ( x ) ; ~ 190 Lcegth ( x ) &gt; 18o Leq~ ( x ) &gt; Leq~ ( A ) Le , t.m ( x ) ~ Le~mCA ) Leqpm ( x ) ~ 2 •</definiens>
				<definiens id="1">the body of a one-place predicate whose single variable is x. As a second example , comparative quantifiers such as `` more than 6 '' are handled by an identical process l° , as indicated by Ii x has -- any y ,</definiens>
			</definition>
			<definition id="5">
				<sentence>em A Size { y I nt , s ( x , y ) } &gt; Size blt~ ( A , y ) } x Im at lem 2 me~ Size { y \ [ Hgix , y ) } y 's tim A ~ 2 + Size \ [ y \ ] l-I~ ( A.y ) } where the initial Constant denotes some arbitrary constant .</sentence>
				<definiendum id="0">Constant</definiendum>
				<definiens id="0">s ( x , y ) } &gt; Size blt~ ( A , y ) } x Im at lem 2 me~ Size { y \ [ Hgix , y ) } y 's tim A ~ 2 + Size \ [ y \ ] l-I~ ( A.y ) } where the initial</definiens>
				<definiens id="1">some arbitrary constant</definiens>
			</definition>
			<definition id="6">
				<sentence>In the case at hand , we must assume something like Q+many -- *Q , where Q denotes a quantity .</sentence>
				<definiendum id="0">Q</definiendum>
				<definiens id="0">a quantity</definiens>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>This process of attitude revision is an interesting domain for the application of nonmonotonic reasoning because speech acts have a conventional aspect that is readily represented by defaults , but that interacts with an agent 's beliefs and intentions in many complex ways that may override the defaults .</sentence>
				<definiendum id="0">attitude revision</definiendum>
			</definition>
			<definition id="1">
				<sentence>Logic Autoepistemic ( AE ) logic was developed by Moore \ [ I0\ ] as a reconstruction of McDermott 's nonmonotonic logic \ [ 9\ ] .</sentence>
				<definiendum id="0">Logic Autoepistemic</definiendum>
			</definition>
			<definition id="2">
				<sentence>The language of HAEL consists of a standard first-order language , augmented by a indexed set of unary modal operators Li .</sentence>
				<definiendum id="0">language of HAEL</definiendum>
			</definition>
			<definition id="3">
				<sentence>A complez stable e~pansion of an HAEL structure r is a set of sets of sentences 2~ corresponding to the subtheories of r. It obeys the following conditions ( ~b is an ordinary sentence ) : quence These conditions are similar to those for AE stable expansions .</sentence>
				<definiendum id="0">~b</definiendum>
				<definiens id="0">a set of sets of sentences 2~ corresponding to the subtheories of r. It obeys the following conditions</definiens>
			</definition>
			<definition id="4">
				<sentence>The precise path belief revision takes depends on the contents of r0 .</sentence>
				<definiendum id="0">precise path belief revision</definiendum>
				<definiens id="0">takes depends on the contents of r0</definiens>
			</definition>
			<definition id="5">
				<sentence>We introduce a schematic operator \ [ ( s , h ) n\ ] which can be thought of as n levels of alternation of s 's and h 's beliefs about each other .</sentence>
				<definiendum id="0">h</definiendum>
				<definiens id="0">n\ ] which can be thought of as n levels of alternation of s 's and h 's beliefs about each other</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>INTONATIONAL PHRASES consist of one or more intermediate phrases , plus a BOUNDARY TONE , also H or L , which falls at the edge of the phrase ; we indicate boundary tones with an ' % ' , as H % .</sentence>
				<definiendum id="0">INTONATIONAL PHRASES</definiendum>
				<definiens id="0">consist of one or more intermediate phrases , plus a BOUNDARY TONE , also H or L , which falls at the edge of the phrase ; we indicate boundary tones with an ' % '</definiens>
			</definition>
			<definition id="1">
				<sentence>Another process , called FINAL LOWEP~NG , involves a compression of the pitch range during the last half second or so of a 'declarative ' utterances .</sentence>
				<definiendum id="0">FINAL LOWEP~NG</definiendum>
				<definiens id="0">involves a compression of the pitch range during the last half second or so of a 'declarative ' utterances</definiens>
			</definition>
			<definition id="2">
				<sentence>The Location Finder queries the user to obtain the origin and destination of the route .</sentence>
				<definiendum id="0">Location Finder</definiendum>
				<definiens id="0">queries the user to obtain the origin and destination of the route</definiens>
			</definition>
			<definition id="3">
				<sentence>In the work reported here , we modified the Describer to generate an abstract representation of the route description and replaced the Narrator with a new component , the Talker , which computes prosodic values from these structures and passes text augmented with commands controlling prosodic variation to the speech synthesizer .</sentence>
				<definiendum id="0">Talker</definiendum>
				<definiens id="0">computes prosodic values from these structures and passes text augmented with commands controlling prosodic variation to the speech synthesizer</definiens>
			</definition>
			<definition id="4">
				<sentence>The Describer selects the one which is most easily recognized ( e.g. a bridge crossing ) sad which is close to the act for which it is a cue .</sentence>
				<definiendum id="0">Describer</definiendum>
				<definiens id="0">selects the one which is most easily recognized ( e.g. a bridge crossing ) sad which is close to the act for which it is a cue</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>Discourse Information Change Rules ( DICRs ) that allow resolving a class of anaphors in honorific contexts are also formulated .</sentence>
				<definiendum id="0">Discourse Information Change Rules</definiendum>
				<definiens id="0">allow resolving a class of anaphors in honorific contexts are also formulated</definiens>
			</definition>
			<definition id="1">
				<sentence>The speaker is set as the point of origin , and the speaker 's honorific attitude toward a discourse agent , say P , is defined as the position vector of point P. The speaker 's honorific attitude toward agent P relative to agent Q is defined as a vector from point Q to point P. The value and the direction of the vector are defined as follows : 139 Honorific Value : for v = ( x. y ) , the honorific value of a vector v ( written as IvJ ) is defined as : Ivl = y iffx=0 ; 0 iffx ~0 ; Honorific Direction : a. up I , t &gt; 0 , b. down Ivi &lt; O , c. flat Iv~=O and x=O , d. across Ivl = 0 and x ~ O. IN .</sentence>
				<definiendum id="0">Honorific Direction</definiendum>
				<definiens id="0">the point of origin , and the speaker 's honorific attitude toward a discourse agent</definiens>
				<definiens id="1">for v = ( x. y )</definiens>
			</definition>
			<definition id="2">
				<sentence>An acrosS direction of a vector corresponds to the case where no positive honorific relation between the two agents ( i.e. up , down , or flat ) is recognized by the speaker .</sentence>
				<definiendum id="0">acrosS direction of a vector</definiendum>
				<definiens id="0">the case where no positive honorific relation between the two agents ( i.e. up , down , or flat ) is recognized by the speaker</definiens>
			</definition>
			<definition id="3">
				<sentence>Honorific Attitude Type : a. honor-up b. honor-down c. honor-flat e. honor-across In Japanese , words in a wide range of syntactic categories ( i.e. nouns , verbs , adjectives , nominal-verbs , nominaladjectives , etc ) are systematically put into their honorific forms .</sentence>
				<definiendum id="0">syntactic categories</definiendum>
				<definiens id="0">nouns , verbs , adjectives , nominal-verbs , nominaladjectives , etc ) are systematically put into their honorific forms</definiens>
			</definition>
			<definition id="4">
				<sentence>The developed parser constitutes an important part of NADINE ( NAtural Dialogue INterpretation Expert ) , an experimental system which translates Japanese-English telephone and inter-keyboard dialogues .</sentence>
				<definiendum id="0">developed parser</definiendum>
				<definiens id="0">constitutes an important part of NADINE ( NAtural Dialogue INterpretation Expert ) , an experimental system which translates Japanese-English telephone and inter-keyboard dialogues</definiens>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>Limited-commitment planning consists of both prescriptive ( hierarchical expansion ) planning and of restrictive planning ( selecting from options with reference to the status of active goals ) .</sentence>
				<definiendum id="0">Limited-commitment planning</definiendum>
			</definition>
			<definition id="1">
				<sentence>The program consists of over 12,000 lines of T , a dialect of LISP developed at Yale University .</sentence>
				<definiendum id="0">program</definiendum>
				<definiens id="0">consists of over 12,000 lines of T , a dialect of LISP developed at Yale University</definiens>
			</definition>
			<definition id="2">
				<sentence>For conflict resolution , PAULINE uses the least-satisfied strategy : the program chooses the option helping the goals with the lowest total satisfaction status .</sentence>
				<definiendum id="0">PAULINE</definiendum>
				<definiens id="0">uses the least-satisfied strategy : the program chooses the option helping the goals with the lowest total satisfaction status</definiens>
			</definition>
			<definition id="3">
				<sentence>PAULINE uses one of two topicordering plans which are simplified scriptifications of the strategies discussed in \ [ Hobbs 78 , 79\ ] and \ [ Mann &amp; Thompson 83 , 87\ ] .</sentence>
				<definiendum id="0">PAULINE</definiendum>
				<definiens id="0">uses one of two topicordering plans</definiens>
			</definition>
			<definition id="4">
				<sentence>Telegram : A Grammar Formalkm for Language Planning .</sentence>
				<definiendum id="0">Telegram</definiendum>
				<definiens id="0">A Grammar Formalkm for Language Planning</definiens>
			</definition>
			<definition id="5">
				<sentence>Amsterdam : North-Holland Publishing Company .</sentence>
				<definiendum id="0">Amsterdam</definiendum>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>The semantics of the compatibility relation is given by the following conditions : I. ~ -NIL always ; set { ~q/ &lt; Pz &gt; ... .. 4/ &lt; p. &gt; } can be unified ( any member of this set may be undefined ; such members are equivalent to null DGs ) ; Unlike satisfaction , the semantics of compatibility can not be defined by simple induction over conjunctive formulas , because of a subtle interaction between path equivalences and 236 nonexistent features .</sentence>
				<definiendum id="0">The semantics of the compatibility relation</definiendum>
			</definition>
			<definition id="1">
				<sentence>The indefinite component is a list of disjunctions .</sentence>
				<definiendum id="0">indefinite component</definiendum>
				<definiens id="0">a list of disjunctions</definiens>
			</definition>
			<definition id="2">
				<sentence>Descriptions The unification operation , which is commonly used to cornblue feature structures ( i.e. , non-disjunctive , non-conditional DGs ) , can be generalised to define an operation for combLuLug the information of two feature descriptions ( i.e. , formulas of FDL ) .</sentence>
				<definiendum id="0">unification operation</definiendum>
				<definiendum id="1">non-conditional DGs</definiendum>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>ABSTRACT Narrative passages told from a character 's perspective convey the character 's thoughts and perceptions .</sentence>
				<definiendum id="0">ABSTRACT Narrative</definiendum>
				<definiens id="0">passages told from a character 's perspective convey the character 's thoughts and perceptions</definiens>
			</definition>
			<definition id="1">
				<sentence>Subjective sentences include those that portray a character 's thoughts ( represented thought ) or present a scene a~ a character perceives it ( represented perception ) .</sentence>
				<definiendum id="0">Subjective sentences</definiendum>
				<definiens id="0">include those that portray a character 's thoughts ( represented thought ) or present a scene a~ a character perceives it ( represented perception )</definiens>
			</definition>
			<definition id="2">
				<sentence>Banfield calls them subjective elements ; they appear only in subjective sentences and can not appear within objective sentences .</sentence>
				<definiendum id="0">Banfield</definiendum>
				<definiens id="0">calls them subjective elements ; they appear only in subjective sentences and can not appear within objective sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>Banfield identifies perspective in narrative with subjectivity , which is expressible via subjective elements .</sentence>
				<definiendum id="0">Banfield</definiendum>
				<definiens id="0">identifies perspective in narrative with subjectivity , which is expressible via subjective elements</definiens>
			</definition>
			<definition id="4">
				<sentence>The CP determines the current belief space with respect to which references are understood .</sentence>
				<definiendum id="0">CP</definiendum>
				<definiens id="0">determines the current belief space with respect to which references are understood</definiens>
			</definition>
			<definition id="5">
				<sentence>The basic level is the preferred level at which people identify things .</sentence>
				<definiendum id="0">basic level</definiendum>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>Incorporating both a graphical interface and a processor for English discourse , Candide allows a user of the Procedural Reasoning System ( PITS ) \ [ 10\ ] to build and maintain procedural networks in a natural way .</sentence>
				<definiendum id="0">Candide</definiendum>
				<definiendum id="1">Reasoning System</definiendum>
				<definiens id="0">allows a user of the Procedural</definiens>
			</definition>
			<definition id="1">
				<sentence>Each conditional interpretation consists of a sense and a \ [ possibly empty\ ] set of assumptions .</sentence>
				<definiendum id="0">conditional interpretation</definiendum>
				<definiens id="0">consists of a sense and a \ [ possibly empty\ ] set of assumptions</definiens>
			</definition>
			<definition id="2">
				<sentence>A bind assumption introduces a new parameter in an interpretation and places constraints on the binding of the parameter to individuals in the context .</sentence>
				<definiendum id="0">bind assumption</definiendum>
				<definiens id="0">introduces a new parameter in an interpretation and places constraints on the binding of the parameter to individuals in the context</definiens>
			</definition>
			<definition id="3">
				<sentence>Semantic-interpretation rules specify the conditional interpretation of a phrase in terms of the conditional interpretations of its constituents .</sentence>
				<definiendum id="0">Semantic-interpretation rules</definiendum>
			</definition>
			<definition id="4">
				<sentence>Interpretation starts at the root node of the analysis tree .</sentence>
				<definiendum id="0">Interpretation</definiendum>
				<definiens id="0">starts at the root node of the analysis tree</definiens>
			</definition>
			<definition id="5">
				<sentence>For each node of the tree , the interpretation process selects an appropriate semanticinterpretation rule and calls itself recursively for each of the node 's daughters .</sentence>
				<definiendum id="0">interpretation process</definiendum>
			</definition>
			<definition id="6">
				<sentence>The applicability condition specifies the syntactic type of phrase to which the semantic interpretation rule applies ; it is stated in terms of a predicate on trees .</sentence>
				<definiendum id="0">applicability condition</definiendum>
				<definiens id="0">specifies the syntactic type of phrase to which the semantic interpretation rule applies ; it is stated in terms of a predicate on trees</definiens>
			</definition>
			<definition id="7">
				<sentence>Finally , the conditional-interpretation function defines the conditional interpretation of the phrase as a function of the conditional interpretations of its constituents .</sentence>
				<definiendum id="0">conditional-interpretation function</definiendum>
			</definition>
			<definition id="8">
				<sentence>{ bind ( a , argl , device ) } &gt; ¢ I failed 3 ( b , { bind ( b , def , jet ) } ) 4 the 5 qet , 0 ) iet Figure 3 : Interpretation of `` The jet failed '' \ [ iv-clause\ ] : AC : intrans-verb-clause ( T ) SF : pred ( T ) = V , argl ( T ) = A CIF : IT\ ] = ( ~VIs , \ [ VIA U \ [ A\ ] AU { restrict ( argl , = , \ [ A\ ] s ) } ) \ [ def-np\ ] : AC : def-np ( T ) SF : argl ( T ) = N CIF : \ [ ~I = ( z , \ [ N\ ] A U { bind ( z , def , \ [ N\ ] s ) } ) \ [ lex\ ] : AC : lex-ltem ( T ) SF : wordstem ( T ) = W CIF : IT\ ] = Iw Figure 2 : Semantic-Interpretation Rules I ing the derivation of a complete interpretation of the first sentence in ( 3 ) .</sentence>
				<definiendum id="0">{ bind</definiendum>
				<definiendum id="1">CIF</definiendum>
				<definiendum id="2">~I =</definiendum>
				<definiens id="0">def-np ( T ) SF : argl ( T ) = N CIF : \ [</definiens>
			</definition>
			<definition id="9">
				<sentence>attached-~o ( z , j ) , where sip is the subsort of s whose elements satisfy property P. 9In the Candide system as it currently exists , a bind assumption encoding a selectlonal restriction and a restrict assumption encoding the filler of an argument must be discharged as soon as the latter has been is introduced ; otherwise an erroneous interpretation might he derived if the restrict asmarnption is mistakenly applied at a higher clause node .</sentence>
				<definiendum id="0">sip</definiendum>
				<definiens id="0">the subsort of s whose elements satisfy property P. 9In the Candide system as it currently exists , a bind assumption encoding a selectlonal restriction and a restrict assumption encoding the filler of an argument</definiens>
			</definition>
			<definition id="10">
				<sentence>\ [ tv-clause\ ] : AC : trans-verb-clause ( T ) SF : pred ( T ) = V , argl ( T ) = A1 , arg2 = A2 CIF : \ [ T\ ] = ( IV\ ] s , \ [ vh u \ [ A~h u \ [ AZ\ ] AU { restrlct ( argl , -- , \ [ A1\ ] s ) , restrlct ( arg2 , = , \ [ A2\ ] s ) } ) \ [ gen-quant\ ] : AC : gen-quant ( T ) SF : pred ( T ) = Q , argl ( T ) = N ClF : IT\ ] = ( x , \ [ N\ ] Au { bind ( z , \ [ Q\ ] s , \ [ NIs ) } ) \ [ indef-np\ ] : AC : indef-np ( T ) SF : argl ( T ) = N CIF : \ [ T\ ] = ( z , \ [ N\ ] AU { bind ( z , indef , IN\ ] s ) } ) Figure 4 : Semantic-Interpretation Rules II Interpreting ( 7 ) requires additional rules of semantic interpretation , shown in Figure 4 , and the lexical entry /control = ( co , ,~rols ( z , y ) , { bind ( z , argl , device ) , bind ( y , arg2 , device ) } ) Derivations of the 3V and the V'~ interpretations are shown in Figures 5 and 6 , respectively .</sentence>
				<definiendum id="0">argl</definiendum>
				<definiendum id="1">Au { bind</definiendum>
				<definiens id="0">pred ( T ) = V , argl ( T ) = A1</definiens>
				<definiens id="1">indef-np ( T ) SF : argl ( T ) = N CIF : \</definiens>
			</definition>
			<definition id="11">
				<sentence>In our example , the rule converts the conditional interpretation ( con~rots ( a , b ) , { bind ( a , V , driver ) , bind ( b , indef , je0 } ) into the completed interpretation { Ya : driver 3b : jet controls ( a , b ) , qb ) • 7 A Donkey Sentence We can now discuss the more complicated interactions between assumptions occurring in donkey sentences .</sentence>
				<definiendum id="0">conditional interpretation ( con~rots</definiendum>
				<definiens id="0">the completed interpretation { Ya : driver 3b : jet controls ( a , b</definiens>
			</definition>
			<definition id="12">
				<sentence>Pundit does the latter in an overly constrained way , with the result that it can not handle systematically the sort of interactions exemplified by the donkey sentences .</sentence>
				<definiendum id="0">Pundit</definiendum>
				<definiens id="0">does the latter in an overly constrained way , with the result that it can not handle systematically the sort of interactions exemplified by the donkey sentences</definiens>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>( b ) For assertions , the speaker was defined as being in control unless the assertion was made in response to a question , for the same reasons as those given for questions ; an assertion which is a response to a question could not be said to be controlling the discourse ; ( c ) For commands , the speaker was defined as controlling the conversation .</sentence>
				<definiendum id="0">assertion</definiendum>
				<definiens id="0">a response to a question could not be said to be controlling the discourse ; ( c ) For commands</definiens>
			</definition>
</paper>

		<paper id="1030">
			<definition id="0">
				<sentence>ABSTRACT This paper discusses a sequence of deductive parsers , called PAD1 PAD5 , that utilize an axiomatization of the principles and parameters of GB theory , including a restricted transformational component ( Move-a ) .</sentence>
				<definiendum id="0">PAD1 PAD5</definiendum>
				<definiens id="0">that utilize an axiomatization of the principles and parameters of GB theory , including a restricted transformational component ( Move-a )</definiens>
			</definition>
			<definition id="1">
				<sentence>A `` grammar '' for these parsers consists entirely of a set of parameter values that parameterize the principles of GB theory thus the parsers described here can be regarded as `` principlebased ' ( Berwick 1987 ) and the parsers ' toplevel internal structure transparently reflects ( some of ) the principles of that theory ; X '' and @ theory apply at D-structure , Case theory applies at S-structure , Move-or is stated as a relation between Dand S-structure , and LFmovement relates S-structure and LF .</sentence>
				<definiendum id="0">`` grammar</definiendum>
				<definiendum id="1">Move-or</definiendum>
				<definiendum id="2">LFmovement</definiendum>
				<definiens id="0">of a set of parameter values that parameterize the principles of GB theory thus the parsers described here can be regarded as `` principlebased ' ( Berwick 1987 ) and the parsers ' toplevel internal structure transparently reflects ( some of ) the principles of that theory ; X '' and @ theory apply at D-structure , Case theory applies at S-structure</definiens>
				<definiens id="1">relates S-structure and LF</definiens>
			</definition>
			<definition id="2">
				<sentence>To a first approximation , D-structure represents configurationally the thematic or predicateargument structure of the utterance , S-structure represents the utterance 's surface constituent structure , PF represents its phonetic form , and LF ( `` Logical Form '' ) is a configurational representation of the scopal relationships between the quantificational elements present in the utterance .</sentence>
				<definiendum id="0">LF</definiendum>
				<definiens id="0">D-structure represents configurationally the thematic or predicateargument structure of the utterance , S-structure represents the utterance 's surface constituent structure , PF represents its phonetic form</definiens>
				<definiens id="1">a configurational representation of the scopal relationships between the quantificational elements present in the utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>PARSING AS DEDUCTION As just outlined , GB theory decomposes a competent user 's knowledge of a language possessed into two components : ( i ) the universal component ( Univeral Grammar ) , and ( ii ) a set of parameter values and a lexicon , which together constitute the knowledge of that i~articular language above and beyond the universal component .</sentence>
				<definiendum id="0">PARSING AS DEDUCTION</definiendum>
				<definiendum id="1">GB theory</definiendum>
				<definiens id="0">decomposes a competent user 's knowledge of a language possessed into two components : ( i ) the universal component ( Univeral Grammar ) , and ( ii ) a set of parameter values and a lexicon , which together constitute the knowledge of that i~articular language above and beyond the universal component</definiens>
			</definition>
			<definition id="4">
				<sentence>Only after all of the principles have applied to the Sstructure node instantiated by the `` phonology '' relation and the corresponding D-structure node ( s ) instantiated by Move-a are any further inferences associated with the 'phonology '' relation performed , causing the instantiation of further S-structure nodes and the repetition of the cycle of activation and delaying .</sentence>
				<definiendum id="0">corresponding D-structure node</definiendum>
				<definiendum id="1">Move-a</definiendum>
				<definiens id="0">causing the instantiation of further S-structure nodes and the repetition of the cycle of activation and delaying</definiens>
			</definition>
			<definition id="5">
				<sentence>The PAD3 parser uses the same parameter values and lexicon as PAD1 and PAD2 , but it uses a reaxiomatization of Universal Grammar obtained by applying the Unfold/Fold transformation described and proven correct by Tamaki and Sato ( 1984 ) and Kanamori and Horiuchi ( 1988 ) .</sentence>
				<definiendum id="0">PAD3 parser</definiendum>
				<definiens id="0">uses the same parameter values and lexicon as PAD1 and PAD2 , but it uses a reaxiomatization of Universal Grammar obtained by applying the Unfold/Fold transformation described and proven correct by Tamaki and Sato</definiens>
			</definition>
			<definition id="6">
				<sentence>The PAD5 parser uses the resulting predicate as its axiomatization of Universal Grammar , thus PAD5 is a parser which uses exactly the same parameter values and lexicon as the earlier parsers to compute exactly the same PF-LF relationship as these parsers , but it does so without explictly constructing either Dstructures or S-structure~ To summarize , this section presents three new parsers .</sentence>
				<definiendum id="0">PAD5</definiendum>
				<definiens id="0">a parser which uses exactly the same parameter values and lexicon as the earlier parsers to compute exactly the same PF-LF relationship as these parsers , but it does so without explictly constructing either Dstructures or S-structure~ To summarize</definiens>
			</definition>
</paper>

		<paper id="1034">
			<definition id="0">
				<sentence>Combinatory Categorial Grammar ( CCG ) , as defined here , is the most recent version of a system that has evolved in a number of papers \ [ 1,12,9,10,11\ ] .</sentence>
				<definiendum id="0">Combinatory Categorial Grammar ( CCG )</definiendum>
			</definition>
			<definition id="1">
				<sentence>A CCG , G , is denoted by ( VT , VN , S , f , R ) where VT is a finite set of terminals ( lexical items ) , VN is a finite set of nonterminals ( atomic categories ) , S is a distinguished member of VN , f is a function that maps elements of VT U { e } to finite subsets of C ( VN ) , the set of categories* , where V N g C ( VN ) and if CI , C 2 e C ( VN ) then ( el/c2 ) E C ( VN ) and ( c1\c2 ) E C ( VN ) .</sentence>
				<definiendum id="0">CCG , G</definiendum>
				<definiendum id="1">VT</definiendum>
				<definiendum id="2">VN</definiendum>
				<definiendum id="3">S</definiendum>
				<definiendum id="4">f</definiendum>
				<definiendum id="5">E C ( VN</definiendum>
				<definiens id="0">a finite set of terminals ( lexical items ) ,</definiens>
				<definiens id="1">a finite set of nonterminals ( atomic categories ) ,</definiens>
				<definiens id="2">a distinguished member of VN</definiens>
				<definiens id="3">a function that maps elements of VT U { e } to finite subsets of C ( VN ) , the set of categories* , where V N g C ( VN ) and if CI</definiens>
			</definition>
			<definition id="2">
				<sentence>R is a finite set of combinatory rules , described below .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">a finite set of combinatory rules , described below</definiens>
			</definition>
			<definition id="3">
				<sentence>An LIG , G , is denoted by G = ( Vjv , VT , Vs , S , P ) where VN iS a finite set of nontenninals , VT is a finite set of terminals , Vs is a finite set of stack symbols , S E VN is the start symbol , and P is a finite set of productions , having the form A\ [ \ ] A\ [ .</sentence>
				<definiendum id="0">VT</definiendum>
				<definiendum id="1">Vs</definiendum>
				<definiendum id="2">S E VN</definiendum>
				<definiendum id="3">P</definiendum>
				<definiens id="0">a finite set of terminals</definiens>
				<definiens id="1">a finite set of stack symbols</definiens>
				<definiens id="2">the start symbol</definiens>
			</definition>
			<definition id="4">
				<sentence>a~P The language , L ( G ) , generated by G is A TAG \ [ 8,7\ ] is denoted G = ( VN , VT , S , I , A ) where VN is a finite set of nontennlnals , VT is a finite set of terminals , S is a distinguished nonterminal , I is a finite set of initial trees and A is a finite set of auxiliary trees .</sentence>
				<definiendum id="0">VN</definiendum>
				<definiendum id="1">VT</definiendum>
				<definiendum id="2">S</definiendum>
				<definiendum id="3">A</definiendum>
				<definiens id="0">a finite set of nontennlnals</definiens>
				<definiens id="1">a finite set of terminals</definiens>
			</definition>
			<definition id="5">
				<sentence>The siring language L ( G ) generated by a TAG , G , is the set of all strings lYing on the frontier of some tree that can be derived from an initial trees with a finite number of adjunctions , where that tree has no OA constraints .</sentence>
				<definiendum id="0">siring language L</definiendum>
				<definiens id="0">the set of all strings lYing on the frontier of some tree that can be derived from an initial trees with a finite number of adjunctions</definiens>
			</definition>
			<definition id="6">
				<sentence>Let the set Dc ( G ) he defined as follows .</sentence>
				<definiendum id="0">Let the set Dc</definiendum>
			</definition>
			<definition id="7">
				<sentence>c E De ( G ) if c is a component of d where c ' E f ( a ) for some a E VT U { e } .</sentence>
				<definiendum id="0">c E De</definiendum>
				<definiens id="0">a component of d where c ' E f ( a ) for some a E VT U { e }</definiens>
			</definition>
			<definition id="8">
				<sentence>Clearly for any CCG , G , Dc ( G ) is a finite set .</sentence>
				<definiendum id="0">Dc ( G )</definiendum>
				<definiens id="0">a finite set</definiens>
			</definition>
			<definition id="9">
				<sentence>283 TAG derivation trees encode the adjanction of specified elementary trees at specified nodes of other elementary trees .</sentence>
				<definiendum id="0">TAG derivation trees</definiendum>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>The reduce action reduces top elements of the stack according to a context-free phrase structure rule in the grammar .</sentence>
				<definiendum id="0">reduce action</definiendum>
				<definiens id="0">reduces top elements of the stack according to a context-free phrase structure rule in the grammar</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>UDICT is a dictionary system intended to support the lexical needs of computer programs that do natural language processing ( NLP ) .</sentence>
				<definiendum id="0">UDICT</definiendum>
				<definiens id="0">a dictionary system intended to support the lexical needs of computer programs that do natural language processing ( NLP )</definiens>
			</definition>
			<definition id="1">
				<sentence>Consequently , UDICVs word grammar contains affix rules which express conditions on the base word and makes assertions about the affixed word .</sentence>
				<definiendum id="0">UDICVs word grammar</definiendum>
				<definiens id="0">contains affix rules which express conditions on the base word and makes assertions about the affixed word</definiens>
			</definition>
			<definition id="2">
				<sentence>( Byrd ( 1983 ) describes further possible distinctions which have so far not been exploited in the French system . )</sentence>
				<definiendum id="0">Byrd</definiendum>
				<definiens id="0">describes further possible distinctions which have so far not been exploited in the French system</definiens>
			</definition>
			<definition id="3">
				<sentence>`` C '' represents an arbitrary consonant , `` D '' represents t or I , and `` = '' represents a repeated letter . )</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">`` = ''</definiendum>
				<definiens id="0">an arbitrary consonant , `` D '' represents t or I , and</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>PROCESSING FRAGMENTS IN PUNDIT Although the initial PUNDIT system wu designed to handle full , as opposed to fragmentary , sentences , one of the interesting results of our work is that it has required only very minor changes to the system to handle the basic fragment types introduced below .</sentence>
				<definiendum id="0">PROCESSING FRAGMENTS IN PUNDIT Although</definiendum>
				<definiens id="0">the initial PUNDIT system wu designed to handle full</definiens>
			</definition>
			<definition id="1">
				<sentence>This gap is permitted in most contexts where nstKo ( noun phrase object ) is found : as a direct object of the verb and as an object of a preposition .</sentence>
				<definiendum id="0">nstKo</definiendum>
				<definiens id="0">a direct object of the verb and as an object of a preposition</definiens>
			</definition>
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>L denotes some fixed mapping from grammars to languages : If G is a grammar , L ( G ) denotes the language generated by-it .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">L ( G )</definiendum>
				<definiens id="0">some fixed mapping from grammars to languages : If G is a grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>A &amp; B denotes the symmetric difference , i.e. ( A -- B ) U ( B -A ) .</sentence>
				<definiendum id="0">B</definiendum>
			</definition>
			<definition id="2">
				<sentence>Then , the degree of locality of r , written locality ( r ) , is defined as follows , locality ( r ) -- -card { ( p , q , n ) I there is an edge in r from a node labeled with p to another labeled with q , and is itself labeled with ~ } The degree of locality of a grammar is the maximum of those of M1 its derivations .</sentence>
				<definiendum id="0">locality of a grammar</definiendum>
				<definiens id="0">the degree of locality of r , written locality ( r ) , is defined as follows , locality ( r ) -- -card { ( p , q , n ) I there is an edge in r from a node labeled with p to another labeled with q , and is itself labeled with ~ } The degree of</definiens>
			</definition>
			<definition id="3">
				<sentence>G is in k.local normal form , i.e. there is an index set I such that G = ( I2r , Ui¢~i , S , { S -* Si I i E I } U ( Ui¢IRi ) ) , and if we let Gi -~ ( ~T , ~ , , Si , Ri ) for each i E I , then ( a ) Each G~ is `` k.simple '' ; Vi E I \ [ Ri \ [ &lt; _ k &amp; : NTO ( R~ ) &lt; _ k. 11 ( b ) Each G , has size bounded by size ( G ) ; Vi E I size ( G , ) = O ( n ) ( c ) All Gi 's have disjoint nonterminal sets ; vi , j ~ I ( i # j ) -r. , n r~ , = ¢ , .</sentence>
				<definiendum id="0">G</definiendum>
				<definiendum id="1">NTO</definiendum>
				<definiens id="0">R~ ) &lt; _ k. 11 ( b ) Each G , has size bounded by size ( G ) ; Vi E I size ( G , ) = O ( n ) ( c ) All Gi 's have disjoint nonterminal sets</definiens>
			</definition>
			<definition id="4">
				<sentence>( We define the `` terminal yield '' of a rule body R to be h ( R ) , where h is a homomorphism that preserves termins2 symbols and deletes nonterminal symbols . )</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">h</definiendum>
				<definiens id="0">the `` terminal yield '' of a rule body R to be h (</definiens>
				<definiens id="1">a homomorphism that preserves termins2 symbols and deletes nonterminal symbols</definiens>
			</definition>
			<definition id="5">
				<sentence>~/EIGHTED-SET-COVER ( WSC ) INSTANCE : ( X , Y , w ) where X is a finite set and Y is a subset of ~ ( X ) and w is a function from Y to N + .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">a finite set</definiens>
				<definiens id="1">a subset of ~</definiens>
			</definition>
			<definition id="6">
				<sentence>Intuitively , Y is a set of subcovers of the set X , each associated with its 'weight ' .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">a set of subcovers of the set X</definiens>
			</definition>
			<definition id="7">
				<sentence>Algorithm B : ( ( X , Y , w ) ) mazweight : = maz { to ( y ) \ [ Y E Y ) m : -\ [ log mazweight\ ] /* this loop gets an approximate solution using C for subsets of Y each defined by putting an upperbound on the weights */ Fori -- 1 tomdo : Y\ [ i\ ] : = { lr/\ [ Y E Y &amp; to ( Y ) &lt; 2 ' } s\ [ , \ ] : = c ( ( x , Y\ [ , \ ] ) ) End/* For */ /* this loop replaces all 'bad ' ( i.e. does not cover X ) solutions with Y the solution with the maximum total weight */ Fori= ltomdo : s\ [ , \ ] : = s\ [ , \ ] if cover ( s\ [ i\ ] ) -- -X : = Y otherwise End/* For */ ~intotaltoelght : = ~i. { totaltoeight ( s\ [ j\ ] ) I J ¢ \ [ m\ ] } Return s\ [ min { i I totaltoeig h t ( s\ [ 'l ) -- mintotaitoeig ht } \ ] End /* Algorithm B */ Time Analysis Clearly , Algorithm B runs in time polynomial in the instance size , since Algorithm C runs in time polynomial in the instance size and there are only m -- -~logmazweight\ ] cMls to it , which certainly does not exceed the instance size .</sentence>
				<definiendum id="0">'bad '</definiendum>
				<definiens id="0">s\ [ j\ ] ) I J ¢ \ [ m\ ] } Return s\ [ min { i I totaltoeig h t ( s\ [ 'l ) -- mintotaitoeig ht } \ ] End /* Algorithm B */ Time Analysis Clearly</definiens>
			</definition>
			<definition id="8">
				<sentence>= x log n ) , where to* is the total weight of a minimal weight cover and nflX \ [ .</sentence>
				<definiendum id="0">to*</definiendum>
				<definiens id="0">the total weight of a minimal weight cover</definiens>
			</definition>
			<definition id="9">
				<sentence>In other words , we let ~r = { mingrammar ( y ) \ [ y E IJ ( ( S+L , Y , w ) ) } where mingrammar ( g ) is a minimal-size grammar H in FGrams ( k , SL ) such that L ( H ) N S + = y. The final output 8ra~nmar H will be the =disjoint union '' of all the grammars in /~ , i.e. H -- -Ip ( H ) .</sentence>
				<definiendum id="0">mingrammar ( g )</definiendum>
				<definiens id="0">the =disjoint union '' of all the grammars in /~</definiens>
			</definition>
			<definition id="10">
				<sentence>size ( O ) ~_ size ( Rei ( G , S+ ) ) is also bounded by a polynomial in the size of a minimal grammar consistent with SL .</sentence>
				<definiendum id="0">Rei</definiendum>
				<definiens id="0">also bounded by a polynomial in the size of a minimal grammar consistent with SL</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>Syn-pos ( syn-pos relation head sub-constituent ) , indicates that the sub-constituent is the relation of the head .</sentence>
				<definiendum id="0">Syn-pos</definiendum>
				<definiens id="0">syn-pos relation head sub-constituent ) , indicates that the sub-constituent is the relation of the head</definiens>
			</definition>
			<definition id="1">
				<sentence>The correspondence between trees and formulas is as follows : Trees s -up ( vp ... head-v ... ) vp ... . head-v np ... vp ~ ... head-v npl np2 ... vp ... . head-v ... ( pp prep ... ) pp ~ prep np Formulas ( syn-pos subject head-v np ) head-v symbol is s symbol ( syn-pos object head-v up ) ( syn-pos indirect-object head-v npl ) ( syn-pos object head-v npg ) ( syn-pp head-prep head-v prep ) ( -yn-pp prel &gt; -np prep rip ) np - ... head-n ... head-n symbol is np symbol np -pronoun pronoun symbol is np symbol np -propernoun propernoun symbol is np symbol np ... . adj head-n ... ( syn-pos adj adj head-n ) np ... . head-n ... ( pp prep ... ) up that s s -np ( vp ... copula ( pp prep ... ) ) s -np ( vp ... copula adj ) ( syn-pp head-prep head-n prep ) s symbol is np symbol ( syn-pp head-prep np prep ) ( syn-pos adj ad3 np ) This is enough to express a wide variety of simple declarative sentences .</sentence>
				<definiendum id="0">prep np Formulas</definiendum>
				<definiens id="0">syn-pos subject head-v np ) head-v symbol is s symbol ( syn-pos object head-v up ) ( syn-pos indirect-object head-v npl ) ( syn-pos object head-v npg ) ( syn-pp head-prep head-v prep ) ( -yn-pp prel &gt; -np prep rip ) np - ... head-n ... head-n symbol is np symbol np -pronoun pronoun symbol is np symbol np -propernoun propernoun symbol is np symbol np ...</definiens>
				<definiens id="1">syn-pp head-prep head-n prep ) s symbol is np symbol ( syn-pp head-prep np prep ) ( syn-pos adj ad3 np</definiens>
			</definition>
			<definition id="2">
				<sentence>Next , Frail uses an ATMS \ [ 9,10\ ] to keep track of disjunctions .</sentence>
				<definiendum id="0">Frail</definiendum>
				<definiens id="0">uses an ATMS \ [ 9,10\ ] to keep track of disjunctions</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>Nlgel follows general systemic-functlonni linguistics ( SFL ) practice in presenting grammar as a resource for expressing meanings ; meanings are realized by a network of interlocking options and ps_ , -ticular grammatical forms are arrived at by making choices In this network .</sentence>
				<definiendum id="0">Nlgel</definiendum>
				<definiens id="0">follows general systemic-functlonni linguistics ( SFL ) practice in presenting grammar as a resource for expressing meanings ; meanings are realized by a network of interlocking options</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>ing to the same node ) between the path ( p ) and the actual path relative to the top-level structure.2 The denotation of a formula @ is usually defined as the set of minimal elements of SAT ( ~ ) with respect to subsumption 3 , where SAT ( @ ) is the set denotation of ( p ) may only be computed with respect to the whole structure that the formula describes .</sentence>
				<definiendum id="0">SAT ( @ )</definiendum>
				<definiens id="0">the same node ) between the path ( p ) and the actual path relative to the top-level structure.2 The denotation of a formula @ is usually defined as the set of minimal elements of SAT ( ~ ) with respect to subsumption 3</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>( Modification involved any word or phrase in the definition that modified the headword ; thus a definition such as `` cube : a regular solid ... '' would yield the modification triple ( cube MOD regular ) ) .</sentence>
				<definiendum id="0">Modification</definiendum>
				<definiens id="0">involved any word or phrase in the definition that modified the headword</definiens>
				<definiens id="1">a regular solid ... '' would yield the modification triple ( cube MOD regular ) )</definiens>
			</definition>
			<definition id="1">
				<sentence>We also identified 125 other relations , in three categories : ( 1 ) `` traditional '' relmions , identified by previous researchers , which we hope to associate with axioms for making inferences ; ( 2 ) syntactic relations between the defined word and various defining words , such as ( in a verb definition ) the direct object of the head verb , which we will investigate for possible consistent semantic significance ; and ( 3 ) syntactic relations within the body of the definition , such as modifier-head , verbobject , etc , The relations in this last category were built into our grammar ; , we were simply collecting s_t~_ti $ ~ics on their occurrence , which we hope even .</sentence>
				<definiendum id="0">verb</definiendum>
				<definiens id="0">in a verb definition ) the direct object of the head</definiens>
			</definition>
			<definition id="2">
				<sentence>( A run-on is a subentry , giving information about a word or phrase derived from the entry word or phrase ; for instance , the verb run has the run-ons run across , run ~fter , and run a temperature among others ; the noun rune has the run-on adjective runic . )</sentence>
				<definiendum id="0">run-on</definiendum>
				<definiens id="0">a subentry , giving information about a word or phrase derived from the entry word or phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>warning } of danger ( 29 ) aitatus 0 0 n a { divine } 7 imparting } of knowledge or power The result of all this effort is a rudimentary parsing system , in which the tagged vocabulary is the lexicon , the tagging program is the lexical analyzer , and the head finder is a syntax analyzer using a very simple finite state grammar of about ten rules .</sentence>
				<definiendum id="0">vocabulary</definiendum>
				<definiens id="0">a rudimentary parsing system , in which the tagged</definiens>
			</definition>
			<definition id="4">
				<sentence>( cube 1 1 ) T ( solid 3 1 ( the ) ( regular ) ( of ( side 1 6b ( PL ) ( six ) • ( equal ) ( square } ) ) ) ( dodecahedron 0 0 ) T ( solid 3 1 ( a ) ( have ( OBJ ( face 1 5a5 ( PL ) ( 12 ) ( plane ) ) ) ) ) ( icosahedron 0 0 ) T ( polyhedron ( a ) ( have ( OBJ ( face 1 5a5 ( PL ) ( 20 ) ) ) ) ) ( octahedron 0 O ) T ( solid 3 1 ( a ) ( bound ( SUBJ ( face 1 5a5 ( PL ) ( eight ) ( plane ) ) ) ) ) ( tetrahedron 0 0 ) T ( polyhedron ( a ) ( of ( face 1 5a5 ( PL ) ( four ) ) ) ) ( polyhedron 0 0 ) T ( solid 3 1 ( a ) ( form ( SUBJ ( face 1 5a5 ( PL ) ( plane ) ) ) ) ) ( solid 3 1 ) T ( figure ( a ) ( geometrical ) ( have ( OBJ ( dimension ( PL ) ( three ) ) ) ) ) ( face 1 5a5 ) T ( surface 1 2 ( plane ) ( bound ( OBJ ( solid 3 1 ( a ) ( geometric ) ) ) ) ) ( side 1 6a ) T ( line ( a ) ( bound ( OBJ ( NULL ) ) ) ( of ( figure ( a ) ( geometrical ) ) ) ) ( side 1 6b ) T ( surface 1 2 ( delimit ( OBJ ( solid ( a ) ) ) ) ) ( surface 1 2 ) T ( locus ( a ) ( or ( plane ) ( curved ) ) ( two-dimensional ) ( of ( point ( PL ) ) . . . ) ) Figure 2 .</sentence>
				<definiendum id="0">T</definiendum>
				<definiendum id="1">PL</definiendum>
				<definiendum id="2">PL</definiendum>
				<definiendum id="3">PL</definiendum>
				<definiendum id="4">OBJ</definiendum>
				<definiendum id="5">1 ( a )</definiendum>
				<definiendum id="6">OBJ</definiendum>
				<definiens id="0">octahedron 0 O ) T ( solid 3 1 ( a ) ( bound ( SUBJ ( face 1 5a5 ( PL ) ( eight ) ( plane ) ) ) ) ) ( tetrahedron 0 0</definiens>
				<definiens id="1">a ) ( bound ( OBJ ( NULL ) ) ) ( of ( figure ( a ) ( geometrical ) ) ) ) ( side 1 6b</definiens>
				<definiens id="2">solid ( a ) ) ) ) ) ( surface 1 2 ) T ( locus ( a ) ( or ( plane ) ( curved ) ) ( two-dimensional )</definiens>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>Daring1 is a time during the being-a-secretary event , and During2 is a time during the testifying event .</sentence>
				<definiendum id="0">Daring1</definiendum>
				<definiendum id="1">During2</definiendum>
				<definiens id="0">a time during the being-a-secretary event</definiens>
				<definiens id="1">a time during the testifying event</definiens>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>In this approach , the representation of the noun phrase `` Peter 's s/stern'would be : { x • SISTERS / POSSESS ( PETER , x ) } , where SISTERS denotes the set of persons who are a sister , and POSSESS represents the possessive relation indicated by the genitive construction .</sentence>
				<definiendum id="0">SISTERS</definiendum>
				<definiendum id="1">POSSESS</definiendum>
				<definiens id="0">the set of persons who are a sister</definiens>
				<definiens id="1">the possessive relation indicated by the genitive construction</definiens>
			</definition>
			<definition id="1">
				<sentence>\ [ 1\ ] \ [ 10\ ] In this approach , interpreting a natural language sentence is a multi-stage process , which starts out with a high-level meaning representation which reflects the semantic structure of the English sentence rather directly , and then applies translation rules which specify how the English-oriented semantic primitives relate to the ones that are used at deeper levels of analysis .</sentence>
				<definiendum id="0">multi-stage process</definiendum>
				<definiens id="0">starts out with a high-level meaning representation which reflects the semantic structure of the English sentence rather directly , and then applies translation rules which specify how the English-oriented semantic primitives relate to the ones that are used at deeper levels of analysis</definiens>
			</definition>
			<definition id="2">
				<sentence>In WML , for instance , FREDERICK has the type SHIPS which denotes the set of all ships ; GUAM and INDIAN-OCEAN have the type LOCATIONS which denotes the set of all locations ; CARRIERS and SHIPS both have the type SETS ( SHIPS ) which denotes the powerset of the set of all ships ; F-SPEED has the type FUNC TIONS ( U ( SHIPS , PLANES , LAND-VEHICLES ) , AMOUNTS ( SPEED .</sentence>
				<definiendum id="0">FREDERICK</definiendum>
				<definiendum id="1">SHIPS</definiendum>
				<definiendum id="2">F-SPEED</definiendum>
				<definiens id="0">the set of all ships</definiens>
				<definiens id="1">the set of all locations</definiens>
				<definiens id="2">the powerset of the set of all ships</definiens>
			</definition>
			<definition id="3">
				<sentence>UNITS ) ) , which denotes the set of functions whose domain is the union of the sets of ships , of planes and of land vehicles , and whose range is the set of amountexpressions whose units are members of the set of speed-units .</sentence>
				<definiendum id="0">UNITS ) )</definiendum>
				<definiens id="0">the set of functions whose domain is the union of the sets of ships , of planes and of land vehicles</definiens>
				<definiens id="1">the set of amountexpressions whose units are members of the set of speed-units</definiens>
			</definition>
			<definition id="4">
				<sentence>28 ( 6 ) `` Peter 's sisters '' ( 6a ) { x ~ R-SISTER / POSSESS ( PETER , x ) } , where R-SISTER , with the type 7 U ( MALES , FEMALES ) X FEMALES , denotes the extension of the sister-relation , and where POSSESS has as one of its types : FUNCTIONS ( ( U ( MALES , FEMALES ) X FEMALES ) , TRUTHVALUES ) .</sentence>
				<definiendum id="0">PETER</definiendum>
				<definiendum id="1">R-SISTER</definiendum>
				<definiens id="0">the extension of the sister-relation , and where POSSESS has as one of its types : FUNCTIONS ( ( U</definiens>
			</definition>
			<definition id="5">
				<sentence>`` Some brothers are John's ' ) We shall now consider the actual EFL-to-WML 7Notation : A X B denotes the set of pairs &lt; x.y &gt; such that x is in the denotation of A and y is in the denotation of B. translation rules which handle the relational nouns in a little more detail .</sentence>
				<definiendum id="0">X B</definiendum>
				<definiens id="0">the set of pairs &lt; x.y &gt; such that x is in the denotation of A and y is in the denotation of B. translation rules which handle the relational nouns in a little more detail</definiens>
			</definition>
			<definition id="6">
				<sentence>Therefore , READINESS-OF is a function which maps two arguments , an element of SHIPS and an element of READINESS-AREAS , into READINESS-VALUES .</sentence>
				<definiendum id="0">READINESS-OF</definiendum>
				<definiens id="0">a function which maps two arguments , an element of SHIPS and an element of READINESS-AREAS , into READINESS-VALUES</definiens>
			</definition>
			<definition id="7">
				<sentence>It transforms OF ( x , FREDERICK ) into x\ [ 1\ ] \ [ 1\ ] , FREDERICK The net result of these logical and descriptive transformations is the following expression : { x ~ { z • ( SHIPS X READINESS-AREAS ) X READINESS-VALUES / READINESS-OF ( # 1\ ] ) , , z\ [ 2\ ] } / # 1\ ] \ [ 1\ ] , , FREDERICK } This expression is then simplified to : { z G ( { FREDERICK~ X READINESS-AREAS ) X READINESS-VALUES / READINESS-OF ( z\ [ 1\ ] ) , z\ [ 2\ ] } which in its turn can be transformed into a logically equivalent but more optimally evaluable expressions : ( for : { FREDERICK } X READINESF-AREAS , apply : ~ x : &lt; x , READINESS-OF ( x ) &gt; ) ) ( The actual system may apply further transformations ( from WML into DBL ) , if it has to account for discrepancles between the database structure and the canonical domain model , possibly followed by further optJmizations at the DBL leveL ) Other restrictions on `` readiness ; as in `` the readiness o.n.n personnel ' , `` the personnel readiness , or `` a c l readiness ' , are handled in an analogous manner : ON - &gt; ~u , v : u\ [ l\ ] \ [ 2\ ] , ,v ) PREMOD , , &gt; ( ~ u , v : u\ [ l\ ] \ [ 2\ ] , , v ) PREMOD , , &gt; ~ u , v : u\ [ 2\ ] v ) where PREMOD is the EFL translation of the elided relation in a noun-noun compound .</sentence>
				<definiendum id="0">PREMOD</definiendum>
				<definiens id="0">the EFL translation of the elided relation in a noun-noun compound</definiens>
			</definition>
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>( Thh is one of the strong motivations for our recent movement toward building a new CUG-based morphology system . )</sentence>
				<definiendum id="0">Thh</definiendum>
			</definition>
			<definition id="1">
				<sentence>~ Figure 2 : \ [ result : \ [ cat : \ [ \ ] index : \ [ \ ] agr : \ [ \ ] feats : \ [ l type : \ [ \ ] elements : \ [ \ ] order : \ [ \ ] arguments : \ [ \ ] \ ] &lt; the syntactic type of ( ~ &lt; relative linear position of ( ~ &lt; grammatical agreement features of o &lt; ( optional ) &lt; pragmatic agreement features of ~- , &lt; the functional type of ¢x ( see below ) &lt; elements within c~ &lt; order of elements ( see below ) &lt; arguments sought ( see below ) l~lure2. Tae notation for a word whose resulting structure is ot A ca~gnry is either SATURXT~D ( looking for no argumen0 or UNSATU~TED ( needing to combine with one or more arguments ) . It is saturated when the value of ARGUMENTS is 'closed ' with symbol # . An unsaturated category may seek one or more arguments , each of which is either unspecified ( \ [ \ ] ) or typed ( e.g. \ [ cat : N\ ] ) . Overall • saturation is sought in parsing. The parser assigns index numbers to words in the input string from left to right , and coindexes corresponding subsWactares under ELEMENTS. The ELEMENTS component currently has A for the word for which this structure is defined , B for the first argument , and C for the second argument. These labels simply flag PATHS for accessing particular elements. There can be any number of order-relevant labels corresponding to an element. These labels , with coindices with respective elements , are in the ORDER component , which is subject to the Word Order ConsU'alnt ( discussed later ) . TYPE is the slot for assigning the pseudo-functional category ARG or NON-ARG that we found significant in the present cross-linguistic treatment of nominals ( see below ) . AGR ( eement ) and FEATS subgraphs contain grammatical and pragmatic agreement features , respectively ( discussed later ) . 196 atomic templates % SG-NO -- ARGUMEN'I~ : \ [ arguments : # \ ] &lt; saturates the category $ SG-LEX : \ [ result : \ [ elements : \ [ a : \ [ lex : \ [ \ ] \ ] \ ] \ ] \ ] &lt; has a slot foe the word form % SG-WORD-FEATS-ARF~TOP-FEATS : &lt; passes the word 's own features to the top \ [ result : \ [ feats : &lt; 1 &gt; elements : \ [ a : \ [ feats : 1\ [ \ ] 1111 inheritance of composite templates % SG-WO RDFEATS-ARE-TOP-FEATS $ SG-LEX `` , , , / JA-N EN-N FR-N GEoN AR-N FISUm 3 .</sentence>
				<definiendum id="0">ca~gnry</definiendum>
				<definiendum id="1">TYPE</definiendum>
				<definiens id="0">either SATURXT~D ( looking for no argumen0 or UNSATU~TED ( needing to combine with one or more arguments</definiens>
				<definiens id="1">subject to the Word Order ConsU'alnt ( discussed later ) .</definiens>
			</definition>
			<definition id="2">
				<sentence>The NONARG nouns become 'complete ' ARG nominals either by being modified with deteTmin~ 's of by chmsing int~ mass nouns ( typically changing an object reference into a property/substance mfe~nce , e.g. , i uaed app/ , /n my p/e . )</sentence>
				<definiendum id="0">NONARG nouns</definiendum>
				<definiens id="0">become 'complete ' ARG nominals either by being modified with deteTmin~ 's of by chmsing int~ mass nouns ( typically changing an object reference into a property/substance mfe~nce</definiens>
			</definition>
			<definition id="3">
				<sentence>see ~ , ur , s. Non-universal determiner category : In the present ~roach , DET ( enniner ) is a modifimtype ( including &amp; ticks , demonstratives , quantifiers , numerals , and possessives ) such that at least one of its members is needed for making an ARG nominal out of a NON-ARG .</sentence>
				<definiendum id="0">DET ( enniner )</definiendum>
			</definition>
			<definition id="4">
				<sentence>The other is the place of demonslralives in relation to DET. Eve~ language has demonstratives encoding two or tluue degre~ of speaker proximity ( e.g. JAPANESE : kono ( close to the speaker ) , sow ( close to the addressee ) , 61n implementation , this latter process may be triggered by a unary rule COUNT- &gt; MASS. 7They are assigned a NON-ARG category MN ( for 'modified noun ' ) separate from the ARG category N. Any modifier changes it into ARG .</sentence>
				<definiendum id="0">JAPANESE</definiendum>
				<definiens id="0">the place of demonslralives in relation to DET. Eve~ language has demonstratives encoding two or tluue degre~ of speaker proximity</definiens>
			</definition>
			<definition id="5">
				<sentence>• MOD is a categm'y-comtant functor ( XIX ) that combines with HEAD ( X ) .</sentence>
				<definiendum id="0">MOD</definiendum>
			</definition>
			<definition id="6">
				<sentence>( see above for SGMOB ) • FN is a category-non-comtant functor ( YIX ) that combines with ARG ( X ) .</sentence>
				<definiendum id="0">FN</definiendum>
				<definiens id="0">a category-non-comtant functor ( YIX ) that combines with ARG ( X )</definiens>
			</definition>
			<definition id="7">
				<sentence>A postpositionai laaguage ( i.e. a language that uses only or predominantly postpositions ) then belongs to TYPE 1 ( ARG &lt; FN ) , and a prepositional language belongs to TYPE 2 ( FN &lt; ARG ) .</sentence>
				<definiendum id="0">postpositionai laaguage</definiendum>
				<definiens id="0">a language that uses only or predominantly postpositions</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>SEAFACT ( Semantic Analysis For the Animation of Cooking Tasks ) is a natural language interface to a computer-generated animation system operating in the domain of cooking tasks .</sentence>
				<definiendum id="0">SEAFACT</definiendum>
				<definiens id="0">a natural language interface to a computer-generated animation system operating in the domain of cooking tasks</definiens>
			</definition>
			<definition id="1">
				<sentence>Introduction SEAFACT is a natural language interface to a computer-generated animation system ( Karlin , 1988 ) .</sentence>
				<definiendum id="0">SEAFACT</definiendum>
			</definition>
			<definition id="2">
				<sentence>The representation consists of a decomposition of verbs into primitive actions which are semantically interpretable by the motion synthesis procedures .</sentence>
				<definiendum id="0">representation</definiendum>
				<definiens id="0">consists of a decomposition of verbs into primitive actions which are semantically interpretable by the motion synthesis procedures</definiens>
			</definition>
			<definition id="3">
				<sentence>A culmination is an event which the speaker views as accompanied by a transition to a new state of the world .</sentence>
				<definiendum id="0">culmination</definiendum>
				<definiens id="0">an event which the speaker views as accompanied by a transition to a new state of the world</definiens>
			</definition>
			<definition id="4">
				<sentence>Freeze is a culminated process and once the culmination has taken place the new state of the substance makes a repetition of the process redundant .</sentence>
				<definiendum id="0">Freeze</definiendum>
				<definiens id="0">a culminated process and once the culmination has taken place the new state of the substance makes a repetition of the process redundant</definiens>
			</definition>
			<definition id="5">
				<sentence>In the SEAFACT implementation these values consist of cardinal numbers which specify the length of an interval between repetitions of the action , expressed as a percentage of the total time period .</sentence>
				<definiendum id="0">SEAFACT implementation</definiendum>
				<definiens id="0">these values consist of cardinal numbers which specify the length of an interval between repetitions of the action , expressed as a percentage of the total time period</definiens>
			</definition>
			<definition id="6">
				<sentence>BUP accepts an extended phrase structure grammar .</sentence>
				<definiendum id="0">BUP</definiendum>
				<definiens id="0">accepts an extended phrase structure grammar</definiens>
			</definition>
			<definition id="7">
				<sentence>The rules consist of the intermediate semantic representation and tests for rule application .</sentence>
				<definiendum id="0">rules</definiendum>
				<definiens id="0">consist of the intermediate semantic representation and tests for rule application</definiens>
			</definition>
			<definition id="8">
				<sentence>The intermediate semantic representation consists of roles and their values , which are taken from the input sentence .</sentence>
				<definiendum id="0">semantic representation</definiendum>
				<definiens id="0">consists of roles and their values , which are taken from the input sentence</definiens>
			</definition>
			<definition id="9">
				<sentence>SEAFACT includes a number of knowledge bases which are implemented using DC-RL , a frame-based knowledge representation language ( Cebula , 1986 ) .</sentence>
				<definiendum id="0">SEAFACT</definiendum>
				<definiens id="0">includes a number of knowledge bases which are implemented using DC-RL , a frame-based knowledge representation language</definiens>
			</definition>
			<definition id="10">
				<sentence>The Object KB contains world knowledge about the objects in the domain .</sentence>
				<definiendum id="0">Object KB</definiendum>
				<definiens id="0">contains world knowledge about the objects in the domain</definiens>
			</definition>
			<definition id="11">
				<sentence>The MAC finds the frequency adverbial and checks for the presence of a duration .</sentence>
				<definiendum id="0">MAC</definiendum>
				<definiens id="0">finds the frequency adverbial and checks for the presence of a duration</definiens>
			</definition>
			<definition id="12">
				<sentence>The output consists of repetitions of pairs of the following type : the primitives for a stirring event and a specification for no action during the interval between stirring events .</sentence>
				<definiendum id="0">output</definiendum>
				<definiens id="0">consists of repetitions of pairs of the following type : the primitives for a stirring event and a specification for no action during the interval between stirring events</definiens>
			</definition>
			<definition id="13">
				<sentence>SEAFACT is a successful implementation of a natural language interface to a computer-generated animation system , operating in the domain of cooking tasks .</sentence>
				<definiendum id="0">SEAFACT</definiendum>
				<definiens id="0">a successful implementation of a natural language interface to a computer-generated animation system</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>The relevant linguistic information consists of surface position , syntactic structure , and the relationship among the function words ( determiners , modals , and negation ) .</sentence>
				<definiendum id="0">linguistic information</definiendum>
				<definiens id="0">consists of surface position , syntactic structure , and the relationship among the function words ( determiners , modals , and negation )</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>INTRODUCTION Project APRIL ( Annealing Parser for ~al~tic Input Language ) is constructing a software system that uses the stochastic optimization technique known as `` simulated annealing ' '' ( Kirkpatnck et al. 1983 , van T ~rhoven &amp; Aatts 1987 ) to parse authentic English inputs by seeking labelled trce-su~ctures that maximize a measure of plausibility defined in terms of empirical statistics on parse-tree configurations drawn from a dmahase of mavnolly parsed English toxL This approach is a response to the fact that `` real-life '' English , such as the m~u , Jial in the Lancaster-Oslo/Bergen Corpus on which our research focuses , does not appear to conform to a fixed set of grammatical rules .</sentence>
				<definiendum id="0">INTRODUCTION Project APRIL ( Annealing Parser</definiendum>
				<definiens id="0">constructing a software system that uses the stochastic optimization technique known as `` simulated annealing ' ''</definiens>
				<definiens id="1">maximize a measure of plausibility defined in terms of empirical statistics on parse-tree configurations drawn from a dmahase of mavnolly parsed</definiens>
			</definition>
			<definition id="1">
				<sentence>Simulated annealing is a variant which deals with this difficulty by using a more sophisticated rule for deciding whether to accept or reject a modification .</sentence>
				<definiendum id="0">Simulated annealing</definiendum>
				<definiens id="0">a variant which deals with this difficulty by using a more sophisticated rule for deciding whether to accept or reject a modification</definiens>
			</definition>
			<definition id="2">
				<sentence>A second currently-pending research proposal plans m convert the Gothenburg Corpus ( Elleg~l 1978 ) , which consists of relatively deep manual parsings of 128,000 words of the Brown Corpus of American English , into a database usable for this purpose .</sentence>
				<definiendum id="0">Gothenburg Corpus</definiendum>
				<definiens id="0">consists of relatively deep manual parsings of 128,000 words of the Brown Corpus of American English</definiens>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>Suppose our knowledge base consists of the following axioms : ( Vp , l , s ) decrease ( p , l , s ) A vertical ( s ) A etc3 ( p , I , s ) = ( 3 el ) reduce ' ( el , p , l ) or el is a reduction of p to l if and only if p decreases to l on some vertical scale s ( plus some other conditions ) .</sentence>
				<definiendum id="0">Suppose our knowledge base</definiendum>
				<definiens id="0">consists of the following axioms : ( Vp , l , s ) decrease ( p , l , s ) A vertical ( s ) A etc3 ( p , I , s ) = ( 3 el ) reduce ' ( el , p , l</definiens>
			</definition>
			<definition id="1">
				<sentence>( V e , lt , l , s ) at ' ( e , It , l ) ^ on ( l , s ) ^ vertical ( s ) A/tat ( y ) A etcs ( e , it , l , s ) -levee ( e , l , y ) or e is the condition of l 's being the level of y if and only if e is the condition of y 's being at I on some vertical scale s and It is fiat ( plus some other conditions ) .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">s ) at ' ( e , It , l ) ^ on ( l , s ) ^ vertical ( s ) A/tat ( y ) A etcs ( e , it , l , s ) -levee ( e , l , y ) or</definiens>
			</definition>
			<definition id="2">
				<sentence>( Vz , I , s ) decrease ( z , I , s ) A landform ( z ) A altitude ( a ) A etce ( y , l , s ) - ( 3 e ) erode ' ( e , z ) or • is an eroding of z if and only if z is a landform that decreases to some point I on the altitude scale s ( plus some other conditions ) ° ( Vs ) vertical ( s ) A etcr ( p ) altitude ( s ) or s is the altitude scale if and only if s is vertical ( plus some other conditions ) .</sentence>
				<definiendum id="0">landform</definiendum>
				<definiendum id="1">altitude</definiendum>
				<definiens id="0">a landform that decreases to some point I on the altitude scale s ( plus some other conditions ) ° ( Vs ) vertical ( s ) A etcr</definiens>
			</definition>
			<definition id="3">
				<sentence>Back-chainlng on level ' ( e2 , I , y ) yields 100 at ' ( e2 , y , l ) A on ( l , ss ) A vertical ( ss ) A flat ( y ) ^ etcs ( p ) and vertical ( s3 ) and vertical ( s2 ) unify , as do flat ( y ) and flat ( p ) , thereby identifying `` it '' , or y , as the plain p. We have not written out the axioms for this , but note also that `` present '' implies the existence of a change of level , or a change in the location of `` it '' on a vertical scale , and a decrease of a plain is a change of the plain 's location on a vertical scale .</sentence>
				<definiendum id="0">vertical</definiendum>
				<definiens id="0">do flat ( y ) and flat ( p )</definiens>
				<definiens id="1">a change of the plain 's location on a vertical scale</definiens>
			</definition>
			<definition id="4">
				<sentence>( Vi , j , k , x , p , args , req , e , c , rel ) np ( i , j , x ) A vp ( j , k , p , args , req ) A 'pt ( e , c ) $ 3 A rel ( c , z ) $ 2° A subst ( req , cons ( c , args ) ) $ 1° D s ( i , k , e ) ( V i , j , k , e , p , ar gs , req , et , c , ~el ) s ( i , j , e ) A pp ( j , k , p , args , req ) A p ' ( el , c ) s3 A tel ( c , e ) 12° A subst ( req , cons ( c , args ) ) *x° D s ( i , k , e &amp; el ) ( Vi , j , k , w , z , c , rel ) v ( i , j , w ) A np ( j , k , z ) A rel ( c , z ) *2° 3 vp ( i , k , ~z\ [ w ( z , c ) \ ] , &lt; c &gt; , Req ( w ) ) ( V i , j , k , z ) det ( i , j , '' the '' ) A cn ( j , k , z , p ) Ap ( z ) 'm D n1~i , k , z ) ( Vi , j , k , z ) det ( i , j , '' a '' ) A cn ( j , k , z , p ) A p ( z ) n D rip ( i , k , z ) ( Vi , j , k , w , z , y , p , nn ) n ( i , j , w ) A cn ( j , k , z , p ) ^w ( y ) '' ^ .</sentence>
				<definiendum id="0">vp</definiendum>
				<definiendum id="1">A subst</definiendum>
				<definiens id="0">e ) ( V i , j , k , e , p , ar gs , req , et , c , ~el ) s ( i , j , e ) A pp ( j , k , p , args , req ) A p '</definiens>
				<definiens id="1">c , args ) ) *x° D s ( i , k , e &amp; el ) ( Vi , j , k , w , z , c , rel ) v ( i , j , w</definiens>
				<definiens id="2">j , k , w , z , y , p , nn ) n ( i , j , w ) A cn ( j , k , z , p ) ^w ( y ) '' ^</definiens>
			</definition>
			<definition id="5">
				<sentence>A subst ( req , cons ( c , argo ) ) st° ^ rel ( c , z ) s2° ~ ( i , k , = , ; ~z\ [ p~ ( : ) ^ ~ ( ~ ) \ ] ) ( Vi , j , w ) n ( i , j , w ) D ( 3z ) cn ( i , j , z , w ) ( Vi , j , k , w , z , c , rel ) prep ( i , j , w ) ^ np ( j , k , x ) A rel ( c , z ) In° 3 ptXi , k , , ~z\ [ w ( c , z ) \ ] , &lt; c &gt; , Req ( w ) ) For example , the first axiom says that there is a sentence from point i to point k asserting eventuality e if there is a noun phrase from i to j referring to z and a verb phrase from j to k denoting predicate p with arguments arg8 and having an associated requirement req , and there is ( or , for $ 3 , can be assumed to be ) an eventuality e of p 's being true of ¢ , where c is related to or coercible from x ( with an assumability cost of $ 20 ) , and the requirement req associated with p can be proved or , for $ 10 , assumed to hold of the arguments of p. The symbol c &amp; el denotes the conjunction of eventualities e and el ( See Hobbs ( 1985b ) , p. 35 . )</sentence>
				<definiendum id="0">subst</definiendum>
				<definiendum id="1">, ~z\ [ w</definiendum>
				<definiens id="0">z , w ) ( Vi , j , k , w , z , c , rel ) prep ( i , j , w ) ^ np ( j , k , x ) A rel ( c , z ) In° 3 ptXi , k ,</definiens>
				<definiens id="1">a verb phrase from j to k denoting predicate p with arguments arg8 and having an associated requirement req</definiens>
			</definition>
</paper>

		<paper id="1033">
			<definition id="0">
				<sentence>Edinburgh EH8 9LW , Scotland remo ( ~linc.cis.upenn.edu ABSTRACT We introduce a first-order version of Categorial Grammar , based on the idea of encoding syntactic types as definite clauses .</sentence>
				<definiendum id="0">Scotland remo</definiendum>
				<definiens id="0">a first-order version of Categorial Grammar , based on the idea of encoding syntactic types as definite clauses</definiens>
			</definition>
			<definition id="1">
				<sentence>Classical Categorial Grammar ( CG ) \ [ 1\ ] is an approach to natural language syntax where all linguistic information is encoded in the lexicon , via the assignment of syntactic types to lexical items .</sentence>
				<definiendum id="0">Classical Categorial Grammar</definiendum>
			</definition>
			<definition id="2">
				<sentence>Consider the string whom John loves Such a sentence determines a program 79 with the following set F of ground atoms : { CONN ( whom , O , I ) , CONN ( John , I , 2 ) , CONN ( loves , 2 , 3 ) } 274 \ , Ve assume lexical type assignments such that the remaining set of clauses A is as follows : { VxVz\ [ CONN ( whom , x 1 , x ) A ( NP ( y , y ) -- * S ( x , y ) ) -- * REL ( x 1 , y ) \ ] , gx\ [ CONN ( John , x 1 , x ) -* NP ( x 1 , x ) \ ] , W : VyVz\ [ CONN ( Ioves , y 1 , y ) A NP ( y , z ) A NV ( x , y 1 ) -- ~ s ( x , z ) l } The clause assigned to the relative pronoun whom corresponds to the type of a higher-order function , and contains an implication in its body .</sentence>
				<definiendum id="0">CONN</definiendum>
				<definiendum id="1">REL</definiendum>
				<definiendum id="2">CONN ( John , x 1 , x ) -* NP ( x 1</definiendum>
				<definiendum id="3">NV</definiendum>
				<definiens id="0">y , y ) -- * S ( x , y ) ) -- *</definiens>
			</definition>
			<definition id="3">
				<sentence>We have the three following structural rules : • Intercha~ , ge , which allows to use hypotheses in any order • Contraction , which allows to use a hypothesis more than once • Thinning , which says that not all hypotheses need to be used Hypotheses All of the structural rules above are implicit in proof rules ( I ) - ( V ) , and they are all needed to obtain intuitionistic soundness and completeness as in \ [ 7\ ] .</sentence>
				<definiendum id="0">ge</definiendum>
				<definiens id="0">allows to use a hypothesis more than once • Thinning , which says that not all hypotheses need to be used Hypotheses All of the</definiens>
				<definiens id="1">V ) , and they are all needed to obtain intuitionistic soundness</definiens>
			</definition>
			<definition id="4">
				<sentence>Moreover , Thinning gives us a straightforward way to account for situations of lexical ambiguity , where the program defined by a certain input string can in fact contain hypotheses which are not needed to derive the type of the string .</sentence>
				<definiendum id="0">Thinning</definiendum>
				<definiens id="0">gives us a straightforward way to account for situations of lexical ambiguity , where the program defined by a certain input string can in fact contain hypotheses which are not needed to derive the type of the string</definiens>
			</definition>
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>Its theoretical focus is the production of explanations over extended interactions in ways that are superior to the simple goal-tree traversal of systems such as TYRESIAS ( \ [ Davis 76\ ] ) and MYCIN ( \ [ Shortliffe 76\ ] ) .</sentence>
				<definiendum id="0">theoretical focus</definiendum>
				<definiens id="0">the production of explanations over extended interactions in ways that are superior to the simple goal-tree traversal</definiens>
			</definition>
			<definition id="1">
				<sentence>The effect field contains a description of the intended effect of the relation ( i.e. , the goal that the plan achieves , if properly executed } .</sentence>
				<definiendum id="0">effect field</definiendum>
				<definiens id="0">contains a description of the intended effect of the relation</definiens>
			</definition>
			<definition id="2">
				<sentence>The RST relation Purpose expresses the relation between an action and its intended result : = Pro .</sentence>
				<definiendum id="0">RST relation Purpose</definiendum>
			</definition>
			<definition id="3">
				<sentence>The structurer produces all coherent paragraphs ( that is , coherent as defined by the relations ) that satisfy the given goal ( s ) for any set of input elements .</sentence>
				<definiendum id="0">structurer</definiendum>
				<definiens id="0">produces all coherent paragraphs ( that is , coherent as defined by the relations ) that satisfy the given goal ( s ) for any set of input elements</definiens>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>D = general de~ermlnafive element ; Da = detetminadve element containing an article as the last or only word ; G = genitive consmu : tion ; Jm = adjective phrase ; M = numeral ' phrase ; N ffi nominal ; N ' ffi noun phrase ; N ' &amp; =-fltlt conjunct of co-ordinated noun phrase ; N'+ ffi non-initial conjunct following a conjunction ; Nr ' = temporal noun phrase ; P = prepo~on~ phrase ; Po ffi p~ .</sentence>
				<definiendum id="0">N'+</definiendum>
				<definiendum id="1">Po ffi</definiendum>
				<definiens id="0">general de~ermlnafive element ; Da = detetminadve element containing an article as the last or only word ; G = genitive consmu : tion ; Jm = adjective phrase ; M = numeral ' phrase</definiens>
			</definition>
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>Although formal properties of Tree Adjoining Grammars ( TAGs ) have been investigated ( VijayShanker , 1987 ) -- for example , there is an O ( ns ) time CKY-like algorithm for TAGs ( Vijay-Shanker and Joshi , 1985 ) -- so far there has been no attempt to develop an Earley-type parser for TAGs .</sentence>
				<definiendum id="0">Vijay-Shanker</definiendum>
				<definiens id="0">no attempt to develop an Earley-type parser for TAGs</definiens>
			</definition>
			<definition id="1">
				<sentence>This paper presents an Earley parser for TAGs and discusses modifications to the parsing algorithm that make it possible to handle extensions of TAGs such as constraints on adjunction , sub*This work is partially supported by ARO grant DAA29-84-9-007 , DARPA grant N0014-85-K0018 , NSF grants MCS-82-191169 and DCR-84-10413 .</sentence>
				<definiendum id="0">Earley parser</definiendum>
				<definiens id="0">the parsing algorithm that make it possible to handle extensions of TAGs such as constraints on adjunction</definiens>
			</definition>
			<definition id="2">
				<sentence>Definition 1 ( Tree Adjoining Grammar ) : A TAG is a 5-tuple G - ( VN , VT , S , I , A ) where VN is a finite set of non-terminal symbols , VT is a finite set of terminals , S is a distinguished nonterminal , I is a finite set of trees called initial trees and A is a finite set of trees called auxiliary trees .</sentence>
				<definiendum id="0">Tree Adjoining Grammar )</definiendum>
				<definiendum id="1">TAG</definiendum>
				<definiendum id="2">VT</definiendum>
				<definiendum id="3">S</definiendum>
				<definiens id="0">a 5-tuple G - ( VN , VT , S , I , A ) where VN is a finite set of non-terminal symbols</definiens>
				<definiens id="1">a finite set of terminals</definiens>
			</definition>
			<definition id="3">
				<sentence>• pos : is the position of the dot ; pos E { above , below } .</sentence>
				<definiendum id="0">• pos</definiendum>
				<definiens id="0">the position of the dot</definiens>
			</definition>
			<definition id="4">
				<sentence>, al ... all atl+l ... . ah ' Figure 4 : Meaning of s E Si • l is an index in the input string indicating where the tree derived from a begins .</sentence>
				<definiendum id="0">l</definiendum>
				<definiens id="0">an index in the input string indicating where the tree derived from a begins</definiens>
			</definition>
			<definition id="5">
				<sentence>• s E Si means that the recognized part of the dotted tree a , which is the left part of it , is consistent with the input string from al to aa and from at to aI , and from ay .</sentence>
				<definiendum id="0">E Si</definiendum>
				<definiens id="0">means that the recognized part of the dotted tree a</definiens>
			</definition>
			<definition id="6">
				<sentence>program recognizer beg~ So = { \ [ a , O , left , above , 0 ... .. -\ ] \ ] a is an initial tree } For i : = 0 to n do begin Process the states of Si , performing one of the following seven operations on each state s = \ [ c~ , dot , side , pos , l , f , , fr , star , t~ , b~\ ] until no more states can be added : I. Sc-~er S. Move dot up If Si+1 is empty and i &lt; n , return rejection .</sentence>
				<definiendum id="0">pos</definiendum>
				<definiens id="0">I. Sc-~er S. Move dot up If Si+1 is empty and i &lt; n , return rejection</definiens>
			</definition>
			<definition id="7">
				<sentence>Definition 5 ( Adjunct ( a , address ) ) Given a TAG G , define Adjunct ( a , address ) as the set of auxiliary trees that can be adjoined in the elementary tree ct at the node n which has the given address .</sentence>
				<definiendum id="0">Adjunct</definiendum>
				<definiendum id="1">TAG G , define Adjunct</definiendum>
				<definiens id="0">the set of auxiliary trees that can be adjoined in the elementary tree ct at the node n which has the given address</definiens>
			</definition>
			<definition id="8">
				<sentence>2 - , -i ( left \ [ /~ , 2 , left , below , 1 ... .. -\ ] ( move dot down ) O , left , below , 2 , -- , -- , - , -- , -- \ ] ( move dot down ) \ [ ~ ' , 1 , right , above , 1 , -t -- 1 -- , -- , -- \ ] ~move dot up ) \ [ 0 , 2.2 , left , below , 1 , 3 , -- , -- , -- , -- \ ] ~left completor ) \ [ /~ , 2.1 , right , above , I , -- , -- , -- , -- , -- \ ] ( move dot up ) \ [ ~ , O , left , above , 0 , ... . -\ ] ( left predictor ) f/J , O , left , below , 0 , - , - , - , - , -\ ] ( move dot down ) -\ ] ~scanner ) \ [ ct , 11 le~t l aboo % 0 r -1 -- I -- P - , ( left predictor ) , \ [ ~ , 2 , left , above , O , - , - , - , - , \ [ 13 , O , left , above , 1 , - , - , - , - , -\ ] ( left predictor ) \ [ 0 , O , left , below , 1 , - , -- , -- , - , -- \ ] ( move dot down ) \ [ /~ , 2.1 , left , aboue , 1 , -- , -- , - , - , -\ ] ( scanner ) \ [ B , 1 , left , above , 2 , - , -- , -- , - , -- \ ] ( scanner ) \ [ /~ , 2 , left , above , 1 , -- , - , -- , -- , -\ ] ( left predictor ) \ [ 0 , 2 , left , below , 0 , - , - , 2 , 1,3\ ] ( move dot down ) \ [ ~ , 2.2 , left , above , 1 , - , - , - , - , -\ ] ( left predictor ) \ [ p , 2.1 , le/t , abate , O , - , - , 211 , a I ( scanne 0 \ [ o , 1 , left , above , O , -- , -- , O , O , 4\ ] ( manner ) \ [ ~ , 2.2 , fell abo~e , O , - , - , 2 , 1 , 3\ ] ( left predictor ) \ [ ~ , 2.2 , le ) 't , below , O , 4 , -- , 2 , 1,3\ ] ( left completor ) \ [ 0 , 2.3 , left , abooe , O , 4 , 5 , 2,1,3\ ] ( scanner ) \ [ ~ , 2.2 , right , above , 0 , 4 , 5 , 2 , 1 , 3\ ] ( move dot up ) \ [ a~ 1 , right , above t O r -- t -- w 01014\ ] ( move dot up ) \ [ 0 , 2.2 , right , above , 1 , 3 , 6 , - , - , -\ ] ( move dot up ) \ [ ~ , 2.3 , left , above , 1 , 3 , 6 , -- , - , -\ ] ( scanner ) \ [ ~ , 2.2 , right , below , 1~ 3~ 6~ -~ r -\ ] ( right predictor r case 2 ) \ [ 0 , 2 , right , below , 1,3 , 6 , -- , - , -- \ ] ( right predictor , case 2 ) B I 3 , lep , above , 1,3 , 6 , -I -- I -- 1 ( scanner ) ~ , O , right , below , I , 3 , 6 , -- , -- , -\ ] ( right predictor , case 2 ) \ [ ~ , 3 , left , above , 0 , 4 , 5 , -- , -- , -- \ ] ( scanner ) ( move dot up ) \ [ ~1 21 fish'1 oh°re10 , 41 51 -- , -- I - ( right predictor , case 2 ) \ [ ~ , O , right , below , O , 4 , 5 , - , - , \ [ ~ , O , rlqht l above , O , 4 , 5 , -- , -- , -- \ ] ( right completor ) \ [ a , 0 , left , beio~ , 0 , -- , -- , 0 , 0 , 4\ ] ( move dot down ) \ [ 0 , 2.1 , right , above , 0 , -- , -- , 2 , 1,3\ ] ( move dot up ) \ [ \ [ 3 , 2.2 , right , below , 0 , 4 , 5 , 2,1,3\ ] ( right predictor , case 2 ) \ [ a , 0 , right , below , O , - , - , O , O , 4\ ] ( right predictor , case 1 ) \ [ 0 , 2.8 , right , above , 0 , 4 , 5 , 2 , 1 , 3\ ] ( move dot up ) LS , 2 , right , below , O , 4 , 5 , 2,1,3\ ] ( right predictor , case 1 ) \ [ 0 , 2 , right , above , 1,3 , 6 , -- , -- , -- \ ] ( move dot up ) I B r 2.31 right I above , 113 , 61 -- I -- ~ -- \ ] ( move dot up ) /3 , O , right , above , I , 3 , 6 , -- , -- , -- \ ] ( right completor ) \ [ 0 , 3 , right , abo~e , 1,3 , 6 , -- , -- , -- \ ] ( move dot up ) \ [ o , O , right , above , O , -- , -- , -- , - , -\ ] ( end test ) \ [ ~ , 3 , right , above , O , 4 , 5 , - , -- , -- \ ] ( move dot up ) Figure 14 : States sets for the input aabbeccdd /\ Figure 15 : Mechanism of substitution context free grammar since this encoding uses adjunction .</sentence>
				<definiendum id="0">-i</definiendum>
				<definiens id="0">left predictor )</definiens>
				<definiens id="1">move dot up ) /3 , O , right , above , I , 3 , 6 , -- , -- , -- \ ] ( right completor ) \ [ 0 , 3 , right , abo~e , 1,3 , 6 , -- , -- , -- \ ] ( move dot up ) \ [ o , O , right , above , O , -- , -- , -- , -</definiens>
			</definition>
			<definition id="9">
				<sentence>Substitution is the basic operation used in CFG .</sentence>
				<definiendum id="0">Substitution</definiendum>
				<definiens id="0">the basic operation used in CFG</definiens>
			</definition>
			<definition id="10">
				<sentence>Substitution is a less powerful operation than adjunction .</sentence>
				<definiendum id="0">Substitution</definiendum>
				<definiens id="0">a less powerful operation than adjunction</definiens>
			</definition>
			<definition id="11">
				<sentence>I , Ubr Figure 19 : Updating of features A NP Vp ( a ) I /\ PRO V PP /\ to go to the movies S.top : :gtsnsed &gt; = + S , bottom : : &lt; tensed &gt; = V.boRom : : &lt; tensed &gt; V.bottom : : &lt; tensed &gt; = Feature structures in TAGs As defined by Vijay-Shanker ( 1987 ) and VijayShanker and 30shi ( 1988 ) , to each adjunction node in an elementary tree two feature structures are attached : a top and a bottom feature structure .</sentence>
				<definiendum id="0">NP Vp</definiendum>
				<definiens id="0">:gtsnsed &gt; = + S , bottom : : &lt; tensed &gt; = V.boRom : : &lt; tensed &gt; V.bottom : : &lt; tensed &gt; = Feature structures in TAGs As defined by Vijay-Shanker ( 1987 ) and VijayShanker and 30shi ( 1988 ) , to each adjunction node in an elementary tree two feature structures are attached : a top and a bottom feature structure</definiens>
			</definition>
			<definition id="12">
				<sentence>The system therefore consists of a TAG and a set of unification equations on the DAGs associated with nodes in elementary trees .</sentence>
				<definiendum id="0">system therefore</definiendum>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>Pinkham gives examples of a wide range of constructions which are difficult or impossible to explain in terms of deletion phenomena , and suggests instead an approach in which at least some comparative constructions are base-generated phrasal and then interpreted using a rule which she calls `` distributive copying '' .</sentence>
				<definiendum id="0">Pinkham</definiendum>
				<definiens id="0">gives examples of a wide range of constructions which are difficult or impossible to explain in terms of deletion phenomena , and suggests instead an approach in which at least some comparative constructions are base-generated phrasal and then interpreted using a rule which she calls `` distributive copying ''</definiens>
			</definition>
			<definition id="1">
				<sentence>So in the `` inner '' copy , P gets instantiated to a a form 2y : comp ( y , y ' ) , where comp is the type of comparison and y and y ' are the degree variables ; in the `` outer '' copy , P is instantiated to the value of the inner form .</sentence>
				<definiendum id="0">comp</definiendum>
				<definiens id="0">the degree variables ; in the `` outer '' copy</definiens>
			</definition>
			<definition id="2">
				<sentence>x : x = `` H &amp; G '' Xx : read ( x , y ) n y = '' H &amp; G '' more ( ~x : women ( x ) , Xx : men ( x ) , ~x : read ( x , '' H &amp; G '' ) ) Table 4 It is interesting to compare our treatment with that suggested in ( Keenan &amp; Stavi 86 ) ( p.282-284 ) for comparative adjectival constructions like that in 6a ) ; they argue convincingly that these are to be regarded as directly interpreted , rather than as `` reduced forms '' of sentences like 6b ) .</sentence>
				<definiendum id="0">Xx</definiendum>
			</definition>
			<definition id="3">
				<sentence>APPENDIX : TERMINOLOGY Comparative Clause : the clause introduced by the comparison marker .</sentence>
				<definiendum id="0">TERMINOLOGY Comparative Clause</definiendum>
				<definiens id="0">the clause introduced by the comparison marker</definiens>
			</definition>
			<definition id="4">
				<sentence>Q : An ( implicit or explicit ) comparison quantifier which is extraposed in the interpretation of clausal comparatives .</sentence>
				<definiendum id="0">Q</definiendum>
				<definiens id="0">An ( implicit or explicit</definiens>
			</definition>
</paper>

	</volume>
