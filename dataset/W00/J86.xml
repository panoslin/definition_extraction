<?xml version="1.0" encoding="UTF-8"?>
	<volume id="J86">

		<paper id="3002">
			<definition id="0">
				<sentence>Portability involves two separate issues .</sentence>
				<definiendum id="0">Portability</definiendum>
				<definiens id="0">involves two separate issues</definiens>
			</definition>
			<definition id="1">
				<sentence>A sublanguage is a specialized form of natural language used to describe a limited subject matter , generally employed by a group of specialists dealing with this subject .</sentence>
				<definiendum id="0">sublanguage</definiendum>
				<definiens id="0">a specialized form of natural language used to describe a limited subject matter , generally employed by a group of specialists dealing with this subject</definiens>
			</definition>
			<definition id="2">
				<sentence>The Linguistic String Parser English grammar ( Sager 1981 ) is an augmented context-free grammar .</sentence>
				<definiendum id="0">Linguistic String Parser English grammar</definiendum>
				<definiens id="0">an augmented context-free grammar</definiens>
			</definition>
			<definition id="3">
				<sentence>We used the NYU Linguistic String Project medical grammar , which is a modification of the Linguistic String Project English grammar including the sentence fragments and other constructs ( such as descriptions of medication dosages ) that appear in medical reports but not in standard English ( Marsh 1983 ) .</sentence>
				<definiendum id="0">NYU Linguistic String Project medical grammar</definiendum>
				<definiens id="0">a modification of the Linguistic String Project English grammar including the sentence fragments and other constructs ( such as descriptions of medication dosages</definiens>
			</definition>
			<definition id="4">
				<sentence>~r 7 , Y / / , , , I * , , i I i i i i I , , , , I i , i I I i i i t I i i i i I , , , , I i , i i I i i i t I i t , 50 t O0 t50 200 250 300 350 400 qSO 500 550 SIZE BF TEXT SAMPLE ( SENTENCES ) The growth in the number of prepositional phrase selectional patterns as a function of the size of the text sample ( in sentences ) .</sentence>
				<definiendum id="0">SIZE BF TEXT SAMPLE</definiendum>
			</definition>
</paper>

		<paper id="3006">
</paper>

		<paper id="4002">
			<definition id="0">
				<sentence>Excerpt 8 demonstrates the latter type of focus confusion that occurs when the speaker ( E ) sets up one focus the MAINTUBE , which is the correct focus in this case but then proceeds in such a manner that the listener ( A ) thinks a focus shift to another piece , the TUBEBASE , has occurred .</sentence>
				<definiendum id="0">MAINTUBE</definiendum>
				<definiens id="0">occurs when the speaker ( E ) sets up one focus the</definiens>
			</definition>
			<definition id="1">
				<sentence>Either repair process involves the use of knowledge about conversation , social conventions , and the world around us .</sentence>
				<definiendum id="0">repair process</definiendum>
				<definiens id="0">involves the use of knowledge about conversation , social conventions , and the world around us</definiens>
			</definition>
			<definition id="2">
				<sentence>The spatial description is a physical description of the object in terms of its dimensions , the basic 3-D shapes composing it , and its physical features ( along the lines developed in Agin ( 1979 ) and Goodman ( 1981 ) ) .</sentence>
				<definiendum id="0">spatial description</definiendum>
				<definiens id="0">a physical description of the object in terms of its dimensions</definiens>
			</definition>
			<definition id="3">
				<sentence>The cognitive/linguistic form is a representation of the parts and features of the object in linguistic terms .</sentence>
				<definiendum id="0">cognitive/linguistic form</definiendum>
				<definiens id="0">a representation of the parts and features of the object in linguistic terms</definiens>
			</definition>
			<definition id="4">
				<sentence>A CONCEPT denotes a set , representing those elements described by it .</sentence>
				<definiendum id="0">CONCEPT</definiendum>
				<definiens id="0">a set , representing those elements described by it</definiens>
			</definition>
			<definition id="5">
				<sentence>FIND POTENTIAL REFERENT CANDIDATES Before relaxation takes place , the algorithm looks for potential candidates for referents ( which denote elements in the listener 's visual scene ) .</sentence>
				<definiendum id="0">FIND POTENTIAL REFERENT CANDIDATES Before relaxation</definiendum>
				<definiens id="0">takes place , the algorithm looks for potential candidates for referents ( which denote elements in the listener 's visual scene )</definiens>
			</definition>
</paper>

		<paper id="2001">
			<definition id="0">
				<sentence>This paper describes a research project designed to explore this conjecture , and describes a robust natural language interface , called MURPHY , which embodies the integrated processing hypothesis .</sentence>
				<definiendum id="0">MURPHY</definiendum>
				<definiens id="0">embodies the integrated processing hypothesis</definiens>
			</definition>
			<definition id="1">
				<sentence>MURPHY knows the meaning of each word in this example , and has appropriate domain knowledge .</sentence>
				<definiendum id="0">MURPHY</definiendum>
				<definiens id="0">knows the meaning of each word in this example , and has appropriate domain knowledge</definiens>
			</definition>
			<definition id="2">
				<sentence>DYPAR combined a context-free semantic grammar , a partial pattern matcher , and equivalence transformations for building a representation of the meaning of the utterance .</sentence>
				<definiendum id="0">DYPAR</definiendum>
				<definiens id="0">combined a context-free semantic grammar , a partial pattern matcher , and equivalence transformations for building a representation of the meaning of the utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>The separatist view suggests that the mechanism that constructs a syntactic description of an utterance is a different mechanism from that which builds a representation for the meaning of the utterance .</sentence>
				<definiendum id="0">utterance</definiendum>
				<definiens id="0">a different mechanism from that which builds a representation for the meaning of the utterance</definiens>
			</definition>
			<definition id="4">
				<sentence>MURPHY is composed of four major component programs : • A natural language analyzer ( NLA ) , which accesses a dictionary of words and phrases to perform low-level understanding of the words in the utterance ; • An inferencer ( Robust Back End , or RBE ) , which completes understanding using conversational history , context , and a body of domain knowledge ; • A conversational control program ( CCON ) , which performs inference on the input meanings of the user 's utterances and provides a mixed-initiative conversational ability , and which allows MURPHY to interact with the robot assembly system ; • A natural language generator ( Conceptual Generator , or CGEN ) , which accepts concepts and expresses them in English .</sentence>
				<definiendum id="0">MURPHY</definiendum>
				<definiendum id="1">NLA</definiendum>
				<definiendum id="2">RBE</definiendum>
				<definiendum id="3">CGEN</definiendum>
				<definiens id="0">accesses a dictionary of words and phrases to perform low-level understanding of the words in the utterance ; • An inferencer ( Robust Back End , or</definiens>
				<definiens id="1">completes understanding using conversational history , context , and a body of domain knowledge ; • A conversational control program ( CCON ) , which performs inference on the input meanings of the user 's utterances and provides a mixed-initiative conversational ability , and which allows MURPHY to interact with the robot assembly system ; • A natural language generator ( Conceptual Generator , or</definiens>
				<definiens id="2">accepts concepts and expresses them in English</definiens>
			</definition>
			<definition id="5">
				<sentence>MURPHY 's domain knowledge consists of a set of semantic primitives appropriate to the domain , represented in Conceptual Dependency format ( Schank 1975~ Schank and Abelson 1977 ; although MURPHY could be implemented with any of a wide variety of knowledge representation formalisms generally similar to Conceptual Dependency ) .</sentence>
				<definiendum id="0">MURPHY 's domain knowledge</definiendum>
			</definition>
			<definition id="6">
				<sentence>Thus , the primary definition of a CD consists of the frame definition , the properties of the CD , and the restrictions that specify which kinds of CDs can fill each slot .</sentence>
				<definiendum id="0">CD</definiendum>
				<definiens id="0">consists of the frame definition , the properties of the CD , and the restrictions that specify which kinds of CDs can fill each slot</definiens>
			</definition>
			<definition id="7">
				<sentence>A word definition consists of the word 's meaning and its syntax .</sentence>
				<definiendum id="0">word definition</definiendum>
			</definition>
			<definition id="8">
				<sentence>NLA is a descendant of the CA program ( Birnbaum and Selfridge 1981 ) , and also uses concepts derived from Wilks ( 1976 ) .</sentence>
				<definiendum id="0">NLA</definiendum>
				<definiens id="0">a descendant of the CA program ( Birnbaum and Selfridge 1981 ) , and also uses concepts derived from Wilks ( 1976 )</definiens>
			</definition>
			<definition id="9">
				<sentence>C-LIST : ( PTRANS ACTOR ( NIL ) OBJECT ( PHYS-OBJ TYPE ( BASE ) PART-OF ( NIL ) REF ( NIL ) ) TO ( TOP VAL ( NIL ) ) ) ( REF ) -used ( PHYS-OBJ TYPE ( POST ) PART-OF ( NIL ) ( TOP VAL ( NIL ) ) -used ( REF ) ( PHYS-OBJ TYPE ( BASE ) PART-OF ( NIL ) REF ( DEF ) ) REF ( NIL ) ) -used EXAMINING : ( TOP VAL ( NIL ) ) CHECKING VAL SLOT : requires phys-obj follows `` on '' , `` put '' , object-filler VAL CANDIDATES : ( PHYS-OBJ TYPE ( POST ) PART-OF ( NIL ) REF ( NIL ) ) preference value I : follow `` put '' , ( PHYS-OBJ TYPE ( BASE ) PART-OF ( NIL ) REF ( NIL ) ) preference value 2 : follows `` on '' , `` put '' PREFERRED FILLER : ( PHYS-OBJ TYPE ( BASE ) PART-OF ( NIL ) REF ( NIL ) ) REMOVING FILLER OF OBJECT SLOT RE-CHECKING OBJECT SLOT : OBJECT CANDIDATES : PREFERRED FILLER : requires phys-obj follows `` put '' , precedes to-filler ( PHYS-OBJ TYPE ( POST ) PART-OF ( NIL ) REF ( NIL ) ) preference value 2 : follows `` put '' precedes to-filler ( PHYS-OBJ TYPE ( BASE ) PART-OF ( NIL ) REF ( NIL ) ) preference value I : follows `` put '' ( PHYS-OBJ TYPE ( POST ) PART-OF ( NIL ) REF ( NIL ) ) C-LIST : ( PTRANS ACTOR ( NIL ) OBJECT ( PHYS-OBJ TYPE ( POST ) PART-OF ( NIL ) REF ( NIL ) ) TO ( TOP VAL ( PHYS-OBJ TYPE ( BASE ) PART-OF ( NIL ) REF ( NIL ) ) ) ) ( REF ) -used ( PHYS-OBJ TYPE ( TOP VAL ( NIL ) ) ( REF ) ( PHYS-OBJ TYPE ( POST ) PART-OF ( NIL ) REF ( NIL ) ) -used -used ( BASE ) PART-OF ( NIL ) REF ( NIL ) ) -used The understanding process is complete when the remaining slots in the meaning of base have been examined and the REF slot filled with the meaning of the second the .</sentence>
				<definiendum id="0">REF</definiendum>
				<definiendum id="1">POST</definiendum>
				<definiendum id="2">TOP VAL</definiendum>
				<definiendum id="3">CHECKING VAL SLOT</definiendum>
				<definiendum id="4">PHYS-OBJ TYPE</definiendum>
				<definiendum id="5">POST</definiendum>
				<definiendum id="6">PHYS-OBJ TYPE</definiendum>
				<definiendum id="7">BASE ) PART-OF ( NIL ) REF ( NIL ) ) REMOVING FILLER OF OBJECT SLOT RE-CHECKING OBJECT SLOT</definiendum>
				<definiendum id="8">FILLER</definiendum>
				<definiendum id="9">POST ) PART-OF ( NIL ) REF</definiendum>
				<definiendum id="10">PHYS-OBJ TYPE</definiendum>
				<definiendum id="11">TOP VAL</definiendum>
				<definiens id="0">requires phys-obj follows `` put '' , precedes to-filler ( PHYS-OBJ TYPE ( POST ) PART-OF ( NIL ) REF ( NIL</definiens>
			</definition>
			<definition id="10">
				<sentence>That is , RBE takes the best understanding provided by NLA as the root node , and descendants are nodes at which CDs have additional slots filled .</sentence>
				<definiendum id="0">RBE</definiendum>
				<definiens id="0">takes the best understanding provided by NLA as the root node , and descendants are nodes at which CDs have additional slots filled</definiens>
			</definition>
			<definition id="11">
				<sentence>Generating the descendants of a node involves • choosing an empty slot ; • retrieving its semantic requirements and preferences ; • retrieving all possible candidates from domain knowledge , conversational history , and user corrections that satisfy the requirements ; • creating a copy of the CD at the current node for each candidate and filling the slot with a candidate filler ; and , finally , • building a new node for each such CD .</sentence>
				<definiendum id="0">Generating the descendants of a node</definiendum>
			</definition>
			<definition id="12">
				<sentence>Thus , RBE continues the search for a complete understanding begun by NLA , using essentially the same local best-first searching process to do so ; if its search fails , it returns control to NLA to generate its next most plausible interpretation of the input , and RBE again continues the search .</sentence>
				<definiendum id="0">RBE</definiendum>
				<definiens id="0">continues the search for a complete understanding begun by NLA , using essentially the same local best-first searching process to do so</definiens>
			</definition>
			<definition id="13">
				<sentence>RBE begins when it receives NLA 's best understanding of this sentence and places it on NODE-list , as shown below .</sentence>
				<definiendum id="0">RBE</definiendum>
				<definiens id="0">begins when it receives NLA 's best understanding of this sentence</definiens>
			</definition>
			<definition id="14">
				<sentence>Thus NLA applies the same mechanism to evaluate syntax as semantics .</sentence>
				<definiendum id="0">NLA</definiendum>
				<definiens id="0">applies the same mechanism to evaluate syntax as semantics</definiens>
			</definition>
			<definition id="15">
				<sentence>RBE chooses to fill a slot in a CD from candidate fillers drawn from conversational history and domain knowledge if that candidate filler satisfies the most semantic requirements and preferences of the CDs retrieved .</sentence>
				<definiendum id="0">RBE</definiendum>
				<definiens id="0">chooses to fill a slot in a CD from candidate fillers drawn from conversational history and domain knowledge if that candidate filler satisfies the most semantic requirements and preferences of the CDs retrieved</definiens>
			</definition>
			<definition id="16">
				<sentence>Syntactic features are retrieved from the definition of image , and from the definition of display as well , since the meaning of image is understood to fill the OBJECT slot of the meaning of display and MURPHY propagates syntax downward from parent to filler .</sentence>
				<definiendum id="0">MURPHY</definiendum>
				<definiens id="0">understood to fill the OBJECT slot of the meaning of display and</definiens>
			</definition>
			<definition id="17">
				<sentence>When this occurs , RBE completes the understanding process by inferring additional concepts .</sentence>
				<definiendum id="0">RBE</definiendum>
				<definiens id="0">completes the understanding process by inferring additional concepts</definiens>
			</definition>
			<definition id="18">
				<sentence>NLA understands this utterance as well as possible , but fails to find a filler for the SOURCE slot in the meaning of image .</sentence>
				<definiendum id="0">NLA</definiendum>
				<definiens id="0">understands this utterance as well as possible , but fails to find a filler for the SOURCE slot in the meaning of image</definiens>
			</definition>
			<definition id="19">
				<sentence>MURPHY does infer the meaning of is , fills two of its three empty slots with the meanings of the phrases understood by NLA , and fills the third with the meaning of A switch post .</sentence>
				<definiendum id="0">MURPHY</definiendum>
				<definiens id="0">does infer the meaning of is , fills two of its three empty slots with the meanings of the phrases understood by NLA , and fills the third with the meaning of A switch post</definiens>
			</definition>
			<definition id="20">
				<sentence>RBE searches context and domain knowledge for fillers for these slots , and finds the meanings of the , current , and workspace .</sentence>
				<definiendum id="0">RBE</definiendum>
				<definiens id="0">searches context and domain knowledge for fillers for these slots , and finds the meanings of the , current , and workspace</definiens>
			</definition>
			<definition id="21">
				<sentence>RBE searches context and domain knowledge for appropriate fillers for each empty slot , and for empty slots in those fillers , and so on , until it builds a CD with no empty slots .</sentence>
				<definiendum id="0">RBE</definiendum>
				<definiens id="0">searches context and domain knowledge for appropriate fillers for each empty slot</definiens>
			</definition>
			<definition id="22">
				<sentence>If not , RBE resumes searching to infer the next most likely set of fillers .</sentence>
				<definiendum id="0">RBE</definiendum>
				<definiens id="0">resumes searching to infer the next most likely set of fillers</definiens>
			</definition>
			<definition id="23">
				<sentence>Moreover , this identity allows MURPHY to understand utterances in which the missing word 's meaning contains a slot that must be filled by the meaning of a word that was present in the input .</sentence>
				<definiendum id="0">MURPHY</definiendum>
				<definiens id="0">to understand utterances in which the missing word 's meaning contains a slot that must be filled by the meaning of a word that was present in the input</definiens>
			</definition>
			<definition id="24">
				<sentence>MURPHY maintains a conversational history by decomposing the meaning of each input into its component parts and appending them to domain knowledge .</sentence>
				<definiendum id="0">MURPHY</definiendum>
				<definiens id="0">maintains a conversational history by decomposing the meaning of each input into its component parts and appending them to domain knowledge</definiens>
			</definition>
			<definition id="25">
				<sentence>MURPHY 's ability to generate a series of possible input meanings ordered by likelihood is a consequence of the fact that the processing performed by NLA and RBE is a best-first search through a tree of semantic structures .</sentence>
				<definiendum id="0">RBE</definiendum>
				<definiens id="0">MURPHY 's ability to generate a series of possible input meanings ordered by likelihood is a consequence of the fact that the processing performed by NLA and</definiens>
				<definiens id="1">a best-first search through a tree of semantic structures</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>A special parser , called the expectation parser , is used to analyze at the sentence level .</sentence>
				<definiendum id="0">special parser</definiendum>
				<definiens id="0">called the expectation parser , is used to analyze at the sentence level</definiens>
			</definition>
			<definition id="1">
				<sentence>Merge ( M1 , M2 ) yields a meaning M that is identical to , or a generalization of , M1 and M2 .</sentence>
				<definiendum id="0">Merge</definiendum>
				<definiens id="0">a meaning M that is identical to , or a generalization of , M1 and M2</definiens>
			</definition>
			<definition id="2">
				<sentence>bsize = the total number of states in B. E ( i ) = { k I J &gt; 0 ( i , j , k ) is in B } , the set of successor states to state i , also called the expected sentence set of i. P ( S , E ( current ) ) = The result of the expectation parser with input S and E ( current ) , where S is the current input sentence which may have errors , and E ( current ) is a set of expected meanings in B , the successors of node current .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">E</definiendum>
				<definiens id="0">the total number of states in B. E ( i ) = { k I J &gt; 0 ( i , j , k ) is in B } , the set of successor states to state i , also called the expected sentence set of i. P ( S , E ( current ) ) = The result of the expectation parser with input S and E ( current ) , where</definiens>
				<definiens id="1">a set of expected meanings in B , the successors of node current</definiens>
			</definition>
			<definition id="3">
				<sentence>An expected sentence set , E ( current ) , along with the most recent input sentence S , are inputs to the expectation parser P. The expectation parser P uses these two inputs to determine the meaning M ( S ) of the input sentence S. Thus , M ( S ) is a deep parse of S. The function Predicts determines if one of the sentences in E ( current ) predicts M ( S ) .</sentence>
				<definiendum id="0">, M ( S )</definiendum>
				<definiens id="0">current ) , along with the most recent input sentence S , are inputs to the expectation parser P. The expectation parser P uses these two inputs to determine the meaning M ( S ) of the input sentence S. Thus</definiens>
			</definition>
			<definition id="4">
				<sentence>• LOSTWS ( lost word slot ) : Assume that the needed word slot from the scanner is lost due to an error in recognition .</sentence>
				<definiendum id="0">• LOSTWS</definiendum>
				<definiens id="0">lost word slot ) : Assume that the needed word slot from the scanner is lost due to an error in recognition</definiens>
			</definition>
			<definition id="5">
				<sentence>Thus , the node containing the command ADV is the parent of the node containing the command CHEK PART ADJ , and so is succeeded by it .</sentence>
				<definiendum id="0">ADV</definiendum>
				<definiens id="0">the parent of the node containing the command CHEK PART ADJ , and so is succeeded by it</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus , we have the following equations that define the various rating values , where n is the number of word slots in the sentence : 1 ) The Transition Value word slot transition value : ws transition\ [ x\ ] = value of SKIPWORD , EXTRA .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of word slots in the sentence : 1 ) The Transition Value word slot transition value : ws transition\ [ x\ ] = value of SKIPWORD</definiens>
			</definition>
			<definition id="7">
				<sentence>The task of the expectation module is to acquire a general dialogue from a series of dialogues spoken by a user .</sentence>
				<definiendum id="0">expectation module</definiendum>
				<definiens id="0">to acquire a general dialogue from a series of dialogues spoken by a user</definiens>
			</definition>
			<definition id="8">
				<sentence>The expectation module takes two inputs and produces two outputs .</sentence>
				<definiendum id="0">expectation module</definiendum>
				<definiens id="0">takes two inputs and produces two outputs</definiens>
			</definition>
			<definition id="9">
				<sentence>The role of the predicate Predicts can be best understood by recalling the function of the parser P. P uses the set of expected sentences E ( current ) to try to error correct the incoming sentence S. P may do this by discovering that some Mk in E ( current ) is quite similar to M ( S ) .</sentence>
				<definiendum id="0">role of the predicate Predicts</definiendum>
				<definiens id="0">understood by recalling the function of the parser P. P uses the set of expected sentences E ( current ) to try to error correct the incoming sentence</definiens>
			</definition>
			<definition id="10">
				<sentence>The Merge function takes two inputs , M1 and M2 , which have been determined by the Mergeable function to be similar in some way by considering their respective environments and meanings .</sentence>
				<definiendum id="0">Merge function</definiendum>
				<definiens id="0">takes two inputs</definiens>
			</definition>
</paper>

		<paper id="3001">
			<definition id="0">
				<sentence>Attention is an essential factor in explicating the processing of utterances in discourse .</sentence>
				<definiendum id="0">Attention</definiendum>
				<definiens id="0">an essential factor in explicating the processing of utterances in discourse</definiens>
			</definition>
			<definition id="1">
				<sentence>The linguistic structure consists of the discourse segments and an embedding relationship that can hold between them .</sentence>
				<definiendum id="0">linguistic structure</definiendum>
			</definition>
			<definition id="2">
				<sentence>The attentional state is a property of the discourse itself , not of the discourse participants .</sentence>
				<definiendum id="0">attentional state</definiendum>
				<definiens id="0">a property of the discourse itself</definiens>
			</definition>
			<definition id="3">
				<sentence>Cognitive state is a richer structure , one that includes at least the knowledge , beliefs , desires , and intentions of an agent , as well as the cognitive corre- ' lates of the attentional state as modeled in this paper .</sentence>
				<definiendum id="0">Cognitive state</definiendum>
				<definiens id="0">a richer structure , one that includes at least the knowledge , beliefs , desires , and intentions of an agent</definiens>
			</definition>
			<definition id="4">
				<sentence>ICP ( Believe OCP P2 ) ) where P2 = the proposition that young people can not drink in through their eyes a continuous spectacle of intense and strained activity without harmful effects .</sentence>
				<definiendum id="0">ICP</definiendum>
				<definiens id="0">Believe OCP P2 ) ) where P2 = the proposition that young people can not drink in through their eyes a continuous spectacle of intense and strained activity without harmful effects</definiens>
			</definition>
			<definition id="5">
				<sentence>ICP ( Believe OCP P5 ) ) where P5 = the proposition that the content of movies ( i.e. , the character of the plays ) is not the best .</sentence>
				<definiendum id="0">ICP</definiendum>
				<definiens id="0">Believe OCP P5 ) ) where P5 = the proposition that the content of movies ( i.e. , the character of the plays</definiens>
			</definition>
			<definition id="6">
				<sentence>ICP ( Believe OCP P6 ) ) where P6 = the proposition that the stories ( i.e. , the plays ) in movies are exciting and over-emotional .</sentence>
				<definiendum id="0">ICP</definiendum>
				<definiens id="0">Believe OCP P6 ) ) where P6 = the proposition that the stories ( i.e. , the plays ) in movies are exciting and over-emotional</definiens>
			</definition>
			<definition id="7">
				<sentence>The primary example is the use of first in ( 1 ) to mark the start of the segment and to indicate that its DSP is the first of several intentions whose satisfaction will contribute to satisfying the larger discourse of which they are a part .</sentence>
				<definiendum id="0">DSP</definiendum>
			</definition>
			<definition id="8">
				<sentence>For example , if there have been several interruptions ( see Section 5 ) , the phrase but anyway indicates a return to some previously interrupted discourse , but does not specify which one .</sentence>
				<definiendum id="0">several interruptions</definiendum>
			</definition>
			<definition id="9">
				<sentence>I0 is an intention to believe , whose proposition is a generalization of the ~p expressed in ( 4 ) .</sentence>
				<definiendum id="0">I0</definiendum>
				<definiens id="0">an intention to believe</definiens>
			</definition>
			<definition id="10">
				<sentence>From an intuitive view , we observe that interruptions are pieces of discourse that break the flow of the preceding discourse .</sentence>
				<definiendum id="0">interruptions</definiendum>
				<definiens id="0">pieces of discourse that break the flow of the preceding discourse</definiens>
			</definition>
			<definition id="11">
				<sentence>D2 is an interruption that breaks the flow of D1 and is distinct from D 1 .</sentence>
				<definiendum id="0">D2</definiendum>
				<definiens id="0">an interruption that breaks the flow of D1</definiens>
			</definition>
			<definition id="12">
				<sentence>Weak definition : An interruption is a discourse segment whose DSP is not dominated nor satisfaction-preceded by the DSP of the immediately preceding segment .</sentence>
				<definiendum id="0">Weak definition</definiendum>
				<definiens id="0">a discourse segment whose DSP is not dominated nor satisfaction-preceded by the DSP of the immediately preceding segment</definiens>
			</definition>
			<definition id="13">
				<sentence>The third type of interruption , which we call a digression , is defined as a strong interruption that contains a reference to some entity that is salient in both the interruption and the interrupted segment .</sentence>
				<definiendum id="0">interruption</definiendum>
				<definiens id="0">a strong interruption that contains a reference to some entity that is salient in both the interruption and the interrupted segment</definiens>
			</definition>
			<definition id="14">
				<sentence>In all discourse changes , the ICP must provide information that allows the OCP to determine all of the following : or creates a new one ; Cue phrases can pack in all of this information , except for ( 5 ) .</sentence>
				<definiendum id="0">Cue phrases</definiendum>
				<definiens id="0">provide information that allows the OCP to determine all of the following : or creates a new one ;</definiens>
			</definition>
			<definition id="15">
				<sentence>The space containing A is salient , but less so than the space with B. Cue phrase ( s ) to signal this case , and only this one , must communicate two pieces of information : that there is a change to some new purpose ( resulting in a new focus space being created in the attentional state model rather than a return to one on the stack ) and that the new purpose ( DSP B ) is dominated by DSP A. Typical cue phrases for this kind of change are for example and to wit , and sometimes first and second .</sentence>
				<definiendum id="0">Cue phrase</definiendum>
				<definiens id="0">a change to some new purpose ( resulting in a new focus space being created in the attentional state model rather than a return to one on the stack ) and that the new purpose ( DSP B ) is dominated by DSP A. Typical cue phrases</definiens>
			</definition>
			<definition id="16">
				<sentence>DISCOURSE-LEVEL INTENTIONS The intentions that serve as DP/DSPs are natural extensions of the intentions Grice ( 1969 ) considers essential to developing a theory of utterer 's meaning .</sentence>
				<definiendum id="0">DISCOURSE-LEVEL INTENTIONS</definiendum>
				<definiens id="0">The intentions that serve as DP/DSPs are natural extensions of the intentions Grice ( 1969 ) considers essential to developing a theory of utterer 's meaning</definiens>
			</definition>
			<definition id="17">
				<sentence>The following portion of his final definition 16 is relevant to this paper : By uttering x U meant that *6p is true iff ( ~tA ) ( 3f \ [ features of the utterance\ ] ) ( 3c \ [ ways of correlating f with utterances17\ ] ) : ( a ) U uttered x intending ( 2 ) that U intends A to think that U ffs that p U ~ks that p ment of ( 4 ) himself to ~k that p Grice takes *~p to be the meaning of the utterance , where *ff is a mood indicator associated with the propositional attitude q~ ( e.g. , *q~=assert and ~k=believe ) .</sentence>
				<definiendum id="0">*ff</definiendum>
				<definiens id="0">a ) U uttered x intending ( 2 ) that U intends A to think that U ffs that p U ~ks that p ment of ( 4 ) himself to ~k that p Grice takes *~p to be the meaning of the utterance</definiens>
				<definiens id="1">a mood indicator associated with the propositional attitude q~</definiens>
			</definition>
			<definition id="18">
				<sentence>For expository purposes , we use the following notation to represent these utterance-level intentions : Intend ( ICP , Believe ( OCP , ICP is a German soldier ) ) Intend ( ICP , Intend ( OCP , OCP give ICP a beer ) ) To extend Grice 's definition to discourses , we replace the utterance x with a discourse segment DS , the utterer U with the initiator of a discourse segment ICP , and the audience A with the OCP .</sentence>
				<definiendum id="0">ICP</definiendum>
				<definiens id="0">a German soldier</definiens>
			</definition>
			<definition id="19">
				<sentence>The full specification of the DP/DSP contains a generates relation that is derived from a relation defined by Goldman ( 1970 ) .</sentence>
				<definiendum id="0">full specification of the DP/DSP</definiendum>
			</definition>
</paper>

		<paper id="4003">
			<definition id="0">
				<sentence>FVS is stated as follows by Garey and Johnson : Given a directed graph G= ( N , L ) and a positive integer k , is there a subset of N consisting of k or fewer nodes that contains at least one vertex from every directed cycle in G ?</sentence>
				<definiendum id="0">FVS</definiendum>
			</definition>
			<definition id="1">
				<sentence>We now observe that asking the question of the size of the smallest set of entries from which D may be reconstructed is computationally equivalent to asking whether or not there is a set of k such entries ( and re-asking this 306 Computational Linguistics , Volume 12 , Number 4 , October-December 1986 A SIMPLIFIED DICTIONARY WITH FIVE PRIMITIVES ama = di ( ( di li zomir ) tso ( di li zomir ) li ) li tso ba + primitive + di + primitive + enig = di zomir ba ( ba tso ( dili zomir ) tso li ) gala = ( di li zomir ) tso ( di li zomir ) li ki = ba tso ( di li zomir ) tso li li + primitive tso + primitive + ub = di li zomir zomir + primitive + David P. Dailey Department of Psychology University of Alaska Fairbanks , Alaska question for a new value of k ) .</sentence>
				<definiendum id="0">SIMPLIFIED DICTIONARY WITH FIVE PRIMITIVES ama</definiendum>
				<definiens id="0">di li zomir ) tso ( di li zomir ) li ) li tso ba + primitive + di + primitive + enig = di zomir ba</definiens>
				<definiens id="1">primitive tso + primitive + ub = di li zomir zomir + primitive + David P. Dailey Department of Psychology University of Alaska Fairbanks</definiens>
			</definition>
</paper>

		<paper id="4001">
			<definition id="0">
				<sentence>The original problem was thus decomposed into two parts : The Morphotactic Problem segments word forms and solves the allomorph relation for morphemes other than stems ; The Stem Alternation Problem solves the residual allomorph relation for stems .</sentence>
				<definiendum id="0">Stem Alternation Problem</definiendum>
				<definiens id="0">solves the residual allomorph relation for stems</definiens>
			</definition>
			<definition id="1">
				<sentence>They obey the general form : ( 4 ) \ [ ml context\ ] &lt; pl context &gt; key &lt; pr context &gt; \ [ mr context\ ] -- &gt; \ [ m result\ ] A rule is applicable and fires whenever a phonemic string identical to key appears somewhere in an input form and the contextual conditions of the rule are satisfied , pl and pr stand for phonemic contexts and inl and mr designate morphemic contexts .</sentence>
				<definiendum id="0">pr stand</definiendum>
				<definiens id="0">applicable and fires whenever a phonemic string identical to key appears somewhere in an input</definiens>
			</definition>
			<definition id="2">
				<sentence>A contextual phonemic string calls for substring identity , morphemic contexts require set inclusion .</sentence>
				<definiendum id="0">contextual phonemic string</definiendum>
				<definiens id="0">calls for substring identity , morphemic contexts require set inclusion</definiens>
			</definition>
			<definition id="3">
				<sentence>A stem rule produces a hypothetical basic stem ( lexeme ) in which the recognized alternant ending is replaced ( concatenated with the root ) by the basic ending ( b ending ) shown .</sentence>
				<definiendum id="0">stem rule</definiendum>
				<definiendum id="1">basic ending</definiendum>
				<definiens id="0">produces a hypothetical basic stem ( lexeme ) in which the recognized alternant ending is replaced ( concatenated with the root</definiens>
			</definition>
			<definition id="4">
				<sentence>An associative Morphotactic Model ( MTModel ) is a pair &lt; { MRi } , &lt; * &gt; , where { MRi } is a set of morphotactic rules ( 5a ) and &lt; * is a precedence relation in the set .</sentence>
				<definiendum id="0">associative Morphotactic Model ( MTModel )</definiendum>
				<definiens id="0">a pair &lt; { MRi } , &lt; * &gt;</definiens>
				<definiens id="1">a set of morphotactic rules ( 5a ) and &lt; * is a precedence relation in the set</definiens>
			</definition>
			<definition id="5">
				<sentence>e v denotes a null ending in a vowel stem , e a null ending in general .</sentence>
				<definiendum id="0">e v</definiendum>
				<definiens id="0">a null ending in a vowel stem , e a null ending in general</definiens>
			</definition>
			<definition id="6">
				<sentence>ev , ev 04 : i , i , i , i , i I i , e , e 05 : i , i , i , i , i I ( i , e ) , e , e 10 : A , A , A , A , A I ( O , A ) , O , O 41 : si , de , t , te , te I s , s , s Verbal stem endings : 01- '' ~V ' ~V ' EV ' eV ' EV ' EV ' EV ' EV '' \ [ EV ' ~V ' EV 02 : A , A , e , A , A , A , A , A I e , e , e , 03 : tA , dA , e v , tA , tA , dA , tA , tA \ [ de , de , de 25 : la , e , e , e , e , e , e , e I e , e , e Each interpretation postulated by MTModel unambiguously chooses a column .</sentence>
				<definiendum id="0">A , A , A I</definiendum>
				<definiendum id="1">A , A , A , A , A I</definiendum>
				<definiens id="0">si , de , t , te , te I s , s , s Verbal stem endings : 01- '' ~V ' ~V ' EV ' eV ' EV ' EV ' EV ' EV '' \</definiens>
				<definiens id="1">e , e , 03 : tA , dA , e v</definiens>
			</definition>
			<definition id="7">
				<sentence>Our associative SAModel consists of a set of stem rules { SRi\ ] , each of the form ( 5b ) and retyped below : ( 11 ) &lt; pl context &gt; a ending\ [ mr context\ ] -~ \ [ cone ( ROOT , b ending ) \ ] 'a ending ' is an alternant stem ending .</sentence>
				<definiendum id="0">SAModel</definiendum>
				<definiens id="0">consists of a set of stem rules { SRi\ ] , each of the form ( 5b ) and retyped below : ( 11 ) &lt; pl context &gt; a ending\ [ mr context\ ] -~ \ [ cone ( ROOT , b ending ) \ ] 'a ending ' is an alternant stem ending</definiens>
			</definition>
			<definition id="8">
				<sentence>SAModel consists of 280 rules .</sentence>
				<definiendum id="0">SAModel</definiendum>
				<definiens id="0">consists of 280 rules</definiens>
			</definition>
			<definition id="9">
				<sentence>The main dictionary consists of an open set of adjectives , nouns , and verbs ( and also numerals ) .</sentence>
				<definiendum id="0">main dictionary</definiendum>
			</definition>
			<definition id="10">
				<sentence>Karttunen et al. ( 1981 ) reports on an implementation that `` can recognize , in a fraction of a second , any inflected form of a word it has stored in its lexicon ... . The present lexicon consists of about 100 roots ... . It can analyze a short unambiguous word in less than 20 milliseconds \ [ DEC-2060/Interlisp\ ] .</sentence>
				<definiendum id="0">present lexicon</definiendum>
				<definiens id="0">consists of about 100 roots ... . It can analyze a short unambiguous word in less than 20 milliseconds</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>PARSIFAL scanned the current token and two lookahead cells .</sentence>
				<definiendum id="0">PARSIFAL</definiendum>
				<definiens id="0">scanned the current token and two lookahead cells</definiens>
			</definition>
			<definition id="1">
				<sentence>When ROBIE identifies a word that has a morphological ending , the morphology must adjust the features of the word .</sentence>
				<definiendum id="0">ROBIE</definiendum>
				<definiens id="0">identifies a word that has a morphological ending , the morphology must adjust the features of the word</definiens>
			</definition>
			<definition id="2">
				<sentence>The final difficult situation arises whenever the following three conditions are true : • the verb will accept a toPP and a toVP , • the item in the second buffer has the features `` tenseless '' and `` ngstart '' and , • the toPP is a required modifier of the verb .</sentence>
				<definiendum id="0">toPP</definiendum>
				<definiens id="0">a required modifier of the verb</definiens>
			</definition>
			<definition id="3">
				<sentence>Robert Milne Resolving Lexieal Ambiguity in a Deterministic Parser This is because what is defined as a determiner that can agree with either a singular noun or a plural noun , as it was in Marcus 's parser .</sentence>
				<definiendum id="0">Robert Milne Resolving Lexieal Ambiguity in a Deterministic Parser This</definiendum>
				<definiens id="0">a determiner that can agree with either a singular noun or a plural noun</definiens>
			</definition>
</paper>

		<paper id="2002">
			<definition id="0">
				<sentence>Pioneering front-end systems such as REL ( Thompson and Thompson 1975 ) , LUNAR ( Woods , Kaplan , and Nash-Webber 1972 ) , ROBOT ( Harris 1977 ) , `` PLANES ( Waltz 1978 ) , REQUEST ( Plath 1976 ) , TORUS ( Mylopoulos et al. 1976 ) , and RENDEZVOUS ( Codd et al. 1978 ) experimented with , among other things , various parsing formalisms ( e.g. semantic grammars , transformational grammars , and augmented transition networks ) ; different knowledge representation schemes ( e.g. using production systems or semantic networks ) ; and the use of clarification dialogues in disambiguating a user 's query .</sentence>
				<definiendum id="0">RENDEZVOUS</definiendum>
				<definiens id="0">transformational grammars , and augmented transition networks ) ; different knowledge representation schemes ( e.g. using production systems or semantic networks</definiens>
			</definition>
			<definition id="1">
				<sentence>The knowledge base consists of two distinct parts : the heuristics , and the frames for the relations and attributes .</sentence>
				<definiendum id="0">knowledge base</definiendum>
				<definiens id="0">consists of two distinct parts : the heuristics , and the frames for the relations and attributes</definiens>
			</definition>
			<definition id="2">
				<sentence>The DISTINGUISHING-VALUE slot provides information for distinguishing a subclass of an entity from other subclasses .</sentence>
				<definiendum id="0">DISTINGUISHING-VALUE slot</definiendum>
				<definiens id="0">provides information for distinguishing a subclass of an entity from other subclasses</definiens>
			</definition>
			<definition id="3">
				<sentence>Similarly , if the value stored for a student under the attribute NATIONALITY is a member of the set ( U.K.U.S.A. Australia ... ) , he/she may be designated as coming from an English-speaking country .</sentence>
				<definiendum id="0">NATIONALITY</definiendum>
				<definiens id="0">a member of the set ( U.K.U.S.A. Australia ... )</definiens>
			</definition>
			<definition id="4">
				<sentence>The conjunction heuristic is the first of the complex heuristics involving more than one predicate .</sentence>
				<definiendum id="0">conjunction heuristic</definiendum>
				<definiens id="0">the first of the complex heuristics involving more than one predicate</definiens>
			</definition>
			<definition id="5">
				<sentence>In this case , it successfully partitions Tqual into three subsets Tqual_l , Tqual_ 2 and Tqual_ 3 where • Tqual_ 1 consists of all tuples in Tqual for which NATURE-OF-FINANCIAL-AID = NSERC-SCHOLARSHIP , • Tqual_ 2 is the subset of all tuples in Tqual with CUMULATIVE-GPA &lt; 6.00 , and • Tqual_ 3 is the subset of tuples in Tqual for which NO-OF-YEARS-COMPLETED &gt; 2 .</sentence>
				<definiendum id="0">Tqual_ 3</definiendum>
				<definiens id="0">consists of all tuples in Tqual for which NATURE-OF-FINANCIAL-AID = NSERC-SCHOLARSHIP , • Tqual_ 2 is the subset of all tuples in Tqual with CUMULATIVE-GPA &lt; 6.00 , and •</definiens>
			</definition>
			<definition id="6">
				<sentence>( GRAD-STUDENT-RECORDS ( EQUAL ( STUDENTS NO-OF-YEARS-COMPLETED ) 0 ) ) Next we take a more complicated question-answer pair : Q10 : Which students are working as T.A. or R.A. ?</sentence>
				<definiendum id="0">GRAD-STUDENT-RECORDS</definiendum>
				<definiendum id="1">EQUAL</definiendum>
			</definition>
			<definition id="7">
				<sentence>( OBTAIN GRAD-STUDENT-RECORDS ( AND-ANY-OF ( EQUAL ( STUDENTS NATURE-OF-FINANCIAL-AID ) TA ) ( EQUAL ( STUDENTS NATURE-OF-FINANCDd~-AID ) ILA ) ) ) S10 : Students who have completed more than one year at the University and who are not employed outside the University .</sentence>
				<definiendum id="0">OBTAIN GRAD-STUDENT-RECORDS</definiendum>
				<definiendum id="1">AND-ANY-OF ( EQUAL</definiendum>
				<definiens id="0">STUDENTS NATURE-OF-FINANCIAL-AID ) TA ) ( EQUAL ( STUDENTS NATURE-OF-FINANCDd~-AID ) ILA ) ) ) S10 : Students who have completed more than one year at the University and who are not employed outside the University</definiens>
			</definition>
			<definition id="8">
				<sentence>( GRAD-STUDENT-RECORDS ( AND-ALL-OF ( GREATER-THAN ( STUDENTS NO-OF-YEARSCOMPLETED ) 1 ) ( NOT-EQUAL ( STUDENTS NATURE-OF-FINANCIAL-AID ) OUTSIDE-JOB ) ) ) We do not want to downplay the difficulties of interpreting natural language into an internal form such as this , nor do we want to trivialize the difficulty of producing surface language responses from the internal form .</sentence>
				<definiendum id="0">GRAD-STUDENT-RECORDS</definiendum>
				<definiendum id="1">AND-ALL-OF ( GREATER-THAN ( STUDENTS NO-OF-YEARSCOMPLETED ) 1 ) ( NOT-EQUAL</definiendum>
				<definiens id="0">STUDENTS NATURE-OF-FINANCIAL-AID ) OUTSIDE-JOB ) ) ) We do not want to downplay the difficulties of interpreting natural language into an internal form such as this , nor do we want to trivialize the difficulty of producing surface language responses from the internal form</definiens>
			</definition>
			<definition id="9">
				<sentence>The foreign-key heuristic involves a join and a projection , and finally the application of all previous heuristics .</sentence>
				<definiendum id="0">foreign-key heuristic</definiendum>
				<definiens id="0">involves a join and a projection , and finally the application of all previous heuristics</definiens>
			</definition>
			<definition id="10">
				<sentence>The conjunction heuristic takes time of the order O ( N a N t + N a Ntl ) where Ntl is the sum of the number of tuples in Tqual and the number of tuples in Tunqual that satisfy some mathematical relation ( s ) satisfied by the !</sentence>
				<definiendum id="0">Ntl</definiendum>
				<definiens id="0">the sum of the number of tuples in Tqual and the number of tuples in Tunqual that satisfy some mathematical relation</definiens>
			</definition>
			<definition id="11">
				<sentence>S14 : All students with a GPA of greater than 5 .</sentence>
				<definiendum id="0">S14</definiendum>
				<definiens id="0">All students with a GPA of greater than 5</definiens>
			</definition>
</paper>

	</volume>
