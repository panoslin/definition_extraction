<?xml version="1.0" encoding="UTF-8"?>
	<volume id="E06">

		<paper id="1048">
			<definition id="0">
				<sentence>We will use the notationt/p to pick out the subtree of the node at address p in the tree t. Replacing the subtree of t at address p by a tree tprime , written t [ p mapsto→tprime ] is defined as ( using · for the insertion of an element on a list ) t [ ε mapsto→tprime ] = tprime f ( t1 , ... , tn ) [ ( i· p ) mapsto→tprime ] = f ( t1 , ... , ti [ p mapsto→tprime ] , ... , tn ) for 1 ≤ i ≤ n .</sentence>
				<definiendum id="0">t1 , ... , tn</definiendum>
			</definition>
			<definition id="1">
				<sentence>The HEIGHT of a tree t , notated height ( t ) , is defined as follows : height ( x ) = 0 for all x ∈ X and height ( f ( t1 , ... , tn ) ) =1+maxni=1height ( ti ) for all f ∈ F. We can use trees with variables as CONTEXTS in which to place other trees .</sentence>
				<definiendum id="0">HEIGHT of</definiendum>
			</definition>
			<definition id="2">
				<sentence>We will extend the function|·|to provide the unranked symbol associated with these symbols as well , so |e↓| = |e∗| = |e ( i ) /0| = e. A TAG is then a quadruple 〈F , S , I , A〉 , where F isarankedalphabet ; S∈Fisadistinguishedinitial symbol ; I isthesetofinitialtrees , afinitesubsetof T ( F∪F/0 ∪F↓ ) ; and A is the set of auxiliary trees , afinitesubsetofT ( F∪F/0∪F↓∪F∗ ) .</sentence>
				<definiendum id="0">S∈Fisadistinguishedinitial symbol ; I isthesetofinitialtrees</definiendum>
				<definiendum id="1">A</definiendum>
			</definition>
			<definition id="3">
				<sentence>and Automata Informally , a TREE TRANSDUCER is a function from T ( F ) to T ( G ) defined such that the symbol at the root ofthe input tree and a current state determines an output context in which the recursive images of the subtrees are placed .</sentence>
				<definiendum id="0">TREE TRANSDUCER</definiendum>
				<definiens id="0">a function from T ( F ) to T ( G ) defined such that the symbol at the root ofthe input tree and a current state determines an output context in which the recursive images of the subtrees are placed</definiens>
			</definition>
			<definition id="4">
				<sentence>1 q ∈ Q f ( n ) ∈F ( n ) g ( n ) ∈G ( n ) xi ∈X : := x0 | x1 | x2 | ··· Eqn : := q ( f ( n ) ( x1 , ... , xn ) ) = τ ( n ) τ ( n ) ∈R ( n ) : := g ( m ) ( τ ( n ) 1 , ... , τ ( n ) m ) | qj ( xi ) where 1 ≤ i ≤ n Intuitively speaking , the expressions in R ( n ) are right-hand-side terms using variables limited to the first n. For example , the grammar allows definition of thefollowingsetofequationsdefiningatreetransducer:2 q ( f ( x ) ) = g ( qprime ( x ) , q ( x ) ) q ( a ) = a qprime ( f ( x ) ) = f ( qprime ( x ) ) qprime ( a ) = a This transducer allows for the following derivation : q ( f ( f ( a ) ) = g ( qprime ( f ( a ) , q ( f ( a ) ) ) ) = g ( f ( qprime ( a ) ) , g ( qprime ( a ) , q ( a ) ) ) = g ( f ( a ) , g ( a , a ) ) The relation defined by a tree transducer with initial state q is { 〈t , u〉 | q ( t ) = u } .</sentence>
				<definiendum id="0">qprime ( x ) , q ( x ) ) q</definiendum>
				<definiendum id="1">f ( x ) ) = f ( qprime ( x )</definiendum>
				<definiens id="0">1 q ∈ Q f ( n ) ∈F ( n ) g ( n ) ∈G ( n ) xi ∈X : := x0 | x1 | x2 | ··· Eqn : := q ( f ( n ) ( x1 , ... , xn ) ) = τ ( n ) τ ( n ) ∈R ( n ) : := g ( m ) ( τ ( n ) 1 , ... , τ ( n ) m ) | qj ( xi ) where 1 ≤ i ≤ n Intuitively speaking , the expressions in R ( n ) are right-hand-side terms using variables limited to the first n. For example , the grammar allows definition of thefollowingsetofequationsdefiningatreetransducer:2 q</definiens>
				<definiens id="1">a ) ) ) ) = g ( f ( qprime ( a ) ) , g ( qprime ( a ) , q ( a ) ) ) = g</definiens>
			</definition>
			<definition id="5">
				<sentence>A bimorphism is a triple 〈L , hi , ho〉 , consisting of a regular tree language L ( or , equivalently , a tree automaton ) and two tree homomorphisms hi and ho .</sentence>
				<definiendum id="0">bimorphism</definiendum>
				<definiens id="0">a triple 〈L , hi , ho〉 , consisting of a regular tree language L ( or , equivalently , a tree automaton</definiens>
			</definition>
			<definition id="6">
				<sentence>Embedded tree transducers are a generalization of tree transducers in which states are allowed to take a single additional argument in a restricted manner .</sentence>
				<definiendum id="0">Embedded tree transducers</definiendum>
				<definiens id="0">a generalization of tree transducers in which states are allowed</definiens>
			</definition>
			<definition id="7">
				<sentence>The same transformation can be defined , a bit more cumbersomely , keeping the permutation pi separate , by tracking the permutation and the current address p in a revised transformation floorleft·floorrightpi , p defined as follows : floorleftA/0 ( t1 , ... , tn ) floorrightpi , p = A ( floorleftt1floorrightpi , p·1 , ... , floorlefttnfloorrightpi , p·n ) floorleftA ( t1 , ... , tn ) floorrightpi , p = qA〈floorleftA/0 ( t1 , ... , tn ) floorrightpi , p〉 ( xpi−1 ( p ) ) floorleftA∗floorrightpi , p = x0 floorleftafloorrightpi , p = a We then use floorleftαfloorrightpi , ε for the transformation of the tree α .</sentence>
				<definiendum id="0">floorleftA ( t1 , ... , tn</definiendum>
				<definiendum id="1">t1 , ... , tn</definiendum>
				<definiendum id="2">p〉 ( xpi−1</definiendum>
				<definiens id="0">keeping the permutation pi separate , by tracking the permutation and the current address p in a revised transformation floorleft·floorrightpi , p defined as follows : floorleftA/0 ( t1 , ... , tn ) floorrightpi , p = A ( floorleftt1floorrightpi , p·1 , ... , floorlefttnfloorrightpi , p·n )</definiens>
				<definiens id="1">( p ) ) floorleftA∗floorrightpi , p = x0 floorleftafloorrightpi , p = a We then use floorleftαfloorrightpi , ε for the transformation of the tree α</definiens>
			</definition>
			<definition id="8">
				<sentence>We therefore construct the equation as follows : qA〈x0〉 ( βA ( x1 , x2 , x3 ) ) = floorleftA/0 ( 1 B ( a ) , 2 C ( 3 D ( A∗ ) ) ) floorright = A ( floorleft1 B ( a ) floorright , floorleft2 C ( 3 D ( A∗ ) ) floorright ) = A ( qB〈floorleftB/0 ( a ) floorright〉 ( x1 ) , floorleft2 C ( 3 D ( A∗ ) ) floorright ) = A ( qB〈B ( floorleftafloorright ) 〉 ( x1 ) , floorleft2 C ( 3 D ( A∗ ) ) floorright ) = ··· = A ( qB〈B ( a ) 〉 ( x1 ) , qC〈C ( qD〈D ( x0 ) 〉 ( x3 ) ) 〉 ( x2 ) ) Similar derivations for the remaining trees yield the ( deterministic linear complete ) embedded tree transducer defined by the following set of equations : qA〈〉 ( α ( x1 ) ) = qA〈A ( e ) 〉 ( x1 ) qA〈x0〉 ( βA ( x1 , x2 , x3 ) ) = A ( qB〈B ( a ) 〉 ( x1 ) , qC〈C ( qD〈D ( x0 ) 〉 ( x3 ) ) 〉 ( x2 ) ) qB〈x0〉 ( βB ( x1 ) ) = qB〈B ( b , x0 ) 〉 ( x1 ) qB〈x0〉 ( εB ( ) ) = x0 qC〈x0〉 ( εC ( ) ) = x0 qD〈x0〉 ( εD ( ) ) = x0 We can use this transducer to compute the derived tree for the derivation tree α ( βA ( βB ( εB ) , εC , εD ) ) .</sentence>
				<definiendum id="0">qA〈x0〉 ( βA</definiendum>
				<definiendum id="1">A∗ ) ) floorright ) = A ( qB〈floorleftB/0 ( a ) floorright〉</definiendum>
				<definiendum id="2">floorleft2 C</definiendum>
				<definiendum id="3">Similar derivations for the</definiendum>
				<definiens id="0">D ( A∗ ) ) floorright ) = A ( qB〈B ( floorleftafloorright ) 〉 ( x1 )</definiens>
			</definition>
			<definition id="9">
				<sentence>qA〈〉 ( α ( βA ( βB ( εB ) , εC , εD ) ) ) = qA〈A ( e ) 〉 ( βA ( βB ( εB ) , εC , εD ) ) = A ( qB〈B ( a ) 〉 ( βB ( εB ) ) , qC〈C ( qD〈D ( A ( e ) ) 〉 ( εD ) ) 〉 ( εC ) ) = A ( qB〈B ( b , B ( a ) ) 〉 ( εB ) , C ( qD〈D ( A ( e ) ) 〉 ( εD ) ) ) = A ( B ( b , B ( a ) ) , C ( D ( A ( e ) ) ) ) As a final step , useful later for the bimorphism characterization of synchronous TAG , it is straightforwardtoshowthatthetransducersoconstructed is the composition of a regular tree language and a linear complete embedded tree homomorphism .</sentence>
				<definiendum id="0">qA〈〉</definiendum>
				<definiendum id="1">α ( βA ( βB</definiendum>
				<definiendum id="2">βA ( βB</definiendum>
				<definiendum id="3">qB〈B</definiendum>
				<definiendum id="4">qD〈D</definiendum>
				<definiendum id="5">B</definiendum>
				<definiendum id="6">B</definiendum>
				<definiendum id="7">C ( D ( A ( e</definiendum>
				<definiens id="0">the composition of a regular tree language and a linear complete embedded tree homomorphism</definiens>
			</definition>
			<definition id="10">
				<sentence>Givenalinearcompleteembeddedtreetransducer , we construct a corresponding TAG as follows : For each rule of the form qi〈 [ x0 ] 〉 ( f ( m ) ( x1 , ... , xm ) ) = τ we build a tree named 〈qi , f , τ〉 .</sentence>
				<definiendum id="0">TAG</definiendum>
				<definiens id="0">For each rule of the form qi〈 [ x0 ] 〉 ( f ( m ) ( x1 , ... , xm ) ) = τ we build a tree named 〈qi , f</definiens>
			</definition>
			<definition id="11">
				<sentence>A synchronous TAG ( Shieber , 1994 ) is composed of a set of triples 〈tL , tR , slurabove〉 where the two trees tL and tR areelementarytreesandsluraboveisasetoflinksspecifying pairs of linked operable nodes from tL and tR .</sentence>
				<definiendum id="0">synchronous TAG</definiendum>
				<definiens id="0">composed of a set of triples 〈tL , tR , slurabove〉 where the two trees tL and tR areelementarytreesandsluraboveisasetoflinksspecifying pairs of linked operable nodes from tL and tR</definiens>
			</definition>
</paper>

		<paper id="3005">
			<definition id="0">
				<sentence>In the context of the current research , a why-question is defined as an interrogative sentence in which the interrogative adverb why ( or one of its synonyms ) occurs in ( near ) initial position .</sentence>
				<definiendum id="0">why-question</definiendum>
			</definition>
			<definition id="1">
				<sentence>Based on the classification of adverbial clauses by Quirk ( 1985:15.45 ) , we distinguish the following sub-types of reason : cause , motivation , circumstance ( which combines reason with conditionality ) , and purpose .</sentence>
				<definiendum id="0">circumstance</definiendum>
				<definiens id="0">combines reason with conditionality ) , and purpose</definiens>
			</definition>
			<definition id="2">
				<sentence>The answer type circumstance , defined by Quirk ( cf. section 15.45 ) as a combination of reason with conditionality , is also rare as well as difficult to recognize .</sentence>
				<definiendum id="0">answer type circumstance</definiendum>
				<definiens id="0">cf. section 15.45 ) as a combination of reason with conditionality , is also rare as well as difficult to recognize</definiens>
			</definition>
			<definition id="3">
				<sentence>The retrieval module , which comes directly after the question analysis module , uses the output of the question analysis module for finding candidate answer paragraphs ( or documents ) .</sentence>
				<definiendum id="0">retrieval module</definiendum>
				<definiens id="0">comes directly after the question analysis module , uses the output of the question analysis module for finding candidate answer paragraphs ( or documents )</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>Wikipedia is a free online encyclopedia written collaboratively by volunteers , using a wiki software that allows almost anyone to add and change articles .</sentence>
				<definiendum id="0">Wikipedia</definiendum>
				<definiens id="0">a free online encyclopedia written collaboratively by volunteers</definiens>
			</definition>
			<definition id="1">
				<sentence>For any entity CTBEBX , CTBMD8CXD8D0CT is the title name of the corresponding article , and CTBMCC is the text of the article .</sentence>
				<definiendum id="0">CTBMD8CXD8D0CT</definiendum>
				<definiendum id="1">CTBMCC</definiendum>
				<definiens id="0">the text of the article</definiens>
			</definition>
			<definition id="2">
				<sentence>Its redirect pages correspond to acronyms ( U.S.A. , U.S. , USA , US ) , Spanish translations ( Los Estados Unidos , Estados Unidos ) , misspellings ( Untied States ) or synonyms ( Yankee land ) .</sentence>
				<definiendum id="0">Spanish translations</definiendum>
				<definiens id="0">misspellings ( Untied States ) or synonyms ( Yankee land )</definiens>
			</definition>
			<definition id="3">
				<sentence>least two capital letters , then CT is a named entity .</sentence>
				<definiendum id="0">CT</definiendum>
			</definition>
			<definition id="4">
				<sentence>If at least BJBHB1 of these occurrences are capitalized , then CT is a named entity .</sentence>
				<definiendum id="0">CT</definiendum>
				<definiens id="0">a named entity</definiens>
			</definition>
			<definition id="5">
				<sentence>The second step constructs the actual dictionary BW as follows : AF The set of entries in BW consists of all strings that may denote a named entity , i.e. if CTBEBX is a named entity , then its title name CTBMD8CXD8D0CT , its redirect names CTBMCA , and its disambiguation names CTBMBW are all added as entries in BW .</sentence>
				<definiendum id="0">actual dictionary BW</definiendum>
				<definiens id="0">AF The set of entries in BW consists of all strings that may denote a named entity</definiens>
				<definiens id="1">a named entity , then its title name CTBMD8CXD8D0CT , its redirect names CTBMCA , and its disambiguation names CTBMBW are all added as entries in BW</definiens>
			</definition>
			<definition id="6">
				<sentence>If CUB4DBB5 is the frequency of word DB in document CS , and C6 is the total number of Wikipedia articles , then the weight of word DBBECE in the D8CU A2 CXCSCU representation of CS is : CS DB BP CUB4DBB5D0D2 C6 CSCUB4DBB5 ( 2 ) An error analysis of the cosine-based ranking method reveals that , in many cases , the pair CWD5BNCTCX fails to rank first , even though words from the query context unambiguously indicate CT as the actual denoted entity .</sentence>
				<definiendum id="0">C6</definiendum>
				<definiens id="0">the frequency of word DB in document CS , and</definiens>
				<definiens id="1">the total number of Wikipedia articles , then the weight of word DBBECE in the D8CU A2 CXCSCU representation of CS is : CS DB BP CUB4DBB5D0D2 C6 CSCUB4DBB5 ( 2 ) An error analysis of the cosine-based ranking method reveals that , in many cases , the pair CWD5BNCTCX fails to rank first</definiens>
			</definition>
			<definition id="7">
				<sentence>We consider using a linear ranking function as follows : CMCT BP CPD6CVD1CPDC CT CZ DB A8B4D5BNCT CZ B5 ( 3 ) The feature vector A8B4D5BNCT CZ B5 contains a dedicated feature AU CRD3D7 for cosine similarity , and CYCE CY A2 CYBVCY features AU DBBNCR corresponding to combinations of words DB from the Wikipedia vocabulary CE and categories CR from the Wikipedia taxonomy BV : AU CRD3D7 B4D5BNCT CZ B5 BP CRD3D7B4D5BMCCBNCT CZ BMCCB5 ( 4 ) AU DBBNCR B4D5BNCT CZ B5 BP AQ BD if DBBED5BMCC and CRBECT CZ BMBVBN BC otherwiseBM The weight vector DB models the magnitude of each word-category correlation , and can be learned by training on the query dataset described at the beginning of Section 4 .</sentence>
				<definiendum id="0">CMCT BP CPD6CVD1CPDC CT CZ DB A8B4D5BNCT CZ B5</definiendum>
				<definiens id="0">feature vector A8B4D5BNCT CZ B5 contains a dedicated feature AU CRD3D7 for cosine similarity</definiens>
			</definition>
			<definition id="8">
				<sentence>BV is a parameter that allows trading-off margin size against training error .</sentence>
				<definiendum id="0">BV</definiendum>
				<definiens id="0">a parameter that allows trading-off margin size against training error</definiens>
			</definition>
			<definition id="9">
				<sentence>The learned DB is a linear combination of the feature vectors A8B4D5BNCT CZ B5 , which makes it possible to use kernels ( Vapnik , 1998 ) .</sentence>
				<definiendum id="0">DB</definiendum>
			</definition>
			<definition id="10">
				<sentence>Table 3 shows a number of relevant statistics for each scenario : # CAT represents the number of Wikipedia categories , # SV is the number of support vectors , TK ( A ) and Cos ( A ) are the accuracy of the Taxonomy Kernel and the Cosine similarity respectively .</sentence>
				<definiendum id="0">CAT</definiendum>
				<definiendum id="1">SV</definiendum>
				<definiens id="0">the number of Wikipedia categories</definiens>
				<definiens id="1">the number of support vectors</definiens>
			</definition>
</paper>

		<paper id="2003">
			<definition id="0">
				<sentence>On corpora validation becomes more and more important for theoretical models , and the accuracy of these models can be evaluated either with regard to their ability to account for the reality of a given corpus ( pursuing descriptive aims ) , either with regard to their ability to analyse it accurately ( pursuing operational aims ) .</sentence>
				<definiendum id="0">corpora validation</definiendum>
				<definiens id="0">becomes more and more important for theoretical models</definiens>
			</definition>
			<definition id="1">
				<sentence>95 Figure 1 : LinguaStream Integrated Environment low-level architecture of LinguaStream is comparable to the HoG middleware , but we are more interested in higher-level aspects such as analysis models and methodological concerns .</sentence>
				<definiendum id="0">LinguaStream</definiendum>
				<definiens id="0">LinguaStream Integrated Environment low-level architecture of</definiens>
			</definition>
			<definition id="2">
				<sentence>• A system called EDCG ( Extended-DCG ) allows local unification grammars to be written , using the DCG ( Definite Clause Grammars ) syntax of Prolog .</sentence>
				<definiendum id="0">DCG</definiendum>
				<definiens id="0">Definite Clause Grammars ) syntax of Prolog</definiens>
			</definition>
			<definition id="3">
				<sentence>• A system called MRE ( Macro-RegularExpressions ) allows patterns to be described using finite state transducers on surface forms and previously computed annotations .</sentence>
				<definiendum id="0">MRE ( Macro-RegularExpressions</definiendum>
			</definition>
</paper>

		<paper id="2017">
			<definition id="0">
				<sentence>In step 2 we used point-wise mutual information ( PMI ) as the co-occurrence based measure of semantic associations between pairs of the vocabulary terms .</sentence>
				<definiendum id="0">PMI</definiendum>
				<definiens id="0">the co-occurrence based measure of semantic associations between pairs of the vocabulary terms</definiens>
			</definition>
			<definition id="1">
				<sentence>We used the term frequency as an estimate for p ( w|d ) .</sentence>
				<definiendum id="0">term frequency</definiendum>
				<definiens id="0">an estimate for p ( w|d )</definiens>
			</definition>
</paper>

		<paper id="2023">
			<definition id="0">
				<sentence>Persian morphology is an affixal system consisting mainly of suffixes and a few prefixes .</sentence>
				<definiendum id="0">Persian morphology</definiendum>
				<definiens id="0">an affixal system consisting mainly of suffixes and a few prefixes</definiens>
			</definition>
			<definition id="1">
				<sentence>The nominal paradigm consists of a relatively small number of affixes [ Megerdoomian 2000 ] .</sentence>
				<definiendum id="0">nominal paradigm</definiendum>
			</definition>
			<definition id="2">
				<sentence>There is no morphological irregularity in Persian and all of the words are stems or derived words , except some imported foreign words , that are not compatible with Persian rules ( such as irregular Arabic plural forms imported to Persian . )</sentence>
				<definiendum id="0">Persian rules</definiendum>
				<definiens id="0">such as irregular Arabic plural forms imported to Persian</definiens>
			</definition>
			<definition id="3">
				<sentence>( 1 ) ) | ( log ) ( log ) , ( 22 MCpMp MModelCCorpusnLengthDescriptio MDL analysis proposes that the morphology M which minimizes the objective function in ( 1 ) is the best morphology of the corpus .</sentence>
				<definiendum id="0">morphology M</definiendum>
				<definiens id="0">minimizes the objective function in ( 1 ) is the best morphology of the corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>} / ) 1 ) ( ( * ) ( { WNLPlenLPfreqRF CWNRPlenRPfreq * } / ) 1 ) ( ( * ) ( { In which LP is the left part of word , RP is the right part of it , Len ( p ) is the length of part P ( number of characters ) , freq ( p ) is the frequency of part P in corpus , WN is the number of words ( corpus size ) and C is a constant number .</sentence>
				<definiendum id="0">RP</definiendum>
				<definiendum id="1">p )</definiendum>
				<definiendum id="2">WN</definiendum>
				<definiendum id="3">C</definiendum>
				<definiens id="0">the left part of word ,</definiens>
				<definiens id="1">the right part of it</definiens>
				<definiens id="2">the length of part P ( number of characters</definiens>
				<definiens id="3">the frequency of part P in corpus</definiens>
				<definiens id="4">the number of words ( corpus size ) and</definiens>
			</definition>
			<definition id="5">
				<sentence>In this cost function freq ( LP ) /WN can be interpreted as the probability of LP being a morph in the corpus .</sentence>
				<definiendum id="0">LP</definiendum>
				<definiens id="0">the probability of LP being a morph in the corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>' In which E is the description length , calculated in equation ( 1 ) and RF the cost function described in equation ( 2 ) .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">the description length , calculated in equation ( 1 ) and RF the cost function described in equation ( 2 )</definiens>
			</definition>
			<definition id="7">
				<sentence>Precision is the number of correct splits divided to the total number of splits done and recall is the number of correct splits divided by total number of gold splits .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the number of correct splits divided to the total number of splits done and recall is the number of correct splits divided by total number of gold splits</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>The interpretation grammar for the domain , written in GF , translates user utterancesto dialoguemoves and thereby holds all possible interpretations of user utterances ( Ljungl¨of et al , 2005 ) .</sentence>
				<definiendum id="0">interpretation grammar</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Gothenburg Spoken Language ( GSLC ) corpus consists of transcribed Swedish spoken language from different social activities such as auctions , phone calls , meetings , lectures and taskoriented dialogue ( Allwood , 1999 ) .</sentence>
				<definiendum id="0">Gothenburg Spoken Language</definiendum>
				<definiens id="0">consists of transcribed Swedish spoken language from different social activities such as auctions , phone calls , meetings , lectures and taskoriented dialogue</definiens>
			</definition>
			<definition id="2">
				<sentence>This simple SLM ( named MP3GFLM ) has the same vocabulary as the Nuance Grammar and models the same language as the GF grammar .</sentence>
				<definiendum id="0">SLM</definiendum>
				<definiens id="0">named MP3GFLM ) has the same vocabulary as the Nuance Grammar and models the same language as the GF grammar</definiens>
			</definition>
			<definition id="3">
				<sentence>We also created two other simple SLMs : a class-based one ( with the classes Song , Artist and Radiostation ) and a model based on a variant of the MP3 corpus where the utterances in which songs and artists co-occur would only match real artist-song pairs ( i.e. including some music knowledge in the model ) .</sentence>
				<definiendum id="0">MP3 corpus</definiendum>
			</definition>
			<definition id="4">
				<sentence>The vocabulary for the MP3GFLM and the MP3NuanceGr is the small MP3 vocabulary .</sentence>
				<definiendum id="0">MP3NuanceGr</definiendum>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>Singular value decomposition ( SVD ) is a near relative of eigen decomposition , appropriate to domains where input is asymmetrical .</sentence>
				<definiendum id="0">SVD</definiendum>
			</definition>
			<definition id="1">
				<sentence>Latent Semantic Analysis ( LSA ) allows passages of text to be compared to each other in a reduced-dimensionality semantic space , based on the wordsthey contain .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">passages of text to be compared to each other in a reduced-dimensionality semantic space , based on the wordsthey contain</definiens>
			</definition>
			<definition id="2">
				<sentence>Optimisation is an important way to increase the applicability of eigen and singular value decomposition .</sentence>
				<definiendum id="0">Optimisation</definiendum>
				<definiens id="0">an important way to increase the applicability of eigen and singular value decomposition</definiens>
			</definition>
			<definition id="3">
				<sentence>GHA calculates the eigen decomposition of a matrix based on single observations presented serially .</sentence>
				<definiendum id="0">GHA</definiendum>
				<definiens id="0">calculates the eigen decomposition of a matrix based on single observations presented serially</definiens>
			</definition>
			<definition id="4">
				<sentence>The algorithm presented here differs in that where GHA produces the eigen decomposition of symmetrical data , our algorithm produces the singular value decomposition of asymmetrical data .</sentence>
				<definiendum id="0">GHA</definiendum>
				<definiens id="0">produces the eigen decomposition of symmetrical data , our algorithm produces the singular value decomposition of asymmetrical data</definiens>
			</definition>
			<definition id="5">
				<sentence>The singular value decomposition of a rectangular data matrix , A , can be presented as ; A = UΣV T ( 1 ) where U and V are matrices of orthogonal left and right singular vectors ( columns ) respectively , and Σ is a diagonal matrix of the corresponding singular values .</sentence>
				<definiendum id="0">Σ</definiendum>
				<definiens id="0">singular value decomposition of a rectangular data matrix , A , can be presented as ; A = UΣV T ( 1 ) where U and V are matrices of orthogonal left and right singular vectors ( columns ) respectively , and</definiens>
				<definiens id="1">a diagonal matrix of the corresponding singular values</definiens>
			</definition>
			<definition id="6">
				<sentence>The essence of these algorithms is a simple Hebbian learning rule : Un ( t +1 ) = Un ( t ) +λ∗ ( UTn ∗Aj ) ∗Aj ( 2 ) Un is the n’th column of U ( i.e. , the n’th eigenvector , see equation 1 ) , λ is the learning rate and Aj is the j’th column of training matrix A. t is the timestep .</sentence>
				<definiendum id="0">Un</definiendum>
				<definiendum id="1">Aj</definiendum>
				<definiens id="0">the j’th column of training matrix</definiens>
			</definition>
			<definition id="7">
				<sentence>Sanger’s final formulation ( Sanger , 1989 ) is : cij ( t+1 ) = cij ( t ) +γ ( t ) ( yi ( t ) xj ( t ) ( 3 ) −yi ( t ) summationdisplay k≤i ckj ( t ) yk ( t ) ) In the above , cij is an individual element in the current eigenvector , xj is the input vector and yi is the activation ( that is to say , ci .</sentence>
				<definiendum id="0">cij</definiendum>
				<definiendum id="1">xj</definiendum>
				<definiendum id="2">yi</definiendum>
				<definiens id="0">an individual element in the current eigenvector ,</definiens>
				<definiens id="1">the activation ( that is to say , ci</definiens>
			</definition>
			<definition id="8">
				<sentence>The training update , that is , the vector to be added to the eigenvector , can then be more simply described as follows , making the next steps more readable ; trianglec = c.x ( x ) ( 5 ) Let us begin with a simplification of 5 : trianglec = 1ncX ( X ) ( 6 ) Here , the upper case X is the entire data matrix .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">the entire data matrix</definiens>
			</definition>
			<definition id="9">
				<sentence>n is the number of training items .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="10">
				<sentence>ax ) bx ( 10 ) Here , σ is the singular value and a and b are left and right data vectors .</sentence>
				<definiendum id="0">σ</definiendum>
			</definition>
			<definition id="11">
				<sentence>The y axis gives the projection of the vector for the given letter onto the singular vector .</sentence>
				<definiendum id="0">y axis</definiendum>
				<definiens id="0">gives the projection of the vector for the given letter onto the singular vector</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>For each utterance boundary , LCSeg calculates a lexical cohesion score by computing the cosine similarity at the transition between the twowindows .</sentence>
				<definiendum id="0">LCSeg</definiendum>
				<definiens id="0">calculates a lexical cohesion score by computing the cosine similarity at the</definiens>
			</definition>
			<definition id="1">
				<sentence>Pk ( Beeferman et al. , 1999 ) is the probability that two utterances drawn randomly from a document ( inourcase , ameeting transcript ) areincorrectly identified as belonging to the same topic segment .</sentence>
				<definiendum id="0">Pk</definiendum>
				<definiens id="0">the probability that two utterances drawn randomly from a document</definiens>
			</definition>
			<definition id="2">
				<sentence>We group the features into four classes : ( 1 ) lexicalcohesion-based features ( LF ) : including lexical cohesion value ( LCV ) and estimated posterior probability ( LCP ) ; ( 2 ) interaction features ( IF ) : the amount of overlapping speech ( OVR ) , the amount of silence between speaker segments ( GAP ) , similarity of speaker activity ( ACT ) ; ( 3 ) cuephrase feature ( CUE ) ; and ( 4 ) allavailable features ( ALL ) .</sentence>
				<definiendum id="0">LF )</definiendum>
				<definiendum id="1">LCV</definiendum>
				<definiendum id="2">posterior probability</definiendum>
				<definiendum id="3">LCP</definiendum>
				<definiendum id="4">CUE</definiendum>
				<definiens id="0">the amount of overlapping speech ( OVR ) , the amount of silence between speaker segments ( GAP ) , similarity of speaker activity</definiens>
			</definition>
			<definition id="3">
				<sentence>predicting from ASR output Features extracted from ASRtranscripts are distinct from those extracted from human transcripts in at least three ways : ( 1 ) incorrectly recognized words incur erroneous lexical cohesion features ( LF ) , ( 2 ) incorrectly recognized words incur erroneous cue phrase features ( CUE ) , and ( 3 ) the ASR system recognizes less overlapping speech ( OVR ) .</sentence>
				<definiendum id="0">CUE</definiendum>
				<definiens id="0">( 1 ) incorrectly recognized words incur erroneous lexical cohesion features ( LF ) , ( 2 ) incorrectly recognized words incur erroneous cue phrase features</definiens>
			</definition>
			<definition id="4">
				<sentence>NOCUE is the model using no cue phrase features .</sentence>
				<definiendum id="0">NOCUE</definiendum>
			</definition>
			<definition id="5">
				<sentence>The Topline is the agreement of human annotators on top-level segments .</sentence>
				<definiendum id="0">Topline</definiendum>
				<definiens id="0">the agreement of human annotators on top-level segments</definiens>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>Addressing is an aspect of every form of communication .</sentence>
				<definiendum id="0">Addressing</definiendum>
				<definiens id="0">an aspect of every form of communication</definiens>
			</definition>
			<definition id="1">
				<sentence>Ratified participants are those participants whoare allowed to take part in conversation .</sentence>
				<definiendum id="0">Ratified participants</definiendum>
				<definiens id="0">those participants whoare allowed to take part in conversation</definiens>
			</definition>
			<definition id="2">
				<sentence>Using a vocative is the explicit verbal way to address someone .</sentence>
				<definiendum id="0">vocative</definiendum>
				<definiens id="0">the explicit verbal way to address someone</definiens>
			</definition>
			<definition id="3">
				<sentence>Adjacency pairs and addressing Adjacency pairs ( AP ) are minimal dialogic units that consist of pairs of utterances called “first pair-part” ( or a-part ) and the “second pair-part” ( or b-part ) that are produced by different speakers .</sentence>
				<definiendum id="0">Adjacency</definiendum>
				<definiens id="0">pairs ( AP ) are minimal dialogic units that consist of pairs of utterances called “first pair-part” ( or a-part ) and the “second pair-part” ( or b-part ) that are produced by different speakers</definiens>
			</definition>
			<definition id="4">
				<sentence>When addressing a triad , speaker gaze seems to be evenly distributed over the listeners in the situation where participants are seated around the table .</sentence>
				<definiendum id="0">speaker gaze</definiendum>
				<definiens id="0">seems to be evenly distributed over the listeners in the situation where participants are seated around the table</definiens>
			</definition>
			<definition id="5">
				<sentence>Group Seg ( % ) N DA ( κ ) ADD ( κ ) B &amp; E 91.73 377 0.77 0.81 M &amp; R 86.14 367 0.70 0.70 Table 1 : Inter-annotator agreement on DA and addressee annotation : N-number ofagreed segments In this section we present the results on addressee classification in four-persons face-to-face meetings using Bayesian Network and Naive Bayes classifiers .</sentence>
				<definiendum id="0">N DA ( κ ) ADD</definiendum>
			</definition>
			<definition id="6">
				<sentence>In a dialogue situation , which is an event which lasts as long as the dialogue act performed by the speaker in that situation , the class variable is the addressee of the dialogue act ( ADD ) .</sentence>
				<definiendum id="0">class variable</definiendum>
				<definiens id="0">the addressee of the dialogue act ( ADD )</definiens>
			</definition>
			<definition id="7">
				<sentence>Therefore , we define addressee classifiers to identify one of the following class values : individual Px where x∈ { 0,1,2,3 } and ALLPwhich denotes the whole group .</sentence>
				<definiendum id="0">ALLPwhich</definiendum>
				<definiens id="0">the whole group</definiens>
			</definition>
			<definition id="8">
				<sentence>The AMI corpus contains more natural , scenario-based , meetings that involve groups focused on the design of a TV remote control .</sentence>
				<definiendum id="0">AMI corpus</definiendum>
				<definiens id="0">contains more natural , scenario-based , meetings that involve groups focused on the design of a TV remote control</definiens>
			</definition>
</paper>

		<paper id="3009">
			<definition id="0">
				<sentence>Information Gain , the numerator in equation ( 4 ) , “measures how much information it [ feature i ] contributes to our knowledge of the correct class label [ ... ] by computing the difference in uncertainty ( i.e. entropy ) between the situations without and with knowledge of the value of that feature” ( Daelemans et al. , 2004 , p.20 ) .</sentence>
				<definiendum id="0">Information Gain</definiendum>
				<definiens id="0">“measures how much information it [ feature i ] contributes to our knowledge of the correct class label [ ... ] by computing the difference in uncertainty ( i.e. entropy ) between the situations without and with knowledge of the value of that feature” ( Daelemans et al. , 2004 , p.20 )</definiens>
			</definition>
			<definition id="1">
				<sentence>In the following equations , C is the set of class labels , H ( C ) is the entropy of that set , and Vi is the set of values for feature i. wi = H ( C ) − summationtext v∈Vi P ( v ) ×H ( C|v ) si ( i ) ( 4 ) si ( i ) = − summationdisplay v∈Vi P ( v ) log2P ( v ) ( 5 ) The IB2 algorithm wasdeveloped alongside IB1 in order to reduce storage requirements ( Aha et al. , 1991 ) .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">H ( C )</definiendum>
				<definiendum id="2">Vi</definiendum>
				<definiens id="0">the set of class labels</definiens>
				<definiens id="1">the entropy of that set , and</definiens>
			</definition>
			<definition id="2">
				<sentence>TiMBL : my TiMBL results N &amp; M : Nissim and Markert’s ( 2003 ) results simple learning phase , TiMBL is able to replicate the results from Nissim and Markert ( 2003 ; 2005 ) .</sentence>
				<definiendum id="0">TiMBL</definiendum>
				<definiens id="0">simple learning phase ,</definiens>
				<definiens id="1">able to replicate the results from Nissim</definiens>
			</definition>
			<definition id="3">
				<sentence>Atestinstance wastreated as mixedonly when its several feature vectors were classified differently .</sentence>
				<definiendum id="0">Atestinstance</definiendum>
				<definiens id="0">wastreated as mixedonly when its several feature vectors were classified differently</definiens>
			</definition>
			<definition id="4">
				<sentence>Nevertheless , my first round of experiments has indicated that Memory-Based Learning is a simple but robust approach to metonymy recognition .</sentence>
				<definiendum id="0">Memory-Based Learning</definiendum>
				<definiens id="0">a simple but robust approach to metonymy recognition</definiens>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>U : Next option S : ... Figure 1 : Typical Information Presentation Phase of a Communicator Dialogue Walker et al. ( 2004 ) observe , having to access the set of available options sequentially makes it difficultfortheusertorememberthevariousaspectsof multiple options and to compare them in memory .</sentence>
				<definiendum id="0">U</definiendum>
				<definiens id="0">Next option S : ... Figure 1 : Typical Information Presentation Phase of a Communicator Dialogue Walker et al. ( 2004 ) observe , having to access the set of available options sequentially makes it difficultfortheusertorememberthevariousaspectsof multiple options and to compare them in memory</definiens>
			</definition>
			<definition id="1">
				<sentence>In the user-model ( UM ) based approach , the system identifies a small number of options that best match the user’s preferences ( Moore et al. , 2004 ; Walker et al. , 2004 ) .</sentence>
				<definiendum id="0">user-model ( UM</definiendum>
			</definition>
			<definition id="2">
				<sentence>M : Okay tell me about the ones in Boston .</sentence>
				<definiendum id="0">M</definiendum>
				<definiens id="0">Okay tell me about the ones in Boston</definiens>
			</definition>
			<definition id="3">
				<sentence>The SR dialogues received on average slightly higher scores for understandability ( question 1 ) , which can be explained by the shorter length of the system turns for that system .</sentence>
				<definiendum id="0">SR dialogues</definiendum>
				<definiens id="0">can be explained by the shorter length of the system turns for that system</definiens>
			</definition>
</paper>

		<paper id="3001">
			<definition id="0">
				<sentence>Video-mediated communication systems , shared media spaces , and collaborative virtual environments are technologies developed to support joint activities between geographically distributed groups .</sentence>
				<definiendum id="0">Video-mediated communication systems</definiendum>
				<definiens id="0">collaborative virtual environments are technologies developed to support joint activities between geographically distributed groups</definiens>
			</definition>
			<definition id="1">
				<sentence>LRC uses grammatical function as a central mechanism for resolving the antecedents of anaphoric references .</sentence>
				<definiendum id="0">LRC</definiendum>
				<definiens id="0">uses grammatical function as a central mechanism for resolving the antecedents of anaphoric references</definiens>
			</definition>
			<definition id="2">
				<sentence>The following presents the results of the three different models on 10 trials of the PUZZLE CORPUS in which the pairs had no shared visual space , and 10 trials from when the pairs had access to shared visual information representing the workspace .</sentence>
				<definiendum id="0">PUZZLE CORPUS</definiendum>
				<definiens id="0">in which the pairs had no shared visual space , and 10 trials from when the pairs had access to shared visual information representing the workspace</definiens>
			</definition>
</paper>

		<paper id="1039">
			<definition id="0">
				<sentence>The MEAD framework decomposes sentence extraction into three steps : ( i ) Feature Calculation : Some numerical feature ( s ) are calculated for each sentence , for example , a score based on document position and a score based on the TF*IDF of a sentence .</sentence>
				<definiendum id="0">Calculation</definiendum>
				<definiens id="0">document position and a score based on the TF*IDF of a sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The sentence selection algorithm permits us to select an arbitrary number of sentences to fit a desired word length .</sentence>
				<definiendum id="0">sentence selection algorithm</definiendum>
				<definiens id="0">permits us to select an arbitrary number of sentences to fit a desired word length</definiens>
			</definition>
			<definition id="2">
				<sentence>In this measure , the importance of a node is a combination of its direct importance and of the importance of its children .</sentence>
				<definiendum id="0">importance of a node</definiendum>
			</definition>
			<definition id="3">
				<sentence>The most obvious is a simple greedy selection – sort the nodes in the UDF by the measure of importance and select the most important node until a desired number of features is included .</sentence>
				<definiendum id="0">most obvious</definiendum>
				<definiens id="0">a simple greedy selection – sort the nodes in the UDF by the measure of importance and select the most important node until a desired number of features is included</definiens>
			</definition>
			<definition id="4">
				<sentence>After content selection , the automatic generation of a natural language summary involves the following additional tasks ( Reiter and Dale , 2000 ) : ( i ) structuring the content by ordering and grouping the selected content elements as well as by specifying discourse relations ( e.g. , supporting vs. opposing evidence ) between the resulting groups ; ( ii ) microplanning , which involves lexical selection and sentence planning ; and ( iii ) sentence realization , which produces English text from the output of the microplanner .</sentence>
				<definiendum id="0">realization</definiendum>
				<definiens id="0">i ) structuring the content by ordering and grouping the selected content elements as well as by specifying discourse relations</definiens>
				<definiens id="1">produces English text from the output of the microplanner</definiens>
			</definition>
</paper>

		<paper id="2028">
			<definition id="0">
				<sentence>The difficulty , however , comes from the fact that the information on which 1Accuracy ( Acc ) is a classification measure : Acc= P+NP+N+p+n where p is the number of anaphoric pronoun occurences tagged as non-anaphoric , which we call the false positive cases , n the number of non-anaphoric pronoun ocurrences tagged as anaphoric , the false negative cases .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">non-anaphoric</definiendum>
				<definiens id="0">comes from the fact that the information on which 1Accuracy ( Acc ) is a classification measure : Acc= P+NP+N+p+n where</definiens>
			</definition>
			<definition id="1">
				<sentence>The BN is a model designed to deal with dubious pieces of information .</sentence>
				<definiendum id="0">BN</definiendum>
				<definiens id="0">a model designed to deal with dubious pieces of information</definiens>
			</definition>
</paper>

		<paper id="1040">
			<definition id="0">
				<sentence>BLEU is a precision metric that assesses the quality of a translation in termsof the proportion of itsword ngrams ( n = 4 has become standard ) that it shares with one or more high-quality reference translations .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">a precision metric that assesses the quality of a translation in termsof the proportion of itsword ngrams ( n = 4 has become standard ) that it shares with one or more high-quality reference translations</definiens>
			</definition>
			<definition id="1">
				<sentence>The NIST MT evaluation metric ( Doddington , 2002 ) is an adaptation of BLEU , but where BLEU givesequal weight toall n-grams , NIST gives more importance to less frequent ( hence more informative ) n-grams .</sentence>
				<definiendum id="0">NIST MT evaluation metric</definiendum>
				<definiendum id="1">NIST</definiendum>
				<definiens id="0">an adaptation of BLEU , but where BLEU givesequal weight toall n-grams</definiens>
			</definition>
			<definition id="2">
				<sentence>The SUMTIME project ( Reiter et al. , 2005 ) developed an NLG system which generated textual weather forecasts from numerical forecast data .</sentence>
				<definiendum id="0">SUMTIME project</definiendum>
				<definiens id="0">Reiter et al. , 2005 ) developed an NLG system which generated textual weather forecasts from numerical forecast data</definiens>
			</definition>
			<definition id="3">
				<sentence>SUMTIME is a knowledge-based NLG system .</sentence>
				<definiendum id="0">SUMTIME</definiendum>
			</definition>
			<definition id="4">
				<sentence>In other words , the SUMTIME corpus contains both the inputs ( numerical weather predictions ) and the outputs ( forecast texts ) ofthe forecast-generation process .</sentence>
				<definiendum id="0">SUMTIME corpus</definiendum>
				<definiens id="0">contains both the inputs ( numerical weather predictions ) and the outputs ( forecast texts ) ofthe forecast-generation process</definiens>
			</definition>
			<definition id="5">
				<sentence>pCRU1 language generation ( Belz , 2006 ) is a language generation framework that was designed to facilitate statistical generation techniques that are more efficient and less biased .</sentence>
				<definiendum id="0">pCRU1 language generation</definiendum>
			</definition>
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>The Web is a very rich source of linguistic data , and in the last few years it has been used intensively by linguists and language technologists for many tasks ( Kilgarriff and Grefenstette , 2003 ) .</sentence>
				<definiendum id="0">Web</definiendum>
				<definiens id="0">a very rich source of linguistic data , and in the last few years it has been used intensively by linguists and language technologists for many tasks</definiens>
			</definition>
			<definition id="1">
				<sentence>The similarity of two unigram distributions P and Q is estimated as the relative entropy , or Kullback Leibler distance , or KL ( Cover and Thomas , 1991 ) D ( P||Q ) : D ( P||Q ) = summationdisplay x∈W P ( x ) log P ( x ) Q ( x ) ( 1 ) KL is a measure of the cost , in terms of average number of additional bits needed to describe the random variable , of assuming that the distribution is Q when instead the true distribution is P. Since D ( P||Q ) ≥ 0 , with equality only if P = Q , unigram distributions generated by similar collections should have low relative entropy .</sentence>
				<definiendum id="0">KL</definiendum>
				<definiendum id="1">KL</definiendum>
				<definiens id="0">a measure of the cost</definiens>
			</definition>
			<definition id="2">
				<sentence>To avoid further infinite cases a smoothing value α is added when estimating probabilities ; i.e. , P ( x ) = cP ( x ) + α|W|α +summationtext x∈W cP ( x ) ( 2 ) where cP ( x ) is the frequency of x in distribution P , and |W| is the number of word types in W. distributions What properties distinguish unigram distributions drawn from the whole of a document collection such as the BNC or the Web ( or , rather , from the space of the Web we are interested in sampling from ) from distributions drawn from biased subsets of it ?</sentence>
				<definiendum id="0">cP ( x )</definiendum>
				<definiendum id="1">|W|</definiendum>
				<definiendum id="2">Web</definiendum>
				<definiens id="0">the number of word types in W. distributions What properties distinguish unigram distributions drawn from the whole of a document collection such as the BNC or the</definiens>
			</definition>
			<definition id="3">
				<sentence>C is the total number of categories .</sentence>
				<definiendum id="0">C</definiendum>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>Turkish is a free-constituent order language with complex agglutinative inflectional and derivational morphology and presents interesting challenges for statistical parsing , as in general , dependency relations are between “portions” of words – called inflectional groups .</sentence>
				<definiendum id="0">Turkish</definiendum>
				<definiens id="0">a free-constituent order language with complex agglutinative inflectional and derivational morphology</definiens>
			</definition>
			<definition id="1">
				<sentence>Turkish is an agglutinative language where a sequence ofinflectional andderivational morphemes get affixed to a root ( Oflazer , 1994 ) .</sentence>
				<definiendum id="0">Turkish</definiendum>
			</definition>
			<definition id="2">
				<sentence>Here each IGi denotes relevant inflectional features including the part-of-speech for the root and for any of the derived forms .</sentence>
				<definiendum id="0">IGi</definiendum>
			</definition>
			<definition id="3">
				<sentence>w1 d4d4 d15d15 d35d35 IG1 d15d15 IG2 d15d15 ··· IG∗g1 d15d15 IG1 IG2 ··· IG∗g1 w2 d1d1 d15d15 d36d36 IG1 d15d15 IG2 ··· IG∗g2 d15d15 IGg1+1 ··· IG∗g1+g2 ... ... wn d4d4 d15d15 d35d35 IG1 IG2 ··· IG∗gn d15d15 ··· IG∗Υn Υi =C8ik=1 gk Figure 4 : Sentence Structure can be formulated as T∗ = argmax T P ( T , S ) = argmax T n−1productdisplay i=1 P ( dep ( wi , wH ( i ) ) |S ) ( 1 ) where in our case S is a sequence of units ( words , IGs ) and T , ranges over possible dependency trees consisting of left-to-right dependency links dep ( wi , wH ( i ) ) with wH ( i ) denoting the head unit to which the dependent unit , wi , is linked to .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">IGs</definiendum>
				<definiens id="0">a sequence of units ( words</definiens>
				<definiens id="1">ranges over possible dependency trees consisting of left-to-right dependency links dep ( wi</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>In this paper , we challenge the applicability of this assumption to the semantic category of sentiment , which consists of positive , negative and neutral subcategories , and present a dictionary-based Sentiment Tag Extraction Program ( STEP ) that we use to generate a fuzzy set of English sentiment-bearing words for the use in sentiment tagging systems 1 .</sentence>
				<definiendum id="0">sentiment</definiendum>
				<definiens id="0">consists of positive , negative and neutral subcategories , and present a dictionary-based Sentiment Tag Extraction Program ( STEP</definiens>
			</definition>
			<definition id="1">
				<sentence>GI-H4 HM List composition nouns , verbs , adj. , adv .</sentence>
				<definiendum id="0">GI-H4 HM</definiendum>
				<definiens id="0">List composition nouns , verbs , adj. , adv</definiens>
			</definition>
			<definition id="2">
				<sentence>The HM list includes some sentiment-marked words where not all meanings are laden with sentiment , but also the words where some meanings are neutral and even the words where such neutral meanings are much more frequent than the sentiment-laden ones .</sentence>
				<definiendum id="0">HM list</definiendum>
				<definiens id="0">includes some sentiment-marked words where not all meanings are laden with sentiment</definiens>
			</definition>
			<definition id="3">
				<sentence>Lexicographical entries in the dictionaries , such as WordNet , seek to establish semantic equivalence between the word and its definition and provide a rich source of human-annotated relationships between the words .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="4">
				<sentence>These results suggest that the two measures of word centrality , Net Overlap Score based on multiple STEP runs and the inter-annotator agreement ( HM vs. GI-H4 ) , are directly related 7 .</sentence>
				<definiendum id="0">inter-annotator agreement</definiendum>
				<definiens id="0">the two measures of word centrality</definiens>
			</definition>
</paper>

		<paper id="2013">
			<definition id="0">
				<sentence>FrameNet ( Baker et al. , 1998 ; Johnson et al. , 2003 ) is a comprehensive lexical database that lists descriptions of words in the frame-semantic paradigm ( Fillmore , 1976 ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>The core concept is the frame , which is conceptual structure that represents a type of situation , object , or event , coupled with a semantic valence description that describes what kinds of semantic arguments ( frame elements ) are allowed or required for that particular frame .</sentence>
				<definiendum id="0">core concept</definiendum>
				<definiens id="0">a type of situation , object , or event , coupled with a semantic valence description that describes what kinds of semantic arguments ( frame elements ) are allowed or required for that particular frame</definiens>
			</definition>
			<definition id="2">
				<sentence>For each frame , FrameNet lists a set of lemmas or lexical units ( mostly nouns , verbs , and adjectives , but also a few prepositions and adverbs ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">lists a set of lemmas or lexical units ( mostly nouns , verbs , and adjectives</definiens>
			</definition>
			<definition id="3">
				<sentence>The following layers are used : • The FE layer , which defines the spans and semantic roles of the arguments of the predicate .</sentence>
				<definiendum id="0">FE layer</definiendum>
				<definiens id="0">defines the spans and semantic roles of the arguments of the predicate</definiens>
			</definition>
			<definition id="4">
				<sentence>• A part-of-speech-specific layer , which contains aspectual information for verbs ; and copulas , support expressions , and slot filling information for nouns and adjectives .</sentence>
				<definiendum id="0">part-of-speech-specific layer</definiendum>
				<definiens id="0">contains aspectual information for verbs ; and copulas , support expressions , and slot filling information for nouns and adjectives</definiens>
			</definition>
			<definition id="5">
				<sentence>There are several uses of copulas : • Class membership : John is a sailor .</sentence>
				<definiendum id="0">John</definiendum>
				<definiens id="0">a sailor</definiens>
			</definition>
</paper>

		<paper id="2027">
			<definition id="0">
				<sentence>Theformer is asilent pause , and the latter a pause accompanied by a sound , like ‘hmm’ .</sentence>
				<definiendum id="0">Theformer</definiendum>
				<definiens id="0">asilent pause</definiens>
			</definition>
</paper>

		<paper id="1051">
			<definition id="0">
				<sentence>Information Extraction ( IE ) is the process of finding relevant entities and their relationships within textual documents .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
				<definiens id="0">the process of finding relevant entities and their relationships within textual documents</definiens>
			</definition>
			<definition id="1">
				<sentence>Our global context kernels operate on the patterns above , where each pattern is represented using a bag-of-words instead of sparse subsequences of words , PoS tags , entity and chunk types , or WordNet synsets as in ( Bunescu and Mooney , 2005b ) .</sentence>
				<definiendum id="0">PoS</definiendum>
				<definiendum id="1">WordNet</definiendum>
				<definiens id="0">tags , entity and chunk types , or</definiens>
			</definition>
			<definition id="2">
				<sentence>The Global Context kernel KGC ( R1 , R2 ) is then defined as KFB ( R1 , R2 ) +KB ( R1 , R2 ) +KBA ( R1 , R2 ) , ( 3 ) where KFB , KB and KBA are n-gram kernels that operate on the Fore-Between , Between and Between-After patterns respectively .</sentence>
				<definiendum id="0">Global Context kernel KGC</definiendum>
				<definiendum id="1">KFB</definiendum>
				<definiendum id="2">R2 ) +KB ( R1 , R2 ) +KBA</definiendum>
				<definiens id="0">3 ) where KFB , KB and KBA are n-gram kernels that operate on the Fore-Between , Between and Between-After patterns respectively</definiens>
			</definition>
			<definition id="3">
				<sentence>Formally , given a relation example R , a local context L = t−w , ... , t−1 , t0 , t+1 , ... , t+w is represented as a row vector ψL ( R ) = ( f1 ( L ) , f2 ( L ) , ... , fm ( L ) ) ∈ { 0,1 } m , ( 4 ) where fi is a feature function that returns 1 if it is active in the specified position of L , 0 otherwise3 .</sentence>
				<definiendum id="0">fi</definiendum>
				<definiens id="0">a local context L = t−w , ... , t−1 , t0 , t+1 , ... , t+w is represented as a row vector ψL ( R ) = ( f1 ( L ) , f2 ( L ) , ... , fm ( L ) ) ∈ { 0,1 } m</definiens>
			</definition>
			<definition id="4">
				<sentence>The Local Context kernel KLC ( R1 , R2 ) is defined as Kleft ( R1 , R2 ) +Kright ( R1 , R2 ) , ( 5 ) whereKleft andKright aredefinedbysubstituting the embedding of the left and right local context into Equation 1 respectively .</sentence>
				<definiendum id="0">Local Context kernel KLC</definiendum>
				<definiens id="0">andKright aredefinedbysubstituting the embedding of the left and right local context into Equation 1 respectively</definiens>
			</definition>
			<definition id="5">
				<sentence>At first glance , it may seem strange that KGC outperforms ERK on AImed , as the latter approach exploits a richer representation : sparse sub-sequences of words , PoS tags , entity and chunk types , or WordNet synsets .</sentence>
				<definiendum id="0">PoS</definiendum>
			</definition>
			<definition id="6">
				<sentence>Zelenko et al. ( 2003 ) describe a relation extraction algorithm that uses a tree kernel defined over a shallow parse tree representation of sentences .</sentence>
				<definiendum id="0">relation extraction algorithm</definiendum>
				<definiens id="0">uses a tree kernel defined over a shallow parse tree representation of sentences</definiens>
			</definition>
</paper>

		<paper id="1038">
			<definition id="0">
				<sentence>Formally , sentence compression aims to shorten a sentence x = x1 ... xn into a substring y = y1 ... ym , where yi ∈ { x1 , ... , xn } .</sentence>
				<definiendum id="0">sentence compression</definiendum>
				<definiens id="0">aims to shorten a sentence x = x1 ... xn into a substring y = y1 ... ym , where yi ∈ { x1 , ... , xn }</definiens>
			</definition>
			<definition id="1">
				<sentence>The noisy-channel model defines the problem as finding the compressed sentence with maximum conditional probability y = argmax y P ( y|x ) = argmax y P ( x|y ) P ( y ) P ( y ) is the source model , which is a PCFG plus bigram language model .</sentence>
				<definiendum id="0">noisy-channel model</definiendum>
				<definiens id="0">the problem as finding the compressed sentence with maximum conditional probability y = argmax y P ( y|x ) = argmax y P ( x|y ) P ( y ) P ( y ) is the source model , which is a PCFG plus bigram language model</definiens>
			</definition>
			<definition id="2">
				<sentence>P ( x|y ) is the channel model , the probability that the long sentence is an expansion of the compressed sentence .</sentence>
				<definiendum id="0">P ( x|y )</definiendum>
				<definiens id="0">the channel model , the probability that the long sentence is an expansion of the compressed sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Let the score of a compression y for a sentence x as s ( x , y ) In particular , we are going to factor this score using a first-order Markov assumption on the words in the compressed sentence s ( x , y ) = |y|summationdisplay j=2 s ( x , I ( yj−1 ) , I ( yj ) ) Finally , we define the score function to be the dot product between a high dimensional feature representation and a corresponding weight vector s ( x , y ) = |y|summationdisplay j=2 w·f ( x , I ( yj−1 ) , I ( yj ) ) Note that this factorization will allow us to define features over two adjacent words in the compression as well as the words in-between that were dropped from the original sentence to create the compression .</sentence>
				<definiendum id="0">Let the score of a compression y</definiendum>
				<definiendum id="1">I</definiendum>
				<definiens id="0">features over two adjacent words in the compression as well as the words in-between that were dropped from the original sentence to create the compression</definiens>
			</definition>
			<definition id="4">
				<sentence>Oneach iteration , MIRA considers a single instance from the training set ( xt , yt ) and updates the weights so that the score of the correct compression , yt , is greater than the score of all other compressions by a margin proportional to their loss .</sentence>
				<definiendum id="0">MIRA</definiendum>
			</definition>
</paper>

		<paper id="1052">
			<definition id="0">
				<sentence>The TEASE algorithm consists of 3 steps , demonstrated in Table 6 .</sentence>
				<definiendum id="0">TEASE algorithm</definiendum>
			</definition>
			<definition id="1">
				<sentence>Next , TEASE retrieves from the Web a corpus S of sentences that contain the characteristic anchor-sets ( second column ) , hoping to find occurrences of these anchor-sets within templates other than the original input template .</sentence>
				<definiendum id="0">TEASE</definiendum>
				<definiens id="0">retrieves from the Web a corpus S of sentences that contain the characteristic anchor-sets ( second column</definiens>
			</definition>
			<definition id="2">
				<sentence>A template is considered directly matched in a sentence if it appears as a sub-graph in the sentence dependency graph , with its variables instantiated .</sentence>
				<definiendum id="0">template</definiendum>
			</definition>
</paper>

		<paper id="1034">
			<definition id="0">
				<sentence>Variation is caused by one of two reasons : i ) ambiguity : there is a type of string with multiple possible labels and different corpus occurrences of that string realize the different options , or ii ) error : the tagging of a string is inconsistent across comparable occurrences .</sentence>
				<definiendum id="0">Variation</definiendum>
				<definiens id="0">caused by one of two reasons : i ) ambiguity : there is a type of string with multiple possible labels and different corpus occurrences of that string realize the different options , or ii ) error : the tagging of a string is inconsistent across comparable occurrences</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , words which vary between IN and RB and tagged as IN ( e.g. , ago , tagged &lt; IN/RB , IN &gt; ) can ignore the contextual information that words varying between DT ( determiner ) and IN ( e.g. , that , tagged &lt; DT/IN , IN &gt; ) provide .</sentence>
				<definiendum id="0">RB</definiendum>
				<definiens id="0">ignore the contextual information that words varying between DT ( determiner</definiens>
			</definition>
</paper>

		<paper id="2007">
			<definition id="0">
				<sentence>In this work we have used Kmeans clustering , which is a partitional method , and the H2 criterion function , which is the ratio of within cluster similarity to between cluster similarity .</sentence>
				<definiendum id="0">Kmeans clustering</definiendum>
				<definiendum id="1">H2 criterion function</definiendum>
				<definiens id="0">the ratio of within cluster similarity to between cluster similarity</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , PK2 will select k where PK2 ( k ) is the closest to ( but not less than ) 1 + standarddeviation ( PK2 [ 1 ... deltaK ] ) .</sentence>
				<definiendum id="0">PK2 ( k )</definiendum>
				<definiens id="0">the closest to ( but not less than ) 1 + standarddeviation ( PK2 [ 1 ... deltaK ] )</definiens>
			</definition>
</paper>

		<paper id="2001">
</paper>

		<paper id="1033">
			<definition id="0">
				<sentence>Althoughourultimategoal 6In reality , TBL improves the accuracy of tags and phrase boundary flags .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">improves the accuracy of tags and phrase boundary flags</definiens>
			</definition>
			<definition id="1">
				<sentence>In the tables , RB is rule-based method , TBL ( tag ) is the TBL run on tags , TBL ( font ) is the TBL run on font style , and GT ( font ) is the ground truth font style .</sentence>
				<definiendum id="0">RB</definiendum>
				<definiendum id="1">TBL ( tag )</definiendum>
				<definiendum id="2">TBL ( font )</definiendum>
				<definiendum id="3">GT ( font )</definiendum>
				<definiens id="0">rule-based method</definiens>
			</definition>
			<definition id="2">
				<sentence>261 Cebuano Iraqi Arabic Token Phrase Token Phrase RB 81.46±1.14 62.38±1.09 92.10±0.69 85.05±1.64 RB + TBL ( tag ) 89.34±0.96 85.17±1.55 94.94±0.56 93.25±0.87 TBL ( font ) + RB 87.40±1.69 71.97±1.26 93.20±1.02 85.49±1.13 TBL ( font ) + RB + TBL ( tag ) 93.13±1.58 90.48±0.80 94.88±0.56 93.03±0.70 GT ( font ) + RB 89.25±1.57 73.13±1.02 93.02±0.58 85.03±2.28 GT ( font ) + RB + TBL ( tag ) 95.31±1.43 91.89±1.80 95.32±0.65 93.36±0.81 Table 3 : Average tagging accuracy results with standard deviation for ten runs using different eight pages for training , and six pages for testing 0 50 100 150 200 250 300 0 20 40 60 80 100 120 140 Number of Errors Number of Entries in Training Data for Cebuano Dictionary # of Errors in Font Style # of Errors in Tagging with TBL ( tag ) # of Errors in Tagging with TBL ( font ) -TBL ( tag ) 0 20 40 60 80 100 120 140 160 0 20 40 60 80 100 120 Number of Errors in Test Data Number of Entries in Training Data for Iraqi Arabic Dictionary # of Errors in Font Style # of Errors in Tagging with TBL ( tag ) # of Errors in Tagging with TBL ( font ) -TBL ( tag ) Figure 3 : The number of errors in two test pages as a function of the number of entries in the training data for two dictionaries number of errors declines dramatically with the addition of the first entries .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiendum id="1">TBL</definiendum>
				<definiens id="0">The number of errors in two test pages as a function of the number of entries in the training data for two dictionaries number of errors declines dramatically with the addition of the first entries</definiens>
			</definition>
</paper>

		<paper id="2031">
</paper>

		<paper id="2012">
			<definition id="0">
				<sentence>Under the hood , Maytag consists of both an on-line component and an off-line one .</sentence>
				<definiendum id="0">Maytag</definiendum>
				<definiens id="0">consists of both an on-line component and an off-line one</definiens>
			</definition>
			<definition id="1">
				<sentence>The online part is a web-based GUI that is connected to a relational database via CGI scripts ( html , JavaScript , and Python ) .</sentence>
				<definiendum id="0">online part</definiendum>
			</definition>
			<definition id="2">
				<sentence>The maximum entropy role classifier relies on a range of feature types : the semantic type of the phrase ( for named entities ) , the phrase vocabulary , the distance to the target head , and local context ( words and phrases ) .</sentence>
				<definiendum id="0">maximum entropy role classifier</definiendum>
				<definiens id="0">the semantic type of the phrase ( for named entities ) , the phrase vocabulary , the distance to the target head , and local context ( words and phrases )</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>Moreover , some Named Entity classes , including names of writers , athletes and organizations , dynamically change over the time , which makes it impossible to capture them in a static Ontology .</sentence>
				<definiendum id="0">Named Entity classes</definiendum>
			</definition>
			<definition id="1">
				<sentence>( Cimiano and V¨olker , 2005 ) describes an unsupervised approach for ontology population based on vector-feature similarity between each concept c and a term to be classified t. For example , in order to conclude how much “Etna” is an appropriate instance of the class “mountain” , this method finds the feature-vector similarity between the word “Etna” and the word “mountain” .</sentence>
				<definiendum id="0">“Etna”</definiendum>
				<definiens id="0">describes an unsupervised approach for ontology population based on vector-feature similarity between each concept c and a term to be classified t. For example</definiens>
			</definition>
			<definition id="2">
				<sentence>If “Edison” is a name to be classified , then two first order features of this name exist ( “invent” , subject-of ) and ( “create” , subject-of ) .</sentence>
				<definiendum id="0">“Edison”</definiendum>
				<definiens id="0">a name to be classified</definiens>
			</definition>
			<definition id="3">
				<sentence>P ( t ) ) where P ( fc , t ) is the probability that feature fc co-occurs with t , P ( fc ) and P ( t ) are the probabilities that fc and t appear in the corpus , α = 14 for syntactic features with lexical element noun and α = 1 for all the other syntactic features .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">the probability that feature fc co-occurs with t , P ( fc ) and P ( t ) are the probabilities that fc and t appear in the corpus , α = 14 for syntactic features with lexical element noun</definiens>
			</definition>
			<definition id="4">
				<sentence>vertices represent words and the edges between them represent syntactic relations like subject , object , modifier , etc .</sentence>
				<definiendum id="0">vertices</definiendum>
			</definition>
			<definition id="5">
				<sentence>When SyntNet represents a syntactically parsed text corpus , its vertices are labeled with words from the text while edges represent syntactic relations from the corpus and are labeled accordingly .</sentence>
				<definiendum id="0">SyntNet</definiendum>
				<definiens id="0">a syntactically parsed text corpus , its vertices are labeled with words from the text while edges represent syntactic relations from the corpus and are labeled accordingly</definiens>
			</definition>
</paper>

		<paper id="3008">
			<definition id="0">
				<sentence>Thisindicates thatthere is a certain group similarity for the nouns of similar frequency that is captured in the combination of the seven features .</sentence>
				<definiendum id="0">Thisindicates thatthere</definiendum>
				<definiens id="0">a certain group similarity for the nouns of similar frequency that is captured in the combination of the seven features</definiens>
			</definition>
</paper>

		<paper id="2016">
			<definition id="0">
				<sentence>GOD ( General Ontology Discovery ) is an unsupervised system to extract semantic relations among domain specific entities and concepts from texts .</sentence>
				<definiendum id="0">GOD</definiendum>
				<definiens id="0">an unsupervised system to extract semantic relations among domain specific entities and concepts from texts</definiens>
			</definition>
			<definition id="1">
				<sentence>GOD ( General Ontology Discovery ) is an unsupervised system to extract semantic relations among domain specific entities and concepts from texts .</sentence>
				<definiendum id="0">GOD</definiendum>
				<definiens id="0">an unsupervised system to extract semantic relations among domain specific entities and concepts from texts</definiens>
			</definition>
			<definition id="2">
				<sentence>god : lord hear prayer god is creator god have mercy faith reverences god lord have mercy jesus_christ is god god banishing him god commanded israelites god was trinity abraham believed god god requires abraham god supply human_need god is holy noah obeyed god From a different perspective , GOD is first of all a general system for ontology learning from texts ( Buitelaar et al. , 2005 ) .</sentence>
				<definiendum id="0">GOD</definiendum>
				<definiens id="0">first of all a general system for ontology learning from texts</definiens>
			</definition>
			<definition id="3">
				<sentence>When a query Q = ( q1 , q2 , ... , qn ) is formulated , GOD operates as follows : Domain Discovery Retrieve the ranked list dom ( Q ) = ( t1 , t2 , ... , tk ) of domain specific terms such that sim ( ti , Q ) &gt; θprime , where sim ( Q , t ) is a similarity function capturing domain proximity and θprime is the domain specificity threshold .</sentence>
				<definiendum id="0">GOD</definiendum>
				<definiens id="0">operates as follows : Domain Discovery Retrieve the ranked list dom ( Q ) = ( t1 , t2 , ... , tk</definiens>
			</definition>
			<definition id="4">
				<sentence>Relation Extraction For each SVO pattern involving two different terms ti ∈ dom ( Q ) and tj ∈ dom ( Q ) such that the term ti occurs in the subject position and the term tj occurs in the object position return the relation tivtj if score ( ti , v , tj ) &gt; θprimeprime , where score ( ti , v , tj ) measures the syntagmatic association among ti , v and tj .</sentence>
				<definiendum id="0">Relation Extraction</definiendum>
				<definiens id="0">For each SVO pattern involving two different terms ti ∈ dom ( Q ) and tj ∈ dom ( Q ) such that the term ti occurs in the subject position and the term tj occurs in the object position return the relation tivtj if score ( ti , v , tj ) &gt; θprimeprime , where score ( ti , v , tj ) measures the syntagmatic association among ti , v and tj</definiens>
			</definition>
			<definition id="5">
				<sentence>Semantic Domains ( Magnini et al. , 2002 ) are clusters of very closely related concepts , lexicalized by domain specific terms .</sentence>
				<definiendum id="0">Semantic Domains</definiendum>
				<definiens id="0">Magnini et al. , 2002 ) are clusters of very closely related concepts , lexicalized by domain specific terms</definiens>
			</definition>
			<definition id="6">
				<sentence>A DM is represented by a k × kprime rectangular matrix D , containing the domain relevance for each term with respect to each domain , where k is the cardinality of the vocabulary , and kprime is the size of the Domain Set .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiendum id="1">k</definiendum>
				<definiendum id="2">kprime</definiendum>
				<definiens id="0">the cardinality of the vocabulary</definiens>
			</definition>
			<definition id="7">
				<sentence>Once a DM has been defined by the matrix D , the Domain Space is a kprime dimensional space , in which both texts and terms are associated to Domain Vectors ( DVs ) , i.e. vectors representing their domain relevances with respect to each domain .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiendum id="1">Domain Space</definiendum>
				<definiens id="0">a kprime dimensional space , in which both texts and terms are associated to Domain Vectors ( DVs ) , i.e. vectors representing their domain relevances with respect to each domain</definiens>
			</definition>
			<definition id="8">
				<sentence>The DV vectortprimei for the term ti ∈ V is the ith row ofD , where V = { t1 , t2 , ... , tk } is the vocabulary of the corpus .</sentence>
				<definiendum id="0">DV vectortprimei</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">the ith row ofD , where V = { t1 , t2 , ... , tk } is the vocabulary of the corpus</definiens>
			</definition>
			<definition id="9">
				<sentence>When a query Q = ( q1 , q2 , ... , qn ) is formulated , its DV vectorQprime is estimated by vectorQprime = nsummationdisplay j=1 vectorqprimej ( 1 ) and then compared to the DVs of each term ti ∈ V by adopting the cosine similarity metric sim ( ti , Q ) = cos ( vectortprimei , vectorQprime ) ( 2 ) where vectortprimei and vectorqprimej are the DVs for the terms ti and qj , respectively .</sentence>
				<definiendum id="0">q2 , ... , qn )</definiendum>
				<definiens id="0">estimated by vectorQprime = nsummationdisplay j=1 vectorqprimej ( 1 ) and then compared to the DVs of each term ti ∈ V by adopting the cosine similarity metric sim ( ti , Q ) = cos ( vectortprimei</definiens>
			</definition>
			<definition id="10">
				<sentence>In particular , GOD extracts the relations tivtj for each ordered couple of domain specific terms ( ti , tj ) such that ti ∈ dom ( Q ) , tj ∈ dom ( Q ) and score ( ti , v , tj ) &gt; θprimeprime .</sentence>
				<definiendum id="0">GOD</definiendum>
				<definiens id="0">extracts the relations tivtj for each ordered couple of domain specific terms ( ti , tj ) such that ti ∈ dom ( Q ) , tj ∈ dom ( Q ) and score ( ti , v , tj ) &gt; θprimeprime</definiens>
			</definition>
			<definition id="11">
				<sentence>The confidence score is estimated by adopting the heuristic confidence measure described in ( Reinberger et al. , 2004 ) , reported below : score ( ti , v , tj ) = F ( ti , v , tj ) min ( F ( ti ) , F ( tj ) ) F ( ti , v ) F ( ti ) + F ( v , tj ) F ( tj ) ( 3 ) where F ( t ) is the frequency of the term t in the corpus , F ( t , v ) is the frequency of the SV pattern involving both t and v , F ( v , t ) is the frequency of the VO pattern involving both v and t , and F ( ti , v , tj ) is the frequency of the SVO pattern involving ti , v and tj .</sentence>
				<definiendum id="0">confidence score</definiendum>
				<definiendum id="1">F ( t )</definiendum>
				<definiendum id="2">F ( ti</definiendum>
				<definiens id="0">the frequency of the term t in the corpus</definiens>
				<definiens id="1">the frequency of the SV pattern involving both t and v</definiens>
				<definiens id="2">the frequency of the VO pattern involving both v</definiens>
				<definiens id="3">the frequency of the SVO pattern involving ti , v and tj</definiens>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>Our fast algorithm computes the kernels between two syntactic parse trees in O ( m + n ) average time , where m and n are the number of nodes in the two trees .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="1">
				<sentence>We define K ( T1 , T2 ) = summationdisplay n1∈NT1 summationdisplay n2∈NT2 ∆ ( n1 , n2 ) ( 1 ) where NT1 and NT2 are the sets of the T1’s and T2’s nodes , respectively and ∆ ( n1 , n2 ) =summationtext |F| i=1 Ii ( n1 ) Ii ( n2 ) .</sentence>
				<definiendum id="0">NT2</definiendum>
			</definition>
			<definition id="2">
				<sentence>Moreover , by combining polynomial and SST kernels , we can improve the classification accuracy ( Moschitti , 2004 ) , i.e. tree kernels provide the learning algorithm with many relevant fragments which hardly can be designed by hand .</sentence>
				<definiendum id="0">SST</definiendum>
				<definiens id="0">the learning algorithm with many relevant fragments which hardly can be designed by hand</definiens>
			</definition>
			<definition id="3">
				<sentence>We have shown that a fast algorithm ( FTK ) can evaluate tree kernels in a linear average running time and also that the overall converging time required by SVMs is compatible with very large data sets .</sentence>
				<definiendum id="0">FTK</definiendum>
			</definition>
</paper>

		<paper id="2008">
			<definition id="0">
				<sentence>( 3 ) My sister lives in Utrecht and [ my sister ] f works in Amsterdam ( 4 ) Amsterdam is the city [ S where Jan lives and wheref Piet works ] ( 5 ) Why did you leave but didn’t yous warn me ?</sentence>
				<definiendum id="0">Amsterdam</definiendum>
				<definiens id="0">the city [ S where Jan lives and wheref</definiens>
			</definition>
			<definition id="1">
				<sentence>Then , ELLEIPO checks all coordination domains for elision options , as follows : • Testing for forward ellipsis : Gapping ( including LDG ) , FCR , or SGF .</sentence>
				<definiendum id="0">ELLEIPO</definiendum>
				<definiendum id="1">Gapping</definiendum>
				<definiens id="0">checks all coordination domains for elision options</definiens>
			</definition>
			<definition id="2">
				<sentence>//global variables communicating the end of leftor right-peripheral identical strings// 6 call FCR ( LCONJ , RCONJ ) ; 7 call SGF ( LCONJ , RCONJ ) ; 8 call BCR ( LCONJ , RCONJ ) ; } ; 9 call ReadOut ( ) ; } 1 proc GAP ( LC , RC , ELLIM ) { //ELLIM records the ‘elliptical mechanism ( s ) ’ applied : “g” for Gapping ; “gl” , “gll” , etc. , for LDG levels// 2 check whether the HEAD verb of LC and the HEAD verb of RC have the same reference tag ; 3 if not then return ; //verbs differ= &gt; no gapping// 4 check whether all other constituents in LC have a counterpart in RC with same grammatical function , not necessarily at the same left-to-right position ; modifiers need identical mod-type ; 5 if not then return ; // no proper set of contrastive pairs of immediate constituents found// 6 for all pairs ( LSIB , RSIB ) resulting from ( 4 ) { 7 if ( LSIB is an S-node ) &amp; ( LSIB is not a superclause root ) then { //LSIB = ”left sibling”// 8 if ( LSIB and RSIB are not coreferential ) 9 then attach “l” to ELLIM ; //LDG variant// 10 call GAP ( LSIB , RSIB , ELLIM ) ; } 11 if NOT ( ( LSIB is an S-node ) &amp; ( LSIB and RSIB are coreferential ) ) 12 then mark RSIB for elision , with ELLIM ; } } 1 proc FCR ( LC , RC ) { 2 while ( FCRcontrol ) { 3 set LSIB and RSIB to left-most daughter of LC and RC , resp. ; 4 if ( LSIB and RSIB are not coreferential ) 5 then { FCRcontrol = FALSE ; 6 return ; } 7 if ( LSIB is an S-node ) 8 then call FCR ( LSIB , RSIB ) ; 9 call FCR ( right neighbor of LSIB , right neighbor of RSIB ) ; 10 mark RSIB for elision by adding “f” ; } } 1 proc SGF ( LC , RC ) { 2 if ( NOT ( SUBJ is 1st daughter of LC ) ) &amp; ( HEAD is 2nd daughter of LC ) &amp; ( SUBJ is 1st or 2nd daughter of RC ) &amp; ( HEAD is 1st or 2nd daughter of RC ) 3 then mark RC’s SUBJ for elision , with “s” ; } 1 proc BCR ( LC , RC ) { 2 while ( BCRcontrol ) { 3 set LSIB and RSIB to right-most daughter node of LC and RC , respectively ; 4 if ( LSIB and RSIB are not coreferential ) 5 then { BCRcontrol = FALSE ; return ; } ; 6 call BCR ( LSIB , RSIB ) ; 7 call BCR ( left neighbor of LSIB , left neighbor of RSIB ) ; 8 if ( RSIB is a terminal node ) 9 then mark LSIB for elision , with “b” ; } } 118</sentence>
				<definiendum id="0">LSIB</definiendum>
				<definiendum id="1">LSIB</definiendum>
				<definiendum id="2">LSIB</definiendum>
				<definiendum id="3">SUBJ</definiendum>
				<definiendum id="4">RSIB</definiendum>
				<definiens id="0">left-to-right position ; modifiers need identical mod-type ; 5 if not then return ; // no proper set of contrastive pairs of immediate constituents found// 6 for all pairs ( LSIB , RSIB ) resulting from</definiens>
				<definiens id="1">an S-node ) &amp; ( LSIB is not a superclause root</definiens>
				<definiens id="2">an S-node ) &amp; ( LSIB and RSIB are coreferential ) ) 12 then mark RSIB for elision , with ELLIM</definiens>
				<definiens id="3">1st daughter of LC ) ) &amp; ( HEAD is 2nd daughter of LC ) &amp; ( SUBJ is 1st or 2nd daughter of RC ) &amp; ( HEAD is 1st or 2nd daughter of RC ) 3 then mark RC’s SUBJ for elision</definiens>
				<definiens id="4">a terminal node ) 9 then mark LSIB for elision</definiens>
			</definition>
</paper>

		<paper id="2022">
			<definition id="0">
				<sentence>Terms are identified using the following pattern describing their morphological structure : E+W where E is a prefix or combining form and W is a wordwhoselengthishigherthan3 ; the‘+’character represents the possible succession of several E elements at the beginning of a term .</sentence>
				<definiendum id="0">E</definiendum>
				<definiendum id="1">W</definiendum>
				<definiens id="0">a prefix or combining form</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 1 : Term cloud example ( Corpus : BC en ) Further information ( terms and frequencies ) is displayed thanks to tooltips ( see Figure 2 ) , using the JavaScript overLIB libray ( http : //www .</sentence>
				<definiendum id="0">JavaScript overLIB libray</definiendum>
				<definiens id="0">Term cloud example ( Corpus : BC en ) Further information ( terms and frequencies</definiens>
			</definition>
			<definition id="2">
				<sentence>Term clustering could be ameliorated as well by investigating the usefulness of stemming to avoid underconflation .</sentence>
				<definiendum id="0">Term clustering</definiendum>
				<definiens id="0">well by investigating the usefulness of stemming to avoid underconflation</definiens>
			</definition>
</paper>

		<paper id="1049">
			<definition id="0">
				<sentence>Carsim is a program that automatically converts narratives into 3D scenes .</sentence>
				<definiendum id="0">Carsim</definiendum>
				<definiens id="0">a program that automatically converts narratives into 3D scenes</definiens>
			</definition>
			<definition id="1">
				<sentence>To create a consistent animation , Carsim extracts the participants mentioned in a text and identifies what they do .</sentence>
				<definiendum id="0">Carsim</definiendum>
				<definiens id="0">extracts the participants mentioned in a text and identifies what they do</definiens>
			</definition>
			<definition id="2">
				<sentence>TimeML is a specification language whose goal is to capture most aspects of temporal relations between events in discourses .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">a specification language whose goal is to capture most aspects of temporal relations between events in discourses</definiens>
			</definition>
			<definition id="3">
				<sentence>It defines XML elements to annotate time expressions , events , and “signals” .</sentence>
				<definiendum id="0">XML</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Carsim language processing module reduces the text content to a frame representation – a template – that outlines what happened and enables a conversion to a symbolic scene .</sentence>
				<definiendum id="0">Carsim language processing module</definiendum>
				<definiens id="0">reduces the text content to a frame representation – a template – that outlines what happened and enables a conversion to a symbolic scene</definiens>
			</definition>
			<definition id="5">
				<sentence>The visualization module considers a subset of the detected events that it interprets graphically .</sentence>
				<definiendum id="0">visualization module</definiendum>
				<definiens id="0">considers a subset of the detected events that it interprets graphically</definiens>
			</definition>
			<definition id="6">
				<sentence>For all pairs of events in the template , Carsim queries the temporal graph to determine their relation .</sentence>
				<definiendum id="0">Carsim</definiendum>
			</definition>
</paper>

		<paper id="2009">
			<definition id="0">
				<sentence>The action returned by the RL agent is a combination of conversational domain , speech act , and task .</sentence>
				<definiendum id="0">RL agent</definiendum>
				<definiens id="0">a combination of conversational domain , speech act</definiens>
			</definition>
</paper>

		<paper id="2025">
			<definition id="0">
				<sentence>Stochastic Tree Substitution Grammars ( henceforth , STSGs ) are a simple generalization of Probabilistic Context Free Grammars , where the productive elements are not rewrite rules but elementary trees of arbitrary size .</sentence>
				<definiendum id="0">Stochastic Tree Substitution Grammars</definiendum>
				<definiens id="0">a simple generalization of Probabilistic Context Free Grammars , where the productive elements are not rewrite rules but elementary trees of arbitrary size</definiens>
			</definition>
			<definition id="1">
				<sentence>The probability of a parse p is therefore given by : P ( p ) = summationtextd : ˆd=p P ( d ) , where ˆd is the tree derived byderivation d , P ( d ) = producttextt∈d w ( t ) andw ( t ) gives the weights of elementary trees t , which are combined in the derivation d ( here treated as a multiset ) .</sentence>
				<definiendum id="0">ˆd</definiendum>
				<definiens id="0">gives the weights of elementary trees t , which are combined in the derivation d ( here treated as a multiset )</definiens>
			</definition>
			<definition id="2">
				<sentence>In Bod’s original DOP implementation ( Bod , 1993 ; Bod , 1998 ) , henceforth DOP1 , the weights of an elementary tree t is defined as its relative frequency ( relative to other subtrees with the same root label ) in the tree bank .</sentence>
				<definiendum id="0">relative frequency</definiendum>
				<definiens id="0">relative to other subtrees with the same root label ) in the tree bank</definiens>
			</definition>
			<definition id="3">
				<sentence>Johnson considers the case where the weights of all trees of the target grammar G are 0 , except for w7 , which is necessarily 1 , and w4 and w6 which are w4 = p and w6 = 1 − p. He finds that the expected values of the weights w4 and w6 of the estimated grammar Gprime are : E [ wprime4 ] = p2 + 2p , ( 2 ) E [ wprime6 ] = 1−p2 + 2p , ( 3 ) which are not equal to their target values for all values of p where 0 &lt; p &lt; 1 .</sentence>
				<definiendum id="0">Johnson</definiendum>
				<definiens id="0">considers the case where the weights of all trees of the target grammar G are 0 , except for w7 , which is necessarily 1 , and w4 and w6 which are w4 = p and w6 = 1 − p. He finds that the expected values of the weights w4 and w6 of the estimated grammar Gprime are : E [ wprime4 ] =</definiens>
			</definition>
			<definition id="4">
				<sentence>For instance , Bonnema et al. replace equation ( 1 ) with : wi = 2−N ( ti ) fisummationtext j : r ( tj ) =r ( ti ) ( fj ) , ( 12 ) where N ( ti ) gives the number of internal nodes in ti ( such that 2−N ( ti ) is inversely proportional to the number of possible derivations of ti ) .</sentence>
				<definiendum id="0">N ( ti )</definiendum>
				<definiens id="0">gives the number of internal nodes in ti ( such that 2−N ( ti ) is inversely proportional to the number of possible derivations of ti )</definiens>
			</definition>
			<definition id="5">
				<sentence>The elementary trees of the estimated STSG are assigned weights according to their usage frequencies u1 , ... , uN in these shortest derivations : wi = uisummationtext j : r ( tj ) =r ( ti ) uj .</sentence>
				<definiendum id="0">, uN</definiendum>
				<definiens id="0">The elementary trees of the estimated STSG are assigned weights according to their usage frequencies u1 , ...</definiens>
			</definition>
</paper>

		<paper id="2010">
			<definition id="0">
				<sentence>SmartWeb1 is a multi-modal dialog system , which derives answers from unstructured resources such as the Web , from automatically acquired knowledge bases and from web services .</sentence>
				<definiendum id="0">SmartWeb1</definiendum>
				<definiens id="0">a multi-modal dialog system , which derives answers from unstructured resources such as the Web , from automatically acquired knowledge bases and from web services</definiens>
			</definition>
			<definition id="1">
				<sentence>1 http : //www.smartweb-projekt.de/start_en.html The SOBA system consists of a web crawler , linguistic annotation components and a component for the transformation of linguistic annotations into an ontology-based representation .</sentence>
				<definiendum id="0">SOBA system</definiendum>
				<definiens id="0">consists of a web crawler , linguistic annotation components and a component for the transformation of linguistic annotations into an ontology-based representation</definiens>
			</definition>
			<definition id="2">
				<sentence>Textual data comprise of match reports as well as news articles .</sentence>
				<definiendum id="0">Textual data</definiendum>
				<definiens id="0">comprise of match reports as well as news articles</definiens>
			</definition>
			<definition id="3">
				<sentence>The feature structure for player as displayed above will be translated into the following FLogic ( Kifer et al. 1995 ) statements , which are then automatically translated to RDF and fed to the visualization component : soba # player124 : sportevent # FootballPlayer [ sportevent # impersonatedBy - &gt; soba # Guido_BUCHWALD ] .</sentence>
				<definiendum id="0">FLogic</definiendum>
				<definiens id="0">Kifer et al. 1995 ) statements , which are then automatically translated to RDF and fed to the visualization component</definiens>
			</definition>
</paper>

		<paper id="2015">
			<definition id="0">
				<sentence>SRL provides the semantic relationships that constituents have with predicates , thus allowing us to include document-level event descriptive information into the relations holding between referring expressions ( REs ) .</sentence>
				<definiendum id="0">SRL</definiendum>
				<definiens id="0">provides the semantic relationships that constituents have with predicates , thus allowing us to include document-level event descriptive information into the relations holding between referring expressions ( REs )</definiens>
			</definition>
			<definition id="1">
				<sentence>Both the Newswire ( NWIRE ) andBroadcastNews ( BNEWS ) sections where split into 60-20-20 % document-based partitions for training , development , and testing , and later per-partition merged ( MERGED ) for system evaluation .</sentence>
				<definiendum id="0">Newswire</definiendum>
				<definiendum id="1">MERGED</definiendum>
				<definiens id="0">sections where split into 60-20-20 % document-based partitions for training , development , and testing</definiens>
			</definition>
			<definition id="2">
				<sentence>Elseiftheybothhave a defined one and it is the same T ; else F. 2Possible values are U ( nknown ) , T ( rue ) and F ( alse ) .</sentence>
				<definiendum id="0">T ( rue</definiendum>
				<definiendum id="1">F ( alse</definiendum>
				<definiens id="0">the same T ; else F. 2Possible values are U ( nknown )</definiens>
			</definition>
			<definition id="3">
				<sentence>In our experiments we use the ASSERT parser ( Pradhan et al. , 2004 ) , an SVM based semantic role tagger which uses a full syntactic analysis to automatically identify all verb predicates in a sentence together with their semantic arguments , which are output as PropBank arguments ( Palmer et al. , 2005 ) .</sentence>
				<definiendum id="0">ASSERT parser</definiendum>
				<definiens id="0">an SVM based semantic role tagger which uses a full syntactic analysis to automatically identify all verb predicates in a sentence together with their semantic arguments</definiens>
			</definition>
</paper>

		<paper id="1045">
			<definition id="0">
				<sentence>The relevant segments included all mentions of tile-design properties ( e.g. , colours , designers ) , modifiers such as once again and also , deictic determiners ( this , these ) , and verbs in contrastive contexts ( e.g. , are in Figure 1 ) .</sentence>
				<definiendum id="0">deictic determiners</definiendum>
				<definiens id="0">included all mentions of tile-design properties ( e.g. , colours , designers ) , modifiers such as once again and also</definiens>
			</definition>
			<definition id="1">
				<sentence>We then made videos of every schedule for every sentence , using the Festival speech synthesiser ( Clark et al. , 2004 ) and the RUTH talking head ( DeCarlo et al. , 2004 ) .</sentence>
				<definiendum id="0">Festival speech synthesiser</definiendum>
			</definition>
			<definition id="2">
				<sentence>Taken together , these results imply that male users prefer and perform better using an embodied agent that is less expressive and that shows less variation in its motions , and may even prefer a system that does not have an agent at all .</sentence>
				<definiendum id="0">embodied agent</definiendum>
				<definiens id="0">less expressive and that shows less variation in its motions , and may even prefer a system that does not have an agent at all</definiens>
			</definition>
</paper>

		<paper id="1044">
			<definition id="0">
				<sentence>The PropBank corpus ( c. 120,000 propositions , c. 3,000 verbs ) adds semantic annotation to the Wall Street Journal part of the Penn Treebank .</sentence>
				<definiendum id="0">PropBank corpus</definiendum>
				<definiens id="0">c. 120,000 propositions , c. 3,000 verbs ) adds semantic annotation to the Wall Street Journal part of the Penn Treebank</definiens>
			</definition>
			<definition id="1">
				<sentence>The data consists of ratings for 30 verbs and 6 arguments each , interpreted as objects .</sentence>
				<definiendum id="0">data</definiendum>
				<definiens id="0">consists of ratings for 30 verbs and 6 arguments each , interpreted as objects</definiens>
			</definition>
			<definition id="2">
				<sentence>Apparently , the FrameNet style of annotation allows us to induce informative verb classes , whereas the PropBank classes introduce noise at most .</sentence>
				<definiendum id="0">FrameNet style of annotation</definiendum>
				<definiens id="0">allows us to induce informative verb classes</definiens>
			</definition>
			<definition id="3">
				<sentence>Beginning with work by Gildea and Jurafsky ( 2002 ) , there has been a large interest in semantic role labelling , as evidenced by its adoption as a shared task in the Senseval-III competition ( FrameNet data , Litkowski , 2004 ) and at the CoNLL-2004 and 2005 conference ( PropBank data , Carreras and Márquez , 2005 ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
			</definition>
			<definition id="4">
				<sentence>A Bayesian model predicts human parse preference and reading time in sentence processing .</sentence>
				<definiendum id="0">Bayesian model</definiendum>
				<definiens id="0">predicts human parse preference and reading time in sentence processing</definiens>
			</definition>
</paper>

		<paper id="1024">
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>The Combined Word Aligner , COWAL-described in section 5 , is a wrapper of the two aligners ( YAWA and MEBA ) merging the individual alignments and filtering the result .</sentence>
				<definiendum id="0">Combined Word Aligner</definiendum>
				<definiens id="0">a wrapper of the two aligners ( YAWA and MEBA ) merging the individual alignments and filtering the result</definiens>
			</definition>
			<definition id="1">
				<sentence>YAWA is a three stage lexical aligner that uses bilingual translation lexicons and phrase boundaries detection to align words of a given bitext .</sentence>
				<definiendum id="0">YAWA</definiendum>
				<definiens id="0">a three stage lexical aligner that uses bilingual translation lexicons and phrase boundaries detection to align words of a given bitext</definiens>
			</definition>
			<definition id="2">
				<sentence>Several heuristics ( string similarity-cognates , POS affinities and alignments locality2 ) are used in a competitive linking manner ( Melamed , 2001 ) to extract the most likely translation equivalents .</sentence>
				<definiendum id="0">Several heuristics</definiendum>
				<definiendum id="1">POS</definiendum>
				<definiens id="0">affinities and alignments locality2 ) are used in a competitive linking manner ( Melamed , 2001 ) to extract the most likely translation equivalents</definiens>
			</definition>
			<definition id="3">
				<sentence>YAWA generates a bitext alignment by incrementally adding new links to those created at the end of the previous stage .</sentence>
				<definiendum id="0">YAWA</definiendum>
			</definition>
			<definition id="4">
				<sentence>However , Romanian is a pro-drop language and although the translation of the English pronoun is not lexicalized in Romanian , one could argue that the auxiliary “ve i” should be aligned also to the pronoun “you” as it incorporates the grammatical information carried by the pronoun .</sentence>
				<definiendum id="0">Romanian</definiendum>
				<definiens id="0">a pro-drop language</definiens>
			</definition>
			<definition id="5">
				<sentence>Similar to YAWA aligner , MEBA generates the links step by step , beginning with the most probable ( anchor links ) .</sentence>
				<definiendum id="0">MEBA</definiendum>
			</definition>
			<definition id="6">
				<sentence>One of the Zipffian laws prescribes a skewed distribution of the senses of a word occurring several times in a coherent text .</sentence>
				<definiendum id="0">Zipffian laws</definiendum>
				<definiens id="0">prescribes a skewed distribution of the senses of a word occurring several times in a coherent text</definiens>
			</definition>
			<definition id="7">
				<sentence>The translation equivalence entropy score is a favouring parameter for the words that have few high probability translations .</sentence>
				<definiendum id="0">translation equivalence entropy score</definiendum>
				<definiens id="0">a favouring parameter for the words that have few high probability translations</definiens>
			</definition>
			<definition id="8">
				<sentence>Locality is a feature that estimates the degree to which the links are sticking together .</sentence>
				<definiendum id="0">Locality</definiendum>
				<definiens id="0">a feature that estimates the degree to which the links are sticking together</definiens>
			</definition>
			<definition id="9">
				<sentence>The likelihood of a link is proportional to the POS affinities of the tokens of the link and inverse proportional to the bounded relative positions ( BRP ) of the respective tokens : where avg is the average displacement in a Gold Standard of the aligned tokens with the same POSes as the tokens of the current link .</sentence>
				<definiendum id="0">avg</definiendum>
				<definiens id="0">the average displacement in a Gold Standard of the aligned tokens with the same POSes as the tokens of the current link</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>French ATR We use the C-value method ( Frantzi and Ananiadou ( 2003 ) ) , which extracts compound terms and ranks them according to their termhood .</sentence>
				<definiendum id="0">C-value method</definiendum>
			</definition>
			<definition id="1">
				<sentence>The linguistic part consists in applying a linguistic filter to constrain the structure of terms extracted .</sentence>
				<definiendum id="0">linguistic part</definiendum>
				<definiens id="0">consists in applying a linguistic filter to constrain the structure of terms extracted</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , consider the N-Prep-Nrelated term sets ( F , J ) the Web ATR Filtering Corpus collection corpora ( C f , C j ) term sets ( X f , X j ) seed terms ( s f , s j ) Figure 1 : Related term collection Prep-N structure in système à base de connaissances ( knowledge based system ) .</sentence>
				<definiendum id="0">Web ATR Filtering Corpus collection corpora</definiendum>
				<definiens id="0">Related term collection Prep-N structure in système à base de connaissances ( knowledge based system )</definiens>
			</definition>
			<definition id="3">
				<sentence>F’ is the subset of F for which Jac≥0.01 : { } 01.0 ) ( ' ≥∈= fJacFfF F’* is the subset of valid related terms in F’ , as determined by human evaluation .</sentence>
				<definiendum id="0">F’</definiendum>
				<definiens id="0">the subset of valid related terms in F’ , as determined by human evaluation</definiens>
			</definition>
			<definition id="4">
				<sentence>P is the set of all potential translation pairs among the collected terms ( P=F×J ) .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">the set of all potential translation pairs among the collected terms ( P=F×J )</definiens>
			</definition>
			<definition id="5">
				<sentence>P’ is the set of pairs containing either a French term or a Japanese term with Jac≥0.01 : ( ) { } 01.0 ) ( 01.0 ) ( , ' ≥∨≥∈∈= jJacfJacJjFfP P’* is the subset of valid translation pairs in P’ , determined by human evaluation .</sentence>
				<definiendum id="0">P’</definiendum>
				<definiendum id="1">jJacfJacJjFfP P’*</definiendum>
				<definiens id="0">the set of pairs containing either a French term or a Japanese term with Jac≥0.01</definiens>
				<definiens id="1">the subset of valid translation pairs in P’ , determined by human evaluation</definiens>
			</definition>
			<definition id="6">
				<sentence>M is the set of all translations selected by our system .</sentence>
				<definiendum id="0">M</definiendum>
			</definition>
			<definition id="7">
				<sentence>M’ is the subset of pairs in M with Jac≥0.01 for either the French or the Japanese term .</sentence>
				<definiendum id="0">M’</definiendum>
			</definition>
			<definition id="8">
				<sentence>FJ + consists of the alignments given by a generation process using Dic FJ and a selection performed on the augmented set of related terms .</sentence>
				<definiendum id="0">FJ +</definiendum>
				<definiens id="0">consists of the alignments given by a generation process using Dic FJ and a selection performed on the augmented set of related terms</definiens>
			</definition>
</paper>

		<paper id="3006">
			<definition id="0">
				<sentence>Compared to these approaches , the novelty of our study lies in the idea that an information request consists of two different parts that should be retrieved in different ways and the whole retrieval process should adopt a two-stage architecture .</sentence>
				<definiendum id="0">information request</definiendum>
				<definiens id="0">consists of two different parts that should be retrieved in different ways and the whole retrieval process should adopt a two-stage architecture</definiens>
			</definition>
			<definition id="1">
				<sentence>We calculated the Pearson’s product-moment correlation coefficient ( r ) ( Weisstein , 1999 ) between any two tags based on their occurrences in sentences of the whole training set .</sentence>
				<definiendum id="0">Pearson’s product-moment correlation coefficient</definiendum>
				<definiens id="0">any two tags based on their occurrences in sentences of the whole training set</definiens>
			</definition>
			<definition id="2">
				<sentence>Although shown to be not so effective in some previous studies ( Yang , 1999 ; Yang and Liu , 1999 ) , Naive Bayes classifier is one of the most commonly-used classifiers for text categorization .</sentence>
				<definiendum id="0">Naive Bayes classifier</definiendum>
				<definiens id="0">one of the most commonly-used classifiers for text categorization</definiens>
			</definition>
			<definition id="3">
				<sentence>The Naive Bayes classifier scores a document jd according to whether it is a typical member of its set — i.e. , the probability of randomly picking up a document like it from the procedural class ( ( ) proceduralCdp j =| ) .</sentence>
				<definiendum id="0">Naive Bayes classifier</definiendum>
				<definiens id="0">the probability of randomly picking up a document like it from the procedural class ( ( ) proceduralCdp j =| )</definiens>
			</definition>
			<definition id="4">
				<sentence>The BM25 algorithm is one variety of the probabilistic schema presented in ( Robertson et al. 1993 ) .</sentence>
				<definiendum id="0">BM25 algorithm</definiendum>
			</definition>
			<definition id="5">
				<sentence>The mean average precision is the mean of the average precisions of a collection of questions .</sentence>
				<definiendum id="0">mean average precision</definiendum>
			</definition>
</paper>

		<paper id="1017">
</paper>

		<paper id="2026">
			<definition id="0">
				<sentence>Among the approaches to overcome this restriction , i.e. that allow for global , theory based constraints , Integer Linear Programming ( ILP ) has been applied to NLP ( Punyakanok et al. , 2004 ) .</sentence>
				<definiendum id="0">Integer Linear Programming</definiendum>
				<definiens id="0">allow for global , theory based constraints</definiens>
			</definition>
			<definition id="1">
				<sentence>Its output is utilized as weights to the ILP component which generates equations to solve the following problem : Given subcategorization frames ( expressed in functional roles , e.g. subject ) , and given a sentence with verbs , a0 ( auxiliary , modal , finite , non-finite , .</sentence>
				<definiendum id="0">ILP component</definiendum>
				<definiens id="0">expressed in functional roles , e.g. subject ) , and given a sentence with verbs</definiens>
			</definition>
			<definition id="2">
				<sentence>Integer Linear Programming ( ILP ) is the name of a class of constraint satisfaction algorithms which are restricted to a numerical representation of the problem to be solved .</sentence>
				<definiendum id="0">ILP )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Thus , a16 is a complex variable name , e.g. a48 a15a46a45 a50 .</sentence>
				<definiendum id="0">a16</definiendum>
				<definiens id="0">a complex variable name</definiens>
			</definition>
			<definition id="4">
				<sentence>We restrict our formalization to the following set of grammatical functions : subject ( a55 ) , direct ( i.e. accusative ) object ( a75 ) , indirect ( i.e. dative ) object ( a76 ) , clausal complement ( a1 ) , prepositional complement ( a77 ) , attributive ( np or pp ) attachment ( a78 ) and adjunct ( a79 ) .</sentence>
				<definiendum id="0">adjunct</definiendum>
				<definiens id="0">direct ( i.e. accusative ) object ( a75 ) , indirect ( i.e. dative ) object ( a76 ) , clausal complement</definiens>
			</definition>
			<definition id="5">
				<sentence>a78 is the weighted sum of all attributive a88a89a88 ( “the book in her hand .</sentence>
				<definiendum id="0">a78</definiendum>
				<definiens id="0">the weighted sum of all attributive a88a89a88 ( “the book in her hand</definiens>
			</definition>
			<definition id="6">
				<sentence>a85 represents the weighted sum of all unassigned objects.3 a0 is the weighted sum of the case frame instantiations of all verbs in the sentence .</sentence>
				<definiendum id="0">a85</definiendum>
				<definiens id="0">the weighted sum of all unassigned objects.3 a0 is the weighted sum of the case frame instantiations of all verbs in the sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>For each verb , each grammatical role ( a115a116a67a96a65 is the set of such roles ) is instantiated from the stock of all constituents ( a47a56a117 a2a119a118a10a120a96a118a53a121 , which includes all np and pp constituents but also the verbs as potential heads of clausal objects ) .</sentence>
				<definiendum id="0">a115a116a67a96a65</definiendum>
				<definiens id="0">the set of such roles</definiens>
				<definiens id="1">includes all np and pp constituents but also the verbs as potential heads of clausal objects</definiens>
			</definition>
			<definition id="8">
				<sentence>a78 isthefunction for weighted attributive attachments : a78a122a13a31a93 a71a70a104 a19a19a97a70a105a106a97 a93 a98 a15 a93 a71a70a104 a19a26a97a74a105a106a97 a93 a98 a45a12a123 a15a70a124 a125 a45a54a126 a62a100a127a119a71a70a65a128a71a106a69a112a110a112a78a129a47 a15a57a47a96a45 ( 3 ) where a62a17a127a130a71a70a65a106a71a106a69 is the weight of an assignment of constituent a47a131a45 to constituent a47 a15 and a78a58a47 a15a114a47a44a45 is a binary variable indicating the classification decision whether a47a131a45 actually modifies a47 a15 .</sentence>
				<definiendum id="0">a78 isthefunction for weighted attributive attachments</definiendum>
				<definiendum id="1">a62a17a127a130a71a70a65a106a71a106a69</definiendum>
				<definiens id="0">the weight of an assignment of constituent a47a131a45 to constituent a47 a15 and a78a58a47 a15a114a47a44a45 is a binary variable indicating the classification decision whether a47a131a45 actually modifies a47 a15</definiens>
			</definition>
			<definition id="9">
				<sentence>ILP has been applied to various NLP problems , including semantic role labeling ( Punyakanok et al. , 2004 ) , extraction of predicates from parsetrees ( Klenner , 2005 ) and discourse ordering in generation ( Althaus et al. , 2004 ) .</sentence>
				<definiendum id="0">ILP</definiendum>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>Inorderto find out whether a given sense has been correctly identified by the WSI algorithm , its retrieval precision ( rP ) the similarity of the found sense with the original sense using the overlap measure can be computed .</sentence>
				<definiendum id="0">rP</definiendum>
				<definiens id="0">the similarity of the found sense with the original sense using the overlap measure can be computed</definiens>
			</definition>
			<definition id="1">
				<sentence>Precision ( P ) is defined as the number of times the original co-occurrence sets are properly restored divided by the number of different sets found .</sentence>
				<definiendum id="0">Precision ( P</definiendum>
			</definition>
			<definition id="2">
				<sentence>Recall ( R ) is defined as the number of senses found divided by the number of words merged to create the pseudoword .</sentence>
				<definiendum id="0">Recall ( R</definiendum>
				<definiens id="0">the number of senses found divided by the number of words merged to create the pseudoword</definiens>
			</definition>
			<definition id="3">
				<sentence>Therefore therawBNCwithoutbaseformreduction ( because lemmatization introduces additional ambiguity ) or POS-tags was used and nine groups each containing five words were picked semi-randomly ( avoiding extremely ambiguous words , with respect to WordNet , if possible ) : • high frequent nouns ( Nh ) : picture , average , blood , committee , economy • medium frequent nouns ( Nm ) : disintegration , substrate , emigration , thirst , saucepan • low frequent nouns ( Nl ) : paratuberculosis , gravitation , pharmacology , papillomavirus , sceptre • highfrequentverbs ( Vh ) : avoid , accept , walk , agree , write • medium frequent verbs ( Vm ) : rend , confine , uphold , evoke , varnish • low frequent verbs ( Vl ) : immerse , disengage , memorize , typify , depute • high frequent adjectives ( Ah ) : useful , deep , effective , considerable , traditional • medium frequent adjectives ( Am ) : ferocious , normative , phenomenal , vibrant , inactive • low frequent adjectives ( Al ) : astrological , crispy , unrepresented , homoclinic , bitchy These nine groups were used to design fours tests , each focussing on a different variable .</sentence>
				<definiendum id="0">inactive • low frequent adjectives</definiendum>
				<definiens id="0">high frequent nouns ( Nh ) : picture , average , blood , committee , economy • medium frequent nouns ( Nm ) : disintegration , substrate , emigration , thirst , saucepan • low frequent nouns ( Nl ) : paratuberculosis , gravitation , pharmacology , papillomavirus , sceptre • highfrequentverbs ( Vh ) : avoid , accept , walk , agree , write • medium frequent verbs ( Vm ) : rend , confine , uphold , evoke , varnish • low frequent verbs ( Vl ) : immerse , disengage , memorize , typify , depute • high frequent adjectives ( Ah ) : useful , deep , effective , considerable , traditional • medium frequent adjectives</definiens>
			</definition>
</paper>

		<paper id="2006">
</paper>

		<paper id="2020">
</paper>

		<paper id="3002">
			<definition id="0">
				<sentence>Others ( Minsky , 1986 ) posit a general mechanism without considering specifics .</sentence>
				<definiendum id="0">Others</definiendum>
				<definiens id="0">posit a general mechanism without considering specifics</definiens>
			</definition>
			<definition id="1">
				<sentence>Coherence relations , such as Elaboration , Explanation and Contrast , are relations between discourse units that bind segments of text into one global structure .</sentence>
				<definiendum id="0">Coherence relations</definiendum>
				<definiens id="0">discourse units that bind segments of text into one global structure</definiens>
			</definition>
			<definition id="2">
				<sentence>The Discourse Representation Theory ( DRT ) ( Kamp , 1984 ) computes inter-sentential anaphora and attempts to maintain text cohesion through sets of predicates , termed Discourse Representation Structures ( DRSs ) , that represent discourse 32 No one does He can still walk by himself Explanation Who supports Gorbachev ?</sentence>
				<definiendum id="0">Discourse Representation Theory ( DRT )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Pustejovsky’s Generative Lexicon ( GL ) model ( Pustejovksy , 1995 ) outlines an ambitious attempt to formulate a lexical semantics framework that can handle the unboundedness of linguistic expressions by providing a rich semantic structure , a principled ontology of concepts ( called qualia ) , and a set of generative devices in which participants in a phrase or sentence can influence each other’s semantic properties .</sentence>
				<definiendum id="0">Pustejovsky’s Generative Lexicon ( GL ) model</definiendum>
				<definiens id="0">a principled ontology of concepts ( called qualia ) , and a set of generative devices in which participants in a phrase or sentence can influence each other’s semantic properties</definiens>
			</definition>
			<definition id="4">
				<sentence>The Probabilistic Qualia Structure , which outlines the ontological hierarchy of a lexical item , also encodes frequency information .</sentence>
				<definiendum id="0">Probabilistic Qualia Structure</definiendum>
				<definiens id="0">outlines the ontological hierarchy of a lexical item</definiens>
			</definition>
			<definition id="5">
				<sentence>Co-composition constrains the type-shifting of the predicate by its arguments .</sentence>
				<definiendum id="0">Co-composition</definiendum>
			</definition>
			<definition id="6">
				<sentence>The General Theory of Verbal Humour ( GTVH ) , introduced earlier , is a well-known computational model of humour .</sentence>
				<definiendum id="0">General Theory of Verbal Humour</definiendum>
				<definiens id="0">a well-known computational model of humour</definiens>
			</definition>
			<definition id="7">
				<sentence>P1 is the preferred interpretation and P2 is hidden .</sentence>
				<definiendum id="0">P1</definiendum>
				<definiendum id="1">P2</definiendum>
				<definiens id="0">the preferred interpretation and</definiens>
			</definition>
			<definition id="8">
				<sentence>At each point in the process of infer34 encing , SDRT’s Glue Logic carries over all interpretations possible within its constraints as a set .</sentence>
				<definiendum id="0">SDRT’s Glue Logic</definiendum>
				<definiens id="0">carries over all interpretations possible within its constraints as a set</definiens>
			</definition>
</paper>

		<paper id="2019">
			<definition id="0">
				<sentence>For example , the Mouse Genome Database ( MGD ) provides essential integration of experimental knowledge for the mouse system with information annotated from both literature and online sources ( Bult et al. , 2004 ) .</sentence>
				<definiendum id="0">Mouse Genome Database</definiendum>
			</definition>
			<definition id="1">
				<sentence>The document set consists of some full-text data obtained from three journals , i.e. , Journal of Biological Chemistry , Journal of Cell Biology and Proceedings of the National Academy of Science in 2002 and 2003 .</sentence>
				<definiendum id="0">document set</definiendum>
				<definiens id="0">consists of some full-text data obtained from three journals , i.e. , Journal of Biological Chemistry , Journal of Cell Biology and Proceedings of the National Academy of Science in 2002 and 2003</definiens>
			</definition>
</paper>

		<paper id="2021">
			<definition id="0">
				<sentence>Acronyms are a subset of abbreviations and are generally formed with capital letters from the original word or phrase , however many acronyms are realized in different surface forms i.e. use of Arabic-numbers , mixed alpha-numeric forms , low-case acronyms etc .</sentence>
				<definiendum id="0">Acronyms</definiendum>
				<definiens id="0">a subset of abbreviations and are generally formed with capital letters from the original word or phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>The AFP utilizes the Longest Common Subsequence ( LCS ) algorithm ( Hunt and Szymanski , 1977 ) to find all possible alignments of the acronym to the text , followed by simple scoring rules which are based on matches .</sentence>
				<definiendum id="0">AFP</definiendum>
			</definition>
			<definition id="2">
				<sentence>A valid acronym candidate is a string of alphabetic , numeric and special characters such as ’-’ and ’/’ .</sentence>
				<definiendum id="0">valid acronym candidate</definiendum>
			</definition>
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>The brevity penalty is calculated as : BP = braceleftBigg 1 if c &gt; r e1−r/c if c ≤ r where c is the length of the corpus of hypothesis translations , and r is the effective reference corpus length.1 Thus , the Bleu score is calculated as Bleu = BP ∗ exp ( Nsummationdisplay n=1 wn logpn ) A Bleu score can range from 0 to 1 , where higher scores indicate closer matches to the reference translations , and where a score of 1 is assigned to a hypothesis translation which exactly 1The effective reference corpus length is calculated as the sum of the single reference translation from each set which is closest to the hypothesis translation .</sentence>
				<definiendum id="0">brevity penalty</definiendum>
				<definiendum id="1">c</definiendum>
				<definiendum id="2">r</definiendum>
				<definiens id="0">the length of the corpus of hypothesis translations</definiens>
				<definiens id="1">the effective reference corpus length.1 Thus , the Bleu score is calculated as Bleu = BP ∗ exp ( Nsummationdisplay n=1 wn logpn ) A Bleu score can range from 0 to 1 , where higher scores indicate closer matches to the reference translations , and where a score of 1 is assigned to a hypothesis translation which exactly 1The effective reference corpus length is calculated as the sum of the single reference translation from each set which is closest to the hypothesis translation</definiens>
			</definition>
			<definition id="1">
				<sentence>In order to allow some amount of variant order in phrases , Bleu places no explicit constraints on the order that matching n-grams occur in .</sentence>
				<definiendum id="0">Bleu</definiendum>
			</definition>
			<definition id="2">
				<sentence>We used Systran for the rule-based system , and used the French-English portion of the Europarl corpus ( Koehn , 2005 ) to train the SMT systems and to evaluate all three systems .</sentence>
				<definiendum id="0">Systran</definiendum>
				<definiens id="0">the rule-based system , and used the French-English portion of the Europarl corpus ( Koehn , 2005 ) to train the SMT systems and to evaluate all three systems</definiens>
			</definition>
			<definition id="3">
				<sentence>Inappropriate uses for Bleu include comparing systems which employ radically different strategies ( especiallycomparingphrase-basedstatistical machine translation systems against systems that do not employ similar n-gram-based approaches ) , trying to detect improvements for aspects of translation that are not modeled well by Bleu , and monitoring improvements that occur infrequently within a test corpus .</sentence>
				<definiendum id="0">Inappropriate</definiendum>
				<definiens id="0">especiallycomparingphrase-basedstatistical machine translation systems against systems that do not employ similar n-gram-based approaches ) , trying to detect improvements for aspects of translation that are not modeled well by Bleu</definiens>
			</definition>
</paper>

		<paper id="3007">
			<definition id="0">
				<sentence>DOM encodes the phonologically realised ( ‘linearised’ ) list of signs : the daughter signs of a        phrase DOM angbracketleftbig 1 © 2 © 3 © ... © n angbracketrightbig HD-DTR angbracketleftBiggbracketleftBiggphrase DOM 1 UNIONED + bracketrightBiggangbracketrightBigg NHD-DTRs angbracketleftBiggbracketleftBiggphrase DOM 2 UNIONED + bracketrightBigg , bracketleftBigg phrase DOM 3 UNIONED + bracketrightBigg ... bracketleftBigg phrase DOM n UNIONED + bracketrightBiggangbracketrightBigg        Figure 1 : Word Order Domain phrase in the HD-DTR and NHD-DTRS features are linearly ordered as in Figure 1 .</sentence>
				<definiendum id="0">DOM</definiendum>
				<definiens id="0">bracketleftBigg phrase DOM n UNIONED + bracketrightBiggangbracketrightBigg        Figure 1 : Word Order Domain phrase in the HD-DTR</definiens>
			</definition>
			<definition id="1">
				<sentence>Let me discuss some auxiliary modifications 25                   head-arg-phrase PHON    phon CONSTITS uniontextbraceleftBigbraceleftbig ph bracerightbig , pa1 , ... , pai , ... , paj , ... pan bracerightBig CONSTRTS|LP uniontextbraceleftbiggbraceleftBig ... , angbracketleftbig pai , paj angbracketrightbig , ... bracerightBig , ca1 , ... , cai , ... caj , ... , can bracerightbigg    ARGS〈〉 HD-DTR hd           word PHN bracketleftbigg CONSTITS braceleftbig ph bracerightbig CONSTRS { } bracketrightbigg ARGS args angbracketleftBigga1   sign PHN bracketleftbigg CONSTITS pa1 CONSTRS ca1 bracketrightbigg   , ... , ai   sign PHN bracketleftbigg CONSTITS pai CONSTRS cai bracketrightbigg   , ... , aj   sign PHN bracketleftbigg CONSTITS paj CONSTRS caj bracketrightbigg   , ... , an bracketleftBiggsign PHN bracketleftBigCONSTITS pan CONSTRS can bracketrightBig bracketrightBigg angbracketrightBigg WOC|LP wocs braceleftBig ... , angbracketleftbig ai , aj angbracketrightbig , ... bracerightBig           NHD-DTRs args                   where wocs ⊆ { 〈x , y〉|xnegationslash=y , x , y∈DtrSet } DtrSet = { hd } ∪ args Figure 3 : Head-Argument Schema with WOC feature first .</sentence>
				<definiendum id="0">... , an bracketleftBiggsign PHN bracketleftBigCONSTITS pan CONSTRS</definiendum>
				<definiens id="0">         NHD-DTRs args                   where wocs ⊆ { 〈x , y〉|xnegationslash=y , x , y∈DtrSet } DtrSet = { hd }</definiens>
			</definition>
			<definition id="2">
				<sentence>This situation can be captured by the following feature specification for PHON , which encodes any of the acceptable strings above in an underspecified way .</sentence>
				<definiendum id="0">PHON</definiendum>
				<definiens id="0">encodes any of the acceptable strings above in an underspecified way</definiens>
			</definition>
			<definition id="3">
				<sentence>It is also at this stage that the WOC is picked up and pushed into the edge , along with the rule generated : 〈Mum→ Hd-Dtr • Nhd1 Nhd2 ... Nhdn ; WOCs〉 where WOCs is the set of ADJ and LP constraints picked up , if any .</sentence>
				<definiendum id="0">WOCs</definiendum>
				<definiens id="0">the set of ADJ and LP constraints picked up</definiens>
			</definition>
			<definition id="4">
				<sentence>The compliance check is a simple list operation .</sentence>
				<definiendum id="0">compliance check</definiendum>
			</definition>
</paper>

		<paper id="1030">
			<definition id="0">
				<sentence>With the growth of the World Wide Web as an information resource , it is increasingly being used as training data in Natural Language Processing ( NLP ) tasks .</sentence>
				<definiendum id="0">Wide Web</definiendum>
			</definition>
			<definition id="1">
				<sentence>Context-sensitive spelling correction is a disambiguation problem , where the correction word in a confusion set ( e.g. { their , they’re } ) needs to be selected for a given context .</sentence>
				<definiendum id="0">Context-sensitive spelling correction</definiendum>
				<definiens id="0">a disambiguation problem , where the correction word in a confusion set ( e.g. { their , they’re } ) needs to be selected for a given context</definiens>
			</definition>
			<definition id="2">
				<sentence>Keller and Lapata concluded that having access linguistic information ( accurate n-gram counts , POS tags , and parses ) outperforms using a large amount of web data .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">tags , and parses ) outperforms using a large amount of web data</definiens>
			</definition>
			<definition id="3">
				<sentence>The Open Directory has a broad coverage of many topics on the web and allows us to create a topic-diverse collection of pages .</sentence>
				<definiendum id="0">Open Directory</definiendum>
				<definiens id="0">a broad coverage of many topics on the web and allows us to create a topic-diverse collection of pages</definiens>
			</definition>
			<definition id="4">
				<sentence>A rule-based component analyses each web page and each sentence within a page to identify sections that are unlikely to be useful text .</sentence>
				<definiendum id="0">rule-based component</definiendum>
				<definiens id="0">analyses each web page and each sentence within a page to identify sections that are unlikely to be useful text</definiens>
			</definition>
			<definition id="5">
				<sentence>We compared with the Gigaword Corpus , a 2 billion token collection ( 1.75 billion words before tokenisation ) of newspaper text ( Graff , 2003 ) .</sentence>
				<definiendum id="0">Gigaword Corpus</definiendum>
			</definition>
			<definition id="6">
				<sentence>A confusion set is a collection of words which are commonly misused by even native speakers of a language because of their similarity .</sentence>
				<definiendum id="0">confusion set</definiendum>
			</definition>
			<definition id="7">
				<sentence>The Gigaword results show a skew towards the business sense of the word chain , while the Web Corpus covers both senses of the word .</sentence>
				<definiendum id="0">Web Corpus</definiendum>
				<definiens id="0">covers both senses of the word</definiens>
			</definition>
</paper>

		<paper id="2024">
			<definition id="0">
				<sentence>The purpose of this paper is to present LX-Suite , a set of tools for the shallow processing of Portuguese , developed under theTagShare1 project by the NLX Group.2 The tools included in this suite are a sentence chunker ; a tokenizer ; a POStagger ; a nominal featurizer ; a nominal lemmatizer ; and a verbal featurizer and lemmatizer .</sentence>
				<definiendum id="0">POStagger</definiendum>
				<definiens id="0">a nominal featurizer ; a nominal lemmatizer ; and a verbal featurizer and lemmatizer</definiens>
			</definition>
			<definition id="1">
				<sentence>The sentence chunker is a finite state automaton ( FSA ) , where the state transitions are triggered by specified character sequences in the input , and the emitted symbols correspond to sentence ( &lt; s &gt; ) and paragraph ( &lt; p &gt; ) boundaries .</sentence>
				<definiendum id="0">sentence chunker</definiendum>
				<definiens id="0">a finite state automaton ( FSA ) , where the state transitions are triggered by specified character sequences in the input , and the emitted symbols correspond to sentence ( &lt; s &gt;</definiens>
			</definition>
			<definition id="2">
				<sentence>The tool uses a list of rules that , depending on the termination of the word , assign all possible lemma-feature pairs .</sentence>
				<definiendum id="0">tool</definiendum>
				<definiens id="0">uses a list of rules that , depending on the termination of the word , assign all possible lemma-feature pairs</definiens>
			</definition>
</paper>

		<paper id="1043">
			<definition id="0">
				<sentence>We calculate the association strength for the target pair , and for each of its variants , a32a39a33a36a35 a9 a5 a37 , using pointwise mutual information ( PMI ) ( Church et al. , 1991 ) : a40a42a41a44a43 a7 a33a36a35 a9a46a45a47a11a48a13 a49a51a50a53a52a55a54 a7 a33a36a35 a9 a45 a11 a54 a7 a33 a11 a54 a7a10a9 a45 a11 a13 a49a51a50a53a52 a19a56a26a57a34a58a59a19a61a60a62a7 a33a36a35 a9a46a45a47a11 a60a62a7 a33a36a35a64a63 a11a62a60a65a7 a63a66a35 a9 a45 a11 ( 1 ) where a67 a23a69a68a70a23a31a28 and a9a36a71 is the target noun ; a56 is the set of all transitive verbs in the corpus ; a58 is the set of all nouns appearing as the direct object of some verb ; a60a2a7 a33a72a35 a9 a45 a11 is the frequency of a33 and a9 a45 occurring as a verb–object pair ; a60a62a7 a33a36a35a64a63 a11 is the total frequency of the target verb with any noun in a58 ; a60a2a7 a63a66a35 a9 a45 a11 is the total frequency of the noun a9 a45 in the direct object position of any verb in a56 .</sentence>
				<definiendum id="0">a9a36a71</definiendum>
				<definiendum id="1">a56</definiendum>
				<definiendum id="2">a58</definiendum>
				<definiens id="0">the association strength for the target pair , and for each of its variants , a32a39a33a36a35 a9 a5 a37 , using pointwise mutual information ( PMI ) ( Church et al. , 1991 ) : a40a42a41a44a43 a7 a33a36a35 a9a46a45a47a11a48a13 a49a51a50a53a52a55a54 a7 a33a36a35 a9 a45 a11 a54 a7 a33 a11 a54 a7a10a9 a45 a11 a13 a49a51a50a53a52 a19a56a26a57a34a58a59a19a61a60a62a7 a33a36a35 a9a46a45a47a11 a60a62a7 a33a36a35a64a63 a11a62a60a65a7 a63a66a35 a9 a45 a11 ( 1 ) where a67 a23a69a68a70a23a31a28 and</definiens>
				<definiens id="1">the set of all transitive verbs in the corpus ;</definiens>
				<definiens id="2">the set of all nouns appearing as the direct object of some verb ; a60a2a7 a33a72a35 a9 a45 a11 is the frequency of a33 and a9 a45 occurring as a verb–object pair ; a60a62a7 a33a36a35a64a63 a11 is the total frequency of the target verb with any noun in a58 ; a60a2a7 a63a66a35 a9 a45 a11 is the total frequency of the noun a9 a45 in the direct object position of any verb in a56</definiens>
			</definition>
			<definition id="1">
				<sentence>The prior probability of an individual pattern a3a5a4 a98 a0 a0 is estimated as : a54 a7a7a6a9a8a86a11a48a13 a10 a11a13a12a15a14a17a16 a10 a18a20a19a21a14a23a22 a60a2a7 a33 a3 a35 a9a46a45 a35 a3a5a4 a11 a10 a11a24a12a25a14a17a16 a10 a18a20a19a21a14a26a22 a10 a27a29a28a31a30a26a14a33a32a35a34 a60a2a7 a33 a3 a35 a9 a45 a35 a3a5a4a37a36 a11 The syntactic behaviour of the target verb–noun pair a32a34a33a72a35 a9 a37 is defined as the posterior probability distribution over the patterns , given the particular pair .</sentence>
				<definiendum id="0">prior probability</definiendum>
				<definiens id="0">of an individual pattern a3a5a4 a98 a0 a0 is estimated as : a54 a7a7a6a9a8a86a11a48a13 a10 a11a13a12a15a14a17a16 a10 a18a20a19a21a14a23a22 a60a2a7 a33 a3 a35 a9a46a45 a35 a3a5a4 a11 a10 a11a24a12a25a14a17a16 a10 a18a20a19a21a14a26a22 a10 a27a29a28a31a30a26a14a33a32a35a34 a60a2a7 a33 a3 a35 a9 a45 a35 a3a5a4a37a36 a11 The syntactic behaviour of the target verb–noun pair a32a34a33a72a35 a9 a37 is defined as the posterior probability distribution over the patterns , given the particular pair</definiens>
			</definition>
			<definition id="2">
				<sentence>To decide whether a3a5a4a25a36 is a canonical pattern for the target pair , we check whether a0 a36 a7 a33a36a35 a9a91a11a4a3a6a5a8a7 , where a5a9a7 is a threshold .</sentence>
				<definiendum id="0">a5a9a7</definiendum>
				<definiens id="0">a threshold</definiens>
			</definition>
</paper>

		<paper id="3004">
			<definition id="0">
				<sentence>Various state-of-the-art machine learning algorithms such as Maximum Entropy ( Borthwick , 1999 ) , AdaBoost ( Carreras et al. , 2002 ) , Hidden Markov Models ( Bikel et al. , ) , Memory-based Based learning ( Tjong Kim Sang , 2002b ) , have been used1 .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">Carreras et al. , 2002 ) , Hidden Markov Models ( Bikel et al. , ) , Memory-based Based learning ( Tjong Kim</definiens>
			</definition>
			<definition id="1">
				<sentence>1For other machine learning methods , consult http : //www.cnts.ua.ac.be/conll2002/ner/ http : //www.cnts.ua.ac.be/conll2003/ner/ Nevertheless all these machine learning algorithms rely on previously hand-labeled training data .</sentence>
				<definiendum id="0">consult http</definiendum>
				<definiens id="0">//www.cnts.ua.ac.be/conll2002/ner/ http : //www.cnts.ua.ac.be/conll2003/ner/ Nevertheless all these machine learning algorithms rely on previously hand-labeled training data</definiens>
			</definition>
			<definition id="2">
				<sentence>f1 : all letters of w08 are in capitals ; f2-f8 : w−3 , w−2 , w−1 , w0 , w+1 , w+2 , w+3 initiate in capitals ; f9 : position of w0 in the current sentence ; f10 : frequency of w0 ; f11-f17 : word forms of w0 and the words in [ −3 , +3 ] window ; f18 : first word making up the entity ; f19 : second word making up the entity , if present ; 6http : //www.cnts.ua.ac.be/conll2002/ner/data/ 7http : //www.cnts.ua.ac.be/conll2002/ner/bin/ 8w0 indicates the word to be classified .</sentence>
				<definiendum id="0">f18</definiendum>
				<definiens id="0">//www.cnts.ua.ac.be/conll2002/ner/bin/ 8w0 indicates the word to be classified</definiens>
			</definition>
			<definition id="3">
				<sentence>The selection restriction implies searching for words appearing after the preposition ”en” ( e.g. en Madrid ) and not before the preposition ( e.g. Madrid en ) .</sentence>
				<definiendum id="0">selection restriction</definiendum>
				<definiens id="0">implies searching for words appearing after the preposition ”en” ( e.g. en Madrid</definiens>
			</definition>
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>The problem of Generating Referring Expressions ( GRE ) can be summed up as a search for the properties in a knowledge base ( KB ) whose combination uniquely distinguishes a set of referents from their distractors .</sentence>
				<definiendum id="0">Generating Referring Expressions ( GRE</definiendum>
			</definition>
			<definition id="1">
				<sentence>A descriptionis functionallyrelevantif itsucceedsin distinguishing the intended referent ( s ) , but conversational relevance arises in part from implicatures carried by the use of attributes in context .</sentence>
				<definiendum id="0">descriptionis functionallyrelevantif itsucceedsin</definiendum>
				<definiens id="0">distinguishing the intended referent ( s ) , but conversational relevance arises in part from implicatures carried by the use of attributes in context</definiens>
			</definition>
			<definition id="2">
				<sentence>Let the two sets Pab , Dab be defined as follows : Pab = braceleftbigx|x∈S∧δ ( x , a ) ∼δ ( x , b ) bracerightbig Dab = braceleftbigy|y∈S∧δ ( y , a ) negationslash∼δ ( y , b ) bracerightbig Then : prox ( a , b ) = F ( δ ( a , b ) , |Pab| , |Dab| ) ( 4 ) that is , prox ( a , b ) is a function of the absolute distance δ ( a , b ) , the number of elements in S − { a , b } which are roughly equidistant from a and b , and the number of elements which are not equidistant .</sentence>
				<definiendum id="0">the two sets Pab , Dab be</definiendum>
				<definiens id="0">defined as follows : Pab = braceleftbigx|x∈S∧δ ( x , a ) ∼δ ( x , b ) bracerightbig Dab = braceleftbigy|y∈S∧δ ( y , a ) negationslash∼δ ( y , b ) bracerightbig Then : prox ( a , b ) = F ( δ ( a , b ) , |Pab| , |Dab| ) ( 4 ) that is , prox</definiens>
			</definition>
			<definition id="3">
				<sentence>Our definition is inspired by Tversky’s feature-based Contrast Model ( 1977 ) , in which the similarity of a , b with feature sets A , B is a linear function of the features they have in common and the features that pertain only to A or B , i.e. : sim ( a , b ) = f ( A∩B ) −f ( A∩B ) .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">in which the similarity of a , b with feature sets A ,</definiens>
			</definition>
			<definition id="4">
				<sentence>The rationale behind the algorithm is captured by the following declarative principle , where C ∈Cis any cluster , and anchor ( a , b ) means ‘b is the anchor of a’ : a∈C∧anchor ( a , b ) →b∈C ( 5 ) A cluster is defined as the transitive closure of the anchor relation , that is , if it holds that anchor ( a , b ) and anchor ( b , c ) , then { a , b , c } will be clustered together .</sentence>
				<definiendum id="0">C ∈Cis</definiendum>
				<definiendum id="1">anchor</definiendum>
				<definiendum id="2">a∈C∧anchor</definiendum>
				<definiens id="0">the transitive closure of the anchor relation , that is , if it holds that anchor ( a , b ) and anchor ( b , c )</definiens>
			</definition>
			<definition id="5">
				<sentence>Clusters could be of arbitrary size , but each element had to be placed in exactly one cluster .</sentence>
				<definiendum id="0">Clusters</definiendum>
				<definiens id="0">arbitrary size , but each element had to be placed in exactly one cluster</definiens>
			</definition>
			<definition id="6">
				<sentence>For each pair〈Uai , Usj〉of algorithm-human clusters , the agreement score was defined as |Uai ∩Usj| |Uai ∩Usj|+|Uai ∩Usi| , i.e. the ratio of the number of elements on which the human/algorithmagree , and the number of elements on which they do not agree .</sentence>
				<definiendum id="0">|Uai ∩Usj| |Uai ∩Usj|+|Uai ∩Usi|</definiendum>
				<definiens id="0">the ratio of the number of elements on which the human/algorithmagree , and the number of elements on which they do not agree</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>SMT attempts to find a sentence ˆe in the desired output language given the corresponding sentence f in the source language , according to ˆe = argmaxeP ( f|e ) P ( e ) ( 1 ) Most state-of-the-art SMT adopt a phrase-based approach such that e is chunked into I phrases ¯e1 , ... , ¯eI and the translation model is defined over mappings between phrases in e and in f. i.e. P ( ¯f|¯e ) .</sentence>
				<definiendum id="0">SMT</definiendum>
				<definiens id="0">attempts to find a sentence ˆe in the desired output language given the corresponding sentence f in the source language , according to ˆe</definiens>
			</definition>
			<definition id="1">
				<sentence>For the case of trigrams , this can be expressed as : pBO ( wt|wt−1 , wt−2 ) ( 2 ) = braceleftBigg dcpML ( wt|wt−1 , wt−2 ) if c &gt; τ α ( wt−1 , wt−2 ) pBO ( wt|wt−1 ) otherwise where pML denotes the maximum-likelihood estimate , c denotes the count of the triple ( wi , wi−1 , wi−2 ) inthetraining data , τ isthe count threshold above which the maximum-likelihood estimate is retained , and dN ( wi , wi−1 , wi−2 ) is a discounting factor ( generally between 0 and 1 ) that is applied to the higher-order distribution .</sentence>
				<definiendum id="0">pML</definiendum>
				<definiendum id="1">dN</definiendum>
				<definiens id="0">the maximum-likelihood estimate , c denotes the count of the triple ( wi , wi−1 , wi−2 ) inthetraining data , τ isthe count threshold above which the maximum-likelihood estimate is retained</definiens>
				<definiens id="1">a discounting factor ( generally between 0 and 1 ) that is applied to the higher-order distribution</definiens>
			</definition>
			<definition id="2">
				<sentence>The backoff procedure could in principle be performed on demand by a specialized decoder ; however , since we use an off-the-shelf decoder ( Pharaoh ( Koehn , 2004 ) ) , backoff is implicitly enforced by providing a phrase-table that includes all required backoff levels and by preprocessing the test data accordingly .</sentence>
				<definiendum id="0">off-the-shelf decoder</definiendum>
				<definiens id="0">includes all required backoff levels and by preprocessing the test data accordingly</definiens>
			</definition>
			<definition id="3">
				<sentence>forms , four probabilities need to be provided : two phrasal translation scores for both translation directions , p ( ¯e| ¯f ) and p ( ¯f|¯e ) , and two corresponding lexical scores , which are computed as a product of the word-by-word translation probabilities under the given alignment a : plex ( ¯e| ¯f ) = Jproductdisplay j=1 1 |j|a ( i ) = j| Isummationdisplay a ( i ) =j p ( fj|ei ) ( 3 ) where j ranges of words in phrase ¯f and i ranges of words in phrase ¯e. In the case of unknown words in the foreign language , we need the probabilities p ( ¯e|stem ( ¯f ) ) , p ( stem ( ¯f ) |¯e ) ( where the stemming operation stem ( ¯f ) applies to the unknown words in the phrase ) , and their lexical equivalents .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">¯f ) |¯e ) ( where the stemming operation stem</definiendum>
				<definiens id="0">a ( i ) =j p ( fj|ei ) ( 3 ) where j ranges of words in phrase ¯f and i ranges of words in phrase</definiens>
				<definiens id="1">the unknown words in the phrase ) , and their lexical equivalents</definiens>
			</definition>
			<definition id="4">
				<sentence>Finnish is a highly agglutinative language with a large number of inflectional paradigms ( e.g. one foreach ofits15 cases ) .</sentence>
				<definiendum id="0">Finnish</definiendum>
			</definition>
			<definition id="5">
				<sentence>Our 46 German-English baseline backoff Set BLEU PER BLEU PER train1 15.3 55.8 16.3 54.8 train2 19.4 52.3 19.6 50.9 train3 20.3 49.6 20.7 49.2 train4 22.5 48.1 22.5 47.9 train5 24.8 46.3 25.1 45.5 Finnish-English baseline backoff Set BLEU PER BLEU PER train1 12.9 58.7 14.0 57.0 train2 14.5 59.5 15.3 58.4 train3 15.6 56.6 16.4 56.2 train4 20.6 50.3 21.0 49.6 train5 22.0 50.0 22.3 49.5 Table 7 : BLEU ( % ) and position-independent word error rate ( PER ) for the test set ( entire test set ) .</sentence>
				<definiendum id="0">PER</definiendum>
				<definiens id="0">for the test set ( entire test set )</definiens>
			</definition>
			<definition id="6">
				<sentence>BACKOFF : i hope that the united nations in the negotiations to reach a conclusion that the greek and turkish communities can work together to bring the benefits of the accession of the republic of ydistetyss¨a. in this respect , under the REF : in this connection , i would hope that the talks conducted under the auspices of the united nations will be able to come to a successful conclusion enabling the greek and turkish cypriot populations to enjoy the advantages of membership of the european union in the context of a reunified republic .</sentence>
				<definiendum id="0">BACKOFF</definiendum>
				<definiendum id="1">REF</definiendum>
				<definiens id="0">a successful conclusion enabling the greek and turkish cypriot populations to enjoy the advantages of membership of the european union in the context of a reunified republic</definiens>
			</definition>
</paper>

		<paper id="2030">
			<definition id="0">
				<sentence>ATT-Meta includes a general-purpose reasoning engine , and can potentially be used to reason about emotion in relation to other factors in a situation .</sentence>
				<definiendum id="0">ATT-Meta</definiendum>
				<definiens id="0">includes a general-purpose reasoning engine</definiens>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>Statistical Machine Translation is a data driven machine translation technique which uses probabilistic models of natural language for automatic translation ( Brown et al. , 1993 ) , ( Al-Onaizan et al. , 1999 ) .</sentence>
				<definiendum id="0">Statistical Machine Translation</definiendum>
				<definiens id="0">a data driven machine translation technique which uses probabilistic models of natural language for automatic translation ( Brown et al. , 1993</definiens>
			</definition>
			<definition id="1">
				<sentence>Expectation Evaluation is the soul of parameter estimation ( Brown et al. , 1993 ) , ( Al-Onaizan et al. , 1999 ) .</sentence>
				<definiendum id="0">Expectation Evaluation</definiendum>
				<definiens id="0">the soul of parameter estimation</definiens>
			</definition>
			<definition id="2">
				<sentence>Exact Decoding is the original decoding problem as defined in ( Brown et al. , 1993 ) and Relaxed Decoding is the relaxation of the decoding problem typically used in practice .</sentence>
				<definiendum id="0">Exact Decoding</definiendum>
				<definiendum id="1">Relaxed Decoding</definiendum>
				<definiens id="0">the relaxation of the decoding problem typically used in practice</definiens>
			</definition>
			<definition id="3">
				<sentence>Given a matrixM = [ Mj , i ] n×n whose entries are either 0 or 1 , compute the following : perm ( M ) = summationtextpiproducttextnj=1Mj , pij where pi is a permutation of 1 , ... , n. This problem is the same as that of counting the number of perfect matchings in a bipartite graph and is known to be # P-Complete ( ? )</sentence>
				<definiendum id="0">pi</definiendum>
				<definiens id="0">the same as that of counting the number of perfect matchings in a bipartite graph</definiens>
			</definition>
			<definition id="4">
				<sentence>Let A be the set of alignments , a , such that a is a permutation of 1,2 , ... , ( n + 1 ) and aj = i. Observe that P ( f , a|e ) is non-zero only for the alignments in A. It follows immediately that with these parameter settings , c ( j|i , n , n ; f , e ) = perm ( M ) .</sentence>
				<definiendum id="0">c ( j|i</definiendum>
				<definiens id="0">a permutation of 1,2 , ... , ( n + 1 ) and aj = i. Observe that P ( f , a|e ) is non-zero only for the alignments in A. It follows immediately that with these parameter settings</definiens>
			</definition>
			<definition id="5">
				<sentence>We set n ( φ|e ) =    1 if φ = 1 and e negationslash= ˆe 1 if φ = k and e = ˆe 0 otherwise .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">φ|e ) =    1 if φ = 1 and e negationslash= ˆe 1 if φ = k and e = ˆe 0 otherwise</definiens>
			</definition>
</paper>

		<paper id="1037">
			<definition id="0">
				<sentence>The following recursive equation gives us a way of calculating the expected cumulative value ( V-value ) of a state a2 ( -value ) : 289 a0a2a1 a2a4a3a6a5a8a7a10a9a10a11a13a12a13a14a16a15 a9a18a17 a9a18a9a10a11a20a19a21 a14a16a15 a9a18a17 a9a22a9a10a11a24a23a26a25 a0a2a1 a2a28a27a29a3a10a30 Here a1 a1 a2a31a3 is the best action for state a2 at this time , a12 is the probability of getting from state a2 to a2 a27 via a1 a1 a2a4a3 .</sentence>
				<definiendum id="0">a12</definiendum>
				<definiens id="0">gives us a way of calculating the expected cumulative value ( V-value ) of a state a2</definiens>
			</definition>
			<definition id="1">
				<sentence>Each session consists of an interaction with one student over 5 different college-level physics problems , for a total of 100 dialogues .</sentence>
				<definiendum id="0">session</definiendum>
				<definiens id="0">consists of an interaction with one student over 5 different college-level physics problems</definiens>
			</definition>
			<definition id="2">
				<sentence>Percent Correct is the percentage of questions in the current problem the student has answered correctly so far .</sentence>
				<definiendum id="0">Percent Correct</definiendum>
				<definiens id="0">the percentage of questions in the current problem the student has answered correctly so far</definiens>
			</definition>
			<definition id="3">
				<sentence>In addition to 290 State Parameters Student Move Shallow ( S ) Novel &amp; As &amp; Deep ( O ) Certainty Certain , Uncertain , Neutral Frustration Frustrated ( F ) , Neutral ( N ) , Correctness Correct ( C ) , Incorrect ( I ) Partially Correct ( PC ) Percent Correct 50-100 % ( High ) , 0-50 % ( Low ) Concept Repetition Concept is not repeated ( 0 ) , Concept is repeated ( R ) Table 1 : Student Features in Tutoring Corpus Action Parameters Tutor Feedback Act Positive , Negative Tutor Question Act Short Answer Question ( SAQ ) Complex Answer Question ( CAQ ) Tutor State Act Restatement , Recap , Hint Expansion , Bottom Out Table 2 : Tutor Acts in Tutoring Corpus explaining physics concepts , the authors also include feedback and other types of helpful measures ( such as hints or restatements ) to help the student along .</sentence>
				<definiendum id="0">Correctness Correct</definiendum>
				<definiens id="0">Student Features in Tutoring Corpus Action Parameters Tutor Feedback</definiens>
			</definition>
			<definition id="4">
				<sentence>Emotion detection and adaptation is a key issue for any spoken dialogue systems as designers try to make the system as easy to use for a student or trip-planner , etc .</sentence>
				<definiendum id="0">adaptation</definiendum>
			</definition>
</paper>

		<paper id="3003">
			<definition id="0">
				<sentence>The term anaphora can be informally explained as a way of mentioning a previously encountered entity without naming it explicitly .</sentence>
				<definiendum id="0">term anaphora</definiendum>
				<definiens id="0">a way of mentioning a previously encountered entity without naming it explicitly</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>A dependency graph is a labeled directed graph , the nodes of which are indices corresponding to the tokens of a sentence .</sentence>
				<definiendum id="0">dependency graph</definiendum>
				<definiens id="0">a labeled directed graph , the nodes of which are indices corresponding to the tokens of a sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally : Definition 1 Given a set R of dependency types ( arc labels ) , a dependency graph for a sentence x = ( w1 , ... , wn ) is a labeled directed graph G = ( V , E , L ) , where : Definition 2 A dependency graph G is wellformed if and only if : The set of V of nodes ( or vertices ) is the set Zn+1 = { 0,1,2 , ... , n } ( n∈Z+ ) , i.e. , the set of non-negative integers up to and including n. This means that every token index i of the sentence is a node ( 1≤i≤n ) and that there is a special node 0 , which does not correspond to any token of the sentence and which will always be a root of the dependency graph ( normally the only root ) .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">a set R of dependency types ( arc labels ) , a dependency graph for a sentence x = ( w1 , ... , wn ) is a labeled directed graph G = ( V , E ,</definiens>
				<definiens id="1">The set of V of nodes ( or vertices</definiens>
			</definition>
			<definition id="2">
				<sentence>a7 a4 a63 AuxK Figure 1 : Dependency graph for Czech sentence from the Prague Dependency Treebank say that i is the head and j is the dependent of the arc ( i , j ) .</sentence>
				<definiendum id="0">j</definiendum>
				<definiens id="0">Dependency graph for Czech sentence from the Prague Dependency Treebank say that i is the head</definiens>
			</definition>
			<definition id="3">
				<sentence>This is well motivated if the time required to compute PERMISSIBLE ( i , j , C ) is insignificant compared to the time needed for LINK ( i , j ) , as is typically the case in data-driven systems , where LINK ( i , j ) requires a call to a trained classifier , while PERMISSIBLE ( i , j , C ) only needs access to the partially built graph G. Theresults obtained in this waywill be partially dependent on the particular algorithm used , but they can in principle be generalized to any algorithm that tries to link all possible word pairs and that satisfies the following condition : For any graph G = ( V , E , L ) derived by the algorithm , if e , eprime ∈E and e covers eprime , then the algorithm adds eprime before e. This condition is satisfied not only by Covington’s incremental algorithm but also by algorithms that add arcs strictly in order of increasing length , such as the algorithm of Eisner ( 2000 ) and other algorithms based on dynamic programming .</sentence>
				<definiendum id="0">eprime ∈E</definiendum>
				<definiens id="0">For any graph G = ( V , E , L ) derived by the algorithm</definiens>
			</definition>
			<definition id="4">
				<sentence>The Danish Dependency Treebank ( DDT ) comprises 100K words of text selected from the Danish PAROLEcorpus , with annotation of primary and secondary dependencies based on Discontinuous Grammar ( Kromann , 2003 ) .</sentence>
				<definiendum id="0">Danish Dependency Treebank ( DDT )</definiendum>
			</definition>
			<definition id="5">
				<sentence>The experiments are performed by parsing each sentence of the treebanks while using the gold standard dependency graph for that sentence as an oracletoresolve thenondeterministic choice inthe LINK ( i , j ) operation as follows : LINK ( i , j ) 1 if ( i , j ) ∈Eg 3 if ( j , i ) ∈Eg where Eg is the arc relation of the gold standard dependency graph Gg and E is the arc relation of the graph G built by the parsing algorithm .</sentence>
				<definiendum id="0">Eg</definiendum>
				<definiens id="0">the arc relation of the gold standard dependency graph Gg and E is the arc relation of the graph G built by the parsing algorithm</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>Formally , the degree of dominance of a particular sense of a word ( target word ) in a given text ( target text ) may be defined as the ratio of the occurrences of the sense to the total occurrences of the target word .</sentence>
				<definiendum id="0">degree of dominance</definiendum>
				<definiens id="0">the ratio of the occurrences of the sense to the total occurrences of the target word</definiens>
			</definition>
			<definition id="1">
				<sentence>While other sense inventories such as WordNet exist , use of a published thesaurus has three distinct advantages : ( i ) coarse senses—it is widely believed that the sense distinctions of WordNet are far too fine-grained ( Agirre and Lopez de Lacalle Lekuona ( 2003 ) and citations therein ) ; ( ii ) computational ease—with just around a thousand categories , the word–category matrix has a manageable size ; ( iii ) widespread availability—thesauri are available ( or can be created with relatively less effort ) in numerous languages , while WordNet is available only for English and a few romance languages .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">available ( or can be created with relatively less effort</definiens>
			</definition>
			<definition id="2">
				<sentence>We provide experimental results using Dice coefficient ( Dice ) , cosine ( cos ) , pointwise mutual information ( pmi ) , odds ratio ( odds ) , Yule’s coefficient of colligation ( Yule ) , and phi coefficient ( φ ) 1 .</sentence>
				<definiendum id="0">cosine ( cos</definiendum>
				<definiens id="0">pointwise mutual information ( pmi ) , odds ratio ( odds ) , Yule’s coefficient of colligation ( Yule ) , and phi coefficient ( φ ) 1</definiens>
			</definition>
			<definition id="3">
				<sentence>( Thus CYCGtCY is equal to the number of occurrences of t , and CYTCY is equal to the total number of words ( tokens ) in the windows around occurrences of t. ) We describe 1Measures of association ( Sheskin , 2003 ) : cosB4wBNcB5BP nwc D4n wA3 A2 D4n A3c BN pmiB4wBNcB5BP log nwcA2Nn wA3 A2n A3c BN oddsB4wBNcB5BP nwcA2n BMBM nw BM A2n BMc BN YuleB4wBNcB5BP D4odds B4wBNcB5A01 D4odds B4wBNcB5B71 BN DiceB4wBNcB5BP 2A2nwcn wA3B7nA3c BN φB4wBNcB5BP B4nwcA2n BMBM B5A0B4nw BM A2n BMcB5 D4n wA3A2nBMA3A2nA3cA2nA3BM UnweightedWeighted disambiguation Implicit sense Explicit sense disambiguation votingvoting DI , W DE , W DI , U E , UD Figure 3 : The four dominance methods .</sentence>
				<definiendum id="0">CYTCY</definiendum>
				<definiens id="0">equal to the total number of words</definiens>
			</definition>
			<definition id="4">
				<sentence>The dominance of a sense is the ratio of the total votes it gets to the sum of votes received by all the senses .</sentence>
				<definiendum id="0">dominance of a sense</definiendum>
			</definition>
			<definition id="5">
				<sentence>The dominance DI BNU of the sense is the ratio of the votes it gets to the total votes cast for the word ( number of cooccurring words ) .</sentence>
				<definiendum id="0">dominance DI BNU of the sense</definiendum>
				<definiens id="0">the ratio of the votes it gets to the total votes cast for the word ( number of cooccurring words )</definiens>
			</definition>
			<definition id="6">
				<sentence>Also , Yule is a derivative of odds .</sentence>
				<definiendum id="0">Yule</definiendum>
				<definiens id="0">a derivative of odds</definiens>
			</definition>
</paper>

		<paper id="2004">
			<definition id="0">
				<sentence>DUDE targets development of flexible and robust ISU dialogue systems from BPMs and databases .</sentence>
				<definiendum id="0">DUDE</definiendum>
				<definiens id="0">targets development of flexible and robust ISU dialogue systems from BPMs and databases</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 3 : Example : using DUDE to define “spotter” phrases for different BPM subtasks Figure 4 shows the developer’s overview of the subtasks of a BPM ( here , hotel information ) .</sentence>
				<definiendum id="0">BPM</definiendum>
				<definiens id="0">hotel information )</definiens>
			</definition>
</paper>

		<paper id="1036">
			<definition id="0">
				<sentence>281 Weobserve parallelism atvarious structural levels of text : among heading structures , VP ellipses and others , enumerations of noun phrases in a sentence , enumerations with or without markers such as frame introducers ( e.g. “In France , ... In Italy , ... ” ) or typographical and layout markers .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">atvarious structural levels of text : among heading structures</definiens>
			</definition>
			<definition id="1">
				<sentence>Similarly to ( Wagner and Fischer , 1974 ) , we considered three edit operations : By definition , the cost of a sequence of edit operations is the sum of the costs2 of the elementary 2We used unitary costs in this study 282 operations , and the distance between S1 and S2 is the cost of the least cost transformation of S1 into S2 .</sentence>
				<definiendum id="0">S2</definiendum>
				<definiens id="0">the cost of the least cost transformation of S1 into S2</definiens>
			</definition>
			<definition id="2">
				<sentence>L is an equivalence relation overnodes and keyroots ( KR ) are bydefinition the equivalence relation representatives of highest postfix index .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">an equivalence relation overnodes and keyroots ( KR ) are bydefinition the equivalence relation representatives of highest postfix index</definiens>
			</definition>
			<definition id="3">
				<sentence>E.g : SST ( 3 ) = T [ 1,2,3 ] is the subtree containing nodes a , b , d. A forest of SST ( k1 ) is defined as : T [ L ( k1 ) , L ( k1 ) + 1 , ... , x ] , where x is a node of SST ( k1 ) .</sentence>
				<definiendum id="0">d. A forest of SST</definiendum>
				<definiendum id="1">x</definiendum>
				<definiens id="0">the subtree containing nodes a , b ,</definiens>
			</definition>
			<definition id="4">
				<sentence>Complexity for this algorithm is : O ( |T1|×|T2|×min ( p ( T1 ) , f ( T1 ) ) ×min ( p ( T2 ) , f ( T2 ) ) ) where d ( Ti ) is the depth Ti and f ( Ti ) is the number of terminal nodes of Ti .</sentence>
				<definiendum id="0">Complexity</definiendum>
				<definiendum id="1">Ti )</definiendum>
				<definiens id="0">|T1|×|T2|×min ( p ( T1 ) , f ( T1 ) ) ×min ( p ( T2 ) , f ( T2 ) ) ) where d</definiens>
			</definition>
			<definition id="5">
				<sentence>Our parallelism detection is an unsupervised clustering application : given a set of pairs of sentences , it automatically classifies them into the class of the parallelisms and the remainders class .</sentence>
				<definiendum id="0">parallelism detection</definiendum>
				<definiens id="0">an unsupervised clustering application : given a set of pairs of sentences</definiens>
			</definition>
			<definition id="6">
				<sentence>Because efforts in improving one often result in degrading the other , the F-measure ( harmonic mean ) combines them into a unique parameter , which simplifies comparisons of results .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiens id="0">harmonic mean ) combines them into a unique parameter , which simplifies comparisons of results</definiens>
			</definition>
			<definition id="7">
				<sentence>Textual parallelism plays an important role among discourse features when detecting discourse structures .</sentence>
				<definiendum id="0">Textual parallelism</definiendum>
				<definiens id="0">plays an important role among discourse features when detecting discourse structures</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>The ICSI Meeting Corpus ( Janin et al. , 2003 ) is a collection of 75 manually transcribed group discussions of about one hour each , involving 3 to 13 speakers .</sentence>
				<definiendum id="0">ICSI Meeting Corpus</definiendum>
				<definiens id="0">a collection of 75 manually transcribed group discussions of about one hour each , involving 3 to 13 speakers</definiens>
			</definition>
			<definition id="1">
				<sentence>This type of pattern matching is done 53 for two reasons : To get a simplified symbolic representation of the syntactic context of it , and to extract the other elements ( nouns , verbs ) from its predicative context .</sentence>
				<definiendum id="0">pattern matching</definiendum>
				<definiens id="0">done 53 for two reasons : To get a simplified symbolic representation of the syntactic context of it , and to extract the other elements ( nouns , verbs ) from its predicative context</definiens>
			</definition>
			<definition id="2">
				<sentence>E.g. , the values ( i.e. mostly nouns , verbs , and adjectives ) of the lexical features , which have been almost entirely ignored by both classifiers , could be generalized bymapping them to common WordNet superclasses .</sentence>
				<definiendum id="0">E.g.</definiendum>
				<definiens id="0">the values ( i.e. mostly nouns , verbs , and adjectives</definiens>
			</definition>
</paper>

		<paper id="2005">
			<definition id="0">
				<sentence>The tree descriptions supported by the XMG formalism are defined by the following tree description language : Description : := x → y | x →+ y | x →∗ y | x ≺ y | x ≺+ y | x ≺∗ y | x [ f : E ] ( 1 ) where x , y represent node variables , →immediate dominance ( x is directly above y ) , →+ strict dominance ( x is above y ) , →∗ large dominance ( x is above or equal to y ) , ≺ is immediate precedence , ≺+ strict precedence , and ≺∗ large precedence3 .</sentence>
				<definiendum id="0">large dominance</definiendum>
				<definiens id="0">the following tree description language : Description : := x → y | x →+ y | x →∗ y | x ≺ y | x ≺+ y | x ≺∗ y | x [ f : E ] ( 1 ) where x , y represent node variables , →immediate dominance ( x is directly above y ) , →+ strict dominance ( x is above y )</definiens>
			</definition>
			<definition id="1">
				<sentence>4E is an expression , so it can be a feature structure : that’s how top and bottom are encoded in TAG .</sentence>
				<definiendum id="0">4E</definiendum>
				<definiens id="0">that’s how top and bottom are encoded in TAG</definiens>
			</definition>
			<definition id="2">
				<sentence>Currently , XMG includes a semantic representationlanguage based onFlatSemantics ( see ( Gardent and Kallmeyer , 2003 ) ) : Description : := lscript : p ( E1 , ... , En ) | ¬lscript : p ( E1 , ... , En ) | Ei lessmuch Ej ( 2 ) where lscript : p ( E1 , ... , En ) represents the predicate p with parameters E1 , .</sentence>
				<definiendum id="0">XMG</definiendum>
				<definiendum id="1">, En</definiendum>
				<definiendum id="2">E1 , ... , En )</definiendum>
				<definiens id="0">Description : := lscript : p ( E1 , ... , En ) | ¬lscript : p ( E1 , ...</definiens>
			</definition>
			<definition id="3">
				<sentence>¬ is the logical negation , and Ei lessmuch Ej is the scope between Ei and Ej ( used to deal with quantifiers ) .</sentence>
				<definiendum id="0">¬</definiendum>
				<definiens id="0">the scope between Ei and Ej ( used to deal with quantifiers</definiens>
			</definition>
			<definition id="4">
				<sentence>As we have seen , an XMG metagrammar consists of classes that are combined .</sentence>
				<definiendum id="0">XMG metagrammar</definiendum>
				<definiens id="0">consists of classes that are combined</definiens>
			</definition>
			<definition id="5">
				<sentence>The idea is to : integer , ( Eqx , Upx , Downx , Leftx , Rightx ) where Eqx ( respectively Upx , Downx , Leftx , Rightx ) denotes the set of nodes in the description which areequal , ( respectively above , below , left , and right ) of x ( see picture 2 ) .</sentence>
				<definiendum id="0">Rightx )</definiendum>
				<definiens id="0">integer , ( Eqx , Upx , Downx , Leftx , Rightx ) where Eqx ( respectively Upx , Downx , Leftx ,</definiens>
				<definiens id="1">the set of nodes in the description which areequal , ( respectively above , below , left , and right ) of x ( see picture 2 )</definiens>
			</definition>
</paper>

		<paper id="2011">
			<definition id="0">
				<sentence>Esfinge is a general domain Portuguese question answering system .</sentence>
				<definiendum id="0">Esfinge</definiendum>
				<definiens id="0">a general domain Portuguese question answering system</definiens>
			</definition>
			<definition id="1">
				<sentence>Esfinge explores a different approach : instead of investing in preprocessing corpora , it tries to use the redundancy existent in the web to find its answers .</sentence>
				<definiendum id="0">Esfinge</definiendum>
			</definition>
			<definition id="2">
				<sentence>( F * S * L ) , through the first 100 snippets resulting from the web search ; where F is the n-gram frequency , S is the score of the search pattern that recovered the document and L is the n-gram length .</sentence>
				<definiendum id="0">F</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">L</definiendum>
				<definiens id="0">the score of the search pattern that recovered the document</definiens>
			</definition>
			<definition id="3">
				<sentence>Esfinge has a module that uses the named entity recognition ( NER ) system SIEMES to detect specific types of answers .</sentence>
				<definiendum id="0">Esfinge</definiendum>
				<definiens id="0">has a module that uses the named entity recognition ( NER ) system SIEMES to detect specific types of answers</definiens>
			</definition>
			<definition id="4">
				<sentence>It was built with the help of Esfinge log ( which records all the answers analysed by the system ) .</sentence>
				<definiendum id="0">Esfinge log</definiendum>
				<definiens id="0">records all the answers analysed by the system )</definiens>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>Someworkwithintheframework of synchronous grammars ( Wu , 1997 ; Melamed , 2003 ) , while others create a generative story that includes a parse tree provided for one of the sentences ( Yamada and Knight , 2001 ) .</sentence>
				<definiendum id="0">synchronous grammars</definiendum>
				<definiens id="0">includes a parse tree provided for one of the sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>An alignment space determines the set of all possible alignments that can ex145 ist for a given sentence pair .</sentence>
				<definiendum id="0">alignment space</definiendum>
				<definiens id="0">determines the set of all possible alignments that can ex145 ist for a given sentence pair</definiens>
			</definition>
			<definition id="2">
				<sentence>Used as a word aligner , an ITG parser searches a subspace of permutation space : the ITG requires that any movement that occurs during translation be explained by a binary tree with inversions .</sentence>
				<definiendum id="0">ITG parser</definiendum>
				<definiens id="0">searches a subspace of permutation space : the ITG requires that any movement that occurs during translation be explained by a binary tree with inversions</definiens>
			</definition>
			<definition id="3">
				<sentence>Our test set is the 500 manually aligned sentence pairs created by Franz Och and Hermann Ney ( 2003 ) .</sentence>
				<definiendum id="0">test set</definiendum>
			</definition>
			<definition id="4">
				<sentence>We test seven methods , one for each of the four syntactic spaces described in this paper , and three variations of search in permutation space : Greedy : A greedy search of permutation space .</sentence>
				<definiendum id="0">Greedy</definiendum>
				<definiens id="0">A greedy search of permutation space</definiens>
			</definition>
			<definition id="5">
				<sentence>Dep : A beam search of the dependency space .</sentence>
				<definiendum id="0">Dep</definiendum>
				<definiens id="0">A beam search of the dependency space</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>The formulation works by defining the score of a dependency tree to be the sum of edge scores , s ( x , y ) = summationdisplay ( i , j ) ∈y s ( i , j ) where x = x1 ···xn is an input sentence and y a dependency tree for x. We can view y as a set of tree edges and write ( i , j ) ∈ y to indicate an edge in y from word xi to word xj .</sentence>
				<definiendum id="0">x = x1 ···xn</definiendum>
				<definiens id="0">the sum of edge scores , s ( x , y ) = summationdisplay</definiens>
				<definiens id="1">an input sentence and y a dependency tree for x. We can view y as a set of tree edges and write ( i , j ) ∈ y to indicate an edge in y from word xi to word xj</definiens>
			</definition>
			<definition id="1">
				<sentence>The score of an edge is in turn computed as the inner product of a high-dimensional feature representation of the edge with a corresponding weight vector , s ( i , j ) = w·f ( i , j ) This is a standard linear classifier in which the weight vector w are the parameters to be learned during training .</sentence>
				<definiendum id="0">score of an edge</definiendum>
				<definiens id="0">the inner product of a high-dimensional feature representation of the edge with a corresponding weight vector , s ( i</definiens>
				<definiens id="1">a standard linear classifier in which the weight vector w are the parameters to be learned during training</definiens>
			</definition>
			<definition id="2">
				<sentence>of what it was in y. The test tree ( y ) is true iff the dependency graph y satisfies the tree constraint .</sentence>
				<definiendum id="0">test tree</definiendum>
				<definiens id="0">true iff the dependency graph y satisfies the tree constraint</definiens>
			</definition>
			<definition id="3">
				<sentence>In the Danish Dependency Treebank , roughly 5 % of words have more than one parent , which breaks the single parent ( or tree ) constraint we have previously required on dependency structures .</sentence>
				<definiendum id="0">Danish Dependency Treebank</definiendum>
				<definiens id="0">breaks the single parent</definiens>
			</definition>
			<definition id="4">
				<sentence>The second-order features are built from the following conjunctions of word and POS identity predicates xi-pos , xk-pos , xj-pos xk-pos , xj-pos xk-word , xj-word xk-word , xj-pos xk-pos , xj-word where xi-pos is the part-of-speech of the ith word in the sentence .</sentence>
				<definiendum id="0">xi-pos</definiendum>
				<definiens id="0">the part-of-speech of the ith word in the sentence</definiens>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>dLJ is the minimum cost of a path between the lower left ( first ) and the upper right ( last ) alignment grid point which covers all reference and candidate words .</sentence>
				<definiendum id="0">dLJ</definiendum>
				<definiens id="0">the minimum cost of a path between the lower left ( first ) and the upper right ( last ) alignment grid point which covers all reference and candidate words</definiens>
			</definition>
			<definition id="1">
				<sentence>CDER ( as opposed to PER ) has the ability to reward correct local ordering , whereas PER ( as opposed to CDER ) penalizes overly long candidate sentences .</sentence>
				<definiendum id="0">CDER</definiendum>
				<definiens id="0">opposed to PER ) has the ability to reward correct local ordering , whereas PER ( as opposed to CDER ) penalizes overly long candidate sentences</definiens>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>The Britannica corpus , collected and annotated by Barzilay and Elhadad ( 2003 ) , consists of 103 pairsofcomprehensive andelementary encyclopedia entries describing major world cities .</sentence>
				<definiendum id="0">Britannica corpus</definiendum>
				<definiens id="0">consists of 103 pairsofcomprehensive andelementary encyclopedia entries describing major world cities</definiens>
			</definition>
			<definition id="1">
				<sentence>Whereas for the Britannica corpus parallels were marked at the resolution of sentences , Aland’s annotation presents parallels as matched sequences of verses , known as pericopes .</sentence>
				<definiendum id="0">Britannica corpus</definiendum>
				<definiens id="0">parallels were marked at the resolution of sentences , Aland’s annotation presents parallels as matched sequences of verses</definiens>
			</definition>
</paper>

		<paper id="1046">
			<definition id="0">
				<sentence>We evaluate and compare the performance of the hand-crafted and learned edit machines in the context of a multimodal conversational system ( MATCH ) .</sentence>
				<definiendum id="0">MATCH</definiendum>
				<definiens id="0">the performance of the hand-crafted and learned edit machines in the context of a multimodal conversational system</definiens>
			</definition>
			<definition id="1">
				<sentence>MATCH ( Multimodal Access To City Help ) is a working city guide and navigation system that enables mobile users to access restaurant and subway information for New York City and Washington , D.C. ( Johnston et al. , 2002 ) .</sentence>
				<definiendum id="0">MATCH</definiendum>
				<definiens id="0">a working city guide and navigation system that enables mobile users to access restaurant and subway information for New York City and Washington</definiens>
			</definition>
			<definition id="2">
				<sentence>The grammar consists of a set of context-free rules .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiens id="0">consists of a set of context-free rules</definiens>
			</definition>
			<definition id="3">
				<sentence>In Figure 4 ( Gesture ) the specific content is indicated in parentheses after SEM .</sentence>
				<definiendum id="0">Gesture )</definiendum>
				<definiens id="0">the specific content is indicated in parentheses after SEM</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , in ( 1 ) , a19a21a20a23a22a54a24a32a26a55a28a44a30a32a31 is the predicate and a33a43a35a56a37a23a39a40a24a57a37a43a42a23a31a41a28a23a39a58a31a45a47a44a48a43a39a44a19a57a33a49a24a23a50a41a39a32a51a38a39a44a19a41a33a23a26a56a31a41a28 is the set of arguments to the predicate .</sentence>
				<definiendum id="0">a19a21a20a23a22a54a24a32a26a55a28a44a30a32a31</definiendum>
				<definiendum id="1">a33a43a35a56a37a23a39a40a24a57a37a43a42a23a31a41a28a23a39a58a31a45a47a44a48a43a39a44a19a57a33a49a24a23a50a41a39a32a51a38a39a44a19a41a33a23a26a56a31a41a28</definiendum>
				<definiens id="0">the predicate and</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>Action control dialogue is a kind of taskoriented dialogue in which a commander controls the actions1 of other agents called followers through verbal interaction .</sentence>
				<definiendum id="0">Action control dialogue</definiendum>
				<definiens id="0">a kind of taskoriented dialogue in which a commander controls the actions1 of other agents called followers through verbal interaction</definiens>
			</definition>
			<definition id="1">
				<sentence>Understanding a DRIU consists of repair target identification and repair content interpretation .</sentence>
				<definiendum id="0">Understanding a DRIU</definiendum>
				<definiens id="0">consists of repair target identification and repair content interpretation</definiens>
			</definition>
			<definition id="2">
				<sentence>The DRIU ( 1.3 ) indicates that V failed to identify U’s intended object in utterance ( 1.1 ) .</sentence>
				<definiendum id="0">DRIU</definiendum>
			</definition>
			<definition id="3">
				<sentence>A DU is a sequence of utterance units ( UUs ) assigned grounding acts ( GAs ) .</sentence>
				<definiendum id="0">DU</definiendum>
				<definiens id="0">a sequence of utterance units ( UUs ) assigned grounding acts ( GAs )</definiens>
			</definition>
			<definition id="4">
				<sentence>In brief , when a level 3 evidence is presented by the follower and negative feedback ( i.e. , DRIUs ) is not provided by the commander , only propositions supported by the evidence are considered to be grounded even though the DU has not yet reached state F. In general , past work on discourse has targeted dialogue consisting of only utterances , or has consideredactionsassubsidiaryelements .</sentence>
				<definiendum id="0">DRIUs</definiendum>
			</definition>
			<definition id="5">
				<sentence>Let us look at a sample dialogue ( 5.1–5.5 ) , where U is the commander and V is the follower .</sentence>
				<definiendum id="0">U</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">the follower</definiens>
			</definition>
			<definition id="6">
				<sentence>( 6 ) α=Request ( U , V , Put ( # Agt1 , # Obj1 , # Dst1 ) ) ( a ) speechActType ( α ) =Request ( b ) presenter ( α ) =U ( c ) addressee ( α ) =V ( d ) actionType ( content ( α ) ) =Put ( e ) agent ( content ( α ) ) = # Agt1 , referent ( # Agt1 ) =V ( f ) object ( content ( α ) ) = # Obj1 , referent ( # Obj1 ) =Ball1 ( g ) destination ( content ( α ) ) = # Dst1 , referent ( # Dst1 ) =Box1 α represents the entire content of ( 5.1 ) .</sentence>
				<definiendum id="0">referent</definiendum>
				<definiens id="0">the entire content of ( 5.1 )</definiens>
			</definition>
			<definition id="7">
				<sentence>“Request” is the name of a speech act type and “Move” is that of fundamental action respectively .</sentence>
				<definiendum id="0">“Request”</definiendum>
				<definiendum id="1">“Move”</definiendum>
				<definiens id="0">the name of a speech act type and</definiens>
			</definition>
			<definition id="8">
				<sentence>U and V represents dialogue participants and “Ball1” represents an entity in the world .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">dialogue participants and “Ball1” represents an entity in the world</definiens>
			</definition>
			<definition id="9">
				<sentence>Walk ( # Agt1 , # Dst1 ) , Grasp ( # Agt1 , # Obj1 ) , ... The first Walk is a prerequisite action for Grasp and # Dst1 depends on # Obj1 .</sentence>
				<definiendum id="0">Walk</definiendum>
				<definiens id="0">a prerequisite action for Grasp and # Dst1 depends on # Obj1</definiens>
			</definition>
			<definition id="10">
				<sentence>However , the evidence for “where is the intended position ( # Dst ) ” will require the action to be completed .</sentence>
				<definiendum id="0">“where</definiendum>
				<definiens id="0">the intended position ( # Dst ) ” will require the action to be completed</definiens>
			</definition>
			<definition id="11">
				<sentence>&lt; V takes a white ball &gt; ( 14.3 ) U : Put it on the ( red ) table .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">takes a white ball &gt; ( 14.3 ) U : Put it on the ( red ) table</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>The Probabilistic Latent Semantic Analysis model ( PLSA ) ( Hofmann , 1999 ) provides a probabilistic framework that attempts to capture polysemy and synonymy in text for applications such as retrieval and segmentation .</sentence>
				<definiendum id="0">Probabilistic Latent Semantic Analysis model</definiendum>
				<definiendum id="1">PLSA )</definiendum>
				<definiens id="0">provides a probabilistic framework that attempts to capture polysemy and synonymy in text for applications such as retrieval and segmentation</definiens>
			</definition>
			<definition id="1">
				<sentence>The PLSA model computes the relevant probability distributions by selecting the model parameter values that maximize the probability of the observed data , i.e. , the likelihood function .</sentence>
				<definiendum id="0">PLSA model</definiendum>
				<definiens id="0">computes the relevant probability distributions by selecting the model parameter values that maximize the probability of the observed data</definiens>
			</definition>
			<definition id="2">
				<sentence>LSA is based on singular value decomposition ( SVD ) of a term by document matrix and retaining the top K singular values , mapping documents and terms to a new representation in a latent semantic space .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">based on singular value decomposition ( SVD ) of a term by document matrix and retaining the top K singular values , mapping documents and terms to a new representation in a latent semantic space</definiens>
			</definition>
			<definition id="3">
				<sentence>As noted in Hofmann ( 1999 ) , an important difference between PLSA and LSA is the type of objective function utilized .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">the type of objective function utilized</definiens>
			</definition>
			<definition id="4">
				<sentence>LSA represents terms and documents in a new vector space with smaller dimensions that minimize the distance between the projected terms and the original terms .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">represents terms and documents in a new vector space with smaller dimensions that minimize the distance between the projected terms and the original terms</definiens>
			</definition>
			<definition id="5">
				<sentence>This is done through the truncated ( to rank a0 ) singular value decomposition a1 a4 a1a6a5 a2a8a7a9a5a11a10a12a5a14a13a16a15a17 or explicitly a1a18a5 a2 a18a20a19 a22 a10a11a10a11a10 a19a21a5 a26 a4a5 a6 a22 a9 ... a22 a17 a14a16a15 a17 a4a5 a6 a23 a22 ... a23 a5 a14a16a15 a17a25a24 ( 2 ) Among all a32a27a26 a33 matrices of rank a0 , a1a6a5 is the one that minimizes the Frobenius norm a28a29a28a1a31a30 a1a32a5 a28a29a28a33a34 a24 The LSA model based on SVD is a dimensionality reduction algorithm and as such does not have a probabilistic interpretation .</sentence>
				<definiendum id="0">a1a6a5</definiendum>
				<definiendum id="1">SVD</definiendum>
				<definiens id="0">a dimensionality reduction algorithm and as such does not have a probabilistic interpretation</definiens>
			</definition>
			<definition id="6">
				<sentence>The E-step is given by a39 a18 a72a73a28 a71 a36 a74 a26 a2 a39 a18 a72 a26 a39 a18 a71 a28a72 a26 a39 a18 a74a75a28a72 a26 a88 a78a53a89 a39 a18 a72a14a90 a26 a39 a18 a71 a28a72a37a90 a26 a39 a18 a74a75a28a72a14a90 a26 ( 9 ) and the M-step is given by a39 a18 a74a76a28a72 a26 a2 a88 a81 a33 a18 a71 a36 a74 a26 a39 a18 a72a73a28 a71 a36 a74 a26 a88 a81 a91 a83 a89 a33 a18 a71 a36 a74a92a90 a26 a39 a18 a72a73a28 a71 a36 a74a92a90 a26 ( 10 ) a39 a18 a71 a28a72 a26 a2 a88 a83 a33 a18 a71 a36 a74 a26 a39 a18 a72a73a28 a71 a36 a74 a26 a88 a81 a89 a91 a83 a33 a18 a71 a90 a36 a74 a26 a39 a18 a72a73a28 a71 a90 a36 a74 a26 ( 11 ) a39 a18 a72 a26 a2 a88 a81 a91 a83 a33 a18 a71 a36 a74 a26 a39 a18 a72a93a28 a71 a36 a74 a26 a88 a81 a91 a83 a33 a18 a71 a36 a74 a26 a24 ( 12 ) An important consideration in PLSA modeling is that the performance of the model is strongly affected by the initialization of the model prior to training .</sentence>
				<definiendum id="0">E-step</definiendum>
				<definiens id="0">a39 a18 a71 a28a72 a26 a2 a88 a83 a33 a18 a71 a36 a74 a26 a39 a18 a72a73a28 a71 a36 a74 a26 a88 a81 a89 a91 a83 a33 a18 a71 a90 a36 a74 a26 a39 a18 a72a73a28 a71 a90 a36 a74 a26 ( 11 ) a39 a18 a72 a26 a2 a88 a81 a91 a83 a33 a18 a71 a36 a74 a26 a39 a18 a72a93a28 a71 a36 a74 a26 a88 a81 a91 a83 a33 a18 a71 a36 a74 a26 a24 ( 12 ) An important consideration in PLSA modeling is that the performance of the model is strongly affected by the initialization of the model prior to training</definiens>
			</definition>
			<definition id="7">
				<sentence>In addition to LSA-based initialization of the PLSA model , we also investigated initializing the PLSA model by first running the “k-means” algorithm to cluster the documents into a0 classes , where a0 is the number of latent classes and then initializing a39 a18 a74a75a28 a72 a26 based on the statistics of word occurrences in each cluster .</sentence>
				<definiendum id="0">a0</definiendum>
				<definiens id="0">a72 a26 based on the statistics of word occurrences in each cluster</definiens>
			</definition>
</paper>

		<paper id="1050">
			<definition id="0">
				<sentence>Word clusters are a way of coping with data sparseness by abstracting a given word to a class of related words .</sentence>
				<definiendum id="0">Word clusters</definiendum>
				<definiens id="0">a way of coping with data sparseness by abstracting a given word to a class of related words</definiens>
			</definition>
			<definition id="1">
				<sentence>Clusters , as used by our probabilistic answer typing system , play a role similar to that of named entity types .</sentence>
				<definiendum id="0">Clusters</definiendum>
				<definiens id="0">used by our probabilistic answer typing system</definiens>
			</definition>
			<definition id="2">
				<sentence>We used the Clustering By Committee ( CBC ) 394 Table 1 : Words and their clusters Word Clusters suite software , network , wireless , ... rooms , bathrooms , restrooms , ... meeting room , conference room , ... ghost rabbit , squirrel , duck , elephant , frog , ... goblins , ghosts , vampires , ghouls , ... punk , reggae , folk , pop , hip-pop , ... huge , larger , vast , significant , ... coming-of-age , true-life , ... clouds , cloud , fog , haze , mist , ... algorithm ( Pantel and Lin , 2002 ) on a 10 GB English text corpus to obtain 3607 clusters .</sentence>
				<definiendum id="0">pop</definiendum>
				<definiens id="0">Words and their clusters Word Clusters suite software , network , wireless , ... rooms , bathrooms , restrooms , ... meeting room , conference room , ... ghost rabbit , squirrel , duck , elephant , frog , ... goblins , ghosts , vampires , ghouls</definiens>
			</definition>
			<definition id="3">
				<sentence>Minipar generates the trace to indicate that the word what is the object of visit in the deep structure of the sentence .</sentence>
				<definiendum id="0">Minipar</definiendum>
				<definiens id="0">generates the trace to indicate that the word what is the object of visit in the deep structure of the sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>The goal of an answer typing model is to evaluate the appropriateness of a candidate word as an answer to the question .</sentence>
				<definiendum id="0">goal of an answer typing model</definiendum>
				<definiens id="0">to evaluate the appropriateness of a candidate word as an answer to the question</definiens>
			</definition>
			<definition id="5">
				<sentence>When ΓQ consists of multiple contexts , we make the na¨ıve Bayes assumption that each individual context γQ ∈ ΓQ is independent of all other contexts given the cluster C. P ( in ( w , ΓQ ) |w ) ≈ X C P ( C|w ) Y γQ∈ΓQ P ( in ( C , γQ ) |C ) ( 5 ) Equation ( 5 ) needs the parameters P ( C|w ) and P ( in ( C , γQ ) |C ) , neither of which are directly available from the context-filler database .</sentence>
				<definiendum id="0">ΓQ</definiendum>
				<definiens id="0">consists of multiple contexts , we make the na¨ıve Bayes assumption that each individual context γQ ∈ ΓQ is independent of all other contexts given the cluster C. P ( in ( w</definiens>
			</definition>
			<definition id="6">
				<sentence>To take intoaccountaword’scontext , wecaninsteadcomputeP ( in ( w , ΓQ ) |w , in ( w , Γw ) ) , whereΓw is the set of contexts for the candidate word w in a retrieved passage .</sentence>
				<definiendum id="0">wecaninsteadcomputeP</definiendum>
				<definiens id="0">the set of contexts for the candidate word w in a retrieved passage</definiens>
			</definition>
			<definition id="7">
				<sentence>It can be estimated by : P ( C|w , in ( w , Γw ) ) = P ( in ( w , Γw ) |w , C ) P ( w , C ) P ( in ( w , Γ w ) |w ) P ( w ) ( 8 ) ≈ Y γw∈Γw P ( in ( w , γw ) |w , C ) Y γw∈Γw P ( in ( w , γw ) |w ) ×P ( C|w ) ( 9 ) = Y γw∈Γw „P ( C|w , in ( w , γ w ) ) P ( C|w ) « ×P ( C|w ) ( 10 ) Our probabilistic model requires the parameters P ( C|w ) , P ( C|w , in ( w , γ ) ) , and P ( in ( C , γ ) |C ) , wherew isaword , C isaclusterthatw belongsto , and γ is a question or candidate context .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">γ</definiendum>
				<definiens id="0">a question or candidate context</definiens>
			</definition>
			<definition id="8">
				<sentence>P ( in ( w , γ ) |w ) = |in ( w , γ ) |+P ( in ( ∗ , γ ) ) |in ( w , ∗ ) |+1 ( 11 ) Pu ( C|w ) = ( 1 | { Cprime|w∈Cprime } | if w ∈ C , 0 otherwise ( 12 ) P ( C|w ) = X wprime∈S ( w ) sim ( w , wprime ) ×Pu ( C|wprime ) X { Cprime|w∈Cprime } , wprime∈S ( w ) sim ( w , wprime ) ×Pu ( Cprime|wprime ) ( 13 ) P ( in ( C , γ ) |C ) =X wprime∈C P ( C|wprime ) ×|in ( wprime , γ ) |+P ( in ( ∗ , γ ) ) X wprime∈C P ( C|wprime ) ×|in ( wprime , ∗ ) |+1 ( 14 ) Figure 2 : Probability estimation We use the average weighted “guesses” of the top similar words of w to compute P ( C|w ) ( see equation 13 ) .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
			<definition id="9">
				<sentence>The evaluation data consist of 154 questions from the TREC-2003 QA Track ( Voorhees , 2003 ) satisfyingthefollowingcriteria , alongwiththetop 10 documents returned for each question as identified by NIST using the PRISE1 search engine .</sentence>
				<definiendum id="0">evaluation data</definiendum>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>Opinion mining is a recent subdiscipline of computational linguistics which is concerned not with the topic a document is about , but with the opinion it expresses .</sentence>
				<definiendum id="0">Opinion mining</definiendum>
				<definiens id="0">a recent subdiscipline of computational linguistics which is concerned not with the topic a document is about , but with the opinion it expresses</definiens>
			</definition>
			<definition id="1">
				<sentence>Opinion mining is a recent subdiscipline of computational linguistics which is concerned not with the topic a document is about , but with the opinion it expresses .</sentence>
				<definiendum id="0">Opinion mining</definiendum>
				<definiens id="0">a recent subdiscipline of computational linguistics which is concerned not with the topic a document is about , but with the opinion it expresses</definiens>
			</definition>
			<definition id="2">
				<sentence>Feature selection is implemented by scoring each feature fk ( i.e. each term that occurs in the glosses of at least one training term ) by means of the mutual information ( MI ) function , defined as MI ( fk ) = summationdisplay c∈ { c1 , ... , cm } , f∈ { fk , fk } Pr ( f , c ) · log Pr ( f , c ) Pr ( f ) Pr ( c ) ( 1 ) and discarding the x % features fk that minimize it .</sentence>
				<definiendum id="0">Feature selection</definiendum>
				<definiens id="0">scoring each feature fk ( i.e. each term that occurs in the glosses of at least one training term ) by means of the mutual information</definiens>
				<definiens id="1">... , cm } , f∈ { fk , fk } Pr ( f , c ) · log Pr ( f , c ) Pr ( f ) Pr ( c ) ( 1 ) and discarding the x % features fk that minimize it</definiens>
			</definition>
			<definition id="3">
				<sentence>Since the task we aim to solve is manifold , we will evaluate our classifiers according to two evaluation measures : • SO-accuracy , i.e. the accuracy of a classifier inseparating SubjectivefromObjective , i.e. in deciding term subjectivity alone ; • PNO-accuracy , the accuracy of a classifier in discriminating among Positive , Negative , 9The naive Bayesian , Rocchio , and PrTFIDF learners we have used are from Andrew McCallum’s Bow package ( http : //www-2.cs.cmu.edu/˜mccallum/bow/ ) , while the SVMs learner we have used is Thorsten Joachims’ SV Mlight ( http : //svmlight.joachims.org/ ) , version 6.01 .</sentence>
				<definiendum id="0">PrTFIDF</definiendum>
				<definiens id="0">deciding term subjectivity alone ; • PNO-accuracy , the accuracy of a classifier in discriminating among Positive , Negative , 9The naive Bayesian , Rocchio , and</definiens>
			</definition>
			<definition id="4">
				<sentence>An interesting observation on the learners we have used is that NB , PrTFIDF and SVMs , unlike Rocchio , generate classifiers that depend on P ( ci ) , the prior probabilities of the classes , which are normally estimated as the proportion of training documents that belong to ci .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">generate classifiers that depend on P ( ci ) , the prior probabilities of the classes , which are normally estimated as the proportion of training documents that belong to ci</definiens>
			</definition>
</paper>

		<paper id="2018">
			<definition id="0">
				<sentence>Word sense induction and disambiguation is of importance for many tasks in speech and language processing , such as speech recognition , machine translation , natural language understanding , question answering , and information retrieval .</sentence>
				<definiendum id="0">disambiguation</definiendum>
				<definiens id="0">of importance for many tasks in speech and language processing , such as speech recognition , machine translation , natural language understanding , question answering , and information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>Another resource that we use is the British National Corpus ( BNC ) , which is a balanced sample of written and spoken English that comprises about 100 million words ( Burnard &amp; Aston , 1998 ) .</sentence>
				<definiendum id="0">National Corpus ( BNC )</definiendum>
				<definiens id="0">a balanced sample of written and spoken English that comprises about 100 million words</definiens>
			</definition>
</paper>

		<paper id="2029">
			<definition id="0">
				<sentence>Most question answering ( QA ) and information retrieval ( IR ) systems are insensitive to different users’ needs and preferences , and also to the existence of multiple , complex or controversial answers .</sentence>
				<definiendum id="0">question answering</definiendum>
				<definiendum id="1">information retrieval</definiendum>
				<definiendum id="2">IR</definiendum>
				<definiens id="0">insensitive to different users’ needs and preferences , and also to the existence of multiple , complex or controversial answers</definiens>
			</definition>
			<definition id="1">
				<sentence>While standard information retrieval ( IR ) systems present the results of a query in the form of a ranked list of relevant documents , question answering ( QA ) systems attempt to return them in the form of sentences ( or paragraphs , or phrases ) , responding more precisely to the user’s request .</sentence>
				<definiendum id="0">IR</definiendum>
				<definiendum id="1">question answering</definiendum>
				<definiens id="0">systems attempt to return them in the form of sentences ( or paragraphs , or phrases</definiens>
			</definition>
			<definition id="2">
				<sentence>As our current application , YourQA2 , isalearning-oriented , webbased system , our UM consists of the user’s : 1 ) age range , a ∈ { 7 − 11,11 − 16 , adult } ; 2 ) reading level , r ∈ { poor , medium , good } ; 3 ) webpages of interest/bookmarks , w. Analogies can be found with the SeAn ( Ardissono et al. , 2001 ) and SiteIF ( Magnini and Strapparava , 2001 ) news recommender systems where age and browsing history , respectively , are part of the UM .</sentence>
				<definiendum id="0">UM</definiendum>
				<definiendum id="1">SiteIF</definiendum>
				<definiens id="0">consists of the user’s : 1 ) age range , a ∈ { 7 − 11,11 − 16 , adult } ; 2 ) reading level , r ∈ { poor , medium , good } ; 3 ) webpages of interest/bookmarks , w. Analogies can be found with the SeAn ( Ardissono et al. , 2001</definiens>
			</definition>
			<definition id="3">
				<sentence>The dialogue manager consults the UM to decide on the most suitable formulation of the answer ( e.g. short sentences ) and produce the final answer accordingly , e.g. : —System : RoaldDahlwrotemanybooksforkidsandadults , including : “The Witches” , “Charlie and the Chocolate Factory” , and “James and the Giant Peach '' .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiendum id="1">“James</definiendum>
				<definiens id="0">consults the UM to decide on the most suitable formulation of the answer ( e.g. short sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>Moreover , each clus5The likelihood is estimated using the formula : Li , D = summationtextw∈D C ( w , D ) · log ( P ( w|lmi ) ) , where w is a word in the document , C ( w , d ) is the number of occurrences of w in D and P ( w|lmi ) is the probability with which w occurs in lmi 6However , if their number does not exceed a given threshold , we accept in our candidate set part of the documents havingthenextlowestreadability–oramediumreadabilityifthe user’s reading level is low ter is assigned a score consisting in the maximal score of the documents composing it .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">a word in the document</definiens>
				<definiens id="1">the number of occurrences of w in D and P ( w|lmi ) is the probability with which w occurs in lmi</definiens>
				<definiens id="2">low ter is assigned a score consisting in the maximal score of the documents composing it</definiens>
			</definition>
			<definition id="5">
				<sentence>Webaseourevaluationon ( Su,2003 ) , which proposes a comprehensive search engine evaluation model , defining the following metrics : the ratio between the number of results rated as relevant and all the returned results , and loose pre201 cision ( P2 ) as the ratio between the number of results rated as relevant or partially relevant and all the returned results .</sentence>
				<definiendum id="0">Webaseourevaluationon</definiendum>
				<definiens id="0">proposes a comprehensive search engine evaluation model , defining the following metrics : the ratio between the number of results rated as relevant and all the returned results</definiens>
				<definiens id="1">the ratio between the number of results rated as relevant or partially relevant and all the returned results</definiens>
			</definition>
</paper>

		<paper id="1042">
			<definition id="0">
				<sentence>TroFi uses sentential context instead of selectional constraint violations or paths in semantic hierarchies .</sentence>
				<definiendum id="0">TroFi</definiendum>
				<definiens id="0">uses sentential context instead of selectional constraint violations or paths in semantic hierarchies</definiens>
			</definition>
			<definition id="1">
				<sentence>Like CorMet , TroFi uses contextual evidence taken from a large corpus and alsousesWordNetasaprimaryknowledge source , but unlike CorMet , TroFi does not use selectional preferences .</sentence>
				<definiendum id="0">TroFi</definiendum>
				<definiens id="0">uses contextual evidence taken from a large corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>The target set consists of sentences from the corpus containing the target word .</sentence>
				<definiendum id="0">target set</definiendum>
				<definiens id="0">consists of sentences from the corpus containing the target word</definiens>
			</definition>
			<definition id="3">
				<sentence>SuperTags ( Bangalore &amp; Joshi , 1999 ) encode a great deal of syntactic information in a single tag ( each tag is an elementary tree from the XTAG English Tree Adjoining Grammar ) .</sentence>
				<definiendum id="0">SuperTags</definiendum>
			</definition>
			<definition id="4">
				<sentence>We devised a SuperTag trigram composed of the SuperTag of the target word and the following two words and their SuperTags if they contain nouns , prepositions , particles , or adverbs .</sentence>
				<definiendum id="0">SuperTags</definiendum>
				<definiens id="0">if they contain nouns , prepositions , particles , or adverbs</definiens>
			</definition>
			<definition id="5">
				<sentence>A final enhancement involves extending the context to help with disambiguation .</sentence>
				<definiendum id="0">final enhancement</definiendum>
			</definition>
			<definition id="6">
				<sentence>κ ( Cohen ) and κ ( S &amp; C ) on a random sample of 200 annotated examples annotated by two different annotators was found to be 0.77 .</sentence>
				<definiendum id="0">κ</definiendum>
			</definition>
			<definition id="7">
				<sentence>Average precision is the average of literal and nonliteral precision ; similarly for average recall .</sentence>
				<definiendum id="0">Average precision</definiendum>
				<definiens id="0">the average of literal and nonliteral precision</definiens>
			</definition>
			<definition id="8">
				<sentence>In this paper we presented TroFi , a system for separating literal and nonliteral usages of verbs through statistical word-sense disambiguation and clustering techniques .</sentence>
				<definiendum id="0">TroFi</definiendum>
				<definiens id="0">a system for separating literal and nonliteral usages of verbs through statistical word-sense disambiguation and clustering techniques</definiens>
			</definition>
</paper>

		<paper id="2014">
			<definition id="0">
				<sentence>USAS-EST is a software system for automatic semantic analysis of text that was designed at Lancaster University ( Rayson et al. , 2004 ) .</sentence>
				<definiendum id="0">USAS-EST</definiendum>
			</definition>
</paper>

		<paper id="1005">
</paper>

		<paper id="1047">
			<definition id="0">
				<sentence>The Arabic language is a collection of spoken dialects with important phonological , morphological , lexical , and syntactic differences , along with a standard written language , Modern Standard Arabic ( MSA ) .</sentence>
				<definiendum id="0">Arabic language</definiendum>
			</definition>
			<definition id="1">
				<sentence>MSA is based on Classical Arabic and is not a native language ofanyArabic speaking people , i.e. , children do not learn it from their parents but in school .</sentence>
				<definiendum id="0">MSA</definiendum>
				<definiens id="0">a native language ofanyArabic speaking people , i.e. , children do not learn it from their parents but in school</definiens>
			</definition>
			<definition id="2">
				<sentence>We then proceed to discuss three approaches : sentence transduction , in which the LA sentence to be parsed is turned into an MSA sentence and then parsed with an MSA parser ( Section 5 ) ; treebank transduction , in which the MSA treebank is turned into anLAtreebank ( Section 6 ) ; and grammar transduction , in which an MSA grammar is turned into an LA grammar which is then used for parsing LA ( Section 7 ) .</sentence>
				<definiendum id="0">MSA parser</definiendum>
				<definiendum id="1">treebank transduction</definiendum>
				<definiendum id="2">grammar transduction</definiendum>
				<definiendum id="3">LA grammar</definiendum>
				<definiens id="0">sentence transduction , in which the LA sentence to be parsed is turned into an MSA sentence and then parsed with an</definiens>
			</definition>
			<definition id="3">
				<sentence>The Levantine treebank LATB ( Maamouri et al. , 2006 ) comprises 33,000 words of treebanked conversational telephone transcripts collected as part of the LDC CALL HOME project .</sentence>
				<definiendum id="0">Levantine treebank LATB</definiendum>
				<definiens id="0">comprises 33,000 words of treebanked conversational telephone transcripts collected as part of the LDC CALL HOME project</definiens>
			</definition>
			<definition id="4">
				<sentence>InTable2 , wereport theF-Measure score onthe test set ( TEST ) for the baseline and for SLXUN ( with and without gold POS tags ) .</sentence>
				<definiendum id="0">TEST</definiendum>
				<definiens id="0">with and without gold POS tags )</definiens>
			</definition>
			<definition id="5">
				<sentence>Sentence Splitting ( TOPS ) : A fair number of sentences in the ATB has a root node S with several embedded direct descendant S nodes , sometimes conjoined using the conjunction w. We split such sentences into several shorter sentences .</sentence>
				<definiendum id="0">TOPS )</definiendum>
				<definiens id="0">A fair number of sentences in the ATB has a root node S with several embedded direct descendant S nodes , sometimes conjoined using the conjunction w. We split such sentences into several shorter sentences</definiens>
			</definition>
			<definition id="6">
				<sentence>VSO-SVO Ordering ( SVO ) : Both Verb Subject Object ( VSO ) and Subject Verb Object ( SVO ) constructions occur in MSA and LA treebanks .</sentence>
				<definiendum id="0">VSO-SVO Ordering</definiendum>
				<definiendum id="1">SVO )</definiendum>
			</definition>
			<definition id="7">
				<sentence>But pure VSO constructions – where there is no pro-drop – occur in the LA corpus only 10 % of the data , while VSO is the most frequent ordering in MSA .</sentence>
				<definiendum id="0">VSO</definiendum>
				<definiens id="0">the most frequent ordering in MSA</definiens>
			</definition>
			<definition id="8">
				<sentence>A tree-substitution grammar is a set of elementary trees .</sentence>
				<definiendum id="0">tree-substitution grammar</definiendum>
			</definition>
			<definition id="9">
				<sentence>A derivation starts with an elementary tree and proceeds by a series of composition operations .</sentence>
				<definiendum id="0">derivation</definiendum>
				<definiens id="0">starts with an elementary tree and proceeds by a series of composition operations</definiens>
			</definition>
			<definition id="10">
				<sentence>A synchronous TSG is a set of pairs of elementary trees .</sentence>
				<definiendum id="0">synchronous TSG</definiendum>
			</definition>
			<definition id="11">
				<sentence>The synchronoussubstitution probabilities can then be estimated as : P ( α , αprime | η , ηprime ) ≈ P ( α | η ) P ( αprime | α ) ≈ P ( α | η ) P ( wprime , tprime | w , t ) P ( ¯αprime | ¯α , wprime , tprime , w , t ) where w and t are the lexical anchor of α and its POS tag , and ¯α is the equivalence class of α modulo lexical anchors and their POS tags .</sentence>
				<definiendum id="0">¯α</definiendum>
				<definiens id="0">P ( α , αprime | η , ηprime ) ≈ P ( α | η ) P ( αprime | α ) ≈ P ( α | η ) P ( wprime , tprime | w , t ) P ( ¯αprime | ¯α , wprime , tprime , w , t ) where w</definiens>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>N , A , Z and C respectively correspond to nouns , adjectives , latent clusters and semantic orientations .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">correspond to nouns , adjectives , latent clusters and semantic orientations</definiens>
			</definition>
			<definition id="1">
				<sentence>N , A , Z and C respectively correspond to nouns , adjectives , latent clusters and semantic orientations .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">correspond to nouns , adjectives , latent clusters and semantic orientations</definiens>
			</definition>
			<definition id="2">
				<sentence>Figure 1- ( c ) is , what we call , the 3-PLSI model , which is the 3observable variable version of the PLSI .</sentence>
				<definiendum id="0">3-PLSI model</definiendum>
				<definiens id="0">the 3observable variable version of the PLSI</definiens>
			</definition>
			<definition id="3">
				<sentence>The Q-function ( i.e. , the expected log-likelihood of the joint probability of complete data with respect to the conditional posterior of the latent variable ) is expressed as : Q ( θ ) = summationdisplay nac fnac summationdisplay z ¯P ( z|nac ) logP ( nazc|θ ) , ( 3 ) where θ denotes the set of the new parameters .</sentence>
				<definiendum id="0">Q-function</definiendum>
				<definiendum id="1">¯P</definiendum>
				<definiens id="0">the expected log-likelihood of the joint probability of complete data with respect to the conditional posterior of the latent variable ) is expressed as : Q ( θ ) = summationdisplay nac fnac summationdisplay z</definiens>
				<definiens id="1">the set of the new parameters</definiens>
			</definition>
			<definition id="4">
				<sentence>In addition to the latent models , we test a baseline classifier , which uses the posterior probability : P ( c|na ) ∝ P ( n|c ) P ( a|c ) P ( c ) .</sentence>
				<definiendum id="0">baseline classifier</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">uses the posterior probability : P ( c|na ) ∝</definiens>
			</definition>
			<definition id="5">
				<sentence>The tempered EM can be realized by a slight modification to the E-step , which results in a new E-step : ¯P ( z|nac ) = parenleftbigP ( c|az ) P ( z|n ) parenrightbigβ summationtext z parenleftbigP ( c|az ) P ( z|n ) parenrightbigβ , ( 18 ) for the U-shaped model , where β is a positive hyper-parameter , called the inverse temperature .</sentence>
				<definiendum id="0">β</definiendum>
				<definiens id="0">a positive hyper-parameter , called the inverse temperature</definiens>
			</definition>
</paper>

		<paper id="2002">
			<definition id="0">
				<sentence>By introducing the hidden word alignment variable a , the following approximate optimization criterion can be applied for that purpose : e∗ = argmaxe Pr ( e | f ) = argmaxe summationdisplay a Pr ( e , a | f ) ≈ argmaxe , a Pr ( e , a | f ) Exploiting the maximum entropy ( Berger et al. , 1996 ) framework , the conditional distribution Pr ( e , a | f ) can be determined through suitable real valued functions ( called features ) hr ( e , f , a ) , r = 1 ... R , and takes the parametric form : pλ ( e , a | f ) ∝ exp { Rsummationdisplay r=1 λrhr ( e , f , a ) } The ITC-irst system ( Chen et al. , 2005 ) is based on a log-linear model which extends the original IBM Model 4 ( Brown et al. , 1993 ) to phrases ( Koehn et al. , 2003 ; Federico and Bertoldi , 2005 ) .</sentence>
				<definiendum id="0">ITC-irst system</definiendum>
				<definiens id="0">extends the original IBM Model 4 ( Brown et al. , 1993 ) to phrases</definiens>
			</definition>
			<definition id="1">
				<sentence>BTEC is a multilingual speech corpus which contains sentences coming from phrase books for tourists .</sentence>
				<definiendum id="0">BTEC</definiendum>
				<definiens id="0">a multilingual speech corpus which contains sentences coming from phrase books for tourists</definiens>
			</definition>
			<definition id="2">
				<sentence>Spanish-to-English ( European Parliament ) The Spanish-to-English system has been trained with the data provided by the Evaluation Campaign 2005 of the European integrated project TCSTAR4 .</sentence>
				<definiendum id="0">Spanish-to-English ( European Parliament</definiendum>
				<definiens id="0">Spanish-to-English system has been trained with the data provided by the Evaluation Campaign 2005 of the European integrated project TCSTAR4</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>In its most basic conception , a CCG over alphabet Σ of terminal symbols is an ordered triple 〈A , S , L〉 , whereAis an alphabet of saturated category symbols , S is a distinguished element ofA , and L is a lexicon , i.e. a mapping from Σ to categories overA .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">L</definiendum>
				<definiens id="0">a distinguished element ofA , and</definiens>
				<definiens id="1">a lexicon</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , assuming the saturated category symbols ‘S’ and ‘NP’ , here is a simple CCG lexicon ( modalities omitted ) : John turnstileleft NP ( 1 ) Mary turnstileleft NP loves turnstileleft ( S\NP ) /NP The combinatory projection of a CCG lexicon is its closure under a finite set of resource-sensitive combinatory operations such as forward application ( 2 ) , backward application ( 3 ) , forward type raising ( 4 ) , and forward composition ( 5 ) : X/Y Y ⇒ X ( 2 ) Y X\Y ⇒ X ( 3 ) X ⇒ Y/ ( Y\X ) ( 4 ) X/Y Y/Z ⇒ X/Z ( 5 ) CCG 〈A , S , L〉 over alphabet Σ generates string s ∈ Σ∗ just in case 〈s , S〉 is in the combinatory projection of lexicon L. The derivation in Figure 1 shows that CCG ( 1 ) generates the sentence John loves Mary , assuming that ‘S’ is the distinguished symbol , and where &gt; T , &gt; B and &gt; denote instances of forward raising , forward composition and forward application respectively : John loves Mary NP ( S\NP ) /NP NP &gt; TS/ ( S\NP ) &gt; BS/NP &gt; S Figure 1 : A CCG derivation CCG has many advantages both as a theory of human linguistic competence and as a tool for practical natural language processing applications ( Steedman , 2000 ) .</sentence>
				<definiendum id="0">S〉</definiendum>
				<definiens id="0">a simple CCG lexicon ( modalities omitted ) : John turnstileleft NP ( 1 ) Mary turnstileleft NP loves turnstileleft</definiens>
				<definiens id="1">X/Y Y/Z ⇒ X/Z ( 5 ) CCG 〈A , S , L〉 over alphabet Σ generates string s ∈ Σ∗ just in case 〈s</definiens>
			</definition>
			<definition id="2">
				<sentence>I start with a generalisation of the CCG formalism where the alphabet of saturated category symbols is organised into a ‘type hierarchy’ in the sense of Carpenter ( 1992 ) , i.e. a weak order 〈A , subsetsqequalA〉 , where A is an alphabet of types , subsetsqequalA is the ‘subsumption’ ordering onA ( with a least element ) , and every subset ofAwith an upper bound has a least upper bound .</sentence>
				<definiendum id="0">subsetsqequalA</definiendum>
				<definiens id="0">the ‘subsumption’ ordering onA ( with a least element</definiens>
			</definition>
			<definition id="3">
				<sentence>NPsgsbj NPplsbj NPsgobj NPplobj a81a81 a81 a81a81 a81 a80a80a80 a80a80a80 a16a16a16 a16a16a16 a16a16a16 a16a16a16 NPsbj NPobj NPsg NPpl Nsg Npl a35a35 a35 a76a76 a72a72 a72a72 a80a80a80 a80a80a80a80 a4a4 a12a12 a80a80a80a80a80a80 a72a72a72a72 a0a0 NP Nomsg Nompl N a16a16a16 a16a16a16 a0a0 a64a64 a80a80a80 a80a80a80 NomSa33 a33a33a33 a80a80a80a80 top Figure 2 : Type hierarchy of saturated categories A type-hierarchical CCG ( T-CCG ) over alphabet Σ is an ordered 4-tuple 〈A , subsetsqequalA , S , L〉 , where 1http : //openccg.sourceforge.net 〈A , subsetsqequalA〉 is a type hierarchy of saturated category symbols , S is a distinguished element of A , and lexicon L is a mapping from Σ to categories over A. Given an appropriate subsetsqequalA-compatibility relation on the categories over A , the combinatory projection of T-CCG 〈A , subsetsqequalA , S , L〉 can again be defined as the closure of L under the CCG combinatory operations , assuming that variable Y in the type raising rule ( 4 ) is restricted to maximally specified categories .</sentence>
				<definiendum id="0">subsetsqequalA〉</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">lexicon L</definiendum>
				<definiens id="0">NPsgsbj NPplsbj NPsgobj NPplobj a81a81 a81 a81a81 a81 a80a80a80 a80a80a80 a16a16a16 a16a16a16 a16a16a16 a16a16a16 NPsbj NPobj NPsg NPpl Nsg Npl a35a35 a35 a76a76 a72a72 a72a72 a80a80a80 a80a80a80a80 a4a4 a12a12 a80a80a80a80a80a80 a72a72a72a72 a0a0 NP Nomsg Nompl N a16a16a16 a16a16a16 a0a0 a64a64 a80a80a80 a80a80a80 NomSa33 a33a33a33 a80a80a80a80 top Figure 2 : Type hierarchy of saturated categories A type-hierarchical CCG ( T-CCG ) over alphabet Σ is an ordered 4-tuple 〈A , subsetsqequalA , S , L〉 , where 1http : //openccg.sourceforge.net 〈A</definiens>
				<definiens id="1">a type hierarchy of saturated category symbols ,</definiens>
				<definiens id="2">a distinguished element of A , and</definiens>
				<definiens id="3">a mapping from Σ to categories over A. Given an appropriate subsetsqequalA-compatibility relation on the categories over A , the combinatory projection of T-CCG 〈A</definiens>
			</definition>
			<definition id="4">
				<sentence>The set of simple category descriptions over alphabetAof saturated category symbols is defined as the smallest set Φ such that : Note that category descriptions may be infinitely embedded , in which case they are considered to be right-associative , e.g. RES ARG RES SLASH f. A simple category description like ( SLASH f ) or ( SLASH b ) denotes the set of all expressions which seek their argument to the right/left .</sentence>
				<definiendum id="0">simple category descriptions over alphabetAof saturated category symbols</definiendum>
				<definiens id="0">the smallest set Φ such that : Note that category descriptions may be infinitely embedded , in which case they are considered to be right-associative , e.g. RES ARG RES SLASH f. A simple category description like ( SLASH f ) or ( SLASH b ) denotes the set of all expressions which seek their argument to the right/left</definiens>
			</definition>
			<definition id="5">
				<sentence>A description of the form ( ARGφ ) denotes the set of expressions which take an argument of category φ , and one like ( RES φ ) denotes the set of expressions which combine with an argument to yield an expression of categoryφ .</sentence>
				<definiendum id="0">description of the form</definiendum>
				<definiendum id="1">ARGφ )</definiendum>
			</definition>
			<definition id="6">
				<sentence>An inheritance-driven CCG ( I-CCG ) over alphabet Σ is an ordered 7-tuple 〈A , subsetsqequalA , B , subsetsqequalB , b , S , L〉 , where 〈A , subsetsqequalA〉 is a type hierarchy of saturated category symbols , 〈B , subsetsqequalB , b〉 is an inheritance hierarchy of lexical types over the set of categorydescriptionsoverA∪B , Sisadistinguished symbol inA , and lexiconLis a function from Σ to A∪B. Given an appropriate subsetsqequalA , B-compatibility relationonthecategoriesoverA∪B , thecombinatory projection of I-CCG 〈A , subsetsqequalA , B , subsetsqequalB , b , S , L〉 can again be defined as the closure ofLunder the 4 CCG combinatory operations .</sentence>
				<definiendum id="0">inheritance-driven CCG ( I-CCG ) over alphabet Σ</definiendum>
				<definiendum id="1">subsetsqequalA〉</definiendum>
				<definiendum id="2">S , L〉 can again</definiendum>
				<definiens id="0">an ordered 7-tuple 〈A , subsetsqequalA , B , subsetsqequalB , b , S , L〉 , where 〈A</definiens>
				<definiens id="1">a type hierarchy of saturated category symbols , 〈B , subsetsqequalB , b〉 is an inheritance hierarchy of lexical types over the set of categorydescriptionsoverA∪B , Sisadistinguished symbol inA , and lexiconLis a function from Σ to A∪B. Given an appropriate subsetsqequalA , B-compatibility relationonthecategoriesoverA∪B , thecombinatory projection of I-CCG 〈A , subsetsqequalA , B , subsetsqequalB , b ,</definiens>
				<definiens id="2">the closure ofLunder the 4 CCG combinatory operations</definiens>
			</definition>
</paper>

	</volume>
