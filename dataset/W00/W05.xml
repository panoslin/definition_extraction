<?xml version="1.0" encoding="UTF-8"?>
	<volume id="W05">

		<paper id="1001">
			<definition id="0">
				<sentence>For example , in the second sentence in Figure 1 , 學校 ( school ) is the headword in the constituent corresponding to the agent of the verb 舉行 ( hold ) , and 比賽 ( contest ) is the headword of the noun phrase corresponding to the patient .</sentence>
				<definiendum id="0">比賽 ( contest )</definiendum>
				<definiens id="0">the headword of the noun phrase corresponding to the patient</definiens>
			</definition>
			<definition id="1">
				<sentence>Position ( posit ) : This feature shows whether the constituent being labelled appears before or after the target verb .</sentence>
				<definiendum id="0">Position ( posit )</definiendum>
				<definiens id="0">This feature shows whether the constituent being labelled appears before or after the target verb</definiens>
			</definition>
</paper>

		<paper id="1204">
			<definition id="0">
				<sentence>Furthermore , when the sentence “Exp_A 2 ” in language A is translated into the sentences “Exp_B 1 , Exp_B n+1 , ... , Exp_B m ” in language B , “Exp_B 1 , Exp_B n+1 , ... , Exp_B m ( n &lt; m ) ” form one synonymous group .</sentence>
				<definiendum id="0">Exp_B</definiendum>
				<definiendum id="1">, Exp_B m</definiendum>
				<definiens id="0">n+1 , ... , Exp_B m ” in language B , “Exp_B 1 , Exp_B n+1 , ...</definiens>
			</definition>
			<definition id="1">
				<sentence>The right-hand side box shows a part of the modified training corpus .</sentence>
				<definiendum id="0">right-hand side box</definiendum>
				<definiens id="0">shows a part of the modified training corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>The SMT systems’ decoder is a graph-based decoder ( Ueffing et al. , 2002 ; Zhang et al. , 2004 ) .</sentence>
				<definiendum id="0">SMT systems’ decoder</definiendum>
			</definition>
			<definition id="3">
				<sentence>For the evaluation , we use BLEU , NIST , WER , and PER as follows : S1⇔T1 S2⇔T1 S1⇔T2 S3⇔T1 ⇒ S1⇔T1 S2⇔T1 S1⇔T1 S3⇔T1 BLEU : A weighted geometric mean of the ngram matches between test and reference sentences multiplied by a brevity penalty that penalizes short translation sentences .</sentence>
				<definiendum id="0">PER</definiendum>
				<definiens id="0">A weighted geometric mean of the ngram matches between test and reference sentences multiplied by a brevity penalty that penalizes short translation sentences</definiens>
			</definition>
</paper>

		<paper id="1202">
			<definition id="0">
				<sentence>Other identified tasks include summarization , paraphrasing , Information Extraction ( IE ) , Information Retrieval ( IR ) and Machine Translation ( MT ) .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">Information Retrieval</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Natural Habitats ( NatHab ) project1 ( Weeds et al. , 2004 ; Owen et al. , 2005 ) provides an interesting setting in which to study paraphrase and tex1http : //www.informatics.susx.ac.uk/projects/nathab/ tual entailment recognition as a tool for natural language understanding .</sentence>
				<definiendum id="0">Natural Habitats</definiendum>
				<definiens id="0">provides an interesting setting in which to study paraphrase</definiens>
				<definiens id="1">//www.informatics.susx.ac.uk/projects/nathab/ tual entailment recognition as a tool for natural language understanding</definiens>
			</definition>
			<definition id="2">
				<sentence>The average word overlap ( i.e. , the proportion of exactly identical word forms ) calculated over the sentences paired by humans in the training set is 0.70 , and the lowest overlap4 for such sentences is 0.3 .</sentence>
				<definiendum id="0">average word overlap</definiendum>
				<definiens id="0">the proportion of exactly identical word forms ) calculated over the sentences paired by humans in the training set</definiens>
			</definition>
			<definition id="3">
				<sentence>The α-skew divergence measure is an approximation to the KullbackLeibler ( KL ) divergence meassure between two distributions p and q : D ( p||q ) = summationdisplay x p ( x ) logp ( x ) q ( x ) 5We currently retain all of the distinctions between grammatical relations output by RASP .</sentence>
				<definiendum id="0">α-skew divergence measure</definiendum>
				<definiens id="0">retain all of the distinctions between grammatical relations output by RASP</definiens>
			</definition>
</paper>

		<paper id="0614">
			<definition id="0">
				<sentence>We develop a small set of production rules in which the left hand side represents a higher order intentional action ( e.g. , “offer drink” ) , and the right hand side represents a sequence of lower level actions that accomplish it ( e.g. “grasp cup” , “move cup” , “release cup” ) .</sentence>
				<definiendum id="0">hand side</definiendum>
				<definiens id="0">a higher order intentional action ( e.g. , “offer drink” ) , and the right</definiens>
			</definition>
			<definition id="1">
				<sentence>5 http : //nwn.bioware.com/ 106 RightClickDoor RightClickFloor RightClickFloor RightClickFloor LeftClickDoor “ok go into the room” “go over to that door” “now open the door” Expert’s utterances : Novice’s actions : RightClickDoor RightClickFloor RightClickFloor RightClickFloor LeftClickDoor MoveThruRoomOpenDoor OpenDoor FindAxe PickUpAxe GetAxe Intention Recognition Action : Get Agent : Player Object : Axe GetAxe - &gt; GoToAxe TakeAxe FindAxe - &gt; Open Move Open OpenDoor - &gt; ClickDoor Behavior Grammar Action : Open Agent : Player Object : Door RightClickDoor RightClickFloor RightClickFloor RightClickFloor LeftClickDoor MoveThruRoomOpenDoor OpenDoor FindAxe PickUpAxe GetAxe Linguistic Mapping “now open the door” P ( words|roles ) Figure 3 .</sentence>
				<definiendum id="0">RightClickDoor RightClickFloor RightClickFloor RightClickFloor LeftClickDoor MoveThruRoomOpenDoor OpenDoor FindAxe PickUpAxe GetAxe Intention Recognition Action</definiendum>
			</definition>
			<definition id="2">
				<sentence>Utterance Action Frame ok this time you are gon na get the axe first MOVE ROOM1 act : GET obj : AXE through the red archway on your right MOVE ROOM2 act : MOVE goal : ARCH manner : THRU now open that door CLICK_ON LEVER act : OPEN obj : DOOR ok now take the axe CLICK_ON CHEST act : TAKE obj : AXE source : CHEST Table 1 : Representative test utterances collected from subjects with associated game actions and frames Data collection produces two parallel streams of information : the sequence of actions taken by the novice and the audio stream produced by the expert ( figure 3a ) .</sentence>
				<definiendum id="0">GET obj</definiendum>
			</definition>
</paper>

		<paper id="0306">
			<definition id="0">
				<sentence>The instance x consists of e1x and e2x , and y consists of e1y and e2y .</sentence>
				<definiendum id="0">instance x</definiendum>
			</definition>
			<definition id="1">
				<sentence>Next , we classi ed the events included in the 699 instances into two syntactic categories : the verb phrase ( VP ) and the noun phrase ( NP ) .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiendum id="1">noun phrase</definiendum>
				<definiendum id="2">NP</definiendum>
				<definiens id="0">ed the events included in the 699 instances into two syntactic categories : the verb phrase</definiens>
			</definition>
</paper>

		<paper id="0304">
			<definition id="0">
				<sentence>As mentioned in the introduction , Variation events are relations between entities representing different aspects of a Variation ; specifically , a Variation is a relationship between two or more of the following entities : Type ( e.g. , point mutation , translocation , orinversion ) , Location ( e.g. , codon 14 , 1p36.1 , orbase pair 278 ) , Original-State and Altered-State ( e.g. , Thymine ) .</sentence>
				<definiendum id="0">Variation events</definiendum>
				<definiendum id="1">Variation</definiendum>
				<definiens id="0">a relationship between two or more of the following entities</definiens>
			</definition>
</paper>

		<paper id="1513">
			<definition id="0">
				<sentence>The parser uses a basic bottom-up shiftreduce algorithm , but employs a classifier to determine parser actions instead of a grammar .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">uses a basic bottom-up shiftreduce algorithm , but employs a classifier to determine parser actions instead of a grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>These classes are : • SHIFT : a shift action is taken ; • REDUCE-UNARY-XX : a unary reduce action is taken , and the root of the new subtree pushed onto S is of type XX ( where XX is a non-terminal symbol , typically NP , VP , PP , for example ) ; • REDUCE-LEFT-XX : a binary reduce action is taken , and the root of the new subtree pushed onto S is of non-terminal type XX .</sentence>
				<definiendum id="0">XX</definiendum>
				<definiens id="0">a non-terminal symbol</definiens>
			</definition>
			<definition id="2">
				<sentence>To that end , we need training instances that consist of sets of features paired with their classes correLet : S ( n ) denote the nth item from the top of the stack S , and W ( n ) denote the nth item from the front of the queue W. Features : • The head-word ( and its POS tag ) of : S ( 0 ) , S ( 1 ) , S ( 2 ) , and S ( 3 ) • The head-word ( and its POS tag ) of : W ( 0 ) , W ( 1 ) , W ( 3 ) and W ( 3 ) • The non-terminal node of the root of : S ( 0 ) , and S ( 1 ) • The non-terminal node of the left child of the root of : S ( 0 ) , and S ( 1 ) • The non-terminal node of the right child of the root of : S ( 0 ) , and S ( 1 ) • The non-terminal node of the left child of the root of : S ( 0 ) , and S ( 1 ) • The non-terminal node of the left child of the root of : S ( 0 ) , and S ( 1 ) • The linear distance ( number of words apart ) between the head-words of S ( 0 ) and S ( 1 ) • The number of lexical items ( words ) that have been found ( so far ) to be dependents of the head-words of : S ( 0 ) , and S ( 1 ) • The most recently found lexical dependent of the head of the head-word of S ( 0 ) that is to the left of S ( 0 ) ’s head • The most recently found lexical dependent of the head of the head-word of S ( 0 ) that is to the right of S ( 0 ) ’s head • The most recently found lexical dependent of the head of the head-word of S ( 0 ) that is to the left of S ( 1 ) ’s head • The most recently found lexical dependent of the head of the head-word of S ( 0 ) that is to the right of S ( 1 ) ’s head Figure 2 : Features used for classification .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">consist of sets of features paired with their classes correLet : S ( n ) denote the nth item from the top of the stack S , and W ( n ) denote the nth item from the front of the queue W. Features : • The head-word</definiens>
				<definiens id="1">The non-terminal node of the left child of the root of : S ( 0 ) , and S ( 1 ) • The non-terminal node of the right child of the root of : S ( 0 ) , and S ( 1 ) • The non-terminal node of the left child of the root of : S ( 0 ) , and S ( 1 ) • The non-terminal node of the left child of the root of : S ( 0 ) , and S ( 1 ) • The linear distance ( number of words apart</definiens>
			</definition>
			<definition id="3">
				<sentence>When we limit the number of consecutive unary reductions to a finite number m , the parser makes at most ( 2n – 1 ) m unary reductions when parsing a sentence of length n. Placing this limit not only guarantees that the algorithm terminates , but also guarantees that the number of actions taken by the parser is O ( n ) , where n is the length of the input string .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of consecutive unary reductions to a finite number m , the parser makes at most ( 2n – 1 ) m unary reductions when parsing a sentence of length n. Placing this limit not only guarantees that the algorithm terminates , but also guarantees that the number of actions taken by the parser is O ( n )</definiens>
				<definiens id="1">the length of the input string</definiens>
			</definition>
			<definition id="4">
				<sentence>The MBL-based parser ( denoted by MBLpar ) uses the IB1 algorithm , with five nearest neighbors , and the modified value difference metric ( MVDM ) , following the work of Nivre and Scholz ( 2004 ) on MBL-based deterministic dependency parsing .</sentence>
				<definiendum id="0">MBL-based parser</definiendum>
				<definiendum id="1">MBLpar )</definiendum>
				<definiendum id="2">MVDM</definiendum>
				<definiens id="0">uses the IB1 algorithm , with five nearest neighbors , and the modified value difference metric (</definiens>
			</definition>
</paper>

		<paper id="0402">
			<definition id="0">
				<sentence>Temporal expressions ( timexes ) are natural language phrases that refer directly to time points or intervals .</sentence>
				<definiendum id="0">Temporal expressions</definiendum>
				<definiens id="0">natural language phrases that refer directly to time points or intervals</definiens>
			</definition>
			<definition id="1">
				<sentence>Timex recognition is a named entity recognition ( NER ) task to which a variety of natural language processing and machine learning techniques have been applied .</sentence>
				<definiendum id="0">Timex recognition</definiendum>
				<definiens id="0">a named entity recognition ( NER ) task to which a variety of natural language processing and machine learning techniques have been applied</definiens>
			</definition>
			<definition id="2">
				<sentence>Timexes exhibit various patterns , ranging from regular patterns that can easily be captured using simple regular expressions to complex linguistic forms ( phrases ) .</sentence>
				<definiendum id="0">Timexes</definiendum>
				<definiens id="0">exhibit various patterns , ranging from regular patterns that can easily be captured using simple regular expressions to complex linguistic forms ( phrases )</definiens>
			</definition>
			<definition id="3">
				<sentence>The IO tagging scheme , which we use as a baseline , assigns the tag I to a token if it is part of a timex and O otherwise .</sentence>
				<definiendum id="0">IO tagging scheme</definiendum>
				<definiens id="0">a baseline , assigns the tag I to a token if it is part of a timex</definiens>
			</definition>
			<definition id="4">
				<sentence>TERN , the Temporal Expression Recognition and Normalization Evaluation , is organized under the auspices of the Automatic Content Extraction program ( ACE , http : //www.nist .</sentence>
				<definiendum id="0">TERN</definiendum>
				<definiendum id="1">Normalization Evaluation</definiendum>
				<definiens id="0">organized under the auspices of the Automatic Content Extraction program ( ACE</definiens>
			</definition>
			<definition id="5">
				<sentence>The special case of linear chain CRFs , which takes the following form , has been widely used for sequence labeling tasks : P ( y | x ) = 1 Z ( x ) exp parenleftBiggsummationdisplay t=1 summationdisplay k λkfk ( t , yt−1 , yt , x ) parenrightBigg , where Z ( x ) is the normalization factor , X = { x1 , ... , xn } is the observation sequence , Y = { y1 , ... , yT } is the label sequences , fk and λk are the feature functions and their weights respectively .</sentence>
				<definiendum id="0">linear chain CRFs</definiendum>
				<definiendum id="1">Z ( x )</definiendum>
				<definiens id="0">the normalization factor</definiens>
			</definition>
			<definition id="6">
				<sentence>The minorThird system takes care of automatically converting from XML format to the corresponding tagging schemes .</sentence>
				<definiendum id="0">minorThird system</definiendum>
				<definiens id="0">takes care of automatically converting from XML format to the corresponding tagging schemes</definiens>
			</definition>
			<definition id="7">
				<sentence>F IO ( baseline ) basic 0.846 0.723 0.780 0.973 0.832 0.897 basic + list 0.822 0.736 0.776 0.963 0.862 0.910 BCEUN basic 0.874 0.768 0.817 0.974 0.856 0.911 basic + list 0.872 0.794 0.831 0.974 0.887 0.928 BCEUN+PRE &amp; POS basic 0.882 0.749 0.810 0.979 0.831 0.899 basic + list 0.869 0.785 0.825 0.975 0.881 0.925 Table 1 : Timex : Results of training on basic and list features , and different tagging schemes .</sentence>
				<definiendum id="0">F IO</definiendum>
				<definiens id="0">Results of training on basic and list features</definiens>
			</definition>
</paper>

		<paper id="0403">
			<definition id="0">
				<sentence>17 Text Categorization ( TC ) systems are typically used to classify a stream of documents soon after they are produced , based upon a set of historical training data .</sentence>
				<definiendum id="0">Text Categorization</definiendum>
				<definiens id="0">typically used to classify a stream of documents soon after they are produced , based upon a set of historical training data</definiens>
			</definition>
			<definition id="1">
				<sentence>The text collections used in our experiments are from various conference proceedings of the Association of Computing Machinery , which uses a hierarchical classification system consisting of over 500 labels ( see Section 2 ) .</sentence>
				<definiendum id="0">Machinery</definiendum>
				<definiens id="0">uses a hierarchical classification system consisting of over 500 labels</definiens>
			</definition>
			<definition id="2">
				<sentence>Text categorization ( TC ) is the problem of assigning documents to one or more pre-defined categories .</sentence>
				<definiendum id="0">Text categorization</definiendum>
				<definiens id="0">the problem of assigning documents to one or more pre-defined categories</definiens>
			</definition>
			<definition id="3">
				<sentence>The following pseudocode describes the process of temporal feature modification : VOCABULARY ADDITIONS : for each class C : for each time ( year ) t : PreModList ( C , t , L ) = OddsRatio ( C , t , L ) ModifyList ( t ) = DecisionRule ( PreModList ( C , t , L ) for each term k in ModifyList ( t ) : Add pseudo-term `` k+t '' to Vocab DOCUMENT MODIFICATIONS : for each document : t = time ( year ) of doc for each term k : if `` k+t '' in Vocab : Replace k with `` k+t '' Classify modified document PreModList ( C , t , L ) is a list of the top L terms that , by the odds ratio measure , are highly associated with category C at time t. ( In our case , time is divided annually , because this is the finest resolution we have for many of the documents in our corpus . )</sentence>
				<definiendum id="0">VOCABULARY ADDITIONS</definiendum>
				<definiendum id="1">k+t '' Classify modified document PreModList</definiendum>
				<definiens id="0">a list of the top L terms that , by the odds ratio measure</definiens>
			</definition>
			<definition id="4">
				<sentence>Terms which pass this test are added to the final ModifyList ( t ) for time t. For the results that we report , DecisionRule is a simple ratio test with threshold factor f. Suppose f is time t as it is atemporally , the decision rule is “passed” .</sentence>
				<definiendum id="0">DecisionRule</definiendum>
				<definiens id="0">a simple ratio test with threshold</definiens>
			</definition>
			<definition id="5">
				<sentence>Stanley uses an innovative approach that eschews the need for an adaptive window of training examples , and 21 instead relies on a voting system for decision trees ( Stanley , 2001 ) .</sentence>
				<definiendum id="0">Stanley</definiendum>
				<definiens id="0">uses an innovative approach that eschews the need for an adaptive window of training examples</definiens>
			</definition>
</paper>

		<paper id="0205">
			<definition id="0">
				<sentence>Major science education standards call on students to engage in Online Inquiry-Based Learning where they pose scientific Driving Questions ( DQ ) , plan their search , collect and analyze online information , and synthesize their findings into an argument .</sentence>
				<definiendum id="0">Major science education standards</definiendum>
			</definition>
			<definition id="1">
				<sentence>OLISA applies Natural Language Processing ( NLP ) and Information Retrieval ( IR ) techniques to provide students query term suggestions and re-rank results returned from search engines by the relevance to the current query as well as to the DQ .</sentence>
				<definiendum id="0">OLISA</definiendum>
				<definiens id="0">applies Natural Language Processing ( NLP ) and Information Retrieval ( IR ) techniques to provide students query term suggestions and re-rank results returned from search engines by the relevance to the current query as well as to the DQ</definiens>
			</definition>
			<definition id="2">
				<sentence>For the term frequency of current query , we assign it a larger weight as it represents the current information needs : ) ( sq i tf ) ( q i tf ) ( ) ( * ) / # ( # q i q i tfywordInQuerextwordInConttf = ( 2 ) Therefore , ) ( ) ( ) ( ) ( ) ( other i sq i dq i q i c i tftftftftf +++= ( 3 ) The inverse document frequency is defined by : ) /ln ( ) ( i c i nNidf = ( 4 ) where N is total number of documents in the corpus , and n i is the number of documents containing ith term .</sentence>
				<definiendum id="0">inverse document frequency</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">a larger weight as it represents the current information needs : ) ( sq i tf</definiens>
			</definition>
</paper>

		<paper id="0625">
			<definition id="0">
				<sentence>Our SRL system consists of four stages : pruning , argument identification , argument classification , and inference .</sentence>
				<definiendum id="0">SRL system</definiendum>
			</definition>
			<definition id="1">
				<sentence>The heuristic is a recursive process starting from the verb whose arguments are to be identified .</sentence>
				<definiendum id="0">heuristic</definiendum>
			</definition>
			<definition id="2">
				<sentence>The inference process aims to optimize the objective function : ˆc1 : N = argmax c1 : N∈PN Nsummationdisplay i=1 Prob ( Si = ci ) , where S1 : N =uniontextki=1 Si , and Prob ( Si = ci ) = 1k ksummationdisplay j=1 Probj ( Si = ci ) , where Probj is the probability output by system j. Note that all systems may not output with the same set of argument candidates due to the pruning and argument identification .</sentence>
				<definiendum id="0">inference process</definiendum>
				<definiendum id="1">Probj</definiendum>
				<definiens id="0">aims to optimize the objective function : ˆc1 : N = argmax c1 : N∈PN Nsummationdisplay i=1 Prob ( Si = ci ) , where S1 : N =uniontextki=1 Si</definiens>
				<definiens id="1">the probability output by system j. Note that all systems may not output with the same set of argument candidates due to the pruning and argument identification</definiens>
			</definition>
			<definition id="3">
				<sentence>SNoW learns a sparse network of linear functions , in which the targets ( argument border predictions or argument type predictions , in this case ) are represented as linear functions over a common feature space .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiens id="0">learns a sparse network of linear functions , in which the targets</definiens>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>Our approach to learning qualia structures from the Web is on the one hand based on the assumption that instances of a certain semantic relation can be learned by matching certain lexico-syntactic patterns more or less reliably conveying the relation of interest in line with the seminal work of ( Hearst , 1992 ) , who defined the following patterns conveying a hypernym relation : ( 1 ) a1a3a2a5a4 such as a1a6a2a8a7 , a1a3a2a10a9 , ... , a1a3a2a10a11a13a12a14a7 ( anda15or ) a1a3a2a10a11 2 ( 2 ) such a1a3a2a5a4 as a1a3a2a8a7 , a1a3a2a10a9 , ... a1a3a2a10a11a16a12a17a7 ( anda15or ) a1a6a2a10a11 ( 3 ) a1a6a2a18a7 , a1a3a2a10a9 , ... , a1a3a2a10a11 ( anda15or ) other a1a3a2a5a4 ( 4 ) a1a6a2a19a4 , ( includinga15especially ) a1a3a2a20a7 , a1a3a2a10a9 , ... , a1a3a2a10a11a16a12a17a7 ( anda15or ) a1a3a2a10a11 According to Hearst , from such patterns we can derive that for all a1a3a2a10a21a23a22a25a24a6a26a28a27a29a26a31a30a8a22a33a32a35a34a37a36a39a38a41a40a37a30a14a34a16a42a44a43a45a1a3a2a5a21a23a22a46a1a3a2 a4a41a47 .</sentence>
				<definiendum id="0">a1a3a2a10a9 , ... , a1a3a2a10a11a13a12a14a7</definiendum>
				<definiens id="0">on the one hand based on the assumption that instances of a certain semantic relation can be learned by matching certain lexico-syntactic patterns more or less reliably conveying the relation of interest in line with the seminal work</definiens>
			</definition>
</paper>

		<paper id="1503">
			<definition id="0">
				<sentence>A type map consists of a mapping typ : SynAtom → SemTyp .</sentence>
				<definiendum id="0">type map</definiendum>
			</definition>
			<definition id="1">
				<sentence>Semantic types are assigned to complex syntactic types as follows : typ ( A · B ) = typ ( A ) × typ ( B ) [ Product ] typ ( A/B ) = typ ( B ) → typ ( A ) [ Right Division ] typ ( B\A ) = typ ( B ) → typ ( A ) [ Left Division ] We will often writeα : A whereαis aλ-term of type typ ( A ) .</sentence>
				<definiendum id="0">typ</definiendum>
				<definiens id="0">A · B ) = typ ( A ) × typ ( B ) [ Product ] typ ( A/B ) = typ ( B ) → typ ( A ) [ Right Division ] typ ( B\A ) = typ ( B ) → typ ( A )</definiens>
			</definition>
			<definition id="2">
				<sentence>A lexicon is a finite relation Lex ⊆ Tok∗ × Term × SynTyp , where all 〈w , α , A〉 ∈ Lex are such that the semantic term α is of the appropriate type for the syntactic type A. We assume that the only terms used in the lexicon are relevant , in the sense of relevance logic , in not containing vacuous abstractions .</sentence>
				<definiendum id="0">lexicon</definiendum>
				<definiens id="0">a finite relation Lex ⊆ Tok∗ × Term × SynTyp , where all 〈w , α , A〉 ∈ Lex are such that the semantic term α is of the appropriate type for the syntactic type A. We assume that the only terms used in the lexicon are relevant , in the sense of relevance logic</definiens>
			</definition>
			<definition id="3">
				<sentence>Unfolding the Lambek connectives to their linear counterparts , ( A/B ) • and ( B\A ) • unfold to A•℘B◦ ; ( A/B ) ◦ and ( B\A ) ◦ unfold to A◦⊗B• ; ( A · B ) • unfolds to A• ⊗ B• ; and ( A · B ) ◦ unfolds to A◦℘B◦ .</sentence>
				<definiendum id="0">Unfolding the Lambek</definiendum>
				<definiens id="0">connectives to their linear counterparts , ( A/B ) • and ( B\A ) • unfold to A•℘B◦ ; ( A/B ) ◦ and ( B\A ) ◦ unfold to A◦⊗B• ; ( A · B ) • unfolds to A• ⊗ B•</definiens>
			</definition>
			<definition id="4">
				<sentence>The proof frame for a syntactic sequent C1 , ... , Cn ⇒ C0 is the ordered sequence of polar trees rooted at C◦0 , C•1 , ... , C•n. We convert sequents to frames in this order , with the output polar tree first .</sentence>
				<definiendum id="0">... , Cn ⇒ C0</definiendum>
				<definiens id="0">the ordered sequence of polar trees rooted at C◦0 , C•1 , ...</definiens>
			</definition>
			<definition id="5">
				<sentence>α : B\A◦ d82d82 d77d67 d54 d45 d39 d79d79d31d31 d15d15d31 d31 d15d15d31 d31 pi1γ : A• { Li } d65d65d65 d65d65d65 d65d65d65 d65d65 d42d42 d38 d44 d53 d65 d77 pi2γ : B• { Ri } d125d125d125 d125d125d125 d125d125d125 d125d125 d116d116 d24 d18d10 d125d114 ℘ γ : A · B• d15d15d31 d31 β : B◦ { } d67d67d67 d67d67d67 d67d67d67 d67d67d67 d79d79d31d31 α : A◦ { } d122d122d122 d122d122d122 d122d122d122 d122d122d122 d79d79d31d31 ⊗ 〈α , β〉 : A · B◦ d82d82 d78d67 d55 d46 d40 d76d76 d112 d122 d7 d16 d22 d79d79d31d31 Figure 1 : Logical Links with Switch Paths ( solid ) and Semantic Trip ( dashed ) x : S ◦ x : N◦ y ( x ) : S • ⊗ y : N\S • d63d63d63d63 d127d127 d127d127 u : CN◦ z ( λx .</sentence>
				<definiendum id="0">β〉</definiendum>
			</definition>
			<definition id="6">
				<sentence>A shift transition pops a literal from the lexical stack and pushes it onto the global stack .</sentence>
				<definiendum id="0">shift transition</definiendum>
				<definiens id="0">pops a literal from the lexical stack and pushes it onto the global stack</definiens>
			</definition>
</paper>

		<paper id="0407">
			<definition id="0">
				<sentence>For this purpose , given a predicate p in a sentence s , we can define the notion of predicate argument spanning trees ( PASTs ) as those syntactic subtrees of s which exactly cover all and only the p’s arguments ( see Section 4.1 ) .</sentence>
				<definiendum id="0">PASTs</definiendum>
				<definiens id="0">those syntactic subtrees of s which exactly cover all</definiens>
			</definition>
			<definition id="1">
				<sentence>Tree kernels are a viable alternative that allows the learning algorithm to measure the similarity between two PASTs in term of all possible tree substructures .</sentence>
				<definiendum id="0">Tree kernels</definiendum>
				<definiens id="0">a viable alternative that allows the learning algorithm to measure the similarity between two PASTs in term of all possible tree substructures</definiens>
			</definition>
			<definition id="2">
				<sentence>Predicates in PB are only embodied by verbs whereas most of the times Arg0 is the subject , Arg1 is the direct object and ArgM indicates locations , as in our example .</sentence>
				<definiendum id="0">Arg1</definiendum>
				<definiendum id="1">ArgM</definiendum>
				<definiens id="0">the subject</definiens>
				<definiens id="1">the direct object and</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , the Phrase Type indicates the syntactic type of the phrase labeled as a predicate argument , e.g. NP for Arg1 in Figure 1 .</sentence>
				<definiendum id="0">Phrase Type</definiendum>
				<definiens id="0">indicates the syntactic type of the phrase labeled as a predicate argument</definiens>
			</definition>
			<definition id="4">
				<sentence>The Parse Tree Path contains the path in the parse tree between the predicate and the argument phrase , expressed as a sequence of nonterminal labels linked by direction ( up or down ) symbols , e.g. V↑VP↓NP for Arg1 in Figure 1 .</sentence>
				<definiendum id="0">Parse Tree Path</definiendum>
				<definiens id="0">contains the path in the parse tree between the predicate and the argument phrase , expressed as a sequence of nonterminal labels linked by direction ( up or down ) symbols</definiens>
			</definition>
			<definition id="5">
				<sentence>The Predicate Word is the surface form of the verbal predicate , e.g. rent for all arguments .</sentence>
				<definiendum id="0">Predicate Word</definiendum>
				<definiens id="0">the surface form of the verbal predicate</definiens>
			</definition>
			<definition id="6">
				<sentence>It follows that : KT ( T1 , T2 ) = summationdisplay n1∈NT1 summationdisplay n2∈NT2 ∆ ( n1 , n2 ) ( 1 ) where NT1 and NT2 are the sets of the T1’s and T2’s nodes , respectively and ∆ ( n1 , n2 ) =summationtext |F| i=1 Ii ( n1 ) Ii ( n2 ) .</sentence>
				<definiendum id="0">NT2</definiendum>
			</definition>
			<definition id="7">
				<sentence>We can compute ∆ as follows : then ∆ ( n1 , n2 ) = 0 ; and n1 and n2 have only leaf children ( i.e. they are pre-terminals symbols ) then ∆ ( n1 , n2 ) = 1 ; and n1 and n2 are not pre-terminals then ∆ ( n1 , n2 ) = nc ( n1 ) productdisplay j=1 ( 1+∆ ( cjn1 , cjn2 ) ) ( 2 ) where nc ( n1 ) is the number of the children of n1 and cjn is the j-th child of the node n. Note that , as the productions are the same , nc ( n1 ) = nc ( n2 ) .</sentence>
				<definiendum id="0">nc ( n1 )</definiendum>
				<definiens id="0">the number of the children of n1 and cjn is the j-th child of the node n. Note that , as the productions are the same , nc</definiens>
			</definition>
			<definition id="8">
				<sentence>The node spanning tree ( NST ) , ps is the subtree rooted in r , from which the nodes that are neither ancestors nor descendants of any ni are removed .</sentence>
				<definiendum id="0">node spanning tree</definiendum>
				<definiendum id="1">NST</definiendum>
				<definiens id="0">the subtree rooted in r , from which the nodes that are neither ancestors nor descendants of any ni are removed</definiens>
			</definition>
</paper>

		<paper id="1519">
			<definition id="0">
				<sentence>Switchboard has over one million words , with telephone conversations on prescribed topics [ Godfrey et al. 1992 ] .</sentence>
				<definiendum id="0">Switchboard</definiendum>
			</definition>
			<definition id="1">
				<sentence>Y is the conditioned variables and ranges from { -1 , +1 } , with Y = +1 indicating that the word is edited .</sentence>
				<definiendum id="0">Y</definiendum>
			</definition>
			<definition id="2">
				<sentence>A boosting classifier is a linear combination of n features to define the prediction variable Z. ∑ = = n i ii FZ 1 α ( 1 ) where α i is the weight to be estimated for feature φ i .</sentence>
				<definiendum id="0">boosting classifier</definiendum>
				<definiens id="0">the weight to be estimated for feature φ i</definiens>
			</definition>
			<definition id="3">
				<sentence>The training subset consists of all files in the sections 2 and 3 of the Switchboard corpus .</sentence>
				<definiendum id="0">training subset</definiendum>
			</definition>
			<definition id="4">
				<sentence>The addition of the feature spaces of relaxed matches for words , POS tags , and POS hierarchy tags all give additive improvements , which leads to an overall of 8.95 % absolute improvement over the re-implemented baseline , or 43.98 % relative error reduction on F-score .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">tags , and POS hierarchy tags all give additive improvements</definiens>
			</definition>
</paper>

		<paper id="0210">
			<definition id="0">
				<sentence>* Figure 2 : Flow generating Fill-In-The-Blank Question ( FBQ ) Seed Sentence Corpus Testing knowledge [ a ] Determine the blank position [ b ] Generate distracter candidates Lexicon [ c ] Verify the incorrectness [ d ] Form the question Question [ a ] The seed sentence is a correct English sentence that is decomposed into a sentence with a blank ( blanked sentence ) and the correct choice for the blank .</sentence>
				<definiendum id="0">seed sentence</definiendum>
				<definiens id="0">Flow generating Fill-In-The-Blank Question ( FBQ ) Seed Sentence Corpus Testing knowledge [ a ] Determine the blank position [ b ] Generate distracter candidates Lexicon [ c ] Verify the incorrectness</definiens>
				<definiens id="1">a correct English sentence that is decomposed into a sentence with a blank ( blanked sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Here , s ( x ) is the blanked sentence , s ( w ) denotes the sentence restored by the word w , and hits ( y ) represents the number of documents retrieved from the Web for the key y. This can be a word of another POS ( Part-Of-Speech ) .</sentence>
				<definiendum id="0">x )</definiendum>
				<definiendum id="1">y )</definiendum>
				<definiens id="0">the blanked sentence , s ( w ) denotes the sentence restored by the word w</definiens>
			</definition>
			<definition id="2">
				<sentence>IRT , in which a question is called an item , calculates the test-takers’ proficiency based on the answers for items of the given test ( Embretson , 2000 ) .</sentence>
				<definiendum id="0">IRT</definiendum>
			</definition>
			<definition id="3">
				<sentence>The x-axis represents the size of the reduced test in number of items , while the yaxis represents the correlation coefficient ( R ) between estimated proficiency and real TOEIC score .</sentence>
				<definiendum id="0">x-axis</definiendum>
				<definiens id="0">the size of the reduced test in number of items , while the yaxis represents the correlation coefficient ( R ) between estimated proficiency and real TOEIC score</definiens>
			</definition>
</paper>

		<paper id="0501">
			<definition id="0">
				<sentence>Children must end up with an Internal Language ( “grammar” ) that is close enough but not to close to the Observable Language ( O-Language ) in the population so that change can happen at the right pace .</sentence>
				<definiendum id="0">Internal Language</definiendum>
				<definiens id="0">close enough but not to close to the Observable Language ( O-Language ) in the population so that change can happen at the right pace</definiens>
			</definition>
			<definition id="1">
				<sentence>An unambiguous triger ( Fodor 198 , Dresher 199 , Lightfoot 199 ) is a piece of data from the Olanguage that unambiguously signals one parameter value over another for a given parameter .</sentence>
				<definiendum id="0">unambiguous triger</definiendum>
				<definiens id="0">a piece of data from the Olanguage that unambiguously signals one parameter value over another for a given parameter</definiens>
			</definition>
			<definition id="2">
				<sentence>( 4a ) Unambiguous OV Triger [ Object Verb/Verb-Marker ] VP ( 4b ) he Subj [ hyne Obj gebidde VerbFinite Subj Obj Verb [ mid ennum mode ] P ] VP PP ( Ælfric 's Letter to Wulfsige , 87.107 ) ( 4c ) we Subj sculen VerbFinite [ [ ure yfele +teawes ] Obj Subj Verb Obj forl+aten Verb-Marker ] VP Verb-Marker ( Alcuin 's De Virtutibus et Vitis , 70.52 ) ( 5a ) Unambiguous VO Triger [ Verb/Verb-Marker Object ] VP ( 5b ) &amp; [ mid his stefne ] P he Subj [ awec+d VerbFinite PP Subj Verb deade Obj [ to life ] P ] VP Obj P ( Saint James , 30.31 ) ( 5c ) þa Adv ahof VerbFinite Paulus Subj [ up Verb-Marker Adv Verb Subj Verb-arker [ his heafod ] Obj ] VP Obj ( Blickling Homilies , 187.35 ) The Object is adjacent to either a Verb or a VerbMarker on the appropriate side – the correct Olanguage order .</sentence>
				<definiendum id="0">VP Obj</definiendum>
				<definiendum id="1">Object</definiendum>
			</definition>
			<definition id="3">
				<sentence>Verb-Markers include particles ( ‘up’ ) , non-finite complements to finite verbs ( ‘shall…perform’ ) , some closed-clas adverbials ( ‘never’ ) , and negatives ( ‘not’ ) as described in Lightfoot ( 191 ) .</sentence>
				<definiendum id="0">Verb-Markers</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Noise Filter acts as a buffer that separates “signal” from “noise” .</sentence>
				<definiendum id="0">Noise Filter</definiendum>
				<definiens id="0">a buffer that separates “signal” from “noise”</definiens>
			</definition>
</paper>

		<paper id="0311">
			<definition id="0">
				<sentence>For this study we simply developed a coding manual for the purposes of our experiment , broadly based on the approach adopted in MATE ( Poesio et al. , 1999 ) and GNOME ( Poesio , 2004 ) , but introducing new types of annotation ( ambiguous anaphora , and a simple form of discourse deixis ) while simplifying other aspects ( e.g. , by not annotating bridging references ) .</sentence>
				<definiendum id="0">GNOME</definiendum>
				<definiens id="0">annotation ( ambiguous anaphora , and a simple form of discourse deixis ) while simplifying other aspects</definiens>
			</definition>
			<definition id="1">
				<sentence>Following Passonneau ( 2004 ) , we used the coefficient α of Krippendorff ( 1980 ) for this purpose , which allows for partial agreement among anaphoric chains.3 The α coefficient measures agreement among a set of coders C who assign each of a set of items I to one of a set of distinct and mutually exclusive categories K ; for anaphora annotation the coders are the annotators , the items are the markables in the text , and the categories are the emerging anaphoric chains .</sentence>
				<definiendum id="0">coders</definiendum>
				<definiens id="0">allows for partial agreement among anaphoric chains.3 The α coefficient measures agreement among a set of coders C who assign each of a set of items I to one of a set of distinct and mutually exclusive categories K ; for anaphora annotation the</definiens>
			</definition>
			<definition id="2">
				<sentence>The expected disagreement is the mean of the distances between all the judgment pairs in the data , without regard to items .</sentence>
				<definiendum id="0">expected disagreement</definiendum>
				<definiens id="0">the mean of the distances between all the judgment pairs in the data , without regard to items</definiens>
			</definition>
			<definition id="3">
				<sentence>For anaphora annotation , the categories are the ANAPHORIC CHAINS : the sets of markables which are mentions of the same discourse entity .</sentence>
				<definiendum id="0">ANAPHORIC CHAINS</definiendum>
			</definition>
			<definition id="4">
				<sentence>Finally , we come to the agreement values obtained by using α to compare anaphoric chains computed With place Without place First Half K 0.62773 0.50066α 0.65615 0.53875 Second Half K 0.66201 0.44997α 0.67736 0.47490 The coefficient reported here as K is the one called K by Siegel and Castellan ( 1988 ) .</sentence>
				<definiendum id="0">K</definiendum>
			</definition>
</paper>

		<paper id="0833">
			<definition id="0">
				<sentence>Translation A sine qua non for both EBMT and SMT is a set of sentences in one language aligned with their translations in another .</sentence>
				<definiendum id="0">Translation A sine qua non</definiendum>
				<definiendum id="1">SMT</definiendum>
				<definiens id="0">a set of sentences in one language aligned with their translations in another</definiens>
			</definition>
			<definition id="1">
				<sentence>Essentially , the translation model establishes the set of target language words ( and more recently , phrases ) which are most likely to be useful in translating the source string , while the language model tries to assemble these words ( and phrases ) in the most likely target word order .</sentence>
				<definiendum id="0">translation model</definiendum>
				<definiens id="0">establishes the set of target language words ( and more recently , phrases ) which are most likely to be useful in translating the source string</definiens>
			</definition>
			<definition id="2">
				<sentence>In order to see whether the amount of training data affected the ( relative ) performance of the EBMT and SMT systems , ( Way and Gough , 2005 ) split the training data into three sets , of 50K ( 1.1M words ) , 100K ( 2.4M words ) and 203K ( 4.8M words ) sentence pairs ( TS1–TS3 in what follows ) .</sentence>
				<definiendum id="0">SMT systems</definiendum>
			</definition>
			<definition id="3">
				<sentence>Table 5 : Seeding Pharaoh with Giza++ word and EBMT phrasal alignments for English–French .</sentence>
				<definiendum id="0">EBMT</definiendum>
				<definiens id="0">Seeding Pharaoh with Giza++ word</definiens>
			</definition>
			<definition id="4">
				<sentence>Table 6 : Seeding Pharaoh with Giza++ word and EBMT phrasal alignments for French–English .</sentence>
				<definiendum id="0">EBMT</definiendum>
				<definiens id="0">Seeding Pharaoh with Giza++ word</definiens>
			</definition>
			<definition id="5">
				<sentence>Essentially , the EBMT data helps the SMT system to make the best use of phrase alignments during translation .</sentence>
				<definiendum id="0">EBMT data</definiendum>
			</definition>
</paper>

		<paper id="0626">
			<definition id="0">
				<sentence>“302110” symbolizes the NP Object of distance 1 prior to the passive predicate .</sentence>
				<definiendum id="0">“302110”</definiendum>
				<definiens id="0">symbolizes the NP Object of distance 1 prior to the passive predicate</definiens>
			</definition>
			<definition id="1">
				<sentence>All possible combinations ( members ) for the example in Figure 1 are M1 : [ AN1 , AM-MOD , V , AM1 &lt; points &gt; ( from ) , AN2 ] ( original ) M2 : [ AN1 AM-MOD V AN3 ( from ) AN2 ] ( change AM1 as AN3 ) M3 : [ AN1 AM-MOD V AM1 &lt; point &gt; ( from ) AM2 &lt; week &gt; ] ( change AN2 as AM2 ) M4 : [ AN1 AM-MOD V AN3 &lt; point &gt; ( from ) AM2 &lt; week &gt; ] ( change AM1 as AN3 and one AN2 as AM2 ) The output from the Member Generator is passed to the Role Classifier , which finds all possible roles for each member with suitable core roles and adjuncts according to a Database built up by training data , in which each predicate has different patterns associated with it , each pattern has different semantic roles , and each role has the following format .</sentence>
				<definiendum id="0">Role Classifier</definiendum>
				<definiens id="0">members ) for the example in Figure 1 are M1 : [ AN1 , AM-MOD , V , AM1 &lt; points &gt; ( from )</definiens>
				<definiens id="1">finds all possible roles for each member with suitable core roles and adjuncts according to a Database built up by training data , in which each predicate has different patterns associated with it , each pattern has different semantic roles</definiens>
			</definition>
			<definition id="2">
				<sentence>And there are 4 roles labeled in M4 , which are AN1 as A1 , AM-MOD , AN3 as A2 , and AM2 as AM-TMP respectively .</sentence>
				<definiendum id="0">AM2</definiendum>
				<definiens id="0">AM-TMP respectively</definiens>
			</definition>
			<definition id="3">
				<sentence>A General Tree-based PredicateArgument Boundary Recognition Algorithm ( GTPARA ) handles the conversion process , turning a parse tree into a flat representation with all predicates and their arguments labeled with some useful features , such as phrase types .</sentence>
				<definiendum id="0">General Tree-based PredicateArgument Boundary Recognition Algorithm ( GTPARA )</definiendum>
				<definiens id="0">handles the conversion process , turning a parse tree into a flat representation with all predicates and their arguments labeled with some useful features , such as phrase types</definiens>
			</definition>
</paper>

		<paper id="0810">
			<definition id="0">
				<sentence>Machine Translation ( MT ) as well as other bilingual applications strongly rely on word alignment .</sentence>
				<definiendum id="0">Machine Translation</definiendum>
				<definiendum id="1">MT</definiendum>
				<definiens id="0">other bilingual applications strongly rely on word alignment</definiens>
			</definition>
			<definition id="1">
				<sentence>pllr ( s|E ) is the normalized log-likelihood ratio score described above and pibm2 ( s|E ) is the probability obtained from an IBM model 2 we trained after the Inuktitut side of the training corpus was segmented using a recursive procedure optimizing a frequency-based criterion .</sentence>
				<definiendum id="0">pllr ( s|E )</definiendum>
				<definiens id="0">the probability obtained from an IBM model 2 we trained after the Inuktitut side of the training corpus was segmented using a recursive procedure optimizing a frequency-based criterion</definiens>
			</definition>
			<definition id="2">
				<sentence>λ is a weighting coefficient .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiens id="0">a weighting coefficient</definiens>
			</definition>
			<definition id="3">
				<sentence>One important weakness of our first approach lies in the cartesian product we generate when JAPA produces a n-m ( n , m &gt; 1 ) alignment .</sentence>
				<definiendum id="0">JAPA</definiendum>
			</definition>
</paper>

		<paper id="0903">
			<definition id="0">
				<sentence>BLEU ( Papineni et al. , 2001 ) is a precision measure based on m-gram count vectors .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">a precision measure based on m-gram count vectors</definiens>
			</definition>
			<definition id="1">
				<sentence>The NIST score ( Doddington , 2002 ) extends the BLEU score by taking information weights of the m-grams into account .</sentence>
				<definiendum id="0">NIST score</definiendum>
				<definiens id="0">extends the BLEU score by taking information weights of the m-grams into account</definiens>
			</definition>
			<definition id="2">
				<sentence>The NIST information weight is defined as Info ( em1 ) : = −parenleftbiglog2 ¯˜nem1 − log2 ¯˜nem−1 1 parenrightbig with ¯˜nem1 : = summationdisplay k , r ˜nen1 , k , r. Note that the weight of a phrase occurring in many references sentence for a candidate is considered to be lower than the weight of a phrase occurring only once !</sentence>
				<definiendum id="0">NIST information weight</definiendum>
			</definition>
</paper>

		<paper id="1604">
			<definition id="0">
				<sentence>The : indicator indicates the type or function of the term and takes the values THE , A , F , PRO , and QUANTITY-TERM .</sentence>
				<definiendum id="0">indicator</definiendum>
				<definiens id="0">indicates the type or function of the term and takes the values THE , A , F , PRO , and QUANTITY-TERM</definiens>
			</definition>
			<definition id="1">
				<sentence>THE represents a grounded object in the discourse , A represents an abstract object , F is a functional operator , PRO is used for references , and QUANTITY-TERM represents quantities expressed in various scales .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">a grounded object in the discourse , A represents an abstract object</definiens>
				<definiens id="1">a functional operator</definiens>
			</definition>
			<definition id="2">
				<sentence>the : lex is the root lexical item for the term .</sentence>
				<definiendum id="0">lex</definiendum>
			</definition>
			<definition id="3">
				<sentence>Lex is an optional feature and is created from the : class if it is not present in the input .</sentence>
				<definiendum id="0">Lex</definiendum>
				<definiens id="0">an optional feature</definiens>
			</definition>
			<definition id="4">
				<sentence>wh-gap ) ) ) The first half of the RHS ( the g- &gt; rule ) creates a global variable and binds a new word forest node label to it .</sentence>
				<definiendum id="0">RHS</definiendum>
				<definiens id="0">the g- &gt; rule ) creates a global variable and binds a new word forest node label to it</definiens>
			</definition>
			<definition id="5">
				<sentence>The RHS ( the b- &gt; rule ) binds the current term to the gap that has already been created , filling the empty node in the word forest .</sentence>
				<definiendum id="0">RHS</definiendum>
				<definiens id="0">the b- &gt; rule ) binds the current term to the gap that has already been created , filling the empty node in the word forest</definiens>
			</definition>
			<definition id="6">
				<sentence>A term attempts to match each rule in the grammar until a RHS creates a leaf node .</sentence>
				<definiendum id="0">term</definiendum>
				<definiens id="0">attempts to match each rule in the grammar until a RHS creates a leaf node</definiens>
			</definition>
			<definition id="7">
				<sentence>The work in [ Chen et al. , 2002 ] generated sentences in in that the input to FERGUS is a shallow syntactic tree , containing all lexemes and function words .</sentence>
				<definiendum id="0">FERGUS</definiendum>
				<definiens id="0">a shallow syntactic tree , containing all lexemes and function words</definiens>
			</definition>
</paper>

		<paper id="0808">
			<definition id="0">
				<sentence>EMILLE is a 63 Million word electronic corpus of South Asian languages , especially those spoken as minority languages in UK .</sentence>
				<definiendum id="0">EMILLE</definiendum>
				<definiens id="0">a 63 Million word electronic corpus of South Asian languages , especially those spoken as minority languages in UK</definiens>
			</definition>
			<definition id="1">
				<sentence>δt is a value that describes the length relationship between the sentences of a pair of type t. For example , given a pair of one Hindi and two English sentences and a value δt , where t = 1:2 , it is possible to check if these sentences can be aligned with each other .</sentence>
				<definiendum id="0">δt</definiendum>
				<definiens id="0">a value that describes the length relationship between the sentences of a pair of type t. For example , given a pair of one Hindi and two English sentences and a value δt</definiens>
			</definition>
			<definition id="2">
				<sentence>Hindi is a partial free order language where the order of word groups in a Hindi sentence is not fixed , but the order of words within groups is fixed ( Ray et al. , 2003 ) .</sentence>
				<definiendum id="0">Hindi</definiendum>
				<definiens id="0">a partial free order language where the order of word groups in a Hindi sentence is not fixed</definiens>
			</definition>
			<definition id="3">
				<sentence>iii ) “थे” is a past tense conjunction of the verb “होना” .</sentence>
				<definiendum id="0">iii ) “थे”</definiendum>
				<definiens id="0">a past tense conjunction of the verb “होना”</definiens>
			</definition>
			<definition id="4">
				<sentence>According to WWW3 , “The edit distance of two strings , s1 and s2 , is defined as the minimum number of point mutations required to change s1 into s2 , where a point mutation is one of : change a letter , insert a letter or delete a letter.”</sentence>
				<definiendum id="0">“The edit distance</definiendum>
			</definition>
			<definition id="5">
				<sentence>The parallel texts consist of 3954 English and 5361 Hindi words taken from the EMILLE Corpus .</sentence>
				<definiendum id="0">parallel texts</definiendum>
			</definition>
			<definition id="6">
				<sentence>Mayers A. , Grishman R. , Kosaka M. , 1998 , A Multilingual Procedure for Dictionary-Based Sentence Alignment , Proceedings of the Third Conference of the Association for Machine Translation in the Americas on Machine Translation and the Information Soup .</sentence>
				<definiendum id="0">Multilingual Procedure</definiendum>
				<definiens id="0">of the Association for Machine Translation in the Americas on Machine Translation and the Information Soup</definiens>
			</definition>
</paper>

		<paper id="1611">
			<definition id="0">
				<sentence>We analyze the content of instructional texts of this kind in terms of temporally related situations , i.e. actions ( b , c , d , e ) states ( a , h ) and events ( f , g ) , denoted by individual discourse units .</sentence>
				<definiendum id="0">e ) states</definiendum>
				<definiens id="0">the content of instructional texts of this kind in terms of temporally related situations</definiens>
			</definition>
			<definition id="1">
				<sentence>The coefficient of variable x ( lij ) which models the assignment cost c ( lij ) is given by : c ( lij ) = −log2 ( p ( lij ) ) where p ( lij ) is the probability of lij being selected as the outcome of task Ti .</sentence>
				<definiendum id="0">coefficient of variable x ( lij )</definiendum>
				<definiendum id="1">assignment cost c</definiendum>
				<definiendum id="2">p ( lij )</definiendum>
			</definition>
			<definition id="2">
				<sentence>The ILP model consists of the target function and a set of constraints which block illegal assignments ( e.g. only one label of the given task can be selected ) 6 .</sentence>
				<definiendum id="0">ILP model</definiendum>
			</definition>
			<definition id="3">
				<sentence>To evaluate individual tasks we applied two metrics : accuracy , calculated as the proportion of correct classifications to the total number of instances , and the κ statistic , which corrects for the proportion of classifications that might occur by chance .</sentence>
				<definiendum id="0">the κ statistic</definiendum>
				<definiens id="0">corrects for the proportion of classifications that might occur by chance</definiens>
			</definition>
			<definition id="4">
				<sentence>Approximation algorithms for classification problems with pairwise relationships : Metric labeling and Markov random fields .</sentence>
				<definiendum id="0">Approximation algorithms</definiendum>
				<definiens id="0">Metric labeling and Markov random fields</definiens>
			</definition>
</paper>

		<paper id="0211">
			<definition id="0">
				<sentence>Coh-Metrix is a text-processing tool that provides new methods of automatically assessing text cohesion , readability , and diﬃculty .</sentence>
				<definiendum id="0">Coh-Metrix</definiendum>
				<definiens id="0">a text-processing tool that provides new methods of automatically assessing text cohesion , readability</definiens>
			</definition>
			<definition id="1">
				<sentence>Long sentences : the ability of the parser to handle sentences longer than 40 words .</sentence>
				<definiendum id="0">Long sentences</definiendum>
				<definiens id="0">the ability of the parser to handle sentences longer than 40 words</definiens>
			</definition>
			<definition id="2">
				<sentence>Charniak presents a parser ( CP ) based on probabilities gathered from the WSJ part of the PTB ( Charniak , 1997 ) .</sentence>
				<definiendum id="0">Charniak</definiendum>
			</definition>
			<definition id="3">
				<sentence>The Stanford Parser ( SP ) is an unlexicalized parser that rivals state-of-the-art lexicalized ones ( Klein and Manning , 2003 ) .</sentence>
				<definiendum id="0">Stanford Parser ( SP )</definiendum>
			</definition>
			<definition id="4">
				<sentence>An additional set of three texts was chosen from the Touchstone Applied Science Associates , Inc. , ( TASA ) corpus with an average sentence length of 13.06 ( overall TASA average ) or higher .</sentence>
				<definiendum id="0">TASA</definiendum>
				<definiens id="0">corpus with an average sentence length of 13.06 ( overall TASA average ) or higher</definiens>
			</definition>
			<definition id="5">
				<sentence>Similar misattachment issues for adjuncts are encountered with adverbial phrases , but they were rare 3 PP = wrong attachment site for a prepositional phrase ; ADV = wrong attachment site for an adverbial phrase ; cNP = misparsed complex noun phrase ; &amp; X = wrong coordination Table 7 : Correlation of Average Performance per Text for all Parsers and Average Sentence Length ( Directed Evaluation ) .</sentence>
				<definiendum id="0">ADV</definiendum>
				<definiendum id="1">cNP</definiendum>
			</definition>
</paper>

		<paper id="0307">
			<definition id="0">
				<sentence>The rst , information status ( old , mediated , new ) , expresses the availability of entities in discourse ( Section 3 ) .</sentence>
				<definiendum id="0">information status</definiendum>
				<definiens id="0">expresses the availability of entities in discourse ( Section 3 )</definiens>
			</definition>
			<definition id="1">
				<sentence>The Switchboard Corpus ( Godfrey et al. , 1992 ) consists of 2430 spontaneous phone conversations ( average six minutes ) , between speakers of American English , for three million words .</sentence>
				<definiendum id="0">Switchboard Corpus</definiendum>
				<definiens id="0">consists of 2430 spontaneous phone conversations ( average six minutes ) , between speakers of American English , for three million words</definiens>
			</definition>
			<definition id="2">
				<sentence>( 12 ) ( A ) I live in Garland , and we’re just beginning to build a real big recycling center ... ( B ) ( YEAH there’s been ) ( NO emphasis on recycling at ALL ) ( in San ANTONIO ) 10Emphasis can occur for two major reasons , both identi ed by Brenier : emphasis of a particular word or phrase , i.e. kontrast , or emphasis over a larger span of speech , conveying affective connotations such as excitement , which is not included here .</sentence>
				<definiendum id="0">ALL )</definiendum>
				<definiens id="0">beginning to build a real big recycling center ... ( B ) ( YEAH there’s been ) ( NO emphasis on recycling at</definiens>
				<definiens id="1">emphasis of a particular word or phrase , i.e. kontrast , or emphasis over a larger span of speech</definiens>
			</definition>
			<definition id="3">
				<sentence>Information structure is one of the desired annotation layers .</sentence>
				<definiendum id="0">Information structure</definiendum>
			</definition>
</paper>

		<paper id="0610">
			<definition id="0">
				<sentence>Manual annotation is a time-consuming process .</sentence>
				<definiendum id="0">Manual annotation</definiendum>
				<definiens id="0">a time-consuming process</definiens>
			</definition>
			<definition id="1">
				<sentence>SVM is a general supervised machine learning algorithm , that has achieved state of the art performance on many classi cation tasks , including NE recognition .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">a general supervised machine learning algorithm</definiens>
			</definition>
			<definition id="2">
				<sentence>Perceptron is a simple , fast and effective learning algorithm , which has successfully been applied to named entity recognition ( Carreras et al. , 2003 ) .</sentence>
				<definiendum id="0">Perceptron</definiendum>
			</definition>
			<definition id="3">
				<sentence>τ is the ratio of negative margin to the positive margin of the classi er and is equal to 1 in the standard SVM .</sentence>
				<definiendum id="0">τ</definiendum>
				<definiens id="0">the ratio of negative margin to the positive margin of the classi er and is equal to 1 in the standard SVM</definiens>
			</definition>
			<definition id="4">
				<sentence>Perceptron is an on-line learning algorithm for linear classi cation .</sentence>
				<definiendum id="0">Perceptron</definiendum>
				<definiens id="0">an on-line learning algorithm for linear classi cation</definiens>
			</definition>
			<definition id="5">
				<sentence>PAUM is simple and fast and performed very well on document classi cation , in particularly on imbalanced training data .</sentence>
				<definiendum id="0">PAUM</definiendum>
				<definiens id="0">simple and fast and performed very well on document classi cation , in particularly on imbalanced training data</definiens>
			</definition>
			<definition id="6">
				<sentence>The Job corpus includes 300 computer related job advertisements and 17 slots encoding job details , such as title , salary , recruiter , computer language , application , and platform .</sentence>
				<definiendum id="0">Job corpus</definiendum>
				<definiens id="0">includes 300 computer related job advertisements and 17 slots encoding job details , such as title , salary , recruiter , computer language , application , and platform</definiens>
			</definition>
			<definition id="7">
				<sentence>CFP corpus consists of 1100 conference or workshop call for papers ( CFP ) , of which 600 were annotated .</sentence>
				<definiendum id="0">CFP corpus</definiendum>
				<definiens id="0">consists of 1100 conference or workshop call for papers ( CFP ) , of which 600 were annotated</definiens>
			</definition>
			<definition id="8">
				<sentence>Table 1 presents the results of our system using three learning algorithms , the uneven margins SVM , the standard SVM and the PAUM on the CONLL2003 test set , together with the results of three participating systems in the CoNLL-2003 shared task : the best system ( Florian et al. , 2003 ) , the SVM-based system ( May eld et al. , 2003 ) and the Perceptron-based system ( Carreras et al. , 2003 ) .</sentence>
				<definiendum id="0">SVM-based system</definiendum>
			</definition>
			<definition id="9">
				<sentence>Our SVM and PAUM systems on their own were respectively in the fourth and fth position among the 20 participating systems .</sentence>
				<definiendum id="0">PAUM</definiendum>
				<definiens id="0">systems on their own were respectively in the fourth and fth position among the 20 participating systems</definiens>
			</definition>
</paper>

		<paper id="1626">
			<definition id="0">
				<sentence>systems Knowledge-based expert systems consist of rules ( or ‘productions’ ) and a knowledge base of facts ( KB ) .</sentence>
				<definiendum id="0">systems Knowledge-based expert systems</definiendum>
				<definiens id="0">consist of rules ( or ‘productions’ ) and a knowledge base of facts ( KB )</definiens>
			</definition>
			<definition id="1">
				<sentence>The Rete networks of production systems ( ‘rete’ is Latin for ‘net’ ) exploit structural similarities between rule antecedents by creating a network that allows facts to match antecedents in several rules at once .</sentence>
				<definiendum id="0">Rete</definiendum>
				<definiens id="0">networks of production systems ( ‘rete’ is Latin for ‘net’ ) exploit structural similarities between rule antecedents by creating a network that allows facts to match antecedents in several rules at once</definiens>
			</definition>
			<definition id="2">
				<sentence>The input to the realizer consists of a bag of semantic tags with associated values in the management succession domain , for example PERSON=Piere Vinken , AGE=61 or POST=chairman .</sentence>
				<definiendum id="0">realizer</definiendum>
				<definiens id="0">consists of a bag of semantic tags with associated values in the management succession domain</definiens>
			</definition>
			<definition id="3">
				<sentence>Conceptually , it consists of two modules : a reasoner that produces logical forms ( descriptions of domain objects ) from a domain representation and a realizer for those logical forms .</sentence>
				<definiendum id="0">realizer</definiendum>
				<definiens id="0">a reasoner that produces logical forms ( descriptions of domain objects</definiens>
			</definition>
			<definition id="4">
				<sentence>The namespace of the realization module is populated with facts that contain syntactic information and surface forms : ( REALIZER : :np ( phon not an instrument ) ( id 35 ) ( dtr-left 5 ) ( dtr-right 11 ) ( num sing ) ( pers 3 ) ( form neq-indefinite ) ) ( REALIZER : :syntax-semantics-mapping ( sem-id 17 ) ( syn-id 35 ) ) The REALIZER : :np fact above is the realization of a corresponding description fact in the LF namespace .</sentence>
				<definiendum id="0">REALIZER</definiendum>
			</definition>
</paper>

		<paper id="0823">
			<definition id="0">
				<sentence>During the last decade , statistical machine translation ( SMT ) systems have evolved from the original word-based approach ( Brown et al. , 1993 ) into phrase-based translation systems ( Koehn et al. , 2003 ) .</sentence>
				<definiendum id="0">SMT</definiendum>
			</definition>
</paper>

		<paper id="0805">
			<definition id="0">
				<sentence>We aim to derive a probability distribution p ( y ) on bilingual phonological units y from a large sample ( p ( c ) denotes the class probability , p ( ysource|c ) is the probability of a phoneme of the source language given class c , and p ( ytarget|c ) is the probability of a phoneme of the target language given class c ) .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the probability of a phoneme of the source language given class c</definiens>
				<definiens id="1">the probability of a phoneme of the target language given class c )</definiens>
			</definition>
</paper>

		<paper id="1617">
			<definition id="0">
				<sentence>More recently , the M-PIRO project [ Isard et al. , 2003 ] developed a multilingual extension of ILEX , which has been tested in a variety of domains , including museum exhibits and items for sale.1 A major problem in this and many other NLG subareas is the difficulty of obtaining source symbolic information in forms compatible with the requirements of the language generators .</sentence>
				<definiendum id="0">M-PIRO project</definiendum>
				<definiens id="0">developed a multilingual extension of ILEX , which has been tested in a variety of domains</definiens>
			</definition>
			<definition id="1">
				<sentence>This would allow computer applications ( e.g. , Web agents visiting the site of a retailer that generates product descriptions using M-PIRO’s technology ) to reason about the semantics of the texts ( e.g , locate items of interest ) .</sentence>
				<definiendum id="0">Web</definiendum>
				<definiens id="0">agents visiting the site of a retailer that generates product descriptions using M-PIRO’s technology ) to reason about the semantics of the texts ( e.g , locate items of interest )</definiens>
			</definition>
</paper>

		<paper id="0204">
			<definition id="0">
				<sentence>This “Landscape Model” ( van den Broek et al. , 1996 ) proves useful for predicting how much students remember from tutoring sessions , as measured by their learning gains .</sentence>
				<definiendum id="0">“Landscape Model”</definiendum>
				<definiens id="0">measured by their learning gains</definiens>
			</definition>
			<definition id="1">
				<sentence>The Landscape Model was designed by van den Broek et al. ( 1996 ) to simulate human reading comprehension .</sentence>
				<definiendum id="0">Landscape Model</definiendum>
				<definiens id="0">designed by van den Broek et al. ( 1996 ) to simulate human reading comprehension</definiens>
			</definition>
			<definition id="2">
				<sentence>We generate a reference average a8a48a47a38a49 a9a11a7a13a12a4a18 by taking 500 random sets of n concepts from the same dialog and averaging their link weights , where n is the number of concepts in the target point 1 .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of concepts in the target point 1</definiens>
			</definition>
			<definition id="3">
				<sentence>The total pointcount for student S is therefore : a0a2a1a4a3a6a5a8a7a52a51a53a1a4a54a55a5a8a7a52a56a21a20 a57 a58 a3a5a4a7a6a27a59a61a60 a0a2a1a4a3a6a5a8a7a10a9a11a7a13a12a15a14a17a16a19a18a55a62 a8a32a47a63a49 a9a11a7a64a12a65a18a67a66 Where P is the total number of points in all dialogs , and T is a threshold function which returns 1 ifa0a68a1a69a3a70a5a8a7a52a9a11a7a13a12a15a14a65a16a19a18a72a71 a8a32a47a63a49 a9a11a7a64a12a65a18 , and 0 otherwise .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">a0a2a1a4a3a6a5a8a7a52a51a53a1a4a54a55a5a8a7a52a56a21a20 a57 a58 a3a5a4a7a6a27a59a61a60 a0a2a1a4a3a6a5a8a7a10a9a11a7a13a12a15a14a17a16a19a18a55a62 a8a32a47a63a49 a9a11a7a64a12a65a18a67a66 Where P is the total number of points in all dialogs , and</definiens>
				<definiens id="1">a threshold function which returns 1 ifa0a68a1a69a3a70a5a8a7a52a9a11a7a13a12a15a14a65a16a19a18a72a71 a8a32a47a63a49 a9a11a7a64a12a65a18 , and 0 otherwise</definiens>
			</definition>
			<definition id="4">
				<sentence>First , the Landscape Model is a model of memory , and our measurements can be interpreted as a measure of what the student is remembering from the tutoring session taken as a whole .</sentence>
				<definiendum id="0">Landscape Model</definiendum>
				<definiens id="0">a model of memory</definiens>
			</definition>
</paper>

		<paper id="0628">
			<definition id="0">
				<sentence>It happens that , in the case of full parses , this node selection strategy is equivalent to the pruning process defined by Xue and Palmer ( 2004 ) , which selects sibling nodes along the path of ancestors from the verb predicate to the root of the tree2 .</sentence>
				<definiendum id="0">full parses</definiendum>
				<definiens id="0">selects sibling nodes along the path of ancestors from the verb predicate to the root of the tree2</definiens>
			</definition>
			<definition id="1">
				<sentence>As a consequence , FPCHA classifiers train faster with less memory requirements , and achieve competitive results ( near the optimal ) with much less rounds of boosting .</sentence>
				<definiendum id="0">FPCHA classifiers</definiendum>
				<definiens id="0">train faster with less memory requirements</definiens>
			</definition>
</paper>

		<paper id="1619">
			<definition id="0">
				<sentence>Surface realization is the process of converting the semantic and syntactic representation of a sentence or series of sentences into a surface form for a particular language .</sentence>
				<definiendum id="0">Surface realization</definiendum>
				<definiens id="0">the process of converting the semantic and syntactic representation of a sentence or series of sentences into a surface form for a particular language</definiens>
			</definition>
			<definition id="1">
				<sentence>AF Punctuation : While most errors involving punctuation marks also contribute very little statistically to the overall score of a sentence ( e.g. , a missing comma ) , the TreeBank also contains combinations of punctuation like long dashes followed by quotation marks .</sentence>
				<definiendum id="0">AF Punctuation</definiendum>
				<definiens id="0">a missing comma ) , the TreeBank also contains combinations of punctuation like long dashes followed by quotation marks</definiens>
			</definition>
			<definition id="2">
				<sentence>AF Mixed conjunctions : Often in the Penn TreeBank the UCP tag ( unlike coordinated phrase ) marks conjunctions where the constituents are not all of the same grammatical category , but in compound verb phrases , they are often marked as simple conjunctions of mixed types .</sentence>
				<definiendum id="0">AF Mixed conjunctions</definiendum>
				<definiendum id="1">UCP tag</definiendum>
				<definiens id="0">unlike coordinated phrase ) marks conjunctions where the constituents are not all of the same grammatical category , but in compound verb phrases</definiens>
			</definition>
</paper>

		<paper id="0902">
			<definition id="0">
				<sentence>Subject B. A manager by qualification and a polyglot by necessity ; English is a second language .</sentence>
				<definiendum id="0">English</definiendum>
				<definiens id="0">a second language</definiens>
			</definition>
</paper>

		<paper id="0835">
			<definition id="0">
				<sentence>The elements of this set are pairs ( ¯x , ¯y ) where ¯y is a possible translation for ¯x. IBM’s model 1 is the simplest of a hierarchy of five statistical models introduced in ( Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">¯y</definiendum>
			</definition>
			<definition id="1">
				<sentence>( 1 ) Where t is the stochastic dictionary and ε represents a table that relates the length of the alignment with the length of the input sentence ( we assume that there is a finite range of possible lengths ) .</sentence>
				<definiendum id="0">t</definiendum>
				<definiens id="0">the stochastic dictionary and ε represents a table that relates the length of the alignment with the length of the input sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>The translation probability can be approximated as follows : pT ( ¯y | ¯x ) = Pr ( M = IBM | ¯x ) pI ( ¯y | ¯x ) + Pr ( M = MAR | ¯x ) pM ( ¯y | ¯x ) .</sentence>
				<definiendum id="0">translation probability</definiendum>
				<definiendum id="1">pT</definiendum>
			</definition>
			<definition id="3">
				<sentence>Note that the probability that ¯y is generated from a pair ( ¯y1 , ¯y2 ) is 0 if ¯y negationslash= ¯y1¯y2 and 1 if ¯y = ¯y1¯y2 , so the last two lines can be rewritten as : summationdisplay ¯y1∈Y+ Pr ( ¯y1 | b , d , ¯x ) summationdisplay ¯y2∈Y+ Pr ( ¯y2 | b , d , ¯x , ¯y1 ) Pr ( ¯y | b , d , ¯x , ¯y1 , ¯y2 ) = summationdisplay ¯y1 , ¯y2∈Y+ ¯y=¯y1¯y2 Pr ( ¯y1 | b , d , ¯x ) Pr ( ¯y2 | b , d , ¯x , ¯y1 ) = summationdisplay ¯y1 ∈ pref ( ¯y ) − ¯y Pr ( ¯y1 | b , d , ¯x ) Pr ( ¯y−11 ¯y | b , d , ¯x , ¯y1 ) = |¯y|−1summationdisplay c=1 Pr ( ¯yc1 | b , d , ¯x ) Pr ( ¯y.c+1 | b , d , ¯x , ¯yc1 ) , 201 where pref ( ¯y ) is the set of prefixes of ¯y. And finally : pM ( ¯y | ¯x ) = |¯x|−1summationdisplay b=1 Pr ( b | ¯x ) summationdisplay d∈ { D , I } Pr ( d | b , ¯x ) |¯y|−1summationdisplay c=1 Pr ( ¯yc1 | b , d , ¯x ) Pr ( ¯y.c+1 | b , d , ¯x , ¯yc1 ) .</sentence>
				<definiendum id="0">pref</definiendum>
				<definiens id="0">the set of prefixes of ¯y. And finally : pM ( ¯y | ¯x ) = |¯x|−1summationdisplay b=1 Pr ( b | ¯x ) summationdisplay d∈ { D , I } Pr ( d | b , ¯x ) |¯y|−1summationdisplay c=1 Pr ( ¯yc1 | b , d , ¯x</definiens>
			</definition>
			<definition id="4">
				<sentence>Then , a new value of P can be computed as follows : N ( P ) = P ∂ V∂ P summationdisplay Q∈F ( P ) Q∂ V∂ Q = summationdisplay ( ¯x , ¯y ) ∈M P pT ( ¯y | ¯x ) ∂ pT ( ¯y | ¯x ) ∂ P summationdisplay Q∈F ( P ) summationdisplay ( ¯x , ¯y ) ∈M Q pT ( ¯y | ¯x ) ∂ pT ( ¯y | ¯x ) ∂ Q = C ( P ) summationdisplay Q∈F ( P ) C ( Q ) , ( 4 ) where C ( P ) = summationdisplay ( ¯x , ¯y ) ∈M P pT ( ¯y | ¯x ) ∂ pT ( ¯y | ¯x ) ∂ P , ( 5 ) are the “counts” of parameter P. This is correct as long as V is a polynomial in P. However , we have a problem for B since V is a rational function of these parameters .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">¯x , ¯y ) ∈M P pT ( ¯y | ¯x ) ∂ pT ( ¯y | ¯x</definiens>
			</definition>
			<definition id="5">
				<sentence>Then Gopalakrishnan’s inequality can be applied similarly and we get : N ( P ) = C +C ( P ) summationdisplay Q∈F ( P ) C +C ( Q ) , ( 6 ) where C is an adequate constant .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">an adequate constant</definiens>
			</definition>
			<definition id="6">
				<sentence>The MAR model can be used to obtain adequate bilingual templates which can be used to translate new test sentences using an appropriate templatebased translation system .</sentence>
				<definiendum id="0">MAR model</definiendum>
				<definiens id="0">bilingual templates which can be used to translate new test sentences using an appropriate templatebased translation system</definiens>
			</definition>
</paper>

		<paper id="1615">
			<definition id="0">
				<sentence>The system being evaluated is SUMTIME-MOUSAM [ Sripada et al , 2003 ] , an NLG system , which generates marine weather forecasts from Numerical Weather Prediction ( NWP ) data .</sentence>
				<definiendum id="0">NLG system</definiendum>
			</definition>
			<definition id="1">
				<sentence>Alignment is a complex activity and is described in detail next .</sentence>
				<definiendum id="0">Alignment</definiendum>
				<definiens id="0">a complex activity and is described in detail next</definiens>
			</definition>
			<definition id="2">
				<sentence>MS is defined as a product of two terms as explained below : • Match score due to degree of match : we assign a match score of 2 for exact matches , 1 for partial matches and 0 for mismatches .</sentence>
				<definiendum id="0">MS</definiendum>
				<definiens id="0">a product of two terms as explained below : • Match score due to degree of match : we assign a match score of 2 for exact matches , 1 for partial matches and 0 for mismatches</definiens>
			</definition>
			<definition id="3">
				<sentence>POS A3 B1 MS conjunction Then &lt; none &gt; 0 Adverb Gradually &lt; none &gt; 0 Verb Increasing &lt; none &gt; 0 Direction &lt; none &gt; SW 0 Speed range 34-39 22-27 0 Time By midnight &lt; none &gt; 0 Table 3 Match Score for A3 and B1 The MS for ( A3 , B2 ) is 2* ( 2*w1+w2 ) where w1 is the weight for Adverb/verb and w2 ( &gt; w1 ) for speed as shown in Table 4 .</sentence>
				<definiendum id="0">w1</definiendum>
				<definiens id="0">the weight for Adverb/verb and w2 ( &gt; w1</definiens>
			</definition>
			<definition id="4">
				<sentence>Segmentation is the process of fitting straight lines to a data set in such a way that a minimum error is introduced by the lines .</sentence>
				<definiendum id="0">Segmentation</definiendum>
			</definition>
			<definition id="5">
				<sentence>We do not know why edit rates vary so much , although it may be significant the individual with the highest ( 93 % ) edit rate is one of the most experienced forecasters , who takes well-justified pride in producing well-crafted forecasts .</sentence>
				<definiendum id="0">edit rate</definiendum>
				<definiens id="0">one of the most experienced forecasters , who takes well-justified pride in producing well-crafted forecasts</definiens>
			</definition>
			<definition id="6">
				<sentence>SUMTIME-MOUSAM : Configurable Marine Weather Forecast Generator .</sentence>
				<definiendum id="0">SUMTIME-MOUSAM</definiendum>
				<definiens id="0">Configurable Marine Weather Forecast Generator</definiens>
			</definition>
			<definition id="7">
				<sentence>: Evaluation of the Linguistic Performance of Machine Translation Systems .</sentence>
				<definiendum id="0">Evaluation</definiendum>
			</definition>
</paper>

		<paper id="0638">
			<definition id="0">
				<sentence>The Semantic Role Labeling problem can be formulated as a sentence tagging problem .</sentence>
				<definiendum id="0">Semantic Role Labeling problem</definiendum>
				<definiens id="0">a sentence tagging problem</definiens>
			</definition>
			<definition id="1">
				<sentence>Incorporation of these two models is realized by weighted summation of P ME and P SVM as follows : P’ = w ME P ME + w SVM P SVM We use P’ for the objective coefficients of the ILP described in Section 2.4 .</sentence>
				<definiendum id="0">P SVM</definiendum>
			</definition>
</paper>

		<paper id="1618">
			<definition id="0">
				<sentence>Instructional texts consist of sequences of instructions designed in order to reach an objective .</sentence>
				<definiendum id="0">Instructional texts</definiendum>
				<definiens id="0">consist of sequences of instructions designed in order to reach an objective</definiens>
			</definition>
			<definition id="1">
				<sentence>We have , for example : a0 regulatory texts [ 16 ] that characterize expected behaviours , a0 procedural texts [ 13 ] defined as rather liear sets of instructions , a0 ’programmatory’ texts [ 11 ] which include receipes , musical scores and architectory plan , identifie how knowledge from an expert is transferred via these texts to users who are expected to follow strictly the instructions which are given .</sentence>
				<definiendum id="0">a0 procedural</definiendum>
				<definiens id="0">rather liear sets of instructions , a0 ’programmatory’ texts [ 11 ] which include receipes , musical scores and architectory plan , identifie how knowledge from an expert is transferred via these texts to users who are expected to follow strictly the instructions which are given</definiens>
			</definition>
			<definition id="2">
				<sentence>G.R. Bieger [ 7 ] propose a taxonomy of the contents of instructions in 9 points : inventory ( objects and concepts used ) , description ( of objects and concepts ) , operational ( information that suggest the agent how to realize an action ) , spatial ( spatial data about the actions ) , contextual , covariance ( of actions , which evolve in conjunction ) , temporal , qualificative ( manners , limits of an information ) , emphatic ( redirects attention to another action ) .</sentence>
				<definiendum id="0">emphatic</definiendum>
				<definiens id="0">propose a taxonomy of the contents of instructions in 9 points : inventory ( objects and concepts used ) , description ( of objects and concepts ) , operational ( information that suggest the agent how to realize an action ) , spatial ( spatial data about the actions ) , contextual , covariance ( of actions , which evolve in conjunction ) , temporal , qualificative ( manners , limits of an information</definiens>
			</definition>
			<definition id="3">
				<sentence>Procedural texts are specific forms of discourse , satisfying constraints of economy of means , accuracy , etc .</sentence>
				<definiendum id="0">Procedural texts</definiendum>
				<definiens id="0">specific forms of discourse , satisfying constraints of economy of means , accuracy , etc</definiens>
			</definition>
			<definition id="4">
				<sentence>Finally , Instruction is the lower level and has the following structure , with recursion on objective : instruction a2 ( iterative expression ) , action , ( reference ) + , ( goal ) + , ( manner ) + , ( motivation ) , ( limit ) , ( picture ) + , ( warning ) / objective .</sentence>
				<definiendum id="0">Instruction</definiendum>
				<definiens id="0">with recursion on objective : instruction a2 ( iterative expression ) , action</definiens>
			</definition>
</paper>

		<paper id="0901">
			<definition id="0">
				<sentence>This paper demonstrates the usefulness of summaries in an extrinsic task of relevance judgment based on a new method for measuring agreement , Relevance-Prediction , which compares subjects’ judgments on summaries with their own judgments on full text documents .</sentence>
				<definiendum id="0">Relevance-Prediction</definiendum>
				<definiens id="0">compares subjects’ judgments on summaries with their own judgments on full text documents</definiens>
			</definition>
			<definition id="1">
				<sentence>Section 5 presents the results of correlation between task usefulness and the Recall Oriented Understudy for Gisting Evaluation ( ROUGE ) metric ( Lin and Hovy , 2003 ) .1 While we show that ROUGE correlates with task usefulness ( using our Relevance-Prediction measure ) , we detect a slight difference between informative , extractive headlines ( containing words from the full document ) and less informative , non-extractive “eye-catchers” ( containing words that might not appear in the full document , and intended to entice a reader to read the entire document ) .</sentence>
				<definiendum id="0">Recall Oriented Understudy for Gisting Evaluation ( ROUGE ) metric</definiendum>
			</definition>
			<definition id="2">
				<sentence>Extrinsic evaluations concentrate on the use of summaries in a specific task , e.g. , executing instructions , information retrieval , question answering , and relevance assessments ( Mani , 2001 ) .</sentence>
				<definiendum id="0">Extrinsic evaluations</definiendum>
			</definition>
			<definition id="3">
				<sentence>LDC-Agreement compares a subject’s judgment on a surrogate or full text against the “correct” judgments as assigned by the TDT corpus annotators ( Linguistic Data Consortium 2001 ) .</sentence>
				<definiendum id="0">LDC-Agreement</definiendum>
			</definition>
			<definition id="4">
				<sentence>Although the HEAD surrogate 4 Surrogate EVENT 1 EVENT 2 EVENT 3 Overall Avg Avg Time LDC RP LDC RP LDC RP LDC RP ( seconds ) HEAD 67 % 76 % 66 % 71 % 70 % 82 % 67 % 76 % 4.60 HUM 69 % 80 % 73 % 86 % 62 % 79 % 68 % 81 % 4.57 DOC — — — — — — — — 13.38 Table 1 : Relevance-Prediction ( RP ) and LDC-Agreement ( LDC ) Rates for HEAD and HUM Surrogates for each Event uses words that do not appear in the original document ( hope and mistakes ) , the subject may infer the relevance of this surrogate by relating hope to the notion of forming a coalition government and mistakes to violence .</sentence>
				<definiendum id="0">Avg Time LDC RP LDC RP LDC RP LDC RP</definiendum>
				<definiens id="0">Relevance-Prediction ( RP ) and LDC-Agreement ( LDC ) Rates for HEAD and HUM Surrogates for each Event uses words that do not appear in the original document ( hope and mistakes ) , the subject may infer the relevance of this surrogate by relating hope to the notion of forming a coalition government and mistakes to violence</definiens>
			</definition>
			<definition id="5">
				<sentence>Partitioned data points of size four provided a high degree of noise reduction without compromising the size of the data set ( 15 points ) .</sentence>
				<definiendum id="0">Partitioned data</definiendum>
				<definiens id="0">points of size four provided a high degree of noise reduction without compromising the size of the data set ( 15 points )</definiens>
			</definition>
			<definition id="6">
				<sentence>5 Surrogate P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 P12 P13 P14 P15 HEAD 80 % 80 % 85 % 70 % 73 % 60 % 80 % 75 % 60 % 75 % 88 % 68 % 80 % 93 % 83 % HUM 83 % 88 % 85 % 68 % 75 % 75 % 93 % 75 % 98 % 90 % 75 % 70 % 80 % 90 % 78 % Table 2 : Relevance-Prediction Rates for HEAD and HUM Surrogates ( Representative Partition of Size 4 ) Surrogate P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 P12 P13 P14 P15 HEAD 70 % 73 % 85 % 70 % 63 % 60 % 60 % 85 % 50 % 73 % 70 % 78 % 65 % 63 % 73 % HUM 68 % 75 % 58 % 68 % 75 % 70 % 68 % 80 % 88 % 58 % 63 % 55 % 55 % 60 % 78 % Table 3 : LDC-Agreement Rates for HEAD and HUM Surrogates ( Representative Partition of Size 4 ) Surrogate P1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 P12 P13 P14 P15 Avg HEAD .10 .23 .13 .27 .20 .24 .26 .22 .13 .08 .30 .16 .26 .27 .30 .211 HUM .16 .22 .17 .23 .19 .36 .39 .29 .28 .25 .37 .22 .22 .39 .27 .269 Table 4 : Average Rouge-1 Scores for HEAD and HUM Surrogates ( Representative Partition of Size 4 ) only ROUGE 1-gram measurement ( R1 ) .9 The ROUGE scores for HEAD surrogates were slightly lower than those for HUM surrogates .</sentence>
				<definiendum id="0">Relevance-Prediction Rates</definiendum>
				<definiens id="0">LDC-Agreement Rates for HEAD and HUM Surrogates ( Representative Partition of Size 4</definiens>
				<definiens id="1">Average Rouge-1 Scores for HEAD and HUM Surrogates ( Representative Partition of Size 4 ) only ROUGE 1-gram measurement</definiens>
			</definition>
			<definition id="7">
				<sentence>To test whether ROUGE correlates more highly with Relevance-Prediction than with LDC-Agreement , we calculated the correlation for the results of both techniques using Pearson’s r ( Siegel and Castellan , 1988 ) : summationtextn i=1 ( ri−¯r ) ( si−¯s ) radicalbigsummationtext n i=1 ( ri−¯r ) 2 radicalbigsummationtextn i=1 ( si−¯s ) 2 where ri is the ROUGE score of surrogate i , ¯r is the average ROUGE score of all data points , si is the agreement score of summary i ( using Relevance-Prediction or LDC-Agreement ) , and ¯s is the average agreement score .</sentence>
				<definiendum id="0">¯r</definiendum>
				<definiendum id="1">si</definiendum>
				<definiendum id="2">¯s</definiendum>
				<definiens id="0">the average ROUGE score of all data points ,</definiens>
				<definiens id="1">the average agreement score</definiens>
			</definition>
</paper>

		<paper id="0213">
			<definition id="0">
				<sentence>The linguistic tools include the following : • A comprehension help that provides students with the most appropriate contextual translation of any word or expression .</sentence>
				<definiendum id="0">comprehension help</definiendum>
				<definiens id="0">provides students with the most appropriate contextual translation of any word or expression</definiens>
			</definition>
			<definition id="1">
				<sentence>Indeed Thetis provides a solution that is strongly web oriented in the sense that it insists on interaction on the web , personalization and information access .</sentence>
				<definiendum id="0">Thetis</definiendum>
				<definiens id="0">provides a solution that is strongly web oriented in the sense that it insists on interaction on the web , personalization and information access</definiens>
			</definition>
</paper>

		<paper id="0712">
			<definition id="0">
				<sentence>The second term ) , ( fe wwEd is length-normalized phonetic based edit distance between the two words .</sentence>
				<definiendum id="0">fe wwEd</definiendum>
				<definiens id="0">length-normalized phonetic based edit distance between the two words</definiens>
			</definition>
			<definition id="1">
				<sentence>The Editex distance ( d ) between two letters a and b is : d ( a , b ) = 0 if both are identical = 1 if they are in the same group = 2 otherwise The Editex distance between two words is the summation of Editex distance between their letters and length-normalized edit distance is : ) | ) || , max ( | ) , ( 1log ( ) , ( fe fe fe ww wwdwwEd −= where ) , ( fe wwd is the “Editex” style edit distance and | ) || , max ( | fe ww is the maximum of the two lengths for the source and target , normalizing the edit distance .</sentence>
				<definiendum id="0">Editex distance</definiendum>
				<definiendum id="1">fe wwd</definiendum>
				<definiens id="0">the summation of Editex distance between their letters and length-normalized edit distance is : ) | ) || , max ( | )</definiens>
			</definition>
			<definition id="2">
				<sentence>89 • Multi-cost Named Entity Alignment by Content Words Elimination In the case of organization and location names ; many content words , which are words other than the NEs , occur in the NE phrases .</sentence>
				<definiendum id="0">many content words</definiendum>
			</definition>
			<definition id="3">
				<sentence>• NEti : the Named Entity target words .</sentence>
				<definiendum id="0">NEti</definiendum>
				<definiens id="0">the Named Entity target words</definiens>
			</definition>
</paper>

		<paper id="0622">
			<definition id="0">
				<sentence>CRFs have been applied with impressive empirical results to the tasks of named entity recognition ( McCallum and Li , 2003 ; Cohn et al. , 2005 ) , part-of-speech ( PoS ) tagging ( Lafferty et al. , 2001 ) , noun phrase chunking ( Sha and Pereira , 2003 ) and extraction of table data ( Pinto et al. , 2003 ) , among other tasks .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiens id="0">the tasks of named entity recognition ( McCallum and Li , 2003 ; Cohn et al. , 2005 ) , part-of-speech ( PoS ) tagging ( Lafferty et al. , 2001</definiens>
			</definition>
			<definition id="1">
				<sentence>We define a CRF over the labelling y given the observation tree x as : p ( y|x ) = 1Z ( x ) expsummationdisplay c∈C summationdisplay k λkfk ( c , yc , x ) where C is the set of cliques in the observation tree , λk are the model’s parameters and fk ( · ) is the feature function which maps a clique labelling to a vector of scalar values .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a CRF over the labelling y given the observation tree x as : p ( y|x ) = 1Z ( x ) expsummationdisplay c∈C summationdisplay k λkfk ( c , yc , x ) where</definiens>
				<definiens id="1">the set of cliques in the observation tree</definiens>
				<definiens id="2">the feature function which maps a clique labelling to a vector of scalar values</definiens>
			</definition>
			<definition id="2">
				<sentence>This can be restated as : p ( y|x ) = 1Z ( x ) exp   summationdisplay v∈C1 summationdisplay k λkgk ( v , yv , x ) + summationdisplay u , v∈C2 summationdisplay j λjhj ( u , v , yu , yv , x )   where C1 are the vertices in the graph and C2 are the maximal cliques in the graph , consisting of all ( parent , child ) pairs .</sentence>
				<definiendum id="0">C2</definiendum>
				<definiens id="0">v , yu , yv , x )   where C1 are the vertices in the graph</definiens>
			</definition>
			<definition id="3">
				<sentence>We have defined node and pairwise clique features using data local to the corresponding syntactic node ( s ) , as well as some features on the predicate itself .</sentence>
				<definiendum id="0">syntactic node</definiendum>
				<definiens id="0">some features on the predicate itself</definiens>
			</definition>
</paper>

		<paper id="0815">
			<definition id="0">
				<sentence>We have used a new model , the MAR ( from the Spanish initials of Recursive Alignment Model ) that allowed us to find structured alignments that were later transformed in a more conventional format .</sentence>
				<definiendum id="0">MAR</definiendum>
				<definiens id="0">from the Spanish initials of Recursive Alignment Model ) that allowed us to find structured alignments that were later transformed in a more conventional format</definiens>
			</definition>
			<definition id="1">
				<sentence>As the model is polynomial on all its parameters except for the cuts ( the B’s ) , BaumEagon’s inequality ( Baum and Eagon , 1967 ) guarantees that normalization of the counts increases the likelihood of the sample .</sentence>
				<definiendum id="0">BaumEagon’s inequality</definiendum>
				<definiens id="0">guarantees that normalization of the counts increases the likelihood of the sample</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>The Spatial Approximation Sample Hierarchy ( SASH ) , proposed by Houle ( 2003b ) , is a data structure for approximate nearestneighbour queries that balances the efficiency/approximation trade-off .</sentence>
				<definiendum id="0">Spatial Approximation Sample Hierarchy ( SASH</definiendum>
				<definiens id="0">a data structure for approximate nearestneighbour queries that balances the efficiency/approximation trade-off</definiens>
			</definition>
			<definition id="1">
				<sentence>A context relation is defined as a tuple ( w , r , w′ ) where w is a term , which occurs in some grammatical relation r with another word w′ in some sentence .</sentence>
				<definiendum id="0">context relation</definiendum>
				<definiendum id="1">w</definiendum>
				<definiens id="0">a term , which occurs in some grammatical relation r with another word w′ in some sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>The SASH requires a distance measure that preserves metric space ( see Section 4.1 ) .</sentence>
				<definiendum id="0">SASH</definiendum>
				<definiens id="0">requires a distance measure that preserves metric space</definiens>
			</definition>
			<definition id="3">
				<sentence>The SASH is a directed , edge-weighted graph with the following properties : • Each term corresponds to a unique node .</sentence>
				<definiendum id="0">SASH</definiendum>
				<definiens id="0">a directed</definiens>
			</definition>
			<definition id="4">
				<sentence>INVR is the sum of the inverse rank of each matching synonym , e.g. matching synonyms at ranks 3 , 5 and 28 give an inverse rank score of 1 3 + 1 5 + 1 28 , and with at most 100 synonyms , the max-imum I NVR score is 5.187 .</sentence>
				<definiendum id="0">INVR</definiendum>
				<definiens id="0">the sum of the inverse rank of each matching synonym</definiens>
			</definition>
			<definition id="5">
				<sentence>This NAIVE HEURISTIC is 14 times faster than NAIVE and 97 % accurate , with 96 % of direct matches .</sentence>
				<definiendum id="0">NAIVE HEURISTIC</definiendum>
				<definiens id="0">14 times faster than NAIVE</definiens>
			</definition>
			<definition id="6">
				<sentence>We have integrated a nearest-neighbour approximation data structure , the Spacial Approximation Sample Hierarchy ( SASH ) , with a state-of-the-art distributional similarity system .</sentence>
				<definiendum id="0">Spacial Approximation Sample Hierarchy</definiendum>
				<definiens id="0">with a state-of-the-art distributional similarity system</definiens>
			</definition>
</paper>

		<paper id="0708">
			<definition id="0">
				<sentence>Part-of-speech ( POS ) tagging is a core natural language processing task that can benefit a wide range of downstream processing applications .</sentence>
				<definiendum id="0">Part-of-speech ( POS ) tagging</definiendum>
				<definiens id="0">a core natural language processing task that can benefit a wide range of downstream processing applications</definiens>
			</definition>
			<definition id="1">
				<sentence>• Dialectal Arabic is a spoken language .</sentence>
				<definiendum id="0">Dialectal Arabic</definiendum>
				<definiens id="0">a spoken language</definiens>
			</definition>
			<definition id="2">
				<sentence>The resources available to us are the CallHome Egyptian Colloquial Arabic ( ECA ) corpus , the LDC Levantine Arabic ( LCA ) corpus , the LDC MSA Treebank corpus , and a generally available morphological analysis tool ( the LDC-distributed Buckwalter stemmer ) for MSA .</sentence>
				<definiendum id="0">LDC MSA Treebank</definiendum>
				<definiens id="0">the CallHome Egyptian Colloquial Arabic ( ECA ) corpus , the LDC Levantine Arabic ( LCA ) corpus , the</definiens>
			</definition>
			<definition id="3">
				<sentence>The ECA corpus consists of telephone conversations between family members or close friends , with one speaker being located in the U.S. and the other in Egypt .</sentence>
				<definiendum id="0">ECA corpus</definiendum>
				<definiens id="0">consists of telephone conversations between family members or close friends , with one speaker being located in the U.S. and the other in Egypt</definiens>
			</definition>
			<definition id="4">
				<sentence>The LCA data consists of telephone conversations on pre-defined topics between Levantine speakers previously unknown to each other ; all of the available data was used .</sentence>
				<definiendum id="0">LCA data</definiendum>
				<definiens id="0">consists of telephone conversations on pre-defined topics between Levantine speakers previously unknown to each other ; all of the available data was used</definiens>
			</definition>
			<definition id="5">
				<sentence>Our taggers are implemented using the Graphical Models Toolkit ( GMTK ) ( Bilmes and Zweig , 2002 ) , which allows training a wide range of probabilistic models with both hidden and observed variables .</sentence>
				<definiendum id="0">Graphical Models Toolkit</definiendum>
				<definiens id="0">allows training a wide range of probabilistic models with both hidden and observed variables</definiens>
			</definition>
			<definition id="6">
				<sentence>The MSA-trained tagger ( System I ) achieves an accuracy of 97 % on a held-out set ( 117k words ) of MSA data , but performs poorly on ECA due to a high OOV rate ( 43 % ) .</sentence>
				<definiendum id="0">MSA-trained tagger ( System I )</definiendum>
				<definiens id="0">achieves an accuracy of 97 % on a held-out set ( 117k words ) of MSA data , but performs poorly on ECA due to a high OOV rate ( 43 % )</definiens>
			</definition>
			<definition id="7">
				<sentence>Parallel corpora have also been used to infer morphological analyzers , POS taggers , and noun phrase bracketers by projections via word alignments ( Yarowsky et al. , 2001 ) .</sentence>
				<definiendum id="0">POS</definiendum>
			</definition>
			<definition id="8">
				<sentence>Contextual model interpolation is a widely-used data-sharing technique which assumes that models trained on data from different sources can be “mixed” in order to provide the most appropriate probability distribution for the target data .</sentence>
				<definiendum id="0">Contextual model interpolation</definiendum>
			</definition>
			<definition id="9">
				<sentence>In our case , we have LCA as an out-of-domain data source , and ECA as the in-domain data source , with the former being about 4 times larger than the latter .</sentence>
				<definiendum id="0">ECA</definiendum>
				<definiens id="0">an out-of-domain data source , and</definiens>
			</definition>
</paper>

		<paper id="1521">
			<definition id="0">
				<sentence>If the pair pi1 and pi2 is in Λ , then together with it will be included in ¯Λ all pairs of QC-paths such that pi1η and pi2η , where η is a feature path ( a common suffix to the two newly selected paths ) .</sentence>
				<definiendum id="0">pi2</definiendum>
				<definiendum id="1">η</definiendum>
				<definiens id="0">a feature path ( a common suffix to the two newly selected paths )</definiens>
			</definition>
</paper>

		<paper id="0406">
			<definition id="0">
				<sentence>A memory-based learning algorithm classifies new instances on the basis of their similarity to instances seen in the training data .</sentence>
				<definiendum id="0">memory-based learning algorithm</definiendum>
				<definiens id="0">classifies new instances on the basis of their similarity to instances seen in the training data</definiens>
			</definition>
			<definition id="1">
				<sentence>Evans chose the k-nearest neighbor algorithm from the Tilburg Memory-Based Learner ( TiMBL ) package ( Daelemans et al. , 2003 ) with approximately 35 features relevant to the 7-way classification .</sentence>
				<definiendum id="0">Tilburg Memory-Based Learner</definiendum>
				<definiens id="0">Daelemans et al. , 2003 ) with approximately 35 features relevant to the 7-way classification</definiens>
			</definition>
</paper>

		<paper id="0111">
			<definition id="0">
				<sentence>The NL Toolkit is a set of libraries written in the Python programming language that provides core data types for processing natural language text , support for statistical processing , and a number of standard processing algorithms used in NLP , including tokenization , part of speech ( POS ) tagging , chunk parsing , and syntactic parsing .</sentence>
				<definiendum id="0">NL Toolkit</definiendum>
				<definiens id="0">a set of libraries written in the Python programming language that provides core data types for processing natural language text , support for statistical processing , and a number of standard processing algorithms used in NLP , including tokenization , part of speech ( POS ) tagging , chunk parsing , and syntactic parsing</definiens>
			</definition>
			<definition id="1">
				<sentence>Again , NL Toolkit provides a library for chunk parsing where regular expressions can be used to specify patterns of words with POS tags either to be included or excluded from phrases .</sentence>
				<definiendum id="0">NL Toolkit</definiendum>
			</definition>
			<definition id="2">
				<sentence>For this , success is measured by : whether students elect to do continued work in NLP , either in the context of further courses in which NLP is utilized , such as Information Retrieval or Text Mining ; whether the masters ( and undergraduate ) students decide to pursue an advanced degree based on the excitement engendered and knowledge gained from the NLP course ; or whether PhD students elect to do continued research either in the school’s Center for Natural Language Processing or as part of their dissertation .</sentence>
				<definiendum id="0">success</definiendum>
			</definition>
</paper>

		<paper id="1304">
			<definition id="0">
				<sentence>The data set consists of 1,901 definition-acronym pairs .</sentence>
				<definiendum id="0">data set</definiendum>
			</definition>
</paper>

		<paper id="1527">
			<definition id="0">
				<sentence>We describe SUPPLE , a freely-available , open source natural language parsing system , implemented in Prolog , and designed for practical use in language engineering ( LE ) applications .</sentence>
				<definiendum id="0">SUPPLE</definiendum>
				<definiens id="0">a freely-available , open source natural language parsing system , implemented in Prolog , and designed for practical use in language engineering ( LE ) applications</definiens>
			</definition>
			<definition id="1">
				<sentence>SUPPLE is a general purpose bottom-up chart parser for feature-based context free phrase structure gram∗ At Microsoft Corporation since 2000 ( Speech and Natural Language Group ) .</sentence>
				<definiendum id="0">SUPPLE</definiendum>
			</definition>
			<definition id="2">
				<sentence>mars ( CF-PSGs ) , written in Prolog , that has a number of characteristics making it well-suited for use in LE applications .</sentence>
				<definiendum id="0">mars</definiendum>
			</definition>
</paper>

		<paper id="1208">
			<definition id="0">
				<sentence>Accordingly , W denotes the set of all possible worlds .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">the set of all possible worlds</definiens>
			</definition>
			<definition id="1">
				<sentence>When estimating the entailment probability we assume that the truth probability of a term u in a hypothesis h is independent of the truth of the other terms in h , obtaining : P ( Trh = 1| t ) = Πu∈hP ( Tru=1|t ) P ( Trh = 1 ) = Πu∈hP ( Tru=1 ) ( 1 ) In order to estimate P ( Tru=1|v1 , … , vn ) for a given word u and text t= { v1 , … , vn } , we further assume that the majority of the probability mass comes from a specific entailing word in t : ) |1 ( max ) |1 ( vutvu TTrtTr =Ρ==Ρ ∈ ( 2 ) where Tv denotes the event that a generated text contains the word v. This corresponds to expecting that each word in h will be entailed from a specific word in t ( rather than from the accumulative context of t as a whole2 ) .</sentence>
				<definiendum id="0">Tv</definiendum>
				<definiens id="0">order to estimate P ( Tru=1|v1 , … , vn ) for a given word u and text t= { v1 , … , vn }</definiens>
			</definition>
			<definition id="2">
				<sentence>This simple co-occurrence probability , which we denote as lexical entailment probability – lep ( u , v ) , is easily estimated from the corpus based on maximum likelihood counts : v vu vu n nTTrvulep , ) |1 ( ) , ( ≈=Ρ= ( 4 ) where nv is the number of documents containing word v and nu , v is the number of documents containing both u and v. Given our definition of the textual entailment relationship ( cf. Section 2.3 ) for a given word v we only consider for entailment words u for which P ( Tru=1|Tv ) &gt; P ( Tru=1 ) or based on our estimations , for which nu , v/nu &gt; nv/N ( N is total number of documents in the corpus ) .</sentence>
				<definiendum id="0">simple co-occurrence probability</definiendum>
				<definiendum id="1">nv</definiendum>
				<definiendum id="2">v</definiendum>
				<definiens id="0">lexical entailment probability – lep ( u , v ) , is easily estimated from the corpus based on maximum likelihood counts : v vu vu n nTTrvulep , ) |1 ( )</definiens>
				<definiens id="1">the number of documents containing word v and nu</definiens>
				<definiens id="2">the number of documents containing both u and v. Given our definition of the textual entailment relationship ( cf. Section 2.3 ) for a given word v we only consider for entailment words u for which P ( Tru=1|Tv ) &gt; P ( Tru=1 ) or based on our estimations , for which nu</definiens>
			</definition>
			<definition id="3">
				<sentence>( Monz and de Rijke , 2001 ) propose modeling the directional entailment between two texts t1 , t2 via the following score : ∑ ∑ ∈ ∩∈= 2 21 ) ( ) ( ) , ( ) ( 21 tw ttw widf widf ttentscore ( 6 ) where idf ( w ) = log ( N/nw ) , N is total number of documents in corpus and nw is number of docu46 ments containing word w. A practically equivalent measure was independently proposed in the context of QA by ( Saggion et al. , 2004 ) 3 .</sentence>
				<definiendum id="0">idf</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">nw</definiendum>
				<definiens id="0">total number of documents in corpus</definiens>
			</definition>
</paper>

		<paper id="0109">
</paper>

		<paper id="0705">
			<definition id="0">
				<sentence>34 5 face-form , part-of-speech-tag , and lemma ) gives rise to a new node , the graph becomes larger , increasing the number of paths that all processing steps must explore .</sentence>
				<definiendum id="0">lemma )</definiendum>
				<definiens id="0">gives rise to a new node , the graph becomes larger , increasing the number of paths that all processing steps must explore</definiens>
			</definition>
			<definition id="1">
				<sentence>A version of our CLIR is available online and illustrated in this article .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">available online and illustrated in this article</definiens>
			</definition>
</paper>

		<paper id="1607">
			<definition id="0">
				<sentence>Following this observation , we treat an object as a candidate landmark if the trajector object can be distinguished from it using the basic incremental algorithm , Algorithm 1.5 Furthermore , a trajector landmark is a member of the candidate landmark set that stands in relation to the trajector and a distractor landmark is a member of the candidate landmark set that stands in relation to a distractor object under the relation being considered .</sentence>
				<definiendum id="0">trajector landmark</definiendum>
				<definiendum id="1">distractor landmark</definiendum>
				<definiens id="0">a member of the candidate landmark set that stands in relation to the trajector and a</definiens>
				<definiens id="1">a member of the candidate landmark set that stands in relation to a distractor object under the relation being considered</definiens>
			</definition>
			<definition id="1">
				<sentence>This partitioning has two advantages : struction , as the relationships between the trajector and the distractor objects or between the distractor objects themselves do not need to be computed ; description is always a subset of the context used for a trajector ( as the trajector , its distractors and the other objects in the domain that do not stand in relation to the trajector or distractors under the relation being considered are excluded ) .</sentence>
				<definiendum id="0">struction</definiendum>
				<definiens id="0">the relationships between the trajector and the distractor objects or between the distractor objects themselves do not need to be computed ; description is always a subset of the context used for a trajector</definiens>
			</definition>
</paper>

		<paper id="0209">
			<definition id="0">
				<sentence>Direkt Profil is an automatic analyzer of texts written in French as a second language .</sentence>
				<definiendum id="0">Direkt Profil</definiendum>
				<definiens id="0">an automatic analyzer of texts written in French as a second language</definiens>
			</definition>
			<definition id="1">
				<sentence>Direkt Profilisananalyzer oftextswritteninFrench as a foreign language .</sentence>
				<definiendum id="0">Direkt Profilisananalyzer oftextswritteninFrench</definiendum>
				<definiens id="0">a foreign language</definiens>
			</definition>
			<definition id="2">
				<sentence>A graphical user interface ( GUI ) shows the results to the user and visualizes by different colors the detected structures .</sentence>
				<definiendum id="0">GUI )</definiendum>
				<definiens id="0">shows the results to the user and visualizes by different colors the detected structures</definiens>
			</definition>
			<definition id="3">
				<sentence>2 An “unknown word” is a token that does not appear in the lexicon employed by the system ( ABUCNAM , see below ) 54 Figure 1 : Le voyage en Italie “The journey to Italy” .</sentence>
				<definiendum id="0">ABUCNAM</definiendum>
				<definiens id="0">a token that does not appear in the lexicon employed by the system</definiens>
			</definition>
			<definition id="4">
				<sentence>Conceptually , the analyzer seeks classes of phrase structures in which all the features are removed .</sentence>
				<definiendum id="0">analyzer</definiendum>
				<definiens id="0">seeks classes of phrase structures in which all the features are removed</definiens>
			</definition>
			<definition id="5">
				<sentence>Direkt Profil applies a cascade of three sets of rules to produce the four annotation layers .</sentence>
				<definiendum id="0">Direkt Profil</definiendum>
				<definiens id="0">applies a cascade of three sets of rules to produce the four annotation layers</definiens>
			</definition>
			<definition id="6">
				<sentence>Finally , the engine creates a group of results and connects them to a profile .</sentence>
				<definiendum id="0">engine</definiendum>
				<definiens id="0">creates a group of results and connects them to a profile</definiens>
			</definition>
</paper>

		<paper id="0827">
			<definition id="0">
				<sentence>Statistical Machine Translation ( SMT ) is based on the assumption that every sentence e in the target language is a possible translation of a given sentence f in the source language .</sentence>
				<definiendum id="0">Statistical Machine Translation ( SMT</definiendum>
				<definiens id="0">based on the assumption that every sentence e in the target language is a possible translation of a given sentence f in the source language</definiens>
			</definition>
			<definition id="1">
				<sentence>A monolingual phrase is a sequence of words .</sentence>
				<definiendum id="0">monolingual phrase</definiendum>
			</definition>
			<definition id="2">
				<sentence>The length of a BP is the greatest of the lengths of its MP .</sentence>
				<definiendum id="0">length of a BP</definiendum>
				<definiens id="0">the greatest of the lengths of its MP</definiens>
			</definition>
			<definition id="3">
				<sentence>P ( f|e ) = N ( f , e ) N ( e ) ( 4 ) where N ( f , e ) means the number of times the phrase f is translated by e. If a phrase e has N &gt; 1 possible translations , then each one contributes as 1/N [ 17 ] .</sentence>
				<definiendum id="0">e )</definiendum>
				<definiens id="0">means the number of times the phrase f is translated by e. If a phrase e has N &gt; 1 possible translations</definiens>
			</definition>
			<definition id="4">
				<sentence>P ( f|e ; M1 ) = 1 ( I + 1 ) J Jproductdisplay j=1 Isummationdisplay i=0 p ( fj|ei ) ( 6 ) The p ( fj|ei ) are the source-target IBM Model 1 word probabilities trained by GIZA++ .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
			<definition id="5">
				<sentence>In addition , we have calculated the IBM−1 Model P ( e|f ; M1 ) = 1 ( J + 1 ) I Iproductdisplay I=1 Jsummationdisplay j=0 p ( ei|fj ) ( 7 ) The English language model plays an important role in the source channel model , see equation ( 2 ) , and also in its modification , see equation ( 3 ) .</sentence>
				<definiendum id="0">language model</definiendum>
				<definiens id="0">plays an important role in the source channel model</definiens>
			</definition>
			<definition id="6">
				<sentence>The phrase penalty is a constant cost per produced phrase .</sentence>
				<definiendum id="0">phrase penalty</definiendum>
				<definiens id="0">a constant cost per produced phrase</definiens>
			</definition>
</paper>

		<paper id="1511">
			<definition id="0">
				<sentence>HPSG ( Pollard and Sag , 1994 ) is a syntactic theory based on lexicalized grammar formalism .</sentence>
				<definiendum id="0">HPSG</definiendum>
				<definiens id="0">a syntactic theory based on lexicalized grammar formalism</definiens>
			</definition>
			<definition id="1">
				<sentence>Given set W of words and set F of feature structures , an HPSG is formulated as a tuple , G = 〈L , R〉 , where L = { l = 〈w , F〉|w ∈ W , F ∈ F } is a set of lexical entries , and R is a set of schemata , i.e. , r ∈ R is a partial function : F ×F → F. Given a sentence , an HPSG computes a set of phrasal signs , i.e. , feature structures , as a result of parsing .</sentence>
				<definiendum id="0">HPSG</definiendum>
				<definiendum id="1">R</definiendum>
				<definiendum id="2">HPSG</definiendum>
				<definiens id="0">a set of schemata , i.e. , r ∈ R is a partial function</definiens>
				<definiens id="1">computes a set of phrasal signs , i.e. , feature structures</definiens>
			</definition>
			<definition id="2">
				<sentence>Previous studies ( Abney , 1997 ; Johnson et al. , 1999 ; Riezler et al. , 2000 ; Miyao et al. , 2003 ; Malouf and van Noord , 2004 ; Kaplan et al. , 2004 ; Miyao and Tsujii , 2005 ) defined a probabilistic model of unification-based grammars as a log-linear model or maximum entropy model ( Berger et al. , 1996 ) .</sentence>
				<definiendum id="0">Previous studies</definiendum>
			</definition>
			<definition id="3">
				<sentence>The probability of parse result T assigned to given sentence w = 〈w1 , ... , wn〉 is p ( T|w ) = 1Z w exp parenleftBiggsummationdisplay i λifi ( T ) parenrightBigg Zw = summationdisplay T prime exp parenleftBiggsummationdisplay i λifi ( Tprime ) parenrightBigg , where λi is a model parameter , and fi is a feature function that represents a characteristic of parse tree T. Intuitively , the probability is defined as the normalized product of the weights exp ( λi ) when a characteristic corresponding to fi appears in parse result T. Model parameters λi are estimated using numer104 ical optimization methods ( Malouf , 2002 ) so as to maximize the log-likelihood of the training data .</sentence>
				<definiendum id="0">fi</definiendum>
				<definiendum id="1">probability</definiendum>
				<definiens id="0">The probability of parse result T assigned to given sentence w = 〈w1 , ... , wn〉 is p ( T|w ) = 1Z w exp parenleftBiggsummationdisplay i λifi ( T ) parenrightBigg Zw = summationdisplay T prime exp parenleftBiggsummationdisplay i λifi ( Tprime ) parenrightBigg , where λi is a model parameter , and</definiens>
				<definiens id="1">a feature function that represents a characteristic of parse tree T. Intuitively , the</definiens>
			</definition>
			<definition id="4">
				<sentence>Large constituent inhibition prevents the parser from generating medial edges that span more than some word length .</sentence>
				<definiendum id="0">Large constituent inhibition</definiendum>
				<definiens id="0">prevents the parser from generating medial edges that span more than some word length</definiens>
			</definition>
			<definition id="5">
				<sentence>The principal idea of using the chunk parser is to use the bracket information , i.e. , parse trees without non-terminal symbols , and prevent the HPSG parser from generating edges that cross brackets .</sentence>
				<definiendum id="0">chunk parser</definiendum>
			</definition>
			<definition id="6">
				<sentence>The CYK algorithm , which is essentially a bottomup parser , is a natural choice for non-probabilistic HPSG parsers .</sentence>
				<definiendum id="0">CYK algorithm</definiendum>
			</definition>
			<definition id="7">
				<sentence>Beam thresholding ( Goodman , 1997 ) is a simple and effective technique for pruning edges during parsing .</sentence>
				<definiendum id="0">Beam thresholding</definiendum>
				<definiens id="0">a simple and effective technique for pruning edges during parsing</definiens>
			</definition>
			<definition id="8">
				<sentence>Local thresholding by beam width Each cell keeps the edges whose FOM is greater than αmax − δ , where αmax is the highest FOM among the edges in the cell .</sentence>
				<definiendum id="0">αmax</definiendum>
				<definiens id="0">Local thresholding by beam width Each cell keeps the edges whose FOM is greater than αmax − δ</definiens>
			</definition>
			<definition id="9">
				<sentence>The global FOM of an edge is defined as its FOM plus its forward and backward FOMs , where the forward and backward FOMs are rough estimations of the outside FOM of the edge .</sentence>
				<definiendum id="0">FOM of an edge</definiendum>
			</definition>
			<definition id="10">
				<sentence>Time ( ms ) No. of failed sentences development set 88.21 % 87.32 % 87.76 % 360 12 test set 87.85 % 86.85 % 87.35 % 360 15 Figure 7 : Parsing time for the sentences in Section 24 of less than 15 words of Viterbi parsing ( none ) ( Left ) and iterative parsing ( iterative ) ( Right ) Figure 6 : Parsing time versus sentence length for the sentences in Section 23 of less than 40 words We evaluated the efficiency of the parsing techniques by using the HPSG for English developed by Miyao et al. ( 2005 ) .</sentence>
				<definiendum id="0">Time</definiendum>
				<definiendum id="1">iterative parsing</definiendum>
				<definiens id="0">Parsing time for the sentences in Section 24 of less than 15 words of Viterbi parsing</definiens>
			</definition>
			<definition id="11">
				<sentence>A predicate-argument relation is defined as a tuple 〈σ , wh , a , wa〉 , where σ is the predicate type ( e.g. , adjective , intransitive verb ) , wh is the head word of the predicate , a is the argument label ( MODARG , ARG1 , ... , ARG4 ) , and wa is the head word of the argument .</sentence>
				<definiendum id="0">predicate-argument relation</definiendum>
				<definiendum id="1">σ</definiendum>
				<definiendum id="2">MODARG , ARG1 , ... , ARG4</definiendum>
				<definiendum id="3">wa</definiendum>
				<definiens id="0">a tuple 〈σ , wh , a , wa〉 , where</definiens>
				<definiens id="1">the predicate type ( e.g. , adjective , intransitive verb ) , wh is the head word of the predicate</definiens>
			</definition>
			<definition id="12">
				<sentence>Precision/recall is the ratio of tuples correctly identified by the parser .</sentence>
				<definiendum id="0">Precision/recall</definiendum>
				<definiens id="0">the ratio of tuples correctly identified by the parser</definiens>
			</definition>
</paper>

		<paper id="0611">
			<definition id="0">
				<sentence>Boosting ( Freund and Schapire , 1996 ) has been applied to optimize chunking systems ( Carreras et al. , 2002 ) , as well as voting over sets of different classifiers ( Florian et al. , 2003 ) .</sentence>
				<definiendum id="0">Boosting</definiendum>
			</definition>
			<definition id="1">
				<sentence>Maximum-entropy markov models ( McCallum et al. , 2000 ) and conditional random fields ( Lafferty et al. , 2001 ) optimize the likelihood of segmentations of output symbol sequences through variations of Viterbi search .</sentence>
				<definiendum id="0">Maximum-entropy markov models</definiendum>
				<definiens id="0">McCallum et al. , 2000 ) and conditional random fields ( Lafferty et al. , 2001 ) optimize the likelihood of segmentations of output symbol sequences through variations of Viterbi search</definiens>
			</definition>
			<definition id="2">
				<sentence>A closer analysis indicated that the two methods appear to render each other ineffective : by feeding back predicted trigrams in the input , the classifier is very much geared towards predicting a next trigram that will be in accordance with the two partly overlapping trigrams in the input , as suggested by overwhelming evidence in this direction in training material – this problem is also known as the label bias problem ( Lafferty et al. , 2001 ) .</sentence>
				<definiendum id="0">closer analysis</definiendum>
			</definition>
</paper>

		<paper id="1525">
			<definition id="0">
				<sentence>The TRIPS LF provides the necessary information for reference resolution , surface speech act analysis , and interpretations for a wide variety of fragmentary utterances and conventional phrases typical in dialog .</sentence>
				<definiendum id="0">TRIPS LF</definiendum>
				<definiens id="0">provides the necessary information for reference resolution , surface speech act analysis , and interpretations for a wide variety of fragmentary utterances and conventional phrases typical in dialog</definiens>
			</definition>
			<definition id="1">
				<sentence>Bikel-M performs somewhat better on the bracketing task for the entire test set , which includes utterances for which TRIPS failed to nd a parse , but it is lower on complete matches , which are crucial for semantic interpretation .</sentence>
				<definiendum id="0">Bikel-M</definiendum>
				<definiens id="0">performs somewhat better on the bracketing task for the entire test set , which includes utterances for which TRIPS failed to nd a parse , but it is lower on complete matches , which are crucial for semantic interpretation</definiens>
			</definition>
			<definition id="2">
				<sentence>Word senses are an important part of the LF representation , so we also evaluated TRIPS on word sense tagging against a baseline of the most common word senses in Monroe .</sentence>
				<definiendum id="0">Word senses</definiendum>
				<definiens id="0">an important part of the LF representation , so we also evaluated TRIPS on word sense tagging against a baseline of the most common word senses in Monroe</definiens>
			</definition>
</paper>

		<paper id="1605">
			<definition id="0">
				<sentence>Briefly1 , a Feature-based TAG consists of a set of ( auxiliary or initial ) elementary trees and of two tree composition operations : substitution and adjunction .</sentence>
				<definiendum id="0">Feature-based TAG</definiendum>
				<definiens id="0">consists of a set of ( auxiliary or initial ) elementary trees and of two tree composition operations : substitution and adjunction</definiens>
			</definition>
			<definition id="1">
				<sentence>The combination column indicates which tree combines with which tree by means of which operation ( ↓ indicates a substitution , ⋆ an adjunction ) .</sentence>
				<definiendum id="0">combination column</definiendum>
				<definiens id="0">indicates which tree combines with which tree by means of which operation ( ↓ indicates a substitution , ⋆ an adjunction )</definiens>
			</definition>
			<definition id="2">
				<sentence>The trees resulting from such a combination are represented using the concatenation of the names of the combined trees ( jeanCampe is the tree resulting from the combination of the tree anchored by Jean with that anchored by campe ) .</sentence>
				<definiendum id="0">jeanCampe</definiendum>
				<definiens id="0">the tree resulting from the combination of the tree anchored by Jean with that anchored by campe )</definiens>
			</definition>
			<definition id="3">
				<sentence>More generally , the selection constraints allowed are syntactico-semantic constraints of the form Synt : SemIndex where Synt is a morpho-syntactic feature ( declarative , interrogative , cleft , pronoun , etc. ) and SemIndex is an index occurring in the input semantics .</sentence>
				<definiendum id="0">Synt</definiendum>
				<definiendum id="1">SemIndex</definiendum>
				<definiens id="0">a morpho-syntactic feature ( declarative , interrogative , cleft , pronoun , etc.</definiens>
				<definiens id="1">an index occurring in the input semantics</definiens>
			</definition>
			<definition id="4">
				<sentence>In particular , the hypertag of the tree with clefted subject of the n0vn1 family ( i.e. , the set of verbs taking two nominal arguments ) will contain the property +cleft : X where X is the semantic index associated with the subject node .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">the semantic index associated with the subject node</definiens>
			</definition>
			<definition id="5">
				<sentence>During lexical selection , this index is instantiated by unification with the input so that the selected elementary tree for regarde will have the property +cleft : j. Conversely , a restrictor is a property that a lexical item intervening in the production of the generated paraphrases must have .</sentence>
				<definiendum id="0">restrictor</definiendum>
				<definiens id="0">a property that a lexical item intervening in the production of the generated paraphrases must have</definiens>
			</definition>
			<definition id="6">
				<sentence>Bangalore assumes a single derivation tree that encodes a word lattice ( a { fierce black , black fierce } cat ) , and uses statistical knowledge to select the best linearilisation .</sentence>
				<definiendum id="0">Bangalore</definiendum>
				<definiens id="0">assumes a single derivation tree that encodes a word lattice ( a { fierce black , black fierce } cat ) , and uses statistical knowledge to select the best linearilisation</definiens>
			</definition>
			<definition id="7">
				<sentence>A post processing phase produces the derived trees on the basis of the derivation trees output by the first step .</sentence>
				<definiendum id="0">post processing phase</definiendum>
				<definiens id="0">produces the derived trees on the basis of the derivation trees output by the first step</definiens>
			</definition>
			<definition id="8">
				<sentence>The most efficient optimisation proposed concerns polarity filtering , a global technique that permits the elimination of combinations of lexical items which can not possibly lead to a syntactically valid sentence .</sentence>
				<definiendum id="0">most efficient optimisation proposed concerns polarity filtering</definiendum>
				<definiens id="0">a global technique that permits the elimination of combinations of lexical items which can not possibly lead to a syntactically valid sentence</definiens>
			</definition>
</paper>

		<paper id="1606">
			<definition id="0">
				<sentence>Determine probability of identification ( D , k , O1 , … , On ) O1 , … , Om Objects to which descriptor D applies Om+1 , … , On Objects to which repair with D is applicable pi , … , pm Probability that D is recognized for Oi Objects ordered along degrees of recognition confidence : ∀i , j ( 1 ≤ i , j ≤ m ) : ( pi &gt; pj ) → ( i &gt; j ) Rprop ← R ( k , p1 , … , pm ) , i ← 1 then Rc ← Min ( Rprop/n , 1-pi ) , p-idi ← pi+Rc else Rc ← Rprop/n , p-idi ← Rc endif if ( i &lt; n ) then i ← i+1 , Rprop ← Rprop Rc , goto 1 endif Figure 2. Assessing identification probabilities including repair In order to keep the repair mechanism simple , we approximate confusability of an object by augmenting its representation with annotations of all property-value combinations that do not apply to it , but which could somehow be perceived as holding for this object. The potentially large amount of data created this way can be significantly reduced by making use of inheritance. For example , one can state that blue and purple ( physical ) objects can be confused , by making annotations about confusability with blue for purple objects , and vice-versa. This annotation is then inherited to all entities that are specializations of ( physical ) objects. The proper repair is then simulated by collecting all candidates to which the descriptor in question could arguably apply , and by assigning these candidates a probability of identification through repair , according to the repair factor , as assessed above. There are two kinds of candidates : ( 1 ) those to which the descriptor is recognized with some probability , and ( 2 ) those to which it could apply with some relaxation , that is , which contains a suitable confusability annotation. The repair factor , which is computed according to the schema in Figure 1 , is then evenly distributed among these two sets of candidates , provided the added probabilities of recognition and repair do not get greater than 1 for some object ; this can only be the case if the number of objects to identify is close to the number of candidates. In such a case , the extra amount is distributed recursively among the remaining candidates , always respecting the upper limit of 1. If the number of objects to identify even exceeds the number of candidates , the effect of the repair mechanism results in a modification of the number of objects to identify , reducing it to the number of available candidates. The computation of the probability of identification through repair is illustrated in Figure 2. Three examples in Figure 3 illustrate the effect of the repair mechanism in quantitative terms. They emphasize the relation between expectations about the number of objects to be identified and probabilities of identification. For k objects to be identified out of n , judging identification by descriptor D , which may involve repair measures ( D applies to m out of these n with probabilities pi , … , pm ) p-id1 = 0.83 , p-id2 = 0.43 , p-id3 = p-id4 = 0.03 p-id1 = 1 , p-id2 = 0.6533 , p-id3 = p-id4 = 0.2533 p-id1 = 1 , p-id2 = 1 , p-id3 = p-id4 = 0.65 Figure 3. Examples of assessing identification probabilities Specifically , the increasing contributions of the repair facility are shown , which will be even more pronounced with several attributes associated with limited recognition expectations. We will see this effect in context with building descriptor combination in the next section , as well as in the detailed exposition of an example in Appendix II. Since a single descriptor is rarely sufficient for identifying one or several objects in scenarios of interesting complexity , boolean compositions of descriptors are generated for this purpose , conjunctions being required for building identifying expressions for single objects. Their probability of recognition is a simple extension of the case of single descriptors. If pi is the probability of recognition of descriptor Di for some object O , an expression consisting of several Di ( i=1 , pn ) is identified with O through recognition if all Di are attributed to O. The probability of this coincidence amounts to the product of all probabilities Πpi ( i=1 , pn ) . The probability of identification through repair is computed by distributing the repair factor R ( k , P1 , … , Pm ) , where each Pj=Πpji ( j=1 , m ; i=1 , pn ) , among all objects qualifying for the repair measure. While this distribution is an equal one for the case of a single descriptor , apart from using the upper limit of 1 for the total probability , such an even distribution would not do full justice here. We propose to distribute the likelihood proportionally to the probabilities of recognition for each descriptor , which makes repair more likely applicable to those objects which are also more likely to be identified anyway. In order to perform this operation properly , “average” probabilities ( ap ) for only reparable descriptors must be estimated. Moreover , we want to favor repairs for objects which require fewer “average” probabilities for this computation , by incorporating a `` scale-down factor” ( sdf ) for each additional repair. The computation schema is given in Figure 4. For concrete computations , we choose 0.5 for both factors ap and sdf – see the examples in Figure 5. The first one demonstrates the partitioning of the repair factor according to the number of attributes which require repair. Specifically , the first three objects get the same share of the repair factor , while the fourth object gets only half of it , since its identification is the only one which requires Compute identification probability ( D1 , … , Dnp , k , O1 , … , On ) O1 , … , Om Objects to which all D1 , … , np are applicable Om+1 , … , On Objects with repair possible for all D1 , … , np pi1 , … , pinp Probability that D1 , … , np is attributed to Oi Objects ordered along degrees of identification confidence : ∀i , j ( 1≤i , j≤m ) : ( Πl=1 , nppil &gt; Πl=1 , nppjl ) → ( i &gt; j ) for i from 1 to n do Pi ← 1 , sdfi ← 1/sdf for j from 1 to np do if pij &gt; 0 then Pi ← Pipij else Pi ← Piap , sdfi ← sdfisdf endif endfor endfor Rprop ← R ( k , Pi , … , Pm ) , i ← 1 , P ← Σi=1 , nPi then Rc ← Min ( Rprop ( Pi/P ) ,1-Pi ) , p-idi ← Pi+Rc else Rc ← Rprop ( Pisdfi/P ) , p-idi ← Rc endif if ( i &lt; n ) then i ← i+1 , Rprop ← Rprop Rc , goto 1 endif Figure 4. Identification probabilities for several descriptors repair regarding two descriptors. The second example features the impact of multiple intended referents on the repair factor , which increases the probabilities of identification substantially. The last example illustrates the compensative effect between comparably low probabilities of recognition and higher ones in connection with the requirement of using the repair facility. Specifically , this example demonstrates that the probability of identification for an object ( the second one ) that is only identifiable through the repair mechanism can even become higher than the probability of identification for an object ( the second one ) that does not require repair for being identified. However , such an effect is only possible in the context of descriptors applicable with some degree of confidence to both candidates , but strongly favoring the object whose identification relies on the repair mechanism due to mismatch with another descriptor. This is the most critical effect in choosing descriptors. The incorproation of disjunctions and negations is more local , since this extension only generalizes the probability of recognition of a single property. This is because these operators appear only in embedded boolean combinations [ van Deemter 2002 ] , which are the basis for building larger varieties of expressions [ Horacek 2004 ] . For disjunctions of two descriptors with associated probabilities p1 and p2 , the joint probability amounts to p1+p2-p1p2 , assuming independence , which is quite normal for descriptors originating from For k objects to be identified out of n , judging identification by np descriptors D , at least repair possible for all ( Dj applies to object i with probability pji , ∀i≤m : pji &gt; 0 ) p22 =0 , p13 =0 , p23 =0.5 , p14 =0 , p24 =0 ) : Rprop = 0.75 p-id1 = 0.464 , p-id2 = 0.214 , p-id3 = 0.214 , p-id4 = 0.107 p22 =0.5 , p13 =0 , p23 =0.55 ) : Rprop = 1.4 p-id1 = p-id2 = 0.766 , p-id3 = 0.466 p12 =0.9 , p22 =0.9 , p32 =0 ) : Rprop = 0.875 p-id1 = 0.331 , p-id2 = 0.668 Figure 5 .</sentence>
				<definiendum id="0">Determine probability of identification</definiendum>
				<definiens id="0">k , O1 , … , On ) O1 , … , Om Objects to which descriptor D applies Om+1 , … , On Objects to which repair with D is applicable pi , … , pm Probability that D is recognized for Oi Objects ordered along degrees of recognition confidence</definiens>
				<definiens id="1">illustrate the effect of the repair mechanism in quantitative terms. They emphasize the relation between expectations about the number of objects to be identified and probabilities of identification. For k objects to be identified out of n , judging identification by descriptor D , which may involve repair measures</definiens>
				<definiens id="2">makes repair more likely applicable to those objects which are also more likely to be identified anyway. In order to perform this operation properly</definiens>
				<definiens id="3">requires Compute identification probability ( D1 , … , Dnp , k , O1 , … , On ) O1 , … , Om Objects to which all D1 , … , np are applicable Om+1 , … , On Objects with repair possible for all D1 , … , np pi1 , … , pinp Probability that D1 , … , np is attributed to Oi Objects ordered along degrees of identification confidence : ∀i</definiens>
			</definition>
</paper>

		<paper id="0110">
</paper>

		<paper id="1512">
			<definition id="0">
				<sentence>In this paper , we study two different latent-head models , as well as two different estimation methods : The first model is built around completely hidden heads , whereas the second one uses relatively fine-grained combinations of Part-Of-Speech ( POS ) tags with hidden extra-information ; The first estimation method selects a head-driven probabilistic context-free grammar ( PCFG ) by exploiting latenthead distributions for each node in the tree-bank , whereas the second one is more traditional , reading off the grammar from the tree-bank annotated with the most probable latent heads only .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">head-driven probabilistic context-free grammar (</definiens>
			</definition>
			<definition id="1">
				<sentence>In the following , we present two of them : Lexical-Rule Transformation ( Model 1 ) : Transform each lexical rule C −→w to a set of rules , having the form C : h−→w , where h ∈ { 1 , ... , L } , and L is a free parameter .</sentence>
				<definiendum id="0">Lexical-Rule Transformation</definiendum>
				<definiendum id="1">L</definiendum>
				<definiens id="0">a free parameter</definiens>
			</definition>
			<definition id="2">
				<sentence>Lexical-Rule Transformation ( Model 2 ) : Transform each lexical rule C −→ w to a set of rules , having the form C : h −→ w , where h ∈ { C } × { 1 , ... , L } , and L is a free parameter .</sentence>
				<definiendum id="0">Lexical-Rule Transformation</definiendum>
				<definiendum id="1">L</definiendum>
				<definiens id="0">a free parameter</definiens>
			</definition>
			<definition id="3">
				<sentence>Model 1 ( Completely Latent Heads ) : hADJ , hN , hV , and hPUNC ∈ { 1 , . . . , L } Model 2 ( Latent Heads Based on POS Tags ) : hADJ ∈ { ADJ } × { 1 , . . . , L } hN ∈ { N } × { 1 , . . . , L } hV ∈ { V } × { 1 , . . . , L } hPUNC ∈ { PUNC } × { 1 , . . . , L } Number of Latent-Head Types = braceleftBigg L for Model 1 |P OS|× L for Model 2 ( L is a free parameter ) Figure 5 : Parse tree with latent heads , and a list of the rules it contains .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">a free parameter</definiens>
			</definition>
</paper>

		<paper id="1508">
			<definition id="0">
				<sentence>We view the source-language treebank as a sequence of trees S1 , ... , Sn , and assume that these trees are generated by a common process from a corresponding sequence of latent target-language trees T1 , ... , Tn .</sentence>
				<definiendum id="0">source-language treebank</definiendum>
			</definition>
			<definition id="1">
				<sentence>Since we employ a conjugate prior , the posterior distribution of Λ p ( Λ | S1 , ... , Sn , T1 , ... , Tn , Ξ , λ , ξ ) = p ( Λ | T1 , ... , Tn , λ ) ( 3 ) has the same form as the prior – it is likewise a product of Dirichlet distributions .</sentence>
				<definiendum id="0">Tn , λ</definiendum>
				<definiens id="0">the posterior distribution of Λ p ( Λ | S1 , ... , Sn , T1 , ... , Tn , Ξ , λ , ξ ) = p ( Λ | T1 , ... ,</definiens>
			</definition>
			<definition id="2">
				<sentence>In fact , for each word type w the posterior Dirichlet density has parameter λw+cw , where λw is the parameter of the prior distribution and cw is a vector of counts for all word forms appearing immediately after w along the fringe of the imputed trees .</sentence>
				<definiendum id="0">λw</definiendum>
				<definiendum id="1">cw</definiendum>
			</definition>
			<definition id="3">
				<sentence>The difficult part is the first step in each scan of the Gibbs sampler , which involves sampling each target-language latent tree from the corresponding posterior distribution .</sentence>
				<definiendum id="0">difficult part</definiendum>
				<definiens id="0">involves sampling each target-language latent tree from the corresponding posterior distribution</definiens>
			</definition>
			<definition id="4">
				<sentence>For a particular tree Tj , the posterior takes the following form : p ( Tj |S1 , ... , Sn , T1 , ... , Tj−1 , Tj+1 , ... , Tn , Λ , Ξ , λ , ξ ) = p ( Tj | S j , Λ , Ξ ) = p ( Tj , S j | Λ , Ξ ) ∑ Tj p ( Tj , S j | Λ , Ξ ) ∝ p ( Tj | Λ ) p ( S j | Tj , Ξ ) ( 5 ) The next section discusses sampling from this posterior distribution in the context of a concrete example and presents an algorithmic solution .</sentence>
				<definiendum id="0">Tj</definiendum>
				<definiens id="0">|S1 , ... , Sn , T1 , ... , Tj−1 , Tj+1 , ... , Tn , Λ , Ξ , λ , ξ ) = p ( Tj | S j , Λ , Ξ ) = p ( Tj , S j | Λ , Ξ ) ∑ Tj p ( Tj , S j | Λ , Ξ ) ∝ p ( Tj | Λ ) p ( S j | Tj</definiens>
			</definition>
			<definition id="5">
				<sentence>The intersection operation is a special case of the intersection construction for context-free grammars and finite automata ( BarHillel et al. , 1961 , pp .</sentence>
				<definiendum id="0">intersection operation</definiendum>
				<definiens id="0">a special case of the intersection construction for context-free grammars and finite automata ( BarHillel et al. , 1961 , pp</definiens>
			</definition>
			<definition id="6">
				<sentence>There are two recursive cases : For choice nodes ( and-nodes ) , their weight is the product of the weights of the node’s children times a local likelihood score .</sentence>
				<definiendum id="0">weight</definiendum>
				<definiens id="0">the product of the weights of the node’s children times a local likelihood score</definiens>
			</definition>
			<definition id="7">
				<sentence>Given this very natural weight-propagation algorithm ( and-nodes correspond to multiplication , ornodes to summation ) , it is clear that the weight of the root node is the sum total of the weights of all trees in the forest , where the weight of a tree is the prod79 ( # , ro ot , $ ) ( # , ro ot , $ ) _ 1 ( # , ro ot , $ ) _ 2 ( # , ro ot , $ ) _ 3 ( # , C , n ) 1 ( n , $ , $ ) 2 ( # , C , n ) _1 ( # , C , n ) _2 ( # , C , n ) _3 ( # , S , n ) 1 ( n , VO , n ) 2 ( # , a1 , a ) 1 ( a , n1 , n ) 2 ( n , v , v ) 1 ( v , O , n ) 2 ( v , a2 , a ) 1 ( a , n2 , n ) 2 ( # , S , a ) 1 ( a , VO , n ) 2 ( # , n1 , n ) 1 ( n , a1 , a ) 2 2 ( a , v , v ) 1 ( # , v , v ) 1 ( v , SO , n ) 2 ( v , SO , n ) _1 ( v , SO , n ) _2 ( v , S , n ) 1 ( n , O , n ) 2 2 ( v , a1 , a ) 1 2 ( n , a 2 , a ) 1 ( v , S , a ) 1 ( a , O , n ) 2 2 ( v , n1 , n ) 1 2 ( a , a2 , a ) 1 ( # , C , a ) 1 ( a , $ , $ ) 2 ( # , C , a ) _1 ( # , C , a ) _2 ( # , C , a ) _3 1 ( a , VO , a ) 2 1 ( v , O , a ) 2 ( v , n2 , n ) 1 ( n , a2 , a ) 2 1 ( n , VO , a ) 2 1 2 1 ( v , SO , a ) 2 ( v , SO , a ) _1 ( v , SO , a ) _2 1 ( a , O , a ) 2 2 ( a , n2 , n ) 1 1 ( n , O , a ) 2 2 ( n , n2 , n ) 1 ( # , C , v ) 1 ( v , $ , $ ) 2 ( # , C , v ) _1 ( # , C , v ) _2 1 ( n , OV , v ) 2 ( n , OV , v ) _1 ( n , OV , v ) _2 2 1 2 1 1 ( a , OV , v ) 2 ( a , OV , v ) _1 ( a , OV , v ) _2 2 1 2 1 Figure 4 : Augmented forest obtained by intersecting the forest in Figure 3 with a bigram language model .</sentence>
				<definiendum id="0">O</definiendum>
				<definiens id="0"># , C , n ) _1 ( # , C , n ) _2 ( # , C , n ) _3 ( # , S , n ) 1 ( n , VO , n ) 2 ( # , a1 , a ) 1 ( a , n1 , n ) 2 ( n , v , v ) 1 ( v ,</definiens>
				<definiens id="1">a , n2 , n ) 2 ( # , S , a ) 1 ( a , VO , n ) 2 ( # , n1 , n ) 1 ( n</definiens>
				<definiens id="2">v , SO , n ) 2 ( v , SO , n ) _1 ( v , SO , n ) _2 ( v , S , n ) 1 ( n , O</definiens>
				<definiens id="3">n , OV , v ) 2 ( n , OV , v ) _1 ( n , OV , v</definiens>
			</definition>
</paper>

		<paper id="0637">
			<definition id="0">
				<sentence>However , in order to keep the number of instances at a reasonable number , we have only built instances for verb–phrase pairs when the phrase parent is an ancestor of the verb ( 400,128 training instances ) .</sentence>
				<definiendum id="0">verb–phrase pairs</definiendum>
				<definiens id="0">an ancestor of the verb ( 400,128 training instances )</definiens>
			</definition>
			<definition id="1">
				<sentence>Levenshtein distance is a dynamically computed distance between two strings , accounting for the number of deletions , insertions , and substitutions needed to transform the one string into the other .</sentence>
				<definiendum id="0">Levenshtein distance</definiendum>
			</definition>
			<definition id="2">
				<sentence>Learning algorithm Precision Recall Fβ=1 without post-processing : Maximum Entropy Models 70.78 % 70.03 % 70.40 Memory-Based Learning 70.70 % 69.85 % 70.27 Support Vector Machines 75.07 % 69.15 % 71.98 including post-processing : Maximum Entropy Models 74.06 % 69.84 % 71.89 Memory-Based Learning 73.84 % 69.88 % 71.80 Support Vector Machines 77.75 % 69.11 % 73.17 Combination 76.79 % 70.01 % 73.24 Table 3 : Effect of the choice of machine learning algorithm , the application of Levenshtein-distancebased post-processing and the use of system combination on the performance obtained for the development data set .</sentence>
				<definiendum id="0">Learning algorithm Precision Recall Fβ=1</definiendum>
				<definiens id="0">Effect of the choice of machine learning algorithm , the application of Levenshtein-distancebased post-processing and the use of system combination on the performance obtained for the development data set</definiens>
			</definition>
</paper>

		<paper id="0706">
			<definition id="0">
				<sentence>The Hebrew Treebank ( Sima’an et al. , 2001 ) consists of syntactically annotated sentences taken from articles from the Ha’aretz daily newspaper .</sentence>
				<definiendum id="0">Hebrew Treebank</definiendum>
				<definiens id="0">consists of syntactically annotated sentences taken from articles from the Ha’aretz daily newspaper</definiens>
			</definition>
			<definition id="1">
				<sentence>languages Our segmentation and POS tagging system consists of a morphological analyzer that assigns a set of possible candidate analyses to each word , and a disambiguator that selects from this set a single preferred analysis per word .</sentence>
				<definiendum id="0">POS tagging system</definiendum>
				<definiens id="0">consists of a morphological analyzer that assigns a set of possible candidate analyses to each word , and a disambiguator that selects from this set a single preferred analysis per word</definiens>
			</definition>
			<definition id="2">
				<sentence>Each candidate analysis consists of a segmentation of the word into morphemes , and a POS tag assignment to these morphemes .</sentence>
				<definiendum id="0">candidate analysis</definiendum>
				<definiens id="0">consists of a segmentation of the word into morphemes</definiens>
			</definition>
			<definition id="3">
				<sentence>If tokenization is per morpheme , the disambiguator aims at finding a combination of a segmentation mn1 and a tagging tn1 for mn1 , such that their joint probability with the given sentence , wk1 , is maximized : argmax ( mn1 , tn1 ) ∈ANALYSES ( wk1 ) P ( wk1 , mn1 , tn1 ) , ( 2 ) where ANALYSES ( wk1 ) is the set of possible analyses for the input sentence wk1 ( output by the morphological analyzer ) .</sentence>
				<definiendum id="0">ANALYSES</definiendum>
			</definition>
			<definition id="4">
				<sentence>Therefore , Formula ( 2 ) can be simplified as : argmax ( mn1 , tn1 ) ∈ANALYSES ( wk1 ) P ( mn1 , tn1 ) ( 3 ) Formulas ( 1 ) and ( 3 ) can be represented in a unified formula that applies to both word tokenization and morpheme tokenization : argmax ( en1 , An1 ) ∈ANALYSES ( wk1 ) P ( en1 , An1 ) ( 4 ) In Formula ( 4 ) en1 represents either a sequence of words or a sequence of morphemes , depending on the level of tokenization , and An1 are the respective nonterminals – either POS tags or word-level analyses .</sentence>
				<definiendum id="0">An1</definiendum>
				<definiens id="0">the respective nonterminals – either POS tags or word-level analyses</definiens>
			</definition>
			<definition id="5">
				<sentence>Our method starts out from a naively smoothed relative fre3the smoothed probabilities are normalized so thatsummationtext w P ( w , a ) = P ( a ) quency lexical model in our POS tagger : PLM0 ( w|a ) = braceleftBigg ( 1 −p0 ) rftr ( w , a ) ftr ( w ) &gt; 0 p0 otherwise ( 7 ) Where ftr ( w ) is the occurrence frequency of w in the training corpus , and p0 is a constant set experimentally to 10−10 .</sentence>
				<definiendum id="0">p0</definiendum>
				<definiens id="0">the occurrence frequency of w in the training corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>Developing a word segmenter and POS tagger for Hebrew with less than 30K annotated words for training is a challenging task , especially given the morphological complexity and high degree of ambiguity in Hebrew .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">a challenging task , especially given the morphological complexity and high degree of ambiguity in Hebrew</definiens>
			</definition>
			<definition id="7">
				<sentence>First , the M+h model , which was found to perform best , is based on morphemelevel tokenization , which suffers of data sparseness less than word tokenization , and makes use of multi-morpheme nonterminals only in specific cases where it was found to be valuable .</sentence>
				<definiendum id="0">M+h model</definiendum>
				<definiens id="0">suffers of data sparseness less than word tokenization</definiens>
			</definition>
</paper>

		<paper id="1518">
			<definition id="0">
				<sentence>176 Method Precision Recall F-measure ( ec+mc+dz ) balanced ( ec+mc+zž ) 86.7 unbalanced ( ec+mc+zž ) 90.2 84.7 87.3 Table 7 : Unbalanced vs. balanced combining .</sentence>
				<definiendum id="0">Method Precision Recall F-measure ( ec+mc+dz ) balanced</definiendum>
				<definiens id="0">Unbalanced vs. balanced combining</definiens>
			</definition>
</paper>

		<paper id="0820">
			<definition id="0">
				<sentence>The test corpus consists of 2000 sentences aligned across all five languages .</sentence>
				<definiendum id="0">test corpus</definiendum>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>SemFrame generates FrameNet-like frames , complete with semantic roles and evoking lexical units .</sentence>
				<definiendum id="0">SemFrame</definiendum>
				<definiens id="0">generates FrameNet-like frames , complete with semantic roles and evoking lexical units</definiens>
			</definition>
			<definition id="1">
				<sentence>58 WordNet is a lexical database for English nouns , verbs , adjectives , and adverbs .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a lexical database for English nouns , verbs , adjectives , and adverbs</definiens>
			</definition>
			<definition id="2">
				<sentence>SemFrame adopts a multistep approach to identifying sets of frame-semantically related verb senses .</sentence>
				<definiendum id="0">SemFrame</definiendum>
				<definiens id="0">adopts a multistep approach to identifying sets of frame-semantically related verb senses</definiens>
			</definition>
			<definition id="3">
				<sentence>, WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0618">
			<definition id="0">
				<sentence>An example of a generic pipeline architecture is GATE ( Cunningham et al. , 1997 ) which provides an infrastructure for building NLP applications .</sentence>
				<definiendum id="0">GATE</definiendum>
			</definition>
			<definition id="1">
				<sentence>The coef cient of variable x ( lij ) , that models the assignment cost c ( lij ) , is given by : c ( lij ) = −log2 ( p ( lij ) ) where p ( lij ) is the probability of lij being selected as the outcome of task Ti .</sentence>
				<definiendum id="0">p ( lij )</definiendum>
			</definition>
			<definition id="2">
				<sentence>The ILP model consists of the target function and a set of constraints which block illegal assignments ( e.g. only one label of the given task can be selected ) 7 .</sentence>
				<definiendum id="0">ILP model</definiendum>
				<definiens id="0">consists of the target function and a set of constraints which block illegal assignments</definiens>
			</definition>
			<definition id="3">
				<sentence>In Marciniak &amp; Strube ( 2004 ) we implemented the generation process sequentially as a cascade of classi ers that realized incrementally the vector representation of the generated text’s form , given the meaning vector as input .</sentence>
				<definiendum id="0">generation process</definiendum>
				<definiens id="0">a cascade of classi ers that realized incrementally the vector representation of the generated text’s form , given the meaning vector as input</definiens>
			</definition>
			<definition id="4">
				<sentence>Generation occurs in a number of stages , during which individual discourse units are realized .</sentence>
				<definiendum id="0">Generation</definiendum>
				<definiens id="0">occurs in a number of stages , during which individual discourse units are realized</definiens>
			</definition>
			<definition id="5">
				<sentence>To evaluate individual tasks we applied two metrics : accuracy , calculated as the proportion of correct classi cations to the total number of instances , and the κ statistic , which corrects for the proportion of classi cations that might occur by chance13 10Both implemented in the Weka machine learning software ( Witten &amp; Frank , 2000 ) .</sentence>
				<definiendum id="0">the κ statistic</definiendum>
				<definiens id="0">corrects for the proportion of classi cations that might occur by chance13 10Both implemented in the Weka machine learning software</definiens>
			</definition>
			<definition id="6">
				<sentence>Approximation algorithms for classi cation problems with pairwise relationships : Metric labeling and Markov random elds .</sentence>
				<definiendum id="0">Approximation algorithms</definiendum>
				<definiens id="0">for classi cation problems with pairwise relationships : Metric labeling and Markov random elds</definiens>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>The shallow parser gives information on the syntactic function of each word ( subject , object , etc. ) , not on phrase structure .</sentence>
				<definiendum id="0">shallow parser</definiendum>
				<definiens id="0">gives information on the syntactic function of each word ( subject , object , etc. ) , not on phrase structure</definiens>
			</definition>
			<definition id="1">
				<sentence>Examples are taula gran ( ‘big table’ ) , arquitecte tècnic ( ‘technical architect’ ) , and element constitutiu ( ‘constitutive element’ ) .</sentence>
				<definiendum id="0">gran</definiendum>
			</definition>
			<definition id="2">
				<sentence>In this table , # f is the number of features for each representation strategy , size the size of the trees ( number of leaves ) , accuracy the accuracy rate of the classifiers ( in percentage ) , and SE the standard error of each parameter .</sentence>
				<definiendum id="0">SE</definiendum>
				<definiens id="0">the number of features for each representation strategy , size the size of the trees ( number of leaves ) , accuracy the accuracy rate of the classifiers ( in percentage ) , and</definiens>
			</definition>
			<definition id="3">
				<sentence>Although more analysis is needed , in many of these cases ( such as interminable ) the underlying verb is stative , which makes the adjectives very similar to basic adjectives , as mentioned in Section 3 .</sentence>
				<definiendum id="0">stative</definiendum>
			</definition>
</paper>

		<paper id="0404">
			<definition id="0">
				<sentence>a10 represents the alphabet , a11 represents the epsilon transition .</sentence>
				<definiendum id="0">a10</definiendum>
				<definiendum id="1">a11</definiendum>
				<definiens id="0">the alphabet</definiens>
				<definiens id="1">the epsilon transition</definiens>
			</definition>
			<definition id="1">
				<sentence>Generic named entity tags , such as person , location and organization names and task-dependent named entity tags , such as drug names in a medical domain , are also incorporated into the graph , where applicable .</sentence>
				<definiendum id="0">Generic</definiendum>
				<definiens id="0">named entity tags , such as person , location and organization names and task-dependent named entity tags</definiens>
			</definition>
			<definition id="2">
				<sentence>The semantic role labels represent the predicate/argument structure of each sentence : Given a predicate , the goal is to identify all of its arguments and their semantic roles .</sentence>
				<definiendum id="0">semantic role labels</definiendum>
				<definiens id="0">to identify all of its arguments and their semantic roles</definiens>
			</definition>
			<definition id="3">
				<sentence>The alphabet a10 contains all the symbols in a12a15a13 .</sentence>
				<definiendum id="0">a10</definiendum>
				<definiens id="0">contains all the symbols in a12a15a13</definiens>
			</definition>
			<definition id="4">
				<sentence>HMM is the simple HMM-based approach , IF is the simpli ed version of BBN’s name nder with an unknown words model .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiendum id="1">IF</definiendum>
				<definiens id="0">the simple HMM-based approach</definiens>
			</definition>
			<definition id="5">
				<sentence>Perplexity is computed using the prior distribution over all the call-types in the training data .</sentence>
				<definiendum id="0">Perplexity</definiendum>
				<definiens id="0">computed using the prior distribution over all the call-types in the training data</definiens>
			</definition>
			<definition id="6">
				<sentence>As the evaluation metric , we use the top class error rate ( TCER ) , which is the ratio of utterances , where the top scoring call-type is not one of the true calltypes assigned to each utterance by the human labelers .</sentence>
				<definiendum id="0">TCER</definiendum>
				<definiens id="0">the ratio of utterances</definiens>
			</definition>
			<definition id="7">
				<sentence>Boostexter : A boosting-based system for text categorization .</sentence>
				<definiendum id="0">Boostexter</definiendum>
				<definiens id="0">A boosting-based system for text categorization</definiens>
			</definition>
</paper>

		<paper id="0508">
			<definition id="0">
				<sentence>In general , bigram probability ( or sentence cross-entropy , as computed in these experiments ) is a poor predictor of grammaticality ; e.g. , the measure that prefers ( 1 ) over ( 2 ) mis-prefers ( 8 ) over ( 9 ) : ( 8 ) *Scared you want to the doggie .</sentence>
				<definiendum id="0">bigram probability</definiendum>
				<definiens id="0">a poor predictor of grammaticality ; e.g. , the measure that prefers ( 1 ) over ( 2 ) mis-prefers ( 8 ) over ( 9</definiens>
			</definition>
</paper>

		<paper id="0302">
			<definition id="0">
				<sentence>Many recent annotation efforts for English have focused on pieces of the larger problem of semantic annotation , rather than producing a single unified representation like Head-driven Phrase Structure Grammar ( Pollard and Sag 1994 ) or the Prague Dependency Tectogramatical Representation ( Hajicova &amp; Kucerova , 2002 ) .</sentence>
				<definiendum id="0">Dependency Tectogramatical Representation</definiendum>
				<definiens id="0">unified representation like Head-driven Phrase Structure Grammar ( Pollard and Sag 1994 ) or the Prague</definiens>
			</definition>
			<definition id="1">
				<sentence>PropBank and NomBank would both support a single IE pattern stating that the object ( ARG1 ) of appoint is John and the subject ( ARG0 ) is IBM , allowing a system to detect that IBM hired John from each of the following strings : IBM appointed John , John was appointed by IBM , IBM 's appointment of John , the appointment of John by IBM and John is the current IBM appointee .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">IBM , allowing a system to detect that IBM hired John from each of the following strings : IBM appointed John , John was appointed by IBM , IBM 's appointment of John , the appointment of John by IBM and John is the current IBM appointee</definiens>
			</definition>
			<definition id="2">
				<sentence>Coreference : Coreference involves the detection of subsequent mentions of invoked entities , as in George Bush , … he… .</sentence>
				<definiendum id="0">Coreference</definiendum>
				<definiens id="0">involves the detection of subsequent mentions of invoked entities</definiens>
			</definition>
			<definition id="3">
				<sentence>TimeBank : The Brandeis TimeBank corpus , funded by ARDA , focuses on the annotation of all major aspects in natural language text associated with temporal and event information ( Day , et al , 2003 , Pustejovsky , et al , 2004 ) .</sentence>
				<definiendum id="0">TimeBank</definiendum>
				<definiens id="0">The Brandeis TimeBank corpus , funded by ARDA , focuses on the annotation of all major aspects in natural language text associated with temporal and event information</definiens>
			</definition>
			<definition id="4">
				<sentence>Investigator is a relational noun in NomBank .</sentence>
				<definiendum id="0">Investigator</definiendum>
				<definiens id="0">a relational noun in NomBank</definiens>
			</definition>
			<definition id="5">
				<sentence>TimeML , however , focuses on the anchoring of events to explicit temporal expressions ( or document creation dates ) through TLINKs , as well as subordinating relations , such as those introduced by modals , intensional predicates , and other event-selecting predicates , through SLINKs .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">focuses on the anchoring of events to explicit temporal expressions</definiens>
			</definition>
			<definition id="6">
				<sentence>For these constructions , the merged representation might not need to include the ( ARG0 ) relation between the subject of the sentence and make , and future propbanking efforts might do well to ignore the shared arguments of such instances and leave them for NomBank .</sentence>
				<definiendum id="0">ARG0</definiendum>
				<definiens id="0">) relation between the subject of the sentence and make</definiens>
			</definition>
			<definition id="7">
				<sentence>With respect to idioms and light verbs , TimeML can be viewed as a mediator between PropBank and NomBank .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">a mediator between PropBank and NomBank</definiens>
			</definition>
</paper>

		<paper id="1514">
			<definition id="0">
				<sentence>Chunk parsing ( Tjong Kim Sang , 2001 ; Brants , 1999 ) is a simple parsing strategy both in implementation and concept .</sentence>
				<definiendum id="0">Chunk parsing</definiendum>
				<definiens id="0">a simple parsing strategy both in implementation and concept</definiens>
			</definition>
			<definition id="1">
				<sentence>The rules used in the training data do not cover all the rules in unseen sentences .</sentence>
				<definiendum id="0">rules</definiendum>
				<definiens id="0">used in the training data do not cover all the rules in unseen sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>By assuming the conditional independence among the features , we can compute the probability for filtering as follows : a0 a1a2a1a4a3a5a7a6a9a8a10a6a12a11 a6a14a13 a0 a1a15a5a7a6a9a8a16a6a12a11a17a3a1 a6 a0 a1a2a1 a6 a0 a1a15a5a7a6a9a8a16a6a12a11 a6 a13 a0 a1a15a5a18a3a1 a6 a0 a1a15a8a9a3a1 a6 a0 a1a2a11a17a3a1 a6 a0 a1a2a1 a6 a19a21a20 a0 a1a15a5a22a3a1 a6 a0 a1a15a8a12a3a1 a6 a0 a1a2a11a17a3a1 a6 a0 a1a2a1 a6 a6 where a1 is a binary output indicating whether the candidate is a phrase of the target type or not , a5 is the RHS of the CFG rule , a8 is the symbol on the left , and a11 is the symbol on the right .</sentence>
				<definiendum id="0">a1</definiendum>
				<definiendum id="1">a5</definiendum>
				<definiendum id="2">a11</definiendum>
				<definiens id="0">a binary output indicating whether the candidate is a phrase of the target type or not ,</definiens>
				<definiens id="1">the symbol on the left</definiens>
				<definiens id="2">the symbol on the right</definiens>
			</definition>
			<definition id="3">
				<sentence>a0 a5a33a32a7a11a35a34 a13 a36 a1a4a37a6a38a13a39a23a40a23a41a43a42 a0 a1 a6 ( 1 ) where a0 a1 is the probability of a phrase given by the maximum entropy classifier .</sentence>
				<definiendum id="0">a0 a1</definiendum>
				<definiens id="0">the probability of a phrase given by the maximum entropy classifier</definiens>
			</definition>
			<definition id="4">
				<sentence>The test set consists of section 23 and we report the performance of the parser on the set .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of section 23 and we report the performance of the parser on the set</definiens>
			</definition>
			<definition id="5">
				<sentence>Collins parser allows the user to change the size of the beam in parsing .</sentence>
				<definiendum id="0">Collins parser</definiendum>
				<definiens id="0">allows the user to change the size of the beam in parsing</definiens>
			</definition>
</paper>

		<paper id="0621">
			<definition id="0">
				<sentence>For example , a feature fi ( a , H ) is true if ’a’ is Ram and ’H’ is ’AGENT of a verb’ .</sentence>
				<definiendum id="0">feature fi</definiendum>
				<definiens id="0">true if ’a’ is Ram and ’H’ is ’AGENT of a verb’</definiens>
			</definition>
</paper>

		<paper id="1301">
			<definition id="0">
				<sentence>( ) ) , ( exp ( ) | ( xZ yxf xyP i ii a0 = λ where Z ( x ) is the normalization function , the iλ are real-valued model parameters and the if are arbitrary realvalued feature functions .</sentence>
				<definiendum id="0">Z ( x )</definiendum>
				<definiens id="0">the normalization function , the iλ are real-valued model parameters and the if are arbitrary realvalued feature functions</definiens>
			</definition>
			<definition id="1">
				<sentence>Abstract Excerpt : “This new receptor , TOR ( thymus orphan receptor ) …” Feature Class Specific Feature Phrase TOR GENEID MGI104856 Previous-1 , Previous-2 receptor Subsequent-1 ( Subsequent-2 thymus Number of Matches 2 Number of Words 1 Prefix-1 T Prefix-2 TO Prefix-3 TOR Suffix-1 R Suffix-2 OR Suffix-3 TOR Figure 1 .</sentence>
				<definiendum id="0">Abstract Excerpt</definiendum>
				<definiens id="0">“This new receptor</definiens>
				<definiens id="1">T Prefix-2 TO Prefix-3 TOR Suffix-1 R Suffix-2 OR Suffix-3 TOR Figure 1</definiens>
			</definition>
			<definition id="2">
				<sentence>Training the model involves finding the parameters that maximize the log-likelihood of the training data .</sentence>
				<definiendum id="0">Training the model involves</definiendum>
				<definiens id="0">finding the parameters that maximize the log-likelihood of the training data</definiens>
			</definition>
			<definition id="3">
				<sentence>Given a classifier able to rank all the test instances ( in our case , the ranks derive from the probabilities output by the maximum entropy classifier ) , we return only the top n gene identifiers , where n is the number of correct identifiers in the development test data – this results in a balanced F-measure score .</sentence>
				<definiendum id="0">maximum entropy classifier</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of correct identifiers in the development test data – this results in a balanced F-measure score</definiens>
			</definition>
			<definition id="4">
				<sentence>As our system matching phase is a bit different ( i.e. we remove punctuation and ignore case ) , this amounts to re-labeling the training data using this looser criterion .</sentence>
				<definiendum id="0">system matching phase</definiendum>
				<definiens id="0">a bit different</definiens>
			</definition>
</paper>

		<paper id="0830">
			<definition id="0">
				<sentence>Syntactic tagging was realized by the TreeTagger , which is a probabilistic part-of-speech tagger and lemmatizer .</sentence>
				<definiendum id="0">TreeTagger</definiendum>
				<definiens id="0">a probabilistic part-of-speech tagger and lemmatizer</definiens>
			</definition>
			<definition id="1">
				<sentence>Secondly , a closer examination of the translation probability value alterations that took place in order to reflect part-of-speech correspondences reveals that the proportion of the entries of the phrase table that were matched syntactically to phrases from the parallel corpus , and thus underwent a modification in their translation probability score , was very low ( less than 1 % ) .</sentence>
				<definiendum id="0">translation probability</definiendum>
				<definiens id="0">a closer examination of the translation probability value alterations that took place in order to reflect part-of-speech correspondences reveals that the proportion of the entries of the phrase table that were matched syntactically to phrases from the parallel corpus</definiens>
			</definition>
</paper>

		<paper id="0103">
			<definition id="0">
				<sentence>Language and Computers is a general enrollment course designed to meet the Mathematical and Logical Analysis requirement that is mandated for all undergraduates at the Ohio State University ( OSU ) , one of the largest universities in the US .</sentence>
				<definiendum id="0">Language</definiendum>
				<definiendum id="1">Computers</definiendum>
				<definiens id="0">a general enrollment course designed to meet the Mathematical and Logical Analysis requirement that is mandated for all undergraduates at the Ohio State University ( OSU ) , one of the largest universities in the US</definiens>
			</definition>
			<definition id="1">
				<sentence>The Ohio State University has a distribution requirement , the General Education Curricu15 lum ( GEC ) , that is designed to ensure adequate breadth in undergraduate education .</sentence>
				<definiendum id="0">Ohio State University</definiendum>
				<definiens id="0">a distribution requirement , the General Education Curricu15 lum ( GEC ) , that is designed to ensure adequate breadth in undergraduate education</definiens>
			</definition>
			<definition id="2">
				<sentence>This meets the MLA objective to emphasize the nature of correct argumentation in symbolic form as well as the logical processes involved in computing and the theory of algorithms .</sentence>
				<definiendum id="0">MLA objective</definiendum>
				<definiens id="0">to emphasize the nature of correct argumentation in symbolic form as well as the logical processes involved in computing and the theory of algorithms</definiens>
			</definition>
			<definition id="3">
				<sentence>For instance , some students were simply unable to understand the notion that the Kleene star is to be interpreted as an operator rather than as a special character occurring in place of any string .</sentence>
				<definiendum id="0">star</definiendum>
				<definiens id="0">a special character occurring in place of any string</definiens>
			</definition>
</paper>

		<paper id="0817">
			<definition id="0">
				<sentence>Introduction In ( Tufiş , 2002 ) we described a translation equivalence extraction program called TREQ the development of which was twofold motivated : to help enriching the synsets of the Romanian wordnet ( Tufiş et al. 2004a ) with new literals based on bilingual corpora evidence and to check the interlingual alignment of our wordnet against the Princeton Wordnet .</sentence>
				<definiendum id="0">Romanian wordnet</definiendum>
				<definiens id="0">new literals based on bilingual corpora evidence and to check the interlingual alignment of our wordnet against the Princeton Wordnet</definiens>
			</definition>
			<definition id="1">
				<sentence>The tokenizer is a finite state automaton using language specific 3 We noticed in the Gold Standard two sentences where alignments were wrongly shifted by one position ( due to an unprintable character ) and we corrected them .</sentence>
				<definiendum id="0">tokenizer</definiendum>
				<definiens id="0">noticed in the Gold Standard two sentences where alignments were wrongly shifted by one position ( due to an unprintable character</definiens>
			</definition>
			<definition id="2">
				<sentence>This tokenization considerably differs from the one prescribed by the Shared Task where a token is any character string delimited by a blank or a punctuation sign ( which itself is considered a token ) .</sentence>
				<definiendum id="0">token</definiendum>
				<definiens id="0">any character string delimited by a blank or a punctuation sign ( which itself is considered a token )</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally , the bitext is assembled as an XML document ( XCES-Align-ana format ) , as used in the MULTEXT-EAST corpus , which is the standard input for most of our tools , including COWAL alignment platform .</sentence>
				<definiendum id="0">XML document</definiendum>
				<definiendum id="1">MULTEXT-EAST corpus</definiendum>
				<definiens id="0">XCES-Align-ana format ) , as used in the</definiens>
			</definition>
			<definition id="4">
				<sentence>MEBA is an iterative algorithm which uses the translation probabilities , distorsions and POS-affinities generated by GIZA++ and takes advantage of all preprocessing phases mentioned in the previous section .</sentence>
				<definiendum id="0">MEBA</definiendum>
				<definiens id="0">an iterative algorithm which uses the translation probabilities , distorsions and POS-affinities generated by GIZA++ and takes advantage of all preprocessing phases mentioned in the previous section</definiens>
			</definition>
			<definition id="5">
				<sentence>The simplest combination method consists in computing either the union ( high recall , low precision ) , or the intersection ( lower recall , higher precision ) of the independent alignments .</sentence>
				<definiendum id="0">simplest combination method</definiendum>
			</definition>
			<definition id="6">
				<sentence>C3 ) competing links to the same target ( s ) of a word occurring several times in the same sentence ; consider , for example , the Romanian fragment : “…la 1 Neptun , la 2 Orastie si la 3 Afumati , … which in English is translated by the next segment : “…in Neptun , Orastie and Afumati… In spite of the gold standard considering that all three occurrences of the preposition “la” in Romanian ( la 1 , la 2 , la 3 ) are aligned to the same word in English ( “in” ) , the filtering , in this case , licensed only the alignment “la 1 &lt; - &gt; in” .</sentence>
				<definiendum id="0">Romanian fragment</definiendum>
				<definiens id="0">the same target ( s ) of a word occurring several times in the same sentence</definiens>
			</definition>
</paper>

		<paper id="1621">
			<definition id="0">
				<sentence>NOCB , a second baseline , which enhances M.NOCB with a global constraint on coherence that [ Karamanis , 2003 ] calls the PageFocus ( PF ) .</sentence>
				<definiendum id="0">NOCB</definiendum>
			</definition>
			<definition id="1">
				<sentence>The random baseline consists of 10 randomly selected orderings for each Testitem .</sentence>
				<definiendum id="0">random baseline</definiendum>
			</definition>
			<definition id="2">
				<sentence>Kendall’s ¿ is based on the number of inversions between the two orderings and is calculated as follows : ( 1 ) ¿ = 1¡ 2IPN = 1¡ 2IN ( N¡1 ) =2 PN stands for the number of pairs of sentences and N is the number of sentences to be ordered.7 I stands for the number of inversions , that is , the number of adjacent transpositions necessary to bring one ordering to another .</sentence>
				<definiendum id="0">Kendall’s ¿</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">based on the number of inversions between the two orderings and is calculated as follows : ( 1 ) ¿ = 1¡ 2IPN = 1¡ 2IN ( N¡1 ) =2 PN stands for the number of pairs of sentences and</definiens>
				<definiens id="1">the number of sentences to be ordered.7 I stands for the number of inversions</definiens>
			</definition>
			<definition id="3">
				<sentence>Since a total of E experts gives rise to PE = E ( E¡1 ) 2 expert pairs , T ( EXPEXP ) , is computed by summing up the average distances between all expert pairs and dividing the sum by PE .</sentence>
				<definiendum id="0">T ( EXPEXP</definiendum>
				<definiens id="0">computed by summing up the average distances between all expert pairs and dividing the sum by PE</definiens>
			</definition>
			<definition id="4">
				<sentence>BFP is the most robust metric , as the difference between T ( EXPPF : BFP ) and T ( EXPEXP ) is clearly not significant .</sentence>
				<definiendum id="0">BFP</definiendum>
				<definiens id="0">the most robust metric</definiens>
			</definition>
</paper>

		<paper id="0818">
			<definition id="0">
				<sentence>As the first step , LIHLA uses alignments between single words defined in two bilingual lexicons ( source–target and target–source ) generated from sentence-aligned parallel texts using NATools.1 Given two sentence-aligned corpus files , the NATools word aligner —based on the Twenty-One system ( Hiemstra , 1998 ) — counts the co-occurrences of words in all aligned sentence pairs and builds a sparse matrix of word-to-word probabilities ( Model A ) using an iterative expectation-maximization algorithm ( 5 iterations by default ) .</sentence>
				<definiendum id="0">LIHLA</definiendum>
				<definiens id="0">uses alignments between single words defined in two bilingual lexicons ( source–target and target–source</definiens>
				<definiens id="1">the co-occurrences of words in all aligned sentence pairs and builds a sparse matrix of word-to-word probabilities ( Model A ) using an iterative expectation-maximization algorithm ( 5 iterations by default )</definiens>
			</definition>
			<definition id="1">
				<sentence>Then , LIHLA selects the best target candidate word ti for sj —the best candidate word according to BS among those in a position which is favorably situated in relation to sj— and looks for multiword units involving sj and ti —those words that occur immediately before and/or after sj ( for source multiword units ) or 2The LCSR of two words is computed by dividing the length of their longest common subsequence by the length of the longer word .</sentence>
				<definiendum id="0">LIHLA</definiendum>
				<definiens id="0">selects the best target candidate word ti for sj —the best candidate word according to BS among those in a position which is favorably situated in relation to sj— and looks for multiword units involving sj and ti —those words that occur immediately before and/or after sj ( for source multiword units ) or 2The LCSR of two words is computed by dividing the length of their longest common subsequence by the length of the longer word</definiens>
			</definition>
			<definition id="2">
				<sentence>ti ( for target multiword units ) and are not possible translations for other words in T and S , respectively .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiens id="0">target multiword units ) and are not possible translations for other words in T and S , respectively</definiens>
			</definition>
			<definition id="3">
				<sentence>This paper has presented a lexical alignment method , LIHLA , which aligns words and multiword units based on initial statistical word-to-word correspondences and language-independent heuristics .</sentence>
				<definiendum id="0">LIHLA</definiendum>
				<definiens id="0">aligns words and multiword units based on initial statistical word-to-word correspondences and language-independent heuristics</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>The ERG is an implemented open-source broad-coverage precision Head-driven Phrase Structure Grammar 68 Secondary LR type Description Preprocessor ( s ) Word list∗∗∗ List of words with basic POS — Morphological lexicon∗ Derivational and inflectional word relations — Compiled corpus∗∗∗ Unannotated text corpus POS tagger∗∗ Chunk parser∗ Dependency parser∗ WordNet-style ontology∗ Lexical semantic word linkages — Table 1 : Secondary LR and tool types targeted in this research ( ∗∗∗ = high expectation of availability for a given language ; ∗∗ = medium expectation of availability ; ∗ = low expectation of availability ) ( HPSG ) developed for both parsing and generation .</sentence>
				<definiendum id="0">ERG</definiendum>
				<definiendum id="1">∗∗</definiendum>
				<definiens id="0">an implemented open-source broad-coverage precision Head-driven Phrase Structure Grammar 68 Secondary LR type Description Preprocessor ( s ) Word list∗∗∗ List of words with basic POS — Morphological lexicon∗ Derivational and inflectional word relations — Compiled corpus∗∗∗ Unannotated text corpus POS tagger∗∗ Chunk parser∗ Dependency parser∗ WordNet-style ontology∗ Lexical semantic word linkages — Table 1 : Secondary LR and tool types targeted in this research ( ∗∗∗ = high expectation of availability for a given language ;</definiens>
			</definition>
			<definition id="1">
				<sentence>The proposed procedure for DLA is to generate a feature signature for each word contained in a given secondary LR , take the subset of lexemes contained in the original DLR as training data , and learn lexical items for the remainder of the lexemes through supervised learning .</sentence>
				<definiendum id="0">DLA</definiendum>
				<definiens id="0">to generate a feature signature for each word contained in a given secondary LR , take the subset of lexemes contained in the original DLR as training data</definiens>
			</definition>
			<definition id="2">
				<sentence>Syntax-based DLA takes a raw text corpus and preprocesses it with either a tagger , chunker or dependency parser .</sentence>
				<definiendum id="0">Syntax-based DLA</definiendum>
				<definiens id="0">takes a raw text corpus and preprocesses it with either a tagger , chunker or dependency parser</definiens>
			</definition>
			<definition id="3">
				<sentence>We also measure the token accuracy for the lexicon derived from each method , relative to the Redwoods treebank of Verbmobil data associated with the ERG ( see Section 2.1 ) .10 The token accuracy represents a weighted version of type precision , relative to the distribution of each lexical item in a representative text sample , and provides a crude approximation of the impact of each DLA method on parser coverage .</sentence>
				<definiendum id="0">token accuracy</definiendum>
				<definiendum id="1">token accuracy</definiendum>
			</definition>
			<definition id="4">
				<sentence>The baseline method ( Base ) in each case is a simple majority-class classifier , which generates a unique lexical item for each lexeme pre-identified as belonging to a given word class of the following type : Word class Majority-class lexical type Noun n intr le Verb v np trans le Adjective adj intrans le Adverb adv int vp le 10Note that the token accuracy is calculated only over the open-class lexical items , not the full ERG lexicon .</sentence>
				<definiendum id="0">Base</definiendum>
				<definiens id="0">a simple majority-class classifier , which generates a unique lexical item for each lexeme pre-identified as belonging to a given word class of the following type</definiens>
			</definition>
			<definition id="5">
				<sentence>This correlates with an inherent advantage in terms of token accuracy , which we have no way of balancing up in our token-based evaluation , as the treebank data offers no insight into the true worth of false negative lexical items ( i.e. have no way of distinguishing between unobserved lexical items which are plain wrong from those which are intuitively correct and could be expected to occur in alternate sets of treebank data ) .</sentence>
				<definiendum id="0">token accuracy</definiendum>
			</definition>
			<definition id="6">
				<sentence>Adjectives , on the other hand , can be learned most effectively from simple character n-grams , i.e. similarlyspelled adjectives tend to have similar syntax , a somewhat surprising finding .</sentence>
				<definiendum id="0">Adjectives</definiendum>
				<definiens id="0">simple character n-grams , i.e. similarlyspelled adjectives tend to have similar syntax , a somewhat surprising finding</definiens>
			</definition>
</paper>

		<paper id="1509">
			<definition id="0">
				<sentence>The set of wellformed sequences of derivation moves in this parser is defined by a Predictive LR pushdown automaton ( Nederhof , 1994 ) , which implements a form of leftcorner parsing strategy .</sentence>
				<definiendum id="0">Predictive LR pushdown automaton</definiendum>
				<definiens id="0">implements a form of leftcorner parsing strategy</definiens>
			</definition>
			<definition id="1">
				<sentence>This pushdown automaton operates on configurations of the form ( Γ , v ) , where Γ represents the stack , whose right-most element is the top , and v the remaining input .</sentence>
				<definiendum id="0">pushdown automaton</definiendum>
				<definiendum id="1">Γ</definiendum>
				<definiens id="0">operates on configurations of the form ( Γ , v )</definiens>
			</definition>
			<definition id="2">
				<sentence>The initial configuration is ( ROOT , w ) where ROOT is a distinguished non-terminal symbol .</sentence>
				<definiendum id="0">ROOT</definiendum>
				<definiens id="0">a distinguished non-terminal symbol</definiens>
			</definition>
			<definition id="3">
				<sentence>Assuming standard notation for context-free grammars ( Nederhof , 1994 ) , three derivation moves are defined : shift ( [ B → β ] , av ) turnstileleft ( [ B → β ] [ A → a ] , v ) where A → a and B → βCγ are productions such that A is a left-corner of C. project ( [ B → β ] [ A → α ] , v ) turnstileleft ( [ B → β ] [ D → A ] , v ) where A → α , D → Aδ and B → βCγ are productions such that D is a left-corner of C. attach ( [ B → β ] [ A → α ] , v ) turnstileleft ( [ B → βA ] , v ) where both A → α and B → βAγ are productions .</sentence>
				<definiendum id="0">context-free grammars</definiendum>
				<definiens id="0">project ( [ B → β ] [ A → α ] , v ) turnstileleft ( [ B → β ] [ D → A ] , v ) where A → α</definiens>
			</definition>
			<definition id="4">
				<sentence>However , the recency preference exhibited by recursively defined neural networks biases learning towards information which flows through fewer 85 history representations .</sentence>
				<definiendum id="0">recency preference</definiendum>
				<definiens id="0">exhibited by recursively defined neural networks biases learning towards information which flows through fewer 85 history representations</definiens>
			</definition>
			<definition id="5">
				<sentence>It is a well-attested typological generalisation that one does not find sentences where the subject is a Theme and the object is the Agent .</sentence>
				<definiendum id="0">subject</definiendum>
				<definiens id="0">a well-attested typological generalisation that one does not find sentences where the</definiens>
			</definition>
			<definition id="6">
				<sentence>Both parsing results taking function labels into account in the evaluation ( FLABEL ) and results not taking them into account in the evaluation ( FLABEL-less ) are reported in Table 2 , which shows results on the test set , section 23 of the PTB .</sentence>
				<definiendum id="0">FLABEL</definiendum>
				<definiens id="0">shows results on the test set , section 23 of the PTB</definiens>
			</definition>
</paper>

		<paper id="1210">
			<definition id="0">
				<sentence>In this paper we define two intermediate models of textual entailment , which correspond to lexical and lexical-syntactic levels of representation .</sentence>
				<definiendum id="0">textual entailment</definiendum>
				<definiens id="0">correspond to lexical and lexical-syntactic levels of representation</definiens>
			</definition>
			<definition id="1">
				<sentence>Co-reference Co-references provide equivalence relations between different terms in the text and thus induce transformations that replace one term in a text with any of its co-referenced terms .</sentence>
				<definiendum id="0">Co-reference Co-references</definiendum>
				<definiens id="0">provide equivalence relations between different terms in the text and thus induce transformations that replace one term in a text with any of its co-referenced terms</definiens>
			</definition>
			<definition id="2">
				<sentence>The RTE test-set4 contains 800 Text-Hypothesis pairs ( usually single sentences ) , which are typical 1Example no 322 in the PASCAL RTE test-set .</sentence>
				<definiendum id="0">RTE test-set4</definiendum>
			</definition>
</paper>

		<paper id="0617">
			<definition id="0">
				<sentence>A somewhat tighter definition of co-occurrence , which nevertheless yields a semantic distance measure , serves as the basis of a method that captures irregular inflectional transformations in Yarowsky and Wicentowski ( 2001 ) .1 Schone and Jurafsky ( 2001 ) employ distributions over adjacent words ( yielding a syntactic distance metric ) to improve the precision of their conflation sets .</sentence>
				<definiendum id="0">co-occurrence</definiendum>
			</definition>
			<definition id="1">
				<sentence>A transform is an affix substitution which entails a change of clusters .</sentence>
				<definiendum id="0">transform</definiendum>
				<definiens id="0">an affix substitution which entails a change of clusters</definiens>
			</definition>
</paper>

		<paper id="0802">
			<definition id="0">
				<sentence>On the other hand in the worldwide scenario of the web age , multilinguality is a crucial issue to deal with and to investigate , leading us to reformulate most of the classical NLP problems .</sentence>
				<definiendum id="0">multilinguality</definiendum>
			</definition>
			<definition id="1">
				<sentence>A MDM is a set of clusters formed by terms in different languages .</sentence>
				<definiendum id="0">MDM</definiendum>
				<definiens id="0">a set of clusters formed by terms in different languages</definiens>
			</definition>
			<definition id="2">
				<sentence>In a more precise way , let L = fL1 , L2 , ... , Llg be a set of languages , let Ti = fti1 , ti2 , ... , ting be a collection of texts expressed in the language Li 2L , and let ψ ( tjh , tiz ) be a function that returns 1 if tiz is the translation of tjh and 0 otherwise .</sentence>
				<definiendum id="0">L2 , ... , Llg</definiendum>
				<definiendum id="1">tiz )</definiendum>
				<definiens id="0">a set of languages , let Ti = fti1 , ti2 , ... , ting be a collection of texts expressed in the language Li 2L</definiens>
			</definition>
			<definition id="3">
				<sentence>In the monolingual settings , the Vector Space Model ( VSM ) is a k-dimensional space Rk , in which the text tj 2 T is represented by means of the vector vectortj such that the zth component of vectortj is the frequency of wz in tj .</sentence>
				<definiendum id="0">Vector Space Model</definiendum>
				<definiendum id="1">VSM )</definiendum>
				<definiendum id="2">vectortj</definiendum>
				<definiens id="0">a k-dimensional space Rk , in which the text tj 2 T is represented by means of the vector vectortj such that the zth component of</definiens>
			</definition>
			<definition id="4">
				<sentence>A MDM is a multilingual extension of the concept of Domain Model .</sentence>
				<definiendum id="0">MDM</definiendum>
				<definiens id="0">a multilingual extension of the concept of Domain Model</definiens>
			</definition>
			<definition id="5">
				<sentence>Each cluster represents a semantic domain , i.e. a set of terms that often co-occur in texts having similar topics .</sentence>
				<definiendum id="0">cluster</definiendum>
				<definiens id="0">a semantic domain</definiens>
			</definition>
			<definition id="6">
				<sentence>The function D is de ned by2 2In ( Wong et al. , 1985 ) the formula 1 is used to de ne a Generalized Vector Space Model , of which the Domain VSM is a particular instance .</sentence>
				<definiendum id="0">Domain VSM</definiendum>
				<definiens id="0">a particular instance</definiens>
			</definition>
			<definition id="7">
				<sentence>D ( vectortj ) = vectortj ( IIDFD ) = vectortprimej ( 1 ) where IIDF is a diagonal matrix such thatiIDFi , i = IDF ( wli ) , vectortj is represented as a row vector , and IDF ( wli ) is the Inverse Document Frequency of wli evaluated in the corpus Tl .</sentence>
				<definiendum id="0">IIDF</definiendum>
				<definiendum id="1">IDF ( wli )</definiendum>
				<definiens id="0">a diagonal matrix such thatiIDFi</definiens>
			</definition>
			<definition id="8">
				<sentence>LSA is an unsupervised technique for estimating the similarity among texts and terms in a large corpus .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">an unsupervised technique for estimating the similarity among texts and terms in a large corpus</definiens>
			</definition>
			<definition id="9">
				<sentence>SVD decomposes the term-by-document matrix T into three matrixes T ’ VΣkprimeUT where Σkprime is the diagonal k k matrix containing the highest kprime k 12 eigenvalues of T , and all the remaining elements are set to 0 .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">decomposes the term-by-document matrix T into three matrixes T ’ VΣkprimeUT where Σkprime is the diagonal k k matrix containing the highest kprime k 12 eigenvalues of T</definiens>
			</definition>
			<definition id="10">
				<sentence>DLSA = INVradicalbigΣkprime ( 2 ) where IN is a diagonal matrix such that iNi , i = 1radicalBig 〈 vectorwprimei , vectorwprimei〉 , vectorwprimei is the ith row of the matrix VpΣkprime .</sentence>
				<definiendum id="0">IN</definiendum>
				<definiendum id="1">vectorwprimei</definiendum>
				<definiens id="0">a diagonal matrix such that iNi , i = 1radicalBig 〈 vectorwprimei</definiens>
			</definition>
			<definition id="11">
				<sentence>New examples are then assigned to the class 13 of the closest support vectors , according to equation f ( x ) = nsummationdisplay i=1 λiK ( xi , x ) +λ0 ( 3 ) The kernel function K ( xi , x ) returns the similarity between two instances in the input space X , and can be designed just by taking care that some formal requirements are satis ed , as described in ( Schcurrency1olkopf and Smola , 2001 ) .</sentence>
				<definiendum id="0">kernel function K</definiendum>
				<definiens id="0">returns the similarity between two instances in the input space X , and can be designed just by taking care that some formal requirements are satis ed</definiens>
			</definition>
			<definition id="12">
				<sentence>The BoW kernel is a particular case of the Domain Kernel , in which D = I , and I is the identity matrix .</sentence>
				<definiendum id="0">BoW kernel</definiendum>
				<definiens id="0">a particular case of the Domain Kernel , in which D = I</definiens>
			</definition>
			<definition id="13">
				<sentence>14 English Italian Categories Training Test Total Training Test Total Quality of Life 5759 1989 7748 5781 1901 7682 Made in Italy 5711 1864 7575 6111 2068 8179 Tourism 5731 1857 7588 6090 2015 8105 Culture and School 3665 1245 4910 6284 2104 8388 Total 20866 6955 27821 24266 8088 32354 Table 3 : Number of documents in the data set partitions 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 F1 measure Fraction of training data BoW Kernel Figure 2 : Learning curves for the English part of the corpus 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 F1 measure Fraction of training data BoW Kernel Figure 3 : Learning curves for the Italian part of the corpus As far as the cross language TC task is concerned , we tried the two possible options : we trained on the English part and we classi ed the Italian part , and we trained on the Italian and classi ed on the En0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 F1 measure Fraction of training data Multilingual Domain Kernel Bow Kernel Figure 4 : Cross-language ( training on Italian , test on English ) learning curves 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 F1 measure Fraction of training data Multilingual Domain Kernel Bow Kernel Figure 5 : Cross-language ( training on English , test on Italian ) learning curves glish part .</sentence>
				<definiendum id="0">Learning curves</definiendum>
				<definiens id="0">for the English part of the corpus 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 F1 measure Fraction of training data BoW Kernel Figure 3 : Learning curves for the Italian part of the corpus As</definiens>
			</definition>
</paper>

		<paper id="0503">
			<definition id="0">
				<sentence>The first line of ( 1b ) expresses the notion that each stem consists of a pointer to its signature and a list of pointers to the letters that comprise it ; σ ( t ) is the signature associated with stem t , and we take its probability to be ] [ ) ] ( [ W tσ , the empirical count of the words associated with σ ( t ) divided by the total count of words in the data .</sentence>
				<definiendum id="0">σ</definiendum>
				<definiens id="0">the empirical count of the words associated with σ ( t ) divided by the total count of words in the data</definiens>
			</definition>
			<definition id="1">
				<sentence>We assign the value of each feature y of x’s context vector as the pointwise mutual information of the corresponding element pair ( x , y ) , defined as ) ( ) ( ) , ( log yprxpr yxpr .</sentence>
				<definiendum id="0">) ( )</definiendum>
				<definiens id="0">the value of each feature y of x’s context vector as the pointwise mutual information of the corresponding element pair ( x , y )</definiens>
			</definition>
</paper>

		<paper id="0801">
			<definition id="0">
				<sentence>Bilingual word alignment is the first step of most current approaches to statistical machine translation .</sentence>
				<definiendum id="0">Bilingual word alignment</definiendum>
			</definition>
			<definition id="1">
				<sentence>We report the performance of various alignment algorithms in terms of precision , recall , and alignment error rate ( AER ) as defined by Och and Ney ( 2003 ) : recall = |A ∩ S| |S| precision = |A ∩ P| |A| AER = 1− |A ∩ P|+ |A ∩ S| |A| + |S| In these definitions , S denotes the set of alignments annotated as sure , P denotes the set of alignments annotated possible or sure , and A denotes the set of alignments produced by the method under test .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">the performance of various alignment algorithms in terms of precision , recall , and alignment error rate ( AER ) as defined by Och and Ney ( 2003 ) : recall = |A ∩ S| |S| precision = |A ∩ P| |A| AER = 1− |A ∩ P|+ |A ∩ S| |A| + |S| In these definitions ,</definiens>
				<definiens id="1">the set of alignments annotated as sure ,</definiens>
				<definiens id="2">the set of alignments annotated possible or sure , and A denotes the set of alignments produced by the method under test</definiens>
			</definition>
			<definition id="2">
				<sentence>We estimate this link probability LP as LP ( f , e ) = links 1 ( f , e ) cooc ( f , e ) where links 1 ( f , e ) is the number of times f and e are linked according to Method 1 , and cooc ( f , e ) is the number of times f and e co-occur in aligned sentences .</sentence>
				<definiendum id="0">cooc</definiendum>
				<definiendum id="1">e )</definiendum>
				<definiens id="0">the number of times f and e co-occur in aligned sentences</definiens>
			</definition>
</paper>

		<paper id="0507">
			<definition id="0">
				<sentence>Conservatism is a powerful mechanism for addressing the logical problem .</sentence>
				<definiendum id="0">Conservatism</definiendum>
				<definiens id="0">a powerful mechanism for addressing the logical problem</definiens>
			</definition>
			<definition id="1">
				<sentence>The Competition Model assumes that children are continually storing traces of the words and phrases they hear along with tags that indicate that these phrases derive directly from adult input .</sentence>
				<definiendum id="0">Competition Model</definiendum>
				<definiens id="0">assumes that children are continually storing traces of the words and phrases they hear along with tags that indicate that these phrases derive directly from adult input</definiens>
			</definition>
			<definition id="2">
				<sentence>The Competition Model holds that , over time , correct forms gain strength from encounters with positive exemplars and that this increasing strength leads them to drive out incorrect forms .</sentence>
				<definiendum id="0">Competition Model</definiendum>
				<definiens id="0">holds that , over time , correct forms gain strength from encounters with positive exemplars and that this increasing strength leads them to drive out incorrect forms</definiens>
			</definition>
			<definition id="3">
				<sentence>MacWhiney ( 1978 ) and Elbers &amp; Wijnen ( 193 ) have treated this type of self-correction as involving ‘expressive monitoring’ in which the child listens to her own output , compares the correct weak rote form with the incorrect overgeneralization , and attempts to block the output of the incorrect form .</sentence>
				<definiendum id="0">MacWhiney</definiendum>
				<definiens id="0">involving ‘expressive monitoring’ in which the child listens to her own output , compares the correct weak rote form with the incorrect overgeneralization , and attempts to block the output of the incorrect form</definiens>
			</definition>
</paper>

		<paper id="0510">
</paper>

		<paper id="0207">
			<definition id="0">
				<sentence>Expression involves the linguistic elements that relate to how an author phrases particular content and can be used to identify potential copyright infringement or plagiarism .</sentence>
				<definiendum id="0">Expression</definiendum>
				<definiens id="0">involves the linguistic elements that relate to how an author phrases particular content and can be used to identify potential copyright infringement or plagiarism</definiens>
			</definition>
			<definition id="1">
				<sentence>Alexander and Kunz ( 1964 ) identi ed syntactic classes of embedding verbs , collected a comprehensive set of verbs for each class , and described the identi ed verb classes with formulae written in terms of phrasal and clausal elements , such as verb phrase heads ( Vh ) , participial phrases ( Partcp . )</sentence>
				<definiendum id="0">participial phrases</definiendum>
				<definiens id="0">formulae written in terms of phrasal and clausal elements</definiens>
			</definition>
			<definition id="2">
				<sentence>T df-weighted Keywords : Keywords , i.e. , content words , are frequently used in content-based text classi cation and constitute one of our baselines .</sentence>
				<definiendum id="0">T df-weighted Keywords</definiendum>
				<definiens id="0">Keywords , i.e. , content words</definiens>
			</definition>
			<definition id="3">
				<sentence>Plagiarism is a problem at all levels of education .</sentence>
				<definiendum id="0">Plagiarism</definiendum>
				<definiens id="0">a problem at all levels of education</definiens>
			</definition>
</paper>

		<paper id="1526">
			<definition id="0">
				<sentence>Aug-TRIPS retains the same grammar and lexicon as TRIPS , but uses its statistical model to determine the order in which unifications are attempted .</sentence>
				<definiendum id="0">Aug-TRIPS</definiendum>
				<definiens id="0">retains the same grammar and lexicon as TRIPS , but uses its statistical model to determine the order in which unifications are attempted</definiens>
			</definition>
			<definition id="1">
				<sentence>Aug-TRIPS is comparable to TRIPS in accuracy , but produces fewer constituents ( Table 1 ) .</sentence>
				<definiendum id="0">Aug-TRIPS</definiendum>
				<definiens id="0">comparable to TRIPS in accuracy , but produces fewer constituents ( Table 1 )</definiens>
			</definition>
			<definition id="2">
				<sentence>The model generates one or more senses from each word with probability P ( sense|word , tag ) , and then uses sense statistics rather than word statistics in all other calculations .</sentence>
				<definiendum id="0">model</definiendum>
				<definiens id="0">generates one or more senses from each word with probability P ( sense|word , tag ) , and then uses sense statistics rather than word statistics in all other calculations</definiens>
			</definition>
</paper>

		<paper id="0809">
			<definition id="0">
				<sentence>All data sets were sentence-aligned , and pre-processed ( i.e. tokenized and lower-cased ) , with identical preprocessing procedures used for training , trial , and test data .</sentence>
				<definiendum id="0">pre-processed</definiendum>
			</definition>
			<definition id="1">
				<sentence>Given numerous ( constructive ) debates held during the previous word alignment evaluation , which questioned the informativeness of the NULL alignment evaluations , we decided 67 Team System name Description Carnegie Mellon University SPA ( Brown et al. , 2005 ) Information Sciences Institute / USC ISI ( Fraser and Marcu , 2005 ) Johns Hopkins University JHU ( Schafer and Drabek , 2005 ) Microsoft Research MSR ( Moore , 2005 ) Romanian Academy Institute of Artificial Intelligence TREQ-AL , MEBA , COWAL ( Tufis et al. , 2005 ) University of Maryland / UMIACS UMIACS ( Lopez and Resnik , 2005 ) University of Sheffield Sheffield ( Aswani and Gaizauskas , 2005a ) University of Montreal JAPA , NUKTI ( Langlais et al. , 2005 ) University of Sao Paulo , University of Alicante LIHLA ( Caseli et al. , 2005 ) University Jaume I MAR ( Vilar , 2005 ) Table 1 : Teams participating in the word alignment shared task to evaluate only no-NULL alignments , and thus the NULL alignments were removed from both submissions and gold standard data .</sentence>
				<definiendum id="0">numerous</definiendum>
			</definition>
			<definition id="2">
				<sentence>Se-veral teams used symmetrization metrics , as introduced in ( Och and Ney , 2003 ) ( union , intersection , refined ) , most of the times applied on the alignments produced for the two directions source–target and target–source , but also as a way to combine different word alignment systems .</sentence>
				<definiendum id="0">symmetrization metrics</definiendum>
				<definiens id="0">union , intersection , refined ) , most of the times applied on the alignments produced for the two directions source–target and target–source , but also as a way to combine different word alignment systems</definiens>
			</definition>
</paper>

		<paper id="1517">
			<definition id="0">
				<sentence>RASP is a robust statistical analysis system for English developed by Briscoe and Carroll ( 2002 ) .</sentence>
				<definiendum id="0">RASP</definiendum>
			</definition>
			<definition id="1">
				<sentence>A ‘packed node’ is a node representing a sub-analysis that is subsumed by , and hence packed into , another node .</sentence>
				<definiendum id="0">‘packed node’</definiendum>
				<definiens id="0">a node representing a sub-analysis that is subsumed by , and hence packed into , another node</definiens>
			</definition>
			<definition id="2">
				<sentence>Therefore , the normalised probability ( and final weight ) of the GR is a3 a6 a11a13a12a15a14a17a16a19a18a20a17a21a17a22a19a23a24a21a26a25a27a12a28a12a15a14a17a16a19a18a20a17a14a17a20a17a20a17a16a17a29a17a22a31a30a33a32 a6 a4 a10a3a1 a6a5a34 a3a27a8 King et al. ( 2003 ) outline the development of the PARC 700 Dependency Bank ( henceforth , DepBank ) , a gold-standard set of relational dependencies for 700 sentences ( originally from the Wall Street Journal ) drawn at random from Section 23 of the Penn Treebank .</sentence>
				<definiendum id="0">normalised probability</definiendum>
				<definiendum id="1">GR</definiendum>
				<definiens id="0">a gold-standard set of relational dependencies for 700 sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>The inside probability represents the probability of all possible sub-analyses of a node .</sentence>
				<definiendum id="0">inside probability</definiendum>
				<definiens id="0">the probability of all possible sub-analyses of a node</definiens>
			</definition>
			<definition id="4">
				<sentence>Conversely , the outside probability represents the probability of all analyses for which the node is a sub-analysis .</sentence>
				<definiendum id="0">outside probability</definiendum>
				<definiens id="0">the probability of all analyses for which the node is a sub-analysis</definiens>
			</definition>
			<definition id="5">
				<sentence>Three processing stages are required to determine weighted GRs over the parse forest , calculating ( 1 ) filled GRs and corresponding inside probabili164 −28.0201 ( ncsubj see+ed_VVD I_PPIS1 _ ) −35.1598 ( ncmod _ man_NN1 in_II ) −28.0201 ( det park_NN1 the_AT ) −29.1187 ( ncmod _ see+ed_VVD in_II ) −28.0562 ( iobj see+ed_VVD in_II ) −28.0201 ( dobj see+ed_VVD man_NN1 ) −28.0201 ( dobj in_II park_NN1 ) −28.0201 ( det man_NN1 the_AT ) parse ( log ) probability : −28.056154 ( ncsubj see+ed I _ ) ( iobj see+ed in ) ( dobj see+ed man ) ( dobj in park ) ( det park the ) ( det man the ) parse ( log ) probability : −29.11871 ( ncsubj see+ed I _ ) ( ncmod _ see+ed in ) ( dobj in park ) ( det park the ) ( dobj see+ed man ) ( det man the ) parse ( log ) probability : −35.159805 ( ncsubj see+ed I _ ) ( dobj see+ed man ) ( det man the ) ( ncmod _ man in ) ( dobj in park ) ( det park the ) Total Probability ( log−sum of all parses ) : −28.0200896 ( NORMALISED ) WEIGHTED GRS N−BEST GRS ( NON NORMALISED ) WEIGHTED GRS Figure 3 : The n-best GRs , and non-normalised/normalised weighted GRs determined from three parses for the sentence I saw the man in the park .</sentence>
				<definiendum id="0">det park the )</definiendum>
				<definiens id="0">dobj see+ed man ) ( dobj in park ) ( det park the )</definiens>
				<definiens id="1">dobj see+ed man ) ( det man the ) ( ncmod _ man in ) ( dobj in park ) ( det park the ) Total Probability ( log−sum of all parses ) : −28.0200896 ( NORMALISED ) WEIGHTED GRS N−BEST GRS ( NON NORMALISED ) WEIGHTED GRS Figure 3 : The n-best GRs , and non-normalised/normalised weighted GRs determined from three parses for the sentence I saw the man in the park</definiens>
			</definition>
			<definition id="6">
				<sentence>Therefore , EWG achieves a substantial improvement in both efficiency and accuracy for weighted GR calculation ; providing increased precision for thresholded GR sets and an increased Fa23 upper bound on the task .</sentence>
				<definiendum id="0">EWG</definiendum>
				<definiens id="0">achieves a substantial improvement in both efficiency and accuracy for weighted GR calculation ; providing increased precision for thresholded GR sets and an increased Fa23 upper bound on the task</definiens>
			</definition>
</paper>

		<paper id="0312">
			<definition id="0">
				<sentence>Like the Penn English Discourse Treebank ( Miltsakaki et al. , 2004a ; Miltsakaki et al. , 2004b ) , the CDTB project adopts the general idea presented in ( Webber and Joshi , 1998 ; Webber et al. , 1999 ; Webber et al. , 2003 ) where discourse connectives are considered to be predicates that take abstract objects such as propositions , events and situations as their arguments .</sentence>
				<definiendum id="0">CDTB project</definiendum>
			</definition>
			<definition id="1">
				<sentence>Subordinate conjunctions , coordinate conjunctions and discourse adverbial can all occur in clauseinitial as well as clause-medial positions .</sentence>
				<definiendum id="0">Subordinate conjunctions</definiendum>
				<definiens id="0">coordinate conjunctions and discourse adverbial can all occur in clauseinitial as well as clause-medial positions</definiens>
			</definition>
			<definition id="2">
				<sentence>Localizers are a class of words that occur after clauses or noun phrases to denote temporal or spatial discourse relations .</sentence>
				<definiendum id="0">Localizers</definiendum>
			</definition>
			<definition id="3">
				<sentence>The flip side of sense disambiguation is that one discourse relation is often realized with different discourse connectives due to the long evolution of the Chinese language and morphological processes like suoxie , which is one form of abbreviation .</sentence>
				<definiendum id="0">suoxie</definiendum>
			</definition>
</paper>

		<paper id="0633">
			<definition id="0">
				<sentence>Adjacency : whether the right ( if before ) or left ( if after ) boundary of the constituent is adjacent , non-adjacent or inside the predicate’s chunk .</sentence>
				<definiendum id="0">Adjacency</definiendum>
				<definiens id="0">non-adjacent or inside the predicate’s chunk</definiens>
			</definition>
			<definition id="1">
				<sentence>Predicate : the predicate lemma , represented as the probability distribution P ( r|p ) of the predicate p of taking one of the available r semantic roles .</sentence>
				<definiendum id="0">Predicate</definiendum>
				<definiens id="0">the predicate lemma , represented as the probability distribution P ( r|p ) of the predicate p of taking one of the available r semantic roles</definiens>
			</definition>
			<definition id="2">
				<sentence>Voice : whether the predicate is in active or passive form .</sentence>
				<definiendum id="0">Voice</definiendum>
				<definiens id="0">whether the predicate is in active or passive form</definiens>
			</definition>
			<definition id="3">
				<sentence>Path : the number of intervening NPB , NP , VP , VPA , PP , PP-A , S , S-A and SBAR nodes along the path from the constituent to the predicate .</sentence>
				<definiendum id="0">Path</definiendum>
				<definiens id="0">the number of intervening NPB , NP , VP , VPA , PP , PP-A , S , S-A and SBAR nodes along the path from the constituent to the predicate</definiens>
			</definition>
			<definition id="4">
				<sentence>The proposition bank : An annotated corpus of semantic roles .</sentence>
				<definiendum id="0">proposition bank</definiendum>
				<definiens id="0">An annotated corpus of semantic roles</definiens>
			</definition>
</paper>

		<paper id="0629">
			<definition id="0">
				<sentence>1st Words ( Bag of Words ) : All words appearing in the training data .</sentence>
				<definiendum id="0">Words )</definiendum>
				<definiens id="0">All words appearing in the training data</definiens>
			</definition>
			<definition id="1">
				<sentence>Input features are written in each column as words ( 1st ) , POS tags ( 2nd ) , base phrase chunks ( 3rd ) , named entities ( 4th ) , token depth ( 5th ) , predicate ( 6th ) , the position of tokens ( 7th ) , the phrase distance ( 8th ) , flat paths ( 9th ) , semantic classes ( 10th ) , and argument classes ( 11th ) .</sentence>
				<definiendum id="0">position of tokens</definiendum>
				<definiens id="0">1st ) , POS tags ( 2nd ) , base phrase chunks ( 3rd ) , named entities ( 4th ) , token depth ( 5th )</definiens>
			</definition>
</paper>

		<paper id="0834">
			<definition id="0">
				<sentence>Word graphs are an important data structure with various applications : † Word Filter .</sentence>
				<definiendum id="0">Word graphs</definiendum>
				<definiens id="0">an important data structure with various applications : † Word Filter</definiens>
			</definition>
			<definition id="1">
				<sentence>A word graph is a directed acyclic graph G = ( V , E ) with one designated root node n0 2 V .</sentence>
				<definiendum id="0">word graph</definiendum>
				<definiens id="0">a directed acyclic graph G = ( V , E ) with one designated root node n0 2 V</definiens>
			</definition>
			<definition id="2">
				<sentence>This translation process consists of the following steps that will be described afterward : Now , we will describe each step .</sentence>
				<definiendum id="0">translation process</definiendum>
				<definiens id="0">consists of the following steps that will be described afterward : Now</definiens>
			</definition>
			<definition id="3">
				<sentence>The rst step is the segmentation into phrases .</sentence>
				<definiendum id="0">rst step</definiendum>
				<definiens id="0">the segmentation into phrases</definiens>
			</definition>
			<definition id="4">
				<sentence>The posterior probability q ( n , nprime , w ) of an edge is de ned as : q ( n , nprime , w ) = F ( n ) ¢ p ( n , n prime , w ) ¢ B ( nprime ) B ( n0 ) The posterior probability of an edge is identical to the sum over the probabilities of all full paths that contain this edge .</sentence>
				<definiendum id="0">posterior probability q</definiendum>
				<definiens id="0">nprime , w ) of an edge is de ned as : q ( n , nprime , w ) = F ( n ) ¢ p ( n , n prime , w ) ¢ B ( nprime ) B ( n0 ) The posterior probability of an edge is identical to the sum over the probabilities of all full paths that contain this edge</definiens>
			</definition>
			<definition id="5">
				<sentence>Note that the backward probability of the root node B ( n0 ) is identical to the sum over all sentence probabilities in the word graph .</sentence>
				<definiendum id="0">backward probability of the root node B</definiendum>
				<definiens id="0">identical to the sum over all sentence probabilities in the word graph</definiens>
			</definition>
			<definition id="6">
				<sentence>The GWER is a generalization of the word error rate .</sentence>
				<definiendum id="0">GWER</definiendum>
				<definiens id="0">a generalization of the word error rate</definiens>
			</definition>
			<definition id="7">
				<sentence>The GPER is a generalization of the positionindependent word error rate .</sentence>
				<definiendum id="0">GPER</definiendum>
				<definiens id="0">a generalization of the positionindependent word error rate</definiens>
			</definition>
			<definition id="8">
				<sentence>Q ( n0 , C0 ) = 0 Q ( n , C ) = min nprime , w : ( nprime , n , w ) ∈E braceleftBig Q ( nprime , C [ fwg ) , Q ( nprime , C ) + 1 bracerightBig Here , n0 denote the root node of the word graph , C0 denotes the multiset representation of the reference string .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">C0</definiendum>
			</definition>
</paper>

		<paper id="1612">
			<definition id="0">
				<sentence>Traditionally , Natural Language Generation ( NLG ) is defined as the automatic production of “meaningful texts in ( ... ) human language from some underlying non-linguistic representation of information” [ Reiter and Dale , 2000 , xvii ] .</sentence>
				<definiendum id="0">Natural Language Generation ( NLG</definiendum>
				<definiendum id="1">human language</definiendum>
				<definiens id="0">the automatic production of “meaningful texts in ( ... )</definiens>
			</definition>
			<definition id="1">
				<sentence>A dependency analysis of a sentence S yields a labeled directed graph D = 〈V , E〉 , where V ( vertices ) are the nodes , and E ( edges ) are the dependency relations .</sentence>
				<definiendum id="0">dependency analysis of a sentence S</definiendum>
				<definiens id="0">yields a labeled directed graph D = 〈V , E〉 , where V ( vertices ) are the nodes , and E ( edges ) are the dependency relations</definiens>
			</definition>
			<definition id="2">
				<sentence>We distinguish five potential , mutually exclusive , relations between nodes ( with illustrative examples ) : ( abstracting from case and word order ) Example : “a small and a large boa-constrictor” equals “a large and a small boa-constrictor” ; information content but different wording ) , Example : “a drawing of a boa-constrictor snake” restates “a drawing of a boa-constrictor” ; Example : “the planet B 612” specifies “the planet” ; STR ( v ) , Example : “the planet” generalizes “the planet B 612” ; formational content , but also each express some piece of information not expressed in the other , Example : “Jupiter and Mars” intersects “Mars and Venus” Note that there is an intuitive relation with entailment here : both equals and restates can be understood as mutual entailment ( i.e. , if the root nodes of the analyses corresponding S and Sprime stand in an equal or restate relation , S entails Sprime and Sprime entails S ) , if S specifies Sprime then S also entails Sprime and if S generalizes Sprime then S is entailed by Sprime .</sentence>
				<definiendum id="0">STR</definiendum>
				<definiens id="0">if the root nodes of the analyses corresponding S and Sprime stand in an equal or restate relation , S entails Sprime and Sprime entails S )</definiens>
			</definition>
			<definition id="3">
				<sentence>An alignment between S and Sprime can now formally be defined on the basis of the respective dependency graphs D = 〈V , E〉 and Dprime = 〈Vprime , Eprime〉 as a graph A = 〈VA , EA〉 , such that EA = { 〈v , l , vprime〉| v ∈ V &amp; vprime ∈ Vprime &amp; l ( STR ( v ) , STR ( vprime ) ) } , where l is one of the five relations defined above .</sentence>
				<definiendum id="0">STR ( vprime</definiendum>
				<definiendum id="1">l</definiendum>
				<definiens id="0">a graph A = 〈VA , EA〉 , such that EA = { 〈v , l , vprime〉| v ∈ V &amp; vprime ∈ Vprime &amp; l ( STR ( v )</definiens>
			</definition>
			<definition id="4">
				<sentence>The nodes of A are those nodes from D en Dprime which are aligned , formally defined as VA = { v |∃vprime∃l〈v , l , vprime〉∈ EA } ∪ { vprime |∃v∃l〈v , l , vprime〉∈ EA } A complete example alignment can be found in the Appendix , Figure 3 .</sentence>
				<definiendum id="0">The nodes of A</definiendum>
			</definition>
			<definition id="5">
				<sentence>With respect to alignment , we calculated the precision , recall and F-score ( with β = 1 ) on aligned node pairs as follows : precision ( Areal , Apred ) = | Areal ∩Apred || A pred | ( 1 ) recall ( Areal , Apred ) = | Areal ∩Apred || A real | ( 2 ) F-score = 2×precision×recallprecision+recall ( 3 ) where Areal is the set of all real alignments ( the reference or golden standard ) , Apred is the set of all predicted alignments , and Apred∩Areal is the set all correctly predicted alignments .</sentence>
				<definiendum id="0">Areal</definiendum>
				<definiendum id="1">Apred</definiendum>
				<definiendum id="2">Apred∩Areal</definiendum>
				<definiens id="0">with β = 1 ) on aligned node pairs as follows : precision ( Areal , Apred ) = | Areal ∩Apred || A pred | ( 1 ) recall</definiens>
				<definiens id="1">the set of all real alignments</definiens>
				<definiens id="2">the set of all predicted alignments</definiens>
				<definiens id="3">the set all correctly predicted alignments</definiens>
			</definition>
			<definition id="6">
				<sentence>Notice that the last two options imply skipping one or more edges , and leaving one or more nodes unaligned.1 The function TREEMATCH ( v , vprime ) is a measure of how well the subtrees rooted at v and vprime match : TREEMATCH ( v , vprime ) = NODEMATCH ( v , vprime ) + max p∈P ( v , vprime ) 2 ( i , j ) ∈p ¡R ELMATCH ( −→v i , −→v primej ) +S ( vi , vprimej ) ¢ 3 5 Here −→v i denotes the dependency relation from v to vi .</sentence>
				<definiendum id="0">function TREEMATCH</definiendum>
				<definiendum id="1">¡R ELMATCH</definiendum>
				<definiens id="0">a measure of how well the subtrees rooted at v and vprime match</definiens>
			</definition>
			<definition id="7">
				<sentence>Given a labeled alignment A between dependency graphs D and Dprime , if there is a restates relation between node v from D and node vprime from Dprime , we add the string realization of vprime as an alternative to those of v. RESTATE ( A ) 1 for each edge 〈v , l , vprime〉∈ EA 2 do if l = restates 3 then STR ( v ) ← STR ( v ) ∨ STR ( vprime ) The same procedure is followed in order to get specifications : SPECIFY ( A ) 1 for each edge 〈v , l , vprime〉∈ EA 2 do if l = generalizes 3 then STR ( v ) ← STR ( v ) ∨ STR ( vprime ) The generalization procedure adds the option to omit the realization of a modifier that is not aligned : GENERALIZE ( D , A ) 1 for each edge 〈v , l , vprime〉∈ EA 2 do if l = specifies 3 then STR ( v ) ← STR ( v ) ∨ STR ( vprime ) 4 for each edge 〈v , l , vprime〉∈ ED 5 do if l ∈ MOD-DEP-RELS and v /∈ EA 6 then STR ( v ) ← STR ( v ) ∨ NIL where MOD-DEP-REL is the set of dependency relations between a node and a modifier ( e.g. head/mod and head/predm ) .</sentence>
				<definiendum id="0">SPECIFY</definiendum>
				<definiendum id="1">vprime ) The generalization procedure</definiendum>
				<definiens id="0">adds the option to omit the realization of a modifier that is not aligned : GENERALIZE</definiens>
			</definition>
			<definition id="8">
				<sentence>One possible direction here is to exploit the relatively rich linguistic representation of the input sentences ( POS tags , lemmas and dependency structures ) , for instance , along the lines of [ Bangalore and Rambow , 2000 ] .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">tags , lemmas and dependency structures</definiens>
			</definition>
</paper>

		<paper id="0603">
			<definition id="0">
				<sentence>Lauer collects n-gram statistics from Grolier’s encyclopedia , containing about 8 million words .</sentence>
				<definiendum id="0">Lauer</definiendum>
				<definiens id="0">collects n-gram statistics from Grolier’s encyclopedia , containing about 8 million words</definiens>
			</definition>
			<definition id="1">
				<sentence>The adjacency model checks ( a ) , whether w2w3 is a compound ( i.e. , how strongly w2 modifies w3 as opposed to w1w2 being a compound ) to decide whether or not to predict a right bracketing .</sentence>
				<definiendum id="0">adjacency model checks</definiendum>
				<definiens id="0">a compound ( i.e. , how strongly w2 modifies w3 as opposed to w1w2 being a compound ) to decide whether or not to predict a right bracketing</definiens>
			</definition>
</paper>

		<paper id="0828">
</paper>

		<paper id="0203">
			<definition id="0">
				<sentence>The interface of the system consists of three sequenced web pages , namely 1 ) the parameter selection page , 2 ) the quiz session page and 3 ) the result page .</sentence>
				<definiendum id="0">interface of the system</definiendum>
				<definiens id="0">consists of three sequenced web pages , namely 1 ) the parameter selection page , 2 ) the quiz session page and 3 ) the result page</definiens>
			</definition>
</paper>

		<paper id="0701">
			<definition id="0">
				<sentence>Memory-based learning , also known as instancebased , example-based , or lazy learning ( Aha et al. , 1991 ; Daelemans et al. , 1999 ) , extensions of the knearest neighbor classifier ( Cover and Hart , 1967 ) , is a supervised inductive learning algorithm for learning classification tasks .</sentence>
				<definiendum id="0">Memory-based learning</definiendum>
				<definiens id="0">instancebased , example-based , or lazy learning ( Aha et al. , 1991 ; Daelemans et al. , 1999 ) , extensions of the knearest neighbor classifier ( Cover and Hart , 1967 ) , is a supervised inductive learning algorithm for learning classification tasks</definiens>
			</definition>
			<definition id="1">
				<sentence>Memory-based learning treats a set of labeled ( pre-classified ) training instances as points in a multi-dimensional feature space , and stores them as such in an instance base in memory .</sentence>
				<definiendum id="0">Memory-based learning</definiendum>
				<definiens id="0">treats a set of labeled ( pre-classified ) training instances as points in a multi-dimensional feature space , and stores them as such in an instance base in memory</definiens>
			</definition>
			<definition id="2">
				<sentence>The input token ( INPUT STRING ) is transliterated ( LOOK-UP WORD ) according to Buckwalter’s transliteration system .</sentence>
				<definiendum id="0">INPUT STRING</definiendum>
			</definition>
			<definition id="3">
				<sentence>We investigated the application of memory-based learning ( k-nearest neighbor classification ) to morphological analysis and PoS tagging of unvoweled written Arabic , using the ATB1 corpus as training and testing material .</sentence>
				<definiendum id="0">memory-based learning</definiendum>
				<definiens id="0">k-nearest neighbor classification ) to morphological analysis and PoS tagging of unvoweled written Arabic , using the ATB1 corpus as training and testing material</definiens>
			</definition>
</paper>

		<paper id="1307">
			<definition id="0">
				<sentence>To evaluate a data set , we calculate a log likelihood ratio ( LLR ) as : C4C4CA BP D0D2 C8B4BWCYC1B5 C8B4BWCYBMC1B5 BP D0D2 C8B4C1CYBWB5C8B4BMC1B5 C8B4BMC1CYBWB5C8B4C1B5 ( 1 ) where C8B4BWCYC1B5 and C8B4BWCYBMC1B5 are the probability of observing the data BW conditioned on the genes sharing benchmark associations ( C1 ) and not sharing benchmark associations ( BMC1 ) .</sentence>
				<definiendum id="0">LLR</definiendum>
				<definiens id="0">C4C4CA BP D0D2 C8B4BWCYC1B5 C8B4BWCYBMC1B5 BP D0D2 C8B4C1CYBWB5C8B4BMC1B5 C8B4BMC1CYBWB5C8B4C1B5 ( 1 ) where C8B4BWCYC1B5 and C8B4BWCYBMC1B5 are the probability of observing the data BW conditioned on the genes sharing benchmark associations ( C1 ) and not sharing benchmark associations ( BMC1 )</definiens>
			</definition>
			<definition id="1">
				<sentence>Conditional Random Fields ( CRF ) ( Lafferty et al. , 2001 ) are new types of probabilistic models that preserve all the advantages of Maximum Entropy models and at the same time avoid the label bias problem by allowing a sequence of tagging decisions to compete against each other in a global probabilistic model .</sentence>
				<definiendum id="0">Conditional Random Fields ( CRF )</definiendum>
				<definiens id="0">Lafferty et al. , 2001 ) are new types of probabilistic models that preserve all the advantages of Maximum Entropy models and at the same time avoid the label bias problem by allowing a sequence of tagging decisions to compete against each other in a global probabilistic model</definiens>
			</definition>
			<definition id="2">
				<sentence>First , we counted the number of abstracts citing a pair of proteins , and then calculated the probability of cocitation under a random model based on the hypergeometric distribution ( Lee et al. , 2004 ; Jenssen et al. , 2001 ) as : C8B4CZCYC6BND1BND2B5 BP AI D2 CZ AJAI C6 A0D2 D1A0CZ AJ AI C6 D1 AJ ( 2 ) where C6 equals the total number of abstracts , D2 of which cite the first protein , D1 cite the second protein , and CZ cite both .</sentence>
				<definiendum id="0">D2</definiendum>
				<definiendum id="1">CZ</definiendum>
				<definiens id="0">the number of abstracts citing a pair of proteins , and then calculated the probability of cocitation under a random model based on the hypergeometric distribution ( Lee et al. , 2004 ; Jenssen et al. , 2001 ) as : C8B4CZCYC6BND1BND2B5 BP AI D2 CZ AJAI C6 A0D2 D1A0CZ AJ AI C6 D1 AJ ( 2 ) where C6 equals the total number of abstracts</definiens>
			</definition>
			<definition id="3">
				<sentence>Each of their rules ( or frames ) is a sequence of words ( or POS tags ) and two protein-name tokens .</sentence>
				<definiendum id="0">rules</definiendum>
				<definiens id="0">a sequence of words ( or POS tags ) and two protein-name tokens</definiens>
			</definition>
</paper>

		<paper id="1516">
			<definition id="0">
				<sentence>However , it was discovered recently that bi-lexical statistics ( parameters that involve two words ) actually played much smaller role than previously believed .</sentence>
				<definiendum id="0">bi-lexical statistics</definiendum>
				<definiens id="0">parameters that involve two words</definiens>
			</definition>
			<definition id="1">
				<sentence>The dependency structure T of S is a directed tree connecting the words in S. Each link in the tree represents a dependency relationship between two words , known as the head and the modifier .</sentence>
				<definiendum id="0">dependency structure T of S</definiendum>
				<definiens id="0">a directed tree connecting the words in S. Each link in the tree represents a dependency relationship between two words</definiens>
			</definition>
			<definition id="2">
				<sentence>We denote a dependency link l by a triple ( u , v , d ) , where u and v are the indices ( u &lt; v ) of the words connected by l , and d specifies the direction of the link l. The value of d is either L or R. If d = L , v is the index of the head word ; otherwise , u is the index of the head word .</sentence>
				<definiendum id="0">u</definiendum>
				<definiens id="0">either L or R. If d = L , v is the index of the head word ; otherwise ,</definiens>
			</definition>
			<definition id="3">
				<sentence>Our model requires three types of parameters : • ( ) d w d w CwEP , | , where w is a word , d is a direction ( left or right ) .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">a direction ( left or right )</definiens>
			</definition>
			<definition id="4">
				<sentence>Many of their model parameters consist of the probability of a word in a given context .</sentence>
				<definiendum id="0">model parameters</definiendum>
				<definiens id="0">consist of the probability of a word in a given context</definiens>
			</definition>
			<definition id="5">
				<sentence>The value of a feature w ' is defined as the point-wise mutual information between the w ' and w : ( ) ( ) ( ) ( )         −= ' ' , log ' , wPwP wwP wwPMI where P ( w , w’ ) is the probability of w and w’ cooccur in a context window .</sentence>
				<definiendum id="0">w’ )</definiendum>
				<definiens id="0">the point-wise mutual information between the w ' and w : ( ) ( ) ( ) ( )         −= ' ' , log ' , wPwP wwP wwPMI where P ( w ,</definiens>
				<definiens id="1">the probability of w and w’ cooccur in a context window</definiens>
			</definition>
			<definition id="6">
				<sentence>( ) ( ) ( ) ( ) ( ) ∑ ∈ = 11 ' 12 1 11 12 '| ' , | wSw MLESIM wwP wnorm wwsim wwP where ( ) 11 ' , wwsim denotes the similarity ( or an increasing function of the similarity ) between w 1 and w’ 1 , S ( w 1 ) denote the set of words that are most similar to w 1 and norm ( w 1 ) is the normalization factor ( ) ( ) ( ) ∑ ∈ = 11 ' 111 ' , wSw wwsimwnorm .</sentence>
				<definiendum id="0">norm ( w 1 )</definiendum>
				<definiens id="0">the similarity ( or an increasing function of the similarity</definiens>
				<definiens id="1">the set of words that are most similar to w 1 and</definiens>
				<definiens id="2">the normalization factor ( ) ( ) ( ) ∑ ∈ = 11 ' 111 '</definiens>
			</definition>
			<definition id="7">
				<sentence>We make a similar assumption : the probability P ( E|C ) of event E given the context C is computed as the weight average of P ( E|C’ ) where C’ is a similar context of C and is attested in the training corpus : ( ) ( ) ( ) ( ) ( ) ∑ ∩∈ = OCSC MLESIM CEP Cnorm CCsim CEP ' '| ' , | where S ( C ) is the set of top-K most similar contexts of C ( in the experiments reported in this paper , K = 50 ) ; O is the set of contexts observed in the training corpus , sim ( C , C’ ) is the similarity between two contexts and norm ( C ) is the normalization factor .</sentence>
				<definiendum id="0">C’</definiendum>
				<definiendum id="1">O</definiendum>
				<definiendum id="2">C’ )</definiendum>
				<definiens id="0">the probability P ( E|C ) of event E given the context</definiens>
				<definiens id="1">a similar context of C and is attested in the training corpus : ( ) ( ) ( ) ( ) ( ) ∑ ∩∈ = OCSC MLESIM CEP Cnorm CCsim CEP ' '| ' , | where S ( C ) is the set of top-K most similar contexts of C ( in the experiments reported in this paper</definiens>
				<definiens id="2">the set of contexts observed in the training corpus , sim ( C ,</definiens>
				<definiens id="3">the normalization factor</definiens>
			</definition>
			<definition id="8">
				<sentence>Their similar contexts are defined as : [ ] ( ) [ ] ( ) { } [ ] ( ) [ ] { } ) ( ' ) , ( ' , ' , ' , , ' , ' , ' vSvuSuCvuCvuS wSwCwCwS d w d w d w d w ∈∈= ∈= where S ( w ) is the set of top-K similar words of w ( K = 50 ) .</sentence>
				<definiendum id="0">S ( w )</definiendum>
			</definition>
			<definition id="9">
				<sentence>We therefore compute P ( E | C ) = α P MLE ( E | C ) + ( 1 – α ) P SIM ( E | C ) where the smoothing factor 5|| 1|| + + = C C α and |C| is the frequency count of the context C in the training data .</sentence>
				<definiendum id="0">|C|</definiendum>
				<definiens id="0">compute P ( E | C ) = α P MLE ( E | C ) + ( 1 – α ) P SIM ( E | C ) where the smoothing factor 5|| 1|| + + = C C α and</definiens>
				<definiens id="1">the frequency count of the context C in the training data</definiens>
			</definition>
			<definition id="10">
				<sentence>We measure the quality of the parser by the undirected accuracy , which is defined as the number of correct undirected dependency links divided by the total number of dependency links in the corpus ( the treebank parse and the parser output always have the same number of links ) .</sentence>
				<definiendum id="0">undirected accuracy</definiendum>
			</definition>
			<definition id="11">
				<sentence>The accuracy of the unlexicalized models ( see Model ( d ) and Model ( e ) in Table 2 ) is 71.1 % which is considerably lower than the strictly lexicalized conditional model , but higher than the strictly lexicalized joint model .</sentence>
				<definiendum id="0">accuracy of the unlexicalized models</definiendum>
				<definiens id="0">71.1 % which is considerably lower than the strictly lexicalized conditional model , but higher than the strictly lexicalized joint model</definiens>
			</definition>
</paper>

		<paper id="0704">
			<definition id="0">
				<sentence>Further MORPHO3 uses a word trigram model to improve in-context morphology , but uses an extensive set of manually crafted rules .</sentence>
				<definiendum id="0">MORPHO3</definiendum>
				<definiens id="0">uses a word trigram model to improve in-context morphology , but uses an extensive set of manually crafted rules</definiens>
			</definition>
			<definition id="1">
				<sentence>Fifty topics were developed cooperatively by the LDC and the National Institute of Standards and Technology ( NIST ) , and relevance judgments were developed at the LDC by manually judging a pool of documents obtained from combining the top 100 documents from all the runs submitted by the participating teams to TREC’s cross-language track in 2002 .</sentence>
				<definiendum id="0">Fifty topics</definiendum>
				<definiendum id="1">LDC</definiendum>
				<definiens id="0">were developed cooperatively by the LDC and the National Institute of Standards and Technology ( NIST ) , and relevance judgments were developed at the</definiens>
			</definition>
</paper>

		<paper id="0609">
			<definition id="0">
				<sentence>Typically , natural language elements ( words , phrases , sentences , etc. ) are partitioned into non-overlapping classes , based on some distance ( or similarity ) metric defined between them , in order to provide some level of syntactic or semantic abstraction .</sentence>
				<definiendum id="0">natural language elements</definiendum>
				<definiens id="0">some level of syntactic or semantic abstraction</definiens>
			</definition>
			<definition id="1">
				<sentence>Clustering is an optimization procedure that takes as input ( 1 ) a collection of domain elements along with ( 2 ) a distance metric between them and ( 3 ) an algorithm selected to partition the data elements , with the goal of optimizing some form of clustering quality with respect to the given distance metric .</sentence>
				<definiendum id="0">Clustering</definiendum>
				<definiens id="0">an optimization procedure that takes as input ( 1 ) a collection of domain elements along with ( 2 ) a distance metric between them and ( 3 ) an algorithm selected to partition the data elements</definiens>
			</definition>
			<definition id="2">
				<sentence>Clustering is the task of partitioning a set of elements S ⊆ X into a disjoint decomposition 1 p ( S ) = { S1 , S2 , ··· , SK } of S. We associate with it a partition function p = pS : X → C = { 1,2 , ... K } that maps each x ∈ S to a class index pS ( x ) = k iff x ∈ Sk .</sentence>
				<definiendum id="0">Clustering</definiendum>
			</definition>
			<definition id="3">
				<sentence>For example , given any two element x1 = &lt; x ( 1 ) 1 , ··· , x ( m ) 1 &gt; and x2 = &lt; x ( 1 ) 2 , ··· , x ( m ) 2 &gt; in an m-dimensional space , a linearly weighted Euclidean distance with parameters θ = { wl } m1 is defined as : dθ ( x1 , x2 ) ≡ radicaltpradicalvertex radicalvertexradicalbt msummationdisplay l=1 wl ·|x ( l ) 1 −x ( l ) 2 |2 ( 1 ) When supervision ( e.g. class index of elements ) is unavailable , the quality of a partition function h operating on S ⊆ X , is measured with respect to the distance metric defined over X. Suppose h partitions S into disjoint sets h ( S ) = { Sprimek } K1 , one quality function used in the KMeans algorithm is defined as : qS ( h ) ≡ Ksummationdisplay k=1 summationdisplay x∈Sprimek d ( x , µprimek ) 2 , ( 2 ) where µprimek is the mean of elements in set Sprimek .</sentence>
				<definiendum id="0">µprimek</definiendum>
				<definiens id="0">the distance metric defined over X. Suppose h partitions S into disjoint sets h ( S ) = { Sprimek } K1 , one quality function used in the KMeans algorithm is defined as : qS ( h ) ≡ Ksummationdisplay k=1 summationdisplay x∈Sprimek d ( x , µprimek</definiens>
			</definition>
			<definition id="4">
				<sentence>A good metric is one in which close proximity correlates well with the likelihood of being in the same class .</sentence>
				<definiendum id="0">good metric</definiendum>
				<definiens id="0">one in which close proximity correlates well with the likelihood of being in the same class</definiens>
			</definition>
			<definition id="5">
				<sentence>A labeled data set S A SupervisedLearner Training Stage : Goal : h*=argmin er S ( h , p ) A distancemetric d a clustering algorithm A+ A unlabeled data set S’ A partition h ( S’ ) Aplication Stage : h ( S’ ) A partition function h ( S ) = Ad ( S ) Figure 2 : Supervised Discriminative Clustering Fig .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">a clustering algorithm A+ A unlabeled data set S’ A partition h ( S’ ) Aplication Stage : h ( S’ ) A partition function h ( S ) = Ad ( S</definiens>
			</definition>
			<definition id="6">
				<sentence>Given a labeled data set S and p ( S ) , one error function , namely weighted clustering error , is defined as a sum of the pairwise errors over any two elements in S , weighted by the distance between them : errS ( h , p ) ≡ 1|S|2 summationdisplay xi , xj∈S [ d ( xi , xj ) ·Aij+ ( D−d ( xi , xj ) ) ·Bij ] ( 3 ) where D = maxxi , xj∈S d ( xi , xj ) is the maximum distance between any two elements in S and I is an indicator function .</sentence>
				<definiendum id="0">xj ) ·Aij+ ( D−d</definiendum>
				<definiendum id="1">xj∈S d</definiendum>
				<definiendum id="2">xj )</definiendum>
				<definiens id="0">Given a labeled data set S and p ( S ) , one error function</definiens>
				<definiens id="1">a sum of the pairwise errors over any two elements in S , weighted by the distance between them : errS ( h , p ) ≡ 1|S|2 summationdisplay xi</definiens>
				<definiens id="2">( xi , xj ) ) ·Bij ] ( 3 ) where D = maxxi ,</definiens>
			</definition>
			<definition id="7">
				<sentence>Definition 3.3 Supervised Metric Learning : Given a labeled data set S and p ( S ) , and a family of partition functions H = { h } that are parameterized by a chosen clustering algorithm A and a family of distance metrics dθ ( θ ∈ Ω ) , the problem is to seek an optimal metric dθ∗ with respect to A , s.t. for h ( S ) = A dθ ( S ) θ∗ = argminθ errS ( h , p ) .</sentence>
				<definiendum id="0">Supervised Metric Learning</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">Given a labeled data set S and p ( S ) , and a family of partition functions H = { h } that are parameterized by a chosen clustering algorithm A and a family of distance metrics dθ ( θ ∈ Ω</definiens>
				<definiens id="1">h ( S ) = A dθ ( S ) θ∗ = argminθ errS</definiens>
			</definition>
			<definition id="8">
				<sentence>In this case , when pairwise features are extracted for any elements x1 , x2 ∈ X , ( x1 , x2 ) = &lt; φ1 , φ2 , ··· , φm &gt; , the linearly weighted Manhattan distance , parameterized by ( θ = { wl } m1 ) is defined as : d ( x1 , x2 ) ≡ msummationdisplay l=1 wl ·φl ( x1 , x2 ) ( 5 ) where wl is the weight over feature φl ( x1 , x2 ) .</sentence>
				<definiendum id="0">wl</definiendum>
			</definition>
			<definition id="9">
				<sentence>SDC works well for all three entity types in spite of their different characteristics .</sentence>
				<definiendum id="0">SDC</definiendum>
				<definiens id="0">works well for all three entity types in spite of their different characteristics</definiens>
			</definition>
			<definition id="10">
				<sentence>X-axis denotes different percentages of 300 names used in training .</sentence>
				<definiendum id="0">X-axis</definiendum>
				<definiens id="0">different percentages of 300 names used in training</definiens>
			</definition>
</paper>

		<paper id="0811">
			<definition id="0">
				<sentence>Inuktitut-English Alignment Problem Guided by the discussion of Inuktitut in Mallon ( 1999 ) , we examined the Nunavut Hansards training and handlabeled trial data sets in order to identify special challenges and exploitable characteristics of the InuktitutEnglish word alignment problem .</sentence>
				<definiendum id="0">Inuktitut-English Alignment Problem Guided</definiendum>
				<definiens id="0">Hansards training and handlabeled trial data sets in order to identify special challenges and exploitable characteristics of the InuktitutEnglish word alignment problem</definiens>
			</definition>
			<definition id="1">
				<sentence>79 % Words Having Specified Alignment Cardinality NULL 1 2 3 4 5 6 7 English 5 94 &lt; 1 &lt; 1 0 0 0 0 Inuktitut 3 43 20 14 10 5 3 2 Table 1 : Alignment cardinalities for English-Inuktitut word alignment , computed over the trial data .</sentence>
				<definiendum id="0">Alignment</definiendum>
				<definiens id="0">cardinalities for English-Inuktitut word alignment , computed over the trial data</definiens>
			</definition>
			<definition id="2">
				<sentence>The WFST aligner is a composition of 4 transducers.2 The structure of the entire WFST composition enforces monotonicity , Inuktitut-to-English 1-N cardinality , and Inuktitut word fertilities ranging between 1 and state toolkit ( Mohri et al. , 1997 ) .</sentence>
				<definiendum id="0">WFST aligner</definiendum>
			</definition>
			<definition id="3">
				<sentence>[ 2 ] is a single-state transducer mapping English word to Inuktitut substrings ( or full words ) with weights derived from the association scores.3 [ 3 ] is a transducer mapping Inuktitut substrings ( and full words ) to their position in the Inuktitut test sentence .</sentence>
				<definiendum id="0">]</definiendum>
				<definiens id="0">a single-state transducer mapping English word to Inuktitut substrings ( or full words ) with weights derived from the association scores.3</definiens>
				<definiens id="1">a transducer mapping Inuktitut substrings ( and full words ) to their position in the Inuktitut test sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>In the nomenclature of our results tables , giza++ syllabized refers to the latter system , giza++ E ( 1 ) -I ( N ) represents GIZA++ run with English as the e language , and giza++ E ( N ) -I ( 1 ) sets English as the f language .</sentence>
				<definiendum id="0">giza++ E</definiendum>
				<definiens id="0">GIZA++ run with English as the e language , and</definiens>
			</definition>
			<definition id="5">
				<sentence>Consistently , WFST 4Exclusion list was compiled as follows : ( a ) capitalized words in 2000 randomly selected English training sentences were examined , Words such as Clerk , Federation , and Fisheries , which are frequently capitalized but should not be transliterated , were put into the exclusion list ; in addition , any word with frequency &gt; 50 in the training corpus was excluded , on the rationale that common-enough words would have well-estimated translation probabilities already .</sentence>
				<definiendum id="0">Fisheries</definiendum>
				<definiens id="0">compiled as follows : ( a ) capitalized words in 2000 randomly selected English training sentences were examined</definiens>
			</definition>
</paper>

		<paper id="0836">
			<definition id="0">
				<sentence>As discussed in ( Och , 2003 ) , the direct translation model represents the probability of target sentence ’English’ e = e1 ... eI being the translation for a source sentence ’French’ f = f1 ... fJ through an exponential , or log-linear model pλ ( e|f ) = exp ( summationtextm k=1 λk ∗ hk ( e , f ) ) summationtext eprime∈E exp ( summationtextm k=1 λk ∗ hk ( eprime , f ) ) ( 1 ) where e is a single candidate translation for f from the set of all English translations E , λ is the parameter vector for the model , and each hk is a feature function of e and f. In practice , we restrict E to the set Gen ( f ) which is a set of highly likely translations discovered by a decoder ( Vogel et al. , 2003 ) .</sentence>
				<definiendum id="0">eprime∈E exp</definiendum>
				<definiendum id="1">e</definiendum>
				<definiendum id="2">λ</definiendum>
				<definiens id="0">the probability of target sentence ’English’ e = e1 ... eI being the translation for a source sentence ’French’ f = f1 ... fJ through an exponential , or log-linear model pλ ( e|f ) = exp ( summationtextm k=1 λk ∗ hk</definiens>
				<definiens id="1">a single candidate translation for f from the set of all English translations E ,</definiens>
				<definiens id="2">the parameter vector for the model</definiens>
			</definition>
			<definition id="1">
				<sentence>In this paper we will compare and evaluate several aspects of these techniques , focusing on Minimum Error Rate ( MER ) training ( Och , 2003 ) and Minimum Bayes Risk ( MBR ) decision rules , within a novel training environment that isolates the impact of each component of these methods .</sentence>
				<definiendum id="0">Minimum Bayes Risk</definiendum>
				<definiens id="0">within a novel training environment that isolates the impact of each component of these methods</definiens>
			</definition>
			<definition id="2">
				<sentence>The Minimum Bayes Risk Decision Rule as proposed by ( Mangu et al. , 2000 ) for the Word Error Rate Metric in speech recognition , and ( Kumar and Byrne , 2004 ) when applied to translation , changes the decision rule in ( 2 ) to select the translation that has the lowest expected loss E [ Loss ( e , r ) ] , which can be estimated by considering a weighted Loss between e and the elements of the n-best list , the approximation to E , as described in ( Mangu et al. , 2000 ) .</sentence>
				<definiendum id="0">Minimum Bayes Risk Decision Rule</definiendum>
				<definiens id="0">Mangu et al. , 2000 ) for the Word Error Rate Metric in speech recognition</definiens>
			</definition>
			<definition id="3">
				<sentence>The score Score ( λi ) of the currently evaluated parameter vector does not only influence the score estimate at the pivot point of the respective region , but the estimates at all pivot points .</sentence>
				<definiendum id="0">score Score</definiendum>
				<definiens id="0">λi ) of the currently evaluated parameter vector does not only influence the score estimate at the pivot point of the respective region , but the estimates at all pivot points</definiens>
			</definition>
			<definition id="4">
				<sentence>Here , mvnpdf ( x , µ , Σ ) denotes the m-dimensional multivariate-normal probability density function with mean µ and covariance matrix Σ , evaluated at point x. We chose the covariance matrix Σ = diag ( d21 , ... , d2m ) , where again dk is the distance between neighboring grid points along dimension k. The term infl ( i ) ( λ ) quantifies the influence of the evaluated point λi on the pivot λ , while corr ( i ) ( λ ) is a correction term for the bias introduced by having sampled λi from p ( i−1 ) .</sentence>
				<definiendum id="0">Σ )</definiendum>
				<definiens id="0">the m-dimensional multivariate-normal probability density function with mean µ and covariance matrix Σ , evaluated at point x. We chose the covariance matrix Σ = diag ( d21 , ...</definiens>
				<definiens id="1">the distance between neighboring grid points along dimension k. The term infl ( i ) ( λ ) quantifies the influence of the evaluated point λi on the pivot λ , while corr ( i ) ( λ ) is a correction term for the bias introduced by having sampled λi from p ( i−1 )</definiens>
			</definition>
			<definition id="5">
				<sentence>The Pharaoh decoder has support for multiple translation and language model scores as well as simple phrase distortion and word length models .</sentence>
				<definiendum id="0">Pharaoh decoder</definiendum>
				<definiens id="0">has support for multiple translation and language model scores as well as simple phrase distortion and word length models</definiens>
			</definition>
			<definition id="6">
				<sentence>Score ( vectore , vectorr ) = BP ( vectore , vectorr ) ∗ exp ( 1N Nsummationdisplay 1 ( logpn ) ) where pn represent the precision of n-grams suggested in vectore and BP is a brevity penalty measuring the relative shortness of vectore over the whole corpus .</sentence>
				<definiendum id="0">Score</definiendum>
				<definiendum id="1">pn</definiendum>
				<definiendum id="2">BP</definiendum>
				<definiens id="0">the precision of n-grams suggested in vectore</definiens>
				<definiens id="1">a brevity penalty measuring the relative shortness of vectore over the whole corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>The bold face scores are the scores for matching training and testing methods .</sentence>
				<definiendum id="0">bold face scores</definiendum>
				<definiens id="0">the scores for matching training and testing methods</definiens>
			</definition>
</paper>

		<paper id="0502">
			<definition id="0">
				<sentence>The simulated population consists of individual simulated people called agents that can use arbitrary mixtures of idealized grammars called fuzzy grammars .</sentence>
				<definiendum id="0">simulated population</definiendum>
			</definition>
			<definition id="1">
				<sentence>A fuzzy grammar consists of a pair of beta distributions with parameters α and β , following the convention from ( Gelman et al. , 2004 ) that the density for Beta ( α , β ) is p ( x ) = Γ ( α + β ) Γ ( α ) Γ ( β ) xα−1 ( 1−x ) β−1,0 &lt; x &lt; 1 .</sentence>
				<definiendum id="0">fuzzy grammar</definiendum>
				<definiens id="0">consists of a pair of beta distributions with parameters α and β , following the convention from ( Gelman et al. , 2004 ) that the density for Beta ( α , β ) is p ( x ) = Γ ( α + β</definiens>
			</definition>
			<definition id="2">
				<sentence>In addition to sampling from the stationary distribution pi of a Markov chain , MCFTP estimates the chain’s mixing time , which is how large t must be for the distribution of Xt to be ε-close to pi ( in total variation distance ) .</sentence>
				<definiendum id="0">MCFTP</definiendum>
				<definiens id="0">estimates the chain’s mixing time</definiens>
			</definition>
</paper>

		<paper id="0710">
			<definition id="0">
				<sentence>Amharic is the language for countrywide communication in Ethiopia and has its own writing system containing extensive systematic redundancy .</sentence>
				<definiendum id="0">Amharic</definiendum>
				<definiens id="0">the language for countrywide communication in Ethiopia and has its own writing system containing extensive systematic redundancy</definiens>
			</definition>
			<definition id="1">
				<sentence>We use the SelfOrganizing Map ( SOM ) model of artificial neural networks for the task of retrieving the documents matching a specific query .</sentence>
				<definiendum id="0">SelfOrganizing Map ( SOM</definiendum>
				<definiens id="0">) model of artificial neural networks for the task of retrieving the documents matching a specific query</definiens>
			</definition>
			<definition id="2">
				<sentence>Artificial Neural Networks ( ANN ) is a computational paradigm inspired by the neurological structure of the human brain , and ANN terminology borrows from neurology : the brain consists of millions of neurons connected to each other through long and thin strands called axons ; the connecting points between neurons are called synapses .</sentence>
				<definiendum id="0">Artificial Neural Networks ( ANN )</definiendum>
				<definiens id="0">a computational paradigm inspired by the neurological structure of the human brain , and ANN terminology borrows from neurology : the brain consists of millions of neurons connected to each other through long and thin strands called axons</definiens>
			</definition>
			<definition id="3">
				<sentence>Self-Organizing Maps ( SOM ) is an unsupervised learning scheme neural network , which was invented by Kohonen ( 1999 ) .</sentence>
				<definiendum id="0">Self-Organizing Maps ( SOM )</definiendum>
				<definiens id="0">an unsupervised learning scheme neural network</definiens>
			</definition>
			<definition id="4">
				<sentence>Self-organizing systems can have many kinds of structures , a common one consists of an input layer and an output layer , with feed-forward connections from input to output layers and full connectivity ( connections between all neurons ) in the output layer .</sentence>
				<definiendum id="0">Self-organizing systems</definiendum>
				<definiens id="0">consists of an input layer and an output layer , with feed-forward connections from input to output layers and full connectivity ( connections between all neurons ) in the output layer</definiens>
			</definition>
			<definition id="5">
				<sentence>The learning process consists of repeatedly modifying the synaptic weights of the connections in the system in response to input ( activation ) patterns and in accordance to prescribed rules , until a final configuration develops .</sentence>
				<definiendum id="0">learning process</definiendum>
			</definition>
			<definition id="6">
				<sentence>Moreover , LSI consumes ample time in calculating similarities of new queries against all documents , but a SOM only needs to calculate similarities versus some representative subset of old input data and can then map new input straight onto the most similar models without having to recompute the whole mapping .</sentence>
				<definiendum id="0">LSI</definiendum>
				<definiens id="0">consumes ample time in calculating similarities of new queries against all documents</definiens>
			</definition>
			<definition id="7">
				<sentence>However , Amharic is the language for countrywide communication and was also for a long period the principal literal language and medium of instruction in primary and secondary schools in the country , while higher education is carried out in English .</sentence>
				<definiendum id="0">Amharic</definiendum>
				<definiens id="0">the language for countrywide communication and was also for a long period the principal literal language and medium of instruction in primary and secondary schools in the country</definiens>
			</definition>
			<definition id="8">
				<sentence>SVD makes it possible to map individual terms to the concept space .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">makes it possible to map individual terms to the concept space</definiens>
			</definition>
</paper>

		<paper id="0822">
			<definition id="0">
				<sentence>Decoding is the central phase in SMT , involving a search for the hypotheses t that have highest probabilities of being translations of the current source sentence s according to a model for P ( t|s ) .</sentence>
				<definiendum id="0">Decoding</definiendum>
				<definiens id="0">the central phase in SMT , involving a search for the hypotheses t that have highest probabilities of being translations of the current source sentence s according to a model for P ( t|s )</definiens>
			</definition>
			<definition id="1">
				<sentence>BLEU : a Method for Automatic Evaluation of Machine Translation .</sentence>
				<definiendum id="0">BLEU</definiendum>
			</definition>
			<definition id="2">
				<sentence>Europarl : a multilingual corpus for evaluation of machine translation .</sentence>
				<definiendum id="0">Europarl</definiendum>
			</definition>
			<definition id="3">
				<sentence>Pharaoh : a Beam Search Decoder for Phrase-based Statistical Machine Translation models .</sentence>
				<definiendum id="0">Pharaoh</definiendum>
			</definition>
</paper>

		<paper id="0623">
			<definition id="0">
				<sentence>173 • Phrase-Type Syntactic category of node • Predicate Lemma Stemmed target verb • Path Sequence of phrase types between the predicate and node , with ↑ , ↓ to indicate direction • Position Before or after predicate • Voice Voice of predicate • Head-Word of Phrase • Head-POS POS tag of head word • Sub-Cat CFG expansion of predicate’s parent • First/Last Word • Left/Right Sister Phrase-Type • Left/Right Sister Head-Word/Head-POS • Parent Phrase-Type • Parent POS/Head-Word • Ordinal Tree Distance Phrase-type concatenated with the length of the Path feature • Node-LCA Partial Path Path from the node to the lowest common ancestor of the predicate and the node • PP Parent Head-Word If the parent of the node is a PP , the parent’s head-word • PP NP Head-Word/Head-POS For a PP , retrieve the headword /head-POS of its rightmost NP • Temporal Keywords* Is the head of the node a temporal word e.g ‘February’ or ‘afternoon’ • Missing subject* Is the predicate missing a subject in the“standard” location • Projected path* Path from the maximal extended projection of the predicate to the node • Predicate Lemma &amp; Path • Predicate Lemma &amp; Head-Word • Predicate Lemma &amp; Phrase-Type • Voice &amp; Position • Predicate Lemma &amp; PP Parent Head-Word • Path &amp; Missing subject* • Projected path &amp; Missing subject* We found that a large source of errors for A0and A1 stemmed from cases such as those illustrated in Figure 1 , where arguments were dislocated by raising or controlling verbs .</sentence>
				<definiendum id="0">Missing subject*</definiendum>
				<definiens id="0">Is the predicate missing a subject in the“standard” location • Projected path* Path from the maximal extended projection of the predicate to the node</definiens>
			</definition>
			<definition id="1">
				<sentence>We introduce a new path feature , Projected Path , which takes the path from the maximal extended projection to an argument node .</sentence>
				<definiendum id="0">Projected Path</definiendum>
				<definiens id="0">takes the path from the maximal extended projection to an argument node</definiens>
			</definition>
			<definition id="2">
				<sentence>Our final score is given by a mixture of the local and joint model’s logprobabilities : scoreSRL ( L|t ) = α scorelscript ( L|t ) + scoreJ ( L|t ) , where scorelscript ( L|t ) is the local score of L , scoreJ ( L|t ) is the corresponding joint score , and α is a tunable parameter .</sentence>
				<definiendum id="0">scorelscript ( L|t )</definiendum>
				<definiendum id="1">L|t )</definiendum>
				<definiendum id="2">α</definiendum>
				<definiens id="0">a tunable parameter</definiens>
			</definition>
			<definition id="3">
				<sentence>Recent releases of the Charniak parser ( Charniak , 2000 ) have included an option to provide the top k parses of a given sentence according to the probability model of the parser .</sentence>
				<definiendum id="0">Charniak parser</definiendum>
				<definiens id="0">included an option to provide the top k parses of a given sentence according to the probability model of the parser</definiens>
			</definition>
</paper>

		<paper id="1603">
			<definition id="0">
				<sentence>The generic task is to map a content representation , which must be encoded as a feature structure1 , onto a chain of terminal elements as defined by the rule set .</sentence>
				<definiendum id="0">generic task</definiendum>
				<definiens id="0">to map a content representation , which must be encoded as a feature structure1 , onto a chain of terminal elements as defined by the rule set</definiens>
			</definition>
			<definition id="1">
				<sentence>[ ( SENTENCE DECL ) ( VC [ ( SBP S2 ) ; ; name of sentence plan ( G AKTIV ) ; ; active voice ( STEM `` verursach '' ) ] ) ( DEEP-OBJ [ ( DET DEMONST ) ( STEM `` wirkung '' ) ] ) ( DEEP-SUBJ [ ( TOP Y ) ; ; this constituent to the fore-field ( DET INDEF ) ; ; indefinite article ( NR V2 ) ; ; name of nominal plan ( STEM `` antagonismus '' ) ( PP-ATR [ ( MODALITY [ ( PP-OBJ [ ( TERM [ ( DET DEF ) ; ; definite article ( STEM `` bindungsstelle '' ) ( ADJ [ ( STEM `` muskarinisch '' ) ( DEG POS ) ] ) ( TERM [ ( DET DEMONST1 ) ; ; demonstrative ( STEM `` substanz '' ) ] ) ] ) ( STEM `` Niveau '' ) ( DET DEF ) ( PREP AUF-DAT ) ] ) ] ) ; ; P governs dative NP here ( STEM `` acetylcholin '' ) ( DET WITHOUT ) ; ; no article ( PREP ZU ) ] ) ; ; this P always governs dative NP ( ADJ [ ( STEM `` kompetitiv '' ) ( DEG POS ) ] ) ] ) ] Figure 3 : A TG/2 MUSI input for “Ein kompetitiver Antagonismus zu Acetylcholin auf dem Niveau der muskarinischen Bindungsstellen dieser Substanzen verursacht diese Wirkungen.”</sentence>
				<definiendum id="0">SENTENCE DECL ) ( VC</definiendum>
				<definiendum id="1">DET DEMONST ) ( STEM</definiendum>
				<definiendum id="2">indefinite article</definiendum>
				<definiendum id="3">STEM ``</definiendum>
				<definiendum id="4">; demonstrative ( STEM</definiendum>
				<definiendum id="5">P</definiendum>
				<definiens id="0">SBP S2 ) ; ; name of sentence plan ( G AKTIV ) ; ; active voice ( STEM `` verursach ''</definiens>
				<definiens id="1">antagonismus '' ) ( PP-ATR [ ( MODALITY [ ( PP-OBJ [ ( TERM [ ( DET DEF ) ; ; definite article ( STEM `` bindungsstelle '' ) ( ADJ [ ( STEM `` muskarinisch '' ) ( DEG POS ) ] ) ( TERM [ ( DET DEMONST1 ) ;</definiens>
				<definiens id="2">governs dative NP here ( STEM `` acetylcholin '' ) ( DET WITHOUT ) ; ; no article ( PREP ZU ) ] ) ; ; this P always governs dative NP ( ADJ [ ( STEM `` kompetitiv '' )</definiens>
			</definition>
			<definition id="2">
				<sentence>The grammar writer defines , in cooperation with the application developer , parameters such as expertise , background , and device with appropriate values .</sentence>
				<definiendum id="0">grammar writer defines</definiendum>
				<definiens id="0">in cooperation with the application developer , parameters such as expertise , background , and device with appropriate values</definiens>
			</definition>
			<definition id="3">
				<sentence>Meta-rules serve as an abbreviation technique and do not affect the expressive power of the system .</sentence>
				<definiendum id="0">Meta-rules</definiendum>
				<definiens id="0">serve as an abbreviation technique and do not affect the expressive power of the system</definiens>
			</definition>
</paper>

		<paper id="1623">
			<definition id="0">
				<sentence>Reversibility is a key to e–cient and maintainable NLG systems .</sentence>
				<definiendum id="0">Reversibility</definiendum>
			</definition>
			<definition id="1">
				<sentence>Reversibility is a key factor in building e–cient and maintainable NLG and natural language dialog systems ( NLDSs ) .</sentence>
				<definiendum id="0">Reversibility</definiendum>
				<definiens id="0">a key factor in building e–cient and maintainable NLG and natural language dialog systems</definiens>
			</definition>
			<definition id="2">
				<sentence>( Computing a relation in both directions according to Neumann and van Noord ) A program P computes a relation r in both directions , ifi for a given input hdir ; ei it recursively enumerates the set fx j ( he ; xi 2 r ^ dir = 0 ) _ ( hx ; ei 2 r ^ dir = 1 ) g. In this deflnition , the parameter dir denotes the direction in which the input is computed , and e represents the content of the input for which the appropriate output has to be obtained .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">the content of the input for which the appropriate output has to be obtained</definiens>
			</definition>
			<definition id="3">
				<sentence>s.5 An NLDS is a program system S with rp !</sentence>
				<definiendum id="0">NLDS</definiendum>
			</definition>
</paper>

		<paper id="0309">
			<definition id="0">
				<sentence>The second phase of the project , PropBank II adds additional levels of semantic annotation which include eventuality variables , co-reference , coarse-grained sense tags , and discourse connectives .</sentence>
				<definiendum id="0">PropBank II</definiendum>
			</definition>
			<definition id="1">
				<sentence>PropBank ( Palmer et al. , 2005 ) is an annotation of the Wall Street Journal portion of the Penn Treebank II ( Marcus et al. , 1994 ) with ‘predicate-argument’ structures , using sense tags for highly polysemous words and semantic role labels for each argument .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">an annotation of the Wall Street Journal portion of the Penn Treebank II</definiens>
			</definition>
			<definition id="2">
				<sentence>Verbs can take any of a set of general , adjunct-like arguments ( ARGMs ) , such as LOC ( location ) , TMP ( time ) , DIS ( discourse connectives ) , PRP ( purpose ) or DIR ( direction ) .</sentence>
				<definiendum id="0">PRP</definiendum>
				<definiens id="0">take any of a set of general , adjunct-like arguments ( ARGMs ) , such as LOC ( location ) , TMP ( time ) , DIS ( discourse connectives ) ,</definiens>
			</definition>
			<definition id="3">
				<sentence>As discussed above , PropBank II adds richer semantic annotation to the PropBank I predicate argument structures , notably eventuality variables , co-references , coarse-grained sense tags ( BabkoMalaya et al. , 2004 ; Babko-Malaya and Palmer , 2005 ) , and discourse connectives ( Xue , To appear ) To create our parallel PropBank II , we began with the first 100K words of the Chinese Treebank which had already been propbanked , and which we had had translated into English .</sentence>
				<definiendum id="0">PropBank II</definiendum>
				<definiendum id="1">discourse connectives</definiendum>
				<definiens id="0">adds richer semantic annotation to the PropBank I predicate argument structures</definiens>
			</definition>
			<definition id="4">
				<sentence>And , finally , part of the PropBank II annotation involves tagging of event coreference for pronouns as well as empty categories .</sentence>
				<definiendum id="0">PropBank II annotation</definiendum>
				<definiens id="0">involves tagging of event coreference for pronouns as well as empty categories</definiens>
			</definition>
			<definition id="5">
				<sentence>The annotation of Chinese discourse connectives follows in large part the theoretic assumptions and annotation practices of the English Penn Discourse Project ( PDTB ) ( Miltsakaki et al. , 2004 ) .</sentence>
				<definiendum id="0">Chinese discourse connectives</definiendum>
			</definition>
			<definition id="6">
				<sentence>Explicit discourse connectives include subordinate ( 8 ) and coordinate conjunctions ( 9 ) as well as discourse adverbials ( 10 ) .</sentence>
				<definiendum id="0">Explicit discourse connectives</definiendum>
			</definition>
</paper>

		<paper id="1506">
			<definition id="0">
				<sentence>Another example is minimum-Bayes-risk decoding ( Kumar and Byrne , 2004 ; Goodman , 1998 ) , where , assuming fprime de nes a probability distribution over all candidates , one seeks the candidate with the highest expected score according to an arbitrary metric ( e.g. , PARSEVAL or BLEU ) ; since in general the metric will not be compatible with the parsing algorithm , the k-best lists can be used to approximate the full distribution f prime .</sentence>
				<definiendum id="0">minimum-Bayes-risk decoding</definiendum>
				<definiens id="0">seeks the candidate with the highest expected score according to an arbitrary metric ( e.g. , PARSEVAL or BLEU</definiens>
			</definition>
			<definition id="1">
				<sentence>For algorithms whose packed representations are graphs , such as Hidden Markov Models and other nitestate methods , Ratnaparkhi’s MXPARSE parser ( Ratnaparkhi , 1997 ) , and many stack-based machine translation decoders ( Brown et al. , 1995 ; Och and Ney , 2004 ) , the k-best paths problem is well-studied in both pure algorithmic context ( see ( Eppstein , 2001 ) and ( Brander and Sinclair , 1995 ) for surveys ) and NLP/Speech community ( Mohri , 2002 ; Mohri and Riley , 2002 ) .</sentence>
				<definiendum id="0">Ratnaparkhi’s MXPARSE parser</definiendum>
				<definiendum id="1">NLP/Speech community</definiendum>
				<definiens id="0">Hidden Markov Models and other nitestate methods</definiens>
			</definition>
			<definition id="2">
				<sentence>An ordered hypergraph ( henceforth hypergraph ) H is a tuple hV , E , t , Ri , where V is a nite set of vertices , E is a nite set of hyperarcs , and R is the set of weights .</sentence>
				<definiendum id="0">henceforth hypergraph ) H</definiendum>
				<definiendum id="1">E</definiendum>
				<definiendum id="2">R</definiendum>
				<definiens id="0">a tuple hV , E , t , Ri , where V is a nite set of vertices</definiens>
				<definiens id="1">a nite set of hyperarcs , and</definiens>
				<definiens id="2">the set of weights</definiens>
			</definition>
			<definition id="3">
				<sentence>Each hyperarc e 2 E is a triple 54 e = hT ( e ) , h ( e ) , f ( e ) i , where h ( e ) 2 V is its head and T ( e ) 2 V∗ is a vector of tail nodes .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">a triple 54 e = hT ( e ) , h ( e ) , f ( e ) i , where h ( e ) 2 V is its head</definiens>
			</definition>
			<definition id="4">
				<sentence>f ( e ) is a weight function from R|T ( e ) | to R. t 2 V is a distinguished vertex called target vertex .</sentence>
				<definiendum id="0">f ( e )</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">a distinguished vertex called target vertex</definiens>
			</definition>
			<definition id="5">
				<sentence>A derivation D of a vertex v in a hypergraph H , its size jDj and its weight w ( D ) are recursively de ned as follows : • If e 2 BS ( v ) with jej = 0 , then D = he , epsilon1i is a derivation of v , its size jDj = 1 , and its weight w ( D ) = f ( e ) ( ) .</sentence>
				<definiendum id="0">epsilon1i</definiendum>
				<definiens id="0">a derivation of v</definiens>
			</definition>
			<definition id="6">
				<sentence>• If e 2 BS ( v ) where jej &gt; 0 and Di is a derivation of Ti ( e ) for 1 • i • jej , then D = he , D1¢¢¢D|e|i is a derivation of v , its size jDj = 1 +summationtext|e|i=1jDij and its weight w ( D ) = f ( e ) ( w ( D1 ) , ... , w ( D|e| ) ) .</sentence>
				<definiendum id="0">Di</definiendum>
				<definiendum id="1">D1¢¢¢D|e|i</definiendum>
			</definition>
			<definition id="7">
				<sentence>Computationally , then , the k-best problem can be stated as follows : given a hypergraph H with arity a , compute D1 ( t ) , ... , Dk ( t ) .1 As shown by Klein and Manning ( 2001 ) , hypergraphs can be used to represent the search space of most parsers ( just as graphs , also known as trellises or lattices , can represent the search space of nite-state automata or HMMs ) .</sentence>
				<definiendum id="0">k-best problem can be</definiendum>
				<definiendum id="1">HMMs</definiendum>
				<definiens id="0">stated as follows : given a hypergraph H with arity a , compute D1 ( t ) , ... , Dk ( t ) .1 As shown by Klein and Manning ( 2001 ) , hypergraphs can be used to represent the search space of most parsers ( just as graphs , also known as trellises or lattices , can represent the search space of nite-state automata or</definiens>
			</definition>
			<definition id="8">
				<sentence>YZ in P and three free indices i &lt; j &lt; k , we have a hyperarc h ( ( Y , i , k ) , ( Z , k , j ) ) , ( X , i , k ) , fi corresponding to the instantiation of the inference rule C in the deductive system of ( Shieber et al. , 1995 ) , and the weight function f is de ned as f ( a , b ) = ab¢Pr ( X !</sentence>
				<definiendum id="0">rule C</definiendum>
				<definiens id="0">fi corresponding to the instantiation of the inference</definiens>
			</definition>
			<definition id="9">
				<sentence>The graph projection of a hypergraph H = hV , E , t , Ri is a directed graph G = hV , Eprimei where Eprime = f ( u , v ) j9e 2 BS ( v ) , u 2 T ( e ) g. A hypergraph H is said to be acyclic if its graph projection G is a directed acyclic graph ; then a topological ordering of H is an ordering of V that is a topological ordering in G ( from sources to target ) .</sentence>
				<definiendum id="0">Ri</definiendum>
				<definiens id="0">a directed graph G = hV , Eprimei where Eprime = f</definiens>
				<definiens id="1">a directed acyclic graph</definiens>
				<definiens id="2">an ordering of V that is a topological ordering in G ( from sources to target )</definiens>
			</definition>
			<definition id="10">
				<sentence>( Nielsen et al. , 2005 ) Given a hypergraph H =hV , E , t , Ri , a hyperpath piv of destination v 2 V is an acyclic minimal hypergraph H… =hV… , E… , v , Risuch that a source vertex in H… .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">an acyclic minimal hypergraph H… =hV…</definiens>
			</definition>
			<definition id="11">
				<sentence>5 : GC ( v , kprime ) triangleright initialize the heap 6 : append E-M ( cand [ v ] ) to D ( v ) triangleright 1-best 7 : while j D ( v ) j &lt; k and jcand [ v ] j &gt; 0 do 8 : he , jiˆ D| D ( v ) | ( v ) triangleright last derivation 9 : LN ( cand [ v ] , e , j , kprime ) triangleright update the heap , adding the successors of last derivation 10 : append E-M ( cand [ v ] ) to D ( v ) triangleright get the next best derivation and delete it from the heap 11 : 12 : procedure LN ( cand , e , j , kprime ) 13 : for i ˆ 1 ... jej do triangleright add the jej neighbors 14 : jprime ˆ j+bi 15 : LKB ( Ti ( e ) , jprimei , kprime ) triangleright recursively solve a sub-problem 16 : if jprimei •j D ( Ti ( e ) ) j and he , jprimeinelement cand then triangleright if it exists and is not in heap yet 17 : I ( cand , he , jprimei ) triangleright add to heap Figure 7 : Algorithm 3 58 Algorithm Time Complexity 1-best Viterbi O ( E ) Algorithm 0 O ( Eka log k ) Algorithm 1 O ( Ek log k ) Algorithm 2 O ( E +Vk log k ) Algorithm 3 O ( E +jDmaxjk log k ) generalized J &amp; M O ( E +jDmaxjk log ( d +k ) ) Table 1 : Summary of Algorithms .</sentence>
				<definiendum id="0">append E-M</definiendum>
				<definiens id="0">LN ( cand [ v ] , e , j , kprime</definiens>
			</definition>
			<definition id="12">
				<sentence>Algorithm 2 has an overall complexity of O ( jEj + jVjk log k ) and Algorithm 3 is O ( jEj+jDmaxjk log k ) where jDmaxj is the size of the longest among all top k derivations ( for CFG in CNF , jDj= 2n¡1 for all D , sojDmaxjis O ( n ) ) .</sentence>
				<definiendum id="0">jDmaxj</definiendum>
				<definiens id="0">the size of the longest among all top k derivations ( for CFG in CNF</definiens>
			</definition>
			<definition id="13">
				<sentence>Casefactor diagrams for structured probabilistic modeling .</sentence>
				<definiendum id="0">Casefactor</definiendum>
				<definiens id="0">diagrams for structured probabilistic modeling</definiens>
			</definition>
</paper>

		<paper id="0814">
			<definition id="0">
				<sentence>Romanian is a Romance language which has a system of suffixes for inflection which is richer than English .</sentence>
				<definiendum id="0">Romanian</definiendum>
				<definiens id="0">a Romance language which has a system of suffixes for inflection which is richer than English</definiens>
			</definition>
			<definition id="1">
				<sentence>We tried the best performing scoring heuristic for Arabic from ( Rogati et al. , 2003 ) where p ( sj , z , aj|e ) is modeled using the heuristic p ( sj , z|lj ) where sj , z is the Romanian suffix , and lj is the last letter of the Romanian word fj ; these adjustments are updated during EM training .</sentence>
				<definiendum id="0">lj</definiendum>
				<definiens id="0">Rogati et al. , 2003 ) where p ( sj , z</definiens>
			</definition>
			<definition id="2">
				<sentence>RUN1 is the word-based baseline system .</sentence>
				<definiendum id="0">RUN1</definiendum>
				<definiens id="0">the word-based baseline system</definiens>
			</definition>
			<definition id="3">
				<sentence>RUN2 is the stem-based baseline system .</sentence>
				<definiendum id="0">RUN2</definiendum>
				<definiens id="0">the stem-based baseline system</definiens>
			</definition>
</paper>

		<paper id="0631">
			<definition id="0">
				<sentence>The argument identification phase is a binary classifier that decides whether each constituent in the full syntax tree of the sentence is a potential argument .</sentence>
				<definiendum id="0">argument identification phase</definiendum>
			</definition>
			<definition id="1">
				<sentence>Support Vector Learning for Semantic Argument Classification , To appear in Machine Learning journal , Special issue on Speech and Natural Language Processing .</sentence>
				<definiendum id="0">Support Vector Learning</definiendum>
			</definition>
</paper>

		<paper id="0639">
			<definition id="0">
				<sentence>For example , NP-SBJ means the noun phrase is a surface subject of the sentence ; PP-LOC means the prepositional phrase is a location .</sentence>
				<definiendum id="0">NP-SBJ</definiendum>
				<definiendum id="1">prepositional phrase</definiendum>
				<definiens id="0">a surface subject of the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The performance of Semantic Role Labeling ( SRL ) is determined by the quality of the syntactic information provided to the system .</sentence>
				<definiendum id="0">SRL</definiendum>
				<definiens id="0">determined by the quality of the syntactic information provided to the system</definiens>
			</definition>
</paper>

		<paper id="0803">
			<definition id="0">
				<sentence>The chart is a data structure which stores all sub-analyses that cover part of the input string ( in parsing ) or meaning representation ( in generation ) .</sentence>
				<definiendum id="0">chart</definiendum>
				<definiens id="0">a data structure which stores all sub-analyses that cover part of the input string ( in parsing</definiens>
			</definition>
			<definition id="1">
				<sentence>( 2 ) 〈X1/X2 → α • Y1 : r1/Y2 : r2 β , [ i1 , j1 , i2 , j2 ] 〉 , 〈Y1/Y2 → γ • , [ j1 , k1 , j2 , k2 ] 〉 〈X1/X2 → α Y1 : r1/Y2 : r2 • β , [ i1 , k1 , i2 , k2 ] 〉 ( 3 ) 〈X1/X2 → α • Y1 : r1/Y2 : r2 β , [ i1 , j1 , j2 , k2 ] 〉 , 〈Y1/Y2 → γ • , [ j1 , k1 , i2 , j2 ] 〉 〈X1/X2 → α Y1 : r1/Y2 : r2 • β , [ i1 , k1 , i2 , k2 ] 〉 Since each inference rule contains six free variables over string positions ( i1 , j1 , k1 , i2 , j2 , k2 ) , we get a parsing complexity of order O ( n6 ) for unlexicalized grammars ( where n is the number of words in the longer of the two strings from language L1 and L2 ) ( Wu , 1997 ; Melamed , 2003 ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">free variables over string positions ( i1 , j1 , k1 , i2 , j2</definiens>
			</definition>
			<definition id="2">
				<sentence>The other language contributes a secondary index , which is mainly used to guide parsing in the master language – i.e. , certain options are eliminated .</sentence>
				<definiendum id="0">secondary index</definiendum>
				<definiens id="0">mainly used to guide parsing in the master language – i.e. , certain options are eliminated</definiens>
			</definition>
			<definition id="3">
				<sentence>Condition ( iii ) excludes discontinuity in passive chart items , i.e. , complete constituents ; active items 11We use the bold-faced variables v , w , u for bit vectors ; the function OR performs bitwise disjunction on the vectors ( e.g. , OR ( [ 0 , 1 , 1 , 0 , 0 ] , [ 0 , 0 , 1 , 0 , 1 ] ) = [ 0 , 1 , 1 , 0 , 1 ] ) .</sentence>
				<definiendum id="0">Condition ( iii )</definiendum>
				<definiens id="0">excludes discontinuity in passive chart items , i.e. , complete constituents ; active items 11We use the bold-faced variables v , w , u for bit vectors ; the function OR performs bitwise disjunction on the vectors</definiens>
			</definition>
			<definition id="4">
				<sentence>So , in addition to the n4 expense of parsing non-nil words , we get an expense of m3 for parsing the L1-NILs , and we conclude that for unlexicalized synchronous parsing , guided by an initial word alignment the complexity class is O ( n4m3 ) ( where n is the total number of words appearing in L1 , and m is the number of words appearing in L2 , without a correspondent in L1 ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">m</definiendum>
				<definiens id="0">the total number of words appearing in L1 , and</definiens>
				<definiens id="1">the number of words appearing in L2</definiens>
			</definition>
			<definition id="5">
				<sentence>number of chart items 77 121 175 256 ( 330 ) ( 435 ) ( 849 ) We also simulated a synchronous parser which does not take advantage of a given word alignment ( by providing an alignment link between any pair of words , plus the option that any word could be a NULL word ) .</sentence>
				<definiendum id="0">synchronous parser</definiendum>
				<definiens id="0">does not take advantage of a given word alignment ( by providing an alignment link between any pair of words , plus the option that any word could be a NULL word )</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>As the SCF is a relevant clue to learn the relation between syntax and semantic , the classification algorithm accuracy was remarkable enhanced .</sentence>
				<definiendum id="0">SCF</definiendum>
				<definiens id="0">a relevant clue to learn the relation between syntax and semantic , the classification algorithm accuracy was remarkable enhanced</definiens>
			</definition>
			<definition id="1">
				<sentence>Convolution kernels are machine learning approaches which aim to describe structured data in 10 terms of its substructures .</sentence>
				<definiendum id="0">Convolution kernels</definiendum>
			</definition>
			<definition id="2">
				<sentence>The major novelty of the article relates to the extensive experimentation carried out on the PropBank ( Kingsbury and Palmer , 2002 ) and FrameNet ( Fillmore , 1982 ) corpora with diverse levels of task complexity , e.g. test instances of unseen predicates ( typical of free-text processing ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">corpora with diverse levels of task complexity , e.g. test instances of unseen predicates ( typical of free-text processing )</definiens>
			</definition>
			<definition id="3">
				<sentence>Arguments There are two main resources that relate to predicate argument structures : PropBank ( PB ) and FrameNet ( FN ) .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiendum id="1">FrameNet</definiendum>
				<definiens id="0">main resources that relate to predicate argument structures</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , the Phrase Type indicates the syntactic type of the phrase labeled as a predicate argument , e.g. NP for Arg1 in Figure 1 .</sentence>
				<definiendum id="0">Phrase Type</definiendum>
				<definiens id="0">indicates the syntactic type of the phrase labeled as a predicate argument</definiens>
			</definition>
			<definition id="5">
				<sentence>The Parse Tree Path contains the path in the parse tree between the predicate and the argument phrase , expressed as a sequence of non-terminal labels linked by direction ( up or down ) symbols , e.g. V ↑ VP ↓ NP for Arg1 in Figure 1 .</sentence>
				<definiendum id="0">Parse Tree Path</definiendum>
				<definiens id="0">contains the path in the parse tree between the predicate and the argument phrase , expressed as a sequence of non-terminal labels linked by direction ( up or down ) symbols , e.g. V ↑ VP ↓ NP for Arg1 in Figure 1</definiens>
			</definition>
			<definition id="6">
				<sentence>The Predicate Word is the surface form of the verbal predicate , e.g. rent for all arguments .</sentence>
				<definiendum id="0">Predicate Word</definiendum>
				<definiens id="0">the surface form of the verbal predicate</definiens>
			</definition>
			<definition id="7">
				<sentence>KPoly ( Fx , Fz ) = ( c+vectorx·vectorz ) d , where c is a constant and d is the degree of the polynom .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">the degree of the polynom</definiens>
			</definition>
			<definition id="8">
				<sentence>The main idea of tree kernels is to model a K ( T1 , T2 ) function which computes the number of the common substructures between two trees T1 and T2 .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">computes the number of the common substructures between two trees T1 and T2</definiens>
			</definition>
			<definition id="9">
				<sentence>It follows that : K ( T1 , T2 ) = summationdisplay n1∈NT1 summationdisplay n2∈NT2 ∆ ( n1 , n2 ) ( 1 ) where NT1 and NT2 are the sets of the T1’s and T2’s nodes , respectively and ∆ ( n1 , n2 ) =summationtext |F| i=1 Ii ( n1 ) Ii ( n2 ) .</sentence>
				<definiendum id="0">NT2</definiendum>
			</definition>
			<definition id="10">
				<sentence>We can compute ∆ as follows : then ∆ ( n1 , n2 ) = 0 ; and n1 and n2 have only leaf children ( i.e. they are pre-terminals symbols ) then ∆ ( n1 , n2 ) = 1 ; and n1 and n2 are not pre-terminals then ∆ ( n1 , n2 ) = nc ( n1 ) productdisplay j=1 ( 1+∆ ( cjn1 , cjn2 ) ) ( 2 ) where σ ∈ { 0,1 } , nc ( n1 ) is the number of the children of n1 and cjn is the j-th child of the node n. 13 Note that , as the productions are the same nc ( n1 ) = nc ( n2 ) .</sentence>
				<definiendum id="0">cjn</definiendum>
				<definiens id="0">the number of the children of n1 and</definiens>
				<definiens id="1">the j-th child of the node n. 13 Note that , as the productions are the same nc ( n1 ) = nc ( n2 )</definiens>
			</definition>
</paper>

		<paper id="0409">
			<definition id="0">
				<sentence>Open domain question answering ( QA ) , as defined by the TREC competitions ( Voorhees , 2003 ) , represents an advanced application of natural language processing ( NLP ) .</sentence>
				<definiendum id="0">Open domain question answering ( QA</definiendum>
				<definiendum id="1">TREC competitions</definiendum>
				<definiens id="0">an advanced application of natural language processing ( NLP )</definiens>
			</definition>
			<definition id="1">
				<sentence>Question Processing ( QP ) Module , which finds some useful information from the questions , such as expected answer type and key words .</sentence>
				<definiendum id="0">Question Processing</definiendum>
				<definiendum id="1">QP ) Module</definiendum>
				<definiens id="0">finds some useful information from the questions , such as expected answer type and key words</definiens>
			</definition>
			<definition id="2">
				<sentence>Information Retrieval ( IR ) Module , which searches a document collection to retrieve a set of relevant sentences using the question key words .</sentence>
				<definiendum id="0">Information Retrieval</definiendum>
				<definiendum id="1">IR ) Module</definiendum>
				<definiens id="0">searches a document collection to retrieve a set of relevant sentences using the question key words</definiens>
			</definition>
			<definition id="3">
				<sentence>Answer Extraction ( AE ) Module , which analyzes the relevant sentences using the information provided by the QP module and identify the answer phrase .</sentence>
				<definiendum id="0">Answer Extraction ( AE ) Module</definiendum>
				<definiens id="0">analyzes the relevant sentences using the information provided by the QP module and identify the answer phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>BBN ( Xu et al. 2002 ) used a HMM-based IR system to score the answer candidates based on the answer contexts .</sentence>
				<definiendum id="0">BBN</definiendum>
				<definiens id="0">a HMM-based IR system to score the answer candidates based on the answer contexts</definiens>
			</definition>
			<definition id="5">
				<sentence>The goal of the AE module is to choose the most probable answer from a set of answer candidates 12 { , , ... } m ac ac ac for the question Q. We regard the answer extraction as a classification problem , which classify each question and 66 answer candidate pair &lt; Q , ac i &gt; into the positive class ( the correct answer ) and the negative class ( the incorrect answer ) , based on some features .</sentence>
				<definiendum id="0">AE module</definiendum>
				<definiens id="0">the incorrect answer</definiens>
			</definition>
			<definition id="6">
				<sentence>Support Vector Machines ( SVM ) ( Vapnik , 1995 ) have strong theoretical motivation in statistical learning theory and achieve excellent generalization performance in many language processing applications , such as text classification ( Joachims , 1998 ) .</sentence>
				<definiendum id="0">Support Vector Machines</definiendum>
			</definition>
			<definition id="7">
				<sentence>Given a set of labeled training instances ( ) ( ) ( ) { } 11 2 2 , , , , ... , , mm D yy y= xx x , where n i ∈xR and { } 1 , 1 i y =− , SVM is to find the optimal hyperplane that separates the positive and negative training instances with a maximal margin .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">to find the optimal hyperplane that separates the positive and negative training instances with a maximal margin</definiens>
			</definition>
			<definition id="8">
				<sentence>, if the answer candidate consists of the words with the syntactic tags “CD NN” , it is more likely to be the proper answer .</sentence>
				<definiendum id="0">answer candidate</definiendum>
				<definiens id="0">consists of the words with the syntactic tags “CD NN” , it is more likely to be the proper answer</definiens>
			</definition>
			<definition id="9">
				<sentence>The question words are divided into four types : z Target word , which indicates the expected answer type , such as “city” in “Q : What city is Disneyland in ? ”</sentence>
				<definiendum id="0">z Target word</definiendum>
				<definiens id="0">indicates the expected answer type</definiens>
			</definition>
			<definition id="10">
				<sentence>We define an object ( a relation tree ) as the smallest tree which covers one answer candidate node and one question key word node .</sentence>
				<definiendum id="0">an object</definiendum>
				<definiens id="0">a relation tree ) as the smallest tree which covers one answer candidate node and one question key word node</definiens>
			</definition>
			<definition id="11">
				<sentence>t 4 t 3 t 2 T : BNP O : null R1 : true R2 : false t 1 Dallas-Fort T : NNP O : CAPALL R1 : false R2 : false International T : JJ O : CAPALL R1 : false R2 : false Airport T : NNP O : CAPALL R1 : false R2 : true Q35 : What is the name of the highest mountain in Africa ?</sentence>
				<definiendum id="0">R2</definiendum>
				<definiens id="0">true R2 : false t 1 Dallas-Fort T : NNP O : CAPALL R1 : false R2 : false International T : JJ O : CAPALL R1 : false R2 : false Airport T : NNP O : CAPALL R1 : false</definiens>
			</definition>
			<definition id="12">
				<sentence>, F trg return the proper answer “25 knots” from the sentence “The submarine , 360 feet ( 109.8 meters ) long , has 129 crew members and travels at 25 knots.”</sentence>
				<definiendum id="0">F trg</definiendum>
			</definition>
</paper>

		<paper id="1625">
			<definition id="0">
				<sentence>and Brittany is a part of France .</sentence>
				<definiendum id="0">Brittany</definiendum>
			</definition>
			<definition id="1">
				<sentence>Consequently , we define the certainty degree a41 a11 a59 of the answer a0a51 a11a41a4 a51 a59 a9 as : a41 a11 a59 a13a43a42 a19 a44a6a45 a33 a11 a59 a13 a19 a40a47a46a70a33 a11 a59 a48a33a44a6a49a51a50a47a52 a20a41a0 a51 a11 a4 a51 a59 a9a46a4 a33 a11 a59 a31 a52 a40 a56 a22 and a40 a13 a33 a11 a59 a3a34a33 a29 a69 where a33 a11 a59 is the best coherence rate and a33 a29 a69 the second best one .</sentence>
				<definiendum id="0">a59</definiendum>
				<definiens id="0">the certainty degree a41 a11 a59 of the answer a0a51 a11a41a4 a51 a59 a9 as : a41 a11 a59 a13a43a42 a19 a44a6a45 a33 a11 a59 a13 a19 a40a47a46a70a33 a11 a59 a48a33a44a6a49a51a50a47a52 a20a41a0 a51 a11 a4 a51 a59 a9a46a4 a33 a11 a59 a31 a52 a40 a56 a22 and a40 a13 a33 a11 a59 a3a34a33 a29 a69 where a33 a11</definiens>
			</definition>
			<definition id="2">
				<sentence>For this purpose , we define a lexicalisation function lex which lexicalises the selected answers and a function lexD which lexicalises a41 .</sentence>
				<definiendum id="0">lexicalisation function lex</definiendum>
				<definiens id="0">lexicalises the selected answers and a function lexD which lexicalises a41</definiens>
			</definition>
			<definition id="3">
				<sentence>case ( 1 ) subject lexD ( a41a6a4 , min ) verb lex ( A , Reg ) case ( 2 ) subject verb lex ( A , Reg ) case ( 3 ) a40 is high : subject lexD ( a41a6a4 , ) verb lex ( A , Reg ) a40 is low : a40 and a40 a2 are proposed if a40 is a date : subject lexD ( a41a6a4 , ) verb lex ( A , Reg ) or lex ( Aa2 , Reg ) if a40 is an interval : subject lexD ( a41a6a4a8a7 , ) verb lex ( Aa2 , Reg ) but lexD ( a41 a4 a7 , plus ) lex ( A , Reg ) Table 1 : Generation schemas Adverb intensity is represented by the following proportional serie ( cf. Figure 3 ) : Figure 3 : Adverb intensity Consequently , if a41 is high , it will be lexicalised by an adverb of high intensity .</sentence>
				<definiendum id="0">lexD</definiendum>
				<definiendum id="1">A , Reg</definiendum>
				<definiendum id="2">lexD</definiendum>
				<definiens id="0">an interval : subject lexD ( a41a6a4a8a7 , ) verb lex</definiens>
				<definiens id="1">Generation schemas Adverb intensity is represented by the following proportional serie ( cf. Figure 3 ) : Figure 3 : Adverb intensity Consequently</definiens>
			</definition>
</paper>

		<paper id="0408">
			<definition id="0">
				<sentence>We also show how we can combine this method with a Naive Bayes bootstrapping approach that takes further advantage of the unlabeled data ( Nigam et al. 2000 ) .</sentence>
				<definiendum id="0">Naive Bayes bootstrapping approach</definiendum>
			</definition>
			<definition id="1">
				<sentence>This labeled subset of the data is then used to bootstrap a Naive Bayes ( NB ) classifier on the remaining unlabeled data D U using the Expectation Maximization ( EM ) algorithm : ( 1 ) An initial naive Bayes classifier with parameters θ is trained on the documents in DL .</sentence>
				<definiendum id="0">Naive Bayes ( NB</definiendum>
				<definiens id="0">) classifier on the remaining unlabeled data D U using the Expectation Maximization ( EM ) algorithm : ( 1 ) An initial naive Bayes classifier with parameters θ is trained on the documents in DL</definiens>
			</definition>
</paper>

		<paper id="1207">
			<definition id="0">
				<sentence>In this work we investigate methods to enable the detection of a specific type of textual entailment ( strict entailment ) , starting from the preliminary assumption that these relations are often clearly expressed in texts .</sentence>
				<definiendum id="0">textual entailment</definiendum>
				<definiens id="0">strict entailment ) , starting from the preliminary assumption that these relations are often clearly expressed in texts</definiens>
			</definition>
			<definition id="1">
				<sentence>Textual entailment has been recently defined as a common solution for modelling language variability in different NLP tasks ( Glickman and Dagan , 2004 ) .</sentence>
				<definiendum id="0">Textual entailment</definiendum>
			</definition>
			<definition id="2">
				<sentence>2.1 can be straightforwardly applied to generate textual entailment patterns , as it often happens that verbs can undergo an agentive nominalization ( hereafter called personification ) , e.g. , play vs. player .</sentence>
				<definiendum id="0">textual entailment patterns</definiendum>
				<definiens id="0">verbs can undergo an agentive nominalization ( hereafter called personification ) , e.g. , play vs. player</definiens>
			</definition>
			<definition id="3">
				<sentence>This set will contain the following textual patterns : Ppers ( vt , vh ) = { “pers ( vh ) |number : sing vt|person : third , tense : present” , “pers ( vh ) |number : plur vt|person : nothird , tense : present” , “pers ( vh ) |number : sing vt|tense : past” , “pers ( vh ) |number : plur vt|tense : past” } where pers ( v ) is the noun deriving from the personification of the verb v and elements such as l|f1 , ... , fN are the tokens generated from lemmas l by applying constraints expressed via the features f1 , ... , fN .</sentence>
				<definiendum id="0">fN</definiendum>
				<definiens id="0">the noun deriving from the personification of the verb v and elements such as l|f1 , ... ,</definiens>
			</definition>
			<definition id="4">
				<sentence>Each 40 Figure 1 : ROC curves pair of synsets ( St , Sh ) is an oriented entailment relation between St and Sh .</sentence>
				<definiendum id="0">Sh )</definiendum>
				<definiens id="0">ROC curves pair of synsets ( St ,</definiens>
				<definiens id="1">an oriented entailment relation between St and Sh</definiens>
			</definition>
			<definition id="5">
				<sentence>Sensitivity , i.e. the probability of having positive answers for positive pairs , and specificity , i.e. the probability of having negative answers for negative pairs , are then defined as : Sensitivity ( t ) = p ( ( vh , vt ) ∈ TS|S ( vh , vt ) &gt; t ) Specificity ( t ) = p ( ( vh , vt ) ∈ CS|S ( vh , vt ) &lt; t ) where p ( ( vh , vt ) ∈ TS|S ( vh , vt ) &gt; t ) is the probability of a candidate pair ( vh , vt ) to belong to TS if the test is positive , i.e. the value S ( vh , vt ) of the entailment detection measure is greater than t , while p ( ( vh , vt ) ∈ CS|S ( vh , vt ) &lt; t ) is the probability of belonging to CS if the test is negative .</sentence>
				<definiendum id="0">Sensitivity</definiendum>
				<definiendum id="1">vt )</definiendum>
				<definiendum id="2">entailment detection measure</definiendum>
				<definiendum id="3">CS|S ( vh , vt ) &lt; t )</definiendum>
				<definiens id="0">the probability of having positive answers for positive pairs , and specificity , i.e. the probability of having negative answers for negative pairs , are then defined as : Sensitivity ( t ) = p ( ( vh , vt ) ∈ TS|S ( vh , vt ) &gt; t ) Specificity ( t ) = p ( ( vh , vt ) ∈ CS|S ( vh , vt ) &lt; t ) where p ( ( vh , vt ) ∈ TS|S ( vh , vt ) &gt; t ) is the probability of a candidate pair</definiens>
				<definiens id="1">the probability of belonging to CS if the test is negative</definiens>
			</definition>
</paper>

		<paper id="0909">
			<definition id="0">
				<sentence>METEOR was designed to explicitly address several observed weaknesses in IBM 's BLEU metric .</sentence>
				<definiendum id="0">METEOR</definiendum>
				<definiens id="0">designed to explicitly address several observed weaknesses in IBM 's BLEU metric</definiens>
			</definition>
			<definition id="1">
				<sentence>Given a pair of translations to be compared ( a system translation and a reference translation ) , METEOR creates an alignment between the two strings .</sentence>
				<definiendum id="0">METEOR</definiendum>
				<definiens id="0">creates an alignment between the two strings</definiens>
			</definition>
			<definition id="2">
				<sentence>Formally , two unigram mappings ( ti , rj ) and ( tk , rl ) ( where ti and tk are unigrams in the system translation mapped to unigrams rj and rl in the reference translation respectively ) are said to cross if and only if the following formula evaluates to a negative number : ( pos ( ti ) – pos ( tk ) ) * ( pos ( rj ) – pos ( rl ) ) where pos ( tx ) is the numeric position of the unigram tx in the system translation string , and pos ( ry ) is the numeric position of the unigram ry in the reference string .</sentence>
				<definiendum id="0">pos</definiendum>
				<definiens id="0">the numeric position of the unigram tx in the system translation string</definiens>
			</definition>
			<definition id="3">
				<sentence>To take into account longer matches , METEOR computes a penalty for a given alignment as follows .</sentence>
				<definiendum id="0">METEOR</definiendum>
				<definiens id="0">computes a penalty for a given alignment as follows</definiens>
			</definition>
			<definition id="4">
				<sentence>The Chinese data set consists of 920 sentences , while the Arabic data set consists of 664 sentences .</sentence>
				<definiendum id="0">Chinese data set</definiendum>
			</definition>
			<definition id="5">
				<sentence>Towards this end , in the rest of this paper , our evaluation methodology is as follows : For each system , we compute the METEOR Score for every translation produced by the system , and then compute the correlation between these individual scores and the human assessments ( average of the adequacy and fluency scores ) for the same translations .</sentence>
				<definiendum id="0">METEOR Score</definiendum>
				<definiens id="0">for every translation produced by the system</definiens>
			</definition>
</paper>

		<paper id="0812">
			<definition id="0">
				<sentence>The objective of word alignment is to discover the wordto-word translational correspondences in a bilingual corpus of S sentence pairs , which we denote f ( f ( s ) , e ( s ) ) : s 2 [ 1 , S ] g. Each sentence pair ( f , e ) = ( f M1 , eN1 ) consists of a sentence f in one language and its translation e in the other , with lengths M and N , respectively .</sentence>
				<definiendum id="0">objective of word alignment</definiendum>
				<definiendum id="1">sentence pair</definiendum>
				<definiendum id="2">eN1 )</definiendum>
				<definiens id="0">to discover the wordto-word translational correspondences in a bilingual corpus of S sentence pairs</definiens>
				<definiens id="1">consists of a sentence f in one language</definiens>
			</definition>
</paper>

		<paper id="0612">
			<definition id="0">
				<sentence>Coreference resolution is the process of determining which expressions in text refer to the same realworld entity .</sentence>
				<definiendum id="0">Coreference resolution</definiendum>
				<definiens id="0">the process of determining which expressions in text refer to the same realworld entity</definiens>
			</definition>
			<definition id="1">
				<sentence>Pronoun resolution is the important yet challenging subset of coreference resolution where a system attempts to establish coreference between a pronominal anaphor , such as a third-person pronoun like he , she , it , or they , and a preceding noun phrase , called an antecedent .</sentence>
				<definiendum id="0">Pronoun resolution</definiendum>
				<definiens id="0">the important yet challenging subset of coreference resolution where a system attempts to establish coreference between a pronominal anaphor , such as a third-person pronoun like he , she , it , or they , and a preceding noun phrase , called an antecedent</definiens>
			</definition>
			<definition id="2">
				<sentence>Kehler used Maximum Entropy to assign a probability distribution over possible noun phrase coreference relationships ( 1997 ) .</sentence>
				<definiendum id="0">Kehler</definiendum>
			</definition>
			<definition id="3">
				<sentence>C consists of all nouns and pronouns that precede p , looking back through the current sentence and the sentence immediately preceding it .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">consists of all nouns and pronouns that precede p , looking back through the current sentence and the sentence immediately preceding it</definiens>
			</definition>
			<definition id="4">
				<sentence>Expectation Maximization ( Dempster et al. , 1977 ) is a process for filling in unobserved data probabilistically .</sentence>
				<definiendum id="0">Expectation Maximization</definiendum>
				<definiens id="0">a process for filling in unobserved data probabilistically</definiens>
			</definition>
			<definition id="5">
				<sentence>Pr ( k|l ) measures the probability of the syntactic relationship between a pronoun and its parent , given a prospective antecedent for the pronoun .</sentence>
				<definiendum id="0">Pr ( k|l )</definiendum>
				<definiens id="0">measures the probability of the syntactic relationship between a pronoun and its parent , given a prospective antecedent for the pronoun</definiens>
			</definition>
			<definition id="6">
				<sentence>Pr ( c|p , k ) = Pr ( p|l ) Pr ( k|l ) Pr ( l ) Pr ( j ) summationtext cprime∈C Pr ( p|lprime ) Pr ( k|lprime ) Pr ( lprime ) Pr ( jprime ) ( 6 ) Pr ( c|p , k ) allows us to get fractional counts of ( p , k , c ) triples in our training set , as if we had actually observed c co-occurring with ( p , k ) in the proportions specified by Equation 6 .</sentence>
				<definiendum id="0">Pr</definiendum>
				<definiens id="0">k ) = Pr ( p|l ) Pr ( k|l ) Pr ( l ) Pr ( j ) summationtext cprime∈C Pr ( p|lprime ) Pr ( k|lprime ) Pr ( lprime ) Pr ( jprime ) ( 6 ) Pr ( c|p , k ) allows us to get fractional counts of ( p , k</definiens>
			</definition>
			<definition id="7">
				<sentence>The development set consists of 333,000 pronouns drawn from 31,000 documents .</sentence>
				<definiendum id="0">development set</definiendum>
				<definiens id="0">consists of 333,000 pronouns drawn from 31,000 documents</definiens>
			</definition>
			<definition id="8">
				<sentence>The development key consists of 644 labeled pronouns drawn from 58 documents ; 417 are drawn from sentences without quotation marks .</sentence>
				<definiendum id="0">development key</definiendum>
				<definiens id="0">consists of 644 labeled pronouns drawn from 58 documents ; 417 are drawn from sentences without quotation marks</definiens>
			</definition>
			<definition id="9">
				<sentence>The test set consists of 890,000 pronouns drawn from 50,000 documents .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of 890,000 pronouns drawn from 50,000 documents</definiens>
			</definition>
			<definition id="10">
				<sentence>The test key consists of 1209 labeled pronouns drawn from 118 documents ; 892 are drawn from sentences without quotation marks .</sentence>
				<definiendum id="0">test key</definiendum>
				<definiens id="0">consists of 1209 labeled pronouns drawn from 118 documents ; 892 are drawn from sentences without quotation marks</definiens>
			</definition>
</paper>

		<paper id="0504">
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>C is a count function that counts concepts that are associated with the given attribute .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a count function that counts concepts that are associated with the given attribute</definiens>
			</definition>
			<definition id="1">
				<sentence>Uniqueness ranges from 0 to 1 .</sentence>
				<definiendum id="0">Uniqueness</definiendum>
				<definiens id="0">ranges from 0 to 1</definiens>
			</definition>
			<definition id="2">
				<sentence>Class Top 10 Distinctive Attributes Related-Agent ( 0.39 ) identity , hands , duty , consent , responsibility , part , attention , voice , death , job Part &amp; Related-Object ( 0.40 ) inside , shape , top , outside , surface , bottom , center , front , size , interior Activity ( 0.29 ) time , result , process , results , timing , date , effect , beginning , cause , purpose Quality ( 0.23 ) measure , basis , determination , question , extent , issue , measurement , light , result , increase Non-Attribute ( 0.18 ) content , value , rest , nature , meaning , format , interpretation , essence , size , source Table 1 : Top 10 distinctive attributes of the five classes of candidate attributes .</sentence>
				<definiendum id="0">measurement</definiendum>
				<definiens id="0">identity , hands , duty , consent , responsibility , part , attention , voice , death , job Part &amp; Related-Object ( 0.40 ) inside , shape , top , outside , surface , bottom , center , front , size , interior Activity ( 0.29 ) time , result , process , results , timing , date</definiens>
				<definiens id="1">nature , meaning , format , interpretation , essence , size , source Table 1 : Top 10 distinctive attributes of the five classes of candidate attributes</definiens>
			</definition>
			<definition id="3">
				<sentence>After collecting occurrence frequencies for all the candidate attributes , we transform these counts into weights using the t-test weighting function as done for all of our counts , using the following formula from Manning and Schuetze ( 1999 ) : 2 2 , ) , ( N ) ( ) ( ) , ( N attributequestionC attributeCquestionC N attributequestionC t ji jiji ji × − ≈ where N is the total number of relations , and C is a count function .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the total number of relations , and</definiens>
			</definition>
			<definition id="4">
				<sentence>The results are based on the CLUTO evaluation meas24 ures : Purity ( which measures the degree of cohesion of the clusters obtained ) and Entropy .</sentence>
				<definiendum id="0">Purity</definiendum>
				<definiens id="0">measures the degree of cohesion of the clusters obtained ) and Entropy</definiens>
			</definition>
			<definition id="5">
				<sentence>S r is a cluster , n r is the size of the cluster , q is the number of classes , n i r is the number of concepts from the ith class that were assigned to the rth cluster , n is the number of concepts , and k is the number of clusters .</sentence>
				<definiendum id="0">n r</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">k</definiendum>
				<definiens id="0">the number of clusters</definiens>
			</definition>
</paper>

		<paper id="0605">
			<definition id="0">
				<sentence>Word Sense Disambiguation ( WSD ) is one of the central problems in Natural Language Processing .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
				<definiendum id="1">WSD</definiendum>
				<definiens id="0">one of the central problems in Natural Language Processing</definiens>
			</definition>
			<definition id="1">
				<sentence>Noun : subject-of , object-of , complement-of , has-adjective-modifier , has-noun-modifier , modifier-of , possess , possessed-by , appositive-of Verb : has-subject , has-object , has-complement , has-adverb-modifier , has-prepositional-phrase-modifier Adjective : modifier-of , has-adverb-modifier Based on the above context features , the following three categories of context similarity features are defined : ( 1 ) VSM-based ( Vector Space Model based ) trigger word similarity : the trigger words around the keyword are represented as a vector , and the word i in context j is weighted as follows : ) ( log* ) , ( ) , ( idf D jitfjiweight = where ) , ( jitf is the frequency of word i in the j-th context ; D is the number of documents in the pool ; and ) ( idf is the number of documents containing the word i. D and ) ( idf are estimated using the document pool introduced above .</sentence>
				<definiendum id="0">jitf</definiendum>
				<definiendum id="1">D</definiendum>
				<definiendum id="2">) ( idf</definiendum>
				<definiens id="0">the number of documents in the pool ; and</definiens>
			</definition>
			<definition id="2">
				<sentence>To solve this problem , LSA is used as a type of synonym expansion in matching .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">a type of synonym expansion in matching</definiens>
			</definition>
			<definition id="3">
				<sentence>The maximum entropy modeling is used to compute the conditional probabilities ( ) jiji CSSS , Pr = and ( ) jiji CSSS , Pr ≠ : once the context pair ji CS , is represented as } { α f , the conditional probability is given as ( ) { } ∏ ∈ = α α ff ft w Z ft , 1 } { Pr ( 1 ) where { } jiji SSSSt ≠=∈ , , Z is the normalization factor , ft w , is the weight associated with tag t and feature f .</sentence>
				<definiendum id="0">maximum entropy modeling</definiendum>
				<definiendum id="1">Z</definiendum>
				<definiens id="0">the weight associated with tag t and feature f</definiens>
			</definition>
			<definition id="4">
				<sentence>The optimization process consists of two steps .</sentence>
				<definiendum id="0">optimization process</definiendum>
			</definition>
</paper>

		<paper id="1520">
			<definition id="0">
				<sentence>Our NLU is a part of Mission Rehearsal Exercise ( MRE ) project ( Swartout et al. , 2001 ) .</sentence>
				<definiendum id="0">NLU</definiendum>
			</definition>
			<definition id="1">
				<sentence>MRE is a large system that is being built to train experts , in which a trainee interacts with a Virtual Human using voice input .</sentence>
				<definiendum id="0">MRE</definiendum>
				<definiens id="0">a large system that is being built to train experts , in which a trainee interacts with a Virtual Human using voice input</definiens>
			</definition>
			<definition id="2">
				<sentence>The purpose of our NLU is to convert the sentence strings produced by the speech recognizer into internal shallow semantic frames composed of slot-value pairs , for the dialogue module .</sentence>
				<definiendum id="0">NLU</definiendum>
				<definiens id="0">to convert the sentence strings produced by the speech recognizer into internal shallow semantic frames composed of slot-value pairs</definiens>
			</definition>
</paper>

		<paper id="0616">
			<definition id="0">
				<sentence>To formalize the idea of decomposition , we define the factorization of an element u in U as : Definition 1 ( Factorization ) A factorization of u ∈ U is a sequence u1 ... un , with ∀i , ui ∈ U , such that : u1 ⊕ ... ⊕un = u. Each term ui is a factor of u. The alternation constraint expresses the fact that analogically related objects should be made of alternating factors : for x : y : : z : t to hold , each factor in x should be found alternatively in y and in z. This yields a first definition of analogical proportions : Definition 2 ( Analogical proportion ) ( x , y , z , t ) ∈U form an analogical proportion , denoted by x : y : : z : t if and only if there exists some factorizations x1⊕ ... ⊕xd = x , y1⊕ ... ⊕yd = y , z1 ⊕ ... ⊕zd = z , t1 ⊕ ... ⊕td = t such that ∀i , ( yi , zi ) ∈ { ( xi , ti ) , ( ti , xi ) } .</sentence>
				<definiendum id="0">U</definiendum>
				<definiendum id="1">alternation constraint</definiendum>
				<definiens id="0">Analogical proportion ) ( x , y , z , t ) ∈U form an analogical proportion</definiens>
			</definition>
			<definition id="1">
				<sentence>Σstar denotes the set of finite sequences of elements of Σ , called words over Σ .</sentence>
				<definiendum id="0">Σstar</definiendum>
				<definiens id="0">the set of finite sequences of elements of Σ , called words over Σ</definiens>
			</definition>
			<definition id="2">
				<sentence>Bound morphemes have a compositional type : B|A. denotes a suffix that turns adjectives into adverbs .</sentence>
				<definiendum id="0">B|A.</definiendum>
				<definiens id="0">a suffix that turns adjectives into adverbs</definiens>
			</definition>
			<definition id="3">
				<sentence>Per instance recall is the relative number of reference values that were actually hypothesized .</sentence>
				<definiendum id="0">Per instance recall</definiendum>
			</definition>
</paper>

		<paper id="1507">
			<definition id="0">
				<sentence>We show 1We speak of m-gram language models to avoid confusion with n , which here is the length of the input sentence for translation .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="1">
				<sentence>Transduction Grammar The Inversion Transduction Grammar ( ITG ) of Wu ( 1997 ) is a type of context-free grammar ( CFG ) for generating two languages synchronously .</sentence>
				<definiendum id="0">Inversion Transduction Grammar</definiendum>
				<definiendum id="1">CFG</definiendum>
				<definiens id="0">a type of context-free grammar (</definiens>
			</definition>
			<definition id="2">
				<sentence>ITG in Chomsky normal form consists of unary production rules that are responsible for generating word pairs : X → e/f X → e/epsilon1 X → epsilon1/f where e is a source language word , f is a foreign language word , and epsilon1 means the null token , and binary production rules in two forms that are responsible for generating syntactic subtree pairs : X → [ Y Z ] 65 and X → 〈Y Z〉 The rules with square brackets enclosing the right-hand side expand the left-hand side symbol into the two symbols on the right-hand side in the same order in the two languages , whereas the rules with angled brackets expand the left hand side symbol into the two right-hand side symbols in reverse order in the two languages .</sentence>
				<definiendum id="0">e</definiendum>
				<definiendum id="1">f</definiendum>
				<definiens id="0">unary production rules that are responsible for generating word pairs</definiens>
				<definiens id="1">a source language word ,</definiens>
			</definition>
			<definition id="3">
				<sentence>One special case of 2-normal ITG is the so-called Bracketing Transduction Grammar ( BTG ) which has only one nonterminal A and two binary rules A → [ AA ] and A → 〈AA〉 By mixing instances of the inverted rule with those of the straight rule hierarchically , BTG can meet the alignment requirements of different language pairs .</sentence>
				<definiendum id="0">ITG</definiendum>
				<definiens id="0">the so-called Bracketing Transduction Grammar ( BTG ) which has only one nonterminal A and two binary rules A →</definiens>
			</definition>
			<definition id="4">
				<sentence>Given a sentence pair , searching for the Viterbi synchronous parse tree , of which the alignment is a byproduct , turns out to be a two-dimensional extension of PCFG parsing , having time complexity of O ( n6 ) , where n is the length of the English string and the foreign language string .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">Given a sentence pair , searching for the Viterbi synchronous parse tree</definiens>
				<definiens id="1">the length of the English string and the foreign language string</definiens>
			</definition>
			<definition id="5">
				<sentence>When the maximum number of lexicalized nonterminals in any rule is two , a CFG is bilexical .</sentence>
				<definiendum id="0">CFG</definiendum>
				<definiens id="0">bilexical</definiens>
			</definition>
			<definition id="6">
				<sentence>β ( A [ i , j , h ] ) = max    max k , hprime , B , C bracketleftBig β ( B [ i , k , hprime ] ) · β ( C [ k , j , h ] ) · P ( A [ h ] → B [ hprime ] C [ h ] ) bracketrightBig , max k , hprime , B , C bracketleftBig β ( B [ i , k , h ] ) · β ( C [ k , j , hprime ] ) · P ( A [ h ] → B [ h ] C [ hprime ] ) bracketrightBig    ( 1 ) max k , hprime , B , C bracketleftBig β ( B [ i , k , hprime ] ) · β ( C [ k , j , h ] ) · P ( A [ h ] → B [ hprime ] C [ h ] ) bracketrightBig = max k , C bracketleftbigg max hprime , B bracketleftBig β ( B [ i , k , hprime ] ) · P ( A [ h ] → B [ hprime ] C [ h ] ) bracketrightBig · β ( C [ k , j , h ] ) bracketrightbigg Figure 2 : Equation for bilexical parsing ( top ) , with an efficient factorization ( bottom ) a right boundary word .</sentence>
				<definiendum id="0">β</definiendum>
				<definiens id="0">h ] ) = max    max k , hprime</definiens>
				<definiens id="1">A [ h ] → B [ hprime ] C [ h ] ) bracketrightBig = max k , C bracketleftbigg max hprime , B bracketleftBig β ( B [ i , k , hprime ] ) · P ( A [ h ] → B [ hprime ] C [ h ] ) bracketrightBig · β ( C [ k , j , h ] ) bracketrightbigg Figure 2</definiens>
			</definition>
			<definition id="7">
				<sentence>The underlying alignment pattern for this rule is as follows : D C E B A It is a rule that can not be binarized in the bitext space using ITG rules .</sentence>
				<definiendum id="0">It</definiendum>
				<definiens id="0">D C E B A</definiens>
			</definition>
</paper>

		<paper id="0206">
			<definition id="0">
				<sentence>Probabilistic Latent Semantic Analysis ( PLSA ) is an information retrieval technique proposed to improve the problems found in Latent Semantic Analysis ( LSA ) .</sentence>
				<definiendum id="0">Probabilistic Latent Semantic Analysis ( PLSA )</definiendum>
			</definition>
			<definition id="1">
				<sentence>LSA has produced promising results in content analysis of essays ( Landauer et al. , 1997 ; Foltz et al. , 1999b ) .</sentence>
				<definiendum id="0">LSA</definiendum>
			</definition>
			<definition id="2">
				<sentence>Based on these measures , threshold values for the grade categories are defined as follows : the grade categories , g1 , g2 , ... , gC , are associated with similarity value limits , l1 , l2 , ... , lC+1 , where C is the number of grades , and lC+1 = ∞ and normally l1 = 0 or −∞ .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">follows : the grade categories , g1 , g2 , ... , gC , are associated with similarity value limits , l1 , l2 , ... , lC+1 , where</definiens>
				<definiens id="1">the number of grades , and lC+1 = ∞ and normally l1 = 0 or −∞</definiens>
			</definition>
			<definition id="3">
				<sentence>Latent Semantic Analysis ( LSA ) ( Landauer et al. , 1998 ) is a corpus-based method used in information retrieval with vector space models .</sentence>
				<definiendum id="0">Latent Semantic Analysis ( LSA )</definiendum>
				<definiens id="0">a corpus-based method used in information retrieval with vector space models</definiens>
			</definition>
			<definition id="4">
				<sentence>SVD is a form of factor analysis , which reduces the dimensionality of the original WCM and thereby increases the dependency between contexts and words ( Landauer et al. , 1998 ) .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">a form of factor analysis</definiens>
			</definition>
			<definition id="5">
				<sentence>SVD is defined as X = T0S0D0T , where X is the preprocessed WCM and T0 and D0 are orthonormal matrices representing the words and the contexts .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiendum id="1">X</definiendum>
			</definition>
			<definition id="6">
				<sentence>S0 is a diagonal matrix with singular values .</sentence>
				<definiendum id="0">S0</definiendum>
				<definiens id="0">a diagonal matrix with singular values</definiens>
			</definition>
			<definition id="7">
				<sentence>The aspect model is a latent variable model for co-occurrence data , which associates unobserved class variables zk , k ∈ { 1,2 , ... , K } with each observation .</sentence>
				<definiendum id="0">aspect model</definiendum>
				<definiens id="0">a latent variable model for co-occurrence data , which associates unobserved class variables zk , k ∈ { 1,2 , ... , K } with each observation</definiens>
			</definition>
			<definition id="8">
				<sentence>The probabilities related to this model are defined as follows : • P ( di ) denotes the probability that a word occurrence will be observed in a particular context di ; • P ( wj|zk ) denotes the class-conditional probability of a specific word conditioned on the unobserved class variable zk ; and • P ( zk|di ) denotes a context specific probability distribution over the latent variable space .</sentence>
				<definiendum id="0">P ( wj|zk )</definiendum>
				<definiendum id="1">• P</definiendum>
				<definiens id="0">the probability that a word occurrence will be observed in a particular context di ; •</definiens>
				<definiens id="1">the class-conditional probability of a specific word conditioned on the unobserved class variable zk ; and</definiens>
				<definiens id="2">a context specific probability distribution over the latent variable space</definiens>
			</definition>
			<definition id="9">
				<sentence>P ( zk|di , wj ) = ( P ( wj|zk ) P ( zk|di ) ) β parenleftBigsummationtextK l=1 P ( wj|zl ) P ( zl|di ) parenrightBigβ ( 4 ) Hofmann ( 2001 ) defines the TEM algorithm as follows : early stopping .</sentence>
				<definiendum id="0">TEM algorithm</definiendum>
				<definiens id="0">early stopping</definiens>
			</definition>
			<definition id="10">
				<sentence>Select-aKibitzer : A computer tool that gives meaningful feedback on student compositions .</sentence>
				<definiendum id="0">Select-aKibitzer</definiendum>
				<definiens id="0">A computer tool that gives meaningful feedback on student compositions</definiens>
			</definition>
</paper>

		<paper id="0907">
			<definition id="0">
				<sentence>49 automatic summary QUEEN operates under the assumption that a summary is better if it is closer to the model summaries according to all metrics ; it is defined as the probability , measured onM ×M ×M , that for every metric in X the automatic summary a is closer to a model than two models to each other : QUEENX , M ( a ) ≡ P ( ∀x ∈ X.x ( a , m ) ≥ x ( mprime , mprimeprime ) ) where a is the automatic summary being evaluated , 〈m , mprime , mprimeprime〉 are three models in M , and x ( a , m ) stands for the similarity ofmtoa .</sentence>
				<definiendum id="0">QUEEN</definiendum>
				<definiendum id="1">M</definiendum>
				<definiendum id="2">P ( ∀x ∈ X.x</definiendum>
				<definiendum id="3">x</definiendum>
				<definiens id="0">operates under the assumption that a summary is better if it is closer to the model summaries according to all metrics</definiens>
				<definiens id="1">the automatic summary being evaluated , 〈m , mprime</definiens>
			</definition>
			<definition id="1">
				<sentence>metrics The measure KINGM , A ( X ) estimates the quality of a set of similarity metrics X using a set of models M and a set of peers A. KING is defined as the probability that a model has higher QUEEN value than any peer in a test sample .</sentence>
				<definiendum id="0">measure KINGM</definiendum>
				<definiendum id="1">X )</definiendum>
				<definiens id="0">estimates the quality of a set of similarity metrics X using a set of models M and a set of peers A. KING is defined as the probability that a model has higher QUEEN value than any peer in a test sample</definiens>
			</definition>
			<definition id="2">
				<sentence>AveragedSentencelengthSim ( AVLS ) : This is a very simple metric that compares the average length of the sentences in two summaries .</sentence>
				<definiendum id="0">AveragedSentencelengthSim</definiendum>
				<definiens id="0">simple metric that compares the average length of the sentences in two summaries</definiens>
			</definition>
			<definition id="3">
				<sentence>We perform an automatic clustering process using the following notion of proximity between two metric sets : sim ( X , Xprime ) ≡ Prob [ H ( X ) ↔ H ( Xprime ) ] where H ( X ) ≡ ∀x ∈ X.x ( a , m ) ≥ x ( mprime , mprimeprime ) Two metrics sets are similar , according to the formula , if they behave similarly with respect to the QUEEN condition ( H predicate in the formula ) , i.e. the probability that the two sets of metrics discriminate the same automatic summaries when they are compared to the same pair of models .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">H predicate in the formula )</definiens>
			</definition>
			<definition id="4">
				<sentence>The JACK measure estimates the reliability of QARLA results , and is correlated with the diversity of automatic summarisation strategies included in thetestbed .</sentence>
				<definiendum id="0">JACK measure</definiendum>
				<definiens id="0">estimates the reliability of QARLA results , and is correlated with the diversity of automatic summarisation strategies included in thetestbed</definiens>
			</definition>
			<definition id="5">
				<sentence>Indeed , this is the case : the Pearson correlation between manual and QUEEN rankings is Of course , QUEEN values depend on the chosen metric set X ; it is also interesting to check whether 53 Figure 3 : JACK vs. Number of Automatic Summaries Figure 4 : QUEEN system ranking for the best metric set ( A-H are models ) Figure 5 : Correlation Between DUC and QARLA results 54 Figure 6 : QUEEN values over GRAMSIM metrics with higher KING values lead to QUEEN rankings more similar to human judgements .</sentence>
				<definiendum id="0">A-H</definiendum>
				<definiens id="0">QUEEN system ranking for the best metric set</definiens>
			</definition>
</paper>

		<paper id="0635">
			<definition id="0">
				<sentence>Content words , which add informative lexicalized information different from the head word , were detected using the heuristics of ( Surdeanu et al. , 2003 ) .</sentence>
				<definiendum id="0">Content words</definiendum>
				<definiens id="0">add informative lexicalized information different from the head word</definiens>
			</definition>
			<definition id="1">
				<sentence>We generalize syntactic paths with more than 3 elements using two templates : ( a ) Arg↑Ancestor↓Ni ↓Pred , where Arg is the argument label , Pred is the predicate label , Ancestor is the label of the common ancestor , and Ni is instantiated with all the labels between Pred and Ancestor in the full path ; and ( b ) Arg↑Ni ↑Ancestor↓Pred , where Ni is instantiated with all the labels between Arg and Ancestor in the full path .</sentence>
				<definiendum id="0">Arg</definiendum>
				<definiendum id="1">Pred</definiendum>
				<definiendum id="2">Ancestor</definiendum>
				<definiendum id="3">Ni</definiendum>
				<definiendum id="4">Ni</definiendum>
				<definiens id="0">the predicate label</definiens>
				<definiens id="1">instantiated with all the labels between Pred and Ancestor in the full path</definiens>
				<definiens id="2">instantiated with all the labels between Arg and Ancestor in the full path</definiens>
			</definition>
			<definition id="2">
				<sentence>Mihai Surdeanu is a research fellow within the Ram´on y Cajal program of the Spanish Ministry of Education and Science .</sentence>
				<definiendum id="0">Mihai Surdeanu</definiendum>
				<definiens id="0">a research fellow within the Ram´on y Cajal program of the Spanish Ministry of Education and Science</definiens>
			</definition>
</paper>

		<paper id="0636">
			<definition id="0">
				<sentence>Our approach to joint parsing and SRL begins with a base SRL system , which uses a standard architecture from the literature .</sentence>
				<definiendum id="0">SRL</definiendum>
				<definiens id="0">uses a standard architecture from the literature</definiens>
			</definition>
			<definition id="1">
				<sentence>Base features [ GJ02 ] Head word Constituent type Position Predicate Voice Head POS [ SHWA03 ] From [ PWHMJ04 ] Parent Head POS First word / POS Last word / POS Sibling constituent type / head word / head POS Conjunctions [ XP03 ] Voice &amp; Position Predicate &amp; Head word Predicate &amp; Constituent type Table 2 : Features used in baseline labeling classifier .</sentence>
				<definiendum id="0">Base features</definiendum>
				<definiens id="0">Features used in baseline labeling classifier</definiens>
			</definition>
			<definition id="2">
				<sentence>The parser is trained on sections 2– 21 of the WSJ Treebank , which does not overlap with the development or test sets .</sentence>
				<definiendum id="0">WSJ Treebank</definiendum>
				<definiens id="0">does not overlap with the development or test sets</definiens>
			</definition>
</paper>

		<paper id="0829">
			<definition id="0">
				<sentence>ISA extracts phrase pairs from a bilingual corpus without requiring the precalculated word alignment as many other phrase alignment models do .</sentence>
				<definiendum id="0">ISA</definiendum>
				<definiens id="0">extracts phrase pairs from a bilingual corpus without requiring the precalculated word alignment as many other phrase alignment models do</definiens>
			</definition>
			<definition id="1">
				<sentence>ISA segments the sentence into phrases and finds their alignment simultaneously .</sentence>
				<definiendum id="0">ISA</definiendum>
				<definiens id="0">segments the sentence into phrases and finds their alignment simultaneously</definiens>
			</definition>
			<definition id="2">
				<sentence>Test Given a bilingual corpus of language pair F ( Foreign , source language ) and E ( English , target language ) , if we know the word alignment for each sentence pair we can calculate the co-occurrence frequency for each source/target word pair type C ( f , e ) and the marginal frequency C ( f ) = summationtexte C ( f , e ) and C ( e ) = summationtextf C ( f , e ) .</sentence>
				<definiendum id="0">Test</definiendum>
				<definiens id="0">Given a bilingual corpus of language pair F ( Foreign , source language ) and E ( English , target language</definiens>
			</definition>
			<definition id="3">
				<sentence>Segmentation and Alignment The competitive linking algorithm ( CLA ) ( Melamed , 1997 ) is a greedy word alignment algorithm .</sentence>
				<definiendum id="0">Segmentation</definiendum>
				<definiens id="0">a greedy word alignment algorithm</definiens>
			</definition>
			<definition id="4">
				<sentence>Here is a description of CGA : For a sentence pair { f , e } , represent the word pair statistics for each word pair { f , e } in a two dimensional matrix LI×J , where L ( i , j ) = χ2 ( fi , ej ) in our implementation .</sentence>
				<definiendum id="0">CGA</definiendum>
				<definiens id="0">For a sentence pair { f , e }</definiens>
			</definition>
			<definition id="5">
				<sentence>1 Figure 1 : Expanding the current phrase pair Denote an aligned phrase pair { ˜f , ˜e } as a tuple [ istart , iend , jstart , jend ] where ˜f is fistart , fistart+1 , ... , fiend and similarly for ˜e .</sentence>
				<definiendum id="0">˜f</definiendum>
				<definiens id="0">Expanding the current phrase pair Denote an aligned phrase pair { ˜f , ˜e } as a tuple [ istart , iend , jstart</definiens>
			</definition>
			<definition id="6">
				<sentence>As described above , CGA is a greedy algorithm and the expansion of the seed pair restricts the possible alignments for the rest of the sentence .</sentence>
				<definiendum id="0">CGA</definiendum>
				<definiens id="0">a greedy algorithm and the expansion of the seed pair restricts the possible alignments for the rest of the sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>Then we iterate the ISA model : each sentence pair to find all possible phrase pairs .</sentence>
				<definiendum id="0">ISA model</definiendum>
			</definition>
			<definition id="8">
				<sentence>As an extension to the competitive linking algorithm which is used for word-to-word alignment , CGA overcomes the assumption of oneto-one mapping and makes it possible to align phrase 3http : //www.isi.edu/licensed-sw/pharaoh/ pairs .</sentence>
				<definiendum id="0">CGA</definiendum>
				<definiens id="0">overcomes the assumption of oneto-one mapping and makes it possible to align phrase 3http : //www.isi.edu/licensed-sw/pharaoh/ pairs</definiens>
			</definition>
</paper>

		<paper id="1613">
			<definition id="0">
				<sentence>Optimal English will arise from detecting the part of speech of any class and role names which are English words ( as well as cases such as multiple word names and roles such as “hasX” , “Xof” where X is a noun ) , and we have been able to obtain this information with reasonable quality automatically using WordNet2 .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a noun</definiens>
			</definition>
			<definition id="1">
				<sentence>but [ An Abstract Region is also a kind of Region ] [ A Temporal Region is a kind of Region . ]</sentence>
				<definiendum id="0">Abstract Region</definiendum>
				<definiendum id="1">Temporal Region</definiendum>
				<definiens id="0">a kind of Region</definiens>
			</definition>
			<definition id="2">
				<sentence>The simple inference system implements a beam search among possible sets of content for generating texts , where each state in the search space is a sequence of formulae .</sentence>
				<definiendum id="0">simple inference system</definiendum>
				<definiens id="0">implements a beam search among possible sets of content for generating texts</definiens>
			</definition>
			<definition id="3">
				<sentence>If these 4 axioms were selected unchanged and realised in this order ( which by chance happens to be quite a good order ) , then the following text would result : An Electrode is a kind of Actuality .</sentence>
				<definiendum id="0">Electrode</definiendum>
				<definiens id="0">selected unchanged and realised in this order ( which by chance happens to be quite a good order</definiens>
			</definition>
			<definition id="4">
				<sentence>The initial states are those axioms which when realised will have Electrode in subject position , with a preference for those that will be realised as “an Electrode is a ... ” .</sentence>
				<definiendum id="0">Electrode</definiendum>
				<definiens id="0">a ... ”</definiens>
			</definition>
			<definition id="5">
				<sentence>For instance , another axiom could be aggregated with this one ( to give a sentence of the form “an Electrode is an actuality which ... ” ) .</sentence>
				<definiendum id="0">Electrode</definiendum>
				<definiens id="0">an actuality which ... ” )</definiens>
			</definition>
			<definition id="6">
				<sentence>The final sequence of formulae selected is : Electrode v Actuality Electrode v = 1 contains : ( CatalystuSupport ) domain ( contains ; FuelCell t MEA t Electrode t Catalyst ) This is realised by the following short text : An Electrode is a kind of Actuality .</sentence>
				<definiendum id="0">Electrode</definiendum>
				<definiens id="0">a kind of Actuality</definiens>
			</definition>
</paper>

		<paper id="0613">
			<definition id="0">
				<sentence>SDRT provides a precise dynamic semantic interpretation for its discourse structures which augments the conventional semantic representations that are built by most grammars .</sentence>
				<definiendum id="0">SDRT</definiendum>
			</definition>
			<definition id="1">
				<sentence>The relation Elaboration ( 153 , h2 ) in Figure 2 means that the segment 154 to 155 resolves to a proposition which elaborates part of the content of the proposition 153 .</sentence>
				<definiendum id="0">relation Elaboration</definiendum>
			</definition>
			<definition id="2">
				<sentence>First , each relation node generates a rhetorical connection in the SDRS : its rst argument is the discourse referent of its parent’s head daughter , and the second is the discourse referent of the node itself ( which unless stated otherwise is its head daughter’s discourse referent ) .</sentence>
				<definiendum id="0">relation node</definiendum>
				<definiens id="0">the discourse referent of the node itself ( which unless stated otherwise is its head daughter’s discourse referent )</definiens>
			</definition>
			<definition id="3">
				<sentence>Probabilistic Context Free Grammars ( PCFGs ) determine the conditional probability of a righthand side of a rule given the left-hand side , P ( RHSjLHS ) .</sentence>
				<definiendum id="0">P ( RHSjLHS</definiendum>
				<definiens id="0">determine the conditional probability of a righthand side of a rule given the left-hand side</definiens>
			</definition>
			<definition id="4">
				<sentence>Ln ( ln ) ... L1 ( l1 ) H ( h ) R1 ( r1 ) ... Rm ( rm ) where h is the head word , H ( h ) is the label of the head constituent , P ( h ) is its parent , and Li ( li ) and Ri ( ri ) are the n left and m right modi ers , respectively .</sentence>
				<definiendum id="0">Ln</definiendum>
				<definiendum id="1">h</definiendum>
				<definiens id="0">the label of the head constituent</definiens>
				<definiens id="1">the n left and m right modi ers , respectively</definiens>
			</definition>
			<definition id="5">
				<sentence>By assuming these modi ers are generated independently of each other but are dependent on the head and its parent , the probability of such expansions can be calculated as follows ( where Ph , Pl and Pr are the probabilities for the head , leftmodi ers and right-modi ers respectively ) : P ( Ln ( ln ) . . . L1 ( l1 ) H ( h ) R1 ( r1 ) . . . Rm ( rm ) |P ( h ) ) = Ph ( H|P ( h ) ) × Y i=1 ... n+1 Pl ( Li ( li ) |P ( h ) , H ) × Y i=1 ... m+1 Pr ( Ri ( ri ) |P ( h ) , H ) This provides the simplest of models .</sentence>
				<definiendum id="0">Pr</definiendum>
				<definiendum id="1">Rm ( rm</definiendum>
				<definiendum id="2">Pl ( Li</definiendum>
				<definiens id="0">generated independently of each other but are dependent on the head and its parent , the probability of such expansions can be calculated as follows ( where Ph , Pl and</definiens>
			</definition>
			<definition id="6">
				<sentence>The word feature w in our model is the rst discourse cue phrase present in the utterance.2 In the absence of a cue phrase , w is the empty string .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">the rst discourse cue phrase present in the utterance.2 In the absence of a cue phrase</definiens>
				<definiens id="1">the empty string</definiens>
			</definition>
			<definition id="7">
				<sentence>To incorporate a larger context into the conditioning information , we also utilize a feature HCR , which encodes the child relation of a node’s head .</sentence>
				<definiendum id="0">HCR</definiendum>
				<definiens id="0">encodes the child relation of a node’s head</definiens>
			</definition>
			<definition id="8">
				<sentence>In future work , we intend to exploit an existing implementation of SDRT’s semantics ( Schlangen and Lascarides , 2002 ) , which adopts theorem proving to infer resolutions of temporal anaphora and communicative goals from SDRSs for scheduling dialogues .</sentence>
				<definiendum id="0">SDRT’s semantics</definiendum>
				<definiens id="0">adopts theorem proving to infer resolutions of temporal anaphora and communicative goals from SDRSs for scheduling dialogues</definiens>
			</definition>
</paper>

		<paper id="1303">
			<definition id="0">
				<sentence>NER is the identification of text terms referring to items of interest , and normalization is the mapping of these terms to the unique concept to which they refer .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiendum id="1">normalization</definiendum>
				<definiens id="0">the identification of text terms referring to items of interest , and</definiens>
			</definition>
			<definition id="1">
				<sentence>To accomplish this , we performed a join between the Entrez database and the MGI ( or Saccharomyces ) database using a mapping identifier between the MGI ( or SGI ) database entries and the Entrez Gene ids while extracting dictionary terms .</sentence>
				<definiendum id="0">MGI</definiendum>
				<definiens id="0">or Saccharomyces ) database using a mapping identifier between the MGI ( or SGI ) database entries and the Entrez Gene ids while extracting dictionary terms</definiens>
			</definition>
</paper>

		<paper id="0607">
			<definition id="0">
				<sentence>Burstiness is a phenomenon of content words , whereby they are likely to occur again in a text after they have occurred once .</sentence>
				<definiendum id="0">Burstiness</definiendum>
				<definiens id="0">a phenomenon of content words , whereby they are likely to occur again in a text after they have occurred once</definiens>
			</definition>
			<definition id="1">
				<sentence>Katz ( 1996 ) describes within-document burstiness as the close proximity of all or some individual instances of a word within a document exhibiting multiple occurrences .</sentence>
				<definiendum id="0">within-document burstiness</definiendum>
				<definiens id="0">the close proximity of all or some individual instances of a word within a document exhibiting multiple occurrences</definiens>
			</definition>
			<definition id="2">
				<sentence>We picked terms which had been used previously in the literature ( Church and Gale , 1995a ; Church , 2000 ; Manning 52 CU λ 1 small CU λ 1 large CU λ 2 small frequently occurring and common function word topical content word occurring in bursts CU λ 2 large comparatively frequent but wellspaced function word infrequent and scattered function word Table 1 : Heuristics for inference , based on the parameter estimates .</sentence>
				<definiendum id="0">Heuristics</definiendum>
				<definiens id="0">for inference , based on the parameter estimates</definiens>
			</definition>
			<definition id="3">
				<sentence>The top part of the table consists of the very frequently occurring function words occurring frequently throughout the corpus .</sentence>
				<definiendum id="0">top part of the table</definiendum>
				<definiens id="0">consists of the very frequently occurring function words occurring frequently throughout the corpus</definiens>
			</definition>
</paper>

		<paper id="1528">
			<definition id="0">
				<sentence>CH is the head child label , Cp the parent constituent label , wp the head word , tp the head part-ofspeech ( POS ) tag .</sentence>
				<definiendum id="0">CH</definiendum>
				<definiens id="0">the head child label</definiens>
			</definition>
			<definition id="1">
				<sentence>NPB stands for base noun phrase .</sentence>
				<definiendum id="0">NPB</definiendum>
				<definiens id="0">base noun phrase</definiens>
			</definition>
</paper>

		<paper id="0813">
			<definition id="0">
				<sentence>( SPA ) In subsentential alignment , mappings are produced from words or phrases in the source language sentence and those words or phrases in the target language sentence that best express their meaning .</sentence>
				<definiendum id="0">SPA</definiendum>
			</definition>
			<definition id="1">
				<sentence>The score of the best possible alignment is computed as follows : Let LT be the Target Language Vocabulary , s a source word , ti be target segment words , and V = fti 2fLTgji 1gthe translation word set of s , We define the translation relation probability p ( Tr ( s ) 2ft0 , t1 , ... , tkg ) as follows : for all ti 2 ft0 , t1 , ... , tkg when ftijti 2 ft0 , t1 , ... , tkggis not empty .</sentence>
				<definiendum id="0">translation relation probability p</definiendum>
				<definiens id="0">computed as follows : Let LT be the Target Language Vocabulary , s a source word , ti be target segment words , and V = fti 2fLTgji 1gthe translation word set of s</definiens>
				<definiens id="1">s ) 2ft0 , t1 , ... , tkg ) as follows : for all ti 2 ft0 , t1 , ... , tkg when ftijti 2 ft0 , t1 , ... , tkggis not empty</definiens>
			</definition>
			<definition id="2">
				<sentence>In the second , labeled “SPA ( n ) ” , a noncontiguous target alignment consisting of two contiguous segments with a gap between them was permitted in addition to contiguous target alignments .</sentence>
				<definiendum id="0">“SPA</definiendum>
				<definiens id="0">( n ) ” , a noncontiguous target alignment consisting of two contiguous segments with a gap between them was permitted in addition to contiguous target alignments</definiens>
			</definition>
</paper>

		<paper id="1529">
</paper>

		<paper id="0308">
			<definition id="0">
				<sentence>The frames have the following attributes : Direct subjective ( subjective speech event or explicit private state ) frame : • text anchor : a pointer to the span of text that represents the speech event or explicit mention of a private state .</sentence>
				<definiendum id="0">subjective</definiendum>
				<definiens id="0">a pointer to the span of text that represents the speech event or explicit mention of a private state</definiens>
			</definition>
			<definition id="1">
				<sentence>Objective speech event : Text anchor : the entire sentence Source : &lt; writer &gt; Implicit : true Objective speech event : Text anchor : said Source : &lt; writer , Xirao-Nima &gt; Direct subjective : Text anchor : fears Source : &lt; writer , Xirao-Nima , U.S. &gt; Intensity : medium Expression intensity : medium The first objective speech event frame represents that , according to the writer , it is true that Xirao-Nima uttered the quote and is a professor at the university referred to .</sentence>
				<definiendum id="0">Text anchor</definiendum>
				<definiens id="0">the entire sentence Source : &lt; writer &gt; Implicit : true Objective speech event : Text anchor : said Source : &lt; writer</definiens>
			</definition>
			<definition id="2">
				<sentence>Objective speech event : Text anchor : the entire sentence Source : &lt; writer &gt; Implicit : true Direct subjective : Text anchor : said Source : &lt; writer , Xirao-Nima &gt; Intensity : high Expression intensity : neutral Expressive subjective element : Text anchor : full of absurdities Source : &lt; writer , Xirao-Nima &gt; Intensity : high The objective frame represents that , according to the writer , it is true that Xirao-Nima uttered the quoted string .</sentence>
				<definiendum id="0">Text anchor</definiendum>
				<definiens id="0">the entire sentence Source : &lt; writer &gt; Implicit : true Direct subjective : Text anchor : said Source : &lt; writer</definiens>
				<definiens id="1">neutral Expressive subjective element : Text anchor : full of absurdities Source : &lt; writer</definiens>
			</definition>
			<definition id="3">
				<sentence>Positive Arguing : arguing for something , arguing that something is true or so , arguing that something did happen or will happen , etc. 56 ( 15 ) Iran insists 〈its nuclear program is purely for peaceful purposes〉 .</sentence>
				<definiendum id="0">Positive Arguing</definiendum>
				<definiens id="0">arguing for something , arguing that something is true or so , arguing that something did happen or will happen</definiens>
			</definition>
			<definition id="4">
				<sentence>The id slot contains a unique alpha-numeric ID for identifying the target annotation .</sentence>
				<definiendum id="0">id slot</definiendum>
			</definition>
</paper>

		<paper id="1504">
			<definition id="0">
				<sentence>Other distance measures could be substituted or added ( following the literature on heavy-shift and sentence comprehension ) , including the phonological , morphological , syntactic , or referential ( given/new ) complexity of the intervening material ( Gibson , 1998 ) .</sentence>
				<definiendum id="0">referential</definiendum>
				<definiens id="0">following the literature on heavy-shift and sentence comprehension</definiens>
			</definition>
			<definition id="1">
				<sentence>Σ is an alphabet of words .</sentence>
				<definiendum id="0">Σ</definiendum>
			</definition>
			<definition id="2">
				<sentence>2a : O ( n2 ( n + tprime ) tg2 ) , where n = |Ω| is the input length , g = maxni=1|Wi| bounds the size of a confusion set , t bounds the number of states per automaton , and tprime ≤ t bounds the number of automaton transitions from a state that emit the same word .</sentence>
				<definiendum id="0">n = |Ω|</definiendum>
				<definiens id="0">the number of states per automaton , and tprime ≤ t bounds the number of automaton transitions from a state that emit the same word</definiens>
			</definition>
			<definition id="3">
				<sentence>We trained models A–C , using unsmoothed maximum likelihood estimation , on three treebanks : the Penn ( English ) Treebank ( split in the standard way , §2–21 train/§23 test , or 950K/57K words ) , the Penn Chinese Treebank ( 80 % train/10 % test or 508K/55K words ) , and the German TIGER corpus ( 80 % /10 % or 539K/68K words ) .13 Estimation was a simple matter of counting automaton events and normalizing counts into probabilities .</sentence>
				<definiendum id="0">German TIGER corpus</definiendum>
				<definiens id="0">using unsmoothed maximum likelihood estimation , on three treebanks : the Penn ( English ) Treebank ( split in the standard way , §2–21 train/§23 test , or 950K/57K words ) , the Penn Chinese Treebank ( 80 % train/10 % test or 508K/55K words</definiens>
			</definition>
			<definition id="4">
				<sentence>The German corpus contains non-projective trees .</sentence>
				<definiendum id="0">German corpus</definiendum>
			</definition>
			<definition id="5">
				<sentence>One might informally use the term “vine grammar” ( VG ) for any generative formalism , intended for partial parsing , in which a parse is a constrained sequence of trees that cover the sentence .</sentence>
				<definiendum id="0">VG</definiendum>
				<definiens id="0">a constrained sequence of trees that cover the sentence</definiens>
			</definition>
			<definition id="6">
				<sentence>The trouble is that this linear runtime hides a constant factor , which depends on the size of the relevant part of the FSA and may be enormous for any correct FSA.19 Consider an example from Fig 1b .</sentence>
				<definiendum id="0">FSA</definiendum>
				<definiens id="0">depends on the size of the relevant part of the</definiens>
			</definition>
			<definition id="7">
				<sentence>After nondeterministically reading w1 ... w11 = According. . . insider along the correct path , the FSA state must record ( at least ) that insider has no parent yet and that R $ and Rcut are in particular states that 19The full runtime is O ( nE ) , where E is the number of FSA edges , or for a tighter estimate , the number of FSA edges that can be traversed by reading ω .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">the number of FSA edges , or for a tighter estimate , the number of FSA edges that can be traversed by reading ω</definiens>
			</definition>
</paper>

		<paper id="1306">
			<definition id="0">
				<sentence>The Medstract corpus uses multiple semantic classes , including gene , protein , cell type , and molecular process .</sentence>
				<definiendum id="0">Medstract corpus</definiendum>
				<definiens id="0">uses multiple semantic classes , including gene , protein , cell type</definiens>
			</definition>
			<definition id="1">
				<sentence>The Medstract corpus contains biomedical material not apparently related to molecular biology .</sentence>
				<definiendum id="0">Medstract corpus</definiendum>
				<definiens id="0">contains biomedical material not apparently related to molecular biology</definiens>
			</definition>
			<definition id="2">
				<sentence>40 reject this hypothesis : the Yapex corpus is one of the smallest ( a fraction of the size of the largest , and only roughly a tenth of the size of GENIA ) , but has achieved fairly wide usage .</sentence>
				<definiendum id="0">Yapex corpus</definiendum>
				<definiens id="0">one of the smallest ( a fraction of the size of the largest</definiens>
			</definition>
			<definition id="3">
				<sentence>The GENIA corpus , with its carefully curated annotation of sentence segmentation , tokenization , and part-of-speech tagging , should serve as a model for future biomedical corpora in this respect .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">with its carefully curated annotation of sentence segmentation , tokenization</definiens>
			</definition>
			<definition id="4">
				<sentence>We suspect that the level of detail of these guidelines contributed greatly to the success of some rule-based approaches to the EI task in the BioCreative competition , which utilized an early version of this corpus .</sentence>
				<definiendum id="0">competition</definiendum>
				<definiens id="0">utilized an early version of this corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>WordFreak : an open tool for linguistic annotation .</sentence>
				<definiendum id="0">WordFreak</definiendum>
			</definition>
			<definition id="6">
				<sentence>Medstract : creating large-scale information servers for biomedical libraries .</sentence>
				<definiendum id="0">Medstract</definiendum>
				<definiens id="0">creating large-scale information servers for biomedical libraries</definiens>
			</definition>
			<definition id="7">
				<sentence>MedTag : a collection of biomedical annotations .</sentence>
				<definiendum id="0">MedTag</definiendum>
			</definition>
			<definition id="8">
				<sentence>GENETAG : a tagged corpus for gene/protein named entity recognition .</sentence>
				<definiendum id="0">GENETAG</definiendum>
				<definiens id="0">a tagged corpus for gene/protein named entity recognition</definiens>
			</definition>
</paper>

		<paper id="1302">
			<definition id="0">
				<sentence>The following is an example of such a mapping , where R corresponds to p21-ras , W to p21 ( Waf ) and G to another entity ( the gene ) .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">corresponds to p21-ras , W to p21 ( Waf ) and G to another entity ( the gene )</definiens>
			</definition>
			<definition id="1">
				<sentence>Informally , a CRF bears resemblance to a Hidden Markov Model ( HMM ) in which , for each input position in a sequence , there is an observed variable and a corresponding hidden variable .</sentence>
				<definiendum id="0">CRF</definiendum>
				<definiens id="0">bears resemblance to a Hidden Markov Model ( HMM ) in which</definiens>
			</definition>
			<definition id="2">
				<sentence>CRFs are log-linear models that compute the probability of a state sequence , a11a6a13a12a15a14a16a6 a7a18a17 a6 a9a10a17a18a19a20a19a20a19a20a17 a6a18a21a23a22 , given an observed sequence , a11 a24 a12a25a14 a24 a7 a17 a24 a9 a17a18a19a20a19a20a19a20a17 a24 a21 a22 as : a26 a14a18a11a6a28a27a29a11 a24 a22a30a12 a31a32a34a33 a35a37a36a39a38a41a40 a42 a21 a43 a44a46a45 a7a48a47 a43 a49 a45 a7a51a50 a49a10a52a10a49 a14a16a6 a44a54a53 a7 a17 a6 a44 a17 a11 a24 a17a56a55 a22a58a57 where the a52a59a49 are arbitrary feature functions , the a50 a49 are the model parameters and a32a60a33 a35 is a normalization function .</sentence>
				<definiendum id="0">CRFs</definiendum>
			</definition>
			<definition id="3">
				<sentence>Training a CRF amounts to finding the a50 a49 that maximize the conditional log-likelihood of the data .</sentence>
				<definiendum id="0">CRF</definiendum>
			</definition>
			<definition id="4">
				<sentence>The inference complexity for CRFs is a82a83a14a16a6 a9 a55 a22 where a6 is the size of the vocabulary of states and a55 is the number of input positions .</sentence>
				<definiendum id="0">a55</definiendum>
				<definiens id="0">a82a83a14a16a6 a9 a55 a22 where a6 is the size of the vocabulary of states</definiens>
			</definition>
			<definition id="5">
				<sentence>A last observation is that the probability assigned to a pair of strings by the model will be reduced geometrically for longer string pairs ( since the probability is computed as a product of a55 terms , where a55 is the length of the sequence ) .</sentence>
				<definiendum id="0">a55</definiendum>
				<definiens id="0">the length of the sequence )</definiens>
			</definition>
			<definition id="6">
				<sentence>The UMLS is a taxonomy of medical and clinical concepts consisting of 1,938,701 lexical entries ( phrase strings ) where each entry belongs to one ( or , in very rarely , more than one ) of 887,688 concepts .</sentence>
				<definiendum id="0">UMLS</definiendum>
			</definition>
			<definition id="7">
				<sentence>The q-gram-Best metric simply selects the match with the lowest a5 -gram match ratio returned by the a5 -gram match procedure described Precision Recall F-measure SoftTFIDF-CRF ( a122a61a123a124 ) 0.761 0.714 0.736 SoftTFIDF-Lev ( a122a68a123a124 ) 0.742 0.697 0.718 CRF ( a122a68a123a125 ) 0.729 0.705 0.717 a126 -gram Best ( a122a68a123a127a39a128a81a124 ) 0.714 0.658 0.685 Levenstein ( a122a68a123a127 ) 0.710 0.622 0.663 TFIDF ( a122a61a123a129a39a130a81a124 ) 0.730 0.576 0.644 Table 5 : Maximum F-measure attained for each string similarity metric , with corresponding precision and recall values .</sentence>
				<definiendum id="0">q-gram-Best metric</definiendum>
				<definiendum id="1">Precision Recall F-measure SoftTFIDF-CRF</definiendum>
				<definiendum id="2">CRF</definiendum>
				<definiendum id="3">TFIDF</definiendum>
				<definiens id="0">Maximum F-measure attained for each string similarity metric , with corresponding precision and recall values</definiens>
			</definition>
			<definition id="8">
				<sentence>The SoftTFIDF-Lev model is the SoftTFIDF metric described earlier where the secondary metric for similarity between pairs of tokens is the Levenstein distance .</sentence>
				<definiendum id="0">SoftTFIDF-Lev model</definiendum>
				<definiens id="0">the SoftTFIDF metric described earlier where the secondary metric for similarity</definiens>
			</definition>
			<definition id="9">
				<sentence>signs a score of a31a68a131 a94 for each test instance where a94 is the position in the ranked list at which the correct concept is found .</sentence>
				<definiendum id="0">a94</definiendum>
				<definiens id="0">the position in the ranked list at which the correct concept is found</definiens>
			</definition>
</paper>

		<paper id="0908">
			<definition id="0">
				<sentence>The objective function to be minimized is the conditional log-likelihood L ( λ ) subject to a regularization term R ( λ ) , where T ( s ) is the set of 1000-best translations for sentence s , λ is a vector or log-parameters , and 1http : //www.fjoch.com/GIZA++.html 2http : //www.isi.edu/licensed-sw/pharaoh/ 3http : //www.speech.sri.com/projects/srilm/ 4http : //www.isi.edu/licensed-sw/carmel/ 5http : //people.csail.mit.edu/people/ koehn/publications/europarl/ 58 Table 1 : NIST , BLEU , F-scores for reranker and baseline on development set NIST BLEU F baseline 6.43 .301 .385 reranking 6.58 .298 .383 approxrand p-value &lt; .0001 .158 .424 bootstrap p-value &lt; .0001 .1 f is a vector of feature functions : L ( λ ) + R ( λ ) = −log mproductdisplay j=1 pλ ( tj|sj ) + R ( λ ) = − msummationdisplay j=1 log e λ·f ( tj ) summationtext t∈T ( sj ) eλ·f ( t ) + R ( λ ) The features employed in our experiments consist of 8 features corresponding to system components ( distortion model , language model , phrasetranslations , lexical weights , phrase penalty , word penalty ) as provided by PHARAOH , together with a multitude of overlapping phrase features .</sentence>
				<definiendum id="0">objective function to be minimized</definiendum>
				<definiens id="0">the conditional log-likelihood L ( λ ) subject to a regularization term R ( λ ) , where T ( s ) is the set of 1000-best translations for sentence s , λ is a vector or log-parameters</definiens>
				<definiens id="1">NIST , BLEU , F-scores for reranker and baseline on development set NIST BLEU F baseline 6.43 .301 .385 reranking 6.58 .298 .383 approxrand p-value &lt; .0001 .158 .424 bootstrap p-value &lt; .0001 .1 f is a vector of feature functions : L ( λ ) + R ( λ ) = −log mproductdisplay j=1 pλ ( tj|sj ) + R ( λ</definiens>
			</definition>
			<definition id="1">
				<sentence>The lscript1 regularizer is defined by the weighted lscript1-norm of the parameters R ( λ ) = γ||λ||1 = γ nsummationdisplay i=1 |λi| where γ is a regularization coefficient , and n is number of parameters .</sentence>
				<definiendum id="0">lscript1 regularizer</definiendum>
				<definiendum id="1">γ</definiendum>
				<definiens id="0">the weighted lscript1-norm of the parameters R ( λ ) = γ||λ||1 = γ nsummationdisplay i=1 |λi| where</definiens>
			</definition>
			<definition id="2">
				<sentence>BLEU weighs all n-grams equally whereas NIST puts more weight on n-grams that are more informative , i.e. , occur less frequently .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">weighs all n-grams equally whereas NIST puts more weight on n-grams that are more informative , i.e. , occur less frequently</definiens>
			</definition>
			<definition id="3">
				<sentence>The reported value is the harmonic mean of precision and recall , which is defined as ( 2× precision × recall ) / ( precision + recall ) .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">the harmonic mean of precision and</definiens>
			</definition>
			<definition id="4">
				<sentence>Significance levels are computed as the percentage of trials where the pseudo statistic , i.e. , the test statistic computed on the shuffled data , is greater than or equal to the actual statistic , i.e. , the test statistic computed on the test data .</sentence>
				<definiendum id="0">Significance levels</definiendum>
				<definiens id="0">the percentage of trials where the pseudo statistic , i.e. , the test statistic computed on the shuffled data , is greater than or equal to the actual statistic , i.e. , the test statistic computed on the test data</definiens>
			</definition>
</paper>

		<paper id="1624">
			<definition id="0">
				<sentence>We made use of an OAA monitor agent which comes with the current OAA distribution to trace all communication events within the system for logging purposes .</sentence>
				<definiendum id="0">OAA monitor agent</definiendum>
				<definiens id="0">comes with the current OAA distribution to trace all communication events within the system for logging purposes</definiens>
			</definition>
</paper>

		<paper id="0832">
			<definition id="0">
				<sentence>Each Chinese character in the source sentence is tokenized individually , and we make use of the IR engine’s phrase query feature , which matches documents in which all terms in the phrase appear in consecutive order , to create the ngrams .</sentence>
				<definiendum id="0">Chinese character</definiendum>
				<definiens id="0">matches documents in which all terms in the phrase appear in consecutive order , to create the ngrams</definiens>
			</definition>
			<definition id="1">
				<sentence>The IR engine returns a list of candidate translation pairs based on the query string , and the final stage of the TM process is the selection of a single target-language output sentence from that set .</sentence>
				<definiendum id="0">IR engine</definiendum>
				<definiens id="0">returns a list of candidate translation pairs based on the query string</definiens>
				<definiens id="1">the selection of a single target-language output sentence from that set</definiens>
			</definition>
			<definition id="2">
				<sentence>wer-g is a variation on traditional word error rate that was found to correlate very well with human judgments ( Foster et al. , 2003 ) , and per is thetraditional position-independenterrorrate that was also shown to correlate well with human judgments ( Leusch et al. , 2003 ) .</sentence>
				<definiendum id="0">wer-g</definiendum>
			</definition>
			<definition id="3">
				<sentence>tf-idf retrieval Figure 2 shows that our best performance is realized when IR queries are composed of cumulative 4-grams ( i.e. unigrams + bigrams + trigrams + 4-grams ) .</sentence>
				<definiendum id="0">IR</definiendum>
				<definiendum id="1">cumulative 4-grams</definiendum>
				<definiens id="0">unigrams + bigrams + trigrams + 4-grams )</definiens>
			</definition>
			<definition id="4">
				<sentence>Ties ( e.g. cases where a metric gave all 1000 pairs the same score ) were broken with tf-idf .</sentence>
				<definiendum id="0">Ties</definiendum>
				<definiens id="0">a metric gave all 1000 pairs the same score ) were broken with tf-idf</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>The strength of the association between the light verb and the complement noun is measured using pointwise mutual information ( PMI ) whose standard formula is given here:1 ASSOC a0 LV ; N a2a9a3 log Pra0 LVa1 Na2 Pra0 LVa2 Pra0 Na2 a10 log n f a0 LVa1 Na2 f a0 LVa2 f a0 Na2 where n is an estimate of the total number of verb and object noun pairs in the corpus .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">mutual information ( PMI ) whose standard formula is given here:1 ASSOC a0 LV ; N a2a9a3 log Pra0 LVa1 Na2 Pra0 LVa2 Pra0 Na2 a10 log n f a0 LVa1 Na2 f a0 LVa2 f a0 Na2</definiens>
				<definiens id="1">an estimate of the total number of verb and object noun pairs in the corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>40 PSpos represents the set of syntactic patterns preferred by less-compositional ( more figurative ) LVCs ( e.g. , as in ( 3a ) ) , and PSneg represents less preferred patterns ( e.g. , those in ( 3b–e ) ) .</sentence>
				<definiendum id="0">PSpos</definiendum>
				<definiendum id="1">LVCs</definiendum>
				<definiendum id="2">PSneg</definiendum>
				<definiens id="0">represents the set of syntactic patterns preferred by less-compositional ( more figurative )</definiens>
				<definiens id="1">represents less preferred patterns</definiens>
			</definition>
			<definition id="2">
				<sentence>DIFF measures the difference between the association strengths of the positive and negative pattern sets , referred to as ASSOC pos and ASSOCneg , respectively .</sentence>
				<definiendum id="0">DIFF</definiendum>
				<definiens id="0">measures the difference between the association strengths of the positive and negative pattern sets</definiens>
			</definition>
			<definition id="3">
				<sentence>We estimate this factor by f a0 PNa2a7a6 n , where n is the number of words in the corpus .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of words in the corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>PSneg consists of all patterns with at least one of these attributes having the alternative value .</sentence>
				<definiendum id="0">PSneg</definiendum>
				<definiens id="0">consists of all patterns with at least one of these attributes having the alternative value</definiens>
			</definition>
			<definition id="5">
				<sentence>The PMILVC measure is an informed baseline , since it draws on properties of LVCs .</sentence>
				<definiendum id="0">PMILVC measure</definiendum>
				<definiens id="0">an informed baseline , since it draws on properties of LVCs</definiens>
			</definition>
			<definition id="6">
				<sentence>Specifically , PMILVC measures the strength of the association between a light verb and a noun appearing in syntactic patterns preferred by LVCs , i.e. , PMILVCa3 PMI a0 LV ; N a1 PSposa2 .</sentence>
				<definiendum id="0">PMILVC</definiendum>
				<definiens id="0">measures the strength of the association between a light verb and a noun appearing in syntactic patterns preferred by LVCs</definiens>
			</definition>
			<definition id="7">
				<sentence>give 114 .37 .21m .41 ( bncDT ) take 106 .32 .30 .35 Table 7 : Correlations ( rs ; n = # of items ) between each measure and each set of human ratings ( counts from web ) .</sentence>
				<definiendum id="0">Correlations</definiendum>
				<definiens id="0"># of items ) between each measure and each set of human ratings ( counts from web )</definiens>
			</definition>
</paper>

		<paper id="0202">
			<definition id="0">
				<sentence>ILP ( Progol , Muggleton 1995 ) was chosen as a representative symbolic learning method .</sentence>
				<definiendum id="0">ILP</definiendum>
				<definiens id="0">a representative symbolic learning method</definiens>
			</definition>
			<definition id="1">
				<sentence>In Weka , Complement of Naïve Bayes ( CNBayes ) is a refinement to the selection process that Naïve Bayes makes when faced with instances where one outcome value has more training data than another .</sentence>
				<definiendum id="0">Complement of Naïve Bayes ( CNBayes )</definiendum>
				<definiens id="0">a refinement to the selection process that Naïve Bayes makes when faced with instances where one outcome value has more training data than another</definiens>
			</definition>
</paper>

		<paper id="0816">
			<definition id="0">
				<sentence>Sentence alignment means identifying which sentence in the target language ( TL ) is a translation of which one in the source language ( SL ) .</sentence>
				<definiendum id="0">Sentence alignment</definiendum>
				<definiendum id="1">TL</definiendum>
				<definiens id="0">a translation of which one in the source language ( SL )</definiens>
			</definition>
			<definition id="1">
				<sentence>Sentence alignment approaches can be categorized as based on sentence length , word correspondence , and composite ( where more than one approaches are combined ) , though other techniques , such as cog99 nate matching ( Simard et al. , 1992 ) were also tried .</sentence>
				<definiendum id="0">Sentence alignment approaches</definiendum>
				<definiens id="0">based on sentence length , word correspondence , and composite ( where more than one approaches are combined )</definiens>
			</definition>
			<definition id="2">
				<sentence>Simard and Plamondon ( Simard and Plamondon , 1998 ) used a composite method in which the rst pass does alignment at the level of characters as in ( Church , 1993 ) ( itself based on cognate matching ) and the second pass uses IBM Model-1 , following Chen ( Chen , 1993 ) .</sentence>
				<definiendum id="0">characters</definiendum>
				<definiens id="0">used a composite method in which the rst pass does alignment at the level of</definiens>
			</definition>
			<definition id="3">
				<sentence>From the syntactic point of view , Hindi is a comparatively free word order language , but with a preference for the SOV ( subject-object-verb ) order , whereas English is more of a xed word order and SVO type language .</sentence>
				<definiendum id="0">Hindi</definiendum>
				<definiens id="0">a comparatively free word order language , but with a preference for the SOV ( subject-object-verb ) order , whereas English is more of a xed word order and SVO type language</definiens>
			</definition>
			<definition id="4">
				<sentence>As Melamed states , how it will fare with languages with more word variation than English and French is an open question .</sentence>
				<definiendum id="0">French</definiendum>
				<definiens id="0">an open question</definiens>
			</definition>
			<definition id="5">
				<sentence>These measures are : • Precision ( local and global ) • Recall ( local and global ) • F-measure ( local and global ) • 95 % Con dence interval of F-measure ( global ) • Runtime ( local ) Unless sentence alignment is correct , everything else that uses aligned parallel corpora , such as word alignment ( for automatically creating bilingual dictionaries ) or statistical machine translation will be less reliable .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiendum id="1">F-measure</definiendum>
				<definiendum id="2">F-measure</definiendum>
				<definiens id="0">correct , everything else that uses aligned parallel corpora , such as word alignment ( for automatically creating bilingual dictionaries</definiens>
			</definition>
</paper>

		<paper id="1522">
			<definition id="0">
				<sentence>A guard G is a boolean expression on equations between FS paths and is equivalent to a finite set of substitutions ΣG .</sentence>
				<definiendum id="0">guard G</definiendum>
				<definiens id="0">a boolean expression on equations between FS paths</definiens>
			</definition>
</paper>

		<paper id="0905">
			<definition id="0">
				<sentence>The MMR score ScMMR ( i ) for a given sentence Si in the document is given by ScMMR ( i ) = λ ( Sim ( Si , D ) ) − ( 1−λ ) ( Sim ( Si , Summ ) ) , where D is the average document vector , Summ is the average vector from the set of sentences already selected , and λ trades off between relevance and redundancy .</sentence>
				<definiendum id="0">MMR score ScMMR</definiendum>
				<definiendum id="1">Sim</definiendum>
				<definiendum id="2">D</definiendum>
				<definiendum id="3">Summ</definiendum>
				<definiens id="0">the average vector from the set of sentences already selected , and λ trades off between relevance and redundancy</definiens>
			</definition>
			<definition id="1">
				<sentence>LSA is a vector-space approach which involves projecting the original term-document matrix to a reduced dimension representation .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">a vector-space approach which involves projecting the original term-document matrix to a reduced dimension representation</definiens>
			</definition>
			<definition id="2">
				<sentence>It is based on the singular value decomposition ( SVD ) of an m × n term-document matrix A , whose elements Aij represent the weighted term frequency of term i in document j. In SVD , the term-document matrix is decomposed as follows : A = USV T where U is an m×n matrix of left-singular vectors , S is an n × n diagonal matrix of singular values , and V is the n×n matrix of right-singular vectors .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">based on the singular value decomposition ( SVD ) of an m × n term-document matrix A , whose elements Aij represent the weighted term frequency of term i in document j. In SVD , the term-document matrix is decomposed as follows : A = USV T where U is an m×n matrix of left-singular vectors</definiens>
				<definiens id="1">an n × n diagonal matrix of singular values , and</definiens>
				<definiens id="2">the n×n matrix of right-singular vectors</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus , dimensionality reduction is no longer tied to summary length and more than one sentence per topic can be chosen .</sentence>
				<definiendum id="0">dimensionality reduction</definiendum>
				<definiens id="0">no longer tied to summary length and more than one sentence per topic can be chosen</definiens>
			</definition>
</paper>

		<paper id="0401">
			<definition id="0">
				<sentence>Tianfang Yao Hans Uszkoreit Department of Computer Science and Engineering Department of Computational Linguistics and Phonetics Shanghai Jiao Tong University Saarland University Shanghai , 200030 , China Saarbruecken , 66041 , Germany yao-tf @ cs.sjtu.edu.cn uszkoreit @ coli.uni-sb.de In this paper , a novel machine learning approach for the identification of named entity relations ( NERs ) called positive and negative case-based learning ( PNCBL ) is proposed .</sentence>
				<definiendum id="0">PNCBL</definiendum>
				<definiens id="0">the identification of named entity relations ( NERs ) called positive and negative case-based learning (</definiens>
			</definition>
			<definition id="1">
				<sentence>Definition 2 ( Relation Pattern ) : A relation pattern ( RP ) is defined as a 14-tuple : RP = ( NO , RE , SC , SGT , NE , NEC , VERB , PAR , NEP , NECP , SP , VV , NECT , VCT ) where NO represents the number of a RP ; RE is a finite set of relation expressions ; SC is a finite set for the words in the sentence group except for the words related to named entities ; SGT is a sentence group type ; NE is a finite set for named entities in the sentence group ; NEC is a finite set that embodies the context of named entities ; VERB is a finite set that includes the sequence numbers of verbs and corresponding verbs ; NEP is a finite set of named entities and their POS tags ; NECP is a finite set which contains the POS tags of the context for named entities ; SP is a finite set in which there are the sequence numbers as well as corresponding POS tags and named entity numbers in a sentence group ; VV is a finite set comprehending the posi3 tion of verbs in a sentence and its valence constraints from Lexical Sports Ontology which is developed by us ; NECT is a finite set that has the concepts of named entities in a sentence group ; and VCT is a finite set which gives the concepts of verbs in a sentence group .</sentence>
				<definiendum id="0">Definition 2 ( Relation Pattern )</definiendum>
				<definiendum id="1">RP</definiendum>
				<definiendum id="2">NO</definiendum>
				<definiendum id="3">RE</definiendum>
				<definiendum id="4">SC</definiendum>
				<definiendum id="5">SGT</definiendum>
				<definiendum id="6">; NE</definiendum>
				<definiendum id="7">NEC</definiendum>
				<definiendum id="8">VERB</definiendum>
				<definiendum id="9">NEP</definiendum>
				<definiendum id="10">NECP</definiendum>
				<definiendum id="11">SP</definiendum>
				<definiendum id="12">VV</definiendum>
				<definiendum id="13">NECT</definiendum>
				<definiendum id="14">VCT</definiendum>
				<definiens id="0">A relation pattern (</definiens>
				<definiens id="1">a 14-tuple : RP = ( NO , RE , SC , SGT , NE , NEC , VERB , PAR , NEP , NECP , SP , VV , NECT , VCT ) where</definiens>
				<definiens id="2">the number of a RP ;</definiens>
				<definiens id="3">a finite set of relation expressions ;</definiens>
				<definiens id="4">a finite set for the words in the sentence group except for the words related to named entities ;</definiens>
				<definiens id="5">a sentence group type</definiens>
				<definiens id="6">a finite set for named entities in the sentence group ;</definiens>
				<definiens id="7">a finite set that embodies the context of named entities ;</definiens>
				<definiens id="8">a finite set that includes the sequence numbers of verbs and corresponding verbs ;</definiens>
				<definiens id="9">a finite set of named entities and their POS tags ;</definiens>
				<definiens id="10">a finite set which contains the POS tags of the context for named entities ;</definiens>
				<definiens id="11">a finite set in which there are the sequence numbers as well as corresponding POS tags and named entity numbers in a sentence group ;</definiens>
				<definiens id="12">a finite set comprehending the posi3 tion of verbs in a sentence and its valence constraints from Lexical Sports Ontology which is developed by us ;</definiens>
				<definiens id="13">a finite set that has the concepts of named entities in a sentence group ; and</definiens>
			</definition>
			<definition id="2">
				<sentence>, Empty , { punc } ) } ; SGT = multi-sentences ; NE = { ( NE1-1 , 3 , LN , { ( 1 , 北京 ) } ) , ( NE1-2 , 4 , Date , { ( 1 , ３ ) , ( 2 , 月 ) , ( 3 , ２６ ) , ( 4 , 日 ) } ) , ... , ( NE2-2 , 26 , TN , { ( 1 , 广州 ) , ( 2 , 太阳神 ) , ( 3 , 队 ) } ) } ; NEC = { ( NE1-1 , 新华社 , ３ ) , ( NE1-2 , 北京 , 电 ) , ... , ( NE2-2 , 击败 , ， ) } ; VERB = { ( 8 , 进行 ) , ( 25 , 击败 ) , ... , ( 39 , 居 ) } PAR = { ( 1 , 据 ) , ( 9 , 了 ) , ... , ( 38 , 暂 ) } ; NEP = { ( NE1-1 , { ( 1 , N5 ) } ) , ( NE1-2 , { ( 1 , M ) , ( 2 , N ) , ( 3 , M ) , ( 4 , N ) } ) , ... , ( NE2-2 , { ( 1 , N5 ) , ( 2 , N ) , ( 3 , N ) } ) } ; NECP = { ( NE1-1 , N , M ) , ( NE1-2 , N5 , N ) , … , ( NE2-2 , V , W ) } ; SP = { ( 1 , P ) , ( 2 , N ) , ( 3 , NE1-1 ) , ... , ( 42 , W ) } ; VV = { ( V_8 , { Agent|fact/compete|CT , -Time|time|DT } ) , ( V_25 , { Agent|human/mass|TN , Patient|human/mass|TN } ) , ... , ( V_39 , { Agent|human/sport|PN , Agent|human/mass|TN } ) } ; NECT = { ( NE1-1 , place/capital/ProperName/China ) , ( NE1-2 , Empty+celestial/unit/time+Empty+ celestial/time/time/ morning ) , … , ( NE2-2 , place/city/ProperName/China+ Empty+community/human/mass ) } ; VCT = { ( V_8 , GoForward/GoOn/Vgoingon ) , ( V_25 , defeat ) , … , ( V_39 , reside/situated ) } Analogous to the definition of the relation pattern , a non-relation pattern is defined as follows : Definition 3 ( Non-Relation Pattern ) : A nonrelation pattern ( NRP ) is also defined as a 14-tuple : NRP = ( NO , NRE , SC , SGT , NE , NEC , VERB , PAR , NEP , NECP , SP , VV , NECT , VCT ) , where NRE is a finite set of non-relation expressions which specify the nonexistent relations in a sentence group .</sentence>
				<definiendum id="0">NRP</definiendum>
				<definiendum id="1">NRE</definiendum>
				<definiens id="0">{ punc } ) } ; SGT = multi-sentences ; NE = { ( NE1-1 , 3 , LN , { ( 1 , 北京 ) } ) , ( NE1-2 , 4 , Date , { ( 1 , ３ ) , ( 2 , 月 ) , ( 3 , ２６ ) , ( 4 , 日 ) } ) , ... , ( NE2-2 , 26 , TN , { ( 1 , 广州 ) , ( 2 , 太阳神 ) , ( 3 , 队 ) } ) } ; NEC = { ( NE1-1 , 新华社 , ３ ) , ( NE1-2 , 北京 , 电 ) , ... , ( NE2-2 , 击败 , ， ) } ; VERB = { ( 8 , 进行 ) , ( 25 , 击败 ) , ... , ( 39 , 居 ) } PAR = { ( 1 , 据 ) , ( 9 , 了 ) , ... , ( 38 , 暂 ) } ; NEP = { ( NE1-1</definiens>
				<definiens id="1">3 , N ) } ) } ; NECP = { ( NE1-1 , N , M ) , ( NE1-2 , N5 , N ) , … , ( NE2-2 , V , W ) } ; SP = { ( 1</definiens>
				<definiens id="2">3 , NE1-1 ) , ... , ( 42 , W ) } ; VV = { ( V_8 , { Agent|fact/compete|CT , -Time|time|DT } ) , ( V_25 , { Agent|human/mass|TN , Patient|human/mass|TN } ) , ... , ( V_39 , { Agent|human/sport|PN , Agent|human/mass|TN } ) } ; NECT = { ( NE1-1 , place/capital/ProperName/China ) , ( NE1-2 , Empty+celestial/unit/time+Empty+ celestial/time/time/ morning ) , … , ( NE2-2 , place/city/ProperName/China+ Empty+community/human/mass ) } ; VCT = { ( V_8 , GoForward/GoOn/Vgoingon ) , ( V_25 , defeat ) , … , ( V_39 , reside/situated ) } Analogous to the definition of the relation pattern , a non-relation pattern is defined as follows : Definition 3 ( Non-Relation Pattern ) : A nonrelation pattern (</definiens>
				<definiens id="3">a 14-tuple : NRP = ( NO , NRE , SC , SGT , NE , NEC , VERB , PAR , NEP , NECP , SP , VV , NECT , VCT ) , where</definiens>
			</definition>
			<definition id="3">
				<sentence>The average similarity for this kind of NERs is defined as follows : Σ Sim ( R ( i ) j , R ( i ) k ) 1≤ j , k ≤ m ; j ≠ k Sim average ( R ( i ) ) = ⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯ ( 1 ) Sum relation_pair ( R ( i ) j , R ( i ) k ) where Sim ( R ( i ) j , R ( i ) k ) denotes the relation similarity between the same kind of relations , R ( i ) j and 4 R ( i ) k .</sentence>
				<definiendum id="0">average similarity</definiendum>
				<definiens id="0">follows : Σ Sim ( R ( i ) j , R ( i ) k ) 1≤ j , k ≤ m ; j ≠ k Sim average ( R ( i ) ) = ⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯⎯ ( 1 ) Sum relation_pair ( R ( i ) j , R ( i ) k ) where Sim ( R ( i ) j , R ( i ) k ) denotes the relation similarity between the same kind of relations</definiens>
			</definition>
			<definition id="4">
				<sentence>( 3 ) ⎯⎯⎯ ⎯⎯ m &gt; 2 where R ( i ) is a defined relation in the NER set ( 1 ≤ i ≤ 14 ) ; n is the size of selected features , 1 ≤ s , t ≤ n ; and ( m-2 ) !</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a defined relation in the NER set ( 1 ≤ i ≤ 14 ) ;</definiens>
			</definition>
			<definition id="5">
				<sentence>Sum f is the total number of features .</sentence>
				<definiendum id="0">Sum f</definiendum>
				<definiens id="0">the total number of features</definiens>
			</definition>
			<definition id="6">
				<sentence>Definition 6 ( Individual-Character Feature ) : An Individual-Character Feature ( ICF ) means its average similarity value in a relation is less than or equal to the self-similarity of this relation .</sentence>
				<definiendum id="0">ICF</definiendum>
				<definiens id="0">An Individual-Character Feature (</definiens>
			</definition>
			<definition id="7">
				<sentence>Definition 7 ( Feature Weight ) : The weight of a selected feature ( GCF or ICF ) denotes the important degree of the feature in GCF or ICF set .</sentence>
				<definiendum id="0">Feature Weight )</definiendum>
				<definiendum id="1">ICF</definiendum>
				<definiens id="0">The weight of a selected feature ( GCF or</definiens>
				<definiens id="1">the important degree of the feature in GCF or ICF set</definiens>
			</definition>
			<definition id="8">
				<sentence>average f ( s ) ( R ( i ) ) w ( R ( i ) ) = ⎯ ⎯ ⎯⎯⎯⎯ ⎯⎯⎯ ( 5 ) n Σ Sim average f ( t ) ( R ( i ) ) t = 1 Σ Sim ( R ( i ) j , R ( i ) k ) ( f ( s ) ) 1≤ j , k ≤ m ; j ≠ k Sim average f ( s ) ( R ( i ) ) = ⎯ ⎯⎯⎯ ⎯⎯ ⎯⎯⎯⎯ ⎯ ( 6 ) Sum relation_pair ( R ( i ) j , R ( i ) k ) j , R ( i ) k ) ( f ( s ) ) computes the feature similarity of the feature f ( s ) between same kinds of relations , R ( i ) j and R ( i ) k .</sentence>
				<definiendum id="0">average f ( s )</definiendum>
				<definiendum id="1">Sim</definiendum>
				<definiendum id="2">R ( i</definiendum>
				<definiens id="0">computes the feature similarity of the feature f ( s ) between same kinds of relations</definiens>
			</definition>
			<definition id="9">
				<sentence>Definition 8 ( Identification Threshold ) : If a candidate relation is regarded as a relation in the relation pattern library , the identification threshold of this relation indicates the minimal similarity value between them .</sentence>
				<definiendum id="0">Identification Threshold )</definiendum>
			</definition>
			<definition id="10">
				<sentence>It is calculated by the average of the sum of average similarity values for selected features : n Σ Sim average f ( t ) ( R ( i ) ) t = 1 IdenThrh ( R ( i ) ) = ⎯⎯⎯ ⎯ ⎯⎯⎯⎯ ( 7 ) n where n is the size of selected features , 1 ≤ t ≤ n. Finally , the PNCBL algorithm is described as follows : 1 ) Input annotated texts ; 2 ) Transform XML format of texts into internal data format ; 3 ) Build NER and non-NER patterns ; 4 ) Store both types of patterns in hash tables and construct indexes for them ; 5 5 ) Compute the average similarity for features and self-similarity for NERs and non-NERs ; 6 ) Select GCFs and ICFs for NERs and nonNERs respectively ; 7 ) Calculate weights for selected features ; 8 ) Decide identification thresholds for every NER and non-NER ; 9 ) Store the above learning results .</sentence>
				<definiendum id="0">n Σ Sim average f</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">Compute</definiendum>
				<definiens id="0">follows : 1 ) Input annotated texts ; 2 ) Transform XML format of texts into internal data format ; 3</definiens>
				<definiens id="1">the average similarity for features and self-similarity for NERs and non-NERs ; 6 ) Select GCFs and ICFs for NERs and nonNERs respectively ; 7 ) Calculate weights for selected features ; 8 ) Decide identification thresholds for every NER and non-NER</definiens>
			</definition>
			<definition id="11">
				<sentence>The relation conflict is one of the problems , which means that contradictory NERs occur in identification results .</sentence>
				<definiendum id="0">relation conflict</definiendum>
				<definiens id="0">means that contradictory NERs occur in identification results</definiens>
			</definition>
			<definition id="12">
				<sentence>For instance , in an identification result , two NERs are : PS_ID ( ne1 , no1 ; ne2 , no2 ) and PS_TM ( ne1 , no1 ; ne3 , no3 ) In the above NER expressions , ne1 is a personal name , ne2 is a personal identity , and ne3 is a team name , because if a person occupies a position , i.e. , he / she has a corresponding identity in a sports team , that means the position or identity belongs to this sports team .</sentence>
				<definiendum id="0">ne1</definiendum>
				<definiendum id="1">ne3</definiendum>
				<definiens id="0">a personal name</definiens>
				<definiens id="1">a team name</definiens>
			</definition>
			<definition id="13">
				<sentence>It is able to adapt the variation of NER and non-NER pattern library ; ( iii ) The information provided by the relation features deals with multiple linguistic levels , depicts both NER and nonNER patterns , as well as satisfies the requirement of Chinese language processing ; ( iv ) Selfsimilarity is a reasonable measure for the concentrative degree of the same kind of NERs or nonNERs , which can be used to select generalcharacter and individual-character features for NERs and non-NERs respectively ; ( v ) The strategies used for achieving an optimal NER identification tradeoff , resolving NER conflicts , and inferring missing NERs can further improve the performance for NER identification ; ( vi ) It can be applied to sentence groups containing multiple sentences .</sentence>
				<definiendum id="0">nonNER patterns</definiendum>
				<definiendum id="1">Selfsimilarity</definiendum>
				<definiens id="0">a reasonable measure for the concentrative degree of the same kind of NERs or nonNERs , which can be used to select generalcharacter and individual-character features for NERs</definiens>
			</definition>
			<definition id="14">
				<sentence>Introduction to Machine Learning : An Early Draft of a Proposed Textbook .</sentence>
				<definiendum id="0">Learning</definiendum>
				<definiens id="0">An Early Draft of a Proposed Textbook</definiens>
			</definition>
</paper>

		<paper id="0405">
			<definition id="0">
				<sentence>A lexical chain is a sequence of lexicographically related word occurrences where every word occurs within a set distance from the previous word .</sentence>
				<definiendum id="0">lexical chain</definiendum>
			</definition>
			<definition id="1">
				<sentence>Reynar ( 1999 ) describes a maximum entropy model that combines hand selected features , including : broadcast news domain cues , number of content word bigrams , number of named entities , number of content words that are WordNet synonyms in the left and right regions , percentage of content words in the right segment that are rst uses , whether pronouns occur in the rst ve words , and whether a word frequency based algorithm predicts a boundary .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
				<definiens id="0">broadcast news domain cues , number of content word bigrams , number of named entities , number of content words that are WordNet synonyms in the left and right regions , percentage of content words in the right segment that are rst uses , whether pronouns occur in the rst ve words</definiens>
			</definition>
			<definition id="2">
				<sentence>Conversation Is this sentence part of a conversation , i.e. does this sentence contain direct speech ?</sentence>
				<definiendum id="0">Conversation</definiendum>
				<definiens id="0">Is this sentence part of a conversation</definiens>
			</definition>
</paper>

		<paper id="0301">
			<definition id="0">
				<sentence>Analysis As of this writing , the latest Pie in the Sky analysis includes : ( 1 ) argument structure of all parts of speech ( verbs , nouns , adjectives , determiners , conjunctions , etc. ) using the PropBank/NomBank/Discourse Treebank argument labels ( ARG0 , ARG1 , ARG2 , a0a1a0a2a0 ) , reminiscent of Relational Grammar of the 1970s and 1980s ( Perlmutter , 1984 ) , ( 2 ) some more speci cally labeled FrameNet ( Baker et al. , 1998 ) roles for these same constituents ; ( 3 ) morphological and part of speech features ; ( 4 ) pointers to gazetteers , both real and hypothetical ( thanks to B. Sundheim ) ; ( 5 ) Veracity/According-To features based on NYU’s proposed FactBank annotation scheme ; ( 6 ) various coreference features including some based on a proposed extension to NomBank ; ( 7 ) temporal features based on Timex2 ( Ferro et al. , 2002 ) and TimeML ( Pustejovsky et al. , 2004 ) ; and ( 8 ) Information Structure features based on ( Calhoun et al. , 2005 ) .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">verbs , nouns , adjectives , determiners , conjunctions , etc. ) using the PropBank/NomBank/Discourse Treebank argument labels ( ARG0 , ARG1 , ARG2 , a0a1a0a2a0 ) , reminiscent of Relational Grammar of the 1970s</definiens>
			</definition>
</paper>

		<paper id="0825">
			<definition id="0">
				<sentence>The y-axis is the source sentence , indexed word by word from bottom to top ; the x-axis is the target sentence , indexed word by word from left to right .</sentence>
				<definiendum id="0">x-axis</definiendum>
				<definiens id="0">the source sentence , indexed word by word from bottom to top</definiens>
				<definiens id="1">the target sentence , indexed word by word from left to right</definiens>
			</definition>
			<definition id="1">
				<sentence>Phrase extraction algorithms in general search for the left and right projected boundaries of each source phrase according to some score metric computed for the given parallel sentence pairs .</sentence>
				<definiendum id="0">Phrase extraction algorithms</definiendum>
			</definition>
			<definition id="2">
				<sentence>Thus , the probability of generating J words from the English phrase along the Viterbi path is : P ( J|eI1 ) = max { φI1 , J=summationtextIi=1 φi } IY i=1 P ( φi|ei ) ( 1 ) The Viterbi path is inferred via dynamic programming in the trellis of the lower panel in Figure 2 : φ [ j , i ] = max 8 &gt; &gt; &lt; &gt; &gt; : φ [ j , i − 1 ] + log PNULL ( 0|ei ) φ [ j − 1 , i − 1 ] + log Pφ ( 1|ei ) φ [ j − 2 , i − 1 ] + log Pφ ( 2|ei ) φ [ j − 3 , i − 1 ] + log Pφ ( 3|ei ) where PNULL ( 0|ei ) is the probability of generating a NULL word from ei ; Pφ ( k = 1|ei ) is the usual word fertility model of generating one French word from the word ei ; φ [ j , i ] is the cost so far for generating j words from i English words ei1 : e1 , ··· , ei .</sentence>
				<definiendum id="0">0|ei )</definiendum>
				<definiens id="0">the usual word fertility model of generating one French word from the word ei</definiens>
			</definition>
			<definition id="3">
				<sentence>In our algorithm , the source center circledotfj+l j of the phrase fj+lj with length l +1 is simply a normalized relative position de ned as follows : circledotfj+l j = 1|F| jprime=j+lX jprime=j jprime l + 1 ( 2 ) where |F| is the French sentence length .</sentence>
				<definiendum id="0">|F|</definiendum>
			</definition>
			<definition id="4">
				<sentence>i is the position index , which is weighted by the word level translation probabilities ; the term of PIi=1 P ( fjprime|ei ) provides a normalization so that the expected center is within the range of target sentence length .</sentence>
				<definiendum id="0">position index</definiendum>
			</definition>
</paper>

		<paper id="0511">
			<definition id="0">
				<sentence>Multiple groups describe how well their algorithm maps various test sets given various training sets , and describe a “result” to improve upon .</sentence>
				<definiendum id="0">Multiple groups</definiendum>
				<definiens id="0">describe how well their algorithm maps various test sets given various training sets</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 1 ( a ) shows the Golden Oldies model of concepts that we must abandon : a Vocabulary Acquisition Device receives a fixed hypothesis space of possible concepts completely determined by a fixed set of primitives ; Figure 1 ( b ) shows the Universal Theory Model of Concepts that we must take steps towards : A Theory Acquisition Device ( TAD ) outputs a state T∗ that describes a learners’s naive theory ; A Concept Generator G maps T∗ to a set of lexicalizable concepts G ( T∗ ) .</sentence>
				<definiendum id="0">Vocabulary Acquisition Device</definiendum>
				<definiendum id="1">Theory Acquisition Device ( TAD )</definiendum>
				<definiens id="0">receives a fixed hypothesis space of possible concepts completely determined by a fixed set of primitives</definiens>
				<definiens id="1">outputs a state T∗ that describes a learners’s naive theory ; A Concept Generator G maps T∗ to a set of lexicalizable concepts G ( T∗ )</definiens>
			</definition>
			<definition id="2">
				<sentence>The theory of the TAD states is Universal Theory ( UT ) ; a UT metalanguage enables an abstract characterization of possible theories – each possible theory describes a system of kinds , attributes , relations , partwhole relations , and causal mechanisms .</sentence>
				<definiendum id="0">UT metalanguage</definiendum>
				<definiens id="0">enables an abstract characterization of possible theories – each possible theory describes a system of kinds , attributes , relations , partwhole relations , and causal mechanisms</definiens>
			</definition>
			<definition id="3">
				<sentence>Assumption : A fixed alphabet of meaning components exists , and we know what it is A key assumption dating to the Golden Oldies is that the meaning of a sentence is adequately captured by a “logical form” ( LF ) characterized by a fixed alphabet of meaning components ( e.g. thematic roles , lexical semantic primitives , conceptual dependency primitives ) .</sentence>
				<definiendum id="0">Assumption</definiendum>
				<definiens id="0">the meaning of a sentence is adequately captured by a “logical form” ( LF ) characterized by a fixed alphabet of meaning components ( e.g. thematic roles , lexical semantic primitives , conceptual dependency primitives</definiens>
			</definition>
			<definition id="4">
				<sentence>Today’s computational linguistics program uses this assumption to demonstrate systems that answer “who did what to whom , where , why , ... ” questions , given sentences like : John saw the man with the telescope .</sentence>
				<definiendum id="0">Today’s computational linguistics program</definiendum>
				<definiens id="0">uses this assumption to demonstrate systems that answer “who did what to whom , where , why , ... ” questions , given sentences like : John saw the man with the telescope</definiens>
			</definition>
</paper>

		<paper id="0108">
			<definition id="0">
				<sentence>Moreover , CoLi offers a European Ph.D. program in Language Technology and Cognitive Systems .</sentence>
				<definiendum id="0">CoLi</definiendum>
			</definition>
</paper>

		<paper id="0632">
			<definition id="0">
				<sentence>cont POS : this is POS of the content word .</sentence>
				<definiendum id="0">cont POS</definiendum>
				<definiens id="0">this is POS of the content word</definiens>
			</definition>
</paper>

		<paper id="0703">
			<definition id="0">
				<sentence>We present MAGEAD , a morphological analyzer and generator for the Arabic language family .</sentence>
				<definiendum id="0">MAGEAD</definiendum>
				<definiens id="0">a morphological analyzer and generator for the Arabic language family</definiens>
			</definition>
			<definition id="1">
				<sentence>Modern Standard Arabic ( MSA ) is the shared written language from Morocco to the Gulf , but it is not a native language of anyone .</sentence>
				<definiendum id="0">MSA )</definiendum>
				<definiens id="0">the shared written language from Morocco to the Gulf , but it is not a native language of anyone</definiens>
			</definition>
			<definition id="2">
				<sentence>In unscripted situations where spoken MSA would normally be required ( such as talk shows on TV ) , speakers usually resort to repeated code-switching between their dialect and MSA , as nearly all native speakers of Arabic are unable to produce sustained spontaneous discourse in MSA .</sentence>
				<definiendum id="0">MSA</definiendum>
				<definiens id="0">nearly all native speakers of Arabic are unable to produce sustained spontaneous discourse in MSA</definiens>
			</definition>
			<definition id="3">
				<sentence>The root morpheme is a sequence of three , four , or five consonants ( termed radicals ) that signifies some abstract meaning shared by all its derivations .</sentence>
				<definiendum id="0">root morpheme</definiendum>
			</definition>
			<definition id="4">
				<sentence>The pattern morpheme is an abstract template in which roots and vocalisms are inserted .</sentence>
				<definiendum id="0">pattern morpheme</definiendum>
				<definiens id="0">an abstract template in which roots and vocalisms are inserted</definiens>
			</definition>
			<definition id="5">
				<sentence>Finally , an example of an orthographic rewrite rule is the deletion of the Alif ( a21 ) of the definite article morpheme Al+ ( +a34a3a21 ) in nouns when preceded by the preposition l+ ( +a11 ) ( in both of the following examples , the Alif is silent ) : ( 2 ) a. a35 a9 a7a20a36 a11 lilbayti /lilbayti/ ‘to the house’ li+ to+ Al+ the+ bayt house +i + [ genitive ] b. a35 a9 a7 a11 a7a12 biAlbayti /bilbayti/ ‘in the house’ bi+ in+ Al+ the+ bayt house +i + [ genitive ] Lexeme The type of morpheme is independent of the morphological function it is used for ( derivational or inflectional ) .</sentence>
				<definiendum id="0">Alif</definiendum>
				<definiens id="0">the deletion of the Alif ( a21 ) of the definite article morpheme Al+ ( +a34a3a21 ) in nouns when preceded by the preposition l+</definiens>
			</definition>
			<definition id="6">
				<sentence>The MBC maps the features to morphemes .</sentence>
				<definiendum id="0">MBC</definiendum>
			</definition>
			<definition id="7">
				<sentence>The CFG covers all dialects and MSA , and only when they differ in terms of the morpheme sequencing does the CFG express dialect-specific rules .</sentence>
				<definiendum id="0">CFG</definiendum>
				<definiens id="0">covers all dialects</definiens>
			</definition>
			<definition id="8">
				<sentence>We intend to evaluate MAGEAD using a double strategy : a test suite of selected surface word/analysis pairs which tests the breadth of phenomena covered , and a test corpus , which tests the adequacy on real text .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiens id="0">a test suite of selected surface word/analysis pairs which tests the breadth of phenomena covered</definiens>
				<definiens id="1">tests the adequacy on real text</definiens>
			</definition>
</paper>

		<paper id="1620">
			<definition id="0">
				<sentence>Referring Expression Generation involves deciding how each element ocurring in the input is described in the output text .</sentence>
				<definiendum id="0">Referring Expression Generation</definiendum>
				<definiens id="0">involves deciding how each element ocurring in the input is described in the output text</definiens>
			</definition>
			<definition id="1">
				<sentence>Levy uses a neural network , trained with examples of valid verse , to evaluate these drafts .</sentence>
				<definiendum id="0">Levy</definiendum>
				<definiens id="0">uses a neural network</definiens>
			</definition>
			<definition id="2">
				<sentence>cFROGS is a framework-like library of architectural classes intended to facilitate the development of NLG applications .</sentence>
				<definiendum id="0">cFROGS</definiendum>
			</definition>
</paper>

		<paper id="0102">
			<definition id="0">
				<sentence>REA is an embodied conversational agent that interacts with a user in a real estate agent domain .</sentence>
				<definiendum id="0">REA</definiendum>
				<definiens id="0">an embodied conversational agent that interacts with a user in a real estate agent domain</definiens>
			</definition>
			<definition id="1">
				<sentence>BEAT ( the behavior expression animation toolkit ) , on the other hand , is a module that fits into animation systems .</sentence>
				<definiendum id="0">BEAT</definiendum>
				<definiens id="0">the behavior expression animation toolkit ) , on the other hand , is a module that fits into animation systems</definiens>
			</definition>
			<definition id="2">
				<sentence>The system , TAGLET , is a context-free treerewriting formalism , defined by the usual complementation operation and the simplest imaginable modification operation .</sentence>
				<definiendum id="0">TAGLET</definiendum>
				<definiens id="0">a context-free treerewriting formalism , defined by the usual complementation operation and the simplest imaginable modification operation</definiens>
			</definition>
</paper>

		<paper id="1524">
			<definition id="0">
				<sentence>LCFLEX is an all-paths parser which uses left-corner prediction and ambiguity packing , and which was shown to be ef cient on other uni cation augmented context-free grammars .</sentence>
				<definiendum id="0">LCFLEX</definiendum>
				<definiens id="0">an all-paths parser which uses left-corner prediction and ambiguity packing</definiens>
			</definition>
</paper>

		<paper id="1505">
			<definition id="0">
				<sentence>In this work , we explore a corrective model which recovers non-projective dependency structures by training a classifier to select correct dependency pairs from a set of candidates based on parses generated by a constituency-based parser .</sentence>
				<definiendum id="0">corrective model</definiendum>
				<definiens id="0">recovers non-projective dependency structures by training a classifier to select correct dependency pairs from a set of candidates based on parses generated by a constituency-based parser</definiens>
			</definition>
			<definition id="1">
				<sentence>Prague Dependency Treebank A dependency tree is a set of nodes Ω= { w 0 , w 1 , ... , w k } where w 0 is the imaginary root node 2 and a set of dependency links G = { g 1 , ... , g k } where g i is an index into Ω representing the governor of w i .</sentence>
				<definiendum id="0">dependency tree</definiendum>
				<definiendum id="1">g i</definiendum>
				<definiens id="0">the imaginary root node 2 and a set of dependency links G = { g 1 , ... , g k } where</definiens>
			</definition>
			<definition id="2">
				<sentence>The rightmost tree , which is non-projective , contains a subtree consisting of w a and w c but not w b ; however , w b occurs between w a and w c in the linear ordering of the nodes .</sentence>
				<definiendum id="0">rightmost tree</definiendum>
				<definiens id="0">contains a subtree consisting of w a</definiens>
			</definition>
			<definition id="3">
				<sentence>Strict word-order languages , such as English , exhibit non-projective dependency structures in a relatively constrained set of syntactic configurations ( e.g. , right-node raising ) .</sentence>
				<definiendum id="0">Strict word-order languages</definiendum>
				<definiens id="0">such as English , exhibit non-projective dependency structures in a relatively constrained set of syntactic configurations ( e.g. , right-node raising )</definiens>
			</definition>
			<definition id="4">
				<sentence>In an attempt to extend a constituency-based parsing model to train on dependency trees , Collins transforms the PDT dependency trees into constituency trees ( Collins et al. , 1999 ) .</sentence>
				<definiendum id="0">Collins</definiendum>
			</definition>
			<definition id="5">
				<sentence>For this reason we use the MaxEnt estimator which provides us with the flexibility to incorporate interdependent features independently while still optimizing for likelihood .</sentence>
				<definiendum id="0">MaxEnt estimator</definiendum>
				<definiens id="0">provides us with the flexibility to incorporate interdependent features independently while still optimizing for likelihood</definiens>
			</definition>
			<definition id="6">
				<sentence>The maximum entropy principle states that we wish to find an estimate of p ( y|x ) ∈Cthat maximizes the entropy over a sample set X for some set of observations Y , wherex ∈ X is an observation and y ∈ Y is a outcome label assigned to that observation , H ( p ) ≡− summationdisplay x∈X , y∈Y ˜p ( x ) p ( y|x ) logp ( y|x ) The set C is the candidate set of distributions from which we wish to select p ( y|x ) .</sentence>
				<definiendum id="0">maximum entropy principle</definiendum>
				<definiendum id="1">X</definiendum>
				<definiendum id="2">Y</definiendum>
				<definiendum id="3">C</definiendum>
				<definiens id="0">states that we wish to find an estimate of p ( y|x ) ∈Cthat maximizes the entropy over a sample set X for some set of observations Y , wherex ∈</definiens>
				<definiens id="1">an observation and y ∈</definiens>
				<definiens id="2">a outcome label assigned to that observation , H ( p ) ≡− summationdisplay x∈X , y∈Y ˜p ( x ) p ( y|x ) logp ( y|x ) The set</definiens>
			</definition>
			<definition id="7">
				<sentence>Recall is the obvious counterpart to precision .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the obvious counterpart to precision</definiens>
			</definition>
</paper>

		<paper id="0305">
			<definition id="0">
				<sentence>Because the PDTB covers the same text as the Penn TreeBank WSJ corpus , syntactic and discourse annotation can be compared .</sentence>
				<definiendum id="0">PDTB</definiendum>
				<definiens id="0">covers the same text as the Penn TreeBank WSJ corpus , syntactic and discourse annotation can be compared</definiens>
			</definition>
			<definition id="1">
				<sentence>The overall goal of the Penn Discourse Treebank ( PDTB ) is to annotate the million word WSJ corpus in the Penn TreeBank ( Marcus et al. , 1993 ) with a layer of discourse annotations .</sentence>
				<definiendum id="0">TreeBank</definiendum>
				<definiens id="0">to annotate the million word WSJ corpus in the Penn</definiens>
			</definition>
			<definition id="2">
				<sentence>The PDTB builds on the DLTAG approach to discourse structure ( Webber and Joshi , 1998 ; Webber et al. , 1999 ; Webber et al. , 2003 ) in which connectives are discourse-level predicates which project predicate-argument structure on a par with verbs at 29 the sentence level .</sentence>
				<definiendum id="0">PDTB</definiendum>
				<definiens id="0">builds on the DLTAG approach to discourse structure ( Webber and Joshi , 1998 ; Webber et al. , 1999 ; Webber et al. , 2003 ) in which connectives are discourse-level predicates which project predicate-argument structure on a par with verbs at 29 the sentence level</definiens>
			</definition>
			<definition id="3">
				<sentence>Such is the case for ( 5 ) where the relation conveyed by even though , and its arguments are attributed to Dick Mayer .</sentence>
				<definiendum id="0">Such</definiendum>
				<definiens id="0">the relation conveyed by even though</definiens>
			</definition>
			<definition id="4">
				<sentence>Conjunctions in the PTB A natural question that arises with the annotation of arguments of subordinating conjunctions ( SUBCONJS ) in the PDTB is to what extent they can be detected directly from the syntactic annotation in the PTB .</sentence>
				<definiendum id="0">SUBCONJS</definiendum>
				<definiens id="0">arises with the annotation of arguments of subordinating conjunctions</definiens>
			</definition>
			<definition id="5">
				<sentence>BVD3D2D2B7BTD6CVBDB7BTD6CVBE is the lowest node with label S or SBAR such that : DC BVD3D2D2B7BTD6CVBDB7BTD6CVBE BE BTD2CRCTD7D8D3D6 D4CPD6CTD2D8B4DC BVD3D2D2B7BTD6CVBE B5 BVD3D2D2B7BTD6CVBDB7BTD6CVBE B5 has label S or SBAR , and has only two children : DC BVD3D2D2B7BTD6CVBDB7BTD6CVBE BP D4CPD6CTD2D8B4DC BVD3D2D2B7BTD6CVBDB7BTD6CVBE B5 BTD6CVBE BP DC BVD3D2D2B7BTD6CVBE A0C6 BVD3D2D2 ( tree subtraction ) BTD6CVBD BP DC BVD3D2D2B7BTD6CVBDB7BTD6CVBE A0CUDC BVD3D2D2B7BTD6CVBE CV ( tree subtraction ) The idea behind the algorithm is as follows .</sentence>
				<definiendum id="0">BVD3D2D2B7BTD6CVBDB7BTD6CVBE</definiendum>
				<definiens id="0">the lowest node with label S or SBAR such that : DC BVD3D2D2B7BTD6CVBDB7BTD6CVBE BE BTD2CRCTD7D8D3D6 D4CPD6CTD2D8B4DC BVD3D2D2B7BTD6CVBE B5 BVD3D2D2B7BTD6CVBDB7BTD6CVBE B5 has label S or SBAR , and has only two children : DC BVD3D2D2B7BTD6CVBDB7BTD6CVBE BP D4CPD6CTD2D8B4DC BVD3D2D2B7BTD6CVBDB7BTD6CVBE B5 BTD6CVBE BP DC BVD3D2D2B7BTD6CVBE A0C6 BVD3D2D2 ( tree subtraction</definiens>
			</definition>
			<definition id="6">
				<sentence>A major source of the mismatches between syntax and discourse is the effect of attribution , either that of the arguments or of the relation denoted by the connective .</sentence>
				<definiendum id="0">discourse</definiendum>
				<definiens id="0">the effect of attribution , either that of the arguments or of the relation denoted by the connective</definiens>
			</definition>
</paper>

		<paper id="1501">
			<definition id="0">
				<sentence>XLE is a large project which concentrates a lot of linguistic and computational technology , relies on a similar point of view on the balance between shallow and deep parsing , and has been successfully used to parse large unrestricted corpora .</sentence>
				<definiendum id="0">XLE</definiendum>
				<definiens id="0">a large project which concentrates a lot of linguistic and computational technology , relies on a similar point of view on the balance between shallow and deep parsing</definiens>
			</definition>
			<definition id="1">
				<sentence>5 If A is a non-terminal symbol of the backbone , A ij is an instantiated non-terminal symbol if and only if A ij + ⇒ G a i+1 ... a j where w = a 1 ... a n is the input string and + ⇒ G the transitive closure of the derives relation .</sentence>
				<definiendum id="0">ij</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the input string and + ⇒ G the transitive closure of the derives relation</definiens>
			</definition>
</paper>

		<paper id="0620">
			<definition id="0">
				<sentence>Precision ( p ) is the proportion of arguments predicted by a system which are correct .</sentence>
				<definiendum id="0">Precision ( p )</definiendum>
				<definiens id="0">the proportion of arguments predicted by a system which are correct</definiens>
			</definition>
			<definition id="1">
				<sentence>Recall ( r ) is the proportion of correct arguments which are predicted by a system .</sentence>
				<definiendum id="0">Recall ( r )</definiendum>
				<definiens id="0">the proportion of correct arguments which are predicted by a system</definiens>
			</definition>
			<definition id="2">
				<sentence>153 And CC * ( S* ( S* * ( AM-DIS* ) ( AM-DIS* ) to TO ( VP* ( S* ( S ( VP* * * ( AM-PNC* attract VB * ) * ( VP* * attract ( V* ) * younger JJR ( NP* * ( NP* * ( A1* * listeners NNS * ) * ) * ) ) ) ) * * ) * ) , , * * * * * * Radio NNP ( NP* * ( NP* ( ORG* ( A0* ( A0* Free NNP * * * * * * Europe NNP * ) * * ) * ) * ) * ) intersperses VBZ ( VP* ) * ( VP* * intersperse * ( V* ) the DT ( NP* * ( NP ( NP* * * ( A1* latest JJS * ) * * ) * * * in IN ( PP* ) * ( PP* * * * Western JJ ( NP* * ( NP* ( MISC* ) * * rock NN * * * * * * groups NNS * ) * * ) ) ) ) * * * ) .</sentence>
				<definiendum id="0">Radio NNP ( NP* *</definiendum>
				<definiendum id="1">DT</definiendum>
				<definiens id="0">NP* * ( A1* * listeners NNS * ) * ) * ) ) ) ) * * ) * ) , , * * * * * *</definiens>
				<definiens id="1">A0* Free NNP * * * * * * Europe NNP * ) * * ) * ) * ) * ) intersperses VBZ ( VP* ) *</definiens>
				<definiens id="2">* * * * * groups NNS * ) * * ) ) ) ) * * * )</definiens>
			</definition>
			<definition id="3">
				<sentence>Input consists of words ( 1st column ) , PoS tags ( 2nd ) , base chunks ( 3rd ) , clauses ( 4th ) , full syntactic tree ( 5th ) and named entities ( 6th ) .</sentence>
				<definiendum id="0">Input</definiendum>
			</definition>
			<definition id="4">
				<sentence>The data consists of sections of the Wall Street Journal part of the Penn TreeBank ( Marcus et al. , 1993 ) , with information on predicate-argument structures extracted from the PropBank corpus ( Palmer et al. , 2005 ) .</sentence>
				<definiendum id="0">data</definiendum>
			</definition>
			<definition id="5">
				<sentence>There are 13 types of adjuncts : AM-ADV : general-purpose AM-MOD : modal verb AM-CAU : cause AM-NEG : negation marker AM-DIR : direction AM-PNC : purpose AM-DIS : discourse marker AM-PRD : predication AM-EXT : extent AM-REC : reciprocal AM-LOC : location AM-TMP : temporal AM-MNR : manner In this section we describe the selected processors that computed input annotations for the SRL systems .</sentence>
				<definiendum id="0">general-purpose AM-MOD</definiendum>
				<definiens id="0">the selected processors that computed input annotations for the SRL systems</definiens>
			</definition>
			<definition id="6">
				<sentence>Regarding novel learning paradigms not applied in previous shared tasks , we find Relevant Vector Machine ( RVM ) , which is a kernel–based linear discriminant inside the framework of Sparse Bayesian Learning ( Johansson and Nugues , 2005 ) and Tree Conditional Random Fields ( T-CRF ) ( Cohn and Blunsom , 2005 ) , that extend the sequential CRF model to tree structures .</sentence>
				<definiendum id="0">RVM )</definiendum>
				<definiens id="0">a kernel–based linear discriminant inside the framework of Sparse Bayesian Learning ( Johansson and Nugues , 2005 ) and Tree Conditional Random Fields ( T-CRF )</definiens>
			</definition>
			<definition id="7">
				<sentence>synt stands for the syntactic structure explored ; pre stands for pre-processing steps ; label stands for the labeling strategy ; embed stands for the technique to ensure nonembedding of arguments ; glob stands for global optimization ; post stands for post-processing ; comb stands for system output combination , and type stands for the type of combination .</sentence>
				<definiendum id="0">synt</definiendum>
				<definiendum id="1">pre</definiendum>
				<definiendum id="2">label</definiendum>
				<definiens id="0">global optimization ; post stands for post-processing ; comb stands for system output combination , and type stands for the type of combination</definiens>
			</definition>
			<definition id="8">
				<sentence>The proposition bank : An annotated corpus of semantic roles .</sentence>
				<definiendum id="0">proposition bank</definiendum>
				<definiens id="0">An annotated corpus of semantic roles</definiens>
			</definition>
</paper>

		<paper id="0107">
			<definition id="0">
				<sentence>Northern Illinois University is a large public university ( 25,000 students ) located in the farmoriented exurbs of Chicago , about 60 miles west of the city .</sentence>
				<definiendum id="0">Northern Illinois University</definiendum>
				<definiens id="0">a large public university ( 25,000 students ) located in the farmoriented exurbs of Chicago , about 60 miles west of the city</definiens>
			</definition>
			<definition id="1">
				<sentence>Kernighan et al. choose as the preferred correction the one that maximizes P ( t|c ) P ( c ) , where t is the typo and c is a candidate correction .</sentence>
				<definiendum id="0">t</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">a candidate correction</definiens>
			</definition>
			<definition id="2">
				<sentence>They were asked to include the following information : Where the language fits in Greenberg’s classification ( SVO , etc. ) One or more syntactic phenomena that make the language interesting A grammar fragment ( a set of CFG rules , possibly with unification-based features ) illustrating one of the chosen phenomena They could show several interesting phenomena with a short implementation of one , a complex phenomenon and a longer fragment of grammar , or one interesting phenomenon and multiple ways to implement it .</sentence>
				<definiendum id="0">grammar fragment</definiendum>
				<definiens id="0">Where the language fits in Greenberg’s classification ( SVO , etc. ) One or more syntactic phenomena that make the language interesting A</definiens>
			</definition>
			<definition id="3">
				<sentence>APE uses a rule-based macro language implemented in Common Lisp .</sentence>
				<definiendum id="0">APE</definiendum>
			</definition>
</paper>

		<paper id="0509">
			<definition id="0">
				<sentence>The Maximum Entropy ( ME ) framework offers a mathematically sound way to build a probabilistic model for SOI , which combines different linguistic cues .</sentence>
				<definiendum id="0">Maximum Entropy</definiendum>
				<definiens id="0">a mathematically sound way to build a probabilistic model for SOI , which combines different linguistic cues</definiens>
			</definition>
			<definition id="1">
				<sentence>It can be proven that the probability distribution p satisfying the above assumption is the one with the highest entropy , is unique and has the following expone ntial form ( Berger et al. 1996 ) : ( 1 ) ∏ = = k j cajf jcZcap 1 ) , ( ) ( 1 ) | ( a where Z ( c ) is a normalization factor , fj ( a , c ) are the values of k features of the pair ( a , c ) and correspond to the linguistic cues of c that are relevant to predict the outcome a. Features are extracted from the training data and define the constraints that the probabilistic model p must satisfy .</sentence>
				<definiendum id="0">Z ( c )</definiendum>
				<definiendum id="1">fj</definiendum>
				<definiendum id="2">c )</definiendum>
				<definiens id="0">a normalization factor</definiens>
				<definiens id="1">c that are relevant to predict the outcome a. Features are extracted from the training data and define the constraints that the probabilistic model p must satisfy</definiens>
			</definition>
			<definition id="2">
				<sentence>The test corpus consists of 645 verb-noun pairs extracted from contexts where agreement happens to be neutralized .</sentence>
				<definiendum id="0">test corpus</definiendum>
			</definition>
			<definition id="3">
				<sentence>Quochi ( in preparation ) reports a similar distributional pattern for the caused motion and intransitive motion verbs in two Italian CHILDES corpora ( named “ItalianAntelmi” and “Italian-Calambrone” ) .</sentence>
				<definiendum id="0">Quochi</definiendum>
			</definition>
</paper>

		<paper id="1628">
			<definition id="0">
				<sentence>The transition probability is the average of the two transition weights based on bigrams and dependencies : ptr ( wi+1jw1 ) = average ( ptrngram ( wi+1jw1 ) ; ptrdep ( wi+1jw1 ) ) Before we begin the generation process , we rst use a dependency parser to parse all the sentences from the source text to 1Here the subscripts refer to the fact that this is a transition probability based on n-grams .</sentence>
				<definiendum id="0">transition probability</definiendum>
				<definiens id="0">the average of the two transition weights based on bigrams and dependencies</definiens>
				<definiens id="1">a transition probability based on n-grams</definiens>
			</definition>
			<definition id="1">
				<sentence>Computing the Dependency Transition Probability We de ne the Dependency Transition weight as : ptrdep ( wi+1jwi ) = p ( Depsym ( wi+1 ; headStack ( wi ) ) where Depsym is the symmetric relation stating that some dependency relation occurs between a word and any of the words in the stack , irrespective of which is the head .</sentence>
				<definiendum id="0">Depsym</definiendum>
				<definiens id="0">Computing the Dependency Transition Probability We de ne the Dependency Transition weight as : ptrdep ( wi+1jwi ) = p</definiens>
				<definiens id="1">the symmetric relation stating that some dependency relation occurs between a word and any of the words in the stack , irrespective of which is the head</definiens>
			</definition>
			<definition id="2">
				<sentence>For two words a and b where a precedes b in the generated string , p ( Depsym ( a ; b ) ) … Adjright ( a ; b ) + Adjleft ( b ; a ) cnt ( co-occur ( a ; b ) ) where Adjright and Adjleft are the right and left adjacency matrices .</sentence>
				<definiendum id="0">Depsym</definiendum>
				<definiens id="0">co-occur ( a ; b ) ) where Adjright and Adjleft are the right and left adjacency matrices</definiens>
			</definition>
			<definition id="3">
				<sentence>Collins’ distance heuristics [ 1996 ] weight the probability of a dependency relation between two words based on the distance between them .</sentence>
				<definiendum id="0">Collins’ distance</definiendum>
				<definiens id="0">weight the probability of a dependency relation between two words based on the distance between them</definiens>
			</definition>
</paper>

		<paper id="0709">
			<definition id="0">
				<sentence>Arabic presents an interesting challenge to natural language processing , being a highly inflected and agglutinative language .</sentence>
				<definiendum id="0">Arabic</definiendum>
				<definiens id="0">presents an interesting challenge to natural language processing , being a highly inflected and agglutinative language</definiens>
			</definition>
			<definition id="1">
				<sentence>We start by highlighting why segmentation is a necessary prerequisite for EDR , continue by presenting a finite-state statistical segmenter , and then examine how the resulting segments can be better included into a mention detection system and an entity recognition system ; both systems are statistical , build around the maximum entropy principle .</sentence>
				<definiendum id="0">segmentation</definiendum>
				<definiens id="0">included into a mention detection system and an entity recognition system ; both systems are statistical , build around the maximum entropy principle</definiens>
			</definition>
			<definition id="2">
				<sentence>Information extraction is a crucial step toward understanding and processing language .</sentence>
				<definiendum id="0">Information extraction</definiendum>
				<definiens id="0">a crucial step toward understanding and processing language</definiens>
			</definition>
			<definition id="3">
				<sentence>The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations ( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL’02 and CoNLL’03 shared tasks .</sentence>
				<definiendum id="0">EDR</definiendum>
				<definiens id="0">has close ties to the named entity recognition</definiens>
			</definition>
			<definition id="4">
				<sentence>This segmentation process consists of separating the normal whitespace delimited words into ( hypothesized ) prefixes , stems , and suffixes , which become the subject of analysis ( tokens ) .</sentence>
				<definiendum id="0">segmentation process</definiendum>
				<definiens id="0">consists of separating the normal whitespace delimited words into ( hypothesized ) prefixes , stems , and suffixes , which become the subject of analysis ( tokens )</definiens>
			</definition>
			<definition id="5">
				<sentence>The Arabic language , which is the mother tongue of more than 300 million people ( Center , 2000 ) , present significant challenges to many natural language processing applications .</sentence>
				<definiendum id="0">Arabic language</definiendum>
				<definiens id="0">the mother tongue of more than 300 million people ( Center , 2000 ) , present significant challenges to many natural language processing applications</definiens>
			</definition>
			<definition id="6">
				<sentence>Arabic is a highly inflected and derived language .</sentence>
				<definiendum id="0">Arabic</definiendum>
				<definiens id="0">a highly inflected and derived language</definiens>
			</definition>
			<definition id="7">
				<sentence>The Arabic alphabet consists of 28 letters that can be extended to ninety by additional shapes , marks , and vowels ( Tayli and AlSalamah , 1990 ) .</sentence>
				<definiendum id="0">Arabic alphabet</definiendum>
			</definition>
			<definition id="8">
				<sentence>The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model ) ( Berger et al. , 1996 ) .</sentence>
				<definiendum id="0">principle of maximum entropy</definiendum>
				<definiens id="0">states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model ) ( Berger et al. , 1996 )</definiens>
			</definition>
			<definition id="9">
				<sentence>Coreference resolution ( or entity recognition ) is defined as grouping together mentions referring to the same object or entity .</sentence>
				<definiendum id="0">Coreference resolution</definiendum>
			</definition>
			<definition id="10">
				<sentence>where mk is one mention in entity e , and the basic model building block ˆPL ( L = 1je , mk , m ) is an exponential or maximum entropy model ( Berger et al. , 1996 ) .</sentence>
				<definiendum id="0">mk</definiendum>
				<definiens id="0">an exponential or maximum entropy model</definiens>
			</definition>
			<definition id="11">
				<sentence>This is because ACE-value is a weighted metric which emphasizes on NAME mentions and heavily discounts PRONOUN mentions .</sentence>
				<definiendum id="0">ACE-value</definiendum>
			</definition>
</paper>

		<paper id="1610">
			<definition id="0">
				<sentence>SG faces the difficult problem of finding an interesting and logically coherent event sequence ( story ) .</sentence>
				<definiendum id="0">SG</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Story Generator decides • what it considers to be a minimal story [ Prince , 1973 ] , • what it considers a good story ( cf. Subsection 2.1 ) , • how to select the content that represents the story : events , participants , and their relations .</sentence>
				<definiendum id="0">Story Generator</definiendum>
			</definition>
			<definition id="2">
				<sentence>In the envisaged architecture , the document structurer receives the narrative content representation from the Story Generator .</sentence>
				<definiendum id="0">document structurer</definiendum>
				<definiens id="0">receives the narrative content representation from the Story Generator</definiens>
			</definition>
			<definition id="3">
				<sentence>Amongst others , the Narratological Structurer can perform the following tasks , some of them in interaction with the Story Generator : • modify the order of events or episodes , tag the shifted elements as flashbacks or flashforwards , and accordingly modify the discourse relations ( a Cause relation might become an Explanation relation because of the inverted event order ) ; • create ellipsis by suppressing events or episodes that the reader might as well infer ; • add or remove narrative levels ( Sections 4–6 ) ; • decide about point of view and focalization for the entire narrative or , rather , for certain episodes , and accordingly present or suppress events and relations .</sentence>
				<definiendum id="0">Narratological Structurer</definiendum>
				<definiens id="0">in interaction with the Story Generator : • modify the order of events or episodes , tag the shifted elements as flashbacks or flashforwards , and accordingly modify the discourse relations ( a Cause relation might become an Explanation relation because of the inverted event order</definiens>
			</definition>
			<definition id="4">
				<sentence>Typically , one of the Consequences of NARRATING is a change of the Addressee’s mental state : the Narrated is added to her or his knowledge .</sentence>
				<definiendum id="0">NARRATING</definiendum>
				<definiens id="0">a change of the Addressee’s mental state</definiens>
			</definition>
			<definition id="5">
				<sentence>The AbstractContent is the “abstract” output of a Story Generator ( the product of content determination ) .</sentence>
				<definiendum id="0">AbstractContent</definiendum>
				<definiens id="0">the “abstract” output of a Story Generator ( the product of content determination )</definiens>
			</definition>
			<definition id="6">
				<sentence>NARRATIVE_INSTANCE A NARRATIVE_INSTANCE is a cognitive agent that occupies the agent role ( NarrativeInstance slot ) of a NARRATING action .</sentence>
				<definiendum id="0">NARRATIVE_INSTANCE A NARRATIVE_INSTANCE</definiendum>
				<definiens id="0">a cognitive agent that occupies the agent role ( NarrativeInstance slot ) of a NARRATING action</definiens>
			</definition>
			<definition id="7">
				<sentence>DISCOURSE_SEQUENCE A DISCOURSE_SEQUENCE is an ordered list of variables standing for different NARRATIONS , as they sequentially occur within the discourse of a global narrative .</sentence>
				<definiendum id="0">DISCOURSE_SEQUENCE</definiendum>
				<definiens id="0">an ordered list of variables standing for different NARRATIONS , as they sequentially occur within the discourse of a global narrative</definiens>
			</definition>
			<definition id="8">
				<sentence>A homodiegetic narrative instance i ( = “I” ) tells outer narration a , while j ( = “Marlow” ) tells inner b : Figure 7 : Narrative levels and discourse sequence uses MessageSupport isOfTextType TextType hasForm LinguisticSurfaceForm isAbout Topic Relation Filler Restriction LinguisticSurfaceForm MsgSupport IndirectLSFFreeIndirectLSFDirectLSF Written Thought Spoken NarratedLinguisticMessage represents ( AbstractContent ) i j a b ba 1 a 2 Classes and Relations Instantiation Narration a NarrativeInstance i Attribution of NarrativeInstance toldBy ( a , i ) Attribution of Narration -Sequence discourse_sequence= [ a ] Table 5 : Zero-Instantiation of Narrative Levels Classes and Relations Instantiation Narration a , b NarrativeInstance i , j Attribution of NarrativeInstance toldBy ( a , i ) , toldBy ( b , j ) Attribution of Narration toldIn ( b , a ) Sequence discourse_sequence= [ a 1 , b , a 2 ] Table 6 : One Inner Narration ; Framing Outer Narration [ a 1 toldBy i ] – there was nothing else to do till the end of the flood ; [ ... ] we knew we were fated [ ... ] to hear about one of Marlow 's inconclusive experiences .</sentence>
				<definiendum id="0">toldBy</definiendum>
				<definiens id="0">Narrative levels and discourse sequence uses MessageSupport isOfTextType TextType hasForm LinguisticSurfaceForm isAbout Topic Relation Filler Restriction LinguisticSurfaceForm MsgSupport IndirectLSFFreeIndirectLSFDirectLSF Written Thought Spoken NarratedLinguisticMessage represents ( AbstractContent</definiens>
			</definition>
			<definition id="9">
				<sentence>Adding an Outer Narration The Story Generator creates Story A. Respecting the conditions for a Type 1 narrative , the Narratological Structurer requests an additional Story B , with some restrictions : • B is shorter than A ; • B contains a NARRATING event .</sentence>
				<definiendum id="0">Narratological Structurer</definiendum>
				<definiens id="0">requests an additional Story B , with some restrictions : • B is shorter than A ; • B contains a NARRATING event</definiens>
			</definition>
			<definition id="10">
				<sentence>The Story Generator generates Story B. This might be a minimal story consisting of the events MEETING ( of characters c 1 and c 2 ) , NARRATING ( of a story by c 1 ) , REACTION ( of c 2 ) .</sentence>
				<definiendum id="0">Story Generator</definiendum>
				<definiens id="0">generates Story B. This might be a minimal story consisting of the events MEETING ( of characters c 1 and c 2 ) , NARRATING ( of a story by c 1 )</definiens>
			</definition>
			<definition id="11">
				<sentence>The Narratological Structurer requests an additional Story B , with the following restrictions : • B is shorter than A ; • the contents of B illustrate a part of A , for example an event present in A , or a character trait of the NarrativeInstance of the NARRATING event .</sentence>
				<definiendum id="0">Narratological Structurer</definiendum>
				<definiens id="0">requests an additional Story B , with the following restrictions : • B is shorter than A</definiens>
			</definition>
			<definition id="12">
				<sentence>The Creative Process : A Computer Model of Storytelling .</sentence>
				<definiendum id="0">Creative Process</definiendum>
			</definition>
</paper>

		<paper id="0904">
			<definition id="0">
				<sentence>Their method , based on the assumption that higher classi cation accuracy in discriminating humanfrom machine-generated translations will yield closer correlation with human judgments , uses support vector machine ( SVM ) based learning to weight multiple metrics such as BLEU , NIST , and WER ( minimal word error rate ) .</sentence>
				<definiendum id="0">WER</definiendum>
				<definiens id="0">uses support vector machine ( SVM ) based learning to weight multiple metrics such as BLEU , NIST , and</definiens>
			</definition>
			<definition id="1">
				<sentence>Then for each hypothesis , the fractions of subtrees with different depths are calculated and their arithmetic mean is computed as the syntax tree based metric , which we denote as subtree metric STM : STM = 1D Dsummationdisplay n=1 summationtext t∈subtreesn ( hyp ) countclip ( t ) summationtext t∈subtreesn ( hyp ) count ( t ) where D is the maximum depth of subtrees considered , count ( t ) denotes the number of times subtree t appears in the candidate’s syntax tree , and countclip ( t ) denotes the clipped number of times t appears in the references’ syntax trees .</sentence>
				<definiendum id="0">D</definiendum>
				<definiendum id="1">countclip</definiendum>
				<definiens id="0">the fractions of subtrees with different depths are calculated and their arithmetic mean is computed as the syntax tree based metric , which we denote as subtree metric STM</definiens>
				<definiens id="1">the maximum depth of subtrees considered , count ( t ) denotes the number of times subtree t appears in the candidate’s syntax tree</definiens>
			</definition>
			<definition id="2">
				<sentence>Using H ( x ) to denote the vector of counts of all subtrees found in tree x , for two trees T1 and T2 , the inner product H ( T1 ) ·H ( T2 ) counts the number of matching pairs of subtrees of T1 and T2 .</sentence>
				<definiendum id="0">Using H ( x )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Dependency trees consist of trees of head-modi er relations with a word at each node , rather than just at the leaves .</sentence>
				<definiendum id="0">Dependency trees</definiendum>
				<definiens id="0">consist of trees of head-modi er relations with a word at each node</definiens>
			</definition>
			<definition id="4">
				<sentence>For the example of the reference syntax tree in Figure 2 , the whole tree with the root S represents a sentence ; and the subtree NP→ART N represents a noun phrase .</sentence>
				<definiendum id="0">NP→ART N</definiendum>
				<definiens id="0">a sentence ; and the subtree</definiens>
				<definiens id="1">a noun phrase</definiens>
			</definition>
			<definition id="5">
				<sentence>A headword chain is a sequence of words which corresponds to a path in the dependency tree .</sentence>
				<definiendum id="0">headword chain</definiendum>
				<definiens id="0">a sequence of words which corresponds to a path in the dependency tree</definiens>
			</definition>
</paper>

		<paper id="1523">
			<definition id="0">
				<sentence>This is done by adding two bitvectors to each edge : a negative mask ( n-mask ) , which marks positions that must not be part of the edge , and a positive mask ( p-mask ) , which marks positions that must be part of the edge .</sentence>
				<definiendum id="0">n-mask )</definiendum>
				<definiens id="0">marks positions that must be part of the edge</definiens>
			</definition>
			<definition id="1">
				<sentence>0 10000 20000 30000 40000 50000 60000 70000 3 4 5 6 7 8 9 10 11 Chart Size ( edges ) Sentence Length ( words ) Initial Medial Final Figure 3 : Average Chart Size per Sentence Length Averaging over all 150 sentences , the final grammar sees a decrease of 69.2 % in the number of chart insertion attempts compared to the initial grammar .</sentence>
				<definiendum id="0">Sentence Length</definiendum>
				<definiens id="0">Average Chart Size per Sentence Length Averaging over all 150 sentences</definiens>
			</definition>
</paper>

		<paper id="0824">
			<definition id="0">
				<sentence>We adapted an approach proposed by Cao et al. ( 2005 ) for an Information Retrieval task , and computed for any parameter ( ei , fj ) be2http : //www.nist.gov/speech/tests/mt/ mt2001/resource longing to the original model the following approximation : ˙p ( ei|fj ) ≈ summationdisplay e∈E pwn ( ei|e ) ×pn ( e|fj ) where E is the English vocabulary , pn designates the native distribution and pwn is the probability that two words in the English side are linked together .</sentence>
				<definiendum id="0">E</definiendum>
				<definiendum id="1">pwn</definiendum>
				<definiens id="0">the English vocabulary , pn designates the native distribution and</definiens>
			</definition>
</paper>

		<paper id="1602">
			<definition id="0">
				<sentence>The ontology acquisition module builds a typed hierarchy of concepts and relations derived from the WordNet and Verbnet .</sentence>
				<definiendum id="0">ontology acquisition module</definiendum>
				<definiens id="0">builds a typed hierarchy of concepts and relations derived from the WordNet and Verbnet</definiens>
			</definition>
			<definition id="1">
				<sentence>This concern underlies the research programme of the Semantic Web , which promotes the encoding in standardized forms of ontological knowledge such as KIF [ Berners-Lee et al. , 2001 ] , [ Genesereth and Fikes , 1992 ] .</sentence>
				<definiendum id="0">Semantic Web</definiendum>
				<definiens id="0">promotes the encoding in standardized forms of ontological knowledge such as KIF [ Berners-Lee et al. , 2001 ]</definiens>
			</definition>
			<definition id="2">
				<sentence>We select the CG formalism as one of the representatives of the family of knowledge encoding formalisms , which benefits from well-established inference and quantification mechanisms and standard syntax encodings in graphical and linear formats .</sentence>
				<definiendum id="0">CG formalism</definiendum>
				<definiens id="0">benefits from well-established inference and quantification mechanisms and standard syntax encodings in graphical and linear formats</definiens>
			</definition>
			<definition id="3">
				<sentence>Our work starts from several related research traditions : multilingual generation systems ; WYSIWYM systems ; knowledge and ontology editors .</sentence>
				<definiendum id="0">WYSIWYM</definiendum>
				<definiens id="0">multilingual generation systems</definiens>
			</definition>
			<definition id="4">
				<sentence>MLG systems share a common architecture consisting of the following modules : † A language-independent underlying knowledge representation : knowledge represented as AI plans [ R¨osner and Stede , 1994 ] [ Delin et al. , 1994 ] , [ Paris and Vander Linden , 1996 ] , knowledge bases ( or ontologies ) such as LOOM , the Penman Upper-model and other ( domain-specific ) concepts and instances [ R¨osner and Stede , 1994 ] .</sentence>
				<definiendum id="0">MLG systems</definiendum>
			</definition>
			<definition id="5">
				<sentence>We have chosen to use Conceptual Graphs as an interlingua for encoding document data [ Sowa , 1987 ] .</sentence>
				<definiendum id="0">Conceptual Graphs</definiendum>
			</definition>
			<definition id="6">
				<sentence>A WYSIWYM editor enables the user to edit information at the semantic level .</sentence>
				<definiendum id="0">WYSIWYM editor</definiendum>
				<definiens id="0">enables the user to edit information at the semantic level</definiens>
			</definition>
			<definition id="7">
				<sentence>The semantic level is a direct controlled feature , and all lower levels which are derived from it , are considered as presentational features .</sentence>
				<definiendum id="0">semantic level</definiendum>
				<definiens id="0">a direct controlled feature , and all lower levels which are derived from it</definiens>
			</definition>
			<definition id="8">
				<sentence>We have categorized the errors found in subjects’ documents in the following manner : † Content can be accurately expressed with SAUT ( user error ) † Content will be accurately expressed with changes in the SAUT’s lexicon and ontology ( ontology deficit ) † Content can not be expressed in the current implementation , and requires further investigation of the concept ( implementation and conceptual limitations ) Document # Accuracy User error 44 % Ontology deficit 23 % Tool limitations 33 % This breakdown indicates that the tool can be improved by investing more time in the GUI and feedback quality and by extending the ontology .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">the tool can be improved by investing more time in the GUI and feedback quality and by extending the ontology</definiens>
			</definition>
</paper>

		<paper id="1616">
</paper>

		<paper id="0627">
			<definition id="0">
				<sentence>The semantic role labeling ( SRL ) is to assign syntactic constituents with semantic roles ( arguments ) of predicates ( most frequently verbs ) in sentences .</sentence>
				<definiendum id="0">SRL</definiendum>
				<definiens id="0">to assign syntactic constituents with semantic roles ( arguments ) of predicates ( most frequently verbs ) in sentences</definiens>
			</definition>
</paper>

		<paper id="1305">
			<definition id="0">
				<sentence>The ABGene corpus consists of over 4 000 sentences annotated with gene and protein named entities .</sentence>
				<definiendum id="0">ABGene corpus</definiendum>
				<definiens id="0">consists of over 4 000 sentences annotated with gene and protein named entities</definiens>
			</definition>
			<definition id="1">
				<sentence>The MedPost corpus consists of 6 700 sentences , and is annotated with parts of speech , and gerund arguments .</sentence>
				<definiendum id="0">MedPost corpus</definiendum>
				<definiens id="0">consists of 6 700 sentences , and is annotated with parts of speech , and gerund arguments</definiens>
			</definition>
			<definition id="2">
				<sentence>The GENETAG corpus for gene/protein named entity identi cation , consists of 20 000 sentences and was used in the BioCreative 2004 Workshop ( Yeh et .</sentence>
				<definiendum id="0">GENETAG corpus</definiendum>
				<definiens id="0">for gene/protein named entity identi cation , consists of 20 000 sentences and was used in the BioCreative 2004 Workshop ( Yeh et</definiens>
			</definition>
			<definition id="3">
				<sentence>Each ANNOTATION record contains a reference to the excerpt ( by identi er and corpus ) , the character offset of the rst and last characters of the phrase being annotated ( only non-whitespace characters are counted , starting with 0 ) , and the corresponding annotation .</sentence>
				<definiendum id="0">ANNOTATION record</definiendum>
				<definiens id="0">contains a reference to the excerpt ( by identi er and corpus ) , the character offset of the rst and last characters of the phrase being annotated ( only non-whitespace characters</definiens>
			</definition>
			<definition id="4">
				<sentence>Following the table name is a series of lines with the form eld : value where eld is the name of the eld and value is the value stored in that eld .</sentence>
				<definiendum id="0">eld</definiendum>
				<definiens id="0">the value stored in that eld</definiens>
			</definition>
			<definition id="5">
				<sentence>GENETAG is a corpus of MEDLINE sentences that have been annotated with gene and protein names .</sentence>
				<definiendum id="0">GENETAG</definiendum>
				<definiens id="0">a corpus of MEDLINE sentences that have been annotated with gene and protein names</definiens>
			</definition>
			<definition id="6">
				<sentence>GENETAG-05 maintains a wide de nition of a gene/protein entity including genes , proteins , domains , sites , sequences , and elements , but excluding plasmids and vectors .</sentence>
				<definiendum id="0">GENETAG-05</definiendum>
				<definiens id="0">maintains a wide de nition of a gene/protein entity including genes , proteins , domains , sites , sequences , and elements</definiens>
			</definition>
			<definition id="7">
				<sentence>MedTag uses a common relational database format along with a web interface to facilitate annotation consistency .</sentence>
				<definiendum id="0">MedTag</definiendum>
				<definiens id="0">uses a common relational database format along with a web interface to facilitate annotation consistency</definiens>
			</definition>
</paper>

		<paper id="1622">
			<definition id="0">
				<sentence>Possibility and necessity are defined as consistency and entailment with respect to the respective conversational background : a proposition is possible if it is consistent with the relevant background , and it is necessary if it is entailed by the conversational background .</sentence>
				<definiendum id="0">Possibility</definiendum>
				<definiens id="0">necessary if it is entailed by the conversational background</definiens>
			</definition>
			<definition id="1">
				<sentence>An ordering source is a set of propositions that describes the plausibility of the states given in the primary modal domain .</sentence>
				<definiendum id="0">ordering source</definiendum>
				<definiens id="0">a set of propositions that describes the plausibility of the states given in the primary modal domain</definiens>
			</definition>
			<definition id="2">
				<sentence>Kratzer uses a modal logic to describe the meaning of modal verbs .</sentence>
				<definiendum id="0">Kratzer</definiendum>
			</definition>
			<definition id="3">
				<sentence>These approaches analyze specific uses of modals as anaphoric expressions : in some discourse segments , modals pick up modal domains introduced by previous modal expressions , and must be interpreted against this already introduced hypothetical scenario .</sentence>
				<definiendum id="0">anaphoric expressions</definiendum>
				<definiens id="0">in some discourse segments , modals pick up modal domains introduced by previous modal expressions , and must be interpreted against this already introduced hypothetical scenario</definiens>
			</definition>
			<definition id="4">
				<sentence>While modal expressions appear in all kinds of text genres produced by humans , be it newspaper articles or dialogue contributions , their realization in NLG-systems did not receive much attention so far .</sentence>
				<definiendum id="0">modal expressions</definiendum>
				<definiens id="0">appear in all kinds of text genres produced by humans , be it newspaper articles or dialogue contributions , their realization in NLG-systems did not receive much attention so far</definiens>
			</definition>
			<definition id="5">
				<sentence>A user provides the system with his/her current term number and the lectures he/she has finished so far , and the system generates a recommendation which lectures he should/must/shall/may/can take .</sentence>
				<definiendum id="0">user</definiendum>
				<definiens id="0">provides the system with his/her current term number and the lectures he/she has finished so far , and the system generates a recommendation which lectures he should/must/shall/may/can take</definiens>
			</definition>
</paper>

		<paper id="0819">
			<definition id="0">
				<sentence>The word-alignment algorithm described here is based on a hybrid – multi-feature approach , which groups Hindi words locally within a Hindi sentence and uses dictionary lookup ( DL ) as the main method of aligning words along with other methods such as Transliteration Similarity ( TS ) , Expected English Words ( EEW ) and Nearest Aligned Neighbors ( NAN ) .</sentence>
				<definiendum id="0">DL</definiendum>
				<definiens id="0">groups Hindi words locally within a Hindi sentence and uses dictionary lookup</definiens>
			</definition>
			<definition id="1">
				<sentence>According to WWW1 , the Named Entity Task is the process of annotating expressions in the text that are “unique identifiers” of entities ( e.g. Organization , Person , Location etc. ) .</sentence>
				<definiendum id="0">Named Entity Task</definiendum>
			</definition>
			<definition id="2">
				<sentence>Hindi is a partially free order language ( i.e. the order of the words in a Hindi sentence is not fixed but the order of words in a group/phrase is fixed ) .</sentence>
				<definiendum id="0">Hindi</definiendum>
				<definiens id="0">a partially free order language</definiens>
			</definition>
			<definition id="3">
				<sentence>Unlike English where the verbs are used in different inflected forms to indicate different tenses , Hindi uses one or two extra words after the verb to indicate the tense .</sentence>
				<definiendum id="0">Hindi</definiendum>
				<definiens id="0">uses one or two extra words after the verb to indicate the tense</definiens>
			</definition>
			<definition id="4">
				<sentence>Considering “customer satisfaction” and “nullाहक के फायदे ” as phrases to be aligned with each other , “के ” is the word that indicates the relation between the two words “nullाहक ” and “फायदे ” , which means the “benefits of customer” in English .</sentence>
				<definiendum id="0">“के ”</definiendum>
				<definiens id="0">the word that indicates the relation between the two words “nullाहक ” and “फायदे ” , which means the “benefits of customer” in English</definiens>
			</definition>
			<definition id="5">
				<sentence>For example : “For X” = “X के िलये ” , where “For” = “के िलये ” .</sentence>
				<definiendum id="0">“For”</definiendum>
				<definiens id="0">“For X” = “X के िलये ”</definiens>
			</definition>
			<definition id="6">
				<sentence>For aligning the word “tougher” , NAN searches for the nearest aligned word , which , in this case , is “controls” .</sentence>
				<definiendum id="0">NAN</definiendum>
				<definiens id="0">searches for the nearest aligned word</definiens>
			</definition>
</paper>

		<paper id="0615">
			<definition id="0">
				<sentence>Expectation Maximization ( EM ) ( Neal and Hinton , 1998 ) is one way to find parameter values that at least locally maximize the likelihood for models with hidden variables .</sentence>
				<definiendum id="0">Expectation Maximization</definiendum>
				<definiendum id="1">EM )</definiendum>
				<definiens id="0">one way to find parameter values that at least locally maximize the likelihood for models with hidden variables</definiens>
			</definition>
			<definition id="1">
				<sentence>The rhyme consists of a nucleus ( the vowel ) followed by an optional coda consonant or cluster .</sentence>
				<definiendum id="0">rhyme</definiendum>
				<definiens id="0">consists of a nucleus ( the vowel ) followed by an optional coda consonant or cluster</definiens>
			</definition>
			<definition id="2">
				<sentence>x.y , where Cat ∈ { Ons , Nuc , Cod } , Pos ∈ { I , M , F , O } , x is the position of a consonant within its cluster , and y is the total number of consonants in the cluster .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">the total number of consonants in the cluster</definiens>
			</definition>
			<definition id="3">
				<sentence>CELEX includes syllable boundaries , which we used for supervised training and for evaluation .</sentence>
				<definiendum id="0">CELEX</definiendum>
				<definiens id="0">includes syllable boundaries , which we used for supervised training and for evaluation</definiens>
			</definition>
</paper>

		<paper id="1209">
			<definition id="0">
				<sentence>2Finding Entailment Data In our study of the Pascal RTE development corpus , we found that a considerable majority of the TRUE pairs exhibit a stronger relationship than entailment ; namely , the hypothesis is a paraphrase of a subset of the text .</sentence>
				<definiendum id="0">hypothesis</definiendum>
				<definiens id="0">a paraphrase of a subset of the text</definiens>
			</definition>
			<definition id="1">
				<sentence>We used SVM-light ( Joachims , 202 ) as a document classifier , training it on the initial set of annotated articles .</sentence>
				<definiendum id="0">SVM-light</definiendum>
				<definiens id="0">a document classifier , training it on the initial set of annotated articles</definiens>
			</definition>
</paper>

		<paper id="0608">
			<definition id="0">
				<sentence>The VSM is a k-dimensional space Rk , in which the text tj 2 T is represented by means of the vector vectortj such that the ith component of vectortj is ti , j. The similarity among two texts in the VSM is estimated by computing the cosine .</sentence>
				<definiendum id="0">VSM</definiendum>
				<definiens id="0">a k-dimensional space Rk , in which the text tj 2 T is represented by means of the vector vectortj such that the ith component of vectortj is ti</definiens>
			</definition>
			<definition id="1">
				<sentence>A Domain Model is represented by a k kprime rectangular matrix D , containing the degree of association among terms and domains , as illustrated in Table 1 .</sentence>
				<definiendum id="0">Domain Model</definiendum>
				<definiens id="0">containing the degree of association among terms and domains</definiens>
			</definition>
			<definition id="2">
				<sentence>D is de ned by2 D ( vectortj ) = vectortj ( IIDFD ) = vectortprimej ( 1 ) where IIDF is a diagonal matrix such that iIDFi , i = IDF ( wi ) , vectortj is represented as a row vector , and IDF ( wi ) is the Inverse Document Frequency of wi .</sentence>
				<definiendum id="0">IIDF</definiendum>
				<definiendum id="1">IDF</definiendum>
				<definiens id="0">the Inverse Document Frequency of wi</definiens>
			</definition>
			<definition id="3">
				<sentence>LSA is an unsupervised technique for estimating the similarity among texts and terms in a corpus .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">an unsupervised technique for estimating the similarity among texts and terms in a corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>LSA is performed by means of a Singular Value Decomposition ( SVD ) of the term-by-document matrix T describing the corpus .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">performed by means of a Singular Value Decomposition ( SVD ) of the term-by-document matrix T describing the corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>The SVD algorithm can be exploited to acquire a domain matrix D from a large 2In ( Wong et al. , 1985 ) a similar schema is adopted to de ne a Generalized Vector Space Model , of which the Domain VSM is a particular instance .</sentence>
				<definiendum id="0">SVD algorithm</definiendum>
				<definiendum id="1">Domain VSM</definiendum>
				<definiens id="0">a particular instance</definiens>
			</definition>
			<definition id="6">
				<sentence>58 f ( x ) = nsummationdisplay i=1 λiK ( xi , x ) + λ0 ( 3 ) The kernel function K returns the similarity between two instances in the input space X , and can be designed in order to capture the relevant aspects to estimate similarity , just by taking care of satisfying set of formal requirements , as described in ( Schcurrency1olkopf and Smola , 2001 ) .</sentence>
				<definiendum id="0">kernel function K</definiendum>
				<definiens id="0">returns the similarity between two instances in the input space X , and can be designed in order to capture the relevant aspects to estimate similarity</definiens>
			</definition>
			<definition id="7">
				<sentence>The Domain Kernel is de ned by KD ( ti , tj ) = hD ( ti ) , D ( tj ) iradicalBig hD ( tj ) , D ( tj ) ihD ( ti ) , D ( ti ) i ( 4 ) where D is the Domain Mapping de ned in equation 1 .</sentence>
				<definiendum id="0">Domain Kernel</definiendum>
				<definiendum id="1">D</definiendum>
				<definiens id="0">the Domain Mapping de ned in equation 1</definiens>
			</definition>
</paper>

		<paper id="1308">
			<definition id="0">
				<sentence>The BioRAT system ( Corney , Buxton et al. 2004 ) uses manually engineered templates that combine lexical and semantic information to identify protein interactions .</sentence>
				<definiendum id="0">BioRAT system</definiendum>
				<definiens id="0">engineered templates that combine lexical and semantic information to identify protein interactions</definiens>
			</definition>
			<definition id="1">
				<sentence>Temkin ( Temkin and Gilder 2003 ) addresses the problem of extracting protein interactions by using an extendable but manually built Context Free Grammar ( CFG ) that is designed specifically for parsing biological text .</sentence>
				<definiendum id="0">Temkin</definiendum>
				<definiens id="0">the problem of extracting protein interactions by using an extendable but manually built Context Free Grammar ( CFG ) that is designed specifically for parsing biological text</definiens>
			</definition>
			<definition id="2">
				<sentence>The LG consists of set of words , each of which has various alternative linking requirements .</sentence>
				<definiendum id="0">LG</definiendum>
				<definiens id="0">consists of set of words</definiens>
			</definition>
			<definition id="3">
				<sentence>The CSP follows a verb-based approach to extract the simple clauses .</sentence>
				<definiendum id="0">CSP</definiendum>
				<definiens id="0">follows a verb-based approach to extract the simple clauses</definiens>
			</definition>
			<definition id="4">
				<sentence>GeneWays system achieves a recall of 65 % where as IntEx extracted a total of 44 interactions corresponding to a recall measure of 66 % .</sentence>
				<definiendum id="0">GeneWays system</definiendum>
				<definiens id="0">achieves a recall of 65 % where as IntEx extracted a total of 44 interactions corresponding to a recall measure of 66 %</definiens>
			</definition>
			<definition id="5">
				<sentence>`` GIS : a biomedical textmining system for gene information discovery . ''</sentence>
				<definiendum id="0">GIS</definiendum>
				<definiens id="0">a biomedical textmining system for gene information discovery</definiens>
			</definition>
			<definition id="6">
				<sentence>Genescene : biomedical text and data mining .</sentence>
				<definiendum id="0">Genescene</definiendum>
				<definiens id="0">biomedical text and data mining</definiens>
			</definition>
			<definition id="7">
				<sentence>`` MedScan , a natural language processing engine for MEDLINE abstracts . ''</sentence>
				<definiendum id="0">MedScan</definiendum>
			</definition>
</paper>

		<paper id="0806">
			<definition id="0">
				<sentence>The goal of statistical machine translation ( SMT ) is to translate a source language sequence f1 , ... , fJ into a target language sequence e1 , ... , eI by maximising the conditional probability Pr ( eI1|fJ1 ) .</sentence>
				<definiendum id="0">SMT</definiendum>
				<definiendum id="1">fJ</definiendum>
				<definiens id="0">to translate a source language sequence f1 , ... ,</definiens>
			</definition>
</paper>

		<paper id="0310">
			<definition id="0">
				<sentence>Corpus tagging is a prerequisite for many machine learning methods in NLP but has the drawbacks of high cost , inter-annotator inconsistency and the insufficient treatment of meaning .</sentence>
				<definiendum id="0">Corpus tagging</definiendum>
			</definition>
			<definition id="1">
				<sentence>Multilingual Text Corpora” project ( http : //aitc.aitcnet.org/nsf/iamtc/ ) is to create a syntactic and semantic annotation representation methodology and test it out on six languages ( English , Spanish , French , Arabic , Japanese , Korean , and Hindi ) .</sentence>
				<definiendum id="0">Hindi</definiendum>
				<definiens id="0">to create a syntactic and semantic annotation representation methodology and test it out on six languages ( English , Spanish , French , Arabic , Japanese , Korean , and</definiens>
			</definition>
			<definition id="2">
				<sentence>• An OntoSem lexicon for each language processed , which contains syntactic and semantic zones ( linked using variables ) as well as calls for procedural semantic routines when necessary .</sentence>
				<definiendum id="0">OntoSem lexicon</definiendum>
				<definiens id="0">contains syntactic and semantic zones ( linked using variables ) as well as calls for procedural semantic routines when necessary</definiens>
			</definition>
			<definition id="3">
				<sentence>• A fact repository , which contains real-world facts represented as numbered “remembered instances” of ontological concepts ( e.g. , SPEECHACT-3366 is the 3366 th instantiation of the concept SPEECH-ACT in the world model constructed during the processing of some given text ( s ) ) .</sentence>
				<definiendum id="0">fact repository</definiendum>
				<definiendum id="1">SPEECHACT-3366</definiendum>
				<definiens id="0">contains real-world facts represented as numbered “remembered instances” of ontological concepts ( e.g. ,</definiens>
			</definition>
			<definition id="4">
				<sentence>• The OntoSem syntactic-semantic analyzer , which covers preprocessing , syntactic analysis , semantic analysis , and the creation of TMRs .</sentence>
				<definiendum id="0">OntoSem syntactic-semantic analyzer</definiendum>
				<definiens id="0">covers preprocessing , syntactic analysis , semantic analysis</definiens>
			</definition>
			<definition id="5">
				<sentence>Coreference links form an additional layer of linking between instantiated concepts .</sentence>
				<definiendum id="0">Coreference links</definiendum>
			</definition>
			<definition id="6">
				<sentence>The preprocessor identifies the root word , part of speech and morphological features of each word ; recognizes sentence boundaries , named entities , dates , times and numbers ; and for named entities , determines the ontological type ( i.e. HUMAN , PLACE , ORGANIZATION , etc. ) of the entity as well as its subparts ( e.g. , the first , last , and middle names of a person ) .</sentence>
				<definiendum id="0">preprocessor</definiendum>
				<definiens id="0">identifies the root word , part of speech and morphological features of each word ; recognizes sentence boundaries , named entities , dates , times and numbers ; and for named entities , determines the ontological type ( i.e. HUMAN , PLACE , ORGANIZATION , etc. ) of the entity as well as its subparts</definiens>
			</definition>
			<definition id="7">
				<sentence>Within the OntoSem environment , there are two stages of text-meaning representations ( TMRs ) : basic and extended .</sentence>
				<definiendum id="0">TMRs )</definiendum>
				<definiens id="0">basic and extended</definiens>
			</definition>
			<definition id="8">
				<sentence>The basic TMR shows the basic ontological mappings and dependency structure , whereas the extended TMR shows the results of procedural semantics , including reference resolution , reasoning about time relations , etc .</sentence>
				<definiendum id="0">TMR</definiendum>
				<definiendum id="1">TMR</definiendum>
				<definiens id="0">shows the basic ontological mappings and dependency structure , whereas the extended</definiens>
			</definition>
			<definition id="9">
				<sentence>With the OntoSem semiautomated approach , there is far less possibility of 73 interannotator disagreement since people only correct the output of the analyzer , which is responsible for consistent and correct deployment of the large and complex static resources : if the knowledge bases are held constant , the analyzer will produce the same output every time , ensuring reproducibility of the annotation .</sentence>
				<definiendum id="0">analyzer</definiendum>
				<definiens id="0">responsible for consistent and correct deployment of the large and complex static resources : if the knowledge bases</definiens>
			</definition>
			<definition id="10">
				<sentence>TMRs are a useful medium for semantic representation in part because they can capture any content in any language , and even content not expressed in natural language .</sentence>
				<definiendum id="0">TMRs</definiendum>
				<definiens id="0">a useful medium for semantic representation in part because they can capture any content in any language , and even content not expressed in natural language</definiens>
			</definition>
			<definition id="11">
				<sentence>We fully expect that , as the actual coverage in the ontology and the lexicons and the quality of semantic analysis grows , the TMR format will be extended to accommodate these improvements .</sentence>
				<definiendum id="0">TMR format</definiendum>
				<definiens id="0">the actual coverage in the ontology and the lexicons and the quality of semantic analysis grows , the</definiens>
			</definition>
</paper>

		<paper id="0208">
			<definition id="0">
				<sentence>Contextual Inquiry is a popular method developed within the Human Computer Interaction community where the design team gathers data from end users while watching what the users do in context of their work .</sentence>
				<definiendum id="0">Contextual Inquiry</definiendum>
				<definiens id="0">a popular method developed within the Human Computer Interaction community</definiens>
			</definition>
			<definition id="1">
				<sentence>The final knowledge sources will be generated from this XML based representation .</sentence>
				<definiendum id="0">final knowledge sources</definiendum>
				<definiens id="0">this XML based representation</definiens>
			</definition>
			<definition id="2">
				<sentence>The authoring environment proper consists of two main views , namely the authoring view and tutoring view .</sentence>
				<definiendum id="0">authoring environment proper</definiendum>
				<definiens id="0">consists of two main views , namely the authoring view and tutoring view</definiens>
			</definition>
			<definition id="3">
				<sentence>50 Figure 2 : Topic Level Authoring View Authoring View : Subtopic Level While the Topic View portion of the authoring interface proper allows specification of which subtopics can occur as part of a dialogue , which are required and which are optional , and what the default ordering is , the Subtopic Level is for specification of the low level turn-by-turn details of what happens within a subtopic segment .</sentence>
				<definiendum id="0">Subtopic Level</definiendum>
				<definiens id="0">Topic Level Authoring View Authoring View : Subtopic Level While the Topic View portion of the authoring interface proper allows specification of which subtopics can occur as part of a dialogue , which are required and which are optional , and what the default ordering is , the</definiens>
			</definition>
			<definition id="4">
				<sentence>The full set of utterance types includes Open questions , Closed questions , Understanding check questions , Assertions , Commands/Requests , Acknowledgements , Acceptances , and Rejections .</sentence>
				<definiendum id="0">Closed</definiendum>
			</definition>
</paper>

		<paper id="0711">
</paper>

		<paper id="0101">
			<definition id="0">
				<sentence>The NLTK tokenizer , POS taggers and the shallow parser ( chunker ) have terrific functionality once they are understood ; some students were able to get quite accurate results using these and the supplied training sets .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">taggers and the shallow parser ( chunker ) have terrific functionality once they are understood</definiens>
			</definition>
</paper>

		<paper id="0634">
			<definition id="0">
				<sentence>The task of Semantic Role Labeling ( SRL ) involves tagging groups of words in a sentence with the semantic roles that they play with respect to a particular predicate in that sentence .</sentence>
				<definiendum id="0">SRL</definiendum>
				<definiens id="0">tagging groups of words in a sentence with the semantic roles that they play with respect to a particular predicate in that sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Using what is known as the ONE VS ALL classification strategy , n binary classifiers are trained , where n is number of semantic classes including a NULL class .</sentence>
				<definiendum id="0">the ONE VS ALL classification strategy</definiendum>
				<definiendum id="1">n binary classifiers</definiendum>
				<definiendum id="2">n</definiendum>
			</definition>
			<definition id="2">
				<sentence>SINGLE CHARACTER PHRASE TAGS : Each phrase category is clustered to a category defined by the first character of the phrase label .</sentence>
				<definiendum id="0">SINGLE CHARACTER PHRASE TAGS</definiendum>
				<definiens id="0">Each phrase category is clustered to a category defined by the first character of the phrase label</definiens>
			</definition>
			<definition id="3">
				<sentence>FEATURE CONTEXT : Features for argument bearing constituents were added as features to the constituent being classified .</sentence>
				<definiendum id="0">FEATURE CONTEXT</definiendum>
				<definiens id="0">the constituent being classified</definiens>
			</definition>
			<definition id="4">
				<sentence>CLAUSE BRACKET PATTERNS CLAUSE POSITION : A binary feature that identifies whether the token is inside or outside the clause containing the predicate HEADWORD SUFFIXES : suffixes of headwords of length 2 , 3 and 4 .</sentence>
				<definiendum id="0">CLAUSE BRACKET PATTERNS CLAUSE POSITION</definiendum>
				<definiendum id="1">HEADWORD SUFFIXES</definiendum>
				<definiens id="0">A binary feature that identifies whether the token is inside or outside the clause containing the predicate</definiens>
			</definition>
			<definition id="5">
				<sentence>LENGTH : the number of words in a token .</sentence>
				<definiendum id="0">LENGTH</definiendum>
				<definiens id="0">the number of words in a token</definiens>
			</definition>
</paper>

		<paper id="1010">
</paper>

		<paper id="1601">
			<definition id="0">
				<sentence>Given a function c ( x ) which returns the frequency count for a decision x , normalising each occurrence by the number of derivations for the sentence , the probability of a decision is obtained in the standard way ( R is the set of all decisions ) : p ( N →α ) = c ( N →α ) summationtext i : N→αi∈Rc ( N →αi ) ( 1 ) 3Also known as applying Laplace’s law .</sentence>
				<definiendum id="0">function c ( x )</definiendum>
				<definiens id="0">returns the frequency count for a decision x , normalising each occurrence by the number of derivations for the sentence , the probability of a decision is obtained in the standard way ( R is the set of all decisions ) : p ( N →α ) = c ( N →α</definiens>
			</definition>
			<definition id="1">
				<sentence>Such ‘wind statements’ look as follows ( for 10-08-01 ) : -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 11-Aug 2001 =====WARNINGS : NIL ======= WIND ( KTS ) CONFIDENCE : HIGH 10M : WNW-NW 12-15 BACKING W’LY 05-10 BY MIDNIGHT , THEN SW-SSW BY MORNING 50M : WNW-NW 15-18 BACKING W’LY 06-12 BY MIDNIGHT , THEN SW-SSW BY MORNING -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- O1 , O2 AND O3 OIL FIELDS ( EAST OF SHETLAND ) 10-08-01 10/18 WNW 11 13 17 1.7 2.7 NW 1.5 7 10/21 W 8 10 12 1.5 2.4 NW 1.4 7 11/00 W 7 8 10 1.4 2.2 NW 1.4 7 11/03 SW 7 8 10 1.4 2.2 NW 1.3 7 11/06 SW 7 8 10 1.3 2.1 NW 1.3 7 11/09 SSW 10 12 15 1.3 2.1 NW 1.2 7 11/12 S 14 17 21 1.5 2.4 NW 1.2 7 11/15 S 20 25 31 1.8 2.9 WNW 1.3 7 11/18 S 22 27 34 1.9 3.0 SW 1.5 8 11/21 S 24 30 37 2.3 3.7 S 1.7 8 12/00 S 28 35 43 3.0 4.8 S 1.9 8 12/03 S 28 35 43 3.0 4.8 S 1.9 8 12/06 SW 27 33 41 3.0 4.8 S 2.0 8 12/09 WSW 26 32 40 2.9 4.6 SSW 2.0 8 12/12 WSW 25 31 39 2.9 4.6 SW 2.0 8 12/15 WSW 25 31 39 2.9 4.6 WSW 2.0 8 12/18 WSW 24 30 37 3.1 5.0 WSW 2.1 8 12/21 SW 23 28 35 2.9 4.6 WSW 2.2 9 13/00 SW 21 26 32 2.8 4.5 WSW 2.3 9 13/03 SW 19 23 29 2.4 3.8 WSW 2.1 8 13/06 SSW 19 23 29 2.2 3.5 SW 2.0 8 13/09 SSW 20 25 31 2.2 3.5 SSW 1.9 8 13/12 SSW 21 26 32 2.4 3.8 SSW 1.8 8 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Figure 2 : Metereological data file for 10-08-01 .</sentence>
				<definiendum id="0">11-Aug 2001 =====WARNINGS</definiendum>
				<definiens id="0">for 10-08-01 ) : -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --</definiens>
			</definition>
			<definition id="2">
				<sentence>The SUMTIME Project construed the mapping from time series data to weather forecasts as two tasks [ Sripada et al. , 2003 ] : selecting a subset of the time series data to be included in the forecast , and expressing this subset of numbers as an NL forecast .</sentence>
				<definiendum id="0">SUMTIME Project</definiendum>
				<definiens id="0">construed the mapping from time series data to weather forecasts as two tasks [ Sripada et al. , 2003 ] : selecting a subset of the time series data to be included in the forecast</definiens>
			</definition>
			<definition id="3">
				<sentence>The automatic part was analysing the entire corpus with a set of simple chunking rules that split wind statements into wind direction , wind speed , gust speed , gust statements , time expressions , transition phrases ( such as and increasing ) , premodifiers ( such as less than for numbers , and mainly for wind direction ) , and post-modifiers ( e.g. in or near the low centre ) .</sentence>
				<definiendum id="0">transition phrases</definiendum>
				<definiens id="0">such as and increasing ) , premodifiers ( such as less than for numbers , and mainly for wind direction ) , and post-modifiers ( e.g. in or near the low centre )</definiens>
			</definition>
			<definition id="4">
				<sentence>The n-gram model’s bias towards shorter strings is an example of a general case : whenever the likelihood of a larger unit that can vary in length ( e.g. sentence ) is modelled in terms of the joint probability of length-invariant smaller units , larger units that are composed of fewer smaller units are more likely .</sentence>
				<definiendum id="0">n-gram model’s bias towards shorter strings</definiendum>
			</definition>
			<definition id="5">
				<sentence>Pearl : A probabilistic chart parser .</sentence>
				<definiendum id="0">Pearl</definiendum>
				<definiens id="0">A probabilistic chart parser</definiens>
			</definition>
			<definition id="6">
				<sentence>SRILM : An extensible language modeling toolkit .</sentence>
				<definiendum id="0">SRILM</definiendum>
				<definiens id="0">An extensible language modeling toolkit</definiens>
			</definition>
			<definition id="7">
				<sentence>Ultra-summarization : A statistical approach to generating highly condensed non-extractive summaries .</sentence>
				<definiendum id="0">Ultra-summarization</definiendum>
				<definiens id="0">A statistical approach to generating highly condensed non-extractive summaries</definiens>
			</definition>
</paper>

		<paper id="0601">
			<definition id="0">
				<sentence>A feature selection technique , which clusters similar features/words , called the Information Bottleneck ( IB ) , was applied to Text Categorization ( TC ) .</sentence>
				<definiendum id="0">feature selection technique</definiendum>
				<definiendum id="1">Information Bottleneck</definiendum>
				<definiens id="0">clusters similar features/words , called the</definiens>
			</definition>
			<definition id="1">
				<sentence>Among them Support Vector Machines ( SVMs ) ( Vapnik , 1995 ) are kernel based learners which achieve high accuracy in presence of many irrelevant features .</sentence>
				<definiendum id="0">Vector Machines ( SVMs )</definiendum>
				<definiens id="0">kernel based learners which achieve high accuracy in presence of many irrelevant features</definiens>
			</definition>
			<definition id="2">
				<sentence>The Wordnet noun hierarchy is a direct acyclic graph1 in which the edges establish the direct isa relations between two synsets .</sentence>
				<definiendum id="0">Wordnet noun hierarchy</definiendum>
				<definiens id="0">a direct acyclic graph1 in which the edges establish the direct isa relations between two synsets</definiens>
			</definition>
			<definition id="3">
				<sentence>On the contrary , the Conceptual Density ( CD ) ( Agirre and Rigau , 1996 ) is a flexible semantic similarity which depends on the generalizations of word senses not referring to any fixed level of the hierarchy .</sentence>
				<definiendum id="0">Conceptual Density</definiendum>
				<definiens id="0">a flexible semantic similarity which depends on the generalizations of word senses not referring to any fixed level of the hierarchy</definiens>
			</definition>
			<definition id="4">
				<sentence>The CD defines a metrics according to the topological structure of WordNet and can be seemingly applied to two or more words .</sentence>
				<definiendum id="0">CD</definiendum>
				<definiens id="0">defines a metrics according to the topological structure of WordNet and can be seemingly applied to two or more words</definiens>
			</definition>
			<definition id="5">
				<sentence>The CD of u1 and u2 is : CD ( u1 , u2 ) =    0 iff S1 ∩S2 = ∅ maxs∈S1∩S2 summationtexth i=0 ( µ ( ¯s ) ) i |¯s| otherwise ( 1 ) where : • S1∩S2 is the set of WN shared generalizations ( i.e. the common hypernyms ) of u1 and u2 • µ ( ¯s ) is the average number of children per node ( i.e. the branching factor ) in the sub-hierarchy ¯s. µ ( ¯s ) depends on WordNet and in some cases its value can approach 1 .</sentence>
				<definiendum id="0">• S1∩S2</definiendum>
				<definiens id="0">the set of WN shared generalizations ( i.e. the common hypernyms ) of u1</definiens>
				<definiens id="1">the average number of children per node ( i.e. the branching factor ) in the sub-hierarchy ¯s. µ ( ¯s ) depends on WordNet</definiens>
			</definition>
			<definition id="6">
				<sentence>Given two documents d1 and d2 ∈ D ( the documentset ) we define their similarity as : K ( d1 , d2 ) = summationdisplay w1∈d1 , w2∈d2 ( λ1λ2 ) ×σ ( w1 , w2 ) ( 3 ) where λ1 and λ2 are the weights of the words ( features ) w1 and w2 in the documents d1 and d2 , respectively and σ is a term similarity function , e.g. the conceptual density defined in Section 2 .</sentence>
				<definiendum id="0">σ</definiendum>
				<definiens id="0">the weights of the words ( features ) w1 and w2 in the documents d1 and d2 , respectively and</definiens>
			</definition>
			<definition id="7">
				<sentence>Given two objects x and y ∈ X their similarity K ( x , y ) is defined as : K ( x , y ) = summationdisplay vectorx∈R−1 ( x ) summationdisplay vectory∈R−1 ( y ) mproductdisplay i=1 Ki ( xi , yi ) ( 4 ) If X defines the document set ( i.e. D = X ) , and X1 the vocabulary of the target document corpus ( X1 = V ) , it follows that : x = d ( a document ) , vectorx = x1 = w ∈ V ( a word which is a part of the document d ) and R−1 ( d ) defines the set of words in the document d. As producttextmi=1 Ki ( xi , yi ) = K1 ( x1 , y1 ) , then K1 ( x1 , y1 ) = K ( w1 , w2 ) = ( λ1λ2 ) × σ ( w1 , w2 ) , i.e. Eq .</sentence>
				<definiendum id="0">y ∈ X their similarity K</definiendum>
				<definiendum id="1">document set</definiendum>
				<definiendum id="2">X1</definiendum>
				<definiendum id="3">d. As producttextmi=1 Ki</definiendum>
				<definiens id="0">the vocabulary of the target document corpus ( X1 = V ) , it follows that : x = d ( a document ) , vectorx = x1 = w ∈ V ( a word which is a part of the document d</definiens>
			</definition>
			<definition id="8">
				<sentence>l αhK ( dh , d ) +b ( 5 ) where , d is a classifying document and dh are all the l training instances , projected in vectorx and vectorxh respectively .</sentence>
				<definiendum id="0">d</definiendum>
				<definiens id="0">a classifying document and dh are all the l training instances , projected in vectorx and vectorxh respectively</definiens>
			</definition>
			<definition id="9">
				<sentence>Additionally , to have a uniform score across different document size , the kernel function can be normalized as follows : SK ( d1 , d2 ) √ SK ( d1 , d1 ) ·SK ( d2 , d2 ) The use of WordNet ( WN ) in the term similarity function introduces a prior knowledge whose impact on the Semantic Kernel ( SK ) should be experimentally assessed .</sentence>
				<definiendum id="0">kernel function</definiendum>
				<definiendum id="1">SK</definiendum>
			</definition>
</paper>

		<paper id="0106">
			<definition id="0">
				<sentence>Hidden Markov Models ( HMMs ) are an important part of the natural language processing toolkit and are often one of the first stochastic generation models that students1 encounter .</sentence>
				<definiendum id="0">Hidden Markov Models</definiendum>
				<definiendum id="1">HMMs )</definiendum>
				<definiens id="0">an important part of the natural language processing toolkit and are often one of the first stochastic generation models that students1 encounter</definiens>
			</definition>
</paper>

		<paper id="0826">
			<definition id="0">
				<sentence>See token descriptions : ( W ) word , ( WL ) word and lemma , ( WP ) word and PoS , ( WC ) word and chunk label , ( WPC ) word , PoS and chunk label , ( Cw ) chunk of words ( Cwl ) , chunk of words and lemmas , ( Cwp ) chunk of words and PoS ( Cwc ) chunk of words and chunk labels ( Cwpc ) chunk of words , PoS and chunk labels .</sentence>
				<definiendum id="0">See token</definiendum>
				<definiendum id="1">WL</definiendum>
				<definiendum id="2">WC</definiendum>
				<definiendum id="3">PoS</definiendum>
				<definiens id="0">) word and chunk label , ( WPC ) word , PoS and chunk label , ( Cw ) chunk of words ( Cwl ) , chunk of words and lemmas , ( Cwp ) chunk of words and PoS ( Cwc ) chunk of words and chunk labels ( Cwpc ) chunk of words ,</definiens>
			</definition>
			<definition id="1">
				<sentence>Moreover , we have used the Multilingual Central Repository ( MCR ) , a multilingual lexical-semantic database ( Atserias et al. , 2004 ) , to build a wordbased translation model .</sentence>
				<definiendum id="0">Multilingual Central Repository</definiendum>
				<definiens id="0">a multilingual lexical-semantic database ( Atserias et al. , 2004 ) , to build a wordbased translation model</definiens>
			</definition>
			<definition id="2">
				<sentence>: O ] ) Cwpc ( Fischler [ VMN : B−VP ] ) ( pronunci´o [ VMI : B−VP ] ) ( un [ DI : B−NP ] discurso [ NC : I−NP ] ) ( este [ DD : B−NP ] fin [ NC : I−NP ] ) ( de [ SP : B−PP ] ) ( semana [ NC : B−NP ] ) ( en [ SP : B−PP ] ) ( el [ DA : B−SBAR ] que [ PR0 : I−SBAR ] ) ( parec´ıa [ VMI : B−VP ] haber [ VAN : I−VP ] cambiado [ VMP : I−VP ] ) ( de [ SP : B−PP ] ) ( actitud [ NC : B−NP ] ) ( .</sentence>
				<definiendum id="0">VMI</definiendum>
				<definiendum id="1">NC : B−NP ] )</definiendum>
				<definiens id="0">B−PP ] ) ( semana [ NC : B−NP ] ) ( en [ SP : B−PP ] ) ( el [ DA : B−SBAR ] que [ PR0 : I−SBAR ] ) ( parec´ıa [</definiens>
			</definition>
</paper>

		<paper id="0604">
			<definition id="0">
				<sentence>The TOEFL consists of 300 multiple-choice question , each question involving five words : the problem or target word and four response words , one of which is a synonym of the target .</sentence>
				<definiendum id="0">TOEFL</definiendum>
				<definiens id="0">consists of 300 multiple-choice question , each question involving five words : the problem or target word and four response words , one of which is a synonym of the target</definiens>
			</definition>
			<definition id="1">
				<sentence>The word “indicted” is either an inflected verb ( so would not be used as a word in a question involving verbs ) or an uninflected adjective .</sentence>
				<definiendum id="0">word “indicted”</definiendum>
				<definiendum id="1">inflected verb</definiendum>
				<definiens id="0">a word in a question involving verbs</definiens>
			</definition>
			<definition id="2">
				<sentence>It has been shown that measures based on the pointwise mutual information ( PMI ) between question words yield good results on the TOEFL ( Turney , 2001 ; Terra and Clarke , 2003 ) .</sentence>
				<definiendum id="0">PMI</definiendum>
				<definiens id="0">shown that measures based on the pointwise mutual information</definiens>
			</definition>
			<definition id="3">
				<sentence>The product of a particular context policy is a cooccurrence matrix a0 , where the contents of a cell a0a2a1a4a3a5 is the number of times context a6 is observed to occur with word a7 .</sentence>
				<definiendum id="0">a0a2a1a4a3a5</definiendum>
				<definiens id="0">a cooccurrence matrix a0 , where the contents of a cell</definiens>
				<definiens id="1">the number of times context a6 is observed to occur with word a7</definiens>
			</definition>
			<definition id="4">
				<sentence>For a48 a49 a1a51a50a23a52a54a53a19a5 and word-conditional context distributions a55 and a56 , we have the so-called a48 -divergences ( Zhu and Rohwer , 1998 ) : a57 a58 a1a59a55a60a52a61a56a4a5a63a62a59a64 a53a65a14 a7 a55 a58 a56 a11a38a66 a58 a48a67a1a45a53a18a14a16a48a42a5 ( 1 ) Divergences a57 a68 and a57 a11 are defined as limits as a48a6a69 a50 and a48a6a69a70a53 : a57 a11 a1a59a55a60a52a61a56a4a5a71a64 a57 a68 a1a51a56a67a52a51a55a72a5a71a64a74a73 a55a76a75a78a77a47a79 a55 a56 In other words , a57 a11a19a1a59a55a60a52a61a56a4a5 is the KL-divergence of a55 from a56 .</sentence>
				<definiendum id="0">a57 a11a19a1a59a55a60a52a61a56a4a5</definiendum>
				<definiens id="0">the so-called a48 -divergences ( Zhu and Rohwer , 1998 ) : a57 a58 a1a59a55a60a52a61a56a4a5a63a62a59a64 a53a65a14 a7 a55 a58 a56 a11a38a66 a58 a48a67a1a45a53a18a14a16a48a42a5 ( 1 ) Divergences a57 a68 and a57 a11 are defined as limits as a48a6a69 a50 and a48a6a69a70a53 : a57 a11 a1a59a55a60a52a61a56a4a5a71a64 a57 a68 a1a51a56a67a52a51a55a72a5a71a64a74a73 a55a76a75a78a77a47a79 a55 a56 In other words ,</definiens>
				<definiens id="1">the KL-divergence of a55 from a56</definiens>
			</definition>
			<definition id="5">
				<sentence>Although there are differences in some of the experimental details ( Ehlert employs a triangular window weighting and experiments with stemming ) , these probably do not account for the discrepancy .</sentence>
				<definiendum id="0">Ehlert</definiendum>
				<definiens id="0">employs a triangular window weighting and experiments with stemming</definiens>
			</definition>
			<definition id="6">
				<sentence>We ran the cosine experiment again , this time weighting the count of context a0 by a1a3a2a5a4 a1 a57 a6a8a7 a8 a5 , where a57 is the number of rows in the count matrix a0 and a7 a8 is the number of rows containing a nonzero count for context a0 .</sentence>
				<definiendum id="0">a57</definiendum>
				<definiens id="0">the number of rows in the count matrix a0 and a7 a8 is the number of rows containing a nonzero count for context a0</definiens>
			</definition>
</paper>

		<paper id="0104">
</paper>

		<paper id="0506">
			<definition id="0">
				<sentence>Second Language Acquisition ( SLA ) is a central topic in many of the fields of activity related to human languages .</sentence>
				<definiendum id="0">Second Language Acquisition ( SLA )</definiendum>
				<definiens id="0">a central topic in many of the fields of activity related to human languages</definiens>
			</definition>
			<definition id="1">
				<sentence>Most relevant to us here is modern example-based machine translation ( EBMT ) [ Somers01 , Carl03 ] , due to its explicit computation of translation templates and to the naturalness of learning from a small number of examples [ Brown00 , Cicekli01 ] .</sentence>
				<definiendum id="0">EBMT</definiendum>
				<definiens id="0">modern example-based machine translation (</definiens>
			</definition>
			<definition id="2">
				<sentence>The Computer Assisted Language Learning ( CALL ) literature [ Levy97 , Chapelle01 ] is rich in project descriptions , and there are several commercial CALL software applications .</sentence>
				<definiendum id="0">Computer Assisted Language Learning</definiendum>
				<definiens id="0">rich in project descriptions</definiens>
			</definition>
			<definition id="3">
				<sentence>In general , CALL applications focus on teacher , environment , memory and automatization aspects , and are thus complementary to the goals that we address here .</sentence>
				<definiendum id="0">CALL applications</definiendum>
				<definiens id="0">focus on teacher , environment , memory and automatization aspects</definiens>
			</definition>
			<definition id="4">
				<sentence>SL learners can make explicit judgments as to their level of confidence in the grammaticality of utterances .</sentence>
				<definiendum id="0">SL learners</definiendum>
				<definiens id="0">can make explicit judgments as to their level of confidence in the grammaticality of utterances</definiens>
			</definition>
			<definition id="5">
				<sentence>SLA is a central subject in linguistics theory and practice , and our main contribution is in addressing it in computational linguistics .</sentence>
				<definiendum id="0">SLA</definiendum>
				<definiens id="0">a central subject in linguistics theory and practice</definiens>
			</definition>
			<definition id="6">
				<sentence>Constructing a Language : a Usage Based Theory of Language Acquisition .</sentence>
				<definiendum id="0">Constructing a Language</definiendum>
				<definiens id="0">a Usage Based Theory of Language Acquisition</definiens>
			</definition>
</paper>

		<paper id="0619">
			<definition id="0">
				<sentence>The ABC corpus consists of abstracts of radio astronomical papers from the NASA Astrophysics Data System archive2 , a digital library for physics , astrophysics , and instrumentation .</sentence>
				<definiendum id="0">ABC corpus</definiendum>
				<definiens id="0">consists of abstracts of radio astronomical papers from the NASA Astrophysics Data System archive2 , a digital library for physics , astrophysics , and instrumentation</definiens>
			</definition>
			<definition id="1">
				<sentence>Source-type ( ST ) Types of objects , e.g. Type II Supernovae ( SNe II ) , radio-loud quasar , type 2 QSO , starburst galaxies , low-luminosity AGNs .</sentence>
				<definiendum id="0">Source-type</definiendum>
				<definiens id="0">ST ) Types of objects</definiens>
			</definition>
			<definition id="2">
				<sentence>Evaluation metrics for named entity recognition are standardly reported as accuracy on the token level , and as f-score on the phrasal level , e.g. Sang ( 2002 ) , where token level annotation refers to the B-I-O coding scheme.3 Likewise , we will use accuracy to report inter-annotator agreement on the token level , and f-score for the phrase level .</sentence>
				<definiendum id="0">Evaluation metrics</definiendum>
				<definiendum id="1">token level annotation</definiendum>
				<definiens id="0">inter-annotator agreement on the token level , and f-score for the phrase level</definiens>
			</definition>
			<definition id="3">
				<sentence>Also the f-score is symmetric , since recall ( A , B ) = precision ( B , A ) and ( balanced ) f-score is the harmonic mean of recall and precision ( Brants , 2000 ) .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the harmonic mean of recall and</definiens>
			</definition>
			<definition id="4">
				<sentence>The 3B-X marks the beginning of a phrase of type X , I-X denotes the continuation of an X phrase , and O a non-phrasal token .</sentence>
				<definiendum id="0">I-X</definiendum>
				<definiens id="0">the continuation of an X phrase</definiens>
			</definition>
			<definition id="5">
				<sentence>Another common agreement metric is the kappa coefficient which normalises token level accuracy by chance , e.g. Carletta et al. ( 1997 ) .</sentence>
				<definiendum id="0">common agreement metric</definiendum>
				<definiens id="0">the kappa coefficient which normalises token level accuracy by chance</definiens>
			</definition>
			<definition id="6">
				<sentence>This metric showed that the human annotators distinguish the four categories with a reproducibility of K=.925 ( N=44775 , k=2 ; where K is the kappa coefficient , N is the number of tokens and k is the number of annotators ) .</sentence>
				<definiendum id="0">K</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the kappa coefficient</definiens>
				<definiens id="1">the number of tokens</definiens>
				<definiens id="2">the number of annotators</definiens>
			</definition>
			<definition id="7">
				<sentence>It measures the divergence between two probability distributions p and q over the same event space χ : D ( p||q ) =summationdisplay x∈χ p ( x ) log p ( x ) q ( x ) ( 1 ) KL-divergence is a non-negative metric .</sentence>
				<definiendum id="0">KL-divergence</definiendum>
				<definiens id="0">a non-negative metric</definiens>
			</definition>
			<definition id="8">
				<sentence>Intuitively , a high KL-divergence score indicates an informative data point .</sentence>
				<definiendum id="0">high KL-divergence score</definiendum>
			</definition>
			<definition id="9">
				<sentence>It is the pairwise f-measure comparison between the multiple analyses for a given sentence : fMcomp = 12 summationdisplay M , Mprime∈M ( 1−F1 ( M ( t ) , Mprime ( t ) ) ) ( 2 ) where F1 is the balanced f-measure of M ( t ) and Mprime ( t ) , the preferred analyses of data point t according to different members M , Mprime of ensemble M. We take the complement so that it is oriented the same as KL-divergence with high values indicating high disagreement .</sentence>
				<definiendum id="0">F1</definiendum>
				<definiens id="0">the balanced f-measure of M ( t ) and Mprime ( t ) , the preferred analyses of data point t according to different members M</definiens>
			</definition>
			<definition id="10">
				<sentence>The Pearson correlation coefficient indicates the degree to which two variables are related .</sentence>
				<definiendum id="0">Pearson correlation coefficient</definiendum>
				<definiens id="0">indicates the degree to which two variables are related</definiens>
			</definition>
			<definition id="11">
				<sentence>However , as our sentence-level selection metrics affect the length of sentences selected , we normalise sentence-level annotation times by sentence length : Ave KL Max KL 1-F All Tokens 0.157 −0.009 0.082 O Removed 0.216 −0.007 0.106 Here we see a small positive correlations for averaged KL-divergence and f-complement indicating that sentences that score higher according to our selection metrics do generally take longer to annotate .</sentence>
				<definiendum id="0">sentence-level selection metrics</definiendum>
				<definiens id="0">the length of sentences selected , we normalise sentence-level annotation times by sentence length : Ave KL</definiens>
			</definition>
</paper>

		<paper id="0702">
			<definition id="0">
				<sentence>Morphological analysis is a crucial component of several natural language processing tasks , especially for languages with a highly productive morphology , where stipulating a full lexicon of surface forms is not feasible .</sentence>
				<definiendum id="0">Morphological analysis</definiendum>
				<definiens id="0">a crucial component of several natural language processing tasks</definiens>
			</definition>
			<definition id="1">
				<sentence>XFST grammars define a binary relation ( a transduction ) on sets of strings : a grammar maps each member of a ( possibly infinite ) set of strings , known as the surface , or lower language , to a set of strings ( the lexical , or upper language ) .</sentence>
				<definiendum id="0">XFST grammars</definiendum>
				<definiendum id="1">binary relation</definiendum>
			</definition>
			<definition id="2">
				<sentence>XFST enables the definition of variables , whose values , or denotations , are sets of strings , or languages .</sentence>
				<definiendum id="0">XFST</definiendum>
				<definiens id="0">enables the definition of variables , whose values , or denotations , are sets of strings , or languages</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , the concatenation operator ( unfortunately indicated by a space ) can be used to concatenate two languages : the expression ‘A B’ denotes the set of strings obtained by concatenating the strings in A with the strings in B. Similarly , the operator ‘|’ denotes set union , ‘ &amp; ’ denotes intersection , ‘˜’ set complement , ‘-’ set difference and ‘*’ Kleene closure ; ‘ $ A’ denotes the set of strings containing at least one instance of a string from A as a substring .</sentence>
				<definiendum id="0">concatenation operator</definiendum>
				<definiendum id="1">expression ‘A B’</definiendum>
				<definiens id="0">the set of strings obtained by concatenating the strings in A with the strings in B. Similarly , the operator ‘|’ denotes set union</definiens>
				<definiens id="1">the set of strings containing at least one instance of a string from A as a substring</definiens>
			</definition>
			<definition id="4">
				<sentence>x.’ operator denotes cross product : the expression ‘A.x.B’ denotes the relation in which each string in A is mapped to each string in B. An extremely useful operation is composition : denoted by ‘ .</sentence>
				<definiendum id="0">x.’ operator</definiendum>
				<definiendum id="1">expression ‘A.x.B’</definiendum>
			</definition>
			<definition id="5">
				<sentence>The system consists of two main components : a lexicon represented in Extensible Markup Language ( XML ) , and a set of finite-state rules , implemented in XFST .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of two main components : a lexicon represented in Extensible Markup Language ( XML ) , and a set of finite-state rules , implemented in XFST</definiens>
			</definition>
			<definition id="6">
				<sentence>Hebrew has grammatical gender , and the gender of nouns that denote animate entities coincides with their natural gender .</sentence>
				<definiendum id="0">Hebrew</definiendum>
				<definiens id="0">has grammatical gender , and the gender of nouns that denote animate entities coincides with their natural gender</definiens>
			</definition>
			<definition id="7">
				<sentence>The grammar consists of specific rules for every part of speech category , which are applied to the appropriate lexicons .</sentence>
				<definiendum id="0">grammar</definiendum>
			</definition>
			<definition id="8">
				<sentence>The variable inflectedWord denotes a union of all the possible inflections of the entire lexicon .</sentence>
				<definiendum id="0">variable inflectedWord</definiendum>
				<definiens id="0">a union of all the possible inflections of the entire lexicon</definiens>
			</definition>
</paper>

		<paper id="0624">
			<definition id="0">
				<sentence>Its principal advantages compared to the SVM approach are : • It typically utilizes fewer examples compared to the SVM , which makes the classifier faster .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">makes the classifier faster</definiens>
			</definition>
			<definition id="1">
				<sentence>We implemented the RVM training method using the ATLAS ( Whaley et al. , 2000 ) implementation of the BLAS and LAPACK standard linear algebra APIs .</sentence>
				<definiendum id="0">ATLAS</definiendum>
				<definiens id="0">Whaley et al. , 2000 ) implementation of the BLAS and LAPACK standard linear algebra APIs</definiens>
			</definition>
			<definition id="2">
				<sentence>To simplify training , we used the soft-prune approach as described in ( Pradhan et al. , 2005 ) , which means that before classification , the nodes were filtered through a binary classifier that classifies them as having a semantic role or not ( NON-NULL or NULL ) .</sentence>
				<definiendum id="0">NULL</definiendum>
				<definiens id="0">means that before classification , the nodes were filtered through a binary classifier that classifies them as having a semantic role or not ( NON-NULL or</definiens>
			</definition>
			<definition id="3">
				<sentence>The NULL nodes missed by the filter were included in the training set for the final classifier .</sentence>
				<definiendum id="0">NULL nodes</definiendum>
				<definiens id="0">missed by the filter were included in the training set for the final classifier</definiens>
			</definition>
</paper>

		<paper id="1502">
			<definition id="0">
				<sentence>The context-free approximation described in section 4 uses a form of CFG with decorated rules of the form f : A → α , where f is the name of the rule , and α is a sequence of terminals and categories subscripted with information needed for post-processing of the context-free parse result .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">α</definiendum>
				<definiens id="0">A → α</definiens>
				<definiens id="1">a sequence of terminals and categories subscripted with information needed for post-processing of the context-free parse result</definiens>
			</definition>
			<definition id="1">
				<sentence>A parse item is a representation of a piece of information that the parsing algorithm has acquired .</sentence>
				<definiendum id="0">parse item</definiendum>
				<definiens id="0">a representation of a piece of information that the parsing algorithm has acquired</definiens>
			</definition>
			<definition id="2">
				<sentence>An inference rule is written γ1 ... γn C γ where γ is the consequence of the antecedents γ1 ... γn , given that the side conditions in C hold .</sentence>
				<definiendum id="0">γ</definiendum>
				<definiens id="0">the consequence of the antecedents γ1 ... γn , given that the side conditions in C hold</definiens>
			</definition>
			<definition id="3">
				<sentence>Φ is the result of substituting the projections in Ψ with ranges for the categories found in vectorB .</sentence>
				<definiendum id="0">Φ</definiendum>
				<definiens id="0">the result of substituting the projections in Ψ with ranges for the categories found in vectorB</definiens>
			</definition>
			<definition id="4">
				<sentence>From the initial parse items we first build LCFRS items , of the form [ A → f [ vectorB ] ; Γ • ri ... rn ; vectorΓ ] where ri ... rn is a list of labels , vectorΓ is a list of |vectorB| range records , and Γ is a range record for the labels r1 ... ri−1 .</sentence>
				<definiendum id="0">ri ... rn</definiendum>
				<definiendum id="1">vectorΓ</definiendum>
				<definiendum id="2">Γ</definiendum>
				<definiens id="0">a list of labels</definiens>
				<definiens id="1">a list of |vectorB| range records</definiens>
			</definition>
			<definition id="5">
				<sentence>vectorΓδ is a list of |vectorB| empty range records since nothing has been found yet .</sentence>
				<definiendum id="0">vectorΓδ</definiendum>
				<definiens id="0">a list of |vectorB| empty range records since nothing has been found yet</definiens>
			</definition>
</paper>

		<paper id="0105">
			<definition id="0">
				<sentence>The Cass partial parsing system ( Abney , 1997 ) makes use of a cascade of FSTs .</sentence>
				<definiendum id="0">Cass partial parsing system</definiendum>
				<definiens id="0">makes use of a cascade of FSTs</definiens>
			</definition>
			<definition id="1">
				<sentence>To date , we have built web interfaces to nine NLPrelated technologies : • the Cass parser ( Abney , 1997 ) , • the MontyTagger Brill-style part-of-speech tagger ( Liu , 2004 ) , • the NLTK statistical part-of-speech tagger , • a NLTK context-free grammar parser ( Loper and Bird , 2002 ) , • the Gsearch context-free grammar parser ( Corley et al. , 2001 ) , • the SenseRelate word sense disambiguation system ( Pedersen et al. , 2005 ) , • a Perl Regular expression evaluator , • a linguistic feature annotator , • and a decision tree classifier ( Witten and Frank , 1999 ) .</sentence>
				<definiendum id="0">Cass parser</definiendum>
				<definiendum id="1">MontyTagger Brill-style part-of-speech tagger</definiendum>
				<definiendum id="2">NLTK context-free grammar parser</definiendum>
				<definiens id="0">the SenseRelate word sense disambiguation system ( Pedersen et al. , 2005 ) , • a Perl Regular expression evaluator , • a linguistic feature annotator , • and a decision tree classifier</definiens>
			</definition>
			<definition id="2">
				<sentence>• PHP is easier to work with than Java Server Pages and CGI scripts ; • requiring users to paste input into text boxes is superior to allowing user to upload files ( for security reasons and because it is easier to control the character encoding used ) ; • getting debugging information back to the student is very important ; • security is an issue since one is allowing users to initiate computationally intensive processes ; • it is still possible for students to claim the interface does not work for them ( even though we used no client-side scripting ) .</sentence>
				<definiendum id="0">security</definiendum>
				<definiens id="0">easier to control the character encoding used</definiens>
			</definition>
</paper>

		<paper id="0303">
			<definition id="0">
				<sentence>Cataphoric relations hold between a preceding pronoun and a following antecedent within the same sentence , even if this antecedent has already been mentioned within the preceding text .</sentence>
				<definiendum id="0">Cataphoric relations</definiendum>
				<definiens id="0">hold between a preceding pronoun and a following antecedent within the same sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>14 In sentence ( 5 ) , the relation between the two bracketed NPs is an example of such an instance relation since the second NP is a particular instantiation of the referent denoted by the first NP .</sentence>
				<definiendum id="0">NP</definiendum>
			</definition>
			<definition id="2">
				<sentence>The TüBa-D/Z annotation relies on a context-free backbone ( i.e. proper trees without crossing branches ) of phrase structure combined with edge labels that specify the grammatical function of the phrase in question .</sentence>
				<definiendum id="0">TüBa-D/Z annotation</definiendum>
				<definiens id="0">relies on a context-free backbone ( i.e. proper trees without crossing branches ) of phrase structure combined with edge labels that specify the grammatical function of the phrase in question</definiens>
			</definition>
			<definition id="3">
				<sentence>17 &lt; sentence id= '' s11976 '' &gt; &lt; node id= '' s11976n518 '' cat= '' SIMPX '' func= '' -- '' parent= '' 0 '' &gt; &lt; node id= '' s11976n515 '' cat= '' VF '' func= '' - '' &gt; &lt; node id= '' s11976n513 '' cat= '' NX '' func= '' OA '' &gt; &lt; node id= '' s11976n500 '' cat= '' NX '' func= '' APP '' &gt; &lt; word id= '' s11976w0 '' form= '' Ihre '' pos= '' PPOSAT '' morph= '' asf '' func= '' - '' &gt; &lt; anaphora &gt; &lt; relation type= '' ana '' antecedent= '' s11975n517 '' / &gt; &lt; /anaphora &gt; &lt; /word &gt; &lt; word id= '' s11976w1 '' form= '' Schulkameradin '' pos= '' NN '' morph= '' asf '' func= '' HD '' / &gt; &lt; /node &gt; &lt; node id= '' s11976n508 '' cat= '' EN-ADD '' func= '' APP '' &gt; &lt; node id= '' s11976n501 '' cat= '' NX '' func= '' - '' &gt; &lt; word id= '' s11976w2 '' form= '' Cassie '' pos= '' NE '' morph= '' asf '' func= '' - '' / &gt; &lt; word id= '' s11976w3 '' form= '' Bernall '' pos= '' NE '' morph= '' asf '' func= '' - '' / &gt; &lt; /node &gt; &lt; /node &gt; &lt; /node &gt; &lt; /node &gt; &lt; node id= '' s11976n509 '' cat= '' LK '' func= '' - '' &gt; &lt; node id= '' s11976n502 '' cat= '' VXFIN '' func= '' HD '' &gt; &lt; word id= '' s11976w4 '' form= '' fragten '' pos= '' VVFIN '' morph= '' 3pit '' func= '' HD '' / &gt; &lt; /node &gt; &lt; /node &gt; &lt; node id= '' s11976n510 '' cat= '' MF '' func= '' - '' &gt; &lt; node id= '' s11976n503 '' cat= '' NX '' func= '' ON '' &gt; &lt; word id= '' s11976w5 '' form= '' sie '' pos= '' PPER '' morph= '' np*3 '' func= '' HD '' &gt; &lt; anaphora &gt; &lt; relation type= '' ana '' antecedent= '' s11976w1 '' / &gt; &lt; /anaphora &gt; &lt; /word &gt; &lt; /node &gt; &lt; /node &gt; &lt; word id= '' s11976w6 '' form= '' , '' pos= '' $ , '' morph= '' -- '' func= '' -- '' parent= '' 0 '' / &gt; &lt; node id= '' s11976n517 '' cat= '' NF '' func= '' - '' &gt; &lt; node id= '' s11976n516 '' cat= '' SIMPX '' func= '' OS '' &gt; &lt; node id= '' s11976n504 '' cat= '' C '' func= '' - '' &gt; &lt; word id= '' s11976w7 '' form= '' ob '' pos= '' KOUS '' morph= '' -- '' func= '' - '' / &gt; &lt; /node &gt; &lt; node id= '' s11976n514 '' cat= '' MF '' func= '' - '' &gt; &lt; node id= '' s11976n505 '' cat= '' NX '' func= '' ON '' &gt; &lt; word id= '' s11976w8 '' form= '' sie '' pos= '' PPER '' morph= '' nsf3 '' func= '' HD '' &gt; &lt; anaphora &gt; &lt; relation type= '' ana '' antecedent= '' s11976n513 '' / &gt; &lt; /anophora &gt; &lt; /word &gt; &lt; /node &gt; &lt; node id= '' s11976n511 '' cat= '' PX '' func= '' OPP '' comment= '' '' &gt; &lt; word id= '' s11976w9 '' form= '' an '' pos= '' APPR '' morph= '' a '' func= '' - '' / &gt; &lt; node id= '' s11976n506 '' cat= '' NX '' func= '' HD '' &gt; &lt; word id= '' s11976w10 '' form= '' Gott '' pos= '' NE '' morph= '' asm '' func= '' HD '' / &gt; &lt; /node &gt; &lt; /node &gt; &lt; /node &gt; &lt; node id= '' s11976n512 '' cat= '' VC '' func= '' - '' &gt; &lt; node id= '' s11976n507 '' cat= '' VXFIN '' func= '' HD '' &gt; &lt; word id= '' s11976w11 '' form= '' glaube '' pos= '' VVFIN '' morph= '' 3sks '' func= '' HD '' / &gt; &lt; /node &gt; &lt; /node &gt; &lt; /node &gt; &lt; /node &gt; &lt; /node &gt; &lt; word form= '' . '' pos= '' $ . '' morph= '' -- '' func= '' -- '' parent= '' 0 '' / &gt; &lt; /sentence &gt; Figure 2 : The XML format represents information on all levels of annotation .</sentence>
				<definiendum id="0">XML format</definiendum>
				<definiens id="0">&gt; &lt; node id= '' s11976n514 '' cat= '' MF '' func= '' - '' &gt; &lt; node id= '' s11976n505 '' cat= '' NX '' func= '' ON</definiens>
				<definiens id="1">represents information on all levels of annotation</definiens>
			</definition>
</paper>

		<paper id="1510">
			<definition id="0">
				<sentence>Surface realization is the final stage of natural language generation which receives a semantic representation and outputs a corresponding sentence where all words are properly inflected and ordered .</sentence>
				<definiendum id="0">Surface realization</definiendum>
				<definiens id="0">the final stage of natural language generation which receives a semantic representation and outputs a corresponding sentence where all words are properly inflected and ordered</definiens>
			</definition>
			<definition id="1">
				<sentence>The Nitrogen system ( Langkilde and Knight , 1998 ; Langkilde , 2000 ) maps semantic relations to a packed forest containing all realizations and selects the best one with a bigram model .</sentence>
				<definiendum id="0">Nitrogen system</definiendum>
				<definiens id="0">maps semantic relations to a packed forest containing all realizations and selects the best one with a bigram model</definiens>
			</definition>
			<definition id="2">
				<sentence>The Fergus system ( Bangalore and Rambow , 2000 ) uses LTAG ( Lexicalized Tree Adjoining Grammar ( Schabes et al. , 1988 ) ) for generating a word lattice containing realizations and selects the best one using a trigram model .</sentence>
				<definiendum id="0">Fergus system</definiendum>
				<definiens id="0">uses LTAG ( Lexicalized Tree Adjoining Grammar ( Schabes et</definiens>
			</definition>
			<definition id="3">
				<sentence>REL expresses the base form of the word corresponding to the predicate .</sentence>
				<definiendum id="0">REL</definiendum>
				<definiens id="0">expresses the base form of the word corresponding to the predicate</definiens>
			</definition>
			<definition id="4">
				<sentence>INDEX expresses a semantic variable to identify each word in the set of relations .</sentence>
				<definiendum id="0">INDEX</definiendum>
				<definiens id="0">expresses a semantic variable to identify each word in the set of relations</definiens>
			</definition>
			<definition id="5">
				<sentence>Equivalence classes are identified with their signs and the semantic relations they cover .</sentence>
				<definiendum id="0">Equivalence classes</definiendum>
				<definiens id="0">identified with their signs and the semantic relations they cover</definiens>
			</definition>
			<definition id="6">
				<sentence>To estimate a13 a11 , pairs of a5 a0 a28 a35 a5a8a44 a9a18a9 are needed , where a0 is the most preferred realization for a44 .</sentence>
				<definiendum id="0">a0</definiendum>
				<definiens id="0">the most preferred realization for a44</definiens>
			</definition>
			<definition id="7">
				<sentence>FOM represents the log probability of an edge which is not normalized .</sentence>
				<definiendum id="0">FOM</definiendum>
			</definition>
			<definition id="8">
				<sentence>When two edges are combined , a11 a5a8a7 a3 a9 is computed as a11 a5a8a7a6a3a21a9 a38 a11 a5a8a7a6a5a9 a13 a11 a5a8a7 a18 a9 a1 a13 a1 a2 a11a4a3 a18a6a5 a3 a5 a2 a18 a4a2 a5a9 , where a13 is the weight of the bigram feature , a2 a5 is the last word of the left daughter , a2 a18 is the first word of the right daughter , and a1 a2 a11a4a3 a18a6a5 a3 represents a log probability of a bigram .</sentence>
				<definiendum id="0">a13</definiendum>
				<definiens id="0">the weight of the bigram feature</definiens>
				<definiens id="1">the last word of the left daughter</definiens>
			</definition>
			<definition id="9">
				<sentence>BLEU is the weighted average of n-gram precision against the reference sentence .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">the weighted average of n-gram precision against the reference sentence</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>A keyboard , as well as being a typewriter or computer keyboard , is also fiddle cat barrow bow cello flute mouse dog game kitten violin piano bass fortepiano orchestra keyboard screen monitor memory guitar rat human Figure 1 : A cluster involving several idiomatic links used to mean ( part of ) a musical instrument such as an organ or piano , and keyboard is linked to violin .</sentence>
				<definiendum id="0">keyboard</definiendum>
				<definiens id="0">being a typewriter or computer keyboard , is also fiddle cat barrow bow cello flute mouse dog game kitten violin piano bass fortepiano orchestra keyboard screen monitor memory guitar rat human Figure 1 : A cluster involving several idiomatic links used to mean</definiens>
			</definition>
</paper>

		<paper id="1206">
			<definition id="0">
				<sentence>Some of us have argued elsewhere there is no need for a distinction between these two notions ( Karttunen and Peters , 1979 ) and that presupposition is a less felicitous term because it tends to be confused with “old information” .</sentence>
				<definiendum id="0">presupposition</definiendum>
				<definiens id="0">a less felicitous term because it tends to be confused with “old information”</definiens>
			</definition>
			<definition id="1">
				<sentence>Conventional implicatures are a rich source of information for IE tasks because the material presented in them is supposed 4For more on conventional implicatures , see e.g. Karttunen and Peters ( 1979 ) and Potts ( 2005 ) to be non-controversial .</sentence>
				<definiendum id="0">Conventional implicatures</definiendum>
				<definiens id="0">a rich source of information for IE tasks because the material presented in them is supposed 4For more on conventional implicatures</definiens>
			</definition>
			<definition id="2">
				<sentence>Here the test suite is the victim of its self imposed constraints , namely that the relation has to be established between two sentences found in “real” text .</sentence>
				<definiendum id="0">test suite</definiendum>
				<definiens id="0">the relation has to be established between two sentences found in “real” text</definiens>
			</definition>
</paper>

		<paper id="0807">
			<definition id="0">
				<sentence>The regular-expression ‘quasi-parser’ takes a direct approach , using several dozen heuristics based on regular-expression-like patterns over words , Penn part-of-speech tags , and the output of the fnTBL noun chunker .</sentence>
				<definiendum id="0">regular-expression ‘quasi-parser’</definiendum>
				<definiens id="0">takes a direct approach , using several dozen heuristics based on regular-expression-like patterns over words</definiens>
			</definition>
			<definition id="1">
				<sentence>52 MiniPar produces a labeled dependency graph , which yields a straightforward extraction of the information needed for this task .</sentence>
				<definiendum id="0">MiniPar</definiendum>
				<definiens id="0">produces a labeled dependency graph</definiens>
			</definition>
			<definition id="2">
				<sentence>The Collins Parser produces a Penn-Treebank-style constituency tree , with head labels .</sentence>
				<definiendum id="0">Collins Parser</definiendum>
				<definiens id="0">produces a Penn-Treebank-style constituency tree</definiens>
			</definition>
</paper>

		<paper id="1515">
			<definition id="0">
				<sentence>A span is a range over contiguous words in the input sentence .</sentence>
				<definiendum id="0">span</definiendum>
				<definiens id="0">a range over contiguous words in the input sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>A state is a set of parse items , none of which may cross .</sentence>
				<definiendum id="0">state</definiendum>
				<definiens id="0">a set of parse items , none of which may cross</definiens>
			</definition>
			<definition id="2">
				<sentence>A parse path ( or history ) is a sequence of parse inferences over some input sentence ( Klein &amp; Manning , 2001 ) .</sentence>
				<definiendum id="0">parse path</definiendum>
			</definition>
			<definition id="3">
				<sentence>Instead of having a single classifier score every inference , we parallelize training by inducing 26 sub-classifiers , one for each constituent label λ in the Penn Treebank ( Taylor , Marcus , &amp; Santorini , 2003 ) : Q ( I ) = Q ( I ) , where Q is the λ-classifier and I is an inference that infers a constituent with labelλ .</sentence>
				<definiendum id="0">Q</definiendum>
				<definiens id="0">the λ-classifier and I is an inference that infers a constituent with labelλ</definiens>
			</definition>
			<definition id="4">
				<sentence>VP ( was ) NP ( timing ) VBD/was ADJP ( perfect ) DT/The NN/timing JJ/perfect Eachλ-classifier is independently trained on training set E , where each example e 2E is a tuple ( I , y ) , I is a candidateλ-inference , and y2f 1g .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">VBD/was ADJP ( perfect ) DT/The NN/timing JJ/perfect Eachλ-classifier is independently trained on training set E , where each example e 2E is a tuple</definiens>
			</definition>
			<definition id="5">
				<sentence>An example ( I , y ) is assigned weight wt ( I , y ) :2 wt ( I , y ) = 11+exp ( y Qt 1 ( I ) ) ( 8 ) The total weight of y-value examples that fall in leaf f is Wtf ; y : Wtf ; y = summationdisplay ( I ; y0 ) 2E y0=y ; I2f wt ( I , y ) ( 9 ) and this leaf has loss Ztf : Ztf =2 radicalBig Wtf ; + Wtf ; ( 10 ) Growing the decision tree : The loss of the entire decision tree qt is Z ( qt ) = summationdisplay leaf f2qt Ztf ( 11 ) exp ( y Qt 1 ( I ) ) 1 , but leave the remainder of the algorithm unchanged , this algorithm would be confidence-rated AdaBoost ( Schapire &amp; Singer , 1999 ) , minimizing the exponential loss L ( z ) = exp ( z ) .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">The loss of the entire decision tree qt is Z ( qt ) = summationdisplay leaf f2qt Ztf ( 11 ) exp ( y Qt 1</definiens>
			</definition>
			<definition id="6">
				<sentence>We evaluated our parser using the standard PARSEVAL measures ( Black et al. , 1991 ) : labelled precision , recall , and F-measure ( LPRC , LRCL , and LFMS , respectively ) , which are computed based on the number of constituents in the parser’s output that match those in the gold-standard parse .</sentence>
				<definiendum id="0">LFMS</definiendum>
				<definiens id="0">computed based on the number of constituents in the parser’s output that match those in the gold-standard parse</definiens>
			</definition>
			<definition id="7">
				<sentence>As in traditional parsers , the baseline was smoothed by replacing any word that occurs fewer than five times in the training data with the special token UNK ( Table 3.9 ) .</sentence>
				<definiendum id="0">UNK</definiendum>
				<definiens id="0">smoothed by replacing any word that occurs fewer than five times in the training data with the special token</definiens>
			</definition>
</paper>

		<paper id="0602">
			<definition id="0">
				<sentence>In this paper , we address the more ambitious task of learning to map sentences to a complete formal meaningrepresentation language ( MRL ) .</sentence>
				<definiendum id="0">MRL</definiendum>
				<definiens id="0">a complete formal meaningrepresentation language</definiens>
			</definition>
			<definition id="1">
				<sentence>The second MRL is a coaching language for robotic soccer developed for the RoboCup Coach Competition , in which AI researchers compete to provide effective instructions to a coachable team of agents in a simulated soccer domain ( et al. , 2003 ) .</sentence>
				<definiendum id="0">MRL</definiendum>
			</definition>
			<definition id="2">
				<sentence>GEOQUERY is a logical query language for a small database of U.S. geography containing about 800 facts .</sentence>
				<definiendum id="0">GEOQUERY</definiendum>
				<definiens id="0">a logical query language for a small database of U.S. geography containing about 800 facts</definiens>
			</definition>
			<definition id="3">
				<sentence>The GEOQUERY language consists of Prolog queries augmented with several meta-predicates ( Zelle and Mooney , 1996 ) .</sentence>
				<definiendum id="0">GEOQUERY language</definiendum>
				<definiens id="0">consists of Prolog queries augmented with several meta-predicates</definiens>
			</definition>
			<definition id="4">
				<sentence>Notation : CG C5CA is the MR of node CG .</sentence>
				<definiendum id="0">CG C5CA</definiendum>
				<definiens id="0">the MR of node CG</definiens>
			</definition>
			<definition id="5">
				<sentence>num ( num , num ) , which is a kind of point that represents a field coordinate in CLANG .</sentence>
				<definiendum id="0">num )</definiendum>
				<definiens id="0">a kind of point that represents a field coordinate in CLANG</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus , we write a nonterminal as CGB4DCB5 , where X is a syntactic label and DC BP CWDBBND8 D7DDD2 CX .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a syntactic label and DC BP CWDBBND8 D7DDD2 CX</definiens>
			</definition>
			<definition id="7">
				<sentence>The subscript D7DDD2 refers to the syntactic part , and D7CTD1 refers to the semantic part .</sentence>
				<definiendum id="0">D7DDD2</definiendum>
				<definiendum id="1">D7CTD1</definiendum>
				<definiens id="0">the semantic part</definiens>
			</definition>
			<definition id="8">
				<sentence>CHILL ( Zelle and Mooney , 1996 ) is a system based on Inductive Logic Programming ( ILP ) .</sentence>
				<definiendum id="0">CHILL</definiendum>
			</definition>
			<definition id="9">
				<sentence>SILT is a system that learns symbolic , pattern-based , transformation rules for mapping NL sentences to formal languages ( Kate et al. , 2005 ) .</sentence>
				<definiendum id="0">SILT</definiendum>
			</definition>
			<definition id="10">
				<sentence>It comes in two versions , SILT-string , which maps NL strings directly to an MRL , and SILT-tree , which maps syntactic 0 10 20 30 40 50 60 70 80 90 100 0 50 100 150 200 250 Precision ( % ) Training sentences SCISSOR SILT-string SILT-tree CHILL GEOBASE Figure 6 : Precision learning curves for GEOQUERY .</sentence>
				<definiendum id="0">SILT-string</definiendum>
				<definiendum id="1">SILT-tree</definiendum>
				<definiens id="0">maps NL strings directly to an MRL</definiens>
				<definiens id="1">Precision learning curves for GEOQUERY</definiens>
			</definition>
			<definition id="11">
				<sentence>A sample frame is AIRTRANSPORTATION which has three slots – the arrival time , origin and destination .</sentence>
				<definiendum id="0">sample frame</definiendum>
				<definiens id="0">AIRTRANSPORTATION which has three slots – the arrival time , origin and destination</definiens>
			</definition>
			<definition id="12">
				<sentence>SCISSOR learns statistical parsers that integrate syntax and semantics in order to produce a semantically augmented parse tree that is then used to compositionally generate a formal meaning representation .</sentence>
				<definiendum id="0">SCISSOR</definiendum>
				<definiens id="0">learns statistical parsers that integrate syntax and semantics in order to produce a semantically augmented parse tree that is then used to compositionally generate a formal meaning representation</definiens>
			</definition>
</paper>

		<paper id="1203">
			<definition id="0">
				<sentence>LSA aims to find similar terms in large text collections , and measure similarity between texts by including these additional related words .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">aims to find similar terms in large text collections</definiens>
			</definition>
			<definition id="1">
				<sentence>The Leacock &amp; Chodorow ( Leacock and Chodorow , 1998 ) similarity is determined as : Simlch = −log length2 ∗ D ( 1 ) where length is the length of the shortest path between two concepts using node-counting , and D is the maximum depth of the taxonomy .</sentence>
				<definiendum id="0">length</definiendum>
				<definiendum id="1">D</definiendum>
				<definiens id="0">the maximum depth of the taxonomy</definiens>
			</definition>
			<definition id="2">
				<sentence>The Lesk similarity of two concepts is defined as a function of the overlap between the corresponding definitions , as provided by a dictionary .</sentence>
				<definiendum id="0">Lesk similarity of two concepts</definiendum>
				<definiens id="0">a function of the overlap between the corresponding definitions</definiens>
			</definition>
			<definition id="3">
				<sentence>The Wu and Palmer ( Wu and Palmer , 1994 ) similarity metric measures the depth of the two concepts in the WordNet taxonomy , and the depth of the least common subsumer ( LCS ) , and combines these figures into a similarity score : Simwup = 2 ∗ depth ( LCS ) depth ( concept 1 ) + depth ( concept2 ) ( 2 ) The measure introduced by Resnik ( Resnik , 1995 ) returns the information content ( IC ) of the LCS of two concepts : Simres = IC ( LCS ) ( 3 ) where IC is defined as : IC ( c ) = −log P ( c ) ( 4 ) and P ( c ) is the probability of encountering an instance of concept c in a large corpus .</sentence>
				<definiendum id="0">similarity metric</definiendum>
				<definiendum id="1">LCS</definiendum>
				<definiendum id="2">IC</definiendum>
				<definiendum id="3">P ( c )</definiendum>
				<definiens id="0">measures the depth of the two concepts in the WordNet taxonomy , and the depth of the least common subsumer</definiens>
				<definiens id="1">returns the information content ( IC ) of the LCS of two concepts : Simres = IC ( LCS )</definiens>
				<definiens id="2">the probability of encountering an instance of concept c in a large corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>The next measure we use in our experiments is the metric introduced by Lin ( Lin , 1998 ) , which builds on Resnik’s measure of similarity , and adds a normalization factor consisting of the information content of the two input concepts : Simlin = 2 ∗ IC ( LCS ) IC ( concept 1 ) + IC ( concept2 ) ( 5 ) Finally , the last similarity metric we consider is Jiang &amp; Conrath ( Jiang and Conrath , 1997 ) , which returns a score determined by : Simjnc = 1IC ( concept 1 ) + IC ( concept2 ) − 2 ∗ IC ( LCS ) ( 6 ) 14 In addition to the semantic similarity of words , we also want to take into account the specificity of words , so that we can give a higher weight to a semantic matching identified between two very specific words ( e.g. collie and sheepdog ) , and give less importance to the similarity score measured between generic concepts ( e.g. go and be ) .</sentence>
				<definiendum id="0">IC</definiendum>
				<definiens id="0">builds on Resnik’s measure of similarity , and adds a normalization factor consisting of the information content of the two input concepts : Simlin = 2 ∗ IC ( LCS ) IC ( concept 1 ) + IC</definiens>
				<definiens id="1">returns a score determined by</definiens>
				<definiens id="2">account the specificity of words , so that we can give a higher weight to a semantic matching identified between two very specific words ( e.g. collie and sheepdog ) , and give less importance to the similarity score measured between generic concepts</definiens>
			</definition>
			<definition id="5">
				<sentence>We determine the specificity of a word using the inverse document frequency introduced in ( Sparck-Jones , 1972 ) , which is defined as the total number of documents in the corpus , divided by the total number of documents that include that word .</sentence>
				<definiendum id="0">inverse document frequency introduced in</definiendum>
				<definiens id="0">determine the specificity of a word using the</definiens>
				<definiens id="1">the total number of documents in the corpus , divided by the total number of documents that include that word</definiens>
			</definition>
			<definition id="6">
				<sentence>We use the Microsoft paraphrase corpus ( Dolan et al. , 2004 ) , consisting of 4,076 training pairs and 1,725 test pairs , and determine the number of correctly identified paraphrase pairs in the corpus using the text semantic similarity measure as the only indicator of paraphrasing .</sentence>
				<definiendum id="0">Microsoft paraphrase corpus</definiendum>
				<definiens id="0">consisting of 4,076 training pairs and 1,725 test pairs , and determine the number of correctly identified paraphrase pairs in the corpus using the text semantic similarity measure as the only indicator of paraphrasing</definiens>
			</definition>
</paper>

		<paper id="0606">
			<definition id="0">
				<sentence>One of the more intangible aspects of a Hidden Markov Model is the choice of the model itself .</sentence>
				<definiendum id="0">Hidden Markov Model</definiendum>
			</definition>
			<definition id="1">
				<sentence>“X” and “Y” , the gap states , output a symbol on only one stream against a gap on the other .</sentence>
				<definiendum id="0">“X”</definiendum>
			</definition>
			<definition id="2">
				<sentence>The log odds algorithm calculates a score for a pair of symbols by dividing the probability of a genuine correspondence between a pair of symbols ( the similarity model ) by the probability of them co-occurring by chance ( the random model ) .</sentence>
				<definiendum id="0">log odds algorithm</definiendum>
			</definition>
			<definition id="3">
				<sentence>Apart from the standard Viterbi ( abbreviated VIT ) and forward ( FOR ) algorithms , we considered two variations of the log odds algorithm , The original log odds algorithm ( LOG ) functions much like a Viterbi algo42 Figure 3 : A Pair Hidden Markov Model for aligning words .</sentence>
				<definiendum id="0">Viterbi ( abbreviated VIT</definiendum>
				<definiens id="0">A Pair Hidden Markov Model for aligning words</definiens>
			</definition>
			<definition id="4">
				<sentence>The principal objective of the bioinformatics model is the optimal alignment of two sequences .</sentence>
				<definiendum id="0">principal objective of the bioinformatics model</definiendum>
				<definiens id="0">the optimal alignment of two sequences</definiens>
			</definition>
			<definition id="5">
				<sentence>In order to rectify this problem , we multiply the final probability by 1Cn , where n is the length of the longer word in the pair , and C is a constant .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the length of the longer word in the pair</definiens>
				<definiens id="1">a constant</definiens>
			</definition>
			<definition id="6">
				<sentence>2Another common method to correct for length is to take the nth root of the final calculation , where n is the length of the longest word .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the length of the longest word</definiens>
			</definition>
			<definition id="7">
				<sentence>The input consists of pairs of words that have the same meaning in distinct languages .</sentence>
				<definiendum id="0">input</definiendum>
			</definition>
</paper>

		<paper id="1609">
			<definition id="0">
				<sentence>The dialogue planner constructs an HLDS logical form that specifies the communication goal reflecting how the belief context could be updated with the information coming from the acoustic and visual dimensions .</sentence>
				<definiendum id="0">HLDS logical</definiendum>
				<definiens id="0">the information coming from the acoustic and visual dimensions</definiens>
			</definition>
			<definition id="1">
				<sentence>The operation add-feature adds a feature and a value to the nominal of the current locus .</sentence>
				<definiendum id="0">operation add-feature</definiendum>
				<definiens id="0">adds a feature and a value to the nominal of the current locus</definiens>
			</definition>
			<definition id="2">
				<sentence>Here , o1 is an identifier for the red ball in the belief context , where we fuse the information about identifiers in the dialogue and visual context .</sentence>
				<definiendum id="0">o1</definiendum>
				<definiens id="0">an identifier for the red ball in the belief context</definiens>
				<definiens id="1">the information about identifiers in the dialogue and visual context</definiens>
			</definition>
			<definition id="3">
				<sentence>The utterance planner makes d the locus , and enters system ( 1 ) .</sentence>
				<definiendum id="0">utterance planner</definiendum>
			</definition>
			<definition id="4">
				<sentence>A path consists of the systems that need to be entered , and the decisions that the associated choosers need to make .</sentence>
				<definiendum id="0">path</definiendum>
				<definiens id="0">consists of the systems that need to be entered</definiens>
			</definition>
</paper>

		<paper id="1201">
			<definition id="0">
				<sentence>In remainder of this paper , we will distinguish two aspects of this task : alignment is the subtask of pairing related nodes – or more precise , pairing the token strings corresponding to these nodes ; classification of semantic relations is the subtask of labeling these alignments in terms of the five types of semantic relations .</sentence>
				<definiendum id="0">alignment</definiendum>
				<definiens id="0">the subtask of pairing related nodes – or more precise , pairing the token strings corresponding to these nodes</definiens>
			</definition>
			<definition id="1">
				<sentence>node pairs as follows : precision = | Areal ∩ Apred | / | Apred | ( 1 ) recall = | Areal ∩ Apred | / | Areal | ( 2 ) F-score = ( 2 × prec × rec ) / ( prec + rec ) ( 3 ) where Areal is the set of all real alignments ( the reference or golden standard ) , Apred is the set of all predicted alignments , and Apred∩Areal is the set all correctly predicted alignments .</sentence>
				<definiendum id="0">Areal</definiendum>
				<definiendum id="1">Apred</definiendum>
				<definiendum id="2">Apred∩Areal</definiendum>
				<definiens id="0">precision = | Areal ∩ Apred | / | Apred | ( 1 ) recall = | Areal ∩ Apred | / |</definiens>
				<definiens id="1">the set of all real alignments ( the reference or golden standard )</definiens>
				<definiens id="2">the set of all predicted alignments</definiens>
				<definiens id="3">the set all correctly predicted alignments</definiens>
			</definition>
</paper>

		<paper id="0630">
</paper>

		<paper id="0505">
			<definition id="0">
				<sentence>Gaze fixations depend on whether the hare is the subject or object of the sentence , as well as the thematic role structure of the verb .</sentence>
				<definiendum id="0">Gaze fixations</definiendum>
				<definiens id="0">the subject or object of the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The Simple Recurrent Network is a type of neural network typically used to process temporal sequences of patterns such as words in a sentence .</sentence>
				<definiendum id="0">Simple Recurrent Network</definiendum>
				<definiens id="0">a type of neural network typically used to process temporal sequences of patterns such as words in a sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>This contextual development may have shaped both our cognitive architecture ( i.e. , providing for rapid , seamless integration of scene and linguistic information ) , and comprehension mechanisms ( e.g. , people rapidly avail themselves of information from the immediate scene when the utterance identifies it ) .</sentence>
				<definiendum id="0">cognitive architecture</definiendum>
				<definiens id="0">providing for rapid , seamless integration of scene and linguistic information ) , and comprehension mechanisms ( e.g. , people rapidly avail themselves of information from the immediate scene when the utterance identifies it )</definiens>
			</definition>
</paper>

		<paper id="1608">
			<definition id="0">
				<sentence>Deixis anchors utterances in their spatio-temporal context and can therefore be seen as a central part of the aboutness of language .</sentence>
				<definiendum id="0">Deixis</definiendum>
				<definiens id="0">anchors utterances in their spatio-temporal context and can therefore be seen as a central part of the aboutness of language</definiens>
			</definition>
			<definition id="1">
				<sentence>A typical setting consists of a human instructor and an anthropomorphic virtual agent interacting in face-to-face manner in VR realised in a three-side Cave-like installation .</sentence>
				<definiendum id="0">typical setting</definiendum>
				<definiens id="0">consists of a human instructor and an anthropomorphic virtual agent interacting in face-to-face manner in VR realised in a three-side Cave-like installation</definiens>
			</definition>
			<definition id="2">
				<sentence>The setting consists of two interlocutors located at a table with some objects lying on it .</sentence>
				<definiendum id="0">setting</definiendum>
				<definiens id="0">consists of two interlocutors located at a table with some objects lying on it</definiens>
			</definition>
			<definition id="3">
				<sentence>R represents the set of restricting properties found , each composed of an attribute-value pair .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">represents the set of restricting properties found , each composed of an attribute-value pair</definiens>
			</definition>
			<definition id="4">
				<sentence>P represents the ordered list of properties which the algorithm gets as additional input .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">represents the ordered list of properties which the algorithm gets as additional input</definiens>
			</definition>
			<definition id="5">
				<sentence>The function GETVALUE ( o , p ) returns the absolute value v of the property p of the object o fetched from the knowledgebase .</sentence>
				<definiendum id="0">function GETVALUE</definiendum>
				<definiendum id="1">p )</definiendum>
				<definiens id="0">returns the absolute value v of the property p of the object o fetched from the knowledgebase</definiens>
			</definition>
			<definition id="6">
				<sentence>MURML enables the specification of arbitrary co-verbal gestures .</sentence>
				<definiendum id="0">MURML</definiendum>
				<definiens id="0">enables the specification of arbitrary co-verbal gestures</definiens>
			</definition>
</paper>

		<paper id="0906">
</paper>

		<paper id="1205">
			<definition id="0">
				<sentence>The Inversion Transduction Grammar or ITG formalism , which historically was developed in the context of translation and alignment , hypothesizes strong expressiveness restrictions that constrain paraphrases to vary word order only in certain allowable nested permutations of arguments ( Wu , 1997 ) .</sentence>
				<definiendum id="0">Inversion Transduction Grammar</definiendum>
			</definition>
			<definition id="1">
				<sentence>25 Formally , ITGs can be defined as the restricted subset of syntax-directed transduction grammars or SDTGs Lewis and Stearns ( 1968 ) where all of the rules are either of straight or inverted orientation .</sentence>
				<definiendum id="0">ITGs</definiendum>
				<definiens id="0">the restricted subset of syntax-directed transduction grammars or SDTGs Lewis and Stearns ( 1968 ) where all of the rules are either of straight or inverted orientation</definiens>
			</definition>
			<definition id="2">
				<sentence>Let W1 , W2 be the vocabulary sizes of the two languages , and N = { A1 , ... , AN } be the set of nonterminals with indices 1 , ... , N. Wu ( 1997 ) also showed that ITGs can be equivalently be defined in two other ways .</sentence>
				<definiendum id="0">W1 , W2</definiendum>
				<definiendum id="1">, N. Wu</definiendum>
				<definiens id="0">the vocabulary sizes of the two languages , and N = { A1 , ... , AN } be the set of nonterminals with indices 1 , ...</definiens>
			</definition>
			<definition id="3">
				<sentence>The key modeling property of Bracketing ITGs that is most relevant to paraphrase recognition is that they assign strong preference to candidate paraphrase pairs in which nested constituent subtrees can be recursively aligned with a minimum of constituent boundary violations .</sentence>
				<definiendum id="0">Bracketing ITGs</definiendum>
				<definiens id="0">assign strong preference to candidate paraphrase pairs in which nested constituent subtrees</definiens>
			</definition>
			<definition id="4">
				<sentence>The condition ( S−s ) ( t−S ) + ( U −u ) ( v−U ) negationslash= 0 is a way to specify that the substring in one but not both languages may be split into an empty string epsilon1 and the substring itself ; this ensures that the recursion terminates , but permits words that have no match in the other language to map to an epsilon1 instead .</sentence>
				<definiendum id="0">S−s )</definiendum>
				<definiens id="0">t−S ) + ( U −u ) ( v−U ) negationslash= 0 is a way to specify that the substring in one but not both languages may be split into an empty string epsilon1 and the substring itself ; this ensures that the recursion terminates , but permits words that have no match in the other language to map to an epsilon1 instead</definiens>
			</definition>
			<definition id="5">
				<sentence>The MSR Paraphrase Corpus test set consists of 1725 candidate paraphrase string pairs , each annotated for semantic equivalence by two or three human collectors .</sentence>
				<definiendum id="0">MSR Paraphrase Corpus test set</definiendum>
				<definiens id="0">consists of 1725 candidate paraphrase string pairs , each annotated for semantic equivalence by two or three human collectors</definiens>
			</definition>
			<definition id="6">
				<sentence>The ITG scoring model produced an uninterpolated average precision ( also known as confidence weighted score ) of 76.1 % .</sentence>
				<definiendum id="0">ITG scoring model</definiendum>
				<definiens id="0">produced an uninterpolated average precision ( also known as confidence weighted score ) of 76.1 %</definiens>
			</definition>
			<definition id="7">
				<sentence>As one might expect , the Bracketing ITG models performed better on the subsets more closely approximating the tasks for which Bracketing ITGs were designed : comparable documents ( CD ) , paraphrasing ( PP ) , and information extraction ( IE ) .</sentence>
				<definiendum id="0">Bracketing ITG</definiendum>
				<definiens id="0">models performed better on the subsets more closely approximating the tasks for which Bracketing ITGs were designed : comparable documents ( CD ) , paraphrasing ( PP ) , and information extraction</definiens>
			</definition>
			<definition id="8">
				<sentence>Among all subsets , CD is perhaps closest to the noisy word alignment task for which Bracketing ITGs were originally developed , and indeed produced the best results for both of the Bracketing ITG models .</sentence>
				<definiendum id="0">CD</definiendum>
			</definition>
</paper>

		<paper id="0831">
			<definition id="0">
				<sentence>The automated transducer inference techniques OMEGA ( Vilar , 2000 ) and GIATI ( Casacuberta et al. , 2004 ) work on phrase level , but ignore the reordering problem from the view of the model .</sentence>
				<definiendum id="0">GIATI</definiendum>
				<definiens id="0">Casacuberta et al. , 2004 ) work on phrase level , but ignore the reordering problem from the view of the model</definiens>
			</definition>
			<definition id="1">
				<sentence>2 as : A2 ( i ) = argminj ˘cij ( 3 ) where ˘cij are the elements of the new cost matrix ˘C which corresponds to the reordered source sentence .</sentence>
				<definiendum id="0">˘cij</definiendum>
				<definiens id="0">the elements of the new cost matrix ˘C which corresponds to the reordered source sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>A state description bJ1 , for which the following condition holds : Mon ( j ) : bjprime = δ ( jprime ≤ j ) ∀ 1 ≤ jprime ≤ J represents the monotonic path up to the word fj .</sentence>
				<definiendum id="0">J</definiendum>
				<definiens id="0">the monotonic path up to the word fj</definiens>
			</definition>
			<definition id="3">
				<sentence>172 mWER mPER BLEU NIST Reordering : [ % ] [ % ] [ % ] BTEC Japanese-to-English ( JE ) dev none 59.7 58.8 13.0 0.00 in training 57.8 39.4 14.7 3.27 + 9-inv-ibm 40.3 32.1 45.1 8.59 + rescoring* 39.1 30.9 53.2 9.93 BTEC Chinese-to-English ( CE ) dev none 55.2 52.1 24.9 1.34 in training 54.0 42.3 23.0 4.18 + 7-inv-ibm 47.1 39.4 34.5 6.53 + rescoring* 48.3 40.7 39.1 8.11 Table 2 : Translation results with optimal reordering constraints and window sizes for the BTEC Japanese-to-English and Chinese-to-English development corpora .</sentence>
				<definiendum id="0">mWER mPER BLEU NIST Reordering</definiendum>
				<definiendum id="1">BTEC Japanese-to-English</definiendum>
				<definiendum id="2">BTEC Chinese-to-English</definiendum>
				<definiens id="0">Translation results with optimal reordering constraints and window sizes for the BTEC Japanese-to-English and Chinese-to-English development corpora</definiens>
			</definition>
			<definition id="4">
				<sentence>mWER mPER BLEU NIST [ % ] [ % ] [ % ] BTEC Japanese-to-English ( JE ) test AT 41.9 33.8 45.3 9.49 WFST 42.1 35.6 47.3 9.50 BTEC Chinese-to-English ( CE ) test AT 45.6 39.0 40.9 8.55 WFST 46.4 38.8 40.8 8.73 Table 3 : Comparison of the IWSLT-2004 automatic evaluation results for the described system ( WFST ) with those of the best submitted system ( AT ) .</sentence>
				<definiendum id="0">BTEC Japanese-to-English</definiendum>
				<definiendum id="1">BTEC Chinese-to-English</definiendum>
				<definiens id="0">Comparison of the IWSLT-2004 automatic evaluation results for the described system ( WFST ) with those of the best submitted system ( AT )</definiens>
			</definition>
</paper>

		<paper id="0201">
			<definition id="0">
				<sentence>Computer-assisted item generation ( CAIG ) allows the creation of large-scale item banks , and has attracted active study in the past decade ( Deane and Sheehan , 2003 ; Irvine and Kyllonen , 2002 ) .</sentence>
				<definiendum id="0">Computer-assisted item generation</definiendum>
				<definiens id="0">the creation of large-scale item banks , and has attracted active study in the past decade</definiens>
			</definition>
			<definition id="1">
				<sentence>Applying techniques for natural language processing ( NLP ) , CAIG offers the possibility of creating a large number of items of different challenging levels , thereby paving a way to make computers more adaptive to students of different competence .</sentence>
				<definiendum id="0">NLP</definiendum>
				<definiendum id="1">CAIG</definiendum>
				<definiens id="0">offers the possibility of creating a large number of items of different challenging levels , thereby paving a way to make computers more adaptive to students of different competence</definiens>
			</definition>
			<definition id="2">
				<sentence>HowNet is a bilingual lexicon .</sentence>
				<definiendum id="0">HowNet</definiendum>
				<definiens id="0">a bilingual lexicon</definiens>
			</definition>
			<definition id="3">
				<sentence>Let w be the word of interest , and pi be the first listed class , in HowNet , of a signal word that has the syntactic relationship µ with w. We define the strength of the association of w and pi as follows : Aµ ( w , pi ) = Prµ ( w , pi ) Pr µ ( w ) , ( 1 ) where Prµ ( w ) is the probability of w participating in the µ relationship , and Prµ ( w , pi ) is the probability that both w and pi participate in the µ relationship .</sentence>
				<definiendum id="0">Prµ</definiendum>
				<definiendum id="1">pi )</definiendum>
				<definiens id="0">the word of interest , and pi be the first listed class , in HowNet , of a signal word that has the syntactic relationship µ with w. We define the strength of the association of w and pi as follows : Aµ ( w , pi ) = Prµ ( w , pi ) Pr µ ( w )</definiens>
				<definiens id="1">the probability of w participating in the µ relationship</definiens>
			</definition>
			<definition id="4">
				<sentence>Ss ( θj|w , T ) = M ( θj , T ) µ ( T ) ( 3 ) The score for w to take sense θj in a target sentence T is the sum of St ( θj|w , T ) defined in ( 2 ) and Ss ( θj|w , T ) defined in ( 3 ) , so the sense of w in T will be set to the sense defined in ( 4 ) when the score exceeds a selected threshold .</sentence>
				<definiendum id="0">Ss</definiendum>
				<definiens id="0">the sum</definiens>
			</definition>
</paper>

		<paper id="0804">
			<definition id="0">
				<sentence>HMM is one of the effective translation models ( Vogel et al. , 1996 ) , which is easily scalable to very large training corpus .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">one of the effective translation models</definiens>
			</definition>
			<definition id="1">
				<sentence>Each French word fj is an observation , and it is generated by a HMM state defined as [ eaj , aj ] , where the alignment aj for position j is considered to have a dependency on the previous alignment aj−1 .</sentence>
				<definiendum id="0">French word fj</definiendum>
				<definiens id="0">an observation , and it is generated by a HMM state defined as [ eaj , aj ] , where the alignment aj for position j is considered to have a dependency on the previous alignment aj−1</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus the first-order HMM is defined as follows : P ( fJ1 |eI1 ) = summationdisplay aJ1 Jproductdisplay j=1 P ( fj|eaj ) P ( aj|aj−1 ) , ( 2 ) where P ( aj|aj−1 ) is the transition probability .</sentence>
				<definiendum id="0">HMM</definiendum>
			</definition>
			<definition id="3">
				<sentence>Thus a uniform prior P ( Fj ) = 1/|F| is introduced as a smoothing factor for P ( Fj|Eaj ) : P ( Fj|Eaj ) = λP ( Fj|Eaj ) + ( 1−λ ) P ( Fj ) , ( 5 ) where |F| is the total number of word clusters in French ( we use the same number of clusters for both languages ) .</sentence>
				<definiendum id="0">|F|</definiendum>
				<definiens id="0">a smoothing factor for P ( Fj|Eaj ) : P ( Fj|Eaj ) = λP ( Fj|Eaj ) +</definiens>
			</definition>
			<definition id="4">
				<sentence>We define the vocabulary VF as the French vocabulary with a size of |VF| ; VE as the English vocabulary with size of |VE| .</sentence>
				<definiendum id="0">vocabulary VF</definiendum>
				<definiens id="0">the French vocabulary with a size of |VF|</definiens>
			</definition>
			<definition id="5">
				<sentence>With C { F , E } , we can infer two affinity matrixes as follows : AE = CT { F , E } C { F , E } AF = C { F , E } CT { F , E } , where AE is an |VE|×|VE| affinity matrix for English words , with rows and columns representing English words and each element the inner product between two English words column vectors .</sentence>
				<definiendum id="0">AE</definiendum>
			</definition>
			<definition id="6">
				<sentence>Correspondingly , AF is an affinity matrix of size |VF|× |VF| for French words with similar definitions .</sentence>
				<definiendum id="0">AF</definiendum>
				<definiens id="0">an affinity matrix of size |VF|× |VF| for French words with similar definitions</definiens>
			</definition>
			<definition id="7">
				<sentence>S is a diagonal matrix , with the singular values ranked from large to small along the diagonal .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">a diagonal matrix , with the singular values ranked from large to small along the diagonal</definiens>
			</definition>
			<definition id="8">
				<sentence>HMM2 gives the best performance in terms of F-measure of word alignment .</sentence>
				<definiendum id="0">HMM2</definiendum>
				<definiens id="0">gives the best performance in terms of F-measure of word alignment</definiens>
			</definition>
</paper>

		<paper id="1627">
			<definition id="0">
				<sentence>Looking at the MapTask corpus from the perspective of GRE , we make the following observations : • The MapTask corpus consists of transcriptions of spoken language and contains many disfluencies .</sentence>
				<definiendum id="0">MapTask corpus</definiendum>
				<definiens id="0">consists of transcriptions of spoken language and contains many disfluencies</definiens>
			</definition>
			<definition id="1">
				<sentence>In sum , the MapTask corpus contains a wealth of data combined with a domain model ( the maps ) .</sentence>
				<definiendum id="0">MapTask corpus</definiendum>
				<definiens id="0">contains a wealth of data combined with a domain model ( the maps )</definiens>
			</definition>
</paper>

		<paper id="0821">
			<definition id="0">
				<sentence>Statistical machine translation ( SMT ) makes use of a noisy channel model where a sentence ¯e in the desired language can be conceived of as originating as a sentence ¯f in a source language .</sentence>
				<definiendum id="0">SMT</definiendum>
				<definiens id="0">makes use of a noisy channel model where a sentence ¯e in the desired language can be conceived of as originating as a sentence ¯f in a source language</definiens>
			</definition>
			<definition id="1">
				<sentence>P ( ¯e ) is a language model specifying the probability of target language strings .</sentence>
				<definiendum id="0">P ( ¯e )</definiendum>
				<definiens id="0">a language model specifying the probability of target language strings</definiens>
			</definition>
			<definition id="2">
				<sentence>A factored language model ( FLM ) ( Bilmes and Kirchhoff , 2003 ) is based on a representation of words as feature vectors and can utilize a variety of additional information sources in addition to words , such as part-of-speech ( POS ) information , morphological information , or semantic features , in a unified and principled framework .</sentence>
				<definiendum id="0">factored language model</definiendum>
				<definiendum id="1">FLM )</definiendum>
				<definiens id="0">based on a representation of words as feature vectors and can utilize a variety of additional information sources in addition to words</definiens>
			</definition>
			<definition id="3">
				<sentence>In standard Katz-style backoff , the maximum-likelihood estimate of an n-gram with too few observations in the training data is replaced with a probability derived from the lower-order ( n 1 ) gram and a backoff weight as follows : pBO ( wtjwt−1 , wt−2 ) ( 4 ) = braceleftbigg d cpML ( wtjwt−1 , wt−2 ) if c &gt; τ α ( wt−1 , wt−2 ) pBO ( wtjwt−1 ) otherwise where c is the count of ( wt , wt−1 , wt−2 ) , pML denotes the maximum-likelihood estimate , τ is a count threshold , dc is a discounting factor and α ( wt−1 , wt−2 ) is a normalization factor .</sentence>
				<definiendum id="0">c</definiendum>
				<definiendum id="1">pML</definiendum>
				<definiens id="0">the maximum-likelihood estimate of an n-gram with too few observations in the training data is replaced with a probability derived from the lower-order ( n 1 ) gram and a backoff weight as follows : pBO ( wtjwt−1 , wt−2 )</definiens>
				<definiens id="1">the maximum-likelihood estimate , τ is a count threshold</definiens>
			</definition>
</paper>

		<paper id="0707">
			<definition id="0">
				<sentence>Amharic is one of the most widely spoken languages in Ethiopia .</sentence>
				<definiendum id="0">Amharic</definiendum>
				<definiens id="0">one of the most widely spoken languages in Ethiopia</definiens>
			</definition>
			<definition id="1">
				<sentence>Word formation involves prefixation , suffixation , infixation , reduplication , and Semitic stem interdigitation , among others .</sentence>
				<definiendum id="0">Word formation</definiendum>
				<definiens id="0">involves prefixation , suffixation , infixation , reduplication , and Semitic stem interdigitation , among others</definiens>
			</definition>
			<definition id="2">
				<sentence>On the other hand , the ye+NOUN construction is a simple morphological variant of the NOUN that can easily be recognized .</sentence>
				<definiendum id="0">ye+NOUN construction</definiendum>
				<definiens id="0">a simple morphological variant of the NOUN that can easily be recognized</definiens>
			</definition>
			<definition id="3">
				<sentence>P ( y | x ) = 1 Z ( x ) exp parenleftBiggsummationdisplay t=1 summationdisplay k λkfk ( t , yt−1 , yt , x ) parenrightBigg , where Z ( x ) is the normalization factor , X = { x1 , ... , xn } is the observation sequence , Y = { y1 , ... , yT } is the label sequences , fk and λk are the feature functions and their corresponding weights respectively ( Lafferty et al. , 2001 ) .</sentence>
				<definiendum id="0">Z ( x )</definiendum>
				<definiendum id="1">, xn }</definiendum>
				<definiendum id="2">yT }</definiendum>
				<definiens id="0">the normalization factor , X = { x1 , ...</definiens>
			</definition>
			<definition id="4">
				<sentence>The training data for segmentation task consists of 5 news articles in which the words are annotated with segment boundaries as shown in the following example. . . . &lt; seg &gt; Ind &lt; /seg &gt; &lt; seg &gt; astawequt &lt; /seg &gt; # &lt; seg &gt; le &lt; /seg &gt; &lt; seg &gt; arso &lt; /seg &gt; # &lt; seg &gt; aderu &lt; /seg &gt; # &lt; seg &gt; be &lt; /seg &gt; &lt; seg &gt; temeTaTaN &lt; /seg &gt; . . . In this example , the morphemes are enclosed in &lt; seg &gt; and &lt; /seg &gt; XML tags .</sentence>
				<definiendum id="0">segmentation task</definiendum>
				<definiens id="0">consists of 5 news articles in which the words are annotated with segment boundaries as shown in the following example.</definiens>
			</definition>
			<definition id="5">
				<sentence>The negative tag ( N ) is assigned to the special symbol # used to indicate the word boundary .</sentence>
				<definiendum id="0">negative tag</definiendum>
				<definiens id="0">assigned to the special symbol # used to indicate the word boundary</definiens>
			</definition>
			<definition id="6">
				<sentence>The character features consist of the current character , the five characters to the left and to the right of the current characters .</sentence>
				<definiendum id="0">character features</definiendum>
				<definiens id="0">consist of the current character , the five characters to the left and to the right of the current characters</definiens>
			</definition>
			<definition id="7">
				<sentence>The lexical features consist of the current word , the two words to the left and to the right of the current word .</sentence>
				<definiendum id="0">lexical features</definiendum>
				<definiens id="0">consist of the current word , the two words to the left and to the right of the current word</definiens>
			</definition>
</paper>

		<paper id="1614">
			<definition id="0">
				<sentence>Computer pun-generators have so far relied on arbitrary semantic content , not linked to the immediate context .</sentence>
				<definiendum id="0">Computer pun-generators</definiendum>
				<definiens id="0">arbitrary semantic content , not linked to the immediate context</definiens>
			</definition>
			<definition id="1">
				<sentence>The precondition consists of a conjunction of terms , where each term is a predicate ( e.g. homophone ) applied to variable arguments , and all variables are existentially quantified .</sentence>
				<definiendum id="0">precondition</definiendum>
				<definiens id="0">consists of a conjunction of terms , where each term is a predicate ( e.g. homophone ) applied to variable arguments , and all variables are existentially quantified</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , one schema ( from [ Ritchie , 2003 ] ) has the precondition : noun_phrase ( NPLex ) , component_lexemes ( NPLex , LexA , LexB ) , written_form ( [ LexA ] , WordA ) , homophone ( WordA , HomWord ) , written_form ( [ HomLex ] , HomWord ) where some of the variables ( NPLex , LexA , LexB , HomLex ) are to be matched against lexemes ( abstract identifiers for lexical entries ) and others ( WordA , HomWord ) are matched against surface strings .</sentence>
				<definiendum id="0">NPLex</definiendum>
				<definiens id="0">some of the variables ( NPLex , LexA , LexB , HomLex ) are to be matched against lexemes ( abstract identifiers for lexical entries</definiens>
			</definition>
			<definition id="3">
				<sentence>Loehr explores limited contextual linking , based on keywords ( for example , using a joke involving the word aid when help was needed ) .</sentence>
				<definiendum id="0">Loehr</definiendum>
				<definiens id="0">explores limited contextual linking , based on keywords</definiens>
			</definition>
			<definition id="4">
				<sentence>CS reduces processing in cases where the possible values of the variables are well-defined and easily enumerable , and evaluating individual constraints is relatively cheap ; i.e. where the main computational load is in testing compatibility among chains of values .</sentence>
				<definiendum id="0">CS</definiendum>
				<definiens id="0">reduces processing in cases where the possible values of the variables are well-defined and easily enumerable</definiens>
			</definition>
</paper>

		<paper id="0212">
			<definition id="0">
				<sentence>E-Speech’s letter-to-phoneme ( LTP ) software , developed over many years for text-to-speech and speech recognition applications , uses proprietary rules to produce pronunciations for any input text .</sentence>
				<definiendum id="0">E-Speech’s letter-to-phoneme</definiendum>
				<definiens id="0">developed over many years for text-to-speech and speech recognition applications</definiens>
			</definition>
			<definition id="1">
				<sentence>Word : photograph Pronunciation Rules Click to see : Rule : ph → f more words &amp; exceptions Rule : o → oʊ in o.V more words &amp; exceptions Rule : t → t more words &amp; exceptions Rule : o → ɑ : , Reduction ɑ : → ə more words &amp; exceptions Rule : g → g more words &amp; exceptions Rule : r → r more words &amp; exceptions Rule : a → æ more words &amp; exceptions Rule : ph → f more words &amp; exceptions Pronunciation : ‘foʊ tə græf Syllable-by-Syllable : ‘foʊ tə græf 78 pronunciation by clicking on one of several options , represented in the International Phonetic Alphabet ( IPA ) or by clicking on a speaker-symbol , so that he can hear the options spoken .</sentence>
				<definiendum id="0">Pronunciation</definiendum>
				<definiens id="0">a → æ more words &amp; exceptions Rule : ph → f more words &amp; exceptions</definiens>
			</definition>
</paper>

	</volume>
