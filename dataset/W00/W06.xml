<?xml version="1.0" encoding="UTF-8"?>
	<volume id="W06">

		<paper id="1513">
			<definition id="0">
				<sentence>The definitory properties of TAG elementary trees provide a natural way to assign polarities to a TAG lexical entries : each elementary tree can be associated with a polarity +C , where C is the category of its root node and each substitution or foot node in that tree , a polarity −C is added , where C is the category of that node .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">definitory properties of TAG elementary trees provide a natural way to assign polarities to a TAG lexical entries</definiens>
			</definition>
			<definition id="1">
				<sentence>To avoid this shortcoming , a common practice ( CCFP99 ) consists in specifying a set of rules which selects empty semantic items on the basis of the input literals .</sentence>
				<definiendum id="0">CCFP99</definiendum>
				<definiens id="0">consists in specifying a set of rules which selects empty semantic items on the basis of the input literals</definiens>
			</definition>
</paper>

		<paper id="2303">
			<definition id="0">
				<sentence>PropBank encodes propositional information by adding a layer of argument structure annotation to the syntactic structures of the Penn Treebank ( Marcus et al. , 1993 ) .</sentence>
				<definiendum id="0">PropBank</definiendum>
			</definition>
			<definition id="1">
				<sentence>Verbal predicates in the Penn Treebank ( PTB ) receive a label REL and their arguments are annotated with abstract semantic role labels A0-A5 or AA for those complements of the predicative verb that are considered arguments while those complements of the verb labelled with a semantic functional label in the original PTB receive the composite semantic role label AM-X , where X stands for labels such as LOC , TMP or ADV , for locative , temporal and adverbial modifiers respectively .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">locative , temporal and adverbial modifiers respectively</definiens>
			</definition>
			<definition id="2">
				<sentence>The set of well-formed sequences of derivation moves in this parser is defined by a Predictive LR pushdown automaton ( Nederhof , 1994 ) , which implements a form of left-corner parsing strategy .</sentence>
				<definiendum id="0">Predictive LR pushdown automaton</definiendum>
				<definiens id="0">implements a form of left-corner parsing strategy</definiens>
			</definition>
			<definition id="3">
				<sentence>However , the recency preference exhibited by recursively defined neural networks biases learning towards information which flows through fewer history representations .</sentence>
				<definiendum id="0">recency preference</definiendum>
				<definiens id="0">exhibited by recursively defined neural networks biases learning towards information which flows through fewer history representations</definiens>
			</definition>
			<definition id="4">
				<sentence>The580newlyintroduced labels consist of a standard PTB label followed by a set of one or more PropBank semantic role such as PP-AM-TMP or NP-A0-A1 .</sentence>
				<definiendum id="0">The580newlyintroduced labels</definiendum>
				<definiens id="0">consist of a standard PTB label followed by a set of one or more PropBank semantic role such as PP-AM-TMP or NP-A0-A1</definiens>
			</definition>
</paper>

		<paper id="3304">
			<definition id="0">
				<sentence>The Gene Ontology provides three orthogonal networks of functional genomic concepts struc1 http : //www.geneontology.org .</sentence>
				<definiendum id="0">Gene Ontology</definiendum>
			</definition>
			<definition id="1">
				<sentence>tured in terms of semantic relationships such as inheritance and meronymy , which encode biological process ( BP ) , molecular function ( MF ) and cellular component ( CC ) properties of genes and gene products .</sentence>
				<definiendum id="0">meronymy</definiendum>
				<definiens id="0">encode biological process ( BP ) , molecular function ( MF ) and cellular component ( CC ) properties of genes and gene products</definiens>
			</definition>
			<definition id="2">
				<sentence>The information content of a concept node c , IC ( c ) , is computed as -log p ( c ) where p ( c ) indicates the probability of encountering instances of c in a specific corpus .</sentence>
				<definiendum id="0">IC ( c )</definiendum>
				<definiendum id="1">p ( c )</definiendum>
				<definiens id="0">information content of a concept node c</definiens>
				<definiens id="1">indicates the probability of encountering instances of c in a specific corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>The XOA similarity between c1 and c2 is defined as shown in ( 4 ) , where 4 • cos ( ci , cj ) denotes the cosine associative measure proposed by Bodenreider et al. ( 2005 ) • sim ( ci , cj ) denotes any of the three intraontological semantic similarities described above , see ( 1 ) - ( 3 ) • max ci in Oj { f ( ci ) } denotes the maximum of the function f ( ) over all GO codes ci in the gene ontology Oj .</sentence>
				<definiendum id="0">XOA similarity</definiendum>
				<definiendum id="1">c2</definiendum>
				<definiendum id="2">ci , cj )</definiendum>
				<definiendum id="3">f ( ci ) }</definiendum>
				<definiens id="0">the cosine associative measure proposed by Bodenreider et al. ( 2005 ) • sim ( ci , cj ) denotes any of the three intraontological semantic similarities described above , see ( 1 ) - ( 3 ) • max ci in Oj {</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , a comparative evaluation of protein similarity , following the benchmark study of Lord et al. ( 2002 , 2003 ) , reveals that XOA provides the basis for a better correlation with protein sequence similarities as measured by BLAST bit score than any intra-ontological semantic similarity measure .</sentence>
				<definiendum id="0">XOA</definiendum>
				<definiens id="0">measured by BLAST bit score than any intra-ontological semantic similarity measure</definiens>
			</definition>
			<definition id="5">
				<sentence>The XOA similarity between GP1 and GP2 is defined as in ( 5 ) , where i=1 , … , n and j=1 , … , m. ( 5 ) XOA ( GP1 , GP2 ) = max { XOA ( c1i , c2j ) } The results of the study by Posse et al. ( 2006 ) are shown in Table 1 .</sentence>
				<definiendum id="0">XOA similarity</definiendum>
				<definiendum id="1">GP2</definiendum>
				<definiendum id="2">XOA</definiendum>
				<definiens id="0">i=1 , … , n and j=1 , …</definiens>
			</definition>
			<definition id="6">
				<sentence>( 6 ) Fusion ( Lin ) = XOA L + LC*Ave ( XOA L ) /Ave ( XOA R ) Fusion ( Jiang &amp; Conrath ) = XOA JC + LC*Ave ( XOA JC ) /Ave ( XOA R ) The second strategy consists in building a prediction model for BLAST bit score ( BBS ) using the XOA score and the log-cosine LC as predictors without the constraint of remaining interpretable .</sentence>
				<definiendum id="0">Fusion</definiendum>
			</definition>
</paper>

		<paper id="3503">
			<definition id="0">
				<sentence>RAINBOW is a tool for developing bag of words ( BOW ) text classifiers ( McCallum and Nigam , 1998 ) .</sentence>
				<definiendum id="0">RAINBOW</definiendum>
			</definition>
			<definition id="1">
				<sentence>Then discourse level processing attempts to resolve nominal and temporal anaphora and ellipsis to produce the candidate FOPL representation for a sentence ( Jordan and VanLehn , 2002 ) .</sentence>
				<definiendum id="0">discourse level processing</definiendum>
				<definiens id="0">attempts to resolve nominal and temporal anaphora and ellipsis to produce the candidate FOPL representation for a sentence</definiens>
			</definition>
</paper>

		<paper id="1509">
			<definition id="0">
				<sentence>This yields the reading where John is the antecedent of himself .</sentence>
				<definiendum id="0">John</definiendum>
				<definiens id="0">the antecedent of himself</definiens>
			</definition>
			<definition id="1">
				<sentence>Extraction of a phrase containing an anaphor , whether topicalization or ( 17 ) or wh-movement ( 18 ) , does not induce a Condition A violation .</sentence>
				<definiendum id="0">Extraction</definiendum>
				<definiens id="0">does not induce a Condition A violation</definiens>
			</definition>
</paper>

		<paper id="1620">
			<definition id="0">
				<sentence>Precision grammars are defined as implemented grammars of natural language which capture finegrained linguistic distinctions , and are generative in the sense of distinguishing between grammatical and ungrammatical inputs ( or at least have some in-built notion of linguistic “markedness” ) .</sentence>
				<definiendum id="0">Precision grammars</definiendum>
				<definiens id="0">implemented grammars of natural language which capture finegrained linguistic distinctions , and are generative in the sense of distinguishing between grammatical and ungrammatical inputs</definiens>
			</definition>
			<definition id="1">
				<sentence>The Grammar Matrix is a framework for streamlining and standardising HPSG-based multilingual grammar development .</sentence>
				<definiendum id="0">Grammar Matrix</definiendum>
				<definiens id="0">a framework for streamlining and standardising HPSG-based multilingual grammar development</definiens>
			</definition>
			<definition id="2">
				<sentence>Fouvry uses the grammar to guide the process of learning lexical items for unknown words , by generating underspecified lexical items for all unknown words and parsing with them .</sentence>
				<definiendum id="0">Fouvry</definiendum>
				<definiens id="0">uses the grammar to guide the process of learning lexical items for unknown words</definiens>
			</definition>
			<definition id="3">
				<sentence>in which the lexical type of n c le encodes the fact that dog is a noun which does not subcategorise for any other constituents and which is countable , `` dog '' specifies the lexical stem , and `` dog n 1 rel '' introduces an ad hoc predicate name for the lexical item to use in constructing a semantic representation .</sentence>
				<definiendum id="0">n c le</definiendum>
				<definiens id="0">countable , `` dog '' specifies the lexical stem , and `` dog n 1 rel '' introduces an ad hoc predicate name for the lexical item to use in constructing a semantic representation</definiens>
			</definition>
			<definition id="4">
				<sentence>We use L-BFGS , an iterative quasi-Newton optimisation method , which performs well for training log-linear models ( Malouf , 2002 ; Sha and Pereira , 2003 ) .</sentence>
				<definiendum id="0">iterative quasi-Newton optimisation method</definiendum>
				<definiens id="0">performs well for training log-linear models</definiens>
			</definition>
			<definition id="5">
				<sentence>Evaluation is based on the treebank data associated with each grammar , and a random training– test split of 20,000 training sentences and 1,013 test sentences in the case of the ERG , and 40,000 training sentences and 1,095 test sentences in the case of the JACY .</sentence>
				<definiendum id="0">Evaluation</definiendum>
				<definiens id="0">based on the treebank data associated with each grammar , and a random training– test split of 20,000 training sentences and 1,013 test sentences in the case of the ERG , and 40,000 training sentences and 1,095 test sentences in the case of the JACY</definiens>
			</definition>
			<definition id="6">
				<sentence>As such , we identify all unknown lexical items in the test data and evaluate according to : token accuracy ( the proportion of unknown lexical items which are correctly tagged : ACCa11 ) ; type precision ( the proportion of correctly hypothesised unknown lexical entries : PREC ) ; type recall ( the proportion of goldstandard unknown lexical entries for which we get a correct prediction : REC ) ; and type F-score ( the harmonic mean of type precision and type recall : F-SCORE ) .</sentence>
				<definiendum id="0">; type precision</definiendum>
				<definiendum id="1">type recall</definiendum>
				<definiendum id="2">type F-score</definiendum>
				<definiens id="0">unknown lexical items in the test data and evaluate according to : token accuracy ( the proportion of unknown lexical items which are correctly tagged : ACCa11 )</definiens>
			</definition>
			<definition id="7">
				<sentence>FNTBL is a transformation-based learner that is distributed with pre-optimised POS tagging modules for English and other European languages that can be redeployed over the task of supertagging .</sentence>
				<definiendum id="0">FNTBL</definiendum>
			</definition>
</paper>

		<paper id="1110">
			<definition id="0">
				<sentence>NCs are noun chunks , PC is a prepositional chunk , and VCL is the finite verb chunk .</sentence>
				<definiendum id="0">PC</definiendum>
				<definiendum id="1">VCL</definiendum>
				<definiens id="0">the finite verb chunk</definiens>
			</definition>
			<definition id="1">
				<sentence>KaRoPars ( M¨uller and Ule , 2002 ) is a partial parser for German , based on the finite-state technology of the TTT suite of tools ( Grover et al. , 1999 ) .</sentence>
				<definiendum id="0">KaRoPars</definiendum>
				<definiens id="0">a partial parser for German , based on the finite-state technology of the TTT suite of tools</definiens>
			</definition>
			<definition id="2">
				<sentence>HD − HD HD HD − HD − HD − ADJX − HD VXFIN HD ADJX − HD NX HD NX − NX HD NX − − ADJX − HD − NX HD NX ON NX OA PX V−MOD VF − LK − MF − SIMPX Figure 1 : The T¨uBa-D/Z tree for sentence ( 1a ) .</sentence>
				<definiendum id="0">HD − HD HD HD − HD − HD − ADJX − HD VXFIN HD ADJX − HD NX HD NX − NX HD NX − − ADJX − HD − NX HD NX ON NX OA</definiendum>
			</definition>
			<definition id="3">
				<sentence>The matrix clause consists of a complex subject noun phrase ( GF : ON ) , a finite verb phrase , which is the head of the sentence , an accusative noun phrase ( GF : OA ) , a verb particle ( GF : VPT ) , and an extraposed relative clause ( GF : ON-MOD ) .</sentence>
				<definiendum id="0">matrix clause</definiendum>
				<definiendum id="1">GF</definiendum>
				<definiendum id="2">finite verb phrase</definiendum>
				<definiens id="0">the head of the sentence , an accusative noun phrase ( GF : OA ) , a verb particle ( GF : VPT ) , and an extraposed relative clause ( GF : ON-MOD )</definiens>
			</definition>
</paper>

		<paper id="3319">
</paper>

		<paper id="1309">
			<definition id="0">
				<sentence>G : no R : OK G : start again from the palm beach 60 G has failed to find the swamp , which means G has failed to perform the action necessary to perform the next one ( take a slight curve ) .</sentence>
				<definiendum id="0">G</definiendum>
				<definiens id="0">no R : OK G : start again from the palm beach 60 G has failed to find the swamp</definiens>
			</definition>
			<definition id="1">
				<sentence>In the slot-filling case , the inference algorithm is to determine whether the semantic type of the answer given by the user match the type that was expected by the dialogue system .</sentence>
				<definiendum id="0">inference algorithm</definiendum>
				<definiens id="0">to determine whether the semantic type of the answer given by the user match the type that was expected by the dialogue system</definiens>
			</definition>
			<definition id="2">
				<sentence>As a consequence , we can consider the logical relation between the current task , the solution organized by the system , and the computed error diagnosis as sufficient conditions for any discourse relation to hold between the user and the 64 Actions up to now System state Expected state Error Diagnosis after go-in-place put-cup-on-spout ( ready jura ) none draw-off-osc ( ready robo ) none produce-coffee ¬ ( parked cup ) none go-in-place ¬ ( empty cup ) none ¬ ( robo-loaded robo ) none ( mode-osc jura ) none ( in-place train ) none ( under-spout cup ) none Last Action Observed state take-cup-off-spout ( under-spout cup ) ¬ ( under-spout cup ) robo could not ¬ ( robo-loaded robo ) ( robo-loaded robo ) hold the cup Figure 7 : Context information for the diagnosis of an error system utterance in the dialogue excerpt above : In terms of TRAUM’s DU acts ( Traum , 1994 ) , coherence between both utterances is established as a reject relation as the purpose of the utterance is to indicate failure of the task that has been initiated by the user request .</sentence>
				<definiendum id="0">reject relation</definiendum>
				<definiens id="0">to indicate failure of the task that has been initiated by the user request</definiens>
			</definition>
</paper>

		<paper id="2912">
			<definition id="0">
				<sentence>2 Unsupervised data-oriented parsing At a general level , U-DOP consists of the following three steps : sentences of DOP sentence Note that in unsupervised parsing we do not need to split the data into a training and a test set .</sentence>
				<definiendum id="0">U-DOP</definiendum>
				<definiens id="0">consists of the following three steps : sentences of DOP sentence Note that in unsupervised parsing we do not need to split the data into a training and a test set</definiens>
			</definition>
			<definition id="1">
				<sentence>NNS VBD Investors suffered X X S VBD suffered X X NNS NNS Investors losses X X S JJ NNS heavy losses XX S JJ NNS heavy losses X NNS VBD Investors suffered X VBD JJ suffered heavy X Figure 2 .</sentence>
				<definiendum id="0">NNS VBD</definiendum>
				<definiens id="0">Investors suffered X X S VBD suffered X X NNS NNS Investors losses X X S JJ NNS heavy losses XX S JJ NNS heavy losses X NNS VBD Investors suffered X VBD JJ suffered heavy X Figure 2</definiens>
			</definition>
			<definition id="2">
				<sentence>The notation A @ k denotes the node at address k where A is the nonterminal labeling that node .</sentence>
				<definiendum id="0">notation A @ k</definiendum>
				<definiens id="0">the node at address k where A is the nonterminal labeling that node</definiens>
			</definition>
			<definition id="3">
				<sentence>Yet , the PCFG reduction in figure 4 can be used to estimate DOP 's most probable parse tree by a Viterbi n-best search in combination with a CKY parser which computes the n most likely derivations and next sums up the probabilities of the derivations producing the same tree .</sentence>
				<definiendum id="0">PCFG reduction</definiendum>
				<definiendum id="1">CKY parser</definiendum>
				<definiens id="0">computes the n most likely derivations and next sums up the probabilities of the derivations producing the same tree</definiens>
			</definition>
			<definition id="4">
				<sentence>The two metrics of UP and UR are combined by the unlabled f-score F1 which is defined as the harmonic mean of UP and UR : F1 = 2*UP*UR/ ( UP+UR ) .</sentence>
				<definiendum id="0">f-score F1</definiendum>
				<definiens id="0">the harmonic mean of UP and UR</definiens>
			</definition>
			<definition id="5">
				<sentence>The CTB10 is the subset of p-o-s strings from the Penn Chinese treebank containing 10 words or less after removal of punctuation ( 2437 strings ) .</sentence>
				<definiendum id="0">CTB10</definiendum>
				<definiens id="0">the subset of p-o-s strings from the Penn Chinese treebank containing 10 words or less after removal of punctuation ( 2437 strings )</definiens>
			</definition>
			<definition id="6">
				<sentence>The NEGRA10 is the subset of p-o-s strings of the same length from the NEGRA corpus using the supplied converson into Penn treebank format ( 2175 strings ) .</sentence>
				<definiendum id="0">NEGRA10</definiendum>
				<definiens id="0">the subset of p-o-s strings of the same length from the NEGRA corpus using the supplied converson into Penn treebank format ( 2175 strings )</definiens>
			</definition>
			<definition id="7">
				<sentence>sentences ( up to 40 words ) We were also interested in U-DOP 's performance on a held-out test set such that we could compare the model with a supervised PCFG treebank grammar trained and tested on the same data ( S-PCFG ) .</sentence>
				<definiendum id="0">sentences</definiendum>
				<definiens id="0">a supervised PCFG treebank grammar trained and tested on the same data ( S-PCFG )</definiens>
			</definition>
</paper>

		<paper id="1312">
			<definition id="0">
				<sentence>Neither the author’s abstract , nor raw citation counts help users in assessing the relation between articles .</sentence>
				<definiendum id="0">raw citation counts</definiendum>
				<definiens id="0">users in assessing the relation between articles</definiens>
			</definition>
			<definition id="1">
				<sentence>7Following Carletta ( 1996 ) , we measure agreement in Kappa , which follows the formula K = P ( A ) −P ( E ) 1−P ( E ) where P ( A ) is observed , and P ( E ) expected agreement .</sentence>
				<definiendum id="0">7Following Carletta</definiendum>
				<definiens id="0">follows the formula K = P ( A ) −P ( E ) 1−P ( E ) where P ( A ) is observed , and P ( E ) expected agreement</definiens>
			</definition>
</paper>

		<paper id="2503">
			<definition id="0">
				<sentence>There are however many systems using man-made resources , particularly WordNet , which have other purposes in mind , such as entailment for applications such as question-answering and information-extraction ( Dagan et al. , 2005 ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>Disambiguation is performed using the first sense heuristic from i ) SemCor ( Semcor FS ) ii ) automatic rankings from the BNC produced using the method proposed by McCarthy et al. ( 2004 ) ( Auto FS ) and iii ) an upper-bound first sense heuristic from the SEVAL-2 ENG LEX data itself ( SEVAL-2 FS ) .</sentence>
				<definiendum id="0">Disambiguation</definiendum>
			</definition>
</paper>

		<paper id="3314">
			<definition id="0">
				<sentence>BioKI : Enzymes is a literature navigation system that uses a two-step process .</sentence>
				<definiendum id="0">BioKI</definiendum>
				<definiens id="0">a literature navigation system that uses a two-step process</definiens>
			</definition>
</paper>

		<paper id="3605">
			<definition id="0">
				<sentence>The POS tagger generates a set of tag sequences that are compatible with the sentence text .</sentence>
				<definiendum id="0">POS tagger</definiendum>
				<definiens id="0">generates a set of tag sequences that are compatible with the sentence text</definiens>
			</definition>
			<definition id="1">
				<sentence>For instance , when assigning POS tags to the words of a sentence , the degree of completion could be defined as the number of words assigned with a POS tag so far , divided by the total number of words in the sentence .</sentence>
				<definiendum id="0">completion</definiendum>
				<definiens id="0">the number of words assigned with a POS tag so far , divided by the total number of words in the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Let δk ( si , n ) = fk ( si ) − fk ( si , n ) ( 3 ) be the difference between the scores of si and si , n. That is , δk ( si , n ) is the error in score caused by the incompleteness of the partial solution si , n. As the solutions are generated incrementally , the exact value of δk ( si , n ) is not known at the moment of generating si , n because the solution si has not been completed 34 yet .</sentence>
				<definiendum id="0">n )</definiendum>
				<definiens id="0">the difference between the scores of si and si</definiens>
				<definiens id="1">the error in score caused by the incompleteness of the partial solution si</definiens>
			</definition>
			<definition id="3">
				<sentence>However , we can model the error based on the knowledge of si , n. We assume that , for a given si , n , the error δk ( si , n ) is a random variable distributed according to a probability distribution with a density function ∆k , denoted as δk ( si , n ) ∼ ∆k ( δ ; si , n ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">n )</definiendum>
				<definiens id="0">a random variable distributed according to a probability distribution with a density function ∆k</definiens>
			</definition>
			<definition id="4">
				<sentence>( 4 ) The partial solution si , n is a parameter to the distribution and , in theory , each partial solution gives rise to a different distribution of the same general shape .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a parameter to the distribution and , in theory , each partial solution gives rise to a different distribution of the same general shape</definiens>
			</definition>
			<definition id="5">
				<sentence>Therefore , assuming independence , its density is the convolution of the densities of these variables , that is , given si , n , d ( f ; si , n ) = ( d1 ∗ . . . ∗ dM ) ( f ; si , n ) , ( 7 ) and f ( si ) ∼ d ( f ; si , n ) .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">the convolution of the densities of these variables , that is , given si , n , d ( f ; si , n ) = ( d1 ∗</definiens>
			</definition>
			<definition id="6">
				<sentence>We thus have d ( f ; si , n ) = nparenleftbigf ; µ ( si , n ) , σ2 ( si , n ) parenrightbig , ( 9 ) where n is the normal density function .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="7">
				<sentence>The algorithm is to a large extent related to the Astar search algorithm , which maintains a priority queue of partial solutions , ordered according to a score g ( x ) + h ( x ) , where g ( x ) is the score of x and h ( x ) is a heuristic overestimate2 of the final score of the goal reached from x. Here , the maximal expected score of a partial solution is an overestimate with the probability of 1−ε and can be viewed as a probabilistic counterpart of the Astar heuristic component h ( x ) .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiendum id="1">score g</definiendum>
				<definiendum id="2">g ( x )</definiendum>
				<definiendum id="3">h ( x )</definiendum>
				<definiens id="0">maintains a priority queue of partial solutions , ordered according to a</definiens>
				<definiens id="1">the maximal expected score of a partial solution is an overestimate with the probability of 1−ε and can be viewed as a probabilistic counterpart of the Astar heuristic component h</definiens>
			</definition>
			<definition id="8">
				<sentence>The overall score f ( si , n ) is defined as the sum of the scores assigned by the individual target functions fk .</sentence>
				<definiendum id="0">overall score f ( si , n )</definiendum>
			</definition>
			<definition id="9">
				<sentence>The kernel K is the product of two Gaussians , centered at ui and fi , respectively .</sentence>
				<definiendum id="0">kernel K</definiendum>
				<definiens id="0">the product of two Gaussians , centered at ui and fi , respectively</definiens>
			</definition>
			<definition id="10">
				<sentence>A partial parse is a sequence of n words from the beginning of the sentence , together with string encoding of their dependencies .</sentence>
				<definiendum id="0">partial parse</definiendum>
			</definition>
			<definition id="11">
				<sentence>The dataset consists of 200 sentences randomly selected from the BioInfer corpus of dependency-parsed sentences extracted from abstracts of biomedical research articles ( Pyysalo et al. , 2006 ) .</sentence>
				<definiendum id="0">dataset</definiendum>
			</definition>
			<definition id="12">
				<sentence>Let further TC be the number of iterations taken before the algorithm stops , and T be the total number of steps needed to generate all parses in S. Thus , |S| is the size of the search space measured in the number of parses , and T is the size of the search space measured in the number of steps .</sentence>
				<definiendum id="0">|S|</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the number of iterations taken before the algorithm stops , and T be the total number of steps needed to generate all parses in S. Thus ,</definiens>
				<definiens id="1">the size of the search space measured in the number of parses , and</definiens>
				<definiens id="2">the size of the search space measured in the number of steps</definiens>
			</definition>
			<definition id="13">
				<sentence>The most important criteria are rank ( ˆsC ) which measures how good the best found solution is , and TCT which measures the proportion of steps actually taken by the algorithm of the total number of steps needed to complete all the candidate solutions .</sentence>
				<definiendum id="0">TCT</definiendum>
				<definiens id="0">measures the proportion of steps actually taken by the algorithm of the total number of steps needed to complete all the candidate solutions</definiens>
			</definition>
			<definition id="14">
				<sentence>Clearly , ε rank ( ˆsC ) ord ( ˆs ) |SC||S| TCT Base 1.0 28.7 1.00 1.00 Table 1 : Average results over all sentences .</sentence>
				<definiendum id="0">ˆsC ) ord</definiendum>
				<definiens id="0">Average results over all sentences</definiens>
			</definition>
</paper>

		<paper id="2005">
			<definition id="0">
				<sentence>Morphological tagging is the process of assigning POS , case , number , gender and other morphological information to each word in a corpus .</sentence>
				<definiendum id="0">Morphological tagging</definiendum>
				<definiens id="0">the process of assigning POS , case , number , gender and other morphological information to each word in a corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Our morphological analyzer ( Hana , 2005 ) is an open and modular system .</sentence>
				<definiendum id="0">morphological analyzer</definiendum>
			</definition>
			<definition id="2">
				<sentence>Lexicon Acquisition consists of three steps : lexicon-less MA ( an MA using a list of mainly closed-class words and a paradigm based guesser ) ; these analyses are created .</sentence>
				<definiendum id="0">Lexicon Acquisition</definiendum>
				<definiens id="0">consists of three steps : lexicon-less MA ( an MA using a list of mainly closed-class words and a paradigm based guesser ) ; these analyses are created</definiens>
			</definition>
			<definition id="3">
				<sentence>Let Ts denote the tags that ws occurs within the Spanish corpus , and let ps ( t ) be the emission probability of a tag t ( t negationslash∈ Ts ⇒ ps ( t ) = 0 ) .</sentence>
				<definiendum id="0">Ts denote</definiendum>
				<definiens id="0">the tags that ws occurs within the Spanish corpus , and let ps ( t ) be the emission probability of a tag t ( t negationslash∈ Ts ⇒ ps ( t ) = 0 )</definiens>
			</definition>
</paper>

		<paper id="2922">
			<definition id="0">
				<sentence>Learning is based on techniques like SVM ( Vapnik 1998 ) or Memory Based Learning ( Daelemans 2003 ) , which provide high accuracy but are often computationally expensive .</sentence>
				<definiendum id="0">Learning</definiendum>
				<definiens id="0">based on techniques like SVM ( Vapnik 1998 ) or Memory Based Learning ( Daelemans 2003 ) , which provide high accuracy but are often computationally expensive</definiens>
			</definition>
			<definition id="1">
				<sentence>Here is an example of non-projectivity that can be handled with Right2 ( nejen → ale ) and Left3 ( fax → Většinu ) : Většinu těchto přístrojů lze take používat nejen jako fax , ale současně … The remaining cases are handled with the last two actions : Extract is used to postpone the creation of a link , by saving the token in a temporary stack ; Insert restores the token from the temporary stack and resumes normal processing .</sentence>
				<definiendum id="0">Insert restores</definiendum>
				<definiens id="0">the token from the temporary stack and resumes normal processing</definiens>
			</definition>
</paper>

		<paper id="2908">
			<definition id="0">
				<sentence>Semantic role labeling ( SRL ) is a task that recognizes the arguments of a predicate ( verb ) in a sentence and assigns the correct role to each argument .</sentence>
				<definiendum id="0">SRL</definiendum>
				<definiens id="0">a task that recognizes the arguments of a predicate ( verb ) in a sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Tree kernels calculate the similarity between trees , taking into consideration all of the subtrees , and , thereforethereisnoneedforsuchfeature engineering .</sentence>
				<definiendum id="0">Tree kernels</definiendum>
				<definiens id="0">calculate the similarity between trees , taking into consideration all of the subtrees , and , thereforethereisnoneedforsuchfeature engineering</definiens>
			</definition>
			<definition id="2">
				<sentence>In general , tree kernels can be calculated in O ( |T1||T2| ) time , where |Ti| is the number of nodes in tree Ti , using dynamic programming ( DP ) procedures ( Collins and Duffy , 2001 ; Kashima and Koyanagi , 2002 ) .</sentence>
				<definiendum id="0">tree kernels</definiendum>
				<definiendum id="1">|Ti|</definiendum>
				<definiendum id="2">DP ) procedures</definiendum>
				<definiens id="0">the number of nodes in tree Ti , using dynamic programming (</definiens>
			</definition>
			<definition id="3">
				<sentence>Given a parse tree , argument recognition can be cast as the classiﬁcation of tree nodes into two classes , ARG and NO-ARG .</sentence>
				<definiendum id="0">ARG</definiendum>
				<definiens id="0">the classiﬁcation of tree nodes into two classes</definiens>
			</definition>
			<definition id="4">
				<sentence>A kernel function K ( xi , xj ) is a function that calculates the inner product 〈Φ ( xi ) , Φ ( xj ) 〉 in thefeaturespacewithoutexplicitlycomputingΦ ( x ) , which is sometimes intractable .</sentence>
				<definiendum id="0">kernel function K</definiendum>
				<definiens id="0">a function that calculates the inner product 〈Φ ( xi ) , Φ ( xj ) 〉 in thefeaturespacewithoutexplicitlycomputingΦ ( x )</definiens>
			</definition>
			<definition id="5">
				<sentence>In this paper , ni is an ID assigned in the post-order traversal .</sentence>
				<definiendum id="0">ni</definiendum>
				<definiens id="0">an ID assigned in the post-order traversal</definiens>
			</definition>
			<definition id="6">
				<sentence>• |Ti| denotes the number of nodes in tree Ti .</sentence>
				<definiendum id="0">• |Ti|</definiendum>
				<definiens id="0">the number of nodes in tree Ti</definiens>
			</definition>
			<definition id="7">
				<sentence>Kazama and Torisawa ( 2005 ) presented a kernel on marked ordered trees ( the MOLT kernel ) , which is deﬁned as:2 K ( T1 , T2 ) = E∑ i=1 W ( Si ) · # Si ( T1 ) · # Si ( T2 ) , where Si is a possible subtree and # Si ( Tj ) is the number of times Si is included in Tj .</sentence>
				<definiendum id="0">Si</definiendum>
				<definiendum id="1">Si ( Tj )</definiendum>
				<definiens id="0">a possible subtree</definiens>
				<definiens id="1">the number of times Si is included in Tj</definiens>
			</definition>
			<definition id="8">
				<sentence>W ( Si ) = { λ|Si|∏ni∈Si γ ( m ( ni ) ) if marked ( Si ) , 0 otherwise , where γ ( m ) ( ≥ 1 ) is the weight of mark m. We call a kernel with this weight the WMOLT kernel .</sentence>
				<definiendum id="0">γ</definiendum>
				<definiens id="0">the weight of mark m. We call a kernel with this weight the WMOLT kernel</definiens>
			</definition>
			<definition id="9">
				<sentence>W ( Si ) = { λ|Si|γ # m ( Si ) if marked ( Si ) , 0 otherwise , where # m ( Si ) is the number of marked nodes in Si .</sentence>
				<definiendum id="0">Si</definiendum>
				<definiendum id="1">Si</definiendum>
				<definiendum id="2">Si )</definiendum>
				<definiens id="0">the number of marked nodes in Si</definiens>
			</definition>
			<definition id="10">
				<sentence>training size ( No. of sentences ) 250 500 700 1,000 setting dev test setting dev test setting dev test setting dev test γ ( λ , C ) ( F1 ) ( F1 ) ( λ , C ) ( F1 ) ( F1 ) ( λ , C ) ( F1 ) ( F1 ) ( λ , C ) ( F1 ) ( F1 ) 1 0.15 , 20.50 63.66 65.13 0.2 , 20.50 69.01 70.33 0.2 , 20.50 72.11 73.57 0.25 , 12.04 75.38 76.25 100 0.3 , 12.04 80.13 80.85 0.3,500 82.25 82.98 0.3 , 34.92 83.93 84.72 0.3 , 3.18 85.09 85.85 1,000 0.2 , 2.438 82.65 83.36 0.2 , 2.438 84.80 85.45 0.2 , 3.182 85.58 86.20 0.2 , 7.071 86.40 86.80 2,000 0.2 , 2.438 83.43 84.12 0.2 , 2.438 85.56 86.24 0.2 , 2.438 86.23 86.80 0.2 , 12.04 86.61 87.18 4,000 0.2 , 2.438 83.87 84.50 0.15 , 4.15 84.94 85.61 0.15 , 7.07 85.84 86.32 0.2 , 12.04 86.82 87.31 4,000 ( w/o ) 80.81 81.41 80.71 81.51 81.86 82.33 84.27 84.63 empirically O ( L2 ) where L is the number of training examples , regardless of the use of the speed-up method ( Kazama and Torisawa , 2005 ) , However , we can observe that the WMOLT kernel achieves a high accuracy even when the training data is very small .</sentence>
				<definiendum id="0">C )</definiendum>
				<definiendum id="1">L</definiendum>
				<definiens id="0">No. of sentences ) 250 500 700 1,000 setting dev test setting dev test setting dev test setting dev test γ ( λ ,</definiens>
				<definiens id="1">the number of training examples</definiens>
			</definition>
			<definition id="11">
				<sentence>For example , the combination of small SVMs ( Shen et al. , 2003 ) is a possible direction .</sentence>
				<definiendum id="0">small SVMs</definiendum>
				<definiens id="0">a possible direction</definiens>
			</definition>
</paper>

		<paper id="1204">
			<definition id="0">
				<sentence>Multi-word expressions ( MWEs ) are those whose structure and meaning can not be derived from their component words , as they occur independently .</sentence>
				<definiendum id="0">Multi-word expressions ( MWEs )</definiendum>
				<definiens id="0">those whose structure and meaning can not be derived from their component words</definiens>
			</definition>
			<definition id="1">
				<sentence>Here , we consider the class of verb based expressions ( verb is the head of the phrase ) , which occur very frequently .</sentence>
				<definiendum id="0">verb</definiendum>
				<definiens id="0">the head of the phrase ) , which occur very frequently</definiens>
			</definition>
			<definition id="2">
				<sentence>Here CX is the index of the verb ( BD BOBP CX BOBP CE ) .</sentence>
				<definiendum id="0">CX</definiendum>
			</definition>
			<definition id="3">
				<sentence>The variable CY is the index of the dependents ( BC BOBP CY BOBP BT ) except when CY BP BC which is used to represent the verb itself .</sentence>
				<definiendum id="0">variable CY</definiendum>
				<definiens id="0">the index of the dependents ( BC BOBP CY BOBP BT ) except when CY BP BC which is used to represent the verb itself</definiens>
			</definition>
			<definition id="4">
				<sentence>That is , we pick the slot CQ CXCY CJD4CL such that D7CRD3D6CTB4CQ CXCY CJD4CLB5A0 D7CRD3D6CTB4CQ CXCY CJBDCLB5 is the least among all the unexplored slots ( or alignment links ) .</sentence>
				<definiendum id="0">CXCY CJBDCLB5</definiendum>
				<definiens id="0">the least among all the unexplored slots ( or alignment links )</definiens>
			</definition>
			<definition id="5">
				<sentence>word and the target word BWBVD3CTABB4D7 CXCY BND8 CZ B5 BP BE A3BVD3D9D2D8B4D7 CXCY BND8 CZ B5 BVD3D9D2D8B4D7 CXCY B5 B7 BVD3D9D2D8B4D8 CZ B5 where BVD3D9D2D8B4D7 CXCY BND8 CZ B5 is the number of times the word D8 CZ was present in the translation of sentences containing the word D7 CXCY in the parallel corpus .</sentence>
				<definiendum id="0">BVD3D9D2D8B4D7 CXCY BND8 CZ B5</definiendum>
				<definiens id="0">the number of times the word D8 CZ was present in the translation of sentences containing the word D7 CXCY in the parallel corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>The following are the four global features which we have considered , AF AvgDist : The average distance between the words in the target language sentence which are aligned to the verbs in the source language sentence .</sentence>
				<definiendum id="0">AF AvgDist</definiendum>
				<definiens id="0">The average distance between the words in the target language sentence which are aligned to the verbs in the source language sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>AF Overlap : This feature stores the count of pairs of verbs in the source language sentence which align with the same word in the target language sentence .</sentence>
				<definiendum id="0">AF Overlap</definiendum>
				<definiens id="0">This feature stores the count of pairs of verbs in the source language sentence which align with the same word in the target language sentence</definiens>
			</definition>
			<definition id="8">
				<sentence>AF MergeMI : This is a compositionality based feature which associates point-wise mutual information ( apart from the POS information ) with the cases where the dependents which have the same alignment in the target He/N away/RP ran/V vaha bhaaga gayaa Figure 5 : Example of MergePos feature language as their verbs .</sentence>
				<definiendum id="0">AF MergeMI</definiendum>
			</definition>
			<definition id="9">
				<sentence>We have 24 CUCB D5 BNCC D5 BNCMCP D5 CV for training where D5 BOBP D1 is the index number of the sentence pair CUCB D5 BNCC D5 CV in the training set and CMCP D5 is the gold alignment for the pair CUCB D5 BNCC D5 CV .</sentence>
				<definiendum id="0">D5 BOBP D1</definiendum>
				<definiendum id="1">CMCP D5</definiendum>
				<definiens id="0">the index number of the sentence pair CUCB D5 BNCC D5 CV in the training set</definiens>
				<definiens id="1">the gold alignment for the pair CUCB D5 BNCC D5 CV</definiens>
			</definition>
</paper>

		<paper id="1519">
			<definition id="0">
				<sentence>SJTree uses 43 part-of-speech tags and 55 syntactic tags ( Sejong Project 2003 ) .</sentence>
				<definiendum id="0">SJTree</definiendum>
			</definition>
			<definition id="1">
				<sentence>The number of tree schemata is not stabilized at the end of the extraction process , which seems to indicate that the size of Treebank is not enough to reach the convergence of extracted grammars .</sentence>
				<definiendum id="0">extraction process</definiendum>
				<definiens id="0">seems to indicate that the size</definiens>
			</definition>
</paper>

		<paper id="0606">
			<definition id="0">
				<sentence>CCTB uses the Informationbased Case Grammar ( ICG ) framework to express both syntactic and semantic descriptions .</sentence>
				<definiendum id="0">CCTB</definiendum>
			</definition>
			<definition id="1">
				<sentence>CKIP POS tagging is a hierarchical system .</sentence>
				<definiendum id="0">CKIP POS tagging</definiendum>
				<definiens id="0">a hierarchical system</definiens>
			</definition>
			<definition id="2">
				<sentence>In CCTB , there are 6 non-terminal phrasal categories : S ( a complete tree headed by a predicate ) , VP ( a phrase headed by a predicate ) , NP ( a phrase beaded by an N ) , GP ( a phrase headed by locational noun or adjunct ) , PP disjunction of verb subcategorization types { cop , intr , cxtr , dimontr , ditr , montr , trans } .</sentence>
				<definiendum id="0">GP (</definiendum>
				<definiens id="0">a complete tree headed by a predicate )</definiens>
				<definiens id="1">a phrase headed by a predicate )</definiens>
				<definiens id="2">a phrase headed by locational noun or adjunct ) , PP disjunction of verb</definiens>
			</definition>
			<definition id="3">
				<sentence>40 ( a phrase headed by a preposition ) and XP ( a conjunctive phrase that is headed by a conjunction ) .</sentence>
				<definiendum id="0">XP</definiendum>
				<definiens id="0">a conjunctive phrase that is headed by a conjunction )</definiens>
			</definition>
			<definition id="4">
				<sentence>In this sense , the linguistic framework of the Penn Treebank is a phrase structure based framework that includes a particular set of node labels ( POS tags , phrasal categories , etc. ) , function tags , indices , etc. 2 .</sentence>
				<definiendum id="0">Penn Treebank</definiendum>
				<definiens id="0">a phrase structure based framework that includes a particular set of node labels ( POS tags , phrasal categories</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , in the phrase Mary called Fred up on the phone , there are two common views : ( a ) called is the head of the VP ( or S ) and up is a particle that depends on called ; and ( b ) the VP has a complex head called up .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">a particle that depends on called</definiens>
			</definition>
			<definition id="6">
				<sentence>The functor is the glue that holds the phrase together -the word that selects for the other words , determines word order , licenses the construction , etc .</sentence>
				<definiendum id="0">functor</definiendum>
				<definiens id="0">the glue that holds the phrase together -the word that selects for the other words , determines word order</definiens>
			</definition>
			<definition id="7">
				<sentence>The phrase is a concrete noun phrase due to book and rock .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">a concrete noun phrase due to book and rock</definiens>
			</definition>
			<definition id="8">
				<sentence>A &lt; coref &gt; element is used to identify mentions of objects ( the MARKABLES ) ; each markable is given an index ; subsequent mentions of already introduced objects are indicated by means of the REF attribute , which specifies the index of the previous mention of the same object .</sentence>
				<definiendum id="0">&lt; coref &gt; element</definiendum>
				<definiens id="0">used to identify mentions of objects ( the MARKABLES ) ; each markable is given an index ; subsequent mentions of already introduced objects are indicated by means of the REF attribute , which specifies the index of the previous mention of the same object</definiens>
			</definition>
			<definition id="9">
				<sentence>The MATE `meta-scheme’ ( Poesio , 1999 ) was proposed as a very general repertoire of markup elements that could be used to implement a variety of existing coreference schemes , such as MUC or the MapTask scheme , but also more linguistically motivated schemes .</sentence>
				<definiendum id="0">MATE `meta-scheme’</definiendum>
				<definiens id="0">a very general repertoire of markup elements that could be used to implement a variety of existing coreference schemes , such as MUC or the MapTask scheme , but also more linguistically motivated schemes</definiens>
			</definition>
			<definition id="10">
				<sentence>Predicate-argument roles label relations between items and are not simply tags on phrases ( like Named Entity Tags , for example ) .</sentence>
				<definiendum id="0">Predicate-argument roles</definiendum>
				<definiens id="0">label relations between items and are not simply tags on phrases</definiens>
			</definition>
			<definition id="11">
				<sentence>SemLink is a project to link the lexical resources of FrameNet , PropBank , and VerbNet .</sentence>
				<definiendum id="0">SemLink</definiendum>
				<definiens id="0">a project to link the lexical resources of FrameNet , PropBank , and VerbNet</definiens>
			</definition>
			<definition id="12">
				<sentence>VerbNet consists of hierarchies of verb classes , extended from those of Levin 1993 .</sentence>
				<definiendum id="0">VerbNet</definiendum>
				<definiens id="0">consists of hierarchies of verb classes</definiens>
			</definition>
			<definition id="13">
				<sentence>The full argument list consists of 23 thematic roles , and 46 possible selectional restrictions on the arguments are expressed using binary predicates .</sentence>
				<definiendum id="0">full argument list</definiendum>
				<definiens id="0">consists of 23 thematic roles , and 46 possible selectional restrictions on the arguments are expressed using binary predicates</definiens>
			</definition>
			<definition id="14">
				<sentence>VerbNet has been extended from the Levin classes , and now covers 4526 senses for 3175 lexemes .</sentence>
				<definiendum id="0">VerbNet</definiendum>
				<definiens id="0">extended from the Levin classes , and now covers 4526 senses for 3175 lexemes</definiens>
			</definition>
			<definition id="15">
				<sentence>FrameNet consists of collections of semantic frames , lexical units that evoke these frames , and annotation reports that demonstrate uses of lexical units .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">consists of collections of semantic frames , lexical units that evoke these frames , and annotation reports that demonstrate uses of lexical units</definiens>
			</definition>
			<definition id="16">
				<sentence>Lexical units appear in a variety of parts of speech , though we focus on verbs here .</sentence>
				<definiendum id="0">Lexical units</definiendum>
				<definiens id="0">appear in a variety of parts of speech , though we focus on verbs here</definiens>
			</definition>
			<definition id="17">
				<sentence>PropBank is an annotation of 1M words of the Wall Street Journal portion of the Penn Treebank II with semantic role labels for each verb argument .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">an annotation of 1M words of the Wall Street Journal portion of the Penn Treebank</definiens>
			</definition>
			<definition id="18">
				<sentence>To summarize , PropBank and FrameNet both annotate the same verb arguments , but assign different labels .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">both annotate the same verb arguments , but assign different labels</definiens>
			</definition>
			<definition id="19">
				<sentence>PropBank has a small number of vague , general purpose labels with sufficient amounts of training data geared specifically to support successful machine learning .</sentence>
				<definiendum id="0">PropBank</definiendum>
			</definition>
			<definition id="20">
				<sentence>FrameNet provides a much richer and more explicit semantics , but without sufficient amounts of training data for the hundreds of individual frame elements .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">provides a much richer and more explicit semantics , but without sufficient amounts of training data for the hundreds of individual frame elements</definiens>
			</definition>
			<definition id="21">
				<sentence>VerbNet provides a level of representation that is still tied to syntax , in the way that PropBank is , but provides a somewhat more fine-grained set of role labels and a set of fairly high level , general purpose semantic predicates , such as contact ( x , y ) , change-oflocation ( x , path ) , cause ( A , X ) , etc .</sentence>
				<definiendum id="0">VerbNet</definiendum>
				<definiendum id="1">change-oflocation</definiendum>
				<definiens id="0">provides a level of representation that is still tied to syntax , in the way that PropBank is , but provides a somewhat</definiens>
			</definition>
			<definition id="22">
				<sentence>In contrast , FrameNet is designed to group lexical items based on frame semantics , and a single FrameNet frame may contain sets of verbs with related senses but different subcategorization properties and sets of verbs with similar syntactic behavior may appear in multiple frames .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">designed to group lexical items based on frame semantics</definiens>
			</definition>
			<definition id="23">
				<sentence>This lexical mapping consists of a mapping between the PropBank framesets and VerbNet 's verb classes ; and a mapping between the roleset argument labels and the VerbNet thematic roles .</sentence>
				<definiendum id="0">lexical mapping</definiendum>
				<definiens id="0">consists of a mapping between the PropBank framesets and VerbNet 's verb classes ; and a mapping between the roleset argument labels and the VerbNet thematic roles</definiens>
			</definition>
			<definition id="24">
				<sentence>The thematic role assignment , on the other hand , was a semi-automatic process which finds the best match for the argument labels , based on their descriptors , to the set of thematic role labels of VerbNet .</sentence>
				<definiendum id="0">semi-automatic process</definiendum>
				<definiens id="0">finds the best match for the argument labels , based on their descriptors , to the set of thematic role labels of VerbNet</definiens>
			</definition>
			<definition id="25">
				<sentence>Similar issues arise with the year to year changes of the ACE annotation guidelines ( projects.ldc.upenn.edu/ace/ ) which include named entity , semantic classes for nouns , anaphora , relation and event annotation .</sentence>
				<definiendum id="0">Similar issues</definiendum>
				<definiens id="0">arise with the year to year changes of the ACE annotation guidelines ( projects.ldc.upenn.edu/ace/ ) which include named entity , semantic classes for nouns , anaphora , relation and event annotation</definiens>
			</definition>
			<definition id="26">
				<sentence>German is a general Verb-Second language which means that in the default structure in declarative main clauses as well as in whquestions the finite verb surfaces in second position preceded by only one constituent which is not necessarily the subject .</sentence>
				<definiendum id="0">German</definiendum>
				<definiens id="0">a general Verb-Second language which means that in the</definiens>
			</definition>
			<definition id="27">
				<sentence>The top level of the syntactic tree is a flat structure of field categories including : Linke Klammer left bracket ( LK ) and Rechte Klammer verbal complex ( VC ) for verbal elements and Vorfeld initial field ( VF ) , C-Feld complementiser field ( C ) , Mittelfeld middle field ( MF ) , Nachfeld final field ( NF ) for other elements .</sentence>
				<definiendum id="0">top level</definiendum>
				<definiens id="0">a flat structure of field categories including : Linke Klammer left bracket ( LK ) and Rechte Klammer verbal complex ( VC ) for verbal elements and Vorfeld initial field ( VF ) , C-Feld complementiser field ( C ) , Mittelfeld middle field ( MF ) , Nachfeld final field ( NF ) for other elements</definiens>
			</definition>
</paper>

		<paper id="3508">
			<definition id="0">
				<sentence>Constructions are the basic building blocks , posited by a particular grammar framework called Construction Grammar , and are defined as follows : “C is a construction iffdef C is a form-meaning pair &lt; Fi , Si &gt; such that some aspect of Fi or some aspect of Si is not strictly predictable from C’s component parts or from other previously established constructions.”</sentence>
				<definiendum id="0">Constructions</definiendum>
			</definition>
			<definition id="1">
				<sentence>One existing formal computational model of construction grammar is the Embodied Construction Grammar ( ECG ) ( Chang et al. , 2002 ; Bergen and Chang , 2002 ) , with its main focus being on language understanding and later simulation 2 .</sentence>
				<definiendum id="0">construction grammar</definiendum>
			</definition>
			<definition id="2">
				<sentence>The ontological frameworks mentioned above are Descriptions &amp; Situations ( D &amp; S ) ( Gangemi and Mika , 2003 ) and Ontology of Information Objects ( OIO ) ( Guarino , 2006 ) , which both are extensions of the Descriptive Ontology for Linguistic and 58 Cognitive Engineering ( DOLCE ) ( Masolo et al. , 2003 ) .</sentence>
				<definiendum id="0">OIO )</definiendum>
			</definition>
			<definition id="3">
				<sentence>D &amp; S is an ontology for representing a variety of reified contexts and states of affairs .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">an ontology for representing a variety of reified contexts and states of affairs</definiens>
			</definition>
			<definition id="4">
				<sentence>It has no effect on the whole class of constructions , i.e. it is possible that there exist constructions that do not express a single schema , as e.g. compositional ones , whose meaning is a composite of all constructions and schemas that constitute that compositional construction .</sentence>
				<definiendum id="0">meaning</definiendum>
				<definiens id="0">a composite of all constructions and schemas that constitute that compositional construction</definiens>
			</definition>
			<definition id="5">
				<sentence>5 To be able to represent these phenomena , we firstly defined a class construction-parameter , that denotes a subclass of edns : parameter , a subclass of edns : concept .</sentence>
				<definiendum id="0">class construction-parameter</definiendum>
				<definiens id="0">a subclass of edns : parameter , a subclass of edns : concept</definiens>
			</definition>
			<definition id="6">
				<sentence>LingInfo constitutes an ontological model that provides other ontologies with linguistic information for different languages , momentarily for English , French , and German .</sentence>
				<definiendum id="0">LingInfo</definiendum>
				<definiens id="0">constitutes an ontological model that provides other ontologies with linguistic information for different languages</definiens>
			</definition>
			<definition id="7">
				<sentence>The LingInfo class is used to associate a term , a language , and morphosyntactic information to classes from the ground ontology ; e.g. a class CafeConstruction , which is an instance of ClassWithLingInfo , from an ontology proper , can be associated through the property linginfo with Café , an instance of the class LingInfo .</sentence>
				<definiendum id="0">class CafeConstruction</definiendum>
				<definiens id="0">an instance of ClassWithLingInfo , from an ontology proper</definiens>
			</definition>
			<definition id="8">
				<sentence>The Seed Corpus C : The primary corpus C in this work is the portion of the World Wide Web confined to web pages containing natural language texts on soccer .</sentence>
				<definiendum id="0">Seed Corpus C</definiendum>
				<definiens id="0">the portion of the World Wide Web confined to web pages containing natural language texts on soccer</definiens>
			</definition>
			<definition id="9">
				<sentence>Constructing a Language : A Usage-Based Theory of Language Acquisition .</sentence>
				<definiendum id="0">Constructing a Language</definiendum>
			</definition>
</paper>

		<paper id="1664">
			<definition id="0">
				<sentence>As described , PMI is one of many measures to calculate the strength of word similarity or word association ( Manning and Sch¨utze , 2002 ) .</sentence>
				<definiendum id="0">PMI</definiendum>
				<definiens id="0">one of many measures to calculate the strength of word similarity or word association</definiens>
			</definition>
			<definition id="1">
				<sentence>Distributional clustering of words was first proposed by Pereira Tishby &amp; Lee in ( Pereira et al. , 1993 ) : They cluster nouns according to their conditional verb distributions .</sentence>
				<definiendum id="0">Distributional clustering</definiendum>
				<definiens id="0">Pereira et al. , 1993 ) : They cluster nouns according to their conditional verb distributions</definiens>
			</definition>
			<definition id="2">
				<sentence>Probability p ( w1 ) is estimated by fw1/N , where fw1 represents the web count of w1 and N represents the number of documents on the web .</sentence>
				<definiendum id="0">Probability p</definiendum>
				<definiendum id="1">fw1</definiendum>
				<definiens id="0">the web count of w1 and N represents the number of documents on the web</definiens>
			</definition>
			<definition id="3">
				<sentence>χ2 ( w1 , w2 ) = N × ( a×d−b×c ) 2 ( a + b ) × ( a + c ) × ( b + d ) × ( c + d ) However , N is a huge number on the web and sometimes it is difficult to know exactly .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">a huge number on the web</definiens>
			</definition>
			<definition id="4">
				<sentence>Therefore we regard the co-occurrence matrix as a contingency table : bprime = ∑ w∈W ; wnegationslash=w2 fw1 , w , cprime = ∑ w∈W ; wnegationslash=w1 fw2 , w ; dprime = ∑ w , wprime∈W ; w and wprimenegationslash=w1 nor w2 fw , wprime , Nprime = ∑ w , wprime∈W fw , wprime , where W represents a given set of words .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">a given set of words</definiens>
			</definition>
			<definition id="5">
				<sentence>Betweenness of an edge is the number of shortest paths between pairs of nodes that run along it .</sentence>
				<definiendum id="0">Betweenness of an edge</definiendum>
				<definiens id="0">the number of shortest paths between pairs of nodes that run along it</definiens>
			</definition>
			<definition id="6">
				<sentence>In Newman clustering , instead of explicitly calculating high-betweenness edges ( which is computationally demanding ) , an objective function is defined as follows : Q = ∑ i parenleftBigg eii − parenleftBigg∑ j eij ) 2 ) ( 1 ) We assume that we have separate clusters , and that eij is the fraction5 of edges in the network that connect nodes in cluster i to those in cluster j. The term eii denotes the fraction of edges within the clusters .</sentence>
				<definiendum id="0">term eii</definiendum>
				<definiens id="0">explicitly calculating high-betweenness edges ( which is computationally demanding ) , an objective function is defined as follows : Q = ∑ i parenleftBigg eii − parenleftBigg∑ j eij ) 2 ) ( 1 ) We assume that we have separate clusters , and that eij is the fraction5 of edges in the network that connect nodes in cluster i to those in cluster</definiens>
			</definition>
			<definition id="7">
				<sentence>The term ∑j eij represents the expected fraction of edges within the cluster .</sentence>
				<definiendum id="0">term ∑j eij</definiendum>
				<definiens id="0">represents the expected fraction of edges within the cluster</definiens>
			</definition>
			<definition id="8">
				<sentence>Calculate the score of each word w in category c similarly to TF-IDF : score ( w , c ) = fc ( w ) ×log ( Nall/fall ( w ) ) where fc denotes the document frequency of word w in category c , Nall denotes the number of all documents , and fall ( w ) denotes the frequency of word w in all documents .</sentence>
				<definiendum id="0">Calculate the score of</definiendum>
				<definiendum id="1">×log ( Nall/fall</definiendum>
				<definiendum id="2">fc</definiendum>
				<definiendum id="3">Nall</definiendum>
				<definiendum id="4">fall ( w )</definiendum>
				<definiens id="0">the document frequency of word w in category c ,</definiens>
				<definiens id="1">the number of all documents , and</definiens>
			</definition>
			<definition id="9">
				<sentence>category specific words to a category as a word group ��� ( art ) h� ( gallery ) , ^� ( artwork ) , 6 � ( theater ) , ���� ( saxophone ) , yN ( verse ) , ��� ( live concert ) , ��� ( guitar ) , x� ( performance ) , ��� ( ballet ) , x 2 ( personal exhibition ) �������� ( recreation ) �� ( raising ) , �� ( poult ) , ����� ( hamster ) , � �G ( travel diary ) , q� ( national park ) , ( brewing ) , �  ( boat race ) , � � ( competition ) , ��� ( fishing pond ) H� ( health ) �� ( illness ) , �</sentence>
				<definiendum id="0">category specific</definiendum>
				<definiens id="0">national park ) , ( brewing ) , �  ( boat race ) , � � ( competition )</definiens>
			</definition>
			<definition id="10">
				<sentence>hypernym hyponyms as a word group E t ( gem ) ����� ( amethyst ) , ������ ( aquamarine ) , ������ ( diamond ) , ����� ( emerald ) , ������� ( moonstone ) , ����� ( peridot ) , ��� ( ruby ) , ����� ( sapphire ) , ���� ( topaz ) , ����� ( tourmaline ) �� ( academic field ) � �J� ( natural science ) , : � ( mathematics ) , �� ( agronomics ) , P �� ( architectonics ) , �� � ( geology ) , �g� ( psychology ) , �C�� ( computer science ) , � �J� ( cognitive science ) , � q� ( sociology ) , t�� ( linguistics ) ��� ( drink ) � � ( milk ) , ����� ( alcohol ) , Z��� ( cooling beverage ) , x��� ( carbonated beverage ) , ���� ( soda ) , ��� ( cocoa ) , �������� ( fruit juice ) , ���� ( coffee ) , S � ( tea ) , � �������� ( mineral water ) Table 8 : Precision of WordNet set .</sentence>
				<definiendum id="0">hypernym hyponyms</definiendum>
				<definiens id="0">a word group E t ( gem ) ����� ( amethyst ) , ������ ( aquamarine ) , ������ ( diamond ) , ����� ( emerald ) , ������� ( moonstone ) , ����� ( peridot ) , ��� ( ruby ) , ����� ( sapphire ) , ���� ( topaz )</definiens>
			</definition>
			<definition id="11">
				<sentence>POLYPHONET : An advanced social network extraction system .</sentence>
				<definiendum id="0">POLYPHONET</definiendum>
				<definiens id="0">An advanced social network extraction system</definiens>
			</definition>
</paper>

		<paper id="3125">
</paper>

		<paper id="2601">
			<definition id="0">
				<sentence>Hence , ME models result in a loglinearcombination ofalarge setoffeatures , whose weights can be estimated by the well known Generalized Iterative Scaling ( GIS ) algorithm by Darroch and Ratcliff ( 1972 ) .</sentence>
				<definiendum id="0">ME models</definiendum>
			</definition>
			<definition id="1">
				<sentence>Syntactic features are denoted by the nameSynand indexed with a 4-tuple ( c , Pos , p , d ) or ( c , Chnk , p , d ) , 2 Name Index Definition Lex c , w , d δ ( ct = c ) ·δ ( wt+d = w ) , d ∈ Z Syn c , T , p , d δ ( ct = c ) ·δ ( T ( wt+d ) = p ) , T ∈ { Pos , Chnk } , d ∈ Z Orth c , F , d δ ( ct = c ) ·F ( wt+d ) , F ∈ { IsCap , IsCAP } , d ∈ Z Dict c , L , d δ ( ct = c ) ·InList ( L , wt+d ) , d ∈ Z Tran c , cprime , d δ ( ct = c ) ·δ ( ct−d = cprime ) d ∈ N+ Lex+ c , s , k , ws+k−1s producttexts+k−1d=s Lexc , wd , d ( x , y ) , k ∈ N+ , s ∈ Z Syn+ c , T , s , k , ps+k−1s producttexts+k−1d=s Sync , T , pd , d ( x , y ) , k ∈ N+ , s ∈ Z Orth+ c , F , k , b+k−k δ ( ct = c ) ·producttextkd=−k δ ( Orthc , F , d ( x , y ) = bd ) , bd ∈ { 0,1 } , k ∈ N+ Dict+ c , L , k , b+k−k δ ( ct = c ) ·producttextkd=−k δ ( Dictc , L , d ( x , y ) = bd ) , bd ∈ { 0,1 } , k ∈ N+ Tran+ c , k , ck1 producttextkd=1prime Tranc , cd , d ( x , y ) k ∈ N+ Table 1 : Standard set of binary features for text tagging .</sentence>
				<definiendum id="0">c ) ·δ ( T</definiendum>
				<definiens id="0">ct−d = cprime ) d ∈ N+ Lex+ c , s , k</definiens>
				<definiens id="1">x , y ) , k ∈ N+ , s ∈ Z Syn+ c , T , s , k</definiens>
			</definition>
			<definition id="2">
				<sentence>Atomic dictionary features are defined as follows : Dictc , L , d ( x , y ) ˆ=δ ( ct = c ) · InList ( L , wt+d ) where L is a specific pre-compiled list , and InList is a function which returns 1 if the specified word matches one of the multi-word entries of list L , and 0 otherwise .</sentence>
				<definiendum id="0">Atomic dictionary features</definiendum>
				<definiendum id="1">InList</definiendum>
				<definiens id="0">follows : Dictc , L , d ( x , y ) ˆ=δ ( ct = c ) · InList ( L , wt+d ) where L is a specific pre-compiled list , and</definiens>
			</definition>
			<definition id="3">
				<sentence>Let p1 ( y|x ) , p2 ( y|x ) , ... , pn ( y|x ) be n different conditional probability distributions estimated on the training corpus .</sentence>
				<definiendum id="0">... , pn</definiendum>
				<definiens id="0">conditional probability distributions estimated on the training corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>Hence , features were re-scaled as follows : fi ( x , y ) = logpi ( y|x ) + log 1 + epsilon1minp i , ( 8 ) where epsilon1 is a small positive constant and the denominator is a constant term defined by : minpi = min ( x , y ) ∈S pi ( y|x ) .</sentence>
				<definiendum id="0">epsilon1</definiendum>
				<definiens id="0">a small positive constant and the denominator is a constant term defined by : minpi = min ( x , y ) ∈S pi ( y|x )</definiens>
			</definition>
			<definition id="5">
				<sentence>Texts originate from the Wall Street Journal and areannotated withpart-of-speech tags and chunks .</sentence>
				<definiendum id="0">Texts</definiendum>
			</definition>
			<definition id="6">
				<sentence>For the NER task , model FinBin adds Orth+ and Dict+ ; FinReal adds Lex+ , Orth+ and Dict+ ; and , FinMix adds real-valued Lex+ and binary-valued Orth+ and Dict+ .</sentence>
				<definiendum id="0">FinReal</definiendum>
				<definiendum id="1">FinMix</definiendum>
				<definiens id="0">adds real-valued Lex+ and binary-valued Orth+</definiens>
			</definition>
</paper>

		<paper id="1642">
			<definition id="0">
				<sentence>Sentiment Analysis ( SA ) ( Nasukawa and Yi , 2003 ; Yi et al. , 2003 ) is a task to recognize writers’ feelings as expressed in positive or negative comments , by analyzing unreadably large numbers of documents .</sentence>
				<definiendum id="0">Sentiment Analysis ( SA )</definiendum>
				<definiens id="0">a task to recognize writers’ feelings as expressed in positive or negative comments</definiens>
			</definition>
			<definition id="1">
				<sentence>From the example Japanese sentence ( 1 ) in the digital camera domain , the SA system extracts a sentiment representation as ( 2 ) , which consists of a predicate and an argument with positive ( + ) polarity .</sentence>
				<definiendum id="0">SA system</definiendum>
				<definiens id="0">consists of a predicate and an argument with positive ( + ) polarity</definiens>
			</definition>
			<definition id="2">
				<sentence>Inter-sentential contexts as in our approach were used as a clue also for subjectivity analysis ( Riloff and Wiebe , 2003 ; Pang and Lee , 2004 ) , which is two-fold classification into subjective and objective sentences .</sentence>
				<definiendum id="0">Inter-sentential contexts</definiendum>
				<definiens id="0">two-fold classification into subjective and objective sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>prior polarity and context polarity , which are similar to polar atoms and syntactic patterns in this paper , respectively .</sentence>
				<definiendum id="0">context polarity</definiendum>
				<definiens id="0">similar to polar atoms and syntactic patterns in this paper , respectively</definiens>
			</definition>
			<definition id="4">
				<sentence>A polar atom consists of polarity , verb or adjective , and optionally , its arguments .</sentence>
				<definiendum id="0">polar atom</definiendum>
			</definition>
			<definition id="5">
				<sentence>“Baseline” is the percentage of positive clauses among the polar clauses6 .</sentence>
				<definiendum id="0">“Baseline”</definiendum>
				<definiens id="0">the percentage of positive clauses among the polar clauses6</definiens>
			</definition>
			<definition id="6">
				<sentence>f ( a ) , p ( a ) , and n ( a ) denote the frequency of the atom and in positive and negative contexts , respectively .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">p</definiendum>
				<definiendum id="2">n</definiendum>
				<definiens id="0">a ) denote the frequency of the atom and in positive and negative contexts</definiens>
			</definition>
</paper>

		<paper id="1311">
			<definition id="0">
				<sentence>Tags As a Constraint Grammar system , PALAVRAS encodes all annotational information as word based tags .</sentence>
				<definiendum id="0">PALAVRAS</definiendum>
				<definiens id="0">encodes all annotational information as word based tags</definiens>
			</definition>
</paper>

		<paper id="0906">
			<definition id="0">
				<sentence>Positive Infinite Durations : These are states which continue essentially forever once they begin .</sentence>
				<definiendum id="0">Positive Infinite Durations</definiendum>
			</definition>
			<definition id="1">
				<sentence>It is computed as : ) ( 1 ) ( ) ( EP EPAP − − =κ P ( A ) is the observed agreement among the annotators , and P ( E ) is the expected agreement , 40 Figure 1 : Overlap of Judgments of [ 10 minutes , 30 minutes ] and [ 10 minutes , 2 hours ] .</sentence>
				<definiendum id="0">P ( E )</definiendum>
				<definiens id="0">the observed agreement among the annotators , and</definiens>
			</definition>
			<definition id="2">
				<sentence>TimeML ( Pustejovsky et al. , 2003 ) is a rich specification language for event and temporal expressions in natural language text .</sentence>
				<definiendum id="0">TimeML</definiendum>
			</definition>
			<definition id="3">
				<sentence>TimeML includes four major data structures : EVENT , TIMEX3 , SIGNAL , AND LINK .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">includes four major data structures : EVENT , TIMEX3 , SIGNAL , AND LINK</definiens>
			</definition>
			<definition id="4">
				<sentence>EVENT is a cover term for situations that happen or occur , and also those predicates describing states or circumstances in which something obtains or holds true .</sentence>
				<definiendum id="0">EVENT</definiendum>
			</definition>
			<definition id="5">
				<sentence>TIMEX3 , which extends TIMEX2 ( Ferro , 2001 ) , is used to mark up explicit temporal expressions , such as time , dates , and durations .</sentence>
				<definiendum id="0">TIMEX3</definiendum>
				<definiens id="0">extends TIMEX2 ( Ferro , 2001 ) , is used to mark up explicit temporal expressions , such as time , dates , and durations</definiens>
			</definition>
			<definition id="6">
				<sentence>In languages such as English and French , there is a grammatical device of aspectual predication , which focuses on different facets of event history , i.e. , initiation , reinitiation , termination , culmination , continuation ( e.g. , begin , stop , finish , continue ) .</sentence>
				<definiendum id="0">aspectual predication</definiendum>
				<definiens id="0">focuses on different facets of event history , i.e. , initiation , reinitiation , termination , culmination , continuation</definiens>
			</definition>
</paper>

		<paper id="3506">
			<definition id="0">
				<sentence>Consider our conceptualization of events as exemplified in the mapping called the Event Structure Metaphor .</sentence>
				<definiendum id="0">Consider our conceptualization of events</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the example literal sentence from Figure 1 , the theme is a person , which is a physical object and thus part of the source domain .</sentence>
				<definiendum id="0">theme</definiendum>
				<definiens id="0">a physical object and thus part of the source domain</definiens>
			</definition>
			<definition id="2">
				<sentence>While FrameNet puts slide both in the Motion frame and in the Cause-motion frame , PropBank uses the argument labeling to distinguish these two senses .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">uses the argument labeling to distinguish these two senses</definiens>
			</definition>
			<definition id="3">
				<sentence>This tremendous bias towards metaphoric usage of motion/cause-motion lexical items shows just how prevalent the Event Structure Metaphor is , especially in the domain of economics where it is used to describe market fluctuations and policy decisions .</sentence>
				<definiendum id="0">Event Structure Metaphor</definiendum>
				<definiens id="0">used to describe market fluctuations and policy decisions</definiens>
			</definition>
			<definition id="4">
				<sentence>Maxent classifiers are designed to maximize the conditional log likelihood of the training data where the conditional likelihood of a particular class c on training example i is computed as : 1 Zexp ( fi · ωc ) Here Z is a normalizing factor , fi is the vector of features associated with example i and ωc is the vector of weights associated with class c. Additionally , the Stanford classifier uses by default a Gaussian prior of 1 on the features , thus smoothing the feature weights and helping prevent overfitting .</sentence>
				<definiendum id="0">fi</definiendum>
				<definiens id="0">designed to maximize the conditional log likelihood of the training data where the conditional likelihood of a particular class c on training example i is computed as : 1 Zexp ( fi · ωc ) Here Z is a normalizing factor</definiens>
			</definition>
			<definition id="5">
				<sentence>More similar to our efforts , Mason’s CorMet uses a corpus-based approach .</sentence>
				<definiendum id="0">Mason’s CorMet</definiendum>
				<definiens id="0">uses a corpus-based approach</definiens>
			</definition>
			<definition id="6">
				<sentence>Metaphors are a ubiquitous phenomenon in language , and our corpus analysis clearly bears this out .</sentence>
				<definiendum id="0">Metaphors</definiendum>
				<definiens id="0">a ubiquitous phenomenon in language</definiens>
			</definition>
</paper>

		<paper id="1632">
			<definition id="0">
				<sentence>Hence , paragraph segmentation is a task which encompasses the traditional borders between content and style .</sentence>
				<definiendum id="0">paragraph segmentation</definiendum>
				<definiens id="0">a task which encompasses the traditional borders between content and style</definiens>
			</definition>
			<definition id="1">
				<sentence>BoosTexter was developed for text categorization , and combines simple rules ( decision stumps ) in a boosting manner .</sentence>
				<definiendum id="0">BoosTexter</definiendum>
				<definiens id="0">developed for text categorization , and combines simple rules ( decision stumps</definiens>
			</definition>
			<definition id="2">
				<sentence>TiMBL is a memory-based learner which classifies every test instance by finding the most similar examples in the training set , hence it does not abstract from the data and is well suited to handle features with many values , e.g. the list of discourse cues .</sentence>
				<definiendum id="0">TiMBL</definiendum>
				<definiens id="0">a memory-based learner which classifies every test instance by finding the most similar examples in the training set , hence it does not abstract from the data and is well suited to handle features with many values</definiens>
			</definition>
			<definition id="3">
				<sentence>The third baseline ( Sporleder ) is a reimplementation of Sporleder &amp; Lapata’s 2006 algorithm with the following features : Word and Sentence Distances from the current sentence to the previous paragraph break ; Sentence Length and Relative Position ( relPos ) of the sentence in a text ; Quotes encodes whether this and the previous sentences contain a quotation , and whether the quotation is continued in the current sentence or not ; Final Punctuation of the previous sentence ; Words – the first ( word1 ) , the first two ( word2 ) , the first three and all words from the sentence ; Parsed has positive value in case the sentence is parsed , negative otherwise ; Number of S , VP , NP and PP nodes in the sentence ; Signature is the sequence of PoS tags with and without punctuation ; 269 Children of Top-Level Nodes are two features representing the sequence of syntactic labels of the children of the root of the parse tree and the children of the highest S-node ; Branching Factor features express the average number of children of S , VP , NP and PP nodes in the parse ; Tree Depth is the average length of the path from the root to the leaves ; Per-word Entropy is a feature based on Genzel &amp; Charniak’s ( 2003 ) observation that paragraph-initial sentences have lower entropy than non-initial ones ; Sentence Probability according to a language model computed from the training data ; Character-level n-gram models are built using the CMU toolkit ( Clarkson &amp; Rosenfeld , 1997 ) .</sentence>
				<definiendum id="0">Sporleder )</definiendum>
				<definiendum id="1">Signature</definiendum>
				<definiendum id="2">Tree Depth</definiendum>
				<definiendum id="3">Per-word Entropy</definiendum>
				<definiendum id="4">Character-level n-gram models</definiendum>
				<definiendum id="5">CMU toolkit</definiendum>
				<definiens id="0">a reimplementation of Sporleder &amp; Lapata’s 2006 algorithm with the following features : Word and Sentence Distances from the current sentence to the previous paragraph break ; Sentence Length and Relative Position ( relPos ) of the sentence in a text ; Quotes encodes whether this and the previous sentences contain a quotation , and whether the quotation is continued in the current sentence or not ; Final Punctuation of the previous sentence</definiens>
				<definiens id="1">all words from the sentence ; Parsed has positive value in case the sentence is parsed , negative otherwise ; Number of S , VP , NP and PP nodes in the sentence ;</definiens>
				<definiens id="2">the sequence of PoS tags with and without punctuation ; 269 Children of Top-Level Nodes are two features representing the sequence of syntactic labels of the children of the root of the parse tree and the children of the highest S-node ; Branching Factor features express the average number of children of S , VP , NP and PP nodes in the parse ;</definiens>
				<definiens id="3">the average length of the path from the root to the leaves</definiens>
				<definiens id="4">a feature based on Genzel &amp; Charniak’s ( 2003 ) observation that paragraph-initial sentences have lower entropy than non-initial ones ; Sentence Probability according to a language model computed from the training data</definiens>
			</definition>
			<definition id="4">
				<sentence>prevSCueClass , currSCueClass : This feature represents the semantic class of the cue word or phrase as assigned by the IDS Mannheim .</sentence>
				<definiendum id="0">currSCueClass</definiendum>
				<definiens id="0">the semantic class of the cue word or phrase as assigned by the IDS Mannheim</definiens>
			</definition>
			<definition id="5">
				<sentence>The latter metric , WindowDiff ( Pevzner &amp; Hearst , 2002 ) , is supposed to overcome the disadvantage of the F-measure which penalizes near misses as harsh as more serious mistakes .</sentence>
				<definiendum id="0">WindowDiff</definiendum>
				<definiens id="0">supposed to overcome the disadvantage of the F-measure which penalizes near misses as harsh as more serious mistakes</definiens>
			</definition>
</paper>

		<paper id="0401">
			<definition id="0">
				<sentence>Optimality Theory ( henceforth OT ) is not only used for analyzing and explaining linguistic phenomena in the domain of phonology , but also in the domains of morphology , syntax , semantics and pragmatics .</sentence>
				<definiendum id="0">Optimality Theory</definiendum>
				<definiens id="0">not only used for analyzing and explaining linguistic phenomena in the domain of phonology , but also in the domains of morphology , syntax , semantics and pragmatics</definiens>
			</definition>
			<definition id="1">
				<sentence>Gapping is a grammatical operation that deletes certain subconstituents in the second conjunct of a coordinate structure , as in ( 1 ) : 1 ( 1 ) Some ate beans , and others rice .</sentence>
				<definiendum id="0">Gapping</definiendum>
				<definiens id="0">a grammatical operation that deletes certain subconstituents in the second conjunct of a coordinate structure</definiens>
			</definition>
			<definition id="2">
				<sentence>( 8 ) The Tendency for Subject-Predicate Interpretation : When Gapping leaves an NP and a VP behind , the two constituents are readily interpreted as constituting a sentential pattern , with the NP representing the subject of the VP .</sentence>
				<definiendum id="0">Subject-Predicate Interpretation</definiendum>
				<definiendum id="1">Gapping</definiendum>
				<definiens id="0">constituting a sentential pattern , with the NP representing the subject of the VP</definiens>
			</definition>
			<definition id="3">
				<sentence>As Kuno already observes , the FSP Principle seems to be able to override the Minimal Distance Principle .</sentence>
				<definiendum id="0">FSP Principle</definiendum>
			</definition>
			<definition id="4">
				<sentence>Thematic Selection expresses the selectional restrictions verbs may impose on their arguments .</sentence>
				<definiendum id="0">Thematic Selection</definiendum>
			</definition>
			<definition id="5">
				<sentence>The Eindhoven corpus ( uit den Boogaart , 1975 ) is an annotated corpus of Dutch written text of about 750 000 words .</sentence>
				<definiendum id="0">Eindhoven corpus</definiendum>
				<definiens id="0">an annotated corpus of Dutch written text of about 750 000 words</definiens>
			</definition>
			<definition id="6">
				<sentence>She distinguished five conditions : the Bake A condition ( Alice bakes cakes for tourists and Caroline for her family ) , the Bake B condition ( Alice bakes cakes for tourists and brownies for her family ) , the Take A condition ( Josh visited the office during the vacation and Sarah during the week ) , the Take B condition ( Josh visited Marjorie during the vacation and Sarah during the week ) and the Introduce condition ( Dan amazed the judges with his talent and James with his musicality ) .</sentence>
				<definiendum id="0">Bake B condition ( Alice</definiendum>
				<definiens id="0">the office during the vacation and Sarah during the week ) , the Take B condition ( Josh visited Marjorie during the vacation and Sarah during the week</definiens>
			</definition>
			<definition id="7">
				<sentence>A central principle of Optimality Theory is the hypothesis of strict domination among constraints .</sentence>
				<definiendum id="0">central principle of Optimality Theory</definiendum>
				<definiens id="0">the hypothesis of strict domination among constraints</definiens>
			</definition>
</paper>

		<paper id="0115">
			<definition id="0">
				<sentence>The Simplified character corpora were provided by Microsoft Research Asia ( MSRA ) for WS and NER , by University of Pennsylvania/University of Colorado ( UPUC ) for WS , and by the Linguistic Data Consortium ( LDC ) for NER .</sentence>
				<definiendum id="0">Simplified character corpora were</definiendum>
				<definiens id="0">provided by Microsoft Research Asia ( MSRA ) for WS and NER , by University of Pennsylvania/University of Colorado ( UPUC ) for WS , and by the Linguistic Data Consortium ( LDC ) for NER</definiens>
			</definition>
			<definition id="1">
				<sentence>These differences highlight the continuing challenges of handling out-of-vocabulary words and performing segmentation across different reg110 Site Name Site Country CITYU CKIP MSRA UPUC CITYU LDC MSRA ID WS WS WS WS NER NER NER Natural Language Processing Lab , Northeastern University of China 1 ZH C C C C Language Technologies Institute , Carnegie Mellon University 2 US O O O O National Institute of Information and Communications Technology , Japan 3 JP C C C Basis Technology Corp. 4 US C C C C Pattern Recognition and Intelligent System Laboratory , Beijing University of Posts and Telecommunications 5 ZH C C HKUST , Human Language Technology Center 6 HK O O O The University of Tokyo 7 JP O O O O Institute of Software , Chinese Academy of Sciences 8 ZH C C C C C C OC Alias-i , Inc. 9 US C C C C C C Beijing University of Posts and Telecommunications 10 ZH O O O France Telecom R &amp; D Beijing 11 ZH C OC O NETEASE Information Technology ( Beijing ) Co. , Ltd. 12 ZH O O AI Lab. , Dept of Information Management , Huafan University , Taiwan .</sentence>
				<definiendum id="0">CKIP MSRA UPUC CITYU LDC MSRA ID WS WS WS WS NER NER NER Natural Language Processing Lab</definiendum>
				<definiens id="0">Sciences 8 ZH C C C C C C OC Alias-i , Inc. 9 US C C C C C C Beijing University of Posts and Telecommunications</definiens>
			</definition>
			<definition id="2">
				<sentence>21 US C C CKIP , Academia Sinica , Taiwan 22 TW O Kookmin University 23 KO C C C C Shenyang Institute of Aeronautical Engineering 24 ZH OC OC Institute for Infocomm Research , Singapore 26 SG C C C C C C National Taiwan University 29 TW C ITNLP , Harbin Institute of Technology , China 30 ZH OC O National Central University at Taiwan 31 TW C C National Laboratory on Machine Perception , Peking University , China 32 ZH OC OC OC OC O University of Texas at Austin 34 US O O O O Table 2 : Participating Sites by Corpus , Task , and Track Source Recall Precision F-measure OOV Rate Roov Riv CITYU 0.930 0.882 0.906 0.040 0.009 0.969 CKIP 0.915 0.870 0.892 0.042 0.030 0.954 MSRA 0.949 0.900 0.924 0.034 0.022 0.981 UPUC 0.869 0.790 0.828 0.088 0.011 0.951 Table 3 : Baselines : WS : Maximum match with training vocabulary 111 Source Recall Precision F-measure OOV Rate Roov Riv CITYU 0.982 0.985 0.984 0.040 0.993 0.981 CKIP 0.980 0.987 0.983 0.042 0.997 0.979 MSRA 0.991 0.993 0.992 0.034 0.999 0.991 UPUC 0.961 0.976 0.968 0.088 0.989 0.958 Table 4 : Toplines : WS : Maximum match with testing vocabulary Site RunID R Cr P Cp F Roov Riv 15 d 0.973 ±0.000691 0.972 ±0.000703 0.972 0.787 0.981 15 b 0.973 ±0.000691 0.972 ±0.000703 0.972 0.787 0.981 20 0.972 ±0.000703 0.971 ±0.000715 0.971 0.792 0.979 32 0.969 ±0.000739 0.970 ±0.000727 0.970 0.773 0.978 1 a 0.971 ±0.000715 0.965 ±0.000783 0.968 0.719 0.981 15 c 0.965 ±0.000783 0.967 ±0.000761 0.966 0.792 0.972 15 a 0.966 ±0.000772 0.967 ±0.000761 0.966 0.786 0.973 26 0.968 ±0.000750 0.961 ±0.000825 0.965 0.633 0.983 11 0.962 ±0.000815 0.962 ±0.000815 0.962 0.722 0.972 16 0.963 ±0.000805 0.958 ±0.000855 0.961 0.689 0.974 9 0.966 ±0.000772 0.957 ±0.000865 0.961 0.555 0.983 1 b 0.958 ±0.000855 0.963 ±0.000805 0.960 0.714 0.968 8 0.952 ±0.000911 0.954 ±0.000893 0.953 0.747 0.960 23 0.950 ±0.000929 0.949 ±0.000938 0.949 0.638 0.963 4 b 0.845 ±0.001543 0.844 ±0.001547 0.844 0.632 0.854 4 a 0.841 ±0.001559 0.844 ±0.001547 0.843 0.506 0.855 13 1 0.589 ±0.002097 0.589 ±0.002097 0.589 0.022 0.613 Table 5 : CITYU : Word Segmentation : Closed Track Site RunID R Cr P Cp F Roov Riv 20 0.978 ±0.000625 0.977 ±0.000639 0.977 0.840 0.984 32 0.979 ±0.000611 0.976 ±0.000652 0.977 0.813 0.985 34 0.971 ±0.000715 0.967 ±0.000761 0.969 0.795 0.978 22 0.970 ±0.000727 0.965 ±0.000783 0.967 0.761 0.979 2 0.964 ±0.000794 0.964 ±0.000794 0.964 0.787 0.971 13 2 0.544 ±0.002123 0.549 ±0.002121 0.547 0.194 0.559 13 3 0.524 ±0.002129 0.503 ±0.002131 0.513 0.195 0.538 13 1 0.497 ±0.002131 0.467 ±0.002127 0.481 0.057 0.516 Table 6 : CITYU : Word Segmentation : Open Track Site RunID R Cr P Cp F Roov Riv 20 0.961 ±0.001280 0.955 ±0.001371 0.958 0.702 0.972 15 a 0.961 ±0.001280 0.953 ±0.001400 0.957 0.658 0.974 15 b 0.961 ±0.001280 0.952 ±0.001414 0.957 0.656 0.974 32 0.958 ±0.001327 0.948 ±0.001468 0.953 0.646 0.972 26 0.958 ±0.001327 0.941 ±0.001558 0.949 0.554 0.976 1 b 0.947 ±0.001482 0.943 ±0.001533 0.945 0.601 0.962 1 a 0.949 ±0.001455 0.940 ±0.001571 0.944 0.694 0.960 9 0.951 ±0.001428 0.935 ±0.001630 0.943 0.389 0.976 23 0.937 ±0.001607 0.933 ±0.001654 0.935 0.547 0.954 8 0.939 ±0.001583 0.929 ±0.001699 0.934 0.606 0.954 4 a 0.836 ±0.002449 0.834 ±0.002461 0.835 0.521 0.849 4 b 0.836 ±0.002449 0.828 ±0.002496 0.832 0.590 0.847 13 1 0.747 ±0.002875 0.677 ±0.003093 0.710 0.036 0.778 Table 7 : CKIP : Word Segmentation : Closed Track 112 Site RunID R Cr P Cp F Roov Riv 20 0.964 ±0.001232 0.955 ±0.001371 0.959 0.704 0.975 34 0.959 ±0.001311 0.949 ±0.001455 0.954 0.672 0.972 32 0.958 ±0.001327 0.948 ±0.001468 0.953 0.647 0.972 2 a 0.953 ±0.001400 0.946 ±0.001495 0.949 0.679 0.965 2 b 0.951 ±0.001428 0.944 ±0.001521 0.948 0.676 0.964 13 2 0.724 ±0.002956 0.668 ±0.003115 0.695 0.161 0.749 13 3 0.736 ±0.002915 0.653 ±0.003148 0.692 0.160 0.761 13 1 0.654 ±0.003146 0.573 ±0.003271 0.611 0.057 0.680 Table 8 : CKIP : Word Segmentation : Open Track Site RunID R Cr P Cp F Roov Riv 32 0.964 ±0.001176 0.961 ±0.001222 0.963 0.612 0.976 26 0.961 ±0.001222 0.953 ±0.001336 0.957 0.499 0.977 9 0.959 ±0.001252 0.955 ±0.001309 0.957 0.494 0.975 1 a 0.955 ±0.001309 0.956 ±0.001295 0.956 0.650 0.966 15 d 0.953 ±0.001336 0.956 ±0.001295 0.955 0.574 0.966 11 a 0.955 ±0.001309 0.953 ±0.001336 0.954 0.575 0.969 15 b 0.952 ±0.001350 0.956 ±0.001295 0.954 0.575 0.966 15 c 0.949 ±0.001389 0.957 ±0.001281 0.953 0.673 0.959 15 a 0.949 ±0.001389 0.958 ±0.001266 0.953 0.672 0.959 16 0.952 ±0.001350 0.954 ±0.001323 0.953 0.604 0.964 11 b 0.950 ±0.001376 0.954 ±0.001323 0.952 0.602 0.962 5 0.956 ±0.001295 0.947 ±0.001414 0.951 0.493 0.972 1 b 0.946 ±0.001427 0.952 ±0.001350 0.949 0.568 0.959 18 c 0.950 ±0.001376 0.930 ±0.001611 0.940 0.272 0.974 30 a 0.963 ±0.001192 0.918 ±0.001732 0.940 0.175 0.991 18 b 0.954 ±0.001323 0.921 ±0.001703 0.937 0.163 0.981 8 0.933 ±0.001578 0.942 ±0.001476 0.937 0.640 0.943 23 0.933 ±0.001578 0.939 ±0.001511 0.936 0.526 0.948 24 0.923 ±0.001683 0.929 ±0.001621 0.926 0.554 0.936 18 a 0.949 ±0.001389 0.897 ±0.001919 0.922 0.022 0.982 4 a 0.830 ±0.002371 0.832 ±0.002360 0.831 0.473 0.842 4 b 0.817 ±0.002441 0.821 ±0.002420 0.819 0.491 0.829 Table 9 : MSRA : Word Segmentation : Closed Track Site RunID R Cr P Cp F Roov Riv 11 a 0.980 ±0.000884 0.978 ±0.000926 0.979 0.839 0.985 11 b 0.977 ±0.000946 0.976 ±0.000966 0.977 0.840 0.982 14 0.975 ±0.000986 0.976 ±0.000966 0.975 0.811 0.981 32 0.977 ±0.000946 0.971 ±0.001059 0.974 0.675 0.988 10 0.970 ±0.001077 0.970 ±0.001077 0.970 0.804 0.976 30 a 0.977 ±0.000946 0.960 ±0.001237 0.968 0.624 0.989 34 0.959 ±0.001252 0.961 ±0.001222 0.960 0.711 0.968 2 0.949 ±0.001389 0.954 ±0.001323 0.952 0.692 0.958 7 0.953 ±0.001336 0.940 ±0.001499 0.947 0.503 0.969 24 0.938 ±0.001522 0.946 ±0.001427 0.942 0.706 0.946 Table 10 : MSRA : Word Segmentation : Open Track 113 Site RunID R Cr P Cp F Roov Riv 20 0.940 ±0.001207 0.926 ±0.001330 0.933 0.707 0.963 32 0.936 ±0.001244 0.923 ±0.001355 0.930 0.683 0.961 1 a 0.940 ±0.001207 0.914 ±0.001425 0.927 0.634 0.969 26 a 0.936 ±0.001244 0.917 ±0.001402 0.926 0.617 0.966 26 b 0.932 ±0.001279 0.910 ±0.001454 0.921 0.577 0.966 16 0.929 ±0.001305 0.909 ±0.001462 0.919 0.628 0.958 5 0.932 ±0.001279 0.904 ±0.001497 0.918 0.546 0.969 1 b 0.922 ±0.001363 0.914 ±0.001425 0.918 0.637 0.949 8 0.922 ±0.001363 0.912 ±0.001440 0.917 0.680 0.945 31 1 0.917 ±0.001402 0.904 ±0.001497 0.910 0.676 0.940 9 0.919 ±0.001387 0.895 ±0.001558 0.907 0.459 0.964 23 0.915 ±0.001417 0.896 ±0.001551 0.905 0.565 0.949 24 0.902 ±0.001511 0.887 ±0.001609 0.895 0.568 0.934 4 a 0.831 ±0.001905 0.819 ±0.001957 0.825 0.487 0.864 4 b 0.809 ±0.001998 0.827 ±0.001922 0.818 0.637 0.825 Table 11 : UPUC : Word Segmentation : Closed Track Site RunID R Cr P Cp F Roov Riv 34 0.949 ±0.001118 0.939 ±0.001216 0.944 0.768 0.966 2 0.942 ±0.001188 0.928 ±0.001314 0.935 0.711 0.964 20 0.940 ±0.001207 0.927 ±0.001322 0.933 0.741 0.959 7 0.944 ±0.001169 0.922 ±0.001363 0.933 0.680 0.970 12 0.933 ±0.001271 0.916 ±0.001410 0.924 0.656 0.959 32 0.940 ±0.001207 0.907 ±0.001476 0.923 0.561 0.976 24 0.928 ±0.001314 0.906 ±0.001483 0.917 0.660 0.954 10 0.925 ±0.001339 0.897 ±0.001545 0.911 0.593 0.957 Table 12 : UPUC : Word Segmentation : Open Track isters and writing styles .</sentence>
				<definiendum id="0">Baselines</definiendum>
				<definiens id="0">Toplines : WS : Maximum match with testing vocabulary Site RunID R Cr</definiens>
			</definition>
</paper>

		<paper id="3409">
			<definition id="0">
				<sentence>Simons ( 2003 ) remarks that DRT is a theory of semantics and not pragmatics .</sentence>
				<definiendum id="0">DRT</definiendum>
				<definiens id="0">a theory of semantics and not pragmatics</definiens>
			</definition>
			<definition id="1">
				<sentence>Acceptance DRS includes the speaker’s acceptance DRS as well as what the speaker takes the hearer to accept .</sentence>
				<definiendum id="0">DRS</definiendum>
				<definiens id="0">includes the speaker’s acceptance DRS as well as what the speaker takes the hearer to accept</definiens>
			</definition>
			<definition id="2">
				<sentence>The intention DRS is a separate DRS from the belief DRS. The beliefs of an agent give the motivation for making an utterance , and the intention DRS represents the speaker’s intended message .</sentence>
				<definiendum id="0">intention DRS</definiendum>
				<definiendum id="1">DRS</definiendum>
				<definiens id="0">a separate DRS from the belief DRS. The beliefs of an agent give the motivation for making an utterance</definiens>
				<definiens id="1">the speaker’s intended message</definiens>
			</definition>
			<definition id="3">
				<sentence>Believed information labeled ‘bn’ inside a belief DRS or accepted information labeled ‘cn’ inside an acceptance DRS can be either presupposed or asserted inside the intention DRS. Thus , the labels in the intention DRS can only be ‘p’ or ‘a’ .</sentence>
				<definiendum id="0">DRS</definiendum>
				<definiens id="0">Believed information labeled ‘bn’ inside a belief DRS or accepted information labeled ‘cn’ inside an acceptance</definiens>
			</definition>
			<definition id="4">
				<sentence>drs1 : i you t m drs2 : attitude ( you , ‘ACCEPT’ , drs3 ) drs3 : attitude ( i , ‘ACCEPT’ , drs2 ) attitude ( i , ‘BEL’ , drs4 ) drs4 : p b1 : tom ( t ) b2 : mary ( m ) b3 : puppy ( p ) b4 : buy ( t , m , p ) attitude ( you , ‘BEL’ , drs5 ) drs5 : b5 : tom ( t ) b6 : mary ( m ) attitude ( i , ‘INT’ , drs6 ) drs6 : p p1 : tom ( t ) p2 : mary ( m ) a1 : puppy ( p ) a2 : buy ( t , m , a1 ) inform ( i , you , a2 ) Figure 2 : A’s initial Cognitive State In Figure 2 , there are essentially three levels of embedding in a main DRS. If we look at the belief DRS , the first embedded DRS is the agent’s own belief DRS. Level two is the agent’s beliefs about the other agent’s beliefs DRS. Level three is inserted when necessary and represents the agent’s beliefs about the other agent’s beliefs about the agent’s beliefs DRS. DRSs of the same level of embedding have similar status .</sentence>
				<definiendum id="0">‘BEL’</definiendum>
				<definiendum id="1">DRS</definiendum>
				<definiens id="0">puppy ( p ) b4 : buy ( t , m , p ) attitude ( you ,</definiens>
				<definiens id="1">the agent’s own belief DRS. Level two is the agent’s beliefs about the other agent’s beliefs DRS. Level three is inserted when necessary and represents the agent’s beliefs about the other agent’s beliefs about the agent’s beliefs DRS. DRSs of the same level of embedding have similar status</definiens>
			</definition>
</paper>

		<paper id="1508">
			<definition id="0">
				<sentence>Eddy and Durbin ( 1994 ) , and Sakakibara et al. ( 1994 ) modeled RNA secondary structure without pseudoknots by using stochastic context-free grammars ( stochastic CFGs or SCFGs ) .</sentence>
				<definiendum id="0">SCFGs</definiendum>
				<definiens id="0">modeled RNA secondary structure without pseudoknots by using stochastic context-free grammars ( stochastic CFGs or</definiens>
			</definition>
			<definition id="1">
				<sentence>Grammar A stochastic multiple context-free grammar ( stochastic MCFG , or SMCFG ) is a probabilistic extension of MCFG ( Kasami et al. , 1988 ; Seki et al. , 1991 ) or linear context-free rewriting system ( Vijay-Shanker et al. , 1987 ) .</sentence>
				<definiendum id="0">stochastic multiple context-free grammar</definiendum>
				<definiendum id="1">SMCFG</definiendum>
				<definiens id="0">a probabilistic extension of MCFG ( Kasami et al. , 1988 ; Seki et al. , 1991 ) or linear context-free rewriting system</definiens>
			</definition>
			<definition id="2">
				<sentence>An SMCFG is a 5tuple G = ( N , T , F , P , S ) where N is a finite set of nonterminals , T is a finite set of terminals , F is a finite set of functions , P is a finite set of ( production ) rules and S ∈ N is the start symbol .</sentence>
				<definiendum id="0">SMCFG</definiendum>
				<definiendum id="1">T</definiendum>
				<definiendum id="2">F</definiendum>
				<definiendum id="3">P</definiendum>
				<definiendum id="4">S ∈ N</definiendum>
				<definiens id="0">a 5tuple G = ( N , T , F , P , S ) where N is a finite set of nonterminals</definiens>
				<definiens id="1">a finite set of terminals</definiens>
				<definiens id="2">a finite set of functions ,</definiens>
				<definiens id="3">the start symbol</definiens>
			</definition>
			<definition id="3">
				<sentence>For each f ∈ F , positive integers di ( 0 ≤ i ≤ k ) are given and f is a total function from ( T∗ ) d1 × ···× ( T∗ ) dk to ( T∗ ) d0 where each component of f is defined as the concatenation of some components of arguments and constant sequences .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">a total function from ( T∗ ) d1 × ···× ( T∗ ) dk to ( T∗ ) d0 where each component of f is defined as the concatenation of some components of arguments and constant sequences</definiens>
			</definition>
			<definition id="4">
				<sentence>The probability of the latter derivation is SMCFG G is defined as L ( G ) = { w ∈ T∗ | S ∗⇒ 58 Table 1 : SMCFG Gs Type Rule set Function Transition probability Emission probability E Wv → ( ε , ε ) 1 1 S Wv →J [ Wy ] J [ ( x1 , x2 ) ] = x1x2 tv ( y ) 1 D Wv →SK [ Wy ] SK [ ( x1 , x2 ) ] = ( x1 , x2 ) tv ( y ) 1 B1 Wv →C1 [ Wy , Wz ] C1 [ x1 , ( x21 , x22 ) ] = ( x1x21 , x22 ) 1 1 B2 Wv →C2 [ Wy , Wz ] C2 [ x1 , ( x21 , x22 ) ] = ( x21x1 , x22 ) 1 1 B3 Wv →C3 [ Wy , Wz ] C3 [ x1 , ( x21 , x22 ) ] = ( x21 , x1x22 ) 1 1 B4 Wv →C4 [ Wy , Wz ] C4 [ x1 , ( x21 , x22 ) ] = ( x21 , x22x1 ) 1 1 U1L Wv →UPai1L [ Wy ] UPai1L [ ( x1 , x2 ) ] = ( aix1 , x2 ) tv ( y ) ev ( ai ) U1R Wv →UPaj1R [ Wy ] UPaj1R [ ( x1 , x2 ) ] = ( x1aj , x2 ) tv ( y ) ev ( aj ) U2L Wv →UPak2L [ Wy ] UPak2L [ ( x1 , x2 ) ] = ( x1 , akx2 ) tv ( y ) ev ( ak ) U2R Wv →UPal2R [ Wy ] UPal2R [ ( x1 , x2 ) ] = ( x1 , x2al ) tv ( y ) ev ( al ) P Wv →BPaial [ Wy ] BPaial [ ( x1 , x2 ) ] = ( aix1 , x2al ) tv ( y ) ev ( ai , al ) w with probability greater than 0 } .</sentence>
				<definiendum id="0">probability of the latter derivation</definiendum>
				<definiendum id="1">SMCFG G</definiendum>
				<definiendum id="2">B3 Wv →C3 [ Wy , Wz ] C3</definiendum>
				<definiens id="0">L ( G ) = { w ∈ T∗ | S ∗⇒ 58 Table 1 : SMCFG Gs Type Rule set Function Transition probability Emission probability E Wv → ( ε , ε ) 1 1 S Wv →J [ Wy ] J [ ( x1 , x2 ) ] = x1x2 tv</definiens>
				<definiens id="1">x21 , x22 ) ] = ( x21 , x22x1 ) 1 1 U1L Wv →UPai1L [ Wy ] UPai1L [ ( x1 , x2 ) ] = ( aix1 , x2 ) tv ( y ) ev ( ai ) U1R Wv →UPaj1R [ Wy ] UPaj1R [ ( x1 , x2 ) ] = ( x1aj , x2 ) tv ( y ) ev ( aj ) U2L Wv →UPak2L [ Wy ] UPak2L [ ( x1 , x2 ) ] = ( x1 , akx2 ) tv ( y ) ev ( ak ) U2R Wv →UPal2R [ Wy ] UPal2R [</definiens>
			</definition>
			<definition id="5">
				<sentence>In this paper , we focus on an SMCFG Gs = ( N , T , F , P , S ) that satisfies the following conditions : Gs has m different nonterminals denoted by W1 , ... , Wm , each of which uses the only one type of a rule denoted by E , S , D , B1 , B2 , B3 , B4 , U1L , U1R , U2L , U2R or P 1 ( see Table 1 ) .</sentence>
				<definiendum id="0">B3</definiendum>
				<definiens id="0">Gs has m different nonterminals denoted by W1 , ... , Wm , each of which uses the only one type of a rule denoted by E , S , D , B1 , B2 ,</definiens>
			</definition>
			<definition id="6">
				<sentence>The type of Wv is denoted by type ( v ) and we predefine type ( 1 ) = S , that is , W1 is the start symbol .</sentence>
				<definiendum id="0">W1</definiendum>
				<definiens id="0">the start symbol</definiens>
			</definition>
			<definition id="7">
				<sentence>In RNA structure analysis using stochastic grammars , we have to deal with the following three problems : ( 1 ) calculate the optimal alignment of a sequence to a stochastic grammar ( alignment problem ) , ( 2 ) calculate the probability of a sequence given a stochastic grammar ( scoring problem ) , and ( 3 ) estimate optimal probability parameters for a stochastic grammar given a set of example sequences ( training problem ) .</sentence>
				<definiendum id="0">optimal probability parameters</definiendum>
				<definiens id="0">calculate the optimal alignment of a sequence to a stochastic grammar ( alignment problem ) , ( 2 ) calculate the probability of a sequence given a stochastic grammar ( scoring problem</definiens>
			</definition>
</paper>

		<paper id="2911">
			<definition id="0">
				<sentence>Word sense disambiguation ( WSD ) is the task of assigning pre-defined senses to words occurring in some context .</sentence>
				<definiendum id="0">Word sense disambiguation ( WSD</definiendum>
				<definiens id="0">the task of assigning pre-defined senses to words occurring in some context</definiens>
			</definition>
			<definition id="1">
				<sentence>A common method to obtain a predictor CM CU is regularized empirical risk minimization , which minimizes an empirical loss of the predictor ( with regularization ) on the D2 labeled training examples CUB4CG CX BNCH CX B5CV : CM CU BP CPD6CVD1CXD2 CU AW D2 CG CXBPBD C4B4CUB4CG CX B5BNCH CX B5 B7 D6B4CUB5 AX BM ( 1 ) A loss function C4B4A1B5 quantifies the difference between the prediction CUB4CG CX B5 and the true output CH CX , and D6B4A1B5 is a regularization term to control the model complexity .</sentence>
				<definiendum id="0">D6B4A1B5</definiendum>
				<definiens id="0">minimizes an empirical loss of the predictor ( with regularization ) on the D2 labeled training examples CUB4CG CX BNCH CX B5CV : CM CU BP CPD6CVD1CXD2 CU AW D2 CG CXBPBD C4B4CUB4CG CX B5BNCH CX B5 B7 D6B4CUB5 AX BM</definiens>
			</definition>
			<definition id="2">
				<sentence>Let D9 CO BP DB CO B7 A2 CC DA CO BM Then ( 3 ) becomes the minimization of the joint empirical risk written as : D1 CG COBPBD AW D2 CO CG CXBPBD C4B4D9 CC CO CG CO CX BNCH CO CX B5 D2 CO B7 ALCZD9 CO A0 A2 CC DA CO CZ BE BE AX BM ( 4 ) This minimization can be approximately solved by repeating the following alternating optimization procedure until a convergence criterion is met : 78 Nouns art , authority , bar , bum , chair , channel , child , church , circuit , day , detention , dyke , facility , fatigue , feeling , grip , hearth , holiday , lady , material , mouth , nation , nature , post , restraint , sense , spade , stress , yew Verbs begin , call , carry , collaborate , develop , draw , dress , drift , drive , face , ferret , find , keep , leave , live , match , play , pull , replace , see , serve strike , train , treat , turn , use , wander wash , work Adjectives blind , colourless , cool , faithful , fine , fit , free , graceful , green , local , natural , oblique , simple , solemn , vital Figure 1 : Words to be disambiguated ; Senseval-2 English lexical sample task .</sentence>
				<definiendum id="0">D9 CO BP DB CO B7 A2 CC DA CO BM Then</definiendum>
				<definiens id="0">D1 CG COBPBD AW D2 CO CG CXBPBD C4B4D9 CC CO CG CO CX BNCH CO CX B5 D2 CO B7 ALCZD9 CO A0 A2 CC DA CO CZ BE BE AX BM</definiens>
				<definiens id="1">78 Nouns art , authority , bar , bum , chair , channel , child , church , circuit , day , detention , dyke , facility , fatigue , feeling , grip , hearth , holiday , lady , material , mouth , nation , nature , post , restraint , sense , spade , stress</definiens>
				<definiens id="2">find , keep , leave , live , match , play , pull , replace , see , serve strike , train , treat , turn</definiens>
			</definition>
			<definition id="3">
				<sentence>DB CX stands for the word at position CX relative to the word to be disambiguated .</sentence>
				<definiendum id="0">DB CX</definiendum>
				<definiens id="0">the word at position CX relative to the word to be disambiguated</definiens>
			</definition>
			<definition id="4">
				<sentence>To exploit such a natural feature split , we explore the following extension of the joint linear model : CU CO B4CUA2 CY CVBNDCB5 BP DB CC CO DCB7 CG CYBEBY DA B4CYB5 CO CC A2 CY DC B4CYB5 BN ( 5 ) where A2 CY A2 CC CY BP C1 for CY BE BY , BY is a set of disjoint feature groups , and DCB4CYB5 ( or DAB4CYB5 CO ) is a portion of the feature vector DC ( or the weight vector DA CO ) corresponding to the feature group CY , respectively .</sentence>
				<definiendum id="0">BY</definiendum>
				<definiendum id="1">DCB4CYB5</definiendum>
				<definiens id="0">CU CO B4CUA2 CY CVBNDCB5 BP DB CC CO DCB7 CG CYBEBY DA B4CYB5 CO CC A2 CY DC B4CYB5 BN ( 5 ) where A2 CY A2 CC CY BP C1 for CY BE BY</definiens>
				<definiens id="1">a set of disjoint feature groups</definiens>
				<definiens id="2">a portion of the feature vector DC ( or the weight vector DA CO ) corresponding to the feature group CY , respectively</definiens>
			</definition>
			<definition id="5">
				<sentence>That is , SVD is applied to the sub-matrix of the predictor ( weight ) matrix corresponding to each feature group CY , which results in more focused dimension reduction of the predictor matrix .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">applied to the sub-matrix of the predictor ( weight ) matrix corresponding to each feature group CY , which results in more focused dimension reduction of the predictor matrix</definiens>
			</definition>
			<definition id="6">
				<sentence>To learn the shared predictive structure of local context ( LC ) and syntactic relations ( SR ) , it is more advantageous to apply ASO to each of the three sets of problems ( disambiguation of nouns , verbs , and adjectives , respectively ) , separately .</sentence>
				<definiendum id="0">SR</definiendum>
				<definiens id="0">disambiguation of nouns , verbs , and adjectives , respectively ) , separately</definiens>
			</definition>
			<definition id="7">
				<sentence>ASO has one parameter , the dimensionality of the structure matrix A2 CY ( i.e. , the number of left singular vectors to compute ) .</sentence>
				<definiendum id="0">ASO</definiendum>
				<definiens id="0">the number of left singular vectors to compute )</definiens>
			</definition>
			<definition id="8">
				<sentence>AF Apply ASO to the three sets of disambiguation problems ( corresponding to nouns , verbs , and adjectives ) , separately , using the extended model ( 5 ) with BY BP CUC4BVBNCBCACV .</sentence>
				<definiendum id="0">AF Apply ASO</definiendum>
				<definiens id="0">to the three sets of disambiguation problems ( corresponding to nouns , verbs , and adjectives</definiens>
			</definition>
			<definition id="9">
				<sentence>SGG04 is an early version of GGS05 .</sentence>
				<definiendum id="0">SGG04</definiendum>
				<definiens id="0">an early version of GGS05</definiens>
			</definition>
</paper>

		<paper id="1666">
			<definition id="0">
				<sentence>More formally , the Bayes risk of a model y = h ( x ) is defined as R ( h ) = Ex , y∆ ( y , h ( x ) ) , ( 1 ) where the expectation is taken over all the possible inputs x and labels y and ∆ ( y , yprime ) denotes a loss incurred by assigning x to yprime when the correct label is y. We assume that the loss function possesses values within the range from 0 to 1 , which is equivalent to the requirement that the loss function is bounded in ( Tsochantaridis et al. , 2004 ) .</sentence>
				<definiendum id="0">Bayes risk of a model y = h ( x )</definiendum>
			</definition>
			<definition id="1">
				<sentence>It follows that an optimal reranker hstar is one which chooses the label y that minimizes the expected loss : hstar ( x ) = arg min yprime∈G ( x ) summationdisplay y P ( y|x ) ∆ ( y , yprime ) , ( 2 ) where G ( x ) denotes a candidate list provided by a baseline probabilistic model for the input x. In this paper we propose different approaches to loss approximation .</sentence>
				<definiendum id="0">G ( x )</definiendum>
				<definiens id="0">an optimal reranker hstar is one which chooses the label y that minimizes the expected loss : hstar ( x ) = arg min yprime∈G ( x ) summationdisplay y P ( y|x ) ∆ ( y , yprime )</definiens>
			</definition>
			<definition id="2">
				<sentence>This kernel defines a feature space which is appropriate for estimating the discriminative probability in the candidate list in the form of a normalized exponential P ( x , y ) summationtext yprime∈G ( x ) P ( x , yprime ) ≈ ( 7 ) exp ( wstarT φFKˆθ ( x , y ) ) summationtext yprime∈G ( x ) exp ( wstarT φFKˆθ ( x , yprime ) ) for some choice of the decision vector w = wstar with the first component equal to one .</sentence>
				<definiendum id="0">wstarT φFKˆθ</definiendum>
				<definiens id="0">appropriate for estimating the discriminative probability in the candidate list in the form of a normalized exponential P ( x , y ) summationtext yprime∈G ( x</definiens>
			</definition>
			<definition id="3">
				<sentence>It follows that it is natural to use an estimator of the discriminative probability P ( y|x ) in exponential form and , therefore , the appropriate form of the loss minimizing classifier is the following : ˆhFK ( x ) = ( 8 ) arg min yprime∈G ( x ) summationdisplay y∈G ( x ) exp ( A ˆwT φFKˆθ ( x , yprime ) ) ∆ ( y , yprime ) , where ˆw is learned during classifier training and the scalar parameter A can be tuned on the development set .</sentence>
				<definiendum id="0">ˆwT φFKˆθ</definiendum>
				<definiens id="0">learned during classifier training and the scalar parameter A can be tuned on the development set</definiens>
			</definition>
			<definition id="4">
				<sentence>From this fact , the form of the loss minimizing classifier follows : ˆhTK ( x ) = ( 11 ) arg min yprime∈G ( x ) summationdisplay y∈G ( x ) g ( A ˆwT φTKˆθ ( x , yprime ) ) ∆ ( y , yprime ) , where g is the logistic sigmoid and the scalar parameter A should be selected on the development set .</sentence>
				<definiendum id="0">ˆwT φTKˆθ</definiendum>
				<definiendum id="1">g</definiendum>
				<definiens id="0">the logistic sigmoid and the scalar parameter A should be selected on the development set</definiens>
			</definition>
			<definition id="5">
				<sentence>The discriminative probability of a candidate is simply the number of votes cast for that candidate normalized across candidates .</sentence>
				<definiendum id="0">discriminative probability of a candidate</definiendum>
				<definiens id="0">the number of votes cast for that candidate normalized across candidates</definiens>
			</definition>
			<definition id="6">
				<sentence>As the Loss kernel was a generalization of the Fisher kernel to arbitrary loss function , so the Loss Logit Kernel is a generalization of the TOP kernel for reranking .</sentence>
				<definiendum id="0">Loss Logit Kernel</definiendum>
				<definiens id="0">a generalization of the TOP kernel for reranking</definiens>
			</definition>
			<definition id="7">
				<sentence>The loss function is defined as ∆ ( y , yprime ) = 1 − F1 ( y , yprime ) , where F1 denotes F1 measure on bracketed constituents .</sentence>
				<definiendum id="0">loss function</definiendum>
				<definiens id="0">∆ ( y , yprime ) = 1 − F1 ( y , yprime ) , where F1 denotes F1 measure on bracketed constituents</definiens>
			</definition>
			<definition id="8">
				<sentence>Standard measures of parsing accuracy , plus complete match accuracy , are shown in table 1.3 As the baselines , the table includes the results of the standard TOP reranking kernel ( TRK ) ( Henderson and Titov , 2005 ) and the baseline probabilistic model ( SSN ) ( Henderson , 2003 ) .</sentence>
				<definiendum id="0">SSN</definiendum>
				<definiens id="0">of parsing accuracy , plus complete match accuracy</definiens>
			</definition>
			<definition id="9">
				<sentence>SSN-Estim is the model using loss estimation on the basic probabilistic model , as explained in section 2 .</sentence>
				<definiendum id="0">SSN-Estim</definiendum>
				<definiens id="0">the model using loss estimation on the basic probabilistic model</definiens>
			</definition>
			<definition id="10">
				<sentence>It is important to point out that SSN-Estim , which improves significantly over SSN , does not require the learning of a discriminative classifier , and differs from the SSN only by use of the different classification model ( equation ( 5 ) ) , which means that it is extremely easy to apply in practice .</sentence>
				<definiendum id="0">SSN-Estim</definiendum>
				<definiens id="0">improves significantly over SSN , does not require the learning of a discriminative classifier</definiens>
			</definition>
			<definition id="11">
				<sentence>Percentage labeled constituent recall ( R ) , precision ( P ) , combination of both ( F1 ) , an average number of crossing brackets per sentence ( CB ) , percentage of sentences with 0 and ≤ 2 crossing brackets ( 0C and 2C , respectively ) .</sentence>
				<definiendum id="0">constituent recall</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">an average number of crossing brackets per sentence ( CB ) , percentage of sentences with 0 and ≤ 2 crossing brackets ( 0C and 2C , respectively )</definiens>
			</definition>
</paper>

		<paper id="1406">
			<definition id="0">
				<sentence>The distributional hypothesis ( Harris , 1968 ) says the following : The meaning of entities , and the meaning of grammatical relations among them , is related to the restriction of combinations of these entities relative to other entities .</sentence>
				<definiendum id="0">distributional hypothesis</definiendum>
				<definiens id="0">The meaning of entities , and the meaning of grammatical relations among them , is related to the restriction of combinations of these entities relative to other entities</definiens>
			</definition>
			<definition id="1">
				<sentence>Weeds and Weir use the following formula to describe the set of True Positives of co-occurrence types , which w1 and w2 are considered main verbs in copora : TP ( w1 , w2 ) = F ( w1 ) ∩F ( w2 ) They use the t-test from ( Manning and Sch¨utze , 1999 ) as the weight formula Dt ( w , c ) : Dt ( w , c ) = p ( c , w ) −P ( c ) P ( w ) radicalBigP ( c , w ) N Weeds and Weir then calculate the precision by using the proportion of features of w1 which occurs in both words , and the recall by using the proportion of features of w2 which occur in both words .</sentence>
				<definiendum id="0">c , w ) N Weeds</definiendum>
				<definiens id="0">the precision by using the proportion of features of w1 which occurs in both words</definiens>
			</definition>
</paper>

		<paper id="2008">
			<definition id="0">
				<sentence>GIZA++ consists of a set of statistical translation models of different complexity , namely the IBM ones ( Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">GIZA++</definiendum>
			</definition>
			<definition id="1">
				<sentence>Since Polish is an inflected language , the connections between words are indicated through cases .</sentence>
				<definiendum id="0">Polish</definiendum>
				<definiens id="0">an inflected language , the connections between words are indicated through cases</definiens>
			</definition>
</paper>

		<paper id="3209">
			<definition id="0">
				<sentence>A paradigm lists the prototypical morphological properties of lexemes belonging to a particular part of speech ( POS ) category ; for example , a paradigm for regular English verbs would include the suffixes { $ , ed $ , ing $ , s $ } 1 .</sentence>
				<definiendum id="0">paradigm</definiendum>
				<definiens id="0">lists the prototypical morphological properties of lexemes belonging to a particular part of speech ( POS</definiens>
			</definition>
			<definition id="1">
				<sentence>The probabilistic paradigm model consists of three matrices : the data matrix D , the morphological probabilities matrix M , and the lexical probabilities matrix L. Let m be the number of stems , n the number of stems , and p the number of paradigms .</sentence>
				<definiendum id="0">probabilistic paradigm model</definiendum>
				<definiens id="0">consists of three matrices : the data matrix D , the morphological probabilities matrix M , and the lexical probabilities matrix L. Let m be the number of stems , n the number of stems , and p the number of paradigms</definiens>
			</definition>
			<definition id="2">
				<sentence>A lexical paradigm is the full set of word forms for a particular stem , and is an instantiation of the canonical paradigm for a particular stem .</sentence>
				<definiendum id="0">lexical paradigm</definiendum>
				<definiens id="0">the full set of word forms for a particular stem , and is an instantiation of the canonical paradigm for a particular stem</definiens>
			</definition>
			<definition id="3">
				<sentence>LDA is a generative probabilistic model for discrete data .</sentence>
				<definiendum id="0">LDA</definiendum>
			</definition>
			<definition id="4">
				<sentence>For the application of topic discovery within a corpus of documents , a document consists of a mixture of underlying topics , and each topic consists of a probability distribution over the vocabulary .</sentence>
				<definiendum id="0">document</definiendum>
			</definition>
			<definition id="5">
				<sentence>LDA produces two non-negative parameter matrices , Gamma and Beta : Gamma is the matrix of Dirichlet posteriors , encoding the distribution of documents and topics ; Beta encodes the distribution of words and topics .</sentence>
				<definiendum id="0">Gamma</definiendum>
				<definiendum id="1">Beta</definiendum>
				<definiens id="0">the matrix of Dirichlet posteriors , encoding the distribution of documents and topics</definiens>
			</definition>
			<definition id="6">
				<sentence>To deal with this , we have formulated a recursive wrapper algorithm for LDA that accomplishes a divisive clustering of suffixes .</sentence>
				<definiendum id="0">LDA</definiendum>
				<definiens id="0">accomplishes a divisive clustering of suffixes</definiens>
			</definition>
			<definition id="7">
				<sentence>mente/amente $ R is a derivational suffix .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">a derivational suffix</definiens>
			</definition>
			<definition id="8">
				<sentence>Linguistica takes a list of word types , proposes segmentations of words into stems and suffixes , and organizes them into signatures .</sentence>
				<definiendum id="0">Linguistica</definiendum>
				<definiens id="0">takes a list of word types , proposes segmentations of words into stems and suffixes , and organizes them into signatures</definiens>
			</definition>
			<definition id="9">
				<sentence>A signature is a nonprobabilistic data structure that groups together all stems that share a common set of suffixes .</sentence>
				<definiendum id="0">signature</definiendum>
				<definiens id="0">a nonprobabilistic data structure that groups together all stems that share a common set of suffixes</definiens>
			</definition>
</paper>

		<paper id="3122">
			<definition id="0">
				<sentence>It generates a vector of 5 numeric values for each phrase pair : • phrase translation probability : φ ( ¯f|¯e ) = count ( ¯f , ¯e ) count ( ¯e ) , φ ( ¯e| ¯f ) = count ( ¯f , ¯e ) count ( ¯f ) 2http : //www.phramer.org/ – Java-based open-source phrase based SMT system 3http : //www.isi.edu/licensed-sw/carmel/ 4http : //www.speech.sri.com/projects/srilm/ 5http : //www.iccs.inf.ed.ac.uk/∼pkoehn/training.tgz 150 • lexical weighting ( Koehn et al. , 2003 ) : lex ( ¯f|¯e , a ) = nproductdisplay i=1 1 | { j| ( i , j ) ∈ a } | summationdisplay ∀ ( i , j ) ∈a w ( fi|ej ) lex ( ¯e|¯f , a ) = mproductdisplay j=1 1 | { i| ( i , j ) ∈ a } | summationdisplay ∀ ( i , j ) ∈a w ( ej|fi ) • phrase penalty : τ ( ¯f|¯e ) = e ; log ( τ ( ¯f|¯e ) ) = 1 We used the Pharaoh decoder for both the Minimum Error Rate Training ( Och , 2003 ) and test dataset decoding .</sentence>
				<definiendum id="0">fi|ej ) lex</definiendum>
			</definition>
			<definition id="1">
				<sentence>German is a compounding language , thus the German vocabulary is virtu7Time factor .</sentence>
				<definiendum id="0">German</definiendum>
				<definiens id="0">a compounding language</definiens>
			</definition>
</paper>

		<paper id="2903">
			<definition id="0">
				<sentence>The probabilistic context-free grammar ( PCFG ) formalism is the basis of most modern statistical parsers .</sentence>
				<definiendum id="0">probabilistic context-free grammar ( PCFG ) formalism</definiendum>
				<definiens id="0">the basis of most modern statistical parsers</definiens>
			</definition>
</paper>

		<paper id="2718">
			<definition id="0">
				<sentence>net Here annotations live in a separate standoff annotation document , and are anchored in the raw data via standoff pointers .</sentence>
				<definiendum id="0">net Here annotations</definiendum>
				<definiens id="0">live in a separate standoff annotation document , and are anchored in the raw data via standoff pointers</definiens>
			</definition>
			<definition id="1">
				<sentence>The HOG system ( Callmeier et al. , 2004 ) for the integration of shallow and deep linguistic processors ( using a pipeline making use of XML plus XSLT transformations to pass data between processors ) was developed during the Deep Thought project , as was a standard for the integration of semantic analyses produced by diverse components : RMRS ( Copestake , 2003 ) allows underspecification of semantic analyses in such a way that the analysis produced by a shallow component may be considered an underspecification of a fuller semantic analysis produced by a deeper component .</sentence>
				<definiendum id="0">HOG system</definiendum>
				<definiendum id="1">RMRS</definiendum>
				<definiens id="0">Callmeier et al. , 2004 ) for the integration of shallow and deep linguistic processors ( using a pipeline making use of XML plus XSLT transformations to pass data between processors</definiens>
			</definition>
			<definition id="2">
				<sentence>E.g. the content of an annotation describing a token may be the text of the token itself ( see fig .</sentence>
				<definiendum id="0">E.g.</definiendum>
				<definiens id="0">the content of an annotation describing a token may be the text of the token itself</definiens>
			</definition>
			<definition id="3">
				<sentence>Each such level consists of a set of annotations each of which may be said to build on a set of lower annotations .</sentence>
				<definiendum id="0">such level</definiendum>
			</definition>
			<definition id="4">
				<sentence>XML provides a clean standardsbased framework in which to serialize our SAF objects .</sentence>
				<definiendum id="0">XML</definiendum>
			</definition>
			<definition id="5">
				<sentence>The fsm element consists of a number of state elements ( with attribute id ) declaring the available lattice nodes , followed by annot annotation definitions .</sentence>
				<definiendum id="0">fsm element</definiendum>
			</definition>
			<definition id="6">
				<sentence>7http : //www.language-archives.orgLAC/metadata.html A SAF-aware sentence splitter produces SAF XML describing the span of each sentence , from which a SAF-aware ( and XML-aware ) preprocessor/tokeniser maps raw sentence text into a SAF XML token lattice ( with some additional annotation to describe tokens such as digit sequences ) .</sentence>
				<definiendum id="0">XML-aware ) preprocessor/tokeniser maps</definiendum>
				<definiens id="0">//www.language-archives.org/OLAC/metadata.html A SAF-aware sentence splitter produces SAF XML describing the span of each sentence</definiens>
			</definition>
</paper>

		<paper id="1618">
			<definition id="0">
				<sentence>TimeBank annotates a word or phrase as an EVENT if it describes a situation that can “happen” or “occur” , or if it describes a “state” or “circumstance” that “participate [ s ] in an opposition structure in a given text” ( Pustejovsky , et .</sentence>
				<definiendum id="0">TimeBank</definiendum>
				<definiendum id="1">phrase</definiendum>
				<definiens id="0">annotates a word or</definiens>
			</definition>
			<definition id="1">
				<sentence>TimeBank EVENTs include not only the normal linguistic events , but also some linguistic states , depending on the contexts in which they occur .</sentence>
				<definiendum id="0">TimeBank EVENTs</definiendum>
			</definition>
			<definition id="2">
				<sentence>YamCha has a number of parameters that define how it learns .</sentence>
				<definiendum id="0">YamCha</definiendum>
			</definition>
			<definition id="3">
				<sentence>As part of its algorithm , Evita includes a check that determines whether or not a word occurs as an event in TimeBank .</sentence>
				<definiendum id="0">Evita</definiendum>
				<definiens id="0">includes a check that determines whether or not a word occurs as an event in TimeBank</definiens>
			</definition>
			<definition id="4">
				<sentence>Precision is defined as the number of B and I labels our system identifies correctly , divided by the total number of B and I labels our system predicted .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the number of B and I labels our system identifies correctly , divided by the total number of B and I labels our system predicted</definiens>
			</definition>
			<definition id="5">
				<sentence>Recall is defined as the number of B and I labels our system identifies correctly , divided by the total number of B and I labels in the TimeBank data .</sentence>
				<definiendum id="0">Recall</definiendum>
			</definition>
			<definition id="6">
				<sentence>Fmeasure is defined as the geometric mean of precision and recall9 .</sentence>
				<definiendum id="0">Fmeasure</definiendum>
			</definition>
</paper>

		<paper id="3117">
			<definition id="0">
				<sentence>Stochastic Inversion Transduction Grammars ( SITG ) can be viewed as a restricted Stochastic Context-Free Syntax-Directed Transduction Scheme .</sentence>
				<definiendum id="0">Stochastic Inversion Transduction Grammars ( SITG</definiendum>
				<definiens id="0">a restricted Stochastic Context-Free Syntax-Directed Transduction Scheme</definiens>
			</definition>
			<definition id="1">
				<sentence>Bilingual translation phrases are an important component of a phrase-based system .</sentence>
				<definiendum id="0">Bilingual translation phrases</definiendum>
			</definition>
			<definition id="2">
				<sentence>Grammars Stochastic Inversion Transduction Grammars ( SITGs ) ( Wu , 1997 ) can be viewed as a restricted subset of Stochastic Syntax-Directed Transduction Grammars .</sentence>
				<definiendum id="0">Grammars Stochastic Inversion Transduction Grammars ( SITGs )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Formally , a SITG in Chomsky Normal Form1 a0a2a1 can be defined as a tuple a3a5a4a7a6a9a8a10a6a9a11a13a12a2a6a9a11a15a14a16a6a18a17a19a6a5a20a22a21 , where : a4 is a finite set of non-terminal symbols ; a8a24a23a25a4 is the axiom of the SITG ; a11a13a12 is a finite set of terminal symbols of language 1 ; and a11 a14 is a finite set of terminal symbols of language 2 .</sentence>
				<definiendum id="0">a4</definiendum>
				<definiendum id="1">a8a24a23a25a4</definiendum>
				<definiendum id="2">a11a13a12</definiendum>
				<definiens id="0">a tuple a3a5a4a7a6a9a8a10a6a9a11a13a12a2a6a9a11a15a14a16a6a18a17a19a6a5a20a22a21 , where :</definiens>
				<definiens id="1">a finite set of non-terminal symbols ;</definiens>
				<definiens id="2">the axiom of the SITG</definiens>
			</definition>
			<definition id="4">
				<sentence>a17 is a finite set of : lexical rules of the type a26a28a27a30a29a22a31a16a32 , a26a33a27a30a32a34a31a36a35 , a26a37a27 a29a22a31a36a35 ; direct syntactic rules that are noted as a26 a27 a38a39a41a40a43a42 ; and inverse syntactic rules that are noted as a26a44a27a46a45a5a39a47a40a49a48 , where a26 a6 a39 a6 a40 a23a50a4 , a29 a23a15a11 a12 , a35 a23a33a11a51a14 , and a32 is the empty string .</sentence>
				<definiendum id="0">a17</definiendum>
				<definiendum id="1">a32</definiendum>
				<definiens id="0">a finite set of : lexical rules of the type a26a28a27a30a29a22a31a16a32 , a26a33a27a30a32a34a31a36a35 , a26a37a27 a29a22a31a36a35 ; direct syntactic rules that are noted as a26 a27 a38a39a41a40a43a42 ; and inverse syntactic rules that are noted as a26a44a27a46a45a5a39a47a40a49a48 , where a26 a6 a39 a6 a40 a23a50a4</definiens>
				<definiens id="1">the empty string</definiens>
			</definition>
			<definition id="5">
				<sentence>More precisely , a bracketed corpus a61 is a set of tuples a3 a29 a6 a39a63a62 a6 a35 a6 a39a63a64 a21 , where a29 and a35 are strings , a39a54a62 is the bracketing of a29 , and a39a54a64 is the bracketing of a35 .</sentence>
				<definiendum id="0">a39a54a62</definiendum>
				<definiendum id="1">a39a54a64</definiendum>
				<definiens id="0">a set of tuples a3 a29 a6 a39a63a62 a6 a35 a6 a39a63a64 a21 , where a29 and a35 are strings</definiens>
				<definiens id="1">the bracketing of a29 , and</definiens>
				<definiens id="2">the bracketing of a35</definiens>
			</definition>
</paper>

		<paper id="3322">
</paper>

		<paper id="0703">
			<definition id="0">
				<sentence>A sentence fragment is defined to be a fragment of text segmented by commas , periods , question marks , exclamation marks , or space marks .</sentence>
				<definiendum id="0">sentence fragment</definiendum>
				<definiens id="0">a fragment of text segmented by commas , periods , question marks , exclamation marks , or space marks</definiens>
			</definition>
			<definition id="1">
				<sentence>The similarity of two sentence fragments X and Y is defined as follows : ( ) ( ) ( ) ( ) ∑∑ ∑ ∈∈ ∩∈ + × = YtXw YXk tWtwWt kWt YXSim 2 , ( 1 ) where Wt ( w ) is the weight of a word w. In Equation 1 , k is one of the words appearing in both X and Y. Fragments with similarity higher than a threshold are merged together .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiendum id="1">Wt ( w )</definiendum>
				<definiens id="0">follows : ( ) ( ) ( ) ( ) ∑∑ ∑ ∈∈ ∩∈ + ×</definiens>
				<definiens id="1">the weight of a word w. In Equation 1 , k is one of the words appearing in both X and Y. Fragments with similarity higher than a threshold are merged together</definiens>
			</definition>
			<definition id="2">
				<sentence>Length is measured in characters and term weights are designed as in Table 3 .</sentence>
				<definiendum id="0">Length</definiendum>
				<definiens id="0">measured in characters and term weights</definiens>
			</definition>
			<definition id="3">
				<sentence>The second column in each table lists the accuracy which is defined as the percentage of postings which are separated into the same number of questions as manually tagged .</sentence>
				<definiendum id="0">accuracy</definiendum>
			</definition>
</paper>

		<paper id="3110">
			<definition id="0">
				<sentence>Word posterior probabilities are a common approach for confidence estimation in automatic speech recognition and machine translation .</sentence>
				<definiendum id="0">Word posterior probabilities</definiendum>
			</definition>
</paper>

		<paper id="1516">
			<definition id="0">
				<sentence>Second , XMG permits the integration in a TAG of a semantic dimension .</sentence>
				<definiendum id="0">XMG</definiendum>
				<definiens id="0">permits the integration in a TAG of a semantic dimension</definiens>
			</definition>
			<definition id="1">
				<sentence>The surface realiser GenI takes a TAG and a flat semantic logical form as input , and produces all the sentences that are associated with that logical form by the grammar .</sentence>
				<definiendum id="0">surface realiser GenI</definiendum>
				<definiens id="0">takes a TAG and a flat semantic logical form as input , and produces all the sentences that are associated with that logical form by the grammar</definiens>
			</definition>
			<definition id="2">
				<sentence>The LORIA toolbox provides an integrated environment for TAG based semantic processing : either to construct the semantic representation of a given sentence ( parsing ) or to generate a sentence verbalising a given semantic content ( generation ) .</sentence>
				<definiendum id="0">LORIA toolbox</definiendum>
				<definiens id="0">provides an integrated environment for TAG based semantic processing : either to construct the semantic representation of a given sentence ( parsing ) or to generate a sentence verbalising a given semantic content</definiens>
			</definition>
			<definition id="3">
				<sentence>Warren’s Abstract Machine : A Tutorial Reconstruction .</sentence>
				<definiendum id="0">Warren’s Abstract Machine</definiendum>
				<definiens id="0">A Tutorial Reconstruction</definiens>
			</definition>
			<definition id="4">
				<sentence>The Metagrammar Compiler : An NLP Application with aMulti-paradigmArchitecture .</sentence>
				<definiendum id="0">Metagrammar Compiler</definiendum>
				<definiens id="0">An NLP Application with aMulti-paradigmArchitecture</definiens>
			</definition>
			<definition id="5">
				<sentence>A Uniform Computational Model for Natural Language Parsing and Generation .</sentence>
				<definiendum id="0">Uniform Computational</definiendum>
				<definiens id="0">Model for Natural Language Parsing and Generation</definiens>
			</definition>
			<definition id="6">
				<sentence>XMG : an Extensible Metagrammatical Framework .</sentence>
				<definiendum id="0">XMG</definiendum>
				<definiens id="0">an Extensible Metagrammatical Framework</definiens>
			</definition>
			<definition id="7">
				<sentence>DyALog : a tabular logic programming based environment for NLP .</sentence>
				<definiendum id="0">DyALog</definiendum>
				<definiens id="0">a tabular logic programming based environment for NLP</definiens>
			</definition>
</paper>

		<paper id="3205">
			<definition id="0">
				<sentence>The length of a particular model ( or morphology ) is defined as the sum of the lengths of the three lists that compose it ; the length of each list is in turn defined as the sum of the lengths of elements in it , plus a small cost for the list structure itself1 .</sentence>
				<definiendum id="0">length of a particular model</definiendum>
				<definiendum id="1">length of each list</definiendum>
				<definiens id="0">the sum of the lengths of the three lists that compose it ; the</definiens>
				<definiens id="1">the sum of the lengths of elements in it , plus a small cost for the list structure itself1</definiens>
			</definition>
			<definition id="1">
				<sentence>A pointer is a symbol that stands for a particular morpheme , and the recourse to pointers relies on the assumption that 1More on this in section 2.1 below 32 their length is lesser than that of the morphemes they replace .</sentence>
				<definiendum id="0">pointer</definiendum>
				<definiens id="0">a symbol that stands for a particular morpheme</definiens>
			</definition>
			<definition id="2">
				<sentence>The length of a signature is the sum of the lengths of the two lists it contains , and the length of each list is the sum of the lengths of the pointers it contains ( plus a small cost for the list itself ) .</sentence>
				<definiendum id="0">length of a signature</definiendum>
				<definiens id="0">the sum of the lengths of the two lists it contains</definiens>
				<definiens id="1">the sum of the lengths of the pointers it contains ( plus a small cost for the list itself )</definiens>
			</definition>
			<definition id="3">
				<sentence>The description length of a list of pointers to a particular subset µ ∈ { M } is defined as the sum of the lengths of the M pointers it contains , plus a small cost of for specifying the list structure itself , defined as λ ( M ) : = 0 if M = 0 and logM bits otherwise3 : DLptr ( µ ) : = λ ( M ) − summationdisplay t∈µ logpr ( t ) The expected length of a pointer is equal to the entropy over the distribution of stems : hstems : = Et∈τ [ −logpr ( t ) ] = − summationdisplay t∈τ pr ( t ) logpr ( t ) Thus , the expected description length of a list of pointers to M stems ( over all subsets µ ∈ { M } ) is : Eµ∈ { M } [ DLptr ( µ ) ] = 1| { M } | summationdisplay µ∈ { M } DLptr ( µ ) = λ ( M ) +Mhstems ( 1 ) This value increases as a function of both the number of stems which are pointed to and the entropy over the distribution of stems .</sentence>
				<definiendum id="0">description length of a list of pointers</definiendum>
				<definiens id="0">the sum of the lengths of the M pointers it contains , plus a small cost of for specifying the list structure itself , defined as λ ( M ) : = 0 if M = 0 and logM bits otherwise3 : DLptr ( µ ) : = λ ( M ) − summationdisplay t∈µ logpr ( t ) The expected length of a pointer is equal to the entropy over the distribution of stems : hstems : = Et∈τ [ −logpr ( t ) ] = − summationdisplay t∈τ pr ( t ) logpr ( t ) Thus , the expected description length of a list of pointers to M stems ( over all subsets µ ∈ { M } ) is : Eµ∈ { M } [ DLptr ( µ ) ] = 1| { M } | summationdisplay µ∈ { M } DLptr ( µ ) = λ ( M ) +Mhstems ( 1 ) This value increases as a function of both the number of stems which are pointed to and the entropy over the distribution of stems</definiens>
			</definition>
			<definition id="4">
				<sentence>For instance , we can make the assumption that M follows a binomial distribution ( M ∼ B [ N , p ] ) .6 Under this assumption ( and , as always , that of a Zipfian distribution of stems ) , the expected description length gain by using binary strings rather than polarized lists is : EMbracketleftbigEµ∈ { M } [ DLptr ( µ ) ] −DLbin ( M ) bracketrightbig = summationtextNM=1 pr ( M ) parenleftBig 1+λ ( ˆM ) + ˆMhZipfN , s−NhbinN , M parenrightBig with pr ( M ) = parenleftbigNMparenrightbigpM ( 1−p ) N−M Letting N and s vary as in the previous computation , we set the probability for a stem to have a pointer on it to p = 0.01 , so that the distribution of pointed versus “unpointed” elements is considerably skewed.7 6This model predicts that most of the time , the number M of elements pointed to is equal to N · p ( where p denotes the probability for a stem to have a pointer on it ) , and that the probability pr ( M ) of other values of M decreases as they diverge from N ·p. 7By symmetry , the same results would be found with p = 0 500 1000 1500 2000 −150 −50 0 50 Binary strings vs. polarized lists ( binomial distribution of M , p = 0.01 ) Total number of stems N Description length gain ( in bits ) s=0 s=1 s=2 s=3 Figure 4 : Expected gain in description length by using binary strings rather than polarized lists under the assumption that M ∼ B [ N,0.01 ] .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the probability for a stem to have a pointer on it ) , and that the probability pr ( M ) of other values of M decreases as they diverge from N ·p. 7By symmetry , the same results would be found with p = 0 500 1000 1500 2000 −150 −50 0 50 Binary strings vs. polarized lists ( binomial distribution of M , p = 0.01 ) Total number of stems N Description length gain ( in bits</definiens>
			</definition>
			<definition id="5">
				<sentence>The frequency of stems as a function of their rank and the distribution of the size of signatures are plot37 0 100 200 300 400 500 6000.0000 Frequency as a function of rank ( French corpus ) Rank Frequency Figure 7 : Frequency versus rank ( stems ) in French corpus .</sentence>
				<definiendum id="0">frequency of stems</definiendum>
				<definiens id="0">a function of rank ( French corpus ) Rank Frequency Figure 7 : Frequency versus rank ( stems ) in French corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>We have seen that in a range of cases , using binary strings instead of the more traditional frequency-based pointers leads to a smaller overall grammar length , and there is no guarantee that we will not find an even shorter way to accomplish the 2 4 6 8 10 0 5000 10000 15000 DL of lists and binary strings ( French corpus ) Heuristics Description length ( in bits ) ListsBinary strings 1 3 5 7 9 Figure 10 : Comparison of DL of 10 successive morphologies using pointers versus binary strings ( French corpus ) same thing tomorrow11 .</sentence>
				<definiendum id="0">French corpus</definiendum>
				<definiens id="0">French corpus ) Heuristics Description length ( in bits</definiens>
			</definition>
</paper>

		<paper id="0604">
			<definition id="0">
				<sentence>The MaxEnt framework offers a mathematically sound way to build a probabilistic model for SOI , which combines different linguistic cues .</sentence>
				<definiendum id="0">MaxEnt framework</definiendum>
				<definiens id="0">offers a mathematically sound way to build a probabilistic model for SOI , which combines different linguistic cues</definiens>
			</definition>
			<definition id="1">
				<sentence>It can be proven that the probability distribution p satisfying the above assumption is the one with the highest entropy , is unique and has the following exponential form ( Berger et al. 1996 ) : ( 1 ) ∏ = = k j caf j j cZcap 1 ) , ( ) ( 1 ) | ( a where Z ( c ) is a normalization factor , fj ( a , c ) are the values of k features of the pair ( a , c ) and correspond to the linguistic cues of c that are relevant to predict the outcome a. Features are extracted from the training data and define the constraints that the probabilistic model p must satisfy .</sentence>
				<definiendum id="0">Z ( c )</definiendum>
				<definiendum id="1">fj</definiendum>
				<definiendum id="2">c )</definiendum>
				<definiens id="0">a normalization factor</definiens>
				<definiens id="1">c that are relevant to predict the outcome a. Features are extracted from the training data and define the constraints that the probabilistic model p must satisfy</definiens>
			</definition>
			<definition id="2">
				<sentence>The context σ is a pair &lt; vσ , nσ &gt; , where vσ is the verbal head and nσ its nominal dependent in σ .</sentence>
				<definiendum id="0">vσ</definiendum>
				<definiens id="0">the verbal head and nσ its nominal dependent in σ</definiens>
			</definition>
			<definition id="3">
				<sentence>The test corpus consists of a set of verb-noun pairs randomly extracted from the reference Treebanks : 1,000 pairs for Italian and 1,373 for Czech .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiens id="0">consists of a set of verb-noun pairs randomly extracted from the reference Treebanks : 1,000 pairs for Italian and 1,373 for Czech</definiens>
			</definition>
</paper>

		<paper id="2205">
			<definition id="0">
				<sentence>A similarity metric defined on the context representations is used to cluster similar terms ( e.g. by the nearest neighbor method ) .</sentence>
				<definiendum id="0">similarity metric</definiendum>
				<definiens id="0">used to cluster similar terms</definiens>
			</definition>
			<definition id="1">
				<sentence>Tokenization errors are heuristically removed and the words are replaced by their normal forms ( e.g. infinitive form for verbs , nominative singular for nouns ) .</sentence>
				<definiendum id="0">Tokenization errors</definiendum>
				<definiens id="0">normal forms ( e.g. infinitive form for verbs , nominative singular for nouns</definiens>
			</definition>
			<definition id="2">
				<sentence>A property edge links the head word of a syntactic chunk ( verb or noun phrase ) with its modifiers ( adverbs or adjectives respectively ) that characterize the head word and is bidirectional .</sentence>
				<definiendum id="0">property edge</definiendum>
				<definiens id="0">links the head word of a syntactic chunk ( verb or noun phrase ) with its modifiers ( adverbs or adjectives respectively ) that characterize the head word</definiens>
			</definition>
			<definition id="3">
				<sentence>A sequential edge connects the head words ( e.g. main verbs , head nouns ) of syntactic chunks reflecting the “semantic backbone” of the sentence .</sentence>
				<definiendum id="0">sequential edge</definiendum>
				<definiens id="0">connects the head words ( e.g. main verbs , head nouns ) of syntactic chunks reflecting the “semantic backbone” of the sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>WeiPropM measures the correlation between two terms based on the path lengths .</sentence>
				<definiendum id="0">WeiPropM</definiendum>
				<definiens id="0">measures the correlation between two terms based on the path lengths</definiens>
			</definition>
			<definition id="5">
				<sentence>The corresponding metric can be defined as follows : FirstCompM ( vi , vj ) =parenleftbigg summationtextn k=1 1RelPathLength ( k ) ∗√|prop ( pk ) | parenrightbigg−1 where RelPathLength ( x ) = 2 3 ∗ e ( vi , px ) min1 + 1 3 ∗ e ( px , vj ) ∗ radicalBig freq ( vj ) min2 As opposed to NaivePropM and WeiPropM FirstCompM is not symmetric because of the emphasis on the first component .</sentence>
				<definiendum id="0">corresponding metric</definiendum>
				<definiens id="0">follows : FirstCompM ( vi , vj ) =parenleftbigg summationtextn k=1 1RelPathLength ( k ) ∗√|prop ( pk ) | parenrightbigg−1 where RelPathLength ( x ) = 2 3 ∗ e ( vi , px ) min1 + 1 3 ∗ e ( px , vj ) ∗ radicalBig freq ( vj ) min2 As opposed to NaivePropM and WeiPropM FirstCompM is not symmetric because of the emphasis on the first component</definiens>
			</definition>
			<definition id="6">
				<sentence>The corpus consists of 75 everyday words ( e.g. “Pr¨asident” ( president ) , “Eingang” ( entrance ) “Gruppe” ( group ) ) , 60 abstract terms ( e.g. “Ursache” ( reason ) , “Element” , “Merkmal” ( feature ) ) and 65 domain-specific words ( e.g. “Software” , “Prozessor” ( CPU ) ) .</sentence>
				<definiendum id="0">corpus</definiendum>
				<definiens id="0">consists of 75 everyday words ( e.g. “Pr¨asident” ( president ) , “Eingang” ( entrance ) “Gruppe” ( group ) ) , 60 abstract terms ( e.g. “Ursache” ( reason ) , “Element” , “Merkmal” ( feature ) ) and 65 domain-specific words</definiens>
			</definition>
			<definition id="7">
				<sentence>Everyday words suffer from the fact that their properties are often too general to uniquely characterize them , which involves loss of precision .</sentence>
				<definiendum id="0">Everyday words</definiendum>
				<definiens id="0">suffer from the fact that their properties are often too general to uniquely characterize them , which involves loss of precision</definiens>
			</definition>
</paper>

		<paper id="0601">
			<definition id="0">
				<sentence>images ) QueryTerms Senses Coverage Examples of visual annotation cues BASS ( 2881 ) 5 : bass , bass guitar , bass instrument , bass fishing , sea bass CRANE ( 2650 ) 5 : crane , construction cranes , whooping crane , sandhill crane , origami cranes SQUASH ( 1948 ) 10 : squash+ : rules , butternut , vegetable , grow , game of , spaghetti , winter , types of , summer Table 1 : Overview of annotated images for three ambiguous query terms , inspired by the WSD literature .</sentence>
				<definiendum id="0">images</definiendum>
				<definiendum id="1">winter</definiendum>
				<definiens id="0">squash+ : rules , butternut , vegetable , grow , game of , spaghetti ,</definiens>
			</definition>
			<definition id="1">
				<sentence>WordNet contains bird as part of the description for the separate entry origami , and some query expansion terms are hyponyms which occur as separate WordNet entries ( e.g. bass guitar , sea bass , summer squash ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">contains bird as part of the description for the separate entry origami</definiens>
			</definition>
			<definition id="2">
				<sentence>2 ( k ) illustrates how sunset background masks birds’ color information .</sentence>
				<definiendum id="0">k )</definiendum>
				<definiens id="0">illustrates how sunset background masks birds’ color information</definiens>
			</definition>
			<definition id="3">
				<sentence>Scale : The distance to objects may render them unclear and influence judgement accuracy , and people may differ in the degree of certainty required for assigning a sense .</sentence>
				<definiendum id="0">Scale</definiendum>
				<definiens id="0">The distance to objects may render them unclear and influence judgement accuracy</definiens>
			</definition>
</paper>

		<paper id="2936">
			<definition id="0">
				<sentence>A part is a tuple 〈DEPREL , i , j〉 where i is the start point of the edge , j is the end point , and DEPREL is the label of the edge .</sentence>
				<definiendum id="0">part</definiendum>
				<definiendum id="1">DEPREL</definiendum>
			</definition>
</paper>

		<paper id="2502">
			<definition id="0">
				<sentence>Rather , the UMLS integrates more than 100 medical domain controlled vocabularies such as SNOMED-CT2 and the International Classification of Diseases ( ICD ) 3 .</sentence>
				<definiendum id="0">UMLS</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Semantic Network is a coarse ontology of the concepts .</sentence>
				<definiendum id="0">Semantic Network</definiendum>
			</definition>
			<definition id="2">
				<sentence>Global rules look at the entire data over k number of clusters .</sentence>
				<definiendum id="0">Global rules</definiendum>
				<definiens id="0">look at the entire data over k number of clusters</definiens>
			</definition>
			<definition id="3">
				<sentence>C &amp; H is a global method .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">a global method</definiens>
			</definition>
			<definition id="4">
				<sentence>The Variance Ratio Criteria C &amp; H uses is kn kWGSSk kBGSS kVRC ) ( 1 ) ( ) ( where BGSS ( between group sum of squares ) is the sum of the dispersions between the k cluster centroids and the general centroid ; WGSS ( within-group sum of squares ) is the sum of each cluster’s dispersion of its cluster members ( measured by the sum of squared distances between each member and the cluster centroid ) weighed by the number of cluster members ; k is the number of clusters and n is the number of instances .</sentence>
				<definiendum id="0">BGSS</definiendum>
				<definiendum id="1">k</definiendum>
				<definiendum id="2">n</definiendum>
				<definiens id="0">the sum of the dispersions between the k cluster centroids and the general centroid ; WGSS ( within-group sum of squares</definiens>
				<definiens id="1">the sum of each cluster’s dispersion of its cluster members ( measured by the sum of squared distances between each member</definiens>
				<definiens id="2">the number of instances</definiens>
			</definition>
			<definition id="5">
				<sentence>� knkWGSS kWGSSkH where n is the total number of instances to be clustered , k is the number of clusters and WGSS ( k ) is the total sum of squared distances of cluster members from their cluster centroid in all clusters when clustered in k clusters .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">k</definiendum>
				<definiens id="0">the total number of instances to be clustered</definiens>
				<definiens id="1">the number of clusters</definiens>
				<definiens id="2">the total sum of squared distances of cluster members from their cluster centroid in all clusters when clustered in k clusters</definiens>
			</definition>
			<definition id="6">
				<sentence>Tibshirani and colleagues use a uniform distribution as the null distribution of the data to standardize the comparison between all the W ( k ) over the various values of k where W ( k ) is the pooled within cluster sum of squares around the cluster means ( distance is squared Euclidean distance ) .</sentence>
				<definiendum id="0">W ( k )</definiendum>
				<definiens id="0">the pooled within cluster sum of squares around the cluster means ( distance is squared Euclidean distance )</definiens>
			</definition>
			<definition id="7">
				<sentence>Method2 uses unigrams which occur at least 5 times in the corpus .</sentence>
				<definiendum id="0">Method2</definiendum>
				<definiens id="0">uses unigrams which occur at least 5 times in the corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>Accuracy is a direct evaluation measuring the correctly recognized number of senses : words with correctly predicted number of senses all words Accuracy evaluates how well the methods discover the exact number of senses in the test corpus .</sentence>
				<definiendum id="0">Accuracy</definiendum>
				<definiens id="0">a direct evaluation measuring the correctly recognized number of senses : words with correctly predicted number of senses all words Accuracy evaluates how well the methods discover the exact number of senses in the test corpus</definiens>
			</definition>
			<definition id="9">
				<sentence>The F-score of the WSD is an indirect evaluation for the quality of the cluster assignment : callecision callecision ) ( scoreF RePr2 RePr12_ Precision is the number of correctly clustered instances divided by the number of clustered instances ; Recall is the number of correctly clustered instances divided by all instances .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiendum id="1">RePr2 RePr12_ Precision</definiendum>
				<definiendum id="2">Recall</definiendum>
				<definiens id="0">an indirect evaluation for the quality of the cluster assignment</definiens>
				<definiens id="1">the number of correctly clustered instances divided by the number of clustered instances ;</definiens>
				<definiens id="2">the number of correctly clustered instances divided by all instances</definiens>
			</definition>
</paper>

		<paper id="0124">
			<definition id="0">
				<sentence>Named entity recognition ( NER ) , which includes the identification and classification of certain proper nouns , such as person names , organizations , locations , temporal , numerical and monetary phrases , plays an important part in many natural language processing applications , such as machine translation , information retrieval , information extraction and question answering .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">includes the identification and classification of certain proper nouns , such as person names , organizations , locations , temporal , numerical and monetary phrases , plays an important part in many natural language processing applications , such as machine translation , information retrieval , information extraction</definiens>
			</definition>
			<definition id="1">
				<sentence>( 3 ) Unlike European languages , Chinese allows an open vocabulary for proper names of persons , eliminating another major source of explicit clues used by European language NER models .</sentence>
				<definiendum id="0">Chinese allows</definiendum>
			</definition>
			<definition id="2">
				<sentence>The original AdaBoost algorithm was designedforthebinaryclassificationproblembutdid not fulfill the requirements of the Chinese NER Input : A training set Tr = { &lt; d1 , C1 &gt; , ... , &lt; dg , Cg &gt; } where Cj ⊆ C = { c1 , ... , cm } for all j = 1 , ... , g. Output : A final hypothesis Φ ( d , c ) =summationtextSs=1 αsΦs ( d , c ) .</sentence>
				<definiendum id="0">) =summationtextSs=1 αsΦs</definiendum>
				<definiens id="0">A final hypothesis Φ ( d , c</definiens>
			</definition>
			<definition id="3">
				<sentence>Algorithm : LetD1 ( dj , ci ) = 1mg for all j = 1 , ... , g and for all i = 1 , ... , m. For s = 1 , ... , S do : • pass distribution Ds ( dj , ci ) to the weak classifier ; • derive the weak hypothesis Φs from the weak classifier ; • choose αs ∈ R ; • set Ds+1 ( dj , ci ) = Ds ( dj , ci ) exp ( −αsCj [ ci ] Φs ( dj , ci ) ) Zs where Zs =summationtextm i=1 summationtextg j=1 Ds ( dj , ci ) exp ( −αsCj [ ci ] Φs ( dj , ci ) ) is a normalization factor chosen so thatsummationtextm i=1 summationtextg j=1 Ds+1 ( dj , ci ) = 1 .</sentence>
				<definiendum id="0">summationtextg j=1 Ds</definiendum>
				<definiens id="0">the weak classifier ; • derive the weak hypothesis Φs from the weak classifier ; • choose αs ∈ R</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , when we consider the geopolitical entity ( GPE ) , our low overall Fmeasure on the LDC test set can not be interpreted meaningfully.3 Even so , using only one-third of the training data , the results on the MSRA and CityU test sets are reasonable : 75.07 and 80.51 overall F-measures were obtained on the MSRA and CityU test sets , respectively .</sentence>
				<definiendum id="0">GPE</definiendum>
				<definiens id="0">CityU test sets are reasonable : 75.07 and 80.51 overall F-measures were obtained on the MSRA and CityU test sets , respectively</definiens>
			</definition>
</paper>

		<paper id="1506">
			<definition id="0">
				<sentence>In the semantic trees , F stands for formulas , R for predicates and T for terms .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">stands for formulas , R for predicates and T for terms</definiens>
			</definition>
			<definition id="1">
				<sentence>saw ( y , x ) T↓ 2 T↓ 1 angbracketrightbigg Figure 1 : Elementary trees for John saw a good movie .</sentence>
				<definiendum id="0">Elementary</definiendum>
				<definiens id="0">trees for John saw a good movie</definiens>
			</definition>
			<definition id="2">
				<sentence>I leave out the tree addresses in the semantic derivation tree , as these are determined by the links between the syntactic and semantic elementary trees.1 angbracketleftbigg ( δ3 ) ( αsaw ) ( αa movie ) DP ( βgood ) NP ( αJohn ) DPi ( δprime3 ) ( αprimesaw ) { ( βprimea movie ) , ( αprimea movie ) } ( βprimegood ) ( αprimeJohn ) angbracketrightbigg Figure 2 : Derivation trees for John saw a good movie .</sentence>
				<definiendum id="0">αa movie ) DP</definiendum>
				<definiens id="0">trees for John saw a good movie</definiens>
			</definition>
			<definition id="3">
				<sentence>angbracketleftbigg ( δ1 ) ( βhit ) ( αwho ) DPj ( β’s brother ) DP ( αMary ) DPi ( δprime1 ) ( βprimehit ) ( βprimewho ) ( βprime’s brother ) ( αprimeMary ) angbracketrightbigg Figure 5 : Derivation trees for whose brother Mary hit Semantically , we must make sure that the variable coming from the wh-word is also the one being predicated of the head noun ( boy in ( 1 ) ) , and yet the same variable does not serve as an argument of the predicate ( hit in ( 1 ) ) in the relative clause .</sentence>
				<definiendum id="0">βhit )</definiendum>
				<definiens id="0">the same variable does not serve as an argument of the predicate</definiens>
			</definition>
			<definition id="4">
				<sentence>THEz [ brother ( z ) ∧ Rel ( x , z ) ] [ hit ( Maryprime , z ) ] 43 angbracketleftbigg ( αmary ) DP D Mary ( αprimemary ) T Maryprime angbracketrightbigg angbracketleftbigg ( β’s brother ) DP DP* Dprime D ’s NP N brother ( βprime’s brother ) GQ λQ F GQ* R λy F THEz F F brother ( z ) F Rel ( y , z ) F Q ( z ) angbracketrightbigg angbracketleftbigg ( βhit ) NP NP* CP DPj↓ 1 Cprime C TP DPi↓ 2 Tprime T VP DP ti Vprime V hit DP tj ( βprimehit ) R R* R 1 R λxλy .</sentence>
				<definiendum id="0">THEz [ brother</definiendum>
				<definiens id="0">β’s brother ) DP DP* Dprime D ’s NP N brother ( βprime’s brother ) GQ λQ F GQ* R λy F THEz F F brother ( z ) F Rel ( y , z ) F Q ( z ) angbracketrightbigg angbracketleftbigg ( βhit ) NP NP* CP DPj↓ 1 Cprime C TP DPi↓ 2 Tprime T VP DP ti Vprime V hit DP tj ( βprimehit ) R R* R 1 R λxλy</definiens>
			</definition>
			<definition id="5">
				<sentence>boy ( x ) ∧ THEz [ brother ( z ) ∧ Rel ( x , z ) ] [ hit ( Maryprime , z ) ] The derivation of a sentence containing ( 1 ) , a boy whose brother Mary hit , as the object , as in ( 8 ) , proceeds in a similar fashion as in ( 3 ) , yielding the semantic derived tree which is reducible to the formula in ( 9 ) .</sentence>
				<definiendum id="0">boy ( x ) ∧ THEz [ brother</definiendum>
				<definiens id="0">The derivation of a sentence containing ( 1 ) , a boy whose brother Mary hit , as the object</definiens>
			</definition>
			<definition id="6">
				<sentence>angbracketleftbigg ( β’s friend ) DP DP* Dprime D ’s NP N friend ( βprime’s friend ) GQ λQ F GQ* R λy F THEz F F friend ( z ) F Rel ( y , z ) F Q ( z ) angbracketrightbigg Figure 7 : Elementary trees for ’s friend ( 10 ) λx .</sentence>
				<definiendum id="0">angbracketleftbigg</definiendum>
				<definiens id="0">β’s friend ) DP DP* Dprime D ’s NP N friend ( βprime’s friend ) GQ λQ F GQ* R λy F THEz F F friend</definiens>
			</definition>
			<definition id="7">
				<sentence>P ( x ) R* angbracketrightbigg angbracketleftbigg ( βthe brother of ) DP D the NP N brother PP P of DP* ( βprimethe brother of ) GQ λQ F GQ* R λy F THEz F F brother ( z ) F Rel ( y , z ) F Q ( z ) angbracketrightbigg Figure 10 : Elementary trees for whom and the brother ofangbracketleftbigg ( γ11 ) NP NP* CP DPj D the NP N brother PP P of DP D whom Cprime C TP DPi D Mary Tprime T VP DP ti Vprime V hit DP tj ( γprime11 ) R R* R λx F GQ λQ F GQ λP .</sentence>
				<definiendum id="0">P ( x ) R* angbracketrightbigg angbracketleftbigg</definiendum>
			</definition>
			<definition id="8">
				<sentence>Using the semantic tree ( βprimea brother of ) , the semantic composition of the relative clause in ( 12 ) can proceed as before : the semantic tree ( βprimea brother of ) adjoins onto the semantic tree ( βprimewhom ) in Figure 10 , which then adjoins onto ( βprimehit ) in Figure 4 .</sentence>
				<definiendum id="0">semantic tree</definiendum>
				<definiens id="0">the semantic composition of the relative clause in</definiens>
			</definition>
			<definition id="9">
				<sentence>47 angbracketleftbigg ( γ12 ) NP NP* CP DPj D whom Cprime C TP DPi D Mary Tprime T VP DP ti Vprime V hit DP D a NP N brother PP P of DP tj ( γprime12 ) R R* R λx F GQ λQ F GQ λP .</sentence>
				<definiendum id="0">GQ λQ F GQ λP</definiendum>
				<definiens id="0">DP ti Vprime V hit DP D a NP N brother PP P of DP tj ( γprime12 ) R R* R λx F</definiens>
			</definition>
</paper>

		<paper id="0110">
			<definition id="0">
				<sentence>Named entity ( NE ) recognition is a fundamental step to many language processing tasks such as information extraction ( IE ) , question answering ( QA ) and machine translation ( MT ) .</sentence>
				<definiendum id="0">recognition</definiendum>
				<definiens id="0">Named entity ( NE )</definiens>
				<definiens id="1">a fundamental step to many language processing tasks such as information extraction ( IE ) , question answering ( QA ) and machine translation ( MT )</definiens>
			</definition>
			<definition id="1">
				<sentence>l is the number of the given training samples .</sentence>
				<definiendum id="0">l</definiendum>
			</definition>
			<definition id="2">
				<sentence>SVMs find an “optimal” hyperplane : to separate the training data into two classes .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">find an “optimal” hyperplane : to separate the training data into two classes</definiens>
			</definition>
			<definition id="3">
				<sentence>B Current token is the beginning of a chunk .</sentence>
				<definiendum id="0">Current token</definiendum>
				<definiens id="0">the beginning of a chunk</definiens>
			</definition>
			<definition id="4">
				<sentence>POS tag Description of the position of the character in a word &lt; POS &gt; -S One-character word &lt; POS &gt; -B first character in a multi-character word &lt; POS &gt; -I intermediate character in a multicharacter word &lt; POS &gt; -E last character in a multi-character word Table 2 .</sentence>
				<definiendum id="0">POS tag Description of</definiendum>
				<definiens id="0">the position of the character in a word &lt; POS &gt; -S One-character word &lt; POS &gt; -B first character in a multi-character word &lt; POS &gt; -I intermediate character in a multicharacter word</definiens>
			</definition>
			<definition id="5">
				<sentence>POS Tags in A Word If the character is a surname , the value is assigned to Y , otherwise assigned to N. The “character” is surface form of the character in the word .</sentence>
				<definiendum id="0">Word If the character</definiendum>
				<definiens id="0">surface form of the character in the word</definiens>
			</definition>
			<definition id="6">
				<sentence>We define the bigram contextual probability CP ( PN ) of the person name PN as the following equation : CP ( PN ) = , ) , , ( TotalPOS rposPNlposPersonPOS &gt; &lt; ( 9 ) where lpos is the POS tag of the character before PN ( called POS forward ) , rpos is the POS tag of the character after PN ( called POS backward ) , and is the number of PN as a pereson name whose POS forward is lpos and POS backward is rpos in training corpus .</sentence>
				<definiendum id="0">bigram contextual probability CP</definiendum>
				<definiendum id="1">lpos</definiendum>
				<definiens id="0">the following equation : CP ( PN ) = , ) , , ( TotalPOS rposPNlposPersonPOS &gt; &lt;</definiens>
				<definiens id="1">the POS tag of the character before PN ( called POS forward ) , rpos is the POS tag of the character after PN ( called POS backward ) , and is the number of PN as a pereson name whose POS forward is lpos and POS backward is rpos in training corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>The evaluated function TotalProbability ( LN ) is composed of two parts : the lexical probability LP ( LN ) and contextual probability CP ( LN ) based on POS tags. )</sentence>
				<definiendum id="0">evaluated function TotalProbability</definiendum>
				<definiendum id="1">LN</definiendum>
			</definition>
			<definition id="8">
				<sentence>1 ) lexical probability LP ( LN ) Suppose LN=F 0 F + S , F + =F 1 …F n , ( i=1 , … , n ) , where F 0 is the first character of the evaluated location name LN , F + is the middle characters of the evaluated location name LN , S is the last character of the evaluated location name LN .</sentence>
				<definiendum id="0">lexical probability LP</definiendum>
				<definiens id="0">i=1 , … , n ) , where F 0 is the first character of the evaluated location name LN , F + is the middle characters of the evaluated location name LN , S is the last character of the evaluated location name LN</definiens>
			</definition>
			<definition id="9">
				<sentence>The lexical probability of the location name LN is defined as ) , ( / ) ) ( ) ( ) ( ( 0 LNLenSPFPFPLN lfh ++= + ( 14 ) where Len ( LN ) is the length of the evaluated location name LN .</sentence>
				<definiendum id="0">lexical probability of the location name LN</definiendum>
				<definiendum id="1">Len ( LN )</definiendum>
			</definition>
</paper>

		<paper id="1643">
			<definition id="0">
				<sentence>Markov models ( HMMs ) ( Rabiner , 1989 ) , are linear chains that only encode local dependencies between utterances to be labeled .</sentence>
				<definiendum id="0">Markov models</definiendum>
				<definiendum id="1">HMMs )</definiendum>
				<definiens id="0">linear chains that only encode local dependencies between utterances to be labeled</definiens>
			</definition>
			<definition id="1">
				<sentence>Dialog act ( DA ) labels describe the pragmatic function of utterances , e.g. a STATEMENT or a BACKCHANNEL .</sentence>
				<definiendum id="0">Dialog act</definiendum>
				<definiendum id="1">DA</definiendum>
				<definiens id="0">the pragmatic function of utterances</definiens>
			</definition>
			<definition id="2">
				<sentence>This auxiliary corpus consists of over 180,000 human-annotated dialog act labels ( κ = .8 ) , for which so-called adjacency pair ( AP ) relations ( e.g. , APOLOGYDOWNPLAY ) were also labeled .</sentence>
				<definiendum id="0">auxiliary corpus</definiendum>
			</definition>
			<definition id="3">
				<sentence>summarization predictors ( see Section 6 ) , and the binary sequence y = y1 : T = ( y1 , ... , yT ) ( where yt ∈ { −1,1 } ) determines which utterances must be included in the summary .</sentence>
				<definiendum id="0">summarization predictors</definiendum>
				<definiens id="0">T = ( y1 , ... , yT ) ( where yt ∈ { −1,1 } ) determines which utterances must be included in the summary</definiens>
			</definition>
			<definition id="4">
				<sentence>Lexical features : · n-grams ( n ≤ 3 ) · number of words · number of digits · number of consecutive repeats Information retrieval features : · max/sum/mean frequency of all terms in ut · max/sum/mean idf score · max/sum/mean tf·idf score · cosine similarity between word vector of ut with centroid of of the meeting · scores of LSA with 5 , 10 , 50 , 100 , 200 , 300 concepts Acoustic features : · seconds of silence before/during/after the turn · speech rate · min/max/mean/median/stddev/onset/outset f0 of utterance t , and of first and last word · min/max/mean/stddev energy · .05 , .25 , .5 , .75 , .95 quantiles of f0 and energy · pitch range · f0 mean absolute slope Durational and structural features : · duration of the previous/current/next utterance · relative position within meeting ( i.e. , index t ) · relative position within speaker turn · large number of structural predicates , i.e. “is the previous utterance of the same speaker ? ”</sentence>
				<definiendum id="0">· n-grams</definiendum>
				<definiens id="0">· duration of the previous/current/next utterance · relative position within meeting ( i.e. , index t ) · relative position within speaker turn · large number of structural predicates</definiens>
			</definition>
			<definition id="5">
				<sentence>Pyramid and ROUGE are techniques looking for content units repeated in different model summaries , i.e. , summarycontentunits ( SCUs ) suchasclauses and noun phrases for the Pyramid method , and ngrams for ROUGE .</sentence>
				<definiendum id="0">SCUs</definiendum>
				<definiens id="0">techniques looking for content units repeated in different model summaries , i.e. , summarycontentunits (</definiens>
			</definition>
</paper>

		<paper id="2937">
			<definition id="0">
				<sentence>However , the SVM is a binary classifier which only recognizes true or false .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">a binary classifier which only recognizes true or false</definiens>
			</definition>
			<definition id="1">
				<sentence>243 Table 2 : A general statistical table of labeled attachment score , test and un-parsed rate ( percentage ) Statistic test Un-Parsed Rate A ( New result ) B ( Old result ) C ( Maltparser ) A vs. B B vs. C A vs. C Forward Backward Arabic 63.75 63.81 54.11 No Yes Yes 10.3 1.4 Chinese 81.25 74.81 73.92 Yes No Yes 4.01 2.3 Czech 71.24 59.36 59.36 Yes No Yes 16.1 5.6 Danish 79.52 78.38 77.31 No No No 12.8 2.5 Dutch 68.45 68.45 63.61 No Yes Yes 18.4 9.8 German 79.57 76.52 76.52 Yes No Yes 12.7 9.2 Japanese 91.43 90.11 89.07 Yes No Yes 1.1 4.4 Portugese 81.33 81.47 75.38 No Yes Yes 24.3 3.17 Slovene 68.41 67.83 55.04 No Yes Yes 14.9 5.5 Spanish 74.65 72.99 72.81 Yes No Yes 20 0.5 Swedish 79.53 71.72 76.28 Yes Yes Yes 19.1 2.8 Turkish 55.33 55.09 52.18 No Yes Yes 2.5 4 Bulgarian 81.23 79.73 79.73 No No No 15.7 1.2 AVG 75.05 72.32 69.64 13.22 4.02 Although our method is efficient for parsing that achieves satisfactory result , it is still away from the state-of-the-art performance .</sentence>
				<definiendum id="0">un-parsed rate</definiendum>
				<definiens id="0">A general statistical table of labeled attachment score</definiens>
			</definition>
			<definition id="2">
				<sentence>Dependency parsing is one of the most important issues in NLP community .</sentence>
				<definiendum id="0">Dependency parsing</definiendum>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>To evaluateour method , we used The EDR Electronic Dictionary1 for a bilingualdictionaryand Fry’s Japanese-Englishparallel web corpus ( Fry , 2005 ) for sample data .</sentence>
				<definiendum id="0">EDR Electronic Dictionary1</definiendum>
				<definiens id="0">for a bilingualdictionaryand Fry’s Japanese-Englishparallel web corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Therearethreegroupsof bars ; ( A ) treat every connectedcomponentequally regardlessof its size , ( B ) simplydropthe largestcomponentand ( C ) dividelarge componentsinto smaller parts .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">simplydropthe largestcomponentand ( C ) dividelarge componentsinto smaller parts</definiens>
			</definition>
</paper>

		<paper id="1901">
			<definition id="0">
				<sentence>com A Question Answering ( QA ) system allows the user to ask questions in natural language and to obtain one or several answers .</sentence>
				<definiendum id="0">Question Answering</definiendum>
				<definiens id="0">the user to ask questions in natural language and to obtain one or several answers</definiens>
			</definition>
			<definition id="1">
				<sentence>Qristal allows the user to query on a static corpus or on the Web .</sentence>
				<definiendum id="0">Qristal</definiendum>
			</definition>
			<definition id="2">
				<sentence>We define “Boolean like” extensively as the use of Boolean operators associated to underlying constraints induced by the word matching techniques .</sentence>
				<definiendum id="0">“Boolean like” extensively</definiendum>
				<definiens id="0">the use of Boolean operators associated to underlying constraints induced by the word matching techniques</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , with the request `` capitale anglaise '' ( `` English capital '' ) , Google returns a lot of snippets containing the phrase `` capitale anglaise '' ( `` English capital '' ) but not the word Londres or London in these snippets .</sentence>
				<definiendum id="0">Google</definiendum>
				<definiens id="0">returns a lot of snippets containing the phrase</definiens>
			</definition>
</paper>

		<paper id="3326">
</paper>

		<paper id="1514">
			<definition id="0">
				<sentence>The parsing schema for the TAG CYK-based algorithm ( Alonso et al. , 1999 ) is a function that maps such a grammar G to a deduction system whose domain is the set of items { [ Nγ , i , j , p , q , adj ] } verifying that Nγ is a tree node in an elementary 1Where VT denotes the set of terminal symbols , VN the set of nonterminal symbols , S the axiom , I the set of initial trees and A the set of auxiliary trees .</sentence>
				<definiendum id="0">parsing schema for the TAG CYK-based algorithm</definiendum>
				<definiendum id="1">VT</definiendum>
				<definiendum id="2">VN</definiendum>
				<definiens id="0">a function that maps such a grammar G to a deduction system whose domain is the set of items { [ Nγ , i , j , p , q , adj ] } verifying that Nγ is a tree node in an elementary 1Where</definiens>
				<definiens id="1">the set of terminal symbols</definiens>
			</definition>
			<definition id="1">
				<sentence>Greek letters ( α , β ... ) will be used to represent trees , Nγ a node in the tree γ , and Rγ the root node of the tree γ .</sentence>
				<definiendum id="0">Greek letters</definiendum>
				<definiens id="0">a node in the tree γ , and Rγ the root node of the tree γ</definiens>
			</definition>
			<definition id="2">
				<sentence>DFootCYK and DAdjCYK implement the adjunction operation , where a tree β is adjoined into a node Nγ ; their side condition β ∈ adj ( Nγ ) means that β must be adjoinable into the node Nγ ( which involves checking that Nγ is an adjunction node , comparing its label to Rβ’s and verifying that no adjunction constraint disallows the operation ) .</sentence>
				<definiendum id="0">DFootCYK</definiendum>
				<definiendum id="1">DAdjCYK</definiendum>
				<definiens id="0">implement the adjunction operation , where a tree β is adjoined into a node Nγ ; their side condition β ∈ adj ( Nγ ) means that β must be adjoinable into the node Nγ ( which involves checking that Nγ is an adjunction node , comparing its label to Rβ’s and verifying that no adjunction constraint disallows the operation )</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally , the DSubsCYK step implements the substitution operation in grammars supporting it .</sentence>
				<definiendum id="0">DSubsCYK step</definiendum>
				<definiens id="0">implements the substitution operation in grammars supporting it</definiens>
			</definition>
			<definition id="4">
				<sentence>The “keep variables” operation is a transformation on feature structures that takes a feature structure as an argument , which may contain features , values , symbolic variables and associations between them , and returns a feature structure containing only the variable-value associations related to a given elementary tree , ignoring the variables and values not associated through these relations , and completely ignoring features .</sentence>
				<definiendum id="0">“keep variables” operation</definiendum>
				<definiens id="0">may contain features , values , symbolic variables and associations between them , and returns a feature structure containing only the variable-value associations related to a given elementary tree</definiens>
			</definition>
			<definition id="5">
				<sentence>A generic system that generates parsers from algebraic specifications ( parsing schemata ) has been applied to the particular case of the XTAG grammar .</sentence>
				<definiendum id="0">generic system</definiendum>
				<definiens id="0">generates parsers from algebraic specifications ( parsing schemata ) has been applied to the particular case of the XTAG grammar</definiens>
			</definition>
</paper>

		<paper id="1111">
			<definition id="0">
				<sentence>We do this by dividing each Cyi , Coi by N/2n , where N is the total count of all trigrams and n is the number of trigram categories being counted .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of trigram categories being counted</definiens>
			</definition>
			<definition id="1">
				<sentence>Corpus Annotation : Linguistic Information from Computer Text Corpora .</sentence>
				<definiendum id="0">Corpus Annotation</definiendum>
			</definition>
</paper>

		<paper id="0208">
			<definition id="0">
				<sentence>Information Extraction ( IE ) is the task of identifying event descriptions in natural language text and extracting information related to those events .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
				<definiens id="0">the task of identifying event descriptions in natural language text and extracting information related to those events</definiens>
			</definition>
			<definition id="1">
				<sentence>IE systems typically focus on information about events that are relevant to a specific domain , such as terrorism ( Sundheim , 1992 ; Soderland et al. , 1995 ; Riloff , 1996 ; Chieu et al. , 2003 ) , management succession ( Sundheim , 1995 ; Yangarber et al. , 2000 ) , or job announcements ( Califf and Mooney , 1999 ; Freitag and McCallum , 2000 ) .</sentence>
				<definiendum id="0">management succession</definiendum>
				<definiens id="0">focus on information about events that are relevant to a specific domain</definiens>
			</definition>
			<definition id="2">
				<sentence>AutoSlog-TS is a weakly supervised learner that requires two sets of texts for training : texts that are relevant to the domain and texts that are irrelevant to the domain .</sentence>
				<definiendum id="0">AutoSlog-TS</definiendum>
				<definiens id="0">a weakly supervised learner that requires two sets of texts for training : texts that are relevant to the domain</definiens>
			</definition>
			<definition id="3">
				<sentence>Unannotated texts have been used successfully for a variety of NLP tasks , including named entity recognition ( Collins and Singer , 1999 ) , subjectivity classification ( Wiebe and Riloff , 2005 ) , text classification ( Nigam et al. , 2000 ) , and word sense disambiguation ( Yarowsky , 1995 ) .</sentence>
				<definiendum id="0">Unannotated texts</definiendum>
			</definition>
			<definition id="4">
				<sentence>Unannotated texts have been used for weakly supervised training of IE systems ( Riloff , 1996 ) and in bootstrapping methods that begin with seed words or patterns ( Riloff and Jones , 1999 ; Yangarber et al. , 2000 ) .</sentence>
				<definiendum id="0">Unannotated texts</definiendum>
			</definition>
			<definition id="5">
				<sentence>CRYSTAL : Inducing a Conceptual Dictionary .</sentence>
				<definiendum id="0">CRYSTAL</definiendum>
				<definiens id="0">Inducing a Conceptual Dictionary</definiens>
			</definition>
</paper>

		<paper id="0508">
			<definition id="0">
				<sentence>Known entities occurring in the text , i.e. , entities that are included in the knowledge base , are semantically annotated with their properties , also provided by the knowledge base and by databases .</sentence>
				<definiendum id="0">Known entities</definiendum>
				<definiens id="0">occurring in the text , i.e. , entities that are included in the knowledge base , are semantically annotated with their properties , also provided by the knowledge base and by databases</definiens>
			</definition>
			<definition id="1">
				<sentence>Relations include those already existent in the knowledge base , new relations predicted as possible by the domain ontology , or completely new ( unpredicted ) relations .</sentence>
				<definiendum id="0">Relations</definiendum>
				<definiens id="0">include those already existent in the knowledge base , new relations predicted as possible by the domain ontology</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus , our patterns consist of triples of the type &lt; class , conceptual_relation , class &gt; , which are compared against a given triple using its classes ( already provided by the linguistic component or by ESpotter++ ) in order to classify relations in that triple as relevant or nonrelevant .</sentence>
				<definiendum id="0">patterns</definiendum>
				<definiens id="0">consist of triples of the type &lt; class , conceptual_relation , class &gt; , which are compared against a given triple using its classes ( already provided by the linguistic component or by ESpotter++ ) in order to classify relations in that triple as relevant or nonrelevant</definiens>
			</definition>
			<definition id="3">
				<sentence>SenseLearner is supervised WSD system to disambiguate all open class words in any given text , after being trained on a small data set , according to global models for word categories .</sentence>
				<definiendum id="0">SenseLearner</definiendum>
				<definiens id="0">is supervised WSD system to disambiguate all open class words in any given text , after being trained on a small data set , according to global models for word categories</definiens>
			</definition>
			<definition id="4">
				<sentence>… ( def-instance Enrico-Motta kmi-academic-staff-member ( ( works-in knowledge-media-institute ) ( award-from european-commission ) ( award-for NeOn ) ( award-for XMEDIA ) ( award-for OK ) ) ) 63 signed mainly to enrich the annotations produced by a semantic web portal , but can be used for other domains and applications , such as ontology population and development .</sentence>
				<definiendum id="0">… ( def-instance Enrico-Motta kmi-academic-staff-member</definiendum>
				<definiens id="0">works-in knowledge-media-institute ) ( award-from european-commission ) ( award-for NeOn ) ( award-for XMEDIA ) ( award-for OK ) ) ) 63 signed mainly to enrich the annotations produced by a semantic web portal , but can be used for other domains and applications , such as ontology population and development</definiens>
			</definition>
			<definition id="5">
				<sentence>AKT is an Interdisciplinary Research Collaboration ( IRC ) , which is sponsored by the UK Engineering and Physical Sciences Research Council under grant number GR/N15764/01 .</sentence>
				<definiendum id="0">AKT</definiendum>
				<definiens id="0">an Interdisciplinary Research Collaboration ( IRC ) , which is sponsored by the UK Engineering and Physical Sciences Research Council under grant number GR/N15764/01</definiens>
			</definition>
</paper>

		<paper id="1905">
			<definition id="0">
				<sentence>Keyword translation is a crucial element of the system ; we describe our translation module in Section 3.2 .</sentence>
				<definiendum id="0">Keyword translation</definiendum>
				<definiens id="0">a crucial element of the system</definiens>
			</definition>
			<definition id="1">
				<sentence>The Answer Generator uses language-specific sub-modules for normalization , and a language-independent algorithm for answer ranking .</sentence>
				<definiendum id="0">Answer Generator</definiendum>
				<definiens id="0">uses language-specific sub-modules for normalization</definiens>
			</definition>
			<definition id="2">
				<sentence>Instead of combining multiple translation candidates with a disjunctive query operator ( Isozaki et al. , 2005 ) , the TM selects the best combination of translated keywords from several sources : Machine Readable Dictionaries ( MRDs ) , Machine Translation systems ( MTs ) and Web-mining-Based Keyword Translators ( WBMTs ) ( Nagata et al. , 2001 , Li et al. , 2003 ) .</sentence>
				<definiendum id="0">TM</definiendum>
				<definiens id="0">selects the best combination of translated keywords from several sources : Machine Readable Dictionaries ( MRDs ) , Machine Translation systems</definiens>
			</definition>
			<definition id="3">
				<sentence>The TM 's job is to find the target language terms given the source language terms , by finding the probability of the target language terms given the source language terms P ( T|S ) .</sentence>
				<definiendum id="0">TM 's job</definiendum>
			</definition>
			<definition id="4">
				<sentence>We then define the translation probability of each keyword translation as : ∑ = j jii jii jii tsco tsco tsP ) ) , ( log ( ) ) , ( log ( ) | ( , , , Where s i is the i-th term in the source language and t i , j is the j-th translation candidate for s i .</sentence>
				<definiendum id="0">translation probability</definiendum>
				<definiens id="0">the i-th term in the source language and t i</definiens>
			</definition>
			<definition id="5">
				<sentence>Translation ( 2,1 ) is the verb `` to go away '' , and translation ( 2,2 ) is the noun for leaf .</sentence>
				<definiendum id="0">Translation ( 2,1 )</definiendum>
				<definiens id="0">the verb `` to go away ''</definiens>
			</definition>
			<definition id="6">
				<sentence># BAND ( # OD4 ( 邪馬台国 王朝 ) 女王 # SYN ( *organization *person ) ) In formulating a structured query , the RS uses an incremental relaxation technique , starting from an initial query that is highly constrained ; the algorithm searches for all the keywords and data types in close proximity to each other .</sentence>
				<definiendum id="0">RS</definiendum>
				<definiens id="0">uses an incremental relaxation technique , starting from an initial query that is highly constrained ; the algorithm searches for all the keywords and data types in close proximity to each other</definiens>
			</definition>
			<definition id="7">
				<sentence>The score for an answer candidate a is calculated as follows : ) ( ) ( ) ( aDistScoreaOccScoreaScore ⋅+⋅= βα where α + β = 1 , OccScore is the occurrence score and DistScore is the distance score .</sentence>
				<definiendum id="0">OccScore</definiendum>
				<definiendum id="1">DistScore</definiendum>
				<definiens id="0">the occurrence score and</definiens>
				<definiens id="1">the distance score</definiens>
			</definition>
			<definition id="8">
				<sentence>The occurrence score formula is : n kExist aOccScore n i i∑ = = 1 ) ( ) ( where a is the answer candidate and k i is the i-th keyword , and n is the number of keywords .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of keywords</definiens>
			</definition>
			<definition id="9">
				<sentence>Information extraction ( including named entity identification ) did not perform as well in E-J .</sentence>
				<definiendum id="0">Information extraction</definiendum>
			</definition>
			<definition id="10">
				<sentence>In question answering systems , the translation results are used directly in information retrieval , which exhibits a high dependency on the lexical form of a word but not so much on the meaning .</sentence>
				<definiendum id="0">question answering systems</definiendum>
				<definiens id="0">exhibits a high dependency on the lexical form of a word but not so much on the meaning</definiens>
			</definition>
</paper>

		<paper id="2904">
			<definition id="0">
				<sentence>For the purpose of learning , we decompose each link score into a weighted linear combination of features sa4a6a5 a20 a21a76a5 a24 a17a46a3 a77a54a78a75a79a80a4a6a5 a20 a21a36a5 a24 a17 ( 2 ) where a77 are the weight parameters to be estimated during training .</sentence>
				<definiendum id="0">a77</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Laplacian regularizer ( 9 ) provides a natural smoother for the bi-lexical parameter estimates that takes into account valuable word similarity information computed as above .</sentence>
				<definiendum id="0">Laplacian regularizer</definiendum>
				<definiens id="0">a natural smoother for the bi-lexical parameter estimates that takes into account valuable word similarity information computed as above</definiens>
			</definition>
</paper>

		<paper id="3808">
			<definition id="0">
				<sentence>The ( un ) smoothness over the particular edge can be defined as wparenleftbigf ( xi ) − f ( xj ) parenrightbig2 .</sentence>
				<definiendum id="0">un ) smoothness over the particular edge</definiendum>
			</definition>
			<definition id="1">
				<sentence>They showed that PSP is a ( noisy ) measure for comparing reviews—reviews with low ratings tend to receive low PSP scores , and those with higher ratings tend to get high PSP scores .</sentence>
				<definiendum id="0">PSP</definiendum>
				<definiens id="0">a ( noisy ) measure for comparing reviews—reviews with low ratings tend to receive low PSP scores</definiens>
			</definition>
			<definition id="2">
				<sentence>SSL uses the similarity measure in more ways than the metric labeling approaches ( i.e. , SSL’s graph is denser ) , so it is not surprising that SSL’s accuracy would suffer more with an inferior similarity measure .</sentence>
				<definiendum id="0">SSL</definiendum>
				<definiens id="0">uses the similarity measure in more ways than the metric labeling approaches</definiens>
			</definition>
</paper>

		<paper id="2706">
			<definition id="0">
				<sentence>Hence it is sufficient to specify a sequence 43 of text fragments and known XML elements ( e.g. linguistic tags ) without knowing by what elements they are nested .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">elements ( e.g. linguistic tags ) without knowing by what elements they are nested</definiens>
			</definition>
			<definition id="1">
				<sentence>Castagna ( Castagna , 2005 ) distinguishes path expressions that rather correspond to the database view and regular expression patterns as complementary “extraction primitives” for XML data .</sentence>
				<definiendum id="0">Castagna</definiendum>
			</definition>
			<definition id="2">
				<sentence>XML QL ( Deutsch et al. , 1999 ) follows the relational paradigm for XML queries , introduces variable binding to multiple nodes and regular expressions describing element paths .</sentence>
				<definiendum id="0">XML QL</definiendum>
				<definiens id="0">follows the relational paradigm for XML queries , introduces variable binding to multiple nodes and regular expressions describing element paths</definiens>
			</definition>
			<definition id="3">
				<sentence>The queries are resolved using an XML graph as the data model , which allows both ordered and unordered node representation .</sentence>
				<definiendum id="0">XML graph</definiendum>
				<definiens id="0">allows both ordered and unordered node representation</definiens>
			</definition>
			<definition id="4">
				<sentence>XQuery features more powerful iteration over elements by FLWR expression borrowed from Quilt ( Chamberlin et al. , 2001 ) , string operations , “if else” case differentiation and aggregate functions .</sentence>
				<definiendum id="0">XQuery</definiendum>
				<definiens id="0">features more powerful iteration over elements</definiens>
			</definition>
			<definition id="5">
				<sentence>Query languages based on path expressions usually return sets ( or sequences ) of elements that are conform with the original hierarchical structure of the document .</sentence>
				<definiendum id="0">Query languages</definiendum>
				<definiens id="0">based on path expressions usually return sets ( or sequences ) of elements that are conform with the original hierarchical structure of the document</definiens>
			</definition>
			<definition id="6">
				<sentence>An XML fragment f is a sequence of XML nodes n1 ... nn that belong to the subtree of the context node ( i.e. the node whose subtree is queried , e.g. document root ) .</sentence>
				<definiendum id="0">XML fragment f</definiendum>
				<definiens id="0">a sequence of XML nodes n1 ... nn that belong to the subtree of the context node ( i.e. the node whose subtree is queried , e.g. document root )</definiens>
			</definition>
			<definition id="7">
				<sentence>XPath imposes a query context by specifying the path expression that usually addresses a certain element , XQuery restricts it indirect by iterating over and binding variables to certain nodes .</sentence>
				<definiendum id="0">XPath</definiendum>
				<definiens id="0">imposes a query context by specifying the path expression that usually addresses a certain element , XQuery restricts it indirect by iterating over and binding variables to certain nodes</definiens>
			</definition>
			<definition id="8">
				<sentence>As opposed to most XML query languages negation is a pattern and not a unary boolean operator .</sentence>
				<definiendum id="0">XML query languages negation</definiendum>
				<definiens id="0">a pattern and not a unary boolean operator</definiens>
			</definition>
			<definition id="9">
				<sentence>( p ) matches an empty fragment , the pattern P1P2 has to match complete f. It is noteworthy that the negation is the only pattern that influences the semantics of a complex pattern as its inner pattern .</sentence>
				<definiendum id="0">negation</definiendum>
				<definiens id="0">matches an empty fragment , the pattern P1P2 has to match complete f. It is noteworthy that the</definiens>
			</definition>
</paper>

		<paper id="2209">
			<definition id="0">
				<sentence>A query module q , which uses the model created by s decides which instances of D will be selected to be checked for errors by a human annotator .</sentence>
				<definiendum id="0">query module q</definiendum>
				<definiens id="0">uses the model created by s decides which instances of D will be selected to be checked for errors by a human annotator</definiens>
			</definition>
			<definition id="1">
				<sentence>For each token t and possible label l , Lingpipe estimates the following Hidden Markov Model from the training data : P ( t [ n ] , l [ n ] |l [ n − 1 ] , t [ n − 1 ] , t [ n − 2 ] ) ( 1 ) Whenannotating acertain textpassage , thetokens are fixed and the joint probability of Equation 1 is computed for each possible combination of labels .</sentence>
				<definiendum id="0">Lingpipe</definiendum>
				<definiens id="0">estimates the following Hidden Markov Model from the training data</definiens>
			</definition>
			<definition id="2">
				<sentence>Oneproperty oftheconditional entropy isthat it estimates the uncertainty of the predictions for the current label given knowledge of the previous tag , which is important in our application because we need the uncertainty over each label independently from the rest of the sequence .</sentence>
				<definiendum id="0">previous tag</definiendum>
				<definiens id="0">Oneproperty oftheconditional entropy isthat it estimates the uncertainty of the predictions for the current label given knowledge of the</definiens>
			</definition>
			<definition id="3">
				<sentence>This is confirmed by the theory , from which we know that for a conditional distribution of X given Y the following equation holds , H [ X|Y ] = H [ X , Y ] − H [ Y ] , where H denotes the entropy .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">the entropy</definiens>
			</definition>
			<definition id="4">
				<sentence>There , the uncertainty is estimated by the margin between the two most likely predictions that would result in a different current label , explicitly : M = maxi , j { P ( t [ n ] = i|t [ n − 1 ] = j ) } − maxk , l , knegationslash=i { P ( t [ n ] = k|t [ n − 1 ] = l ) } ( 5 ) Intuitively , the margin M is the difference between the two highest scored predictions that disagree .</sentence>
				<definiendum id="0">margin M</definiendum>
				<definiens id="0">the difference between the two highest scored predictions that disagree</definiens>
			</definition>
</paper>

		<paper id="2906">
			<definition id="0">
				<sentence>Accuracy is the fraction of total examples that were assigned the correct antecedent and Accuracytag is the same excluding the examples that had POS tagging errors for the correct antecedent.7 Av Rank is the rank of the true antecedent averaged over the number of test examples.8 Based on the above experiment , the rest of thispaperassumesMutualInformationscoringtechnique for TheY-Model .</sentence>
				<definiendum id="0">Accuracy</definiendum>
				<definiendum id="1">Accuracytag</definiendum>
			</definition>
			<definition id="1">
				<sentence>6For the purposes of TF-IDF computation , document frequency df ( X ) is defined as the number of unique definite NPs for which X appears as an antecedent .</sentence>
				<definiendum id="0">document frequency df ( X</definiendum>
				<definiens id="0">the number of unique definite NPs for which X appears as an antecedent</definiens>
			</definition>
			<definition id="2">
				<sentence>Although Markert and Nissim ( 2005 ) report that using Mutual Information performs similar to using raw frequency , Table 5 shows that using Mutual Information makes a substantial impact on results using large training corpora relative to using raw frequency .</sentence>
				<definiendum id="0">Mutual Information</definiendum>
				<definiens id="0">makes a substantial impact on results using large training corpora relative to using raw frequency</definiens>
			</definition>
</paper>

		<paper id="3123">
			<definition id="0">
				<sentence>The original IBM Models ( Brown et al. , 1993 ) learn word-to-word alignment probabilities which makes it computationally feasible to estimate model parameters from large amounts of training data .</sentence>
				<definiendum id="0">IBM Models</definiendum>
				<definiens id="0">makes it computationally feasible to estimate model parameters from large amounts of training data</definiens>
			</definition>
			<definition id="1">
				<sentence>A concept , ci , is defined as a pair of aligned phrases &lt; ei , fi &gt; .</sentence>
				<definiendum id="0">ci</definiendum>
				<definiens id="0">a pair of aligned phrases &lt; ei , fi &gt;</definiens>
			</definition>
</paper>

		<paper id="1670">
			<definition id="0">
				<sentence>Named entity recognition ( NER ) is the most studied information extraction ( IE ) task .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">the most studied information extraction</definiens>
			</definition>
			<definition id="1">
				<sentence>Word sense disambiguation ( WSD ) is the task of deciding the intended sense for ambiguous words in context .</sentence>
				<definiendum id="0">Word sense disambiguation ( WSD</definiendum>
				<definiens id="0">the task of deciding the intended sense for ambiguous words in context</definiens>
			</definition>
			<definition id="2">
				<sentence>594 NOUNS SUPERSENSE NOUNS DENOTING SUPERSENSE NOUNS DENOTING act acts or actions object natural objects ( not man-made ) animal animals quantity quantities and units of measure artifact man-made objects phenomenon natural phenomena attribute attributes of people and objects plant plants body body parts possession possession and transfer of possession cognition cognitive processes and contents process natural processes communication communicative processes and contents person people event natural events relation relations between people or things or ideas feeling feelings and emotions shape two and three dimensional shapes food foods and drinks state stable states of affairs group groupings of people or objects substance substances location spatial position time time and temporal relations motive goals Tops abstract terms for unique beginners VERBS SUPERSENSE VERBS OF SUPERSENSE VERBS OF body grooming , dressing and bodily care emotion feeling change size , temperature change , intensifying motion walking , flying , swimming cognition thinking , judging , analyzing , doubting perception seeing , hearing , feeling communication telling , asking , ordering , singing possession buying , selling , owning competition fighting , athletic activities social political and social activities and events consumption eating and drinking stative being , having , spatial relations contact touching , hitting , tying , digging weather raining , snowing , thawing , thundering creation sewing , baking , painting , performing Table 1 .</sentence>
				<definiendum id="0">SUPERSENSE NOUNS DENOTING SUPERSENSE NOUNS DENOTING act</definiendum>
				<definiens id="0">acts or actions object natural objects ( not man-made ) animal animals quantity quantities and units of measure artifact man-made objects phenomenon natural phenomena attribute attributes of people and objects plant plants body body parts possession possession and transfer of possession cognition cognitive processes and contents process natural processes communication communicative processes and contents person people event natural events relation relations between people or things or ideas feeling feelings and emotions shape two and three dimensional shapes food foods and drinks state stable states of affairs group groupings of people or objects substance substances location spatial position time time and temporal relations motive goals Tops abstract terms for unique beginners VERBS SUPERSENSE VERBS OF SUPERSENSE VERBS OF body grooming</definiens>
			</definition>
			<definition id="3">
				<sentence>Wordnet ( Fellbaum , 1998 ) is a broad-coverage machine-readable dictionary which includes 11,306 verbs mapped to 13,508 word senses , called synsets , and 114,648 common and proper nouns mapped to 79,689 synsets .</sentence>
				<definiendum id="0">Wordnet</definiendum>
				<definiens id="0">a broad-coverage machine-readable dictionary which includes 11,306 verbs mapped to 13,508 word senses , called synsets , and 114,648 common and proper nouns mapped to 79,689 synsets</definiens>
			</definition>
			<definition id="4">
				<sentence>( 3 ) Φ is a global feature representation , mapping each ( x , y ) pair to a vector of feature counts Φ ( x , y ) ∈ IRd , where d is the total number of features .</sentence>
				<definiendum id="0">Φ</definiendum>
				<definiendum id="1">d</definiendum>
				<definiens id="0">a global feature representation , mapping each ( x , y ) pair to a vector of feature counts Φ ( x , y ) ∈ IRd</definiens>
				<definiens id="1">the total number of features</definiens>
			</definition>
			<definition id="5">
				<sentence>For each observed word xi in the data φ extracts the following features : for xi , fs ( xi ) , cf. Section 5.3 ; posi+1 , posi+2 , posi [ 0 ] , posi−1 [ 0 ] , posi−2 [ 0 ] , posi+1 [ 0 ] , posi+2 [ 0 ] , pos commi if xi’s POS tagsis“NN”or“NNS” ( commonnouns ) , and pos propi if xi’s POS is “NNP” or “NNPS” ( proper nouns ) ; sh ( xi+1 ) , sh ( xi+2 ) , where sh ( xi ) is as described below .</sentence>
				<definiendum id="0">sh</definiendum>
				<definiens id="0">for xi , fs ( xi )</definiens>
				<definiens id="1">commi if xi’s POS tagsis“NN”or“NNS” ( commonnouns ) , and pos propi if xi’s POS is “NNP” or “NNPS” ( proper nouns</definiens>
			</definition>
			<definition id="6">
				<sentence>In addition shi = low if the first character of xi is lowercase , shi = cap brk if the first character of xi is uppercase and xi−1 is a full stop , question or exclamation mark , or xi is the first word of the sentence , shi = cap nobrk otherwise ; Word features ( 1 ) are morphologically simplified using the morphological functions of the Wordnet library .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiens id="0">a full stop , question or exclamation mark , or</definiens>
				<definiens id="1">the first word of the sentence</definiens>
			</definition>
</paper>

		<paper id="1202">
			<definition id="0">
				<sentence>1 Computing Department Lancaster University Lancaster , UK { s.piao , p.rayson , r.garside } @ lancaster.ac.uk 2 Dept. of Linguistics and EL Lancaster University Lancaster , UK { o.mudraya , a.wilson } @ lancaster.ac.uk This paper reports on an experiment in which we explore a new approach to the automatic measurement of multi-word expression ( MWE ) compositionality .</sentence>
				<definiendum id="0">MWE</definiendum>
				<definiens id="0">a new approach to the automatic measurement of multi-word expression (</definiens>
			</definition>
			<definition id="1">
				<sentence>On the other hand , decomposability is a metric of the degree to which the meaning of a MWE can be assigned to its parts ( Nunberg , 1994 ; Riehemann , 2001 ; Sag et al. , 2002 ) .</sentence>
				<definiendum id="0">decomposability</definiendum>
				<definiendum id="1">MWE</definiendum>
				<definiens id="0">a metric of the degree to which the meaning of a</definiens>
			</definition>
			<definition id="2">
				<sentence>With respect to weight α , suppose L is the number of candidate tags of the constituent word under consideration , N is the position of the specific tag in the candidate list ( the position starts from the top with N=1 ) , then the weight α is calculated as ( 2 ) 2 1 L NL +− =α , where N=1 , 2 , … , n and N &lt; =L. Ranging between [ 1 , 0 ) , α takes into account both the location of the matched tag in the candidate tag list and the number of candidate tags .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the number of candidate tags of the constituent word under consideration</definiens>
			</definition>
			<definition id="3">
				<sentence>As we mentioned earlier , a semantic tag consists of an initial letter and some trailing digits divided by points , e.g. S1.1.2 { RECIPROCITY } , S1.1.3 { PARTICIPATION } , S1.1.4 { DESERVE } etc .</sentence>
				<definiendum id="0">semantic tag</definiendum>
				<definiens id="0">consists of an initial letter and some trailing digits divided by points</definiens>
			</definition>
			<definition id="4">
				<sentence>The Lancaster semantic lexicon is one such lexical resource which allows us to have direct access to semantic field information of large number of MWE and single words .</sentence>
				<definiendum id="0">Lancaster semantic lexicon</definiendum>
				<definiens id="0">one such lexical resource which allows us to have direct access to semantic field information of large number of MWE and single words</definiens>
			</definition>
</paper>

		<paper id="1904">
			<definition id="0">
				<sentence>Fastr ( Jacquemin , 1996 ) is a parser which takes as input a corpus and a list of terms ( multi or monoterms ) and outputs the indexed corpus in which terms and their variants are recognized .</sentence>
				<definiendum id="0">Fastr</definiendum>
				<definiens id="0">a parser which takes as input a corpus and a list of terms ( multi or monoterms ) and outputs the indexed corpus in which terms and their variants are recognized</definiens>
			</definition>
</paper>

		<paper id="0302">
			<definition id="0">
				<sentence>Coreference resolution is the problem of deciding what noun phrases in the text ( i.e. mentions ) refer to the same real-world entities ( i.e. are coreferent ) .</sentence>
				<definiendum id="0">Coreference resolution</definiendum>
				<definiens id="0">the problem of deciding what noun phrases in the text ( i.e. mentions ) refer to the same real-world entities</definiens>
			</definition>
			<definition id="1">
				<sentence>Finally , the MPQA corpus contains no coreference information for general NPs ( which are not sources ) .</sentence>
				<definiendum id="0">MPQA corpus</definiendum>
				<definiens id="0">contains no coreference information for general NPs ( which are not sources )</definiens>
			</definition>
			<definition id="2">
				<sentence>First , SVMs trained on the full training set outperform RIPPER trained on the same training set as well as the corresponding SVMs trained on the 200-document training set .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">trained on the full training set outperform RIPPER trained on the same training set as well as the corresponding SVMs trained on the 200-document training set</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>An LS is a directed graph , and just that .</sentence>
				<definiendum id="0">LS</definiendum>
				<definiens id="0">a directed graph</definiens>
			</definition>
			<definition id="1">
				<sentence>An LS is a non-hierarchical structure , although it can contain sets of nodes that are hierarchically connected .</sentence>
				<definiendum id="0">LS</definiendum>
			</definition>
			<definition id="2">
				<sentence>Fuzziness encoding is an essential feature of LSs , as structures on which inference can take place or as structures that are , at least partially , inferred from others ( in case of generation of LSs from existing lexical databases ) .</sentence>
				<definiendum id="0">Fuzziness encoding</definiendum>
				<definiens id="0">an essential feature of LSs , as structures on which inference can take place or as structures that are , at least partially , inferred from others</definiens>
			</definition>
			<definition id="3">
				<sentence>The DiCo is a French lexical database that focuses on the modeling of paradigmatic and syntagmatic lexical links controlled by lexical units .</sentence>
				<definiendum id="0">DiCo</definiendum>
				<definiens id="0">a French lexical database that focuses on the modeling of paradigmatic and syntagmatic lexical links controlled by lexical units</definiens>
			</definition>
			<definition id="4">
				<sentence>RANCUNE ( ‘resentment’ ) : ( 1 ) /* [ X ] éprouver ~*/ { Oper12 } avoir , éprouver , nourrir , ressentir [ ART ~ Prép-envers N=Y ] We isolate five different types of LS entities in the above example : • The expression between curly brackets Oper12 is the name of a lexical function denoting a type of support verbs .</sentence>
				<definiendum id="0">RANCUNE</definiendum>
			</definition>
			<definition id="5">
				<sentence>The FileMaker ( or SQL ) DiCo database that has been used contained only 775 lexical unit records ( word senses ) .</sentence>
				<definiendum id="0">FileMaker</definiendum>
			</definition>
</paper>

		<paper id="1902">
			<definition id="0">
				<sentence>The goal of CLIR is to help searchers find relevant documents when their query terms are chosen from a language different from the language in which the documents are written .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">to help searchers find relevant documents when their query terms are chosen from a language different from the language in which the documents are written</definiens>
			</definition>
			<definition id="1">
				<sentence>Detail analysis of AnswerFinder Performance-monolingual run To measure the performance of AnswerFinder , recall ( ratio of relevant items retrieved to all relevant items in a collection ) and precision ( the ratio of relevant items retrieved to all retrieved items ) were calculated .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">recall ( ratio of relevant items retrieved to all relevant items in a collection</definiens>
				<definiens id="1">the ratio of relevant items retrieved to all retrieved items ) were calculated</definiens>
			</definition>
			<definition id="2">
				<sentence>Types of Translation Errors Wrong Transliteration Wrong transliteration is the most common error that encountered during translation .</sentence>
				<definiendum id="0">Translation Errors Wrong Transliteration Wrong transliteration</definiendum>
				<definiens id="0">the most common error that encountered during translation</definiens>
			</definition>
			<definition id="3">
				<sentence>Transliteration is the process of replacing words in the source language with their phonetic equivalent in the target language .</sentence>
				<definiendum id="0">Transliteration</definiendum>
				<definiens id="0">the process of replacing words in the source language with their phonetic equivalent in the target language</definiens>
			</definition>
			<definition id="4">
				<sentence>The Arabic form is a compound phrase ; however Systran translated each word individually even after diacritics were added .</sentence>
				<definiendum id="0">Arabic form</definiendum>
			</definition>
			<definition id="5">
				<sentence>Arabic writing involves diacritization ( vowel ) , which is largely ignored in modern texts .</sentence>
				<definiendum id="0">Arabic writing</definiendum>
				<definiens id="0">involves diacritization ( vowel ) , which is largely ignored in modern texts</definiens>
			</definition>
</paper>

		<paper id="1523">
			<definition id="0">
				<sentence>In particular , Adjoining provides a simple and elegant solution for the long-standing and difficult problem in modern syntactic theory concerning a proper formulation of the recursive , or ’successive-cyclic’ , character of unbounded long movement in examples such as ( 1 ) where the whphrase stops by each intermediate CP ( ’Comp’ ) .</sentence>
				<definiendum id="0">Adjoining</definiendum>
				<definiens id="0">provides a simple and elegant solution for the long-standing and difficult problem in modern syntactic theory concerning a proper formulation of the recursive , or ’successive-cyclic’ , character of unbounded long movement</definiens>
			</definition>
			<definition id="1">
				<sentence>Long-distance dependencies ( LDD ) thus reduce to local dependencies within an elementary tree ( in the sense of TAG ) coupled with the recursive mechanism of ’interpolating’ additional structural chunk ( s ) by Adjoining .</sentence>
				<definiendum id="0">Long-distance dependencies</definiendum>
				<definiendum id="1">LDD</definiendum>
			</definition>
			<definition id="2">
				<sentence>invited Control infinitivals in Russian have been independently shown to be domains smaller than CP , namely , VPs ( Babby , 1998 ) , unlike in English where they are analyzed as either CPs or TPs , depending on a theory.1 Subjunctive clauses present a well known ’restructuring’ context .</sentence>
				<definiendum id="0">Control</definiendum>
				<definiens id="0">infinitivals in Russian have been independently shown to be domains smaller than CP</definiens>
			</definition>
			<definition id="3">
				<sentence>It seems appropriate , therefore , to split Adjoining into two different operations , e.g. Adjunction ( which coincides with the traditional transformational usage ) for ( 14 ) a , and Interpolation for the case ( 14 ) a. The proposal in ( 10 ) then pertains to the latter , without loss of generality .</sentence>
				<definiendum id="0">e.g. Adjunction</definiendum>
				<definiendum id="1">Interpolation</definiendum>
				<definiens id="0">coincides with the traditional transformational usage</definiens>
			</definition>
			<definition id="4">
				<sentence>The present study applies the TAG machinery in the domain of well known but ill explained phenomenon of radical across-the-board locality of syntactic dependencies in two Slavic languages , Russian and Polish .</sentence>
				<definiendum id="0">TAG machinery</definiendum>
			</definition>
</paper>

		<paper id="1315">
			<definition id="0">
				<sentence>But sometimes performance factors intervene as in the following example , where B is engaging in floor-holding using a dialogue act annotated here as DELIBERATE : A : so that maybe I if I need to if I need to order like a limo or something SUGGEST B : &lt; hes &gt; let us see DELIBERATE B : the this is the &lt; hes &gt; wrong month DELIBERATE B : the third DELIBERATE B : let us see DELIBERATE B : I do n't have anything scheduled that morning and we are leaving at one INFORM The response ( INFORM ) finally comes , but the forgetful ‘previous tag’ feature is now looking for what comes after DELIBERATE .</sentence>
				<definiendum id="0">DELIBERATE</definiendum>
				<definiendum id="1">INFORM</definiendum>
				<definiens id="0">the third DELIBERATE B : let us see DELIBERATE B : I do n't have anything scheduled that morning</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , SUGGEST : REJECT is a well-known adjacency pair , but it does not appear on the list until after several less-worthy-seeming pairs .</sentence>
				<definiendum id="0">REJECT</definiendum>
				<definiens id="0">a well-known adjacency pair</definiens>
			</definition>
</paper>

		<paper id="3815">
			<definition id="0">
				<sentence>Treating an ontology as a network , we can represent a context as a set of nodes in the network ( i.e. , concepts in the ontology ) , each with a weight ( i.e. , frequency ) .</sentence>
				<definiendum id="0">Treating an ontology</definiendum>
				<definiens id="0">a set of nodes in the network ( i.e. , concepts in the ontology ) , each with a weight</definiens>
			</definition>
			<definition id="1">
				<sentence>Mathematically , let a2a4a3a6a5a8a7a10a9a12a11a14a13 be a connected network , where a15 is the set of nodes , and a16 is the set of edges.1 Each edge has a cost a17a19a18a20a16a22a21 a23 , which is the distance of the edge .</sentence>
				<definiendum id="0">a15</definiendum>
				<definiendum id="1">a16</definiendum>
				<definiens id="0">the set of nodes , and</definiens>
				<definiens id="1">the set of edges.1 Each edge has a cost a17a19a18a20a16a22a21 a23 , which is the distance of the edge</definiens>
			</definition>
			<definition id="2">
				<sentence>A relation ( such as hyponymy ) between two concepts a24 and a79 is represented by an edge a5a29a24a78a9a80a79a81a13 , and the cost a17 on each edge can be defined as the semantic distance between the two concepts .</sentence>
				<definiendum id="0">relation</definiendum>
				<definiens id="0">such as hyponymy ) between two concepts a24 and a79 is represented by an edge a5a29a24a78a9a80a79a81a13</definiens>
				<definiens id="1">the semantic distance between the two concepts</definiens>
			</definition>
			<definition id="3">
				<sentence>Mathematically , for any path from node a24 to node a157 , a158a81a5a98a79a113a159a59a9a80a79a28a160a119a13a12a9a121a161a121a161a121a161a162a9a113a5a98a79a121a163a81a164a67a160a113a9a80a79a121a163a124a13a137a165 , where a24a106a3a166a79a113a159 and a157a167a3a168a79 a163 , the distance between nodes a24 and a157 is the sum of the distance of the edges along the path : a169 a153a171a170a8a172a173a88a57a153 a107a30a174 a91a124a92a176a175a119a177a32a178a93 a179a124a180a116a181 a169 a153a171a170a8a172a173a88a183a182 a179 a107 a182 a179a124a184 a178 a91 ( 5 ) The additivity of a concept-to-concept distance entails that selecting the cheapest edge at each step ( i.e. , locally ) yields the overall cheapest set of routes ( i.e. , globally ) .</sentence>
				<definiendum id="0">a157</definiendum>
				<definiens id="0">the sum of the distance of the edges along the path : a169 a153a171a170a8a172a173a88a57a153 a107a30a174 a91a124a92a176a175a119a177a32a178a93 a179a124a180a116a181 a169 a153a171a170a8a172a173a88a183a182 a179 a107 a182 a179a124a184 a178 a91 ( 5 ) The additivity of a concept-to-concept distance entails that selecting the cheapest edge at each step ( i.e. , locally ) yields the overall cheapest set of routes</definiens>
			</definition>
			<definition id="4">
				<sentence>Each edge has the exact concept-to-concept distance from the original network , so that the distance between any two nodes a189 and a191 is the sum of three exact distances .</sentence>
				<definiendum id="0">a191</definiendum>
				<definiens id="0">the sum of three exact distances</definiens>
			</definition>
			<definition id="5">
				<sentence>Thus , the transformed distance between a189 and a191 , a212a28a146a102a213a104a203a66a220a171a221a102a222a68a223a121a216a162a5a173a213a59a9a113a212a124a13 , becomes : a169 a153a171a170a8a172a51a224a183a225a51a226 a175a173a227 a88a57a170 a107 a169 a91a124a92 a169 a153a171a170a8a172a30a88a57a170 a107a137a228 a227 a91a81a229 a169 a153a171a170a8a172a173a88 a228 a227 a107a137a228a137a230 a91a81a229 a169 a153a51a170a80a172a173a88 a228a12a230a121a107 a169 a91 ( 6 ) where a191a218a24a30a189a187a231a121a5a29a24a78a9a80a79a81a13 is the precise concept-to-concept distance between a24 and a79 in the original network .</sentence>
				<definiendum id="0">a191a218a24a30a189a187a231a121a5a29a24a78a9a80a79a81a13</definiendum>
				<definiens id="0">the precise concept-to-concept distance between a24 and a79 in the original network</definiens>
			</definition>
			<definition id="6">
				<sentence>To illustrate the distortion effect , consider Jiang and Conrath’s ( 1997 ) distance : a169 a153a171a170a8a172a232a98a233a68a88a57a153 a107 a182 a91a124a92a235a234a137a236 a88a57a153 a91a218a229a134a234a137a236 a88a183a182 a91a81a115a238a237a12a234a137a236 a88a102a239 a236a116a240 a88a57a153 a107 a182 a91a66a91 ( 7 ) where a69a28a241a14a5a30a146a147a13 is the information content of a node a24 , and a242a86a241a106a243a244a5a30a146a137a9a66a245a138a13 is the lowest common subsumer of nodes a24 and a79 .</sentence>
				<definiendum id="0">a69a28a241a14a5a30a146a147a13</definiendum>
				<definiendum id="1">a242a86a241a106a243a244a5a30a146a137a9a66a245a138a13</definiendum>
				<definiens id="0">the information content of a node a24</definiens>
				<definiens id="1">the lowest common subsumer of nodes a24 and a79</definiens>
			</definition>
			<definition id="7">
				<sentence>Unfortunately , the complexity of these algorithms is quadratic ( the former ) or cubic ( the latter ) in the number of nodes in a network , which is unacceptably expensive for our transformation method .</sentence>
				<definiendum id="0">quadratic</definiendum>
				<definiens id="0">the former ) or cubic ( the latter</definiens>
			</definition>
</paper>

		<paper id="2007">
			<definition id="0">
				<sentence>At the end of this step , we have produced a set a4 , which consists of Chinese words a5 a6 a8 a10 a6 a12 a10 a13 a13 a13 a10 a6 a18 a20 , wherea6 a2 is the translation corresponding to sense a1 a2 of a0 , anda22 is the number of senses that a0 has .</sentence>
				<definiendum id="0">anda22</definiendum>
				<definiens id="0">consists of Chinese words a5 a6 a8 a10 a6 a12 a10 a13 a13 a13 a10 a6 a18 a20 , wherea6 a2 is the translation corresponding to sense a1 a2 of a0 ,</definiens>
			</definition>
			<definition id="1">
				<sentence>In such cases , the annotator was advised to try to capture the subtle difference between these English word senses and then to 2 PowerWord is a commercial electronic dictionary application .</sentence>
				<definiendum id="0">PowerWord</definiendum>
				<definiens id="0">a commercial electronic dictionary application</definiens>
			</definition>
</paper>

		<paper id="2506">
			<definition id="0">
				<sentence>Table 1 provides an example of the most frequent response types and their frequencies for the homophone target noun Schloss , as described in Section 2 ; the ‘lock’ meaning was depicted , ‘castle’ is an alternative meaning .</sentence>
				<definiendum id="0">‘castle’</definiendum>
				<definiens id="0">an alternative meaning</definiens>
			</definition>
			<definition id="1">
				<sentence>An enourmous number of approaches in computational linguistics can be found on the SENSEVAL webpage ( SENSEVAL , ) , which hosts a word sense disambiguation competition .</sentence>
				<definiendum id="0">SENSEVAL , )</definiendum>
				<definiens id="0">hosts a word sense disambiguation competition</definiens>
			</definition>
			<definition id="2">
				<sentence>The LSC algorithm is an instance of the Expectation-Maximisation algorithm ( Baum , 1972 ) for unsupervised training based on unannotated data , and has been applied to model the selectional dependency between two sets of words participatinginagrammaticalrelationship ( Rooth , 1998 ; Rooth et al. , 1999 ) .</sentence>
				<definiendum id="0">LSC algorithm</definiendum>
			</definition>
			<definition id="3">
				<sentence>Noun similarity : Those target nouns which were assigned to a common cluster were assumed tobesemanticallysimilar ( withrespecttothecluster content ) .</sentence>
				<definiendum id="0">Noun similarity</definiendum>
				<definiens id="0">Those target nouns which were assigned to a common cluster were assumed tobesemanticallysimilar ( withrespecttothecluster content )</definiens>
			</definition>
</paper>

		<paper id="0134">
			<definition id="0">
				<sentence>Word is a logical semantic and syntactic unit in natural language .</sentence>
				<definiendum id="0">Word</definiendum>
				<definiens id="0">a logical semantic and syntactic unit in natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>According to formula ( 1 ) , the probability of the whole candidate path , which includes “我们 /吃 / 香蕉 ” is zero , as a result of the local zero probability .</sentence>
				<definiendum id="0">”</definiendum>
				<definiens id="0">the probability of the whole candidate path , which includes “我们 /吃 / 香蕉</definiens>
			</definition>
			<definition id="2">
				<sentence>.9 ] ; null &lt; year &gt; : := &lt; digit &gt; { &lt; digit &gt; + } 年” ; null &lt; integer &gt; : := { &lt; digit &gt; + } ; where “- &gt; ” is a temporary generative rule , and “ : :=” is a real generative rule .</sentence>
				<definiendum id="0">“- &gt; ”</definiendum>
				<definiens id="0">a temporary generative rule , and “ : :=” is a real generative rule</definiens>
			</definition>
			<definition id="3">
				<sentence>Then the model’s conditional probability is defined as 190 ∑ ∈ = Tt thp thp htp ' ) ' , ( ) , ( ) | ( ( 6 ) where ∏ = = k j thf j j thp 1 ) , ( ) , ( απµ ( 7 ) where h is the current context and t is one of the possible tags .</sentence>
				<definiendum id="0">conditional probability</definiendum>
				<definiendum id="1">h</definiendum>
				<definiens id="0">190 ∑ ∈ = Tt thp thp htp ' ) ' , ( ) , ( ) | ( ( 6 ) where ∏ = = k j thf j j thp 1 ) , ( )</definiens>
			</definition>
</paper>

		<paper id="2105">
			<definition id="0">
				<sentence>In German , PPs can occur also as invariant syntagmas in light verb constructions ( ‘Funktionsverbgef¨uge’ ) such as in Beschlag nehmen ( ‘to occupy’ ) , to which the complement-adjunct distinction does not apply .</sentence>
				<definiendum id="0">‘Funktionsverbgef¨uge’</definiendum>
				<definiens id="0">‘to occupy’ ) , to which the complement-adjunct distinction does not apply</definiens>
			</definition>
			<definition id="1">
				<sentence>Examples for verbs , adjectives , and nouns of this sort are glauben an ( ‘to belief in’ ) , sich verlassen auf ( ‘to depend on’ ) , gut in ( ‘good at’ ) , and Wut auf ( ‘anger at’ ) .</sentence>
				<definiendum id="0">Wut auf</definiendum>
				<definiens id="0">‘to belief in’ ) , sich verlassen auf ( ‘to depend on’</definiens>
			</definition>
			<definition id="2">
				<sentence>MultiNet is one of the few knowledge representation paradigms which have also been used as a semantic interlingua in real-life NLP applications ( Leveling and Helbig , 2002 ) .</sentence>
				<definiendum id="0">MultiNet</definiendum>
				<definiens id="0">one of the few knowledge representation paradigms which have also been used as a semantic interlingua in real-life NLP applications ( Leveling</definiens>
			</definition>
			<definition id="3">
				<sentence>The MultiNet formalism represents meanings of natural language expressions by means of ( partial ) semantic networks .</sentence>
				<definiendum id="0">MultiNet formalism</definiendum>
				<definiens id="0">represents meanings of natural language expressions by means of ( partial ) semantic networks</definiens>
			</definition>
			<definition id="4">
				<sentence>A semantic network consists of nodes representing concepts and edges representing relations between concepts .</sentence>
				<definiendum id="0">semantic network</definiendum>
			</definition>
</paper>

		<paper id="2501">
			<definition id="0">
				<sentence>The measure of relatedness between two concepts is the information content of the most specific concept that both concepts have in common ( i.e. , their lowest common subsumer in the is-a hierarchy ) .</sentence>
				<definiendum id="0">specific concept</definiendum>
				<definiens id="0">the information content of the most</definiens>
			</definition>
			<definition id="1">
				<sentence>Very low frequency words do not occur enough to draw distinctions among different glosses , whereas high frequency words occur in many glosses , and again do not provide useful information to distinguish among glosses .</sentence>
				<definiendum id="0">Very low</definiendum>
				<definiens id="0">provide useful information to distinguish among glosses</definiens>
			</definition>
			<definition id="2">
				<sentence>Word sense disambiguation is the task of determining the meaning ( from multiple possibilities ) of a word in its given context .</sentence>
				<definiendum id="0">Word sense disambiguation</definiendum>
				<definiens id="0">the task of determining the meaning ( from multiple possibilities</definiens>
			</definition>
			<definition id="3">
				<sentence>Each instance consists of approximately 2-3 sentences and one occurrence of a target word .</sentence>
				<definiendum id="0">instance</definiendum>
				<definiens id="0">consists of approximately 2-3 sentences and one occurrence of a target word</definiens>
			</definition>
			<definition id="4">
				<sentence>For a given word , term frequency ( tf ) is the number of times a word appears in the corpus .</sentence>
				<definiendum id="0">term frequency</definiendum>
				<definiendum id="1">tf )</definiendum>
				<definiens id="0">the number of times a word appears in the corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>The document frequency is number of documents in which the word occurs .</sentence>
				<definiendum id="0">document frequency</definiendum>
			</definition>
			<definition id="6">
				<sentence>Inverse document frequency ( idf ) is then computed as idf = logNumber of DocumentsDocument Frequency ( 1 ) The tf · idf value is an indicator of the specificity of a word .</sentence>
				<definiendum id="0">Inverse document frequency</definiendum>
				<definiendum id="1">idf</definiendum>
				<definiendum id="2">idf value</definiendum>
				<definiens id="0">an indicator of the specificity of a word</definiens>
			</definition>
</paper>

		<paper id="1625">
			<definition id="0">
				<sentence>For this study , we use a number of acousticprosodic as well as some non acoustic-prosodic features as listed below : Acoustic-Prosodic Features : AF Pitch ( F0 ) : Mean , Max , Min , Range , Standard Deviation AF Energy ( RMS ) : Mean , Max , Min , Range , Standard Deviation AF Temporal : Duration , Internal Silence , Tempo Non Acoustic-Prosodic Features : AF Lexical AF Turn Length ( # Words ) AF Speaker Our acoustic-prosodic features make use of the pitch , energy and temporal information in the speech signal , and are computed using Wavesurfer .</sentence>
				<definiendum id="0">AF Pitch ( F0 )</definiendum>
				<definiendum id="1">AF Lexical AF Turn Length</definiendum>
				<definiens id="0">Mean , Max , Min , Range , Standard Deviation AF Energy ( RMS ) : Mean , Max , Min , Range , Standard Deviation AF Temporal</definiens>
			</definition>
			<definition id="1">
				<sentence>Duration is measured in terms of time in seconds , from the beginning to the end of the turn including pauses ( if any ) in between .</sentence>
				<definiendum id="0">Duration</definiendum>
				<definiens id="0">measured in terms of time in seconds , from the beginning to the end of the turn including pauses</definiens>
			</definition>
			<definition id="2">
				<sentence>Feature Humor Non-Humor Mean-F0 206.9 208.9 Max-F0* 299.8 293.5 Min-F0* 121.1 128.6 Range-F0* 178.7 164.9 StdDev-F0 41.5 41.1 Mean-RMS* 58.3 57.2 Max-RMS* 76.4 75 Min-RMS* 44.2 44.6 Range-RMS* 32.16 30.4 StdDev-RMS* 7.8 7.5 Duration* 3.18 2.66 Int-Sil* 0.452 0.503 Tempo* 3.21 3.03 Length* 10.28 7.97 Table 3 : Humor Prosody : Mean feature values for Humor and Non-Humor groups Table 3 shows mean values of various acousticprosodic features over all speaker turns in our data , across humor and non-humor groups .</sentence>
				<definiendum id="0">Humor Prosody</definiendum>
				<definiens id="0">Mean feature values for Humor and Non-Humor groups Table 3 shows mean values of various acousticprosodic features over all speaker turns in our data</definiens>
			</definition>
</paper>

		<paper id="1640">
			<definition id="0">
				<sentence>To date , research in the area ( see Related Work section ) has focused on the problem of extracting sentiment both at the document level ( coarse-grained sentiment information ) , and at the level of sentences , clauses , or individual expressions ( finegrained sentiment information ) .</sentence>
				<definiendum id="0">document level</definiendum>
				<definiens id="0">coarse-grained sentiment information ) , and at the level of sentences , clauses , or individual expressions ( finegrained sentiment information )</definiens>
			</definition>
			<definition id="1">
				<sentence>Coreference resolution is defined as the problem of deciding which noun phrases in the text ( mentions ) refer to the same real world entities ( are coreferent ) .</sentence>
				<definiendum id="0">Coreference resolution</definiendum>
			</definition>
			<definition id="2">
				<sentence>Semi-supervised clustering can be defined as the problem of clustering a set of items in the presence of limited supervisory information such as pairwise constraints ( e.g. two items must/ can not be in the same cluster ) or labeled points .</sentence>
				<definiendum id="0">Semi-supervised clustering</definiendum>
				<definiens id="0">the problem of clustering a set of items in the presence of limited supervisory information such as pairwise constraints ( e.g. two items must/ can not be in the same cluster</definiens>
			</definition>
			<definition id="3">
				<sentence>In the fully supervised setting , an algorithm is given a set S of n training examples ( x1 , y1 ) , ... , ( xn , yn ) ∈ X × Y , where X is the set of all possible sets of items and Y is the set of all possible clusterings of these sets .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">the set of all possible sets of items</definiens>
				<definiens id="1">the set of all possible clusterings of these sets</definiens>
			</definition>
			<definition id="4">
				<sentence>The items in each training example are the NPs and the clustering over the items is the equivalence relation defined by the coreference information .</sentence>
				<definiendum id="0">clustering over the items</definiendum>
				<definiens id="0">the equivalence relation defined by the coreference information</definiens>
			</definition>
			<definition id="5">
				<sentence>RIPPER consists of two phases – a ruleset is grown and then optimized .</sentence>
				<definiendum id="0">RIPPER</definiendum>
				<definiens id="0">consists of two phases – a ruleset is grown and then optimized</definiens>
			</definition>
			<definition id="6">
				<sentence>The ruleset creation phase begins by randomly splitting the training data into a rulegrowing set ( 2/3 of the training data ) and a pruning set ( the remaining 1/3 ) .</sentence>
				<definiendum id="0">ruleset creation phase</definiendum>
				<definiens id="0">begins by randomly splitting the training data into a rulegrowing set ( 2/3 of the training data ) and a pruning set</definiens>
			</definition>
			<definition id="7">
				<sentence>After all rules are considered , RIPPER attempts to grow residual rules that cover data not already covered by the ruleset .</sentence>
				<definiendum id="0">RIPPER</definiendum>
				<definiens id="0">attempts to grow residual rules that cover data not already covered by the ruleset</definiens>
			</definition>
			<definition id="8">
				<sentence>We compute transitive closure by using a Union-Find structure , which runs in time O ( log∗n ) , which for practical purposes can be considered linear ( O ( n ) ) gain for a nominal feature , StRip has to make a pass over the data for each value that the feature takes , while RIPPER can split the data into bags and perform the computation in one pass .</sentence>
				<definiendum id="0">Union-Find structure</definiendum>
			</definition>
			<definition id="9">
				<sentence>We use the same test set for all experi3For the transitive closure , n is the number of items in a document , which is O ( √k ) , where k is the number of NP pairs .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">k</definiendum>
				<definiens id="0">the number of items in a document</definiens>
			</definition>
			<definition id="10">
				<sentence>Recall for i is defined as the number of correctly identified mentions in ci divided by the number of mentions in the gold standard chain for i. Results are shown in Table 1 .</sentence>
				<definiendum id="0">Recall for i</definiendum>
				<definiens id="0">the number of correctly identified mentions in ci divided by the number of mentions in the gold</definiens>
			</definition>
</paper>

		<paper id="2610">
			<definition id="0">
				<sentence>The heads of the phrases have been annotated with the lowest possible node , i.e. ontological type , of the top ontology .</sentence>
				<definiendum id="0">heads of the phrases</definiendum>
				<definiens id="0">annotated with the lowest possible node , i.e. ontological type</definiens>
			</definition>
			<definition id="1">
				<sentence>Role Description AGT Agent of act or process BMO By means of , instrument , via CBY Caused by CHR Characteristic ( property ascription ) CMP Comprising , has part DST Destination of moving process LOC Location , position PNT Patient of act or process SRC Source of act or process TMP Temporal aspects WRT With respect to Table 2 : The set of relations used in the annotation , which is a subset of the set proposed in Nilsson , 2001 .</sentence>
				<definiendum id="0">CHR Characteristic ( property ascription ) CMP Comprising</definiendum>
				<definiens id="0">has part DST Destination of moving process LOC Location , position PNT Patient of act or process SRC Source of act or process TMP Temporal aspects WRT With respect</definiens>
			</definition>
</paper>

		<paper id="2918">
			<definition id="0">
				<sentence>A linear chain conditional random eld ( CRF ) ( Lafferty et al. , 2001 ) de nes the conditional probability of a label sequence s given an observed sequence o via : pa0 s a1 oa2a4a3 1Za0 o a2 exp a5 Ta6 1∑ ta7 1 ∑ k λk fk a0 st a8 1a9 st a9 o a9 ta2a11a10 ( 1 ) where T is the length of both sequences , λk are parameters of the model and Za0 oa2 is a partition function that ensures that ( 1 ) represents a probability distribution .</sentence>
				<definiendum id="0">linear</definiendum>
				<definiendum id="1">T</definiendum>
				<definiendum id="2">λk</definiendum>
				<definiens id="0">chain conditional random eld ( CRF ) ( Lafferty et al. , 2001 ) de nes the conditional probability of a label sequence s given an observed sequence o via : pa0 s a1 oa2a4a3 1Za0 o a2</definiens>
				<definiens id="1">the length of both sequences</definiens>
			</definition>
			<definition id="1">
				<sentence>Named entity recognition ( NER ) involves the identi cation of the location and type of pre-de ned entities within a sentence .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">involves the identi cation of the location and type of pre-de ned entities within a sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>The training set consists of 14 a9 987 sentences and 204 a9 567 tokens , the development set consists of 3 a9 466 sentences and 51 a9 578 tokens and the test set consists of 3 a9 684 sentences and 46 a9 666 tokens .</sentence>
				<definiendum id="0">training set</definiendum>
				<definiendum id="1">development set</definiendum>
			</definition>
			<definition id="3">
				<sentence>Given models pα and per-model weights wα , the LOP distribution is de ned by : pLOP a0 s a1 oa2a4a3 1Z LOP a0 o a2 ∏ α a15 pα a0 s a1 oa2 a17 wα ( 2 ) with wα a1 0 and ∑α wα a3 1 , and where ZLOP a0 oa2 is a normalising function .</sentence>
				<definiendum id="0">ZLOP a0 oa2</definiendum>
				<definiens id="0">a normalising function</definiens>
			</definition>
</paper>

		<paper id="0701">
			<definition id="0">
				<sentence>Input consists of a detailed query1 and a set of 25 to 50 relevant documents .</sentence>
				<definiendum id="0">Input</definiendum>
				<definiens id="0">consists of a detailed query1 and a set of 25 to 50 relevant documents</definiens>
			</definition>
			<definition id="1">
				<sentence>The former is often represented by the term frequency and the latter by the inverse document frequency ( idfi = Ndfi ) , where N is the number of documents and dfi is the number of documents containing term ti .</sentence>
				<definiendum id="0">inverse document frequency</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">dfi</definiendum>
				<definiens id="0">the number of documents</definiens>
				<definiens id="1">the number of documents containing term ti</definiens>
			</definition>
			<definition id="2">
				<sentence>Singular value decomposition is a technique for dimensionality reduction that has been used extensively for the analysis of lexical semantics under the name of latent semantic analysis ( Landauer et al. , 1998 ) .</sentence>
				<definiendum id="0">Singular value decomposition</definiendum>
			</definition>
			<definition id="3">
				<sentence>And S is a diagonal matrix of singular values in decreasing order .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">a diagonal matrix of singular values in decreasing order</definiens>
			</definition>
			<definition id="4">
				<sentence>Using a concatenation of Aquaint and DUC 2005 data ( 100+ million words ) , we utilised the Infomap tool4 to build a semantic model based on singular value decomposition ( SVD ) .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">Using a concatenation of Aquaint and DUC 2005 data ( 100+ million words</definiens>
			</definition>
			<definition id="5">
				<sentence>MMR ( Maximal Marginal Relevance ) is a common approach for determining relevance and redundancy in multi-document summarisation , in which candidate sentences are represented as weighted term-frequency vectors which can thus be compared to query vectors to gauge similarity and already-extracted sentence vectors to gauge redundancy , via the cosine of the vector pairs ( Carbonell and Goldstein , 1998 ) .</sentence>
				<definiendum id="0">MMR</definiendum>
				<definiens id="0">a common approach for determining relevance and redundancy in multi-document summarisation , in which candidate sentences are represented as weighted term-frequency vectors which can thus be compared to query vectors to gauge similarity and already-extracted sentence vectors to gauge redundancy , via the cosine of the vector pairs</definiens>
			</definition>
			<definition id="6">
				<sentence>The experimental setup uses the DUC 2005 data ( Dang , 2005 ) and the Rouge evaluation metric to explore the hypothesis that query-oriented multi-document summarisation using a term cooccurrence representation can be improved using SVD .</sentence>
				<definiendum id="0">experimental setup</definiendum>
				<definiendum id="1">term cooccurrence representation</definiendum>
				<definiens id="0">uses the DUC 2005 data ( Dang , 2005 ) and the Rouge evaluation metric to explore the hypothesis that query-oriented multi-document summarisation using a</definiens>
			</definition>
			<definition id="7">
				<sentence>The preprocessing was largely based on LT TTT and LT XML tools ( Grover et al. , 2000 ; Thompson et al. , 1997 ) .</sentence>
				<definiendum id="0">LT XML</definiendum>
			</definition>
			<definition id="8">
				<sentence>Rouge estimates the coverage of appropriate concepts ( Lin and Hovy , 2003 ) in a summary by comparing it several human-created reference summaries .</sentence>
				<definiendum id="0">Rouge</definiendum>
				<definiens id="0">estimates the coverage of appropriate concepts</definiens>
			</definition>
			<definition id="9">
				<sentence>pl -n 2 -x -m -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0 d 7Specifically , we use tfi , j ∗ log ( N dfi ) for term weighting where tfi , j is the number of times term i occurs in sentence j , N is the number of sentences , and dfi is the number of sentences containing term i. p Metric hypothesis Table 1 : Holm-corrected Wilcoxon hypothesis test results .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">dfi</definiendum>
				<definiens id="0">the number of times term i occurs in sentence j ,</definiens>
				<definiens id="1">the number of sentences</definiens>
			</definition>
</paper>

		<paper id="2603">
			<definition id="0">
				<sentence>An R-decomposition structure ( Haussler , 1999 ; Shawe-Taylor and Cristianini , 2004 ) on a set X is a triple R = 〈 vectorX , R , vectork〉 where vectorX = ( X1 , ... , XD ) is a D–tuple of non–empty subsets of X , R is a finite relation on X1 × ··· × XD × X , and vectork = ( k1 , ... , kD ) is a D–tuple of positive definite kernel functions kd : Xd ×Xd mapsto→ IR .</sentence>
				<definiendum id="0">XD )</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a triple R = 〈 vectorX , R , vectork〉 where vectorX = ( X1 , ... ,</definiens>
				<definiens id="1">a D–tuple of non–empty subsets of X</definiens>
			</definition>
			<definition id="1">
				<sentence>For any x ∈ X , let R−1 ( x ) = { ( x1 , ... , xD ) ∈ vectorX : R ( vectorx , x ) } denote the multiset of all possible decompositions1 of x. A decomposition kernel is then defined as the multiset kernel between the decompositions : KR ( x , xprime ) = summationdisplay vectorx ∈ R−1 ( x ) vectorxprime ∈ R−1 ( xprime ) Dproductdisplay d=1 κd ( xd , xprimed ) ( 1 ) 1Decomposition examples in the string domain include taking all the contiguous fixed-length substrings or all the possible ways of dividing a string into two contiguous substrings .</sentence>
				<definiendum id="0">x1 , ... , xD ) ∈ vectorX</definiendum>
			</definition>
			<definition id="2">
				<sentence>A weighted decomposition kernel ( WDK ) is characterized by the following decomposition structure : R = 〈 vectorX , R , ( δ , κ1 , ... , κD ) 〉 where vectorX = ( S , Z1 , ... , ZD ) , R ( s , z1 , ... , zD , x ) istrue iffs ∈ S isa subpartofxcalledthe selector andvectorz = ( z1 , ... , zD ) ∈ Z1×···×ZD isatupleof subparts of x called the contexts of s in x. Precise definitions of s and vectorz are domain-dependent .</sentence>
				<definiendum id="0">weighted decomposition kernel</definiendum>
				<definiendum id="1">WDK</definiendum>
				<definiendum id="2">ZD</definiendum>
				<definiendum id="3">R (</definiendum>
				<definiens id="0">characterized by the following decomposition structure : R = 〈 vectorX , R , ( δ , κ1 , ... , κD ) 〉 where vectorX = ( S , Z1 , ... ,</definiens>
			</definition>
			<definition id="3">
				<sentence>Denoteby pi ( j ) the observed frequency of value j in z. Then 18 ki can be defined as a HIK or a PPK respectively : ki ( z , zprime ) = misummationdisplay j=1 min { pi ( j ) , pprimei ( j ) } ( 3 ) ki ( z , zprime ) = misummationdisplay j=1 radicalBig pi ( j ) ·pprimei ( j ) ( 4 ) This setting results in the following general form of the kernel : K ( x , xprime ) = summationdisplay ( s , vectorz ) ∈ R−1 ( x ) ( sprime , vectorzprime ) ∈ R−1 ( xprime ) δ ( s , sprime ) Dsummationdisplay d=1 κd ( zd , zprimed ) ( 5 ) where we can replace the summation of kernels withproducttextDd=1 1 + κd ( zd , zprimed ) .</sentence>
				<definiendum id="0">Denoteby pi</definiendum>
				<definiendum id="1">K</definiendum>
				<definiendum id="2">sprime ) Dsummationdisplay d=1 κd</definiendum>
				<definiens id="0">a HIK or a PPK respectively : ki ( z , zprime ) = misummationdisplay j=1 min { pi ( j ) , pprimei ( j ) } ( 3 ) ki ( z , zprime ) = misummationdisplay j=1 radicalBig pi ( j ) ·pprimei ( j ) ( 4 ) This setting results in the following general form of the kernel</definiens>
			</definition>
			<definition id="4">
				<sentence>The relation for the first kernel version is defined as : R = { ( s , zLL , zLR , zRL , zRR , r ) } such that the selector s = x [ i ] is the word at position i , the zLL ( LeftLeft ) part is a sequence defined as x [ 1 .</sentence>
				<definiendum id="0">part</definiendum>
				<definiens id="0">R = { ( s , zLL , zLR , zRL , zRR , r ) } such that the selector s = x [ i ] is the word at position i , the zLL ( LeftLeft )</definiens>
			</definition>
			<definition id="5">
				<sentence>Informally , zLL is the initial portion of the sentence up to word of position i , and zLR is the portion of the sentence from word at position i + 1 up to t ( see Fig .</sentence>
				<definiendum id="0">zLL</definiendum>
				<definiendum id="1">zLR</definiendum>
				<definiens id="0">the initial portion of the sentence up to word of position i , and</definiens>
			</definition>
			<definition id="6">
				<sentence>we are interested in predicting that Wolff and Del Bosque are people’s names , that Argentina is a name of a location and that Real Madrid is a name of an organization .</sentence>
				<definiendum id="0">Madrid</definiendum>
				<definiens id="0">a name of a location and that Real</definiens>
				<definiens id="1">a name of an organization</definiens>
			</definition>
			<definition id="7">
				<sentence>WordNet ( Fellbaum , 1998 ) is an electronic lexical database of English words built and annotated by linguistic researchers .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">an electronic lexical database of English words built and annotated by linguistic researchers</definiens>
			</definition>
			<definition id="8">
				<sentence>WordNet is an extensive and reliable source of semantic information that can be used to enrich the representation of a word .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">an extensive and reliable source of semantic information that can be used to enrich the representation of a word</definiens>
			</definition>
			<definition id="9">
				<sentence>The resulting synset kernel is : κσ ( σ , σprime ) = δ ( λ , λprime ) + summationdisplay pi∈Π summationdisplay piprime∈Πprime k ( pi , piprime ) ( 8 ) where Π is the set of paths originating from σ and the exact match kernel δ ( λ , λprime ) is 1 if λ ≡ λprime and 0 otherwise .</sentence>
				<definiendum id="0">Π</definiendum>
				<definiens id="0">the set of paths originating from σ and the exact match kernel δ ( λ , λprime ) is 1 if λ ≡ λprime and 0 otherwise</definiens>
			</definition>
			<definition id="10">
				<sentence>ResultsoftheexperimentsarereportedinTab.3 for various kernels parameters : S or P denote if the sum or product of the kernels between words are used , W denotes that WordNet semantic informationisadded ( otherwisethekernelbetweentwo wordsisjusttheexactmatchkernel ) andLdenotes that lexicographer files identifiers are used .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">WordNet semantic informationisadded ( otherwisethekernelbetweentwo wordsisjusttheexactmatchkernel ) andLdenotes that lexicographer files identifiers are used</definiens>
			</definition>
			<definition id="11">
				<sentence>In ( Frasconi et al. , 2004 ) we introduced declarative kernels ( DK ) as a set of kernels working on mereotopological relations , such as that of proper parthood ( ≺P ) or more complex relations based on connected parts .</sentence>
				<definiendum id="0">DK</definiendum>
				<definiens id="0">a set of kernels working on mereotopological relations , such as that of proper parthood ( ≺P ) or more complex relations based on connected parts</definiens>
			</definition>
			<definition id="12">
				<sentence>A basic kernel on parts KP was defined as follows : KP ( x , xprime ) = summationdisplay s≺P x sprime≺P xprime δT ( s , sprime ) parenleftbigκ ( s , sprime ) +KP ( s , sprime ) parenrightbig ( 10 ) where δT matches objects of the same type and κ is a kernel over object attributes .</sentence>
				<definiendum id="0">s≺P x sprime≺P xprime δT</definiendum>
				<definiens id="0">defined as follows : KP ( x , xprime ) = summationdisplay</definiens>
				<definiens id="1">δT matches objects of the same type</definiens>
				<definiens id="2">a kernel over object attributes</definiens>
			</definition>
			<definition id="13">
				<sentence>( 10 ) simply adding to the attribute kernel κ a context kernel that compares the surrounding of a pair of objects—as defined by the topologyrelation—usingsomeaggregatekernelsuchas PPK or HIK ( see Section 3 ) .</sentence>
				<definiendum id="0">context kernel</definiendum>
			</definition>
</paper>

		<paper id="0204">
			<definition id="0">
				<sentence>The linked chains model ( Greenwood et al. , 2005 ) represents extraction patterns as a pair of chains which share the same verb but no direct descendants .</sentence>
				<definiendum id="0">extraction patterns</definiendum>
				<definiens id="0">a pair of chains which share the same verb but no direct descendants</definiens>
			</definition>
			<definition id="1">
				<sentence>The similarity of two nodes is zero if their part of speech tags are different and , otherwise , is simply the sum of the scores provided by the four functions which form the set F. This is represented by the function s : s ( n1 , n2 ) = braceleftBigg 0 if pos ( n 1 , n2 ) = 0summationtext f∈F f ( n1 , n2 ) otherwise The similarity of a pair of linked chain patterns , l1 and l2 , is determined by the function sim : sim ( l1 , l2 ) =    0 if s ( r1 , r2 ) = 0 s ( r1 , r2 ) + simc ( Cr1 , Cr2 ) otherwise where r1 and r2 are the root nodes of patterns l1 and l2 ( respectively ) and Cr is the set of children of node r. The final part of the similarity function calculates the similarity between the child nodes of n1 and n2.2 simc ( Cn1 , Cn2 ) = summationtext c1∈Cn1 summationtext c2∈Cn2 sim ( c1 , c2 ) Using this similarity function a pair of identical nodes have a similarity score of four .</sentence>
				<definiendum id="0">r2 ) + simc</definiendum>
				<definiendum id="1">Cr</definiendum>
				<definiens id="0">zero if their part of speech tags are different and</definiens>
				<definiens id="1">otherwise where r1 and r2 are the root nodes of patterns l1 and l2 ( respectively ) and</definiens>
				<definiens id="2">the set of children of node r. The final part of the similarity function calculates the similarity between the child nodes of n1 and n2.2 simc ( Cn1 , Cn2</definiens>
			</definition>
</paper>

		<paper id="2403">
			<definition id="0">
				<sentence>For a given pair of words X and Y and a search window W , let a be the number of windows in which X and Y co-occur , let b be the number of windows in which only X occurs , let c be the number of windows in which only Y occurs , and let d be the number of windows in which none of them occurs , then G 2 = 2 ( alna + blnb + clnc + dlnd ( a+b ) ln ( a+b ) ( a+c ) ln ( a+c ) ( b+d ) ln ( b+d ) ( c+d ) ln ( c+d ) ) + ( a+b+c+d ) ln ( a+b+c+d ) ) In addition to the log-likelihood , the t-score is used to filter out insignificant co-occurrence word pairs ( Fung and Church , 1994 ) , which is calculated as follows : ) , ( 1 ) ( ) ( ) , ( ba baba WWprob M WprobWprobWWprob t − = In order to filter out weak collocates , a threshold is often used , i.e. in the stage of collocation extraction , any pairs of items producing word affinity scores lower than a given threshold are excluded from the MWE searching process .</sentence>
				<definiendum id="0">a+c )</definiendum>
				<definiendum id="1">b+d ) ln</definiendum>
				<definiens id="0">the number of windows in which only X occurs , let c be the number of windows in which only Y occurs , and let d be the number of windows in which none of them occurs</definiens>
			</definition>
			<definition id="1">
				<sentence>In this experiment , our main aim was to examine the feasibility of practical application of the MWE tool as a component of an MT system , therefore we used test data from some domains in which translation services are in strong demand .</sentence>
				<definiendum id="0">MWE tool</definiendum>
				<definiens id="0">a component of an MT system , therefore we used test data from some domains in which translation services are in strong demand</definiens>
			</definition>
</paper>

		<paper id="0141">
			<definition id="0">
				<sentence>In detail , V1 represents the basic SVM-based segmenter ; V2 represents the segmenter which applied IV rules following SVMbased segmentation ; V3 represents the segmenter composing of all the components , that is , including SVM-based segmenter , IV rules and OOV rules .</sentence>
				<definiendum id="0">V1</definiendum>
				<definiendum id="1">V2</definiendum>
				<definiendum id="2">V3</definiendum>
				<definiens id="0">the basic SVM-based segmenter ;</definiens>
				<definiens id="1">the segmenter which applied IV rules following SVMbased segmentation ;</definiens>
			</definition>
</paper>

		<paper id="2901">
			<definition id="0">
				<sentence>Statistical Learning Theory and progress in Graphical Models theory have provided us with a welldefined framework in which we can relate different approaches like kernel methods , Naive Bayes , Markov models , maximum entropy approaches ( logistic regression ) , perceptrons and CRFs .</sentence>
				<definiendum id="0">Naive Bayes , Markov</definiendum>
				<definiens id="0">models , maximum entropy approaches ( logistic regression ) , perceptrons and CRFs</definiens>
			</definition>
			<definition id="1">
				<sentence>Learning is a search process in a hypothesis space .</sentence>
				<definiendum id="0">Learning</definiendum>
				<definiens id="0">a search process in a hypothesis space</definiens>
			</definition>
</paper>

		<paper id="1808">
			<definition id="0">
				<sentence>A candidate answer is in an inclusion relation if it entails another answer ( for example , concepts of candidate answers linked in an ontology by the is-a or part-of relations ) .</sentence>
				<definiendum id="0">candidate answer</definiendum>
			</definition>
			<definition id="1">
				<sentence>Thus , let crit 2 ftime ; place ; restrictiong and ai ; aj 2 A , if no information has been extracted for 2 compared criteria , then we consider that those criteria are equal ( there is no information indicating that there is a variation according to those criteria ) , i.e. if ai ( crit ) = ; and aj ( crit ) = ; , then 46 KRAQ06 ai ( crit ) = aj ( crit ) if no information has been extracted for one of the 2 compared criteria , then we consider that those criteria are different ( there is a variation ) , i.e. if ai ( crit ) = ; and aj ( crit ) 6= ; , then ai ( crit ) 6= aj ( crit ) In the example of figure 2 , the price varies according to time , place and restriction .</sentence>
				<definiendum id="0">aj</definiendum>
				<definiendum id="1">aj</definiendum>
				<definiens id="0">the price varies according to time , place and restriction</definiens>
			</definition>
</paper>

		<paper id="1649">
			<definition id="0">
				<sentence>Speci cally , given an incomplete sense-tagged corpus and a large amount of untagged examples for a target word 3 , we are interested in ( 1 ) labeling the instances in the untagged corpus with sense tags occurring in the tagged corpus ; ( 2 ) trying to nd unde ned senses ( or new senses ) of the target word 4 from the untagged corpus , which will be represented by instances from the untagged corpus .</sentence>
				<definiendum id="0">untagged corpus</definiendum>
				<definiens id="0">given an incomplete sense-tagged corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Disambiguation The partially supervised sense disambiguation problem can be generalized as a model order iden3Untagged data usually includes the occurrences of all the possible senses of the target word 4 unde ned senses are the senses that do not appear in tagged corpus .</sentence>
				<definiendum id="0">unde ned senses</definiendum>
				<definiens id="0">a model order iden3Untagged data usually includes the occurrences of all the possible senses of the target word 4</definiens>
			</definition>
			<definition id="2">
				<sentence>The stability criterion assesses the agreement between classi cation results on full mixed data and sampled mixed data .</sentence>
				<definiendum id="0">stability criterion</definiendum>
				<definiens id="0">assesses the agreement between classi cation results on full mixed data and sampled mixed data</definiens>
			</definition>
			<definition id="3">
				<sentence>Function : ELP ( DL , DU , k , Y 0DL+DU ) Input : labeled examples DL , unlabeled examples DU , model order k , initial labeling matrix Y 0DL+DU ; Output : the labeling matrix YDU on DU ; YDU =NULL ; Run plain label propagation algorithm on DU with YDU as output ; of new classes ; for ( kXL + 1 ) -th to k-th new classes ; on DU with augmented tagged dataset as labeled data ; propagation algorithm ; End if Let XL+U = fxigni=1 be a set of contexts of occurrences of an ambiguous word w , where xi represents the context of the i-th occurrence , and n is the total number of this word’s occurrences .</sentence>
				<definiendum id="0">Output</definiendum>
				<definiendum id="1">xi</definiendum>
				<definiendum id="2">n</definiendum>
				<definiens id="0">the labeling matrix YDU on DU</definiens>
			</definition>
			<definition id="4">
				<sentence>Let k denote the possible value of the number of senses in mixed data XL+U , and kXL be the number of senses in initial tagged data XL .</sentence>
				<definiendum id="0">kXL</definiendum>
				<definiens id="0">the possible value of the number of senses in mixed data XL+U , and</definiens>
			</definition>
			<definition id="5">
				<sentence>If the value of k is equal to kXL , then ELP is identical with the plain label propagation algorithm ( LP ) ( Zhu and Ghahramani , 2002 ) .</sentence>
				<definiendum id="0">ELP</definiendum>
				<definiens id="0">identical with the plain label propagation algorithm ( LP )</definiens>
			</definition>
			<definition id="6">
				<sentence>i ) = Wijsummationtextn k=1 Wkj , where Tij is the probability to jump from example xj to example xi .</sentence>
				<definiendum id="0">Tij</definiendum>
				<definiens id="0">the probability to jump from example xj to example xi</definiens>
			</definition>
			<definition id="7">
				<sentence>Function : CV ( XL+U , k , q , Y 0XL+U ) Input : data set XL+U , model order k , and sampling frequency q ; Output : the score of the merit of k ; algorithm with XL , XU , k and Y 0XL+U ; on above classi cation solution on XU ; uniformly drawn labels to each vector in XU ; above classi cation solution on XU ; the size αjXL+Uj from XL+U , 0 &lt; α &lt; 1 ; algorithm with XµL , XµU , k and Y 0µ ; above classi cation solution on XµU ; to each vector in XµU ; above classi cation solution on XµU ; Endfor formula : Mk = 1q summationtextµ ( M ( Cµk , Ck ) M ( Cµρk , Cρk ) ) , where M ( Cµ , C ) is given by equation ( 2 ) ; Then this model order identi cation procedure can be formulated as : ˆkX L+U = argmaxKmin≤k≤Kmax { CV ( XL+U , k , q , Y 0 XL+U ) } .</sentence>
				<definiendum id="0">CV</definiendum>
				<definiens id="0">data set XL+U , model order k</definiens>
				<definiens id="1">ˆkX L+U = argmaxKmin≤k≤Kmax { CV ( XL+U , k , q</definiens>
			</definition>
			<definition id="8">
				<sentence>( 1 ) ˆkX L+U is the estimated sense number in XL+U , Kmin ( or Kmax ) is the minimum ( or maximum ) value of sense number , and k is the possible value of sense number in XL+U .</sentence>
				<definiendum id="0">ˆkX L+U</definiendum>
				<definiendum id="1">k</definiendum>
				<definiens id="0">the estimated sense number in XL+U</definiens>
				<definiens id="1">the possible value of sense number in XL+U</definiens>
			</definition>
			<definition id="9">
				<sentence>CV is a cluster validation based evaluation function .</sentence>
				<definiendum id="0">CV</definiendum>
				<definiens id="0">a cluster validation based evaluation function</definiens>
			</definition>
			<definition id="10">
				<sentence>M ( Cµ , C ) measures the proportion of example pairs in each group computed on XU that are also assigned into the same group by the classi cation solution on XµU .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">C )</definiendum>
			</definition>
			<definition id="11">
				<sentence>The reason to normalize M ( Cµk , Ck ) is that M ( Cµk , Ck ) tends to decrease when increasing the value of k ( Lange et al. , 2002 ) .</sentence>
				<definiendum id="0">Ck )</definiendum>
			</definition>
			<definition id="12">
				<sentence>Given of cial training data of the word w , we constructed incomplete tagged data XL by removing the all the tagged instances from of cial training data that have sense tags from Ssubset , where Ssubset is a subset of the ground-truth sense set S for w , and S consists of the sense tags in of cial training set for w. The removed training data and of cial test data of w were used as XU .</sentence>
				<definiendum id="0">Ssubset</definiendum>
				<definiens id="0">a subset of the ground-truth sense set S for w , and S consists of the sense tags in of cial training set for w. The removed training data and of cial test data of w were used as XU</definiens>
			</definition>
			<definition id="13">
				<sentence>We used Jensen-Shannon ( JS ) divergence ( Lin , 1991 ) as distance measure for semi-supervised clustering and ELP , since plain LP with JS divergence achieves better performance than that with cosine similarity on SENSEVAL-3 data ( Niu et al. , 2005 ) .</sentence>
				<definiendum id="0">Jensen-Shannon</definiendum>
			</definition>
</paper>

		<paper id="0907">
			<definition id="0">
				<sentence>The Edinburgh Mouse Atlas Project ( EMAP ) 1 uses Theiler stages to organise anatomical terms in their Mouse Atlas Nomenclature ( MAN ) .</sentence>
				<definiendum id="0">Edinburgh Mouse Atlas Project</definiendum>
			</definition>
			<definition id="1">
				<sentence>TimeML ( Pustejovsky et al. , 2004 ) is a speci cation language designed for the annotation of temporal and event information .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">a speci cation language designed for the annotation of temporal and event information</definiens>
			</definition>
</paper>

		<paper id="3324">
			<definition id="0">
				<sentence>In this case , PEA determines the anchor sentence ( main crux of the purpose ) , and then whether to include a leading and trailing sentence , or two leading sentences or two trailing ones , to reach the 3-sentence limit .</sentence>
				<definiendum id="0">PEA</definiendum>
				<definiens id="0">determines the anchor sentence ( main crux of the purpose</definiens>
			</definition>
</paper>

		<paper id="1419">
</paper>

		<paper id="1105">
			<definition id="0">
				<sentence>Dimensionality reduction techniques for document and corpus modelling aim to reduce description length and model a type of semantic similarity that is more linguistic in nature ( e.g. , see Landauer et al.’s ( 1998 ) discussion of LSA and synonym tests ) .</sentence>
				<definiendum id="0">Dimensionality reduction</definiendum>
				<definiens id="0">techniques for document and corpus modelling aim to reduce description length and model a type of semantic similarity that is more linguistic in nature ( e.g. , see Landauer et al.’s ( 1998 ) discussion of LSA and synonym tests</definiens>
			</definition>
			<definition id="1">
				<sentence>And S is a diagonal matrix of singular values in decreasing order .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">a diagonal matrix of singular values in decreasing order</definiens>
			</definition>
			<definition id="2">
				<sentence>Probabilistic LSA ( pLSA ) is a generative probabilistic version of LSA ( Hofmann , 2001 ) .</sentence>
				<definiendum id="0">Probabilistic LSA</definiendum>
				<definiendum id="1">pLSA )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Latent Dirichlet Allocation ( LDA ) addresses this by representing documents as random mixtures over latent topics ( Blei et al. , 2003 ) .</sentence>
				<definiendum id="0">Latent Dirichlet Allocation ( LDA )</definiendum>
			</definition>
			<definition id="4">
				<sentence>Cosine ( Cos ) is commonly used in the literature to compute similarities between tf*idf vectors : Cos ( p , q ) = summationtext ipiqiradicalbigsummationtext p2radicalbigsummationtextq2 In the current work , we use cosine over term and SVD representations of entity pair context .</sentence>
				<definiendum id="0">Cosine</definiendum>
				<definiens id="0">use cosine over term and SVD representations of entity pair context</definiens>
			</definition>
			<definition id="5">
				<sentence>The KL divergence of two probability distributions ( p and q ) over the same event space is defined as : KL ( p||q ) = summationdisplay i pi log piq i In information-theoretic terms , KL divergence is the average number of bits wasted by encoding events from a distribution p with a code based on distribution q. The symmetric measures are defined as : Sym ( p , q ) = 12 [ KL ( p||q ) + KL ( q||p ) ] JS ( p , q ) = 12 bracketleftbigg KL parenleftbigg p||p + q2 parenrightbigg + KL parenleftbigg q||p + q2 parenrightbiggbracketrightbigg The first is termed symmetrised KL divergence ( Sym ) and the second is termed Jensen-Shannon ( JS ) divergence .</sentence>
				<definiendum id="0">KL divergence of two probability distributions</definiendum>
				<definiendum id="1">KL</definiendum>
				<definiendum id="2">KL divergence</definiendum>
				<definiendum id="3">Sym</definiendum>
				<definiens id="0">p||q ) = summationdisplay i pi log piq i In information-theoretic terms</definiens>
				<definiens id="1">the average number of bits wasted by encoding events from a distribution p with a code based on distribution q. The symmetric measures</definiens>
			</definition>
			<definition id="6">
				<sentence>For KL divergence , this function is defined as Sim ( p , q ) = 10−βKL ( p||q ) , where β is a free parameter , which is tuned on the development set ( as described in Section 4.2 ) .</sentence>
				<definiendum id="0">β</definiendum>
			</definition>
			<definition id="7">
				<sentence>I1 is a criterion function that maximises sum of pairwise similarities between relation instances assigned to each cluster , I2 is an internal criterion function that maximises the similarity between each relation instance and the centroid of the cluster it is assigned to , E1 is an external criterion function that minimises the similarity between the centroid vector of each cluster and the centroid vector of the 8http : //www.cis.upenn.edu/˜treebank/ tokenizer .</sentence>
				<definiendum id="0">I1</definiendum>
				<definiendum id="1">I2</definiendum>
				<definiendum id="2">E1</definiendum>
				<definiens id="0">a criterion function that maximises sum of pairwise similarities between relation instances assigned to each cluster</definiens>
			</definition>
			<definition id="8">
				<sentence>entire collection , and H1 is a combined criterion function that consists of the ration of I1 over E1 .</sentence>
				<definiendum id="0">H1</definiendum>
				<definiens id="0">a combined criterion function that consists of the ration of I1 over E1</definiens>
			</definition>
			<definition id="9">
				<sentence>Type-totoken ratio ( TTR ) is the number of words divided by the number of word instances and indicates how much repetition there is in word use .</sentence>
				<definiendum id="0">TTR</definiendum>
				<definiens id="0">the number of words divided by the number of word instances and indicates how much repetition there is in word use</definiens>
			</definition>
</paper>

		<paper id="1909">
			<definition id="0">
				<sentence>wh-questionl SUB underspecified-location.0 [ GENER sp ] c27na SUB vorname.1.1  GENER sp QUANT one CARD 1 ETYPE 0   VAL c sd15d15 c26d SUB mensch.1.1     FACT real GENER sp QUANT one REFER det CARD 1 ETYPE 0 VARIA con      ATTR cc d111d111 ATTRcc d79d79 c2st SUBS sitzen.1.1 TEMP present.0 [ GENER sp ] LOC s sd15d15 LOC s s d79d79 SCAR cs d111d111 hugo.0fe c32d PRED gitter.1.1  FACT real QUANT mult REFER indet ETYPE 1   c36l  FACT real QUANT mult REFER indet ETYPE 1  *HINTER csd111d111 corresponding word plus a numerical homograph identifier and a numerical reading identifier .</sentence>
				<definiendum id="0">LOC</definiendum>
				<definiens id="0">s sd15d15 LOC s s d79d79 SCAR cs d111d111 hugo.0fe c32d PRED gitter.1.1  FACT real QUANT</definiens>
			</definition>
			<definition id="1">
				<sentence>The generation of a preselection query described above indicates that there is a fundamental level mismatch between the first level ( web search engine ) and the second level ( an NL understanding system like the QA system InSicht ) : words EACL 2006 Workshop on Multilingual Question Answering MLQA06 63 ( plus proximity information3 ) vs. concepts within ( possibly normalized ) semantic representations of sentences ( or texts ) .</sentence>
				<definiendum id="0">level</definiendum>
				<definiendum id="1">second level</definiendum>
			</definition>
			<definition id="2">
				<sentence>Thepercentagesfornon-emptyanswers differ for right answers and wrong answers .</sentence>
				<definiendum id="0">Thepercentagesfornon-emptyanswers</definiendum>
			</definition>
</paper>

		<paper id="0112">
			<definition id="0">
				<sentence>Fang Xu Chengqing Zong Jun Zhao National Laboratory of Pattern Recognition Institute of Automation Chinese Academy of Sciences , Beijing 100080 , China { fxu , cqzong , jzhao } @ nlpr.ia.ac.cn In this paper , we propose a hybrid approach to chunking Chinese base noun phrases ( base NPs ) , which combines SVM ( Support Vector Machine ) model and CRF ( Conditional Random Field ) model .</sentence>
				<definiendum id="0">CRF ( Conditional Random Field</definiendum>
				<definiens id="0">combines SVM ( Support Vector Machine ) model</definiens>
			</definition>
			<definition id="1">
				<sentence>The definition of base noun phrase ( base NP ) is simple and non-recursive noun phrase which does not contain other noun phrase descendants .</sentence>
				<definiendum id="0">base noun phrase</definiendum>
				<definiendum id="1">base NP</definiendum>
				<definiens id="0">simple and non-recursive noun phrase which does not contain other noun phrase descendants</definiens>
			</definition>
			<definition id="2">
				<sentence>SVM is a machine learning algorithm for a linear binary classifier in order to maximize the margin of confidence of the classification on the training data set .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">a machine learning algorithm for a linear binary classifier in order to maximize the margin of confidence of the classification on the training data set</definiens>
			</definition>
			<definition id="3">
				<sentence>CRF SVM Testing data Comparison Error pruning with rules and P ( Y|X ) Final result Figure 1 the Experiments’ Procedure Using the comparison between SVM and CRF we can check most of those errors .</sentence>
				<definiendum id="0">CRF SVM</definiendum>
				<definiens id="0">Testing data Comparison Error pruning with rules</definiens>
			</definition>
</paper>

		<paper id="1507">
			<definition id="0">
				<sentence>In Palestinian Arabic ( PA ) , negative concord occurs with the determiner wEla “ ( not ) even one , ” where negative concord describes the failure of an expression which expresses negation in some sentences to do so in others .</sentence>
				<definiendum id="0">Palestinian Arabic</definiendum>
				<definiendum id="1">negative concord</definiendum>
				<definiens id="0">describes the failure of an expression which expresses negation in some sentences to do so in others</definiens>
			</definition>
			<definition id="1">
				<sentence>The unary modalities in CTL can be duplicated in CCG as features on category labels , so to approximate Hepple’s proposal , I define a feature hierarchy as follows : ( 51 ) h g c Each pair of sisters in the hierarchy consists of a “penetrative feature” and the “bounding feature” which blocks it ( following Hepple’s terminology ) .</sentence>
				<definiendum id="0">unary modalities</definiendum>
				<definiendum id="1">CCG</definiendum>
			</definition>
			<definition id="2">
				<sentence>A wide-scope derivation ( in which the wEla-phrase combines with the composition of the 54 matrix and embedded verbs ) is blocked by a feature clash between the g and c features ( Figure 4 ) .</sentence>
				<definiendum id="0">wide-scope derivation</definiendum>
				<definiens id="0">the composition of the 54 matrix and embedded verbs</definiens>
			</definition>
</paper>

		<paper id="3114">
			<definition id="0">
				<sentence>The BLEU metric , as all currently proposed automatic metrics , is occasionally suspected to be biased towards statistical systems , especially the phrase-based systems currently in use .</sentence>
				<definiendum id="0">BLEU metric</definiendum>
				<definiens id="0">all currently proposed automatic metrics , is occasionally suspected to be biased towards statistical systems , especially the phrase-based systems currently in use</definiens>
			</definition>
			<definition id="1">
				<sentence>Because of this , we retokenized and lowercased submitted output with our own tokenizer , which was also used to prepare the training and test data .</sentence>
				<definiendum id="0">own tokenizer</definiendum>
			</definition>
			<definition id="2">
				<sentence>Confidence Interval : Since BLEU scores are not computed on the sentence level , traditional methods to compute statistical significance and confidence intervals do not apply .</sentence>
				<definiendum id="0">Confidence Interval</definiendum>
				<definiens id="0">Since BLEU scores are not computed on the sentence level , traditional methods to compute statistical significance and confidence intervals do not apply</definiens>
			</definition>
			<definition id="3">
				<sentence>Since different judges judged different systems ( recall that judges were excluded to judge system output from their own institution ) , we normalized the scores .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">that judges were excluded to judge system output from their own institution )</definiens>
			</definition>
			<definition id="4">
				<sentence>Confidence Interval : To estimate confidence intervals for the average mean scores for the systems , we use standard significance testing .</sentence>
				<definiendum id="0">Confidence Interval</definiendum>
				<definiens id="0">To estimate confidence intervals for the average mean scores for the systems</definiens>
			</definition>
</paper>

		<paper id="1619">
			<definition id="0">
				<sentence>Supertagging is a process where words in an input sentence are tagged with ‘supertags , ’ which are lexical entries in lexicalized grammars , e.g. , elementary trees in LTAG , lexical categories in CCG , and lexical entries in HPSG .</sentence>
				<definiendum id="0">Supertagging</definiendum>
				<definiens id="0">a process where words in an input sentence are tagged with ‘supertags , ’ which are lexical entries in lexicalized grammars , e.g. , elementary trees in LTAG , lexical categories in CCG , and lexical entries in HPSG</definiens>
			</definition>
			<definition id="1">
				<sentence>HPSG ( Pollard and Sag , 1994 ) is a syntactic theory based on lexicalized grammar formalism .</sentence>
				<definiendum id="0">HPSG</definiendum>
				<definiens id="0">a syntactic theory based on lexicalized grammar formalism</definiens>
			</definition>
			<definition id="2">
				<sentence>Given a set W of words and a set F of feature structures , an HPSG is formulated as a tuple , G = 〈L , R〉 , where L = { l = 〈w , F〉|w ∈W , F ∈F } is a set of lexical entries , and R is a set of schemata ; i.e. , r ∈ R is a partial function : F ×F →F. Given a sentence , an HPSG computes a set of phrasal signs , i.e. , feature structures , as a result of parsing .</sentence>
				<definiendum id="0">HPSG</definiendum>
				<definiendum id="1">R</definiendum>
				<definiendum id="2">i.e.</definiendum>
				<definiendum id="3">HPSG</definiendum>
				<definiens id="0">a set of lexical entries , and</definiens>
				<definiens id="1">a set of schemata ;</definiens>
				<definiens id="2">computes a set of phrasal signs , i.e. , feature structures</definiens>
			</definition>
			<definition id="3">
				<sentence>Note that HPSG is one of the lexicalized grammar formalisms , in which lexical entries determine the dominant syntactic structures .</sentence>
				<definiendum id="0">HPSG</definiendum>
				<definiens id="0">one of the lexicalized grammar formalisms , in which lexical entries determine the dominant syntactic structures</definiens>
			</definition>
			<definition id="4">
				<sentence>Previous studies ( Abney , 1997 ; Johnson et al. , 1999 ; Riezler et al. , 2000 ; Malouf and van Noord , 2004 ; Kaplan et al. , 2004 ; Miyao and Tsujii , 2005 ) defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model ( Berger et al. , 1996 ) .</sentence>
				<definiendum id="0">Previous studies</definiendum>
			</definition>
			<definition id="5">
				<sentence>The probability that a parse result T is assigned to a given sentence w = 〈w1 , ... , wn〉 is phpsg ( T|w ) = 1Z w exp parenleftBiggsummationdisplay u λufu ( T ) parenrightBigg Zw = summationdisplay Tprime exp parenleftBiggsummationdisplay u λufu ( Tprime ) parenrightBigg , where λu is a model parameter , fu is a feature function that represents a characteristic of parse tree T , and Zw is the sum over the set of all possible parse trees for the sentence .</sentence>
				<definiendum id="0">λu</definiendum>
				<definiendum id="1">Zw</definiendum>
				<definiens id="0">assigned to a given sentence w = 〈w1 , ...</definiens>
				<definiens id="1">a feature function that represents a characteristic of parse tree T , and</definiens>
			</definition>
			<definition id="6">
				<sentence>We have ( Previous probabilistic HPSG ) phpsgprime ( T|w ) = p0 ( T|w ) 1Z w exp parenleftBiggsummationdisplay u λufu ( T ) parenrightBigg Zw = summationdisplay Tprime p0 ( Tprime|w ) exp parenleftBiggsummationdisplay u λufu ( Tprime ) parenrightBigg p0 ( T|w ) = nproductdisplay i=1 p ( li|wi ) , where li is a lexical entry assigned to word wi in T and p ( li|wi ) is the probability of selecting lexical entry li for wi .</sentence>
				<definiendum id="0">p0</definiendum>
				<definiendum id="1">li</definiendum>
				<definiens id="0">Previous probabilistic HPSG ) phpsgprime ( T|w ) =</definiens>
				<definiens id="1">the probability of selecting lexical entry li for wi</definiens>
			</definition>
			<definition id="7">
				<sentence>The feature templates fbinary and funary are defined for constituents at binary and unary branches , froot is a feature template set for the root nodes of parse trees , and flex is a feature template set for calculating the preliminary probabilistic model .</sentence>
				<definiendum id="0">froot</definiendum>
				<definiendum id="1">flex</definiendum>
				<definiens id="0">a feature template set for the root nodes of parse trees , and</definiens>
				<definiens id="1">a feature template set for calculating the preliminary probabilistic model</definiens>
			</definition>
			<definition id="8">
				<sentence>Given a set of lexical entries , L , a sentence , w = 〈w1 , ... , wn〉 , and the probabilistic model of lexical entry selection , p ( li ∈ L|w , i ) , the first model is formally defined as follows : ( Model 1 ) pmodel1 ( T|w ) = nproductdisplay i=1 p ( li|w , i ) , where li is a lexical entry assigned to word wi in T and p ( li|w , i ) is the probability of selecting lexical entry li for wi .</sentence>
				<definiendum id="0">lexical entries , L</definiendum>
				<definiendum id="1">p</definiendum>
				<definiendum id="2">li</definiendum>
				<definiens id="0">a lexical entry assigned to word wi in T and p</definiens>
			</definition>
			<definition id="9">
				<sentence>That is , the second model is also defined without the probabilities on phrase structures : ( Model 2 ) pmodel2 ( T|w ) = 1 Zmodel2pmodel1 ( T|w ) exp   summationdisplay u ( fu∈froot ) λufu ( T )   Zmodel2 = summationdisplay Tprime pmodel1 ( Tprime|w ) exp   summationdisplay u ( fu∈froot ) λufu ( Tprime )   , where Zmodel2 is the sum over the set of all possible parse trees for the sentence .</sentence>
				<definiendum id="0">Zmodel2</definiendum>
				<definiens id="0">the sum over the set of all possible parse trees for the sentence</definiens>
			</definition>
			<definition id="10">
				<sentence>The probabilities of lexical entry selection , p ( li|w , i ) , are defined as follows : ( Probabilistic Model of Lexical Entry Selection ) p ( li|w , i ) = 1Z w exp parenleftBiggsummationdisplay u λufu ( li , w , i ) parenrightBigg 158 fexlex = angbracketleftbigg wi−1 , wi , wi+1 , pi−2 , pi−1 , pi , pi+1 , pi+2 angbracketrightbigg combinations of feature templates 〈wi−1〉 , 〈wi〉 , 〈wi+1〉 , 〈pi−2〉 , 〈pi−1〉 , 〈pi〉 , 〈pi+1〉 , 〈pi+2〉 , 〈pi+3〉 , 〈wi−1 , wi〉 , 〈wi , wi+1〉 , 〈pi−1 , wi〉 , 〈pi , wi〉 , 〈pi+1 , wi〉 , 〈pi , pi+1 , pi+2 , pi+3〉 , 〈pi−2 , pi−1 , pi〉 , 〈pi−1 , pi , pi+1〉 , 〈pi , pi+1 , pi+2〉 〈pi−2 , pi−1〉 , 〈pi−1 , pi〉 , 〈pi , pi+1〉 , 〈pi+1 , pi+2〉 Table 2 : Features for the probabilities of lexical entry selection .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">Entry Selection ) p</definiendum>
				<definiens id="0">follows : ( Probabilistic Model of Lexical</definiens>
				<definiens id="1">158 fexlex = angbracketleftbigg wi−1 , wi , wi+1 , pi−2 , pi−1 , pi , pi+1 , pi+2 angbracketrightbigg combinations of feature templates 〈wi−1〉 , 〈wi〉 , 〈wi+1〉 , 〈pi−2〉 , 〈pi−1〉 , 〈pi〉 , 〈pi+1〉 , 〈pi+2〉 , 〈pi+3〉 , 〈wi−1 , wi〉 , 〈wi , wi+1〉 , 〈pi−1 , wi〉 , 〈pi , wi〉 , 〈pi+1 , wi〉 , 〈pi , pi+1 , pi+2 , pi+3〉 , 〈pi−2 , pi−1 , pi〉 , 〈pi−1 , pi , pi+1〉 , 〈pi , pi+1 , pi+2〉 〈pi−2 , pi−1〉 , 〈pi−1 , pi〉 , 〈pi , pi+1〉 , 〈pi+1</definiens>
			</definition>
			<definition id="11">
				<sentence>Zw = summationdisplay lprime exp parenleftBiggsummationdisplay u λufu ( lprime , w , i ) parenrightBigg , where Zw is the sum over all possible lexical entries for the word wi .</sentence>
				<definiendum id="0">Zw</definiendum>
				<definiens id="0">the sum over all possible lexical entries for the word wi</definiens>
			</definition>
			<definition id="12">
				<sentence>In the figure , the pi [ i , j ] represents the set of partial parse results that cover words wi+1 , ... , wj , and ρ [ i , j , F ] stores the maximum figure-of-merit ( FOM ) of partial parse result F at cell ( i , j ) .</sentence>
				<definiendum id="0">FOM</definiendum>
				<definiens id="0">the set of partial parse results that cover words wi+1 , ... , wj</definiens>
			</definition>
			<definition id="13">
				<sentence>A predicate-argument relation is defined as a tuple 〈σ , wh , a , wa〉 , where σ is the predicate type ( e.g. , adjective , intransitive verb ) , wh is the head word of the predicate , a is the argument label ( MODARG , ARG1 , ... , ARG4 ) , and wa is the head word of the argument .</sentence>
				<definiendum id="0">predicate-argument relation</definiendum>
				<definiendum id="1">σ</definiendum>
				<definiendum id="2">MODARG , ARG1 , ... , ARG4</definiendum>
				<definiendum id="3">wa</definiendum>
				<definiens id="0">a tuple 〈σ , wh , a , wa〉 , where</definiens>
				<definiens id="1">the predicate type ( e.g. , adjective , intransitive verb ) , wh is the head word of the predicate</definiens>
			</definition>
			<definition id="14">
				<sentence>Labeled precision ( LP ) /labeled recall ( LR ) is the ratio of tuples correctly identified by the parser3 .</sentence>
				<definiendum id="0">Labeled precision</definiendum>
				<definiendum id="1">LP ) /labeled recall</definiendum>
				<definiendum id="2">LR )</definiendum>
				<definiens id="0">the ratio of tuples correctly identified by the parser3</definiens>
			</definition>
			<definition id="15">
				<sentence>Unlabeled precision ( UP ) /unlabeled recall ( UR ) is the ratio of tuples without the predicate type and the argument label .</sentence>
				<definiendum id="0">Unlabeled precision</definiendum>
				<definiens id="0">the ratio of tuples without the predicate type and the argument label</definiens>
			</definition>
			<definition id="16">
				<sentence>When compared with other supertag sets of automatically extracted lexicalized grammars , the ( effective ) size of our supertag set , 1,361 lexical entries , is between the CCG supertag set ( 398 categories ) used by Curran and Clark ( 2003 ) and the LTAG supertag set ( 2920 elementary trees ) used by Shen and Joshi ( 2003 ) .</sentence>
				<definiendum id="0">the ( effective</definiendum>
			</definition>
</paper>

		<paper id="3801">
			<definition id="0">
				<sentence>Name disambiguation is a particular application of the suggested general framework , which is also applicable to any real-world setting in which structural data is available as well as text .</sentence>
				<definiendum id="0">Name disambiguation</definiendum>
				<definiens id="0">a particular application of the suggested general framework</definiens>
			</definition>
			<definition id="1">
				<sentence>A graph G consists of a set of nodes , and a set of labeled directed edges .</sentence>
				<definiendum id="0">graph G</definiendum>
			</definition>
			<definition id="2">
				<sentence>and probability 0 to all other nodes , then the value given to y in Vk can be interpreted as a similarity measure between x and y. In our framework , a query is an initial distribution Vq over nodes , plus a desired output type Tout , and the answer is a list of nodes y of type Tout , ranked by their score in the distribution Vk .</sentence>
				<definiendum id="0">query</definiendum>
				<definiens id="0">the value given to y in Vk can be interpreted as a similarity measure between x</definiens>
			</definition>
			<definition id="3">
				<sentence>The ranking function for node x is defined as : F ( x , ¯α ) = α0L ( x ) + msummationdisplay k=1 αkfk ( x ) where L ( x ) = log ( p ( x ) ) and ¯α is a vector of realvalue parameters .</sentence>
				<definiendum id="0">ranking function for node x</definiendum>
				<definiens id="0">F ( x , ¯α ) = α0L ( x ) + msummationdisplay k=1 αkfk ( x ) where L ( x ) = log ( p ( x ) ) and ¯α is a vector of realvalue parameters</definiens>
			</definition>
</paper>

		<paper id="2407">
			<definition id="0">
				<sentence>Although the exact definition of a LVC varies in the literature , we use the following operational definition : A light verb construction ( LVC ) is a verb-complement pair in which the verb has little lexical meaning ( is “light” ) and much of the semantic content of the construction is obtained from the complement .</sentence>
				<definiendum id="0">LVC</definiendum>
				<definiens id="0">a verb-complement pair in which the verb has little lexical meaning ( is “light” ) and much of the semantic content of the construction</definiens>
			</definition>
			<definition id="1">
				<sentence>Let f ( v , n ) be the count of verb-object pairs occurring in the corpus , such that v is the verb , n is a deverbal noun .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the count of verb-object pairs occurring in the corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>They focused on expressions of the form v-a-n and v-det-n , where v is a light verb , n is a deverbal noun , a is an indefinite determiner ( namely , “a” or “an” ) , and det is any determiner other than the indefinite .</sentence>
				<definiendum id="0">v</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">det</definiendum>
				<definiens id="0">an indefinite determiner ( namely , “a” or “an” ) , and</definiens>
			</definition>
			<definition id="3">
				<sentence>The probability that a verb-object pair v-n ( where v is a light verb ) is a LVC can be expressed as a product of three probabilities : ( 1 ) probability of the object 50 n occurring in the corpus , ( 2 ) the probability that n is part of any LVC given n , and ( 3 ) the probability of v occurring given n and that v-n is a LVC .</sentence>
				<definiendum id="0">v</definiendum>
				<definiendum id="1">probability</definiendum>
			</definition>
			<definition id="4">
				<sentence>The SFN04 metric adds in the context provided by determiners to augment LVC detection .</sentence>
				<definiendum id="0">SFN04 metric</definiendum>
				<definiens id="0">adds in the context provided by determiners to augment LVC detection</definiens>
			</definition>
			<definition id="5">
				<sentence>Formally , the mutual information between a verb v and a deverbal noun n is defined as I ( v , n ) = log2 P ( v , n ) P ( v ) P ( n ) , ( 8 ) where P ( v , n ) denotes the probability of v and n constructing verb-object pairs .</sentence>
				<definiendum id="0">deverbal noun n</definiendum>
				<definiendum id="1">n )</definiendum>
				<definiens id="0">I ( v , n ) = log2 P ( v , n ) P ( v ) P ( n ) , ( 8 ) where P ( v</definiens>
			</definition>
			<definition id="6">
				<sentence>P ( v ) is the probability of occurrence of v and P ( n ) represents the probability of occurrence of n. Let f ( v , n ) be the frequency of occurrence of the verb-object pair v-n and N be the number of all verb-object pairs in the corpus .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the probability of occurrence of v and P ( n ) represents the probability of occurrence of n. Let f</definiens>
				<definiens id="1">the number of all verb-object pairs in the corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>The annotator is then asked whether the presented verb-object pair is a LVC given the context of the sentence , and he or she will choose from the following options : ( 1 ) Yes , 1Binning is the process of grouping measured data into data classes or histogram bins .</sentence>
				<definiendum id="0">1Binning</definiendum>
				<definiens id="0">the context of the sentence , and he or she will choose from the following options : ( 1 ) Yes</definiens>
			</definition>
			<definition id="8">
				<sentence>The evaluation criteria used is the F1-measure on the LV C class , which is defined as F1 = 2PRP + R , ( 11 ) where P and R are the precision and recall for the LV C class respectively .</sentence>
				<definiendum id="0">LV C class</definiendum>
				<definiens id="0">F1 = 2PRP + R , ( 11 ) where P and R are the precision and recall for the LV C class respectively</definiens>
			</definition>
			<definition id="9">
				<sentence>Multiword expressions ( MWEs ) are a major obstacle that hinder precise natural language processing ( Sag et al. , 2002 ) .</sentence>
				<definiendum id="0">Multiword expressions ( MWEs )</definiendum>
			</definition>
</paper>

		<paper id="0111">
			<definition id="0">
				<sentence>BA-construction ( ‘ ’ ) is a special syntactic structure in the Chinese language .</sentence>
				<definiendum id="0">BA-construction ( ‘ ’ )</definiendum>
				<definiens id="0">a special syntactic structure in the Chinese language</definiens>
			</definition>
			<definition id="1">
				<sentence>However , recent research tends to classify the BA-construction to the category of the prepositional phrase ( PP ) , which characterizes the pre-posed object ( usually a noun phrase – NP ) of a transitive verb ( Zhou and PU , 1985 ) .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiendum id="1">NP</definiendum>
				<definiens id="0">characterizes the pre-posed object ( usually a noun phrase –</definiens>
			</definition>
			<definition id="2">
				<sentence>For instance , most monosyllable verbs can be duplicated as independent “AA” or “A A” structures in Chinese , for example “ ( see , look ) ” as “ ” or “ ” “ ( read ) ” as “ ” or “ ” ; “ ( eat ) ”as “ ” or “ ” ; and “ ( go or walk ) ” as “ ” or “ ” ; but never “ ” as “* ” or “* ” ( some transitive verbs can be used this way without objects , but the duplicated “ ” or “ ” as a verb must have its object following it , e.g. “ ( make checks ; to guard a pass , etc. ) ” or “ ” ) .</sentence>
				<definiendum id="0">“* ”</definiendum>
				<definiens id="0">see , look ) ” as “ ” or “ ” “ ( read ) ” as “ ” or “ ” ; “ ( eat ) ”as “ ” or “ ” ; and “ ( go or walk ) ” as “ ” or “ ” ; but never “ ” as “* ” or</definiens>
			</definition>
			<definition id="3">
				<sentence>Furthermore the verb following the BA-construction is a transitive verb which in fact subcategorizes for ( or still governs ) the pre-posed logical object ( the complement of the preposition BA ) and the main verb is usually accompanied by other auxiliary constituents following or immediately preceding it .</sentence>
				<definiendum id="0">BA-construction</definiendum>
				<definiens id="0">a transitive verb which in fact subcategorizes for ( or still governs ) the pre-posed logical object</definiens>
			</definition>
			<definition id="4">
				<sentence>c ) ( Subj + BAstructure + auxiliary constituent + V + LE ) ( literal translation : I BA letter carefully read LE ) I have carefully read the letter .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiens id="0">auxiliary constituent + V + LE ) ( literal translation : I BA letter carefully read LE ) I have carefully read the letter</definiens>
			</definition>
			<definition id="5">
				<sentence>Concerning our own view , we adopt the idea that the BA is a preposition with which the patient object is shifted to the front of the main verb and the BA structure functions as an adjunct of the verb like many other adjuncts that are often placed between the subject and the predicate verb ( HU , 1991 ) .</sentence>
				<definiendum id="0">BA</definiendum>
				<definiens id="0">a preposition with which the patient object is shifted to the front of the main verb and the BA structure functions as an adjunct of the verb like many other adjuncts that are often placed between the subject and the predicate verb</definiens>
			</definition>
			<definition id="6">
				<sentence>However , if the transitive verb ( e.g. “vortex” ) is used intransitively as is often the case in our corpus , the BA-construction has to be changed to the normal sentence structure ( V + ( X ) + PP ) , for example : 17 ) Vortex gently for a few seconds .</sentence>
				<definiendum id="0">BA-construction</definiendum>
				<definiens id="0">has to be changed to the normal sentence structure ( V + ( X ) + PP</definiens>
			</definition>
			<definition id="7">
				<sentence>While the machine is searching the information concerning this sentence , two major supported sources of information ( lexicon and grammar rules ) will help it find the correct structure for transferring the sentence into the correct TL correspondence .</sentence>
				<definiendum id="0">grammar rules</definiendum>
				<definiens id="0">searching the information concerning this sentence , two major supported sources of information ( lexicon and</definiens>
			</definition>
</paper>

		<paper id="2401">
</paper>

		<paper id="0904">
			<definition id="0">
				<sentence>Qualitative relations ( e.g. , event A BEFORE event B , or event A DURING time T ) are certainly of interest in developing timelines of events in news and other genres .</sentence>
				<definiendum id="0">Qualitative relations</definiendum>
				<definiens id="0">event A BEFORE event B , or event A DURING time T ) are certainly of interest in developing timelines of events in news and other genres</definiens>
			</definition>
			<definition id="1">
				<sentence>TimeML ( Pustejovsky et al. 2005 ) ( www.timeml.org ) is an annotation scheme for markup of events , times , and their qualitative temporal relations in news articles .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">an annotation scheme for markup of events , times , and their qualitative temporal relations in news articles</definiens>
			</definition>
			<definition id="2">
				<sentence>TimeML uses 14 temporal relations in the TLINK relTypes .</sentence>
				<definiendum id="0">TimeML</definiendum>
			</definition>
			<definition id="3">
				<sentence>In order to have a nonhierarchical classification , SIMULTANEOUS and IDENTITY are collapsed , since IDENTITY is a subtype of SIMULTANEOUS .</sentence>
				<definiendum id="0">IDENTITY</definiendum>
				<definiens id="0">a subtype of SIMULTANEOUS</definiens>
			</definition>
			<definition id="4">
				<sentence>Formally , each TLINK is a constraint of the general form x R y , where x and y are intervals , and R is a disjunct ∨ i=1 , .</sentence>
				<definiendum id="0">TLINK</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a constraint of the general form x R y , where x and y are intervals , and</definiens>
				<definiens id="1">a disjunct ∨ i=1 ,</definiens>
			</definition>
			<definition id="5">
				<sentence>In our example , where x is fall and y is the announce , we are given the qualitative relationship that x is BEFORE Y , so the metric constraint ( x2-y1 ) &lt; 0 can be asserted .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">given the qualitative relationship that x is BEFORE Y , so the metric constraint ( x2-y1 ) &lt; 0 can be asserted</definiens>
			</definition>
			<definition id="6">
				<sentence>The algorithm runs in O ( n 3 ) time , where n is the number of intervals .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of intervals</definiens>
			</definition>
</paper>

		<paper id="0608">
			<definition id="0">
				<sentence>In this paper we discuss the ( lexical ) semantic annotation for the Hinoki Corpus , which is part of a larger project in psycho-linguistic and computational linguistics ultimately aimed at language understanding ( Bond et al. , 2004 ) .</sentence>
				<definiendum id="0">lexical</definiendum>
			</definition>
			<definition id="1">
				<sentence>Lexeed consists of all words with a familiarity greater than or equal to five .</sentence>
				<definiendum id="0">Lexeed</definiendum>
				<definiens id="0">consists of all words with a familiarity greater than or equal to five</definiens>
			</definition>
			<definition id="2">
				<sentence>The ontology includes more than 50 thousand relationship between word senses , e.g. synonym , hypernym , abbreviation , etc .</sentence>
				<definiendum id="0">ontology</definiendum>
			</definition>
			<definition id="3">
				<sentence>c multiword expressions ( compound / idiom ) : the target word is a part of a non-compositional compound or idiom .</sentence>
				<definiendum id="0">c multiword expressions</definiendum>
				<definiens id="0">a part of a non-compositional compound or idiom</definiens>
			</definition>
			<definition id="4">
				<sentence>To answer these questions , and to provide feedback for the annotators , twice a day we calculated and graphed the speed ( in words/day ) and majority agreement ( how often an annotator agrees with the majority of annotators for each token , measured over all words annotated so far ) .</sentence>
				<definiendum id="0">majority agreement</definiendum>
				<definiens id="0">how often an annotator agrees with the majority of annotators for each token , measured over all words annotated so far )</definiens>
			</definition>
			<definition id="5">
				<sentence>These results show 67 Corpus Annotated Tokens # WS Agreement token ( type ) % Unanimous token ( type ) Kappa LXD-DEF 199,268 5.18 .787 ( .850 ) 62.8 ( 41.1 ) 0.58 LXD-EX 126,966 5.00 .820 ( .871 ) 69.1 ( 53.2 ) 0.65 Senseval2 223,983 4.07 .832 ( .833 ) 73.9 ( 45.8 ) 0.52 Kyoto 268,597 3.93 .833 ( .828 ) 71.5 ( 46.1 ) 0.50 Table 4 : Basic Annotation Statistics Corpus % Other Sense % MWE % Homonym % Proper Noun % Error % Multiple Tags LXD-DEF 4.2 1.5 0.084 0.046 0.92 11.9 LXD-EX 2.3 0.44 0.035 0.0018 0.43 11.6 Senseval2 9.3 5.6 4.1 8.7 5.7 7.9 Kyoto 9.8 7.9 3.3 9.0 5.5 9.3 Table 10 : Special Tags and Multiple Tags Fam Agreement token ( type ) # WS % Monosem ALL .829 ( .869 ) 4.72 39.1 Lumping together Hypernyms ( 4,380 senses compressed into 1,900 senses ) Fam Agreement token ( type ) # WS % Monosem ALL .835 ( .891 ) 4.48 41.7 Lumping together Semantic Classes ( 8,691 senses compressed into 4,030 senses ) Table 8 : Sense Lumping Results ( LXD-DEF ) ( LXD-DEF ) Agreement token ( type ) # WS % Monosem no lumping .698 ( .816 ) 8.81 0.0 lumping .811 ( .910 ) 8.24 20.0 Hypernum Lumping ( LXD-DEF ) Agreement token ( type ) # WS % Monosem no lumping .751 ( .814 ) 7.09 0.0 lumping .840 ( .925 ) 5.99 21.9 Semantic Class Lumping Table 9 : Lumped Sense Agreement ( LXD-DEF ) the differences in corpus characteristics between dictionary and newspaper .</sentence>
				<definiendum id="0">Lumped Sense Agreement</definiendum>
				<definiens id="0">senses compressed into 1,900 senses ) Fam Agreement token</definiens>
			</definition>
			<definition id="6">
				<sentence>The word segmentation is the problem of how to determine an unit expressing a meaning .</sentence>
				<definiendum id="0">word segmentation</definiendum>
				<definiens id="0">the problem of how to determine an unit expressing a meaning</definiens>
			</definition>
</paper>

		<paper id="2935">
			<definition id="0">
				<sentence>For development , we chose the initial a0 sentences of every treebank , where a0 is the number of the sentences in the test set .</sentence>
				<definiendum id="0">a0</definiendum>
				<definiens id="0">the number of the sentences in the test set</definiens>
			</definition>
			<definition id="1">
				<sentence>BitPar is a CKY parser that uses bit vectors for efficient representation of the chart and its items .</sentence>
				<definiendum id="0">BitPar</definiendum>
			</definition>
</paper>

		<paper id="2710">
			<definition id="0">
				<sentence>The NITE XML Toolkit ( NXT ) is open source software for working with multimodal , spoken , or text language corpora .</sentence>
				<definiendum id="0">NITE XML Toolkit ( NXT</definiendum>
				<definiens id="0">open source software for working with multimodal , spoken , or text language corpora</definiens>
			</definition>
			<definition id="1">
				<sentence>NXT is open source software , available from Sourceforge and documented at http : //www.ltg.ed.ac.uk/NITE .</sentence>
				<definiendum id="0">NXT</definiendum>
			</definition>
			<definition id="2">
				<sentence>At its core , NXT consists of three libraries : one for data handling , one for searching data , and one for building GUIs for working with data .</sentence>
				<definiendum id="0">NXT</definiendum>
			</definition>
			<definition id="3">
				<sentence>Finally , contributing projects plan work that will improve interoperability between NXT and other tools , including eyetrackers , NLP applications such as part-of-speech taggers , and machine learning software .</sentence>
				<definiendum id="0">NLP</definiendum>
				<definiens id="0">applications such as part-of-speech taggers , and machine learning software</definiens>
			</definition>
</paper>

		<paper id="0301">
			<definition id="0">
				<sentence>In news articles , opinion topics can be social issues , government’s acts , new events , or someone’s opinions .</sentence>
				<definiendum id="0">government’s</definiendum>
			</definition>
			<definition id="1">
				<sentence>Subjectivity detection is the task of identifying subjective words , expressions , and sentences ( Wiebe et al. , 1999 ; Hatzivassiloglou and Wiebe , 2000 ; Riloff et al. , 2003 ) .</sentence>
				<definiendum id="0">Subjectivity detection</definiendum>
			</definition>
			<definition id="2">
				<sentence>Sentiment detection is the task of determining positive or negative sentiment of words ( Hatzivassiloglou and McKeown , 1997 ; Turney , 2002 ; Esuli and Sebastiani , 2005 ) , phrases and sentences ( Kim and Hovy , 2004 ; Wilson et al. , 2005 ) , or documents ( Pang et al. , 2002 ; Turney , 2002 ) .</sentence>
				<definiendum id="0">Sentiment detection</definiendum>
				<definiens id="0">the task of determining positive or negative sentiment of words</definiens>
			</definition>
			<definition id="3">
				<sentence>Phase 1 : Collect Opinion Words In this study , we consider an opinion-bearing ( positive/negative ) word is a key indicator of an opinion .</sentence>
				<definiendum id="0">opinion-bearing</definiendum>
				<definiens id="0">a key indicator of an opinion</definiens>
			</definition>
			<definition id="4">
				<sentence>We used FrameNet II ( Baker et al. , 2003 ) which contains 450 semantic frames and more than 3000 frame elements ( FE ) .</sentence>
				<definiendum id="0">FrameNet II</definiendum>
				<definiens id="0">Baker et al. , 2003 ) which contains 450 semantic frames and more than 3000 frame elements ( FE )</definiens>
			</definition>
			<definition id="5">
				<sentence>A frame consists of lexical items , called Lexical Unit ( LU ) , and related frame elements .</sentence>
				<definiendum id="0">frame</definiendum>
				<definiens id="0">consists of lexical items , called Lexical Unit ( LU ) , and related frame elements</definiens>
			</definition>
			<definition id="6">
				<sentence>Precision ( P ) , Recall ( R ) , and Fscore ( F ) of Topic and Holder identification for opinion verbs ( V ) and adjectives ( A ) on Testset 1 .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">Recall ( R ) , and Fscore ( F ) of Topic and Holder identification for opinion verbs ( V ) and adjectives ( A ) on Testset 1</definiens>
			</definition>
			<definition id="7">
				<sentence>Topic Holder P ( % ) R ( % ) F ( % ) P ( % ) R ( % ) F ( % ) V 85.5 18.5 30.4 73.7 46.4 56.9 A 68.2 26.5 38.2 12.0 49.1 19.3 5 tions : “Her letter” is a stimulus and “me” is an experiencer of the verb upset .</sentence>
				<definiendum id="0">“Her letter”</definiendum>
				<definiendum id="1">“me”</definiendum>
				<definiens id="0">an experiencer of the verb upset</definiens>
			</definition>
			<definition id="8">
				<sentence>Result : Note that Testset 1 was collected from sentences of opinion-related frames in FrameNet and therefore all sentences in the set contained either opinion-bearing verb or adjective .</sentence>
				<definiendum id="0">Result</definiendum>
				<definiens id="0">collected from sentences of opinion-related frames in FrameNet and therefore all sentences in the set contained either opinion-bearing verb or adjective</definiens>
			</definition>
</paper>

		<paper id="1405">
			<definition id="0">
				<sentence>We describe CRAG , which generates dialogues between pairs of agents , who are linguistically distinguishable , but able to align .</sentence>
				<definiendum id="0">CRAG</definiendum>
				<definiens id="0">generates dialogues between pairs of agents</definiens>
			</definition>
			<definition id="1">
				<sentence>Language models are trained on a corpus and subsequently used to compute probability scores of word sequences .</sentence>
				<definiendum id="0">Language models</definiendum>
				<definiens id="0">a corpus and subsequently used to compute probability scores of word sequences</definiens>
			</definition>
			<definition id="2">
				<sentence>An n-gram language model approximates the probability of a word given its history of the preceding n−1 words .</sentence>
				<definiendum id="0">n-gram language model</definiendum>
				<definiens id="0">approximates the probability of a word given its history of the preceding n−1 words</definiens>
			</definition>
			<definition id="3">
				<sentence>Equation ( 1 ) shows a trigram model that takes into account two words of context to predict the probability of a word sequence wn1 : ( 1 ) P ( wn1 ) ≈ n∏ i=1 P ( wi|wi−1i−2 ) 26 Because word probabilities are always less than 1 and therefore each multiplication decreases the total , if we use this standard model , longer sentences will always receive lower scores ( this is known as the length effect ) .</sentence>
				<definiendum id="0">Equation ( 1 )</definiendum>
			</definition>
			<definition id="4">
				<sentence>We therefore calculate the probability of a sentence as the geometric mean of the probability of each word in the sentence as shown in ( 2 ) : ( 2 ) P ( wn1 ) ≈ n∏ i=1 P ( wi|wi−1i−2 ) 1/n OPENCCG supports the linear combination of language models , where each model is assigned a weight .</sentence>
				<definiendum id="0">OPENCCG</definiendum>
				<definiens id="0">the probability of a sentence as the geometric mean of the probability of each word in the</definiens>
				<definiens id="1">supports the linear combination of language models</definiens>
			</definition>
			<definition id="5">
				<sentence>Also , each character receives an agenda of topics they wish to discuss , along with polarities ( positive/negative ) that indicate their opinion on the respective topic .</sentence>
				<definiendum id="0">character</definiendum>
				<definiens id="0">receives an agenda of topics they wish to discuss , along with polarities ( positive/negative ) that indicate their opinion on the respective topic</definiens>
			</definition>
			<definition id="6">
				<sentence>In the first ( Figure 4 ) neither character aligns with the other at all , while in the second ( Figure 5 ) Stan has a slight tendency towards alignment and in the third ( Figure 6 ) a more pronounced tendency .</sentence>
				<definiendum id="0">Stan</definiendum>
				<definiens id="0">a slight tendency towards alignment and in the third ( Figure 6 ) a more pronounced tendency</definiens>
			</definition>
</paper>

		<paper id="1641">
			<definition id="0">
				<sentence>A statement DB CX is a string of 346 wordsDB CXBD BMBMBMDB CXD2 CX , drawn from a common vocabulary CE .</sentence>
				<definiendum id="0">statement DB CX</definiendum>
				<definiens id="0">a string of 346 wordsDB CXBD BMBMBMDB CXD2 CX , drawn from a common vocabulary CE</definiens>
			</definition>
			<definition id="1">
				<sentence>For our purposes , CQ CXCY is either provided by a human annotator ( manual annotation ) , or determined heuristically ( automatic annotation ) .</sentence>
				<definiendum id="0">CQ CXCY</definiendum>
				<definiens id="0">either provided by a human annotator ( manual annotation ) , or determined heuristically ( automatic annotation )</definiens>
			</definition>
			<definition id="2">
				<sentence>Each of these observations corresponds to a unique point D4 D8CX BND4 D7CX BND4 DCCX in the space of paired distributions C1C8A2C1C8A2C1C8 DC , defined by the following coordinates : D4 D8CX B4DAB5 BP AL D8 AZB4DABNDB D8 CX B5BPAZB4DB D8 CX B5 B7 B4BDA0AL D8 B5CR D8DA D4 D7CX B4DAB5 BP AL D7 AZB4DABNDB D7 CX B5BPAZB4DB D7 CX B5 B7 B4BDA0AL D7 B5CR D7DA D4 DCCX B4DCB5 BP AL DC BD DCBPDC CX B7 B4BDA0AL DC B5BM ( 2 ) Here , AZB4DABNDB D8 CX B5 represents the number of times the word DA was observed in the topic part of statement CX , the length of which is denoted by AZB4DB D8 CX B5 .</sentence>
				<definiendum id="0">AL D7 AZB4DABNDB D7 CX B5BPAZB4DB D7 CX B5 B7 B4BDA0AL D7 B5CR D7DA D4 DCCX B4DCB5 BP AL DC BD DCBPDC CX B7 B4BDA0AL DC B5BM</definiendum>
				<definiendum id="1">AZB4DABNDB D8 CX B5</definiendum>
				<definiens id="0">a unique point D4 D8CX BND4 D7CX BND4 DCCX in the space of paired distributions C1C8A2C1C8A2C1C8 DC , defined by the following coordinates : D4 D8CX B4DAB5 BP AL D8 AZB4DABNDB D8 CX B5BPAZB4DB D8 CX B5 B7 B4BDA0AL D8 B5CR D8DA D4 D7CX B4DAB5 BP</definiens>
			</definition>
			<definition id="3">
				<sentence>The Boolean indicator function BD DD returns one when the predicate DD is true and zero otherwise .</sentence>
				<definiendum id="0">Boolean indicator function BD DD</definiendum>
				<definiens id="0">true and zero otherwise</definiens>
			</definition>
			<definition id="4">
				<sentence>Our model represents each statement DB CX as a bag of words , or more formally an order-invariant sequence .</sentence>
				<definiendum id="0">statement DB CX</definiendum>
				<definiens id="0">a bag of words , or more formally an order-invariant sequence</definiens>
			</definition>
			<definition id="5">
				<sentence>We assume that our query D5 D7 BND5 D8 BND5 DC is a random sample from a distribution defined by equation ( 1 ) , and then for each word DA we estimate the likelihood that DA would be observed if we sampled one more topic or sentiment word : CA D8 B4DAB5BP C8B4D5 D7 BND5 D8 ÆDABND5 DC B5 C8B4D5 D7 BND5 D8 BND5 DC B5 BN CA D7 B4DAB5BP C8B4D5 D7 ÆDABND5 D8 BND5 DC B5 C8B4D5 D7 BND5 D8 BND5 DC B5 BM ( 4 ) Both the numerator and denominator are computed according to equation ( 1 ) , with the mass function APB4B5 given by equations ( 3 ) and ( 2 ) .</sentence>
				<definiendum id="0">query D5 D7 BND5 D8 BND5 DC</definiendum>
				<definiens id="0">a random sample from a distribution defined by equation ( 1 ) , and then for each word DA we estimate the likelihood that DA would be observed if we sampled one more topic or sentiment word : CA D8 B4DAB5BP C8B4D5 D7 BND5 D8 ÆDABND5 DC B5 C8B4D5 D7 BND5 D8 BND5 DC B5 BN CA D7 B4DAB5BP C8B4D5 D7 ÆDABND5 D8 BND5 DC B5 C8B4D5 D7 BND5 D8 BND5 DC B5 BM ( 4 ) Both the numerator and denominator are computed according to equation ( 1 ) , with the mass function APB4B5 given by equations ( 3 ) and ( 2 )</definiens>
			</definition>
			<definition id="6">
				<sentence>Output : a ranked list of topic-relevant and sentiment-relevant sentences from the test data .</sentence>
				<definiendum id="0">Output</definiendum>
			</definition>
</paper>

		<paper id="0607">
			<definition id="0">
				<sentence>Positive Arguing : arguing for something , arguing that something is true or is so , arguing that something did happen or will happen , etc. ( 6 ) ZDN : Yeah definitely moon roof In ( 6 ) , the speaker is arguing that whatever car they get should have a moon roof .</sentence>
				<definiendum id="0">Positive Arguing</definiendum>
				<definiens id="0">arguing for something , arguing that something is true or is so , arguing that something did happen or will happen</definiens>
			</definition>
			<definition id="1">
				<sentence>Positive Arguing : expressing support for or backing the acceptance of an object , viewpoint , idea or stance by providing reasoning , justifications , judgment , evaluations or beliefs .</sentence>
				<definiendum id="0">Positive Arguing</definiendum>
				<definiens id="0">expressing support for or backing the acceptance of an object , viewpoint , idea or stance by providing reasoning , justifications , judgment , evaluations or beliefs</definiens>
			</definition>
			<definition id="2">
				<sentence>The SWBD DAMSL ( Jurafsky et al. , 1997 ) annotation scheme over the Switchboard telephonic conversation corpus labels shallow discourse structures .</sentence>
				<definiendum id="0">SWBD DAMSL</definiendum>
				<definiens id="0">Jurafsky et al. , 1997 ) annotation scheme over the Switchboard telephonic conversation corpus labels shallow discourse structures</definiens>
			</definition>
			<definition id="3">
				<sentence>The ICSI MRDA annotation scheme ( Rajdip et al. , 2003 ) adopts the SWBD DAMSL scheme , but does not distinguish between the opinionated and objective statements .</sentence>
				<definiendum id="0">ICSI MRDA annotation scheme</definiendum>
				<definiens id="0">adopts the SWBD DAMSL scheme , but does not distinguish between the opinionated and objective statements</definiens>
			</definition>
			<definition id="4">
				<sentence>The ISL meeting corpus ( Burger and Sloane , 2004 ) is annotated with dialog acts and discourse moves like initiation and response , which in turn consist of dialog tags such as query , align , and statement .</sentence>
				<definiendum id="0">ISL meeting corpus</definiendum>
				<definiens id="0">annotated with dialog acts and discourse moves like initiation and response , which in turn consist of dialog tags such as query , align , and statement</definiens>
			</definition>
</paper>

		<paper id="3804">
			<definition id="0">
				<sentence>We used the following measure of similarity of the rankings : sim ( Rx , Rm ) =1− rx , i−rm , i i ∑ floor n 2 2 *100 where n is the number of items in the 2 rankings and r x , i and r m , i denote the position of the ith item in R x and R m. respectively .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of items in the 2 rankings</definiens>
			</definition>
			<definition id="1">
				<sentence>The work is inspired by link analysis algorithms such as HITS , which uses theories of spectral partitioning of a graph for detecting authoritative pages in a graph of hyperlinked pages ( Kleinberg 1998 ) .</sentence>
				<definiendum id="0">HITS</definiendum>
				<definiens id="0">uses theories of spectral partitioning of a graph for detecting authoritative pages in a graph of hyperlinked pages</definiens>
			</definition>
</paper>

		<paper id="0140">
			<definition id="0">
				<sentence>CRFs define the conditional probability of a state sequence given an input sequence as ⎟ ⎠ ⎞ ⎜ ⎝ ⎛ = ∑∑ == −Α T t K k ttkk o tossf Z osP 11 1 ) , , , ( exp 1 ) | ( λ Where ) , , , ( 1 tossf ttk − is an arbitrary feature function over its arguments , and λ k is a learned weight for each feature function .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiendum id="1">λ k</definiendum>
				<definiens id="0">an arbitrary feature function over its arguments , and</definiens>
				<definiens id="1">a learned weight for each feature function</definiens>
			</definition>
			<definition id="1">
				<sentence>The basic segmentation is a process of labeling each hanzi with a tag given the features derived from its surrounding context .</sentence>
				<definiendum id="0">basic segmentation</definiendum>
				<definiens id="0">a process of labeling each hanzi with a tag given the features derived from its surrounding context</definiens>
			</definition>
			<definition id="2">
				<sentence>Atomic feature patterns for ORG names Atomic pattern Meaning of pattern CurWord Current word LocationName Check if current word is a location name PersonName Check if current word is a person name KnownORG Check if current word is a known organization name ORGFeature ScanFeatureWord_8 Check if current word is a feature word of ORG name Check if there exist a feature word among eight words behind the current word LeftBoundary1_-2 LeftBoundary2_-2 Check if there exist a first-class or second-class left boundary word among two words before the current word RightBoundary1_+2 RightBoundary2_+2 Check if there exist a first-class or second-class right boundary word among two words behind the current word There exists some single-word named entities that aren’t tagged by CRFs models .</sentence>
				<definiendum id="0">Atomic feature patterns</definiendum>
			</definition>
</paper>

		<paper id="2409">
			<definition id="0">
				<sentence>The Papillon project ( S´erasset and MangeotLerebours , 2001 ) proposes a general architecture for the interlingual linking of monolingual dictionaries ; as it is inspired by the DiCo formalizarion , it foresees links between readings , e.g. to account for morphological relations .</sentence>
				<definiendum id="0">Papillon project</definiendum>
				<definiens id="0">proposes a general architecture for the interlingual linking of monolingual dictionaries</definiens>
			</definition>
			<definition id="1">
				<sentence>OWL DL is the description logic sublanguage of the OWL Web Ontology Language ( Bech2Cf .</sentence>
				<definiendum id="0">OWL DL</definiendum>
			</definition>
			<definition id="2">
				<sentence>An OWL DL data model consists of a subsumption hierarchy of classes , i.e. a class X subsumes all its subclasses X1 to Xn .</sentence>
				<definiendum id="0">OWL DL data model</definiendum>
				<definiens id="0">consists of a subsumption hierarchy of classes</definiens>
			</definition>
			<definition id="3">
				<sentence>It was designed using the Prot´eg´e OWL Plugin ( Knublauch et al. , 2004 ) and makes use of the advantages of OWL DL mentioned above .</sentence>
				<definiendum id="0">Prot´eg´e OWL Plugin</definiendum>
				<definiens id="0">Knublauch et al. , 2004 ) and makes use of the advantages of OWL DL mentioned above</definiens>
			</definition>
			<definition id="4">
				<sentence>For instance , isSynonymOf has been defined as a symmetric and transitive property ( as opposed to the non-transitive isQuasiSynonymOf ; see section 2 ) , while hasCompound has been defined as the inverse of a property isCompoundOf .</sentence>
				<definiendum id="0">isSynonymOf</definiendum>
				<definiens id="0">a symmetric and transitive property</definiens>
			</definition>
			<definition id="5">
				<sentence>The bilingual dictionary model is an instantiation of the translation model .</sentence>
				<definiendum id="0">bilingual dictionary model</definiendum>
				<definiens id="0">an instantiation of the translation model</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus , in an English-German dictionary , for instance , a relation calledhasTranslationmay be defined as a symmetric property linking lexical entities of the English monolingual dictionary model ( i.e. its domain is defined for instances with the english : prefix ) to lexical entities of the German model ( i.e. instances with german : ) .</sentence>
				<definiendum id="0">relation calledhasTranslationmay</definiendum>
				<definiendum id="1">German model</definiendum>
				<definiens id="0">a symmetric property linking lexical entities of the English monolingual dictionary model</definiens>
			</definition>
</paper>

		<paper id="1629">
			<definition id="0">
				<sentence>The second task is back-transliteration ( Fujii and Ishikawa , 2001 ; Jeong et al. , 1999 ; Knight and Graehl , 1998 ; Qu et al. , 2003 ) , which identifies the source word corresponding to an existing transliterated word .</sentence>
				<definiendum id="0">back-transliteration</definiendum>
				<definiens id="0">identifies the source word corresponding to an existing transliterated word</definiens>
			</definition>
			<definition id="1">
				<sentence>The language model , P ( K ) , models the probability of K irrespective of R and W. In probabilistic natural language processing , P ( K ) is usually realized by a word or character N-gram model , and therefore a K that appears frequently in a corpus is assigned a high probability .</sentence>
				<definiendum id="0">P ( K</definiendum>
				<definiendum id="1">P ( K</definiendum>
				<definiens id="0">the probability of K irrespective of R and W. In probabilistic natural language processing</definiens>
				<definiens id="1">usually realized by a word or character N-gram model</definiens>
			</definition>
			<definition id="2">
				<sentence>P ( R|K ) ≈ P ( R|Y ) ·P ( Y|K ) ≈ Nproductdisplay i=1 P ( ri|yi ) · Nproductdisplay j=1 P ( yj|kj ) ( 2 ) Y denotes the Pinyin strings representing the pronunciation of K. ki denotes a single Kanji character .</sentence>
				<definiendum id="0">P ( R|K ) ≈ P ( R|Y ) ·P</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">the Pinyin strings representing the pronunciation of K. ki denotes a single Kanji character</definiens>
			</definition>
			<definition id="3">
				<sentence>P ( ri|yi ) = F ( ri , yi ) summationdisplay r F ( r , yi ) P ( yi|ki ) = F ( yi , ki ) summationdisplay y F ( y , ki ) ( 3 ) F ( x , y ) denotes the co-occurrence frequency of x and y. We need the co-occurrence frequencies of ri and yi and the co-occurrence frequencies of yi and ki in order to calculate P ( R|K ) .</sentence>
				<definiendum id="0">summationdisplay y F</definiendum>
				<definiendum id="1">y )</definiendum>
			</definition>
</paper>

		<paper id="0901">
			<definition id="0">
				<sentence>Events , like entities , are distinguished from their mentions in text .</sentence>
				<definiendum id="0">Events</definiendum>
				<definiens id="0">distinguished from their mentions in text</definiens>
			</definition>
			<definition id="1">
				<sentence>An event mention is a span of text ( an extent , usually a sentence ) with a distinguished anchor ( the word that “most clearly expresses [ an event’s ] occurrence” ( LDC , 2005 ) ) and zero or more arguments , which are entity mentions , timexes , or values in the extent .</sentence>
				<definiendum id="0">event mention</definiendum>
				<definiens id="0">a span of text ( an extent , usually a sentence ) with a distinguished anchor ( the word that “most clearly expresses [ an event’s ] occurrence” ( LDC , 2005 ) ) and zero or more arguments , which are entity mentions , timexes , or values in the extent</definiens>
			</definition>
			<definition id="2">
				<sentence>• Lexical features : full word , lowercase word , lemmatized word , POS tag , depth of word in parse tree • WordNet features : for each WordNet POS category c ( from N , V , ADJ , ADV ) : – If the word is in catgory c and there is a corresponding WordNet entry , the ID of the synset of first sense is a feature value – Otherwise , if the word has an entry in WordNet that is morphologically related to a synset of category c , the ID of the related synset is a feature value • Left context ( 3 words ) : lowercase , POS tag • Right context ( 3 words ) : lowercase , POS tag • Dependency features : if the candidate word is the dependent in a dependency relation , the label of the relation is a feature value , as are the dependency head word , its POS tag , and its entity type • Related entity features : for each entity/timex/value type t : – Number of dependents of candidate word of type t – Label ( s ) of dependency relation ( s ) to dependent ( s ) of type t – Constituent head word ( s ) of dependent ( s ) of type t – Number of entity mentions of type t reachable by some dependency path ( i.e. , in same sentence ) – Length of path to closest entity mention of type t In table 1 , we present the results of our anchor classification experiments ( precision , recall and Fmeasure ) .</sentence>
				<definiendum id="0">synset</definiendum>
				<definiens id="0">full word , lowercase word , lemmatized word , POS tag , depth of word in parse tree</definiens>
				<definiens id="1">a feature value • Left context ( 3 words ) : lowercase , POS tag • Right context ( 3 words ) : lowercase</definiens>
				<definiens id="2">a feature value , as are the dependency head word</definiens>
				<definiens id="3">dependents of candidate word of type t – Label ( s ) of dependency relation ( s ) to dependent ( s ) of type t – Constituent head word ( s ) of dependent ( s ) of type t – Number of entity mentions of type t reachable by some dependency path</definiens>
			</definition>
			<definition id="3">
				<sentence>This may be related to the binarization of the dependency-path features for maximum entropy training : the word and POS tag sequences ( but not the label sequences ) are broken down into their component steps , so that there is a separate binary feature corresponding to the presence of a given word or POS tag in the dependency path .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">the presence of a given word or POS tag in the dependency path</definiens>
			</definition>
</paper>

		<paper id="2938">
			<definition id="0">
				<sentence>A decision list is an ordered list of rules where each rule consists of a pattern and a classi cation ( Rivest , 1987 ) .</sentence>
				<definiendum id="0">decision list</definiendum>
			</definition>
			<definition id="1">
				<sentence>To describe each training instance , I used the attributes of the two candidate words , their surface neighbors ( i.e. the words they are adjacent to in the actual sentence ) , and their syntactic neighbors ( i.e. the words they have linked with so far ) .</sentence>
				<definiendum id="0">surface neighbors</definiendum>
				<definiens id="0">adjacent to in the actual sentence ) , and their syntactic neighbors ( i.e. the words they have linked with so far )</definiens>
			</definition>
</paper>

		<paper id="3303">
			<definition id="0">
				<sentence>The GO is a controlled vocabulary of biological terms developed and maintained by biologists .</sentence>
				<definiendum id="0">GO</definiendum>
				<definiens id="0">a controlled vocabulary of biological terms developed and maintained by biologists</definiens>
			</definition>
			<definition id="1">
				<sentence>The authors use the Open Directory Project ( ODP ) as a source of world knowledge to help alleviate problems of polysemy and synonymy .</sentence>
				<definiendum id="0">Open Directory Project ( ODP</definiendum>
				<definiens id="0">a source of world knowledge to help alleviate problems of polysemy and synonymy</definiens>
			</definition>
			<definition id="2">
				<sentence>The ODP is a hierarchy of concepts where each concept node has links to related web pages .</sentence>
				<definiendum id="0">ODP</definiendum>
				<definiens id="0">a hierarchy of concepts where each concept node has links to related web pages</definiens>
			</definition>
			<definition id="3">
				<sentence>Our length constraint reduces the chances of including mislabeled training instances in our data .</sentence>
				<definiendum id="0">length constraint</definiendum>
			</definition>
			<definition id="4">
				<sentence>TFIDF is defined as : TFIDF ( wi ) = f ( wi ) ∗log ( nD ( w i ) ) where f ( wi ) is the number of times word wi appears in documents associated with a protein , n is the total number of training documents and D ( wi ) is the number of documents in the whole training set that contain the word wi .</sentence>
				<definiendum id="0">TFIDF</definiendum>
				<definiendum id="1">f ( wi )</definiendum>
				<definiendum id="2">n</definiendum>
				<definiendum id="3">wi )</definiendum>
				<definiens id="0">the number of times word wi appears in documents associated with a protein</definiens>
				<definiens id="1">the total number of training documents</definiens>
				<definiens id="2">the number of documents in the whole training set that contain the word wi</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , “thermoregulation” is a type of “homeostasis” , which is a “physiological process” .</sentence>
				<definiendum id="0">“thermoregulation”</definiendum>
				<definiens id="0">a “physiological process”</definiens>
			</definition>
			<definition id="6">
				<sentence>Term generalization gives the SVM algorithm the opportunity to learn correlations that exist between general terms and subcellular localization even if the general term never appears in an abstract and we encounter only its more specific children .</sentence>
				<definiendum id="0">Term generalization</definiendum>
				<definiens id="0">gives the SVM algorithm the opportunity to learn correlations that exist between general terms and subcellular localization even if the general term never appears in an abstract</definiens>
			</definition>
</paper>

		<paper id="3309">
			<definition id="0">
				<sentence>Our experiments involved MEDLINE , the bibliographicaldatabaseofbiomedicalarticlesmaintained by the U.S. National Library of Medicine ( NLM ) .</sentence>
				<definiendum id="0">MEDLINE</definiendum>
			</definition>
			<definition id="1">
				<sentence>Following Ruch et al. ( 2003 ) and Barzilay and Lee ( 2004 ) , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .</sentence>
				<definiendum id="0">Hidden Markov Models</definiendum>
			</definition>
			<definition id="2">
				<sentence>Venables and Ripley ( 1994 ) describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matricesoftheclasses , andusingSingularValueDecomposition ( SVD ) to compute the eigenvectors of the new space .</sentence>
				<definiendum id="0">andusingSingularValueDecomposition ( SVD</definiendum>
				<definiens id="0">describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matricesoftheclasses</definiens>
			</definition>
			<definition id="3">
				<sentence>Second , using continuous distributions allows ustoleverageavarietyoftools ( e.g. , LDA ) thathave been shown to be successful in other fields , such as speech recognition ( Evermann et al. , 2004 ) .</sentence>
				<definiendum id="0">LDA )</definiendum>
			</definition>
</paper>

		<paper id="1660">
			<definition id="0">
				<sentence>Named entity recognition ( NER ) is an important task in many natural language processing applications , such as information extraction and machine translation .</sentence>
				<definiendum id="0">NER</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the RRM method , the above conditional probability model has the following parametric form : P ( ti = c|xi , ti−l , ... , ti−1 ) = T ( wTc xi + bc ) , where T ( y ) = min ( 1 , max ( 0 , y ) ) is the truncation of y into the interval [ 0 , 1 ] .</sentence>
				<definiendum id="0">) )</definiendum>
				<definiens id="0">P ( ti = c|xi , ti−l , ... , ti−1 ) = T ( wTc xi + bc ) , where T ( y ) = min ( 1 , max ( 0 , y</definiens>
			</definition>
			<definition id="2">
				<sentence>The function f is defined as : f ( p , y ) =    −2py py &lt; 1 1 2 ( py − 1 ) 2 py ∈ [ −1,1 ] 0 py &gt; 1 Given the above conditional probability model , the best possible sequence of ti’s can be estimated by dynamic programming in the decoding stage ( Zhang et al. , 2002 ) .</sentence>
				<definiendum id="0">function f</definiendum>
			</definition>
			<definition id="3">
				<sentence>This Chinese NER system uses Chinese characters ( not Chinese words ) as the basic token units , and then maps word-based features that are associated with each word into corresponding features of those characters that are contained in the word .</sentence>
				<definiendum id="0">Chinese characters</definiendum>
				<definiens id="0">the basic token units , and then maps word-based features that are associated with each word into corresponding features of those characters that are contained in the word</definiens>
			</definition>
			<definition id="4">
				<sentence>NE density is defined as ”the count of NE instances in one thousand Chinese characters” .</sentence>
				<definiendum id="0">NE density</definiendum>
				<definiens id="0">”the count of NE instances in one thousand Chinese characters”</definiens>
			</definition>
			<definition id="5">
				<sentence>The confidence score of the whole sample sentence is defined as the average of the confidence scores of all the annotations contained in the sentence .</sentence>
				<definiendum id="0">confidence score</definiendum>
				<definiens id="0">the average of the confidence scores of all the annotations contained in the sentence</definiens>
			</definition>
</paper>

		<paper id="0801">
			<definition id="0">
				<sentence>Indonesian is the official language in Indonesia .</sentence>
				<definiendum id="0">Indonesian</definiendum>
				<definiens id="0">the official language in Indonesia</definiens>
			</definition>
			<definition id="1">
				<sentence>Unlike other languages used in Indonesia such as Javanese , Sundanese and Balinese that use their own scripts , Indonesian uses the familiar Roman script .</sentence>
				<definiendum id="0">Indonesian</definiendum>
				<definiens id="0">uses the familiar Roman script</definiens>
			</definition>
			<definition id="2">
				<sentence>Affixes used in the Indonesian language include [ Kosasih 2003 ] me ( n ) - , ber- , di- , ter- , pe ( n ) - , per- , se- , ke- , -el- , -em- , -er- , -kan , -i , -nya , -an , me ( n ) kan , di-kan , memper-i , diper-i , ke-an , pe ( n ) -an , per-an , ber-an , ber-kan , se-nya .</sentence>
				<definiendum id="0">Affixes</definiendum>
			</definition>
			<definition id="3">
				<sentence>Translation System Indonesian-Japanese query translation is a component of the Indonesian-Japanese CLIR .</sentence>
				<definiendum id="0">Translation System Indonesian-Japanese query translation</definiendum>
			</definition>
			<definition id="4">
				<sentence>The keyword translation process consists of native ( Indonesian ) word translation and borrowed word translation .</sentence>
				<definiendum id="0">keyword translation process</definiendum>
			</definition>
			<definition id="5">
				<sentence>We measure our query translation performance by the IR score achieved by a CLIR system because CLIR is a real application and includes the performance of key word expansion .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">a real application and includes the performance of key word expansion</definiens>
			</definition>
			<definition id="6">
				<sentence>The Indonesian queries ( 47 queries ) are manually translated from English queries .</sentence>
				<definiendum id="0">Indonesian queries</definiendum>
			</definition>
			<definition id="7">
				<sentence>The labels used in Figure 5 are : • jp ( monolingual translation ) , where “jp” denotes Japanese query • iej ( transitive translation using bilingual dictionary ) , where “i” , “e” , “j” denote Indonesian , English and Japanese , respectively , • iej-mx ( transitive machine translation using Kataku and Excite engines ) , where “m” denotes machine translation , • iej-mb ( transitive machine translation using Kataku and Babelfish engines ) , • ijn ( direct translation using the built in Indonesian-Japanese dictionary ) , • ij ( direct translation using Indonesian-Japanese dictionary ) , • ij-iej ( combination of direct ( ij ) and transitive ( iej ) translation using bilingual dictionary ) .</sentence>
				<definiendum id="0">iej-mb</definiendum>
				<definiens id="0">transitive translation using bilingual dictionary )</definiens>
				<definiens id="1">direct translation using the built in Indonesian-Japanese dictionary ) , • ij ( direct translation using Indonesian-Japanese dictionary ) , • ij-iej ( combination of direct ( ij ) and transitive ( iej ) translation using bilingual dictionary )</definiens>
			</definition>
			<definition id="8">
				<sentence>• I-n ( n = 3,5,10 ) : combination of the n-best query candidates based on mutual information score ; example : iej-3 ( disjuncture of the 3-best mutual information score candidates ) .</sentence>
				<definiendum id="0">I-n</definiendum>
				<definiens id="0">combination of the n-best query candidates based on mutual information score</definiens>
			</definition>
</paper>

		<paper id="3325">
			<definition id="0">
				<sentence>In the recent past , NER has received much attention , which yielded a variety of methods .</sentence>
				<definiendum id="0">much attention</definiendum>
				<definiens id="0">yielded a variety of methods</definiens>
			</definition>
			<definition id="1">
				<sentence>List-based NER techniques ( Palmer 1997 ) make use of lists to determine whether a word is a NE of the category sought .</sentence>
				<definiendum id="0">List-based NER techniques</definiendum>
				<definiens id="0">make use of lists to determine whether a word is a NE of the category sought</definiens>
			</definition>
			<definition id="2">
				<sentence>Instead of a large amount of labeled training data , Bootstrapping uses some labeled examples ( “seeds” ) and an even larger amount of unlabeled data for the training .</sentence>
				<definiendum id="0">Bootstrapping</definiendum>
				<definiens id="0">uses some labeled examples ( “seeds” )</definiens>
			</definition>
			<definition id="3">
				<sentence>To quantify this effort as well , there are two further measures : U ( P ) : = positives not classified ( uncertain ) U ( N ) : = negatives not classified ( uncertain ) Given this , Coverage C is defined as the fraction of all classifications that are not uncertain : ) N ( U ) N ( N ) N ( P ) P ( U ) P ( N ) P ( P ) N ( N ) N ( P ) P ( N ) P ( P : C +++++ +++ = To obtain a single measure for overall classification quality , we multiply f-Measure and coverage and define Quality Q as CfMeasure : Q ×= for Taxonomic Name Extraction In earlier work ( Sautter 2006 ) , we have presented a technique to classify words as parts of taxonomic names or as common English , respectively .</sentence>
				<definiendum id="0">Coverage C</definiendum>
				<definiens id="0">U ( P ) : = positives not classified ( uncertain ) U ( N ) : = negatives not classified ( uncertain ) Given this ,</definiens>
				<definiens id="1">the fraction of all classifications that are not uncertain : ) N ( U ) N ( N ) N ( P ) P ( U ) P ( N ) P ( P ) N ( N ) N ( P ) P ( N ) P ( P : C +++++ +++ = To obtain a single measure for overall classification quality , we multiply f-Measure and coverage and define Quality Q as CfMeasure : Q ×= for Taxonomic Name Extraction In earlier work ( Sautter 2006 ) , we have presented a technique to classify words as parts of taxonomic names or as common English , respectively</definiens>
			</definition>
			<definition id="4">
				<sentence>and TaxonGrab A word-level classifier ( WLC ) is the core component of the combining technique .</sentence>
				<definiendum id="0">TaxonGrab A word-level classifier</definiendum>
				<definiendum id="1">WLC )</definiendum>
				<definiens id="0">the core component of the combining technique</definiens>
			</definition>
</paper>

		<paper id="1634">
			<definition id="0">
				<sentence>The ENTITY1 plays key roles by activating ENTITY2 .</sentence>
				<definiendum id="0">ENTITY1</definiendum>
				<definiens id="0">plays key roles by activating ENTITY2</definiens>
			</definition>
			<definition id="1">
				<sentence>The procedure to obtain a raw pattern ( p0 , ... , pn ) is as follows : predicate ( p ) : PASs that have p as their argument argument ( p ) : PASs that p has as its arguments to one of interacting proteins , and we obtain candidates of the raw pattern as follows : 1-1 .</sentence>
				<definiendum id="0">p0 , ... , pn )</definiendum>
				<definiens id="0">predicate ( p ) : PASs that have p as their argument argument ( p ) : PASs that p has as its arguments to one of interacting proteins</definiens>
			</definition>
			<definition id="2">
				<sentence>If pi is of the word of the other interacting protein , ( p0 , ... , pi ) is a candidate of the raw pattern .</sentence>
				<definiendum id="0">p0 , ... , pi )</definiendum>
				<definiens id="0">a candidate of the raw pattern</definiens>
			</definition>
			<definition id="3">
				<sentence>Single-entity is a special MainEntity-Entity for interactions with only one participant ( e.g. “ENTITY1 dimerization” ) .</sentence>
				<definiendum id="0">Single-entity</definiendum>
			</definition>
			<definition id="4">
				<sentence>Fragmental matching is matching all fragmental patterns to PASs derived from sentences .</sentence>
				<definiendum id="0">Fragmental matching</definiendum>
				<definiens id="0">matching all fragmental patterns to PASs derived from sentences</definiens>
			</definition>
			<definition id="5">
				<sentence>1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Precision Recall ALLSCOREERK Figure 4 : Results of IE Experiment ENTITY1FGF-2/NNbind well to FGFR1 butinteract/VB with/INpoorly/RB ENTITY2KGFR/NN ARG1 ARG1 ARG2 Figure 5 : Example Demonstrating Advantages of Full Parsing Corpus To evaluate extraction patterns automatically constructed with our method , we used the AImed corpus , which consists of 225 MEDLINE ( U.S. National Library of Medicine , 2006 ) abstracts ( 1969 sentences ) annotated with protein names and protein-protein interactions , for the training/test corpora .</sentence>
				<definiendum id="0">AImed corpus</definiendum>
				<definiens id="0">consists of 225 MEDLINE ( U.S. National Library of Medicine , 2006 ) abstracts ( 1969 sentences ) annotated with protein names and protein-protein interactions , for the training/test corpora</definiens>
			</definition>
			<definition id="6">
				<sentence>And the line ERK represents results by Bunescu and Mooney ( 2006 ) .</sentence>
				<definiendum id="0">ERK</definiendum>
			</definition>
</paper>

		<paper id="3204">
</paper>

		<paper id="1103">
			<definition id="0">
				<sentence>In subjective scaling ( Voinov , 2002 ) , the subjective human judgment is considered as a convenient raw material to make comparison between empirical studies of similarity .</sentence>
				<definiendum id="0">subjective scaling</definiendum>
				<definiens id="0">a convenient raw material to make comparison between empirical studies of similarity</definiens>
			</definition>
			<definition id="1">
				<sentence>Equation 1 shows the evaluation of similarity , where ) , ( jkik xxd stands for the distance between objects ix and jx on stimulus ( dimension ) k and kw is the psychological salience of that stimulus k : ( ) ) ) , ( ( , 1 a0 = = m k jkikkji xxdwxxD .</sentence>
				<definiendum id="0">kw</definiendum>
			</definition>
			<definition id="2">
				<sentence>( 1 ) Shepard’s MDS theory assumes that a monotonic transformation should be done from a nonmetric psychological salience of a stimulus to a metric space model .</sentence>
				<definiendum id="0">1 ) Shepard’s MDS</definiendum>
				<definiens id="0">a nonmetric psychological salience of a stimulus to a metric space model</definiens>
			</definition>
			<definition id="3">
				<sentence>In his model , the measure of similarity is computed by : ) ( ) ( ) , ( BAfBAfBAS −−= βα a10 ) ( ABf −− χ ( 5 ) 10 where ) ( BAf a0 represents a function of the common features of both entities A and B , ) ( BAf − is the function of the features belonging to A but not B , ) ( ABf − is the function of the features belonging to B but not A and χβα , , are their respective weighting parameters .</sentence>
				<definiendum id="0">, ) ( ABf −</definiendum>
				<definiens id="0">the measure of similarity is computed by : ) ( ) ( ) , ( BAfBAfBAS −−= βα a10 ) ( ABf −− χ ( 5 ) 10 where ) ( BAf a0 represents a function of the common features of both entities A and B , ) ( BAf − is the function of the features belonging to A but not B</definiens>
			</definition>
			<definition id="4">
				<sentence>It follows that ) ( # YX a2 is the number of couples ( 1,1 ) and YX − denotes the sets difference ) ( ) ( cYXYX a3=− .</sentence>
				<definiendum id="0">YX −</definiendum>
			</definition>
			<definition id="5">
				<sentence>Table 3 shows the measures classified in the four categories of the mathematical model presented in section 4 : measures of cardinality ( Card ) , of distance ( Dist ) , of probability ( Prob ) and of angle ( Ang ) .</sentence>
				<definiendum id="0">Card</definiendum>
				<definiens id="0">measures of cardinality (</definiens>
			</definition>
			<definition id="6">
				<sentence>Reflexivity Is it true that the relation that it holds between an object and itself is always the same ?</sentence>
				<definiendum id="0">Reflexivity</definiendum>
				<definiens id="0">Is it true that the relation that it holds between an object</definiens>
			</definition>
</paper>

		<paper id="0307">
			<definition id="0">
				<sentence>Then the Metaphone spelling-correction algorithm ( http : //aspell.net/metaphone/ ) , which is based on pronunciation , works with the dictionary to locate the base forms of words with letter repetitions .</sentence>
				<definiendum id="0">Metaphone spelling-correction algorithm</definiendum>
				<definiendum id="1">//aspell.net/metaphone/ )</definiendum>
				<definiens id="0">works with the dictionary to locate the base forms of words with letter repetitions</definiens>
			</definition>
			<definition id="1">
				<sentence>EMMA normally responds to , on average , every Nth speech by another character in the e-drama session , where N is a changeable parameter ( currently set to 3 ) .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
			<definition id="2">
				<sentence>Each Improvisation Phase involves some preliminaries followed by ten minutes of improvisation proper .</sentence>
				<definiendum id="0">Improvisation Phase</definiendum>
				<definiens id="0">involves some preliminaries followed by ten minutes of improvisation proper</definiens>
			</definition>
</paper>

		<paper id="0129">
			<definition id="0">
				<sentence>LingPipe is a Java-based natural language processing toolkit distributed with source code by Alias-i ( 2006 ) .</sentence>
				<definiendum id="0">LingPipe</definiendum>
			</definition>
			<definition id="1">
				<sentence>LingPipe provides n-gram based character language models with a generalized form of WittenBell smoothing , which performed better than other approaches to smoothing in extensive English trials ( Carpenter 2005 ) .</sentence>
				<definiendum id="0">LingPipe</definiendum>
				<definiens id="0">provides n-gram based character language models with a generalized form of WittenBell smoothing</definiens>
			</definition>
			<definition id="2">
				<sentence>The maximum likelihood estimator for n-grams is ˆPML ( c|σ ) = count ( σc ) /extCount ( σ ) , where count ( σ ) is the number of times the sequence σ was observed in the training data and extCount ( σ ) 169 is the number of single-character extensions of σ observed : extCount ( σ ) =summationtextc count ( σc ) .</sentence>
				<definiendum id="0">maximum likelihood estimator</definiendum>
				<definiens id="0">the number of times the sequence σ was observed in the training data</definiens>
				<definiens id="1">the number of single-character extensions of σ observed : extCount ( σ ) =summationtextc count ( σc )</definiens>
			</definition>
			<definition id="3">
				<sentence>A noisy-channel model consists of a source model Ps ( µ ) defining the probability of message µ , coupled with a channel model Pc ( σ|µ ) defining the likelihood of a signal σ given a message µ .</sentence>
				<definiendum id="0">noisy-channel model</definiendum>
				<definiens id="0">consists of a source model Ps ( µ ) defining the probability of message µ , coupled with a channel model Pc ( σ|µ ) defining the likelihood of a signal σ given a message µ</definiens>
			</definition>
			<definition id="4">
				<sentence>Specifically , the tags used are B-O-T for a character not in an entity following an entity of type T , I-O for any middle character not in an entity , and E-O-T for a character not in an entity but preceding a character in an entity of type T , and finally , W-O-T for a character that is a single character between two entities , the following entity being of type T. Finally , the first tag is conditioned on the begin-ofsentence tag ( BOS ) and after the last tag , the endof-sentence tag ( EOS ) is generated .</sentence>
				<definiendum id="0">I-O</definiendum>
				<definiens id="0">an entity but preceding a character in an entity of type T , and finally , W-O-T for a character that is a single character between two entities</definiens>
			</definition>
			<definition id="5">
				<sentence>Rather than the process estimate P ( X ) , we use P ( X # | # ) , where # is a distinguished boundary character 170 Corpus Encod Sents Chars Uniq Words Uniq Test S Test Ch Unseen City U HK HKSCS ( trad ) 57K 4.3M 5113 1.6M 76K 7.5K 364K 0.046 % Microsoft gb18030 ( simp ) 46K 3.4M 4768 1.3M 63K 4.4K 173K 0.046 % Ac Sinica Big5 ( trad ) 709K 13.2M 6123 5.5M 146K 11.0K 146K 0.560 % Penn/Colo CP936 ( simp ) 19K 1.3M 4294 0.5M 37K 5.1K 256K 0.160 % Figure 1 : Word Segmentation Corpora Corpus Sents Chars Uniq LOC PER ORG Test S Test Ch Unseen City U HK 48K 2.7M 5113 48.2K 36.4K 27.8K 7.5K 364K 0.046 % Microsoft 44K 2.2M 4791 36.9K 17.6K 20.6K 4.4K 173K 0.046 % Figure 2 : Named Entity Recognition Corpora not in the training or test character sets .</sentence>
				<definiendum id="0">HK HKSCS</definiendum>
				<definiens id="0">a distinguished boundary character 170 Corpus Encod Sents Chars Uniq Words Uniq Test S Test Ch Unseen City U</definiens>
				<definiens id="1">Word Segmentation Corpora Corpus Sents Chars Uniq LOC PER ORG Test S Test Ch Unseen City U HK</definiens>
				<definiens id="2">Named Entity Recognition Corpora not in the training or test character sets</definiens>
			</definition>
			<definition id="6">
				<sentence>The rescoring model is a longer-distance generative model that produces alternating out/entity tags for all characters .</sentence>
				<definiendum id="0">rescoring model</definiendum>
				<definiens id="0">a longer-distance generative model that produces alternating out/entity tags for all characters</definiens>
			</definition>
			<definition id="7">
				<sentence>cEOS|cLOC ) where each estimator is a character language model , and where the cT are distinct characters not in the training/test sets that encode begin-ofsentence ( BOS ) , end-of-sentence ( EOS ) , and type ( e.g. PER , LOC , ORG ) .</sentence>
				<definiendum id="0">BOS</definiendum>
				<definiens id="0">a character language model , and where the cT are distinct characters not in the training/test sets that encode begin-ofsentence</definiens>
			</definition>
</paper>

		<paper id="0503">
			<definition id="0">
				<sentence>LEILA uses a deep analysis for natural-language sentences as well as other advanced NLP methods like anaphora resolution , and combines them with machine learning techniques for robust and high-yield information extraction .</sentence>
				<definiendum id="0">LEILA</definiendum>
				<definiens id="0">uses a deep analysis for natural-language sentences as well as other advanced NLP methods like anaphora resolution , and combines them with machine learning techniques for robust and high-yield information extraction</definiens>
			</definition>
			<definition id="1">
				<sentence>A linkage is a connected planar undirected graph , the nodes of which are the words of the sentence .</sentence>
				<definiendum id="0">linkage</definiendum>
				<definiens id="0">a connected planar undirected graph , the nodes of which are the words of the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Psychological evidence ( Rosch et al. , 1976 ) suggests that humans prefer a certain layer of concepts in the taxonomy to classify entities .</sentence>
				<definiendum id="0">Psychological evidence</definiendum>
				<definiens id="0">humans prefer a certain layer of concepts in the taxonomy to classify entities</definiens>
			</definition>
			<definition id="3">
				<sentence>TextToOnto requires an ontology as source of possible concepts .</sentence>
				<definiendum id="0">TextToOnto</definiendum>
				<definiens id="0">requires an ontology as source of possible concepts</definiens>
			</definition>
</paper>

		<paper id="1803">
			<definition id="0">
				<sentence>KM is a descriptionlogic based language which has been used to represent facts and rules in a HALO system for AP chemistry tests ( Barker et al. , 2004 ) .</sentence>
				<definiendum id="0">KM</definiendum>
			</definition>
			<definition id="1">
				<sentence>The interpretation process consists of parsing , reference resolution , dialogue act recognition and diagnosing student answers .</sentence>
				<definiendum id="0">interpretation process</definiendum>
				<definiens id="0">consists of parsing , reference resolution , dialogue act recognition and diagnosing student answers</definiens>
			</definition>
			<definition id="2">
				<sentence>interpretation techniques ( e.g. LSA ( Person et al. , 2000 ) , finite-state parsing ( Glass , 2001 ) ) in combination with shallow knowledge representations ( tutorial scripts or FSA-based knowledge construction dialogues ) , or they use deep KR &amp; R systems but with highly domain-specific parsing and semantic interpretation ( e.g. ATLAS-ANDES ( Ros´e et al. , 2001 ) , PACT ( Aleven et al. , 2002 ) ) .</sentence>
				<definiendum id="0">PACT</definiendum>
				<definiens id="0">in combination with shallow knowledge representations ( tutorial scripts or FSA-based knowledge construction dialogues ) , or they use deep KR &amp; R systems but with highly domain-specific parsing and semantic interpretation</definiens>
			</definition>
			<definition id="3">
				<sentence>The Why2-Atlas system ( VanLehn et al. , 2002 ) makes progress on combining wide coverage interpretation with deep knowledge representation by utilizing a wide-coverage syntactic grammar ( Ros´e , 2000 ) and a theorem prover to interpret student essays ( Makatchev et al. , 2004 ) .</sentence>
				<definiendum id="0">Why2-Atlas system</definiendum>
				<definiendum id="1">wide-coverage syntactic grammar</definiendum>
				<definiens id="0">VanLehn et al. , 2002 ) makes progress on combining wide coverage interpretation with deep knowledge representation by utilizing a</definiens>
			</definition>
</paper>

		<paper id="1665">
			<definition id="0">
				<sentence>in Language Models The basic IR approach based on LM ( Ponte and Croft , 1998 ) determines the score of relevance of a document D by its probability to generate the query Q. By assuming independence between query terms , we have : ∑∏ ∈∈ ∝= Qw i Qw i ii DwPDwPDQP ) | ( log ) | ( ) | ( where ) | ( DwP i denotes the probability of a word in the language model of the document D. As no ambiguity will arise , we will use D to mean both the language model of the document and the document itself ( similarly for a query model and a query Q ) .</sentence>
				<definiendum id="0">LM</definiendum>
				<definiens id="0">determines the score of relevance of a document D by its probability to generate the query Q. By assuming independence between query terms</definiens>
			</definition>
			<definition id="1">
				<sentence>Another score function is based on KLdivergence or cross entropy between the document model and the query model : ∑ ∈ = Vw ii i DwPQwPQDscore ) | ( log ) | ( ) , ( where V is the vocabulary .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the vocabulary</definiens>
			</definition>
			<definition id="2">
				<sentence>Model 2 : Context-dependent query expansion model ( CDQE ) ∑ ∑ ∈ ∈ ≈ = Qqq kjkjiR Vqq kjkjiRiR kj kj QqqPqqwP QqqPqqwPQwP , , ) | ( ) | ( ) | ( ) | ( ) | ( As ) | ( kjiR qqwP is a relation with two terms as condition , we will also call it a biterm relation .</sentence>
				<definiendum id="0">kjiR qqwP</definiendum>
				<definiens id="0">Context-dependent query expansion model ( CDQE ) ∑ ∑ ∈ ∈ ≈</definiens>
				<definiens id="1">a relation with two terms as condition</definiens>
			</definition>
			<definition id="3">
				<sentence>We use the following formula to determine this probability : ∑= lw jl ji jiR wwc wwcwwP ) , ( ) , ( ) | ( where ) , ( ji wwc is the frequency of co-occurrence of the biterm ) , ( ji ww , i.e. two terms in the same window of fixed size across the collection .</sentence>
				<definiendum id="0">ji wwc</definiendum>
				<definiens id="0">the frequency of co-occurrence of the biterm</definiens>
			</definition>
			<definition id="4">
				<sentence>This is equivalent to a uniform probability distribution , i.e. : U i QQqP || 1 ) | ( = where |Q|U is the number of unigrams in the query .</sentence>
				<definiendum id="0">|Q|U</definiendum>
				<definiens id="0">the number of unigrams in the query</definiens>
			</definition>
			<definition id="5">
				<sentence>Uniform probability This simple approach distributes the probability uniformly among all biterms in the query , i.e. : B kj QQqqP || 1 ) | ( = where BQ || is the number of biterms in Q. According to mutual information In a query , if two words are strongly associated , this also means that their association is more meaningful to the query , thus should be weighted higher .</sentence>
				<definiendum id="0">BQ ||</definiendum>
				<definiens id="0">the probability uniformly among all biterms in the query</definiens>
				<definiens id="1">the number of biterms in Q. According to mutual information</definiens>
			</definition>
			<definition id="6">
				<sentence>UM is the basic unigram model without query expansion ( i.e. we use MLE for the query model , while the document model is smoothed with Dirichlet method ) .</sentence>
				<definiendum id="0">UM</definiendum>
				<definiens id="0">the basic unigram model without query expansion</definiens>
			</definition>
			<definition id="7">
				<sentence>CIQE is the context-independent query expansion model using unigram relations ( Model 1 ) .</sentence>
				<definiendum id="0">CIQE</definiendum>
			</definition>
			<definition id="8">
				<sentence>CDQE is the context-dependent query expansion model using biterm relations ( Model 2 ) .</sentence>
				<definiendum id="0">CDQE</definiendum>
			</definition>
</paper>

		<paper id="3502">
			<definition id="0">
				<sentence>The TRIPS grammar ( Dzikovska et al. , 2005 ) is a wide-coverage uni cation grammar that has been used very successfully in several task-oriented dialogue systems .</sentence>
				<definiendum id="0">TRIPS grammar</definiendum>
				<definiens id="0">a wide-coverage uni cation grammar that has been used very successfully in several task-oriented dialogue systems</definiens>
			</definition>
			<definition id="1">
				<sentence>LCFLEX is an all-paths parser that uses left-corner prediction and ambiguity packing to make all-paths parsing tractable , and which was shown to be ef cient for long sentences with somewhat less complex uni cation augmented context-free grammars .</sentence>
				<definiendum id="0">LCFLEX</definiendum>
				<definiens id="0">an all-paths parser that uses left-corner prediction and ambiguity packing to make all-paths parsing tractable , and which was shown to be ef cient for long sentences with somewhat less complex uni cation augmented context-free grammars</definiens>
			</definition>
			<definition id="2">
				<sentence>To achieve parsing ef ciency , TRIPS uses a bestrst beam search algorithm based on the scores from a parse selection model ( Dzikovska et al. , 2005 ; Elsner et al. , 2005 ) .</sentence>
				<definiendum id="0">TRIPS</definiendum>
			</definition>
			<definition id="3">
				<sentence>The LCFLEX parser ( Ros·e and Lavie , 2001 ) is an all-paths robust left corner chart parser designed to incorporate various robustness techniques such as word skipping , exible uni cation , and constituent insertion .</sentence>
				<definiendum id="0">LCFLEX parser</definiendum>
				<definiens id="0">an all-paths robust left corner chart parser designed to incorporate various robustness techniques such as word skipping , exible uni cation , and constituent insertion</definiens>
			</definition>
</paper>

		<paper id="1302">
			<definition id="0">
				<sentence>( domain : temple ) S2 ( bad ) : Searching spots near Tamba-bashi .</sentence>
				<definiendum id="0">bad )</definiendum>
				<definiens id="0">Searching spots near Tamba-bashi</definiens>
			</definition>
</paper>

		<paper id="3510">
			<definition id="0">
				<sentence>A ( very ) BriefIntroductiontoFluidConstructionGrammar LucSteels ( 1,2 ) andJoachimdeBeule ( 1 ) ( 1 ) UniversityofBrussels ( VUBAILab ) ( 2 ) SONYComputerScienceLab-Paris steels @ arti.vub.ac.be Fluid Construction Grammar ( FCG ) is a new linguistic formalism designed to explore in how far a construction grammar approach can be used for handling open-ended grounded dialogue , i.e. dialogue between or with autonomous embodied agents about the world as experienced through their sensory-motor apparatus .</sentence>
				<definiendum id="0">1 ) UniversityofBrussels</definiendum>
				<definiendum id="1">FCG )</definiendum>
				<definiens id="0">a new linguistic formalism designed to explore in how far a construction grammar approach can be used for handling open-ended grounded dialogue , i.e. dialogue between or with autonomous embodied agents about the world as experienced through their sensory-motor apparatus</definiens>
			</definition>
			<definition id="1">
				<sentence>FCG is a tool offered to the community of researchers interested in construction grammar .</sentence>
				<definiendum id="0">FCG</definiendum>
				<definiens id="0">a tool offered to the community of researchers interested in construction grammar</definiens>
			</definition>
</paper>

		<paper id="1661">
			<definition id="0">
				<sentence>Now , let our ( positive ) training data be given as CG D4 BP CUDC BD BNBMBMBMBNDC C6 CV where each DC CX is a pair B4D7 CX BND6 CY B5 for which D6 CY BE CHB4D7 CX B5 and D6 CY is annotated in the treebank as being a correct realization of D7 CX .</sentence>
				<definiendum id="0">CG D4 BP CUDC BD BNBMBMBMBNDC C6 CV</definiendum>
				<definiendum id="1">DC CX</definiendum>
				<definiens id="0">a pair B4D7 CX BND6 CY B5 for which D6 CY BE CHB4D7 CX B5 and D6 CY is annotated in the treebank as being a correct realization of D7 CX</definiens>
			</definition>
			<definition id="1">
				<sentence>A conditional MaxEnt model of the probability of a realization D6 given the semantics D7 , is defined as D4 DB B4D6CYD7B5 BP CT BY DB B4D7BND6B5 CI DB B4D7B5 ( 3 ) where the function BY DB is simply the sum of the products of all feature values and feature weights , given by ( 4 ) BY DB B4D7BND6B5 BP CS CG CXBPBD DB CX A8 CX B4D7BND6B5 BP DB A1A8B4D7BND6B5 The normalization term CI DB is defined as ( 5 ) CI DB B4D7B5 BP CG D6 BC BECHB4D7B5 CT BY DB B4D7BND6B5 When we want to find the best realization for a given input semantics according to a model D4 DB , it is sufficient to compute the score function as in Equation ( 4 ) and then use the decision function previously given in Equation ( 2 ) above .</sentence>
				<definiendum id="0">conditional MaxEnt model of the probability of a realization D6</definiendum>
				<definiendum id="1">BECHB4D7B5 CT BY DB</definiendum>
				<definiens id="0">D4 DB B4D6CYD7B5 BP CT BY DB B4D7BND6B5 CI DB B4D7B5 ( 3 ) where the function BY DB is simply the sum of the products of all feature values and feature weights , given by ( 4 ) BY DB B4D7BND6B5 BP CS CG CXBPBD DB CX A8 CX B4D7BND6B5 BP DB A1A8B4D7BND6B5 The normalization term CI DB is defined as ( 5 ) CI DB B4D7B5 BP CG D6 BC</definiens>
			</definition>
			<definition id="2">
				<sentence>When it 518 comes to estimating1 the parameters DB , the procedure seeks to maximize the ( log of ) a penalized likelihood function as in ( 6 ) CMDB BP CPD6CVD1CPDC DB D0D3CVC4B4DBB5 A0 C8 CS CXBPBD DB BE CX BEAR BE where C4B4DBB5 is the ‘conditionalized’ likelihood of the training data CG D4 ( Johnson et al. , 1999 ) , computed as C4B4DBB5 BP C9C6 CXBPBD D4 DB B4D6 CX CYD7 CX B5 .</sentence>
				<definiendum id="0">C4B4DBB5</definiendum>
				<definiens id="0">the ‘conditionalized’ likelihood of the training data CG D4 ( Johnson et al. , 1999 ) , computed as C4B4DBB5 BP C9C6 CXBPBD D4 DB B4D6 CX CYD7 CX B5</definiens>
			</definition>
			<definition id="3">
				<sentence>However , when applied to the ‘Rondane’ test set , this in523 model error ties correct BNC LM 253 68 313 MaxEnt ( sans LM ) 222 63 349 MaxEnt ( combined ) 225 3 404 Table 7 : Exact match error counts for three models , viz .</sentence>
				<definiendum id="0">MaxEnt</definiendum>
				<definiendum id="1">MaxEnt</definiendum>
				<definiens id="0">Exact match error counts for three models , viz</definiens>
			</definition>
			<definition id="4">
				<sentence>Further contrasting the first two of these , the BNC LM yields 129 unique errors , in the sense that the structural MaxEnt makes the correct predictions on these items , contrasted to 98 unique errors in the structural MaxEnt model .</sentence>
				<definiendum id="0">BNC LM</definiendum>
				<definiens id="0">yields 129 unique errors , in the sense that the structural MaxEnt makes the correct predictions on these items , contrasted to 98 unique errors in the structural MaxEnt model</definiens>
			</definition>
</paper>

		<paper id="0902">
			<definition id="0">
				<sentence>We then leave it to the interpreter to combine the intermediate semantics of NP0 with the intermediate semantics of NP2 to produce a final semantics for NP0 : schematically , we have ( 11 ) NP0 ( VAL ) = NP0 ( T-VAL ) ∗ NP2 ( T-VAL ) where ‘∗’ is the combinatory operation that corresponds to the preposition used .</sentence>
				<definiendum id="0">‘∗’</definiendum>
				<definiendum id="1">combinatory operation</definiendum>
				<definiens id="0">the interpreter to combine the intermediate semantics of NP0 with the intermediate semantics of NP2 to produce a final semantics for NP0</definiens>
			</definition>
			<definition id="1">
				<sentence>( 15 ) &lt; TIMEX2 VAL= '' 1998-12-29 '' T-VAL= '' xxxx-xx-xx '' 15 T-REL= '' EQUAL '' &gt; my birthday , &lt; TIMEX2 VAL= '' 1998-12-29 '' T-VAL= '' xxxx-12-29 '' &gt; December twenty-ninth &lt; /TIMEX2 &gt; &lt; /TIMEX2 &gt; ( 16 ) &lt; TIMEX2 VAL= '' 196 '' T-VAL= '' 196 '' T-REL= '' EQUAL '' &gt; the 1960s , &lt; TIMEX2 VAL= '' 196 '' T-VAL= '' PXD '' &gt; the days of free love &lt; /TIMEX2 &gt; &lt; /TIMEX2 &gt; Here , the fact that the T-REL is EQUAL causes the interpreter to combine the values of the two TIMEXs , with points taking precedence over durations .</sentence>
				<definiendum id="0">EQUAL</definiendum>
				<definiens id="0">causes the interpreter to combine the values of the two TIMEXs , with points taking precedence over durations</definiens>
			</definition>
</paper>

		<paper id="1603">
			<definition id="0">
				<sentence>The rst is to identify all discrete information nuggets , or individual semantic content units , shared by the sentences .</sentence>
				<definiendum id="0">rst</definiendum>
				<definiens id="0">to identify all discrete information nuggets , or individual semantic content units , shared by the sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>A predicate argument tuple is a structured representation of a verb predicate together with its arguments .</sentence>
				<definiendum id="0">predicate argument tuple</definiendum>
			</definition>
			<definition id="2">
				<sentence>A pair of sentences is rst fed to a syntactic parser ( Charniak , 2000 ) and then passed to a semantic role labeler ( ASSERT ; ( Pradhan et al. , 2004 ) ) , to label predicate argument tuples .</sentence>
				<definiendum id="0">pair of sentences</definiendum>
				<definiens id="0">rst fed to a syntactic parser ( Charniak , 2000 ) and then passed to a semantic role labeler ( ASSERT ; ( Pradhan et al. , 2004 ) ) , to label predicate argument tuples</definiens>
			</definition>
			<definition id="3">
				<sentence>( Paired ) Tuples target : said arg0 : Authorities arg1 : a young man injured Richard Miller target : said arg0 : Authorities arg1 : Richard Miller injured a young man target : hurt arg0 : a young man arg1 : Richard Miller target : injured arg0 : a young man arg1 : Richard Miller target : injured arg0 : Richard Miller arg1 : a young man Table 1 : Similarity Detection : pairing of predicate argument tuples tuples have ) : Sim ( Ta , Tb ) = 1α X Sim ( ca , cb ) ∗ c= { target , argshared } wc==targettarget ( 1 ) where normalization factor α is the sum of the weights of constituents in C , i.e. : α = bardbl { argshared } bardbl + wtarget ( 2 ) In our current implementation we reduce targets and their arguments to their syntactic headwords .</sentence>
				<definiendum id="0">Similarity Detection</definiendum>
				<definiendum id="1">normalization factor α</definiendum>
				<definiens id="0">the sum of the weights of constituents in C , i.e. : α = bardbl { argshared } bardbl</definiens>
			</definition>
</paper>

		<paper id="1701">
			<definition id="0">
				<sentence>A medium-range corpus is one that remains within the confines of a few text types , even if the authorship of individual documents can be discerned e.g. by detailed study of word usage .</sentence>
				<definiendum id="0">medium-range corpus</definiendum>
				<definiens id="0">one that remains within the confines of a few text types</definiens>
			</definition>
			<definition id="1">
				<sentence>The LDC gigaword corpora , composed almost entirely of news ( journalistic prose ) , are from this perspec1 tive medium range .</sentence>
				<definiendum id="0">LDC gigaword corpora</definiendum>
				<definiens id="0">composed almost entirely of news ( journalistic prose</definiens>
			</definition>
</paper>

		<paper id="1114">
			<definition id="0">
				<sentence>Clearly , the rank distance gives a score zero only to letters which are in the same position in both strings , as Hamming distance does ( we recall that Hamming distance is the number of positions where two strings of the same length differ ) .</sentence>
				<definiendum id="0">rank distance</definiendum>
				<definiens id="0">the number of positions where two strings of the same length differ )</definiens>
			</definition>
			<definition id="1">
				<sentence>A ranking over U is an ordered list : τ = ( x1 &gt; x2 &gt; ... &gt; xd ) , where { x1 , ... , xd } ⊆ U , and &gt; is a strict ordering relation on { x1 , ... , xd } , ( an ordering criterion .</sentence>
				<definiendum id="0">ranking over U</definiendum>
				<definiendum id="1">&gt;</definiendum>
				<definiens id="0">an ordered list : τ = ( x1 &gt; x2 &gt; ... &gt; xd ) , where { x1 , ... , xd } ⊆ U</definiens>
			</definition>
			<definition id="2">
				<sentence>Given a multiset T of ranked lists , a median of T is a list L such that 112 d ( L , T ) = minX d ( X , T ) , where d is a metric and X is a ranked list over the universe of T. Depending on the choice of measure d , the upper problem may contain many unpleasant surprises .</sentence>
				<definiendum id="0">d</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">a metric and</definiens>
				<definiens id="1">a ranked list over the universe of T. Depending on the</definiens>
			</definition>
			<definition id="3">
				<sentence>What happens in item 1 is a consequence of a general property of rank distance which states that ∆ ( uv , u ) = ∆ ( uv , v ) , for any nonempty strings u and v. Total rank distance repairs this fact , as we can see from item 2 ; we observe that the total rank distance is more sensitive than rank distance to the differences from the first part of strings .</sentence>
				<definiendum id="0">rank distance</definiendum>
				<definiens id="0">a consequence of a general property of rank distance which states that ∆ ( uv , u ) = ∆ ( uv , v</definiens>
			</definition>
</paper>

		<paper id="3102">
			<definition id="0">
				<sentence>As Turkish is a language with complex agglutinative word structures , we experiment with morphologically segmented and disambiguated versions of the parallel texts in order to also uncover relations between morphemes and function words in one language with morphemes and functions words in the other , in addition to relations between open class content words .</sentence>
				<definiendum id="0">Turkish</definiendum>
				<definiens id="0">a language with complex agglutinative word structures</definiens>
			</definition>
			<definition id="1">
				<sentence>Statistical machine translation views the translation process as a noisy-channel signal recovery process in which one tries to recover the input “signal” e , from the observed output signal f.1 Early statistical machine translation systems used a purely word-based approach without taking into account any of the morphological or syntactic properties of the languages ( Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">translation process</definiendum>
			</definition>
			<definition id="2">
				<sentence>As Turkish is a language with agglutinative word structures , we experiment with morphologically segmented and disambiguated versions of the parallel text , in order to also uncover relations between morphemes and function words in one language with morphemes and functions words in the other , in addition to relations between open class content words ; as a cursory analysis of sentence aligned Turkish and English texts indicates that translations of certain English words are actually morphemes embedded into Turkish words .</sentence>
				<definiendum id="0">Turkish</definiendum>
				<definiens id="0">a language with agglutinative word structures</definiens>
			</definition>
			<definition id="3">
				<sentence>Although we have collected about 300K sentence parallel texts , most of these require significant clean-up ( from HTML/PDF sources ) and we have limited our training data in this paper to about 22,500 sentence subset of these parallel texts which comprises the subset of sentences of 40 words or less from the 30K sentences that have been cleaned-up and sentence aligned.2 a03 The main aspect that would have to be seriously considered first for Turkish in SMT is the productive inflectional and derivational morphology .</sentence>
				<definiendum id="0">30K sentences</definiendum>
				<definiens id="0">comprises the subset of sentences of 40 words or less from the</definiens>
				<definiens id="1">the productive inflectional and derivational morphology</definiens>
			</definition>
			<definition id="4">
				<sentence>Turkish word forms consist of morphemes concatenated to a root morpheme or to other morphemes , much like “beads on a string” ( Oflazer , 1994 ) .</sentence>
				<definiendum id="0">Turkish word forms</definiendum>
				<definiens id="0">consist of morphemes concatenated to a root morpheme or to other morphemes</definiens>
			</definition>
			<definition id="5">
				<sentence>For instance , the English word activities was segmented as activ6The tagset used by the TreeTagger is a refinement of PennTreebank tagset where the second letter of the verb part-ofspeech tags distinguishes between ”be” verbs ( B ) , ”have” verbs ( H ) and other verbs ( V ) , ( Schmid , 1994 ) .</sentence>
				<definiendum id="0">TreeTagger</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">a refinement of PennTreebank tagset where the second letter of the verb part-ofspeech tags distinguishes between ”be” verbs ( B ) , ”have” verbs</definiens>
			</definition>
			<definition id="6">
				<sentence>Table 2 : The set of tags used to mark explicit morphemes in English Tag Meaning JJR Adjective , comparative JJS Adjective , superlative NNS Noun , plural POS Possessive ending RBR Adverb , comparative RBS Adverb , superlative VB Verb , base form VBD Verb , past tense VBG Verb , gerund or present participle VBN Verb , past participle VBP Verb , non3rd person singular present VBZ Verb , 3rd person singular present Figure 2 : “Morpheme” alignment between a Turkish and an English sentence We proceeded with the following sequence of experiments : ( 1 ) Baseline : As a baseline system , we used a pure word-based approach and used Pharaoh Training tool ( 2004 ) , to train on the 22,500 sentences , and decoded using Pharaoh ( Koehn et al. , 2003 ) to obtain translations for a test set of 50 sentences .</sentence>
				<definiendum id="0">decoded using Pharaoh</definiendum>
				<definiens id="0">The set of tags used to mark explicit morphemes in English Tag Meaning JJR Adjective , comparative JJS Adjective , superlative NNS Noun , plural POS Possessive ending RBR Adverb , comparative RBS Adverb , superlative VB Verb , base form VBD Verb</definiens>
			</definition>
</paper>

		<paper id="0206">
			<definition id="0">
				<sentence>The name tagger identifies three name types : Person ( PER ) , Organization ( ORG ) and Geopolitical ( GPE ) entities ( locations which are also political units , such as countries , counties , and cities ) .</sentence>
				<definiendum id="0">Organization</definiendum>
				<definiens id="0">locations which are also political units , such as countries , counties , and cities )</definiens>
			</definition>
			<definition id="1">
				<sentence>So our solution is to take all the name candidates in the top N best hypotheses for each sentence to construct a query set Q. Using Q , we compute the cross entropy H ( TestT , d ) between TestT and d by : ∑ ∈ ×−= Qx dxprobTestTxprobdTestTH ) | ( log ) | ( ) , ( 2 where x is a name candidate in Q , and prob ( x|TestT ) is the probability ( frequency ) of x appearing in TestT while prob ( x|d ) is the probability of x in d. If H ( T , d ) is smaller than a threshold then we consider d a useful unlabeled document 3 .</sentence>
				<definiendum id="0">prob</definiendum>
				<definiens id="0">a name candidate in Q</definiens>
			</definition>
			<definition id="2">
				<sentence>The ACE keys used for the evaluations were obtained by dual annotation and adjudication .</sentence>
				<definiendum id="0">ACE keys</definiendum>
				<definiens id="0">used for the evaluations were obtained by dual annotation and adjudication</definiens>
			</definition>
</paper>

		<paper id="1320">
			<definition id="0">
				<sentence>Thematic segmentation is a valuable initial tool in information retrieval and natural language processing .</sentence>
				<definiendum id="0">Thematic segmentation</definiendum>
				<definiens id="0">a valuable initial tool in information retrieval and natural language processing</definiens>
			</definition>
			<definition id="1">
				<sentence>The C99 algorithm ( Choi , 2000 ) makes a linear segmentation based on a divisive clustering strategy and the cosine similarity measure between any two minimal units .</sentence>
				<definiendum id="0">C99 algorithm</definiendum>
				<definiens id="0">makes a linear segmentation based on a divisive clustering strategy and the cosine similarity measure between any two minimal units</definiens>
			</definition>
			<definition id="2">
				<sentence>The second step consists of constructing a similarity matrix Sm×m , where m is the number of utterances and an element sij of the matrix corresponds to the cosine similarity between the vectors representing the frequencies of the words in the ith utterance and the j-th utterance .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">the number of utterances and an element sij of the matrix corresponds to the cosine similarity between the vectors representing the frequencies of the words in the ith utterance and the j-th utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>The segmentation task is modeled as a problem of finding the minimum cost C ( S ) of a segmentation S. The segmentation cost is defined as : C ( S ) ≡ −logPr ( W|S ) Pr ( S ) , 1Occasionally within this document we employ the term utterance to denote either a sentence or an utterance in its proper sense .</sentence>
				<definiendum id="0">segmentation task</definiendum>
				<definiens id="0">a problem of finding the minimum cost C ( S ) of a segmentation S. The segmentation cost is defined as : C ( S ) ≡ −logPr ( W|S ) Pr ( S ) , 1Occasionally within this document we employ the term utterance to denote either a sentence or an utterance in its proper sense</definiens>
			</definition>
			<definition id="4">
				<sentence>One of the commonly used data sets for topic segmentation emerged from the Topic Detection and Tracking ( TDT ) project , which includes the task of story segmentation , i.e. the task of segmenting a stream of news data into topically cohesive stories .</sentence>
				<definiendum id="0">Topic Detection</definiendum>
				<definiens id="0">includes the task of story segmentation</definiens>
			</definition>
			<definition id="5">
				<sentence>N is the number of words in the reference data .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of words in the reference data</definiens>
			</definition>
			<definition id="6">
				<sentence>WindowDiff can be rewritten as : WindowDiff = WDMiss +WDFalseAlarm , where : WDMiss = a80N−k i=1 [ r ( i , k ) &gt; h ( i , k ) ] N−k , WDFalseAlarm = a80N−k i=1 [ r ( i , k ) &lt; h ( i , k ) ] N−k . Hence both misses and false alarms are weighted by 1N−k. Note that , on the one hand , there are indeed ( Nk ) equiprobable possibilities to have a false alarm in an interval of k units. On the other hand , however , the total number of equiprobable possibilities to have a miss in an interval of k units is smaller than ( N-k ) since it depends on the number of reference boundaries ( i.e. we can have a miss in the interval of k units only if in that interval the reference corpus contains at least one boundary ) . Therefore misses , being weighted by 1N−k , are less penalised than false alarms. Let Bref be the number of thematic boundaries in the reference data. Let’s say that the reference data contains about 20 % boundaries and 80 % non-boundaries from the total number of potential boundaries. Therefore , since there are relatively few boundaries compared with non-boundaries , a strategy introducing no false alarms , but introducing a maximum number of misses ( i.e. k · Bref misses ) can be judged as being around 80 % correct by the WindowDiff measure. On the other hand , a segmentation with no misses , but with a maximum number of false alarms ( i.e. ( N − k ) false alarms ) is judged as being 100 % erroneous by the WindowDiff measure. That is , misses and false alarms are not equally penalised. Another issue regarding WindowDiff is that it is not clear “how does one interpret the values produced by the metric” ( Pevzner and Hearst , 2002 ) . In order to address the inadequacies of Pk and WindowDiff , we propose a new evaluation metric , defined as follows : Prerror = Cmiss ·Prmiss +Cfa ·Prfa , where : Cmiss ( 0 ≤ Cmiss ≤ 1 ) is the cost of a miss , Cfa ( 0 ≤ Cfa ≤ 1 ) is the cost of a false alarm , Prmiss = a80N−k i=1 [ Θref hyp ( i , k ) ] a80 N−k i=1 [ ∆ref ( i , k ) ] , Prfa = a80N−k i=1 [ Ψref hyp ( i , k ) ] N−k , Θref hyp ( i , k ) = braceleftBigg 1 , if r ( i , k ) &gt; h ( i , k ) 0 , otherwise Ψref hyp ( i , k ) = braceleftBigg 1 , if r ( i , k ) &lt; h ( i , k ) 0 , otherwise .</sentence>
				<definiendum id="0">WindowDiff</definiendum>
				<definiens id="0">WindowDiff = WDMiss +WDFalseAlarm , where : WDMiss = a80N−k i=1 [ r ( i , k ) &gt; h ( i , k ) ] N−k , WDFalseAlarm = a80N−k i=1 [ r ( i , k ) &lt; h ( i , k ) ] N−k . Hence both misses and false alarms are weighted by 1N−k. Note that , on the one hand , there are indeed ( Nk ) equiprobable possibilities to have a false alarm in an interval of k units. On the other hand , however , the total number of equiprobable possibilities to have a miss in an interval of k units is smaller than ( N-k ) since it depends on the number of reference boundaries</definiens>
				<definiens id="1">contains at least one boundary ) . Therefore misses , being weighted by 1N−k , are less penalised than false alarms. Let Bref be the number of thematic boundaries in the reference data. Let’s say that the reference data contains about 20 % boundaries and 80 % non-boundaries from the total number of potential boundaries. Therefore , since there are relatively few boundaries compared with non-boundaries , a strategy introducing no false alarms , but introducing a maximum number of misses ( i.e. k · Bref misses ) can be judged as being around 80 % correct by the WindowDiff measure. On the other hand , a segmentation with no misses , but with a maximum number of false alarms ( i.e. ( N − k ) false alarms ) is judged as being 100 % erroneous by the WindowDiff measure. That is , misses and false alarms are not equally penalised. Another issue regarding WindowDiff is that it is not clear “how does one interpret the values produced by the metric” ( Pevzner and Hearst , 2002 ) . In order to address the inadequacies of Pk and WindowDiff</definiens>
				<definiens id="2">the cost of a miss</definiens>
				<definiens id="3">the cost of a false alarm</definiens>
			</definition>
			<definition id="7">
				<sentence>Analogously Prfa is the probability that the hypothesized segmentation contains more boundaries than the reference segmentation in an interval of k units .</sentence>
				<definiendum id="0">Prfa</definiendum>
				<definiens id="0">the probability that the hypothesized segmentation contains more boundaries than the reference segmentation in an interval of k units</definiens>
			</definition>
			<definition id="8">
				<sentence>Percent error values are given in the figures and we used the following abbreviations : WD to denote WindowDiff error metric ; TextSeg KA to denote the TextSeg algorithm ( Utiyama and Isahara , 2001 ) when the average number of boundaries in the reference data was provided to the algorithm ; C99 KA to denote the C99 algorithm ( Choi , 2000 ) when the average number of boundaries in the reference data was provided to the algorithm ; N0 to denote the algorithm proposing a segmentation with no boundaries ; All to denote the algorithm proposing the degenerate segmentation all boundaries ; RK to denote the algorithm that generates a random known segmentation ; and RU to denote the algorithm that generates a random unknown segmentation .</sentence>
				<definiendum id="0">TextSeg KA</definiendum>
				<definiens id="0">the algorithm proposing a segmentation with no boundaries ; All to denote the algorithm proposing the degenerate segmentation all boundaries</definiens>
			</definition>
			<definition id="9">
				<sentence>For example , when tested on TDT data , C99 KA seems to work better than C99 by Pk and Pprimek metrics , while the WindowDiff metric gives a contradictory assessment .</sentence>
				<definiendum id="0">C99 KA</definiendum>
				<definiens id="0">seems to work better than C99 by Pk and Pprimek metrics , while the WindowDiff metric gives a contradictory assessment</definiens>
			</definition>
</paper>

		<paper id="3306">
			<definition id="0">
				<sentence>two tasks inherent in gene recognition : identifying gene mentions in text ( task 1A ) ( Yeh et al. , 2005 ) and normalizing an identified gene list ( task 1B ) ( Hirschman et al. , 2005 ) .</sentence>
				<definiendum id="0">identified gene list</definiendum>
			</definition>
			<definition id="1">
				<sentence>A normalization system consists of multiple normalization steps in sequence .</sentence>
				<definiendum id="0">normalization system</definiendum>
				<definiens id="0">consists of multiple normalization steps in sequence</definiens>
			</definition>
</paper>

		<paper id="2608">
			<definition id="0">
				<sentence>The Gap-Weighted Subsequences Kernel is the most general Sequence Kernel .</sentence>
				<definiendum id="0">Gap-Weighted Subsequences Kernel</definiendum>
				<definiens id="0">the most general Sequence Kernel</definiens>
			</definition>
			<definition id="1">
				<sentence>The associate kernel is defined as Kn ( s , t ) = 〈φn ( s ) , φn ( t ) 〉 = X u∈Σn φnu ( s ) φnu ( t ) .</sentence>
				<definiendum id="0">associate kernel</definiendum>
				<definiens id="0">Kn ( s , t ) = 〈φn ( s ) , φn ( t ) 〉 = X u∈Σn φnu ( s ) φnu ( t )</definiens>
			</definition>
			<definition id="2">
				<sentence>The Syntagmatic Kernel is defined as a linear combination of Gap-Weighted Subsequences Kernels thatoperate atwordandPoStaglevel .</sentence>
				<definiendum id="0">Syntagmatic Kernel</definiendum>
			</definition>
			<definition id="3">
				<sentence>Analogously , we defined the PoS Kernel ( KnPoS ) to operate on sequences of PoS tags p−3 , p−2 , p−1 , p0 , p+1 , p+2 , p+3 , where p0 is the PoS tag of l0 .</sentence>
				<definiendum id="0">PoS Kernel</definiendum>
				<definiendum id="1">KnPoS</definiendum>
				<definiens id="0">) to operate on sequences of PoS tags p−3 , p−2 , p−1 , p0 , p+1 , p+2 , p+3 , where p0 is the PoS tag of l0</definiens>
			</definition>
			<definition id="4">
				<sentence>KColl ( s , t ) = nsummationdisplay l=1 KlColl ( s , t ) ( 11 ) and KPoS ( s , t ) = nsummationdisplay l=1 KlPoS ( s , t ) .</sentence>
				<definiendum id="0">KColl</definiendum>
				<definiens id="0">s , t ) ( 11 ) and KPoS ( s , t ) = nsummationdisplay l=1 KlPoS ( s , t )</definiens>
			</definition>
			<definition id="5">
				<sentence>( 12 ) Both kernels depend on the parameter n , the length of the non-contiguous subsequences , and λ , the de59 cay factor .</sentence>
				<definiendum id="0">Both kernels</definiendum>
				<definiendum id="1">λ</definiendum>
				<definiens id="0">depend on the parameter n , the length of the non-contiguous subsequences , and</definiens>
			</definition>
			<definition id="6">
				<sentence>Semantic Domains are groups of strongly paradigmatically related words , and can be acquired automatically from corpora in a totally unsupervised way ( Gliozzo , 2005 ) .</sentence>
				<definiendum id="0">Semantic Domains</definiendum>
			</definition>
			<definition id="7">
				<sentence>SVD decomposes the term-by-document matrix T into three matrices T = VΣkUT where Σk is the diagonal k × k matrix containing the k singular values of T. D = VΣkprime where kprime lessmuch k. Once a DM has been defined by the matrixD , the Domain Space is a kprime dimensional space , in which both texts and terms are represented by means of Domain Vectors ( DVs ) , i.e. vectors representing the domain relevances among the linguistic object and each domain .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiendum id="1">Domain Space</definiendum>
				<definiens id="0">decomposes the term-by-document matrix T into three matrices T = VΣkUT where Σk is the diagonal k × k matrix containing the k singular values of T. D = VΣkprime where kprime lessmuch k. Once a DM has been defined by the matrixD , the</definiens>
				<definiens id="1">a kprime dimensional space , in which both texts and terms are represented by means of Domain Vectors ( DVs ) , i.e. vectors representing the domain relevances among the linguistic object and each domain</definiens>
			</definition>
			<definition id="8">
				<sentence>The DV vectorwprimei for the term wi ∈ V is the ith row of D , where V = { w1 , w2 , ... , wk } is the vocabulary of the corpus .</sentence>
				<definiendum id="0">DV vectorwprimei</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">for the term wi ∈</definiens>
				<definiens id="1">the ith row of D , where V = { w1 , w2 , ... , wk } is the vocabulary of the corpus</definiens>
			</definition>
			<definition id="9">
				<sentence>The Domain Kernel measures the similarity among the topics ( domains ) of two texts , so to capture domain aspects of sense distinction .</sentence>
				<definiendum id="0">Domain Kernel</definiendum>
				<definiens id="0">measures the similarity among the topics ( domains ) of two texts , so to capture domain aspects of sense distinction</definiens>
			</definition>
			<definition id="10">
				<sentence>It is a variation of the Latent Semantic Kernel ( Shawe-Taylor and Cristianini , 2004 ) , in which a DM is exploited to define an explicit mapping D : Rk → Rkprime from the Vector Space Model ( Salton and McGill , 1983 ) into the Domain Space ( see Section 4 ) , defined by the following mapping : D ( vectortj ) = vectortj ( IIDFD ) = vectortprimej ( 16 ) where IIDF is a k × k diagonal matrix such that iIDFi , i = IDF ( wi ) , vectortj is represented as a row vector , and IDF ( wi ) isthe Inverse Document Frequency of wi .</sentence>
				<definiendum id="0">IIDF</definiendum>
				<definiens id="0">a variation of the Latent Semantic Kernel ( Shawe-Taylor and Cristianini , 2004 ) , in which a DM is exploited to define an explicit mapping D : Rk → Rkprime from the Vector Space Model ( Salton and McGill , 1983 ) into the Domain Space ( see Section 4 ) , defined by the following mapping : D ( vectortj ) = vectortj ( IIDFD ) = vectortprimej ( 16 ) where</definiens>
				<definiens id="1">a k × k diagonal matrix such that iIDFi , i = IDF ( wi ) , vectortj is represented as a row vector , and IDF ( wi ) isthe Inverse Document Frequency of wi</definiens>
			</definition>
			<definition id="11">
				<sentence>The Domain Kernel is then defined by : KD ( ti , tj ) = 〈D ( ti ) , D ( tj ) 〉radicalbig〈D ( t j ) , D ( tj ) 〉〈D ( ti ) , D ( ti ) 〉 ( 17 ) The final system for WSD results from a combination of kernels that deal with syntagmatic and paradigmatic aspects ( i.e. PoS , collocations , bag of words , domains ) , according to the following kernel 61 combination schema : KC ( xi , xj ) = nsummationdisplay l=1 Kl ( xi , xj ) radicalbig Kl ( xj , xj ) Kl ( xi , xi ) ( 18 ) In this section we evaluate the Syntagmatic Kernel , showing that it improves over the standard feature extraction technique based on bigrams and trigrams of words and PoS tags .</sentence>
				<definiendum id="0">Domain Kernel</definiendum>
				<definiendum id="1">xj ) radicalbig Kl ( xj , xj</definiendum>
				<definiens id="0">final system for WSD results from a combination of kernels that deal with syntagmatic and paradigmatic aspects ( i.e. PoS , collocations , bag of words</definiens>
				<definiens id="1">the Syntagmatic Kernel , showing that it improves over the standard feature extraction technique based on bigrams and trigrams of words</definiens>
			</definition>
			<definition id="12">
				<sentence>For the future , we plan to exploit the Syntagmatic Kernel for a wide variety of Natural Language Processing tasks , such as Entity Recognition and Relation Extraction .</sentence>
				<definiendum id="0">Syntagmatic Kernel</definiendum>
				<definiens id="0">a wide variety of Natural Language Processing tasks , such as Entity Recognition and Relation Extraction</definiens>
			</definition>
</paper>

		<paper id="2806">
			<definition id="0">
				<sentence>This study can be also seen as a confirmatory study , because it confirms that a number of recent web genres , unprecedented in the paper world ( such as home page , FAQs , and blog ) can be recognized by the subjects ; others have not fully emerged and many web users are not familiar with their new genre labels ; finally some web pages show a high level of ambiguity and web users largely disagree on assigning labels to them .</sentence>
				<definiendum id="0">blog</definiendum>
				<definiens id="0">such as home page , FAQs , and</definiens>
			</definition>
			<definition id="1">
				<sentence>Adjusted Residuals : A test statistic , such as Fisher’s exact test , and statistical significance summarize the strength of evidence against the null hypothesis of independence , but does not indicate how many and which cells deviate greatly from this hypothesis .</sentence>
				<definiendum id="0">Adjusted Residuals</definiendum>
				<definiens id="0">A test statistic , such as Fisher’s exact test , and statistical significance summarize the strength of evidence against the null hypothesis of independence , but does not indicate how many and which cells deviate greatly from this hypothesis</definiens>
			</definition>
</paper>

		<paper id="1307">
			<definition id="0">
				<sentence>This paper investigates the problems facing modelling agents’ beliefs in Discourse Representation Theory ( DRT ) and presents a viable solution in the form of a dialogue-based DRT representation of beliefs .</sentence>
				<definiendum id="0">DRT</definiendum>
				<definiens id="0">presents a viable solution in the form of a dialogue-based DRT representation of beliefs</definiens>
			</definition>
			<definition id="1">
				<sentence>H3 : Does your wife like black ?</sentence>
				<definiendum id="0">H3</definiendum>
			</definition>
			<definition id="2">
				<sentence>For example , in Prolegomena , Kamp introduces a simple model of verbal communication ( Kamp 1990 : 71 ) , which consists of two agents , A and B , and their mental states K ( A ) and K ( B ) .</sentence>
				<definiendum id="0">Kamp</definiendum>
				<definiens id="0">introduces a simple model of verbal communication</definiens>
			</definition>
			<definition id="3">
				<sentence>Kamp et al.’s ( 2005 ) expansion of the original , also known as ‘vanilla’ , DRT ( Poesio and Traum 1997a ) , deal minimally with intentions .</sentence>
				<definiendum id="0">Kamp et al.’s</definiendum>
				<definiens id="0">2005 ) expansion of the original , also known as ‘vanilla’ , DRT ( Poesio and Traum 1997a ) , deal minimally with intentions</definiens>
			</definition>
			<definition id="4">
				<sentence>The notion of belief ( or strong belief ) is to be understood in relation to the agent : it is what the agent takes to be true .</sentence>
				<definiendum id="0">notion of belief</definiendum>
				<definiens id="0">to be understood in relation to the agent : it is what the agent takes to be true</definiens>
			</definition>
			<definition id="5">
				<sentence>Acceptance consists of the agent’s weakly believed propositions .</sentence>
				<definiendum id="0">Acceptance</definiendum>
			</definition>
			<definition id="6">
				<sentence>Knowledge and Belief : An Introduction to the Logic of the Two Notions .</sentence>
				<definiendum id="0">Belief</definiendum>
				<definiens id="0">An Introduction to the Logic of the Two Notions</definiens>
			</definition>
			<definition id="7">
				<sentence>Convention : A Philosophical Study .</sentence>
				<definiendum id="0">Convention</definiendum>
			</definition>
</paper>

		<paper id="0305">
			<definition id="0">
				<sentence>The PDTB contains annotations of discourse relations and their arguments on the Wall Street Journal corpus ( Marcus et al. , 1993 ) .</sentence>
				<definiendum id="0">PDTB</definiendum>
			</definition>
			<definition id="1">
				<sentence>Following the approach towards discourse structure in ( Webber et al. , 2003 ) , the PDTB takes a lexicalized ap31 proacha2 towards the annotation of discourse relations , treating discourse connectives as the anchors of the relations , and thus as discourse-level predicates taking two abstract objects ( AOs ) as their arguments .</sentence>
				<definiendum id="0">PDTB</definiendum>
				<definiendum id="1">AOs</definiendum>
				<definiens id="0">takes a lexicalized ap31 proacha2 towards the annotation of discourse relations , treating discourse connectives as the anchors of the relations , and thus as discourse-level predicates taking two abstract objects</definiens>
			</definition>
			<definition id="2">
				<sentence>In the examples here , Arg1 appears in italics , while Arg2 appears in bold .</sentence>
				<definiendum id="0">Arg1</definiendum>
				<definiens id="0">appears in italics</definiens>
			</definition>
</paper>

		<paper id="0132">
			<definition id="0">
				<sentence>Given an observation sequence o= &lt; o 1 , o 2 , ... , o T &gt; , linear-chain CRFs model based on the assumption of first order Markov chains defines the corresponding state sequence s′ probability as follows ( Lafferty et al. , 2001 ) : 1 1 1 ( | ) exp ( ( , , , ) ) T kk t t tk pf Z λ Λ− = = ∑∑ o so o ( 1 ) Where Λ is the model parameter set , Z o is the normalization factor over all state sequences , f k is an arbitrary feature function , and λ k is the learned feature weight .</sentence>
				<definiendum id="0">Λ</definiendum>
				<definiendum id="1">f k</definiendum>
				<definiendum id="2">λ k</definiendum>
				<definiens id="0">the model parameter set</definiens>
				<definiens id="1">the normalization factor over all state sequences</definiens>
			</definition>
			<definition id="1">
				<sentence>POS feature is an important feature which carries some syntactic information .</sentence>
				<definiendum id="0">POS feature</definiendum>
				<definiens id="0">an important feature which carries some syntactic information</definiens>
			</definition>
</paper>

		<paper id="0102">
			<definition id="0">
				<sentence>For instance , in terms of housing , 居屋 ( housing under the Home Ownership Scheme ) is a specific kind of housing in Hong Kong , 組屋 is a specific term in Singapore ( as seen in SG data ) , whereas housing is generally expressed as 住 房 in Mainland China ( as seen in BJ data ) .</sentence>
				<definiendum id="0">組屋</definiendum>
				<definiens id="0">a specific term in Singapore ( as seen in SG data</definiens>
			</definition>
			<definition id="1">
				<sentence>As mentioned earlier , the Tongyici Cilin contains some 70,000 lexical items under 12 broad semantic classes , 94 subclasses , and 1,428 heads .</sentence>
				<definiendum id="0">Tongyici Cilin</definiendum>
				<definiens id="0">contains some 70,000 lexical items under 12 broad semantic classes</definiens>
			</definition>
</paper>

		<paper id="0306">
</paper>

		<paper id="3108">
			<definition id="0">
				<sentence>The approach presented here has some resemblance to the bracketing transduction grammars ( BTG ) of ( Wu , 1997 ) , which have been applied to a phrase-based machine translation system in ( Zens et al. , 2004 ) .</sentence>
				<definiendum id="0">bracketing transduction grammars</definiendum>
				<definiendum id="1">BTG</definiendum>
			</definition>
			<definition id="1">
				<sentence>We consider the following binary features : rent source position j hf , d , c ( fJ1 , eI1 , FJ1 , EI1 , i , j , j′ ) ( 6 ) = δ ( fj+d , f ) · δ ( c , cj , j′ ) rent target position i he , d , c ( fJ1 , eI1 , FJ1 , EI1 , i , j , j′ ) ( 7 ) = δ ( ei+d , e ) · δ ( c , cj , j′ ) around the current source position j hF , d , c ( fJ1 , eI1 , FJ1 , EI1 , i , j , j′ ) ( 8 ) = δ ( Fj+d , F ) · δ ( c , cj , j′ ) around the current target position i hE , d , c ( fJ1 , eI1 , FJ1 , EI1 , i , j , j′ ) ( 9 ) = δ ( Ei+d , E ) · δ ( c , cj , j′ ) Here , δ ( · , · ) denotes the Kronecker-function .</sentence>
				<definiendum id="0">cj</definiendum>
				<definiens id="0">Ei+d , E ) · δ ( c , cj</definiens>
				<definiens id="1">the Kronecker-function</definiens>
			</definition>
			<definition id="2">
				<sentence>As the BTEC is a rather clean corpus , the preprocessing consisted mainly of tokenization , i.e. , separating punctuation marks from words .</sentence>
				<definiendum id="0">BTEC</definiendum>
				<definiens id="0">a rather clean corpus , the preprocessing consisted mainly of tokenization</definiens>
			</definition>
</paper>

		<paper id="3124">
			<definition id="0">
				<sentence>The Microsoft Research translation system is a syntactically informed phrasal SMT system that uses a phrase translation model based on dependency treelets and a global reordering model based on the source dependency tree .</sentence>
				<definiendum id="0">Microsoft Research translation system</definiendum>
				<definiens id="0">a syntactically informed phrasal SMT system that uses a phrase translation model based on dependency treelets and a global reordering model based on the source dependency tree</definiens>
			</definition>
			<definition id="1">
				<sentence>Psurf T =∏ i=1 ∣T∣ Ptrisurf T i∣T i−2 , T i−1 PbilexT =∏ i=1 ∣T∣ PbidepT i∣parentT i Ptrisurf is a Kneser-Ney smoothed trigram language model trained on the target side of the training corpus , and Pbilex is a Kneser-Ney smoothed we ­2 should ­1 follow the ­2 Rio ­1 agenda +1 hemos ­1 de +1 cumplir el ­1 programa +1 de ­1 Río +1 Figure 1 : Aligned dependency tree pair , annotated with headrelative positions 159 bigram language model trained on target language dependencies extracted from the aligned parallel dependency tree corpus .</sentence>
				<definiendum id="0">Pbilex</definiendum>
				<definiens id="0">a Kneser-Ney smoothed trigram language model trained on the target side of the training corpus</definiens>
			</definition>
</paper>

		<paper id="1605">
			<definition id="0">
				<sentence>The context ( or “company” ) of a target word is represented by its distributional profile ( DP ) , which lists the strength of association between the target and each of the lexical , syntactic , and/or semantic units that co-occur with it .</sentence>
				<definiendum id="0">DP</definiendum>
				<definiens id="0">lists the strength of association between the target and each of the lexical , syntactic , and/or semantic units that co-occur with it</definiens>
			</definition>
			<definition id="1">
				<sentence>ASD cp is a modification of Kullback-Leibler divergence that overcomes the latter’s problem of division by zero , which can be caused by data sparseness .</sentence>
				<definiendum id="0">ASD cp</definiendum>
			</definition>
			<definition id="2">
				<sentence>limitations The distributional hypothesis ( Firth , 1957 ) states that words that occur in similar contexts tend to be semantically similar .</sentence>
				<definiendum id="0">distributional hypothesis</definiendum>
				<definiens id="0">words that occur in similar contexts tend to be semantically similar</definiens>
			</definition>
			<definition id="3">
				<sentence>But both kinds of measures have large space requirements to do this , requiring matrices of size N A2N , whereN is the size of the vocabulary ( perhaps 100,000 for most languages ) in the case of distributional measures and the number of senses ( 75,000 just for nouns in WordNet ) in the case of semantic measures .</sentence>
				<definiendum id="0">whereN</definiendum>
			</definition>
			<definition id="4">
				<sentence>The matrix that is created after one pass of the corpus , which we call the base WCCM , although noisy ( as it is created from raw text and not senseannotated data ) , captures strong associations between categories and co-occurring words .</sentence>
				<definiendum id="0">WCCM</definiendum>
				<definiens id="0">it is created from raw text and not senseannotated data ) , captures strong associations between categories and co-occurring words</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , following is the cosine formula for distance between words w 1 and w 2 using relation-free lexical DPWs , with conditional probability of the co-occurring word given the target as the strength of association : Cos cp B4w 1 BNw 2 B5BP ∑ wBECB4w 1 B5CJCB4w 2 B5 B4PB4wCYw 1 B5A2PB4wCYw 2 B5B5 D5 ∑ wBECB4w 1 B5 PB4wCYw 1 B5 2 A2 D5 ∑ wBECB4w 2 B5 PB4wCYw 2 B5 2 Here , CB4xB5 is the set of words that co-occur with word x within a pre-determined window .</sentence>
				<definiendum id="0">CB4xB5</definiendum>
				<definiens id="0">the set of words that co-occur with word x within a pre-determined window</definiens>
			</definition>
			<definition id="6">
				<sentence>Below is the formula for cosine with conditional probabilities when applied to concepts : Cos cp B4c 1 BNc 2 B5BP ∑ wBECB4c 1 B5CJCB4c 2 B5 B4PB4wCYc 1 B5A2PB4wCYc 2 B5B5 D5 ∑ wBECB4c 1 B5 PB4wCYc 1 B5 2 A2 D5 ∑ wBECB4c 2 B5 PB4wCYc 2 B5 2 Now , CB4xB5 is the set of words that co-occur with concept x within a pre-determined window .</sentence>
				<definiendum id="0">CB4xB5</definiendum>
				<definiens id="0">the set of words that co-occur with concept x within a pre-determined window</definiens>
			</definition>
			<definition id="7">
				<sentence>We will refer to such measures as distributional measures of concept-distance ( Distrib concept ) , in contrast to the earlier-described distributional measures of word-distance ( Distrib word ) and WordNet-based ( or semantic ) measures of concept-distance ( WNet concept ) .</sentence>
				<definiendum id="0">WordNet-based</definiendum>
				<definiens id="0">distributional measures of concept-distance ( Distrib concept ) , in contrast to the earlier-described distributional measures of word-distance ( Distrib word</definiens>
			</definition>
			<definition id="8">
				<sentence>The co-occurrence frequency of a parent is the weighted sum of cooccurrence frequencies of its children .</sentence>
				<definiendum id="0">co-occurrence frequency of a parent</definiendum>
				<definiens id="0">the weighted sum of cooccurrence frequencies of its children</definiens>
			</definition>
</paper>

		<paper id="0404">
			<definition id="0">
				<sentence>Indeed , Simons concludes that DRT is a theory of semantic and not pragmatic presupposition ( 2003 ) .</sentence>
				<definiendum id="0">DRT</definiendum>
			</definition>
			<definition id="1">
				<sentence>Werth , for example , claims that DRT is essentially only about truthconditionality : 25 [ DRT’s ] goal is truth-conditionality and its models are minimal worlds inhabited by predicates and variables ... it does not model human understanding : there is no place in it for participant roles , setting , background knowledge , purposes , even inferences ( Werth 1999 : 65 ) .</sentence>
				<definiendum id="0">Werth</definiendum>
				<definiens id="0">minimal worlds inhabited by predicates and variables ... it does not model human understanding : there is no place in it for participant roles , setting , background knowledge , purposes</definiens>
			</definition>
</paper>

		<paper id="2204">
			<definition id="0">
				<sentence>Information extraction is a form of shallow text analysis that involves identifying domain-specific fragments within natural language text .</sentence>
				<definiendum id="0">Information extraction</definiendum>
			</definition>
			<definition id="1">
				<sentence>As a side-effect , TPLEX does generate a set of extraction patterns which may be a useful in their own right , depending on the application .</sentence>
				<definiendum id="0">TPLEX</definiendum>
				<definiens id="0">generate a set of extraction patterns which may be a useful in their own right , depending on the application</definiens>
			</definition>
			<definition id="2">
				<sentence>Also , NOMEN uses a binary scoring mechanism , which works well in dense corpora with substantial redundancy .</sentence>
				<definiendum id="0">NOMEN</definiendum>
				<definiens id="0">uses a binary scoring mechanism , which works well in dense corpora with substantial redundancy</definiens>
			</definition>
			<definition id="3">
				<sentence>TPLEX employs a recursive scoring metric in which good patterns reinforce good positions , and good positionsreinforcegoodpatterns .</sentence>
				<definiendum id="0">TPLEX</definiendum>
				<definiens id="0">employs a recursive scoring metric in which good patterns reinforce good positions</definiens>
			</definition>
			<definition id="4">
				<sentence>Our scoring mechanism calculates the score of a pattern as a function of the scores of the positions that it matches , and the score of a position as a function of the scores of the patterns that extract it .</sentence>
				<definiendum id="0">scoring mechanism</definiendum>
				<definiens id="0">calculates the score of a pattern as a function of the scores of the positions that it matches , and the score of a position as a function of the scores of the patterns that extract it</definiens>
			</definition>
			<definition id="5">
				<sentence>TPLEX learns patterns to identify the start and end of target occurrences independently of each other .</sentence>
				<definiendum id="0">TPLEX</definiendum>
				<definiens id="0">learns patterns to identify the start</definiens>
			</definition>
			<definition id="6">
				<sentence>The notation p → r indicates that pattern p matches position r. Fields are denoted by f , and F is the set of all fields .</sentence>
				<definiendum id="0">notation p → r</definiendum>
				<definiendum id="1">F</definiendum>
			</definition>
			<definition id="7">
				<sentence>posf ( p ) can be thought of as a measure of the benefit of p to f , while negf ( p ) measures the harm of p to f , and unk ( p ) measures the uncertainty about the field with which p is associated .</sentence>
				<definiendum id="0">posf ( p )</definiendum>
				<definiens id="0">measures the uncertainty about the field with which p is associated</definiens>
			</definition>
			<definition id="8">
				<sentence>These quantities are defined as follows : posf ( p ) is the average score for field f of positions extracted by p. We first compute : posf ( p ) = 1Z p summationdisplay p→r scoretf ( r ) , where Zp = summationtextf summationtextp→r scoretf ( r ) is a normalizing constant to ensure thatsummationtextf posf ( p ) = 1 .</sentence>
				<definiendum id="0">Zp = summationtextf summationtextp→r scoretf ( r )</definiendum>
				<definiens id="0">the average score for field f of positions extracted by p. We first compute : posf ( p ) = 1Z p summationdisplay p→r scoretf ( r )</definiens>
				<definiens id="1">a normalizing constant to ensure thatsummationtextf posf ( p ) = 1</definiens>
			</definition>
			<definition id="9">
				<sentence>Finally , unk ( p ) measures the degree to which p extract positions whose field is unknown : unk ( p ) = 1| { p → r } | summationdisplay p→r unk ( r ) , where unk ( r ) measures the degree to which position r is unknown .</sentence>
				<definiendum id="0">unk</definiendum>
				<definiens id="0">measures the degree to which p extract positions whose field is unknown</definiens>
			</definition>
			<definition id="10">
				<sentence>Let score ( G ) be the chance that G is the correct set of fragments for D. Assuming that the correctness of the fragments can be determined independently given that the correct number of fragments have been identified for each field , then score ( G ) can be defined zero if ∃ ( r1 , r1 ) , ( s2 , r2 ) ∈ G such that ( s1 , r1 ) overlaps ( s2 , r2 ) , and score ( G ) = producttextf score ( Gf ) otherwise , where Gf ⊆ G is the fragments in G for field f. The score of Gf = { e1 , e2 , ... } is defined as score ( Gf ) = Pr ( |Gf| ) ·producttextj score ( ej ) , wherePr ( |Gf| ) is the fraction of training documents that have |Gf| instances of field f. It is infeasible to enumerate all subsets G ⊆ E , so we perform a heuristic search .</sentence>
				<definiendum id="0">Let score ( G</definiendum>
				<definiendum id="1">wherePr ( |Gf| )</definiendum>
				<definiens id="0">the chance that G is the correct set of fragments for D. Assuming that the correctness of the fragments can be determined independently given that the correct number of fragments have been identified for each field , then score ( G ) can be defined zero if ∃ ( r1 , r1 ) , ( s2 , r2 ) ∈ G such that ( s1 , r1 ) overlaps ( s2 , r2 ) , and score ( G ) = producttextf score ( Gf ) otherwise , where Gf ⊆ G is the fragments in G for field f. The score of Gf = { e1 , e2 , ... } is defined as score ( Gf ) = Pr ( |Gf| ) ·producttextj score ( ej ) ,</definiens>
				<definiens id="1">the fraction of training documents that have |Gf| instances of field f. It is infeasible to enumerate all subsets G ⊆ E , so we perform a heuristic search</definiens>
			</definition>
			<definition id="11">
				<sentence>The states in the search space are pairs of the form ( G , P ) , where G is a list of good fragments ( i.e. fragments that have been accepted ) , and P is a list of pending fragments ( i.e. fragments that haven’t yet been accepted or rejected ) .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">pairs of the form ( G , P ) , where G is a list of good fragments ( i.e. fragments that have been accepted ) , and</definiens>
				<definiens id="1">a list of pending fragments ( i.e. fragments that haven’t yet been accepted or rejected )</definiens>
			</definition>
			<definition id="12">
				<sentence>We compared TPLEX to BWI ( Freitag and Kushmerick , 2000 ) , LP2 ( Ciravegna , 2001 ) , ELIE ( Finn and Kushmerick , 2004 ) , and an approach based on conditional random fields ( Lafferty et al. , 2001 ) .</sentence>
				<definiendum id="0">TPLEX</definiendum>
			</definition>
			<definition id="13">
				<sentence>TPLEX is the least accurate algorithm for the MUC data .</sentence>
				<definiendum id="0">TPLEX</definiendum>
			</definition>
			<definition id="14">
				<sentence>TPLEX extracts all fields simultaneously and uses the scores from each of the 0 0 2 4 6 8 10 F1 Percentage of data used for training Trained with unlabeled data a51 a51 a51 a51 a51 a51 a51 Trained with only labeled data + + + + + + + Figure 3 : F1 averaged across all fields , for the Seminar dataset trained on only labeled data and trained on labeled and unlabeled data patterns that extract a given position to determine the most likely field for that position .</sentence>
				<definiendum id="0">TPLEX</definiendum>
				<definiens id="0">extracts all fields simultaneously and uses the scores</definiens>
			</definition>
			<definition id="15">
				<sentence>Boosting is a highly effective ensemble learning technique , and BWI uses boosting to tune the weights of the learned patterns , so if we generalize boosting to handle unlabelled data , then the learned weights may well be more effective than those calculated by TPLEX .</sentence>
				<definiendum id="0">Boosting</definiendum>
			</definition>
</paper>

		<paper id="3301">
			<definition id="0">
				<sentence>By analyzing a large set of online definitions , this study shows that 1 ) SDef correlates with SDT , and 2 ) SDT constrains the lexicosyntactic patterns of the corresponding definitions .</sentence>
				<definiendum id="0">SDT</definiendum>
				<definiens id="0">constrains the lexicosyntactic patterns of the corresponding definitions</definiens>
			</definition>
			<definition id="1">
				<sentence>The Unified Medical Language System ( UMLS ) is the largest biomedical knowledge source maintained by the National Library of Medicine .</sentence>
				<definiendum id="0">Unified Medical Language System</definiendum>
			</definition>
			<definition id="2">
				<sentence>The UMLS includes the Metathesaurus ( MT ) , which contains over one million biomedical concepts and the Semantic Network ( SN ) , which represents a high-level abstraction from the UMLS Metathesaurus .</sentence>
				<definiendum id="0">UMLS</definiendum>
			</definition>
			<definition id="3">
				<sentence>The SN consists of 134 semantic types with 54 types of semantic relations ( e.g. , is-a or part-of ) that relate the semantic types to each other .</sentence>
				<definiendum id="0">SN</definiendum>
			</definition>
			<definition id="4">
				<sentence>The UMLS Semantic Network provides broad and general world knowledge that is related to human health .</sentence>
				<definiendum id="0">UMLS Semantic Network</definiendum>
				<definiens id="0">provides broad and general world knowledge that is related to human health</definiens>
			</definition>
			<definition id="5">
				<sentence>The National Library of Medicine also makes available MMTx , a programming implementation of MetaMap ( Aronson 2001 ) , which maps free text to the UMLS concepts and associated semantic types .</sentence>
				<definiendum id="0">National Library</definiendum>
				<definiens id="0">maps free text to the UMLS concepts and associated semantic types</definiens>
			</definition>
			<definition id="6">
				<sentence>For each candidate term , MMTx ranks a list of UMLS concepts with confidence .</sentence>
				<definiendum id="0">MMTx</definiendum>
				<definiens id="0">ranks a list of UMLS concepts with confidence</definiens>
			</definition>
			<definition id="7">
				<sentence>AutoSlog-TS first generates every possible lexicosyntactic pattern to extract every noun phrase in both collections of text and then computes statistics based on how often each pattern appears in the relevant text versus the background and outputs a ranked list of extraction patterns coupled with statistics indicating how strongly each pattern is associated with relevant and non-relevant texts .</sentence>
				<definiendum id="0">AutoSlog-TS</definiendum>
				<definiens id="0">generates every possible lexicosyntactic pattern to extract every noun phrase in both collections of text and then computes statistics based on how often each pattern appears in the relevant text versus the background and outputs a ranked list of extraction patterns coupled with statistics indicating how strongly each pattern is associated with relevant and non-relevant texts</definiens>
			</definition>
			<definition id="8">
				<sentence>Figure 1 shows three SDT ( [ Body Part , Organ , or Organ Component ] , [ Disease or Syndrome ] , and [ Organization ] ) with the corresponding top five statistically correlated semantic types that appear in their definitions .</sentence>
				<definiendum id="0">SDT</definiendum>
				<definiens id="0">correlated semantic types that appear in their definitions</definiens>
			</definition>
			<definition id="9">
				<sentence>Our results show that in a total of 112 ( or 83.6 % ) cases , SDT appears as one of the top five statistically correlated semantic types in SDef , and that in a total of 94 ( or 70.1 % ) cases , SDT appears at the top in SDef .</sentence>
				<definiendum id="0">SDT</definiendum>
				<definiendum id="1">SDT</definiendum>
				<definiens id="0">appears as one of the top five statistically correlated semantic types in SDef</definiens>
			</definition>
			<definition id="10">
				<sentence>For example , when SDT is “Entity” , the minimum size for a SDef was 4.75 , which is larger than the total number of the definitions ( i.e. , 4 ) .</sentence>
				<definiendum id="0">SDT</definiendum>
				<definiens id="0">larger than the total number of the definitions</definiens>
			</definition>
</paper>

		<paper id="0603">
			<definition id="0">
				<sentence>The following is an example of the annotation where the annotators were to choose an appropriate tense tag from the provided tense tags : ( ( IP ( NP-TPC ( NP-PN ( NR  � ) ) ( NP ( NN �1 % ) ( NN� ) ) ) ( LCP-TMP ( NP ( NT E� H ) ) ( LC9 ) ) ( NP-SBJ ( NP ( PP ( P � ) ( NP ( NN � ) ) ) ( NP ( NN � ) ) ) ( NP ( NN !</sentence>
				<definiendum id="0">IP ( NP-TPC ( NP-PN</definiendum>
				<definiens id="0">an example of the annotation where the annotators were to choose an appropriate tense tag from the provided tense tags : ( (</definiens>
			</definition>
			<definition id="1">
				<sentence>It is defined by the following formula , where P ( A ) is the observed agreement among the judges and P ( E ) is the expected agreement : k = P ( A ) −P ( E ) 1−P ( E ) ( 1 ) Depending on how one identifies the expected agreement brought about by pure chance , there are two ways to calculate the Kappa score .</sentence>
				<definiendum id="0">P ( A )</definiendum>
				<definiens id="0">the observed agreement among the judges and P ( E ) is the expected agreement : k = P ( A ) −P ( E ) 1−P ( E ) ( 1 ) Depending on how one identifies the expected agreement brought about by pure chance</definiens>
			</definition>
			<definition id="2">
				<sentence>Put abstractly , ambiguity is an intrinsic property of natural languages .</sentence>
				<definiendum id="0">ambiguity</definiendum>
			</definition>
			<definition id="3">
				<sentence>A log-linear model is a special case of generalized linear models ( GLMs ) and has been widely applied in many fields of social science research for multivariate analysis of categorical data .</sentence>
				<definiendum id="0">log-linear model</definiendum>
				<definiendum id="1">GLMs</definiendum>
				<definiens id="0">a special case of generalized linear models</definiens>
			</definition>
</paper>

		<paper id="1522">
			<definition id="0">
				<sentence>Using the fusion operation involves inserting partial derivations , which are linked to already existing ones ( the realized derivation ) , into the shared forest whereas using 4w .</sentence>
				<definiendum id="0">fusion operation</definiendum>
				<definiens id="0">involves inserting partial derivations , which are linked to already existing ones ( the realized derivation ) , into the shared forest whereas using 4w</definiens>
			</definition>
			<definition id="1">
				<sentence>We used S as the starting symbol of the grammar and n is the length of the initial string .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the length of the initial string</definiens>
			</definition>
			<definition id="2">
				<sentence>where γ ( N ) is the node of the tree γ where the derivation takes place9 ) .</sentence>
				<definiendum id="0">γ ( N )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Given this item , we start the opposite process , called “descent” , which use the available data gathered by the climbing ( the derivation starting nodes , the argumental position marked by an index on nodes in TAG gram8The first phase is the generation of the set of rules , ( Vijay-Shanker and Weir , 1993 ) , and the second one is the forest traversal ( Lang , 1992 ) .</sentence>
				<definiendum id="0">Vijay-Shanker</definiendum>
				<definiens id="0">use the available data gathered by the climbing ( the derivation starting nodes , the argumental position marked by an index on nodes in TAG gram8The first phase is the generation of the set of rules</definiens>
			</definition>
</paper>

		<paper id="1313">
			<definition id="0">
				<sentence>Radiobots are a general class of dialogue systems meant to speak over the radio in military simulations .</sentence>
				<definiendum id="0">Radiobots</definiendum>
				<definiens id="0">a general class of dialogue systems meant to speak over the radio in military simulations</definiens>
			</definition>
			<definition id="1">
				<sentence>Our most extended effort to date is the Radiobot-CFF system , which engages in “call for fire” dialogues to train artillery observers within a virtual reality training simulation .</sentence>
				<definiendum id="0">Radiobot-CFF system</definiendum>
				<definiens id="0">engages in “call for fire” dialogues to train artillery observers within a virtual reality training simulation</definiens>
			</definition>
			<definition id="2">
				<sentence>A Dialogue Manager processes the tagged output , sending a reply to the FO ( via a template-based Generator ) and , when necessary , a message to the artillery simulator FireSim XXI1 to make decisions on what type of fire to send .</sentence>
				<definiendum id="0">Dialogue Manager</definiendum>
				<definiens id="0">processes the tagged output , sending a reply to the FO ( via a template-based Generator ) and , when necessary , a message to the artillery simulator FireSim XXI1 to make decisions on what type of fire to send</definiens>
			</definition>
			<definition id="3">
				<sentence>Mission Information : Observer Coordinates Situation Report Identification Warning Order Method of Control Method of Engagement Target Location Target Description End of Mission Confirming Information : Message to Observer Shot Splash Rounds Complete Intel Report Other Requests : Radio Check Say Again Status Standby Command Figure 2 : FO Dialogue Moves The dialogue moves that provide information include those in which the FOs transmit their Observer Coordinates ( grid location on a map ) , a generic Situation Report , or one of the various components of a fire mission request ranging from call sign Identification to final End of Mission .</sentence>
				<definiendum id="0">Mission Information</definiendum>
				<definiendum id="1">Observer Coordinates</definiendum>
				<definiens id="0">provide information include those in which the FOs transmit their</definiens>
			</definition>
			<definition id="4">
				<sentence>Identification : steel one nine this is gator niner one fdc id : steel one nine fo id : gator niner one Warning Order : adjust fire polar method of fire : adjust fire method of location : polar Figure 4 : Example Dialogue Moves and Parameters The Radiobot-CFF dialogue manager’s information state consists of five classes of informational components , defined by their role in the dialogue and their level of accessibility to the user .</sentence>
				<definiendum id="0">Identification</definiendum>
				<definiens id="0">adjust fire polar method of fire : adjust fire method of location : polar Figure 4 : Example Dialogue Moves and Parameters The Radiobot-CFF dialogue manager’s information state consists of five classes of informational components , defined by their role in the dialogue and their level of accessibility to the user</definiens>
			</definition>
</paper>

		<paper id="1511">
			<definition id="0">
				<sentence>Our paper aims at capturing the distribution of negative polarity items ( NPIs ) within lexicalized Tree Adjoining Grammar ( LTAG ) .</sentence>
				<definiendum id="0">NPIs</definiendum>
			</definition>
			<definition id="1">
				<sentence>( 10 ) john ( x ) , l2 : always ( 3 ) , l1 : laugh ( x ) , 3 ≥ l1 We assume a scope window for quantifiers specifying an upper boundary MAXS ( ‘maximal scope’ ) and a lower boundary MINS ( ‘minimal scope’ ) for the nuclear scope .</sentence>
				<definiendum id="0">MAXS</definiendum>
				<definiens id="0">laugh ( x ) , 3 ≥ l1 We assume a scope window for quantifiers specifying an upper boundary</definiens>
			</definition>
			<definition id="2">
				<sentence>A quantifer such as jeden is then ruled out due to two semantic constraints it contributes : its semantic content is a subexpression of MAXS ( constraint 3 ≥ l3 ) and MINS is a subexpression of its nuclear scope ( constraint 6 ≥ l2 ) .</sentence>
				<definiendum id="0">MINS</definiendum>
			</definition>
			<definition id="3">
				<sentence>The crucial criterion for an NPI is the requirement to be in the scope of a negation that is semantically in the same finite clause such that no quantifier can scopally intervene between negation and NPI .</sentence>
				<definiendum id="0">NPI</definiendum>
				<definiens id="0">the requirement to be in the scope of a negation that is semantically in the same finite clause such that no quantifier can scopally intervene between negation and NPI</definiens>
			</definition>
</paper>

		<paper id="1417">
			<definition id="0">
				<sentence>The discourse generation process involves three modules : a qualitative causal probabilistic domain model , a normative argument generator , and a genrespecific discourse grammar .</sentence>
				<definiendum id="0">discourse generation process</definiendum>
				<definiens id="0">a qualitative causal probabilistic domain model</definiens>
			</definition>
			<definition id="1">
				<sentence>The argument generator returns a structured representation of an argument in which the communicative function of information , e.g. , as data or warrant , is identified .</sentence>
				<definiendum id="0">argument generator</definiendum>
				<definiens id="0">returns a structured representation of an argument in which the communicative function of information , e.g. , as data or warrant , is identified</definiens>
			</definition>
			<definition id="2">
				<sentence>On the other hand , autosomal recessive inheritance , an inheritance pattern where inheriting two mutated alleles ( one from each parent ) is usually necessary to cause health problems , is characterized by zero product synergy ( X 0 ) ; A and B have zero product synergy with respect to state V C of C , X 0 ( { state ( A , V A ) , state ( B , V B ) } , state ( C , V C ) ) , if the state of A reaching a threshold V A and the state of B reaching a threshold V B makes it more likely that the state of C reaches V C .</sentence>
				<definiendum id="0">V A )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Thanks to the regularities in this domain and in this genre , the grammar consists of a small number of rules .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiens id="0">consists of a small number of rules</definiens>
			</definition>
			<definition id="4">
				<sentence>Argument for decrease in belief to unlikely that state of causal variable is at or over threshold value , based on absence of predicted effect : An argument for the claim that there has been a decrease in belief , from time T 1 to T 2 , to the belief at T 2 that it is unlikely that state ( A , V A ) holds , consists of the ( newly acquired ) data that it is unlikely that state ( C , V Ci ) holds for all V Ci $ V C , where the warrant is a positive influence relation S + ( state ( A , V A ) , state ( C , V C ) ) .</sentence>
				<definiendum id="0">V Ci )</definiendum>
				<definiendum id="1">warrant</definiendum>
				<definiendum id="2">state ( A , V A )</definiendum>
				<definiens id="0">holds for all V Ci $ V C , where the</definiens>
			</definition>
			<definition id="5">
				<sentence>Letters CF and WS had 23 and 25 segments , respectively , where a segment is defined as a unit fulfilling one of the above functions , or a non-argument-related function .</sentence>
				<definiendum id="0">Letters CF</definiendum>
			</definition>
			<definition id="6">
				<sentence>Reorder is a measure of acceptability of ordering .</sentence>
				<definiendum id="0">Reorder</definiendum>
				<definiens id="0">a measure of acceptability of ordering</definiens>
			</definition>
</paper>

		<paper id="1707">
			<definition id="0">
				<sentence>Online newspapers are an interesting source of textual data on the Web because they are continuously updated and they usually publish articles reviewed through a full editorial 2 http : //wacky.sslmit.unibo.it 3 http : //www-igm.univ-mlv.fr/~unitex/ 43 process which ensures ( a certain ) quality of the text .</sentence>
				<definiendum id="0">Online newspapers</definiendum>
				<definiens id="0">an interesting source of textual data on the Web because they are continuously updated and they usually publish articles reviewed through a full editorial 2 http : //wacky.sslmit.unibo.it 3 http : //www-igm.univ-mlv.fr/~unitex/ 43 process which ensures ( a certain ) quality of the text</definiens>
			</definition>
			<definition id="1">
				<sentence>Example of RSS feeds proposed by Reuters ( left ) and the New York Times ( right ) 44 Figure 2 shows two lists of RSS proposed by Reuters and the New York Times respectively .</sentence>
				<definiendum id="0">Reuters</definiendum>
				<definiens id="0">lists of RSS proposed by Reuters and the New York Times respectively</definiens>
			</definition>
			<definition id="2">
				<sentence>In S. Granger and S. Petch-Tyson ( eds ) , Extending the scope of corpus-based research : new applications , new challenges , Rodopi , Amsterdam , pp .</sentence>
				<definiendum id="0">S. Petch-Tyson</definiendum>
			</definition>
</paper>

		<paper id="1801">
</paper>

		<paper id="3208">
			<definition id="0">
				<sentence>The WordFrame model ( Wicentowski , 2004 ) uses inflection-root pairs , where unseen inflections are transformed into their corresponding root forms .</sentence>
				<definiendum id="0">WordFrame model</definiendum>
				<definiens id="0">unseen inflections are transformed into their corresponding root forms</definiens>
			</definition>
			<definition id="1">
				<sentence>61 Longest Common Substring ( LCS ) Given two strings p = p1 ... pn and q = q1 ... qm , LCS finds the longest contiguous sequence appearing in p and q. The longest common substring is not same as the longest common subsequence because the longest common subsequence need not be contiguous .</sentence>
				<definiendum id="0">LCS</definiendum>
				<definiens id="0">finds the longest contiguous sequence appearing in p</definiens>
			</definition>
			<definition id="2">
				<sentence>We then find the sequence of the edit operations performed in achieving the minimum distance alignment to transform ecand to w using SED-path algorithm we described above.6 Let cnt ( X ) be the count of X operation in the computed path .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">the count of X operation in the computed path</definiens>
			</definition>
			<definition id="3">
				<sentence>The BRIDGE system ( Ma et al. , 2003 ) processes scanned and OCRed dictionaries to reproduce electronic versions and extract information from dictionary entries .</sentence>
				<definiendum id="0">BRIDGE system</definiendum>
				<definiens id="0">Ma et al. , 2003 ) processes scanned and OCRed dictionaries to reproduce electronic versions and extract information from dictionary entries</definiens>
			</definition>
			<definition id="4">
				<sentence>type ) 1060 ( 207 ) 14 ( 5 ) 20 ( 20 ) 0 ( 0 ) Couldn’t decide 1159 13 765 15 Table 2 : Total Number and Different Types of Affixes Extracted from Two Dictionaries Using MIND affixes ( in parenthesis ) are presented for two dictionaries , CebEng and TurEng , and two data sets , the whole dictionary and 20 randomly selected pages .</sentence>
				<definiendum id="0">CebEng</definiendum>
				<definiens id="0">Total Number and Different Types of Affixes Extracted from Two Dictionaries Using MIND affixes ( in parenthesis ) are presented for two dictionaries ,</definiens>
			</definition>
			<definition id="5">
				<sentence>A word segmenter takes a list of suffixes , and their counts from the morphology induction system ( Linguistica or MIND ) , a headword list as a dictionary , a threshold value , and the words from a treebank .</sentence>
				<definiendum id="0">word segmenter</definiendum>
				<definiens id="0">takes a list of suffixes , and their counts from the morphology induction system ( Linguistica or MIND</definiens>
			</definition>
</paper>

		<paper id="1903">
			<definition id="0">
				<sentence>Several components along the work-flow of a typical QA system were identified : a Unit Alignment component in cross-language environments and a Query Expansion component for the Question Analysis task ; a Unit Processor and a Query Generator component for the Information Retrieval task ; a Mention Chain component for the Answer Extraction task and a Scoring Strategy for the Answer Selection task .</sentence>
				<definiendum id="0">Query Expansion component</definiendum>
				<definiendum id="1">Mention</definiendum>
				<definiens id="0">Chain component for the Answer Extraction task and a Scoring Strategy for the Answer Selection task</definiens>
			</definition>
			<definition id="1">
				<sentence>The Unit Processor covers the abovementioned aspects : it takes as input an InformationUnit ( i.e. , a raw text document ) and it either reduces it to a set of new units ( i.e. , sentences ) , or it annotates the unit at different levels ( i.e. , named entities , grammatical relations ) .</sentence>
				<definiendum id="0">Unit Processor</definiendum>
				<definiens id="0">covers the abovementioned aspects : it takes as input an InformationUnit ( i.e. , a raw text document ) and it either reduces it to a set of new units ( i.e. , sentences ) , or it annotates the unit at different levels</definiens>
			</definition>
			<definition id="2">
				<sentence>Even more , the Query Generator relies on an abstract description of the search engine , too , and can adapt the IRQuery according to either a boolean or a ranked search engine .</sentence>
				<definiendum id="0">Query Generator</definiendum>
			</definition>
			<definition id="3">
				<sentence>A mention chain contains all answers sharing a common normalized representation , determined either through the string similarity of the answers only or by additionally employing context entailment measures .</sentence>
				<definiendum id="0">mention chain</definiendum>
				<definiens id="0">contains all answers sharing a common normalized representation , determined either through the string similarity of the answers only or by additionally employing context entailment measures</definiens>
			</definition>
			<definition id="4">
				<sentence>“Extensibility is a system design principle where the implementation takes into consideration future growth .</sentence>
				<definiendum id="0">“Extensibility</definiendum>
				<definiens id="0">a system design principle where the implementation takes into consideration future growth</definiens>
			</definition>
			<definition id="5">
				<sentence>( 0.8 ) translations with a satisfactory degree of resemblance to a natural language utterance ( i.e. linguistically well-formedness ) , given by a threshold on the language model ranking , are aligned based on several filters : backpropagation dictionary filter based on MRD ( machine readable dictionaries ) , PoS filter based on statistical part-of-speech taggers , and cognates filter based on string similarity measures ( dice coefficient and LCSR ( lowest common substring ratio ) ) .</sentence>
				<definiendum id="0">LCSR</definiendum>
				<definiens id="0">machine readable dictionaries ) , PoS filter based on statistical part-of-speech taggers , and cognates filter based on string similarity measures ( dice coefficient</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus our expanded example has gained several more expanded words as follows : { Nipponese , commit , place , put } In the ideal case , a Questions Answering System ( QAS ) will deliver correct answers and knows that they are correct , i.e. , it can deliver a proof of the correctness of the answers .</sentence>
				<definiendum id="0">Questions Answering System</definiendum>
			</definition>
			<definition id="7">
				<sentence>This URL links to the Web Credibility Project of the Stanford Persuasive Technology Lab .</sentence>
				<definiendum id="0">URL</definiendum>
			</definition>
			<definition id="8">
				<sentence>Thus , the credibility of an answer is a complex value determined through composition of component-related credibility values .</sentence>
				<definiendum id="0">credibility of an answer</definiendum>
				<definiens id="0">a complex value determined through composition of component-related credibility values</definiens>
			</definition>
			<definition id="9">
				<sentence>The Data-Model implements credibility properties as decision rules over instantiated meta information taking into account either static or dynamic meta data .</sentence>
				<definiendum id="0">Data-Model</definiendum>
				<definiens id="0">implements credibility properties as decision rules over instantiated meta information taking into account either static or dynamic meta data</definiens>
			</definition>
</paper>

		<paper id="2111">
			<definition id="0">
				<sentence>In English , for instance , they are introduced by for if the VP denotes a state or a process and by in if the VP denotes an accomplishment .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">a state or a process and by in if the VP denotes an accomplishment</definiens>
			</definition>
			<definition id="1">
				<sentence>The PP [ for/per/da ] adjuncts select a VP which denotes an unbounded temporal object and specify the duration of the V-time.7 ( 34 ) a0a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a2 H a12 S a12 C a0a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a2 unbd-temp-obj INDEX a21 index RESTR a22a0a0 a23 a0 a0 a24 a0a1 a1 a2 incl-rel INST a21 TIME a1 a8a9 a9 a11 a25 a0 a0 a27 a0 a0 a28 TIMES a0 ... , a1 a1 EXTENT a2 a3a5a4 a8a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a11 COMPS a0 a1 CONTENT a2 a3a6a4 a8a10a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a11 The restricton to unbounded temporal objects accounts for the fact that these adjuncts combine with states and processes , but not with accomplishments or achievements .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">an unbounded temporal object and specify the duration of the V-time.7 ( 34 ) a0a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a2 H a12 S a12 C a0a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a1 a2 unbd-temp-obj INDEX a21 index RESTR a22a0a0 a23 a0 a0 a24 a0a1 a1 a2 incl-rel INST a21 TIME a1 a8a9 a9 a11 a25 a0 a0 a27 a0 a0 a28 TIMES a0 ... , a1 a1 EXTENT a2 a3a5a4 a8a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a11 COMPS a0 a1 CONTENT a2 a3a6a4 a8a10a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a9 a11 The restricton to unbounded temporal objects accounts for the fact that these adjuncts combine with states and processes , but not with accomplishments or achievements</definiens>
			</definition>
			<definition id="2">
				<sentence>The floating PP [ in ] adjuncts select a VP which denotes a bounded temporal object and specify the duration of the V-time .</sentence>
				<definiendum id="0">floating PP</definiendum>
				<definiendum id="1">VP</definiendum>
				<definiens id="0">a bounded temporal object and specify the duration of the V-time</definiens>
			</definition>
</paper>

		<paper id="3107">
			<definition id="0">
				<sentence>A parallel corpus can be defined as a set ∗This work has been supported by the Spanish Projects JCCM ( PBI-05-022 ) and HERMES 05/06 ( Vic .</sentence>
				<definiendum id="0">parallel corpus</definiendum>
			</definition>
			<definition id="1">
				<sentence>EDAs , as well as genetics algorithms ( Michalewicz , 1996 ) , are population-based evolutionary algorithms but , instead of using genetic operators are based on the estimation/learning and posterior sampling of a probability distribution , which relates the variables or genes forming and individual or chromosome .</sentence>
				<definiendum id="0">EDAs</definiendum>
				<definiendum id="1">probability distribution</definiendum>
				<definiens id="0">relates the variables or genes forming and individual or chromosome</definiens>
			</definition>
			<definition id="2">
				<sentence>Since the quality of the population should be improved in each step , only the s fittest individuals are selected to be included in the dataset used to learn the probability distribution Pr ( a1 , ... , aJ ) , in this way we try to discover the common regularities among good individuals .</sentence>
				<definiendum id="0">aJ )</definiendum>
				<definiens id="0">individuals are selected to be included in the dataset used to learn the probability distribution Pr ( a1 , ... ,</definiens>
			</definition>
			<definition id="3">
				<sentence>As a result , the computational resources 1The symbols in this formula are : J ( the length of e ) , I ( the length of f ) , ei ( the i-th word in eI1 ) , e0 ( the NULL word ) , φi ( the fertility of ei ) , τik ( the k-th word produced by ei in a ) , piik ( the position of τik in f ) , ρi ( the position of the first fertile word to the left of ei in a ) , cρi ( the ceiling of the average of all piρik for ρi , or 0 if ρi is undefined ) .</sentence>
				<definiendum id="0">ei</definiendum>
				<definiendum id="1">piik</definiendum>
				<definiens id="0">the length of e ) , I ( the length of f )</definiens>
				<definiens id="1">the k-th word produced by ei in a )</definiens>
				<definiens id="2">the position of τik in f )</definiens>
			</definition>
			<definition id="4">
				<sentence>The test corpus consists of 447 English-French sentences .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiens id="0">consists of 447 English-French sentences</definiens>
			</definition>
</paper>

		<paper id="1502">
			<definition id="0">
				<sentence>2 eXtensible MetaGrammar ( XMG ) By opposition to other metagrammatical frameworks , XMG ( Duchier et al. , 2004 ) uses an expressive though simple language , enabling a monotonic description of a real scale grammar .</sentence>
				<definiendum id="0">eXtensible MetaGrammar ( XMG</definiendum>
				<definiendum id="1">XMG</definiendum>
				<definiens id="0">Duchier et al. , 2004 ) uses an expressive though simple language , enabling a monotonic description of a real scale grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>For instance the following tree descriptions on the right of the arrow are associated with the names stated on the left of the arrow2 : ( 1 ) a. CanonicalSubject → S N↓ V b. RelativisedSubject → N N* S N↓ V c. VerbalForm → S Vdiamondmath Naming is the main device that allows the grammar writer to express and to take advantage of the structure sharing axis mentioned above .</sentence>
				<definiendum id="0">Vdiamondmath Naming</definiendum>
				<definiens id="0">the names stated on the left of the arrow2 : ( 1 ) a. CanonicalSubject → S N↓ V b. RelativisedSubject → N N* S N↓ V c. VerbalForm → S</definiens>
			</definition>
			<definition id="2">
				<sentence>Red is the colour used to label nodes that can not be merged with any other node .</sentence>
				<definiendum id="0">Red</definiendum>
				<definiens id="0">the colour used to label nodes that can not be merged with any other node</definiens>
			</definition>
			<definition id="3">
				<sentence>Overall language dependent constraints handle cases where the information independently specified in different fragments may interact .</sentence>
				<definiendum id="0">Overall language dependent constraints</definiendum>
				<definiens id="0">cases where the information independently specified in different fragments may interact</definiens>
			</definition>
			<definition id="4">
				<sentence>Note that the XMG’s virtual machine uses the structure sharing technique for memory management , i.e. data are represented by a pair pattern – environment in which to interpret it .</sentence>
				<definiendum id="0">virtual machine</definiendum>
				<definiens id="0">uses the structure sharing technique for memory management</definiens>
			</definition>
			<definition id="5">
				<sentence>As a first approximation , let us imagine that we refer to a node x in a model by means of a 5-tuple Nix = ( Eq , Up , Down , Left , Right ) where i is an integer associated with x and Eq ( respectively Up , Down , Left , Right ) denotes the set of nodes8 in the description which are equal , ( respectively above , below , left , and right ) of x. Then we can convert the relations between nodes of our description language into constraints on sets of integer .</sentence>
				<definiendum id="0">Eq</definiendum>
				<definiendum id="1">Right )</definiendum>
				<definiens id="0">the set of nodes8 in the description which are equal , ( respectively above , below , left</definiens>
			</definition>
			<definition id="6">
				<sentence>RB ∈ VφB ( c ) where VφB represents the black nodes in a model , i.e. VφB = Vφ ∩VB .</sentence>
				<definiendum id="0">RB ∈ VφB ( c</definiendum>
				<definiendum id="1">VφB</definiendum>
				<definiens id="0">the black nodes in a model</definiens>
			</definition>
			<definition id="7">
				<sentence>Thus , we have seen that Constraint Programming offers an efficient and relatively natural way of representing syntactic constraints , as ”all” that has to be done is to find an adequate node representation in terms of sets of nodes , then declare the constraints associated with these sets , and finally use a search strategy to compute the solutions .</sentence>
				<definiendum id="0">Constraint Programming</definiendum>
				<definiens id="0">offers an efficient and relatively natural way of representing syntactic constraints , as ”all” that has to be done is to find an adequate node representation in terms of sets of nodes</definiens>
			</definition>
			<definition id="8">
				<sentence>The system has been used successfully to produce core TAG ( Crabb´e , 2005b ) and Interaction Grammar ( Perrier , 2003 ) for French along with a core French TAG augmented with semantics ( Gardent , 2006 ) .</sentence>
				<definiendum id="0">Interaction Grammar</definiendum>
			</definition>
			<definition id="9">
				<sentence>The Metagrammar Compiler : An NLP Application with a Multiparadigm Architecture .</sentence>
				<definiendum id="0">Metagrammar Compiler</definiendum>
			</definition>
</paper>

		<paper id="1663">
			<definition id="0">
				<sentence>EuroWordNet ( Vossen , 1998 ) is a multilingual lexical database with wordnets for several European languages , which are structured as the Princeton WordNet .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
				<definiens id="0">a multilingual lexical database with wordnets for several European languages</definiens>
			</definition>
			<definition id="1">
				<sentence>The Princeton WordNet contains information about nouns , verbs , adjectives and adverbs in English and is organized around the notion of a synset .</sentence>
				<definiendum id="0">Princeton WordNet</definiendum>
				<definiens id="0">contains information about nouns , verbs , adjectives and adverbs in English and is organized around the notion of a synset</definiens>
			</definition>
			<definition id="2">
				<sentence>• spBNC ( McCarthy , 2001 ) : This knowledge resource contains the selectional preferences acquired from the BNC .</sentence>
				<definiendum id="0">spBNC</definiendum>
				<definiens id="0">contains the selectional preferences acquired from the BNC</definiens>
			</definition>
			<definition id="3">
				<sentence>• MCR ( Atserias et al. , 2004 ) : This knowledge resource uses the direct relations included in MCR .</sentence>
				<definiendum id="0">MCR</definiendum>
				<definiendum id="1">knowledge resource</definiendum>
				<definiens id="0">uses the direct relations included in MCR</definiens>
			</definition>
			<definition id="4">
				<sentence>TFIDF ( w , C ) = wfwmax wwfw ×log NCf w ( 1 ) Where w stands for word context , wf for the word frecuency , C for Collection ( all the corpus gathered for a particular word sense ) , and Cf stands for the Collection frecuency .</sentence>
				<definiendum id="0">TFIDF</definiendum>
				<definiens id="0">word context , wf for the word frecuency</definiens>
				<definiens id="1">all the corpus gathered for a particular word sense</definiens>
			</definition>
			<definition id="5">
				<sentence>Furthermore , the combination of TSWEB and MCR-spBNC ( TSWEB+MCR-spBNC ) outperforms both resources individually indicating that both knowledge bases contain complementary information .</sentence>
				<definiendum id="0">MCR-spBNC ( TSWEB+MCR-spBNC )</definiendum>
				<definiens id="0">outperforms both resources individually indicating that both knowledge bases contain complementary information</definiens>
			</definition>
</paper>

		<paper id="2301">
</paper>

		<paper id="2909">
			<definition id="0">
				<sentence>For example , the Phrase Type indicates the syntactic type of the phrase labeled as a predicate argument and the Parse Tree Path contains the path in the parse tree between the predicate and the argument phrase , expressed as a sequence of nonterminal labels linked by direction ( up or down ) symbols , e.g. V↑VP↓NP .</sentence>
				<definiendum id="0">Phrase Type</definiendum>
				<definiens id="0">indicates the syntactic type of the phrase labeled as a predicate argument and the Parse Tree Path contains the path in the parse tree between the predicate and the argument phrase , expressed as a sequence of nonterminal labels linked by direction ( up or down ) symbols</definiens>
			</definition>
			<definition id="1">
				<sentence>A treekernel function over t1 and t2 is Kt ( t1 , t2 ) =summationtext n1∈Nt1 summationtext n2∈Nt2 ∆ ( n1 , n2 ) , where Nt1 and Nt2 are the sets of the t1’s and t2’s nodes , respectively .</sentence>
				<definiendum id="0">treekernel function</definiendum>
				<definiendum id="1">Nt2</definiendum>
			</definition>
			<definition id="2">
				<sentence>In turn ∆ ( n1 , n2 ) = summationtext|F|i=1 λl ( fi ) Ii ( n1 ) Ii ( n2 ) , where 0 ≤ λ ≤ 1 and l ( fi ) is the height of the subtree fi .</sentence>
				<definiendum id="0">fi )</definiendum>
				<definiens id="0">the height of the subtree fi</definiens>
			</definition>
			<definition id="3">
				<sentence>2 ) Kpr ( e1 , e2 ) = Kp ( v11 , v12 ) +Kp ( v21 , v22 ) −Kp ( v11 , v22 ) −Kp ( v21 , v12 ) , where vji is the j-th feature vector of the pair ei and Kp is the polynomial kernel applied to such vectors .</sentence>
				<definiendum id="0">vji</definiendum>
				<definiendum id="1">Kp</definiendum>
				<definiens id="0">the j-th feature vector of the pair ei and</definiens>
				<definiens id="1">the polynomial kernel applied to such vectors</definiens>
			</definition>
			<definition id="4">
				<sentence>The real drawback is the computational complexity of working with SVMs , thus the design of fast algorithm is an interesting future work .</sentence>
				<definiendum id="0">real drawback</definiendum>
				<definiens id="0">the computational complexity of working with SVMs</definiens>
			</definition>
</paper>

		<paper id="3317">
			<definition id="0">
				<sentence>The architecture uses a natural language processing module to extract entities , dependencies and simple semantic relationships from texts , and then feeds these features into a probabilistic reasoning module which combines the semantic relationships extracted by the NLP module to form new semantic relationships .</sentence>
				<definiendum id="0">architecture</definiendum>
				<definiens id="0">uses a natural language processing module to extract entities , dependencies and simple semantic relationships from texts</definiens>
			</definition>
			<definition id="1">
				<sentence>We have created a prototype software system called BioLiterate , which applies dependency parsing and advanced probabilistic inference to the problem of combining semantic relationships extracted from biomedical texts , have tested this system via experimentation on research abstracts in the domain of the molecular genetics of oncology .</sentence>
				<definiendum id="0">BioLiterate</definiendum>
				<definiens id="0">applies dependency parsing and advanced probabilistic inference to the problem of combining semantic relationships extracted from biomedical texts</definiens>
			</definition>
			<definition id="2">
				<sentence>The nominalization tagger uses a set of rules based on word morphology and immediate context .</sentence>
				<definiendum id="0">nominalization tagger</definiendum>
				<definiens id="0">uses a set of rules based on word morphology and immediate context</definiens>
			</definition>
			<definition id="3">
				<sentence>The dependency extractor component carries out dependency grammar parsing via a customized version of the open-source Sleator and Temperley link parser ( 1993 ) .</sentence>
				<definiendum id="0">dependency extractor component</definiendum>
			</definition>
			<definition id="4">
				<sentence>PLN is a comprehensive uncertain inference framework that combines probabilistic and heuristic truth value estimation formulas within a knowledge representation framework capable of expressing general logical information , and possesses flexible inference control heuristics including forward-chaining , backward-chaining and reinforcement-learning-guided approaches .</sentence>
				<definiendum id="0">PLN</definiendum>
				<definiens id="0">a comprehensive uncertain inference framework that combines probabilistic and heuristic truth value estimation formulas within a knowledge representation framework capable of expressing general logical information , and possesses flexible inference control heuristics including forward-chaining , backward-chaining and reinforcement-learning-guided approaches</definiens>
			</definition>
			<definition id="5">
				<sentence>The PLN component receives the logical relationships output by the semantic mapper , and performs reasoning operations on them , with the aim at arriving at new conclusions implicit in the set of relationships fed to it .</sentence>
				<definiendum id="0">PLN component</definiendum>
				<definiens id="0">receives the logical relationships output by the semantic mapper</definiens>
			</definition>
			<definition id="6">
				<sentence>Evaluation is the relation between a predicate and its arguments ; e.g. Eval subj ( inhib , DLC ) means that the subj predicate holds when applied to the list ( inhib , DLC ) .</sentence>
				<definiendum id="0">Evaluation</definiendum>
				<definiendum id="1">e.g. Eval subj</definiendum>
				<definiendum id="2">DLC )</definiendum>
				<definiens id="0">the relation between a predicate and its arguments ;</definiens>
			</definition>
			<definition id="7">
				<sentence>PLN is an uncertain inference system , which means that each of the terms and relationships used as premises , conclusions or intermediaries in PLN inference come along with uncertain truth values .</sentence>
				<definiendum id="0">PLN</definiendum>
				<definiens id="0">an uncertain inference system</definiens>
			</definition>
			<definition id="8">
				<sentence>Relationships used in premises along the trail , but not produced as conclusions along the trail , were introduced into the trail via the system looking in its knowledge base to obtain the previously computed truth value of a relationship , which was found via prior knowledge or a prior inference trail .</sentence>
				<definiendum id="0">Relationships</definiendum>
				<definiens id="0">was found via prior knowledge or a prior inference trail</definiens>
			</definition>
			<definition id="9">
				<sentence>In our work with BioLiterate so far , we have identified a number of examples where PLN is able to draw biological conclusions by combining simple semantic relationships extracted from different biological research abstracts .</sentence>
				<definiendum id="0">PLN</definiendum>
				<definiens id="0">able to draw biological conclusions by combining simple semantic relationships extracted from different biological research abstracts</definiens>
			</definition>
			<definition id="10">
				<sentence>Novamente : An Integrative Approach to Artificial General Intelligence .</sentence>
				<definiendum id="0">Novamente</definiendum>
			</definition>
			<definition id="11">
				<sentence>Textpresso : An Ontology-Based Information Retrieval and Extraction System for Biological Literature .</sentence>
				<definiendum id="0">Textpresso</definiendum>
			</definition>
			<definition id="12">
				<sentence>IntEx : A Syntactic Role Driven Protein-Protein Interaction Extractor for BioMedical Text .</sentence>
				<definiendum id="0">IntEx</definiendum>
			</definition>
</paper>

		<paper id="2703">
			<definition id="0">
				<sentence>Furthermore , these units can be easily selected , swept out or snapped to by the annotators and certain classes of annotation mistakes can be prevented by building a tool that does not permit selection of a substring which does not entirely span one or more XML elements .</sentence>
				<definiendum id="0">annotation</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the Text Mining programme ( TXM ) we have collected a corpus of abstracts and full texts of biomedical papers taken from PubMed Central , the U.S. National Institutes of Health ( NIH ) free digital archive of biomedical and life sciences journal literature3 .</sentence>
				<definiendum id="0">Text Mining programme</definiendum>
				<definiens id="0">a corpus of abstracts and full texts of biomedical papers taken from PubMed Central , the U.S. National Institutes of Health ( NIH ) free digital archive of biomedical and life sciences journal literature3</definiens>
			</definition>
			<definition id="2">
				<sentence>In our tokenisation of the astronomy data , we initially assumed a vanilla MUC-style tokenisation which gives strong weight to whitespace as a token delimiter .</sentence>
				<definiendum id="0">vanilla MUC-style tokenisation</definiendum>
				<definiens id="0">gives strong weight to whitespace as a token delimiter</definiens>
			</definition>
			<definition id="3">
				<sentence>MedPost : a part-of-speech tagger for biomedical text .</sentence>
				<definiendum id="0">MedPost</definiendum>
			</definition>
</paper>

		<paper id="2713">
			<definition id="0">
				<sentence>Annotation levels are related to each other following a hierarchy of annotation levels , which reflects a theoretically grounded hierarchy of linguistic objects .</sentence>
				<definiendum id="0">Annotation levels</definiendum>
				<definiens id="0">reflects a theoretically grounded hierarchy of linguistic objects</definiens>
			</definition>
			<definition id="1">
				<sentence>The basic ( orthographic ) annotation level , representing tokens , is implemented with pointers to the character positions in the hub corpus .</sentence>
				<definiendum id="0">basic</definiendum>
				<definiens id="0">orthographic ) annotation level , representing tokens , is implemented with pointers to the character positions in the hub corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>News MEANING Annotation Format Callisto Lucene AIF format Manual annotation Automatic annotation TextPro TextPro format Indexing Data Base Conversion MEANING Browser I-CAB Corpus As one can see in the above figure , two different annotation processes ( automatic and manual ) produce two different formats which must be converted and integrated into MAF in order to be accessed by the MEANING Browser ( or any other NLP tool ) .</sentence>
				<definiendum id="0">Browser</definiendum>
				<definiens id="0">News MEANING Annotation Format Callisto Lucene AIF format Manual annotation Automatic annotation TextPro TextPro format Indexing Data Base Conversion MEANING Browser I-CAB Corpus As one can see in the above figure , two different annotation processes ( automatic and manual ) produce two different formats which must be converted and integrated into MAF in order to be accessed by the MEANING</definiens>
			</definition>
			<definition id="3">
				<sentence>Format TextPro takes a raw text as input and carries out basic processing tasks such as tokenization , mor78 phological analysis , PoS tagging , lemmatization , and multiword recognition .</sentence>
				<definiendum id="0">Format TextPro</definiendum>
				<definiens id="0">takes a raw text as input and carries out basic processing tasks such as tokenization , mor78 phological analysis , PoS tagging , lemmatization , and multiword recognition</definiens>
			</definition>
			<definition id="4">
				<sentence>The Callisto manual annotation tool produces a coding format called AIF ( Atlas Interchange Format ) , which implements a stand-off XML annotation scheme .</sentence>
				<definiendum id="0">Callisto manual annotation tool</definiendum>
				<definiens id="0">implements a stand-off XML annotation scheme</definiens>
			</definition>
			<definition id="5">
				<sentence>Each annotation level is mapped into a table , where rows represent instances of the relevant linguistic object ( e.g. words ) , and columns represent its attributes ( e.g. lemma , PoS , etc ) .</sentence>
				<definiendum id="0">annotation level</definiendum>
				<definiens id="0">rows represent instances of the relevant linguistic object ( e.g. words ) , and columns represent its attributes ( e.g. lemma , PoS , etc )</definiens>
			</definition>
</paper>

		<paper id="2604">
			<definition id="0">
				<sentence>On the one hand , we use Latent Semantic Indexing ( LSI ) ( Deerwester et al. , 1990 ) , which is a variant of the vector space model ( VSM ) ( Salton and McGill , 1983 ) , in order to obtain the vector representation of documents .</sentence>
				<definiendum id="0">VSM )</definiendum>
				<definiens id="0">a variant of the vector space model</definiens>
			</definition>
			<definition id="1">
				<sentence>LSI , which is based on Singular Value Decomposition ( SVD ) of matrices , has showed to have the ability to extract the relations among words and documents by means of their context of use , and has been successfully applied to Information Retrieval tasks .</sentence>
				<definiendum id="0">LSI</definiendum>
				<definiens id="0">based on Singular Value Decomposition ( SVD ) of matrices , has showed to have the ability to extract the relations among words and documents by means of their context of use</definiens>
			</definition>
			<definition id="2">
				<sentence>The most widely used is Reuters-21578 collection , which is a multiclass ( 135 categories ) and multilabel ( the mean number of categories assigned to a document is 1.2 ) dataset .</sentence>
				<definiendum id="0">multilabel</definiendum>
			</definition>
			<definition id="3">
				<sentence>Precision ( Prec ) is the percentageofdocumentscorrectlyclassifiedintoa given category , and recall ( Rec ) is the percentage of documents belonging to a given category that are indeed classified into it .</sentence>
				<definiendum id="0">Precision ( Prec )</definiendum>
				<definiens id="0">the percentageofdocumentscorrectlyclassifiedintoa given category , and recall ( Rec ) is the percentage of documents belonging to a given category that are indeed classified into it</definiens>
			</definition>
			<definition id="4">
				<sentence>Sebastiani ( Sebastiani , 2002 ) presents a table wherelistsresultsofexperimentsforvarioustraining/testing divisions of Reuters .</sentence>
				<definiendum id="0">Sebastiani</definiendum>
				<definiens id="0">presents a table wherelistsresultsofexperimentsforvarioustraining/testing divisions of Reuters</definiens>
			</definition>
			<definition id="5">
				<sentence>The SVD technique used by LSI consists in factoring term-document matrix M into the product of three matrices , M = UΣV T where Σ is a diagonal matrix of singular values in non-increasing order , andU andV are orthogonal matrices of singular vectors ( term and document vectors , respectively ) .</sentence>
				<definiendum id="0">Σ</definiendum>
				<definiens id="0">a diagonal matrix of singular values in non-increasing order , andU andV are orthogonal matrices of singular vectors ( term and document vectors , respectively )</definiens>
			</definition>
			<definition id="6">
				<sentence>Fordocumentcategorizationpurposes ( Dumais , 2004 ) , the testing document q is also projected to the p-dimensional space , qp = qTUpΣ−1p , and the cosine is usually calculated to measure the semantic similarity between training and testing document vectors .</sentence>
				<definiendum id="0">Fordocumentcategorizationpurposes</definiendum>
			</definition>
			<definition id="7">
				<sentence>algorithm ( k-NN ) k-NN is a distance based classification approach .</sentence>
				<definiendum id="0">algorithm ( k-NN ) k-NN</definiendum>
				<definiens id="0">a distance based classification approach</definiens>
			</definition>
			<definition id="8">
				<sentence>We use one of the most widely used training/testing divisions , the “ModApte” split , in which 75 % of the documents ( 9,603documents ) areselectedfortrainingandthe remaining 25 % ( 3299 documents ) to test the accuracy of the classifier .</sentence>
				<definiendum id="0">“ModApte” split</definiendum>
				<definiendum id="1">9,603documents</definiendum>
				<definiens id="0">documents ) to test the accuracy of the classifier</definiens>
			</definition>
			<definition id="9">
				<sentence>Whenthereisalownumberofdocumentsavailable for a given category , the power of LSI gets limited to create a space that reflects interesting properties of the data .</sentence>
				<definiendum id="0">LSI</definiendum>
			</definition>
			<definition id="10">
				<sentence>ARIST , AnnualReviewofInformationScienceTechnology , 38 , 189–230 , ( 2004 ) Freund , Y. and Schapire , R.E. : A Short Introduction to Boosting .</sentence>
				<definiendum id="0">R.E.</definiendum>
			</definition>
</paper>

		<paper id="0502">
			<definition id="0">
				<sentence>Japanese The Lexeed Semantic Database of Japanese is a machine readable dictionary that covers the most familiar open class words in Japanese as measured by a series of psycholinguistic experiments ( Kasahara et al. , 2004 ) .</sentence>
				<definiendum id="0">Lexeed Semantic Database of Japanese</definiendum>
			</definition>
			<definition id="1">
				<sentence>Lexeed consists of all open class words with a familiarity greater than or equal to five on a scale of one to seven .</sentence>
				<definiendum id="0">Lexeed</definiendum>
			</definition>
			<definition id="2">
				<sentence>We used Robust Minimal Recursion Semantics ( RMRS ) designed as part of the Deep Thought project ( Callmeier et al. , 2004 ) as the formalism for our ontological relation extraction engine .</sentence>
				<definiendum id="0">Robust Minimal Recursion Semantics ( RMRS</definiendum>
				<definiens id="0">) designed as part of the Deep Thought project ( Callmeier et al. , 2004 ) as the formalism for our ontological relation extraction engine</definiens>
			</definition>
			<definition id="3">
				<sentence>Robust Minimal Recursion Semantics is a form of flat semantics which is designed to allow deep and shallow processing to use a compatible semantic representation , with fine-grained atomic components of semantic content so shallow methods can contribute just what they know , yet with enough expressive power for rich semantic content including generalized quantifiers ( Frank , 2004 ) .</sentence>
				<definiendum id="0">Robust Minimal Recursion Semantics</definiendum>
			</definition>
			<definition id="4">
				<sentence>The representation can be underspecified in three ways : relationships can be omitted ( such as quantifiers , messages , conjunctions and so on ) ; predicate-argument relations can be omitted ; and predicate names can be simplified .</sentence>
				<definiendum id="0">predicate-argument relations</definiendum>
				<definiens id="0">quantifiers , messages , conjunctions and so on</definiens>
			</definition>
			<definition id="5">
				<sentence>∃ ( ch , cg ) : { ch ⊂ cg ; ch ∈C ( wh ) ; cg ∈C ( wg ) } ( 1 ) To test cross-linguistically , we looked up the headwords in a translation lexicon ( ALT-J/E ( Ikehara et al. , 1991 ) and EDICT ( Breen , 2004 ) ) and then did the confirmation on the set of translations ci ⊂ C ( T ( wi ) ) .</sentence>
				<definiendum id="0">ch ∈C</definiendum>
				<definiendum id="1">cg ∈C</definiendum>
				<definiens id="0">the confirmation on the set of translations ci ⊂ C ( T ( wi ) )</definiens>
			</definition>
</paper>

		<paper id="3006">
			<definition id="0">
				<sentence>( QAC3-30029-05 ) In the above example ( q1 is the rst question and q2 is follow-up question ) , system checks obligatory case elements of verb a139a144a143 ( write ) of question q1 .</sentence>
				<definiendum id="0">q1</definiendum>
				<definiendum id="1">q2</definiendum>
				<definiens id="0">the rst question and</definiens>
				<definiens id="1">follow-up question ) , system checks obligatory case elements of verb a139a144a143 ( write ) of question q1</definiens>
			</definition>
			<definition id="1">
				<sentence>In the above example , q3 is the rst question and q4 is the follow-up question .</sentence>
				<definiendum id="0">q3</definiendum>
				<definiendum id="1">q4</definiendum>
				<definiens id="0">the rst question and</definiens>
			</definition>
			<definition id="2">
				<sentence>In the above example , q5 is the rst question and q6 is the follow-up question .</sentence>
				<definiendum id="0">q5</definiendum>
				<definiendum id="1">q6</definiendum>
				<definiens id="0">the rst question and</definiens>
			</definition>
</paper>

		<paper id="1653">
			<definition id="0">
				<sentence>Recommender systems ( Resnick and Varian , 1997 ) help users select particular items ( e.g , movies , books , music , and TV programs ) that match their taste from a large number of choices by providing recommendations .</sentence>
				<definiendum id="0">Recommender systems</definiendum>
				<definiens id="0">help users select particular items ( e.g , movies , books , music , and TV programs ) that match their taste from a large number of choices by providing recommendations</definiens>
			</definition>
			<definition id="1">
				<sentence>A CF system makes recommendations to current ( active ) users by exploiting their ratings in the database .</sentence>
				<definiendum id="0">CF system</definiendum>
				<definiens id="0">makes recommendations to current ( active ) users by exploiting their ratings in the database</definiens>
			</definition>
			<definition id="2">
				<sentence>User-based CF first identifies a set of users ( neighbors ) that are similar to the active user in terms of their rating patterns in the database .</sentence>
				<definiendum id="0">User-based CF</definiendum>
				<definiens id="0">neighbors ) that are similar to the active user in terms of their rating patterns in the database</definiens>
			</definition>
			<definition id="3">
				<sentence>In contrast to CF , CBF uses the contents ( e.g. , texts , genres , authors , images , and audio ) of items to make recommendations for the active user .</sentence>
				<definiendum id="0">CBF</definiendum>
				<definiens id="0">uses the contents ( e.g. , texts , genres , authors , images , and audio ) of items to make recommendations for the active user</definiens>
			</definition>
			<definition id="4">
				<sentence>Lavrenko ( 2004 ) adopts the method of kernels to estimate probabilities : Let d be an item in the database or training data , the probability of item x is estimated as p ( x ) = 1M summationtextdp ( x|θd ) , where M is the number of items in the training data , θd is the parameter vector estimated from d , and p ( x|θd ) is the conditional probability of x given θd.3 This means that once we have defined a probability distribution p ( x|θ ) and the method of estimating θd from d , then we can assign probability p ( x ) to x and apply language modeling approaches to CF and CBF .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">θd</definiendum>
				<definiens id="0">the method of kernels to estimate probabilities : Let d be an item in the database or training data , the probability of item x is estimated as p ( x ) = 1M summationtextdp ( x|θd ) , where</definiens>
				<definiens id="1">the number of items in the training data</definiens>
				<definiens id="2">the parameter vector estimated from d</definiens>
				<definiens id="3">x|θ ) and the method of estimating θd from d , then we can assign probability p ( x ) to x and apply language modeling approaches to CF and CBF</definiens>
			</definition>
			<definition id="5">
				<sentence>In this case , ω ( w ) and µ ( u ) are the probabilities of word w and user u. Then , pω ( wx|ω ) is defined as pω ( wx|ω ) = |wx|productdisplay i=1 ω ( wxi ) = productdisplay w∈Vw ω ( w ) n ( w , wx ) ( 1 ) where n ( w , wx ) is the number of occurrences of w in wx .</sentence>
				<definiendum id="0">µ ( u )</definiendum>
				<definiendum id="1">n ( w , wx )</definiendum>
				<definiens id="0">the number of occurrences of w in wx</definiens>
			</definition>
			<definition id="6">
				<sentence>ωd ( w ) = λωPl ( w|wd ) + ( 1−λω ) Pg ( w ) ( 2 ) where Pl ( w|wd ) = n ( w , wd ) summationtext wprime n ( w prime , wd ) , Pg ( w ) =summationtext dn ( w , wd ) summationtext d summationtext wprime n ( w prime , wd ) and λω ( 0 ≤ λω ≤ 1 ) is a smoothing parameter .</sentence>
				<definiendum id="0">Pl</definiendum>
				<definiens id="0">a smoothing parameter</definiens>
			</definition>
			<definition id="7">
				<sentence>We call those implicit ratings query q. It is a set of items and is represented as q = { q1 ... qk } , where qi is an item implicitly rated by an active user and k is the size of q. We next estimate θq = { ωq , µq } .</sentence>
				<definiendum id="0">qi</definiendum>
				<definiens id="0">a set of items</definiens>
				<definiens id="1">an item implicitly rated by an active user</definiens>
				<definiens id="2">the size of q. We next estimate θq = { ωq , µq }</definiens>
			</definition>
			<definition id="8">
				<sentence>We define S ( µqi||µd ) similarly.4 Then , the score of d given qi , Sqi ( d ) is defined as Sqi ( d ) = λsS ( µqi||µd ) + ( 1−λs ) S ( ωqi||ωd ) ( 7 ) where λs ( 0 ≤ λs ≤ 1 ) is a free parameter .</sentence>
				<definiendum id="0">S ( µqi||µd</definiendum>
				<definiens id="0">the score of d given qi , Sqi ( d ) is defined as Sqi ( d ) = λsS ( µqi||µd ) + ( 1−λs ) S ( ωqi||ωd )</definiens>
				<definiens id="1">a free parameter</definiens>
			</definition>
			<definition id="9">
				<sentence>pω ( wx|αω ) = Γ ( summationtext w αωw ) Γ ( summationtextw nxw +αωw ) productdisplay w Γ ( nxw +αωw ) Γ ( αωw ) ( 9 ) 4S ( µq i||µd ) = summationtext u Pl ( u|uqi ) × log parenleftBig λµPl ( u|ud ) ( 1−λµ ) Pg ( u ) +1 parenrightBig , where Pl ( u|uqi ) = n ( u , µqi ) summationtext uprime n ( u prime , µqi ) , Pl ( u|ud ) = n ( u , ud ) summationtext uprime n ( u prime , ud ) , and Pg ( u ) = summationtext d n ( u , ud ) summationtext d summationtext uprime n ( u prime , ud ) .</sentence>
				<definiendum id="0">pω</definiendum>
				<definiendum id="1">Pl</definiendum>
				<definiens id="0">u , ud ) summationtext d summationtext uprime n ( u prime , ud )</definiens>
			</definition>
			<definition id="10">
				<sentence>451 0 1 2 3 4 5 6 7 8 9 10 0 2 4 6 8 100 1 2 3 4 5 6 7 8 9 10 nu ( n , alpha ) n alpha=1e+5alpha=38.8 alpha=16.4alpha=9.0 alpha=5.4alpha=3.3 alpha=2.0alpha=1.1 alpha=0.4alpha=1e-5 Figure 1 : Relationship between original count n and dumped count ν ( n , α ) where Γ is known as the gamma function , αωw is a parameter for word w and nxw = n ( w , wx ) .</sentence>
				<definiendum id="0">αωw</definiendum>
				<definiens id="0">451 0 1 2 3 4 5 6 7 8 9 10 0 2 4 6 8 100 1 2 3 4 5 6 7 8 9 10 nu ( n , alpha ) n alpha=1e+5alpha=38.8 alpha=16.4alpha=9.0 alpha=5.4alpha=3.3 alpha=2.0alpha=1.1 alpha=0.4alpha=1e-5 Figure 1 : Relationship between original count n and dumped count ν ( n , α ) where Γ is known as the gamma function</definiens>
				<definiens id="1">a parameter for word w and nxw = n ( w , wx )</definiens>
			</definition>
			<definition id="11">
				<sentence>pω ( wx|αω ) ∼productdisplay w ω ( w ) ˜n ( w , wx ) ( 10 ) where ˜n ( w , wx ) = αωw ( Ψ ( nxw +αωw ) −Ψ ( αωw ) ) ≡ ν ( nxw , αωw ) ( 11 ) Ψ is known as the digamma function and is similar to the natural logarithm .</sentence>
				<definiendum id="0">pω ( wx|αω )</definiendum>
			</definition>
			<definition id="12">
				<sentence>We used P @ N ( precision at rank N = the ratio of the articles edited by the user in the top-N articles ) , S @ N ( success at rank N = 1 if some top-N articles were edited by the user , else 0 ) , and R-precision ( = P @ N , where N is the number of articles edited by the user in the test data ) .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
</paper>

		<paper id="1517">
			<definition id="0">
				<sentence>D f.wi ; wj/2W STXW jwj depends onwi g RS D f.wi ; wj/2W STXW ji &lt; j g To interpret a grammar formalism as a specification for a set of dependency structures , we need to assign meaning to the relation ‘depends’ in terms of this formalism. For TAG , this can be done based on the Fundamental Hypothesis that ‘every syntactic dependency is expressed locally within a single elementary tree’ ( Frank , 2002 ) . More specifically , a derivation in a ( strongly ) lexicalized TAG can be viewed as a dependency structure as follows : The setW contains the ( occurences of ) lexical anchors involved in the derivation. For two anchors wi ; wj 2 W , wi ! wj if the elementary tree anchored atwj was substituted or adjoined into the tree anchored atwi. We then havewi RSwj ifwi precedes wj in the yield of the derived tree corresponding to the derivation. Notice that the relation ! in such a dependency structure is almost exactly the derivation tree of the underlying TAG derivation ; the only difference is that elementary trees have been replaced by their lexical anchors. Figure 1 shows a TAG grammar together with a dependency structure induced by a derivation of this grammar. Tokens in the derived string are represented by labelled nodes ; the solid arcs between the nodes represent the dependencies. An interesting feature of the dependency structure shown in Figure 1 is that it violates a standard constraint on dependency structures known as projectivity ( Marcus , 1967 ) . We introduce some terminology for non-projective dependency structures : A set T DC2 W is convex , if for no two tokens w1 ; w2 2 T , there exists a token w from W NULT such that w1 RS w RS w2. The cover of T , C.T/ , is the smallest convex set that contains T. For w 2 W , we write # w for the set of tokens in the S ; a T D B C T ; a T D B ? C B ; b C ; c D ; d . a1 a2 b2 b1 c1 c2 d2 d1 Figure 1 : TAG grammar for anbncndn , and a dependency structure induced by this grammar subtree rooted atw ( includingw itself ) . A gap in # wis a largest convex set inC. # w/NUL # w. The gap degree ofw , gd.w/ , is the number of gaps in # w. The gaps in # wpartition # winto gd.w/NUL1largest convex blocks ; we write # iw to refer to the i-th of these blocks , counted from left to right ( with respect to RS ) . The gap degree of a dependency structureisthemaximumoverthegapdegreesofits subtrees ; we writeDg for the set of all dependency structures with a gap degree of at mostg. The gap degree provides a quantitative measure for the non-projectivity of dependency structures. Well-nestedness is a qualitative property : it constrains the relative positions of disjoint subtrees. Let w1 ; w2 2 W such that # w1 and # w2 are disjoint. Four tokensw11 ; w21 2 # w1 , w12 ; w22 2 # w2 interleave , if w11 RS w12 RS w21 RS w22. A dependency structure is well-nested , if it does not contain interleaving tokens. We write Dwn for the set of all well-nested dependency structures. For illustration , consider again the dependency structure shown in Figure 1. It has gap degree 1 : a2 is the only tokenw for which # w is not convex ; the set fb1 ; c1g forms a gap in # a2. The structure is also well-nested. In contrast , the structure shown in the right half of Figure 2 is not well-nested ; the tokensb ; c ; d ; e interleave. Bodirsky et al. ( 2005 ) show that TAG induces precisely the set Dwn \D1. Multi-component TAG ( MCTAG ) extends TAG with the ability to adjoin a whole set of elementary trees ( components ) simultaneously. To answer the question , whether this extension also leads to an extended class of dependency structures , we first need to decide how we want to transfer the Fundamental Hypothesis ( Frank , 2002 ) to MCTAGs. 122 A ; a B1 C1 B2 C2 8 &lt; : B ; 1 b B ; 2 D 9 &gt; = &gt; ; 8 &lt; : C ; 1 c C ; 2 E 9 &gt; = &gt; ; D ; d E ; e Figure 2 : An MCTAG and a not well-nested dependency structure derived by it .</sentence>
				<definiendum id="0">wj/2W STXW jwj</definiendum>
				<definiendum id="1">a2</definiendum>
				<definiendum id="2">Fundamental Hypothesis</definiendum>
				<definiens id="0">to assign meaning to the relation ‘depends’ in terms of this formalism. For TAG , this can be done based on the Fundamental Hypothesis that ‘every syntactic dependency is expressed locally within a single elementary tree’</definiens>
				<definiens id="1">The setW contains the ( occurences of ) lexical anchors involved in the derivation. For two anchors wi ; wj 2 W , wi ! wj if the elementary tree anchored atwj was substituted or adjoined into the tree anchored atwi. We then havewi RSwj ifwi precedes wj in the yield of the derived tree corresponding to the derivation. Notice that the relation</definiens>
				<definiens id="2">elementary trees have been replaced by their lexical anchors. Figure 1 shows a TAG grammar together with a dependency structure induced by a derivation of this grammar. Tokens in the derived string are represented by labelled nodes ; the solid arcs between the nodes represent the dependencies. An interesting feature of the dependency structure shown in Figure 1 is that it violates a standard constraint on dependency structures known as projectivity ( Marcus , 1967 ) . We introduce some terminology for non-projective dependency structures : A set T DC2 W</definiens>
				<definiens id="3">a T D B C T ; a T D B ? C B ; b C ; c D</definiens>
				<definiens id="4">a qualitative property : it constrains the relative positions of disjoint subtrees. Let w1</definiens>
				<definiens id="5">2005 ) show that TAG induces precisely the set Dwn \D1. Multi-component TAG ( MCTAG ) extends TAG with the ability to adjoin a whole set of elementary trees ( components ) simultaneously. To answer the question , whether this extension also leads to an extended class of dependency structures</definiens>
			</definition>
			<definition id="1">
				<sentence>A ranked alphabet is a pair˘ D.˙ ; SUB/ , where˙ is an alphabet , andSUB2˙ !</sentence>
				<definiendum id="0">where˙</definiendum>
				<definiens id="0">an alphabet</definiens>
			</definition>
			<definition id="2">
				<sentence>Coupled Context-Free Grammar ( CCFG ) is a generalization of context-free grammar in which non-terminals come from a ranked alphabet , and components of a non-terminal can only be substituted simultaneously .</sentence>
				<definiendum id="0">Coupled Context-Free Grammar ( CCFG )</definiendum>
				<definiens id="0">a generalization of context-free grammar in which non-terminals come from a ranked alphabet</definiens>
			</definition>
			<definition id="3">
				<sentence>N ; T ; P ; S/ where : N is a ranked alphabet of non-terminal symbols ; T is an unranked alphabet of terminal symbols ; P is a ranked rewriting system over ESD .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">a ranked alphabet of non-terminal symbols ; T is an unranked alphabet of terminal symbols</definiens>
				<definiens id="1">a ranked rewriting system over ESD</definiens>
			</definition>
			<definition id="4">
				<sentence>u ; i/ forms a contiguous region of the sentence derived by T ] .</sentence>
				<definiendum id="0">i/</definiendum>
			</definition>
			<definition id="5">
				<sentence>E˛ , where w 2 W , and E˛ is a tuple with arity gd .</sentence>
				<definiendum id="0">E˛</definiendum>
				<definiens id="0">a tuple with arity gd</definiens>
			</definition>
</paper>

		<paper id="1206">
			<definition id="0">
				<sentence>The parsability of a sequence wi ... wj is defined as : R ( wi ... wj ) = C ( wi ... wj , OK ) C ( w i ... wj ) ( 1 ) where C ( wi ... wj ) is the number of sentences in which the sequence wi ... wj occurs , and C ( wi ... wj , OK ) is the number of sentences with a successful parse which contain the sequence .</sentence>
				<definiendum id="0">parsability of a sequence wi ... wj</definiendum>
				<definiendum id="1">C ( wi ... wj )</definiendum>
				<definiens id="0">the number of sentences in which the sequence wi ... wj occurs</definiens>
				<definiens id="1">the number of sentences with a successful parse which contain the sequence</definiens>
			</definition>
			<definition id="1">
				<sentence>Among them , one common error , and subsequently very common cause of parse failure is due to Multiword Expressions ( MWEs ) , like phrasal verbs ( break down ) , collocations ( bread and butter ) , compound nouns ( coffee machine ) , determiner-less PPs ( in hospital ) , as well as socalled “frozen expressions” ( by and large ) , as discussed by both Baldwin et al. ( 2004 ) and van Noord ( 2004 ) .</sentence>
				<definiendum id="0">MWEs</definiendum>
				<definiens id="0">collocations ( bread and butter ) , compound nouns ( coffee machine ) , determiner-less PPs ( in hospital</definiens>
			</definition>
			<definition id="2">
				<sentence>The term Multiword Expressions ( MWEs ) has been used to describe expressions for which the syntactic or semantic properties of the whole expression can not be derived from its parts ( ( Sag et al. , 2002 ) , ( Villavicencio et al. , 2005 ) ) , including a large number of related but distinct phenomena , such as phrasal verbs ( e.g. come along ) , nominal compounds ( e.g. frying pan ) , institutionalised phrases ( e.g. bread and butter ) , and many others .</sentence>
				<definiendum id="0">term Multiword Expressions</definiendum>
				<definiens id="0">used to describe expressions for which the syntactic or semantic properties of the whole expression can not be derived from its parts ( ( Sag et al. , 2002</definiens>
				<definiens id="1">phrasal verbs ( e.g. come along ) , nominal compounds ( e.g. frying pan ) , institutionalised phrases ( e.g. bread and butter</definiens>
			</definition>
			<definition id="3">
				<sentence>Therefore , given a candidate , such as the likes of , we measure the frequency of occurrence of all its permutations ( e.g. the of likes , likes the of , etc ) and we calculate the candidate’s entropy as S = − 1logN Nsummationdisplay k=1 Pi logPi ( 2 ) where Pi is the probability of occurrence of a given permutation , and N the total number of permutations .</sentence>
				<definiendum id="0">Pi</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the probability of occurrence of a given permutation , and</definiens>
			</definition>
			<definition id="4">
				<sentence>The lexicon of HPSG consists of a list of wellformed Typed Feature Structures ( TFSs ) ( Carpenter , 1992 ) , which convey the constraints on specific words by two ways : the type compatibility , and the feature-value consistency .</sentence>
				<definiendum id="0">lexicon of HPSG</definiendum>
				<definiens id="0">consists of a list of wellformed Typed Feature Structures ( TFSs ) ( Carpenter , 1992 ) , which convey the constraints on specific words by two ways : the type compatibility</definiens>
			</definition>
</paper>

		<paper id="2917">
			<definition id="0">
				<sentence>We shall assume an order ≺ or precedesequal on Σ which we shall extend to Σ∗ in the normal way by saying that u ≺ v if |u| &lt; |v| or |u| = |v| and u is lexicographically before v. A grammar is a quadruple G = 〈V , Σ , P , S〉 where Σ is a finite alphabet of terminal symbols , V 1We do not consider in this paper the complex and contentious issues around negative data .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">a finite alphabet of terminal symbols</definiens>
			</definition>
			<definition id="1">
				<sentence>is a finite alphabet of variables or non-terminals , P is a finite set of production rules , and S ∈ V is a start symbol .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">a finite alphabet of variables or non-terminals</definiens>
				<definiens id="1">a finite set of production rules , and S ∈ V is a start symbol</definiens>
			</definition>
			<definition id="2">
				<sentence>A learning algorithm A for a class of representations R , is an algorithm that computes a function from a finite sequence of strings s1 , . . . , sn to R. We define a presentation of a language L to be an infinite sequence of elements of L such that every element of L occurs at least once .</sentence>
				<definiendum id="0">learning algorithm A for</definiendum>
				<definiens id="0">a presentation of a language L to be an infinite sequence of elements of L such that every element of L occurs at least once</definiens>
			</definition>
</paper>

		<paper id="3807">
			<definition id="0">
				<sentence>Text-based question answering ( QA ) is the process of automatically finding the answers to arbitrary questions in plain English by searching collections of text files .</sentence>
				<definiendum id="0">Text-based question answering</definiendum>
				<definiens id="0">the process of automatically finding the answers to arbitrary questions in plain English by searching collections of text files</definiens>
			</definition>
			<definition id="1">
				<sentence>The resulting MCS is an unconnected graph , though Myaeng and L´opez-L´opez ( 1992 ) ’s algorithm returns the two parts of the graph as independent MCSs .</sentence>
				<definiendum id="0">MCS</definiendum>
			</definition>
			<definition id="2">
				<sentence>Let us now assume that the graph rule R is originatedfromapair ( q , as ) inthetrainingcorpus , where q is a question and as a sentence containing the answer a. The rule components are built as follows : Rp is the MCS of q and as , that is , MCS ( q , as ) .</sentence>
				<definiendum id="0">Rp</definiendum>
				<definiendum id="1">MCS</definiendum>
				<definiens id="0">a question and as a sentence containing the answer a. The rule components</definiens>
			</definition>
			<definition id="3">
				<sentence>Ra is the graph representation of the exact answer .</sentence>
				<definiendum id="0">Ra</definiendum>
				<definiens id="0">the graph representation of the exact answer</definiens>
			</definition>
			<definition id="4">
				<sentence>A Logical Graph ( LG ) is a directed , bipartite graph with two types of vertices , concepts and relations .</sentence>
				<definiendum id="0">Logical Graph ( LG )</definiendum>
				<definiens id="0">a directed</definiens>
			</definition>
			<definition id="5">
				<sentence>There is recent interest on the use of graph methods for Natural Language Processing , such as document summarisation ( Mihalcea , 2004 ) document retrieval ( Montes-y-G´omez et al. , 2000 ; Mishne,2004 ) , andrecognitionoftextualentailment ( Pazienza et al. , 2005 ) .</sentence>
				<definiendum id="0">document retrieval</definiendum>
				<definiens id="0">recent interest on the use of graph methods for Natural Language Processing , such as document summarisation</definiens>
			</definition>
</paper>

		<paper id="2907">
			<definition id="0">
				<sentence>Lexical substitution the task of replacing a word with another one that conveys the same meaning is a prominent task in many Natural Language Processing ( NLP ) applications .</sentence>
				<definiendum id="0">Lexical substitution</definiendum>
			</definition>
			<definition id="1">
				<sentence>Subtitle generation is the task of generating target language TV subtitles for video recordings of a source language speech .</sentence>
				<definiendum id="0">Subtitle generation</definiendum>
				<definiens id="0">the task of generating target language TV subtitles for video recordings of a source language speech</definiens>
			</definition>
			<definition id="2">
				<sentence>Contextual models score the “fitness” of the replacing word within the context of the sentence , in order to filter out synonyms of senses of the original word that are not the right sense in the given context .</sentence>
				<definiendum id="0">Contextual models</definiendum>
				<definiens id="0">score the “fitness” of the replacing word within the context of the sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>The dataset consists of 918 substitution examples originating from 231 different sentences .</sentence>
				<definiendum id="0">dataset</definiendum>
				<definiens id="0">consists of 918 substitution examples originating from 231 different sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>2WordNet lists job as a possible member of the synset for a state of difficulty that needs to be resolved , as might be used in sentences like “it is always a job to contact him” As representative approaches for addressing this problem , we chose two methods that rely on statistical information of two types : supervised sense distributions from SemCor and unsupervised distributional similarity .</sentence>
				<definiendum id="0">2WordNet lists job</definiendum>
			</definition>
			<definition id="5">
				<sentence>Contextual models score lexical substitutions based on the context of the sentence .</sentence>
				<definiendum id="0">Contextual models</definiendum>
				<definiens id="0">score lexical substitutions based on the context of the sentence</definiens>
			</definition>
			<definition id="6">
				<sentence>For a bag-of-words context C = { w1 , ... , wi−1 , wi+1 , ... , wn } and target word v the Na¨ıve Bayes probability estimation for the conditional probability of a word v may occur in a given a context C is as follows : P ( v|C ) = P ( C|v ) P ( v ) P ( C|v ) P ( v ) +P ( C|¬v ) P ( ¬v ) ≈ P ( v ) producttext w∈C P ( w|v ) P ( v ) producttext w∈C P ( w|v ) +P ( ¬v ) producttext w∈C P ( w|¬v ) ( 1 ) where P ( w|v ) is the probability that a word w appears in the context of a sentence containing v and correspondingly P ( w|¬v ) is the probability that w 48 appears in a sentence not containing v. The probability estimates were obtained from the processed BNC corpus as follows : P ( w|v ) = |w appears in sentences containing v||words in sentences containing v| P ( w|¬v ) = |w occurs in sentences not containing v||words in sentences not containing v| To avoid 0 probabilities these estimates were smoothed by adding a small constant to all counts and normalizing accordingly .</sentence>
				<definiendum id="0">Na¨ıve Bayes probability estimation</definiendum>
				<definiens id="0">the probability that a word w appears in the context of a sentence containing v</definiens>
				<definiens id="1">the probability that w 48 appears in a sentence not containing v. The probability estimates were obtained from the processed BNC corpus as follows</definiens>
			</definition>
			<definition id="7">
				<sentence>NNTR is a discriminative approach which aims at modeling how likely a given word v is in the context of a piece of text C , while learning a more compact representation of reduced dimensionality for both v and C. NNTR is composed of 3 Multilayer Perceptrons , noted mlpA ( ) , mlpB ( ) and mlpC ( ) , connected as follow : NNTR ( v , C ) = mlpC [ mlpA ( v ) , mlpB ( C ) ] .</sentence>
				<definiendum id="0">NNTR</definiendum>
				<definiendum id="1">mlpA</definiendum>
				<definiens id="0">a discriminative approach which aims at modeling how likely a given word v is in the context of a piece of text C</definiens>
			</definition>
			<definition id="8">
				<sentence>mlpA ( v ) and mlpB ( C ) project respectively the vector space representation of the word and text into a more compact space of lower dimensionality .</sentence>
				<definiendum id="0">mlpA</definiendum>
				<definiendum id="1">mlpB ( C</definiendum>
				<definiens id="0">) project respectively the vector space representation of the word and text into a more compact space of lower dimensionality</definiens>
			</definition>
			<definition id="9">
				<sentence>It is equivalent to the area under the uninterpolated recall-precision curve , defined as follows : average precision = summationtextN i=1 P ( i ) T ( i ) summationtextN i=1 T ( i ) P ( i ) = summationtexti k=1 T ( k ) i ( 2 ) where N is the number of examples in the test set ( 797 in our case ) , T ( i ) is the gold annotation ( true=1 , false=0 ) and i ranges over the examples ranked by decreasing score .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">T ( i )</definiendum>
				<definiens id="0">equivalent to the area under the uninterpolated recall-precision curve , defined as follows : average precision = summationtextN i=1 P ( i ) T ( i ) summationtextN i=1 T ( i ) P ( i ) = summationtexti k=1 T ( k</definiens>
				<definiens id="1">the number of examples in the test set ( 797 in our case )</definiens>
				<definiens id="2">the gold annotation ( true=1 , false=0 ) and i ranges over the examples ranked by decreasing score</definiens>
			</definition>
</paper>

		<paper id="0139">
</paper>

		<paper id="2902">
			<definition id="0">
				<sentence>The probabilistic model is a neural network statistical parser ( Henderson , 2003 ) , and the data-defined kernel is a TOP reranking kernel ( Henderson and Titov , 2005 ) .</sentence>
				<definiendum id="0">probabilistic model</definiendum>
				<definiens id="0">a neural network statistical parser</definiens>
			</definition>
			<definition id="1">
				<sentence>The reranking task is defined as selecting a parse tree from the list of candidate trees ( y1 , . . . , ys ) suggested by a probabilistic model P ( x , y|ˆθ ) , where ˆθ is a vector of model parameters learned during training the probabilistic model .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">ˆθ</definiendum>
				<definiens id="0">selecting a parse tree from the list of candidate trees ( y1 , . . . , ys ) suggested by a probabilistic model</definiens>
				<definiens id="1">a vector of model parameters learned during training the probabilistic model</definiens>
			</definition>
			<definition id="2">
				<sentence>The probabilistic model ( Henderson , 2003 ) allows us to distinguish between those parameters responsible for the distributions of individual vocabulary items , and those parameters responsible for the distributions of structural decisions , as described in more details in section 4.2 .</sentence>
				<definiendum id="0">probabilistic model</definiendum>
				<definiens id="0">allows us to distinguish between those parameters responsible for the distributions of individual vocabulary items</definiens>
			</definition>
			<definition id="3">
				<sentence>Standard measures of accuracy for the original probabilistic model ( SSN-WSJ+Br ) and the kernel method ( TOP-Focus ) are also shown in table 2 .</sentence>
				<definiendum id="0">Standard</definiendum>
				<definiens id="0">measures of accuracy for the original probabilistic model ( SSN-WSJ+Br )</definiens>
			</definition>
</paper>

		<paper id="3813">
			<definition id="0">
				<sentence>A graph consists of the main unit and all syntactic units with which it is syntactically connected .</sentence>
				<definiendum id="0">graph</definiendum>
			</definition>
			<definition id="1">
				<sentence>Most approaches rely on VerbNet ( Kipper et al. , 2000 ) and FrameNet ( Baker et al. , 1998 ) to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions ( Carreras and Marquez , 2004 ; Carreras and Marquez , 2005 ) and also ( Gildea and Jurafsky , 2002 ; Pradhan et al. , 2005 ; Shi and Mihalcea , 2005 ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">Baker et al. , 1998 ) to provide associations between verbs and semantic roles , that are then mapped onto the current instance</definiens>
			</definition>
			<definition id="2">
				<sentence>The relations are grouped by general similarity into 6 relation classes ( H denotes the head of a base NP , M denotes the modi er ) .</sentence>
				<definiendum id="0">H</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">the head of a base NP</definiens>
				<definiens id="1">the modi er )</definiens>
			</definition>
			<definition id="3">
				<sentence>Examples : direction H is directed towards M : outgoing mail ; location H is the location of M : home town ; location at H is located at M : desert storm ; currence at an absolute or relative point in time .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">the location of M : home town</definiens>
			</definition>
			<definition id="4">
				<sentence>A graph G ( w ) centered on word w consists of the following : a node for w ; a set of nodes for each of the words wi in the sentence with which w is connected by a grammatical relation ( including situations when w is a modi er/argument ) ; edges that connect w with each wi , tagged with grammatical relation GR ( such as subject , object , complement ) and connective information Con ( prepositions , coordinators , subordinators , or nil ) .</sentence>
				<definiendum id="0">graph G ( w</definiendum>
				<definiens id="0">a node for w ; a set of nodes for each of the words wi in the sentence with which w is connected by a grammatical relation ( including situations when w is a modi er/argument ) ; edges that connect w with each wi , tagged with grammatical relation GR ( such as subject , object , complement ) and connective information Con ( prepositions , coordinators , subordinators , or nil )</definiens>
			</definition>
			<definition id="5">
				<sentence>If G ( w ) is the graph centered on word w whose pairs are currently being processed , the system selects from the collection of previously stored graphs , a set of graphs fG ( wi ) g , which satisfy the following conditions : The central nodes match .</sentence>
				<definiendum id="0">w )</definiendum>
				<definiens id="0">the graph centered on word w whose pairs are currently being processed , the system selects from the collection of previously stored graphs</definiens>
			</definition>
			<definition id="6">
				<sentence>S , and is connected to wg edge ( w , wi ) = fGRi , Conig ; GRi 2 fsubject , object , complement , ... g Coni 2 fat , in , on , with , for , ... g Distance metric between two graphs : dist ( G ( w1 ) , G ( w2 ) ) = Nsummationtext k=1 d ( edge1k , edge2k ) ; edgeik 2 G ( wi ) , N is the number of edges in G ( wi ) d ( edge1k , edge2k ) =d ( fGR1k , Con1kg , fGR2k , Con2kg ) =d1 ( GR1k , GR2k ) + d1 ( Con1k , Con2k ) d1 ( x , y ) = braceleftbigg 0 : x = y 1 : x 6= y Figure 1 : Distance between two graphs with the current graph .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">2 fsubject , object , complement , ... g Coni 2 fat , in , on , with , for , ... g Distance metric between two graphs : dist ( G ( w1 ) , G ( w2 ) ) = Nsummationtext k=1 d ( edge1k , edge2k ) ; edgeik 2 G ( wi ) ,</definiens>
				<definiens id="1">the number of edges in G ( wi</definiens>
				<definiens id="2">x , y ) = braceleftbigg 0 : x = y 1 : x 6= y Figure 1 : Distance between two graphs with the current graph</definiens>
			</definition>
</paper>

		<paper id="3116">
			<definition id="0">
				<sentence>MOOD is implemented with the C++ programming language and is licensed under the Gnu General Public License ( GPL ) 2 .</sentence>
				<definiendum id="0">MOOD</definiendum>
				<definiens id="0">implemented with the C++ programming language and is licensed under the Gnu General Public License</definiens>
			</definition>
</paper>

		<paper id="1521">
			<definition id="0">
				<sentence>Definition 4 A typing context Γ ( context for short ) , is a set of pairs of the form x : d where x is a variable and d is a syntactic description such that x : d ∈ Γ and x : e ∈ Γ iff d = e. If x : d ∈ Γ , then we say that x is declared with type d in Γ .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">a syntactic description such that x : d ∈ Γ</definiens>
			</definition>
			<definition id="1">
				<sentence>Lexical entries are triples ( Γ , t , α ) where Γ is a typing context , t is a linear λ-term and α is either Na , Ns or Na.1 if N is a non-terminal of the considered TAG .</sentence>
				<definiendum id="0">Lexical entries</definiendum>
				<definiendum id="1">Γ</definiendum>
				<definiendum id="2">α</definiendum>
				<definiens id="0">a typing context</definiens>
				<definiens id="1">a linear λ-term and</definiens>
				<definiens id="2">a non-terminal of the considered TAG</definiens>
			</definition>
			<definition id="2">
				<sentence>Given an initial tree T whose root is labeled by N and t the normal form of φ ( T ) , ( , t , Ns ) 2 is the lexical entry associated to T ; if T is an auxiliary tree whose root is labeled by N and t is the normal form of φ ( T ) then ( , λfNa.1 .</sentence>
				<definiendum id="0">t</definiendum>
				<definiens id="0">an auxiliary tree whose root is labeled by N and</definiens>
			</definition>
			<definition id="3">
				<sentence>xNa ( φ ( T1 ) +··· + φ ( Tn ) ) y xNa and y are fresh φ    NNA T1 Tn. . .   −→ φ ( T1 ) +··· + φ ( Tn ) φ ( N∗ ) −→ λy .</sentence>
				<definiendum id="0">xNa</definiendum>
				<definiens id="0">φ ( T1 ) +··· + φ ( Tn ) ) y xNa and y are fresh φ    NNA T1 Tn. . .   −→ φ ( T1 ) +··· + φ ( Tn ) φ ( N∗ ) −→ λy</definiens>
			</definition>
			<definition id="4">
				<sentence>The algorithm uses two kinds of items ; either items of the form ( α ; Γ turnstileleft t : d ; L ) ( where L is a list of sequents , the subgoals , here L contains either zero or one element ) or items of the form [ Na.1 ; Γ ; t ; ( C1 [ ] , v1 ) multimap ( C2 [ ] , v2 ) ] .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">v1 ) multimap</definiendum>
				<definiens id="0">a list of sequents , the subgoals , here L contains either zero or one element ) or items of the form [ Na.1 ; Γ ; t ; ( C1 [ ] ,</definiens>
			</definition>
			<definition id="5">
				<sentence>[ ] , C [ y ] ) ; ) ( where S is the start symbol of the TAG G. 4There is no occurence of F or Y in d. 144 General items ( Na ; turnstileleft λfNa.1y.t1 : ( F , Y ) multimap ( C1 [ ] , v1 ) ; fNa.1 : F , y : Y turnstileleft t2 : ( C2 [ ] , v2 ) ) ( Na ; turnstileleft λfNa.1y.t : ( ( C1 [ ] , v1 ) multimap ( C2 [ ] , v2 ) , Y ) multimap ( C3 [ ] , v3 ) ; y : Y turnstileleft t2 : ( C4 [ ] , v4 ) ) ( Na ; turnstileleft λfNa.1y.t : ( ( C1 [ ] , v1 ) multimap ( C2 [ ] , v2 ) , ( C3 [ ] , v3 ) ) multimap ( C4 [ ] , v4 ) ; ) ( α ; turnstileleft λy .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">G. 4There</definiendum>
				<definiendum id="2">turnstileleft λfNa.1y.t</definiendum>
				<definiens id="0">the start symbol of the TAG</definiens>
			</definition>
</paper>

		<paper id="3701">
			<definition id="0">
				<sentence>We present our Translation Shortcuts facility , which minimizes the need for interactive verification of sentences after they have been vetted once , considerably speeds throughput while maintaining accuracy , and allows use by minimally literate patients for whom any mode of text entry might be difficult .</sentence>
				<definiendum id="0">Translation Shortcuts facility</definiendum>
				<definiens id="0">minimizes the need for interactive verification of sentences after they have been vetted once , considerably speeds throughput while maintaining accuracy</definiens>
			</definition>
			<definition id="1">
				<sentence>It is natural to hope that automatic real-time translation in general , and spoken language translation ( SLT ) in particular , can help to meet this communicative need .</sentence>
				<definiendum id="0">SLT</definiendum>
				<definiens id="0">natural to hope that automatic real-time translation in general , and spoken language translation (</definiens>
			</definition>
			<definition id="2">
				<sentence>• Translation memory : Translation Shortcuts can be seen as a variant of Translation Memory , a facility that remembers past successful translations so as to circumvent error-prone reprocessing .</sentence>
				<definiendum id="0">Translation Shortcuts</definiendum>
				<definiens id="0">a variant of Translation Memory , a facility that remembers past successful translations so as to circumvent error-prone reprocessing</definiens>
			</definition>
			<definition id="3">
				<sentence>We have presented our Translation Shortcuts facility , which minimizes the need for interactive verification of sentences after they have been vetted once , considerably speeds throughput while maintaining accuracy , and allows use by minimally literate patients for whom any mode of text entry might be difficult .</sentence>
				<definiendum id="0">Translation Shortcuts facility</definiendum>
				<definiens id="0">minimizes the need for interactive verification of sentences after they have been vetted once , considerably speeds throughput while maintaining accuracy</definiens>
			</definition>
</paper>

		<paper id="1609">
			<definition id="0">
				<sentence>During the last few years , SMT systems have evolved from the original word-based approach ( Brown et al. , 1993 ) to phrase-based translation systems ( Koehn et al. , 2003 ) .</sentence>
				<definiendum id="0">SMT</definiendum>
				<definiens id="0">the original word-based approach ( Brown et al. , 1993 ) to phrase-based translation systems</definiens>
			</definition>
			<definition id="1">
				<sentence>SMR is a rst-pass translation performed on the source corpus , which converts it into an intermediate representation , in which source-language words are presented in an order that more closely matches that of the target language .</sentence>
				<definiendum id="0">SMR</definiendum>
				<definiens id="0">a rst-pass translation performed on the source corpus , which converts it into an intermediate representation , in which source-language words are presented in an order that more closely matches that of the target language</definiens>
			</definition>
			<definition id="2">
				<sentence>70 This section brie y describes the n-gram-based SMT which uses a translation model based on bilingual n-grams .</sentence>
				<definiendum id="0">n-gram-based SMT</definiendum>
				<definiens id="0">uses a translation model based on bilingual n-grams</definiens>
			</definition>
			<definition id="3">
				<sentence>In addition to the bilingual n-gram translation model , the baseline system implements a log-linear combination of four feature functions , which are described as follows : • A target language model .</sentence>
				<definiendum id="0">baseline system</definiendum>
				<definiens id="0">implements a log-linear combination of four feature functions , which are described as follows : • A target language model</definiens>
			</definition>
			<definition id="4">
				<sentence>P ( tK1 ) = exp ( − Ksummationdisplay k=1 dk ) where dk is the distance between the rst word of the kth tuple ( unit ) , and the last word+1 of the ( k − 1 ) th tuple .</sentence>
				<definiendum id="0">dk</definiendum>
				<definiens id="0">the distance between the rst word of the kth tuple</definiens>
			</definition>
			<definition id="5">
				<sentence>Therefore , the SMR system can be seen as an SMT system which translates from an original source language ( S ) to a reordered source language ( S’ ) , given a target language ( T ) .</sentence>
				<definiendum id="0">SMR system</definiendum>
				<definiens id="0">an SMT system which translates from an original source language ( S ) to a reordered source language ( S’ ) , given a target language ( T )</definiens>
			</definition>
			<definition id="6">
				<sentence>There three blocks inside SMR : ( 1 ) class replacing ; ( 2 ) the decoder , which requires the translation model ; and , ( 3 ) the block which reorders the original sentence using the indexes given by the decoder .</sentence>
				<definiendum id="0">decoder</definiendum>
				<definiens id="0">the block which reorders the original sentence using the indexes given by the decoder</definiens>
			</definition>
			<definition id="7">
				<sentence>Figure 3 shows the block diagram of the training process of the SMR translation model , which is a bilingual n-gram-based model .</sentence>
				<definiendum id="0">translation model</definiendum>
				<definiens id="0">a bilingual n-gram-based model</definiens>
			</definition>
			<definition id="8">
				<sentence>EuroParl corpus : training , development and test data sets .</sentence>
				<definiendum id="0">EuroParl corpus</definiendum>
			</definition>
			<definition id="9">
				<sentence>• We used MARIE as a decoder ( Crego et al. , 2005b ) .</sentence>
				<definiendum id="0">MARIE</definiendum>
			</definition>
			<definition id="10">
				<sentence>BTEC corpus : training , development and test data sets .</sentence>
				<definiendum id="0">BTEC corpus</definiendum>
			</definition>
</paper>

		<paper id="0605">
			<definition id="0">
				<sentence>The following are a few of the catalogs ofinformationaboutlanguagesandtheirresources that are available : • The Ethnologue3 : This is the standard listing of the living languages of the world , but contains little or no information about what resources exist for each language .</sentence>
				<definiendum id="0">Ethnologue3</definiendum>
				<definiens id="0">of the world , but contains little or no information about what resources exist for each language</definiens>
			</definition>
			<definition id="1">
				<sentence>• OLAC ( Open Archives Language Community7 ) : Given that many of the above resources ( particularly those of the many language archives ) are hard to find , OLAC is an attempt to be a meta-catalog ( or aggregator ) of such resources .</sentence>
				<definiendum id="0">OLAC</definiendum>
				<definiendum id="1">OLAC</definiendum>
				<definiens id="0">an attempt to be a meta-catalog ( or aggregator</definiens>
			</definition>
			<definition id="2">
				<sentence>Aceh is a lower-density language . )</sentence>
				<definiendum id="0">Aceh</definiendum>
				<definiens id="0">a lower-density language</definiens>
			</definition>
</paper>

		<paper id="2712">
			<definition id="0">
				<sentence>MMAX21 is a versatile , XML-based annotation tool which has already been used in a variety of annotation projects .</sentence>
				<definiendum id="0">MMAX21</definiendum>
				<definiens id="0">a versatile , XML-based annotation tool which has already been used in a variety of annotation projects</definiens>
			</definition>
			<definition id="1">
				<sentence>The project uses the ICSI Meeting Corpus ( Janin et al. , 2003 ) , a corpus of multi-party dialogs which contains a considerable amount of simultaneous speech .</sentence>
				<definiendum id="0">ICSI Meeting Corpus</definiendum>
				<definiens id="0">a corpus of multi-party dialogs which contains a considerable amount of simultaneous speech</definiens>
			</definition>
			<definition id="2">
				<sentence>Normally , these PCDATA children represent orthographical words , but larger or smaller units ( e.g. characters ) are also possible , depending on the required granularity of the representation.2 &lt; ? xml version= '' 1.0 '' encoding= '' US-ASCII '' ? &gt; &lt; ! DOCTYPE words SYSTEM `` words.dtd '' &gt; &lt; words &gt; ... &lt; word id= '' word_3710 '' &gt; That &lt; /word &gt; &lt; word id= '' word_3711 '' &gt; ’s &lt; /word &gt; &lt; word id= '' word_3712 '' &gt; just &lt; /word &gt; &lt; word id= '' word_3713 '' &gt; a &lt; /word &gt; &lt; word id= '' word_3714 '' meta= '' true '' &gt; Pause &lt; /word &gt; &lt; word id= '' word_3715 '' &gt; specification &lt; /word &gt; &lt; word id= '' word_3716 '' &gt; for &lt; /word &gt; &lt; word id= '' word_3717 '' &gt; the &lt; /word &gt; &lt; word id= '' word_3718 '' &gt; X_M_L &lt; /word &gt; &lt; word id= '' word_3719 '' &gt; Yep &lt; /word &gt; &lt; word id= '' word_3720 '' &gt; .</sentence>
				<definiendum id="0">PCDATA children</definiendum>
				<definiens id="0">represent orthographical words , but larger or smaller units</definiens>
				<definiens id="1">/word &gt; &lt; word id= '' word_3713 '' &gt; a &lt; /word &gt; &lt; word id= '' word_3714 '' meta= '' true '' &gt; Pause &lt; /word &gt; &lt; word id= '' word_3715 '' &gt; specification &lt; /word &gt; &lt; word id= '' word_3716 '' &gt; for &lt; /word &gt; &lt; word id= '' word_3717 '' &gt; the &lt; /word &gt; &lt; word id= '' word_3718</definiens>
			</definition>
			<definition id="3">
				<sentence>A discontinuous markable is one that contains more than one fragment , like 3Note that this merely means that markables are not defined in terms of other markables , while they can indeed reference each other : In the above example , markable markable 7837 ( [ ’s just a specification ] ) uses an associative relation ( in this case namedsubject ) to represent a reference to markable markable 7834 ( [ That ] ) on the same When a MMAX2 document is currently loaded , the main display contains the base data text plus annotation-related information .</sentence>
				<definiendum id="0">discontinuous markable</definiendum>
				<definiendum id="1">associative relation</definiendum>
				<definiens id="0">one that contains more than one fragment</definiens>
			</definition>
			<definition id="4">
				<sentence>The query combines the segment level , the meta level ( which contains markables representing e.g. pauses , emphases , or sounds like breathing or mike noise ) , and the base data level to retrieve those instances of you know from the ICSI Meeting corpus that occur in segments spoken by female speakers6 which also contain a pause or an emphasis ( represented on the meta level ) : ’ [ Yy ] ou know’ in ( /participant= { f.* } dom / { pause , emphasis } ) The next query shows how overlap can be han5Associative relations are not discussed here , ( M¨uller , 2005 ) .</sentence>
				<definiendum id="0">meta level</definiendum>
				<definiens id="0">contains markables representing e.g. pauses , emphases , or sounds like breathing or mike noise ) , and the base data level to retrieve those instances of you know from the ICSI Meeting corpus that occur in segments spoken by female speakers6 which also contain a pause or an emphasis</definiens>
			</definition>
			<definition id="5">
				<sentence>The XSL processor provides some special extensions for handling standoff annotation as it is realized in MMAX2 .</sentence>
				<definiendum id="0">XSL processor</definiendum>
				<definiens id="0">provides some special extensions for handling standoff annotation as it is realized in MMAX2</definiens>
			</definition>
			<definition id="6">
				<sentence>A minimal template pair for matching starting and ending markables from the chunks level and enclosing them in bold brackets ( using HTML ) looks like this : &lt; xsl : template match= '' chunks : markable '' mode= '' opening '' &gt; &lt; b &gt; [ &lt; /b &gt; &lt; /xsl : template &gt; &lt; xsl : template match= '' chunks : markable '' mode= '' closing '' &gt; &lt; b &gt; ] &lt; /b &gt; &lt; /xsl : template &gt; Note how the markable level name ( here : chunks ) is used as a markable name space to control which markables the above templates should match .</sentence>
				<definiendum id="0">chunks</definiendum>
				<definiens id="0">template match= '' chunks : markable '' mode= '' closing '' &gt; &lt; b &gt; ] &lt; /b &gt; &lt; /xsl : template &gt; Note how the markable level name</definiens>
				<definiens id="1">markables the above templates should match</definiens>
			</definition>
			<definition id="7">
				<sentence>MMAX2 is a practically usable tool for multilevel annotation .</sentence>
				<definiendum id="0">MMAX2</definiendum>
			</definition>
</paper>

		<paper id="0405">
			<definition id="0">
				<sentence>A dependency is a function that connects together distant nodes within a chunk tree .</sentence>
				<definiendum id="0">dependency</definiendum>
				<definiens id="0">a function that connects together distant nodes within a chunk tree</definiens>
			</definition>
			<definition id="1">
				<sentence>TOP is a node that is automatically created , once all chunking rules have applied , to transform this sequence of chunks into a tree .</sentence>
				<definiendum id="0">TOP</definiendum>
				<definiens id="0">a node that is automatically created</definiens>
			</definition>
			<definition id="2">
				<sentence>SUBJ ( produce , rules ) OBJ ( produce , tree ) SUBJ is a subject relation , which has been extracted with the following rule : | NP { ?</sentence>
				<definiendum id="0">SUBJ</definiendum>
				<definiendum id="1">SUBJ</definiendum>
				<definiens id="0">a subject relation</definiens>
			</definition>
			<definition id="3">
				<sentence>The other reason of this choice , over for instance a more conventional language such as C or Java is the fact that it is an interpreted language .</sentence>
				<definiendum id="0">Java</definiendum>
				<definiens id="0">the fact that it is an interpreted language</definiens>
			</definition>
			<definition id="4">
				<sentence>A XIP grammar is a set of text files , which are all compiled on the fly in memory every time the parser is run .</sentence>
				<definiendum id="0">XIP grammar</definiendum>
				<definiens id="0">a set of text files , which are all compiled on the fly in memory every time the parser is run</definiens>
			</definition>
			<definition id="5">
				<sentence>XIP is the master program with python scripts being triggered by grammar rules .</sentence>
				<definiendum id="0">XIP</definiendum>
				<definiens id="0">the master program with python scripts being triggered by grammar rules</definiens>
			</definition>
			<definition id="6">
				<sentence>XIP recognizes many different sorts of data , which can all be transmitted to a Python script , such as syntactic nodes , dependencies , integer variables , string variables , or even vector variables .</sentence>
				<definiendum id="0">XIP</definiendum>
				<definiens id="0">recognizes many different sorts of data , which can all be transmitted to a Python script , such as syntactic nodes , dependencies , integer variables , string variables , or even vector variables</definiens>
			</definition>
			<definition id="7">
				<sentence>This API consists of a dozen instructions , which can be called anywhere in the Python code .</sentence>
				<definiendum id="0">API</definiendum>
				<definiens id="0">consists of a dozen instructions , which can be called anywhere in the Python code</definiens>
			</definition>
			<definition id="8">
				<sentence>Second , the selection of syntactic nodes on which to apply Python procedures is done at the grammar level , which means that the access of specific nodes is done through the parsing engine itself , without any need to duplicate any sorts of tree operators , which would be mandatory in the case of a Java , XML or C++ object .</sentence>
				<definiendum id="0">level</definiendum>
				<definiens id="0">the parsing engine itself , without any need to duplicate any sorts of tree operators</definiens>
			</definition>
			<definition id="9">
				<sentence>def TestCouple ( v , n ) : noun=XipNode ( n ) verb=XipNode ( v ) cmd=”select * from couples where ” cmd+=”verb=”+verb .</sentence>
				<definiendum id="0">def TestCouple</definiendum>
			</definition>
</paper>

		<paper id="1201">
</paper>

		<paper id="3112">
			<definition id="0">
				<sentence>Open and closed class items One important conclusion we draw from analysing the synonyms obtained through word alignment is that equivalence is limited mainly to words that belong to open word classes , i.e. nouns , verbs , adjectives , adverbs , but is unlikely to extend to closed word classes like prepositions or pronouns .</sentence>
				<definiendum id="0">Open</definiendum>
				<definiens id="0">belong to open word classes , i.e. nouns , verbs , adjectives , adverbs , but is unlikely to extend to closed word classes like prepositions</definiens>
			</definition>
</paper>

		<paper id="1321">
</paper>

		<paper id="2607">
			<definition id="0">
				<sentence>Therefore , a tree-kernel function K over T1 and T2 can be defined as K ( T1 , T2 ) = summationtextn1∈NT 1 summationtext n2∈NT2 ∆ ( n1 , n2 ) , where NT1 and NT2 are the sets of the T1’s and T2’s nodes , respectively and ∆ ( n1 , n2 ) = summationtext|F|i=1 Ii ( n1 ) Ii ( n2 ) .</sentence>
				<definiendum id="0">tree-kernel function K</definiendum>
				<definiendum id="1">K</definiendum>
				<definiendum id="2">NT2</definiendum>
			</definition>
			<definition id="1">
				<sentence>We used as a target dataset the PropBank corpus available at www.cis.upenn.edu/∼ace , along with the Penn TreeBank 2 for the gold trees ( www.cis.upenn.edu/∼treebank ) ( Marcusetal. , 1993 ) , which includes about 53,700 sentences .</sentence>
				<definiendum id="0">www.cis.upenn.edu/∼treebank )</definiendum>
				<definiens id="0">includes about 53,700 sentences</definiens>
			</definition>
</paper>

		<paper id="3607">
			<definition id="0">
				<sentence>The 2005 ACE evaluation had 7 types of entities , of which the most common were PER ( persons ) , ORG ( organizations ) , LOC ( natural locations ) and GPE ( ‘geo-political entities’ – locations which are also political units , such as countries , counties , and cities ) .</sentence>
				<definiendum id="0">LOC</definiendum>
				<definiens id="0">‘geo-political entities’ – locations which are also political units</definiens>
			</definition>
			<definition id="1">
				<sentence>Examples of these relations are “the CEO of Microsoft” ( an organization-affiliation relation ) , “Fred’s wife” ( a 1 The ACE task description can be found at http : //www.itl.nist.gov/iad/894.01/tests/ace/ personal-social relation ) , and “a military base in Germany” ( a located relation ) .</sentence>
				<definiendum id="0">“Fred’s wife”</definiendum>
				<definiens id="0">//www.itl.nist.gov/iad/894.01/tests/ace/ personal-social relation ) , and “a military base in Germany” ( a located relation )</definiens>
			</definition>
</paper>

		<paper id="0308">
			<definition id="0">
				<sentence>We used Support Vector Machines ( Joachims , 2001 ) with three basic classic features ( unigrams , POS and stems ) to classify the posts as belonging to one quadrant or one of the three others .</sentence>
				<definiendum id="0">Support Vector Machines</definiendum>
			</definition>
			<definition id="1">
				<sentence>PMI ( Church and Hanks , 1990 ) between two phrases is de ned as : log2 prob ( ph1 is near ph2 ) prob ( ph 1 ) ⁄ prob ( ph2 ) PMI is positive when two phrases tend to co-occur and negative when they tend to be in a complementary distribution .</sentence>
				<definiendum id="0">PMI</definiendum>
				<definiens id="0">positive when two phrases tend to co-occur and negative when they tend to be in a complementary distribution</definiens>
			</definition>
			<definition id="2">
				<sentence>Computing probabilities using hit counts from IR , this yields to a value for PMI-IR of : logn N ⁄ ( hits ( ph1 NEAR ph2 ) + 1/N ) ( hits ( ph 1 ) + 1 ) ⁄ ( hits ( ph2 ) + 1 ) where N is the total number of documents in the corpus .</sentence>
				<definiendum id="0">N ⁄ ( hits</definiendum>
				<definiendum id="1">1/N ) ( hits</definiendum>
				<definiendum id="2">⁄ ( hits</definiendum>
				<definiendum id="3">N</definiendum>
				<definiens id="0">the total number of documents in the corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>In this and the following matrices , the topleft cell indicates the overall accuracy8 , the POSitive ( ACTive ) and NEGative ( PASsive ) columns represent the instances in a predicted class , the P/T column ( where present ) indicates the average number of patterns per text ( blog post ) , E/P indicates the average evaluation score per pattern and A/P indicates the average activity score per pattern .</sentence>
				<definiendum id="0">topleft cell</definiendum>
				<definiendum id="1">POSitive</definiendum>
				<definiendum id="2">P/T column</definiendum>
				<definiendum id="3">present )</definiendum>
				<definiens id="0">indicates the average number of patterns per text ( blog post ) , E/P indicates the average evaluation score per pattern and A/P indicates the average activity score per pattern</definiens>
			</definition>
			<definition id="4">
				<sentence>The 81.1 % POS NEG P/T E/P POS ( 43 ) 60.5 % 39.5 % 1 0.4 NEG ( 47 ) 0.0 % 100.0 % 1 -6.4 66.7 % ACT PAS P/T A/P ACT ( 39 ) 33.3 % 66.7 % 1 -0.9 PAS ( 51 ) 7.8 % 92.2 % 1 -2.9 Table 4 : CM for the Typology affective states value of 1 under P/T re ects the fact that the experiment amounts , in practical terms , to classifying the annotation of the post ( a single word ) .</sentence>
				<definiendum id="0">NEG</definiendum>
				<definiendum id="1">PAS</definiendum>
				<definiens id="0">the experiment amounts , in practical terms , to classifying the annotation of the post ( a single word )</definiens>
			</definition>
</paper>

		<paper id="3702">
			<definition id="0">
				<sentence>MedSLT ( MedSLT , 2005 ; Bouillon et al. , 2005 ) is a unidirectional , grammar-based medical speech translation system intended for use in doctorpatient diagnosis dialogues .</sentence>
				<definiendum id="0">MedSLT</definiendum>
				<definiens id="0">a unidirectional , grammar-based medical speech translation system intended for use in doctorpatient diagnosis dialogues</definiens>
			</definition>
			<definition id="1">
				<sentence>MedSLT includes a help module , whose purpose is to add robustness to the system and guide the user towards the supported coverage .</sentence>
				<definiendum id="0">MedSLT</definiendum>
				<definiens id="0">includes a help module , whose purpose is to add robustness to the system and guide the user towards the supported coverage</definiens>
			</definition>
			<definition id="2">
				<sentence>Scores are on a 5-point scale , averaged over all answers .</sentence>
				<definiendum id="0">Scores</definiendum>
			</definition>
</paper>

		<paper id="3323">
</paper>

		<paper id="2006">
</paper>

		<paper id="3703">
			<definition id="0">
				<sentence>The number of people in the U.S. who speak a language other than English is large and growing , and Spanish is the most commonly spoken language next to English .</sentence>
				<definiendum id="0">Spanish</definiendum>
				<definiens id="0">the most commonly spoken language next to English</definiens>
			</definition>
			<definition id="1">
				<sentence>S-MINDS uses a combination of grammars and language models with these engines , depending on the task and the availability of training data .</sentence>
				<definiendum id="0">S-MINDS</definiendum>
				<definiens id="0">uses a combination of grammars and language models with these engines , depending on the task and the availability of training data</definiens>
			</definition>
			<definition id="2">
				<sentence>S-MINDS is a flexible system that can be configured in different ways depending on the needs of the end user .</sentence>
				<definiendum id="0">S-MINDS</definiendum>
				<definiens id="0">a flexible system that can be configured in different ways depending on the needs of the end user</definiens>
			</definition>
</paper>

		<paper id="1318">
			<definition id="0">
				<sentence>Agreement is sometimes measured as percentage of the cases on which the annotators agree , but more often expected agreement is taken into account in using the kappa statistic ( Cohen , 1960 ; Carletta , 1996 ) , which is given by : κ = po − pe1 − p e ( 1 ) where po is the observed proportion of agreement and pe is the proportion of agreement expected by chance .</sentence>
				<definiendum id="0">pe</definiendum>
				<definiens id="0">percentage of the cases on which the annotators agree , but more often expected agreement is taken into account in using the kappa statistic ( Cohen , 1960 ; Carletta , 1996 ) , which is given by : κ = po − pe1 − p e ( 1 ) where po is the observed proportion of agreement and</definiens>
			</definition>
			<definition id="1">
				<sentence>DIT is a context-change ( or information-state update ) approach to the analysis of dialogue , which describes utterance meaning in terms of context update operations called ‘dialogue acts’ .</sentence>
				<definiendum id="0">DIT</definiendum>
				<definiens id="0">a context-change ( or information-state update</definiens>
				<definiens id="1">describes utterance meaning in terms of context update operations called ‘dialogue acts’</definiens>
			</definition>
			<definition id="2">
				<sentence>DIT takes a multidimensional view on dialogue in the sense that speakers may use utterances to address several aspects of the communication simultaneously , as reflected in the multifunctionality of utterances .</sentence>
				<definiendum id="0">DIT</definiendum>
				<definiens id="0">reflected in the multifunctionality of utterances</definiens>
			</definition>
			<definition id="3">
				<sentence>A dialogue act falls within a specific dimension if it has a communicative function specific for that dimension or if it has a general-purpose function and a semantic content relating to that dimension .</sentence>
				<definiendum id="0">dialogue act</definiendum>
				<definiens id="0">a general-purpose function and a semantic content relating to that dimension</definiens>
			</definition>
			<definition id="4">
				<sentence>An aspect in which the DIT++ scheme differs from other taxonomies for dialogue acts is that , as noted in Section 2 , communicative functions ( CFs ) within a dimension as well as generalpurpose CFs are often structured into hierarchies in which a difference in level represents a relation of specificity .</sentence>
				<definiendum id="0">CFs</definiendum>
				<definiens id="0">often structured into hierarchies in which a difference in level represents a relation of specificity</definiens>
			</definition>
			<definition id="5">
				<sentence>Two CFs are said to be located in the same branch when one of the two CFs is an ancestor of the other .</sentence>
				<definiendum id="0">CFs</definiendum>
				<definiens id="0">said to be located in the same branch when one of the two</definiens>
			</definition>
			<definition id="6">
				<sentence>For the hierarchies in DIT , we keep the magnitude of disagreement linear with the difference in levels , and independent of level depth ; Given the considerations above , we propose the following metric : δ ( ci , cj ) = a∆ ( ci , cj ) · bΓ ( ci , cj ) ( 4 ) where : • a is a constant for which 0 &lt; a &lt; 1 , expressing how much distance there is between two adjacent levels in the hierarchy ; a plausible value for a could be 0.75 ; • ∆ is a function that returns the difference in depth between the levels of ci and cj ; • b is a constant for which 0 &lt; b ≤ 1 , expressing in what rate differences should become smaller when the depth in the hierarchy gets larger .</sentence>
				<definiendum id="0">b</definiendum>
				<definiens id="0">a function that returns the difference in depth between the levels of ci and cj ; •</definiens>
			</definition>
			<definition id="7">
				<sentence>If there is no reason to assume that differences on a higher depth in the hierarchy are of less magnitude than differences on a lower depth , then b = 1 ; • Γ ( ci , cj ) is a function that returns the minimal depth of ci and cj .</sentence>
				<definiendum id="0">cj )</definiendum>
				<definiens id="0">a function that returns the minimal depth of ci and cj</definiens>
			</definition>
</paper>

		<paper id="2929">
			<definition id="0">
				<sentence>We reserved 200 sentences in each language for training the reranker , plus 200 for choosing among rerankers trained on different feature sets and different ( U ×L ) -best lists.6 Features Our reranking features predict tags , labels , lemmata , suffixes and other information given all or some of the following non-local conditioning context : bigrams and trigrams of tags or dependency labels ; parent and grandparent dependency labels ; subcategorization frames ( in terms of tags or dependency labels ) ; the occurrence of certain tags between head and child ; surface features like the lemma7 and the 3-character suffix .</sentence>
				<definiendum id="0">subcategorization frames</definiendum>
				<definiens id="0">tags , labels , lemmata , suffixes and other information given all or some of the following non-local conditioning context : bigrams and trigrams of tags or dependency labels ; parent and grandparent dependency labels</definiens>
			</definition>
			<definition id="1">
				<sentence>The highest-ranked features during training , for all languages , are the parser and labeler probabilities , followed by p ( ∆i | tparent ) , p ( direction | tparent ) , p ( label | labelpred , labelsucc , subcat ) , and p ( coarse ( t ) | D , coarse ( tparent ) , Betw ) , where Betw is TRUE iff an instance of the coarse tag type with the highest mutual information between its left and right children ( usually verb ) is between the child and its head .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">p</definiendum>
				<definiendum id="2">labelsucc</definiendum>
				<definiendum id="3">Betw</definiendum>
			</definition>
</paper>

		<paper id="3708">
			<definition id="0">
				<sentence>S-MINDS uses a number of voice-independent automated speech recognition ( ASR ) engines , with the usage dependent on the languages and the particular domain .</sentence>
				<definiendum id="0">S-MINDS</definiendum>
				<definiens id="0">uses a number of voice-independent automated speech recognition ( ASR ) engines , with the usage dependent on the languages and the particular domain</definiens>
			</definition>
			<definition id="1">
				<sentence>iii Sehda’s ( internal ) dialog/translation creation tools allow developers to compile and run new dialogs with any ASR engine so they do not have to be encumbered by the nuances of any particular engine .</sentence>
				<definiendum id="0">iii Sehda’s</definiendum>
				<definiens id="0">internal ) dialog/translation creation tools allow developers to compile and run new dialogs with any ASR engine so they do not have to be encumbered by the nuances of any particular engine</definiens>
			</definition>
			<definition id="2">
				<sentence>A complete S-MINDS system contains three main hardware components : a Windows XP computer with S-MINDS software installed ; a headset microphone , which the healthcare provider uses to control S-MINDS and communicate with the patient ; and a telephone handset , which the patient uses to communicate with the provider .</sentence>
				<definiendum id="0">headset microphone</definiendum>
				<definiens id="0">a Windows XP computer with S-MINDS software installed</definiens>
			</definition>
</paper>

		<paper id="2701">
			<definition id="0">
				<sentence>Corpus-based question answering is a complex task that draws from information retrieval , information extraction and computational linguistics to pinpoint information users are interested in .</sentence>
				<definiendum id="0">Corpus-based question answering</definiendum>
				<definiens id="0">a complex task that draws from information retrieval , information extraction and computational linguistics to pinpoint information users are interested in</definiens>
			</definition>
			<definition id="1">
				<sentence>The source text , or character data , isstoredinaBinaryLargeOBject ( BLOB ) , andall annotations , in a single XML document .</sentence>
				<definiendum id="0">isstoredinaBinaryLargeOBject ( BLOB</definiendum>
				<definiens id="0">source text , or character data</definiens>
			</definition>
			<definition id="2">
				<sentence>XML is a tree structured language and provides very limited capabilities for representing several annotations of the same data simultaneously , even when each of the annotations is tree-like .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">a tree structured language and provides very limited capabilities for representing several annotations of the same data simultaneously</definiens>
			</definition>
			<definition id="3">
				<sentence>XIRAF ( Figure 2 ) combines multiple text processing tools , each having an input descriptor and a tool-specific wrapper that converts the tool output into stand-off XML annotation .</sentence>
				<definiendum id="0">XIRAF</definiendum>
			</definition>
			<definition id="4">
				<sentence>Using XIRAF , we annotate the corpora with named entities ( including type information ) , temporal expressions ( normalized to ISO values ) , syntactic chunks , and syntactic parses ( dependencyparsesforDutchandphrasestructure 6 ; 4XHVWD ; ,5 $ ) ) HDWXUH ( [ WUDFWLRQ ) UDPHZRUN ; 4XHU\ 6\VWHP a0a2a1a3a1a5a4a5a6a7a5a6 a8a4a9a1a5a10 a11 a12a2a13a15a14 a16a17a4a3a18a20a19a20a21a23a22a24a1a25a6a26 a27 a14a3a28a30a29 a27 a4a9a31 a32a17a19a5a10 a11 a33a30a8a1a5a7a24a31a34a15a14a5a7a9a31a35a3a22 a36a23a37a39a38a22a17a18a39a6a24a11a40a33a41a14 a36 a33a42a26 a26 a12a44a43a45a19a25a22a24a31a34 a46 a1a47a6 a22a24a31 a48 a7a3a18a47a22 a13a49a4a9a1a25a22a20a6a50a51a33a24a52a12a44a43a45a19a25a22a24a31a34 a53a41a54 a55a24a56a9a57a42a58a2a59a59 a60a2a61a17a62a20a63 a64a42a65a42a65a67a66a3a68a30a62a24a69a9a65a9a63a42a70a54 a65a67a71 a72 a6 a4a3a4a9a73a74a0 a6 a4a3a4a9a73a47a33 a6 a4a3a4a9a73 a27 a75a17a62 a55a20a54a77a76 a71 a62 a78a24a61 a54 a71 a55a9a79a5a54 a70a65 a56 a75a42a71 a55a9a80 a62a20a81a45a65a67a71a77a82 a83a85a84 a76 a62a20a63 a54 a55 a84 a76 a62a20a63 a54 a70a65 a56 a60 a56a17a55 a66a72a17a63a42a70a63 Figure 2 : XIRAF Architecture a0a2a1a4a3 a5a4a6a8a7a9a4a10a2a11a12a3 a13 a14a16a15a18a17a19a14a18a14a16a20 a21a22a11a18a9 a17a19a14a18a14a16a20 a23 a20a7a24a25a9a27a26a16a9a29a28a30a5 a14 a9a12a31a32a1 a15 a3 a14 a11a12a3 a10a2a11a12a3a18a3 a14a8a33 a3 a26a16a9a29a28a18a34 a14a32a13 a13 a35a9 a33 a1 a15 a3a36a7a9a12a3 a14 a28a2a26a32a3 a26a2a37a4a26 a33 a1 a38 a39 a40 a41 a3 a1a18a42a12a3a16a43a27a44a46a45a48a47 a26a16a9a18a9 a14 a3 a26a32a3 a7a14 a9 a33 a44a46a45a48a47 a44a22a45a30a47 a3 a1a4a42a29a3a16a43a27a44a46a45a48a47a27a26a16a9a18a9 a14 a3 a26a32a3 a7a14 a9 a33 a44a22a45a30a47 a49 a47a18a50a51a0 a49a46a14a16a15 a10a2a11 a33 a43 a52 a3 a26a16a9a29a28a2a53 a13 a13 a44a22a45a30a47 Figure 3 : Tool Wrapping Example parses for English ) .</sentence>
				<definiendum id="0">HDWXUH</definiendum>
				<definiens id="0">the corpora with named entities ( including type information ) , temporal expressions ( normalized to ISO values ) , syntactic chunks , and syntactic parses</definiens>
				<definiens id="1">XIRAF Architecture a0a2a1a4a3 a5a4a6a8a7a9a4a10a2a11a12a3 a13 a14a16a15a18a17a19a14a18a14a16a20 a21a22a11a18a9 a17a19a14a18a14a16a20 a23 a20a7a24a25a9a27a26a16a9a29a28a30a5 a14 a9a12a31a32a1 a15 a3 a14 a11a12a3 a10a2a11a12a3a18a3 a14a8a33 a3 a26a16a9a29a28a18a34 a14a32a13 a13 a35a9 a33 a1 a15 a3a36a7a9a12a3 a14 a28a2a26a32a3 a26a2a37a4a26 a33 a1 a38 a39 a40 a41 a3 a1a18a42a12a3a16a43a27a44a46a45a48a47 a26a16a9a18a9 a14 a3 a26a32a3 a7a14 a9 a33 a44a46a45a48a47 a44a22a45a30a47 a3 a1a4a42a29a3a16a43a27a44a46a45a48a47a27a26a16a9a18a9 a14 a3 a26a32a3 a7a14 a9 a33 a44a22a45a30a47 a49 a47a18a50a51a0 a49a46a14a16a15 a10a2a11 a33 a43 a52 a3 a26a16a9a29a28a2a53 a13 a13 a44a22a45a30a47 Figure 3 : Tool Wrapping Example parses for English )</definiens>
			</definition>
			<definition id="5">
				<sentence>Note that phrase and word elements are annotations generated by a single tool ( the phrase-structure parser ) and thus in the same annotation layer , which is why standard XPath can be used to express this query .</sentence>
				<definiendum id="0">word elements</definiendum>
				<definiens id="0">annotations generated by a single tool ( the phrase-structure parser</definiens>
			</definition>
			<definition id="6">
				<sentence>, `` Kennedy '' ) ] /select-narrow : :timex This query can be glossed : find temporal expressions whose textual extent is contained inside a sentence ( or clause ) that is headed by assassinated and contains the string “Kennedy” .</sentence>
				<definiendum id="0">Kennedy</definiendum>
				<definiens id="0">find temporal expressions whose textual extent is contained inside a sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>, `` Kennedy '' ) ] /phrase [ @ type= '' NP '' ] / select-wide : :ne [ @ type= '' per '' ] This query can be glossed : find person namedentities whose textual extent overlaps the textual extent of an NP phrase that is the subject of a sentence phrase that is headed by killed and contains the string “Kennedy” .</sentence>
				<definiendum id="0">Kennedy</definiendum>
				<definiens id="0">textual extent overlaps the textual extent of an NP phrase that is the subject of a sentence phrase that is headed by killed</definiens>
			</definition>
</paper>

		<paper id="0505">
			<definition id="0">
				<sentence>WordNet ( Fellbaum et al. , 1998 ) is a lexical database whose design is inspired by psycholinguistic theories of human lexical memory .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a lexical database whose design is inspired by psycholinguistic theories of human lexical memory</definiens>
			</definition>
			<definition id="1">
				<sentence>A synset is a collection of words that have a close meaning and that represent an underlying concept .</sentence>
				<definiendum id="0">synset</definiendum>
				<definiens id="0">a collection of words that have a close meaning</definiens>
			</definition>
			<definition id="2">
				<sentence>A noun X is a hypernym of a noun Y if Y is a subtype or instance of X. For example , “bird” is a hypernym of “penguin” ( and “penguin” is a hyponym of “bird” ) .</sentence>
				<definiendum id="0">noun X</definiendum>
				<definiendum id="1">“bird”</definiendum>
			</definition>
			<definition id="3">
				<sentence>Using the hypernym/hyponym relations from WordNet , we can also easily find out that “ambulance” is a kind of “car” , which in turn is a kind of “conveyance , transport” which in turn is a “physical object” .</sentence>
				<definiendum id="0">“ambulance”</definiendum>
				<definiens id="0">a kind of “conveyance , transport” which in turn is a “physical object”</definiens>
			</definition>
			<definition id="4">
				<sentence>Conditional random fields ( CRFs ) ( Lafferty et al. , 2001 ; Jordan , 1999 ; Wallach , 2004 ) is a statistical method based on undirected graphical models .</sentence>
				<definiendum id="0">Conditional random fields</definiendum>
				<definiendum id="1">CRFs )</definiendum>
				<definiens id="0">a statistical method based on undirected graphical models</definiens>
			</definition>
			<definition id="5">
				<sentence>If each random variable Yv obeys the Markov property with respect to G ( e.g. , in a first order model the transition probability depends only on the neighboring state ) , then the model ( Y , X ) is a Conditional Random Field .</sentence>
				<definiendum id="0">X )</definiendum>
				<definiens id="0">a Conditional Random Field</definiens>
			</definition>
			<definition id="6">
				<sentence>A CRF defines a conditional probability distribution p ( Y|X ) of label sequences given input sequences .</sentence>
				<definiendum id="0">CRF</definiendum>
				<definiens id="0">defines a conditional probability distribution p ( Y|X ) of label sequences given input sequences</definiens>
			</definition>
			<definition id="7">
				<sentence>Considering K feature functions , the conditional probability distribution defined by the CRF is p ( y|x ) = 1Z ( x ) exp braceleftBigg Tsummationdisplay t=1 Ksummationdisplay k=1 λkfk ( yt−1 , yt , x ) bracerightBigg ( 2 ) where λj is a parameter to model the observed statistics and Z ( x ) is a normalizing constant computed as Z ( x ) = summationdisplay y∈Y exp braceleftBigg Tsummationdisplay t=1 Ksummationdisplay k=1 λkfk ( yt−1 , yt , x ) bracerightBigg This method can be thought of a generalization of both the Maximum Entropy Markov model ( MEMM ) and the Hidden Markov model ( HMM ) .</sentence>
				<definiendum id="0">Z ( x )</definiendum>
				<definiens id="0">a parameter to model the observed statistics</definiens>
				<definiens id="1">a normalizing constant computed as Z ( x ) = summationdisplay y∈Y exp braceleftBigg Tsummationdisplay t=1 Ksummationdisplay k=1 λkfk ( yt−1 , yt , x ) bracerightBigg This method can be thought of a generalization of both the Maximum Entropy Markov model ( MEMM ) and the Hidden Markov model ( HMM )</definiens>
			</definition>
			<definition id="8">
				<sentence>Formally , we are given a set of training examples D = braceleftBig x ( i ) , y ( i ) bracerightBigN i=1 where each x ( i ) = braceleftBig x ( i ) 1 , x ( i ) 2 , ... , x ( i ) T bracerightBig is a sequence of inputs and y ( i ) = braceleftBig y ( i ) 1 , y ( i ) 2 , ... , y ( i ) T bracerightBig is a sequence of the desired labels .</sentence>
				<definiendum id="0">x ( i ) T bracerightBig</definiendum>
				<definiens id="0">a sequence of inputs and y ( i ) = braceleftBig y ( i ) 1 , y ( i ) 2 , ... , y ( i ) T bracerightBig is a sequence of the desired labels</definiens>
			</definition>
			<definition id="9">
				<sentence>This algorithm has a computational complexity of O ( TM2 ) ( where T is the length of the sequence and M the number of the labels ) .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the length of the sequence and M the number of the labels )</definiens>
			</definition>
			<definition id="10">
				<sentence>The total cost of training a linear-chained CRFs is thus : O ( TM2NG ) where N is the number of training examples and G the number of iterations .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of training examples</definiens>
			</definition>
			<definition id="11">
				<sentence>Informally , Fv is the collection of features which are useful to evaluate for a certain node .</sentence>
				<definiendum id="0">Fv</definiendum>
				<definiens id="0">the collection of features which are useful to evaluate for a certain node</definiens>
			</definition>
			<definition id="12">
				<sentence>The probability of this labeling ytop−1 is p ( ytop−1|x ) = 1Z′ ( x ) Tproductdisplay t=1 G′ ( yt−1 , ytop−1t , x ) where Z′ ( x ) is an appropriate normalizing constant .</sentence>
				<definiendum id="0">Z′ ( x )</definiendum>
				<definiens id="0">an appropriate normalizing constant</definiens>
			</definition>
			<definition id="13">
				<sentence>The Mallet package ( McCallum , 2002 ) is an integrated collection of Java code useful for statistical natural language processing , document classification , clustering , and information extraction .</sentence>
				<definiendum id="0">Mallet package</definiendum>
				<definiens id="0">an integrated collection of Java code useful for statistical natural language processing , document classification , clustering , and information extraction</definiens>
			</definition>
</paper>

		<paper id="3603">
			<definition id="0">
				<sentence>A span is a range over contiguous words in the input .</sentence>
				<definiendum id="0">span</definiendum>
				<definiens id="0">a range over contiguous words in the input</definiens>
			</definition>
			<definition id="1">
				<sentence>The frontier of a state consists of the items with no parents yet .</sentence>
				<definiendum id="0">frontier of a state</definiendum>
				<definiens id="0">consists of the items with no parents yet</definiens>
			</definition>
			<definition id="2">
				<sentence>Ω ( α ) in Equation 3 is a regularizer , which penalizes overly complex models to reduce overfitting and generalization error .</sentence>
				<definiendum id="0">Ω ( α</definiendum>
				<definiens id="0">penalizes overly complex models to reduce overfitting and generalization error</definiens>
			</definition>
			<definition id="3">
				<sentence>We use the lscript1 penalty : Ω ( α ) = summationdisplay f λ·|αf| ( 7 ) where λ is the lscript1 parameter that controls the strength of the regularizer .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiens id="0">the lscript1 parameter that controls the strength of the regularizer</definiens>
			</definition>
			<definition id="4">
				<sentence>The overall score given to an inference by the whole ensemble is the sum of the confidences returned by the trees in the ensemble .</sentence>
				<definiendum id="0">ensemble</definiendum>
				<definiens id="0">the sum of the confidences returned by the trees in the ensemble</definiens>
			</definition>
			<definition id="5">
				<sentence>We have : ∂L ( I ; α ) ∂αf = summationdisplay i∈I ∂l ( i ; α ) ∂µ ( i ; α ) · ∂µ ( i ; α ) ∂αf ( 8 ) where : ∂µ ( i ; α ) ∂αf = y ( i ) ·X f ( i ) ( 9 ) We define the weight of an example under the current model as : w ( i ; α ) =−∂l ( i ; α ) ∂µ ( i ; α ) = b ( i ) · 11 + exp ( µ ( i ; α ) ) .</sentence>
				<definiendum id="0">i ) ·X f ( i )</definiendum>
				<definiendum id="1">α</definiendum>
				<definiens id="0">the weight of an example under the current model as : w ( i ;</definiens>
			</definition>
			<definition id="6">
				<sentence>Otherwise , G f is the magnitude of the gradient of the objective as we adjust αf in the appropriate direction .</sentence>
				<definiendum id="0">G f</definiendum>
				<definiens id="0">the magnitude of the gradient of the objective as we adjust αf in the appropriate direction</definiens>
			</definition>
			<definition id="7">
				<sentence>The gain of splitting node f using some atomic feature a is defined as ˇG f ( a ) = G f∧a + G f∧¬a ( 14 ) We allow node f to be split only by atomic features a that increase the gain , i.e. ˇG f ( a ) &gt; G f .</sentence>
				<definiendum id="0">atomic feature</definiendum>
				<definiendum id="1">ˇG f</definiendum>
				<definiendum id="2">ˇG f</definiendum>
				<definiens id="0">a ) = G f∧a + G f∧¬a ( 14 ) We allow node f to be split only by atomic features a that increase the gain</definiens>
				<definiens id="1">a ) &gt; G f</definiens>
			</definition>
			<definition id="8">
				<sentence>Decision trees ensure that these compound features are mutually exclusive , so they can be directly optimized independently of each other using a line search over the objective R. 6Since α is fixed during a particular training iteration and I is fixed throughout training , we omit parameters ( I ; α ) henceforth .</sentence>
				<definiendum id="0">Decision trees</definiendum>
				<definiens id="0">using a line search over the objective R. 6Since α is fixed during a particular training iteration and I is fixed throughout training</definiens>
			</definition>
</paper>

		<paper id="2926">
			<definition id="0">
				<sentence>The parsing algorithm is a modi ed shift-reduce parser ( Aho et al. , 1986 ) that makes use of the actions described above and applies them in a left to right manner on consecutive word pairs ( a , b ) ( a &lt; b ) in the word list T. T is initialized as the full sentence .</sentence>
				<definiendum id="0">parsing algorithm</definiendum>
				<definiens id="0">a modi ed shift-reduce parser ( Aho et al. , 1986 ) that makes use of the actions described above and applies them in a left to right manner on consecutive word pairs ( a , b ) ( a &lt; b ) in the word list T. T is initialized as the full sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>getFeatures extracts the features describing the currently considered pair of words ; getAction determines the appropriate action for the pair ; assignParent assigns the parent for the child word based on the action ; and deleteWord deletes the word which become child once the action is taken .</sentence>
				<definiendum id="0">getAction</definiendum>
				<definiendum id="1">deleteWord</definiendum>
				<definiens id="0">determines the appropriate action for the pair ; assignParent assigns the parent for the child word based on the action</definiens>
			</definition>
			<definition id="2">
				<sentence>The de nition of Lift is as follows : Lift ( wj → wk ) = parent ( wj ) → wk , where a → b means that a is the parent of b , and parent is a function which returns the parent word of the given word .</sentence>
				<definiendum id="0">parent</definiendum>
				<definiens id="0">a function which returns the parent word of the given word</definiens>
			</definition>
			<definition id="3">
				<sentence>SNoW uses softmax over the raw activation values as its con dence measure , which can be shown to be a reliable approximation of the labels’ probabilities .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiens id="0">uses softmax over the raw activation values as its con dence measure</definiens>
			</definition>
			<definition id="4">
				<sentence>For each word pair ( w1 , w2 ) , we used their LEMMA , the POSTAG and also the POSTAG of the children of w1 and w2 .</sentence>
				<definiendum id="0">LEMMA</definiendum>
				<definiens id="0">, the POSTAG and also the POSTAG of the children of w1 and w2</definiens>
			</definition>
			<definition id="5">
				<sentence>The other problem for Czech is that Czech is one of the languages with many types of part of speech and dependency types , and also the 2Training our system for most languages takes 30 minutes or 1 hour for both phases of labeling HEAD and DEPREL .</sentence>
				<definiendum id="0">Czech</definiendum>
				<definiens id="0">one of the languages with many types of part of speech and dependency types</definiens>
			</definition>
</paper>

		<paper id="0202">
			<definition id="0">
				<sentence>A common approach to Information Extraction ( IE ) is to use patterns which match against text and identify items of interest .</sentence>
				<definiendum id="0">Information Extraction ( IE )</definiendum>
				<definiens id="0">to use patterns which match against text and identify items of interest</definiens>
			</definition>
			<definition id="1">
				<sentence>Predicate-Argument Model ( SVO ) : A simple approach , used by Yangarber ( 2003 ) and Stevenson and Greenwood ( 2005 ) , is to use subject-verbobject tuples from the dependency parse as extraction patterns .</sentence>
				<definiendum id="0">Predicate-Argument Model ( SVO )</definiendum>
				<definiens id="0">A simple approach</definiens>
			</definition>
			<definition id="2">
				<sentence>Each node in the tree is represented in the format a [ b/c ] ( e.g. subj [ N/bomber ] ) where c is the lexical item ( bomber ) , b its grammatical tag ( N ) and a the dependency relation between this node and its parent ( subj ) .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">the lexical item ( bomber ) , b its grammatical tag ( N ) and a the dependency relation between this node</definiens>
			</definition>
			<definition id="3">
				<sentence>The relationship between nodes is represented as X ( A+B+C ) which indicates that nodes A , B and C are direct descendents of node X. of participants in specific events .</sentence>
				<definiendum id="0">X ( A+B+C )</definiendum>
				<definiens id="0">indicates that nodes A , B and C are direct descendents of node X. of participants in specific events</definiens>
			</definition>
			<definition id="4">
				<sentence>Chains : A pattern is defined as a path between a verb node and any other node in the dependency tree passing through zero or more intermediate nodes ( Sudo et al. , 2001 ) .</sentence>
				<definiendum id="0">Chains</definiendum>
			</definition>
			<definition id="5">
				<sentence>The subtree model is a richer representation than those discussed so far and can represent any part of a dependency tree .</sentence>
				<definiendum id="0">subtree model</definiendum>
				<definiens id="0">a richer representation than those discussed so far and can represent any part of a dependency tree</definiens>
			</definition>
			<definition id="6">
				<sentence>Predicate-Argument Model ( SVO ) : The number of SVO patterns extracted from T is : Nsvo ( T ) = |V | ( 1 ) Chain Model : A chain can be created between any verb and a node it dominates ( directly or indirectly ) .</sentence>
				<definiendum id="0">Predicate-Argument Model ( SVO )</definiendum>
				<definiens id="0">The number of SVO patterns extracted from T is : Nsvo ( T ) = |V | ( 1 ) Chain Model : A chain can be created between any verb and a node it dominates ( directly or indirectly )</definiens>
			</definition>
			<definition id="7">
				<sentence>Now assume that d ( v ) denotes the count of a node v and all its descendents then the number of chains is given by : Nchains ( T ) = summationdisplay v∈V ( d ( v ) −1 ) ( 2 ) Linked Chains : Let C ( v ) denote the set of direct child nodes of node v and vi denote the i-th child , so C ( v ) = braceleftbigv1 , v2 , ... v|C ( v ) |bracerightbig .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the count of a node v and all its descendents then the number of chains is given by : Nchains ( T ) = summationdisplay v∈V</definiens>
			</definition>
			<definition id="8">
				<sentence>The number of possible linked chains in T is given by : Nlinkedchains ( T ) = summationdisplay v∈V |C ( v ) |summationdisplay i=1 |C ( v ) |summationdisplay j=i+1 d ( vi ) d ( vj ) ( 3 ) Subtrees : Now assume that sub ( n ) is a function denoting the number of subtrees , including single nodes , rooted at node n. This can be defined recursively as follows : sub ( n ) =    1 if n is a leaf node |C ( n ) |producttext i=1 ( sub ( ni ) + 1 ) otherwise ( 4 ) The total number of subtrees in a tree is given by : Nsubtree ( T ) = parenleftBiggsummationdisplay n∈N sub ( n ) parenrightBigg −|N| ( 5 ) The dependency tree shown in Figure 1 generates 2 , 8 , 14 and 42 possible SVO , chain , linked chain and subtree patterns respectively .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">node |C</definiendum>
				<definiendum id="2">parenleftBiggsummationdisplay n∈N sub</definiendum>
				<definiendum id="3">parenrightBigg −|N|</definiendum>
				<definiens id="0">a function denoting the number of subtrees</definiens>
				<definiens id="1">a leaf</definiens>
			</definition>
			<definition id="9">
				<sentence>Events in this corpus identify relations between up to four entities : PersonIn ( the person starting a new job ) , PersonOut ( person leaving a job ) , Post ( the job title ) and Organisation ( the employer ) .</sentence>
				<definiendum id="0">PersonIn</definiendum>
				<definiendum id="1">Organisation</definiendum>
				<definiens id="0">the person starting a new job ) , PersonOut ( person leaving a job )</definiens>
			</definition>
			<definition id="10">
				<sentence>The second corpus uses documents taken from the biomedical domain , specifically the training corpus used in the LLL-05 challenge task ( N´edellec , 2005 ) , and a pair of corpora ( Craven and Kumlien , 1999 ) which were derived from the Yeast Proteome Database ( YPD ) ( Hodges et al. , 1999 ) and the Online Mendelian Inheritance in Man database ( OMIM ) ( Hamosh et al. , 2002 ) .</sentence>
				<definiendum id="0">OMIM )</definiendum>
				<definiens id="0">were derived from the Yeast Proteome Database ( YPD ) ( Hodges et al. , 1999 ) and the Online Mendelian Inheritance in Man database</definiens>
			</definition>
			<definition id="11">
				<sentence>These three parsers represent a cross-section of approaches to producing dependency analyses : MINIPAR uses a constituency grammar internally before converting the result to a dependency tree , Machinese Syntax uses a functional dependency grammar , and the Stanford Parser is a lexicalized probabilistic parser .</sentence>
				<definiendum id="0">Stanford Parser</definiendum>
				<definiens id="0">a lexicalized probabilistic parser</definiens>
			</definition>
</paper>

		<paper id="1659">
			<definition id="0">
				<sentence>Hany Hassan Ahmed Hassan Ossama Emam IBM Cairo Technology Development Center Giza , Egypt P.O. Box 166 Al-Ahram hanyh @ eg.ibm.com hasanah @ eg.ibm.com emam @ eg.ibm.com Information Extraction ( IE ) is the task of extracting knowledge from unstructured text .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
			</definition>
			<definition id="1">
				<sentence>Relation Detection and Characterization ( RDC ) was introduced in the Automatic Content Extraction Program ( ACE ) ( ACE , 2004 ) .</sentence>
				<definiendum id="0">Relation Detection</definiendum>
				<definiendum id="1">Characterization ( RDC</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Hypertext Induced Topic Selection ( HITS ) algorithm is an algorithm for rating , and therefore ranking , web pages .</sentence>
				<definiendum id="0">Hypertext Induced Topic Selection</definiendum>
				<definiens id="0">an algorithm for rating , and therefore ranking , web pages</definiens>
			</definition>
			<definition id="3">
				<sentence>A hub value is the sum of the scaled authority values of the authorities it points to .</sentence>
				<definiendum id="0">hub value</definiendum>
				<definiens id="0">the sum of the scaled authority values of the authorities it points to</definiens>
			</definition>
			<definition id="4">
				<sentence>A template , as we define for this work , is a sequence of generic forms that could generalize 502 over the given instances .</sentence>
				<definiendum id="0">template</definiendum>
				<definiens id="0">a sequence of generic forms that could generalize 502 over the given instances</definiens>
			</definition>
			<definition id="5">
				<sentence>A tuple , in our notation during this paper , is the result of the application of a pattern to unstructured text .</sentence>
				<definiendum id="0">tuple</definiendum>
			</definition>
			<definition id="6">
				<sentence>The weights are calculated iteratively as follows : ( ) ( ) ( )  =+ = pTu iii H uhpa 1 ) ( ) ( ) 1 ( ( 1 ) ( ) ( ) ( )  =+ = tPu iii A uath 1 ) ( ) ( ) 1 ( ( 2 ) where T ( p ) is the set of tuples matched by p , P ( t ) is the set of patterns matching t , ( ) pa i ) 1 ( + is the authoritative weight of pattern p at iteration ) 1 ( +i , and ( ) th i ) 1 ( + is the hub weight of tuple t at iteration ) 1 ( +i .</sentence>
				<definiendum id="0">( ) th</definiendum>
				<definiendum id="1">+</definiendum>
				<definiens id="0">the set of tuples matched by p</definiens>
				<definiens id="1">the set of patterns matching t , ( ) pa i ) 1 ( + is the authoritative weight of pattern p at iteration ) 1 ( +i , and</definiens>
			</definition>
			<definition id="7">
				<sentence>MCL is a fast and scalable unsupervised clustering algorithm for graphs based on simulation of stochastic flow .</sentence>
				<definiendum id="0">MCL</definiendum>
				<definiens id="0">a fast and scalable unsupervised clustering algorithm for graphs based on simulation of stochastic flow</definiens>
			</definition>
			<definition id="8">
				<sentence>ACE is an evaluation conducted by NIST to measure Entity Detection and Tracking ( EDT ) and Relation Detection and Characterization ( RDC ) .</sentence>
				<definiendum id="0">ACE</definiendum>
			</definition>
			<definition id="9">
				<sentence>Mentions are any instances of textual references to objects like people , organizations , geopolitical entities ( countries , cities …etc ) , locations , or facilities .</sentence>
				<definiendum id="0">Mentions</definiendum>
				<definiens id="0">any instances of textual references to objects like people , organizations , geopolitical entities ( countries , cities …etc ) , locations , or facilities</definiens>
			</definition>
</paper>

		<paper id="0125">
			<definition id="0">
				<sentence>The above model consists of two sub-models : the state transition model ∑ = − n i i i SsPMI 2 1 1 ) , ( , which can be computed by applying ngram modeling , and the output model ∑ = n i n i OsP 1 1 ) | ( log , which can be estimated by any probability-based classifier , such as a maximum entropy classifier or a SVM plus sigmoid classifier ( Zhou et al 2006 ) .</sentence>
				<definiendum id="0">above model</definiendum>
			</definition>
			<definition id="1">
				<sentence>For Chinese word segmentation and named entity recognition by chunking , a word or a entity name is regarded as a chunk of one or more word atoms and we have : • &gt; = &lt; iii wpo , ; i w is the thi − word atom in the sequence of word atoms n n wwwWL 211 = ; i p is the word formation pattern of the word atom i w .</sentence>
				<definiendum id="0">i w</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">the word formation pattern of the word atom i w</definiens>
			</definition>
			<definition id="2">
				<sentence>i s is structural and consists of two parts : o Boundary category ( B ) : it includes four values : { O , B , M , E } , where O means that current word atom is a whOle word or entity name and B/M/E means that current word atom is at the Beginning/in the Middle/at the End of a word or entity name .</sentence>
				<definiendum id="0">O</definiendum>
				<definiens id="0">structural and consists of two parts : o Boundary category ( B ) : it includes four values : { O , B , M</definiens>
			</definition>
			<definition id="3">
				<sentence>LearningPatterns ( ) // Input : training corpus // Output : patterns BEGIN ( 1 ) Training a MIIM model using training corpus ( 2 ) Using the MIIM model to segment training corpus ( 3 ) Aligning the training corpus with the segmented training corpus ( 4 ) Extracting error segmentations ( 5 ) Generating disambiguation patterns using the left and right context ( 6 ) Removing the conflicting entries if two patterns have the same left hand side but different right hand side .</sentence>
				<definiendum id="0">LearningPatterns</definiendum>
			</definition>
			<definition id="4">
				<sentence>Precision ( P ) , Recall ( R ) , F-measure ( F ) , OOV Recall and IV Recall are adopted to measure the performance of word segmentation .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">Recall ( R</definiendum>
				<definiens id="0">F-measure ( F ) , OOV Recall and IV Recall are adopted to measure the performance of word segmentation</definiens>
			</definition>
</paper>

		<paper id="1113">
			<definition id="0">
				<sentence>Then a total cost for the alignment , C ( σ′ ) can be defined as the sum of these components costs , and the tree distance can then be defined as the cost of the least-cost map : ∆ ( S , T ) = min ( { C ( σ′ ) | σ ∈ H ( S , T ) } ) For any 3 trees , T1 , T2 , T3 , the triangle inequality holds ∆ ( T1 , T3 ) ≤ ∆ ( T1 , T2 ) + ∆ ( T2 , T3 ) .</sentence>
				<definiendum id="0">total cost for the alignment , C ( σ′ )</definiendum>
				<definiens id="0">the sum of these components costs</definiens>
				<definiens id="1">the cost of the least-cost map : ∆ ( S , T ) = min ( { C ( σ′ ) | σ ∈ H ( S , T ) } ) For any 3 trees , T1 , T2 , T3 , the triangle inequality holds ∆ ( T1 , T3 ) ≤ ∆ ( T1 , T2 ) + ∆ ( T2</definiens>
			</definition>
			<definition id="1">
				<sentence>1If Tj 1 = σ ( Si1 ) and Tj2 = σ ( Si2 ) then ( i ) Si1 is to theleft of S i2 iff Tj1 is to the left of Tj2 and ( ii ) Si1 is a descendant of Si2 iff Tj1 is a descendant of Tj2 , with descendency understood as the transitive closure of the daugher-mother relation .</sentence>
				<definiendum id="0">Si1</definiendum>
				<definiendum id="1">Tj1</definiendum>
				<definiens id="0">to theleft of S i2 iff Tj1 is to the left of Tj2 and ( ii )</definiens>
				<definiens id="1">a descendant of Tj2 , with descendency understood as the transitive closure of the daugher-mother relation</definiens>
			</definition>
			<definition id="2">
				<sentence>Where ∆ ( S , T ) gives the cost of aligning the whole source tree S with the target T , one can consider variants where one minimises over a set of subparts of S. This is equivalent to letting all but the nodes belonging to the chosen sub-part to delete at zero cost3 .</sentence>
				<definiendum id="0">∆ ( S , T )</definiendum>
				<definiens id="0">gives the cost of aligning the whole source tree S with the target T , one can consider variants where one minimises over a set of subparts of S.</definiens>
			</definition>
			<definition id="3">
				<sentence>if ( d is head or complement ) { assign weight = 1/rank , Str ( rank , d ) } else if ( d is adjunct ) { assign weight = 1/ ( 5 × rank ) , Str ( 5∗ rank , d ) } else { assign weight = 1/ ( 2 × rank ) Str ( 2∗ rank , d ) } LEX is a function which can be composed with STR , and scales up the weights of leaf nodes by a factor of 3 .</sentence>
				<definiendum id="0">LEX</definiendum>
				<definiens id="0">a function which can be composed with STR , and scales up the weights of leaf nodes by a factor of 3</definiens>
			</definition>
			<definition id="4">
				<sentence>A wild card np tree might can be put in the position of the gap in wh-questions , allowing for example what is memory allocation , to closely match any sentences with memory allocation as their object , no matter what their subject – see Figure 3 .</sentence>
				<definiendum id="0">wild card np tree</definiendum>
				<definiens id="0">memory allocation , to closely match any sentences with memory allocation as their object , no matter what their subject – see Figure 3</definiens>
			</definition>
			<definition id="5">
				<sentence>Source self-effacers S/λ : this is a function which classifies source sub-trees as selfeffacers .</sentence>
				<definiendum id="0">Source self-effacers S/λ</definiendum>
				<definiens id="0">a function which classifies source sub-trees as selfeffacers</definiens>
			</definition>
			<definition id="6">
				<sentence>101 process n np s vp rhs lhs be rhs lhs vp call be memory n n n allocation np something pro np s vp lhs rhs memory n n n allocation np sub tree matching dist=5.0 Figure 1 : Sub tree example we define Π ( s , t ) , as ∆ ( l tree ( s ) , l tree ( t ) ) , and π ( s , t ) , as vectorδ ( l tree ( s ) , l tree ( t ) ) , then Π and π coincide with the standard sequence edit distance and sub-sequence edit distance .</sentence>
				<definiendum id="0">π ( s</definiendum>
				<definiens id="0">n n allocation np something pro np s vp lhs rhs memory n n n allocation np sub tree matching dist=5.0 Figure 1</definiens>
			</definition>
			<definition id="7">
				<sentence>If we define Πw ( a , b ) as |aw ∪ bw|−|aw ∩ bw| – the size of the symmetric difference between aw and bw – this can be seen as a set-based version of edit distance5 , which ( i ) considers mappings on the sets of words , aw , bw , not the sequences a , b , and ( ii ) sets replacement cost to infinity .</sentence>
				<definiendum id="0">Πw</definiendum>
				<definiens id="0">a set-based version of edit distance5 , which ( i ) considers mappings on the sets of words</definiens>
			</definition>
			<definition id="8">
				<sentence>The Cosine is a measure of the angle between the vectors vectora , vectorb , and is not relatable in the 5Πw ( a , b ) could be equivalently defined as | ( vectora −vectorb ) |2 binary-case to the alignment-based , differencecounting perspective of the edit-distances : dividing Πw ( a , b ) , the symmetric difference , by |aw|.5|bw|.5 does not give a measure with maximum value 1 for the disjoint case , and does not give the reverse of a ranking by Cosine similarity.6 Below we shall use θ to denote the Cosine distance .</sentence>
				<definiendum id="0">Cosine</definiendum>
				<definiens id="0">a measure of the angle between the vectors vectora , vectorb , and is not relatable in the 5Πw ( a</definiens>
				<definiens id="1">the alignment-based , differencecounting perspective of the edit-distances : dividing Πw ( a , b ) , the symmetric difference , by |aw|.5|bw|.5 does not give a measure with maximum value 1 for the disjoint case , and does not give the reverse of a ranking</definiens>
			</definition>
			<definition id="9">
				<sentence>The Collins parser ( Collins , 1999 ) ( Model 3 variant ) is a probabilistic parser , using a model of trees as built top-down with a repertoire of moves , learnt from the Penn Treebank .</sentence>
				<definiendum id="0">Collins parser</definiendum>
				<definiens id="0">a probabilistic parser , using a model of trees as built top-down with a repertoire of moves , learnt from the Penn Treebank</definiens>
			</definition>
			<definition id="10">
				<sentence>The preterminal node labels are a combination of a Penn Treebank label with other information pertaining to the head/complement/adjunct distinction , but the replacement cost function R is set to ignore all but the Penn Treebank part of the label .</sentence>
				<definiendum id="0">preterminal node labels</definiendum>
				<definiens id="0">a combination of a Penn Treebank label with other information pertaining to the head/complement/adjunct distinction , but the replacement cost function R is set to ignore all but the Penn Treebank part of the label</definiens>
			</definition>
</paper>

		<paper id="2920">
			<definition id="0">
				<sentence>Mel’ˇcuk ( 1988 ) describes a multistratal dependency grammar , i.e. one that distinguishes between several types of dependency relations ( morphological , syntactic and semantic ) .</sentence>
				<definiendum id="0">multistratal dependency grammar</definiendum>
				<definiens id="0">morphological , syntactic and semantic )</definiens>
			</definition>
			<definition id="1">
				<sentence>A sentence consists of one or more tokens .</sentence>
				<definiendum id="0">sentence</definiendum>
			</definition>
			<definition id="2">
				<sentence>For the Arabic data only , FORM is a concatenation of the word in Arabic script and its transliteration in Latin script , separated by an underscore .</sentence>
				<definiendum id="0">FORM</definiendum>
				<definiens id="0">a concatenation of the word in Arabic script and its transliteration in Latin script , separated by an underscore</definiens>
			</definition>
			<definition id="3">
				<sentence>Participants’ parsers then predicted the HEAD and DEPREL columns ( any predicted PHEAD and PDEPREL columns were ignored ) .</sentence>
				<definiendum id="0">DEPREL columns</definiendum>
				<definiens id="0">any predicted PHEAD and PDEPREL columns were ignored )</definiens>
			</definition>
			<definition id="4">
				<sentence>Each IG consists of either a stem or a derivational suffix plus all the inflectional suffixes belonging to that stem/derivational suffix .</sentence>
				<definiendum id="0">IG</definiendum>
				<definiens id="0">consists of either a stem or a derivational suffix plus all the inflectional suffixes belonging to that stem/derivational suffix</definiens>
			</definition>
			<definition id="5">
				<sentence>Its original PoS tag set is very coarse and the PoS and the word stem information is not very reliable.25 We therefore decided to retag the treebank automatically using the Memory-Based Tagger ( MBT ) ( Daelemans et al. , 1996 ) which uses a very fine-grained tag set .</sentence>
				<definiendum id="0">Memory-Based Tagger</definiendum>
				<definiens id="0">uses a very fine-grained tag set</definiens>
			</definition>
			<definition id="6">
				<sentence>A span consists of a potential dependency arc r between two tokens i and j and all those dependency arcs that would be spanned by r , i.e. all arcs between tokens k and l with i ≤ k , l ≤ j. Parsing in this order means that the parser has to find all children and siblings on one side of a token before it can attach that token to a head on the same side .</sentence>
				<definiendum id="0">span</definiendum>
				<definiens id="0">consists of a potential dependency arc r between two tokens i and j and all those dependency arcs that would be spanned by r , i.e. all arcs between tokens k and l with i ≤ k , l ≤ j. Parsing in this order means that the parser has to find all children and siblings on one side of a token before it can attach that token to a head on the same side</definiens>
			</definition>
			<definition id="7">
				<sentence>4.3 n/a 1.8 n/a 15.9 n/a n/a 7.8 9.9 9.7 n/a 13.2 n/a Table 1 : Characteristics of the data sets for the 13 languages ( abbreviated by their first two letters ) : language family ( Semitic , Sino-Tibetan , Slavic , Germanic , Japonic ( or language isolate ) , Romance , Ural-Altaic ) ; number of genres , and genre if only one ( news , dialogue , novel ) ; type of annotation ( d=dependency , c=constituents , dc=discontinuous constituents , +f=with functions , +t=with types ) .</sentence>
				<definiendum id="0">type of annotation</definiendum>
				<definiens id="0">Characteristics of the data sets for the 13 languages ( abbreviated by their first two letters ) : language family ( Semitic , Sino-Tibetan , Slavic , Germanic , Japonic ( or language isolate ) , Romance , Ural-Altaic</definiens>
			</definition>
			<definition id="8">
				<sentence>+ , traces MLE [ ME ] d2c c2d − Table 2 : Overview of parsing approaches taken by participating groups ( identified by the first three letters of the first author ) : algorithm ( Y &amp; M : Yamada and Matsumoto ( 2003 ) , ILP : Integer Linear Programming ) , vertical direction ( irrelevant , mpf : most probable first , bottom-up-spans , bottom-up-trees ) , horizontal direction ( irrelevant , mpf : most probable first , forward , backward ) , search ( optimal , approximate , incremental , best-first exhaustive , deterministic ) , labeling ( interleaved , separate and 1st step , separate and 2nd step ) , non-projective ( ps-pr : through pseudo-projective approach ) , learner ( ME : Maximum Entropy ; learners in brackets were explored but not used in the official submission ) , preprocessing ( projectivize , d2c : dependencies to constituents ) , postprocessing ( deprojectivize , c2d : constituents to dependencies ) , learner parameter optimization per language anon-projectivity through approximate search , used for some languages b20 averaged perceptrons combined into a Bayes Point Machine cintroduced a single POS tag “aux” for all Swedish auxiliary and model verbs dby having no projectivity constraint eselective projectivity constraint for Japanese fseveral approaches to non-projectivity gusing some FEATS components to create some finer-grained POSTAG values hreattachment rules for some types of non-projectivity ihead automaton grammar jdetermined the maximally allowed distance for relations kthrough special parser actions lpseudo-projectivizing training data only mGreedy Prepend Algorithm nbut two separate learners used for unlabeled parsing versus labeling oboth foward and backward , then combined into a single tree with CLE pbut two separate SVMs used for unlabeled parsing versus labeling qforward parsing for Japanese and Turkish , backward for the rest rattaching remaining unattached tokens through exhaustive search ( not for submitted runs ) 156 sequence classifier can label all children of a token together ( McDonald et al. , 2006 ) .</sentence>
				<definiendum id="0">ILP</definiendum>
				<definiens id="0">interleaved , separate and 1st step , separate and 2nd step ) , non-projective ( ps-pr : through pseudo-projective approach ) , learner ( ME : Maximum Entropy ; learners in brackets were explored but not used in the official submission</definiens>
				<definiens id="1">constituents to dependencies ) , learner parameter optimization per language anon-projectivity through approximate search , used for some languages b20 averaged perceptrons combined into a Bayes Point Machine cintroduced a single POS tag “aux” for all Swedish auxiliary and model verbs dby having no projectivity constraint eselective projectivity constraint</definiens>
			</definition>
			<definition id="9">
				<sentence>However , for multilingual parsing which includes languages that are written from right to left ( Arabic ) or sometimes top to bottom ( Chinese , Japanese ) this terminology is confusing because it is not always clear whether a left-to-right parser for Arabic would really start with the leftmost ( i.e. last ) token of a sentence or , like for other languages , with the first ( i.e. rightmost ) .</sentence>
				<definiendum id="0">leftmost</definiendum>
				<definiens id="0">i.e. last ) token of a sentence or</definiens>
			</definition>
			<definition id="10">
				<sentence>Factors that have been discussed so far are : the size of the training data , the proportion of new FORM and LEMMA values in the test set , the ratio of ( C ) POSTAG to DEPREL values , the average length of the parsing unit the proportion of nonprojective arcs/parsing units .</sentence>
				<definiendum id="0">LEMMA</definiendum>
				<definiens id="0">of the parsing unit the proportion of nonprojective arcs/parsing units</definiens>
			</definition>
</paper>

		<paper id="1627">
			<definition id="0">
				<sentence>The Inversion Transduction Grammar ( ITG ) of Wu ( 1997 ) is a syntactically motivated algorithm for producing word-level alignments of pairs of translationally equivalent sentences in two languages .</sentence>
				<definiendum id="0">Inversion Transduction Grammar ( ITG</definiendum>
				<definiens id="0">a syntactically motivated algorithm for producing word-level alignments of pairs of translationally equivalent sentences in two languages</definiens>
			</definition>
			<definition id="1">
				<sentence>An Inversion Transduction Grammar can generate pairs of sentences in two languages by recursively applying context-free bilingual production rules .</sentence>
				<definiendum id="0">Inversion Transduction Grammar</definiendum>
				<definiens id="0">generate pairs of sentences in two languages by recursively applying context-free bilingual production rules</definiens>
			</definition>
			<definition id="2">
				<sentence>The destination node is the common root node for all the parse trees in the forest .</sentence>
				<definiendum id="0">destination node</definiendum>
				<definiens id="0">the common root node for all the parse trees in the forest</definiens>
			</definition>
			<definition id="3">
				<sentence>A stochastic ITG can be thought of as a stochastic CFG extended to the space of bitext .</sentence>
				<definiendum id="0">stochastic ITG</definiendum>
				<definiens id="0">a stochastic CFG extended to the space of bitext</definiens>
			</definition>
			<definition id="4">
				<sentence>227 β ( X [ i , j , u , v ] ) = max braceleftbigβ〈〉 ( X [ i , j , u , v ] ) , β [ ] ( X [ i , j , u , v ] ) bracerightbig β [ ] ( X [ i , j , u , v ] ) = max k , v1 , u2 , Y , Z bracketleftBig β ( Y [ i , k , u , v1 ] ) · β ( Z [ k , j , u2 , v ] ) · P ( X → [ Y Z ] ) · Plm ( u2 | v1 ) bracketrightBig = max k , u2 , Y , Z bracketleftbigg maxv 1 bracketleftBig β ( Y [ i , k , u , v1 ] ) · Plm ( u2 | v1 ) bracketrightBig · P ( X → [ Y Z ] ) · β ( Z [ k , j , u2 , v ] ) bracketrightbigg Figure 3 : Top : An ITG decoding constituent can be built with either a straight or an inverted rule .</sentence>
				<definiendum id="0">Top</definiendum>
				<definiendum id="1">ITG decoding constituent</definiendum>
				<definiens id="0">u , v1 ] ) · β ( Z [ k , j , u2 , v ] ) · P ( X → [ Y Z ] ) · Plm ( u2 | v1 ) bracketrightBig = max k</definiens>
			</definition>
			<definition id="5">
				<sentence>Bottom : An ef cient factorization for straight rules .</sentence>
				<definiendum id="0">Bottom</definiendum>
				<definiens id="0">An ef cient factorization for straight rules</definiens>
			</definition>
			<definition id="6">
				<sentence>The key to the success of A* decoding is an outside estimate that combines word-for-word translation probabilities and n-gram probabilities .</sentence>
				<definiendum id="0">A* decoding</definiendum>
				<definiens id="0">an outside estimate that combines word-for-word translation probabilities and n-gram probabilities</definiens>
			</definition>
			<definition id="7">
				<sentence>While hf considers language model probabilities for words following s , the backward-looking value hb considers language model probabilities for s given possible preceding words : hb ( n ) = max s∈Sn bracketleftbigg Pt ( s | tn ) max sprime∈S Plm ( s | sprime ) bracketrightbigg Our overall heuristic for a partial translation hypothesis X [ i , j , u , v ] combines language model probabilities at the boundaries of the input substring with backward-looking values for the preceding words , and forward-looking values for the following words : h ( i , j , u , v ) = bracketleftbigg max s∈S Plm ( u | s ) bracketrightbigg bracketleftbigg max s∈S Plm ( s | v ) bracketrightbigg · productdisplay n &lt; i , n &gt; j max [ hb ( n ) , hf ( n ) ] Because we don’t know whether a given input word will appear before or after the partial hypothesis in the nal translation , we take the maximum of the forward and backward values for words outside the span [ i , j ] .</sentence>
				<definiendum id="0">bracketleftbigg max s∈S Plm</definiendum>
				<definiens id="0">s given possible preceding words : hb ( n ) = max s∈Sn bracketleftbigg Pt ( s | tn ) max sprime∈S Plm ( s | sprime ) bracketrightbigg Our overall heuristic for a partial translation hypothesis</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>Named Entity Recognition ( NER ) is useful in NLP applications such as question answering , machine translation and information extraction .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">useful in NLP applications such as question answering , machine translation and information extraction</definiens>
			</definition>
			<definition id="1">
				<sentence>NER , especially of personal names and place names , is an area in which lexicon-driven methods have a clear advantage over probabilistic methods and in which the role of lexical resources should be a central one .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">an area in which lexicon-driven methods have a clear advantage over probabilistic methods and in which the role of lexical resources should be a central one</definiens>
			</definition>
			<definition id="2">
				<sentence>This is equivalent to saying that headwaiter should not be considered an instance of waiter , which is indeed how Google behaves .</sentence>
				<definiendum id="0">waiter</definiendum>
			</definition>
			<definition id="3">
				<sentence>That is , meaningful linguistic units , equivalent to lexemes , with the important difference that the TC is the traditional version of the SC on a character form level .</sentence>
				<definiendum id="0">TC</definiendum>
				<definiens id="0">meaningful linguistic units , equivalent to lexemes , with the important difference that the</definiens>
				<definiens id="1">the traditional version of the SC on a character form level</definiens>
			</definition>
			<definition id="4">
				<sentence>α is a coincidental occurrence factor , such as in '100人参加 , in which ' 人参 ' is unrelated to the 'carrot ' sense .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">a coincidental occurrence factor , such as in '100人参加 , in which ' 人参 ' is unrelated to the 'carrot ' sense</definiens>
			</definition>
			<definition id="5">
				<sentence>CJKI , which specializes in CJK and Arabic computational lexicography , is engaged in an ongoing research and development effort to compile CJK and Arabic lexical databases ( currently about seven million entries ) , with special emphasis on proper nouns , orthographic normalization , and C2C .</sentence>
				<definiendum id="0">CJKI</definiendum>
			</definition>
</paper>

		<paper id="1709">
			<definition id="0">
				<sentence>Like most of the world’s 6,000 or so languages , Tagalog is a language for which carefully constructed , tagged corpora ( written or audio ) do not exist .</sentence>
				<definiendum id="0">Tagalog</definiendum>
				<definiens id="0">a language for which carefully constructed , tagged corpora ( written or audio ) do not exist</definiens>
			</definition>
			<definition id="1">
				<sentence>However , unlike most of the world’s languages , Tagalog has a substantial web presence .</sentence>
				<definiendum id="0">Tagalog</definiendum>
				<definiens id="0">a substantial web presence</definiens>
			</definition>
			<definition id="2">
				<sentence>BootCaT ( Baroni &amp; Bernardini 2004 ) , which is designed to create corpora and discover multi-word terms in specialized domains , such as psychiatry , works similarly , with the added twist that queries use words that are more frequent in the target domain than in a reference corpus .</sentence>
				<definiendum id="0">BootCaT</definiendum>
				<definiens id="0">designed to create corpora and discover multi-word terms in specialized domains</definiens>
			</definition>
</paper>

		<paper id="2102">
			<definition id="0">
				<sentence>Thus , the LM is a point on the metric scale , as is depicted in Figure 6 .</sentence>
				<definiendum id="0">LM</definiendum>
				<definiens id="0">a point on the metric scale</definiens>
			</definition>
			<definition id="1">
				<sentence>A motel represents a LM which constitutes an idealized cubical container .</sentence>
				<definiendum id="0">motel</definiendum>
				<definiens id="0">a LM which constitutes an idealized cubical container</definiens>
			</definition>
			<definition id="2">
				<sentence>The TR bears a lateral relation to the LM , but the position is not precise , and it may be considered as coincident or rather 13 contiguous with the LM , contiguity being usually reflected by means of na + LOC in Polish .</sentence>
				<definiendum id="0">TR</definiendum>
				<definiens id="0">contiguity being usually reflected by means of na + LOC in Polish</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus , the most prominent part of the LM is the location of the TR .</sentence>
				<definiendum id="0">LM</definiendum>
				<definiens id="0">the location of the TR</definiens>
			</definition>
			<definition id="4">
				<sentence>Contact between the TR and LM is a possible but not a necessary element of the configuration .</sentence>
				<definiendum id="0">LM</definiendum>
				<definiens id="0">a possible but not a necessary element of the configuration</definiens>
			</definition>
			<definition id="5">
				<sentence>Spatial Prepositions : A Case Study in French .</sentence>
				<definiendum id="0">Spatial Prepositions</definiendum>
			</definition>
</paper>

		<paper id="3207">
			<definition id="0">
				<sentence>Gaja Jarosz Department of Cognitive Science Johns Hopkins University Baltimore , MD 21218 jarosz @ cogsci.jhu.edu This paper proposes an unsupervised learning algorithm for Optimality Theoretic grammars , which learns a complete constraint ranking and a lexicon given only unstructured surface forms and morphological relations .</sentence>
				<definiendum id="0">Optimality Theoretic grammars</definiendum>
				<definiens id="0">learns a complete constraint ranking</definiens>
			</definition>
			<definition id="1">
				<sentence>In particular , the Gradual Learning Algorithm for Stochastic OT ( Boersma , 1997 , 1998 ; Boersma and Hayes , 2001 ) is capable of learning in spite of noisy training data and is capable of learning variable grammars in a supervised fashion .</sentence>
				<definiendum id="0">Gradual Learning Algorithm for Stochastic OT</definiendum>
				<definiens id="0">capable of learning in spite of noisy training data and is capable of learning variable grammars in a supervised fashion</definiens>
			</definition>
			<definition id="2">
				<sentence>In OT there are two basic types of constraints , markedness constraints , which penalize dispreferred surface structures , and faithfulness constraints , which penalize nonidentical mappings from underlying to surface forms .</sentence>
				<definiendum id="0">markedness constraints</definiendum>
			</definition>
			<definition id="3">
				<sentence>As discussed above , the goal of the learning algorithm is to find the probability distributions over rankings and lexicons that maximize the probability assigned to the observed set of data according to the objective function .</sentence>
				<definiendum id="0">learning algorithm</definiendum>
			</definition>
			<definition id="4">
				<sentence>Finally , the middle language is a combination of lexical and grammatical stress , requiring that the algorithm learn that a contrast in roots is preserved , while a contrast in suffixes is neutralized .</sentence>
				<definiendum id="0">middle language</definiendum>
				<definiens id="0">a combination of lexical and grammatical stress</definiens>
			</definition>
</paper>

		<paper id="0116">
			<definition id="0">
				<sentence>For each sentence x , we define two non-negative factors : exp ( summationtextKk=1 λkfk ( yi−1 , yi , x ) ) for each edge exp ( summationtextKprimek=1 λprimekfprimek ( yi , x ) ) for each node where fk is a binary feature function , and K and Kprime are the number of features defined for edges and nodes respectively .</sentence>
				<definiendum id="0">fk</definiendum>
				<definiendum id="1">Kprime</definiendum>
				<definiens id="0">the number of features defined for edges and nodes respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>We use the following feature functions : f ( yi−1 , yi , x , i ) = p ( x , i ) q ( yi−1 , yi ) ( 2 ) where p ( x , i ) is a predicate on the input sequence x and current position i and q ( yi−1 , yi ) is a predicate on pairs of labels .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">a predicate on pairs of labels</definiens>
			</definition>
			<definition id="2">
				<sentence>CnCn+1 ( n = −1,0 ) Where C refers to a Chinese character while C0 denotes the current character and Cn ( C−n ) denotes the character n positions to the right ( left ) of the current character .</sentence>
				<definiendum id="0">CnCn+1</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">Cn ( C−n )</definiendum>
				<definiens id="0">the current character</definiens>
				<definiens id="1">the character n positions to the right ( left ) of the current character</definiens>
			</definition>
			<definition id="3">
				<sentence>WTn ( n = −1,0,1 ) Where WT refers to the word boundary tag while WT0 denotes the tag of current character and WTn ( WT−n ) denotes the tag n positions to the right ( left ) of the current character .</sentence>
				<definiendum id="0">WTn</definiendum>
				<definiendum id="1">WT</definiendum>
				<definiens id="0">the tag of current character and WTn ( WT−n ) denotes the tag n positions to the right ( left ) of the current character</definiens>
			</definition>
			<definition id="4">
				<sentence>LC0OC0 ; S is the list of sentences , S = { s1 , s2 , ... , sn } .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">the list of sentences , S = { s1 , s2 , ... , sn }</definiens>
			</definition>
</paper>

		<paper id="0107">
			<definition id="0">
				<sentence>Languages vary in the granularity of their tense and aspect representations ; some have finergrained tenses or aspects than others .</sentence>
				<definiendum id="0">Languages</definiendum>
				<definiens id="0">vary in the granularity of their tense and aspect representations</definiens>
			</definition>
			<definition id="1">
				<sentence>The problem we are interested in can be formalized as a standard classification or labeling problem , in which we try to learn a classifier C : V →T ( 1 ) where V is a set of verbs ( each described by a feature vector ) , and T is the set of possible tense tags .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">a set of verbs ( each described by a feature vector</definiens>
			</definition>
			<definition id="2">
				<sentence>Telicity specifies a verb’s ability to be bound in a certain time span , while punctuality specifies whether or not a verb is associated with a point event in time .</sentence>
				<definiendum id="0">Telicity</definiendum>
				<definiens id="0">specifies a verb’s ability to be bound in a certain time span</definiens>
			</definition>
			<definition id="3">
				<sentence>The conditional nature of CRFs relaxes the independence assumptions required by traditional Hidden Markov Models ( HMMs ) .</sentence>
				<definiendum id="0">CRFs</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Kappa Statistic ( Cohen , 1960 ) is a standard measurement of interannotator agreement for categorical data annotation .</sentence>
				<definiendum id="0">Kappa Statistic</definiendum>
			</definition>
			<definition id="5">
				<sentence>The Kappa score is defined by the following formula , where P ( A ) is the observed agreement rate from multiple annotators and P ( E ) is the expected rate of agreement due to pure chance : k = P ( A ) −P ( E ) 1−P ( E ) ( 2 ) Since tense annotation requires disambiguating grammatical meaning , which is more abstract than lexical meaning , one would expect the challenge posed by human annotators in a tense annotation experiment to be even greater than for word sense disambiguation .</sentence>
				<definiendum id="0">Kappa score</definiendum>
				<definiendum id="1">P ( A )</definiendum>
				<definiendum id="2">P ( E )</definiendum>
				<definiens id="0">the observed agreement rate from multiple annotators</definiens>
				<definiens id="1">the expected rate of agreement due to pure chance : k = P ( A ) −P ( E ) 1−P ( E ) ( 2 ) Since tense annotation requires disambiguating grammatical meaning , which is more abstract than lexical meaning , one would expect the challenge posed by human annotators in a tense annotation experiment to be even greater than for word sense disambiguation</definiens>
			</definition>
			<definition id="6">
				<sentence>The main idea of Classification Tree is to do a recursive partitioning of the variable space to achieve good separation of the classes in the training dataset .</sentence>
				<definiendum id="0">Classification Tree</definiendum>
				<definiens id="0">to do a recursive partitioning of the variable space to achieve good separation of the classes in the training dataset</definiens>
			</definition>
</paper>

		<paper id="0106">
			<definition id="0">
				<sentence>Coreference resolution is the process of identifying expressions that refer to the same entity .</sentence>
				<definiendum id="0">Coreference resolution</definiendum>
				<definiens id="0">the process of identifying expressions that refer to the same entity</definiens>
			</definition>
			<definition id="1">
				<sentence>Noun phrase coreference resolution is the process of detecting noun phrases ( NPs ) in a document and determining whether the NPs refer to the same entity , where an entity is defined as “a construct that represents an abstract identity” .</sentence>
				<definiendum id="0">Noun phrase coreference resolution</definiendum>
				<definiens id="0">the process of detecting noun phrases ( NPs ) in a document and determining whether the NPs refer to the same entity , where an entity is defined as “a construct that represents an abstract identity”</definiens>
			</definition>
			<definition id="2">
				<sentence>NP coreference resolution is an important subtask in natural language processing ( NLP ) applications such as text summarization , information extraction , data mining and question answering .</sentence>
				<definiendum id="0">NP coreference resolution</definiendum>
				<definiens id="0">an important subtask in natural language processing ( NLP ) applications such as text summarization , information extraction</definiens>
			</definition>
			<definition id="3">
				<sentence>Identifying coreferent NPs in an unanotated document actually involves two tasks : mention detection , which identifies the anaphors and antecedents in a document , folowed by noun phrase coreference resolution .</sentence>
				<definiendum id="0">mention detection</definiendum>
				<definiens id="0">identifies the anaphors and antecedents in a document , folowed by noun phrase coreference resolution</definiens>
			</definition>
			<definition id="4">
				<sentence>Our gazetteer consists of 470 entries , each of which is labeled with one of the folowing semantic classes : person , organization , location , facility , GPE , date , money , vehicle and weapon .</sentence>
				<definiendum id="0">gazetteer</definiendum>
				<definiens id="0">consists of 470 entries , each of which is labeled with one of the folowing semantic classes : person , organization , location , facility , GPE , date , money , vehicle and weapon</definiens>
			</definition>
			<definition id="5">
				<sentence>Demonstrative Noun Phrase – A demonstrative noun phrase is a phrase that consists of a noun phrases preceded by one of the characters [  � � ] ( this/that/some )</sentence>
				<definiendum id="0">Demonstrative Noun Phrase – A demonstrative noun phrase</definiendum>
			</definition>
			<definition id="6">
				<sentence>( e.g. “Bil Gates , the chairman of Microsoft Corp” ) Abbreviation – A noun phrase is an abbreviation when it is formed by using part of another noun phrase , e.g. � � �  � �</sentence>
				<definiendum id="0">noun phrase</definiendum>
				<definiens id="0">an abbreviation when it is formed by using part of another noun phrase</definiens>
			</definition>
			<definition id="7">
				<sentence>The DISTANCE , GENDER , NUMBER , SEMANTIC , PROPER NAME , PRONOUN and EDIT_DISTANCE functions return a positive value when the two phrases mismatch on that particular feature .</sentence>
				<definiendum id="0">EDIT_DISTANCE functions</definiendum>
				<definiens id="0">return a positive value when the two phrases mismatch on that particular feature</definiens>
			</definition>
			<definition id="8">
				<sentence>= `` Each C i is a gold standard cluster ( i.e. a set of phrases which we know refer to the same entity ) , and p ( C i ) is the partitioning of C i by the automatically-generated clusters .</sentence>
				<definiendum id="0">p ( C i )</definiendum>
				<definiens id="0">the partitioning of C i by the automatically-generated clusters</definiens>
			</definition>
			<definition id="9">
				<sentence>Our results were evaluated using the MUC scoring program which reports recall , precision and F-measure , where the F-measure is defined as the harmonic mean of precision and recall : !</sentence>
				<definiendum id="0">MUC scoring program</definiendum>
				<definiendum id="1">F-measure</definiendum>
				<definiens id="0">the harmonic mean of precision</definiens>
			</definition>
</paper>

		<paper id="0610">
			<definition id="0">
				<sentence>The square node indicates an obligatory but missing valent .</sentence>
				<definiendum id="0">square node</definiendum>
				<definiens id="0">indicates an obligatory but missing valent</definiens>
			</definition>
			<definition id="1">
				<sentence>TR lacks attributes distinguishing intensional and extensional information and there are no relations like SUBM denoting relation between a set and its subset .</sentence>
				<definiendum id="0">TR</definiendum>
				<definiens id="0">lacks attributes distinguishing intensional and extensional information and there are no relations like SUBM denoting relation between a set and its subset</definiens>
			</definition>
			<definition id="2">
				<sentence>In contrast to CLASSIC ( Brachman et al. , 1991 ) and other KL-ONE networks , MultiNet contains a prede ned nal set of relation types , encapsulation of concepts , and attribute layers concerning cardinality of objects mentioned in discourse .</sentence>
				<definiendum id="0">MultiNet</definiendum>
				<definiens id="0">contains a prede ned nal set of relation types , encapsulation of concepts , and attribute layers concerning cardinality of objects mentioned in discourse</definiens>
			</definition>
			<definition id="3">
				<sentence>Sorts ( the upper conceptual ontology ) are an important source of constraints for MultiNet relations .</sentence>
				<definiendum id="0">Sorts</definiendum>
			</definition>
			<definition id="4">
				<sentence>WOCADI uses no theoretical intermediate structures and relies heavily on semantically annotated dictionary ( HagenLex , see Hartrumpf et al. ( 2003 ) ) .</sentence>
				<definiendum id="0">WOCADI</definiendum>
				<definiens id="0">uses no theoretical intermediate structures and relies heavily on semantically annotated dictionary</definiens>
			</definition>
			<definition id="5">
				<sentence>• TFA has an effect on the identi cation of presuppositions ( Peregrin , 1995a ) and allegations ( Haji cov·a , 1984 ) .</sentence>
				<definiendum id="0">TFA</definiendum>
				<definiens id="0">an effect on the identi cation of presuppositions ( Peregrin , 1995a ) and allegations</definiens>
			</definition>
</paper>

		<paper id="3315">
			<definition id="0">
				<sentence>The gene synonym list consists of 183,142 synonyms for 52,594 genes ; the training data consists of 100 mouse-relevant Medline abstracts , associated with the MGI geneId’s for those genes that are mentioned in the abstract ; the evaluation data consists of an additional 50 mouse-relevant Medline abstracts , also associated with the MGI geneId’s as above ; the test data consists of an additional 250 mouse-relevant Medline abstracts , again associated with MGI geneId’s ; finally the historical data consists of 5000 mouserelevant Medline abstracts , each of which is associated with the MGI geneId’s for all genes which are ( a ) associated with the article according to the MGI database , and ( b ) mentioned in the abstract , as determined by an automated procedure based on the gene synonym list.1 We also annotated the evaluationdata for NER evaluation .</sentence>
				<definiendum id="0">gene synonym list</definiendum>
			</definition>
</paper>

		<paper id="0103">
			<definition id="0">
				<sentence>An abbreviation lexicon , which consists of the root-abbreviation pairs , can thus be constructed automatically .</sentence>
				<definiendum id="0">abbreviation lexicon</definiendum>
				<definiens id="0">consists of the root-abbreviation pairs</definiens>
			</definition>
			<definition id="1">
				<sentence>The table indicates which characters will be deleted from the root of a particular length ( n ) with a bit ‘0’ ; on the other hand , a bit ‘1’ means that the respective character will be retained .</sentence>
				<definiendum id="0">bit ‘1’</definiendum>
				<definiens id="0">the respective character will be retained</definiens>
			</definition>
			<definition id="2">
				<sentence>Therefore , a reasonable simplification for the abbreviation model is to introduce the length and the positional bit pattern as additional features , resulting in the following augmented model for the abbreviation probability .</sentence>
				<definiendum id="0">abbreviation model</definiendum>
				<definiens id="0">to introduce the length and the positional bit pattern as additional features , resulting in the following augmented model for the abbreviation probability</definiens>
			</definition>
			<definition id="3">
				<sentence>The N-to-1 abbreviation patterns can thus be regarded as the atomic abbreviation pairs .</sentence>
				<definiendum id="0">N-to-1 abbreviation</definiendum>
			</definition>
</paper>

		<paper id="2928">
			<definition id="0">
				<sentence>We used a maximum entropy classifier ( Berger et al. , 1996 ) to assign labels to the unlabeled dependencies produced by the Bayes Point Machine .</sentence>
				<definiendum id="0">maximum entropy classifier</definiendum>
				<definiens id="0">the unlabeled dependencies produced by the Bayes Point Machine</definiens>
			</definition>
</paper>

		<paper id="0602">
			<definition id="0">
				<sentence>We chose the GENIA corpus ( Kim et al. , 2003 ) , a collection of MEDLINE abstracts selected from the search results with the following keywords : human , blood cells , and transcription factors .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">a collection of MEDLINE abstracts selected from the search results with the following keywords : human , blood cells , and transcription factors</definiens>
			</definition>
			<definition id="1">
				<sentence>express ( BioProp ) Arg0 : causer of expression Arg1 : thing expressing [ B lymphocytes and macrophages Arg0 ] [ express predicate ] [ closely related immunoglobulin G ( IgG ) Fc receptors ( Fc gamma RII ) that differ only in the structures of their cytoplasmic domains Arg1 ] .</sentence>
				<definiendum id="0">BioProp</definiendum>
			</definition>
			<definition id="2">
				<sentence>The annotation process consists of the following steps : ( 1 ) identifying predicate candidates ; ( 2 ) automatically annotating the biomedical semantic roles with our WSJ SRL system ; ( 3 ) transforming the automatic tagging results into WordFreak ( Morton and LaCivita , 2003 ) format ; and ( 4 ) manually correcting the annotation results with the WordFreak annotation tool .</sentence>
				<definiendum id="0">annotation process</definiendum>
			</definition>
			<definition id="3">
				<sentence>tions are transformed into WordFreak format ( an XML format ) , which allows annotators to view a sentence in a tree-like fashion .</sentence>
				<definiendum id="0">XML format )</definiendum>
				<definiens id="0">allows annotators to view a sentence in a tree-like fashion</definiens>
			</definition>
			<definition id="4">
				<sentence>BASIC FEATURES z Predicate – The predicate lemma z Path – The syntactic path through the parsing tree from the parse constituent being classified to the predicate z Constituent type z Position – Whether the phrase is located before or after the predicate z Voice – passive : If the predicate has a POS tag VBN , and its chunk is not a VP , or it is preceded by a form of “to be” or “to get” within its chunk ; otherwise , it is active z Head word – Calculated using the head word table described by Collins ( 1999 ) z Head POS – The POS of the Head Word z Sub-categorization – The phrase structure rule that expands the predicate’s parent node in the parsing tree z First and last Word and their POS tags z Level – The level in the parsing tree PREDICATE FEATURES z Predicate’s verb class z Predicate POS tag z Predicate frequency z Predicate’s context POS z Number of predicates FULL PARSING FEATURES z Parent’s , left sibling’s , and right sibling’s paths , constituent types , positions , head words and head POS tags z Head of PP parent – If the parent is a PP , then the head of this PP is also used as a feature COMBINATION FEATURES z Predicate distance combination z Predicate phrase type combination z Head word and predicate combination z Voice position combination OTHERS z Syntactic frame of predicate/NP z Headword suffixes of lengths 2 , 3 , and 4 z Number of words in the phrase z Context words &amp; POS tags Table 6 .</sentence>
				<definiendum id="0">tree PREDICATE FEATURES z Predicate’s verb class z Predicate POS tag z Predicate frequency z Predicate’s</definiendum>
				<definiens id="0">a feature COMBINATION FEATURES z Predicate distance combination z Predicate phrase type combination z Head word and predicate combination</definiens>
			</definition>
			<definition id="5">
				<sentence>When tested on the biomedical corpus , BIOSMILE outperforms the WSJ SRL system by 22.9 % .</sentence>
				<definiendum id="0">BIOSMILE</definiendum>
				<definiens id="0">outperforms the WSJ SRL system by 22.9 %</definiens>
			</definition>
</paper>

		<paper id="0119">
			<definition id="0">
				<sentence>A high-performance Chinese word segmentor ( CWS ) is a critical processing stage to produce an intermediate result for later processes , such as search engines , text mining , word spell checking , text-to-speech and speech recognition , etc .</sentence>
				<definiendum id="0">high-performance Chinese word segmentor</definiendum>
				<definiendum id="1">CWS</definiendum>
			</definition>
			<definition id="1">
				<sentence>They are : ( 1 ) Lack of unknown word ( LUW ) , it means segmentation error occurred by lack of an unknown word in the system dictionary , and ( 2 ) Error identified word ( EIW ) , it means segmentation error occurred by an error identified unknown words .</sentence>
				<definiendum id="0">LUW</definiendum>
			</definition>
			<definition id="2">
				<sentence>The CCUWI uses template matching technique to extract unknown words from sentences .</sentence>
				<definiendum id="0">CCUWI</definiendum>
				<definiens id="0">uses template matching technique to extract unknown words from sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>The F-measure improvement between the BMM-based CWS and it with WSM in the MSR_C track ( OOV is 0.034 ) using a , b , and c system dictionary .</sentence>
				<definiendum id="0">OOV</definiendum>
				<definiens id="0">0.034 ) using a , b , and c system dictionary</definiens>
			</definition>
</paper>

		<paper id="0123">
			<definition id="0">
				<sentence>Four tags ‘B , I , E , S’ are defined for the word segmentation system , in which ‘B’ means the character is the beginning of one word , ‘I’ means the character is inside one word , ‘E’ means the character is at the end of one word and ‘S’ means the character is one word by itself .</sentence>
				<definiendum id="0">‘I’</definiendum>
				<definiendum id="1">‘E’</definiendum>
				<definiens id="0">the word segmentation system , in which ‘B’ means the character is the beginning of one word</definiens>
				<definiens id="1">means the character is inside one word</definiens>
				<definiens id="2">means the character is at the end of one word and ‘S’ means the character is one word by itself</definiens>
			</definition>
			<definition id="1">
				<sentence>Here NE-Tag ‘O’ means the character does not belong to any named entities .</sentence>
				<definiendum id="0">NE-Tag ‘O’</definiendum>
			</definition>
			<definition id="2">
				<sentence>A character list , which contains all the characters in the lexicon introduced later , is used to identify them .</sentence>
				<definiendum id="0">character list</definiendum>
				<definiens id="0">contains all the characters in the lexicon introduced later , is used to identify them</definiens>
			</definition>
			<definition id="3">
				<sentence>SVMlight ( T.Joachims , 1999 ) was used as SVM tool .</sentence>
				<definiendum id="0">SVMlight</definiendum>
				<definiens id="0">SVM tool</definiens>
			</definition>
			<definition id="4">
				<sentence>Third , the in-NE probability used in postprocessing is helpful to identify named entities which can not be recognized by the basic model .</sentence>
				<definiendum id="0">in-NE probability</definiendum>
				<definiens id="0">helpful to identify named entities which can not be recognized by the basic model</definiens>
			</definition>
</paper>

		<paper id="2913">
			<definition id="0">
				<sentence>RCV1 : a new benchmark collection for text categorization research .</sentence>
				<definiendum id="0">RCV1</definiendum>
			</definition>
</paper>

		<paper id="3805">
			<definition id="0">
				<sentence>The sentence score combines the number of edges matched and the number of connections found with equal weight factors for the edge match and path score .</sentence>
				<definiendum id="0">sentence score</definiendum>
				<definiens id="0">combines the number of edges matched and the number of connections found with equal weight factors for the edge match and path score</definiens>
			</definition>
</paper>

		<paper id="1401">
</paper>

		<paper id="1639">
			<definition id="0">
				<sentence>In some sense , the availability of such data is simply a manifestation of a general trend of “everybody putting their records on the Internet”.1 The 1It is worth pointing out that the United States’ Library of Congress was an extremely early adopter of Web technology : the THOMAS database ( http : //thomas.loc.gov ) of congresonline accessibility of politically oriented texts in particular , however , is a phenomenon that some have gone so far as to say will have a potentially society-changing effect .</sentence>
				<definiendum id="0">THOMAS database ( http</definiendum>
				<definiens id="0">worth pointing out that the United States’ Library of Congress</definiens>
			</definition>
			<definition id="1">
				<sentence>In this paper , we demonstrate that the incorporation of agreement modeling can provide substantial improvements over the application of support vector machines ( SVMs ) in isolation , which represents the state of the art in the individual classification of documents .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">represents the state of the art in the individual classification of documents</definiens>
			</definition>
			<definition id="2">
				<sentence>Each debate consists of a series of speech segments , where each segment is a sequence of uninterrupted utterances by a single speaker .</sentence>
				<definiendum id="0">debate</definiendum>
				<definiens id="0">consists of a series of speech segments , where each segment is a sequence of uninterrupted utterances by a single speaker</definiens>
			</definition>
			<definition id="3">
				<sentence>Assume we have a non-negative function ind ( s , C ) indicating the degree of preference that an individual-document classifier , such as an SVM , has for placing speech-segment s in class C. Also , assume that some pairs of speech segments have weighted links between them , where the non-negative strength ( weight ) str ( lscript ) for a link lscript indicates the degree to which it is preferable that the linked speech segments receive the same label .</sentence>
				<definiendum id="0">non-negative strength ( weight ) str</definiendum>
				<definiens id="0">indicating the degree of preference that an individual-document classifier , such as an SVM , has for placing speech-segment s in class C. Also , assume that some pairs of speech segments have weighted links between them , where the</definiens>
				<definiens id="1">the degree to which it is preferable that the linked speech segments receive the same label</definiens>
			</definition>
			<definition id="4">
				<sentence>for each speech segment s was based on the signed distance d ( s ) from the vector representing s to the trained SVM decision plane : ind ( s , Y ) def=    1 d ( s ) &gt; 2σs ; parenleftBig 1+ d ( s ) 2σs parenrightBig /2 |d ( s ) |≤ 2σs ; 0 d ( s ) &lt; −2σs where σs is the standard deviation of d ( s ) over all speech segments s in the debate in question , and ind ( s , N ) def= 1− ind ( s , Y ) .</sentence>
				<definiendum id="0">σs</definiendum>
				<definiendum id="1">ind</definiendum>
				<definiens id="0">based on the signed distance d ( s ) from the vector representing s to the</definiens>
				<definiens id="1">the standard deviation of d ( s ) over all speech segments s in the debate in question</definiens>
			</definition>
</paper>

		<paper id="3501">
			<definition id="0">
				<sentence>1 An implicature can be defined as anything that is infered from an uterance but that is not a condition for the truth of the uterance ( Levinson 1983:127 ) .</sentence>
				<definiendum id="0">implicature</definiendum>
			</definition>
			<definition id="1">
				<sentence>Elipsis has a part in the study of anaphora , as it is often referred to as ‘zero anaphora’ .</sentence>
				<definiendum id="0">Elipsis</definiendum>
				<definiens id="0">has a part in the study of anaphora</definiens>
			</definition>
			<definition id="2">
				<sentence>They are that subject elipsis is used for : 1 ) Economy , for speaking fast 2 ) Coherence 3 ) Conversation ( i.e. spoken dialogue ) 4 ) Spontaneous ( unplanned ) speech 5 ) First person pronoun elided in a declarative and second person in an interrogative 1 ) Regarding economy , subject ellipsis hapens for more than simple reasons of economy .</sentence>
				<definiendum id="0">Conversation</definiendum>
				<definiens id="0">more than simple reasons of economy</definiens>
			</definition>
</paper>

		<paper id="0705">
			<definition id="0">
				<sentence>Section 6 presents results from our evaluations , and Section 7 summarizes our conclusions We de ne contextual entailment ( CE ) as a directional relation that exists between a text passage t and one of a set of implicit subquestions q that can be derived from a user’s interpretation of a scenario .</sentence>
				<definiendum id="0">contextual entailment ( CE</definiendum>
				<definiens id="0">a directional relation that exists between a text passage t</definiens>
			</definition>
			<definition id="1">
				<sentence>CASE 3 : CASE 2 : S does not entail A , Q entails A , S entails Q S entails A , Q entails A , S does not entail Q S entails A , Q entails A , S entails Q Figure 2 : Examples of Contextual Entailment .</sentence>
				<definiendum id="0">Q</definiendum>
			</definition>
			<definition id="2">
				<sentence>This architecture includes three basic types of modules : ( 1 ) a Context Discovery module , which identi es passages relevant to the concepts mentioned in a scenario , ( 2 ) a Textual Entailment module , which recognizes implicational relationships between passages , and ( 3 ) a Entailment Merging module , which ranks relevant passages according to their relevance to the scenario itself .</sentence>
				<definiendum id="0">Entailment Merging module</definiendum>
				<definiens id="0">recognizes implicational relationships between passages</definiens>
				<definiens id="1">ranks relevant passages according to their relevance to the scenario itself</definiens>
			</definition>
			<definition id="3">
				<sentence>Once a set of topic answers have been identi ed , each topic answer is paired with a question submitted by a user and sent to the Textual Entailment system described in Section 2 .</sentence>
				<definiendum id="0">topic answers</definiendum>
			</definition>
			<definition id="4">
				<sentence>When CE was used to rank passages for Answer Processing ( AnsSet2 ) , accuracy increased by nearly 9 % over the baseline ( AnsSet1 ) , while accuracy increased by almost 14 % overall when CE was used to select answers directly ( AnsSet3 ) .</sentence>
				<definiendum id="0">CE</definiendum>
				<definiens id="0">used to rank passages for Answer Processing ( AnsSet2 ) , accuracy increased by nearly 9 % over the baseline ( AnsSet1 ) , while accuracy increased by almost 14 % overall when CE was used to select answers directly</definiens>
			</definition>
			<definition id="5">
				<sentence>This paper introduced a new form of textual entailment , known as contextual entailment , which can be used to recognize scenario-relevant information in both the questions users ask and in the answers that automatic Q/A systems return .</sentence>
				<definiendum id="0">contextual entailment</definiendum>
				<definiens id="0">scenario-relevant information in both the questions users ask and in the answers that automatic Q/A systems return</definiens>
			</definition>
</paper>

		<paper id="1651">
			<definition id="0">
				<sentence>Because many ( 60 % ) opinion-source relations appear as predicate-argument relations , where the predicate is a verb , we also hypothesize that semantic role labeling ( SRL ) will be very useful for our task .</sentence>
				<definiendum id="0">predicate</definiendum>
				<definiens id="0">predicate-argument relations , where the</definiens>
			</definition>
			<definition id="1">
				<sentence>The relation classifier is modeled using Markov order-0 CRFs ( Lafferty 2Wiebe et al. ( 2005 ) reports human annotation agreement for opinion expression as 82.0 by F1 measure .</sentence>
				<definiendum id="0">relation classifier</definiendum>
				<definiens id="0">reports human annotation agreement for opinion expression as 82.0 by F1 measure</definiens>
			</definition>
			<definition id="2">
				<sentence>Either E1 is an opinion entity and E2 is a source , or vice versa .</sentence>
				<definiendum id="0">E2</definiendum>
				<definiens id="0">an opinion entity and</definiens>
				<definiens id="1">a source , or vice versa</definiens>
			</definition>
			<definition id="3">
				<sentence>ILP consists of an objective function which is a dot product between a vector of variables and a vector of weights , and a set of equality and inequality constraints among variables .</sentence>
				<definiendum id="0">ILP</definiendum>
				<definiens id="0">consists of an objective function which is a dot product between a vector of variables and a vector of weights , and a set of equality and inequality constraints among variables</definiens>
			</definition>
			<definition id="4">
				<sentence>Given an objective function and a set of constraints , LP finds the optimal assignment of values to variables , i.e. one that minimizes the objective function .</sentence>
				<definiendum id="0">LP</definiendum>
			</definition>
			<definition id="5">
				<sentence>For each source entity , we add an equality constraint and an inequality constraint that together allow a source to link to at most two opinions : Sj+Aj =summationtexti Li , j and Aj − Sj ≤ 0 , where Aj is an auxiliary variable , such that its weight is some positive constant value that suppresses Aj from being assigned to 1 .</sentence>
				<definiendum id="0">Aj</definiendum>
				<definiens id="0">an auxiliary variable , such that its weight is some positive constant value that suppresses Aj from being assigned to 1</definiens>
			</definition>
			<definition id="6">
				<sentence>Values of d decrease as 4/4 , 4/5 , 4/6 , 4/7 ... . We evaluate our system using the NRRC MultiPerspective Question Answering ( MPQA ) corpus that contains 535 newswire articles that are manually annotated for opinion-related information .</sentence>
				<definiendum id="0">NRRC MultiPerspective Question Answering ( MPQA )</definiendum>
				<definiens id="0">corpus that contains 535 newswire articles that are manually annotated for opinion-related information</definiens>
			</definition>
			<definition id="7">
				<sentence>436 Overlap Match Exact Match r ( % ) p ( % ) f ( % ) r ( % ) p ( % ) f ( % ) NEAREST-1 51.6 71.4 59.9 26.2 36.9 30.7 NEAREST-2 60.7 45.8 52.2 29.7 19.0 23.1 NEAREST-10 66.3 20.9 31.7 28.2 00.0 00.0 SRL 59.7 36.3 45.2 32.6 19.3 24.2 SRL+CRF-OP 45.6 83.2 58.9 27.6 49.7 35.5 ILP-1 51.6 80.8 63.0 26.4 42.0 32.4 ILP-10 64.0 72.4 68.0 31.0 34.8 32.8 Table 2 : Relation extraction performance NEAREST-n : link-nearest heuristic w/ n-best SRL : all V-A0 frames from SRL SRL+CRF-OP : all V-A0 filtered by CRF-OP ILP-n : ILP applied to n-best sequences link-nearest heuristic on the full source-expressesopinion relation extraction task are shown in the first three rows of table 2 .</sentence>
				<definiendum id="0">CRF-OP ILP-n</definiendum>
				<definiens id="0">link-nearest heuristic w/ n-best SRL : all V-A0 frames from SRL SRL+CRF-OP : all V-A0 filtered by</definiens>
			</definition>
			<definition id="8">
				<sentence>17A potential issue with overlap precision and recall is that the measures may drastically overestimate the system’s performance as follows : a system predicting a single link relation whose source and opinion expression both overlap with every token of a document would achieve 100 % overlap precision and recall .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">a system predicting a single link relation whose source and opinion expression both overlap with every token of a document would achieve 100 % overlap precision and recall</definiens>
			</definition>
</paper>

		<paper id="3505">
			<definition id="0">
				<sentence>The exception-based learning approach consists of four main phases : • First , a candidate discovery takes place , in which the agent analyzes a rule together with its examples , exceptions and the ontology and finds the most plausible types of extensions of the latter that may reduce or eliminate the rule’s exceptions .</sentence>
				<definiendum id="0">exception-based learning approach</definiendum>
				<definiens id="0">consists of four main phases : • First , a candidate discovery takes place , in which the agent analyzes a rule together with its examples , exceptions and the ontology and finds the most plausible types of extensions of the latter that may reduce or eliminate the rule’s exceptions</definiens>
			</definition>
			<definition id="1">
				<sentence>When the titles contain the hypernym it still is to be expected that they might not consist of full sentences , Hearst patterns ( Hearst , 1992 ) are , therefore , unlikely to be found .</sentence>
				<definiendum id="0">Hearst patterns</definiendum>
				<definiens id="0">to be expected that they might not consist of full sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>RelExt : A tool for relation extraction in ontology extension .</sentence>
				<definiendum id="0">RelExt</definiendum>
				<definiens id="0">A tool for relation extraction in ontology extension</definiens>
			</definition>
</paper>

		<paper id="0101">
			<definition id="0">
				<sentence>Thesaurus is one of the most useful linguistic resources .</sentence>
				<definiendum id="0">Thesaurus</definiendum>
			</definition>
			<definition id="1">
				<sentence>Hownet uses some primitive senses to describe word meanings .</sentence>
				<definiendum id="0">Hownet</definiendum>
				<definiens id="0">uses some primitive senses to describe word meanings</definiens>
			</definition>
			<definition id="2">
				<sentence>Each relation could be defined as a triple ( w , r , c ) , where w is the thesaurus term , c is the co-occurred context word and r is the relation between w and c. Then context vector of a word is represented differently by different models , such as : tf , weight-tf , Latent Semantic Indexing ( LSI ) ( Deerwester , S. , et al. , 1990 ) and Probabilistic LSI ( Hofmann , 1999 ) .</sentence>
				<definiendum id="0">w</definiendum>
				<definiendum id="1">r</definiendum>
				<definiendum id="2">Probabilistic LSI</definiendum>
				<definiens id="0">a triple</definiens>
				<definiens id="1">the thesaurus term , c is the co-occurred context word</definiens>
				<definiens id="2">the relation between w and c. Then context vector of a word is represented differently by different models , such as : tf , weight-tf , Latent Semantic Indexing ( LSI ) ( Deerwester , S. , et al. , 1990 ) and</definiens>
			</definition>
			<definition id="3">
				<sentence>word x= , where weighti , we used here , is defined as [ logm-entropy ( wordi ) ] /logm ) ( wordikp is the co-occurrence probability of wordk when given wordi .</sentence>
				<definiendum id="0">/logm ) ( wordikp</definiendum>
				<definiens id="0">the co-occurrence probability of wordk when given wordi</definiens>
			</definition>
			<definition id="4">
				<sentence>Some enhanced KL models were developed to prevent these problems such as Jensen-Shannon ( Jianhua , 1991 ) , which introducing a probabilistic variable m , or α -Skew Divergence ( Lee , 1999 ) , by adopting adjustable variable α .</sentence>
				<definiendum id="0">Divergence</definiendum>
				<definiens id="0">introducing a probabilistic variable m</definiens>
			</definition>
			<definition id="5">
				<sentence>The HAC clustering process : While the similarity of the most similar word pair ( wordx , wordy ) is greater than a threshold ε then cluster wordx , wordy together and replace it with the centroid between wordx and wordy Recalculate the similarity between other words and the centroid We obtain the synonyms sets S from above HAC method .</sentence>
				<definiendum id="0">HAC clustering process</definiendum>
				<definiens id="0">While the similarity of the most similar word pair</definiens>
			</definition>
			<definition id="6">
				<sentence>The new feature vector of wordj = ∑= ×Ni 1 jitf Distribution_Vector_among_S ( iC ) , where jitf is the term frequency of the context word Ci occurs with wordj .</sentence>
				<definiendum id="0">jitf</definiendum>
				<definiens id="0">the term frequency of the context word Ci occurs with wordj</definiens>
			</definition>
			<definition id="7">
				<sentence>Christiance Fellbaum , editor 1998 , WordNet : An alectronic lwxical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An alectronic lwxical database</definiens>
			</definition>
</paper>

		<paper id="1112">
			<definition id="0">
				<sentence>languages The Machine Translation field is a good testing ground for any theory concerning the similarity of natural languages .</sentence>
				<definiendum id="0">Machine Translation field</definiendum>
			</definition>
			<definition id="1">
				<sentence>( Cze ) plave d117d117d106d106d106d106d106d106 d106d106d106d106d106d106 d106d106d106d106d106d106 d106 d121d121 d31 d31 d31 d31 d31 d31 d31 d31 d31 d31 on r´ad likes d124d124 d37d37 he d49d49 swimming The Czech-English example ( 11 ) shows two sentences which have a mutual distance equal to 3 — if we start changing the Czech tree into an English one , then the first elementary operation is the deletion of the node r´ad , the second operation adds the new node corresponding to the English word likes and the third and last operation is the change of the father of the node corresponding to the personal pronoun on [ he ] from swimming to likes .</sentence>
				<definiendum id="0">Cze</definiendum>
				<definiens id="0">a mutual distance equal to 3 — if we start changing the Czech tree into an English one , then the first elementary operation is the deletion of the node r´ad</definiens>
			</definition>
</paper>

		<paper id="1102">
</paper>

		<paper id="3113">
			<definition id="0">
				<sentence>Whittaker and Raj ( 2001 ) discuss probability encoding as a means to reduce memory requirements of an n-gram language model .</sentence>
				<definiendum id="0">Whittaker</definiendum>
				<definiens id="0">discuss probability encoding as a means to reduce memory requirements of an n-gram language model</definiens>
			</definition>
			<definition id="1">
				<sentence>Quantization provides an effective way of reducing the number of bits needed to store oating point variables .</sentence>
				<definiendum id="0">Quantization</definiendum>
				<definiens id="0">provides an effective way of reducing the number of bits needed to store oating point variables</definiens>
			</definition>
			<definition id="2">
				<sentence>Quantization algorithms differ in the way partition of data points is computed and centers are identi ed .</sentence>
				<definiendum id="0">Quantization algorithms</definiendum>
			</definition>
</paper>

		<paper id="1602">
			<definition id="0">
				<sentence>9 the tallest woman AS Roma’s quickest player the Big Board’s most respected floor traders France’s third-largest chemical group the most-recent wave of friendly takeovers the two largest competitors the the southern-most tip of England its lowest possible prices Superlative adjectives can manifest themselves in predicative ( “Mia is the tallest.” )</sentence>
				<definiendum id="0">“Mia</definiendum>
				<definiens id="0">the tallest.”</definiens>
			</definition>
			<definition id="1">
				<sentence>Thesecondlevelofagreementisrelativetotype identification ( attributive , predicative , adverbial , idiomatic ) , and is only calculated on the subset ofcasesbothannotatorsrecognisedassuperlatives ( 79 instances , as mentioned ) .</sentence>
				<definiendum id="0">Thesecondlevelofagreementisrelativetotype identification</definiendum>
				<definiens id="0">attributive , predicative , adverbial , idiomatic )</definiens>
			</definition>
			<definition id="2">
				<sentence>The overwhelming majority of superlatives are attributive ( 89.1 % ) , and only a few are used in a predicative way ( 6.9 % ) , adverbially ( 3.0 % ) , or in idiomatic expressions ( 0.9 % ) .1 Table 3 shows the detailed distribution according to data source and experimental sets .</sentence>
				<definiendum id="0">attributive</definiendum>
				<definiens id="0">the detailed distribution according to data source and experimental sets</definiens>
			</definition>
			<definition id="3">
				<sentence>( CCG ) CCG is a lexicalised theory of grammar ( Steedman , 2001 ) .</sentence>
				<definiendum id="0">CCG ) CCG</definiendum>
			</definition>
			<definition id="4">
				<sentence>The DLA system outperforms the baseline system on precision in all sub-corpora .</sentence>
				<definiendum id="0">DLA system</definiendum>
				<definiens id="0">outperforms the baseline system on precision in all sub-corpora</definiens>
			</definition>
			<definition id="5">
				<sentence>Acknowledgements We would like to thank Steve Pulman ( for information on the analysis of superlatives in the Core Language Engine ) , Mark Steedman ( for useful suggestions on an earlier draft of this paper ) , and Jean Carletta ( for helpful comments on annotation agreement issues ) , as well as three anonymous reviewers for their comments .</sentence>
				<definiendum id="0">Jean Carletta</definiendum>
			</definition>
</paper>

		<paper id="3810">
			<definition id="0">
				<sentence>Laplacian Eigenmaps Embedding ( Belkin and Niyogi , 2003 ) and Locality Preserving Indexing ( LPI ) ( He et al. , 2004 ) discover the local structure of the term and document space and compute a semantic subspace with a stronger discriminative power .</sentence>
				<definiendum id="0">Laplacian Eigenmaps Embedding</definiendum>
				<definiendum id="1">Locality Preserving Indexing ( LPI</definiendum>
				<definiens id="0">) ( He et al. , 2004 ) discover the local structure of the term and document space and compute a semantic subspace with a stronger discriminative power</definiens>
			</definition>
			<definition id="1">
				<sentence>LPI is a linear approximation to Laplacian Eigenmaps Embedding that eliminates this problem .</sentence>
				<definiendum id="0">LPI</definiendum>
				<definiens id="0">a linear approximation to Laplacian Eigenmaps Embedding that eliminates this problem</definiens>
			</definition>
			<definition id="2">
				<sentence>Generalized Latent Semantic Analysis ( GLSA ) ( Matveeva et al. , 2005 ) is a framework for computing semantically motivated term and document vectors .</sentence>
				<definiendum id="0">Generalized Latent Semantic Analysis ( GLSA )</definiendum>
			</definition>
			<definition id="3">
				<sentence>LSA is a special case of GLSA that uses inner product in step 1 and singular value decomposition in step 2 , see ( Bartell et al. , 1992 ) .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiendum id="1">GLSA</definiendum>
				<definiens id="0">a special case of</definiens>
			</definition>
			<definition id="4">
				<sentence>Given any matrix S , its singular value decomposition ( SVD ) is S = UΣV T .</sentence>
				<definiendum id="0">SVD</definiendum>
			</definition>
			<definition id="5">
				<sentence>The basic GLSA computes the SVD of S and uses k eigenvectors corresponding to the largest eigenvalues as a representation for term vectors .</sentence>
				<definiendum id="0">GLSA</definiendum>
				<definiens id="0">computes the SVD of S and uses k eigenvectors corresponding to the largest eigenvalues as a representation for term vectors</definiens>
			</definition>
			<definition id="6">
				<sentence>The Laplacian Eigenmaps Embedding algorithm computes the low dimensional vectors y to minimize under certain constraints summationdisplay ij ||yi −yj||2Wij .</sentence>
				<definiendum id="0">Laplacian Eigenmaps Embedding algorithm</definiendum>
				<definiens id="0">computes the low dimensional vectors y to minimize under certain constraints summationdisplay ij ||yi −yj||2Wij</definiens>
			</definition>
			<definition id="7">
				<sentence>W is the weight matrix based on the graph adjacency matrix .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">the weight matrix based on the graph adjacency matrix</definiens>
			</definition>
			<definition id="8">
				<sentence>GLSA offers a greater flexibility in exploring the notion of semantic relatedness between terms .</sentence>
				<definiendum id="0">GLSA</definiendum>
				<definiens id="0">offers a greater flexibility in exploring the notion of semantic relatedness between terms</definiens>
			</definition>
			<definition id="9">
				<sentence>Laplacian Eigenmaps Embedding preserves the similarities only locally , thus providing a potentially better approximation to the low dimensional semantic space .</sentence>
				<definiendum id="0">Laplacian Eigenmaps Embedding</definiendum>
				<definiens id="0">preserves the similarities only locally , thus providing a potentially better approximation to the low dimensional semantic space</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>LeXFlow is an adaptation to computational lexicons of XFlow , a cooperative web application for the management of document workflows ( DW , Marchetti et al. , 2005 ) .</sentence>
				<definiendum id="0">LeXFlow</definiendum>
			</definition>
			<definition id="1">
				<sentence>A LWT describes the life-cycle of a lexical entry , the agents allowed to act over it , the actions to be performed by the agents , and the order in which the actions are to be executed .</sentence>
				<definiendum id="0">LWT</definiendum>
				<definiens id="0">describes the life-cycle of a lexical entry , the agents allowed to act over it , the actions to be performed by the agents , and the order in which the actions are to be executed</definiens>
			</definition>
			<definition id="2">
				<sentence>Moreover , deriving from a tool designed for the cooperation of agents , LeXFlow allows to manage workflows where the different agents can reside over distributed places .</sentence>
				<definiendum id="0">LeXFlow</definiendum>
				<definiens id="0">deriving from a tool designed for the cooperation of agents</definiens>
			</definition>
			<definition id="3">
				<sentence>This module , named “multilingual WN Service” is responsible for the automatic crosslingual fertilization of lexicons having a Word19 Net-like structure .</sentence>
				<definiendum id="0">“multilingual WN Service”</definiendum>
				<definiens id="0">responsible for the automatic crosslingual fertilization of lexicons having a Word19 Net-like structure</definiens>
			</definition>
			<definition id="4">
				<sentence>Moreover , the enrichment of WN ( A ) will not only import the relations found in WN ( B ) , but it will also propose target synsets in the language ( A ) on the basis of those found in language ( B ) .</sentence>
				<definiendum id="0">enrichment of WN</definiendum>
				<definiens id="0">synsets in the language ( A ) on the basis of those found in language ( B )</definiens>
			</definition>
			<definition id="5">
				<sentence>This is why the version of the ILI is a parameter of the query to web service ( see Section below ) .</sentence>
				<definiendum id="0">ILI</definiendum>
			</definition>
			<definition id="6">
				<sentence>The WN ( B ) web service returns the synset ( s ) corresponding to the WN ( A ) synset , together with reliability scores .</sentence>
				<definiendum id="0">WN ( B ) web service</definiendum>
				<definiens id="0">returns the synset ( s ) corresponding to the WN ( A ) synset , together with reliability scores</definiens>
			</definition>
			<definition id="7">
				<sentence>Each new relation is obtained by substituting the target WN ( B ) synset with the corresponding synset WN ( A ) , which again is found by querying back the WN ( A ) web service ( all these steps through the ILI ) .</sentence>
				<definiendum id="0">A )</definiendum>
			</definition>
			<definition id="8">
				<sentence>ItalWordNet was realized as an extension of the Italian component of EuroWordNet .</sentence>
				<definiendum id="0">ItalWordNet</definiendum>
				<definiens id="0">an extension of the Italian component of EuroWordNet</definiens>
			</definition>
			<definition id="9">
				<sentence>A New Paradigm for an Open Distributed Language Resource Infrastructure : the Case of Computational Lexicons .</sentence>
				<definiendum id="0">New Paradigm for an Open Distributed Language Resource Infrastructure</definiendum>
			</definition>
			<definition id="10">
				<sentence>XFlow : An XML-Based Document-Centric Workflow .</sentence>
				<definiendum id="0">XFlow</definiendum>
			</definition>
			<definition id="11">
				<sentence>ItalWordNet : Building a Large Semantic Database for the Automatic Treatment of Italian .</sentence>
				<definiendum id="0">ItalWordNet</definiendum>
				<definiens id="0">Building a Large Semantic Database for the Automatic Treatment of Italian</definiens>
			</definition>
</paper>

		<paper id="0403">
			<definition id="0">
				<sentence>The notion of construction is similar to the one in Construction Grammar ( CxG ) 4 , as in ( Goldberg , 1995 ) , where : Cx is a construction iff Cx is a formmeaning pair 〈Fi , Si〉 such that some aspect of Fi or some aspect of Si is not strictly predictable from Cx’s component parts or from other previously established constructions .</sentence>
				<definiendum id="0">Cx</definiendum>
				<definiens id="0">a construction iff Cx is a formmeaning pair 〈Fi</definiens>
			</definition>
			<definition id="1">
				<sentence>For us , at the syntactic level , a construction is defined by a form , where a form is specified as a list of properties .</sentence>
				<definiendum id="0">construction</definiendum>
				<definiens id="0">a form is specified as a list of properties</definiens>
			</definition>
			<definition id="2">
				<sentence>A property is a constraint , which models a relationship among constructions .</sentence>
				<definiendum id="0">property</definiendum>
				<definiens id="0">models a relationship among constructions</definiens>
			</definition>
			<definition id="3">
				<sentence>By definition , ( C1 ≺ C2 ) [ c1 , c2 , A ] holds iff    cx ( c1 ) = C1 , and cx ( c2 ) = C2 , and { c1 , c2 } ∈ A , and ind ( c1 , A ) &lt; ind ( c2 , A ) Exclusion ( notdblarrowboth ) .</sentence>
				<definiendum id="0">]</definiendum>
				<definiendum id="1">ind</definiendum>
				<definiendum id="2">) Exclusion</definiendum>
				<definiens id="0">holds iff    cx ( c1 ) = C1 , and cx ( c2 ) = C2 , and { c1</definiens>
			</definition>
			<definition id="4">
				<sentence>By definition , ( C1 notdblarrowboth C2 ) [ c1 , c2 , A ] holds iff    cx ( c1 ) = C1 , and cx ( c2 ) = C2 , and { c1 , c2 } ∩A negationslash= { c1 , c2 } Uniqueness ( Uniq ) .</sentence>
				<definiendum id="0">]</definiendum>
				<definiens id="0">holds iff    cx ( c1 ) = C1 , and cx ( c2 ) = C2</definiens>
			</definition>
			<definition id="5">
				<sentence>By definition , Uniq ( C ) [ c , A ] holds iff    cx ( c ) = C , and c ∈ A , and ∀cprime ∈ A\ { c } , cx ( cprime ) negationslash= C CO parsing with PG is an intersection of different classes of constraint-related problems , each of which is listed below .</sentence>
				<definiendum id="0">Uniq ( C</definiendum>
				<definiendum id="1">]</definiendum>
				<definiens id="0">holds iff    cx ( c ) = C , and c ∈ A , and ∀cprime ∈ A\ { c } , cx ( cprime ) negationslash= C CO parsing with PG is an intersection of different classes of constraint-related problems</definiens>
			</definition>
			<definition id="6">
				<sentence>Heuristic 2 ( Contiguity ) An assignment is a set of contiguous elements .</sentence>
				<definiendum id="0">Contiguity ) An assignment</definiendum>
				<definiens id="0">a set of contiguous elements</definiens>
			</definition>
			<definition id="7">
				<sentence>6A CHR handler is a rule of the general form ( A = &gt; B | C ) , which can be read “if A then ( if B then C ) ” 21 derlying this handler can be expressed as follows : for each ( list of n constituents , assignment , property ) if ( the list of n constituents and the assignment match the property’s ones ) then if ( property is satisfied ) then ( tick property as being SATISFIED ) else ( tick property as being VIOLATED ) The CHR handler takes the following form : listOfConstituents ( Ccs ) &amp; &amp; assignment ( Asg ) &amp; &amp; property ( Pp ) == &gt; Pp .</sentence>
				<definiendum id="0">CHR handler</definiendum>
				<definiendum id="1">CHR handler</definiendum>
				<definiens id="0">a rule of the general form ( A = &gt; B | C ) , which can be read “if A then ( if B then C ) ” 21 derlying this handler can be expressed as follows : for each ( list of n constituents , assignment , property ) if ( the list of n constituents and the assignment match the property’s ones ) then if ( property is satisfied ) then ( tick property as being SATISFIED ) else</definiens>
			</definition>
</paper>

		<paper id="3410">
			<definition id="0">
				<sentence>Communication is the heart of what makes us social creatures .</sentence>
				<definiendum id="0">Communication</definiendum>
				<definiens id="0">the heart of what makes us social creatures</definiens>
			</definition>
			<definition id="1">
				<sentence>‘Discourse Diagrams’ describes newsgroups with semantic graphs of related concepts , and also graphs people’s conectedness to one another in social networks ( Sack , 200 ) .</sentence>
				<definiendum id="0">‘Discourse Diagrams’</definiendum>
				<definiens id="0">describes newsgroups with semantic graphs of related concepts , and also graphs people’s conectedness to one another in social networks</definiens>
			</definition>
			<definition id="2">
				<sentence>As a post-hoc analysis tol , RACE aids the analyst by adding system interpretations of affect and social dynamics to the information represented in the prior art .</sentence>
				<definiendum id="0">RACE</definiendum>
				<definiens id="0">aids the analyst by adding system interpretations of affect and social dynamics to the information represented in the prior art</definiens>
			</definition>
			<definition id="3">
				<sentence>The ultimate goal of the RACE project is to assist analysts as they try to extract meaning from a myriad of sources .</sentence>
				<definiendum id="0">RACE project</definiendum>
				<definiens id="0">they try to extract meaning from a myriad of sources</definiens>
			</definition>
			<definition id="4">
				<sentence>Research needs to be performed to determine how best to enable the analyst to fil in these blanks .</sentence>
				<definiendum id="0">Research</definiendum>
				<definiens id="0">needs to be performed to determine how best to enable the analyst to fil in these blanks</definiens>
			</definition>
			<definition id="5">
				<sentence>Erickson T and Laff MR ( 201 ) The design of the ‘Babble’ timeline : A social proxy for visualizing group activity over time .</sentence>
				<definiendum id="0">‘Babble’ timeline</definiendum>
				<definiens id="0">A social proxy for visualizing group activity over time</definiens>
			</definition>
</paper>

		<paper id="3507">
			<definition id="0">
				<sentence>A context declaration is a description of a container that can hold instances of schemas .</sentence>
				<definiendum id="0">context declaration</definiendum>
				<definiens id="0">a description of a container that can hold instances of schemas</definiens>
			</definition>
			<definition id="1">
				<sentence>Implicit contexts are however used in Construction Grammar : the form pole , which stores instances of schemas representing linguistic data in a linear space , and the unstructured meaning pole .</sentence>
				<definiendum id="0">Implicit contexts</definiendum>
				<definiens id="0">the form pole , which stores instances of schemas representing linguistic data in a linear space</definiens>
			</definition>
</paper>

		<paper id="0127">
</paper>

		<paper id="0108">
			<definition id="0">
				<sentence>( ) ( ) ∏ Qw i i D|wpD|Qp ∈ = ( 1 ) where , w i is a query term , p ( w i |D ) is document model which represents terms distribution over document .</sentence>
				<definiendum id="0">p ( w</definiendum>
				<definiens id="0">represents terms distribution over document</definiens>
			</definition>
			<definition id="1">
				<sentence>The proposed cluster-based language model is a mixture model of three components , that are sentence model p ML ( w|S ) , cluster/topic model p_topic ML ( w|T ) and collection model p ML ( w|C ) .</sentence>
				<definiendum id="0">cluster-based language model</definiendum>
			</definition>
			<definition id="2">
				<sentence>In this paper , the cluster model is in the form of term distribution over cluster/topic , associated with the distribution of clusters/topics over sentence , which can be expressed by equation ( 4 ) .</sentence>
				<definiendum id="0">cluster model</definiendum>
				<definiens id="0">in the form of term distribution over cluster/topic , associated with the distribution of clusters/topics over sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>( ) ( ) ( ) ∑ ∈Tt StptwpTwp_topic ||=| ( 4 ) where , T is the set of clusters/topics .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the set of clusters/topics</definiens>
			</definition>
			<definition id="4">
				<sentence>p ( t|S ) is topic sentence distribution which means the distribution of topic over sentence .</sentence>
				<definiendum id="0">p ( t|S</definiendum>
				<definiens id="0">topic sentence distribution which means the distribution of topic over sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>q j is the j-th query term , N is the number of all query terms .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the j-th query term</definiens>
				<definiens id="1">the number of all query terms</definiens>
			</definition>
</paper>

		<paper id="3105">
			<definition id="0">
				<sentence>The performance gap stems primarily from the addition of a hidden segmentation variable , which increases the capacity for overfitting during maximum likelihood training with EM .</sentence>
				<definiendum id="0">hidden segmentation variable</definiendum>
				<definiens id="0">increases the capacity for overfitting during maximum likelihood training with EM</definiens>
			</definition>
			<definition id="1">
				<sentence>2Our notation matches the literature for phrase-based translation : e is an English word , ¯e is an English phrase , and ¯eI1 is a sequence of I English phrases , and e is an English sentence .</sentence>
				<definiendum id="0">e</definiendum>
				<definiendum id="1">¯e</definiendum>
				<definiendum id="2">¯eI1</definiendum>
				<definiendum id="3">e</definiendum>
				<definiens id="0">an English phrase , and</definiens>
			</definition>
			<definition id="2">
				<sentence>Learning φEM degrades translation quality in large part because EM learns overly determinized segmentations and translation parameters , overfitting the training data and failing to generalize .</sentence>
				<definiendum id="0">Learning φEM</definiendum>
				<definiens id="0">degrades translation quality in large part because EM learns overly determinized segmentations and translation parameters , overfitting the training data and failing to generalize</definiens>
			</definition>
			<definition id="3">
				<sentence>The simplest strategy to increase entropy is to interpolate the heuristic and learned phrase tables .</sentence>
				<definiendum id="0">entropy</definiendum>
			</definition>
			<definition id="4">
				<sentence>φnew ( ¯ej| ¯fi ) = c ( ¯fi , ¯ej ) c ( ¯fi ) + kl−1 In the equation above , l is the length of the French phrase and k is a tuning parameter .</sentence>
				<definiendum id="0">k</definiendum>
				<definiens id="0">the length of the French phrase</definiens>
				<definiens id="1">a tuning parameter</definiens>
			</definition>
</paper>

		<paper id="2505">
</paper>

		<paper id="2808">
			<definition id="0">
				<sentence>NIL is ubiquitous due in special to the rapid proliferation of Internet applications .</sentence>
				<definiendum id="0">NIL</definiendum>
			</definition>
			<definition id="1">
				<sentence>Classes based on the POS tags , or the morphological analysis of words , or the semantic information have been tried .</sentence>
				<definiendum id="0">Classes</definiendum>
				<definiens id="0">based on the POS tags , or the morphological analysis of words , or the semantic information have been tried</definiens>
			</definition>
			<definition id="2">
				<sentence>The confidence-based value is defined as ( ) K K i i TCWC 1 1 ) ( ⎟ ⎠ ⎞ ⎜ ⎝ ⎛ = ∏ = ( 3 ) where K denotes the number of trigrams in chat text W and i T is the i-th order trigram .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the number of trigrams in chat text W and i T is the i-th order trigram</definiens>
			</definition>
</paper>

		<paper id="2711">
			<definition id="0">
				<sentence>NXT uses a stand-off XML data format that consist of several XML files that point to each other .</sentence>
				<definiendum id="0">NXT</definiendum>
			</definition>
</paper>

		<paper id="1636">
			<definition id="0">
				<sentence>A PCFG is a tuple ( V , M , µ0 , R , q : R → [ 0,1 ] ) , where V is a set of terminal symbols ; M = { µi } is a set of nonterminal symbols ; µ0 is a start or root symbol ; R is a set of productions of the form µi → ρ , where ρ is a sequence of terminals and nonterminals ; and q is a family of probability distributions over rules conditioned on each rule’s left-hand side .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiendum id="1">V</definiendum>
				<definiendum id="2">R</definiendum>
				<definiendum id="3">ρ</definiendum>
				<definiendum id="4">q</definiendum>
				<definiens id="0">a tuple ( V , M , µ0 , R , q : R → [</definiens>
				<definiens id="1">a set of terminal symbols</definiens>
				<definiens id="2">a set of nonterminal symbols ; µ0 is a start or root symbol</definiens>
				<definiens id="3">a set of productions of the form µi → ρ , where</definiens>
			</definition>
			<definition id="1">
				<sentence>A PCFG is derived from the trees in the usual manner , with production rules taken directly from the annotated trees , and the probability of an annotated rule q ( λ → ρ ) = C ( λ→ρ ) C ( λ ) where C ( λ → ρ ) and C ( λ ) are the number of observations of the production and its left hand side , respectively .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">derived from the trees in the usual manner , with production rules taken directly from the annotated trees , and the probability of an annotated rule q ( λ → ρ ) = C ( λ→ρ ) C ( λ ) where C ( λ → ρ ) and C ( λ ) are the number of observations of the production and its left hand side</definiens>
			</definition>
			<definition id="2">
				<sentence>dM is the number of degrees of freedom in the model , which for a PCFG is the number of productions minus the number of nonterminals .</sentence>
				<definiendum id="0">dM</definiendum>
				<definiendum id="1">PCFG</definiendum>
				<definiens id="0">the number of degrees of freedom in the model</definiens>
				<definiens id="1">the number of productions minus the number of nonterminals</definiens>
			</definition>
			<definition id="3">
				<sentence>Next comes the heir of the constituent , D. This is followed by the first constituent that is to be unpacked from the binarized version , C , which in turn is followed by its head part-of-speech PC , giving us ( A , D , C , PC , ... ) .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">to be unpacked from the binarized version ,</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>Lexical Markup Framework ( LMF ) is a model that provides a common standardized framework for the construction of Natural Language Processing ( NLP ) lexicons .</sentence>
				<definiendum id="0">Lexical Markup Framework ( LMF )</definiendum>
			</definition>
			<definition id="1">
				<sentence>LMF is also used to model machine readable dictionaries ( MRD ) , which are not within the scope of this paper .</sentence>
				<definiendum id="0">MRD</definiendum>
				<definiens id="0">also used to model machine readable dictionaries</definiens>
			</definition>
			<definition id="2">
				<sentence>LMF is comprised of two components : 1 ) The core package consists of a structural skeleton that describes the basic hierarchy of information in a lexical entry .</sentence>
				<definiendum id="0">LMF</definiendum>
				<definiendum id="1">core package</definiendum>
			</definition>
			<definition id="3">
				<sentence>In the core package , the class called Database represents the entire resource and is a container for one or more lexicons .</sentence>
				<definiendum id="0">Database</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Lexicon class is the container for all the lexical entries of the same language within the database .</sentence>
				<definiendum id="0">Lexicon class</definiendum>
				<definiens id="0">the container for all the lexical entries of the same language within the database</definiens>
			</definition>
			<definition id="5">
				<sentence>The Lexicon Information class contains administrative information and other general attributes .</sentence>
				<definiendum id="0">Lexicon Information class</definiendum>
			</definition>
			<definition id="6">
				<sentence>Form consists of a text string that represents the word .</sentence>
				<definiendum id="0">Form</definiendum>
				<definiens id="0">consists of a text string that represents the word</definiens>
			</definition>
			<definition id="7">
				<sentence>Therefore , the Lexical Entry manages the relationship between sets of related forms and their senses .</sentence>
				<definiendum id="0">Lexical Entry</definiendum>
			</definition>
			<definition id="8">
				<sentence>The use of the Sense Axis facilitates the representation of the translation of words that do not necessarily have the same valence or morphological form in one language than in another .</sentence>
				<definiendum id="0">Sense Axis</definiendum>
				<definiens id="0">facilitates the representation of the translation of words that do not necessarily have the same</definiens>
			</definition>
			<definition id="9">
				<sentence>Sense Axis Relation permits to describe the linking between two different Sense Axis instances .</sentence>
				<definiendum id="0">Sense Axis Relation</definiendum>
			</definition>
			<definition id="10">
				<sentence>The following conventions are adopted : • each UML attribute is transcoded as a DC ( for Data Category ) element • each UML class is transcoded as an XML element • UML aggregations are transcoded as content inclusion • UML shared associations ( i.e. associations that are not aggregations ) are transcoded as IDREF ( S ) The first example ( i.e. `` river '' ) can be represented with the following XML tags : &lt; Database &gt; &lt; ! — French section</sentence>
				<definiendum id="0">DC</definiendum>
				<definiens id="0">content inclusion • UML shared associations</definiens>
			</definition>
			<definition id="11">
				<sentence>&lt; Lexicon &gt; &lt; LexiconInformation &lt; DC att= '' name '' val=”French Extract”/ &gt; &lt; DC att= '' language '' val= '' fra '' / &gt; &lt; /LexiconInformation &gt; &lt; LexicalEntry &gt; &lt; DC att= '' partOfSpeech '' val=”noun”/ &gt; &lt; LemmatisedForm &gt; &lt; DC att= '' writtenForm '' val=”fleuve”/ &gt; &lt; /LemmatisedForm &gt; &lt; Sense id=”fra.fleuve1” &gt; &lt; SemanticDefinition &gt; &lt; DC att= '' text '' val=”Grande rivière lorsqu'elle aboutit à la mer”/ &gt; &lt; DC att= '' source '' val=”Le Petit Robert 2003”/ &gt; &lt; /SemanticDefinition &gt; &lt; /Sense &gt; &lt; /LexicalEntry &gt; &lt; LexicalEntry &gt; &lt; DC att= '' partOfSpeech '' val=”noun”/ &gt; &lt; LemmatisedForm &gt; &lt; DC att= '' writtenForm '' val=”rivière”/ &gt; &lt; /LemmatisedForm &gt; &lt; Sense id=”fra.riviere1” &gt; &lt; SemanticDefinition &gt; &lt; DC att= '' text '' val=”Cours d'eau naturel de moyenne importance”/ &gt; &lt; DC att= '' source '' val=”Le Petit Robert 2003”/ &gt; &lt; /SemanticDefinition &gt; &lt; /Sense &gt; &lt; /LexicalEntry &gt; &lt; /Lexicon &gt; &lt; ! — Multilingual section</sentence>
				<definiendum id="0">partOfSpeech</definiendum>
				<definiens id="0">&lt; Lexicon &gt; &lt; LexiconInformation &lt; DC att= '' name '' val=”French Extract”/ &gt; &lt; DC att= '' language '' val= '' fra '' / &gt; &lt; /LexiconInformation &gt; &lt; LexicalEntry &gt; &lt; DC att= ''</definiens>
			</definition>
</paper>

		<paper id="1411">
			<definition id="0">
				<sentence>SOG : [ G 0 R 0 G 1 R 1 ... G i R i ... G n ] G i : a group R i : a relation between G i and G i+1 R i , a relation between groups G i and G i+1 , denotes a shift of attention from G i to G i+1 with a certain focused feature .</sentence>
				<definiendum id="0">SOG</definiendum>
				<definiens id="0">[ G 0 R 0 G 1 R 1 ... G i R i ... G n ] G i : a group R i : a relation between G i and G i+1 R i , a relation between groups G i and G i+1 , denotes a shift of attention from G i to G i+1 with a certain focused feature</definiens>
			</definition>
			<definition id="1">
				<sentence>An inter-group relation is a spatial relation and denoted by symbol ⇒ .</sentence>
				<definiendum id="0">inter-group relation</definiendum>
				<definiens id="0">a spatial relation and denoted by symbol ⇒</definiens>
			</definition>
			<definition id="2">
				<sentence>IfNewG contains the target object , call function extend unless Checkedcontains NewG .</sentence>
				<definiendum id="0">IfNewG</definiendum>
				<definiens id="0">contains the target object , call function extend unless Checkedcontains NewG</definiens>
			</definition>
			<definition id="3">
				<sentence>The group followed by 1 Although different languages require different surface realization rules , we presume perceptual grouping and SOG generation ( Step 1 and 2 ) are applicable to other languages as well .</sentence>
				<definiendum id="0">SOG generation</definiendum>
				<definiens id="0">applicable to other languages as well</definiens>
			</definition>
</paper>

		<paper id="0506">
			<definition id="0">
				<sentence>Taxonomy is a collection of controlled vocabulary terms organized into a hierarchical structure .</sentence>
				<definiendum id="0">Taxonomy</definiendum>
				<definiens id="0">a collection of controlled vocabulary terms organized into a hierarchical structure</definiens>
			</definition>
			<definition id="1">
				<sentence>Specificity is degree of detailed information of an object about given target object .</sentence>
				<definiendum id="0">Specificity</definiendum>
				<definiens id="0">degree of detailed information of an object about given target object</definiens>
			</definition>
			<definition id="2">
				<sentence>In this context , specificity is a function of objects and target object to real number .</sentence>
				<definiendum id="0">specificity</definiendum>
				<definiens id="0">a function of objects and target object to real number</definiens>
			</definition>
			<definition id="3">
				<sentence>On the other hand , term specificity is the function of terms and target domains in taxonomy learning context ( Ryu &amp; Choi 2005 ) .</sentence>
				<definiendum id="0">term specificity</definiendum>
				<definiens id="0">the function of terms and target domains in taxonomy learning context</definiens>
			</definition>
			<definition id="4">
				<sentence>( | ) Spec t D R + ∈ ( 1 ) where t is a term , and Spec ( t|D ) is the specificity of t in a given domain D. We simply use Spec ( t ) instead of Spec ( t|D ) assuming a particular domain D in this paper .</sentence>
				<definiendum id="0">t</definiendum>
				<definiendum id="1">Spec ( t|D )</definiendum>
				<definiens id="0">the specificity of t in a given domain D. We simply use Spec ( t</definiens>
			</definition>
			<definition id="5">
				<sentence>1 ( ) ( | ) log ( | ) arg arg vargarg v Spec t P t v P t v − =− ∑ ( 3 ) where P ( t|v arg ) , the probability that t is argument of v arg , is estimated as freq ( t , v arg ) /freq ( v arg ) .</sentence>
				<definiendum id="0">P (</definiendum>
				<definiens id="0">t|v arg ) , the probability that t is argument of v arg , is estimated as freq ( t , v arg ) /freq ( v arg )</definiens>
			</definition>
			<definition id="6">
				<sentence>The entropy is the average information quantity of all ( t , v arg ) pairs for term t. Conditional probability of term co-occurrence in documents was used in ( Sanderson &amp; Croft , 1999 ) to build term taxonomy .</sentence>
				<definiendum id="0">entropy</definiendum>
				<definiens id="0">the average information quantity of all ( t , v arg ) pairs for term t. Conditional probability of term co-occurrence in documents</definiens>
			</definition>
			<definition id="7">
				<sentence>1 ( , ) ( ) j jn coldoc subsume t t Spec t n ≤≤ = ∑ ( 6 ) where n is number of terms co-occurring terms with t. Finally , inside-word information is important to compute specificity for multiword terms .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">number of terms co-occurring terms with t. Finally , inside-word information is important to compute specificity for multiword terms</definiens>
			</definition>
			<definition id="8">
				<sentence>2* ( , ) ( , ) ||| | ij in i j ij cwc t t Sim t t tt = + ( 10 ) where |t| is word count of t , and cwc ( t i , t j ) is common word count in t i and t j .</sentence>
				<definiendum id="0">|t|</definiendum>
				<definiendum id="1">cwc</definiendum>
				<definiens id="0">common word count in t i and t j</definiens>
			</definition>
			<definition id="9">
				<sentence>t 1 t 2 t 3 t 4 t 5 t 6 t 7 t 8 t 9 t new t 10 Spec ( t 1 ) = 1.0 Spec ( t 3 ) = 1.5 Spec ( t 2 ) = 1.5 Spec ( t 4 ) = 2.0 Spec ( t 5 ) = 3.0 Spec ( t 7 ) = 4.0 Spec ( t 8 ) = 3.5 Spec ( t 6 ) = 2.4 Spec ( t 9 ) = 2.5 Spec ( t new ) = 2.3 Spec ( t 10 ) = 3.0 S p e c if ic it y High Low Figure 4 .</sentence>
				<definiendum id="0">Spec</definiendum>
				<definiens id="0">( t 8 ) = 3.5 Spec ( t 6 ) = 2.4 Spec ( t 9 ) = 2.5 Spec ( t new ) = 2.3 Spec ( t 10 ) = 3.0 S p e c if ic it y High Low Figure 4</definiens>
			</definition>
			<definition id="10">
				<sentence>Recall is the fraction of the terms that have specificity values by the given measuring method .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the fraction of the terms that have specificity values by the given measuring method</definiens>
			</definition>
			<definition id="11">
				<sentence>Precision is the fraction of relations with correct specificity values .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the fraction of relations with correct specificity values</definiens>
			</definition>
			<definition id="12">
				<sentence>Precision ( P spec ) , recall ( R spec ) , Fmeasure ( F spec ) is defined as follows : # # # ( , ) # ( , ) spec valid spec valid of terms with specificity R of all terms of R p c with correct specificity P of R p c = = ( 11 ) where R valid ( p , c ) is a valid parent-child relation in original taxonomy , and a relation is valid when the specificity of two terms are measured by the given method .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiendum id="2">Fmeasure ( F spec )</definiendum>
				<definiendum id="3">c )</definiendum>
				<definiens id="0">follows : # # # ( , ) # ( , ) spec valid spec valid of terms with specificity R of all terms of R p c with correct specificity P of R p c = = ( 11 ) where R valid ( p ,</definiens>
			</definition>
			<definition id="13">
				<sentence>We defined recall of similarity measure , R Sim , as the fraction of the term pairs that have similarity values by the given measuring method as Eq .</sentence>
				<definiendum id="0">R Sim</definiendum>
			</definition>
			<definition id="14">
				<sentence>LR Tax is defined as the ratio of number of common terms in learned taxonomy and reference taxonomy over number of terms in reference taxonomy .</sentence>
				<definiendum id="0">LR Tax</definiendum>
				<definiens id="0">the ratio of number of common terms in learned taxonomy and reference taxonomy over number of terms in reference taxonomy</definiens>
			</definition>
</paper>

		<paper id="3126">
			<definition id="0">
				<sentence>For evaluation we have selected a set of 8 metric variants corresponding to seven different families : BLEU ( n = 4 ) ( Papineni et al. , 2001 ) , NIST ( n = 5 ) ( Lin and Hovy , 2002 ) , GTM F1-measure ( e = 1,2 ) ( Melamed et al. , 2003 ) , 1-WER ( Nießen et al. , 2000 ) , 1-PER ( Leusch et al. , 2003 ) , ROUGE ( ROUGE-S* ) ( Lin and Och , 2004 ) and METEOR3 ( Banerjee and Lavie , 2005 ) .</sentence>
				<definiendum id="0">NIST</definiendum>
				<definiendum id="1">GTM F1-measure</definiendum>
				<definiendum id="2">1-WER</definiendum>
				<definiendum id="3">METEOR3</definiendum>
				<definiens id="0">a set of 8 metric variants corresponding to seven different families</definiens>
			</definition>
</paper>

		<paper id="2611">
			<definition id="0">
				<sentence>In order to test the feasibility of such a task , we have trained an SVM ( Support Vector Machine ) Tree Kernel model for the automatic acquisition of the frame information .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">Support Vector Machine ) Tree Kernel model for the automatic acquisition of the frame information</definiens>
			</definition>
			<definition id="1">
				<sentence>As opposed , the FrameNet frames were build on semantic bases , by putting together verbs , nouns and adjectives that evoke the same situations .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">frames were build on semantic bases</definiens>
			</definition>
			<definition id="2">
				<sentence>VerbNet classes The mapping algorithm consists of three steps : ( a ) we link the frames and Intersective Levin verb classes that have the largest number of verbs in common and we create a set of pairs 〈FrameNet frame , VerbNet class〉 ( see Figure 1 ) ; ( b ) we refine the pairs obtained in the previous step based on diathesis alternation criteria , i.e. the verbs pertaining to the FrameNet frame have to undergo the same diathesis alternation that characterize the corresponding VerbNet class ( see Figure 2 ) and ( c ) we manually check and correct the resulting mapping .</sentence>
				<definiendum id="0">VerbNet classes The mapping algorithm</definiendum>
				<definiens id="0">consists of three steps : ( a ) we link the frames and Intersective Levin verb classes that have the largest number of verbs in common and we create a set of pairs 〈FrameNet frame</definiens>
				<definiens id="1">the pairs obtained in the previous step based on diathesis alternation criteria , i.e. the verbs pertaining to the FrameNet frame have to undergo the same diathesis alternation that characterize the corresponding VerbNet class</definiens>
			</definition>
			<definition id="3">
				<sentence>Our good results show that we have defined an effective framework which is a promising step toward the design of free-text semantic parsers .</sentence>
				<definiendum id="0">effective framework</definiendum>
				<definiens id="0">a promising step toward the design of free-text semantic parsers</definiens>
			</definition>
</paper>

		<paper id="1628">
			<definition id="0">
				<sentence>Phrase-based approaches ( Och and Ney , 2004 ) to statistical machine translation ( SMT ) have recently achieved impressive results , leading to significant improvements in accuracy over the original IBM models ( Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">Phrase-based approaches</definiendum>
				<definiendum id="1">SMT</definiendum>
			</definition>
			<definition id="1">
				<sentence>A major part of the AEP is a parse-tree fragment , that is similar to a TAG elementary tree ( see also Figure 2 ) : SBAR that S NP VP V has VP V been NP Following the work of Frank ( 2002 ) , we will refer to a structure like this as an extended projection ( EP ) .</sentence>
				<definiendum id="0">extended projection</definiendum>
				<definiens id="0">a parse-tree fragment</definiens>
			</definition>
			<definition id="2">
				<sentence>An AEP contains an EP , as well as alignment information about where the German modifiers should be placed in the extended projection .</sentence>
				<definiendum id="0">AEP</definiendum>
				<definiens id="0">contains an EP , as well as alignment information about where the German modifiers should be placed in the extended projection</definiens>
			</definition>
			<definition id="3">
				<sentence>Substitution nodes ( such as NP-A or SBAR-A ) in the elementary trees specify the positions of arguments of the content words .</sentence>
				<definiendum id="0">Substitution nodes</definiendum>
				<definiens id="0">such as NP-A or SBAR-A</definiens>
			</definition>
			<definition id="4">
				<sentence>An AEP consists of the following parts : STEM : A string specifying the stemmed form of the main verb in the clause .</sentence>
				<definiendum id="0">AEP</definiendum>
				<definiens id="0">consists of the following parts : STEM : A string specifying the stemmed form of the main verb in the clause</definiens>
			</definition>
			<definition id="5">
				<sentence>WH : This variable is always NULL if there is no wh-phrase position within the SPINE ; it is always a non-empty string ( such as which , or in which ) if a wh-phrase position does exist .</sentence>
				<definiendum id="0">WH</definiendum>
				<definiens id="0">such as which , or in which ) if a wh-phrase position does exist</definiens>
			</definition>
			<definition id="6">
				<sentence>INFL : The inflected form of the verb .</sentence>
				<definiendum id="0">INFL</definiendum>
			</definition>
			<definition id="7">
				<sentence>MOD ( i ) : There are n modifier variables MOD ( 1 ) , MOD ( 2 ) , ... , MOD ( n ) that specify the positions for German arguments that have not already been assigned to the SUBJECT or OBJECT positions in the spine .</sentence>
				<definiendum id="0">MOD</definiendum>
				<definiendum id="1">MOD</definiendum>
				<definiens id="0">( n ) that specify the positions for German arguments that have not already been assigned to the SUBJECT or OBJECT positions in the spine</definiens>
			</definition>
			<definition id="8">
				<sentence>235 German Clause English AEP s-oc kous-cp daß np-sb 1 art das nn haupthemmnis np-pd 2 art der adja vorhersehbare nn widerstand np-ag art der nn hersteller vafin-hd war Paraphrase : that [ np-sb the main obstacle ] [ np-pd the predictable resistance of manufacturers ] was STEM : be SPINE : SBAR-A IN that S NP-A VP V NP-A VOICE : active SUBJECT : 1 OBJECT : 2 WH : NULL MODALS : has INFL : been MOD1 : null MOD2 : null s pp-mo 1 appr zwischen piat beiden nn gesetzen vvfin-hd bestehen adv-mo 2 also np-sb 3 adja erhebliche adja rechtliche $ , , adja praktische kon und adja wirtschaftliche nn unterschiede Paraphrase : [ pp-mo between the two pieces of legislation ] exist so [ np-sb significant legal , practical and economic differences ] STEM : be SPINE : S NP-A VP V NP-A VOICE : active SUBJECT : “there” OBJECT : 3 WH : NULL MODALS : NULL INFL : are MOD1 : post-verb MOD2 : pre-sub MOD3 : null s-rc prels-sb die vp pp-mo 1 appr an pdat jenem nn tag pp-mo 2 appr in ne tschernobyl vvpp-hd gez¨undet vafin-hd wurde Paraphrase : which [ pp-mo on that day ] [ pp-mo in chernobyl ] released were STEM : release SPINE : SBAR WHNP SG-A VP V VOICE : passive SUBJECT : NULL OBJECT : NULL WH : which MODALS : was INFL : released MOD1 : post-verb MOD2 : post-verb Figure 2 : Three examples of German parse trees , together with their aligned extended projections ( AEPs ) in the training data .</sentence>
				<definiendum id="0">Paraphrase</definiendum>
				<definiendum id="1">AEPs</definiendum>
				<definiens id="0">adja praktische kon und adja wirtschaftliche nn unterschiede Paraphrase : [ pp-mo between the two pieces of legislation ] exist so [ np-sb significant legal , practical and economic differences ] STEM : be SPINE : S NP-A VP V NP-A VOICE : active SUBJECT : “there” OBJECT</definiens>
			</definition>
			<definition id="9">
				<sentence>Each training example consists of a German clause paired with an English AEP ( see Figure 2 ) .</sentence>
				<definiendum id="0">English AEP</definiendum>
				<definiens id="0">a German clause paired with an</definiens>
			</definition>
			<definition id="10">
				<sentence>In our approach , N will be a fixed number for any input x : we take the N decisions to correspond to the sequence of variables STEM , SPINE , ... , MOD ( 1 ) , MOD ( 2 ) , ... , MOD ( n ) described in section 3 .</sentence>
				<definiendum id="0">SPINE , ... , MOD</definiendum>
				<definiendum id="1">MOD</definiendum>
			</definition>
			<definition id="11">
				<sentence>ADVANCE is a function that specifies which decisions are allowable for a past history 〈d1 , ... , di−1〉 and an input x. In our case the ADVANCE function implements hard constraints on AEPs ( for example , the constraint that the SUBJECT variable must be NULL if no subject position exists in the SPINE ) .</sentence>
				<definiendum id="0">ADVANCE</definiendum>
				<definiens id="0">a function that specifies which decisions are allowable for a past history 〈d1 , ...</definiens>
			</definition>
			<definition id="12">
				<sentence>We define the score for any partial or complete decision sequence y = 〈d1 , d2 , ... , dm〉 paired with x as : SCORE ( x , y ) = Φ ( x , y ) · ¯α ( 1 ) where Φ ( x , y ) = summationtextmi=1 ¯φ ( x , 〈d1 , ... , di−1〉 , di ) .</sentence>
				<definiendum id="0">Φ</definiendum>
				<definiens id="0">the score for any partial or complete decision sequence y = 〈d1 , d2 , ... , dm〉 paired with x as : SCORE ( x , y ) = Φ</definiens>
			</definition>
</paper>

		<paper id="3604">
			<definition id="0">
				<sentence>As the third test set we selected all tokens of the Brown corpus part of the Penn Treebank ( Marcus et al. , 1993 ) , a selected portion of the original one-million word Brown corpus ( Kuˇcera and Francis , 1967 ) , a collection of samples of American English in many different genres , from sources printed in 1961 ; we refer to this test set as BROWN .</sentence>
				<definiendum id="0">Kuˇcera</definiendum>
				<definiens id="0">a collection of samples of American English in many different genres , from sources printed in 1961</definiens>
			</definition>
			<definition id="1">
				<sentence>The IG of feature i is measured by computing the difference in uncertainty ( i.e. entropy ) between the situations without and with knowledge of the value of that feature with respect to predicting the class label : IGi = H ( C ) −summationtextv∈Vi P ( v ) ×H ( C|v ) , where C is the set of class labels , Vi is the set of values for feature i , and H ( C ) = −summationtextc∈C P ( c ) log2 P ( c ) is the entropy of the class labels .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">Vi</definiendum>
				<definiendum id="2">H</definiendum>
				<definiens id="0">measured by computing the difference in uncertainty ( i.e. entropy ) between the situations without and with knowledge of the value of that feature with respect to predicting the class label</definiens>
				<definiens id="1">the set of class labels</definiens>
				<definiens id="2">the entropy of the class labels</definiens>
			</definition>
			<definition id="2">
				<sentence>IGTREE , therefore , can be seen as an approximation of IB1-IG with k = 1 that has favorable asymptotic complexities as compared to IB1-IG .</sentence>
				<definiendum id="0">IGTREE</definiendum>
				<definiens id="0">an approximation of IB1-IG with k = 1 that has favorable asymptotic complexities as compared to IB1-IG</definiens>
			</definition>
			<definition id="3">
				<sentence>IGTREE’s computational bottleneck is the trie construction process , which has an asymptotic complexity of O ( nlg ( v ) f ) of CPU , where n is the number of training examples , v is the average branching factor of IGTREE ( how many branches fan out of a node , on average ) , and f is the number of features .</sentence>
				<definiendum id="0">IGTREE’s computational bottleneck</definiendum>
				<definiendum id="1">trie construction process</definiendum>
				<definiendum id="2">n</definiendum>
				<definiendum id="3">v</definiendum>
				<definiendum id="4">IGTREE</definiendum>
				<definiendum id="5">f</definiendum>
				<definiens id="0">the number of training examples</definiens>
				<definiens id="1">the number of features</definiens>
			</definition>
			<definition id="4">
				<sentence>28 speed The numbers of nodes exhibit an interesting sublinear relation with respect to the number of training examples , which is in line with the asymptotic complexity order O ( n ) , where n is the number of training instances .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of training instances</definiens>
			</definition>
</paper>

		<paper id="0109">
			<definition id="0">
				<sentence>Named Entity Recognition ( NER ) is useful in NLP applications such as question answering , machine translation and information extraction .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">useful in NLP applications such as question answering , machine translation and information extraction</definiens>
			</definition>
			<definition id="1">
				<sentence>NER , especially of personal names and place names , is an area in which lexicon-driven methods have a clear advantage over probabilistic methods and in which the role of lexical resources should be a central one .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">an area in which lexicon-driven methods have a clear advantage over probabilistic methods and in which the role of lexical resources should be a central one</definiens>
			</definition>
			<definition id="2">
				<sentence>This is equivalent to saying that headwaiter should not be considered an instance of waiter , which is indeed how Google behaves .</sentence>
				<definiendum id="0">waiter</definiendum>
			</definition>
			<definition id="3">
				<sentence>That is , meaningful linguistic units , equivalent to lexemes , with the important difference that the TC is the traditional version of the SC on a character form level .</sentence>
				<definiendum id="0">TC</definiendum>
				<definiens id="0">meaningful linguistic units , equivalent to lexemes , with the important difference that the</definiens>
				<definiens id="1">the traditional version of the SC on a character form level</definiens>
			</definition>
			<definition id="4">
				<sentence>CJKI , which specializes in CJK and Arabic computational lexicography , is engaged in an ongoing research and development effort to compile CJK and Arabic lexical databases ( currently about seven million entries ) , with special emphasis on proper nouns , orthographic normalization , and C2C .</sentence>
				<definiendum id="0">CJKI</definiendum>
			</definition>
</paper>

		<paper id="0133">
			<definition id="0">
				<sentence>Our Chinese word segmenter is a modification of the system described by Low et al. ( 2005 ) , which they entered in the 2005 Second International Chinese Word Segmentation Bakeoff .</sentence>
				<definiendum id="0">Chinese word segmenter</definiendum>
				<definiens id="0">a modification of the system described by Low et al. ( 2005 ) , which they entered in the 2005 Second International Chinese Word Segmentation Bakeoff</definiens>
			</definition>
			<definition id="1">
				<sentence>All of the feature templates of Low et al.’s system are utilized in our own ( with a few slight modifications ) : In the above feature templates , Ci refers to the character i positions away from the character under consideration , where negative values indicate characters to the left of the present position .</sentence>
				<definiendum id="0">Ci</definiendum>
				<definiens id="0">the character i positions away from the character under consideration</definiens>
			</definition>
			<definition id="2">
				<sentence>L is defined to be the length of the longest wordW in the dictionary that matches some sequence of characters around C0 185 in the current context and t0 is the boundary tag of C0 inW .</sentence>
				<definiendum id="0">t0</definiendum>
				<definiens id="0">the boundary tag of C0 inW</definiens>
			</definition>
			<definition id="3">
				<sentence>Thisisasurprisingresult , asinourtesting the added features helped to improve the F scores and OOV recall rates of the system when dealing with the 2005 bakeoff data , even if only by a small amount in some cases .</sentence>
				<definiendum id="0">Thisisasurprisingresult</definiendum>
				<definiens id="0">asinourtesting the added features helped to improve the F scores and OOV recall rates of the system when dealing with the 2005 bakeoff data</definiens>
			</definition>
</paper>

		<paper id="2110">
			<definition id="0">
				<sentence>Multiword expressions ( hereafter MWEs ) are lexical items that can be decomposed into multiple simplex words and display lexical , syntactic and/or semantic idiosyncracies ( Sag et al. , 2002 ; Calzolari et al. , 2002 ) .</sentence>
				<definiendum id="0">Multiword expressions</definiendum>
				<definiens id="0">hereafter MWEs ) are lexical items that can be decomposed into multiple simplex words and display lexical , syntactic and/or semantic idiosyncracies</definiens>
			</definition>
			<definition id="1">
				<sentence>The VPCs or verb-PPs are represented with corresponding information as given below : P ( type|v , p , wsSUBJ , wsDOBJ , wsIOBJ ) where type denotes either a VPC or verb-PP , v is the head verb , p is the preposition , and ws* is the word sense of the subject , direct object or indirect object .</sentence>
				<definiendum id="0">type</definiendum>
				<definiendum id="1">v</definiendum>
				<definiendum id="2">p</definiendum>
				<definiens id="0">corresponding information as given below : P ( type|v , p</definiens>
			</definition>
</paper>

		<paper id="1671">
			<definition id="0">
				<sentence>Information extraction ( IE ) algorithms populate a database with facts discovered from unstructured text .</sentence>
				<definiendum id="0">Information extraction</definiendum>
				<definiens id="0">a database with facts discovered from unstructured text</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , we model the conditional distribution PΛ ( Sij|Fi , Fj ) ∝ exp parenleftBiggsummationdisplay k λkfk ( Sij , Fi , Fj ) parenrightBigg where fk is a binary feature function that computes attributes over the field sets , and Λ = { λk } is the set of real-valued weights that are the parameters of the maximum-entropy model .</sentence>
				<definiendum id="0">conditional distribution PΛ</definiendum>
				<definiendum id="1">fk</definiendum>
				<definiens id="0">a binary feature function that computes attributes over the field sets , and Λ = { λk } is the set of real-valued weights that are the parameters of the maximum-entropy model</definiens>
			</definition>
			<definition id="2">
				<sentence>• Pairwise Compatibility : In this approach , the compatibility function only estimates the compatibility between pairs of fields , not sets of fields .</sentence>
				<definiendum id="0">compatibility function</definiendum>
				<definiens id="0">sets of fields</definiens>
			</definition>
			<definition id="3">
				<sentence>Wealsoexaminedocumentswhereclustercompatibility outperforms the pairwise methods .</sentence>
				<definiendum id="0">Wealsoexaminedocumentswhereclustercompatibility</definiendum>
				<definiens id="0">outperforms the pairwise methods</definiens>
			</definition>
</paper>

		<paper id="2930">
			<definition id="0">
				<sentence>arc ( k , FIRST ) ∈ G , then re ; Using the first sentence of the Swedish corpus as input ( Table 1 ) , this algorithm produces the sequence of 24 actions : sh , sh , la , ra , re , la , sh , sh , sh , la , la , ra , ra , sh , la , re , ra , ra , ra , re , re , re , re , and ra ( Table 2 ) .</sentence>
				<definiendum id="0">ra</definiendum>
				<definiens id="0">sh , sh , la , ra , re , la , sh , sh , sh , la , la , ra , ra , sh , la , re , ra , ra , ra , re , re , re , re</definiens>
			</definition>
</paper>

		<paper id="0803">
			<definition id="0">
				<sentence>Person name disambiguation can be seen as a special case of word sense disambiguation ( WSD ) ( Schutze , 1998 ; McCarthy et al. , 2004 ) problem which has been studied extensively in Natural Language Understanding .</sentence>
				<definiendum id="0">Person name disambiguation</definiendum>
			</definition>
			<definition id="1">
				<sentence>A snippet is a brief text extracted from a document around the query term .</sentence>
				<definiendum id="0">snippet</definiendum>
			</definition>
			<definition id="2">
				<sentence>We define the similarity sim ( T ( A ) , T ( B ) ) , between two term-entity models T ( A ) = { a1 , ... , an } and T ( B ) = { b1 , ... , bm } of documents A and B as follows , sim ( T ( A ) , T ( B ) ) = 1n nsummationdisplay i=1 max1≤j≤m|ai|·|bj| .</sentence>
				<definiendum id="0">similarity sim ( T</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">between two term-entity models T ( A ) = { a1 , ... , an } and T ( B ) = { b1 , ... , bm } of documents A and B as follows</definiens>
			</definition>
			<definition id="3">
				<sentence>Then , GAAC in each iteration executes the merger that gives rise to the cluster Γ with the largest average correlation C ( Γ ) where , C ( Γ ) = 12 1|Γ| ( |Γ|−1 ) X u∈Γ X v∈Γ sim ( T ( u ) , T ( v ) ) ( 2 ) Here , |Γ| denotes the number of documents in the merged cluster Γ ; u and v are two documents in Γ and sim ( T ( u ) , T ( v ) ) is given by equation 1 .</sentence>
				<definiendum id="0">GAAC</definiendum>
				<definiens id="0">the number of documents in the merged cluster Γ ; u and v are two documents in Γ and sim ( T ( u ) , T ( v ) ) is given by equation 1</definiens>
			</definition>
			<definition id="4">
				<sentence>We define the disambiguation accuracy as the sum of diagonal elements divided by the sum of all elements in the matrix .</sentence>
				<definiendum id="0">disambiguation accuracy</definiendum>
				<definiens id="0">the sum of diagonal elements divided by the sum of all elements in the matrix</definiens>
			</definition>
			<definition id="5">
				<sentence>X axis represents the similarity value .</sentence>
				<definiendum id="0">X axis</definiendum>
				<definiens id="0">represents the similarity value</definiens>
			</definition>
</paper>

		<paper id="2805">
			<definition id="0">
				<sentence>ZeroR achieves no more than 73 % , and is the only algorithm that actually performs worse than our baseline .</sentence>
				<definiendum id="0">ZeroR</definiendum>
			</definition>
</paper>

		<paper id="3707">
			<definition id="0">
				<sentence>MedSLT is a unidirectional medical speech translation system intended for use in doctor-patient diagnosis dialogues , which provides coverage of several different language pairs and subdomains .</sentence>
				<definiendum id="0">MedSLT</definiendum>
				<definiens id="0">a unidirectional medical speech translation system intended for use in doctor-patient diagnosis dialogues , which provides coverage of several different language pairs and subdomains</definiens>
			</definition>
			<definition id="1">
				<sentence>Vocabulary ranges from about 350 to 1000 surface words , depending on the language and subdomain .</sentence>
				<definiendum id="0">Vocabulary</definiendum>
				<definiens id="0">ranges from about 350 to 1000 surface words , depending on the language and subdomain</definiens>
			</definition>
			<definition id="2">
				<sentence>MedSLT ( MedSLT , 2005 ; Bouillon et al. , 2005 ) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues , which covers several different language pairs and subdomains .</sentence>
				<definiendum id="0">MedSLT</definiendum>
				<definiens id="0">a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues , which covers several different language pairs and subdomains</definiens>
			</definition>
			<definition id="3">
				<sentence>MedSLT also includes an intelligent help module , which adds robustness to the system and guides the user towards the supported coverage .</sentence>
				<definiendum id="0">intelligent help module</definiendum>
				<definiens id="0">adds robustness to the system and guides the user towards the supported coverage</definiens>
			</definition>
			<definition id="4">
				<sentence>The help module uses a backup recogniser , equipped with a statistical language model , and matches the results from this second recogniser against a corpus of utterances which are within system coverage and translate correctly .</sentence>
				<definiendum id="0">help module</definiendum>
				<definiens id="0">uses a backup recogniser , equipped with a statistical language model , and matches the results from this second recogniser against a corpus of utterances which are within system coverage and translate correctly</definiens>
			</definition>
			<definition id="5">
				<sentence>The interlingua representation is [ [ utterance_type , ynq ] , [ pronoun , you ] , [ state , have_symptom ] , [ symptom , pain ] , [ tense , present ] , [ prep , in_time ] , [ time , night ] ] Applying Interlingua → Spanish rules , the result is [ [ utterance_type , ynq ] , [ pronoun , usted ] , [ state , tener ] , [ symptom , dolor ] , [ tense , present ] , [ prep , por_temporal ] , failed : [ time , night ] ] where the tag failed indicates that the element [ time , night ] could not be processed .</sentence>
				<definiendum id="0">interlingua representation</definiendum>
				<definiens id="0">the element [ time , night ] could not be processed</definiens>
			</definition>
</paper>

		<paper id="1108">
			<definition id="0">
				<sentence>When the edit distance is divided by the length of the longer string , Inkpen et al. call it normalized edit distance ( NED ) .</sentence>
				<definiendum id="0">NED</definiendum>
				<definiens id="0">divided by the length of the longer string</definiens>
			</definition>
			<definition id="1">
				<sentence>The Norwegian data comes from a database comprising more than 50 dialect sites , compiled by Jørn Almberg and Kristian Skarbø of the Department of Linguistics of the University of Trond3We have no proof that normalization by alignment length always allows this simple relation to similarity , but we have examined a large number of calculations in which this always seems to hold .</sentence>
				<definiendum id="0">Norwegian data</definiendum>
				<definiens id="0">comes from a database comprising more than 50 dialect sites , compiled by Jørn Almberg and Kristian Skarbø of the Department of Linguistics of the University of Trond3We have no proof that normalization by alignment length</definiens>
			</definition>
			<definition id="2">
				<sentence>The Norwegian text consists of 58 different words , some of which occur more than once , in which case we seek a least expensive pairing of the different elements ( Nerbonne and Kleiweg , 2003 , p. 349 ) .</sentence>
				<definiendum id="0">Norwegian text</definiendum>
				<definiens id="0">consists of 58 different words , some of which occur more than once , in which case we seek a least expensive pairing of the different elements ( Nerbonne and Kleiweg , 2003 , p. 349 )</definiens>
			</definition>
</paper>

		<paper id="2715">
			<definition id="0">
				<sentence>A second topic is the use of heterogeneous linguistic resources ( e.g. , XML annotated documents , taggers , lexical nets ) as a source for semiautomatic multi-dimensional markup to resolve typical linguistic issues , dealing with anaphora resolution as a case study.1 heterogeneous linguistic resources A large and diverse amount of linguistic resources ( audio and video recodings , textual recordings ) has been piled up during various projects all over the world .</sentence>
				<definiendum id="0">XML annotated documents</definiendum>
				<definiens id="0">a case study.1 heterogeneous linguistic resources A large and diverse amount of linguistic resources ( audio and video recodings , textual recordings ) has been piled up during various projects all over the world</definiens>
			</definition>
			<definition id="1">
				<sentence>A reasonable subset of these resources consists of machine-readable structured linguistic documents ( often XML annotated ) , dictionaries , grammars or ontologies .</sentence>
				<definiendum id="0">reasonable subset of these resources</definiendum>
			</definition>
			<definition id="2">
				<sentence>A Python script converts the different annotation layers ( XML Documents ) to the above mentioned Prolog representation which serves as input for the unification process .</sentence>
				<definiendum id="0">Python script</definiendum>
				<definiens id="0">converts the different annotation layers ( XML Documents</definiens>
			</definition>
			<definition id="3">
				<sentence>Base for the resolution of anaphoric relations ( both pronominal anaphora and definite description anaphora ) is a small test corpus containing German newspaper articles and scientific articles in German and English .</sentence>
				<definiendum id="0">Base</definiendum>
				<definiens id="0">a small test corpus containing German newspaper articles and scientific articles in German and English</definiens>
			</definition>
</paper>

		<paper id="3803">
			<definition id="0">
				<sentence>Novelty detection is the task of identifying novel information given a set of already accumulated background information .</sentence>
				<definiendum id="0">Novelty detection</definiendum>
				<definiens id="0">the task of identifying novel information given a set of already accumulated background information</definiens>
			</definition>
			<definition id="1">
				<sentence>Novelty was defined as “providing new information that has not been found in any previously picked sentences” .</sentence>
				<definiendum id="0">Novelty</definiendum>
				<definiens id="0">“providing new information that has not been found in any previously picked sentences”</definiens>
			</definition>
			<definition id="2">
				<sentence>This combination of distance and a cooccurrence measure such as PMI is reminiscent of decaying language models , as described for IR , for example , in Gao et al. ( 2002 ) 4 .</sentence>
				<definiendum id="0">IR</definiendum>
				<definiens id="0">reminiscent of decaying language models</definiens>
			</definition>
			<definition id="3">
				<sentence>• G ( S ) : the graph of the sentence that is currently being evaluated .</sentence>
				<definiendum id="0">G ( S )</definiendum>
				<definiens id="0">the graph of the sentence that is currently being evaluated</definiens>
			</definition>
			<definition id="4">
				<sentence>TextRank is designed to work well in text graph representations : it can take edge weights into account and it works on undirected graphs .</sentence>
				<definiendum id="0">TextRank</definiendum>
				<definiens id="0">designed to work well in text graph representations : it can take edge weights into account and it works on undirected graphs</definiens>
			</definition>
			<definition id="5">
				<sentence>where TR ( V i ) is the TextRank score for vertex i , NB ( V i ) is the set of neighbors of V i , i.e. the set of nodes connected to V i by a single edge , wt xy is the weight of the edge between vertex x and vertex y , and d is a constant “dampening factor” , set at 6 .</sentence>
				<definiendum id="0">TR ( V i )</definiendum>
				<definiendum id="1">wt xy</definiendum>
				<definiens id="0">the set of neighbors of V i , i.e. the set of nodes connected to V i by a single edge</definiens>
				<definiens id="1">the weight of the edge between vertex x and vertex y</definiens>
			</definition>
</paper>

		<paper id="2201">
			<definition id="0">
				<sentence>Problem : Given the classes cq and ca , the sets of instances Iq and Ia , a relation R and a set of R-related instance-pairs TR , learn effective surface text patterns that express the relation R. Say , for example , we consider the classes ‘author’and‘booktitle’andtherelation‘haswritten’ .</sentence>
				<definiendum id="0">Problem</definiendum>
				<definiens id="0">a relation R and a set of R-related instance-pairs TR , learn effective surface text patterns that express the relation R. Say</definiens>
			</definition>
			<definition id="1">
				<sentence>KnowItAll is a hybrid named-entity extraction system ( Etzioni et al. , 2005 ) that £nds lists of instances of some class from the web using a search engine .</sentence>
				<definiendum id="0">KnowItAll</definiendum>
			</definition>
			<definition id="2">
				<sentence>P ( s , x ) = FI ( s , x ) FO ( s , x ) and FI ( s , x ) = the number of Google excerpts after querying s in combination with x containing instances of ca .</sentence>
				<definiendum id="0">FI (</definiendum>
				<definiens id="0">s , x ) = the number of Google excerpts after querying s in combination with x containing instances of ca</definiens>
			</definition>
			<definition id="3">
				<sentence>where h ( p , cq , t ) is the number of Google hits for query with pattern p combined with term t and the plural form of the class name cq .</sentence>
				<definiendum id="0">h</definiendum>
				<definiens id="0">the number of Google hits for query with pattern p combined with term t and the plural form of the class name cq</definiens>
			</definition>
			<definition id="4">
				<sentence>pattern freq prec spr ( countries ) like 645 0.66 134 ( countries ) such as 537 0.54 126 is a small ( country ) 142 0.69 110 ( country ) code for 342 0.36 84 ( country ) map of 345 0.34 78 ( countries ) including 430 0.21 93 is the only ( country ) 138 0.55 102 is a ( country ) 339 0.22 99 ( country ) ¤ag of 251 0.63 46 and other ( countries ) 279 0.34 72 and neighboring ( countries ) 164 0.43 92 ( country ) name republic of 83 0.93 76 ( country ) book of 59 0.77 118 is a poor ( country ) 63 0.73 106 is the £rst ( country ) 53 0.70 112 ( countries ) except 146 0.37 76 ( country ) code for calling 157 0.95 26 is an independent ( country ) 62 0.55 114 and surrounding ( countries ) 84 0.40 107 is one of the poorest ( countries ) 61 0.75 78 and several other ( countries ) 65 0.59 90 among other ( countries ) 84 0.38 97 is a sovereign ( country ) 48 0.69 89 or any other ( countries ) 87 0.58 58 ( countries ) namely 58 0.44 109 Table 2 : Learned hyponym patterns and their scores .</sentence>
				<definiendum id="0">pattern freq prec spr ( countries</definiendum>
				<definiens id="0">a ( country ) 339 0.22 99 ( country ) ¤ag of 251 0.63 46 and other ( countries ) 279 0.34 72 and neighboring ( countries ) 164 0.43 92 ( country ) name republic of 83 0.93 76 ( country ) book of 59 0.77 118 is a poor ( country ) 63 0.73 106 is the £rst ( country ) 53 0.70 112 ( countries ) except 146 0.37 76 ( country ) code for calling 157 0.95 26 is an independent ( country ) 62 0.55 114 and surrounding ( countries ) 84 0.40 107 is one of the poorest ( countries</definiens>
				<definiens id="1">a sovereign ( country ) 48 0.69 89 or any other ( countries ) 87 0.58 58 ( countries</definiens>
			</definition>
</paper>

		<paper id="0105">
			<definition id="0">
				<sentence>The Sentence Degeneration model , which is one model of the Hierarchical Network of Concepts theory ( HNC ) , focuses on representing the subordinate clause in a sentence .</sentence>
				<definiendum id="0">Sentence Degeneration model</definiendum>
				<definiens id="0">one model of the Hierarchical Network of Concepts theory ( HNC ) , focuses on representing the subordinate clause in a sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The objective of HNC is to establish natural language representation patterns based on the association veins of concepts , which can simulate the language perception process of the human brain and can be applied to computational Natural Language Understanding .</sentence>
				<definiendum id="0">objective of HNC</definiendum>
				<definiens id="0">to establish natural language representation patterns based on the association veins of concepts , which can simulate the language perception process of the human brain and can be applied to computational Natural Language Understanding</definiens>
			</definition>
			<definition id="2">
				<sentence>Sentence Degeneration ( SD ) represents the semantic patterns of the subordinate clause in a sentence .</sentence>
				<definiendum id="0">Sentence Degeneration</definiendum>
				<definiendum id="1">SD )</definiendum>
				<definiens id="0">represents the semantic patterns of the subordinate clause in a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , 中国加入世界贸易组 织 ( China joined the WTO ) is a complete sentence .</sentence>
				<definiendum id="0">WTO )</definiendum>
				<definiens id="0">a complete sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>Key-element SD involves an NP which semantically is an attributive clause .</sentence>
				<definiendum id="0">Key-element SD</definiendum>
				<definiens id="0">involves an NP which semantically is an attributive clause</definiens>
			</definition>
			<definition id="5">
				<sentence>An NP allocated ambiguity garden-path is a sentence in which one NP can be both the object of v1 and the subject of v2 .</sentence>
				<definiendum id="0">NP allocated ambiguity garden-path</definiendum>
				<definiens id="0">a sentence in which one NP can be both the object of v1 and the subject of v2</definiens>
			</definition>
			<definition id="6">
				<sentence>For example , 36 in sentence ( 12 ) 伊拉克起因于能源危机 ( Iraq is due to the crisis of energy ) is not a clause , so sentence ( 12 ) is a non garden-path sentence .</sentence>
				<definiendum id="0">Iraq</definiendum>
				<definiens id="0">a non garden-path sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>Second , one of v1 and v2 is the main verb of the sentence , and NP2 has to be in NP1+v1+NP2 or NP2+v2+NP3 , and can not be shared .</sentence>
				<definiendum id="0">v2</definiendum>
				<definiens id="0">the main verb of the sentence , and NP2 has to be in NP1+v1+NP2 or NP2+v2+NP3</definiens>
			</definition>
			<definition id="8">
				<sentence>The difference between a serial verb interpretation and an NP allocated ambiguity interpretation is the semantic information of the two verbs .</sentence>
				<definiendum id="0">NP allocated ambiguity interpretation</definiendum>
			</definition>
			<definition id="9">
				<sentence>Suppose VS ( pro ) is the set of all verbs whose subject can be a prototype SD , VO ( pro ) is the set of all verbs whose object can be a prototype SD .</sentence>
				<definiendum id="0">VS ( pro )</definiendum>
				<definiens id="0">the set of all verbs whose subject can be a prototype SD</definiens>
				<definiens id="1">the set of all verbs whose object can be a prototype SD</definiens>
			</definition>
			<definition id="10">
				<sentence>In the garden-path caused by SD ambiguity , v1 is regarded as the main verb initially , however , in the end , v2 is the real main verb .</sentence>
				<definiendum id="0">v2</definiendum>
				<definiens id="0">the real main verb</definiens>
			</definition>
			<definition id="11">
				<sentence>Here prior to means that if v1 is one of VO ( pro ) and v2 is one of VS ( pro ) , the main verb is v1 in most cases .</sentence>
				<definiendum id="0">v2</definiendum>
				<definiens id="0">one of VO ( pro ) and</definiens>
			</definition>
			<definition id="12">
				<sentence>Main verb is NP2 is Sentence semantic structure Example Comment v1 The subject of v2 NP1+v1+ ( NP2+v2 +NP3 ) Sentence ( 8 ) , ( 16 ) NP2+v2+NP3 is a prototype SD , this SD is the object of v1 .</sentence>
				<definiendum id="0">NP2</definiendum>
				<definiendum id="1">SD</definiendum>
				<definiens id="0">the object of v1</definiens>
			</definition>
			<definition id="13">
				<sentence>v2 The object of v1 ( NP1+v1+NP2 ) +v2 +NP3 Sentence ( 12 ) NP1+v1+NP2 is a prototype SD , this SD is the subject of v2 .</sentence>
				<definiendum id="0">SD</definiendum>
				<definiens id="0">the subject of v2</definiens>
			</definition>
			<definition id="14">
				<sentence>Where , P is precision ratio , R is recall ratio , and F is F-measure ( Fβ=1 , which is defined as 2PR/ ( P+R ) ) .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">precision ratio , R is recall ratio , and</definiens>
			</definition>
</paper>

		<paper id="1310">
</paper>

		<paper id="1805">
			<definition id="0">
				<sentence>Intersective adjectives ( e.g. , red ) licence the following inference inference patterns : A + N j= A A + N j= N For instance , if X is a red car then X is a car and X is red Subsective adjectives ( e.g. , big ) licence the following inference pattern : A + N j= N For instance , if X is a big mouse , then X is a mouse but it is not necessarily true X is big Privative adjectives licence the inference pattern : A + N j= : N For instance , if X is a fake gun then X is not a gun Plain non-subsective adjectives ( e.g. , alledged ) do not licence any inference For instance , if X is an alleged murderer then it is unknown whether X is a murderer or not From the lexical semantics literature , we take one additional classification criterion namely antonymy .</sentence>
				<definiendum id="0">Intersective adjectives</definiendum>
				<definiendum id="1">X</definiendum>
				<definiendum id="2">X</definiendum>
				<definiendum id="3">X</definiendum>
				<definiens id="0">a car</definiens>
				<definiens id="1">big Privative adjectives licence the inference pattern : A + N j=</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , the axioms describing antonymy are obtained by extracting from WordNet the antonyms of a particular adjective and then by considering the direction of the entailment relevant for the class the adjective belongs to : asleep wake vs. polite &lt; rude Morpho-derivational information are derived from WordNet by extracting the derivationally related forms for the given adjective and then iterating the extraction on nouns and verbs in order to obtain information about their antonyms and hyponyms. For scalar adjective like tall , WordNet contains also a relation is a value of which offers a pointer to the noun concept the adjective is a value of. Moreover , WordNet links the noun concept to a list of attributes which describe the scalar property it represents. For example , the adjective tall is a value of fstature , heightg and attributes offstature , heightg are tall and short. Based on some basic syntactic patterns , we then show that these axioms predict the observed textual entailment patterns for that class. Before we illustrate this approach by means of some example , we first show how we capture logical entailment between NL semantic representations in a description logic setting. entailment between NL sentences As argued in ( Gardent and Jacquey , 2003 ) , description logic ( DL ) is an intuitive framework within which to perform lexical reasoning : it is efficient ( basic versions of description logics are decidable ) , it is tailored to reason about complex taxonomies ( taxonomies of descriptions ) and it is equipped with powerful , freely available automated provers ( such as RACER , ( Volker Haarslev , 2001 ) ) . For these reasons , we are here exploring a DL encoding of the entailment recognition task for the set of examples we are considering.The particular language we assume has the following syntax. C ; D ! Aj &gt; j ?</sentence>
				<definiendum id="0">adjective</definiendum>
				<definiendum id="1">adjective tall</definiendum>
				<definiendum id="2">DL )</definiendum>
				<definiens id="0">a value of fstature , heightg and attributes offstature , heightg are tall and short. Based on some basic syntactic patterns</definiens>
				<definiens id="1">an intuitive framework within which to perform lexical reasoning : it is efficient ( basic versions of description logics</definiens>
			</definition>
			<definition id="2">
				<sentence>( ui=1 ; nEventi u1 &lt; k &lt; j ; j &lt; k &lt; m 9Rk.Typek ) so that the formula : Event1u Event2 u : : : u Eventn u9R1.Type1 u9R2.Type2 ... u9Rn.Typen corresponds to the following n Rotations each of which describe the same situation from the point of view of a particular type Event Type1 Type2 ... n. Typen u9R 1n . ( Event u9R1.Type1 ... u9Rn 1.Typen 1 ) Typen So for example , the sentence Mary knows that John is the inventor of the radio will be represented as a predicate logic formula 9x1mary ( x1 ) ^9x2john ( x2 ) ^9x3radio ( x3 ) ^9e1know ( e1 ) ^ 9agent ( e1 ; x1 ) ^9topic ( e1 ; e2 ) ^9e2invent ( e2 ) ^agent ( e2 ; x2 ) ^ patient ( e2 ; x3 ) the denotation of this PL formula corresponds to the set of individuals fx1 ; x2 ; x3g [ fe1 ; e2g. The corresponding DL representation will be the underspecified representation know u9 agent.mary u9 topic. ( invent u9agent.john u9 patient.radio ) the denotation of which corresponds to the set fe1g and all its rotations which permit to access the other sets of individuals asserted in the sentence. Thus for example , the set fx1g which describes the individual Mary can be accessed through the following rotation : Rotation1 : mary u9 agent 1. ( know u9 topic. ( invent u9agent.john u9 patient.radio ) ) Finally , we say that an arbitrary formula/representation 1 implies the formula 2 iff it is possible to find a rotation Rotationi of 1 the denotation of which describes a subset of the denotation of 2 : Definition 1 j= 2 iff 9i : Rotationi ( 1 ) v 2 ( 1 ) 23 KRAQ06 We now illustrate our approach by looking at two classes in more detail namely , class 1 and class 8. Syntactically , Class 1 contains adjectives like adrift , afloat , aground which can only be used predicatively , are non gradable and can not be modified by very. Semantically , they behave like intersective adjectives which enter in multiple opposition relations with other adjectives. They are furthermore morphologically derived from verbs and can be nominalized. To reflect these semantic properties we use the following axioms. Model theoretic semantics. Adjectives of class 1 are intersective adjective. They will thus licence the correponding inference patterns namely : A + N j= A ( 2 ) A + N j= N ( 3 ) Lexical semantics. Adjectives of class 1 enter in multiple opposition relations. Hence For instance : afloat j= : aground ^ : afloat 6j= aground aground j= : afloat ^ : aground 6j= afloat sunken j= : afloat ^ : afloat 6j= sunken afloat j= : sunken ^ : sunken 6j= afloat Morpho-derivational semantics. Adjectives in Class 1 can be related to both nouns and verbs. Thus , for example the adjective afloat in WordNet is related to the noun floating which is related to the verb float , by assuming that the semantics assigned to the verb float is float ( e ) , theme ( e , a ) , the adjective afloat is assigned the following semantics : afloat 9 Theme 1.float This is encoded in the following axiom schemas : MDR 1. Adj1 &lt; : Adj2 If Adj1 = Anto ( Adj2 ) e.g. , afloat &lt; : sunken MDR 2. Adj1 9 Theme 1.V1 If Adj1 is related to V1 e.g. , afloat 9 Theme 1.float MDR 3. V1 &lt; : V2 If V1 = Anto ( V2 ) e.g. , float &lt; : sink MDR 4. N1 V1 If Adj1 is related to an evt denoting N1 e.g. , floating float MDR 5. N1 &lt; : N2 If N1 is an antonym of N2 e.g. , floating &lt; : sinking MDR 6. N11 9 Theme 1.V1 If Adj1 is related to a noun N11 denoting the theme role of the verb V1 e.g. , floater 9 Theme 1.float We make the following assumptions about the syntax/semantic interface that is , about the semantic representations associated with given sentence patterns. SCR 1. NP toBe Adj ADJ u NP SCR 2. NP toBe clearly Adj ADJ u NP SCR 3. Ni [ +event ] of NP is clear V i u9theme : NP SCR 4. Nii [ -event ] is clear 9theme 1 : V i SCR 5. NP toBe V [ +ing ] . V u9Theme : NP Given the above axiom schemas and semantic constructions rules , the following inference patterns can be handled : Ex. This boat is afloat. j= This is a boat. Ex. This boat is afloat. j= This is afloat. Ex. The boat is afloat. 6j= This not a boat. Ex. The boat is afloat. j= The boat is not sunken. Ex. The boat is not afloat. 6j= The boat is sunken. Ex. The boat is afloat. j= The boat is the floater. Ex. The boat is afloat. j= The boat is floating. Ex. This boat is clearly afloat. j= The floating of the boat is clear. Ex. This boat is clearly afloat. j= The floating of the boat is clear ( or the boat is the floating object ) . 10. : ( ADJ1 + N ) j= : ( V1 u9theme.N ) 6j= : N Ex. This is not a floating boat. 6j= This is not a boat. 11. : ( ADJ1 + N ) 6j= : Adj1 Ex. This is not a floating boat. 6j= This is not afloat. 12. : ( ADJ1 + N ) 6j= : V1 Ex. This is not a floating boat. 6j= This is not floating. 13. : ( ADJ1 + N ) 6j= : N1 Ex. This is not a floating boat. 6j= This is not a floating. 14. : ( ADJ1 + N ) 6j= :9 theme 1.V1 Ex. This is not a floating boat. 6j= This is not the floater. 15. : ( ADJ1 + N ) 6j= :9 theme.N Ex. This is not a floating boat. 6j= This is not a floating. 24 KRAQ06 In the inference patterns 10 to 15 , the negation of the adjective-noun compound : ( ADJ1 + N ) is syntactically blocked , as the adjectives in this class are used predicative only , however the equivalent representation V1 u9theme.N can be used to motivate the inferences. The following show in more detail how the first three of the above ( non ) entailments are recognised. ( 4 ) a. The boat is afloat. b. j= The boat is floating. 4a Boat u Afloat ( by SCR 1 ) A 4b Float u9Theme : Boat ( by SCR 5 ) B Afloat 9Theme 1 : Float ( by MDR 2 ) C 1 Boat u9Theme 1 : Float ( from A and C ) D D j= B ( By Defn 1 ) E ( 5 ) a. The boat is afloat. b. j= The boat is the floater. 5a Boat u Afloat ( by SCR 1 ) A 5b Boat u9Theme 1 : float ( by SCR 4 ) B Afloat 9Theme 1 : Float ( by MDR 2 ) C A j= B ( from B und C ) D ( 6 ) a. The boat is afloat. b. j= The boat is not sinking. 6a Boat u Afloat ( by SCR 1 ) A 6b : sink u9Theme : boat ( by SCR 5 ) B Afloat 9Theme 1 : Float ( by MDR 2 ) C Boat u9Theme 1 : Float ( from A and C ) D float u9Theme : boat ( By Defn 1 ) E E j= B ( by MDR 1 ) F Class 8 contains adjectives like big , fast , tall , deep which can be used attributively and predicatively , are gradable , can be modified by very. Semantically , they are classified as subsective adjectives and their antonyms are contraries. They are morphologically related to nouns which describe the particular property denoted by the adjectives and to nouns of which they are attributes. Model theoretic semantics. Adjectives of class 8 are subsective adjective. They will thus licence the correponding inference patterns namely : A + N 6j= A ( 4 ) A + N j= N ( 5 ) Lexical semantics. The Adjectives of class 8 enter in contrary opposition relations. Hence , the following axioms schemas will be licensed : Ai j= : Anto ( Ai ) and : Ai 6j= Anto ( Ai ) ( 6 ) For instance : long j= : small ^ : long 6j= small deep j= : shallow ^ : deep 6j= shallow Morpho-derivational semantics. Adjectives in Class 8 can be related to nouns but not to verbs. Moreover , such adjectives are mapped in WordNet to noun concepts through two different links : derivationallyrelated to and is a value of. For example , the adjective tall in WordNet is derivationally related to the noun tallness and is a value of the concept noun height. The adjectives in this class describe gradable properties so that their semantics corresponds to : has-property ( Related Noun u9has-measure.Top ) in which the role has-measure account for the value of the scalar property described by the adjective , which remain underspecified ( Top ) if the adjective is used without a reference to the value of measure. When the value of the measure is specified , for example by combining the adjective with a noun , as for example in This is a tall man , then the noun is assigned as a value of the measure role : man u9has-property. ( tallness u9has-measure.man ) which translate This is tall as a man. This is encoded in the following axiom schemas : MDR 1. Adj1 &lt; : Adj2 If Adj1 = Anto ( Adj2 ) Ex. tall &lt; : short MDR 2. Adj1 &lt; 9 has property. ( N1 u9has measure.Top ) If Adj1 is related to a noun N1 denoting the property described by Adj1 Ex. tall &lt; 9 has property. ( tallness u9has measure.Top ) MDR 3. N1 &lt; : N2 If N1=Anto ( N2 ) Ex. tallness &lt; : shortness MDR 4. N1 N’ u9has value.Adj1 If Adj1 is an attribute of the noun N’ Ex. tallness height u9has value.tall MDR 5. N2 N’ u9has value.Adj2 If Adj2 is an attribute of the noun N’ Ex. shortness height u9has value.short MDR 6. N1 &lt; N’ If N1 is an hyponym of N’ Ex. tallness &lt; height 25 KRAQ06 MDR 7. N2 &lt; N’ If N2 is an hyponym of N’ Ex. shortness &lt; height MDR 8. Adj11 &lt; Adj1 If Adj1 is a scalar attribute with value less then Adj11 ( hyponymy is not defined for adjectives ) Ex. giant &lt; tall For the moment , we don’t account for the semantics of comparatives forms of adjectives but we will do that in the feature , by also introducing a representation for scales as described in ( Kennedy , 2005 ) . We make the following assumptions about the semantic representations associated with basic sentence patterns. SCR 1. NP toBe Adj NP u9 has property. ( N1 u9has measure.NP ) SCR 2. That toBe Det Adj NP NP u9 has property. ( N1 u9has measure.NP ) SCR 3. NP toBe clearly Adj NP u9 has property. ( N1 u9has measure.NP ) SCR 4. N1 of NP is clear NP u9 has property. ( N1 u9has measure.NP ) SCR 5. The Adj N’ of NP NP u9 has property. ( N’ u9 has value.Adj u9has measure.NP ) SCR 6. NP1 toBe Adj as a N NP1 u N u9has property. ( N’ u9 value.Adj u9 has measure.N ) SCR 7. NP1 toBe NP2 [ +measure ] Adj NP1 u9has property. ( N’ u9 value.Adj u9 has measure.NP2 ) SCR 8. NP1 toBe NP2 [ +measure ] Adj N NP1 u N u9has property. ( N’ u9has value.Adj u9 has measure.NP2 ) Given the above axioms , the following examples can be handled : ( 7 ) ( a ) John is a 1.50 meter tall man. j= ( b ) John is 1.50 meter tall. 7a John u Man u9has property. ( height A uhas value.tall uhas measure ( 1.50 meter ) ) ( by SCR 8 ) 7b j= John u9has property. ( height uhas value.tall B uhas measure ( 1.50 meter ) ) ( by SCR 7 and from A ) A j= B C ( 8 ) ( a ) John is a 1.50 meter tall man. 6j= ( b ) John is a tall man. 8a John u Man u9has property. ( height A uhas value.tall uhas measure ( 1.50 meter ) ) ( by SCR 8 ) 8b j= John u Man u9has property. ( height u B has value.tall uhas measure ( man ) ) ( by SCR1 and from A ) A 6j= B C For each of the 15 classes , we have specified a set of axioms schemas , some basic semantic construction rules and a set of inference patterns which could be deduced to follow from both of these. The axioms schemas were implemented in Description Logic using RACER and for each inference pattern identified , the corresponding Description Logic query was checked to verify that the proposed axioms and semantic construction rules did indeed correctly predict the deduced inference patterns. The main contribution of this work is a detailed analysis of the interactions between derivational morphology , lexical and compositional semantics and of their impact on the entailment patterns licensed by sentences containing adjective or their related nouns/verbs. To turn this analysis into a computational system , its components need to be integrated into a semantic analyser and the behaviour of that analyser tested against a collection of data. We are currently working on developing such an analyser within a symbolic grammar framework. We have also started to develop an evaluation test suite geared towards entailment recognition between sentence pairs containing adjectives. At the moment , the test suite contains about 1 000 inference pairs. Each item in the TestSuite ( see fig. 2 ) is annotated with a judgement about the truth of the entailment between the pair of sentences , with the type of inference involved and with the specification of adjective involved. Moreover , each adjective is annotated with the WordNet sense corresponding to the given class. The idea behind this test suite is similar to that underlying the creation of the TSNLP ( Test suite for natural language processing ) ( see ( Oepen and Netter , 1995 ) ) or the Eurotra testsuites ( see ( Arnold and des Tombe , 1987 ) ) namely , to provide a benchmark against which to evaluate and compare existing semantic analyzers. Thus this 26 KRAQ06 &lt; pair id= '' 1 '' value= '' TRUE '' class= '' [ CLASS1 ] '' inference= '' Adj/Verb '' &gt; &lt; t &gt; The boat is &lt; sn n= '' 1 '' &gt; afloat &lt; /sn &gt; .</sentence>
				<definiendum id="0">x1 ) ^9topic</definiendum>
				<definiens id="0">they behave like intersective adjectives which enter in multiple opposition relations with other adjectives. They are furthermore morphologically derived from verbs</definiens>
				<definiens id="1">subsective adjectives and their antonyms are contraries. They are morphologically related to nouns which describe the particular property denoted by the adjectives and to nouns of which they are attributes. Model theoretic semantics. Adjectives of class</definiens>
				<definiens id="2">shallow ^ : deep 6j= shallow Morpho-derivational semantics. Adjectives in Class 8 can be related to nouns but not to verbs. Moreover , such adjectives are mapped in WordNet to noun concepts through two different links : derivationallyrelated to</definiens>
				<definiens id="3">a detailed analysis of the interactions between derivational morphology , lexical and compositional semantics and of their impact on the entailment patterns licensed by sentences containing adjective or their related nouns/verbs. To turn this analysis into a computational system , its components need to be integrated into a semantic analyser and the behaviour of that analyser tested against a collection of data. We are currently working on developing such an analyser within a symbolic grammar framework. We have also started to develop an evaluation test suite geared towards entailment recognition between sentence pairs containing adjectives. At the moment , the test suite contains about 1 000 inference pairs. Each item in the TestSuite</definiens>
			</definition>
			<definition id="3">
				<sentence>Beside implementing and evaluating the analysis of adjectives presented in this paper , we are also working on refining this analysis by combining it with a detailed analysis of noun semantics so as to handle ( non ) entailments such as : ( 9 ) Lyon is the gastronomical capital of France 6j= Lyon is the capital of France</sentence>
				<definiendum id="0">Lyon</definiendum>
				<definiendum id="1">Lyon</definiendum>
			</definition>
</paper>

		<paper id="1415">
			<definition id="0">
				<sentence>The Pearson’s correlation is 0:694 meaning that the number of inhabitants increases over time ( between 1999 and 2005 ) .</sentence>
				<definiendum id="0">Pearson’s correlation</definiendum>
			</definition>
			<definition id="1">
				<sentence>A graph G of numerical values is defined by N the set of nodes ( set of values ) and Arc the set of arcs .</sentence>
				<definiendum id="0">graph G</definiendum>
				<definiendum id="1">Arc</definiendum>
				<definiens id="0">the set of arcs</definiens>
			</definition>
			<definition id="2">
				<sentence>The cost c ( x ; y ) of arc ( x ; y ) is : jx yj y ( w ( x ) + nX i=1 w ( xi ) ) + nX i=1 c ( xi ; x ) : with ( x1 ; : : : ; xn ; x ) a path from x1 to x. Finally , we define a fusion operator which selects the value which is used for the direct answer .</sentence>
				<definiendum id="0">cost c</definiendum>
				<definiens id="0">a fusion operator which selects the value which is used for the direct answer</definiens>
			</definition>
			<definition id="3">
				<sentence>Generated answers are composed of three parts : ( 1 ) a direct answer : the content determination process ”chooses” a direct answer among candidates , dealing with data inconsistencies and approximations , ( 2 ) an explanation : the content determination process allows to identify , from data sets , the possible value variations and to infer their variation criteria ( time , place or restrictions on the question focus ) , and ( 3 ) a possible Web page extract .</sentence>
				<definiendum id="0">Generated answers</definiendum>
				<definiens id="0">time , place or restrictions on the question focus</definiens>
			</definition>
</paper>

		<paper id="3711">
			<definition id="0">
				<sentence>The Arabic language model ( LM ) is an interpolated model consisting of a trigram LM , a class-based LM and a morphologically processed LM , all trained from a corpus of a few hundred thousand words .</sentence>
				<definiendum id="0">Arabic language model ( LM )</definiendum>
				<definiens id="0">an interpolated model consisting of a trigram LM , a class-based LM and a morphologically processed LM , all trained from a corpus of a few hundred thousand words</definiens>
			</definition>
			<definition id="1">
				<sentence>Statistical machine translation methods translate a sentence W in the source language into a sentence A in the target language by using a statistical model that estimates the probability of A given W , i.e. ( ) WAp .</sentence>
				<definiendum id="0">Statistical machine translation methods</definiendum>
				<definiens id="0">translate a sentence W in the source language into a sentence A in the target language by using a statistical model that estimates the probability of A given W</definiens>
			</definition>
			<definition id="2">
				<sentence>During the offline training , we separate the entire translation lattice H into two pieces : the language model L and the translation model M : ( ) ( ) ( ) WTPDetMinMinM = where is the composition operator , Min denotes the minimization operation , and Det denotes the determinization operation ; T is the phrase translation transducer , and W is the phrase-to-word transducer .</sentence>
				<definiendum id="0">Min</definiendum>
				<definiendum id="1">Det</definiendum>
				<definiendum id="2">W</definiendum>
				<definiens id="0">the language model L and the translation model M : ( ) ( ) ( ) WTPDetMinMinM = where is the composition operator ,</definiens>
				<definiens id="1">the minimization operation</definiens>
				<definiens id="2">the determinization operation ; T is the phrase translation transducer , and</definiens>
			</definition>
			<definition id="3">
				<sentence>We represent each state s in the search space using the following 7-tuple : Is , Ms , Ls , Mc , Lc , ha0 , prevs , where Is , Ms , and Ls record the current state in each input FSM ; Mc and Lc record the accumulated cost in L and M in the best path up to this point ; h a0 records the target word sequence labeling the best path up to this point ; and prevs records the best previous state .</sentence>
				<definiendum id="0">Ls record</definiendum>
				<definiens id="0">Is , Ms , Ls , Mc , Lc , ha0 , prevs , where Is , Ms , and</definiens>
			</definition>
</paper>

		<paper id="0903">
			<definition id="0">
				<sentence>The ARIMA process is further defined as a non-stationary extension of the stationary ARMA model .</sentence>
				<definiendum id="0">ARIMA process</definiendum>
				<definiens id="0">a non-stationary extension of the stationary ARMA model</definiens>
			</definition>
			<definition id="1">
				<sentence>The SARIMA extension adds seasonal AR and MA polynomials that can handle seasonally varying data in time series .</sentence>
				<definiendum id="0">SARIMA extension</definiendum>
				<definiens id="0">adds seasonal AR and MA polynomials that can handle seasonally varying data in time series</definiens>
			</definition>
</paper>

		<paper id="1510">
			<definition id="0">
				<sentence>Semantic computation consists of certain feature value identifications between mother and daughter nodes in the derivation tree .</sentence>
				<definiendum id="0">Semantic computation</definiendum>
				<definiens id="0">consists of certain feature value identifications between mother and daughter nodes in the derivation tree</definiens>
			</definition>
			<definition id="1">
				<sentence>In the liesttree , MINS appears in the feature structure of different nodes , with each MINS value determined in the following way : the value of MINS at the NP2 address is the label l1 of the verb ; the value of MINS at the NP1 address depends on what is attached at NP2 ( see variables 4 and 0 , which in this case will be identified with each other ) ; and the value of MINS at the top VP address depends on what is attached at NP1 ( 5 ) .</sentence>
				<definiendum id="0">MINS</definiendum>
				<definiens id="0">appears in the feature structure of different nodes , with each MINS value determined in the following way</definiens>
				<definiens id="1">the label l1 of the verb</definiens>
			</definition>
</paper>

		<paper id="1611">
			<definition id="0">
				<sentence>First , a significant correlation between an interaction parameter and the performance metric is a good indicator of the parameter’s relevance for PARADISE modeling .</sentence>
				<definiendum id="0">performance metric</definiendum>
				<definiens id="0">a good indicator of the parameter’s relevance for PARADISE modeling</definiens>
			</definition>
			<definition id="1">
				<sentence>ITSPOKE is a speech-enabled version of the text-based Why2-Atlas conceptual physics tutoring system ( VanLehn et al. , 2002 ) .</sentence>
				<definiendum id="0">ITSPOKE</definiendum>
			</definition>
			<definition id="2">
				<sentence>Please note that each student dialogue has a specific discourse structure based on the dialogue that dynamically emerges based on the correctness of her answers .</sentence>
				<definiendum id="0">Please note</definiendum>
			</definition>
			<definition id="3">
				<sentence>Bigram parameters exploit the discourse structure context .</sentence>
				<definiendum id="0">Bigram parameters</definiendum>
				<definiens id="0">exploit the discourse structure context</definiens>
			</definition>
			<definition id="4">
				<sentence>The Advance–Advance bigram covers situations where the student is covering tutoring material without major knowledge gaps .</sentence>
				<definiendum id="0">Advance–Advance bigram</definiendum>
				<definiens id="0">covers situations where the student is covering tutoring material without major knowledge gaps</definiens>
			</definition>
			<definition id="5">
				<sentence>Several information sources are being tapped to devise parameters classified by ( Möller , 2005a ) in several categories : dialogue and communication parameters ( e.g. dialogue duration , number of system/user turns ) , speech input parameters ( e.g. word error rate , recognition/concept accuracy ) and metacommunication parameters ( e.g. number of help request , cancel requests , corrections ) .</sentence>
				<definiendum id="0">Several information sources</definiendum>
				<definiens id="0">dialogue and communication parameters ( e.g. dialogue duration , number of system/user turns ) , speech input parameters ( e.g. word error rate , recognition/concept accuracy ) and metacommunication parameters ( e.g. number of help request , cancel requests , corrections )</definiens>
			</definition>
			<definition id="6">
				<sentence>The DATE annotation captures information on three dimensions : speech acts ( e.g. acknowledge , confirm ) , conversation domain ( e.g. conversationversus task-related ) and the task model ( e.g. subtasks like getting the date , time , origin , and destination ) .</sentence>
				<definiendum id="0">DATE annotation</definiendum>
				<definiendum id="1">destination</definiendum>
				<definiens id="0">captures information on three dimensions : speech acts</definiens>
			</definition>
</paper>

		<paper id="3606">
			<definition id="0">
				<sentence>Markov logic networks ( MLNs ) combine the probabilistic semantics of graphical models with the expressivity of first-order logic to model relational dependencies ( Richardson and Domingos , 2004 ) .</sentence>
				<definiendum id="0">Markov logic networks ( MLNs</definiendum>
				<definiens id="0">the probabilistic semantics of graphical models with the expressivity of first-order logic to model relational dependencies</definiens>
			</definition>
			<definition id="1">
				<sentence>Identity uncertainty ( also known as record linkage , deduplication , object identification , and co-reference resolution ) is the problem of determining whether a set of constants ( mentions ) refer to the same object ( entity ) .</sentence>
				<definiendum id="0">Identity uncertainty</definiendum>
				<definiendum id="1">co-reference resolution )</definiendum>
				<definiens id="0">record linkage , deduplication , object identification , and</definiens>
			</definition>
			<definition id="2">
				<sentence>Most relevant to this work are the recent relational models of identity uncertainty ( Milch et al. , 2005 ; McCallum and Wellner , 2003 ; Parag and Domingos , 2004 ) .</sentence>
				<definiendum id="0">McCallum</definiendum>
				<definiens id="0">the recent relational models of identity uncertainty ( Milch et al. , 2005 ;</definiens>
			</definition>
			<definition id="3">
				<sentence>In this paper , we present of identity uncertainty that incorporates the attractive properties of McCallum and Wellner ( 2003 ) and Milch et al. ( 2005 ) , resulting in a discriminative model to reason about objects .</sentence>
				<definiendum id="0">identity uncertainty</definiendum>
				<definiens id="0">incorporates the attractive properties of McCallum and Wellner ( 2003 ) and Milch et al. ( 2005 ) , resulting in a discriminative model to reason about objects</definiens>
			</definition>
			<definition id="4">
				<sentence>Given a set of constants C = { ci } , define ni ( x ) to be the number of true groundings of Fi realized in a setting 42 of the world given by atomic formulae x. A Markov logic network ( MLN ) ( Richardson and Domingos , 2004 ) defines a joint probability distribution over possible worlds x. In this paper , we will work with discriminative MLNs ( Singla and Domingos , 2005 ) , which define the conditional distribution over a set of query atoms y given a set of evidence atoms x. Using the normalizing constant Zx , the conditional distribution is given by P ( Y = y|X = x ) = 1Z x exp   |Fy|summationdisplay i=1 wini ( x , y )   ( 1 ) where Fy ⊆ F is the set ofclauses for which at least one grounding contains a query atom , and ni ( x , y ) is the number of true groundings of the ith clause containing evidence atom x and query atom y. Markov Networks The set of predicates and constants in Markov logic define the structure of a Markov network , called a ground Markov network .</sentence>
				<definiendum id="0">conditional distribution</definiendum>
				<definiens id="0">{ ci } , define ni ( x ) to be the number of true groundings of Fi realized in a setting 42 of the world given by atomic formulae x. A Markov logic network ( MLN )</definiens>
				<definiens id="1">y )   ( 1 ) where Fy ⊆ F is the set ofclauses for which at least one grounding contains a query atom , and ni ( x , y ) is the number of true groundings of the ith clause containing evidence atom x and query atom y. Markov Networks The set of predicates and constants in Markov logic define the structure of a Markov network , called a ground Markov network</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , the HaveSameAdvisor ( ai ... ai+k ) predicate in the previous section is an example of an aggregate predicate over k −i +1 constants .</sentence>
				<definiendum id="0">HaveSameAdvisor</definiendum>
				<definiens id="0">an example of an aggregate predicate over k −i +1 constants</definiens>
			</definition>
			<definition id="6">
				<sentence>In this paper , we provide algorithms to perform approximate inference and parameter estimation by incrementally instantiating these predicates 44 AreEqual ( a , b ) AreEqual ( a , c ) AreEqual ( b , c ) AreEqual ( a , b , c ) Figure 1 : An example of the network instantiated by an MLN with three constants and the aggregate predicate AreEqual , instantiated for all possible subsets with size ≥ 2 .</sentence>
				<definiendum id="0">AreEqual</definiendum>
				<definiens id="0">An example of the network instantiated by an MLN with three constants and the aggregate predicate AreEqual , instantiated for all possible subsets with size ≥ 2</definiens>
			</definition>
			<definition id="7">
				<sentence>Maximum a posteriori ( MAP ) inference seeks the solution to y∗ = argmax y P ( Y = y|X = x ) where y∗ is the setting of all the query predicates Fy ( e.g. AreEqual ) with the maximal conditional density .</sentence>
				<definiendum id="0">y∗</definiendum>
				<definiens id="0">the setting of all the query predicates Fy ( e.g. AreEqual ) with the maximal conditional density</definiens>
			</definition>
			<definition id="8">
				<sentence>Note that Pairs is a strong baseline that performs collective inference of citation matching decisions , but is restricted to use only IsEqual ( ci , cj ) predicates over pairs of citations .</sentence>
				<definiendum id="0">Pairs</definiendum>
				<definiens id="0">a strong baseline that performs collective inference of citation matching decisions , but is restricted to use only IsEqual ( ci , cj ) predicates over pairs of citations</definiens>
			</definition>
</paper>

		<paper id="1205">
			<definition id="0">
				<sentence>CPs are characterized by a predicate or host typically a noun ( N ) , adjective ( A ) , verb ( V ) , or adverb ( Adv ) followed by a light verb ( LV ) , a grammaticalized version of a main verb , which contributes little telic significance to the composite predicate .</sentence>
				<definiendum id="0">CPs</definiendum>
				<definiens id="0">characterized by a predicate or host typically a noun ( N ) , adjective ( A ) , verb ( V ) , or adverb ( Adv ) followed by a light verb ( LV ) , a grammaticalized version of a main verb , which contributes little telic significance to the composite predicate</definiens>
			</definition>
			<definition id="1">
				<sentence>This filtering is based on two parameters : a ) Fertility count ( r f ) , which is defined as the number of Hindi words an English word maps to , and b ) Acceptance level ( k ) , defined as the number of words acceptable in a sentence with fertility count greater than equal to r f .</sentence>
				<definiendum id="0">) Acceptance level</definiendum>
				<definiens id="0">based on two parameters : a ) Fertility count ( r f</definiens>
				<definiens id="1">the number of Hindi words an English word maps to , and b</definiens>
				<definiens id="2">the number of words acceptable in a sentence with fertility count greater than equal to r f</definiens>
			</definition>
</paper>

		<paper id="0609">
			<definition id="0">
				<sentence>The PropBank corpus annotates the entire Penn Treebank with predicate argument structures by adding semantic role labels to the syntactic constituents of the Penn Treebank .</sentence>
				<definiendum id="0">PropBank corpus</definiendum>
				<definiens id="0">annotates the entire Penn</definiens>
			</definition>
			<definition id="1">
				<sentence>Treebank annotation involves two tasks : part-of-speech tagging and syntactic annotation .</sentence>
				<definiendum id="0">Treebank annotation</definiendum>
			</definition>
			<definition id="2">
				<sentence>Adjunct constituents are sister to the NP that contains the head noun , child of the NP that contains both : ( NP ( NP head ) ( PP adjunct ) ) PropBank is an annotation of predicate-argument structures on top of syntactically parsed , or Treebanked , structures .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">contains both : ( NP ( NP head ) ( PP adjunct ) )</definiens>
				<definiens id="1">an annotation of predicate-argument structures on top of syntactically parsed , or Treebanked , structures</definiens>
			</definition>
			<definition id="3">
				<sentence>More specifically , PropBank annotation involves three tasks : argument labeling , annotation of modifiers , and creating co-reference chains for empty categories .</sentence>
				<definiendum id="0">PropBank annotation</definiendum>
				<definiens id="0">involves three tasks : argument labeling , annotation of modifiers</definiens>
			</definition>
			<definition id="4">
				<sentence>The second task of the PropBank annotation involves assigning functional tags to all modifiers of the verb , such as MNR ( manner ) , LOC ( locative ) , TMP ( temporal ) , DIS ( discourse connectives ) , PRP ( purpose ) or DIR ( direction ) and others .</sentence>
				<definiendum id="0">PropBank annotation</definiendum>
				<definiendum id="1">LOC ( locative</definiendum>
				<definiens id="0">involves assigning functional tags to all modifiers of the verb , such as MNR ( manner )</definiens>
			</definition>
			<definition id="5">
				<sentence>Original PropBank annotation : Rel : like Arg0 : you Arg1 : [ *T* ] - &gt; What Such chains usually include traces of A and A’ movement and PRO for subject and object control .</sentence>
				<definiendum id="0">PRO</definiendum>
				<definiens id="0">subject and object control</definiens>
			</definition>
			<definition id="6">
				<sentence>For example , in the following case , the PropBank concatenates the NP and the PP to be the Arg1 .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">concatenates the NP and the PP to be the Arg1</definiens>
			</definition>
			<definition id="7">
				<sentence>PropBank has around 550 phrasal verbs like keep up , touch on , used to and others , which are analyzed as separate predicates in PropBank .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">has around 550 phrasal verbs like keep up , touch on , used to and others , which are analyzed as separate predicates in PropBank</definiens>
			</definition>
			<definition id="8">
				<sentence>( 26 ) ( NP ( NNP Richard ) ( NNP Thornburgh ) ) ( , , ) ( SBAR ( WHNP-164 ( WP who ) ) ( S ( NP-SBJ-1 ( -NONE*T*-164 ) ) ( VP ( VBD went ) ( PRT ( RP on ) ) ( S ( NP-SBJ ( -NONE*-1 ) ) ( VP ( TO to ) ( VP ( VB [ rel ] become ) ( NP-PRD ( NP [ ARG2 ] ( NP ( NN governor ) ) ( PP ( IN of ) ( NP ( NNP Pennsylvania ) ) ) ) 76 ( CC and ) ( PRN ( , , ) ( ADVP-TMP ( RB now ) ) ( , , ) ) ( NP [ ARG2 ] ( NNP U.S. ) ( NNP Attorney ) ( NNP General ) ) ) ) ) ) ) ) ) In PropBank , cases like this can be decomposed into two propositions : ( 27 ) Prop1 : rel : become Arg1 : attorney general Arg0 : [ -NONE*-1 ] Prop2 : rel : become ArgM-TMP : now Arg0 : [ -NONE*-1 ] Arg1 : a governor In Treebank , the conjoined NP is necessarily analyzed as one constituent .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">NN governor ) ) ( PP ( IN of ) ( NP ( NNP Pennsylvania ) ) ) ) 76 ( CC and ) ( PRN ( , , ) ( ADVP-TMP ( RB now ) ) ( , , ) ) ( NP [ ARG2 ] ( NNP U.S. ) ( NNP Attorney ) ( NNP General ) ) ) ) ) ) )</definiens>
			</definition>
</paper>

		<paper id="2504">
			<definition id="0">
				<sentence>The semantic information , in the form of Dekang Lin’s ( 1998 ) thesaurus of semantically similar words , allowed the classifier to search the training set for instances whose head was similar , and not just identical , to that of a test instance .</sentence>
				<definiendum id="0">semantic information</definiendum>
				<definiens id="0">thesaurus of semantically similar words , allowed the classifier to search the training set for instances whose head was similar , and not just identical , to that of a test instance</definiens>
			</definition>
			<definition id="1">
				<sentence>SVD is said to abstract away from word dimensions , and to discover topical dimensions instead .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">said to abstract away from word dimensions , and to discover topical dimensions instead</definiens>
			</definition>
			<definition id="2">
				<sentence>They are defined in the following way : • Overall accuracy is the total number of instances that is classified correctly .</sentence>
				<definiendum id="0">Overall accuracy</definiendum>
				<definiens id="0">the total number of instances that is classified correctly</definiens>
			</definition>
			<definition id="3">
				<sentence>• Recall for the metonymical category is the percentage of metonymies that the classifier recognizes .</sentence>
				<definiendum id="0">• Recall</definiendum>
			</definition>
			<definition id="4">
				<sentence>TiMBL implements a number of MBL algorithms .</sentence>
				<definiendum id="0">TiMBL</definiendum>
			</definition>
			<definition id="5">
				<sentence>WordNet is a machine-readable lexical database that , among other things , structures English verbs , nouns and adjectives in a hierarchy of so-called “synonym sets” or synsets ( Fellbaum , 1998 ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="6">
				<sentence>In short , the experiments above demonstrate convincingly that Memory-Based Learning is a simple but robust approach to metonymy recognition .</sentence>
				<definiendum id="0">Memory-Based Learning</definiendum>
				<definiens id="0">a simple but robust approach to metonymy recognition</definiens>
			</definition>
</paper>

		<paper id="1633">
			<definition id="0">
				<sentence>BESTCUT has a different way of computing the cut weight than Min-Cut and a different way of stopping the cut2 .</sentence>
				<definiendum id="0">BESTCUT</definiendum>
				<definiens id="0">has a different way of computing the cut weight than Min-Cut and a different way of stopping the cut2</definiens>
			</definition>
			<definition id="1">
				<sentence>To decide the minimum cut ( from here on called the BESTCUT ) , we use as cut weight the number of mentions that are correctly placed in their set .</sentence>
				<definiendum id="0">BESTCUT</definiendum>
			</definition>
			<definition id="2">
				<sentence>C.E is the set of edges crossing the cut , and G is the current graph before the cut .</sentence>
				<definiendum id="0">C.E</definiendum>
				<definiendum id="1">G</definiendum>
				<definiens id="0">the current graph before the cut</definiens>
			</definition>
			<definition id="3">
				<sentence>S.V and T.V are the set of vertexes in S and in T , respectively .</sentence>
				<definiendum id="0">S.V</definiendum>
				<definiendum id="1">T.V</definiendum>
				<definiens id="0">the set of vertexes in S and in T , respectively</definiens>
			</definition>
			<definition id="4">
				<sentence>hmeax ( C.E ) = 1 − hmean ( C.E′ ) where each edge from E′ has the weight equal to 1 minus the corresponding edge from E lt-c-avg-ratio how many edges from the cut are less than the average of the cut ( as a ratio ) lt-c-hmeanratio how many edges from the cut are less than the harmonic mean of the cut ( as a ratio ) st-avg avg ( S.E + T.E ) – the average of the edges from the graph when the edges from the cut are not considered g-avg avg ( G.E ) – the average of the edges from the graph st-wrong-avgratio how many vertexes are in the wrong part of the cut using the average measure for the ‘wrong’ ( as a ratio ) st-wrongmax-ratio how many vertexes are in the wrong part of the cut using the max measure for the ‘wrong’ ( as a ratio ) lt-c-avg-ratio &lt; st-lt-c-avgratio 1 if r1 &lt; r2 , 0 otherwise ; r1 is the ratio of the edges from C.E that are smaller than the average of the cut ; r2 is the ratio of the edges from S.E + T.E that are smaller than the average of the cut g-avg &gt; stavg 1 if the avg ( G.E ) &gt; avg ( S.E+T .</sentence>
				<definiendum id="0">hmeax</definiendum>
				<definiendum id="1">r1</definiendum>
				<definiendum id="2">r2</definiendum>
				<definiens id="0">C.E ) = 1 − hmean ( C.E′ ) where each edge from E′ has the weight equal to 1 minus the corresponding edge from E lt-c-avg-ratio how many edges from the cut are less than the average of the cut</definiens>
				<definiens id="1">the average of the edges from the graph st-wrong-avgratio how many vertexes are in the wrong part of the cut using the average measure for the ‘wrong’ ( as a ratio ) st-wrongmax-ratio how many vertexes are in the wrong part of the cut using the max measure for the ‘wrong’</definiens>
				<definiens id="2">the ratio of the edges from C.E that are smaller than the average of the cut ;</definiens>
			</definition>
			<definition id="5">
				<sentence>We used the ACE corpus , which is annotated with mention and entity information , as data in a supervised machine learning method to detect nominal mentions and their entity types .</sentence>
				<definiendum id="0">ACE corpus</definiendum>
				<definiens id="0">annotated with mention and entity information , as data in a supervised machine learning method to detect nominal mentions and their entity types</definiens>
			</definition>
			<definition id="6">
				<sentence>In our first experiment , we tested the three coreference clusterization algorithms on the development-test set of the ACE Phase 2 corpus , first on true mentions ( i.e. the mentions annotated in the key files ) , then on detected mentions ( i.e. the mentions output by our mention detection system presented in section 3 ) and finally without any prior knowledge of the mention types .</sentence>
				<definiendum id="0">mention detection system</definiendum>
				<definiens id="0">the mentions annotated in the key files</definiens>
			</definition>
			<definition id="7">
				<sentence>WordNet : An Electronic Lexical Database and Some of its Applications .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="1615">
			<definition id="0">
				<sentence>Nevertheless , PoS tagging is an important stage in pipelined language processing systems , from information extractors to speech synthesizers .</sentence>
				<definiendum id="0">PoS tagging</definiendum>
				<definiens id="0">an important stage in pipelined language processing systems</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 2 ( c ) shows some words that occur together with the pivot features in the WSJ unlabeled data .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiens id="0">shows some words that occur together with the pivot features in the WSJ unlabeled data</definiens>
			</definition>
			<definition id="2">
				<sentence>The pivot predictors are the key element in SCL .</sentence>
				<definiendum id="0">pivot predictors</definiendum>
				<definiens id="0">the key element in SCL</definiens>
			</definition>
			<definition id="3">
				<sentence>The ASO baseline is an implementation of Ando and Zhang ( 2005b ) .</sentence>
				<definiendum id="0">ASO baseline</definiendum>
			</definition>
			<definition id="4">
				<sentence>Roark and Bacchiani ( 2003 ) use a Dirichlet prior on the multinomial parameters of a generative parsing model to combine a large amount of training data from a source corpus ( WSJ ) , and small amount of training data from a target corpus ( Brown ) .</sentence>
				<definiendum id="0">WSJ</definiendum>
				<definiens id="0">use a Dirichlet prior on the multinomial parameters of a generative parsing model to combine a large amount of training data from a source corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>Lease and Charniak ( 2005 ) adapt a WSJ parser to biomedical text without any biomedical treebanked data .</sentence>
				<definiendum id="0">Lease</definiendum>
				<definiendum id="1">Charniak</definiendum>
			</definition>
			<definition id="6">
				<sentence>SCL is a general technique that can be applied to any feature-based discriminative learner .</sentence>
				<definiendum id="0">SCL</definiendum>
			</definition>
</paper>

		<paper id="2704">
			<definition id="0">
				<sentence>The NITE Query Language ( NQL ) has been used successfully for analysis of a number of heavily cross-annotated data sets , and users especially value its elegance and flexibility .</sentence>
				<definiendum id="0">NITE Query Language</definiendum>
				<definiens id="0">used successfully for analysis of a number of heavily cross-annotated data sets , and users especially value its elegance and flexibility</definiens>
			</definition>
			<definition id="1">
				<sentence>NXT is designed specifically for data sets with multiple kinds of annotation .</sentence>
				<definiendum id="0">NXT</definiendum>
			</definition>
			<definition id="2">
				<sentence>NXT supports data exploration using a search GUI , callable from any tool , that will run an NQL query and highlight results on the tool’s display .</sentence>
				<definiendum id="0">NXT</definiendum>
				<definiens id="0">supports data exploration using a search GUI , callable from any tool</definiens>
			</definition>
			<definition id="3">
				<sentence>A ‘metadata’ file defines the structures of the individual files and the relationships among them , as well as detailing where to find the data and signals on the file system .</sentence>
				<definiendum id="0">‘metadata’ file</definiendum>
				<definiens id="0">defines the structures of the individual files and the relationships among them , as well as detailing where to find the data and signals on the file system</definiens>
			</definition>
			<definition id="4">
				<sentence>The query expression consists of two parts , separated by a colon ( : ) .</sentence>
				<definiendum id="0">query expression</definiendum>
				<definiens id="0">consists of two parts , separated by a colon ( : )</definiens>
			</definition>
			<definition id="5">
				<sentence>TigerSearch ( Tiger Project , nd ) is primarily for single trees , but does allow some out-of-tree relationships ; the data model includes “secondary edges” that link a node to an additional parent and that can be labelled , with query language operators that will test for the presence or absence of such an edge , with or without a specific label .</sentence>
				<definiendum id="0">TigerSearch</definiendum>
				<definiens id="0">includes “secondary edges” that link a node to an additional parent</definiens>
				<definiens id="1">query language operators that will test for the presence or absence of such an edge , with or without a specific label</definiens>
			</definition>
			<definition id="6">
				<sentence>XQuery queries can include a mixture of XML , XPath expressions , and function calls ; and also FLWOR expressions , which provide various programmatical constructs such as for , let , where , orderby and return keywords for looping and variable assignment .</sentence>
				<definiendum id="0">XQuery queries</definiendum>
				<definiens id="0">include a mixture of XML , XPath expressions , and function calls</definiens>
			</definition>
			<definition id="7">
				<sentence>XQuery is designed to make efficient use of the inherent structure of XML to calculate the results of a query .</sentence>
				<definiendum id="0">XQuery</definiendum>
				<definiens id="0">designed to make efficient use of the inherent structure of XML to calculate the results of a query</definiens>
			</definition>
			<definition id="8">
				<sentence>XQuery allows us to combine fragments of XML , selected by XPath , in meaningful ways to construct the results of a given query .</sentence>
				<definiendum id="0">XQuery</definiendum>
				<definiens id="0">allows us to combine fragments of XML , selected by XPath</definiens>
			</definition>
			<definition id="9">
				<sentence>“Knitting” is the process of starting with one XML file and recursively following children and child links , storing the expanded result as an XML file .</sentence>
				<definiendum id="0">“Knitting”</definiendum>
				<definiens id="0">the process of starting with one XML file</definiens>
			</definition>
			<definition id="10">
				<sentence>Apart from some primitive optimizations , on this and all queries , NXT Search does an exhaustive search of all possible k-tuples that match the types given in the query , varying the rightmost variable fastest .</sentence>
				<definiendum id="0">NXT Search</definiendum>
				<definiens id="0">does an exhaustive search of all possible k-tuples that match the types given in the query , varying the rightmost variable fastest</definiens>
			</definition>
			<definition id="11">
				<sentence>This XQuery implementation strategy draws more heavily on XPath than the standoff strategy , and XPath is the most well-exercised portion of XQuery .</sentence>
				<definiendum id="0">XPath</definiendum>
				<definiens id="0">the most well-exercised portion of XQuery</definiens>
			</definition>
</paper>

		<paper id="3408">
			<definition id="0">
				<sentence>The tool includes a UI that plots information over time , and a semantic graph that highlights relationships of interest .</sentence>
				<definiendum id="0">UI</definiendum>
				<definiens id="0">plots information over time</definiens>
			</definition>
			<definition id="1">
				<sentence>In this paper , we present a Conversational Analysis Tool ( ChAT ) which integrates several language processing tools ( topic segmentation , affect scoring , named entity extraction ) that can be used to automatically annotate conversational data .</sentence>
				<definiendum id="0">Conversational Analysis Tool ( ChAT )</definiendum>
				<definiens id="0">integrates several language processing tools ( topic segmentation , affect scoring , named entity extraction ) that can be used to automatically annotate conversational data</definiens>
			</definition>
			<definition id="2">
				<sentence>The ICSI meeting corpus ( Janin et al. , 2003 ) is a corpus of text transcripts of research meetings .</sentence>
				<definiendum id="0">ICSI meeting corpus</definiendum>
				<definiens id="0">a corpus of text transcripts of research meetings</definiens>
			</definition>
			<definition id="3">
				<sentence>Instead , WLM employs a constrained minimal-spanning tree ( MST ) algorithm to find and join pairs of elements in a sequence .</sentence>
				<definiendum id="0">WLM</definiendum>
				<definiens id="0">employs a constrained minimal-spanning tree</definiens>
			</definition>
			<definition id="4">
				<sentence>However since WLM only requires information on the distance between adjoining elements in the sequence the search space for finding the two closest adjoining elements is linear , O ( N ) , where N is the number of elements in the sequence .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of elements in the sequence</definiens>
			</definition>
			<definition id="5">
				<sentence>Analyzing conversations consists of more than analyzing the topics within them .</sentence>
				<definiendum id="0">Analyzing conversations</definiendum>
			</definition>
			<definition id="6">
				<sentence>Affect is measured by the proportion of POS to NEG words in the selected time frame .</sentence>
				<definiendum id="0">Affect</definiendum>
				<definiens id="0">measured by the proportion of POS to NEG words in the selected time frame</definiens>
			</definition>
			<definition id="7">
				<sentence>In the current implementation , the named entity panel consists of only list of entity labels present in a given time frame .</sentence>
				<definiendum id="0">named entity panel</definiendum>
				<definiens id="0">consists of only list of entity labels present in a given time frame</definiens>
			</definition>
</paper>

		<paper id="0704">
			<definition id="0">
				<sentence>EBM is a widelyaccepted paradigm for medical practice that involves the explicit use of current best evidence , i.e. , high-quality patient-centered clinical research reported in the primary medical literature , to make decisions about patient care .</sentence>
				<definiendum id="0">EBM</definiendum>
				<definiens id="0">a widelyaccepted paradigm for medical practice that involves the explicit use of current best evidence , i.e. , high-quality patient-centered clinical research reported in the primary medical literature , to make decisions about patient care</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , a PDA is an ideal vehicle for delivering question answering capabilities ( Hauser et al. , 2004 ) .</sentence>
				<definiendum id="0">PDA</definiendum>
			</definition>
			<definition id="2">
				<sentence>As conceived , clinical question answering is a knowledge-intensive endeavor that requires automatic identification of PICO elements from MEDLINE abstracts .</sentence>
				<definiendum id="0">clinical question answering</definiendum>
			</definition>
			<definition id="3">
				<sentence>The knowledge extraction module provides the basic frame elements used in the semantic matching process , described in the next section .</sentence>
				<definiendum id="0">knowledge extraction module</definiendum>
				<definiens id="0">provides the basic frame elements used in the semantic matching process , described in the next section</definiens>
			</definition>
			<definition id="4">
				<sentence>The Problem is the main disease under consideration in an abstract , and outcomes are statements that assert clinical findings , e.g. , efficacy of a drug or a comparison between two drugs .</sentence>
				<definiendum id="0">Problem</definiendum>
				<definiens id="0">the main disease under consideration in an abstract , and outcomes are statements that assert clinical findings , e.g. , efficacy of a drug or a comparison between two drugs</definiens>
			</definition>
			<definition id="5">
				<sentence>These considerationsarecomputationallyoperationalizedinthe semantic matcher , which takes as input elements identified by the knowledge extractor and scores the relevance of each PubMed citation with respect to the question .</sentence>
				<definiendum id="0">semantic matcher</definiendum>
				<definiens id="0">takes as input elements identified by the knowledge extractor</definiens>
			</definition>
			<definition id="6">
				<sentence>Clinical Evidence ( CE ) is a periodic report created by the British Medical Journal ( BMJ ) Publishing Group that summarizes the best treatments for a few dozen diseases at the time of publication .</sentence>
				<definiendum id="0">Clinical Evidence ( CE )</definiendum>
				<definiens id="0">a periodic report created by the British Medical Journal ( BMJ ) Publishing Group that summarizes the best treatments for a few dozen diseases at the time of publication</definiens>
			</definition>
			<definition id="7">
				<sentence>Overall , the construction of our semantic model is enabled by the UMLS ontology , which provides an enumeration of relevant concepts ( e.g. , the names of diseases , drugs , etc. ) and semantic relations between those concepts .</sentence>
				<definiendum id="0">UMLS ontology</definiendum>
				<definiens id="0">provides an enumeration of relevant concepts</definiens>
			</definition>
			<definition id="8">
				<sentence>Question answering in the clinical domain is an emerging area of research that has only recently begun to receive serious attention .</sentence>
				<definiendum id="0">Question answering</definiendum>
				<definiens id="0">has only recently begun to receive serious attention</definiens>
			</definition>
</paper>

		<paper id="2612">
			<definition id="0">
				<sentence>One of the most widely quoted and wellknown definition of ontology is Gruber 's ( Gruber , 1993 ) : An ontology is an explicit specification of a conceptualization .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">an explicit specification of a conceptualization</definiens>
			</definition>
			<definition id="1">
				<sentence>Here in this paper we adopt the following definition : Ontology is the study or concern about what kinds of things exist what entities or things are there in the universe ( Blackburn , 1996 ) .</sentence>
				<definiendum id="0">Ontology</definiendum>
				<definiens id="0">the study or concern about what kinds of things exist what entities or things</definiens>
			</definition>
			<definition id="2">
				<sentence>An ontology of names can be worked out in many different forms , but every ontology will include a dictionary , some definition of the terms 87 ( semantics ) , and indications how they depend on each other , e.g. in hierarchies and semantic networks .</sentence>
				<definiendum id="0">ontology of names</definiendum>
				<definiens id="0">some definition of the terms 87 ( semantics ) , and indications how they depend on each other , e.g. in hierarchies and semantic networks</definiens>
			</definition>
			<definition id="3">
				<sentence>A name consists of one or more syllables .</sentence>
				<definiendum id="0">name</definiendum>
			</definition>
</paper>

		<paper id="1104">
			<definition id="0">
				<sentence>Semantic relatedness is a special form of linguistic distance between words .</sentence>
				<definiendum id="0">Semantic relatedness</definiendum>
				<definiens id="0">a special form of linguistic distance between words</definiens>
			</definition>
			<definition id="1">
				<sentence>Linguistic distance plays an important role in many applications like information retrieval , word sense disambiguation , text summarization or spelling correction .</sentence>
				<definiendum id="0">Linguistic distance</definiendum>
				<definiens id="0">plays an important role in many applications like information retrieval , word sense disambiguation</definiens>
			</definition>
			<definition id="2">
				<sentence>Concept annotated datasets can be used to test the ability of a measure to differentiate between senses when determining the relatedness of polysemous words .</sentence>
				<definiendum id="0">Concept annotated datasets</definiendum>
				<definiens id="0">the ability of a measure to differentiate between senses when determining the relatedness of polysemous words</definiens>
			</definition>
			<definition id="3">
				<sentence>The BERUFEnet ( BN ) corpus7 consists of descriptions of 5,800 professions in Germany and therefore contains many terms specific to professional training .</sentence>
				<definiendum id="0">BERUFEnet ( BN ) corpus7</definiendum>
				<definiens id="0">consists of descriptions of 5,800 professions in Germany and therefore contains many terms specific to professional training</definiens>
			</definition>
			<definition id="4">
				<sentence>Correlation coefficients for experiments measuring semantic relatedness are expected to be lowerthanresultsforsemanticsimilarity , sincethe former also includes additional relations ( like cooccurrence of words ) and is thus a more complicated task .</sentence>
				<definiendum id="0">Correlation coefficients</definiendum>
				<definiens id="0">sincethe former also includes additional relations ( like cooccurrence of words</definiens>
			</definition>
			<definition id="5">
				<sentence>When analyzing the concept pairs with lowest deviation there is a clear tendency for particularly highly related pairs , e.g. hypernymy : Universität – Bildungseinrichtung ( university – educational institution ) ; functional relation : Tätigkeit – ausführen ( task – perform ) ; or pairs that are obviously not connected , e.g. logisch – Juni ( logical – June ) .</sentence>
				<definiendum id="0">e.g. hypernymy</definiendum>
				<definiens id="0">a clear tendency for particularly highly related pairs</definiens>
			</definition>
</paper>

		<paper id="1662">
			<definition id="0">
				<sentence>However , this may lead to wrong theme correlations , since B’s occurrence may rely on a third theme C and have nothing to do with A. In addition , when outputting theme orders , MO uses a kind of heuristic that chooses a theme based on its in-out edge difference in the directed theme graph .</sentence>
				<definiendum id="0">MO</definiendum>
				<definiens id="0">uses a kind of heuristic that chooses a theme based on its in-out edge difference in the directed theme graph</definiens>
			</definition>
			<definition id="1">
				<sentence>Suppose the input is the class graph G= &lt; C , E &gt; , where C = { c1 , c2 , … , cL } is the set of the classes , E= { ei , j|1≤i , j≤L } is the set of the directed edges , and o is the ordering of the classes .</sentence>
				<definiendum id="0">o</definiendum>
				<definiens id="0">the set of the directed edges</definiens>
			</definition>
			<definition id="2">
				<sentence>For comparison between different matrices , E ( M ) needs to be averaged over n×m. For sentence ordering , we used Kendall’s τ coefficient ( Lapata , 2003 ) , as defined in 10 ) , 2/ ) 1 ( ) ( 21 ) 10 −−= NN N Iτ where , NI is number of inversions of consecutive sentences needed to transform output of the algorithm to manual summaries .</sentence>
				<definiendum id="0">E ( M )</definiendum>
				<definiendum id="1">NI</definiendum>
				<definiens id="0">needs to be averaged over n×m. For sentence ordering</definiens>
				<definiens id="1">number of inversions of consecutive sentences needed to transform output of the algorithm to manual summaries</definiens>
			</definition>
</paper>

		<paper id="1908">
			<definition id="0">
				<sentence>Telugu is an important language in India belonging to the Dravidian family .</sentence>
				<definiendum id="0">Telugu</definiendum>
				<definiens id="0">an important language in India belonging to the Dravidian family</definiens>
			</definition>
			<definition id="1">
				<sentence>RDQA has a long history , beginning with systems working over databases ( e.g. , BASEBALL ( Green et al. , 1961 ) , and LUNAR ( woods et al. , 1972 ) ) .</sentence>
				<definiendum id="0">RDQA</definiendum>
				<definiens id="0">a long history , beginning with systems working over databases</definiens>
			</definition>
			<definition id="2">
				<sentence>ARISE ( Automatic Railway Information System for Europe ) is a spoken dialogue system to provide train timetable information over the phone .</sentence>
				<definiendum id="0">ARISE</definiendum>
				<definiens id="0">a spoken dialogue system to provide train timetable information over the phone</definiens>
			</definition>
			<definition id="3">
				<sentence>ARISE uses a mixed initiative Dialogue Manager ( DM ) .</sentence>
				<definiendum id="0">ARISE</definiendum>
			</definition>
			<definition id="4">
				<sentence>In this keyword based approach the input query statement is analyzed by the query analyzer , which uses domain ontology stored as knowledge base , generating tokens and keywords .</sentence>
				<definiendum id="0">query analyzer</definiendum>
				<definiens id="0">uses domain ontology stored as knowledge base</definiens>
			</definition>
			<definition id="5">
				<sentence>Precision= ( Number of correct answers given by the system/Number of answers given by the system ) *100 .</sentence>
				<definiendum id="0">Precision= ( Number</definiendum>
				<definiens id="0">of correct answers given by the system/Number of answers given by the system</definiens>
			</definition>
			<definition id="6">
				<sentence>BASEBALL : An automatic question answerer .</sentence>
				<definiendum id="0">BASEBALL</definiendum>
				<definiens id="0">An automatic question answerer</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>Amongthe mostoftenusedtypesof lexicalassociationmeasures ( henceforth AMs ) we mention : statistical hypothesistests ( e.g. , binomial , Poisson , Fisher , zscore , chi-squared , t-score , andlog-likelihoodratiotests ) , thatmeasurethesignificanceoftheassociationbetweentwowordsbasedonacontingency table listing their joint and marginal frequency , and Information-theoretic measures ( Mutual Information— henceforthMI — and its variants ) , that quantityof ‘information’sharedby two randomvariables .</sentence>
				<definiendum id="0">Amongthe mostoftenusedtypesof lexicalassociationmeasures</definiendum>
				<definiens id="0">binomial , Poisson , Fisher , zscore , chi-squared , t-score , andlog-likelihoodratiotests ) , thatmeasurethesignificanceoftheassociationbetweentwowordsbasedonacontingency table listing their joint and marginal frequency , and Information-theoretic measures ( Mutual Information— henceforthMI — and its variants</definiens>
			</definition>
</paper>

		<paper id="3002">
			<definition id="0">
				<sentence>Open-domain question answering ( QA ) technologies allow users to ask a question using natural language and obtain the answer itself rather than a list of documents that contain the answer ( Voorhees et al.2000 ) .</sentence>
				<definiendum id="0">Open-domain question answering</definiendum>
				<definiens id="0">allow users to ask a question using natural language and obtain the answer itself rather than a list of documents that contain the answer ( Voorhees et al.2000 )</definiens>
			</definition>
			<definition id="1">
				<sentence>QACIAD ( Question Answering Challenge for Information Access Dialogue ) is an objective and quantitative evaluation framework to measure the abilities of QA systems used interactively to participate in dialogues for accessing information ( Kato et al.2004a ) ( Kato et al.2006 ) .</sentence>
				<definiendum id="0">QACIAD</definiendum>
				<definiens id="0">an objective and quantitative evaluation framework to measure the abilities of QA systems used interactively to participate in dialogues for accessing information</definiens>
			</definition>
			<definition id="2">
				<sentence>QAC covers factoid questions in the form of complete sentences with interrogative pronouns .</sentence>
				<definiendum id="0">QAC</definiendum>
				<definiens id="0">covers factoid questions in the form of complete sentences with interrogative pronouns</definiens>
			</definition>
			<definition id="3">
				<sentence>This restriction reflects the fact that the QACIAD is a simulation of interactive use of QA systems in dialogues .</sentence>
				<definiendum id="0">QACIAD</definiendum>
				<definiens id="0">a simulation of interactive use of QA systems in dialogues</definiens>
			</definition>
			<definition id="4">
				<sentence>The questions were restricted to wh-type questions , and a natural series of questions that may contain anaphoric expressions and ellipses was con1The NTCIR Workshop is a series of evaluation workshops designed to enhance research in information access technologies including information retrieval , QA , text summarization , extraction , and so on ( NTCIR 2006 ) .</sentence>
				<definiendum id="0">con1The NTCIR Workshop</definiendum>
				<definiens id="0">a series of evaluation workshops designed to enhance research in information access technologies including information retrieval</definiens>
			</definition>
</paper>

		<paper id="3210">
			<definition id="0">
				<sentence>The time-complexity bounding factor is the number of suffixes , i.e the cardinality of SW , which is linear ( in the size of the input ) if words are bounded in length by a constant and quadratic in the ( really ) worst case if not .</sentence>
				<definiendum id="0">time-complexity bounding factor</definiendum>
				<definiens id="0">the number of suffixes , i.e the cardinality of SW , which is linear ( in the size of the input ) if words</definiens>
			</definition>
			<definition id="1">
				<sentence>Many publications ( ´Cavar et al. , 2004 ; Brent et al. , 1995 ; Goldsmith et al. , 2001 ; D´ejean , 1998 ; Snover et al. , 2002 ; Argamon et al. , 2004 ; Goldsmith , 2001 ; Creutz and Lagus , 2005 ; Neuvel and Fulop , 2002 ; Baroni , 2003 ; Gaussier , 1999 ; Sharma et al. , 2002 ; Wicentowski , 2002 ; Oliver , 2004 ) , and various other works by the same authors , describe strategies that use frequencies , probabilities , and optimization criteria , often Minimum Description Length ( MDL ) , in various combinations .</sentence>
				<definiendum id="0">Many publications</definiendum>
				<definiendum id="1">Baroni</definiendum>
				<definiens id="0">use frequencies , probabilities , and optimization criteria , often Minimum Description Length ( MDL ) , in various combinations</definiens>
			</definition>
</paper>

		<paper id="1208">
			<definition id="0">
				<sentence>Compound nouns are a class of multiword expression ( MWE ) that have been of interest in recent computational linguistic work , as any task with a lexical semantic dimension ( like machine translation or information extraction ) must take into account their semantic markedness .</sentence>
				<definiendum id="0">Compound nouns</definiendum>
				<definiendum id="1">MWE</definiendum>
				<definiens id="0">any task with a lexical semantic dimension ( like machine translation or information extraction</definiens>
			</definition>
			<definition id="1">
				<sentence>We propose two novel paraphrases for a corpus statistical approach to predicting the relationship for a set of compound nominalisations , and investigate how using the World Wide Web as a corpus alleviates the common phenomenon of data sparseness , and how the volume of data impacts on the classi cation results .</sentence>
				<definiendum id="0">World Wide Web</definiendum>
				<definiens id="0">a corpus alleviates the common phenomenon of data sparseness , and how the volume of data impacts on the classi cation results</definiens>
			</definition>
			<definition id="2">
				<sentence>Calculating the z-score exactly can be quite costly , so we instead use the binomial approximation to the normal distribution with equal prior probabilities and nd that a given z-score Z is : Z = f −µσ ( 2 ) where f is the frequency count , µ is the mean in a pairwise test , and σ is the standard deviation of the test .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">σ</definiendum>
				<definiens id="0">the mean in a pairwise test , and</definiens>
				<definiens id="1">the standard deviation of the test</definiens>
			</definition>
			<definition id="3">
				<sentence>The Google API ( www.google.com/apis ) gives a method for examining the actual text of the returned documents .</sentence>
				<definiendum id="0">Google API ( www.google.com/apis )</definiendum>
				<definiens id="0">gives a method for examining the actual text of the returned documents</definiens>
			</definition>
			<definition id="4">
				<sentence>Using these frequencies , we calculate the pairwise z-scores between SUB and DOB , and between SUB and POB : the score given to the SUB interpretation is the greater of the two .</sentence>
				<definiendum id="0">POB</definiendum>
				<definiendum id="1">SUB interpretation</definiendum>
				<definiens id="0">the score given to the</definiens>
			</definition>
</paper>

		<paper id="3001">
			<definition id="0">
				<sentence>Following Ahrenberg et al. ( 1990 ) , the QA discourse is structured in segments composed by a pair of initiative-response units , like questionanswer , or question-assertion , in the absence of an answer .</sentence>
				<definiendum id="0">question-assertion</definiendum>
				<definiens id="0">the QA discourse is structured in segments composed by a pair of initiative-response units , like questionanswer , or</definiens>
			</definition>
</paper>

		<paper id="0611">
			<definition id="0">
				<sentence>Simple parsers ( commonly called ‘shallow parsers’ ) , on the other hand , produce only one type of annotationally relevant information ( e.g. , PoS , phrase/dependency structure ) .</sentence>
				<definiendum id="0">Simple parsers</definiendum>
				<definiens id="0">commonly called ‘shallow parsers’ ) , on the other hand , produce only one type of annotationally relevant information ( e.g. , PoS , phrase/dependency structure )</definiens>
			</definition>
			<definition id="1">
				<sentence>First , the generator actually constructs the sentence ( or other unit ) as determined by the feature selection .</sentence>
				<definiendum id="0">generator actually</definiendum>
				<definiens id="0">constructs the sentence ( or other unit ) as determined by the feature selection</definiens>
			</definition>
			<definition id="2">
				<sentence>An additional layer holds the complete constituent structure of the clause ( cf. Figure 4 for the corresponding extract from the running example ) , 89 &lt; constituent unit= '' -TOP- '' selexp= '' LEXICAL-VERB-TERM-RESOLUTION ... '' &gt; &lt; token features= '' HOWEVER '' &gt; However , &lt; /token &gt; &lt; constituent unit= '' TOPICAL '' selexp= '' THEY-PRONOUN ... '' &gt; &lt; token features= '' THEY PLURAL-FORM '' &gt; they &lt; /token &gt; &lt; /constituent &gt; &lt; token features= '' OUTCLASSIFY-REDUCED ... '' &gt; will &lt; /token &gt; &lt; token features= '' DO-VERB ... '' &gt; step up &lt; /token &gt; &lt; constituent unit= '' DIRECTCOMPLEMENT '' selexp= '' NOMINAL-TERM-RESOLUTION OBLIQUE ... '' &gt; &lt; constituent unit= '' DEICTIC '' selexp= '' THEIR GENITIVE NONSUPERLATIVE ... '' &gt; &lt; token features= '' THEIR PLURAL-FORM '' &gt; their &lt; /token &gt; &lt; /constituent &gt; &lt; token features= '' ... COMMON-NOUN ... '' &gt; presence &lt; /token &gt; &lt; /constituent &gt; &lt; constituent unit= '' TIMELOCATIVE '' selexp= '' IN STRONG-INCLUSIVE UNORDERED ... '' &gt; &lt; token features= '' IN '' &gt; in &lt; /token &gt; &lt; constituent unit= '' MINIRANGE '' selexp= '' NOMINAL-TERM-RESOLUTION ... '' &gt; &lt; token features= '' THE '' &gt; the &lt; /token &gt; &lt; constituent unit= '' STATUS '' selexp= '' QUALITY-TERM-RESOLUTION ... '' &gt; &lt; token features= '' ... ADJECTIVE '' &gt; next &lt; /token &gt; &lt; /constituent &gt; &lt; token features= '' ... COMMON-NOUN ... '' &gt; year .</sentence>
				<definiendum id="0">constituent unit= '' TIMELOCATIVE</definiendum>
				<definiens id="0">UNORDERED ... '' &gt; &lt; token features= '' IN '' &gt; in &lt; /token &gt; &lt; constituent unit= '' MINIRANGE '' selexp= '' NOMINAL-TERM-RESOLUTION ... '' &gt; &lt; token features= '' THE</definiens>
			</definition>
			<definition id="3">
				<sentence>This guidance is either in the form of direct selections of grammatical features , in which case the user needs to know when the features apply , or in the form of semantic specifications , in which case the user needs information concerning the appropriate semantic classification according to the constructs of the linguistic ontology .</sentence>
				<definiendum id="0">guidance</definiendum>
				<definiens id="0">in which case the user needs information concerning the appropriate semantic classification according to the constructs of the linguistic ontology</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus manual correction consists of minor alignment statements between generated structure and string .</sentence>
				<definiendum id="0">manual correction</definiendum>
				<definiens id="0">consists of minor alignment statements between generated structure and string</definiens>
			</definition>
			<definition id="5">
				<sentence>GODDAG : A Data Structure for Overlapping Hierarchies .</sentence>
				<definiendum id="0">GODDAG</definiendum>
			</definition>
</paper>

		<paper id="2406">
			<definition id="0">
				<sentence>a. A collocation is a combination of a free ( ’autosematic’ ) element ( the base ) and a lexically determined ( ’synsemantic’ ) element ( the collocate , which may lose ( some of ) its meaning in a collocation ) ( adapted from ( Hausmann , 1979 ; Hausmann , 1989 ; Hausmann , 2003 ) ) .</sentence>
				<definiendum id="0">collocation</definiendum>
				<definiendum id="1">collocate</definiendum>
				<definiens id="0">a combination of a free ( ’autosematic’ ) element ( the base</definiens>
			</definition>
			<definition id="1">
				<sentence>b. A collocation is a word combination whose semantic and/or syntactic properties can not be fully predicted from those of its components , and which therefore has to be listed in a lexicon ( Evert , 2004 ) .</sentence>
				<definiendum id="0">collocation</definiendum>
				<definiens id="0">a word combination whose semantic and/or syntactic properties can not be fully predicted from those of its components , and which therefore has to be listed in a lexicon</definiens>
			</definition>
			<definition id="2">
				<sentence>Positional patterns ( based on adjacency or a ’window’ ) are adequate for con gurational languages , but in languages with rather free word order , words belonging to a phrase or collocation do not necessarily occur within a prede ned span1 .</sentence>
				<definiendum id="0">Positional patterns</definiendum>
				<definiens id="0">based on adjacency or a ’window’ ) are adequate for con gurational languages , but in languages with rather free word order , words belonging to a phrase or collocation do not necessarily occur within a prede ned span1</definiens>
			</definition>
			<definition id="3">
				<sentence>The chunker YAC determines phrase boundaries and heads , and disambiguates agreement information as far as possible .</sentence>
				<definiendum id="0">chunker YAC</definiendum>
				<definiens id="0">determines phrase boundaries and heads , and disambiguates agreement information as far as possible</definiens>
			</definition>
			<definition id="4">
				<sentence>SELECT COUNT ( * ) AS f , n_lemma , v_lemma FROM comfea1 GROUP BY n_lemma , v_lemma ORDER BY f DESC ; Figure 3 : sample query Filtering The instances extracted in the previous step are grouped according to noun and verb lemmas , i.e. instances of the same lemma pair form one group .</sentence>
				<definiendum id="0">SELECT COUNT</definiendum>
				<definiens id="0">instances of the same lemma pair form one group</definiens>
			</definition>
			<definition id="5">
				<sentence>Secondly , de nitions ( a ) and ( b ) may judge the same example differently : Anteil nehmen ( example ( 12 ) ) is usually agreed upon to be a support verb construction , but the distinction of the noun Anteil as the base ( making the main contribution to the meaning ) is questionable .</sentence>
				<definiendum id="0">Anteil nehmen</definiendum>
				<definiens id="0">the base ( making the main contribution to the meaning</definiens>
			</definition>
</paper>

		<paper id="0130">
</paper>

		<paper id="1421">
</paper>

		<paper id="3305">
			<definition id="0">
				<sentence>The Priority Model achieves an F-measure of statistical language model and probabilistic context-free grammar .</sentence>
				<definiendum id="0">Priority Model</definiendum>
				<definiens id="0">achieves an F-measure of statistical language model and probabilistic context-free grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>Advances in the area of gene and protein named entity recognition ( NER ) have been accelerated by freely available tagged corpora ( Kim et al. , 2003 , Cohen et al. , 2005 , Smith et al. , 2005 , Tanabe et al. , 2005 ) .</sentence>
				<definiendum id="0">NER</definiendum>
			</definition>
			<definition id="2">
				<sentence>MaSTerClass uses term contexts from an annotated corpus of 2072 MEDLINE abstracts related to nuclear receptors as a basis for classifying new terms .</sentence>
				<definiendum id="0">MaSTerClass</definiendum>
				<definiens id="0">uses term contexts from an annotated corpus of 2072 MEDLINE abstracts related to nuclear receptors as a basis for classifying new terms</definiens>
			</definition>
			<definition id="3">
				<sentence>To address this deficiency , we constructed the SemCat database , based on a subset of the UMLS Semantic Network enriched with categories from the GENIA Ontology ( Kim et al , 2003 ) , and a few new semantic types .</sentence>
				<definiendum id="0">Ontology</definiendum>
				<definiens id="0">a subset of the UMLS Semantic Network enriched with categories from the GENIA</definiens>
			</definition>
			<definition id="4">
				<sentence>The UMLS Semantic Network ( SN ) is an ongoing project at the National Library of Medicine .</sentence>
				<definiendum id="0">UMLS Semantic Network ( SN )</definiendum>
				<definiens id="0">an ongoing project at the National Library of Medicine</definiens>
			</definition>
			<definition id="5">
				<sentence>Similar hierarchies exist for the SN Conceptual Entity and Event trees .</sentence>
				<definiendum id="0">Similar hierarchies</definiendum>
			</definition>
			<definition id="6">
				<sentence>Unlike the Termino database ( Harkema et al. ( 2004 ) , which contains terminology annotated with morphosyntactic and conceptual information , SemCat currently consists of gazetteer lists only .</sentence>
				<definiendum id="0">Termino database</definiendum>
				<definiens id="0">contains terminology annotated with morphosyntactic and conceptual information</definiens>
			</definition>
			<definition id="7">
				<sentence>GP consists of specific terms from the semantic types DNA MOLECULE , PROTEIN MOLECULE , DNA FAMILY , PROTEIN FAMILY , PROTEIN COMPLEX and PROTEIN SUBUNIT .</sentence>
				<definiendum id="0">GP</definiendum>
				<definiendum id="1">PROTEIN MOLECULE , DNA FAMILY</definiendum>
				<definiens id="0">consists of specific terms from the semantic types DNA MOLECULE ,</definiens>
			</definition>
			<definition id="8">
				<sentence>NGP consists of entities from all other SemCat types , along with generic entities from the GP semantic types .</sentence>
				<definiendum id="0">NGP</definiendum>
				<definiens id="0">consists of entities from all other SemCat types , along with generic entities from the GP semantic types</definiens>
			</definition>
			<definition id="9">
				<sentence>Now let i s N′ be the set of all i for which 12 ... rr r k x xx x ++ is a substring of and let be the set of all for which i s N i 12 ... 1rr r k x xx x ++ − is a substring of .</sentence>
				<definiendum id="0">++ −</definiendum>
				<definiens id="0">a substring of</definiens>
			</definition>
			<definition id="10">
				<sentence>For our language model ( LM ) , we used Witten-Bell smoothing , which reserves probability mass for out of vocabulary values ( Witten and Bell , 1991 , Chen and Goodman , 1998 ) .</sentence>
				<definiendum id="0">LM</definiendum>
				<definiendum id="1">Witten-Bell smoothing</definiendum>
			</definition>
			<definition id="11">
				<sentence>CATP represents a string from GP , and NotCATP represents a string from NGP .</sentence>
				<definiendum id="0">CATP</definiendum>
				<definiendum id="1">NotCATP</definiendum>
				<definiens id="0">a string from GP</definiens>
			</definition>
			<definition id="12">
				<sentence>MedTag : A collection of biomedical annotations .</sentence>
				<definiendum id="0">MedTag</definiendum>
			</definition>
			<definition id="13">
				<sentence>GENETAG : a tagged corpus for gene/protein named entity recognition .</sentence>
				<definiendum id="0">GENETAG</definiendum>
				<definiens id="0">a tagged corpus for gene/protein named entity recognition</definiens>
			</definition>
</paper>

		<paper id="0304">
			<definition id="0">
				<sentence>Classification models require that a set of documents are hand labeled for affect , and a system is 23 trained on the feature vectors associated with labels .</sentence>
				<definiendum id="0">Classification models</definiendum>
				<definiens id="0">a set of documents are hand labeled for affect</definiens>
			</definition>
			<definition id="1">
				<sentence>The visualization tool is a mature tool that supports the analytical process by enabling users to explore the thematic content of the collection , use natural language to query the collection , make groups , view documents by time , etc .</sentence>
				<definiendum id="0">visualization tool</definiendum>
			</definition>
			<definition id="2">
				<sentence>The GI tool is a computer-assisted approach for content analyses of textual data ( Stone , 1977 ) .</sentence>
				<definiendum id="0">GI tool</definiendum>
			</definition>
			<definition id="3">
				<sentence>Lexical bootstrapping is a method used to help expand dictionaries of semantic categories ( Riloff &amp; Jones , 1999 ) in the context of a document set of interest .</sentence>
				<definiendum id="0">Lexical bootstrapping</definiendum>
				<definiens id="0">a method used to help expand dictionaries of semantic categories</definiens>
			</definition>
			<definition id="4">
				<sentence>Included in the editor is a Lexicon Bootstrapping Utility which the user can use to help create a specialized lexicon of their own .</sentence>
				<definiendum id="0">Bootstrapping Utility</definiendum>
				<definiens id="0">a Lexicon</definiens>
			</definition>
			<definition id="5">
				<sentence>IN-SPIRE ( Hetzler and Turner , 2004 ) is a visual analytics tool designed to facilitate rapid understanding of large textual corpora .</sentence>
				<definiendum id="0">IN-SPIRE</definiendum>
				<definiens id="0">a visual analytics tool designed to facilitate rapid understanding of large textual corpora</definiens>
			</definition>
			<definition id="6">
				<sentence>IN-SPIRE generates a compiled document set from mathematical signatures for each document in a set .</sentence>
				<definiendum id="0">IN-SPIRE</definiendum>
				<definiens id="0">generates a compiled document set from mathematical signatures for each document in a set</definiens>
			</definition>
			<definition id="7">
				<sentence>IN-SPIRE includes a variety of analytic tools that allow exploration of temporal trends , thematic distribution by source or other metadata , and query relationships and overlaps .</sentence>
				<definiendum id="0">IN-SPIRE</definiendum>
				<definiens id="0">includes a variety of analytic tools that allow exploration of temporal trends</definiens>
			</definition>
			<definition id="8">
				<sentence>The IN-SPIRE visualization tool is a non-data specific tool , designed to explore large amounts of textual data for a variety of genres and document types ( doc , xml , etc ) .</sentence>
				<definiendum id="0">IN-SPIRE visualization tool</definiendum>
				<definiens id="0">a non-data specific tool , designed to explore large amounts of textual data for a variety of genres</definiens>
			</definition>
			<definition id="9">
				<sentence>IN-SPIRE is a document visualization tool that is designed to explore the thematic content of a large collection of documents .</sentence>
				<definiendum id="0">IN-SPIRE</definiendum>
				<definiens id="0">a document visualization tool that is designed to explore the thematic content of a large collection of documents</definiens>
			</definition>
</paper>

		<paper id="1323">
			<definition id="0">
				<sentence>The largest conversational dialogue corpus is the Switchboard Corpus , which consists of about 2400 conversational English dialogues between two unfamiliar speakers over the telephone on one of 70 topics ( e.g. pets , family life , education , gun control , etc. ) .</sentence>
				<definiendum id="0">Switchboard Corpus</definiendum>
				<definiens id="0">consists of about 2400 conversational English dialogues between two unfamiliar speakers over the telephone on one of 70 topics ( e.g. pets , family life , education , gun control , etc. )</definiens>
			</definition>
			<definition id="1">
				<sentence>161 Dialogue Acts ( DAs ) and Rhetorical Relations ( RRs ) are well-known tagging schemes for annotating an utterance or a sentence .</sentence>
				<definiendum id="0">RRs</definiendum>
				<definiens id="0">well-known tagging schemes for annotating an utterance or a sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Table 1 : Dialogue Act Definition SWBDDAMSL/MRDA Our DAs Definition Statement non opinion inform objective fact inform non opinion Statement opinion inform subjective element inform opinion Wh-Question request objective fact request non opinion Yes-Noquestion request agreement request agreement opinion OpenQuestion confirm objective fact confirm non opinion Or-Question confirm agreement confirm agreement opinion Accept accept accept non opinion agree accept opinion Reject denial denial non opinion disagree denial opinion not marked express admiration inform admiration Summary DEL. ( mark as RR ) ————— Table 2 : Rhetorical Relation Definition Mann’s RST Our RRs definition evaluation ( positive ) U2 is a positive evaluation about U1 Evaluation evaluation ( negative ) U2 is a negative evaluation about U1 evaluation ( neutral ) U2 is neutral evaluation about U1 Volitional cause volitional cause-effect U2 is a volitional action , and U1 cause U2 Volitional result No Definition addition U2 consists of a part of U1 vided the Evaluation into three types of evaluation ( positive/negative/neutral ) .</sentence>
				<definiendum id="0">U2</definiendum>
				<definiens id="0">Dialogue Act Definition SWBDDAMSL/MRDA Our DAs Definition Statement non opinion inform objective fact inform non opinion Statement opinion inform subjective element inform opinion Wh-Question request objective fact request non opinion Yes-Noquestion request agreement request agreement opinion OpenQuestion confirm objective fact confirm non opinion Or-Question confirm agreement confirm agreement opinion Accept accept accept non opinion agree accept opinion Reject denial denial non opinion disagree denial opinion not marked express admiration inform admiration Summary DEL. ( mark as RR ) ————— Table 2 : Rhetorical Relation Definition Mann’s RST Our RRs definition evaluation ( positive )</definiens>
			</definition>
			<definition id="3">
				<sentence>An AP consists of two utterances where each part is produced by a different speaker .</sentence>
				<definiendum id="0">AP</definiendum>
				<definiens id="0">consists of two utterances where each part is produced by a different speaker</definiens>
			</definition>
			<definition id="4">
				<sentence>Rating the score of enthusiasm for POD A rater estimates a score of the enthusiasm corresponding to the part of dialogue ( POD ) , which is a series of five utterances .</sentence>
				<definiendum id="0">Rating the score of enthusiasm for POD A rater</definiendum>
				<definiens id="0">estimates a score of the enthusiasm corresponding to the part of dialogue ( POD ) , which is a series of five utterances</definiens>
			</definition>
			<definition id="5">
				<sentence>E ( AP i ) = 1 2 { E ( U j ) +E ( U k ) } ( 3 ) U j and U k denote the utterances in AP i .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">U j ) +E ( U k ) } ( 3 ) U j and U k denote the utterances in AP i</definiens>
			</definition>
			<definition id="6">
				<sentence>The Enthusiasm corpus annotated by R3 was used because we found that R4 rated Enthusiasm based on non-subjective reasons : after the examination of the rating , R4 said that speaker1 spoke enthusiastically but that it seemed unnatural because speaker1 had to manage the recording of the dialogue , which appears in the results as speaker1’s Enthusiasm as annotated by R4 as a notable difference ( see Figure 3 ) .</sentence>
				<definiendum id="0">Enthusiasm corpus</definiendum>
			</definition>
</paper>

		<paper id="1910">
			<definition id="0">
				<sentence>Question Answering ( QA ) is the task of , given a query expressed in Natural Language ( NL ) , retrieving its correct answer ( a single item , a text snippet , ... ) .</sentence>
				<definiendum id="0">Question Answering ( QA )</definiendum>
				<definiens id="0">a single item , a text snippet , ... )</definiens>
			</definition>
			<definition id="1">
				<sentence>GeoTALP-QA is a multilingual Geographical Domain Question Answering ( GDQA ) system .</sentence>
				<definiendum id="0">GeoTALP-QA</definiendum>
			</definition>
			<definition id="2">
				<sentence>The system architecture uses a common schema with three phases that are performed sequentially without feedback : Question Processing ( QP ) , Passage Retrieval ( PR ) and Answer Extraction ( AE ) .</sentence>
				<definiendum id="0">system architecture</definiendum>
			</definition>
			<definition id="3">
				<sentence>A worldwide gazetteer , excluding the USA and Antarctica , with 5.3 million entries .</sentence>
				<definiendum id="0">worldwide gazetteer</definiendum>
				<definiens id="0">excluding the USA and Antarctica , with 5.3 million entries</definiens>
			</definition>
			<definition id="4">
				<sentence>Otherwise , a trigger phrase pattern can be used to resolve the ambiguity ( e.g. ”Madrid” is an ambiguous NE , but in the phrase , ”comunidad de Madrid” ( State of Madrid ) , ambiguity is solved ) .</sentence>
				<definiendum id="0">e.g. ”Madrid”</definiendum>
				<definiens id="0">an ambiguous NE , but in the phrase</definiens>
			</definition>
			<definition id="5">
				<sentence>The extraction process consists on the application of a set of extraction rules on the set of sentences that have satisfied the MC .</sentence>
				<definiendum id="0">extraction process</definiendum>
				<definiens id="0">consists on the application of a set of extraction rules on the set of sentences that have satisfied the MC</definiens>
			</definition>
			<definition id="6">
				<sentence>Our ODQA AE needs a grammatically well-structured text to extract correctly the answers .</sentence>
				<definiendum id="0">ODQA AE</definiendum>
			</definition>
</paper>

		<paper id="1656">
			<definition id="0">
				<sentence>Thus , URES utilizes a more expressive extraction pattern language , which enables it to extract information from a broader set of sentences .</sentence>
				<definiendum id="0">URES</definiendum>
				<definiens id="0">utilizes a more expressive extraction pattern language , which enables it to extract information from a broader set of sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>Snowball is an unsupervised system for learning relations from document collections .</sentence>
				<definiendum id="0">Snowball</definiendum>
			</definition>
			<definition id="2">
				<sentence>KnowItAll is a system developed at University of Washington by Oren Etzioni and colleagues ( Etzioni , Cafarella et al. 2005 ) .</sentence>
				<definiendum id="0">KnowItAll</definiendum>
			</definition>
			<definition id="3">
				<sentence>Brief description of KnowItAll KnowItAll uses a set of generic extraction patterns , and automatically instantiates rules by combining those patterns with user supplied relation labels .</sentence>
				<definiendum id="0">KnowItAll KnowItAll</definiendum>
				<definiens id="0">uses a set of generic extraction patterns</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , KnowItAll has patterns for a generic “of” relation : NP1 &lt; relation &gt; NP2 NP1 's &lt; relation &gt; , NP2 NP2 , &lt; relation &gt; of NP1 474 where NP1 and NP2 are simple noun phrases that extract values of attribute1 and attribute2 of a relation , and &lt; relation &gt; is a user-supplied string associated with the relation .</sentence>
				<definiendum id="0">KnowItAll</definiendum>
				<definiens id="0">has patterns for a generic “of” relation : NP1 &lt; relation &gt; NP2 NP1 's &lt; relation &gt; , NP2 NP2 , &lt; relation &gt; of NP1 474 where NP1 and NP2 are simple noun phrases that extract values of attribute1 and attribute2 of a relation</definiens>
			</definition>
			<definition id="5">
				<sentence>KnowItAll includes a simple pattern learning scheme ( KnowItAll-PL ) that builds on the generic extraction mechanism ( KnowItAll-baseline ) .</sentence>
				<definiendum id="0">KnowItAll</definiendum>
				<definiens id="0">includes a simple pattern learning scheme ( KnowItAll-PL ) that builds on the generic extraction mechanism ( KnowItAll-baseline )</definiens>
			</definition>
			<definition id="6">
				<sentence>KnowItAll-PL creates a set of positive training sentences by downloading sentences that contain both argument values of a seed tuple and also the relation label .</sentence>
				<definiendum id="0">KnowItAll-PL</definiendum>
				<definiens id="0">creates a set of positive training sentences by downloading sentences that contain both argument values of a seed tuple and also the relation label</definiens>
			</definition>
			<definition id="7">
				<sentence>KnowItAll-PL retains the most general version of each pattern that has training frequency over a threshold and training precision over a threshold .</sentence>
				<definiendum id="0">KnowItAll-PL</definiendum>
				<definiens id="0">retains the most general version of each pattern that has training frequency over a threshold and training precision over a threshold</definiens>
			</definition>
			<definition id="8">
				<sentence>The Pattern Learner uses the seeds to learn likely patterns of relation occurrences .</sentence>
				<definiendum id="0">Pattern Learner</definiendum>
				<definiens id="0">uses the seeds to learn likely patterns of relation occurrences</definiens>
			</definition>
			<definition id="9">
				<sentence>Then , the Instance Extractor uses the patterns to extracts the instances from the sentences .</sentence>
				<definiendum id="0">Instance Extractor</definiendum>
				<definiens id="0">uses the patterns to extracts the instances from the sentences</definiens>
			</definition>
			<definition id="10">
				<sentence>The function does a dynamical programming search for the best match between the two patterns ( Optimal String Alignment algorithm ) , with the cost of the match defined as the sum of costs of matches for all elements .</sentence>
				<definiendum id="0">function</definiendum>
			</definition>
			<definition id="11">
				<sentence>Merger is a symmetric predicate , in the sense that the order of its attributes does not matter .</sentence>
				<definiendum id="0">Merger</definiendum>
				<definiens id="0">a symmetric predicate , in the sense that the order of its attributes does not matter</definiens>
			</definition>
			<definition id="12">
				<sentence>In this experiment we used Acquisition as the model predicate for testing all other predicates except itself .</sentence>
				<definiendum id="0">Acquisition</definiendum>
				<definiens id="0">the model predicate for testing all other predicates except itself</definiens>
			</definition>
</paper>

		<paper id="0406">
			<definition id="0">
				<sentence>Although our system still lacks a comprehensive specification of input format and semantics , we have already established on the basis of the above rationale that our original PA predicates must be decomposed into simpler , primitive predicates that expose their inter-relations .</sentence>
				<definiendum id="0">PA</definiendum>
			</definition>
			<definition id="1">
				<sentence>Finally , completeness is imposed by means of node feature axiom , upon which holds the invariant sem ( v ) ⇒ axiom ( v ) , ( 3 ) for every node v. The idea is to have axiom as a lexicalized feature and consistently assign it the neutralizing constant true for all lexical entries but those meant for the root node , in which case the value should equal the intended semantic content .</sentence>
				<definiendum id="0">invariant sem</definiendum>
				<definiens id="0">the root node , in which case the value should equal the intended semantic content</definiens>
			</definition>
			<definition id="2">
				<sentence>However , the set of potential daughters of a node v is best approximated by function dcands thus : dcands ( v ) = ( uniontext { 〈x〉 : x ∈ ran ( holes ( v ) ) } ) − { v } , where 〈x〉 denotes the coreference class of variable x ; and ran ( f ) , the range of function f. It is worth noticing that in generation dcands is known at model creation .</sentence>
				<definiendum id="0">〈x〉</definiendum>
			</definition>
			<definition id="3">
				<sentence>Each “big” conjunction is reduced to the form logicalandtext { f ( v ) : v ∈ V } , where V is a set variable of integer-encoded node identifiers , and modelled by a union selection constraint uniontext〈f ( 1 ) f ( 2 ) ... f ( M ) 〉 [ V ] , where M is the maximum node identifier and which constrains its result — a set variable — to be the union of f ( v ) for all v ∈ V ; • implications of the form x ⇒ y are implemented as y ⊆ x , while those of the form x → y as reify ( x ) ≤ reify ( y ) , where the result of reify ( x ) is an integer-encoded boolean variable constrained to coincide with the truth-value of expression x. Our branch of the XDK now counts on two new principles , namely ( i ) Delete , which requires the Graph principle , creates doubles for the node attributes introduced by the latter , providing the illusion of deletion , and introduces features for sisterhood constraints ; and ( ii ) Compsem , imposing all constraints described in Section 3 .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">M</definiendum>
				<definiendum id="2">reify ( x )</definiendum>
				<definiens id="0">a set variable of integer-encoded node identifiers , and modelled by a union selection constraint uniontext〈f ( 1 ) f ( 2 ) ... f ( M ) 〉 [ V ] , where</definiens>
				<definiens id="1">the maximum node identifier and which constrains its result — a set variable — to be the union of f ( v ) for all v ∈ V ; • implications of the form x ⇒ y are implemented as y ⊆ x , while those of the form x → y as reify ( x ) ≤ reify ( y )</definiens>
			</definition>
</paper>

		<paper id="3109">
			<definition id="0">
				<sentence>This led us to the following equation : pθ ( fJ1 |eI1 ) = α ( eI1 ) summationdisplay K , ˜aK1 Kproductdisplay k=1 p ( ˜fk|˜ek ) ( 4 ) In both cases the model parameters that have to be estimated are the translation probabilities between phrase pairs ( θ = { p ( ˜f|˜e ) } ) , which typically are estimated as follows : p ( ˜f|˜e ) = N ( ˜f , ˜e ) N ( ˜e ) ( 5 ) 65 where N ( ˜f|˜e ) is the number of times that ˜f have been seen as a translation of ˜e within the training corpus .</sentence>
				<definiendum id="0">N ( ˜f|˜e</definiendum>
				<definiens id="0">˜f|˜e ) } ) , which typically are estimated as follows : p ( ˜f|˜e )</definiens>
				<definiens id="1">the number of times that ˜f have been seen as a translation of ˜e within the training corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>The expansion process consists of the application of a set of operators over the best hypothesis in the stack , as it is depicted in Figure 1 .</sentence>
				<definiendum id="0">expansion process</definiendum>
				<definiens id="0">consists of the application of a set of operators over the best hypothesis in the stack</definiens>
			</definition>
			<definition id="2">
				<sentence>The granularity parameter determines the number of stacks used during the decoding process .</sentence>
				<definiendum id="0">granularity parameter</definiendum>
				<definiens id="0">determines the number of stacks used during the decoding process</definiens>
			</definition>
			<definition id="3">
				<sentence>The granularity ( G ) of a generalized stack algorithm is an integer which takes values between 1 and J , where J is the number of words which compose the sentence to translate .</sentence>
				<definiendum id="0">granularity ( G</definiendum>
				<definiens id="0">an integer which takes values between 1 and J , where J is the number of words which compose the sentence to translate</definiens>
			</definition>
</paper>

		<paper id="0501">
			<definition id="0">
				<sentence>In the current version ( 4.0 ) the CIDOC includes 84 taxonomically structured concepts ( called entities ) and a flat set of 141 semantic relations , called properties .</sentence>
				<definiendum id="0">CIDOC</definiendum>
			</definition>
			<definition id="1">
				<sentence>Properties are defined in terms of domain ( the class for which a property is formally defined ) and range ( the class that comprises all potential values of a property ) , e.g. : P46 is composed of ( forms part of ) Domain : E19 Physical Object Range : E42 Object Identifier The CIDOC is an “informal” resource .</sentence>
				<definiendum id="0">Properties</definiendum>
				<definiendum id="1">CIDOC</definiendum>
				<definiens id="0">an “informal” resource</definiens>
			</definition>
			<definition id="2">
				<sentence>Then , for each annotated fragment , we extract a semantic relation instance R ( C t , C w ) , where R is a relation in O , C t and C w are respectively the domain and range of R. The concept C t corresponds to its lexical realization t , while C w is the concept associated to the “head” word w in the annotated segment of the glos .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">a relation in O</definiens>
			</definition>
			<definition id="3">
				<sentence>P is the part-of-speech tag chosen by TreeTager for word w i , and P = { N , A , V , J , R , C , P , S , W } is a simplified set of syntactic categories ( respectively , nouns , articles , verbs , adjectives , adverbs , conjunctions , prepositions , 5 TreTager is available at : htp : /ww .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">TreTager</definiendum>
				<definiens id="0">A , V , J , R , C , P , S , W } is a simplified set of syntactic categories ( respectively , nouns , articles , verbs , adjectives</definiens>
			</definition>
			<definition id="4">
				<sentence>We augmented TreeTagger with the ability to capture named entities of locations , organizations , persons , numbers and time expressions .</sentence>
				<definiendum id="0">TreeTagger</definiendum>
				<definiens id="0">with the ability to capture named entities of locations , organizations , persons , numbers and time expressions</definiens>
			</definition>
			<definition id="5">
				<sentence>3 R kind-of * ( C d , C t ) and R kind-of * ( C r , C w ) 7 More formally , the annotation process is defined as folows : A relation checker c R for a property R is a logical expression composed with constraint predicates and logical conectives , using the folowing production rules : c R → s D ( f , semantic-domain ) ! ``</sentence>
				<definiendum id="0">R kind-of *</definiendum>
				<definiens id="0">A relation checker c R for a property R is a logical expression composed with constraint predicates and logical conectives , using the folowing production rules : c R → s D ( f</definiens>
			</definition>
			<definition id="6">
				<sentence>c R ’ ) | ( c R ’ c R ’ ) c R ’ → p ( f , pos-string ) | l ( f , k , lexical-constraint ) | s ( f , k , semantic-range ) where f is a variable representing a sentence fragment .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">( c R ’ c R ’ ) c R ’ → p ( f , pos-string ) | l ( f , k , lexical-constraint ) | s ( f , k</definiens>
				<definiens id="1">a variable representing a sentence fragment</definiens>
			</definition>
			<definition id="7">
				<sentence>Checker ( 1 ) recognizes , among others , the folowing fragments ( the words whose part-of7 R kind-of * denotes zero , one , or more aplications of R kind-of .</sentence>
				<definiendum id="0">folowing fragments</definiendum>
			</definition>
			<definition id="8">
				<sentence>In general , for each glos G defining a concept C t , 4 and for each fragment f ∈ F R of G annotated with the property R : &lt; R &gt; f &lt; /R &gt; , it is posible to extract one or more property instances in the form of a triple R ( C t , C w ) , where C w is the concept asociated with a term or multi-word expression w occurring in f ( i.e. its language realization ) and C t is the concept asociated to the defined term t in AT .</sentence>
				<definiendum id="0">C w</definiendum>
				<definiens id="0">fragment f ∈ F R of G annotated with the property R : &lt; R &gt; f &lt; /R &gt;</definiens>
				<definiens id="1">posible to extract one or more property instances in the form of a triple R ( C t</definiens>
			</definition>
			<definition id="9">
				<sentence>As a result , the folowing triple is produced : R has-curent-or-former-location ( Venetian_lace # 1 , Venice : city # 1 ) where Venetian_ lace # 1 is the concept label generated for the term Venetian lace in the AT and Venice is an instance of the concept city # 1 ( city , metropolis , urban center ) in WordNet .</sentence>
				<definiendum id="0">R has-curent-or-former-location</definiendum>
				<definiendum id="1">Venice</definiendum>
				<definiens id="0">metropolis , urban center ) in WordNet</definiens>
			</definition>
			<definition id="10">
				<sentence>Given a property R , labeled precision is the number of words annotated correctly with R over the number of words annotated automatically with R , while labeled recal is the number of words annotated correctly with R over the total number of words manually annotated with R. Table 3 shows the results obtained by applying the checkers to tag the test set ( containing a total number of 1,328 distinct annotations and 5,965 annotated words ) .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the number of words annotated correctly with R over the number of words annotated automatically with R , while labeled recal is the number of words annotated correctly with R over the total number of words manually annotated with R. Table 3 shows the results obtained by applying the checkers to tag the test set ( containing a total number of 1,328 distinct annotations and 5,965 annotated words</definiens>
			</definition>
</paper>

		<paper id="1667">
			<definition id="0">
				<sentence>This method can address two difficulties encoutered in Hasegawa et al. ( 2004 ) ’s hierarchical clustering : no consideration of manifold structure in data , and requirement to provide cluster number by users .</sentence>
				<definiendum id="0">hierarchical clustering</definiendum>
				<definiens id="0">no consideration of manifold structure in data , and requirement to provide cluster number by users</definiens>
			</definition>
			<definition id="1">
				<sentence>Let X = { xi } ni=1 be the set of context vectors of occurrences of all entity mention pairs , where xi represents the context vector of the i-th occurrence , and n is the total number of occurrences of all entity pairs .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the total number of occurrences of all entity pairs</definiens>
			</definition>
			<definition id="2">
				<sentence>Input : A set of context vectors X = { x1 , x2 , ... , xn } , X ∈Rfracturn×d ; Output : Clustered data and number of clusters ; 2 ij σ2 ) if i negationslash=j , 0 if i = j. Here , s ij is the similarity between xi and xj calculated by Cosine similarity measure .</sentence>
				<definiendum id="0">Input</definiendum>
				<definiens id="0">A set of context vectors X = { x1 , x2 , ... , xn }</definiens>
			</definition>
			<definition id="3">
				<sentence>and the free distance parameter σ2 is used to scale the weights ; D−1/2AD−1/2 , where D is a diagonal matrix whose ( i , i ) element is the sum of A’s ith row ; Arrange them in a matrix Y .</sentence>
				<definiendum id="0">D</definiendum>
				<definiens id="0">a diagonal matrix whose ( i , i ) element is the sum of A’s ith row ; Arrange them in a matrix Y</definiens>
			</definition>
			<definition id="4">
				<sentence>Table 1 shows the details of the whole algorithm for context clustering , which contains two main stages : 1 ) Transformation of Clustering Space ( Step 1-4 ) ; 2 ) Clustering in the transformed space using Elongated K-means algorithm ( Step 5-6 ) .</sentence>
				<definiendum id="0">context clustering</definiendum>
				<definiens id="0">contains two main stages : 1</definiens>
			</definition>
			<definition id="5">
				<sentence>The elongated K-means algorithm computes the distance of point x from the center ci as follows : • If the center is not very near the origin , cTi ci &gt; epsilon1 ( epsilon1 is a parameter to be fixed by the user ) , the distances are cal570 -4 -3 -2 -1 0 1 2 3 4-4 -3 -2 -1 0 1 2 3 4 ( a ) -4 -3 -2 -1 0 1 2 3 4-4 -3 -2 -1 0 1 2 3 4 ( b ) 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08-0.08 -0.06 -0.04 -0.02 0 ( c ) -4 -3 -2 -1 0 1 2 3 4-4 -3 -2 -1 0 1 2 3 4 ( d ) Figure 1 : An Example : ( a ) The Three Circle Dataset .</sentence>
				<definiendum id="0">epsilon1</definiendum>
				<definiens id="0">a parameter to be fixed by the user</definiens>
			</definition>
			<definition id="6">
				<sentence>( triangle , ◦ and + denote examples in different clusters ) culated as : edist ( x , ci ) = ( x − ci ) TM ( x− ci ) , where M = 1λ ( Iq − cicTicT i ci ) +λcicTicT i ci , λ is the sharpness parameter that controls the elongation ( the smaller , the more elongated the clusters ) 2 .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiens id="0">examples in different clusters ) culated as : edist ( x , ci ) = ( x − ci ) TM ( x− ci )</definiens>
				<definiens id="1">the sharpness parameter that controls the elongation ( the smaller , the more elongated the clusters ) 2</definiens>
			</definition>
			<definition id="7">
				<sentence>P W is the within-cluster scatter matrix as : PW = summationtextcj=1summationtextX i∈χj ( Xi − mj ) ( Xi − mj ) t and PB is the between-cluster scatter matrix as : PB = summationtextcj=1 ( mj − m ) ( mj − m ) t , where m is the total mean vector and mj is the mean vector for jth cluster and ( Xj − mj ) t is the matrix transpose of the column vector ( Xj −mj ) .</sentence>
				<definiendum id="0">P W</definiendum>
				<definiendum id="1">PB</definiendum>
				<definiendum id="2">m</definiendum>
				<definiendum id="3">mj</definiendum>
				<definiens id="0">the within-cluster scatter matrix as : PW = summationtextcj=1summationtextX i∈χj ( Xi − mj ) ( Xi − mj ) t and</definiens>
				<definiens id="1">the between-cluster scatter matrix as : PB = summationtextcj=1</definiens>
				<definiens id="2">the total mean vector and</definiens>
				<definiens id="3">the mean vector for jth cluster</definiens>
			</definition>
			<definition id="8">
				<sentence>Relation Dectection Relation Classification on Types on Subtypes Method P R F P R F P R F Culotta and Soresen ( 2004 ) Tree kernel based 81.2 51.8 63.2 67.1 35.0 45.8 Kambhatla ( 2004 ) Feature based , Maximum Entropy 63.5 45.2 52.8 Zhou et al. ( 2005 ) Feature based , SVM 84.8 66.7 74.7 77.2 60.7 68.0 63.1 49.5 55.5 the cluster number as the number of ground truth classes .</sentence>
				<definiendum id="0">Relation Dectection</definiendum>
				<definiens id="0">Relation Classification on Types on Subtypes Method P R F P R F P R F Culotta</definiens>
			</definition>
</paper>

		<paper id="1622">
			<definition id="0">
				<sentence>fined as : D ( xi , xj ) = √√√ √ Σ ( ar ( xi ) ) -ar ( xj ) ) 2 where r=1 to n ( n = number of different classifications ) , and ar ( x ) is the r-th feature of instance x. If instances xi and xj are identical , then D ( xi , xj ) =0 otherwise D ( xi , xj ) represents the vector distance between xi and xj .</sentence>
				<definiendum id="0">ar ( x )</definiendum>
				<definiens id="0">the vector distance between xi and xj</definiens>
			</definition>
			<definition id="1">
				<sentence>The classification function is F^ ( xq ) &lt; argmaxΣδ ( v , f ( xi ) ) where i =1 to k , v =1 to m ( m = size of training data ) , δ ( a , b ) =1 if a=b , 0 otherwise ; and v denotes a semantic role for each instance of training data. Computational complexity for kNN is linear , such that TkNN - &gt; O ( m * n ) , which is proportional to the product of the number of features ( m ) and the number of training instances ( n ) .</sentence>
				<definiendum id="0">v</definiendum>
				<definiens id="0">F^ ( xq ) &lt; argmaxΣδ ( v , f ( xi ) ) where i =1 to k , v =1 to m ( m = size of training data</definiens>
			</definition>
			<definition id="2">
				<sentence>Examination of the details of execution time ( described in the results section of this paper ) show that a plot of the execution time exhibits logarithmic characteristics , implying that the computational complexity for PML is log-linear , such that TPML - &gt; O ( m * log n ) where m denotes the size of features and n denotes the size of training data .</sentence>
				<definiendum id="0">O</definiendum>
				<definiendum id="1">m</definiendum>
				<definiens id="0">execution time ( described in the results section of this paper ) show that a plot of the execution time exhibits logarithmic characteristics , implying that the computational complexity for PML is log-linear , such that TPML - &gt;</definiens>
				<definiens id="1">the size of training data</definiens>
			</definition>
			<definition id="3">
				<sentence>Precision ( p ) is the proportion of arguments predicated by the system that are correct .</sentence>
				<definiendum id="0">Precision ( p )</definiendum>
				<definiens id="0">the proportion of arguments predicated by the system that are correct</definiens>
			</definition>
			<definition id="4">
				<sentence>Recall ( r ) is the proportion of correct arguments in the dataset that are predicated by the system .</sentence>
				<definiendum id="0">Recall ( r )</definiendum>
				<definiens id="0">the proportion of correct arguments in the dataset that are predicated by the system</definiens>
			</definition>
			<definition id="5">
				<sentence>If phrase type of the predicate ==NP find the boundary area ( the NP clause ) find RB ( POS ) before predicate and add to boundary list .</sentence>
				<definiendum id="0">RB</definiendum>
				<definiens id="0">predicate and add to boundary list</definiens>
			</definition>
			<definition id="6">
				<sentence>Specifically , the following have been demonstrated : scores with considerably faster execution times ( compared to Gildea &amp; Jurasky , 2002 ) for the Semantic role labeling problem using the Priority Maximum Likelihood instance-based learning algorithm and the Tree-based Predicate-Argument Algorithm ( PARA ) as a preprocessing step , without any training given a state-of-the-art parser such as Charniak’s parser .</sentence>
				<definiendum id="0">Tree-based Predicate-Argument Algorithm</definiendum>
				<definiens id="0">a preprocessing step , without any training given a state-of-the-art parser such as Charniak’s parser</definiens>
			</definition>
			<definition id="7">
				<sentence>kNN , where the computational complexity for PML is O ( m * log n ) as opposed to O ( m * n ) for kNN , where m denotes the number of features and n denotes the number of training instances .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">the number of features and n denotes the number of training instances</definiens>
			</definition>
</paper>

		<paper id="1203">
			<definition id="0">
				<sentence>Identifying non-compositional ( or idiomatic ) multi-word expressions ( MWEs ) is an important subtask for any computational system ( Sag et al. , 2002 ) , and significant attention has been paid to practical methods for solving this problem in recent years ( Lin , 1999 ; Baldwin et al. , 2003 ; Villada Moir´on and Tiedemann , 2006 ) .</sentence>
				<definiendum id="0">idiomatic ) multi-word expressions ( MWEs )</definiendum>
				<definiens id="0">an important subtask for any computational system ( Sag et al.</definiens>
			</definition>
			<definition id="1">
				<sentence>Multiword expressions : A pain in the neck for NLP .</sentence>
				<definiendum id="0">Multiword expressions</definiendum>
				<definiens id="0">A pain in the neck for NLP</definiens>
			</definition>
</paper>

		<paper id="1630">
			<definition id="0">
				<sentence>one can either only use the phonetic model , which does not depend on the sample size ; or else one must expand the data set and hope for more occurrence .</sentence>
				<definiendum id="0">phonetic model</definiendum>
				<definiens id="0">does not depend on the sample size ; or else one must expand the data set and hope for more occurrence</definiens>
			</definition>
</paper>

		<paper id="3402">
			<definition id="0">
				<sentence>Each part of speech ( POS ) is taken to be a feature , whose value is a count of the number of occurrences in the given utterance .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">a count of the number of occurrences in the given utterance</definiens>
			</definition>
</paper>

		<paper id="1414">
			<definition id="0">
				<sentence>The WYSIWYM interface presents the contents of a knowledge base to the user in the form of a natural language feedback text .</sentence>
				<definiendum id="0">WYSIWYM interface</definiendum>
				<definiens id="0">presents the contents of a knowledge base to the user in the form of a natural language feedback text</definiens>
			</definition>
			<definition id="1">
				<sentence>As a query-formulation method , WYSIWYM provides most of the advantages of NLIDBs , but overcomes the problems associated with natural language interpretation and of users attempting to pose questions that are beyond the capability of the system or , conversely , refraining from asking useful questions that are in fact within the system’s capability .</sentence>
				<definiendum id="0">WYSIWYM</definiendum>
				<definiens id="0">provides most of the advantages of NLIDBs , but overcomes the problems associated with natural language interpretation and of users attempting to pose questions that are beyond the capability of the system or</definiens>
			</definition>
			<definition id="2">
				<sentence>Similarly , numerical entities can have the semantic type : age , time ( year , month , hour ) , length , 97 OrgName Sem : organisation Lex : insurance company Morph : proper noun Phone # … Extension … StateName Sem : location Lex : state Morph : proper noun Type : descriptive Arity : n to 1 Sem : location Lex : be located in Frame : NP-VB-NP Table 1 Type : attributive Sem : possession Lex : have Frame : NP-VB-NP Type : attributive Sem : possession Lex : have Frame : NP-VB-NP Table 2 Figure 2 : Example of a semantic graph weight , value , height .</sentence>
				<definiendum id="0">possession Lex</definiendum>
				<definiendum id="1">Lex</definiendum>
				<definiens id="0">descriptive Arity : n to 1 Sem : location Lex</definiens>
				<definiens id="1">attributive Sem : possession</definiens>
			</definition>
</paper>

		<paper id="1520">
</paper>

		<paper id="3406">
			<definition id="0">
				<sentence>Among other features , Ciranda provides an easy interface for feature extraction and feature selection , outputs the prediction confidence , and allows retraining using several learning algorithms .</sentence>
				<definiendum id="0">Ciranda</definiendum>
				<definiens id="0">provides an easy interface for feature extraction and feature selection , outputs the prediction confidence</definiens>
			</definition>
			<definition id="1">
				<sentence>Very briefly , a Request asks the recipient to perform some activity ; a Propose message proposes a joint activity ( i.e. , asks the recipient to perform some activity and commits the sender ) ; a Commit message commits the sender to some future course of action ; Data is information , or a pointer to information , delivered to the recipient ; and a Meeting is a joint activity that is constrained in time and ( usually ) space .</sentence>
				<definiendum id="0">Request</definiendum>
				<definiendum id="1">Propose message</definiendum>
				<definiendum id="2">Meeting</definiendum>
				<definiens id="0">information , or a pointer to information , delivered to the recipient ; and a</definiens>
			</definition>
			<definition id="2">
				<sentence>Its values ranges from -1 ( complete disagreement ) to +1 ( perfect agreement ) and it is defined as ( A-R ) / ( 1-R ) , where A is the empirical probability of agreement on a category , and R is the probability of agreement for two annotators that 36 label documents at random ( with the empirically observed frequency of each label ) .</sentence>
				<definiendum id="0">A</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">the empirical probability of agreement on a category , and</definiens>
			</definition>
</paper>

		<paper id="2807">
</paper>

		<paper id="0114">
			<definition id="0">
				<sentence>The annotation of our corpus consists of transcription , segmental annotation , and prosodic annotation .</sentence>
				<definiendum id="0">annotation of our corpus</definiendum>
				<definiens id="0">consists of transcription , segmental annotation , and prosodic annotation</definiens>
			</definition>
			<definition id="1">
				<sentence>We transcription and segmentation we used BSCA ( Broadcasting Speech Corpus Annotator ) which was designed by ourselves ( Hu Fengguo and Zou Yu 2005 ) .</sentence>
				<definiendum id="0">BSCA</definiendum>
			</definition>
			<definition id="2">
				<sentence>The labels of the break tier occurring times are shown in table 2 : Table 2 the labels of the break tier occurring in 4 hours annotated corpora Break index Occurrence 1 1512 2 2998 3 1986 4 740 Stress is a significant prosodic feature .</sentence>
				<definiendum id="0">Stress</definiendum>
				<definiens id="0">a significant prosodic feature</definiens>
			</definition>
			<definition id="3">
				<sentence>In line with Shen Jiong’s view about intonation ( Shen Jiong 1994 ) , we found that the intonation construction tier is an important component of the annotation of discourses ( Chen Yudong 2004 ) .</sentence>
				<definiendum id="0">intonation construction tier</definiendum>
			</definition>
</paper>

		<paper id="1708">
			<definition id="0">
				<sentence>The matching process starts from a pair of ontologies to be aligned .</sentence>
				<definiendum id="0">matching process</definiendum>
				<definiens id="0">starts from a pair of ontologies to be aligned</definiens>
			</definition>
			<definition id="1">
				<sentence>A signature is defined as a function S : K → R+ , mapping a finite set of keys ( which can be complex objects ) to positive real values .</sentence>
				<definiendum id="0">signature</definiendum>
				<definiens id="0">a function S : K → R+ , mapping a finite set of keys ( which can be complex objects ) to positive real values</definiens>
			</definition>
			<definition id="2">
				<sentence>WordNet is a dictionary where words are linked together by semantic relationships .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a dictionary where words are linked together by semantic relationships</definiens>
			</definition>
			<definition id="3">
				<sentence>The final signature has the form of a mapping synset → value , where value is a weighted sum of all the synsets found .</sentence>
				<definiendum id="0">value</definiendum>
				<definiens id="0">a weighted sum of all the synsets found</definiens>
			</definition>
			<definition id="4">
				<sentence>The experiments have been run with several combinations of the relevant parameters : number of instance documents per node ( 5 or 10 ) , algorithm ( 1 to 4 ) , extracted parts of speech ( nouns , verbs , or both ) , hypernym level ( an integer value equal or greater than zero ) , hypernym factor ( a real number ) , and context length ( an integer number equal or greater than zero ) .</sentence>
				<definiendum id="0">hypernym level</definiendum>
				<definiens id="0">a real number ) , and context length ( an integer number equal or greater than zero )</definiens>
			</definition>
			<definition id="5">
				<sentence>The average of A represents the expected score that the system would assign to a match ; likewise , the average of B is the expected score of a non-match .</sentence>
				<definiendum id="0">average of A</definiendum>
				<definiens id="0">the expected score of a non-match</definiens>
			</definition>
			<definition id="6">
				<sentence>Algorithm 3 ( WordNet signature ) , which introduces some additional level of semantics , has even better performance .</sentence>
				<definiendum id="0">WordNet signature )</definiendum>
				<definiens id="0">introduces some additional level of semantics</definiens>
			</definition>
			<definition id="7">
				<sentence>WordNet is a very general lexicon that does not support domain specific vocabulary , such as that used in geosciences or in medicine or simply that contained in a subontology that users may define according to their interests .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="1317">
			<definition id="0">
				<sentence>Resemblance : similarity ( par ) , contrast ( contr ) , example ( examp ) , generalization ( gen ) , elaboration ( elab ) ; expectation ( expv ) , condition ( cond ) ; contexts .</sentence>
				<definiendum id="0">Resemblance</definiendum>
				<definiens id="0">similarity ( par ) , contrast ( contr ) , example ( examp ) , generalization ( gen )</definiens>
			</definition>
			<definition id="1">
				<sentence>Event annotation follows version 1.2.1 of the TimeML specifications.4 Modal parsing in the form of identifying subordinating verb relations and their type was performed using SlinkET ( Saur´ı et al. , 2006 ) , another component of the TARSQI framework .</sentence>
				<definiendum id="0">Event annotation</definiendum>
				<definiens id="0">follows version 1.2.1 of the TimeML specifications.4 Modal parsing in the form of identifying subordinating verb relations</definiens>
			</definition>
			<definition id="2">
				<sentence>SlinkET identifies subordination constructions introducing modality information in text ; essentially , infinitival and that-clauses embedded by factive predicates ( regret ) , reporting predicates ( say ) , and predicates referring to events of attempting ( try ) , volition ( want ) , command ( order ) , among others .</sentence>
				<definiendum id="0">SlinkET</definiendum>
				<definiens id="0">identifies subordination constructions introducing modality information in text ; essentially , infinitival and that-clauses embedded by factive predicates ( regret ) , reporting predicates ( say ) , and predicates referring to events of attempting ( try ) , volition ( want ) , command</definiens>
			</definition>
			<definition id="3">
				<sentence>Resemblance relations , in particular , require similar entities to be involved and lexical similarity here serves as an approximation to definite nominal coreference .</sentence>
				<definiendum id="0">Resemblance relations</definiendum>
				<definiens id="0">an approximation to definite nominal coreference</definiens>
			</definition>
			<definition id="4">
				<sentence>Lexical similarity was computed using the Word Sketch Engine ( WSE ) ( Killgarrif et al. , 2004 ) similarity metric applied over British National Corpus .</sentence>
				<definiendum id="0">Word Sketch Engine</definiendum>
				<definiens id="0">Killgarrif et al. , 2004 ) similarity metric applied over British National Corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>The BSO is a lexicallybased ontology in the Generative Lexicon tradition ( Pustejovsky , 2001 ; Pustejovsky , 1995 ) .</sentence>
				<definiendum id="0">BSO</definiendum>
				<definiens id="0">a lexicallybased ontology in the Generative Lexicon tradition</definiens>
			</definition>
			<definition id="6">
				<sentence>The BSO contains ontological qualia information ( shown below ) .</sentence>
				<definiendum id="0">BSO</definiendum>
			</definition>
			<definition id="7">
				<sentence>Tlink Temporal links between events in the two segments .</sentence>
				<definiendum id="0">Tlink Temporal</definiendum>
			</definition>
			<definition id="8">
				<sentence>The task of identifying the presence of a relation is complicated by the fact that we must consider all a25a27a26 a11a29a28 potential relations where a30 is the number of segments .</sentence>
				<definiendum id="0">a30</definiendum>
				<definiens id="0">the number of segments</definiens>
			</definition>
</paper>

		<paper id="2925">
			<definition id="0">
				<sentence>Finally , let Y ( x ) be the space of well-formed dependency trees for x. A dependency tree y ∈ Y ( x ) is a set of n dependencies of the form [ h , m , l ] , where h is the index of the head word ( 0 ≤ h ≤ n , where 0 means root ) , m is the index of the modifier word ( 1 ≤ m ≤ n ) , and l is the dependency label ( 1 ≤ l ≤ L ) .</sentence>
				<definiendum id="0">m</definiendum>
				<definiendum id="1">l</definiendum>
				<definiens id="0">a set of n dependencies of the form [ h , m , l ] , where h is the index of the head word ( 0 ≤ h ≤ n , where 0 means root )</definiens>
				<definiens id="1">the index of the modifier word ( 1 ≤ m ≤ n ) , and</definiens>
				<definiens id="2">the dependency label ( 1 ≤ l ≤ L )</definiens>
			</definition>
			<definition id="1">
				<sentence>Each word of x participates as a modifier in exactly one dependency of y. Our dependency parser , dp , returns the maximum scored dependency tree for a sentence x : dp ( x , w ) = argmax y∈Y ( x ) summationdisplay [ h , m , l ] ∈y sco ( [ h , m , l ] , x , y , w ) In the formula , w is the weight vector of the parser , that is , the set of parameters used to score dependencies during the parsing process .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">a modifier in exactly one dependency of y. Our dependency parser , dp , returns the maximum scored dependency tree for a sentence x : dp ( x , w ) = argmax y∈Y ( x ) summationdisplay [ h , m , l ] ∈y sco ( [ h , m , l ] , x , y , w</definiens>
				<definiens id="1">the set of parameters used to score dependencies during the parsing process</definiens>
			</definition>
			<definition id="2">
				<sentence>The scoring function is defined as follows : sco ( [ h , m , l ] , x , y , w ) = φ ( h , m , x , y ) · wl Note that the scoring of a dependency makes use of y , the tree that contains the dependency .</sentence>
				<definiendum id="0">scoring function</definiendum>
				<definiens id="0">follows : sco ( [ h , m , l ] , x , y , w ) = φ ( h , m , x , y ) · wl Note that the scoring of a dependency makes use of y , the tree that contains the dependency</definiens>
			</definition>
			<definition id="3">
				<sentence>In recent years , Perceptron has been used in a number of Natural Language Learning works , such as in w = 0 for t = 1 to T foreach training example ( x , y ) do ˆy = dp ( x , w ) foreach [ h , m , l ] ∈ y\ˆy do wl = wl +φ ( h , m , x , ˆy ) foreach [ h , m , l ] ∈ ˆy\y do wl = wl −φ ( h , m , x , ˆy ) return w Figure 1 : Pseudocode of the Perceptron Algorithm .</sentence>
				<definiendum id="0">Perceptron</definiendum>
				<definiens id="0">used in a number of Natural Language Learning works , such as in w = 0 for t = 1 to T foreach training example ( x , y ) do ˆy = dp ( x , w</definiens>
			</definition>
			<definition id="4">
				<sentence>Perceptron is an online learning algorithm that learns by correcting mistakes made by the parser when visiting training sentences .</sentence>
				<definiendum id="0">Perceptron</definiendum>
				<definiens id="0">an online learning algorithm that learns by correcting mistakes made by the parser when visiting training sentences</definiens>
			</definition>
			<definition id="5">
				<sentence>Our feature extraction patterns , that exploit both lexicalization and combination , generate millions of feature dimensions , even with small datasets .</sentence>
				<definiendum id="0">feature extraction patterns</definiendum>
				<definiens id="0">generate millions of feature dimensions</definiens>
			</definition>
</paper>

		<paper id="1412">
			<definition id="0">
				<sentence>DG : you can currently see three buttons ... there’s actually a fourth button that’s kind of hidden DF : yeah DG : by this cabinet on the right DF : I know , yeah DG : ok , um , so what you wan na do is you want to go in and you’re gon na press one of the buttons that’s on the right hand wall , so you wan na go all the way straight into the room and then face the wall DF : mhm DG : there with the two buttons DF : yep DG : um and you wan na push the one that’s on the left Figure 1 : Sample dialog fragment and accompanying video frame His partner , the direction-giver ( DG ) , had a paper 2D map of the world and a list of tasks to complete .</sentence>
				<definiendum id="0">DG</definiendum>
				<definiendum id="1">DG</definiendum>
				<definiens id="0">you can currently see three buttons ... there’s actually a fourth button that’s kind of hidden DF : yeah</definiens>
			</definition>
			<definition id="1">
				<sentence>Centering designates the backward-looking center ( Cb ) as the item in the current sentence that was most topical in the previous sentence .</sentence>
				<definiendum id="0">backward-looking center ( Cb</definiendum>
				<definiens id="0">the item in the current sentence that was most topical in the previous sentence</definiens>
			</definition>
</paper>

		<paper id="2109">
			<definition id="0">
				<sentence>They can be de ned as follows : there is an X which undergoes a change of location , whereby X is in a particular manner of motion , moving into the speci ed direction relative to the position of the relatum .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">undergoes a change of location , whereby</definiens>
			</definition>
			<definition id="1">
				<sentence>Group C consists of particle verbs which can be followed by a pleonastic PP in the accusative or dative .</sentence>
				<definiendum id="0">Group C</definiendum>
				<definiens id="0">consists of particle verbs which can be followed by a pleonastic PP in the accusative or dative</definiens>
			</definition>
			<definition id="2">
				<sentence>Sg in Det.Dat soil PART ’soaks the soil’ Example ( 9 ) describes an event where an X 60 ( rainwater ) undergoes a directed motion during which it enters into the region of the reference object Y ( the soil ) .</sentence>
				<definiendum id="0">rainwater )</definiendum>
				<definiens id="0">undergoes a directed motion during which it enters into the region of the reference</definiens>
			</definition>
			<definition id="3">
				<sentence>On the syntactic level this results in them having a different grammatical function : the accusative PP can be considered as a verb complement , while the dative PP is a free adjunct , modifying the information of the verb particle .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">a free adjunct , modifying the information of the verb particle</definiens>
			</definition>
			<definition id="4">
				<sentence>( 11 ) S→ NP VP ( 12 ) ( ↑SUBJ ) =↓ ↑=↓ LFG is a non-transformational theory , syntactic phenomena are treated locally through the speci cation of rules and constraints in the lexicon .</sentence>
				<definiendum id="0">LFG</definiendum>
				<definiens id="0">a non-transformational theory , syntactic phenomena are treated locally through the speci cation of rules and constraints in the lexicon</definiens>
			</definition>
			<definition id="5">
				<sentence>The FORM attribute contains the lexical form of the particle and is formulated as a constraint ( =c ) to check that the particle is lexically lled .</sentence>
				<definiendum id="0">FORM attribute</definiendum>
				<definiens id="0">contains the lexical form of the particle and is formulated as a constraint ( =c ) to check that the particle is lexically lled</definiens>
			</definition>
			<definition id="6">
				<sentence>Figure 6 : Lexical entry ( Berman &amp; Frank , 1996 ) for auf ’on’ ( free adjunct ) We concentrate on the formalisation of the particle verbs in Group C which can either licence a pleonastic PP in the accusative or a PP in the dative .</sentence>
				<definiendum id="0">Lexical entry</definiendum>
			</definition>
			<definition id="7">
				<sentence>The attribute PCASE expresses the directionality in the semantics of the verb particle ( ( ↑PCASE ) = DIR ) .</sentence>
				<definiendum id="0">PCASE</definiendum>
				<definiens id="0">expresses the directionality in the semantics of the verb particle ( ( ↑PCASE ) = DIR )</definiens>
			</definition>
			<definition id="8">
				<sentence>The formalisation gives an adequate description of the behaviour of particle verbs in Group C , but it does not suppress the licencing of a pleonastic accusative PP for verbs in Group B which combine with locative PPs in the dative only .</sentence>
				<definiendum id="0">formalisation</definiendum>
				<definiens id="0">gives an adequate description of the behaviour of particle verbs in Group C , but it does not suppress the licencing of a pleonastic accusative PP for verbs in Group B which combine with locative PPs in the dative only</definiens>
			</definition>
			<definition id="9">
				<sentence>vorfahren V ( ↑PRED ) = ’vorfahren &lt; ( ↑SUBJ , ↑OBL DIR ) &gt; ’ ( ↑OBL DIR : PART-FORM ) = vor ( ↑OBL DIR : OBJ : CASE ) = acc ( ↑OBL DIR : OBJ : PRED ) =c PRO Figure 12 : Lexical entry for vorfahren ’to drive up’ ( Group B ) The constraint checks that the predicate of the object in the OBL DIR f-structure is instantiated with the value ’PRO’ .</sentence>
				<definiendum id="0">vorfahren V</definiendum>
				<definiens id="0">Lexical entry for vorfahren ’to drive up’ ( Group B ) The constraint checks that the predicate of the object in the OBL DIR f-structure is instantiated with the value ’PRO’</definiens>
			</definition>
</paper>

		<paper id="3202">
			<definition id="0">
				<sentence>s.t ( 7 ) X.r.C.s.t → C Rules of this type bear four features for a consonant C inside an onset or a coda ( X=On , Cod ) , namely : the position of the syllable in the word ( r=ini , med , fin , one ) , the current terminal node ( C = consonant ) , the succeeding consonant ( C+ ) , the cluster size ( t = 1 ... 5 ) , and the position of a consonant within a cluster ( s = 1 ... 5 ) .</sentence>
				<definiendum id="0">succeeding consonant</definiendum>
				<definiendum id="1">cluster size</definiendum>
				<definiens id="0">the position of the syllable in the word ( r=ini , med , fin , one ) , the current terminal node</definiens>
			</definition>
			<definition id="1">
				<sentence>Word accuracy is a very strict measure and does not depend on the number of syllables within a word .</sentence>
				<definiendum id="0">Word accuracy</definiendum>
				<definiens id="0">a very strict measure and does not depend on the number of syllables within a word</definiens>
			</definition>
			<definition id="2">
				<sentence>Then the word accuracy will be 50 % 15 transferring trA : ns–f3 : –rIN wet wEt Table 1 : Example : evaluation corpus transferring trA : n–sf3 : –rIN wet wEt Table 2 : Example : predicted boundaries ( 1 correct word2 words ) , the syllable accuracy will be 50 % ( 2 correct syllables4 syllables ) , and the syllable boundary accuracy is 75 % ( 3 correct syllable boundaries4 syllable boundaries ) .</sentence>
				<definiendum id="0">syllable boundary accuracy</definiendum>
			</definition>
			<definition id="3">
				<sentence>If we define the probability of a two-consonantal onset as p ( onset ini 2 ) =def p ( C1 ) ×p ( C2 ) where p ( C1 ) is the probability of the rule X.r.C1 .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the probability of the rule X.r.C1</definiens>
			</definition>
</paper>

		<paper id="2809">
			<definition id="0">
				<sentence>According to the English version of Wikipedia 2 , Wikipedia is a multi-lingual web-based , freecontent encyclopedia which is updated continuously in a collaborative way .</sentence>
				<definiendum id="0">Wikipedia</definiendum>
				<definiens id="0">a multi-lingual web-based , freecontent encyclopedia which is updated continuously in a collaborative way</definiens>
			</definition>
			<definition id="1">
				<sentence>Besides , EuroWordNet defines a language independent index called Inter-Lingual-Index ( ILI ) which allows to establish relations between words in wordnets of different languages .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
				<definiens id="0">defines a language independent index called Inter-Lingual-Index ( ILI ) which allows to establish relations between words in wordnets of different languages</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>Polysemy is indicated by the presence of translations with different senses , that is , where a collocation is the member of more than one sense group .</sentence>
				<definiendum id="0">collocation</definiendum>
				<definiens id="0">indicated by the presence of translations with different senses , that is , where a</definiens>
				<definiens id="1">the member of more than one sense group</definiens>
			</definition>
			<definition id="1">
				<sentence>The Studygram system in any case supports algorithm solutions ( called operations ) which can be procedure calls , which in this context would be to MultiCoDiCT .</sentence>
				<definiendum id="0">Studygram system</definiendum>
				<definiens id="0">called operations ) which can be procedure calls</definiens>
			</definition>
</paper>

		<paper id="1610">
			<definition id="0">
				<sentence>BLEU measures how close machine-generated translations are to professional human translations , and ROUGE does the same with respect to summaries .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiendum id="1">ROUGE</definiendum>
				<definiens id="0">measures how close machine-generated translations are to professional human translations</definiens>
			</definition>
			<definition id="1">
				<sentence>Being an $ 8 billion industry ( Browner , 2006 ) , MT calls for rapid development and the ability to differentiate good systems from less adequate ones .</sentence>
				<definiendum id="0">MT</definiendum>
				<definiens id="0">calls for rapid development and the ability to differentiate good systems from less adequate ones</definiens>
			</definition>
			<definition id="2">
				<sentence>BLEU is a precision-based metric , which is the ratio of the number of n-grams from the peer translation that occurred in reference translations to the total number of n-grams in the peer translation .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">a precision-based metric</definiens>
			</definition>
			<definition id="3">
				<sentence>The question becomes how to use contextual information to calculate semantic closeness between two phrases .</sentence>
				<definiendum id="0">question</definiendum>
				<definiens id="0">becomes how to use contextual information to calculate semantic closeness between two phrases</definiens>
			</definition>
</paper>

		<paper id="2709">
			<definition id="0">
				<sentence>We present ANNIS , a linguistic database that aims at facilitating the process of exploiting richly annotated language data by naive users .</sentence>
				<definiendum id="0">ANNIS</definiendum>
				<definiens id="0">a linguistic database that aims at facilitating the process of exploiting richly annotated language data by naive users</definiens>
			</definition>
			<definition id="1">
				<sentence>Data heterogeneity is a result of : ( i ) the language data to be annotated , varying with respect to size ( single sentences vs. narrations ) , modality ( monologue vs. dialogue , text vs. speech ) and language ; ( ii ) the annotations , which use different 1http : //www.sfb632.uni-potsdam.de/ .</sentence>
				<definiendum id="0">Data heterogeneity</definiendum>
				<definiens id="0">a result of : ( i ) the language data to be annotated , varying with respect to size ( single sentences vs. narrations ) , modality ( monologue vs. dialogue , text vs. speech</definiens>
			</definition>
			<definition id="2">
				<sentence>ANNIS is a Java servlet application that can be accessed via standard web browsers .</sentence>
				<definiendum id="0">ANNIS</definiendum>
				<definiens id="0">a Java servlet application that can be accessed via standard web browsers</definiens>
			</definition>
			<definition id="3">
				<sentence>Discourse studies The Potsdam Commentary Corpus , PCC ( Stede , 2004 ) , consists of 173 newspaper commentaries , annotated for morphosyntax , coreference , discourse structure according to Rhetorical Structure Theory , and information structure .</sentence>
				<definiendum id="0">Potsdam Commentary Corpus , PCC</definiendum>
				<definiens id="0">consists of 173 newspaper commentaries , annotated for morphosyntax , coreference , discourse structure according to Rhetorical Structure Theory , and information structure</definiens>
			</definition>
</paper>

		<paper id="2932">
</paper>

		<paper id="2207">
			<definition id="0">
				<sentence>Several approaches have been proposed in the context of word sense disambiguation ( Yarowsky , 1995 ) , named entity ( NE ) classification ( Collins and Singer , 1999 ) , patternacquisitionforIE ( Riloff,1996 ; Yangarber , 2003 ) , or dimensionality reduction for text categorization ( TC ) ( Yang and Pedersen , 1997 ) .</sentence>
				<definiendum id="0">entity</definiendum>
				<definiendum id="1">patternacquisitionforIE</definiendum>
				<definiens id="0">or dimensionality reduction for text categorization ( TC )</definiens>
			</definition>
			<definition id="1">
				<sentence>The algorithm output is a list R of rules p → y , where p is a pattern in the set of patterns P , and y a category label in Y = { 1 ... k } , k being the number of categories in the document collection .</sentence>
				<definiendum id="0">algorithm output</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">a pattern in the set of patterns P , and y a category label in Y = { 1 ... k } , k being the number of categories in the document collection</definiens>
			</definition>
			<definition id="2">
				<sentence>Similarlyto ( Collins and Singer , 1999 ; Yarowsky , 1995 ) , we define the strength of a pattern p in a category y as the precision of p in the set of documents labeled with category y , estimated using Laplace smoothing : strength ( p , y ) = count ( p , y ) + epsilon1count ( p ) + kepsilon1 ( 3 ) where count ( p , y ) is the number of documents labeled y containing pattern p , count ( p ) is the overall number of labeled documents containing p , and k is the number of domains .</sentence>
				<definiendum id="0">Similarlyto</definiendum>
				<definiendum id="1">count</definiendum>
				<definiendum id="2">y )</definiendum>
				<definiendum id="3">k</definiendum>
				<definiens id="0">the strength of a pattern p in a category y as the precision of p in the set of documents labeled with category y</definiens>
				<definiens id="1">the number of documents labeled y containing pattern p</definiens>
			</definition>
			<definition id="3">
				<sentence>Thispaperfocusesontheframeworkintroduced in Figure 2 for two reasons : ( a ) “cautious” al50 gorithms were shown to perform best for several NLP problems ( including acquisition of IE patterns ) , and ( b ) it has nice theoretical properties : Abney ( 2004 ) showed that , regardless of the selection procedure , “sequential” bootstrapping algorithms converge to a local minimum of K , where K is an upper bound of the negative log likelihood of the data .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">a ) “cautious” al50 gorithms were shown to perform best for several NLP problems ( including acquisition of IE patterns ) , and ( b ) it has nice theoretical properties : Abney ( 2004 ) showed that , regardless of the selection procedure , “sequential” bootstrapping algorithms converge to a local minimum of K , where</definiens>
			</definition>
			<definition id="4">
				<sentence>The intuition behind it is that a qualitative pattern is yielded by a compromise between pattern precision ( which is a good indicator of relevance ) and pattern frequency ( which is a good indicator of coverage ) .</sentence>
				<definiendum id="0">pattern frequency</definiendum>
				<definiens id="0">a qualitative pattern is yielded by a compromise between pattern precision ( which is a good indicator of relevance</definiens>
				<definiens id="1">a good indicator of coverage )</definiens>
			</definition>
			<definition id="5">
				<sentence>Criterion 3 : χ2 ( Chi ) The χ2 score measures the lack of independence between a pattern p and a category y. It is computed using a two-way contingency table of p and y , whereaisthenumberoftimespandy co-occur , b is the number of times p occurs without y , c is the number of times y occurs without p , and d is the number of times neither p nor y occur .</sentence>
				<definiendum id="0">χ2 score</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">measures the lack of independence between a pattern p and a category y. It is computed using a two-way contingency table of p and y , whereaisthenumberoftimespandy co-occur , b is the number of times p occurs without y ,</definiens>
				<definiens id="1">the number of times y occurs without p</definiens>
			</definition>
			<definition id="6">
				<sentence>( 9 ) MI ( p , y ) = log P ( p∧y ) P ( p ) ×P ( y ) ( 10 ) ≈ log na ( a + c ) ( a + b ) ( 11 ) For all experiments reported in this paper we used the following three document collections : ( a ) the AP collection is the Associated Press ( year 1999 ) subset of the AQUAINT collection ( LDC catalog number LDC2002T31 ) ; ( b ) the LATIMES collection is the Los Angeles Times subset of the TREC5 collection1 ; and ( c ) the REUTERS collection is the by now classic Reuters-21578 text categorization collection2 .</sentence>
				<definiendum id="0">REUTERS collection</definiendum>
				<definiens id="0">the Associated Press ( year 1999 ) subset of the AQUAINT collection ( LDC catalog number LDC2002T31 ) ; ( b ) the LATIMES collection is the Los Angeles Times subset of the TREC5 collection1</definiens>
				<definiens id="1">the by now classic Reuters-21578 text categorization collection2</definiens>
			</definition>
			<definition id="7">
				<sentence>Following the above processing steps , we extractSubject-Verb-Object ( SVO ) tuplesusingaseries of heuristics , e.g. : ( a ) nouns preceding active verbs are subjects , ( b ) nouns directly attached to a verb phrase are objects , ( c ) nouns attached to the verb phrase through a prepositional attachment are indirect objects .</sentence>
				<definiendum id="0">SVO</definiendum>
				<definiens id="0">nouns directly attached to a verb phrase are objects , ( c ) nouns attached to the verb phrase through a prepositional attachment are indirect objects</definiens>
			</definition>
			<definition id="8">
				<sentence>Patterns s ( ORG ) v ( beat ) v ( beat ) o ( ORG ) s ( ORG ) o ( ORG ) v ( beat ) io ( in game ) s ( ORG ) io ( in game ) o ( ORG ) io ( in game ) s ( ORG ) v ( beat ) o ( ORG ) s ( ORG ) v ( beat ) io ( in game ) v ( beat ) o ( ORG ) io ( in game ) Table 2 : Patterns extracted from one sample sentence .</sentence>
				<definiendum id="0">ORG</definiendum>
				<definiendum id="1">ORG</definiendum>
				<definiens id="0">) o ( ORG ) v ( beat ) io ( in game ) s ( ORG ) io ( in game ) o ( ORG ) io ( in game ) s ( ORG ) v</definiens>
			</definition>
			<definition id="9">
				<sentence>The quality of the generated classification is measured using micro-averaged precision and recall : P = summationtextq i=1 TruePositivesisummationtextq i=1 ( TruePositivesi + FalsePositivesi ) ( 12 ) R = summationtextq i=1 TruePositivesisummationtextq i=1 ( TruePositivesi + FalseNegativesi ) ( 13 ) where q is the number of categories in the document collection .</sentence>
				<definiendum id="0">q</definiendum>
				<definiens id="0">measured using micro-averaged precision and recall : P = summationtextq i=1 TruePositivesisummationtextq i=1 ( TruePositivesi + FalsePositivesi ) ( 12 ) R = summationtextq i=1 TruePositivesisummationtextq i=1 ( TruePositivesi + FalseNegativesi</definiens>
			</definition>
			<definition id="10">
				<sentence>Evaluation of the co-training system Figure 4 compares the performance of the stand-alone pattern acquisition algorithm ( “bootstrapping” ) with the performance of the acquisition algorithm trained in the co-training environ53 Precision Recall collins riloff chi mi ( a ) Precision Recall collins riloff chi mi ( b ) Precision Recall collins riloff chi mi ( c ) Figure 3 : Performance of the pattern acquisition algorithm for various pattern selection strategies and multiple collections : ( a ) AP , ( b ) LATIMES , and ( c ) REUTERS ment ( “co-training” ) .</sentence>
				<definiendum id="0">( c ) REUTERS ment</definiendum>
				<definiens id="0">a ) Precision Recall collins riloff chi mi ( b ) Precision Recall collins riloff chi mi</definiens>
			</definition>
			<definition id="11">
				<sentence>54 Precision Recall co-training bootstrapping baseline ( a ) Precision Recall co-training bootstrapping baseline ( b ) Precision Recall co-training bootstrapping baseline ( c ) Figure4 : Comparisonofthebootstrappingpatternacquisitionalgorithmwiththeco-trainingapproach : ( a ) AP , ( b ) LATIMES , and ( c ) REUTERS Baseline Co-training s ( he ) o ( game ) v ( win ) o ( title ) v ( miss ) o ( game ) s ( I ) v ( play ) v ( play ) o ( game ) s ( he ) v ( game ) v ( play ) io ( in LOC ) s ( we ) v ( play ) v ( go ) o ( be ) v ( miss ) o ( game ) s ( he ) v ( be ) s ( he ) v ( coach ) s ( that ) v ( be ) v ( lose ) o ( game ) s ( I ) v ( be ) s ( I ) o ( play ) s ( it ) v ( go ) o ( be ) v ( make ) o ( play ) s ( it ) v ( be ) v ( play ) io ( in game ) s ( I ) v ( think ) v ( want ) o ( play ) s ( I ) v ( know ) v ( win ) o ( MISC ) s ( I ) v ( want ) s ( he ) o ( player ) s ( there ) v ( be ) v ( start ) o ( game ) s ( we ) v ( do ) s ( PER ) o ( contract ) v ( do ) o ( it ) s ( we ) o ( play ) s ( it ) o ( be ) s ( team ) v ( win ) s ( we ) v ( are ) v ( rush ) io ( for yard ) s ( we ) v ( go ) s ( we ) o ( team ) s ( PER ) o ( DATE ) v ( win ) o ( Bowl ) Table 4 : Top 20 patterns acquired from the Sports domain by the baseline system ( Riloff ) and the co-training system for the AP collection .</sentence>
				<definiendum id="0">Precision Recall co-training bootstrapping baseline</definiendum>
				<definiendum id="1">REUTERS Baseline Co-training s</definiendum>
				<definiens id="0">a ) Precision Recall co-training bootstrapping baseline ( b ) Precision Recall co-training bootstrapping baseline</definiens>
				<definiens id="1">Top 20 patterns acquired from the Sports domain by the baseline system ( Riloff ) and the co-training system for the AP collection</definiens>
			</definition>
</paper>

		<paper id="1650">
			<definition id="0">
				<sentence>Our main contributions are : • A system for automatically ranking reviews according to helpfulness ; using state of the art SVM regression , we empirically evaluate our system on a real world dataset collected from Amazon.com on the task of reconstructing the helpfulness ranking ; and • An analysis of different classes of features most important to capture review helpfulness ; including structural ( e.g. , html tags , punctuation , review length ) , lexical ( e.g. , ngrams ) , syntactic ( e.g. , percentage of verbs and nouns ) , semantic ( e.g. , product feature mentions ) , and meta-data ( e.g. , star rating ) .</sentence>
				<definiendum id="0">meta-data</definiendum>
				<definiens id="0">e.g. , html tags , punctuation , review length ) , lexical ( e.g. , ngrams ) , syntactic ( e.g. , percentage of verbs and nouns ) , semantic ( e.g. , product feature mentions ) , and</definiens>
			</definition>
			<definition id="1">
				<sentence>We define a review helpfulness function , h , as : ( ) ( ) ( ) ( ) rratingrrating rrating Rrh −+ + + =∈ ( 1 ) where rating + ( r ) is the number of people that will find a review helpful and rating ( r ) is the number of people that will find the review unhelpful .</sentence>
				<definiendum id="0">rating +</definiendum>
				<definiens id="0">the number of people that will find a review helpful and rating</definiens>
				<definiens id="1">the number of people that will find the review unhelpful</definiens>
			</definition>
			<definition id="2">
				<sentence>• Sentential ( SEN ) : Observations of the sentences , including the number of sentences , the average sentence length , the percentage of question sentences , and the number of exclamation marks .</sentence>
				<definiendum id="0">Sentential</definiendum>
				<definiens id="0">Observations of the sentences , including the number of sentences , the average sentence length , the percentage of question sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>• Bigram ( BGR ) : The tf-idf statistic of each bigram occurring in a review .</sentence>
				<definiendum id="0">Bigram</definiendum>
				<definiendum id="1">BGR</definiendum>
				<definiens id="0">The tf-idf statistic of each bigram occurring in a review</definiens>
			</definition>
			<definition id="4">
				<sentence>3 http : //www.wjh.harvard.edu/~inquirer/homecat.htm 425 In this paper , we estimate the helpfulness function in Equation 1 using user ratings extracted from Amazon.com , where rating + ( r ) is the number of unique users that rated the review r as helpful and rating ( r ) is the number of unique users that rated r as unhelpful .</sentence>
				<definiendum id="0">rating +</definiendum>
				<definiens id="0">the number of unique users that rated the review r as helpful and rating</definiens>
				<definiens id="1">the number of unique users that rated r as unhelpful</definiens>
			</definition>
</paper>

		<paper id="1704">
			<definition id="0">
				<sentence>CUCWeb is the outcome of the common interest of two groups , a Computational Linguistics group and a Computer Science group interested on Web studies .</sentence>
				<definiendum id="0">CUCWeb</definiendum>
			</definition>
			<definition id="1">
				<sentence>One of the by-products of the project is a 166 million word corpus for Catalan.1 The biggest annotated Catalan corpus before CUCWeb is the CTILC corpus ( Rafel , 1994 ) , consisting of about 50 million words .</sentence>
				<definiendum id="0">CUCWeb</definiendum>
				<definiens id="0">a 166 million word corpus for Catalan.1 The biggest annotated Catalan corpus before</definiens>
				<definiens id="1">the CTILC corpus ( Rafel , 1994 ) , consisting of about 50 million words</definiens>
			</definition>
			<definition id="2">
				<sentence>The crawler downloaded all pages , except those that had an identical URL ( http : //www.web.es/main/ and http : //www.web.es/main/index.html were considered different URLs ) .</sentence>
				<definiendum id="0">URL ( http</definiendum>
				<definiens id="0">//www.web.es/main/ and http : //www.web.es/main/index.html were considered different URLs</definiens>
			</definition>
			<definition id="3">
				<sentence>The final corpus consists of 166 million words from 204 thousand documents .</sentence>
				<definiendum id="0">final corpus</definiendum>
				<definiens id="0">consists of 166 million words from 204 thousand documents</definiens>
			</definition>
			<definition id="4">
				<sentence>Documents ( % ) es 89,541 44.6 com 49,146 24.5 org 35,528 17.7 net 18,819 9.4 info 5,005 2.5 edu 688 0.3 others 2,042 1.4 Table 2 : Domain distribution in CUCWeb The corpus was further processed with CatCG ( `Alex Alsina et al. , 2002 ) , a POS-tagger and shallow parser for Catalan built with the Connexor Constraint Grammar formalism and tools.7 CatCG provides part of speech , morphological features ( gender , number , tense , etc. ) and syntactic information .</sentence>
				<definiendum id="0">Documents</definiendum>
				<definiens id="0">a POS-tagger and shallow parser for Catalan built with the Connexor Constraint Grammar formalism and tools.7 CatCG provides part of speech , morphological features ( gender , number , tense , etc. ) and syntactic information</definiens>
			</definition>
			<definition id="5">
				<sentence>The simple mode allows for searches of words , lemmata or word strings .</sentence>
				<definiendum id="0">simple mode</definiendum>
				<definiens id="0">allows for searches of words , lemmata or word strings</definiens>
			</definition>
			<definition id="6">
				<sentence>The annotated corpus can be used as a source of data for NLP purposes .</sentence>
				<definiendum id="0">annotated corpus</definiendum>
			</definition>
			<definition id="7">
				<sentence>The Spanish corpus , however , will be much larger than the Catalan one ( a conservative estimate is 600 25 million words ) , so that new challenges in processing and searching it will arise .</sentence>
				<definiendum id="0">Spanish corpus</definiendum>
				<definiens id="0">a conservative estimate is 600 25 million words ) , so that new challenges in processing and searching it will arise</definiens>
			</definition>
</paper>

		<paper id="3311">
</paper>

		<paper id="1608">
			<definition id="0">
				<sentence>Here , a treelet is a connected subgraph of a dependency tree .</sentence>
				<definiendum id="0">treelet</definiendum>
				<definiens id="0">a connected subgraph of a dependency tree</definiens>
			</definition>
			<definition id="1">
				<sentence>A treelet translation pair consists of a source treelet S , a target treelet T , and a word alignment A ⊂ S×T such that for all s ∈ S , there exists a unique t ∈T such that ( s , t ) ∈A , and if t is the root of T , there is a unique s ∈ S such that ( s , t ) ∈ A. Translation of a sentence begins by parsing that sentence into a dependency representation .</sentence>
				<definiendum id="0">treelet translation pair</definiendum>
				<definiens id="0">consists of a source treelet S , a target treelet T , and a word alignment A ⊂ S×T such that for all s ∈ S , there exists a unique t ∈T such that ( s , t ) ∈A , and if t is the root of T , there is a unique s ∈ S such that ( s , t ) ∈ A. Translation of a sentence begins by parsing that sentence into a dependency representation</definiens>
			</definition>
			<definition id="2">
				<sentence>This limits the number of mappings to be O ( n3 ) in the worst case , where n is the number of nodes in the dependency tree .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of nodes in the dependency tree</definiens>
			</definition>
</paper>

		<paper id="3119">
			<definition id="0">
				<sentence>We use the following features for our rules : • sourceand target-conditioned neg-log lexical weights as described in ( Koehn et al. , 2003b ) • neg-log relative frequencies : left-handside-conditioned , target-phrase-conditioned , source-phrase-conditioned • Counters : n.o. rule applications , n.o. target words • Flags : IsPurelyLexical ( i.e. , contains only terminals ) , IsPurelyAbstract ( i.e. , contains only nonterminals ) , IsXRule ( i.e. , non-syntactical span ) , IsGlueRule 139 • Penalties : rareness penalty exp ( 1 − RuleFrequency ) ; unbalancedness penalty |MeanTargetSourceRatio ∗ ‘n.o. source words’− ‘n.o. target words’| Our SynCFG rules are equivalent to a probabilistic context-free grammar and decoding is therefore an application of chart parsing .</sentence>
				<definiendum id="0">IsPurelyLexical</definiendum>
				<definiendum id="1">IsXRule</definiendum>
				<definiens id="0">left-handside-conditioned , target-phrase-conditioned , source-phrase-conditioned • Counters : n.o. rule applications</definiens>
				<definiens id="1">equivalent to a probabilistic context-free grammar and decoding is therefore an application of chart parsing</definiens>
			</definition>
			<definition id="1">
				<sentence>A hypergraph node is an equivalence class of complete hypotheses ( derivations ) with identical production results ( left-hand sides of the corresponding applied rules ) .</sentence>
				<definiendum id="0">hypergraph node</definiendum>
				<definiens id="0">an equivalence class of complete hypotheses ( derivations ) with identical production results ( left-hand sides of the corresponding applied rules</definiens>
			</definition>
</paper>

		<paper id="0118">
			<definition id="0">
				<sentence>Suppose w0 represents the current word , w−1 is the first word to the left , w−2 is the second word to the left , w1 is the first word to the right , and w2 is the second word to the right , then in our experiments , the types of unigram features used include w0 , w−1 , w1 , w−2 , w2 , w0w−1 , w0w1 , w−1w1 , w−2w−1 , and w2w0 .</sentence>
				<definiendum id="0">w1</definiendum>
				<definiendum id="1">w2</definiendum>
				<definiens id="0">features used include w0 , w−1 , w1 , w−2 , w2 , w0w−1 , w0w1 , w−1w1 , w−2w−1 , and w2w0</definiens>
			</definition>
</paper>

		<paper id="3401">
			<definition id="0">
				<sentence>All training and testing pairs consist of a nucleus followed by a satellite , and the relations are defined as follows : 2 • Contrast : The information in the satellite contradicts or is an exception to the information in the nucleus .</sentence>
				<definiendum id="0">Contrast</definiendum>
				<definiens id="0">All training and testing pairs consist of a nucleus followed by a satellite , and the relations are defined as follows : 2 •</definiens>
				<definiens id="1">The information in the satellite contradicts or is an exception to the information in the nucleus</definiens>
			</definition>
</paper>

		<paper id="1644">
			<definition id="0">
				<sentence>On the other hand , although topic-specific vocabulary can be gleaned from related text materials , such as the textbook and lecture slides , written language is a poor predictor of how words are actually spoken .</sentence>
				<definiendum id="0">language</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Author Topic model adds an additional dependency on the author ( s ) to the topic mixture weights of each document ( Rosen-Zvi et al. , 2005 ) .</sentence>
				<definiendum id="0">Author Topic model</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Hierarchical Dirichlet Process is a nonparametric model that generalizes distribution parameter modeling to multiple levels .</sentence>
				<definiendum id="0">Hierarchical Dirichlet Process</definiendum>
				<definiens id="0">a nonparametric model that generalizes distribution parameter modeling to multiple levels</definiens>
			</definition>
			<definition id="3">
				<sentence>Our language modeling experiments have been conducted on high-fidelity transcripts of approximately 168 hours of lectures from three undergraduate subjects in math , physics , and computer science ( CS ) , as well as 79 seminars covering a wide range of topics ( Glass et al. , 2004 ) .</sentence>
				<definiendum id="0">CS</definiendum>
				<definiens id="0">conducted on high-fidelity transcripts of approximately 168 hours of lectures from three undergraduate subjects in math , physics , and computer science</definiens>
			</definition>
			<definition id="4">
				<sentence>An OR GATE is a SIMILAR two INPUT PRIMITIVE FUNCTION box that drives its OUTPUT SIGNAL to a value that is the LOGICAL OR of the INPUTS .</sentence>
				<definiendum id="0">OR GATE</definiendum>
				<definiens id="0">a SIMILAR two INPUT PRIMITIVE FUNCTION box that drives its OUTPUT SIGNAL to a value that is the LOGICAL OR of the INPUTS</definiens>
			</definition>
</paper>

		<paper id="3103">
			<definition id="0">
				<sentence>Arabic is a highly inflected language compared to English which has very little morphology .</sentence>
				<definiendum id="0">Arabic</definiendum>
				<definiens id="0">a highly inflected language compared to English which has very little morphology</definiens>
			</definition>
			<definition id="1">
				<sentence>• WF : is achieved if the word begins with w or f. • And the states , K , L , B and AL are achieved if the word begins with s , k , l , b and Al , respectively .</sentence>
				<definiendum id="0">WF</definiendum>
				<definiens id="0">achieved if the word begins with w or f. • And the states , K , L , B and AL are achieved if the word begins with s , k , l , b and Al , respectively</definiens>
			</definition>
			<definition id="2">
				<sentence>The best performing segmentation method is IFSA which generates the best translation results based on all evaluation criteria , and it is consistent over both development and evaluation sets .</sentence>
				<definiendum id="0">IFSA</definiendum>
				<definiens id="0">generates the best translation results based on all evaluation criteria</definiens>
			</definition>
			<definition id="3">
				<sentence>ARABIC ENGLISH TOKENIZED IFSA Train : Sentences 8.5M Running Words 260.5M 316.8M 279.2M Vocabulary 510.3K 411.2K 301.2K Dev : Sentences 1043 Running Words 30.2K 33.3K 33K OOVs ( Running Words ) 809 399 NA Test : Sentences 1353 Running Words 40K 47.9K 48.3K OOVs ( Running Words ) 871 505 NA Table 6 : Case insensitive evaluation results for translating the development and test data of BTEC task after performing divers preprocessing .</sentence>
				<definiendum id="0">ARABIC ENGLISH TOKENIZED IFSA Train</definiendum>
				<definiendum id="1">OOVs ( Running Words</definiendum>
				<definiens id="0">Case insensitive evaluation results for translating the development and test data of BTEC task after performing divers preprocessing</definiens>
			</definition>
</paper>

		<paper id="2202">
			<definition id="0">
				<sentence>This paper describes SIE ( Simple Information Extraction ) , a modular information extraction system designed with the goal of being easily and quickly portable across tasks and domains .</sentence>
				<definiendum id="0">SIE ( Simple Information Extraction</definiendum>
				<definiens id="0">a modular information extraction system designed with the goal of being easily and quickly portable across tasks and domains</definiens>
			</definition>
			<definition id="1">
				<sentence>A crucial role in the architecture is played by Instance Filtering , which allows to increase efficiency without reducing effectiveness .</sentence>
				<definiendum id="0">Instance Filtering</definiendum>
				<definiens id="0">allows to increase efficiency without reducing effectiveness</definiens>
			</definition>
			<definition id="2">
				<sentence>In this paper , we present SIE ( Simple Information Extraction ) , an information extraction system based on a supervised machine learning approach for extracting domain-specific entities from documents .</sentence>
				<definiendum id="0">SIE ( Simple Information Extraction</definiendum>
				<definiens id="0">an information extraction system based on a supervised machine learning approach for extracting domain-specific entities from documents</definiens>
			</definition>
			<definition id="3">
				<sentence>The results show that SIE is competitive with the state-of-the-art systems , and it often outperforms systems customized to a specific domain .</sentence>
				<definiendum id="0">SIE</definiendum>
				<definiens id="0">competitive with the state-of-the-art systems</definiens>
			</definition>
			<definition id="4">
				<sentence>SIE has a modular system architecture .</sentence>
				<definiendum id="0">SIE</definiendum>
				<definiens id="0">a modular system architecture</definiens>
			</definition>
			<definition id="5">
				<sentence>Instance Filtering Feature Extraction Learning Algorithm Tag Matcher Classification Algorithm Instance Filtering Feature Extraction Lexicon Training Corpus New Documents Data Model Tagged Documents Filter Model Extraction Script Extraction Script Figure 1 : The SIE Architecture .</sentence>
				<definiendum id="0">Instance Filtering</definiendum>
				<definiens id="0">Feature Extraction Learning Algorithm Tag Matcher Classification Algorithm Instance Filtering Feature Extraction Lexicon Training Corpus New Documents Data Model Tagged Documents Filter Model Extraction Script Extraction Script Figure 1 : The SIE Architecture</definiens>
			</definition>
			<definition id="6">
				<sentence>A Tag Matcher module ( Section 6 ) is used to match the boundary predictions made by the Classification module .</sentence>
				<definiendum id="0">Tag Matcher module</definiendum>
				<definiens id="0">used to match the boundary predictions made by the Classification module</definiens>
			</definition>
			<definition id="7">
				<sentence>InformationContent ( IC ) Themostcommonly used feature selection metric in text categorization is based on document frequency ( i.e , the number of documents in which a term occurs ) .</sentence>
				<definiendum id="0">InformationContent ( IC</definiendum>
				<definiens id="0">) Themostcommonly used feature selection metric in text categorization is based on document frequency ( i.e , the number of documents in which a term occurs )</definiens>
			</definition>
			<definition id="8">
				<sentence>The frequency of a term in the corpus is a good indicator of its generality , rather than of its information content .</sentence>
				<definiendum id="0">frequency of a term</definiendum>
				<definiens id="0">a good indicator of its generality</definiens>
			</definition>
			<definition id="9">
				<sentence>jFex generates the features specified by a feature extraction script , indexes them , and returns the example set , as well as the mapping between the features and their indices ( lexicon ) .</sentence>
				<definiendum id="0">jFex</definiendum>
				<definiens id="0">generates the features specified by a feature extraction script</definiens>
			</definition>
			<definition id="10">
				<sentence>SIE achieves results close to the best systems in all tasks13 .</sentence>
				<definiendum id="0">SIE</definiendum>
				<definiens id="0">achieves results close to the best systems in all tasks13</definiens>
			</definition>
</paper>

		<paper id="2002">
			<definition id="0">
				<sentence>Let L = { L word , L PT , L NT } , whereL word is a labeling scheme for words , L PT is a labeling scheme for preterminals , and L NT is a labeling scheme for nonterminals .</sentence>
				<definiendum id="0">L PT</definiendum>
				<definiendum id="1">L NT</definiendum>
				<definiens id="0">a labeling scheme for words</definiens>
				<definiens id="1">a labeling scheme for preterminals</definiens>
				<definiens id="2">a labeling scheme for nonterminals</definiens>
			</definition>
			<definition id="1">
				<sentence>Ourplanned bootstrapping approach willnotstartoutwithagivenparserforEnglish ( or any other language ) , but use a small set of manuallyannotated seeddatafollowingtheleanphrase correspondence scheme , and then bootstrap consensus representations on large amounts of unannotated multitext data .</sentence>
				<definiendum id="0">Ourplanned bootstrapping approach willnotstartoutwithagivenparserforEnglish</definiendum>
				<definiens id="0">any other language ) , but use a small set of manuallyannotated seeddatafollowingtheleanphrase correspondence scheme , and then bootstrap consensus representations on large amounts of unannotated multitext data</definiens>
			</definition>
			<definition id="2">
				<sentence>Acknowledgement Theworkreported inthispaperwassupported by the Deutsche Forschungsgemeinschaft ( DFG ; German Research Foundation ) in the Emmy Noether project PTOLEMAIOS on grammar learning from parallelcorpora .</sentence>
				<definiendum id="0">Acknowledgement Theworkreported</definiendum>
				<definiens id="0">inthispaperwassupported by the Deutsche Forschungsgemeinschaft ( DFG ; German Research Foundation ) in the Emmy Noether project PTOLEMAIOS on grammar learning from parallelcorpora</definiens>
			</definition>
</paper>

		<paper id="1705">
			<definition id="0">
				<sentence>A word sketch is an automatic one-page corpus-derived summary of a word 's grammatical and collocational behaviour .</sentence>
				<definiendum id="0">word sketch</definiendum>
				<definiens id="0">an automatic one-page corpus-derived summary of a word 's grammatical and collocational behaviour</definiens>
			</definition>
			<definition id="1">
				<sentence>In simple terms , P2P is a technology that takes advantage of the resources and services available at the edge of the Internet ( Shirky , 2001 ) .</sentence>
				<definiendum id="0">P2P</definiendum>
			</definition>
			<definition id="2">
				<sentence>Better known for file-sharing and Instant Messenger applications , P2P has increasingly been applied in distributed computational systems .</sentence>
				<definiendum id="0">P2P</definiendum>
				<definiens id="0">has increasingly been applied in distributed computational systems</definiens>
			</definition>
			<definition id="3">
				<sentence>The Sketch Engine requires a large well-balanced corpus which has been part-of-speech tagged and shallow parsed to find subjects , objects , heads , and modifiers .</sentence>
				<definiendum id="0">Sketch Engine</definiendum>
				<definiens id="0">part-of-speech tagged and shallow parsed to find subjects , objects , heads , and modifiers</definiens>
			</definition>
			<definition id="4">
				<sentence>To evaluate text conversion and clean-up routines for PDF documents , we will use a 5million-word gold-standard sub-corpus extracted 12 The Corpus of Professional English ( CPE ) is a major research project of PERC ( the Professional English Research Consortium ) currently underway that , when finished , will consist of a 100-million-word computerised database of English used by professionals in science , engineering , technology and other fields .</sentence>
				<definiendum id="0">CPE )</definiendum>
				<definiens id="0">the Professional English Research Consortium ) currently underway that , when finished , will consist of a 100-million-word computerised database of English used by professionals in science , engineering , technology and other fields</definiens>
			</definition>
</paper>

		<paper id="3101">
</paper>

		<paper id="3121">
			<definition id="0">
				<sentence>Phramer is a phrase-based SMT system written in Java .</sentence>
				<definiendum id="0">Phramer</definiendum>
				<definiens id="0">a phrase-based SMT system written in Java</definiens>
			</definition>
			<definition id="1">
				<sentence>The LM is the only model that opposes the tendency of the distortion model towards monotone phrase order .</sentence>
				<definiendum id="0">LM</definiendum>
				<definiens id="0">the only model that opposes the tendency of the distortion model towards monotone phrase order</definiens>
			</definition>
</paper>

		<paper id="1106">
			<definition id="0">
				<sentence>In Christine Fellbaum , editor , WordNet : An Electronic Lexical Database , chapter 3 , pages 70 { 104 .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An Electronic Lexical Database , chapter 3</definiens>
			</definition>
</paper>

		<paper id="1601">
			<definition id="0">
				<sentence>The two main handtagged corpora are PropBank ( Palmer et al. , 2003 ) and FrameNet ( Baker et al. , 1998 ) , the former of which currently has broader coverage .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">Baker et al. , 1998 ) , the former of which currently has broader coverage</definiens>
			</definition>
			<definition id="1">
				<sentence>More relevant is the work of McCarthy and 1 Relation Description subj NP preceding verb np # n NP in the nth position following verb np NP that is not the subject and not immediately following verb cl # n Complement clause in the nth position following verb cl Complement clause not immediately following verb xcl # n Complement clause without subject in the nth position following verb xcl Complement clause without subject not immediately following verb acomp # n Adjectival complement in the nth position following verb acomp Adjectival complement not immediately following verb prep x Prepositional modifier with preposition x advmod Adverbial modifier advcl Adverbial clause Table 1 : The set of syntactic relations we use , where n ∈ { 1,2,3 } and x is a preposition .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">the work of McCarthy and 1 Relation Description subj NP preceding verb np # n NP in the nth position following verb np NP that is not the subject and not immediately following verb cl # n Complement clause in the nth position following verb cl Complement clause not immediately following verb xcl # n Complement clause without subject in the nth position following verb xcl Complement clause without subject not immediately following verb acomp # n Adjectival complement in the nth position following verb</definiens>
			</definition>
			<definition id="2">
				<sentence>Verb : give Syntactic Semantic Head Relation Role Word subj ARG0 plunge/NN np ARGM today/NN np # 1 ARG2 they/PRP np # 2 ARG1 test/NN v = give lscript = { ARG0 → subj , ARG1 → np # 2 ARG2 → np # 1 } o = [ ( ARG0 , subj ) , ( ARGM , ? )</sentence>
				<definiendum id="0">Verb</definiendum>
				<definiens id="0">give Syntactic Semantic Head Relation Role Word</definiens>
			</definition>
			<definition id="3">
				<sentence>A verb instance consists of the base form ( lemma ) of the observed verb , and for each dependent of the verb , the dependent’s syntactic relation and head word ( represented as the base form with part of speech information ) .</sentence>
				<definiendum id="0">verb instance</definiendum>
				<definiens id="0">consists of the base form ( lemma ) of the observed verb , and for each dependent of the verb , the dependent’s syntactic relation and head word ( represented as the base form with part of speech information )</definiens>
			</definition>
			<definition id="4">
				<sentence>There are two problems with this simple implementation , both stemming from the fact that the space of possible linkings is large ( there are O ( |G+1||R| ) , where G is the set of syntactic relations and R is the set of semantic roles ) .</sentence>
				<definiendum id="0">G</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">the set of syntactic relations and</definiens>
			</definition>
			<definition id="5">
				<sentence>More formally , we factor P ( lscript|v ) as follows , where c is the vector of construction operations used to build lscript : P ( lscript|v ) = summationdisplay c P ( lscript|c ) P ( c|v ) = summationdisplay c |R|productdisplay i=1 P ( ci|v ) Note that in the second step we drop the term P ( lscript|c ) since it is always 1 ( a sequence of operations leads deterministically to a linking ) .</sentence>
				<definiendum id="0">c</definiendum>
			</definition>
			<definition id="6">
				<sentence>Although it is intractable to find exact solutions to optimization problems of this form , the ExpectationMaximization ( EM ) algorithm is a greedy search procedure over the parameter space which is guaranteed to increase the expected likelihood , and thus find a local maximum of the function .</sentence>
				<definiendum id="0">ExpectationMaximization</definiendum>
				<definiens id="0">a greedy search procedure over the parameter space which is guaranteed to increase the expected likelihood</definiens>
			</definition>
			<definition id="7">
				<sentence>“Good” models are ones which list linkings for each verb that correspond to linguists’ judgments about verb linking behavior .</sentence>
				<definiendum id="0">“Good” models</definiendum>
				<definiens id="0">ones which list linkings for each verb that correspond to linguists’ judgments about verb linking behavior</definiens>
			</definition>
			<definition id="8">
				<sentence>The development set consists of 2507 verb instances and 833 different verb types , and the test set consists of 4269 verb instances and 1099 different verb types .</sentence>
				<definiendum id="0">development set</definiendum>
				<definiens id="0">consists of 2507 verb instances and 833 different verb types , and the test set consists of 4269 verb instances and 1099 different verb types</definiens>
			</definition>
</paper>

		<paper id="0113">
			<definition id="0">
				<sentence>Functional chunks are defined as a series of non-overlapping , non-nested functional units in a sentence , such as subjects , predicates , objects , adverbs , complements and so on .</sentence>
				<definiendum id="0">Functional chunks</definiendum>
				<definiens id="0">a series of non-overlapping , non-nested functional units in a sentence , such as subjects , predicates , objects , adverbs , complements and so on</definiens>
			</definition>
			<definition id="1">
				<sentence>Functional chunks are defined as a series of non-overlapping , non-nested segments of text at the sentence level without leaving any words outside .</sentence>
				<definiendum id="0">Functional chunks</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Chinese functional chunk parser takes a stream of segmented and tagged words as its input , and outputs all the functional chunk boundaries in a sentence .</sentence>
				<definiendum id="0">Chinese functional chunk parser</definiendum>
				<definiens id="0">takes a stream of segmented and tagged words as its input , and outputs all the functional chunk boundaries in a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>“Nuclear electricity is a kind of safe , clean and economical energy.”</sentence>
				<definiendum id="0">“Nuclear electricity</definiendum>
			</definition>
			<definition id="4">
				<sentence>The performance of each experiment is measured with 3 rates : precision , recall and F β =1 , where precision is the percentage of detected boundaries that are correct , recall is the percentage of boundaries in the test data that are found by the parser , and F β =1 is defined as F β = ( β 2 +1 ) *precision*recall/ ( β 2 *precision + recall ) with β =1 .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">measured with 3 rates : precision , recall and F β =1 , where</definiens>
			</definition>
			<definition id="5">
				<sentence>In both tasks , Naïve Bayes algorithm performs the worst , which makes us very disappointed .</sentence>
				<definiendum id="0">Naïve Bayes</definiendum>
				<definiens id="0">makes us very disappointed</definiens>
			</definition>
			<definition id="6">
				<sentence>In SP boundary detection task , we list the number of wrongly detected chunk boundaries ( # WDB ) and the corresponding chunk types ( CT ) where WDB arises in the following table .</sentence>
				<definiendum id="0">corresponding chunk types</definiendum>
				<definiendum id="1">WDB</definiendum>
				<definiens id="0">arises in the following table</definiens>
			</definition>
			<definition id="7">
				<sentence>Misclassified Chunk Boundaries in the Test Results of T1 and T4 .</sentence>
				<definiendum id="0">Misclassified Chunk Boundaries</definiendum>
				<definiens id="0">in the Test Results of T1 and T4</definiens>
			</definition>
			<definition id="8">
				<sentence>Misclassified Chunk Boundaries in the Test Results of T1 and T4 .</sentence>
				<definiendum id="0">Misclassified Chunk Boundaries</definiendum>
				<definiens id="0">in the Test Results of T1 and T4</definiens>
			</definition>
</paper>

		<paper id="2914">
			<definition id="0">
				<sentence>Automatic thematic segmentation ( TS ) , i.e. the segmentation of a text stream into topically coherent segments , is an important component in applications dealing with large document collections such as information retrieval and document browsing .</sentence>
				<definiendum id="0">Automatic thematic segmentation ( TS</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the TS task , we used an automated procedure to select the regularization parameters , as further described in section In cases where non-linear hypothesis functions should be optimised , each vectorui can be mapped into ϕ ( vectorui ) ∈ F , where F is a higher dimensional space usually called feature space , in order to make linear the relation between vectorui and yi .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">a higher dimensional space usually called feature space</definiens>
			</definition>
			<definition id="2">
				<sentence>vectorui , where a j-th element of vectorui is computed as : ui , j =   isummationdisplay t=i−winSize ft , j     i+winSizesummationdisplay k=i+1 fk , j   , where winSize ≥ 1 and fi , j is the weighted frequency ( determined in the previous step ) of the j-th word from the vocabulary in the i-th utterance .</sentence>
				<definiendum id="0">j</definiendum>
				<definiens id="0">the weighted frequency ( determined in the previous step ) of the j-th word from the vocabulary in the i-th utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>A test sample from this dataset consists of the transcription of an approximately onehour long meeting and contains an average of about seven thematic episodes .</sentence>
				<definiendum id="0">test sample</definiendum>
				<definiens id="0">the transcription of an approximately onehour long meeting and contains an average of about seven thematic episodes</definiens>
			</definition>
			<definition id="4">
				<sentence>Therefore , in order to ensure that positive points are not considered as being noisy labels , we change the penalty of the minority ( positive ) class by setting the parameter C+ of this class to : C+ = λ· parenleftbigg n n+ −1 −1 parenrightbigg ·C− , where n+ is the number of positive training examples , n is the total number of training examples and λ is the scaling factor .</sentence>
				<definiendum id="0">n+</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of positive training examples</definiens>
				<definiens id="1">the total number of training examples and λ is the scaling factor</definiens>
			</definition>
			<definition id="5">
				<sentence>Intention-based Segmentation : Human Reliability and Correlation with Linguistic Cues .</sentence>
				<definiendum id="0">Intention-based Segmentation</definiendum>
			</definition>
</paper>

		<paper id="1647">
			<definition id="0">
				<sentence>The Arabic language consist of a collection of spoken dialects and a standard written language ( Modern Standard Arabic , or MSA ) .</sentence>
				<definiendum id="0">Arabic language</definiendum>
				<definiendum id="1">MSA</definiendum>
				<definiens id="0">consist of a collection of spoken dialects and a standard written language ( Modern Standard Arabic , or</definiens>
			</definition>
			<definition id="1">
				<sentence>Transductive clustering ( TC ) is a simple algorithm that directly implements the cluster assumption .</sentence>
				<definiendum id="0">Transductive clustering ( TC )</definiendum>
				<definiens id="0">a simple algorithm that directly implements the cluster assumption</definiens>
			</definition>
			<definition id="2">
				<sentence>Let ˆRh ( Xm ) be the empirical risk of a given hypothesis ( i.e. classi er ) on the training set ; let Rh ( Xu ) be the test risk .</sentence>
				<definiendum id="0">ˆRh ( Xm )</definiendum>
				<definiens id="0">the empirical risk of a given hypothesis ( i.e. classi er</definiens>
			</definition>
			<definition id="3">
				<sentence>The prior p ( h ) indicates ones prior belief on the hypothesis h over the set of all possible hypotheses .</sentence>
				<definiendum id="0">prior p ( h )</definiendum>
				<definiens id="0">indicates ones prior belief on the hypothesis h over the set of all possible hypotheses</definiens>
			</definition>
			<definition id="4">
				<sentence>In particular , the modi cation involves a different estimate of the priors p ( h ) , which was assumed to be uniform in ( El-Yaniv and Gerzon , 2005 ) .</sentence>
				<definiendum id="0">modi cation</definiendum>
				<definiens id="0">involves a different estimate of the priors p ( h ) , which was assumed</definiens>
			</definition>
			<definition id="5">
				<sentence>Spectral Graph Transducer ( SGT ) ( Joachims , 2003 ) achieves transduction via an extension of the normalized mincut clustering criterion .</sentence>
				<definiendum id="0">Spectral Graph Transducer ( SGT )</definiendum>
				<definiens id="0">achieves transduction via an extension of the normalized mincut clustering criterion</definiens>
			</definition>
			<definition id="6">
				<sentence>The test set consists of 15k tokens and 2.4k types , and is manually annotated with POS tags .</sentence>
				<definiendum id="0">test set</definiendum>
			</definition>
</paper>

		<paper id="2004">
			<definition id="0">
				<sentence>Name ambiguity is a problem that is increasing in complexity and scope as online information sources grow and expand their coverage .</sentence>
				<definiendum id="0">Name ambiguity</definiendum>
			</definition>
</paper>

		<paper id="1673">
			<definition id="0">
				<sentence>Ng and Jordan ( 2001 ) show that under mild assumptions , with only N samples the relative classification error will be at most O ( 1N ) higher than the error of the Bayes optimal classifier ( in our case , the classifier which does exact inference ) .</sentence>
				<definiendum id="0">Bayes optimal classifier</definiendum>
				<definiens id="0">does exact inference )</definiens>
			</definition>
			<definition id="1">
				<sentence>The 620 inside probability βk ( p , q ) is the probability that words p through q , inclusive , were produced by the non-terminal k. So the probability of the sentence The boy pet the dog .</sentence>
				<definiendum id="0">inside probability βk</definiendum>
				<definiens id="0">the probability that words p through q , inclusive , were produced by the non-terminal k. So the probability of the sentence The boy pet the dog</definiens>
			</definition>
			<definition id="2">
				<sentence>The inside probabilities are calculated just once , and we can then generate many samples very quickly ; DrawSamples is linear in the number of words , and rules .</sentence>
				<definiendum id="0">DrawSamples</definiendum>
				<definiens id="0">linear in the number of words , and rules</definiens>
			</definition>
			<definition id="3">
				<sentence>The probability of a state sequence is then defined by the sequence of factor tables in the clique chain , given the observation sequence : PCRF ( s|o ) = 1Z ( o ) Nproductdisplay i=1 Fi ( si−n ... si ) ( 4 ) where Fi ( si−n ... si ) is the element of the factor table at position i corresponding to states si−n through si , and Z ( o ) is the partition function which serves to normalize the distribution.1 To in1To handle the start condition properly , imagine also that we define a set of distinguished start states s− ( n−1 ) ... s0 .</sentence>
				<definiendum id="0">probability of a state</definiendum>
				<definiendum id="1">Z ( o )</definiendum>
				<definiens id="0">the sequence of factor tables in the clique chain , given the observation sequence : PCRF ( s|o ) = 1Z ( o ) Nproductdisplay i=1 Fi ( si−n ... si ) ( 4 ) where Fi ( si−n ... si ) is the element of the factor table at position i corresponding to states si−n through si , and</definiens>
				<definiens id="1">the partition function which serves to normalize the distribution.1 To in1To handle the start condition properly</definiens>
			</definition>
			<definition id="4">
				<sentence>Responses are sorted based on entailment confidence and then average precision is calculated by the following equation : 1 R nsummationdisplay i=1 E ( i ) # correct up to pair ii ( 5 ) where n is the size of the test set , R is the number of positive ( entailed ) examples , E ( i ) is an indicator function whose value is 1 if the ith pair is entailed , and the is are sorted based on the entailment confidence .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">the size of the test set</definiens>
			</definition>
</paper>

		<paper id="3318">
			<definition id="0">
				<sentence>Baohua Gu School of Computing Science Simon Fraser University , Burnaby , BC , Canada bgu @ cs.sfu.ca Nested Named Entities ( nested NEs ) , one containing another , are commonly seen in biomedical text , e.g. , accounting for 16.7 % of all named entities in GENIA corpus .</sentence>
				<definiendum id="0">Nested Named Entities ( nested NEs</definiendum>
				<definiens id="0">commonly seen in biomedical text , e.g. , accounting for 16.7 % of all named entities in GENIA corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Named Entity Recognition ( NER ) is a key task in biomedical text mining , as biomedical named entities usually represent biomedical concepts of research interest ( e.g. , protein/gene/virus , etc ) .</sentence>
				<definiendum id="0">Named Entity Recognition</definiendum>
				<definiendum id="1">NER )</definiendum>
				<definiens id="0">a key task in biomedical text mining , as biomedical named entities usually represent biomedical concepts of research interest ( e.g. , protein/gene/virus , etc )</definiens>
			</definition>
			<definition id="2">
				<sentence>The GENIA corpus ( version 3.02 ) contains 97876 named entities ( 35947 distinct ) of 36 types , and 490941 tokens ( 19883 distinct ) .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">contains 97876 named entities ( 35947 distinct ) of 36 types , and 490941 tokens ( 19883 distinct )</definiens>
			</definition>
</paper>

		<paper id="1314">
			<definition id="0">
				<sentence>fined as : κ = P ( O ) −P ( E ) 1 −P ( E ) where P ( O ) is the probability of the observed agreement , and P ( E ) the probability of the “expected agreement” ( i.e. , under the assumption the two sets of annotations are independent ) .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
			<definition id="1">
				<sentence>Maxent models seek to maximize the conditional probability of a class c given the observations X using the exponential form P ( c|X ) = 1Z ( X ) exp bracketleftBiggsummationdisplay i λi , c fi , c ( X ) bracketrightBigg where fi , c ( X ) is the ith feature of the data X in class c , λi , c is the corresponding weight , and Z ( X ) is a normalization term .</sentence>
				<definiendum id="0">Maxent models</definiendum>
				<definiendum id="1">X )</definiendum>
				<definiendum id="2">c</definiendum>
				<definiendum id="3">Z ( X</definiendum>
				<definiens id="0">the ith feature of the data X in class c</definiens>
			</definition>
			<definition id="2">
				<sentence>To evaluate system performance , we calculate the F measure ( F ) of precision ( P ) and recall ( R ) , defined as : P = |A ∩C||A| R = |A ∩C||C| F = 2PRP + R where A is the set of utterances marked as action items by the system , and C is the set of ( all ) correct action item utterances .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">P = |A ∩C||A| R = |A ∩C||C| F = 2PRP + R where A is the set of utterances marked as action items by the system , and</definiens>
				<definiens id="1">the set of ( all ) correct action item utterances</definiens>
			</definition>
			<definition id="3">
				<sentence>98 The use of precision and recall is motivated by the fact that the large imbalance between positive and negative examples in the corpus ( Section 3 ) means that simpler metrics like accuracy are insufficient—a system that simply classifies every utterance as negative will achieve an accuracy of 97.5 % , which clearly is not a good reflection of desired behavior .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">motivated by the fact that the large imbalance between positive and negative examples in the corpus ( Section 3 ) means that simpler metrics like accuracy are insufficient—a system that simply classifies every utterance as negative will achieve an accuracy of</definiens>
			</definition>
			<definition id="4">
				<sentence>It seems likely that applying a sequence model such as an HMM or conditional random field ( CRFs ) will act as a generalization of this feature and may further improve performance .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiens id="0">an HMM or conditional random field</definiens>
			</definition>
</paper>

		<paper id="2931">
			<definition id="0">
				<sentence>In our paper the arc probabilities are calculated as follows : P 1 = P ( R , D|CTag i , CTag j , Dist ) P 2 = P ( R , D|FTag i , FTag j ) P 3 = P ( R , D|CTag i , Word j ) P 4 = P ( R , D|Word i , CTag j ) P 5 = P ( R , D|Word i , CTag i , Word j , CTag j ) P 6 = P ( R , D|CTag i−1 , CTag i , CTag j , CTag j+1 ) Where CTag is coarse-grained part of speech tag and FTag is fine-grained tag .</sentence>
				<definiendum id="0">CTag</definiendum>
				<definiendum id="1">FTag</definiendum>
				<definiens id="0">coarse-grained part of speech tag</definiens>
				<definiens id="1">fine-grained tag</definiens>
			</definition>
			<definition id="1">
				<sentence>Dist is the distance between Node i and Node j .</sentence>
				<definiendum id="0">Dist</definiendum>
				<definiens id="0">the distance between Node i and Node j</definiens>
			</definition>
			<definition id="2">
				<sentence>213 Figure 4 : Token score with size of training data Figure 5 : Token score with sentence length • P ( R’ ) &gt; λP ( R ) , the current arc R will be delayed Length* ( P ( R’ ) /P ( R ) ) times .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">Token score with size of training data Figure 5 : Token score with sentence length •</definiens>
			</definition>
			<definition id="3">
				<sentence>hatwidest GD is empirical value and GD is current value .</sentence>
				<definiendum id="0">GD</definiendum>
				<definiens id="0">empirical value</definiens>
			</definition>
			<definition id="4">
				<sentence>Turkish is a typical head-final language and 81.1 % of dependencies are right-headed .</sentence>
				<definiendum id="0">Turkish</definiendum>
				<definiens id="0">a typical head-final language</definiens>
			</definition>
</paper>

		<paper id="1109">
			<definition id="0">
				<sentence>Such methods differ in the way they calculate the likelihood that the test data matches with one of the pro les .</sentence>
				<definiendum id="0">Such methods</definiendum>
				<definiens id="0">differ in the way they calculate the likelihood that the test data matches with one of the pro les</definiens>
			</definition>
			<definition id="1">
				<sentence>Assuming that we have two models or distributions P and Q over a variable X , the measures ( sim ) are de ned as below ( p and q being probabilities and r and s being ranks in models P and Q : sim =summationdisplay x ( log p ( x ) − log q ( x ) ) ( 1 ) sim =summationdisplay x ( abs ( log p ( x ) ) − abs ( log q ( x ) ) ) ( 2 ) 65 sim =summationdisplay x ( p ( x ) ∗ log q ( x ) ) ( 3 ) Kullback-Leibler distance see note below ) : sim =summationdisplay x p ( x ) log p ( x ) log q ( x ) ( 4 ) measure ) ( Jiang and Conrath , 1997 ) : sim = A − B ( 5 ) where , A = 2 ∗summationdisplay x ( log p ( x ) + log q ( x ) ) ( 6 ) and , B =summationdisplay x log p ( x ) +summationdisplay x log q ( x ) ( 7 ) 1994 ) : sim =summationdisplay x abs ( r ( x ) − s ( x ) ) ( 8 ) ric relative entropy , the original de nition of KL-distance given by Kullback and Leibler ) : sim =summationdisplay x p ( x ) log p ( x ) log q ( x ) +summationdisplay x q ( x ) log q ( x ) log p ( x ) ( 9 ) sim =summationdisplay x ( p ( x ) ∗log q ( x ) +q ( x ) ∗log p ( x ) ) ( 10 ) As can be noticed , all these measures , in a way , seem to be information theoretic in nature .</sentence>
				<definiendum id="0">sim =summationdisplay x ( abs</definiendum>
				<definiendum id="1">log p</definiendum>
				<definiendum id="2">− B</definiendum>
				<definiendum id="3">B =summationdisplay x log p</definiendum>
				<definiendum id="4">sim =summationdisplay</definiendum>
				<definiens id="0">p ( x ) ( 9 ) sim =summationdisplay x ( p ( x ) ∗log q</definiens>
			</definition>
			<definition id="2">
				<sentence>These parameters allow the algorithm to be tuned 66 Table 1 : DESCRIPTION OF DATA SETS Names Total Count Languages Afrikaans ( 1 ) , Assamese ( 1 ) , Bengali ( 2 ) , Bulgarian ( 1 ) , Catalan ( 1 ) Czech ( 1 ) , Danish ( 1 ) , Dutch ( 1 ) , English ( 1 ) , Esperanto ( 1 ) Finnish ( 1 ) , French ( 1 ) , German ( 1 ) , Gujarati ( 2 ) , Hindi ( 8 ) Icelandic ( 1 ) , Iloko ( 1 ) , Iroquoian ( 1 ) , Italian ( 1 ) , Kannada ( 1 ) Khasi ( 1 ) , Latin ( 1 ) , Malayalam ( 1 ) , Marathi ( 5 ) , Modern Greek ( 1 ) Nahuatl ( 1 ) , Norwegian ( 1 ) , Oriya ( 2 ) , Polish ( 1 ) , Portugues ( 1 ) Punjabi ( 1 ) , Romanian ( 1 ) , Russian ( 1 ) , Serbian ( 1 ) , Spanish ( 1 ) Tagalog ( 1 ) , Tamil ( 1 ) , Telugu ( 1 ) , Welsh ( 1 ) 39 Encodings UTF8 ( 7 ) , ISO-8859-1 ( 16 ) , ISO-8859-2 ( 1 ) , US-ASCII ( 4 ) Windows-1251 ( 2 ) , Windows-1250 ( 1 ) , ISCII ( 10 ) , ISFOCB ( 1 ) ITrans ( 1 ) , Shusha ( 1 ) , Typewriter ( 1 ) , WX ( 1 ) , Gopika ( 1 ) Govinda ( 1 ) , Manjusha ( 1 ) , Saamanaa ( 1 ) , Subak ( 1 ) Akruti Sarala ( 1 ) , Webdunia ( 1 ) 19 Counts in parenthesis represent the extra ambiguity for that language or encoding .</sentence>
				<definiendum id="0">Punjabi</definiendum>
				<definiens id="0">1 ) , Gopika ( 1 ) Govinda ( 1 )</definiens>
			</definition>
			<definition id="3">
				<sentence>This API uses another API to prepare pruned character and word n-grams which was developed as part of another project .</sentence>
				<definiendum id="0">API</definiendum>
				<definiens id="0">uses another API to prepare pruned character and word n-grams which was developed as part of another project</definiens>
			</definition>
			<definition id="4">
				<sentence>• LPD : Log probability difference • ALPD : Absolute log probability difference • CE : Cross entropy • RE : RE measure based on relative entropy • JC : JC measure ( based on Jiang and Conrath’s measure ) • CT : Cavnar and Trenkle’s out of rank measure • MRE : MRE measure based on mutual ( symmetric ) relative entropy • MCE : Mutual ( symmetric ) cross entropy We tested on six different sizes in terms of characters , namely 100 , 200 , 500 , 1000 , 2000 , and all the available test data ( which was not equal for various language-encoding pairs ) .</sentence>
				<definiendum id="0">symmetric ) relative entropy • MCE</definiendum>
				<definiens id="0">Log probability difference • ALPD : Absolute log probability difference • CE : Cross entropy • RE : RE measure based on relative entropy • JC : JC measure ( based on Jiang and Conrath’s measure ) • CT : Cavnar and Trenkle’s out of rank measure</definiens>
			</definition>
</paper>

		<paper id="3504">
			<definition id="0">
				<sentence>Syntax-Semantics Templates ( or templates ) capture the linking between the syntax and semantics ( LF type and semantic roles ) of a word .</sentence>
				<definiendum id="0">Syntax-Semantics Templates</definiendum>
				<definiens id="0">or templates ) capture the linking between the syntax and semantics ( LF type and semantic roles ) of a word</definiens>
			</definition>
			<definition id="1">
				<sentence>VERBNET is a hierarchical verb lexicon in which verbs are organised in classes .</sentence>
				<definiendum id="0">VERBNET</definiendum>
				<definiens id="0">a hierarchical verb lexicon in which verbs are organised in classes</definiens>
			</definition>
			<definition id="2">
				<sentence>The role mapping is one to many ( each VERBNET role maps to 1 to 8 TRIPS roles ) , however , since the appropriate LF type has been identified prior to argument mapping , we usually have a unique mapping based on the roles defined by the LF type.6 Once the classes and semantic roles have been aligned , the mapping of syntactic functions between the intermediate representation and TRIPS syntax is quite straightforward .</sentence>
				<definiendum id="0">role mapping</definiendum>
				<definiendum id="1">VERBNET role</definiendum>
				<definiendum id="2">TRIPS</definiendum>
				<definiens id="0">maps to 1 to 8 TRIPS roles ) , however , since the appropriate LF type has been identified prior to argument mapping</definiens>
				<definiens id="1">a unique mapping based on the roles defined by the LF type.6 Once the classes and semantic roles have been aligned , the mapping of syntactic functions between the intermediate representation</definiens>
			</definition>
			<definition id="3">
				<sentence>29 ; ; entries ( relish ( SENSES ( ( EXAMPLE `` The tourists admired the paintings '' ) ( LF-PARENT LF : :EXPERIENCER-EMOTION ) ( TEMPL VN-EXPERIENCER-THEME-TEMPL-84 ) ) ( ( EXAMPLE `` The children liked that the clown had a red nose '' ) ( LF-PARENT LF : :EXPERIENCER-EMOTION ) ( TEMPL VN-EXPERIENCER-THEME-XP-TEMPL-87 ) ) ) ) ; ; Templates ( VN-EXPERIENCER-THEME-TEMPL-84 ( ARGUMENTS ( LSUBJ ( % NP ) LF : :EXPERIENCER ) ( LOBJ ( % NP ) LF : :THEME ) ) ) ( VN-EXPERIENCER-THEME-XP-TEMPL-87 ( ARGUMENTS ( LSUBJ ( % NP ) LF : :EXPERIENCER ) ( LCOMP ( % CP ( vform fin ) ( ctype s-finite ) ) LF : :THEME ) ) ) Figure 3 : Sample TRIPS generated entries LF-PARENT ) and to a template ( line introduced by TEMPL ) generated on the fly by our syntactic conversion algorithm .</sentence>
				<definiendum id="0">; entries</definiendum>
				<definiens id="0">tourists admired the paintings '' ) ( LF-PARENT LF : :EXPERIENCER-EMOTION ) ( TEMPL VN-EXPERIENCER-THEME-TEMPL-84</definiens>
				<definiens id="1">:EXPERIENCER ) ( LCOMP ( % CP ( vform fin ) ( ctype s-finite ) ) LF : :THEME ) ) ) Figure 3 : Sample TRIPS generated entries LF-PARENT ) and to a template ( line introduced by TEMPL ) generated on the</definiens>
			</definition>
			<definition id="4">
				<sentence>For both techniques , we evaluate how many word senses were added , and the number of different words defined and VERBNET classes covered .</sentence>
				<definiendum id="0">VERBNET</definiendum>
				<definiens id="0">classes covered</definiens>
			</definition>
			<definition id="5">
				<sentence>The results of evaluation are shown in Table 2.7 Since for mapping with syntax filtering we considered all possible TRIPS-VERBNET intersections , it in effect presents an upper bound the number of words shared between the two databases .</sentence>
				<definiendum id="0">upper bound</definiendum>
				<definiens id="0">the number of words shared between the two databases</definiens>
			</definition>
</paper>

		<paper id="2927">
			<definition id="0">
				<sentence>Support Vector Machines ( SVMs ) are utilized to determine the word dependency attachments .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs</definiendum>
				<definiens id="0">utilized to determine the word dependency attachments</definiens>
			</definition>
			<definition id="1">
				<sentence>Then , a maximum entropy method ( MaxEnt ) is used for determining the label of the dependency relation .</sentence>
				<definiendum id="0">maximum entropy method</definiendum>
				<definiendum id="1">MaxEnt</definiendum>
				<definiens id="0">determining the label of the dependency relation</definiens>
			</definition>
			<definition id="2">
				<sentence>The features for dependency analysis BOS BOS BOS 收復 VC V 臺灣 Nb N 的 DE DE 偉大 VH V 功業 Nac N 鄭成功 Na N S I position t-1position t-2 The child of the position t-1 position n position n+1position n+2position t A feature : the distance between the position t and n FORM LEMMA CPOSTAG POSTAG FEATS Key : The features for machine learning of each token the label .</sentence>
				<definiendum id="0">n FORM LEMMA CPOSTAG POSTAG FEATS Key</definiendum>
				<definiens id="0">machine learning of each token the label</definiens>
			</definition>
			<definition id="3">
				<sentence>The architecture of the parser consists of four major procedures and as in Fig.1 : ( i ) Decide the neighboring dependency attachment between all adjacent words in the input sentence by SVM-based tagger ( as a preprocessing ) ( ii ) Extract the surrounding features for the focused pair of nodes .</sentence>
				<definiendum id="0">architecture of the parser</definiendum>
			</definition>
			<definition id="4">
				<sentence>S and I are stacks , S keeps the words being in consideration , and I keeps the words to be processed .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">keeps the words being in consideration</definiens>
			</definition>
</paper>

		<paper id="1623">
			<definition id="0">
				<sentence>We represent ordering of events as a temporal directed acyclic graph ( TDAG ) .</sentence>
				<definiendum id="0">TDAG</definiendum>
				<definiens id="0">a temporal directed acyclic graph</definiens>
			</definition>
			<definition id="1">
				<sentence>In contrast to many existing temporal representations ( Allen , 1984 ; Pustejovsky et al. , 2003 ) , TDAG is a coarse annotation scheme : it does not capture interval overlap and distinguishes only a subset of commonly used ordering relations .</sentence>
				<definiendum id="0">TDAG</definiendum>
				<definiens id="0">a coarse annotation scheme : it does not capture interval overlap and distinguishes only a subset of commonly used ordering relations</definiens>
			</definition>
			<definition id="2">
				<sentence>These summaries consist of 97 segments , and their transitive closure contain a total of 1,331 edges .</sentence>
				<definiendum id="0">These summaries</definiendum>
				<definiens id="0">consist of 97 segments , and their transitive closure contain a total of 1,331 edges</definiens>
			</definition>
</paper>

		<paper id="2705">
			<definition id="0">
				<sentence>The empirical evidence for the investigation consists in a corpus of English originals , their German translations as well as German originals and their English translations .</sentence>
				<definiendum id="0">empirical evidence for the investigation</definiendum>
				<definiens id="0">consists in a corpus of English originals , their German translations as well as German originals and their English translations</definiens>
			</definition>
			<definition id="1">
				<sentence>Alto35 gether the CroCo Corpus comprises one million words .</sentence>
				<definiendum id="0">Alto35 gether the CroCo Corpus</definiendum>
				<definiens id="0">comprises one million words</definiens>
			</definition>
			<definition id="2">
				<sentence>The XPointer links the annotation of each function to the chunk id in the chunk index file .</sentence>
				<definiendum id="0">XPointer</definiendum>
				<definiens id="0">links the annotation of each function to the chunk id in the chunk index file</definiens>
			</definition>
			<definition id="3">
				<sentence>The classification of English and German linguistic units and relations chosen for the CroCo project ( i.e. for the investigation of explicitation in translations and originals ) is reflected in the CroCo annotation and alignment schemes and thus in the CroCo Corpus annotation and alignment .</sentence>
				<definiendum id="0">CroCo project</definiendum>
				<definiens id="0">reflected in the CroCo annotation and alignment schemes and thus in the CroCo Corpus annotation and alignment</definiens>
			</definition>
</paper>

		<paper id="3709">
</paper>

		<paper id="2107">
			<definition id="0">
				<sentence>Role Description TMP Temporalaspects LOC Location , position PRP Purpose , function WRT Withrespectto CHR Characteristic ( propertyascription ) CUM Cum ( i.e. , with , accompanying ) CBY Causedby CAU Causes BMO Bymeansof , instrument , via CMP Comprising , haspart POF Partof AGT Agentofactorprocess PNT Patientofactorprocess SRC Sourceofactorprocess RST Resultofactorprocess DST Destinationofmovingprocess Table 1 : The set of possible relations used in the annotation process ( Nilsson , 2001 ) 46 Following the initial annotation , we performed an analysis of all occurences of the relations and the ontological types of their arguments .</sentence>
				<definiendum id="0">CUM Cum</definiendum>
				<definiens id="0">The set of possible relations used in the annotation process</definiens>
				<definiens id="1">the relations and the ontological types of their arguments</definiens>
			</definition>
			<definition id="1">
				<sentence>• A static locative relation consists of just one subevent , and it denotes ’being located at’ .</sentence>
				<definiendum id="0">static locative relation</definiendum>
				<definiens id="0">consists of just one subevent , and it denotes ’being located at’</definiens>
			</definition>
</paper>

		<paper id="3003">
			<definition id="0">
				<sentence>Interactive QA assumes an interaction between the human and the computer , typically through a combination of a clarification dialogue and user modeling to capture previous interactions of users with the system .</sentence>
				<definiendum id="0">Interactive QA</definiendum>
				<definiens id="0">assumes an interaction between the human and the computer , typically through a combination of a clarification dialogue and user modeling to capture previous interactions of users with the system</definiens>
			</definition>
			<definition id="1">
				<sentence>The answer finding process draws on models of question types and document-based knowledge to seek answers without additional feedback from the user .</sentence>
				<definiendum id="0">answer finding process</definiendum>
				<definiens id="0">draws on models of question types and document-based knowledge to seek answers without additional feedback from the user</definiens>
			</definition>
			<definition id="2">
				<sentence>The QA system provides answers in the form of short answers , sentences , and answer-providing passages , as well as links to the full answer-providing documents .</sentence>
				<definiendum id="0">QA system</definiendum>
				<definiens id="0">provides answers in the form of short answers , sentences , and answer-providing passages</definiens>
			</definition>
			<definition id="3">
				<sentence>The QTB enables organizations to identify questions for which they want human intervention and to build specialized term expansion sets for terms in the collection .</sentence>
				<definiendum id="0">QTB</definiendum>
				<definiens id="0">enables organizations to identify questions for which they want human intervention and to build specialized term expansion sets for terms in the collection</definiens>
			</definition>
			<definition id="4">
				<sentence>Knowledge Base Builder ( KBB ) is a suite of tools developed for both commercial and government customers .</sentence>
				<definiendum id="0">KBB )</definiendum>
				<definiens id="0">a suite of tools developed for both commercial and government customers</definiens>
			</definition>
			<definition id="5">
				<sentence>Question Similarity : Question Similarity is the task of identifying when two or more questions are related .</sentence>
				<definiendum id="0">Question Similarity</definiendum>
				<definiens id="0">the task of identifying when two or more questions are related</definiens>
			</definition>
</paper>

		<paper id="2609">
			<definition id="0">
				<sentence>A maximum entropy classifier which incorporates features referring to the position of the sentence in the document as well as various syntactic features , gives the best results .</sentence>
				<definiendum id="0">maximum entropy classifier</definiendum>
			</definition>
			<definition id="1">
				<sentence>Answers to such questions ( asking for the definition of a concept ) are typically found in sentences such as A runner’s knee is a degenerative condition of the cartilage surface of the back of the knee cap , or patella or A cerebrovascular accident is a decrease in the number of circulating white blood cells ( leukocytes ) in the blood .</sentence>
				<definiendum id="0">cerebrovascular accident</definiendum>
				<definiens id="0">a decrease in the number of circulating white blood cells ( leukocytes ) in the blood</definiens>
			</definition>
			<definition id="2">
				<sentence>For instance , sentences such as RSI is a major problem in the Netherlands , every suicide attempt is an emergency or an infection of the lungs is the most serious complication are of the relevant syntactic form , but do not constitute definitions .</sentence>
				<definiendum id="0">RSI</definiendum>
				<definiens id="0">the most serious complication are of the relevant syntactic form , but do not constitute definitions</definiens>
			</definition>
			<definition id="3">
				<sentence>On the other hand , we do include sentences in which the predicative phrase precedes the subject , as in Onderdeel van de testis is de Leydig-cel ( the Leydig cel is part of the testis ) .</sentence>
				<definiendum id="0">Leydig-cel</definiendum>
				<definiens id="0">sentences in which the predicative phrase precedes the subject</definiens>
			</definition>
			<definition id="4">
				<sentence>One of the criteria for undecided sentences is that it mentions a characteristic of a definition but is not really a ( complete ) definition , for example , Benzeen is carcinogeen ( Benzene is a carcinogen ) .</sentence>
				<definiendum id="0">Benzene</definiendum>
				<definiens id="0">a carcinogen )</definiens>
			</definition>
			<definition id="5">
				<sentence>As shown in Table 2 , the majority of subjects in definition sentences have no determiner ( 62 % ) , e.g. Paracetamol is een pijnstillend en koortsverlagend middel ( Paracetamol is an pain alleviating and a fever reducing medicine ) , while in nondefinition sentences subject determiners tend to be definite ( 50 % ) , e.g. De werkzame stof is acetylsalicylzuur ( The operative substance is acetylsalicylacid ) .</sentence>
				<definiendum id="0">Paracetamol</definiendum>
				<definiens id="0">an pain alleviating and a fever reducing medicine</definiens>
			</definition>
			<definition id="6">
				<sentence>Naive Bayes is a fast and easy to use classifier based on the probabilistic model of text and has often been used in text classification tasks as a baseline .</sentence>
				<definiendum id="0">Naive Bayes</definiendum>
				<definiens id="0">a fast and easy to use classifier based on the probabilistic model of text and has often been used in text classification tasks as a baseline</definiens>
			</definition>
			<definition id="7">
				<sentence>Maximum entropy is a general estimation technique that has been used in many fields such as information retrieval and machine learning .</sentence>
				<definiendum id="0">Maximum entropy</definiendum>
				<definiens id="0">a general estimation technique that has been used in many fields such as information retrieval and machine learning</definiens>
			</definition>
</paper>

		<paper id="0707">
			<definition id="0">
				<sentence>The Document Understanding Conference ( DUC ) is a series of evaluations of automatic text summarization systems .</sentence>
				<definiendum id="0">Document Understanding Conference ( DUC )</definiendum>
				<definiens id="0">a series of evaluations of automatic text summarization systems</definiens>
			</definition>
			<definition id="1">
				<sentence>Since the number of ROUGE evaluations per topic varied depending on the number of reference summaries , we computed a macroaverage of each score for each peer , where the macro-average score is the mean over all topics of the mean per-topic score for the peer .</sentence>
				<definiendum id="0">macro-average score</definiendum>
				<definiens id="0">the mean over all topics of the mean per-topic score for the peer</definiens>
			</definition>
			<definition id="2">
				<sentence>Unlike responsiveness and linguistic quality scores , which are ordinal data and are best suited for non-parametric analyses , ROUGE scores , can be measured on an interval scale and are suitable for parametric analysis .</sentence>
				<definiendum id="0">ROUGE scores</definiendum>
				<definiens id="0">are ordinal data and are best suited for non-parametric analyses</definiens>
			</definition>
</paper>

		<paper id="2405">
			<definition id="0">
				<sentence>Melamed computes the translational distribution T of a word s in a source language and uses it to measure the translational entropy of the wordH ( T|s ) ; this entropy approximates the semantic entropy of the word that can be interpreted either as ( a ) the semantic ambiguity or ( b ) the inverse of reliability .</sentence>
				<definiendum id="0">Melamed</definiendum>
				<definiens id="0">computes the translational distribution T of a word s in a source language and uses it to measure the translational entropy of the wordH ( T|s ) ; this entropy approximates the semantic entropy of the word that can be interpreted either as ( a ) the semantic ambiguity or ( b ) the inverse of reliability</definiens>
			</definition>
			<definition id="1">
				<sentence>Entropy is a good measure for the unpredictability of an event .</sentence>
				<definiendum id="0">Entropy</definiendum>
				<definiens id="0">a good measure for the unpredictability of an event</definiens>
			</definition>
			<definition id="2">
				<sentence>H ( Ts|s ) = − summationdisplay t∈Ts P ( t|s ) logP ( t|s ) ( 1 ) This measure is equivalent to translational entropy ( Melamed , 1997b ) .</sentence>
				<definiendum id="0">H</definiendum>
			</definition>
			<definition id="3">
				<sentence>P ( t|s ) is estimated as the proportion of alignment t among all alignments of word s found in the corpus in the context of the given triple.6 Finally , the translational entropy of a triple is the average translational entropy of its components .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">the proportion of alignment t among all alignments of word s found in the corpus in the context of the given triple.6 Finally , the translational entropy of a triple is the average translational entropy of its components</definiens>
			</definition>
			<definition id="4">
				<sentence>Score NL-EN NL-ES NL-DE entropy without NO LINKS 0.864 0.892 0.907 NO LINKS=many 0.858 0.890 0.883 NO LINKS=one 0.859 0.890 0.911 pda 0.891 0.894 0.894 baseline 0.755 0.755 0.755 Table 4 : Translational entropy and the pda across three language pairs .</sentence>
				<definiendum id="0">Score NL-EN NL-ES NL-DE entropy</definiendum>
			</definition>
			<definition id="5">
				<sentence>Translational entropy measures the predictability of the translation of an expression by looking at the links of its components to a target language .</sentence>
				<definiendum id="0">Translational entropy</definiendum>
				<definiens id="0">measures the predictability of the translation of an expression by looking at the links of its components to a target language</definiens>
			</definition>
</paper>

		<paper id="3104">
			<definition id="0">
				<sentence>Given a source-language parse tree T1 , a QG defines a monolingual grammar that generates translations of T1 .</sentence>
				<definiendum id="0">QG</definiendum>
				<definiens id="0">defines a monolingual grammar that generates translations of T1</definiens>
			</definition>
			<definition id="1">
				<sentence>We seek to model the conditional probability p ( T2 , A | T1 ) ( 1 ) where T1 is a parse tree for S1 , T2 is a parse tree for S2 , and A is a node-to-node alignment between them .</sentence>
				<definiendum id="0">T1</definiendum>
				<definiendum id="1">T2</definiendum>
				<definiendum id="2">A</definiendum>
				<definiens id="0">a parse tree for S1</definiens>
				<definiens id="1">a parse tree for S2</definiens>
				<definiens id="2">a node-to-node alignment between them</definiens>
			</definition>
			<definition id="2">
				<sentence>A quasi-synchronous grammar is a monolingual grammar that generates translations of a sourcelanguage sentence .</sentence>
				<definiendum id="0">quasi-synchronous grammar</definiendum>
				<definiens id="0">a monolingual grammar that generates translations of a sourcelanguage sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>The QCFG generates the target sentence using nonterminals from the cross product U × 2V1 , where U is the set of monolingual target-language nonterminals such as NP , and V1 is the set of nodes in T1 .</sentence>
				<definiendum id="0">U</definiendum>
				<definiendum id="1">V1</definiendum>
				<definiens id="0">the set of nodes in T1</definiens>
			</definition>
			<definition id="4">
				<sentence>Similarly , a quasi-synchronous tree-substitution grammar ( QTSG ) annotates the root and frontier nodes of its elementary trees with sets of source nodes from 2V1 .</sentence>
				<definiendum id="0">quasi-synchronous tree-substitution grammar</definiendum>
				<definiendum id="1">QTSG</definiendum>
				<definiens id="0">annotates the root and frontier nodes of its elementary trees with sets of source nodes from 2V1</definiens>
			</definition>
			<definition id="5">
				<sentence>In scoring dependency attachments , DMV uses tags rather than words .</sentence>
				<definiendum id="0">DMV</definiendum>
				<definiens id="0">uses tags rather than words</definiens>
			</definition>
			<definition id="6">
				<sentence>We thus use the conditional probability ptrans ( a | aprime ) that source word aprime , which may be NULL , translates as target word a. Finally , when a parent word h aligned to hprime generates a child , we stochastically decide to align the child to a node aprime in T1 with one several possible relations to hprime .</sentence>
				<definiendum id="0">conditional probability ptrans</definiendum>
				<definiens id="0">a | aprime ) that source word aprime , which may be NULL , translates as target word a. Finally , when a parent word h aligned to hprime generates a child</definiens>
				<definiens id="1">the child to a node aprime in T1 with one several possible relations to hprime</definiens>
			</definition>
			<definition id="7">
				<sentence>TotesttheexplanatorypowerofourQCFG , weevaluated its conditional cross-entropy on held-out data ( table 1 ) .</sentence>
				<definiendum id="0">TotesttheexplanatorypowerofourQCFG</definiendum>
			</definition>
</paper>

		<paper id="3814">
			<definition id="0">
				<sentence>Our results for nouns show that thanks to the optimization of parameters and the mapping method , HyperLex obtains results close to supervised systems using the same kind of bag-ofwords features .</sentence>
				<definiendum id="0">HyperLex</definiendum>
				<definiens id="0">the optimization of parameters and the mapping method</definiens>
			</definition>
			<definition id="1">
				<sentence>Word sense disambiguation ( WSD ) is a key enabling technology .</sentence>
				<definiendum id="0">Word sense disambiguation ( WSD</definiendum>
				<definiens id="0">a key enabling technology</definiens>
			</definition>
			<definition id="2">
				<sentence>If the scores are organized in a score vector , all values are 0 , except , say , the i-th component , which receives a score d ( hi , v ) , which is the distance between the hub hi and the node representing the word v. Thus , d ( hi , v ) assigns a score of 1 to hubs and the score decreases as the nodes move away from the hub in the tree .</sentence>
				<definiendum id="0">i-th component</definiendum>
				<definiens id="0">receives a score d ( hi , v ) , which is the distance between the hub hi and the node representing the word v. Thus , d ( hi , v ) assigns a score of 1 to hubs and the score decreases as the nodes move away from the hub in the tree</definiens>
			</definition>
			<definition id="3">
				<sentence>Base corpus hyperLex_wsd hyperLex_wsd hyperLex Evaluator Tagged corpus Test corpus Mapping corpus MST matrix Mapping Figure 1 : Design for the automatic mapping and evaluation of HyperLex algorithm against a gold standard ( test corpora ) .</sentence>
				<definiendum id="0">Base corpus hyperLex_wsd hyperLex_wsd hyperLex Evaluator Tagged</definiendum>
				<definiendum id="1">test corpora</definiendum>
				<definiens id="0">corpus Test corpus Mapping corpus MST matrix Mapping Figure 1 : Design for the automatic mapping and evaluation of HyperLex algorithm against a gold standard</definiens>
			</definition>
			<definition id="4">
				<sentence>• The Test Corpus : a separate collection , also annotated with senses .</sentence>
				<definiendum id="0">Test Corpus</definiendum>
				<definiens id="0">a separate collection , also annotated with senses</definiens>
			</definition>
			<definition id="5">
				<sentence>Then , M = { mij } 1 ≤ i ≤ m,1 ≤ j ≤ n , and each mij = P ( sj|hi ) , that is , mij is the probability of a word having sense j given that it has been assigned hub i. This probability can be computed counting the times an occurrence with sense sj has been assigned hub hi .</sentence>
				<definiendum id="0">mij</definiendum>
			</definition>
			<definition id="6">
				<sentence>Defined means the number of hubs induced , and used means the ones actually returned by HyperLex when disambiguating the test set .</sentence>
				<definiendum id="0">Defined</definiendum>
				<definiens id="0">means the number of hubs induced , and used means the ones actually returned by HyperLex when disambiguating the test set</definiens>
			</definition>
			<definition id="7">
				<sentence>We include three supervised systems , the winner of S3LS ( Mihalcea et al. , 2004 ) , an in-house system ( kNN-all , CITATION OMITTED ) which uses optimized kNN , and the same in-house system restricted to bag-of-words features only ( kNN-bow ) , i.e. discarding other local features like bigrams or trigrams ( which is what most unsupervised systems do ) .</sentence>
				<definiendum id="0">in-house system</definiendum>
				<definiendum id="1">CITATION OMITTED )</definiendum>
				<definiens id="0">uses optimized kNN</definiens>
			</definition>
			<definition id="8">
				<sentence>We also plan to apply the parameters to the Senseval 3 allwords task , which seems well fit for HyperLex : the best supervised system only outperforms MFS by a few points in this setting , and the training corpora used ( Semcor ) is not related to the test corpora ( mainly Wall Street Journal texts ) .</sentence>
				<definiendum id="0">Semcor</definiendum>
				<definiens id="0">the best supervised system only outperforms MFS by a few points in this setting</definiens>
			</definition>
</paper>

		<paper id="1413">
			<definition id="0">
				<sentence>A domain consists of a set D of objects , and a set P of properties applicable to objects in D. A description is a subset of P. The denotation of S , written [ [ S ] ] , is { x ∈ D | ∀p ∈ S : p ( x ) } .</sentence>
				<definiendum id="0">domain</definiendum>
				<definiens id="0">consists of a set D of objects , and a set P of properties applicable to objects in D. A description is a subset of P. The denotation of S , written [ [ S ] ] , is { x ∈ D | ∀p ∈ S : p ( x ) }</definiens>
			</definition>
			<definition id="1">
				<sentence>Our fC operates on the description S , not just on the number of distractors , so it can assess the aptness of the denotation of any potential S. However , it has to ensure that this denotation ( subarea of the surface ) contains the target ( contaminated area ) , and does not contain too much beyond that .</sentence>
				<definiendum id="0">fC</definiendum>
				<definiens id="0">operates on the description S , not just on the number of distractors</definiens>
			</definition>
</paper>

		<paper id="1503">
			<definition id="0">
				<sentence>Frameworkand language-neutral syntactic invariants Using a MG , and following Candito , we can postulate cross-linguistic and crossframework syntactic invariants such as : 17 a0 The notion of subcategorization a0 The existence of a finite number of syntactic functions ( subject , object etc. ) a0 The existence of a finite number of syntactic categories ( NP , PP , etc. ) a0 The existence of valency alternations ( Candito’s dimension 2 ) a0 The existence , orthogonal to valency alternations , of syntactic phenomena which do not alter valency , such as wh-movement ( Candito’s dimension 3 ) .</sentence>
				<definiendum id="0">wh-movement</definiendum>
				<definiens id="0">The existence of a finite number of syntactic functions ( subject , object etc. ) a0 The existence of a finite number of syntactic categories</definiens>
			</definition>
			<definition id="1">
				<sentence>A ST is a TAG elementary tree , which provides richer information than standard POS tagging , but in a framework-specific manner ( TAG ) , and also in a grammar-specific manner since a ST tagset can’t be ported from one TAG to another TAG .</sentence>
				<definiendum id="0">ST</definiendum>
				<definiendum id="1">TAG</definiendum>
				<definiens id="0">a TAG elementary tree , which provides richer information than standard POS tagging , but in a framework-specific manner</definiens>
			</definition>
			<definition id="2">
				<sentence>A HT is an abstraction of STs , where the main syntactic properties of any given ST is encoded in a general readable Feature Structure ( FS ) , by recording which MG classes a ST inherited from when it was generated .</sentence>
				<definiendum id="0">HT</definiendum>
				<definiens id="0">an abstraction of STs , where the main syntactic properties of any given ST is encoded in a general readable Feature Structure ( FS ) , by recording which MG classes a ST inherited from when it was generated</definiens>
			</definition>
			<definition id="3">
				<sentence>In XMG , an MG consists of a set of classes similar to those in object-oriented programming , which are structured into a multiple inheritance hierarchy .</sentence>
				<definiendum id="0">MG</definiendum>
				<definiens id="0">consists of a set of classes similar to those in object-oriented programming , which are structured into a multiple inheritance hierarchy</definiens>
			</definition>
			<definition id="4">
				<sentence>The Verb-Second ( V2 ) phenomenon is a wellknown set of data that demonstrates small-scale cross-linguistic variation .</sentence>
				<definiendum id="0">Verb-Second</definiendum>
				<definiens id="0">a wellknown set of data that demonstrates small-scale cross-linguistic variation</definiens>
			</definition>
			<definition id="5">
				<sentence>a0 Top ( topic ) : a feature which creates a specifier position for the topic ( semantically represented in a lambda abstraction ) which must be filled in a derivation , and which does not allow recursion .</sentence>
				<definiendum id="0">Top ( topic )</definiendum>
			</definition>
			<definition id="6">
				<sentence>The maximal projection expresses the expected feature content .</sentence>
				<definiendum id="0">maximal projection</definiendum>
				<definiens id="0">expresses the expected feature content</definiens>
			</definition>
			<definition id="7">
				<sentence>A topology is a combination of the projection and any combination of heads allowed by the language-specific head inventory .</sentence>
				<definiendum id="0">topology</definiendum>
				<definiens id="0">a combination of the projection and any combination of heads allowed by the language-specific head inventory</definiens>
			</definition>
</paper>

		<paper id="0612">
			<definition id="0">
				<sentence>94 The Functional Generative Description ( FGD ) ( Sgall et al. , 1986 ) is a dependency-based formal strati cational language description framework that goes back to the functional-structural Prague School .</sentence>
				<definiendum id="0">Functional Generative Description</definiendum>
				<definiens id="0">a dependency-based formal strati cational language description framework that goes back to the functional-structural Prague School</definiens>
			</definition>
			<definition id="1">
				<sentence>FGD captures valency in the underlying syntax ( the so-called tectogrammatical language layer ) .</sentence>
				<definiendum id="0">FGD captures valency</definiendum>
				<definiens id="0">the so-called tectogrammatical language layer )</definiens>
			</definition>
			<definition id="2">
				<sentence>Treebank The Prague English Dependency Treebank ( PEDT ) stands for the data from Wall Street Journal section of the Penn Treebank annotated in the PDT 2.0 shape .</sentence>
				<definiendum id="0">PEDT )</definiendum>
				<definiens id="0">the data from Wall Street Journal section of the Penn Treebank annotated in the PDT 2.0 shape</definiens>
			</definition>
			<definition id="3">
				<sentence>EngValLex is a supporting tool for the manual annotation of the tectogrammatical layer of PEDT .</sentence>
				<definiendum id="0">EngValLex</definiendum>
				<definiens id="0">a supporting tool for the manual annotation of the tectogrammatical layer of PEDT</definiens>
			</definition>
			<definition id="4">
				<sentence>On the topmost level , EngValLex consists of word entries , which are characterized by lemmas .</sentence>
				<definiendum id="0">EngValLex</definiendum>
				<definiens id="0">consists of word entries , which are characterized by lemmas</definiens>
			</definition>
			<definition id="5">
				<sentence>Each word entry consists of a sequence of frame entries , which roughly correspond to individual senses of the word entry and contain the valency information .</sentence>
				<definiendum id="0">word entry</definiendum>
				<definiens id="0">consists of a sequence of frame entries , which roughly correspond to individual senses of the word entry and contain the valency information</definiens>
			</definition>
			<definition id="6">
				<sentence>IN ) The ACT ( Actor ) can be any noun in the subjective case ( the abbreviation n ) , the PAT ( Patient ) can be a particle to with a daughter verb , and the LOC ( Locative ) can be the preposition at .</sentence>
				<definiendum id="0">Actor</definiendum>
				<definiendum id="1">LOC ( Locative</definiendum>
				<definiens id="0">the abbreviation n ) , the PAT ( Patient ) can be a particle to with a daughter verb</definiens>
			</definition>
			<definition id="7">
				<sentence>Moreover , EngValLex contains links to external data sources ( e.g. lexicons ) from words , frames , valency slots and example sentences .</sentence>
				<definiendum id="0">EngValLex</definiendum>
				<definiens id="0">contains links to external data sources ( e.g. lexicons ) from words , frames , valency slots and example sentences</definiens>
			</definition>
</paper>

		<paper id="2924">
</paper>

		<paper id="1319">
			<definition id="0">
				<sentence>We de ne an interpretation of a user’s argument as the tuple fSC , IG , EEg , where SC is a supposition con guration , IG is an interpretation graph , and EE are explanatory extensions .</sentence>
				<definiendum id="0">SC</definiendum>
				<definiendum id="1">IG</definiendum>
				<definiens id="0">a supposition con guration</definiens>
				<definiens id="1">an interpretation graph , and EE are explanatory extensions</definiens>
			</definition>
			<definition id="1">
				<sentence>The middle segment contains an excerpt of the domain BN which includes the interpretation ; the probabilities of some nodes are indicated with linguistic terms.2 The interpretation graph , which appears inside a light gray bubble in the BN excerpt , includes the extra node GreenInGardenAtTimeOfDeath ( boxed ) .</sentence>
				<definiendum id="0">GreenInGardenAtTimeOfDeath</definiendum>
				<definiens id="0">includes the interpretation</definiens>
			</definition>
			<definition id="2">
				<sentence>IntBest = argmaxi=1 , ... , qPr ( SCi , IGi , EEijArg ) where q is the number of interpretations .</sentence>
				<definiendum id="0">q</definiendum>
				<definiens id="0">the number of interpretations</definiens>
			</definition>
			<definition id="3">
				<sentence>The rst factor represents model complexity , and the second factor represents data t. Model complexity measures how dif cult it is to produce the model ( interpretation ) from the background knowledge .</sentence>
				<definiendum id="0">rst factor</definiendum>
				<definiens id="0">Model complexity measures how dif cult it is to produce the model</definiens>
			</definition>
			<definition id="4">
				<sentence>Data t measures how well the data ( argument ) matches the model ( interpretation ) .</sentence>
				<definiendum id="0">Data t</definiendum>
			</definition>
			<definition id="5">
				<sentence>The similarity between structural data and a structural model is a function of the number and type of operations required to convert the model into the data , e.g. , node and arc insertions and 4In the rare cases where n &gt; N/2 , smaller models do not yield lower probabilities .</sentence>
				<definiendum id="0">n &gt; N/2</definiendum>
				<definiens id="0">a function of the number and type of operations required to convert the model into the data , e.g. , node and arc insertions</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus , Equation 1 is simply Pr ( IGijArg ) = α Pr ( IGi ) Pr ( ArgjIGi ) ( 2 ) The difference in the calculations of model complexity and data t for numerical and structural information warrants the separation of structure and belief , which yields Pr ( IGijArg ) = α Pr ( bel IGi , struc IGi ) Pr ( bel Arg , struc Argjbel IGi , struc IGi ) After applying the chain rule of probability Pr ( IGijArg ) = α Pr ( bel IGijstruc IGi ) Pr ( struc IGi ) Pr ( bel Argjstruc Arg , bel IGi , struc IGi ) Pr ( struc Argjbel IGi , struc IGi ) Note that Pr ( bel IGijstruc IGi ) does not calculate the probability of ( or belief in ) the nodes in IGi .</sentence>
				<definiendum id="0">struc IGi</definiendum>
				<definiens id="0">yields Pr ( IGijArg ) = α Pr ( bel IGi , struc IGi ) Pr ( bel Arg , struc Argjbel IGi , struc IGi ) After applying the chain rule of probability Pr ( IGijArg ) = α Pr ( bel IGijstruc IGi ) Pr ( struc IGi ) Pr ( bel Argjstruc Arg , bel IGi</definiens>
			</definition>
			<definition id="7">
				<sentence>Now the model comprises the pair fSCi , IGig , and Equation 2 becomes Pr ( SCi , IGijArg ) = ( 4 ) α Pr ( SCi , IGi ) Pr ( ArgjSCi , IGi ) Similar probabilistic manipulations to those performed in Section 3.1 yield Pr ( SCi , IGijArg ) = ( 5 ) α Pr ( struc IGijSCi ) Pr ( SCi ) Pr ( bel ArgjSCi , bel IGi ) Pr ( struc Argjstruc IGi ) Table 2 : Probability More informed model Model complexity ( against background ) Pr ( struc IGijSCi ) structural complexity ↓Pr ( SCi ) ↑numerical discrepancy Data t with model Pr ( struc Argjstruc IGi ) structural discrepancy ↑Pr ( bel ArgjSCi , bel IGi ) ↓numerical discrepancy ( Recall that suppositions pertain to beliefs only , i.e. , they don’t have a structural component . )</sentence>
				<definiendum id="0">IGi ) Similar probabilistic</definiendum>
				<definiendum id="1">Pr ( struc IGijSCi ) Pr ( SCi ) Pr ( bel ArgjSCi , bel IGi ) Pr ( struc Argjstruc IGi</definiendum>
				<definiendum id="2">IGi</definiendum>
				<definiens id="0">Probability More informed model Model complexity ( against background ) Pr ( struc IGijSCi ) structural complexity ↓Pr ( SCi ) ↑numerical discrepancy Data t with model Pr ( struc Argjstruc IGi ) structural discrepancy ↑Pr ( bel ArgjSCi , bel</definiens>
			</definition>
</paper>

		<paper id="1646">
			<definition id="0">
				<sentence>Experiments on a large vocabulary task , namely the Czech portion of the MALACH corpus , demonstrate performance gain of about 1.1–1.5 % absolute in word error rate , wherein morphological features contribute about a third of the improvement .</sentence>
				<definiendum id="0">MALACH corpus</definiendum>
				<definiens id="0">the Czech portion of the</definiens>
			</definition>
			<definition id="1">
				<sentence>Czech speech recognition needs to deal with two sources of errors which are absent in English , namely , the inflectional morphology and the differences in the formal ( written ) and colloquial ( spoken ) forms .</sentence>
				<definiendum id="0">Czech speech recognition</definiendum>
			</definition>
			<definition id="2">
				<sentence>Czech is known as a free word-order language allowing for subject , object , and verbal components to come in any order .</sentence>
				<definiendum id="0">Czech</definiendum>
				<definiens id="0">a free word-order language allowing for subject , object , and verbal components to come in any order</definiens>
			</definition>
			<definition id="3">
				<sentence>The # Values field indicates the size of the closed set of possible values .</sentence>
				<definiendum id="0"># Values field</definiendum>
				<definiens id="0">indicates the size of the closed set of possible values</definiens>
			</definition>
			<definition id="4">
				<sentence>POS , case Captures associated POS/Case features ( e.g. , adjectives associated with nominative elements ) .</sentence>
				<definiendum id="0">POS/Case features</definiendum>
				<definiens id="0">adjectives associated with nominative elements )</definiens>
			</definition>
			<definition id="5">
				<sentence>χ2 ( f , c ) = ( P ( f , c ) −P ( f ) ) 2 P ( f ) + ( P ( f , ¯c ) −P ( f ) ) 2 P ( f ) + ( P ( ¯f , c ) −P ( ¯f ) ) 2 P ( ¯f ) + ( P ( ¯f , ¯c ) −P ( ¯f ) ) 2 P ( ¯f ) 394 This can be simplified using a two-way contingency table of feature and class , where A is the number of times f and c co-occur , B is the number of times f occurs without c , C is the number of times c occurs without f , and D is the number of times neither f nor c occurs , and N is the total number of examples .</sentence>
				<definiendum id="0">B</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">D</definiendum>
				<definiendum id="3">N</definiendum>
				<definiens id="0">the number of times f and c co-occur ,</definiens>
				<definiens id="1">the number of times f occurs without c ,</definiens>
				<definiens id="2">the number of times c occurs without f , and</definiens>
				<definiens id="3">the number of times neither f nor c occurs , and</definiens>
				<definiens id="4">the total number of examples</definiens>
			</definition>
</paper>

		<paper id="3005">
			<definition id="0">
				<sentence>Question Answering ( QA ) is an interactive human-machine process that aims to respond to users’ natural language questions with exact answers rather than a list of documents .</sentence>
				<definiendum id="0">Question Answering ( QA )</definiendum>
				<definiens id="0">an interactive human-machine process that aims to respond to users’ natural language questions with exact answers rather than a list of documents</definiens>
			</definition>
			<definition id="1">
				<sentence>34 Given the current question Qi and a sequence of history questions Qi−n , ... , Qi−1 : no references in the current question , Qi is a follow-up question .</sentence>
				<definiendum id="0">Qi</definiendum>
				<definiens id="0">a follow-up question</definiens>
			</definition>
			<definition id="2">
				<sentence>Confidence is defined as out of the training records for which the left hand side of the rule is true , the percentage of records for which the right hand side is also true .</sentence>
				<definiendum id="0">Confidence</definiendum>
				<definiens id="0">out of the training records for which the left hand side of the rule is true , the percentage of records for which the right hand side is also true</definiens>
			</definition>
			<definition id="3">
				<sentence>The HandQA data contain some noisy information , such as typos and bad grammars .</sentence>
				<definiendum id="0">HandQA data</definiendum>
				<definiens id="0">contain some noisy information , such as typos and bad grammars</definiens>
			</definition>
</paper>

		<paper id="1626">
			<definition id="0">
				<sentence>Conventional n-gram language modeling counts the frequency of all the n-grams in a corpus and calculates the conditional probabilities of a word given its history of n − 1 words P ( wi|wi−1i−n+1 ) .</sentence>
				<definiendum id="0">Conventional n-gram language modeling</definiendum>
			</definition>
			<definition id="1">
				<sentence>For each cut , calculate the point-wise mutual information ( PMI ) between the two short ngrams .</sentence>
				<definiendum id="0">PMI</definiendum>
				<definiens id="0">calculate the point-wise mutual information (</definiens>
			</definition>
			<definition id="2">
				<sentence>Client/server is the most common paradigm of distributed computing at present ( Leopold , 2001 ) .</sentence>
				<definiendum id="0">Client/server</definiendum>
			</definition>
			<definition id="3">
				<sentence>Hiero is a statistical phrase-based translation model that uses hierarchical phrases .</sentence>
				<definiendum id="0">Hiero</definiendum>
				<definiens id="0">a statistical phrase-based translation model that uses hierarchical phrases</definiens>
			</definition>
			<definition id="4">
				<sentence>Define the BLEU sentence-level gain for e ( r ) t as : GBLEUe ( r ) t = BLEU { e ( 1 ) 1 , e ( 1 ) 2 , ... , e ( r ) t , ... , e ( r ) T } − BLEU { e ( 1 ) 1 , e ( 1 ) 2 , ... , e ( 1 ) t , ... , e ( r ) T } GBLEUe ( r ) t calculates the gain if we switch the model-best hypothesis e ( 1 ) t using e ( r ) t for sentence ft and keep the translations for the rest of the test set untouched .</sentence>
				<definiendum id="0">Define the BLEU sentence-level gain for e</definiendum>
				<definiens id="0">keep the translations for the rest of the test set untouched</definiens>
			</definition>
			<definition id="5">
				<sentence>BLEU measures the similarity between the translation hypothesis and human reference by counting how many n-grams in MT can be found in the references .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">measures the similarity between the translation hypothesis</definiens>
			</definition>
</paper>

		<paper id="0706">
			<definition id="0">
				<sentence>The clustering is performed in advance of the prediction process by the intrinsic classi cation program Snob ( Wallace and Boulton , 1968 ) , using the content lemmas ( unigrams ) in the answers as features .</sentence>
				<definiendum id="0">content lemmas</definiendum>
				<definiens id="0">unigrams ) in the answers as features</definiens>
			</definition>
			<definition id="1">
				<sentence>Coverage is the proportion of requests for which a response can be generated .</sentence>
				<definiendum id="0">Coverage</definiendum>
				<definiens id="0">the proportion of requests for which a response can be generated</definiens>
			</definition>
			<definition id="2">
				<sentence>In three of the datasets , Answer Retrieval is the only method that produces good answers , successfully addressing 15-20 requests ( about 5 % of the requests in these datasets ) .</sentence>
				<definiendum id="0">Answer Retrieval</definiendum>
				<definiens id="0">the only method that produces good answers , successfully addressing 15-20 requests ( about 5 % of the requests in these datasets )</definiens>
			</definition>
</paper>

		<paper id="0804">
			<definition id="0">
				<sentence>Information Retrieval ( IR ) is an established eld and , today , the ‘conventional’ IR task is embodied by web searching .</sentence>
				<definiendum id="0">Information Retrieval</definiendum>
				<definiendum id="1">IR</definiendum>
				<definiens id="0">an established eld and , today , the ‘conventional’ IR task is embodied by web searching</definiens>
			</definition>
			<definition id="1">
				<sentence>IBM translation models try to model the translation probability ... which describes the relationship between a source language sentence ... and a target language sentence ... .</sentence>
				<definiendum id="0">IBM translation models</definiendum>
				<definiens id="0">translation probability ... which describes the relationship between a source language sentence ... and a target language sentence ...</definiens>
			</definition>
</paper>

		<paper id="1710">
			<definition id="0">
				<sentence>We perform 3 experiments : ply a one against all strategy , that is , we use X \ Yi as the set of negative examples for learning category Ci where X is the set of all training examples and Yi is the set of positive examples of Ci .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Yi</definiendum>
			</definition>
			<definition id="1">
				<sentence>The following description of tree edit distances is due to Bille ( 2003 ) : The principle to compute the edit distance between two trees T1 , T2 is to successively perform elementary edit operations on the former tree to turn it into the formation of the latter .</sentence>
				<definiendum id="0">T2</definiendum>
				<definiens id="0">to successively perform elementary edit operations on the former tree to turn it into the formation of the latter</definiens>
			</definition>
			<definition id="2">
				<sentence>Next , an edit script S is a list of consecutive edit operations which turn T1 into T2 .</sentence>
				<definiendum id="0">edit script S</definiendum>
				<definiens id="0">a list of consecutive edit operations which turn T1 into T2</definiens>
			</definition>
			<definition id="3">
				<sentence>Obviously , a linearization poses a loss of structure information which has impact on the results of distance measurement .</sentence>
				<definiendum id="0">linearization</definiendum>
				<definiens id="0">poses a loss of structure information which has impact on the results of distance measurement</definiens>
			</definition>
</paper>

		<paper id="1638">
			<definition id="0">
				<sentence>Just as Collins manually split the S nonterminal label into S and SG for sentences with and without subjects , Matsuzaki et al. ( 2005 ) split S into S [ 1 ] , S [ 2 ] , . . . , S [ L ] where L is a predefined number—but they do it automatically and systematically , and not only for S but for every nonterminal .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">split the S nonterminal label into S and SG for sentences with and without subjects</definiens>
			</definition>
			<definition id="1">
				<sentence>However , not all these parameters are free , as there are L × N sum-to-one constraints , where N is the number of backbone nonterminals .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of backbone nonterminals</definiens>
			</definition>
			<definition id="2">
				<sentence>Under the INHERIT model that we propose , the 319 Model Runtime and d.f. Simplified equation for inside probabilities ( ignores unary rules ) Matsuzaki et al. ( 2005 ) test : O ( n3L3 ) train : O ( nL3 ) d.f. : L3R3 + L2R2 +LR1−LN BX [ α ] ( i , k ) = X Y , β , Z , γ , j P ( X [ α ] → Y [ β ] Z [ γ ] ) ( 4 ) ×BY [ β ] ( i , j ) ×BZ [ γ ] ( j , k ) INHERIT model ( this paper ) test : O ( n3L ) train : O ( nL ) d.f. : L ( R3 + R2 + R1 ) + 3R3 −N BX [ α ] ( i , k ) = X Y , Z , j P ( X [ α ] → Y Z ) ( 5 ) × 0 B @ P ( neither | X , Y , Z ) × BY ( i , j ) × BZ ( j , k ) ) + P ( left | X , Y , Z ) × BY [ α ] ( i , j ) × BZ ( j , k ) ) + P ( right | X , Y , Z ) × BY ( i , j ) × BZ [ α ] ( j , k ) ) + P ( both | X , Y , Z ) × BY [ α ] Y ( i , j ) × BZ [ α ] ( j , k ) ) 1 CA BX ( i , j ) = X α Pann ( α | X ) ×BX [ α ] ( i , j ) ( 6 ) P ( left | X , Y , Z ) =  P ( head | X , Y , Z ) if Y heads X →Y Z P ( nonhead | X , Y , Z ) otherwise ( 7 ) P ( right | X , Y , Z ) =  P ( head | X , Y , Z ) if Z heads X → Y Z P ( nonhead | X , Y , Z ) otherwise ( 8 ) Table 2 : Comparison of the PCFG-LA model with the INHERIT model proposed in this paper .</sentence>
				<definiendum id="0">INHERIT model</definiendum>
				<definiens id="0">j P ( X [ α ] → Y Z ) ( 5 ) × 0 B @ P ( neither | X</definiens>
			</definition>
			<definition id="3">
				<sentence>“d.f.” stands for “degrees of freedom” ( i.e. , free parameters ) .</sentence>
				<definiendum id="0">“d.f.”</definiendum>
			</definition>
			<definition id="4">
				<sentence>Each auxiliary node consists of the parent label , the direction ( L or R ) and the label of the child just picked up .</sentence>
				<definiendum id="0">auxiliary node</definiendum>
				<definiens id="0">consists of the parent label , the direction ( L or R ) and the label of the child just picked up</definiens>
			</definition>
			<definition id="5">
				<sentence>Figure 4 : Horizontal and vertical markovization and center-parent binarization of the rule X → A BH C D where H is the head child .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">the head child</definiens>
			</definition>
</paper>

		<paper id="1410">
			<definition id="0">
				<sentence>for each pi ∈ P do : Ci ← C ∩ { x|pi ( x ) } Chosen property is pj , where Cj is the smallest set .</sentence>
				<definiendum id="0">Cj</definiendum>
				<definiens id="0">the smallest set</definiens>
			</definition>
			<definition id="1">
				<sentence>The Full Brevity Algorithm has as a primary goal the avoidance of redundant descriptions , so it is a sign of the algorithm being consistent with its specification that it covers fewer of the redundant expressions than the Incremental Algorithm .</sentence>
				<definiendum id="0">Full Brevity Algorithm</definiendum>
				<definiens id="0">a primary goal the avoidance of redundant descriptions , so it is a sign of the algorithm being consistent with its specification that it covers fewer of the redundant expressions than the Incremental Algorithm</definiens>
			</definition>
</paper>

		<paper id="1518">
			<definition id="0">
				<sentence>Semantic role labeling ( SRL ) is a natural extension of the syntactic parsing task .</sentence>
				<definiendum id="0">SRL</definiendum>
				<definiens id="0">a natural extension of the syntactic parsing task</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , the following sentence , taken from the PropBank corpus , shows the annotation of semantic roles : [ A0 Late buying ] [ V gave ] [ A2 the Paris Bourse ] [ A1 a parachute ] [ AM-TMP after its free fall early in the day ] .</sentence>
				<definiendum id="0">PropBank corpus</definiendum>
				<definiens id="0">shows the annotation of semantic roles</definiens>
			</definition>
			<definition id="2">
				<sentence>We make two enhancements to the pruned Propbank tree : we enrich the sister nodes with their head information , which is a part-of-speech tag and word pair : 〈t , w〉 and PP nodes are expanded to include the NP complement of the PP ( including the head information ) .</sentence>
				<definiendum id="0">head information</definiendum>
				<definiens id="0">a part-of-speech tag and word pair : 〈t , w〉 and PP nodes are expanded to include the NP complement of the PP ( including the head information</definiens>
			</definition>
			<definition id="3">
				<sentence>128 S NP PRP-H He VP-H VBZ-H backflips PP IN-H into NP NP-H NN-H terminal , , SBAR WHNP-H WDT-H which S VP-H VBZ-H explodes , , S VP-H VBG-H covering NP NN-H face PP IN-H with NP NNS-H microchips Figure 1 : The pruned tree for the sentence “He backflips into a desktop computer terminal , which explodes , covering Huntz Hall ’s face with microchips.”</sentence>
				<definiendum id="0">S VP-H VBG-H</definiendum>
				<definiens id="0">PP IN-H into NP NP-H NN-H terminal , , SBAR WHNP-H WDT-H which S VP-H VBZ-H explodes , ,</definiens>
			</definition>
			<definition id="4">
				<sentence>129 S ( backflips ) NP ( he ) PP ( into ) NP ( terminal ) , ( , ) SBAR ( which ) S ( explodes ) , ( , ) S ( cover ) NP ( face ) PP ( with ) Figure 3 : The LTAG derivation tree ( with no semantic role labels ) corresponding to the pruned tree .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">he ) PP ( into ) NP ( terminal ) , ( , ) SBAR ( which ) S ( explodes ) , ( , ) S ( cover ) NP ( face )</definiens>
			</definition>
			<definition id="5">
				<sentence>A0 : NP-NP ( NN , terminal ) R-A0 : SBAR-WHNP ( WDT , which ) NULL : S-VP ( VBZ , explodes ) predicate : S-VPH ( VBG , cover ) A1 : NP-NP ( NN , terminal ) R-A0 : SBAR-WHNP ( WDT , which ) NULL : S-VP ( VBZ , explodes ) predicate : S-VPH ( VBG , cover ) A0 : NP-NP ( NN , terminal ) R-A0 : SBAR-WHNP ( WDT , which ) AM-ADV : S-VP ( VBZ , explodes ) predicate : S-VPH ( VBG , cover ) Figure 4 : Different LTAG derivation trees corresponding to different assignments of semantic roles to constituents .</sentence>
				<definiendum id="0">A0</definiendum>
				<definiendum id="1">WDT</definiendum>
				<definiendum id="2">WDT</definiendum>
				<definiendum id="3">VBG</definiendum>
				<definiendum id="4">S-VPH ( VBG</definiendum>
				<definiens id="0">Different LTAG derivation trees corresponding to different assignments of semantic roles to constituents</definiens>
			</definition>
			<definition id="6">
				<sentence>yi is the label ( either NULL for no SRL , or the SRL ) of the ith example .</sentence>
				<definiendum id="0">yi</definiendum>
				<definiens id="0">the label ( either NULL for no SRL , or the SRL ) of the ith example</definiens>
			</definition>
			<definition id="7">
				<sentence>xi is a feature vector 〈P , A , Dist , Position , Rtype , ti ∈ tI , Distti〉 , where P is the predicate elementary tree , A is the tree for the constituent being labeled with a SRL , tI is a set of intermediate elementary trees between the predicate tree and the argument tree .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiendum id="1">tI</definiendum>
				<definiens id="0">a feature vector 〈P , A , Dist , Position , Rtype , ti ∈ tI , Distti〉 , where P is the predicate elementary tree</definiens>
				<definiens id="1">a set of intermediate elementary trees between the predicate tree and the argument tree</definiens>
			</definition>
			<definition id="8">
				<sentence>M1 is the LTAGbased model , M2 is the derived tree pattern matching Model , M3 is a hybrid model SRL task .</sentence>
				<definiendum id="0">M1</definiendum>
				<definiendum id="1">M2</definiendum>
				<definiendum id="2">M3</definiendum>
				<definiens id="0">the LTAGbased model</definiens>
			</definition>
			<definition id="9">
				<sentence>The Proposition Bank : An Annotated Corpus of Semantic Roles .</sentence>
				<definiendum id="0">Proposition Bank</definiendum>
			</definition>
</paper>

		<paper id="1101">
			<definition id="0">
				<sentence>Word sense disambiguation models often work with a notion of similarity among the contexts within which word ( senses ) appear , and MT identifies candidate lexical translation equivalents via a comparable measure of similarity .</sentence>
				<definiendum id="0">Word sense disambiguation models</definiendum>
				<definiens id="0">word ( senses ) appear , and MT identifies candidate lexical translation equivalents via a comparable measure of similarity</definiens>
			</definition>
			<definition id="1">
				<sentence>Laver goes on to sketch the work that has been done on phonetic similarity , or , more exactly , phonetic distance , in particular , the empirical derivation of confusion matrices , which indicate the likelihood with which people or speech recognition systems confusion one sound for another .</sentence>
				<definiendum id="0">confusion matrices</definiendum>
				<definiens id="0">indicate the likelihood with which people or speech recognition systems confusion one sound for another</definiens>
			</definition>
			<definition id="2">
				<sentence>Singh ( this volume ) investigates the technical question of identifying languages and character encoding systems from limited amounts of text .</sentence>
				<definiendum id="0">Singh</definiendum>
				<definiens id="0">this volume ) investigates the technical question of identifying languages and character encoding systems from limited amounts of text</definiens>
			</definition>
			<definition id="3">
				<sentence>LANGUAGE CONTACT studies seek to identify the elements of one language which have been adopted in a second in a situation in which two or more languages are used in the same community ( Thomason and Kaufmann , 1988 ; van Coetsem , 1988 ) .</sentence>
				<definiendum id="0">LANGUAGE CONTACT studies</definiendum>
				<definiens id="0">seek to identify the elements of one language which have been adopted in a second in a situation in which two or more languages are used in the same community</definiens>
			</definition>
			<definition id="4">
				<sentence>While similarity as such has not been a prominent term in theoretical and computational research on natural language semantics , the study of LEXICAL SEMANTICS , which attempts to identify regularities of and systematic relations among word meanings , is more often than not predicated on an implicit notion of ’semantic similarity’ .</sentence>
				<definiendum id="0">LEXICAL SEMANTICS</definiendum>
				<definiens id="0">attempts to identify regularities of and systematic relations among word meanings</definiens>
			</definition>
			<definition id="5">
				<sentence>Radical Construction Grammar : Syntactic Theory in Typological Perspective .</sentence>
				<definiendum id="0">Construction Grammar</definiendum>
			</definition>
			<definition id="6">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="7">
				<sentence>Selection and Information : A Class-Based Approach to Lexical Relationships .</sentence>
				<definiendum id="0">Selection</definiendum>
				<definiendum id="1">Information</definiendum>
			</definition>
</paper>

		<paper id="1703">
			<definition id="0">
				<sentence>13 Table 1 : Numbers of Entries and Translation Pairs in the Lexicons lexicon # of entries # of translation English Japanese pairs Eijiro 1,292,117 1,228,750 1,671,230 P 2 217,861 186,823 235,979 B P 37,090 34,048 95,568 B S 20,315 19,345 62,419 B 48,000 42,796 147,848 Eijiro : existing bilingual lexicon P 2 : entries of Eijiro with two constituents in both languages B P : bilingual constituents lexicon ( prefix ) B S : bilingual constituents lexicon ( suffix ) B : bilingual constituents lexicon ( merged ) composed into their constituents as below : y s = s 1 , s 2 , ··· , s n ( 1 ) where each s i is a single word or a sequence of words .</sentence>
				<definiendum id="0">Translation Pairs</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">entries of Eijiro with two constituents in both languages B P : bilingual constituents lexicon ( prefix ) B</definiens>
			</definition>
			<definition id="1">
				<sentence>Corpus score measures appropriateness of the translation candidate y t based on the target language corpus .</sentence>
				<definiendum id="0">Corpus score</definiendum>
				<definiens id="0">measures appropriateness of the translation candidate y t based on the target language corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>As the definition of the confidence score q ( 〈s , t〉 ) of a translation pair 〈s , t〉 , we use the following : q ( 〈s , t〉 ) = ⎧ ⎨ ⎩ 10 ( compo ( s ) −1 ) ( 〈s , t〉 in Eijiro ) log 10 f p ( 〈s , t〉 ) ( 〈s , t〉 in B P ) log 10 f s ( 〈s , t〉 ) ( 〈s , t〉 in B S ) ( 6 ) , where compo ( s ) denotes the word count of s , f p ( 〈s , t〉 ) represents the frequency of 〈s , t〉 as the first constituent in P 2 , and f s ( 〈s , t〉 ) represents the frequency of 〈s , t〉 as the second constituent in P 2 .</sentence>
				<definiendum id="0">t〉 )</definiendum>
				<definiendum id="1">compo ( s )</definiendum>
				<definiendum id="2">t〉 )</definiendum>
				<definiens id="0">the word count of s , f p ( 〈s , t〉 ) represents the frequency of 〈s</definiens>
			</definition>
			<definition id="3">
				<sentence>P ( s|t ) = f prob ( 〈s , t〉 ) summationtext s j f prob ( 〈s j , t〉 ) ( 8 ) 14 Table 2 : 9 Scoring Functions of Translation Candidates and their Components bilingual lexicon score corpus score corpus score ID freq-length probability probability frequency occurrence off-line on-line ( search engine ) A prune/final prune/final o B prune/final prune/final o C prune/final prune/final o D prune/final prune o E prune/final F prune/final final prune o G prune/final prune/final o H prune/final final o I prune/final final o f prob ( 〈s , t〉 ) denotes the frequency of the translation pair 〈s , t〉 in the bilingual lexicons as follows : f prob ( 〈s , t〉 ) = braceleftBigg 10 ( 〈s , t〉 in Eijiro ) f B ( 〈s , t〉 ) ( 〈s , t〉 in B ) ( 9 ) Note that the frequency of a translation pair in Eijiro is regarded as 10 6 and f B ( 〈s , t〉 ) denotes the frequency of the translation pair 〈s , t〉 in the bilingual constituent lexicon B. Corpus Score We evaluate three types of corpus scores as follows .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">f prob</definiendum>
				<definiendum id="2">f prob</definiendum>
				<definiendum id="3">f B</definiendum>
				<definiendum id="4">t〉 )</definiendum>
				<definiens id="0">Scoring Functions of Translation Candidates and their Components bilingual lexicon score corpus score corpus score ID freq-length probability probability frequency occurrence off-line on-line ( search engine ) A prune/final prune/final o B prune/final prune/final o C prune/final prune/final o D prune/final prune o E prune/final F prune/final final prune o G prune/final prune/final o H prune/final final o I prune/final final o f prob</definiens>
				<definiens id="1">the frequency of the translation pair 〈s</definiens>
				<definiens id="2">the frequency of the translation pair 〈s , t〉 in the bilingual constituent lexicon B. Corpus Score We evaluate three types of corpus scores as follows</definiens>
			</definition>
			<definition id="4">
				<sentence>• Probability : the occurrence probability of y t estimated by the following bi-gram model Q corpus ( y t ) =P ( t 1 ) · n productdisplay i=1 P ( t i+1 |t i ) ( 10 ) • Frequency : the frequency of a translation candidate in a target language corpus Q corpus ( y t ) =freq ( y t ) ( 11 ) • Occurrence : whether a translation candidate occurs in a target language corpus or not Q corpus ( y t ) = ⎧ ⎪ ⎨ ⎪ ⎩ 1 y t occurs in a corpus 0 y t does not occur in a corpus ( 12 ) 6 It is necessary to empirically examine whether or not the definition of the frequency of a translation pair in Eijiro is appropriate .</sentence>
				<definiendum id="0">Frequency</definiendum>
				<definiendum id="1">Occurrence</definiendum>
				<definiens id="0">the occurrence probability of y t estimated by the following bi-gram model Q corpus ( y t</definiens>
				<definiens id="1">the frequency of a translation candidate in a target language corpus Q corpus ( y t ) =freq ( y t</definiens>
				<definiens id="2">whether a translation candidate occurs in a target language corpus or not Q corpus ( y t</definiens>
			</definition>
			<definition id="5">
				<sentence>T ) translation set ( language T ) web ( language S ) web ( language S ) existing bilingual lexicon X S M ( # of translations is more than one ) Y S ( # of translations is zero ) web ( language T ) web ( language T ) looking up bilingual lexicon domain/topic specific corpus ( language T ) validating translation candidates web ( language T ) web ( language T ) Figure 4 : Experimental Evaluation of Translation Estimation for Technical Terms with/without the Domain/Topic-Specific Corpus ( taken from Figure 1 ) In our experimental evaluation , within the framework of compiling a bilingual lexicon for technical terms , we evaluate the translation estimation portion that is indicated by the bold line in Figure 4 .</sentence>
				<definiendum id="0">Domain/Topic-Specific Corpus</definiendum>
				<definiens id="0">translation set ( language T ) web ( language S ) web ( language S</definiens>
				<definiens id="1">zero ) web ( language T ) web ( language T ) looking up bilingual lexicon domain/topic specific corpus ( language T ) validating translation candidates web ( language T ) web ( language T ) Figure 4 : Experimental Evaluation of Translation Estimation for Technical Terms with/without the</definiens>
			</definition>
</paper>

		<paper id="1303">
			<definition id="0">
				<sentence>When SGT Blackwell detects a question that can not be answered with one of the contentfocused lines , it selects one out of 13 off-topic responses , ( e.g. , “I am not authorized to comment on that , ” ) indicating that the user has ventured out of the allowed conversation domain .</sentence>
				<definiendum id="0">SGT Blackwell</definiendum>
				<definiens id="0">detects a question that can not be answered with one of the contentfocused lines</definiens>
			</definition>
			<definition id="1">
				<sentence>The “art” of the field is to estimate the language models as accurately as possible given observed queries and documents .</sentence>
				<definiendum id="0">“art” of the field</definiendum>
				<definiens id="0">to estimate the language models as accurately as possible given observed queries and documents</definiens>
			</definition>
			<definition id="2">
				<sentence>Let Q = q1 ... qm be the question that is received by the system , RQ is the set of all the answers appropriate to that question , and P ( w|RQ ) is the probability that a word randomly sampled from an appropriate answer would be the word w. The language model of Q is the set of probabilities P ( w|RQ ) for every word in the vocabulary .</sentence>
				<definiendum id="0">RQ</definiendum>
				<definiendum id="1">P ( w|RQ )</definiendum>
				<definiens id="0">the set of all the answers appropriate to that question</definiens>
			</definition>
			<definition id="3">
				<sentence>Using the de Finetti’s representation theorem and kernel-based probability estimations , he derived the following estimate for the query language model : P ( w|Q ) = summationtext s∈S pis ( w ) producttextm i=1pis ( qi ) summationtext s producttextm i=1pis ( qi ) ( 2 ) Here we sum over all training strings s ∈ S , where S is the set of training strings .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">sum over all training strings s ∈ S , where</definiens>
				<definiens id="1">the set of training strings</definiens>
			</definition>
			<definition id="4">
				<sentence>pis ( w ) is the probability of observing word w in the string s , which can be estimated directly from the training data .</sentence>
				<definiendum id="0">pis ( w )</definiendum>
			</definition>
			<definition id="5">
				<sentence>Generally the unigram maximum likelihood estimator is used with some smoothing factor : pis ( w ) = λpi · # ( w , s ) |s| + ( 1−λpi ) · summationtext s # ( w , s ) summationtext s |s| ( 3 ) 20 where # ( w , s ) is the number of times word w appears in string s , |s| is the length of the string s , we sum over all training strings s ∈ S , and the constant λpi is the tunable parameter that can be determined from training data .</sentence>
				<definiendum id="0">|s|</definiendum>
				<definiens id="0">the number of times word w appears in string s ,</definiens>
				<definiens id="1">the length of the string s , we sum over all training strings s ∈ S</definiens>
				<definiens id="2">the tunable parameter that can be determined from training data</definiens>
			</definition>
			<definition id="6">
				<sentence>The accuracy is the proportion of correctly answered questions among all test questions .</sentence>
				<definiendum id="0">accuracy</definiendum>
			</definition>
			<definition id="7">
				<sentence>The alpha score is 0.929 for TRS-QA and 0.916 for ASR-QA , which indicate high consistency among the raters .</sentence>
				<definiendum id="0">alpha score</definiendum>
			</definition>
			<definition id="8">
				<sentence>Figure 1a and 1b show plots of the cumulative average appropriateness score ( CAA ) as function of WER : for each WER value t we average appropriateness scores for all questions-answer pairs with WER score less than 23 ( a ) pre-designated ( b ) user-designated Figure 1 : Shows the cumulative average appropriateness score ( CAA ) of ( a ) pre-designated and ( b ) user-designated question-answer pairs as function of the ASR’s output word error rate .</sentence>
				<definiendum id="0">CAA</definiendum>
				<definiens id="0">all questions-answer pairs with WER score less than 23 ( a ) pre-designated ( b ) user-designated Figure 1 : Shows the cumulative average appropriateness score ( CAA ) of ( a ) pre-designated and ( b ) user-designated question-answer pairs as function of the ASR’s output word error rate</definiens>
			</definition>
			<definition id="9">
				<sentence>or equal to t. CAA ( t ) = 1|S|summationdisplay p∈S A ( p ) , S = { p|WER ( p ) ≤ t } where p is a question-answer pair , A ( p ) is the appropriateness score for p , and WER ( p ) is the WER score for p. It is the expected value of the appropriateness score if the ASR WER was at most t. Both figures show the CAA values for TRSQA ( dotted black line ) and ASR-QA ( solid black line ) .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">p )</definiendum>
				<definiendum id="2">WER ( p )</definiendum>
				<definiens id="0">the WER score for p. It is the expected value of the appropriateness score if the ASR WER was at most t. Both figures show the CAA values for TRSQA ( dotted black line ) and ASR-QA ( solid black line )</definiens>
			</definition>
</paper>

		<paper id="0122">
			<definition id="0">
				<sentence>The technique computes the probability p ( y|x ) , where y denotes all possible outcomes of the space , and x denotes all possible features of the space .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">all possible outcomes of the space , and x denotes all possible features of the space</definiens>
			</definition>
			<definition id="1">
				<sentence>Conditional Random Field A conditional random field ( CRF ) [ 5 ] can be seen as an undirected graph model in which the nodes corresponding to the label sequence y are conditional on the observed sequence x. The goal of CRF is to find the label sequence y that has the maximized probability , given an observation sequence x. The formula for the CRF model can be written as : ( ) ( ) ( ) ( ) xy x xy , exp 1 | j j j F Z P ∑ = λ , where λ j is the parameter of a corresponding feature F j , Z ( x ) is an normalizing factor , and F j can be written as : ( ) ( ∑ = − = n i iiij iyyfF 0 1 , , , , xxy ) , where i means the relative position in the sequence , and y i-1 and y i denote the label at position i-1 and i respectively .</sentence>
				<definiendum id="0">Z ( x )</definiendum>
				<definiens id="0">Conditional Random Field A conditional random field ( CRF ) [ 5 ] can be seen as an undirected graph model in which the nodes corresponding to the label sequence y are conditional on the observed sequence x. The goal of CRF is to find the label sequence y that has the maximized probability , given an observation sequence x. The formula for the CRF model can be written as : ( ) ( ) ( ) ( ) xy x xy , exp 1 | j j j F Z P ∑ = λ , where λ j is the parameter of a corresponding feature F j</definiens>
				<definiens id="1">an normalizing factor , and F j can be written as : ( ) ( ∑ = − = n i iiij iyyfF 0 1 , , , , xxy ) , where i means the relative position in the sequence , and y i-1 and y i denote the label at position i-1 and i respectively</definiens>
			</definition>
			<definition id="2">
				<sentence>( ) ( ) ∑ = = T i i xyCxyS 0 , , , where S ( y , x ) is the score of a label y and a character x respectively ; T denotes the total number of CRF models ; and the value of C i ( y , x ) is 1 if the decision of the result of the i th CRF model is y , otherwise it is zero .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the score of a label y and a character x respectively ;</definiens>
				<definiens id="1">the total number of CRF models</definiens>
			</definition>
			<definition id="3">
				<sentence>Precision Recall FB1 Frequency Threshold 86.18 78.16 81.97 Relative Frequency Threshold 86.21 78.14 81.98 Only Person 86.27 77.58 81.69 Table 8 cityuThe performances of memory based ensemble methods under different rules .</sentence>
				<definiendum id="0">Precision Recall</definiendum>
				<definiens id="0">of memory based ensemble methods under different rules</definiens>
			</definition>
</paper>

		<paper id="2803">
</paper>

		<paper id="2606">
			<definition id="0">
				<sentence>The denominator represents a normalization factor that depends only on the source sentence fJ1 .</sentence>
				<definiendum id="0">denominator</definiendum>
				<definiens id="0">a normalization factor that depends only on the source sentence fJ1</definiens>
			</definition>
			<definition id="1">
				<sentence>Supertagging ( BangaloreandJoshi , 1999 ) usesthe Lexicalized Tree Adjoining Grammar formalism ( LTAG ) ( XTAG Research Group , 2001 ) .</sentence>
				<definiendum id="0">Supertagging</definiendum>
			</definition>
			<definition id="2">
				<sentence>Lexicalization allows us to associate each elementary tree with a lexical item called the anchor .</sentence>
				<definiendum id="0">Lexicalization</definiendum>
				<definiens id="0">allows us to associate each elementary tree with a lexical item called the anchor</definiens>
			</definition>
			<definition id="3">
				<sentence>BTEC is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books .</sentence>
				<definiendum id="0">BTEC</definiendum>
			</definition>
</paper>

		<paper id="1657">
			<definition id="0">
				<sentence>One kernel belonging to this family is : k ( XA , XB ) = X q∈Qstar wq C ( q|XA ) C ( q|XB ) ( 4 ) where Qstar represents all possible sequences , in XA and XB , of the symbols in Q. In turn , Q is a set of possible symbols , which can be characters , e.g. Q = { ‘a’ , ‘b’ , ‘c’ , ··· } , or words , e.g. Q = { ‘kangaroo’ , ‘koala’ , ‘platypus’ , ··· } .</sentence>
				<definiendum id="0">Qstar</definiendum>
				<definiendum id="1">Q</definiendum>
				<definiens id="0">represents all possible sequences , in XA and XB , of the symbols in Q. In turn ,</definiens>
				<definiens id="1">a set of possible symbols , which can be characters</definiens>
			</definition>
			<definition id="1">
				<sentence>Furthermore , C ( q|X ) is the number of occurrences of sequence q in X , and wq is the weight for sequence q. If the sequences are restricted to have only one item , Eqn .</sentence>
				<definiendum id="0">q|X )</definiendum>
				<definiendum id="1">wq</definiendum>
				<definiens id="0">the number of occurrences of sequence q in X</definiens>
			</definition>
			<definition id="2">
				<sentence>In the third experiment we utilised SVMs with character sequence kernels and studied the effects of chunk size .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">with character sequence kernels and studied the effects of chunk size</definiens>
			</definition>
</paper>

		<paper id="0702">
			<definition id="0">
				<sentence>The paper also points out several challenges specific to evaluating summaries of fiction such as questionable suitability of traditional metrics ( those based on sentence overlap ) , unavailability of clearly defined criteria to judge “godness” of a summary and a higher degree of redundancy in such texts .</sentence>
				<definiendum id="0">traditional metrics</definiendum>
				<definiens id="0">those based on sentence overlap )</definiens>
			</definition>
			<definition id="1">
				<sentence>Cohen denotes Cohen’s kappa ( Cohen 1960 ) .</sentence>
				<definiendum id="0">Cohen</definiendum>
			</definition>
			<definition id="2">
				<sentence>ICC denotes Intra-class Correlation Coefficient ( Shrout and Fleis 1979 ) .</sentence>
				<definiendum id="0">ICC</definiendum>
			</definition>
			<definition id="3">
				<sentence>ICC is the statistic that measures interrater agreement and can be computed for more than 2 judges .</sentence>
				<definiendum id="0">ICC</definiendum>
				<definiens id="0">the statistic that measures interrater agreement and can be computed for more than 2 judges</definiens>
			</definition>
			<definition id="4">
				<sentence>ICC was computed for a two-way mixed model and measures the average reliability of ratings taken together .</sentence>
				<definiendum id="0">ICC</definiendum>
				<definiens id="0">computed for a two-way mixed model and measures the average reliability of ratings taken together</definiens>
			</definition>
			<definition id="5">
				<sentence>PABAK is a measure that takes class imbalance into account , but it is to optimistic because it artificially removes class imbalance present in the original setting .</sentence>
				<definiendum id="0">PABAK</definiendum>
				<definiens id="0">a measure that takes class imbalance into account</definiens>
			</definition>
			<definition id="6">
				<sentence>The majority gold-standard summary contains all sentences that were selected by at least two judges .</sentence>
				<definiendum id="0">majority gold-standard summary</definiendum>
				<definiens id="0">contains all sentences that were selected by at least two judges</definiens>
			</definition>
</paper>

		<paper id="0205">
			<definition id="0">
				<sentence>In particular , WordNet is missing a lot of explicit links between intuitively related words .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">missing a lot of explicit links between intuitively related words</definiens>
			</definition>
			<definition id="1">
				<sentence>So , p ( w1 , w2 ) represents the density function computed as follows : the number of times w1 and w2 co-occur divided by the number of words in the corpus7 .</sentence>
				<definiendum id="0">w2 )</definiendum>
				<definiens id="0">the density function computed as follows : the number of times w1 and w2 co-occur divided by the number of words in the corpus7</definiens>
			</definition>
			<definition id="2">
				<sentence>idf ( w , d ) is defined in Equation 2 wheretf ( w , d ) is the number of occurrences of w in d , |d| corresponds to the number of words in d , N is the number of documents in the corpus and df ( w ) stands for the number of documents in the corpus in which the word w occurs .</sentence>
				<definiendum id="0">idf</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the number of occurrences of w in d</definiens>
				<definiens id="1">the number of documents in the corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>In particular , e is the obtained by the Symmetric Conditional Probability measure compared to the Pointwise Mutual Information for instance ( Cleuziou et al. , 2003 ) 38 base of the natural logarithm so that ln ( e ) = 1 .</sentence>
				<definiendum id="0">e</definiendum>
				<definiendum id="1">Mutual Information</definiendum>
				<definiens id="0">the obtained by the Symmetric Conditional Probability measure compared to the Pointwise</definiens>
			</definition>
			<definition id="4">
				<sentence>Suppose that Xi = ( Xi1 , Xi2 , Xi3 , ,Xip ) is a row vector of observations on p variables associated with a label i. The similarity between two words i and j is defined as Sij = f ( Xi , Xj ) where f is some function of the observed values .</sentence>
				<definiendum id="0">,Xip )</definiendum>
				<definiendum id="1">f</definiendum>
				<definiens id="0">a row vector of observations on p variables associated with a label i. The similarity between two words i and j is defined as Sij = f ( Xi</definiens>
				<definiens id="1">some function of the observed values</definiens>
			</definition>
			<definition id="5">
				<sentence>InfoSimBA ( Xi , Xj ) = AijB i ×Bj + Aij ( 5 ) where Aij = pa88 k=1 pa88 l=1 Xik ×Xjl ×SCP ( wik , wjl ) ∀i , Bi = a118a117 a117a116 pa88 k=1 pa88 l=1 Xik ×Xil ×SCP ( wik , wil ) and any Xzv corresponds to the word weighting factor weight ( wzv ) , SCP ( wik , wjl ) is the Symmetric ConditionalProbabilityvaluebetweenwik , theword that indexes the word context vector i at position k and wjl , the word that indexes the word context vector j at position l. In particular , this similarity measure has proved to lead to better results compared to the classical similarity measure ( Cosine ) and shares the same idea as the Latent Semantic Analysis ( LSA ) but in a different manner .</sentence>
				<definiendum id="0">InfoSimBA</definiendum>
				<definiendum id="1">wjl )</definiendum>
				<definiens id="0">the word weighting factor weight ( wzv )</definiens>
				<definiens id="1">the Symmetric ConditionalProbabilityvaluebetweenwik , theword that indexes the word context vector i at position k</definiens>
			</definition>
			<definition id="6">
				<sentence>Some methodologies are listed below where V is the set of vertices , E the set of edges , G ( V , E ) a graph and d a distance measure : • Nearest Neighbor Graph ( NNG ) : each vertex is connected to its nearest neighbor , • Minimum Spanning Tree ( MST ) : ∀ ( xi , xj ) ∈ V ×V a path exists between xi and xj in G witha80 ( xi , xj ) ∈E d ( xi , xj ) minimized , 9The tight clusters are called “committees” in CBC and “poles” in PoBOC .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the set of vertices , E the set of edges , G ( V , E ) a graph and d a distance measure : • Nearest Neighbor Graph ( NNG ) : each vertex is connected to its nearest neighbor , • Minimum Spanning Tree ( MST ) : ∀ ( xi , xj ) ∈ V ×V a path exists between xi and xj in G witha80 ( xi , xj ) ∈E d ( xi , xj ) minimized , 9The tight clusters are called “committees” in CBC and “poles” in PoBOC</definiens>
			</definition>
			<definition id="7">
				<sentence>N ( xi ) = { xj ∈ X|s ( xi , xj ) &gt; s ( xi , X ) } ( 6 ) where the notation s ( xi , I ) denotes the average similarity of xi with the set of objects I i.e. a88 xk∈I s ( xi , xk ) |I| ( 7 ) This definition of neighborhood is a way to avoid requiringtoaparameterthatwouldbetoodependent of the similarity used .</sentence>
				<definiendum id="0">neighborhood</definiendum>
				<definiens id="0">the average similarity of xi with the set of objects I i.e. a88 xk∈I s ( xi , xk</definiens>
				<definiens id="1">a way to avoid requiringtoaparameterthatwouldbetoodependent of the similarity used</definiens>
			</definition>
			<definition id="8">
				<sentence>P ( Ci ) = # of words in the cluster # of distinct words in all clusters ( 14 ) The relatedness criterion is the threshold that needs to be respected in order to assign a word to a Lexical Chain .</sentence>
				<definiendum id="0">relatedness criterion</definiendum>
			</definition>
			<definition id="9">
				<sentence>Domain=Sport , Document=3 , c=7 # 0 , 1 cluster and score=1.0 : { United States , couple , competition } # 6 , 3 clusters and score=1.0 : { boats , Sunday night , sailor , Sword , Orion , veteran , cutter , WinstonChurchill , SoloGlobe , Challenger , navy , Race , supposition , instructions , responsibility , skipper , east , Melbourne , deck , kilometer , masts , bodies , races , GMT , Admiral’s , Cups , Britain , Star , Class , Atlanta , Seattle , arms , fatality , sea , waves , dark , yacht’s , Dad , Guy’s , son , Mark , beer , talk , life , Richard , Winning , affair , canopy , death } # 9 , 1 cluster and score=1.0 : { record , days , hours , minutes , rescue } # 16 , 3 clusters and score=1.0 : { Snow , shape , north , easters , thunder , storm , change , knots , west , level , maxi’s , search , Authority , seas , helicopter , night vision , equipment , feet , rescues , Campbell , suffering , hypothermia , safety , foot , sailors , colleagues , Hospital , deaths , bodies , fatality } # 19 , 2 clusters and score=1.0 : { challenge , crew , Monday , VC , Offshore , Stand , Newcastle , mid morning , Eden , Rescuers , aircraft , unsure , whereabouts , killing , contact } Table 4 : 5 best Lexical Chains for Sport Domain=Economy , Document=5 , c=7 # 88 , 4 clusters and score=1.0 : { sign , chance , Rio , Janeiro , Grande , Sul , uphill , promise , hospitals , powerhouse , success , inhabitants , victory , pad , presidency , contingent , exit , legislature } # 50 , 1 cluster and score=1.0 : { transactions , taxes , Stabilization , spate , fuel , income , fortunes , means } # 77 , 1 cluster and score=1.0 : { proposal , factory , owners , Fund , Rubin’s } # 126 , 1 cluster and score=1.0 : { disaster , control , investment , review } - # 12 , 2clustersandscore=0.99 : { issue , order , University , population , question , timing , currencies } Table 5 : 5 best Lexical Chains for Economy For instance , the Lexical Chain # 16 in the domain of Sport clearly exemplifies the tragedy of climbers that were killed in a sudden change of weather in the mountains and who could not be rescued by the authorities .</sentence>
				<definiendum id="0">Race</definiendum>
				<definiens id="0">yacht’s , Dad , Guy’s , son , Mark , beer , talk , life , Richard , Winning , affair , canopy</definiens>
			</definition>
			<definition id="10">
				<sentence>Indeed , none of the words present in the chain seem 45 Domain=Politics , Document=3 , c=7 # 5 , 1 cluster and score=1.0 : { report , leaders , lives , information } # 33 , 1 cluster and score=1.0 : { past , attention , defenders , investigations } # 28 , 2 clusters and score=0.95 : { investigators , hospital , ward , wounds , neck , description , fashion , suspects , raids , assault , rifles , door , further details , surgery , service , detective , Igor , Kozhevnikov , Ministry } # 40 , 2 clusters and score=0.92 : { security , times , weeks , fire } # 24 , 3 clusters and score=0.85 : { enemies , Choice , stairwell , assailants , woman , attackers , entrance , car , guns , Friends , relatives , Mrs. Staravoitova , founder , movement , well thought , Sergei , Kozyrev , Association , Societies , supporter , Stalin’s , council , criminals , Yegor , Gaidar , minister , ally , suggestions , measures , smile , commitment } Table 6 : 5 best Lexical Chains for Politics Domain=War , Document=1 , c=7 # 25 , 2 clusters and score=1.0 : { lightning , advance , Africa’s , nation , outskirts , capital Kinshasa , troops , Angola , Zimbabwe , Namibia , chunk , routes , Katanga , Eastern , Kasai , provinces , copper } # 53 , 1 cluster and score=1.0 : { Back , years , Ngeyo , farm , farmers , organization , breadbasket , quarter , century , businessman , hotels , tourist , memory , rivalry , rebellions } # 56 , 1 cluster and score=1.0 : { political , freedoms , Hutus , Mai-Mai , warriors , Hunde , Nande , militiamen , Rwanda , ideology , weapons , persecution , landowners , ranchers , anarchy , Safari , Ngezayo , farmer , hotel , owner , camps } # 24 , 2 clusters and score=0.87 : { fighting , people , leaders , diplomats , cause , president , Washington , U.S , units , weeks } # 51 , 2 clusters and score=0.82 : { West , buildings , sight , point , tourists , mountain , gorillas , shops , guest , disputes } Table 7 : 5 best Lexical Chains for War to express any idea about Politics .</sentence>
				<definiendum id="0">assault</definiendum>
				<definiens id="0">hospital , ward , wounds , neck , description , fashion , suspects , raids ,</definiens>
				<definiens id="1">years , Ngeyo , farm , farmers , organization , breadbasket , quarter , century , businessman , hotels , tourist , memory , rivalry , rebellions } # 56 , 1 cluster and score=1.0 : { political , freedoms , Hutus , Mai-Mai , warriors , Hunde , Nande , militiamen , Rwanda , ideology , weapons , persecution , landowners , ranchers , anarchy , Safari , Ngezayo , farmer , hotel , owner</definiens>
			</definition>
</paper>

		<paper id="1607">
			<definition id="0">
				<sentence>Smoothing is an important technique in statistical NLP , used to deal with perennial data sparseness and empirical distributions that overfit the training corpus .</sentence>
				<definiendum id="0">Smoothing</definiendum>
				<definiens id="0">an important technique in statistical NLP , used to deal with perennial data sparseness and empirical distributions that overfit the training corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>The “forward” phrase probabilities p ( ˜t|˜s ) are not used as features , but only as a filter on the set of possible translations : for each source phrase ˜s that matches some ngram in s , only the 30 top-ranked translations ˜t according to p ( ˜t|˜s ) are retained .</sentence>
				<definiendum id="0">“forward” phrase probabilities p ( ˜t|˜s</definiendum>
				<definiens id="0">a filter on the set of possible translations : for each source phrase ˜s that matches some ngram in s</definiens>
			</definition>
			<definition id="2">
				<sentence>Black-box techniques do not look inside phrases but instead treat them as atomic objects : that is , both the ˜s and the ˜t in the expression p ( ˜s|˜t ) are treated as units about which nothing is known except their counts .</sentence>
				<definiendum id="0">atomic objects</definiendum>
			</definition>
			<definition id="3">
				<sentence>Good-Turing smoothing is a well-known technique ( Church and Gale , 1991 ) in which observed counts c are modified according to the formula : cg = ( c + 1 ) nc+1/nc ( 2 ) where cg is a modified count value used to replace c in subsequent relative-frequency estimates , and nc is the number of events having count c. An intuitive motivation for this formula is that it approximates relative-frequency estimates made by successively leaving out each event in the corpus , and then averaging the results ( N´adas , 1985 ) .</sentence>
				<definiendum id="0">Good-Turing smoothing</definiendum>
				<definiendum id="1">cg</definiendum>
				<definiendum id="2">nc</definiendum>
				<definiens id="0">a well-known technique ( Church and Gale , 1991 ) in which observed counts c are modified according to the formula : cg = ( c +</definiens>
				<definiens id="1">a modified count value used to replace c in subsequent relative-frequency estimates</definiens>
			</definition>
			<definition id="4">
				<sentence>Our implementation pools all counts c ( ˜s , ˜t ) together to obtain nprimec ( we have not yet tried separate counts based on length of ˜t as discussed above ) .</sentence>
				<definiendum id="0">counts c</definiendum>
			</definition>
			<definition id="5">
				<sentence>Normalization constraints fix the value of α ( ˜t ) : α ( ˜t ) = D n1+ ( ∗ , ˜t ) / summationdisplay ˜s c ( ˜s , ˜t ) , where n1+ ( ∗ , ˜t ) is the number of phrases ˜s for which c ( ˜s , ˜t ) &gt; 0 .</sentence>
				<definiendum id="0">Normalization constraints</definiendum>
				<definiendum id="1">summationdisplay ˜s c ( ˜s</definiendum>
				<definiendum id="2">n1+</definiendum>
				<definiens id="0">the number of phrases ˜s for which c ( ˜s , ˜t ) &gt; 0</definiens>
			</definition>
			<definition id="6">
				<sentence>The complement of this , proposed in ( Koehn et al. , 2005 ) , to say that sj should appear in ˜s if it is the translation of at least one of the words in ˜t : p ( sj|˜t ) = summationdisplay i∈Aj p ( sj|ti ) /|Aj| where Aj is a set of likely alignment connections for sj .</sentence>
				<definiendum id="0">Aj</definiendum>
				<definiens id="0">a set of likely alignment connections for sj</definiens>
			</definition>
</paper>

		<paper id="3321">
			<definition id="0">
				<sentence>Part-of-speech ( POS ) tagging is a fundamental component for performing natural language tasks such as parsing , information extraction , and question answering .</sentence>
				<definiendum id="0">Part-of-speech</definiendum>
				<definiens id="0">a fundamental component for performing natural language tasks such as parsing , information extraction</definiens>
			</definition>
</paper>

		<paper id="1645">
</paper>

		<paper id="1658">
			<definition id="0">
				<sentence>uW that occur in the collection , where W is the number of tokens in I. Additionally , for each unique token ui , I has a postings list L ( ui ) = &lt; l1 , l2 , ... lcnt ( ui ) &gt; of locations in D at which ui occurs .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">ui ) = &lt; l1 , l2 , ... lcnt ( ui ) &gt; of locations in D at which ui occurs</definiens>
			</definition>
			<definition id="1">
				<sentence>cnt ( ui ) is the length of L ( ui ) .</sentence>
				<definiendum id="0">ui )</definiendum>
				<definiens id="0">the length of L ( ui )</definiens>
			</definition>
			<definition id="2">
				<sentence>JAPE is a pattern matching language .</sentence>
				<definiendum id="0">JAPE</definiendum>
				<definiens id="0">a pattern matching language</definiens>
			</definition>
			<definition id="3">
				<sentence>The Common Pattern Specification Language ( CSPL ) 1 specifies a standard for describing Annotators that can be implemented by a series of cascading regular expression matches .</sentence>
				<definiendum id="0">Common Pattern Specification Language</definiendum>
				<definiens id="0">a standard for describing Annotators that can be implemented by a series of cascading regular expression matches</definiens>
			</definition>
			<definition id="4">
				<sentence>The object lists , k is a posting list of all token sequences of length exactly k that end in state s. The lists , k is initialized to be empty for all states and lengths .</sentence>
				<definiendum id="0">k</definiendum>
				<definiens id="0">a posting list of all token sequences of length exactly k that end in state s. The lists , k is initialized to be empty for all states and lengths</definiens>
			</definition>
			<definition id="5">
				<sentence>The time taken by all the merge operations for a state Si at step k is given by γ ( log ( |prev ( Si ) | ) |listSi , k| ) Assuming all the merges are performed simultaneously , γ ( log ( |prev ( Si ) | ) is the time taken to create each entry in the final merged list , where γ is a constant that varies with the lower level implementation .</sentence>
				<definiendum id="0">)</definiendum>
				<definiendum id="1">γ</definiendum>
				<definiens id="0">|prev ( Si ) | ) |listSi , k| ) Assuming all the merges are performed simultaneously , γ ( log ( |prev ( Si ) |</definiens>
				<definiens id="1">the time taken to create each entry in the final merged list , where</definiens>
				<definiens id="2">a constant that varies with the lower level implementation</definiens>
			</definition>
			<definition id="6">
				<sentence>With this assumptions from Equations 1 and 2 , the ratio CD/CI can be approximated by : 1 +summationtextNi=2 fcnt ( Si ) summationtextN i=2 bracketleftBigsummationtext s∈dest ( Si ) 2log ( ¯ρis ) + log ( |prev ( Si ) | ) bracketrightBig fcnt ( Si ) ( 3 ) The overall ratio of CD to CI is invariant to W and depends on two key factors fcnt ( Si ) andsummationtext s∈dest ( Si ) log ( ¯ρis ) .</sentence>
				<definiendum id="0">Si</definiendum>
				<definiens id="0">1 +summationtextNi=2 fcnt ( Si ) summationtextN i=2 bracketleftBigsummationtext s∈dest ( Si ) 2log ( ¯ρis ) + log ( |prev ( Si ) |</definiens>
			</definition>
			<definition id="7">
				<sentence>Let DR have five arcs from S1 to S2 one for each element in E. The DFA DR is a simple acceptor for the dictionary E , and if run over a token sequence T drawn from A , it will match any single token that is in E. For this simple case fcnt ( S2 ) is just the fraction of tokens that occur in E and hence by definition fcnt ( S2 ) ≤ 1 .</sentence>
				<definiendum id="0">DFA DR</definiendum>
				<definiens id="0">a simple acceptor for the dictionary E , and if run over a token sequence T drawn from A , it will match any single token that is in E. For this simple case fcnt ( S2 ) is just the fraction of tokens that occur in E and hence by definition fcnt ( S2 ) ≤ 1</definiens>
			</definition>
			<definition id="8">
				<sentence>JAPE is a version of CPSL6 ( Common Pattern Specification Language ) .</sentence>
				<definiendum id="0">JAPE</definiendum>
			</definition>
			<definition id="9">
				<sentence>JAPE provides finite state transduction over annotations based on regular expressions .</sentence>
				<definiendum id="0">JAPE</definiendum>
				<definiens id="0">provides finite state transduction over annotations based on regular expressions</definiens>
			</definition>
			<definition id="10">
				<sentence>The LHS is a regular expression which has to be matched on the input ; the RHS describes the annotations to be added to the Annotation Set .</sentence>
				<definiendum id="0">LHS</definiendum>
				<definiens id="0">a regular expression which has to be matched on the input ; the RHS describes the annotations to be added to the Annotation Set</definiens>
			</definition>
			<definition id="11">
				<sentence>The RHS uses ’ ; ’ as a separator between statements that set the values of the different attributes .</sentence>
				<definiendum id="0">RHS</definiendum>
				<definiens id="0">uses ’ ; ’ as a separator between statements that set the values of the different attributes</definiens>
			</definition>
			<definition id="12">
				<sentence>The JAPE Rule : Each JAPE rule has two parts , separated by “– &gt; ” .</sentence>
				<definiendum id="0">JAPE Rule</definiendum>
				<definiens id="0">Each JAPE rule has two parts , separated by “– &gt; ”</definiens>
			</definition>
			<definition id="13">
				<sentence>The LHS consists of an annotation pattern to be matched ; the RHS describes the annotation to be assigned .</sentence>
				<definiendum id="0">LHS</definiendum>
				<definiens id="0">consists of an annotation pattern to be matched ; the RHS describes the annotation to be assigned</definiens>
			</definition>
			<definition id="14">
				<sentence>minorType == month } ( 2 ) Right hand side : The RHS consists of details of the annotations and optional features to be created .</sentence>
				<definiendum id="0">RHS</definiendum>
				<definiens id="0">consists of details of the annotations and optional features to be created</definiens>
			</definition>
			<definition id="15">
				<sentence>Dataset GATE Index-based Enron 4974343 374926 Reuters 752287 92238 Table 1 : Time ( in milliseconds ) for computing annotations using the two techniques Dataset Orthographic Gazetteer Derived entitytypes entitytypes entitytypes Enron 38285 105870 230771 Reuters 28493 21531 42214 Table 2 : Time ( in milliseconds ) for computing postings lists of entity types An important advantage of performing annotations over the inverse index is that index entries for basic entity types can be preserved and reused for annotation types as additional rules for annotation are specified by users .</sentence>
				<definiendum id="0">Time</definiendum>
				<definiens id="0">annotation types as additional rules for annotation are specified by users</definiens>
			</definition>
</paper>

		<paper id="3115">
			<definition id="0">
				<sentence>In a phrase-based statistical translation ( Koehn et al. , 2003 ) , a bilingual text is decomposed as K phrase translation pairs ( ¯e1 , ¯f¯a1 ) , ( ¯e2 , ¯f¯a2 ) , ... : The input foreign sentence is segmented into phrases ¯f K1 , 122 mapped into corresponding English ¯eK1 , then , reordered to form the output English sentence according to a phrase alignment index mapping ¯a. In a hierarchical phrase-based translation ( Chiang , 2005 ) , translation is modeled after a weighted synchronous-CFG consisting of production rules whose right-hand side is paired ( Aho and Ullman , 1969 ) : X → 〈γ , α , ∼〉 where X is a non-terminal , γ and α are strings of terminals and non-terminals .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">reordered to form the output English sentence according to a phrase alignment index mapping ¯a. In a hierarchical phrase-based translation ( Chiang , 2005 ) , translation is modeled after a weighted synchronous-CFG consisting of production rules whose right-hand side is paired ( Aho and Ullman , 1969 ) : X → 〈γ , α , ∼〉 where</definiens>
			</definition>
			<definition id="1">
				<sentence>∼ is a one-to-one correspondence for the non-terminals appeared in γ and α .</sentence>
				<definiendum id="0">∼</definiendum>
				<definiens id="0">a one-to-one correspondence for the non-terminals appeared in γ and α</definiens>
			</definition>
			<definition id="2">
				<sentence>Our phrase-based model uses a standard pharaoh feature functions listed as follows ( Koehn et al. , 2003 ) : • Relative-count based phrase translation probabilities in both directions .</sentence>
				<definiendum id="0">phrase-based model</definiendum>
				<definiens id="0">uses a standard pharaoh feature functions listed as follows ( Koehn et al. , 2003 ) : • Relative-count based phrase translation probabilities in both directions</definiens>
			</definition>
</paper>

		<paper id="1422">
			<definition id="0">
				<sentence>As the main 1http : //lingo.stanford.edu/ 2http : //www.csd.abdn.ac.uk/research/babytalk/ 137 Corpus num texts num ref ( * ) text size main NLG challenges Weather statements 3000 300 1-2 sentences content det , lex choice , aggregation Statistical summaries 1000 100 paragraph above plus surface realisation Nurses’ reports 200 50 several paras above plus text structuring/layout ( * ) In addition to the main corpus , we will also gather texts which will be used as reference texts for corpus-based evaluations ; ‘num ref’ is the number of such texts .</sentence>
				<definiendum id="0">‘num ref’</definiendum>
				<definiens id="0">//www.csd.abdn.ac.uk/research/babytalk/ 137 Corpus num texts num ref ( * ) text size main NLG challenges Weather statements 3000 300 1-2 sentences content det , lex choice , aggregation Statistical summaries 1000 100 paragraph above plus surface realisation Nurses’ reports 200 50 several paras above plus text structuring/layout ( * ) In addition to the main corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Human-based preference judgements : We will investigate different experimental designs and methods for overcoming respondent bias ( e.g. what is known as ‘central tendency bias’ , where some respondents avoid judgements at either end of a scale ) .</sentence>
				<definiendum id="0">Human-based preference judgements</definiendum>
				<definiens id="0">We will investigate different experimental designs and methods for overcoming respondent bias ( e.g. what is known as ‘central tendency bias’ , where some respondents avoid judgements at either end of a scale )</definiens>
			</definition>
</paper>

		<paper id="2605">
			<definition id="0">
				<sentence>VerbNet operationalizes Levin’s work and accounts for 4962 distinct verbs classified into 237 main classes .</sentence>
				<definiendum id="0">VerbNet</definiendum>
				<definiens id="0">operationalizes Levin’s work and accounts for 4962 distinct verbs classified into 237 main classes</definiens>
			</definition>
			<definition id="1">
				<sentence>( *SEM* ( ( AGENT YOU ) ( VERBCLASS ( ( VNCLASS MIX-22.1-2 ) ) ) ( EVENT + ) ( EVENT0 ( ( END ( ( ARG1 ( LIQUID ) ) ( FRAME *TOGETHER ) ( ARG0 PHYSICAL ) ( ARG2 ( WATER ) ) ) ) ) ) ) ( EVENTSEM ( ( FRAME *CAUSE ) ( ARG1 E ) ( ARG0 ( YOU ) ) ) ) ) ( PATIENT1 LIQUID ) ( PATIENT2 WATER ) ( ROOT-VERB ADD ) ) Figure 2 : Parser Output ( Semantic Information ) of the F-Structure produced by the parser .</sentence>
				<definiendum id="0">VERBCLASS</definiendum>
				<definiens id="0">VNCLASS MIX-22.1-2 ) ) ) ( EVENT + ) ( EVENT0 ( ( END ( ( ARG1 ( LIQUID ) ) ( FRAME *TOGETHER ) ( ARG0 PHYSICAL ) ( ARG2 ( WATER ) ) ) ) ) ) ) ( EVENTSEM ( ( FRAME *CAUSE ) ( ARG1 E ) ( ARG0 ( YOU ) ) ) ) ) ( PATIENT1 LIQUID ) ( PATIENT2 WATER ) ( ROOT-VERB ADD ) ) Figure 2 : Parser Output ( Semantic Information ) of the F-Structure produced by the parser</definiens>
			</definition>
			<definition id="2">
				<sentence>The former group consists of relations between an action and other actions or between actions and their conditions or effects .</sentence>
				<definiendum id="0">former group</definiendum>
			</definition>
			<definition id="3">
				<sentence>ILP is an area of research at the intersection of Machine Learning ( ML ) and Logic Programming .</sentence>
				<definiendum id="0">ILP</definiendum>
				<definiens id="0">an area of research at the intersection of Machine Learning ( ML ) and Logic Programming</definiens>
			</definition>
			<definition id="4">
				<sentence>Progol learns logic programs with an arbitrarily low expected error using only positive data .</sentence>
				<definiendum id="0">Progol</definiendum>
				<definiens id="0">learns logic programs with an arbitrarily low expected error using only positive data</definiens>
			</definition>
			<definition id="5">
				<sentence>m is the number of examples covered by the hypothesis and dm is a normalizing constant .</sentence>
				<definiendum id="0">dm</definiendum>
				<definiens id="0">the number of examples covered by the hypothesis and</definiens>
			</definition>
			<definition id="6">
				<sentence>Types are defined as a single definite clause .</sentence>
				<definiendum id="0">Types</definiendum>
				<definiens id="0">a single definite clause</definiens>
			</definition>
</paper>

		<paper id="3308">
			<definition id="0">
				<sentence>We chose the GENIA corpus ( Kim et al. , 2003 ) , a collection of MEDLINE abstracts selected from the search results with the following keywords : human , blood cells , and transcription factors .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">a collection of MEDLINE abstracts selected from the search results with the following keywords : human , blood cells , and transcription factors</definiens>
			</definition>
			<definition id="1">
				<sentence>The maximum entropy model ( ME ) is a flexible statistical model that assigns an outcome for each instance based on the instance’s history , which is all the conditioning data that enables one to assign probabilities to the space of all outcomes .</sentence>
				<definiendum id="0">maximum entropy model ( ME )</definiendum>
				<definiens id="0">all the conditioning data that enables one to assign probabilities to the space of all outcomes</definiens>
			</definition>
			<definition id="2">
				<sentence>Formally , we can represent this feature as follows : ⎪ ⎩ ⎪ ⎨ ⎧ = = = otherwise :0 LOC-AMo and true ) ( s_in_cellde_endcurrent_no if :1 ) , ( h ohf Here , current_node_ends_in_cell ( h ) is a binary function that returns a true value if the current node in the history , h , ends in “cell” .</sentence>
				<definiendum id="0">current_node_ends_in_cell ( h )</definiendum>
				<definiens id="0">a binary function that returns a true value if the current node in the history , h , ends in “cell”</definiens>
			</definition>
			<definition id="3">
				<sentence>Source Sources are biological locations where substances are found and their reactions take place .</sentence>
				<definiendum id="0">Source Sources</definiendum>
				<definiens id="0">biological locations where substances are found and their reactions take place</definiens>
			</definition>
			<definition id="4">
				<sentence>Algorithm 1 Template Generation Input : Sentences set S = { s 1 , . . . , s n } , Output : A set of template T = { t 1 , . . . , t k } .</sentence>
				<definiendum id="0">Output</definiendum>
				<definiens id="0">Sentences set S = { s 1 , . . . , s n } ,</definiens>
				<definiens id="1">A set of template T = { t 1 , . . . , t k }</definiens>
			</definition>
</paper>

		<paper id="2112">
			<definition id="0">
				<sentence>The correct attachment of prepositional phrases ( PPs ) is a central disambiguation problem in parsing natural languages .</sentence>
				<definiendum id="0">prepositional phrases</definiendum>
				<definiendum id="1">PPs</definiendum>
				<definiens id="0">a central disambiguation problem in parsing natural languages</definiens>
			</definition>
			<definition id="1">
				<sentence>All these treebanks consist of constituent structure trees , and they are in representation formats which allow them to be loaded into TIGER-Search .</sentence>
				<definiendum id="0">these treebanks</definiendum>
				<definiens id="0">consist of constituent structure trees , and they are in representation formats which allow them to be loaded into TIGER-Search</definiens>
			</definition>
			<definition id="2">
				<sentence>SynTag ( J¨arborg , 1986 ) is a treebank consisting of around 5100 sentences .</sentence>
				<definiendum id="0">SynTag</definiendum>
				<definiens id="0">a treebank consisting of around 5100 sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>These are disturbing cases where the PP is a child node of the sentence node S ( which means that it is interpreted as a verb attachment ) with the edge label OA ( objektadverbial ) .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">a child node of the sentence node S ( which means that it is interpreted as a verb attachment ) with the edge label OA ( objektadverbial )</definiens>
			</definition>
			<definition id="4">
				<sentence>Other than that , TIGER-Search is a wonderful tool which allows for quick sanity checks of the queries with the help of the highlighted tree structure displays in its GUI .</sentence>
				<definiendum id="0">TIGER-Search</definiendum>
			</definition>
</paper>

		<paper id="3106">
			<definition id="0">
				<sentence>SYNTEX identifies syntactic dependency relations between words .</sentence>
				<definiendum id="0">SYNTEX</definiendum>
			</definition>
			<definition id="1">
				<sentence>The components are the so-called feature functions ( described below ) and the weighting coefficients ( λ ) are the parameters of the model : s ( h ) = λpprf logppprf ( h ) + λp|h|+ λtprf logptprf ( h ) + λt|h|+ λppibm logpppibm ( h ) + λtpibm logptpibm ( h ) + λlm logplm ( projE ( h ) ) + λd d ( h ) + λw|projE ( h ) | We briefly enumerate the features used in this study .</sentence>
				<definiendum id="0">projE</definiendum>
				<definiens id="0">the so-called feature functions ( described below ) and the weighting coefficients ( λ ) are the parameters of the model : s ( h ) = λpprf logppprf</definiens>
			</definition>
			<definition id="2">
				<sentence>Require : a source sentence f U ← { u : s-match ( u , f ) } FUTURECOST ( U ) for s←1 to|f|do S [ s ] ←∅ S [ 0 ] ← { ( ∅ , epsilon1,0 ) } for s←0 to|f|−1 do PRUNE ( S [ s ] , β ) for all hypotheses alive h∈S [ s ] do for all u∈U do if EXTENDS ( u , h ) then hprime←UPDATE ( u , h ) k←|projF ( hprime ) | S [ k ] ←S [ k ] ∪ { hprime } return argmaxh∈S [ |f| ] ρ : h→ ( ps , t , ρ ) Figure 3 : The search algorithm .</sentence>
				<definiendum id="0">Require</definiendum>
				<definiendum id="1">EXTENDS</definiendum>
				<definiendum id="2">h ) k←|projF</definiendum>
				<definiens id="0">a source sentence f U ← { u : s-match ( u , f ) } FUTURECOST ( U ) for s←1 to|f|do S [ s ] ←∅</definiens>
			</definition>
			<definition id="3">
				<sentence>In practice , the target material of a hypothesis is encoded as a vector of triplets { 〈wi , logplm ( wi|ci ) , li〉 } i∈ [ 1 , |e|max ] where wi is the word at position i in the translation , logplm ( wi|ci ) is its score as given by the language model , ci denotes the largest conditioning context possible , and li indicates the length ( in words ) of ci ( 0 means a unigram probability , 1 a bigram probability and 2 a trigram probability ) .</sentence>
				<definiendum id="0">wi</definiendum>
				<definiendum id="1">ci</definiendum>
				<definiens id="0">the largest conditioning context possible , and li indicates the length ( in words</definiens>
			</definition>
			<definition id="4">
				<sentence>For each language l , l-toks is the number of tokens , l-toks/sent is the average number of tokens per sentence ( ±the standard deviation ) , l-types is the number of different token forms and l-hapax is the number of tokens that appear only once in the corpus .</sentence>
				<definiendum id="0">l-toks/sent</definiendum>
				<definiendum id="1">l-types</definiendum>
				<definiens id="0">the average number of tokens per sentence ( ±the standard deviation</definiens>
			</definition>
			<definition id="5">
				<sentence>Weseparatelytunedbothsystemsonthe DEV corpus by applying a brute force strategy , i.e. by sampling uniformly the range of each parameter ( λ ) and pickingtheconfigurationwhichledtothebest BLEU score .</sentence>
				<definiendum id="0">Weseparatelytunedbothsystemsonthe DEV</definiendum>
				<definiens id="0">corpus by applying a brute force strategy</definiens>
			</definition>
</paper>

		<paper id="3602">
			<definition id="0">
				<sentence>a79 is the so-called coverage vector that ensures that a consistent block alignment is obtained during decoding and that the decoding 10 Table 1 : Multi-beam ( a93 -Beam ) decoding algorithm , which is similar to ( Koehn , 2004 ) .</sentence>
				<definiendum id="0">a79</definiendum>
				<definiens id="0">the so-called coverage vector that ensures that a consistent block alignment is obtained during decoding and that the decoding</definiens>
			</definition>
			<definition id="1">
				<sentence>a85 is the cost of the shortest path ( distance ) from some initial state a105 a98 to the current state a105 .</sentence>
				<definiendum id="0">a85</definiendum>
				<definiens id="0">the cost of the shortest path</definiens>
			</definition>
			<definition id="2">
				<sentence>The baseline decoder maintains a115a132a131 a113 state lists with entries of the above type , where a115 is the number of input words .</sentence>
				<definiendum id="0">a115</definiendum>
				<definiens id="0">the number of input words</definiens>
			</definition>
			<definition id="3">
				<sentence>Some special cases , e.g. where a148a149a39 has less than two target words , are taken into account .</sentence>
				<definiendum id="0">a148a149a39</definiendum>
				<definiens id="0">has less than two target words</definiens>
			</definition>
			<definition id="4">
				<sentence>a155a146a4a7a105a12a39a7a11 is the source phrase length of the matching block a6a20a39 when going from a105 to a105a12a39 .</sentence>
				<definiendum id="0">a155a146a4a7a105a12a39a7a11</definiendum>
			</definition>
			<definition id="5">
				<sentence>The path cost a85 is set : a85 a39a137a15 a85a84a131a141a166 , where a166 is the state transition cost a85 a4a7a105 a23 a105a12a39a60a11 divided by the source phrase length of block a6a20a39 : we evenly spread the cost of generating a6a20a39 over all source positions being matched .</sentence>
				<definiendum id="0">a166</definiendum>
				<definiens id="0">the state transition cost a85 a4a7a105 a23 a105a12a39a60a11 divided by the source phrase length of block a6a20a39</definiens>
			</definition>
			<definition id="6">
				<sentence>a94a99a39 contains all the hypotheses in the current beam that cover a111 a131 a113 source positions .</sentence>
				<definiendum id="0">a94a99a39</definiendum>
				<definiens id="0">contains all the hypotheses in the current beam that cover a111 a131 a113 source positions</definiens>
			</definition>
			<definition id="7">
				<sentence>For such a weighted graph , the shortest path from a single source can be computed in a174a101a4a20a175a102a172a84a175 a131 a175a173 a175a90a11 time , where a175a102a172a134a175 is the number of vertexes and a175a173 a175 number of edges in the graph .</sentence>
				<definiendum id="0">a175a102a172a134a175</definiendum>
				<definiens id="0">the number of vertexes</definiens>
			</definition>
			<definition id="8">
				<sentence>This way for the single-word based search in ( Tillmann and Ney , 2003 ) , a complexity of a174a101a4a60a175a18a172 a28 a175a177 a30 a115a147a178 a30 a179 a96 a11 is shown , where a175a18a172 a28 a175 is the size of the target vocabulary and a115 is the length of the input sentence .</sentence>
				<definiendum id="0">a115</definiendum>
				<definiens id="0">the length of the input sentence</definiens>
			</definition>
			<definition id="9">
				<sentence>Here , a word alignment a180 is a subset of the Cartesian product of source and target positions : a180a182a181a183a103a87a113 a23 a30a50a30a97a30 a23a7a184 a106a171a185a123a103a87a113 a23 a30a50a30a97a30 a23a50a115 a106a25a35 Here , a184 is the target sentence length and a115 is the source sentence length .</sentence>
				<definiendum id="0">a184</definiendum>
				<definiendum id="1">a115</definiendum>
				<definiens id="0">a subset of the Cartesian product of source and target positions</definiens>
				<definiens id="1">the target sentence length and</definiens>
			</definition>
			<definition id="10">
				<sentence>To restrict the block selection based on word aligned training data , interval projection functions are defined as follows 4 : a140 is a source interval and a148 is an target inter3 ( Tillmann , 2003 ) reports an intersection coverage of about a186a168a187 % for Arabic-English parallel data , and a coverage of a188a97a189 % for Chinese-English data .</sentence>
				<definiendum id="0">interval projection functions</definiendum>
				<definiendum id="1">a140</definiendum>
				<definiendum id="2">a148</definiendum>
				<definiens id="0">a source interval and</definiens>
			</definition>
			<definition id="11">
				<sentence>Formally , the definitions look like this : a190a77a191a55a192a14a38 a28 a4a7a140a193a11a197a15 a103a99a194a118a175a87a4a90a194 a23 a38a198a11a118a199a112a180 anda38a108a199a122a140a31a106 a190a77a191a55a192a14a38 a145 a4a133a148a108a11a197a15 a103a99a38a29a175a77a4a90a194 a23 a38a198a11a118a199a200a180 anda194a201a199a153a148a143a106 In order to obtain a particularly simple block alignment algorithm , the allowed block links a4a20a140 a23 a148a108a11 are restricted by an ADMISSIBILITY restriction , which is defined as follows : a4a133a148 a23 a140a193a11 is admissible iff ( 6 ) a190a77a191a55a192a14a38 a145 a4a133a148a108a11a118a181a104a140 anda190a87a191a55a192a14a38 a28 a4a7a140a5a11a118a181a141a148 Admissibility is related to the word re-ordering problem : for the source positions in an interval a140 and for the target positions in an intervala148 , all word re-ordering involving these positions has to take place within the block defined by a140 and a148 .</sentence>
				<definiendum id="0">the definitions</definiendum>
			</definition>
			<definition id="12">
				<sentence>target clumping is generated sequentially from bottomto-top and it induces some source clumping in an order which is defined by the word alignment .</sentence>
				<definiendum id="0">target clumping</definiendum>
				<definiens id="0">generated sequentially from bottomto-top and it induces some source clumping in an order which is defined by the word alignment</definiens>
			</definition>
			<definition id="13">
				<sentence>Pharaoh : a Beam Search Decoder for Phrase-Based Statistical Machine Translation Models .</sentence>
				<definiendum id="0">Pharaoh</definiendum>
			</definition>
</paper>

		<paper id="2302">
			<definition id="0">
				<sentence>The authors ( Poesio , M. and Mijail A. Kabadjov 2004 ) present their algorithm as an attempt at providing a domain independent anaphora resolution module , “that developers of NLE applications can pick off the shelf in the way of tokenizers , POS taggers , parsers , or Named Entity classifiers” .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">taggers , parsers , or Named Entity classifiers”</definiens>
			</definition>
			<definition id="1">
				<sentence>The approach is presented as a knowledge poor anaphora resolution algorithm ( Mitkov R. [ 1995 ; 1998 ] ) , which makes use of POS and NP chunking , it tries to individuate pleonastic “it” occurrences , and assigns animacy .</sentence>
				<definiendum id="0">] )</definiendum>
			</definition>
</paper>

		<paper id="3201">
			<definition id="0">
				<sentence>Quantitative representation of phonemes A phoneme is denoted by ) ( ip l , where l ( =1 , … , L ) represents the language that includes the phoneme , and i ( =1 , … , I l ) represents the index of the phoneme in language l. Thus , the phoneme inventory of language l is ( 1 ) } , ,1| ) ( { ll Iiip K= .</sentence>
				<definiendum id="0">L )</definiendum>
				<definiens id="0">the language that includes the phoneme</definiens>
			</definition>
			<definition id="1">
				<sentence>The monophoneme distribution metric is a typological comparison that is based on two principal classes of information : ( 1 ) types of sounds and ( 2 ) frequencies of these sounds in the lexicon .</sentence>
				<definiendum id="0">monophoneme distribution metric</definiendum>
				<definiens id="0">a typological comparison that is based on two principal classes of information : ( 1 ) types of sounds</definiens>
			</definition>
			<definition id="2">
				<sentence>The feature-based phoneme distance metric is defined as ( 18 ) N g ltN g ltNltd DDkidkiCPP ] [ ] [ ) ] , ( [ ) , ( γαραα γρ ⋅+⋅+⋅= where ) , ( kiCPP represents the distance between phoneme ) ( ip l from language l and phoneme ) ( kp t from language t , and both phonemes belong to the same phonological category g ( vowels or consonants ) .</sentence>
				<definiendum id="0">feature-based phoneme distance metric</definiendum>
				<definiendum id="1">kiCPP</definiendum>
				<definiens id="0">the distance between phoneme ) ( ip l from language l and phoneme ) ( kp t from language t</definiens>
			</definition>
</paper>

		<paper id="2934">
			<definition id="0">
				<sentence>Our model is based on the linear model presented in McDonald et al. ( 2005a ) , s ( x , y ) = summationdisplay ( i , j ) ∈y s ( i , j ) =summationdisplayw ·f ( i , j ) ( 1 ) where x is a sentence , y a parse and s a score function over sentence-parse pairs .</sentence>
				<definiendum id="0">x</definiendum>
			</definition>
			<definition id="1">
				<sentence>n , label ∈ bestb ( i , j ) where n is the number of tokens and the index 0 represents the root token .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of tokens and the index 0 represents the root token</definiens>
			</definition>
</paper>

		<paper id="1305">
</paper>

		<paper id="2915">
			<definition id="0">
				<sentence>Denote a training corpus as a set of documents Wn and their perspectives labels Dn , n = 1 , ... , N , where N is the total number of documents in the corpus .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of documents in the corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Words in the document are then sampled from a multinomial distribution , where Ln is the length of the document .</sentence>
				<definiendum id="0">Ln</definiendum>
				<definiens id="0">the length of the document</definiens>
			</definition>
			<definition id="2">
				<sentence>S is naturally modeled as a binomial variable , where τ is the parameter of S. S represents how likely it is that a sentence strongly conveys a perspective .</sentence>
				<definiendum id="0">τ</definiendum>
				<definiens id="0">the parameter of S. S represents how likely it is that a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>For training SVM , we represent each document as a V -dimensional feature vector , where V is the vocabulary size and each coordinate is the normalized term frequency within the document .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the vocabulary size and each coordinate is the normalized term frequency within the document</definiens>
			</definition>
			<definition id="4">
				<sentence>NB-B , which performs full Bayesian inference , improves 113 on NB-M , which only performs point estimation .</sentence>
				<definiendum id="0">NB-B</definiendum>
				<definiens id="0">performs full Bayesian inference , improves 113 on NB-M , which only performs point estimation</definiens>
			</definition>
</paper>

		<paper id="1906">
			<definition id="0">
				<sentence>Question Classification is an important task in Question Answering Systems .</sentence>
				<definiendum id="0">Question Classification</definiendum>
			</definition>
			<definition id="1">
				<sentence>The use of Cross Language Information Retrieval Systems ( CLIR ) is growing , and also the application of these ones into other general systems , such as Question Answering or Question Classification .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">growing , and also the application of these ones into other general systems , such as Question Answering or Question Classification</definiens>
			</definition>
			<definition id="2">
				<sentence>A CLIR system is an Information Retrieval System that works with collections in several languages , and extract relevant documents or passages ( Grefenstette , 1998 ) .</sentence>
				<definiendum id="0">CLIR system</definiendum>
			</definition>
			<definition id="3">
				<sentence>Question Classification is the task that , given a question , classifies it in one of k semantic classes .</sentence>
				<definiendum id="0">Question Classification</definiendum>
				<definiens id="0">the task that , given a question , classifies it in one of k semantic classes</definiens>
			</definition>
			<definition id="4">
				<sentence>( Zhang and Lee , 2003 ) propose a QC system that uses Support Vector Machine ( SVM ) as the best machine learning algorithm .</sentence>
				<definiendum id="0">QC system</definiendum>
				<definiens id="0">uses Support Vector Machine ( SVM ) as the best machine learning algorithm</definiens>
			</definition>
			<definition id="5">
				<sentence>TiMBL 1 is a program that implements several Memory-Based Learning techniques .</sentence>
				<definiendum id="0">TiMBL 1</definiendum>
			</definition>
			<definition id="6">
				<sentence>It implements Stanfill modified value difference metric ( MVDM ) , Jeffrey Divergence and Class voting in the k-NN kernel according to the distance of the nearest neighbors .</sentence>
				<definiendum id="0">MVDM</definiendum>
			</definition>
			<definition id="7">
				<sentence>We have analyzed each question in order to extract the following features : † Lexical Features – The two first words of the question – All the words of the question in lowercase – The stemming words – Bigrams of the question – Each word with its position in the question – The interrogative pronoun of the question – The headwords of the nouns and verbs † Syntactic Features – The interrogative pronoun and the Part of Speech ( POS ) of the rest of the words – The headword ( a word to which an independent meaning can be assigned ) of the first noun phrase – All POS – Chunks – The first verb chunk – The length of the question † Semantic Features – The question focus ( a noun phrase that is likely to be present in the answer ) – POS with the named entities recognized – The type of the entity if the focus is one of them – Wordnet hypernyms for the nouns and Wordnet synonyms for the verbs We have used some English resources such as the POS tagger TreeTagger ( Schmid , 1994 ) , Lingpipe 2 to make Named Entity Recognition , and the Porter stemmer ( Porter , 1980 ) .</sentence>
				<definiendum id="0">Porter stemmer</definiendum>
				<definiens id="0">† Lexical Features – The two first words of the question – All the words of the question in lowercase – The stemming words – Bigrams of the question – Each word with its position in the question – The interrogative pronoun of the question – The headwords of the nouns and verbs † Syntactic Features – The interrogative pronoun and the Part of Speech ( POS ) of the rest of the words – The headword ( a word to which an independent meaning can be assigned ) of the first noun phrase – All POS – Chunks – The first verb chunk – The length of the question † Semantic Features – The question focus ( a noun phrase that is likely to be present in the answer ) – POS with the named entities recognized – The type of the entity if the focus is one of them – Wordnet hypernyms for the nouns</definiens>
			</definition>
			<definition id="8">
				<sentence>Accuracy = ] ofcorrectpredictions ] ofpredictions ( 1 ) precision ( c ) = ] ofcorrectpredictionsofthecategoryc ] ofpredictionsofthecategoryc ( 2 ) Other measure used is the F-score , defined as the harmonic mean of precision and recall ( Van Rijsbergen , 1979 ) .</sentence>
				<definiendum id="0">precision</definiendum>
			</definition>
			<definition id="9">
				<sentence>Different parameters have been the test file used ( originally in English or translated from Spanish with the MT Epals or Prompt ) , the machine learning algorithm , some TiMBL parameters and the lexical , syntactic or semantic features .</sentence>
				<definiendum id="0">Different parameters</definiendum>
				<definiens id="0">the MT Epals or Prompt ) , the machine learning algorithm , some TiMBL parameters and the lexical , syntactic or semantic features</definiens>
			</definition>
</paper>

		<paper id="1668">
			<definition id="0">
				<sentence>If X is the space of inputs and Y is the space of labels , a classifier is a function f : X → Y. A generative model is one that models the joint probability of inputs and labels PD ( x , y ) through a distribution Pθ ( x , y ) , dependent on some parameter vector θ .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiendum id="1">classifier</definiendum>
				<definiens id="0">the space of inputs</definiens>
				<definiens id="1">a function f : X → Y. A generative model is one that models the joint probability of inputs and labels PD ( x , y ) through a distribution Pθ ( x , y ) , dependent on some parameter vector θ</definiens>
			</definition>
			<definition id="1">
				<sentence>We study generative models represented as Bayesian Networks ( Pearl , 1988 ) , because their parameters can be estimated extremely fast as the maximizer of the joint likelihood is the closed form relative frequency estimate .</sentence>
				<definiendum id="0">Bayesian Networks</definiendum>
			</definition>
			<definition id="2">
				<sentence>A Bayesian Network is an acyclic directed graph over a set of nodes .</sentence>
				<definiendum id="0">Bayesian Network</definiendum>
			</definition>
			<definition id="3">
				<sentence>If the model is trained through maximizing the joint likelihood of the data , the optimal parameters are the relative frequency estimates : ˆP ( Zi = v|Pa ( Zi ) = vectoru ) = count ( Zi=v , Pa ( Zi ) =vectoru ) count ( Pa ( Z i ) =vectoru ) Herev denotes a value of Z i and vectoru denotes a vector of values for the parents of Zi .</sentence>
				<definiendum id="0">ˆP</definiendum>
				<definiens id="0">a value of Z i and vectoru denotes a vector of values for the parents of Zi</definiens>
			</definition>
			<definition id="4">
				<sentence>The recursion is ended by interpolating with a uniform distribution 1Vz , where Vz is the vocabulary of values for the prediction variable Z. We determine the interpolation back-off order by looking at the number of values of each variable .</sentence>
				<definiendum id="0">Vz</definiendum>
				<definiens id="0">the vocabulary of values for the prediction variable Z. We determine the interpolation back-off order by looking at the number of values of each variable</definiens>
			</definition>
			<definition id="5">
				<sentence>VOICE : Active or passive relative to predicate HEAD WORD OF PHRASE SUB-CAT : CFG expansion of predicate’s parent Table 2 : Features for Semantic Role Labeling .</sentence>
				<definiendum id="0">VOICE</definiendum>
				<definiens id="0">Active or passive relative to predicate HEAD WORD OF PHRASE SUB-CAT : CFG expansion of predicate’s</definiens>
			</definition>
			<definition id="6">
				<sentence>The proposition bank : An annotated corpus of semantic roles .</sentence>
				<definiendum id="0">proposition bank</definiendum>
				<definiens id="0">An annotated corpus of semantic roles</definiens>
			</definition>
</paper>

		<paper id="2408">
			<definition id="0">
				<sentence>expressions in Estonian A VMWE consists of a verb and 1 ) a particle or 2 ) a nominal phrase ( usually , but not always , consisting of one noun ) in more or less frozen inflectional form , or 3 ) a non-finite form of a verb .</sentence>
				<definiendum id="0">VMWE</definiendum>
				<definiens id="0">consists of a verb and 1 ) a particle or 2 ) a nominal phrase ( usually , but not always , consisting of one noun ) in more or less frozen inflectional form , or 3 ) a non-finite form of a verb</definiens>
			</definition>
			<definition id="1">
				<sentence>Idiomatic expressions are usually defined as word combinations , the meaning of which is not the sum or combination of the meanings of its parts .</sentence>
				<definiendum id="0">Idiomatic expressions</definiendum>
			</definition>
			<definition id="2">
				<sentence>Support verb constructions , sometimes also called light verb constructions , are combinations of a verb and its object or , rarely , some other argument , where the nominal component denotes an action of some kind and the verb is semantically empty in this context , e.g. English make a speech , take a walk .</sentence>
				<definiendum id="0">Support verb constructions</definiendum>
				<definiens id="0">combinations of a verb and its object or</definiens>
			</definition>
			<definition id="3">
				<sentence>First , it contained VMWEs from six human-created dictionaries : the Explanatory Dictionary of Estonian ( EKSS , 1988-2000 ) , Index of the Thesaurus of Estonian ( Saareste , 1979 ) , a list of particle verbs ( Hasselblatt , 1990 ) , Dictionary of Phrases ( Õim , 1991 ) , Dictionary of Synonyms ( Õim , 1993 ) and the Filosoft thesaurus ( http : //www.filosoft.ee/ thes_et/ ) .</sentence>
				<definiendum id="0">Filosoft</definiendum>
			</definition>
			<definition id="4">
				<sentence>Partitive is the unmarked form of the object .</sentence>
				<definiendum id="0">Partitive</definiendum>
			</definition>
</paper>

		<paper id="1702">
</paper>

		<paper id="0131">
</paper>

		<paper id="1700">
			<definition id="0">
				<sentence>High-performance NLP needs web-scale resources The most talked-about presentation of the ACL 2005 was Franz-Josef Och’s , in which he presented statistical MT results based on a 200 billion word English corpus .</sentence>
				<definiendum id="0">Franz-Josef Och’s</definiendum>
				<definiens id="0">in which he presented statistical MT results based on a 200 billion word English corpus</definiens>
			</definition>
</paper>

		<paper id="1635">
			<definition id="0">
				<sentence>Proteins are sequences of amino acids ( polypeptide chains ) that form unique , sequence-specific threedimensional structures .</sentence>
				<definiendum id="0">Proteins</definiendum>
				<definiens id="0">sequences of amino acids ( polypeptide chains ) that form unique , sequence-specific threedimensional structures</definiens>
			</definition>
			<definition id="1">
				<sentence>CKY provides an explicit computational recipe to efficiently search ( and return ) all possible folding routes .</sentence>
				<definiendum id="0">CKY</definiendum>
				<definiens id="0">provides an explicit computational recipe to efficiently search</definiens>
			</definition>
			<definition id="2">
				<sentence>Our folding algorithm restricts the possible order of folding events , but places no explicit restrictions on the structures it can account for ( other than those imposed by the spatial model used to represent them , and those that are implied by the hierarchical nature of the folding process ) .</sentence>
				<definiendum id="0">folding algorithm</definiendum>
			</definition>
			<definition id="3">
				<sentence>The free energy G a0 H a1 TS of a system depends on its energy H , its entropy S ( the amount of disorder in the system ) , and the temperature T. A computational model therefore requires an energy function φ : Rn a2 R , which maps n-dimensional vectors that describe the structure of a polypeptide chain ( eg .</sentence>
				<definiendum id="0">entropy S</definiendum>
				<definiens id="0">the amount of disorder in the system )</definiens>
			</definition>
			<definition id="4">
				<sentence>The complexity of standard CKY is O a1 n3 a3 Ga3 a2 , where n is the length of the input string and a3 Ga3 the “size” of the grammar .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the length of the input string</definiens>
			</definition>
			<definition id="5">
				<sentence>With our current pruning strategy , CKY finds the native state of 96.7 % of all 24,900 unique-folding 20mers , confirming our hypothesis that the hierarchical greedy search that is implemented in CKY is a viable strategy .</sentence>
				<definiendum id="0">CKY</definiendum>
				<definiens id="0">a viable strategy</definiens>
			</definition>
</paper>

		<paper id="0504">
			<definition id="0">
				<sentence>The input of the OPTM task consists of classified mentions and the output consists of individual entities filled with textual material ( i.e. there is no normalization ) with their co-reference relations .</sentence>
				<definiendum id="0">OPTM task</definiendum>
				<definiens id="0">consists of classified mentions and the output consists of individual entities filled with textual material ( i.e. there is no normalization ) with their co-reference relations</definiens>
			</definition>
			<definition id="1">
				<sentence>However , since mentions have been introduced as an evolution of the traditional Named Entity Recognition task ( see Tanev and Magnini , 2006 ) , they guarantee a reasonable level of difficulty , which makes OPTM challenging both for the Computational Linguistic side and the Knowledge Representation community .</sentence>
				<definiendum id="0">difficulty</definiendum>
				<definiens id="0">makes OPTM challenging both for the Computational Linguistic side and the Knowledge Representation community</definiens>
			</definition>
			<definition id="2">
				<sentence>I-CAB ( Magnini et al. 2006 ) consists of 525 news documents taken from the local newspaper ‘L’Adige’ 5 .</sentence>
				<definiendum id="0">I-CAB</definiendum>
			</definition>
			<definition id="3">
				<sentence>In total , I-CAB consists of around 182,500 words : 113,500 and 69,000 words in the training and the test sections respectively ( the average length of a news story is around 339 words in the training section and 363 words in the test section ) .</sentence>
				<definiendum id="0">I-CAB</definiendum>
				<definiens id="0">consists of around 182,500 words : 113,500 and 69,000 words in the training and the test sections respectively ( the average length of a news story is around 339 words in the training section and 363 words in the test section )</definiens>
			</definition>
</paper>

		<paper id="1420">
			<definition id="0">
				<sentence>This work is part of the TUNA project ( http : //www.csd.abdn.ac.uk/ research/tuna/ ) , funded by the EPSRC in the UK ( GR/S13330/01 ) .</sentence>
				<definiendum id="0">TUNA project</definiendum>
			</definition>
</paper>

		<paper id="3706">
			<definition id="0">
				<sentence>Points to notice : • The Translation Shortcuts Panel contains the Translation Shortcuts Browser , split into two main areas , Shortcuts Categories ( above ) and Shortcuts List ( below ) .</sentence>
				<definiendum id="0">Translation Shortcuts Panel</definiendum>
				<definiens id="0">contains the Translation Shortcuts Browser , split into two main areas</definiens>
			</definition>
			<definition id="1">
				<sentence>• Translation memory : Translation Shortcuts can be seen as a variant of Translation Memory , a facility that remembers past successful translations so as to circumvent error-prone reprocessing .</sentence>
				<definiendum id="0">Translation Shortcuts</definiendum>
				<definiens id="0">a variant of Translation Memory , a facility that remembers past successful translations so as to circumvent error-prone reprocessing</definiens>
			</definition>
			<definition id="2">
				<sentence>We have presented our Translation Shortcuts facility , which minimizes the need for interactive verification of sentences after they have been vetted once , considerably speeds throughput while maintaining accuracy , and allows use by minimally literate patients for whom any mode of text entry might be difficult .</sentence>
				<definiendum id="0">Translation Shortcuts facility</definiendum>
				<definiens id="0">minimizes the need for interactive verification of sentences after they have been vetted once , considerably speeds throughput while maintaining accuracy</definiens>
			</definition>
</paper>

		<paper id="1706">
			<definition id="0">
				<sentence>The US Election 2004 Web Monitor represents an initiative of the Research Network on Environmental Online Communication ( www.ecoresearch.net ) , cooperating with the University of Western Australia , Graz University of Technology , Vienna University of Economics and Business Administration , and the Know-Center , which is funded by the Austrian Competence Center program Kplus under the auspices of the Austrian Ministry of Transport , Innovation and Technology ( http : //www.ffg.at ) and by the State of Styria .</sentence>
				<definiendum id="0">US Election 2004 Web Monitor</definiendum>
				<definiendum id="1">Know-Center</definiendum>
				<definiendum id="2">Technology ( http</definiendum>
				<definiens id="0">an initiative of the Research Network on Environmental Online Communication ( www.ecoresearch.net )</definiens>
				<definiens id="1">//www.ffg.at ) and by the State of Styria</definiens>
			</definition>
</paper>

		<paper id="1404">
			<definition id="0">
				<sentence>The rule-based core of the generator is a set of productions written in a production system .</sentence>
				<definiendum id="0">rule-based core of the generator</definiendum>
				<definiens id="0">a set of productions written in a production system</definiens>
			</definition>
			<definition id="1">
				<sentence>Alignment Alignment is a key to successful natural language dialogue ( Brockmann et al. , 2005 ) .</sentence>
				<definiendum id="0">Alignment Alignment</definiendum>
			</definition>
			<definition id="2">
				<sentence>The presentation dialogue moves do microplanning , for example by deciding to present retrieved database items either as examples ( s4 in table 1 ) or as part of a larger answer list of items .</sentence>
				<definiendum id="0">presentation dialogue moves do microplanning</definiendum>
				<definiens id="0">table 1 ) or as part of a larger answer list of items</definiens>
			</definition>
</paper>

		<paper id="3809">
			<definition id="0">
				<sentence>In this paper we introduce a new measure of term weighting , which integrates the locality of a term and its relation to the surrounding context .</sentence>
				<definiendum id="0">term weighting</definiendum>
				<definiens id="0">integrates the locality of a term and its relation to the surrounding context</definiens>
			</definition>
			<definition id="1">
				<sentence>TextRank takes as input a set of textual entities and relations between them , and uses a graph-based ranking algorithm ( also known as random walk algorithm ) to produce a set of scores that represent the accumulated weight or rank for each textual entity in their context .</sentence>
				<definiendum id="0">TextRank</definiendum>
				<definiens id="0">input a set of textual entities and relations between them , and uses a graph-based ranking algorithm ( also known as random walk algorithm ) to produce a set of scores that represent the accumulated weight or rank for each textual entity in their context</definiens>
			</definition>
			<definition id="2">
				<sentence>The PageRank score associated with the vertex Va is then defined using a recursive function that integrates the scores of its predecessors : S ( Va ) = ( 1 − d ) +d ∗ summationdisplay Vb∈In ( Va ) S ( Vb ) |Out ( Vb ) | ( 1 ) where d is a parameter that is set between 0 and 11 .</sentence>
				<definiendum id="0">PageRank score</definiendum>
				<definiendum id="1">recursive function</definiendum>
				<definiens id="0">integrates the scores of its predecessors : S ( Va ) = ( 1 − d ) +d ∗ summationdisplay Vb∈In ( Va ) S ( Vb ) |Out ( Vb ) | ( 1 ) where d is a parameter that is set between 0 and 11</definiens>
			</definition>
			<definition id="3">
				<sentence>The error rate ER is defined as : ER = Sk+1 ( Vi ) − Sk ( Vi ) ( 2 ) This vertex scoring scheme is based on a random walk model , where a walker takes random steps on the graph G , with the walk being modeled as a Markov process – that is , the decision on what edge to follow is solely based on the vertex where the walker is currently located .</sentence>
				<definiendum id="0">error rate ER</definiendum>
			</definition>
			<definition id="4">
				<sentence>In matrix notation , the PageRank vector of stationary probabilities is the principal eigenvector for the matrix Arow , which is obtained from the adjacency matrix A representing the graph , with all rows normalized to sum to 1 : ( P = ATrowP ) .</sentence>
				<definiendum id="0">Arow</definiendum>
				<definiens id="0">the principal eigenvector for the matrix</definiens>
			</definition>
			<definition id="5">
				<sentence>idf = tf ∗ logNDn where ND represent the total number of documents in the collection and n is the number of documents in which the target term appeared at least once .</sentence>
				<definiendum id="0">ND</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of documents in which the target term appeared at least once</definiens>
			</definition>
			<definition id="6">
				<sentence>K-Nearest Neighbor is one of the earliest text categorization approaches ( Makoto and Takenobu , 1995 ; Masand et al. , 1992 ) .</sentence>
				<definiendum id="0">K-Nearest Neighbor</definiendum>
				<definiens id="0">one of the earliest text categorization approaches</definiens>
			</definition>
			<definition id="7">
				<sentence>Support Vector Machines ( Vapnik , 1995 ) is a state-of-the-art machine learning approach based on decision plans .</sentence>
				<definiendum id="0">Support Vector Machines</definiendum>
				<definiens id="0">a state-of-the-art machine learning approach based on decision plans</definiens>
			</definition>
</paper>

		<paper id="1501">
			<definition id="0">
				<sentence>The standard written language is the same throughout the Arab world , Modern Standard Arabic ( MSA ) , which is also used in some scripted spoken communication ( news casts , parliamentary debates ) .</sentence>
				<definiendum id="0">MSA )</definiendum>
				<definiens id="0">is also used in some scripted spoken communication ( news casts , parliamentary debates )</definiens>
			</definition>
			<definition id="1">
				<sentence>Tree-substitution grammar ( Schabes , 1990 ) is TAG without auxiliary trees or adjunction ; instead we include a weaker composition operation , sister-adjunction ( Rambow et al. , 2001 ) , in which an initial tree is inserted between two sister nodes ( see Figure 4 ) .</sentence>
				<definiendum id="0">Tree-substitution grammar</definiendum>
				<definiens id="0">TAG without auxiliary trees or adjunction ; instead we include a weaker composition operation , sister-adjunction ( Rambow et al. , 2001 ) , in which an initial tree is inserted between two sister nodes</definiens>
			</definition>
			<definition id="2">
				<sentence>A synchronous TSG+SA is a set of pairs of elementary trees .</sentence>
				<definiendum id="0">synchronous TSG+SA</definiendum>
			</definition>
			<definition id="3">
				<sentence>As for Pt , in order to obtain better probability estimates , we further decompose Pt into Pt1 and Pt2 so they can be estimated separately ( as in the monolingual parsing model ) : Pt ( αprime | α ) ≈ Pt1 ( ¯αprime | ¯α , wprime , tprime , w , t ) × Pt2 ( wprime , tprime | w , t ) ( 5 ) where w and t are the lexical anchor of α and its POS tag , and ¯α is the equivalence class of α modulo lexical anchors and their POS tags .</sentence>
				<definiendum id="0">¯α</definiendum>
				<definiens id="0">Pt2 so they can be estimated separately ( as in the monolingual parsing model ) : Pt ( αprime | α ) ≈ Pt1 ( ¯αprime | ¯α , wprime , tprime , w</definiens>
			</definition>
			<definition id="4">
				<sentence>Pt2 represents the lexical transfer model , and Pt1 the syntactic transfer model .</sentence>
				<definiendum id="0">Pt2</definiendum>
				<definiens id="0">the lexical transfer model</definiens>
			</definition>
			<definition id="5">
				<sentence>Arabic Just as the probability model discussed in the preceding section factored the rewriting probabilities 5 into three parts , we create a synchronous TSG-SA and the probabilities of a hidden TAG model in three steps : • Ps and Psa are the parameters of a monolingual TSG+SA for MSA .</sentence>
				<definiendum id="0">Psa</definiendum>
				<definiens id="0">the parameters of a monolingual TSG+SA for MSA</definiens>
			</definition>
			<definition id="6">
				<sentence>• VSO-SVO Ordering ( SVO ) : Both VerbSubject-Object ( VSO ) and Subject-VerbObject ( SVO ) constructions occur in MSA and LA treebanks .</sentence>
				<definiendum id="0">VSO-SVO Ordering</definiendum>
				<definiendum id="1">SVO )</definiendum>
			</definition>
</paper>

		<paper id="0905">
			<definition id="0">
				<sentence>In 2004 , the Timex2 Detection and Recognition task6 ( also known as TERN , for Time Expression Recognition and Normalization ) has been added to the ACE program , making the whole evaluation exercise more complete .</sentence>
				<definiendum id="0">Timex2 Detection</definiendum>
				<definiendum id="1">TERN</definiendum>
				<definiens id="0">Time Expression Recognition and Normalization ) has been added to the ACE program , making the whole evaluation exercise more complete</definiens>
			</definition>
			<definition id="1">
				<sentence>I-CAB consists of 525 news documents taken from the Italian newspaper L’Adige ( http : //www.adige.it ) , and contains around 182,500 words .</sentence>
				<definiendum id="0">I-CAB</definiendum>
				<definiens id="0">consists of 525 news documents taken from the Italian newspaper L’Adige ( http : //www.adige.it ) , and contains around 182,500 words</definiens>
			</definition>
			<definition id="2">
				<sentence>35 Like all the other state-of-the-art systems addressing the recognition/normalization task , ITAChronos is a rule-based system .</sentence>
				<definiendum id="0">ITAChronos</definiendum>
				<definiens id="0">a rule-based system</definiens>
			</definition>
</paper>

		<paper id="3302">
			<definition id="0">
				<sentence>The query interpretation process consists of two major steps : 1 ) Syntactic analysis – parsing and decomposition of the input query ; and 2 ) Semantic analysis – mapping of syntactic structures to an intermediate conceptual representation .</sentence>
				<definiendum id="0">query interpretation process</definiendum>
				<definiens id="0">consists of two major steps : 1 ) Syntactic analysis – parsing and decomposition of the input query ; and 2 ) Semantic analysis – mapping of syntactic structures to an intermediate conceptual representation</definiens>
			</definition>
			<definition id="1">
				<sentence>Linguistic normalization is a process by which linguistic variants that contain the same semantic content are mapped onto the same representational structure .</sentence>
				<definiendum id="0">Linguistic normalization</definiendum>
				<definiens id="0">a process by which linguistic variants that contain the same semantic content are mapped onto the same representational structure</definiens>
			</definition>
			<definition id="2">
				<sentence>Syntactic normalization involves transformational rules that recognize the equivalence of different structures , e.g. : • Verb Phrase Normalization – elimination of tense , modality and voice .</sentence>
				<definiendum id="0">Syntactic normalization</definiendum>
				<definiens id="0">involves transformational rules that recognize the equivalence of different structures</definiens>
			</definition>
			<definition id="3">
				<sentence>The output of semantic analysis is a set of relationship triplets , which can be grouped into four categories : Subject Action Object Events , including interactions between entities and inter-event relations ( nested events ) , e.g. Inhibition ( “il-2” , “erbb2” ) Inhibition ( protein , Activation ( DEX , IkappaB ) ) Event Attributes , including attributes of an interaction event , e.g. Subject Modifier Action Modifier Object Modifier 11 Location ( Inhibition ( il-2 , erbb2 ) , “blood cell” ) Entity Attributes , including attributes of a given entity , e.g. Has-Location ( “erbb2” , “human” ) Entity Types , including taxonomic paths of a given entity , e.g. Is-A ( “erbb2” , “Protein” ) A natural language query will be decomposed into a list of inter-linked triplets .</sentence>
				<definiendum id="0">Subject Modifier Action Modifier Object Modifier 11 Location ( Inhibition</definiendum>
				<definiens id="0">a set of relationship triplets , which can be grouped into four categories : Subject Action Object Events , including interactions between entities and inter-event relations ( nested events</definiens>
			</definition>
			<definition id="4">
				<sentence>Relations : Inhibition ( “hiv-1 tat” , UNKNOWN ) IS-A ( UNKNOWN , “Protein” ) HAS-ATTRIBUTE ( UNKNOWN , “enzyme” ) ER query : ( hiv-1 tat &gt; [ Inhibition ] &gt; [ protein ] ) DOC_LEVEL_AND ( [ protein ] &gt; be &gt; enzyme ) One of the answer sentences is displayed below : “Thus , our experiments demonstrate that the Cterminal region of HIV-1 Tat is required to suppress Mn-SOD expression” while Mn-SOD is indicated as an enzyme in a different sentence : “… Mn-dependent superoxide dismutase ( MnSOD ) , a mitochondrial enzyme … ” Inter-Event Relations The inter-event relations or nested event queries ( CLAUSE_LEVEL_AND ) are currently implemented using the ER query’s local context constraints , i.e. one event must appear within the local context of the other .</sentence>
				<definiendum id="0">Mn-SOD</definiendum>
				<definiens id="0">implemented using the ER query’s local context constraints</definiens>
			</definition>
</paper>

		<paper id="3404">
</paper>

		<paper id="2101">
			<definition id="0">
				<sentence>A spatial locative expression consists of a locative prepositional phrase together with whatever the phrase modifies ( noun , clause , etc. ) .</sentence>
				<definiendum id="0">spatial locative expression</definiendum>
				<definiens id="0">consists of a locative prepositional phrase together with whatever the phrase modifies ( noun , clause , etc. )</definiens>
			</definition>
			<definition id="1">
				<sentence>In their simplest form , a locative expression consists of a prepositional phrase modifying a noun phrase , for example the man near the desk .</sentence>
				<definiendum id="0">locative expression</definiendum>
				<definiens id="0">consists of a prepositional phrase modifying a noun phrase</definiens>
			</definition>
</paper>

		<paper id="2921">
</paper>

		<paper id="1612">
			<definition id="0">
				<sentence>We also plan to run experiments on the automatic classification of old and mediated subtypes ( the finer-grained classification ) that is included in the corpus but that we did not consider for the present study ( see Section 2.1 ) .</sentence>
				<definiendum id="0">mediated subtypes</definiendum>
				<definiens id="0">the finer-grained classification ) that is included in the corpus</definiens>
			</definition>
</paper>

		<paper id="1512">
			<definition id="0">
				<sentence>Semantic composition consists of feature unification .</sentence>
				<definiendum id="0">Semantic composition</definiendum>
				<definiens id="0">consists of feature unification</definiens>
			</definition>
			<definition id="1">
				<sentence>l2 : every ( x , R2 , N2 ) l3 : some ( y , R3 , N3 ) l4 : student ( x ) l4 ≤ R2 , P1 ≤ N2 l5 : course ( y ) l5 ≤ R3 , P2 ≤ N3 l2 : every ( x , R2 , N2 ) l4 : student ( x ) l4 ≤R2 l3 : some ( y , R3 , N3 ) l5 : course ( y ) l5 ≤ R3 l1 : like ( x , y ) l1 ≤N2 l1 ≤N3 92 In LTAG semantics , semantic representations are introduced by lexicalized trees .</sentence>
				<definiendum id="0">l2</definiendum>
				<definiendum id="1">R3</definiendum>
				<definiens id="0">some ( y ,</definiens>
			</definition>
			<definition id="2">
				<sentence>C3 ( v5 ) NP [ i : r ] V jane ( r ) Final Representation : This sentence introduces an intransitive tree and one propositional variable C3 .</sentence>
				<definiendum id="0">Final Representation</definiendum>
			</definition>
			<definition id="3">
				<sentence>every ( y , student ( y ) , some ( x , test ( x ) , give ( v , y , z ) ) ) ( r ) = every ( y , student ( y ) , some ( x , test ( x ) , give ( r , y , z ) ) ) The inverse reading ( where some &gt; &gt; every ) can be obtained by the following mapping C3- &gt; l0 , C2- &gt; l3 , R7- &gt; l8 , N7 - &gt; l2 , C1- &gt; l5 , R5- &gt; l9 , N5 - &gt; l7 l2 : give ( v , y , z ) l7 : every ( y , student ( y ) , give ( v , y , z ) ) l5 : some ( x , test ( x ) , every ( y , student ( y ) , give ( v , y , z ) ) ) l1 : some ( x , test ( x ) , every ( y , student ( y ) , give ( x , y , z ) ) ) Now , when the second sentence is interpreted , C3 is unified with C1 , which is being mapped to l5 : C3 ( =C1 ) - &gt; l5 .</sentence>
				<definiendum id="0">test</definiendum>
				<definiendum id="1">test</definiendum>
				<definiendum id="2">inverse reading</definiendum>
				<definiendum id="3">student</definiendum>
				<definiens id="0">some ( x , test ( x ) , every ( y , student ( y )</definiens>
			</definition>
</paper>

		<paper id="1655">
			<definition id="0">
				<sentence>The semi-CRF is a sequence model that is designed to address this difficulty via careful relaxation of the Markov assumption .</sentence>
				<definiendum id="0">semi-CRF</definiendum>
				<definiens id="0">a sequence model that is designed to address this difficulty via careful relaxation of the Markov assumption</definiens>
			</definition>
			<definition id="1">
				<sentence>The general form of a log-linear model is as follows : given an input x ∈ X , an output y∈Y , a feature mapping Φ : X×Y mapsto→Rn , and a weight vector w , the conditional probability of y given x is estimated as : P ( y|x ) = exp ( w·Φ ( x , y ) ) Z ( x ) where Z : x mapsto→ R is a normalizing factor .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">w·Φ ( x , y ) ) Z ( x ) where Z : x mapsto→</definiens>
				<definiens id="1">a normalizing factor</definiens>
			</definition>
			<definition id="2">
				<sentence>466 segmentation task , x is an ordered sequence of characters ( x1 , x2 , ... , xn ) , and y is a set of indices corresponding to the start of each word : { y1 , y2 , ... , ym } such that y1 = 1 , ym ≤ n , and for all j , yj &lt; yj+1 .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">an ordered sequence of characters ( x1 , x2 , ... , xn ) , and</definiens>
			</definition>
			<definition id="3">
				<sentence>A log-linear model in this space is an order-1 semi-CRF if its feature map Φ decomposes according to Φ ( x , y ) = msummationdisplay j=1 φS ( yj , yj+1 , x ) ( 1 ) where φS is a local feature map that only considers one chunk at a time ( defining ym+1 = n+1 ) .</sentence>
				<definiendum id="0">log-linear model</definiendum>
				<definiendum id="1">φS</definiendum>
				<definiens id="0">a local feature map that only considers one chunk at a time</definiens>
			</definition>
			<definition id="4">
				<sentence>An order-1 Markov CRF is a log-linear model in which the global feature vector Φ decomposes into a sum over local feature vectors that consider bigrams of the label sequence : Φ ( x , y ) = nsummationdisplay i=1 φM ( Li , Li+1 , i , x ) ( 2 ) ( where Ln+1 is defined as B ) .</sentence>
				<definiendum id="0">order-1 Markov CRF</definiendum>
			</definition>
			<definition id="5">
				<sentence>In this paper , we experiment with the use of a single “hybrid” local semi-CRF feature , the smoothed log conditional odds that a given subsequence xab = ( xa , ... , xb−1 ) forms a word : log wordcount ( xab ) + 1nonwordcount ( x ab ) + 1 , where wordcount ( xab ) is the number of times xab forms a word in the training set , and nonwordcount ( xab ) is the number of times xab occurs , not segmented into a single word .</sentence>
				<definiendum id="0">wordcount</definiendum>
				<definiens id="0">the number of times xab forms a word in the training set</definiens>
			</definition>
			<definition id="6">
				<sentence>In order to be directly comparable to the Bakeoff results , we also worked under the very strict “closed test” conditions of the Bakeoff , which require that no information or data outside of the training set be used , not even prior knowledge of which characters represent Arabic numerals , Latin characters or punctuation marks .</sentence>
				<definiendum id="0">Bakeoff</definiendum>
				<definiens id="0">require that no information or data outside of the training set be used , not even prior knowledge of which characters represent Arabic numerals , Latin characters or punctuation marks</definiens>
			</definition>
</paper>

		<paper id="3312">
			<definition id="0">
				<sentence>The preprocessing phase consists of standard tokenization and part-of-speech tagging , as well as named entity recognition ( and other term lookup ) using gazetteer lists and simple transducers .</sentence>
				<definiendum id="0">preprocessing phase</definiendum>
				<definiens id="0">consists of standard tokenization and part-of-speech tagging , as well as named entity recognition ( and other term lookup ) using gazetteer lists and simple transducers</definiens>
			</definition>
</paper>

		<paper id="1804">
</paper>

		<paper id="1301">
			<definition id="0">
				<sentence>In Addition to the visualhaptic interface , iDrive includes a speech dialogue system ( SDS ) as well .</sentence>
				<definiendum id="0">iDrive</definiendum>
				<definiens id="0">includes a speech dialogue system ( SDS ) as well</definiens>
			</definition>
			<definition id="1">
				<sentence>T = B ·N−α ( power law ) ( 1 ) T = B ·e−α·N ( exponential law ) ( 2 ) In both equations T represents the time to solve a task , B is the time needed for the first trial of a task , N stands for the number of trials and α is the learning rate parameter that is a measure for the learning speed .</sentence>
				<definiendum id="0">B</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">α</definiendum>
				<definiens id="0">power law ) ( 1 ) T = B ·e−α·N ( exponential law ) ( 2 ) In both equations T represents the time to solve a task ,</definiens>
				<definiens id="1">the time needed for the first trial of a task</definiens>
				<definiens id="2">the number of trials and</definiens>
			</definition>
			<definition id="2">
				<sentence>µnew = µold ·ln ( t + e ) −δ ( logarithmic ) ( 4 ) µnew = µold ·e−δ·t ( exponential ) ( 5 ) µnew = µold · ( t + δ ) −δ ( power ) ( 6 ) µnew = µold ·e−δ· √t ( square root ) ( 7 ) The variable µ represents the initial amount of learned items .</sentence>
				<definiendum id="0">variable µ</definiendum>
				<definiens id="0">represents the initial amount of learned items</definiens>
			</definition>
			<definition id="3">
				<sentence>F represents the complete functionality of the system .</sentence>
				<definiendum id="0">F</definiendum>
			</definition>
			<definition id="4">
				<sentence>The following parameters are used to calculate an additional user model : help requests h ( user asked for general information about the system ) , options requests o ( user asked for the currently available speech commands ) , timeouts t ( the ASR did not get any acoustic signal ) , onset time ot ( user needed more than 3 sec to start answering ) and bargein b ( user starts speech input during the system’s speech output ) .</sentence>
				<definiendum id="0">bargein b</definiendum>
				<definiens id="0">used to calculate an additional user model : help requests h ( user asked for general information about the system</definiens>
				<definiens id="1">the ASR did not get any acoustic signal ) , onset time ot ( user needed more than 3 sec to start answering</definiens>
			</definition>
</paper>

		<paper id="0507">
			<definition id="0">
				<sentence>In this paper , we describe a rote extractor that learns patterns for finding semantic relations in unrestricted text , with new procedures for pattern generalisation and scoring .</sentence>
				<definiendum id="0">rote extractor</definiendum>
				<definiens id="0">learns patterns for finding semantic relations in unrestricted text , with new procedures for pattern generalisation and scoring</definiens>
			</definition>
			<definition id="1">
				<sentence>Rote extractors ( Mann and Yarowsky , 2005 ) estimate the probability of a relation r ( p , q ) given the surrounding context A1pA2qA3 .</sentence>
				<definiendum id="0">Rote extractors</definiendum>
				<definiens id="0">the probability of a relation r ( p , q ) given the surrounding context A1pA2qA3</definiens>
			</definition>
			<definition id="2">
				<sentence>From the downloaded corpus , we extract sentences such as Dickens was born in 1812 Dickens ( 1812 1870 ) was an English writer Dickens ( 1812 1870 ) wrote Oliver Twist Thesystemidentifiesthatthecontextsofthelast two sentences are very similar and chooses their longest common substring to produce the following patterns : &lt; hook &gt; was born in &lt; target &gt; &lt; hook &gt; ( &lt; target &gt; 1870 ) The rote extractor needs to estimate automatically the precision of the extracted patterns , in order to keep the best ones .</sentence>
				<definiendum id="0">rote extractor</definiendum>
				<definiens id="0">needs to estimate automatically the precision of the extracted patterns</definiens>
			</definition>
</paper>

		<paper id="2702">
			<definition id="0">
				<sentence>Terms ( such as names of genes , proteins , gene products , organisms , drugs , chemical compounds , etc. ) are a key factor for accessing and integrating the information stored in literature ( Krauthammer and Nenadic , 2004 ) .</sentence>
				<definiendum id="0">Terms</definiendum>
				<definiens id="0">such as names of genes , proteins , gene products , organisms , drugs , chemical compounds , etc. ) are a key factor for accessing and integrating the information stored in literature</definiens>
			</definition>
			<definition id="1">
				<sentence>The pair consisting of the database name and the accession number ( s ) forms a unique identifier ( UID ) that represents the semantics of the term and can be trivially rewritten into a URL pointing to the database entry .</sentence>
				<definiendum id="0">s )</definiendum>
				<definiens id="0">forms a unique identifier ( UID ) that represents the semantics of the term and can be trivially rewritten into a URL pointing to the database entry</definiens>
			</definition>
			<definition id="2">
				<sentence>The part-of-speech tagger ( POS-tagger ) is a separate module and combines tokenization and POS annotation .</sentence>
				<definiendum id="0">part-of-speech tagger</definiendum>
			</definition>
			<definition id="3">
				<sentence>Annotation ( i.e. XML ) -based problems mainly relate to an open question whether different tag names should be used for various semantic types , or semantic types should be represented via attributes of a generalised named entity or term tag .</sentence>
				<definiendum id="0">Annotation</definiendum>
				<definiens id="0">be represented via attributes of a generalised named entity or term tag</definiens>
			</definition>
			<definition id="4">
				<sentence>A similar challenge is how to treat and make use of entities such as inline references , citations and formulas ( typically annotated in journals ) , which are commonly ignored by NLP modules .</sentence>
				<definiendum id="0">similar challenge</definiendum>
				<definiens id="0">typically annotated in journals</definiens>
			</definition>
</paper>

		<paper id="2714">
			<definition id="0">
				<sentence>Chunker analysis results are included in the RMRS to be built through an XSLT stylesheet using the XPath expression document ( $ uri ) /chunkie/chunks/chunk [ @ cstart= $ beginspan and @ cend= $ endspan ] where $ uri is a variable containing an annotation identifier of the form hog : //sid/acid/aid as explained in Section 2.1 .</sentence>
				<definiendum id="0">XPath expression document</definiendum>
				<definiens id="0">a variable containing an annotation identifier of the form hog : //sid/acid/aid as explained in Section 2.1</definiens>
			</definition>
</paper>

		<paper id="3206">
			<definition id="0">
				<sentence>Such systems tend to perform badly when there are many low-frequent and too case-specific classes ; task decomposition allows them to be robust and generic when they process unseen words .</sentence>
				<definiendum id="0">task decomposition</definiendum>
				<definiens id="0">allows them to be robust and generic when they process unseen words</definiens>
			</definition>
			<definition id="1">
				<sentence>Optimality Theory ( Prince and Smolensky , 2004 ) can also be seen as a constraint-based approach to language processing based on linguistically motivated constraints .</sentence>
				<definiendum id="0">Optimality Theory</definiendum>
				<definiens id="0">a constraint-based approach to language processing based on linguistically motivated constraints</definiens>
			</definition>
			<definition id="2">
				<sentence>Here , X = { x1 , x2 , ... , xn } is a finite set of variables .</sentence>
				<definiendum id="0">x2 , ... , xn }</definiendum>
				<definiens id="0">a finite set of variables</definiens>
			</definition>
			<definition id="3">
				<sentence>D ( x ) is a function that maps each variable to its domain , that is , the set of values that variable can take on .</sentence>
				<definiendum id="0">D ( x )</definiendum>
				<definiens id="0">a function that maps each variable to its domain</definiens>
			</definition>
			<definition id="4">
				<sentence>C is the set of constraints .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the set of constraints</definiens>
			</definition>
			<definition id="5">
				<sentence>Let a constraint c ∈ C be defined as a function that maps each variable assignment to 1 if the constraint is satisfied , or to 0 if it is not .</sentence>
				<definiendum id="0">constraint c ∈ C</definiendum>
				<definiens id="0">a function that maps each variable assignment to 1 if the constraint is satisfied , or to 0 if it is not</definiens>
			</definition>
			<definition id="6">
				<sentence>Constraints derived from this class are weighted according to the following rules : • for a trigram constraint , the weight is simply the base classifier’s confidence value for the class c∗ ; • for a bigram constraint , the weight is the sum of the confidences for all trigram classes in the nearest-neighbor set of x that assign the same symbol bigram to the letters spanned by the constraint ; • for a unigram constraint , the weight is the sum of the confidences for all trigram classes in the nearest-neighbor set of x that assign the same symbol to the letter spanned by the constraint .</sentence>
				<definiendum id="0">weight</definiendum>
				<definiens id="0">the sum of the confidences for all</definiens>
			</definition>
</paper>

		<paper id="1402">
			<definition id="0">
				<sentence>PG enables a simple and uniform treatment of a heterogeneous collection of linear order phenomena in the domain of verb constructions ( variably known as Cros-serial Dependencies , Verb Raising , Clause Union , Extraposition , Third Construction , Particle Hoping , etc. ) .</sentence>
				<definiendum id="0">PG</definiendum>
				<definiendum id="1">Cros-serial Dependencies</definiendum>
				<definiens id="0">enables a simple and uniform treatment of a heterogeneous collection of linear order phenomena in the</definiens>
			</definition>
			<definition id="1">
				<sentence>LinGO ( Copestake &amp; Flickinger , 200 ) , for Head-Driven Phrase Structure Grammar , provides a generator in addition to a parser .</sentence>
				<definiendum id="0">LinGO</definiendum>
				<definiens id="0">for Head-Driven Phrase Structure Grammar , provides a generator in addition to a parser</definiens>
			</definition>
			<definition id="2">
				<sentence>3 A sketch of PGW’s software design The PGW is a computational grammar development tol for PG .</sentence>
				<definiendum id="0">PGW</definiendum>
				<definiens id="0">a computational grammar development tol for PG</definiens>
			</definition>
</paper>

		<paper id="2905">
			<definition id="0">
				<sentence>For construction grammarians , multi-word expressions ( MWEs ) such as idioms , collocations , xed expressions and compound verbs and nouns , are not so much exceptions to the rule , but rather extreme cases that reveal some fundamental properties of natural language .</sentence>
				<definiendum id="0">multi-word expressions ( MWEs</definiendum>
				<definiens id="0">) such as idioms , collocations , xed expressions and compound verbs and nouns , are not so much exceptions to the rule , but rather extreme cases that reveal some fundamental properties of natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>Crucially , I use a formalism known as Stochastic Tree Substitution Grammars ( henceforth , STSGs ) , which can represent single words , contiguous and noncontiguous MWEs , context-free rules or complete parse trees in a uni ed representation .</sentence>
				<definiendum id="0">Stochastic Tree Substitution Grammars</definiendum>
				<definiendum id="1">STSGs )</definiendum>
				<definiens id="0">contiguous and noncontiguous MWEs , context-free rules or complete parse trees in a uni ed representation</definiens>
			</definition>
			<definition id="2">
				<sentence>STSGs are a simple generalization of Stochastic Context Free Grammars ( henceforth , SCFGs ) , where the productive units are elementary trees of arbitrary size instead of the rewrite rules in SCFGs ( which can be viewed as trees of depth 1 ) .</sentence>
				<definiendum id="0">STSGs</definiendum>
				<definiens id="0">a simple generalization of Stochastic Context Free Grammars ( henceforth , SCFGs ) , where the productive units are elementary trees of arbitrary size instead of the rewrite rules in SCFGs ( which can be viewed as trees of depth 1 )</definiens>
			</definition>
			<definition id="3">
				<sentence>An STSG is a 5-tuple 〈Vn , Vt , S , T , w〉 , where Vn is the set of non-terminal symbols ; Vt is the set of terminal symbols ; S ∈ Vn is the start symbol ; T is a set of elementary trees , such that for every t ∈ T the unique root node r ( t ) ∈ Vn , the set of internal nodes i ( t ) ⊂ Vn and the set of leaf nodes l ( t ) ⊂ Vn ∪ Vt ; nally , w : T → [ 0,1 ] is a probability ( weight ) distribution over the elementary trees , such that for any t ∈ T , summationtexttprime∈R ( t ) w ( tprime ) = 1 , where R ( t ) is the set of elementary trees with the same root label as t. It will prove useful to also dene the set of all possible trees θ over the de ned alphabets ( with the same conditions on root , internal and leaf nodes as for T ) , and the set of all possible complete parse trees Θ ( with r ( t ) = S and all leaf nodes l ( t ) ⊂ Vt ) .</sentence>
				<definiendum id="0">STSG</definiendum>
				<definiendum id="1">Vn</definiendum>
				<definiendum id="2">Vt</definiendum>
				<definiendum id="3">T</definiendum>
				<definiens id="0">a 5-tuple 〈Vn , Vt , S , T , w〉 , where</definiens>
				<definiens id="1">the set of non-terminal symbols</definiens>
				<definiens id="2">the set of terminal symbols ; S ∈ Vn is the start symbol</definiens>
				<definiens id="3">a set of elementary trees , such that for every t ∈ T the unique root node r ( t ) ∈ Vn , the set of internal nodes i ( t ) ⊂ Vn and the set of leaf nodes l ( t ) ⊂ Vn ∪ Vt ; nally , w : T → [ 0,1 ] is a probability ( weight ) distribution over the elementary trees , such that for any t ∈ T , summationtexttprime∈R ( t ) w ( tprime ) = 1 , where R ( t ) is the set of elementary trees with the same root label as t. It will prove useful to also dene the set of all possible trees θ over the de ned alphabets ( with the same conditions on root , internal and leaf nodes as for T ) , and the set of all possible complete parse trees Θ ( with r ( t ) = S and all leaf nodes l ( t ) ⊂ Vt )</definiens>
			</definition>
			<definition id="4">
				<sentence>A derivation is a sequence of elementary trees , where the rst tree t ∈ T has root-label S and every next tree combines through substitution with the result of the substitutions before it .</sentence>
				<definiendum id="0">derivation</definiendum>
				<definiens id="0">a sequence of elementary trees , where the rst tree t ∈ T has root-label S and every next tree combines through substitution with the result of the substitutions before it</definiens>
			</definition>
			<definition id="5">
				<sentence>Multiple derivations can yield the same parse tree ; the probability of a parse tree p equals the sum of the probabilities of the different derivations that yield that same tree : P ( p ) = summationdisplay d : ˆd=p ( P ( d ) ) , ( 2 ) where ˆd is the tree derived by derivation d. In this paper , we are only concerned with grammars that de ne proper probability distributions over 30 trees , such that the probability of all derivations sum up to 1 and no probability mass gets lost in derivations that never reach a terminal yield .</sentence>
				<definiendum id="0">ˆd</definiendum>
				<definiens id="0">the probability of a parse tree p equals the sum of the probabilities of the different derivations that yield that same tree</definiens>
				<definiens id="1">concerned with grammars that de ne proper probability distributions over 30 trees , such that the probability of all derivations sum up to 1 and no probability mass gets lost in derivations that never reach a terminal yield</definiens>
			</definition>
			<definition id="6">
				<sentence>More generally , the expected occurrence frequency f ( t ) ( relative to the number n of complete trees in the tree bank ) of a subtree t is : E [ f ( t ) ] = summationdisplay p : t∈p∗ ( P ( p ) C ( t , p∗ ) ) , ( 5 ) where p∗ is the multiset of all subtrees of p. Hence , w ( t ) , u ( t ) and f ( t ) all assign values ( the latter two not necessarily between 0 and 1 ) to trees .</sentence>
				<definiendum id="0">expected occurrence frequency f</definiendum>
				<definiendum id="1">p∗</definiendum>
			</definition>
			<definition id="7">
				<sentence>With a bit of algebra we can work out the following relations : u ( t ) =    w ( t ) if r ( t ) = S w ( t ) summationdisplay tprime : r ( t ) ∈l ( tprime ) u ( tprime ) Ctprimet otherwise ( 6 ) where Ctprimet gives the number of occurrences of the root label r ( t ) of t among the leaves of tprime .</sentence>
				<definiendum id="0">Ctprimet</definiendum>
				<definiens id="0">gives the number of occurrences of the root label r ( t ) of t among the leaves of tprime</definiens>
			</definition>
			<definition id="8">
				<sentence>Using ◦ to indicate left-most substitution , we write : • t1 is a twig of t2 , if either t1 = t2 or ∃t3 , such that t3 ◦ t1 = t2 ; • t1 is a prune of t2 , if either t1 = t2 or ∃t3 ... tn , such that t1 ◦ t3 ... ◦ tn = t2 ; • tprime = prx ( t ) , if x is a set of nodes in t , such that if t is pruned at each i ∈ x it equals tprime .</sentence>
				<definiendum id="0">t1</definiendum>
				<definiens id="0">a twig of t2 , if either t1 = t2 or ∃t3 , such that t3 ◦ t1 = t2 ; •</definiens>
				<definiens id="1">a prune of t2 , if either t1 = t2 or ∃t3 ... tn , such that t1 ◦ t3 ... ◦ tn = t2 ; • tprime = prx ( t ) , if x is a set of nodes in t</definiens>
			</definition>
			<definition id="9">
				<sentence>In pseudocode , the push-n-pull algorithm is as follows : for each observed parse tree p 32 for each depth-1 subtree t in p update-score ( t,1.0 ) for each subtree t of p ∆ =min ( sc ( t ) , B + γ ( E [ f ( t ) ] − f ( t ) ) ) ∆prime = 0 for each of n derivations d of t let tprime ... tprimeprime be all elementary trees in d δ =min ( sc ( tprime ) , ... , sc ( tprimeprime ) , −∆/n ) ∆prime− = δ for each elementary tree tprime in d update-score ( tprime , δ ) update-score ( t , ∆prime ) where sc ( t ) is the score of t , B is the bias towards smaller subtrees , γ is the learning rate parameter and f ( t ) is the observed frequency of t. ∆prime thus gives the actual change in the score of t , based on the difference between expected and observed frequency , bias , learning rate and how much scores can be pushed or pulled2 .</sentence>
				<definiendum id="0">sc</definiendum>
				<definiendum id="1">γ</definiendum>
				<definiendum id="2">f ( t )</definiendum>
				<definiens id="0">the score of t , B is the bias towards smaller subtrees ,</definiens>
				<definiens id="1">the observed frequency of t. ∆prime thus gives the actual change in the score of t , based on the difference between expected and observed frequency , bias , learning rate</definiens>
			</definition>
			<definition id="10">
				<sentence>In this paper we have presented an approach to identifying the relevant statistical correlations in a corpus based on the assumption that the 34 TOP VB SHOW VP* PRP ME NP NP* DT NNS NP** PP-DIR PP-DIR* ( a ) The show me NP PP frame , which occurs very frequently in the training data and is represented in several elementary trees with high weight .</sentence>
				<definiendum id="0">TOP VB SHOW VP* PRP ME NP NP* DT NNS NP** PP-DIR PP-DIR*</definiendum>
				<definiens id="0">an approach to identifying the relevant statistical correlations in a corpus based on the assumption that the 34</definiens>
				<definiens id="1">occurs very frequently in the training data and is represented in several elementary trees with high weight</definiens>
			</definition>
</paper>

		<paper id="2206">
			<definition id="0">
				<sentence>Distance-based methods ( Knorr and Ng , 1998 ) utilise a k-nearest neighbour approach where outliers are defined , for example , as those instances whose distance to their nearest neighbour exceeds a certain threshold .</sentence>
				<definiendum id="0">Distance-based methods</definiendum>
				<definiens id="0">those instances whose distance to their nearest neighbour exceeds a certain threshold</definiens>
			</definition>
			<definition id="1">
				<sentence>In our database , for example , there is an interdependency between the LOCATION and the COUNTRY columns : the probability that the COUNTRY column contains the value South Africa increases if the LOCATION column contains the string Tafel Mountain ( and vice versa ) .</sentence>
				<definiendum id="0">COUNTRY columns</definiendum>
				<definiens id="0">the probability that the COUNTRY column contains the value South Africa increases if the LOCATION column contains the string Tafel Mountain ( and vice versa )</definiens>
			</definition>
			<definition id="2">
				<sentence>The similarity between a string , consisting of a set T of tokens t1 ... tn , and a column colx was defined as : sim ( T , colx ) = summationtextn i=1 ti × tfidfti , colx |T| where tfidfticolx is the tfidf weight ( term frequency inverse document frequency , cf. ( SparckJones , 1972 ) ) of token ti in column colx .</sentence>
				<definiendum id="0">term frequency inverse document frequency</definiendum>
				<definiens id="0">sim ( T , colx ) = summationtextn i=1 ti × tfidfti</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally , the tfidf weight for a term ti in column colx is defined as : tfidfti , colx = tfti , colx log idfti A high tfidf weight for a given token in a given column means that the token frequently occurs in that column but rarely in other columns , thus the token is a good indicator for that column .</sentence>
				<definiendum id="0">tfidf weight</definiendum>
				<definiens id="0">tfidfti , colx = tfti , colx log idfti A high tfidf weight for a given token in a given column means that the token frequently occurs in that column but rarely in other columns</definiens>
			</definition>
			<definition id="4">
				<sentence>To assign a text string to one of the 35 database columns , we trained TiMBL ( Daelemans et al. , 2004 ) on the feature vectors of all other database cells labelled with the column they belong to.11 Cases where the predicted column differed from the current column of the string were recorded as potential errors .</sentence>
				<definiendum id="0">TiMBL</definiendum>
				<definiens id="0">Daelemans et al. , 2004 ) on the feature vectors of all other database cells labelled with the column they belong to.11 Cases where the predicted column differed from the current column of the string were recorded as potential errors</definiens>
			</definition>
			<definition id="5">
				<sentence>1970 COLLECTION NUMBER COLLECTOR ( Surinam Expedition 1970 ) Table 6 : Examples of automatically corrected errors ( vertical method ) unfiltered filtered flagged errors 836 262 real errors 148 67 correctly corrected 100 54 precision error detection 17.70 % 25.57 % accuracy error correction 67.57 % 80.60 % Table5 : Resultsautomaticerrordetectionandcorrection for all database fields ( vertical method ) ing the flagged errors .</sentence>
				<definiendum id="0">COLLECTION NUMBER COLLECTOR</definiendum>
				<definiens id="0">Examples of automatically corrected errors ( vertical method</definiens>
			</definition>
</paper>

		<paper id="1407">
			<definition id="0">
				<sentence>Verbal suffix C ad c C pr 1 C pr 2 ru 9 16 0 tei-ru 5 42 0 re-ru 14 8 0 re-tei-ru 2 5 0 ta 57 0 7 tei-ta 2 0 2 re-ta 6 0 1 re-tei-ta 0 0 1 both ta and tei-ru 4 0 0 both ta and ru 1 0 0 tea-ru 0 2 0 Total 100 73 11 where ru : baseform tei : progressive / perfective re : passive / potential ta : past / attributive tea : perfective and characters ( kanji ) , and either of adjective or verb falls into the easiest three levels .</sentence>
				<definiendum id="0">ru</definiendum>
			</definition>
</paper>

		<paper id="2108">
			<definition id="0">
				<sentence>In this definition , the triple relation agent-instrumentgoal ( as in : John cuts the bread with a knife , where John is agent , knife is instrument that does the cutting , and bread cut is the goal ) , is left vague in what concerns the exact involvement of the agent and the instrument in the action , and the control the agent has on the instrument and on the action ( Mari and St-Dizier 01 ) .</sentence>
				<definiendum id="0">John</definiendum>
				<definiendum id="1">bread cut</definiendum>
				<definiens id="0">left vague in what concerns the exact involvement of the agent and the instrument in the action</definiens>
			</definition>
			<definition id="1">
				<sentence>This entails generic forms such as bi-tarika , bi-istemali ( by means of , the first form reinforces the importance of the instrument , while the latter is more formal ) and bi-fadli ( thanks to ) .</sentence>
				<definiendum id="0">bi-fadli (</definiendum>
				<definiens id="0">thanks to )</definiens>
			</definition>
			<definition id="2">
				<sentence>Case suffixes ( vibakhti ) are added to nouns or pronouns , but case suffixes do not correspond strictly to thematic roles ( kAraka ) .</sentence>
				<definiendum id="0">Case</definiendum>
				<definiens id="0">suffixes ( vibakhti ) are added to nouns or pronouns , but case suffixes do not correspond strictly to thematic roles</definiens>
			</definition>
			<definition id="3">
				<sentence>Thai , from the Thai-Kadai family , has 6 prepositions ( Silapasarn , 98 ) to denote instruments , the most common being doi and duai which are used for concrete instruments , means of transportation , instruments close to manners , etc. kap is used when the instrument is a part of the body , while thang is used for means of transportation only .</sentence>
				<definiendum id="0">Thai</definiendum>
				<definiens id="0">has 6 prepositions ( Silapasarn , 98 ) to denote instruments , the most common being doi and duai which are used for concrete instruments , means of transportation , instruments close to manners</definiens>
				<definiens id="1">a part of the body</definiens>
			</definition>
</paper>

		<paper id="1802">
			<definition id="0">
				<sentence>Closed-domain ( medical ) QA can benefit from the fact that dependency relations allow answers to be identified for questions which are not restricted to specific named entity classes , i.e. definitions , causes , symptoms , etc .</sentence>
				<definiendum id="0">Closed-domain</definiendum>
			</definition>
			<definition id="1">
				<sentence>Joost is a QA system for Dutch which incorporates the features mentioned above , using the Alpino parser for Dutch to parse ( offline ) the document collections as well as ( interactively ) user questions .</sentence>
				<definiendum id="0">Joost</definiendum>
			</definition>
</paper>

		<paper id="1504">
			<definition id="0">
				<sentence>Satta and Schuler ( 1998 ) , working within the application domain of natural language syntax , dene another restriction on TAG which is also recognizable in O ( n5 ) time .</sentence>
				<definiendum id="0">TAG</definiendum>
				<definiens id="0">working within the application domain of natural language syntax , dene another restriction on</definiens>
			</definition>
			<definition id="1">
				<sentence>We assume a standard de nition of TAG , with or without substitution , in which adjunction is not allowed at foot nodes , and other nodes can have noadjunction ( NA ) constraints , obligatory-adjunction ( OA ) , or selective-adjunction constraints .</sentence>
				<definiendum id="0">NA</definiendum>
				<definiens id="0">obligatory-adjunction ( OA ) , or selective-adjunction constraints</definiens>
			</definition>
			<definition id="2">
				<sentence>The subtree of a node η is the set of all nodes dominated by η , including η itself .</sentence>
				<definiendum id="0">subtree of a node η</definiendum>
				<definiens id="0">the set of all nodes dominated by η , including η itself</definiens>
			</definition>
			<definition id="3">
				<sentence>A wrapping auxiliary tree is one which is neither a left or a right auxiliary tree .</sentence>
				<definiendum id="0">wrapping auxiliary tree</definiendum>
				<definiens id="0">neither a left or a right auxiliary tree</definiens>
			</definition>
			<definition id="4">
				<sentence>A simple linear tree-adjoining grammar ( SL-TAG ) , with or without substitution , is a TAG , with or without substitution , respectively , in which every initial tree has exactly one active node , and every auxiliary tree has exactly one active node on its spine and no active nodes elsewhere .</sentence>
				<definiendum id="0">simple linear tree-adjoining grammar</definiendum>
				<definiens id="0">with or without substitution , is a TAG , with or without substitution , respectively , in which every initial tree has exactly one active node , and every auxiliary tree has exactly one active node on its spine and no active nodes elsewhere</definiens>
			</definition>
			<definition id="5">
				<sentence>L ( SSL-TAG ) ⊆ L ( SL-TAG + substitution ) : We deal rst with the left and right auxiliary trees , and then with off-spine adjunction .</sentence>
				<definiendum id="0">L ( SSL-TAG ) ⊆ L</definiendum>
				<definiens id="0">SL-TAG + substitution ) : We deal rst with the left and right auxiliary trees , and then with off-spine adjunction</definiens>
			</definition>
			<definition id="6">
				<sentence>Since these only insert material to the left or right of a node , just as in tree-insertion grammars ( TIGs ) , we may apply the conversion from TIGs to tree-substitution grammars ( Schabes and Waters , 1995 ) , used in the proof of the context-freeness of 26 ( Step 1a ) ... X ... ⇒ ... X ... ... XNA LX↓ XNA ... ... XNA XNA ... RX↓ ... XNA LX↓ XNA ... RX↓ ( Step 1b ) X X∗ Y ⇒ RX Y RX Y RX↓ X Y X∗ ⇒ LX Y LX LX↓ Y Figure 2 : Elimination of left/right auxiliary trees .</sentence>
				<definiendum id="0">XNA XNA</definiendum>
				<definiens id="0">Step 1a ) ... X ... ⇒ ... X ... ... XNA LX↓ XNA ... ...</definiens>
			</definition>
			<definition id="7">
				<sentence>X , then adjoining βR at the root of βL , which is allowed because the de nition of SSL-TAG prohibits adjunction constraints at the root of βL .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">βL</definiendum>
				<definiens id="0">is allowed because the de nition of SSL-TAG prohibits adjunction constraints at the root of βL</definiens>
			</definition>
			<definition id="8">
				<sentence>( Step 2 ) Next , we transform the grammar so that no initial tree has more than one substitution node , while maintaining the form acquired in step nodes , we apply the same transformation as in step 1 , except that Y is the child of the root node , Z1 is its left child , and Z2 is its other child if it exists and is not already a substitution node .</sentence>
				<definiendum id="0">Z2</definiendum>
				<definiens id="0">no initial tree has more than one substitution node , while maintaining the form acquired in step nodes</definiens>
				<definiens id="1">the child of the root node</definiens>
			</definition>
			<definition id="9">
				<sentence>... X↓ ⇒ ... SX OA epsilon1 For each initial tree with root label X , convert it into an auxiliary tree by adding a new root node labeled SX whose children are the old root node and a new foot node .</sentence>
				<definiendum id="0">SX OA epsilon1 For</definiendum>
				<definiens id="0">each initial tree with root label X , convert it into an auxiliary tree by adding a new root node labeled SX whose children are the old root node</definiens>
			</definition>
			<definition id="10">
				<sentence>A decomposed string over Σ is a sequence of strings over Σ , which can be projected into Σ∗ by concatenating their members in order , and again we will talk about decomposed strings and their projections interchangeably .</sentence>
				<definiendum id="0">decomposed string over Σ</definiendum>
				<definiens id="0">a sequence of strings over Σ , which can be projected into Σ∗ by concatenating their members in order</definiens>
			</definition>
			<definition id="11">
				<sentence>Moreover , it holds such that the w1 and w2 it provides can be further decomposed into z1z2 and z3z4 , respectively , such that for any marking of n symbols of any of the zj , either Condition 1 holds of z = x1zjx2 ( where x1 and x2 are the surrounding context of zj ) or Condition 2 holds of z = x1z1z2x2z3z4x3 ( where x1 , x2 , and x3 are the surrounding context of z1z2 and z3z4 ) .</sentence>
				<definiendum id="0">x3</definiendum>
				<definiens id="0">z = x1z1z2x2z3z4x3 ( where x1 , x2 , and</definiens>
			</definition>
</paper>

		<paper id="3007">
			<definition id="0">
				<sentence>The basic change in viewpoint required , in the study of interactive systems with real users , is that one can not follow the Cranfield Model , in which specific items ( whether documents , or snippets of information ) are known to be “good , ” so that measures can be based on the count of such items ( e.g. , precision and recall ) .</sentence>
				<definiendum id="0">Cranfield Model</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">in which specific items ( whether documents , or snippets of information ) are known to be “good , ” so that measures can be based on the count of such items ( e.g. , precision and</definiens>
			</definition>
			<definition id="1">
				<sentence>The CNS data consists of the January 2004 distribution of the Eye on Proliferation CD , which has been `` disaggregated '' by CNS into about 40,000 documents .</sentence>
				<definiendum id="0">CNS data</definiendum>
				<definiens id="0">consists of the January 2004 distribution of the Eye on Proliferation CD , which has been `` disaggregated '' by CNS into about 40,000 documents</definiens>
			</definition>
			<definition id="2">
				<sentence>The SmiFro Console contained links to the Status Questionnaires which were designed to solicit analysts’ opinions and feedback about the progress of their work during the session .</sentence>
				<definiendum id="0">SmiFro Console</definiendum>
				<definiens id="0">contained links to the Status Questionnaires which were designed to solicit analysts’ opinions and feedback about the progress of their work during the session</definiens>
			</definition>
			<definition id="3">
				<sentence>The Glass Box uses a relational database to store time-stamped events and a hierarchical file store where files and the content of web pages are stored .</sentence>
				<definiendum id="0">Glass Box</definiendum>
				<definiens id="0">uses a relational database to store time-stamped events and a hierarchical file store where files and the content of web pages are stored</definiens>
			</definition>
</paper>

		<paper id="3328">
			<definition id="0">
				<sentence>Named entity recognition ( NER ) is one of the most important tasks in information extraction .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">one of the most important tasks in information extraction</definiens>
			</definition>
			<definition id="1">
				<sentence>Therefore we would expect that , even though the material used for the annotation is not drawn from the exact domain of our test data ( FlyBase curated abstracts ) , it would still be useful to train a system to identify gene names .</sentence>
				<definiendum id="0">FlyBase curated abstracts</definiendum>
				<definiens id="0">useful to train a system to identify gene names</definiens>
			</definition>
			<definition id="2">
				<sentence>4http : //www.alias-i.com/lingpipe/ 140 The standard evaluation metric used for NER is the F-score ( Van Rijsbergen , 1979 ) , which is the harmonic average of Recall and Precision .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">the harmonic average of Recall and Precision</definiens>
			</definition>
</paper>

		<paper id="2602">
			<definition id="0">
				<sentence>The name memory-based learning refers to a class of methods based on the k-nearest neighbour rule .</sentence>
				<definiendum id="0">memory-based learning</definiendum>
				<definiens id="0">a class of methods based on the k-nearest neighbour rule</definiens>
			</definition>
			<definition id="1">
				<sentence>The function Ns , w , k ( x ) maps a given instance x to the set of its nearest neighbours ; here , the parameters s , w , and k are the similarity metric , the feature weights , and the number k of nearest neighbours , respectively .</sentence>
				<definiendum id="0">function Ns</definiendum>
				<definiens id="0">the parameters s , w , and k are the similarity metric , the feature weights , and the number k of nearest neighbours , respectively</definiens>
			</definition>
			<definition id="2">
				<sentence>The function wd ( c , N ( x ) ) returns the weight assigned to class c in the given neighbourhood according to the distance metric d ; again we will use the notation w ( c , N ( x ) ) to refer to a specific instantiation ofthisfunction .</sentence>
				<definiendum id="0">function wd</definiendum>
				<definiendum id="1">N ( x ) )</definiendum>
				<definiens id="0">returns the weight assigned to class c in the given neighbourhood according to the distance metric d</definiens>
			</definition>
			<definition id="3">
				<sentence>Here , X = { x1 , x2 , ... , xn } is a finite set of variables .</sentence>
				<definiendum id="0">x2 , ... , xn }</definiendum>
				<definiens id="0">a finite set of variables</definiens>
			</definition>
			<definition id="4">
				<sentence>D ( x ) is a function that maps each variable to its domain , that is , the set of values that variable can take on .</sentence>
				<definiendum id="0">D ( x )</definiendum>
				<definiens id="0">a function that maps each variable to its domain</definiens>
			</definition>
			<definition id="5">
				<sentence>C is the set of constraints .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the set of constraints</definiens>
			</definition>
			<definition id="6">
				<sentence>Let a constraint c ∈ C be defined as a function that maps each variable assignment to 1 if the constraint is satisfied , or to 0 if it is not .</sentence>
				<definiendum id="0">constraint c ∈ C</definiendum>
				<definiens id="0">a function that maps each variable assignment to 1 if the constraint is satisfied , or to 0 if it is not</definiens>
			</definition>
			<definition id="7">
				<sentence>x∗ = argmax x summationdisplay c W ( c ) c ( x ) That is , the assignment of values to its variables that maximises the sum of weights of the constraints that have been satisfied .</sentence>
				<definiendum id="0">argmax x summationdisplay c W ( c ) c ( x</definiendum>
				<definiens id="0">the assignment of values to its variables that maximises the sum of weights of the constraints that have been satisfied</definiens>
			</definition>
			<definition id="8">
				<sentence>• for a trigram constraint , the weight is simply the base classifier’s confidence value for the class c∗ • for a bigram constraint , the weight is the sum of the confidences for all trigram classes in the nearest-neighbour set of x that assign the same label bigram to the tokens spanned by the constraint • for a unigram constraint , the weight is the sum of the confidences for all trigram classes in the nearest-neighbour set of x that assign the same label to the token spanned by the constraint To thoroughly evaluate our new inference procedure , and to show that it performs well over a wide range of natural-language sequence labelling tasks , we composed a benchmark set consisting of six different tasks , covering four areas in natural language processing : syntax ( syntactic chunking ) , morphology ( morphological analysis ) , phonology ( grapheme-to-phoneme conversion ) , and information extraction ( general , medical , and biomedical named-entity recognition ) .</sentence>
				<definiendum id="0">weight</definiendum>
				<definiens id="0">the sum of the confidences for all trigram classes in the nearest-neighbour set of x that assign the same label</definiens>
				<definiens id="1">the sum of the confidences for all trigram classes in the nearest-neighbour set of x that assign the same label to the token spanned by the constraint To thoroughly evaluate our new inference procedure , and to show that it performs well over a wide range of natural-language sequence labelling tasks</definiens>
				<definiens id="2">benchmark set consisting of six different tasks , covering four areas in natural language processing : syntax ( syntactic chunking ) , morphology ( morphological analysis ) , phonology ( grapheme-to-phoneme conversion ) , and information extraction ( general , medical , and biomedical named-entity recognition )</definiens>
			</definition>
			<definition id="9">
				<sentence>The GENIA corpus ( Tateisi et al. , 2002 ) is a collection of annotated abstracts taken from the National Library of Medicine’s MEDLINE database .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">a collection of annotated abstracts taken from the National Library of Medicine’s MEDLINE database</definiens>
			</definition>
			<definition id="10">
				<sentence>Performance is measured by the F-score on correctly identified and labelled chunks , or named entities .</sentence>
				<definiendum id="0">Performance</definiendum>
				<definiens id="0">measured by the F-score on correctly identified and labelled chunks , or named entities</definiens>
			</definition>
			<definition id="11">
				<sentence>On the other extreme , if all three candidate labels disagree for all tokens in the sequence , the inference procedure’s task is to select the best sequence among 3n possible sequences , where n denotes the length of the sequence ; it is likely that such a huge amount of candidate label sequences can not be dealt with appropriately .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the length of the sequence</definiens>
			</definition>
</paper>

		<paper id="1322">
			<definition id="0">
				<sentence>Natural language is the most intuitive way to communicate for human beings ( Allen et al. , 2001 ) .</sentence>
				<definiendum id="0">Natural language</definiendum>
			</definition>
			<definition id="1">
				<sentence>Since semantic representation is created out of communicative intentions ( Levelt , 1989 ) we assume the communication intentions are the modality independent base that governs the multi-modal language production .</sentence>
				<definiendum id="0">communication intentions</definiendum>
				<definiens id="0">the modality independent base that governs the multi-modal language production</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , Iverson et al. ( 1999 ) identified three types of informational relationship -ConversationLayerverbalgeneratornon-verbalgenerator intentionconception -IntentionLayerFigure 3 : IU between speech and gesture : reinforcement ( gesture reinforces the message conveyed in speech , e.g. , emphatic gesture ) , disambiguation ( gesture serves as the precise referent of the speech , e.g. , deictic gesture accompanying the utterance “this cup” ) , and adding-information ( e.g. , saying “The ball is so big.”</sentence>
				<definiendum id="0">gesture</definiendum>
				<definiens id="0">reinforces the message conveyed in speech , e.g. , emphatic gesture ) , disambiguation ( gesture serves as the precise referent of the speech , e.g. , deictic gesture accompanying the utterance “this cup” ) , and adding-information</definiens>
			</definition>
			<definition id="3">
				<sentence>The Robot Control Manager receives messages from the robot control system and calls the Dialog Manager to do relevant operations .</sentence>
				<definiendum id="0">Robot Control Manager</definiendum>
				<definiens id="0">receives messages from the robot control system and calls the Dialog Manager to do relevant operations</definiens>
			</definition>
			<definition id="4">
				<sentence>BIRON needs to associate its symbolic name ( and eventually other features ) mentioned by the user with the image of the object .</sentence>
				<definiendum id="0">BIRON</definiendum>
			</definition>
			<definition id="5">
				<sentence>After the Dialog Manager receives this ID , the processing of the conversation layer of the user IU ends , the Dialog Manager proceeds to create its own IU to react to the user’s IU .</sentence>
				<definiendum id="0">Dialog Manager</definiendum>
			</definition>
			<definition id="6">
				<sentence>A robot system is usually a complex system including a 159 large number of modules that claim plenty of processing time or are subject to environmental conditions .</sentence>
				<definiendum id="0">robot system</definiendum>
				<definiens id="0">claim plenty of processing time or are subject to environmental conditions</definiens>
			</definition>
</paper>

		<paper id="2304">
			<definition id="0">
				<sentence>PG makes it possible to represent syntactic information in a decentralized way and at different levels .</sentence>
				<definiendum id="0">PG</definiendum>
				<definiens id="0">makes it possible to represent syntactic information in a decentralized way and at different levels</definiens>
			</definition>
			<definition id="1">
				<sentence>The different categories to be built are : GA ( adjective group : adjective or passed participle ) , GN ( nominal group : determiner , noun adjective and its modifiers ) , GP ( prepositional group ) , GR ( adverb ) , NV ( verbal nucleus : verb , clitics ) and PV ( verbal propositional group ) .</sentence>
				<definiendum id="0">PV</definiendum>
				<definiens id="0">adjective or passed participle ) , GN ( nominal group : determiner , noun adjective and its modifiers ) , GP ( prepositional group )</definiens>
			</definition>
</paper>

		<paper id="3812">
			<definition id="0">
				<sentence>Clustering is the process of grouping together objects based on their similarity to each other .</sentence>
				<definiendum id="0">Clustering</definiendum>
			</definition>
			<definition id="1">
				<sentence>A graph represents objects ( as nodes ) and their relations ( as edges ) .</sentence>
				<definiendum id="0">graph</definiendum>
				<definiens id="0">represents objects ( as nodes ) and their relations ( as edges )</definiens>
			</definition>
			<definition id="2">
				<sentence>The degree of a node is the number of edges a node takes part in .</sentence>
				<definiendum id="0">degree of a node</definiendum>
				<definiens id="0">the number of edges a node takes part in</definiens>
			</definition>
			<definition id="3">
				<sentence>The neighborhood of a node v is defined by the set of all nodes v’ such that ( v , v’ , w ) ∈E or ( v’ , v , w ) ∈E ; it consists of all nodes that are connected to v. The adjacency matrix AG of a graph G with n nodes is an n×n matrix where the entry aij denotes the weight of the edge between vi and vj , 0 otherwise .</sentence>
				<definiendum id="0">neighborhood of a node v</definiendum>
				<definiens id="0">the set of all nodes v’ such that ( v , v’ , w ) ∈E or ( v’ , v , w ) ∈E ; it consists of all nodes that are connected to v. The adjacency matrix AG of a graph G with n nodes is an n×n matrix where the entry aij denotes the weight of the edge between vi and vj , 0 otherwise</definiens>
			</definition>
			<definition id="4">
				<sentence>The class matrix DG of a Graph G with n nodes is an n×n matrix where rows represent nodes and columns represent classes ( ci ) ∈C. The value dij at row i and column j represents the amount of vi as belonging to a class cj .</sentence>
				<definiendum id="0">class matrix DG</definiendum>
				<definiens id="0">an n×n matrix where rows represent nodes and columns represent classes ( ci ) ∈C. The value dij at row i and column j represents the amount of vi as belonging to a class cj</definiens>
			</definition>
			<definition id="5">
				<sentence>For convention , class matrices are row-normalized ; the i-th row denotes a distribution of vi over C. If all rows have exactly one non-zero entry with value 1 , DG denotes a hard partitioning of V , soft partitioning otherwise .</sentence>
				<definiendum id="0">DG</definiendum>
				<definiens id="0">a hard partitioning of V , soft partitioning otherwise</definiens>
			</definition>
			<definition id="6">
				<sentence>The expansion step is a matrix multiplication of MG with the current transition matrix .</sentence>
				<definiendum id="0">expansion step</definiendum>
				<definiens id="0">a matrix multiplication of MG with the current transition matrix</definiens>
			</definition>
			<definition id="7">
				<sentence>As we operate on unweighted graphs , however , CW is left with two choices : producing two clusters or grouping all nodes into one cluster .</sentence>
				<definiendum id="0">CW</definiendum>
				<definiens id="0">producing two clusters or grouping all nodes into one cluster</definiens>
			</definition>
			<definition id="8">
				<sentence>When generating SW-graphs with the SteyversTenenbaum model , we fixed M to 10 and varied n and the merge rate r , which is the fraction of nodes of the smaller graph that is merged with nodes of the larger graph .</sentence>
				<definiendum id="0">merge rate r</definiendum>
				<definiens id="0">the fraction of nodes of the smaller graph that is merged with nodes of the larger graph</definiens>
			</definition>
			<definition id="9">
				<sentence>The co-occurrence graph of a multilingual corpus resembles the synthetic SW-graphs : Every language forms a separate co-occurrence graph , some words that are used in more than one language are members of several graphs , connecting them .</sentence>
				<definiendum id="0">synthetic SW-graphs</definiendum>
				<definiens id="0">Every language forms a separate co-occurrence graph , some words that are used in more than one language are members of several graphs , connecting them</definiens>
			</definition>
			<definition id="10">
				<sentence>The weighted average of cluster purity ( i.e. the number of predominant tags divided by cluster size ) was measured at 88.8 % , which exceeds significantly the precision of 53 % on word type as reported by Schütze ( 1995 ) on a related task .</sentence>
				<definiendum id="0">weighted average of cluster purity</definiendum>
				<definiens id="0">the number of predominant tags divided by cluster size</definiens>
			</definition>
			<definition id="11">
				<sentence>The task of word sense induction ( WSI ) is to find the different senses of a word .</sentence>
				<definiendum id="0">WSI</definiendum>
				<definiens id="0">to find the different senses of a word</definiens>
			</definition>
			<definition id="12">
				<sentence>Bordag defines four measures : • retrieval precision ( rP ) : similarity of the found sense with the gold standard sense • retrieval recall ( rR ) : amount of words that have been correctly assigned to the gold standard sense • precision ( P ) : fraction of correctly found disambiguations • recall ( R ) : fraction of correctly found senses We used the same program to compute cooccurrences on the same corpus ( the BNC ) .</sentence>
				<definiendum id="0">retrieval precision</definiendum>
				<definiendum id="1">retrieval recall</definiendum>
				<definiendum id="2">precision</definiendum>
			</definition>
</paper>

		<paper id="2716">
			<definition id="0">
				<sentence>The ANC standoff format for annotations is a simple graph representation , consisting of one node set and one , or more , edge sets .</sentence>
				<definiendum id="0">ANC standoff format</definiendum>
				<definiens id="0">a simple graph representation , consisting of one node set and one , or more , edge sets</definiens>
			</definition>
			<definition id="1">
				<sentence>The ANC Tol provides a graphical user interface for the XCES parser and is used to convert ANC documents to other formats .</sentence>
				<definiendum id="0">ANC Tol</definiendum>
				<definiens id="0">provides a graphical user interface for the XCES parser and is used to convert ANC documents to other formats</definiens>
			</definition>
			<definition id="2">
				<sentence>Currently , the ANC Tol can be used to generate the folowing output formats : • XML XCES format , suitable for use with the BNC’s XAIRA 12 search and access interface ; • Text with part of speech tags appended to each word and separated by an underscore ; • WordSmith/MonoConc Pro format .</sentence>
				<definiendum id="0">ANC Tol</definiendum>
				<definiens id="0">• XML XCES format , suitable for use with the BNC’s XAIRA 12 search and access interface ; • Text with part of speech tags appended to each word</definiens>
			</definition>
</paper>

		<paper id="3705">
			<definition id="0">
				<sentence>The doctor–patient consultation is a central element of the “pathway to healthcare” , and with language problems recognised as the single most significant barrier on this pathway , spoken-language translation ( SLT ) of doctor–patient dialogues is an obvious and timely and attractive application of language technology .</sentence>
				<definiendum id="0">doctor–patient consultation</definiendum>
				<definiendum id="1">SLT</definiendum>
				<definiens id="0">an obvious and timely and attractive application of language technology</definiens>
			</definition>
			<definition id="1">
				<sentence>Systems that have been developed so far can be divided into those for use in the doctors office – notably , MedSLT ( Rayner and Bouillon , 2002 ) , CCLINC ( Lee et al. , 2002 ) , and ( honourable mention ) the early work done at CMU ( Tomita et al. , 1988 ) 1 – and those for use for first contact with medical professionals “in the field” , developed under DARPA’s CAST programme:2 MASTOR ( Zhou et al. , 2004 ) , Speechalator ( Waibel et al. , 2003 ) , Transonics ( Narayanan et al. , 2004 ) and SRI’s system ( Precoda et al. , 2004 ) .</sentence>
				<definiendum id="0">MedSLT</definiendum>
				<definiendum id="1">Speechalator</definiendum>
			</definition>
			<definition id="2">
				<sentence>Appointment scheduling is the classical application of SLT , as seen in most of the early work in the field , and is a typical case of a task-oriented cooperative dialogue .</sentence>
				<definiendum id="0">Appointment scheduling</definiendum>
				<definiens id="0">the classical application of SLT , as seen in most of the early work in the field</definiens>
			</definition>
</paper>

		<paper id="0120">
			<definition id="0">
				<sentence>A linear-chain CRF with parameters Λ= { λ 1 , λ 2 , … } defines a conditional probability for a state sequence y = y 1 …y T , given that an input sequence x = x 1 …x T is ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ = ∑∑ = −Λ T tk ttkk tyyf Z P 1 1 ) , , , ( exp 1 ) | ( xxy x λ , ( 1 ) where Z x is the normalization factor that makes the probability of all state sequences sum to one ; f k ( y t-1 , y t , x , t ) is often a binary-valued feature function and λ k is its weight .</sentence>
				<definiendum id="0">linear-chain CRF</definiendum>
				<definiendum id="1">Z x</definiendum>
				<definiendum id="2">f k</definiendum>
				<definiens id="0">the normalization factor that makes the probability of all state sequences sum to one</definiens>
				<definiens id="1">often a binary-valued feature function and λ k is its weight</definiens>
			</definition>
			<definition id="1">
				<sentence>For each character c i , we use v j to represent its j-dimension value , which is calculated as follows : r jiijj ffv ) ] , ) [ min ( 1 ( αα −+= ’ ( 2 ) , where f ij denotes the frequency with which c i and c j appear in the same word when c i ’s position precedes that of c j .</sentence>
				<definiendum id="0">f ij</definiendum>
				<definiens id="0">the frequency with which c i and c j appear in the same word when c i ’s position precedes that of c j</definiens>
			</definition>
			<definition id="2">
				<sentence>Our K-means algorithm uses the cosine distance .</sentence>
				<definiendum id="0">K-means algorithm</definiendum>
				<definiens id="0">uses the cosine distance</definiens>
			</definition>
			<definition id="3">
				<sentence>We calculate v j as follows : r jijiijijj ffffv ) ] ' , , ' , ) [ min ( 1 ( ' αα −+= , ( 5 ) where ij f stands for the frequency with which c i and c j appear in the same word when c i is the first character ; and f’ ij stands for the frequency with which c i and c j co-occur in the same word when c i precedes c j but not in the first position .</sentence>
				<definiendum id="0">ij f</definiendum>
				<definiens id="0">the frequency with which c i and c j co-occur in the same word when c i precedes c j but not in the first position</definiens>
			</definition>
</paper>

		<paper id="1306">
			<definition id="0">
				<sentence>Formally , a dialogue act in DIT consists of a Semantic Content and a Communicative Function , the latter specifying how the information state of the addressee is to be updated with the former .</sentence>
				<definiendum id="0">dialogue act in DIT</definiendum>
				<definiens id="0">consists of a Semantic Content and a Communicative Function , the latter specifying how the information state of the addressee is to be updated with the former</definiens>
			</definition>
			<definition id="1">
				<sentence>The Information State according to DIT is represented by a Context Model , containing all information considered relevant for interpreting user utterances ( in terms of dialogue acts ) and generating system dialogue acts ( leading to system utterances ) .</sentence>
				<definiendum id="0">Information State</definiendum>
				<definiens id="0">containing all information considered relevant for interpreting user utterances</definiens>
			</definition>
			<definition id="2">
				<sentence>Finally , there are two features that 39                    LingContext :      user utts : 〈last user dial act = uda0 , uda−1 , uda−2 , . . .〉 system utts : 〈last system dial act = sda0 , sda−1 , sda−2 , . . .〉 topic struct : 〈referents〉 conv state : opening|body|closing candidate dial acts : . . . dial acts pres : . . .      SemContext :    task progress : comp quest|quest qa|answ eval|user sat user info needs : 〈. . . , bracketleftbiggquestion : . . . satisfied : +|− bracketrightbigg , . . .〉 qa answers : 〈. . .〉    CogContext : bracketleftbiggown proc state : [ proc problem : perc|int|eval|exec|none ] partner proc state : [ proc problem : perc|int|eval|exec|none ] bracketrightbigg PhysPercContext : bracketleftbig bracketrightbig SocContext : bracketleftbiggreactive pressures : none|grt|apo|thk|valed interactive pressures : none|grt|apo|thk|valed bracketrightbigg                    Figure 1 : Feature structure representation of the PARADIME context model .</sentence>
				<definiendum id="0">bracketleftbiggown proc state</definiendum>
				<definiens id="0">39                    LingContext :      user utts : 〈last user dial act = uda0 , uda−1 , uda−2 , . . .〉 system utts : 〈last system dial act</definiens>
				<definiens id="1">perc|int|eval|exec|none ] bracketrightbigg PhysPercContext : bracketleftbig bracketrightbig SocContext : bracketleftbiggreactive pressures : none|grt|apo|thk|valed interactive pressures : none|grt|apo|thk|valed bracketrightbigg                  </definiens>
			</definition>
			<definition id="3">
				<sentence>The Cognitive Context is specified by means of two features , representing the processing states of the system ( own proc state ) and the user ( partner proc state ) .</sentence>
				<definiendum id="0">Cognitive Context</definiendum>
				<definiens id="0">specified by means of two features , representing the processing states of the system ( own proc state</definiens>
			</definition>
			<definition id="4">
				<sentence>Hence the dialogue management process involves 11 dialogue act agents that operate in parallel on the context model .</sentence>
				<definiendum id="0">dialogue management process</definiendum>
				<definiens id="0">involves 11 dialogue act agents that operate in parallel on the context model</definiens>
			</definition>
			<definition id="5">
				<sentence>GP AUF IM-SOM YN-Question PosAutoFb Init-Open WH-Question NegAutoFb-Int Init-Close H-Question NegAutoFb-Eval Request Instruct Table 1 : Dialogue act types for interpreting user utterances .</sentence>
				<definiendum id="0">GP AUF IM-SOM YN-Question PosAutoFb Init-Open WH-Question NegAutoFb-Int Init-Close H-Question NegAutoFb-Eval Request</definiendum>
				<definiens id="0">Dialogue act types for interpreting user utterances</definiens>
			</definition>
			<definition id="6">
				<sentence>The ISA metaphor is reflected in the system behaviour especially in the way in which QA results are presented to the user .</sentence>
				<definiendum id="0">ISA metaphor</definiendum>
				<definiens id="0">reflected in the system behaviour especially in the way in which QA results are presented to the user</definiens>
			</definition>
</paper>

		<paper id="1524">
			<definition id="0">
				<sentence>The observed displacement effect is a result of the extension of the like-headed tree after the adjunction of an auxiliary tree headed by seem ( Kroch and Joshi , 1985 ) .</sentence>
				<definiendum id="0">displacement effect</definiendum>
			</definition>
</paper>

		<paper id="0126">
			<definition id="0">
				<sentence>Let F f 1 is probability of the C 1 , iM f is the probability of the i C , nE f is the probability of the C n .</sentence>
				<definiendum id="0">nE f</definiendum>
				<definiens id="0">the probability of the C n</definiens>
			</definition>
			<definition id="1">
				<sentence>( 1 ) BCD : the Chinese personal name is composed of three Hanzi ( ( Chinese character ) .</sentence>
				<definiendum id="0">BCD</definiendum>
			</definition>
</paper>

		<paper id="0138">
			<definition id="0">
				<sentence>Our official F-scores on the 2006 Bakeoff open tracks are 0.935 ( UPUC ) , 0.964 ( CityU ) , Given an observed Chinese character sequence X = { C1 , C2 , ... , Cn } , let S and T denote a segmentation sequence and a POS tagging sequence over X. Our goal is to find a segmentation sequence ˆS and a POS tagging sequence ˆT that maximize the posterior probability : P ( S , T|X = { C1 , C2 , ... , Cn } ) ( 1 ) Applying chain rule , we can further derive from Equation 1 the following : &lt; ˆS , ˆT &gt; = argmax S , T P ( T|S , X = { C1 , C2 , ... , Cn } ) ×P ( S|X = { C1 , C2 , ... , Cn } ) ( 2 ) Since we have factorized the joint probability in Equation 1 into two terms , we can now model these two components using conditional random fields ( Lafferty et al. , 2001 ) .</sentence>
				<definiendum id="0">CityU</definiendum>
			</definition>
			<definition id="1">
				<sentence>In our case , X is the sequence of characters or words , and Z is the segmentation labels for characters ( START or NON-START , used to indicate word boundaries ) or the POS tagging for words ( NN , VV , JJ , etc. ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Z</definiendum>
				<definiens id="0">the sequence of characters or words , and</definiens>
				<definiens id="1">the segmentation labels for characters ( START or NON-START , used to indicate word boundaries ) or the POS tagging for words</definiens>
			</definition>
			<definition id="2">
				<sentence>The conditional probability is defined as : P ( Z|X ) = 1N ( X ) exp ( Tsummationdisplay t=1 Ksummationdisplay k=1 λkfk ( Z , X , t ) ) ( 3 ) where N ( X ) is a normalization term to guarantee that the summation of the probability of all label sequences is one .</sentence>
				<definiendum id="0">conditional probability</definiendum>
				<definiendum id="1">N ( X )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Instead of exhaustively searching the whole space of all possible segmentations , we restrict our searching to S = { S1 , S2 , ... , SN } , where S is the restricted search space consisting of N-best decoded segmentation sequences .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">the restricted search space consisting of N-best decoded segmentation sequences</definiens>
			</definition>
			<definition id="4">
				<sentence>T ( Cn ) classifies the character Cn into four classes : numbers , dates ( year , month , date ) , English letters and all other characters .</sentence>
				<definiendum id="0">T ( Cn )</definiendum>
				<definiens id="0">classifies the character Cn into four classes : numbers , dates ( year , month , date ) , English letters and all other characters</definiens>
			</definition>
			<definition id="5">
				<sentence>LBegin ( C0 ) , LEnd ( C0 ) and LMid ( C0 ) represent the maximum length of words found in a lexicon1 that contain the current character as either the first , last or middle character , respectively .</sentence>
				<definiendum id="0">LBegin</definiendum>
				<definiendum id="1">LEnd</definiendum>
				<definiens id="0">the maximum length of words found in a lexicon1 that contain the current character as either the first , last or middle character , respectively</definiens>
			</definition>
			<definition id="6">
				<sentence>Single ( C0 ) indicates whether the current character can be found as a single word in the lexicon .</sentence>
				<definiendum id="0">Single</definiendum>
				<definiens id="0">the current character can be found as a single word in the lexicon</definiens>
			</definition>
			<definition id="7">
				<sentence>For ( 1.8 ) , Sem0 refers to the semantic class of current character , and Sem−1 , Sem1 represent the semantic class of characters one position to the left and right of the current character , respectively .</sentence>
				<definiendum id="0">Sem0</definiendum>
				<definiens id="0">the semantic class of current character , and Sem−1 , Sem1 represent the semantic class of characters one position to the left and right of the current character , respectively</definiens>
			</definition>
			<definition id="8">
				<sentence>W0 denotes the current word .</sentence>
				<definiendum id="0">W0</definiendum>
				<definiens id="0">the current word</definiens>
			</definition>
			<definition id="9">
				<sentence>Cn ( W0 ) is the nth character in current word .</sentence>
				<definiendum id="0">Cn</definiendum>
				<definiens id="0">the nth character in current word</definiens>
			</definition>
			<definition id="10">
				<sentence>Len ( W0 ) is the number of characters in the current word .</sentence>
				<definiendum id="0">Len</definiendum>
				<definiens id="0">the number of characters in the current word</definiens>
			</definition>
</paper>

		<paper id="3316">
			<definition id="0">
				<sentence>The lexical information consists of the words themselves .</sentence>
				<definiendum id="0">lexical information</definiendum>
				<definiens id="0">consists of the words themselves</definiens>
			</definition>
			<definition id="1">
				<sentence>The syntactic information consists of noun phrase boundaries and the distinction between head and premodifiers ( extracted from RASP output ) .</sentence>
				<definiendum id="0">syntactic information</definiendum>
				<definiens id="0">consists of noun phrase boundaries and the distinction between head and premodifiers ( extracted from RASP output )</definiens>
			</definition>
			<definition id="2">
				<sentence>The Sequence Ontology ( SO ) can be used to identify words and phrases related to a gene : its subtypes ( e.g. oncogene , transposable element ) , parts ( e.g. transcript , regulatory region ) and products ( e.g. polypeptide , protein ) .</sentence>
				<definiendum id="0">Sequence Ontology</definiendum>
				<definiens id="0">transposable element ) , parts ( e.g. transcript , regulatory region ) and products</definiens>
			</definition>
			<definition id="3">
				<sentence>RASP is a pipelined parser which identifies sentence boundaries , tokenises sentences , tags the tokens with their part-of-speech ( PoS ) and finally parses PoS tag sequences , statistically ranking the resulting derivations .</sentence>
				<definiendum id="0">RASP</definiendum>
				<definiens id="0">a pipelined parser which identifies sentence boundaries , tokenises sentences , tags the tokens with their part-of-speech ( PoS ) and finally parses PoS tag sequences</definiens>
			</definition>
			<definition id="4">
				<sentence>For linking anaphors to their antecedents we look at : • headan : anaphor head noun • heada : antecedent head noun • modan : set of anaphor pre-modifiers • moda : set of antecedent pre-modifiers • biotypean : anaphor biotype • biotypea : antecedent biotype • d : distance in sentences from the anaphor The pseudo-code to find the antecedent for the DDs and PNs is given below : • Input : a set A with all the anaphoric expressions ( DDs and PNs ) ; a set C with all the possible antecedents ( all NPs with biotype information ) • For each anaphoric expression Ai : – Let antecedent 1 be the closest preceding NP Cj such that head ( Cj ) =head ( Ai ) and biotype ( Cj ) =biotype ( Ai ) 99 – Let antecedent 2 be the closest preceding NP Cj such that biotype ( Cj ) negationslash=biotype ( Ai ) , but head ( Cj ) =head ( Ai ) or head ( Cj ) =mod ( Ai ) or mod ( Cj ) =head ( Ai ) or mod ( Cj ) =mod ( Ai ) – Take the closest candidate as antecedent , if 1 and/or 2 are found ; if none is found , the DD/PN is treated as non-anaphoric • Output : The resolved anaphoric expressions in A linked to their antecedents .</sentence>
				<definiendum id="0">PNs</definiendum>
			</definition>
			<definition id="5">
				<sentence>When the NER system fails to recognise a gene name , it can decrease the parser performance ( as it would have to deal with an unknown word ) and influences the semantic tagging ( the NP containing such a gene name won’t be selected as a possible antecedent or anaphor unless it contains another word that is part of SO ) .</sentence>
				<definiendum id="0">semantic tagging</definiendum>
			</definition>
</paper>

		<paper id="0104">
</paper>

		<paper id="0136">
			<definition id="0">
				<sentence>( a ) trigram : A i B j C ( b ) bigram : i A j B k ( c ) unigram : i A j In the above features , AB and ABC are a Chinese character sequence of bigram and trigram , respectively .</sentence>
				<definiendum id="0">AB</definiendum>
				<definiendum id="1">ABC</definiendum>
				<definiens id="0">A i B j C ( b ) bigram : i A j B k ( c ) unigram : i A j In the above features</definiens>
			</definition>
</paper>

		<paper id="1624">
			<definition id="0">
				<sentence>Spoken Language Understanding ( SLU ) is one of the key components in spoken dialogue systems .</sentence>
				<definiendum id="0">SLU</definiendum>
				<definiens id="0">one of the key components in spoken dialogue systems</definiens>
			</definition>
			<definition id="1">
				<sentence>Also , a spoken language corpus was collected through the deployment of a preliminary version of telephone-based dialog system , of which the speech recognizer is based on the speaker-independent Chinese dictation system of IBM ViaVoice Telephony and the SLU component is a robust rule-based parser .</sentence>
				<definiendum id="0">SLU component</definiendum>
				<definiens id="0">a robust rule-based parser</definiens>
			</definition>
</paper>

		<paper id="1614">
			<definition id="0">
				<sentence>The positions of the verbal elements form the Satzklammer ( sentence bracket ) which divides the sentence into a Vorfeld ( initial field ) , a Mittelfeld ( middle field ) , and a Nachfeld ( final field ) .</sentence>
				<definiendum id="0">Mittelfeld</definiendum>
				<definiendum id="1">Nachfeld</definiendum>
				<definiens id="0">The positions of the verbal elements form the Satzklammer ( sentence bracket ) which divides the sentence into a Vorfeld ( initial field ) , a</definiens>
			</definition>
			<definition id="1">
				<sentence>The rechte Satzklammer ( right sentence bracket ) is realized by the verb complex and consists of verbal particles or sequences of verbs .</sentence>
				<definiendum id="0">rechte Satzklammer</definiendum>
			</definition>
			<definition id="2">
				<sentence>The left sentence bracket ( LK ) in ( 2c ) is realized by a complementizer field ( CF ) and the right sentence bracket ( RK ) by a verbal complex ( VC ) that contains the finite verb wird .</sentence>
				<definiendum id="0">LK</definiendum>
				<definiens id="0">realized by a complementizer field ( CF ) and the right sentence bracket ( RK ) by a verbal complex ( VC ) that contains the finite verb wird</definiens>
			</definition>
			<definition id="3">
				<sentence>Negra has an average of 1.4 clause nodes per sentence , T¨uBa-D/Z Both treebanks use an annotation framework that is based on phrase structure grammar and that is enhanced by a level of predicate-argument structure .</sentence>
				<definiendum id="0">Negra</definiendum>
				<definiens id="0">has an average of 1.4 clause nodes per sentence , T¨uBa-D/Z Both treebanks use an annotation framework that is based on phrase structure grammar</definiens>
			</definition>
			<definition id="4">
				<sentence>Apart from commonly accepted grammatical functions , such as SB ( subject ) or OA ( accusative object ) , Negra grammatical functions comprise a more extended notion , e.g. RE ( repeated element ) or RC ( relative clause ) .</sentence>
				<definiendum id="0">OA</definiendum>
				<definiendum id="1">RC</definiendum>
				<definiens id="0">accusative object ) , Negra grammatical functions comprise a more extended notion , e.g. RE ( repeated element</definiens>
			</definition>
			<definition id="5">
				<sentence>phrasal category that serves to structure the sentence as a whole is the verb phrase ( VP ) .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">serves to structure the sentence as a whole is the verb phrase</definiens>
			</definition>
			<definition id="6">
				<sentence>− HD HD HD HD − HD HD − NX HD VXFIN HD NX ON ADVX MOD NX OA VXINF OV PX OA−MOD VF − LK − MF − VC − SIMPX Figure 4 : T¨uBa-D/Z annotation without crossing branches .</sentence>
				<definiendum id="0">HD HD HD HD − HD HD − NX HD VXFIN HD NX ON ADVX MOD NX OA VXINF OV</definiendum>
				<definiens id="0">T¨uBa-D/Z annotation without crossing branches</definiens>
			</definition>
			<definition id="7">
				<sentence>Notice also that compared to the Negra annotation , T¨uBa-D/Z introduces more internal structure into NPs and PPs .</sentence>
				<definiendum id="0">T¨uBa-D/Z</definiendum>
				<definiens id="0">introduces more internal structure into NPs and PPs</definiens>
			</definition>
			<definition id="8">
				<sentence>Its functional label ( OA-MOD ) provides the information that it modifies the accusative object ( OA ) keinen Nachweis .</sentence>
				<definiendum id="0">functional label</definiendum>
				<definiens id="0">the information that it modifies the accusative object ( OA ) keinen Nachweis</definiens>
			</definition>
			<definition id="9">
				<sentence>By contrast , T¨uBa-D/Z uses topological fields as the primary structuring principle , which leads to a purely context-free annotation of discontinuous structures .</sentence>
				<definiendum id="0">T¨uBa-D/Z</definiendum>
				<definiens id="0">uses topological fields as the primary structuring principle , which leads to a purely context-free annotation of discontinuous structures</definiens>
			</definition>
</paper>

		<paper id="2104">
			<definition id="0">
				<sentence>24 Optimality Theory is a model of the system of the linguistic knowledge a speaker of a language has ( cf. Prince and Smolensky 1993 ) .</sentence>
				<definiendum id="0">Optimality Theory</definiendum>
			</definition>
			<definition id="1">
				<sentence>Bidirectional OT gives a general procedure of optimization of the relation of form and meaning , simultaneously optimizing in both directions , from meaning to form , and from form to meaning .</sentence>
				<definiendum id="0">Bidirectional OT</definiendum>
				<definiens id="0">gives a general procedure of optimization of the relation of form and meaning</definiens>
			</definition>
			<definition id="2">
				<sentence>Optimality theory : Constraint Interaction in Generative Grammar .</sentence>
				<definiendum id="0">Optimality theory</definiendum>
			</definition>
</paper>

		<paper id="3307">
			<definition id="0">
				<sentence>Information Extraction ( IE ) is a natural language processing task in which text documents are analyzed with the aim of finding mentions of relevant entities and important relationships between them .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
			</definition>
			<definition id="1">
				<sentence>Thus , if C6 is the total number of abstracts , D2 of which cite the first protein , D1 cite the second protein , and CZ cite both , then the probability of co-citation under a random model is : C8B4CZCYC6BND1BND2B5 BP AI D2 CZ AJAI C6 A0D2 D1A0CZ AJ AI C6 D1 AJ ( 1 ) The approach that we take in this paper is to constrain the two proteins to be mentioned in the same sentence , based on the assumption that if there is a reason for two protein names to co-occur in the same sentence , then in most cases that is caused by their interaction .</sentence>
				<definiendum id="0">CZ AJAI C6 A0D2 D1A0CZ AJ AI C6 D1 AJ</definiendum>
				<definiens id="0">the total number of abstracts , D2 of which cite the first protein , D1 cite the second protein , and CZ cite both , then the probability of co-citation under a random model is : C8B4CZCYC6BND1BND2B5 BP AI D2</definiens>
				<definiens id="1">to constrain the two proteins to be mentioned in the same sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>D7C8C5C1B4D4 BD BND4 BE B5 BP D2 BDBE D2 BD A1 D2 BE ( 3 ) The D7C8C5C1B4D4 BD BND4 BE B5 formula can be rewritten as : D7C8C5C1B4D4 BD BND4 BE B5 BP BD D2 BD A1 D2 BE A1 D2 BDBE CG CXBPBD BD ( 4 ) Let D7 BD , D7 BE , ... , D7 D2 BDBE be the sentence contexts corresponding to the D2 BDBE co-occurrences of D4 BD and D4 BE , and assume that a sentence-level relation extractor is available , with the capability of computing normalized confidence values for all extractions .</sentence>
				<definiendum id="0">D7 BE , ... , D7 D2 BDBE</definiendum>
				<definiens id="0">D7C8C5C1B4D4 BD BND4 BE B5 BP BD D2 BD A1 D2 BE A1 D2 BDBE CG CXBPBD BD</definiens>
				<definiens id="1">the sentence contexts corresponding to the D2 BDBE co-occurrences of D4 BD and D4 BE , and assume that a sentence-level relation extractor is available , with the capability of computing normalized confidence values for all extractions</definiens>
			</definition>
			<definition id="3">
				<sentence>The KEGG ( Kanehisa et al. , 2004 ) and Gene Ontology ( Ashburner et al. , 2000 ) databases provide specific pathway and biological process annotations for approximately 7,500 human genes , assigning human genes into 155 KEGG pathways ( at the lowest level of KEGG ) and 1,356 GO pathways ( at level 8 of the GO biological process annotation ) .</sentence>
				<definiendum id="0">KEGG</definiendum>
				<definiendum id="1">Gene Ontology</definiendum>
				<definiens id="0">databases provide specific pathway and biological process annotations for approximately 7,500 human genes</definiens>
			</definition>
</paper>

		<paper id="1672">
			<definition id="0">
				<sentence>Our discriminative transliteration models have a number of parameters reflecting the length of strings chosen in either language as well as the relative distance between strings .</sentence>
				<definiendum id="0">discriminative transliteration models</definiendum>
				<definiens id="0">a number of parameters reflecting the length of strings chosen in either language as well as the relative distance between strings</definiens>
			</definition>
			<definition id="1">
				<sentence>Transliteration Results for Different Values of Relative Distance ( d ) .</sentence>
				<definiendum id="0">Transliteration Results</definiendum>
			</definition>
</paper>

		<paper id="2708">
			<definition id="0">
				<sentence>The NXT API supports multi-layered stand-off data annotation and synchronisation with timed and speech data .</sentence>
				<definiendum id="0">NXT API</definiendum>
			</definition>
			<definition id="1">
				<sentence>In our basic electricity and electronics domain , a tutorial session consists of a set of “teach” segments , and within each segment a number of “task” segments .</sentence>
				<definiendum id="0">tutorial session</definiendum>
			</definition>
			<definition id="2">
				<sentence>The NITE query language ( NQL ) enables us to access the data as a directed acyclic graph to correlate simple annotations , such as finding out the 58 Figure 1 : Utterance Segmentation Tool .</sentence>
				<definiendum id="0">NITE query language</definiendum>
				<definiendum id="1">NQL</definiendum>
				<definiens id="0">a directed acyclic graph to correlate simple annotations , such as finding out the 58 Figure 1 : Utterance Segmentation Tool</definiens>
			</definition>
</paper>

		<paper id="1648">
			<definition id="0">
				<sentence>Experimentation shows that character segment based correction is superior to single character correction and that language modeling boosts correction , by improving the ranking of candidate corrections , while shallow morphology had a small adverse effect .</sentence>
				<definiendum id="0">Experimentation</definiendum>
				<definiens id="0">shows that character segment based correction is superior to single character correction</definiens>
			</definition>
			<definition id="1">
				<sentence>The correction uses an improved character segment based noisy channel model , language modeling , and shallow morphological processing to correct OCR errors .</sentence>
				<definiendum id="0">correction</definiendum>
			</definition>
			<definition id="2">
				<sentence>The usual process is to automatically segment a document image into character images in the proper reading order using image analysis heuristics , apply an automatic classifier to determine the character codes that most likely correspond to each character image , and then exploit sequential context ( e.g. , preceding and following characters and a list of possible words ) to select the most likely character in each position .</sentence>
				<definiendum id="0">usual process</definiendum>
				<definiens id="0">to automatically segment a document image into character images in the proper reading order using image analysis heuristics , apply an automatic classifier to determine the character codes that most likely correspond to each character image</definiens>
			</definition>
			<definition id="3">
				<sentence>• Word N-Grams ( Language Modeling ) : A Word n-gram is a sequence of n consecutive words in text .</sentence>
				<definiendum id="0">Word N-Grams ( Language Modeling )</definiendum>
				<definiendum id="1">Word n-gram</definiendum>
				<definiens id="0">a sequence of n consecutive words in text</definiens>
			</definition>
			<definition id="4">
				<sentence>Given the output alignments of the algorithm , properly aligned characters ( such as a barb2right a and e barb2right e ) are used as anchors , ε’s ( null characters ) are combined to misaligned adjacent characters producing m : n alignments , and ε’s between correctly aligned characters are counted as deletions or insertions .</sentence>
				<definiendum id="0">ε’s</definiendum>
			</definition>
			<definition id="5">
				<sentence>P ( χ ) is the prior probability of observing χ in text and P ( δ|χ ) is the probability of producing δ from χ .</sentence>
				<definiendum id="0">P ( χ )</definiendum>
				<definiens id="0">the prior probability of observing χ in text and P ( δ|χ ) is the probability of producing δ from χ</definiens>
			</definition>
			<definition id="6">
				<sentence>The 1:1 and m : n character mapping models were tested while enabling or disabling character position training ( CP ) , smoothing by the assignment of small probabilities to unseen single character substitutions ( UP ) , language modeling ( LM ) , and shallow morphological processing ( SM ) using the 6-gram model .</sentence>
				<definiendum id="0">language modeling</definiendum>
				<definiens id="0">n character mapping models were tested while enabling or disabling character position training ( CP ) , smoothing by the assignment of small probabilities to unseen single character substitutions ( UP )</definiens>
			</definition>
</paper>

		<paper id="3710">
</paper>

		<paper id="1631">
			<definition id="0">
				<sentence>From the IR perspective , foreign words can be split into two AH DL AG ASC2 AA A9 EVGPDMAS AA FMC2 AA FV AH DLAS AA AG C2C2 AA A9 EUC2 AA DNGPFMC2 AA FV AH DL AG ASC2 AA A9 EU AH DNGPFMC2 AA FV AH DL AG ASC2 AA A9 EUC2 AA DNGPC2 AA FMFV AH DL AG ASC2 AA A9 EUC2 AA DMAS AA FMC2 AA FV AH DL AG ASC2 AA A9 EUC2 AA AH DNGPFMC2 AA FV AH DL AG ASC2 AA A9 EUDMAT AA GPFMC2 AA FV AH DL AG ASC2 AA A9 EUC2 AA DMFMC2 AA FV AH DL AG ASC2 AA A9 EUC2 AA AH DMAS AA FMFV AH DL AG ASC2 AA A9 EVGPDMFMC2 AA FV AH DL AG ASC2 AA A9 EVGPC2 AA DNGPFMC2 AA FV AH DL AG ASC2 AA A9 EU AH DMAS AA FMC2 AA FV AH DL AG ASC2 AA A9 EUC2 AA DNGPC2 AA FMC2 AA FV DL AG ASC2 AA A9 EUC2 AA DNGPFMC2 AA FV AH DL AG AS A9 EUC2 AA AH DMAS AA FMC2 AA FV AH DL AG ASC2 AA A9 EVGPDNGPC2 AA FMFV DL AG ASC2 AA A9 EVGPDNGPFMC2 AA FV AH DL AG ASC2 AA A9 EUC3 AA A9 C8GPFMC2 AA FV AH DL AG ASC2 AA A9 EUDNGPC2 AA FMFV DL AG ASC2 AA A9 EUC2 AA AH DNGPFMC2 AA FV AH DL AG ASC2 AA A9 EV A9 C8GPFMC2 AA FV AH DL AG ASC2 AA A9 EVGPDNGPFMC2 AA FV AH DLAS AA AG C2 A9 EUC2 AA DNGPFMC2 AA FV AH DL AG ASC2 AA A9 EUC2 AA DNGPFMC2 AA FV AH DLAS AA AG C2C2 AA A9 EUDNGPFMC2 AA FV AH DL AG ASC2 AA A9 EUDNGPFMC2 AA FV AH DL AG AS A9 EUC2 AA DNGPFMC2 AA FV AH DLAS AA AG C2 A9 EUDNGPFMC2 AA FV Table 1 : Different spelling versions for the name Milosevic general categories : translated and transliterated .</sentence>
				<definiendum id="0">AA A9 EUC2 AA DNGPC2 AA FMC2 AA FV DL AG ASC2 AA A9 EUC2 AA DNGPFMC2 AA FV AH DL AG</definiendum>
				<definiens id="0">Different spelling versions for the name Milosevic general categories : translated and transliterated</definiens>
			</definition>
			<definition id="1">
				<sentence>Translated : These are foreign words that are modified or remodelled to conform with Arabic word paradigms ; they are well assimilated into Arabic , and are sometimes referred to as Arabicised words ( Aljlayl and Frieder , 2002 ) .</sentence>
				<definiendum id="0">Translated</definiendum>
				<definiens id="0">These are foreign words that are modified or remodelled to conform with Arabic word paradigms ; they are well assimilated into Arabic , and are sometimes referred to as Arabicised words</definiens>
			</definition>
			<definition id="2">
				<sentence>Arabic patterns system Arabic uses a pattern system to derive words from their roots .</sentence>
				<definiendum id="0">Arabic</definiendum>
			</definition>
			<definition id="3">
				<sentence>For instance , ALFLER AB BT AB A9 EV ( /CUGEG5C1D0/ = doer ) , and ACFLABEQALA9EUABC3 AA ( /DDCUG5D0CD/ = is doing ) are two different patterns that respectively represent the active participle , and present tense verb from the pattern ABFLA6ABEQA6ABA9EV .</sentence>
				<definiendum id="0">ALFLER AB BT AB A9 EV</definiendum>
				<definiendum id="1">ACFLABEQALA9EUABC3 AA</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Khoja stemmer has an associated compressed language dictionary that contains wellknown roots .</sentence>
				<definiendum id="0">Khoja stemmer</definiendum>
				<definiens id="0">has an associated compressed language dictionary that contains wellknown roots</definiens>
			</definition>
			<definition id="5">
				<sentence>The Buckwalter morphological analyser is a lexicon that uses three tables and an algorithm to check possible affixes .</sentence>
				<definiendum id="0">Buckwalter morphological analyser</definiendum>
				<definiens id="0">a lexicon that uses three tables and an algorithm to check possible affixes</definiens>
			</definition>
			<definition id="6">
				<sentence>The total distance is computed by summing up all differences between the position of the n-gram in the text profile and the position of the same n-gram in the language profile : Dj = Nisummationdisplay i=1 | rank ( ti , text ) N i − rank ( ti , lj ) N j | where Dj is the total distance between a text t with Ni n-grams , and a language profile lj with Nj ngrams ; and rank is the position of the n-gram in the frequency-sorted list of all n-grams for either the text or language profile .</sentence>
				<definiendum id="0">total distance</definiendum>
				<definiendum id="1">Dj</definiendum>
				<definiendum id="2">rank</definiendum>
				<definiens id="0">computed by summing up all differences between the position of the n-gram in the text profile and the position of the same n-gram in the language profile : Dj = Nisummationdisplay i=1 | rank</definiens>
				<definiens id="1">the total distance between a text t with Ni n-grams , and a language profile lj with Nj ngrams</definiens>
			</definition>
</paper>

		<paper id="1418">
			<definition id="0">
				<sentence>Horacek considers the input problem and advocates the gradual and collective development of a generic ‘generation specification’ formalism .</sentence>
				<definiendum id="0">Horacek</definiendum>
				<definiens id="0">considers the input problem and advocates the gradual and collective development of a generic ‘generation specification’ formalism</definiens>
			</definition>
</paper>

		<paper id="2001">
			<definition id="0">
				<sentence>The multilingual extension procedure ( Figure 3 ) is carried out in three phases : Spanish Temporal Recognition Model Spanish-Italian TRANSLATOR TEs FILTER KEYWORDS Unit NEW TEs FINDER RULE ASSIGNMENTS Google WordNet Italian TEs Italian TEs Temporal keywords New Italian TEs New Normalizer rule Italian Temporal Normalizer Model Online DictionariesITALIAN TEs GRAMATICS Generator English Temporal Recognition Model Italian I-CAB Corpus English-Italian TRANSLATOR Italian-Spanish TRANSLATOR Italian-English TRANSLATOR Spanish Temporal Normalizer Model English Temporal Normalizer Model Italian TEs Italian generalized TEs Phase 1 Phase 2 Phase 3 Figure 2 : Multilingual extension procedure .</sentence>
				<definiendum id="0">multilingual extension procedure</definiendum>
				<definiens id="0">carried out in three phases : Spanish Temporal Recognition Model Spanish-Italian TRANSLATOR TEs FILTER KEYWORDS Unit NEW TEs FINDER RULE ASSIGNMENTS Google WordNet Italian TEs Italian TEs Temporal keywords New Italian TEs New Normalizer rule Italian Temporal Normalizer Model Online DictionariesITALIAN TEs GRAMATICS Generator English Temporal Recognition Model Italian I-CAB Corpus English-Italian TRANSLATOR Italian-Spanish TRANSLATOR Italian-English TRANSLATOR Spanish Temporal Normalizer Model English Temporal Normalizer Model Italian TEs Italian generalized TEs</definiens>
			</definition>
			<definition id="1">
				<sentence>In this phase , the TEs Gramatics Generator uses the morphological and syntactical information from the collected TEs to generate the grammatical rules that generalize the recognition of the TEs .</sentence>
				<definiendum id="0">TEs Gramatics Generator</definiendum>
				<definiens id="0">uses the morphological and syntactical information from the collected TEs to generate the grammatical rules that generalize the recognition of the TEs</definiens>
			</definition>
			<definition id="2">
				<sentence>I-CAB consists of 525 news documents taken from the local newspaper L’Adige ( http : //www.adige.it ) .</sentence>
				<definiendum id="0">I-CAB</definiendum>
			</definition>
			<definition id="3">
				<sentence>As shown in Table 5 , these expressions have been obtained from the different resources available : ENG ITA : This group of expressions has been obtained from the automatic translation into Italian of the English Temporal Expressions stored in the knowledge DB .</sentence>
				<definiendum id="0">ENG ITA</definiendum>
			</definition>
			<definition id="4">
				<sentence>Like all the other state of the art systems addressing the recognition/normalization task , Chronos is a rule-based system .</sentence>
				<definiendum id="0">Chronos</definiendum>
				<definiens id="0">a rule-based system</definiens>
			</definition>
			<definition id="5">
				<sentence>EuroWordNet : Building a Multilingual Database with WordNets in 8 European Languages .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
				<definiens id="0">Building a Multilingual Database with WordNets in 8 European Languages</definiens>
			</definition>
</paper>

		<paper id="3802">
			<definition id="0">
				<sentence>The Hypertext Induced Topic Selection ( HITS ) algorithm is an algorithm for rating , and therefore ranking , web pages .</sentence>
				<definiendum id="0">Hypertext Induced Topic Selection</definiendum>
				<definiens id="0">an algorithm for rating , and therefore ranking , web pages</definiens>
			</definition>
			<definition id="1">
				<sentence>A hub value is the sum of the scaled authority values of the authorities it points to .</sentence>
				<definiendum id="0">hub value</definiendum>
				<definiens id="0">the sum of the scaled authority values of the authorities it points to</definiens>
			</definition>
			<definition id="2">
				<sentence>A template , as we define for this work , is a sequence of generic forms that could generalize over the given training instance .</sentence>
				<definiendum id="0">template</definiendum>
				<definiens id="0">a sequence of generic forms that could generalize over the given training instance</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally , the word ( s ) with the tag NOUN_PHRASE represents the relation between the two previous entities .</sentence>
				<definiendum id="0">NOUN_PHRASE</definiendum>
				<definiens id="0">s ) with the tag</definiens>
			</definition>
			<definition id="4">
				<sentence>A tuple , in our notation during this paper , is the result of the application of a pattern to unstructured text .</sentence>
				<definiendum id="0">tuple</definiendum>
			</definition>
			<definition id="5">
				<sentence>The pattern induction problem can be formulated as follows : Given a very large set of data D containing a large set of patterns P which match a P P P P P T T T T T P P T T Patterns Tuples American vice President Al Gore said today ... Word : American Entity : PEOPLE POS : ADJ Sem : Inhabitant Word : vice president Entity : POS : NOUN_PHRASE Sem : Word : Al Gore Entity : PERSON POS : Sem : PEOPLE_Inhabitant NOUN_PHRASE PERSON VERB_PHRASE Entity 1 : Al Gore Entity 2 : American Relation : vice President American vice President Al Gore said today… Italian Prime Minister Berlusconi visited… .</sentence>
				<definiendum id="0">American Relation</definiendum>
				<definiens id="0">match a P P P P P T T T T T P P T T Patterns Tuples American vice President Al Gore said today ... Word : American Entity : PEOPLE POS : ADJ Sem : Inhabitant Word : vice president Entity</definiens>
			</definition>
			<definition id="6">
				<sentence>The weights are calculated iteratively as follows : ( ) ( ) ( )  =+ = pTu i i i H uhpa 1 ) ( ) ( ) 1 ( ( 1 ) ( ) ( ) ( )  =+ = tPu i i i A uath 1 ) ( ) ( ) 1 ( ( 2 ) where T ( p ) is the set of tuples matched by p , P ( t ) is the set of patterns matching t , ( ) pa i ) 1 ( + is the authoritative weight of pattern p at iteration ) 1 ( +i , and ( ) th i ) 1 ( + is the hub weight of tuple t at iteration ) 1 ( +i .</sentence>
				<definiendum id="0">T ( p )</definiendum>
				<definiendum id="1">(</definiendum>
				<definiendum id="2">+</definiendum>
				<definiens id="0">the set of tuples matched by p , P ( t ) is the set of patterns matching t , ( ) pa i ) 1 ( + is the authoritative weight of pattern p at iteration ) 1 ( +i , and</definiens>
			</definition>
			<definition id="7">
				<sentence>A prior probabilities vector pr = { pr1 , . . . , prn } is defined such that the probabilities sum to 1 , where prv denotes the relative importance ( or “prior bias” ) we attach to node v. A pattern Pi is assigned a prior pri=1/n if pattern Pi matches a supervised tuple , otherwise pri is set to zero , n is the total number of patterns that have a supervised match .</sentence>
				<definiendum id="0">prv</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the relative importance ( or “prior bias” ) we attach to node v. A pattern Pi is assigned a prior pri=1/n if pattern Pi matches a supervised tuple</definiens>
			</definition>
			<definition id="8">
				<sentence>We also define a “back probability” a0 , 0 a1 a0 a1 1 which determines how often we bias the supervised nodes : ( ) ( ) ( ) ( ) ppTu iii prH uhpa *1 1 ) ( ) ( ) 1 ( ββ + −= = + ( 5 ) ( ) ( ) ( ) ( ) ttPu iii prA uath *1 1 ) ( ) ( ) 1 ( ββ + −= = + ( 6 ) where T ( p ) is the set of tuples matched by p , P ( t ) is the set of patterns matching t , and H ( i ) and A ( i ) are normalization factors defined as in equations ( 3 ) and ( 4 ) Thus each node in the graph ( pattern or tuple ) has an associated prior weight depending on its supervised data .</sentence>
				<definiendum id="0">T ( p )</definiendum>
				<definiendum id="1">tuple ) has an associated</definiendum>
				<definiens id="0">a “back probability” a0 , 0 a1 a0 a1 1 which determines how often we bias the supervised nodes : ( )</definiens>
				<definiens id="1">the set of tuples matched by p , P ( t ) is the set of patterns matching t</definiens>
			</definition>
			<definition id="9">
				<sentence>ACE is an evaluation conducted by NIST to measure Entity Detection and Tracking ( EDT ) and Relation Detection and Characterization ( RDC ) .</sentence>
				<definiendum id="0">ACE</definiendum>
			</definition>
			<definition id="10">
				<sentence>Mentions are any instances of textual references to objects like peo12 ple , organizations , geo-political entities ( countries , cities …etc ) , locations , or facilities .</sentence>
				<definiendum id="0">Mentions</definiendum>
				<definiens id="0">any instances of textual references to objects like peo12 ple , organizations , geo-political entities ( countries , cities …etc ) , locations , or facilities</definiens>
			</definition>
			<definition id="11">
				<sentence>The base line system uses a Maximum Entropy model that combines diverse lexical , syntactic and semantic features derived from text , like the system described in ( Nanda , 2004 ) .</sentence>
				<definiendum id="0">base line system</definiendum>
			</definition>
			<definition id="12">
				<sentence>2 2 2 where SE1 , and SE2 are the similarity scores of the first entities in the two tuples , and their second entitles respectively .</sentence>
				<definiendum id="0">SE2</definiendum>
				<definiens id="0">the similarity scores of the first entities in the two tuples , and their second entitles respectively</definiens>
			</definition>
			<definition id="13">
				<sentence>MCL is a fast and scalable unsupervised cluster algorithm for graphs based on simulation of stochastic flow .</sentence>
				<definiendum id="0">MCL</definiendum>
				<definiens id="0">a fast and scalable unsupervised cluster algorithm for graphs based on simulation of stochastic flow</definiens>
			</definition>
</paper>

		<paper id="0128">
</paper>

		<paper id="1606">
			<definition id="0">
				<sentence>For example , we may make explicit that the Chinese phrase “ASTRO-NAUTS” may be translated into English as a noun phrase , NP ( NNS ( astronauts ) ) ; that the phrase FRANCE AND RUSSIA may be translated into a complex nounphrase , NP ( NP ( NNP ( france ) ) CC ( and ) NP ( NNP ( russia ) ) ) ; that the phrase COMINGFROM may be translated into a partially realized verb phrase that is looking for a noun phrase to its right in order to be fully realized , VP ( VBG ( coming ) PP ( IN ( from ) NP : x0 ) ) ; and that the Chinese particle p-DE , when occurring between a Chinese string that was translated into a verb phrase to its left and another Chinese string that was translated into a noun phrase to its right , VP : x1 p-DE NP : x0 , should be translated to nothing , while forcing the reordering of the two constituents , NP ( NP : x0 , VP : x1 ) .</sentence>
				<definiendum id="0">NP ( NNS</definiendum>
				<definiendum id="1">Chinese string</definiendum>
				<definiens id="0">a noun phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>We assume that observed ( pi , F , A ) triplets are generated by a stochastic process similar to r1 : NP ( NNS ( astronauts ) ) → ASTRO-NAUTS r2 : NP ( NP ( NNP ( france ) ) CC ( and ) NP ( NNP ( russia ) ) ) → FRANCE AND RUSSIA r3 : VP ( VBG ( coming ) PP ( IN ( from ) NP : x0 ) ) → COMINGFROM x0 r4 : NP ( NP : x0 , VP : x1 ) → x1 p-DE x0 r5 : NNP ( france ) → FRANCE r6 : NP ( NP ( NNP ( france ) ) CC ( and ) NP : x0 ) → FRANCE AND x0 r7 : NNS ( astronauts ) → ASTRO-NAUTS r8 : NNP ( russia ) → RUSSIA r9 : NP ( NNS : x0 ) → x0 r10 : PP ( IN : x0 NP : x1 ) → x0 x1 r11 : NP ( NP : x0 CC : x1 NP : x2 ) → x0 x1 x2 r12 : NP ( NNP : x0 ) → x0 r13 : CC ( and ) → AND r14 : NP ( NP : x0 CC ( and ) NP : x1 ) → x0 AND x1 r15 : NP ( NP : x0 VP ( VBG ( coming ) PP ( IN ( from ) NP : x1 ) ) ) → x1 COMINGFROM x0 Figure 1 : Examples of xRS rules .</sentence>
				<definiendum id="0">NNS</definiendum>
				<definiens id="0">x0 ) → x0 r10 : PP ( IN : x0 NP : x1 ) → x0 x1 r11 : NP ( NP : x0 CC : x1 NP : x2 ) → x0 x1 x2 r12 : NP ( NNP : x0 ) → x0 r13 : CC</definiens>
			</definition>
			<definition id="2">
				<sentence>pcfg ( ri ) is the CFG-like probability of the non-lexicalized rules in the model .</sentence>
				<definiendum id="0">pcfg ( ri )</definiendum>
				<definiens id="0">the CFG-like probability of the non-lexicalized rules in the model</definiens>
			</definition>
			<definition id="3">
				<sentence>Phrase-based-like submodels : lex pef ( ri ) is the direct phrase-based conditional probability computed over the foreign/source and target phrases subsumed by a rule .</sentence>
				<definiendum id="0">lex pef</definiendum>
				<definiens id="0">the direct phrase-based conditional probability computed over the foreign/source and target phrases subsumed by a rule</definiens>
			</definition>
			<definition id="4">
				<sentence>lm ( e ) is the language model probability of the target translation under an ngram language model .</sentence>
				<definiendum id="0">lm ( e )</definiendum>
				<definiens id="0">the language model probability of the target translation under an ngram language model</definiens>
			</definition>
			<definition id="5">
				<sentence>wp ( e ) is a word penalty model designed to favor longer translations .</sentence>
				<definiendum id="0">wp ( e )</definiendum>
			</definition>
</paper>

		<paper id="0207">
			<definition id="0">
				<sentence>LoLo has been used to build a local grammar to extract ‘sentiment’ or key ( changing ) market events in English and in Arabic from unseen texts .</sentence>
				<definiendum id="0">LoLo</definiendum>
				<definiens id="0">used to build a local grammar to extract ‘sentiment’ or key ( changing ) market events in English and in Arabic from unseen texts</definiens>
			</definition>
			<definition id="1">
				<sentence>The N-gram patterns ( when N ≤ 4 ) show poor results in that either such patterns found in the training corpus are not found in the test corpus , or the patterns retrieved from test corpora are at semantic variance with the same pattern in the training corpus .</sentence>
				<definiendum id="0">N-gram patterns</definiendum>
				<definiens id="0">either such patterns found in the training corpus are not found in the test corpus , or the patterns retrieved from test corpora are at semantic variance with the same pattern in the training corpus</definiens>
			</definition>
</paper>

		<paper id="2003">
			<definition id="0">
				<sentence>First , an alignment between the word pairs is computed by an EM algorithm that uses an edit distance metric based on an increasingly refined individual letter correspondence cost function .</sentence>
				<definiendum id="0">EM algorithm</definiendum>
			</definition>
			<definition id="1">
				<sentence>The linear affixing operator combines stems and bound morphemes ( affixes ) using linear ordering with possible fusion effects , usually at the seams .</sentence>
				<definiendum id="0">linear affixing operator</definiendum>
				<definiens id="0">combines stems and bound morphemes ( affixes ) using linear ordering with possible fusion effects</definiens>
			</definition>
			<definition id="2">
				<sentence>Both cognate identification ( Kondrak et al 03 ) and morphological information in one of the languages ( Niessen00 ) have been proven useful in statistical machine translation .</sentence>
				<definiendum id="0">cognate identification</definiendum>
				<definiens id="0">morphological information in one of the languages ( Niessen00 ) have been proven useful in statistical machine translation</definiens>
			</definition>
</paper>

		<paper id="0402">
			<definition id="0">
				<sentence>While chart parsing can famously be cast as deduction ( Pereira and Warren , 1983 ) , what chart parsing really is is an algebraic closure over the rules of a phrase structure grammar , which is most naturally expressed inside a constraint solver such as CHR ( Morawietz , 2000 ) .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiendum id="1">CHR</definiendum>
				<definiens id="0">an algebraic closure over the rules of a phrase structure</definiens>
			</definition>
			<definition id="1">
				<sentence>2 CanBV is the set of all words that can be used to build an C6 , and ReqBV is the set of all words that must be used while building the C6 .</sentence>
				<definiendum id="0">CanBV</definiendum>
				<definiendum id="1">ReqBV</definiendum>
				<definiens id="0">the set of all words that can be used to build an C6 , and</definiens>
			</definition>
			<definition id="2">
				<sentence>Search ( CWC6BNBVBNCACX ) can then be defined in the constraint solver as follows : A top-down parse of an D2-length string begins with the state consisting of the distinguished category , CB , of the grammar , and BVCPD2BUCE BP CACTD5BUCE BP CUBDBMBMBMD2CV .</sentence>
				<definiendum id="0">Search</definiendum>
				<definiens id="0">A top-down parse of an D2-length string begins with the state consisting of the distinguished category , CB , of the grammar</definiens>
			</definition>
			<definition id="3">
				<sentence>Given a FWO grammar , BZ , with immediate dominance rules , CA , over a set of non-terminals , C6 , wedefinethecategory graph of BZ to be the smallest directed bipartite graph , BVB4BZB5BPCWCEBNBXCX , such that : AF CE BP C6 CJCACJCUC4CTDCBNBXD1D4D8DDCV , AF B4CGBND6B5 BE BX if non-terminal CG appears on the RHS of rule D6 , AF B4D6BNCGB5 BE BX if the LHS non-terminal of D6 is CG , AF B4C4CTDCBND6B5 BE BX if there is a terminal on the RHS of rule D6 , and AF B4BXD1D4D8DDBND6B5 BE BX if D6 is an empty production rule .</sentence>
				<definiendum id="0">AF B4BXD1D4D8DDBND6B5 BE BX if D6</definiendum>
				<definiens id="0">with immediate dominance rules , CA , over a set of non-terminals , C6 , wedefinethecategory graph of BZ to be the smallest directed bipartite graph</definiens>
				<definiens id="1">an empty production rule</definiens>
			</definition>
			<definition id="4">
				<sentence>The CG D1CXD2 functions converge in the presence of unit production cycles in BVB4BZB5 ; theCG D1CPDC functions can also converge in this case .</sentence>
				<definiendum id="0">CG D1CXD2 functions</definiendum>
				<definiens id="0">converge in the presence of unit production cycles in BVB4BZB5</definiens>
			</definition>
			<definition id="5">
				<sentence>Rather than provide the general definitions here , we simply give some of the equations for Figure 4 , 15 for shortage of space : S D1CPDC B4CWBND2BND1B5BPS D1CPDC B4CWBNAMD2BN AMD1B5 S D1CPDC B4CWBND2BN AMD1B5BPS D1CPDC B4CWBNAMD2BN AMD1B5 S D1CPDC B4CWBN AMD2BN AMD1B5BP D1CPDC CX B7 CY BP D2 , CZ B7 D0 BP D1 BK BQ BQ BQ BO BQ BQ BQ BM NP D1CPDC B4CWA0BDBN AM CXBNCZB5 B7VP D1CPDC B4AK CWA0BDBNCYBN AM D0B5 NP D1CPDC B4AK CWA0BDBN AM CXBNCZB5 B7VP D1CPDC B4CWA0BDBNCYBN AM D0B5 NP D1CPDC B4CWBN AMD2BN AMD1B5 BP D1CPDC B4 NP D1CPDC BD B4CWBNAMD2BN AMD1B5 NP D1CPDC BE B4CWBND2BND1B5 NP D1CPDC BD B4CWBN AMD2BN AMD1B5BP D1CPDC BK BQ BQ BQ BO BQ BQ BQ BM N’ D1CPDC B4CWA0BDB5 B7S D1CPDC B4AK CWA0BDBND2A0BDBND1A0BDB5 N’ D1CPDC B4AK CWA0BDB5 B7S D1CPDC B4CWA0BDBND2A0BDBND1A0BDB5 NP D1CPDC BD B4CWBND2BN AMD1B5BP D1CPDC BK BQ BQ BQ BO BQ BQ BQ BM N’ D1CPDC B4CWA0BDB5 B7S D1CPDC B4AK CWA0BDBND2BND1A0BDB5 N’ D1CPDC B4AK CWA0BDB5 B7S D1CPDC B4CWA0BDBND2BND1A0BDB5 NP D1CPDC BD B4CWBN AMD2BND1B5BP D1CPDC BK BQ BQ BQ BO BQ BQ BQ BM N’ D1CPDC B4CWA0BDB5 B7S D1CPDC B4AK CWA0BDBND2A0BDBND1B5 N’ D1CPDC B4AK CWA0BDB5 B7S D1CPDC B4CWA0BDBND2A0BDBND1B5 NP D1CPDC BE B4CWBND2BND1B5BP B4 N’ D1CPDC B4CWA0BDB5 D2 BP D1 BPBC undefined D3BMDBBM VP D1CPDC BD B4CWBND2BN AMD1B5BP D1CPDC BK BQ BQ BQ BO BQ BQ BQ BM V D1CPDC B4CWA0BDB5 B7NP D1CPDC B4AK CWA0BDBND2BND1A0BDB5 V D1CPDC B4AK CWA0BDB5 B7NP D1CPDC B4CWA0BDBND2BND1A0BDB5 We think of functions in which overscores are written over some parameters as entirely different functions that have witnessed partial traversals through the cycles corresponding to the overscored parameters , beginning at the respective index nodes of those cycles .</sentence>
				<definiendum id="0">NP D1CPDC BD B4CWBND2BN AMD1B5BP D1CPDC BK BQ BQ BQ BO BQ BQ BQ BM</definiendum>
				<definiendum id="1">BP D1 BPBC undefined D3BMDBBM VP D1CPDC BD B4CWBND2BN AMD1B5BP D1CPDC BK BQ BQ BQ BO BQ BQ BQ BM V D1CPDC B4CWA0BDB5 B7NP D1CPDC B4AK CWA0BDBND2BND1A0BDB5 V D1CPDC B4AK CWA0BDB5</definiendum>
				<definiens id="0">B7NP D1CPDC B4CWA0BDBND2BND1A0BDB5 We think of functions in which overscores are written over some parameters as entirely different functions that have witnessed partial traversals through the cycles corresponding to the overscored parameters</definiens>
			</definition>
</paper>

		<paper id="3407">
			<definition id="0">
				<sentence>However , a flat segmentation model is an adequate approximation .</sentence>
				<definiendum id="0">flat segmentation model</definiendum>
				<definiens id="0">an adequate approximation</definiens>
			</definition>
			<definition id="1">
				<sentence>The first corpus , which we call the Olney &amp; Cai corpus , is a set of dialogues selected randomly from the same corpus Olney and Cai obtained their corpus from ( Olney and Cai , 2005 ) .</sentence>
				<definiendum id="0">Cai corpus</definiendum>
				<definiens id="0">a set of dialogues selected randomly from the same corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>The second corpus , the Thermo corpus , is a locally collected corpus of thermodynamics tutoring dialogues , in which tutor-student pairs work together to solve an optimization task .</sentence>
				<definiendum id="0">Thermo corpus</definiendum>
				<definiens id="0">a locally collected corpus of thermodynamics tutoring dialogues</definiens>
			</definition>
			<definition id="3">
				<sentence>In addition to these approaches , we include segmentation results from three degenerate approaches : ( 1 ) classifying all contributions as NEW_TOPIC ( ALL ) , ( 2 ) classifying no contributions as NEW_TOPIC ( NONE ) , and ( 3 ) classifying contributions as NEW_TOPIC at uniform intervals ( EVEN ) , separated by the average reference topic length ( see Table 2 ) .</sentence>
				<definiendum id="0">average reference topic length</definiendum>
				<definiens id="0">results from three degenerate approaches : ( 1 ) classifying all contributions as NEW_TOPIC ( ALL ) , ( 2 ) classifying no contributions as NEW_TOPIC ( NONE ) , and ( 3 ) classifying contributions as NEW_TOPIC at uniform intervals ( EVEN ) , separated by the</definiens>
			</definition>
			<definition id="4">
				<sentence>TextTiling measures the term overlap between adjacent regions in the discourse .</sentence>
				<definiendum id="0">TextTiling</definiendum>
				<definiens id="0">measures the term overlap between adjacent regions in the discourse</definiens>
			</definition>
			<definition id="5">
				<sentence>Sinclair and Coulthard posit that if exchanges constitute the minimal unit of interaction , IRF is a primary structure of interactive discourse in general .</sentence>
				<definiendum id="0">IRF</definiendum>
				<definiens id="0">a primary structure of interactive discourse in general</definiens>
			</definition>
</paper>

		<paper id="1107">
			<definition id="0">
				<sentence>Cognate identi cation is a problem of nding , in distinct languages , words that can be traced back to a common word in a proto-language .</sentence>
				<definiendum id="0">Cognate identi cation</definiendum>
				<definiens id="0">a problem of nding , in distinct languages , words that can be traced back to a common word in a proto-language</definiens>
			</definition>
			<definition id="1">
				<sentence>The principal component of ALINE is a function that calculates the similarity of two phonemes that are expressed in terms of about a dozen multi-valued phonetic features ( Place , Manner , Voice , etc. ) .</sentence>
				<definiendum id="0">ALINE</definiendum>
				<definiens id="0">a function that calculates the similarity of two phonemes that are expressed in terms of about a dozen multi-valued phonetic features</definiens>
			</definition>
			<definition id="2">
				<sentence>CORDI ( Kondrak , 2002 ) is a program for detecting recurrent sound correspondences in bilingual wordlists .</sentence>
				<definiendum id="0">CORDI</definiendum>
				<definiens id="0">a program for detecting recurrent sound correspondences in bilingual wordlists</definiens>
			</definition>
			<definition id="3">
				<sentence>A DBN is a Bayesian Net where a set of arcs and nodes are maintained for each point in time in a dynamic process .</sentence>
				<definiendum id="0">DBN</definiendum>
				<definiens id="0">a Bayesian Net where a set of arcs and nodes are maintained for each point in time in a dynamic process</definiens>
			</definition>
			<definition id="4">
				<sentence>In the following description of the models , Z denotes the current edit operation , which can be either a substitution , an insertion , or a deletion .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiens id="0">the current edit operation , which can be either a substitution , an insertion , or a deletion</definiens>
			</definition>
			<definition id="5">
				<sentence>The input consists of pairs of words that have the same meaning in distinct languages .</sentence>
				<definiendum id="0">input</definiendum>
			</definition>
			<definition id="6">
				<sentence>ALINE denotes the algorithm for aligning phonetic sequences ( Kondrak , 2000 ) described in Section 2.1 .</sentence>
				<definiendum id="0">ALINE</definiendum>
			</definition>
			<definition id="7">
				<sentence>R &amp; Y is the stochastic transducer of Ristad and Yianilos ( 1998 ) .</sentence>
				<definiendum id="0">Y</definiendum>
			</definition>
			<definition id="8">
				<sentence>LLW stands for Levenshtein with learned weights , which is a modi cation of R &amp; Y proposed by Mann and Yarowsky ( 2001 ) .</sentence>
				<definiendum id="0">LLW</definiendum>
			</definition>
			<definition id="9">
				<sentence>ALINE outperforms Mielke’s metric , which is not surprising considering that ALINE was developed speci cally for identifying cognates , and Mielke’s substitution matrix lacks several phonemes that occur in the test set .</sentence>
				<definiendum id="0">ALINE outperforms Mielke’s metric</definiendum>
				<definiendum id="1">Mielke’s substitution matrix</definiendum>
				<definiens id="0">lacks several phonemes that occur in the test set</definiens>
			</definition>
</paper>

		<paper id="1409">
			<definition id="0">
				<sentence>Their content can be modelled as a list L = 〈 ( x1 , P1 ) , ( x2 , P2 ) ... ( xn , Pn ) 〉 , where x1 = r is the referent of the referring expression and , for every j &gt; 1 , xj is an ancestor ( not necessarily the parent ) of xj−1 in D. For every j , Pj is a set of properties that jointly identify xj within xj+1 or , if j = n , within the whole domain .</sentence>
				<definiendum id="0">xj</definiendum>
				<definiendum id="1">Pj</definiendum>
			</definition>
			<definition id="1">
				<sentence>Both take as input a hierarchical domain D , a location d where the referring expression will materialise , and an intended referent r. Briefly , the FI algorithm represents a straightforward way of reducing the length of search paths , without particular attention to DE or LO .</sentence>
				<definiendum id="0">FI algorithm</definiendum>
				<definiens id="0">represents a straightforward way of reducing the length of search paths , without particular attention to DE or LO</definiens>
			</definition>
			<definition id="2">
				<sentence>FI gives maximal weight to ease of resolution .</sentence>
				<definiendum id="0">FI</definiendum>
				<definiens id="0">gives maximal weight to ease of resolution</definiens>
			</definition>
			<definition id="3">
				<sentence>SL prevents DE and LO but opts for brevity when DE and LO do not occur .</sentence>
				<definiendum id="0">SL</definiendum>
				<definiens id="0">prevents DE and LO but opts for brevity when DE and LO do not occur</definiens>
			</definition>
</paper>

		<paper id="2801">
			<definition id="0">
				<sentence>Basedontheseconsiderations , wecomputenetwork characteristicsof three extractionsof the GermanWikipedia ( see table 1 ) : VariantI consists of a graphwhosevertex set containsall Article nodes and whose edge set is based on Interlinks andappropriatelyresolved Redirect links .</sentence>
				<definiendum id="0">VariantI</definiendum>
			</definition>
			<definition id="1">
				<sentence>VariantIII consists of a graphwhosevertex setcoversall verticesand edgesfoundin theextraction .</sentence>
				<definiendum id="0">VariantIII</definiendum>
				<definiens id="0">consists of a graphwhosevertex setcoversall verticesand edgesfoundin theextraction</definiens>
			</definition>
</paper>

		<paper id="3111">
			<definition id="0">
				<sentence>The translation model can be further extended to a statistical alignment model with the following equation : Pr ( fJ1 |eI1 ) = summationdisplay aJ1 Pr ( fJ1 , aJ1|eI1 ) The alignment model Pr ( fJ1 , aJ1|eI1 ) introduces a ‘hidden’ word alignment a = aJ1 , which describes a mapping from a source position j to a target position aj .</sentence>
				<definiendum id="0">translation model</definiendum>
				<definiens id="0">a ‘hidden’ word alignment a = aJ1 , which describes a mapping from a source position j to a target position aj</definiens>
			</definition>
			<definition id="1">
				<sentence>In the monotone case , the model is represented as h4 ( j , i,1|fJ1 , eI1 ) = log parenleftBiggN ( fj 1 , ei1 ) +N ( fJj+1 , eIi+1 ) N ( fJ1 , eI1 ) parenrightBigg , where N ( fj1 , ei1 ) denotes the number of the alignment links inside the matrix ( 1,1 ) and ( j , i ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">ei1 )</definiendum>
				<definiens id="0">the number of the alignment links inside the matrix</definiens>
			</definition>
			<definition id="2">
				<sentence>80 Table 1 : Corpus Statistics : NIST Chinese English Train Sentences 8.64 M Running Words 210 M 226 M Average Sentence Length 24.4 26.3 Vocabulary 224 268 359 623 Singletons 98 842 156 493 Segmentation Sentences 17.9 M Running Words 210 M 226 M Average Sentence Length 11.7 12.6 Vocabulary 221 517 353 148 Singletons 97 062 152 965 Segmentation with Additional Data Sentences 19.5 M Running Words 230 M 248 M Added Running Words 8.0 % 8.2 % Evaluation Sentences 878 3 512 Running Words 24 111 105 516 Vocabulary 4 095 6 802 OOVs ( Running Words ) 8 658 In this section , we describe the different methods to extract the bilingual sentence pairs from the document aligned corpus .</sentence>
				<definiendum id="0">Corpus Statistics</definiendum>
				<definiens id="0">the different methods to extract the bilingual sentence pairs from the document aligned corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>After a paragraph is divided into sentences at punctuation marks , the Champollion tool ( Ma , 2006 ) is used , which applies dynamic programming for the sentence alignment .</sentence>
				<definiendum id="0">Champollion tool</definiendum>
				<definiens id="0">applies dynamic programming for the sentence alignment</definiens>
			</definition>
			<definition id="4">
				<sentence>We use four different criteria to evaluate the translation results automatically : • WER ( word error rate ) : The WER is computed as the minimum number of substitution , insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence , divided by the reference sentence length .</sentence>
				<definiendum id="0">WER</definiendum>
			</definition>
			<definition id="5">
				<sentence>The PER compares the words in the two sentences ignoring the word order .</sentence>
				<definiendum id="0">PER</definiendum>
				<definiens id="0">compares the words in the two sentences ignoring the word order</definiens>
			</definition>
</paper>

		<paper id="0805">
			<definition id="0">
				<sentence>Values come below the attributes , headed by their frequencies in all specifications .</sentence>
				<definiendum id="0">Values</definiendum>
				<definiens id="0">come below the attributes , headed by their frequencies in all specifications</definiens>
			</definition>
			<definition id="1">
				<sentence>The frequency information ( in parentheses ) is used to calculate term weights of attributes and values .</sentence>
				<definiendum id="0">frequency information</definiendum>
				<definiens id="0">used to calculate term weights of attributes and values</definiens>
			</definition>
			<definition id="2">
				<sentence>The normalized cost is computed as : ) log ( / ) /log ( TNNTN where TN is the total number of values for an attribute , and N is the number of values where a term occurs .</sentence>
				<definiendum id="0">TN</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the total number of values for an attribute , and</definiens>
				<definiens id="1">the number of values where a term occurs</definiens>
			</definition>
			<definition id="3">
				<sentence>The distance between a new phrase and a DM phrase is then calculated using word editing cost based on the costs of substitution , insertion , and deletion , where Costsub = ( CostDM + Costnew ) / 2 Costins = Costnew Costdel = CostDM Costedit = min ( Costsub , Costins , Costdel ) where CostDM is the cost of a word in a domain value ( i.e. , its normalized IDF score ) , and Costnew 35 is that of a word in the new phrase .</sentence>
				<definiendum id="0">CostDM</definiendum>
				<definiens id="0">calculated using word editing cost based on the costs of substitution , insertion , and deletion , where Costsub = ( CostDM + Costnew</definiens>
				<definiens id="1">the cost of a word in a domain value ( i.e. , its normalized IDF score ) , and Costnew 35 is that of a word in the new phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>Disambiguation by Sentence Context The AV identification process often returns multiple attribute candidates for a phrase that needs to be further disambiguated .</sentence>
				<definiendum id="0">identification process</definiendum>
				<definiens id="0">multiple attribute candidates for a phrase that needs to be further disambiguated</definiens>
			</definition>
			<definition id="5">
				<sentence>For the experiments described in the paper , we used the dot product function for computing similarities between a query and a document : where WQ ( t ) is the weight associated with the query term t and WD ( t ) is the weight associated with the term t in the document D. The two weights were computed as follows : where IDF and TF are standard inverse document frequency and term frequency statistics , respectively .</sentence>
				<definiendum id="0">WQ</definiendum>
				<definiens id="0">the weight associated with the query term t</definiens>
				<definiens id="1">the weight associated with the term t in the document D. The two weights were computed as follows : where IDF and TF are standard inverse document frequency and term frequency statistics , respectively</definiens>
			</definition>
			<definition id="6">
				<sentence>The coefficient C ( t ) is an “importance coefficient” , which can be modified either manually by the user or automatically by the system ( e.g. , updated during feedback ) .</sentence>
				<definiendum id="0">coefficient C</definiendum>
				<definiens id="0">an “importance coefficient” , which can be modified either manually by the user or automatically by the system ( e.g. , updated during feedback )</definiens>
			</definition>
			<definition id="7">
				<sentence>( ) ( ) , ( tWtWDQsim D DQt Q ⋅= ∑ ∩∈ 36 is present in a document d with a value v’ that satisfies v , that is , v’= v if v is a concrete value or v’ falls in the range defined by v , d is given a positive score w. However , if v’ does not satisfy v , then d is given a negative score -w. No mention of a does not change the score of d , except that , when c is a string constraint , we use a backoff model that awards d a positive score w if it contains v as a substring .</sentence>
				<definiendum id="0">tWtWDQsim D DQt Q ⋅= ∑ ∩∈ 36</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">present in a document d with a value v’ that satisfies v , that is , v’= v if v is a concrete value or v’ falls in the range defined by v , d is given a positive score w. However , if v’ does not satisfy v , then d is given a negative score -w. No mention of a does not change the score of d , except that</definiens>
			</definition>
			<definition id="8">
				<sentence>The final score of d given q is the sum of all scores for each constraint in q , normalized by the maximum score for q : ∑ = n i iiwc 1 , where ci is one of the n constraints specified in q and wi its score .</sentence>
				<definiendum id="0">ci</definiendum>
				<definiens id="0">one of the n constraints specified in q and wi its score</definiens>
			</definition>
			<definition id="9">
				<sentence>The inter-annotator agreement ( without annotator training ) as measured by Kappa is 0.72 , which suggests satisfactory agreement .</sentence>
				<definiendum id="0">inter-annotator agreement</definiendum>
				<definiens id="0">without annotator training ) as measured by Kappa is 0.72 , which suggests satisfactory agreement</definiens>
			</definition>
			<definition id="10">
				<sentence>For both judgments , the combined Average Precision is the average of the precision value obtained after each relevant document is retrieved , and Mean Average Precision is the average of AP over all topics ; RPrecision is the precision after R documents have been retrieved , where R is the number of relevant documents for the topic .</sentence>
				<definiendum id="0">RPrecision</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">the average of the precision value obtained after each relevant document is retrieved , and Mean Average Precision is the average of AP over all topics</definiens>
				<definiens id="1">the precision after R documents have been retrieved , where</definiens>
				<definiens id="2">the number of relevant documents for the topic</definiens>
			</definition>
</paper>

		<paper id="2707">
			<definition id="0">
				<sentence>The head noun of the NP realizing the subject of the sentence , “ManU” gets a positive mention tag , since it is the subject of a positive verb and direct object combination ( the NP “the command” having a positive reading , whereas the verb “takes” has a neutral reading ) .</sentence>
				<definiendum id="0">“ManU”</definiendum>
				<definiens id="0">gets a positive mention tag</definiens>
			</definition>
</paper>

		<paper id="3320">
</paper>

		<paper id="2402">
			<definition id="0">
				<sentence>Eng 400 11.7 k 2.7 k 29.1 Spa 400 12.3 k 3.1 k 30.4 Table 1 : Basic statistics for the considered training ( a ) translation test ( b ) and alignment test ( c ) data sets ( M and k stands for millions and thousands , respectively ) .</sentence>
				<definiendum id="0">alignment test ( c ) data sets</definiendum>
				<definiens id="0">Basic statistics for the considered training ( a ) translation test</definiens>
			</definition>
			<definition id="1">
				<sentence>The alignment error rate ( AER ) is given by the following formula : AER = 1− |A∩GS|+|A∩G||A|+|G S| ( 4 ) where A is the set of computed links , GS is the set of Sure reference links and G is the entire set of reference links .</sentence>
				<definiendum id="0">alignment error rate</definiendum>
				<definiendum id="1">AER</definiendum>
				<definiendum id="2">GS</definiendum>
				<definiens id="0">the set of Sure reference links and G is the entire set of reference links</definiens>
			</definition>
			<definition id="2">
				<sentence>As for translation evaluation , we used the following measures : WER ( word error rate ) or mWER ( multireference word error rate ) The WER is the minimum number of substitution , insertion and deletion operations that must be performed to convert the generated sentence into the reference target sentence .</sentence>
				<definiendum id="0">WER</definiendum>
				<definiens id="0">the minimum number of substitution , insertion and deletion operations that must be performed to convert the generated sentence into the reference target sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Table 6 presents the automatic translation eval14 Recall Precision AER Baseline 76.3 85.0 19.4 All 78.0 82.0 19.9 Verb 77.0 84.5 19.3 Noun 76.8 83.0 20.0 Misc 77.0 84.1 19.4 Table 5 : Alignment results uation results .</sentence>
				<definiendum id="0">Alignment</definiendum>
				<definiens id="0">results uation results</definiens>
			</definition>
</paper>

		<paper id="3704">
			<definition id="0">
				<sentence>LifeCode : a deployed application for automated medical coding .</sentence>
				<definiendum id="0">LifeCode</definiendum>
				<definiens id="0">a deployed application for automated medical coding</definiens>
			</definition>
</paper>

		<paper id="2910">
			<definition id="0">
				<sentence>The different frameworks depend on different instantiations of semantic similarity , e.g. Levin relies on verb similarity referring to syntax-semantic alternation behaviour , WordNet uses synonymy , and FrameNet relies on situation-based agreement as de ned in Fillmore’s frame semantics ( Fillmore , 1982 ) .</sentence>
				<definiendum id="0">e.g. Levin</definiendum>
				<definiendum id="1">FrameNet</definiendum>
				<definiens id="0">relies on verb similarity referring to syntax-semantic alternation behaviour</definiens>
			</definition>
			<definition id="1">
				<sentence>The different results for the two resources are due to their semantic background ( i.e. capturing synonymy vs. situation-based agreement ) , the numbers of verbs , and the degrees of ambiguity ( an average of 1.6 senses per verb in FrameNet , as compared to 1.3 senses in GermaNet ) .</sentence>
				<definiendum id="0">semantic background</definiendum>
				<definiens id="0">an average of 1.6 senses per verb in FrameNet</definiens>
			</definition>
			<definition id="2">
				<sentence>ment NPs and PPs ( as separate sets and together ) , and in addition we checked verb-noun pairs in the most common speci c NP functions : n refers to the ( nominative ) intransitive subject , na to the transitive subject , and na to the transitive ( accusative ) object .</sentence>
				<definiendum id="0">PPs</definiendum>
				<definiens id="0">separate sets and together ) , and in addition we checked verb-noun pairs in the most common speci c NP functions : n refers to the ( nominative ) intransitive subject , na to the transitive subject , and na to the transitive ( accusative ) object</definiens>
			</definition>
			<definition id="3">
				<sentence>Interestingly , the GermaNet clusterings behave in the opposite direction .</sentence>
				<definiendum id="0">GermaNet clusterings</definiendum>
				<definiens id="0">behave in the opposite direction</definiens>
			</definition>
			<definition id="4">
				<sentence>Comparing the grammar-based relations with each other shows that for the assoc-classes using all NPs is better than restricting the NPs to ( subject ) functions , and using both NPs and PPs is best ; similarly for the FrameNet classes where using all NPs is the second best results ( but adverbs ) .</sentence>
				<definiendum id="0">PPs</definiendum>
				<definiendum id="1">NPs</definiendum>
				<definiens id="0">the second best results</definiens>
			</definition>
</paper>

		<paper id="3004">
			<definition id="0">
				<sentence>FERRET uses a large collection of QUAB question-answerpairsinordertoprovideuserswith suggestionsofnewresearchtopicsthatcouldbeexplored over the course of a dialogue .</sentence>
				<definiendum id="0">FERRET</definiendum>
				<definiens id="0">uses a large collection of QUAB question-answerpairsinordertoprovideuserswith suggestionsofnewresearchtopicsthatcouldbeexplored over the course of a dialogue</definiens>
			</definition>
			<definition id="1">
				<sentence>FERRET uses a version of LCC’s PALANTIR questionanswering system ( Harabagiu et al. , 2005b ) in order to provide answers to questions in documents .</sentence>
				<definiendum id="0">FERRET</definiendum>
				<definiens id="0">uses a version of LCC’s PALANTIR questionanswering system ( Harabagiu et al. , 2005b ) in order to provide answers to questions in documents</definiens>
			</definition>
			<definition id="2">
				<sentence>Conceptual similarity ( as firstdescribedin ( Harabagiuetal.,2005a ) ) iscalculated using the version of the cosine similarity formulapresentedinFigure5 .</sentence>
				<definiendum id="0">Conceptual similarity</definiendum>
			</definition>
			<definition id="3">
				<sentence>As expected , experts believed QUABs to be significantly ( p &lt; 0.05 ) lessrelevantthannovices , who found approximately 38.12 % of QUABs to be relevant to the original question submitted by a user .</sentence>
				<definiendum id="0">QUABs</definiendum>
				<definiens id="0">to be significantly ( p &lt; 0.05 ) lessrelevantthannovices , who found approximately 38.12 % of QUABs to be relevant to the original question submitted by a user</definiens>
			</definition>
</paper>

		<paper id="0303">
			<definition id="0">
				<sentence>A is classified into one of the following three categories depending on the value of xA : • if A appears in the pros more frequently than in the cons , xA is a positive number , • if A appears in the pros and cons equally often , xA is zero , • if A appears in the cons more frequently than in the pros , xA is a negative number .</sentence>
				<definiendum id="0">xA</definiendum>
				<definiendum id="1">xA</definiendum>
				<definiendum id="2">xA</definiendum>
				<definiens id="0">a positive number</definiens>
				<definiens id="1">a negative number</definiens>
			</definition>
			<definition id="1">
				<sentence>Recall is the ratio of the number of correct answers extracted automatically to the total number of correct answers .</sentence>
				<definiendum id="0">Recall</definiendum>
			</definition>
			<definition id="2">
				<sentence>Precision is the ratio of the number of correct answers extracted automatically to the total number of points at issue extracted automatically .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio of the number of correct answers extracted automatically to the total number of points at issue extracted automatically</definiens>
			</definition>
			<definition id="3">
				<sentence>The accuracy is the ratio of the number of correct answers to the number of opinions presented by the method under evaluation .</sentence>
				<definiendum id="0">accuracy</definiendum>
				<definiens id="0">the ratio of the number of correct answers to the number of opinions presented by the method under evaluation</definiens>
			</definition>
</paper>

		<paper id="3601">
			<definition id="0">
				<sentence>In this context , an SD translator consists of two components , a sourcelanguage parser and a recursive converter which is usually modeled as a top-down tree-to-string transducer ( G´ecseg and Steinby , 1984 ) .</sentence>
				<definiendum id="0">SD translator</definiendum>
			</definition>
			<definition id="1">
				<sentence>For example , Shieber and Schabes ( 1990 ) introduce synchronous tree-adjoining grammar ( STAG ) and Eisner ( 2003 ) uses a synchronous tree-substitution grammar ( STSG ) , which is a restricted version of STAG with no adjunctions .</sentence>
				<definiendum id="0">STAG</definiendum>
				<definiendum id="1">synchronous tree-substitution grammar</definiendum>
				<definiendum id="2">STSG</definiendum>
			</definition>
			<definition id="2">
				<sentence>→x1 x2 ◦ 2 Then , the rule r2 grabs the whole sub-tree for “the gunman” and translates it as a phrase : ( r2 ) NP-C ( DT ( the ) NN ( gunman ) ) →qiangshou Now we get a “partial Chinese , partial English” sentence “qiangshou VP ◦” as shown in Fig .</sentence>
				<definiendum id="0">DT</definiendum>
				<definiens id="0">the whole sub-tree for “the gunman” and translates it as a phrase : ( r2 ) NP-C</definiens>
			</definition>
			<definition id="3">
				<sentence>By contrast , our model applies rule r3 only if A is a past participle ( VBN ) and B is a noun phrase ( NP-C ) .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">a noun phrase ( NP-C )</definiens>
			</definition>
			<definition id="4">
				<sentence>Although they share with this work the basic motivations and similar speed-up , it is difficult to specify re-ordering information within dependency elementary structures , so they either resort to heuristics ( Lin ) or a separate ordering model for linearization ( the other two 3 works ) .2 Our approach , in contrast , explicitly models the re-ordering of sub-trees within individual transfer rules .</sentence>
				<definiendum id="0">linearization</definiendum>
				<definiens id="0">difficult to specify re-ordering information within dependency elementary structures</definiens>
			</definition>
			<definition id="5">
				<sentence>A 1-xRLNs transducer is a tuple ( N , Σ , ∆ , R ) where N is the set of nonterminals , Σ is the input alphabet , ∆ is the output alphabet , and R is a set of rules .</sentence>
				<definiendum id="0">1-xRLNs transducer</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a tuple ( N , Σ , ∆ , R ) where N is the set of nonterminals</definiens>
				<definiens id="1">a set of rules</definiens>
			</definition>
			<definition id="6">
				<sentence>r1 r2 r3 r4 r5 r1 r2 r6 r4 r7 r5 ( a ) ( b ) Figure 4 : ( a ) the derivation in Figure 3 ; ( b ) another derviation producing the same output by replacing r3 with r6 and r7 , which provides another way of translating the passive construction : ( r6 ) VP ( VBD ( was ) VP-C ( x1 : VBN x2 : PP ) ) →x2 x1 ( r7 ) PP ( IN ( by ) x1 : NP-C ) →bei x1 tree into a target-language string , with each step applying one tranduction rule .</sentence>
				<definiendum id="0">passive construction</definiendum>
				<definiens id="0">provides another way of translating the</definiens>
			</definition>
			<definition id="7">
				<sentence>A derivation d , its source and target projections , noted E ( d ) and C ( d ) respectively , are recursively defined as follows : then d = r is a derivation , whereE ( d ) = t and C ( d ) = s ; derivation with the root symbol of its source projection matches the corresponding substitution node in r , i.e. , ρ ( E ( di ) ) = φ ( xi ) , then d = r ( d1 , ... , dm ) is also a derivation , where E ( d ) = [ xi mapsto→ E ( di ) ] t and C ( d ) = [ xi mapsto→ C ( di ) ] s. Note that we use a short-hand notation [ ximapsto→yi ] t to denote the result of substituting each xi with yi in t , where xi ranges over all variables in t. For example , Figure 4 shows two derivations for the sentence pair in Example ( 1 ) .</sentence>
				<definiendum id="0">ρ ( E</definiendum>
				<definiens id="0">its source and target projections , noted E ( d ) and C ( d ) respectively , are recursively defined as follows : then d = r is a derivation , whereE ( d ) = t and C ( d ) = s ; derivation with the root symbol of its source projection matches the corresponding substitution node in r</definiens>
			</definition>
			<definition id="8">
				<sentence>4 Departing from the conventional noisy-channel approach of Brown et al. ( 1993 ) , our basic model is a direct one : c∗ = argmax c Pr ( c|e ) ( 2 ) where e is the English input string and c∗ is the best Chinese translation according to the translation model Pr ( c | e ) .</sentence>
				<definiendum id="0">basic model</definiendum>
				<definiendum id="1">e</definiendum>
				<definiens id="0">the best Chinese translation according to the translation model Pr ( c | e )</definiens>
			</definition>
			<definition id="9">
				<sentence>Similarly , we now marginalize over all derivations D ( τ∗ ) = { d|E ( d ) = τ∗ } that translates English tree τ into some Chinese string and apply the Viterbi approximation again to search for the best derivation d∗ : c∗ =C ( d∗ ) =C ( argmax d∈D ( τ∗ ) Pr ( d ) ) ( 6 ) Assuming different rules in a derivation are applied independently , we approximate Pr ( d ) as Pr ( d ) = productdisplay r∈d Pr ( r ) ( 7 ) where the probability Pr ( r ) of the rule r is estimated by conditioning on the root symbol ρ ( t ( r ) ) : Pr ( r ) = Pr ( t ( r ) , s ( r ) |ρ ( t ( r ) ) ) = c ( r ) summationtext rprime : ρ ( t ( rprime ) ) =ρ ( t ( r ) ) c ( rprime ) ( 8 ) where c ( r ) is the count ( or frequency ) of rule r in the training data .</sentence>
				<definiendum id="0">=C</definiendum>
				<definiendum id="1">ρ ( t</definiendum>
				<definiens id="0">the count ( or frequency ) of rule r in the training data</definiens>
			</definition>
			<definition id="10">
				<sentence>Following Och and Ney ( 2002 ) , we extend the direct model into a general log-linear framework in order to incorporate other features : c∗ = argmax c Pr ( c|e ) α·Pr ( c ) β·e−λ|c| ( 9 ) where Pr ( c ) is the language model and e−λ|c| is the length penalty term based on |c| , the length of the translation .</sentence>
				<definiendum id="0">Pr ( c )</definiendum>
				<definiendum id="1">e−λ|c|</definiendum>
				<definiens id="0">the language model and</definiens>
				<definiens id="1">the length penalty term based on |c| , the length of the translation</definiens>
			</definition>
			<definition id="11">
				<sentence>3 : return cache [ η ] 4 : best←0 5 : for r∈Rdo triangleright try each rule r 6 : matched , sublist←PATTERNMATCH ( t ( r ) , η ) triangleright tree pattern matching 7 : if matched then triangleright if matched , sublist contains a list of matched subtrees 8 : prob←Pr ( r ) triangleright the probability of rule r 9 : for ηi∈sublist do 10 : pi , si←TRANSLATE ( ηi ) triangleright recursively solve each sub-problem 11 : prob←prob·pi 12 : if prob &gt; best then 13 : best←prob 14 : str← [ ximapsto→si ] s ( r ) triangleright plug in the results 15 : cache [ η ] ←best , str triangleright caching the best solution for future use 16 : return cache [ η ] triangleright returns the best string with its prob .</sentence>
				<definiendum id="0">pi</definiendum>
				<definiens id="0">return cache [ η ] triangleright returns the best string with its prob</definiens>
			</definition>
			<definition id="12">
				<sentence>Pharaoh : a beam search decoder for phrase-based statistical machine translation models .</sentence>
				<definiendum id="0">Pharaoh</definiendum>
				<definiens id="0">a beam search decoder for phrase-based statistical machine translation models</definiens>
			</definition>
			<definition id="13">
				<sentence>Srilm : an extensible language modeling toolkit .</sentence>
				<definiendum id="0">Srilm</definiendum>
				<definiens id="0">an extensible language modeling toolkit</definiens>
			</definition>
</paper>

		<paper id="2203">
</paper>

		<paper id="0117">
			<definition id="0">
				<sentence>The NER system uses a hybrid algorithm based on Class-based language model and rule-based knowledge .</sentence>
				<definiendum id="0">NER system</definiendum>
				<definiens id="0">uses a hybrid algorithm based on Class-based language model and rule-based knowledge</definiens>
			</definition>
</paper>

		<paper id="1505">
			<definition id="0">
				<sentence>In this tree , FP is a small clause of the copula from which the two DPs being equated originate .</sentence>
				<definiendum id="0">FP</definiendum>
				<definiens id="0">a small clause of the copula from which the two DPs being equated originate</definiens>
			</definition>
			<definition id="1">
				<sentence>In the semantic trees , F stands for formulas , R for predicates and T for terms .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">stands for formulas , R for predicates and T for terms</definiens>
			</definition>
			<definition id="2">
				<sentence>( αprimeit ) and ( βprimewho won ) in the multi-component set in Figure 1 together define semantics of quantification , where the former contributes the argument variable and the latter the restriction and scope , and ( αprimewas ) represents the semantics of equative sentences .</sentence>
				<definiendum id="0">αprimewas )</definiendum>
				<definiens id="0">the semantics of equative sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>Further , the semantics of the two trees is defined as a definite quantified phrase , capturing the intuition that they form a semantic unit as a definite description .</sentence>
				<definiendum id="0">the semantics of the two trees</definiendum>
				<definiens id="0">a definite quantified phrase , capturing the intuition that they form a semantic unit as a definite description</definiens>
			</definition>
</paper>

		<paper id="2919">
			<definition id="0">
				<sentence>The IDF weight fw for a word w occurring in a corpus is given by : fw = log parenleftbiggN nw parenrightbigg where N is the total number of documents in the corpus and nw is the total number of documents containing w. Now , for each context segment c ∈ C , we select a dominating word dc given by dc = argmaxw∈c fw There is exactly one dominating word for each c ∈ C. All dominating words for contexts in C form multiset M. Let mw be the multiplicity of the dominating word w in M. We sort M by decreasing mw and select the top n tokens from this list as potential trigger words .</sentence>
				<definiendum id="0">IDF weight fw</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">nw</definiendum>
				<definiens id="0">the total number of documents in the corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>An automaton A is k-reversible iff ( 1 ) A is deterministic and ( 2 ) Ar is deterministic with k tokens of lookahead , where Ar is the automaton obtained by reversing the transitions of A. Wrapper induction using k-reversible grammar is discussed by Chidlovskii ( 2000 ) .</sentence>
				<definiendum id="0">Ar</definiendum>
				<definiendum id="1">Ar</definiendum>
				<definiens id="0">deterministic with k tokens of lookahead , where</definiens>
			</definition>
</paper>

		<paper id="2810">
			<definition id="0">
				<sentence>Ourunderlyingassumption here is that there is a generalagreementon the kindofinformationthatneedstobeincludedinthe pagesof differenttypesof topicssuchas a biography of a person , andthedefinitionanddescription of a conceptetc. , and that this agreementis to a consderableextent“materialized”in thehypertext links ( andtheiranchortexts ) in Wikipedia .</sentence>
				<definiendum id="0">Ourunderlyingassumption</definiendum>
				<definiens id="0">a biography of a person , andthedefinitionanddescription of a conceptetc. , and that this agreementis to a consderableextent“materialized”in thehypertext links ( andtheiranchortexts ) in Wikipedia</definiens>
			</definition>
			<definition id="1">
				<sentence>Wikipedia uses a redirectionfacility to map several titles into a canonicalform .</sentence>
				<definiendum id="0">Wikipedia</definiendum>
				<definiens id="0">uses a redirectionfacility to map several titles into a canonicalform</definiens>
			</definition>
</paper>

		<paper id="2717">
			<definition id="0">
				<sentence>A parallel treebank consists of syntactically annotated sentences in two or more languages , taken from translated ( i.e. parallel ) documents .</sentence>
				<definiendum id="0">parallel treebank</definiendum>
				<definiens id="0">consists of syntactically annotated sentences in two or more languages , taken from translated ( i.e. parallel ) documents</definiens>
			</definition>
			<definition id="1">
				<sentence>Parallel treebanks can be used as training or evaluation corpora for word and phrase alignment , as input for example-based machine translation ( EBMT ) , as training corpora for transfer rules , or for translation studies .</sentence>
				<definiendum id="0">Parallel treebanks</definiendum>
				<definiens id="0">training or evaluation corpora for word and phrase alignment , as input for example-based machine translation ( EBMT ) , as training corpora for transfer rules , or for translation studies</definiens>
			</definition>
			<definition id="2">
				<sentence>TIGER-XML is a line-based ( i.e. not nested and thus database-friendly ) representation for graph structures , which includes syntax trees with node labels , edge labels , multiple features on the word level and even crossing edges.3 In a TIGER-XML graph each leaf ( = token ) and each node ( = linguistic constituent ) has a unique identifier which is prefixed with the sentence number .</sentence>
				<definiendum id="0">TIGER-XML</definiendum>
				<definiens id="0">includes syntax trees with node labels , edge labels , multiple features on the word level and even crossing edges.3 In a TIGER-XML graph each leaf ( = token ) and each node ( = linguistic constituent ) has a unique identifier which is prefixed with the sentence number</definiens>
			</definition>
			<definition id="3">
				<sentence>The phrase consists of word number 4 , which is the preposition in , plus node 502 which in turn is marked as an NP ( noun phrase ) , consisting of the words 5 and 6 .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">consists of word number 4 , which is the preposition in , plus node 502 which in turn is marked as an NP ( noun phrase ) , consisting of the words 5 and 6</definiens>
			</definition>
			<definition id="4">
				<sentence>TIGER-XML is a powerful representation format and is typically used with constituent symbols on the nodes and functional information on the edge labels .</sentence>
				<definiendum id="0">TIGER-XML</definiendum>
				<definiens id="0">a powerful representation format and is typically used with constituent symbols on the nodes and functional information on the edge labels</definiens>
			</definition>
			<definition id="5">
				<sentence>The alignment format allows alignments to be specified between an arbitrary number of nodes , for example nodes from three languages .</sentence>
				<definiendum id="0">alignment format</definiendum>
				<definiens id="0">allows alignments to be specified between an arbitrary number of nodes</definiens>
			</definition>
			<definition id="6">
				<sentence>The TreeAligner allows for m : n sentence alignment , word alignment and node alignment .</sentence>
				<definiendum id="0">TreeAligner</definiendum>
				<definiens id="0">allows for m : n sentence alignment , word alignment and node alignment</definiens>
			</definition>
</paper>

		<paper id="1403">
			<definition id="0">
				<sentence>To specify the desired paraphrase space , one may either provide an input logical form that underspecifies certain realization choices , or include explicit disjunctions in the input LF ( or both ) .</sentence>
				<definiendum id="0">LF</definiendum>
				<definiens id="0">underspecifies certain realization choices , or include explicit disjunctions in the input</definiens>
			</definition>
			<definition id="1">
				<sentence>Obtaining the alternatives and optional parts of the LF is a bit more involved .</sentence>
				<definiendum id="0">LF</definiendum>
				<definiens id="0">a bit more involved</definiens>
			</definition>
</paper>

		<paper id="2208">
			<definition id="0">
				<sentence>KnowItAll uses a set of generic extraction patterns , and automatically instantiates rules by combining these patterns with user supplied relation labels .</sentence>
				<definiendum id="0">KnowItAll</definiendum>
				<definiens id="0">uses a set of generic extraction patterns</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , KnowItAll has patterns for a generic “of” relation : NP1 ’s BOrelationBQ , NP2 NP2 , BOrelationBQ of NP1 where NP1 and NP2 are simple noun phrases that extract values of argument1 and argument2 of a relation , and BOrelationBQ is a user-supplied string associated with the relation .</sentence>
				<definiendum id="0">KnowItAll</definiendum>
				<definiendum id="1">NP2</definiendum>
				<definiendum id="2">BOrelationBQ</definiendum>
				<definiens id="0">simple noun phrases that extract values of argument1 and argument2 of a relation</definiens>
				<definiens id="1">a user-supplied string associated with the relation</definiens>
			</definition>
			<definition id="2">
				<sentence>We introduce Relation-dependent NER ( Relation NER ) , which trains an off-the-shelf supervised NER based on CRF ( Lafferty et al. , 2001 ) with bootstrapping .</sentence>
				<definiendum id="0">Relation-dependent NER</definiendum>
				<definiens id="0">trains an off-the-shelf supervised NER based on CRF ( Lafferty et al. , 2001 ) with bootstrapping</definiens>
			</definition>
			<definition id="3">
				<sentence>SPL : a simple string pattern learning method .</sentence>
				<definiendum id="0">SPL</definiendum>
				<definiens id="0">a simple string pattern learning method</definiens>
			</definition>
			<definition id="4">
				<sentence>LRPL : a less restrictive pattern learning method .</sentence>
				<definiendum id="0">LRPL</definiendum>
				<definiens id="0">a less restrictive pattern learning method</definiens>
			</definition>
			<definition id="5">
				<sentence>SPL tabulates the occurrence of such patterns in the set of positive training sentences ( all sentences from the reservoir that contain both argument values from a seed tuple in either order ) , and also tabulates their occurrence in negative training sentences .</sentence>
				<definiendum id="0">SPL</definiendum>
				<definiens id="0">tabulates the occurrence of such patterns in the set of positive training sentences ( all sentences from the reservoir that contain both argument values from a seed tuple in either order ) , and also tabulates their occurrence in negative training sentences</definiens>
			</definition>
			<definition id="6">
				<sentence>SPL selects the best patterns as follows : same middle string .</sentence>
				<definiendum id="0">SPL</definiendum>
				<definiens id="0">selects the best patterns as follows : same middle string</definiens>
			</definition>
			<definition id="7">
				<sentence>where CB D4D3D7CXD8CXDACT B4D4B5 is a set of sentences that match pattern D4 and include both argument values of a seed tuple .</sentence>
				<definiendum id="0">CB D4D3D7CXD8CXDACT B4D4B5</definiendum>
				<definiens id="0">a set of sentences that match pattern D4 and include both argument values of a seed tuple</definiens>
			</definition>
			<definition id="8">
				<sentence>CB D2CTCVCPD8CXDACT B4D4B5 is a set of sentences that match D4 and include just one argument value of a seed tuple ( e.g. just a company or a person for CeoOf ) .</sentence>
				<definiendum id="0">CB D2CTCVCPD8CXDACT B4D4B5</definiendum>
				<definiens id="0">a set of sentences that match</definiens>
			</definition>
			<definition id="9">
				<sentence>AB is a constant for smoothing .</sentence>
				<definiendum id="0">AB</definiendum>
				<definiens id="0">a constant for smoothing</definiens>
			</definition>
			<definition id="10">
				<sentence>Rather than using exact string match on a simple sequence of tokens , LRPL uses a combination of bag of words and immediately adjacent token .</sentence>
				<definiendum id="0">LRPL</definiendum>
				<definiens id="0">uses a combination of bag of words and immediately adjacent token</definiens>
			</definition>
			<definition id="11">
				<sentence>Here is an example of how LRPL represents the context of a training sentence with window size set to 4 .</sentence>
				<definiendum id="0">LRPL</definiendum>
				<definiens id="0">the context of a training sentence with window size set to 4</definiens>
			</definition>
			<definition id="12">
				<sentence>LRPL trains a supervised NER in bootstrapping for extracting candidate entities .</sentence>
				<definiendum id="0">LRPL</definiendum>
				<definiens id="0">trains a supervised NER in bootstrapping for extracting candidate entities</definiens>
			</definition>
			<definition id="13">
				<sentence>LRPL trains the Relational NER from seed tuples provided by the baseline KnowItAll system and unlabeled sentences in the reservoir .</sentence>
				<definiendum id="0">LRPL</definiendum>
				<definiens id="0">trains the Relational NER from seed tuples provided by the baseline KnowItAll system and unlabeled sentences in the reservoir</definiens>
			</definition>
			<definition id="14">
				<sentence>Recognizer Relation NER leverages an off-the-shelf supervised NER , based on Conditional Random Fields ( CRF ) .</sentence>
				<definiendum id="0">Recognizer Relation NER</definiendum>
			</definition>
			<definition id="15">
				<sentence>In Figure 1 , ContextRepresentationGenerator generates extended bag of words contexts , from entity annotated sentences , and classifies the contexts into two classes : training contexts BV D8D6CPCXD2 ( if their entity values and their orders match a seed tuple ) and test contexts BV D8CTD7D8 ( otherwise ) .</sentence>
				<definiendum id="0">ContextRepresentationGenerator</definiendum>
				<definiens id="0">generates extended bag of words contexts , from entity annotated sentences , and classifies the contexts into two classes : training contexts BV D8D6CPCXD2 ( if their entity values and their orders match a seed tuple</definiens>
			</definition>
			<definition id="16">
				<sentence>TrainConfidenceEstimator clusters BV D8D6CPCXD2 based on the match score between contexts , and generates a rule from each cluster , that has average vectors over contexts belonging to the cluster .</sentence>
				<definiendum id="0">TrainConfidenceEstimator clusters BV D8D6CPCXD2</definiendum>
				<definiens id="0">based on the match score between contexts , and generates a rule from each cluster , that has average vectors over contexts belonging to the cluster</definiens>
			</definition>
			<definition id="17">
				<sentence>C5B4CR CX BNCR CY B5 BP CG D7BND8 DB D7D8 CRD3D7B4CR CXD7D8 BNCR CYD7D8 B5 ( 2 ) where , D7 is the index of left , middle , or right contexts .</sentence>
				<definiendum id="0">D7</definiendum>
				<definiens id="0">the index of left , middle , or right contexts</definiens>
			</definition>
			<definition id="18">
				<sentence>D8 is the index of left adjacent , right adjacent , or other tokens .</sentence>
				<definiendum id="0">D8</definiendum>
				<definiens id="0">the index of left adjacent , right adjacent , or other tokens</definiens>
			</definition>
			<definition id="19">
				<sentence>DB D7D8 is the weight corresponding to the context vector indexed by D7 and D8 .</sentence>
				<definiendum id="0">DB D7D8</definiendum>
				<definiens id="0">the weight corresponding to the context vector indexed by D7 and D8</definiens>
			</definition>
			<definition id="20">
				<sentence>CXCY inBV D8CTD7D8 , identifies the best match rule D6A3B4CR CXCY B5 , based on the match score between CR CXCY and each rule D6 .</sentence>
				<definiendum id="0">CXCY inBV D8CTD7D8</definiendum>
				<definiens id="0">identifies the best match rule D6A3B4CR CXCY B5 , based on the match score between CR CXCY and each rule D6</definiens>
			</definition>
			<definition id="21">
				<sentence>CR CXCY is the CYth context that includes tuple D8 CX .</sentence>
				<definiendum id="0">CR CXCY</definiendum>
				<definiens id="0">the CYth context that includes tuple D8 CX</definiens>
			</definition>
			<definition id="22">
				<sentence>D6 A3 B4CR CXCY B5 BP argmax D6 C5B4D6BNCR CXCY B5 ( 3 ) 59 D7 B5 BP BD for all D8 D7 , where D8 D7 is a seed tuple .</sentence>
				<definiendum id="0">D8 D7</definiendum>
				<definiens id="0">a seed tuple</definiens>
			</definition>
			<definition id="23">
				<sentence>CABVB4D6 CQ B5C5B4D6 CQ BNCR CXCQ B5 BP D1CPDC CR CABVB4D6 A3 B4CRB5B5C5B4D6 A3 B4CRB5BNCRB5 ( 7 ) where CR CXCQ denotes the context of tuple D8 CX that matches a baseline pattern , and D6 CQ is any baseline pattern .</sentence>
				<definiendum id="0">CR CXCQ</definiendum>
				<definiendum id="1">D6 CQ</definiendum>
				<definiens id="0">the context of tuple D8 CX that matches a baseline pattern , and</definiens>
				<definiens id="1">any baseline pattern</definiens>
			</definition>
			<definition id="24">
				<sentence>For consistency , SPL employs the same assessment methods with LRPL .</sentence>
				<definiendum id="0">SPL</definiendum>
				<definiens id="0">employs the same assessment methods with LRPL</definiens>
			</definition>
			<definition id="25">
				<sentence>trast , LRPL achieves higher recall for Acquisition and Merger .</sentence>
				<definiendum id="0">LRPL</definiendum>
				<definiens id="0">achieves higher recall for Acquisition and Merger</definiens>
			</definition>
			<definition id="26">
				<sentence>CACTCRCPD0D0 CPD6CV BP CYBX CTDCD8D6CPCRD8CTCS CK BX D8D6D9CTBNCPD6CV CY CYBX D8D6D9CTBNCPD6CV CY ( 8 ) C8D6CTCRCXD7CXD3D2 CPD6CV BP CYBX CTDCD8D6CPCRD8CTCS CK BX D8D6D9CTBNCPD6CV CY CYBX CTDCD8D6CPCRD8CTCS CY ( 9 ) where , BX D8D6D9CTBNCPD6CV is a set of true entities that have an argument type of a target relation .</sentence>
				<definiendum id="0">CACTCRCPD0D0 CPD6CV BP CYBX CTDCD8D6CPCRD8CTCS CK BX D8D6D9CTBNCPD6CV CY CYBX D8D6D9CTBNCPD6CV CY</definiendum>
				<definiendum id="1">BX D8D6D9CTBNCPD6CV</definiendum>
				<definiens id="0">a set of true entities that have an argument type of a target relation</definiens>
			</definition>
			<definition id="27">
				<sentence>BX CTDCD8D6CPCRD8CTCS is a set of entities extracted as an argument .</sentence>
				<definiendum id="0">BX CTDCD8D6CPCRD8CTCS</definiendum>
			</definition>
			<definition id="28">
				<sentence>C8D6CTCRCXD7CXD3D2 CVCTD2CTD6CXCR BP CYBX CTDCD8D6CPCRD8CTCS CK BX D8D6D9CTBNCVCTD2CTD6CXCR CY CYBX CTDCD8D6CPCRD8CTCS CY ( 10 ) where , BX D8D6D9CTBNCVCTD2CTD6CXCR is a set of true entities that have a generic type 2 .</sentence>
				<definiendum id="0">C8D6CTCRCXD7CXD3D2 CVCTD2CTD6CXCR BP CYBX CTDCD8D6CPCRD8CTCS CK BX D8D6D9CTBNCVCTD2CTD6CXCR CY CYBX CTDCD8D6CPCRD8CTCS CY</definiendum>
				<definiendum id="1">BX D8D6D9CTBNCVCTD2CTD6CXCR</definiendum>
				<definiens id="0">a set of true entities that have a generic type 2</definiens>
			</definition>
			<definition id="29">
				<sentence>SPL is a similar approach to DIPRE ( Brin , 1998 ) DIPRE uses a pre-defined simple regular expression to identify argument values .</sentence>
				<definiendum id="0">SPL</definiendum>
				<definiens id="0">a similar approach to DIPRE ( Brin , 1998 ) DIPRE uses a pre-defined simple regular expression to identify argument values</definiens>
			</definition>
			<definition id="30">
				<sentence>LRPL is similar to SnowBall ( Agichtein , 2005 ) , which employs a generic NER , and reported that most errors come from NER errors .</sentence>
				<definiendum id="0">LRPL</definiendum>
				<definiens id="0">employs a generic NER</definiens>
			</definition>
			<definition id="31">
				<sentence>This paper describes two bootstrapping strategies , SPL , which learns simple string patterns , and LRPL , which trains Relation NER and uses it with less restrictive patterns .</sentence>
				<definiendum id="0">SPL</definiendum>
				<definiendum id="1">LRPL</definiendum>
				<definiens id="0">learns simple string patterns</definiens>
				<definiens id="1">trains Relation NER and uses it with less restrictive patterns</definiens>
			</definition>
			<definition id="32">
				<sentence>LRPL works better than SPL for MayorOf relation by avoiding several errors caused by the tuples that co-occur with a short strict context , but have a wrong type entity value .</sentence>
				<definiendum id="0">LRPL</definiendum>
				<definiens id="0">works better than SPL for MayorOf relation by avoiding several errors caused by the tuples that co-occur with a short strict context</definiens>
			</definition>
</paper>

		<paper id="1308">
			<definition id="0">
				<sentence>The resolution algorithm consists of two phases : the referential space when interpreting a referring expression .</sentence>
				<definiendum id="0">resolution algorithm</definiendum>
				<definiens id="0">consists of two phases : the referential space when interpreting a referring expression</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 2 : A domain tree built from a scenario above ( focus in bold ) The operations are the following : U1 : Hotel1 becomes a subdomain of Hotel*all which gains focus in Hotel+ .</sentence>
				<definiendum id="0">Hotel1</definiendum>
				<definiens id="0">becomes a subdomain of Hotel*all which gains focus in Hotel+</definiens>
			</definition>
</paper>

		<paper id="0135">
</paper>

		<paper id="2113">
			<definition id="0">
				<sentence>Bengali is the fifth language in the world in terms of the number of native speakers and is an important language in India .</sentence>
				<definiendum id="0">Bengali</definiendum>
				<definiens id="0">the fifth language in the world in terms of the number of native speakers and is an important language in India</definiens>
			</definition>
			<definition id="1">
				<sentence>Bengali is the fifth language in the world in terms of the number of native speakers and is an important language in India .</sentence>
				<definiendum id="0">Bengali</definiendum>
				<definiens id="0">the fifth language in the world in terms of the number of native speakers and is an important language in India</definiens>
			</definition>
			<definition id="2">
				<sentence>A shallow parser identifies the constituent phrases of the source language sentence and tags them to encode all relevant information that might be needed to translate these phrases and perhaps resolve ambiguities in other phrases .</sentence>
				<definiendum id="0">shallow parser</definiendum>
				<definiens id="0">identifies the constituent phrases of the source language sentence and tags them to encode all relevant information that might be needed to translate these phrases</definiens>
			</definition>
			<definition id="3">
				<sentence>A PP is a group of words containing a preposition , an object of the preposition , and any modifiers of the object .</sentence>
				<definiendum id="0">PP</definiendum>
			</definition>
			<definition id="4">
				<sentence>åa LãXÌ [ ý % çãG åYgì»K÷ç_ ( se [ he ] jan-er age [ John before ] pouchhalo [ reached ] ) From the WordNet , the system acquires the semantic information that ‘door’ is a hyponym of ‘artifact’ , whereas ‘evening’ and ‘me’ ( which represents a person ) are not .</sentence>
				<definiendum id="0">çãG åYgì»K÷ç_</definiendum>
				<definiens id="0">the semantic information that ‘door’ is a hyponym of ‘artifact’ , whereas ‘evening’ and ‘me’ ( which represents a person</definiens>
			</definition>
</paper>

		<paper id="2305">
</paper>

		<paper id="1806">
			<definition id="0">
				<sentence>The Temporal Action Logic ( TAL ) is a nonmonotonic temporal logic developed specifically for reasoning about actions and dynamical domains .</sentence>
				<definiendum id="0">Temporal Action Logic ( TAL )</definiendum>
				<definiens id="0">a nonmonotonic temporal logic developed specifically for reasoning about actions and dynamical domains</definiens>
			</definition>
			<definition id="1">
				<sentence>A persistence statement ( labelled per1 ) constrains the fluents alive and loaded’s values to persist unless they are affected by some action .</sentence>
				<definiendum id="0">persistence statement</definiendum>
				<definiens id="0">constrains the fluents alive and loaded’s values to persist unless they are affected by some action</definiens>
			</definition>
			<definition id="2">
				<sentence>NL1 carries on an interactive natural language text dialogue with the user , executing commands and answering queries about a simulated blocksworld .</sentence>
				<definiendum id="0">NL1</definiendum>
				<definiens id="0">carries on an interactive natural language text dialogue with the user</definiens>
			</definition>
			<definition id="3">
				<sentence>User interaction consists of natural language input and output through a minimal user interface in the form of a text top-loop .</sentence>
				<definiendum id="0">User interaction</definiendum>
				<definiens id="0">consists of natural language input and output through a minimal user interface in the form of a text top-loop</definiens>
			</definition>
			<definition id="4">
				<sentence>The LKB chart parser uses a Head-driven Phrase Structure Grammar ( HPSG ) , 29 KRAQ06 based on the grammar in ( Sag et al. , 2003 ) , to parse the input text string and build a feature structure representation .</sentence>
				<definiendum id="0">LKB chart parser</definiendum>
				<definiens id="0">uses a Head-driven Phrase Structure Grammar ( HPSG ) , 29 KRAQ06 based on the grammar in ( Sag et al. , 2003</definiens>
			</definition>
			<definition id="5">
				<sentence>( domain block ( b1 b2 b3 ) ) ( domain table ( table1 ) ) ( domain surface ( block table ) ) ( fluent ( holding block ) boolean ) ( fluent ( on block surface ) boolean ) ( action ( pickup block ) ) ( action ( putdown block surface ) ) ( variable t time ) ( variable block1 block ) ( variable surface1 surface ) ( variable surface2 surface ) ( per ( forall ( t block1 surface1 ) ( and ( per t ( holding block1 ) ) ( per t ( on block1 surface1 ) ) ) ) ) ( dep ( forall ( t block1 surface1 surface2 ) ( - &gt; ( and ( time t ( on block1 surface1 ) ) ( not ( = surface1 surface2 ) ) ) ( time t ( not ( on block1 surface2 ) ) ) ) ) ) ( acs t1 t2 ( pickup block1 ) ( and ( r ( oc t1 t2 ) ( holding block1 ) ) ( forall ( surface1 ) ( r ( oc t1 t2 ) ( not ( on block1 surface1 ) ) ) ) ) ) ( acs t1 t2 ( putdown block1 surface1 ) ( r ( oc t1 t2 ) ( and ( not ( holding block1 ) ) ( on block1 surface1 ) ) ) ) ( obs ( forall ( block1 ) ( time 0 ( not ( holding block1 ) ) ) ) ) ( occ 0 1 ( pickup b3 ) ) ( occ 1 2 ( putdown b3 table1 ) ) Figure 7 : TAL representation of the blocksworld .</sentence>
				<definiendum id="0">surface2 ) ) ) ) ) ) ( acs t1 t2 ( pickup block1 )</definiendum>
				<definiendum id="1">surface1 ) ( r ( oc t1</definiendum>
				<definiens id="0">t1 t2 ( putdown block1 surface1 ) ( r ( oc t1 t2 ) ( and ( not ( holding block1 ) ) ( on block1 surface1 ) ) ) ) ( obs ( forall ( block1 )</definiens>
			</definition>
			<definition id="6">
				<sentence>NL1 improves upon SHRDLU by using modern HPSG grammars instead of CFG grammars and declarative instead of procedural knowledge representation , but still falls short of the complexity of correctly executed dialogues .</sentence>
				<definiendum id="0">NL1</definiendum>
				<definiens id="0">improves upon SHRDLU by using modern HPSG grammars instead of CFG grammars and declarative instead of procedural knowledge representation , but still falls short of the complexity of correctly executed dialogues</definiens>
			</definition>
			<definition id="7">
				<sentence>Our approach is similar in the application of an automated theorem prover after a translation step , but our background knowledge is encoded in Temporal Action Logic , which endows the system with the power to perform actions and reason about their effects .</sentence>
				<definiendum id="0">Logic</definiendum>
				<definiens id="0">endows the system with the power to perform actions and reason about their effects</definiens>
			</definition>
</paper>

		<paper id="3120">
			<definition id="0">
				<sentence>Block reordering ( br ) The difference in word order between two languages is one of the most signi cant sources of error in SMT .</sentence>
				<definiendum id="0">Block reordering</definiendum>
				<definiens id="0">one of the most signi cant sources of error in SMT</definiens>
			</definition>
			<definition id="1">
				<sentence>Then , the list of Alignment Blocks ( LAB ) is processed in order to decide whether two consecutive blocks have to be reordered or not .</sentence>
				<definiendum id="0">list of Alignment Blocks</definiendum>
			</definition>
			<definition id="2">
				<sentence>A phrase ( or bilingual phrase ) is any pair of m source words and n target words that satis es two basic constraints : words are consecutive along both sides of the bilingual phrase , and no word on either side of the phrase is aligned to a word out of the phrase .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">or bilingual phrase ) is any pair of m source words and n target words that satis es two basic constraints : words are consecutive along both sides of the bilingual phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>The target language model ( lm ) consists of an n-gram model , in which the probability of a translation hypothesis is approximated by the product of word n-gram probabilities .</sentence>
				<definiendum id="0">target language model</definiendum>
				<definiens id="0">an n-gram model , in which the probability of a translation hypothesis is approximated by the product of word n-gram probabilities</definiens>
			</definition>
			<definition id="4">
				<sentence>The POS target language model ( tpos ) consists of an N-gram language model estimated over the same target-side of the training corpus but using POS tags instead of raw words .</sentence>
				<definiendum id="0">POS target language model ( tpos )</definiendum>
				<definiens id="0">consists of an N-gram language model estimated over the same target-side</definiens>
			</definition>
			<definition id="5">
				<sentence>The word bonus model ( wb ) introduces a sentence length bonus in order to compensate the system preference for short output sentences .</sentence>
				<definiendum id="0">word bonus model</definiendum>
				<definiens id="0">introduces a sentence length bonus in order to compensate the system preference for short output sentences</definiens>
			</definition>
</paper>

		<paper id="1621">
			<definition id="0">
				<sentence>Expansion consists of altering a given text ( usually a query ) by adding terms of similar meaning .</sentence>
				<definiendum id="0">Expansion</definiendum>
				<definiens id="0">consists of altering a given text ( usually a query</definiens>
			</definition>
			<definition id="1">
				<sentence>WordNet is commonly used as a source of related words for expansion .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a source of related words for expansion</definiens>
			</definition>
			<definition id="2">
				<sentence>Context : if there is a clear reference to the meaning of the target word by the overall meaning of some part ( s ) of the sentence ( possibly all the sentence ) , though it is not referenced by any single word or phrase .</sentence>
				<definiendum id="0">Context</definiendum>
				<definiens id="0">s ) of the sentence ( possibly all the sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>It is defined for a text t and a word u as follows : bayes ( t , u ) = P ( u ) producttext v∈t P ( v|u ) n ( v , t ) P ( ¬u ) producttext v∈t P ( v|¬u ) n ( v , t ) +P ( u ) producttext v∈t P ( v|u ) n ( v , t ) ( 3 ) where n ( w , t ) is the number of times word w appears in t , P ( u ) is the probability that a sentence containstheword u andP ( v|¬u ) istheprobability that a sentence NOT containing u contains v. In order to reduce data size and to account for zero probabilities we applied smoothing and information gain based feature selection on the data prior to running the model .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of times word w appears in t</definiens>
				<definiens id="1">the probability that a sentence containstheword u andP ( v|¬u ) istheprobability that a sentence NOT containing u contains v. In order to reduce data size and to account for zero probabilities we applied smoothing and information gain based feature selection on the data prior to running the model</definiens>
			</definition>
</paper>

		<paper id="2106">
			<definition id="0">
				<sentence>38 NODE , the definitions constitute a lexicographic statement that the meaning of the phrase has an idiomatic status , i.e. , is not solely recoverable based on an understanding of the meanings of its constituents .</sentence>
				<definiendum id="0">NODE</definiendum>
				<definiens id="0">a lexicographic statement that the meaning of the phrase has an idiomatic status</definiens>
			</definition>
			<definition id="1">
				<sentence>In general , then , TPP broadly covers the full range of meanings expressed by prepositions as described in Quirk et al..</sentence>
				<definiendum id="0">TPP broadly</definiendum>
			</definition>
			<definition id="2">
				<sentence>of action denoted in the POA Feature Backdrop on background on which the POA is located forming a distinctive or marked part of ( the surface of something ) Whole object of which the POA is a part , piece , or sample Downside against downside ; the con in a pro/con situation in conceptual contrast to Comparator second term of a comparison Table 2 .</sentence>
				<definiendum id="0">POA</definiendum>
				<definiens id="0">a part</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , in the time space , such semantic relations as ActivePeriod , ClockHour , CreationDate , FutureTime , Hour , PeriodBisected , PointInTime , TargetTime , TimeOrigin , and TimePeriod would be examined together .</sentence>
				<definiendum id="0">TimePeriod</definiendum>
				<definiens id="0">such semantic relations as ActivePeriod , ClockHour , CreationDate , FutureTime , Hour , PeriodBisected , PointInTime , TargetTime , TimeOrigin , and</definiens>
			</definition>
</paper>

		<paper id="0121">
			<definition id="0">
				<sentence>For the open track especially , three extended features are extracted with the help of an external dictionary as follows : d ) Pu ( c0 ) e ) L and t0 f ) cnt0 ( n = −1,0,1 ) where Pu ( c0 ) denotes whether the current character is a punctuation , L is the length of word W that conjoined from the character and its context which matching a word in the external dictionary as long as possible .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">extracted with the help of an external dictionary as follows : d ) Pu ( c0 ) e ) L and t0 f ) cnt0 ( n = −1,0,1 ) where Pu ( c0 ) denotes whether the current character is a punctuation</definiens>
				<definiens id="1">the length of word W that conjoined from the character and its context which matching a word in the external dictionary as long as possible</definiens>
			</definition>
			<definition id="1">
				<sentence>t0 is the boundary tag of the character in W. With the features , a ME model is trained which could output four scores for each character with regard to four classes .</sentence>
				<definiendum id="0">t0</definiendum>
				<definiens id="0">the boundary tag of the character in</definiens>
			</definition>
			<definition id="2">
				<sentence>And the unigram of the OOV word will be calculated as : Unigram ( OOV Word ) = pl ( 3 ) where p is the minimal unigram value of words in vocabulary ; l is the length of the word acting as a punishment factor to avoid overemphasizing the long OOV words .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">l</definiendum>
				<definiens id="0">the minimal unigram value of words in vocabulary</definiens>
			</definition>
</paper>

		<paper id="0201">
			<definition id="0">
				<sentence>Our automatic trend exploration system consists of the following components .</sentence>
				<definiendum id="0">automatic trend exploration system</definiendum>
				<definiens id="0">consists of the following components</definiens>
			</definition>
			<definition id="1">
				<sentence>• Equation for the TF numerical term in Okapi ( Robertson et al. , 1994 ) Score = summationdisplay i∈Docs TF i TF i + l i ∆ ( 1 ) • Use of total word frequency Score = summationdisplay i∈Docs TF i ( 2 ) • Use of total frequency of documents where a word appears Score = summationdisplay i∈Docs 1 ( 3 ) In these equations , i is the ID ( identification number ) of a document , Docs is a set of document IDs , TF i is the occurrence number of an expression in document i , l is the length of document i , and ∆ is the average length of documents in Docs .</sentence>
				<definiendum id="0">Docs</definiendum>
				<definiendum id="1">TF i</definiendum>
				<definiendum id="2">l</definiendum>
				<definiendum id="3">∆</definiendum>
				<definiens id="0">a set of document IDs ,</definiens>
				<definiens id="1">the average length of documents in Docs</definiens>
			</definition>
			<definition id="2">
				<sentence>TP1 is the average of the precision in the first output .</sentence>
				<definiendum id="0">TP1</definiendum>
				<definiens id="0">the average of the precision in the first output</definiens>
			</definition>
			<definition id="3">
				<sentence>RP is the average of the r-precision and AP is the average of the average precision .</sentence>
				<definiendum id="0">RP</definiendum>
				<definiendum id="1">AP</definiendum>
				<definiens id="0">the average of the r-precision and</definiens>
				<definiens id="1">the average of the average precision</definiens>
			</definition>
			<definition id="4">
				<sentence>The precision is the ratio of correct answers in the system output .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the ratio of correct answers in the system output</definiens>
			</definition>
			<definition id="5">
				<sentence>The recall is the ratio of correct answers in the system output to the total number of correct answers .</sentence>
				<definiendum id="0">recall</definiendum>
			</definition>
</paper>

		<paper id="2916">
			<definition id="0">
				<sentence>Distributional methods analyze text by alignment , aiming to find equivalence classes covering substitutable units .</sentence>
				<definiendum id="0">Distributional methods</definiendum>
				<definiens id="0">analyze text by alignment , aiming to find equivalence classes covering substitutable units</definiens>
			</definition>
			<definition id="1">
				<sentence>ABL uses minimal String-Edit Distance between sentences to propose constituents , from which the most probable combination is chosen .</sentence>
				<definiendum id="0">ABL</definiendum>
				<definiens id="0">uses minimal String-Edit Distance between sentences to propose constituents</definiens>
			</definition>
			<definition id="2">
				<sentence>The EMILE system ( Adriaans , 1999 ) learns shallow languages in an incremental manner , and has been applied to natural language under the assumption that such languages are shallow .</sentence>
				<definiendum id="0">EMILE system</definiendum>
				<definiens id="0">learns shallow languages in an incremental manner , and has been applied to natural language under the assumption that such languages are shallow</definiens>
			</definition>
			<definition id="3">
				<sentence>ADIOS learns context-sensitive equivalence classes , but does not induce grammars , and has not been formally evaluated against treebanks .</sentence>
				<definiendum id="0">ADIOS</definiendum>
				<definiens id="0">learns context-sensitive equivalence classes , but does not induce grammars , and has not been formally evaluated against treebanks</definiens>
			</definition>
			<definition id="4">
				<sentence>First , previous systems hypothesize and select constituents according to the probability of their contexts : ABL , EMILE and CCM use the probability of proposed equivalence classes , or the equivalent context probability ; ADIOS uses an information gain metric , again favouring probable contexts .</sentence>
				<definiendum id="0">ADIOS</definiendum>
				<definiens id="0">the probability of their contexts : ABL , EMILE and CCM use the probability of proposed equivalence classes</definiens>
				<definiens id="1">uses an information gain metric</definiens>
			</definition>
			<definition id="5">
				<sentence>Table 1 summarizes the EVALB scores for two 500-iteration runs of Directed Alignment over ICEGB : DA is the standard context-sensitive version of the algorithm ; DAcluster is the version with context clustering .</sentence>
				<definiendum id="0">DA</definiendum>
				<definiendum id="1">DAcluster</definiendum>
				<definiens id="0">the standard context-sensitive version of the algorithm ;</definiens>
				<definiens id="1">the version with context clustering</definiens>
			</definition>
			<definition id="6">
				<sentence>We distinguish the following POS categories as being primarily functional , as they account for the majority of context-units considered by Directed Alignment : prepositions ( PREP ) , articles ( ART ) , aux3The same trends can be shown for words , but a POS analysis is preferred for clarity and brevity .</sentence>
				<definiendum id="0">Directed Alignment</definiendum>
				<definiens id="0">account for the majority of context-units considered by</definiens>
			</definition>
			<definition id="7">
				<sentence>In order to calculate the likelihood of a particular context word w occurring at the start or end of a sentence , we simply use the bigram probabilities between w and the special symbols START and END , which denote the start and end of a sentence respectively .</sentence>
				<definiendum id="0">END</definiendum>
				<definiens id="0">denote the start and end of a sentence respectively</definiens>
			</definition>
</paper>

		<paper id="3403">
			<definition id="0">
				<sentence>Unlike some other statistical approaches ( e.g. chi-square ) , SCC has been shown effective on determining similarity between corpora of varying sizes , therefore SCC will serve as a baseline for comparison in this paper ( Kilgarriff , 2001 ) .</sentence>
				<definiendum id="0">SCC</definiendum>
				<definiens id="0">shown effective on determining similarity between corpora of varying sizes</definiens>
			</definition>
			<definition id="1">
				<sentence>The Junior Summit launched in 1998 as a closed online community for young people to discuss how to use technology to make the world better .</sentence>
				<definiendum id="0">Junior Summit</definiendum>
				<definiens id="0">a closed online community for young people to discuss how to use technology to make the world better</definiens>
			</definition>
			<definition id="2">
				<sentence>We based our approach on the algorithm used by ( Benedetto , Caglioti , &amp; Loreto , 2002 ) , where the cross-entropy per character is defined as : Here , A and B are documents ; A B+ is document B appended to document A ; zip ( A ) is the zipped document ; and length ( A ) is the length of the document .</sentence>
				<definiendum id="0">B+</definiendum>
				<definiendum id="1">length ( A )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Spearman’s Correlation Coefficient demonstrates a steady decline in similarity .</sentence>
				<definiendum id="0">Spearman’s Correlation Coefficient</definiendum>
				<definiens id="0">demonstrates a steady decline in similarity</definiens>
			</definition>
			<definition id="4">
				<sentence>LSA demonstrates the same divergent trend over time , F ( 5,1410 ) = 27.139 , p &lt; .001 , N=1416 , with a slight spike at T 4 and T 5 .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">demonstrates the same divergent trend over time</definiens>
			</definition>
			<definition id="5">
				<sentence>For instance , Spearman’s Correlation Coefficient found a significant difference in similarity between three groups , where F ( 2,273 ) = 6.804 , p &lt; .001 , n=276 , such that delegate-delegate pairs demonstrate higher similarity scores than nondelegate pairs and mixed pairs .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">such that delegate-delegate pairs demonstrate higher similarity scores than nondelegate pairs and mixed pairs</definiens>
			</definition>
</paper>

		<paper id="2802">
</paper>

		<paper id="3203">
			<definition id="0">
				<sentence>A grammar is some device that must at least respond Yes or No when asked if a linguistic sign is a possible sign for this language ( Chomsky and Halle , 1968 ; Halle , 1978 ) .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiens id="0">a possible sign for this language</definiens>
			</definition>
			<definition id="1">
				<sentence>A finite state machine is a 5-tuple ( Σ , Q , q 0 , F , δ ) where Σ is a finite alphabet , Q is a set of states , q 0 ∈ Q is the start state , F ⊆ Q is a set of final states , and δ is a set of transitions .</sentence>
				<definiendum id="0">Σ</definiendum>
				<definiendum id="1">Q</definiendum>
				<definiendum id="2">δ</definiendum>
				<definiens id="0">a set of states</definiens>
				<definiens id="1">the start state</definiens>
				<definiens id="2">a set of final states</definiens>
				<definiens id="3">a set of transitions</definiens>
			</definition>
			<definition id="2">
				<sentence>Neighborhood-distinctness is a universal property of the patterns under consideration .</sentence>
				<definiendum id="0">Neighborhood-distinctness</definiendum>
				<definiens id="0">a universal property of the patterns under consideration</definiens>
			</definition>
			<definition id="3">
				<sentence>The second stage of the learner is state-merging , a process which reduces the number of states in the machine .</sentence>
				<definiendum id="0">state-merging</definiendum>
				<definiens id="0">a process which reduces the number of states in the machine</definiens>
			</definition>
			<definition id="4">
				<sentence>Learning is a process which identifies actually different environments as ‘the same’— here states are ‘the same’ iff their local features , i.e their neighborhoods , are the same .</sentence>
				<definiendum id="0">Learning</definiendum>
				<definiens id="0">a process which identifies actually different environments as ‘the same’— here states are ‘the same’ iff their local features , i.e their neighborhoods</definiens>
			</definition>
			<definition id="5">
				<sentence>As it happens , Hopi is a QS language which prohibits light , but permits heavy , monosyllables .</sentence>
				<definiendum id="0">Hopi</definiendum>
			</definition>
			<definition id="6">
				<sentence>The Forward Backward Neighborhood Learner learns all of these patterns successfully irrespective of whether the patterns ( and corresponding input samples ) permit monosyllables , predicting that such patterns do not correlate with a prohibition on monosyllables ( see appendix ) .</sentence>
				<definiendum id="0">Forward Backward Neighborhood Learner</definiendum>
				<definiens id="0">learns all of these patterns successfully irrespective of whether the patterns</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , the Neighborhood Learner learns a pattern in which words with an odd number of syllables bear initial stress but words with an even number of syllables bear stress on all odd syllables .</sentence>
				<definiendum id="0">Neighborhood Learner</definiendum>
				<definiens id="0">learns a pattern in which words with an odd number of syllables bear initial stress</definiens>
			</definition>
			<definition id="8">
				<sentence>The class of languages to be learned is finite—as in the Optimality-theoretic and Principles and Parameters frameworks—and is a proper subset of the regular languages .</sentence>
				<definiendum id="0">Parameters frameworks—and</definiendum>
				<definiens id="0">a proper subset of the regular languages</definiens>
			</definition>
</paper>

		<paper id="1304">
			<definition id="0">
				<sentence>The Knowledge Manager ( KM ) controls access to domain knowledge that is structured according to domain-dependent ontologies .</sentence>
				<definiendum id="0">Knowledge Manager</definiendum>
				<definiens id="0">controls access to domain knowledge that is structured according to domain-dependent ontologies</definiens>
			</definition>
			<definition id="1">
				<sentence>Constraint relaxation makes use of the ontological relationships in the knowledge base .</sentence>
				<definiendum id="0">Constraint relaxation</definiendum>
				<definiens id="0">makes use of the ontological relationships in the knowledge base</definiens>
			</definition>
			<definition id="2">
				<sentence>The input to the generator consists of the name of the dialogue move and the relevant instantiated nodes of the dialogue move tree .</sentence>
				<definiendum id="0">generator</definiendum>
				<definiens id="0">consists of the name of the dialogue move and the relevant instantiated nodes of the dialogue move tree</definiens>
			</definition>
			<definition id="3">
				<sentence>The core of the generator is a set of productions1 written in the Java Expert System Shell ( Friedman-Hill , 2003 ) .</sentence>
				<definiendum id="0">core of the generator</definiendum>
			</definition>
</paper>

		<paper id="1408">
			<definition id="0">
				<sentence>A referential description ( Donellan 1966 ) serves the purpose of letting the hearer or reader identify a particular object or set of objects in a situation .</sentence>
				<definiendum id="0">referential description</definiendum>
				<definiens id="0">a particular object or set of objects in a situation</definiens>
			</definition>
			<definition id="1">
				<sentence>Moreover , the contrast set ( the set of potential distractors ( McDonald 1981 ) ) is defined to entail all elements of the context set except the intended referents .</sentence>
				<definiendum id="0">potential distractors</definiendum>
				<definiens id="0">defined to entail all elements of the context set except the intended referents</definiens>
			</definition>
			<definition id="2">
				<sentence>¥ Termination criteria include a test whether a cardinality or position-based implicature establishes a unique preference .</sentence>
				<definiendum id="0">¥ Termination criteria</definiendum>
				<definiens id="0">include a test whether a cardinality or position-based implicature establishes a unique preference</definiens>
			</definition>
			<definition id="3">
				<sentence>Group ( x ) : := G ≡ { y | ∃z ( ∀y dominates ( z , y ) ) } ^ G ⊇ x T-group-items : : = { x | ∃y ( ´∃z dominates ( z , y ) ^ ∀x dominates ( y , x ) ) } L1-items : : = { x | ∃y ( y ∈ T-group-items ^ dominates ( y , x ) ) } Group-pref ( Group , N , V ) : : = | ( r ∪ C ) ∩ Group| = N ^ ∀x ∈ ( ( r ∪ C ) ∩ Group ) : Position ( x , Group , N ) = V T-group-pref ( N , V ) : := Group-pref ( T-group-items , N , V ) L1-group-pref ( x , N , V ) : := ´T-Group-pref ( N , V ) ^ L1-items ⊇ Group ( x ) ^ Group-pref ( x , N , V ) ^ ( ∀y ( Group ( y ) ^ L1-items ⊇ Group ( y ) ) : ( x≠y → ´Group-pref ( y , N , V ) ) ) Figure 2 : Definitions with group components In order to precisely define the extensions , we introduce some predicates and formal definitions for them ( Figure 2 ) .</sentence>
				<definiendum id="0">N , V ) L1-group-pref</definiendum>
				<definiens id="0">: = { x | ∃y ( y ∈ T-group-items ^ dominates ( y , x ) ) } Group-pref ( Group , N , V ) : : = | ( r ∪ C ) ∩ Group| = N ^ ∀x ∈ ( ( r ∪ C ) ∩ Group ) : Position ( x , Group , N ) = V T-group-pref ( N , V ) : := Group-pref ( T-group-items ,</definiens>
			</definition>
			<definition id="4">
				<sentence>A Group which some items x belong to is the set of items dominated by one same item , if existing .</sentence>
				<definiendum id="0">Group</definiendum>
				<definiens id="0">the set of items dominated by one same item , if existing</definiens>
			</definition>
			<definition id="5">
				<sentence>A special group is the set of items on top level , T-groupitems , which are all dominated by the entire structure , the root item , which is not dominated by any item .</sentence>
				<definiendum id="0">special group</definiendum>
				<definiens id="0">the set of items on top level , T-groupitems , which are all dominated by the entire structure , the root item</definiens>
			</definition>
			<definition id="6">
				<sentence>The most complex addition is the descriptor position , which expresses some sort of relative position of an object considered within the context of a set of comparable objects ( e.g. , first , second ) .</sentence>
				<definiendum id="0">descriptor position</definiendum>
				<definiens id="0">expresses some sort of relative position of an object considered within the context of a set of comparable objects</definiens>
			</definition>
</paper>

		<paper id="1637">
			<definition id="0">
				<sentence>Crossed Composition : Y/Z X\Y ⇒B X/Z Forward Type-raising : X ⇒T T/ ( T\X ) Coordination : X conj X ⇒Φ X Function application is the most basic operation ( and used by all variants of categorial grammar ) : I saw the man NP ( S\NP ) /NP NP &gt; S\NP &lt; S Composition ( B ) and type-raising ( T ) are necessary for the analysis of long-range dependencies and for incremental derivations. CCG uses the same lexical categories for long-range dependencies that arise eg. in wh-movement or coordination as for local dependencies , and does not require traces : the man that I saw NP ( NP\NP ) / ( S/NP ) NP ( S\NP ) /NP &gt; TS/ ( S\NP ) &gt; BS/NP &gt; NP\NP I saw and you heard the man NP ( S\NP ) /NP conj NP ( S\NP ) /NP &gt; T &gt; TS/ ( S\NP ) S/ ( S\NP ) &gt; B &gt; BS/NP S/NP &lt; Φ &gt; S/NP &gt; S The combinatory rules of CCG allow multiple , semantically equivalent , syntactic derivations of the same sentence .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiendum id="1">TS/ ( S\NP ) S/</definiendum>
				<definiens id="0">the most basic operation ( and used by all variants of categorial grammar</definiens>
				<definiens id="1">uses the same lexical categories for long-range dependencies that arise eg. in wh-movement or coordination as for local dependencies</definiens>
				<definiens id="2">B &gt; BS/NP S/NP &lt; Φ &gt; S/NP &gt; S The combinatory rules of CCG allow multiple , semantically equivalent , syntactic derivations of the same sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , the verb saw might have the ( lexical ) category ( S\NP ) /NP , which allows it to combine with an NP to the right .</sentence>
				<definiendum id="0">S\NP ) /NP</definiendum>
				<definiens id="0">allows it to combine with an NP to the right</definiens>
			</definition>
			<definition id="2">
				<sentence>The Switchboard ( Marcus et al. , 1994 ) corpus contains transcriptions of spoken , spontaneous conversation annotated with phrase-structure trees .</sentence>
				<definiendum id="0">Switchboard</definiendum>
			</definition>
			<definition id="3">
				<sentence>The original Switchboard transcripts contains these disfluencies ( marked up as EDITED ) : ( ( S &gt; &gt; &gt; ( EDITED ( RM ( -DFL\bs [ ) ) ( EDITED ( RM ( -DFL\bs [ ) ) ( CC And ) ( , , ) ( IP ( -DFL\bs + ) ) ) ( CC and ) ( , , ) ( RS ( -DFL\bs ] ) ) ( IP ( -DFL\bs + ) ) ) &lt; &lt; &lt; 2Selectional criteria such as information structure and intonation allow to distinguish between semantically different analyses .</sentence>
				<definiendum id="0">) ( RS</definiendum>
				<definiendum id="1">IP</definiendum>
				<definiens id="0">information structure and intonation allow to distinguish between semantically different analyses</definiens>
			</definition>
			<definition id="4">
				<sentence>CCG assumes a minimal set of combinatory rule schemata .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiens id="0">assumes a minimal set of combinatory rule schemata</definiens>
			</definition>
			<definition id="5">
				<sentence>312 Normalformderivation Incrementalderivation S [ dcl ] S/S and S [ dcl ] S/ ( S\NP ) NP I S [ dcl ] \NP ( S [ dcl ] \NP ) /S [ dcl ] guess S [ dcl ] S/ ( S\NP ) NP that S [ dcl ] \NP ( S [ dcl ] \NP ) /NP ’s NP NP/ ( S [ dcl ] /NP ) what S [ dcl ] /NP S/ ( S\NP ) NP I ( S [ dcl ] \NP ) /NP ( S\NP ) / ( S\NP ) really ( S [ dcl ] \NP ) /NP like S [ dcl ] S [ dcl ] / ( S [ dcl ] /NP ) S [ dcl ] /NP S [ dcl ] / ( S\NP ) S [ dcl ] /S [ dcl ] S/ ( S\NP ) S/S and S/ ( S\NP ) NP I ( S [ dcl ] \NP ) /S [ dcl ] guess S/ ( S\NP ) NP that ( S [ dcl ] \NP ) /NP ’s NP/ ( S [ dcl ] /NP ) what S [ dcl ] /NP S/ ( S\NP ) S/ ( S\NP ) NP I ( S\NP ) / ( S\NP ) really ( S [ dcl ] \NP ) /NP like Figure 1 : Two derivations ( normal form : left ) , incremental : right ) for the sentence fragment and I guess that’s what I really like from Switchboard .</sentence>
				<definiendum id="0">S/ ( S\NP</definiendum>
				<definiendum id="1">/NP S/</definiendum>
				<definiendum id="2">S/ ( S\NP</definiendum>
				<definiendum id="3">guess S/</definiendum>
				<definiendum id="4">/NP S/</definiendum>
			</definition>
			<definition id="6">
				<sentence>Other explanatory variables , such as ROLE , which indicates whether priming occurs within a speaker ( production-production priming , PP ) or in between speakers ( comprehension-production priming , CP ) , receive an interaction coefficient that adds linearly to βlnDist .</sentence>
				<definiendum id="0">ROLE</definiendum>
				<definiens id="0">indicates whether priming occurs within a speaker ( production-production priming</definiens>
			</definition>
			<definition id="7">
				<sentence>From the data produced , we include all cases of reptition and a an equal number of randomly sampled non-repetition cases.5 and Normal-form Derivations Hypothesis CCG assumes a multiplicity of semantically equivalent derivations with different syntactic constituent structures .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiens id="0">assumes a multiplicity of semantically equivalent derivations with different syntactic constituent structures</definiens>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>This paper describes an empirical evaluation of the Bible as a resource for cross-language information retrieval ( CLIR ) .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">a resource for cross-language information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>Indeed , there is good reason for this : CLEF is an activity under the auspices of the European Commission .</sentence>
				<definiendum id="0">CLEF</definiendum>
			</definition>
			<definition id="2">
				<sentence>Mean similarities by language pair One hypothesis we have is that the lower overall similarity for English-Russian is at least partly due to the fact that Russian is a much more highly inflected language then any of English , French , or Spanish .</sentence>
				<definiendum id="0">Russian</definiendum>
				<definiens id="0">a much more highly inflected language then any of English , French , or Spanish</definiens>
			</definition>
</paper>

		<paper id="3327">
</paper>

		<paper id="2410">
			<definition id="0">
				<sentence>Bolinger ( Bolinger 1965 ) elegantly sums up this approach as Dictionaries do not exist to define , but to help people grasp meaning , and for this purpose their main task is to supply a series of hints and associations that will relate the unknown to something known .</sentence>
				<definiendum id="0">Bolinger</definiendum>
				<definiens id="0">to supply a series of hints and associations that will relate the unknown to something known</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 2 Representing the phrases in Figure 1 with semantic features Note that to render expressions like in 2 ) we use local grammars containing nodes that range from specific word forms through lemmas , lists of words , words defined by a semantic class in an ontology to syntactic class or even the completely general placeholder for any word .</sentence>
				<definiendum id="0">Representing</definiendum>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>Figure 1 : A set of Alpine Convention terms and their relations The LexALP term bank consists in 5 volumes for French , German , Italian , Slovene and English ( no data is being entered for this fifth language at the moment ) , which contain the term descriptions .</sentence>
				<definiendum id="0">LexALP term bank</definiendum>
				<definiens id="0">no data is being entered for this fifth language at the moment ) , which contain the term descriptions</definiens>
			</definition>
			<definition id="1">
				<sentence>In fact such t erms can only be found in the Alpine Convention ( which is considered as a legal system expressed in all the considered languages ) .</sentence>
				<definiendum id="0">Alpine Convention</definiendum>
				<definiens id="0">a legal system expressed in all the considered languages )</definiens>
			</definition>
</paper>

		<paper id="1652">
			<definition id="0">
				<sentence>Information extraction ( IE ) patterns are lexico-syntactic patterns that represent expressions which identify role relationships .</sentence>
				<definiendum id="0">Information extraction</definiendum>
				<definiens id="0">lexico-syntactic patterns that represent expressions which identify role relationships</definiens>
			</definition>
			<definition id="1">
				<sentence>AutoSlog relies on the Sundance shallow parser and can be applied exhaustively to a text corpus to generate IE patterns that can extract every noun phrase in the corpus .</sentence>
				<definiendum id="0">AutoSlog</definiendum>
				<definiens id="0">relies on the Sundance shallow parser and can be applied exhaustively to a text corpus to generate IE patterns that can extract every noun phrase in the corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>Subjects ( subj ) , direct objects ( dobj ) , PP objects ( np ) , and possessives can be extracted by the patterns.2 We created a subsumption hierarchy that de nes the representational scope of different types of features .</sentence>
				<definiendum id="0">Subjects</definiendum>
				<definiens id="0">subj ) , direct objects ( dobj ) , PP objects ( np ) , and possessives can be extracted by the patterns.2 We created a subsumption hierarchy that de nes the representational scope of different types of features</definiens>
			</definition>
			<definition id="3">
				<sentence>We will say that feature A behaviorally subsumes feature B if two criteria are met : ( 1 ) A representationally subsumes B , and ( 2 ) IG ( A ) IG ( B ) δ , where δ is a parameter representing an acceptable margin of performance difference .</sentence>
				<definiendum id="0">IG</definiendum>
				<definiendum id="1">δ</definiendum>
				<definiens id="0">a parameter representing an acceptable margin of performance difference</definiens>
			</definition>
			<definition id="4">
				<sentence>The OP data consists of 2,452 documents from the Penn Treebank ( Marcus et al. , 1993 ) .</sentence>
				<definiendum id="0">OP data</definiendum>
			</definition>
			<definition id="5">
				<sentence>The Polarity data consists of 700 positive and 700 negative reviews from the Internet Movie Database ( IMDb ) archive .</sentence>
				<definiendum id="0">Polarity data</definiendum>
			</definition>
			<definition id="6">
				<sentence>The MPQA data consists of English language versions of articles from the world press .</sentence>
				<definiendum id="0">MPQA data</definiendum>
				<definiens id="0">consists of English language versions of articles from the world press</definiens>
			</definition>
			<definition id="7">
				<sentence>Begin with ( C2 ) captures an adverbial phrase used in argumentation ( To begin with ... ) but does not match objective usages such as will begin an action .</sentence>
				<definiendum id="0">C2 )</definiendum>
				<definiens id="0">captures an adverbial phrase used in argumentation ( To begin with ...</definiens>
			</definition>
</paper>

		<paper id="1616">
			<definition id="0">
				<sentence>McDonald et al. ( 2005a ) introduce a dependency parsing framework which treats the task as searching for the projective tree that maximises the sum of local dependency scores .</sentence>
				<definiendum id="0">dependency parsing framework</definiendum>
				<definiens id="0">treats the task as searching for the projective tree that maximises the sum of local dependency scores</definiens>
			</definition>
			<definition id="1">
				<sentence>130 where x is a sentence , y is a set of labelled dependencies , f ( i , j , l ) is a multidimensional feature vector representation of the edge from token i to token j with label l and w the corresponding weight vector .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">a multidimensional feature vector representation of the edge from token i to token j with label l and w the corresponding weight vector</definiens>
			</definition>
			<definition id="2">
				<sentence>Linear Programming ( LP ) is a tool for solving optimisation problems in which the aim is to maximise ( or minimise ) a given linear function with respect to a set of linear constraints .</sentence>
				<definiendum id="0">Linear Programming ( LP )</definiendum>
				<definiens id="0">a tool for solving optimisation problems in which the aim is to maximise</definiens>
			</definition>
			<definition id="3">
				<sentence>Integer Linear Programming is an extension of linear programming where all decision variables must take integer values .</sentence>
				<definiendum id="0">Integer Linear Programming</definiendum>
				<definiens id="0">an extension of linear programming where all decision variables must take integer values</definiens>
			</definition>
			<definition id="4">
				<sentence>For a sentence x , Bx is the set of constraints that we add in advance and Ix are the constraints we add incrementally .</sentence>
				<definiendum id="0">Bx</definiendum>
				<definiendum id="1">Ix</definiendum>
				<definiens id="0">the set of constraints that we add in advance</definiens>
			</definition>
			<definition id="5">
				<sentence>Ox is the objective function and Vx is a set of variables including integer declarations .</sentence>
				<definiendum id="0">Ox</definiendum>
				<definiendum id="1">Vx</definiendum>
				<definiens id="0">the objective function and</definiens>
				<definiens id="1">a set of variables including integer declarations</definiens>
			</definition>
			<definition id="6">
				<sentence>n , l∈bestk ( i , j ) where n is the number of tokens and the index 0 represents the root token .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of tokens and the index 0 represents the root token</definiens>
			</definition>
			<definition id="7">
				<sentence>133 We use the Alpino treebank ( van der Beek et al. , 2002 ) , taken from the CoNLL shared task of multilingual dependency parsing3 .</sentence>
				<definiendum id="0">Alpino treebank</definiendum>
				<definiens id="0">taken from the CoNLL shared task of multilingual dependency parsing3</definiens>
			</definition>
			<definition id="8">
				<sentence>To evaluate our systems we use the accuracy over labelled attachment decisions : LAC = NlN t where Nl is the number of tokens with correct head and label and Nt is the total number of tokens .</sentence>
				<definiendum id="0">Nl</definiendum>
				<definiendum id="1">Nt</definiendum>
				<definiens id="0">the total number of tokens</definiens>
			</definition>
			<definition id="9">
				<sentence>The baseline system ( no additional constraints ) gives an unlabelled accuracy of 84.6 % and labelled accuracy of 88.9 % .</sentence>
				<definiendum id="0">baseline system</definiendum>
				<definiens id="0">no additional constraints ) gives an unlabelled accuracy of 84.6 % and labelled accuracy of 88.9 %</definiens>
			</definition>
			<definition id="10">
				<sentence>For example , suppose we attach two subjects , t1 and t2 , to a verb , where t1 is the actual subject while t2 is meant to be labelled as object .</sentence>
				<definiendum id="0">t1</definiendum>
				<definiens id="0">meant to be labelled as object</definiens>
			</definition>
</paper>

		<paper id="1416">
			<definition id="0">
				<sentence>RIG employs Charniak’s ( 1997 ) parser which appeared to be quite robust in the medical domain .</sentence>
				<definiendum id="0">RIG</definiendum>
				<definiens id="0">employs Charniak’s ( 1997 ) parser which appeared to be quite robust in the medical domain</definiens>
			</definition>
			<definition id="1">
				<sentence>RIG utilises a simple transformational component which produces a stem via minimal changes in the ordering of the source clause .</sentence>
				<definiendum id="0">RIG</definiendum>
				<definiens id="0">utilises a simple transformational component which produces a stem via minimal changes in the ordering of the source clause</definiens>
			</definition>
			<definition id="2">
				<sentence>RIG is a simple system which often avoids tough problems such as dealing with key-terms in syntactic positions that might puzzle the parser or might be too difficult to question upon .</sentence>
				<definiendum id="0">RIG</definiendum>
				<definiens id="0">a simple system which often avoids tough problems such as dealing with key-terms in syntactic positions that might puzzle the parser or</definiens>
			</definition>
</paper>

		<paper id="0802">
			<definition id="0">
				<sentence>RDFs are asertions about the things ( people , Webpages and whatever ) they predicate about by aserting that they have certain properties with certain values .</sentence>
				<definiendum id="0">RDFs</definiendum>
				<definiens id="0">people , Webpages and whatever ) they predicate about by aserting that they have certain properties with certain values</definiens>
			</definition>
			<definition id="1">
				<sentence>A semantic relation triple consists of a discourse entity , a semantic relation which characterizes the entity 's role in the sentence , and a governing word to which the entity stands in the semantic relation .</sentence>
				<definiendum id="0">semantic relation triple</definiendum>
				<definiens id="0">consists of a discourse entity , a semantic relation which characterizes the entity 's role in the sentence , and a governing word to which the entity stands in the semantic relation</definiens>
			</definition>
			<definition id="2">
				<sentence>Other similar problems ocur with TEs when the two elements of the relation have the same head , as in : -The president of Rusia visited the president of China .</sentence>
				<definiendum id="0">TEs</definiendum>
				<definiens id="0">-The president of Rusia visited the president of China</definiens>
			</definition>
			<definition id="3">
				<sentence>This is however not true and the problem is related to the posibility to detect in texts the presence of such semantic indicators as those listed here below : Negation ; Quantification ; Opaque contexts ( wish , want ) ; Future , Subjunctive Mode ; Modality ; Conditionals Finaly there is a discourse related problem and is the Anaphora Resolution problem which is the hardest to be tackled by NLP : it is a fact that anaphoric relations are the building blocks of cohesivenes and coherence in texts .</sentence>
				<definiendum id="0">; Opaque contexts</definiendum>
				<definiens id="0">the posibility to detect in texts the presence of such semantic indicators as those listed here below : Negation ; Quantification</definiens>
			</definition>
			<definition id="4">
				<sentence>Natural language suport gives users a whole new way of interacting with any information system , and from a knowledge enginering point of view , natural language technology divorces the majority of users from the ned to understand formal ontologies .</sentence>
				<definiendum id="0">Natural language suport</definiendum>
				<definiens id="0">gives users a whole new way of interacting with any information system</definiens>
			</definition>
</paper>

		<paper id="3509">
</paper>

		<paper id="1809">
			<definition id="0">
				<sentence>Question answering ( QA ) systems are information retrieval systems accepting queries in natural language and returning the results in the form of sentences ( or paragraphs , or phrases ) .</sentence>
				<definiendum id="0">Question answering</definiendum>
				<definiens id="0">information retrieval systems accepting queries in natural language and returning the results in the form of sentences ( or paragraphs , or phrases )</definiens>
			</definition>
			<definition id="1">
				<sentence>Our UM consists of the user’s : • age range , a ∈ { 7−11,11−16 , adult } • reading level , r ∈ { poor , medium , good } • webpages of interest/bookmarks , w The age range parameter has been chosen to match the partition between primary school , contemporary school and higher education age in 2http : //www.cs.york.ac.uk/aig/aqua Britain ; our reading level parameter takes three values which ideally ( but not necessarily ) correspond to the three age ranges and may be further refined in the future for more fine-grained modelling .</sentence>
				<definiendum id="0">UM</definiendum>
			</definition>
			<definition id="2">
				<sentence>Kea outputs a ranked list of phrases , among which we select the top three as keyphrases for each of our documents .</sentence>
				<definiendum id="0">Kea</definiendum>
				<definiens id="0">outputs a ranked list of phrases</definiens>
			</definition>
			<definition id="3">
				<sentence>A unigram language model lms is then built for each set s ; the model consists of a list of the word stems appearing in the training documents with their individual probabilities .</sentence>
				<definiendum id="0">unigram language model lms</definiendum>
				<definiens id="0">a list of the word stems appearing in the training documents with their individual probabilities</definiens>
			</definition>
			<definition id="4">
				<sentence>Such likelihood is estimated using the formula : L ( lmi|D ) = summationdisplay w∈D C ( w , D ) ·log ( P ( w|lmi ) ) where w is a word in the document , C ( w , d ) represents the number of occurrences of w in D and P ( w|lmi ) is the probability that w occurs in lmi ( approached by its frequency ) .</sentence>
				<definiendum id="0">w</definiendum>
			</definition>
			<definition id="5">
				<sentence>—UMmed : “In all Michelangelo painted more than 300 different figures on the Sistine Chapel ceiling.”</sentence>
				<definiendum id="0">—UMmed</definiendum>
			</definition>
</paper>

		<paper id="1907">
			<definition id="0">
				<sentence>In particular , we hypothesize that the answer BT depends on two sets of features CF BP CFB4C9B5 and CG BP CGB4C9B5 as follows : C8B4BT CY C9B5BPC8B4BT CY CFBNCGB5BN ( 1 ) where CF BP DB BD BNBMBMBMBNDB D0 CF can be thought of as a set of D0 CF features describing the “question-type” part of C9 such as who , when , where , which , etc. and CG BP DC BD BNBMBMBMBNDC D0 CG is a set of D0 CG features comprising the “information-bearing” part of C9 i.e. what the question is actually about and what it refers to .</sentence>
				<definiendum id="0">CF BP DB BD BNBMBMBMBNDB D0 CF</definiendum>
				<definiendum id="1">CG</definiendum>
				<definiens id="0">a set of D0 CF features describing the “question-type” part of C9 such as who , when , where , which , etc. and CG BP DC BD BNBMBMBMBNDC D0</definiens>
			</definition>
			<definition id="1">
				<sentence>We therefore introduce an intermediate variable representing classes of example questions-and-answers ( q-and-a ) CR CT for CT BP BDBMBMBMCYBV BX CY drawn from the set BV BX , and to facilitate modelling we say that CF is conditionally independent of BT given CR CT as follows : C8B4CF CY BTB5BP CYBV BX CY CG CTBPBD C8B4CF CY CR CT B5A1C8B4CR CT CY BTB5BM ( 4 ) Given a set BX of example q-and-a D8 CY for CY BP BDBMBMBMCYBXCY where D8 CY BP B4D5 CY BNCP CY B5 BP B4D5 CY BD BNBMBMBMBND5 CY D0 C9 CY BNCP CY BD BNBMBMBMBNCP CY D0 BT CY B5 we define a mapping function CU BM BX AX BV BX by CUB4D8 CY B5 BP CT .</sentence>
				<definiendum id="0">BP B4D5 CY BD BNBMBMBMBND5 CY D0 C9 CY BNCP CY BD BNBMBMBMBNCP CY</definiendum>
				<definiens id="0">follows : C8B4CF CY BTB5BP CYBV BX CY CG CTBPBD C8B4CF CY CR CT B5A1C8B4CR CT CY BTB5BM ( 4 ) Given a set BX of example q-and-a D8 CY for CY BP BDBMBMBMCYBXCY where D8 CY BP B4D5 CY BNCP CY B5</definiens>
			</definition>
			<definition id="2">
				<sentence>Assuming conditional independence of the answer words in class CR CT given BT and making the modelling assumption that the CYth answer word CP CT CY in the example class CR CT is dependent only on the CYth answer word in BT we obtain : C8B4CF CY BTB5BP CYBV BX CY CG CTBPBD C8B4CF CY CR CT B5A1 D0 BT CT CH CYBPBD C8B4CP CT CY CY CP CY B5 BP CYBV BX CY CG CTBPBD C8B4CF CY CR CT B5 D0 BT CT CH CYBPBD CYBV BT CY CG CPBPBD C8B4CP CT CY CY CR CP B5C8B4CR CP CY CP CY B5BN ( 5 ) where CR CP is a concrete class in the set of CYBV BT CY answer classes BV BT , and assuming CP CT CY is conditionally independent of CR CP given CP CY .</sentence>
				<definiendum id="0">BT CT CH CYBPBD C8B4CP CT CY CY CP CY B5 BP CYBV BX CY CG CTBPBD C8B4CF CY CR</definiendum>
				<definiendum id="1">CP CY CP CY B5BN</definiendum>
				<definiendum id="2">CR CP</definiendum>
				<definiens id="0">CT B5 D0 BT CT CH CYBPBD CYBV BT CY CG CPBPBD C8B4CP CT CY CY CR CP B5C8B4CR</definiens>
				<definiens id="1">a concrete class in the set of CYBV BT CY answer classes BV BT</definiens>
			</definition>
			<definition id="3">
				<sentence>The q-and-a ( BV BX ) for different languages can often be found on the web or in commercial quiz software .</sentence>
				<definiendum id="0">q-and-a ( BV BX )</definiendum>
				<definiens id="0">found on the web or in commercial quiz software</definiens>
			</definition>
			<definition id="4">
				<sentence>A more significant problem is that Swedish is a language spoken by only about 9 million people and correspondingly there were far fewer training questions and answers freely available on the web and much less web-data available for finding answers .</sentence>
				<definiendum id="0">Swedish</definiendum>
				<definiens id="0">a language spoken by only about 9 million people and correspondingly there were far fewer training questions and answers freely available on the web and much less web-data available for finding answers</definiens>
			</definition>
</paper>

		<paper id="1654">
			<definition id="0">
				<sentence>Random Indexing is a vector space technique that provides an efficient and scalable approximation to distributional similarity problems .</sentence>
				<definiendum id="0">Random Indexing</definiendum>
				<definiens id="0">a vector space technique that provides an efficient and scalable approximation to distributional similarity problems</definiens>
			</definition>
			<definition id="1">
				<sentence>These vectors consist of a large number of 0s and a small number ( epsilon1 ) of 1s .</sentence>
				<definiendum id="0">These vectors</definiendum>
				<definiens id="0">consist of a large number of 0s and a small number ( epsilon1 ) of 1s</definiens>
			</definition>
			<definition id="2">
				<sentence>The context vector is the sum of the index vectors of all the contexts in which the term appears .</sentence>
				<definiendum id="0">context vector</definiendum>
				<definiens id="0">the sum of the index vectors of all the contexts in which the term appears</definiens>
			</definition>
			<definition id="3">
				<sentence>For each unique 458 IDENTITY 1.0 FREQ f ( w , r , wprime ) RELFREQ f ( w , r , w prime ) f ( w , ∗ , ∗ ) TF-IDF f ( w , r , wprime ) n ( ∗ , r , wprime ) TF-IDF† log2 ( f ( w , r , wprime ) +1 ) log2 ( 1+ N ( r , wprime ) n ( ∗ , r , wprime ) ) MI log ( p ( w , r , wprime ) p ( w , ∗ , ∗ ) p ( ∗ , r , wprime ) ) TTEST p ( w , r , w prime ) −p ( ∗ , r , wprime ) p ( w , ∗ , ∗ ) √ p ( ∗ , r , wprime ) p ( w , ∗ , ∗ ) GREF94 log2 ( f ( w , r , wprime ) +1 ) log2 ( n ( ∗ , r , wprime ) +1 ) LIN98A log ( f ( w , r , wprime ) f ( ∗ , r∗ ) f ( ∗ , r , wprime ) f ( w , r , ∗ ) ) LIN98B −log ( n ( ∗ , r , wprime ) Nw ) CHI2 cf. Manning and Sch¨utze ( 1999 ) LR cf. Manning and Sch¨utze ( 1999 ) DICE 2p ( w , r , w prime ) p ( w , ∗ , ∗ ) +p ( ∗ , r , wprime ) Table 1 : Weight Functions Evaluated context attribute , a d length index vector will be generated .</sentence>
				<definiendum id="0">wprime ) RELFREQ f</definiendum>
				<definiens id="0">r∗ ) f ( ∗ , r , wprime ) f ( w , r , ∗ ) ) LIN98B −log ( n ( ∗ , r , wprime ) Nw</definiens>
			</definition>
			<definition id="4">
				<sentence>Following the notation of Curran ( 2004 ) , a context relation is defined as a tuple ( w , r , wprime ) where w is a term , which occurs in some grammatical relation r with another word wprime in some sentence .</sentence>
				<definiendum id="0">Following the notation of Curran ( 2004 )</definiendum>
				<definiendum id="1">context relation</definiendum>
				<definiens id="0">a tuple ( w , r , wprime ) where w is a term , which occurs in some grammatical relation r with another word wprime in some sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>DIRECT is the number of returned synonyms found in the gold standard .</sentence>
				<definiendum id="0">DIRECT</definiendum>
				<definiens id="0">the number of returned synonyms found in the gold standard</definiens>
			</definition>
			<definition id="6">
				<sentence>INVR is the sum of the inverse rank of each matching synonym , e.g. matches at ranks 3 , 5 and 28 give an inverse rank score of 13 + 15 + 128 .</sentence>
				<definiendum id="0">INVR</definiendum>
				<definiens id="0">the sum of the inverse rank of each matching synonym , e.g. matches at ranks 3 , 5 and 28 give an inverse rank score of 13 + 15 + 128</definiens>
			</definition>
			<definition id="7">
				<sentence>The German abblendlicht ( low beam light ) is treated as a translation candidate for low , beam and light separately .</sentence>
				<definiendum id="0">German abblendlicht</definiendum>
				<definiens id="0">a translation candidate for low , beam and light separately</definiens>
			</definition>
			<definition id="8">
				<sentence>The basic Random Indexing algorithm ( FREQ ) produces a DIRECT score of the only other linear weight , IDENTITY , produces more accurate results .</sentence>
				<definiendum id="0">FREQ</definiendum>
				<definiens id="0">produces a DIRECT score of the only other linear weight , IDENTITY , produces more accurate results</definiens>
			</definition>
			<definition id="9">
				<sentence>TF-IDFy , which is a log-weighted alternative to TF-IDF , produced very good results .</sentence>
				<definiendum id="0">TF-IDFy</definiendum>
				<definiens id="0">a log-weighted alternative to TF-IDF , produced very good results</definiens>
			</definition>
</paper>

		<paper id="3310">
			<definition id="0">
				<sentence>The SLIF ( Subcellular Location Image Finder ) system ( Murphy et al. , 2001 ; Kou et al. , 2003 ) searches protein images reported in literature .</sentence>
				<definiendum id="0">SLIF ( Subcellular Location Image Finder ) system</definiendum>
				<definiens id="0">searches protein images reported in literature</definiens>
			</definition>
			<definition id="1">
				<sentence>Graph consists of bar charts , column charts , line charts , plots and other graphs that are drawn either by authors or by a computer ( e.g. , results of patch clamping ) .</sentence>
				<definiendum id="0">Graph</definiendum>
				<definiens id="0">consists of bar charts , column charts , line charts , plots and other graphs that are drawn either by authors or by a computer ( e.g. , results of patch clamping )</definiens>
			</definition>
			<definition id="2">
				<sentence>We explored supervised machine-learning systems using Support Vector Machines ( SVMs ) which have shown to out-perform many other supervised machine-learning systems for text categorization tasks ( Joachims , 1998 ) .</sentence>
				<definiendum id="0">SVMs )</definiendum>
				<definiens id="0">have shown to out-perform many other supervised machine-learning systems for text categorization tasks</definiens>
			</definition>
			<definition id="3">
				<sentence>From this adjusted , normalized histogram , we calculated the total entropy as the sum of the products of the entries with their logarithms .</sentence>
				<definiendum id="0">total entropy</definiendum>
			</definition>
			<definition id="4">
				<sentence>Edge-Direction Histogram ( Jain and Vailaya , 1996 ) features may help distinguish images with predominantly straight lines such as those found in graphs , diagrams , or charts from other images with more variation in edge orientation .</sentence>
				<definiendum id="0">Edge-Direction Histogram</definiendum>
				<definiens id="0">those found in graphs , diagrams , or charts from other images with more variation in edge orientation</definiens>
			</definition>
			<definition id="5">
				<sentence>An 8-connected region is a group of edge pixels for which each member touches another member vertically , horizontally , or diagonally in the eight adjacent pixel positions surrounding it .</sentence>
				<definiendum id="0">8-connected region</definiendum>
				<definiens id="0">a group of edge pixels for which each member touches another member vertically , horizontally</definiens>
			</definition>
			<definition id="6">
				<sentence>Recall is the total number of true positive predictions divided by the total number of true positives in the set ( true pos + false neg ) .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the total number of true positive predictions divided by the total number of true positives in the set ( true pos + false neg )</definiens>
			</definition>
			<definition id="7">
				<sentence>Precision is the fraction of the number of true positive predictions divided by the total number of positive predictions ( true pos + false pos ) .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the fraction of the number of true positive predictions divided by the total number of positive predictions ( true pos + false pos )</definiens>
			</definition>
</paper>

		<paper id="2404">
			<definition id="0">
				<sentence>html 3 http : //chasen.naist.jp/hiki/ChaSen/ 4 http : //chasen.org/˜taku/software/ cabocha/ 25 Table 1 : Translation Selection of a Japanese Compound Expression “t ( ni ) mMo ( tsuite ) ” � ( watashi ) x ( ha ) t ( kare ) t ( ni ) mMo ( tsuite ) �`h ( hanashita ) ( A ) ( I ) ( TOP ) ( he ) ( about ) ( talked ) ( I talked about him . )</sentence>
				<definiendum id="0">Compound Expression “t</definiendum>
				<definiens id="0">Translation Selection of a Japanese</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , in Table 3 , the expression “qs�q ( to-naru-to ) ” in the sentence ( 2 ) has the meaning “ that ( something ) becomes ∼” , which corresponds to a literal concatenation of the usages of the constituents : the postpositional particle “q” , the verb “s�” , and the post-positional particle “q” , and can be regarded as a content word usage .</sentence>
				<definiendum id="0">expression “qs�q</definiendum>
				<definiens id="0">a content word usage</definiens>
			</definition>
			<definition id="2">
				<sentence>This is because the sequence of the two morphemes “q ( to ) ” and “MO ( iu ) ” constituting the candidate expression “qMO ( to-iu ) ” is a subsequence of the four morphemes constituting the candidate expression “qMO�ww ( to-iu-monono ) ” as below : Morpheme sequence q ( to ) MO ( iu ) �w ( mono ) w ( no ) Candidate expressionqMO ( to-iu ) q ( to ) MO ( iu ) �w ( mono ) w ( no ) Candidate expressionqMO�ww ( to-iu-mono-no ) q ( to ) MO ( iu ) �w ( mono ) w ( no ) This is also the case with the sentence ( 10 ) .</sentence>
				<definiendum id="0">to-iu ) ”</definiendum>
			</definition>
			<definition id="3">
				<sentence>On the other hand , the sentence ( 10 ) is an example of the functional usage of the compound functional expression “qMO�ww ( to-iu-monono ) ” , where the sequence of the four morphemes “ q ( to ) ” , “MO ( iu ) ” , “�w ( mono ) ” , and “w ( no ) ” should be identified and chunked into a compound functional expression .</sentence>
				<definiendum id="0">“w</definiendum>
				<definiens id="0">an example of the functional usage of the compound functional expression “qMO�ww ( to-iu-monono ) ” , where the sequence of the four morphemes “ q ( to ) ”</definiens>
			</definition>
			<definition id="4">
				<sentence>Giving x is the context ( a set of features ) of an input example ; x i and y i ( i =1 , ... , l , x i ∈ R n , y i ∈ { 1 , −1 } ) indicate the context of the training data and its category , respectively ; The decision function f in SVM framework is defined as : f ( x ) =sgn parenleftBigg l summationdisplay i=1 α i y i K ( x i , x ) +b parenrightBigg ( 1 ) where K is a kernel function , b ∈ R is a threshold , and α i are weights .</sentence>
				<definiendum id="0">f ( x</definiendum>
				<definiendum id="1">K</definiendum>
				<definiens id="0">the context ( a set of features ) of an input example ; x i and y i ( i =1 , ... , l , x i ∈ R n , y i ∈ { 1 , −1 } ) indicate the context of the training data and its category</definiens>
				<definiens id="1">a kernel function , b ∈ R is a threshold</definiens>
			</definition>
			<definition id="5">
				<sentence>Besides , the weights α i satisfy the following constraints : 0 ≤ α i ≤ C ( i =1 , ... , l ) ( 2 ) summationtext l i=1 α i y i =0 ( 3 ) where C is a misclassification cost .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a misclassification cost</definiens>
			</definition>
			<definition id="6">
				<sentence>B Current token is the beginning of a chunk .</sentence>
				<definiendum id="0">Current token</definiendum>
				<definiens id="0">the beginning of a chunk</definiens>
			</definition>
			<definition id="7">
				<sentence>The feature set F i is defined as a tuple of the morpheme feature MF ( m i ) of the i-th morpheme m i , the chunk candidate feature CF ( i ) at i-th position , and the chunk context feature OF ( i ) at i-th position .</sentence>
				<definiendum id="0">F i</definiendum>
				<definiendum id="1">CF</definiendum>
				<definiens id="0">a tuple of the morpheme feature MF ( m i ) of the i-th morpheme m i , the chunk candidate feature</definiens>
			</definition>
			<definition id="8">
				<sentence>Suppose that a sequence of morphemes m j ... m i ... m k including m i at the current position i constitutes a candidate functional expression E as below : m j−2 m j−1 m j ... m i ... m k m k+1 m k+2 candidate E of a compound functional expression where the morphemes m j−2 , m j−1 , m k+1 , and m k+2 are at immediate left/right contexts of E. Then , the chunk candidate feature CF ( i ) at i-th position is defined as a tuple of the number of morphemes constituting E and the position of m i in E. The chunk context feature OF ( i ) at i-th position is defined as a tuple of the morpheme features 30 Table 6 : Examples of Chunk Representation and Chunk Candidate/Context Features ( a ) Sentence ( 7 ) of Table 3 ( English Chunk candidate Chunk context Morpheme translation ) Chunk label feature feature \w ( kono ) ( this ) O ∅ ∅ ^� ( giron ) ( discussion ) O ∅ ∅ U ( ga ) ( NOM ) O ∅ ∅ 4�l ( owatt ) ( finish ) O ∅ ∅ h� ( tara ) ( after ) O ∅ ∅ s ( kyuukei ) ( break ) O ∅ ∅ ` ( shi ) ( have ) O ∅ ∅ o ( te ) ( may ) B-functional 〈2 , 1〉 〈 MF ( s ( kyuukei ) ) , ∅ , MF ( ` ( shi ) ) , ∅ , MM ( ii ) I-functional 〈2 , 2〉 MF (  { ( period ) ) , ∅ , ∅ , ∅〉 { ( period ) ( period ) O ∅ ∅ ( b ) Sentence ( 8 ) of Table 3 ( English Chunk candidate Chunk context Morpheme translation ) Chunk label feature feature \w ( kono ) ( this ) O ∅ ∅ Ty� ( bag ) ( discussion ) O ∅ ∅ x ( ha ) ( TOP ) O ∅ ∅ GVX ( ookiku ) ( big ) O ∅ ∅ o ( te ) ( because ) B-content 〈2 , 1〉 〈 MF ( x ( ha ) ) , ∅ , MF ( GVX ( ookiku ) ) , ∅ , MM ( ii ) ( nice ) I-content 〈2 , 2〉 MF (  { ( period ) ) , ∅ , ∅ , ∅〉 { ( period ) ( period ) O ∅ ∅ as well as the chunk candidate features at immediate left/right contexts of E. CF ( i ) =〈 length of E , position of m i in E 〉 OF ( i ) =〈 MF ( m j−2 ) , CF ( j − 2 ) , MF ( m j−1 ) , CF ( j − 1 ) , MF ( m k+1 ) , CF ( k +1 ) , MF ( m k+2 ) , CF ( k +2 ) 〉 Table 6 gives examples of chunk candidate features and chunk context features It can happen that the morpheme at the current position i constitutes more than one candidate compound functional expression .</sentence>
				<definiendum id="0">Candidate/Context Features</definiendum>
				<definiendum id="1">MF</definiendum>
				<definiens id="0">Examples of Chunk Representation and Chunk</definiens>
				<definiens id="1">giron ) ( discussion ) O ∅ ∅ U ( ga ) ( NOM ) O ∅ ∅ 4�l ( owatt ) ( finish ) O ∅ ∅ h� ( tara ) ( after ) O ∅ ∅ s ( kyuukei ) ( break ) O ∅ ∅ ` ( shi ) ( have ) O ∅ ∅ o ( te ) ( may ) B-functional 〈2 , 1〉 〈 MF ( s ( kyuukei ) ) , ∅ ,</definiens>
				<definiens id="2">Chunk candidate Chunk context Morpheme translation ) Chunk label feature feature \w ( kono ) ( this ) O ∅ ∅ Ty� ( bag ) ( discussion ) O ∅ ∅ x ( ha ) ( TOP ) O ∅ ∅ GVX ( ookiku ) ( big ) O ∅ ∅ o ( te ) ( because ) B-content 〈2 , 1〉 〈 MF ( x ( ha ) ) , ∅ , MF ( GVX ( ookiku ) ) , ∅ , MM ( ii ) ( nice ) I-content 〈2 , 2〉 MF (  { ( period ) ) , ∅ , ∅ , ∅〉 { ( period ) ( period ) O ∅ ∅ as well as the chunk candidate features at immediate left/right contexts of E. CF ( i ) =〈 length of E</definiens>
				<definiens id="3">examples of chunk candidate features and chunk context features It can happen that the morpheme at the current position i constitutes more than one candidate compound functional expression</definiens>
			</definition>
</paper>

		<paper id="1316">
			<definition id="0">
				<sentence>The high-level description is a task definition that can easily construct typical agent-based interactive task control information .</sentence>
				<definiendum id="0">high-level description</definiendum>
				<definiens id="0">a task definition that can easily construct typical agent-based interactive task control information</definiens>
			</definition>
			<definition id="1">
				<sentence>The middlelevel description is an interaction description that defines agent’s behavior and user’s input at the granularity of dialogue segment .</sentence>
				<definiendum id="0">middlelevel description</definiendum>
				<definiens id="0">an interaction description that defines agent’s behavior and user’s input at the granularity of dialogue segment</definiens>
			</definition>
			<definition id="2">
				<sentence>The low-level description is a platform dependent description that can override the pre-defined function in the interaction description .</sentence>
				<definiendum id="0">low-level description</definiendum>
				<definiens id="0">a platform dependent description that can override the pre-defined function in the interaction description</definiens>
			</definition>
			<definition id="3">
				<sentence>If the developer wants to make sequential output , it should be written in &lt; smil &gt; element ( Synchronized Multimedia Integration Language ) 4 , For audio output , &lt; audio &gt; element works as the same way as VoiceXML , that is , the content of the element is passed to TTS ( Text-to-Speech module ) and if the audio file is specified by the src attribute , it is a prior output .</sentence>
				<definiendum id="0">VoiceXML</definiendum>
				<definiens id="0">the content of the element is passed to TTS ( Text-to-Speech module</definiens>
				<definiens id="1">a prior output</definiens>
			</definition>
</paper>

		<paper id="0203">
			<definition id="0">
				<sentence>Terminological knowledge consists in definitions of concepts used to describe the sanctioned facts .</sentence>
				<definiendum id="0">Terminological knowledge</definiendum>
			</definition>
			<definition id="1">
				<sentence>Accurate definition extraction is a prerequisite to building up an information system that allows for concept-centred access to the interpretational knowledge spread over tens of thousands of documents produced by courts every year .</sentence>
				<definiendum id="0">Accurate definition extraction</definiendum>
				<definiens id="0">a prerequisite to building up an information system that allows for concept-centred access to the interpretational knowledge spread over tens of thousands of documents produced by courts every year</definiens>
			</definition>
			<definition id="2">
				<sentence>The field query contains an expression characterising a sentence with the predicate vorliegen and a subclause that is introduced by the subjunction wenn ( if ) .</sentence>
				<definiendum id="0">field query</definiendum>
				<definiens id="0">contains an expression characterising a sentence with the predicate vorliegen and a subclause that is introduced by the subjunction wenn ( if )</definiens>
			</definition>
</paper>

		<paper id="2804">
			<definition id="0">
				<sentence>The interlinking process becomes simpler to type by just putting the word ( s ) in square brackets .</sentence>
				<definiendum id="0">interlinking process</definiendum>
				<definiens id="0">becomes simpler to type by just putting the word ( s ) in square brackets</definiens>
			</definition>
			<definition id="1">
				<sentence>It simultaneously creates a new topic title ( a WikiWord ) , a new writing space for that topic and a link to that space .</sentence>
				<definiendum id="0">WikiWord</definiendum>
				<definiens id="0">a new writing space for that topic and a link to that space</definiens>
			</definition>
			<definition id="2">
				<sentence>1 SysOp is the abbreviation for `` systems operator '' , and is a commonly used term for the administrator of a specialinterest area of an online service .</sentence>
				<definiendum id="0">SysOp</definiendum>
				<definiens id="0">the abbreviation for `` systems operator '' , and is a commonly used term for the administrator of a specialinterest area of an online service</definiens>
			</definition>
			<definition id="3">
				<sentence>A contrastive frequency of meaningful keywords has also been 3 Folksonomy is a neologism which indicates a practice of collaborative categorization which makes use of freely chosen keywords .</sentence>
				<definiendum id="0">contrastive frequency</definiendum>
				<definiendum id="1">Folksonomy</definiendum>
				<definiens id="0">a neologism which indicates a practice of collaborative categorization which makes use of freely chosen keywords</definiens>
			</definition>
			<definition id="4">
				<sentence>A table representing a part of the collected data , and their graphical representation , has been provided in Appendix A ( Fig .</sentence>
				<definiendum id="0">table</definiendum>
				<definiens id="0">representing a part of the collected data</definiens>
			</definition>
			<definition id="5">
				<sentence>WikiSpeak is an unofficial and high-context language which can be considered as a new variety of the Netspeak , one of the most creative domains of contemporary English .</sentence>
				<definiendum id="0">WikiSpeak</definiendum>
				<definiens id="0">an unofficial and high-context language</definiens>
			</definition>
			<definition id="6">
				<sentence>WikiSpeak is an informal and colloquial language rich , for example , in acronyms [ i.e. NPOV ( Neutral Point Of View ) , COTW ( Collaboration Of The Week ) , IFD ( Image For Deletion ) , etc ] .</sentence>
				<definiendum id="0">WikiSpeak</definiendum>
				<definiens id="0">an informal and colloquial language rich</definiens>
			</definition>
			<definition id="7">
				<sentence>6 CamelCase is the practice of writing compound words or phrases where the words are joined without spaces , and each word is capitalized within the compound .</sentence>
				<definiendum id="0">CamelCase</definiendum>
				<definiens id="0">the practice of writing compound words or phrases where the words are joined without spaces , and each word is capitalized within the compound</definiens>
			</definition>
			<definition id="8">
				<sentence>It is the point of view of this study that Wikipedia can be taken as an example of the evolution of an extant traditional genre ( encyclopedias ) which has been officially preserved in the articles’ superficial form , but not in the writing and reading processes ( social editing , intertextuality , high informativeness and browsing mechanisms ) .</sentence>
				<definiendum id="0">encyclopedias</definiendum>
				<definiens id="0">the articles’ superficial form , but not in the writing and reading processes ( social editing , intertextuality , high informativeness and browsing mechanisms</definiens>
			</definition>
			<definition id="9">
				<sentence>Encyclopaedia Britannica is a knowledge compendium without any political meaning hosted by a commercial website ( .</sentence>
				<definiendum id="0">Encyclopaedia Britannica</definiendum>
				<definiens id="0">a knowledge compendium without any political meaning hosted by a commercial website (</definiens>
			</definition>
</paper>

		<paper id="2923">
</paper>

		<paper id="2103">
</paper>

		<paper id="0137">
			<definition id="0">
				<sentence>A MSU is a character or a string which is the minimal unit in a text fragment that can not be segmented any more .</sentence>
				<definiendum id="0">MSU</definiendum>
				<definiens id="0">a character or a string which is the minimal unit in a text fragment that can not be segmented any more</definiens>
			</definition>
			<definition id="1">
				<sentence>Besides the classes above , we define a tag ”NL” as a special MSU , which refers to the beginning or ending of a text fragment .</sentence>
				<definiendum id="0">tag ”NL”</definiendum>
				<definiens id="0">a special MSU , which refers to the beginning or ending of a text fragment</definiens>
			</definition>
			<definition id="2">
				<sentence>Then we can extract all of the features from the text fragment and decide which check point we should tag as r = 0 by this equation : p ( r|c ) = 1Z Kproductdisplay j=1 αfj ( r|c ) j ( 1 ) where K is the number of features , Z is the normalization constant used to ensure that a probability distribution results , and c represents the context of the check point .</sentence>
				<definiendum id="0">K</definiendum>
				<definiendum id="1">Z</definiendum>
				<definiendum id="2">c</definiendum>
				<definiens id="0">the number of features</definiens>
				<definiens id="1">the normalization constant used to ensure that a probability distribution results , and</definiens>
			</definition>
			<definition id="3">
				<sentence>The WFP of a character is defined as : WFP ( c ) = Nwc/Nc , where Nwc is the number of times that the character c appears in a word of at least 2 characters in the training corpus , Nc is the number of times the character c occursinthetrainingcorpus .</sentence>
				<definiendum id="0">WFP of a character</definiendum>
				<definiendum id="1">Nwc</definiendum>
				<definiendum id="2">Nc</definiendum>
				<definiens id="0">the number of times that the character c appears in a word of at least 2 characters in the training corpus ,</definiens>
				<definiens id="1">the number of times the character c occursinthetrainingcorpus</definiens>
			</definition>
</paper>

		<paper id="1207">
			<definition id="0">
				<sentence>Predominant sense identification is a useful component of sense disambiguation of word tokens ( McCarthy et al. , 2004 ) , and we presume our VPC type classification work will form the basis for later token disambiguation .</sentence>
				<definiendum id="0">Predominant sense identification</definiendum>
				<definiens id="0">a useful component of sense disambiguation of word tokens</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , in sentence ( 3 ) , the TR is the balloon and the LM is the ground the balloon is moving away from .</sentence>
				<definiendum id="0">TR</definiendum>
				<definiendum id="1">LM</definiendum>
				<definiens id="0">the balloon and the</definiens>
			</definition>
			<definition id="2">
				<sentence>Cmpl-up is a sub-sense of Goal-up in which the goal represents an action being done to completion .</sentence>
				<definiendum id="0">Cmpl-up</definiendum>
				<definiens id="0">an action being done to completion</definiens>
			</definition>
</paper>

		<paper id="3405">
</paper>

		<paper id="1613">
			<definition id="0">
				<sentence>Neither the author’s abstract , nor raw citation counts help users in assessing the relation between articles .</sentence>
				<definiendum id="0">raw citation counts</definiendum>
				<definiens id="0">users in assessing the relation between articles</definiens>
			</definition>
			<definition id="1">
				<sentence>Our evaluation corpus for citation analysis consists of 116 articles ( randomly drawn from the part of our corpus which was not used for guideline development or cue phrase acquisition ) .</sentence>
				<definiendum id="0">evaluation corpus for citation analysis</definiendum>
				<definiens id="0">consists of 116 articles ( randomly drawn from the part of our corpus which was not used for guideline development or cue phrase acquisition )</definiens>
			</definition>
			<definition id="2">
				<sentence>Macro-F is the mean of the F-measures of all twelve categories .</sentence>
				<definiendum id="0">Macro-F</definiendum>
				<definiens id="0">the mean of the F-measures of all twelve categories</definiens>
			</definition>
			<definition id="3">
				<sentence>Kappa has the additional advantage over Macro-F that it lters out random agreement ( random use , but following the observed distribution of categories ) .</sentence>
				<definiendum id="0">Kappa</definiendum>
				<definiens id="0">has the additional advantage over Macro-F that it lters out random agreement</definiens>
			</definition>
</paper>

		<paper id="1669">
			<definition id="0">
				<sentence>Word sense disambiguation ( WSD ) is a key enabling-technology .</sentence>
				<definiendum id="0">Word sense disambiguation ( WSD</definiendum>
				<definiens id="0">a key enabling-technology</definiens>
			</definition>
			<definition id="1">
				<sentence>PageRank is an iterative algorithm that ranks all the vertices according to their relative importance within the graph following a random-walk model .</sentence>
				<definiendum id="0">PageRank</definiendum>
				<definiens id="0">an iterative algorithm that ranks all the vertices according to their relative importance within the graph following a random-walk model</definiens>
			</definition>
			<definition id="2">
				<sentence>The rank of vi is de ned as : P ( vi ) = ( 1−d ) + d summationdisplay j∈In ( vi ) wjisummationtext k∈In ( vj ) wjk P ( vj ) where wij is the weight of the link between vertices vi and vj , and 0 ≤ d ≤ 1 .</sentence>
				<definiendum id="0">wij</definiendum>
				<definiens id="0">the weight of the link between vertices vi and vj</definiens>
			</definition>
			<definition id="3">
				<sentence>If the scores are organized in a score vector , all values are 0 , except , say , the i-th component , which receives a score d ( hi , v ) , which is the distance between the hub hi and the node representing the word v. Thus , d ( hi , v ) assigns a score of 1 to hubs and the score decreases as the nodes move away from the hub in the tree .</sentence>
				<definiendum id="0">i-th component</definiendum>
				<definiens id="0">receives a score d ( hi , v ) , which is the distance between the hub hi and the node representing the word v. Thus , d ( hi , v ) assigns a score of 1 to hubs and the score decreases as the nodes move away from the hub in the tree</definiens>
			</definition>
			<definition id="4">
				<sentence>Note that the mapping introduces noise and information loss , which is a disadvantage when comparing to other systems that rely on the gold-standard senses .</sentence>
				<definiendum id="0">information loss</definiendum>
				<definiens id="0">a disadvantage when comparing to other systems that rely on the gold-standard senses</definiens>
			</definition>
			<definition id="5">
				<sentence>The WSD system rst tags the training part of some hand-annotated corpus with the induced hubs .</sentence>
				<definiendum id="0">WSD system rst</definiendum>
				<definiens id="0">tags the training part of some hand-annotated corpus with the induced hubs</definiens>
			</definition>
			<definition id="6">
				<sentence>kNN-all is a state-of-the-art system ( Agirre et al. , 2005 ) using wide range of local and topical features , and only 2.3 points below the best S3LS system .</sentence>
				<definiendum id="0">kNN-all</definiendum>
				<definiens id="0">a state-of-the-art system</definiens>
			</definition>
</paper>

		<paper id="3811">
			<definition id="0">
				<sentence>A nearsynonym is a word that can be used instead of another one , in some contexts , without too much change in meaning .</sentence>
				<definiendum id="0">nearsynonym</definiendum>
				<definiens id="0">a word that can be used instead of another one</definiens>
			</definition>
</paper>

		<paper id="2933">
			<definition id="0">
				<sentence>We projectivize training data by a minimal transformation , lifting non-projective arcs one step at a time , and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson ( 2005 ) , which means that a lifted arc is assigned the label r↑h , where r is the original label and h is the label of the original head in the nonprojective dependency graph .</sentence>
				<definiendum id="0">r</definiendum>
				<definiens id="0">the original label and h is the label of the original head in the nonprojective dependency graph</definiens>
			</definition>
			<definition id="1">
				<sentence>Moreover , when we break down the results according to whether the head of a dependency is part of a multiple-IG word or a complete ( single-IG ) word , we observe a highly significant difference in accuracy , with only 53.2 % unlabeled attachment score for multiple-IG heads versus 83.7 % for single-IG heads .</sentence>
				<definiendum id="0">complete</definiendum>
				<definiens id="0">the results according to whether the head of a dependency is part of a multiple-IG word or a</definiens>
			</definition>
</paper>

		<paper id="1604">
			<definition id="0">
				<sentence>The ERG is a hand-built grammar and thus does not have the same coverage as the grammar we use .</sentence>
				<definiendum id="0">ERG</definiendum>
				<definiens id="0">a hand-built grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>WOODWARD consists of two components : a semantic interpreter that takes a parse tree and converts it to a conjunction of first-order predicates , and a sequence of four increasingly sophisticated methods that check semantic plausibility of conjuncts on the Web .</sentence>
				<definiendum id="0">WOODWARD</definiendum>
			</definition>
			<definition id="2">
				<sentence>Each relation in an RC consists of a relation name and a tuple of variables and string constants representing the arguments of the relation .</sentence>
				<definiendum id="0">relation in an RC</definiendum>
				<definiens id="0">consists of a relation name and a tuple of variables and string constants representing the arguments of the relation</definiens>
			</definition>
			<definition id="3">
				<sentence>VAST counts these as well , and considers the sum of the noun and clause arguments as the number of essential arguments .</sentence>
				<definiendum id="0">VAST</definiendum>
				<definiens id="0">counts these as well , and considers the sum of the noun</definiens>
			</definition>
			<definition id="4">
				<sentence>TextRunner provides a search interface to a set of over a billion triples of the form ( object string , predicate string , object string ) that have been extracted automatically from approximately 90 million documents to date .</sentence>
				<definiendum id="0">TextRunner</definiendum>
				<definiens id="0">object string , predicate string , object string</definiens>
			</definition>
			<definition id="5">
				<sentence>The TextRunner semantic filter checks the validity of an RC conjunct in a natural way : it asks TextRunner for the number of tuples that match the argument heads and relation name of the conjunct being checked .</sentence>
				<definiendum id="0">TextRunner semantic filter</definiendum>
				<definiens id="0">checks the validity of an RC conjunct in a natural way : it asks TextRunner for the number of tuples that match the argument heads and relation name of the conjunct being checked</definiens>
			</definition>
			<definition id="6">
				<sentence>It relies on TextRunner and KnowItNow ( Cafarella et al. , 2005 ) to quickly find possible answers , given the relational conjunction ( RC ) of the question .</sentence>
				<definiendum id="0">RC</definiendum>
				<definiens id="0">Cafarella et al. , 2005 ) to quickly find possible answers , given the relational conjunction</definiens>
			</definition>
			<definition id="7">
				<sentence>KnowItNow is a state of the art Information Extraction system that uses a set of domain independent patterns to efficiently find hyponyms of a class .</sentence>
				<definiendum id="0">KnowItNow</definiendum>
				<definiens id="0">a state of the art Information Extraction system that uses a set of domain independent patterns to efficiently find hyponyms of a class</definiens>
			</definition>
			<definition id="8">
				<sentence>We formalize the process as follows : define a question as a set of variables Xi corresponding to noun phrases , a set of noun type predicates Ti ( Xi ) , and a set of relational predicates Pi ( Xi1 , ... , Xik ) which relate one or more variables and constants .</sentence>
				<definiendum id="0">noun phrases</definiendum>
				<definiens id="0">define a question as a set of variables Xi corresponding to</definiens>
			</definition>
			<definition id="9">
				<sentence>We define an answer as a set of values for each variable that satisfies all types and predicates ans ( x1 , ... , xn ) = logicalanddisplay i Ti ( xi ) ∧ logicalanddisplay j Pj ( xj1 , ... , xjk ) The algorithm is as follows : 31 values for Xi , using KnowItNow .</sentence>
				<definiendum id="0">answer</definiendum>
				<definiendum id="1">, xjk</definiendum>
				<definiens id="0">x1 , ... , xn ) = logicalanddisplay i Ti ( xi ) ∧ logicalanddisplay j Pj ( xj1 , ...</definiens>
			</definition>
			<definition id="10">
				<sentence>WOODWARD combines the four semantic filters in a way that draws on each of their strengths .</sentence>
				<definiendum id="0">WOODWARD</definiendum>
			</definition>
			<definition id="11">
				<sentence>Parser efficacy reports the percentage of sentences that the Collins parser parsed correctly .</sentence>
				<definiendum id="0">Parser efficacy</definiendum>
				<definiens id="0">reports the percentage of sentences that the Collins parser parsed correctly</definiens>
			</definition>
			<definition id="12">
				<sentence>Filter precision is defined as the ratio of correctly parsed sentences in the filtered set to total sentences in the filtered set .</sentence>
				<definiendum id="0">Filter precision</definiendum>
				<definiens id="0">the ratio of correctly parsed sentences in the filtered set to total sentences in the filtered set</definiens>
			</definition>
			<definition id="13">
				<sentence>Filter recall is defined as the ratio of correctly parsed sentences in the filtered set to correctly parsed sentences in the unfiltered set .</sentence>
				<definiendum id="0">Filter recall</definiendum>
				<definiens id="0">the ratio of correctly parsed sentences in the filtered set to correctly parsed sentences in the unfiltered set</definiens>
			</definition>
			<definition id="14">
				<sentence>Our WSJ test set is a subset of the set of sentences used in Collins’ experiments , so our results are not directly comparable , but we do achieve a roughly similar decrease in error rate ( 20 % ) when we use our filtered precision/recall metrics .</sentence>
				<definiendum id="0">WSJ test set</definiendum>
				<definiens id="0">a subset of the set of sentences used in Collins’ experiments</definiens>
			</definition>
</paper>

		<paper id="3806">
			<definition id="0">
				<sentence>requires to detect that : ilar to T1 and H3 is more similar to H1 than to H2 ; ( T3 , H3 ) ( e.g. , T3 and H3 have the same noun governing the subject of the main sentence ) are similar to the relations between sentences in the pairs ( T1 , H1 ) and ( T1 , H2 ) .</sentence>
				<definiendum id="0">H3</definiendum>
				<definiens id="0">the same noun governing the subject of the main sentence ) are similar to the relations between sentences in the pairs</definiens>
			</definition>
			<definition id="1">
				<sentence>This function should consider pairs similar when : ( 1 ) texts and hypotheses are structurally and lexically similar ( structural similarity ) ; ( 2 ) the relations between the sentences in the pair ( Tprime , Hprime ) are compatible with the relations in ( Tprimeprime , Hprimeprime ) ( intra-pair word movement compatibility ) .</sentence>
				<definiendum id="0">Hprimeprime )</definiendum>
				<definiens id="0">the relations between the sentences in the pair ( Tprime , Hprime ) are compatible with the relations in ( Tprimeprime ,</definiens>
			</definition>
			<definition id="2">
				<sentence>mappings from aprime ⊆ Aprime : |aprime| = |Aprimeprime| to Aprimeprime , an element c ∈ C is a substitution function .</sentence>
				<definiendum id="0">C</definiendum>
			</definition>
			<definition id="3">
				<sentence>The coindexed tree pair similarity is then defined as : Ks ( ( Tprime , Hprime ) , ( Tprimeprime , Hprimeprime ) ) = maxc∈C ( KT ( t ( Hprime , c ) , t ( Hprimeprime , i ) ) +KT ( t ( Tprime , c ) , t ( Tprimeprime , i ) ) where ( 1 ) t ( S , c ) returns the syntactic tree of the hypothesis ( text ) S with placeholders replaced by means of the substitution c , ( 2 ) i is the identity substitution and ( 3 ) KT ( t1 , t2 ) is a function that measures the similarity between the two trees t1 and t2 .</sentence>
				<definiendum id="0">Ks ( ( Tprime , Hprime</definiendum>
				<definiendum id="1">maxc∈C ( KT ( t</definiendum>
				<definiendum id="2">t ( S , c )</definiendum>
				<definiendum id="3">t2 )</definiendum>
				<definiens id="0">returns the syntactic tree of the hypothesis ( text ) S with placeholders replaced by means of the substitution c</definiens>
				<definiens id="1">a function that measures the similarity between the two trees t1 and t2</definiens>
			</definition>
			<definition id="4">
				<sentence>For the experiments , we used the Recognizing Textual Entailment ( RTE ) Challenge data sets , which we name as D1 , T1 and D2 , T2 , are the development and the test sets of the first and second RTE challenges , respectively .</sentence>
				<definiendum id="0">Recognizing Textual Entailment</definiendum>
				<definiens id="0">the development and the test sets of the first and second RTE challenges , respectively</definiens>
			</definition>
</paper>

		<paper id="2811">
			<definition id="0">
				<sentence>FLICKR is an onlinetoolformanagingandsharingpersonalphotographsandcurrentlycontainsover five million freelyaccessibleimages .</sentence>
				<definiendum id="0">FLICKR</definiendum>
				<definiens id="0">an onlinetoolformanagingandsharingpersonalphotographsandcurrentlycontainsover five million freelyaccessibleimages</definiens>
			</definition>
			<definition id="1">
				<sentence>FLICKR provides both private and public imagestorage , and photoswhichare shared ( around5 million ) canbe protectedundera CreativeCommons ( CC ) licensing5 agreement ( analternative to fullcopyright ) .</sentence>
				<definiendum id="0">FLICKR</definiendum>
				<definiens id="0">provides both private and public imagestorage</definiens>
			</definition>
</paper>

		<paper id="3118">
			<definition id="0">
				<sentence>Briefly , Portage is a research vehicle and development prototype system exploiting the state-of-the-art in statistical machine translation ( SMT ) .</sentence>
				<definiendum id="0">Portage</definiendum>
				<definiens id="0">a research vehicle and development prototype system exploiting the state-of-the-art in statistical machine translation ( SMT )</definiens>
			</definition>
			<definition id="1">
				<sentence>This replaces each observed joint frequency c with cg = ( c + 1 ) nc+1/nc , where nc is the number of distinct pairs with frequency c ( smoothed for large c ) .</sentence>
				<definiendum id="0">nc</definiendum>
				<definiens id="0">the number of distinct pairs with frequency c ( smoothed for large c )</definiens>
			</definition>
			<definition id="2">
				<sentence>The second strategy is Kneser-Ney smoothing ( Kneser and Ney , 1995 ) , using the interpolated variant described in ( Chen and Goodman. , 1998 ) :1 pk ( s|t ) = c ( s , t ) − D + D n1+ ( ∗ , t ) pk ( s ) summationtext s c ( s , t ) where D = n1/ ( n1 + 2n2 ) , n1+ ( ∗ , t ) is the number of distinct phrases s with which t co-occurs , and pk ( s ) = n1+ ( s , ∗ ) /summationtexts n1+ ( s , ∗ ) , with n1+ ( s , ∗ ) analogous to n1+ ( ∗ , t ) .</sentence>
				<definiendum id="0">Kneser-Ney smoothing</definiendum>
				<definiens id="0">the number of distinct phrases s with which t co-occurs</definiens>
			</definition>
</paper>

		<paper id="1807">
			<definition id="0">
				<sentence>In order to merge a new story with the current working merged story ( WMS ) , the facts in the WMS are examined one by one in an attempt to match them to a fact in the story to be merged .</sentence>
				<definiendum id="0">WMS</definiendum>
				<definiens id="0">the facts in the WMS are examined one by one in an attempt to match them to a fact in the story to be merged</definiens>
			</definition>
			<definition id="1">
				<sentence>Finally , the primary benefit of the use of knowledge representation is the possibility of using inference .</sentence>
				<definiendum id="0">knowledge representation</definiendum>
				<definiens id="0">the possibility of using inference</definiens>
			</definition>
</paper>

		<paper id="1515">
			<definition id="0">
				<sentence>This paper contrasts two frameworks for computational semantics , the proposal for semantics in LTAG described in ( Kallmeyer and Romero , 2005 ) and LRS ( Richter and Sailer , 2004 ) , a computational semantics framework formulated in HeadDriven Phrase Structure Grammar ( HPSG ) .</sentence>
				<definiendum id="0">LRS</definiendum>
			</definition>
			<definition id="1">
				<sentence>These fundamental differences are reflected in the respective architectures for semantics : LTAG assumes a separate level of underspecified semantic representations ; LRS uses the description logic of syntax for semantic specifications .</sentence>
				<definiendum id="0">LTAG</definiendum>
				<definiendum id="1">LRS</definiendum>
				<definiens id="0">assumes a separate level of underspecified semantic representations</definiens>
				<definiens id="1">uses the description logic of syntax for semantic specifications</definiens>
			</definition>
			<definition id="2">
				<sentence>With the assignments following from the feature identifications we obtain the semantic representation ( 6 ) : ( 6 ) l1 : laugh ( x ) , l2 : every ( x , 4 , 5 ) , l3 : person ( x ) 2 ≥ l1 , 4 ≥ l3 , 2 ≥ 5 , 5 ≥ l1 There is one possible disambiguation consistent with the scope constraints , namely 2 → l2 , 4 → l3 , 5 → l1 .</sentence>
				<definiendum id="0">l2</definiendum>
				<definiens id="0">one possible disambiguation consistent with the scope constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>LTAG ( both syntax and semantics ) is a formalism with restricted expressive power that guarantees good formal properties .</sentence>
				<definiendum id="0">LTAG</definiendum>
			</definition>
</paper>

		<paper id="1617">
			<definition id="0">
				<sentence>A successful PropBank-based SRL system would correctly determine that “Ben Bernanke” is the subject ( labeled as ARG0 in PropBank ) of predicate “replace” , and “Greenspan” is the object ( labeled as ARG1 ) : • Ben Bernanke replaced Greenspan as Fed chair .</sentence>
				<definiendum id="0">“Greenspan”</definiendum>
				<definiens id="0">the object ( labeled as ARG1 ) : • Ben Bernanke replaced Greenspan as Fed chair</definiens>
			</definition>
			<definition id="1">
				<sentence>Zx is a normalization factor .</sentence>
				<definiendum id="0">Zx</definiendum>
				<definiens id="0">a normalization factor</definiens>
			</definition>
			<definition id="2">
				<sentence>Max ( T ) = max braceleftbigg NONE ( T ) +summationtext ( Max ( child ) ) ARG ( T ) +summationtext ( NONETree ( child ) ) ( 2 ) Max ( T ) is the maximum log-probability of a tree T , NONE ( T ) and ARG ( T ) are respectively the log-probability of assigning label “NONE” and “ARG” by our argument identification model to tree node T , child ranges through each of T’s children , and NONETree ( child ) is the logprobability of each node that is dominated by node child being labeled as “NONE” .</sentence>
				<definiendum id="0">Max</definiendum>
				<definiendum id="1">NONETree ( child )</definiendum>
				<definiens id="0">the maximum log-probability of a tree T , NONE ( T ) and ARG ( T ) are respectively the log-probability of assigning label “NONE” and “ARG” by our argument identification model to tree node T</definiens>
				<definiens id="1">the logprobability of each node that is dominated by node child being labeled as “NONE”</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , feature b11FW in the group b11 denotes the first word spanned by the constituent and b13LH denotes the left sister’s head word .</sentence>
				<definiendum id="0">b13LH</definiendum>
				<definiens id="0">the left sister’s head word</definiens>
			</definition>
			<definition id="4">
				<sentence>The current NomBank release also contains the “NOMLEX-PLUS” dictionary , which contains the class of nominal predicates according to their origin and the roles they play .</sentence>
				<definiendum id="0">“NOMLEX-PLUS” dictionary</definiendum>
				<definiens id="0">contains the class of nominal predicates according to their origin and the roles they play</definiens>
			</definition>
</paper>

	</volume>
