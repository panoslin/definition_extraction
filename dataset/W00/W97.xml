<?xml version="1.0" encoding="UTF-8"?>
	<volume id="W97">

		<paper id="1016">
			<definition id="0">
				<sentence>We compare Memory-Based Learning , which stores examples in memory and generalizes by using intelligent similarity metrics , with a number of recently proposed statistical methods that are well suited to large numbers of features .</sentence>
				<definiendum id="0">Memory-Based Learning</definiendum>
				<definiens id="0">stores examples in memory and generalizes by using intelligent similarity metrics , with a number of recently proposed statistical methods that are well suited to large numbers of features</definiens>
			</definition>
			<definition id="1">
				<sentence>In this paper , we examine whether Memory-Based Learning ( MBL ) , a family of statistical methods from the field of Machine Learning , can improve on the performance of previous approaches .</sentence>
				<definiendum id="0">Memory-Based Learning ( MBL</definiendum>
				<definiens id="0">a family of statistical methods from the field of Machine Learning</definiens>
			</definition>
			<definition id="2">
				<sentence>The Information Gain of feature f is measured by computing the difference in uncertainty ( i.e. entropy ) between the situations without and with knowledge of the value of that feature ( Equation 3 ) : w !</sentence>
				<definiendum id="0">Information Gain of feature f</definiendum>
				<definiens id="0">measured by computing the difference in uncertainty ( i.e. entropy ) between the situations without and with knowledge of the value of that feature</definiens>
			</definition>
			<definition id="3">
				<sentence>= H ( C ) Eveyf P ( v ) × H ( CIv ) sift ) ( 3 ) si ( f ) = E P ( v ) log 2 P ( v ) ( 4 ) veVf Where C is the set of class labels , V !</sentence>
				<definiendum id="0">veVf Where C</definiendum>
				<definiens id="0">the set of class labels</definiens>
			</definition>
			<definition id="4">
				<sentence>is the set of values for feature f , and H ( C ) : -EeeC P ( c ) log 2P ( c ) is the entropy of the class labels .</sentence>
				<definiendum id="0">H ( C )</definiendum>
				<definiens id="0">the entropy of the class labels</definiens>
			</definition>
			<definition id="5">
				<sentence>PCA accomplishes the dimension reduction that preserves as much of the structure of the original data as possible .</sentence>
				<definiendum id="0">PCA</definiendum>
				<definiens id="0">accomplishes the dimension reduction that preserves as much of the structure of the original data as possible</definiens>
			</definition>
			<definition id="6">
				<sentence>dk-dj if dk ~ dl 4k-d , ( 6 ) Wj = 1 if dk = dl where dj is the distance to the query of the j'th nearest neighbor , dl the distance of the nearest neighbor , and dk the distance of the furthest ( k'th ) neighbor .</sentence>
				<definiendum id="0">dj</definiendum>
				<definiens id="0">the distance to the query of the j'th nearest neighbor , dl the distance of the nearest neighbor , and dk the distance of the furthest ( k'th ) neighbor</definiens>
			</definition>
			<definition id="7">
				<sentence>The values of k , the voting function , and the IG weights were determined on the training and validation sets .</sentence>
				<definiendum id="0">IG</definiendum>
				<definiens id="0">weights were determined on the training and validation sets</definiens>
			</definition>
</paper>

		<paper id="0217">
</paper>

		<paper id="0308">
			<definition id="0">
				<sentence>The following sequences can then be computed from each corpus : W ( z , * } the terminal elements S { t , * } the terminal elements and structural delimiters So S is the corpus retaining structural annotation , and W is a `` text only '' version of the corpus .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">the corpus retaining structural annotation , and</definiens>
			</definition>
</paper>

		<paper id="0805">
			<definition id="0">
				<sentence>WORDNET is a thesaurus for the English language based on psycholinguistics principles and developed at the Princeton University by George Miller \ [ Miller , 1990\ ] .</sentence>
				<definiendum id="0">WORDNET</definiendum>
			</definition>
			<definition id="1">
				<sentence>The WORDNET verb taxonomy is based on the ~roponymy relation , which is defined as the co-occurrence of both lexical implication and temporal co-extension between two verbs .</sentence>
				<definiendum id="0">WORDNET verb taxonomy</definiendum>
				<definiendum id="1">~roponymy relation</definiendum>
			</definition>
			<definition id="2">
				<sentence>mge -- Unit V PropertyV Address-SpeechV Print-Media Write-Music Person Music -Write-Communicate Somebody Somebody ( Written-4 { aterialA ~Section ) V Symbolic-Repres V SayingV Sentence V NameV Message V Message-ContentV Code V Date V Property Write-Publish Somebody Written-MateriaiV Print..-MediaV Publishing-House ( Print-MediaA ~Section ) Write-Send Somebody CorrespondenceV MessageV Somebody Letter-Missive Figure 4 : Lexical entries for Scriveze ( Writs ) .</sentence>
				<definiendum id="0">Print..-MediaV Publishing-House</definiendum>
				<definiens id="0">V SayingV Sentence V NameV Message V Message-ContentV Code V Date V Property Write-Publish Somebody Written-MateriaiV</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , that `` a queen-Regnant could ~/rlte-Music an Letter-Missive '' ( i.e. , a kind of correspondence ) is one of the allowed readings .</sentence>
				<definiendum id="0">Letter-Missive ''</definiendum>
				<definiens id="0">one of the allowed readings</definiens>
			</definition>
</paper>

		<paper id="0122">
			<definition id="0">
				<sentence>For a contingency table of dimensions m x n , if the null hypothesis is true , the statistic E ) 2 E ( where 0 is the observed value , E is the expected value calculated on the basis of the joint corpus , and the sum is over the cells of the contingency table ) will be M-distributed with ( rn 1 ) x ( n 1 ) degrees of freedom .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">the expected value calculated on the basis of the joint corpus , and the sum is over the cells of the contingency table ) will be M-distributed with ( rn 1 ) x ( n 1 ) degrees of freedom</definiens>
			</definition>
			<definition id="1">
				<sentence>Horn is the homogeneity of each corpus .</sentence>
				<definiendum id="0">Horn</definiendum>
				<definiens id="0">the homogeneity of each corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>243 Mirror Guardian WORD POS ~ WORD POS • PRON DET '' l ON she PRON n't NOT he PRON 's V her DET his DET we PRON 're vhb you PRON mirror PN her PRON boss N my dps him PRON star N after PREP me PRON was V your DET 'm V said V major PN away PART mnm N night N a DET tv N just ADV fergie PN Guardian Independent WORD POS WORD POS the mr PN of PREP million NUMBER mr PN christmas PN its DET bill N which REL page N-PN government N romania PN by PREP gen PN that CONJ billion NUM us PN clowes PN european ADJ-N ambulance N political ADJ romanian ADJ part F N guardian PN however ADV eastern PN east PN summit N kong PN europe PN hong PN dixons PN market N ceausescu PN per cent N aged PREP group N panama PN national ADJ december PN in PREP barlow PN president PN hurd PN soviet ADJ havel PN eu~pe PN beijing PN cup N-PN bucharest PN military ADJ commons N minister N-PN january PN not NOT thatcher PN berlin PN sport N conference N in-short ADV rates N peking PN lawson PN sir N-PN interest N blackpool PN football N-PN october PN knighton PN is V / PREP mandela PN conservative ADJ-N base ADJ-N Table 10 : Mirror-Guardian and Guardian-Independent comparisons : high-contrast words .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">your DET 'm V said V major PN away PART</definiens>
				<definiens id="1">Mirror-Guardian and Guardian-Independent comparisons : high-contrast words</definiens>
			</definition>
</paper>

		<paper id="0701">
</paper>

		<paper id="0121">
			<definition id="0">
				<sentence>£n ) and has an exponential form : p ( wi ) = ½e E×¢Exxx¢*'fx¢ ( w ' ) where ( 2 ) * T is a set of instantiated by their values atomic features of the model ; * w/ is a described by the model entity which can be represented as a configuration of the instantiated atomic features from T. We will call wi a configuration from con .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">a set of instantiated by their values atomic features of the model ; * w/ is a described by the model entity which can be represented as a configuration of the instantiated atomic features from T. We will call wi a configuration from con</definiens>
			</definition>
			<definition id="1">
				<sentence>figuration space • W. The configuration space W includes not only observed configurations ( w ) but rather all possible in the domain configurations many of which might have not ever been observed ; * X1 is a constraint from the constraint space X imposed to the model .</sentence>
				<definiendum id="0">* X1</definiendum>
				<definiens id="0">a constraint from the constraint space X imposed to the model</definiens>
			</definition>
			<definition id="2">
				<sentence>This function takes two values : 1 if the constraint is active and 0 otherwise ; • ~ ( Lagrange multiplier ) is the weight of the j-th constraint ( Xj ) ; • Z is the normalization constant which ensures that the probabilities for all configurations sum up to 1 : z= ( 3 ) wiEW Apart from being a distribution of maximum entropy this distribution also po6sesses a very important property of model decomposition .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiens id="0">the weight of the j-th constraint ( Xj ) ; •</definiens>
			</definition>
			<definition id="3">
				<sentence>Now our model will predict the probability for the word `` Mr. '' as : 1Note here the difference between atomic features and constraint features : constraint features consist from atomic features but we can have a set of constraints which does not include some or even all atomic features per se but only their combinations .</sentence>
				<definiendum id="0">Mr.</definiendum>
			</definition>
			<definition id="4">
				<sentence>~ ( ~ , y ) * ~ ( ~ ) * pCy I ~ ) = p ( xk ) ( 9 ) x6X yEY xEX yEY where ~ ( x , y ) is an empirical probability of a joint configuration ( w ) of certain instantiated factor I variables with certain instantiated behavior variables .</sentence>
				<definiendum id="0">y )</definiendum>
			</definition>
			<definition id="5">
				<sentence>~ ( x ) is the marginal empirical probability of the factor variables .</sentence>
				<definiendum id="0">~ ( x )</definiendum>
			</definition>
			<definition id="6">
				<sentence>Formally , the feature collocation lattice is a 3-ple : ( 0 , C_ , ~ &gt; where 222 0 is a set of nodes of the lattice which corresponds tothe union of the feature space of the maximum entropy model and the configuration space : 8 = XU¢ ( w ) .</sentence>
				<definiendum id="0">feature collocation lattice</definiendum>
				<definiens id="0">a set of nodes of the lattice which corresponds tothe union of the feature space of the maximum entropy model and the configuration space : 8 = XU¢ ( w )</definiens>
			</definition>
			<definition id="7">
				<sentence>• p ( Si ) is the probability for the i-th node in the empirical lattice : N oj~o • p ' ( ei ) is the probability assigned to the i-th node using only the nodes included into the optimized lattice .</sentence>
				<definiendum id="0">Si</definiendum>
				<definiens id="0">the probability for the i-th node in the empirical lattice</definiens>
				<definiens id="1">the probability assigned to the i-th node using only the nodes included into the optimized lattice</definiens>
			</definition>
			<definition id="8">
				<sentence>The same stands for the features B and C the frequency of seeing the feature C is the frequency of not seeing the feature B because they are mutually exclusive and thus all the configurations without feature B will account for the presence of the feature C if we do n't put it into the lattice .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the frequency of not seeing the feature B because they are mutually exclusive and thus all the configurations without feature B will account for the presence of the feature</definiens>
			</definition>
			<definition id="9">
				<sentence>A period can act as the end of sentence or be a part of an abbreviation , but when an abbreviation is the last word in a sentence , the period denotes the end of sentence as well .</sentence>
				<definiendum id="0">period</definiendum>
				<definiens id="0">the end of sentence or be a part of an abbreviation , but when an abbreviation is the last word in a sentence , the</definiens>
			</definition>
</paper>

		<paper id="0110">
			<definition id="0">
				<sentence>Recent work involves novel ways to employ annotated corpus in part of speech tagging ( Church 1988 ) ( Derose 1988 ) and the application of mutual information statistics on the corpora to uncover lexical information ( Church 1989 ) .</sentence>
				<definiendum id="0">Recent work</definiendum>
				<definiens id="0">involves novel ways to employ annotated corpus in part of speech tagging ( Church 1988 ) ( Derose 1988 ) and the application of mutual information statistics on the corpora to uncover lexical information</definiens>
			</definition>
			<definition id="1">
				<sentence>In the training process , the user , with the help of a graphical user intefface ( GUI ) scans a parsed sample article and indicates a series of semantic net nodes and transitions that he or she would like to create to represent the information of interest .</sentence>
				<definiendum id="0">GUI</definiendum>
				<definiens id="0">scans a parsed sample article and indicates a series of semantic net nodes and transitions that he or she would like to create to represent the information of interest</definiens>
			</definition>
			<definition id="2">
				<sentence>The right hand side ( RHS ) of the rule consists of the operations I I I I I I 82 Training Scntcncc : DCR Inc .</sentence>
				<definiendum id="0">RHS</definiendum>
			</definition>
			<definition id="3">
				<sentence>NODE is to add an object in the semantic transition .</sentence>
				<definiendum id="0">NODE</definiendum>
				<definiens id="0">to add an object in the semantic transition</definiens>
			</definition>
			<definition id="4">
				<sentence>Each entity ( sp ) is a quadruple , in the form of ( w , c , s , t ) , where w is the headword of the trained phrase ; c is the part of the speech of the word ; s is the sense number representing the meaning of w ; t is the semantic type identified by the preprocessor for w. For each sp = ( w , c , s , t ) , if w exists in WordNet , then there is a corresponding synset in WordNet .</sentence>
				<definiendum id="0">w</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">a quadruple , in the form of ( w , c , s , t )</definiens>
				<definiens id="1">the headword of the trained phrase</definiens>
				<definiens id="2">the part of the speech of the word ; s is the sense number representing the meaning of w ; t is the semantic type identified by the preprocessor for w. For each sp = ( w , c , s , t ) , if w exists in WordNet</definiens>
			</definition>
			<definition id="5">
				<sentence>Although these statistics are not strong enough to indicate the training set is absolutely the good trMn ; ng corpora for this information extraction task , it suggests that as far as the facts of interest are concerned , the training set is a reasonable set to be trained and learned .</sentence>
				<definiendum id="0">ng corpora</definiendum>
				<definiens id="0">a reasonable set to be trained and learned</definiens>
			</definition>
			<definition id="6">
				<sentence>Precision is the number of transitions correctly extracting facts of interest out of the total number of transitions produced by the system ; recall is the number of facts which have been correctly extracted out of the total number of facts of interest .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the number of transitions correctly extracting facts of interest out of the total number of transitions produced by the system</definiens>
			</definition>
			<definition id="7">
				<sentence>The overall performance of recall and precision is defined by the Fomeasurement ( Chinchor 1992 ) , which is ( ~2 + 1.0 ) • P * R ~ .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiendum id="1">Fomeasurement</definiendum>
			</definition>
			<definition id="8">
				<sentence>Our information extraction system learns the necessary knowledge by analyzing sample corpora through a training process .</sentence>
				<definiendum id="0">information extraction system</definiendum>
				<definiens id="0">learns the necessary knowledge by analyzing sample corpora through a training process</definiens>
			</definition>
			<definition id="9">
				<sentence>The Generalization Tree algorithm prorides a way to make the system adaptable to the user 's needs .</sentence>
				<definiendum id="0">Generalization Tree algorithm</definiendum>
				<definiens id="0">prorides a way to make the system adaptable to the user 's needs</definiens>
			</definition>
			<definition id="10">
				<sentence>Introduction to WordNet : An On-Line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="11">
				<sentence>Resuik , Philip 1993 Selection and Information : A Class Based Approach to Lexical Relationships , Ph.D Dissertation , University of Pennsylvania , 1993 .</sentence>
				<definiendum id="0">Information</definiendum>
				<definiens id="0">A Class Based Approach to Lexical Relationships</definiens>
			</definition>
</paper>

		<paper id="1505">
</paper>

		<paper id="0806">
			<definition id="0">
				<sentence>A lexical database is a referencesystem that accumulates information on the lexical items of one o 39 several languages In this view , machine readable dictionaries can also be regarded as primitive lexicaldatabases .</sentence>
				<definiendum id="0">lexical database</definiendum>
				<definiens id="0">a referencesystem that accumulates information on the lexical items of one o 39 several languages In this view , machine readable dictionaries can also be regarded as primitive lexicaldatabases</definiens>
			</definition>
			<definition id="1">
				<sentence>Finally , we have employed both WordNet and Reuters to get a betterrepresentation of undertramed categories SpaceModel The Vector Space Model ( VSM ) \ [ Salton and McGill , 1983\ ] is a very suitableenvironment for expressing our approaches to TC : it is supported by many experiences in textretrieval \ [ Lewis , 1992 ; Salton , 1989\ ] ; ' it allows the seamless integratlonof multiple knowledge sources for text classification , and it makes it easyto identify the role of every knowledge source involved in the classification operation In the nextsections we present a straightforward adaptation of the VSM for TC , and theway we use the chosen resources for calculating several model elements .</sentence>
				<definiendum id="0">Vector Space Model</definiendum>
				<definiens id="0">it is supported by many experiences in textretrieval \ [ Lewis , 1992 ; Salton , 1989\ ] ; ' it allows the seamless integratlonof multiple knowledge sources for text classification</definiens>
			</definition>
			<definition id="2">
				<sentence>Lexical databases contain many kinds of information ( concepts ; synonymy andother lexical relations ; hyponymy and other conceptual relations ; etc. ) , For instance , WordNet represents concepts as synonyms sets , or synsets .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">concepts as synonyms sets , or synsets</definiens>
			</definition>
			<definition id="3">
				<sentence>The Reuters-22173 collection consists of 22,173 newswire articles from Reuters collected during 1987 .</sentence>
				<definiendum id="0">Reuters-22173 collection</definiendum>
			</definition>
</paper>

		<paper id="1504">
			<definition id="0">
				<sentence>On the side of usability , grammar documentation is the base for producing final user documentation , without which no natural language system will ever be able to attract any industrial user ( cf. Zoeppritz , 1995 ) .</sentence>
				<definiendum id="0">grammar documentation</definiendum>
			</definition>
			<definition id="1">
				<sentence>HyperGram ( Hypertextual Grammars ) is a model for grammar development and documentation inspired to the idea of literate programming , which was first proposed by Knuth ( 1974 ) ( cf. Knuth ( 1992 ) , for an overview ) .</sentence>
				<definiendum id="0">HyperGram ( Hypertextual Grammars )</definiendum>
				<definiens id="0">a model for grammar development and documentation inspired to the idea of literate programming</definiens>
			</definition>
</paper>

		<paper id="0703">
			<definition id="0">
				<sentence>We investigate one techmque to produce a summary of an original text without requmng zts full semanttc interpretation , but instead relying on a model of the topic progresston m the text derived from lexlcal chains We present a new algonthm to compute lexlcal chains m a text , merging several robust knowledge sources the WordNet thesaurus , a partof-speech tagger and shallow parser for the identification of nominal groups , and a segmentatton algorithm dernved from ( Hearst , 1994 ) Summarization proceeds m three steps the ongmal text is first segmented , lexxcal chmns are constructed , strong chains are ldsnhfied and ssgnzflcant sentences are extracted from the text We present m tins paper empirical results on the tdent~catlon of strong chains and of slgmfieant sentences Introduction Summarization ts the process of condensing a source text into a shorter Version preserving its reformation content It can serve several goals -from survey analysis of a sctenttfic field to qmck mchcatzve notes on the general toplc of a text Producing a quahty reformative summary of an arbitrary text remams a challenge winch reqmres full understanding of the text Indtcattves , lm~artes , winch can be used to qmckly decide whether a text is worth reading , are naturally easter to produce In tins paper we investigate a method for the production of such mdxcatlve summaries from arintrary text ( Jones , 1993 ) descnbes summarization as a twostep process ( 1 ) Building from the source text a source representatton , ( 2 ) Summary generationfonmng summary representation from the source representation bmlt m the first step and synthesismg the output summary text Within this framework , the relevantquestion is what reformation has to be included m the source representation m order to create a summary There are three types of source text reformation hngmstlc , domain and commumcatlve Each of these text aspects can be chosen as a barns for source representatlon Summaries can be bmlt on a deep semantic anal= ysis of the source text For example , ( McKcown and Radsv , !</sentence>
				<definiendum id="0">WordNet thesaurus</definiendum>
				<definiens id="0">full semanttc interpretation , but instead relying on a model of the topic progresston m the text derived from lexlcal chains We present a new algonthm to compute lexlcal chains m a text , merging several robust knowledge sources the</definiens>
				<definiens id="1">a partof-speech tagger and shallow parser for the identification of nominal groups</definiens>
				<definiens id="2">strong chains and of slgmfieant sentences Introduction Summarization ts the process of condensing a source text into a shorter Version preserving its reformation content It can serve several goals -from survey analysis of a sctenttfic field to qmck mchcatzve notes on the general toplc of a text Producing a quahty reformative summary of an arbitrary text remams a challenge winch reqmres full understanding of the text Indtcattves , lm~artes , winch can be used to qmckly decide whether a text is worth reading</definiens>
			</definition>
			<definition id="1">
				<sentence>905 ) investigate ways to produce a coherent summary of several texts describing the same event , when a detaded semantic representation of the source texts m available ( m their case , they use MUC-style systems to interpret the source texts ) Alternatzvely , early summarisatzon systems ( Luhn , 1968 ) used only hngumtlc source mformation The mtmtlon was that the moat frequent words represent the tmportant concepts of the text In this approach the source representation was the frequency table of text words Tins representation abstracts the text into the umon of its words w~thout conmdermg any connectlon among them In contrast to these two extreme pcsltlous ( using as a source representation a full semantic representation of the text or reducing ltto a simple frequency table ) , we deal m tins paper wttb the issue of producmg a summary from an arbitrary text without reqmrmg zts full understanding , but using wtdely avadable knowledge sources Our mare goal is therefore to find a middle ground for source representation , rich enough to braid quality indicative summaries , but easy enough to extract from the source text to work on arbltrary text Over-slmphficatlon can harm the quahty of the source representation As a trivial illustration , consider the following two sequences • 1 `` Dr Kenny has sn~ented an anesthetsc maehsne Thss devwe controls the rate at wh : ch an anaesthctsc ss pumped into the blood '' 2 `` Dr Kenny has : nvented an anesthet : c machsne The Doctor spent two years on thu research '' ~Dr Kenny ~ appears once m both sequences and I0 I I I I i I II II I !</sentence>
				<definiendum id="0">moat frequent words</definiendum>
				<definiens id="0">a source representation a full semantic representation of the text or reducing ltto a simple frequency table )</definiens>
			</definition>
			<definition id="2">
				<sentence>locatlons 13 ( Mr , lms~e¢ } ~ ( 'MLczq-~__'~ { PC , rmarocomputer , } t Iperso~ Figure 3 Step 3 Interpretation 1 Figure 4 Step 3 Interpretation 2 such as `` digital computeff ) However , Enghsh includes a productive system of noun comp0hnds , and m each domain , new noun-compounds and collocations not present m WordNet play a major role We addreseed the issue , by usmg a shallow parser ( developed by Ido Dagan 's team at Bar Ilan Umverslty ) to identify noun-compounds using a snnple characterization of noun sequences Tins has two major benefits ( 1 ) it ldentflles Important concepts m the domain ( for example , m a text on `` quantum computing '' , the mare token was the noun compound `` ~uantum computing '' winch was not present m WordNet ) , ( 2 ) it chromates words that occur as modn~ere as posmble can &amp; dates for chain membersinp For example , when `` quantum computing '' m selected as a smgle umt , the word `` ¢uantum ~ is not selected This Is beneficial because m tins example , the text was not about- '' quantum ' , but more about computers When a noun compound ~s selected , the relatedness criterion in WordNet ~s used by cousldermg its head noun only Thus , `` quantum computer ~ ~s related to `` machine ~ as a ~computer ~ The second dflfexence m our algorithm hes m the operative defuntion we gwe to the notion of text umt We use as text umts the segments obtained from Hearst 's algorithm of text segmentation ( Hearst , 1994 ) We braid chains m every segment according to relatedness criteria , and in a second stage , we merge chains from the dflferent segments using much stronger criteria for connectedness only two chains are merged across a segment boundary only if they contain a common word with the same sense Our mira-segment relatedness criterion .</sentence>
				<definiendum id="0">Enghsh</definiendum>
				<definiens id="0">includes a productive system of noun comp0hnds</definiens>
			</definition>
			<definition id="3">
				<sentence>~tandardDeemtson ( Scorea ) These are prehmmary results but they are confirmed by our experience on 30 texts analyzed extensively We have expertraenteed wsth d~erent normahzation methods for the score function , but they do not seem to nnprove the results We plan on extending the empmcal analym m the future and to use formal learmng methods to determine a good scoring function The average number of strong chains selected by thxs selection method was 5 for texts of 1055 words on average ( 474 words mmunum , 3198 words maremum ) , when 32 chmnR were originally generated on average The strongest chmn of the sample text are represented m Appendix Extracting Significant Sentences Once strong chains have been selected , the next step of the summarization algorithm is to extract full sentences from the original text based on chain distn .</sentence>
				<definiendum id="0">~tandardDeemtson</definiendum>
			</definition>
</paper>

		<paper id="1207">
			<definition id="0">
				<sentence>Concept-to-Speech ( CTS ) systems , which aim to synthesize speech from semantic information and discourse context , have succeeded in producing more appropriate and naturalsounding prosody than text-to-speech ( TTS ) systems , which rely mostly on syntactic and orthographic information .</sentence>
				<definiendum id="0">Concept-to-Speech ( CTS ) systems</definiendum>
				<definiens id="0">aim to synthesize speech from semantic information and discourse context , have succeeded in producing more appropriate and naturalsounding prosody than text-to-speech ( TTS ) systems , which rely mostly on syntactic and orthographic information</definiens>
			</definition>
			<definition id="1">
				<sentence>WordNet is a large on-fine Engfish lexical database , based on theories of human lexical memory and comprised of four part-of-speech categories : nouns , verbs , adjectives , and adverbs ( Miller et al. , 1993 ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="2">
				<sentence>WordNet contains 16,428 synsets of adjectives divided into descriptive and relational types , and a small closed-class of reference-modifying adjectives .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">contains 16,428 synsets of adjectives divided into descriptive and relational types</definiens>
			</definition>
			<definition id="3">
				<sentence>PostV contains focused items : theme = \ [ PreV\ ] rheme = \ [ V PostV\ ] Accent V material .</sentence>
				<definiendum id="0">PostV</definiendum>
				<definiens id="0">contains focused items : theme = \ [ PreV\ ] rheme = \ [ V PostV\ ] Accent V material</definiens>
			</definition>
			<definition id="4">
				<sentence>NPtool : a detector of English noun phrases .</sentence>
				<definiendum id="0">NPtool</definiendum>
				<definiens id="0">a detector of English noun phrases</definiens>
			</definition>
</paper>

		<paper id="0210">
			<definition id="0">
				<sentence>WordNet supplies links between semantically related senses as encoded in synonym sets ( synsets ) .</sentence>
				<definiendum id="0">WordNet supplies</definiendum>
				<definiens id="0">links between semantically related senses as encoded in synonym sets ( synsets )</definiens>
			</definition>
			<definition id="1">
				<sentence>WordNet contains the needed information on permissible combinations of syntactic context and semantic content , but its subcategorization information is limited .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">contains the needed information on permissible combinations of syntactic context and semantic content</definiens>
			</definition>
			<definition id="2">
				<sentence>Introduction to WordNet : An on-line lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0803">
			<definition id="0">
				<sentence>The SVMV model formalizes the probability P ( clw ) as follows .</sentence>
				<definiendum id="0">SVMV model</definiendum>
			</definition>
			<definition id="1">
				<sentence>17 P ( V = v~lc ) is the probability that a randomly extracted verb co-occurring with a noun is v~ , given that the noun belongs to word class c. This is estimated from the relative frequency of v~ co-occurring with the nouns in word class c , namely , E eo/r ( w , v , ) ( 4 ) P ( v = , lc ) = E , Ewe° P ( V = v , lw ) is the probability that a randomly extracted verb co-occurring with a noun w is vs. This is estimated from the relative frequency of v , co-occurring with noun w , namely , P ( V = = ( 5 ) P ( V = v , ) is the prior probability that a randomly extracted verb co-occurring with a randomly selected noun is v~ .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">the probability that a randomly extracted verb co-occurring with a noun is v~ , given that the noun belongs to word class c. This is estimated from the relative frequency of v~ co-occurring with the nouns in word class c</definiens>
				<definiens id="1">( v = , lc ) = E , Ewe° P ( V = v</definiens>
			</definition>
			<definition id="2">
				<sentence>• the k-nearest neighbor ( k-nn ) or Memory based reasoning ( MBR ) approach • the category-based approach • the cluster-based approach The k-nn approach searches for the k documents most similar to a target document in training data , and assigns that category with the highest distribution in the k documents \ [ Weiss and Kulikowski , 1991\ ] .</sentence>
				<definiendum id="0">k-nearest neighbor</definiendum>
				<definiens id="0">k-nn ) or Memory based reasoning</definiens>
			</definition>
			<definition id="3">
				<sentence>A Kanzi character is an ideogram and has a distinct stand-alone meaning , to a certain extent .</sentence>
				<definiendum id="0">Kanzi character</definiendum>
				<definiens id="0">an ideogram and has a distinct stand-alone meaning , to a certain extent</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , if the class codes of Kanzi Ks and K s are ~1 , c~2 } and { c31 , c32 , c~3 } respectively , then a word including K , and K~ is assigned the codes { Ctl , Cs2 , C31 , C32 , C33 } .</sentence>
				<definiendum id="0">K~</definiendum>
				<definiens id="0">assigned the codes { Ctl</definiens>
			</definition>
</paper>

		<paper id="0502">
			<definition id="0">
				<sentence>The aim of the WordKeys project is to enhance a communication aid with techniques based on research in text retrieval , in order to reduce the cognitive load normally associated with retrieving pre-stored messages in augmentative and alternative communication ( AAC ) systems .</sentence>
				<definiendum id="0">WordKeys project</definiendum>
				<definiendum id="1">AAC</definiendum>
				<definiens id="0">to enhance a communication aid with techniques based on research in text retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>This is especially true for a system such as WordKeys , which uses semantic relationship for retrieval and performs message ranking , which can increase the impact of inaccuracies in the morphological analysis .</sentence>
				<definiendum id="0">WordKeys</definiendum>
				<definiens id="0">uses semantic relationship for retrieval and performs message ranking , which can increase the impact of inaccuracies in the morphological analysis</definiens>
			</definition>
			<definition id="2">
				<sentence>A path is the concatenation of semantic links that are used to get from the input key word to the index word .</sentence>
				<definiendum id="0">path</definiendum>
				<definiens id="0">the concatenation of semantic links that are used to get from the input key word to the index word</definiens>
			</definition>
			<definition id="3">
				<sentence>A semantic path is a series of semantic relations which can be used to reach a lemmatised message word from a lemmatised input key word .</sentence>
				<definiendum id="0">semantic path</definiendum>
				<definiens id="0">a series of semantic relations which can be used to reach a lemmatised message word from a lemmatised input key word</definiens>
			</definition>
</paper>

		<paper id="0415">
			<definition id="0">
				<sentence>The ITSVox system consists ( i ) of a signal processing module based on the standard N-best approach ( cf. Jimenez et al. , 1995 I , ( ii I a robust GB-based parser , ( iii I a transfer-based translation module , and ( iv ) a speech synthesis module .</sentence>
				<definiendum id="0">ITSVox system</definiendum>
				<definiens id="0">consists ( i ) of a signal processing module based on the standard N-best approach ( cf. Jimenez et al. , 1995 I</definiens>
			</definition>
			<definition id="1">
				<sentence>Good quality speech synthesis systems need a significant amount of linguistic knowledge in order ( i ) to disambiguate homographs which are not homophones ( words with the same spelling but different pronunciations such as to lead/tile lead , to wind/tt~e wind , he read/to read , he records/the records , etc. , ( ii ) to derive the syntactic structure which is used to segment sentences into phrases , to set accent levels , etc. , and finally to determine an appropriate prosodic pattern .</sentence>
				<definiendum id="0">Good quality speech synthesis systems</definiendum>
				<definiens id="0">used to segment sentences into phrases , to set accent levels , etc. , and finally to determine an appropriate prosodic pattern</definiens>
			</definition>
</paper>

		<paper id="0112">
			<definition id="0">
				<sentence>Indexing consists of recognising the terms in a text that belong to a reference system ; this is called controlled indexing .</sentence>
				<definiendum id="0">Indexing</definiendum>
				<definiens id="0">consists of recognising the terms in a text that belong to a reference system</definiens>
			</definition>
			<definition id="1">
				<sentence>The lexical resources ( general language dictionaries ) are fairly stable , whereas terminologies evolve dynamically with the fields they describe .</sentence>
				<definiendum id="0">lexical resources</definiendum>
			</definition>
			<definition id="2">
				<sentence>Word sense disambiguation uses a single context ( generally a window of a few words around the word to be disambiguated ) as input to predict its sense among a few possible senses ( generally less than ten ) .</sentence>
				<definiendum id="0">Word sense disambiguation</definiendum>
				<definiens id="0">uses a single context ( generally a window of a few words around the word to be disambiguated</definiens>
			</definition>
			<definition id="3">
				<sentence>Each document consists of one or two pages of text .</sentence>
				<definiendum id="0">document</definiendum>
			</definition>
			<definition id="4">
				<sentence>Description of the Thesaurus The EDF thesaurus consists of 20,000 terms ( including 6,000 synonyms ) that cover a wide variety of fields ( statistics , nuclear power plants , information retrieval , etc. ) .</sentence>
				<definiendum id="0">Thesaurus The EDF thesaurus</definiendum>
				<definiens id="0">consists of 20,000 terms ( including 6,000 synonyms ) that cover a wide variety of fields ( statistics , nuclear power plants , information retrieval</definiens>
			</definition>
			<definition id="5">
				<sentence>The local density of an expression is the 105 mean of the cosines between documents which contain the given expression .</sentence>
				<definiendum id="0">local density of an expression</definiendum>
				<definiens id="0">the 105 mean of the cosines between documents which contain the given expression</definiens>
			</definition>
			<definition id="6">
				<sentence>A document is a vector in the Document Vector Space where a dimension is a term .</sentence>
				<definiendum id="0">document</definiendum>
				<definiens id="0">a vector in the Document Vector Space where a dimension is a term</definiens>
			</definition>
			<definition id="7">
				<sentence>The method consists of breaking down the text fragment being processed by a series of successive transformations that may be syntactical ( nominalisation , de-coordination , etc. ) , semantic ( e.g. , nuclear and atomic ) , or pragmatic ( the thesaurus '' synonym relationships are scanned to transform a synonym by its main form ) .</sentence>
				<definiendum id="0">pragmatic</definiendum>
				<definiens id="0">breaking down the text fragment being processed by a series of successive transformations that may be syntactical ( nominalisation , de-coordination , etc. ) , semantic ( e.g. , nuclear and atomic )</definiens>
			</definition>
			<definition id="8">
				<sentence>The problem of WSD is to build indicators describing the different senses of a word .</sentence>
				<definiendum id="0">problem of WSD</definiendum>
				<definiens id="0">to build indicators describing the different senses of a word</definiens>
			</definition>
			<definition id="9">
				<sentence>xi=l means the variable xi describes the term x. xi=0 means the varaible xi does not describe the term x. The probability that an element x is in a class c is written : P ( C=c I X=x ) where C is a random variable and X is a random vector .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">The probability that an element x is in a class c is written : P ( C=c I X=x ) where C is a random variable and</definiens>
				<definiens id="1">a random vector</definiens>
			</definition>
			<definition id="10">
				<sentence>Using Bayes formula , it may be deduced that : P ( C=c \ [ X=x ) = ( P ( C = c ) P ( X = x I C = c ) ) / P ( X = x ) There are three probabilities to estimate : Estimate P ( C = c ) 107 P ( C = c ) is estimated by nc / n where : nc is the number of elements of the class c n is the number of elements in the sample Estimate P ( X = x ) This estimate is simplified by normalising the probabilities to I. Estimate P ( X = x I C = c ) For this estimate , we assume that the random variables Xl , X2 ... . Xm are independent for a given class c. This leads to : P ( X=x I C=c ) =HP ( xi =xi I C =c ) and P ( Xi = 1 I C = c ) is estimated by nc , i / nc P ( Xi = 0 I C = c ) is estimated by 1 nc , i / nc where nc , i is the number of elements in the sample which are in class c , and for which xi =i , and nc is the number of elements of the sample in class c. Once all the probabilities are estimated , the classification function for an element x consists of choosing the class that has the highest probability .</sentence>
				<definiendum id="0">nc</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">nc</definiendum>
				<definiens id="0">the number of elements of the class c</definiens>
				<definiens id="1">independent for a given class c. This leads to : P ( X=x I C=c ) =HP ( xi =xi I C =c ) and P ( Xi = 1 I C = c ) is estimated by nc</definiens>
				<definiens id="2">the number of elements in the sample which are in class c , and for which xi =i , and</definiens>
				<definiens id="3">the number of elements of the sample in class c. Once all the probabilities are estimated , the classification function for an element x consists of choosing the class that has the highest probability</definiens>
			</definition>
			<definition id="11">
				<sentence>MI ( x , y ) is the mutual information between terms x and y , and is written : 109 MI ( x , y ) = log2 ( P ( xy ) /P ( x ) P ( y ) ) where P ( x , y ) the probability of observing x and y together and P ( x ) the probability of observing x , P ( y ) the probability of observing y. In the two cases , the matrix has to be transformed into a binary matrix .</sentence>
				<definiendum id="0">MI</definiendum>
				<definiendum id="1">P</definiendum>
				<definiendum id="2">P ( x</definiendum>
				<definiendum id="3">P ( y</definiendum>
				<definiens id="0">the mutual information between terms x and y</definiens>
			</definition>
</paper>

		<paper id="0204">
			<definition id="0">
				<sentence>The official name of the project is `` Tools for lexicon building '' ; the PI is Charles J. Fillmore .</sentence>
				<definiendum id="0">PI</definiendum>
				<definiens id="0">Charles J. Fillmore</definiens>
			</definition>
			<definition id="1">
				<sentence>frame ( CommercialTransaction ) frame-elements { BUYER , SELLER , PAYMENT , GOODS } scenes ( BUYER gets GOODS , SELLER gets PAYMENT ) frame ( Rea~stateTransaction ) inherits ( Corn mercialTransaction ) link ( BORROWER = BUYER , LOAN = PAYMENT ) frame-elements { BORROWER , LOAN , LENDER } scenes ( LOAN ( from LENDER ) creates PAYMENT , BUYER gets LOAN ) Figure h A subframe can inherit elements and semantics from its parent .</sentence>
				<definiendum id="0">CommercialTransaction ) frame-elements { BUYER</definiendum>
				<definiendum id="1">BUYER</definiendum>
				<definiendum id="2">LOAN</definiendum>
				<definiens id="0">gets GOODS , SELLER gets PAYMENT ) frame ( Rea~stateTransaction ) inherits ( Corn mercialTransaction ) link</definiens>
			</definition>
			<definition id="2">
				<sentence>For each semantic frame , the process of elucidation involves a series of steps : which can serve as predicates in this frame , elements ( encoded we expect as a TEL compliant SGML document using feature structures ( Sperberg-McQueen and Burnard , 1994 ) , ging the predicate with the name of the frame and its arguments with the names of the FE 's designating their roles relative to the predicate ( also using SGML markup introduced with software developed for this purpose ) , tion of the co-occurrence constraints and possible syntactic realizations in the light of the corpus data , and , vised frames.7 The last two steps will be repeated as needed to refine the frame description .</sentence>
				<definiendum id="0">elucidation</definiendum>
				<definiens id="0">involves a series of steps : which can serve</definiens>
				<definiens id="1">ging the predicate with the name of the frame and its arguments with the names of the FE 's designating their roles relative to the predicate ( also using SGML markup introduced with software developed for this purpose ) , tion of the co-occurrence constraints and possible syntactic realizations in the light of the corpus data</definiens>
			</definition>
			<definition id="3">
				<sentence>A Frame Element Group ( FEG ) is a list of the FEs from a given frame which occur in a phrase or sentence headed by a given word .</sentence>
				<definiendum id="0">Frame Element Group ( FEG )</definiendum>
				<definiens id="0">a list of the FEs from a given frame which occur in a phrase or sentence headed by a given word</definiens>
			</definition>
</paper>

		<paper id="1403">
			<definition id="0">
				<sentence>PI : The availability of pointing , communication through the visual channel reduces the amount of information conveyed through the speech or linguistic channel .</sentence>
				<definiendum id="0">PI</definiendum>
				<definiens id="0">The availability of pointing</definiens>
			</definition>
			<definition id="1">
				<sentence>The object description is a noun phrase that has modifiers describing features of the object such as its color or size followed by a head common noun describing the object category .</sentence>
				<definiendum id="0">object description</definiendum>
				<definiens id="0">a noun phrase that has modifiers describing features of the object such as its color</definiens>
			</definition>
			<definition id="2">
				<sentence>\ [ description of the features of the object s\ ] * Towards Generation of Fluent Referring Action in Multimodal Situations 25 Table 3 : The schemata for referring to group members and their occurrence frequency ID RS $ 1 RS22 RSI ' RS2 ' RS1 '' RS2 '' Others Pattern/Descritpion \ [ referring to the group s\ ] , RSi \ [ referring to the group s\ ] , RS2 RS1 ( with group descriptions ) RS2 ( with group descriptions ) RS1 ( w/o group descriptions ) RS2 ( w/o group descriptions ) MMD SMD 4 12 7 15 0 4 7 9 12 7 23 8 7 5 \ [ object function pp/comp\ ] \ [ object np\ ] ga ( SUBJ ) \ [ position pp/comp\ ] \ [ object description up\ ] desu ( COeVLa ) .</sentence>
				<definiendum id="0">COeVLa</definiendum>
				<definiens id="0">group descriptions ) RS2 ( with group descriptions ) RS1 ( w/o group descriptions ) RS2 ( w/o group descriptions</definiens>
			</definition>
</paper>

		<paper id="0309">
			<definition id="0">
				<sentence>The number of parameters -- or transition probabilities-scales as V n , where V is the vocabulary size .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the vocabulary size</definiens>
			</definition>
			<definition id="1">
				<sentence>Mixed-order Markov models express the predictions P ( wt\ [ wt-1 , wt-2 , ... , Wt-m ) as a convex combination of skip-k transition matrices , M ( wt-k , wt ) .</sentence>
				<definiendum id="0">Mixed-order Markov models</definiendum>
				<definiens id="0">express the predictions P ( wt\ [ wt-1 , wt-2 , ... , Wt-m ) as a convex combination of skip-k transition matrices</definiens>
			</definition>
			<definition id="2">
				<sentence>Let P ( clwl ) denote the probability that word wl is mapped into class c. Likewise , let P ( w21c ) denote the probability that words in class c are followed by the word w2 .</sentence>
				<definiendum id="0">P ( clwl</definiendum>
			</definition>
			<definition id="3">
				<sentence>The class-based bigram model predicts that word wl is followed by word w2 with probability c P ( w21wl ) = Z P ( w21c ) P ( clwx ) ' ( 1 ) c=l where C is the total number of classes .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the total number of classes</definiens>
			</definition>
			<definition id="4">
				<sentence>The Expectation-Maximization ( EM ) algorithm ( Dempster , Laird , and Rubin , 1977 ) is an iterative procedure for estimating the parameters of hidden variable models .</sentence>
				<definiendum id="0">Expectation-Maximization</definiendum>
				<definiens id="0">an iterative procedure for estimating the parameters of hidden variable models</definiens>
			</definition>
			<definition id="5">
				<sentence>Each iteration consists of two steps : an E-step which computes statistics over the hidden variables , and an M-step which updates the parameters to reflect these statistics .</sentence>
				<definiendum id="0">iteration</definiendum>
			</definition>
			<definition id="6">
				<sentence>The updates for aggregate Markov models are : ~w N ( wl , w ) P ( ClWl , w ) P ( clwl ) ~ ~wc , N ( wl ' , , w ) P ( c \ [ wl , w ) ( 3 ) Ew N ( w , w2 ) P ( clw , w~ ) P ( w2\ [ c ) ~Eww'g ( w , w ' ) P ( clw , w ' ) ' ( 4 ) where N ( Wl , w2 ) denotes the number of counts of wlw2 in the training set .</sentence>
				<definiendum id="0">w2 )</definiendum>
				<definiens id="0">the number of counts of wlw2 in the training set</definiens>
			</definition>
			<definition id="7">
				<sentence>The perplexity V* is related to the log-likelihood by V* : e -~/N , where N is the total number of words processed .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of words processed</definiens>
			</definition>
			<definition id="8">
				<sentence>C train test 1 964.7 964.9 2 771.2 772.2 4 541.9 543.6 8 399.5 401.5 16 328.8 331.8 32 278.9 283.2 V 123.6 -Table 1 : Perplexities of aggregate Markov models on the training and test sets ; C is the number of classes .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">Perplexities of aggregate Markov models on the training and test sets ;</definiens>
				<definiens id="1">the number of classes</definiens>
			</definition>
			<definition id="9">
				<sentence>A mixed-order Markov model combines the information in these matrices for different values of k. Let m denote the number of bigram models being combined .</sentence>
				<definiendum id="0">mixed-order Markov model</definiendum>
				<definiens id="0">combines the information in these matrices for different values of k. Let m denote the number of bigram models being combined</definiens>
			</definition>
			<definition id="10">
				<sentence>m train missing 1 123.2 0.045 2 89.4 0.014 3 77.9 0.0063 4 72.4 0.0037 Table 3 : Results for ML mixed-order models ; m denotes the number of bigrams that were mixed into each prediction .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">the number of bigrams that were mixed into each prediction</definiens>
			</definition>
			<definition id="11">
				<sentence>Rosenfeld argues at length against naive linear combinations in favor of maximum entropy methods .</sentence>
				<definiendum id="0">Rosenfeld</definiendum>
				<definiens id="0">argues at length against naive linear combinations in favor of maximum entropy methods</definiens>
			</definition>
			<definition id="12">
				<sentence>( 1 ) , it should be clear that the rank of the classbased transition matrix is bounded by the number of classes , C. ) As such , there are interesting parallels between Expectation-Maximization ( EM ) , which minimizes the approximation error as measured by the KL divergence , and singular value decomposition ( SVD ) , which minimizes the approximation error as measured by the L2 norm ( Press et al. , 1988 ; Schiitze , 1992 ) .</sentence>
				<definiendum id="0">Schiitze</definiendum>
				<definiens id="0">minimizes the approximation error as measured by the KL divergence , and singular value decomposition ( SVD ) , which minimizes the approximation error as measured by the L2 norm ( Press et al. , 1988 ;</definiens>
			</definition>
</paper>

		<paper id="0604">
			<definition id="0">
				<sentence>A Domain Spotter supports the ability to move between domains and between individual skillsets .</sentence>
				<definiendum id="0">Domain Spotter</definiendum>
				<definiens id="0">supports the ability to move between domains</definiens>
			</definition>
			<definition id="1">
				<sentence>A Dialogue Model records individual concepts as they occur ; notes the extent to which concepts have been confirmed ; populates request templates ; and fulfils a remembering and reminding role as the system attempts to gather coherent information from an imperfect speech recognition component .</sentence>
				<definiendum id="0">Dialogue Model</definiendum>
				<definiens id="0">records individual concepts as they occur ; notes the extent to which concepts have been confirmed ; populates request templates</definiens>
			</definition>
			<definition id="2">
				<sentence>The Dialogue Manager supplies the Handle Enquiry dialogue intention with details of the selected Domain Expert .</sentence>
				<definiendum id="0">Dialogue Manager</definiendum>
				<definiens id="0">supplies the Handle Enquiry dialogue intention with details of the selected Domain Expert</definiens>
			</definition>
			<definition id="3">
				<sentence>Dialogue Model : Dialogue Object , Discourse State , Request Template The Dialogue Model class is a containment class encompassing Dialogue Objects ( semantic interpretations of user utterances in the light of specialist knowledge brought to bear by the appropriate Domain Expert ) ; the Discourse State ( which records the current status confirmed , assumed , etc. of the parameters that apply to the Dialogue Objects ) and the Request Template ( which when fully populated is used by the Handle Transaction class a database driver to make a database access ) .</sentence>
				<definiendum id="0">Discourse State</definiendum>
				<definiens id="0">semantic interpretations of user utterances in the light of specialist knowledge brought to bear by the appropriate Domain Expert</definiens>
			</definition>
</paper>

		<paper id="1102">
			<definition id="0">
				<sentence>To calculate this we need a base figure for database entropy : H ( D ) = -E pilog2pi i If we have n : different vectors for all the dialects , then 1 &lt; i &lt; n. Pi is the probability of vector i , estimated by its frequency divided by ID\ [ , which is the total number of vectors in all dialects .</sentence>
				<definiendum id="0">Pi</definiendum>
			</definition>
			<definition id="1">
				<sentence>Second we calculate the average entropy for each feature : ID\ [ / H ( D\ [ y\ ] ) = E H ( Du='~'\ ] ) v , ~v IDI \ [ Dll=~d\ [ is the number of vectors that have value vi for feature f. V is the set of possible values for feature f. H ( Du=vd ) is the remaining entropy of all vectors in the database that have value vi for feature f. It is calculated using the first formula , where the i 's are now only the vectors that have value vi for feature f. Finally we can calculate the information gain associated with a feature : G ( f ) = H ( D ) H ( Dll\ ] ) If we then compare two vectors using Manhattan distance , the weighted difference between two vectors X and Y is now : T~ A ( x , y ) = a ( / , ) lx , i=l And similarly for Euclidean distance and `` inverse correlation '' .</sentence>
				<definiendum id="0">average entropy</definiendum>
				<definiens id="0">D\ [ y\ ] ) = E H ( Du='~'\ ] ) v</definiens>
				<definiens id="1">the number of vectors that have value vi for feature f. V is the set of possible values for feature f. H ( Du=vd ) is the remaining entropy of all vectors in the database that have value vi for feature f. It is calculated using the first formula , where the i 's are now only the vectors that have value vi for feature f. Finally we can calculate the information gain associated with a feature : G ( f ) = H ( D ) H ( Dll\ ]</definiens>
			</definition>
</paper>

		<paper id="0620">
			<definition id="0">
				<sentence>MATTINO GINOSA ALLE OTTO MORNING GINOSA AT EIGHT &lt; part-day=MORNING , city=GINOSA , hour=EIGHTy TT-S : Train 243 leaves from Milano Centrale at 8:20 p.m. ; it arrives at Roma Termini at S a.m. Do you need additional information about this train ? Figure 1 : Excerpt from the Dialogos corpus As it was explained above , telephone recognition is error-prone. For preventing recognition errors the dialogue system sends to the lower levels of analysis information about the domain objects focused during each turn of the interaction ; this information allows the triggering of context dependent language models that help to constraint the lexical choices at 115 the recognition level ( see section 4 ) . Moreover , in order to detect recognition or interpretation errors that occurred in previous turns , the dialogue system takes advantage from the global history of the interaction and it only accepts interpretations of user 's input that are coherent with the dialogue history. For example , let us consider the excerpt from the Dialogos corpus shown in Figure 1. In the example , on the left , the letter 'T ' stands for 'Turn ' , the letters 'U ' and 'S ' stand for user and system , respectively. In each user 's turn we reported in Italian the original user 's utterance and its English translation ( in italics ) . Then we have transcribed the best decoded sequence ( in ALL CAPS ) , that is the recognizer output. The translations into English of the best decoded sequences are shown in ALL CAPS ( in italics ) . The task-oriented semantic frames ( the input of the dialogue module ) have been put between angles. The system turns have been only reported in their English translation. In T2-U the user utterance contains an hesitation when uttering the name of the departure city , `` Milano '' . The first part of the word , `` Mila- '' was misrecognized as a noise , and the last syllable was recognized as `` no '' , that the parser interpreted as the negation adverb `` no '' . In this initial dialogue context there were no parameters to be denied , and the dialogue module was able to discard this information related to the negative adverb. It addressed the user with the request of confirmation of T3-S. T4-U was a confirmation turn of the user. After having consulted the data in the railway database , the system realized that the number of connections between Milano and Roma in the evening was high , and it suggested the user to choose a more precise departure time ( T5-S ) . In T6-U the utterance segment `` mah ... mi dica se c'e ' qualcosa '' ( who knows ... tell me if there is something ) was misrecognized as `` mattino Ginosa '' ( morning Ginosa , where `` Ginosa '' is the name of an Italian village ) . As a consequence , the parser output contains another value for the part-ofday parameter and a departure hour. However , the dialogue discarded the information about the partof-day , since this conflicted with a parameter value that the user had already confirmed , and only the second part of the utterance interpretation was retained ( that is , the departure hour ) . In this case the insertion of a concept due to misrecognition was repaired at the dialogue level 1 . As we can see from the example , the dialogue module makes use of confirmation turns because it deals with potentially incorrect information. However , the need for confirmations may result in a lack 1This version of Dialogos only considers the first best solution. If the expected information is not found in the semantic representation of the current user 's utterance , the dialogue system hypothesizes that something went wrong in the previous analysis , and it interprets that situation as an occurrence of non-understanding. of naturalness of the telephone human-machine dialogues. In order to reduce the number of confirmation turns , we use the following strategies : • the dialogue system avoids confirmation turns when the acquired information is coherent with the dialogue history and with the current focus • the dialogue system asks for multiple confirmations of the acquired parameters ( as in T3-S ) • the dialogue system asks for implicit confirmations whenever it is possible ( as `` From Milano to Roma. When do you want to travel ? '' ) Sometimes the detection of some recognition errors ( for example , the substitution of an uttered word with another one of the same class ) is outside of the capabilities of both the parser and the dialogue modules. On the contrary , in principle the user is able to detect and correct such errors , and often she does it immediately or in subsequent turns. In ( Danieli , 1996 ) an analysis of such phenomena is offered , and the method described in that paper is currently implemented in Dialogos. The approach is based on pragmatic-based expectations about the semantic content of the user utterance in the next turn. The theoretical background is the account of human-human conversation given by ( Grice , 1967 ) , re-interpreted in the context of human-computer conversation. In particular , the dialogue system is able to deal with non-understandings and misunderstandings ( see ( Hirst et al. , 1994 ) for the classification of non-understanding , misunderstanding , and misconception ) , and it may recognize the occurrence of a miscommunication phenomena on the basis of the occurrence of two pragmatic counterparts , that is the deviation of the the user 's behaviour from the system expectations , and the generation of a conversational implicature. Non-understanding is recognized by the dialogue system as soon as it happens , because the system is not able to find any interpretation of the current user turn. On the contrary , misunderstandings are more difficult to detect and solve , because usually the dialogue system may get an interpretation of the user 's utterance , but that interpretation is not the one intended by the speaker. If the user 's correction of a misunderstanding occurs when the parameter is focused ( that is , it occurs as a third-turn repair , see ( Schegloff , 1992 ) ) , the focusing mechanism and the dialogue expectations allow to grasp the correction immediately. However , it is more problematic to detect user 's corrections if they happen some turns after the occurrence of the errors. The dialogue system initially interprets user 's correction with respect to its current set of expectations. As soon as it realizes that there is a deviation of the user behaviour from the expected behaviour , it hypothesizes a misunderstanding , and it re-interprets the current utterance 116 on the basis of the context of the misunderstood utterance ( thanks to a focus-shifting mechanism ) . Finally , the output of the parsing module may be only partially determined. In that case the dialogue module initiates clarification subdialogues. Let us discuss the excerpt shown in Figure 2. TI-S : T2-U : T3-S : T4-U : T5-S : Hello , This is Train Enquiry Service. Please speak after the tone. Please state your departure and your destination. A Firenze. To Firenze. BLOW FIRENZE BL 0 W FIR ENZE &lt; ¢ity=FIRENZE &gt; Are your leaving from Firenze or going to Firenze ?</sentence>
				<definiendum id="0">hour=EIGHTy TT-S</definiendum>
				<definiendum id="1">task-oriented semantic frames</definiendum>
				<definiens id="0">the lower levels of analysis information about the domain objects focused during each turn of the interaction ; this information allows the triggering of context dependent language models that help to constraint the lexical choices at 115 the recognition level ( see section 4 ) . Moreover , in order to detect recognition or interpretation errors that occurred in previous turns , the dialogue system takes advantage from the global history of the interaction</definiens>
				<definiens id="1">the negative adverb. It addressed the user with the request of confirmation of T3-S. T4-U was a confirmation turn of the user. After having consulted the data in the railway database , the system realized that the number of connections between Milano</definiens>
				<definiens id="2">the expected information is not found in the semantic representation of the current user 's utterance , the dialogue system hypothesizes that something went wrong in the previous analysis , and it interprets that situation as an occurrence of non-understanding. of naturalness of the telephone human-machine dialogues. In order to reduce the number of confirmation turns</definiens>
				<definiens id="3">coherent with the dialogue history and with the current focus • the dialogue system asks for multiple confirmations of the acquired parameters</definiens>
				<definiens id="4">the deviation of the the user 's behaviour from the system expectations , and the generation of a conversational implicature. Non-understanding is recognized by the dialogue system as soon as it happens</definiens>
				<definiens id="5">get an interpretation of the user 's utterance , but that interpretation is not the one intended by the speaker. If the user 's correction of a misunderstanding occurs when the parameter is focused ( that is , it occurs as a third-turn repair</definiens>
			</definition>
			<definition id="1">
				<sentence>The Dialogos corpus consists of 1,404 dialogues , including 13,123 utterances .</sentence>
				<definiendum id="0">Dialogos corpus</definiendum>
				<definiens id="0">consists of 1,404 dialogues , including 13,123 utterances</definiens>
			</definition>
</paper>

		<paper id="1502">
			<definition id="0">
				<sentence>The Spoken Language Translator ( SLT ; Becket et al , forthcoming ; Rayner and Carter , 1996 and 1997 ) is a pipelined speech understanding system of the type assumed here .</sentence>
				<definiendum id="0">Spoken Language Translator</definiendum>
				<definiens id="0">a pipelined speech understanding system of the type assumed here</definiens>
			</definition>
			<definition id="1">
				<sentence>Given an input string , N-best list or lattice , the CLE applies unification-based syntactic rules and their corresponding semantic rules to create zero or more quasi-logical form ( QLF , described below ; Alshawi , 1992 ; Alshawi and Crouch , 1992 ) analyses of it ; disambiguation is then a matter of selecting the correct ( or at least , the best available ) QLF .</sentence>
				<definiendum id="0">CLE</definiendum>
				<definiens id="0">applies unification-based syntactic rules and their corresponding semantic rules to create zero or more quasi-logical form</definiens>
			</definition>
			<definition id="2">
				<sentence>The CLE uses this data to analyse speech recognizer output efficiently and to choose accurately among the interpretations it creates .</sentence>
				<definiendum id="0">CLE</definiendum>
				<definiens id="0">uses this data to analyse speech recognizer output</definiens>
			</definition>
			<definition id="3">
				<sentence>In view of this , the TreeBanker includes a `` merge '' option which allows existing judgments applying to an old set of analyses of a sentence to be transferred to a new set that reflects a coverage change .</sentence>
				<definiendum id="0">TreeBanker</definiendum>
				<definiens id="0">includes a `` merge '' option which allows existing judgments applying to an old set of analyses of a sentence to be transferred to a new set that reflects a coverage change</definiens>
			</definition>
</paper>

		<paper id="0907">
			<definition id="0">
				<sentence>We describe an experimental system implemented using the Java ( TM ) programming language which demonstrates a variety of application-level tradeoffs available to distributed natural language processing ( NLP ) applications .</sentence>
				<definiendum id="0">Java</definiendum>
				<definiens id="0">demonstrates a variety of application-level tradeoffs available to distributed natural language processing ( NLP ) applications</definiens>
			</definition>
			<definition id="1">
				<sentence>A proxy server is an intermediary program that provides value added functionality to documents as part of the transmission process .</sentence>
				<definiendum id="0">proxy server</definiendum>
				<definiens id="0">an intermediary program that provides value added functionality to documents as part of the transmission process</definiens>
			</definition>
</paper>

		<paper id="1303">
			<definition id="0">
				<sentence>The IA is built on modules consisting of different types of rule-based knowledge syntactic , semantic , domain , discourse and heuristic ( \ [ Mitkov 94a\ ] ) .</sentence>
				<definiendum id="0">IA</definiendum>
				<definiens id="0">built on modules consisting of different types of rule-based knowledge syntactic , semantic , domain , discourse and heuristic ( \ [ Mitkov 94a\ ] )</definiens>
			</definition>
			<definition id="1">
				<sentence>The IA operates as follows .</sentence>
				<definiendum id="0">IA</definiendum>
				<definiens id="0">operates as follows</definiens>
			</definition>
			<definition id="2">
				<sentence>16 CFhy p ( s , CFol d ) = CF s + CFol d CF s * CFol d ~ CF s &gt; 0 , CFol d &gt; 0 or ( CF s + CFold ) /\ [ l-min ( ICFsl , ICFoldl ) \ ] ¢ : ~ CFs &gt; 0 , CFol d &lt; 0 or CFs &gt; O , CFol d &lt; 0 or CFhy p ( s , CFol d ) ~ CF s &lt; 0 , CFol d &lt; 0 where CFhy p ( s , CFold ) is the hypothesis certainty factor , contributed by the presence/absence of symptom s and the current ( old ) hypothesis certainty factor CFol d. As an illustration , suppose a certain NP has reached a CF=0.5 after testing the presence of some symptoms ( e.g. syntactic agreement ) and that the symptom s with CF=0.45 holds .</sentence>
				<definiendum id="0">CFold )</definiendum>
				<definiens id="0">s , CFol d ) = CF s + CFol d CF s * CFol d ~ CF s &gt; 0 , CFol d &gt; 0 or ( CF s + CFold ) /\ [ l-min ( ICFsl , ICFoldl ) \ ] ¢ : ~ CFs &gt; 0 , CFol d &lt; 0 or CFs &gt; O , CFol d &lt; 0 or CFhy p ( s , CFol d ) ~ CF s &lt; 0 , CFol d &lt; 0 where CFhy p ( s ,</definiens>
				<definiens id="1">the hypothesis certainty factor , contributed by the presence/absence of symptom s and the current ( old ) hypothesis certainty factor CFol d. As an illustration , suppose a certain NP has reached a CF=0.5 after testing the presence of some symptoms ( e.g. syntactic agreement</definiens>
			</definition>
			<definition id="3">
				<sentence>Our evaluation also showed that ( iii ) The IA is more decisive but could be `` iffy '' ( iv ) When information is ample , the URA is more `` confident '' ( v ) The URA is better in cases of gender and number discrepancy between anaphor and antecedent Because the IA followed the traditional rule that anaphor and antecedent must agree in gender and number , its initial version did not capture a number of exceptions ( e.g. in the case of collective Computer memory , also known as primary storage , is closely associated with the central processing unit i but not actually part of it i. Memory holds the data k after it k is input to the system but before it k is processed .</sentence>
				<definiendum id="0">IA</definiendum>
				<definiendum id="1">URA</definiendum>
				<definiendum id="2">URA</definiendum>
				<definiens id="0">more decisive but could be `` iffy '' ( iv ) When information is ample , the</definiens>
			</definition>
			<definition id="4">
				<sentence>( vi ) The IA is better in cases where `` it '' occurs frequently and refers to different antecedents The Central Processing Unit and Memory : Data Manipulation Computer memory , also known as primary storage , is closely associated with the central processing unit i but not actually part of it i. Memory k holds the dataj after itj is input to the system but before itj is processed .</sentence>
				<definiendum id="0">IA</definiendum>
				<definiens id="0">better in cases where `` it '' occurs frequently and refers to different antecedents The Central Processing Unit and Memory : Data Manipulation Computer memory , also known as primary storage , is closely associated with the central processing unit i but not actually part of it i. Memory k holds the dataj after itj is input to the system but before itj is processed</definiens>
			</definition>
			<definition id="5">
				<sentence>In W. Ramm ( ed ) : Studies in Machine Translation and Natural Language Processing , Volume 6 `` Text and content in Machine Translation : Aspects of discourse representation and discourse processing '' , Office for Official Publications of the European Community , Luxembourg , 1994 \ [ Rich &amp; LuperFoy 88\ ] E. Rich , S. LuperFoy An architecture for anaphora resolution .</sentence>
				<definiendum id="0">Ramm</definiendum>
				<definiens id="0">Studies in Machine Translation and Natural Language Processing</definiens>
			</definition>
</paper>

		<paper id="1301">
			<definition id="0">
				<sentence>2 Synonymy/Hyponymy/Meronymy This class ( henceforth , Syn/Hyp/Mer ) includes those DDs which are in a synonymy/hyponymy/meronymy relation with their anchors , i.e. , the kind of semantic relation that is currently encoded in WordNet .</sentence>
				<definiendum id="0">Syn/Hyp/Mer )</definiendum>
				<definiens id="0">includes those DDs which are in a synonymy/hyponymy/meronymy relation with their anchors , i.e. , the kind of semantic relation that is currently encoded in WordNet</definiens>
			</definition>
			<definition id="1">
				<sentence>For instance , ( 5 ) the industry ( in a text whose discourse topic is oil companies ) ; the first half ( in a text whose discourse topic is a concert ) .</sentence>
				<definiendum id="0">discourse topic</definiendum>
				<definiens id="0">a concert )</definiens>
			</definition>
			<definition id="2">
				<sentence>Instead , we use a simple recency heuristic -- we only consider the antecedents in the n previous sentences , where n is a constant determined empirically .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a constant determined empirically</definiens>
			</definition>
</paper>

		<paper id="0409">
			<definition id="0">
				<sentence>Assimilation makes use of existing acoustic models from a language that has a large phonetic overlap with the target language .</sentence>
				<definiendum id="0">Assimilation</definiendum>
				<definiens id="0">makes use of existing acoustic models from a language that has a large phonetic overlap with the target language</definiens>
			</definition>
</paper>

		<paper id="0908">
			<definition id="0">
				<sentence>Sketch grammars use a computational dictionary 49 containing part-of-speech , morphological , and subcategofization information to yield an initial syntactic analysis ( the sketch ) .</sentence>
				<definiendum id="0">Sketch grammars</definiendum>
				<definiens id="0">a computational dictionary 49 containing part-of-speech , morphological , and subcategofization information to yield an initial syntactic analysis ( the sketch )</definiens>
			</definition>
</paper>

		<paper id="1414">
			<definition id="0">
				<sentence>In addition , language L can produce expressions like France is a country , Frankfurt is a city of Germany or Germany is to the east of France which express common sense knowledge required in the interpretation of maps .</sentence>
				<definiendum id="0">Frankfurt</definiendum>
				<definiens id="0">a country</definiens>
				<definiens id="1">a city of Germany or Germany is to the east of France which express common sense knowledge required in the interpretation of maps</definiens>
			</definition>
			<definition id="1">
				<sentence>The set of syntactic categories of L is as follows : CN , where t is the category of sentences , IV is the category of intransitive verbs and CN is the category of common nouns .</sentence>
				<definiendum id="0">IV</definiendum>
				<definiendum id="1">CN</definiendum>
				<definiens id="0">the category of intransitive verbs</definiens>
			</definition>
			<definition id="2">
				<sentence>In the following , Pc is the set of expressions of catergory C. L Paris Frankfurt Saarbriicken France Germany city country border G LP\ [ P ( dg\ ] ; t , ,P\ [ P ( rt ) \ ] X2\ [ P ( r2 ) \ ] dot resion curve line line intersection intersection east be lie at be to a the right kPkxP ( Z , y\ [ x=y\ ] ) lie_at in_zone kP~ , QBy\ [ Vx\ [ P ( x ) ~ x=y\ ] ^ Q ( y ) \ ] Figure 6 In this section , the syntax and semantics or the graphical language are formally defined , as well as the rules for translating graphical expressions back into natural language .</sentence>
				<definiendum id="0">Pc</definiendum>
				<definiens id="0">the set of expressions of catergory C. L Paris Frankfurt Saarbriicken France Germany city country border G LP\ [ P ( dg\ ] ; t</definiens>
			</definition>
			<definition id="3">
				<sentence>So , instead of referring directly to the dot representing Paris , the corresponding expression denotes the set of geometrical properties that the dot representing Paris has .</sentence>
				<definiendum id="0">corresponding expression</definiendum>
			</definition>
			<definition id="4">
				<sentence>According to this , expression 1 ( of G ) in Figure 9 denotes the set containing all sets of dots of the drawing in which dt is included ; thus , if P is the set of all dots representing cities , dl is included in P ( that is to say , P is a property of dl ) , but if P is the set of all dots representing cities in Germany then d~ is not included in P. 108 L.A. Pineda and G. Garza G Figure 9 L Paris Frankfurt Saarbriicken France Germany the border between France and Germany be a the The syntactic definition of G is as follows .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">the set containing all sets of dots of the drawing in which dt is included</definiens>
				<definiens id="1">the set of all dots representing cities , dl is included in P ( that is to say ,</definiens>
			</definition>
			<definition id="5">
				<sentence>Note that all expressions of L can be translated into G ; however , G is a very expressive language and only a subset of well-formed expressions of G has translation into L. The definition of this last subset the format used for introducing L is also used .</sentence>
				<definiendum id="0">G</definiendum>
				<definiens id="0">a very expressive language and only a subset of well-formed expressions of G has translation</definiens>
			</definition>
			<definition id="6">
				<sentence>The constant curve denotes the set of curves on the drawing , so the expressions ~ , P~Q3x\ [ P ( x ) ^ Q ( x ) \ ] ( curve ) -- a border-and 2~P~Q3y\ [ Vx\ [ P ( x ) ~ x=y\ ] ^ Q ( y ) \ ] ( curve ) -- the border-can be formed ; the interpretation of the former expression results in the set of properties that one curve or another has , including the properties of curve ct ; however , the intepretation of the last expression results in an empty set as there is more than one curve in the drawing .</sentence>
				<definiendum id="0">constant curve</definiendum>
				<definiens id="0">the set of curves on the drawing , so the expressions ~</definiens>
				<definiens id="1">the interpretation of the former expression results in the set of properties that one curve or another has , including the properties of curve ct</definiens>
			</definition>
</paper>

		<paper id="0215">
</paper>

		<paper id="1416">
</paper>

		<paper id="0114">
			<definition id="0">
				<sentence>The system consists of the following three parts ; the analysis of the Japanese sentence ; the analysis of the Engtish sentence ; and the identification of Japanese zero pronouns in Japanese sentences and their antecedents in English equivalent sentences .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of the following three parts ; the analysis of the Japanese sentence ; the analysis of the Engtish sentence ; and the identification of Japanese zero pronouns in Japanese sentences and their antecedents in English equivalent sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>The predicate part means the consecutive words which consist of verb and modal , tense and aspect .</sentence>
				<definiendum id="0">predicate part</definiendum>
				<definiens id="0">means the consecutive words which consist of verb and modal , tense and aspect</definiens>
			</definition>
</paper>

		<paper id="0910">
			<definition id="0">
				<sentence>However , since each target lexical entry L is created from a source counterpart L ' , it is trivial to create simultaneously a transfer rule which maps the source QLF constant associated with L ' into the target QLF constant associated with L. The previous sections have hopefully conveyed some of the flavour of our translation framework , which conceptually can be thought of as half-way between transfer and interlingua .</sentence>
				<definiendum id="0">translation framework</definiendum>
				<definiens id="0">half-way between transfer and interlingua</definiens>
			</definition>
</paper>

		<paper id="0712">
			<definition id="0">
				<sentence>features ( Fig 2 ) represent rhetorical semantxc criteria often employed m the processing of focus reformation and m anaphor chsamblguatlon For example , Topscalzsahon , Focus Change , Cardznahty and Elhps~ have all been used m computatmnal contexts such as ( Hobbs , 1978 , Rexchman , 1985 , Sldner , 1983 , Webber , 1983 ) Finally , the surface features ( Fig 3 ) comclde mostly with exphmt cues m the text wlnch denote cohesive and coherence relatlous among sentences ( d ( Li~hn , 1958 , Pmce , 1981 ) ) The Functzon Word and the Common Content Word Pools , for instance , conmst of lemcal 1terns with a semantic/rhetorical load exteuslvely dmcussed m a Systennc-Fauctxonal ( Coulthard , 1994 ) and Problem-Solutxon context ( Jordan , 1984 , Jordan , !</sentence>
				<definiendum id="0">Functzon Word</definiendum>
				<definiendum id="1">Common Content Word Pools</definiendum>
				<definiendum id="2">Systennc-Fauctxonal</definiendum>
				<definiens id="0">m the processing of focus reformation and m anaphor chsamblguatlon For example , Topscalzsahon , Focus Change , Cardznahty and Elhps~ have all been used m computatmnal contexts such as ( Hobbs , 1978 , Rexchman , 1985 , Sldner , 1983 , Webber , 1983</definiens>
			</definition>
			<definition id="1">
				<sentence>enee on Artsfic~al Intelhgence , Ezpert Systems and Natural Language Processing , A~guon , ~anee , May 1993 M Gopmk Lmgutstsc Structures m Scientific Tezts Mouton , The Hague , the Netherlands , 1972 B J Grosz The Itepreeentatmn and Use of Focus m a System for Understanding Dml0gs In B J Grosz , K Sparck Jones , and B L Webber , edztors , Readzngs In Natural Langzuzge Processmg Morgan Ksllfi'n~m~ Cahforma , 1986 Fzrst appeared m Proceedings of the 5th 13CAI , Cambridge , Massachusetts , 67-76 , los Altos Wzlham Kaufmann , 1977 M A K Halhday and R Hasan Cohesion m Engltsh Longman , London , U K , 1976 M Hoey Szgnallmg m Dxscourse A Panctlonal Analysm of a common Discourse pattern m written and spoken Enghsh In M Coulthard , e &amp; torl Advances m Wrvtten Tezt Analysts , pages 26 -- 45 Routledge , london , U K , 1994 E Hovy Generating Natural Language Under Pragmatzc Constraints Journal of Pragmatws , 11 689 -- 719 , 1987 P S Jacobs and L F Ran scIsoR Extracting Infonnatzon from On-Line News Cornmumcatsons of the ACM , 33 ( 11 ) , pages 88 -- 97 , 1990 M P Jordan The Rhetorsc of Everyday Enghsh Tezts George Allen &amp; Unwm , London , U K , 1984 M P Jordan Openings m Very Formal Techmcal Texts Technostyle , 11 ( 1 ) 1-28 , 1993 M P Jordan The Power of Negatzon Pragmatzccs , Discourse Patterns and Clausal Semantzcs In Annual Meetzng of the Canadmn Assocmtzon of Teachers of Techmcal Wrdmg , Canachan Learned Conferences , Montreal , Canada , 1995 J Kuplee , J Pedersen , and F Chen A Trainable Document Summarizer In Proceedings of the 18th ACM-8IGIR Conference , pages 68-731 1995 W G Lehnert Plot Umts and Narrative Summ &amp; nzatlon Cogmtwe Sczence , 4 , 1981 , pages 293331 N Lucas , K Nmhma , T Alaba , and KG Suresh Dmcourse Analyszs of Scientific Textbooks m Japanese A Tool for Producing Automatic Summanes Techmcal Report 93TR-0004 , Dept of Computer Science , Tokyo Instztute of Technology , Tokyo , Japan , March 1993 H P Luhn The Automatze Creatmn of L~terature Abstracts ram Journal of Itesearch &amp; Development , 2 ( 2 ) , April , 1958 , pages 159 -- 165 R E Mamell , J F Smith , and T E R Stager Abstracting Sczentzfie and Techmcal £s~rature An Introductory Grade and Tezt for Scsentis~ , Abstractors , and Management Wfley-Intersclence John Wdey &amp; Sons , Inc , New York , 1971 W C Mann and S A Thompson Pdaetoncal Structure Theory A Theory of Text Orgamzatmn Techmcal Report , ISZ Repnnt Series IS1/RS-87190 , usc Informatzon Sciences Instztute , Manna Del Rey , Ca , June 1987 M T Maybury Automated Event Summ~zatlon Techmques In Dagstuhl-Semmar-Reeport 79 Sumrnartsmg Tezt for Intelhgent Commumeat~on , B Endres-Nlggemeyer , J Hobbs , and K SparckJones , editors , Dagstuhl , Wadern , Germany , Dec 13-17 , 1993 J L McClelland , D E Rumelhart , and the PDP Research Group ( Eds ) Parallel Dtstrsbuted Proceasing Ezploratsons sn the Mtcrostrueture of Cognstson Volume 2 Psychologseal and Bsologseal Models The MIT Press , Cambridge , Massachusetts , 1986 R Mltkov , D Le Roux , and J-P Desclbs Knowledge-Based Automattc Abstracting Expernnents m the Sublanguage of Elementary Geometry In C Martm-Vlde , editor , Current Issues m Mathematgcal gmgu~tzcs , pages 415-421 NorthHolland , the Netherlands , 1994 Proceedings of the Fifth Message Understanding Conference ( MUC-5 ) , Aug ~5-~7 , San Mateo , CA , Baltnnore , 'Maryland , 1993 Morgan Ka , fmann K Ono , K Smmta , andS Mnke Abstract Generation based on Rhetorical Structure Extraction In Proccedmgs of the 15th lnternatwnal Conference on Computatsonal Lmgusstzes ( COLING-94 ) , volume 1 , pages 344-348 , Kyoto , Japan , August 1994 Association for Computatmnal Lmgtustics Also appeared as cmp-lg/9411023 C D Pmce Automatic Generatmn of Literature Abstracts An Approach Based on the Identzficstmn of Self-In &amp; citing Phrases In R NOddy , S E Robertson , C J van RIjsbergen , and P W Wflhums , editors , Information Retrieval Research , pages 172-191 Butterworths , London , U K , 1981 C D Pmce Constructing Literature Abstracts by Computer Techmques and Prospects In In/ormatwn Processing ~ Management , 26 ( 1 ) , pages 171-186 , 1990 L F Ran , R Brandow , and K M~tze DomainIndependent S-mmarmat~on of News In Dagstuhl Seminar Report 79 Summartszng Tezt for Intelhgent Communzeatwn , B Endres-Niggemeyer , J Hobbs , and K Sparck-Jones , editors , Dagstuhl , Wadern , Germany , Dec 13-17 , 1993 R Re~chman Getting Computers to Talk Like You and Me lhscourse Contezt , Focus , and ~ernantics ( An ATN Model ) The MIT Press , Cambridge , Massachusetts , 1985 D '' E Rumelhaxt , G E Hmton , and R J Wflllam .</sentence>
				<definiendum id="0">B L Webber</definiendum>
				<definiendum id="1">M A K Halhday</definiendum>
				<definiens id="0">R Re~chman Getting Computers to Talk Like You and Me lhscourse Contezt , Focus , and ~ernantics ( An ATN Model</definiens>
			</definition>
</paper>

		<paper id="0614">
			<definition id="0">
				<sentence>The NWO Priority Programme Language and Speech Technology is a research programme aiming at the development of spoken language information systems .</sentence>
				<definiendum id="0">NWO Priority Programme Language</definiendum>
				<definiens id="0">a research programme aiming at the development of spoken language information systems</definiens>
			</definition>
			<definition id="1">
				<sentence>The DM keeps track of the information provided by the user by maintaining an information state or form .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiens id="0">keeps track of the information provided by the user by maintaining an information state or form</definiens>
			</definition>
			<definition id="2">
				<sentence>The input to the NLP module consists of wordgraphs produced by the speech recognizer .</sentence>
				<definiendum id="0">NLP module</definiendum>
				<definiens id="0">consists of wordgraphs produced by the speech recognizer</definiens>
			</definition>
			<definition id="3">
				<sentence>At each node we visit , we compute a partial score consisting of a tuple ( S , P , A ) , where S is the number of transitions on the path not part of a maximal projection ( the skips ) , P is the number of maximal projections , A is the sum of the acoustic scores of all the transitions on the path , including those internal in maximal projections .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">the number of transitions on the path not part of a maximal projection ( the skips ) ,</definiens>
				<definiens id="1">the number of maximal projections , A is the sum of the acoustic scores of all the transitions on the path</definiens>
			</definition>
			<definition id="4">
				<sentence>Besides S , P , and A , other factors can be taken into account as well , such as the semantic score , which is obtained by comparing the updates corresponding to maximal projections with the meaning of the question generated by the system prior to the user utterance .</sentence>
				<definiendum id="0">semantic score</definiendum>
				<definiens id="0">obtained by comparing the updates corresponding to maximal projections with the meaning of the question generated by the system prior to the user utterance</definiens>
			</definition>
			<definition id="5">
				<sentence>Bigrams attach a measure of likelihood to the occurrence of a word given a preceding word .</sentence>
				<definiendum id="0">Bigrams</definiendum>
				<definiens id="0">attach a measure of likelihood to the occurrence of a word given a preceding word</definiens>
			</definition>
			<definition id="6">
				<sentence>Word accuracy is defined as 1~ where n is the length of the actual utterance and d is the distance as defined above .</sentence>
				<definiendum id="0">Word accuracy</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the length of the actual utterance</definiens>
			</definition>
			<definition id="7">
				<sentence>Finally , following ( Boros and others , 1996 ) , we also present concept accuracy as CA = IO0 ( 1SUs + SUi SUD ) ~ where SU is the total number of semantic units in the translated corpus annotation , and SUs , SUt , and SUp are the number of substitutions , insertions , and deletions that are necessary to make the translated grammar update equivalent to the translation of the corpus update .</sentence>
				<definiendum id="0">SU</definiendum>
				<definiendum id="1">SUp</definiendum>
				<definiens id="0">the total number of semantic units in the translated corpus annotation , and SUs , SUt , and</definiens>
				<definiens id="1">the number of substitutions , insertions , and deletions that are necessary to make the translated grammar update equivalent to the translation of the corpus update</definiens>
			</definition>
			<definition id="8">
				<sentence>Therefor~ the experiment is 71 Method 3800 graphs : user utterance word-graphs word-graphs ( +bigram ) 5000 graphs : word-graphs word-graphs ( +bigram ) WA SA 85.3 72.9 86.5 75.1 79.5 70.0 82.4 74.2 Semantic accuracy match precision recall CA 97.9 99.2 98.5 98.5 81.0 84.7 86.6 84.4 81.8 85.5 8'7.4 85.2 Table 4 : Evaluation of the NLP component with respect to word accuracy , sentence accuracy and concept accuracy .</sentence>
				<definiendum id="0">user utterance word-graphs word-graphs</definiendum>
				<definiendum id="1">word-graphs word-graphs</definiendum>
				<definiens id="0">Evaluation of the NLP component with respect to word accuracy , sentence accuracy and concept accuracy</definiens>
			</definition>
			<definition id="9">
				<sentence>Semantic accuracy consists of the percentage of graphs which receive a fully correct analysis ( match ) , percentages for precision and recall of semantic slots , and concept accuracy .</sentence>
				<definiendum id="0">Semantic accuracy</definiendum>
				<definiens id="0">consists of the percentage of graphs which receive a fully correct analysis ( match ) , percentages for precision and recall of semantic slots , and concept accuracy</definiens>
			</definition>
</paper>

		<paper id="0615">
			<definition id="0">
				<sentence>Let Sn ( wi ) be the score of the word wi having observed N-best hypothesis up to rank n : = + ( 2 ) Where Vn ( wi ) is the potential for rescoring the word wi according to hypothesis Hn -the sentence hypothesis at rank n and ASh is the rescoring amplitude at rank n. The first factor of the re-evaluation is the potential , defined in equation 3 .</sentence>
				<definiendum id="0">Sn ( wi )</definiendum>
				<definiendum id="1">ASh</definiendum>
				<definiendum id="2">re-evaluation</definiendum>
				<definiens id="0">the score of the word wi having observed N-best hypothesis up to rank n : = + ( 2 ) Where Vn ( wi ) is the potential for rescoring the word wi according to hypothesis Hn -the sentence hypothesis at rank n</definiens>
			</definition>
			<definition id="1">
				<sentence>COVEN ( COllaborative Virtual ENvironments ) addresses the technical and design-level requirements of Virtual-based multi-participant collaborative activities in professional and citizen-oriented domains .</sentence>
				<definiendum id="0">COllaborative Virtual ENvironments )</definiendum>
				<definiens id="0">addresses the technical and design-level requirements of Virtual-based multi-participant collaborative activities in professional and citizen-oriented domains</definiens>
			</definition>
			<definition id="2">
				<sentence>Nodes X0 , X1 , or more generally Xn , are substitution sites , they are awaiting a tree whose head symbol is X. Substitution sites bear syntactic and semantic constraints on their possible substitutors .</sentence>
				<definiendum id="0">X. Substitution</definiendum>
				<definiens id="0">sites bear syntactic and semantic constraints on their possible substitutors</definiens>
			</definition>
</paper>

		<paper id="0314">
			<definition id="0">
				<sentence>Lexical acquisition methods rely on collocational analysis ( pure statistics ) , robust parsing ( syntax-driven acquisition ) or semantic annotations as they are found in large thesaura or on-line dictionaries .</sentence>
				<definiendum id="0">pure statistics</definiendum>
				<definiens id="0">syntax-driven acquisition ) or semantic annotations as they are found in large thesaura or on-line dictionaries</definiens>
			</definition>
			<definition id="1">
				<sentence>Tile environmental corpus , called ENEA , is a collection of short scientific abstracts or newspaper articles dealing with pollution .</sentence>
				<definiendum id="0">Tile environmental corpus</definiendum>
				<definiendum id="1">ENEA</definiendum>
				<definiens id="0">a collection of short scientific abstracts or newspaper articles dealing with pollution</definiens>
			</definition>
			<definition id="2">
				<sentence>Sentence fragments like ... l'inizio della attivitd di costruzione ... the start of the building activity or ... lrasportavano articoli da spiaggia ... they transported beach articles , although inherently ambiguous ( l 'inizio della costruzione and trasportavano da spiaggia are sentence readings that also obey to selectional constraints ( e.g. to transport/bring from a place ) ) can be correctly parsed when the two terms are employed before syntactic analysis is triggered .</sentence>
				<definiendum id="0">Sentence fragments</definiendum>
				<definiens id="0">the start of the building activity or ... lrasportavano articoli da spiaggia ... they transported beach articles , although inherently ambiguous ( l 'inizio della costruzione and trasportavano da spiaggia are sentence readings that also obey to selectional constraints ( e.g. to transport/bring from a place</definiens>
			</definition>
			<definition id="3">
				<sentence>2In lexical acquisition the role of other syntactic categories ( e.g. verbs , adjectives , ... ) is also very important but the set of phenomena related to them is very different , ms also outlined by ( Basili et al.,1996b ) 127 A detailed analysis of the role of syntactic moditiers and specifiers ( De Rossi,1996 ) revealed that legal structures for modifiers and specifiers in Italian are mainly of two types : inal participial , adjectival or prepositional phrases ) nal modifiers , i.e. adjectival phrases ) Restrictive modifiers are generally used to constraint , the semantic information related to the corresponding noun , via a further specification of a given typefor that noun as in scambi commerciali ( *exchanges commercial ) : the referent noun is forced to belong to a restricted set of exchanges ( that are in fact of commercial nature ) .</sentence>
				<definiendum id="0">commercial )</definiendum>
				<definiens id="0">inal participial , adjectival or prepositional phrases ) nal modifiers</definiens>
			</definition>
			<definition id="4">
				<sentence>Given a term i , its inverse document frequency is defined as follows : idfi = log s ~N where dfi is the number of documents of the corpus that include term i , while N is the total number of documents in the collection .</sentence>
				<definiendum id="0">inverse document frequency</definiendum>
				<definiendum id="1">dfi</definiendum>
				<definiendum id="2">N</definiendum>
				<definiens id="0">the number of documents of the corpus that include term i</definiens>
				<definiens id="1">the total number of documents in the collection</definiens>
			</definition>
			<definition id="5">
				<sentence>In the Extend step of the a.lgorithm we need to evaluate the mutual information values of phrase structures like : head Modl head Modl Mod2 head Modi Mod2 ... Mod , ~ Mutual Information between two words x and y is defined as ( Fano,1961 ) : l ( x , y ) = log vrob ( ~ , y ) prob ( x ) prob ( y ) and it can be estimated by a maximum likelihood method as in ( Dagan,1993 ) : \ ] ( x , y ) = log s N.Jreq ( x , y ) \ ] req ( x ) freq ( y ) where : freq ( x , y ) is the frequency of the joint event of ( x , y ) , freq ( x ) , freq ( y ) and N are the frequency of x , y and the corpus size respectively .</sentence>
				<definiendum id="0">log s N.Jreq</definiendum>
				<definiendum id="1">, freq ( x</definiendum>
				<definiendum id="2">N</definiendum>
				<definiens id="0">evaluate the mutual information values of phrase structures like : head Modl head Modl Mod2 head Modi Mod2 ... Mod , ~ Mutual Information between two words x and y is defined as ( Fano,1961 ) : l ( x , y ) = log vrob ( ~ , y ) prob ( x ) prob ( y ) and it can be estimated by a maximum likelihood method as in ( Dagan,1993 ) : \ ] ( x , y ) =</definiens>
				<definiens id="1">the frequency of the joint event of ( x , y )</definiens>
				<definiens id="2">the frequency of x , y and the corpus size respectively</definiens>
			</definition>
			<definition id="6">
				<sentence>A section is the set of terms that share the same term head .</sentence>
				<definiendum id="0">section</definiendum>
				<definiens id="0">the set of terms that share the same term head</definiens>
			</definition>
			<definition id="7">
				<sentence>Distributional , as well syntactic , knowledge is a crucial source of information for large scale similarity estimation among detected terms .</sentence>
				<definiendum id="0">Distributional</definiendum>
				<definiens id="0">a crucial source of information for large scale similarity estimation among detected terms</definiens>
			</definition>
</paper>

		<paper id="0404">
			<definition id="0">
				<sentence>TDMT which refers to as Example-Based Machine translation ( EBMT ) \ [ 7\ ] does not require a full analysis and instead defines patterns on sentences/phrases expressed by `` variables '' and `` constituent boundaries '' .</sentence>
				<definiendum id="0">TDMT</definiendum>
				<definiens id="0">Example-Based Machine translation ( EBMT ) \ [ 7\ ] does not require a full analysis and instead defines patterns on sentences/phrases expressed by `` variables '' and `` constituent boundaries ''</definiens>
			</definition>
</paper>

		<paper id="0311">
			<definition id="0">
				<sentence>Mutual information measures how well one random variable predicts another3 : Pr ( s , t ) I ( S ; T ) = ~ ~ Pr ( s , t ) log Pr ( s ) Pr ( t ) ( 1 ) sES tET When Pr ( s , t ) is a text translation model , mutual information indicates how well the model can predict the distribution of words in the target text given the distribution of words in the source text , and vice versa .</sentence>
				<definiendum id="0">Mutual information</definiendum>
				<definiens id="0">a text translation model , mutual information indicates how well the model can predict the distribution of words in the target text given the distribution of words in the source text , and vice versa</definiens>
			</definition>
			<definition id="1">
				<sentence>Note that , by definition , Pr ( x : RC = y ) = Pr ( y : LC = X ) -- -Pr ( xy ) .</sentence>
				<definiendum id="0">Pr (</definiendum>
				<definiens id="0">x : RC = y ) = Pr ( y : LC = X ) -- -Pr ( xy )</definiens>
			</definition>
			<definition id="2">
				<sentence>The final form of Equation 5 ( in Figure 2 ) allows us to partition all the terms in Equation 4 into two sets , one for each of the components of the candidate NCC : Amy = £m~y + £me-y ( 11 ) where + + -i ( x ) ( 12 ) Pr ( x : RC ~ y , t ) E Pr ( x : aC ~ y , t ) log Pr ( x , ac ~ y ) Pr ( t ) tET Pr ( x : ac = y , t ) EPr ( x : ac = Y't ) l°g pr~ ; RC ~_ yi~r ( t ) tET £xe-y = -iCy ) ( 13 ) Pr ( y : LC ~ x , t ) + E Pr ( y : LC ¢ X , t ) log Fr~ , LC '' ~ x ) Pr ( t ) tET Pr ( y : LC = x , t ) + E Pr ( y : LC = x , t ) log Pr~ .</sentence>
				<definiendum id="0">RC ~_ yi~r</definiendum>
				<definiens id="0">y : LC ~ x , t ) + E Pr ( y : LC ¢ X , t ) log Fr~ , LC '' ~ x ) Pr ( t ) tET Pr ( y : LC = x , t ) + E Pr ( y : LC = x</definiens>
			</definition>
			<definition id="3">
				<sentence>The objective function V for this ap101 plication follows by analogy with the mutual information function I in Equation 1 : Pr ( s , t ) V ( S ; T ) = ~ E ~ ( t , re ( s ) ) Pr ( s , t ) log Pr ( s ) Pr ( t ) 8E~ tET Pr ( s , m ( s ) ) ( 15 ) = ~ Pr ( s , re ( s ) ) log Pr ( s ) Pr ( m ( s ) ) sE8 The Kronecker ~ function is equal to one when its arguments are identical and zero otherwise .</sentence>
				<definiendum id="0">objective function V</definiendum>
				<definiens id="0">s , re ( s ) ) log Pr ( s ) Pr</definiens>
			</definition>
			<definition id="4">
				<sentence>The form of the objective function again permits easy distribution of its value over the s E S : Pr ( s , m ( s ) ) ( 16 ) vT '' ( s ) = Pr ( s , re ( s ) ) log Pr ( s ) Pr ( m ( s ) ) '' The formula for estimating the net change in the objective function due to each candidate NCC remains the same : = ¢ ( = ) + ¢ ( y ) + v ' ( xy ) v ( x ) v ( y ) .</sentence>
				<definiendum id="0">xy ) v</definiendum>
				<definiens id="0">easy distribution of its value over the s E S</definiens>
				<definiens id="1">s ) ) log Pr ( s ) Pr ( m ( s ) ) '' The formula for estimating the net change in the objective function due to each candidate NCC remains the same : = ¢ ( = ) + ¢ ( y ) + v '</definiens>
			</definition>
			<definition id="5">
				<sentence>The NCC discovery method makes few assumptions about the data sets from which the statistical translation models are induced .</sentence>
				<definiendum id="0">NCC discovery method</definiendum>
				<definiens id="0">makes few assumptions about the data sets from which the statistical translation models are induced</definiens>
			</definition>
			<definition id="6">
				<sentence>106 Count 786 183 79 63 36 34 24 23 17 17 16 14 11 10 10 10 NCC ( in italics ) in typical context non-compositional translation in French text could have flow-through shares I repeat the case I just mentioned tax base single parent family perform &lt; GAP &gt; duty red tape middle of the night Della Noce heating oil proceeds of crime rat pack urban dwellers nuclear generating station Air India disaster 7 plea bargaining 7 manifestly unfounded claims 7 machine gun 7 a group called Rural Dignity 6 a slight bit 6 cry for help 5 video tape 5 sow the seed 5 arrange a meeting 4 shot-gun wedding 4 we lag behind 3 severe sentence 3 rear its ugly head 3 inability to deal effectively with 3 en masse 3 create a disturbance 3 blaze the trail 2 wrongful conviction 2 weak sister 2 of both the users and providers of transportation 2 understand the motivation 2 swimming pool 2 ship unprocessed uranium 2 by reason of insanity 2 l'agence de Presse libre du QuEbec 2 do cold weather research 2 the bread basket of the nation 2 turn back the boatload of European Jews pourrait actions accrgditives je tiens ~ dire le casque je viens de mentionner assiette fiscale famille monoparentale assumer ... fonction la paperasserie en pleine nuit Della noce ( see text for explanation ) mazout les produits tirds du crime meute citadins centrale nucl~aire dcrasement de l'avion indien Outaouais j'ose croire vall~e de l'Outaouais marchandage avoir revendiqud ~i tort le statut mitrailleuse une groupe appel~ Rural Dignity la moindre appel au secour video semer organiser un entretien mariage force nous trainions de la patte Great West Life Company mettre fin et interrompre le n~gociation s~v~re sanction manifests ne sait pas traiter de mani~re efficace avec en bloc suscite de perturbation ouvre la voie erreur judiciaire parent pauvre des utilisateurs et des transporteurs saisir le motif piscine exp~dier de l'uranium non raffin~ pour cause d'ali~nation mentale l'agence de Presse libre du Qudbec ~tudier l'effet du froid le grenier du Canada renvoyer tout ces juifs europ~ens Generic Pharmaceutical Industry Association Table 4 : Random sample of 50 of the English NCCs validated in the first five iterations of the NCC discovery algorithm , using the objective function V. `` Count '' is the number of times the NCC occurs in the training text .</sentence>
				<definiendum id="0">NCC</definiendum>
			</definition>
</paper>

		<paper id="0608">
			<definition id="0">
				<sentence>The Message-to-Speech ( MTS ) system described below is specifically designed to function in an environment with seriously restrained computational resources where it is impossible to store large amounts of pre-recorded speech .</sentence>
				<definiendum id="0">Message-to-Speech</definiendum>
				<definiens id="0">specifically designed to function in an environment with seriously restrained computational resources where it is impossible to store large amounts of pre-recorded speech</definiens>
			</definition>
			<definition id="1">
				<sentence>The MTS system combines transplanted prosody with prosody by model in order to cope with partly variable messages while still preserving natural prosody ( Van Coile et al. , 1995 ) .</sentence>
				<definiendum id="0">MTS system</definiendum>
			</definition>
			<definition id="2">
				<sentence>Each breakpoint consists of a location value ( in ms ) relative to the beginning of the phoneme , followed by a pitch 41 # T\ [ 104\ ] ae\ [ 74 ( 0,98 ) 1 N\ [ 471 k\ [ 107 ( 10,81 ) 1 j\ [ 14 ( 0,106 ) 1 u\ [ 44\ ] f\ [ 93 ( 0,91 ) \ ] o\ [ 47 ( 0,102 ) \ ] r\ [ 29\ ] j\ [ 68 ( 0,98 ) ( 30,90 ) \ ] o\ [ 50 ( 0,96 ) 1 r\ [ 71\ ] $ \ [ 45 ( 0,93 ) \ ] -t\ [ 108\ ] E\ [ 70 ( 0,102 ) \ ] n\ [ 68\ ] -S\ [ 96\ ] $ \ [ 561 n\ [ 106 ( 30,83 ) ( 100,83 ) 1 # Figure 1 : textual representation of an EPT for the sentence `` Thank you for your attention '' value ( in ST/4 ; reference 50 Hz ) .</sentence>
				<definiendum id="0">breakpoint</definiendum>
				<definiens id="0">consists of a location value ( in ms ) relative to the beginning of the phoneme</definiens>
			</definition>
			<definition id="3">
				<sentence>A major asset of Prosody Transplantation is the combination of natural sounding speech with a low bit rate for storage ( less than 300 bit per second ) .</sentence>
				<definiendum id="0">Prosody Transplantation</definiendum>
				<definiens id="0">the combination of natural sounding speech with a low bit rate for storage ( less than 300 bit per second )</definiens>
			</definition>
			<definition id="4">
				<sentence>A message represents a complete sentence and is composed of one or more building blocks or message units ( MU ) , which constitute the input of the MTS system .</sentence>
				<definiendum id="0">message</definiendum>
				<definiendum id="1">MU</definiendum>
				<definiens id="0">a complete sentence and is composed of one or more building blocks or message units</definiens>
			</definition>
			<definition id="5">
				<sentence>A carrier is a template containing the enriched phonetic transcription of canned text , transplanted from an appropriate donor message ( see above ) , together with the prosodic information for the free slot parts ( see below ) .</sentence>
				<definiendum id="0">carrier</definiendum>
				<definiens id="0">a template containing the enriched phonetic transcription of canned text , transplanted from an appropriate donor message</definiens>
			</definition>
			<definition id="6">
				<sentence>A duration model is a rule-based system calculating durations , taking into account parameters such as lexical stress , position of phonemes ( word initial , word medial , word final , sentence final ) , length of the argument , phonetic context of phonemes ( left/right neighbour , consonant cluster , open/closed syllable ) etc .</sentence>
				<definiendum id="0">duration model</definiendum>
				<definiens id="0">a rule-based system calculating durations</definiens>
			</definition>
</paper>

		<paper id="0810">
			<definition id="0">
				<sentence>The input to the parser is a tagged string represented by a sequence of word-form + tag pairs of the type : le bon vin ( the good wine ) &lt; Ie+DET-SG &gt; &lt; bon+ADJ-SG &gt; &lt; vin+NOUN-SG &gt; 71 The parser output is a shallow parse where phrasal and clausal constructs are bracketed and more or less richly annotated as in : Jean aime le ben vin ( lit. : John likes the good wine ) \ [ VC \ [ NP Jean NP\ ] /SUBJ : v airne v : VC\ ] \ [ NP le \ [ AP bon AP\ ] vin NP\ ] BJ The parser consists of a sequence of transducers .</sentence>
				<definiendum id="0">parser output</definiendum>
				<definiens id="0">a tagged string represented by a sequence of word-form + tag pairs of the type : le bon vin ( the good wine ) &lt; Ie+DET-SG &gt; &lt; bon+ADJ-SG &gt;</definiens>
				<definiens id="1">a shallow parse where phrasal and clausal constructs are bracketed and more or less richly annotated as in : Jean aime le ben vin ( lit. : John likes the good wine ) \ [ VC \ [ NP Jean NP\ ] /SUBJ : v airne v : VC\ ] \ [ NP le \</definiens>
			</definition>
			<definition id="1">
				<sentence>Segmentation consists in bracketing and labeling adjacent elements belonging to a same partial construction ( e.g. a nominal or a verbal phrase , or a more partial syntactic chain if necessary ) .</sentence>
				<definiendum id="0">Segmentation</definiendum>
				<definiens id="0">consists in bracketing and labeling adjacent elements belonging to a same partial construction ( e.g. a nominal or a verbal phrase , or a more partial syntactic chain if necessary )</definiens>
			</definition>
			<definition id="2">
				<sentence>A segment ( or chunk ) is a continuous sequence of words that are syntactically linked to each other or to a governing head ( see \ [ Federici et al. , 1996 ; A~t-Mokhtar and Chanod , 1997\ ] for a more detailed description ) .</sentence>
				<definiendum id="0">segment</definiendum>
				<definiendum id="1">chunk )</definiendum>
				<definiens id="0">a continuous sequence of words that are syntactically linked to each other or to a governing head</definiens>
			</definition>
			<definition id="3">
				<sentence>Function tagging is performed during the shallow parsing process ; then a special transducer recognizes subject/verb and object/verb dependencies ( i.e. it finds out which is the subject or object of which verb ) and extracts them .</sentence>
				<definiendum id="0">Function tagging</definiendum>
				<definiens id="0">the subject or object of which verb</definiens>
			</definition>
			<definition id="4">
				<sentence>In order to handle this difficulty properly with the finite state calculus , we take advantage of the verb segmenting marks produced by the shallow parser and define a maximal embedding level : 6The factory which the minister should establish at Eloyes represents approximately a 148 bdhon francs investment 73 level0 = ~ $ \ [ BeginVC I EndVC\ ] level1 = \ [ level0 I \ [ BeginVC level0 EndVC\ ] \ ] * curlev = \ [ level1 \ [ \ [ BeginVC levell EndVC\ ] \ ] * The regular expression levelO matches any string which does not contain any BeginVC or EndVC marks , i.e , an embedded clause , level1 matches any string that contains strings matching levelO or entire embedded clauses that contains only levelO matching strings .</sentence>
				<definiendum id="0">levelO</definiendum>
				<definiens id="0">matches any string which does not contain any BeginVC or EndVC marks , i.e , an embedded clause</definiens>
			</definition>
			<definition id="5">
				<sentence>Sub : errors Actual Tagged Correct PreclRecall as Tag slon % % 296 278 266 95.6 89 8 ( 94 4 ) ( 87 4 ) 177 175 152 86.8 85 8 ( 86 3 ) ( 79 9 ) ect and object recognition without POS tagging The improvement is mostly for recall of objects .</sentence>
				<definiendum id="0">Sub</definiendum>
				<definiens id="0">79 9 ) ect and object recognition without POS tagging The improvement is mostly for recall of objects</definiens>
			</definition>
</paper>

		<paper id="0115">
			<definition id="0">
				<sentence>The correlation coefficient could be measured by several methods , such as co-occurrence frequency , mutual information , generalized likelihood estimation , chi-square test , Dice coefficient .</sentence>
				<definiendum id="0">correlation coefficient</definiendum>
				<definiens id="0">mutual information , generalized likelihood estimation , chi-square test , Dice coefficient</definiens>
			</definition>
			<definition id="1">
				<sentence>2 Vii ill If the characters A and B occur independently , then we would expect P ( AB ) =P ( A ) XP ( B ) , where P ( ABJ is the probability of A and B occurring next to each other ; P ( A ) is the probability of A , P ( B ) is the probability of B. To test the null hypothesis P ( ABJ=P ( A ) XP ( B ) , we compute the chi-square statistic : 2 2 2 ( n¢ x \ ] '/I • xn .</sentence>
				<definiendum id="0">Vii ill If the</definiendum>
				<definiendum id="1">A ) XP</definiendum>
				<definiendum id="2">P ( ABJ</definiendum>
				<definiendum id="3">P ( B )</definiendum>
				<definiens id="0">the probability of A and B occurring next to each other</definiens>
				<definiens id="1">the probability of A</definiens>
				<definiens id="2">the probability of B. To test the null hypothesis P ( ABJ=P ( A ) XP ( B )</definiens>
			</definition>
			<definition id="2">
				<sentence>Let Pc ( W ) be the frequency of word W in domain corpus , P , ( W ) be the normal frequency of W. If Pc ( W ) &gt; &gt; P , ( W ) , W is extracted and further examined by professionals , otherwise it is discarded .</sentence>
				<definiendum id="0">Pc ( W )</definiendum>
				<definiens id="0">the frequency of word W in domain corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>In the following experiment , this formula is replaced with Pc ( W ) &gt; T2 • P , ( W ) , where T2 is a threshold .</sentence>
				<definiendum id="0">T2</definiendum>
				<definiens id="0">a threshold</definiens>
			</definition>
</paper>

		<paper id="0606">
			<definition id="0">
				<sentence>33 For the representation of contextual information a dialogue memory has been developed which consists of two subcomponents : the Sequence Memory , which mirrors the sequential order in which the utterances and the related dialogue acts occur , and the Thematic Structure , which consists of instances of temporal categories and their status in the dialogue .</sentence>
				<definiendum id="0">Thematic Structure</definiendum>
				<definiens id="0">consists of two subcomponents : the Sequence Memory , which mirrors the sequential order in which the utterances</definiens>
			</definition>
</paper>

		<paper id="0603">
			<definition id="0">
				<sentence>Spoken language technologies are being viewed as one of the most important next steps towards truly natural interactive systems which are able to communicate with humans the same way that humans communicate with each other .</sentence>
				<definiendum id="0">Spoken language technologies</definiendum>
			</definition>
			<definition id="1">
				<sentence>When used prior to implementation , DET acts as a design guide ; when applied to an implemented system , DET acts as a diagnostic evaluation tool .</sentence>
				<definiendum id="0">DET</definiendum>
				<definiendum id="1">DET</definiendum>
				<definiens id="0">a diagnostic evaluation tool</definiens>
			</definition>
			<definition id="2">
				<sentence>Until the user has built up a flail query , which of course may be done in a single utterance but sometimes takes several utterances to dothe system would only respond by asking for more information or by correcting errors in the information provided by the user .</sentence>
				<definiendum id="0">flail query</definiendum>
				<definiens id="0">more information or by correcting errors in the information provided by the user</definiens>
			</definition>
			<definition id="3">
				<sentence>NOBNOB is NOB 's annotation of the NOB sub-corpus .</sentence>
				<definiendum id="0">NOBNOB</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Sundial corpus was analysed by two of the DET tool developers .</sentence>
				<definiendum id="0">Sundial corpus</definiendum>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>5y ( x , , y , ) i=1 n i=l ( 1 ) In this formula , n indicates the number of features , Di the number of instances that have value 1 for feature i , and Cy the class of the training case Y. The term p ( Di , Cy ) then denotes the proportion of instances in Di that belong to class Cy .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of features , Di the number of instances that have value 1 for feature i , and Cy the class of the training case Y. The term p</definiens>
				<definiens id="1">the proportion of instances in Di that belong to class Cy</definiens>
			</definition>
			<definition id="1">
				<sentence>Model-based Learning In contrast to instance-based learning , model-based approaches represent the learned knowledge in a theory language that is richer than the language used for the description of the training data ( Quinlan , 1986 ) .</sentence>
				<definiendum id="0">Model-based Learning</definiendum>
				<definiens id="0">In contrast to instance-based learning , model-based approaches represent the learned knowledge in a theory language that is richer than the language used for the description of the training data</definiens>
			</definition>
			<definition id="2">
				<sentence>In addition , we have also implemented the IGTree algorithm ( Daelemans et al. , 1997 ) , which uses the information gain as static splitting criterion , and C~.5 ( Quinlan , 1993b ) , which applies the information gain to dynamic splitting .</sentence>
				<definiendum id="0">IGTree algorithm</definiendum>
				<definiens id="0">uses the information gain as static splitting criterion</definiens>
				<definiens id="1">applies the information gain to dynamic splitting</definiens>
			</definition>
			<definition id="3">
				<sentence>5-R ULES ( Quinlan , 1993b ) , which extracts rules from the decision tree built by C4.5 .</sentence>
				<definiendum id="0">5-R ULES</definiendum>
				<definiens id="0">extracts rules from the decision tree built by C4.5</definiens>
			</definition>
			<definition id="4">
				<sentence>SE-trees are a generalization of decision trees in that they allow not only one but several feature tests at one node .</sentence>
				<definiendum id="0">SE-trees</definiendum>
				<definiens id="0">a generalization of decision trees in that they allow not only one but several feature tests at one node</definiens>
			</definition>
			<definition id="5">
				<sentence>The PPC performs the mean-term scheduling of products and resources involved in the manufacturing processes , i.e. material , machines , and labor .</sentence>
				<definiendum id="0">PPC</definiendum>
				<definiens id="0">performs the mean-term scheduling of products and resources involved in the manufacturing processes , i.e. material , machines , and labor</definiens>
			</definition>
			<definition id="6">
				<sentence>Concerning the method BIN-PRO , which uses prototypes of classes , we achieved results at the same quality level as for BIN-CAT .</sentence>
				<definiendum id="0">method BIN-PRO</definiendum>
				<definiens id="0">uses prototypes of classes</definiens>
			</definition>
</paper>

		<paper id="1408">
			<definition id="0">
				<sentence>A context set is defined as the set of entities the addressee is currently assumed to be attending to the contrast set is the same except to the intended referent ; an equivalent term is the set of potential distractors ( McDonald , 1981 ) .</sentence>
				<definiendum id="0">equivalent term</definiendum>
				<definiens id="0">the set of entities the addressee is currently assumed to be attending to the contrast set is the same except to the intended referent ; an</definiens>
			</definition>
</paper>

		<paper id="1406">
			<definition id="0">
				<sentence>1 We proved the reusability of the methods and the architecture of MOFA in a completely different domain by implementing a prototype for multimodal calendar management ( the system TALKY ) .</sentence>
				<definiendum id="0">TALKY</definiendum>
				<definiens id="0">the system</definiens>
			</definition>
			<definition id="1">
				<sentence>Architecture of MOFA In our architecture the MOFA interface is organized into four main components that are realized as independent processes that communicate via sockets : • The Graphical Interface ( GI ) for gestural input and graphical output , • the Speech Recognizer ( SR ) , Active and Passive Gestures 45 • the multimodal interpretation , dialogue and presentation planning process ( MIDP ) • and the speech synthesis component ( SYN ) .</sentence>
				<definiendum id="0">Graphical Interface</definiendum>
				<definiendum id="1">Speech Recognizer</definiendum>
				<definiendum id="2">SYN</definiendum>
				<definiens id="0">the multimodal interpretation , dialogue and presentation planning process ( MIDP ) • and the speech synthesis component</definiens>
			</definition>
			<definition id="2">
				<sentence>The back end application ( AP ) may be integrated in the MIDP or realized as separate process ( in case of MOFA , the AP is the route planner ) .</sentence>
				<definiendum id="0">AP</definiendum>
				<definiendum id="1">MOFA</definiendum>
				<definiendum id="2">AP</definiendum>
				<definiens id="0">the route planner )</definiens>
			</definition>
			<definition id="3">
				<sentence>The GI sends both gestural events like pointing to an object or selecting a menu item , and written input to the MIDP .</sentence>
				<definiendum id="0">GI</definiendum>
				<definiens id="0">sends both gestural events like pointing to an object or selecting a menu item</definiens>
			</definition>
			<definition id="4">
				<sentence>The MIDP consists of the following components : used in parallel or subsequently and determines temporal relations between events .</sentence>
				<definiendum id="0">MIDP</definiendum>
				<definiens id="0">consists of the following components : used in parallel or subsequently and determines temporal relations between events</definiens>
			</definition>
			<definition id="5">
				<sentence>• USER : `` Boehmerwaldplatz '' ( Boehmerwaldplatz is a tube-station ) • MOFA : `` Von A fiber B nach C habe ich die gelbe Route gefunden .</sentence>
				<definiendum id="0">Boehmerwaldplatz</definiendum>
				<definiens id="0">a tube-station</definiens>
			</definition>
			<definition id="6">
				<sentence>Without the support of other modalities , an active gesture determines an action of the system ( in case of a graphical user interface ) or it causes the dialog partner to perform an action ( in case of natural communication ) .</sentence>
				<definiendum id="0">active gesture</definiendum>
				<definiens id="0">determines an action of the system ( in case of a graphical user interface</definiens>
			</definition>
			<definition id="7">
				<sentence>Manipulative Gestures by Active and Passive Gesture Forms To allow for a coexistence of natural communication style and direct manipulative interaction in one multimodal interface we dedicate • ( 1 ) , ( 2 ) and ( 3 ) to natural communication • and ( 4 ) , ( 5 ) and ( 6 ) to graphical interaction ( ( 4 ) could be seen as a communication failure or as an attempt to perform natural communication by manipulative gestures ) .</sentence>
				<definiendum id="0">Manipulative Gestures</definiendum>
			</definition>
			<definition id="8">
				<sentence>Autonumuos Communicative Acts We recall the fact , that we use active gesture forms as deictic ( i.e. passive ) gestures in the touchscreen version of MOFA .</sentence>
				<definiendum id="0">Autonumuos Communicative Acts</definiendum>
				<definiens id="0">deictic ( i.e. passive ) gestures in the touchscreen version of MOFA</definiens>
			</definition>
</paper>

		<paper id="1202">
			<definition id="0">
				<sentence>In this paper , we present a Message-toSpeech ( MTS ) system that offers the linguistic flexibility desired for spoken dialogue and message generating systems .</sentence>
				<definiendum id="0">Message-toSpeech</definiendum>
				<definiens id="0">offers the linguistic flexibility desired for spoken dialogue and message generating systems</definiens>
			</definition>
			<definition id="1">
				<sentence>The Message-to-Speech ( MTS ) system described below is specifically designed to generate high quality speech output with the flexibility desired for spoken dialogue and message generating systems .</sentence>
				<definiendum id="0">Message-to-Speech</definiendum>
				<definiens id="0">specifically designed to generate high quality speech output with the flexibility desired for spoken dialogue and message generating systems</definiens>
			</definition>
			<definition id="2">
				<sentence>Text-to-Speech ( TTS ) is an evident technique for providing speech output with nearly unlimited flexibility .</sentence>
				<definiendum id="0">Text-to-Speech ( TTS</definiendum>
				<definiens id="0">an evident technique for providing speech output with nearly unlimited flexibility</definiens>
			</definition>
			<definition id="3">
				<sentence>Each breakpoint consists of a location value ( in ms ) relative to the beginning of the phoneme , followed by a pitch value ( in ST/4 ; reference 50 Hz ) .</sentence>
				<definiendum id="0">breakpoint</definiendum>
			</definition>
			<definition id="4">
				<sentence>A major asset , of Prosody Transplantation is the combination of natural sounding speech with a low bit .</sentence>
				<definiendum id="0">Prosody Transplantation</definiendum>
				<definiens id="0">the combination of natural sounding speech with a low bit</definiens>
			</definition>
			<definition id="5">
				<sentence>A slot is a placeholder that can take an argument .</sentence>
				<definiendum id="0">slot</definiendum>
			</definition>
			<definition id="6">
				<sentence>A carrier is a template containing the enriched phonetic transcription of the canned text part , transplanted from an appropriate donor , and zero or more slots .</sentence>
				<definiendum id="0">carrier</definiendum>
				<definiens id="0">a template containing the enriched phonetic transcription of the canned text part , transplanted from an appropriate donor , and zero or more slots</definiens>
			</definition>
			<definition id="7">
				<sentence>A duration model is a rule-based system calculating durations , taking into account parameters such as lexical stress , position of phonemes ( word initial , word medial , word final , sentence final ) , length of the argument , phonetic context of phonemes ( left/right neighbour , consonant cluster ) , etc .</sentence>
				<definiendum id="0">duration model</definiendum>
			</definition>
			<definition id="8">
				<sentence>The result of the mapping stage is a complete surface form ( represented by an EPT ) : the precise wording of a message has been fixed in accordance with syntactic and morphologic restrictions .</sentence>
				<definiendum id="0">EPT )</definiendum>
				<definiens id="0">the precise wording of a message has been fixed in accordance with syntactic and morphologic restrictions</definiens>
			</definition>
</paper>

		<paper id="1313">
</paper>

		<paper id="1405">
			<definition id="0">
				<sentence>System description GEORAL Tactile is a multimodal system which is able to provide information of a touristic nature to naive users .</sentence>
				<definiendum id="0">System description GEORAL Tactile</definiendum>
				<definiens id="0">a multimodal system which is able to provide information of a touristic nature to naive users</definiens>
			</definition>
			<definition id="1">
				<sentence>a church ) , locality is a place name and zone is a region delimited by the system or the user .</sentence>
				<definiendum id="0">locality</definiendum>
				<definiens id="0">a region delimited by the system or the user</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>Words , as they are known in English and other western languages , are the basic units of recognition in most CSR systems , but when a language is written as a string of characters with no white space , how does one go about specifying the fundamental units that must be recognized ?</sentence>
				<definiendum id="0">Words</definiendum>
				<definiens id="0">the basic units of recognition in most CSR systems , but when a language is written as a string of characters with no white space , how does one go about specifying the fundamental units that must be recognized</definiens>
			</definition>
			<definition id="1">
				<sentence>In principle the speech recognition problem is to find the most likely word sequence W given the acoustic A. argmaxwP ( W \ [ A ) Using Bayes theorem and the knowledge that p ( A ) does not change the maximization we arrive at argm xwp ( AIW ) , v ( w ) p ( AIW ) is commonly referred to as the acoustic model , p ( W ) is the language model and the argmax operator is realized by specialized search procedures .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the language model and the argmax operator is realized by specialized search procedures</definiens>
			</definition>
			<definition id="2">
				<sentence>The statistical language modeling problem for the sequence of words W = Wl , ... , wn where wn is a special end of sentence symbol can then be rephrased as n p ( W ) = rIp ( w~lwl , ... , w , _x ) i=1 We will for most applications probably never be able to find enough data to estimate p as presented above .</sentence>
				<definiendum id="0">wn</definiendum>
				<definiens id="0">The statistical language modeling problem for the sequence of words W = Wl , ... , wn where</definiens>
				<definiens id="1">a special end of sentence symbol can then be rephrased as n p ( W ) = rIp ( w~lwl , ... , w</definiens>
			</definition>
			<definition id="3">
				<sentence>A mora is a suprasegmental unit similar to a syllable , with the important distinctions that a mora does not need to contain a vowel ( syllabic /n/ and the first of double consonants are considered independent morae ) and a mora-based segmentation would treat long vowels as two morae .</sentence>
				<definiendum id="0">mora</definiendum>
				<definiens id="0">a suprasegmental unit similar to a syllable , with the important distinctions that a mora does not need to contain a vowel ( syllabic /n/</definiens>
			</definition>
			<definition id="4">
				<sentence>Teller and Batchelder ( Teller and Batchelder , 1994 ) describe another segmentation algorithm which uses extensively knowledge about the type of a character ( hiragana/katakana/kanji , etc ) .</sentence>
				<definiendum id="0">segmentation algorithm</definiendum>
				<definiens id="0">uses extensively knowledge about the type of a character ( hiragana/katakana/kanji , etc )</definiens>
			</definition>
			<definition id="5">
				<sentence>The Spontaneous Scheduling Task ( SST ) databases are a collection of dialogues in which two speakers are trying to schedule a time to meet together .</sentence>
				<definiendum id="0">Spontaneous Scheduling Task ( SST</definiendum>
				<definiens id="0">a collection of dialogues in which two speakers are trying to schedule a time to meet together</definiens>
			</definition>
</paper>

		<paper id="0611">
			<definition id="0">
				<sentence>CAPITAL LETTERs name concepts ; unnamed relations denote subconcept relations ; named relations represent particular relations holding between concepts ( e.g. , takes-temporal-data ) .</sentence>
				<definiendum id="0">CAPITAL LETTERs</definiendum>
			</definition>
			<definition id="1">
				<sentence>Individual nodes ( i.e. concepts ) in the task model can be in one of several states : open/dosed nodes are nodes for which the system has not/has acquired a confirmed value .</sentence>
				<definiendum id="0">Individual nodes</definiendum>
			</definition>
			<definition id="2">
				<sentence>-- an abbreviation of 'acquire confirmation sval ( source ) = uval ( source ) ' 'acquire confir ( a ) Dialogue ( u ) ( b ) Dialogue ( s ) O ( s ) Ac ( u ) O ( s ) RO ( u ) R ( s ) R ( s ) I I I I I I offer ( s ) accept ( u ) offer ( s ) to ( u ) r ( s ) r ( s ) pePr~nute `` rate '' TotalCost source destination Figure 4 : Structures that can be abbreviated .</sentence>
				<definiendum id="0">'acquire confir</definiendum>
				<definiens id="0">s ) O ( s ) Ac ( u ) O ( s ) RO ( u ) R ( s ) R ( s ) I I I I I I offer ( s ) accept ( u</definiens>
				<definiens id="1">Structures that can be abbreviated</definiens>
			</definition>
</paper>

		<paper id="1306">
			<definition id="0">
				<sentence>Pronoun resolution is one of the 'classic ' computational linguistics problems .</sentence>
				<definiendum id="0">Pronoun resolution</definiendum>
			</definition>
			<definition id="1">
				<sentence>CogNIAC is a pronoun resolution engine designed around the assumption that there is a sub-class of anaphora that does not require general purpose reasoning .</sentence>
				<definiendum id="0">CogNIAC</definiendum>
				<definiens id="0">a pronoun resolution engine designed around the assumption that there is a sub-class of anaphora that does not require general purpose reasoning</definiens>
			</definition>
			<definition id="2">
				<sentence>to find possible antecedents : For noun phrase anaphora , gathering semantically possible antecedents amounts to running all the noun phrases in a text through various databases for number and gender , and perhaps then a classifier that determines whether a noun phrase is a company , person or place 1 .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">a classifier that determines whether a noun</definiens>
			</definition>
			<definition id="3">
				<sentence>In lieu of full world knowledge , CogNIAC uses regularities of English usage in an attempt to mimic strategies used by humans when resolving pronouns .</sentence>
				<definiendum id="0">CogNIAC</definiendum>
				<definiens id="0">uses regularities of English usage in an attempt to mimic strategies used by humans when resolving pronouns</definiens>
			</definition>
			<definition id="4">
				<sentence>CogNIAC consists of a set of such observations implemented in Perl .</sentence>
				<definiendum id="0">CogNIAC</definiendum>
				<definiens id="0">consists of a set of such observations implemented in Perl</definiens>
			</definition>
			<definition id="5">
				<sentence>The Naive Algorithm would still maintain a salience distinction between 'Earl ' and 'Ted ' , where CogNIAC has no rule that makes a salience distinction between subject and object of a sentence which has two intervening sentences .</sentence>
				<definiendum id="0">CogNIAC</definiendum>
				<definiens id="0">has no rule that makes a salience distinction between subject and object of a sentence which has two intervening sentences</definiens>
			</definition>
			<definition id="6">
				<sentence>Ultimately , the utility of CogNIAC is a function of how it performs .</sentence>
				<definiendum id="0">utility of CogNIAC</definiendum>
				<definiens id="0">a function of how it performs</definiens>
			</definition>
			<definition id="7">
				<sentence>CogNIAC is currently the common noun and pronoun resolution component of the University of Pennsylvania 's coreference resolution software and general NLP software ( Camp ) .</sentence>
				<definiendum id="0">CogNIAC</definiendum>
				<definiens id="0">the common noun and pronoun resolution component of the University of Pennsylvania 's coreference resolution software and general NLP software</definiens>
			</definition>
</paper>

		<paper id="0213">
			<definition id="0">
				<sentence>In both cases , performance of stateof-the-art systems is respectable , if not perfect , and the fundamentals of the dominant approaches ( noisy channel models for tagging , two-level morphology ) are by now well understood .</sentence>
				<definiendum id="0">noisy channel</definiendum>
			</definition>
			<definition id="1">
				<sentence>The penalty matrix distance ( subsensel , subsense2 ) could capture simple hierarchical distance ( e.g. ( Resnik , 1995 ; Richardson et al. , 1994 ) ) , derived from a single semantic hierarchy such as WordNet , or be based on a weighted average of simple hierarchical distances from multiple sources such as sense/subsense hierarchies in several dictionaries .</sentence>
				<definiendum id="0">penalty matrix distance</definiendum>
				<definiens id="0">WordNet , or be based on a weighted average of simple hierarchical distances from multiple sources such as sense/subsense hierarchies in several dictionaries</definiens>
			</definition>
			<definition id="2">
				<sentence>Although unsupervised methods may be evaluated ( with some limitations ) by a sequentially tagged corpus such as the WordNet semantic concordance ( with a large number of polysemous words represented but with few examples of each ) , supervised methods require much larger data sets focused on a subset of polysemous words to provide adequately large training and testing material .</sentence>
				<definiendum id="0">WordNet semantic concordance</definiendum>
				<definiens id="0">sets focused on a subset of polysemous words to provide adequately large training and testing material</definiens>
			</definition>
			<definition id="3">
				<sentence>It would also be helpful for Table 5 to include alignments between multiple monolingual sense representations , such as COBUILD sense numbers , LDOCE tags or WordNet synsets , to support the sharing and leveraging of results between multiple systems .</sentence>
				<definiendum id="0">LDOCE</definiendum>
				<definiens id="0">tags or WordNet synsets , to support the sharing and leveraging of results between multiple systems</definiens>
			</definition>
</paper>

		<paper id="1413">
			<definition id="0">
				<sentence>R is the contrasting relation which allows the interpreter to isolate the referent of the expression from the other members of the set of alternatives .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the contrasting relation which allows the interpreter to isolate the referent of the expression from the other members of the set of alternatives</definiens>
			</definition>
</paper>

		<paper id="0214">
</paper>

		<paper id="0707">
</paper>

		<paper id="1511">
			<definition id="0">
				<sentence>This task is achieved by two components : ( 1 ) the rule-based component , which detects incompleteness of the current grammar and generates a set of hypotheses of new rules and ( 2 ) the corpus-based component , which selects plausible hypotheses based on local contextual information .</sentence>
				<definiendum id="0">rule-based component</definiendum>
				<definiens id="0">detects incompleteness of the current grammar and generates a set of hypotheses of new rules</definiens>
			</definition>
			<definition id="1">
				<sentence>These processes are ( 1 ) the rulebased process , which detects incompleteness of the current grammar and generates a set of hypotheses of new rules and ( 2 ) the corpus-based process , which selects plausible hypotheses based on local contextual information .</sentence>
				<definiendum id="0">rulebased process</definiendum>
				<definiens id="0">detects incompleteness of the current grammar and generates a set of hypotheses of new rules</definiens>
				<definiens id="1">selects plausible hypotheses based on local contextual information</definiens>
			</definition>
			<definition id="2">
				<sentence>The corpus-based process , as the second process , uses the probability information from parsable sentences to rank these hypotheses .</sentence>
				<definiendum id="0">corpus-based process</definiendum>
				<definiens id="0">uses the probability information from parsable sentences to rank these hypotheses</definiens>
			</definition>
			<definition id="3">
				<sentence>p ( Cat -- * ~ ) - '' p ( Cat\ [ l , r ) g ( Cat , l , r ) N ( l , r ) ( 1 ) where N ( Cat , l , r ) is the number of times that Cat is occurred in the environment ( l , r ) .</sentence>
				<definiendum id="0">N ( Cat</definiendum>
				<definiens id="0">the number of times that Cat is occurred in the environment</definiens>
			</definition>
			<definition id="4">
				<sentence>Nrl is the number of rules and Nc is the number of possible contexts , i.e. , the left and right categories .</sentence>
				<definiendum id="0">Nrl</definiendum>
				<definiendum id="1">Nc</definiendum>
				<definiens id="0">the number of rules</definiens>
				<definiens id="1">the number of possible contexts</definiens>
			</definition>
</paper>

		<paper id="1412">
			<definition id="0">
				<sentence>( ICS ) ICS is a comprehensive model of human information processing that describes cognition in terms a collection of sub-systems that operate on specific mental codes or representations .</sentence>
				<definiendum id="0">ICS ) ICS</definiendum>
				<definiens id="0">a comprehensive model of human information processing that describes cognition in terms a collection of sub-systems that operate on specific mental codes or representations</definiens>
			</definition>
			<definition id="1">
				<sentence>\ [ sys\ ] : ICS subsystems \ [ repr\ ] : representations tr == sysxsys Representations consist of basic units of information organised into superordinate structures .</sentence>
				<definiendum id="0">representations tr == sysxsys Representations</definiendum>
				<definiens id="0">consist of basic units of information organised into superordinate structures</definiens>
			</definition>
			<definition id="2">
				<sentence>A mental process ( VIS ) transforms ( : vis-obj : ) it into an object representation that involves the structuring of sensory data into objects , and the grouping together of those objects .</sentence>
				<definiendum id="0">mental process</definiendum>
				<definiendum id="1">VIS ) transforms</definiendum>
				<definiens id="0">vis-obj : ) it into an object representation that involves the structuring of sensory data into objects</definiens>
			</definition>
			<definition id="3">
				<sentence>This new representation can be interpreted by another mental process ( OBJ ) and transformed ( : obj-prop : ) to produce a more abstract representation at propositional level in which objects are identified and related .</sentence>
				<definiendum id="0">OBJ</definiendum>
				<definiens id="0">obj-prop : ) to produce a more abstract representation at propositional level in which objects are identified and related</definiens>
			</definition>
</paper>

		<paper id="0406">
			<definition id="0">
				<sentence>Robustness is an important issue for multilingual speech interfaces for spoken language translation systems .</sentence>
				<definiendum id="0">Robustness</definiendum>
				<definiens id="0">an important issue for multilingual speech interfaces for spoken language translation systems</definiens>
			</definition>
			<definition id="1">
				<sentence>Robustness is a critical issue which must be addressed for this technology to be useful in real applications .</sentence>
				<definiendum id="0">Robustness</definiendum>
				<definiens id="0">a critical issue which must be addressed for this technology to be useful in real applications</definiens>
			</definition>
</paper>

		<paper id="1514">
			<definition id="0">
				<sentence>The generated F-Structure contains the feature Error , whose value is an association of the two uncompatible values .</sentence>
				<definiendum id="0">F-Structure</definiendum>
				<definiens id="0">contains the feature Error , whose value is an association of the two uncompatible values</definiens>
			</definition>
			<definition id="1">
				<sentence>Each non terminal constituent of the grammar is then defined as a Smalltalk class , whose instance methods are the rules whose left part is this constituent ( e.g. , NP is a class , NP -- * ProperNoun and NP -- ~ Det Adj* Noun are instance methods of this class ) .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">a class , NP -- * ProperNoun and NP -- ~ Det Adj* Noun are instance methods of this class )</definiens>
			</definition>
			<definition id="2">
				<sentence>Applications are defined as sets of classes , methods , and extensions of classes , that can be independently edited and versioned .</sentence>
				<definiendum id="0">Applications</definiendum>
				<definiens id="0">sets of classes , methods , and extensions of classes</definiens>
			</definition>
			<definition id="3">
				<sentence>Conceptual graphs ( Sowa , 1984 ) form the basis of the semantic and encyclopedic representations used in our system .</sentence>
				<definiendum id="0">Conceptual graphs</definiendum>
			</definition>
			<definition id="4">
				<sentence>A verb V1 is the hyperonym ( respectively a hyponym ) of a verb V2 ( which is noted VI~-V2 , respectively VI- &lt; V2 ) if they share a common basic action and if , in the thematic relations structure associated with it , we have : * absence ( for the hyperonym ) or presence ( for the hyponym ) of a particular thematic relation : e.g. for the pair divide /cut ; to cut is to divide using a sharp instrument , thus divide ~cut • presence of a generic value thematic relation vs. a specific value ( example cut ( object is generic : solid object ~behead ( object is ahead ) ) For every verb : • the semantic description pointed out is coded in the lexical knowledge base as a definitional graph .</sentence>
				<definiendum id="0">verb V1</definiendum>
				<definiens id="0">the hyperonym ( respectively a hyponym ) of a verb V2 ( which is noted VI~-V2</definiens>
			</definition>
			<definition id="5">
				<sentence>'voler ( derober ) ' -- * ( Steal ( Agent ~ I Suj ; Objet -- * 1 '' Obj ) ) , Explanations : the first item between quotes is the Pred value , followed by a list of types of concepts ( or types of relations ) and their mapping definition structure in the F-Structure .</sentence>
				<definiendum id="0">Explanations</definiendum>
				<definiendum id="1">quotes</definiendum>
				<definiens id="0">followed by a list of types of concepts ( or types of relations</definiens>
			</definition>
			<definition id="6">
				<sentence>CORBA ( Common Object Request Broker Architecture ) ( Ben-Natan , 1995 ) , has been defined by the OMG as an interoperability norm for heterogeneous languages ( Smalltalk , C++ , JAVA ) and platforms ( UNIX , Macintosh , PC ) .</sentence>
				<definiendum id="0">CORBA ( Common Object Request Broker Architecture )</definiendum>
			</definition>
			<definition id="7">
				<sentence>CORBA defines a common interface definition language ( IDL ) , as well as a set of services ( naming service , security , concurrency management ... ) .</sentence>
				<definiendum id="0">CORBA</definiendum>
				<definiens id="0">defines a common interface definition language ( IDL ) , as well as a set of services ( naming service , security , concurrency management ... )</definiens>
			</definition>
</paper>

		<paper id="0710">
			<definition id="0">
				<sentence>, pcF , ~ , Fj ) Probablhty that sentence s m the source text m mcluded 111 ~lmmary S , given Its feature vvlues , compressmn rate ( constant ) , probablhty of feature-value pair occurnng m a sentence winch m m the summary , probabihty that the feature-value pair occurs uncon &amp; tzonally , • number of feature-valus pairs , j-th feature-value pair Aseummg statmtmal independence of the features , P ( ~ls E S ) and P ( Fj ) can be estnnated from the corpus Evaluatmn rches on ccross-vahdatmn The model m trmned on a training set of documents , having one document out at a tune ( the cu~ent test document ) The model is then used to extract can &amp; date sentences from the test document , allowing evaluation of precision ( sentences selected correctly over total number of sentences selected ) and recall ( sentences selected correctly over ahgnable sentences m summary ) Since from anygrven test text as many sentences are selected as there are ahgnable sentences m the summary , precamon and recall are always the same Kupiec et al reports that preasion of the m &amp; wdual hetmstles ranges between 20-33 % , the highest cumulative result ( 44 % ) was adaeved using para .</sentence>
				<definiendum id="0">P ( ~ls E S</definiendum>
				<definiens id="0">sentences selected correctly over total number of sentences selected ) and recall ( sentences selected correctly over ahgnable sentences m summary ) Since from anygrven test text as many sentences</definiens>
			</definition>
</paper>

		<paper id="0407">
			<definition id="0">
				<sentence>Given two strings x , y E X ' , xy denotes the concatenation of x and y. A Subsequential Transducer ( Berstel , 1979 ) is a deterministic finite state network that accepts sentences from a given input language and produces associated sentences of an output language .</sentence>
				<definiendum id="0">y. A Subsequential Transducer</definiendum>
				<definiens id="0">a deterministic finite state network that accepts sentences from a given input language and produces associated sentences of an output language</definiens>
			</definition>
			<definition id="1">
				<sentence>44 Formally , a SST is a tuple r = ( X , Y , Q , q0 , E , o- ) where X and 1 , '' are the input and output alphabets , Q is a finite set of states , qo E Q is the initial state , E E Q x X x Y '' x ~ is a set of arcs satisfying the determinism condition , and a : Q ~ Y '' is a state emission function 2 .</sentence>
				<definiendum id="0">SST</definiendum>
				<definiendum id="1">Q</definiendum>
				<definiens id="0">a tuple r = ( X , Y , Q , q0 , E , o- ) where X and 1 , '' are the input and output alphabets</definiens>
				<definiens id="1">a finite set of states , qo E Q is the initial state</definiens>
				<definiens id="2">a set of arcs satisfying the determinism condition</definiens>
			</definition>
			<definition id="2">
				<sentence>gories were defined , simple scripts substituted the words in the categories by adequate labels , so that the pair ( ddme la Have de la habitaci6n ciento veintitrds give me the key to room one two three ) became ( dime Is Uave de la habitaci6n $ ROOM give me the key to room SROOM ) , where $ ROOM is the category label for room numbers .</sentence>
				<definiendum id="0">ROOM</definiendum>
				<definiens id="0">simple scripts substituted the words in the categories by adequate labels</definiens>
			</definition>
			<definition id="3">
				<sentence>• LEXICAL LEVEL Spanish Phonetics allows the representation of each word as a sequence of phones that can be derived from standard rules .</sentence>
				<definiendum id="0">LEXICAL LEVEL Spanish Phonetics</definiendum>
				<definiens id="0">allows the representation of each word as a sequence of phones that can be derived from standard rules</definiens>
			</definition>
</paper>

		<paper id="1401">
			<definition id="0">
				<sentence>The Quickset system , which recognizes spoken and pen-based input to maps and has been modeled on the present simulation \ [ 16\ ] , was adapted to accept open-microphone speech for testing purposes .</sentence>
				<definiendum id="0">Quickset system</definiendum>
				<definiens id="0">recognizes spoken and pen-based input to maps and has been modeled on the present simulation</definiens>
			</definition>
			<definition id="1">
				<sentence>Pittman , J. , Cohen , P. , Smith , I. , Yang , T. &amp; Oviatt , S. Quickset : A multimodal interface for distributed interactive simulations , Proc .</sentence>
				<definiendum id="0">Quickset</definiendum>
				<definiens id="0">A multimodal interface for distributed interactive simulations</definiens>
			</definition>
</paper>

		<paper id="0621">
			<definition id="0">
				<sentence>\ ] Complexity this this line \ [ writln ( ' Hello ' ) ; \ ] Ct~i , _poi , ter * log ( n ) ( with pointer ) ( with pointer ) in in this line writln ( 'Hello ' ) ; Cm ( with pointer ) character character in this line \ [ w\ ] Jr\ ] \ [ i\ ] \ [ 1 ; \ ] \ [ 1\ ] In\ ] ... Cchar ( with pointer ) ordinal fifth character in this line \ [ i\ ] Cora * 5 ( with pointer ) the the fifth character in this line 1 Cart ( with pointer ) Figure 2 : The operator grammar generating syntax to select an item on the screen .</sentence>
				<definiendum id="0">Complexity</definiendum>
				<definiens id="0">with pointer ) character character in this line</definiens>
			</definition>
			<definition id="1">
				<sentence>The pointer complexity is also multiplied by log ( n ) where n is the number of items that are being distinguished from .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of items that are being distinguished from</definiens>
			</definition>
</paper>

		<paper id="0713">
			<definition id="0">
				<sentence>the data that reflected only one Importance level In the first Version we considered as being important the judgments with a score of 2 and unimportant the judgments with a score of 0 and 1 In the second version , we consdered as being important the judgments with a score of 2 and 1 and ummportant the judgments with a score of 0 EssenUally , we mapped the judgment matrices of each of the five texts rote matnces whose elements ranged over only two values 0 and 1 After these mod , ficauons were made , we computed for each version and each text the Cochran stausucs Q , winch approximates the X z &amp; stnbuuon w , th n 1 degrees of freedom , where n rs the number of elements m the dataset In all cases we obtmned probabflmes that were very low p &lt; 10 -6 Tins means that the agreement among judges was extremely slgmficant Although the probainhty was very low for both versions , it was lower for the first Vermon of the modflied data than for the second Tins means that , t is more rehable to consider as important only the units that were I I I • assigned a score of 2 by a majority of the judges As we have already menUoned , our ulumate goal was to detenmne whether there exists a correlauon between ~ the umts that judges find important and the umts that have nuclear status m the rhetorical structure trees of the same texts Since the percentage agreement for the umts that were consadered very important was higher than the percentage agreement for the mats that were consadered less amportant , and since the Cochran 's slgmficance computed for the first versaon of the mochfied data was Ingher that the one computed for the second , we decaded to consider the set of 36 textual umts labeled by a majority of judges wath 2 as a rehable reference set of importance umts for the five texts For example , umts 4 and 12 from text ( 1 ) belong to t/us reference set Agreement between analysts .</sentence>
				<definiendum id="0">Tins</definiendum>
				<definiens id="0">matnces whose elements ranged over only two values 0 and 1 After these mod , ficauons were made</definiens>
			</definition>
</paper>

		<paper id="1512">
			<definition id="0">
				<sentence>Specifier-based grammar partitions may be established along two basic dimensions illustrated in Figure 7 : along a vertical dimension , grammar partitions may be established according to different types of processing operations to apply ; lexical entries , for instances , may be specified to be applied during word segmentation ( = two-level based morphographemic analysis ) , during analysis ( = parsing ) , or during refinement only ( the operation of refinement will be explicated below ) .</sentence>
				<definiendum id="0">Specifier-based grammar partitions</definiendum>
				<definiens id="0">two-level based morphographemic analysis</definiens>
			</definition>
</paper>

		<paper id="0106">
			<definition id="0">
				<sentence>IOrl is the number of possible contexts and A is an interpolation coefficient .</sentence>
				<definiendum id="0">IOrl</definiendum>
				<definiens id="0">the number of possible contexts and A is an interpolation coefficient</definiens>
			</definition>
			<definition id="1">
				<sentence>Also let cs be the result label p ( e\ [ cl ) , p ( e\ [ c2 ) and p ( e\ ] c3 ) are probability distributions over contexts e of cl , c2 and ~ , respectively , p ( cl ) , p ( c2 ) and p ( c3 ) are estimated probabilities of cl , c2 and ca , respectively .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">distributions over contexts e of cl , c2 and ~ , respectively , p ( cl ) , p ( c2 ) and p ( c3 ) are estimated probabilities of cl , c2 and ca , respectively</definiens>
			</definition>
			<definition id="2">
				<sentence>DE '' = Consequence E~troFg Previous E~t~opy = pCc~ ) × ~p ( elc~ ) logp ( elc~ ) £ + pCcl ) × ~pCelcl ) logpCelcl ) + pCc2 ) × ~pCelc~ ) logpCe\ [ ~ ) e where ~ep ( elc/ ) log P ( elc/ ) is the total entropy over various contexts of label c~ .</sentence>
				<definiendum id="0">~ep</definiendum>
				<definiens id="0">the total entropy over various contexts of label c~</definiens>
			</definition>
			<definition id="3">
				<sentence>~Vhile a model of a simple probabilistic CFG applies the probability of a parse which is defined as the multiplication of the probability of all applied rules , however , for the purposes of our model where left and right contexts of a constituent are taken into account , the model estimates P ( T\ [ S ) by ass-m~-g that each rule are dependent not only on the occurrences of the rule but also on its left and right context as follow .</sentence>
				<definiendum id="0">S )</definiendum>
				<definiens id="0">a simple probabilistic CFG applies the probability of a parse which is defined as the multiplication of the probability of all applied rules</definiens>
				<definiens id="1">the model estimates P ( T\ [</definiens>
			</definition>
			<definition id="4">
				<sentence>l P ( TIS ) P ( r , ,c , ) I il I I I where r~ is an application rule in the tree and ~ is the left and right contexts at the place the rule is applied .</sentence>
				<definiendum id="0">r~</definiendum>
				<definiens id="0">an application rule in the tree and ~ is the left and right contexts at the place the rule is applied</definiens>
			</definition>
			<definition id="5">
				<sentence>• Positive Recall ( PLY ) : ~ • Positive Precision ( PP ) : ~ -- -- ~ • NeKative Recall ( l~t ) : • Negative Precision ( I~P ) : * F-measure ( FM ) • ( ~2+I ) ×PP×PR /32 ×PP+ P.R where a is the number of the label pairs which the WS3 corpus assigns in the same group and so does the system , 5 is the number of the pairs which the ~WSJ corpus does not assign in the same group but the system does , c is the number of the pairs which the WSJ assigned but the system does not , and d is the number of the pairs which both the WSJ and the system does not assign in the same group .</sentence>
				<definiendum id="0">Positive Recall</definiendum>
				<definiendum id="1">Positive Precision</definiendum>
				<definiendum id="2">Negative Precision</definiendum>
				<definiens id="0">the number of the label pairs which the WS3 corpus assigns in the same group</definiens>
				<definiens id="1">the number of the pairs which the ~WSJ corpus does not assign in the same group but the system does , c is the number of the pairs which the WSJ assigned but the system does not , and d is the number of the pairs which both the WSJ and the system does not assign in the same group</definiens>
			</definition>
</paper>

		<paper id="0209">
			<definition id="0">
				<sentence>The prior distribution PrR ( c ) captures the probability of a class occurring as the argument in predicate-argument relation R , regardless of the identity of the predicate .</sentence>
				<definiendum id="0">prior distribution PrR ( c )</definiendum>
				<definiens id="0">captures the probability of a class occurring as the argument in predicate-argument relation R , regardless of the identity of the predicate</definiens>
			</definition>
			<definition id="1">
				<sentence>Information theory provides an appropriate way to quantify the difference between the prior and posterior distributions , in the form of relative entropy ( Kullback and Leibler , 1951 ) .</sentence>
				<definiendum id="0">Information theory</definiendum>
				<definiendum id="1">relative entropy</definiendum>
				<definiens id="0">provides an appropriate way to quantify the difference between the prior and posterior distributions</definiens>
			</definition>
			<definition id="2">
				<sentence>Intuitively , SR ( p ) measures how much information , in bits , predicate p provides about the conceptual class of its argument .</sentence>
				<definiendum id="0">SR ( p )</definiendum>
			</definition>
			<definition id="3">
				<sentence>Formally , given a predicate-argument relationship R ( for example , the verb-object relationship ) , a predicate p , and a conceptual class c , ~'~ count ( p , w ) freqR ( p , c ) ~ ~ ~ ' tvEc where countR ( p , w ) is the number of times word w was observed as the argument of p with respect to R , and classes ( w ) is the number of taxonomic classes to which w belongs .</sentence>
				<definiendum id="0">w )</definiendum>
				<definiens id="0">given a predicate-argument relationship R ( for example , the verb-object relationship ) , a predicate p , and a conceptual class c</definiens>
				<definiens id="1">the number of taxonomic classes to which w belongs</definiens>
			</definition>
</paper>

		<paper id="1104">
			<definition id="0">
				<sentence>The /a/ vowel is an automatic consequence of a back constriction associated with a front cavity , and , the/i/vowel of a front constriction associated with a back cavity ( anti-symmetrical behavior ) , a pharynx cavity , thus , being automatically obtained .</sentence>
				<definiendum id="0">/a/ vowel</definiendum>
				<definiens id="0">an automatic consequence of a back constriction associated with a front cavity , and , the/i/vowel of a front constriction associated with a back cavity ( anti-symmetrical behavior ) , a pharynx cavity</definiens>
			</definition>
</paper>

		<paper id="0201">
			<definition id="0">
				<sentence>The Penn Treebank corpus contains a sufficient number of partof-speech tagged and syntactically parsed sentences to serve as adequate training material for building broad coverage part-of-speech taggers and parsers .</sentence>
				<definiendum id="0">Penn Treebank corpus</definiendum>
				<definiens id="0">contains a sufficient number of partof-speech tagged and syntactically parsed sentences to serve as adequate training material for building broad coverage part-of-speech taggers and parsers</definiens>
			</definition>
			<definition id="1">
				<sentence>Information retrieval ( IR ) is a practical NLP task where WSD has brought about improvement in accuracy .</sentence>
				<definiendum id="0">Information retrieval</definiendum>
				<definiendum id="1">IR</definiendum>
				<definiens id="0">a practical NLP task where WSD has brought about improvement in accuracy</definiens>
			</definition>
			<definition id="2">
				<sentence>BC50 consists of 7,119 occurrences of the 191 words that occur in 50 text files of the Brown corpus .</sentence>
				<definiendum id="0">BC50</definiendum>
			</definition>
			<definition id="3">
				<sentence>WordNet : An on-line lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An on-line lexical database</definiens>
			</definition>
</paper>

		<paper id="0609">
			<definition id="0">
				<sentence>In what follows , we first explicate how information from the accoustic level ( e.g. , the presence of certain kinds of background noise from a radio ) enables better system performance .</sentence>
				<definiendum id="0">accoustic level</definiendum>
				<definiens id="0">the presence of certain kinds of background noise from a radio ) enables better system performance</definiens>
			</definition>
</paper>

		<paper id="0617">
			<definition id="0">
				<sentence>Several web sites permit database queries where the user types in the search constraints on an HTML FORM and the server submits this form to the CGI script which generates a response after searching a local database .</sentence>
				<definiendum id="0">CGI script</definiendum>
				<definiens id="0">generates a response after searching a local database</definiens>
			</definition>
			<definition id="1">
				<sentence>The lower level dialogue states in this sub-dialogue could be • VERIFY_ USER : which asks for the user 's account ID and password , • SIDE_EFFECTS : which informs the user of some side effects of the imposed constraints , e.g. `` This transaction will lead to a negative balance in the checking account , '' or • some other domain-specific state depending upon the nature of the action involved .</sentence>
				<definiendum id="0">VERIFY_ USER</definiendum>
				<definiens id="0">asks for the user 's account ID and password , • SIDE_EFFECTS : which informs the user of some side effects of the imposed constraints</definiens>
			</definition>
			<definition id="2">
				<sentence>DATABASE_CONFLICT : A database conflict arises when the constraints specified by the user do not match any item in the database .</sentence>
				<definiendum id="0">DATABASE_CONFLICT</definiendum>
				<definiens id="0">A database conflict arises when the constraints specified by the user do not match any item in the database</definiens>
			</definition>
			<definition id="3">
				<sentence>• Extensibility : Additional queries can be added to any application by specifying the query semantics in the application schema and any new fields that they may need .</sentence>
				<definiendum id="0">Additional queries</definiendum>
				<definiens id="0">any application by specifying the query semantics in the application schema and any new fields that they may need</definiens>
			</definition>
			<definition id="4">
				<sentence>The system is designed to generate either SQL queries or CGI script queries , which makes it capable of querying the vast amount of information available on the World Wide Web .</sentence>
				<definiendum id="0">CGI script queries</definiendum>
			</definition>
</paper>

		<paper id="1201">
			<definition id="0">
				<sentence>Prosody , therefore , is an important part of the route from meaning to speech .</sentence>
				<definiendum id="0">Prosody</definiendum>
				<definiens id="0">an important part of the route from meaning to speech</definiens>
			</definition>
			<definition id="1">
				<sentence>Acoustic/Prosody/Concept Relationships If the task of automatic speech synthesis can be framed as that of selecting the most probable acoustic production associated with a text string annotated for intended meaning , it can be achieved by finding ar gmaxxp ( x\ ] meaning ) .</sentence>
				<definiendum id="0">Acoustic/Prosody/Concept Relationships</definiendum>
				<definiens id="0">text string annotated for intended meaning , it can be achieved by finding ar gmaxxp ( x\ ] meaning )</definiens>
			</definition>
			<definition id="2">
				<sentence>/~acb data token ( a word pair ) is shunted along a path from the root to a leaf node .</sentence>
				<definiendum id="0">/~acb data token</definiendum>
				<definiens id="0">a word pair ) is shunted along a path from the root to a leaf node</definiens>
			</definition>
</paper>

		<paper id="1208">
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>Words consist of a stem and a sequence of suffixes .</sentence>
				<definiendum id="0">Words</definiendum>
				<definiens id="0">consist of a stem and a sequence of suffixes</definiens>
			</definition>
</paper>

		<paper id="0501">
			<definition id="0">
				<sentence>, u. } • I r participati°n L in activities 1 { independence } I quality 1 of life • fulfilment Figure 1 : A model linking AAC design approaches , pragmatic features of conversation and user goals tionalist is either speaking or listening .</sentence>
				<definiendum id="0">user goals tionalist</definiendum>
				<definiens id="0">A model linking AAC design approaches , pragmatic features of conversation and</definiens>
			</definition>
</paper>

		<paper id="0126">
			<definition id="0">
				<sentence>The filtering process calculates the probabilities of all possible chains of tagged words using a Markov Model .</sentence>
				<definiendum id="0">filtering process</definiendum>
				<definiens id="0">calculates the probabilities of all possible chains of tagged words using a Markov Model</definiens>
			</definition>
			<definition id="1">
				<sentence>Therefore , the Word Filtering , also , includes the scanning process that detect and correct these errors .</sentence>
				<definiendum id="0">Word Filtering</definiendum>
				<definiens id="0">includes the scanning process that detect</definiens>
			</definition>
			<definition id="2">
				<sentence>ai morphological analysis consists of three steps : sentence segmenting , spell checking and word ill , ring .</sentence>
				<definiendum id="0">ai morphological analysis</definiendum>
				<definiens id="0">consists of three steps : sentence segmenting , spell checking and word ill , ring</definiens>
			</definition>
			<definition id="3">
				<sentence>*A Statistical Approach to Thai Morphological Analyzer is a part of WPA ( Writing Production Assistant ) Project supported by the National Research Council of Thailand .</sentence>
				<definiendum id="0">Morphological Analyzer</definiendum>
				<definiens id="0">a part of WPA ( Writing Production Assistant ) Project supported by the National Research Council of Thailand</definiens>
			</definition>
			<definition id="4">
				<sentence>A computalional model consists of word segmenting , spelling checking and word filtering processes is proposed to handle the morphological problems mentioned earlier .</sentence>
				<definiendum id="0">computalional model</definiendum>
				<definiens id="0">consists of word segmenting , spelling checking and word filtering processes is proposed to handle the morphological problems mentioned earlier</definiens>
			</definition>
			<definition id="5">
				<sentence>A Trigram Model \ [ CHAR 93\ ] is utilized to calculate the probabilities of word cluster , i.e. how the previous two words affects the probabilities of next word .</sentence>
				<definiendum id="0">Trigram Model</definiendum>
				<definiens id="0">utilized to calculate the probabilities of word cluster</definiens>
			</definition>
			<definition id="6">
				<sentence>I I I I i I i I I I i , :i I I I I i I I I I I _/ i \ In order to estimate the probability of J~w , lw , _~ , ,_ , ) in ( 1 ) , the following equation is used : where PeO0 is the estimated probability for Xbased on some count C : So to estimate the probability of w , appear after `` w ; .</sentence>
				<definiendum id="0">_~</definiendum>
				<definiendum id="1">PeO0</definiendum>
				<definiens id="0">the probability of J~w , lw ,</definiens>
				<definiens id="1">the estimated probability for Xbased on some count C : So to estimate the probability of w</definiens>
			</definition>
</paper>

		<paper id="1410">
			<definition id="0">
				<sentence>Figure 2 presents the formal criterion for a set of components to be characteristic components of a given side s. The variable , S denotes a set of other sides of the given object .</sentence>
				<definiendum id="0">S</definiendum>
			</definition>
			<definition id="1">
				<sentence>01 and 02 ( i.e. indistinguishable ( Ol , 02 ) is false for arbitrary components 01 and 02 ) , every component is a characteristic component for the side on which it is located .</sentence>
				<definiendum id="0">component</definiendum>
			</definition>
			<definition id="2">
				<sentence>Navigational , or 76 K. Hartmann and J. SchSpp attention-directing information , is intended to bring the referent in the hearer 's focus of attention \ [ while\ ] discriminating information is intended to distinguish the intended referent from other objects in the hearer 's focus of attention '' .</sentence>
				<definiendum id="0">Navigational</definiendum>
				<definiens id="0">intended to bring the referent in the hearer 's focus of attention \ [ while\ ] discriminating information is intended to distinguish the intended referent from other objects in the hearer 's focus of attention ''</definiens>
			</definition>
</paper>

		<paper id="0619">
			<definition id="0">
				<sentence>The Alparon project aims to improve Vxos , Openbaar Vervoer Reisinformatie 's ( OVa ) automated speech processing system for public transport information , by using a corpus-based approach .</sentence>
				<definiendum id="0">Alparon project</definiendum>
				<definiens id="0">aims to improve Vxos , Openbaar Vervoer Reisinformatie 's ( OVa ) automated speech processing system for public transport information</definiens>
			</definition>
			<definition id="1">
				<sentence>The pilot corpus consists of dialogues that concern the exchange of train information only .</sentence>
				<definiendum id="0">pilot corpus</definiendum>
				<definiens id="0">consists of dialogues that concern the exchange of train information only</definiens>
			</definition>
			<definition id="2">
				<sentence>VIos is a Dutch version of the train timetable information system developed by Philips Aachen for the Deutsche Bundesbahn ( Aust and Oerder , 1995 ; Aust et al. , 1995 ) .</sentence>
				<definiendum id="0">VIos</definiendum>
				<definiendum id="1">Bundesbahn</definiendum>
				<definiens id="0">a Dutch version of the train timetable information system developed by Philips Aachen for the Deutsche</definiens>
			</definition>
			<definition id="3">
				<sentence>OVR is a partner in both MAIS and ARISE .</sentence>
				<definiendum id="0">OVR</definiendum>
				<definiens id="0">a partner in both MAIS and ARISE</definiens>
			</definition>
			<definition id="4">
				<sentence>human-human OVR dialogues A study of a sample of 100 information dialogues out of a corpus of over 5000 dialogues shows that the presentation of a travel plan in a human-human dialogue involves more than just a monologue that presents the entire plan at once .</sentence>
				<definiendum id="0">human-human dialogue</definiendum>
				<definiens id="0">involves more than just a monologue that presents the entire plan at once</definiens>
			</definition>
			<definition id="5">
				<sentence>The information transfer in an OVR dialogue consists of three phases : During the query phase the caller poses his query , and the information service tries to understand this query as clear as possible .</sentence>
				<definiendum id="0">information transfer</definiendum>
				<definiens id="0">During the query phase the caller poses his query</definiens>
			</definition>
			<definition id="6">
				<sentence>A reconfirmation sequence consists of a reconfirm by the caller and an appropriate answer by the information service .</sentence>
				<definiendum id="0">reconfirmation sequence</definiendum>
				<definiens id="0">consists of a reconfirm by the caller and an appropriate answer by the information service</definiens>
			</definition>
			<definition id="7">
				<sentence>A clarification sequence consists of a whquestion of the caller and an appropriate answer by the information service .</sentence>
				<definiendum id="0">clarification sequence</definiendum>
				<definiens id="0">consists of a whquestion of the caller and an appropriate answer by the information service</definiens>
			</definition>
			<definition id="8">
				<sentence>A checking sequence consists of a check by the caller and an appropriate answer by the information service .</sentence>
				<definiendum id="0">checking sequence</definiendum>
				<definiens id="0">consists of a check by the caller and an appropriate answer by the information service</definiens>
			</definition>
			<definition id="9">
				<sentence>A correcting sequence consists of a correction and possibly a negative 110 acknowledgement by the caller and an appropriate answer by the information service .</sentence>
				<definiendum id="0">correcting sequence</definiendum>
				<definiens id="0">consists of a correction and possibly a negative 110 acknowledgement by the caller and an appropriate answer by the information service</definiens>
			</definition>
			<definition id="10">
				<sentence>The text generator will have to choose the right linguistic form , following Table 7 : An example of a scenario Information given by the query phase : Information given by the database query : Scenario : Possible linguistic form : Departure place , arrival place , and a global indication of the departure or arrival time One train connection with one change , exact departure times , exact arrival times , place of change which is the same as the direction of the train , the direction of the second train is the same as the arrival place Departure_Time ( new ) -Departure_Place ( given ) , Arrival_Time ( new ) -Place_of_Change ( new ) , Place_oLChange ( given ) -Departure_Time ( new ) -Arrival_Place ( given ) , Arrival_Place ( given ) -Arrival_Time ( new ) .</sentence>
				<definiendum id="0">arrival place Departure_Time</definiendum>
				<definiendum id="1">new ) -Place_of_Change</definiendum>
				<definiens id="0">An example of a scenario Information given by the query phase : Information given by the database query : Scenario : Possible linguistic form : Departure place , arrival place , and a global indication of the departure or arrival time One train connection with one change , exact departure times</definiens>
			</definition>
</paper>

		<paper id="0116">
			<definition id="0">
				<sentence>154 Example SF Description PP\ [ auf\ ] V\ [ warten\ ] 'wait for ' Verb with PP PP\ [ an\ ] NPA V\ [ erlnnern\ ] 'remind NP of ' Verb with accusative object and PP PP\ [ fiir\ ] NPD V\ [ danken\ ] 'thauk NP for ' Verb with dative object and PP PP\ [ auf\ ] sich V\ [ vorbereiten\ ] 'to prepare oneself for ' reflexive verb with PP PP\ [ auf\ ] N\ [ Hoffmtmg\ ] 'hope for ' Noun with PP PP\ [ auf\ ] A\ [ stolz\ ] 'proud of '' Adjective with PP Figure 1 : Subcategorization flames learned by the system b. *Mary denkt an es .</sentence>
				<definiendum id="0">Subcategorization</definiendum>
				<definiens id="0">flames learned by the system b. *Mary denkt an es</definiens>
			</definition>
			<definition id="1">
				<sentence>The internal structure of the clause pair consists of phrase-like constituents ; these include nominative ( NC ) ~ prepositional ( PC ) , adjectival ( AC ) , verbal ( VC ) , and clausal constituents .</sentence>
				<definiendum id="0">clause pair</definiendum>
				<definiens id="0">consists of phrase-like constituents ; these include nominative ( NC ) ~ prepositional ( PC ) , adjectival ( AC ) , verbal ( VC ) , and clausal constituents</definiens>
			</definition>
			<definition id="2">
				<sentence>( In the following , p denotes the preposition within the pronomlnal adverb 156 I I I I , I I I i I I I I in a correlative construct main clause , VC the main verbal constituent in the clause ; v in VC\ [ v\ ] denotes the head Iemm~ of the verbal constituent , analogously for NC\ [ n\ ] . )</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">VC</definiendum>
				<definiendum id="2">v</definiendum>
				<definiens id="0">the main verbal constituent in the clause ;</definiens>
			</definition>
			<definition id="3">
				<sentence>( 7 ) a. Mary erinnert ihren Freund daran , daB ... Mary reminds her friend on it that 'Mary reminds her friend of the fact that ... ' b. Mary nimmt keine Rficksicht darauf , daft ... Mary takes no consideration on it that 'Mary shows no consideration for the fact that ... ' Copula/NCl\ [ nl\ ] /NC2\ [ n2\ ] .</sentence>
				<definiendum id="0">daft ... Mary</definiendum>
			</definition>
			<definition id="4">
				<sentence>For instance , with this rule the clause in ( 9 ) is mapped to { PP\ [ auf\ ] A\ [ stolz\ ] , PP\ [ auf\ ] N\ [ Student\ ] } ( 9 ) Stolz ist der Student darauf , da6 ... proud is the student on it that 'The student is proud of the fact that ... ' PCs .</sentence>
				<definiendum id="0">proud</definiendum>
			</definition>
			<definition id="5">
				<sentence>For instance , ( 11 ) is mapped with the VC/NC and Morphology rules to { PP\ [ an\ ] V\ [ denken\ ] , PP\ [ an\ ] V\ [ gedenken\ ] } , since g~acht is the past participle of both the verbs nken ( 'to think ' ) and g~enken ( 'to consider ' ) .</sentence>
				<definiendum id="0">g~acht</definiendum>
				<definiens id="0">mapped with the VC/NC and Morphology rules to { PP\ [ an\ ] V\ [ denken\ ] , PP\ [ an\ ] V\ [ gedenken\ ] }</definiens>
			</definition>
			<definition id="6">
				<sentence>The EM algorithm ( Dempster , Laird , and Rubin , 1977 ) is a general iterative method to obtain maximum likelihood estimators in incomplete data situations .</sentence>
				<definiendum id="0">EM algorithm</definiendum>
				<definiens id="0">a general iterative method to obtain maximum likelihood estimators in incomplete data situations</definiens>
			</definition>
			<definition id="7">
				<sentence>go ( X ) ) XE8 Step k + 1 ( k &gt; = 0 ) : Ck+l ( Z ) = ek ( Z ) `` tE ( Pk ( z , X ) `` ge ( X ) ) xE $ Where ge is a ftmetion from S to the natural n-tubers mapping a set X to the number of times it was produced by the SF mapping for a given corpus C. Fm-ther , I , Pk , and Pk are run .</sentence>
				<definiendum id="0">ge</definiendum>
				<definiens id="0">a ftmetion from S to the natural n-tubers mapping a set X to the number of times it was produced by the SF mapping for a given corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>In the formulae above , kl is k ( L S ) , nl is the total number of occurrences of S , k2 is/c ( L S ) , and n2 the total number of occurrences of structures other than S. A large value of -2 log A for a lemma L and structure S m~n~ that the outcome is such that the hypothesis that the two distributions have the same underlying parameter is , mllicely , and that a lemm~ L is highly associated with a structure S in a given corpus .</sentence>
				<definiendum id="0">nl</definiendum>
				<definiens id="0">the total number of occurrences of S</definiens>
			</definition>
</paper>

		<paper id="0602">
			<definition id="0">
				<sentence>However , 'Din10 logue Management ' is a high-level linguistic concept which can not be measured so straightforwardly for several reasons : existing DMSs are very domain-specific , and we need to compare dialogue systems across domains ; so it makes no sense to look for a common standard 'test corpus ' ; the boundary between 'good ' and 'bad ' dialogue is very ill-defined , so it makes little sense to try to assess against a target 'correct output ' , or even by subjective assessment of 'pleasantness ' of output ; the structure of dialogue ( and hence a DMS ) is complex , multi-level , and non-algorithmic , making a single overall 'evaluation metric ' meaningless without consideration of component behaviours ; we need to evaluate the integrated system holistically , as opposed to measuring speed or accuracy of individual components ; alternative dialogue systems use a wide range of alternative component technologies ; only by fitting these against a generic template can we discriminate between superficial and substantive differences in component assumptions and functionalities .</sentence>
				<definiendum id="0">alternative dialogue systems</definiendum>
				<definiens id="0">very ill-defined , so it makes little sense to try to assess against a target 'correct output '</definiens>
			</definition>
			<definition id="1">
				<sentence>Consider ( Churcher et al 1997 ) , which included a first attempt at an outline of a generic spoken language system .</sentence>
				<definiendum id="0">Consider</definiendum>
				<definiens id="0">included a first attempt at an outline of a generic spoken language system</definiens>
			</definition>
</paper>

		<paper id="0405">
			<definition id="0">
				<sentence>Spoken utterances consist of larger portions of fully-lexicalized or semi-lexicalized morpheme sequences , the use of which greatly contributes to sounding natural and native-like , but whose meanings are not totally predicatable from their forms ( Pawley and Syder , 1983 ) .</sentence>
				<definiendum id="0">Spoken utterances</definiendum>
			</definition>
			<definition id="1">
				<sentence>The system architecture separates general linguistic knowledge , domain knowledge , and transfer knowledge .</sentence>
				<definiendum id="0">system architecture</definiendum>
			</definition>
			<definition id="2">
				<sentence>In hybrid analogical translation , the use of a morphological and syntactic module for shallow analysis to derive a linguistic representation with syntactic and lexical features allows us to handle phenomena such as inflections , transformations , and languagespecific phenomena ( such as the English determiner system and certain Japanese constructions that encode politeness information ) in a linguistically efficient manner .</sentence>
				<definiendum id="0">languagespecific phenomena</definiendum>
				<definiens id="0">certain Japanese constructions that encode politeness information</definiens>
			</definition>
			<definition id="3">
				<sentence>Analogical Matching When applied to spoken language , the central step in analogical translation is a robust matching Step that compares the output of the speech recognition component with the contents of the example database .</sentence>
				<definiendum id="0">Analogical Matching When</definiendum>
				<definiens id="0">applied to spoken language , the central step in analogical translation is a robust matching Step that compares the output of the speech recognition component with the contents of the example database</definiens>
			</definition>
			<definition id="4">
				<sentence>This distance is defined by the following recurrence : f D ( p-t , n-t ) , logP ( echo ( ewp ) ) J D ( p , n-1 ) -logP ( add ( iw~ ) ) D ( p , n ) =min ~ D ( p-l , n ) -logP ( delete ( ew~ ) ) I , D ( p-l , n-1 ) -logP ( alter ( ewp .</sentence>
				<definiendum id="0">logP ( echo</definiendum>
				<definiendum id="1">n ) -logP ( delete</definiendum>
				<definiens id="0">the following recurrence : f D ( p-t , n-t )</definiens>
			</definition>
			<definition id="5">
				<sentence>A thesaurus is a semantic IA-A hierarchy whose nodes are semantic categories , and whose leaves are words .</sentence>
				<definiendum id="0">thesaurus</definiendum>
				<definiens id="0">a semantic IA-A hierarchy whose nodes are semantic categories , and whose leaves are words</definiens>
			</definition>
</paper>

		<paper id="0101">
</paper>

		<paper id="1407">
			<definition id="0">
				<sentence>Basho ( meaning 'location ' ) and 3ikoku ( meaning 'time ' ) input forms indicate the list of locations and the list of times , from which we select one value for each as query terms .</sentence>
				<definiendum id="0">Basho</definiendum>
				<definiens id="0">meaning 'time ' ) input forms indicate the list of locations and the list of times</definiens>
			</definition>
			<definition id="1">
				<sentence>Dousa ( meaning 'action ' ) input form indicates the list of verbs .</sentence>
				<definiendum id="0">Dousa</definiendum>
			</definition>
</paper>

		<paper id="0403">
			<definition id="0">
				<sentence>Each spoken utterance thus usually carries a large portion of what ( Traugolf , 1982 ) calls the expressive component , which expresses the speaker 's attitude toward the proposition , toward the interlocutor , and toward the speech situation .</sentence>
				<definiendum id="0">expressive component</definiendum>
				<definiens id="0">expresses the speaker 's attitude toward the proposition</definiens>
			</definition>
			<definition id="1">
				<sentence>Utterance strategies range from grammatically-encoded information to extra-linguistic devices such as facial expressions and body language , to natural speech properties ( Figure 1 ) .</sentence>
				<definiendum id="0">Utterance strategies</definiendum>
			</definition>
</paper>

		<paper id="0401">
			<definition id="0">
				<sentence>Although we have not performed large-scale frequency tests , some initial counts suggest that a typical dialogue from the VERBMOBIL corpus , which consists of about 15 turns , contains 20 to 30 occurrences of such particles .</sentence>
				<definiendum id="0">VERBMOBIL corpus</definiendum>
				<definiens id="0">consists of about 15 turns , contains 20 to 30 occurrences of such particles</definiens>
			</definition>
			<definition id="1">
				<sentence>( Eschborn is a smaller town neighbouring Frankfurt ) .</sentence>
				<definiendum id="0">Eschborn</definiendum>
			</definition>
			<definition id="2">
				<sentence>Summarizing the examples given above , a particle can have • a `` literal '' lexical translation , where semantics ( truth conditions ) is relevant ( there can still be ambiguity between several sentential readings ) , * a `` non-literal '' lexical translation , where pragmatic intent is relevant ( again , there can be ambiguity between several discourse readings ) , • a non-lexical translation , i.e. , it is rendered by a syntactic or intonation feature , • a zero translation .</sentence>
				<definiendum id="0">semantics</definiendum>
				<definiendum id="1">pragmatic intent</definiendum>
				<definiens id="0">relevant ( there can still be ambiguity between several sentential readings</definiens>
			</definition>
			<definition id="3">
				<sentence>While English often uses verbs for these purposes , German also offers a range of particles for speakers to convey a POSITIVE ( example : gem ) , NEGATIVE ( example : leider ) , or INDIFFERENT ( example : ruhig ) attitude towards the propositional content in their utterance , or towards the last utterance of the dialogue partner .</sentence>
				<definiendum id="0">INDIFFERENT</definiendum>
				<definiens id="0">the propositional content in their utterance , or towards the last utterance of the dialogue partner</definiens>
			</definition>
</paper>

		<paper id="0804">
			<definition id="0">
				<sentence>Example : hmp is a troponym of ( or a special way to perform ) walk , and snore is an entailment of sleep , if simulated snoring is not snoring .</sentence>
				<definiendum id="0">hmp</definiendum>
				<definiendum id="1">snore</definiendum>
				<definiens id="0">a troponym of ( or a special way to perform</definiens>
			</definition>
			<definition id="1">
				<sentence>antosemy The WordNet antonymy relation is a lexical relation , i.e. a relation between synset elements of different synsets \ [ Miller et aL , 1993\ ] .</sentence>
				<definiendum id="0">WordNet antonymy relation</definiendum>
			</definition>
			<definition id="2">
				<sentence>Coming across other perhaps more harmful cases ( see below Figure 12 and Figure 13 ) of a concept which is to be represented as a disjunction of concepts and itself a lexical gap , we now suggest that the constellation of Figure 8 was intended to say : arzse \ [ 3\ ] is an antosem of the one concept sit down \ [ 2\ ] or he down .</sentence>
				<definiendum id="0">]</definiendum>
				<definiens id="0">a disjunction of concepts</definiens>
			</definition>
</paper>

		<paper id="0706">
			<definition id="0">
				<sentence>Evaluauon is a key part of any research and development effort , but the goals and focus of evaluat : ons are often narrow m scope , addressing a specific algonthm or technique , or analyzing a single result All of the evaluation work clone to date on text summarization systems has been by the developers of mdlvldual systems , usually to study and improve sentence selection cntena Under TIPSTER III , DARPA ~s sponsoring a task-based evaluauon of multiple text summarization systems This focus of this evaluation wall be on user needs , and the feaslbdlty of applying summarization technology to a variety of tasks The explosion of on-lme textual matenal and the advances m text .</sentence>
				<definiendum id="0">Evaluauon</definiendum>
				<definiens id="0">a key part of any research and development effort</definiens>
			</definition>
			<definition id="1">
				<sentence>Pro Intent Inchcauve IndlcaUve Focus Genenc User-dn'ected Coverage Smgle document Single document appropriate category relevant to topic measures Ume accuracy umo accuracy ) osed Evaluation learned that then '' summaries were effecuve enough to support accurate retrieval Full text summanzauon as a major task an TIPSTER Phase HI TIPSTER Phase I sponsored research an reformation extracUon and reformation retrieval , and supported the Message Understanding Conferences ( MUC ) .</sentence>
				<definiendum id="0">Pro Intent Inchcauve IndlcaUve Focus Genenc User-dn'ected Coverage</definiendum>
				<definiens id="0">Smgle document Single document appropriate category relevant to topic measures Ume accuracy umo accuracy ) osed Evaluation learned that then '' summaries were effecuve enough to support accurate retrieval Full text summanzauon as a major task an TIPSTER Phase HI TIPSTER Phase I sponsored research an reformation extracUon and reformation retrieval</definiens>
			</definition>
			<definition id="2">
				<sentence>Literature Abstracts by Computer Techmques and Prospects Informatwn Processmg and Management , 26 ( 1 ) 171-186 Chris D Pmce and Paul A Jones 1993 The Idenuficatlon of Important Concepts m I-hghly Structured Teehmcal Papers SIGIR '93 , pages 69-77 G J Rath , A Restock , and T R Savage 1961 The FormaUon of Abstract by the Seleclaon of Sentences American Documentatwn , pages 139-143 U Relraer and U Hahn 1988 Text Condensation as a Knowledge Base Abstractton IEEE Conference on AI Apphcatwns , pages 338-344 Tomek Strzalkowski 1996 Robust Natural Language Processmg and User-Graded Concept Discovery for Information Retrieval , Extraction , and Surnmanzatlon Tipster Phase III In T/PSTER Text Phase III Ktckoff Workshop , Columbin , Maryland , October Beth Sundhesm 1995 Overview of Results of the MUC-6 Evaluauon In Sooth Message Understandmg Conference ( MUC-6 ) , pages 13-31 , Columbm , Maryland Sarah Taylor 1996 TIPSTER Text Program Overwew In TIPSTER Text Phase 11 , Tysons Corner , V~rgmm</sentence>
				<definiendum id="0">Literature Abstracts</definiendum>
				<definiens id="0">a Knowledge Base Abstractton IEEE</definiens>
			</definition>
</paper>

		<paper id="0304">
			<definition id="0">
				<sentence>Furthermore , Hearst 's approach segments at the paragraph level , which may be too coarse for applications like information retrieval on transcribed or automatically recognized spoken documents , in which paragraph boundaries are not known .</sentence>
				<definiendum id="0">paragraph level</definiendum>
			</definition>
			<definition id="1">
				<sentence>In contrast to Hearst 's focus on strict repetition , Kozima uses a semantic network to provide knowledge about related word pairs .</sentence>
				<definiendum id="0">Kozima</definiendum>
				<definiens id="0">uses a semantic network to provide knowledge about related word pairs</definiens>
			</definition>
			<definition id="2">
				<sentence>Kozima generalizes lexical cohesiveness to apply to a window of text , and plots the cohesiveness of successive text windows in a document , identifying the valleys in the measure as segment boundaries .</sentence>
				<definiendum id="0">Kozima</definiendum>
				<definiens id="0">generalizes lexical cohesiveness to apply to a window of text , and plots the cohesiveness of successive text windows in a document , identifying the valleys in the measure as segment boundaries</definiens>
			</definition>
			<definition id="3">
				<sentence>Another model was constructed on the Broadcast News corpus ( BN ) , made up of approximately 150 million words ( four and a half years ) of transcripts of various news broadcasts , including CNN news , political roundtables , NPR broadcasts , and interviews .</sentence>
				<definiendum id="0">NPR</definiendum>
				<definiens id="0">constructed on the Broadcast News corpus ( BN ) , made up of approximately 150 million words ( four and a half years</definiens>
			</definition>
			<definition id="4">
				<sentence>Another approach , using maximum entropy methods , introduces a parameter for trigger pairs of mutually informative words , so that the occurrence of certain words in recent context boosts the probability of the words that they trigger ( Lau , Rosenfeld , and Roukos , 1993 ) .</sentence>
				<definiendum id="0">maximum entropy methods</definiendum>
				<definiens id="0">introduces a parameter for trigger pairs of mutually informative words</definiens>
			</definition>
			<definition id="5">
				<sentence>We then build a family of conditional exponential models of the general form pexp ( W I H ) = Z ( H ) exp Aifi ( H , w ) Ptri ( W I w-2 , w-1 ) where H~ W-N , W-N+l , ... , w-x is the word history ( the N words preceding w in the text ) , and Z ( H ) is the normalization constant Z ( H ) = w EI , 'V 37 ( $ , t ) e A RESIDUES , CARCINOGENS 2.3 CHARLESTON , SHIPYARDS 4.0 MICROSCOPIC , CUTICLE 4.1 DEFENSE , DEFENSE 8.4 TAX , TAX 10.5 KURDS , ANKARA 14.8 VLADIMIR , GENNADY 19.6 STEVE , STEVE 20.7 EDUCATION , EDUCATION 22.2 MUSIC , MUSIC 22.4 INSURANCE , INSURANCE 23.0 PULITZER , PRIZEWINNING 23.6 YELTSIN , YELTSIN 23.7 RUSSIAN , RUSSIAN 26 .</sentence>
				<definiendum id="0">w-x</definiendum>
				<definiens id="0">a family of conditional exponential models of the general form pexp ( W I H ) = Z</definiens>
				<definiens id="1">the word history ( the N words preceding w in the text )</definiens>
				<definiens id="2">the normalization constant Z ( H ) = w EI</definiens>
			</definition>
			<definition id="6">
				<sentence>In general , the cache consists of content words s which promote the probability of their mate t , and correspondingly demote the probability of other words .</sentence>
				<definiendum id="0">cache</definiendum>
				<definiens id="0">consists of content words s which promote the probability of their mate t , and correspondingly demote the probability of other words</definiens>
			</definition>
			<definition id="7">
				<sentence>The statistics were collected over the roughly seven million words of mixed broadcast news and Reuters data comprising the TDT corpus ( see Section 5 ) .</sentence>
				<definiendum id="0">TDT corpus</definiendum>
				<definiens id="0">collected over the roughly seven million words of mixed broadcast news and Reuters data comprising the</definiens>
			</definition>
			<definition id="8">
				<sentence>To cast the problem of determining segment boundaries in statistical terms , we set as our goal the construction of a probability distribution q ( b i w ) , where b E { YES , NO } is a random variable describing the presence of a segment boundary in context w. We consider distributions in the linear exponential family Q ( f , qo ) given by { 1 } Q ( f , qo ) -q ( bloJ ) Zx~w ) e x't ( '° ) q0 ( blw ) where q0 ( blw ) is a prior or default distribution on the presence of a boundary , and Af ( w ) is a linear combination of binary features fi ( w ) E { 0 , 1 } with real-valued feature parameters ) ti : ) t. f ( w ) = ) tlfl ( w ) + ) t2f2 ( w ) -I- .</sentence>
				<definiendum id="0">q0 ( blw )</definiendum>
				<definiens id="0">a random variable describing the presence of a segment boundary</definiens>
			</definition>
			<definition id="9">
				<sentence>The TDT corpus is a mixed collection of newswire articles and broadcast news transcripts adapted from text corpora previously released by the Linguistic Data Consortium ; in particular , portions of data were extracted from the 1995 and 1996 Language Model text collections published by the LDC in support of the DARPA Continuous Speech Recognition project .</sentence>
				<definiendum id="0">TDT corpus</definiendum>
				<definiens id="0">a mixed collection of newswire articles and broadcast news transcripts adapted from text corpora previously released by the Linguistic Data Consortium ; in particular , portions of data were extracted from the 1995 and 1996 Language Model text collections published by the LDC in support of the DARPA Continuous Speech Recognition project</definiens>
			</definition>
			<definition id="10">
				<sentence>The sixth feature which boosts the probability of a segment if the previous sentence contained the word CLOSED -- is another artifact of the WSJ domain , where articles often end with a statement of a company 's performance on the stock market during the day of the story of interest .</sentence>
				<definiendum id="0">CLOSED --</definiendum>
				<definiens id="0">boosts the probability of a segment if the previous sentence contained the word</definiens>
			</definition>
			<definition id="11">
				<sentence>The fluctuating curve is the probability of a segment boundary according to the exponential model after 70 features were induced .</sentence>
				<definiendum id="0">fluctuating curve</definiendum>
			</definition>
			<definition id="12">
				<sentence>Figure 8 shows the performance of the TDT segmenter ( Model B ) on five randomly chosen blocks of 200 sentences from the TDT test data .</sentence>
				<definiendum id="0">TDT segmenter</definiendum>
			</definition>
</paper>

		<paper id="0400">
			<definition id="0">
				<sentence>Exploiting and Exploring Dialogue Structure SLT is the latest frontier for MT research perhaps the last frontier .</sentence>
				<definiendum id="0">Exploring Dialogue Structure SLT</definiendum>
				<definiens id="0">the latest frontier for MT research perhaps the last frontier</definiens>
			</definition>
			<definition id="1">
				<sentence>The first paper in the section , Lavie et al , focuses on the issues that arise when one transfers from a relatively narrow domain ( in this case , Appointment Scheduling dialogues ) to a broader domain ( Travel Planning dialogues ) .</sentence>
				<definiendum id="0">Appointment Scheduling</definiendum>
				<definiens id="0">dialogues ) to a broader domain ( Travel Planning dialogues )</definiens>
			</definition>
			<definition id="2">
				<sentence>Carter et al argue that the characteristics of the Core Language Engine -the language processing component of the system they are describing ( SLT ) -facilitate this customization .</sentence>
				<definiendum id="0">SLT</definiendum>
				<definiens id="0">al argue that the characteristics of the Core Language Engine -the language processing component of the system they are describing</definiens>
			</definition>
			<definition id="3">
				<sentence>Verbrnobil : A Translation System for Face-to-Face Dialog , CSLI Lecture Notes No. 33 , Stanford , CA : Center for the Study of Language and Information .</sentence>
				<definiendum id="0">Verbrnobil</definiendum>
				<definiens id="0">A Translation System for Face-to-Face Dialog</definiens>
			</definition>
</paper>

		<paper id="1108">
			<definition id="0">
				<sentence>Syriac has the Vowel Deletion Rule V ~ e/__ CV where e is the empty string .</sentence>
				<definiendum id="0">Syriac</definiendum>
				<definiendum id="1">e</definiendum>
				<definiens id="0">the empty string</definiens>
			</definition>
			<definition id="1">
				<sentence>Here , we shall use the following formalism which derives from the one reported by ( Pulman and Hepple , 1993 ) to express regular rewrite rules : LLC LEx RLC { : : : ~ , ~- : ~ ) LSC SURF -I : ~SC where LLC is the left lexical context , L~x is the lexical form , RLC is the right lexical context , LSC is the left surface context , SURF is the surface form , and RSC is the right surface context .</sentence>
				<definiendum id="0">LLC</definiendum>
				<definiendum id="1">RLC</definiendum>
				<definiendum id="2">LSC</definiendum>
				<definiendum id="3">SURF</definiendum>
				<definiendum id="4">RSC</definiendum>
				<definiens id="0">the left surface context</definiens>
			</definition>
			<definition id="2">
				<sentence>The pattern morpheme is { cvcvc } ( in small letters ) ; capitals in rules denote variables drawn from a finite-set of symbols .</sentence>
				<definiendum id="0">pattern morpheme</definiendum>
			</definition>
			<definition id="3">
				<sentence>* { v , ~ , a ) ( cV , C , ¢ ¢* R5 , _ _ , * a ( cv , C , a ) ¢* R6 , , R7 * a CV * _ _ * where C is a consonant and V is a vowel lexical expression ( c , k , s ) denotes a \ [ c\ ] on the first ( pattern ) tape , i a \ [ k\ ] on the second ( root ) tape and the empty string on the third ( vocalism ) tape .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">a ) ¢* R6 , , R7 * a CV * _ _ * where C is a consonant and</definiens>
				<definiens id="1">a vowel lexical expression ( c , k , s ) denotes a \ [ c\ ] on the first ( pattern ) tape , i a \ [ k\ ] on the second ( root ) tape and the empty string on the third ( vocalism ) tape</definiens>
			</definition>
			<definition id="4">
				<sentence>Formally , an n-tape finlte-state automaton is a 5-tuple M = ( Q , Z , 5 , q0 , F ) , where Q is a finite set of states , E is a finite input alphabet ( a set of n-tuples of symbols ) , t~ is a transition function mapping Q x E'~ to Q , q0 E Q is an initial state , and F C Q is a set of final states .</sentence>
				<definiendum id="0">n-tape finlte-state automaton</definiendum>
				<definiendum id="1">Q</definiendum>
				<definiendum id="2">E</definiendum>
				<definiens id="0">a finite set of states</definiens>
				<definiens id="1">a finite input alphabet ( a set of n-tuples of symbols</definiens>
				<definiens id="2">an initial state</definiens>
				<definiens id="3">a set of final states</definiens>
			</definition>
			<definition id="5">
				<sentence>Since R4-R7 in Grammar 2 represent the one phonological phenomenon , viz. , the deletion of a short vowel in an open syllable , they can be combined into one rules : * a CV R8 * * where C is a consonant and V is a vowel ~o Grammar 3 Grammar for Spirantization , case for \ [ b\ ] -- ~ Iv\ ] V b * ¢~ lZ9 .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">* a CV R8 * * where C is a consonant and</definiens>
				<definiens id="1">a vowel ~o Grammar 3 Grammar for Spirantization</definiens>
			</definition>
			<definition id="6">
				<sentence>Consider the case of Syriac spirantization mentioned above , viz. , \ [ plosive\ ] ~ \ [ + fricative\ ] / V __ Each of the six Syriac plosives requires a set of rules of the form in Grammar 3 : R9 applies when the center and context belong to prefixes and suffixes , R10 applies when the center belongs to the stem and the context belongs to a prefix , and Rll applies when the center and context belong to the stem .</sentence>
				<definiendum id="0">R10</definiendum>
				<definiendum id="1">Rll</definiendum>
				<definiens id="0">a set of rules of the form in Grammar 3 : R9 applies when the center and context belong to prefixes and suffixes</definiens>
			</definition>
</paper>

		<paper id="1501">
			<definition id="0">
				<sentence>These are Elhadad 's ( Elhadad , 1990 ) 'Functional Unification Formalism ' ( FUF ) , the KPML/Penman systems ( Mann and Matthiessen , 1985 ; Bateman , 1997 ) , and approaches within the Meaning-Text Model ( cf. ( Mel'Suk and Zholkovskij , 1970 ) ) as used in the CoGenTex-family of generators .</sentence>
				<definiendum id="0">KPML/Penman systems</definiendum>
				<definiens id="0">used in the CoGenTex-family of generators</definiens>
			</definition>
			<definition id="1">
				<sentence>KPML maintains the linguistic structure as an explicit record of the process of generation .</sentence>
				<definiendum id="0">KPML</definiendum>
				<definiens id="0">maintains the linguistic structure as an explicit record of the process of generation</definiens>
			</definition>
			<definition id="2">
				<sentence>Integrated test suites Sets of linguistic resources for generation are typically provided with test suites : such test suites consist minimally of a semantic specification and the string that should result when generating .</sentence>
				<definiendum id="0">Integrated test suites Sets</definiendum>
				<definiens id="0">test suites : such test suites consist minimally of a semantic specification and the string that should result when generating</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , interaction with the KPML GDE is , as with Smalltalk and ALEP , object-oriented but , in contrast to ALEP , the objects to which a user has access are strongly restricted to just those linguistic constructs that are relevant for generation .</sentence>
				<definiendum id="0">KPML GDE</definiendum>
				<definiens id="0">the objects to which a user has access are strongly restricted to just those linguistic constructs that are relevant for generation</definiens>
			</definition>
</paper>

		<paper id="1415">
			<definition id="0">
				<sentence>Events produced by the speech recognition system ( a Vecsys Datavox ) are either words or sequences of words ( `` I_want_to_go '' ) .</sentence>
				<definiendum id="0">Events</definiendum>
				<definiens id="0">produced by the speech recognition system ( a Vecsys Datavox</definiens>
			</definition>
			<definition id="1">
				<sentence>A chart is a graph whose nodes are positioned between the words of the sentence to be parsed ( figure 3 ) .</sentence>
				<definiendum id="0">chart</definiendum>
			</definition>
			<definition id="2">
				<sentence>They contain two types of arcs : active arcs ( which represent beginnings of a syntactic structure ) and completed arcs ( which represent a whole syntactic structure ) .</sentence>
				<definiendum id="0">completed arcs</definiendum>
				<definiens id="0">active arcs ( which represent beginnings of a syntactic structure</definiens>
			</definition>
</paper>

		<paper id="0906">
			<definition id="0">
				<sentence>The consortium consists of two universities ( both with significant experience in language engineering ) , three software companies , and various potential commercial users with the organisations being located in a total of four countries .</sentence>
				<definiendum id="0">consortium</definiendum>
			</definition>
			<definition id="1">
				<sentence>The MABLe project as it is currently formulated has as its core the belief that language technology now exists which can satisfy real user needs and requirements .</sentence>
				<definiendum id="0">MABLe project</definiendum>
				<definiens id="0">its core the belief that language technology now exists which can satisfy real user needs and requirements</definiens>
			</definition>
			<definition id="2">
				<sentence>UNIX tools have been created to allow automatic conversion from the SGML format to an agreed Access database format accessible to the Tree Walking algorithm that creates the final letter in conjunction with the user .</sentence>
				<definiendum id="0">UNIX tools</definiendum>
				<definiens id="0">created to allow automatic conversion from the SGML format to an agreed Access database format accessible to the Tree Walking algorithm that creates the final letter in conjunction with the user</definiens>
			</definition>
</paper>

		<paper id="0711">
			<definition id="0">
				<sentence>robust mforrmatlon extractlon , and readlly-avmlable on-hne NLP resources These techtuques and resources allow us to create a richer indexed source of Imgmstlc and domain knowledge than other frequency approaches Our approach attempts to apprommate text dlscourse structure through these multlple layers of mformatlon , ohtinned from automated methods m contrast to labor-lntenslve , discourse-based approaches Moreover , our planned training methodology will also allow us to explmt thin productlve infrastructure m ways whlch model human performance whde avoidmg hand-crafting domain-dependent rules of the knowledge-based approaches Our ultlmate goal m to make our summarlzatlon system scalable and portable by learning summarization rules from easily extractable text features Our summarization system DlmSum consmts of the Summarization Server and the Summarlzatzon Chent The Server extracts features ( the Feature Extractor ) from a document using various robust NLP techmques , described In Sectzon 2 1 , and combines these features ( the Feature Combiner ) to basehne multiple combinations of features , as described m Section 2 2 Our work m progress to automattcally tram the Feature Combiner based upon user and apphcatlon needs m presented in Section 2 2 2 The Java-based Chent , which wdl be dmcnssed In Section 4 , provides a graphical user interface ( GUI ) for the end user to cnstomlze the summamzatlon preferences and see multiple views of generated sumInarles In this section , we describe how we apply robust NLP technology to extract summarization features Our goal IS to add more mtelhgence to frequencybased approaches , to acqmre domain knowledge In a more automated fashion , and to apprommate text structure by recogmzing sources of dmcourse cohesion and coherence Frequency-based summarization systems typically use a single word stnng as a umt for counting frequencies Whde such a method IS very robust , it ignores the semantic content of words and their potential membership m multi-word phrases For example , zt does not dmtmgumh between `` bill '' m `` Bdl Table 1 Collocations with `` chlps '' { potato tortdla corn chocolate b~gle } chips { computer pentmm Intel macroprocessor memory } chips { wood oak plastlc } cchlps bsrgmmng clups blue clups mr chips Clmton '' and `` bill '' in `` reform bill '' This may introduce noise m frequency counting as the same strmgs are treated umformly no matter how the context may have dmamblguated the sense or regardless of membership in multl-word phrases For DlrnSum , we use term frequency based on tf*Idf ( Salton and McGdl , 1983 , Brandow , Mitze , and Rau , 1995 ) to derive ssgnature words as one of the summarization features If single words were the sole basra of countmg for our summarization application , nome would be introduced both m term frequency and reverse document frequency However , recent advances in statmtlcal NLP and information extraction make it possible to utilize features which go beyond the single word level Our approach is to extract multi-word phrases automatlcally with high accuracy and use them as the basic unit in the summarization process , including frequency calculation Ftrst , just as word association methods have proven effective m lemcal analysis , e g ( Church and Hanks , 1990 ) , we are exploring whether frequently occurring Collocatlonal reformation can improve on simple word-based approaches We have preprocessed about 800 MB of LA tlmes/Wastnngton Post newspaper articles nsmg a POS tagger ( Bnll , 1993 ) and derived two-word noun collocations using mutual information The .</sentence>
				<definiendum id="0">GUI</definiendum>
				<definiens id="0">us to create a richer indexed source of Imgmstlc and domain knowledge than other frequency approaches Our approach attempts to apprommate text dlscourse structure through these multlple layers of mformatlon , ohtinned from automated methods m contrast to labor-lntenslve , discourse-based approaches Moreover</definiens>
				<definiens id="1">summarization system DlmSum consmts of the Summarization Server and the Summarlzatzon Chent The Server extracts features ( the Feature Extractor ) from a document using various robust NLP techmques , described In Sectzon 2 1 , and combines these features ( the Feature Combiner ) to basehne multiple combinations of features</definiens>
				<definiens id="2">to extract multi-word phrases automatlcally with high accuracy and use them as the basic unit in the summarization process , including frequency calculation Ftrst , just as word association methods have proven effective m lemcal analysis</definiens>
			</definition>
			<definition id="1">
				<sentence>their aliases so that term frequency can be more accurately reflected , x e , `` IBM '' and `` International Business Machine '' are counted as two occurrences of the same term Another overt clue for chscourse cohesion and coherence is synonymous words When a theme of an article m developed throughout the text , synonymous words often appear as variants m the text In the example below , forinstance , `` pictures '' and ~mages '' are used interchangeably A new medzcal imaging technzque may someday be able to detect lung cancer and diseases of the bra : n earher than conventwnal methods , according to doctors at the State Un : vers , ty of New York , Stony Brook , and Princeton Un : verszty If doctors want to take pictures of the lungs , he noted , they have to use X-ray machines , ezpos : ng thezr pat : ents to doses of radtatzon : n the process The new technlque uses an anesthetfc , tenon gas , instead of water to create images of the body Although synonym sets have not proven effective in reformation retrieval for query expansion ( Vorhees , 1994 ) , we are using WordNet ( Mallet et al , 1990 ) to link synonymous words m an article In the IR task , a query term is expanded with Its synonyms without dlsambxguatmg the senses of the term Thus , semantically irrelevant query terms are added , and the system typically retrieves more irrelevant documents , decreasing the precision Our summarization approach , in contrast , attempts to exploit WordNet synonym sets of only signature terms m a szngle document Our hypothesis m that if a synonym of a signature term extsts m the article , the term has been dlsamblgnated by the context of the article and the `` correct '' synonym , not a synonym of the term in a different sense , m likely to co-occur in the same document In addition , morphological analysts allows us to link morphological variants of the same word within a document Morphological variants are often used to refer to the same concept throughout a document , 68 !</sentence>
				<definiendum id="0">term frequency</definiendum>
				<definiens id="0">synonyms without dlsambxguatmg the senses of the term Thus , semantically irrelevant query terms</definiens>
			</definition>
</paper>

		<paper id="0715">
			<definition id="0">
				<sentence>met &amp; Hahn 88 ) , a text summanzat~an system Which has been apphed to expos~tory texts m the domain of computer eqmpment as well as to various kinds of texts dealing with legal lssUes ( company regulations , adwsory texts , etc ) This paper m organized as follows In Section 2 we lay down a description of the syntax and semantics of the terminological logic which serves as the formal backbone for the specification of condensation operators on ( text ) knowledge bases From thin formal descnptmn we then turn to the formal model of text summarization m Section 3 Representation Model In the following , we describe a subset of a terminological logic ( for an introduction to ~ts underlying basic notatlonal conventions , cf ( Woods &amp; Schmolze 92 ) ) Sectmn 2 1 considers the terminological component , whde Section 2 2 deals with appropriate extensions for representing text-specific knowledge We dmtmgmsh two kinds of relations , namely properttes and conceptual relationships A property denotes a relation between individuals and string or integer values A conceptual relatsonshsp denotes a relation between two mchv~duals The concept description language prowdes constructs to formulate necessary ( and possibly sufllcmnt ) conditions on the properties and conceptual relationships every element of a concept class m reqmred to have The syntax of thin language m given m Fig 1 Oe , m , ~oto~ ) = ( ~onc- , .</sentence>
				<definiendum id="0">property</definiendum>
				<definiens id="0">a text summanzat~an system Which has been apphed to expos~tory texts m the domain of computer eqmpment as well as to various kinds of texts dealing with legal lssUes ( company regulations , adwsory texts</definiens>
				<definiens id="1">a relation between individuals and string or integer values A conceptual relatsonshsp denotes a relation between two mchv~duals The concept description language prowdes constructs to formulate necessary ( and possibly sufllcmnt ) conditions on the properties and conceptual relationships every element of a concept</definiens>
			</definition>
			<definition id="1">
				<sentence>( conc-name ) ) ( conc-~am~ ) = Odent~ f ~ed F~gure 1 Syntax of a Terminological Logic Every constructor m Fig 1 can be used to define a concept class ( cf Fig 5 ) The all-p constructor introduces the class of mdlwduals all Of which have a certain property ( whose value can vary from individual to individual ) For example , ( all-p prsce \ [ $ 200 , $ 5000\ ] ) denotes the class of individuals that have a property called 'price ' w~th a value ranging between $ 200 and $ 5000 An individual can only have one value for each of Its propertins ( cf Fig 2 ) The alLr constructor introduces a class of individuals that all partlctpate m , ~ertam kind of relatlonsh\ ] p to individuals from One of the concept classes given m the constructor For example , ( all-r equzpped-wzth OperatmgSystem ApphcatsonSoftware ) denotes the class of individuals that are m a relationship called 'eqmpped-wlth ' only to individuals of the class 'OperatmgSystem ' or the class 'ApphcatlonSoftware ' The dmtmctlon between the constructs all-p and all-r m uncommon m the domain of terminological logics ( Woods 8z Schmolze 92 ) , because primitive types hke stnng and integer are usually considered to be concept classes as well As we wdl see m Section 3 , the terminological reasomng underlying the text condensation process explmts thin dmtmctlon between properties and relatmnshlps The exist-v constructor introduces the class of individuals that all have a certain property value For example , ( exlst-v wezght 6 51bs ) denotes the class of individuals that have a property called 'weight ' with the value '6 51bs ' The exist-c constructor defines the class of individuals t\ ] ~at have a conceptual relatloushlp to at least one individual of a specific concept class For example , ( exlst-c has-part Cpu ) denotes the class of mdlvlduals that are ma relationship called 'has-part ' to at least one individual of the class 'Cpu ' With the and constructor several class descriptions can be combined into one ( cf Fig 5 ) The model-theoretic semantles of the terminological languagewe use m depicted in Fig 2 TOPIC 's text parser heavily rehes on terminological knowledge about the domain the texts deal wlth ( Hahn 89 ) .</sentence>
				<definiendum id="0">all-p constructor</definiendum>
				<definiendum id="1">exist-v constructor</definiendum>
				<definiens id="0">introduces the class of mdlwduals all Of which have a certain property ( whose value can vary from individual to individual</definiens>
			</definition>
			<definition id="2">
				<sentence>pcount ~rop-name ) ( mve , ght ) ) \ [ rcount ( rel-name ) ( conc-name ) ( awesght ) ) Add~tlonal Termmologlcal Constructs for Representing Text Knowledge by the syntax • Properties of a new concept can be learned ( exlst-v construct ) • Relationships to other concepts can be learned ( exlst-c construct ) m case the relatlonshlp range m already defined by a corresponding all-r construct The text-knowledge-specflic versions of the exist-v and exist-c constructs have an additional argument whlch serves as a flag that is set whenever one of these constructs is added to a concept descnptlon 0 e , when the assoclated property or relatlonshlp has been learned ) The text condensatmn component of TOPIC makes use of tlns flag m or- .</sentence>
				<definiendum id="0">tlns</definiendum>
				<definiens id="0">rel-name ) ( conc-name ) ( awesght ) ) Add~tlonal Termmologlcal Constructs for Representing Text Knowledge by the syntax • Properties of a new concept can be learned ( exlst-v construct ) • Relationships to other concepts can be learned ( exlst-c construct ) m case the relatlonshlp range m already defined by a corresponding all-r construct The text-knowledge-specflic versions of the exist-v and exist-c constructs have an additional argument whlch serves as a flag that is set whenever one of these constructs is added to a concept descnptlon 0 e , when the assoclated property or relatlonshlp has been learned ) The text condensatmn component of TOPIC makes use of</definiens>
			</definition>
			<definition id="3">
				<sentence>~T ( and `` ( rcount tel c ' n ) ) O , else n , ff c &lt; ( and ( pcount prop n ) ) pcount ( c , prop ) = n , \ ] f c -- &lt; T ( and ( pcount prop n ) ) O , else I , ff rpcount ( c , rp ) &gt; 0 rpachve ( c , rp ) = O , else ( ~ex , ,tc ( c , rp , c ' ) , ff rp ~ R 1 , ~c -- &lt; T ( and ( exist-c rel c ' f ) ) A f # 0 exzstc ( c , tel , c ' ) = { O , ex~stv ( c , prop , ~s-a ( ez , c~ ) ¢~ c~ _ &lt; e= V cz &lt; ~ , c~ V c~ &lt; ( and c~ ) vcz _ &lt; T ( and C = { c I c &lt; cezpr or c _ &lt; T cezpr ~s part of the knowledge base } AC = { c I c ~ C ^ e~o.nt ( c ) &gt; O } V = the set of all property values occurring m the knowledge base P = the set of all properties occurnng m the knowledge base R = the set of all relatmnslups occurnng m the knowledge base ( ccount n ) ) c= ) Table 1 Au~hary Set and Functmn Defimtmns for Sahence Computatmn ( SC2 ) c zs a sahent concept df rpa~ , ve ( c , rp , ) &gt; rpsERuP ¢~EAC rp~fiRuP tlACll Th e following two cnterm explozt the inherent speclalzzatmn structure of concept hzerarchzes ( cf also ( Lm 95 ) for a slmzlar perspectwe on using semantm generalzzatmn relatmns for the computatmn of concept salmnce ) They thus resemble criteria as used for the defimtmn of macro rules to achmve summanes of texts ( Correzra 80 , D~k 80 , Fum et al 85 ) These criteria also incorporate some notmn of graph connectzvzty that has previously been conszdered by ( Lehnert 81 ) for text summarLzatmn purposes ( SC3 ) determines an actwe concept c as bemg salmnt sff a slgmficant amount of subordinates of c are actwe , too ( SC4 ) zs szmflar but zt marks all non-actzve ( t ) concepts as being salmnt winch are related to a slgmficcant number of actwe subordinates Thus , concepts can be included m the topm descnptmn winch have never been mentioned exphcltly m a text ( SC4 ) only ymlds the most spectfic concepts , z e , zt excludes concepts for whmh the main criterion zs fulfilled , but which are superorchnate to another concept that also fulfills the criterion Lastly , ( SC4 ) has a more stnngent cut-off criterion Tins m necessary because zt makes non-actwe concepts sahent , accordingly , one has to be careful not to include \ ] rrelevant concepts Therefore , ( SC4 ) reqmres a quarter of all subordinates ( at least 3 ) to be actwe , whzle ( SC3 ) has a relatwe cut-off , value winch gives lower percentages for greater numbers of subordinates ( the cut-off values have been determined empmcally ) ( SC3 ) c is a salzent concept flf ceo~nt ( c ) &gt; o ^ II { e ' I~-a ( c ' , c ) } nACll &gt; `` II { V I , ~-a ( V , c ) } ll I1 { ¢ I , s-a ( ¢ , e ) } n ACll ( SC4 ) c lS a salient concept flf lit v I , ~a ( d , c ) } n ACII &gt; _ 3 and ccount ( c ) = OAc E candA ~3c ~ E cand zs-a ( d ' , c ) where ca .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">T cezpr ~s part of the knowledge base } AC = { c I c ~ C ^ e~o.nt ( c ) &gt; O } V = the set of all property values occurring m the knowledge base P = the set of all properties occurnng m the knowledge base R = the set of all relatmnslups occurnng m the knowledge base</definiens>
			</definition>
</paper>

		<paper id="0708">
</paper>

		<paper id="0901">
			<definition id="0">
				<sentence>SRA 's proprietary product , NameTag TM , which provides fast and accurate name recognition , has been reused in many applications in recent and ongoing efforts , including multilingual information retrieval and browsing , text clustering , and assistance to manual text indexing .</sentence>
				<definiendum id="0">NameTag TM</definiendum>
				<definiens id="0">provides fast and accurate name recognition , has been reused in many applications in recent and ongoing efforts , including multilingual information retrieval and browsing , text clustering , and assistance to manual text indexing</definiens>
			</definition>
			<definition id="1">
				<sentence>NameTag is a multilingual name recognition system .</sentence>
				<definiendum id="0">NameTag</definiendum>
				<definiens id="0">a multilingual name recognition system</definiens>
			</definition>
			<definition id="2">
				<sentence>NameTag incorporates a language-independent C-t-+ pattern-matching engine along with the language-specific lexicons , patterns , and other resources necessary for each language .</sentence>
				<definiendum id="0">NameTag</definiendum>
				<definiens id="0">incorporates a language-independent C-t-+ pattern-matching engine along with the language-specific lexicons , patterns</definiens>
			</definition>
			<definition id="3">
				<sentence>Now these users have available our multilingual ( or cross-linguistic ) information browsing and retrieval system , which is aimed at monolingual users who are interested in information from multiple language sources .</sentence>
				<definiendum id="0">retrieval system</definiendum>
			</definition>
			<definition id="4">
				<sentence>The system consists of an Indexing Module , a Client Module , and a Term Translation Module .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of an Indexing Module , a Client Module , and a Term Translation Module</definiens>
			</definition>
			<definition id="5">
				<sentence>The Indexing Module creates and inserts indices into a database while the Client , Module allows browsing and retrieval of information in the database through a Web-browser-based graphical user interface ( ( ~ IJ l ) .</sentence>
				<definiendum id="0">Indexing Module</definiendum>
				<definiens id="0">creates and inserts indices into a database while the Client , Module allows browsing and retrieval of information in the database through a Web-browser-based graphical user interface ( ( ~ IJ l )</definiens>
			</definition>
			<definition id="6">
				<sentence>It employs Cobwebbased conceptual clustering ( Fisher , 1987 ) , with the feature vectors required for that algorithm supplied by keywords picked from the body of a text based upon their worth as determined by the Inverse Document Frequency ( IDF ) metric ( Church and Gale , 1995 ) .</sentence>
				<definiendum id="0">conceptual clustering</definiendum>
				<definiens id="0">with the feature vectors required for that algorithm supplied by keywords picked from the body of a text based upon their worth as determined by the Inverse Document Frequency ( IDF ) metric</definiens>
			</definition>
			<definition id="7">
				<sentence>Integrated with Manual Text Indexing SRA recently developed an an operational indexing system , the Human Indexing Assistant ( HIA ) , which assists the human indexing of an incoming flow of documents .</sentence>
				<definiendum id="0">Human Indexing Assistant ( HIA )</definiendum>
				<definiens id="0">assists the human indexing of an incoming flow of documents</definiens>
			</definition>
</paper>

		<paper id="1105">
			<definition id="0">
				<sentence>An online lexicon ( originally published as Bird &amp; Tadadjeu , 1997 ) , contains records with the format in Figure 1 .</sentence>
				<definiendum id="0">online lexicon</definiendum>
				<definiens id="0">contains records with the format in Figure 1</definiens>
			</definition>
			<definition id="1">
				<sentence>The # character is a boundary symbol marking the end of the root .</sentence>
				<definiendum id="0"># character</definiendum>
				<definiens id="0">a boundary symbol marking the end of the root</definiens>
			</definition>
			<definition id="2">
				<sentence>6 8 1 1 6 1 6 4 5 3 5 2 4 1 1 5 1 6 1 1 3 Figure 2 : Query to Probe the Phonemic Status of the O/U Contrast Recall the way that parameters ( parenthesised subexpressions ) allowed output to be structured .</sentence>
				<definiendum id="0">O/U Contrast Recall</definiendum>
			</definition>
			<definition id="3">
				<sentence>Dschang is a tone language , and the records in the lexicon include a field containing a toni melody .</sentence>
				<definiendum id="0">Dschang</definiendum>
				<definiens id="0">a tone language , and the records in the lexicon include a field containing a toni melody</definiens>
			</definition>
			<definition id="4">
				<sentence>Tone melodies consist of the characters H ( high ) , L ( low ) , D ( downstep ) and F ( fall ) • A single tone has the form D ?</sentence>
				<definiendum id="0">Tone melodies</definiendum>
				<definiens id="0">consist of the characters H ( high )</definiens>
			</definition>
			<definition id="5">
				<sentence>A CGI program constructs a query string based on the submitted form data .</sentence>
				<definiendum id="0">CGI program</definiendum>
			</definition>
			<definition id="6">
				<sentence>The Reconstruction Engine : a computer implementation of the comparative method .</sentence>
				<definiendum id="0">Reconstruction Engine</definiendum>
				<definiens id="0">a computer implementation of the comparative method</definiens>
			</definition>
</paper>

		<paper id="0808">
			<definition id="0">
				<sentence>The main contribution of this work is that it uses shallow parses produced by a fully automatic parser and that some word sense disambiguation ( WSD ) is performed on the heads collected from these parses .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">it uses shallow parses produced by a fully automatic parser and that some word sense disambiguation</definiens>
			</definition>
			<definition id="1">
				<sentence>The relationship between selectional preference acquisition and WSD is a circular one .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">a circular one</definiens>
			</definition>
			<definition id="2">
				<sentence>Ribas explains that this 53 occurs because some individual nouns occur particularly frequently as complements to a given verb and so all senses of these nouns also get unusually high frequencies .</sentence>
				<definiendum id="0">Ribas</definiendum>
				<definiens id="0">explains that this 53 occurs because some individual nouns occur particularly frequently as complements to a given verb and so all senses of these nouns also get unusually high frequencies</definiens>
			</definition>
			<definition id="3">
				<sentence>The TCMs obtained for a given slot with and without WSD were similar .</sentence>
				<definiendum id="0">TCMs</definiendum>
				<definiens id="0">a given slot with and without WSD were similar</definiens>
			</definition>
</paper>

		<paper id="0307">
			<definition id="0">
				<sentence>Annotation is viewed as an interactive process where manual and automatic processing alternate .</sentence>
				<definiendum id="0">Annotation</definiendum>
				<definiens id="0">an interactive process where manual and automatic processing alternate</definiens>
			</definition>
			<definition id="1">
				<sentence>tt Last edited : Thorsten , 28/05/97 , 14:08:48 Es o spleit I ebe~ keine 3 Roll % PPER WFIN ADV PlAT NN I &lt; U 511 KOUS ART NN gef '' ~llg 9 iS~o ADJD VAFIN -Move : I .~r~ , II _ '' .. ' I ~_o'o : ' , I - , o II + , o I D ~ , , , e , I -'°° II + , oo I Mat~eo : o i r -- _Dependeney : / -s¢~ '' °n : I _Command : I | i ~- '' ~'° I I IB _ our o , o `` °u° '' ' ; i ' mu , I i T ag : Node no. : I J Zag : I IB I- '' '' ' II `` -'°~ I1-~-I I Switchin~ to sentence no , 4. , . Done. Figure 2 : Screen dump of the annotation tool predictions of the parser. The size of such 'supervision increments ' varies from local trees of depth one to larger chunks , depending on the amount of training data available. We distinguish six degrees of automation : 0 ) Completely manual annotation. 1 ) The user determines phrase boundaries and syntactic categories ( S , NP , VP , ... ) . The program automatically assigns grammatical functions. The annotator can alter the assigned tags ( cf. figure 3 ) . 2 ) The user only determines the components of a new phrase ( local tree of depth 1 ) , while both category and function labels are assigned automatically. Again , the annotator has the option of altering the assigned tags ( cf. figure 4 ) . 3 ) The user selects a substring and a category , whereas the entire structure covering the substring is determined automatically ( cf. figure 5 ) . 4 ) The program performs simple bracketing , i.e. , finds 'kernel phrases ' without the user having to explicitly mark phrase boundaries. The task can be performed by a chunk parser that is equipped with an appropriate finite state grammar ( Abney , 1996 ) . 5 ) The program suggests partiM or complete parses. A set of 500 manually annotated training sentences ( step 0 ) was sufficient for a statistical tagger to reliably assign grammatical functions , provided the user determines the elements of a phrase and its category ( step 1 ) . Approximately 700 additional sentences have been annotated this way. Annotation efficiency increased by 25 % , namely from an average annotation time of 4 minutes to 3 minutes per sentence ( 300 to 400 words per hour ) . The 1,200 sentences were used to train the tagger for automation step 2. Together with improvements in the user interface , this increased the efficiency by another 33 % , from approximately 3 to 2 minutes ( 600 words per hour ) . The fastest annotators cover up to 66 das 1993 startende Bonusprogramm for Vielflieger ART CARD ADJA NN APPR NN 'the bonus program for .h'equent fliers starting in 1993 ' Figure 3 : Example for automation level 1 : the user has marked das , the AP , Bonusprogramm , and the PP as a constituent of category NP , and the tool 's task is to determine the new edge labels ( marked with question marks ) , which are , from left to right , NK , NK , NK , MNR. das 1993 startende Bonusprogramm ffir Vielflieger ART CARD ADJA NN APPR NN 'the bonus program for frequent fliers starting in 1993 ' Figure 4 : Example for automation level 2 : the user has marked das , the AP , Bonusprogramm and the PP as a constituent , and the tool 's task is to determine the new node and edge labels ( marked with question marks ) . 1000 words per hour. At present , the treebank comprises 3000 sentences , each annotated independently by two annotators. 1,200 of the sentences are compared with the corresponding second annotation and are cleaned , 1,800 are currently cleaned. In the following sections , the automation steps 1 and 2 are presented in detail. In contrast to a standard part-of-speech tagger which estimates lexical and contextual probabilities of tags from sequences of word-tag pairs in a corpus , ( e.g. ( Cutting et al. , 1992 ; Feldweg , 1995 ) ) , the tagger for grammatical functions works with lexical and contextual probability measures Pq ( . ) depending on the category of the mother node ( Q ) . Each phrasal category ( S , VP , NP , PP etc. ) is represented by a different Markov model. The categories of the dau+++®+ ++ das 1993 startende Bonusprograrnm for Vielflieger ART CARD ADJA NN APPR NN 'the bonus program for frequent fliers starting in 1993 ' Figure 5 : Example for automation level 3 : the user has marked the words as a constituent , and the tool 's task is to determine simple sub-phrases ( the AP and PP ) as well as the new node and edge labels ( cf. previous figures ~br the resulting structure ) . Selbst ADV himself l '' l besucht hat Peter VVPP VAFIN NE visited has Peter +l Sabine nie NE ADV Sabine never 'Peter never visited Sabine himself ' Figure 6 : Example sentence ghter nodes correspond to the outputs of the Markov model , while grammatical functions correspond to states. The structure of a sample sentence is shown in figure 6. Figure 7 shows those parts of the Markov models for sentences ( S ) and verb phrases ( VP ) that represent the correct paths for the example. 4 Given a sequence of word and phrase categories T = T1 ... Tk and a parent category Q , we calculate the sequence of grammatical functions G = G1 ... Gk that link T and Q as argmaxPQ ( GIT ) ( 1 ) G Pq ( a ) . Pq ( TIC ) = argmax a PQ ( T ) = argm xPq ( a ) . Pq ( TJG ) G Assuming the Markov property we have 4cf. appendix A for a description of tags used in the example 67 VP VA FIN NE A D V &amp; -- @ -- ® -- -® -- @ -- ® O ~m m ~a o ~ .2. ~ ~ADV VVPP NE Ps ( ADVIMO ) 1 PVp ( VVPP IHD ) l Pvp ( N~IOA ) 1 N ~ o o ~ d d Figure 7 : Parts of the Markov models used in Selbst besucht hat Peter Sabine hie ( cf. figure 6 ) . All unused states , transitions and outputs are omitted. and k PQ ( TIG ) = II PQ ( ~qlG , ) ( 2 ) i=1 k Pq ( a ) = II P ( a , lC , ) ( 3 ) i=1 The contexts Ci are modeled by a fixed number of surrounding elements. Currently , we use two grammatical functions , which results in a trigram model : PO ( G ) = H Po ( GiIGi-2 , Gi-1 ) ( 4 ) i=1 The contexts are smoothed by linear interpolation of unigrams , bigrams , and trigrams. Their weights are calculated by deleted interpolation ( Brown et al. , 1992 ) . The predictions of the tagger are correct in approx. 94 % of Ml cases. In section 4.3 , we demonstrate how to cope with wrong predictions. As the annotation format permits trees with crossing branches , we need a convention for determining the relative position of overlapping sibling phrases in order to assign them a position in a Markov model. For instance , in figure 6 the range of the terminal node positions of VP overlaps with those of the subject $ B and the finite verb HD. Thus there is no single a-priori position for the VP node 5. The position of a phrase depends on the position of its descendants. We define the relative order of two phrases recursively as the order of their anchors , i.e. , some specified daughter nodes. If the anchors are words , we simply take their linear order. The exact definition of the anchor is based on linguistic knowledge. We choose the most intuitive alternative and define the anchor as the head of the phrase ( or some equivalent function ) . Noun phrases do not necessarily have a unique head ; instead , we use the last element in the noun kernel ( elements of the noun kernel are determiners , adjectives , and nouns ) to mark the anchor position. Except for NPs , we employ a default rule that takes the leftmost element as the anchor in case the phrase has no ( unique ) head. Thus the position of the VP in figure 6 is defined as equal to the string position of besucht. The position of the VP node in figure 1 is equal to that of anfgegeben , and the position of the NP in figure 3 is equivalent to that of Bonusprograrara. Experience gained from the development of the Penn Treebank ( Marcus et al. , 1994 ) has shown that auSWithout crossing edges , the serial order of phrases is trivial : phrase Q1 precedes phrase Q2 if and only if all terminal nodes derived from Qa precede those of Q2. This suffices to uniquely determine the order of sibling nodes. 68 tomatic annotation is useful only if it is absolutely correct , while wrong analyses are often difficult to detect and their correction can be time-consuming. To prevent the human annotator from missing errors , the tagger for grammatical functions is equipped with a measure for the reliability of its output. Given a sequence of categories , the tagger calculates the most probable sequence of grammatical functions. In addition , it computes the probabilities of the second-best functions of each daughter node. If some of these probabilities are close to that of the best sequence , the alternatives are regarded as equally suited and the most probable one is not taken to be the sole winner , the prediction is marked as unreliable in the output of the tagger. These unreliable predictions can be further classified in that we distinguish `` unreliable '' sequences as opposed to `` almost reliable '' ones. The distance between two probabilities for the best and second-best alternative , Pbest and Pse¢ond , is measured by their quotient. The classification of reliability is based on thresholds. In the current implementation we employ three degrees of reliability which are separated by two thresholds 01 and 02. 01 separating unreliable decisions from those considered almost reliable. 02 marks the difference between almost and fully reliable predictions. Unreliable : Pbes -- -- -k &lt; 01 Pseeond The probabilities of alternative assignments are within some small specified distance. In this case , it is the annotator who has to specify the grammatical function. Almost reliable : 01 &lt; Pbes_____t__ &lt; 02 Psecond The probability of an alternative is within some larger distance. In this case , the most probable function is displayed , but the annotator has to confirm it. Reliable : Pbes -- -- -L__ &gt; 02 Psecond The probabilitiesof all alternatives are much smaller than that of the best assignment , thus the latter is assigned .</sentence>
				<definiendum id="0">iS~o ADJD VAFIN -Move</definiendum>
				<definiendum id="1">o `` °u° ''</definiendum>
				<definiendum id="2">I i T ag</definiendum>
				<definiendum id="3">IB I- '' '' ' II `` -'°~ I1-~-I I Switchin~</definiendum>
				<definiendum id="4">NK , NK , NK , MNR.</definiendum>
				<definiendum id="5">phrasal category ( S , VP , NP , PP etc.</definiendum>
				<definiendum id="6">verb phrases</definiendum>
				<definiendum id="7">VP</definiendum>
				<definiendum id="8">Pq ( TJG</definiendum>
				<definiendum id="9">~ADV VVPP NE Ps</definiendum>
				<definiendum id="10">k PQ</definiendum>
				<definiendum id="11">PO</definiendum>
				<definiendum id="12">position of a phrase</definiendum>
				<definiendum id="13">probability of an alternative</definiendum>
				<definiens id="0">Screen dump of the annotation tool predictions of the parser. The size of such 'supervision increments ' varies from local trees of depth one to larger chunks , depending on the amount of training data available. We distinguish six degrees of automation : 0 ) Completely manual annotation. 1 ) The user determines phrase boundaries and syntactic categories ( S , NP , VP , ... )</definiens>
				<definiens id="1">finds 'kernel phrases ' without the user having to explicitly mark</definiens>
				<definiens id="2">a statistical tagger to reliably assign grammatical functions , provided the user determines the elements of a phrase and its category ( step 1 ) . Approximately 700 additional sentences have been annotated this way. Annotation efficiency increased by 25 %</definiens>
				<definiens id="3">to determine the new node and edge labels</definiens>
				<definiens id="4">to determine simple sub-phrases ( the AP and PP ) as well as the new node and edge labels</definiens>
				<definiens id="5">Parts of the Markov models used in Selbst besucht hat Peter Sabine hie ( cf. figure 6 ) . All unused states</definiens>
				<definiens id="6">determiners , adjectives , and nouns ) to mark the anchor position. Except for NPs</definiens>
			</definition>
			<definition id="2">
				<sentence>Subsequently , S is to be assigned based on the categories of the daughters VP , VAFIN , NE , and ADV .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">to be assigned based on the categories of the daughters VP , VAFIN , NE , and ADV</definiens>
			</definition>
</paper>

		<paper id="1509">
			<definition id="0">
				<sentence>The Attribute Logic Engine ( ALE , ( CP94 ) ) is a logic programming language based on typed feature structures , which can compile common logical operations like type inferencing and unification into efficient lower-level code .</sentence>
				<definiendum id="0">Attribute Logic Engine</definiendum>
				<definiens id="0">a logic programming language based on typed feature structures</definiens>
			</definition>
			<definition id="1">
				<sentence>( SNMP90 ) uses definite clause grammars , while ( Noo89 ) uses a Prolog-based extension of PATRII , which has features and atoms , but no featurebearing types , and thus no appropriateness .</sentence>
				<definiendum id="0">PATRII</definiendum>
				<definiens id="0">definite clause grammars</definiens>
			</definition>
			<definition id="2">
				<sentence>ALE allows the user to refer to feature structures by means of descriptions , taken from a language which allows reference to types ( Prolog atoms ) , feature values ( colon-separated paths ) , conjunction and disjunction ( as in Prolog ) , and structure sharing through the use of variables ( with Prolog variables ) .</sentence>
				<definiendum id="0">ALE</definiendum>
				<definiens id="0">allows the user to refer to feature structures by means of descriptions , taken from a language which allows reference to types ( Prolog atoms ) , feature values ( colon-separated paths</definiens>
			</definition>
			<definition id="3">
				<sentence>ALE uses a distinguished predicate , seN_select ( + , - ) , from its procedural attachment language in order to identify this material , e.g. : sem_select ( seN : S , S ) if true .</sentence>
				<definiendum id="0">ALE</definiendum>
				<definiens id="0">uses a distinguished predicate</definiens>
			</definition>
			<definition id="4">
				<sentence>, -u. ql L ALRGs : ( \ [ llPRED : mary'PggO : j°hn-\ ] J mary mary vp P 3 FORM : finite p , ARGS : SU BCAT : ( \ [ p , SEM : PRED : up\ ] \ [ np , AG R : sg3 , SEM : \ [ 1\ ] \ ] ) SEM : FRED : call-up q up -\ [ ARGS : ( \ [ 1\ ] PRED : mary , PRED : john n_\ ] B m vp FORM : finite SUBCAT : ( \ [ Hp , SEM : \ [ 2\ ] \ ] \ [ p , SEM : PRED : up\ ] \ [ np , AGR : sg3 , SEM : \ [ 1\ ] \ ] ) SEM : FRED : call-up q -I ARGS : ( \ [ 1\ ] PRED : mary'\ [ 2\ ] PRED : j°hnn\ ] ( e ) PGR : Sg 3 q M : \ [ PRED : john , ARGS:0\ ] \ ] john john calls calls Figure 1 : A Sample Generation Tree .</sentence>
				<definiendum id="0">SEM</definiendum>
				<definiendum id="1">SEM</definiendum>
				<definiendum id="2">FRED</definiendum>
				<definiendum id="3">PRED</definiendum>
				<definiendum id="4">PRED</definiendum>
				<definiendum id="5">PRED</definiendum>
				<definiens id="0">A Sample Generation Tree</definiens>
			</definition>
			<definition id="5">
				<sentence>We have presented the steps in compiling headdriven generation code for ALE grammar signatures , which can make use of ALE 's efficient compilation of descriptions .</sentence>
				<definiendum id="0">ALE grammar signatures</definiendum>
			</definition>
			<definition id="6">
				<sentence>, Machine Learning : an artificial intelligence approach , Morgan Kaufmann .</sentence>
				<definiendum id="0">Machine Learning</definiendum>
				<definiens id="0">an artificial intelligence approach</definiens>
			</definition>
			<definition id="7">
				<sentence>ID5 : an incremental ID3 .</sentence>
				<definiendum id="0">ID5</definiendum>
			</definition>
</paper>

		<paper id="0408">
			<definition id="0">
				<sentence>Head transducer models consist of collections of weighted finite state transducers associated with pairs of lexical items in a bilingual lexicon .</sentence>
				<definiendum id="0">Head transducer models</definiendum>
				<definiens id="0">consist of collections of weighted finite state transducers associated with pairs of lexical items in a bilingual lexicon</definiens>
			</definition>
			<definition id="1">
				<sentence>The transducer model can be characterized as a statistical translation model , but unlike the models proposed by Brown et al. ( 1990 , 1993 ) , these models have non-uniform linguistically motivated structure , at present coded by hand .</sentence>
				<definiendum id="0">transducer model</definiendum>
				<definiens id="0">a statistical translation model</definiens>
			</definition>
</paper>

		<paper id="0120">
			<definition id="0">
				<sentence>\ [ Luo and Roukos , 1996\ ] proposed a re-estimation procedure which alternates word segmentation and word frequency re-estimation on each half of the training text divided into halves .</sentence>
				<definiendum id="0">re-estimation procedure</definiendum>
				<definiens id="0">alternates word segmentation and word frequency re-estimation on each half of the training text divided into halves</definiens>
			</definition>
			<definition id="1">
				<sentence>The word segmentation task can be defined as finding a word segmentation l~ r that maximizes the joint probability of word sequence given character sequence Ill P ( W\ [ C ) .</sentence>
				<definiendum id="0">word segmentation task</definiendum>
			</definition>
			<definition id="2">
				<sentence>We decompose it into the product of word length probability and word spelling probability , P ( wil &lt; ImX &gt; ) = P ( cl ... ckl &lt; UNX &gt; ) = P ( k ) P ( cl ... cklk ) ( 3 ) where k is the length of the character sequence and &lt; OlqK &gt; represents unknown word .</sentence>
				<definiendum id="0">k</definiendum>
				<definiens id="0">into the product of word length probability and word spelling probability , P ( wil &lt; ImX &gt; ) = P ( cl ... ckl &lt; UNX &gt; ) = P ( k</definiens>
				<definiens id="1">the length of the character sequence and &lt; OlqK &gt; represents unknown word</definiens>
			</definition>
			<definition id="3">
				<sentence>, X = E Iw~lC ( w~ ) EC ( w~ ) ( 6 ) 205 'i where Iw l and C ( w ) are the length and the frequency of word ~i , respectively .</sentence>
				<definiendum id="0">Iw l</definiendum>
				<definiendum id="1">C ( w )</definiendum>
				<definiens id="0">the length and the frequency of word ~i , respectively</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , D200 consists of words appearing more than 200 times in training-0 .</sentence>
				<definiendum id="0">D200</definiendum>
				<definiens id="0">consists of words appearing more than 200 times in training-0</definiens>
			</definition>
			<definition id="5">
				<sentence>Let the number of words in the manually segmented corpus be Std , the number of words in the output of the word segmenter be Sys , and the number of matched words be M. Recall is defined as M/Std , and precision is defined as M/Sys .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the number of words in the manually segmented corpus be Std , the number of words in the output of the word segmenter be Sys , and the number of matched words be M. Recall</definiens>
			</definition>
			<definition id="6">
				<sentence>It is calculated by F= f12 x P + R ( 7 ) where P is precision , R is recall , and fl is the relative importance given to recall over precision .</sentence>
				<definiendum id="0">fl</definiendum>
				<definiens id="0">the relative importance given to recall over precision</definiens>
			</definition>
			<definition id="7">
				<sentence>C ( cic2 ) C ( cz ) C ( c2 ) &lt; N N ( s ) where C ( - ) represents the word frequency and N is the number of word tokens in the training text .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">s ) where C ( - ) represents the word frequency</definiens>
			</definition>
</paper>

		<paper id="0208">
			<definition id="0">
				<sentence>Sense tagging , the automatic assignment of the appropriate sense from some lexicon to each of the words in a text , is a specialised instance of the general problem of semantic tagging by category or type .</sentence>
				<definiendum id="0">Sense tagging</definiendum>
				<definiens id="0">a specialised instance of the general problem of semantic tagging by category or type</definiens>
			</definition>
			<definition id="1">
				<sentence>Sense tagging is the process of assigning , to each content word in a text , its particular sense from some lexicon .</sentence>
				<definiendum id="0">Sense tagging</definiendum>
				<definiens id="0">the process of assigning , to each content word in a text</definiens>
			</definition>
			<definition id="2">
				<sentence>Lesk ( Lesk , 1986 ) proposed a method for semantic disambiguation using the dictionary definitions of words as a measure of their semantic closeness and proposed the disambiguation of sentences by computing the overlap of definitions for a sentence .</sentence>
				<definiendum id="0">Lesk</definiendum>
				<definiens id="0">a measure of their semantic closeness and proposed the disambiguation of sentences by computing the overlap of definitions for a sentence</definiens>
			</definition>
</paper>

		<paper id="1302">
			<definition id="0">
				<sentence>( 2 ) ¢~ = ¢b = the hearer ( = the user ) Here , 'TO ' is a Japanese conjunctive particle which represents a causal relation , and 'ARE ' shows ability or permission .</sentence>
				<definiendum id="0">'TO '</definiendum>
				<definiens id="0">a Japanese conjunctive particle which represents a causal relation</definiens>
			</definition>
			<definition id="1">
				<sentence>Dohsaka ( Dohsaka , 1994 ) proposes a similar approach , in which several pragmatic constraints are used to determine referents of zero pronouns .</sentence>
				<definiendum id="0">Dohsaka</definiendum>
				<definiens id="0">in which several pragmatic constraints are used to determine referents of zero pronouns</definiens>
			</definition>
			<definition id="2">
				<sentence>This constraint and Constraint 1 ( Objects ) show that a SUBJECT of a sentence with the expressions of ability or permission is a user , because all of the actions of manufacturer have been finished when the user is reading the manual .</sentence>
				<definiendum id="0">permission</definiendum>
				<definiens id="0">a SUBJECT of a sentence with the expressions of ability or</definiens>
			</definition>
			<definition id="3">
				<sentence>The RU form is the basic form of verbs and it denotes the non-past tense .</sentence>
				<definiendum id="0">RU form</definiendum>
				<definiens id="0">the basic form of verbs</definiens>
			</definition>
			<definition id="4">
				<sentence>Default 2 ( SUBJECT of sentence with an intransitive ) A SUBJECT of a sentence with an intransitive is a machine .</sentence>
				<definiendum id="0">SUBJECT</definiendum>
				<definiens id="0">of sentence with an intransitive ) A SUBJECT of a sentence with an intransitive is a machine</definiens>
			</definition>
			<definition id="5">
				<sentence>The passivization is the transfer of the viewpoint of the speaker from the nominative to the objective by exchanging their positions .</sentence>
				<definiendum id="0">passivization</definiendum>
			</definition>
</paper>

		<paper id="0113">
			<definition id="0">
				<sentence>A single test material consists of three extraction problems , each with a text from a different category .</sentence>
				<definiendum id="0">single test material</definiendum>
				<definiens id="0">consists of three extraction problems</definiens>
			</definition>
			<definition id="1">
				<sentence>The kappa coefficient ( K ) of agreement measures the ratio of observed agreements to possible agreements among a set of raters on category judgements , correcting for chance agreement : K = P ( A ) P ( E ) 1 P ( E ) ( I ) where P ( A ) is the propo~ion of the times that raters agree and P ( E ) is the proportion of the times that we would expect them to agree by chance .</sentence>
				<definiendum id="0">kappa coefficient ( K</definiendum>
				<definiendum id="1">P ( A )</definiendum>
				<definiens id="0">the propo~ion of the times that raters agree and P ( E ) is the proportion of the times that we would expect them to agree by chance</definiens>
			</definition>
			<definition id="2">
				<sentence>We represent the assignments data as an N x m matrix ( Table 2 ) , where the value ( n~j ) at each cellij ( 0 &lt; i _ &lt; N , 0 &lt; j &lt; m ) denotes the number of raters assigning the ith object to the jth category .</sentence>
				<definiendum id="0">N x m matrix</definiendum>
				<definiens id="0">the number of raters assigning the ith object to the jth category</definiens>
			</definition>
			<definition id="3">
				<sentence>A coded description consists of a specification of data in terms of a fixed set of attributes and a category to which the data are to be assigned .</sentence>
				<definiendum id="0">coded description</definiendum>
				<definiens id="0">consists of a specification of data in terms of a fixed set of attributes and a category to which the data are to be assigned</definiens>
			</definition>
			<definition id="4">
				<sentence>IDF ( w ) ~eW ( T ) W ( T ) is a set of words in T. s For each word w in W ( T ) , we find its normalized word frequency NF ( w ) in S by : s ) = MAX_F ( S ) where F ( w , S ) denotes a frequency of the word w in S and MAX_F ( S ) the frequency of the most frequent word in S. wE ( w ) = log logN DF ( w ) is the number of sentences in the text which have an occurrence of w. N is the total number of sentences in the text .</sentence>
				<definiendum id="0">IDF</definiendum>
				<definiendum id="1">T ) W ( T )</definiendum>
				<definiendum id="2">S )</definiendum>
				<definiendum id="3">logN DF ( w )</definiendum>
				<definiens id="0">a set of words in T. s For each word w in W ( T ) , we find its normalized word frequency NF ( w ) in S by : s ) = MAX_F ( S ) where F ( w ,</definiens>
				<definiens id="1">a frequency of the word w in S and MAX_F ( S ) the frequency of the most frequent word in S. wE ( w ) = log</definiens>
				<definiens id="2">the number of sentences in the text which have an occurrence of w. N is the total number of sentences in the text</definiens>
			</definition>
			<definition id="5">
				<sentence>This attribute is categorical and takes one of the three values , TYPE 1 , TYPE 2 and TYPE 3 , depending on whether the sentence ends with a verbal of non-attitudinal type ( TYPE I ) , or with an attidutinal verbal or a modal ( TYPE 2 ) , or with a sentence final particle ( TYPE 3 ) .</sentence>
				<definiendum id="0">TYPE</definiendum>
				<definiens id="0">categorical and takes one of the three values</definiens>
			</definition>
			<definition id="6">
				<sentence>The procedure for evaluation consists in the following steps : ( 1 ) choose at random 200 cases of category `` no '' and 40 of category `` yes '' from each of the data sets to form evaluation data ; ( 2 ) divide the data so chosen into a training set and a test set ; ( 3 ) build a decision tree from the training set , rnnning C4.5 with the default options ; and ( 4 ) evaluate its performance on the test data .</sentence>
				<definiendum id="0">procedure for evaluation</definiendum>
				<definiens id="0">consists in the following steps : ( 1 ) choose at random 200 cases of category `` no '' and 40 of category `` yes '' from each of the data sets to form evaluation data ; ( 2 ) divide the data so chosen into a training set and a test set ; ( 3 ) build a decision tree from the training set , rnnning C4.5 with the default options</definiens>
			</definition>
			<definition id="7">
				<sentence>Precision is the ratio of cases assigned correctly to the `` yes '' category to the total cases assigned to the `` yes '' category .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio of cases assigned correctly to the `` yes '' category to the total cases assigned to the `` yes '' category</definiens>
			</definition>
			<definition id="8">
				<sentence>Recall is the ratio of cases assigned correctly to the =yes '' category to the total `` yes '' cases .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the ratio of cases assigned correctly to the =yes '' category to the total `` yes '' cases</definiens>
			</definition>
			<definition id="9">
				<sentence>Intention-based Segmentation : Human Reliability and Correlation with Linguistic Cues .</sentence>
				<definiendum id="0">Intention-based Segmentation</definiendum>
			</definition>
</paper>

		<paper id="0109">
			<definition id="0">
				<sentence>WordNet is a network of meanings connected by a variety of relations .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a network of meanings connected by a variety of relations</definiens>
			</definition>
			<definition id="1">
				<sentence>SEMANTIC DISTANCE The traditional method of evaluating semantic distance between two meanings based merely on the length of the path between the nodes representing them , does not work well in WordNet , because the distance also depends on the depth at which the concepts appear in the hierarchy .</sentence>
				<definiendum id="0">SEMANTIC DISTANCE</definiendum>
				<definiens id="0">The traditional method of evaluating semantic distance between two meanings based merely on the length of the path between the nodes representing them</definiens>
			</definition>
			<definition id="2">
				<sentence>D12 COMP~ dist ( SUBSIDIARY l , COMPANY 5 ) =1/2 ( LI I/DI 1+L21/D2 I ) =I/2 ( 3/6+3/6 ) =0.5 dist ( SUBSIDIARY I , COMPANY~I ) =0 ( no common ancestor ) dist ( S UB SIDIARY 2 , COMPANY I ) = I/2 ( I , 12/D 12+L22/D22 ) = I/2 ( I/7+0/6 ) =0.071 dist ( PLANT_I , FACILITYI ) = I/2 ( L 13/D 13+L23/D23 ) = I/2 ( 3/6+ I/4 ) =0.375 , ~¢GROUP~ ... .- '' ) `` , , : '' SOCIAL GROUP\ ORGANIZATION 1 ' D22 ENTERPRISE : BUSINESS 1 '' '' • ~L12 % UBSJD ) AR¥.2 In order to determine the position of a word in the semantic hierarchy , we have to determine the meaning of the word from the context in which it appears .</sentence>
				<definiendum id="0">D12 COMP~ dist</definiendum>
				<definiens id="0">determine the meaning of the word from the context in which it appears</definiens>
			</definition>
			<definition id="3">
				<sentence>The verb buy in Q2 is already disambiguated and the distance to both Q2 and Q4 is the same , i.e. : dqv ( Q3 , Q2 ) ffidqv ( Q3 , Q4 ) ffi ( 0.2Yz+0.083+0 ) /3ffi0.0485 where the minimum semantic distance between the nearest senses of the verb acquire and buy is : min ( dist ( acquire , buy ) ffidist ( AOOUIRE-1 , BUY-1 ) ffiO.25 The verb acquire is disambiguated to the sense nearest to the sense of the verb buy and the algorithm proceeds to the noun business in Q3 .</sentence>
				<definiendum id="0">Q4</definiendum>
				<definiens id="0">ffi ( 0.2Yz+0.083+0 ) /3ffi0.0485 where the minimum semantic distance between the nearest senses of the verb acquire</definiens>
			</definition>
			<definition id="4">
				<sentence>The matching distance between two quadruples Ql=Vl-nl-P-dl and Q2=v2-n2-p-d2 is defined as follows ( v=verb , n=noun , p=preposition , d=description noun ) : Dqv ( Q1 , Q2 ) = ( D ( vl , v2 ) 2 ) +D ( nl , n~ ) +D ( dl , d2 ) ) /P , when disambiguating verb Don ( Q1 , Q2 = ( D ( vl , v2 ) +D ( nlrn2 ) Z+D ( dl , d2 ) ) /P , when disambiguating noun Dqd ( ~l , Q2 ) = ( D ( Vl , V2 ) +D ( nl , n2 ) +D ( dl , d2 ) 2 ) /P , when disambiguating description where P is the number of pairs of words in the quadruples which have a common semantic ancestor , i.e. P = 1 , 2 or 3 ( if there is no such a pair , Dq = .</sentence>
				<definiendum id="0">matching distance between two</definiendum>
				<definiendum id="1">V2 ) +D</definiendum>
				<definiendum id="2">P</definiendum>
				<definiens id="0">follows ( v=verb , n=noun , p=preposition , d=description noun</definiens>
				<definiens id="1">the number of pairs of words in the quadruples which have a common semantic ancestor</definiens>
			</definition>
			<definition id="5">
				<sentence>identificators ( synsets ) of WordNet .</sentence>
				<definiendum id="0">identificators</definiendum>
				<definiens id="0">synsets ) of WordNet</definiens>
			</definition>
			<definition id="6">
				<sentence>At first , all the training examples ( separately for each preposition ) are split into subsets which correspond to the topmost concepts of WordNet , which contains 11 topical roots for nouns and description nouns , and 337 for verbs ( both nouns and verbs have hierarchical structure , although the hierarchy for verbs is shallower and wider ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">contains 11 topical roots for nouns and description nouns</definiens>
			</definition>
			<definition id="7">
				<sentence>We feel that a bigger corpus , would provide us with an increase of accuracy of `` certainty 1 '' attachments , which partly includes attachments based on the small leaves .</sentence>
				<definiendum id="0">certainty 1 '' attachments</definiendum>
				<definiens id="0">partly includes attachments based on the small leaves</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>Information extraction systems process natural language documents and locate a specific set of relevant items .</sentence>
				<definiendum id="0">Information extraction systems</definiendum>
			</definition>
			<definition id="1">
				<sentence>GOLEM ( Muggleton and Feng , 1992 ) is a bottomup ( specific to general ) ILP algorithm based on the construction of relative least-general generalizations , rlggs ( Plotkin , 1970 ) .</sentence>
				<definiendum id="0">GOLEM</definiendum>
			</definition>
			<definition id="2">
				<sentence>The idea of least-general generalizations ( LGGs ) is , given two items ( in ILP , two clauses ) , finding the least general item that covers the original pair .</sentence>
				<definiendum id="0">least-general generalizations ( LGGs )</definiendum>
				<definiens id="0">given two items ( in ILP , two clauses ) , finding the least general item that covers the original pair</definiens>
			</definition>
			<definition id="3">
				<sentence>The CHILLIN ( Zelle and Mooney , 1994 ) system combines top-down ( general to specific ) and bottomup ILP techniques .</sentence>
				<definiendum id="0">CHILLIN</definiendum>
			</definition>
			<definition id="4">
				<sentence>In cases where a correct clause can not be learned with the existing background relations , CHILLIN attempts to construct new predicates which will distinguish the covered negative examples from the covered positives .</sentence>
				<definiendum id="0">CHILLIN</definiendum>
				<definiens id="0">attempts to construct new predicates which will distinguish the covered negative examples from the covered positives</definiens>
			</definition>
			<definition id="5">
				<sentence>An outline of the algorithm appears in Figure 3 where RuleList is a prioritized list of no more than BeamWidth rules .</sentence>
				<definiendum id="0">RuleList</definiendum>
			</definition>
			<definition id="6">
				<sentence>AUTOSLOG creates a dictionary of extraction patterns by specializing a set of general syntactic patterns ( Riloff , 1993 , Riloff , 1996 ) .</sentence>
				<definiendum id="0">AUTOSLOG</definiendum>
				<definiens id="0">creates a dictionary of extraction patterns by specializing a set of general syntactic patterns</definiens>
			</definition>
			<definition id="7">
				<sentence>Introduction to WordNet : An on-line lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0218">
</paper>

		<paper id="0119">
			<definition id="0">
				<sentence>When matching vectors are very similar such as those in the WSJ English/English corpus , a simple metric like the Euclidean Distance could be used to find those matching pairs : g : V/Zl &lt; i &lt; . ( w~ , wt , ) 2 I I I I I I 196 I I I I I I , I I I I I I I I i I I I g c 0 g 1200 1000 8OO 6O0 4O0 2OO 0 0 i |riLL 5O 100 July offered Canadian preferred June exchange issue notes gas 695.58 646.30 596.42 551.50 393.14 387.16 373.80 229.45 158.60 \ [ ~WWfmll offered preferred July June exchange issue notes gas Capital 646.30 551.5O 695.58 393.14 387.16 373.80 229.45 158.60 157.64 Figure 2 : Most correlated seed words with debentures `` debeNtures.wrma '' , .IJ , t 150 200 250 300 seed words 800 ~ , , • 7OO • I ! 350 IO0 600 ~o ¢ : o 400 ~o 2OO , oo 0 5O `` debentures.wrmb '' 150 200 250 300 seed words Figure 3 : Word relation matrix for debenture in both texts However , most word pairs in truly non-parallel bilingual corpus are less similar than those in Figure 3. The 9 value of a new word is high when there is a z-th seed word which co-occurs with it siguificantly often. If a pair of bilingual words are supposed to be translations of each other , they should share the most significant y values. In this case , the Cosine Measure would be more appropriate where : C = Et &lt; i &lt; ~ ( w , . wt , ) The Cosine Measure will give the highest value to vector pairs which share the most non-zero y values. Therefore , it favors word pairs which share the most number of closely related seed words. However , the Cosine Measure is also directly proportional to another parameter , namely the actual ( ws. × wt. ) values. Consequently , if ws has a high y value everywhere , then the Cosine Measure between any wt and this ws would be high. This violates our assumptions in that although w8 and wt might not correlate closely with the same set of seed words , the matching score would be nevertheless high. This is another supporting reason for choosing mid-frequency content words as seed words. 197 3S0 A , i Li , AJ ltA ill SO 10o 1SO ZO 250 ~0 35O I °wmm/admmi~mmi~.wmm SO 1nO r~O 1400 ~mO 4OO 0 40CO 35C0 ~1000 2OOO 1000 SO0 ' , o AI , , 0 1 $ 0 I~0 N~m~mwtmb '' m 2SO ~10 3 $ 0 Figure 4 : Word relation matrix for administration in both texts The evaluation on the WSJ/WSJ English/English corpus is intended as a pilot test on the discriminative power of the Word Relation Matrix. This non-parallel corpus has minimal content and style differences. Furthermore , using such an English/English test set , the output can be evaluated automatically -- a translated pair is considered correct if they are identical English words. 307 seed words are chosen according to their occurrence frequency ( 400-3900 ) to minimize the number of function words. However , a frequency of 3900 in a corpus of 1.SM words is quite high. As a result , a segment delimited by two punctuations is used as the context window size. Furthermore , the frequent nature of the seed words led to our choice of the Euclidean Distance , instead of the Cosine Measure. The choices of segment size , seed words , and Euclidean Distance measure are all direct consequences of the atypical nature of the English/English pilot test set. We selected a test set of 582 ( set A ) by 687 ( set B ) single words with mid-range frequency from the WSJ texts. We computed the WoRM feature for each of these test words and computed the Euclidean Distance between every word in these sets. We then calculated the accuracy by counting the number of words whose top one candidate is identical to itself , obtaining a precision of 29 % . By allowing N-top candidates , the accuracy improves as shown in the graphs for 582 words output in Figure 5 ( i.e. a translation is correct if it appears among the first N candidates ) . If we find the correct translation among the top 100 candidates , we obtain a precision of around 58 % . N-top candidates are useful as translator aids. Meanwhile , precisions for translating less polysemous content words are higher. If only the 445 content words ( manually selected ) are kept from the 582-word set , the precisions at different top N candidates for the 445-word set are higher as shown in Figure 5 by the dotted line. We believe the accuracy would be even higher if we only look at really unambiguous test words , such as an entire technical term. It is well known that polysemous words usually have only one sense when used as part of a collocation or technical term ( Yarowsky 1993 ) . m Evaluations are also carried out on the Wall Street Journal and Nikkei Financial News corpus , matching technical terms in Japanese to their counterpart in English. This evaluation is a difficult test case because ( 1 ) the two languages , English and Japanese , are across language groups ; ( 2 ) the i 198 ! 0 0 ~L 0 i 582 word ouptput 445 content word output I I ! I 0 20 40 60 80 100 top N candidates Figure 5 : Evaluation results of WoRM in 1993/94 Wall Street Journal two texts , Wall Street Journal and Nikkei Financial News , do not focus on the same topics ; and ( 3 ) the two texts are not written by the same authors. 1,416 entries from the Japanese/English online dictionary EDICT with occurrence frequencies between 100 and 1000 are chosen as seed words. Since these seed words have relatively low frequencies compared to the corpus size of around 7 million words for the WSJ text , we chose the segment size to be that of an entire paragraph. For the same reason , the Cosine Measure is chosen as a matching function. For evaluation , we need to select a test set of known technical term translations. We handtranslated a selected set of technical terms from the Nikkei Financial News corpus and looked them up in the Wall Street Journal text. Among these , 19 terms , shown in Figure 6 , have their counterparts in the WSJ text. Three evaluations were carried out. In all cases , a translation is counted as correct if the top candidate is the rig~ht one. Test I tries to find the correct translation for each of the nineteen Japanese terms among the nineteen Engl/sh terms. To increase the candidate numbers , test II is carried out on 19 Japanese terms with their English counterparts plus 293 other English terms , giving a total of 312 possible English candidates. The third test set HI consists of the nineteen Japanese terms paired with their translations and 383 single English words in addition. The accuracies for the three test sets are shown in Figure 7 ; precision ranges from 21.1 % to 52.6 % . Figure 8 shows the ranking of the true translations among all the candidates for all 19 cases for the purpose of a translator-aid. Most of the correct translations can be found among the top 20 cand/dates. The previous two evaluations show that the precision of best-candidate translation using our algorithm is around 30 % on average. While it is far from ideal , this is the first result of terminology translation from non-parallel corpora. Meanwhile , we have found that the correct translation is often among the top 20 candidates. This leads us to conjecture that the output from this algorithm can be used as a translator-aid. 199 p'ub~ i~sv~.~maE ~rade ~ ; iaKiow • udet~ inspe~ion price , m , mperi ri~ , m : om , mic Sm~ h U $ .. , .h~.pa~a : Ntde U S..Jiapan : r.axlle NTT avi~ane~ml pt~mecio~ free ~rade eec~nmln~e rd'orm HA F'rA 'ur~rld ; r.ade eo~x~mp ~ sam I~r~pou U~'io 'm sax reform m~m~ = x l , ll\ ] ~ s~JI~ sZ~Ir~s ws~ ~-i 'm , s~slik~ w~e~sk , a , : Figure 6 : The 19 term test set for the WSJ/Nikkei corpus To*se* II 19 &gt; I**I 402 , I Precision of best candidate 10/19=52.6 % 4/19=21.1 % 6/19=31.6 % Figure 7 : Precisions for the best candidate translation in the WSJ/Nikkei corpus To evaluate this , we again chose the nineteen English/Japanese terms from the WSJ/Nikkei non-parallel corpus as a test set .</sentence>
				<definiendum id="0">matching score</definiendum>
				<definiens id="0">When matching vectors are very similar such as those in the WSJ English/English corpus , a simple metric like the Euclidean Distance could be used to find those matching pairs : g : V/Zl &lt; i &lt; . ( w~ , wt , ) 2 I I I I I I 196 I I I I I I , I I I I I I I I i I I I g c 0 g 1200 1000 8OO 6O0 4O0 2OO 0 0 i |riLL 5O 100 July offered Canadian preferred June exchange issue notes gas 695.58 646.30 596.42 551.50 393.14 387.16 373.80 229.45 158.60 \ [ ~WWfmll offered preferred July June exchange issue notes gas Capital 646.30 551.5O 695.58 393.14 387.16 373.80 229.45 158.60 157.64 Figure 2 : Most correlated seed words with debentures `` debeNtures.wrma '' , .IJ , t 150 200 250 300 seed words 800 ~ , , • 7OO • I ! 350 IO0 600 ~o ¢ : o 400 ~o 2OO , oo 0 5O `` debentures.wrmb '' 150 200 250 300 seed words Figure 3 : Word relation matrix for debenture in both texts However , most word pairs in truly non-parallel bilingual corpus</definiens>
				<definiens id="1">a z-th seed word which co-occurs with it siguificantly often. If a pair of bilingual words are supposed to be translations of each other , they should share the most significant y values. In this case , the Cosine Measure would be more appropriate where : C = Et &lt; i &lt; ~ ( w , . wt , ) The Cosine Measure will give the highest value to vector pairs which share the most non-zero y values. Therefore , it favors word pairs which share the most number of closely related seed words. However , the Cosine Measure is also directly proportional to another parameter , namely the actual ( ws. × wt. ) values. Consequently , if ws has a high y value everywhere , then the Cosine Measure between any wt and this ws would be high. This violates our assumptions in that although w8 and wt might not correlate closely with the same set of seed words</definiens>
				<definiens id="2">another supporting reason for choosing mid-frequency content words as seed words. 197 3S0 A , i Li , AJ ltA ill SO 10o 1SO ZO 250 ~0 35O I °wmm/admmi~mmi~.wmm SO 1nO r~O 1400 ~mO 4OO 0 40CO 35C0 ~1000 2OOO 1000 SO0 ' , o AI , , 0 1 $ 0 I~0 N~m~mwtmb '' m 2SO ~10 3 $ 0 Figure 4 : Word relation matrix for administration in both texts The evaluation on the WSJ/WSJ English/English corpus is intended as a pilot test on the discriminative power of the Word Relation Matrix. This non-parallel corpus has minimal content and style differences. Furthermore , using such an English/English test set , the output can be evaluated automatically -- a translated pair is considered correct if they are identical English words. 307 seed words are chosen according to their occurrence frequency ( 400-3900 ) to minimize the number of function words. However , a frequency of 3900 in a corpus of 1.SM words is quite high. As a result , a segment delimited by two punctuations is used as the context window size. Furthermore , the frequent nature of the seed words led to our choice of the Euclidean Distance , instead of the Cosine Measure. The choices of segment size , seed words , and Euclidean Distance measure are all direct consequences of the atypical nature of the English/English pilot test set. We selected a test set of 582 ( set A ) by 687 ( set B ) single words with mid-range frequency from the WSJ texts. We computed the WoRM feature for each of these test words and computed the Euclidean Distance between every word in these sets. We then calculated the accuracy by counting the number of words whose top one candidate is identical to itself , obtaining a precision of 29 % . By allowing N-top candidates , the accuracy improves as shown in the graphs for 582 words output in</definiens>
				<definiens id="3">useful as translator aids. Meanwhile , precisions for translating less polysemous content words are higher. If only the 445 content words ( manually selected ) are kept from the 582-word set , the precisions at different top N candidates for the 445-word set are higher as shown in Figure 5 by the dotted line. We believe the accuracy would be even higher if we only look at really unambiguous test words , such as an entire technical term. It is well known that polysemous words usually have only one sense when used as part of a collocation or technical term ( Yarowsky 1993 ) . m Evaluations are also carried out on the Wall Street Journal and Nikkei Financial News corpus , matching technical terms in Japanese to their counterpart in English. This evaluation is a difficult test case because ( 1 ) the two languages , English and Japanese , are across language groups ; ( 2 ) the i 198 ! 0 0 ~L 0 i 582 word ouptput 445 content word output I I ! I 0 20 40 60 80 100 top N candidates Figure 5 : Evaluation results of WoRM in 1993/94 Wall Street Journal two texts , Wall Street Journal and Nikkei Financial News , do not focus on the same topics ; and ( 3 ) the two texts are not written by the same authors. 1,416 entries from the Japanese/English online dictionary EDICT with occurrence frequencies between 100 and 1000 are chosen as seed words. Since these seed words have relatively low frequencies compared to the corpus size of around 7 million words for the WSJ text , we chose the segment size to be that of an entire paragraph. For the same reason , the Cosine Measure is chosen as a matching function. For evaluation , we need to select a test set of known technical term translations. We handtranslated a selected set of technical terms from the Nikkei Financial News corpus and looked them up in the Wall Street Journal text. Among these , 19 terms , shown in Figure 6 , have their counterparts in the WSJ text. Three evaluations were carried out. In all cases , a translation is counted as correct if the top candidate is the rig~ht one. Test I tries to find the correct translation for each of the nineteen Japanese terms among the nineteen Engl/sh terms. To increase the candidate numbers , test II is carried out on 19 Japanese terms with their English counterparts plus 293 other English terms , giving a total of 312 possible English candidates. The third test set HI consists of the nineteen Japanese terms paired with their translations and 383 single English words in addition. The accuracies for the three test sets are shown in Figure 7 ; precision ranges from 21.1 % to 52.6 % . Figure 8 shows the ranking of the true translations among all the candidates for all 19 cases for the purpose of a translator-aid. Most of the correct translations can be found among the top 20 cand/dates. The previous two evaluations show that the precision of best-candidate translation using</definiens>
				<definiens id="4">leads us to conjecture that the output from this algorithm can be used as a translator-aid. 199 p'ub~ i~sv~.~maE ~rade ~ ; iaKiow • udet~ inspe~ion price , m , mperi ri~ , m : om , mic Sm~ h U $ .. , .h~.pa~a : Ntde U S..Jiapan : r.axlle NTT avi~ane~ml pt~mecio~ free ~rade eec~nmln~e rd'orm HA F'rA 'ur~rld ; r.ade eo~x~mp ~ sam I~r~pou U~'io 'm sax reform m~m~ = x l</definiens>
				<definiens id="5">The 19 term test set for the WSJ/Nikkei corpus To*se* II 19 &gt; I**I 402</definiens>
				<definiens id="6">Precisions for the best candidate translation in the WSJ/Nikkei corpus To evaluate this , we again chose the nineteen English/Japanese terms from the WSJ/Nikkei non-parallel corpus as a test set</definiens>
			</definition>
</paper>

		<paper id="1409">
			<definition id="0">
				<sentence>Inspired by ( Mac86 ) , we use a relation tuple of the form : ( Encodes carrier info context-space ) to specify the semantic relationship between a presentation means , and the information the means is to convey in a certain context space ( cf. ( AR94 ) ) .</sentence>
				<definiendum id="0">cf.</definiendum>
				<definiens id="0">a relation tuple of the form : ( Encodes carrier info context-space ) to specify the semantic relationship between a presentation means , and the information the means is to convey in a certain context space</definiens>
			</definition>
</paper>

		<paper id="0316">
			<definition id="0">
				<sentence>daily ( z ) slowly ( 3 ) ~ every uhere Counter-Examples : ( 4 ) ~ person name ( 5 ) H~21-~I Japan Honshu ( e ) u.s. congress Rule 2 : Px , where P is a small set of 31 special characters , are stopwords for any x -these characters are tagged '2 ' in our lexicon and examples are shown Rule 2 Examples : ( 7 ) ~ : ~ a branch/stick of ( 8 ) -- ~ early ( 9 ) -- ~ together ( 18 ) ( ~ , ~ ) ~ ( this , that ) kind ( 11 ) ( ~ , ~ ) ~ ( this , that ) time ( 12 ) ~ consider to be ( 13 ) ~ , ,~ .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">a small set of 31 special characters</definiens>
			</definition>
			<definition id="1">
				<sentence>PIRCS is an automatic , learning-based IR system that is conceptualized as a 3-layer network and operates via activation spreading .</sentence>
				<definiendum id="0">PIRCS</definiendum>
				<definiens id="0">an automatic , learning-based IR system that is conceptualized as a 3-layer network and operates via activation spreading</definiens>
			</definition>
			<definition id="2">
				<sentence>Precision is defined as the proportion of retrieved documents which are relevant , and recall that of relevant documents which are retrieved .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the proportion of retrieved documents which are relevant , and recall that of relevant documents which are retrieved</definiens>
			</definition>
			<definition id="3">
				<sentence>USeg : a retargetable word segmentation procedure for information retrieval .</sentence>
				<definiendum id="0">USeg</definiendum>
			</definition>
</paper>

		<paper id="0702">
			<definition id="0">
				<sentence>i 1 1 1 I i I of data reducUon over the original text Indeed , by adoptmg ~ner granularity Of representauon ( below that of sen 7 tence ) , we consaously trade m `` readab~hty '' ( or narrative coherence ) for tracking of detad 2 In particular , we seek to charactense a document 's content m a way which ms representahve of the full flaw of the narratwe this ~s m contrast to passage extraction methods , which typically h~ghhght only certain fragments ( an unavoidable consequence of the compronuses necessary when the passages are sentence-stzed ) A capsule overwew ms not a fully mstantmted meanmg template eather A pnmary considerahon m our work ms that content charactensahon methods apply to any document source or type Tins emphasms on domain independence translates into a processing model which stops short of a fully mstantmted semantic representation Sun~larly , the requirement for eJ~iaent , and sca/ab/e , technology necessitates operahng from a shallow syntactic base , thus our procedures are designed to arcumvent the need for a comprehensive parsing engine Not having to rely upon the parsing components typically seeking to dehver mdepth , full , syntactic analysms of text , makes ~t posslble to generate capsule summaries for a variety of documents , up to and including real data from unfanuhar domains or novel genres For us , a capsule overwew is instead a coherently presented hst of those hngumt~c expressions wluch refer to the most pronunent objects mentioned m the dl~urse-Its topw stamps -- -and prowde further spenficat~on of the relational contexts m wluch they appear The mtmt~ons underlying our approach can be illustrated with the following news article s. PRIEST IS CHARGED WITH POPE ATTACK A Spamsh/b'~est was charged here today with attempting to murder the Pope .</sentence>
				<definiendum id="0">meanmg template eather A pnmary</definiendum>
				<definiens id="0">a document 's content m a way which ms representahve of the</definiens>
			</definition>
			<definition id="1">
				<sentence>for a segment S to be the n lughes t ranked referents m s ( where n ms a scalable value ) 4Our sahence factors nurror those used by Lappm and Leass , with fl'te excephon of Poss , wluch Is sens~ve to possessive expmsmons , and CNTX , wl~ch Is sensllav e to the chscourse segment m whlch a candldate appears I i i , i , l I i I I !</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">ms a scalable value ) 4Our sahence factors nurror those used by Lappm and Leass , with fl'te excephon of Poss</definiens>
			</definition>
			<definition id="2">
				<sentence>\ [ 2\ ] Advanced Research Projects Agency Trpster Text Program Phase I , Fredericksburg , Vlrgmm , 1993 \ [ 3\ ] D Boungault Surface grammatical analysis for the extract2on of terminological noun phrases In 14th International C.onfe~ei~celon Computatzonal Lmgulstlcs , Nantes , France , 1992 ' D Caruso New software summarizes documents The New York Tunes , January 27,1997 I Dagan and K Church Ternught identifying and translating technical terminology In Proceedings of 4th Conference on Apphed NLP , Stuttgart , German3~ 1995 \ [ 6\ ] Defense Advanced Research Prolects Agency Fourth Message Understanding Conference ( MUC-4 ) , McLean , VlrgTaua , 1992 Software and Intelhgent Systems Technology Office \ [ 7\ ] G DeJong An over , new of the FRUMP system In • W Lehnert and M Rmgle , editors , Strategies for Natural Language Parsing , pp 149-176 Lawrence Eftbaum Assocmtes , Hfllsdale , NJJ , 1982 \ [ 8\ ] M Hearst Multi-paragraph segmentation ofexposxtory text In 32nd Annual Meeting of the Assocmt~on for Computatwnal Lmgu~st ; es , Las Cruces , NM , 1994 N Hutheesmg Gdbert Ameho 's grand scheme to rescue Apple Forbes Magazine , December 16,1996 J S Justeson and S M Katz Techmcal terminology some hngmst~c properties and an algorithm for xdentff~cat~on m text Natural Language Engineering , 1 ( 1 ) 9-27,1995 F Karlsson , A Vouhlamen , j Hetkkda , and A Antdla Constraint grammar A language-independent system for parsing free text Mouton de Gruyter , 1995 E Keenan and B Comne Noun phrase accesszb~hty and umversal grammar Linguistic Inquiry , 8 62-100 , 1977 C Kennedy and B Boguraev Anaphora for everyone Prononunal anaphora resolution without a parser In Proceedings of COLING-96 , Copenhagen , DK , 1996 C Kennedy ~ind B Boguraev Anaphora m a wider context Tracking discourse referents In W Wahlster , editor , Proceedings of ECAI-96 , Budapest , Hungar3~ 1996 John Wdey and Sons J Kupmc , J Pedersen , and F Chen A trainable document summarizer In Proceedings of the 18th Annual International ACM SIGIR Conference , 68 -- 733 , Seattle , Washington , 1995 \ [ 16\ ] S Lappm and H Leass An algorithm for pronominal anaphora resolution Conrputahonal Lmgulst~es , 20 ( 4 ) 535-561,1994 \ [ 17\ ] H Luhn `` The automatic creation of hterature abstracts IBM Journal of Research and Development , 2 159 -- 165,1959 \ [ 18\ ] K Mahesh Hypertext summary extraction for fast document browsing In Proceedings of AAAI 5pnng Symposmra NLP for WWW , pp 95 -- 104 , Stanford , CA , 1997 \ [ 19\ ] I Mare and T MacMillan Identff3nng unknown proper names m newswlre text In B Boguraev and J Pustejovsk~ eeds , Corpus Processing for Lexlcal Acqu~sztum , pp 41-59 MIT Press , Cambridge , MA , 1996 M M McCord Slot grammar a system for sunpler construction of practical natural language grammars In R Studer , ed , Natural language and lbgnc mternatwnal sc~enhJic sympos ; um , Lecture Notes m Computer Science , pp 118 -- 145 Springer Verlag , 1990 \ [ 21\ ] K McKeown and D Radev Generating summanes of multiple news articles In Proceedings of the 18th Annual Internatzonal ACM SIGIR , pp 74 -- 82 , Seattle , Washington , 1995 \ [ 22\ ] C D Pmce Constructing hterature abstracts by computer techmques and prospects Informahon Processing and Management , 26 171-186,1990 \ [ 23\ ] K Preston and S Wflhams Managing the mformatron ove~Ioad new automatic summarization tools are good news for the hard-pressed executive Phymcs m Business , 1994 \ [ 24\ ] L Rau Conceptual reformation extraction and mformation retrieval from natural language input In Proceedings of RIAO-88 , Conference on User-oriented , Content-Based , Text and Image Handhng , pp 424.-437 , Cambndge , MA , 1988 \ [ 2.5\ ] L Ran , R Brandow , and K Ivhtze Dommnindependent summarization of news In Suramanzmg Text for Intelhgent Commumcatzons , pp 71-75 , Dagstuhl , German~ 1994 \ [ 26\ ] G Salton , A Smghal , C Buckle~andM M~tra Automatic text decompo~tlon using text segments and text themesIn Seventh A CM Conference on Hypertext , Washington , D C , 1996 \ [ 27\ ] K Sparck Jones Discourse modelling for automatic text summansmg Techmcal Report 290 , Umverslty of Cambridge Computer Laborator~ 1993 \ [ 28\ ] K Sparck Jones What might be m a surnmary~ ' In Knorz , Krause , and Womaer-Hacker , eds , Informatton Retrieval 93 Von der Modelherung zur Anwendung , pp 9-26 , Umversltatsverlag Konstanz , 1993 \ [ 29\ ] J Trot Automatzc summansmg of Enghsh texts PhD thesis , Umverslty of Cambridge Computer Laboratory , Cambndge , UK , 1983 Technical Report 47</sentence>
				<definiendum id="0">J Pustejovsk~</definiendum>
				<definiens id="0">Defense Advanced Research Prolects Agency Fourth Message Understanding Conference ( MUC-4 ) , McLean , VlrgTaua , 1992 Software and Intelhgent Systems Technology Office \ [ 7\ ] G DeJong An over , new of the FRUMP system In • W Lehnert and M Rmgle , editors , Strategies for Natural Language Parsing , pp 149-176 Lawrence Eftbaum Assocmtes</definiens>
				<definiens id="1">eeds , Corpus Processing for Lexlcal Acqu~sztum , pp 41-59 MIT Press , Cambridge , MA , 1996 M M McCord Slot grammar a system for sunpler construction of practical natural language grammars In R Studer , ed , Natural language and lbgnc mternatwnal sc~enhJic sympos</definiens>
			</definition>
</paper>

		<paper id="1507">
</paper>

		<paper id="0618">
			<definition id="0">
				<sentence>speechact_showpath \ ] OBJECT \ [ \ ] obj_pathJ \ [ \ ] obj_path Figure 6 : The representation on the semantic level after having processed the utterance show me how to get to the museum with a misrecognition on the museum .</sentence>
				<definiendum id="0">OBJECT</definiendum>
				<definiens id="0">The representation on the semantic level after having processed the utterance show me how to get to the museum with a misrecognition on the museum</definiens>
			</definition>
</paper>

		<paper id="0127">
			<definition id="0">
				<sentence>The pel-plexity , which is the inverse of the probability over the whole text , is measured .</sentence>
				<definiendum id="0">pel-plexity</definiendum>
			</definition>
			<definition id="1">
				<sentence>where P ( x , ) and P ( x , ) are the probabilities of the events , and P ( x , ,x2 ) is the probability of the joint event .</sentence>
				<definiendum id="0">P (</definiendum>
				<definiens id="0">the probability of the joint event</definiens>
			</definition>
			<definition id="2">
				<sentence>Let C , , C\ ] be the classes , i.j= 0,1.2 ... .. N ; N denotes the number of classes .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of classes</definiens>
			</definition>
			<definition id="3">
				<sentence>Mutual information can be explained as : the ability of dispelling the uncertainty of information source .</sentence>
				<definiendum id="0">Mutual information</definiendum>
				<definiens id="0">the ability of dispelling the uncertainty of information source</definiens>
			</definition>
			<definition id="4">
				<sentence>And let Ptr ( Cilwl ) , Plr ( Cilw2 ) , Prt ( O/\ [ w , ) amLd Prl ( Ojlw2 ) be the probabilities of words w I and w 2 contained in classes C , and C~ in the left-right and right-left trees respectively .</sentence>
				<definiendum id="0">amLd Prl</definiendum>
				<definiens id="0">the left-right and right-left trees respectively</definiens>
			</definition>
			<definition id="5">
				<sentence>( w , w , ) P , ~ ( C , lw , ) log wGl '' where V is the vocabulary .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the vocabulary</definiens>
			</definition>
			<definition id="6">
				<sentence>Perplexity ( Jelinek , 1990a ; McCandless,1994 ; ) is an informationtheoretic measure for evaluating how well a statistical language model predicts a particular test set .</sentence>
				<definiendum id="0">Perplexity</definiendum>
				<definiens id="0">an informationtheoretic measure for evaluating how well a statistical language model predicts a particular test set</definiens>
			</definition>
			<definition id="7">
				<sentence>N is the number of words in the corpus .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of words in the corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>N is the number of words in the training corpus .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of words in the training corpus</definiens>
			</definition>
			<definition id="9">
				<sentence>The SPHINX-II Speech Recognition System : An Overview .</sentence>
				<definiendum id="0">SPHINX-II Speech Recognition System</definiendum>
				<definiens id="0">An Overview</definiens>
			</definition>
			<definition id="10">
				<sentence>Adaptive Statistical Language Modeling : A Maximum Entropy Aproach .</sentence>
				<definiendum id="0">Adaptive Statistical Language Modeling</definiendum>
				<definiens id="0">A Maximum Entropy Aproach</definiens>
			</definition>
</paper>

		<paper id="1305">
			<definition id="0">
				<sentence>Processing In natural language processing in general , the robustness issue comprises the ability of a software system to cope with input that gives rise to deficient descriptions at some descriptional layerJ More or less implicit is the assumption that the system exhibits some kind of monotonic behaviour : the less deficient the description , the higher the quality of the output ( Menzel , 1995 ) .</sentence>
				<definiendum id="0">robustness issue</definiendum>
			</definition>
			<definition id="1">
				<sentence>where binding category denotes the next dominator containing some kind of subject ( Chomsky , 1981 ) , and binding is defined as coindexed and ccommanding : Definition 2 ( thec-command relation ) Surface structure node X c-commands node Y if and only if the next `` branching node '' which dominates X also dominates Y and neither X dominates Y , Y dominates X nor X = Y. A further structural well-formedness condition , commonly named i-within-i filter , rules out `` referentially circular '' coindexings , i.e. configurations matching the pattern \ [ c~ ... Ill ... \ ] i\ ] i. In the above example , the latter restriction comes to an application , licensing a coindexing of telescope and it only if the PP containing it is not interpreted as an attribute to telescope otherwise , in contradiction to the i-within-i condition , the pronoun would be contained in the NP of the tentative antecedent .</sentence>
				<definiendum id="0">binding category</definiendum>
			</definition>
			<definition id="2">
				<sentence>Based on a suitable corpus annotated with syntactic and referential information , it should be possible to determine probthe branching node dominating X according to the ccommand definition ; the subscript of Xtypev denotes that the binding theoretic class of the occurrence contributed by X is Y E { A , B , C } , e.g. P , yp~ s is a pronominal .</sentence>
				<definiendum id="0">yp~ s</definiendum>
			</definition>
			<definition id="3">
				<sentence>Given a PSF T with nodes V = { vl , ... , Vk } , let P ( vl ) , ... , P ( Vk ) be the respective derivation variants according to packing .</sentence>
				<definiendum id="0">, P ( Vk</definiendum>
				<definiens id="0">Given a PSF T with nodes V = { vl , ... , Vk } , let P ( vl ) , ...</definiens>
			</definition>
			<definition id="4">
				<sentence>The outermost vector disjunction sums over the derivation variants P ( vi ) which , due to packing , exist for the interior node vi .</sentence>
				<definiendum id="0">outermost vector disjunction</definiendum>
				<definiens id="0">sums over the derivation variants P ( vi ) which , due to packing , exist for the interior node vi</definiens>
			</definition>
			<definition id="5">
				<sentence>Vectors l~l ( vi , vo ) , which characterize the readings in which vi locally dominates Vo , are computed similarly .</sentence>
				<definiendum id="0">Vectors l~l</definiendum>
				<definiens id="0">characterize the readings in which vi locally dominates Vo , are computed similarly</definiens>
			</definition>
			<definition id="6">
				<sentence>For this purpose , during anaphor resolution , each pair of anaphor a and antecedent candidate '7 ( identified with the corresponding preterminal nodes ) is assigned a vector g ( a , ,7 ) characterizing the readings under which a 9Upon fixation of a particular encoding scheme for reading characterization , vectors lY ( P ( vi ) , m ) may be computed according to a simple formula .</sentence>
				<definiendum id="0">vector g</definiendum>
				<definiens id="0">characterizing the readings under which a 9Upon fixation of a particular encoding scheme for reading characterization , vectors lY ( P ( vi ) , m ) may be computed according to a simple formula</definiens>
			</definition>
			<definition id="7">
				<sentence>Here , these vectors characterize the subset of readings in which the property of being a branching node relatively to node x holds for v. The strong ( constructive ) and weak ( unconstructive ) verification of binding princi~es is accompl~hed by a conjunction with vectors bps ( v , a ) and bpw ( v , '7 ) , respectively , which , depending on the applicable binding principle , exploit the reading-qualified domination information : b s ( vl , v ) : = { The sole difference between l~l ( vl , v2 ) , if bttype ( v2 ) = A /d ( Vl , v2 ) , if bttype ( v2 ) -B a~d ( vl , v2 ) , if bttype ( v2 ) = C ( 1 , ... , 1 ) , if bttype ( v2 ) -A l~l ( Vl , v2 ) , if bttype ( v2 ) = B ad ( Vl , v2 ) , if bttype ( v2 ) = C the strong and the week 35 ( a ) Verify morphosyntactic or lexical agreement with `` 7 ( b ) If the antecedent candidate `` 7 is intrasentential : by checking that F ' ( a , 5 ' ) ¢ ( 0 , - .</sentence>
				<definiendum id="0">strong</definiendum>
				<definiendum id="1">v2 ) -B a~d</definiendum>
				<definiens id="0">if bttype ( v2 ) = B ad</definiens>
			</definition>
			<definition id="8">
				<sentence>The reading compatibility is verified by the stepwise computation of vector ~.11 A theoretical analysis shows that , under the assumption of a clever organization of the computation , the number of bitvector conjunctions and disjunctions ( including dominance vector determination ) is bounded by O ( bq 2 + s ) , where q is the number of occurrence contributing NPs , s denotes the size of the PSF , and b stands for the maximal degree of branching due to packing and sharing .</sentence>
				<definiendum id="0">reading compatibility</definiendum>
				<definiendum id="1">q</definiendum>
				<definiens id="0">verified by the stepwise computation of vector ~.11 A theoretical analysis shows that , under the assumption of a clever organization of the computation</definiens>
				<definiens id="1">the size of the PSF , and b stands for the maximal degree of branching due to packing and sharing</definiens>
			</definition>
</paper>

		<paper id="0413">
			<definition id="0">
				<sentence>To make 'ageru ' and 'give ' interchangeable , a rule such as ageru ( E ) ~ give ( E ) is suffice , where E is an event .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">an event</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>The Rule Generalization routines , with the help of WordNet 1 , generalize the specific rules generated by the Training Process .</sentence>
				<definiendum id="0">Rule Generalization routines</definiendum>
				<definiens id="0">generalize the specific rules generated by the Training Process</definiens>
			</definition>
			<definition id="1">
				<sentence>The output of the Scanning Process , for each article , is a semantic network ( Quillian , 1968 ) for that article which can then be used by a Postprocessor to fill templates , answer queries , or generate abstracts .</sentence>
				<definiendum id="0">Scanning Process</definiendum>
			</definition>
			<definition id="2">
				<sentence>WordNet is an on-line lexical reference system in which English nouns , verbs , and adjectives are organized into synonym sets ( synsets ) , each representing one underlying lexical concept ( meaning or sense ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">an on-line lexical reference system in which English nouns , verbs , and adjectives are organized into synonym sets ( synsets ) , each representing one underlying lexical concept ( meaning or sense )</definiens>
			</definition>
			<definition id="3">
				<sentence>WordNet contains approximately 95,600 word forms organized into some 70,100 synsets ( Miller , 1990 ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="4">
				<sentence>In addition , WordNet attempts to organize different senses of a word based on the frequency of usage of the senses .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="5">
				<sentence>The Tokenizer accepts ASCII characters as input and produces a stream of tokens ( words ) as output .</sentence>
				<definiendum id="0">Tokenizer</definiendum>
				<definiens id="0">accepts ASCII characters as input and produces a stream of tokens ( words ) as output</definiens>
			</definition>
			<definition id="6">
				<sentence>The Partial Parser accepts the word stack produced by the Preprocessor as input and produces a sequence of non-overlapping phrases as output .</sentence>
				<definiendum id="0">Partial Parser</definiendum>
				<definiens id="0">accepts the word stack produced by the Preprocessor as input and produces a sequence of non-overlapping phrases as output</definiens>
			</definition>
			<definition id="7">
				<sentence>The Partial Parser is a finite-state parser and is largely borrowed from SRI 's FASTUS system ( Hobbs , 1993 ) .</sentence>
				<definiendum id="0">Partial Parser</definiendum>
			</definition>
			<definition id="8">
				<sentence>The Training Process yields a collection of training-article-specific rules which are then generalized by the Rule Generalization routines .</sentence>
				<definiendum id="0">Training Process</definiendum>
			</definition>
			<definition id="9">
				<sentence>Therefore , the Sense Classifier determines the senses of the headwords of the phrases based on the SenseUsage Table built during the Training Process .</sentence>
				<definiendum id="0">Sense Classifier</definiendum>
				<definiens id="0">determines the senses of the headwords of the phrases based on the SenseUsage Table built during the Training Process</definiens>
			</definition>
			<definition id="10">
				<sentence>RELATION operation by identifying IBM Corporation , and job candidates as the two nodes , and seeks as the transition connecting the nodes .</sentence>
				<definiendum id="0">RELATION operation</definiendum>
			</definition>
			<definition id="11">
				<sentence>NODE ( IBM Corporation ) , ADD_NODE ( candidate ) , ADD__RELATION ( seek , IBM Corporation , candidate ) Figure 3 : A Sample Rule ( Wl , el , Sl , tl ) , ( W2 , e2 , 82 , t2 ) , ( ~3 , c3 , 83 , $ 3 ) ADD_NODE ( wx ) , ADD_NODE ( w3 ) , ADD_RELATION ( w2 , wl , w3 ) Figure 4 : An Abstract Specific Rule sp = ( w , e , s , t ) , where w is the headword of the trained phrase , c is the part of the speech of the word , s is the sense number representing the meaning of w , t is the semantic type identified by the preprocessor for w. An abstract specifi c rule is shown in Figure 4 .</sentence>
				<definiendum id="0">NODE ( IBM Corporation</definiendum>
				<definiendum id="1">IBM Corporation</definiendum>
				<definiendum id="2">Sample Rule</definiendum>
				<definiendum id="3">w</definiendum>
				<definiendum id="4">c</definiendum>
				<definiens id="0">the sense number representing the meaning of w</definiens>
			</definition>
			<definition id="12">
				<sentence>sp = ( IBM Corporation , NG , 1 , company ) generalized at degree 1 Generalize ( sp , 1 ) = { business , concem } generalized at degree 2 Generalize ( sp , 2 ) = { enterprise } generalized at degree 3 Generalize ( sp , 3 ) = { organization } generalized at degree 5 Generalize ( sp , 5 ) = { group , social group } Figure 5 : Degrees of Generalization for a Specific Concept The process of generalizing rules consists of replacing each sp = ( w , e , s , t ) in the specific rules by a more general superordinate synset from its hypernym tree in WordNet by performing the Generalize ( sp , h ) function .</sentence>
				<definiendum id="0">IBM Corporation</definiendum>
				<definiens id="0">Degrees of Generalization for a Specific Concept The process of generalizing rules consists of replacing each sp = ( w , e , s , t</definiens>
			</definition>
			<definition id="13">
				<sentence>The Scanning Process consists of the following steps : • Parse the unseen article and segment it into phrases belonging to one of NG , VG , or PG ( c , ) .</sentence>
				<definiendum id="0">Scanning Process</definiendum>
				<definiens id="0">consists of the following steps : • Parse the unseen article and segment it into phrases belonging to one of NG , VG , or PG ( c , )</definiens>
			</definition>
			<definition id="14">
				<sentence>Use the Sense Classifier ( as described in Section 2.5.1 to assign the appropriate sense ( Si ) to each headword .</sentence>
				<definiendum id="0">Use the Sense Classifier</definiendum>
				<definiendum id="1">Si</definiendum>
				<definiens id="0">described in Section 2.5.1 to assign the appropriate sense</definiens>
			</definition>
			<definition id="15">
				<sentence>Introduction to WordNet : An On-Line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0503">
			<definition id="0">
				<sentence>The Compansion prototype contains three processing modules and requires a great deal of lexical knowledge : Word Order Parser encodes a loose grammar of telegraphic sentences and determines and attaches modifiers ( e.g. , 3 is an adjective which is modifying watch ) , determines part of speech information ( e.g. , think is a verb , watch is a noun ) , and passes sentence sized chunks to the next phase of processing ( e.g. , first 3 watch give John Andrew would be passed on to the next phase , and then Mary thinks with the result of the previous processing ) .</sentence>
				<definiendum id="0">Compansion prototype</definiendum>
				<definiendum id="1">watch</definiendum>
				<definiens id="0">contains three processing modules and requires a great deal of lexical knowledge : Word Order Parser encodes a loose grammar of telegraphic sentences and determines</definiens>
				<definiens id="1">an adjective which is modifying watch ) , determines part of speech information</definiens>
				<definiens id="2">a verb</definiens>
				<definiens id="3">a noun ) , and passes sentence sized chunks to the next phase of processing</definiens>
			</definition>
			<definition id="1">
				<sentence>Sentence Generator creates an actual English sentence from the semantic representation ( E1hadad , 1991 ) .</sentence>
				<definiendum id="0">Sentence Generator</definiendum>
			</definition>
			<definition id="2">
				<sentence>In conjunction with the Prentke Romich Company ( PRC ) ( a well known communication device manufacturer ) we have been working on developing a pared-down version of Compansion for people with cognitive impairments ( McCoy et al. , 1997 ) .</sentence>
				<definiendum id="0">PRC )</definiendum>
			</definition>
			<definition id="3">
				<sentence>The speech output communication aids that PRC designs for commercial use incorporate an encoding technique called semantic compaction , commercially known as Minspeak R ( a contraction of the phrase `` minimum effort speech '' ) ( Baker , 1982 ) , ( Baker , 1984 ) .</sentence>
				<definiendum id="0">speech output communication aids</definiendum>
				<definiens id="0">commercial use incorporate an encoding technique called semantic compaction</definiens>
			</definition>
			<definition id="4">
				<sentence>The success of the general Minspeak R paradigm of vocabulary access led PRC to start designing tailored prestored vocabulary programs known as Minspeak Application Programs ( MAPs TM ) for specific populations of users .</sentence>
				<definiendum id="0">success of</definiendum>
				<definiendum id="1">Minspeak Application Programs ( MAPs TM )</definiendum>
				<definiens id="0">the general Minspeak R paradigm of vocabulary access led PRC to start designing tailored prestored vocabulary programs known as</definiens>
			</definition>
</paper>

		<paper id="1402">
			<definition id="0">
				<sentence>For a long time , face-to-face communication has been considered a reliable model for natural language based human-computer interaction ( hencepirical work is available on what actually happens in multimodal HCI and how communication features cohabit with modern graphical interfaces ( Oviatt , 1996 ; De Angeli et al. , 1996 ; Oviatt et al. , 1997 ; Siroux et al. , 1995 ) .</sentence>
				<definiendum id="0">human-computer interaction</definiendum>
				<definiens id="0">available on what actually happens in multimodal HCI and how communication features cohabit with modern graphical interfaces</definiens>
			</definition>
			<definition id="1">
				<sentence>Each user question was tabulated in one of the following five categories according to the referent identification strategy adopted in it : • direct naming : it is a unimodal reference and occurs when the field label is explicitly used in the utterance , e.g. , il campo dati anagrafici ( the personal data field ) ; • language reference : it is a unimodal reference and occurs whenever the field is referred by a pure verbal input , but without direct naming , e.g. , l'ultimo campo ( the last field ) .</sentence>
				<definiendum id="0">e.g. , l'ultimo campo</definiendum>
				<definiens id="0">the personal data field ) ; • language reference : it is a unimodal reference and occurs whenever the field is referred by a pure verbal input , but without direct naming ,</definiens>
			</definition>
			<definition id="2">
				<sentence>This category includes , among others , anaphoric reference and metonymia ; • deixis : it is a multimodal reference that occurs whenever an explicit anchor ( deictic linguistic expression ) for the pointing exists , e.g. , questo , ,2 campo ( this/2 field ) ; • mixed : it is a multimodal reference that occurs when the reference contains both linguistic and gestural part , but no deictic mark can be found in the utterance , e.g. , in/z ( in ,7 ) ; • redundant : it is a multimodal reference ; it occurs when one component ( or part of it ) is not needed for the understanding , e.g. , il campo A /2 ( the field A/2 ) .</sentence>
				<definiendum id="0">il campo A /2</definiendum>
				<definiens id="0">a multimodal reference that occurs whenever an explicit anchor ( deictic linguistic expression ) for the pointing exists</definiens>
			</definition>
			<definition id="3">
				<sentence>There , the simulated system , called MIS ( Multimodal Intelligent System ) , had a quite different layout : each field had a very short label ( a single letter ) not related to the required content of the field ( figure 3 ) .</sentence>
				<definiendum id="0">MIS</definiendum>
			</definition>
</paper>

		<paper id="0802">
			<definition id="0">
				<sentence>GermaNet is a broad-coverage lexical-semantic net for German which currently contains some 16.000 words and alms at modeling at least the base vocabulary of German .</sentence>
				<definiendum id="0">GermaNet</definiendum>
				<definiens id="0">a broad-coverage lexical-semantic net for German which currently contains some 16.000 words and alms at modeling at least the base vocabulary of German</definiens>
			</definition>
			<definition id="1">
				<sentence>10 For verbs , WordNet makes the assumption that the relation of entailment holds in two different situations .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">makes the assumption that the relation of entailment holds in two different situations</definiens>
			</definition>
			<definition id="2">
				<sentence>I Figure 5 : Regular Polysemy Cross-Classification as To allow for regular polysemy , GermaNet introduces a special bidirectional relator which is placed to the top concepts for which the regular polysemy holds ( c.f. figure 6 ) .</sentence>
				<definiendum id="0">GermaNet</definiendum>
			</definition>
			<definition id="3">
				<sentence>ooo-.0 Figure 3 : Proper Artificial Concepts Ior za '' on I F regular polysemy pointer I I i depository financial institufionl bankl , banking concern , \ [ banking company | L I I I I I Figure 6 : Regular Polysemy Pointer banking company , which are not synonyms of banks ( a building in which commercial banking is transacted ) .</sentence>
				<definiendum id="0">banks</definiendum>
				<definiens id="0">Proper Artificial Concepts Ior za '' on I F regular polysemy pointer</definiens>
			</definition>
			<definition id="4">
				<sentence>GermaNet provides frames for verb senses , rather than for lemmas , implying a full disambiguation of the CELEX complementation codes for GermaNet .</sentence>
				<definiendum id="0">GermaNet</definiendum>
				<definiendum id="1">CELEX complementation codes</definiendum>
				<definiens id="0">provides frames for verb senses</definiens>
			</definition>
			<definition id="5">
				<sentence>As compatibility with the Princeton WordNet and EuroWordNet is a major construction criteria of GermaNet , German can now , finally , be integrated into multilingual large-scale projects based on ontological and conceptual information .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
				<definiens id="0">a major construction criteria of GermaNet , German can now , finally , be integrated into multilingual large-scale projects based on ontological and conceptual information</definiens>
			</definition>
</paper>

		<paper id="1101">
			<definition id="0">
				<sentence>In the context of PFSA , the MML is a sum of : • the length of encoding a description of the proposed machine • the length of encoding the dataset assuming it was emitted by the proposed machine The following formula is used for the purpose of computing the MML : N 1 ) !</sentence>
				<definiendum id="0">MML</definiendum>
				<definiens id="0">a sum of : • the length of encoding a description of the proposed machine • the length of encoding the dataset</definiens>
			</definition>
			<definition id="1">
				<sentence>where N is the number of states in the PFSA , tj is the number of times the jth state is visited , V is the cardinality of the alphabet including the delimiter symbol , nij the frequency of the ith arc from the jth state , mj is the number of different arcs from the jth state and m } is the number of different arcs on non-delimiter symbols from the jth state .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">tj</definiendum>
				<definiendum id="2">V</definiendum>
				<definiendum id="3">mj</definiendum>
				<definiens id="0">the cardinality of the alphabet including the delimiter symbol</definiens>
			</definition>
			<definition id="2">
				<sentence>The logs are to the base 2 and the MML is in bits .</sentence>
				<definiendum id="0">MML</definiendum>
				<definiens id="0">in bits</definiens>
			</definition>
</paper>

		<paper id="0607">
			<definition id="0">
				<sentence>Learnability measures how easily subjects could learn to communicate with the machine .</sentence>
				<definiendum id="0">Learnability</definiendum>
				<definiens id="0">measures how easily subjects could learn to communicate with the machine</definiens>
			</definition>
			<definition id="1">
				<sentence>TINA used probabilistic networks and semantic filtering to reduce perplexity .</sentence>
				<definiendum id="0">TINA</definiendum>
				<definiens id="0">used probabilistic networks and semantic filtering to reduce perplexity</definiens>
			</definition>
			<definition id="2">
				<sentence>Utterances/Correctly Processed Queries This measures how well a system processed utterances in isolation , but does not give the complete picture of system performance in a dialog where utterances are related through context .</sentence>
				<definiendum id="0">Utterances/Correctly Processed Queries This</definiendum>
				<definiens id="0">measures how well a system processed utterances in isolation</definiens>
			</definition>
			<definition id="3">
				<sentence>Robustness was measured in terms of how infrequently a system crashed .</sentence>
				<definiendum id="0">Robustness</definiendum>
			</definition>
</paper>

		<paper id="1307">
			<definition id="0">
				<sentence>( b ) Nondestructive Option : RECORD the antecedent entity list in the anaphoric entity to allow reordering ( i.e. , preference revisions ) by event merging or overall model selection .</sentence>
				<definiendum id="0">Nondestructive Option</definiendum>
				<definiens id="0">RECORD the antecedent entity list in the anaphoric entity to allow reordering ( i.e. , preference revisions</definiens>
			</definition>
			<definition id="1">
				<sentence>name , IF it is an alias or acronym of another name already recognized in the given text , MERGE the two -- an alias is a selective substring of the full name ( e.g. , Colonial for Colonial Bee ) ~ , and acronym is a selective sequence of initial characters in the full name ( e.g. , GM for General Motors ) .</sentence>
				<definiendum id="0">alias</definiendum>
				<definiendum id="1">acronym</definiendum>
			</definition>
			<definition id="2">
				<sentence>cal roles and head-argument and head-adjunct relations noncoreference and gender features rocals role , grammatical parallelism , frequency of mention , proximity , and sentence recency ( NPs ) in equivalence classes ( with seven salience factors ) preferred candidate antecedents Kennedy and Boguraev ( 1996 ) approximated the above components with a poorer syntactic input , which is an output of a part-of-speech tagger with grammatical function information , plus NPs recognized by finite-state patterns and NPs ' adjunct and subordination contexts recognized by heuristics .</sentence>
				<definiendum id="0">NPs</definiendum>
				<definiens id="0">grammatical parallelism , frequency of mention , proximity , and sentence recency ( NPs ) in equivalence classes ( with seven salience factors</definiens>
				<definiens id="1">an output of a part-of-speech tagger with grammatical function information , plus NPs recognized by finite-state patterns and</definiens>
			</definition>
			<definition id="3">
				<sentence>Index subscripts ( such as 4a ) indicate subset , part , or membership of another expression ( e.g. , indexed 4 ) .</sentence>
				<definiendum id="0">Index subscripts</definiendum>
			</definition>
</paper>

		<paper id="0117">
			<definition id="0">
				<sentence>The Correction Box consists of a text alignment program , a correction-rule generator , and a series of rule application and verification steps .</sentence>
				<definiendum id="0">Correction Box</definiendum>
				<definiens id="0">consists of a text alignment program , a correction-rule generator , and a series of rule application and verification steps</definiens>
			</definition>
			<definition id="1">
				<sentence>The main goal of the C-Box approach is to generate a collection of context-sensitive text-based correction rules , in the form of xt , Y = xq~¥ , where X and Y are context word patterns , L is a word pattern in an erroneous transcription string , and R is a replacement string correcting transcription errors in L. In order to generate the correction rules we require both training and validation steps to optimize the C-Box performance with respect to a specific sublanguage as well as a speaker or a group of speakers .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a word pattern in an erroneous transcription string</definiens>
			</definition>
			<definition id="2">
				<sentence>Therefore , the C-Box approach consists of the following sub-processes : ( 1 ) collecting training data , ( 2 ) aligning text samples , ( 3 ) generating correction rules , ( 4 ) validating correction rules , and ( 5 ) applying correction rules .</sentence>
				<definiendum id="0">C-Box approach</definiendum>
				<definiens id="0">consists of the following sub-processes : ( 1 ) collecting training data</definiens>
			</definition>
			<definition id="3">
				<sentence>Misalignect sections give rise to preliminary context-free string replacement `` rules '' , L = R , where L is a section in the ASR output , and R is the corresponding section of the true manmercial Radiologyncology spell-checker .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">the corresponding section of the true manmercial Radiology/Oncology spell-checker</definiens>
			</definition>
			<definition id="4">
				<sentence>If such a feature or features are found , they will be used to restate t , =~ R as a context-sensitive rule , XLY = XRY , where X and Y are context features .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a context-sensitive rule</definiens>
			</definition>
			<definition id="5">
				<sentence>Chest X-ray is the most prevalent form of radiology , and we decided to start with this sub-area because of its the largest potential practical significance .</sentence>
				<definiendum id="0">Chest X-ray</definiendum>
				<definiens id="0">the most prevalent form of radiology</definiens>
			</definition>
</paper>

		<paper id="1312">
			<definition id="0">
				<sentence>Several documents ( user 's guides ) , with an overall length of 40 000 words , served as an initial evaluation corpus .</sentence>
				<definiendum id="0">Several documents</definiendum>
				<definiens id="0">with an overall length of 40 000 words , served as an initial evaluation corpus</definiens>
			</definition>
</paper>

		<paper id="0206">
			<definition id="0">
				<sentence>Evidence indicates that taggers selecting senses from a list ordered by frequency of occurrence , where salient , core senses are found at the beginning of the entry , use a different strategy than taggers working with a randomly ordered list of senses .</sentence>
				<definiendum id="0">Evidence</definiendum>
				<definiens id="0">taggers working with a randomly ordered list of senses</definiens>
			</definition>
			<definition id="1">
				<sentence>Semantic tagging is the inverse of lexicography , in that taggers identify and interpret dictionary entries with respect to words occurring in a text .</sentence>
				<definiendum id="0">Semantic tagging</definiendum>
				<definiens id="0">the inverse of lexicography , in that taggers identify and interpret dictionary entries with respect to words occurring in a text</definiens>
			</definition>
			<definition id="2">
				<sentence>Taggers , like lexicographers , first interpret the target word in the text , and then match the meaning they have identified for a given occurrence of a polysemous word with one of several dictionary senses .</sentence>
				<definiendum id="0">Taggers</definiendum>
				<definiens id="0">interpret the target word in the text , and then match the meaning they have identified for a given occurrence of a polysemous word with one of several dictionary senses</definiens>
			</definition>
			<definition id="3">
				<sentence>In C. Fellbaum , editor , WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="4">
				<sentence>Wordnet : An on-line lexical database .</sentence>
				<definiendum id="0">Wordnet</definiendum>
				<definiens id="0">An on-line lexical database</definiens>
			</definition>
</paper>

		<paper id="0601">
			<definition id="0">
				<sentence>• Explicit Recovery : the proportion of explicit recovery utterances made by both the system system turn correction ( STC ) , and the user , user turn correction ( UTC ) .</sentence>
				<definiendum id="0">STC</definiendum>
				<definiens id="0">the proportion of explicit recovery utterances made by both the system system turn correction</definiens>
			</definition>
			<definition id="1">
				<sentence>PARADISE uses linear regression to quantify the relative contribution of the success and cost factors to user satisfaction .</sentence>
				<definiendum id="0">PARADISE</definiendum>
				<definiens id="0">uses linear regression to quantify the relative contribution of the success and cost factors to user satisfaction</definiens>
			</definition>
			<definition id="2">
				<sentence>PARADISE uses an attribute value matrix ( AVM ) to represent dialogue tasks .</sentence>
				<definiendum id="0">PARADISE</definiendum>
				<definiens id="0">uses an attribute value matrix</definiens>
			</definition>
			<definition id="3">
				<sentence>The AVM consists of the information that must be exchanged between the agent and the user during the dialogue , represented as a set of ordered pairs of attributes and their possible values .</sentence>
				<definiendum id="0">AVM</definiendum>
				<definiens id="0">consists of the information that must be exchanged between the agent and the user during the dialogue , represented as a set of ordered pairs of attributes and their possible values</definiens>
			</definition>
			<definition id="4">
				<sentence>Success at the task for a whole dialogue ( or subdialogue ) is measured by how well the agent and user achieve the information requirements of the task by the end of the dialogue ( or subdialogue ) .</sentence>
				<definiendum id="0">subdialogue )</definiendum>
				<definiens id="0">measured by how well the agent and user achieve the information requirements of the task by the end of the dialogue ( or subdialogue )</definiens>
			</definition>
			<definition id="5">
				<sentence>Whenever an attribute value in a dialogue ( i.e. , data ) AVM matches the value in its scenario key , the number in the appropriate diagonal cell of the matrix ( boldface for clarity ) is incremented by 1 .</sentence>
				<definiendum id="0">AVM</definiendum>
				<definiens id="0">matches the value in its scenario key , the number in the appropriate diagonal cell of the matrix</definiens>
			</definition>
			<definition id="6">
				<sentence>Given a confusion matrix M , success at achieving the information requirements of the task is measured with the Kappa coefficient ( Carletta , 1996 ; Siegel and Castellan , 1988 ) : P ( A ) P ( Z ) 1 P ( z ) P ( A ) is the proportion of times that the AVMs for the actual set of dialogues agree with the AVMs for the scenario keys , and P ( E ) is the proportion of times that the AVMs for the dialogues and the keys are expected to agree by chance .</sentence>
				<definiendum id="0">Kappa coefficient</definiendum>
				<definiens id="0">the proportion of times that the AVMs for the actual set of dialogues agree with the AVMs for the scenario keys</definiens>
				<definiens id="1">the proportion of times that the AVMs for the dialogues and the keys are expected to agree by chance</definiens>
			</definition>
			<definition id="7">
				<sentence>In particular : i=1 where ti is the sum of the frequencies in column i of M , and T is the sum of the frequencies in M ( tl + ... + tn ) .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the sum of the frequencies in M ( tl + ... + tn )</definiens>
			</definition>
			<definition id="8">
				<sentence>Multiple linear regression produces a set of coefficients ( weights ) describing the relative contribution of each predictor factor in accounting for the variance in a predicted factor .</sentence>
				<definiendum id="0">Multiple linear regression</definiendum>
				<definiens id="0">produces a set of coefficients ( weights ) describing the relative contribution of each predictor factor in accounting for the variance in a predicted factor</definiens>
			</definition>
			<definition id="9">
				<sentence>The PARADISE methodology consists of the following steps : • definition of a task and a set of scenarios ; • specification of the AVM task representation ; • experiments with alternate dialogue agents for the task ; • calculation of user satisfaction using surveys ; • calculation of task success using to ; • calculation of dialogue cost using efficiency and qualitative measures ; • estimation of a performance function using linear regression and values for user satisfaction , x and dialogue costs ; • comparison with other agents/tasks to determine which factors that are most strongly weighted in the performance function generalize as important factors in other applications ; • refinement of the performance model .</sentence>
				<definiendum id="0">PARADISE methodology</definiendum>
				<definiens id="0">consists of the following steps : • definition of a task and a set of scenarios ; • specification of the AVM task representation ; • experiments with alternate dialogue agents for the task ; • calculation of user satisfaction using surveys</definiens>
				<definiens id="1">user satisfaction , x and dialogue costs ; • comparison with other agents/tasks to determine which factors that are most strongly weighted in the performance function generalize as important factors in other applications ; • refinement of the performance model</definiens>
			</definition>
</paper>

		<paper id="0616">
			<definition id="0">
				<sentence>The project consists of two stages : for the first stage a basic command &amp; control language is defined consisting of about 70 keywords , which essentially encompasses the functionalities of the current system ( selecting a device : `` navigation '' , `` tuner '' , choosing a destination , making phone calls , etc. ) , as well as dialogue control keywords ( `` no '' , `` OK '' , `` abort '' , etc. ) .</sentence>
				<definiendum id="0">project</definiendum>
				<definiens id="0">consists of two stages : for the first stage a basic command &amp; control language is defined consisting of about 70 keywords , which essentially encompasses the functionalities of the current system ( selecting a device : `` navigation ''</definiens>
			</definition>
			<definition id="1">
				<sentence>Commandment Iv stresses the importance of error-prevention ( IV .</sentence>
				<definiendum id="0">Commandment Iv</definiendum>
			</definition>
</paper>

		<paper id="1203">
			<definition id="0">
				<sentence>Definition : A noun phrase or a pronoun used in the nominative case PP ( Prepositionl Phrase ) Example : Der Zug f~hrt nach Ulna .</sentence>
				<definiendum id="0">Definition</definiendum>
				<definiens id="0">A noun phrase or a pronoun used in the nominative case PP ( Prepositionl Phrase ) Example : Der Zug f~hrt nach Ulna</definiens>
			</definition>
			<definition id="1">
				<sentence>Definition : A prepositional phrase AP ( Adverbial Phrase ) Examples : morgen friih ; Der Zug f~ihrt jeden Tag .</sentence>
				<definiendum id="0">Definition</definiendum>
				<definiens id="0">A prepositional phrase AP ( Adverbial Phrase ) Examples : morgen friih ; Der Zug f~ihrt jeden Tag</definiens>
			</definition>
			<definition id="2">
				<sentence>Definition : A conjunction together with the following syntactic segment V ( Verb ) Example : Der Zug f~ihrt .</sentence>
				<definiendum id="0">Definition</definiendum>
			</definition>
			<definition id="3">
				<sentence>Definition : An isolated inflected verb in a main clause VP ( Verb Phrase ) Examples : ... , ob man f~hren kann ; ... , ob der Zug f'~ihrt Definition : A complete verb phrase if all words are contiguous or an isolated inflected verb in a subordinate clause Other Once the atomic groups have been determined , it is necessary to specify how these groups are logically connected to each other .</sentence>
				<definiendum id="0">Definition</definiendum>
				<definiens id="0">An isolated inflected verb in a main clause VP ( Verb Phrase ) Examples : ... , ob man f~hren kann ; ... , ob der Zug f'~ihrt Definition : A complete verb phrase if all words are contiguous or an isolated inflected verb in a subordinate clause Other Once the atomic groups have been determined</definiens>
			</definition>
			<definition id="4">
				<sentence>E.g. , if the noun phrase `` the man '' has been articulated and it is incrementally extended by an adjective `` young '' , the correction of the articulation consists of the repetition of the whole phrase `` the young man '' .</sentence>
				<definiendum id="0">E.g.</definiendum>
				<definiens id="0">the young man ''</definiens>
			</definition>
</paper>

		<paper id="0809">
			<definition id="0">
				<sentence>SRA ( Krupka , 1995 ) employs a graphical user interface that allows the user to create patterns by identifying the important concepts in the text , as well as the relationships between the concepts .</sentence>
				<definiendum id="0">SRA</definiendum>
				<definiens id="0">employs a graphical user interface that allows the user to create patterns by identifying the important concepts in the text</definiens>
			</definition>
			<definition id="1">
				<sentence>First , it introduces the idea of generalization ; then it describes our Generalization Tree ( GT ) model based on the WordNet and illustrates how GT controls the degree of generalization according to the user 's needs .</sentence>
				<definiendum id="0">Generalization Tree</definiendum>
			</definition>
			<definition id="2">
				<sentence>Other research concerns using WordNet senses to tag large corpus with the lexical semantics for automated word sense disambiguation ( Ng , 1997 ) ( Wiebe et al. , 1997 ) System Our system contains three major processes which , respectively , address training , rule generalization , and the scanning of new information .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">senses to tag large corpus with the lexical semantics for automated word sense disambiguation ( Ng , 1997 ) ( Wiebe et al. , 1997 ) System Our system contains three major processes which , respectively , address training , rule generalization</definiens>
			</definition>
			<definition id="3">
				<sentence>The user , with -- -- -- -- -Braining Process \ [ Scanning Process \ ] Figure 1 : The Use of WordNet in the System 1200 1000 800 600 400 200 0 I I I | sense dtstnbutton 2 3 4 5 6 sense number I I 7 8 Figure 2 : The Sense Distribution the help of a graphical user intefface ( GUI ) scans a parsed sample article and indicates a series of semantic net nodes and transitions that he or she would like to create to represent the information of interest .</sentence>
				<definiendum id="0">Sense Distribution</definiendum>
				<definiens id="0">the help of a graphical user intefface ( GUI ) scans a parsed sample article and indicates a series of semantic net nodes and transitions that he or she would like to create to represent the information of interest</definiens>
			</definition>
			<definition id="4">
				<sentence>The right hand side ( RHS ) of the rule consists of the operations required to create a semantic transitionADD .</sentence>
				<definiendum id="0">right hand side</definiendum>
				<definiendum id="1">RHS</definiendum>
				<definiens id="0">the operations required to create a semantic transitionADD</definiens>
			</definition>
			<definition id="5">
				<sentence>Each entity ( sp ) is a quadruple , in the form of ( w , c , s , t ) , where w is the headword of the trained phrase ; c is the part of the speech of the word ; s is the sense number representing the meaning of w ; t is the semantic type identified by the preprocessor for w. For each sp = ( w , c , s , t ) , if w exists in WordNet , 63 \ [ DCR Inc , NG , 1 , company\ ] , \ [ look .</sentence>
				<definiendum id="0">w</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">a quadruple , in the form of ( w , c , s , t )</definiens>
				<definiens id="1">the headword of the trained phrase</definiens>
				<definiens id="2">the part of the speech of the word ; s is the sense number representing the meaning of w ; t is the semantic type identified by the preprocessor for w. For each sp = ( w , c , s , t</definiens>
			</definition>
			<definition id="6">
				<sentence>Recursive-Seareh algorithm , which is defined as the following : Recursive-Seareh ( coneept x ) { i/ ( ret ( x ) &gt; O ) { put x into Optimal-Concepts set ; exit ; ) else { let m denote the number of children nodes of x ; let x , denote the child of x ( 0 &lt; i _ &lt; m ) ; for ( i = 1 ; i &lt; m ; i++ ) Recursive-Seareh ( x , ) ; ) ; } An experiment is conducted to test the applicability of GT in automatic information extraction .</sentence>
				<definiendum id="0">Recursive-Seareh algorithm</definiendum>
				<definiendum id="1">i++ ) Recursive-Seareh</definiendum>
				<definiens id="0">the following : Recursive-Seareh ( coneept x ) { i/ ( ret ( x ) &gt; O ) { put x into Optimal-Concepts set ; exit ; ) else { let m denote the number of children nodes of x ; let x , denote the child of x ( 0 &lt; i _ &lt; m</definiens>
				<definiens id="1">conducted to test the applicability of GT in automatic information extraction</definiens>
			</definition>
			<definition id="7">
				<sentence>Precision is the number of transitions created which containing position/title information out of the total number of transitions produced by the system ; recall is the number of articles which have been correctly extracted position/title information out of the total number of articles with position/title information .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the number of transitions created which containing position/title information out of the total number of transitions produced by the system ; recall is the number of articles which have been correctly extracted position/title information out of the total number of articles with position/title information</definiens>
			</definition>
			<definition id="8">
				<sentence>The overall performance of recall and precision is defined by F-measurement ( Chinchor , 1992 ) , which is ( /~2 + 1.0 ) • P • R /32*P+R where P is precision , R is recall , /~ = 1 if precision and recall are equally important .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiendum id="1">F-measurement</definiendum>
				<definiendum id="2">P</definiendum>
				<definiendum id="3">R</definiendum>
				<definiens id="0">recall , /~ = 1 if precision and recall are equally important</definiens>
			</definition>
			<definition id="9">
				<sentence>This problem is solved by our Preprocessor , which identifies the proper nouns to be several semantic types , such as company name , software name , city name , and so on .</sentence>
				<definiendum id="0">Preprocessor</definiendum>
				<definiens id="0">identifies the proper nouns to be several semantic types</definiens>
			</definition>
			<definition id="10">
				<sentence>The Generalization Tree algorithm provides a way to make the system adaptable to the user 's needs .</sentence>
				<definiendum id="0">Generalization Tree algorithm</definiendum>
				<definiens id="0">provides a way to make the system adaptable to the user 's needs</definiens>
			</definition>
			<definition id="11">
				<sentence>Introduction to WordNet : An On-Line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0813">
			<definition id="0">
				<sentence>WSD system SENSE ( Self-Expanding linguistic kNowledge-base for Sense Elicitation ) is a specialised version of a general purpose language-learning system ( \ [ Federici and Pirrelli , 1994\ ] ; \ [ Federici et el. , 1996a\ ] ; \ [ Montemagni et al. , 1996\ ] ) for carrying out WSD on the basis of distributional evidence .</sentence>
				<definiendum id="0">WSD system SENSE</definiendum>
				<definiens id="0">a specialised version of a general purpose language-learning system ( \ [</definiens>
			</definition>
			<definition id="1">
				<sentence>SENSE 's inferential routine requires : i ) a structured data set of known word co-occurrence patterns ( WCPs ) constituting an Example Base ( EB ) ; ii ) a target context to be disambiguated ( TC ) ; iii ) a best-analogue ( s ) function ( BAF ) projecting TC onto EB for the best analogue ( s ) to be selected and thus the most likely senses to be identified• Word co-occurrence patterns WCPs are modelled here as consisting of an input and an output level of representation .</sentence>
				<definiendum id="0">WCPs</definiendum>
				<definiens id="0">a structured data set of known word co-occurrence patterns</definiens>
				<definiens id="1">the best analogue ( s ) to be selected and thus the most likely senses to be identified• Word co-occurrence patterns WCPs are modelled here as consisting of an input</definiens>
			</definition>
			<definition id="2">
				<sentence>BAF uses the notion of distributionally-driven word-sense analogy developed in the previous pages , and can be informally described through the following steps : a ) if EB contains a pattern wcp , which fully matches TC .</sentence>
				<definiendum id="0">BAF</definiendum>
			</definition>
			<definition id="3">
				<sentence>at the input level , then wcp , is the best analogue and its output is ranked first in the list of available answers ; note that this step does not stop SENSE from continuing its search ; b ) if EB contains a single AF such that two of AF 's nodes together cover TC 's input representation in its entirety , the output representations associated with the matching nodes is added to the list of available answers with a ranking score , gauged as a function of type and quantity of supporting evidence ( see below for more detail ) ; c ) if steps a ) and b ) yield no result , no output is provided by SENSE .</sentence>
				<definiendum id="0">EB</definiendum>
				<definiens id="0">contains a single AF such that two of AF 's nodes together</definiens>
			</definition>
			<definition id="4">
				<sentence>As a consequence , SENSE outputs more than one sense interpretation , while ranking the attested interpretation first .</sentence>
				<definiendum id="0">SENSE</definiendum>
				<definiens id="0">outputs more than one sense interpretation</definiens>
			</definition>
			<definition id="5">
				<sentence>The ranking score of a given sense interpretation S is then the sum of the specificity scores of all AFs = { AFt , AF~ ... .. AF , } supporting it : Ss~ &gt; ~ , ~ = Spec ( AF0+ Spec ( AF2 ) + ... + Spec ( AF , ) where Spec ( AF , ) = 1/type-frequency ( hook_noun ) .</sentence>
				<definiendum id="0">ranking score</definiendum>
				<definiens id="0">the sum of the specificity scores of all AFs = { AFt , AF~ ... .. AF</definiens>
				<definiens id="1">AF0+ Spec ( AF2 ) + ... + Spec ( AF , ) where Spec ( AF</definiens>
			</definition>
			<definition id="6">
				<sentence>The hook noun supporting the sense affluire_l is hqutdo 'liquid ' , whose specificity score is 0.111111 when used as an object and is significantly lower in the cases supporting the other sense : The specificity score tends to overrate very specific analogies , that is analogies supported by analogical families with highly idiosynractic collocates , over more general analogies .</sentence>
				<definiendum id="0">specificity score</definiendum>
			</definition>
			<definition id="7">
				<sentence>On a more practical front , this measure was evaluated as an integral part of the disambiguation strategy of SENSE , whose main advantages over other WSD systems can be summarised as follows : • SENSE does not take attested evidence at face value but always entertains other hypotheses ; • SENSE 's inferences are not restricted to contexts which exhibit symmetric syntactic dependencies , but also exploit alternations in argument surface realisation with semantically related verbs ; • SENSE is sensitive to the semantic generality/specificity of supporting evidence .</sentence>
				<definiendum id="0">SENSE</definiendum>
				<definiens id="0">sensitive to the semantic generality/specificity of supporting evidence</definiens>
			</definition>
</paper>

		<paper id="1510">
			<definition id="0">
				<sentence>The definition constructor instances simply states that the class will contain the set of objects defined as words in the grammar .</sentence>
				<definiendum id="0">definition constructor instances</definiendum>
				<definiens id="0">the class will contain the set of objects defined as words in the grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>The defined constraint relations can be used with the EFLUF unifier , which uses a modification of lazy narrowing by inductive simplification , ( Hanus , 1992 ) , to unify the corresponding expressions according to the derived subsumption order .</sentence>
				<definiendum id="0">EFLUF unifier</definiendum>
				<definiens id="0">uses a modification of lazy narrowing by inductive simplification , ( Hanus , 1992 ) , to unify the corresponding expressions according to the derived subsumption order</definiens>
			</definition>
</paper>

		<paper id="0123">
			<definition id="0">
				<sentence>A verb-noun collocation e is represented by a feature structure which consists of the verb v and all the pairs of co-occurring case-markers p and thesaurus classes c of case-marked nouns : Fred : v Pz : cz e = : ( 1 ) Pk : ck We assume that a thesaurus is a tree-structured type hierarchy in which each node represents a semantic class , and each thesaurus class cx , ... , c~ in a verb-noun collocation is a leaf class .</sentence>
				<definiendum id="0">verb-noun collocation e</definiendum>
				<definiens id="0">consists of the verb v and all the pairs of co-occurring case-markers p and thesaurus classes c of case-marked nouns : Fred : v Pz</definiens>
				<definiens id="1">a semantic class , and each thesaurus class cx , ...</definiens>
				<definiens id="2">a leaf class</definiens>
			</definition>
			<definition id="1">
				<sentence>i i i| i I i i I T 2.3.3 Independent-Case Model In addition to the requirement that s subsumes e , we can also put an assumption that all the cases in the given verb-noun collocation e are independent of each other and that a subcategorization frame s which has only one case of e can generate e : \ [ pred : v \ ] ( l &lt; i &lt; k ) 8 ~ Ct -Pi : i We call the model satisfying this requirement as the independent-cause model. For example , supposing that the verb-noun collocation e in the equation ( 5 ) is given , the examples in the formula ( 8 ) satisfy this requirement. As can be seen in the definitions of the above three models , the basic idea of defining the model of generating a verb-noun collocation from subcategorization frame ( s ) lies in identifying the dependencies of the cases in the given verb-noun collocation and expressing the dependencies within a subcategorization frame. Here , we briefly show a method of statistically identifying the dependencies of the cases in verb-noun collocations from corpus. 2 Then , by incorporating the identified case dependencies into the generation model , we introduce a model of generating a verb-noun collocation from a tuple of independent partial subcategorization frames. We call this model as the independent-frame model. Partial Subcategor2ation Frame Suppose a verb-noun collocation e is given as in the formula ( 10 ) and a subcategorization frame s satisfies the requirement of the one-frame model in section 2.3.2 , i.e. , as in the formula ( 10 ) , s has exactly the same case-markers as e has , and s subsumes e. Then , we define a part~l subeate~orization frame si of s as a subcategorization frame which has the same verb v as s as well as some of the case-markers of s and their semantic classes. Then , we can find a division of s into a tuple ( sl , ... , s , ) of partial subcategorization frames of s , where any pair si and si , ( i ~ i ' ) do not have common case-markers and the unification sl A -- . Asn of all the partial subcategorization frames equals to s : pred : v : vjvf p~ # ~ pey ( 11 ) s = siA -- -AS , , Si = Pij : ~j ' ( i , i'=l , ... , n~ i~i ' ) Independence of Partial Subcategorization Frames The conditional joint probability p ( sl~ ... , sn I v ) is estimated by svmmlug up p ( e I v ) where e is subsumed by all of Sl , ... , sn ( e -~sl Sl , ... , s , ) : rCsl , ... , s~l~ ) ~ ~ p ( ~l~ ) ( 12 ) e.~o l al , ... , $ , Then , we introduce a parameter c~ ( 0 &lt; c~ &lt; 1 ) for relaxing the constraint of independence. Partial subcategorization frames sl , ... , s , are judged as independent if , for every subset sil , -- - , si # of j of these partial subcategorization frames ~ = 2 , ... , z~ ) , the following inequalities hold : &lt; _ pCs~ , , ... , ~ , l~ ) &lt; _1 ( 13 ) p ( ~ I~ ) ' '' p ( ~ I~ ) o~ This definition of independence judgment means that the condition on independence judgment becomes weaker as ce decreases , while it becomes more strict as cz increases. 2Details of the method of statistically identifying the dependencies of the cases in verb.noun collocations are ~ven in Utsuro and Matsumoto ( 1997 ) . ti 251 Generation from Independent Partial Subcategorization Frames Now , we denote the generation of e from a tuple ( Sl , ... , sn ) of independent partial subcategorization frames of s as below : ( sl , ... , s , ) e ( 14 ) Example For example , suppose that a verb-noun collocation e is given as in the formula ( 5 ) in section 2.2.1. If the three cases in e are dependent on each other as in the generation of e in the formula ( 6 ) , the generation of e is denoted as below in the case of the independent-frame model : pred : nomu ga : Chum `` 11.70 : Cbe v : cpz~ ~ e ( 15 ) ! i | i i *~'k , I the generation of e is denoted as below : Otherwise , if only the two cases `` ga ( NOM ) '' and `` wo ( ACG ) ~ are dependent on each other and Ude ( at ) '' case is independent of those two cases as in the generation of e in the formula ( 7 ) , the ! ( -- -- * e ( 16 ) ~0 : Obey This section gives a formal description of maximum entropy modeling ( Della Pietra , Dena Pietra , and Lafferty , 1997 ; Berger , Della Pietra , and Della Pietra , 1996 ) . We consider a random process that produces an output value y , a member of a finite set y. In generating y , the process may be influenced by some conteztual information z , a member of a finite set t~'. Our task is to construct a stochastic model that accurately represents the behavior of the random process. Such a model is a method of estimating the conditional probability that , given a context x , the process will output y. We denote by p ( y I z ) the probability that the model assigns to y in context x. We also denote by ~ the set of all conditional probability distributions. Thus a model p ( y Ix ) is an element of ~P. To study the process , we observe the behavior of the random process by collecting a large number of samples of the event ( z , y ) . We can summarize the training sample in terms of its empirical probsbility distribution ~ , defined by : ( 17 ) X , y where freq ( z , y ) is the number of time.s that the pair ( x , y ) occurs in the sample. Next , in order to express certain features of the whole event ( z , y ) , a binary-valued indicator function is introduced and called a feature function. Usually , we suppose that there exists a large collection .T of candidate features , and include in the model only a subset S of the full set of candidate features ~. We call S the set of active features. The choice of S must capture as much information about the random process as possible , yet only include features whose expected values can be reliably estimated. In this section and the next section , we assume that the set 8 of active features can be found in some way. How to find 8 will be described in section 3.3. 1 I i 11 ! ! i I 252 I ! ! | , | . ° g ! i 'i '' | I I | : ! Now , we assume that S contains n feature functions. For each feature fi ( E S ) , the sets V~ and Vyi will be given for indicating the sets of the values of z and y for that feature. According to those sets , each feature function fi will be defined as follows : 1 ifz•Vz , andy•V~i fi ( z , y ) = 0 otherwise ( 18 ) When we discover a feature that we feel is useful , we can acknowledge its importance by requiring that our model accord with the feature 's empirical distribution. In ma~dmum entropy modeling approach , this is done by constraining that the expected value of each fi with respect to the model p ( y \ ] x ) ( left-hand side ) be the same as that of fi in the training sample ( right-hand side ) : I = v f , • s ( 19 ) This requirement is called a constraint equation. This requirement means that we would like p to lie in the subset of ~. Then , among the possible models p , the philosophy of the maximum entropy modeling approach is that we should select the most uniform distribution. A mathematical measure of the uniformity of a conditional distribution p ( y I z ) is provided by the conditional entropy : Hb , ) : fC ) pCu I ) logpCy Ix ) ( 20 ) Now , we present the principle of maximum entropy : Maximum Entropy Principle To select a model from a set of allowed probability distributions , choose the model p. with ma~irmm~ entropy H ( p ) : p. = argmaxH ( p ) ( 21 ) P It can be shown that there always exists a unique model p. with maximum entropy in any constrained set. According to Della Pietra , Della Pietra , and Lafferty ( 1997 ) and Berger , Della Pietra , and Della Pietra ( 1996 ) , the solution can be found as the following px ( y \ [ z ) of the form of the exponential family : p~ ( y \ [ = ) = ~ ( 22 ) y i where a parameter Ai is introduced for each feature fi. Della Pietra , Della Pietra , and Lafferty ( 1997 ) and Berger , Della Pietra , and Della Pietra ( 1996 ) also presented an optimization method of estimating the parameter values ~*i that max~rn~.e the entropy , which is called Improved Iterative Scaling ( IIS. ) algorithm. Given the full set .T of candidate features , this section outlines how to select an appropriate subset S of active features. The feature selection process is an incremental procedure that builds up S by successively adding features. At each step , we select the candidate feature which , when adjoined to the set of active features S , produces the greatest increase in log-likelihood of the training sample : 3 sit is shown in Della Pietra , Della Pietra , and La/ferty ( 1997 ) and Berger , Della Pietra~ and Della Pietra ( 1996 ) that the model p. with maximum entropy H ( p ) is the model in the parametric f~m~ly Px ( Y I z ) of the .formula ( 22 ) that maximizes the likelihood of the tr~inlug sample i~. 253 ! erence Ill This section describes how to apply the maximum entropy modeling approach to the task of model r ! learning of subcategorization preference• IIW In our task of model learning of subcategorization preference , each event ( x , y ) in the training sample ~ is a verb-noun collocation e , which is defined as in the formula ( 1 ) . As well as a subcategorization frame , a verb-noun collocation e can be divided into two parts : one is the verbal part ~ containing the verb v while the other is the nominal part ep containing all the pairs of case-markers p and thesaurus leaf classes c of case-marked nouns : e = e , Aep = \ [ trred : v \ ] A `` 1 Pl : Cl / J Pk : ck Then , we define the contezt x of an event ( z , y ) as the verb v and the output 9 as the nominal part ep of e , and each event in the training sample is denoted as ( v , ep ) : ! ! i i Each ( partial ) subcategorisation frame is represented as a feature in the maximum entropy modeling approach. In the case of the partial-frame/one-frame/independent-case models in the sections 2.3.1 , ,~ 2.3.3 , a binary-valued feature function fs ( v , ep ) is defined for each subcategorization frame s. In the case of the independent-frame model in section 2.3.4 , a binary-valued feature function fs~ ( v , ~ ) is defined for each partial subcategorization frames si in the tuple of the formula ( 14 ) . Each feature 'B function f has its own parameter A , which is also the parameter of the corresponding ( partial ) subcategorization frame. According to the possible variations of case dependencies and noun class generalization , we consider every possible patterns of subcategorization frames which can generate a verb-noun collocation , and then construct the full set jr of candidate features. In the following , we give formal definitions of the features in each of the partial-frame/oneframe/independent-case/independent-frame models which we introduced in section 2.3. I Each feature function corresponds to a subcategorization frame s. For each subcategorization frame s , a binary-valued feature function fs ( v , ep ) is defined to be true if and only if the given verb-noun collocation e is subsumed by s : 'lg f3 ( v , ep ) = 0 otherwise Each feature function corresponds~to a subcategorization frame s which has exactly the same cases | as the given verb-noun collocation e has. For each subcategorization frame s , a binary-valued feature function fs ( v , ep ) is defined to be true if and only if the given verb-noun collocation e has exactly the same cases as s has and is also subsumed by s : ~l Pl : Cl Pl : Ctl 1 g e= ( \ [ ~rex~ : ~\ ] Aep ) ~ $ f 8 e = . , s = . , j , ( v , ep ) = 0 otherwise pk : ck pk : dk ! 254 r ! Each feature function corresponds to a subcategorization frame s which has only one case of the given verb-noun collocation e. For each subcategorization frame s which has only one case , a binary-valued feature function fs ( v , ~ ) is defined to be true if and only if the given verb-noun collocation e has the same case and is also subsumed by s : ~ , red : v \ [ \ ] { l if e= ( ~red : v\ ] Ae , ) ~__. $ f $ Pa : ca pred : v ( 1 &lt; i &lt; k ) , fs ( v , ep ) = e = . , s = p~ : c'i -- 0 otherwise p~ : ck Each feature function corresponds to a partial subcategorization frames s~ in the tuple of independent , partial subcategorization frames which can generate the given verb-noun collocation. First , for the given verb-noun collocation e , tuples of independent partial subcategorization frames which can generate e are collected into the set SF ( e ) as below : 4 s SF ( e ) Then , for each partial subcategorization frame s , a binary-valued feature function fs ( v , e~ ) is defined to be true if and only if at least one element of the set SF ( e ) is a tuple ( sl , ... , s , ... , s , ) that contains s : { z if 3 ( s~ , ... , s , ... , s , ~ ) • SF ( ~=C~ea : H Aep ) ) ( 2~ ) fs ( v , ep ) = 0 otherwise Let £ be the training corpus consisting of traln~ng events of the form ( v , ep ) . Let Jr be the full set of candidate features each element of which corresponds to a possible subcategorization frame. Then , given the empirical distribution i~ ( v , e~ ) of the training sample , the set 5 ( C_ ~ ' ) of active features is found according to the feature selection algorithm in section 3.3 , and the parameters of subcategorization frames are estimated according to HS Algorithm ( Della Pietra , Della Pietra , and Lafferty , 1997 ; Berger , Della Pietra , and Della Pietra~ 1996 ) . Finally , the conditional probability distribution p $ ( e~ Iv ) is estimated. ps ( ~ I~ ) = f , ~s ( 25 ) ep Y , E8 Suppose that , after estimating parameters of subcategorization preference from the training corpus £ of verb-noun collocations , we obtain the set ,5 of active features and the model ps ( ep \ ] v ) incorporating these features. Now , we describe how to rank parse trees of a given input sentence according to the estimated parameters of subcategorization preference of verbs. 4More precisely , for a tuple ( sl , ... , s. ) of independent partial subcategorization frames to be included in the set SF ( e ) , the following requirement has to be satisfied : it is not possible to divide any of the partial frames s ; , ... , s , into more than one frame and to construct a finer-grained tuple ' ' ... , s , +~ ) of independent partial subcategorization frames. SWhen applying the learned probabilistic model to the he\ ] d-out test event e ~ ' , independence of the partial subcategorization frames are judged using the probabilities of partial subcategorization frames estimated from the truini~g da~ ( as described in section 2.3.4 ) , then the set SF ( e is ) is constructed. 255 Let w be the given input sentence , T ( w ) be the set of parse trees of w , t be a parse tree in T ( w ) , E ( t ) be the set of verb-noun collocations contained in t. Then , each parse tree is assigned the product of all the conditk , nal probabilities ps ( e~ s I v ) of verb-noun collocations ( v , e~ s ) within it , which is denoted by ¢ ( t ) : ( , , , e~ ' ) eE ( O A parse tree t ( 6 T ( ~u ) ) with the greatest value of ¢ ( t ) is chosen as the best parse tree { of w. i = ~gmax~ ( O ~er ( ~ ) Along with the estimated conditional probabilities ps ( e~ s I v ) and the basic model above , we consider a heuristics concerning covering of the cases of verb-noun collocations as below and evaluate their effectiveness in the experiments of the next section. Let ( v , e~ ) be a test event which is not included in the training corpus E ( i.e. , ( v , e~ ) ~ £ ) . Subcategorization preference of test events is determined according to whether each case p ( and the leaf class marked by p ) of e~ is covered by at least one feature in S. More formally , we introduce case cover/ng relation - &lt; ~ of a verb-noun collocation ( v , e~ ) and a feature set S : ( v , ~ ) - &lt; _~ S iff. for each casep ( and the leaf class ct marked byp ) of~ , at least one subcategorization frame corresponding to a feature in S has the same case p and its sense restriction cs subsumes c~ , i.e. cl _-de cs According to this factor , ( vl , e~i ) is preferred to ( v2 , % 2 ) if and only if the following condition holds : Ranking Parse Trees This heuristics can be also incorporated into ranking parse trees of a given input sentence. Let z~ be the given input sentence , T ( zv ) be the set of parse trees of zv , t be a parse tree in T ( zv ) , E ( t ) be the set of verb-noun collocations contained in t. Let ~-~ ( t ) ( C_ E ( t ) ) be the set of verb-noun collocations ( % e~ ) for which ( % ~ ) ~co , q holds , and Esnco ( t ) ( C E ( t ) ) be the set of verb-noun collocations ( v , e~ ) for which ( v , e~ ) ___co , ~ does not hold. Then , subcategorization preference of parse trees is determined as follows , tt is preferred to t2 if and only if one of the following conditions ( i ) , - , ( iii ) holds : ( i ) I~ , , ( ' , . ) 1 &gt; IEf. , , ( t2 ) l ( a ) IE~ ( ' , . )</sentence>
				<definiendum id="0">Della Pietra</definiendum>
				<definiendum id="1">T ( w )</definiendum>
				<definiens id="0">I i i I T 2.3.3 Independent-Case Model In addition to the requirement that s subsumes e , we can also put an assumption that all the cases in the given verb-noun collocation e are independent of each other and that a subcategorization frame s which has only one case of e can generate e : \ [ pred : v \ ] ( l &lt; i &lt; k ) 8 ~ Ct -Pi : i We call the model satisfying this requirement as the independent-cause model. For example , supposing that the verb-noun collocation e in the equation ( 5 ) is given , the examples in the formula ( 8 ) satisfy this requirement. As can be seen in the definitions of the above three models , the basic idea of defining the model of generating a verb-noun collocation from subcategorization frame ( s ) lies in identifying the dependencies of the cases in the given verb-noun collocation and expressing the dependencies within a subcategorization frame. Here , we briefly show a method of statistically identifying the dependencies of the cases in verb-noun collocations from corpus. 2 Then , by incorporating the identified case dependencies into the generation model , we introduce a model of generating a verb-noun collocation from a tuple of independent partial subcategorization frames. We call this model as the independent-frame model. Partial Subcategor2ation Frame Suppose a verb-noun collocation e is given as in the formula ( 10 ) and a subcategorization frame s satisfies the requirement of the one-frame model in section 2.3.2 , i.e. , as in the formula ( 10 ) , s has exactly the same case-markers as e has , and s subsumes e. Then , we define a part~l subeate~orization frame si of s as a subcategorization frame which has the same verb v as s as well as some of the case-markers of s and their semantic classes. Then , we can find a division of s into a tuple ( sl , ... , s , ) of partial subcategorization frames of s , where any pair si and si , ( i ~ i ' ) do not have common case-markers and the unification sl A -- . Asn of all the partial subcategorization frames equals to s : pred : v : vjvf p~ # ~ pey ( 11 ) s = siA -- -AS , , Si = Pij : ~j ' ( i , i'=l , ... , n~ i~i ' ) Independence of Partial Subcategorization Frames The conditional joint probability p ( sl~ ... , sn I v ) is estimated by svmmlug up p ( e I v ) where e is subsumed by all of Sl , ... , sn ( e -~sl Sl , ... , s , ) : rCsl , ... , s~l~ ) ~ ~ p ( ~l~ ) ( 12 ) e.~o l al , ... , $ , Then , we introduce a parameter c~ ( 0 &lt; c~ &lt; 1 ) for relaxing the constraint of independence. Partial subcategorization frames sl , ... , s , are judged as independent if , for every subset sil , -- - , si # of j of these partial subcategorization frames ~ = 2 , ... , z~ ) , the following inequalities hold : &lt; _ pCs~ , , ... , ~ , l~ ) &lt; _1 ( 13 ) p ( ~ I~ ) ' '' p ( ~ I~ ) o~ This definition of independence judgment means that the condition on independence judgment becomes weaker as ce decreases , while it becomes more strict as cz increases. 2Details of the method of statistically identifying the dependencies of the cases in verb.noun collocations are ~ven in Utsuro and Matsumoto ( 1997 ) . ti 251 Generation from Independent Partial Subcategorization Frames Now , we denote the generation of e from a tuple ( Sl , ... , sn ) of independent partial subcategorization frames of s as below : ( sl , ... , s , ) e ( 14 ) Example For example , suppose that a verb-noun collocation e is given as in the formula ( 5 ) in section 2.2.1. If the three cases in e are dependent on each other as in the generation of e in the formula ( 6 ) , the generation of e is denoted as below in the case of the independent-frame model : pred : nomu ga : Chum `` 11.70 : Cbe v : cpz~ ~ e ( 15 ) ! i | i i *~'k , I the generation of e is denoted as below : Otherwise , if only the two cases `` ga ( NOM ) '' and `` wo ( ACG ) ~ are dependent on each other and Ude ( at ) '' case is independent of those two cases as in the generation of e in the formula ( 7 ) , the ! ( -- -- * e ( 16 ) ~0 : Obey This section gives a formal description of maximum entropy modeling ( Della Pietra , Dena Pietra , and Lafferty , 1997 ; Berger , Della Pietra , and Della Pietra , 1996 ) . We consider a random process that produces an output value y , a member of a finite set y. In generating y , the process may be influenced by some conteztual information z , a member of a finite set t~'. Our task is to construct a stochastic model that accurately represents the behavior of the random process. Such a model is a method of estimating the conditional probability that , given a context x , the process will output y. We denote by p ( y I z ) the probability that the model assigns to y in context x. We also denote by ~ the set of all conditional probability distributions. Thus a model p ( y Ix ) is an element of ~P. To study the process , we observe the behavior of the random process by collecting a large number of samples of the event ( z , y ) . We can summarize the training sample in terms of its empirical probsbility distribution ~ , defined by : ( 17 ) X , y where freq ( z , y ) is the number of time.s that the pair ( x , y ) occurs in the sample. Next , in order to express certain features of the whole event ( z , y ) , a binary-valued indicator function is introduced and called a feature function. Usually , we suppose that there exists a large collection .T of candidate features , and include in the model only a subset S of the full set of candidate features ~. We call S the set of active features. The choice of S must capture as much information about the random process as possible , yet only include features whose expected values can be reliably estimated. In this section and the next section , we assume that the set 8 of active features can be found in some way. How to find 8 will be described in section 3.3. 1 I i 11 ! ! i I 252 I ! ! | , | . ° g ! i 'i '' | I I | : ! Now , we assume that S contains n feature functions. For each feature fi ( E S ) , the sets V~ and Vyi will be given for indicating the sets of the values of z and y for that feature. According to those sets , each feature function fi will be defined as follows : 1 ifz•Vz , andy•V~i fi ( z , y ) = 0 otherwise ( 18 ) When we discover a feature that we feel is useful , we can acknowledge its importance by requiring that our model accord with the feature 's empirical distribution. In ma~dmum entropy modeling approach , this is done by constraining that the expected value of each fi with respect to the model p ( y \ ] x ) ( left-hand side ) be the same as that of fi in the training sample ( right-hand side ) : I = v f , • s ( 19 ) This requirement is called a constraint equation. This requirement means that we would like p to lie in the subset of ~. Then , among the possible models p , the philosophy of the maximum entropy modeling approach is that we should select the most uniform distribution. A mathematical measure of the uniformity of a conditional distribution p ( y I z ) is provided by the conditional entropy : Hb , ) : fC ) pCu I ) logpCy Ix ) ( 20 ) Now , we present the principle of maximum entropy : Maximum Entropy Principle To select a model from a set of allowed probability distributions , choose the model p. with ma~irmm~ entropy H ( p ) : p. = argmaxH ( p ) ( 21 ) P It can be shown that there always exists a unique model p. with maximum entropy in any constrained set. According to Della Pietra , Della Pietra , and Lafferty ( 1997 ) and Berger , Della Pietra , and</definiens>
				<definiens id="1">the following px ( y \ [ z ) of the form of the exponential family : p~ ( y \ [ = ) = ~ ( 22 ) y i where a parameter Ai is introduced for each feature fi. Della Pietra , Della Pietra , and Lafferty ( 1997 ) and Berger , Della Pietra , and Della Pietra ( 1996 ) also presented an optimization method of estimating the parameter values ~*i that max~rn~.e the entropy , which is called Improved Iterative Scaling ( IIS. ) algorithm. Given the full set .T of candidate features , this section outlines how to select an appropriate subset S of active features. The feature selection process is an incremental procedure that builds up S by successively adding features. At each step , we select the candidate feature which , when adjoined to the set of active features S , produces the greatest increase in log-likelihood of the training sample : 3 sit is shown in Della Pietra , Della Pietra , and La/ferty ( 1997 ) and Berger , Della Pietra~ and Della Pietra ( 1996 ) that the model p. with maximum entropy H ( p ) is the model in the parametric f~m~ly Px ( Y I z ) of the .formula ( 22 ) that maximizes the likelihood of the tr~inlug sample i~. 253 ! erence Ill This section describes how to apply the maximum entropy modeling approach to the task of model r ! learning of subcategorization preference• IIW In our task of model learning of subcategorization preference , each event ( x , y ) in the training sample ~ is a verb-noun collocation e , which is defined as in the formula ( 1 ) . As well as a subcategorization frame , a verb-noun collocation e can be divided into two parts : one is the verbal part ~ containing the verb v while the other is the nominal part ep containing all the pairs of case-markers p and thesaurus leaf classes c of case-marked nouns : e = e , Aep = \ [ trred : v \ ] A `` 1 Pl : Cl / J Pk : ck Then , we define the contezt x of an event ( z , y ) as the verb v and the output 9 as the nominal part ep of e , and each event in the training sample is denoted as ( v , ep ) : ! ! i i Each ( partial ) subcategorisation frame is represented as a feature in the maximum entropy modeling approach. In the case of the partial-frame/one-frame/independent-case models in the sections 2.3.1 , ,~ 2.3.3 , a binary-valued feature function fs ( v , ep ) is defined for each subcategorization frame s. In the case of the independent-frame model in section 2.3.4 , a binary-valued feature function fs~ ( v , ~ ) is defined for each partial subcategorization frames si in the tuple of the formula ( 14 ) . Each feature 'B function f has its own parameter A , which is also the parameter of the corresponding ( partial ) subcategorization frame. According to the possible variations of case dependencies and noun class generalization , we consider every possible patterns of subcategorization frames which can generate a verb-noun collocation , and then construct the full set jr of candidate features. In the following , we give formal definitions of the features in each of the partial-frame/oneframe/independent-case/independent-frame models which we introduced in section 2.3. I Each feature function corresponds to a subcategorization frame s. For each subcategorization frame s , a binary-valued feature function fs ( v , ep ) is defined to be true if and only if the given verb-noun collocation e is subsumed by s : 'lg f3 ( v , ep ) = 0 otherwise Each feature function corresponds~to a subcategorization frame s which has exactly the same cases | as the given verb-noun collocation e has. For each subcategorization frame s , a binary-valued feature function fs ( v , ep ) is defined to be true if and only if the given verb-noun collocation e has exactly the same cases as s has and is also subsumed by s : ~l Pl : Cl Pl : Ctl 1 g e= ( \ [ ~rex~ : ~\ ] Aep ) ~ $ f 8 e = . , s = . , j , ( v , ep ) = 0 otherwise pk : ck pk : dk ! 254 r ! Each feature function corresponds to a subcategorization frame s which has only one case of the given verb-noun collocation e. For each subcategorization frame s which has only one case , a binary-valued feature function fs ( v , ~ ) is defined to be true if and only if the given verb-noun collocation e has the same case and is also subsumed by s : ~ , red : v \ [ \ ] { l if e= ( ~red : v\ ] Ae , ) ~__. $ f $ Pa : ca pred : v ( 1 &lt; i &lt; k ) , fs ( v , ep ) = e = . , s = p~ : c'i -- 0 otherwise p~ : ck Each feature function corresponds to a partial subcategorization frames s~ in the tuple of independent , partial subcategorization frames which can generate the given verb-noun collocation. First , for the given verb-noun collocation e , tuples of independent partial subcategorization frames which can generate e are collected into the set SF ( e ) as below : 4 s SF ( e ) Then , for each partial subcategorization frame s , a binary-valued feature function fs ( v , e~ ) is defined to be true if and only if at least one element of the set SF ( e ) is a tuple ( sl , ... , s , ... , s , ) that contains s : { z if 3 ( s~ , ... , s , ... , s , ~ ) • SF ( ~=C~ea : H Aep ) ) ( 2~ ) fs ( v , ep ) = 0 otherwise Let £ be the training corpus consisting of traln~ng events of the form ( v , ep ) . Let Jr be the full set of candidate features each element of which corresponds to a possible subcategorization frame. Then , given the empirical distribution i~ ( v , e~ ) of the training sample , the set 5 ( C_ ~ ' ) of active features is found according to the feature selection algorithm in section 3.3 , and the parameters of subcategorization frames are estimated according to HS Algorithm ( Della Pietra , Della Pietra , and Lafferty , 1997 ; Berger , Della Pietra , and Della Pietra~ 1996 ) . Finally , the conditional probability distribution p $ ( e~ Iv ) is estimated. ps ( ~ I~ ) = f , ~s ( 25 ) ep Y , E8 Suppose that , after estimating parameters of subcategorization preference from the training corpus £ of verb-noun collocations , we obtain the set ,5 of active features and the model ps ( ep \ ] v ) incorporating these features. Now , we describe how to rank parse trees of a given input sentence according to the estimated parameters of subcategorization preference of verbs. 4More precisely , for a tuple ( sl , ... , s. ) of independent partial subcategorization frames to be included in the set SF ( e ) , the following requirement has to be satisfied : it is not possible to divide any of the partial frames s ; , ... , s , into more than one frame and to construct a finer-grained tuple ' ' ... , s , +~ ) of independent partial subcategorization frames. SWhen applying the learned probabilistic model to the he\ ] d-out test event e ~ ' , independence of the partial subcategorization frames are judged using the probabilities of partial subcategorization frames estimated from the truini~g da~ ( as described in section 2.3.4 ) , then the set SF ( e is ) is constructed. 255 Let w be the given input sentence</definiens>
				<definiens id="2">the set of parse trees of w , t be a parse tree in T ( w ) , E ( t ) be the set of verb-noun collocations contained in t. Then , each parse tree is assigned the product of all the conditk , nal probabilities ps ( e~ s I v ) of verb-noun collocations ( v , e~ s ) within it , which is denoted by ¢ ( t ) : ( , , , e~ ' ) eE ( O A parse tree t ( 6 T ( ~u ) ) with the greatest value of ¢ ( t ) is chosen as the best parse tree { of w. i = ~gmax~ ( O ~er ( ~ ) Along with the estimated conditional probabilities ps ( e~ s I v ) and the basic model above , we consider a heuristics concerning covering of the cases of verb-noun collocations as below and evaluate their effectiveness in the experiments of the next section. Let ( v , e~ ) be a test event which is not included in the training corpus E ( i.e. , ( v , e~ ) ~ £ ) . Subcategorization preference of test events is determined according to whether each case p ( and the leaf class marked by p ) of e~ is covered by at least one feature in S. More formally , we introduce case cover/ng relation - &lt; ~ of a verb-noun collocation ( v , e~ ) and a feature set S : ( v , ~ ) - &lt; _~ S iff. for each casep ( and the leaf class ct marked byp ) of~ , at least one subcategorization frame corresponding to a feature in S has the same case p and its sense restriction cs subsumes c~ , i.e. cl _-de cs According to this factor , ( vl , e~i ) is preferred to ( v2 , % 2 ) if and only if the following condition holds : Ranking Parse Trees This heuristics can be also incorporated into ranking parse trees of a given input sentence. Let z~ be the given input sentence , T ( zv ) be the set of parse trees of zv , t be a parse tree in T ( zv ) , E ( t ) be the set of verb-noun collocations contained in t. Let ~-~ ( t ) ( C_ E ( t ) ) be the set of verb-noun collocations ( % e~ ) for which ( % ~ ) ~co , q holds , and Esnco ( t ) ( C E ( t ) ) be the set of verb-noun collocations ( v , e~ ) for which ( v , e~ ) ___co , ~ does not hold. Then , subcategorization preference of parse trees is determined as follows , tt is preferred to t2 if and only if one of the following conditions ( i ) , - , ( iii ) holds : ( i ) I~ , , ( ' , . ) 1 &gt; IEf. , , ( t2 ) l ( a ) IE~ ( ' ,</definiens>
			</definition>
			<definition id="2">
				<sentence>~ As the training and test corpus , we used the EDR Japanese bracketed corpus ( EDR , 1995 ) , which contains about 210,000 sentences collected from newspaper and magazine articles .</sentence>
				<definiendum id="0">EDR Japanese bracketed corpus</definiendum>
				<definiens id="0">contains about 210,000 sentences collected from newspaper and magazine articles</definiens>
			</definition>
			<definition id="3">
				<sentence>BGH has a s~xlayered abstraction hierarchy and more than 60,000 words are assigned at the leaves and its nominal part contains about 45,000 words .</sentence>
				<definiendum id="0">BGH</definiendum>
				<definiens id="0">a s~xlayered abstraction hierarchy and more than 60,000 words</definiens>
			</definition>
			<definition id="4">
				<sentence>r One-Frame Model in~pendeetndent-Frame Model ( a~u~0.9 ) 4OO S00 6O0 Number of Sele~ed Features &amp; 8 ( b ) Precisions of Case-Covered Events ( All Models Pm ( : ismn ( covered ) 120 Precision ( heuristic ) precision ( ba~c ) -- , ~100 80 60 40 20 0 , I 0 100 200 ~00 40o soo Number o~ Selected Features ( d ) Independent-Frame Model ( a = 0.9 ) Figure 1 : Changes in Case-Coverage of Test Data and Precisions of Subcategorization Preference For the independent-frame model , we examined two different values of the independence parameter a , i.e. , c~ 0.5 as a weak condition on independence judgment and ~ 0.9 as a strict condition on independence judgment .</sentence>
				<definiendum id="0">r One-Frame Model in~pendeetndent-Frame Model</definiendum>
				<definiendum id="1">Case-Covered Events</definiendum>
				<definiendum id="2">Models Pm</definiendum>
				<definiendum id="3">Independent-Frame Model</definiendum>
				<definiens id="0">ismn ( covered ) 120 Precision ( heuristic ) precision ( ba~c ) -- , ~100 80 60 40 20 0 , I 0 100 200 ~00 40o soo Number o~ Selected Features ( d )</definiens>
			</definition>
</paper>

		<paper id="1503">
			<definition id="0">
				<sentence>The development of a LEA is a task involving different kinds of skills and expertise .</sentence>
				<definiendum id="0">LEA</definiendum>
				<definiens id="0">a task involving different kinds of skills and expertise</definiens>
			</definition>
			<definition id="1">
				<sentence>PD employs a wide range of techniques ( Muller et al. , 1993 ) whose applicability depends on such factors as design goals , group size , availability of users for long periods , and the like .</sentence>
				<definiendum id="0">PD</definiendum>
				<definiens id="0">employs a wide range of techniques ( Muller et al. , 1993 ) whose applicability depends on such factors as design goals , group size</definiens>
			</definition>
			<definition id="2">
				<sentence>Background : computer science ; knowledge of computational linguistics ; • Computational Linguist ( CL ) : expert on linguistic data development .</sentence>
				<definiendum id="0">Background</definiendum>
			</definition>
			<definition id="3">
				<sentence>Background : computational linguistics ; little knowledge of computer science ; • Processor Manager ( PM ) : expert on processors for language processing .</sentence>
				<definiendum id="0">Background</definiendum>
			</definition>
			<definition id="4">
				<sentence>Background : computer science ; knowledge of computational linguistics .</sentence>
				<definiendum id="0">Background</definiendum>
				<definiens id="0">computer science ; knowledge of computational linguistics</definiens>
			</definition>
			<definition id="5">
				<sentence>In GEPPETTO an application consists of two main parts : a ( set of ) processor ( s ) and a Linguistic System .</sentence>
				<definiendum id="0">GEPPETTO an application</definiendum>
				<definiens id="0">consists of two main parts : a ( set of ) processor ( s ) and a Linguistic System</definiens>
			</definition>
			<definition id="6">
				<sentence>Such an effort produced a highly detailed description of the tool functionalities and of its layout ; in particular , the kind of information and actions ( showing parse/generation trees , TFS descriptions associated with edges ) to be made available to the user , the different viewpoints on edges and vertices , etc .</sentence>
				<definiendum id="0">TFS</definiendum>
				<definiens id="0">descriptions associated with edges</definiens>
			</definition>
			<definition id="7">
				<sentence>PPETTO reports diagnostic messages on the causes of the failure : missing grammar rules/lexical items , failure during unification , etc .</sentence>
				<definiendum id="0">PPETTO</definiendum>
				<definiens id="0">reports diagnostic messages on the causes of the failure : missing grammar rules/lexical items , failure during unification , etc</definiens>
			</definition>
			<definition id="8">
				<sentence>GEPPETTO has been used in the development of a number of applicative projects , in different application domains , including multi-lingual text generation ( LRE-GIST ) , information extraction from agency news ( LE-FACILE ) , and Natural Language information query ( LE-TAMIC-P ) ; all these projects have been funded by the European Union .</sentence>
				<definiendum id="0">GEPPETTO</definiendum>
				<definiens id="0">LE-FACILE ) , and Natural Language information query ( LE-TAMIC-P ) ; all these projects have been funded by the European Union</definiens>
			</definition>
</paper>

		<paper id="1515">
			<definition id="0">
				<sentence>GTU ( German : Grammatik-Testumgebung ; grammar test environment ) was developed as a flexible and user-friendly tool for the development and testing of grammars in various formats .</sentence>
				<definiendum id="0">GTU</definiendum>
				<definiens id="0">a flexible and user-friendly tool for the development and testing of grammars in various formats</definiens>
			</definition>
			<definition id="1">
				<sentence>A model for the employment of grammar checks is the workbench for affix grammars introduced by ( Nederhof et al. , 1992 ) , which uses grammar checks in order to report on inconsistencies ( conflicts with well-formedness conditions such as that every nonterminal should have a definition ) , properties ( such as LL ( 1 ) ) , and information on the overall grammar structure ( such as the is-cMled-by relation ) .</sentence>
				<definiendum id="0">model for the employment of grammar checks</definiendum>
			</definition>
			<definition id="2">
				<sentence>For GPSG grammars GTU presents every edge produced by the bottom-up chart parser .</sentence>
				<definiendum id="0">GTU</definiendum>
				<definiens id="0">presents every edge produced by the bottom-up chart parser</definiens>
			</definition>
			<definition id="3">
				<sentence>The test criterion is a list of feature-value pairs to be checked against a word 's lexical information .</sentence>
				<definiendum id="0">test criterion</definiendum>
				<definiens id="0">a list of feature-value pairs to be checked against a word 's lexical information</definiens>
			</definition>
			<definition id="4">
				<sentence>Test suite administration GTU contains a test suite with about 300 sentences annotated with their syntactic properties .</sentence>
				<definiendum id="0">Test suite administration GTU</definiendum>
			</definition>
			<definition id="5">
				<sentence>TSNLP provides more than 4000 test items for English , French and German each .</sentence>
				<definiendum id="0">TSNLP</definiendum>
				<definiens id="0">provides more than 4000 test items for English , French and German each</definiens>
			</definition>
			<definition id="6">
				<sentence>GTU supports such modularisation into files that can be loaded and tested independently .</sentence>
				<definiendum id="0">GTU</definiendum>
				<definiens id="0">supports such modularisation into files that can be loaded and tested independently</definiens>
			</definition>
</paper>

		<paper id="0714">
			<definition id="0">
				<sentence>the group opinion and dehvers the result to the next blackboard • Knowledge base The SlmSum knowledge base ts a common knowledge store compnsmg a text representation winch holds all texts in the system and an ontology of the concepts which are needed to deal with them tion Since summarizing is a text and reformation processing task , we have to represent those surface text passages and text meamng umts m the system winch are really worked upon , concentraung on semantic and pragmatic structures The representation must support pragmatic text handhng and deal with bollsUc text structures as well as wtth local rmcrostructures and layout features , because document structure knowledge ts a core item of a professional summanzer 's competence • • The practical coding of the vlslble document arcintecture follows SGML conventlons SGML tags like `` &lt; hl I &gt; .</sentence>
				<definiendum id="0">SlmSum knowledge base</definiendum>
				<definiens id="0">ts a common knowledge store compnsmg a text representation winch holds all texts in the system and an ontology of the concepts which are needed to deal with them tion Since summarizing is a text and reformation processing task</definiens>
			</definition>
			<definition id="1">
				<sentence>indicator phrase , matching rots dmctaonary entry with a proposmon such as proposmon 5 mn table 2 Consequently , the agent annotates proposmon 4 as describing the project theme and therefore as Important and puts it together wroth others on the relevance blackboard ( see fig 2 and table 4 ) • Relevant-caU Relevant-call recoguizes a text meamng totem as relevant because it hnks it to the document theme ( see figure 3 ) The agent needs the themauc structure and , as a candidate for linkage to the document topmc , a text proposmon The agent checks whether an open RST-type hnk of the document theme is able to attach the candidate If so , the proposmon Is regarded as relevant and added to the document theme Theme-of-document .</sentence>
				<definiendum id="0">open RST-type hnk of the document theme</definiendum>
				<definiens id="0">able to attach the candidate If so , the proposmon Is regarded as relevant and added to the document theme Theme-of-document</definiens>
			</definition>
			<definition id="2">
				<sentence>Is attached by an ELABORATION hnk Th6 new hypothesis of a topic structure ~s given m figure 3 At that moment , two new proposltaons have been attached tothe theme , so that the theme has three extensions Advancing the sc~entfftc frontiers of text summanzaUon presupposes more knowledge about the way summartzatton works The mare frmt of the empmcal mvesUgat~on behind SlmSum is an tmage of the summanzalaon process which Is detmled enough to lay the foundattons for a stmulat~on Since the resulting summarization model incorporates the know-how of human experts , tt has good prospects of presenting powerful techmques Summarizing by cooperating cognmve agents seems to be such a pnnclple The researchers have reached their aim to show that an observauonally founded ImplementaUon of summarizing processes ~s possible However , SlmSum Is a system mthe-small It sufftcesto demonstrate how the summarization agents work m thetr cogmUve environment To meetpracttcal challenges such as text summarizing m the WWW , a much more comprehensive system must be realized Tl~s means m pamcular • providing knowledge bases of real-world size , be they private ones of agents or pubhc resources of the whole system • choosing the most useful strategies or agents and malang them flexible to deal with any legmmate data • using text understanders or reformation extracUon components as well as generauon systems provtded by colleagues 95 6 , Acknowledgements .</sentence>
				<definiendum id="0">SlmSum</definiendum>
				<definiens id="0">an tmage of the summanzalaon process which Is detmled enough to lay the</definiens>
			</definition>
			<definition id="3">
				<sentence>ference on Artlficzal Intelhgence ( pp 840-844 ) Los Altos CA Kaufmann Glaser , B G , &amp; Strauss , A L ( 1980 ) The dzscovery of grounded theory Strategtes for • quahtatzve research ( llth ed ) New York Aldme Atherton Hovy , E ( 1993 ) Automated dtscourse generation using discourse structure relauons Artohczal Intelhgence 63 , 341-385 Jacobs , P S , &amp; Rau , L F ( 1990 ) SCISOR Extracting mformatton from on-hne news Commumcauons of the ACM 33 ( 11 ) , 88-97 Kmtseh , W , &amp; van DIjk , TA ( 1983 ) Strategzes of chscourse comprehenston Orlando FLA Academic Press Lincoln , Y S , &amp; Guba , E G ( 1985 ) Natural~st~c mqmry Beverly Hills CA Sage Mann , WC &amp; Thompson S A ( 1987 ) Rhetorical Structure Theory A Theory of Text OrgamzaUon In L Polany ( FEd ) The Structure of Dtscourse Norwood , N J Ablex McClelland , J L , &amp; Rumelhart , D E ( 1981 ) An interactive activation model of context effects tn letter perception Part 1 An account of b.~le fln &amp; ngs Psychologwal Remew 88 , 375-407 MeKeown , K R ( 1985 ) Text generatzon Uszng dzscourse strategies and focus constraints to generate natural language text Cambndge Cambridge Umv Press Norman , D A ( 1983 ) Some observations on mental models In D Gentner &amp; A L Stevens ( Eds ) , Mental models ( pp 7-14 ) Hlllsdale NJ Erlbaum Patce , C D ( 1990 ) Constructing literature abstracts by computer Techniques and prospects Information Processing &amp; Management 26 ( 1 ) ,171-186 Penman Project ( 1989 ) PENMAN documentatton the primer , the user grade , the reference manual and the Nzgel manual Techmcal Report USC/Informaaon Sciences InstRute , Marina del Rey , Cahfornla Schrmber , G , Wlehnga , B , &amp; Breuker , J ( 1993 ) KADS A prmctpled approach to .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">L Stevens</definiendum>
				<definiendum id="2">Mental models</definiendum>
				<definiens id="0">generate natural language text Cambndge Cambridge Umv Press Norman</definiens>
			</definition>
</paper>

		<paper id="1103">
			<definition id="0">
				<sentence>Furthermore Stevens ( Stevens , 1989 ) has developed a theory that explains the shape of sound systems through non-linear characteristics of the human vocal tract and auditory system .</sentence>
				<definiendum id="0">Furthermore Stevens</definiendum>
				<definiens id="0">developed a theory that explains the shape of sound systems through non-linear characteristics of the human vocal tract and auditory system</definiens>
			</definition>
</paper>

		<paper id="0205">
			<definition id="0">
				<sentence>However , despite its shortcomings WORDNET is a vast resource of lexical semantic knowledge that can m m m mm m \ [ \ ] m m n \ [ \ ] m m n m m m m m n m m be mined , restructured and extended , which makes it a good starting point for the construction of CORELEX .</sentence>
				<definiendum id="0">WORDNET</definiendum>
				<definiens id="0">a vast resource of lexical semantic knowledge that can m m m mm m \ [ \ ] m m n \ [ \ ] m m n m m m m m n m m be mined , restructured and extended , which makes it a good starting point for the construction of CORELEX</definiens>
			</definition>
			<definition id="1">
				<sentence>m ) , artifact ( art ) , attribute ( air ) , blunder ( bln ) , cell ( cel ) , chemical ( chm ) , communication ( corn ) , event ( evl ; ) , food ( rod ) , form ( frm ) , group_biological ( grb ) , group ( grp ) , group_social ( grs ) , h-m~n ( hum ) , llnear_measure ( 1me ) , location ( loc ) , 1ocation_geographical ( log ) , measure ( mea ) , natural_object ( nat ) , phenomenon ( p\ ] m ) , plant ( plt ) , possession ( pos ) , part ( prt ) , psychological ( psy ) , quantity_definite ( qud ) , quantity_indefinite ( qui ) , relation ( re1 ) , space ( spc ) , state ( sta ) , time ( tree ) Figure 3 shows their distribution among noun stems in the BROWN corpus .</sentence>
				<definiendum id="0">plant</definiendum>
				<definiendum id="1">possession ( pos</definiendum>
				<definiens id="0">artifact ( art ) , attribute ( air ) , blunder ( bln ) , cell ( cel ) , chemical ( chm ) , communication ( corn ) , event</definiens>
				<definiens id="1">nat ) , phenomenon ( p\ ] m )</definiens>
			</definition>
			<definition id="2">
				<sentence>Other classes consist of both homonyms and systematically polysemous lexical items like the class act log , which includes caliphate , clearing , emirate , prefecture , repair , wheeling vs. bolivia , charleston , chicago , michigan .</sentence>
				<definiendum id="0">Other classes</definiendum>
				<definiens id="0">consist of both homonyms and systematically polysemous lexical items like the class act log , which includes caliphate , clearing , emirate , prefecture , repair</definiens>
			</definition>
			<definition id="3">
				<sentence>A condition aRb restricts this set of pairs to only those for which some relation R holds , where R denotes a subset of the Cartesian product of the sets of type ~ objects and type r objects .</sentence>
				<definiendum id="0">condition aRb</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">some relation R holds , where</definiens>
				<definiens id="1">a subset of the Cartesian product of the sets of type ~ objects and type r objects</definiens>
			</definition>
			<definition id="4">
				<sentence>MI is defined in general as follows : y ) I ix y ) = log2 P ( x ) P ( y ) We can use this definition to derive an estimate of the connectedness between words , in terms of collocations ( Smadja , 1993 ) , but also in terms of phrases and grammatical relations ( Hindle , 1990 ) .</sentence>
				<definiendum id="0">MI</definiendum>
				<definiens id="0">y ) I ix y ) = log2 P ( x ) P ( y ) We can use this definition to derive an estimate of the connectedness between words</definiens>
			</definition>
			<definition id="5">
				<sentence>The Jaccard measure is defined as the number of attributes shared by two objects divided by the total number of unique attributes shared by both objects : A A+B+C A : attributes shared by both objects B : attributes unique to object 1 C : attributes unique to object 2 The Jaccard scores for each CORELEx class are sorted and the class with the highest score is assigned to the noun .</sentence>
				<definiendum id="0">Jaccard measure</definiendum>
				<definiens id="0">the number of attributes shared by two objects divided by the total number of unique attributes shared by both objects : A A+B+C A : attributes shared by both objects B : attributes unique to object 1 C : attributes unique to object 2</definiens>
			</definition>
			<definition id="6">
				<sentence>CORZLEx provides such knowledge representations , and as such it is fundamentally different from existing semantic lexicons like WORDNET .</sentence>
				<definiendum id="0">CORZLEx</definiendum>
				<definiens id="0">provides such knowledge representations</definiens>
			</definition>
</paper>

		<paper id="0105">
			<definition id="0">
				<sentence>The Treebank consists of a correct parse for each sentence it contains ; with respect to the ATR English Grammar .</sentence>
				<definiendum id="0">Treebank</definiendum>
			</definition>
			<definition id="1">
				<sentence>The ATR parser is a probabilistic parser which uses decision-tree models .</sentence>
				<definiendum id="0">ATR parser</definiendum>
			</definition>
			<definition id="2">
				<sentence>Transition between states is accomplished by one of the following steps : ( 1 ) assigning syntax to a word ; ( 2 ) assigning semantics to a word ; ( 3 ) deciding whether the current parse tree node is the last node of a constituent ; ( 4 ) assigning a ( rule ) label to an internal node of the parse tree .</sentence>
				<definiendum id="0">tree node</definiendum>
				<definiens id="0">accomplished by one of the following steps : ( 1 ) assigning syntax to a word ; ( 2 ) assigning semantics to a word ; ( 3 ) deciding whether the current parse</definiens>
				<definiens id="1">the last node of a constituent ; ( 4 ) assigning a ( rule ) label to an internal node of the parse tree</definiens>
			</definition>
			<definition id="3">
				<sentence>The estimated probability of any parse state is the product of the probabilities of each step taken to reach that state .</sentence>
				<definiendum id="0">estimated probability of any parse state</definiendum>
				<definiens id="0">the product of the probabilities of each step taken to reach that state</definiens>
			</definition>
			<definition id="4">
				<sentence>Consistency is the degree to which all team members posit the identical parse for the identical sentence in the identical document of test data .</sentence>
				<definiendum id="0">Consistency</definiendum>
			</definition>
			<definition id="5">
				<sentence>Vocabulary Size ( Tr~Jniug Corpus ) Domain Tagset Size Nonterminal Labels Test-Data Source Training Set Size ( in words ) Test Set Size ( in words ) Average Sentence Length ( TraJ-i~g Corpus ) Average Sentence Length ( Test Corpus ) Number of Constits in 20-Word Sentence Restricted 3,000 IBM Computer Manuals 193 17 ?</sentence>
				<definiendum id="0">Vocabulary Size</definiendum>
			</definition>
			<definition id="6">
				<sentence>For instance , as noted in 3.1 , the Parse Base of the ATR English Grammar , which generates the parses of the ATl~/Lancaster Treebank , is 1.76 , which means that on average , the Grammar generates about 200 parses for 10-word sentence ; 2000 parses for a IS-word sentence , and 70,000 parses for a 20-word sentence .</sentence>
				<definiendum id="0">ATl~/Lancaster Treebank</definiendum>
				<definiens id="0">noted in 3.1 , the Parse Base of the ATR English Grammar , which generates the parses of the</definiens>
			</definition>
			<definition id="7">
				<sentence>A simpler , but probably adequate approach would combine the two models p ( A ) and p ( AIF ) heuristically , using p ( AIF ) to rescore the N best parses found by the model p ( A ) .</sentence>
				<definiendum id="0">AIF</definiendum>
				<definiens id="0">) to rescore the N best parses found by the model p ( A )</definiens>
			</definition>
			<definition id="8">
				<sentence>Evaluation Methodology We evaluate trsebank conversion to ATR-Treebank format in the same way as we evaluate the parser when it is trained in the normal ma-ner ( cf. 4.1 ) , except that test data consists of ATR-Treebank-format documents of which we also possess aligned source treebank ( in this case : IBM/Lancaster-Treebank ) versions .</sentence>
				<definiendum id="0">IBM/Lancaster-Treebank</definiendum>
				<definiens id="0">We evaluate trsebank conversion to ATR-Treebank format in the same way as we evaluate the parser when it is trained in the normal ma-ner ( cf. 4.1 ) , except that test data consists of ATR-Treebank-format documents of which we also possess aligned source treebank</definiens>
			</definition>
</paper>

		<paper id="1411">
			<definition id="0">
				<sentence>Projects which have attempted to ' integrate natural language ( NL ) with graphical displays ( B~s and Guillotin , 1992 ; Neal and Shapiro , 1991 ; Pineda , 1989 ) have mainly focussed on one of two problems : graphical information displayed on the screen ?</sentence>
				<definiendum id="0">NL</definiendum>
			</definition>
</paper>

		<paper id="0605">
</paper>

		<paper id="0807">
			<definition id="0">
				<sentence>6 wl w2 w3 w4 Figure 1 : A fragment of the thesaurus X 1 `` ~X2 -~X 3 `` ~X 5 = vsm ( wl , w3 ) Xl'~X2 +x3+x6 = vsm ( wl , w4 ) xl +x2+x4+x5 = vsm ( w~ , ws ) Figure 2 : A fragment of the simultaneous equation associated with figure 1 Our word similarity measurement proceeds in the following way : combination of given words , thesaurus and previously computed word similarity , and find solutions for the statistics-based length ( SBL ) of the corresponding thesaurus branch ( see figures 1 and 2 ) , by the sum of SBLs included in the path between those words .</sentence>
				<definiendum id="0">SBL</definiendum>
				<definiens id="0">A fragment of the simultaneous equation associated with figure 1 Our word similarity measurement proceeds in the following way : combination of given words , thesaurus and previously computed word similarity , and find solutions for the statistics-based length (</definiens>
			</definition>
			<definition id="1">
				<sentence>This can be expressed by equation ( 1 ) , where ~z is the vector for the word in question , and t , j is the cooccurrence statistics of w~ and w : .</sentence>
				<definiendum id="0">~z</definiendum>
				<definiens id="0">the cooccurrence statistics of w~ and w</definiens>
			</definition>
			<definition id="2">
				<sentence>Based on this notion , t , ~ is calculated as in equation ( 2 ) , where \ ] ~ is the frequency of w , collocating 45 with w3 , f3 is the frequency of w3 , and T is the total number of collocations within the overall co-occurrence data .</sentence>
				<definiendum id="0">f3</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the frequency of w3 , and</definiens>
				<definiens id="1">the total number of collocations within the overall co-occurrence data</definiens>
			</definition>
			<definition id="3">
				<sentence>X is a list of variables , which represents the statisticsbased length ( SBL ) for the corresponding branch in the thesaurus .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">SBL</definiendum>
				<definiens id="0">a list of variables , which represents the statisticsbased length (</definiens>
			</definition>
			<definition id="4">
				<sentence>In this figure , x,1 and x~2 denote the answers for branch i individually derived from subsets 1 and 2 , and x~ is approximated by the average of xzl and x,2 ( that is , x , l+x,2 ~ To generalize this notion , let x , j denote the 2 / '' solution associated with branch i in subset j. The approximate solution for branch i is given by equation ( 7 ) , where n is the number of divisions of the equation set .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of divisions of the equation set</definiens>
			</definition>
			<definition id="5">
				<sentence>In general , the similarity between words a and b using SBL ( sbl ( a , b ) , hereafter ) is realized by equation ( 8 ) , where x~ is the SBL for branch i , and path ( a , b ) is the path that includes thesaurus branches located between a and b. sbl ( a , b ) = E x~ ( 8 ) ~Epath ( a , b ) We conducted experiments on noun entries in the Bunruigoihyo thesaurus .</sentence>
				<definiendum id="0">x~</definiendum>
				<definiendum id="1">path</definiendum>
				<definiens id="0">the path that includes thesaurus branches located between a and b. sbl ( a , b</definiens>
			</definition>
			<definition id="6">
				<sentence>max sim ( nc , e ) ( 9 ) C eE~s , c CCD ( c ) expresses the weight factor of case c using the notion of case contribution to verb sense disambiguation ( CCD ) proposed by Fujii et al \ [ Fujii et al. , 1996\ ] .</sentence>
				<definiendum id="0">c CCD ( c )</definiendum>
				<definiens id="0">expresses the weight factor of case c using the notion of case contribution to verb sense disambiguation</definiens>
			</definition>
			<definition id="7">
				<sentence>Besides this , as we pointed out in section 1 , SBL allows us to reduce the data size from O ( N 2 ) to O ( N ) in our framework , given that N is the number of word entries .</sentence>
				<definiendum id="0">SBL</definiendum>
				<definiens id="0">allows us to reduce the data size from O</definiens>
				<definiens id="1">the number of word entries</definiens>
			</definition>
</paper>

		<paper id="0118">
			<definition id="0">
				<sentence>The work makes use of the Abbot recogniser , which is a eonnectionist/HMM continuous speech recognition system developed by the Connectionist Speech Group at Cambridge University .</sentence>
				<definiendum id="0">Abbot recogniser</definiendum>
				<definiens id="0">a eonnectionist/HMM continuous speech recognition system developed by the Connectionist Speech Group at Cambridge University</definiens>
			</definition>
			<definition id="1">
				<sentence>The British National Corpus ( BNC ) is a suitable example , since it contains 100 million words of modem English , both spoken and written , sampled from the widest range of materials .</sentence>
				<definiendum id="0">British National Corpus ( BNC )</definiendum>
				<definiens id="0">a suitable example , since it contains 100 million words of modem English , both spoken and written , sampled from the widest range of materials</definiens>
			</definition>
			<definition id="2">
				<sentence>BNC : the whole of the BNC Email : the 2 million word email corpus For large samples such as these the rank correlation coefficient has a normal distribution with mean 0 and variance 1/ ( n-l ) where n is the number of common words .</sentence>
				<definiendum id="0">BNC</definiendum>
				<definiendum id="1">BNC Email</definiendum>
				<definiendum id="2">n</definiendum>
				<definiens id="0">the number of common words</definiens>
			</definition>
			<definition id="3">
				<sentence>Accuracy = x 100 % N where : H is the number of correct transcriptions ( words in the utterance that are found in the transcription ) , D is the number of deletions ( words in the utterance that are missing from the transcription ) , S is the number of substitutions ( words in the utterance that are replaced by an incorrect word in the transcription ) , and I is the number of insertions ( extra words in the transcription ) .</sentence>
				<definiendum id="0">H</definiendum>
				<definiendum id="1">D</definiendum>
				<definiendum id="2">S</definiendum>
				<definiens id="0">the number of correct transcriptions ( words in the utterance that are found in the transcription )</definiens>
				<definiens id="1">the number of deletions ( words in the utterance that are missing from the transcription</definiens>
				<definiens id="2">the number of substitutions ( words in the utterance that are replaced by an incorrect word in the transcription</definiens>
			</definition>
			<definition id="4">
				<sentence>As mentioned above , the VMR database is a collection of speech data with transcriptions ( of which the latter were used in the above evaluation ) .</sentence>
				<definiendum id="0">VMR database</definiendum>
				<definiens id="0">a collection of speech data with transcriptions ( of which the latter were used in the above evaluation</definiens>
			</definition>
</paper>

		<paper id="0320">
			<definition id="0">
				<sentence>is calculated as follows , where the numerator is the average percentage agreement among the annotators ( Pa ) less a term for chance agreement ( Pc ) , and the denominator is 100 % agreement less the same term for chance agreement ( Pe ) : Pa Re 1 Pe ( For details on calculating Pa and Pe see Siegel &amp; Castellan 1988 ) .</sentence>
				<definiendum id="0">Pc</definiendum>
				<definiens id="0">the average percentage agreement among the annotators ( Pa ) less a term for chance agreement</definiens>
			</definition>
			<definition id="1">
				<sentence>Resolvent : the union of the information in the two Temporal Units .</sentence>
				<definiendum id="0">Resolvent</definiendum>
				<definiens id="0">the union of the information in the two Temporal Units</definiens>
			</definition>
			<definition id="2">
				<sentence>specificity ( TU ) : returns the specificity of the most specific field in TU .</sentence>
				<definiendum id="0">specificity ( TU )</definiendum>
				<definiens id="0">returns the specificity of the most specific field in TU</definiens>
			</definition>
			<definition id="3">
				<sentence>TU is the current temporM 179 unit being resolved .</sentence>
				<definiendum id="0">TU</definiendum>
				<definiens id="0">the current temporM 179 unit being resolved</definiens>
			</definition>
			<definition id="4">
				<sentence>TodaysDate is a representation of the dialog date .</sentence>
				<definiendum id="0">TodaysDate</definiendum>
				<definiens id="0">a representation of the dialog date</definiens>
			</definition>
			<definition id="5">
				<sentence>FocusList is the list of discourse entities from all previous utterances .</sentence>
				<definiendum id="0">FocusList</definiendum>
				<definiens id="0">the list of discourse entities from all previous utterances</definiens>
			</definition>
			<definition id="6">
				<sentence>Accuracy measures the degree to which the system produces the correct answers , while precision measures the degree to which the system 's answers are correct ( see the formulas in the tables ) .</sentence>
				<definiendum id="0">Accuracy</definiendum>
				<definiens id="0">measures the degree to which the system produces the correct answers , while precision measures the degree to which the system 's answers are correct ( see the formulas in the tables )</definiens>
			</definition>
			<definition id="7">
				<sentence>for each non-empty temporal unit TUIt from FocusList ( starting with most recent ) if specificity ( TU ) &gt; specificity ( TUfl ) then TUternp = TUlt for each { f I f - &gt; most specific field in TU } TUte , np~f = null if not empty merge ( TUtemp , TU ) then CF = 0.5 distance_factor ( TUlt , FocusList ) return { \ [ when , merge ( TUtemp , TU ) \ ] , \ [ certainty , CF\ ] } Figure 3 : Main Temporal Resolution Rules 181 Label Cot Inc Mis Ext Nul start Month 49 3 7 3 0 Date 48 4 7 3 0 WeekDay 46 6 7 3 0 HourMin 18 0 7 0 37 TimeDay 9 0 18 0 35 end Month 48 3 7 1 3 Date 47 5 6 3 1 WeekDay 45 7 6 3 1 HourMin 9 0 9 0 44 TimeDay 4 0 13 1 44 overall 323 28 87 17 165 Legend Cor ( rect ) : Inc ( orrect ) : Mis ( sing ) : Ext ( ra ) : Nul ( l ) : Acc ( uracy ) LB : Acc ( uracy ) : AccLB Acc System and key agree on non-null value System and key differ on non-null value System has null value for non-null key System has non-null value for null key Both System and key give null answer accuracy lower bound percentage of key values matched correctly Prec ( Correct + Null ) / ( Correct + Incorrect + Missing + Null ) Prec ( ision ) : percentage of System answers matching the key ( Correct + Null ) / ( Correct + Incorrect + Extra + Null ) Table 2 : Evaluation of System on CMU Test Data Label start Month 55 0 23 Date 49 6 23 WeekDay 52 3 23 HourMin 34 3 7 TimeDay 18 8 31 end Month 55 0 23 Date 49 6 23 WeekDay 52 3 23 HourMin 28 2 13 TimeDay 9 2 32 overall 401 33 221 i ... .. Table 3 : 5 3 0.060 0.716 0.921 5 3 0.060 0.642 0.825 5 3 0.085 0.679 0.873 6 36 0.852 0.875 0.886 2 27 0.354 0.536 0.818 5 3 0.060 0.716 0.921 5 3 0.060 0.642 0.825 5 3 0.060 0.679 0.873 1 42 0.795 0.824 0.959 5 38 0.482 0.580 0.870 44 161 0.286 0.689 0.879 Evaluation of System on NMSU Test Data Set cmu nmsu Cor Inc Mis Ext Nul Acc Input Error 84 6 360 10 190 0.428 0.055 65 3 587 4 171 0.286 0.029 Table 4 : Lower Bounds for both Test Sets 182 seen/ emu/ unseen nmsu seen cmu seen cmu unseen cmu seen nmsu seen nmsu unseen nmsu Ambiguous/ # dialogs\ ] # utterances Accuracy Precision unambiguous ambiguous 12 659 0.883 0.918 unambiguous 12 659 0.914 0.957 ambiguous 3 193 0.809 0.916 ambiguous 4 0.679 unambiguous ambiguous 358 358 236 Table 5 : Results on Corrected Input ( to isolate focus issues ) are noticeable gains in performance on the seen data going from ambiguous to unambiguous input , especially for the NMSU data .</sentence>
				<definiendum id="0">Ext ( ra )</definiendum>
				<definiendum id="1">uracy ) : AccLB Acc</definiendum>
				<definiens id="0">Main Temporal Resolution Rules 181 Label Cot Inc Mis Ext Nul start Month 49 3 7 3 0 Date 48 4 7 3 0 WeekDay 46 6 7 3 0 HourMin 18 0 7 0 37 TimeDay 9 0 18</definiens>
				<definiens id="1">null value for non-null key System has non-null value for null key Both System and key give null answer accuracy lower bound percentage of key values matched correctly Prec</definiens>
				<definiens id="2">percentage of System answers matching the key ( Correct + Null ) / ( Correct + Incorrect + Extra + Null</definiens>
				<definiens id="3">Results on Corrected Input ( to isolate focus issues ) are noticeable gains in performance on the seen data going from ambiguous to unambiguous input</definiens>
			</definition>
</paper>

		<paper id="0612">
			<definition id="0">
				<sentence>Input speech is analyzed by the following conditions : Sampling frequency : Hamming window size : Frame period : LPC analysis : Feature parameter : 12kHz 21.33ms ( 256 samples ) 8ms 14th order 10 LPC Mel-cepstram coefficients and regression coefficients ( ACEP ) The acoustic models consist of 113 syllable based HMMs , which have 5 states , 4 Gaussian densities and 4 discrete duration distributions .</sentence>
				<definiendum id="0">HMMs</definiendum>
				<definiens id="0">analyzed by the following conditions : Sampling frequency : Hamming window size : Frame period : LPC analysis : Feature parameter : 12kHz 21.33ms ( 256 samples ) 8ms 14th order 10 LPC Mel-cepstram coefficients and regression coefficients ( ACEP ) The acoustic models consist of 113 syllable based</definiens>
			</definition>
			<definition id="1">
				<sentence>On man-machine communication , user wants to know his or machine situation what information he gets from the dialogue or how machine interprets/understands his utterances , as well as the speech recognition result .</sentence>
				<definiendum id="0">user</definiendum>
				<definiens id="0">wants to know his or machine situation what information he gets from the dialogue or how machine interprets/understands his utterances</definiens>
			</definition>
			<definition id="2">
				<sentence>Firstly , the dialogue manager receives a semantic representation ( that is , semantic network ) through the semantic interpreter for the user 's utterance .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">receives a semantic representation ( that is , semantic network ) through the semantic interpreter for the user 's utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>The dialogue manager is a component which carries out some operations such as dialogue management , control of contextual information and query to users .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">a component which carries out some operations such as dialogue management , control of contextual information</definiens>
			</definition>
			<definition id="4">
				<sentence>Secondly , to get intention for managing dialogues , the dialogue manager passes semantic network to intention ( M ) analyzer which extracts a dialogue intention and conditions/information of a user 's query .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">passes semantic network to intention ( M ) analyzer which extracts a dialogue intention and conditions/information of a user 's query</definiens>
			</definition>
			<definition id="5">
				<sentence>Thirdly , the dialogue manager passes a semantic network and contextual information to problem solver to retrieve any information from the knowledge database .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">passes a semantic network and contextual information to problem solver to retrieve any information from the knowledge database</definiens>
			</definition>
			<definition id="6">
				<sentence>Finally , the response sentence generator decides a response form from the received inputs and then forms response sentence networks according to this form .</sentence>
				<definiendum id="0">response sentence generator</definiendum>
				<definiens id="0">decides a response form from the received inputs and then forms response sentence networks according to this form</definiens>
			</definition>
			<definition id="7">
				<sentence>`` Data presentation '' is the rate that the system offered the valuable information to user .</sentence>
				<definiendum id="0">Data presentation ''</definiendum>
				<definiens id="0">the rate that the system offered the valuable information to user</definiens>
			</definition>
</paper>

		<paper id="0301">
			<definition id="0">
				<sentence>Starting from the left , CHUNK assigns each ( word , POS tag ) pair a `` chunk '' tag , either Start X , Join X , or Other .</sentence>
				<definiendum id="0">CHUNK</definiendum>
				<definiendum id="1">POS tag</definiendum>
				<definiens id="0">assigns each ( word ,</definiens>
			</definition>
			<definition id="1">
				<sentence>w , have all been assigned Join X. The result of chunk detection , shown in figure 4 , is a forest of trees and serves as the input to the third pass .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">a forest of trees</definiens>
			</definition>
			<definition id="2">
				<sentence>Accordingly , it annotates the tree with either Start X , where X is any constituent label , or with Join X , where X matches the label of the incomplete constituent to the left .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">any constituent label , or with Join X , where X matches the label of the incomplete constituent to the left</definiens>
			</definition>
			<definition id="3">
				<sentence>The third pass terminates when CHECK is presented a constituent that spans the entire sentence .</sentence>
				<definiendum id="0">CHECK</definiendum>
				<definiens id="0">presented a constituent that spans the entire sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>Each training sample has the form T = ( ( al , 51 ) , ( a2 , b2 ) , ... , CaN , bN ) } , where ai is an action of the corresponding procedure and bi is the list of contextual predicates that were true in the context in which al was decided .</sentence>
				<definiendum id="0">ai</definiendum>
				<definiens id="0">the list of contextual predicates that were true in the context in which al was decided</definiens>
			</definition>
			<definition id="5">
				<sentence>The training samples are respectively used to create the models PT^G , PCHUNK , PBUILD , and PCMECK , all of which have the form : k p ( a , b ) = II _ij ( o , b ~j ( 1 ) j -- -- 1 where a is some action , b is some context , ~ '' is a nor4 Model Categories Description Templates Used TAG See ( Ratnaparkhi , 1996 ) CHUNK chunkandpostag ( n ) * BUILD CHECK chunkandpostag ( m , n ) * cons ( n ) cons ( re , n ) * cons ( m , n , p ) T punctuation checkcons ( n ) * checkcons ( m , n ) * production surround ( n ) * The word , POS tag , and chunk tag of nth leaf .</sentence>
				<definiendum id="0">k p</definiendum>
				<definiendum id="1">b</definiendum>
				<definiendum id="2">n ) cons</definiendum>
				<definiens id="0">n , p ) T punctuation checkcons</definiens>
				<definiens id="1">n ) * production surround ( n ) * The word , POS tag , and chunk tag of nth leaf</definiens>
			</definition>
			<definition id="6">
				<sentence>For each model , the corresponding conditional probability is defined as usual : p ( a , b ) P ( alb ) = Ea'eA p ( a ' , b ) For notational convenience , define q as follows \ [ PrAa ( a\ ] b ) if a is an action from TAG pCStmK ( a\ [ b ) if a is an action from CHUNK q ( alb ) = PBUILD ( al b ) if a is an action from BUILD PcnEcK ( alb ) if a is an action from CHECK Let deriv ( T ) = { al , ... , an } be the derivation of a parse T , where T is not necessarily complete , and where each al is an action of some tree-building procedure .</sentence>
				<definiendum id="0">corresponding conditional probability</definiendum>
				<definiendum id="1">Ea'eA p</definiendum>
				<definiens id="0">an action from CHECK Let deriv ( T ) = { al , ... , an } be the derivation of a parse T , where T is not necessarily complete , and where each al is an action of some tree-building procedure</definiens>
			</definition>
			<definition id="7">
				<sentence>The bigram parser is a statistical CKY-style chart parser , which uses cooccurrence statistics of headmodifier pairs to find the best parse .</sentence>
				<definiendum id="0">bigram parser</definiendum>
			</definition>
			<definition id="8">
				<sentence>The maximum entropy parser is a statistical shift-reduce style parser that can not always access head-modifier pairs .</sentence>
				<definiendum id="0">maximum entropy parser</definiendum>
				<definiens id="0">a statistical shift-reduce style parser that can not always access head-modifier pairs</definiens>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>An IAC network consists of a collection of processing units divided into several competitive pools .</sentence>
				<definiendum id="0">IAC network</definiendum>
				<definiens id="0">consists of a collection of processing units divided into several competitive pools</definiens>
			</definition>
			<definition id="1">
				<sentence>Subnetworks differ in their `` time-constants '' i.e. respond to information over different time-scales .</sentence>
				<definiendum id="0">Subnetworks</definiendum>
				<definiens id="0">differ in their `` time-constants '' i.e. respond to information over different time-scales</definiens>
			</definition>
			<definition id="2">
				<sentence>The dynamics of all units in the network are governed by the first order equation da~ ~ s~n s vn dt = 2-~wiJ aj-a~ ( 1 ) s , j Where v , ~ is the time constant for subnetwork n , a~ is the activity of the jth unit in subnetwork s , a~ is the activity of the i th unit in subnetwork n , u~ .</sentence>
				<definiendum id="0">dynamics of all</definiendum>
				<definiendum id="1">a~</definiendum>
				<definiendum id="2">a~</definiendum>
				<definiens id="0">the time constant for subnetwork n</definiens>
				<definiens id="1">the activity of the jth unit in subnetwork s ,</definiens>
			</definition>
			<definition id="3">
				<sentence>Evolution does all the hard work and gives the network a developmental `` legup '' .</sentence>
				<definiendum id="0">Evolution</definiendum>
				<definiens id="0">does all the hard work and gives the network a developmental `` legup ''</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>Decision problems are classically defined as problems whose answers fall in either of two classes : Yes and No ( Garey and Johnson , 1979 ) .</sentence>
				<definiendum id="0">Decision problems</definiendum>
			</definition>
			<definition id="1">
				<sentence>If it is attached to Kayaalp , Pedersen ~ Bruce 33 Statistical PP Attachment Mehmet Kayaalp , Ted Pedersen and Rebecca Bruce ( 1997 ) A Statistical Decision Making Method : A Case Study on Prepositional Phrase Attachment .</sentence>
				<definiendum id="0">Statistical Decision Making Method</definiendum>
				<definiens id="0">A Case Study on Prepositional Phrase Attachment</definiens>
			</definition>
			<definition id="2">
				<sentence>Both PPA data were formatted in tuples with five variables ( 4 ) , which denote the class ( i.e. , the PPA attachment site ) and the features ( i.e. , verb , object noun , preposition and PP noun ) in the respective order• Values of these variables for the above example ( 1 ) are illustrated in ( 5 ) , where ( A , B , C , D , E ) ( 4 ) ( verb lnoun , `` describe '' , `` problem '' , `` on '' , `` paper '' X5 ) For representation convenience , we can map the values of these variables to positive integers as in Table 1 .</sentence>
				<definiendum id="0">PPA</definiendum>
				<definiens id="0">data were formatted in tuples with five variables ( 4 ) , which denote the class ( i.e. , the PPA attachment site ) and the features ( i.e. , verb , object noun , preposition and PP noun</definiens>
			</definition>
			<definition id="3">
				<sentence>These missing edges denote three conditional independence relations : pendent given AB ( intersection of two cliques , ABD N ABE ) .</sentence>
				<definiendum id="0">ABD N ABE</definiendum>
				<definiens id="0">pendent given AB ( intersection of two cliques ,</definiens>
			</definition>
			<definition id="4">
				<sentence>When all variables are considered to be interdependent ( i.e. , the saturated decomposable model ) the maximum likelihood estimate of the probability of any 5-tuple is equal to the count in the corresponding cell noklm divided by the total count N , which is equal to 24,840 for the IBM training data ( Table 2 ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the saturated decomposable model ) the maximum likelihood estimate of the probability of any 5-tuple is equal to the count in the corresponding cell noklm divided by the total count</definiens>
			</definition>
			<definition id="5">
				<sentence>CO } , where Cd denotes a clique in the graph representation of A// , then the direct estimates ( MLEs ) are computed as in ( 19 ) .</sentence>
				<definiendum id="0">Cd</definiendum>
			</definition>
			<definition id="6">
				<sentence>The MLE algorithm is a table look up , where each table contains marginal values for a clique of variables as defined in the graph representation .</sentence>
				<definiendum id="0">MLE algorithm</definiendum>
				<definiens id="0">a table look up , where each table contains marginal values for a clique of variables as defined in the graph representation</definiens>
			</definition>
			<definition id="7">
				<sentence>Non-recursive Model Switching consists of two phases : out cross-validation ) , data ; whenever that model does not yield any estimate , the system switches to the next model on the list .</sentence>
				<definiendum id="0">Non-recursive Model Switching</definiendum>
				<definiens id="0">consists of two phases : out cross-validation ) , data ; whenever that model does not yield any estimate , the system switches to the next model on the list</definiens>
			</definition>
			<definition id="8">
				<sentence>These four symbolic classifiers are well known and are diverse to some extent : Naive Bayes is a simple Bayesian approach , CN2 is based on rule induction , C4.5 is based on decision trees , and PEBLS is based on nearest neighbor method .</sentence>
				<definiendum id="0">Naive Bayes</definiendum>
				<definiendum id="1">PEBLS</definiendum>
				<definiens id="0">a simple Bayesian approach</definiens>
			</definition>
			<definition id="9">
				<sentence>With only two test trials and without any deviation measure these differences can not be considered significant , especially in this case , where the performances of the classifiers fluctuate 2-3 % ( e.g. , C~B accuracy deviates 2.2 % ) within two very similar data sets , B~R and IBM data .</sentence>
				<definiendum id="0">C~B accuracy</definiendum>
			</definition>
			<definition id="10">
				<sentence>As one anonymous reviewer indicated , the 0.7 % accuracy difference on B &amp; R data needs to be evaluated cautiously due to the size of the B~R test data , which contains only 500 test instances ; whereas the IBM data contains 3097 test instances .</sentence>
				<definiendum id="0">B~R test data</definiendum>
				<definiens id="0">contains only 500 test instances ; whereas the IBM data contains 3097 test instances</definiens>
			</definition>
			<definition id="11">
				<sentence>MS1 is a machine learning alternative to the system developed by ( Collins and Brooks , 1995 ) , and the ordering of the models that it produces may provide insight into the data that could aid in developing a custom mixture model .</sentence>
				<definiendum id="0">MS1</definiendum>
				<definiens id="0">it produces may provide insight into the data that could aid in developing a custom mixture model</definiens>
			</definition>
			<definition id="12">
				<sentence>Unlike the other techniques , MS1 generates an ordered list of models where each model provides a graphical representation of the interdependencies among variables .</sentence>
				<definiendum id="0">MS1</definiendum>
			</definition>
</paper>

		<paper id="0216">
</paper>

		<paper id="0111">
</paper>

		<paper id="0705">
			<definition id="0">
				<sentence>abstracts , and a hst of mstructlons explaining the approach to be used ( the `` jurors '' each had different texts Each reader-assessor then had to read the documents m a pre-defined order ( firstly , all the abstracts , then all the source texts ) , fill m the reader 's sheet ( attached to each document ) as he went along , give Ins overall opmmn on the `` comparison sheets '' provided for thts purpose The second stage of the assessment revolved analysing the sheets returned by the readers The-whole experiment ( defmamn of procedure , and the actual assessment ) lasted a total of eight months On the basis of the experiments camed out by Borko et al ( 1975 ) , Edmunson ( 1969 ) , Mathls et al ( 1973 ) , Payne ( 1964 ) on the assessment of the quahty of `` abstracts '' , and m terms of the apphcat~ons defined ( section 3 1 ) , we set four criteria , and for each criterion we estabhshed the means of assessing it Apphcatlon I For the first apphcatton , the criteria defined in MLUCE are designed to assess the utdlty of the abstract as a statable dec~ston-makmg tool for the reader These criteria must allow one to judge whether the abstract contains the mformauon requwed to be able to decide whether or not to read the source text In order to do so , we wall say that the abstract must allow usto * Identify the field or nature of the source text Each reader fills m two grids ( one for the source text and one for the 27 abstract ) which show the fields or natures of the texts sctenufic or techmcal , pohtlcal , sociological , polemical , general , prospective , retrospective , situational or state-ofthe-art • check the presence of the essentml Ideas Each reader underlines the ideas m text Tt which he feels to be essential , and checks that they are present m abstract R~ • avmd parasmc ideas Each reader highhghts sentences In R~ which should not be m RI , and the sentences m abstract Rt which are cut off from the context ( essential ideas that have been cut short ) Apphcauon 2 For the second application , the cntena defined m MLUCE • are designed to assess the utthty of the abstract as a support for writing a synthesis of a written document In order to do so , we will say that the abstract must allow us to • identify the fie !</sentence>
				<definiendum id="0">avmd parasmc</definiendum>
				<definiens id="0">the `` jurors '' each had different texts Each reader-assessor then had to read the documents m a pre-defined order ( firstly , all the abstracts , then all the source texts ) , fill m the reader 's sheet ( attached to each document ) as he went along , give Ins overall opmmn on the `` comparison sheets '' provided for thts purpose The second stage of the assessment revolved analysing the sheets returned by the readers The-whole experiment ( defmamn of procedure , and the actual assessment</definiens>
				<definiens id="1">designed to assess the utdlty of the abstract as a statable dec~ston-makmg tool for the reader These criteria must allow one to judge whether the abstract contains the mformauon requwed to be able to decide whether or not to read the source text In order to do so , we wall say that the abstract must allow usto * Identify the field or nature of the source text Each reader fills m two grids ( one for the source text and one for the 27 abstract ) which show the fields or natures of the texts sctenufic or techmcal , pohtlcal , sociological , polemical , general , prospective , retrospective , situational or state-ofthe-art • check the presence of the essentml Ideas Each reader underlines the ideas m text Tt which he feels to be essential , and checks that they are present m abstract R~ •</definiens>
			</definition>
</paper>

		<paper id="0107">
			<definition id="0">
				<sentence>The inside-outside algorithm is a probabilistic parameter reestimation algorithm for phrase structure grammars in Chomsky Normal Form ( CNF ) .</sentence>
				<definiendum id="0">inside-outside algorithm</definiendum>
			</definition>
			<definition id="1">
				<sentence>The reestimation and BFP algorithms utilize CYK-style chart and the nonconstituent objects as chart entries .</sentence>
				<definiendum id="0">BFP algorithms</definiendum>
				<definiens id="0">utilize CYK-style chart and the nonconstituent objects as chart entries</definiens>
			</definition>
			<definition id="2">
				<sentence>Dependency grammar defines a language as a set of dependency relations between any two words .</sentence>
				<definiendum id="0">Dependency grammar</definiendum>
				<definiens id="0">defines a language as a set of dependency relations between any two words</definiens>
			</definition>
			<definition id="3">
				<sentence>Complete-sequence is defined as a sequence of null or more adjacent complete-lknks of same direction .</sentence>
				<definiendum id="0">Complete-sequence</definiendum>
				<definiens id="0">a sequence of null or more adjacent complete-lknks of same direction</definiens>
			</definition>
			<definition id="4">
				<sentence>\ ] IlWi Wi+l , , comprehend link Rightward Complete-link I Wi Wk Wm Rightward Complete-sequence Wm+ 1 WI Wj Leftward Complete-sequence tmi complet~ sequence Figure 2 : Abstract complete-link and complete-sequence • St ( i , j ) : rightward complete-sequence for wit/ , i.e. { St ( i , m ) , Lr ( m , j ) } • Sz ( i , j ) : leftward complete-sequence for wid , i.e. { Lt ( ~ , m ) , Sdm , j ) } To generalize the structure of a dependency tree , we assume that there are marking tags , BOS ( Begin Of Sentence ) before w , and EOS ( End Of Sentence ) after wn and that there are always the dependency links , ( wBos -- + WEos ) and ( wk ~-wEos ) when wk is the head word of the sentence .</sentence>
				<definiendum id="0">BOS</definiendum>
				<definiendum id="1">EOS</definiendum>
				<definiendum id="2">wk</definiendum>
				<definiens id="0">the dependency links , ( wBos -- + WEos ) and ( wk ~-wEos ) when</definiens>
			</definition>
			<definition id="5">
				<sentence>Wj ... ... ... . Wk ( head ) ... Wn EOS Lr ( BOS , EOS ) Figure 3 : Abstract dependency tree of a sentence The probability of each object is defined as follows .</sentence>
				<definiendum id="0">Wk ( head ) ... Wn EOS Lr</definiendum>
			</definition>
			<definition id="6">
				<sentence>The best parse is maximum Lr ( BOS , EOS ) in the chart position ( 0 , n + 1 ) .</sentence>
				<definiendum id="0">EOS )</definiendum>
				<definiens id="0">in the chart position ( 0 , n + 1 )</definiens>
			</definition>
			<definition id="7">
				<sentence>So the ~r ( BOS , EOS ) is the same as the sentence probability which is the sum of probabilities of all the possible parses .</sentence>
				<definiendum id="0">EOS )</definiendum>
				<definiens id="0">the sum of probabilities of all the possible parses</definiens>
			</definition>
			<definition id="8">
				<sentence>-~p ( tree , wl , n , w~ ~ wj ) tree - ( ilJl , n , W , ~ Wj ) j-1 -~ p ( w~ , n , Lr ( i , j ) , S~ ( i , m ) , &amp; ( ~ + l , j ) ) rct=i j -- 1 -~ p ( ~ , ~ , ~_~ , w~ , ,~ , w , ~+~ , j , wj+~ , ,~ , L , .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">w~ , ,~ , w , ~+~ , j</definiens>
			</definition>
			<definition id="9">
				<sentence>The reestimation algorithm computes eight items for each chart box and the computation of each item needs maximally n number of productions and snmrnations respectively .</sentence>
				<definiendum id="0">reestimation algorithm</definiendum>
				<definiens id="0">computes eight items for each chart box and the computation of each item needs maximally n number of productions and snmrnations respectively</definiens>
			</definition>
			<definition id="10">
				<sentence>Korean is a partially ordered language in which the head words are always placed to the right of their dependent words .</sentence>
				<definiendum id="0">Korean</definiendum>
				<definiens id="0">a partially ordered language in which the head words are always placed to the right of their dependent words</definiens>
			</definition>
			<definition id="11">
				<sentence>The KAIST corpora consist of raw text corpus ( 45,000.000 wordphrases ) , POS tagged corpus ( 6,750,000 word-phrases ) , and tree tagged corpus ( 30,000 sentences ) at present .</sentence>
				<definiendum id="0">KAIST corpora</definiendum>
				<definiens id="0">consist of raw text corpus ( 45,000.000 wordphrases ) , POS tagged corpus ( 6,750,000 word-phrases ) , and tree tagged corpus ( 30,000 sentences ) at present</definiens>
			</definition>
</paper>

		<paper id="0317">
			<definition id="0">
				<sentence>Ambiguity is the most specific feature of natural languages , which sets them aside from programming languages , and which is at the root of the difficulty of the parsing enterprise , pervading languages at all levels : lexical , morphological , syntactic , semantic and pragmatic .</sentence>
				<definiendum id="0">Ambiguity</definiendum>
				<definiens id="0">the most specific feature of natural languages , which sets them aside from programming languages</definiens>
			</definition>
			<definition id="1">
				<sentence>The PP attachment model presented by Collins and Brooks ( 1995 ) determines the most likely attachment for a particular prepositional phrase by estimating the probability of the attachment .</sentence>
				<definiendum id="0">PP attachment model</definiendum>
				<definiens id="0">determines the most likely attachment for a particular prepositional phrase by estimating the probability of the attachment</definiens>
			</definition>
			<definition id="2">
				<sentence>In the subsequent algorithms , C5 and C14 are used to indicate the larger sets of configurations .</sentence>
				<definiendum id="0">C5</definiendum>
				<definiens id="0">used to indicate the larger sets of configurations</definiens>
			</definition>
</paper>

		<paper id="0202">
			<definition id="0">
				<sentence>We note here a problem that we encountered using SEMCOR 's tag format for idioms : SEMCOR merges the component words of the idiom into one annotation , thereby making it impossible to unambiguously represent information about the individual words .</sentence>
				<definiendum id="0">SEMCOR</definiendum>
				<definiens id="0">merges the component words of the idiom into one annotation</definiens>
			</definition>
</paper>

		<paper id="0904">
			<definition id="0">
				<sentence>Formally , ff i is the predicted class and j is the true class , then for n classes , the total cost of misclassification is n n Cost = Z E Eij Cij i=lj=l where Eq is the number of errors and Cq is the cost for that type misclassification .</sentence>
				<definiendum id="0">Eq</definiendum>
				<definiendum id="1">Cq</definiendum>
				<definiens id="0">the number of errors</definiens>
			</definition>
			<definition id="1">
				<sentence>If misclassification costs are 24 assigned as negative numbers , and gains from correct classification as positive numbers , then we can express the total risk as n n Risk =g g E~jR~ i=l j=l where Eq is once again the number of errors and R e is the risk of classifying a case that truly belongs in class j into class i. Costs and risks can all be employed in conjunction with error rate analysis .</sentence>
				<definiendum id="0">R e</definiendum>
				<definiens id="0">n n Risk =g g E~jR~ i=l j=l where Eq is once again the number of errors</definiens>
				<definiens id="1">the risk of classifying a case that truly belongs in class</definiens>
			</definition>
			<definition id="2">
				<sentence>The estimatod error rate is the average of the error rates for classifiers derived for the independently and randomly generated tests partitions .</sentence>
				<definiendum id="0">estimatod error rate</definiendum>
			</definition>
			<definition id="3">
				<sentence>The error rate is the number of errors on the single test cases divided by n. Leaving-one-out is an elegant and straightforward technique for estimating classifier error rates .</sentence>
				<definiendum id="0">error rate</definiendum>
				<definiens id="0">the number of errors on the single test cases divided by n. Leaving-one-out is an elegant and straightforward technique for estimating classifier error rates</definiens>
			</definition>
			<definition id="4">
				<sentence>The leaving-one-out estimator is an almost unbiased estimator of the true error rate of a classifier .</sentence>
				<definiendum id="0">leaving-one-out estimator</definiendum>
				<definiens id="0">an almost unbiased estimator of the true error rate of a classifier</definiens>
			</definition>
			<definition id="5">
				<sentence>The estimated error rate is the average of the error rates over a number of iterations .</sentence>
				<definiendum id="0">estimated error rate</definiendum>
				<definiens id="0">the average of the error rates over a number of iterations</definiens>
			</definition>
</paper>

		<paper id="0323">
			<definition id="0">
				<sentence>In PEBLS ( Cost and Salzberg , 1993 ) , the distance between two symbolic values vl and v2 of a feature f is defined as : n d ( vl , v2 ) = E IP ( CdVl ) P ( c~I~ ) I i=l where n is the total number of classes .</sentence>
				<definiendum id="0">feature f</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the distance between two symbolic values vl and v2 of a</definiens>
				<definiens id="1">the total number of classes</definiens>
			</definition>
			<definition id="1">
				<sentence>P ( Ci\ ] vl ) h N 1 is estimated by N1 ' W ere ~ , ~ `` s the number of training examples with value vl for feature f that is classified as class i in the training corpus , and N1 is the number of training examples with value Vl for feature f in any class .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">N1</definiendum>
				<definiens id="0">the number of training examples with value vl for feature f that is classified as class i in the training corpus</definiens>
				<definiens id="1">the number of training examples with value Vl for feature f in any class</definiens>
			</definition>
			<definition id="2">
				<sentence>This algorithm is based on Bayes ' theorem : P ( nv~ IC~ ) P ( C~ ) P ( Ci\ ] A vj ) = P ( Avj ) i = 1 ... u where P ( Ci\ [ A vj ) is the probability that a test example is of class Ci given feature values vj .</sentence>
				<definiendum id="0">vj )</definiendum>
				<definiens id="0">the probability that a test example is of class Ci given feature values vj</definiens>
			</definition>
			<definition id="3">
				<sentence>( Avj denotes the conjunction of all feature values in the test example . )</sentence>
				<definiendum id="0">Avj</definiendum>
				<definiens id="0">the conjunction of all feature values in the test example</definiens>
			</definition>
			<definition id="4">
				<sentence>To avoid one zero count of P ( vj \ [ Ci ) nullifying the effect of the other non-zero conditional probabilities in the multiplication , we replace zero counts of P ( vj\ ] Ci ) by P ( Ci ) /N , where N is the total number of training examples .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of training examples</definiens>
			</definition>
			<definition id="5">
				<sentence>Cross validation is a well-known technique that can be used for estimating the expected error rate of a classifier which has been trained on a particular data set .</sentence>
				<definiendum id="0">Cross validation</definiendum>
				<definiens id="0">a well-known technique that can be used for estimating the expected error rate of a classifier which has been trained on a particular data set</definiens>
			</definition>
			<definition id="6">
				<sentence>The first test set , named BC50 , consists of 7,119 occurrences of the 191 words appearing in 50 text files of the Brown corpus .</sentence>
				<definiendum id="0">BC50</definiendum>
			</definition>
			<definition id="7">
				<sentence>The second test set , named WSJ6 , consists of 14,139 occurrences of the 191 words appearing in 6 text files of the WSJ corpus .</sentence>
				<definiendum id="0">WSJ6</definiendum>
			</definition>
			<definition id="8">
				<sentence>Decision lists for lexical ambiguity resolution : Application to accent restoration in Spanish and French .</sentence>
				<definiendum id="0">Decision lists</definiendum>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>Automatic word categorization is an important field of application in statistical natural language processing where the process is unsupervised and is carried out by working on n-gram statistics to find out the categories of words .</sentence>
				<definiendum id="0">Automatic word categorization</definiendum>
				<definiens id="0">an important field of application in statistical natural language processing where the process is unsupervised and is carried out by working on n-gram statistics to find out the categories of words</definiens>
			</definition>
			<definition id="1">
				<sentence>Lanchorst ( Lankhorst , 1994 ) uses genetic algorithms to determine the members of predetermined classes .</sentence>
				<definiendum id="0">Lanchorst</definiendum>
				<definiens id="0">uses genetic algorithms to determine the members of predetermined classes</definiens>
			</definition>
			<definition id="2">
				<sentence>Wilms ( Wilms , 1995 ) uses corpus based techniques together with knowledge-based techniques in order to induce a lexical sublanguage grammar .</sentence>
				<definiendum id="0">Wilms</definiendum>
				<definiens id="0">uses corpus based techniques together with knowledge-based techniques in order to induce a lexical sublanguage grammar</definiens>
			</definition>
			<definition id="3">
				<sentence>Machine Translation is an other area where knowledge bases and statistics Korkmaz ~ U~oluk 43 Automatic Word Categorization Emin Erkan Korkmaz and GSktiirk U~oluk ( 1997 ) A Method for Improving Automatic Word Categorization .</sentence>
				<definiendum id="0">Machine Translation</definiendum>
				<definiens id="0">an other area where knowledge bases and statistics Korkmaz ~ U~oluk 43 Automatic Word Categorization Emin Erkan Korkmaz and GSktiirk U~oluk ( 1997 ) A Method for Improving Automatic Word Categorization</definiens>
			</definition>
			<definition id="4">
				<sentence>Let X be a stochastic variable defined over the set X = { Xl , X2 , ... , x , ~ } where the probabilities Px ( xi ) are defined for 1 _ &lt; i _~ n as Px ( xi ) = P ( X = xi ) then the entropy of X , H ( X ) is defined as : H { X } =E Px ( x , ) logPx ( x , ) ( 1 ) And if Y is another stochastic variable than the mutual information between these two stochastic variables is defined as : I { X : V } : H { X } + H { Y } H { X , Y } ( 2 ) Korkmaz ~ O~oluk Here H { X , Y } is the joint entropy of the stochastic variables X and Y. The joint entropy is defined as : 44 H { X , Y } =E E P~u ( x '' YJ ) l°gP~u ( x '' YJ ) ( 3 ) And in this formulation Pxu ( xi , yj ) is the joint probability defined as P~u ( xi , yj ) : P ( X : x~ , Y : Given a lexicon space W = { wl , w2 , ... , w , } consisting of n words to be clustered , we can use the formulation of mutual information for the bigram statistics of a natural language corpus .</sentence>
				<definiendum id="0">H { X , Y }</definiendum>
				<definiens id="0">a stochastic variable defined over the set X = { Xl , X2 , ... , x , ~ } where the probabilities Px ( xi ) are defined for 1 _ &lt; i _~ n as Px ( xi ) = P ( X = xi ) then the entropy of X</definiens>
				<definiens id="1">H { X } =E Px ( x , ) logPx ( x , ) ( 1 ) And if Y is another stochastic variable than the mutual information between these two stochastic variables is defined as : I { X : V } : H { X } + H { Y } H { X</definiens>
				<definiens id="2">the joint entropy of the stochastic variables X and Y. The joint entropy is defined as : 44 H { X , Y } =E E P~u ( x '' YJ ) l°gP~u ( x '' YJ ) ( 3 ) And in this formulation Pxu ( xi , yj ) is the joint probability defined as P~u ( xi , yj ) : P ( X : x~ , Y : Given a lexicon space W = { wl , w2 , ... , w , } consisting of n words to be clustered , we can use the formulation of mutual information for the bigram statistics of a natural language corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>N** itx : Y } = ( 4 ) l _ &lt; i _ &lt; n l _ &lt; j _ &lt; n In this formulation N** is the total number of word pairs in the corpus and N~j is the number of occurances of word pair ( wordi , wordj ) , Ni .</sentence>
				<definiendum id="0">N~j</definiendum>
			</definition>
			<definition id="6">
				<sentence>is the number of occurences of wordi and N.j is the number of occurences of wordj respectively .</sentence>
				<definiendum id="0">N.j</definiendum>
				<definiens id="0">the number of occurences of wordj respectively</definiens>
			</definition>
			<definition id="7">
				<sentence>Since the mutual information denotes the amount of probabilistic knowledge that a word provides on the proceeding word in a corpus , if similar behaving words are collected together to the same clusters than the loss of mutual information would be minimal .</sentence>
				<definiendum id="0">mutual information</definiendum>
				<definiens id="0">the amount of probabilistic knowledge that a word provides on the proceeding word in a corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>Here Px is the probability of occurences of word pairs as stated in section 3.1 .</sentence>
				<definiendum id="0">Px</definiendum>
			</definition>
			<definition id="9">
				<sentence>Px ( wl , Z ) is the probability where Wl appears as the first element in a word pair and Px ( Z , wl ) is the reverse probability where wl is the second element of the word pair .</sentence>
				<definiendum id="0">wl</definiendum>
				<definiens id="0">the probability where Wl appears as the first element in a word pair</definiens>
				<definiens id="1">the second element of the word pair</definiens>
			</definition>
			<definition id="10">
				<sentence>The distance function D between two words wl and w2 is defined as follows : D ( wl , w2 ) = Dl ( Wl , w2 ) + D2 ( wl , w2 ) where ( 5 ) Dl ( Wl , W2 ) : ~ \ ] Px ( wl , Wl ) Px ( w2 , wl ) l l &lt; i &lt; n ( 6 ) and D~ ( wl , w2 ) = ~ I PX ( W , , Wl ) -Px ( wi , w2 ) \ ] l &lt; i &lt; n ( 7 ) Korkmaz ~ O~oluk 45 Here n is the total number of words to be clustered .</sentence>
				<definiendum id="0">w2</definiendum>
				<definiens id="0">follows : D ( wl , w2 ) = Dl ( Wl , w2 ) + D2 ( wl , w2 ) where ( 5 ) Dl ( Wl , W2 ) : ~ \ ] Px ( wl , Wl ) Px ( w2 , wl ) l l &lt; i &lt; n ( 6 ) and D~ ( wl</definiens>
			</definition>
			<definition id="11">
				<sentence>The membership function uij that is the degree of membership of the i th element to the jth cluster is defined as : ~x77~y = -K 1 ir ( 9 ) Ek=l I X77 5 Here Xi denotes an element in the search space , l , ~ is the centroid of the jth cluster .</sentence>
				<definiendum id="0">membership function uij</definiendum>
				<definiendum id="1">jth cluster</definiendum>
				<definiens id="0">the degree of membership of the i th element to the</definiens>
				<definiens id="1">an element in the search space , l</definiens>
			</definition>
			<definition id="12">
				<sentence>K denotes the number of clusters .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the number of clusters</definiens>
			</definition>
</paper>

		<paper id="0704">
			<definition id="0">
				<sentence>i I I I II This breakdown is motivated as follows determine the most important , central , topics For generahty we assume that a text can have many ( sub ) -toplcs , and that the topic extraction process can be parametertzed to include more or fewer of them to produce longer or shorter summaries together frequently mentmned portions of the input text does not m itself make an abstract What are the central , most important , concepts m the following story9 John and Bdl wanted money They bought ski-masks and guns and stole an old car from a netghbor Wearing their skimasks and wavmg their guns , the two entered the bank , and within minutes left the bank with several bags of $ 100 bdls They drove away happy , throwing away the ski-masks and guns m a sidewalk trash can They were never caught The popular method of sunple word counting would indicate that the story is about sk|-masks and guns , both of which are mentmned three times , more than any other word Clearly , however , the story is about a robbery , and any summary of It must menUon th|s fact Some process of interpreting the mdlwdual words as part of some encompassing concept is requued One such process , word clustenng , ~s an essentml technique for topic =dent=ficaUon m IR This techmque would match the words `` gun '' , `` mask '' , `` money '' , `` caught '' , `` stole '' , etc , against the set of words that form the so-called signature for the word `` robbery '' Other , more soph|sttcated forms of word clustering and fusion are possible , mcludmg script matchmg , deductive reference , and concept clustenng output is a verbatim quotaUon of some portion ( s ) of the input , or ~t must be generated anew In the former case , no generator is needed , but the output is not lflcely to be htgh-quahty text ( although this might be sufficient for the apphcatlon ) For each of the three steps of the above 'equation ' , SUMMARIST uses a mixture of symbolic world knowledge ( from WordNvt and slmdar resources ) and statistical or IR-based techniques Each stage employs several different , complementary , methods ( SUMMARIST will eventually contain several modules m each stage ) To date , we have developed some methods for each stage of processing , and are busy developing additional methods and lmkmg them rote a single system In the next sections we describe one method from each stage The overall architecture is shown m Figure 1 Figure 1 Architecture of SUMMARIST 19 I s e , the title ( TI ) is the most hkely to bear topics , I 2,1 Tonic Identification followed by the first sentence of paragraph 2 , the ~• first sentence of paragraph 3 , etc In contrast , for II Several techmques for topic identification have the Wall Street Journal the OPP is B been reported in the hterature , including methods r-r1 P1S1 P1S2 1 based on Posmon \ [ Luhn 58 , Edmundson 69\ ] , Cue L- , , .</sentence>
				<definiendum id="0">SUMMARIST</definiendum>
				<definiens id="0">a verbatim quotaUon of some portion ( s ) of the input</definiens>
				<definiens id="1">uses a mixture of symbolic world knowledge ( from WordNvt and slmdar resources ) and statistical or IR-based techniques Each stage employs several different , complementary , methods</definiens>
			</definition>
</paper>

		<paper id="0903">
			<definition id="0">
				<sentence>In this paper , we focus on the lessons learned during the successive development of three text generation systems at Bellcore : PLANDoc ( McKeown et al. , 1994 ) summarizes execution traces of an expert system for telephone network capacity expansion analysis ; FLOwDoc ( Passonneau et al. , 1996 ) provides summaries of the most important events in flow diagrams constructed during business reengineering ; and ZEDDoc ( Passonnean et al. , 1997 ) produces summaries of activity for a user-specified set of advertisements within a user-specified time period from logs of WWW page hits .</sentence>
				<definiendum id="0">FLOwDoc</definiendum>
				<definiendum id="1">ZEDDoc</definiendum>
				<definiens id="0">summarizes execution traces of an expert system for telephone network capacity expansion analysis</definiens>
			</definition>
			<definition id="1">
				<sentence>PLANDoc produces textual summaries of the scenarios explored by engineers .</sentence>
				<definiendum id="0">PLANDoc</definiendum>
				<definiens id="0">produces textual summaries of the scenarios explored by engineers</definiens>
			</definition>
			<definition id="2">
				<sentence>A pipeline architecture is one that separates the functions involved in text generation , such as content planning , discourse organization , lexicalization , and syntactic realization , into distinct modules that operate in sequence .</sentence>
				<definiendum id="0">pipeline architecture</definiendum>
				<definiens id="0">one that separates the functions involved in text generation , such as content planning , discourse organization , lexicalization , and syntactic realization , into distinct modules that operate in sequence</definiens>
			</definition>
			<definition id="3">
				<sentence>In PLANDoc , FLowDoc , and ZEDDoc , we utilize the following main modules , in the order listed below : • Message Generator : The message generator transcribes the raw data from LEIS-PLAN execution traces , SHowBIz , or ZED transaction logs into instances of message classes .</sentence>
				<definiendum id="0">message generator</definiendum>
				<definiens id="0">transcribes the raw data from LEIS-PLAN execution traces , SHowBIz , or ZED transaction logs into instances of message classes</definiens>
			</definition>
			<definition id="4">
				<sentence>Message classes are domainspecific ( e.g. , there are 30 of them in PLANDoc , 13 in FLowDoc , and 6 in ZEDDoc ) , but they all share the same representation as the basic content unit .</sentence>
				<definiendum id="0">Message classes</definiendum>
			</definition>
			<definition id="5">
				<sentence>Lexicalizer : The lexicalizer maps message attributes into thematic/case roles , and chooses appropriate content ( open-class ) words for tile values of these attributes .</sentence>
				<definiendum id="0">Lexicalizer</definiendum>
			</definition>
			<definition id="6">
				<sentence>Surface Generator : This module maps thematic roles into syntactic roles and builds syntactic constituents , chooses function ( closedclass ) words , ensures grammatical agreement , and linearizes to produce the final surface sentence .</sentence>
				<definiendum id="0">Surface Generator</definiendum>
				<definiens id="0">This module maps thematic roles into syntactic roles and builds syntactic constituents , chooses function ( closedclass ) words , ensures grammatical agreement , and linearizes to produce the final surface sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>Even so , their ontological generalization technique , which produces semantically concise descriptions from frequency data , is domain-independent .</sentence>
				<definiendum id="0">ontological generalization technique</definiendum>
				<definiens id="0">produces semantically concise descriptions from frequency data , is domain-independent</definiens>
			</definition>
			<definition id="8">
				<sentence>• A heterogeneity penalty , for descriptions that are locally optimal but significantly lower in the ontology ( more specific ) than the global specificity level .</sentence>
				<definiendum id="0">heterogeneity penalty</definiendum>
				<definiens id="0">descriptions that are locally optimal but significantly lower in the ontology ( more specific ) than the global specificity level</definiens>
			</definition>
			<definition id="9">
				<sentence>Indeed , we believe that our ontological generalization algorithm ( i.e. , message aggregation guided by quantitative formulas over plug-and-play ontologies ) is generally domain-independent .</sentence>
				<definiendum id="0">ontological generalization algorithm</definiendum>
				<definiens id="0">message aggregation guided by quantitative formulas over plug-and-play ontologies</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>Language learners create discourse domains as contexts for interlanguage development .</sentence>
				<definiendum id="0">Language learners</definiendum>
				<definiens id="0">create discourse domains as contexts for interlanguage development</definiens>
			</definition>
			<definition id="1">
				<sentence>LEVEL ) ; structure interlanguage_structure_context_indep ; subtype-of : interlanguage_structure , structure interlanguage_structure_context_dep ; subtype-of : interlanguage_structure , structure interlanguage_structure ; subtypes : interlanguage_strueture_context _indep , interlanguage_structure_context _dep ; parts : phenomena : set ( instance ( linguistic_phenomenon ) ) ; conditions : set ( instance ( interlanguage_condition ) ) ; properties : description : string ; eontextualization : boolean ; deviation : boolean ; stabilization : function ( stabilization of the rules associated to each phenomenon ) ; axioms : If contextualization= False then conditions= &lt; &gt; .</sentence>
				<definiendum id="0">eontextualization</definiendum>
				<definiens id="0">set ( instance ( interlanguage_condition ) ) ; properties : description : string ;</definiens>
			</definition>
			<definition id="2">
				<sentence>concept condition ; subtypes : linguistic_condition , non_linguistic_condition ; properties : description : string ; concept linguistic_condition ; subtype-of : condition ; properties : word_level : llst ( part_of_speech , declension_case ... ) sentence_level : list ( use_of_subordinates ... ) concept non_linguistic_condition ; subtype-of : condition ; subtypes : textual_condition , thematic_condition ; concept textual_condition subtype-of : non_linguistic_condition ; properties : text_conditions : list ( summary , formalJetter , translation ... ) ; structure_conditions : list ( long_sentence_based , long_word_based , apl_place_lem , apl_place_mor ... ) ; concept thematic_condition subtype-of : non_linguistic_condition ; properties : type : ( general , technical ) ; Linguistic conditions are studied by means of a corpus .</sentence>
				<definiendum id="0">textual_condition</definiendum>
				<definiens id="0">general , technical ) ; Linguistic conditions are studied by means of a corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>These tools are : the Lexical Database for Basque ( EDBL ) ( Agirre et al. , 1994 ) , the morphological analyser based on the Two-Level Morphology ( Agirre et al. , 1992 ) , the lemmatiser ( Aldezabal et al. , 1994 ) and some parts of the Constraint Grammar for Basque ( Alegria et al. , 1996 ) ( Karlsson et hi. , 1995 ) .</sentence>
				<definiendum id="0">Two-Level Morphology</definiendum>
				<definiens id="0">the Lexical Database for Basque ( EDBL ) ( Agirre et al. , 1994 ) , the morphological analyser based on the</definiens>
			</definition>
			<definition id="4">
				<sentence>We identify this context by adding to the adapted morphological analyser ( Learner_Analyser ) some characteristics such as the place ( lemma/morpheme ) where the rule is applied , the length of the word and the type of the last letter ( vowel/consonant ) of the root ( Postprocess ) .</sentence>
				<definiendum id="0">Learner_Analyser</definiendum>
				<definiens id="0">the length of the word and the type of the last letter ( vowel/consonant ) of the root ( Postprocess )</definiens>
			</definition>
			<definition id="5">
				<sentence>The Learning Process Subsystem guides users in their learning process giving hints according to their language level .</sentence>
				<definiendum id="0">Learning Process Subsystem</definiendum>
				<definiens id="0">guides users in their learning process giving hints according to their language level</definiens>
			</definition>
</paper>

		<paper id="0811">
			<definition id="0">
				<sentence>The training corpus consists of 75,000 tokens and covers about 72 % of all possible ambiguity classes .</sentence>
				<definiendum id="0">training corpus</definiendum>
				<definiens id="0">consists of 75,000 tokens and covers about 72 % of all possible ambiguity classes</definiens>
			</definition>
			<definition id="1">
				<sentence>LocoLex is a tool that has been developed at RXRC and which looks up a word in a bilingual dictionary taking the syntactic context into account .</sentence>
				<definiendum id="0">LocoLex</definiendum>
				<definiens id="0">a tool that has been developed at RXRC and which looks up a word in a bilingual dictionary taking the syntactic context into account</definiens>
			</definition>
</paper>

		<paper id="0104">
			<definition id="0">
				<sentence>A constituent boundary parse B is therefore given by B = ( bl , b2 ... , bn ) , where b i is the boundary tag of the//th word and n is the number of and syntactic tagsets can be found in \ [ ZQd96\ ] : \ [ POS tags\ ] : r-pronoun , n-noun , v-verb , m-numeral , q-classifier , w-punctuation .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of and syntactic tagsets can be found in \ [ ZQd96\ ] : \ [ POS tags\ ] : r-pronoun , n-noun , v-verb , m-numeral , q-classifier , w-punctuation</definiens>
			</definition>
			<definition id="1">
				<sentence>, ) and the close bracket ( bj = R ) under one of the following conditions : ( a ) 3 { SM ( i , k ) , i &lt; k &lt; j } and V bp =M , p¢ ( kj ) . ( b ) 3 { SM ( k~ ) , i &lt; k &lt; j } and V bp = M , pe ( i , k ) . ( c ) 3 { SM ( i , k ) ~-SM~ , j ) , .i.~.k &lt; p &lt; j } and V bq =M , qe ( k , p ) . ( 3 ) Matched consfitaent A matched constituent MC ( ij ) is a syn~.actic constituent constructed by the simple matching operation SM ( ij ) or the expanded matching operation EM ( ij ) . Therefore , a basic matching algorithm can be built as follows : Starting from the preprocessed sentence S= &lt; W , T , B &gt; , we first use the simple matching operation , then the expanded matching operation , so as to fred every possible matched constituent in the sentence .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">Matched consfitaent A matched constituent MC</definiendum>
				<definiens id="0">a syn~.actic constituent constructed by the simple matching operation SM ( ij ) or the expanded matching operation EM ( ij )</definiens>
			</definition>
</paper>

		<paper id="0506">
			<definition id="0">
				<sentence>The basic technique behind word prediction is to give the user a choice of the words ( or words and phrases ) which are calculated to be the most likely , based on the previous input .</sentence>
				<definiendum id="0">word prediction</definiendum>
				<definiens id="0">to give the user a choice of the words ( or words and phrases ) which are calculated to be the most likely , based on the previous input</definiens>
			</definition>
			<definition id="1">
				<sentence>Cogeneration involves a combination of grammatical , statistical , and template-based constraints .</sentence>
				<definiendum id="0">Cogeneration</definiendum>
				<definiens id="0">involves a combination of grammatical , statistical , and template-based constraints</definiens>
			</definition>
</paper>

		<paper id="1304">
			<definition id="0">
				<sentence>Furthermore , when the English analyzer contains an anaphora resolution process such as Lappin and Leass ( 1994 ) , even if the antecedents of zero pronouns in Japanese are anaphoric expressions such as pronouns and definite noun phrases , the anaphora resolution process determines the antecedents of anaphoric expressions in English and the overall system can determine intersentential and intrasentential resolution rules of Japanese zero pronouns by using extracted pairs of the antecedents of anaphoric expressions in English and their Japanese equivalents .</sentence>
				<definiendum id="0">anaphora resolution process</definiendum>
				<definiens id="0">determines the antecedents of anaphoric expressions in English and the overall system can determine intersentential and intrasentential resolution rules of Japanese zero pronouns by using extracted pairs of the antecedents of anaphoric expressions in English</definiens>
			</definition>
			<definition id="1">
				<sentence>In the implementation in ALT-J/E , the rules are extracted using the case type of the zero pronoun , the verbal semantic attributes ( VSA ; 107 categories ) of the verb which governs the zero pronoun ( Nakaiwa et al. , 1994 ) and categorized types of modal expression ( 134 categories ) in the unit sentence which contains the zero pronoun ( Kawai , 1987 ) and categorized types of conjunction ( 56 categories ) which are directly connected to the unit sentence .</sentence>
				<definiendum id="0">verbal semantic attributes</definiendum>
				<definiens id="0">56 categories ) which are directly connected to the unit sentence</definiens>
			</definition>
</paper>

		<paper id="1205">
			<definition id="0">
				<sentence>The corpus analysed consists of task-oriented dialogues between six pairs of Bari Italian speakers .</sentence>
				<definiendum id="0">corpus analysed</definiendum>
			</definition>
</paper>

		<paper id="0310">
			<definition id="0">
				<sentence>Training data consists of tuples ( nl , v , n2 , x ) , where v is a verb , nl and n2 are nouns , and x E { 1,0 } indicates whether nl is the subject of the verb .</sentence>
				<definiendum id="0">v</definiendum>
				<definiens id="0">tuples ( nl , v , n2 , x )</definiens>
			</definition>
			<definition id="1">
				<sentence>Test data consists of ambiguous tuples ( nx , v , n2 ) for which it can not be established which noun is the subject/object of the verb based on morpho-syntacticai information alone .</sentence>
				<definiendum id="0">Test data</definiendum>
				<definiens id="0">consists of ambiguous tuples ( nx , v , n2 ) for which it can not be established which noun is the subject/object of the verb based on morpho-syntacticai information alone</definiens>
			</definition>
			<definition id="2">
				<sentence>For each shallow structure s in the corpus containing one verbal and two nominative/accusative nominal constituents , let nl , v , n2 be such that v is the main verb in s , and nl and n2 are the heads of the nominative/accusative NCs in s such that nl precedes n2 in s. In the rules below , i , j e { 1,2 } , j ~ i , and g ( i ) = 1 if i = 1 , and 0 otherwise .</sentence>
				<definiendum id="0">n2</definiendum>
				<definiens id="0">the main verb in s , and nl and</definiens>
			</definition>
			<definition id="3">
				<sentence>The back-off estimate computes the probability of a word given the n 1 preceding words .</sentence>
				<definiendum id="0">back-off estimate</definiendum>
				<definiens id="0">computes the probability of a word given the n 1 preceding words</definiens>
			</definition>
			<definition id="4">
				<sentence>In the current context , instead of estimating the probability of a word given the n-1 preceding words , we estimate the probability that the first noun nz in a test triple ( nl , v , n2 ) is the subject of the verb v , i.e. , P ( S = ilNi = nl , V = v , N2 = n2 ) where S is an indicator random variable iS = I if the first noun in the triple is the subject of the verb , 0 otherwise ) .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">estimating the probability of a word given the n-1 preceding words</definiens>
				<definiens id="1">the subject of the verb v</definiens>
			</definition>
			<definition id="5">
				<sentence>We define the count fso ( nl , v , n2 ) : c ( nl , v , n2 , 1 ) + c ( n2 , v , nx , 0 ) of nl as the subject and n2 as the object of v. Further , we define the count fs ( nl , v ) = ~n2e£fso ( nl , v , n2 ) of nl as the subject of v with any object , and analogously , the count fo ( nx , v ) of nl as the object of v with any subject .</sentence>
				<definiendum id="0">count fs</definiendum>
				<definiens id="0">c ( nl , v , n2 , 1 ) + c ( n2 , v , nx , 0 ) of nl as the subject</definiens>
				<definiens id="1">the subject of v with any object</definiens>
			</definition>
			<definition id="6">
				<sentence>In ( Collins and Brooks , 1995 ) the back-off model is used to decide PP attachment given a tuple ( v , nl , p , n2 ) , where v is a verb , nl and n2 are nouns , and p a preposition such that the PP headed by p may be attached either to the verb phrase headed by v or to the NP headed by nx , and n : is the head of the NP governed by p. The model presented in section 3.2 is similar to that in ( Collins and Brooks , 1995 ) , however , unlike ( Collins and Brooks , 1995 ) , who use examples from a treebank to train their model , the procedure described in this paper uses training data automatically obtained from sample text .</sentence>
				<definiendum id="0">v</definiendum>
				<definiendum id="1">n :</definiendum>
				<definiens id="0">nouns , and p a preposition such that the PP headed by p may be attached either to the verb phrase headed by v or to the NP headed by nx</definiens>
			</definition>
</paper>

		<paper id="0306">
			<definition id="0">
				<sentence>, w ( fn , c ) ) ( wl , w2 , ... Wn ) , where n is the total number of features in the domain and w ( f , c ) is the weight of the feature f for this category .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">c )</definiendum>
				<definiens id="0">the total number of features in the domain</definiens>
				<definiens id="1">the weight of the feature f for this category</definiens>
			</definition>
			<definition id="1">
				<sentence>Each pair consists of 2000 training documents and 1000 test documents , and was used to train and test the classifier on a sample of 10 topical categories .</sentence>
				<definiendum id="0">pair</definiendum>
				<definiens id="0">consists of 2000 training documents and 1000 test documents , and was used to train and test the classifier on a sample of 10 topical categories</definiens>
			</definition>
			<definition id="2">
				<sentence>Specifically , we measured the effectiveness of the classification by keeping track of the following four numbers : • Pl = number of correctly classified class members • P2 = number of mis-classified class members • nl = number of correctly classified non-class members • n2 = number of mis-classified ion-class members In those terms , the recall measure is defines as Pl/Pl+P2 , and the precision is defined as pl/pl÷n2 .</sentence>
				<definiendum id="0">recall measure</definiendum>
				<definiens id="0">the effectiveness of the classification by keeping track of the following four numbers : • Pl = number of correctly classified class members • P2 = number of mis-classified class members • nl = number of correctly classified non-class members</definiens>
			</definition>
			<definition id="3">
				<sentence>For the remainder of this section we denote a training document with rn active features 57 by d = ( sil , si~ , ... si , , ) , where sij stands for the strength of the ij feature .</sentence>
				<definiendum id="0">sij</definiendum>
				<definiens id="0">the strength of the ij feature</definiens>
			</definition>
			<definition id="4">
				<sentence>Positive Winnow ( Littlestone , 1988 ) : The algorithm keeps an n-dimensional weight vector w = ( wl , w2 , ... Wn ) , wi being the weight of the ith feature , which it updates whenever a mistake is made .</sentence>
				<definiendum id="0">Positive Winnow</definiendum>
				<definiens id="0">an n-dimensional weight vector w = ( wl , w2 , ... Wn ) , wi being the weight of the ith feature</definiens>
			</definition>
			<definition id="5">
				<sentence>For a given instance ( Sil , Sia ... , 8ira ) the algorithm predicts 1 iff m ~ Wijaij ~ O , j=l where wit is the weight corresponding to the active feature indexed by ij .</sentence>
				<definiendum id="0">wit</definiendum>
				<definiens id="0">the weight corresponding to the active feature indexed by ij</definiens>
			</definition>
			<definition id="6">
				<sentence>There are other versions of the Winnow algorithm that allow the use of negative features : ( 1 ) Littlestone , when introducing the Balanced version , introduced also a simpler version a version of PositiveWinnow with a duplication of the number of features .</sentence>
				<definiendum id="0">Winnow algorithm</definiendum>
				<definiens id="0">when introducing the Balanced version , introduced also a simpler version a version of PositiveWinnow with a duplication of the number of features</definiens>
			</definition>
			<definition id="7">
				<sentence>The reason is that if Fc ( d ) is the score produced by the classifier Fc when evaluated on the document d then , under some assumptions on the dependencies among the features , the probability that the document d is relevant to the category c is given by Prob ( d E c ) _ l+e=~ ; r~7 This function , known as the sigmoid function , `` flattens '' the decision region in a way that only scores that are far apart from the threshold value indicate that the decision is made with significant probability .</sentence>
				<definiendum id="0">Prob</definiendum>
				<definiens id="0">the score produced by the classifier Fc when evaluated on the document d then</definiens>
			</definition>
			<definition id="8">
				<sentence>( 2 ) s ( f , d ) = n ( f , d ) , where n ( f , d ) is the number of occurrences of f in d ; and ( 3 ) s ( f , d ) = ~ d ) ( as in ( Wiener , Pedersen , and Weigend , 1995 ) ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of occurrences of f in d</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>This approach to the storing of Differential Grammars helps to keep the requirements for a given confused word set small , and thus contributes to our goal ( 4 ) of minimizing the size of the grammar , without significantly affecting reliability ( precision and detection rate ) .</sentence>
				<definiendum id="0">Differential Grammars</definiendum>
				<definiens id="0">helps to keep the requirements for a given confused word set small</definiens>
			</definition>
			<definition id="1">
				<sentence>Maximum diameter is another parameter of the training stage , and experiments on optimal size and the role of diameter in relation to syntactic and semantic words were undertaken early on in setting 10 as the size beyond which environments were unlikely to reach significance .</sentence>
				<definiendum id="0">Maximum diameter</definiendum>
				<definiens id="0">another parameter of the training stage , and experiments on optimal size and the role of diameter in relation to syntactic and semantic words were undertaken early on in setting 10 as the size beyond which environments were unlikely to reach significance</definiens>
			</definition>
</paper>

		<paper id="0812">
			<definition id="0">
				<sentence>The information content ( or entropy ) of a concept c -- which in WordNet corresponds to a set of such as fire_v_4 , dismiss_v_4 , terminate_v_4 , sack v 2 -- is formally defined as -log p ( c ) ( Abramson , 1963:6-13 ) .</sentence>
				<definiendum id="0">information content</definiendum>
				<definiens id="0">or entropy ) of a concept c -- which in WordNet corresponds to a set of such as fire_v_4 , dismiss_v_4 , terminate_v_4 , sack v</definiens>
			</definition>
			<definition id="1">
				<sentence>Find all verb-object cooccurrence restrictions containing the verbfire , which as shown in the previous section are &lt; 102_VO , 102_OV &gt; &lt; 104 VO , 104_OV • • Retrieve all members of the direct object collocate class , e.g. 102OV - &gt; clerk_n_ 1/2 , employee_n_1 104OV - &gt; gun_n_l , rocket n_l Cluster the statistically inconspicuous collocate with all members of the direct object collocate class .</sentence>
				<definiendum id="0">Retrieve</definiendum>
				<definiens id="0">all members of the direct object collocate class</definiens>
			</definition>
</paper>

		<paper id="1106">
			<definition id="0">
				<sentence>Under the term paradigm I mean the set of endings that belong to one lemma ( e.g. noun endings for all seven cases in both numbers ) and possible derivations with their corresponding endings ( e.g. possessive adjectives derived from nouns in all possible forms ) .</sentence>
				<definiendum id="0">corresponding endings</definiendum>
				<definiens id="0">possessive adjectives derived from nouns in all possible forms</definiens>
			</definition>
			<definition id="1">
				<sentence>Palatalization occurs mainly in declension and partly also in conjugation .</sentence>
				<definiendum id="0">Palatalization</definiendum>
				<definiens id="0">occurs mainly in declension and partly also in conjugation</definiens>
			</definition>
			<definition id="2">
				<sentence>The label End denotes any character that can occur in an ending and that is removed from the base form .</sentence>
				<definiendum id="0">label End</definiendum>
				<definiens id="0">any character that can occur in an ending</definiens>
			</definition>
</paper>

		<paper id="0207">
			<definition id="0">
				<sentence>Yarowsky ( Yar93 ) compares the semantic entropy of homographs conditioned on different contexts .</sentence>
				<definiendum id="0">Yarowsky</definiendum>
				<definiens id="0">compares the semantic entropy of homographs conditioned on different contexts</definiens>
			</definition>
			<definition id="1">
				<sentence>Entropy is a functional of probability distribution functions ( pdf 's ) .</sentence>
				<definiendum id="0">Entropy</definiendum>
			</definition>
			<definition id="2">
				<sentence>Under this assumption , the contribution to the semantic entropy of s made by each null link is -- F -- ~ log F -- ~ '' If F ( NULLIs ) represents the number of times that s is linked to nothing , then the total contribution of all these null links to the semantic entropy of s is N ( s ) = -F ( NULLIs ) log F ( s ) = P ( NULL\ ] s ) IogF ( s ) ( 2 ) The semantic entropy E ( s ) of each word s accounts for both the null links and the non-null links of 8 . ''</sentence>
				<definiendum id="0">semantic entropy E</definiendum>
				<definiens id="0">the contribution to the semantic entropy of s made by each null link is -- F -- ~ log F -- ~ '' If F ( NULLIs ) represents the number of times that s is linked to nothing</definiens>
			</definition>
			<definition id="3">
				<sentence>( 3 ) To estimate the semantic entropy of English words , roughly thirteen million words were used from the record of proceedings of the Canadian parliament ( `` Hansards '' ) , which is available in English and in French .</sentence>
				<definiendum id="0">Canadian parliament</definiendum>
				<definiens id="0">estimate the semantic entropy of English words , roughly thirteen million words were used from the record of proceedings of the</definiens>
			</definition>
			<definition id="4">
				<sentence>Second , in order to measure semantic similarity over concepts , his method requires a concept taxonomy , such as the Princeton WordNet ( Milg0 ) , which is grounded in the lexical ontology of a particular language .</sentence>
				<definiendum id="0">Princeton WordNet</definiendum>
				<definiens id="0">is grounded in the lexical ontology of a particular language</definiens>
			</definition>
			<definition id="5">
				<sentence>The best counter-example to the correlation between semantic entropy and logfrequency is the period , which is the most frequent token in the English Hansards and has a semantic entropy of zero .</sentence>
				<definiendum id="0">logfrequency</definiendum>
				<definiens id="0">the most frequent token in the English Hansards and has a semantic entropy of zero</definiens>
			</definition>
			<definition id="6">
				<sentence>The semantic entropy of a word can be interpreted as its semantic ambiguity and is inversely proportional to the word 's informatio n content , semantic weight , and consistency in translation .</sentence>
				<definiendum id="0">semantic entropy of a word</definiendum>
				<definiens id="0">its semantic ambiguity and is inversely proportional to the word 's informatio n content , semantic weight , and consistency in translation</definiens>
			</definition>
</paper>

		<paper id="0302">
			<definition id="0">
				<sentence>The outside probability of a node N~k is the probability of that node given the surrounding terminals of the sentence , i.e. P ( S =~ tl ... tj-xXtk+l..</sentence>
				<definiendum id="0">outside probability of a node N~k</definiendum>
				<definiens id="0">the probability of that node given the surrounding terminals of the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Remember that B ( N~i. ) is the probability that Nfk is in the correct parse ( given , as always , the model and the string ) .</sentence>
				<definiendum id="0">B ( N~i. )</definiendum>
				<definiendum id="1">Nfk</definiendum>
				<definiens id="0">the probability that</definiens>
			</definition>
			<definition id="2">
				<sentence>The only technique that Caraballo and Charniak ( 1996 ) give that took into account the scores of other nodes in the priority function , the `` prefix model , '' required O ( n 5 ) time to compute , compared to our O ( n 3 ) system .</sentence>
				<definiendum id="0">prefix model</definiendum>
			</definition>
			<definition id="3">
				<sentence>Hwa ( personal communication ) using a model similar to PCFGs , Stochastic Lexicalized Tree Insertion Grammars , also was not able to obtain a speedup using this technique .</sentence>
				<definiendum id="0">Hwa</definiendum>
				<definiens id="0">personal communication ) using a model similar to PCFGs , Stochastic Lexicalized Tree Insertion Grammars</definiens>
			</definition>
			<definition id="4">
				<sentence>The inner loop of the CKY algorithm , which determines for every pair of cells what nodes must be 18 Original S X Y A B ... G H Z A B Binary Branching S X y A X~ , C , D , E , F Z A B B XC , D , E , F , G I C XD , E , F , G , H D X ~ E , F , G , H E X~ , a , H F X~ , H G H Figure 8 : Converting to Binary Branching added to the parent , can be written in several different ways .</sentence>
				<definiendum id="0">H F X~ , H G</definiendum>
				<definiens id="0">determines for every pair of cells what nodes must be 18 Original S X Y A B ... G H Z A B Binary Branching S X y A X~ , C , D , E , F Z A B B XC , D , E , F , G I C XD , E , F</definiens>
			</definition>
			<definition id="5">
				<sentence>SBTG is a contextfree-like formalism designed for translation from one language to another ; it uses a four dimensional chart to index spans in both the source and target language simultaneously .</sentence>
				<definiendum id="0">SBTG</definiendum>
				<definiens id="0">a contextfree-like formalism designed for translation from one language to another</definiens>
			</definition>
			<definition id="6">
				<sentence>The traditional way to speed up STAG parsing is to use the context-free subset of an STAG to form a Stochastic Tree Insertion Grammar ( STIG ) ( Schabes and Waters , 1994 ) , an O ( n 3 ) formalism , but this method has problems , because the STIG undergenerates since it is missing some elementary trees .</sentence>
				<definiendum id="0">O</definiendum>
				<definiens id="0">to use the context-free subset of an STAG to form a Stochastic Tree Insertion Grammar ( STIG )</definiens>
			</definition>
</paper>

		<paper id="0505">
			<definition id="0">
				<sentence>• The recursive behaviour is one of the reasons to create more than one table of probabilities which stores the probability of apparition of a suffi immediately after the previous one .</sentence>
				<definiendum id="0">recursive behaviour</definiendum>
			</definition>
			<definition id="1">
				<sentence>For instance , let us consider these rules : NP &lt; Noun PP PP &lt; Prep NP , where NP means Noun Phrase , PP , Prepositional Phrase , Noun is a noun and Prep , a preposition .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiendum id="1">Noun</definiendum>
				<definiens id="0">a noun</definiens>
			</definition>
</paper>

		<paper id="0108">
			<definition id="0">
				<sentence>Kenmore , being a supervised algorithm , relies on an annotated corpus of domainspecific classes .</sentence>
				<definiendum id="0">Kenmore</definiendum>
				<definiens id="0">being a supervised algorithm , relies on an annotated corpus of domainspecific classes</definiens>
			</definition>
			<definition id="1">
				<sentence>Our information source is the extensive semantic hierarchy WordNet ( Miller , 1990 ) which was designed to capture the semantics of general nuances and uses of the English language .</sentence>
				<definiendum id="0">information source</definiendum>
				<definiens id="0">the extensive semantic hierarchy WordNet ( Miller , 1990 ) which was designed to capture the semantics of general nuances and uses of the English language</definiens>
			</definition>
			<definition id="2">
				<sentence>Information Content Resnik ( 1995 ) proposed a word sense disambiguation algorithm which determ~ the senses of words in noun groupings .</sentence>
				<definiendum id="0">Information Content Resnik</definiendum>
				<definiens id="0">proposed a word sense disambiguation algorithm which determ~ the senses of words in noun groupings</definiens>
			</definition>
			<definition id="3">
				<sentence>Agirre and Rigau uses the conceptual density of the ancestors of the nouns in WordNet as their metric .</sentence>
				<definiendum id="0">Rigau</definiendum>
				<definiens id="0">uses the conceptual density of the ancestors of the nouns in WordNet as their metric</definiens>
			</definition>
			<definition id="4">
				<sentence>Link probability is defined as the difference between the probability of instance occurrences of the parent and child of the \ ] i.k~ Formally , Lin &amp; l'P ( e , b ) = p ( a ) p ( b ) , SWe clarified with the authoz~ certain parts of the algorithm which we find unclear .</sentence>
				<definiendum id="0">Link probability</definiendum>
			</definition>
			<definition id="5">
				<sentence>Descendant coverage of a l~nlc is defined as the difference in the percentage of descendants subsumed by the parent and that subsumed by the child : Des~ee ( a , b ) -- -~ ( a ) -d ( b ) , Total ~umber of de~cet~d~ , ~ i~ WordNe¢ `` b ~ ~ o~ ~he iinJ # .</sentence>
				<definiendum id="0">Descendant coverage of a l~nlc</definiendum>
				<definiens id="0">the difference in the percentage of descendants subsumed by the parent and that subsumed by the child : Des~ee ( a , b ) -- -~ ( a ) -d ( b )</definiens>
			</definition>
			<definition id="6">
				<sentence>Taxonomic Link ( IS-A ) All the metrics detailed above were designed to capture semantic similarity or closeness .</sentence>
				<definiendum id="0">Taxonomic Link</definiendum>
				<definiens id="0">the metrics detailed above were designed to capture semantic similarity or closeness</definiens>
			</definition>
</paper>

		<paper id="0411">
			<definition id="0">
				<sentence>We describe the methodology used to build the SLT system itself , particularly in the areas of customization ( Section 2 ) , robustness ( Section 3 ) , and multilinguality ( Section 4 ) .</sentence>
				<definiendum id="0">multilinguality</definiendum>
				<definiens id="0">the methodology used to build the SLT system itself</definiens>
			</definition>
</paper>

		<paper id="1404">
			<definition id="0">
				<sentence>Such is the magic of the World Wide Web .</sentence>
				<definiendum id="0">Such</definiendum>
			</definition>
</paper>

		<paper id="0610">
			<definition id="0">
				<sentence>The DYD system produces spoken monologues derived from information stored in a general-purpose database about W.A.Mozart 's instrumental compositions .</sentence>
				<definiendum id="0">DYD system produces</definiendum>
				<definiens id="0">spoken monologues derived from information stored in a general-purpose database about W.A.Mozart 's instrumental compositions</definiens>
			</definition>
			<definition id="1">
				<sentence>This record will be called the Discourse Model , which is also a part of the Context Model .</sentence>
				<definiendum id="0">Discourse Model</definiendum>
				<definiens id="0">also a part of the Context Model</definiens>
			</definition>
			<definition id="2">
				<sentence>For each paragraph of the monologue , the Topic State , which is another part of the Context Model , keeps track of the topic of the paragraph , which is defined as a set of attributes from the ( music ) database .</sentence>
				<definiendum id="0">Topic State</definiendum>
				<definiens id="0">another part of the Context Model , keeps track of the topic of the paragraph</definiens>
			</definition>
			<definition id="3">
				<sentence>Moreover , the Discourse Model , as we have seen , contains semantic information about the sentence .</sentence>
				<definiendum id="0">Discourse Model</definiendum>
				<definiens id="0">contains semantic information about the sentence</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>A partial-tree ( also subtree ) of a given tree t is a tree-structure which is the result of a subderivation of a derivation represented by t. A partialtree which has as its root the start non-terminal is called a sentential partial-tree .</sentence>
				<definiendum id="0">partial-tree</definiendum>
				<definiens id="0">the result of a subderivation of a derivation represented by t. A partialtree which has as its root the start non-terminal is called a sentential partial-tree</definiens>
			</definition>
			<definition id="1">
				<sentence>A Context-Free rule ( CF-rule ) R=A -4 A1 ... An is said to appear in a tree t if there is a node in t , labeled A , and that node has n children labeled with ( maintaining order from left to right ) A1 ... A , ~ .</sentence>
				<definiendum id="0">Context-Free rule</definiendum>
				<definiens id="0">a node in t , labeled A , and that node has n children labeled with ( maintaining order from left to right</definiens>
			</definition>
			<definition id="2">
				<sentence>The CFG ( VN , VT , S , 7~ ) is called the CFG underlying a given tree-bank iff ~ is the set { R I rule R appears in a tree in the tree-bank } ( and the start non-terminal S , non-terminal set VN , terminal set VT are exactly those of the tree-bank ) .</sentence>
				<definiendum id="0">CFG</definiendum>
				<definiens id="0">the set { R I rule R appears in a tree in the tree-bank } ( and the start non-terminal S , non-terminal set VN , terminal set VT are exactly those of the tree-bank )</definiens>
			</definition>
			<definition id="3">
				<sentence>EBL assumes a domain theory ( or background theory ) which provides explanations to and enables the definition of concepts .</sentence>
				<definiendum id="0">EBL</definiendum>
				<definiens id="0">assumes a domain theory ( or background theory ) which provides explanations to and enables the definition of concepts</definiens>
			</definition>
			<definition id="4">
				<sentence>Minton discusses a formula for computing the utility of knowledge during learning .</sentence>
				<definiendum id="0">Minton</definiendum>
				<definiens id="0">discusses a formula for computing the utility of knowledge during learning</definiens>
			</definition>
			<definition id="5">
				<sentence>Subsentential-form A subsentential-form ( SSF ) is a sequence of grammar-symbols which forms the frontier of a partial-tree .</sentence>
				<definiendum id="0">SSF</definiendum>
				<definiens id="0">a sequence of grammar-symbols which forms the frontier of a partial-tree</definiens>
			</definition>
			<definition id="6">
				<sentence>A measure of how much a single PA-SSF contributes to reducing a sentential-form is the Reduction Factor , and the `` expected utility '' of a PASSF is estimated as the Global Reduction Factor : Reduction Factor The Reduction Factor ( RF ) of a given SSFssf is RF ( ssf ) = n ( ssf ) 1 , where L ( ssf ) is the number of symbols which constitute ssf .</sentence>
				<definiendum id="0">L ( ssf )</definiendum>
				<definiens id="0">the number of symbols which constitute ssf</definiens>
			</definition>
			<definition id="7">
				<sentence>Global RF The global reduction factor of a given PA-SSF ssf with respect to the tree-bank is defined as GRF ( ssf ) = fc ( ssf ) x RF ( ssf ) , where fc ( ssf ) is the frequency of ssf as a constituent .</sentence>
				<definiendum id="0">ssf ) x RF</definiendum>
				<definiendum id="1">fc ( ssf )</definiendum>
				<definiens id="0">the frequency of ssf as a constituent</definiens>
			</definition>
			<definition id="8">
				<sentence>The algorithm learns PA-SSFs by an iterative procedure which `` eats '' up the tree-bank trees from their leaves upwards .</sentence>
				<definiendum id="0">PA-SSFs</definiendum>
			</definition>
			<definition id="9">
				<sentence>/* Frontier_Of ( N ) denotes the frontier ( i.e. an SSF ) of the partial-tree under N. /* Descendent ( Nch , Np ) denotes the predicate : the node addressed Nch is a /* descendent of the node addressed Np .</sentence>
				<definiendum id="0">Frontier_Of ( N )</definiendum>
				<definiendum id="1">Np )</definiendum>
				<definiendum id="2">Nch</definiendum>
				<definiens id="0">the frontier ( i.e. an SSF ) of the partial-tree under N. /* Descendent ( Nch ,</definiens>
				<definiens id="1">the predicate : the node addressed</definiens>
				<definiens id="2">a /* descendent of the node addressed Np</definiens>
			</definition>
			<definition id="10">
				<sentence>The parsing algorithm A Tree-Substitution Grammar ( TSG ) is a CFG with rules which are partial-trees called elementary-trees .</sentence>
				<definiendum id="0">Tree-Substitution Grammar</definiendum>
				<definiens id="0">a CFG with rules which are partial-trees called elementary-trees</definiens>
			</definition>
			<definition id="11">
				<sentence>A Finite State Transducer ( FST ) is learned at each iteration of the learning algorithm ; the FST 's language is the set of PA-SSFs learned at that iteration , and the output of the FST on recognition of a PA-SSF is the set of subtrees associated with that PA-SSF .</sentence>
				<definiendum id="0">Finite State Transducer ( FST</definiendum>
				<definiendum id="1">FST 's language</definiendum>
				<definiens id="0">the set of PA-SSFs learned at that iteration , and the output of the FST on recognition of a PA-SSF is the set of subtrees associated with that PA-SSF</definiens>
			</definition>
			<definition id="12">
				<sentence>DOP projects all partial-trees from a treebank and employs them as a stochastic grammar called a Stochastic Tree-Substitution Grammar ( STSG ) .</sentence>
				<definiendum id="0">DOP</definiendum>
			</definition>
			<definition id="13">
				<sentence>Firstly , the so called domain-theory consists of the annotation convention as well as the annotation intuitions used for the annotation of the tree-bank .</sentence>
				<definiendum id="0">so called domain-theory</definiendum>
				<definiens id="0">consists of the annotation convention as well as the annotation intuitions used for the annotation of the tree-bank</definiens>
			</definition>
			<definition id="14">
				<sentence>These partial-trees are obtained by using a simple operationality criterion , which states that any partial-tree obtained from a tree-bank tree is acceptable ( in the experiments mentioned in ( Bod , 1995 ) , Bod limits the depth of partial-trees , Charniak ( Charniak , 1996 ) limits the partial-trees to CFG rules , and in ( Sekine and Grishman , 1995 ) only a subset of the non-terminals are allowed to supply partial-trees ) .</sentence>
				<definiendum id="0">Bod</definiendum>
				<definiens id="0">limits the depth of partial-trees</definiens>
				<definiens id="1">a subset of the non-terminals are allowed to supply partial-trees )</definiens>
			</definition>
			<definition id="15">
				<sentence>Precision denotes the ratio ( Right parse/Any parse ) , which expresses the precision of the parser as a parse-space generator .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio ( Right parse/Any parse ) , which expresses the precision of the parser as a parse-space generator</definiens>
			</definition>
			<definition id="16">
				<sentence>tor sentence length &gt; 2 \ [ _ &gt; 7 \ [ _ &gt; 10 number of nodes in trees 141960 ( 938 ) 117134 ( 1627 ) 818.5 ( 10.26 ) 117750 ( 1551 ) 812 ( lO.4O ) Table 2 : Means and STDs of ten experiments ( OVIS ) , ParPar denotes Partial-Parser employs prior to disambiguation ( Sima'an , 1996a ) , and for specifying the cut-nodes for DOP .</sentence>
				<definiendum id="0">ParPar</definiendum>
				<definiens id="0">Partial-Parser employs prior to disambiguation ( Sima'an , 1996a ) , and for specifying the cut-nodes for DOP</definiens>
			</definition>
			<definition id="17">
				<sentence>The measures which the table lists are coverage and accuracy , where coverage is the percentage of sentences that received a parse , and accuracy is the percentage of parsable sentences that received exactly the same parse as the test-set counterpart .</sentence>
				<definiendum id="0">coverage</definiendum>
				<definiendum id="1">accuracy</definiendum>
				<definiens id="0">the percentage of sentences that received a parse , and</definiens>
				<definiens id="1">the percentage of parsable sentences that received exactly the same parse as the test-set counterpart</definiens>
			</definition>
			<definition id="18">
				<sentence>is set beforehand , DOP misses around the 600 cases ( of 3372 ) while the EBL misses less than 100 cases .</sentence>
				<definiendum id="0">DOP misses</definiendum>
			</definition>
</paper>

		<paper id="1506">
			<definition id="0">
				<sentence>ConTroll is a grammar development system which supports the implementation of current constraint-based theories .</sentence>
				<definiendum id="0">ConTroll</definiendum>
				<definiens id="0">a grammar development system which supports the implementation of current constraint-based theories</definiens>
			</definition>
			<definition id="1">
				<sentence>For the rest of the paper , we will focus on those aspects of ConTroll , which directly address large scale grammar development : • A graphical user interface : data structure visualization debugging and tracing tool • Grammar organization issues : supporting a modular file organization automatic macro detection automatic macro generation • Compilation techniques : special compilation of lexica with lexical rules for a compact and efficient lexicon incremental compilation and global grammar optimization arbitrary multiple indexing of constraints 39 ConTroll is the only system combining all of these features in one architecture .</sentence>
				<definiendum id="0">ConTroll</definiendum>
				<definiendum id="1">ConTroll</definiendum>
				<definiens id="0">the only system combining all of these features in one architecture</definiens>
			</definition>
			<definition id="2">
				<sentence>The GUI comes with a clean backend interface and has already been used as frontend for other natural language applications , e.g. , in the VER .</sentence>
				<definiendum id="0">GUI</definiendum>
				<definiens id="0">comes with a clean backend interface and has already been used as frontend for other natural language applications , e.g. , in the VER</definiens>
			</definition>
			<definition id="3">
				<sentence>~r~c } ~ '' &lt; ndmelle~ , fd'rracD ) \ [ \ [ \ [ °'*\ [ o ' head \ [ \ ] \ [ r , *siwpleo.~ 'd A\ ] \ [ h* , ei~q~lc.~ 'd U\ ] head , ~.~ ~ `` head ~\ ] r~.~¢ I I I l ~'e~d \ [ \ ] ~ '' : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :~ : : : : : : : : : :~.~. : ili . ! : ) : : `` ? : : ! : : : ) ) ) ) ) ~ ) : ~ : : : ~ : ~ : ~ : ~ : ! : : ) : : : ? : Figure 2 : Screen shot of a window showing user configured tree output To organize grammars in a modular fashion , it is important to be able to distribute the grammar into several files to permit modification , loading , and testing of the different parts of a grammar separately. Also , only a modular file organization allows for distributed grammar development since such an organization makes it possible to coordinate the work on the individual files with software engineering tools such as a revision control system. ConTroll supports the use of a grammar configuration file which can contain basic directory and file specifications , as well as a more sophisticated system allowing the linguist to specify the dependencies between signature , theory and lexicon files. To find out which signature , theory , and lexicon is supposed to be used and in which directories the files are supposed to be found , the system looks for a grammar configuration file. If such a file is not found , default names for the signature and the theory file are used. If there is a configuration file , it can specify the theory , signature , and lexicon files to be used , as well as the relevant directories. The downside of this explicit mode of specification is that each time one wants to load a part of the grammar , e.g. for testing , one needs to realize which files needed are needed to test this part of the grammar in order to be able to list them explicitly. While this might seem like a trivial task , our experience has shown that in a distributed grammar development environment such a complete specification requires significant insight into the entire grammar. ConTroll therefore provides a more intelligent way of specifying the files needed for a module by allowing statements which make the dependencies between the different theory , signature , and lexicon files explicit. These specifications were modeled after the makefiles used in some programming environments. Once the dependencies are provided in the configuration file , selecting the parts of the grammar to be loaded can be done without having to being aware of the whole grammar organization by specifying one file for each module of the grammar needs to be included. The signature , theory , and lexicon files which are needed for the selected files are then automatically loaded according to the dependency specifications. When writing a typed feature structure based grammar one usually wants to abbreviate often used feature paths or complex specifications. In ConTroll 41 this can be done using the definite clause mechanism. However , from a processing point of view , it is inefficient to treat macros in the same way as ordinary relations. We thus implement a fast , purely syntactic preprocessing step that finds the relations that can be treated as macros , i.e. , unfolded at compile time. These macro relations are then compiled into an internal representation during a second preprocessing step. When the rest of the grammar is parsed , any macro goal will simply be replaced by its internal representation. After the actual compilation , ConTroll closes the grammar under deterministic computation. This step must be carefully distinguished from the macro detection described above. A goal is deterministic in case it matches at most one defining clause , but a relation is a macro by virtue of its definition , irrespective of the instantiation of the actual calling goals. Of course , the macro detection step can be eliminated , since the deterministic closure will also unfold all macros. However , for our reference grammar , adding the macro detection step reduced compile times by a factor of 20. Thus , for large grammars , compilation without macros is simply not practical. Obviously , making automatic macro detection a property of the compiler relieves the grammar developer from the burden of distinguishing between macros and relations , thereby eliminating a potential source of errors. Since HPSG theories usually formulate constraints about different kind of objects , the grammar writer usually has to write a large number of macros to access the same attribute , or to make the same specification , namely one for each type of object which this macro is to apply to. For example , when formulating immediate dominance schemata , one wants to access the VFORM specification of a sign. When specifying the valence information one wants to access the VFORM specification of a synsem object. And when specifying something about non-local dependencies , one may want to refer to VFOI~M specifications of local objects. ConTroll provides a mechanism which automatically derives definitions of relations describing one type of object on the basis of relations describing another type of object as long as the linguist tells the system which path of attributes leads from the first type of object to the second. Say we want to have abbreviations to access the VFOR.M of a sign , a synsem , local , cat , and a head object. Then we need to define a relation accessing the most basic object having a VFORM , namely head : vform_h ( X-vforra ) : == vforra : X. Second , ( once per grammar ) access_suffix and access_rule declarations for the grammar need to be provided. The former define a naming convention for the generated relations by pairing types with relation name suffixes. The latter define the rules to be used by the mechanism by specifying the relevant paths from one type of object to another. For our example the grammar should include the recipes shown in Fig. 4. This results in the macros shown in Fig. 5 to be generated. access_suf f ix ( head , `` _h '' ) . access_suf f ix ( cat , `` _c '' ) . access_suf f ix ( loc , `` _l '' ) . accessnsuf f ix ( synsem , `` .s '' ) . access.suf f ix ( sign , `` someSuff ix '' ) . acce ss_rule ( cat , head , head ) . access.rule ( loc , cat , cat ) . access_rule ( synsem , loc , loc ) . access_rule ( s ign , synsem , synsem ) . Figure 4 : Macro generation specification vform_h ( X ) : -vform : X. vform_c ( X ) : -head : vform_h ( X ) . vf orm_l ( X ) : -cat : vf orm_c ( X ) . vf orm_y ( X ) : -loc : vf orm_l ( X ) . vform_s ( X ) : -synsem : vform_y ( X ) . Figure 5 : Example result of macro generation For a large grammar , which usually specifies hundreds of macros , this mechanism can save a significant amount of work. It also provides a systematic rather than eclectic way of specifying abbreviations in a grammar , which is vital if several people are involved in grammar development. scale grammars efficient lexicon encoding Lexical rules receive a special treatment in ConTroll. The lexical rule compiler implements the covariation approach to lexical rules ( Meurers and Minnen , 1995 ) . It translates a set of HPSG lexical rules and their interaction into definite relations used to constrain lexical entries. In HPSG , lexical rules are intended to `` preserve all properties of the input not mentioned in the rule. '' ( Pollard and Sag , 1987 , p. 314 ) . The lexical rule compiler of the ConTroll system to our knowledge is the only system which provides a computational mechanism for such lexical rules by automatically computing the necessary 42 B frame predicates accounting for the intended preservation of properties. Since the lexical rules do not need to be expanded at compile time , ConTroll is able to handle the infinite lexica which have been proposed in a number of HPSG theories. Constraint propagation is used as program transformation techniques on the definite clause encoding resulting from the lexical rule compiler ( Meurers and Minnen , 1996 ) . The relation between parsing times with the expanded ( EXP ) , the covariation ( cov ) and the constraint propagated covariation ( OPT ) lexicon for a German HPSG grammar ( Hinrichs , Meurers , and Nakazawa , 1994 ) can be represented as OPT : EXP : COV = 0.75 : 1 : 18. Thus , the lexical rule compiler results not only in a compact representation but also in more efficient processing of a lexicon including lexical rules. grammar optimization To keep development cycles short , a fast compiler is essential. Particularly when developing a large grammar , small changes should not necessitate the recompilation of the whole grammar an incremental compiler is called for. This is relatively easy for systems where the compilation of individual pieces of code does not depend on the rest of the program. In ConTroll , this task is complicated for two reasons. eral different universal constraints apply to objects of the same type , the compiler will merge them together. Changing a single high-level constraint may thus necessitate the recompilation of large parts of the grammar. grammar is closed under deterministic computation at compile time , a change in some relation entails recompilation of all clauses that have inlined a call to that relation , which in turn may lead to changes in yet other relations , and so on. Nothing less than the maintenance of a complete call graph for the whole grammar would enable the compiler to know which parts of the grammar need to be recompiled. We decided on a compromise for incremental compilation and made our compiler aware of the first sort of dependency , but not the second. This means that incremental recompilation is always done on the basis of the grammar before deterministic closure. Therefore , after incremental recompilation deterministic closure needs to be done for the whole grammar. grammar constraints ConTroll allows the specification of indexing information for predicates individually. This is comparable to the indexing of terms in relational databases , e.g. , the SICStus Prolog external database ( Nilsson , 1995 ) . Figure 6 shows the definition of a two-place r ( t ) ** &gt; t. r ( a ) : = b. index ( r , arg0 : t ) .</sentence>
				<definiendum id="0">ConTroll</definiendum>
				<definiendum id="1">ConTroll</definiendum>
				<definiens id="0">a more sophisticated system allowing the linguist to specify the dependencies between signature , theory and lexicon files. To find out which signature , theory , and lexicon is supposed to be used and in which directories the files are supposed to be found</definiens>
				<definiens id="1">make the dependencies between the different theory , signature , and lexicon files explicit. These specifications were modeled after the makefiles used in some programming environments. Once the dependencies</definiens>
				<definiens id="2">a relation accessing the most basic object having a VFORM</definiens>
				<definiens id="3">a set of HPSG lexical rules and their interaction into definite relations used to constrain lexical entries. In HPSG , lexical rules are intended to `` preserve all properties of the input not mentioned in the rule. ''</definiens>
				<definiens id="4">the only system which provides a computational mechanism for such lexical rules by automatically computing the necessary 42 B frame predicates accounting for the intended preservation of properties. Since the lexical rules do not need to be expanded at compile time</definiens>
				<definiens id="5">comparable to the indexing of terms in relational databases , e.g. , the SICStus Prolog external database</definiens>
			</definition>
</paper>

		<paper id="0319">
			<definition id="0">
				<sentence>Natural language information extraction ( IE ) systems take texts containing natural language as input and produce database templates populated with information that is relevant to a particular application .</sentence>
				<definiendum id="0">Natural language information extraction</definiendum>
				<definiens id="0">systems take texts containing natural language as input and produce database templates populated with information that is relevant to a particular application</definiens>
			</definition>
			<definition id="1">
				<sentence>The first component consists of a series of phases that recognize domain-relevant patterns in the text and create templates representing event and entity descriptions from them .</sentence>
				<definiendum id="0">first component</definiendum>
			</definition>
			<definition id="2">
				<sentence>166 Template S Template T Probability A B 0.671 A D 0.505 B D 0.752 C D 0.504 Table 1 : Pairwise Probabilities for Example Coreference Set scribed with an indefinite phrase , a definite phrase ( including pronouns ) , or neither of these ( e.g. , a bare , non-pronominal noun phrase ) .</sentence>
				<definiendum id="0">Template S Template T Probability A B</definiendum>
				<definiendum id="1">definite phrase</definiendum>
				<definiens id="0">Pairwise Probabilities for Example Coreference Set scribed with an indefinite phrase , a</definiens>
			</definition>
</paper>

		<paper id="1309">
</paper>

		<paper id="0219">
</paper>

		<paper id="0303">
			<definition id="0">
				<sentence>We run LR MDP over the same test corpus in different settings , demonstrating the flexibility/quality/parse time trade off .</sentence>
				<definiendum id="0">LR MDP</definiendum>
				<definiens id="0">over the same test corpus in different settings</definiens>
			</definition>
			<definition id="1">
				<sentence>Partial Analyses : Chunkl : that ( ( ROOT THAT ) ( TYPE PRONOUN ) ( FRAME *THAT ) ) Chunk2 : out ( ( TYPE NEGATIVE ) ( DEGREE NORMAL ) ( FRAME *RESPOND ) ) Chunk3 : my ( ( ROOT I ) ( TYPE PERSON-POSS ) ( FRAME *I ) ) Chunk4 : mornings ( ( TIME-OF-DAY MORNING ) ( NUMBER PLURAL ) ( FRAME *SIMPLE-TIME ) ( SIMPLE-UNIT-NAME TOD ) ) Figure 1 : Parse Example The first stage in our approach is the Partial Parsing stage where the goal is to obtain an analysis for islands of the speaker 's utterance if it is not possible to obtain an analysis for the whole utterance .</sentence>
				<definiendum id="0">Partial Analyses</definiendum>
				<definiendum id="1">Chunkl</definiendum>
				<definiens id="0">that ( ( ROOT THAT ) ( TYPE PRONOUN ) ( FRAME *THAT ) ) Chunk2 : out ( ( TYPE NEGATIVE ) ( DEGREE NORMAL ) ( FRAME *RESPOND ) ) Chunk3 : my ( ( ROOT I ) ( TYPE PERSON-POSS ) ( FRAME *I ) ) Chunk4 : mornings ( ( TIME-OF-DAY MORNING ) ( NUMBER PLURAL ) ( FRAME *SIMPLE-TIME ) ( SIMPLE-UNIT-NAME TOD</definiens>
			</definition>
			<definition id="2">
				<sentence>It is defined by an interlingua specification , which serves as the primary symbolic knowledge source used during the Combination stage .</sentence>
				<definiendum id="0">interlingua specification</definiendum>
			</definition>
			<definition id="3">
				<sentence>Ideal Repair Hypothesis : ( MY-COMB ( ( FRAME *RESPOND ) ( DEGREE NORMAL ) ( TYPE NEGATIVE ) ) ; argl ( ( TIME-OF-DAY MORNING ) ( NUMBER PLURAL ) ( FRAME *SIMPLE-TIME ) ( SIMPLE-UNIT-NAME TOD ) ) ; arg2 WHEN ) ; slot ; insert arg2 into argl in slot Ideal Structure : ( ( FRAME *RESPOND ) ( DEGREE NORMAL ) ( TYPE NEGATIVE ) ( WHEN ( ( FRAME *SIMPLE-TIME ) ( TIME-OF-DAY MORNING ) ( NUMBER PLURAL ) ( SIMPLE-UNIT-NAME TOD ) ) ) ) Gloss : Mornings are out .</sentence>
				<definiendum id="0">FRAME *RESPOND )</definiendum>
				<definiens id="0">TIME-OF-DAY MORNING ) ( NUMBER PLURAL ) ( FRAME *SIMPLE-TIME ) ( SIMPLE-UNIT-NAME TOD ) ) ; arg2 WHEN ) ; slot ; insert arg2 into argl in slot Ideal Structure : ( ( FRAME *RESPOND ) ( DEGREE NORMAL ) ( TYPE NEGATIVE ) ( WHEN ( ( FRAME *SIMPLE-TIME ) ( TIME-OF-DAY MORNING ) ( NUMBER PLURAL ) ( SIMPLE-UNIT-NAME TOD</definiens>
			</definition>
			<definition id="4">
				<sentence>The job of the Combination Mechanism is both to determine which fragments to include as well as how to combine the selected ones .</sentence>
				<definiendum id="0">Combination Mechanism</definiendum>
			</definition>
			<definition id="5">
				<sentence>The first hypothesis , displayed in Figure Hypothesis2 : ( MY-COMB ( ( TIME-OF-DAY MORNING ) ( NUMBER PLURAL ) ( FRAME *SIMPLE-TIME ) ( SIMPLE-UNIT-NAME TOD ) ) ( ( FRAME *RESPOND ) ( DEGREE NORMAL ) ( TYPE NEGATIVE ) ) ? ? )</sentence>
				<definiendum id="0">MY-COMB (</definiendum>
				<definiens id="0">TIME-OF-DAY MORNING ) ( NUMBER PLURAL ) ( FRAME *SIMPLE-TIME ) ( SIMPLE-UNIT-NAME TOD ) ) ( ( FRAME *RESPOND ) ( DEGREE NORMAL ) ( TYPE NEGATIVE</definiens>
			</definition>
			<definition id="6">
				<sentence>The parser uses a semantic grammar with approximately 1000 rules which maps the input sentence onto an interlingua representation ( ILT ) which represents the meaning of the sentence in a languageindependent manner .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">uses a semantic grammar with approximately 1000 rules which maps the input sentence onto an interlingua representation ( ILT ) which represents the meaning of the sentence in a languageindependent manner</definiens>
			</definition>
</paper>

		<paper id="0102">
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>We first cluster words according to the given compositions , then construct a cluster-based compositional frame for each word cluster , which contains both new and given compositions relevant with the words in the cluster .</sentence>
				<definiendum id="0">cluster</definiendum>
				<definiens id="0">contains both new and given compositions relevant with the words in the cluster</definiens>
			</definition>
			<definition id="1">
				<sentence>Word compositions have long been a concern in lexicography ( Benson et al. 1986 ; Miller et al. 1995 ) , and now as a specific kind of lexical knowledge , it has been shown that they have an important role in many areas in natural language processing , e.g. , parsing , generation , lexicon building , word sense disambiguation , and information retrieving , etc. ( e.g. , Abney 1989 , 1990 ; Benson et al. 1986 ; Yarowsky 1995 ; Church and Hanks 1989 ; Church , Gale , Hans , and Hindle 1989 ) .</sentence>
				<definiendum id="0">Church</definiendum>
				<definiens id="0">an important role in many areas in natural language processing , e.g. , parsing , generation , lexicon building , word sense disambiguation , and information retrieving</definiens>
			</definition>
			<definition id="2">
				<sentence>Suppose A is the set of adjectives , N is the set of nouns , for any a E A , let f ( a ) C N be the instance set of a , i.e. , the set of nouns in N which can be combined with a , and for any n E N , let g ( n ) C A be the instance set of n , i.e. , the set of adjectives in A which can be combined with n. We first give some formal definitions in the following : Definition 1 partition Suppose U is a non-empty finite set , we call &lt; U1 , U2 , ... , Uk &gt; a partition of U , if : i ) for any Ui , and Uj , i ¢ j , Ui M Uj = ii ) U = Ul &lt; t &lt; kUl We call Ui a cluster of U. Suppose U -- &lt; A1 , A2 , ... , Ap &gt; is a partition of A , V ~ &lt; N1 , N2 , ... , Nq &gt; is a partition of N , f and g are defined as above , for any N/ , let g ( N ) = { &amp; : n # ¢ ) , and for any n , let , f &lt; U , V &gt; ( n ) =l { a : 3At , Al E g ( Nk ) , a E Ajl } -g ( n ) I , where n E Nk .</sentence>
				<definiendum id="0">Suppose A</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">E A , let f</definiendum>
				<definiendum id="3">U2 , ... , Uk &gt;</definiendum>
				<definiendum id="4">, Ap &gt;</definiendum>
				<definiendum id="5">N2 , ... , Nq &gt;</definiendum>
				<definiendum id="6">V &gt;</definiendum>
				<definiens id="0">the set of adjectives</definiens>
				<definiens id="1">the set of nouns , for any a</definiens>
				<definiens id="2">the instance set of a , i.e. , the set of nouns in N which can be combined with a , and for any n E N , let g ( n ) C A be the instance set of n , i.e. , the set of adjectives in A which can be combined with n. We first give some formal definitions in the following : Definition 1 partition Suppose U is a non-empty finite set</definiens>
				<definiens id="3">ii ) U = Ul &lt; t &lt; kUl We call Ui a cluster of U. Suppose U -- &lt; A1 , A2 , ...</definiens>
				<definiens id="4">a partition of A</definiens>
				<definiens id="5">a partition of N , f and g</definiens>
			</definition>
			<definition id="3">
				<sentence>The other is tl = t2 = 1 , the abstract degree is the highest , when a possible result is that all nouns form a cluster and all adjectives form a cluster , which means that all possible compositions , reasonable or unreasonable , are learned .</sentence>
				<definiendum id="0">abstract degree</definiendum>
				<definiens id="0">all nouns form a cluster and all adjectives form a cluster , which means that all possible compositions</definiens>
			</definition>
			<definition id="4">
				<sentence>Suppose al , a2 E A , f is defined as above , we define the linear distance between them as ( 2 ) : ( 2 ) dis ( a1 a2 ) -1 I/ ( ax ) nl ( a2 ) l ' \ [ f ( ax ) Of ( a2 ) l Similarly , we can define the linear distance between nouns dis ( nl , n2 ) based on g. In contrast , we call the distances in definition 3 non-linear distances .</sentence>
				<definiendum id="0">linear distance</definiendum>
			</definition>
			<definition id="5">
				<sentence>In general , evolution operation consists of recombination , mutation and selection .</sentence>
				<definiendum id="0">evolution operation</definiendum>
				<definiens id="0">consists of recombination , mutation and selection</definiens>
			</definition>
			<definition id="6">
				<sentence>Selection operation selects the solutions among those in the population of certain generation according to their fitness .</sentence>
				<definiendum id="0">Selection operation</definiendum>
			</definition>
			<definition id="7">
				<sentence>Suppose Fi is the compositional frame of Ni , let F = &lt; F1 , F~ , ... , Fq &gt; , for any F~ , let AF~ = { a : 3X E F~ , a E X } .</sentence>
				<definiendum id="0">Suppose Fi</definiendum>
				<definiens id="0">the compositional frame of Ni</definiens>
			</definition>
			<definition id="8">
				<sentence>Intuitively , AF~ is the set of the adjectives learned as the compositional instances of the noun in Ni .</sentence>
				<definiendum id="0">AF~</definiendum>
				<definiens id="0">the set of the adjectives learned as the compositional instances of the noun in Ni</definiens>
			</definition>
			<definition id="9">
				<sentence>Definition 5 Deficiency rate o~F El &lt; i &lt; q EneN , \ [ A~ ARe \ [ Intuitively , aF refers to the ratio between the reasonable compositions which are not learned and all the reasonable ones. Definition 6 Redundancy rate fir fiR -- -El_ &lt; i_ &lt; q EneNi \ ] AF~ -An I 5F Intuitively , fie refers to the ratio between unreasonable compositions which are learned and all the learned ones. So the problem of estimating tl and t2 can be formalized as ( 5 ) : ( 5 ) to find tl and t2 , which makes av = 0 , and flF=0. But , ( 5 ) may exists no solutions , because its constraints are two strong , on one hand , the sparseness of instances may cause ~F not to get 0 value , even if tl and t~ close to 1 , on the other hand , the difference between words may cause fir not to get 0 value , even if tl and t2 close to 0. So we need to weaken ( 5 ) . In fact , both O~F and flF can be seen as the functions of tl and t2 , denoted as o~f ( tl , t2 ) and l~F ( tl , tu ) respectively. Given some values for tl and t2 , we can compute aF and fiR. Although there may exist no values ( t~ , t~ ) for ( tl , t2 ) , such that ! ! aF ( t~ , t~ ) = flF ( tx , t2 ) = 0 , but with t~ and t2 increasing , off tends to decrease , while fiE tends to increase. So we can weaken ( 5 ) as ( 6 ) . ( 6 ) to find tl and t2 , which maximizes ( 7 ) . ( 7 ) ~ ( ~l , ~ ) ~rl ( ~ ' , ,~'~ ) ~F ( tl , t2 ) Fi ( t ' 1 , t'2 ) \ [ ~ ( ta , t : ) eF2 ( t ' 1 , t~2 ) ~F ( tl , 42 ) ) I r2 ( t'l , I where rx ( t~ , t~ ) = { ( tl , t2 ) : 0 &lt; tl _ &lt; t~,0 _ &lt; t2 _ &lt; t~ ) , r2 ( t~ , t~ ) = { ( tl , t2 ) : t~ &lt; tl &lt; 1 , t~ &lt; t2 &lt; 1 } Intuitively , if we see the area ( \ [ 0 , 1\ ] ; \ [ 0 , 1\ ] ) as a sample space for tl and t2 , Fl ( t~ , t~ ) and F2 ( t~ , t~ ) are its sub-areas. So the former part of ( 7 ) is the ! ! mean deficiency rate of the points in Fl ( tl , tz ) , and the latter part of ( 7 ) is the mean deficiency rate of the points in F2 ( t~ , t~ ) . To maximize ( 7 ) means to maximize its former part , while to minimize its latter part. So our weakening ( 5 ) into ( 6 ) lies in finding a point ( t~ , t~ ) , such that the mean deficiency rate of the sample points in F2 ( t~ , t~ ) tends to be very low , rather than finding a point ( t~ , t~ ) , such that its deficiency rate is 0. Evaluation We randomly select 30 nouns and 43 adjectives , and retrieve 164 compositions ( see Appendix I ) between them from Xiandai Hanyu Cihai ( Zhang et al. 1994 ) , a word composition dictionary of Chinese. After checking by hand , we get 342 reasonable compositions ( see Appendix I ) , among which 177 ones are neglected in the dictionary. So the sufficiency rate ( denoted as 7 ) of these given compositions is 47.9 % . We select 0.95 as the value of t3 , and let tl = tively , we get 121 groups of values for O~F and fiR. Fig.1 and Fig.2 demonstrate the distribution of aF and ~3F respectively. dc£ielcney i ! iiiii ! iiiiiii ! i ! iiiii ! 4o ... . `` i i iiiiiiiiiiiiiiiiiiiiiiiiiii ii : : ... . 3 t2 tl Figure 1 : The distribution of O~F For any given tl , and t2 , we found ( 7 ) get its biggest value when t I = 0.4 and t2 = 0.4 , so we seJi , He and Huang 29 Learning New Compositions rcdundanec • atc ( % ) ... .. ~ : ~'.. : : ' : ili : :iii~i~i~i~ ~160-80 .~ &lt; .v..'.~ ! ! ! ~i ! ! ! i ! ! ! ii ! ! ! ! : ' : ' : ! : ! : ! ! ! ! i ! ! ! i ! i ! i ! iiiii ! iii ! iii ! i : i : : ' : ' : ' : '' D 4.0-50 L00 : ~ : ~iii : :iiiiiii ; ; ii ; iiiiiiii : : ~ ... ... . i ? : ~i ~ ... ... ... . \ [ \ ] Z0-~ 0 : iiiiiiiiiiiiiiiii ' , i ' , iii ' , iiiiiii',0 iiiiiiiiiiiiiii ii t2 ( L/tO ) Figure 2 : The distribution of fir ~ ( % ) ~1 ~2 O/F ( % ) BF ( % ) 32.5 0.5 0.6 13.2 34.5 47.9 0.4 0.4 15.4 26.4 58.2 0.4 0.4 10.3 15.4 72.5 0.3 0.3 9.5 7.6 Table 1 : The relation between 7 , ~1 , t2 , aF and fiR. ~ ( % ) ~F ( % ) e1 ( % ) BF ( % ) ~2 ( % ) 58.2 11.2 8.3 17.5 10.8 72.5 7.4 4.1 8.7 5.4 Table 2 : The relation between 7 , mean O~F and mean BF , el and e~ is the mean error. lect 0.4 as the appropriate value for both tl and t2. The result is listed in Appendix II. From Fig.1 and Fig.2 , we can see that when tl = 0.4 and t2 = 0.4 , both c~F and BF get smaller values. With the two parameters increasing , aF decreases slowly , while BF increases severely , which demonstrates the fact that the learning of new compositions from the given ones has reached the limit at the point : the other reasonable compositions will be learned at a cost of severely raising the redundancy rate. From Fig.l , we can see that o~F generally increases as ~1 and t2 increase , this is because that to increase the thresholds of the distances between clusters means to raise the abstract degree of the model , then more reasonable compositions will be learned. On the other hand , we can see from Fig.2 that when tl _ &gt; 0.4 , t2 &gt; _ 0.4 , fiR roughly increases as ~1 and ~2 increase , but when tz &lt; 0.4 , or t2 &lt; 0.4 , fir changes in a more confused manner .</sentence>
				<definiendum id="0">aF</definiendum>
				<definiendum id="1">e~</definiendum>
				<definiens id="0">the ratio between unreasonable compositions which are learned and all the learned ones. So the problem of estimating tl</definiens>
			</definition>
			<definition id="10">
				<sentence>1993 Introduction to WordNet : An On-line Lexical Database , International Journal of Lexicography , ( Second Edition .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An On-line Lexical Database</definiens>
			</definition>
</paper>

		<paper id="0124">
			<definition id="0">
				<sentence>Finally , the post-mortem method , which integrates these concepts into a parsing system , is described .</sentence>
				<definiendum id="0">post-mortem method</definiendum>
				<definiens id="0">integrates these concepts into a parsing system , is described</definiens>
			</definition>
			<definition id="1">
				<sentence>Noun modifier is a fifth part of speech that is used in this research to indicate those words that can be used to modify nouns ; this will eliminate extraneous parses that occur when a word defined as both a noun and adjective is used to modify a head noun .</sentence>
				<definiendum id="0">Noun modifier</definiendum>
				<definiens id="0">a fifth part of speech that is used in this research to indicate those words that can be used to modify nouns ; this will eliminate extraneous parses that occur when a word defined as both a noun and adjective is used to modify a head noun</definiens>
			</definition>
			<definition id="2">
				<sentence>Badecker and Caramazza \ [ 2\ ] discussed the distinction between inflectional and derivational morphology as it applies to acquired language deficit disorder , and , in general , to the theory of language learning .</sentence>
				<definiendum id="0">Badecker</definiendum>
				<definiens id="0">discussed the distinction between inflectional and derivational morphology as it applies to acquired language deficit disorder</definiens>
			</definition>
			<definition id="3">
				<sentence>Morphological reconstruction researchers process an unknown word by using knowledge of the root stem and affixes of that word .</sentence>
				<definiendum id="0">Morphological reconstruction researchers</definiendum>
				<definiens id="0">process an unknown word by using knowledge of the root stem and affixes of that word</definiens>
			</definition>
			<definition id="4">
				<sentence>Morphological recognition uses knowledge about affixes to determine the possible parts of speech and other features of a word , without utilizing any direct information about the word 's stem .</sentence>
				<definiendum id="0">Morphological recognition</definiendum>
				<definiens id="0">uses knowledge about affixes to determine the possible parts of speech and other features of a word , without utilizing any direct information about the word 's stem</definiens>
			</definition>
			<definition id="5">
				<sentence>The first-choice list is a subset of the second-choice list .</sentence>
				<definiendum id="0">first-choice list</definiendum>
				<definiens id="0">a subset of the second-choice list</definiens>
			</definition>
			<definition id="6">
				<sentence>The test corpus is a set of 356 sentences from the Timit corpus \ [ 16\ ] , a corpus of sentences that has no underlying semantic theme .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiens id="0">a set of 356 sentences from the Timit corpus \ [ 16\ ] , a corpus of sentences that has no underlying semantic theme</definiens>
			</definition>
			<definition id="7">
				<sentence>A match occurs when the sentence has generated a parse that occurs within the control parse forest for that sentence .</sentence>
				<definiendum id="0">match</definiendum>
				<definiens id="0">occurs when the sentence has generated a parse that occurs within the control parse forest for that sentence</definiens>
			</definition>
			<definition id="8">
				<sentence>A deletion occurs when the sentence has failed to produce a parse that occurs in the : control parse forest for that sentence .</sentence>
				<definiendum id="0">deletion</definiendum>
				<definiens id="0">occurs when the sentence has failed to produce a parse that occurs in the : control parse forest for that sentence</definiens>
			</definition>
</paper>

		<paper id="0322">
			<definition id="0">
				<sentence>The variance between CK and eL is computed as follows : II~K -~rII 2 VKL , + I ( 1 ) NK I~FL where XK is the mean observation for cluster CK , NK is the number of observations in CK , and ~L and NL are defined similarly for CL .</sentence>
				<definiendum id="0">eL</definiendum>
				<definiendum id="1">XK</definiendum>
				<definiendum id="2">NK</definiendum>
				<definiens id="0">the mean observation for cluster CK</definiens>
				<definiens id="1">the number of observations in CK</definiens>
			</definition>
			<definition id="1">
				<sentence>The expectation maximization algorithm ( Dempster , Laird , and Rubin , 1977 ) , commonly known as the EM algorithm , is an iterative estimation procedure in which a problem with missing data is recast to make use of complete data estimation techniques .</sentence>
				<definiendum id="0">expectation maximization algorithm ( Dempster , Laird</definiendum>
				<definiens id="0">an iterative estimation procedure in which a problem with missing data is recast to make use of complete data estimation techniques</definiens>
			</definition>
			<definition id="2">
				<sentence>This is the expected value of the loglikelihood function for the complete data D = ( Y , S ) , where Y is the observed data and S is the missing sense value : Q ( /9/1/9 ) = E\ [ lnp ( Y , SI/9 ' ) I/9 , Y ) \ ] ( 3 ) Here , /9 is the current value of the maximum likelihood estimates of the model parameters and/9i is the improved estimate that we are seeking ; p ( Y , SI/9 i ) is the likelihood of observing the complete data given the improved estimate of the model parameters .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">/9</definiendum>
				<definiendum id="3">SI/9 i )</definiendum>
				<definiens id="0">the observed data and</definiens>
				<definiens id="1">the current value of the maximum likelihood estimates of the model parameters and/9i is the improved estimate</definiens>
			</definition>
			<definition id="3">
				<sentence>The E-step finds the expected values of the sufficient statistics of the complete model using the current estimates of the model parameters .</sentence>
				<definiendum id="0">E-step</definiendum>
			</definition>
			<definition id="4">
				<sentence>For the Naive Bayes model with 3 observable features A , B , C and an unobservable classification feature S , where 8 = { P ( a , s ) , P ( b , s ) , P ( c , s ) , P ( s ) } , the E and M-steps are : statistics are computed as follows : eoun # ( s , a ) = P ( sla ) x count ( a ) coun # ( s , b ) -= P ( slb ) × count ( b ) eounti ( s , c ) = P ( slc ) x count ( c ) count ' ( s ) -~ { P ( sla , b , c ) x count ( a , b , e ) } a , b , c where : P ( sla ) = E P ( sla ' b , c ) hie P ( sla , b , c ) = P ( s , a , b , c ) P ( a , b , c ) P ( s , a , b , c ) = P ( s , a ) x P ( s , b ) x P ( s , c ) P ( s ) ~ P ( a , b , c ) = E P ( s , a ) × P ( s , b ) × P ( s , c ) , P ( s ) 2 step are used to re-estimate the model parameters/9i : Pi ( s , a ) = c°unti ( s ' a ) N pi ( s , b ) -c°unti ( s ' b ) N Pi ( s , c ) -'c°unti ( s ' c ) N counti ( s ) Pi ( s ) = N where s , a , b , and c denote specific values of S , A , B , and C respectively , and P ( slb ) and P ( s\ ] c ) are defined analogously to P ( sIa ) .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">s ) , P ( b , s ) , P ( c , s ) , P ( s ) } , the E and M-steps are : statistics are computed as follows : eoun #</definiens>
				<definiens id="1">s ) -~ { P ( sla , b , c ) x count ( a , b , e ) } a , b , c where : P ( sla ) = E P ( sla ' b , c ) hie P ( sla , b , c ) = P ( s , a , b , c ) P ( a , b , c ) P ( s , a , b , c ) = P ( s , a ) x P ( s , b ) x P ( s , c ) P ( s ) ~ P ( a , b , c ) = E P ( s , a</definiens>
				<definiens id="2">s ' b ) N Pi ( s , c ) -'c°unti ( s ' c ) N counti ( s ) Pi ( s ) = N where s , a , b , and c denote specific values of S , A , B , and C respectively , and</definiens>
			</definition>
			<definition id="5">
				<sentence>Morphology The feature M represents the morphology of the ambiguous word .</sentence>
				<definiendum id="0">M</definiendum>
				<definiens id="0">the morphology of the ambiguous word</definiens>
			</definition>
			<definition id="6">
				<sentence>As an example , the values of these features for concern are as follows : • UL2 : and , the , a , of , to , financial , have , because , an , 's , real , cause , calif. , york , u.s. , other , mass. , german , ( null ) , ( none ) • UL1 : the , services , of , products , banking , 's , pharmaceutical , energy , their , expressed , electronics , some , biotechnology , aerospace , environmental , such , japanese , gas , investment , ( null ) , ( none ) • URI : about , said , that , over , 's , in , with , had , are , based , and , is , has , was , to , for , among , will , did , ( null ) , ( none ) • URn : the , said , a , it , in , that , to , n't , is , which , by , and , was , has , its , possible , net , but , annual , ( null ) , ( none ) Content Collocations Features of the form CL1 and CR1 indicate the content word occurring in the position 1 place to the left or right , respectively , of the ambiguous word .</sentence>
				<definiendum id="0">banking</definiendum>
				<definiens id="0">'s , real , cause</definiens>
			</definition>
			<definition id="7">
				<sentence>Conceptually , the neighborhood of a word is a type of equivalence class .</sentence>
				<definiendum id="0">neighborhood of a word</definiendum>
				<definiens id="0">a type of equivalence class</definiens>
			</definition>
			<definition id="8">
				<sentence>The Baum-Welch forward-backward algorithm ( Baum , 1972 ) is a specialized form of the EM algorithm that assumes the underlying parametric model is a hidden Markov model .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiens id="0">a specialized form of the EM</definiens>
				<definiens id="1">a hidden Markov model</definiens>
			</definition>
</paper>

		<paper id="0509">
			<definition id="0">
				<sentence>Key words used in the high-frequency key word method are content words which appear more than twice in a given text ( Luhn , 1957 ) , ( Edmundson , 1969 ) .</sentence>
				<definiendum id="0">Key words</definiendum>
			</definition>
			<definition id="1">
				<sentence>The model consists of two strings of words ( keywordsl and keywords2 ) before and after the synchronization point ( point B ) .</sentence>
				<definiendum id="0">model</definiendum>
			</definition>
</paper>

		<paper id="0909">
			<definition id="0">
				<sentence>`` Mass change '' means more than a simple `` global search and replace '' of text , Using formal language and NLP components , we customized .</sentence>
				<definiendum id="0">Mass change ''</definiendum>
				<definiens id="0">means more than a simple `` global search and replace '' of text , Using formal language</definiens>
			</definition>
			<definition id="1">
				<sentence>The semantic domain model consists of a set of assertions of the form object ( Child , \ [ Relation , Parent\ ] ) where Relation is either 'isa ' or 'ispart ' , and the three possible roots of the hierarchies are 'entity ' , 'predicate ' , and 'property ' .</sentence>
				<definiendum id="0">semantic domain model</definiendum>
				<definiendum id="1">Relation</definiendum>
				<definiens id="0">consists of a set of assertions of the form object ( Child , \ [ Relation</definiens>
			</definition>
			<definition id="2">
				<sentence>A post-generation process diverts constraint violations to a separate stream which results eventually in the creation of a special report .</sentence>
				<definiendum id="0">post-generation process diverts</definiendum>
				<definiens id="0">constraint violations to a separate stream which results eventually in the creation of a special report</definiens>
			</definition>
			<definition id="3">
				<sentence>KIMMO : A General Morphological Processor .</sentence>
				<definiendum id="0">KIMMO</definiendum>
			</definition>
			<definition id="4">
				<sentence>Two-Level Morphology : A General Computational Model for Word-Form Recognition and Production .</sentence>
				<definiendum id="0">Two-Level Morphology</definiendum>
			</definition>
			<definition id="5">
				<sentence>Categorial Investigations : Logical and Linguistic Aspects of the Lambek Calculus .</sentence>
				<definiendum id="0">Categorial Investigations</definiendum>
			</definition>
</paper>

		<paper id="0905">
			<definition id="0">
				<sentence>If we look at GRASSIC first , there are three comparisons that can be made : • GRASSIC vs. non-personalised booklets : As pointed out above , GRASSIC has the potential to save the Scottish health service several million pounds per year ( assuming that doctors are willing to use the system ) , which means that its development , fielding , and deployment costs would probably be paid back within a year .</sentence>
				<definiendum id="0">GRASSIC</definiendum>
				<definiens id="0">the potential to save the Scottish health service several million pounds per year ( assuming that doctors are willing to use the system</definiens>
			</definition>
</paper>

		<paper id="0318">
			<definition id="0">
				<sentence>Aspectual classification is a necessary component for a system that analyzes temporal constraints , or performs lexical choice and tense selection in machine translation ( Moens and Steedman , 1988 ; Passonneau , 1988 ; Doff , 1992 ; Klavans , 1994 ) .</sentence>
				<definiendum id="0">Aspectual classification</definiendum>
				<definiens id="0">a necessary component for a system that analyzes temporal constraints , or performs lexical choice and tense selection in machine translation ( Moens and Steedman , 1988 ; Passonneau , 1988</definiens>
			</definition>
			<definition id="1">
				<sentence>The first indicator , frequency , is simply the the frequency with which each verb occurs .</sentence>
				<definiendum id="0">frequency</definiendum>
			</definition>
			<definition id="2">
				<sentence>The most popular method of decision tree induction , employed here , is recursive partitioning ( Quinlan , 1986 ; Breiman et al. , 1984 ) , which expands the tree from top to bottom .</sentence>
				<definiendum id="0">recursive partitioning</definiendum>
				<definiens id="0">expands the tree from top to bottom</definiens>
			</definition>
</paper>

		<paper id="0125">
			<definition id="0">
				<sentence>Notice that PTs can also appear without PNs : ( bebhag + E ) bagsa-ga jeil senmangbad-neun sahoijeg fiwijung-eui hana-i-da ( A doctor ( of Law + E ) is one of the most envied social titles ) - ' ( ~'+E ) ~1 -- ~ ~'~ ~-~'-~ ~t~ geu ( 'bebhag + E ) bagsa-neun iljfig hangug-eul ddena-ssda ( This doctor ( of Law + E ) left Korea early ) Thus , in order to analyze the strin~ followed by a PT in contexts such as ( 5 ) , the system should first look up a lexicon of Common Nouns ( and eventually a lexicon of Determiners ) , and if the search fails , one could suppose that we found a proper name : ( Sa ) ol~ ~,1-71~71~ -~r~ igonggyei bagsa-ga ingi-ga nop-da ( Doctors of Natural Science are highly requested ) ( Sb ) o I ~ ~x~7~ ~71~ ~ i gonghag bagsa-ga ingi-ga nop-da ( This doctor of Science is highly requested ) 277 ( Sc ) ol ~ ~'l'~ ~ 21 21~r4iminu bagsa-ga ingi-ga nop-da ( Doctor Lee MinU is highly requested ) In ( Sa ) , the string found with 'bagsa \ [ doctor\ ] ' is a simple noun 'igonggyei \ [ natural science\ ] ' ; the sequence that precedes 'bagsa \ [ doctor\ ] ' in ( 5b ) is a phrase composed of a determiner 'i \ [ this\ ] ' and a common noun 'gonghag \ [ science\ ] ' ; the element followed by `` bagsa \ [ doctor\ ] ' in ( 5c ) will not be matched with any entries of the lexicon of common nouns : only this string will then be recognized as a proper name .</sentence>
				<definiendum id="0">Sa ) ol~ ~,1-71~71~ -~r~ igonggyei bagsa-ga ingi-ga nop-da</definiendum>
				<definiens id="0">PTs can also appear without PNs : ( bebhag + E ) bagsa-ga jeil senmangbad-neun sahoijeg fiwijung-eui hana-i-da ( A doctor ( of Law + E ) is one of the most envied social titles</definiens>
				<definiens id="1">a simple noun 'igonggyei \ [ natural science\ ] '</definiens>
			</definition>
			<definition id="1">
				<sentence>Let us compare ( 4 ) with ( 6 ) : bebhag bagsa Kim MinU-neun migug-eise 5 nyengan gongbuha-essda ( Kim MinU , Dr. of Laws , has studied in U.S.A during 5 years ) The sentence ( 6 ) can still be transformed into : ~ ~l~oll , ~-I ~ ~ ~ ~ , q-olr -- lKim MinU-neun migug-eise 5 nyengan gongbuha-n bebhag bagsa-ida ( Kim MinU is a doctor of Laws who has studied in U.S.A. during 5 years ) In fact , the sequence containing PTs corresponds to a simple sentence : PN W-Professional Title W-Professional Title PN S : PN be a W-Professional Title ( 7a ) ~ ~q~ ~x~ ( Tb ) ffi ~ed ~x~ ~ ~ ( 7¢ ) = z~ ~-~ ~ ~1-x\ ] .</sentence>
				<definiendum id="0">Kim MinU</definiendum>
				<definiens id="0">a doctor of Laws who has studied in U.S.A. during 5 years</definiens>
				<definiens id="1">a simple sentence : PN W-Professional Title W-Professional Title PN S</definiens>
			</definition>
			<definition id="2">
				<sentence>t. Kdm MinU bebhag bagsa \ [ Dr. of Law Kim MinU\ ] bebhag bagsa Kim MinU \ [ KJm MinU , Dr. of Law , \ ] Kim MinU-neun bebhag bagsa-ida \ [ KimMinU is a Dr. of Law\ ] This type of phrases contains nouns designating a family relation ( FR ) such as : o ) ~ adeul \ [ son\ ] o~x\ ] ~eji \ [ father\ ] ~ che \ [ wife\ ] ; ~ sonja \ [ ~andchild\ ] ~ ~ myenegli \ [ daughter-in-law\ ] These nouns have a strong possibility to occur with a proper name , as shown in the following sentence : ~o_ .</sentence>
				<definiendum id="0">KimMinU</definiendum>
				<definiens id="0">a Dr. of Law\ ] This type of phrases contains nouns designating a family relation ( FR ) such as : o ) ~ adeul \ [ son\ ] o~x\ ] ~eji \</definiens>
			</definition>
			<definition id="3">
				<sentence>.9_a\ ] ~lo~lx t -~o1 ~rqGangGinO-ssi-nei-eise PN &lt; Kang GinO &gt; -IS\ [ Mr.\ ] -PostHN\ [ house\ ] -Postp fire-Postp occur-Past ( There was a fire in Mr. Kang GinO 's house ) bul-i na-ssda In French , we observe a preposition similar to this PostHN : ehez ( 's family/house ) , a locative preposition , as at one ~ in English , which selects only human nouns : 283 fly a eu un feu chez M. Pierre Piton There was afire at M. Pierre Picon Therefore , when we encounter a sequence that ends with an IN-PostHN-Poalp , the possibility to find a PN is increased .</sentence>
				<definiendum id="0">-Postp fire-Postp occur-Past</definiendum>
				<definiens id="0">ends with an IN-PostHN-Poalp , the possibility to find a PN is increased</definiens>
			</definition>
			<definition id="4">
				<sentence>In general , it is understood that Recall is the ratio of relevant documents retrieved for a given query over the number of relevant documents for that query in a database , and Precision is the I ratio of the number of relevant documents retrieved over the total number of documents retrieved \ [ Fra92\ ] .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiendum id="1">Precision</definiendum>
				<definiens id="0">the ratio of relevant documents retrieved for a given query over the number of relevant documents for that query in a database</definiens>
				<definiens id="1">the I ratio of the number of relevant documents retrieved over the total number of documents retrieved</definiens>
			</definition>
</paper>

		<paper id="1308">
			<definition id="0">
				<sentence>The London-Lund Corpus is the source of English data , whereas the Portuguese data come from a corpus collected especially for the purposes of this research .</sentence>
				<definiendum id="0">London-Lund Corpus</definiendum>
				<definiens id="0">the source of English data , whereas the Portuguese data come from a corpus collected</definiens>
			</definition>
			<definition id="1">
				<sentence>A full description of the procedures , as well as the complete listing of codes used in the annotation scheme , can be found in ( Rocng ) .</sentence>
				<definiendum id="0">full description of the procedures</definiendum>
				<definiens id="0">the complete listing of codes used in the annotation scheme</definiens>
			</definition>
			<definition id="2">
				<sentence>Other strategies grouped under discourse processes include : secondary reference , which is the use of first and second person pronouns in speech reported verbatim to refer to persons previously mentioned in the dialogue ; distant anaphora , which are pronouns with very distant antecedents over fifty tone units but without competing candidates ; pronouns which conjoin referents in a set , called set creation ; reference to an element within a set , called set member ; and the cases of antecedentless anaphors ( see ( Cor96 ) ) , in which the processing 58 strategy is called deixis .</sentence>
				<definiendum id="0">distant anaphora</definiendum>
				<definiens id="0">pronouns with very distant antecedents over fifty tone units but without competing candidates ; pronouns which conjoin referents in a set , called set creation</definiens>
			</definition>
</paper>

		<paper id="1204">
			<definition id="0">
				<sentence>A Speech Integrating Markup Language ( SIML ) is designed as an general interface for integrating NLG and SS .</sentence>
				<definiendum id="0">Speech Integrating Markup Language ( SIML</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Text Encoding Initiative ( TEl ) ( SperbergMcQueen and Burnard , 1993 ) provides a general guideline for transcribing spoken language using Standard Generalized Markup Language ( SGML ) .</sentence>
				<definiendum id="0">Text Encoding Initiative</definiendum>
			</definition>
			<definition id="2">
				<sentence>SGML is an international standard for encoding electronic document for data interchange .</sentence>
				<definiendum id="0">SGML</definiendum>
				<definiens id="0">an international standard for encoding electronic document for data interchange</definiens>
			</definition>
			<definition id="3">
				<sentence>The STP component computes the prosodic features based on the discourse , semantic and syntactic information encoded in the SIML format .</sentence>
				<definiendum id="0">STP component</definiendum>
				<definiens id="0">computes the prosodic features based on the discourse , semantic and syntactic information encoded in the SIML format</definiens>
			</definition>
			<definition id="4">
				<sentence>MAGICs goal is to provide a temporally coordinated multimedia presentation of data in an online medical database .</sentence>
				<definiendum id="0">MAGICs goal</definiendum>
				<definiens id="0">to provide a temporally coordinated multimedia presentation of data in an online medical database</definiens>
			</definition>
			<definition id="5">
				<sentence>In our algorithm , we first identify the basic semantic unit ( BSU ) , which is the smallest , complete information unit in the semantic structure .</sentence>
				<definiendum id="0">BSU</definiendum>
				<definiens id="0">the smallest , complete information unit in the semantic structure</definiens>
			</definition>
			<definition id="6">
				<sentence>A Basic Semantic Unit ( BSU ) is a leaf node in a semantic hierarchy .</sentence>
				<definiendum id="0">Basic Semantic Unit</definiendum>
				<definiendum id="1">BSU</definiendum>
				<definiens id="0">a leaf node in a semantic hierarchy</definiens>
			</definition>
			<definition id="7">
				<sentence>Breath length is defined as the typical number of words a human can speak comfortably without breathing .</sentence>
				<definiendum id="0">Breath length</definiendum>
				<definiens id="0">the typical number of words a human can speak comfortably without breathing</definiens>
			</definition>
			<definition id="8">
				<sentence>The following is the element definition for `` u.pro '' : &lt; ! ELEMENT u.pro- ( ( # PCDATAI phrase\ ] pause ) * ) &gt; ELEMENT is a reserved word for the element definition .</sentence>
				<definiendum id="0">ELEMENT</definiendum>
				<definiens id="0">a reserved word for the element definition</definiens>
			</definition>
			<definition id="9">
				<sentence>MAGIC is a system involving a large number of people at Columbia University .</sentence>
				<definiendum id="0">MAGIC</definiendum>
				<definiens id="0">a system involving a large number of people at Columbia University</definiens>
			</definition>
</paper>

		<paper id="0212">
			<definition id="0">
				<sentence>Here , the CIDE database gives the possible selectionai classes for head as body part , state , object , human or device ; for pupil as human or body part ; for question as communication or abstract .</sentence>
				<definiendum id="0">CIDE database</definiendum>
				<definiens id="0">gives the possible selectionai classes for head as body part , state , object , human or device ; for pupil as human or body part</definiens>
			</definition>
			<definition id="1">
				<sentence>Yarowsky , D. , 1994 , Decision Lists for Lexical Ambiguity Resolution : Application to Accent Restoration in Spanish and French , ACL Proceedings .</sentence>
				<definiendum id="0">Decision Lists</definiendum>
				<definiens id="0">for Lexical Ambiguity Resolution : Application to Accent Restoration in Spanish and French , ACL Proceedings</definiens>
			</definition>
</paper>

		<paper id="0321">
			<definition id="0">
				<sentence>The semantic space is a set of multidimensional real-valued vectors , which formally describe the contexts of words .</sentence>
				<definiendum id="0">semantic space</definiendum>
				<definiens id="0">a set of multidimensional real-valued vectors , which formally describe the contexts of words</definiens>
			</definition>
			<definition id="1">
				<sentence>Exemplar-based method makes use of typical contexts ( exemplars ) of a word sense , e.g. , verbnoun collocations or adjective-noun collocations , and identifies the correct sense of a word in a particular context by comparing the context with the exemplars ( Ng and Lee , 1996 ) .</sentence>
				<definiendum id="0">Exemplar-based method</definiendum>
				<definiens id="0">makes use of typical contexts ( exemplars ) of a word sense , e.g. , verbnoun collocations or adjective-noun collocations , and identifies the correct sense of a word in a particular context by comparing the context with the exemplars</definiens>
			</definition>
			<definition id="2">
				<sentence>Suppose S is the set of the mona-senses in the 189 I V l~i~k l~i~k semantic space , for any sense si~S , we create a preliminary node dj , and let Idjl=l , which denotes the number of senses related with d~ .</sentence>
				<definiendum id="0">Suppose S</definiendum>
				<definiens id="0">the set of the mona-senses in the 189 I V l~i~k l~i~k semantic space</definiens>
				<definiens id="1">the number of senses related with d~</definiens>
			</definition>
			<definition id="3">
				<sentence>Procedure Den-construct ( D ) begin i ) select dr and d2 among all in D , whose distance is the smallest ; ii ) merge dl and d2 into a new node d , and let Idl=l dl I+l de l ; iii ) remove dr and d2 from D , and put d into D ; iv ) compute the context vector of d based on the vectors of dl and d/ ; v ) go to i ) until there is only one node ; end ; Obviously , the algorithm is a bottom-up merging procedure .</sentence>
				<definiendum id="0">Procedure Den-construct</definiendum>
				<definiens id="0">a bottom-up merging procedure</definiens>
			</definition>
			<definition id="4">
				<sentence>In ( n-1 ) th step , where n is the number of word senses in S , a final node is produced .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of word senses in S , a final node is produced</definiens>
			</definition>
			<definition id="5">
				<sentence>So , in l_ &lt; i_ &lt; k , zi = ( \ [ d , \ ] e x , +1 d21y , ) /I d I. a linear composition of the vectors of dl and d2. 190 order to make out the sense clusters , we only need to determine the level. Unfortunately , the complexity of determining such a level is exponential to the edges in the dendrogram , which demonstrates that the problem is hard. So we adopt an heuristic strategy to determine an optimal level. Suppose T is the dendrogram , sub_T is the subtree of T , which takes the same root as T , we also use T and sub T to denote the sets of nonpreliminary nodes in T and in sub_T respectively , for any de T , let Wei ( d ) be the weight of the node d , we define an object function , as ( 5 ) : ( 5 ) ~ Wei ( d ) / d~sub T /sub_ 7~ Oby ( sub_T ) Wei ( d ) / de ( T-sub T ) / /JZub /* v.L is not a sense cluster */ else Tee-Tc ~ { v.L } ; /* v.L is a sense cluster */ if Obj ( sub T+v.R ) &gt; Obj ( sub T ) then Clustering ( v.R , sub T ) /* v.R is not a sense cluster */ else Tc¢-Tc u { v.R } ; /* v.R is a sense cluster */ end ; The algorithm is a depth-first search procedure .</sentence>
				<definiendum id="0">sub_T</definiendum>
				<definiendum id="1">object function</definiendum>
				<definiendum id="2">Wei</definiendum>
				<definiendum id="3">v.L</definiendum>
				<definiendum id="4">; /* v.R</definiendum>
				<definiens id="0">d , \ ] e x , +1 d21y , ) /I d I. a linear composition of the vectors of dl and d2. 190 order to make out the sense clusters</definiens>
				<definiens id="1">exponential to the edges in the dendrogram , which demonstrates that the problem is hard. So we adopt an heuristic strategy to determine an optimal level. Suppose T is the dendrogram</definiens>
				<definiens id="2">the subtree of T , which takes the same root as T , we also use T and sub T to denote the sets of nonpreliminary nodes in T and in sub_T respectively , for any de T , let Wei ( d ) be the weight of the node d</definiens>
				<definiens id="3">a sense cluster */ if Obj ( sub T+v.R ) &gt; Obj ( sub T ) then Clustering ( v.R , sub T ) /* v.R is not a sense cluster */ else Tc¢-Tc u { v.R }</definiens>
				<definiens id="4">a depth-first search procedure</definiens>
			</definition>
			<definition id="6">
				<sentence>Its complexity is O ( n ) , where n is the number of the leaf nodes in the dendrogram , i.e. , the number of the mono-sense words in the semantic space .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of the leaf nodes in the dendrogram , i.e. , the number of the mono-sense words in the semantic space</definiens>
			</definition>
			<definition id="7">
				<sentence>Suppose NCw be the set of all semantic codes of the words in the context , then cvw= &lt; x~ , x2 ... .. xp , where if c~eNC , , then x~=l ; otherwise x~=O. For any cluster clu in the space , let cvau be its context vector , we also define its distance from w based on the cosine of the angle between their context vectors as ( 6 ) . ( 6 ) disl ( clu , w ) =l-cos ( cvdu , cvw ) We say clu is activated , if disl ( clu , w ) .~dl , where dt is a threshold. Here we do n't define the activated cluster as the one which makes disl ( clu , w ) smallest , this is because that the context may contain much noise , and the senses in the cluster which makes disj ( clu , w ) smallest may not be similar with the very sense of the word in the context. To estimate a reasonable value for dl , we can compute the distance between the context vector of each mono-sense word occurrence in the corpus and the context vector of the cluster containing the word , then select a reasonable value ford1 based on these distances as the threshold. Suppose CLU is the set of all sense clusters in the space , O is the set of all occurrences of the mono-sense word in the corpus , for any weO , let cluw be the sense cluster containing the sense in the space , we compute all distances dist ( cluw , w ) , for all weO. It should be the case that most values for disl ( cluw , w ) will be smaller than a threshold , but some will be bigger , even close to 1 , this is because most contexts in which the monosense words occur would contain meaningful words for the senses , while other contexts contain much noise , and less words , even no words in the contexts are meaningful for the senses. When estimating the parameter di for the Chinese semantic space , we let n=5 , i.e. , we only take 5 words to the left or the right of a word as its context. Fig. 2 demonstrates the distribution of the values of disl ( cluw , w ) , where X axle denotes the 192 distance , and Y axle denotes the percent of the distances whose values are smaller than x~\ [ 0 , 1\ ] among all distances. We produce a function fix ) to model the distribution based on commonly used smoothing tools and locate its inflection point by settingf '' ( x ) =0. Finally we get x=0.378 , and let it be the threshold dr. ( 7 ) I { w , \ [ c sat ( c , clu ) = n We call ( 8 ) definition vector ofclu , denoted as dvd~. ( 8 ) dvau = &lt; sal ( cl , clu ) , sal ( c2 , clu ) ... .. sal ( ck , clu ) &gt; Given a word w in some context c , suppose CLU~ is the set of all the clusters in the semantic space activated by the context , the problem is to determine the correct sense of the word in the context , among all of its senses defined in the modem Chinese dictionary .</sentence>
				<definiendum id="0">w ) =l-cos</definiendum>
				<definiendum id="1">clu , w</definiendum>
				<definiendum id="2">dt</definiendum>
				<definiendum id="3">O</definiendum>
				<definiendum id="4">X axle</definiendum>
				<definiendum id="5">Y axle</definiendum>
				<definiens id="0">the set of all semantic codes of the words in the context</definiens>
				<definiens id="1">the cosine of the angle between their context vectors as ( 6 ) .</definiens>
				<definiens id="2">the activated cluster as the one which makes disl ( clu , w ) smallest , this is because that the context may contain much noise , and the senses in the cluster which makes disj ( clu , w ) smallest may not be similar with the very sense of the word in the context. To estimate a reasonable value for dl , we can compute the distance between the context vector of each mono-sense word occurrence in the corpus and the context vector of the cluster containing the word , then select a reasonable value ford1 based on these distances as the threshold. Suppose CLU is the set of all sense clusters in the space</definiens>
				<definiens id="3">the set of all occurrences of the mono-sense word in the corpus</definiens>
				<definiens id="4">most contexts in which the monosense words occur would contain meaningful words for the senses , while other contexts contain much noise , and less words , even no words in the contexts are meaningful for the senses. When estimating the parameter di for the Chinese semantic space</definiens>
				<definiens id="5">the left or the right of a word as its context. Fig. 2 demonstrates the distribution of the values of disl ( cluw , w )</definiens>
			</definition>
			<definition id="8">
				<sentence>Structured semantic space can be seen as a general model to deal with WSD problems , because it does n't concern any language-specific knowledge at all .</sentence>
				<definiendum id="0">Structured semantic</definiendum>
				<definiens id="0">a general model to deal with WSD problems</definiens>
			</definition>
</paper>

		<paper id="0902">
</paper>

		<paper id="1508">
			<definition id="0">
				<sentence>GWB provides a computational environment tailored especially for defining and testing grammars in the LFG formalism .</sentence>
				<definiendum id="0">GWB</definiendum>
				<definiens id="0">provides a computational environment tailored especially for defining and testing grammars in the LFG formalism</definiens>
			</definition>
			<definition id="1">
				<sentence>We constructed XLE around the same databaseplus-configuration model but adapted it to operate in the C/Unix world and to meet an additional set of user requirements .</sentence>
				<definiendum id="0">XLE</definiendum>
				<definiens id="0">around the same databaseplus-configuration model but adapted it to operate in the C/Unix world and to meet an additional set of user requirements</definiens>
			</definition>
			<definition id="2">
				<sentence>XLE provides a facility for constructing simple Addition transducers from lists of the desired input/output pairs : email : email +Nsg emails : email +Npl email : email +Vpres The relational composition operator is also quite useful , since it enables the output of the external transducer to be transformed into more suitable arrangements .</sentence>
				<definiendum id="0">XLE</definiendum>
				<definiens id="0">provides a facility for constructing simple Addition transducers from lists of the desired input/output pairs : email : email +Nsg emails : email +Npl email : email +Vpres The relational composition operator is also quite useful</definiens>
			</definition>
			<definition id="3">
				<sentence>Logically , the relationship between the effective finite-state tokenizer , which carries out all of the above functions , and the morphological analyzer can be defined as : tokenizer o \ [ morph analyzer @ \ ] * That is , the tokenizer , which inserts token boundaries ( © ) between tokens , is composed with a cyclic transducer that expects a © after each word .</sentence>
				<definiendum id="0">tokenizer</definiendum>
			</definition>
			<definition id="4">
				<sentence>The sublexical rule for combining English nouns with their inflectional suffixes is N -- &gt; N-BASE N-SFX Here the constraints for the N are simply the conjunction of the constraints for the base and suffix , and this rule represents the interpretation that is built in to the GWB system .</sentence>
				<definiendum id="0">rule</definiendum>
			</definition>
			<definition id="5">
				<sentence>XLE contains several mechanisms for reconciling external resources with grammar-specific lexical and syntactic requirements .</sentence>
				<definiendum id="0">XLE</definiendum>
				<definiens id="0">contains several mechanisms for reconciling external resources with grammar-specific lexical and syntactic requirements</definiens>
			</definition>
</paper>

		<paper id="0801">
			<definition id="0">
				<sentence>b ) Linking through an structured artificial language c ) Linking through one of the languages d ) Linking through an non-structured index The first option ( a ) is to pair-wise link the languages involved .</sentence>
				<definiendum id="0">) Linking</definiendum>
				<definiens id="0">an structured artificial language c</definiens>
			</definition>
			<definition id="1">
				<sentence>Each wordnet represents a language-internal system of synsets with semantic relations such as hyponymy , meronymy , cause , roles ( e.g. agent , patient , instrument , location ) .</sentence>
				<definiendum id="0">wordnet</definiendum>
				<definiens id="0">a language-internal system of synsets with semantic relations such as hyponymy , meronymy , cause , roles ( e.g. agent , patient , instrument</definiens>
			</definition>
			<definition id="2">
				<sentence>1990 `` Introduction to WordNet : An On-line Lexical Database , in : International Journal of Lexicography , Vol 3 , No.4 ( winter 1990 ) , 235-244 .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An On-line Lexical Database , in : International Journal of Lexicography</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>Stochastic categorial grammars ( SCGs ) are introduced as a more appropriate formalism for statistical language learners to estimate than stochastic context free grammars .</sentence>
				<definiendum id="0">Stochastic categorial grammars ( SCGs</definiendum>
				<definiens id="0">a more appropriate formalism for statistical language learners to estimate than stochastic context free grammars</definiens>
			</definition>
			<definition id="1">
				<sentence>Stochastic context free grammars ( SCFGs ) , which are standard context free grammars extended with a probabilistic interpretation of the generation of strings , have been shown to model some sources with hidden branching processes more efficiently than stochastic regular grammars ( Lari and Young , 1990 ) .</sentence>
				<definiendum id="0">Stochastic context free grammars ( SCFGs )</definiendum>
				<definiens id="0">which are standard context free grammars extended with a probabilistic interpretation of the generation of strings</definiens>
				<definiens id="1">shown to model some sources with hidden branching processes more efficiently than stochastic regular grammars</definiens>
			</definition>
			<definition id="2">
				<sentence>Stochastic categorial grammars ( SCGs ) , which are classical categorial grammars extended with a probabilistic component , by contrast , have a grammatical component that is naturally lexicalised .</sentence>
				<definiendum id="0">Stochastic categorial grammars</definiendum>
				<definiendum id="1">SCGs )</definiendum>
				<definiens id="0">classical categorial grammars extended with a probabilistic component , by contrast</definiens>
			</definition>
			<definition id="3">
				<sentence>Stochastic grammars ( of all varieties ) are usually estimated using the Maximum Likelihood Principle , which assumes an indifferent prior probability distribution .</sentence>
				<definiendum id="0">Stochastic grammars</definiendum>
				<definiendum id="1">Maximum Likelihood Principle</definiendum>
				<definiens id="0">assumes an indifferent prior probability distribution</definiens>
			</definition>
			<definition id="4">
				<sentence>statistical models An SCG is a classical categorial grammar ( one using just functional application , see , for example , Wood ( Wood , 1993 ) ) such that each category is augmented with a probability , which is used to model the choices made when constructing a parse .</sentence>
				<definiendum id="0">SCG</definiendum>
				<definiens id="0">a classical categorial grammar</definiens>
			</definition>
			<definition id="5">
				<sentence>• V is a non-empty set of lexical items ( words ) .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">a non-empty set of lexical items ( words )</definiens>
			</definition>
			<definition id="6">
				<sentence>A categorial grammar consists of a categorial lexicon augmented with the rule of left functional application : a b\a ~ b and the rule of right functional application : b/a a ~-+ b. A probabilistic categorial grammar is a categorial grammar such that the sum of the probabilities of all derivations is one .</sentence>
				<definiendum id="0">categorial grammar</definiendum>
			</definition>
			<definition id="7">
				<sentence>Bayesian inference forms the basis of many popular language learning systems , examples of which include the Baum-Welch algorithm for estimating hidden Markov models ( Baum , 1972 ) and the InsideOutside algorithm for estimating CFGs ( Baker , 1990 ) .</sentence>
				<definiendum id="0">Bayesian inference</definiendum>
				<definiens id="0">forms the basis of many popular language learning systems</definiens>
			</definition>
			<definition id="8">
				<sentence>The likelihood probability describes how well the training material can be encoded in the hypothesis .</sentence>
				<definiendum id="0">likelihood probability</definiendum>
				<definiens id="0">describes how well the training material can be encoded in the hypothesis</definiens>
			</definition>
			<definition id="9">
				<sentence>Learning can be viewed as compression of the training data in terms of a compact hypothesis .</sentence>
				<definiendum id="0">Learning</definiendum>
				<definiens id="0">compression of the training data in terms of a compact hypothesis</definiens>
			</definition>
			<definition id="10">
				<sentence>Let l ( H ) be the total length of the code words for some set of objects H , as assigned by some optimal coding scheme .</sentence>
				<definiendum id="0">Let l ( H )</definiendum>
				<definiens id="0">the total length of the code words for some set of objects H , as assigned by some optimal coding scheme</definiens>
			</definition>
			<definition id="11">
				<sentence>The length of a lexicon is the sum of the lengths of all the categories used in the grammar : l ( H ) = ~ -log ( P ( x ) ) ( 6 ) xEH 83 Stochastic Categorial Grammars The prior is therefore : P ( g ) = 2 -t ( H ) ( 7 ) The likelihood probability , P ( D \ [ H ) , is defined as simply the product of the probabilities of the categories used to parse the corpus .</sentence>
				<definiendum id="0">length of a lexicon</definiendum>
				<definiens id="0">the sum of the lengths of all the categories used in the grammar : l ( H ) = ~ -log ( P ( x ) ) ( 6 ) xEH 83 Stochastic Categorial Grammars The prior is therefore : P ( g</definiens>
				<definiens id="1">simply the product of the probabilities of the categories used to parse the corpus</definiens>
			</definition>
</paper>

		<paper id="1206">
			<definition id="0">
				<sentence>The LGM takes data as input and produces enriched text , i.e. , prosodically annotated text .</sentence>
				<definiendum id="0">LGM</definiendum>
				<definiens id="0">takes data as input and produces enriched text , i.e. , prosodically annotated text</definiens>
			</definition>
			<definition id="1">
				<sentence>In this section we present the rules that are used in the Prosody module of the LGM , which determines the location of accents and phrase boundaries in a generated sentence on the basis of both syntactic 40 `` De `` wedstrijd tussen `` PSV en `` Ajax / eindigde in `` @ een// '' @ drie/// '' Vijfentwintig duizend `` toeschouwers / bezochten het `` Philipsstadion /// `` Ajax ham na `` vijf `` minuten de `` leiding / door een `` treff~r van `` Kluivert/// '' Dertien minuten `` later / tier de aanvaller zijn `` tweede doelpunt aantekenen /// De 7o `` verdediger `` Blind / verzilverde in de `` drieentachtigste minuut een `` strafschop voor Ajax///Vlak voor het `` eindsignaal / bepaalde `` Nilis van `` PSV de `` eindstand / op `` @ een//- '' @ drie/// % `` Scheidsrechter van `` Dijk / `` leidde het duel /// '' Valckx van `` PSV kreeg een `` gele `` kaart/// Translation : The match between PSV and Ajax ended in 1Philips stadium .</sentence>
				<definiendum id="0">strafschop voor Ajax///Vlak voor het</definiendum>
				<definiens id="0">determines the location of accents</definiens>
			</definition>
			<definition id="2">
				<sentence>In our example , the accents launched by CP , IP and VP all coincide with the accent launched by the NP node dominating zijn tweede doelpunt , finally landing on the word tweede .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">all coincide with the accent launched by the NP node dominating zijn tweede doelpunt , finally landing on the word tweede</definiens>
			</definition>
			<definition id="3">
				<sentence>The LGM generates an orthographic representation which has a unique mapping to a phonetic representation .</sentence>
				<definiendum id="0">LGM</definiendum>
				<definiens id="0">generates an orthographic representation which has a unique mapping to a phonetic representation</definiens>
			</definition>
			<definition id="4">
				<sentence>A major phrase boundary triggers a pause and possibly a lengthening of the word preceding the boundary .</sentence>
				<definiendum id="0">major phrase boundary</definiendum>
				<definiens id="0">triggers a pause and possibly a lengthening of the word preceding the boundary</definiens>
			</definition>
</paper>

		<paper id="0412">
			<definition id="0">
				<sentence>This position paper sketches the author 's research in six areas related to speech translation : interactive disambiguation ; system architecture ; the interface between speech recognition and analysis ; the use of natural pauses for segmenting utterances ; dialogue acts ; and the tracking of lexical co-occurrences .</sentence>
				<definiendum id="0">dialogue</definiendum>
				<definiens id="0">interactive disambiguation ; system architecture ; the interface between speech recognition</definiens>
			</definition>
			<definition id="1">
				<sentence>The paper sketches work in six areas : interactive disambiguation ; system architecture ; the interface between speech recognition and analysis ; the use of natural pauses for segmenting utterances ; dialogue acts ; and the tracking of lexical co-occurrences .</sentence>
				<definiendum id="0">dialogue</definiendum>
				<definiens id="0">interactive disambiguation</definiens>
			</definition>
			<definition id="2">
				<sentence>A window is defined as a sequence of minimal segments , where a segment is typically a turn , but can also be a block delimited by suitable markers in the transcript .</sentence>
				<definiendum id="0">window</definiendum>
				<definiens id="0">a sequence of minimal segments , where a segment is typically a turn , but can also be a block delimited by suitable markers in the transcript</definiens>
			</definition>
			<definition id="3">
				<sentence>A weighted co-occurrence betweerf morphemes or lexemes can be viewed as an association between these itemsi so the set of co-occurrences which COOC discovers can be viewed as an associative or semantic network .</sentence>
				<definiendum id="0">weighted co-occurrence betweerf</definiendum>
				<definiens id="0">an associative or semantic network</definiens>
			</definition>
</paper>

		<paper id="0211">
			<definition id="0">
				<sentence>Lexical Acquisition ( LA ) processes strongly rely on basic assumptions embodied by the source information and training examples .</sentence>
				<definiendum id="0">Lexical Acquisition</definiendum>
				<definiens id="0">processes strongly rely on basic assumptions embodied by the source information and training examples</definiens>
			</definition>
			<definition id="1">
				<sentence>Tagging is a dynamic process that aims to produce a core semantic information to support several induction processes over the same domain .</sentence>
				<definiendum id="0">Tagging</definiendum>
				<definiens id="0">a dynamic process that aims to produce a core semantic information to support several induction processes over the same domain</definiens>
			</definition>
			<definition id="2">
				<sentence>The Lexical Knowledge base ( i.e. WordNet ) and the ( POS tagged ) source corpus axe used to select relevant words in each semantic class .</sentence>
				<definiendum id="0">Lexical Knowledge base</definiendum>
				<definiens id="0">the ( POS tagged ) source corpus axe used to select relevant words in each semantic class</definiens>
			</definition>
			<definition id="3">
				<sentence>Class-based models can be derived according to the tags appropriate in the corpus and used to derive lexical information according to generalized collocations .</sentence>
				<definiendum id="0">Class-based models</definiendum>
				<definiens id="0">the tags appropriate in the corpus and used to derive lexical information according to generalized collocations</definiens>
			</definition>
			<definition id="4">
				<sentence>We call these words w the salient words of a category C. We define the typicality Tw ( C ) of w in C , as : Tw ( C ) = N , c Nw ( 1 ) where : N~ is the total number of synsets of a word w , i.e. all the WordNet synonymy sets including w. N .</sentence>
				<definiendum id="0">typicality Tw</definiendum>
				<definiendum id="1">c Nw</definiendum>
				<definiens id="0">the total number of synsets of a word w</definiens>
			</definition>
			<definition id="5">
				<sentence>c is the number of synsets of w that belong to the semantic category C , i.e. synsets indexed with C in WordNet .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">the number of synsets of w that belong to the semantic category C , i.e. synsets indexed with C in WordNet</definiens>
			</definition>
			<definition id="6">
				<sentence>A typical verb for a category C is one that is either non ambiguously assigned to C in WordNet , or that has most of its senses ( syneets ) in C. The synonymy Sto of w in C , i.e. the degree of synonymy showed by words other than w in the synsets of the class C in which w appears , is modeled by the following ratio : S~ ( C ) = O~ , c o , ( 2 ) where : O~ is the number of words in the corpus that appear in at least one of the synsets of w. Ow , c is the number of words in the corpus appearing in at least one of the synsets of w , that belong to C. The synonymy depends both on WordNet and on the corpus .</sentence>
				<definiendum id="0">O~</definiendum>
				<definiens id="0">either non ambiguously assigned to C in WordNet , or that has most of its senses ( syneets ) in C. The synonymy Sto of w in C , i.e. the degree of synonymy showed by words other than w in the synsets of the class C in which w appears , is modeled by the following ratio : S~ ( C ) = O~ , c o</definiens>
				<definiens id="1">the number of words in the corpus that appear in at least one of the synsets of w. Ow , c is the number of words in the corpus appearing in at least one of the synsets of w</definiens>
			</definition>
			<definition id="7">
				<sentence>x T. ( C ) x S. ( C ) ( 3 ) where OAw are the absolute occurrences of w in the corpus .</sentence>
				<definiendum id="0">x T. ( C ) x S.</definiendum>
				<definiendum id="1">OAw</definiendum>
				<definiens id="0">the absolute occurrences of w in the corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>For a given verb or noun w , and for each category C , we evaluate the following function , that we call Domain Sense ( DSense ( w , C ) ) : k where Y ( k , c ) = c ) x Pr ( C ) ( 5 ) w~Ek where k 's are the contexts of w , and w I is a generic word in k. In ( 5 ) , Pr ( C ) is the ( not uniform ) probability of a class C , given by the ratio between the number of collective contexts for C 3 and the total number of collective contexts .</sentence>
				<definiendum id="0">w I</definiendum>
				<definiens id="0">the ( not uniform ) probability of a class C , given by the ratio between the number of collective contexts for C 3 and the total number of collective contexts</definiens>
			</definition>
			<definition id="9">
				<sentence>A recall ( shared classes ) of 41 % denotes a very high compression ( i.e. reduction in the number of senses ) with a corresponding precision of 82 % that indicate a good agreement between WordNet and the system classifications : many classes are pruned out ( lower recall ) but most of the remaining ones axe among the initial ones .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">a very high compression ( i.e. reduction in the number of senses</definiens>
			</definition>
			<definition id="10">
				<sentence>The WSD algorithm ( WSD-GODoT ) can be sketched as follows : I. Let k be a context of a noun/verb to in the source corpus and { Ci , C2 , ... , C , } be the set of domain specific classifications of w , as they have been pre-selected by C-GODoT ; sense , NCS , is given by : NCS ( k , w , Ci ) = Y ( k , Ci ) Pc , ( 6 ) where Y ( k , Ci ) is defined as in ( 5 ) , and # c , , ac~ are the mean and standard deviation of the Dsense ( w , Ci ) over the set of kernel words w in Ci .</sentence>
				<definiendum id="0">WSD algorithm</definiendum>
				<definiendum id="1">WSD-GODoT )</definiendum>
				<definiendum id="2">NCS</definiendum>
				<definiendum id="3"># c , , ac~</definiendum>
				<definiendum id="4">Dsense</definiendum>
				<definiens id="0">the mean and standard deviation of the</definiens>
			</definition>
			<definition id="11">
				<sentence>Information indeed is a typical abstraction that can be catalogued .</sentence>
				<definiendum id="0">Information indeed</definiendum>
				<definiens id="0">a typical abstraction that can be catalogued</definiens>
			</definition>
</paper>

		<paper id="0312">
			<definition id="0">
				<sentence>The client interface is an enhancement of a manual annotation tool .</sentence>
				<definiendum id="0">client interface</definiendum>
				<definiens id="0">an enhancement of a manual annotation tool</definiens>
			</definition>
			<definition id="1">
				<sentence>The client consists of a tagging tool interface written in Tk/Tcl , a cross-platform GUI scripting language .</sentence>
				<definiendum id="0">client</definiendum>
				<definiens id="0">consists of a tagging tool interface written in Tk/Tcl , a cross-platform GUI scripting language</definiens>
			</definition>
			<definition id="2">
				<sentence>When RoboTag processes a tagged training text , it creates labeled feature vectors ( called tuples ) from the preprocessor data .</sentence>
				<definiendum id="0">RoboTag</definiendum>
				<definiens id="0">processes a tagged training text , it creates labeled feature vectors ( called tuples ) from the preprocessor data</definiens>
			</definition>
			<definition id="3">
				<sentence>To resolve these cases , RoboTag uses a static tag priority scheme .</sentence>
				<definiendum id="0">RoboTag</definiendum>
				<definiens id="0">uses a static tag priority scheme</definiens>
			</definition>
			<definition id="4">
				<sentence>They report their best precision/recall results for machine-learned rules on the MUC-6 task with equivalent F-Measures 4 of 78.50 ZF-measure is calculated by : F= ( fl2+l.O ) xPxR fl~ xP+R where P is precision , R is recall , and fl is the relative importance given to recall over precision .</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">fl</definiendum>
				<definiens id="0">the relative importance given to recall over precision</definiens>
			</definition>
			<definition id="5">
				<sentence>RoboTag is a multilingual text extraction system that automatically learns to tag texts by observing its users .</sentence>
				<definiendum id="0">RoboTag</definiendum>
				<definiens id="0">a multilingual text extraction system that automatically learns to tag texts by observing its users</definiens>
			</definition>
</paper>

		<paper id="0510">
			<definition id="0">
				<sentence>ILLICO combines two principles : modularity in the representation of knowledge defined at the different levels of language processing , and sentence composition using partial synthesis and guided composition .</sentence>
				<definiendum id="0">ILLICO</definiendum>
				<definiens id="0">combines two principles : modularity in the representation of knowledge defined at the different levels of language processing , and sentence composition using partial synthesis and guided composition</definiens>
			</definition>
			<definition id="1">
				<sentence>The ILLICO system is a generic system for natural language processing ( NLP ) .</sentence>
				<definiendum id="0">ILLICO system</definiendum>
			</definition>
			<definition id="2">
				<sentence>ILLICO has been designed from the following two principles : defined at the different levels of language processing ( lexical , syntactic , semantic , conceptual , contextual levels ) ; and guided composition .</sentence>
				<definiendum id="0">ILLICO</definiendum>
				<definiens id="0">designed from the following two principles : defined at the different levels of language processing ( lexical , syntactic , semantic , conceptual , contextual levels</definiens>
			</definition>
			<definition id="3">
				<sentence>The guided composition mode enables the development of user-friendly interfaces in which errors on the domain of the application never occur , and in which non-expected ( i.e. incorrect ) expressions are never used ( Pasero and Sabatier , 1997 ) ( Pasero and Sabatier , 1994 ) ( Milhaud , 1994 ) ( Godbert et al. , 1993 ) .</sentence>
				<definiendum id="0">guided composition mode</definiendum>
				<definiens id="0">enables the development of user-friendly interfaces in which errors on the domain of the application never occur , and in which non-expected</definiens>
			</definition>
			<definition id="4">
				<sentence>Pictures are a medium for language , and allow a child to enter a world by playing .</sentence>
				<definiendum id="0">Pictures</definiendum>
				<definiens id="0">a medium for language , and allow a child to enter a world by playing</definiens>
			</definition>
			<definition id="5">
				<sentence>At higher levels of difficulty , the use of relative clauses is allowed and an object can be designated by its position ( the circle which is in the square A3 ) ; plurals ( the circles ) and the generic word pawn are also allowed .</sentence>
				<definiendum id="0">plurals</definiendum>
				<definiens id="0">the circle which is in the square A3</definiens>
			</definition>
</paper>

		<paper id="1314">
			<definition id="0">
				<sentence>Various knowledge sources have been used for anaphora resolution , leading to more or less realistic systems .</sentence>
				<definiendum id="0">Various knowledge sources</definiendum>
				<definiens id="0">used for anaphora resolution , leading to more or less realistic systems</definiens>
			</definition>
			<definition id="1">
				<sentence>The representation of a character C consists of a set of facets .</sentence>
				<definiendum id="0">representation of a character C</definiendum>
				<definiens id="0">consists of a set of facets</definiens>
			</definition>
			<definition id="2">
				<sentence>The reference resolution mechanism consists in the interaction of two modules ( namely M1 and M2 , cf. §2 ) .</sentence>
				<definiendum id="0">reference resolution mechanism</definiendum>
				<definiens id="0">consists in the interaction of two modules ( namely M1 and M2 , cf. §2 )</definiens>
			</definition>
			<definition id="3">
				<sentence>When MI processes a pronominal RE , it uses `` salience value '' criteria ( cf. ( Lappin and Leass , 1994 ) and ( Huis , 1995 ) ) , intertwined with morpho-syntaxic constraints ( and later semantic ones ) , in order to choose a character from the set as referent of the RE .</sentence>
				<definiendum id="0">MI</definiendum>
				<definiens id="0">intertwined with morpho-syntaxic constraints ( and later semantic ones ) , in order to choose a character from the set as referent of the RE</definiens>
			</definition>
</paper>

		<paper id="0305">
			<definition id="0">
				<sentence>each word ( stage 2 ) Hearst treats a text more or less as a bag of words in its statistical analysis .</sentence>
				<definiendum id="0">Hearst</definiendum>
				<definiens id="0">treats a text more or less as a bag of words in its statistical analysis</definiens>
			</definition>
			<definition id="1">
				<sentence>Function words ( for example determiners , auxiliary verbs etc. ) support and coordinate the combination of content words into meaningful sentences .</sentence>
				<definiendum id="0">Function words</definiendum>
				<definiens id="0">auxiliary verbs etc. ) support and coordinate the combination of content words into meaningful sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>In her implementation , Hearst attempts to do this by having a finite list of problematic words that are filtered out from the text before the statistical analysis takes place ( Hearst , 1994 ) .</sentence>
				<definiendum id="0">Hearst</definiendum>
				<definiens id="0">attempts to do this by having a finite list of problematic words that are filtered out from the text before the statistical analysis takes place</definiens>
			</definition>
			<definition id="3">
				<sentence>, will be used for the characterisation of two closely related but distinct phenomena : ( a ) document-level burstiness , i.e. multiple occurrence of a content word or phrase in a single text document , which is contrasted with the fact that most other documents contain no other instances of this word or phrase at all ; and ( b ) within-document burstiness ( or burstiness proper ) , i.e. close proximity of all or some individual instances of a content word or phrase within a document exhibiting multiple occurrence . ''</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiendum id="1">within-document burstiness</definiendum>
				<definiens id="0">a ) document-level burstiness , i.e. multiple occurrence of a content word or</definiens>
			</definition>
			<definition id="4">
				<sentence>W is the total number of words in the text .</sentence>
				<definiendum id="0">W</definiendum>
			</definition>
			<definition id="5">
				<sentence>w is the number of occurrences of the word like x. n is the number of nearest neighbours to include in the calculation and depends on the overall frequency of the word in the text .</sentence>
				<definiendum id="0">w</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of occurrences of the word like x.</definiens>
				<definiens id="1">the number of nearest neighbours to include in the calculation and depends on the overall frequency of the word in the text</definiens>
			</definition>
			<definition id="6">
				<sentence>This means that a highly significant word occurring only in A has exactly the same effect as an insignificant word occurring only in A. In other words the significance biasing is only taking place for words that appear in both A and B. Therefore , the formula actually used is : Correspondence= L~I ~-~ `` k I-~P-~I 2 where A '' is the subset of A which contains only those words that occur in A and not in B. Similarly , B ~ is the subset of B which contains only those words that occur in B and not in A. This is shown in Figure 4 .</sentence>
				<definiendum id="0">B ~</definiendum>
				<definiens id="0">the subset of A which contains only those words that occur in A</definiens>
				<definiens id="1">the subset of B which contains only those words that occur in B</definiens>
			</definition>
</paper>

		<paper id="1513">
			<definition id="0">
				<sentence>nl Hdrug is an environment to develop grammars , parsers and generators for natural languages .</sentence>
				<definiendum id="0">nl Hdrug</definiendum>
				<definiens id="0">an environment to develop grammars , parsers and generators for natural languages</definiens>
			</definition>
			<definition id="1">
				<sentence>Hdrug is an environment to develop grammars , parsers and generators for natural languages .</sentence>
				<definiendum id="0">Hdrug</definiendum>
				<definiens id="0">an environment to develop grammars , parsers and generators for natural languages</definiens>
			</definition>
			<definition id="2">
				<sentence>• Graph ( plots of two variable data ) , e.g. to display the ( average ) cputime or memory requirements of different parsers .</sentence>
				<definiendum id="0">Graph</definiendum>
				<definiens id="0">plots of two variable data</definiens>
			</definition>
			<definition id="3">
				<sentence>Hdrug provides an interface for the definition of parsers and generators .</sentence>
				<definiendum id="0">Hdrug</definiendum>
				<definiens id="0">provides an interface for the definition of parsers and generators</definiens>
			</definition>
			<definition id="4">
				<sentence>To quote the authors : ALE is an integrated phrase structure parsing and definite clause logic programming system in which the terms are typed feature structures .</sentence>
				<definiendum id="0">ALE</definiendum>
				<definiens id="0">an integrated phrase structure parsing and definite clause logic programming system in which the terms are typed feature structures</definiens>
			</definition>
			<definition id="5">
				<sentence>The combined ALE/Hdrug system consists of the original ALE sources plus about 450 lines of Prolog code and 250 lines of Tcl code .</sentence>
				<definiendum id="0">ALE/Hdrug system</definiendum>
				<definiens id="0">consists of the original ALE sources plus about 450 lines of Prolog code and 250 lines of Tcl code</definiens>
			</definition>
			<definition id="6">
				<sentence>The Hdrug window consists of two large canvases which are used to display important data-structures .</sentence>
				<definiendum id="0">Hdrug window</definiendum>
				<definiens id="0">consists of two large canvases which are used to display important data-structures</definiens>
			</definition>
			<definition id="7">
				<sentence>button includes options to load grammar files , Prolog files and Tcl/Tk files .</sentence>
				<definiendum id="0">button</definiendum>
				<definiens id="0">includes options to load grammar files , Prolog files and Tcl/Tk files</definiens>
			</definition>
			<definition id="8">
				<sentence>The NWO Priority Programme Language and Speech Technology is a research programme aiming at the development of spoken language information systems .</sentence>
				<definiendum id="0">NWO Priority Programme Language</definiendum>
				<definiens id="0">a research programme aiming at the development of spoken language information systems</definiens>
			</definition>
</paper>

		<paper id="0313">
			<definition id="0">
				<sentence>In the UMass/MUC-4 information extraction system ( Lehnert et al. , 1992 ) , the words ammunition and bullets were defined as weapons , mainly for the purpose of selectional restrictions .</sentence>
				<definiendum id="0">UMass/MUC-4 information extraction system</definiendum>
				<definiens id="0">Lehnert et al. , 1992 ) , the words ammunition and bullets were defined as weapons , mainly for the purpose of selectional restrictions</definiens>
			</definition>
</paper>

		<paper id="0203">
			<definition id="0">
				<sentence>Minnesota Contextual Content Analysis ( MCCA ) is a technique for characterizing the concepts and themes occurring in text ( sentences , paragraphs , interview transcripts , books ) .</sentence>
				<definiendum id="0">MCCA )</definiendum>
				<definiens id="0">a technique for characterizing the concepts and themes occurring in text ( sentences , paragraphs , interview transcripts , books )</definiens>
			</definition>
			<definition id="1">
				<sentence>Unlike other content analysis techniques ( or classification techniques used for measuring the distance between documents in information retrieval ) , MCCA uses the non-agglomerative technique of multidimensional sealing ( MDS ) .</sentence>
				<definiendum id="0">MCCA</definiendum>
				<definiens id="0">uses the non-agglomerative technique of multidimensional sealing ( MDS )</definiens>
			</definition>
			<definition id="2">
				<sentence>Introduction to WordNet : An on-line lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0504">
			<definition id="0">
				<sentence>Profet , a word prediction program , has been in use for the last ten years as a writing aid , and was designed to accelerate the writing process and minimize the writing effort for persons with motor dysfunction .</sentence>
				<definiendum id="0">Profet</definiendum>
				<definiens id="0">a writing aid , and was designed to accelerate the writing process and minimize the writing effort for persons with motor dysfunction</definiens>
			</definition>
			<definition id="1">
				<sentence>Profet is a statistically based adaptive word prediction program and is used as an aid in writing by individuals with motoric and/or linguistic disabilities , e.g. , mild aphasia and dyslexia ( Hunnicutt , 1986 ) , ( Hunnicutt , 1989a ) .</sentence>
				<definiendum id="0">Profet</definiendum>
				<definiens id="0">a statistically based adaptive word prediction program and is used as an aid in writing by individuals with motoric and/or linguistic disabilities</definiens>
			</definition>
			<definition id="2">
				<sentence>In summary , the results of this first study indicate that a ) there was most often a reduction of keystrokes , which meant less effort ; b ) a reduction in the number of keystrokes did not necessarily mean a savings in time ; c ) the writing strategy had to be changed due to a higher cognitive load on the writing process , i.e. , the time-saving gained by fewer keystrokes was consumed by longer time looking for the right alternative , which involved shifting one 's gaze from the keyboard to the screen and back to the keyboard , then having to make a decision and hit the right key ; d ) speed was not the most important aspect to the user , but the effort-saving ( as typing is often very laborious for a person with a motor impairment ; one comment was : `` I get less exhausted when I write with Profet '' ) , and the possibility of producing more correct texts ; e ) the written texts were often better spelled and , on the whole , had a better linguistic structure , which was an unexpected , positive finding ; f ) a typical Profet error that occurred was when the subject chose an incorrect prediction ( This type of error , where the word is spelled correctly but completely unrelated to the context , gives the text a bizarre look , and the text actually ends up being more unintelligible than if the word had merely been misspelled .</sentence>
				<definiendum id="0">i.e.</definiendum>
				<definiens id="0">a higher cognitive load on the writing process ,</definiens>
			</definition>
			<definition id="3">
				<sentence>For instance , the lower keystroke savings in Swedish compared to English might be explained in part by the fact that compounding ( the formation of a new word , i.e. , string , through the concatenation of two or more words ) is a highly productive word creation strategy in Swedish , but not in English .</sentence>
				<definiendum id="0">compounding</definiendum>
				<definiens id="0">the formation of a new word , i.e. , string , through the concatenation of two or more words</definiens>
			</definition>
</paper>

		<paper id="1311">
			<definition id="0">
				<sentence>A management succession event ( as used in MUC-6 ) may involve the two separate events of a corporate position being vacated by one person and then filled by another .</sentence>
				<definiendum id="0">management succession event</definiendum>
				<definiens id="0">used in MUC-6 ) may involve the two separate events of a corporate position being vacated by one person</definiens>
			</definition>
</paper>

		<paper id="1310">
			<definition id="0">
				<sentence>XANADU is an interactive tool which allows an analyst to rapidly introduce cohesion annotations into corpus texts .</sentence>
				<definiendum id="0">XANADU</definiendum>
				<definiens id="0">an interactive tool which allows an analyst to rapidly introduce cohesion annotations into corpus texts</definiens>
			</definition>
			<definition id="1">
				<sentence>The UCREL Anaphoric Treebank This treebank consists of 100,000 words of morphosyntactically-annotated Associated The UCREL annotation scheme scores very highly in terms of granularity of analysis it is possible to mark a wide range of cohesive phenomena using the scheme .</sentence>
				<definiendum id="0">UCREL Anaphoric Treebank This treebank</definiendum>
				<definiens id="0">consists of 100,000 words of morphosyntactically-annotated Associated The UCREL annotation scheme scores very highly in terms of granularity of analysis it is possible to mark a wide range of cohesive phenomena using the scheme</definiens>
			</definition>
			<definition id="2">
				<sentence>Also , each annotation string contains a short phrase describing the current topic for the segment or subsegment under analysis .</sentence>
				<definiendum id="0">annotation string</definiendum>
				<definiens id="0">contains a short phrase describing the current topic for the segment or subsegment under analysis</definiens>
			</definition>
			<definition id="3">
				<sentence>It % 4677 99.91 % 18 l 0.02 % 4678 99.94 % 19 2 0.04 % 4680 99.98 % 21 1 0.02 % 4681 100.00 % Key to table : A is numbers of intervening sentence boundaries , B is number of occurrences , C is rate of occurrences , D is the sum of occurrences to that point and E is rate of sum .</sentence>
				<definiendum id="0">D</definiendum>
				<definiendum id="1">E</definiendum>
				<definiens id="0">numbers of intervening sentence boundaries , B is number of occurrences</definiens>
				<definiens id="1">the sum of occurrences to that point</definiens>
			</definition>
			<definition id="4">
				<sentence>In S P Botley , J Glass , A M McEnery and A Wilson ( eds ) , Approaches to Discourse Anaphora : Proceedings of the Discourse Anaphora and Resolution Colloquium ( DAARC96 ) .</sentence>
				<definiendum id="0">M McEnery</definiendum>
				<definiendum id="1">Wilson</definiendum>
			</definition>
			<definition id="5">
				<sentence>In S.P. Botley and A.M. McEnery ( eds ) Corpus-Based and Computational Approaches to Discourse Anaphora , UCL Press , ( forthcoming ) \ [ Garside 1993\ ] R. Garside , The Marking of Cohesive Relationships : Tools for the Construction of a Large Bank of Anaphoric Data .</sentence>
				<definiendum id="0">McEnery</definiendum>
				<definiens id="0">Tools for the Construction of a Large Bank of Anaphoric Data</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>A word trigger pair is defined as a long-distance word pair .</sentence>
				<definiendum id="0">word trigger pair</definiendum>
				<definiens id="0">a long-distance word pair</definiens>
			</definition>
			<definition id="1">
				<sentence>The criterion for measuring the quality of a language model p ( Wlh ) is the so-called log-likelihood criterion ( Ney and Essen , 1994 ) , which for a corpus Wl , ... , wn , ... wN is defined by : F N ~= y~logp ( wn\ [ hn ) , rt-~ -- 1 According to this definition , the log-likelihood criterion measures for each position n how well the language model can predict the next word given the knowledge about the preceeding words and computes an average over all word positions n. In the context of language modeling , the log-likelihood criterion F is converted to perplexity PP , defined by PP : = -FIN .</sentence>
				<definiendum id="0">Wlh )</definiendum>
				<definiendum id="1">log-likelihood criterion</definiendum>
				<definiens id="0">measuring the quality of a language model p (</definiens>
				<definiens id="1">the so-called log-likelihood criterion ( Ney and Essen , 1994 ) , which for a corpus Wl , ... , wn , ... wN is defined by : F N ~= y~logp ( wn\ [ hn )</definiens>
			</definition>
			<definition id="2">
				<sentence>The framework of the EM algorithm is based on the so-called Q ( # ; ~ ) function , where ~ is the new estimate obtained from the previous estimate / .</sentence>
				<definiendum id="0">~</definiendum>
				<definiens id="0">the new estimate obtained from the previous estimate /</definiens>
			</definition>
			<definition id="3">
				<sentence>l a ) language model training corpus 104.9 \ ] 92.1 88.5 I 87.4 trigram with no cache 255.1 168.4 trigram with cache 200.0 138.9 I -ttriggers : no EM 183.2 129.8 + triggers : with EM 179.0 127.2 b ) +triggers : noEM .83/.11/.06 .86/.09/.05 .89/.08/.04 +triggers : withEM .82/.10/.09 .85/.09/.07 .86/.07/.07 where ( ~ ( w , v ) = 1 if and only if v = w. The trigger model PT ( Wn Ihn ) is defined as : M 1 pT ( Wn\ [ W~I ) a ( Wn\ [ Wn -- m ) M 2. , rn -- -- 1 There were two me~hods used to compute the trigger parameters : • method 'no : EM ' : The trigger parameters cr ( w\ [ v ) are obtained by renormalization from the single trigger parameters q ( wlv ) : q ( wlv ) ~ ( wlv ) ~q ( w'lv ) The backing-off method described in Section 2.1 was used to select the top-K most significant single trigger pairs .</sentence>
				<definiendum id="0">trigger model PT ( Wn Ihn</definiendum>
				<definiendum id="1">trigger parameters cr</definiendum>
				<definiendum id="2">single trigger parameters q</definiendum>
				<definiens id="0">l a ) language model training corpus 104.9 \ ] 92.1 88.5 I 87.4 trigram with no cache 255.1 168.4 trigram with cache 200.0 138.9 I -ttriggers : no EM 183.2 129.8 + triggers : with EM 179.0 127.2 b ) +triggers : noEM .83/.11/.06 .86/.09/.05 .89/.08/.04 +triggers</definiens>
			</definition>
			<definition id="4">
				<sentence>/ , From the table it can be seen that for the no EM trigger pairs the trigger parameter oL ( wlv ) varies only slightly over the triggered words w. This is different for the EM triggers , where the trigger parameters o~ ( wlv ) have a much larger variation .</sentence>
				<definiendum id="0">EM trigger</definiendum>
				<definiens id="0">pairs the trigger parameter oL ( wlv ) varies only slightly over the triggered words w. This is different for the EM triggers</definiens>
			</definition>
</paper>

		<paper id="0402">
			<definition id="0">
				<sentence>Sentence Type \ [ Assert YN-Quest WH-Quest Imperative Main-Verb t PV PA FRAG LEXEME Aux-Verb I Clue-Word I Must t yey Want aniyo Intent kulemyen Possible ... Serve Serve_to May Intend Figure 1 : A Syntactic Pattern P ( UilUt , U2 , ... , U i-l ) means the probability that Ui will be uttered given a sequence of utterances U1 , U2 , ... , Ui-1 .</sentence>
				<definiendum id="0">U i-l )</definiendum>
				<definiens id="0">the probability</definiens>
			</definition>
			<definition id="1">
				<sentence>• MainVerb is the type of the main verb in the utterance .</sentence>
				<definiendum id="0">MainVerb</definiendum>
				<definiens id="0">the type of the main verb in the utterance</definiens>
			</definition>
			<definition id="2">
				<sentence>PA is used when the main verb represents a slate and PV for the verbs of type 11 Table 1 : A part of the syntactic patterns extracted from corpus Speech Act Sentence Type MainVerb AuxVerb Clue Word Request-Act Imperative PV Request None Request-Act YN-Quest PV Possible None Request-Act Assert PV Want None Ask-Ref WH-Quest PV None None Ask-Ref YN-Quest PJ None None Ask-Ref Imperative malhata Request None Inform Assert PJ None None Inform Assert PV None None Request-Conf YN-Quest PJ None None Request-Conf YN-Quest FRAG None None Response Assert PJ None yey Suggest Wh-Quest PV Serve None event or action .</sentence>
				<definiendum id="0">PV</definiendum>
				<definiens id="0">A part of the syntactic patterns extracted from corpus Speech Act Sentence Type MainVerb AuxVerb Clue Word Request-Act Imperative PV Request None Request-Act YN-Quest PV Possible None Request-Act Assert PV Want None Ask-Ref WH-Quest PV None None Ask-Ref YN-Quest PJ None None Ask-Ref Imperative malhata Request None Inform Assert PJ None None Inform Assert PV None None Request-Conf YN-Quest PJ None None Request-Conf YN-Quest FRAG None None Response Assert PJ None yey Suggest Wh-Quest PV Serve None event or action</definiens>
			</definition>
			<definition id="3">
				<sentence>( 4 ) S , where Si is a possible speech act for the utterance Ui .</sentence>
				<definiendum id="0">Si</definiendum>
			</definition>
			<definition id="4">
				<sentence>DS is an index that represents the hierarchical structure of discourse .</sentence>
				<definiendum id="0">DS</definiendum>
				<definiens id="0">an index that represents the hierarchical structure of discourse</definiens>
			</definition>
</paper>

		<paper id="0103">
</paper>

		<paper id="0613">
			<definition id="0">
				<sentence>Currently , the best speaker-independent continuous speech recognition ( SR ) is orders of magnitude weaker than a human native speaker in recognizing arbitrary sequences of words .</sentence>
				<definiendum id="0">SR</definiendum>
				<definiens id="0">orders of magnitude weaker than a human native speaker in recognizing arbitrary sequences of words</definiens>
			</definition>
</paper>

		<paper id="0709">
			<definition id="0">
				<sentence>s e , the window to consider when extracting words related to word w , should span from postttuon w-5 to w+5 Maarek also defines the resolwng power of a parr m a document d as P = ~'Pd log Pc where Pd is the observed probabshty of appearance of the pan '' m document d , Pc the observed probabdny of the pmr recorpus , and -log Pc the quantity of mformauon assocmted to the pmr It Is easdy seen that p wall be h|gher , the higher the frequency of the pmr m the document and the lower sts frequency m the corpus , which agrees wlth the sdea presented at the begmnmg of this sectton Church and Hanks ( 1990 ) propose the apphcatlon of the concept of mutual mformatton e ( x , y ) ~ , ( x.y ) = hog2 ecx ) e ( y ) 51 to the retrieval , ro a corpus , of pairs of lextcally related words They alsoconslder a word span of : e5 words and observe that `` roterestrog '' pmr , s generally present a mutual mformatxon above 3 Salton and .</sentence>
				<definiendum id="0">Pd</definiendum>
				<definiens id="0">the observed probabshty of appearance of the pan '' m document d , Pc the observed probabdny of the pmr recorpus , and -log Pc the quantity of mformauon assocmted to the pmr It Is easdy seen that p wall be h|gher , the higher the frequency of the pmr m the document and the lower sts frequency m the corpus , which agrees wlth the sdea presented at the begmnmg of this sectton Church and Hanks ( 1990 ) propose the apphcatlon of the concept of mutual mformatton e ( x , y ) ~</definiens>
			</definition>
			<definition id="1">
				<sentence>I i I i 1 I The base corpus was uuually bruit vath news from Lusa news agency , m a total of 216 319 words Later , news from `` 0 P6bllco '' newspaper ( about 90 000 w~ds ) and more news from Lusa were added , and the total reached 537 085 words The consequences of tins enlargement will be chscussed m the next secUon Experunents were made vath 10 articles from `` O Pdbhco '' , that chd n't belong to the corpus Both the corpus and the documents were subjected to a very elementary pre-processmg , wluch basically 6onslsted of • convemng all uppercase letters to lowercase * convemng all numbers to NUMERO ( NUMBER ) 3 • ehmmaUng all non-letter characters Words or co-occurrences not present m the corpus , if occumng m a document , would lead , respectively m the computatlon of mutual mformatlon or resolwng power , to ¢hwdmg by 0 or to log2 0 To prevent sltuatton , in such cases , and only for calculatlon purposes , the document is added to the corpus By doing so , though , the mutual mformatmn becomes overestamated For instance , the parr \ [ ha eslav6ma\ ] ( m slavoma ) occurs 3 tnnes in an article As eslav6ma does n't occur m the corpus , the artacle m hdded to the corpus , for calculatmn purposes only concernmg tlus pair The result is the presuppositmn that , despite the qmte low frequencies of eslav6ma and \ [ na eslav6ma\ ] , almost every tune the word eslav6ma occurs it IS preceded by ha , the mutual mfc~naUon of the parr being then artificially raised To overcome this overest~maUon , 2 adthUonal mutual mformauon thresholds were defined *tf one of the words ( or both ) does n't occur m the cOrpus , it must be I ( x , y ) &gt; 10 , • .</sentence>
				<definiendum id="0">ehmmaUng all non-letter</definiendum>
				<definiens id="0">m a total of 216 319 words Later , news from `` 0 P6bllco '' newspaper ( about 90 000 w~ds ) and more news from Lusa were added</definiens>
				<definiens id="1">a document , would lead , respectively m the computatlon of mutual mformatlon or resolwng power , to ¢hwdmg by 0 or to log2 0 To prevent sltuatton</definiens>
				<definiens id="2">tune the word eslav6ma occurs it IS preceded by ha , the mutual mfc~naUon of the parr being then artificially raised To overcome this overest~maUon , 2 adthUonal mutual mformauon thresholds were defined *tf one of the words</definiens>
			</definition>
</paper>

		<paper id="0315">
			<definition id="0">
				<sentence>Name searching is a term that has been used in a variety of ways .</sentence>
				<definiendum id="0">Name searching</definiendum>
				<definiens id="0">a term that has been used in a variety of ways</definiens>
			</definition>
			<definition id="1">
				<sentence>Name recognition is the precess of identifying that a given character string is in fact a name .</sentence>
				<definiendum id="0">Name recognition</definiendum>
				<definiens id="0">the precess of identifying that a given character string is in fact a name</definiens>
			</definition>
			<definition id="2">
				<sentence>Information retrieval differs from both of these types of applications , because it has neither the structure provided by a database record , nor the linguistic depth or domain knowledge representation of the natural language understanding system .</sentence>
				<definiendum id="0">Information retrieval</definiendum>
				<definiens id="0">the linguistic depth or domain knowledge representation of the natural language understanding system</definiens>
			</definition>
			<definition id="3">
				<sentence>Name searching can be defined as the process of using a name as part of a query in order to retrieve information associated with that name in a database .</sentence>
				<definiendum id="0">Name searching</definiendum>
				<definiens id="0">the process of using a name as part of a query in order to retrieve information associated with that name in a database</definiens>
			</definition>
</paper>

		<paper id="0410">
			<definition id="0">
				<sentence>JANUS is a multi-lingual speech-to-speech translation system , which has been designed to translate spontaneous spoken language in a limited domain .</sentence>
				<definiendum id="0">JANUS</definiendum>
				<definiens id="0">a multi-lingual speech-to-speech translation system , which has been designed to translate spontaneous spoken language in a limited domain</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>Collins uses a reduced sentence in which every basic noun phrase ( i.e. , a noun phrase that has no noun phrase as a child ) is reduced to its headword .</sentence>
				<definiendum id="0">Collins</definiendum>
				<definiens id="0">uses a reduced sentence in which every basic noun phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>Table 1 : Dependencies for the sentence John Smith works fast dependent word head word relation John Smith NP ( proper noun ) ( proper noun ) Smith works NP S VP ( proper noun ) fast ( adverb ) ( verb ) works VP ( verb ) Words The next step we take , is eliminating one of the two words in this table of dependencies .</sentence>
				<definiendum id="0">NP S VP</definiendum>
				<definiens id="0">Dependencies for the sentence John Smith works fast dependent word head word relation John Smith NP ( proper noun</definiens>
			</definition>
			<definition id="2">
				<sentence>We consider the following distributions : p ( R , talwdt~ ) ( 1 ) p ( R , tdlWhth ) ( 2 ) where R indicates the triple representing the syntactic relation , Wd a dependent word that modifies headword Wh , and td and th their respective part of speech tags .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">indicates the triple representing the syntactic relation , Wd a dependent word that modifies headword Wh , and td and th their respective part of speech tags</definiens>
			</definition>
			<definition id="3">
				<sentence>The word Rep. is the abbreviation of Republic , and obviously occurs mainly in names of countries .</sentence>
				<definiendum id="0">word Rep.</definiendum>
				<definiens id="0">the abbreviation of Republic , and obviously occurs mainly in names of countries</definiens>
			</definition>
</paper>

		<paper id="0414">
</paper>

		<paper id="0507">
</paper>

		<paper id="0508">
			<definition id="0">
				<sentence>1 ASL is a visual-gestural language whose grammar is distinct and independent of the grammar 1While we recognize that many people who are deaf or hard of hearing use other communication systems , our 47 / of English or any other spoken language ( Stokoe , Jr. , 1960 ) , ( Baker and Padden , 1978 ) , ( Baker and Cokely , 1980 ) , ( Hoffmeister and Shettle , 1983 ) , ( Klima and Bellugi , 1979 ) , ( Bellman , Poizner , and Bellugi , 1983 ) .</sentence>
				<definiendum id="0">ASL</definiendum>
				<definiens id="0">a visual-gestural language whose</definiens>
			</definition>
			<definition id="1">
				<sentence>The cognitive level is that which concerns the content of the feedback , or the part which addresses the intellect of the learner and either enforces the assimilation of the concepts involved , or tells the learner to retry his attempt at communication .</sentence>
				<definiendum id="0">cognitive level</definiendum>
				<definiens id="0">concerns the content of the feedback , or the part which addresses the intellect of the learner and either enforces the assimilation of the concepts involved , or tells the learner to retry his attempt at communication</definiens>
			</definition>
</paper>

		<paper id="1107">
			<definition id="0">
				<sentence>We find that an experimentally obtained measure of subjective phonotactic `` badness '' correlates with three probabilistic measures : word probability , log word probability , and frequency of the lowest frequency ( i.e. `` worst '' ) constituent .</sentence>
				<definiendum id="0">lowest frequency</definiendum>
				<definiens id="0">an experimentally obtained measure of subjective phonotactic `` badness '' correlates with three probabilistic measures : word probability , log word probability , and frequency of the</definiens>
			</definition>
			<definition id="1">
				<sentence>Propagating this type of indexing , we can then provide for the fact that the rhyme/emp/is more common word finally than elsewhere as follows : 10 ) Ssf~ Osf Rsf Rsf ~ `` emp '' , p = X. 11 ) Ssi ~ Osi Rsi Rsi ~ `` emp '' , p=Y , whereY &lt; X. This is , obviously , a brute force solution to the problem. It has the penalty that it treats as unrelated cases which are , in fact , related. In order to allow monosyllabic words to display both wordinitial anomalies for the onset , and word-final anomalies for the rhyme , it is necessary to posit the categories Ssif and Swif. But then the expansion of the Ssif rhyme becomes formally unrelated to that of the Ssf rhyme , and that of the Ssif onset is unrelated to that of the Ssi onset. The practical penalty is that proliferation of logically different types under this approach reduces the count of words which can be used in training the probabilities for any individual case. For the rarer cases , the result can be that the sample sizes are reduced to a point at which statistically reliable estimates of the probabilities are no longer available from a full-size dictionary. This is a scientific problem in ~ addition to an engineering problem. In developing robust and productive phonotactics , speakers must have a better ability than standard stochastic CFGs provide to treat different contexts as analogous so that data over these contexts can be collapsed together. In developing the present parser , we have made a further assumption which allows us to circumvent this problem. In general , the phonological effects of edges are concentrated right at the edge in question. This means that the effect of the left word edge is concentrated on the onset , while the effect of the right word edge is concentrated on the rhyme. The tabulation of probabilities can then be organized according to the vertical , root-to-frontier paths through the tree with only a highly restricted reference to the horizontal context. Specifically , we claim that the root-to-frontier paths are tagged only for whether the frontier is at the left and/or the right edge of the word. Some example paths , those of the word `` candle '' , are : 14 ) U U U U I I I I W W W W I I I I Ssi Ssi Swf Swf I I I I Osi Rsi Owf Rwf I I I I k ~en d 1 which we write for convenience U : W : Ssi : Osi : k , U : W : Ssi : Rsi : a~n , etc. Although the resulting representations are remiscent of those used in data-oriented parsing ( see Bod , 1995 ) , there is a very important difference. The paths we use partition the data ; each terminal string is an instance of only one path = type , with the. result that the probabilities add up to one over all paths. The result is that paths are properly treated as statistically independent , modulo any empirical dependencies which we have failed to model. DOP posits multiple descriptions Which can subsume each other , so that any given Syntactic fragment can contribute to many different descriptions. As a result , the descriptions are not independent by the very nature of the Way they are set up. = To use the paths in parsing new examples , we zip consistent paths together from their roots downwards , unifying neighbouring categories as far down the paths as possible , an operation we call sequential ' : path unification. The probability of the combined l~ath is taken to be the product of the probabilities of the two parts. That is , since the original path sit partitioned the data , a finite state model is a justifiable method of combining paths. Onsets and rhymes which are unattested in the original dictioiaary are assigned a nominal low probability by Good-Turing estimation ( Good , 1953 ) which Bod ( 1995 ) argues to be better behaved than alternative methods for dealing with missing probab ! lity estimates for infrequent items. The sequencing constraints described by the original gramn~ar ( for example , the requirement that an onset be followed by a rhyme and not by another onset ) are enforced by tagging some nodes for the type of e~lement which must succeed it , in a fashion reminiscent of categorial grammar. That is , onsets must ~ be followed by rhymes with the same i/f and s/'w subscripts , and initial syllables = must be followed by final syllables , with an initial weak syllable followed by a strong syllable or an initial strong syllable followed by a weak one. 15 ) a ) A successful instance of path unification U U U I I I W W W I :1 I Ssi/Swf ~ , Ssi/Swf Swf I :1 I Osi/Rsi Rsi Owf/Rwf I :1 I k i~en d U I W I Swf I Rwf I 1 U U l I W W I I Ssi/Swf Swf Osi/Rsi Rsi Owf/Rwf Rwf I I I I k ~en d 1 U I W Ssi/Swf Sw Osi/Rsi Rsi Owf/Rwf Rwf I I I I k ~en d 1 b ) An unsuccessful attempt at path unification U U U I I I W W W I I I Ssi/Swf Swf Swf I l I Osi/Rsi Owf/Rwf Rwf I I I k d 1 U `` I W Ssi/Swf f Osi/Rsi ~ Owf/Rwf Rwf I I I k d I In 15b ) , the parse fails as the initial Osi is not followed by an Rsi , as it requires. To establish the path probabilities for English monosyllabic and disyllabic words , the paths were tabulated over the 48,580 parsed instances of such words in Mitton ( 1992 ) . With each word ~3 containing two to four paths , there was a total of 98,697 paths in the training set. Parsing such a large set of words requires one Osf to take a stand on some issues which are disputed s 234 in the literature. Here are the most important of t 206 these decisions. 1 ) We included every single form 1 193 in the dictionary , including proper nouns , no r 164 matter how foreign or anomalous it might appear p 157 to be , because we have the working hypothesis m 152 that low probabilities can explain the poor v 152 productivity of anomalous patterns. 2 ) Following f 139 current phonological theory ( see e.g. Ito 1988 ) , we d 123 syllabified all word-medial VCV sequences as V.CV. As a related point , we took medial clusters k 123 beginning with/s/to be syllable onsets when they were possible as word onsets. If the sC sequence Rsf is not an attested word onset , it was split medially em 45 ( e.g. 'bus.boy '' ) . elt 41 There are a number of situations in which the eIts 37 dictionary does not mark phonological information which we know to be important. We et 37 have done our best to work around this fact , but in es 34 some cases our estimates are inevitably iz34 contaminated. Specifically : although compounds ekt 33 which are hyphenated in the dictionary can be ekts 33 ( correctly ) parsed as two phonological words , many compounds have no indication of their ent 33 status and are parsed as if they were single words , eI 32 Similarly , words # affixes such as -ly and -ness have been parsed as if they had no internal structure. This contaminates the counts for nonfinal rhymes with a certain number of final rhymes , and it contaminates the counts for noninitial onsets with a certain number of wordinitial onsets. Second , stress is not marked in monosyllabic words. We have therefore taken all monosyllabic words to have a main word stress. As a result , a few reduced pronunciations for function words are included , with the result that there is a small , rather than a zero , probability for stressed syllable rhymes with a schwa. Third , secondary stresses are not reliably marked , particularly when adjacent to a primary stress ( as in the word `` Rangoon '' ) . This means that a certain number of stressed rhymes have been tabulated as if they were unstressed. These problems for the most part can be viewed as sources of noise. We believe that the main trends of our tabulations are correct. To illustrate the fact that positional probabilities differ , table 1 compares the 10 most frequent onsets and rimes in each position. Table 1. Osif Osi Owf 0 836 O 1180 1 979 r 616 k 848 b 934 b 614 s 813 t 884 1 490 p 767 s 748 k 489 m 765 0 746 p 459 b 725 d 708 t 453 h 688 n 698 s 445 t 627 r 656 h 444 r 584 m 621 m 430 1 567 k 601 Rsif Rsi Rwf Rwi i 365 ~e 950 1 740 1 815 eI 147 1 819 IZ 703 ~ 742 ztJ114 e694 o ~661 In 203 ai107 ~654 ~z644 zn120 An 95 i 584 1 514 An 87 U 91 eI 558 1z420 O 69 Ap89 CU537 ~S417 ZU60 eIz 89 A 503 zn 398 Ik 59 ctut88 ztJ472 ~226 Im 59 m76 0429 zu213 zb49 The data set we used to evaluate the parser was obtained in a prior study ( Coleman 1996 ) . The goal of this study was to `` evaluate the psychological reality of phonotactic constraints. The materials were designed to permit minimal comparisons between a nonsense word which was in principle possible and one which was expected to be impossible by virtue of containing an onset or a rhyme which does not occur at all in the Mitton ( 1992 ) dictionary. Thus , the materials were made up of paired words such as /'mhsl~s/ ( impossible by virtue of the cluster /rnl/ ) and /'9hslzs/ ( otherwise identical , but containing the attested cluster 191/instead of/ml/ ) . The materials were randomized , with a post-hoc test to ensure that related items in a pair were separated in the presentation. The words were recorded by John Coleman and presented aurally , twice over , to 6 naive subjects , who judged whether each word could or could not be a possible English word by pressing one of two response buttons. The total number of responses against the well-formedness of each word was taken as a score of subjective degree of wellformedness. : The distributions of scores of forms containing non-occuring clusters and those containing occuring clusters were significantly distinct. Forms which~ were designed to be `` bad '' were judged `` ..i sigmfiCantly worse than forms which were designed to be `` good '' . This was the case for the pooled data , ahd for each matched pair , the `` bad '' variant received a lower score than `` good '' variant for 61/75 `` ~ pmrs. However the data contained a number of surprises , some of which , indeed , motivated thel present study. The scores of the `` bad '' forms , were much more variable than anticipated. `` Bad '' forms in some pairs ( e.g. /nuu'pe~J'n/ ) were scored better than `` good '' forms in other pairs ( e.g. /'splet , soM ) . Apparently , a single subpart , of zero ( observed ) probability is not enough to render a form impossible. Conversely , forms which v~iolate no constraints , but which are composed of 10w frequency constituents and have few lexical r neighbors , are assigned low acceptability s~cores e.g. /'firjkslAp/ and /\ ] 'o'lencS/ , which scored 1,2 , i.e. completely unacceptable. These findings are contrary to the predictions both of a ~classical phonological treatment ( according to which linguistic competence is categorical , and forms which can not be parsed are impossible ) a~ well as to the predictions of Optimality T ! eory ( in which a single severe deviation should determine the evaluation of the form ) . Appare~ ) ly , the well-formed subparts of an otherwise ill-f0rmed word may alleviate the illformed parts , especially if their frequency is high , as in the `` ation '' part of `` mrupation '' ( /nuu'pelJ'n/ ) . We used the stochastic grammar to parse the 116 monoand di-syllabic neologisms from the earlier study , and compared various methods of scoring the goodness of the parse as a predictor of the experimentally obtained measure of acceptability. Specifically , we compared the four alternatives discussed in the introduction. Of the four proposals ' for scoring phonotactic wellformedness , tfiree yield statistically significant correlations : with experimentally obtained judgzements. ( Significance was assessed via a t-test on r , two-tailed , df= 114. ) Scoring method 1 ) p ( word ) , p &lt; .01 2 ) ln ( p ( word ) ) p &lt; .001 3 ) p ( worst part ) p &lt; .01 Significance of correlation 4 ) p ( best part ) n.s. Scoring method 2 ) is a better model of acceptability than 1 ) because it.linearizes the exponential shape of p ( word ) arising from the multiplication of successive parts. Figure 1 is a scatterplot of the best correlation , ln ( p ( word ) ) against the number of votes against wellformedness. It is apparent that less probable words are less acceptable. Figure 1. . &amp; ol Ill &gt; o A A A • -25 -20 A 49 -15 `` 10 `` 5 In ( parse probability ) o 5 We have compared several methods of using frequency information to predict the acceptability of neologisms .</sentence>
				<definiendum id="0">'o'lencS/</definiendum>
				<definiendum id="1">parse probability</definiendum>
				<definiens id="0">a brute force solution to the problem. It has the penalty that it treats as unrelated cases which are , in fact</definiens>
				<definiens id="1">a justifiable method of combining paths. Onsets and rhymes which are unattested in the original dictioiaary are assigned a nominal low probability by Good-Turing estimation</definiens>
				<definiens id="2">materials were designed to permit minimal comparisons between a nonsense word which was in principle possible and one which was expected to be impossible by virtue of containing an onset or a rhyme which does not occur at all in the Mitton</definiens>
				<definiens id="3">a post-hoc test to ensure that related items in a pair were separated in the presentation. The words were recorded by John Coleman and presented aurally , twice over , to 6 naive subjects</definiens>
			</definition>
</paper>

	</volume>
