<?xml version="1.0" encoding="UTF-8"?>
	<volume id="J82">

		<paper id="3001">
			<definition id="0">
				<sentence>The LFG recognition problem represents or mimics the decision problem for 3-CNF in the sense that the `` yes '' and `` no '' answers to both satisfiability problem and membercan generate at least all the indexed languages as defined by Aho 1968 .</sentence>
				<definiendum id="0">LFG recognition problem</definiendum>
				<definiens id="0">represents or mimics the decision problem for 3-CNF in the sense that the `` yes '' and `` no '' answers to both satisfiability problem and membercan generate at least all the indexed languages as defined by Aho 1968</definiens>
			</definition>
			<definition id="1">
				<sentence>8 To see how a reduction can tell us something about the `` worst case '' time or space complexity required to recognize whether a string is or is not in an LFG language , suppose for example that the decision procedure for determining whether a string is in an LFG language took only polynomial time ( that is , takes time n k on a deterministic Turing machine , for some integer k , where n is the length of the input string ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">example that the decision procedure for determining whether a string is in an LFG language took only polynomial time ( that is , takes time n k on a deterministic Turing machine</definiens>
			</definition>
			<definition id="2">
				<sentence>A Lexical-Functi0nal Grammar consists of more than just a base context-free grammar , however .</sentence>
				<definiendum id="0">Lexical-Functi0nal Grammar</definiendum>
				<definiens id="0">consists of more than just a base context-free grammar</definiens>
			</definition>
			<definition id="3">
				<sentence>For instance , the Subject NP in turn has a sub-feature Number ; the Predicate contains complex sub-features corresponding to the Verb and Verb Complements .</sentence>
				<definiendum id="0">Predicate</definiendum>
				<definiens id="0">contains complex sub-features corresponding to the Verb and Verb Complements</definiens>
			</definition>
</paper>

		<paper id="1004">
</paper>

		<paper id="2005">
			<definition id="0">
				<sentence>Information Acquisition Denotative Translation Connotative Translations Fully Automatic Machine Translation can be quite cheap ( revision excluded ) requires effort and experience to read technical material ; possibly other material applications exist , greatly improvable faster and cheaper than human 1st pass human revision required technical material technology coming of age ; applications exist ( METEO ) ; very large intermediate and long-term payoff N/A Human Assisted Machine Translation N/A very high-quality especially multilingual possibly high cost technical material few or no existing prototypes ; FAMT spinoffs possible in near term with suitable funding Machine Assisted Human Translation increased human efficiency more expensive and slower then FAMT almost any material technology exists ; might use FAMT to select candidates increased human efficiency high minimum costs almost any material commercial systems exist ( e.g. , ALPS ) ; FAMT spinoffs could reduce costs in near term advantages disadvantages text types status and prospects advantages disadvantages text types status and prospects increased human advantages efficiency necessarily costly N/A legal and religious texts ; literature ?</sentence>
				<definiendum id="0">Information Acquisition Denotative Translation Connotative Translations Fully Automatic Machine Translation</definiendum>
				<definiendum id="1">FAMT</definiendum>
				<definiens id="0">technical material ; possibly other material applications exist , greatly improvable faster and cheaper than human 1st pass human revision required technical material technology coming of age ; applications exist ( METEO ) ; very large intermediate and long-term payoff N/A Human Assisted Machine Translation N/A very high-quality especially multilingual possibly high cost technical material few or no existing prototypes ; FAMT spinoffs possible in near term with suitable funding Machine Assisted Human Translation increased human efficiency more expensive and slower then FAMT almost any material technology exists</definiens>
				<definiens id="1">spinoffs could reduce costs in near term advantages disadvantages text types status and prospects advantages disadvantages text types status and prospects increased human advantages efficiency necessarily costly N/A legal and religious texts</definiens>
			</definition>
			<definition id="1">
				<sentence>Denotative Translation refers to an information dissemination situation in which the everyday and technical definitions of the words are meant , and where subtle nuances of a word choice are unjustified or even undesirable .</sentence>
				<definiendum id="0">Denotative Translation</definiendum>
				<definiens id="0">an information dissemination situation in which the everyday and technical definitions of the words are meant</definiens>
			</definition>
</paper>

		<paper id="2003">
			<definition id="0">
				<sentence>The knowledge representation , which resembles Brachman 's early KL-ONE , is being used for both the subject matter of Penman 's generation and the text plans by which Penman generates text .</sentence>
				<definiendum id="0">knowledge representation</definiendum>
			</definition>
</paper>

		<paper id="2006">
</paper>

		<paper id="2001">
			<definition id="0">
				<sentence>One area of special interest to the Naval Research Laboratory ( NRL ) is the application of computational linguistics in automated message systems .</sentence>
				<definiendum id="0">NRL )</definiendum>
				<definiens id="0">the application of computational linguistics in automated message systems</definiens>
			</definition>
			<definition id="1">
				<sentence>A third application area is Concept Extraction , which extracts information from an incoming message and builds a suitable knowledge base representation .</sentence>
				<definiendum id="0">Concept Extraction</definiendum>
				<definiens id="0">extracts information from an incoming message and builds a suitable knowledge base representation</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>The grammar controls the syntax of the generated sentence , but bases specific decisions on the structural properties of the semantic network and on the information contained therein .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiens id="0">controls the syntax of the generated sentence , but bases specific decisions on the structural properties of the semantic network and on the information contained therein</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , an ATN grammar can be constructed so that the `` parse '' of a natural language question is the natural language statement that answers it , interaction with representation and inference routines being done on arcs along the way .</sentence>
				<definiendum id="0">ATN grammar</definiendum>
				<definiens id="0">the natural language statement that answers it , interaction with representation and inference routines being done on arcs along the way</definiens>
			</definition>
			<definition id="2">
				<sentence>The JUMP arc provides a place to make an arbitrary test and perform some actions without consuming an input symbol .</sentence>
				<definiendum id="0">JUMP arc</definiendum>
				<definiens id="0">provides a place to make an arbitrary test and perform some actions without consuming an input symbol</definiens>
			</definition>
			<definition id="3">
				<sentence>VIR sets * to an element of the HOLD register .</sentence>
				<definiendum id="0">VIR</definiendum>
				<definiens id="0">sets * to an element of the HOLD register</definiens>
			</definition>
			<definition id="4">
				<sentence>Node M2 represents the name LUCY .</sentence>
				<definiendum id="0">Node M2</definiendum>
				<definiens id="0">the name LUCY</definiens>
			</definition>
			<definition id="5">
				<sentence>The CAT arc from state V ( Figure 6 ) wants a word of category V. The first word in the input buffer is SAW , which is two-ways lexically ambiguous ( see Figure 1 ) , so we can think of the CAT arc as being two arcs , on one of which * contains the singular of the Noun SAW1 , and on the other of which * contains the past tense of the Verb SEE .</sentence>
				<definiendum id="0">SAW</definiendum>
			</definition>
			<definition id="6">
				<sentence>Control then passes to state O. The first arc of state O ( Figure 8 ) recognizes the beginning of a `` by '' prepositional phrase in a passive sentence .</sentence>
				<definiendum id="0">Control</definiendum>
				<definiens id="0">the beginning of a `` by '' prepositional phrase in a passive sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>T ( SENDR TYPE 'm ) ( SETR TYPE 'D ) ( LIFTR TYPE ) ( SETR SUBJ * ) ( TO V ) ) ) Figure 4 .</sentence>
				<definiendum id="0">SETR TYPE 'D )</definiendum>
				<definiens id="0">LIFTR TYPE ) ( SETR SUBJ * ) ( TO V ) ) ) Figure 4</definiens>
			</definition>
			<definition id="8">
				<sentence>( VIR ADJ T ( FINDORBUILD WHICH ( A ( GETR NH ) ) ADJ ( A ( GETR * ) ) ) ( TO mmi ) ) ( POP NH T ) ) Figure 5 .</sentence>
				<definiendum id="0">VIR ADJ T</definiendum>
			</definition>
			<definition id="9">
				<sentence>( WRD BY ( EQ ( GETR VC ) 'PASS ) ; Passive sentences have ( TO PAG ) ) ( PUSH NPP T ; A &lt; tive sentences have an object NP. ( SENDR TYPE ) ( SETR OBJ * ) ( LIFTR VC ) ( TO SVO ) ) ) `` by NP '' . ( PAG ( PUSH NPP T ; Parse the subject NP of a passive sentence. ( SENDR TYPE ) ( SETR SUBJ * ) ( LIFTR VC ) ( TO SVO ) ) ) Figure 8. ATN Grammar ( continued ) . ( SVO ; Return a semantic node. ( POP ( BUILD AGENT ( ^ ( GETR SUBJ ) ) VERB ( A ( GETR VB ) ) OBJECT ( ^ ( GETR OBJ ) ) STIME ( A ( GETR STM ) ) ETIME *ETM ) ( EQ ( GETR TYPE ) 'D ) ) ; An Agent-Verb-Object statement. ( POP ( DEDUCE AGENT ( A ( GETR SUBJ ) ) VERB ( ^ ( GETR VB ) ) OBJECT ( ^ ( GETR OBJ ) ) ) ( EQ ( GETR TYPE ) 'Q ) ) ) ; An Agent-Verb-Object question. ( SVC ( POP ( EVAL ( BUILDQ ( FINDORBUILD WHICH + ADJ + ) SUBJ ADJ ) ) ( EQ ( GETR TYPE ) 'D ) ) ; A Noun-be-Adj statement. ( POP ( DEDUCE WHICH ( A ( GETR SUBJ ) ) ADJ ( A ( GETR ADJ ) ) ) ( EQ ( GETR TYPE ) 'Q ) ) ) ; A Noun-be-Adj question. Figure 9. ATN Grammar ( continued ) . 20 American Journal of Computational Linguistics , Volume 8 , Number 1 , January-March 1982 Stuart C. Shapiro Generalized Augmented Transition Network Grammars ( RESPOND ; Generate the response represented by the semantic node in *. ( JUMP G ( EQ ( GETR TYPE ) 'D ) ; The input was a statement represented by *. ( SETR STRING ' ( I UNDERSTAND THAT ) ) ) ( JUMP G ( EQ ( GETR TYPE ) 'Q ) ) ) ; The input was a question answered by *. Figure 10. ATN Grammar ( continued ) . phrase I UNDERSTAND THAT. Then both arcs JUMP to state G. We follow the generation process assuming that the input buffer is now ( M12 ) . In state G ( Figure 11 ) , the node representing the statement to be generated is analyzed to decide what kind of sentence will be produced. The first arc , for a passive version of M12 , sets the SUBJ register to M11 ( the saw ) , the OBJ register to M4 ( Lucy ) , and the PREP register to the word BY. ( Note the use of GETA , defined in Section 3.3. ) The second arc , for an active version of M12 , sets SUBJ to M4 , OBJ to Mll , and leaves PREP empty. It also makes sure VC is set to ACT , since active voice is the default if VC is empty. The third arc is for generating sentences for nodes such as M15. In that case it sets SUBJ to M4 , OBJ to M14 ( the property SWEET ) , VC to ACT , and leaves PREP empty. All three arcs then JUMP to state GS. The CALL arc at state GS ( Figure 12 ) sets the NUMBR register to SING or PL to determine whether the subject and verb of the sentence will be singular or plural , respectively. It does this by CALLing the network beginning at state NUMBR , sending it the contents of the SUBJ register , and placing the form returned by the lower network into the NUMBR register. Let us assume we are generating an active version of M12. In that case when state NUMBR ( Figure 12 ) is reached , the input buffer will be ( M4 ) , and when the parser returns to the CALL arc the input buffer will again be ( M12 ) . At state NUMBR , the semantic network attached to the node in the * register is examined to determine if it represents a ( singular ) individual or a ( plural ) class of individuals. The first arc decides on PL if the node has a SUB- , SUP- , or CLASSare emanating from it. These arcs are the converses of SUB , SUP , and CLASS arcs , respectively. The first would occur if the node represented the subset of some class. The second would occur if the node represented the superset of some class. The third would occur if the node represented a class with at least one member. In our example , the only semantic node that would be recognized by this arc as representing a class would be M9. The second arc from state NUMBR decides on SING if none of the three mentioned arcs emanate from the node in * , and in our case this is the successful arc. The decision is made by placing SING or PL in the NUMBR register , and transferring TO state NUMBR1. There the input buffer is empty and the contents of NUMBR is popped to the CALL arc in the state GS as discussed above. The last thing the CALL arc in state GS does is set the DONE register to the node in • This register is used to remember the node being expressed in the main clause of the sentence so that it is not also used to form a subordinate clause or description. For example , we would not want to generate `` Lucy , who saw a saw , saw a saw. '' This is used ( G ; Generate a sentence to express the semantic node in *. ( JUMP GS ( AND ( GETA OBJECT ) ( OVERLAP ( GETR VC ) 'PASS ) ) ; A passive sentence is `` OBJECT VERB by AGENT '' . ( SETR SUBJ ( GETA OBJECT ) ) ( SETR OBJ ( GETA AGENT ) ) ( SETR PREP 'BY ) ) ( JUMP GS ( AND ( GETA AGENT ) ( DISJOINT ( GETR VC ) 'PASS ) ) ; An active sentence is `` AGENT VERB OBJECT '' . ( SETR SUBJ ( GETA AGENT ) ) ( SETR OBJ ( GETA OBJECT ) ) ( SETR VC 'ACT ) ) ( JUMP GS ( GETA WHICH ) ( SETR SUBJ ( GETA WHICH ) ) ; A WHICH-ADJ sentence is `` WHICH be ADJ '' . ( SETR OBJ ( GETA ADJ ) ) ( SETR VC 'ACT ) ) ) Figure 1 h ATN Grammar ( continued ) . American Journal of Computational Linguistics , Volume 8 , Number 1 , January-March 1982 21 Stuart C. Shapiro Generalized Augmented Transition Network Grammars effectively in the response to statement 3 to prevent the response from being `` I UNDERSTAND THAT SWEET YOUNG LUCY IS SWEET '' . We will see where DONE is used in the ATN network shortly. The parser then JUMPs to state GS1 , where NP is CALLed with input buffer ( M4 ) , DONE set to M12 , and NUMBR set to SING. State NP ( Figure 13 ) is the beginning of a network that generates a noun phrase to describe the concept represented by the semantic node in the * register ( in this case , M4 ) . The first arc just uses the node at the end of the LEX arc if one exists , as it does for nodes M1 , M2 , etc. WRDIZE is a LISP function that does morphological synthesis for nouns. Its first argument must be SING or PL , and its second argument must be a non-ambiguous lexeme in the lexicon. Nouns whose singular or plural forms are irregular must have them explicitly noted in the lexical feature list. The regular rule is to use the ROOT form as the singular , and to pluralize according to rules built into WRDIZE that operate on the ROOT form. For example , the singular of SAW1 is its ROOT , SAW , and its plural is SAWS. The second arc in the state NP uses a proper name to describe * , if it has one , and if the proposition that this name is * 's name is not the point of the main ( GS ; Set the NUMBR register to the number of the subject , ; and the DONE register to the proposition of the main clause. ( CALL NUMBR SUBJ T NUMBR ( SETR DONE * ) ( JUMP GSl ) ) ) ( GSI ( CALL NP SUBJ T ; Generate a NP to express the subject. ( SENDR DONE ) ( SENDR NUMBR ) REG ( ADDR STRING REG ) ( JUMP SVB ) ) ) ( NUMBR ; The proper number is PL for a class , SING for an individual. ( TO ( NUMBRI ) ( OR ( GETA SUB- ) ( GETA SUP- ) ( GETA CLASS- ) ) ( SETR NUMBR 'PL ) ) ( TO ( NUMBRI ) ( NOT ( OR ( GETA SUB- ) ( GETA SUP- ) ( GETA CLASS- ) ) ) ( SETR NUMBR 'SING ) ) ) ( NUMBRI ( POP NUMBR T ) ) ; Return the number. Figure 12. ATN Grammar ( Continued ) . ( NP ; Generate a NP to express *. ( TO ( END ) ( GETA LEX ) ; Just use the word at the end of the LEX arc if present. ( SETR STRING ( WRDIZE ( GETR NUMBR ) ( GETA LEX ) ) ) ) ( CALL ADJS ( GETA WHICH- ) ; If it has a name , ( AND ( GETA NAMED- ) ( DISJOINT ( GETA NAMED- ) DONE ) ) ( SENDR DONE ) REG ( ADDR STRING REG ) ; add an adjective string , ( TO NPGA ( GETA NAME ( GETA NAMED- ) ) ) ) ; and consider its name. ( CALL ADJS ( GETA WHICH- ) ; If it has a class , ( AND ( GETA MEMBER- ) ( DISJOINT ( GETA MEMBER- ) DONE ) ) ( SENDR DONE ) REG ; add 'A and an adjective string , ( ADDR STRING 'A REG ) ; and consider its class. ( TO NPGA ( GETA CLASS ( GETA MEMBER- ) ) ) ) ) ( NPGA ; Generate a noun phrase for the name or class. ( PUSH NP T ( SENDR DONE ) ( ADDR STRING * ) ( TO END ) ) ) ( END ( POP STRING T ) ) ; Return the string that has been built. Figure 13. ATN Grammar ( continued ) . 22 American Journal of Computational Linguistics , Volume 8 , Number 1 , January-March 1982 Stuart C. Shapiro Generalized Augmented Transition Network Grammars clause. The third arc uses the phrase `` a &lt; class &gt; '' if * is known to be a member of some class , and if that fact is not the main clause of the sentence .</sentence>
				<definiendum id="0">WRD BY ( EQ</definiendum>
				<definiendum id="1">&lt; tive sentences</definiendum>
				<definiendum id="2">LIFTR VC )</definiendum>
				<definiendum id="3">A ( GETR SUBJ ) ) VERB</definiendum>
				<definiendum id="4">OBJECT ( ^</definiendum>
				<definiendum id="5">CLASS arcs</definiendum>
				<definiendum id="6">GETA MEMBER- )</definiendum>
				<definiens id="0">PUSH NPP T ; Parse the subject NP of a passive sentence. ( SENDR TYPE ) ( SETR SUBJ * ) ( LIFTR VC ) ( TO SVO ) ) ) Figure 8. ATN Grammar ( continued ) . ( SVO ; Return a semantic node. ( POP ( BUILD AGENT ( ^ ( GETR SUBJ ) ) VERB ( A ( GETR VB ) ) OBJECT ( ^ ( GETR OBJ )</definiens>
				<definiens id="1">An Agent-Verb-Object question. ( SVC ( POP ( EVAL ( BUILDQ ( FINDORBUILD WHICH + ADJ + ) SUBJ ADJ ) ) ( EQ ( GETR TYPE ) 'D ) ) ; A Noun-be-Adj statement. ( POP ( DEDUCE WHICH ( A ( GETR SUBJ ) ) ADJ ( A ( GETR ADJ ) ) ) ( EQ ( GETR TYPE ) 'Q ) ) ) ; A Noun-be-Adj question. Figure 9. ATN Grammar ( continued ) . 20 American Journal of Computational Linguistics , Volume 8 , Number 1 , January-March 1982 Stuart C. Shapiro Generalized Augmented Transition Network Grammars ( RESPOND ; Generate the response represented by the semantic node in *. ( JUMP G ( EQ ( GETR TYPE ) 'D )</definiens>
				<definiens id="2">*. Figure 10. ATN Grammar ( continued )</definiens>
				<definiens id="3">the node representing the statement to be generated is analyzed to decide what kind of sentence</definiens>
				<definiens id="4">the saw ) , the OBJ register to M4 ( Lucy )</definiens>
				<definiens id="5">sets the NUMBR register to SING or PL to determine whether the subject and verb of the sentence will be singular or plural</definiens>
				<definiens id="6">used to remember the node being expressed in the main clause of the sentence so that it is not also used to form a subordinate clause</definiens>
				<definiens id="7">used ( G ; Generate a sentence to express the semantic node in *. ( JUMP GS ( AND ( GETA OBJECT ) ( OVERLAP ( GETR VC ) 'PASS ) ) ; A passive sentence is `` OBJECT VERB by AGENT '' . ( SETR SUBJ ( GETA OBJECT ) ) ( SETR OBJ ( GETA AGENT ) ) ( SETR PREP 'BY ) ) ( JUMP GS ( AND ( GETA AGENT ) ( DISJOINT ( GETR VC ) 'PASS ) ) ; An active sentence is `` AGENT VERB OBJECT '' . ( SETR SUBJ ( GETA AGENT ) ) ( SETR OBJ ( GETA OBJECT ) ) ( SETR VC 'ACT ) ) ( JUMP GS ( GETA WHICH ) ( SETR SUBJ ( GETA WHICH ) ) ; A WHICH-ADJ sentence is `` WHICH be ADJ '' . ( SETR OBJ ( GETA ADJ ) ) ( SETR VC 'ACT ) ) ) Figure 1 h ATN Grammar ( continued ) . American Journal of Computational Linguistics , Volume 8 , Number 1 , January-March 1982 21 Stuart C. Shapiro Generalized Augmented Transition Network Grammars effectively in the response to statement 3 to prevent the response from being `` I UNDERSTAND THAT SWEET YOUNG LUCY IS SWEET '' . We will see where DONE is used in the ATN network shortly. The parser then JUMPs to state GS1 , where NP is CALLed with input buffer ( M4 ) , DONE set to M12 , and NUMBR set to SING. State NP ( Figure 13 ) is the beginning of a network that generates a noun phrase to describe the concept represented by the semantic node in the * register</definiens>
				<definiens id="8">a non-ambiguous lexeme in the lexicon. Nouns whose singular or plural forms are irregular must have them explicitly noted in the lexical feature list. The regular rule is to use the ROOT form as the singular , and to pluralize according to rules built into WRDIZE that operate on the ROOT form. For example</definiens>
				<definiens id="9">the number of the subject , ; and the DONE register to the proposition of the main clause. ( CALL NUMBR SUBJ T NUMBR ( SETR DONE * ) ( JUMP GSl ) ) ) ( GSI ( CALL NP SUBJ T ; Generate a NP to express the subject. ( SENDR DONE ) ( SENDR NUMBR ) REG ( ADDR STRING REG ) ( JUMP SVB ) ) ) ( NUMBR</definiens>
				<definiens id="10">an individual. ( TO ( NUMBRI ) ( OR ( GETA SUB- ) ( GETA SUP- ) ( GETA CLASS- ) ) ( SETR NUMBR 'PL ) ) ( TO ( NUMBRI ) ( NOT ( OR ( GETA SUB- ) ( GETA SUP- ) ( GETA CLASS- ) ) ) ( SETR NUMBR 'SING ) ) ) ( NUMBRI ( POP NUMBR T ) ) ; Return the number. Figure 12. ATN Grammar ( Continued ) . ( NP ; Generate a NP to express *. ( TO ( END ) ( GETA LEX ) ; Just use the word at the end of the LEX arc if present. ( SETR STRING ( WRDIZE ( GETR NUMBR ) ( GETA LEX ) ) ) ) ( CALL ADJS ( GETA WHICH- )</definiens>
				<definiens id="11">AND ( GETA NAMED- ) ( DISJOINT ( GETA NAMED- ) DONE ) ) ( SENDR DONE ) REG ( ADDR STRING REG ) ; add an adjective string , ( TO NPGA ( GETA NAME ( GETA NAMED- ) ) ) )</definiens>
				<definiens id="12">DISJOINT ( GETA MEMBER- ) DONE ) ) ( SENDR DONE ) REG ; add 'A and an adjective string , ( ADDR STRING 'A REG ) ; and consider its class. ( TO NPGA ( GETA CLASS ( GETA MEMBER- ) ) ) ) ) ( NPGA ; Generate a noun phrase for the name or class. ( PUSH NP T ( SENDR DONE ) ( ADDR STRING * ) ( TO END ) ) ) ( END ( POP STRING T ) ) ; Return the string that has been built. Figure 13. ATN Grammar ( continued ) . 22 American Journal of Computational Linguistics , Volume 8 , Number 1 , January-March 1982 Stuart C. Shapiro Generalized Augmented Transition Network Grammars clause. The third arc uses the phrase `` a &lt; class &gt; '' if * is known to be a member of some class</definiens>
			</definition>
			<definition id="10">
				<sentence>( CALL NP ( GETA ADJ ) ( DISJOINT * DONE ) ( SENDR DONE ) * ( ADDR STRING * ) ( TO ADJS ) ) ( TO ( ADJS ) T ) ( POP STRING T ) ) Figure 14 .</sentence>
				<definiendum id="0">CALL NP ( GETA ADJ )</definiendum>
				<definiens id="0">DISJOINT * DONE ) ( SENDR DONE ) * ( ADDR STRING * ) ( TO ADJS ) ) ( TO ( ADJS ) T ) ( POP STRING T ) ) Figure 14</definiens>
			</definition>
			<definition id="11">
				<sentence>( PAST ; If we can get to *NOW by BEFORE arcs , ( TO ( PASTEND ) ( OVERLAP * *NOW ) ) ( TO ( PAST ( GETA BEFORE ) ) T ) ) ( PASTEND ( POP 'PAST T ) ) it is past tense .</sentence>
				<definiendum id="0">PASTEND )</definiendum>
				<definiens id="0">OVERLAP * *NOW ) ) ( TO ( PAST ( GETA BEFORE ) ) T ) ) ( PASTEND ( POP 'PAST T ) ) it is past tense</definiens>
			</definition>
</paper>

		<paper id="2004">
			<definition id="0">
				<sentence>An important part of this evolution , which was alluded to above , is the specification of the two major components of such a system , namely A. A Natural Language Understander , which will be based on a model of the universe of discourse represented in the content of the messages ; B. A Message Routing Expert , which will be based on a model of Navy organizational and functional structure .</sentence>
				<definiendum id="0">Natural Language Understander</definiendum>
				<definiendum id="1">; B. A Message Routing Expert</definiendum>
				<definiens id="0">a model of the universe of discourse represented in the content of the messages</definiens>
			</definition>
</paper>

		<paper id="3004">
			<definition id="0">
				<sentence>Lexical ambiguity , for example , will be analyzed as the sum of its senses , or in flow graph terminology ( Oppenheim and Schafer 1975 ) as a parallel connection of its senses .</sentence>
				<definiendum id="0">Lexical ambiguity</definiendum>
				<definiens id="0">the sum of its senses , or in flow graph terminology</definiens>
			</definition>
			<definition id="1">
				<sentence>That is , I A `` B I * ICI = IAI * IB `` CI , where A , B , and C are sets of trees and I A I denotes the number of members of A , and * is integer multiplication .</sentence>
				<definiendum id="0">I</definiendum>
				<definiens id="0">B I * ICI = IAI * IB `` CI , where A , B , and C are sets of trees</definiens>
				<definiens id="1">the number of members of A , and * is integer multiplication</definiens>
			</definition>
			<definition id="2">
				<sentence>Equation ( 9 ) is such a special case ; the coefficients follow a well-known combinatoric series called the Catalan Numbers ( Knuth 1975 , pp .</sentence>
				<definiendum id="0">Catalan Numbers</definiendum>
				<definiens id="0">such a special case ; the coefficients follow a well-known combinatoric series called the</definiens>
			</definition>
			<definition id="3">
				<sentence>It is very useful to know that the ambiguity coefficients are Catalan numbers because this observation enables us to replace equation ( 9 ) with ( 11 ) , where Cat i denotes the i th Catalan number .</sentence>
				<definiendum id="0">Cat i</definiendum>
				<definiens id="0">the ambiguity coefficients are Catalan numbers because this observation enables us to replace equation ( 9 ) with ( 11 ) , where</definiens>
			</definition>
			<definition id="4">
				<sentence>Suppose we have a non-terminal S that is a series combination of two other non-terminals , NP and VP .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">a series combination of two other non-terminals</definiens>
			</definition>
			<definition id="5">
				<sentence>Multiplication is a cross-product operation ; L × R generates the set of binary trees whose left sub-tree 1 is from L and whose right sub-tree r is from R , -m ( 22 ) LxR = { ( l , r ) ll EL &amp; reR } This is a formal definition .</sentence>
				<definiendum id="0">Multiplication</definiendum>
				<definiens id="0">a cross-product operation ; L × R generates the set of binary trees whose left sub-tree 1 is from L and whose right sub-tree r is from R</definiens>
				<definiens id="1">a formal definition</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>A local constraint rule is a rule of the form A -* u/C A where C A is a Boolean combination of proper analysis and domination predicates .</sentence>
				<definiendum id="0">local constraint rule</definiendum>
				<definiendum id="1">C A</definiendum>
				<definiens id="0">a Boolean combination of proper analysis and domination predicates</definiens>
			</definition>
			<definition id="1">
				<sentence>S /\ A B '= /\ I C d E C e pt = { S , AB , AE , Ae , CdB , CdE , Cde , cdB , cdE , cde } .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">/\ A B '= /\ I C d E C e pt = { S , AB , AE , Ae , CdB , CdE , Cde , cdB , cdE , cde }</definiens>
			</definition>
			<definition id="2">
				<sentence>Let G be a context-sensitive grammar ; i.e. , its rules are of the form A - '' ~/~r__~ where A cV E ( V is the alphabet and E is the set of terminal symbols ) , w e V + ( set of non-null strings on V ) and ~r , 4~ E V* ( set of all strings onV ) .</sentence>
				<definiendum id="0">cV E ( V</definiendum>
				<definiendum id="1">E</definiendum>
				<definiens id="0">the alphabet</definiens>
				<definiens id="1">the set of terminal symbols ) , w e V + ( set of non-null strings on V</definiens>
			</definition>
			<definition id="3">
				<sentence>Specifically , if T is the set of derivation trees of a context-free grammar , G , then there is a tree automaton that recognizes T. Conversely , if T is the set of trees recognized by a tree automaton , A , then T may be systematically relabeled as the set of derivation trees of a context-free grammar .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the set of derivation trees of a context-free grammar</definiens>
			</definition>
			<definition id="4">
				<sentence>w I BCDXE FYG where A , B , C , D.E , F , G are nonterminals , w is a string of terminals and/or nonterminals , and X and Y are variables that range over arbitrary strings of terminals and nonterminals .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">a string of terminals and/or nonterminals , and X and Y are variables that range over arbitrary strings of terminals and nonterminals</definiens>
			</definition>
			<definition id="5">
				<sentence>Usually B is an S node .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">an S node</definiens>
			</definition>
			<definition id="6">
				<sentence>c I PP1 X V 2 NP 3 __ A DOM ( S ' 4 S 5 Y VP 6 ) A COM ( PP1 S'4 VP6 ) -/k LMS ( PP1 $ 5 ) The last rule has a proper analysis predicate , a domination predicate , and COMMAND and LEFTMOSTSISTER predicates whose arguments satisfy the requirements mentioned in ( iii ) above ( i.e. , they relate nodes mentioned in proper analysis predicates and domination predicates ) .</sentence>
				<definiendum id="0">DOM</definiendum>
				<definiendum id="1">COM</definiendum>
			</definition>
			<definition id="7">
				<sentence>For a local constraint rule of the form A- , BC I P where A -* BC is the context-free part and P is the contextual constraint , we can have o ( A ) as a composition of o ( B ) and o ( C ) , which depends on P. This idea has been pursued in the context of programming languages ( Joshi , Levy , and Yueh 1980 ) .</sentence>
				<definiendum id="0">A -* BC</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">the context-free part and</definiens>
				<definiens id="1">A ) as a composition of o ( B</definiens>
			</definition>
</paper>

		<paper id="3003">
			<definition id="0">
				<sentence>The algorithm introduces equivalence parsing , which is a general execution method for nondeterministic programs that is based on a recall table , a generalization of the well-formed substring table .</sentence>
				<definiendum id="0">equivalence parsing</definiendum>
				<definiens id="0">a general execution method for nondeterministic programs that is based on a recall table , a generalization of the well-formed substring table</definiens>
			</definition>
			<definition id="1">
				<sentence>The syntactic component of PTQ is an essentially context-free grammar , augmented by some additional rules of a different form .</sentence>
				<definiendum id="0">PTQ</definiendum>
				<definiens id="0">an essentially context-free grammar , augmented by some additional rules of a different form</definiens>
			</definition>
			<definition id="2">
				<sentence>Each substitution rule substitutes a term phrase ( NP ) for one or more occurrences of a free variable in a phrase ( which may be a sentence , common noun phrase , or intransitive verb phrase ) .</sentence>
				<definiendum id="0">substitution rule</definiendum>
			</definition>
			<definition id="3">
				<sentence>The recall table is a set of buckets used to organize and hold partial syntactic structures while larger ones are constructed .</sentence>
				<definiendum id="0">recall table</definiendum>
				<definiens id="0">a set of buckets used to organize and hold partial syntactic structures while larger ones are constructed</definiens>
			</definition>
			<definition id="4">
				<sentence>The recall table is a generalization of the familiar well-formed substring table ( WFST ) to arbitrary programs that contain procedure calls .</sentence>
				<definiendum id="0">recall table</definiendum>
				<definiens id="0">a generalization of the familiar well-formed substring table ( WFST ) to arbitrary programs that contain procedure calls</definiens>
			</definition>
			<definition id="5">
				<sentence>The ATN handles the substitution by using a LIFTR to carry the variablebinding information .</sentence>
				<definiendum id="0">ATN</definiendum>
				<definiens id="0">handles the substitution by using a LIFTR to carry the variablebinding information</definiens>
			</definition>
			<definition id="6">
				<sentence>A language is a pair &lt; ~2 , R &gt; where ~2 is a disambiguated language and R is a binary relation with domain included in A. Given a disambiguated language ~2 = &lt; A , F~ , X # , S , 80 &gt; ~EF , ~EA , a disambiguated language f~v = &lt; A , F~ , Xts , , S t , 80v &gt; ~ , EF , 8'EA ' is a refinement of 12 if there is a refinement function d : AW- .</sentence>
				<definiendum id="0">language</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a pair &lt; ~2 , R &gt; where ~2 is a disambiguated language and</definiens>
			</definition>
			<definition id="7">
				<sentence>136 American Journal of Computational Linguistics , Volume 8 , Number 3-4 , July-December 1982 David Scott Warren and Joyce Friedman Using Semantics in Non-Context-Free Parsing As a more intuitive example of refinement , consider an English-like language with categories term ( TE ) and intransitive verb phrase ( IV ) that both include singular and plural forms .</sentence>
				<definiendum id="0">IV</definiendum>
				<definiens id="0">a more intuitive example of refinement , consider an English-like language with categories term ( TE ) and intransitive verb phrase</definiens>
			</definition>
			<definition id="8">
				<sentence>The language generated would then allow subject-verb disagreement ( assuming the ambiguating relation R does not filter them out ) .</sentence>
				<definiendum id="0">subject-verb disagreement</definiendum>
				<definiens id="0">assuming the ambiguating relation R does not filter them out )</definiens>
			</definition>
			<definition id="9">
				<sentence>The ATN for PTQ represents the disambiguated language for PTQ in the UG sense .</sentence>
				<definiendum id="0">ATN for PTQ</definiendum>
				<definiens id="0">represents the disambiguated language for PTQ in the UG sense</definiens>
			</definition>
			<definition id="10">
				<sentence>An interpretation , t ' for L is a system &lt; B , G~ , ,f &gt; 3 , EF such that &lt; B , Gv &gt; v~ r is an algebra similar to &lt; A , F./ &gt; 3 , eF ; i.e. , for each ~ , E F , Fy and G./ have the same number of arguments , and f is a function from O , EAX 8 into B. Note that the algebra &lt; B , G~ , &gt; .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">a system &lt; B , G~ , ,f &gt; 3</definiens>
			</definition>
			<definition id="11">
				<sentence>B is the set of meanings of the interpretation , I , ; Gv is the semantic rule corresponding to syntactic rule Fv ; f assigns meanings to the basic expressions Xv .</sentence>
				<definiendum id="0">Gv</definiendum>
			</definition>
			<definition id="12">
				<sentence>The notion of input-refinement for context-free grammars was introduced by example , and the tabular context-free recognition algorithms were described in these terms .</sentence>
				<definiendum id="0">notion of input-refinement</definiendum>
				<definiens id="0">for context-free grammars was introduced by example , and the tabular context-free recognition algorithms were described in these terms</definiens>
			</definition>
</paper>

		<paper id="3002">
			<definition id="0">
				<sentence>exports ( france , wine , britain ) France is a country , country ( france ) Paris is the capital of France .</sentence>
				<definiendum id="0">France</definiendum>
				<definiens id="0">a country , country ( france ) Paris is the capital of France</definiens>
			</definition>
			<definition id="1">
				<sentence>european ( france ) Many kinds of more complex phrases or sentences can be represented by conjunctions of predications , for example : Paris is a European city .</sentence>
				<definiendum id="0">Paris</definiendum>
				<definiens id="0">a European city</definiens>
			</definition>
			<definition id="2">
				<sentence>France is a country that borders on Spain .</sentence>
				<definiendum id="0">France</definiendum>
				<definiens id="0">a country that borders on Spain</definiens>
			</definition>
			<definition id="3">
				<sentence>Read 'answer ( X ) &lt; = P ' as `` X is an answer if P '' or `` I want to know X if P ( is true ) '' .</sentence>
				<definiendum id="0">Read 'answer</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">an answer if P '' or</definiens>
				<definiens id="1">true ) ''</definiens>
			</definition>
			<definition id="4">
				<sentence>How is it that the bits of structure corresponding to each individual work in this sentence fit together to produce the following logical form : American Journal of Computational Linguistics , Volume 8 , Number 3-4 , July-December 1982 113 David H , D. Warren and Fernando C.N. Pereira An Efficient Easily Adaptable System answer ( C ) &lt; = european ( C ) &amp; country ( C ) &amp; \ +exists ( X , arm ( X ) &amp; exists ( C1 , country ( C1 ) &amp; in ( Cl , africa ) &amp; exports ( C , X , C1 ) ) ) ( One should realize that this is just a shorthand for `` For any C , C is an answer if C is European and C is a country and it can not be shown that there is some X such that X is an armament and there is some C1 such that C1 is a country and C1 is in Africa and C exports X to CI '' . )</sentence>
				<definiendum id="0">country</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">C</definiendum>
				<definiendum id="3">C1</definiendum>
				<definiens id="0">a country</definiens>
			</definition>
			<definition id="5">
				<sentence>Type matching helps the system to find a semantically sound argument placement , and is also used to create additional predications when attributes are referred to implicitly , as in comparatives .</sentence>
				<definiendum id="0">Type matching</definiendum>
				<definiens id="0">helps the system to find a semantically sound argument placement</definiens>
			</definition>
			<definition id="6">
				<sentence>answer ( C ) &lt; = country ( C ) &amp; borders ( C , mediterranean ) &amp; exists ( Cl , country ( C1 ) &amp; asian ( C1 ) &amp; borders ( C , C 1 ) ) After planning , the logical form is transformed into : answer ( C ) &lt; = borders ( C , mediterranean ) &amp; { country ( C ) } &amp; { borders ( C , C1 ) &amp; { asian ( C1 ) &amp; { country ( C1 ) } } } When executed by Prolog , this produces a behaviour equivalent to the following procedural interpretation : To generate an answer C : generate a C bordering the mediterranean , and then check that C is a country , and then check that it is possible to : generate a C1 bordered by C , and then check that C1 is asian , and then check that C1 is a country .</sentence>
				<definiendum id="0">answer</definiendum>
				<definiens id="0">borders ( C , mediterranean ) &amp; { country ( C ) } &amp; { borders ( C , C1 ) &amp; { asian ( C1 ) &amp; { country ( C1 ) } } } When executed by Prolog , this produces a behaviour equivalent to the following procedural interpretation : To generate an answer</definiens>
				<definiens id="1">a country , and then check that it is possible to : generate a C1 bordered by C , and then check that C1 is asian , and then check that C1 is a country</definiens>
			</definition>
</paper>

		<paper id="2002">
			<definition id="0">
				<sentence>Natural-language ( NL ) interfaces built so far have primarily addressed the problem of accessing information stored in conventional data base systems .</sentence>
				<definiendum id="0">Natural-language</definiendum>
				<definiens id="0">the problem of accessing information stored in conventional data base systems</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>For example , the rule \ [ ( S ) ( NP ) ( VP ) \ ] states that a fragment with root S , left branch NP and right branch VP is an admissible fragment of a syntactic tree .</sentence>
				<definiendum id="0">branch VP</definiendum>
				<definiens id="0">the rule \ [ ( S ) ( NP ) ( VP ) \ ] states that a fragment with root S , left branch NP and right</definiens>
				<definiens id="1">an admissible fragment of a syntactic tree</definiens>
			</definition>
			<definition id="1">
				<sentence>Gazdar refutes the assumption by using metagrammatical devices to achieve descriptive elegance .</sentence>
				<definiendum id="0">Gazdar</definiendum>
				<definiens id="0">refutes the assumption by using metagrammatical devices to achieve descriptive elegance</definiens>
			</definition>
			<definition id="2">
				<sentence>These devices include rule-schemata ( e.g. , coordination schemata that yield the rules of coordinate structure for all coordinators and all syntactic categories ) , and metarules ( e.g. , a passive metarule that takes any transitive-VP rule as 'input ' and generates a corresponding passive-VP rule as 'output ' by deleting the sionally followed by supplementary features , e.g. , ( V TRAN ) for transitive verb .</sentence>
				<definiendum id="0">passive metarule</definiendum>
				<definiens id="0">coordination schemata that yield the rules of coordinate structure for all coordinators and all syntactic categories ) , and metarules</definiens>
			</definition>
			<definition id="3">
				<sentence>The semantic rule states that the intensional logic translation of the S-constituent is compounded of the VP-translation ( as functor ) and the NP-translation ( as operand ) , where the latter is first to be prefixed with the intension operator A. In general , a primed syntactic symbol denotes the logical translation of the corresponding constituent , and a double-primed symbol the logical translation prefixed with the intension operator ( thus , NP '' stands for ANP ' ) .</sentence>
				<definiendum id="0">intension operator</definiendum>
				<definiendum id="1">NP</definiendum>
				<definiens id="0">The semantic rule states that the intensional logic translation of the S-constituent is compounded of the VP-translation ( as functor ) and the NP-translation ( as operand ) , where the latter is first to be prefixed with the intension operator A. In general , a primed syntactic symbol denotes the logical translation of the corresponding constituent , and a double-primed symbol the logical translation prefixed with the</definiens>
			</definition>
			<definition id="4">
				<sentence>Roughly speaking , it is used to bring meanings within the domain of discourse ; e.g , , while an NP t denotes a property set at each index , the corresponding ANp~ denotes the entire NP intension ( mapping from indices to property sets ) at each index .</sentence>
				<definiendum id="0">corresponding ANp~</definiendum>
				<definiens id="0">the entire NP intension ( mapping from indices to property sets</definiens>
			</definition>
			<definition id="5">
				<sentence>Atomic sentences are of the form \ [ t n P t 1 ... tn_l\ ] , ( equivalently , ( P t 1 ... tn ) ) , where t I ... . , t n are terms and P is a predicate constant , and the square brackets and blunt angle brackets distinguish infix and prefix syntax respectively .</sentence>
				<definiendum id="0">Atomic sentences</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">a predicate constant</definiens>
			</definition>
			<definition id="6">
				<sentence>For example , let V denote the semantic valuation function ( with a particular interpretation and possible world understood ) and let V ( P ) = { &lt; a , b , c &gt; , &lt; a , b , d &gt; , &lt; e , f , g &gt; } , V ( x ) = a , V ( y ) = b , and V ( z ) = d , where P is a triadic predicate symbol , x , y , and z are individual constants or variables , and a , b ... .. g are elements of the individual domain D. Then V ( ( P x ) ) = { &lt; b , c &gt; , &lt; b , d &gt; } , V ( ( P x y ) ) = V ( ( ( P x ) y ) = { &lt; c &gt; , &lt; d &gt; } , and V ( \ [ z V x y\ ] ) = V ( ( ( ( P x ) y ) z ) ) = { &lt; &gt; } .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the semantic valuation function ( with a particular interpretation and possible world understood ) and let V ( P ) = { &lt; a , b , c &gt; , &lt; a , b , d &gt; , &lt; e , f , g &gt; }</definiens>
				<definiens id="1">( x ) = a , V ( y ) = b , and V ( z ) = d , where P is a triadic predicate symbol , x , y , and z are individual constants or variables , and a , b ... .. g are elements of the individual domain D. Then V ( ( P x ) ) = { &lt; b , c &gt; , &lt; b , d &gt; } , V ( ( P x y ) ) = V ( ( ( P x ) y ) = { &lt; c &gt; , &lt; d &gt; } , and V ( \ [ z V x y\ ] ) = V ( ( ( ( P x ) y ) z ) ) = { &lt; &gt; }</definiens>
			</definition>
			<definition id="7">
				<sentence>, and P = ) tx ( P x ) = ~ , xhy ( P x y ) ... .. where P is a predicate of any adicity ( including null , if we use { &lt; &gt; } XA= A for any set A ) .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">a predicate of any adicity</definiens>
			</definition>
			<definition id="8">
				<sentence>x\ [ \ [ x ADJP'\ ] &amp; \ [ x N'\ ] \ ] ; in the case of `` little '' , we would use ADJP ' = ( little-for P ) , where P is an indeterminate predicate to be replaced pragmatically by a comparison-class predicate .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">an indeterminate predicate to be replaced pragmatically by a comparison-class predicate</definiens>
			</definition>
			<definition id="9">
				<sentence>Further postprocessing to determine referents and disambiguate operators and predicates might then yield S ' = \ [ INDIVI7 SMILESl\ ] , where INDIV17 is a ( possibly new ) logical constant unambiguously denoting the referent of ( the\ ] x5 : \ [ x5 ( little2 boy3 ) \ ] ) and SMILESl is an unambiguous logical predicate .</sentence>
				<definiendum id="0">INDIV17</definiendum>
				<definiendum id="1">SMILESl</definiendum>
				<definiens id="0">an unambiguous logical predicate</definiens>
			</definition>
			<definition id="10">
				<sentence>The linking rules for topicalization are obtained from the rule schemata &lt; I I , \ [ B/B t\ ] , h &gt; , and &lt; 12 , \ [ ( S ) B ( S ) /B\ ] , &lt; AhS ' B ' ) &gt; , where B ranges over all basic phrasal categories , and t is a dummy element ( trace ) .</sentence>
				<definiendum id="0">t</definiendum>
				<definiens id="0">the rule schemata &lt; I I , \ [ B/B t\ ] , h &gt; , and &lt; 12 , \ [ ( S ) B ( S ) /B\ ] , &lt; AhS ' B ' ) &gt; , where B ranges over all basic phrasal categories</definiens>
			</definition>
			<definition id="11">
				<sentence>A further rule reduces the S/NP to an R ( relative clause ) , and its semantic part abstracts on h to yield the predicate R ' = Xh\ [ Mary wants \ [ Mary buys h\ ] \ ] as the translation of the relative clause .</sentence>
				<definiendum id="0">further rule</definiendum>
				<definiens id="0">reduces the S/NP to an R ( relative clause ) , and its semantic part abstracts on h to yield the predicate R ' = Xh\ [ Mary wants \ [ Mary buys h\ ] \ ] as the translation of the relative clause</definiens>
			</definition>
			<definition id="12">
				<sentence>The rules for NPs can be formulated in such a way that `` every dog '' will be translated as &lt; every kx\ [ \ [ x dog\ ] &amp; \ [ x R\ ] \ ] &gt; where R is a free predicate variable that is replaced by the translation of the relative clause when the NP-R rule &lt; 13 , \ [ ( NP ) ( NP ) ( R ) \ ] , &lt; XRNP ' R ' &gt; &gt; is applied ( cf. , Gazdar 1981b ; we have ignored multiple relative clauses ) .</sentence>
				<definiendum id="0">The rules for NPs</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a free predicate variable that is replaced by the translation of the relative clause when the NP-R rule &lt; 13 , \ [ ( NP ) ( NP ) ( R ) \ ] , &lt; XRNP ' R '</definiens>
			</definition>
			<definition id="13">
				<sentence>The translation of the complete sentence , after extraction of the quantifier and conversion of the constraint on the universally quantified variable to an implicative antecedent , would be ¥y\ [ \ [ \ [ y dog\ ] &amp; \ [ Mary wants \ [ Mary buys y\ ] \ ] \ ] = &gt; \ [ y ( small P ) \ ] \ ] , where P is an undetermined predicate ( = dog , in the absence of contrary contextual information ) .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
			<definition id="14">
				<sentence>In the original and resultant semantic rules , ( ~ '' ... ) represents the original rule matrix in which NP '' is embedded ; thus ( ~r p ) is the result of substituting the lambda variable P ( which varies over NP intensions ) for NP '' in the original rule .</sentence>
				<definiendum id="0">~r p )</definiendum>
				<definiens id="0">the original rule matrix in which NP '' is embedded</definiens>
				<definiens id="1">the result of substituting the lambda variable P ( which varies over NP intensions ) for NP '' in the original rule</definiens>
			</definition>
			<definition id="15">
				<sentence>&lt; 15 , \ [ ( A ~ ) ( ~ ) ( A ) \ ] , A ' &gt; , where A is any syntactic category and ~ E { and , or\ ] ( a ) and admires ( b ) admires ( a ) ' or Mary ( b ) ' Mary &lt; 16 , \ [ ( A ) ( A ) + ( A ~ ) \ ] , &lt; ~ ' A'A ' ... A ' &gt; &gt; ( a ) loves \ [ and admires\ ] ( b ) &lt; and loves admires &gt; ( a ) ' \ [ Fido Kim\ ] \ [ or Mary\ ] ( b ) ' &lt; or Fido Kim Mary &gt; &lt; 17 , \ [ ( A ) ( A ) ( A ~ ) +\ ] , &lt; ~ ' A'A ' ... A ' &gt; &gt; ( a ) Fido \ [ \ [ or Kim\ ] \ [ or Mary\ ] \ ] ( b ) &lt; or Fido Kim Mary &gt; The order in which coordinators are extracted and distributed is a matter of pragmatic choice .</sentence>
				<definiendum id="0">A )</definiendum>
				<definiendum id="1">A ) ( A )</definiendum>
				<definiens id="0">A ) \ ] , A ' &gt;</definiens>
				<definiens id="1">a ) Fido \ [ \ [ or Kim\ ] \ [ or Mary\ ] \ ] ( b ) &lt; or Fido Kim Mary &gt; The order in which coordinators are extracted</definiens>
			</definition>
			<definition id="16">
				<sentence>Lenhart K. Schubert is an associate professor of computer science at the University of Alberta , Edmonton .</sentence>
				<definiendum id="0">Lenhart K. Schubert</definiendum>
				<definiens id="0">an associate professor of computer science at the University of Alberta</definiens>
			</definition>
</paper>

	</volume>
