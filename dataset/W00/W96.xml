<?xml version="1.0" encoding="UTF-8"?>
	<volume id="W96">

		<paper id="0107">
			<definition id="0">
				<sentence>Translation candidates of word sequences are evaluated by a similarity measure between the sequences defined by the co-occurrence frequency and independent frequency of the word sequences .</sentence>
				<definiendum id="0">Translation candidates of word sequences</definiendum>
				<definiens id="0">independent frequency of the word sequences</definiens>
			</definition>
			<definition id="1">
				<sentence>Smadja proposes a method of finding translation patterns of continuous as well as discontinuous collocations between English and French \ [ Smadja 96\ ] .</sentence>
				<definiendum id="0">Smadja</definiendum>
			</definition>
</paper>

		<paper id="0213">
			<definition id="0">
				<sentence>The Probability Model The probability model is defined over 7-/x 7- , where 7t is the set of possible word and tag contexts , or `` histories '' , and T is the set of allowable tags .</sentence>
				<definiendum id="0">probability model</definiendum>
				<definiendum id="1">7t</definiendum>
				<definiendum id="2">T</definiendum>
				<definiens id="0">the set of possible word and tag contexts</definiens>
			</definition>
			<definition id="1">
				<sentence>l , tET and the observed feature expectation is i=1 and where iS ( hi , ti ) denotes the observed probability of ( hi , ti ) in the training data .</sentence>
				<definiendum id="0">iS</definiendum>
				<definiens id="0">the observed probability of ( hi , ti ) in the training data</definiens>
			</definition>
			<definition id="2">
				<sentence>In practice , 7-/ is very large and the model 's expectation Efj can not be computed directly , so the following approximation ( Lau et al. , 1993 ) is used : n E fj , ~ E15 ( hi ) p ( tilhi ) fj ( hi , ti ) i=1 where fi ( hi ) is the observed probability of the history hi in the training set .</sentence>
				<definiendum id="0">fi ( hi )</definiendum>
				<definiens id="0">the observed probability of the history hi in the training set</definiens>
			</definition>
			<definition id="3">
				<sentence>It can be shown ( Darroch and Ratcliff , 1972 ) that if p has the form ( 1 ) and satisfies the k constraints ( 2 ) , it uniquely maximizes the entropy H ( p ) over distributions that satisfy ( 2 ) , and uniquely maximizes the likelihood L ( p ) over distributions of the form ( 1 ) .</sentence>
				<definiendum id="0">L</definiendum>
			</definition>
			<definition id="4">
				<sentence>If the Tag Dictionary is in effect , the search procedure , for known words , generates only tags given by the dictionary entry , while for unknown words , generates all tags in the tag set .</sentence>
				<definiendum id="0">Tag Dictionary</definiendum>
				<definiens id="0">generates all tags in the tag set</definiens>
			</definition>
			<definition id="5">
				<sentence>The running time of the parameter estimation algorithm is O ( NTA ) , where N is the training set size , T is the number of allowable tags , and A is the average number of features that are active for a given event ( h , t ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the number of allowable tags</definiens>
			</definition>
			<definition id="6">
				<sentence>The running time of the search procedure on a sentence of length N is O ( NTAB ) , where T , A are defined above , and B is the beam size .</sentence>
				<definiendum id="0">T</definiendum>
				<definiendum id="1">B</definiendum>
				<definiens id="0">the beam size</definiens>
			</definition>
			<definition id="7">
				<sentence>The total accuracy is higher , implying that the singly-annotated training and test sets are more consistent , and the improvement due to the specialized features is higher than before ( .1 % ) but still modest , implying that either the features need further improvement or that intra-annotator inconsistencies exist in the corpus .</sentence>
				<definiendum id="0">total accuracy</definiendum>
				<definiens id="0">the singly-annotated training and test sets</definiens>
				<definiens id="1">further improvement or that intra-annotator inconsistencies exist in the corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>Comparison With Previous Work Most of the recent corpus-based POS taggers in the literature are either statistically based , and use Markov Model ( Weischedel et al. , 1993 , Merialdo , 1994 ) or Statistical Decision Tree ( Jelinek et al. , 1994 , Magerman , 1995 ) ( SDT ) techniques , or are primarily rule based , such as Drill 's Transformation Based Learner ( Drill , 1994 ) ( TBL ) .</sentence>
				<definiendum id="0">Markov Model</definiendum>
				<definiens id="0">Weischedel et al. , 1993 , Merialdo , 1994 ) or Statistical Decision Tree ( Jelinek et al. , 1994 , Magerman , 1995 ) ( SDT ) techniques , or are primarily rule based</definiens>
			</definition>
			<definition id="9">
				<sentence>The single-annotator Development Set is the portion of the Development Set which has also been annotated by `` maryann '' .</sentence>
				<definiendum id="0">single-annotator Development Set</definiendum>
				<definiens id="0">the portion of the Development Set which has also been annotated by `` maryann ''</definiens>
			</definition>
			<definition id="10">
				<sentence>TBL is a non-statistical approach to POS tagging which also uses a rich feature representation , and performs at a total word accuracy of 96.5 % and an unknown word accuracy of 85 % .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">a non-statistical approach to POS tagging which also uses a rich feature representation</definiens>
			</definition>
			<definition id="11">
				<sentence>unlike MaxEnt , can not be used as a probabilistic component in a larger model .</sentence>
				<definiendum id="0">MaxEnt</definiendum>
				<definiens id="0">a probabilistic component in a larger model</definiens>
			</definition>
</paper>

		<paper id="0203">
			<definition id="0">
				<sentence>( Brill and Resnik , 1994 ) use transformationbased error-driven learning ( Brill , 1992 ) to derive disambiguation rules based on simple context information ( e.g. right and left adjacent words or POSs ) .</sentence>
				<definiendum id="0">POSs</definiendum>
				<definiens id="0">transformationbased error-driven learning ( Brill , 1992 ) to derive disambiguation rules based on simple context information ( e.g. right and left adjacent words or</definiens>
			</definition>
			<definition id="1">
				<sentence>To conduct the experiment , we used a shallow syntactic analyzer ( SSA ) ( Basili et al , 1994 ) to extract word associations from two very different corpora in Italian ( a scientific corpus of environmental abstracts , called ENEA , and a legal corpus on taxation norms , called LD ) 2 Given a corpus , SSA produces an extensive database of elementary syntactic links ( esl ) .</sentence>
				<definiendum id="0">SSA</definiendum>
				<definiens id="0">syntactic analyzer ( SSA ) ( Basili et al , 1994 ) to extract word associations from two very different corpora in Italian ( a scientific corpus of environmental abstracts</definiens>
				<definiens id="1">produces an extensive database of elementary syntactic links ( esl )</definiens>
			</definition>
			<definition id="2">
				<sentence>An esl has the following structure : esl ( h , mod ( p , w ) ) , where h is the head of the underlying phrasal structure and rood ( p , w ) denotes the head modifier , and w as the modifier head .</sentence>
				<definiendum id="0">h</definiendum>
				<definiendum id="1">w )</definiendum>
				<definiens id="0">the head modifier</definiens>
			</definition>
			<definition id="3">
				<sentence>The definition of Collision Set ( CS ) is the following : DEF ( Collision Set ) : A Collision Set ( CS ) is the set of syntactic groups , derived from a given sentence that share the same modifier , mod O. To smooth the weight of ambiguous esl 's in lexical learning , each detected esl is weighted by a measure called plausibility .</sentence>
				<definiendum id="0">Collision Set ( CS )</definiendum>
				<definiens id="0">the set of syntactic groups , derived from a given sentence that share the same modifier</definiens>
			</definition>
			<definition id="4">
				<sentence>If the Mutual Information is high , it means that the measured phenomena ( productive word tuples ) do not independently occur in collision sets , i.e. they systematically occur in reciprocal ambiguity in the corpus .</sentence>
				<definiendum id="0">Mutual Information</definiendum>
				<definiens id="0">productive word tuples ) do not independently occur in collision sets</definiens>
			</definition>
			<definition id="5">
				<sentence>The average Mutual Information was evaluated by first computing , in the standard way , the Mutual Information of all the pairs of esl 's that co-occurred in at least one collision set : Prob ( esli , eslj ) Mr ( est , , esl~ ) = log2 Prob ( esl~ ) Prob ( esl~ ) ( 1 ) where the probability is evaluated over the space of collision sets with cardinality &gt; 1 .</sentence>
				<definiendum id="0">Mutual Information</definiendum>
				<definiens id="0">the probability is evaluated over the space of collision sets with cardinality &gt; 1</definiens>
			</definition>
			<definition id="6">
				<sentence>Given an esl , the value of its corresponding MCPl is defined by the following : DEF ( Mutual Conditioned Plausibility ) : The Mutual Conditioned Plausibility ( MCP1 ) of a prepositional attachment esl ( w , mod ( p , n ) ) , is : M C Pl ( esl ( w , rood ( p , n ) ) = ~yer pl ( esl ( w , mod ( p , y ) ) ) ~vh , yer pl ( esl ( h , mod ( p , y ) ) ) ~v~ pl ( esl ( w , mod ( p , y ) ) ) ( 2 ) where F is the high level semantic tag assigned to the modifier n and pl 0 is the plausibility function .</sentence>
				<definiendum id="0">Pl ( esl</definiendum>
				<definiendum id="1">pl ( esl</definiendum>
				<definiendum id="2">mod</definiendum>
				<definiendum id="3">F</definiendum>
				<definiens id="0">the following : DEF ( Mutual Conditioned Plausibility ) : The Mutual Conditioned Plausibility ( MCP1 ) of a prepositional attachment esl ( w , mod ( p , n ) ) , is : M C</definiens>
				<definiens id="1">p , y ) ) ) ~vh , yer pl ( esl ( h , mod ( p , y ) ) ) ~v~</definiens>
			</definition>
			<definition id="7">
				<sentence>After the first scan of the corpus by means of the SSA grammar , the corpus is re-written as a set of possibly ambiguous Collision Sets , i.e. if C is the corpus and CSi a Collision Set , we have : C = CSo U CSx U ... W CS~ U ... CSN CSiNCSj= { O } , fori¢j , i , j=O , 1,2 , ... N where N is the total number of collision sets found in the corpus .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the corpus</definiens>
				<definiens id="1">the total number of collision sets found in the corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>C measures the Data Compression , that is the mere reduction of eis 's in the corpus .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">Compression</definiendum>
				<definiens id="0">measures the Data</definiens>
			</definition>
</paper>

		<paper id="0508">
			<definition id="0">
				<sentence>Aggregation is the process of removing redundant information during language generation while preserving the information to be conveyed .</sentence>
				<definiendum id="0">Aggregation</definiendum>
				<definiens id="0">the process of removing redundant information during language generation while preserving the information to be conveyed</definiens>
			</definition>
			<definition id="1">
				<sentence>Aggregation is an important component of text or sentence planning .</sentence>
				<definiendum id="0">Aggregation</definiendum>
			</definition>
			<definition id="2">
				<sentence>John hit Tom on Monday Tom kicked John on Tuesday John punched Tom on Wednesday Tom hit John on Thursday John hit Tom on Friday Tom kicked John on Saturday John punched Tom on Sunday unbounded iexical aggregation John fought with Tom on Monday , Tuesday , Wednesday , Thursday , Friday , Saturday and Sunday ~ bounded lexieal aggregation John fought with Tom all week Figure 1 .</sentence>
				<definiendum id="0">Thursday</definiendum>
				<definiens id="0">John hit Tom on Monday Tom kicked John on Tuesday John punched Tom on Wednesday Tom hit John on Thursday John hit Tom on Friday Tom kicked John on Saturday John punched Tom on Sunday unbounded iexical aggregation John fought with Tom on Monday , Tuesday , Wednesday ,</definiens>
			</definition>
			<definition id="3">
				<sentence>We implemented three aggregation rules ( the Subject-Predicate and Predicate-Direct-Object ( Syntactic ) aggregation rules and the Bounded Lexical aggregation rule ) ; also to control the order of input clauses , we created three ordering rules .</sentence>
				<definiendum id="0">aggregation rules</definiendum>
				<definiens id="0">the Subject-Predicate and Predicate-Direct-Object ( Syntactic ) aggregation rules and the Bounded Lexical aggregation rule</definiens>
			</definition>
</paper>

		<paper id="0416">
			<definition id="0">
				<sentence>V is the visitor , and C is the curator .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the visitor , and</definiens>
			</definition>
			<definition id="1">
				<sentence>ALFRESCO uses general generation methods for the first screen produced , but canned representations for the other nodes accessible by hyperlinks .</sentence>
				<definiendum id="0">ALFRESCO</definiendum>
				<definiens id="0">uses general generation methods for the first screen produced</definiens>
			</definition>
			<definition id="2">
				<sentence>IDAS uses a number of intermediate forms that mix canned text with standard knowledge representations .</sentence>
				<definiendum id="0">IDAS</definiendum>
				<definiens id="0">uses a number of intermediate forms that mix canned text with standard knowledge representations</definiens>
			</definition>
			<definition id="3">
				<sentence>PEBA-II and PIGLIT have no discourse modelling , whereas ALFRESCO uses it within the first generated node only .</sentence>
				<definiendum id="0">PEBA-II</definiendum>
				<definiens id="0">no discourse modelling , whereas ALFRESCO uses it within the first generated node only</definiens>
			</definition>
			<definition id="4">
				<sentence>IDAS tracks the discourse history , but only within the current hypertext node being generated .</sentence>
				<definiendum id="0">IDAS</definiendum>
				<definiens id="0">tracks the discourse history , but only within the current hypertext node being generated</definiens>
			</definition>
</paper>

		<paper id="0202">
			<definition id="0">
				<sentence>A traditional context-free grammar ( CFG ) is a four-tuple G = ( N , ~ , P , S ) , where N is a finite set of nonterminal symbols , ~ is a finite set of terminal symbols such that N N ~ = O , p is a finite set of productions and S E N is a special designated start symbol .</sentence>
				<definiendum id="0">traditional context-free grammar ( CFG )</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">p</definiendum>
				<definiens id="0">a four-tuple G = ( N , ~ , P , S ) , where</definiens>
				<definiens id="1">a finite set of nonterminal symbols</definiens>
				<definiens id="2">a finite set of productions and S E N is a special designated start symbol</definiens>
			</definition>
			<definition id="1">
				<sentence>The difficulty that ordinary CFGs have with complex compounding phenomena can be seen from the following example grammar fragment : Here , RelPh is a relative phrase , Nom is a nominalization ( similar to a gerund ) , vn is lexical verb category requiring an NP argument , and ~J ( de ) is a genitive particle .</sentence>
				<definiendum id="0">RelPh</definiendum>
				<definiendum id="1">Nom</definiendum>
				<definiens id="0">a relative phrase</definiens>
				<definiens id="1">a nominalization ( similar to a gerund )</definiens>
				<definiens id="2">a genitive particle</definiens>
			</definition>
			<definition id="2">
				<sentence>The difference between the two phrases is that although ~-~ '' and ~ are both location nouns , not all NPs following a ~ can be formed into locative phrase -- only if the head noun of the NP is a location noun can it can be parsed as a locative phrase .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">a locative phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>We have rules and localion_noun -- -* np/gJGE location_noun -- -+ nc/g~GE where GE is the abbreviation of geology .</sentence>
				<definiendum id="0">GE</definiendum>
				<definiens id="0">the abbreviation of geology</definiens>
			</definition>
			<definition id="4">
				<sentence>Weighted constituent precision , i.e. , the percentage of incorrectly identified syntactic constituents .</sentence>
				<definiendum id="0">Weighted constituent precision</definiendum>
				<definiens id="0">the percentage of incorrectly identified syntactic constituents</definiens>
			</definition>
			<definition id="5">
				<sentence>( nounph ( noun ( nc A : \ [ = ) ) ) ) ( verbph ( verbph ( vi2 ( vadv ~¢~ ) ( vi2 ( vadv f~ ) ( vi2 g~ ) ) ) ) ( cjw ~ ) ( verbph ( vn ( vadv ~t ) J ) ( vn ~J~ ) ) ( nounph ( assocph ( nounph ( noun ( nc ~ ) ) ( noun ( nc 7~ ) ) ) ~J ) ( nounph ( noun ( nc ~ ) ~ ) ) ) ) ) ) ) o ( clause ( clause ( clause ( nounph ( noun ( up *A ) ) ) ( verbph ( vnv { ~ ) ( nounph ( noun ( nc ~a ) ) ) ( verbph ( vv ~-~ ) ( verbph ( covph ( p ~ ) ( nounph ( nounph ( noun ( nc ~ -- ~ ) ) ( noun ( nc ~ ) ) ) ) ) ( verbph ( vv 5~ ) ( verbph ( vn } ~ ) ( nounph ( noun ( he ~ ) ) ) ) ) ) ) ) ) ( punc , ) ( clause ( verbph ( advph ( sadv ~ ) ) ( verbph ( vn { @ ~ ) ( nounph ( noun ( nc ~tJ~y~ ) ) ) ) ) ) ) ( punc , ) ' ( clause ( verbph ( vnv { E ) ( nounph ( noun ( nc ~t~ ) ) ) ( verbph ( eovph ( p ~ ) ( nounph ( noun ( nc ~-~ ) ) ) ) ( verbph ( vi2 ~ ) ) ) ) ) ) ( nounph ( noun ( nc ~ ) ) ) , ( clause ( nounph ( noun ( nc Y/ ) ) ) ( verbph ( vn \ ] J~ ) ( nounph ( noun ( nc ~ ) ) ) ) ) ( nounph ( modph ( attrph ( aa ( a i~ ) ) ~ ) ) ( nounph ( modph ( aa ( vil -~ , .</sentence>
				<definiendum id="0">nc ~t~ ) ) ) ( verbph ( eovph</definiendum>
				<definiens id="0">a i~ ) ) ~ ) ) ( nounph ( modph ( aa ( vil -~ ,</definiens>
			</definition>
</paper>

		<paper id="0311">
			<definition id="0">
				<sentence>The most difficult issue in derivations is the semantic composition , For instance , the -CI morpheme ( with allomorph s -ct/-ci/-cu/-cii/-ft/-fi/-~u/-fii ) adds the meaning `` doer/user of something '' ( 7a ) , `` seller/lover of something '' ( 7b ) , or habitual ( 7c ) .</sentence>
				<definiendum id="0">-CI morpheme</definiendum>
				<definiens id="0">the semantic composition</definiens>
			</definition>
			<definition id="1">
				<sentence>There are other linguistic phenomena that are on the boundary of lexicon and syntax , which we opted to contain in the lexicon , e.g. , non-referential objects , and valency change in the causatives .</sentence>
				<definiendum id="0">syntax</definiendum>
				<definiens id="0">non-referential objects , and valency change in the causatives</definiens>
			</definition>
</paper>

		<paper id="0507">
			<definition id="0">
				<sentence>AlethGen is an industrial toolbox that uses several techniques in a hybrid way , i.e. it has several modules which can be integrated and used in different ways to meet different applications ' requirements .</sentence>
				<definiendum id="0">AlethGen</definiendum>
				<definiens id="0">an industrial toolbox that uses several techniques in a hybrid way , i.e. it has several modules which can be integrated and used in different ways to meet different applications ' requirements</definiens>
			</definition>
			<definition id="1">
				<sentence>The AlethGen Generation Grammar is composed of several sets of rules , defining the transition between the different levels of representation : Events - &gt; Semantic - &gt; Deep Syntactic - &gt; Surface Syntactic - &gt; Morphology .</sentence>
				<definiendum id="0">AlethGen Generation Grammar</definiendum>
				<definiens id="0">Events - &gt; Semantic - &gt; Deep Syntactic - &gt; Surface Syntactic - &gt; Morphology</definiens>
			</definition>
			<definition id="2">
				<sentence>MultiMeteo is a 3-year project funded partially by the Language Engineering programme of the European Commission .</sentence>
				<definiendum id="0">MultiMeteo</definiendum>
			</definition>
</paper>

		<paper id="0401">
			<definition id="0">
				<sentence>The task of the sP is to transform selected , not necessarily consecutive , plans ( which may vary in detail , from text plans specifying only content and discourse organization to fine-grained but incohesive , sentence plans ) into completely specified specifications for the surface generator .</sentence>
				<definiendum id="0">sP</definiendum>
				<definiens id="0">plans ( which may vary in detail , from text plans specifying only content and discourse organization to fine-grained but incohesive , sentence plans ) into completely specified specifications for the surface generator</definiens>
			</definition>
			<definition id="1">
				<sentence>invokes modules , updates pre-sPL expressions , manages parallel alternative expressions , etc. matches the left-hand sides of tree transforaWe also foresee an Ordering module .</sentence>
				<definiendum id="0">etc.</definiendum>
				<definiens id="0">matches the left-hand sides of tree transforaWe also foresee an Ordering module</definiens>
			</definition>
			<definition id="2">
				<sentence>Each operator has a different effect on the fragment ( s ) of pre-SPL that match its left hand side : RBWRIT~ alters its content or structure , ADD adds new information but alters nothing , and SUPPLANT replaces the matched portion with something else ( see \ [ Jakeway et al. , 1996\ ] ) .</sentence>
				<definiendum id="0">ADD</definiendum>
				<definiendum id="1">SUPPLANT</definiendum>
				<definiens id="0">new information but alters nothing , and</definiens>
			</definition>
			<definition id="3">
				<sentence>The Sentence Structuring module determines the structure of the sentences to be encoded in the SPL .</sentence>
				<definiendum id="0">Sentence Structuring module</definiendum>
				<definiens id="0">determines the structure of the sentences to be encoded in the SPL</definiens>
			</definition>
			<definition id="4">
				<sentence>The Content Delimitation module determines the material to be included into each separate SPL expression .</sentence>
				<definiendum id="0">Content Delimitation module</definiendum>
			</definition>
</paper>

		<paper id="0204">
			<definition id="0">
				<sentence>In this paper , we describe annotations to the Switchboard corpus which add part of speech and dysfluency markings and our latest work using those annotations to create a level of generalization on top of the annotation to capture the structure of conversational speech .</sentence>
				<definiendum id="0">Switchboard</definiendum>
				<definiens id="0">corpus which add part of speech and dysfluency markings and our latest work using those annotations to create a level of generalization on top of the annotation to capture the structure of conversational speech</definiens>
			</definition>
			<definition id="1">
				<sentence>The Switchboard corpus ( Godfrey , et al. 1992 ) consists of 2 million words of conversational English collected over the phone by having strangers chat with one another about 70 different topics ranging from pets and family life to education and gun control .</sentence>
				<definiendum id="0">Switchboard corpus</definiendum>
				<definiens id="0">consists of 2 million words of conversational English collected over the phone by having strangers chat with one another about 70 different topics ranging from pets and family life to education and gun control</definiens>
			</definition>
			<definition id="2">
				<sentence>The interruption point ( IP ) markes the end of the reparandum and it is followed by an optional interregnum ( IM ) , which includes editing phases , such as a filled pause or editing terms .</sentence>
				<definiendum id="0">interruption point ( IP</definiendum>
				<definiens id="0">the end of the reparandum and it is followed by an optional interregnum ( IM ) , which includes editing phases , such as a filled pause or editing terms</definiens>
			</definition>
			<definition id="3">
				<sentence>Otherwise , `` oh '' is treated as a regular word unit of language if it appears by itself as a reply , as in Example 3 .</sentence>
				<definiendum id="0">oh</definiendum>
				<definiens id="0">a regular word unit of language if it appears by itself as a reply</definiens>
			</definition>
			<definition id="4">
				<sentence>`` Yeah '' ( row 13 ) occurs almost exclusively in the NPC set , which is comprised mainly of replies .</sentence>
				<definiendum id="0">Yeah</definiendum>
				<definiens id="0">occurs almost exclusively in the NPC set , which is comprised mainly of replies</definiens>
			</definition>
			<definition id="5">
				<sentence>Frequencies In Before , In After , not not in After in Before 1 877 5328 2 114 1938 3-5 40 1202 6-10 1 381 11-50 0 217 51-100 0 24 100+ ( max 214 ) 0 6 Total ( diffe~nt words ) 1028 9944 Total ( instances ) 1254 30131 .046 % 7 % % ofcorpus Table 8 : Vocabulary Differences in Before Pivot and After Pivot Sentence Parts 43 taken 222 forget 93 notice 75 sold 62 teach 185 expect 90 bother 74 continue 60 suppose 133 quit 89 moving 74 became 59 played 131 follow 85 died 73 mentioned 55 caught 129 wondering 80 selling 70 prefer 54 rid 112 helping 79 choose 68 drove 52 telling 105 born 76 considered 67 depending 52 write 97 stopped 75 covered 62 trust 51 happening 94 notice 75 staying 62 pickin£ 51 Table 9 : Words occurring more than 50 times in the After Pivot sentence parts and not at all in the Before Pivot parts Table 9 shows the actual words and counts for those words occurring over fifty times in the after corpus and not at all in the before part .</sentence>
				<definiendum id="0">Total</definiendum>
				<definiens id="0">Vocabulary Differences in Before Pivot and After Pivot Sentence Parts 43 taken 222 forget 93 notice 75 sold 62 teach 185 expect 90 bother 74 continue 60 suppose 133 quit 89 moving 74 became 59 played 131 follow 85 died 73 mentioned 55 caught 129 wondering 80 selling 70 prefer 54 rid 112 helping 79 choose 68 drove 52 telling 105 born 76 considered 67 depending 52 write 97 stopped 75 covered 62 trust 51 happening 94 notice 75 staying 62 pickin£ 51 Table 9 : Words occurring more than 50 times in the After Pivot sentence parts and not at all in the Before Pivot parts Table 9 shows the actual words and counts for those words occurring over fifty times in the after corpus and not at all in the before part</definiens>
			</definition>
			<definition id="6">
				<sentence>Perplexity gives a rough indication of the average number of alternatives in the grammar based on the computation of the entropy .</sentence>
				<definiendum id="0">Perplexity</definiendum>
				<definiens id="0">gives a rough indication of the average number of alternatives in the grammar based on the computation of the entropy</definiens>
			</definition>
			<definition id="7">
				<sentence>NPI ( incomplete segments that were interrupted before the verb ) are most likely to be followed by the end of a turn ( TE ) .</sentence>
				<definiendum id="0">NPI</definiendum>
				<definiens id="0">incomplete segments that were interrupted before the verb ) are most likely to be followed by the end of a turn ( TE )</definiens>
			</definition>
</paper>

		<paper id="0304">
			<definition id="0">
				<sentence>F-H is an experimental inferencing item in which an examinee is presented with a short passage ( about 30 words ) in which a hypothetical situation is described , and s/he composes up to 15 hypotheses that could explain Why the situation exists .</sentence>
				<definiendum id="0">F-H</definiendum>
				<definiens id="0">an experimental inferencing item in which an examinee is presented with a short passage ( about 30 words ) in which a hypothetical situation is described</definiens>
			</definition>
</paper>

		<paper id="0410">
			<definition id="0">
				<sentence>Words come in a variety of conventional combinations ; these units range from short expressions with idiosyncratic meanings , like the call number of a book , to full sentences with compositionallyderived , yet frozen , meanings , like You ca n't teach an old dog new tricks .</sentence>
				<definiendum id="0">Words</definiendum>
				<definiens id="0">come in a variety of conventional combinations</definiens>
			</definition>
			<definition id="1">
				<sentence>Second , COLLOCATIONS PROPER involve constituents whose meaning is determined by ordinary principles , like copy area , but which must be regarded as conventional in light of the oddness of near synonyms ( like duplication zone ) ; such collocations are the subject of the Lexical Functions of the Meaning-Text Theory ( MTT ) ( Mel'~uk and Polgu~re , 1987 ) .</sentence>
				<definiendum id="0">Meaning-Text Theory ( MTT )</definiendum>
				<definiens id="0">involve constituents whose meaning is determined by ordinary principles , like copy area , but which must be regarded as conventional in light of the oddness of near synonyms ( like duplication zone ) ; such collocations are the subject of the Lexical Functions of the</definiens>
			</definition>
			<definition id="2">
				<sentence>\ [ = ( Nunberg et al. , 1994 ) 10c\ ] Semantic collocations recover their parameters based simply on the things described , regardless of their syntactic proximity , as the examples in ( 5 ) show : ( 5 ) a I will not check out a long book .</sentence>
				<definiendum id="0">Semantic</definiendum>
				<definiens id="0">collocations recover their parameters based simply on the things described , regardless of their syntactic proximity</definiens>
			</definition>
			<definition id="3">
				<sentence>A TAG grammar consists of a finite set of ELEMENTARY trees , which can be combined by these operations to produce derived trees recognized by the grammar .</sentence>
				<definiendum id="0">TAG grammar</definiendum>
				<definiens id="0">consists of a finite set of ELEMENTARY trees , which can be combined by these operations to produce derived trees recognized by the grammar</definiens>
			</definition>
			<definition id="4">
				<sentence>First , as originally advocated by Hobbs ( 1985 ) , we adopt an ONTOLOGICALLY PROMISCUOUS representation that includes a wide variety of types of entities .</sentence>
				<definiendum id="0">ONTOLOGICALLY PROMISCUOUS representation</definiendum>
				<definiens id="0">includes a wide variety of types of entities</definiens>
			</definition>
			<definition id="5">
				<sentence>, , N* \ [ about : &lt; lq NP.L \ [ about : ? , ? , .-er\ ] VP\ [ about : &lt; 1~ syntax V \ [ \ ] NP \ [ about : &lt; 2~ concerns ( l : INFO , S : STATE , I I X : IND , syntax : INb ) /have./ t \ [ always applicable\ ] have ( l : lNFO , H : STATE , H-er : IND , H-ee : INg ) ( b ) ( in-poset ( H-ee ) , in-op ( have ( I , H , H-er , H-ee ) ) ) ( c ) Figure 1 : LTAG trees with semantic and pragmatic specifications collection of entities ( this is inspired by a similar hypothesis in ( Jackendoff , 1990 ) ) . To guarantee a coherent meaning for a derived structure , a node about x can only substitute or adjoin into another node about x. Here , we simply use an additional feature on the node to capture this. Figure 1 also shows the semantics and about labels for each tree ; ? indicates unspecified about values. To package information appropriately requires sensitivity to the knowledge of the hearer and the state of the discourse. Different constructions make different assumptions about the status of entities and propositions. We model these differences by including in each tree a specification of the contextual conditions under which use of the tree is pragmatically licensed. Our conditions derive from linguistic analysis , particularly ( Gundel et al. , 1993 ; Ward , 1985 ; Ward and Prince , 1991 ; Prince , 1993 ; Birner , 1992 ) . The status of entities and propositions in discourse varies along at least four dimensions that are relevant to these specifications. First , entities differ in NEWNESS ( Prince , 1981 ) . At any point , an entity is either new or old to the HEARER , according to whether or not the hearer has at least implicit knowledge of the existence of the entity. Analogously , an entity is either new or old to the DISCOURSE , according to whether the discourse contains an earlier reference to it. Second , entities differ in SALIENCE ( Grosz and Sidner , 1986 ; Grosz et al. , 1995 ) . At any point , salience assigns each entity a position in a partial order that indicates how accessible it is for reference in the current context. Third , entities are related by material PARTIALLY-ORDERED SET ( POSET ) RELATIONS to other entities in the context ( Hirschberg , 1985 ) . These relations include part and whole , subset and superset , and membership in a common class ; a number of constructions depend on poset relations to signal their connection with context. Finally , the discourse may distinguish some OPEN PROPOSITIONS , propositions containing free variables , as being under discussion ( Halliday , 1967 ; Prince , 1986 ) . This privileges subsequent information that provides true instantiations for the variables in a salient open proposition. We assume that information of these four kinds is available in a model of the current discourse state , and that the applicability conditions of constructions can freely make reference to this information. The pragmatic specification for the book , syntax , and topicalized have appear under the semantics for each tree in figure 1. Our discourse model contains information on the shared knowledge of the speaker and hearer , private knowledge of the speaker , and a specification of entities and their discourse status. In the library domain , shared knowledge includes such things as rules about how to check out books , while speaker knowledge includes such information as the status of books in the library. The discourse model can also include general properties that describe the conversational situation as a whole ; for example , it might specify the formality of the register in which the communication is being conducted. Our system takes two types of goals. First , goals of the form identify x as cat instruct the algorithm to construct a description of entity x using the syntactic category cat. If x is uniquely identifiable , then this goal is only satisfied when the overall content planned so far distinguishes x for the hearer. Ifx is hearer new , this goal is satisfied by including any constituent of type cat. Sec94 ond , goals of the form communicate p instruct the algorithm to include the proposition p. This goal is satisfied as.long as the overall content ENTAILS p given the shared knowledge of speaker and hearer. In each iteration , our algorithm must determine the appropriate elementary tree to incorporate into the current description. It performs this task in two steps to take advantage of the regular associations between semantics and trees in the lexicon. Lexical entries pair a semantic constraint with a FAMILY of TREES that describe the combinatory possibilities for realizing the semantics. For example , book is stored with a tree family that includes a book and the book. We have chosen to include the determiners in the basic NP trees because of their importance for the semantics and pragmatics of the NP. Similarly , there are different initial trees for each clause type anchored by a particular verb. Trees in the tree family are shared among all lexical items that share a particular structure. This allows us to specify the pragmatic constraints associated with the tree type once and for all , regardless of which verb selects it. Moreover , we can determine which tree to use by looking at each tree ONCE , even when the same tree is associated with multiple lexical items. Hence , the first step is to identify applicable lexical entries : these items must correctly describe some entity ; they must anchor trees that can substitute or adjoin into a node that describes the entity ; and they must contribute toward satisfying current goals. ( We describe more precisely how this contribution is evaluated in section 4.1 . ) Then , the second step identifies which of the associated trees are applicable , by testing their pragmatic conditions against the current representation of discourse. We combine possible lexical items and possible trees , to give an evaluation of all applicable options. The algorithm identifies the entries that most contribute to current goals , and from these , selects the entry with the most specific semantic and pragmatic licensing conditions. This means that the algorithm generates the most marked licensed form for the particular context. The entry is then substituted or adjoined into the tree at the appropriate node. The meaning of the derived tree is simply the CONJUNCTION of the meanings of the elementary trees used to derive it. The entry may specify additional goals , because it describes one entity in terms of a new one. These new goals are added to the current goals , and then the algorithm repeats. The strength of the present work is that it captures a number of phenomena discussed elsewhere separately , and does so within the unified framework of description. In particular , we treat many types of content as contributing to expressions that refer to semantic objects. The tenses of sentences in discourse refer to times in much the same way pronouns and full NPs refer to individuals ( Partee , 1973 ; Partee , 1984 ) . The modality of sentences may refer to a salient possibility ( Roberts , 1986 ) or provide the content of a salient psychological state ( Wiebe , 1994 ) . The rhetorical connection between a sentence and surrounding discourse should also be described with adjuncts ( Huang , 1994 ) . Adjuncts giving details about an event should be included only after reasoning that these adjuncts are in fact necessary in context ( McDonald , 1992 ) . With its incremental choices and its emphasis on the consequences of functional choices in the grammar , our algorithm resembles the networks of systemic grammar ( Mathiessen , 1983 ; Yang et al. , 1991 ) . However , unlike systemic networks , our system derives its functional choices dynamically using a simple declarative specification of function that correlates well with recent linguistic work. Further , like many sentence planners , we assume that there is a flexible association between the content input to a sentence planner and the meaning that comes out. Other researchers ( Nicolov et al. , 1995 ; Rubinoff , 1992 ) have assumed that this flexibility comes from a mismatch between input content and grammatical options. In our system , such differences arise from the referential requirements and inferential opportunities that are encountered. Previous authors ( McDonald and Pustejovsky , 1985 ; Joshi , 1987 ) have noted that TAG has many advantages for generation as a syntactic formalism , because of its localization of argument structure. These aspects of TAGs are crucial for us. Lexicalization allows us to easily specify local semantic and pragmatic constraints imposed by the lexical item in a particular syntactic frame. Various efforts at using TAG for generation ( McDonald and Pustejovsky , 1985 ; Joshi , 1987 ; Yang et al. , 1991 ; Nicolov et al. , 1995 ; Wahlster et al. , 1991 ) enjoy many of these advantages. Furthermore , ( Shieber et al. , 1990 ; Shieber and Schabes , 1991 ; Prevost and Steedman , 1993 ; Hoffman , 1994 ) exploit similar benefits of lexicalization and localization. What sets SPUD apart is its simultaneous construction of syntax and semantics , and the tripartite , lexicalized , declarative gram95 matical specifications for constructions it uses. ( Shieber et al. , 1990 ; Shieber and Schabes , 1991 ) construct a simult .~eous derivation of syntax and semantics -- but they do not construct the semantics : it is an input to their system. Moreover , they do not represent any pragmatic inforrnatiGn. ( Prevost and Steedman , 1993 ; Hoffman , 1994 ) do represent the division of sentences into theme and rheme , but because they do not model the pragmatics of particular constructions , they plan descriptions in a separate step. Because LTAG can associate multiple iexical items to a single tree , it is straightforward to list frozen idioms , like call number , in the lexicon ( Abeille and Schabes , 1989 ) . These specifications can include idiosyncratic semantic and pragmatic information ; grammatical processes like tense marking apply normally. In this section , we describe how SPUD can be made to use words in other conventional combinations. Our proposal involves three steps. First , as in ( Reiter and Dale , 1992 ) , we stipulate that some attributes of entities are more important than others , and that some words more naturally describe those attributes. Second , in keeping with ontological promiscuity ( Hobbs , 1985 ) , we represent the importance of attributes by the salience of events and states in the discourse model -- these states and events now have the same status in the discourse model as any other entities. Finally , we extend SPUD 's evaluation of alternatives , so that it describes the most salient entities possible , and uses basic-level terms wherever possible. By associating entities not just with salient attributes but also with salient actions and salient figurations , we capture collocations , semantic collocations and idiomatic compositionality using a uniform mechanism. Although primarily concerned with the interpretation of Gricean maxims , the work of ( Reiter and Dale , 1992 ; Dale and Reiter , 1995 ) underlines the conventionality of description. Based on a review of psychological experimentation and their own study of referring expressions in task-oriented dialogue , they argue that some referring expressions can be constructed simply by selecting properties from a prioritized list of attributes until the entity is distinguished. To further conventionalize descriptions , they privilege the selection of properties that provide basic-level characterizations of the entity ( Rosch , 1978 ; Reiter , 199l ) . Because any property is considered for only one attribute , this algorithm offers a linear speedup over the greedy strategy used in ( Dale and Haddock , 1991 ) and described above for SPUD , which considers every property at every stage. However , here we focus on how incorporating similar ideas into SPUD gives a general framework for specifying conventional uses of words , and remain neutral about achieving similar speedups. Reiter and Dale suggest that the prioritized list of attributes their algorithm uses is domaindependent. In fact , we find that these lists are both domain and object-dependent. Obviously the attributes by which we describe abstractions like events and states -- typically time , location , and manner or quality -- are quite distinct from the natural attributes by which physical objects are distinguished. However , in the library , widely different attributes can be appropriate even for physical objects of various types. Books can be described by author , by physical characteristics , or by content ( e.g. Chomsky ~ book ; the yellow book , a math book ) . Periodicals , meanwhile , are best described by date of issue ( e.g. the May issue of Language ) . Parts of the library , as we shall see below , are best distinguished by the special services they provide ( e.g. the reference desk ) . SPUD 's ontologically promiscuous discourse model offers a natural dimension to represent these distinctions. Since each property of an object is associated with an eventuality argument , we can assign a level of salience for that eventuality. We can use this ranking to indicate the conventional importance of the eventuality in distinguishing the object. In other words , if we know p ( e , x ) , and it is natural to describe x in terms of p , e will be salient. For example , since periodicals are easily identified by their date of issue , we should make this state salient. Note then that salience is determined for explicitly mentioned and inferable entities and depends not only on recency of mention but also on facts about the conversational situation and real-world relationships between objects. Reiter and Dale also point out that which characterizations are basic-level must be adjusted to reflect the expertise of the addressee ; however , we shall sidestep this issue here by assuming that certain lexical items are simply listed as basiclevel terms. By itself , these additions are not enough : SPUD must also take salience and basic-level semantics into account in the evaluation of its alternatives. That is : other things being equal , SPUD should choose to incorporate at each stage the 96 syntactic-semantic-pragmatic unit which refers to maximally salient entities ; and , other things being equal , SPUD should incorporate a basic-level predicate. Integrating Reiter and Dale 's prioritization of these considerations with SPUD 's other considerations leads to the following ranking of criteria for comparison : ( 7 ) RULES OUT A DISTRACTOR OR ENTAILS NEEDED INFORMATION &gt; SALIENCE OF ENTITIES MENTIONED &gt; NUMBER OF DISTRACTORS RULED OUT &gt; NUMBER OF INFORMATIONAL GOALS ACHIEVED &gt; BASIC-LEVEL TERM &gt; SPECIFICITY OF LICENSING CONDITIONS With the right linguistic specification , this is all the machinery SPUD needs to generate conventionalized forms .</sentence>
				<definiendum id="0">entity</definiendum>
				<definiendum id="1">entity</definiendum>
				<definiens id="0">H-er , H-ee ) ) ) ( c ) Figure 1 : LTAG trees with semantic and pragmatic specifications collection of entities</definiens>
				<definiens id="1">contains information on the shared knowledge of the speaker and hearer , private knowledge of the speaker , and a specification of entities and their discourse status. In the library domain , shared knowledge includes such things as rules about how to check out books , while speaker knowledge includes such information as the status of books in the library. The discourse model can also include general properties that describe the conversational situation as a whole</definiens>
				<definiens id="2">the overall content ENTAILS p given the shared knowledge of speaker</definiens>
				<definiens id="3">determine the appropriate elementary tree to incorporate into the current description. It performs this task in two steps to take advantage of the regular associations between semantics and trees in the lexicon. Lexical entries pair a semantic constraint with a FAMILY of TREES that describe the combinatory possibilities for realizing the semantics. For example , book is stored with a tree family that includes a book and the book. We have chosen to include the determiners in the basic NP trees because of their importance for the semantics and pragmatics of the NP. Similarly , there are different initial trees for each clause type anchored by a particular verb. Trees in the tree family are shared among all lexical items that share a particular structure. This allows us to specify the pragmatic constraints associated with the tree type once and for all , regardless of which verb selects it. Moreover</definiens>
				<definiens id="4">to identify applicable lexical entries : these items must correctly describe some entity ; they must anchor trees that can substitute or adjoin into a node that describes the entity ; and they must contribute toward satisfying current goals. ( We describe more precisely how this contribution is evaluated in section 4.1 .</definiens>
				<definiens id="5">considers every property at every stage. However , here we focus on how incorporating similar ideas into SPUD gives a general framework for specifying conventional uses of words</definiens>
			</definition>
			<definition id="6">
				<sentence>For a photocopier , this might be specified this way : ( 1 I ) photocopier ( I , S , X ) 3 ( participant ( I , S 1 ( X ) , X , copy-action ) A participant ( I , S2 ( X ) , X , repair-action ) A participant ( I , S3 ( X ) , X , fill-paper-action ) A SI ( X ) &gt; s S2 ( X ) &gt; s S3 ( X ) ) That is , typically , with copiers , you not only make copies , but also fill them with paper , and ( sadly , all too often ) , have them repaired ; however , copying is the most salient thing to do with them .</sentence>
				<definiendum id="0">( sadly</definiendum>
				<definiens id="0">fill-paper-action ) A SI ( X ) &gt; s S2 ( X ) &gt; s S3 ( X ) ) That is , typically , with copiers , you not only make copies , but also fill them with paper , and</definiens>
			</definition>
			<definition id="7">
				<sentence>To see how SPUD uses these specifications , let us say that we have a copier , c42 , which is the sole fast copier ( at making copies ) in the library .</sentence>
				<definiendum id="0">SPUD</definiendum>
				<definiens id="0">at making copies ) in the library</definiens>
			</definition>
			<definition id="8">
				<sentence>( 13 ) strings ( bp ( k , C ) , S4 ( k , C ) , C ) A pull ( bp ( k , C ) , E , X , C ) Now we just use the ordinary meanings of pull and strings to describe this situation .</sentence>
				<definiendum id="0">pull</definiendum>
				<definiens id="0">the ordinary meanings of pull and strings to describe this situation</definiens>
			</definition>
			<definition id="9">
				<sentence>Hence , SPUD offers a natural framework for dealing with the interactions between syntax , semantics and pragmatics which characterize the sentence planning problem , and ensuring contextually appropriate output .</sentence>
				<definiendum id="0">SPUD</definiendum>
				<definiens id="0">offers a natural framework for dealing with the interactions between syntax , semantics and pragmatics which characterize the sentence planning problem</definiens>
			</definition>
			<definition id="10">
				<sentence>For different languages , SPUD 's model may vary along a number of dimensions , including the exact range of objects which roughly corresponding lexical items can describe , and the ( default ) salience rankings -- both for typical properties and actions associated with objects and for the information states licensing idioms .</sentence>
				<definiendum id="0">SPUD 's model</definiendum>
				<definiens id="0">the information states licensing idioms</definiens>
			</definition>
</paper>

		<paper id="0206">
			<definition id="0">
				<sentence>The perplexity is defined as 1 PPM ( O ' ) ~v/fi ~ The probability is normalized by taking the k th root ( k is the length of the sequence ) .</sentence>
				<definiendum id="0">PPM</definiendum>
				<definiendum id="1">k</definiendum>
				<definiens id="0">the length of the sequence )</definiens>
			</definition>
			<definition id="1">
				<sentence>Generally , there are O ( l 2 ) hypothetical merges to be tested for each merging step ( l is the length of the training corpus ) .</sentence>
				<definiendum id="0">l</definiendum>
				<definiens id="0">the length of the training corpus )</definiens>
			</definition>
</paper>

		<paper id="0415">
			<definition id="0">
				<sentence>An event including an activity is a culmination ; as an example , consider the event of oil draining from an engine , which is given here in an abbreviated KL-ONE notation ( roles names in capital letters , instance names in lower-case ) : ( event 1 ( PRE-STATE ( fill-statel ( VALUE 'not-empty ) ( CONTAINER enginel ) ( CONTENT oill ) ) ( ACTIVITY ( move-I ( OBJECT oill ) ( PATH ( pathl ( DESTIBATIO~ tankl ) ) ) ) ) ( POST-STATE ( fill-state2 ( VALUE 'empty ) ( CONTAINER enginel ) ) ) ) Figure 2 shows the overall taxonomy of situation types .</sentence>
				<definiendum id="0">event including an activity</definiendum>
				<definiendum id="1">PRE-STATE</definiendum>
				<definiendum id="2">VALUE 'empty )</definiendum>
				<definiens id="0">( fill-statel ( VALUE 'not-empty ) ( CONTAINER enginel ) ( CONTENT oill ) ) ( ACTIVITY ( move-I ( OBJECT oill ) ( PATH ( pathl ( DESTIBATIO~ tankl ) ) )</definiens>
			</definition>
			<definition id="1">
				<sentence>Furthermore , since our system takes lexicalization as the decisive task in mapping a SitSpec to a SemSpec , the UM concepts referred to in a SemSpec must be annotated with : lex expressions ; thus , a SemSpec is a lexicalized structure .</sentence>
				<definiendum id="0">SemSpec</definiendum>
				<definiens id="0">a lexicalized structure</definiens>
			</definition>
			<definition id="2">
				<sentence>Furthermore , since our system takes lexicalization as the decisive task in mapping a SitSpec to a SemSpec , the UM concepts referred to in a SemSpec must be annotated with : lex expressions ; thus , a SemSpec is a lexicalized structure .</sentence>
				<definiendum id="0">SemSpec</definiendum>
				<definiens id="0">a lexicalized structure</definiens>
			</definition>
			<definition id="3">
				<sentence>Aktionsart \ [ Denotation pattern stative ( state X ) durative ( protracted-act ivity X ) semelfactive ( moment aneous-act ivity X ) transformative ( event ( PRE-STATE X ) ( POST-STATE not-X ) ) resultative ( event ( ACTIVITY X ) ( POST-STATE Y ) causative ( activity ( CAUSER X ) ) Simple cases are stative verbs like to own or to know .</sentence>
				<definiendum id="0">Aktionsart \ [ Denotation pattern stative</definiendum>
				<definiens id="0">resultative ( event ( ACTIVITY X ) ( POST-STATE Y ) causative ( activity ( CAUSER X ) ) Simple cases are stative verbs like to own or to know</definiens>
			</definition>
			<definition id="4">
				<sentence>To compute these configurations automatically , we define an alternation or extension rule as a 5-tuple with the following components : NAM : a unique name ; DXT : extension of denor .</sentence>
				<definiendum id="0">NAM</definiendum>
				<definiendum id="1">DXT</definiendum>
				<definiens id="0">a unique name ;</definiens>
			</definition>
			<definition id="5">
				<sentence>Levin discusses a 'causative/inchoative ' alternation that , applies to a large number of verbs .</sentence>
				<definiendum id="0">Levin</definiendum>
				<definiens id="0">discusses a 'causative/inchoative ' alternation that , applies to a large number of verbs</definiens>
			</definition>
			<definition id="6">
				<sentence>|AM : durative-causative DXT : ( activity ( CAUSER X ) ) COY : ( ) ROC : ( ( : actor : actee ) ( nondirected-action directed-action ) ) HRO : ( : actor X ) §AM : resultative-causative DXT : ( event ( ACTIVITY ( X ( CAUSER Y ) ) ) ) COY : ( ) ROC : ( ( : actor : actee ) ( nondirected-action directed-action ) ) |RO : ( : actor Y ) The first rule derives , for example , Tom moved the cat from The cat moved , and the second Tom closed the door from The door closed .</sentence>
				<definiendum id="0">ACTIVITY ( X</definiendum>
				<definiens id="0">durative-causative DXT : ( activity ( CAUSER X ) ) COY : ( ) ROC : ( ( : actor : actee ) ( nondirected-action directed-action ) ) HRO : ( : actor X</definiens>
			</definition>
			<definition id="7">
				<sentence>l ) ( VALUE 'covered ) ) ) ) Figure 3 : SitSpecs for configurations of to spray fimction ONa is a derivative of ON and means that something 'distributively ' covers a surface , e.g. , the paint covers all of the wall .</sentence>
				<definiendum id="0">l ) ( VALUE 'covered</definiendum>
				<definiens id="0">a derivative of ON and means that something 'distributively ' covers a surface</definiens>
			</definition>
			<definition id="8">
				<sentence>The exact interpretation of COMPLETION-STATE is the open question that Levin \ [ 1993\ ] referred to , and that 3ackendoff treated with his 'a ' subscript .</sentence>
				<definiendum id="0">exact interpretation of COMPLETION-STATE</definiendum>
				<definiens id="0">the open question that Levin \ [ 1993\ ] referred to , and that 3ackendoff treated with his 'a ' subscript</definiens>
			</definition>
			<definition id="9">
				<sentence>( move-1 ( OBJECT water-l ) ( PATH ( path-1 ( SOURCE tank-I ) ) ) ) Note that our ducative-causative extension rule given fact has critical influence on the 'holistic ' interpretation of mass flollns , above applies in this case and extends the coverage of the SitSpec to one corresponding to Tom drained the water from the tank .</sentence>
				<definiendum id="0">OBJECT water-l ) ( PATH ( path-1</definiendum>
				<definiens id="0">extends the coverage of the SitSpec to one corresponding to Tom drained the water from the tank</definiens>
			</definition>
			<definition id="10">
				<sentence>EAH : locative/cleex-intr~msitive DXT : ( event ( MOVE ( OBJECT X ) ( PATH ( SOURCE Y ) ) ) ( POST-STATE ( Z completion-state ( OBJECT Y ) ) ) ) COY : ( Z ) ROC : ( ( : actor &lt; : of-matter &gt; ) ( : source : actor ) ) IR0 : ( ) Summary Tile extensions introduced now can apply in a sequential order to a verb .</sentence>
				<definiendum id="0">EAH</definiendum>
				<definiens id="0">locative/cleex-intr~msitive DXT : ( event ( MOVE ( OBJECT X ) ( PATH ( SOURCE Y ) ) ) ( POST-STATE ( Z completion-state ( OBJECT Y ) ) ) ) COY : ( Z ) ROC : ( ( : actor &lt; : of-matter &gt; ) ( : source : actor ) ) IR0 : ( ) Summary Tile extensions introduced now can apply in a sequential order to a verb</definiens>
			</definition>
			<definition id="11">
				<sentence>The `` double box '' in the middle is the entry point for both TRANSFORMATIVE and RESULTATIVE verbs , but the incoming arrows produce RESULTATIVE forms .</sentence>
				<definiendum id="0">RESULTATIVE</definiendum>
			</definition>
</paper>

		<paper id="0406">
			<definition id="0">
				<sentence>This paper describes a system , called PostGraphe , which generates a report integrating graphics and text from a single set of writer 's intentions .</sentence>
				<definiendum id="0">PostGraphe</definiendum>
				<definiens id="0">generates a report integrating graphics</definiens>
			</definition>
			<definition id="1">
				<sentence>Reports are an organized synthesis of data that span a whole array of forms going from tables of numbers to a text summarizing the findings .</sentence>
				<definiendum id="0">Reports</definiendum>
			</definition>
			<definition id="2">
				<sentence>Relational keys are similar to the notion of the same name in relational databases \ [ 7\ ] and help determine which variables depend on which others .</sentence>
				<definiendum id="0">help determine</definiendum>
				<definiens id="0">variables depend on which others</definiens>
			</definition>
			<definition id="3">
				<sentence>PostGraphe uses the same planning mechanism to generate text and graphics .</sentence>
				<definiendum id="0">PostGraphe</definiendum>
			</definition>
			<definition id="4">
				<sentence>Other related works include Mittal et al.s extension \ [ 14\ ] to the SAGE system \ [ 15\ ] which uses text to explain the structure of graphs and charts unlike o , ,r system , which uses it to present and explain the data itselfand wIP \ [ 1\ ] , a well-known multimedia generator which has the same goals as our system , but works on a different type of data ( structured representations vs tables of numbers ) .</sentence>
				<definiendum id="0">well-known multimedia generator</definiendum>
				<definiens id="0">SAGE system \ [ 15\ ] which uses text to explain the structure of graphs and charts unlike o , ,r system</definiens>
			</definition>
</paper>

		<paper id="0502">
			<definition id="0">
				<sentence>ABSTRACT SPLAT ( Sentence Plan Language Authoring Tool ) is an authoring tool intended to facilitate the creation of sentence-plan specifications for the Penman natural language generation system .</sentence>
				<definiendum id="0">ABSTRACT SPLAT ( Sentence Plan Language Authoring Tool )</definiendum>
				<definiens id="0">an authoring tool intended to facilitate the creation of sentence-plan specifications for the Penman natural language generation system</definiens>
			</definition>
			<definition id="1">
				<sentence>SPLAT uses an examplebased approach in the form of sentence .</sentence>
				<definiendum id="0">SPLAT</definiendum>
				<definiens id="0">uses an examplebased approach in the form of sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>SPLAT is a first attempt to provide such a facility for the Penman generation system in the form of an authoring tool for Sentence Plan Language ( SPL ) .</sentence>
				<definiendum id="0">SPLAT</definiendum>
			</definition>
			<definition id="3">
				<sentence>SPLAT is a Sentence Plan Language Authoring Tool that has been developed as part of the HealthDoc project \ [ Jakeway , 1995 , DiMarco et al. , 1995\ ] and aims to address many of the earlier difficulties in building the input SPL specifications for Penman .</sentence>
				<definiendum id="0">SPLAT</definiendum>
				<definiens id="0">a Sentence Plan Language Authoring Tool that has been developed as part of the HealthDoc project \ [ Jakeway , 1995 , DiMarco et al. , 1995\ ] and aims to address many of the earlier difficulties in building the input SPL specifications for Penman</definiens>
			</definition>
</paper>

		<paper id="0402">
			<definition id="0">
				<sentence>If P ( A ) is the proportion of times the coders agree , and P ( E ) is the proportion of times that coders are expected to agree by chance , K is computed as follows : P ( A ) P ( E ) K= 1 P ( E ) There are various ways of computing P ( E ) according to Siegel and Castellan ( 1988 ) ; most researchers agree on the following formula , which we also adopted : m Pie ) = j=l where m is the number of categories , andpj is the proportion of objects assigned to category j. The mere fact that K may have a value k greater than zero is not sufficient to draw any conclusion , however , as it must be established whether k is significantly different from zero .</sentence>
				<definiendum id="0">m</definiendum>
				<definiendum id="1">andpj</definiendum>
				<definiens id="0">the proportion of times the coders agree , and P ( E ) is the proportion of times that coders are expected to agree by chance , K is computed as follows : P ( A ) P ( E ) K= 1 P ( E ) There are various ways of computing P ( E ) according to Siegel and Castellan ( 1988 ) ; most researchers agree on the following formula , which we also adopted : m Pie</definiens>
			</definition>
			<definition id="1">
				<sentence>The upper stream processes the training set and contains a type module which marks the main syntactic form ( i.e. , DONT , NEVER , or Neg-TC ) as the variable to be predicted and the AWARENESS , SAFETY , and INTENTIONALITY features as the inputs .</sentence>
				<definiendum id="0">INTENTIONALITY</definiendum>
				<definiens id="0">the variable to be predicted and the AWARENESS , SAFETY , and</definiens>
			</definition>
			<definition id="2">
				<sentence>Its output is passed to the C4.5 node , labelled reform , which produces the decision tree .</sentence>
				<definiendum id="0">reform</definiendum>
				<definiens id="0">produces the decision tree</definiens>
			</definition>
			<definition id="3">
				<sentence>The conversion routine takes the following inputs : • the applicable language ( s ) -- C4.5 produces its decision trees based on examples from a particular language , and KPML is capable of being conditionalised for particular languages .</sentence>
				<definiendum id="0">KPML</definiendum>
				<definiens id="0">the applicable language ( s ) -- C4.5 produces its decision trees based on examples from a particular language , and</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , we may perform separate corpus analyses of a particular phenomenon for various languages , and learn separate microplanning trees ; 3A cross-validation test is a test where C4.5 breaks the data into different combinations of training and testing sets , builds and tests decision trees for each , and averages the results ( Clementine , 1995 ) .</sentence>
				<definiendum id="0">cross-validation test</definiendum>
				<definiens id="0">a test where C4.5 breaks the data into different combinations of training and testing sets , builds and tests decision trees for each , and averages the results</definiens>
			</definition>
			<definition id="5">
				<sentence>DRAFTER is a instructional text authoring tool that allows technical authors to specify a procedural structure , and then uses that structure as input to a multilingual text generation facility ( Paris and Vander Linden , 1996 ) .</sentence>
				<definiendum id="0">DRAFTER</definiendum>
				<definiens id="0">a instructional text authoring tool that allows technical authors to specify a procedural structure , and then uses that structure as input to a multilingual text generation facility</definiens>
			</definition>
</paper>

		<paper id="0417">
			<definition id="0">
				<sentence>PEBA-II is part of a larger research programme built around the idea of an intelligent on-line encyclopaedia , where the descriptions produced by the system vary for different users and at different times .</sentence>
				<definiendum id="0">PEBA-II</definiendum>
				<definiens id="0">part of a larger research programme built around the idea of an intelligent on-line encyclopaedia , where the descriptions produced by the system vary for different users and at different times</definiens>
			</definition>
			<definition id="1">
				<sentence>The plan library consists of discourse plans which are used by the text planning component .</sentence>
				<definiendum id="0">plan library</definiendum>
				<definiens id="0">consists of discourse plans which are used by the text planning component</definiens>
			</definition>
			<definition id="2">
				<sentence>3 A comparison is the linguistic realisation of a set of one or more comparative propositions , where the purpose of the set of propositions is to draw the hearer 's attention to one or more differences or similarities between two entities .</sentence>
				<definiendum id="0">comparison</definiendum>
				<definiens id="0">the linguistic realisation of a set of one or more comparative propositions , where the purpose of the set of propositions is to draw the hearer 's attention to one or more differences or similarities between two entities</definiens>
			</definition>
			<definition id="3">
				<sentence>A DIRECT COMPARISON is a comparison whose purpose is to compare two entities where neither entity is more central to the discourse than the other .</sentence>
				<definiendum id="0">DIRECT COMPARISON</definiendum>
			</definition>
			<definition id="4">
				<sentence>This text is essentially 'bi-focal ' : the echidna and the porcupine are equally imporaIn the terminology we adopt here , a PROPERTY is a tuple consisting of an ATTRIBUTE and a VALUE ; \ [ or example , ( colour , red/ .</sentence>
				<definiendum id="0">PROPERTY</definiendum>
				<definiens id="0">a tuple consisting of an ATTRIBUTE and a VALUE</definiens>
			</definition>
			<definition id="5">
				<sentence>The African Porcupine is a type of Flacental Mammal .</sentence>
				<definiendum id="0">African Porcupine</definiendum>
			</definition>
			<definition id="6">
				<sentence>The Placental Mammal is a type of Mammal that carries its developing young inside the mothers womb .</sentence>
				<definiendum id="0">Placental Mammal</definiendum>
				<definiens id="0">a type of Mammal that carries its developing young inside the mothers womb</definiens>
			</definition>
			<definition id="7">
				<sentence>• The Echidna is a carruvore and eats ants , termites and earthworms whereas the African Porcupine is a herbivore and eats leaves , roots and fruit .</sentence>
				<definiendum id="0">African Porcupine</definiendum>
				<definiens id="0">a carruvore and eats ants , termites and earthworms whereas the</definiens>
				<definiens id="1">a herbivore and eats leaves , roots and fruit</definiens>
			</definition>
			<definition id="8">
				<sentence>A CLARIFICATORY COMPARISON is a comparison whose purpose is to describe an entity by distinguishing it clearly from another entity with which it might be confused or with which it shares a number of salient properties .</sentence>
				<definiendum id="0">CLARIFICATORY COMPARISON</definiendum>
			</definition>
			<definition id="9">
				<sentence>An ILLUSTRATIVE COMPARISON is a comparison whose purpose is to describe one or more attributes of an entity by referring to the same attribute ( s ) of another entity with which the user is familiar .</sentence>
				<definiendum id="0">ILLUSTRATIVE COMPARISON</definiendum>
				<definiens id="0">a comparison whose purpose is to describe one or more attributes of an entity by referring to the same attribute ( s ) of another entity with which the user is familiar</definiens>
			</definition>
			<definition id="10">
				<sentence>As mentioned earlier , the PEBA-II system allows the user to request one of two actions : to describe a single entity or to compare two entities .</sentence>
				<definiendum id="0">PEBA-II system</definiendum>
				<definiens id="0">allows the user to request one of two actions : to describe a single entity or to compare two entities</definiens>
			</definition>
</paper>

		<paper id="0209">
			<definition id="0">
				<sentence>The probabilistic model is a refinement of probabilistic context-free grammar ( PCFG ) conditioning CF 'backbone ' rule application on LR state and lookahead item .</sentence>
				<definiendum id="0">probabilistic model</definiendum>
				<definiens id="0">a refinement of probabilistic context-free grammar ( PCFG ) conditioning CF 'backbone ' rule application on LR state and lookahead item</definiens>
			</definition>
			<definition id="1">
				<sentence>PUNCTUATION Nunberg ( 1990 ) develops a partial 'text ' grammar for English which incorporates mnany constraints that ( ultimately ) restrict syntactic and semantic interpretation .</sentence>
				<definiendum id="0">PUNCTUATION Nunberg</definiendum>
				<definiens id="0">incorporates mnany constraints that ( ultimately ) restrict syntactic and semantic interpretation</definiens>
			</definition>
			<definition id="2">
				<sentence>A more succinct though less intuitive measure of ambiguity rate for a given corpus is Briscoe &amp; Carroll 's ( 1995 ) average parse base ( APB ) , defined as the geometric mean over all sentences in the corpus of ¢/~ , where n is the number of words in a sentence , and p , the number of parses for that sentence .</sentence>
				<definiendum id="0">APB</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the geometric mean over all sentences in the corpus of ¢/~</definiens>
			</definition>
			<definition id="3">
				<sentence>This compares unlabelled bracketings derived from corpus treebanks with those derived from parses for the same sentences by computing recall , the ratio of matched brackets over all brackets in the treebank ; precision , the ratio of matched brackets over all brackets found by the parser ; mean crossings , the number of times a bracketed sequence output by the parser overlaps with one from the treebank but neither is properly contained in the other , averaged over all sentences ; and zero crossings , the percentage of sentences for which the analysis returned has zero crossings .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiendum id="1">zero crossings</definiendum>
				<definiens id="0">corpus treebanks with those derived from parses for the same sentences by computing recall , the ratio of matched brackets over all brackets in the treebank</definiens>
			</definition>
			<definition id="4">
				<sentence>Precision is less than 100 % due to crossings , minor mismatches and inconsistencies ( due to the manual nature of the markup process ) in tree annotations , and the fact that Susanne often favours a `` flat '' treatment of VP constituents , whereas our grammar always makes an explicit choice between argumentand adjunct-hood .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">less than 100 % due to crossings , minor mismatches and inconsistencies ( due to the manual nature of the markup process ) in tree annotations</definiens>
			</definition>
</paper>

		<paper id="0408">
			<definition id="0">
				<sentence>For example , ASL uses the same sign ( i.e. , lexical item ) for `` other '' and `` another '' .</sentence>
				<definiendum id="0">ASL</definiendum>
				<definiens id="0">uses the same sign ( i.e. , lexical item</definiens>
			</definition>
			<definition id="1">
				<sentence>Our initial investigations lead us to believe that this may be done within FUE a functional unification-based text generation system \ [ Elh93\ ] through a dynamic ordering of altemative realizations ( ALTs ) .</sentence>
				<definiendum id="0">FUE</definiendum>
				<definiens id="0">a functional unification-based text generation system \ [ Elh93\ ] through a dynamic ordering of altemative realizations ( ALTs )</definiens>
			</definition>
</paper>

		<paper id="0504">
</paper>

		<paper id="0108">
			<definition id="0">
				<sentence>Word errors present problems for various textor speech-based applications such as optical character recognition ( OCR ) and voice-input computer interfaces .</sentence>
				<definiendum id="0">Word errors present problems</definiendum>
			</definition>
			<definition id="1">
				<sentence>If we assume that strings produced under OCR are independent of one another , we have the following formula : Pr ( SIW ) = rI Pr ( S~lw~ ) ( 6 ) i=1 So , = argmaxw ( Pr ( W ) , pr ( SlW ) ) n = argmaxw ( l~ Ipr ( wilwi_l ) • pr ( silwi ) ) ( 7 ) i=1 Thus , the problem of calculating W is reduced to estimating the word-bigram probability , pr ( wil w~_ 1 ) , and the word confusion probability , pr ( silw~ ) .</sentence>
				<definiendum id="0">pr</definiendum>
				<definiens id="0">strings produced under OCR are independent of one another</definiens>
			</definition>
			<definition id="2">
				<sentence>The word-bigram probability , pr ( wi\ [ wi_ ~ ) , can be estimated by a maximum likelihood estimator ( MLE ) : prML ( WiiW , _i ) = C ( Wi-1 , Wi ) where c ( wi_x ) is the number of times that wi-1 occurs in the text and c ( wi_~ , w~ ) is the number of times that the word bigram ( Wi_l , wi ) occurs in the text .</sentence>
				<definiendum id="0">pr</definiendum>
				<definiendum id="1">MLE</definiendum>
				<definiendum id="2">c ( wi_x</definiendum>
			</definition>
			<definition id="3">
				<sentence>90 The probability pr ( slw ) -- the conditional probability that , given a word w , it is recognized by the OCR software as the string s -- -can be estimated by the confusion probabilities of the characters in s if we assume that character recognition in OCR is an independent process .</sentence>
				<definiendum id="0">probability pr</definiendum>
				<definiendum id="1">conditional probability</definiendum>
				<definiens id="0">an independent process</definiens>
			</definition>
			<definition id="4">
				<sentence>The dynamic programming recurrence is given as follows : pr ( i llj ) * pr ( ins ( ti ) ) pr ( ilj ) = max pr ( ilj 1 ) • pr ( del ( sj ) lsj ) ( 8 ) pr ( il\ [ j1 ) *pr ( t , lsj ) where pr ( ins ( y ) ) is the probability that letter y is inserted .</sentence>
				<definiendum id="0">pr ( ins ( y ) )</definiendum>
				<definiens id="0">the probability that letter y is inserted</definiens>
			</definition>
			<definition id="5">
				<sentence>If we have no information about the character confusion probabilities , we can estimate them as : pr ( ylx ) = { ~7 ify=x -otherwise ( 9 ) 1 -- ~ pr ( dd ( x ) lx ) = pr ( ins ( x ) ) = i ( 10 ) where N is the total number of printable characters .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of printable characters</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus , for example , if the system encounters the word `` MobileData '' ( a correct name ) in the OCR output , but does not have `` MobileData '' in its lexicon , it might change `` MobileData '' to `` MobileComm '' ( a word that does exist in the training corpus lexicon ) .</sentence>
				<definiendum id="0">MobileData</definiendum>
				<definiens id="0">MobileData '' to `` MobileComm '' ( a word that does exist in the training corpus lexicon )</definiens>
			</definition>
</paper>

		<paper id="0101">
			<definition id="0">
				<sentence>Among all parts of speech , there is a clear division between closed-class parts of speech , which include prepositions and conjunctions , and open-class ones , which includes verbs , nouns , and adjectives .</sentence>
				<definiendum id="0">speech</definiendum>
				<definiens id="0">includes verbs , nouns , and adjectives</definiens>
			</definition>
</paper>

		<paper id="0405">
			<definition id="0">
				<sentence>The input is described in terms of Halliday 's ( 1978 ) three meaning components , ideational meaning ( the propositional content to be expressed ) , interactional meaning ( what the speaker intends the listener to do in making the utterance ) , and textual meaning ( how the content is structured as a message , in terms of theme , reference , etc. ) .</sentence>
				<definiendum id="0">ideational meaning</definiendum>
				<definiendum id="1">textual meaning</definiendum>
				<definiens id="0">the propositional content to be expressed ) , interactional meaning ( what the speaker intends the listener to do in making the utterance</definiens>
			</definition>
			<definition id="1">
				<sentence>The input is described in terms of Halliday 's ( 1978 ) three meaning components , ideational meaning ( the propositional content to be expressed ) , interactional meaning ( what the speaker intends the listener to do in making the utterance ) , and textual meaning ( how the ideational content is structured as a message , in terms of theme , reference , etc. ) .</sentence>
				<definiendum id="0">ideational meaning</definiendum>
				<definiens id="0">the propositional content to be expressed ) , interactional meaning ( what the speaker intends the listener to do in making the utterance ) , and textual meaning ( how the ideational content is structured as a message</definiens>
			</definition>
			<definition id="2">
				<sentence>The WAG Sentence Generation System is one component of the Workbench for Analysis and Generation ( WAG ) , a system which offers various tools for developing Systemic resources ( grammars , semantics , lexicons , etc. ) , maintaining these resources ( lexical acquisition tools , network graphers , hypertext browsers , etc. ) , and processing ( sentence analysis O'Donnell 1993 , 1994 ; sentence generation O'Donnell 1995b ; knowledge representation O'Donnell 1994 ; corpus tagging and explorationO'Donnell 1995a ) .</sentence>
				<definiendum id="0">WAG Sentence Generation System</definiendum>
				<definiens id="0">one component of the Workbench for Analysis and Generation ( WAG ) , a system which offers various tools for developing Systemic resources ( grammars , semantics , lexicons , etc. ) , maintaining these resources ( lexical acquisition tools , network graphers , hypertext browsers</definiens>
			</definition>
			<definition id="3">
				<sentence>Other sentence generators , while working from abstract semantic specifications , do not represent a generalised realiser , but are somewhat domain specific in implementation , e.g. , Proteus ( Davey 1974/1978 ) ; Slang ( Patten 1988 ) .</sentence>
				<definiendum id="0">Other sentence generators</definiendum>
				<definiens id="0">working from abstract semantic specifications , do not represent a generalised realiser , but are somewhat domain specific in implementation</definiens>
			</definition>
			<definition id="4">
				<sentence>Interactional representation views the text as part of the interaction between participants .</sentence>
				<definiendum id="0">Interactional representation</definiendum>
				<definiens id="0">views the text as part of the interaction between participants</definiens>
			</definition>
			<definition id="5">
				<sentence>The UM provides a generalised classification system of conceptual entities .</sentence>
				<definiendum id="0">UM</definiendum>
				<definiens id="0">provides a generalised classification system of conceptual entities</definiens>
			</definition>
			<definition id="6">
				<sentence>48 / The input specification for the WAG sentence generator is a ' speech-act , which includes an indication of which relations in the KB are relevant for expression at this point .</sentence>
				<definiendum id="0">WAG sentence generator</definiendum>
				<definiens id="0">a ' speech-act , which includes an indication of which relations in the KB are relevant for expression at this point</definiens>
			</definition>
			<definition id="7">
				<sentence>In taking this approach , WAG attempts to extend the degree to which surface forms can be constrained by semantic specification .</sentence>
				<definiendum id="0">WAG</definiendum>
				<definiens id="0">attempts to extend the degree to which surface forms can be constrained by semantic specification</definiens>
			</definition>
</paper>

		<paper id="0102">
			<definition id="0">
				<sentence>Memory-based learning is a form of supervised learning based on similarity-based reasoning .</sentence>
				<definiendum id="0">Memory-based learning</definiendum>
				<definiens id="0">a form of supervised learning based on similarity-based reasoning</definiens>
			</definition>
			<definition id="1">
				<sentence>A memorybased approach has features of both learning rule-based taggers ( each case can be regarded as a very specific rule , the similarity based reasoning as a form of conflict resolution and rule selection mechanism ) and of stochastic taggers : it is fundamentally a form of k-nearest neighbors ( k-nn ) modeling , a well-known non-parametric statistical pattern recognition technique .</sentence>
				<definiendum id="0">rule-based taggers</definiendum>
				<definiens id="0">it is fundamentally a form of k-nearest neighbors ( k-nn ) modeling , a well-known non-parametric statistical pattern recognition technique</definiens>
			</definition>
			<definition id="2">
				<sentence>Memory-based Learning is a form of supervised , inductive learning from examples .</sentence>
				<definiendum id="0">Memory-based Learning</definiendum>
				<definiens id="0">a form of supervised , inductive learning from examples</definiens>
			</definition>
			<definition id="3">
				<sentence>Performance of a memory-based system ( accuracy on the test set ) crucially depends on the distance metric ( or similarity metric ) used .</sentence>
				<definiendum id="0">memory-based system</definiendum>
			</definition>
			<definition id="4">
				<sentence>The most straightforward distance metric would be the one in equation ( 1 ) , where X and Y are the patterns to be compared , and ~i ( x~ , y/ ) is the distance between the values of the i-th feature in a pattern with n features .</sentence>
				<definiendum id="0">most straightforward distance metric</definiendum>
				<definiens id="0">the distance between the values of the i-th feature in a pattern with n features</definiens>
			</definition>
			<definition id="5">
				<sentence>Without optimisation , it has an asymptotic retrieval complexity of O ( NF ) ( where N is the number of items in memory , and F the number of features ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of items in memory , and F the number of features</definiens>
			</definition>
			<definition id="6">
				<sentence>IGTree is a heuristic approximation of the IB-IG algorithm .</sentence>
				<definiendum id="0">IGTree</definiendum>
				<definiens id="0">a heuristic approximation of the IB-IG algorithm</definiens>
			</definition>
			<definition id="7">
				<sentence>Output : A class label .</sentence>
				<definiendum id="0">Output</definiendum>
				<definiens id="0">A class label</definiens>
			</definition>
			<definition id="8">
				<sentence>Complexity of searching a query pattern in the tree is proportional to F * log ( V ) , where F is the number of features ( equal to the maximal depth of the tree ) , and V is the average number of values per feature ( i.e. , the average branching factor in the tree ) .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">F</definiendum>
				<definiendum id="2">V</definiendum>
				<definiens id="0">the number of features ( equal to the maximal depth of the tree ) , and</definiens>
				<definiens id="1">the average number of values per feature ( i.e. , the average branching factor in the tree )</definiens>
			</definition>
			<definition id="9">
				<sentence>A case consists of information about a focus word to be tagged , its left and right context , and an associated category ( tag ) valid for the focus word in that context .</sentence>
				<definiendum id="0">case</definiendum>
				<definiens id="0">consists of information about a focus word to be tagged , its left and right context , and an associated category ( tag ) valid for the focus word in that context</definiens>
			</definition>
			<definition id="10">
				<sentence>Experimental Set-up The experimental methodology was taken from Machine Learning practice ( e.g. Weiss &amp; Kulikowski , 1991 ) : independent training and test sets were selected from the original corpus , the system was trained on the training set , and the generalization accuracy ( percentage of correct category assignments ) was computed on the independent test set .</sentence>
				<definiendum id="0">generalization accuracy</definiendum>
				<definiens id="0">taken from Machine Learning practice ( e.g. Weiss &amp; Kulikowski , 1991 ) : independent training and test sets were selected from the original corpus</definiens>
			</definition>
			<definition id="11">
				<sentence>Average accuracy provides a reliable estimate of the generalization accuracy .</sentence>
				<definiendum id="0">Average accuracy</definiendum>
				<definiens id="0">provides a reliable estimate of the generalization accuracy</definiens>
			</definition>
			<definition id="12">
				<sentence>In order to prove that IGTree is a suitable candidate for practical memory-based tagging , we compared three memory-based learning algorithms : ( i ) IB1 , a slight extension ( to cope with symbolic values and ambiguous training items ) of the well-known k-nn algorithm in statistical pattern recognition ( see Aha et al. , 1991 ) , ( ii ) IBI-IG , an extension of IB1 which uses feature relevance weighting ( described in Section 2 ) , and ( iii ) IGTree , a memoryand processing time saving heuristic implementation of IBi-IG ( see Section 3 ) .</sentence>
				<definiendum id="0">IGTree</definiendum>
			</definition>
			<definition id="13">
				<sentence>The feature weighting method takes care of the optimal fusing of different sources of information ( e.g. word form and context ) , automatically .</sentence>
				<definiendum id="0">feature weighting method</definiendum>
				<definiens id="0">takes care of the optimal fusing of different sources of information ( e.g. word form and context</definiens>
			</definition>
</paper>

		<paper id="0104">
			<definition id="0">
				<sentence>Introduction Word Sense Disambiguation ( WSD ) is the problem of assigning a sense to an ambiguous word , using its context .</sentence>
				<definiendum id="0">Introduction Word Sense Disambiguation</definiendum>
				<definiendum id="1">WSD</definiendum>
				<definiens id="0">the problem of assigning a sense to an ambiguous word</definiens>
			</definition>
			<definition id="1">
				<sentence>Affinity ( a real number between 0 and 1 ) reflects the contextual relationships between W and the words of the sentence .</sentence>
				<definiendum id="0">Affinity</definiendum>
				<definiens id="0">a real number between 0 and 1 ) reflects the contextual relationships between W and the words of the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>We say that a word belongs to a sentence , denoted as W E S , if it textually contained there ; in this case , sentence is said to include the word : S ~ W. Affinity is then defined as follows : affn ( W , S ) = max siren ( W , Wi ) ( 1 ) Wi ES aftn ( 8 , W ) = max sims ( S , 8j ) ( 2 ) s~w where n denotes the iteration number .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a word belongs to a sentence , denoted as W E S , if it textually contained there ; in this case , sentence is said to include the word : S ~ W. Affinity is then defined as follows : affn ( W , S ) = max siren ( W , Wi ) ( 1 ) Wi ES aftn ( 8 , W ) = max sims</definiens>
				<definiens id="1">the iteration number</definiens>
			</definition>
			<definition id="3">
				<sentence>SSimilarity sims ( X , y ) is a non-decreasing function of the number of iteration n , and the similarity values are bounded by 1 .</sentence>
				<definiendum id="0">SSimilarity sims</definiendum>
				<definiens id="0">a non-decreasing function of the number of iteration n</definiens>
			</definition>
			<definition id="4">
				<sentence>Pr ( Wi I W ) log Pr ( W~ ) ( 10 ) where Pr0d\ ] i ) is estimated from the frequency of W in the entire corpus , and Pr ( Wi \ [ W ) -from the frequency of I'Yi in the training set , given the examples of the current ambiguous word } , V ( cf. ( Gale et al. , 1992 ) ) .</sentence>
				<definiendum id="0">V ( cf.</definiendum>
				<definiens id="0">estimated from the frequency of W in the entire corpus</definiens>
				<definiens id="1">the frequency of I'Yi in the training set , given the examples of the current ambiguous word }</definiens>
			</definition>
</paper>

		<paper id="0109">
			<definition id="0">
				<sentence>Dc is a collection of texts in D whose title contains a term c. doc_f ( D ) is the count of texts in D. Similarly , doc_f ( Dc ) refers to the count of texts which have a term c in the title .</sentence>
				<definiendum id="0">Dc</definiendum>
				<definiens id="0">a collection of texts in D whose title contains a term c. doc_f ( D ) is the count of texts in D. Similarly</definiens>
				<definiens id="1">the count of texts which have a term c in the title</definiens>
			</definition>
			<definition id="1">
				<sentence>The vertical dimension represents the proportion of words in text against words in title . )</sentence>
				<definiendum id="0">vertical dimension</definiendum>
				<definiens id="0">represents the proportion of words in text against words in title</definiens>
			</definition>
			<definition id="2">
				<sentence>idf measurement ( Wilkinson , 1994 ) : N SIM ( h , d ) = E ntftd `` idft i=O N is the number of words that appear in h. ntft d is a normalized term frequency of t in d , which is given by : tfta ntft d -__ max_t f d where tftd denotes a frequency of the term t in d and max_tfd the frequency of the most frequent term in d. = log log df tdf is the number of segments which have an occurrence of t. df is the total number of segments in d. log df is a normalization factor .</sentence>
				<definiendum id="0">idf measurement</definiendum>
				<definiendum id="1">SIM</definiendum>
				<definiendum id="2">idft i=O N</definiendum>
			</definition>
			<definition id="3">
				<sentence>The article consists of a title ( 1 ) plus two sentences ( 2,3 ) .</sentence>
				<definiendum id="0">article</definiendum>
			</definition>
			<definition id="4">
				<sentence>A nucleus is a set of clauses that presents a main claim of the text , something that makes the text newsworthy , while an adjunct supplements the main claim with some background or ancillary information .</sentence>
				<definiendum id="0">nucleus</definiendum>
				<definiens id="0">a set of clauses that presents a main claim of the text , something that makes the text newsworthy , while an adjunct supplements the main claim with some background or ancillary information</definiens>
			</definition>
			<definition id="5">
				<sentence>Precision and recall are determined for each text in the test set , by the formulae below : the number of words correctly identified as title words Precision = the number of words assigned the number of words correctly identified as title words Recall = the number of actual topics We use a assigning strategy called probabilistic thresholding ( Lewis , 1992 ) to decide what words to be assigned to the text as potential title indicators .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the number of words assigned the number of words correctly identified as title words Recall = the number of actual topics We use a assigning strategy called probabilistic thresholding ( Lewis , 1992</definiens>
			</definition>
</paper>

		<paper id="0113">
			<definition id="0">
				<sentence>Credit factors for training data to improve the reliability of the estimated models axe also introduced .</sentence>
				<definiendum id="0">Credit factors</definiendum>
			</definition>
			<definition id="1">
				<sentence>In this formulation , the tagger searches for the best sequence that maximizes the probability ( Nagata , 1994 ) : ( 1~ r , T ) = arg maxp ( W , TIS ) = arg maxp ( W , T ) ( 1 ) W , T W , T where W is a word sequence ( wl , w2 , ... , Wn ) , T is a tag sequence ( tl , t2 , ... , tn ) and S is an input sentence .</sentence>
				<definiendum id="0">W</definiendum>
				<definiendum id="1">T</definiendum>
				<definiendum id="2">S</definiendum>
				<definiens id="0">a word sequence</definiens>
				<definiens id="1">a tag sequence ( tl , t2 , ... , tn</definiens>
				<definiens id="2">an input sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>A state of the HMM represents an abstract class of a part of the input symbol sequence .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">an abstract class of a part of the input symbol sequence</definiens>
			</definition>
			<definition id="3">
				<sentence>: \ [ `` ( X7 ( 1 ) noun:5 `` ~7 ( 3 ) Figure 2 : An example of the network trellis K 1 O¢~ ( / ) ~sk ( i ) E~ E k=l 8Eon ( 1 ) ~ = g N ( 8 ) k=l sEon ( 1 ) j=l where k represents the k-th input sentence and Pk is sum of the probabilities of possible sequences in the k-th morpheme network weighted by the credit factors .</sentence>
				<definiendum id="0">k</definiendum>
			</definition>
			<definition id="4">
				<sentence>The notation ~st ( i ) is used to denote the unscaled forward probabilities of the s-th morpheme on the syncronous point l , &amp; sl ( i ) to denote the scaled forward probabilities , and &amp; , l ( i ) to denote the local version of c~ before scaling , cl is the scaling factor of synchronous point I. initial : &amp; sl ( i ) = ~sl ( i ) = ~ribi ( ws , t , ) credit ( ~ , s ) where s E on ( l ) N ^ C 1 : 1/ E E &amp; sl ( / ) sEon ( 1 ) i=1 ^ &amp; sl ( i ) = Cl &amp; sl ( i ) where s E on ( l ) 160 cost 0 1-10 11-20 21-50 51-100 101-200 201-500 501-1000 precision 0.84 0.16 0.13 0.069 0.074 0.0083 0.0017 0 Table 1 : The precision on each cost of Juman recursion : &amp; s , /-l ( i ) if L , 7~l N &amp; , l_l ( i ) aijbtj ( w , ,t ) credit ( r , s ) if L , = l rEpre ( s ) i=1 N ^ C l -~ 1 E E &amp; sl ( i ) sEon ( l ) i=1 &amp; st ( i ) = Cl &amp; t ( i ) The scaled forward probabilities can be calculated synchronizing with the synchronous points from left to right .</sentence>
				<definiendum id="0">~st</definiendum>
				<definiens id="0">used to denote the unscaled forward probabilities of the s-th morpheme on the syncronous point l , &amp; sl ( i ) to denote the scaled forward probabilities , and &amp; , l ( i ) to denote the local version of c~ before scaling</definiens>
				<definiens id="1">s ) i=1 N ^ C l -~ 1 E E &amp; sl</definiens>
			</definition>
			<definition id="5">
				<sentence>Juman is a rule-based Japanese tagging system which uses hand-coding cost values that represent the implausibility of morpheme connections , and wordand tag-occurences .</sentence>
				<definiendum id="0">Juman</definiendum>
				<definiens id="0">a rule-based Japanese tagging system which uses hand-coding cost values that represent the implausibility of morpheme connections , and wordand tag-occurences</definiens>
			</definition>
			<definition id="6">
				<sentence>The numbers of parameters of the TAG-bigram model , the TAG-HMM and the PAIR-HMM are approximated by the equations NT 2 + ND , NS 2 + NS * NT + ND , and NS 2 + NS * ND , respectively , where NT is the number of tags , NS is the number of states of the HMM , and ND is the number of entries in the dictionary .</sentence>
				<definiendum id="0">NT</definiendum>
				<definiendum id="1">NS</definiendum>
				<definiendum id="2">ND</definiendum>
				<definiens id="0">the number of tags</definiens>
				<definiens id="1">the number of states of the HMM , and</definiens>
				<definiens id="2">the number of entries in the dictionary</definiens>
			</definition>
</paper>

		<paper id="0513">
			<definition id="0">
				<sentence>Moreover , some phenomenon , such as event ellipsis ( EE ) can not be handled by a pure statistical approach nor by a lexicographic approach , as its recovery necessitates a semantic treatment , ( \ [ Viegas and Nirenburg , 1995a\ ] ) , which is , in fact , handled by a computalional Linguistic approach making use of semantics .</sentence>
				<definiendum id="0">EE</definiendum>
				<definiens id="0">in fact , handled by a computalional Linguistic approach making use of semantics</definiens>
			</definition>
</paper>

		<paper id="0201">
			<definition id="0">
				<sentence>The Smooth Injective Map Recognizer ( SIMR ) is a new bitext mapping algorithm .</sentence>
				<definiendum id="0">Smooth Injective Map Recognizer ( SIMR )</definiendum>
				<definiens id="0">a new bitext mapping algorithm</definiens>
			</definition>
			<definition id="1">
				<sentence>Alignment algorithms assume the availability of text unit boundary information and their output has less expressive power than a general bitext map .</sentence>
				<definiendum id="0">Alignment algorithms</definiendum>
				<definiens id="0">assume the availability of text unit boundary information and their output has less expressive power than a general bitext map</definiens>
			</definition>
			<definition id="2">
				<sentence>The Smooth Injective Map Recognizer ( SIMR ) is a greedy algorithm for mapping bitext correspondence .</sentence>
				<definiendum id="0">Smooth Injective Map Recognizer ( SIMR )</definiendum>
				<definiens id="0">a greedy algorithm for mapping bitext correspondence</definiens>
			</definition>
			<definition id="3">
				<sentence>align ( Church 1993 ) , SIMR infers bitext maps from likely points of correspondence between the two texts , points that are plotted in a two-dimensional space of possibilities .</sentence>
				<definiendum id="0">SIMR</definiendum>
				<definiens id="0">infers bitext maps from likely points of correspondence between the two texts , points that are plotted in a two-dimensional space of possibilities</definiens>
			</definition>
			<definition id="4">
				<sentence>Second , SIMR selects those points whose geometric arrangement most resembles the typical arrangement of true points of correspondence .</sentence>
				<definiendum id="0">SIMR</definiendum>
				<definiens id="0">selects those points whose geometric arrangement most resembles the typical arrangement of true points of correspondence</definiens>
			</definition>
			<definition id="5">
				<sentence>For each bitext , the true bitext map ( TBM ) is the shortest bitext map that runs through all the TPCs .</sentence>
				<definiendum id="0">TBM )</definiendum>
				<definiens id="0">the shortest bitext map that runs through all the TPCs</definiens>
			</definition>
			<definition id="6">
				<sentence>If more than one chain is found , SIMR accepts the chain whose points are least dispersed around its least-squares line .</sentence>
				<definiendum id="0">SIMR</definiendum>
				<definiens id="0">accepts the chain whose points are least dispersed around its least-squares line</definiens>
			</definition>
			<definition id="7">
				<sentence>SIMR employs a simple heuristic to select regions of the bitext space to search .</sentence>
				<definiendum id="0">SIMR</definiendum>
				<definiens id="0">employs a simple heuristic to select regions of the bitext space to search</definiens>
			</definition>
			<definition id="8">
				<sentence>A matching predicate is a heuristic for guessing whether a given point in the bitext space is a TPC .</sentence>
				<definiendum id="0">matching predicate</definiendum>
				<definiendum id="1">space</definiendum>
				<definiens id="0">a heuristic for guessing whether a given point in the bitext</definiens>
			</definition>
			<definition id="9">
				<sentence>I have considered only token-based matching predicates , which can only return TRUE for a point ( x , y ) if x is the position of a token e on the x-axis and y is the position of a token f on the yaxis .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">the position of a token f on the yaxis</definiens>
			</definition>
			<definition id="10">
				<sentence>SIMR judges the cognateness of each token pair by their Longest Common Subsequence Ratio ( LCSR ) .</sentence>
				<definiendum id="0">SIMR</definiendum>
			</definition>
			<definition id="11">
				<sentence>The LCSR of a token pair is the number of characters that appear in the same order in both tokens divided by the length of the longer token ( Melamed 1995 ) .</sentence>
				<definiendum id="0">LCSR of a token pair</definiendum>
			</definition>
			<definition id="12">
				<sentence>For instance , if the input contains ( G , e ) , ( H , e ) , and ( H , f ) , then GSA adds the pairing ( G , f ) .</sentence>
				<definiendum id="0">GSA</definiendum>
				<definiens id="0">adds the pairing ( G , f )</definiens>
			</definition>
			<definition id="13">
				<sentence>So , GSA 's running time is O ( kn ) , where n is the number of input sentences and k is a small constant proportional to the size of the largest realigned block .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">k</definiendum>
				<definiens id="0">a small constant proportional to the size of the largest realigned block</definiens>
			</definition>
			<definition id="14">
				<sentence>SIMR produced bitext maps for 200 megabytes of the Canadian Hansards .</sentence>
				<definiendum id="0">SIMR</definiendum>
				<definiens id="0">produced bitext maps for 200 megabytes of the Canadian Hansards</definiens>
			</definition>
			<definition id="15">
				<sentence>The Linguistic Data Consortium plans to publish both the maps and the alignments in the near future .</sentence>
				<definiendum id="0">Linguistic Data Consortium</definiendum>
				<definiens id="0">plans to publish both the maps and the alignments in the near future</definiens>
			</definition>
</paper>

		<paper id="0105">
			<definition id="0">
				<sentence>Let the input be { ncl-mcl , nc2-mc2 , nc3-mc3 , v } , where nei denotes the case filler for the case ci , and mci denotes the case marker for ci .</sentence>
				<definiendum id="0">nei</definiendum>
				<definiendum id="1">mci</definiendum>
				<definiens id="0">the case filler for the case ci , and</definiens>
			</definition>
			<definition id="1">
				<sentence>Table 1 : The relation between the length of the path between two nouns X and Y ( fen ( X , Y ) ) in Bunruigoihyo and their relative similarity ( sire ( X , Y ) ) len ( X , Y ) 0 2 4 6 8 10 12 sim ( X , Y ) 11 10 9 8 7 5 0 input \ [ ncl-rr ~81 , Cl database £s2 , cl ncl-mel nc2-rnc2 ne3-mc3 v ( ? )</sentence>
				<definiendum id="0">relative similarity</definiendum>
				<definiens id="0">The relation between the length of the path between</definiens>
			</definition>
			<definition id="2">
				<sentence>CCD ( c ) expresses the weight factor of the case c contribution to the ( current ) verb sense disambiguation .</sentence>
				<definiendum id="0">CCD ( c )</definiendum>
				<definiens id="0">expresses the weight factor of the case c contribution to the ( current ) verb sense disambiguation</definiens>
			</definition>
			<definition id="3">
				<sentence>_y x X X X X sense 1 x~x~ __~/ ... .~ sense 2 X Figure 6-a : The case where the interpretation certainty of the enclosed `` x '' is great Figure 6-b : The case where the interpretation certainty of the the enclosed `` x '' is small Figure 6 : The concept of interpretation certainty Considering the two restrictions , we compute interpretation certainties by using equation ( 7 ) , where C ( x ) is the interpretation certainty of an example x. Sl ( x ) and S2 ( x ) are the highest 1Note that this method can easily be extended for a verb which has more than two senses .</sentence>
				<definiendum id="0">C ( x )</definiendum>
				<definiendum id="1">S2 ( x )</definiendum>
				<definiens id="0">a verb which has more than two senses</definiens>
			</definition>
			<definition id="4">
				<sentence>~ , which ranges from 0 to 1 , is a parametric constant to control the degree to which each condition affects the computation of C ( x ) .</sentence>
				<definiendum id="0">~</definiendum>
				<definiens id="0">ranges from 0 to 1 , is a parametric constant to control the degree to which each condition affects the computation of C ( x )</definiens>
			</definition>
			<definition id="5">
				<sentence>TUF ( x=s ) = ~ AC ( x=s , y ) ( 8 ) yEN We compute TUF ( x ) by calculating the average of each TUF ( x = s ) , weighted by the probability that x takes sense s. This can be realized by equation ( 9 ) , where P ( x = s ) is the probability that x is used in training with the sense s. TUF ( x ) = ~ P ( x=s ) .</sentence>
				<definiendum id="0">TUF</definiendum>
				<definiendum id="1">TUF</definiendum>
				<definiendum id="2">P ( x = s )</definiendum>
				<definiens id="0">( x ) by calculating the average of each TUF ( x = s ) , weighted by the probability that x takes sense s.</definiens>
			</definition>
			<definition id="6">
				<sentence>TUF ( x=s ) ( 9 ) S Given the fact that ( a ) P ( x = s ) is difficult to estimate in the current formulation , and ( b ) the cost of computation for each TUF ( x = s ) is not trivial , we temporarily approximate TUF ( x ) as in equation ( 10 ) , where K is a set of the k-best verb sense ( s ) of x with respect to the interpretation score in the current state .</sentence>
				<definiendum id="0">TUF</definiendum>
				<definiendum id="1">K</definiendum>
				<definiens id="0">a ) P ( x = s ) is difficult to estimate in the current formulation</definiens>
				<definiens id="1">a set of the k-best verb sense ( s ) of x with respect to the interpretation score in the current state</definiens>
			</definition>
			<definition id="7">
				<sentence>In equation ( 11 ) , Cmax is the maximum value of the interpretation certainty , which can be derived by substituting the maximum and the mimimum interpretation score for Si ( x ) and S2 ( x ) , respectively , in equation ( 7 ) .</sentence>
				<definiendum id="0">Cmax</definiendum>
			</definition>
			<definition id="8">
				<sentence>N is the total number of the inputs and 5 is a coefficient defined as in equation ( 12 ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of the inputs</definiens>
			</definition>
			<definition id="9">
				<sentence>1 if the interpratation of x is correct = ( 12 ) -p otherwise In equation ( 12 ) , p is the parametric constant to control the degree of the penalty for a system error .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the parametric constant to control the degree of the penalty for a system error</definiens>
			</definition>
</paper>

		<paper id="0514">
			<definition id="0">
				<sentence>• The perceived knowledge consists of the information the interlocutors perceive during the utterance situation besides speech comprehension , e.g. visual , tactile or further auditory perceptions .</sentence>
				<definiendum id="0">perceived knowledge</definiendum>
				<definiens id="0">consists of the information the interlocutors perceive during the utterance situation besides speech comprehension , e.g. visual , tactile or further auditory perceptions</definiens>
			</definition>
			<definition id="1">
				<sentence>• The inferrable knowledge consists of the relevant knowledge potentially inferrable from the remaining context-classes by means of common sense and sufficient knowledge of the currently spoken language .</sentence>
				<definiendum id="0">inferrable knowledge</definiendum>
				<definiens id="0">consists of the relevant knowledge potentially inferrable from the remaining context-classes by means of common sense and sufficient knowledge of the currently spoken language</definiens>
			</definition>
			<definition id="2">
				<sentence>The Conceptualizer creates a bipartite output stream which consists of an incremental conceptual structure CS comprising the propositional content of the intended utterance and a contextual structure CT with the currently relevant parts of the contextual environment .</sentence>
				<definiendum id="0">Conceptualizer</definiendum>
				<definiens id="0">creates a bipartite output stream which consists of an incremental conceptual structure CS comprising the propositional content of the intended utterance and a contextual structure CT with the currently relevant parts of the contextual environment</definiens>
			</definition>
			<definition id="3">
				<sentence>Information structuring creates conditions for producing the most felicitous utterance within the set of all possible utterances .</sentence>
				<definiendum id="0">Information structuring</definiendum>
				<definiens id="0">creates conditions for producing the most felicitous utterance within the set of all possible utterances</definiens>
			</definition>
</paper>

		<paper id="0210">
			<definition id="0">
				<sentence>The model for interdependence among all variables : V tag , fl , f2 , ... , fn P ( tag , fl , f2 ... . , fn ) = P ( tag , fl , f2 , ... , fn ) ( 1 ) The model for conditional independence among all non-classification variables given the value of the classification variable : V tag , fl , f2 , ... , fn P ( tag , fl , f2 ... . , fn ) = P ( flltag ) x ... x P ( fnltag ) x P ( tag ) ( 2 ) The model for independence among all variables : V tag , fl , f~ , ... , fn P ( tag , fl , f2 , ... , fn ) = P ( tag ) x P ( fl ) x P ( f2 ) x ... x P ( fn ) ( 3 ) The objective in defining the parametric form of a model is to describe the relationships among all variables in terms of only the most important interdependencies .</sentence>
				<definiendum id="0">model for interdependence</definiendum>
				<definiendum id="1">x ... x P ( fnltag ) x P</definiendum>
				<definiens id="0">among all variables : V tag , fl , f2 , ... , fn P ( tag , fl</definiens>
				<definiens id="1">all variables : V tag , fl , f~ , ... , fn P ( tag , fl</definiens>
			</definition>
			<definition id="1">
				<sentence>This probability function is the following conditional or context-specific distribution of tags , where the fi 's now denote the values assumed by the non-classification variables in the specific context being considered .</sentence>
				<definiendum id="0">probability function</definiendum>
				<definiens id="0">the following conditional or context-specific distribution of tags , where the fi 's now denote the values assumed by the non-classification variables in the specific context being considered</definiens>
			</definition>
			<definition id="2">
				<sentence>The focus of this work is on formulating a probabilistic model ( steps ( 1 ) - ( 3 ) ) ; these steps are crucial to the success of any probabilistic classifier .</sentence>
				<definiendum id="0">probabilistic model</definiendum>
				<definiens id="0">crucial to the success of any probabilistic classifier</definiens>
			</definition>
			<definition id="3">
				<sentence>Comments : The classification performance of a probabilistie model should not be worse than that of the simplest model , the model for independence : V tag , fl , f2 , ... , fn P ( tag , fl , f2 , ... , fn ) = P ( tag ) x P ( ffl ) x P ( f2 ) × ... x P ( fn ) ( 6 ) Because the probability of seeing each value of the classification variable ( i.e. , each tag ) is independent of the context , this model assigns every object the most frequently occurring tag : argflrla~ tag = taa e ( taal/1 , Y2 , Y3 , ... , Y , ) = ar ffma~ tag P ( tag ) ( T ) Therefore , the proportion of the test set belonging to the most frequently occurring tag establishes the lower bound on model performance .</sentence>
				<definiendum id="0">x P ( ffl ) x P</definiendum>
				<definiens id="0">the model for independence : V tag , fl , f2 , ... , fn P ( tag , fl , f2 , ... , fn ) = P ( tag )</definiens>
			</definition>
			<definition id="4">
				<sentence>105 which the parameters have been estimated from the training data : Of the portion of the test set that is assigned some tag by a classifier using that model to tag the test set , precision is the percentage that is tagged correctly .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the parameters have been estimated from the training data : Of the portion of the test set that is assigned some tag by a classifier using that model to tag the test set</definiens>
			</definition>
</paper>

		<paper id="0303">
			<definition id="0">
				<sentence>Although these treatments allow for the efficient use of productive lexical rules , they do not address the issue of semi-productivity of derivational morphological and sense extension rules , which causes considerable problems in construction of broad coverage lexical knowledge bases ( LKBs ) ( see , for example , Climent and Mart/ ( 1995 ) , Pirelli et al. , 1994 ) .</sentence>
				<definiendum id="0">sense extension rules</definiendum>
				<definiens id="0">causes considerable problems in construction of broad coverage lexical knowledge bases</definiens>
			</definition>
			<definition id="1">
				<sentence>EVENT : e |EVENT : e | e ARG : \ [ \ ] L ARG : \ [ \ ] J create/transfer-lexeme-fsm ( trans ( 0.2 ) , to-ditrans ( 0.3 ) ... ) Figure h Lexeme for fax dative-lr @ transf °rlr~to .</sentence>
				<definiendum id="0">EVENT</definiendum>
				<definiendum id="1">create/transfer-lexeme-fsm</definiendum>
				<definiens id="0">e |EVENT : e | e ARG : \ [ \ ] L ARG : \ [ \ ] J</definiens>
			</definition>
			<definition id="2">
				<sentence>We can estimate the relative productivity of each lexical rule by calculating the ratio of possible to attested outputs for each rule ( cf Aronoff , 1976 ) : M Prod ( lexical-rule ) = T ( where N is the number of attested lexical entries which match the lexical rule input and M is the number of attested output entries ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">the number of attested lexical entries which match the lexical rule input</definiens>
				<definiens id="1">the number of attested output entries )</definiens>
			</definition>
</paper>

		<paper id="0503">
			<definition id="0">
				<sentence>A requirements analyst builds a formal objectoriented ( OO ) data model ( modeling ) .</sentence>
				<definiendum id="0">requirements analyst</definiendum>
				<definiens id="0">builds a formal objectoriented ( OO ) data model ( modeling )</definiens>
			</definition>
			<definition id="1">
				<sentence>• MoDEx uses a simple modeling language , which is based on the ODL standard developed by the Object Database Management Group ( OMC ) ( Cattail , 1994 ) .</sentence>
				<definiendum id="0">MoDEx</definiendum>
			</definition>
			<definition id="2">
				<sentence>The MODEx expects classes to be labeled with singular nouns , and relations to be labeled with third person singular active verbs , passive verbs with by , or nouns .</sentence>
				<definiendum id="0">MODEx</definiendum>
				<definiens id="0">expects classes to be labeled with singular nouns , and relations to be labeled with third person singular active verbs , passive verbs with by , or nouns</definiens>
			</definition>
			<definition id="3">
				<sentence>It has been integrated with two object-oriented modeling environments , the ADM ( Advanced Development Model ) of the KBSA ( Knowledge-Based Software Assistant ) ( DeBellis et al. , 1992 ) , and with Ptech , a commercial off-the-shelf object modeling tool .</sentence>
				<definiendum id="0">ADM</definiendum>
				<definiens id="0">Advanced Development Model ) of the KBSA ( Knowledge-Based Software Assistant ) ( DeBellis et al. , 1992 ) , and with Ptech , a commercial off-the-shelf object modeling tool</definiens>
			</definition>
</paper>

		<paper id="0510">
			<definition id="0">
				<sentence>The Cb is defined as the highest thematically ranked element in the previous utterance that also occurs in the current utterance .</sentence>
				<definiendum id="0">Cb</definiendum>
				<definiens id="0">the highest thematically ranked element in the previous utterance that also occurs in the current utterance</definiens>
			</definition>
			<definition id="1">
				<sentence>Their semantic representations contain the propositions call ( computer , prisoner ) and plugin ( prisoner ) , after anaphora resolution and inferences such as that call ( computer , prisoner ) is equivalent to make ( a computerized call , to a former prisoner 's home ) .</sentence>
				<definiendum id="0">plugin</definiendum>
				<definiens id="0">a computerized call , to a former prisoner 's home )</definiens>
			</definition>
</paper>

		<paper id="0307">
			<definition id="0">
				<sentence>In addition , an aggregation is defined to be a set of aggregates with the requirements that their join yield the greatest aggregate ( that is , the unit aggregate ) and that it be minimal , in the sense that , no aggregate in the set is a proper sub-aggregate of any other aggregate in the set .</sentence>
				<definiendum id="0">aggregation</definiendum>
				<definiens id="0">a set of aggregates with the requirements that their join yield the greatest aggregate ( that is , the unit aggregate ) and that it be minimal , in the sense that , no aggregate in the set is a proper sub-aggregate of any other aggregate in the set</definiens>
			</definition>
			<definition id="1">
				<sentence>Indeed , emotion is a mass noun which converts to a count noun with the correlated shift in meaning of kinds of emotion .</sentence>
				<definiendum id="0">emotion</definiendum>
				<definiens id="0">a mass noun which converts to a count noun with the correlated shift in meaning of kinds of emotion</definiens>
			</definition>
			<definition id="2">
				<sentence>This can be formalized as follows is a kind of I ( Nm\ ] } is an instance of \ [ ( Nml } is a unit of \ [ ( Nml } is a source of I ( gml } ( where 'Nm ' denotes a mass noun , 'Co ' denotes the morphological operation of conversion from a mass noun to a count noun , and '\ ] \ ] ' denotes the interpretation function ) .</sentence>
				<definiendum id="0">'Nm</definiendum>
				<definiens id="0">a kind of I ( Nm\ ] } is an instance of \ [</definiens>
				<definiens id="1">a unit of \ [ ( Nml } is a source of I ( gml }</definiens>
				<definiens id="2">the morphological operation of conversion from a mass noun to a count noun</definiens>
			</definition>
			<definition id="3">
				<sentence>This can be formalized as follows ( where 'No ' denotes a count noun , 'Cm ' denotes the morphological operation of conversion from a count noun to a mass noun , '~r ' is a function which associates with an object its parts 6 and '1 I ' denotes the interpretation function ) .</sentence>
				<definiendum id="0">'No '</definiendum>
				<definiens id="0">a function which associates with an object its parts 6 and '1 I ' denotes the interpretation function )</definiens>
			</definition>
			<definition id="4">
				<sentence>ICm ( Nc ) l = for some y E I ( Ncl } Above , I presented a semantic , syntactic , and morphological account of the mass count distinction and I have shown how that account can be extended to accommodate the fact that mass nouns can be converted into count nounS and count nouns into mass nouns , with concomitant shifts in the meanings of the nouns .</sentence>
				<definiendum id="0">ICm</definiendum>
			</definition>
			<definition id="5">
				<sentence>( 25.1 ) Eric is a veritable Napoleon .</sentence>
				<definiendum id="0">Eric</definiendum>
			</definition>
</paper>

		<paper id="0305">
			<definition id="0">
				<sentence>A DEFINITION scheme begins with a genus term ( that is , conceptual parent or ancestor of the sense ) , followed by the so-called differentia that consists of words : semanficaUy related to the sense to provide specifics about the sense .</sentence>
				<definiendum id="0">DEFINITION</definiendum>
				<definiens id="0">consists of words : semanficaUy related to the sense to provide specifics about the sense</definiens>
			</definition>
			<definition id="1">
				<sentence>To facilitate estimation of similarity between a definition sentence and a topic , we use TOPS to denote the list of words under a LLOCE topic S , while REFS denotes the list of words under cross references of S. For instance , the label Jel04 ( as well as Jel06 ) is associated with a list of words from its topic ( TOPJel04 ) and cross reference ( REFJe l 04 = TOPDe ) : TOPJe l04 = TOPJe = { affluent , budget , cut down , deficit , economize , fortune , giro , income , keep , luxury , maintenance , needy , pay , windfall , amenity ... . } REFJeI04 = TOPDe = { bring back , contribution , doff , equip , facility , keep , yield , ... } .</sentence>
				<definiendum id="0">REFS</definiendum>
				<definiendum id="1">label Jel04</definiendum>
				<definiens id="0">the list of words under cross references of S. For instance , the</definiens>
				<definiens id="1">{ affluent , budget , cut down , deficit , economize , fortune , giro , income , keep , luxury , maintenance , needy , pay , windfall , amenity ... . } REFJeI04 = TOPDe = { bring back , contribution , doff , equip , facility , keep , yield , ... }</definiens>
			</definition>
</paper>

		<paper id="0411">
			<definition id="0">
				<sentence>In TG/2 preconditions are tests over the database contents ( the generator 's input structure ) , and actions typically lead to a new subset of rules the applicabilitv of which would be tested on some selected portion of the database .</sentence>
				<definiendum id="0">TG/2 preconditions</definiendum>
				<definiens id="0">tests over the database contents ( the generator 's input structure ) , and actions typically lead to a new subset of rules the applicabilitv of which would be tested on some selected portion of the database</definiens>
			</definition>
			<definition id="1">
				<sentence>GIL is the basis for the precondition test predicates and the selector functions of TGL .</sentence>
				<definiendum id="0">GIL</definiendum>
				<definiens id="0">the basis for the precondition test predicates and the selector functions of TGL</definiens>
			</definition>
			<definition id="2">
				<sentence>The example shows the major language elements : • The top level consists of a speech act predicate and arguments for author , addressee and theme ( the speechact proper ) .</sentence>
				<definiendum id="0">top level</definiendum>
				<definiens id="0">consists of a speech act predicate and arguments for author , addressee and theme ( the speechact proper )</definiens>
			</definition>
			<definition id="3">
				<sentence>• SMOOD expresses sentence modalities in103 \ [ ( PRED request ) ( HEARER \ [ ( ID refo365 ) ( SET &lt; nussbaum &gt; ) \ ] ) ( SPEAKER \ [ ( ID refo752 ) ( SET &lt; digisec &gt; ) \ ] ) ( THEME \ [ ( SMOOD \ [ ( TOPIC # i ) ( MODALITY unmarked ) ( TIME pres ) \ ] ) ( PRED meet ) ( DREF \ [ ( ID refo610 ) ( SET &lt; meetl &gt; ) \ ] ) ( ARGS &lt; # 1= \ [ ( ROLE agent ) ( CARD single ) ( CONTENT \ [ ( DREF \ [ ( ID refo621 ) ( SET &lt; zweig &gt; ) \ ] ) ( QFORCE noquant ) ( PRED humname ) ( NAME \ [ ( TITLE \ '' Prof.\ '' ) ( SURNAME \ '' Zweig\ '' ) ( SORT female ) \ ] ) \ ] ) \ ] , \ [ ( ROLE patient ) ( CARD single ) ( CONTENT \ [ ( DREF \ [ ( ID refo365 ) ( SET &lt; nussbaum &gt; ) \ ] ) ( QFORCE iota ) ( PRED object ) \ ] ) \ ] &gt; ) ( TIME-ADJ \ [ ( ROLE on ) ( CONTENT \ [ ( WEEKDAY 5 ) \ ] ) \ ] ) \ ] ) \ ] Figure 2 : A sample GIL input structure ( Prof. Zweig will Sic am Freitag treffen \ [ Prof. Zweig wants to meet you on Friday\ ] .</sentence>
				<definiendum id="0">SMOOD</definiendum>
				<definiens id="0">expresses sentence modalities in103 \ [ ( PRED request ) ( HEARER \ [ ( ID refo365 ) ( SET &lt; nussbaum &gt; ) \ ] ) ( SPEAKER \ [ ( ID refo752 ) ( SET &lt; digisec &gt; ) \ ] ) ( THEME \ [ ( SMOOD \ [ ( TOPIC # i ) ( MODALITY unmarked ) ( TIME pres ) \ ] ) ( PRED meet ) ( DREF \ [</definiens>
				<definiens id="1">ROLE agent ) ( CARD single ) ( CONTENT \ [ ( DREF \ [ ( ID refo621 ) ( SET &lt; zweig &gt; ) \ ] ) ( QFORCE noquant ) ( PRED humname ) ( NAME \ [</definiens>
			</definition>
			<definition id="4">
				<sentence>Language ( TGL ) TGL defines a general format for expressing production rules as precondition-action pairs ( cf. Figure 3 ) .</sentence>
				<definiendum id="0">Language ( TGL ) TGL</definiendum>
			</definition>
			<definition id="5">
				<sentence>SPL : A sentence plan language for text generation .</sentence>
				<definiendum id="0">SPL</definiendum>
				<definiens id="0">A sentence plan language for text generation</definiens>
			</definition>
			<definition id="6">
				<sentence>Zebu : A Tool for Specifying Reversible LALR ( 1 ) Parsers .</sentence>
				<definiendum id="0">Zebu</definiendum>
			</definition>
</paper>

		<paper id="0111">
			<definition id="0">
				<sentence>DOP1 uses substitution for the combination of subtrees .</sentence>
				<definiendum id="0">DOP1</definiendum>
				<definiens id="0">uses substitution for the combination of subtrees</definiens>
			</definition>
			<definition id="1">
				<sentence>DOP1 estimates the probability of substituting a subtree ti on a specific node as the probability of selecting ti among all subtrees in the corpus that could be substituted on that node .</sentence>
				<definiendum id="0">DOP1</definiendum>
				<definiens id="0">estimates the probability of substituting a subtree ti on a specific node as the probability of selecting ti among all subtrees in the corpus that could be substituted on that node</definiens>
			</definition>
			<definition id="2">
				<sentence>Sima'an ( 1995 ) gives an efficient polynomial algorithm for selecting the parse corresponding to the most probable derivation .</sentence>
				<definiendum id="0">Sima'an ( 1995 )</definiendum>
				<definiens id="0">gives an efficient polynomial algorithm for selecting the parse corresponding to the most probable derivation</definiens>
			</definition>
			<definition id="3">
				<sentence>The parse accuracy is defined as the percentage of test sentences for which the most probable parse exactly matches with the test set parse .</sentence>
				<definiendum id="0">parse accuracy</definiendum>
			</definition>
			<definition id="4">
				<sentence>DOP2 is a very simple extension of DOPI : assign all lexical categories to each unknown word , and select the most probable parse among the parses of all resulting `` sentences '' by means of DOP1 .</sentence>
				<definiendum id="0">DOP2</definiendum>
				<definiens id="0">a very simple extension of DOPI : assign all lexical categories to each unknown word , and select the most probable parse among the parses of all resulting `` sentences '' by means of DOP1</definiens>
			</definition>
			<definition id="5">
				<sentence>To do that , Good-Turing uses an additional notion , represented by Nr , which is defined as the number of types which are instantiated by r tokens in an observed sample : Nr = # ( { t I fit ) = r } ) .</sentence>
				<definiendum id="0">Good-Turing</definiendum>
				<definiendum id="1">Nr</definiendum>
				<definiens id="0">uses an additional notion , represented by</definiens>
				<definiens id="1">the number of types which are instantiated by r tokens in an observed sample : Nr = # ( { t I fit ) = r } )</definiens>
			</definition>
			<definition id="6">
				<sentence>Among others , it is shown that DOP3 displays a preference for parses constructed by generalizing over a minimal number of words , and that DOP3 prefers parses that generalize over open-class words to parses that generalize over closed-class words .</sentence>
				<definiendum id="0">DOP3</definiendum>
				<definiens id="0">displays a preference for parses constructed by generalizing over a minimal number of words , and that DOP3 prefers parses that generalize over open-class words to parses that generalize over closed-class words</definiens>
			</definition>
			<definition id="7">
				<sentence>Unfortunately , the ATIS corpus contains several abbreviations and proper nouns that are not found in a dictionary , and which therefore still need to be treated as unknown by means of DOP3 .</sentence>
				<definiendum id="0">ATIS corpus</definiendum>
				<definiens id="0">contains several abbreviations and proper nouns that are not found in a dictionary , and which therefore still need to be treated as unknown by means of DOP3</definiens>
			</definition>
			<definition id="8">
				<sentence>DOP4 puts all lexical categories ( p-o-s tags ) of the sentence words , as found in a dictionary , in the chart .</sentence>
				<definiendum id="0">DOP4</definiendum>
				<definiens id="0">puts all lexical categories ( p-o-s tags ) of the sentence words</definiens>
			</definition>
</paper>

		<paper id="0412">
			<definition id="0">
				<sentence>The beginning of a `` sentence '' is the beginning of a discourse segment in our implementation ( Yeh95 ) .</sentence>
				<definiendum id="0">beginning of a `` sentence</definiendum>
				<definiens id="0">the beginning of a discourse segment in our implementation ( Yeh95 )</definiens>
			</definition>
</paper>

		<paper id="0302">
</paper>

		<paper id="0511">
			<definition id="0">
				<sentence>As we have seen , RST relations can be fully integrated with the richer SFM framework by restating the 'sister-dependency ' relations of RST as occurring via their mother unit , i.e. in an 'element and unit ' model .</sentence>
				<definiendum id="0">RST relations</definiendum>
				<definiens id="0">occurring via their mother unit</definiens>
			</definition>
			<definition id="1">
				<sentence>The answer seems to be that GENEDIS , which is itself adapted from the sentence generator GENESYS , provides an appropriately rich and relevant array of o.perators .</sentence>
				<definiendum id="0">answer seems</definiendum>
				<definiens id="0">to be that GENEDIS , which is itself adapted from the sentence generator GENESYS , provides an appropriately rich and relevant array of o.perators</definiens>
			</definition>
			<definition id="2">
				<sentence>This suggests in turn the value of the particular set of concepts incorporated into the Cardiff Grammar , and of the grammar-writing tool DEFREL , in which both GENESYS and GENEDIS are written .</sentence>
				<definiendum id="0">DEFREL</definiendum>
				<definiens id="0">turn the value of the particular set of concepts incorporated into the Cardiff Grammar , and of the grammar-writing tool</definiens>
			</definition>
</paper>

		<paper id="0506">
			<definition id="0">
				<sentence>PICARD enables similar results for the field of text planning by recasting localized means-end planning instances into abstractions connected by usage constraints that allow HUNTER-GATHERER to process the global problem as a simple constraint satisfaction problem .</sentence>
				<definiendum id="0">PICARD</definiendum>
				<definiens id="0">enables similar results for the field of text planning by recasting localized means-end planning instances into abstractions connected by usage constraints that allow HUNTER-GATHERER to process the global problem as a simple constraint satisfaction problem</definiens>
			</definition>
			<definition id="1">
				<sentence>HUNTER-GATHERER is a general control strategy that works particularly well for NL problems .</sentence>
				<definiendum id="0">HUNTER-GATHERER</definiendum>
			</definition>
			<definition id="2">
				<sentence>Instead , solution synthesis operates with maximally interacting groupings ( circles ) of variables of any order and extends to the highest levels of synthesizing .</sentence>
				<definiendum id="0">solution synthesis</definiendum>
				<definiens id="0">operates with maximally interacting groupings ( circles ) of variables of any order and extends to the highest levels of synthesizing</definiens>
			</definition>
			<definition id="3">
				<sentence>Besides this limitation , HUNTER-GATHERER is guaranteed to find the same solution ( s ) as an exhaustive search .</sentence>
				<definiendum id="0">HUNTER-GATHERER</definiendum>
				<definiens id="0">an exhaustive search</definiens>
			</definition>
			<definition id="4">
				<sentence>By converting means-end planners into a format that can be used by HUNTER-GATHER , PICARD achieves efficient processing with guaranteed soundness and completeness without sacrificing the generality of means-end planning .</sentence>
				<definiendum id="0">PICARD</definiendum>
				<definiens id="0">achieves efficient processing with guaranteed soundness and completeness without sacrificing the generality of means-end planning</definiens>
			</definition>
</paper>

		<paper id="0112">
			<definition id="0">
				<sentence>LPR is a lexical semantic principle , while RAP and ALPP are syntactic ones , and in psycholinguistics it is commonly claimed that LPR overrides RAP and ALPP ( Hobbs and Bear , 1990 ) .</sentence>
				<definiendum id="0">LPR</definiendum>
				<definiens id="0">a lexical semantic principle</definiens>
			</definition>
			<definition id="1">
				<sentence>LPR implies that ( in natural language ) one should communicate as relevantly as possible , while RAP and ALPP implies that one should communicate as efficiently as possible .</sentence>
				<definiendum id="0">LPR</definiendum>
			</definition>
			<definition id="2">
				<sentence>Assuming that 1 is known to be 5 , if H is a verb phrase and M is a prepositional phrase , the preference value is likely to be high , but if H is a noun phrase and M is a prepositional phrase , it is likely to be low .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">a verb phrase</definiens>
				<definiens id="1">a prepositional phrase</definiens>
				<definiens id="2">a noun phrase</definiens>
				<definiens id="3">a prepositional phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>n ( I ) = ( 14 ) i=l where Si denotes the syntactic preference value of the ith attachment in the syntactic tree of interpretation I , and m the number of attachments in it .</sentence>
				<definiendum id="0">Si</definiendum>
				<definiens id="0">the syntactic preference value of the ith attachment in the syntactic tree of interpretation I , and m the number of attachments in it</definiens>
			</definition>
			<definition id="4">
				<sentence>RAP prefers an interpretation attached to a nearer phrase , while ALPP prefers interpretations with attachments that are low and in parallel .</sentence>
				<definiendum id="0">RAP</definiendum>
				<definiens id="0">prefers an interpretation attached to a nearer phrase</definiens>
			</definition>
			<definition id="5">
				<sentence>Considering the fact that individual rules will be applied with different frequency , it is desirable to modify the syntactic preference to f ( ll , 12 , ... , lk , ( L ~ R1 , R2 , ... , Rk ) ) ( 16 ) f ( ( L -R1 , R2 , ... , Rk ) ) ' where f ( ( L -+ R1 , R2 , ... , Rk ) ) denotes the frequence of application of CFG rule L -- + R1 , R~ , ... , Rk .</sentence>
				<definiendum id="0">R2 , ... , Rk )</definiendum>
				<definiendum id="1">R2 , ... , Rk ) )</definiendum>
			</definition>
			<definition id="6">
				<sentence>However since LPR overrides RAP and ALPP , a simpler approach is to adopt the back-off method , i.e. , to rank interpretations/1 and I2 as follows : ( 23 ) where/1 and/2 denote any two interpretations , Pl= ( ) denotes the lexical likelihood of an interpretation , and Psyn ( ) the syntactic likelihood of an interpretation .</sentence>
				<definiendum id="0">Pl= ( )</definiendum>
				<definiendum id="1">Psyn ( )</definiendum>
				<definiens id="0">the lexical likelihood of an interpretation</definiens>
				<definiens id="1">the syntactic likelihood of an interpretation</definiens>
			</definition>
			<definition id="7">
				<sentence>Ptex3 ( ) denotes the lexical likelihood value of an interpretation calculated as the geometric mean of three-word probabilities , Pte,2 ( ) the lexical likelihood value of an interpretation calculated as the geometric mean of two-word probabilities , and Psyn ( ) the syntactic likelihood value of an interpretation .</sentence>
				<definiendum id="0">Ptex3 ( )</definiendum>
				<definiendum id="1">Psyn ( )</definiendum>
				<definiens id="0">the lexical likelihood value of an interpretation calculated as the geometric mean of three-word probabilities</definiens>
				<definiens id="1">the syntactic likelihood value of an interpretation</definiens>
			</definition>
</paper>

		<paper id="0208">
			<definition id="0">
				<sentence>We compare a naive Bayesian classifier ( Duda &amp; Hart , 1973 ) , a perceptron ( Rosenblatt , 1962 ) , a decision-tree learner ( Quinlan , 1993 ) , a k nearest-neighbor classifier ( Cover &amp; Hart , 1967 ) , logic-based DNF ( disjunctive normal form ) and CNF ( conjunctive normal form ) learners ( Mooney , 1995 ) and a decisionlist learner ( Rivest , 1987 ) .</sentence>
				<definiendum id="0">decision-tree learner</definiendum>
				<definiens id="0">disjunctive normal form</definiens>
				<definiens id="1">conjunctive normal form ) learners ( Mooney , 1995</definiens>
			</definition>
			<definition id="1">
				<sentence>Naive Bayes is intended as a simple representative of statistical methods and nearest neighbor as a simple representative of instancebased ( case-based , exemplar ) methods ( Cover Hart , 1967 ; Aha , Kibler , ~ Albert , 1991 ) .</sentence>
				<definiendum id="0">Naive Bayes</definiendum>
				<definiendum id="1">instancebased</definiendum>
				<definiens id="0">a simple representative of statistical methods and nearest neighbor as a simple representative of</definiens>
			</definition>
			<definition id="2">
				<sentence>Alternative instance-based methods that weight features based on their predictive ability have also been developed ( Aha et al. , 1991 ) .</sentence>
				<definiendum id="0">Alternative instance-based</definiendum>
			</definition>
</paper>

		<paper id="0407">
			<definition id="0">
				<sentence>The realization stage linearizes the plan and takes care of the ellipsis , conjoined structures , punctuation and morphological forms .</sentence>
				<definiendum id="0">realization stage</definiendum>
				<definiens id="0">linearizes the plan and takes care of the ellipsis , conjoined structures</definiens>
			</definition>
			<definition id="1">
				<sentence>The knowledge elicitation scenario consists in the system requesting the user , in English , to supply information about the invention , its components , their properties and relations among them .</sentence>
				<definiendum id="0">knowledge elicitation scenario</definiendum>
			</definition>
			<definition id="2">
				<sentence>The user-supplied information is recorded using a simple text representation language : text : := ( template } { template } * template : := ( label predicate-class predicate ( { case-role } ( caserole } * ) case-role : := ( rank ( ( label-string ) value ) ) where label is a unique identifier of the template ( by convention , marked by the number of its predi63 cate ) , predicate-class is the label of a synonym set of predicate-type words , see below , predicate is a string corresponding tO one of the predicates from the system lexicon , case roles are ranked 1 based on their frequency of cooccurrence with each predicate in the training corpus 2 and value is the string which fills a case role .</sentence>
				<definiendum id="0">label</definiendum>
				<definiendum id="1">predicate-class</definiendum>
				<definiendum id="2">predicate</definiendum>
				<definiens id="0">a unique identifier of the template ( by convention , marked by the number of its predi63 cate</definiens>
				<definiens id="1">the label of a synonym set of predicate-type words</definiens>
				<definiens id="2">a string corresponding tO one of the predicates from the system lexicon , case roles are ranked 1 based on their frequency of cooccurrence with each predicate in the training corpus 2 and value is the string which fills a case role</definiens>
			</definition>
			<definition id="3">
				<sentence>A label-string consists of a grammatical class symbol ( see Table 1 ) and a unique ordinal number for each distinct string .</sentence>
				<definiendum id="0">label-string</definiendum>
				<definiens id="0">consists of a grammatical class symbol ( see Table 1 ) and a unique ordinal number for each distinct string</definiens>
			</definition>
			<definition id="4">
				<sentence>A sample template using `` mounted : ' The patent sublanguage is a union of a legal sublanguage and a sublanguage of the domain of the invention .</sentence>
				<definiendum id="0">patent sublanguage</definiendum>
				<definiens id="0">a union of a legal sublanguage and a sublanguage of the domain of the invention</definiens>
			</definition>
			<definition id="5">
				<sentence>Verb entries in the system 's lexicon consist of a number of zones as follows : • Zone I lists all morphological forms of the verb in which it is expected to occur in patent texts .</sentence>
				<definiendum id="0">Verb entries</definiendum>
				<definiens id="0">in the system 's lexicon consist of a number of zones as follows : • Zone I lists all morphological forms of the verb in which it is expected to occur in patent texts</definiens>
			</definition>
			<definition id="6">
				<sentence>The contexts are characterized by a ) existence of matching elements in the two segments ; b ) quality of the match ; c ) the position in the segments of the matching elements and d ) the relative position of partially matched strings .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiens id="0">the position in the segments of the matching elements and d ) the relative position of partially matched strings</definiens>
			</definition>
</paper>

		<paper id="0103">
			<definition id="0">
				<sentence>Suppose that we want to parse sentences using a statistical parser and that sentences ( a ) and ( b ) appeared in the training and test data , respectively .</sentence>
				<definiendum id="0">sentences</definiendum>
				<definiens id="0">a ) and ( b ) appeared in the training and test data , respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>Our word bits construction algorithm ( Ushioda 1996 ) is a modification and an extension 29 of the mutual information ( MI ) clustering algorithm proposed by Brown et al. ( 1992 ) .</sentence>
				<definiendum id="0">word bits construction algorithm</definiendum>
				<definiens id="0">a modification and an extension 29 of the mutual information</definiens>
			</definition>
			<definition id="2">
				<sentence>Define a new vocabulary V ' = V1 U V2 , where V1 = { all the words in C ( i ) } , V2 = { C1 , C2 , ... , Ci-l , Ci+l , Cc } , and Cj is a token for C ( j ) for 1 &lt; j _ &lt; C. Assign each element in V ' to its own class and execute binary merging with a merging constraint such that only those classes which only contain elements of V1 can be merged .</sentence>
				<definiendum id="0">V1</definiendum>
				<definiendum id="1">Cj</definiendum>
				<definiens id="0">a token for C ( j ) for 1 &lt; j _ &lt; C. Assign each element in V ' to its own class and execute binary merging with a merging</definiens>
			</definition>
			<definition id="3">
				<sentence>The ATR Decision-Tree Part-Of-Speech Tagger is an integrated module of the ATR DecisionTree Parser which is based on SPATTER ( Magerman 1994 ) .</sentence>
				<definiendum id="0">ATR Decision-Tree Part-Of-Speech Tagger</definiendum>
				<definiendum id="1">DecisionTree Parser</definiendum>
				<definiens id="0">an integrated module of the ATR</definiens>
			</definition>
			<definition id="4">
				<sentence>By asking a value of a specific feature on each event in the set , the set can be split into N subsets where N is the number of possible values for the feature .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
			<definition id="5">
				<sentence>The ATR corpus is a comprehensive sampling of Written American English , displaying language use in a very wide range of styles and settings , and compiled from many different domains ( Black et al. 1996 ) .</sentence>
				<definiendum id="0">ATR corpus</definiendum>
				<definiens id="0">a comprehensive sampling of Written American English , displaying language use in a very wide range of styles and settings , and compiled from many different domains</definiens>
			</definition>
			<definition id="6">
				<sentence>Bits @ • LingQuest &amp; WordBits , i i i I i I J r i i 10 20 30 40 50 Clustering Text Size ( Million Words ) Figure 6 : Effects of Reshuffling for Tagging to a randomly generated bit-string .</sentence>
				<definiendum id="0">Clustering Text Size</definiendum>
				<definiens id="0">Effects of Reshuffling for Tagging to a randomly generated bit-string</definiens>
			</definition>
			<definition id="7">
				<sentence>Agency ANC Labor_Party AFL-CIO FASB NFL Federal_Aviation_Administration ACLU 38 Compound-class-171 consists of names with title many of which are politicians ' names .</sentence>
				<definiendum id="0">Agency ANC Labor_Party AFL-CIO FASB NFL Federal_Aviation_Administration ACLU 38 Compound-class-171</definiendum>
				<definiens id="0">consists of names with title many of which are politicians ' names</definiens>
			</definition>
</paper>

		<paper id="0414">
			<definition id="0">
				<sentence>The role of the text generator is to propose bilingual drafts of procedural texts intended to be integrated in maintenance manuals , and to perform rephrasing operations which may be requested by the technical author , for example grouping maintenance instructions at surface level or changing the specificity level of an instruction .</sentence>
				<definiendum id="0">generator</definiendum>
				<definiens id="0">to propose bilingual drafts of procedural texts intended to be integrated in maintenance manuals</definiens>
			</definition>
			<definition id="1">
				<sentence>We should note that these prob2A Meaning-Text model consists of the grammar and the lexicon of a particular language .</sentence>
				<definiendum id="0">prob2A Meaning-Text model</definiendum>
				<definiens id="0">consists of the grammar and the lexicon of a particular language</definiens>
			</definition>
			<definition id="2">
				<sentence>The number designates the actant of the predicative noun which is promoted as first actant ( syntactic subject ) of the operator verb .</sentence>
				<definiendum id="0">predicative noun</definiendum>
				<definiens id="0">syntactic subject ) of the operator verb</definiens>
			</definition>
			<definition id="3">
				<sentence>The rules should be able to introduce modifiers on the 'main ' predicative element of the sentence , i.e. the main verb in rx and the direct object of the operator verb ( the predicative noun ) in r2 : • In rx : an attribute of the action will be realised as an adverb linked to the main verb V by means of an attributive deep syntactic relation ( ATTR ) .</sentence>
				<definiendum id="0">operator verb</definiendum>
				<definiens id="0">the 'main ' predicative element of the sentence</definiens>
				<definiens id="1">an attribute of the action will be realised as an adverb linked to the main verb V by means of an attributive deep syntactic relation ( ATTR )</definiens>
			</definition>
</paper>

		<paper id="0110">
			<definition id="0">
				<sentence>( T , ) , where Ssem ( Ni ) , Ssyn ( Lj ) , Slex ( T k ) stand for the semantic score function , syntactic score function , and lexical score function , respectively ; they are defined as follows : S,4Ni ) =P ( NiILj , Tk , W ) S..</sentence>
				<definiendum id="0">Ssem ( Ni</definiendum>
				<definiens id="0">T k ) stand for the semantic score function , syntactic score function , and lexical score function , respectively ; they are defined as follows : S,4Ni ) =P</definiens>
			</definition>
			<definition id="1">
				<sentence>~ nere s~i I is the word senses corresponding to W ( = w : ) ; I '' : ~g ' = { l-'l , r'2 , ' '' , I '' n , } is the M i case subtrees which define the structure of the normal form N j. In such a way , the semantic score is rewritten as follows : S , ,m ( Ni ) =P ( NiI~j , Lj , Tk , W ) ( i .</sentence>
				<definiendum id="0">semantic score</definiendum>
				<definiens id="0">the word senses corresponding to W ( = w : ) ; I ''</definiens>
			</definition>
</paper>

		<paper id="0114">
			<definition id="0">
				<sentence>G3 I ( ADJ ) { NOUN ) C1 -- -~gl ( rip without an article ) ( NOUN ) ( NOUN ) C7 t ( ART ) ( NOUN ) C2 t ( PRON ) INOUN ) C5 g2 ( rip with an article ) ( INDEF ) ( NOUN ) C6 I | INDEF = { both , some , any ... . } ART = { a , the ... . } PRON = { my , his , her , their ... . } NOUN = { trip , newspaper ... . } ADJ = { high , available ... . } Figure 2 : A part of the bracket grouping process To compute the similarity of a pair of labels ( in step 2 ) , we propose two types of techniques called distributional analysis and hierarchical Bayesian cbtstering as shown in section 3 .</sentence>
				<definiendum id="0">PRON</definiendum>
				<definiens id="0">rip without an article ) ( NOUN ) ( NOUN ) C7 t ( ART ) ( NOUN ) C2 t</definiens>
				<definiens id="1">A part of the bracket grouping process To compute the similarity of a pair of labels</definiens>
			</definition>
			<definition id="1">
				<sentence>( l_A ) Nt~g N ( ~ ) s 2 where , N ( a ) is the occurrence frequency of o~ , Ntag8 is the number of terminal categories and A is a interpolation coefficient .</sentence>
				<definiendum id="0">Ntag8</definiendum>
				<definiens id="0">the occurrence frequency of o~</definiens>
			</definition>
			<definition id="2">
				<sentence>Let 's denote a posterior probability with P ( GIC ) , where C is a collection of data ( i.e. , in Figure 2 , C = { c1 , e2 , ... , CN } ) and G is a set of groups ( clusters ) ( i.e. , G = { gz , g2 , ... } ) .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">G</definiendum>
				<definiens id="0">a collection of data</definiens>
				<definiens id="1">a set of groups ( clusters ) ( i.e. , G = { gz</definiens>
			</definition>
			<definition id="3">
				<sentence>Each group ( cluster ) gj is a set of data and the groups are mutually exclusive .</sentence>
				<definiendum id="0">cluster ) gj</definiendum>
				<definiens id="0">a set of data and the groups are mutually exclusive</definiens>
			</definition>
			<definition id="4">
				<sentence>PC ( Gh ) SC ( g= ) SC ( g , ) Here PC ( G~ ) corresponds to the prior probability that N random data are classified in to a set of groups O~ .</sentence>
				<definiendum id="0">PC ( Gh ) SC</definiendum>
				<definiens id="0">the prior probability that N random data are classified in to a set of groups O~</definiens>
			</definition>
			<definition id="5">
				<sentence>SO ( g , U g , ) SIM ( g= , g , ) = SC ( g= ) SC ( g , ) SC ( g ) = I~ P ( elg ) cEg SMaximizing P ( GIC ) is a generalization of Mac/mUSh L//cel/hood estimation .</sentence>
				<definiendum id="0">SIM</definiendum>
				<definiens id="0">a generalization of Mac/mUSh L//cel/hood estimation</definiens>
			</definition>
			<definition id="6">
				<sentence>171 = ~ P ( clg , e ) P ( elg ) P ( clg ) eEEnvi~onwtc~ta , ~ , E P ( cle ) p ( elg ) e P ( elc ) P ( elg ) = P ( c ) P ( e ) where SC ( g ) expresses the probability that all the labels in a group g are produced from the group , an elementai probability P ( c\ [ g ) means the probability that a group g produces its member c and P ( elc ) denotes a relative frequency of an environment e of a label e , P ( elg ) means a relative frequency of an environment e of a group g and P ( e ) is a relative frequency of an environment e of the entire label set .</sentence>
				<definiendum id="0">SC ( g )</definiendum>
				<definiendum id="1">P ( elc )</definiendum>
				<definiendum id="2">P ( e )</definiendum>
				<definiens id="0">expresses the probability that all the labels in a group g are produced from the group , an elementai probability P ( c\ [ g ) means the probability that a group g produces its member c</definiens>
				<definiens id="1">a relative frequency of an environment e of a label e , P ( elg ) means a relative frequency of an environment e of a group g</definiens>
				<definiens id="2">a relative frequency of an environment e of the entire label set</definiens>
			</definition>
			<definition id="7">
				<sentence>In this section , we describe a criterion named differential entropy which is a measure of entropy ( perplexity ) fluctuation before and after merging a pair of labels , Let cl and c2 be the most similar pair of labels based on divergence or Bayesia~u posterior probability .</sentence>
				<definiendum id="0">differential entropy</definiendum>
				<definiens id="0">a measure of entropy ( perplexity ) fluctuation before and after merging a pair of labels</definiens>
			</definition>
			<definition id="8">
				<sentence>P~i ( e ) , Pc= ( e ) and Pc3 ( e ) are probability distributions over environment e of cl , e2 and c3 , respectively .</sentence>
				<definiendum id="0">P~i ( e )</definiendum>
				<definiendum id="1">Pc3</definiendum>
				<definiens id="0">( e ) are probability distributions over environment e of cl , e2 and c3 , respectively</definiens>
			</definition>
			<definition id="9">
				<sentence>173 Members ( INDEF ) ( NOUN ) , ( ART ) ( NOUN ) , ( PRON ) ( NOUN ) , ( DEMO ) ( NOUN ) , ( NUM ) ( NOUN ) , ( NUM ) ( UNIT ) , ( NOUN ) ( NUM ) ( ADJ ) ( NOUN ) , ( NOUN ) ( NOUN ) , ( NOUN ) ( CONJ ) ( NOUN ) 3 ( AUX ) ( VT ) ( PREP ) ( NOUN ) , ( PREP ) ( NUM ) , ( PREP ) ( PRON ) , ( ADV ) ( ADV ) , ( PTCL ) ( VI ) m I\ [ gDI ( VT ) ( NOUN ) , ( VI ) ( ADV ) , ( VT ) ( PRON ) , ( AUX ) ( VI ) , ( BE ) ( VI ) , ( BE ) ( VT ) , ( BE ) ( ADJ ) , ( ADV ) ( VI ) , ( VI ) ( PTCL ) 7 ( ADV ) ( ADJ ) 8 ( AUX ) ( ADV ) 9 ( ADV ) ( VT ) , ( VT ) ( PTGL ) , ( VI ) ( PREP ) 10 ( AUX ) ( BE ) 11 ( BE ) ( ADV ) 12 ( ADV ) ( BE ) 13 ( PRON ) ( VT ) Members 1 ( INDEF ) ( NOUN ) , ( ART ) ( NOUN ) , ( PRON ) ( NOUN ) , ( DEMO ) ( NOUN ) , ( NOUN ) ( CONJ ) ( NOUN ) 2 ( ADJ ) ( NOUN ) , ( NOUN ) ( NOUN ) 3 ( AUX ) ( VT ) , ( AUX ) ( BE ) , ( BE ) ( ADV ) , ( PTCL ) ( VT ) , ( AUX ) ( ADV ) 4 ( PREP ) ( NOUN ) , ( ADV ) ( ADV ) , ( PREP ) ( PRON ) , ( PTCL ) ( VI ) , ( PREP ) ( NUM ) 5 ( VT ) ( NOUN ) , ( Vl ) ( ADV ) , ( VT ) ( PRON ) , ( AUX ) ( VI ) , ( BE ) ( Vl ) , ( BE ) ( ADJ ) , ( BE ) ( VT ) , ( ADV ) ( VI ) , ( VI ) ( PTCL ) 6 ( ADV ) ( AD3 ) , ( NUM ) ( NOUN ) , ( NUM ) ( UNIT ) 7 ( ADV ) ( VT ) , ( VT ) ( PTCL ) , ( VI ) ( PREP ) 8 ( NOUN ) ( NUM ) , ( ADV ) ( BE ) , ( PRON ) ( VT ) Table 2 : The grouping result using divergence ( left ) and BPP ( fight ) The system says Yes The system says No The Evaluator 's Answer Yes ' No a b e d Table 3 : The number of entry pairs for evaluating accuracy To evaluate the system with the model solutions , we applied a contingency table model as one shown in Table 3 .</sentence>
				<definiendum id="0">PREP )</definiendum>
				<definiendum id="1">PREP ) ( PRON</definiendum>
				<definiendum id="2">PTCL ) ( VI</definiendum>
				<definiendum id="3">BE )</definiendum>
				<definiendum id="4">ADV</definiendum>
				<definiendum id="5">VT ) ( PTGL ) , ( VI ) ( PREP</definiendum>
				<definiendum id="6">AUX</definiendum>
				<definiendum id="7">PRON ) ( VT</definiendum>
				<definiendum id="8">PRON )</definiendum>
				<definiendum id="9">NOUN )</definiendum>
				<definiendum id="10">ADV )</definiendum>
				<definiendum id="11">PREP )</definiendum>
				<definiendum id="12">ADV</definiendum>
				<definiendum id="13">ADV</definiendum>
				<definiendum id="14">NUM</definiendum>
				<definiendum id="15">NUM</definiendum>
				<definiendum id="16">ADV</definiendum>
				<definiens id="0">INDEF ) ( NOUN ) , ( ART ) ( NOUN ) , ( PRON ) ( NOUN ) , ( DEMO ) ( NOUN ) , ( NUM ) ( NOUN ) , ( NUM ) ( UNIT ) , ( NOUN ) ( NUM ) ( ADJ ) ( NOUN ) , ( NOUN ) ( NOUN ) , ( NOUN ) ( CONJ )</definiens>
				<definiens id="1">The number of entry pairs for evaluating accuracy To evaluate the system with the model solutions</definiens>
			</definition>
			<definition id="10">
				<sentence>In the table , a is the number of the label pairs which an evaiuator assigned in the same group and so did the system , b is the number of the pairs which an evaluator did not assign in the same group but the system did , e is the number of the pairs which an evaluator assigned but the system did not , and d is the number of the pairs which both an evaluator and the system did not assign in the same group .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">the number of the pairs which an evaluator did not assign in the same group but the system did</definiens>
				<definiens id="1">the number of the pairs which an evaluator assigned but the system did not , and d is the number of the pairs which both an evaluator and the system did not assign in the same group</definiens>
			</definition>
			<definition id="11">
				<sentence>NP • Averaged Precision ( AP ) : 2 ( fl3-1-1 ) ×PPxPR • F-measure ( FM ) : fla×PP+PR The F-measure is used as a combined measure of recall and precision , where fl is the weight of recall relative to precision .</sentence>
				<definiendum id="0">FM</definiendum>
				<definiendum id="1">fl</definiendum>
				<definiens id="0">the weight of recall relative to precision</definiens>
			</definition>
			<definition id="12">
				<sentence>A+B B+A B+C C+B C+A A+C l Measures l PR \ [ PP \ [ NR \ [ NP \ [ AR AP \ [ FM I , Averaged10 '' 6110 '' 61\ [ 0 '' 96 \ [ 0 '' 96 \ [ 0 '' 78 0 '' 78\ [ 0 '' 61l Table 5 : Comparing the grouping results obtained by the evaluators ( A , B , C ) We also make an experiment to evaluate whether divergence is a better measure than BPP , and whether the application of differential entropy to cut off the merging process is appropriate .</sentence>
				<definiendum id="0">A+B B+A B+C C+B C+A A+C</definiendum>
				<definiens id="0">a better measure than BPP , and whether the application of differential entropy to cut off the merging process is appropriate</definiens>
			</definition>
</paper>

		<paper id="0413">
			<definition id="0">
				<sentence>saw ( QI ( R , rep ( R ) ) , Q2 ( S , sample ( S ) ) ) saw ( Q3 ( R , rep ( R ) ^ of ( R , Q4 ( C , com ( C ) ) ) , Qs ( S , sample ( S ) ) ) and the purpose of the algorithm is to assign values to the Oi 's given some suitable model .</sentence>
				<definiendum id="0">QI</definiendum>
				<definiendum id="1">Q2 ( S</definiendum>
				<definiens id="0">sample ( S ) ) ) saw ( Q3 ( R , rep ( R ) ^ of ( R , Q4 ( C , com ( C ) ) )</definiens>
			</definition>
			<definition id="1">
				<sentence>O O S 's restriction is sample ( S ) in both cases R 's restriction is rep ( R ) in the first PAS and rep ( R ) Aof ( R , a ( C , company ( C ) ) in the second Since the algorithm generates quantifiers its input PASs are not exactly like these .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">sample ( S ) in both cases R 's restriction is rep (</definiens>
			</definition>
</paper>

		<paper id="0306">
			<definition id="0">
				<sentence>However , they claim that the semantic classification of verbs based on standard machine-readable dictionaries ( e.g. , the LDOCE ) is `` a hopeless pursuit \ [ since\ ] standard dictionaries are simply not equipped to offer this kind of information with consistency and exhaustiveness . ''</sentence>
				<definiendum id="0">LDOCE</definiendum>
				<definiens id="0">the semantic classification of verbs based on standard machine-readable dictionaries</definiens>
			</definition>
			<definition id="1">
				<sentence>In particular , Recall is the number of correct categorizations the algorithm gives divided by the number of correct categorizations already given in the database .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the number of correct categorizations the algorithm gives divided by the number of correct categorizations already given in the database</definiens>
			</definition>
			<definition id="2">
				<sentence>Precision , on the other hand , is the number of correct categorizations that the algorithm gives divided by the total number of categorizations that it gave .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the number of correct categorizations that the algorithm gives divided by the total number of categorizations that it gave</definiens>
			</definition>
			<definition id="3">
				<sentence>Clearly , the semantic filter constrains the possible assignments , but the question to ask is whether the constraint improves the accuracy of the assignments .</sentence>
				<definiendum id="0">semantic filter</definiendum>
			</definition>
</paper>

		<paper id="0310">
			<definition id="0">
				<sentence>( Artifact ) permits evaluation of uses ; ( Component of a system ) functions ; ( Role ) duties ; ( OrnamentaUon ) purposes ; ( Food ) pleasurability and healthfulness ; there are many others . ''</sentence>
				<definiendum id="0">Artifact</definiendum>
				<definiens id="0">permits evaluation of uses ; ( Component of a system ) functions</definiens>
			</definition>
			<definition id="1">
				<sentence>The MikroKosmos project is a component of a knowledge-based machine translation system ( see Nirenburg et al. 1992 ) .</sentence>
				<definiendum id="0">MikroKosmos project</definiendum>
				<definiens id="0">a component of a knowledge-based machine translation system</definiens>
			</definition>
			<definition id="2">
				<sentence>( 1 ) is a partial lexical entry for big , with just two of the 13 lexical zones represented : ( 1 ) ( big ( big-Adj ~CAT adj ) 91 ( SYN-STRUC ( 1 ( ( root Svarl ) ( cat n ) ( mods ( ( root $ var0 ) ) ) ) ) ( 2 ( ( root $ var0 ) ( cat adj ) ( subj ( ( root $ varl ) ( cat n ) ) ) ) ) ) ( SEM-STRUC ( LEX-MAP ( ( 1 2 ) ( size-attribute ( domain ( value ^ $ varl ) ( sem physical-object ) ) ( range ( value ( &gt; 0.75 ) ) ( relaxable-to ( value ( &gt; 0.6 ) ) ) ) ) ) ) ) ) ) SIZE is an ontological concept of the SCALAR-PHYSICAL-OBJECT-A'FrRIBUTE-PROPERTY type , with the term 'scalar ' used here , as it is customarily , primarily in the sense of 'gradable . '</sentence>
				<definiendum id="0">cat n ) ( mods</definiendum>
				<definiendum id="1">SEM-STRUC ( LEX-MAP</definiendum>
				<definiendum id="2">SIZE</definiendum>
				<definiens id="0">root $ var0 ) ( cat adj ) ( subj ( ( root $ varl ) ( cat n ) ) ) )</definiens>
				<definiens id="1">an ontological concept of the SCALAR-PHYSICAL-OBJECT-A'FrRIBUTE-PROPERTY type , with the term 'scalar ' used here</definiens>
			</definition>
			<definition id="3">
				<sentence>In the SEM-STRUC zone , instead of variables which are bound to syntactic elements , the meanings of the elements remerical values like these correspond to the feature of gradability , which extends beyond scalarity : all scalar adjectives are gradable but not all gradable adjectives are true scalars .</sentence>
				<definiendum id="0">gradability</definiendum>
				<definiens id="0">all scalar adjectives are gradable but not all gradable adjectives are true scalars</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , an entry like ( 1 ) should be read as follows : • first , the entry is the specification of a single sense , while the superentry is the set of such entries ; • the second line assigns a sense number to the entry ; • next , the adjective is assigned to its lexical category ; • the first subcategorization pattern in the SYN-STRUC zone describes the Adj-N construction ; the second subcategorization pattern describes the N-Copula-Adj construction ; • the LEX-MAP part of the SEM-STRUC zone defines the lexical semantics of the adjective by assigning it to the class of SIZE adjectives , that is , anchoring it in the ontological propertytype concept SEE and stating that it is applicable to physical objects and that its meaning is a high-value range on the SIZE scale/property .</sentence>
				<definiendum id="0">entry</definiendum>
			</definition>
			<definition id="5">
				<sentence>The most general case of a denominal adjective-entry and its connection to that of the corresponding noun is demonstrated in ( 3 ) : ( 3 ) ( i ) ( medicine ( medicine-N1 ) ( CAT n ) ( SYN-STRUC ( root Svar0 ) ( cat n ) ) ) ( SEM-STRUC ( LEX-MAP medicine ) ) ) ) ( ii ) ( medical ( medical-Adj ) ( CAT adj ) ( SYN-STRUC ( 1 ( ( root $ varl ) ( cat n ) ( mods ( ( root $ var0 ) ) ) ) ) ( 2 ( ( root $ var0 ) ( cat adj ) ( subj ( ( root $ varl ) ( cat n ) ) ) ) ) ) ( SEM-STRUC ( LEX-MAP ( ^ $ varl ( pertain-to medicine ) ) ) ) ) ) The formula of transition from the noun entry to that of the adjective is simple and transparent , and it remains constant for this type of adjective .</sentence>
				<definiendum id="0">SEM-STRUC ( LEX-MAP</definiendum>
				<definiens id="0">cat adj ) ( subj ( ( root $ varl ) ( cat n ) )</definiens>
			</definition>
			<definition id="6">
				<sentence>Each LR takes a ready entry ( El ) and creates another entry ( E2 ) out of it automatically : ( 11 ) LR ( El ) = E 2 Typically , each E 1 is produced `` manually , '' that is , by a qualified human on the basis of all the available heuristics for the lexical acquisition process ( see Raskin andNirenburg 1995 : 41-57 ) .</sentence>
				<definiendum id="0">LR</definiendum>
				<definiens id="0">takes a ready entry</definiens>
			</definition>
			<definition id="7">
				<sentence>The LR exists in at least these 6 forms , corresponding to the event or its semantic cases/thematic roles : • event-itself ( E ) , e.g. , abusive in ( 9 ) : abusive behavior ; • agent-of-event ( A ) , e.g. , abusive in ( 10 ) : abusive husband ; • beneficiary-of-event ( B ) , e.g. , free in free bird ; • theme-of-event ( T ) , e.g. , automatic in automatic elevator ; • instrument-of-event ( I ) , e.g. , poisonous in poisonous food ; • location-of-event ( L ) , e.g. , international in international company .</sentence>
				<definiendum id="0">LR</definiendum>
				<definiens id="0">abusive behavior ; • agent-of-event ( A )</definiens>
			</definition>
</paper>

		<paper id="0301">
			<definition id="0">
				<sentence>Notes on the Workshop The workshop was organized around three main themes reflecting the topic addressed in the papers we received : a large scale acquisition of semantic lexicons using a corpus-based approach b development of micro-theories addressing various topics and phenomena such as , word sense disambiguation nominal compounds deverbal adjectives inflectional morphology c position papers discussing the status of lexical rules or focusing on the dynamic aspect of knowledge sources and of cognitive processes Some ( though not necessarily all ) specific questions suggested for discussion include : What are the different types of lexical rules which should be considered in the building of computational lexicons ( inflectional and derivational morphology , verbal diatheses , regular word-sense shifts , other ) How to evaluate the cost-efficiency of the acquisition effort against the utility of the resulting lexicons .</sentence>
				<definiendum id="0">morphology c position papers</definiendum>
				<definiens id="0">inflectional and derivational morphology , verbal diatheses , regular word-sense shifts</definiens>
			</definition>
</paper>

		<paper id="0205">
			<definition id="0">
				<sentence>Suppose the input sentence is `` -~4 ) ~p/~7 ~ } ~ ENIAC 69 50 ~ 3o `` , which means `` University of Pennsylvania celebrates the 50th anniversary of ENIAC '' , where the words ~Y5~ JP/~7 ( transliteration of 'Pennsylvania ' ) and ENIAC ( the name of the world 's first computer ) are not registered in the system dictionary .</sentence>
				<definiendum id="0">ENIAC</definiendum>
			</definition>
			<definition id="1">
				<sentence>We then describe the word segmentation algorithm and the new word extraction method , with their derivation as an approximation of a generalization of the Forward-Backward algorithm ( Baum , 1972 ) .</sentence>
				<definiendum id="0">Forward-Backward algorithm</definiendum>
				<definiens id="0">with their derivation as an approximation of a generalization of the</definiens>
			</definition>
			<definition id="2">
				<sentence>The word segmentation task can be defined as finding the set of word segmentation and parts of speech assignment ( ~V , T ) that maximize the joint probability of word sequence and tag sequence given character sequence P ( W , TIC ) .</sentence>
				<definiendum id="0">word segmentation task</definiendum>
			</definition>
			<definition id="3">
				<sentence>We decompose it into the product of word length probability and word spelling probability , P ( wi\ [ &lt; U~K &gt; ) = P ( e , ... ck I &lt; UNK &gt; ) = P ( k ) P ( Cl ... ck IZ~ ) ( 5 ) where k is the length of the character sequence .</sentence>
				<definiendum id="0">ck IZ~</definiendum>
				<definiendum id="1">k</definiendum>
				<definiens id="0">into the product of word length probability and word spelling probability , P ( wi\ [ &lt; U~K &gt; ) = P ( e , ... ck I &lt; UNK &gt; ) = P ( k ) P ( Cl ...</definiens>
				<definiens id="1">the length of the character sequence</definiens>
			</definition>
			<definition id="4">
				<sentence>We call P ( k ) the word length model , and P ( cl ... ck I k ) the word spelling model .</sentence>
				<definiendum id="0">P ( k )</definiendum>
				<definiens id="0">the word length model , and P ( cl ... ck I k ) the word spelling model</definiens>
			</definition>
			<definition id="5">
				<sentence>In the generalized forward algorithm , the forward probability o~ ( wi ) is the joint probability of the character sequence c~ and the event that the final word in the segmentation of cq0 is wi that spans the substring d. Forward probabilities can be recurslvely computed as follows .</sentence>
				<definiendum id="0">forward probability o~ ( wi )</definiendum>
			</definition>
			<definition id="6">
				<sentence>O &lt; p &lt; q wiED ( c~ ) e o &lt; q &lt; . , q &lt; &lt; . 02 ) The generalized forward algorithm starts from the beginning of the input sentence , and proceeds character by character. At each point q in the sentence , it sums over the product of the forward probability of the word segmentation hypotheses ending at the point ~pq ( wl ) and the transition probability to the word hypotheses starting at that point P ( wi+l \ [ wi ) . o~ i ~ 2~ 3~ 4~ s~ 6 , Figure 4 : One Step in the Generalized Forward Algorithrn. Figure 4 shows a snapshot of the generalized forward algorithm. Tile input is ~\ [ \ ] ~i~ , and the current point q is 2. The word hypotheses ending at point 2 ( wi 6 n ( c~ ) ) are ~I~ ( Co 2 ) and \ [ \ ] ( c~ ) . Those starting at point 2 ( wi+x 6 D ( c~ ) ) are ~J.~ ( c~ ) , ~_ ( c~ ) , and ~li ( c~ ) . The string ~ $ ~ ( c25 ) is not registered in the dictionary. All combinations of these words are examined. The generalized Viterbi algorithm can be ob51 tained by replacing summation with maximization in Equation ( 12 ) . Here , Cpq ( wi ) is the probability of the most likely word segmentation sequence for the character sequence cq0 whose final word wi spans the substring c~. 6 ; ( wi+l ) = max max ¢q~ ( w , ) P ( w , +~lw , ) o_ &lt; p &lt; q ~ , ev ( ¢~ ) w , +l e D ( c ; ) , O _ &lt; q &lt; u , q &lt; r &lt; n ( 13 ) Note that tile original Forward algorithm and tile Viterbi algorithin is the special case in Equation ( 12 ) and ( 13 ) where p and q are fixed as p=q-1 andr=q+i. In order to handle unknown words , the dictionary function D returns a word hypothesis tagged as unknown word if the substring cpq is not registered in the dictionary , such as ~i.~gf ( % 5 ) in Figure 4. The word model assigns a reasonable probability to the unknown word. Therefore , in the generalized forward algorithm and the generalized Viterbi algorithm , we hypothesize all substrings in the input sentence as words , and examine all possible combinations of these word hypotheses. Since we can define the generalized Backward algorithm in the same manner , we can define the generalized Forward-Backward algorithm to estimate the word N-gram counts in Japanese texts , and to reestimate the word N-gram probabilities in the segmentation model. However , we give a more intuitive account of the method to introduce an approximation of the generalized Forward-Backward algorithm. Expected Word N-gram Count By using the above mentioned word segmentation algorithm , we can get all word segmentation hypotheses of the input sentence. Once we get them , we can estimate word N-gram count in an unsegmented Japanese corpus. Let Oj be the jth word segmentation hypothesis for the ith sentence in the corpus. P ( O~ ) can • d be cornputed by using the segmentahon model The Bayes a posleriori estimate of the word unigram count Ci ( wi ) and the word bigram count Ci ( wi_l , wi ) ill the ith sentence can be computed as , C ' ( wo ) = ~ '' ~ '' P ( Oj ) x n~ ( w~ ) ) ( 14 ) z.. , t P ( oD 3 i r- , , P ( O } ) xn~ ( w~ , c ( wo , w ) = P ( O ; ) -3 Here , . n } ( w~ ) and. ni ' ( w~'w3 Z ) denote the number of tunes the umgram w~ and the bigram w~ , w~ appeared in tile jth candidate of tile ith sentence 1 The estimate of the total unigram count C ( w~ ) and the total bigram count C ( w~ , wE ) can be obtained by summing the counts over all sentences in the corpus. c ( , ,o ) = ( 16 ) i c ( wo , = ( 17 ) i The estimate of the unigram probability and the bigram probability can be obtained as the relative frequency of the associated events. c ( wo ) ( is ) f ( w~ ) -'w C ( wo , ( 19 ) f ( wfllwc ' ) -C ( w~ ) If necessary , we can reestimate the word N-gram probabilities by replacing P ( w~ ) and P ( w~lw , ~ ) with f ( w~ ) and f ( wolw~ ) . Extraction of New Words in Texts Expected word unigram counts ( expected word frequencies ) in the corpus ( Equation ( 16 ) ) can be used as a measure of likelihood that a particular substring in the input texts is actually a word. Let 0 denote the minimum expected word frequency that we use to classify a given word hypothesis w~ as a word. C ( w. ) &gt; o ( 20 ) Those words that are not found in the dictionary and whose expected frequencies in the corpus are larger than the threshold O are extracted as the new words in the input texts .</sentence>
				<definiendum id="0">~li</definiendum>
				<definiens id="0">wi 6 n ( c~ )</definiens>
				<definiens id="1">~J.~ ( c~ ) , ~_ ( c~ ) , and</definiens>
				<definiens id="2">the probability of the most likely word segmentation sequence for the character sequence cq0 whose final word</definiens>
				<definiens id="3">the number of tunes the umgram w~ and the bigram w~ , w~ appeared in tile jth candidate of tile ith sentence 1 The estimate of the total unigram count C</definiens>
				<definiens id="4">actually a word. Let 0 denote the minimum expected word frequency that we use to classify a given word hypothesis w~ as a word. C ( w. ) &gt; o ( 20 ) Those words that are not found in the dictionary and whose expected frequencies in the corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>52 Figure 5 : An example of computing the expected word frequencies N-best word segmentation hypotheses can be obtained by using the Forward-DP Backward-A* algorithm ( Nagata , 1994 ) .</sentence>
				<definiendum id="0">segmentation</definiendum>
				<definiens id="0">An example of computing the expected word frequencies N-best word</definiens>
			</definition>
			<definition id="8">
				<sentence>First , we count the number of unknown words in the corpus segmentation ( Std ) , the number of unknown words in the system segmentation ( Sys ) , and the number of matching words ( M ) .</sentence>
				<definiendum id="0">Sys</definiendum>
				<definiens id="0">the number of unknown words in the corpus segmentation ( Std ) , the number of unknown words in the system segmentation</definiens>
			</definition>
			<definition id="9">
				<sentence>F-measure is used in Information Retrieval , and is calculated by F= ( /32+l.O ) xPxR /32 x P+R ( 23 ) where P is precision , R is recall , and/3 is the relative importance given to recall over precision .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">the relative importance given to recall over precision</definiens>
			</definition>
</paper>

		<paper id="0211">
			<definition id="0">
				<sentence>Next , the sentence analyzer processes the training sentences and creates a training case every time an instance of the ambiguity occurs .</sentence>
				<definiendum id="0">sentence analyzer</definiendum>
			</definition>
			<definition id="1">
				<sentence>The experiments described below employ the following case retrieval algorithm : in the case base and calculate for each pair : Igl Z match ( XN , , Ylv , ) i=1 where N is the set of features used to describe all instances , Ni is the ith feature in the ordered set , XN~ is the value of Ni in the problem case , YN~ is the value of Ni in the training case , and match ( a , b ) is a function that returns 1 if a and b are equal and 0 otherwise .</sentence>
				<definiendum id="0">Ni</definiendum>
				<definiendum id="1">XN~</definiendum>
				<definiendum id="2">YN~</definiendum>
				<definiendum id="3">match</definiendum>
				<definiens id="0">in the case base and calculate for each pair : Igl Z match ( XN , , Ylv , ) i=1 where N is the set of features used to describe all instances</definiens>
				<definiens id="1">the ith feature in the ordered set</definiens>
				<definiens id="2">the value of Ni in the problem case ,</definiens>
				<definiens id="3">the value of Ni in the training case</definiens>
				<definiens id="4">a function that returns 1 if a and b are equal and 0 otherwise</definiens>
			</definition>
			<definition id="2">
				<sentence>case , T , in the case base and calculate , for each pair : Igl WN , * match ( PN , , TNi ) i=1 where N is the normalized feature set , Ni is the ith feature in N , PN~ is the value of Ni in the problem case , TN~ is the value of Ni in the training case , and match ( a , b ) is a function that returns 1 if a and b are equal and 0 otherwise .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">Ni</definiendum>
				<definiendum id="2">PN~</definiendum>
				<definiendum id="3">TN~</definiendum>
				<definiendum id="4">match</definiendum>
				<definiens id="0">the normalized feature set</definiens>
				<definiens id="1">the ith feature in N ,</definiens>
				<definiens id="2">the value of Ni in the problem case</definiens>
				<definiens id="3">the value of Ni in the training case , and</definiens>
				<definiens id="4">a function that returns 1 if a and b are equal and 0 otherwise</definiens>
			</definition>
			<definition id="3">
				<sentence>The disappointing perforSentence : baseline representation : right-to-left labeling : \ [ It\ [ \ [ was\ ] \ [ the hardliners\ ] \ [ in Congress\ ] \ [ , \ ] who ... ( s entity ) ( v exists ) ( do human ) ( do-ppl entity ) ( prevl-syntactic-type prep .</sentence>
				<definiendum id="0">disappointing perforSentence</definiendum>
				<definiens id="0">s entity ) ( v exists ) ( do human ) ( do-ppl entity ) ( prevl-syntactic-type prep</definiens>
			</definition>
			<definition id="4">
				<sentence>Incorporating the Restricted Memory Bias Psychological studies have determined that people can remember at most seven plus or minus two items at any one time ( Miller , 1956 ) .</sentence>
				<definiendum id="0">Incorporating the Restricted Memory Bias Psychological</definiendum>
			</definition>
			<definition id="5">
				<sentence>To incorporate the restricted memory bias and the combined recency bias into the baseline case representation , we ( 1 ) apply the right-to-left labeling , ( 2 ) rank the features of the case according to the recency weighting , and ( 3 ) keep the n features with the highest weights ( where n is the memory limit ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the memory limit )</definiens>
			</definition>
</paper>

		<paper id="0409">
			<definition id="0">
				<sentence>Introduction Natural Language Generation is the operation of producing natural language sentences using specified communicative goals .</sentence>
				<definiendum id="0">Natural Language Generation</definiendum>
				<definiens id="0">the operation of producing natural language sentences using specified communicative goals</definiens>
			</definition>
			<definition id="1">
				<sentence>2In the glosses , 3SG denotes third person singular verbal agreement , P1PL and P3SG denote first person plural and third person singular possessive agreement , WITH denotes a derivational marker making adjectives from nouns , L0C , ABL , DAT , GEtl denote locative , ablative , dative , and genitive case markers , PAST denotes past tense , and INF denotes a marker that derives an infinitive form from a verb .</sentence>
				<definiendum id="0">WITH</definiendum>
				<definiendum id="1">PAST</definiendum>
				<definiendum id="2">INF</definiendum>
				<definiens id="0">a derivational marker making adjectives from nouns , L0C , ABL , DAT , GEtl denote locative , ablative , dative , and genitive case markers</definiens>
				<definiens id="1">past tense , and</definiens>
				<definiens id="2">a marker that derives an infinitive form from a verb</definiens>
			</definition>
			<definition id="2">
				<sentence>Sentential clauses 3Here , c-name denotes a feature structure for representing noun phrases or case-frames representing embedded sentential forms which can be used as nominal or adverbial constituents .</sentence>
				<definiendum id="0">c-name</definiendum>
				<definiens id="0">a feature structure for representing noun phrases or case-frames representing embedded sentential forms which can be used as nominal or adverbial constituents</definiens>
			</definition>
			<definition id="3">
				<sentence>MODALITY potentiality DIR-OBJ c-name SOURCE c.name GOAL c-name LOCATION c.name BENEFICIARY c-narne INSTRUMENT c-narne VALUE c-name TIME c-namePLACE e-name MANNER c-name PATH c-narne DURATION c-name `` TOPIC constituent '' FOCUS constituent BACKGR constituent Figure 1 : The case-frame for Turkish sentences .</sentence>
				<definiendum id="0">MODALITY potentiality DIR-OBJ c-name SOURCE</definiendum>
				<definiens id="0">The case-frame for Turkish sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>Non-terminals in the phrase structure part of a rule are referenced as x0 ... .. xn in the equations , where x0 corresponds to the nonterminal in the left hand side , and xn is the n th non-terminal in the right hand side .</sentence>
				<definiendum id="0">xn</definiendum>
				<definiens id="0">the n th non-terminal in the right hand side</definiens>
			</definition>
			<definition id="5">
				<sentence>To implement the sentence level generator ( described by the finite state machine presented earlier ) , we use rules of the form : Si -- -- ~ XP Sj where the Si and Sj denote some state in the finite state machine and the XP denotes the constituent to be realized while taking this transition .</sentence>
				<definiendum id="0">sentence level generator</definiendum>
				<definiendum id="1">XP</definiendum>
				<definiens id="0">the constituent to be realized while taking this transition</definiens>
			</definition>
			<definition id="6">
				<sentence>Hoffman , in her thesis ( Hoffman , 1995a , Hoffman , 1995b ) , has used the MultisetCombinatory Categorial Grammar formalism ( Hoffman , 1992 ) , an extension of Combinatory Categorial Grammar to handle free word order languages , to develop a generator for Turkish .</sentence>
				<definiendum id="0">Hoffman</definiendum>
				<definiens id="0">has used the MultisetCombinatory Categorial Grammar formalism ( Hoffman , 1992 ) , an extension of Combinatory Categorial Grammar to handle free word order languages , to develop a generator for Turkish</definiens>
			</definition>
</paper>

		<paper id="0404">
			<definition id="0">
				<sentence>Natural language generation is the process of realising communicative intentions as text ( or speech ) .</sentence>
				<definiendum id="0">Natural language generation</definiendum>
				<definiens id="0">the process of realising communicative intentions as text ( or speech )</definiens>
			</definition>
			<definition id="1">
				<sentence>The generation task is standardly broken down into the following processes : content determination ( what is the meaning to be conveyed ) , sentence planning 1 ( chunking the meaning into sentence sized units , choosing words ) , surface realisation ( determining the syntactic structure ) , morphology ( inflection of words ) , synthesising speech or formatting the text output .</sentence>
				<definiendum id="0">content determination</definiendum>
				<definiens id="0">the meaning to be conveyed ) , sentence planning 1 ( chunking the meaning into sentence sized units , choosing words ) , surface realisation ( determining the syntactic structure ) , morphology ( inflection of words</definiens>
			</definition>
			<definition id="2">
				<sentence>A graph is a set of concepts connected with relations .</sentence>
				<definiendum id="0">graph</definiendum>
				<definiens id="0">a set of concepts connected with relations</definiens>
			</definition>
			<definition id="3">
				<sentence>An utterance path is the sequence of nodes and arcs that are traversed in the process of mapping a graph to a sentence .</sentence>
				<definiendum id="0">utterance path</definiendum>
				<definiens id="0">the sequence of nodes and arcs that are traversed in the process of mapping a graph to a sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>Our generator uses a particular syntactic theory -- D-Tree Grammar ( DIG ) which we briefly introduce because the generation strategy is influenced by the linguistic structures and the operations on them .</sentence>
				<definiendum id="0">generator</definiendum>
				<definiens id="0">uses a particular syntactic theory -- D-Tree Grammar ( DIG ) which we briefly introduce because the generation strategy is influenced by the linguistic structures and the operations on them</definiens>
			</definition>
			<definition id="5">
				<sentence>¢ If the generator happens to introduce more semantic information by choosing a particular expression , LowerSem is the place where such additions can be checked for consistency .</sentence>
				<definiendum id="0">LowerSem</definiendum>
				<definiens id="0">the place where such additions can be checked for consistency</definiens>
			</definition>
			<definition id="6">
				<sentence>Initially Partial represents the syntactic-semantic correspondences which are imposed on the generator .</sentence>
				<definiendum id="0">Partial</definiendum>
				<definiens id="0">the syntactic-semantic correspondences which are imposed on the generator</definiens>
			</definition>
			<definition id="7">
				<sentence>A morphological post-processor reads the leaves of the final syntactic tree and inflects the words .</sentence>
				<definiendum id="0">morphological post-processor</definiendum>
			</definition>
			<definition id="8">
				<sentence>°Terminal mapping rules are mapping rules which have no internal generation goals and in which all terminal nodes of the syntactic structure are labelled with terminal symbols ( lexemes ) .</sentence>
				<definiendum id="0">°Terminal mapping rules</definiendum>
				<definiens id="0">in which all terminal nodes of the syntactic structure are labelled with terminal symbols ( lexemes )</definiens>
			</definition>
			<definition id="9">
				<sentence>The use of a syntactic theory ( D-Tree Grammars ) allows for the production of linguistically motivated syntactic structures which will pay off in terms of better coverage of the language and overall maintainability of the generator .</sentence>
				<definiendum id="0">D-Tree Grammars</definiendum>
				<definiens id="0">the production of linguistically motivated syntactic structures which will pay off in terms of better coverage of the language and overall maintainability of the generator</definiens>
			</definition>
</paper>

		<paper id="0308">
			<definition id="0">
				<sentence>But for them , there is only one system of knowledge , which contains both linguistic and world knowledge .</sentence>
				<definiendum id="0">knowledge</definiendum>
				<definiens id="0">contains both linguistic and world knowledge</definiens>
			</definition>
			<definition id="1">
				<sentence>67 ( 8 ) Cake is a four-letter word .</sentence>
				<definiendum id="0">Cake</definiendum>
				<definiens id="0">a four-letter word</definiens>
			</definition>
			<definition id="2">
				<sentence>( 9 ) Brownie is a seven-letter word .</sentence>
				<definiendum id="0">Brownie</definiendum>
				<definiens id="0">a seven-letter word</definiens>
			</definition>
			<definition id="3">
				<sentence>( 10 ) Cake is a noun .</sentence>
				<definiendum id="0">Cake</definiendum>
				<definiens id="0">a noun</definiens>
			</definition>
</paper>

		<paper id="0214">
			<definition id="0">
				<sentence>There are two ways to define a STSG : either as a Stochastic Tree Adjoining Grammar ( Schabes , 1992 ) restricted to substitution operations , or as an extended PCFG in which entire trees may occur on the right hand side , instead of just strings of terminals and nonterminals .</sentence>
				<definiendum id="0">STSG</definiendum>
				<definiens id="0">either as a Stochastic Tree Adjoining Grammar ( Schabes , 1992 ) restricted to substitution operations , or as an extended PCFG in which entire trees may occur on the right hand side</definiens>
			</definition>
			<definition id="1">
				<sentence>DET N vP ( ½ ) NP ( ½ ) V NP PN PN DET N s s NP VP NP VP PN PN PN PN V NP s s NP VP NP VP V NP s ( { ) NP VP PN PN V NP DET N Figure 2 : Sample STSG Produced from DOP Model Khalil Sima'an ( 1996 ) implemented a version of the DOP model , which parses efficiently by limiting the number of trees used and by using an efficient most probable derivation model .</sentence>
				<definiendum id="0">DET N vP</definiendum>
				<definiens id="0">½ ) V NP PN PN DET N s s NP VP NP VP PN PN PN PN V NP s s NP VP NP VP V NP s ( { ) NP VP PN PN V NP DET N Figure 2 : Sample STSG Produced from DOP Model Khalil Sima'an</definiens>
				<definiens id="1">parses efficiently by limiting the number of trees used and by using an efficient most probable derivation model</definiens>
			</definition>
			<definition id="2">
				<sentence>Since the total probability of the trees produced by the STSG is 1 , and the PCFG produces these trees with the same probability , no probability is `` left over '' for any other trees .</sentence>
				<definiendum id="0">PCFG</definiendum>
			</definition>
</paper>

		<paper id="0501">
			<definition id="0">
				<sentence>An FG is an FD with disjunctions and control annotations .</sentence>
				<definiendum id="0">FG</definiendum>
			</definition>
			<definition id="1">
				<sentence>A lexical process is a shallower and less semantic form of input , where the subcategorization constraints and the mapping from the thematic roles to the oblique roles \ [ 7\ ] are already specified ( instead of being automatically computed by the grammar as is the case for general process types ) .</sentence>
				<definiendum id="0">lexical process</definiendum>
				<definiens id="0">a shallower and less semantic form of input , where the subcategorization constraints and the mapping from the thematic roles to the oblique roles \ [ 7\ ] are already specified</definiens>
			</definition>
			<definition id="2">
				<sentence>( 3 ) Mood , which handles departures from the default core syntactic structure triggered by variations in terms speech acts ( e.g. , interrogative or imperative clause ) and syntactic functions ( e.g..</sentence>
				<definiendum id="0">Mood</definiendum>
				<definiens id="0">handles departures from the default core syntactic structure triggered by variations in terms speech acts ( e.g. , interrogative or imperative clause</definiens>
			</definition>
			<definition id="3">
				<sentence>( 4 ) Adverbial , which handles mapping of satellite roles onto the peripheral svntactic structure .</sentence>
				<definiendum id="0">Adverbial</definiendum>
				<definiens id="0">handles mapping of satellite roles onto the peripheral svntactic structure</definiens>
			</definition>
			<definition id="4">
				<sentence>As it stands , SURGE provides a comprehensive syntactic realization component , easy to integrate within a wide range of architectures tbr complete generation systems .</sentence>
				<definiendum id="0">SURGE</definiendum>
				<definiens id="0">provides a comprehensive syntactic realization component , easy to integrate within a wide range of architectures tbr complete generation systems</definiens>
			</definition>
</paper>

		<paper id="0207">
			<definition id="0">
				<sentence>The features selected are inflectional and certain derivational markers , and stems for open class of words , 72 TOKEN IZATION MORPHOLOGY NON-LEXICAL UNKNOWN FORMAT COLLOCATION WORD CONVERSION RECOGNIZER PROCESSOR ( / PRO/ECTION ) PREPROCESSOR MORPHOLOGICAL DISAM BIGUATION MODULE LEARNING LEARNED RULES MOI ) ULE Figure h The structure of the constraint-based morphological disambiguation system .</sentence>
				<definiendum id="0">TOKEN IZATION MORPHOLOGY NON-LEXICAL UNKNOWN FORMAT COLLOCATION WORD CONVERSION RECOGNIZER PROCESSOR ( / PRO/ECTION ) PREPROCESSOR MORPHOLOGICAL DISAM BIGUATION MODULE LEARNING LEARNED RULES MOI</definiendum>
				<definiens id="0">Figure h The structure of the constraint-based morphological disambiguation system</definiens>
			</definition>
			<definition id="1">
				<sentence>The system uses rules of the sort if LC and RC then choose PARSE or if LC and RC then delete PARSE where LC and RC are feature constraints on unambiguous left and right contexts of a given token , and PARSE is a feature constraint on the parse ( s ) that is ( are ) chosen ( or deleted ) in that context if they are subsumed by that constraint .</sentence>
				<definiendum id="0">PARSE</definiendum>
				<definiens id="0">uses rules of the sort if LC and RC then choose PARSE or if LC and RC then delete PARSE where LC and RC are feature constraints on unambiguous left and right contexts of a given token</definiens>
			</definition>
			<definition id="2">
				<sentence>The word o is either a personal or a demonstrative pronoun ( in addition to being a determiner ) .</sentence>
				<definiendum id="0">word o</definiendum>
				<definiens id="0">a personal or a demonstrative pronoun ( in addition to being a determiner )</definiens>
			</definition>
</paper>

		<paper id="0505">
			<definition id="0">
				<sentence>A knowledge specification tool allows the author to build a model of the form in the knowledge representation language LOOM .</sentence>
				<definiendum id="0">knowledge specification tool</definiendum>
				<definiens id="0">allows the author to build a model of the form in the knowledge representation language LOOM</definiens>
			</definition>
			<definition id="1">
				<sentence>IGIST ( Generating TnStructional Text ) is supported by the Commission of the European Union Grant LRE-06209 .</sentence>
				<definiendum id="0">IGIST ( Generating TnStructional Text</definiendum>
			</definition>
			<definition id="2">
				<sentence>To cover these variations , the GIST system includes a panel which allows the user to make some broad stylistic choices ( e.g. formal vs informal ; integrated instructions vs separate instructions ) .</sentence>
				<definiendum id="0">GIST system</definiendum>
			</definition>
</paper>

		<paper id="0509">
			<definition id="0">
				<sentence>LIn the appropriate context , ( la ) could also be interpreted as asking H to bring the ironing board into the basement , where S is ( or will be , at the time H executes the action ) .</sentence>
				<definiendum id="0">S</definiendum>
			</definition>
			<definition id="1">
				<sentence>LONGBOW is an extension to partial-order causal link ( POCL ) planners , in which a plan 3Note the difference between referring and grounding : an NP refers in the discourse , but it is grounded to an entity in the world .</sentence>
				<definiendum id="0">LONGBOW</definiendum>
				<definiens id="0">an extension to partial-order causal link</definiens>
			</definition>
			<definition id="2">
				<sentence>Second , LONGBOW allows to distinguish between intended and .</sentence>
				<definiendum id="0">LONGBOW</definiendum>
				<definiens id="0">allows to distinguish between intended and</definiens>
			</definition>
			<definition id="3">
				<sentence>The description will be a conjunction of descriptors d/ ; if a di consists of a unary predicate applied to param ( SIMPLE ( d/ ) ) , no recursive ( : all to INFORM-REF is necessary ; however , if di is 6We have n't addressed yet wh~l the system decides to expand the domain plan in this way .</sentence>
				<definiendum id="0">recursive</definiendum>
				<definiens id="0">consists of a unary predicate applied to param ( SIMPLE ( d/ ) ) , no</definiens>
			</definition>
			<definition id="4">
				<sentence>COMPLEX , i.e. describes a relation REL between param and other objects , INFORM-REF must be recursively called to provide a description for OTHER-PARAM ( di ) .</sentence>
				<definiendum id="0">COMPLEX</definiendum>
				<definiendum id="1">INFORM-REF</definiendum>
				<definiens id="0">a relation REL between param and other objects</definiens>
			</definition>
			<definition id="5">
				<sentence>35 Action Header : INFORM-REF ( S , H , param , depend ) Preconditions : ~ ABLE ( H , idendfy ( param ) ) Effects : ABLE ( H , identify ( param ) ) A ABLE ( H , identify ( depend ) ) Decomposition Header : Constraints : Steps : INFORM-REF ( S , H , param , depend ) 3 unique-desc ( H , param , depend , dlA ... Ad~ ) Start , '4 d , , SIMPLE ( d~ ) : INFORM ( S , H , d , ) , '¢ d~ , COMPLEX ( d~ ) : INFORM ( S , H , REL ( d , ) ) , INFORM-REF ( S , H , OTHER-PARAM ( d~ ) , d~ ) , Final , Figure 1 : The INFORM-REF operator cific demands of instructional text : and issues of Knowledge Representation , among which the need to represent both lexical and planning knowledge about action verbs .</sentence>
				<definiendum id="0">ABLE</definiendum>
			</definition>
</paper>

		<paper id="0403">
			<definition id="0">
				<sentence>The work reported here is part of a fully implemented system called PRO VERB , which produces natural language proofs from proofs found by ' automated reasoning systems \ [ 7\ ] .</sentence>
				<definiendum id="0">PRO VERB</definiendum>
			</definition>
			<definition id="1">
				<sentence>F is a subset of G. '' although the following is much more natural : `` The set F is a subset of G. '' Therefore , we came to the conclusion that an intermediate level of representation is necessary that allows flexible combinations of linguistic resources .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">a subset of G. '' although the following</definiens>
			</definition>
			<definition id="2">
				<sentence>( Derive Reasons : ( a 6F , F C G ) Method : def-subset Conclusion : a 6G ) Depending on the reference choices , the following is a possible verbalization : `` Since a is an element of F and F is a subset of G , a is an element of G by the definition of subset . ''</sentence>
				<definiendum id="0">def-subset Conclusion</definiendum>
			</definition>
			<definition id="3">
				<sentence>The Upper Model is a domain-independent property inheritance network of concepts that are hierarchically organized according to how they can be linguistically expressed .</sentence>
				<definiendum id="0">Upper Model</definiendum>
				<definiens id="0">a domain-independent property inheritance network of concepts that are hierarchically organized according to how they can be linguistically expressed</definiens>
			</definition>
			<definition id="4">
				<sentence>The Text Structure evolves by the expansion of leaves top-down and left to right .</sentence>
				<definiendum id="0">Text Structure</definiendum>
				<definiens id="0">evolves by the expansion of leaves top-down and left to right</definiens>
			</definition>
			<definition id="5">
				<sentence>This process is controlled by the main module of our microplanner , the Text Structure Generator ( TSG ) , which carries out the following algorithm : • When the current node is an APO with more than one son , apply ordering and aggregation , in order to produce more concise and more coherent text .</sentence>
				<definiendum id="0">Text Structure Generator ( TSG )</definiendum>
				<definiens id="0">carries out the following algorithm : • When the current node is an APO with more than one son</definiens>
			</definition>
			<definition id="6">
				<sentence>The realization class associated to the concept , however , contains several alternative resource trees leading to different patterns of verbalization .</sentence>
				<definiendum id="0">realization class</definiendum>
				<definiens id="0">contains several alternative resource trees leading to different patterns of verbalization</definiens>
			</definition>
			<definition id="7">
				<sentence>further resource trees . . . ) ) Figure 4 : The Realization Class for derive &lt; lex be &gt; vp head arguraent argulnent conj ( C , , C~ ) Para no no As a verb phrase • nil comproPsite \ [ matrix adjunct Para conj ( C , , CC~ ) no modifier As a nominal phrase Figure 5 : Textual Variations in form of Resource Trees The second tree in Fig .</sentence>
				<definiendum id="0">Realization Class</definiendum>
				<definiens id="0">a verb phrase • nil comproPsite \ [ matrix adjunct Para conj</definiens>
			</definition>
			<definition id="8">
				<sentence>G is a set . ''</sentence>
				<definiendum id="0">G</definiendum>
				<definiens id="0">a set</definiens>
			</definition>
			<definition id="9">
				<sentence>governing T in Q\ [ T\ ] , • concepts ( f , T ) denotes the Upper Model concepts the argument T of f may take , • concepts ( P ) denotes the Upper Model concept P may result in .</sentence>
				<definiendum id="0">f , T )</definiendum>
				<definiendum id="1">P )</definiendum>
				<definiens id="0">the Upper Model concepts the argument T of f may take</definiens>
			</definition>
			<definition id="10">
				<sentence>F is a subset of G. '' Since F is directly governed by Subset , f and Q in our rule above coincide here .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">a subset of G. '' Since F is directly governed by Subset , f</definiens>
			</definition>
			<definition id="11">
				<sentence>Let F C G. Let a E F. Let b E F. Since a E F and F C G , a E G. Since b E F and F C G , b E G. '' Aggregation of the assume-PMs results in : assume ( Set ( F ) A Set ( G ) A Subset ( F , G ) i element ( a , F ) i element ( b , F ) ) whereas the application of the grouping rule for independent derive-PMs provides : derive ( ( element ( a , F ) A element ( b , F ) A Subset ( F , G ) ) , e , ( element ( a , G ) A element ( b , G ) ) ) After that , the predicate grouping rule A.1 is applied to the arguments of assume , which are grouped to : ( Set ( F A G ) A Subset ( F , G ) A element ( a A B , F A F ) ) ) Note that F A F is later reduced to F. Predicate grouping applies to the arguments of derive in a similar way .</sentence>
				<definiendum id="0">F ) A Subset</definiendum>
				<definiendum id="1">element</definiendum>
				<definiens id="0">a E F. Let b E F. Since a E F and F C G , a E G. Since b E F and F C G , b E G. '' Aggregation of the assume-PMs results in : assume</definiens>
			</definition>
			<definition id="12">
				<sentence>PROVERB : A system explaining machine-found proofs .</sentence>
				<definiendum id="0">PROVERB</definiendum>
				<definiens id="0">A system explaining machine-found proofs</definiens>
			</definition>
</paper>

		<paper id="0212">
			<definition id="0">
				<sentence>The chart is a data structure which contains all of the constituents which may occur in the sentence being parsed .</sentence>
				<definiendum id="0">chart</definiendum>
				<definiens id="0">a data structure which contains all of the constituents which may occur in the sentence being parsed</definiens>
			</definition>
			<definition id="1">
				<sentence>Ideally , we would like to use as our figure of merit the conditional probability of that constituent , given the entire sentence , in order to choose a constituent that not only appears likely in isolation , but maximizes the likelihood of the sentence as a whole ; that is , we would like to pick the constituent that maximizes the following quantity : i P ( N~ , klto , ~ ) where to , n is the sequence of the n tags , or parts of speech , in the sentence ( numbered to , ... , tn1 ) , and Nj , k is a nonterminal of type i covering terms tj ... tk_l .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">Nj , k</definiendum>
				<definiens id="0">the conditional probability of that constituent , given the entire sentence , in order to choose a constituent that not only appears likely in isolation , but maximizes the likelihood of the sentence as a whole</definiens>
				<definiens id="1">the sequence of the n tags , or parts of speech , in the sentence ( numbered to , ...</definiens>
			</definition>
			<definition id="2">
				<sentence>Inside probability is defined as the probability of the words or tags in the constituent given that the constituent is dominated by a particular nonterminal symbol .</sentence>
				<definiendum id="0">Inside probability</definiendum>
				<definiens id="0">the probability of the words or tags in the constituent given that the constituent is dominated by a particular nonterminal symbol</definiens>
			</definition>
			<definition id="3">
				<sentence>The inside probability of the constituent N~ , k is defined as /3 ( Nj , k ) ~ p ( tj , klN i ) where N i represents the ith nonterminal symbol .</sentence>
				<definiendum id="0">inside probability of the constituent N~</definiendum>
				<definiendum id="1">k</definiendum>
				<definiendum id="2">N i</definiendum>
				<definiens id="0">represents the ith nonterminal symbol</definiens>
			</definition>
			<definition id="4">
				<sentence>Outside probability a of a constituent Nj , k is defined as the probability of that constituent and the rest of the words in the sentence ( or rest of the tags in the tag sequence , in our case ) .</sentence>
				<definiendum id="0">Outside probability</definiendum>
				<definiendum id="1">k</definiendum>
				<definiens id="0">the probability of that constituent and the rest of the words in the sentence ( or rest of the tags in the tag sequence</definiens>
			</definition>
			<definition id="5">
				<sentence>The p ( N ~ ) term is estimated from our PCFG as the sum of the counts for all rules having N i as their lefthand side , divided by the sum of the counts for all rules .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">the sum of the counts for all rules having N i as their lefthand side , divided by the sum of the counts for all rules</definiens>
			</definition>
			<definition id="6">
				<sentence>p ( Nj , klto , n ) P ( Nj , k , to , ~ ) p ( to , ) p ( tk , ~ ) p ( N ) , k , to , j Itk , ~ ) p ( tj , k \ ] Nj , k , to , j , ta , n ) p ( tk , , , ) p ( to , k\ ] tk , = ) p ( Nj , k , to , j \ ] t k , ~ ) p ( t j , k I Nj , k , to , a , t k , ~ ) p ( to , kltk , ,~ ) We again make the independence assumption that p ( tj , kINj , k , to , j , tk , ~ ) ~ fl ( Nj , k ) .</sentence>
				<definiendum id="0">k</definiendum>
				<definiens id="0">to , kltk , ,~ ) We again make the independence assumption that p ( tj , kINj , k , to , j , tk , ~ ) ~ fl ( Nj , k )</definiens>
			</definition>
</paper>

		<paper id="0418">
			<definition id="0">
				<sentence>Intonation is not only used to mark sentence-internal information structures , but additionally it can be employed in the management of the communicative demands of interaction partners .</sentence>
				<definiendum id="0">Intonation</definiendum>
				<definiens id="0">not only used to mark sentence-internal information structures , but additionally it can be employed in the management of the communicative demands of interaction partners</definiens>
			</definition>
			<definition id="1">
				<sentence>The text generation system ( KOMETPENMAN ) receives input from a dialogue module ( colt , dialogue history ) and perhaps several other information sources ( e.g. , confidence measure from a speech recognition unit ) , which will be made more precise below ( see Section 4 ) .</sentence>
				<definiendum id="0">KOMETPENMAN</definiendum>
				<definiens id="0">dialogue history ) and perhaps several other information sources ( e.g. , confidence measure from a speech recognition unit</definiens>
			</definition>
			<definition id="2">
				<sentence>A dialogue model guides the interaction between a user and an information retrieval system , i.e. , it calculates a subset of possible dialogue acts that the user action ( spoken or deictic ) could correspond to , and on the system side it calculates those dialogue acts that would provide appropriate responses to a given user action .</sentence>
				<definiendum id="0">dialogue model</definiendum>
				<definiens id="0">guides the interaction between a user and an information retrieval system</definiens>
			</definition>
			<definition id="3">
				<sentence>COR is a task independent model based on Searle 's speech act theory \ [ 29\ ] .</sentence>
				<definiendum id="0">COR</definiendum>
			</definition>
			<definition id="4">
				<sentence>Dialogue ( S ) -- &gt; ( Request ( S ) ) , ( Promise ( K ) ) , Inform ( K ) , ( Evaluate ( S ) ) , ( Dialogue ( _ ) ) Dialogue ( S ) -- &gt; ( Offer ( K ) ) , ( Accept ( S ) ) , Inform ( K ) , ( Evaluate ( S ) ) , ( Dialogue ( _ ) ) 173 Dialogue ( S ) -- &gt; 0fret ( K ) , ( Accept ( S ) ) , WithdrawOffer ( K ) , ( Dialogue ( _ ) ) Dialogue ( S ) -- &gt; 0fret ( K ) , Accept ( S ) , WithdrawAccept ( S ) , ( Dialogue ( _ ) ) Dialogue ( S ) -- &gt; Request ( S ) , ( Promise ( K ) ) , WithdrawRequest ( S ) , ( Dialogue ( _ ) ) Dialogue ( S ) -- &gt; Request ( S ) , Promise ( K ) , WithdrawPromise ( K ) , ( Dialogue ( _ ) ) Dialogue ( S ) -- &gt; 0fret ( K ) , WithdrawOffer ( K ) , ( Dialogue ( _ ) ) Dialogue ( S ) -- &gt; 0ffer ( K ) , Reject0ffer ( S ) , ( Dialogue ( _ ) ) Dialogue ( S ) -- &gt; Request ( S ) , Withdrawftequest ( S ) , ( Dialogue ( _ ) ) Dialogue ( S ) -- &gt; Request ( S ) , RejectRequest ( K ) , ( Dialogue ( _ ) ) Dialogue ( S ) -- &gt; Withdraw ( _ ) Request ( S ) -- &gt; request ( S ) , ( Dialogue ( K ) ) Request ( S ) -- &gt; request ( S ) , ( Assert ( S ) ) Request ( S ) -- &gt; Dialogue ( K ) Request ( S ) -- &gt; Assert ( S ) , ( request ( S ) ) Request ( S ) -- &gt; Assert ( S ) , ( Dialogue ( S ) ) Inform ( K ) -- &gt; inform ( K ) , ( Dialogue ( S ) ) Assert ( _ ) -- &gt; assert ( _ ) , ( Dialogue ( _ ) ) Based on the dialogue model , the system builds up a tree-like dialogue history of the ongoing dialogue ( see Section 4 ) .</sentence>
				<definiendum id="0">Evaluate</definiendum>
				<definiendum id="1">Inform ( K</definiendum>
				<definiendum id="2">Evaluate</definiendum>
				<definiendum id="3">Dialogue</definiendum>
				<definiendum id="4">Accept ( S ) ) , WithdrawOffer</definiendum>
				<definiendum id="5">Request</definiendum>
				<definiendum id="6">Promise</definiendum>
				<definiendum id="7">Dialogue</definiendum>
				<definiendum id="8">Dialogue ( S ) -- &gt; 0ffer ( K</definiendum>
				<definiens id="0">Dialogue ( _ ) ) Dialogue ( S ) -- &gt;</definiens>
			</definition>
			<definition id="5">
				<sentence>A major constraint on the mapping between speech function and mood is the kind of discourse or genre , and the type of discourse stage the message is produced in .</sentence>
				<definiendum id="0">mood</definiendum>
				<definiens id="0">the kind of discourse or genre</definiens>
			</definition>
			<definition id="6">
				<sentence>An exchange structure consists of moves which are the units for which the SPEECH FUNCTION network holds .</sentence>
				<definiendum id="0">exchange structure</definiendum>
			</definition>
			<definition id="7">
				<sentence>A linguistically based discourse model would be able to provide more information , but in the context of an interactive conversational system in which there \ [ 7\ ] are practical limits on how tong it can take to produce a response , we believe that a full fledged discourse analysis system would be too slow .</sentence>
				<definiendum id="0">linguistically based discourse model</definiendum>
				<definiens id="0">information , but in the context of an interactive conversational system in which there \</definiens>
			</definition>
</paper>

		<paper id="0106">
			<definition id="0">
				<sentence>N.+~ N~ ( 1 ) Here N~ is the number of species with frequency count x , and x* is the improved estimate of x. Let N be the size of the entire population and note that x ~r N = ~x'N. and f~ = x -- -- 1 where X is the count of the most populous species and f~ is the relative frequency of any species with frequency count x. Let r ( x ) be the rank of the last species with frequency count x. This means that quite in general r ( x ) X = Z Nk k=x X X ix = ~ ik ~ ik = r ( ~ ) r ( x + 1 ) ( 2 ) k=x k=x+l We first make a continuum approximation by extending Nx from the integer points x = 1 , 2 , ... to a continuous function N ( x ) on \ [ 1 , oo ) .</sentence>
				<definiendum id="0">Here N~</definiendum>
				<definiendum id="1">X</definiendum>
				<definiendum id="2">r ( x )</definiendum>
				<definiens id="0">the number of species with frequency count x , and x* is the improved estimate of x. Let N be the size of the entire population and note that x ~r N = ~x'N. and f~ = x -- -- 1 where</definiens>
				<definiens id="1">the count of the most populous species and f~ is the relative frequency of any species with frequency count x. Let</definiens>
			</definition>
			<definition id="1">
				<sentence>Nle-~ '' and that thus `` Turing 's asymptotic law '' is r -- 1 f ( r ) = ~-e `` ~ ( 7 ) Note that , reassuringly , the relative frequency of the most populous species , fx , is preserved : f ( 1 ) = N1 N fx r -- 1 Upon examining the frequency function -- N1 e ~ , we realize that we have an exponential 1 distribution with intensity parameter ~- , the probability of the most common species .</sentence>
				<definiendum id="0">fx</definiendum>
				<definiens id="0">an exponential 1 distribution with intensity parameter ~- , the probability of the most common species</definiens>
			</definition>
</paper>

		<paper id="0309">
			<definition id="0">
				<sentence>The Generative Lexicon ( Pustejovsky 1995 ) provides us with a model of the lexicon which couples sufficiently expressive lexical semantic representations with mechanisms which capture the relationship between those representations and their syntactic expression .</sentence>
				<definiendum id="0">Generative Lexicon</definiendum>
				<definiens id="0">provides us with a model of the lexicon which couples sufficiently expressive lexical semantic representations with mechanisms which capture the relationship between those representations and their syntactic expression</definiens>
			</definition>
			<definition id="1">
				<sentence>A bullet hole is a hole which was brought about by the passage of a bullet , and lemon juice is juice that is brought about by squeezing a lemon .</sentence>
				<definiendum id="0">bullet hole</definiendum>
				<definiens id="0">a hole which was brought about by the passage of a bullet</definiens>
			</definition>
			<definition id="2">
				<sentence>The modifier hunting is a process nominal and provides hunt as the TELIC within the TELIC of the compound .</sentence>
				<definiendum id="0">modifier hunting</definiendum>
				<definiens id="0">a process nominal and provides hunt as the TELIC within the TELIC of the compound</definiens>
			</definition>
			<definition id="3">
				<sentence>Complex nominals play an important role in the encapsulation and expression of nominal concepts and are frequent in a wide variety of types of texts .</sentence>
				<definiendum id="0">Complex nominals</definiendum>
				<definiens id="0">an important role in the encapsulation and expression of nominal concepts and are frequent in a wide variety of types of texts</definiens>
			</definition>
</paper>

		<paper id="0512">
			<definition id="0">
				<sentence>One of the major problems with the Internet is the abundance of information and the difficulty for the average computer user to read everything existing on a specific topic .</sentence>
				<definiendum id="0">Internet</definiendum>
				<definiens id="0">the abundance of information and the difficulty for the average computer user to read everything existing on a specific topic</definiens>
			</definition>
			<definition id="1">
				<sentence>SUMMONS ( SUMMarizing Online NewS articles ) is based on an architecture used in PLANDoc \ [ McKeown et al. 1994\ ] , developed jointly by Bellcore and Columbia University .</sentence>
				<definiendum id="0">SUMMONS</definiendum>
				<definiens id="0">SUMMarizing Online NewS articles ) is based on an architecture used in PLANDoc \ [ McKeown et al. 1994\ ] , developed jointly by Bellcore and Columbia University</definiens>
			</definition>
			<definition id="2">
				<sentence>KQML aims at 46 the standardization of both a protocol and a message format for communication among independent processes over a wide-area network .</sentence>
				<definiendum id="0">KQML</definiendum>
				<definiens id="0">a message format for communication among independent processes over a wide-area network</definiens>
			</definition>
			<definition id="3">
				<sentence>Such facilitators communicate through KQML performatives and exchange messages written in some content language .</sentence>
				<definiendum id="0">Such facilitators</definiendum>
				<definiens id="0">communicate through KQML performatives and exchange messages written in some content language</definiens>
			</definition>
			<definition id="4">
				<sentence>Database servers : expert agents that have access to knowledge bases which are updated periodically and which contain information that is less likely to change over the course of a summarization session ( e.g. heads of state , geographical and common-sense knowledge ) .</sentence>
				<definiendum id="0">Database servers</definiendum>
				<definiens id="0">expert agents that have access to knowledge bases which are updated periodically and which contain information that is less likely to change over the course of a summarization session ( e.g. heads of state , geographical and common-sense knowledge )</definiens>
			</definition>
</paper>

	</volume>
