<?xml version="1.0" encoding="UTF-8"?>
	<volume id="J79">

		<paper id="1063">
			<definition id="0">
				<sentence>11 ' : ( IN-THCPAST ( HAVE-EN ( BE-ING ( beat John Mary ) ) ) ) Ll and L1 ' are semantic representations for S1 and S1 ' respectively .</sentence>
				<definiendum id="0">IN-THCPAST ( HAVE-EN ( BE-ING</definiendum>
				<definiens id="0">( beat John Mary ) ) ) ) Ll and L1 ' are semantic representations for S1 and S1 ' respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>Presuppositions play an important part in the meaning of many words ; these presuppositions my therefore be associated with lexical entries .</sentence>
				<definiendum id="0">Presuppositions</definiendum>
				<definiens id="0">an important part in the meaning of many words</definiens>
			</definition>
			<definition id="2">
				<sentence>Factive predicates may be loosely defined as verbs which take embedded sentences as subject or object , and the embedded sentences can usually be replaced by pamphr &amp; ng them with ''the fact that S. '' b. The Phillies have made no trades .</sentence>
				<definiendum id="0">Factive predicates</definiendum>
				<definiens id="0">verbs which take embedded sentences as subject or object</definiens>
			</definition>
			<definition id="3">
				<sentence>Huwever , Peters suggested ( a footnote in Karttunen ( 1974 ) ) that the presuppositions of `` if A then B , '' ( where rraterial implication is the interpretation of `` if then '' ) , arising from the presuppositions of B are of the form `` if A then C '' , where C is a presupposition of B. Further , all presuppusitions of A are presupposit~ons of `` if A -then B. `` This suggestion eliminates the need for theorem proving and offers instead a simple computation similar to that for the verbs of saying and the verbs of prop0siticma .</sentence>
				<definiendum id="0">rraterial implication</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">Further</definiendum>
				<definiens id="0">the interpretation of `` if then '' ) , arising from the presuppositions of B are of the form `` if A then C '' , where</definiens>
				<definiens id="1">a presupposition of B.</definiens>
				<definiens id="2">the need for theorem proving and offers instead a simple computation similar to that for the verbs of saying and the verbs of prop0siticma</definiens>
			</definition>
			<definition id="4">
				<sentence>Hawever , when lldenyN is positive the entailnmts of the negative form of the anbedded sentence are entailed by the c-md sentence , but under the speakert s claims .</sentence>
				<definiendum id="0">lldenyN</definiendum>
			</definition>
			<definition id="5">
				<sentence>For `` if A then Bn , the entailments are of the form `` if A then Cfr , where C is an entailment of B , For ''A and B '' , the entailments are the union of the entailments of A and of the entailments of B , since both A and B are entailed by `` A and B '' .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">entailments</definiendum>
				<definiens id="0">an entailment of B</definiens>
			</definition>
			<definition id="6">
				<sentence>Semantic primitives have been investigated as the el-t with which to associate inferences .</sentence>
				<definiendum id="0">Semantic primitives</definiendum>
				<definiens id="0">the el-t with which to associate inferences</definiens>
			</definition>
			<definition id="7">
				<sentence>SEMANTIC REPRESENTATION ( ( ( ( A INDIVIDUAL / , X0067 ) ( ( JOHN / , XB061 ) ( NEQ X0 @ 63 XM61 ) ) ) / , X0 862 ) ( ASSERT I ( NOT ( IN-THE-FUTURE ( LEAVE XB062 ) ) ) ) ) NON-NP PRESUPP &amp; ~ITIONS ( ( JOHN / , X006l ) ( IN-THE-FUTURE ( LEAVE X0061 ) ) ) JOHN WILL LEAVE NP-RELATED PRESUPPOSITIONS ( ( JOHN / , X006l ) ( *UNTENSED ( IN-THE-SHARED-INFO X0061 ) ) ) JOHN IWXST WUNTENSEDIN THE SHARED INFORMATION .</sentence>
				<definiendum id="0">SEMANTIC REPRESENTATION ( ( (</definiendum>
				<definiendum id="1">INDIVIDUAL</definiendum>
				<definiendum id="2">NP-RELATED PRESUPPOSITIONS</definiendum>
				<definiens id="0">*UNTENSED ( IN-THE-SHARED-INFO X0061 ) ) ) JOHN IWXST WUNTENSEDIN THE SHARED INFORMATION</definiens>
			</definition>
			<definition id="8">
				<sentence>( Sponsored by the American Society for cybernetics and AAAS Sections 3 , T , and Q ) SCFENCE INFORMATION XNTERNAT IONAL COWUNICATION FOR RESEARCR XN BIQMEDICINE Arranged by Arthur W. Elias ( Difector of Professional Services , BioScience Informatioh Service , Phila. , Pa. ) Wednesday , 23 February Denver Miltgn , Beverly 3:00 p.m. Presiding : Arthur W , Elias ~ommunications for Research in Biomedicine in the united Kingdom and Commonwealth Countries ~rian Perry ( British Library ) Communications for Research in Biomedicine in Western EU~QP~ Rolf Fritz ( dimdi ) Communications for Research in Biomedicine in Canada George Ember ; ( National Research council ) ~ommunications for Research in ~iornedicinti ?</sentence>
				<definiendum id="0">Elias</definiendum>
			</definition>
</paper>

		<paper id="1034">
			<definition id="0">
				<sentence>HB is rn clrmtnt of &lt; HAVE , BEAMBP the set of all rlturtionr in which a physical object is chrractarizrd by a rnrarurc at itr breadth , Cartrin autgoing arc # fro % r nods rsprrrrntlnp r rituatlon are ured to specify rbtuatlon rttributrr through derp rrmrntlc crtcs , lor txrmPLe , the outgoing obprrc from 'HB ' rveettirs the value of the wobjw [ ( ObjftCt ) lttrlbutt ot HB to be DOLPHLN , Hera @ tttr the notatton a~~ojw will bt uled to indtchtc hthr vrjoe ot the attribute ( Q ) Obj** The network of Fluure 1 hat bran divL4e6 into five spacer , KSP S4r 85 , 86 , and 87 , Pictarirllyc each of thrle 8paeCa 11 tdOreatnted by ' boxc The mo8t global informrtion In the network ir encoded in rprca KS rthr outerrnofit bog , ramrtimrs erllQ4 the wKnowledqa Spacea ) which Includqs Such ~n~tltirr rr node8 'IJ ' and 'PHYBCJBJ6 ' and thr r-arc connrctlng them. Thr baxar rrprerentinp # vrcrr 84 thraugh 37 may be thought of as hole8 ln the box of KB , Patrllaling the rrlrti6nahlp botweqn an inn~r and an outer black of an ALGOL program , qach of thrm sprees 8~ecitle8 a nore lac41 rrra of the net than 18 rpeciticd by KS. From the pcrrprettvr ot 85 , far aXamDlr~ it &amp; S Pasribls to accrtr bath lacrl node *Po and ( rtlatl.vely ) Pl~brl node .PHYIOBJIF , Haravrt , from KI the nodal and rrct Inride $ 5 ate not &amp; cc &amp; # # ibl @ , The hierarchy of SPlca 1oealiertlon nay be ttprerrntcd by r partial ordering suoh rr that of Flqura 2 , From any FPICC 251 the node8 and arcs arc aCC*LISblc that lie in 6 or fh any mace S ' above 8 in tht hierrrchy , For rxawpler from 83 onty nodes and arcs in 53 , 62 , $ 1 , and KS &amp; ? Q &amp; ceersfblc , Pictorfrllyl kt may ba nscegaary to 6raw an arc crossing box baundariar , In such erars , the arc belbngs to the space ( or spacer ) In whose box tht , arc Zabrl is written , Sp &amp; ~et may overtap , For exampler in figure 1r node 'ED , HBe ller In both rpacc 84 and rpaeo 85 , Further , r spate may tcrve 4r a node in s more global Spice , Both 64 and S5 bhhsve &amp; I nodes in KS and arc connected by s conssrsrc ( ~anseq~rnce ] ~ FIGURE 2 SPACE LOCALIZATION HIERARCHY Typleally , locrllzed rpaeQ8 ruch ar $ 4 and 55 art used to @ ncoda higher-order `` ~rtdicrte~ , ~ such as quantiflarrr logical eonnrctlvrr , and hyp~thetic11 data , Here , 84 and 55 rm used to ancoda an fmpllcatlon , Thr rpaet 84 , doubling a8 a node in apace KS , Lo connected by an emarc to '*fHPtY &gt; ' and by a eanrwrrc to 'SSPr The inttt~rttati~n of any tiamant of set cLM~ty . &gt;</sentence>
				<definiendum id="0">lor txrmPLe</definiendum>
				<definiens id="0">mo8t global informrtion In the network ir encoded in rprca KS rthr outerrnofit bog , ramrtimrs erllQ4 the wKnowledqa Spacea ) which Includqs Such ~n~tltirr rr node8 'IJ '</definiens>
			</definition>
			<definition id="1">
				<sentence>PLANTS , According to node 'H* , thia power plant is the $ @ subpart in a &lt; H-AVE , PART , relrtionahlp in which SI the PartlCular mqmber of SUBS currantiy In context , is the # @ su~p.art ( Wtrp8rt ) a Discourse analY8Ls mrchani # mS dlrcusred Ln Deutrch [ 1'975f and , rare fully , in Walker rt al , ( 1975 ) will br used ta rrraclate W with the unique Wertlnphb~rr Cerporatlon known to the semantle net in space KS , The other definite NPS ( `` the sub '' and Vthc power plant ot the rub9 vwill Llkewira ba r @ ~~lv~d , ToesUpp~ $ s 8sCOndary details whtle considering the building of this structuret rrrum~ the highly airn~llfiad language deflaitiont Crammrr Irsrricon Rit 6 a &gt; NP VP NPr , the-~owar*plrnt , R2 a NP a &gt; NP PRCPP thta~~br Westinghou # e R3t VP r &gt; VB PREPP VP ; was-built R4t PREPP 8 , WEP NP PREP1 ofr by ( Note $ wthe-p~~~~~PllntR 18 not treated 4s an NP in the actual 8Ysttm0 Rsthcr , NOM npowrr plant98 first comb-tncd ~tth PREPP rnof the rubw and only afterward is `` thew appended to produce the NP `` the Power plant of the subR , ) In the trrnalatlon procerrt rpacer are created to reprarent the ternantleg of each grammatically defined conrtltuent of tne total utterance , These spaces Ire shown In Figure 4 with he8VY arrows indicating the space hlararchy , SA -380419~ FIGURE 4 MULTIPLE SCRATCH SPACES FOR `` THE-POWER-PLANT OF THE-SUB WAS-BUILT BY WES'I'INGHOUSE '' At the rtrrt of prot~ssing~ oprcr K8 contains knowledga about Powst=PlantSt cHAVE , PART &gt; rlrlationships~ SUbmarlne~~ &lt; BUILD &gt; eventst mb Westinghousa , On rpottlng the noun phraae athe-powrr-plantc , an 8CR ir called to set up a rpaee , NPI , below KS tn the partial dtderlng , Withln thfr rpace , a structure is crested reprerenting the meaning of Hthe~pawer-~lant~ , 8lmilarlY~ new space8 are bet UP to encad @ the 0thN Sentence cbnrtitucntr that correspond to cxpllcit lexLcrl antrlas , A8 the ~hrrar gtbu~s rubphrase8 into lakper units , SCRr arc ~~llcd to aid in the praters , Usinq rule R4 , PREPPl ( MbyR ) and NP3 ( @ WestingMu~c~l are combined to form PREPPl C ''by Wcstinuhousew ) .</sentence>
				<definiendum id="0">PLANTS</definiendum>
				<definiens id="0">the $ @ subpart in a &lt; H-AVE , PART , relrtionahlp in which SI the PartlCular mqmber of SUBS currantiy In context , is the # @ su~p.art ( Wtrp8rt ) a Discourse analY8Ls mrchani # mS dlrcusred Ln Deutrch [ 1'975f and , rare fully , in Walker rt al , ( 1975 ) will br used ta rrraclate W with the unique Wertlnphb~rr Cerporatlon known to the semantle net in space KS</definiens>
				<definiens id="1">ToesUpp~ $ s 8sCOndary details whtle considering the building of this structuret rrrum~ the highly airn~llfiad language deflaitiont Crammrr Irsrricon</definiens>
			</definition>
			<definition id="2">
				<sentence>SPS is a rule-based system with a rule-ordering scheme that can produce deep case structures from phrase-structure trees .</sentence>
				<definiendum id="0">SPS</definiendum>
			</definition>
			<definition id="3">
				<sentence>SPS a1 so a1 lows these tests to be made against features associated with registers by other rules .</sentence>
				<definiendum id="0">SPS</definiendum>
				<definiens id="0">a1 so a1 lows these tests to be made against features associated with registers by other rules</definiens>
			</definition>
			<definition id="4">
				<sentence>To see how SPS works in detail , and , , '' explain how it allows for locative prepositions we look at a typical rule : Rul e 2-STAT-LO : ( ( *I-S5 ( 1 2.3 4 ) 1 ( 4 ) *1-S7 ( ( EQ # 2STAT 1-1 ) ( COMPATIBLE 1-1 2-1 ) ( COMPATIBLE 1-2 OBJ ( I-i 1 ) ( COMPATIBLE R ( SS ) SUBJ ( I-1 ) ) ) I ======+ ( ( ( : PLACE R ( CAUSED ) !</sentence>
				<definiendum id="0">SPS</definiendum>
				<definiens id="0">works in detail</definiens>
			</definition>
			<definition id="5">
				<sentence>The wble notion of a case derives frcm the syntactic and sa~ntic similarities bebeen the role played by the argurrrents of many predicates .</sentence>
				<definiendum id="0">wble notion of a case derives frcm</definiendum>
				<definiens id="0">the syntactic and sa~ntic similarities bebeen the role played by the argurrrents of many predicates</definiens>
			</definition>
			<definition id="6">
				<sentence>`` John gives the book tc Mary .</sentence>
				<definiendum id="0">John</definiendum>
			</definition>
</paper>

		<paper id="1038">
			<definition id="0">
				<sentence>Not all sentenpes will have a causal actant , Where present , the locuC4 is the object or being that the '~herne is a syntactically and semantically defined fuactioflal reldtion introduced by Gruber ( 1965 ) .</sentence>
				<definiendum id="0">present</definiendum>
				<definiendum id="1">locuC4</definiendum>
			</definition>
			<definition id="1">
				<sentence>Paiadigms and Trangforma t ions The paradQms discussed above interact with a nusber of movement and deJetion transformations that should also be diecussed , Firstly , a number of English verbs permit a transformational deletion in the surface structure of e lexically unspecified yet semantically delimited surface object theme .</sentence>
				<definiendum id="0">paradQms</definiendum>
				<definiens id="0">a number of English verbs permit a transformational deletion in the surface structure of e lexically unspecified yet semantically delimited surface object theme</definiens>
			</definition>
			<definition id="2">
				<sentence>A well-known movement transformatibn is the passive transformagion which operates on a sentence such as ( 53 ) and produces ( 54 ) : ( 53 ) Dick purchased the car yesterday .</sentence>
				<definiendum id="0">well-known movement transformatibn</definiendum>
				<definiens id="0">the passive transformagion which operates on a sentence such as ( 53 ) and produces ( 54 ) : ( 53 ) Dick purchased the car yesterday</definiens>
			</definition>
</paper>

		<paper id="1067">
			<definition id="0">
				<sentence>The assimilation of an uttcranco in the dialogue is rcprcscntcd in this model by a sequence of modifica\ions of a `` Work~pacc '' [ 2 ] which rcprcscnfs the attention or awareness af the listening party .</sentence>
				<definiendum id="0">assimilation of an uttcranco</definiendum>
				<definiens id="0">rcprcscnfs the attention or awareness af the listening party</definiens>
			</definition>
			<definition id="1">
				<sentence>Thc dialogue types wc have represented so far as Dialogue-games have each required only thrcc Parameters : the two participants involved ( called `` Roles '' ) , and the subjcct of the dialogue ( called `` Topic '' ) .</sentence>
				<definiendum id="0">Thc dialogue types</definiendum>
				<definiens id="0">the two participants involved ( called `` Roles '' ) , and the subjcct of the dialogue ( called `` Topic '' )</definiens>
			</definition>
			<definition id="2">
				<sentence>Acceptance is one of tho typical responses to a Bid , and leads to purwit of thc game .</sentence>
				<definiendum id="0">Acceptance</definiendum>
				<definiens id="0">one of tho typical responses to a Bid , and leads to purwit of thc game</definiens>
			</definition>
			<definition id="3">
				<sentence>In thc ca : r of t~rmindion , thrce altcrnat~vc. : ; rrfa po : &lt; iblc : ~rllrlrruptiun : ~nd 5pont : lncous torminotian by ei thcr 1 ; oal x~lisfclcIior\ or uncotl ( llI~on : ~I i ; o : ~l f : ~iI~~rcr. A Model of Dialogue Once a eamc has bccn bid and acccptcd , the two participants each pursue the subgoals spccificd for their role by the Components of this game. Thcse subgoals are mutually complcn~cntary , each set facilitating the other. Furthermore , by the time the tcrrninati on stage has been rcachcd , pursuit of the Component-specified subgoals will have assurcd satisfaction of the higher , initial goals of the participants , for which the Came was initiated in thc first place. In this scction , wc c.xhibit a specific Diolocuc-game : the Helping gn/ne. This game is prcscntcd in an informal rcprcsentation , in order to emphasize the informational content , rather than the representational power of our formalism. Later in this report we will prcscnt thc formal analocue of this same game. In what follows , the bold face indicates the information contained in tho representation of this particular Dialogue-game : the tcxt in regular type is explanatory commentary. The ( annotated ) Helping-game. -- -- -- -- 1 -- -11 -- -- -- -- -- -- -- -Pnmn~clcrs : HELPEE , HELPER , and TASK. The HELPEE wants help from the HELPEE. The TASK is some sort of a problem , otherwise unspecified. Paran~eler Specificat ions : HELPEE : wants to perform TASK. HELPFE : wants lo be able lo perform TASK. HELPEE : not ab/e lo perform TASK. HELPEE : permitted tii perfirm TASK. MELPFF : a person. A Modcl of Dialogue Thcse Spccifications not only constrain who would qualify as filling the rolc of HELPEE , but also provide reliable information about the HELPEE , given that this individual is believed to be engaged in the Helping-game. This prohibits someone from asking for help on a problem he did not want solved. Similarly , if one rcc~ivcs what he judges to be a sincere request for help to do some task , the helper normally as : umes that the requester has the necessary authority to do the task , if only he knew how. HELPER : wants to help HELPEE perform TASK. HELPER : able to provide help. HELPER : a person. So , in ordcr to be a HELPER , an individual must be willing and able to provide the needed assistance. Since this Dialogue-game rcprcscnts shared knowledge , the HELPER knows these Spccifications , and therefore will not bid the Helping-game to someone who is not likely to meet them. And similarly , no one who fails to meet these Specifications ( and knows he fails ) will accept a bid for the Helping-game with himself as HELPER. Components of the Helping game : Thcre are three components : the first two constitute the `` Diagnosis '' phase to communicate what the problem is. . HELPEE wants HEfPFR to know about a sef of unexcepfiona/ , acfuuii/ events. 'The HELPEE sets up a context by describing a situation where everything , so far , is going well. Since the HELPEE assumes that the TASK is understood by the HELPER , he also assumes that the HELPER shares his expectations for r~bsequent activity. A Modcl of Dialogue // a set of exceptional events whkh occurred or 2 ) a set of expected , unexcepflbnal events which did not occur. This pattern of a Helping-game is sufficiently well known to the participants , that the HELPEE almost never needs to actually ask a question at this point. By simply exhibiting a failure of expectation , the HELPEE has communicated that this acts as a block to his successfully pursuing the TASK. The HELPER is expected to explain why the failure occurred and how HELPEE canavoid it or otherwise continue in the TASK. The third componcnt specifies the 'Treatment '' phase where the HELPER communicates an explanation for the perceived failure. undesired event or cause the desired one. The context description enables the HELPEE to identify a collection of activities which he understands , and in which the HELPEE is attempting to participate. The violation-of-expectation description points out just where the HELPEE 's image of the activities differs from the correct image. It is from this area of difference that the HELPER selects an action for the HELPEE. A Model of Dialogue # ia/o , mue games in the Con ? pre/rension of Dialogue In this section we describe the five stages of dialogue assimilation and detail the involvement of Dialogue-games with ~ach stage : 1 ) nomination , 2 ) recognition , 3 ) instantiation , 4 ) conduct , 5 ) termination. Proccssi ng Environment Our description of the model should be viewed as representing the changing coy , nitive state of one of the participants , throunhout the course of the dialogue. That is , two models are involved , one for each participant. Since the same processing occurs for both , we will describe only one. Thc Dialogue-Game Modcl consists of a Long-Term Memory ( LTM ) , a Workspacc ( WS ) , and a set of proccsscs that modify the contents of WS , contingent upon the contents of LTM and WS. LTM conbins a rcprescntation of the knowledge that the partigular di ologuc participant bl ines to the dialogue bcfo~e it starts. This includcs knowlcdgc about the world , relevant objects , processes , concepts , the cognitive statc of his partner in dialogue , rules of inference and evidence , as well as linguistic knowlcdp ; e ( words and thcir semantic rcprcscntation , case frames for verbs and predicates and the multi-turn language s'trbctures , the Dialogue-games ) . WS is the volatile short-term rncmory of thc modcl , containing all the partial and temporary rcsults of processing. The contcnte of WS at any momcnt rcprc. ; cnt thc madel 's state of comprchcnsion and focus at that point. Tho processes arc autonomous specialists , opcrl~tiny : indcpcndcntly and in parallel , to modify thqentitics in WS ( callcd `` activations '' ) . Thcsc proccsscs arc also influcnccd by the contents of WS , as well a. ; by thc knowlcdgc in LTM. Thus , WS is the place in which thcso concurrcnt~ly operating proccsscs interact with each othcr. This anarchistic control structure rcscrnblcs that the HEARSAY system ( Erman , Fennel , Lesser &amp; Rcddy , 1973 ) A Modcl of Dialogue Nomination When dialo~uc participants propose a new type of interaction , they do not consistently use any single word or phrase to introducc the interaction. Thus we can not dcterminc which Dialogue-games represent the dialoguc type through a simple invocation by namc or any othcr pre-known collection of words or phrases. Instcad the diolo~uc type is cornmunicatcd by attempts to establish various entities as the values of the Psi actcrs of ihe dcsircd Dialogue-game. Thus , an utterance which is cornprchcndcd as associating an entity ( a-person or a concept ) with a Parameter of a Di aloguc-game suggests that Dialogue-game as a possi bilily for initiation. The Dialogue-Game Modcl has two ways in which these nominations of ncw Dialo~uc-games occur. One of the processes of the modcl is a `` spreading activation '' proccss call &amp; Protcus ( Lcvin , 1976 ) . Protcus gcncratcs new activations in WS on thc basic of cclations in LTM , from concepts ( nodes in the semantic network ) that are already in WS. Protcus brings into focus concepts somehow related to those already thcrc. A collection of concepts in WS leads to focusing on some aspect of a particular Dialocuc-game , in this sense `` nominating '' it as a possible new Dialoeue-game. MATCH and DEDUCE are two of thc modcl s processes which operatc in .conjunction to ccncratc ncw activations from existing ones , means of finding and ap , prp @ rulc-like transformations , Thcy operate through partial match and plausible i nfcrencetcchniques , and if thcy activate Pardrnetcrs , thcn the Dialogue-gsrnc that contains those ~ararndtcrs bccomcs nomina , tcd as.a candidate Dialogue-game. Match and Deduce operate to , gether as a kind of production system ( Newell , 1973 ) . For cx ; lmplc , from the input utterance : `` I tried to send a message to &lt; person &gt; at &lt; computer-site3 and it~did n't go. '' the following two scqucnccs of associations and inferences result : ( la ) I trjcd toX. ( 25 ) 1 wpntcd to X. ( 3a ) 1'want to X. ( 4a ) HELPEE wants to do TASK. ( I b ) It did n't go. ( 2b ) What I tried to do did n't work. ( 3b ) X did n't work. ( 4b ) I ca n't X. ( 58 ) 1 do n't know ha to X. ( 6b ) HEL.PEE\doc $ n7t know how to do TASK. A Model of Dialogue ( Where : I = HELPEE and X = do TASK = send a message to &lt; person &gt; at &lt; computer-site &gt; . )</sentence>
				<definiendum id="0">Thc Dialogue-Game Modcl</definiendum>
				<definiendum id="1">WS</definiendum>
				<definiens id="0">r of t~rmindion , thrce altcrnat~vc. : ; rrfa po : &lt; iblc : ~rllrlrruptiun : ~nd 5pont : lncous torminotian by ei thcr 1 ; oal x~lisfclcIior\ or uncotl ( llI~on : ~I i ; o : ~l f : ~iI~~rcr. A Model of Dialogue Once a eamc has bccn bid and acccptcd , the two participants each pursue the subgoals spccificd for their role by the Components of this game. Thcse subgoals are mutually complcn~cntary , each set facilitating the other. Furthermore , by the time the tcrrninati on stage has been rcachcd , pursuit of the Component-specified subgoals will have assurcd satisfaction of the higher , initial goals of the participants , for which the Came was initiated in thc first place. In this scction , wc c.xhibit a specific Diolocuc-game : the Helping gn/ne. This game is prcscntcd in an informal rcprcsentation , in order to emphasize the informational content , rather than the representational power of our formalism. Later in this report we will prcscnt thc formal analocue of this same game. In what follows , the bold face indicates the information contained in tho representation of this particular Dialogue-game : the tcxt in regular type is explanatory commentary. The ( annotated ) Helping-game. -- -- -- -- 1 -- -11 -- -- -- -- -- -- -- -Pnmn~clcrs : HELPEE , HELPER , and TASK. The HELPEE wants help from the HELPEE. The TASK is some sort of a problem , otherwise unspecified. Paran~eler Specificat ions : HELPEE : wants to perform TASK. HELPFE : wants lo be able lo perform TASK. HELPEE : not ab/e lo perform TASK. HELPEE : permitted tii perfirm TASK. MELPFF : a person. A Modcl of Dialogue Thcse Spccifications not only constrain who would qualify as filling the rolc of HELPEE , but also provide reliable information about the HELPEE , given that this individual is believed to be engaged in the Helping-game. This prohibits someone from asking for help on a problem he did not want solved. Similarly , if one rcc~ivcs what he judges to be a sincere request for help to do some task , the helper normally as : umes that the requester has the necessary authority to do the task , if only he knew how. HELPER : wants to help HELPEE perform TASK. HELPER : able to provide help. HELPER : a person. So , in ordcr to be a HELPER , an individual must be willing and able to provide the needed assistance. Since this Dialogue-game rcprcscnts shared knowledge , the HELPER knows these Spccifications , and therefore will not bid the Helping-game to someone who is not likely to meet them. And similarly , no one who fails to meet these Specifications ( and knows he fails ) will accept a bid for the Helping-game with himself as HELPER. Components of the Helping game : Thcre are three components : the first two constitute the `` Diagnosis '' phase to communicate what the problem is. . HELPEE wants HEfPFR to know about a sef of unexcepfiona/ , acfuuii/ events. 'The HELPEE sets up a context by describing a situation where everything , so far , is going well. Since the HELPEE assumes that the TASK is understood by the HELPER , he also assumes that the HELPER shares his expectations for r~bsequent activity. A Modcl of Dialogue // a set of exceptional events whkh occurred or 2 ) a set of expected , unexcepflbnal events which did not occur. This pattern of a Helping-game is sufficiently well known to the participants , that the HELPEE almost never needs to actually ask a question at this point. By simply exhibiting a failure of expectation , the HELPEE has communicated that this acts as a block to his successfully pursuing the TASK. The HELPER is expected to explain why the failure occurred and how HELPEE canavoid it or otherwise continue in the TASK. The third componcnt specifies the 'Treatment '' phase where the HELPER communicates an explanation for the perceived failure. undesired event or cause the desired one. The context description enables the HELPEE to identify a collection of activities which he understands , and in which the HELPEE is attempting to participate. The violation-of-expectation description points out just where the HELPEE 's image of the activities differs from the correct image. It is from this area of difference that the HELPER selects an action for the HELPEE. A Model of Dialogue # ia/o , mue games in the Con ? pre/rension of Dialogue In this section we describe the five stages of dialogue assimilation and detail the involvement of Dialogue-games with ~ach stage : 1 ) nomination , 2 ) recognition , 3 ) instantiation , 4 ) conduct , 5 ) termination. Proccssi ng Environment Our description of the model should be viewed as representing the changing coy , nitive state of one of the participants , throunhout the course of the dialogue. That is , two models are involved , one for each participant. Since the same processing occurs for both</definiens>
				<definiens id="1">consists of a Long-Term Memory ( LTM ) , a Workspacc ( WS ) , and a set of proccsscs that modify the contents of WS , contingent upon the contents of LTM and WS. LTM conbins a rcprescntation of the knowledge that the partigular di ologuc participant bl ines to the dialogue bcfo~e it starts. This includcs knowlcdgc about the world , relevant objects , processes , concepts , the cognitive statc of his partner in dialogue , rules of inference and evidence , as well as linguistic knowlcdp ; e ( words and thcir semantic rcprcscntation , case frames for verbs and predicates and the multi-turn language s'trbctures , the Dialogue-games ) . WS is the volatile short-term rncmory of thc modcl , containing all the partial and temporary rcsults of processing. The contcnte of WS at any momcnt rcprc. ; cnt thc madel 's state of comprchcnsion and focus at that point. Tho processes arc autonomous specialists , opcrl~tiny : indcpcndcntly and in parallel , to modify thqentitics in WS ( callcd `` activations '' ) . Thcsc proccsscs arc also influcnccd by the contents of WS , as well a. ; by thc knowlcdgc in LTM. Thus ,</definiens>
				<definiens id="2">the place in which thcso concurrcnt~ly operating proccsscs interact with each othcr. This anarchistic control structure rcscrnblcs that the HEARSAY system ( Erman , Fennel , Lesser &amp; Rcddy , 1973 ) A Modcl of Dialogue Nomination When dialo~uc participants propose a new type of interaction , they do not consistently use any single word or phrase to introducc the interaction. Thus we can not dcterminc which Dialogue-games represent the dialoguc type through a simple invocation by namc or any othcr pre-known collection of words or phrases. Instcad the diolo~uc type is cornmunicatcd by attempts to establish various entities as the values of the Psi actcrs of ihe dcsircd Dialogue-game. Thus , an utterance which is cornprchcndcd as associating an entity ( a-person or a concept ) with a Parameter of a Di aloguc-game suggests that Dialogue-game as a possi bilily for initiation. The Dialogue-Game Modcl has two ways in which these nominations of ncw Dialo~uc-games occur. One of the processes of the modcl is a `` spreading activation '' proccss call &amp; Protcus ( Lcvin , 1976 ) . Protcus gcncratcs new activations in WS on thc basic of cclations in LTM , from concepts ( nodes in the semantic network ) that are already in WS. Protcus brings into focus concepts somehow related to those already thcrc. A collection of concepts in WS leads to focusing on some aspect of a particular Dialocuc-game , in this sense `` nominating '' it as a possible new Dialoeue-game. MATCH and DEDUCE are two of thc modcl s processes which operatc in .conjunction to ccncratc ncw activations from existing ones , means of finding and ap , prp @ rulc-like transformations , Thcy operate through partial match and plausible i nfcrencetcchniques , and if thcy activate Pardrnetcrs , thcn the Dialogue-gsrnc that contains those ~ararndtcrs bccomcs nomina , tcd as.a candidate Dialogue-game. Match and Deduce operate to , gether as a kind of production system ( Newell , 1973 ) . For cx ; lmplc , from the input utterance : `` I tried to send a message to &lt; person &gt; at &lt; computer-site3 and it~did n't go. '' the following two scqucnccs of associations and inferences result : ( la ) I trjcd toX. ( 25 ) 1 wpntcd to X. ( 3a ) 1'want to X. ( 4a ) HELPEE wants to do TASK. ( I b ) It did n't go. ( 2b ) What I tried to do did n't work. ( 3b ) X did n't work. ( 4b ) I ca n't X. ( 58 ) 1 do n't know ha to X. ( 6b ) HEL.PEE\doc $ n7t know how to do TASK. A Model of Dialogue ( Where : I = HELPEE and X = do TASK = send a message to &lt; person &gt; at &lt; computer-site &gt;</definiens>
			</definition>
			<definition id="4">
				<sentence>The Dialogue-garnc Manager investigates each of the nomi natcd Dial.oguc-games , verifying infcrcnccs based on the Parameter Specifications , and eliminating &lt; those Dialogue-gamcs for which one or more Specifications are contraclictcd .</sentence>
				<definiendum id="0">Dialogue-garnc Manager</definiendum>
				<definiens id="0">investigates each of the nomi natcd Dial.oguc-games , verifying infcrcnccs based on the Parameter Specifications , and eliminating &lt; those Dialogue-gamcs for which one or more Specifications are contraclictcd</definiens>
			</definition>
			<definition id="5">
				<sentence>SPEA~ER wants to know how to do that TASK .</sentence>
				<definiendum id="0">SPEA~ER</definiendum>
				<definiens id="0">wants to know how to do that TASK</definiens>
			</definition>
			<definition id="6">
				<sentence>SPEAKER expects HEARER to t'cll'him how to do TASK .</sentence>
				<definiendum id="0">SPEAKER</definiendum>
				<definiens id="0">expects HEARER to t'cll'him how to do TASK</definiens>
			</definition>
			<definition id="7">
				<sentence>Long-term Mcrnory ( LTM ) The Long-Term Memory is the rnodcl 's representation of a participant 's knowledge of the external world .</sentence>
				<definiendum id="0">Long-term Mcrnory</definiendum>
				<definiendum id="1">Long-Term Memory</definiendum>
				<definiens id="0">the rnodcl 's representation of a participant 's knowledge of the external world</definiens>
			</definition>
			<definition id="8">
				<sentence>LTMis a semantic network , containing a set of nodes ( also called concepts ) and the relations that hold between them at the Iowost ievel .</sentence>
				<definiendum id="0">LTMis</definiendum>
				<definiens id="0">a semantic network , containing a set of nodes ( also called concepts ) and the relations that hold between them at the Iowost ievel</definiens>
			</definition>
			<definition id="9">
				<sentence>he SIM representation of thi~~assertion ( which we shall name Ql ) is Ql : ( MARY HIT JOHN ROCK ) which translates into the foll~ing triples : &lt; Q1 PRED HIT &gt; ( 01 SUBJ MARY &gt; 41 OBJ JOHN &gt; &lt; Q1 INST ROCK , Workspace ( WS ) The Workspace is the model 's representation for that information which the participant is activcly using , This memory corresponds roughly ta a model of the participant 's focus of attention. While the L'TM is static during the operation of the model ( we are not attempting to simulate learning ) , the WS is extremely volatile , with elements ( activations ) coming into and out of focus c~tinuously. All incoming sensations ( i.e. , utterances ) appear in the WS , as do all augmentations of the participant 's knowledge and goal statc. The representational format of the WS is the same as in LTM. Each node in the WS isa token ( copy ) of some node in LTM. Whenever some process determines that the model 's attention ( WS ) should include a token of a specific node ( C ) from LTM , a new node ( A ) is created by copying C and this new node is added to the WS. A is referred to as an artlr , ntlnnn ( ranrlihr , aiw &lt; A IAQ C &gt; This rcprescntatim providcs the associative links between an object in attention , and the body of knowledge assbciated with it , but not yet broucH into attention .</sentence>
				<definiendum id="0">SIM representation of thi~~assertion</definiendum>
				<definiendum id="1">IAQ</definiendum>
				<definiens id="0">Ql : ( MARY HIT JOHN ROCK ) which translates into the foll~ing triples : &lt; Q1 PRED HIT &gt;</definiens>
				<definiens id="1">the model 's representation for that information which the participant</definiens>
				<definiens id="2">static during the operation of the model ( we are not attempting to simulate learning ) , the WS is extremely volatile , with elements ( activations ) coming into and out of focus c~tinuously. All incoming sensations ( i.e. , utterances ) appear in the WS , as do all augmentations of the participant 's knowledge and goal statc. The representational format of the WS is the same as in LTM. Each node in the WS isa token ( copy ) of some node in LTM. Whenever some process determines that the model 's attention ( WS ) should include a token of a specific node</definiens>
				<definiens id="3">the associative links between an object in attention , and the body of knowledge assbciated with it , but not yet broucH into attention</definiens>
			</definition>
			<definition id="10">
				<sentence>then Process decreases the salience of the activation of the neighboring conccpt .</sentence>
				<definiendum id="0">Process</definiendum>
				<definiens id="0">decreases the salience of the activation of the neighboring conccpt</definiens>
			</definition>
			<definition id="11">
				<sentence>The Diatogua-game Model is a collection of cooperative processes which continuausly updated a representation of each participant 's attention state in a Workspaco .</sentence>
				<definiendum id="0">Diatogua-game Model</definiendum>
				<definiens id="0">a collection of cooperative processes which continuausly updated a representation of each participant 's attention state in a Workspaco</definiens>
			</definition>
			<definition id="12">
				<sentence>We make use of a particular version of the Helping-game and alsc explore another structure , an Execution Scene , which describes the customary events surrounding the successful execution of a particular program ( Runoff ) .</sentence>
				<definiendum id="0">Execution Scene</definiendum>
				<definiens id="0">describes the customary events surrounding the successful execution of a particular program ( Runoff )</definiens>
			</definition>
			<definition id="13">
				<sentence>HGXlQ= Thc HELPEE wants to dcscribo what dtd not hsppcn that he A Model of Dialogue expected , and wanted , the ACTION [ s ] /BAD .</sentence>
				<definiendum id="0">HGXlQ= Thc HELPEE</definiendum>
				<definiens id="0">wants to dcscribo what dtd not hsppcn that he A Model of Dialogue expected , and wanted , the ACTION [ s ] /BAD</definiens>
			</definition>
			<definition id="14">
				<sentence>( describing these ACTION [ s ] /BAD is a subgoal of having the HELPER enable the HELPEE to perform the TASK/HG . )</sentence>
				<definiendum id="0">/BAD</definiendum>
				<definiens id="0">a subgoal of having the HELPER enable the HELPEE to perform the TASK/HG</definiens>
			</definition>
			<definition id="15">
				<sentence>Results : R311 is an activation of H2 , ( ~ctting Runoff working ) corrcsponds to the task .</sentence>
				<definiendum id="0">R311</definiendum>
				<definiens id="0">an activation of H2 , ( ~ctting Runoff working</definiens>
			</definition>
			<definition id="16">
				<sentence>Results : R21 is an activation if the lcft half of Rule4 .</sentence>
				<definiendum id="0">R21</definiendum>
				<definiens id="0">an activation if the lcft half of Rule4</definiens>
			</definition>
			<definition id="17">
				<sentence>Cycle 117 -Match A Model of Dtalogua Match RVe3 with Left , hatf of RutaZa = If 0 knows ( apcrson asks how to perform a ta $ k ) , then 0 knows ( that porson wants O to onable him to perform that task ) .</sentence>
				<definiendum id="0">apcrson</definiendum>
				<definiens id="0">asks how to perform a ta $ k )</definiens>
			</definition>
			<definition id="18">
				<sentence>RosuIf S : RVa1 is an activation of tho left half of Ru~B~B , L corrcsponds to that person .</sentence>
				<definiendum id="0">RVa1</definiendum>
				<definiens id="0">an activation of tho left half of Ru~B~B</definiens>
			</definition>
			<definition id="19">
				<sentence>Rcsul ts : An activation of the Helping-game is created in the WS .</sentence>
				<definiendum id="0">Rcsul ts</definiendum>
				<definiens id="0">An activation of the Helping-game is created in the WS</definiens>
			</definition>
			<definition id="20">
				<sentence>The Dialogue-game Manager ( OGM ) makes use of a set of correspondences that have already been established by the matches which led to the activations of HI , H2 , and H11 : A Modol of Dialogue Previous Rosults : L corresponds to Hclpee 0 corresponds to Helper Case13 ( = ( Runoff working ) ) corresponds to the task .</sentence>
				<definiendum id="0">Dialogue-game Manager</definiendum>
				<definiendum id="1">H11</definiendum>
				<definiens id="0">makes use of a set of correspondences that have already been established by the matches which led to the activations of HI , H2 , and</definiens>
				<definiens id="1">A Modol of Dialogue Previous Rosults</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>An obj~ct is defined as a LOGO graphzcs program that draws it ( see Section VI ) A scene is a set of ob~ects related in terms of contact points , A scene can be described by a set of pradicstes ( BOAT ABOVE WATER ) ( ATTACH BOAT* WATEqpl ) ( ~CK ABOVE WATER ) ( DOCK LEFTOF WATER ) ( BOAT RIGHTOF WK ) ( ATTACH DOCYky WATE % ) ( ATTACH BOATXl+kY DOCSy Orientation functions for adjusting starting points and headings of the programs that draw the ob~ects are requlred and these imply some trigonornetrlc functians A LISP package of about 650 llnes has been developed by Gordon Bennett m p~ovide the plcture making capablllty What 1s rnalnly relevant , to the computation of language meanings 1s that a semantlc structure sufficient to transmlt data to the drawing package is easlly represented as a property list associated ulth an artlficlal pme for the scene For example , A CLOWN ON A-PEDESTAL '' results in the following stbqture ( Cl , TOK CLOWN , SUPPORTBY C2 , ATTACH ( C1 FEET= C2 TOPXY ) ) ( €2 , TOK PEDESTAL , SUPPORT C1 , ATTACH ( C2 TOPXY Cl FEETXI ) ) ( CLOUN , EXPRCWDAO , ) FEET XI , SIZE 3 , STARTPT XY , HEADING A ) ( PEDES~AL .</sentence>
				<definiendum id="0">WATER ) ( DOCK LEFTOF WATER ) ( BOAT RIGHTOF WK ) ( ATTACH DOCYky WATE % )</definiendum>
				<definiendum id="1">STARTPT XY , HEADING A )</definiendum>
				<definiens id="0">a LOGO graphzcs program that draws it ( see Section VI ) A scene is a set of ob~ects related in terms of contact points , A scene can be described by a set of pradicstes ( BOAT ABOVE WATER ) ( ATTACH BOAT* WATEqpl ) ( ~CK ABOVE</definiens>
				<definiens id="1">ATTACH BOATXl+kY DOCSy Orientation functions for adjusting starting points and headings of the programs that draw the ob~ects are requlred and these imply some trigonornetrlc functians A LISP package of about 650 llnes has been developed by Gordon Bennett m p~ovide the plcture making capablllty What 1s rnalnly relevant , to the computation of language meanings 1s that a semantlc structure sufficient to transmlt data to the drawing package is easlly represented as a property list associated ulth an artlficlal pme for the scene For example , A CLOWN ON A-PEDESTAL '' results in the following stbqture</definiens>
			</definition>
			<definition id="1">
				<sentence>€ollowinp grammar and semantlc system our emphasis ~s on dealing with the highly dariable nature of Fnglish embeddings This means that we have bean more interested in the many forms of dependent 14 clau~e -- ~re~ositiondl phrase , relative clause , inf lnitive , participial phrase , relative cpnjuetive clause , etc , -- than in the ffne detail on noun phrase , noun-noun combinations ; and the fine grain of verb sttings We have also for the moment ignored ordinary conjunctions in view of the clear treatment offered by Woods , Wipograd and Grishman ; each of whom points out that an and or an `` ~r '' triggers a special subgrammar that attempts to find a structural repetition of a constituent that was just cbmpleted .</sentence>
				<definiendum id="0">noun-noun</definiendum>
			</definition>
			<definition id="2">
				<sentence>ID is the name of a register that generally contains the last constituent found .</sentence>
				<definiendum id="0">ID</definiendum>
				<definiens id="0">the name of a register that generally contains the last constituent found</definiens>
			</definition>
			<definition id="3">
				<sentence>HOLD contains Dependent Clauses that are missing soare element that delays their semantic processing .</sentence>
				<definiendum id="0">HOLD</definiendum>
				<definiens id="0">contains Dependent Clauses that are missing soare element that delays their semantic processing</definiens>
			</definition>
			<definition id="4">
				<sentence>The verbs SUPPORT , SAIL , and MOVE are defined as semantic functions in seetion V. PreA positions are also defined as semantic functions in that section .</sentence>
				<definiendum id="0">MOVE</definiendum>
				<definiens id="0">semantic functions in seetion V. PreA positions</definiens>
			</definition>
			<definition id="5">
				<sentence>PUTMODS is a semantic function that works with adjectives and adverbs iri the following fashioe : An adjective , e.g. big , has the following lexical structure : ( BIG ADJ T , POS T , TYPE SIZE , VALUE 7 ) PUTMODS will for each adjective obtain the TYPE and VALUE and put them on the noun 's property list .</sentence>
				<definiendum id="0">PUTMODS</definiendum>
				<definiens id="0">a semantic function that works with adjectives</definiens>
			</definition>
			<definition id="6">
				<sentence>GLST is the name of a list of candidates .</sentence>
				<definiendum id="0">GLST</definiendum>
				<definiens id="0">the name of a list of candidates</definiens>
			</definition>
			<definition id="7">
				<sentence>( BESIDE ( LAMBDA ( N $ N2 ) ( RIGHTOF N1 N2 ) ) ) ( RIGHTOF ( LAMBDA ( N1 N2 ) ( CO'ND ( ( AND ( GET N1 `` PICT ) ( GET N2 `` PIcT ) ) ( PUT N2 `` RIGHTOF Nl ) ( PUT N1 `` LEFTOF N2 ) ) ( T NIL ) 1 1 ) Thue .</sentence>
				<definiendum id="0">BESIDE</definiendum>
				<definiendum id="1">LAMBDA</definiendum>
				<definiendum id="2">RIGHTOF N1 N2 ) ) ) ( RIGHTOF ( LAMBDA ( N1 N2 ) ( CO'ND ( ( AND</definiendum>
			</definition>
			<definition id="8">
				<sentence>SUPPORT1 takes as arguments , SL5J , OBJ , and CflMPS where COWS is a list of complements .</sentence>
				<definiendum id="0">SUPPORT1</definiendum>
				<definiens id="0">takes as arguments , SL5J , OBJ , and CflMPS where COWS is a list of complements</definiens>
			</definition>
			<definition id="9">
				<sentence>The result of SUPPORT1 is to create a process model of the fbllowing form : ( Ci TOK balance , GLOBAL ( ... ) - , INIT ( ... ) , INTER ( ... ) RESULT ( . . . ) ) The value of the attribute , GLOBAL is a quoted set of ( PUT X Y Z ) whrch Me true at all times in the model .</sentence>
				<definiendum id="0">GLOBAL</definiendum>
				<definiens id="0">to create a process model of the fbllowing form : ( Ci TOK balance</definiens>
				<definiens id="1">a quoted set of ( PUT X Y Z ) whrch Me true at all times in the model</definiens>
			</definition>
			<definition id="10">
				<sentence>is the set of relations true Bt the initial state of time 5n the model , INTER Ts those for the intermadiage states , and R~SULT is the set fbr the final state .</sentence>
				<definiendum id="0">R~SULT</definiendum>
				<definiens id="0">the set fbr the final state</definiens>
			</definition>
			<definition id="11">
				<sentence>SAIL is defined as f~llows : ( SAIL ( LAMBDA ( ST ) ( PROG ( ) ( PUT ST lq~~~~~ `` WATER ) ( PUT ST `` VEHICLE `` BOAT ) ( RETURN ( MOVE* s T ) ) 1 ) ) That is , SAIL implies a movement of*a boat on water and so passes thiS Lnformetion to mVE* which may have to use it to bind lte case roles of 5EDIUM and VEHICLE which in fact at ?</sentence>
				<definiendum id="0">SAIL</definiendum>
			</definition>
			<definition id="12">
				<sentence>s `` LEFTOF ) ( PUT VEHIC `` BETWEEN ( S G ) ) Por RkSULT , ( REMPROP VEHIC `` BETWEEN ) ( PUT VEHIC `` LEFTOF G ) ( PUT G `` ~IGHTOF VEHIC ) Ffg .</sentence>
				<definiendum id="0">PUT VEHIC `` BETWEEN</definiendum>
				<definiendum id="1">REMPROP</definiendum>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>The definition is a model of the notion that it is phrases which have meaning and that the meaning of a phrase is a function of its syntactic structure and of the meanings of its constituents .</sentence>
				<definiendum id="0">definition</definiendum>
				<definiens id="0">a model of the notion that it is phrases which have meaning and that the meaning of a phrase is a function of its syntactic structure and of the meanings of its constituents</definiens>
			</definition>
			<definition id="1">
				<sentence>G = ( V , z , P , S ) be a context free grammar where : V is the finite nonempty vocabulary , C c V is the terminal alphabet , S € ( V C ) is the axiom , and P is the finite nonempty set of grammar rules , having the form + A -t B , for A € ( V C ) and B 6 V .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">C c V</definiendum>
				<definiendum id="2">P</definiendum>
				<definiens id="0">the finite nonempty vocabulary</definiens>
				<definiens id="1">the terminal alphabet</definiens>
			</definition>
			<definition id="2">
				<sentence>A phrase-structure semantics for G is a 7btuple d = ( u , M , u , X , A , F , R ) , where : U is a set , the universe of discourse , TT M c 2 '' is a finite set of atomic morphemes , M p : V + 2 is the vocabulary meaning function , X = , 1 , , , xl , X29 .</sentence>
				<definiendum id="0">phrase-structure semantics for G</definiendum>
				<definiendum id="1">U</definiendum>
				<definiendum id="2">M p</definiendum>
				<definiens id="0">a 7btuple d = ( u , M , u</definiens>
				<definiens id="1">the vocabulary meaning function</definiens>
			</definition>
			<definition id="3">
				<sentence>, XI ) for some integer n , R A is a finite set of nbes of partial recursive functions , F is a finite set of definitions for the partial recursive functions named in A , R is a finite set of semantic rules , with the property that to each grammar rule A -t B . . .B there is assigned one 1 n semantic rule , having the form r A + B1. . .B ( xl , * .</sentence>
				<definiendum id="0">XI ) for</definiendum>
				<definiendum id="1">F</definiendum>
				<definiens id="0">some integer n</definiens>
				<definiens id="1">a finite set of definitions for the partial recursive functions named in A , R is a finite set of semantic rules , with the property that to each grammar rule A -t B</definiens>
			</definition>
			<definition id="4">
				<sentence>L ( G ) = { I , I+I , I+I+I , . . .I. G = ( V , Z , P , S ) , and d = ( U , M , , X , 4 , F , R ) , where : semantics v = { S , I , + ) + U = N U { f } U { I } , where : c = { I , + ) N is the set of non-aegatiue integers , 3and f and I are recursive functions defined in F below , +t M = { N , 1 , f 1 F contains just the following definitions : 1 ( identity function on N + N ) : 1 ( x ) = x + f ( integer addition on N x N + N ) : 1 ) f+ ( x , Y ) = ( f+ ( X , Y ) ) ( ' is the successor fn . )</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">G ) = { I , I+I , I+I+I , . . .I. G = ( V , Z , P , S ) , and d = ( U , M , , X , 4 , F , R ) , where : semantics v = { S , I , + ) + U = N U { f } U { I } , where : c = { I , + )</definiens>
			</definition>
			<definition id="5">
				<sentence>To specify a n n semantic function we will use the notathn f ( x **8 , \ ) : D + C , where f is 1 ' the name of the function , ( xl , . . . , x ) is the vector of arguments , D is the n domain , and C is the codomain .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">D</definiendum>
				<definiendum id="2">C</definiendum>
				<definiens id="0">the n domain , and</definiens>
				<definiens id="1">the codomain</definiens>
			</definition>
			<definition id="6">
				<sentence>~I ( B~ ) x '' *x~ ( B~ ) + v ( rt ( tO ) ) n i n n Intuitiv &amp; ly , the semantic function assigned to each tree t is the composition of the semantic functions assigned to the subtrees of which t is composed .</sentence>
				<definiendum id="0">~I</definiendum>
				<definiens id="0">+ v ( rt ( tO ) ) n i n n Intuitiv &amp; ly , the semantic function assigned to each tree t is the composition of the semantic functions assigned to the subtrees of which t is composed</definiens>
			</definition>
			<definition id="7">
				<sentence>Their meanings , wMch are the arguments of the semantic function , are among the morphemes of the language -those morphemes which can not be furthe-r separated into morphemes ( this is the set of `` atomic morphemes '' , M ) .</sentence>
				<definiendum id="0">wMch</definiendum>
				<definiens id="0">the arguments of the semantic function , are among the morphemes of the language -those morphemes which can not be furthe-r separated into morphemes</definiens>
			</definition>
			<definition id="8">
				<sentence>Thus , the meaning of a sentence is a function of its morphemes .</sentence>
				<definiendum id="0">meaning of a sentence</definiendum>
			</definition>
			<definition id="9">
				<sentence>Informally , T is a generating .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">a generating</definiens>
			</definition>
			<definition id="10">
				<sentence>Formally , let T be a set of trees with labpls from Z. The set gen ( T ) of trees generated by T is defined inductively % as fol'lows : 0 0 ) TI : C gen ( 7 ) and T c gen ( T ) , 1 ) tO [ tl .</sentence>
				<definiendum id="0">T c gen</definiendum>
				<definiens id="0">a set of trees with labpls from Z. The set gen ( T ) of trees generated by T</definiens>
			</definition>
			<definition id="11">
				<sentence>n T is a generating set for gen ( T ) .</sentence>
				<definiendum id="0">n T</definiendum>
				<definiens id="0">a generating set for gen ( T )</definiens>
			</definition>
			<definition id="12">
				<sentence>T , is a finite set ) It .</sentence>
				<definiendum id="0">T</definiendum>
			</definition>
			<definition id="13">
				<sentence>The tr~nslator is L. given a sentence w in7L 1 ' The parser produces a parse tree t &lt; w ) for w. ( If w is syntactically ambiguous , the parser may produce all the parse trees of w. ) If t ( w ) is in the domain of tihe function T defined by the tree mapper , the tree mapper will produce ~ ( t ( w ) ) whose frontier is a sentence u in L 2 ' r -- -1 transformation TRANSLATOR I table ( ; and i ) I I 9I * T &amp; K FRONTIER MPSPER -- -- -- -- -- -- -Figure 1. Translator generator and translator. The importance of the argument that the function defined By the PROCEDURE is a translation , is just that w and u are guaranteed to have the sgne meaning. if they are unambiguous , and if thev are ambiguous , w and u are guaranteed to have meanings in common -i . e . , that u is , a bona f i'de -translation of w , in the ordinary sense of the word The usefulness of such a method of trahslating is that the generator , which has to considet all issues of syntax and semantics , and therefore runs very slowly , need only run once. The translator which it produces should run very fast , since , other than parsing , it bhly has to transform trees according to the finite set of rules in the tree transformation table ( the funct '' ion ; ) . No seman &amp; c computing is required at transloto time. This saction presents some examples of translations on context free languages. The tree search procedure outlined in Section 3 is programmed in CPS and runs on the IBM ~/370/165 at Ohio State. All of these translations were `` found '' by the program. TRANSLATION I ( Postfix to Precedence Infix ) Postfix : Infix : Grammar Rules Semantic Rules Grammar Rules Semantic Rules S - , sso x3 ( *l , x2 ) E + EOT Universe of discourse R = real numbers = IR~ , R2 , Rg , ... 1 F = ~f+~ f- , f* , £'I Meaning function assigning atomic morphemes to lexicaL items and svntactic variables : A1 = A2 = { I } , and F1 = F contains just the definition : I : N + N : ~ ( x ) = x. 2 The reader should be able to figure out , after reading the definition in +*/ Section 1 , that MlaH2= { R , R1 , % I R3 , F , f , f , f , f 1 and A number of finite specifications far translations are possible. One is : A TA sso J= ( EoT A , , 91002 ) ; ( AJ= ( ? ! sso yl~~ ] 9 EOT + F A ( E A E It is interesting to note that the PROCEDURE does not have to know how + * 1 to corppute the functions f , , f , and f in order to discover this translation. All that is needed is to assume that if a symbol appears in both semantics , it represents the same semantic entity in each , whatever that entity is. For example , consider the two trees in the translation involving `` + '' . Let t = S &lt; S % O &lt; + &gt; &gt; , and t ' = E &lt; EO &lt; + &gt; T &lt; F &lt; ( E ) &gt; &gt; &gt; .</sentence>
				<definiendum id="0">tree mapper</definiendum>
				<definiendum id="1">TA sso J=</definiendum>
				<definiens id="0">L. given a sentence w in7L 1 ' The parser produces a parse tree t &lt; w ) for w. ( If w is syntactically ambiguous , the parser may produce all the parse trees of w. ) If t ( w ) is in the domain of tihe function T defined by the tree mapper , the</definiens>
				<definiens id="1">a sentence u in L 2 ' r -- -1 transformation TRANSLATOR I table ( ; and i ) I I 9I * T &amp; K FRONTIER MPSPER -- -- -- -- -- -- -Figure 1. Translator generator and translator. The importance of the argument that the function defined By the PROCEDURE is a translation , is just that w and u are guaranteed to have the sgne meaning. if they are unambiguous , and if thev are ambiguous , w and u are guaranteed to have meanings in common -i . e . , that u is , a bona f i'de -translation of w , in the ordinary sense of the word The usefulness of such a method of trahslating is that the generator , which has to considet all issues of syntax and semantics , and therefore runs very slowly , need only run once. The translator which it produces should run very fast , since , other than parsing , it bhly has to transform trees according to the finite set of rules in the tree transformation table ( the funct '' ion ; ) . No seman &amp; c computing is required at transloto time. This saction presents some examples of translations on context free languages. The tree search procedure outlined in Section 3 is programmed in CPS and runs on the IBM ~/370/165 at Ohio State. All of these translations were `` found '' by the program. TRANSLATION I ( Postfix to Precedence Infix ) Postfix : Infix : Grammar Rules Semantic Rules Grammar Rules Semantic Rules S - , sso x3 ( *l , x2 ) E + EOT Universe of discourse R = real numbers = IR~ , R2 , Rg , ... 1 F = ~f+~ f- , f* , £'I Meaning function assigning atomic morphemes to lexicaL items and svntactic variables : A1 = A2 = { I } , and F1 = F contains just the definition : I : N + N : ~ ( x ) = x. 2 The reader should be able to figure out , after reading the definition in +*/ Section 1 , that MlaH2= { R , R1 , % I R3 , F , f , f , f , f 1 and A number of finite specifications far translations are possible. One is : A</definiens>
				<definiens id="2">EOT + F A ( E A E It is interesting to note that the PROCEDURE does not have to know how + * 1 to corppute the functions f , , f , and f in order to discover this translation. All that is needed is to assume that if a symbol appears in both semantics , it represents the same semantic entity in each , whatever that entity is. For example , consider the two trees in the translation involving `` + '' . Let t = S &lt; S % O &lt; + &gt; &gt; , and t ' = E &lt; EO &lt; + &gt; T &lt; F &lt; ( E ) &gt; &gt; &gt;</definiens>
			</definition>
			<definition id="14">
				<sentence>PAE ri m 11 R s A * A* SOS 111 111 A * I f A B*A B*A B A I B n A TRANSLATION 111 ( 2 , + to 1 , + ) L ( G ) is the language of all addition expressions with 2 , i.e. , the 1 set of all strings of the form 2 + 2 + . . . + 2 .</sentence>
				<definiendum id="0">B*A B*A B A I B n A TRANSLATION</definiendum>
				<definiens id="0">the language of all addition expressions with 2</definiens>
			</definition>
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>Construct ion Modes : The phase of parsing in which the parts of the parse tree and associated tag values are formed , is a place where most of the non-syntactic information ( tags ] about the string being parsed can come into play .</sentence>
				<definiendum id="0">Construct ion Modes</definiendum>
				<definiens id="0">The phase of parsing in which the parts of the parse tree</definiens>
				<definiens id="1">a place where most of the non-syntactic information ( tags ] about the string being parsed can come into play</definiens>
			</definition>
			<definition id="1">
				<sentence>The text consists of the set of entities X1 , X2 , ... , explicitly and implicitly referred to in the text , and structures of $ he form p ( X1 , X2 ) representing the statements m # de or implied about these entities , e.g. walk ( XI ) = X1 walks , building ( XZ ) = X is a building , 2 door ( X3 , X2 ) = X is a &amp; or of X2 .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">the set of entities X1 , X2 , ... , explicitly and implicitly referred to in the text , and structures of $ he form p ( X1 , X2 ) representing the statements m # de or implied about these entities , e.g. walk ( XI ) = X1 walks , building ( XZ ) =</definiens>
				<definiens id="1">a building , 2 door ( X3 , X2 ) =</definiens>
			</definition>
			<definition id="2">
				<sentence>A fact consists of enabling conditions and conclusions .</sentence>
				<definiendum id="0">fact</definiendum>
			</definition>
			<definition id="3">
				<sentence>The '' &lt; Truth Status '' of Inferences. In natural language , unlike mathematics , one is not always free to draw certain inferehces. We tag our inferences always , normally , or sometimes. These notions are defined operationally. An always inference is one we are always free to draw , such as that a street is a path through space. A normally inference is one we can draw if it is not explicitly contradicted elsewhere , such as that buildings have windows. A sometimes inference may be drawn if reinforced elsewhere , such as the fact used below that a building is by a street. This classification of inferencescuts across the cluster structure of the Lexicon. Lattices. A large number of statements in any natural language text , especially the texts this system analyzes , involve a transitive relation , or equivalently , say something about an underlying scale. For example , the word `` walk '' indicates a change of location along a path through space , or a distance scale ; `` turn '' indicates a change along a scale of angular orie , n-tation. In any particular type of text there are scales or transitive relations which are important enough to deserve a more economical repredentation than predicate notation. In this particulak task , the important scales are a distance scale , a subscale of thbis indicating the path `` you '' $ ill travel , and a scale representing angular orientation. This is the principal information used in constructing the map. For these scales we translate into a directed graph or lattice-like representation ( Hobbs 1974 ) . Some of the things which can be said about the structure of a scale are mat some point is on the scale , that of two points on the scale one is closer to the positive end tHan the other , 26 and that a scale is a part of another scale. If a point B is closer to the positive end of the scale than point A , this *fact is represented by A-B If point C lies in the interval from A to B the representation is The diagram mean &amp; the scale from C to D is part of the scale from A to B , It is possible to represent incompleteness of information. For example , if it is known that points A and B both lie in a region R of a scale but their relative positions are not known and if it is known about C only thati , tprecedes B this is represented by The lattice for the distance scale for text ( 1 ) is as follows : Washington St. The Second St. the cross st. Library The lattices are intermediate between the linguistic representation of the directions and the visual representation of the maps. They are used at several points in the semantic and task 27 processes. They can be constructed for any transitive relation , and could be very useful , for example , in representing causal and enabling relations in a system translating descriptions of algorithms into flowcharts OE programs. SEMANTIC OPERATIONS Basic Principle of Semantic Analysis. We bedieve the key to t=he first problem of semantic analysis , that of finding which inferences are appropriate , is Joos ' Semantic Axiom Number One ( Joos 1972 ) , or what I will call the Principle of knitting. Restated , this is , `` The important facts in a text will be repeated , explicitly or implicity. '' That is , we capitalize on the very high degree of redundancy that characterizes a11 texts. Consiifer , for example , the simple sentenced `` Walk out the door of this building. '' `` Walk '' implies motion from one pLace to another. `` Out '' implies motion from inside something to the outside. `` Door '' is something which permits motion from inside something to the outside or from the outside to the inside , or if closed , prevents this motion. `` Building '' is something whose , purpose is for people to be in. Thus , all four content words of the sentence repeatedly key the same facts. Those inferences which should be drawn are those which are keyed by more than one element in the text. This principle is used both formally and informally by the semantic operations. It is used formally in the interpretation. of higher predicates and in finding antecedents. It is used more informally for deciding among competing plausible antecedents , resolving ambiguities , detecting intersentential relations , and knitting the text together in some minimal way. Here it isd primarily the formal uses that will be described. Xnterpretation.of Higher Predicates. In `` walk out '' , `` walk slwoly '' , and `` pleasant walk '' , the higher predicates `` out '' , `` slow '' and ''pleasant '' a11 apply to `` walk '' , but they narrow in on different aspects of walking. That is , each demands that a different inference be drawn from the statement that `` X walks '' . `` Out '' and `` slow '' demand their arguments be motion from one place to another. , forcing us to infe'r from `` X walks '' that `` X goes from A to B '' . `` Out '' then adds information about the locations sf A and B , while `` slow '' says something about the speed of this motion. `` Pleasant '' , on the other hand , requires its argument to be an awareness , so we must infer from `` X walks '' that `` X engages in a bodily activity he is aware of '' . Stored in the Lexicon with each higher predicate is the inference which must be drawn from its argument and the informa11 tion it adds to this inference. For example , go ( zl , z2 , z3 ) '' must be inferred from the argument of `` out '' . When the statement `` out ( waDk ( X1 ) ) '' is encountered in the Text , the higher predicate operation makes efforts to find a proof of 11go ( zl , ~1 , ~3 ) I1 from `` walk ( XL ) '' . The search for this inference is similar td the search procedure described below for finding antecefienes. The facts in the resulting chain of inference are instantiated together with the information added by the higher predicate , and they are subsequently treated as though part ofthe explicit Text. It is usual for them to be useful in further processing , unless the modifier is simply gratuitous information. Note that this operation allows considerable compression in 29 the number of senses that must be stored for each word* It ellows us , for example , to define `` slow '' as something like `` Find the most salient associated motion. Find the most specific speed Scale for the object X of this motion. X 's speed is on the lower end of this scale '' . This definition is adequate for such phrases as `` walk slowlyn ( the most salient motion is the forward motion of the walking ) , `` slow race '' [ the forward motion of the competitors ) , `` slow horsew ( its running at full speed , usually in a race ) , and `` slow personw. This last case is highly dependent on context , and could mean the person 's physical acts in general , his mental processes , or the act he is engaged in at the moment. This operation has a default feature , If a proof of the required inference ca n't be found , it is assumed anyway. This allows a text to be understood even if all the words are n't known. Suppose , for example , `` veer rightw is encountered , and the word `` veern is n't known , i.e. no inferences can be drawn from it. Since `` rightn requires a change in angular orientation as its argument , it is assumed this is what `` veer '' means. Only the information that the change is small is lost. FIND ANTECEDENTS OF DEFINITE NOUN PHRASES ~ntities referred to in a text may be arranged in a hierarchy according to their degree of specification : indefinite , and demofistrative articles zeroed arguments am5 implied entities. 30 So far our work has concerned primarily definite noun phrases , but it is expected that many features of the definite noun phrase algorithm will carry over to other cases , The definite noun phrase algorithm consists of four steps. First , `` uniquent2~s conditionsn are checked to determine whether an antecedent is required. If so , the Text and Lexicon are searched for plausible anteceaents. Third , consistency checks are made on these. Finally if more than one plausible antecedent remains the Principle of Knitting is applied to decide between them. Vniqueness Conditions , In the phrase `` the end of the block '' , we know we must look back in the text for an explicitly or implicitly mentioned `` block '' ( the search case ) , but we do fiat neqessarily look for a previously meptioned `` end '' ( the no-search case ) . Given a definite noun phrase the algorithm first tries to determine whether it belongstothe search or no-search case. This is done by checking two broad criteria. ( These criteria were motivated by a large number of examples not only from sets of directions but also from technical and news articles , ) These criteria are checked by searching the Lexicon for certain features. However these searches are generally very shallow , in contrast to the potentially much deeper searches in the riext step of the algorithm. Sincs by far the majority of definite noun phrases are in the no-search case , checking uniqueness conditions can result in great savings. A caveat is in order. We state the criteria at a very high level of abstraction , We feel in fact that the algorithm can work at that level of abstraction if the ex icon is properly constructed. But how to construct a large exi icon properly is a problem we have not yet tackled in detail. In any event , we give examples for each case , and the examples themselves form a reasonably exhaustive classification. located precisely with respect to some framework. n his includes me following conditions. a. Objects which are located with respect to some identified point in space : `` the building on the corner '' . b , Plurals and mass nouns which are restricted to some identified region sf space : `` the trees in the park '' , `` the water in the swimming pool '' . Here `` the '' indicates all such objects or substance. c.. Points and intervals in time khich are fixed with respect to some identified event : `` the minute you arrive '' , `` the hour since you left '' . d. Events in which at least some of the participants are identified and which can be recognized as occurring at a specific time : nthe ride you took through the park yesterday1 ' ; e , Points or intervqls on more abstract scales : `` the end of the block '' , `` the size of the building '' . The end is a specific point on the distance scale defined by the block. The size of the building is a specific point on the general size scale for objects , i . e. the volume scale. f. Superlatives , ordinals , and related terms : `` the largest house on the block '' , `` the second house on the block '' , `` the only house on the block '' . If the set of comparison is identified , the superlative or ordinal indicates the scale oE comparison and the place on that scale of the entity it describes. This is a subcase of ( e ) . All of these conditions can be checked in one operation if the facts in the Lexicon are expressed in terms of suitably abstract operators relating entities to scales. We simply ask if the definite entity is on or part of a scale or at a point on or along an +interval of a scale , where the scale can be identified. However this requires that we take very seriously my suggestion in Hobbs ( 1974 ) that the lexicon for the entire language be built , insofar as possible , along the lines of a spatial metaphor. We have not yet had to face these problems since our only scales are physical -our `` at '' and `` on '' are the locative `` at '' and `` on '' . Also checking this criterion presupposes a very sophisticated syntactic and semantic analysis. For example , [ d ) assumes that the times of events mentioned in tenseless constructions can be recovered. dominant entity of that description. This divides into two subcriteria : a , Those entities which are unique or dominant by virtue of the properties which describe them : `` the sun1 ' , `` the wind '' . If the properties p1 ( X ) , pZ ( X ) , ... , are known about the definite entity X , the definitions of p1 , p2 , ... , are probed for the fact that the entity does not normally occur in the plural. Included under this heading are proper names beginning with `` the '' , like `` the Empire State Buildingff , and appositives , like `` the city of Bos tonr ' . b. Those entities which are unique by virtue of the properties of an entity with which they are grammatically related : `` the door of the building '' , `` the Hudson River valley '' . `` The door of the buildingn is represented in the Text as `` xl 1 door ' ( ^^ , ^^ 1 building { X2 ) ) ' i.e. `` the Xl such that XI is the door of X2 which is a building '' . The uniqueness or dominance of XI is not a property of `` door '' but of `` building '' . Stored with `` building '' is the fact that a building has in its front surface a main door which does not normally occur in the plural. `` The door of the buildingr ' is interpreted as this dominant dosr. If the tvliqueness conditions succeed , a pointer is set from the dominant lexical variable to the corresponding entity. If subsequently the same definite noun phrase occurs , the uniqueness check will discover this pointer and correctly identify the antecedent. Thus , we can handle the example `` Walk up to the door of the building. Go through the door of the building. '' Here the uniqueness check gives us a shortcut around the next step in the algorithm. The Search for Plausible Antecedents. To illustrate the search for an antecedent , consider `` Walk out the door of this buil8ing. Turn right. Walk to the end of the block. `` What block ? From `` block '' We follow a back pointerto the fact stored with `` streetn *that `` streets consist of blocks '' , and from 34 `` street1 ' the fact with `` buildingt ' that `` Buildings are by streets '' Since a building is mentioned , we assume it is `` the block of the street the building is on '' . The facts in the chain of inference leading to this are instantiated , An entity is introduced into the text for the `` street '' and the Text is augmented by the statements that `` the building is on the street '' and `` the block is part of the street '' . This information turns out to be required for the map. Note that the Eact that a building is on a street is a sometimes fact and that we are free to d'raw it only because `` the blockn occurs* To conduct the search of the Lexicon , ideally we would like to send out a pulse from the word `` block '' which travels faster over more salient paths , and look for the first entity which the ptXlse reaches. The saliency is simulated by the cluster structure descrihea above , The parallel process of the spreading signal is simulated by interleafing deeper pfobes from salient clusters with shallower probes from less salient clusters. For example , if `` streets consist of blocks '' is a cluster 1 fact , then we might probe for a cluster 1 fact involving syreets and a cluster 2 Eact involving blocks at roughly the same time , After one plausible antecedent is found in this way , the search is continued for possible antecedents which are nearly as plausible. If after a time no plausible antecedents are found , the search is discontinued. Searches for antecedents are conducted not only for entities but also for definite noun phrases that the nominalization transformations of the syntactic component have turned into statements 35 -- e.g. `` The walk was tiring '' . Here we look back for a statement whose predicate is `` walk '' or from which a statement involving `` walkn can be inferred. There are cases in which the required inference is in fact a summary of an entire paragraph -- e.g. `` These actions surprised. , . `` -- although of course we can not handle these cases. Consistencv. Each of the plausible antecedents is checked for consistency. Suppose X1 is the definite entity which prompted the search and its properties are and X2 is the proposed antecedent with properties We must cycle through the q 's and the r 's to ensure they are consistent properties. Of course , to prove two properties q ( X ) and r ( X ) inconsistent can be an indefinitely long process with no assurance of termination. One admittedly ad hoc way we get around this is by placing into a special cluster those facts we feel are likely to lead quickly to a contradiction. The second tool we use for deriving inconsistencies may turn out to be quite significant. In the course of processing , the lattice described abave is constructed for several predicates. They contain information which can be useful in deriving an inconsistency. Suppose we have a text in which `` the block '' occurs explicitly several times. Toward the end of it , we encounter `` Turn right onto Adarnii Street. The library fs at the end of the block '' . The search algorithm looks first for explicit mentions of `` blockl '' and finds them. Yet none of these entities is the one we want. Intuitively , the reason we know this is our almost visual feeling that we are already beyond those points. The lattice consistency check corresponds precisely to this feeling. If a definite entity X1 is a point or interval in a lattice or at a point or along an interval , we ask if the proposed antecedent X2 is or can be related to a portion of the lattice. If so , then since the lattice represents a transitive relation , we need only ask if there is a path in the lattice from X2 to XI. If there is , they can not be the same entity. Many cases which pass for applications of the supposed recency principle -- '' Pick the most recent plausible antecedentn-are in reality examples of this consistency check. The earlier plausible antecedent is rejected because of lattice considerations. As the text is processed , the whole structure of the discourse is built up. When a definite noun phrase is encountered , this discourse structure is known and it is this knowledge that is used to determine the antecedent rather than the linear ordering of the words on the page. Competition among Remaining Plausible Antecedents. Even after the consistency checks , several plausible antecedents may remain , forcing us to decide among them on less certain criteria. To do this , we appeal to the Principle of Knitting again and make the choice that will maximize the redundancy in the simplest possible way. A probe is sent out from the definite entity and from each plausible antecedent. Each plausible antecedent is searched for properties it has in comon with the definite entity. Common properties Count most if they are already in the Text , an8 within the Lexicon , comon properties count more if they are within more salient clusters or they result from shorter chains of inference. Default. Like the higher predicate algorithm , the definite noun phrase algorithm has a default feature. If the uniqueness conditions fail and the search turns up no antecedent , we simply introduce a new entity. In fact , in the directians texts there are a disproportionately large number of default cases , for `` the object '' may simply be the object you will see when you reach that point in following the directions. Other Anaphora. We have not yet implemented routines for handling other anaphora. However , we believe they are very similar to the definite noun phrase routine , with certain differences. For entities tagged with demonstrative articles , we do not check uniqueness conditions , and the search will be narrower since the antecedent must be an entity or statement actually occurring in the text. For pronouns also , no uniqueness conditions are checked. The search will turn up more consistent plausible antecedents , and a correspondingly greater burden will be placed on the competition routine. INTERSENTENTIAL CONNECTIVES We detect unstated inter-sentence connectives by matching two successive sentences S1 S2 with a small number of common 38 patterns. In the directions texts the patterns are usually few and simple. The most common are presupposed by S2. S1 asserts or presupposes a state which is the initial state of a change asserted by S2. ( These are likely very common patterns in all narratives , ) For example , in the text `` Walk out the door of this building. Turn right. Walk to the end of the black '' , pattern ( 1 ) joins the first two sentences , where the state is `` You at X '' , Pattern ( 2 ' ) joins the last two sentences , where again the state is `` You at X- '' . Note moreover that the sentences axe interlocked by n second application of the two patterns : The first sentence assumes an angular orientation which is the initial state of the change asserted in the second sentence. The final state of this change is assumed by the third sentence. In addition to providing the discourse with structure , this operation is one of the-princlipal means by which implied entities in one sentence , like X above , are identified with those in another. When pqttern ( 2 ) is applied , we delete the independent occurrence of the state in the Text , so that subsequently it exists only as one intermediate state ih a larger event. Changes across time are handled in this way. TASK PERF-ORMANCE COMPONENT Arbitrary Decisians , The semantic operations are quite 39 general and can be used for any application. The augmented and interrelated Text is then handed aver to the task performance component , which of course is specific to the application. Our task component first makes arbitrary decisions required by the map but not given in the text. Both natural language directions and sketched maps allow information to be incomplete and imprecise , but in different ways. Far example , in nTurn right at the third street or the second stoplight '' . we must decide whether to put the first stoplight at the first or second street , The lattice representing the path `` your ' take must be complete in the sense that it is continuous , begins at the initial location , and ends at the desired goal , and that the relative locations of all points on the path are known. The lattide is complete if and only if there is a directed path passing through every point in the lattice at least once. If it is not complete , it is completed by supplying the fewest possible new links. Gsometr-izing the Lattices. The second task operation is to convert the topological lattice representation into the geometric representation required by the maps. First we assign directions to all the points in the angular orientation lattice. In the simplest case we may have something like where `` a b '' means direction b results from a clockwise rotation of direction a. If no explicit directional information 4 ( 0 is present , we simply assume a , c , and e are the same direction , and b and d are the same , and then assume the two directions are at right angles , Then in the distance lattice , contiguous or overlapping paths which share the same orientation are assumed to be parts of the same path and are mapped into a straight line. Information about names is accessed and assigned to the streets and buildings and the map is drawn , Specific Systems with a General Semantic Component. We are aiming not so much at the construction of a general natural language processing system , which still seems reasonably far off but at an easier way of constructing specific systems. The case of syntax is instructive. It would be foolish for one who is building a natural language processing system to build his syntactic component from scratch. Large general grammars and parsers for them exist ( e.g. Grishman et al. 1973 , Sager &amp; Grishrnan 1975 ) . It is easier by several orders of magnitude to begin with a general grammar and specialize it , by weeding out the rules for constructions that do n't occur in the texts one is dealing with , and by adding a few rules for constructions and constraints peculiar to orre 's application. We are trying to make a similar facility available for the most common kinds of semantic processing. Specializing the general semantic component would consist of several relatively easy steps. First the Lexicon would be organized into a cluster structure appropriate to the task. At worst , this would mean specifying the necessary knowledge in a fairly simple format. If a very large Lexicon were available , this could mean no more than designating for each fact the cluster it should appear in. Certain inferences could be made obligatory while others which are irrelevant to the task could be left out of the special Lexicon altogether. Second a Task Component would be built which would take , as ours does , the semantically processed Text , and use it to perform the task. We are demonstrating the usefulness of this approach in performing a task involving a visual representation. It is likely to be useful in other sorts of tasks also. PERRY t. MILLER Massachusetts Institute of Technology Cambridge , Massachusetts 02139 ABSTRACT \Jheh a user interacts with a natural language system , he may well use words and expressions which were not anticipated by the system designers. This paper describes a system which can play TIC-TAC-TOE , and discuss the game while it is in progress. If the system encounters new words , new expressions , or inadvertent ungrammaticalities , it attempts to understand what was meant , through contextual inference , and by asking ihteliigent clarifying questions of the user. The system then records the meaning of any ne9 words or expressions , thus augmenting its 1inguist ; lic knowledge in the course of user interaction , A number of systems tire being developed which communicate with users in a natural language such as English. The ultimate purpose of such systems is to provide easy computer access to a technically Onsophisticated pepon. When such a person interacts with a natural language systemr , however , he is quite likely to use words and expressions which were not anticipated. To provide truly natural interaction , the system should be able to respond intelligently when this happens. Most current systems , such as those of Winograd [ lo ] and Woods Ill ] , are not designed to ; ope with such `` liiguistic input uncertainty. '' Their parsers fail completely if an input sentence does not use a specific , built-in syntax and vocabulary. At the other extreme , systems like ELIZB [ 93 and PARRY [ Z ] allow the user to type anything , but make no attempt to fully understand the sentence. The present work explores the tnlddle ground between these extremes : developing a sys.t ; em which has a great deal of knowledge about a particular subject area , and which can use this knowledge to make language interaction a flexible , adaptive , learning medium. In pursuing this goal , the present work is most closely related to work being dona in the various speech recognition efforts [ 5 , 7 , 8 , 121 which ara studying how linguistic and semantic constraints can help deal with the ACOUSTIC error and uncertainty of speech. The adaptive system , however , is designed to deal with a much mors LINGUISTIC type of uncertainty. When people use unfamiliar words or expressions in conversation , we can usually deduce from context what is meant , and if not , we can at least ask intelligent clarifying qu~stions. To allow the machine to do the same , there must be a very flexible interaction of syntax and $ emantics in the parsing/understanding process , There must be a different parser organization , and a more flexible use oP linguistic and semantic constraints , than is pfesen t in current natural language sys tern . The adaptive system is a step towards this goal Tha current implementation is a prototype , design'ed to illustrate many of these ideas , and to tie them together in a restricted system that is complete but not too complex. The system 's domain of discourse is TIC-TAC-TOE : it. plays a game and discusses the game in progress. It has a ( currently limited ) set of semantic concepts , and attempts to interpret the user 's sentences ih terms of these. The set of semantic concepts is FIXED. The system does not attempt to learn new concepts , merely new ways of describing concepts that are already familiar. When the system encounters a new word or a new phrasing , it uses contextual information to detername the possible meaning , and to ask clarifying questions which are as intelligent as possible. It then remembers the meaning of the new e &amp; pressfon , and will use it itselF *en it talks. The best way to introduce the system is to show it in operatian. In the sample session that follows , user input is pteced~rd by 'U : '' , machine output by and comments added by the author arg in small type , enclosed in brackets , ( HACHINE : I PLACE AM X IN TClE TOP LEFT SQUARE ) [ The machine makes its opening move. ] ( USER : PLAY A ZERO IN THE CENTER WARE ) ( H : 1s ZERO A NOW HEANING 0 ) ( U : YES ) ( H : OK ) [ The new word *zeroa is added to the machine 's vocabu1ary.l ( R : I PLACE AN X IN THE BOTTOM RIGHT WARE ) ( O : SLAP Ab4 0 IN THE BOTTOV ! LEFT CORNER ) ( PI : IS ( TO SLAP SOMETHING SOREWHERE ) A WAY OF SAYING ( 70 PLACE SOMEmING SOMEWHERE ) ) ( U : YES ) ( 19 : OK ) [ A new surface framer ( as described in section 4 ) Is added to the set sf surface braes which express the concept of making a move. ] ( m : 1 SLAP AN X IN TWE TOP RIGHT SQUARE ) f n this sample sassion , the machine uses its newly acquired vocabulary at every opportunity. ) HOU CORE YOU PLACED AN X IN THE TOP RIGHT SQUARE ) ( H : IS ( HOW CQHE MMEONE DOES SOHETHING ) AN EXPRESSION ISEANIMG ( l ! lOES SOMEONE 00 SQMETHING ) ) ( U : YES ) ( M : OR ) ( H : TO-BEAT YOU ) [ A new surface frme is added to those sxpssssing the concept ' I Syntactic featuras are associated with each such frauge indicating such things as Wether subject-verb invsrsion is ds be DerBomed.1 ( U : CAN YOU CURRENTLY BEAT ME ) m : 1s CURRENTLY AN ADVERB REFERRING TO THE TInE OF A RWE ) [ These are the only adverbs the system knows about. In fact , at present , the system ignores adverbs in its sewantic processing. I % asks the question because it wants to account for all the words in the sentence. ( U : YES ) ' ( M : OK ) ( 11 : YES ) ( M : r s WEST AN ADJECTIVE ~EANING EITHER ( 1 : CORNER ) ( 2 : LEFT ) ( U : 2 ) ( n : or ; ^ ( H : NO ) [ Notice that two top squares contain an x. However , only the left onel was played while the bottom right square was Free. Therefore the systcszn concluded that the top left square was being described. This example illustrates how contextual information can be used to ask as intelligent a cBarifying question as passibla. ] ( U : *yOW COME YOU PLACED AJ4 X IN THE TOP EAST SQUARE ) ( ! I : IS EAST AN l @ JECTLVE NEAWXNG ) EITHER ( 1 : RIGHT ) ( 2 : WEST ) ( 0 : lp ( U : on ) M IS ( TO LAY SONETHING SOHEWHERE ) A WAY OF SAYING ( TO SLAP SOflETHING S0UEWERE ) ) ( U : YES ) ( M : OK ) ( H : IS ( TO POLISH SOMEONE OFF ) A WAY OF SAYING ) E I THER ( 1 : ( TO BEAT SOMEONE ) ) ( 2 : ( TO LOSE TO SOMEONE ) ) ( 3 : ( TO TIE SOMEONE ) ) ( U : I ) ( ? '¶ : OK ) ( R : BY LAYING AN X ON WE TOP CENTER CELL ) [ If this same session were subsequently repeated , sf course , the system would not need to ask any questions of the ushJr. 1 There are a number of limrtations to the adaptive system as it now stands. Some of these may be apparent in the smple session , bud an introductian to the system is not complete without discussing them explicitly. ( 1 ) The number of concepts available to the system at present is very small. This , in fact , is why the system 's first guess is usually the correct one. If the sentence is at all within the systea 's comprehension , the options as to its meaning are currently quite limited. ( 2 ) The range of expressive devices presently recognized is quits limited as well. For instance , the system does not recognaze relative clauses , con junctions , or pronouns ( except for 1 and you ) . ( 3 ) The system currently deals only with TOTALLY UNFMILIAR words and expressions in this adaptive fashion , It will not correctly handle familiar words which are used in new ways ( such as a noun used eas a varb , as in wzero the center squaren ) . ( 4 ) The system tries to map the meaning of new wards and expressiuns into its specified set of underlying concepts. It then displays its hypotheses to the user , giving him only the option of saying yas or nu. The user cann-ot say `` no , not quite , it meahs . . . '' . ( Thus concepts like Vhe 'northeast1 square '' or `` the 'topmost ' squarew would ba confusing and not correctly understood. ) The present simple system has been developed with two goals in mind : ( 1 ) to explore the techniques required to achieve adaptive behavior , and ( 2 ) to help fornulate the issues which will have to be faced when incorporating these techniques into a much broader natural language system. Fig. 1 shows ths various stages that the Adaptive System gees through in understanding a sentence. In this sectian , we shall watch while the system processes the sentence `` Mow came you placed an x in the top right ~quare.~ ( 1 ) Local Syntactic Processing : In this first stage , the system scans the entire sentence looking for local constituents. These include Hsimplem noun phrases ( NPs ) and prepositional phrases ( PPs ) , ( `` simplen meaning 'up to the head noun but not including any modifying clauses or phrases '' ) , and verb groups ( VGs ) consisting of verbs together with any adjoining rnodals , auxilliaries , and adverbs. In this instance , the system Finds the two NPs , `` youe and `` an xm , the PP `` in the top right squarem , and the VG nplacedw. ( 2 ) Semantic Clustering : At this stage , the clause-level processing starts. Unlike most systems , this clause-level processing is driven by SEMANTIC rslationshigs , rath-er than by syntactic form. It uses a semantics-first kclustssinsg* , with a sscondary use of syntax for cormnents and confirmation+ In this example , all the local constituents found can be clustered into s description of e single concept : that of making a nave , Section 4 describes the mechanics of this stage in more detail. ( 3 ) Cluster Expansion and Connection : During this stage an attempt Is mada to account Psr each word in the sentence by expanding the concept clusters , and if there is more thaw one , by joining them together to form an entire multicXausa1 sentenceIn this case , ths concept cluster rnlght bs axpanded In two ways. a ) One possiblllty night be that It is a `` MOW '' type question , and that wcornc.tn is some sort of adverb , However this possibility violatsf a semantic constraiet , since the system is not set up to answer haw a move is made ; only how to win , how to prevent sorneons From winning , etc. Therefore this possibility is ignored. b ) The other possibility f r ; that `` how come '' is a new way of describing soma other clause funetton. ( 4 ) Contextual Inference ; Clarification ; and Response : During this final staga , any contextual inf~rrnatfsn available is brought to bear on araas of uncertainty , any necessary clarifying questions are asked , and the system responds to the sentencs. In this example , the only uncertainty is the meaning of `` how comew. Since this is the main sentence 1 Xocal constituents concept clusters complete sentence hypothesf s system responds to sentence Fig. 1 : Adaptive System Overview clause of the sentence , the possibility of its being an Wn or *aftsra clause are discarded. The remaining possibilities are nimperativsw , `` hown , m~hyn , and `` canw. The system does not answer % own and `` canw quest ions in relation to making moves. Similarly , `` imperativen does not make sense since the action described is a previously made move. Therefore the system asks if `` How come someone does somethingw means Vhy does someone do somethingn. The user answers `` yesn , so the system stores this new way of asking `` whyn , and proceeds to answer the question. One of the major differences between this approach to parsing and that of a top-down , syntax-driven system ( such as Moods ' or Winograd 's ) is the order in which syntactic and semantic processing is done at the clause level. In a top-dom system , a sentence must exactly match the built-in syntax before semantics can even be called and given the various constituents of a clause , This IS clearly undesirable when one is dealing with input uncertainty , since one can not be sure exactly how the user will phrase his sentence. One would prefer to Bet semantics opera % @ First on any local consituents present , so that it can make a reasonable grgss as to what is being discussed. As semantically-rslated clusters of local constf tuents are found , syntax can be consulted and asked to comment. on the rslative grmmaticality of the various clusters. If there are two competing semantlc inte~pretations of one part of a sentence , and syntax likes one much better than the other , then the `` syntactically pleasing '' interpretation can be pursued first. Later , if this does not pan out , the syntactically irregular possibility can be looked at as wsP1. In this way , syntax can help guide the system , but is not placed in a totally controlling position. A by-product advantage of this semantics-first approach is that the system can handle mildly ungrammatical input without any extra work , In addition , the semantics-first clustaring approach lends itself quite naturally to handling sentence fragments. In the remainder of thks section , we describe how the adaptive system organizes ids linguistic knowledge to implement this semanticsfirst approach. As we shall see , there are three componeflts of this knowledge. ( a ) Ths local racognizars which initially find local constituents. recognizers are represented tn Augmented Transition Network [ Ill fom , are quits simple , and are not described further in this paper. ( b ) Clause-level knowledge sf how actions and clause-functions are described. This knowledge is expressed in a descriptiva fashion which makes it msily manipulabla , and easy to add to. ( c ) Clause-level syntactic knowladge which is sxprssred ira a domainindebpendent fom. Figure 2 illustrates how the system stores its knowledge sf how actions ( or events ) are described. This knowledge is stored at two levels : the conceptual level , and the surface ( or expressive ) level As shown in Fig. 2 , the concept PLACE represents the act of making a TIC-TAC-TOE wove. ( a ) On the CONCEPTUAL level , there are three `` conceptual slots ' indicating the actors which are involved in the actlon : a player , a @ ark , and a square. ( b ) On the SURFACE , or expressive , level there is a list sf surface frames each indicating one possible way that the concept can be expressed. Each surface frame conslsts of a verb plus a set of syntactis case frames to be filled by the actors. ( Notice that neither the conceptual slots nar the surface frames indicate explicitly the order in which the varlous constituents are to appear Fw a sentence. ) When the system processes a sentence , it fills the concsptual shots with local constituents found rn the sentence If it has found a fmiliar verb , then it also gets any surface e ( s ) associated with that verb. At this point it calls syntax , asking for csments. For instance , if the input sentence is `` 1 place an x in the corner '' , then all the conceptual slots of # PLACE would be filled , and the system would pass the following string to syntax wagen % verb obj ppw . As a result , clause-level syntax does not see the actual constituents of the sentence , only the labels specifled In the surface case frame , plus information indicating number , tense , etc . An interesting aspect of this approach is that the clause-level syntax is entirely domain-independent. It knows no thing about TIC-TACTOE , or even about the words used to talk about TIC-TAC-TOE. Tke surface frames allow semantics to talk to syntax purely in terms of syntactic labels. As a result , one could write a single syntactic module , and than insert it unchanged into many domains. In this section , we describe in more detail how this knowledge can be used when processing a sentence. ( 1 ) If the verb and constituents are familiar : If there is no uncertainty in a clause , then each constituent can be put into one of Ghe conceptual slots , and any surface frames associated with the verb can be examined The frame ~ndicates the csse ( agent , object , etc. ) associated with each constituent whon that verb is used. The frame is used ta create a string of case labels that are sent to syntax for coments. For instance , iF the sentence is `` 1 place an x in the center CONCEPT : PLACE CONCEPTUAL SLOTS : P : player H : mark S : square SURFACE FRAMES : VERB : place ( as in : AGENT : P mI place an x in the centera ) OW : PI in : S VERB : play ( as in : AGENT : P sf play an x in the centers ) ow : H In : S VERB : play ( as in : AGENT : P wX play the center '' ) 00J : S FLg . 2 : Linguistic KnowleMge about Actions square '' , the string passed to syntax is `` agent verb obj pp '' . Syntax replies that the sentence follows normal order. Had the string been `` verb obj pp '' syntax would reply that the subject had been deleted. If the string was @ 'do agent verb obj ppn , syntax would reply that subjectverb inversion had taken place. Given `` gent obj verb ppn , syntax would reply that the object was out of position. Thus syntax is set up to notice both g~irnmcatical and ungrmatf cal permutations in constituent order , and to comment appropriately. The system must then decide how to interpret these comments. For instance , if syntax replies that the object is out of position in the clause , or that there is incorrect agreement in number between subject and verb , the system may decide that the user has made a minor grammatical error , and allow the sentence to be processed anyway , especially if there is no better interpretation of the sentence. In this way , clause-level syntax plays an assisting role rather than a castrolling role in the analysis of a sentence. ( 2 ) If a constituent is unknown : If an unknown constituent is present , then both the frame and slot information can be used to help resolve its meaning. For instance , suppose the sentence is `` I place a cross in the canter squarew , and the , word ~crossu is unfamiliar , Here , during the semantic clustering , the conceptual slots for a player and a square can bs filled by `` Iu and `` in the center square '' , but the slot for a mark is unfilled. In additiq , there is the unknown constituent `` a crossg. A natural hypothesis , therefore , is that the unknown constituent refers to a type of mark. Since the verb is familia~ , a surface frme is avaflable. Next , assumtag the unknown constituent is a mark , the string `` agent verb obj ppw can be passed to syntax. Men syntax approves , this offers additional confirmation that the hypothesis is probably right. Subsequent evaluation of this hypothesis indicates that the sentence makes sense only if the mark referred to is Etn x , so the system asks if `` crossu is a noun meaning ( 3 ) If the verb is unknown : If an unfamiliar verb is used , then there is no surface fsme availabls to help guide the analysis. Instead , syntax must ba used in a different mode to propose what the surface frame should be. Suppose the sentence is `` I plunk an x in the center squareM. Here , all the constituants can be clustered into the concept # PLACE , but tbre is an unknown word , and no verb. Ths loglcrrl hypothasis is that the new word is a verb. A special syntactic module is therefore passad the followfag string `` NP ( P ) verb ( p1unk ) NP ( M ) PP ( in , S ) # This module examines the string and produces tn new Frame : VERB : plunk AGENT : P OW : R in : 8 The system can then ask if `` to plunk something somewherew means `` to place something somewheren , and upon getting an affirmative reply , can add the new frame to those associated with the concept PLACE. Since the system uses the surface frames to generate its om replies , it can now-use this new frame itself when it talks. When the system wants to generate a clause , it passes a selected frame , the constituents , and a list of syntactic features to a clause generator which outputs the specified form. ( Thus , clauss-level syntax can be used by the system in three different modes : ( 1 ) to comment on the grmaticality of a string of case markers , ( 2 ) to constrbct a new surface frame , and ( 3 ) to generate clauscas when tha system itself replies. ) As illustrated in Fig. 3 , knowledge of how clause-function concepts are described is also expressed as two Lexals. CONCEPT : # WHY CONCEPTUAL SLOTS : ACTION : # PLACE SURFACE F Why ACTIQN ( SV1NV ) ( as in : *Why does someone do somsthkng '' ) flow come ACTION ( ) ( as in : `` Now come someone does something '' ) Fig. 3 : Linguistic howl edge about Clause Functions Each clause function has a conceptual slot indicating what types of action can be used with that clause type ( in this case , the action # PLACE ) , and a list of surface frames indicating different ways in which the cancspt can be expressed. A clause-type frame currently includes any special words which introduce the clause ( ie. `` whyn or `` how comen ) , together with a list sf syntactic proparties which should be present in the clauss. This list of syntactic properties might include SVIMV , nsubjec $ -verb inversionw ( as in `` why does someone do something '' ) , ar 9ub ject deletionH , 'ING fomm , and `` use of a particular preposition* ( as in `` from doing somethingw ) . These syntactic features , however , need not bs inflexible rules. Sentence understanding can still psocaed wen if tha syntactic features found by syntax do not exactly match those specified by the clausefunction frame. Thus , an inadvertent ungrammaticality cam readily be recognized as such , and processing can continue. In this section we examine how this clause function knowledge can be used. ( 1 ) With no uncertainty : If the input sentence is `` Why dld you place an x in the center squarew , then during the semantic clustering the string Rdo agent verb obj ppu is passed to syntax , which replies that subject-verb inversion has taken place. When exarninlng the whole clause , the system sees that it exactly matches one of the surface frames for a # WHY-type question , since it starts with the word n~hyVind contams subject-verb inverslbon , Suppose , however , the sentence had been `` Why you place an x IR the center squaren , or `` How come did you place an x in the center square*. Each of these sentences matches a surface frame for a MY-type question , except that in both cases subject-verb inversion is incorrect. In such a case , the system can , if it chooses , decide that the user has made a minor error , and allow the sentence to be processed anway. The locally-driven semantics-first approach Lets this happen in a natural way. ( 2 ) A new surface frame : Another problem arises when a new clause introducer is encountered , as in : `` Wherefore did you place an x in the center squareM. Here , as described in section 3 , the system hypothesizes that this may be a new way of asking a # WHY-type question. Since syntax reports that subject-verb inversion has taken place , the system can therefore create a new surface frame : Wherefore ACTIOM ( SV1NV ) to be added to the frames associated with # WHY. B In summary , the adaptive -5ys tern stores its linguistic knowledge in a very accessible form. It is not embedded in the parsing logic. howledge of how actions and clause-functions are described is represented in a descriptive , manipulable format. Syntax is domain independent , and is used only to make cornants , with semantics playing the guiding role. This organization allows the parsinglunderstanding process to proceed kn a flexible fashion , Language communication is an inherently adaptive medium. One sees this clearly ~f one takes a problem to a lawyer and spends time trying to assimilate the related `` legalesen. One also sees it in any conversation where a persron is trying to convey a complicated idea , expressed in his own mental terms , to someone else. The listener must try to relate the words he Rears to his own set of concepts. Language has , presumably , evolved to facilitate this sort of interaction. Therefore it is reasonable to expect that a good deal of the structure of language is in some sense set up to assist in this adaptive process. By the same token , studying language from an adaptive standpoint should provide a fresh perspective on how the various levsls of linguistic structure interact. 1575 ACL Mcetlng CONCEPTUAL GRAMMAR WILLIAM A , MARTIN Kassachusetts Insti tute of Tech~ology In OWL , an implementation of conceptual grammar , the two types of data items are symbols and concepts and the two basic data composition operations are specialization and restriction. A symbol is an alphanumeric string headed by `` . Symbols correspond to words , suffixes , prefixes , and word stens in Znglish and the programer can introduce them at willm OWL concepts correspond to the meanings of EEglish words and phrases. They are constructed using the specialization operation , comparable to CONS in LISP* ( A B ) is the specialization of A , a concept , by B , a concept or symbol. OWL form a branching tree under specialization , with SOMETHING at the top. Concepts are given properties by restriction , which puts a concept on the reference list of another concept ( compare property lists and S-expressions in LISP ) . A/B is the restriction of A by B. The categories in the specialization tree are semantic , but we use them also for the purposes usually assigned to syntactic dategories. A predication is a double specification of 2 model such as present tense or can. Examples are The pool is full of water. ( ( PRES-TNS ( BE ( FULL 94TER ) ) J POOL/THE ) The cookie can be in the jaf. ( ( CAN ( BE ( IN JAR/TIIE ) ) ) COOKIE/THE ) aob is the father of Sam. ( ( PRES -TKS ( BE ( FATHE : SAM ) ITHE ) ) BOB ) 3ob hits the ball. ( ( PRES-TNS ( HIT BALLITHE ) ) Boa ) Bob is hitting the ball. ( ( PRES-TNS ( BE ( -ING ( HIT BALL/THE ) ) ) ) BOB ) Starting from this base we will discuss a number of issues buch as n~minalization incorporation , and deep vs surface cases. American Journal of Computational Linguistics ~icroffche 32 : 58 JOHN F. BURGER , ANTONIO LEAL , AND ARIE SHOSHANI System Development Corporation Santa Monica , California 90406 mcT We describe a natural-language recognition system having both applied and theoretical relevance. At the applications level , the prwram will give a natural ccmmunications interface facility to users of existing interactive data management systems. At the theoretical level , our work shows that the useful infoxmation in a natural-language expression ( its `` meaning '' ) can be obtained by an algorithm that uses no formal description of synt-. The construction of the parsing tree is controlled primarily by semantics in the form of an abstraction of the nmicxo-world '' of the DMS 's functional capabilities and the organizat~on and semantic relations of the data base content material. A prototype is currently implemented in LTSP 1.5 on tho IBM 370/145 computsr at System Development Corporation. In a recent article in Scientific , American , Dr. Alphonse Chapanis says , `` Tf truly interactive computer ( ; ystm are ever to be created , they will ~omehow have to cope with the ... errors and violations of format that are the rule rather than the exception in normal human ccmmunication '' [ 1 ] . An example dialogue produced by twa persons interacting with each other by teletypewriter to solve a problem as~igned to them by experimenters showed that : not one grernaaatfcally correct sentence appears in the entire protocol. tl Many existing language pmcessors ( woods , Kellogg , Thcmpson , etc. ) [ 2,3,4 ) are limited to what Chapanis calls `` Irmnaculate prose , '' that is , `` the sentences that are fed into the computer are parsed in one way or another so that the meaning of the ensemble can be inferred frm conventional rules of syntax , '' which are a £0description of the language. In effect , users are required to interact with these system in sme formal language , or at least in a language that has a formal representation in the computer system that a user 's expression must conform to ( we are thinking , in the latter instance , of Vhampsonls REL , which has an extensible formal representation facility ) . In addition , most natural-language question-answering systems , including all referenced above , require that a user 's data be restruct-wedl and reorganized acwraing to the particular data base requirements of the natural-language system to be used. At the level of artificial intelligence research [ ti ,6 , ? 'I , Mere is same interest in systems that recognize meaning in natural-language expressions by methods that dd not mire compiler-like syntactic analysi~ of an expression prior to asmantic interpretation. We believe it is possible , practical , and feasible , using new lingufstic processing strategies , to design a natural-language interface system that will permit flexible , intuitive coaansmicatiba with information management systems and other computer programs already in existence. This interface is open-ended in that it has no prejudice about the user 's system funckians and can be joined to almost any such system with relatively little effort. It is , in addition , able to infer the meaning of free-form English expressions , as they pertain to the host system , without requiring any formal description or representation of English. THE SEMANTIC INTEREACE ALTERNATIVE The syntactic inflexibiiity of existing natural-language processors limits their usefulness in interactive man-madine tasks. Our approach does not use a collection of syntax rules or equations as they are normally defined. Instead , we construct a dictionary in which we define words in terms of their possible meanings with respect to the particular data base and data management system ( DMS ) we want to use and according to the possible relations that can exist between data-base and I3MS elements ( e.g. , an averaging function on a group CKE numbers ) in the limited `` micro-world '' of this precisely organized data collection. Words appearing in a user 's expression that are not explicitly defined are ignored by the system in processing the expression ; an example would be the word `` the , '' which is usually not meaningful in a data management environment. Wa thus avoid the expressive rigidity that formal syntactic methods hposa on tha user and the excesaivcs time and resource consumption that results from the catibinatorial explosions usually produced by such rnethade. We distinguish in their definitions beween two types of words : content words md function worb ( or `` operatore '' ) . Content words are wads whoae 'meaningsw are the objects , events , and concepts that make up the subjects being referred to by users , More precisely , for data axetnagernent systems , these meanings ( or `` concepts '' ) are the field names and entz'y identifiers for *e data b-e and the names for available IHS operations such as averaging , sdng , sorting , comparing , etc. Function words serve as connectors of content words. Their use in natural language is to indicate khe manner in which neighboring conltent words ar'e intended to relate to one another. In the example `` the salary of the secretary , '' used belaw , `` salary '' and `` secretary , '' are content words , and `` of '' is a function word used to connect theta. Many cmntent wor &amp; are context sensitive , In a particular data base , for btmcm , the ward `` salary '' may refer to the data-base field name SECSAL if the saXW frs `` of a secretary , '' but may also indicate the field name CLKSAL if it is a *salary of a clerk. '' In recpgnition of this we therefore define eaah aontent word by a set of one or more pairs of the form ( ( XI Yl ) ( X2 Y2 ) . . . ( Xn Yn ) ) where the Xi ad Yi are `` ooncep~ '' ( that is , field names , etc. ) as described above. This expression may be interpreted as , `` if the word so defined irjt contactually related in a sehtance to Xl , its particular meaning in this centact is Y1 , if it isr eo related b X2 , it meme Y2 , md ao forth. '' This particular oontextual mnaranfng af the word is callad its sense. Two content warm are consrid= &amp; to bls artmantically related if the intersection of the Xi'a fmtn the definition of one wort ! with the Yi 's from the definition of U1Q other ira not empty. To get a more intuitive understanding of this process , suppose , again , that a data base contains entries for both secretaries and clerks with salaries fox each. Suppose `` Suzi &amp; ' is an instance of a secretary and om '' is an instance of a clerk. We then have three words defined as follms : Suzie ( ( SUZIE SECY ) ) Torn ( ( TOM C-LK ) ) Salary ( ( sECY SECSAL ) ( CLK CLKSAL ) ) Processing me phrase `` Suzie ' s salary '' would intersect the Yi ( `` ( SECY ) `` ) from the definition of `` Suzie '' with the Xi 's ( `` SECY '' and `` CLK '' ) from the definition of `` salary. '' The intersection is nan-empty ( `` ( SECY ) '' ) , and , in discovering the semantic relationship the sense `` SECSALI- ' is assigned to the word `` salary. '' Similarly , `` Tan 's salary '' assigns the sense `` CLKSAL '' to `` salary. ! I A particular bplmentation of the natural-language interface processor operates for a particular DMS/data-base target system. It contains a particular &amp; &amp; ioncreated for that target system. For a particular dictionary , the set of a21 lists 05 pairs as described above , therefore , constitutes the equivalent of a ~anccpt q~aph ox network for the particular data baa malogous to those URQ~ hy many of the more conventj-onall , parsers Pox semantic analysis folluwing ( or during ) the syntactic phase of parsing. In the analysis of a particular input by our system , two words in context are te~ted using the `` intersection '' method described abave and , if they are found to be semantically related , they are considered candidates for `` connection '' as descrrLbed below. Two words so connected £om a phrase. Function words are defined as operators or processors that perform this semantic test. The definition of one function word differs fm that of another according to its slope ( see belaw ) and also in that the operational definition of a function word can reject a connection even though the two words may be samntically related. In the operational definition of the function word may be a list of acceptable concepts or a rejection list of unacceptable concepts. In most conceivable data bases , the phrase `` salary in the secretary '' would be thus rejected by the function word `` in. n As the analysis of an input expression proceeds , a `` clumpifig '' of word and phr as e meanings more and more explicitly normally , processing of the entire sentence results in a tree structure made up of the connected senses of all the content words fran the sentence. This result we term the sentence qraph even though the input expression may not be a grammatically cmplete sentence. This sentence graph will be translated into statement. We recognize that the linear ordering of the words in an input expression is not entirely randm and that certain aspects of me function of syntax must be taken into accorunt. This is done by means of a new and pwerful azgorithm bkd on what we call the syntactic-semantic slope. Linguists generally recognize that whenever two units of meaning are combined , one is semantically domfnant and the other subordinate , as a modifier is subordinate to the modified word. After coenbinatfon , the ddnant word may be wed in most cases to refar to the canjoined pair. Thus , a `` red herring '' 18 a `` herring '' ( not a `` red '' ) , and the `` salary of the secretary '' is a `` salary. '' If this relationship of dominance is represented vertically on a ltrectangular graph ( i.e. , dominance on the Y-axis ) , and if t &amp; e linear ordering of the words in the expression is represented on the X-axis in now1 left -- -right : order , then the connection of an adjacent pair of content words or phrases will describe a linear slope on the graph. The slope is positive eir negative as the dominating sub-unit is , respectively , to the right or to the left of the subordinate sub-unit. For example , the phrase `` red herring '' makes a positive slope , thus : HERRING / RED and `` the salary of the secre= '' makes a negative slope : S ; 71LARY Thus , the ~pera~onal meanings of fqnctian words operate on the meanings of nearby content words. Dominance is assigned , semantic relationships are verified , and the relationships so discovered are accepted or rejected. If accepted , the two word-meanings are connected , and the acceptable sense is assigned to the dumllnant word. Eunction words may connect content words in `` positive , '' `` negative , '' or `` peak '' connections. me follming are examples of each mannax of connection : SALARY contrast with positive and negative operators , peak operators add a representation of their m semantics into the structures they build ; AND \ A-IC PACIFIC operator that is a positive operator , as in `` red herring '' : RED In general , all prepositions are defined as negative operators. This is equivalent Go the rule used by syntactic processors. The positive empty operator is equivalent to the rule NP+AxxrP3P and athew , while vexbe and conjunctions are defined as peak operators , giving our atatemcnt of rules such errs s+NPvE'NP MP + NP CONJ NP. Each operator has the facility to accept or reject any semantic rejlation accordin9 to the precise definition of the function word for the host data management system. Progressive connection of word meanings and previously connected groups or `` phrase meanings '' results in a tree graph that we call the sentence qraph. For example , the question `` What is ; t ; he surface displacement of US. diesel submarines ? '' could , for a particular data base , produce from the dictionary a string of content-word and funeion-word definitions that might be represented typographically like this : ( ( SUB SURE-DISC ) ) &lt; OF &gt; ( ( U .</sentence>
				<definiendum id="0">definition</definiendum>
				<definiendum id="1">end</definiendum>
				<definiendum id="2">X2</definiendum>
				<definiendum id="3">Response</definiendum>
				<definiendum id="4">tbre</definiendum>
				<definiendum id="5">restriction. A symbol</definiendum>
				<definiendum id="6">'I , Mere</definiendum>
				<definiens id="0">The '' &lt; Truth Status '' of Inferences. In natural language , unlike mathematics , one is not always free to draw certain inferehces. We tag our inferences always , normally , or sometimes. These notions are defined operationally. An always inference is one we are always free to draw , such as that a street is a path through space. A normally inference is one we can draw if it is not explicitly contradicted elsewhere , such as that buildings have windows. A sometimes inference may be drawn if reinforced elsewhere , such as the fact used below that a building is by a street. This classification of inferencescuts across the cluster structure of the Lexicon. Lattices. A large number of statements in any natural language text , especially the texts this system analyzes , involve a transitive relation , or equivalently , say something about an underlying scale. For example , the word `` walk '' indicates a change of location along a path through space , or a distance scale ; `` turn '' indicates a change along a scale of angular orie , n-tation. In any particular type of text there are scales or transitive relations which are important enough to deserve a more economical repredentation than predicate notation. In this particulak task , the important scales are a distance scale , a subscale of thbis indicating the path `` you '' $ ill travel , and a scale representing angular orientation. This is the principal information used in constructing the map. For these scales we translate into a directed graph or lattice-like representation ( Hobbs 1974 ) . Some of the things which can be said about the structure of a scale are mat some point is on the scale , that of two points on the scale one is closer to the positive end tHan the other , 26 and that a scale is a part of another scale. If a point B is closer to the positive end of the scale than point A , this *fact is represented by A-B If point C lies in the interval from A to B the representation is The diagram mean &amp; the scale from C to D is part of the scale from A to B , It is possible to represent incompleteness of information. For example , if it is known that points A and B both lie in a region R of a scale but their relative positions are not known and if it is known about C only thati , tprecedes B this is represented by The lattice for the distance scale for text ( 1 ) is as follows : Washington St. The Second St. the cross st. Library The lattices are intermediate between the linguistic representation of the directions and the visual representation of the maps. They are used at several points in the semantic and task 27 processes. They can be constructed for any transitive relation , and could be very useful , for example , in representing causal and enabling relations in a system translating descriptions of algorithms into flowcharts OE programs. SEMANTIC OPERATIONS Basic Principle of Semantic Analysis. We bedieve the key to t=he first problem of semantic analysis , that of finding which inferences are appropriate , is Joos ' Semantic Axiom Number One ( Joos 1972 ) , or what I will call the Principle of knitting. Restated , this is , `` The important facts in a text will be repeated , explicitly or implicity. '' That is , we capitalize on the very high degree of redundancy that characterizes a11 texts. Consiifer , for example , the simple sentenced `` Walk out the door of this building. '' `` Walk '' implies motion from one pLace to another. `` Out '' implies motion from inside something to the outside. `` Door '' is something which permits motion from inside something to the outside or from the outside to the inside , or if closed , prevents this motion. `` Building '' is something whose , purpose is for people to be in. Thus , all four content words of the sentence repeatedly key the same facts. Those inferences which should be drawn are those which are keyed by more than one element in the text. This principle is used both formally and informally by the semantic operations. It is used formally in the interpretation. of higher predicates and in finding antecedents. It is used more informally for deciding among competing plausible antecedents , resolving ambiguities , detecting intersentential relations , and knitting the text together in some minimal way. Here it isd primarily the formal uses that will be described. Xnterpretation.of Higher Predicates. In `` walk out '' , `` walk slwoly '' , and `` pleasant walk '' , the higher predicates `` out '' , `` slow '' and ''pleasant '' a11 apply to `` walk '' , but they narrow in on different aspects of walking. That is , each demands that a different inference be drawn from the statement that `` X walks '' . `` Out '' and `` slow '' demand their arguments be motion from one place to another. , forcing us to infe'r from `` X walks '' that `` X goes from A to B '' . `` Out '' then adds information about the locations sf A and B , while `` slow '' says something about the speed of this motion. `` Pleasant '' , on the other hand , requires its argument to be an awareness , so we must infer from `` X walks '' that `` X engages in a bodily activity he is aware of '' . Stored in the Lexicon with each higher predicate is the inference which must be drawn from its argument and the informa11 tion it adds to this inference. For example , go ( zl , z2 , z3 ) '' must be inferred from the argument of `` out '' . When the statement `` out ( waDk ( X1 ) ) '' is encountered in the Text , the higher predicate operation makes efforts to find a proof of 11go ( zl , ~1 , ~3 ) I1 from `` walk ( XL ) '' . The search for this inference is similar td the search procedure described below for finding antecefienes. The facts in the resulting chain of inference are instantiated together with the information added by the higher predicate , and they are subsequently treated as though part ofthe explicit Text. It is usual for them to be useful in further processing , unless the modifier is simply gratuitous information. Note that this operation allows considerable compression in 29 the number of senses that must be stored for each word* It ellows us , for example , to define `` slow '' as something like `` Find the most salient associated motion. Find the most specific speed Scale for the object X of this motion. X 's speed is on the lower end of this scale ''</definiens>
				<definiens id="1">adequate for such phrases as `` walk slowlyn ( the most salient motion is the forward motion of the walking ) , `` slow race '' [ the forward motion of the competitors ) , `` slow horsew ( its running at full speed , usually in a race ) , and `` slow personw. This last case is highly dependent on context , and could mean the person 's physical acts in general , his mental processes , or the act he is engaged in at the moment. This operation has a default feature , If a proof of the required inference ca n't be found , it is assumed anyway. This allows a text to be understood even if all the words are n't known. Suppose , for example , `` veer rightw is encountered , and the word `` veern is n't known , i.e. no inferences can be drawn from it. Since `` rightn requires a change in angular orientation as its argument , it is assumed this is what `` veer '' means. Only the information that the change is small is lost. FIND ANTECEDENTS OF DEFINITE NOUN PHRASES ~ntities referred to in a text may be arranged in a hierarchy according to their degree of specification : indefinite , and demofistrative articles zeroed arguments am5 implied entities. 30 So far our work has concerned primarily definite noun phrases , but it is expected that many features of the definite noun phrase algorithm will carry over to other cases , The definite noun phrase algorithm consists of four steps. First , `` uniquent2~s conditionsn are checked to determine whether an antecedent is required. If so , the Text and Lexicon are searched for plausible anteceaents. Third , consistency checks are made on these. Finally if more than one plausible antecedent remains the Principle of Knitting is applied to decide between them. Vniqueness Conditions , In the phrase `` the end of the block '' , we know we must look back in the text for an explicitly or implicitly mentioned `` block '' ( the search case ) , but we do fiat neqessarily look for a previously meptioned `` end '' ( the no-search case ) . Given a definite noun phrase the algorithm first tries to determine whether it belongstothe search or no-search case. This is done by checking two broad criteria. ( These criteria were motivated by a large number of examples not only from sets of directions but also from technical and news articles , ) These criteria are checked by searching the Lexicon for certain features. However these searches are generally very shallow , in contrast to the potentially much deeper searches in the riext step of the algorithm. Sincs by far the majority of definite noun phrases are in the no-search case , checking uniqueness conditions can result in great savings. A caveat is in order. We state the criteria at a very high level of abstraction , We feel in fact that the algorithm can work at that level of abstraction if the ex icon is properly constructed. But how to construct a large exi icon properly is a problem we have not yet tackled in detail. In any event , we give examples for each case , and the examples themselves form a reasonably exhaustive classification. located precisely with respect to some framework. n his includes me following conditions. a. Objects which are located with respect to some identified point in space : `` the building on the corner '' . b , Plurals and mass nouns which are restricted to some identified region sf space : `` the trees in the park '' , `` the water in the swimming pool '' . Here `` the '' indicates all such objects or substance. c.. Points and intervals in time khich are fixed with respect to some identified event : `` the minute you arrive '' , `` the hour since you left '' . d. Events in which at least some of the participants are identified and which can be recognized as occurring at a specific time : nthe ride you took through the park yesterday1 ' ; e , Points or intervqls on more abstract scales : `` the end of the block '' , `` the size of the building ''</definiens>
				<definiens id="2">a specific point on the distance scale defined by the block. The size of the building is a specific point on the general size scale for objects , i . e. the volume scale. f. Superlatives , ordinals , and related terms : `` the largest house on the block '' , `` the second house on the block '' , `` the only house on the block '' . If the set of comparison is identified , the superlative or ordinal indicates the scale oE comparison and the place on that scale of the entity it describes. This is a subcase of ( e ) . All of these conditions can be checked in one operation if the facts in the Lexicon are expressed in terms of suitably abstract operators relating entities to scales. We simply ask if the definite entity is on or part of a scale or at a point on or along an +interval of a scale , where the scale can be identified. However this requires that we take very seriously my suggestion in Hobbs ( 1974 ) that the lexicon for the entire language be built , insofar as possible , along the lines of a spatial metaphor. We have not yet had to face these problems since our only scales are physical -our `` at '' and `` on '' are the locative `` at '' and `` on '' . Also checking this criterion presupposes a very sophisticated syntactic and semantic analysis. For example , [ d ) assumes that the times of events mentioned in tenseless constructions can be recovered. dominant entity of that description. This divides into two subcriteria : a , Those entities which are unique or dominant by virtue of the properties which describe them : `` the sun1 ' , `` the wind '' . If the properties p1 ( X ) , pZ ( X ) , ... , are known about the definite entity X , the definitions of p1 , p2 , ... , are probed for the fact that the entity does not normally occur in the plural. Included under this heading are proper names beginning with `` the '' , like `` the Empire State Buildingff , and appositives , like `` the city of Bos tonr ' . b. Those entities which are unique by virtue of the properties of an entity with which they are grammatically related : `` the door of the building '' , `` the Hudson River valley '' . `` The door of the buildingn is represented in the Text as `` xl 1 door ' ( ^^ , ^^ 1 building { X2 ) ) ' i.e. `` the Xl such that XI is the door of X2 which is a building '' . The uniqueness or dominance of XI is not a property of `` door '' but of `` building '' . Stored with `` building '' is the fact that a building has in its front surface a main door which does not normally occur in the plural. `` The door of the buildingr ' is interpreted as this dominant dosr. If the tvliqueness conditions succeed , a pointer is set from the dominant lexical variable to the corresponding entity. If subsequently the same definite noun phrase occurs , the uniqueness check will discover this pointer and correctly identify the antecedent. Thus , we can handle the example `` Walk up to the door of the building. Go through the door of the building. '' Here the uniqueness check gives us a shortcut around the next step in the algorithm. The Search for Plausible Antecedents. To illustrate the search for an antecedent , consider `` Walk out the door of this buil8ing. Turn right. Walk to the end of the block. `` What block ? From `` block '' We follow a back pointerto the fact stored with `` streetn *that `` streets consist of blocks '' , and from 34 `` street1 ' the fact with `` buildingt ' that `` Buildings are by streets '' Since a building is mentioned , we assume it is `` the block of the street the building is on '' . The facts in the chain of inference leading to this are instantiated , An entity is introduced into the text for the `` street '' and the Text is augmented by the statements that `` the building is on the street '' and `` the block is part of the street '' . This information turns out to be required for the map. Note that the Eact that a building is on a street is a sometimes fact and that we are free to d'raw it only because `` the blockn occurs* To conduct the search of the Lexicon , ideally we would like to send out a pulse from the word `` block '' which travels faster over more salient paths , and look for the first entity which the ptXlse reaches. The saliency is simulated by the cluster structure descrihea above , The parallel process of the spreading signal is simulated by interleafing deeper pfobes from salient clusters with shallower probes from less salient clusters. For example , if `` streets consist of blocks '' is a cluster 1 fact , then we might probe for a cluster 1 fact involving syreets and a cluster 2 Eact involving blocks at roughly the same time , After one plausible antecedent is found in this way , the search is continued for possible antecedents which are nearly as plausible. If after a time no plausible antecedents are found , the search is discontinued. Searches for antecedents are conducted not only for entities but also for definite noun phrases that the nominalization transformations of the syntactic component have turned into statements 35 -- e.g. `` The walk was tiring '' . Here we look back for a statement whose predicate is `` walk '' or from which a statement involving `` walkn can be inferred. There are cases in which the required inference is in fact a summary of an entire paragraph -- e.g. `` These actions surprised. , . `` -- although of course we can not handle these cases. Consistencv. Each of the plausible antecedents is checked for consistency. Suppose X1 is the definite entity which prompted the search and its properties are and</definiens>
				<definiens id="3">the proposed antecedent with properties We must cycle through the q 's and the r 's to ensure they are consistent properties. Of course , to prove two properties q ( X ) and r ( X ) inconsistent can be an indefinitely long process with no assurance of termination. One admittedly ad hoc way we get around this is by placing into a special cluster those facts we feel are likely to lead quickly to a contradiction. The second tool we use for deriving inconsistencies may turn out to be quite significant. In the course of processing , the lattice described abave is constructed for several predicates. They contain information which can be useful in deriving an inconsistency. Suppose we have a text in which `` the block '' occurs explicitly several times. Toward the end of it , we encounter `` Turn right onto Adarnii Street. The library fs at the end of the block '' . The search algorithm looks first for explicit mentions of `` blockl '' and finds them. Yet none of these entities is the one we want. Intuitively , the reason we know this is our almost visual feeling that we are already beyond those points. The lattice consistency check corresponds precisely to this feeling. If a definite entity X1 is a point or interval in a lattice or at a point or along an interval , we ask if the proposed antecedent X2 is or can be related to a portion of the lattice. If so , then since the lattice represents a transitive relation , we need only ask if there is a path in the lattice from X2 to XI. If there is , they can not be the same entity. Many cases which pass for applications of the supposed recency principle -- '' Pick the most recent plausible antecedentn-are in reality examples of this consistency check. The earlier plausible antecedent is rejected because of lattice considerations. As the text is processed , the whole structure of the discourse is built up. When a definite noun phrase is encountered , this discourse structure is known and it is this knowledge that is used to determine the antecedent rather than the linear ordering of the words on the page. Competition among Remaining Plausible Antecedents. Even after the consistency checks , several plausible antecedents may remain , forcing us to decide among them on less certain criteria. To do this , we appeal to the Principle of Knitting again and make the choice that will maximize the redundancy in the simplest possible way. A probe is sent out from the definite entity and from each plausible antecedent. Each plausible antecedent is searched for properties it has in comon with the definite entity. Common properties Count most if they are already in the Text , an8 within the Lexicon , comon properties count more if they are within more salient clusters or they result from shorter chains of inference. Default. Like the higher predicate algorithm , the definite noun phrase algorithm has a default feature. If the uniqueness conditions fail and the search turns up no antecedent , we simply introduce a new entity. In fact , in the directians texts there are a disproportionately large number of default cases , for `` the object '' may simply be the object you will see when you reach that point in following the directions. Other Anaphora. We have not yet implemented routines for handling other anaphora. However , we believe they are very similar to the definite noun phrase routine , with certain differences. For entities tagged with demonstrative articles , we do not check uniqueness conditions , and the search will be narrower since the antecedent must be an entity or statement actually occurring in the text. For pronouns also , no uniqueness conditions are checked. The search will turn up more consistent plausible antecedents , and a correspondingly greater burden will be placed on the competition routine. INTERSENTENTIAL CONNECTIVES We detect unstated inter-sentence connectives by matching two successive sentences S1 S2 with a small number of common 38 patterns. In the directions texts the patterns are usually few and simple. The most common are presupposed by S2. S1 asserts or presupposes a state which is the initial state of a change asserted by S2. ( These are likely very common patterns in all narratives , ) For example , in the text `` Walk out the door of this building. Turn right. Walk to the end of the black '' , pattern ( 1 ) joins the first two sentences , where the state is `` You at X '' , Pattern ( 2 ' ) joins the last two sentences , where again the state is `` You at X- '' . Note moreover that the sentences axe interlocked by n second application of the two patterns : The first sentence assumes an angular orientation which is the initial state of the change asserted in the second sentence. The final state of this change is assumed by the third sentence. In addition to providing the discourse with structure , this operation is one of the-princlipal means by which implied entities in one sentence , like X above , are identified with those in another. When pqttern ( 2 ) is applied , we delete the independent occurrence of the state in the Text , so that subsequently it exists only as one intermediate state ih a larger event. Changes across time are handled in this way. TASK PERF-ORMANCE COMPONENT Arbitrary Decisians , The semantic operations are quite 39 general and can be used for any application. The augmented and interrelated Text is then handed aver to the task performance component , which of course is specific to the application. Our task component first makes arbitrary decisions required by the map but not given in the text. Both natural language directions and sketched maps allow information to be incomplete and imprecise , but in different ways. Far example , in nTurn right at the third street or the second stoplight '' . we must decide whether to put the first stoplight at the first or second street , The lattice representing the path `` your ' take must be complete in the sense that it is continuous , begins at the initial location , and ends at the desired goal , and that the relative locations of all points on the path are known. The lattide is complete if and only if there is a directed path passing through every point in the lattice at least once. If it is not complete , it is completed by supplying the fewest possible new links. Gsometr-izing the Lattices. The second task operation is to convert the topological lattice representation into the geometric representation required by the maps. First we assign directions to all the points in the angular orientation lattice. In the simplest case we may have something like where `` a b '' means direction b results from a clockwise rotation of direction a. If no explicit directional information 4 ( 0 is present , we simply assume a , c , and e are the same direction , and b and d are the same , and then assume the two directions are at right angles , Then in the distance lattice , contiguous or overlapping paths which share the same orientation are assumed to be parts of the same path and are mapped into a straight line. Information about names is accessed and assigned to the streets and buildings and the map is drawn , Specific Systems with a General Semantic Component. We are aiming not so much at the construction of a general natural language processing system , which still seems reasonably far off but at an easier way of constructing specific systems. The case of syntax is instructive. It would be foolish for one who is building a natural language processing system to build his syntactic component from scratch. Large general grammars and parsers for them exist ( e.g. Grishman et al. 1973 , Sager &amp; Grishrnan 1975 ) . It is easier by several orders of magnitude to begin with a general grammar and specialize it , by weeding out the rules for constructions that do n't occur in the texts one is dealing with , and by adding a few rules for constructions and constraints peculiar to orre 's application. We are trying to make a similar facility available for the most common kinds of semantic processing. Specializing the general semantic component would consist of several relatively easy steps. First the Lexicon would be organized into a cluster structure appropriate to the task. At worst , this would mean specifying the necessary knowledge in a fairly simple format. If a very large Lexicon were available , this could mean no more than designating for each fact the cluster it should appear in. Certain inferences could be made obligatory while others which are irrelevant to the task could be left out of the special Lexicon altogether. Second a Task Component would be built which would take , as ours does , the semantically processed Text , and use it to perform the task. We are demonstrating the usefulness of this approach in performing a task involving a visual representation. It is likely to be useful in other sorts of tasks also. PERRY t. MILLER Massachusetts Institute of Technology Cambridge , Massachusetts 02139 ABSTRACT \Jheh a user interacts with a natural language system , he may well use words and expressions which were not anticipated by the system designers. This paper describes a system which can play TIC-TAC-TOE , and discuss the game while it is in progress. If the system encounters new words , new expressions , or inadvertent ungrammaticalities , it attempts to understand what was meant , through contextual inference , and by asking ihteliigent clarifying questions of the user. The system then records the meaning of any ne9 words or expressions , thus augmenting its 1inguist ; lic knowledge in the course of user interaction , A number of systems tire being developed which communicate with users in a natural language such as English. The ultimate purpose of such systems is to provide easy computer access to a technically Onsophisticated pepon. When such a person interacts with a natural language systemr , however , he is quite likely to use words and expressions which were not anticipated. To provide truly natural interaction , the system should be able to respond intelligently when this happens. Most current systems , such as those of Winograd [ lo ] and Woods Ill ] , are not designed to ; ope with such `` liiguistic input uncertainty. '' Their parsers fail completely if an input sentence does not use a specific , built-in syntax and vocabulary. At the other extreme , systems like ELIZB [ 93 and PARRY [ Z ] allow the user to type anything , but make no attempt to fully understand the sentence. The present work explores the tnlddle ground between these extremes : developing a sys.t ; em which has a great deal of knowledge about a particular subject area , and which can use this knowledge to make language interaction a flexible , adaptive , learning medium. In pursuing this goal , the present work is most closely related to work being dona in the various speech recognition efforts [ 5 , 7 , 8 , 121 which ara studying how linguistic and semantic constraints can help deal with the ACOUSTIC error and uncertainty of speech. The adaptive system , however , is designed to deal with a much mors LINGUISTIC type of uncertainty. When people use unfamiliar words or expressions in conversation , we can usually deduce from context what is meant , and if not , we can at least ask intelligent clarifying qu~stions. To allow the machine to do the same , there must be a very flexible interaction of syntax and $ emantics in the parsing/understanding process , There must be a different parser organization , and a more flexible use oP linguistic and semantic constraints , than is pfesen t in current natural language sys tern . The adaptive system is a step towards this goal Tha current implementation is a prototype , design'ed to illustrate many of these ideas , and to tie them together in a restricted system that is complete but not too complex. The system 's domain of discourse is TIC-TAC-TOE : it. plays a game and discusses the game in progress. It has a ( currently limited ) set of semantic concepts , and attempts to interpret the user 's sentences ih terms of these. The set of semantic concepts is FIXED. The system does not attempt to learn new concepts , merely new ways of describing concepts that are already familiar. When the system encounters a new word or a new phrasing , it uses contextual information to detername the possible meaning , and to ask clarifying questions which are as intelligent as possible. It then remembers the meaning of the new e &amp; pressfon , and will use it itselF *en it talks. The best way to introduce the system is to show it in operatian. In the sample session that follows , user input is pteced~rd by 'U : '' , machine output by and comments added by the author arg in small type , enclosed in brackets , ( HACHINE : I PLACE AM X IN TClE TOP LEFT SQUARE ) [ The machine makes its opening move. ] ( USER : PLAY A ZERO IN THE CENTER WARE ) ( H : 1s ZERO A NOW HEANING 0 ) ( U : YES ) ( H : OK ) [ The new word *zeroa is added to the machine 's vocabu1ary.l ( R : I PLACE AN X IN THE BOTTOM RIGHT WARE ) ( O : SLAP Ab4 0 IN THE BOTTOV ! LEFT CORNER ) ( PI : IS ( TO SLAP SOMETHING SOREWHERE ) A WAY OF SAYING ( 70 PLACE SOMEmING SOMEWHERE ) ) ( U : YES ) ( 19 : OK ) [ A new surface framer ( as described in section 4 ) Is added to the set sf surface braes which express the concept of making a move. ] ( m : 1 SLAP AN X IN TWE TOP RIGHT SQUARE ) f n this sample sassion , the machine uses its newly acquired vocabulary at every opportunity. ) HOU CORE YOU PLACED AN X IN THE TOP RIGHT SQUARE ) ( H : IS ( HOW CQHE MMEONE DOES SOHETHING ) AN EXPRESSION ISEANIMG ( l ! lOES SOMEONE 00 SQMETHING ) ) ( U : YES ) ( M : OR ) ( H : TO-BEAT YOU ) [ A new surface frme is added to those sxpssssing the concept ' I Syntactic featuras are associated with each such frauge indicating such things as Wether subject-verb invsrsion is ds be DerBomed.1 ( U : CAN YOU CURRENTLY BEAT ME ) m : 1s CURRENTLY AN ADVERB REFERRING TO THE TInE OF A RWE ) [ These are the only adverbs the system knows about. In fact , at present , the system ignores adverbs in its sewantic processing. I % asks the question because it wants to account for all the words in the sentence. ( U : YES ) ' ( M : OK ) ( 11 : YES ) ( M : r s WEST AN ADJECTIVE ~EANING EITHER ( 1 : CORNER ) ( 2 : LEFT ) ( U : 2 ) ( n : or ; ^ ( H : NO ) [ Notice that two top squares contain an x. However , only the left onel was played while the bottom right square was Free. Therefore the systcszn concluded that the top left square was being described. This example illustrates how contextual information can be used to ask as intelligent a cBarifying question as passibla. ] ( U : *yOW COME YOU PLACED AJ4 X IN THE TOP EAST SQUARE ) ( ! I : IS EAST AN l @ JECTLVE NEAWXNG ) EITHER ( 1 : RIGHT ) ( 2 : WEST ) ( 0 : lp ( U : on ) M IS ( TO LAY SONETHING SOHEWHERE ) A WAY OF SAYING ( TO SLAP SOflETHING S0UEWERE ) ) ( U : YES ) ( M : OK ) ( H : IS ( TO POLISH SOMEONE OFF ) A WAY OF SAYING ) E I THER ( 1 : ( TO BEAT SOMEONE ) ) ( 2 : ( TO LOSE TO SOMEONE ) ) ( 3 : ( TO TIE SOMEONE ) ) ( U : I ) ( ? '¶ : OK ) ( R : BY LAYING AN X ON WE TOP CENTER CELL ) [ If this same session were subsequently repeated , sf course , the system would not need to ask any questions of the ushJr. 1 There are a number of limrtations to the adaptive system as it now stands. Some of these may be apparent in the smple session , bud an introductian to the system is not complete without discussing them explicitly. ( 1 ) The number of concepts available to the system at present is very small. This , in fact , is why the system 's first guess is usually the correct one. If the sentence is at all within the systea 's comprehension , the options as to its meaning are currently quite limited. ( 2 ) The range of expressive devices presently recognized is quits limited as well. For instance , the system does not recognaze relative clauses , con junctions , or pronouns ( except for 1 and you ) . ( 3 ) The system currently deals only with TOTALLY UNFMILIAR words and expressions in this adaptive fashion , It will not correctly handle familiar words which are used in new ways ( such as a noun used eas a varb , as in wzero the center squaren ) . ( 4 ) The system tries to map the meaning of new wards and expressiuns into its specified set of underlying concepts. It then displays its hypotheses to the user , giving him only the option of saying yas or nu. The user cann-ot say `` no , not quite , it meahs . . . '' . ( Thus concepts like Vhe 'northeast1 square '' or `` the 'topmost ' squarew would ba confusing and not correctly understood. ) The present simple system has been developed with two goals in mind : ( 1 ) to explore the techniques required to achieve adaptive behavior , and ( 2 ) to help fornulate the issues which will have to be faced when incorporating these techniques into a much broader natural language system. Fig. 1 shows ths various stages that the Adaptive System gees through in understanding a sentence. In this sectian , we shall watch while the system processes the sentence `` Mow came you placed an x in the top right ~quare.~ ( 1 ) Local Syntactic Processing : In this first stage , the system scans the entire sentence looking for local constituents. These include Hsimplem noun phrases ( NPs ) and prepositional phrases ( PPs ) , ( `` simplen meaning 'up to the head noun but not including any modifying clauses or phrases '' ) , and verb groups ( VGs ) consisting of verbs together with any adjoining rnodals , auxilliaries , and adverbs. In this instance , the system Finds the two NPs , `` youe and `` an xm , the PP `` in the top right squarem , and the VG nplacedw. ( 2 ) Semantic Clustering : At this stage , the clause-level processing starts. Unlike most systems , this clause-level processing is driven by SEMANTIC rslationshigs , rath-er than by syntactic form. It uses a semantics-first kclustssinsg* , with a sscondary use of syntax for cormnents and confirmation+ In this example , all the local constituents found can be clustered into s description of e single concept : that of making a nave , Section 4 describes the mechanics of this stage in more detail. ( 3 ) Cluster Expansion and Connection : During this stage an attempt Is mada to account Psr each word in the sentence by expanding the concept clusters , and if there is more thaw one , by joining them together to form an entire multicXausa1 sentenceIn this case , ths concept cluster rnlght bs axpanded In two ways. a ) One possiblllty night be that It is a `` MOW '' type question , and that wcornc.tn is some sort of adverb , However this possibility violatsf a semantic constraiet , since the system is not set up to answer haw a move is made ; only how to win , how to prevent sorneons From winning , etc. Therefore this possibility is ignored. b ) The other possibility f r ; that `` how come '' is a new way of describing soma other clause funetton. ( 4 ) Contextual Inference ; Clarification ; and</definiens>
				<definiens id="4">During this final staga , any contextual inf~rrnatfsn available is brought to bear on araas of uncertainty , any necessary clarifying questions are asked , and the system responds to the sentencs. In this example , the only uncertainty is the meaning of `` how comew. Since this is the main sentence 1 Xocal constituents concept clusters complete sentence hypothesf s system responds to sentence Fig. 1 : Adaptive System Overview clause of the sentence , the possibility of its being an Wn or *aftsra clause are discarded. The remaining possibilities are nimperativsw , `` hown , m~hyn , and `` canw. The system does not answer % own and `` canw quest ions in relation to making moves. Similarly , `` imperativen does not make sense since the action described is a previously made move. Therefore the system asks if `` How come someone does somethingw means Vhy does someone do somethingn. The user answers `` yesn , so the system stores this new way of asking `` whyn , and proceeds to answer the question. One of the major differences between this approach to parsing and that of a top-down , syntax-driven system ( such as Moods ' or Winograd 's ) is the order in which syntactic and semantic processing is done at the clause level. In a top-dom system , a sentence must exactly match the built-in syntax before semantics can even be called and given the various constituents of a clause , This IS clearly undesirable when one is dealing with input uncertainty , since one can not be sure exactly how the user will phrase his sentence. One would prefer to Bet semantics opera % @ First on any local consituents present , so that it can make a reasonable grgss as to what is being discussed. As semantically-rslated clusters of local constf tuents are found , syntax can be consulted and asked to comment. on the rslative grmmaticality of the various clusters. If there are two competing semantlc inte~pretations of one part of a sentence , and syntax likes one much better than the other , then the `` syntactically pleasing '' interpretation can be pursued first. Later , if this does not pan out , the syntactically irregular possibility can be looked at as wsP1. In this way , syntax can help guide the system , but is not placed in a totally controlling position. A by-product advantage of this semantics-first approach is that the system can handle mildly ungrammatical input without any extra work , In addition , the semantics-first clustaring approach lends itself quite naturally to handling sentence fragments. In the remainder of thks section , we describe how the adaptive system organizes ids linguistic knowledge to implement this semanticsfirst approach. As we shall see , there are three componeflts of this knowledge. ( a ) Ths local racognizars which initially find local constituents. recognizers are represented tn Augmented Transition Network [ Ill fom , are quits simple , and are not described further in this paper. ( b ) Clause-level knowledge sf how actions and clause-functions are described. This knowledge is expressed in a descriptiva fashion which makes it msily manipulabla , and easy to add to. ( c ) Clause-level syntactic knowladge which is sxprssred ira a domainindebpendent fom. Figure 2 illustrates how the system stores its knowledge sf how actions ( or events ) are described. This knowledge is stored at two levels : the conceptual level , and the surface ( or expressive ) level As shown in Fig. 2 , the concept PLACE represents the act of making a TIC-TAC-TOE wove. ( a ) On the CONCEPTUAL level , there are three `` conceptual slots ' indicating the actors which are involved in the actlon : a player , a @ ark , and a square. ( b ) On the SURFACE , or expressive , level there is a list sf surface frames each indicating one possible way that the concept can be expressed. Each surface frame conslsts of a verb plus a set of syntactis case frames to be filled by the actors. ( Notice that neither the conceptual slots nar the surface frames indicate explicitly the order in which the varlous constituents are to appear Fw a sentence. ) When the system processes a sentence , it fills the concsptual shots with local constituents found rn the sentence If it has found a fmiliar verb , then it also gets any surface e ( s ) associated with that verb. At this point it calls syntax , asking for csments. For instance , if the input sentence is `` 1 place an x in the corner '' , then all the conceptual slots of # PLACE would be filled , and the system would pass the following string to syntax wagen % verb obj ppw . As a result , clause-level syntax does not see the actual constituents of the sentence , only the labels specifled In the surface case frame , plus information indicating number , tense , etc . An interesting aspect of this approach is that the clause-level syntax is entirely domain-independent. It knows no thing about TIC-TACTOE , or even about the words used to talk about TIC-TAC-TOE. Tke surface frames allow semantics to talk to syntax purely in terms of syntactic labels. As a result , one could write a single syntactic module , and than insert it unchanged into many domains. In this section , we describe in more detail how this knowledge can be used when processing a sentence. ( 1 ) If the verb and constituents are familiar : If there is no uncertainty in a clause , then each constituent can be put into one of Ghe conceptual slots , and any surface frames associated with the verb can be examined The frame ~ndicates the csse ( agent , object , etc. ) associated with each constituent whon that verb is used. The frame is used ta create a string of case labels that are sent to syntax for coments. For instance , iF the sentence is `` 1 place an x in the center CONCEPT : PLACE CONCEPTUAL SLOTS : P : player H : mark S : square SURFACE FRAMES : VERB : place ( as in : AGENT : P mI place an x in the centera ) OW : PI in : S VERB : play ( as in : AGENT : P sf play an x in the centers ) ow : H In : S VERB : play ( as in : AGENT : P wX play the center '' ) 00J : S FLg . 2 : Linguistic KnowleMge about Actions square '' , the string passed to syntax is `` agent verb obj pp '' . Syntax replies that the sentence follows normal order. Had the string been `` verb obj pp '' syntax would reply that the subject had been deleted. If the string was @ 'do agent verb obj ppn , syntax would reply that subjectverb inversion had taken place. Given `` gent obj verb ppn , syntax would reply that the object was out of position. Thus syntax is set up to notice both g~irnmcatical and ungrmatf cal permutations in constituent order , and to comment appropriately. The system must then decide how to interpret these comments. For instance , if syntax replies that the object is out of position in the clause , or that there is incorrect agreement in number between subject and verb , the system may decide that the user has made a minor grammatical error , and allow the sentence to be processed anyway , especially if there is no better interpretation of the sentence. In this way , clause-level syntax plays an assisting role rather than a castrolling role in the analysis of a sentence. ( 2 ) If a constituent is unknown : If an unknown constituent is present , then both the frame and slot information can be used to help resolve its meaning. For instance , suppose the sentence is `` I place a cross in the canter squarew , and the , word ~crossu is unfamiliar , Here , during the semantic clustering , the conceptual slots for a player and a square can bs filled by `` Iu and `` in the center square '' , but the slot for a mark is unfilled. In additiq , there is the unknown constituent `` a crossg. A natural hypothesis , therefore , is that the unknown constituent refers to a type of mark. Since the verb is familia~ , a surface frme is avaflable. Next , assumtag the unknown constituent is a mark , the string `` agent verb obj ppw can be passed to syntax. Men syntax approves , this offers additional confirmation that the hypothesis is probably right. Subsequent evaluation of this hypothesis indicates that the sentence makes sense only if the mark referred to is Etn x , so the system asks if `` crossu is a noun meaning ( 3 ) If the verb is unknown : If an unfamiliar verb is used , then there is no surface fsme availabls to help guide the analysis. Instead , syntax must ba used in a different mode to propose what the surface frame should be. Suppose the sentence is `` I plunk an x in the center squareM. Here , all the constituants can be clustered into the concept # PLACE , but</definiens>
				<definiens id="5">an unknown word , and no verb. Ths loglcrrl hypothasis is that the new word is a verb. A special syntactic module is therefore passad the followfag string `` NP ( P ) verb ( p1unk ) NP ( M ) PP ( in , S ) # This module examines the string and produces tn new Frame : VERB : plunk AGENT : P OW : R in : 8 The system can then ask if `` to plunk something somewherew means `` to place something somewheren , and upon getting an affirmative reply , can add the new frame to those associated with the concept PLACE. Since the system uses the surface frames to generate its om replies , it can now-use this new frame itself when it talks. When the system wants to generate a clause , it passes a selected frame , the constituents , and a list of syntactic features to a clause generator which outputs the specified form. ( Thus , clauss-level syntax can be used by the system in three different modes : ( 1 ) to comment on the grmaticality of a string of case markers , ( 2 ) to constrbct a new surface frame , and ( 3 ) to generate clauscas when tha system itself replies. ) As illustrated in Fig. 3 , knowledge of how clause-function concepts are described is also expressed as two Lexals. CONCEPT : # WHY CONCEPTUAL SLOTS : ACTION : # PLACE SURFACE F Why ACTIQN ( SV1NV ) ( as in : *Why does someone do somsthkng '' ) flow come ACTION ( ) ( as in : `` Now come someone does something '' ) Fig. 3 : Linguistic howl edge about Clause Functions Each clause function has a conceptual slot indicating what types of action can be used with that clause type ( in this case , the action # PLACE ) , and a list of surface frames indicating different ways in which the cancspt can be expressed. A clause-type frame currently includes any special words which introduce the clause ( ie. `` whyn or `` how comen ) , together with a list sf syntactic proparties which should be present in the clauss. This list of syntactic properties might include SVIMV , nsubjec $ -verb inversionw ( as in `` why does someone do something '' ) , ar 9ub ject deletionH , 'ING fomm , and `` use of a particular preposition* ( as in `` from doing somethingw ) . These syntactic features , however , need not bs inflexible rules. Sentence understanding can still psocaed wen if tha syntactic features found by syntax do not exactly match those specified by the clausefunction frame. Thus , an inadvertent ungrammaticality cam readily be recognized as such , and processing can continue. In this section we examine how this clause function knowledge can be used. ( 1 ) With no uncertainty : If the input sentence is `` Why dld you place an x in the center squarew , then during the semantic clustering the string Rdo agent verb obj ppu is passed to syntax , which replies that subject-verb inversion has taken place. When exarninlng the whole clause , the system sees that it exactly matches one of the surface frames for a # WHY-type question , since it starts with the word n~hyVind contams subject-verb inverslbon , Suppose , however , the sentence had been `` Why you place an x IR the center squaren , or `` How come did you place an x in the center square*. Each of these sentences matches a surface frame for a MY-type question , except that in both cases subject-verb inversion is incorrect. In such a case , the system can , if it chooses , decide that the user has made a minor error , and allow the sentence to be processed anway. The locally-driven semantics-first approach Lets this happen in a natural way. ( 2 ) A new surface frame : Another problem arises when a new clause introducer is encountered , as in : `` Wherefore did you place an x in the center squareM. Here , as described in section 3 , the system hypothesizes that this may be a new way of asking a # WHY-type question. Since syntax reports that subject-verb inversion has taken place , the system can therefore create a new surface frame : Wherefore ACTIOM ( SV1NV ) to be added to the frames associated with # WHY. B In summary , the adaptive -5ys tern stores its linguistic knowledge in a very accessible form. It is not embedded in the parsing logic. howledge of how actions and clause-functions are described is represented in a descriptive , manipulable format. Syntax is domain independent , and is used only to make cornants , with semantics playing the guiding role. This organization allows the parsinglunderstanding process to proceed kn a flexible fashion , Language communication is an inherently adaptive medium. One sees this clearly ~f one takes a problem to a lawyer and spends time trying to assimilate the related `` legalesen. One also sees it in any conversation where a persron is trying to convey a complicated idea , expressed in his own mental terms , to someone else. The listener must try to relate the words he Rears to his own set of concepts. Language has , presumably , evolved to facilitate this sort of interaction. Therefore it is reasonable to expect that a good deal of the structure of language is in some sense set up to assist in this adaptive process. By the same token , studying language from an adaptive standpoint should provide a fresh perspective on how the various levsls of linguistic structure interact. 1575 ACL Mcetlng CONCEPTUAL GRAMMAR WILLIAM A , MARTIN Kassachusetts Insti tute of Tech~ology In OWL , an implementation of conceptual grammar , the two types of data items are symbols and concepts and the two basic data composition operations are specialization and</definiens>
				<definiens id="6">an alphanumeric string headed by `` . Symbols correspond to words , suffixes , prefixes , and word stens in Znglish and the programer can introduce them at willm OWL concepts correspond to the meanings of EEglish words and phrases. They are constructed using the specialization operation , comparable to CONS in LISP* ( A B ) is the specialization of A , a concept , by B , a concept or symbol. OWL form a branching tree under specialization , with SOMETHING at the top. Concepts are given properties by restriction , which puts a concept on the reference list of another concept ( compare property lists and S-expressions in LISP ) . A/B is the restriction of A by B. The categories in the specialization tree are semantic , but we use them also for the purposes usually assigned to syntactic dategories. A predication is a double specification of 2 model such as present tense or can. Examples are The pool is full of water. ( ( PRES-TNS ( BE ( FULL 94TER ) ) J POOL/THE ) The cookie can be in the jaf. ( ( CAN ( BE ( IN JAR/TIIE ) ) ) COOKIE/THE ) aob is the father of Sam. ( ( PRES -TKS ( BE ( FATHE : SAM ) ITHE ) ) BOB ) 3ob hits the ball. ( ( PRES-TNS ( HIT BALLITHE ) ) Boa ) Bob is hitting the ball. ( ( PRES-TNS ( BE ( -ING ( HIT BALL/THE ) ) ) ) BOB ) Starting from this base we will discuss a number of issues buch as n~minalization incorporation , and deep vs surface cases. American Journal of Computational Linguistics ~icroffche 32 : 58 JOHN F. BURGER , ANTONIO LEAL , AND ARIE SHOSHANI System Development Corporation Santa Monica , California 90406 mcT We describe a natural-language recognition system having both applied and theoretical relevance. At the applications level , the prwram will give a natural ccmmunications interface facility to users of existing interactive data management systems. At the theoretical level , our work shows that the useful infoxmation in a natural-language expression ( its `` meaning '' ) can be obtained by an algorithm that uses no formal description of synt-. The construction of the parsing tree is controlled primarily by semantics in the form of an abstraction of the nmicxo-world '' of the DMS 's functional capabilities and the organizat~on and semantic relations of the data base content material. A prototype is currently implemented in LTSP 1.5 on tho IBM 370/145 computsr at System Development Corporation. In a recent article in Scientific , American , Dr. Alphonse Chapanis says , `` Tf truly interactive computer ( ; ystm are ever to be created , they will ~omehow have to cope with the ... errors and violations of format that are the rule rather than the exception in normal human ccmmunication '' [ 1 ] . An example dialogue produced by twa persons interacting with each other by teletypewriter to solve a problem as~igned to them by experimenters showed that : not one grernaaatfcally correct sentence appears in the entire protocol. tl Many existing language pmcessors ( woods , Kellogg , Thcmpson , etc. ) [ 2,3,4 ) are limited to what Chapanis calls `` Irmnaculate prose , '' that is , `` the sentences that are fed into the computer are parsed in one way or another so that the meaning of the ensemble can be inferred frm conventional rules of syntax , '' which are a £0description of the language. In effect , users are required to interact with these system in sme formal language , or at least in a language that has a formal representation in the computer system that a user 's expression must conform to ( we are thinking , in the latter instance , of Vhampsonls REL , which has an extensible formal representation facility ) . In addition , most natural-language question-answering systems , including all referenced above , require that a user 's data be restruct-wedl and reorganized acwraing to the particular data base requirements of the natural-language system to be used. At the level of artificial intelligence research [ ti ,6 , ?</definiens>
			</definition>
			<definition id="4">
				<sentence>Global subdivision of PHLIQA 1 , The interface between the Question understanding component and the Answer Computation component 1s a formal language , called the World Model Language ( WML ) .</sentence>
				<definiendum id="0">World Model Language ( WML</definiendum>
				<definiens id="0">Question understanding component and the Answer Computation component 1s a formal language , called the</definiens>
			</definition>
			<definition id="5">
				<sentence>The Data Base Language ( DBL ) , which contains conatants that correspond to data base primitives .</sentence>
				<definiendum id="0">Data Base Language ( DBL )</definiendum>
				<definiens id="0">contains conatants that correspond to data base primitives</definiens>
			</definition>
			<definition id="6">
				<sentence>A syntact'ic construction is an unordered collection of labeled branches , departing from one node .</sentence>
				<definiendum id="0">syntact'ic construction</definiendum>
				<definiens id="0">an unordered collection of labeled branches , departing from one node</definiens>
			</definition>
			<definition id="7">
				<sentence>The syntactic rule for the construction function application t ' could state that the emreasion is well -formed if T is a well-formed expre~lsion of type and T is a 2 1 well formed expression of type 6 -+ /3 , where oC and may be any type ; the whole expression then has the type P The PHLIQA languages contaln a wide variety of syntactic constructions , e , g. constructions for different kinds of quantification , for selecting elements from a list , for reordering a list , etc , The PaIQA language8 have a formal semantics which recursively defines the values of the expressions , This definition assumes as primitive nations the denotatian~ of the conetants of the language : function constants denote procedures , and the other canstants denoh value expressions , This means that if we know the denotations of the constants occurring in an expreesion , the value of the expression fs defined by the semantic rules of the language , For tb Data Base Language , we indeed know the denotations of the constants ; what we call the data base is nothing but the implementation of the `` primitive procedure8 `` , t e. : the procedures corresponding to DBL functions , and the procedures for finding the value expres~ions of the other DBL constants .</sentence>
				<definiendum id="0">syntactic rule for the construction function</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">a well-formed expre~lsion of type</definiens>
				<definiens id="1">a 2 1 well formed expression of type 6 -+ /3 , where oC and may be any type</definiens>
				<definiens id="2">contaln a wide variety of syntactic constructions , e , g. constructions for different kinds of quantification , for selecting elements from a list , for reordering a list , etc , The PaIQA language8 have a formal semantics which recursively defines the values of the expressions , This definition assumes as primitive nations the denotatian~ of the conetants of the language : function constants denote procedures , and the other canstants denoh value expressions</definiens>
			</definition>
			<definition id="8">
				<sentence>The construction of the semantic deep structure in EFL consists of three main phanes r phase 1 : a lexicon , providing for each word one or more interpretations , represented by pairs ( CATi , SEM \ , where CAT Is a syntactic category i i and SEM an EFL expression .</sentence>
				<definiendum id="0">SEM</definiendum>
				<definiens id="0">a lexicon , providing for each word one or more interpretations , represented by pairs ( CATi , SEM \ , where CAT Is a syntactic category i i and</definiens>
			</definition>
			<definition id="9">
				<sentence>i phase 2 : a set of rules that enables to combine the sequence of pairs ( CAT SEM1 ) , it corresponding to the original sequence of words , into higher level categories and more complex structures , until we have ultimately the pair ( SENTENCE , SEM ) , S where SEM is the EFL expression for the bomplete sentence .</sentence>
				<definiendum id="0">SEM</definiendum>
				<definiens id="0">a set of rules that enables to combine the sequence of pairs</definiens>
				<definiens id="1">the EFL expression for the bomplete sentence</definiens>
			</definition>
			<definition id="10">
				<sentence>A transformation specifies the subject of the use-situation as Shell ' .</sentence>
				<definiendum id="0">transformation</definiendum>
				<definiens id="0">specifies the subject of the use-situation as Shell '</definiens>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>A more satisfactory method wquld be for the PGT to produce a set of derivations such that any tine an optional rule can apply , the PGT produces a derivation for the case where the .</sentence>
				<definiendum id="0">PGT</definiendum>
				<definiens id="0">produces a derivation for the case where the</definiens>
			</definition>
</paper>

		<paper id="1076">
			<definition id="0">
				<sentence>In ahother sentence-memory experiment ( predict ion ( 3 ) ) semantically complex verbs that provided more unde~lying ~dterconnections between the nouns in a sentence led to bettdr memory fof the nouns in the sentence than simple general verbs , or than gther complex verbs that did not provide such extra interconnections .</sentence>
				<definiendum id="0">sentence-memory experiment</definiendum>
				<definiens id="0">the nouns in a sentence led to bettdr memory fof the nouns in the sentence than simple general verbs , or than gther complex verbs that did not provide such extra interconnections</definiens>
			</definition>
			<definition id="1">
				<sentence>s ; ors '' ( CAPP 's ) by Foster Such mach~ner arc qul te po~ er ful B ) ' ~II ( C~H caving rtbcugwit~on 'ind multi-\+ r itc ~pc'r~itions , w~th appropriate use of bit-rndqhit~g , a CAPP is ahle to ric-hicte speeds , flcr ; lbi11 t y , d11d pr~r~ril~t~rning easc well beyond t hc rlinze uf CL en .</sentence>
				<definiendum id="0">CAPP</definiendum>
				<definiens id="0">ahle to ric-hicte speeds , flcr ; lbi11 t y</definiens>
			</definition>
			<definition id="2">
				<sentence>The RE14 board converts it to the desired REM action For a recognize , the data written on the data bus by the CPU is a cornparand the Ctem to be recognized .</sentence>
				<definiendum id="0">CPU</definiendum>
				<definiens id="0">a cornparand the Ctem to be recognized</definiens>
			</definition>
			<definition id="3">
				<sentence>es for the £01 easier , complex lowing SEMIO1lICS has mitt REM operations , inc ( all of which operat en a package luding such e in paralle all REM records ) : Identify all records which have a specified character sequence Identify all records with zero ( or all 1 's ) in specified byte position .</sentence>
				<definiendum id="0">inc</definiendum>
				<definiens id="0">all of which operat en a package luding such e in paralle all REM records ) : Identify all records which have a specified character sequence Identify all records with zero ( or all 1 's ) in specified byte position</definiens>
			</definition>
			<definition id="4">
				<sentence>r ; -+ : &gt; -rl ) Ainerican Journal of Computational Linguistics Microfiche 76 : 54 from Micro Divcrslons RoheAs Information Scnices , Inc. ( ROBINS ) Fairfax , Virklnt~ 22030 Phortc ( '03 ) SW '8438 SCREENSYLITTZR is a complete text-oriented TV display system for S-100 cojnpatible hobbyist , small business and OEM microcomputer s st , eas , , SCREENSPLITTER represents a significant advance over ot er TV text display systems in three important respects : h * The q~antity of displayed text is large .</sentence>
				<definiendum id="0">SCREENSPLITTER</definiendum>
				<definiens id="0">a complete text-oriented TV display system for S-100 cojnpatible hobbyist , small business and OEM microcomputer s st , eas , ,</definiens>
				<definiens id="1">a significant advance over ot er TV text display systems in three important respects : h * The q~antity of displayed text is large</definiens>
			</definition>
			<definition id="5">
				<sentence>INIT ( ch ) -Tpears the entire display buffer .</sentence>
				<definiendum id="0">INIT ( ch ) -Tpears</definiendum>
				<definiens id="0">the entire display buffer</definiens>
			</definition>
			<definition id="6">
				<sentence>CLEAR ( ud b ) mars the window and resets the cursor to the top left , FRAME ( wdb , hc , vc , cc ) Tzrres the Mlndow , uging HC for the top an8 bottom borders , VC for the left and right borders and CC for the-four corners ; reduces tne window 's interior region by two characters in each dimension , and clears the winaow .</sentence>
				<definiendum id="0">VC</definiendum>
				<definiens id="0">the-four corners ; reduces tne window 's interior region by two characters in each dimension , and clears the winaow</definiens>
			</definition>
			<definition id="7">
				<sentence>CURSORCH ( wdb , ch ) ~efices CH to be the window 's cursor character ; autoaatically cosp1eir ; ents CH ~f window 's flgure/ground is reversdd .</sentence>
				<definiendum id="0">CURSORCH</definiendum>
			</definition>
			<definition id="8">
				<sentence>Space coristra~nts prevent a dct ailccl cic~cription of the interactions lead~ng to the entry of this term into the dictionary , but the follnw~ng is a trace of the process : &gt; create Term : bondLanguage : en Field Classl 1 lcat Ion !</sentence>
				<definiendum id="0">Space coristra~nts</definiendum>
				<definiens id="0">a trace of the process : &gt; create Term</definiens>
			</definition>
</paper>

		<paper id="1045">
			<definition id="0">
				<sentence>Since SPARSER was implemented as part of a speech understanding system called SPEECHLIS which is under development at Bolt beranek and Newman Inc. , that system is briefly described hare and is further documeatad in [ 3 , 4 , 5 , 6 , 15 , 23 , 24 , 26 , 33 9 351 .</sentence>
				<definiendum id="0">SPEECHLIS</definiendum>
				<definiens id="0">implemented as part of a speech understanding system called</definiens>
			</definition>
			<definition id="1">
				<sentence>The semantic component uses a semantic network to associate semantically related words and to judge the meaningfulness of a hypothesized interpretation ( See Nash-Wabber [ 15 ] ) .</sentence>
				<definiendum id="0">semantic component</definiendum>
			</definition>
			<definition id="2">
				<sentence>SPARSER selects a subset of the set of active co'nfi~urations ( how this subset is selected will be discussed in the next section ) and for each configuration tries to extend it by tryin8 to parse the rest of the island beginning in that confipuration .</sentence>
				<definiendum id="0">SPARSER</definiendum>
				<definiens id="0">selects a subset of the set of active co'nfi~urations</definiens>
			</definition>
			<definition id="3">
				<sentence>Whether just one transition , or several , or all possible transitions are made from an active Page 26 conf , iguration is a matter to be discussed in Section Five .</sentence>
				<definiendum id="0">iguration</definiendum>
			</definition>
			<definition id="4">
				<sentence>CAT and WRD arcs cause the prediction of syntactic categories and specific words , respectively , modified by the Context-free test on the arc .</sentence>
				<definiendum id="0">WRD arcs</definiendum>
				<definiens id="0">modified by the Context-free test on the arc</definiens>
			</definition>
			<definition id="5">
				<sentence>Concretely , an event is a piece of data consistina of : 1 ) the old theory that proposed or set a monitor far the event 2 ) something to be added to the theory ( a new ward natch or constituent ) 4 ) the arc in the Rramnar which will process the new information 4 ) the corifipuration ih the old tbrory which will be at one end of the transition created by the above arc When SPARSER is ~iven an event , it retrieves from its tables the bundle of configurations , transit ion , etc. in the old theory .</sentence>
				<definiendum id="0">event</definiendum>
				<definiendum id="1">SPARSER</definiendum>
				<definiens id="0">a piece of data consistina of : 1 ) the old theory that proposed or set a monitor far the event 2 ) something to be added to the theory ( a new ward natch or constituent ) 4 ) the arc in the Rramnar which will process the new information 4 ) the corifipuration ih the old tbrory which will be at one end of the transition created by the above arc When</definiens>
			</definition>
			<definition id="6">
				<sentence>SPARSER handles the problem by assigning a score &amp; o every configuration which reflects the likelihood of the path which terminates on that confi~uration to be correct .</sentence>
				<definiendum id="0">SPARSER</definiendum>
				<definiens id="0">reflects the likelihood of the path which terminates on that confi~uration to be correct</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , upon encountarinr an arc such as ( PUSH NP/ ( ( NPSTART ) T T ) ... ) the look-ahead function NPSTART returns a high integer valua ir the next word is a noun and a lowen valua if it is a verb ( e.g. ltaccounting coststt ) .</sentence>
				<definiendum id="0">NPSTART</definiendum>
				<definiens id="0">PUSH NP/ ( ( NPSTART ) T T ) ... ) the look-ahead function</definiens>
			</definition>
			<definition id="8">
				<sentence>Scores range from 0 to 95 for proposals , 0 to 40 for notices , and 0 to 15 for monitors .</sentence>
				<definiendum id="0">Scores</definiendum>
				<definiens id="0">range from 0 to 95 for proposals , 0 to 40 for notices , and 0 to 15 for monitors</definiens>
			</definition>
			<definition id="9">
				<sentence>SELECTED CONFIGS ( 5 ) FOR EXTENSION PICKING UP CONFIG 5 : NPRU:3 ( 16 ) STARTING AT 3 : MONITORING [ QUANT/ ] SETTING UP CONFIG 6 : QUANT/ : 3 ( 16 ) ( Hare all the words which can start quantifiers , like `` a hundredw or `` point fivam , ard proposed .</sentence>
				<definiendum id="0">Hare</definiendum>
				<definiens id="0">all the words which can start quantifiers</definiens>
			</definition>
			<definition id="10">
				<sentence>J STARTING AT 3 : MONITORING R/ PP/ R/NIL 1 SETTING UP CONFIG 11 : R/:3 ( 29 ) { MONITORING lPREP WHOSE WHO WHICH THAT WHOM ] } ( PROPOSING LYHOSE1l lfWHOw 'WHICH '' `` THAT '' `` WHOM '' ] SETTING UP CONFIG 12 : PP/:3 ( 29 ) MONITORING [ PREP 1 SETTING UP CONFIG 13 : R/NIL : 3 ( 29 ) MONITORING [ THERE ] PROPOSING `` THERE '' TRYING POP ARC POP TRANS 88 FROM 10 : NP/HEAD:3 ( 29 ) EXECUTING PATH ( 3 5 6 7 8 ) BEGINNING AT TRANS 3 , CONFIG 3 DOING CAT ARC WITH WHQ FROM 3 : NP/ TO 5 : NPRD DOING JUMP ARC FROM 5 : NPRD TO 7 : NP/QUANT DOING JUMP ARC FROM 7 : NP/QUANT TO 8 : NP/DET DOING JUMP ARC FROM 8 : NP/DET TO 10 : NP/HEAD TEST FAILED { A question-determiner alone can not bs a complete noun phrase ; although this is permitted by considering `` whatw as a QWORD as in tranaition # 2 . )</sentence>
				<definiendum id="0">NP/QUANT DOING JUMP</definiendum>
				<definiens id="0">NP/DET TO 10 : NP/HEAD TEST FAILED { A question-determiner alone can not bs a complete noun phrase</definiens>
			</definition>
			<definition id="11">
				<sentence>`` 1 PREDICTIONS : NOTICING ( 4 FEE 19 23 155 Q ) , SCORE -5 NOTICING ( 9 THE 4 6 103 01 , SCORE 0 PROPOSING ( ONLY WHOSE ) ENDING AT 6 PROPOSING ( ZERO NO POINT A WHOSE WHO WHICH THAT WHOM THERE ) STARTING AT 3 { MONITORING [ PREP ] STARTING AT 19 , SCORE 0 MONITORING [ WHOSE WHO WHICH THAT WHOM THERE ] STARTING AT 19 , SCORE 5 MONITORING [ ADJ N V ORD QDET ART QUANT POSS ] ENDING AT 6 , SCORE 0 MONITORINC [ WHOSE ONLY ] ENDING AT 6 , SCORE 5 MONITORINC [ MODAL V INTEGER NPR N ADJ V ADV PREP ] STARTING AT 3 , SCORE 0 MONITORING [ WHOSE WHO WHICH THAT WHO11 THERE ZERO NO POINT A ] STARTING AT 3 , SCORE 5 ) PROPOSING ( V N ADJ ) FROM 3 TO 6 { Proposals were made to fill the gap because there were monitors from both sides of a pap small enoush to contain one word . )</sentence>
				<definiendum id="0">SCORE -5 NOTICING</definiendum>
				<definiens id="0">STARTING AT 19 , SCORE 0 MONITORING [ WHOSE WHO WHICH THAT WHOM THERE ] STARTING AT 19 , SCORE 5 MONITORING [ ADJ N V ORD QDET ART QUANT POSS ] ENDING AT 6 , SCORE 0 MONITORINC [ WHOSE ONLY ] ENDING AT 6 , SCORE 5 MONITORINC [ MODAL V INTEGER NPR N ADJ V ADV PREP ] STARTING AT 3 , SCORE 0 MONITORING [ WHOSE WHO WHICH THAT WHO11</definiens>
			</definition>
			<definition id="12">
				<sentence>NO SEMANTICS FOR HEAD { This is a comment from the sarnantic component indicating that it can not currently interpret the construction . )</sentence>
				<definiendum id="0">SEMANTICS FOR HEAD { This</definiendum>
				<definiens id="0">a comment from the sarnantic component indicating that it can not currently interpret the construction</definiens>
			</definition>
			<definition id="13">
				<sentence>SPARSER PROCESSING THEORY 2 : STARTING AN ISLAND STARTING AT LEFT END OF SENTENCE SELECTED CONFIGS ( 1 ) FOR EXTENSION { Upon picking up this configuration to extend it , SPARSER finds thd transitions which were created durin~ the processing of the word I1whatfr by tha previous theory .</sentence>
				<definiendum id="0">I1whatfr</definiendum>
				<definiens id="0">STARTING AN ISLAND STARTING AT LEFT END OF SENTENCE SELECTED CONFIGS ( 1 ) FOR EXTENSION { Upon picking up this configuration to extend it , SPARSER finds thd transitions which were created durin~ the processing of the word</definiens>
			</definition>
			<definition id="14">
				<sentence>( 7 ) SELECTED CONFIGS ( 35 37 39 44 48 ) FOR EXTENSION PICKING UP CONFIG 35 : TO/:19 ( 7 ) STARTING AT 19 : MONITORING [ NEG 1 MONITORING [ TO 3 PROPOSING If TOtf ALL ARCS TRIED AT THIS CONFIG PICKING UP CONFIG 37 : PP/NP:19 ( 7 ) TRYING POP ARC POP TRANS # 45 FROM 37 : PP/NP:19 ( 7 ) PICKING UP CONFIG 39 : S/NP:19 ( 7 ) STARTING AT 19 : MONITORING [ MODAL 1 MONITORING [ V 1 TRYING POP ARC POP TRANS # 46 FROM 39 : S/NP:19 ( 7 ) EXECUTING PATH ( 32 31 46 ) BEGINNING AT TRANS 32 , CONFIG 42 **** MADE $ 3 FROM 4 TO 19 : S NPU NP DET ART THE N REGISTRATION FEATS NU SG WITH FEATURES ( NPU ) +*** SYN WEIGHT + SEM WT = 10 + 0 = 10 PICKING UP CONFIG 44 : VP/V:19 ( 7 ) STARTING AT 19 : { MONITORING NP/ N-QDET ADJ INTEGER ARE QUANT PRO NPR POSS V V ADV TEST ( N0T ( CAT V ) ) I } SETTING UP CONFIG 20 : NP/:19 ( 7 ) NOTICING `` FEE '' ALL ARCS TRIED AT THIS CONFIG PICKING UP CONFIG 48 : VP/NP:19 ( ? )</sentence>
				<definiendum id="0">S NPU NP DET ART THE N REGISTRATION FEATS NU SG WITH FEATURES</definiendum>
				<definiens id="0">STARTING AT 19 : { MONITORING NP/ N-QDET ADJ INTEGER ARE QUANT PRO NPR POSS V V ADV TEST ( N0T ( CAT V )</definiens>
			</definition>
			<definition id="15">
				<sentence>ThesB examples have shown that SPARSER is a u~oful tool in th* automatic reco~nition df speech .</sentence>
				<definiendum id="0">SPARSER</definiendum>
				<definiens id="0">a u~oful tool in th* automatic reco~nition df speech</definiens>
			</definition>
			<definition id="16">
				<sentence>( NP/ ( CAT ART ( T T ) 5 ( SETR # ART ( BUILDQ ( ( ART * ) ) ) ) ( TO ' NP/ART ) ) ( JUMP NP/ART ( T T ) 4 ) ) ( N'P/ADJ ( CAT N ( T T ) 5 ( SETR # '*I ( SETR NU ( GETFEATURE NUMBER ) ) ( TO NP/N ) ) ( CAT N ( T T ) 2 ( ADDL ADJS ( BUILDQ tADJ ( NP ( N * ) ( N.U ( GETF ; EATURE NUMBER ) ) ) ( TO NPIADJ ) ) ) ( NPIART ( CAT QUINT ( T , T ) 4 ( SETR QUANT ( BUILDQ ( ( QUANT * ) ) I ) ( TO NPIQUANT ) 1 ( JUMP NPIQUANT ( T T ) 5 ) ) ( NP/QUANT ( CAT ADJ ( T T ) 4 ( ADDR ADJS ( BUILDQ ( @ ( ADJ ) ( *I FEATURES ) ) ( TQ NP/QUANT ) ) ( JUMP NP/ADJ ( T T ) '4 1 ) ( NP/N ( PUSH PP/ ( ( PPSTART ) 4 ( ADDL NMODS * ) ( TO NP/N ) ) ( POP ( BUILDQ ( Q ( NP ) + + + ( ( N + ) I ( ( NU + ) I + ART QUANT ADJS N NU NMODS ) IT ( DETAGREE ) ) 5 ) ( PP/ ( CAT PREP ( T T ) 5 ( SETR PREP * ) ( .</sentence>
				<definiendum id="0">CAT ART</definiendum>
				<definiendum id="1">BUILDQ</definiendum>
				<definiendum id="2">ADDL ADJS ( BUILDQ tADJ ( NP</definiendum>
				<definiendum id="3">SETR QUANT ( BUILDQ</definiendum>
				<definiendum id="4">JUMP NPIQUANT</definiendum>
				<definiendum id="5">CAT ADJ</definiendum>
				<definiendum id="6">ADDR ADJS ( BUILDQ</definiendum>
				<definiendum id="7">ADJ ) ( *I FEATURES ) ) ( TQ NP/QUANT ) ) ( JUMP NP/ADJ</definiendum>
				<definiens id="0">ADDL NMODS * ) ( TO NP/N ) ) ( POP ( BUILDQ ( Q ( NP ) + + + ( ( N + ) I ( ( NU + ) I + ART QUANT ADJS N NU NMODS</definiens>
			</definition>
			<definition id="17">
				<sentence>OCTOBER OF ON ONE ONLY OH OTIIER OUT OVERHEAT , PAJARRDPDUNES PARTICIPAIJT PAUL PAY PENNSYLVANIA PEOPLE PER PEHSON PHONOLOGY PITTSBURGH PLACE PLEASE PLUS PRINT PROJECT-N PROJECT-V PURPOSE QUARTER REGISTRATION REMAIN REST REVISE RICH RICHARD ROUNDeTRhIP SANTAeBARBARA SCHEDULE SECOND SEND SENDING SENDS SENT SEPTEMBER SkVEN SEVENTEEN SEVENTEENTlI SEVENTH SEVENTY SHE SINCE SETE SIX SIXTEEN SIXTEENTH SIXTH SIXTY SO SOCIETY SOME SOMEONE SPEECH SPEND SPENDING SPENDS SPENT SPRING ST.LOUIS START STATUS STOCKHOLH SUMMER SUPPOSE SUPPOSED SUPPOSITION SUN SWEDEN TAKE TAKEN TAKES TAKING TEN TENTH THAN THANKQYOU THAT THE THEIH THEM THERE THESE THEY THIRD THIRTEEN THIRTEENTH THIRTIETH THIRTY THIS THOSE THOUSAND THREE TIME TO TOO TOOK TOTAL TRAVEL TRIP TWELFTH TWELVE TWENTIETH TWENTY TWO UNANTICIPATED UNDUDCETED UNSPEilT UNTAXEN NUS VARIOUS VISIT WANT WAS WASHINGTON WE WEEK WENT WERE WHAT WHEN WHERE WHICH iJHO WHOM WHOSE WILL WINTER WISCONSIN WITH WITHIN WORKSHOP YEAR YES YOU ) The syntactic categories : ( ADJ 23 ( ACOUSTICAL ADDITIONAL AVAILABLE BIG COI-IPUTATIONAL CURRENT EACII ENOUGH EXPZNSIVE FINAL FISCAL INTERNATIONAL LATE LEFT LONG MANY MISCELLANEOUS OTHER UNANTICIPATE~ UNBUDGETED UNSPENT UNTAKEN VARIOUS ) ) ( ADV 18 ( ALREADY ALSO ANYWHERE EITHER ENOUGH WOW [ , ATE LONG NORE MOST MUCH NOW ONLY PLEASE SO THERE TOO YES ) ) ( ART 8 ( A AN NO THAT THE THESE THIS THOSE ) ) ( CONJ 8 ( AND BECAUSE BOTH IF OR PLUS SINCE SO ) ) ( IN .</sentence>
				<definiendum id="0">ATE LONG NORE MOST MUCH NOW ONLY PLEASE SO THERE</definiendum>
				<definiens id="0">PAY PENNSYLVANIA PEOPLE PER PEHSON PHONOLOGY PITTSBURGH PLACE PLEASE PLUS PRINT PROJECT-N PROJECT-V PURPOSE QUARTER REGISTRATION REMAIN REST REVISE RICH RICHARD ROUNDeTRhIP SANTAeBARBARA SCHEDULE SECOND SEND SENDING SENDS SENT SEPTEMBER SkVEN SEVENTEEN SEVENTEENTlI SEVENTH SEVENTY SHE SINCE SETE SIX SIXTEEN SIXTEENTH SIXTH SIXTY SO SOCIETY SOME SOMEONE SPEECH SPEND SPENDING SPENDS SPENT SPRING ST.LOUIS START STATUS STOCKHOLH SUMMER SUPPOSE SUPPOSED SUPPOSITION SUN SWEDEN TAKE TAKEN TAKES TAKING TEN TENTH THAN THANKQYOU THAT THE THEIH THEM THERE THESE THEY THIRD THIRTEEN THIRTEENTH THIRTIETH THIRTY THIS THOSE THOUSAND THREE TIME TO TOO TOOK TOTAL TRAVEL TRIP TWELFTH TWELVE TWENTIETH TWENTY TWO UNANTICIPATED UNDUDCETED UNSPEilT UNTAXEN NUS VARIOUS VISIT WANT WAS WASHINGTON WE WEEK WENT WERE WHAT WHEN WHERE WHICH iJHO WHOM WHOSE WILL WINTER WISCONSIN WITH WITHIN WORKSHOP YEAR YES YOU ) The syntactic categories : ( ADJ 23 ( ACOUSTICAL ADDITIONAL AVAILABLE BIG COI-IPUTATIONAL CURRENT EACII ENOUGH EXPZNSIVE FINAL FISCAL INTERNATIONAL LATE LEFT LONG MANY MISCELLANEOUS OTHER UNANTICIPATE~ UNBUDGETED UNSPENT UNTAKEN VARIOUS ) ) ( ADV 18 ( ALREADY ALSO ANYWHERE EITHER ENOUGH WOW [</definiens>
			</definition>
			<definition id="18">
				<sentence>TEQER 27 ( EIGHT EIGHTEEN EIGHTY ELEVEN FIFTEEN FIFTY FIVE FOR*TY FOUR FOURTEEN NINE NINETEEN NINETY ONE SEVEN SEVENTEEN SEVENTY SIX SIXTEEN SIXTY TEN THIRTEEN THIRTY THREE TWELVE TWENTY TWO ) ) ( MODAL 5 ( CAN DID DO DOES WILL ) ) ( N 70 ( ACOUSTICS AIR AIRPLANE AMOUNT ASSOCIATION ASSUMPTION BEGINN-ING BREAKDOWN BUDGET BUS CAR CENT CHANGE CITY CONFERENCE COST COUNTRY DATE DAY DIVISION END ESTIMATE-N EXPENSE FALL FARE FEE FIGURE GROUP HALF HALVES LINGUISTICS LIST MEETING MEMBER MONEY MONTH MUCH NEED NOTE OVERHEAD PARTICIPANT PEOPLE PERSON PHONOLOGY PLACE PROJECT-N PURPOSE QUARTER REGISTRATION REST ROUNDQTRIP SCHEDULE SITE SOCIETY SOME SPEECH SPRING STATUS SUMMER SUPPOSITION TH4NKeYOU TIME TOTAL TRAVEL TRIP VISIT WEEK WINTER WORKSHOP YEAR ) ) ( NEG 1 ( NOT ) ) ( NPR 53 ( ACL A1 AMHERST APRIL ARPA SA AUGUST BATES BILL BONNIE BOSTON CALIFORNIA CARNEGIE C : ILARUSSO COSELL CRAIG DECEMBER DENNIS ENGLAND FEBRUARY IFIP IJCAI JANUARY JERRY JOHN JULY JUNE L.A. LINDA LONDON LOS @ NGELES LYN LYNN MAKHOUL MARCH MASSACHUSETTS MAY NEWCYORK NOVEMBER OCTOBER PAJARROeDUNE-S .</sentence>
				<definiendum id="0">EIGHT EIGHTEEN EIGHTY ELEVEN FIFTEEN FIFTY FIVE FOR*TY FOUR FOURTEEN NINE NINETEEN NINETY ONE SEVEN SEVENTEEN SEVENTY SIX SIXTEEN SIXTY TEN THIRTEEN THIRTY THREE TWELVE TWENTY TWO ) )</definiendum>
			</definition>
</paper>

		<paper id="1053">
			<definition id="0">
				<sentence>The CARPS program builds a structure ( generally a single tree ) containing the information derived from the problem statement .</sentence>
				<definiendum id="0">CARPS program</definiendum>
				<definiens id="0">builds a structure ( generally a single tree ) containing the information derived from the problem statement</definiens>
			</definition>
			<definition id="1">
				<sentence>Thc Augmented Transition Network ( ATN ) of Woods [ Woods 501 is a powerful formalisnl for representing grammars .</sentence>
				<definiendum id="0">Thc Augmented Transition Network</definiendum>
				<definiens id="0">a powerful formalisnl for representing grammars</definiens>
			</definition>
			<definition id="2">
				<sentence>A transition network consists of a set of nodes ( representing states ) and a set of directed arcs between the nodes which specify transitions between states based upon the input string being scanned .</sentence>
				<definiendum id="0">transition network</definiendum>
				<definiens id="0">consists of a set of nodes ( representing states ) and a set of directed arcs between the nodes which specify transitions between states based upon the input string being scanned</definiens>
			</definition>
			<definition id="3">
				<sentence>The Semantic Network formnlism of Sio~mons [ Simmons 7 : l : Simmc~~s and Bruce ill provides n po\verful and convenient method for representing the elements of a sentence and the semantic relations ( deri\-ed from a variety of syl~tactir forms ) \~hirh hold between them .</sentence>
				<definiendum id="0">Semantic Network formnlism of Sio~mons</definiendum>
				<definiens id="0">Simmc~~s and Bruce ill provides n po\verful and convenient method for representing the elements of a sentence and the semantic relations ( deri\-ed from a variety of syl~tactir forms ) \~hirh hold between them</definiens>
			</definition>
			<definition id="4">
				<sentence>A noun phrase , for example , causes the production of a noun phrase token structure which has a standard form , independent of the function of the noun phrase in the sentence .</sentence>
				<definiendum id="0">noun phrase</definiendum>
				<definiens id="0">a standard form , independent of the function of the noun phrase in the sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>The function CAT ( category ) is frequently used to test whether the word currently under the scanner is in a particular category , as defined in the lexicon .</sentence>
				<definiendum id="0">function CAT</definiendum>
				<definiens id="0">frequently used to test whether the word currently under the scanner</definiens>
			</definition>
			<definition id="6">
				<sentence>FAIL restores the pointers to the sentence to their original position , and calls SET to restol-r the * register .</sentence>
				<definiendum id="0">FAIL</definiendum>
				<definiens id="0">restores the pointers to the sentence to their original position , and calls SET to restol-r the * register</definiens>
			</definition>
			<definition id="7">
				<sentence>( NP ( LAMBDA ( ) ( PROG ( 7 ( SAVE ) ( COND ( ( CAT WET ) ( = &gt; ) ) ) A ( COND ( ( CAT `` ADJ ) ( = &gt; ) ( GO A ) ) ( ( CAT `` NOUN ) ( = &gt; ) ( RETURN ( SUCCESS ) ) ) ( T ( RETURN ( FAIL ) ) ) ) 1 ) ) This pmqram accepts a noun phrase equivalent to that accepted by the following grammar : Using the Woods ATN formalism , such a program could be written as followkr ( NP/ ( CAT DET T ( TO NP1 ) ) ( TST T T ( JUMP NP-1 ) ) I ( NP1 ( CATADJ T ( TO NPI ) ) ( CAT NOUN T ( TO NP2 ) ) ) ( NP2 ( POP T T ) ) Our method of writing pnrsing-functions requires th~ writing of slightly more code than is required for a Woods interpreter system , but sit avoids the overhead of interpretive execution .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiendum id="1">LAMBDA ( )</definiendum>
				<definiendum id="2">SAVE ) ( COND</definiendum>
				<definiendum id="3">COND ( ( CAT</definiendum>
				<definiendum id="4">) ) ( ( CAT `` NOUN</definiendum>
				<definiendum id="5">NP/ ( CAT DET T</definiendum>
				<definiens id="0">CATADJ T ( TO NPI ) ) ( CAT NOUN T ( TO NP2 ) ) ) ( NP2 ( POP T T ) ) Our method of writing pnrsing-functions requires th~ writing of slightly more code than is required for a Woods interpreter system , but sit avoids the overhead of interpretive execution</definiens>
			</definition>
			<definition id="8">
				<sentence>The functibn SET* , which sets the value of the 'X register , checks for maltiple-word units , and replaces them with single words in the * register .</sentence>
				<definiendum id="0">functibn SET*</definiendum>
				<definiens id="0">sets the value of the 'X register , checks for maltiple-word units , and replaces them with single words in the * register</definiens>
			</definition>
			<definition id="9">
				<sentence>$ E : hlO BJ ( Semantic Object ) is a link to the object in the problenl ~llotlel which the location refvrs to , in this case the scaffold SC'AFF0LYH ; 'r. RFN'I ' ( Referent ) is a list of painters to the items in the problemmodel to which the phrase refers : the locarions LOC91 and LOC ! )</sentence>
				<definiendum id="0">hlO BJ</definiendum>
				<definiens id="0">a list of painters to the items in the problemmodel to which the phrase refers : the locarions LOC91 and LOC</definiens>
			</definition>
			<definition id="10">
				<sentence>[ Geometric names , as in `` AT END ( A ) '' , are represented in LISP as lists containing the names ; in the original sources from which the problems were taken , such names were written as italic capitnls . ]</sentence>
				<definiendum id="0">END</definiendum>
				<definiens id="0">lists containing the names</definiens>
			</definition>
			<definition id="11">
				<sentence>NPHD is a noun phrase token which is the syntactic subject of the verb .</sentence>
				<definiendum id="0">NPHD</definiendum>
				<definiens id="0">a noun phrase token which is the syntactic subject of the verb</definiens>
			</definition>
			<definition id="12">
				<sentence>VPHD ( if specified ) is a verb phrase token which is either the first part of a compound verb phrase or the initial auxiliary verb which is separated from the rest of the verb group in a question .</sentence>
				<definiendum id="0">VPHD</definiendum>
				<definiens id="0">a verb phrase token which is either the first part of a compound verb phrase or the initial auxiliary verb which is separated from the rest of the verb group in a question</definiens>
			</definition>
			<definition id="13">
				<sentence>CMPND is a flap which is true if the verb group is part of a compound verb phrase .</sentence>
				<definiendum id="0">CMPND</definiendum>
				<definiens id="0">a flap which is true if the verb group is part of a compound verb phrase</definiens>
			</definition>
			<definition id="14">
				<sentence>QFLG is true if the verb group is a top-level verb group in a question .</sentence>
				<definiendum id="0">QFLG</definiendum>
				<definiens id="0">a top-level verb group in a question</definiens>
			</definition>
			<definition id="15">
				<sentence>In addition to the usual PP consisting of a preposition and noun phrase , the PP parser accepts a phrase involving a measurement and a preposition and noun phrase ( as in `` 10 ft from one end '' ) as a single prepositional phrase .</sentence>
				<definiendum id="0">PP parser</definiendum>
				<definiendum id="1">noun phrase</definiendum>
				<definiens id="0">accepts a phrase involving a measurement and a preposition and</definiens>
			</definition>
			<definition id="16">
				<sentence>This verb phrase token is passed as an argument to the verb serna~ltics driver , EXVBSEM , which completes semantic processing of the sentence .</sentence>
				<definiendum id="0">EXVBSEM</definiendum>
				<definiens id="0">completes semantic processing of the sentence</definiens>
			</definition>
			<definition id="17">
				<sentence>The semantic routine for `` by '' sinlply attached its object phrase token , TOK186 ; to the verb phrase token as the subject of the verb ; hence , there is no need for `` by '' to appear anywhere in the structure ) TOKl8l is the noun phrase token produced from the initial noun phrase of the sentence ; it is a TOKen of the word SCAFFOLD , is a Linguistic FRAME of t-ype NP ( Noun Phrase ) has an INDEFinite DETerminer , and has a NBR ( number ) of NS ( Noun Singular ) .</sentence>
				<definiendum id="0">TOKl8l</definiendum>
				<definiendum id="1">NBR</definiendum>
				<definiens id="0">the verb phrase token as the subject of the verb</definiens>
				<definiens id="1">the noun phrase token produced from the initial noun phrase of the sentence</definiens>
				<definiens id="2">a Linguistic FRAME of t-ype NP ( Noun Phrase ) has an INDEFinite DETerminer</definiens>
			</definition>
			<definition id="18">
				<sentence>TOK181 is the syntactic subject of a DCLAUSE ( Dependent CLAUSE ) whose verb token is TOK182 .</sentence>
				<definiendum id="0">TOK181</definiendum>
				<definiens id="0">the syntactic subject of a DCLAUSE ( Dependent CLAUSE ) whose verb token is TOK182</definiens>
			</definition>
			<definition id="19">
				<sentence>FROM2 ( preceded by a measurement phrase ) always specifies a LOC ; the measureme~lt phrase may be a question phrase , a8 in `` how far from the center '' ( P20 ) .</sentence>
				<definiendum id="0">FROM2</definiendum>
				<definiens id="0">preceded by a measurement phrase ) always specifies a LOC ; the measureme~lt phrase may be a question phrase</definiens>
			</definition>
			<definition id="20">
				<sentence>Referent Identification is the process of associating the phrases in a sentence with the objects and relationships they refer to ( explicitly or implicitly ) ih the reader 's model of the world .</sentence>
				<definiendum id="0">Referent Identification</definiendum>
				<definiens id="0">the process of associating the phrases in a sentence with the objects and relationships they refer to ( explicitly or implicitly ) ih the reader 's model of the world</definiens>
			</definition>
			<definition id="21">
				<sentence>Similarly , an equilibrant is a force which is applied to a rigid body to produce equilibrium .</sentence>
				<definiendum id="0">equilibrant</definiendum>
				<definiens id="0">a force which is applied to a rigid body to produce equilibrium</definiens>
			</definition>
			<definition id="22">
				<sentence>In most cases , the SELECT semantics consists of a test for an identical SELECT modifier ( e.g. , RIGHT or LEFT ) .</sentence>
				<definiendum id="0">SELECT semantics</definiendum>
				<definiens id="0">consists of a test for an identical SELECT modifier ( e.g. , RIGHT or LEFT )</definiens>
			</definition>
			<definition id="23">
				<sentence>LOCNP identifies the referent ( s ) of a location noun phrase ; such a location may be denoted in many different ways .</sentence>
				<definiendum id="0">LOCNP</definiendum>
				<definiens id="0">identifies the referent ( s ) of a location noun phrase</definiens>
			</definition>
			<definition id="24">
				<sentence>IDATT identifies an attachment frame which specifies the attachment of all the objects in the list ; if no such attachment frame exists , one is created , along with links between it and the objects involved .</sentence>
				<definiendum id="0">IDATT</definiendum>
				<definiens id="0">identifies an attachment frame which specifies the attachment of all the objects in the list</definiens>
			</definition>
			<definition id="25">
				<sentence>Such a force is identified by the function IDFORCE , which creates variables for the force vector and adds them to the attachmefit relation if necess-ary .</sentence>
				<definiendum id="0">IDFORCE</definiendum>
				<definiens id="0">creates variables for the force vector and adds them to the attachmefit relation if necess-ary</definiens>
			</definition>
			<definition id="26">
				<sentence>In addition to the verb SUPPORT , the verbs REST , PIN , BALANCE , SIT , HANG , CARRY , ATTACH , STAND , LIFT , and EXERT can all be used to specify attachment relations .</sentence>
				<definiendum id="0">EXERT</definiendum>
				<definiens id="0">the verbs REST , PIN , BALANCE , SIT , HANG , CARRY , ATTACH , STAND , LIFT , and</definiens>
			</definition>
			<definition id="27">
				<sentence>A Canonical Object is an idealizatio~~ of an actual physical object which represents its salient characteristics for a particular physics problem .</sentence>
				<definiendum id="0">Canonical Object</definiendum>
				<definiens id="0">an idealizatio~~ of an actual physical object which represents its salient characteristics for a particular physics problem</definiens>
			</definition>
			<definition id="28">
				<sentence>A constant or variable is a GENGYM atom which is added to the list of objects in the model ; it has property list values which tell the canonical object frame it is associated with , the quantity it measures ( e.g. , TENSION ) , the units ( e.g. , LB ) , and whether it is a constant or variable .</sentence>
				<definiendum id="0">GENGYM atom</definiendum>
			</definition>
			<definition id="29">
				<sentence>The function MFPEIISON , which makes a frame for a PERSON , esnmines* the contest to determine whether to model the PERSON ns a WEIGHT or as ( 1 PIVOT .</sentence>
				<definiendum id="0">MFPEIISON</definiendum>
			</definition>
			<definition id="30">
				<sentence>When EUCLID is initiated , every object has a geometric size ( in terms of length units , e.g. , meters ) specified under the property list indicator GSIZE .</sentence>
				<definiendum id="0">EUCLID</definiendum>
				<definiens id="0">length units , e.g. , meters ) specified under the property list indicator GSIZE</definiens>
			</definition>
			<definition id="31">
				<sentence>Given an object A , TRITEST looks for objects B and C such that .</sentence>
				<definiendum id="0">TRITEST</definiendum>
				<definiens id="0">looks for objects B and C such that</definiens>
			</definition>
			<definition id="32">
				<sentence>A FORCE may be specified as a two-component force vector , or in magnitude and direction form .</sentence>
				<definiendum id="0">FORCE</definiendum>
				<definiens id="0">a two-component force vector , or in magnitude and direction form</definiens>
			</definition>
			<definition id="33">
				<sentence>Others , such as our attachment equations , are eliminated by substitution of variables which is done mentally .</sentence>
				<definiendum id="0">attachment equations</definiendum>
				<definiens id="0">eliminated by substitution of variables which is done mentally</definiens>
			</definition>
			<definition id="34">
				<sentence>These functions perform some elementary simplifications on their arguments when possible ; for example , ( SPLUS 0 x ) = x , where x is any expression .</sentence>
				<definiendum id="0">SPLUS</definiendum>
				<definiendum id="1">x</definiendum>
				<definiens id="0">some elementary simplifications on their arguments when possible</definiens>
			</definition>
			<definition id="35">
				<sentence>SOLVEQ attempts to solve an equation ; if it succeeds , the results are propagated to related equations and variables , which may lead to the solution of additional equations .</sentence>
				<definiendum id="0">SOLVEQ</definiendum>
				<definiens id="0">attempts to solve an equation ; if it succeeds , the results are propagated to related equations and variables</definiens>
			</definition>
			<definition id="36">
				<sentence>PRTVAR prints the value of a variable and the wits associated with it , If the answer is an expression which contains constants , the f~ilnction EXPLCON is called to explain each constant .</sentence>
				<definiendum id="0">PRTVAR</definiendum>
				<definiens id="0">prints the value of a variable and the wits associated with it , If the answer is an expression which contains constants , the f~ilnction EXPLCON is called to explain each constant</definiens>
			</definition>
			<definition id="37">
				<sentence>EXPLCON gets the object with which the constant is ; associated and the attribute which it measures from the constant 's property list , and outputs these in a standard format , e.g. , `` where 1 ENGTH'iG is the length of the pole '' ( P2 ) .</sentence>
				<definiendum id="0">EXPLCON</definiendum>
				<definiens id="0">gets the object with which the constant is ; associated and the attribute which it measures from the constant 's property list , and outputs these in a standard format</definiens>
				<definiens id="1">the length of the pole '' ( P2 )</definiens>
			</definition>
			<definition id="38">
				<sentence>EXPLCON is called by most of the answer generation routines if the answer is an expression involving constants .</sentence>
				<definiendum id="0">EXPLCON</definiendum>
				<definiens id="0">an expression involving constants</definiens>
			</definition>
			<definition id="39">
				<sentence>PRTLOC generates a description of a location ; typically , a location which is the object of a question will be represented as a point which is a certain distance from a known point , with the distance an unknown .</sentence>
				<definiendum id="0">PRTLOC</definiendum>
				<definiens id="0">generates a description of a location</definiens>
			</definition>
			<definition id="40">
				<sentence>MAKEPF is a function which makes a picture frame for a single object .</sentence>
				<definiendum id="0">MAKEPF</definiendum>
				<definiens id="0">a function which makes a picture frame for a single object</definiens>
			</definition>
			<definition id="41">
				<sentence>Figure 7.1 : Computing Picture Frame for a Rotated Object &gt; After a picture frame has been made for an object by MAKEPF , DIAGRAM searches the attachment rclutions of the object to find a pbint at which it is attached to an object which is al~*eildy in the picture .</sentence>
				<definiendum id="0">DIAGRAM</definiendum>
				<definiens id="0">searches the attachment rclutions of the object to find a pbint at which it is attached to an object</definiens>
			</definition>
			<definition id="42">
				<sentence>PICTLOC calculates the position of a point on an object relative to the object s picture frame .</sentence>
				<definiendum id="0">PICTLOC</definiendum>
				<definiens id="0">calculates the position of a point on an object relative to the object s picture frame</definiens>
			</definition>
			<definition id="43">
				<sentence>For each object which is to be drawn , DRAWPICS calculates the proper offsetstarting position , sets the initial position and heading , and calls the program to draw the object with the size as an argument .</sentence>
				<definiendum id="0">DRAWPICS</definiendum>
				<definiens id="0">calculates the proper offsetstarting position , sets the initial position and heading</definiens>
			</definition>
			<definition id="44">
				<sentence>Object which this object is a part of .</sentence>
				<definiendum id="0">Object</definiendum>
				<definiens id="0">a part of</definiens>
			</definition>
			<definition id="45">
				<sentence>LB ) ( LENGTH FT ) ) Equations Generated By Problem Solver SOLVEQ ( EQUALS 0 FORCE3281 SOLVEQ ( EQUALS 0 ( PLUS FORCE329 FORCE3381 SOLVEQ ( EQUALS 0 ( PLUS FORCE330 ( TIMES FORCE336 -1 ) ) ) SOLVEQ ( EQUALS 0 FORCF331 ) SOLVEQ ( EQUALS 0 ( PLUS ( TIMES FORCE337 -1 TENSION327 ) SOLVEQ ( EQUALS 0 0 ) SOLVEQ ( EQUALS 0 ( PLUS ( TIMES TENSION327 -1,00000 ) F3HCE332 ) ) SOLVEQ ( EQUALS 0 FORCE3331 SOLVEQ ( EQUALS 0 FORCE3341 SOLVEQ ( EQUALS 0 ( PLUS -150 FOHCE335 ) ) SOLVEQ ( EQUALS 0 ( PLUS 250 ( MINUS FORCE338 ) ' ) ) SOLVEQ ( EQUALS 0 ( PLU5 FORCE332 FORCE33611 SOLYEQ ( EQlUALS 0 ( PLUS ( PLUS ( PLUS ( DIFFERENCE ( TIMES FORCE332 8o00000 ) ( TIMES FORCE333 6,00000 ) ) ( ( 1IFFERENCE ( TIMES FORCE330-32*80000 ) ( TIMES FOHCE331 -24,00000 ) ) ) ( DIFFERENCE ( TIMES FORCE328 -32,00000 ) ( TIMES FORCE329 -24.00000 ) ) 1 1200.00000 ) ) ANSWER : 120000000 LR Final Model of the Problem LADDER-291 ( ( TOK .</sentence>
				<definiendum id="0">LB )</definiendum>
				<definiendum id="1">PLU5 FORCE332 FORCE33611 SOLYEQ</definiendum>
				<definiendum id="2">TIMES FORCE333 6,00000 ) ) ( ( 1IFFERENCE ( TIMES FORCE330-32*80000 )</definiendum>
			</definition>
</paper>

		<paper id="1047">
			<definition id="0">
				<sentence>A predictive analyzer is a top-down parser for contest-free grammars written in Greibach normal form ; this formulation of the grammar was adopted from earlier work by Ida Rhodes for her Russian-English translation project .</sentence>
				<definiendum id="0">predictive analyzer</definiendum>
				<definiens id="0">a top-down parser for contest-free grammars written in Greibach normal form</definiens>
			</definition>
			<definition id="1">
				<sentence>A &amp; hornsky ) tree transformational grammar consists of a set of context-sensitive phrase structure rules , which generate a set of base treesa , and a set of transformations , which act on base trees to produce the surf ace trees .</sentence>
				<definiendum id="0">transformational grammar</definiendum>
			</definition>
			<definition id="2">
				<sentence>A ( Harris ) string transfo~tional grammar consists of a finite set of sequences of word categories , called kernel sentences , and a set of transformations which combine and modify these kernel sentences t6 e the other sentences of the language .</sentence>
				<definiendum id="0">Harris ) string transfo~tional grammar</definiendum>
				<definiens id="0">consists of a finite set of sequences of word categories , called kernel sentences , and a set of transformations which combine and modify these kernel sentences t6 e the other sentences of the language</definiens>
			</definition>
			<definition id="3">
				<sentence>Rejection rules were tests which were applied to the tree during the reverse transformational process ( step ( 2 ) above ) , in order , to eliminate some trees as early as possible in the parsing .</sentence>
				<definiendum id="0">Rejection rules</definiendum>
				<definiens id="0">were tests which were applied to the tree during the reverse transformational process ( step ( 2 ) above ) , in order , to eliminate some trees as early as possible in the parsing</definiens>
			</definition>
			<definition id="4">
				<sentence>A transition network is a set of nodes ( including one initial and at least one terminal node ) and a set of directed arcs between the nodes , labeled with symbols from the language ; it is a standard representation for regular languages .</sentence>
				<definiendum id="0">transition network</definiendum>
				<definiens id="0">a set of nodes ( including one initial and at least one terminal node ) and a set of directed arcs between the nodes , labeled with symbols from the language</definiens>
			</definition>
			<definition id="5">
				<sentence>A recursive transition network is a set of transition networks in which the arcs of one network may also be labeled with the names of other networks ; it is a form of representation of context-f ree languages .</sentence>
				<definiendum id="0">recursive transition network</definiendum>
				<definiens id="0">a set of transition networks in which the arcs of one network may also be labeled with the names of other networks ; it is a form of representation of context-f ree languages</definiens>
			</definition>
			<definition id="6">
				<sentence>The Linguistic String Project grammar ; by performing a &amp; l operations on the parse tree through a s~nall nunbcr of lowlevel routines , was able to localize the changes to these routines and a srngll number of restrictions ( such as nun &amp; er agrcerneJt ) which are specially af fectcd by con junction [ Raze 19741 .</sentence>
				<definiendum id="0">Linguistic String Project</definiendum>
				<definiens id="0">such as nun &amp; er agrcerneJt ) which are specially af fectcd by con junction</definiens>
			</definition>
			<definition id="7">
				<sentence>The four types are : ( 0 ) Develops a single parse tree at a time ; at any instant the store holds a set of nodes corresponding to the nodes of an incomplete potential parse tree ft ) The store holds a set of nodes , each of which represents the fact that some substring of the sentence , from word f to word R , can be analyz~d as some symbol N. ( 2 ) The store holds a set of nodes , each of which represents an analysis of some substring of the sentence , from word f to word a , as some symbol N ( if there are several different analyses of words f to 11 as some symbol N , there will be several nodes corresponding to a single node in a type 1 parser ) .</sentence>
				<definiendum id="0">store</definiendum>
				<definiens id="0">represents the fact that some substring of the sentence , from word f to word R</definiens>
			</definition>
			<definition id="8">
				<sentence>WORD holds the number of the next word in fie sentence to be matched .</sentence>
				<definiendum id="0">WORD</definiendum>
				<definiens id="0">holds the number of the next word in fie sentence to be matched</definiens>
			</definition>
			<definition id="9">
				<sentence>TREE , NODES , PARSES , MS , I ; /* initialization */ SPAN = n1 ; SPANS = 0 ; TODO = nl ; /* iterate over WORD=last word subsumed by spans being constructed */ ( 1 &lt; = VWORD &lt; = # SENTENCE ) /* add span whose name is sentence word */ ADDSPAN ( SENTENCE ( WORD ) , WORD , WORD+l , nult ) ; /* TODO contains the numbers of spans which were just created and for which ye have not yet checked whether they can be used as the last daughter span in building some more spans */ ( while TODO ne nl ) /* select a span from TODO */ CURRENT from TODO ; /* loop over all productions whose last element = name of current span */ ( VDEF E GRAMMAR ( DEF ( # DEF ) eq SPAN ( CURRENT , 'NAME ' ) ) /* separate left and right sides of production */ DEETIAME = hd DEF ; DEFELIST = tl DEF ; /* if elements preceding last element of production can be matched by spans , add a new span whose name = left-hand side of prodncision for each match*/ ( ~REM E MATCH ( DEFELIST ( 1 : ( # DEFELIST ) -1 ) , a SPAN ( CURmNT , 'FW ' ) ) ) ADDSPAN ( DEFNAME , hd REM , SPAN ( CUIXWNT , 'LW+l ' ) , ( tl REM ) -t &lt; CURRENT &gt; ) ; end VREM ; end VDEF ; end while TODO ; end 1 \= VWORD ; /* eXtract trees from set of spans */ PARSES = nl ; ( 1 &lt; = \tI &lt; = SPANS I ( SP .</sentence>
				<definiendum id="0">SPAN</definiendum>
				<definiens id="0"># SENTENCE ) /* add span whose name is sentence word */ ADDSPAN ( SENTENCE ( WORD ) , WORD , WORD+l , nult</definiens>
				<definiens id="1">the last daughter span in building some more spans */ ( while TODO ne nl ) /* select a span from TODO */ CURRENT from TODO ; /* loop over all productions whose last element = name of current span */ ( VDEF E GRAMMAR ( DEF ( # DEF ) eq SPAN ( CURRENT , 'NAME ' ) ) /* separate left and right sides of production */ DEETIAME = hd DEF ; DEFELIST = tl DEF ; /* if elements preceding last element of production can be matched by spans</definiens>
			</definition>
			<definition id="10">
				<sentence>cqhich span a portion of the sentence whose last word +l = ENDFVDPI ; returns a set , each element of which is an ( ntl ) -tuple , whose tail is one of the n-tupleof spans and whose head is the rlunher of the first word spanned by the n-tuple of spans */ if ELIST cq nu9t then return ( ( ENDwDP~~~ ) ; else return [ U : 1 &lt; = 1 &lt; = NODESJ ( if ( SPAN ( I , 'NAME ' ) eq ELXST ( # ELIST ) ) and ( SPAN ( I , 'LFJ+ll ) eq ENDWDP1 ) then CNTUP + &lt; I &gt; , NTUP E bylTCH ( ELIST ( 1 : ( $ ELIST ) , SPAN ( 1 , 'FlY ' ) ) 1 else nl ) ; ; end MATCH ; &amp; fix % @ ADDSPAN ( NAME , FW r LWP1 , DAUGHTERS ) I* ADDSPAN builds a span whose components are passed in the four parameters */ mms = SPANS+l ; % Pm [ SP .</sentence>
				<definiendum id="0">NTUP E bylTCH ( ELIST</definiendum>
				<definiendum id="1">ADDSPAN</definiendum>
			</definition>
			<definition id="11">
				<sentence>SrgNAME ' ) = NAME : ; S~hWiiI ( SPANL : ,'E'W ' ) = FW ; SP~ ( SPANS , 'LW+~ ' ) = LWP1 ; S3Pm [ SPANS , ' DAUGHTERS ' ) = DAUGHTERS ; SmS h TOM ) ; *~bef EZ~PAND ( DAW , PAR ) ; /* creates a node for each span in DAW and each descendant thereof , and returns a tuple with the numbers of the nodes ( in TREE ) corresponding to the spans in DAW */ Dr Ni eq Q then return 52 ; ; n = zBtplt ; 1 S = NODES + ; 1 ; S = BODES ; ei~3 = SPANCS ) ; E ( Nr*PARENT1 ) = PAR ; ( N , 'DAqGHTERS ' ) = EXPAND ( TREE ( N , 'DAUGHTERS ' ) , N ) ; p = D + &lt; N &gt; ; end YS ; Algorithm C Type 1 Bottom-up Parallel Algorithm C is the basic `` nodal spansr ' parsing algorithm [ Cocke 19701 .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">creates a node for each span in DAW and each descendant thereof , and returns a tuple with the numbers of the nodes</definiens>
			</definition>
			<definition id="12">
				<sentence>; TREE ( X , 'WFSI ) = WFSS ; return true ; se I = I+1 end if I ; else TRSE ( JODES ) = a ; NODES = NODES-1 ; TREE ( X , ' DAUGHTERS ' ) ( I ) = 52 ; I = 1-1 ; end if EXPAND ; end while I ; OPT = Q ; if TREE ( X , 'ALTERHATE OPTIONS ' ) ne nR then go to GETOPT ; ; /* all expansions tried */ EXPANDED ( TREE ( X , 'NAME ' 1 , WORD ) = true ; return false ; end EXPAND ; define ADDTUFS ( NODEX ) /* add an entry to WFS */ local I ; WFSS = WFSS+l ; WFS ( WFSS , 'NAME ' ) = NODEX ( 'NAME ' ) ; WFS ( WFSS , ~FW~ ) = NODEX ( ~FN~ ) ; WFS ( IVPSS , LW+~ ) = NODEX ( LW+L ) if NODEX ( 'DAUGHTERS1 ) ne Q then WFS ( NFSS , 'DAUGHTERS ' ) = [ + : I E NODEX ( 'DAUGHTERS1 ) ] &lt; TREE ( I , T~~~f 1 &gt; ; end if NODEX ; return ; end AQDWFS ; Note that this parser returns an ordered pair consisting of the set of trees and the set of well-formed sSstrings , since the trees alone do not contain complete information about the sentence analysis .</sentence>
				<definiendum id="0">TREE</definiendum>
				<definiendum id="1">TREE</definiendum>
				<definiendum id="2">ADDTUFS</definiendum>
				<definiendum id="3">WFSS</definiendum>
				<definiendum id="4">WFS</definiendum>
				<definiens id="0">NODEX ) /* add an entry to WFS */ local I ;</definiens>
				<definiens id="1">an ordered pair consisting of the set of trees and the set of well-formed sSstrings , since the trees alone do not contain complete information about the sentence analysis</definiens>
			</definition>
			<definition id="13">
				<sentence>ORD+l , nu1 t ) ; * TODO co~ltains the nunhers of spans which were created and for which we have not yet checked just whether they can be used as the last daughter span in building some more spans */ ( while TODO ne nult ) /* select a span from TODO */ CURRENT = hd TODO ; TODO = tl TODO ; /* loop over all productions whose last element = name of current span */ ( VDEF E GRAMMAR~DEF ( # DEF ) eq SPAN ( CURRENT , ' ) ) /* separate left and right sides of production */ DEFNkW = hd DEF ; DEFELIST = tl DEF ; /* if elements preceding last element of production can be matched by spans , add new spans whose names = left-hand side of production for each match*/ ( VFSM E MATCH ( DEFELIST ( 1 : ( # DEFELIST ) -1 ) , SFX~ ( CURRENT , 'FW ' ) ) ) ADDSPANS ( DEFNAMEet hd REM , SPAN ( CURRENT , 'LW+l ) , ( tl REM ) + &lt; CURRENT &gt; ) ; end VREM ; end VDEF ; end while TODO ; end 1 &lt; = VWORD ; return SPAN ; end URRPARSE ; define MATCH ( ELIST , ENDWDP~ ) ; local I , NTUP ; /* MATCHfinds all n-tuples sf spans whose names match the elements of the n-tuple ELIST and which span a portion of the se~ltence whose last word + 1 = ENDWDP1 ; returns a set , each element of which is an ( n+l ) -tuple , whose tail is one of the n-tuples of spans and whose head is the number of the first word spanned by the n-tuple of spans */ if ELIST eq nult then return ( &lt; ENDWDPl &gt; ; else return [ U : 1 &lt; = I .</sentence>
				<definiendum id="0">define MATCH</definiendum>
				<definiens id="0">a span from TODO */ CURRENT = hd TODO ; TODO = tl TODO ; /* loop over all productions whose last element = name of current span */</definiens>
				<definiens id="1">separate left and right sides of production */ DEFNkW = hd DEF ; DEFELIST = tl DEF ; /* if elements preceding last element of production can be matched by spans , add new spans whose names = left-hand side of production for each match*/ ( VFSM E MATCH ( DEFELIST ( 1 : ( # DEFELIST ) -1 )</definiens>
				<definiens id="2">spans whose names match the elements of the n-tuple ELIST and which span a portion of the se~ltence whose last word + 1 = ENDWDP1</definiens>
			</definition>
			<definition id="14">
				<sentence>The grammar consists of a bass curnps~t8nt and a ~~~Lz~~s~oI*~* : LI $ .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiens id="0">consists of a bass curnps~t8nt and a ~~~Lz~~s~oI*~* : LI $</definiens>
			</definition>
			<definition id="15">
				<sentence>The strllctural irldex is a tuple ( vector ) , &lt; si . . . s &gt; I each of whose components 1 ' n is either a symbol ( name of a node ) or `` XuThe structural change is a tuple &lt; sclr. . . , sc of the same length as the n structural index. Each of its components is ir turn a tuple SC = &lt; SC i il , . . , sc &gt; , possibly empty ( ni = 0 ) .</sentence>
				<definiendum id="0">strllctural irldex</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">a tuple &lt; sclr. . . , sc of the same length as the n structural index. Each of its components is ir turn a tuple SC</definiens>
			</definition>
			<definition id="16">
				<sentence>il lni as right siblings of that node : If scij is an integer , between 1 and n , the new node is the node matched to the scij-th element of the structural index ; if SCij is a terminal symbol , the new node is a terminal node with that name .</sentence>
				<definiendum id="0">SCij</definiendum>
				<definiens id="0">a terminal symbol</definiens>
			</definition>
			<definition id="17">
				<sentence>For the parser , it is more convenient to represent this as two separate tuples , one with the boundary markers and the elements between them replaced by the symbol 'COMP ' ( m m m 'COMP ' m m m ) the other with the elements between the markers ( c c c ) In the transformation , these are components XFm ( i , 'ISC-MATRIX ' ) inverse structural change for matrix sentence inverse structural change for component : sentence The value of XFPARSE is a set , with each element giving one possible deep Structure frontier for the sentence , and the reverse transformations which were applied to obtain that deep structure .</sentence>
				<definiendum id="0">c c c</definiendum>
				<definiens id="0">a set , with each element giving one possible deep Structure frontier for the sentence</definiens>
			</definition>
			<definition id="18">
				<sentence>de fine f XFPARSE ( SENTENCE , XFMN , NUMXFMNS , BASEGR , AUXRULES ) ; local TODO , DONE , PARSES , SGRAMMAR , XFMNNO , CONT , SEiOT , XFAPPLD , MATCHSET , MATCH , COMPPARS , , ROMP MATRIX , P ; WNE = { &lt; SENTENCE , nult &gt; 1 ; PARSES = nk ; /* compute covering grammar */b SGRAMMAR = BASEGR CJ AUXRULES ; /* iterate over transformations */ ( 1 &lt; = YXF~NO &lt; = NUMXFMNS ) TODO 1= DONE ; DONE = nR ; /* iterate over active continuations */ ( WONT E TODO ) SENT = CONT ( 1 ) ; XFAPPLD = CONT ( 2 ) ; MATCHSET=PROCES ( SENT , XFMN ( XFMNNO , ISI ) ,1 , SGRAMMAR ) ; /* iterate over matches to structural index */ ( YMATCH E MATCHSET ) if XFMN ( XFMtJNO , ' TYPE ' ) eq ' BINARY ' then /* for binary transformatibns , first try to analyze embedded sentence */ COMl ?</sentence>
				<definiendum id="0">ROMP MATRIX</definiendum>
				<definiendum id="1">WONT E TODO ) SENT = CONT</definiendum>
				<definiendum id="2">MATCHSET=PROCES</definiendum>
				<definiens id="0">local TODO , DONE , PARSES , SGRAMMAR , XFMNNO , CONT , SEiOT , XFAPPLD , MATCHSET , MATCH , COMPPARS , ,</definiens>
			</definition>
			<definition id="19">
				<sentence>GJNQ , ' ISC-COMP ' ) ) , XFMN , XFMNJO , BASEGR , AUXRULES ) ; /* iterate over analyses of embedded sentence , adding matrlx with analyzed embedded sentence to continuations */ CVKOMP E COMPPARS ) MATRIX=IMPOSE ( MATCH , XFMN ( XFMNNO , ' ISC-MATRIX ' ) ) ; &lt; MATRIX , &lt; XFMiWO &gt; -t XFAPPLD &gt; in DONE ; end YKOMP ; else /* unary transformation */ /* add transformed sentence to continuations*/ NEWSENT = IMPOSE ( MATCH , XFNJ ( XFK~L\I~ , ' ISC ' ) ) ; &lt; NEWSENT , &lt; XFMiVNO &gt; + XFAPPLD &gt; in DONE ; end VMATCH ; / '' include untrans formed sentence in continuations , since reverse transformation is optional */ CONT in DONE ; end VCONT ; end 1 c= V XFMNdO ; / '' fi lraransfo~ .</sentence>
				<definiendum id="0">GJNQ</definiendum>
				<definiens id="0">/* iterate over analyses of embedded sentence , adding matrlx with analyzed embedded sentence to continuations */ CVKOMP E COMPPARS</definiens>
			</definition>
			<definition id="20">
				<sentence>mations haw bcon triod */ /* select and return those strings Which can be analyzcd by tho base component */ t -1 return { PCDONE~ PARSE ( DASRGR , b , P ( 1 ) ) ne n $ ) ; cnd XFPARSE ; Most of the work of the parser is done by the two Eoutines PROCES and IMPOSE , PROCES matches cv-rant string against the inverse struct~iral index , an1 IMPOSE con~putes the e'flfect of the inverse structural change .</sentence>
				<definiendum id="0">PCDONE~ PARSE</definiendum>
				<definiendum id="1">PROCES</definiendum>
				<definiens id="0">matches cv-rant string against the inverse struct~iral index</definiens>
			</definition>
			<definition id="21">
				<sentence>PROCES takes four arguments : SENTENCE STARTWD the string to be matched the structural indax the number o the fixst word in the string to be matcl~ed by the structural index ( , this argument is required because the procedure operates recursively ; its value is 1 for calls from XFPARSE ) the context-free gl-anmar used in matching the structuxal index to the string .</sentence>
				<definiendum id="0">SENTENCE STARTWD</definiendum>
				<definiens id="0">the string to be matched the structural indax the number o the fixst word in the string to be matcl~ed by the structural index</definiens>
			</definition>
			<definition id="22">
				<sentence>Successive trees subsume contiguous segments of the string being matched .</sentence>
				<definiendum id="0">Successive trees</definiendum>
				<definiens id="0">subsume contiguous segments of the string being matched</definiens>
			</definition>
			<definition id="23">
				<sentence>def inef PROCES ( SENTENCE , SI , STARTWD , GRAMMAR ) ; local R , RMDRSI , MATCHES , EI\ ; IDWD , P , PI , RMDRMATCH , PARSES ; /* split off first element of structural index */ R = hd SI ; WRSI = tl SI ; /* parse part of remainaer of sentence with this element*/ PARSES = PARTPARSE ( GRAMMAR I R , SENTENCE STARTWD ) ; MATCHES = nR ; ( VP E PARSES ) * set ENDWD = next word in sentence to be matched */ ENDWD = P ( 1 , ' LW+ll ) ; if RMDRSI eg nult then /* if at end of swim , accept parse tree for last element of s.i. only if it extends to end of sentence */ if ENDWD eq ( ( # SENTEiJCE ) + 1 ) then &lt; P &gt; in MATCHES ; end if ENDWD ; else /* not ak end of s. i. , call PROCES recursively to process next element */ RMDRMTCH = PROCESS ( SEIITENEE , RMDRSI : , ENDWD , GRAMMAR ) ; /* concatenate parse tree for current element to each forest of matches to succeeding elements*/ ( YM E RMDRMTCH ) &lt; P &gt; + M in WCHES ; end RMDRMTCH ; end if RMDRSI ; end VP PARSES ; re turn MATCHES ; end PROCESS , The transformational parser uses two varieties of context-free parser .</sentence>
				<definiendum id="0">def inef PROCES</definiendum>
				<definiens id="0">local R , RMDRSI , MATCHES , EI\ ; IDWD , P , PI , RMDRMATCH , PARSES ; /* split off first element of structural index */ R = hd SI ; WRSI = tl SI ; /* parse part of remainaer of sentence with this element*/ PARSES = PARTPARSE ( GRAMMAR I R , SENTENCE STARTWD ) ; MATCHES = nR ; ( VP E PARSES ) * set ENDWD = next word in sentence to be matched */ ENDWD = P ( 1 , ' LW+ll</definiens>
			</definition>
			<definition id="24">
				<sentence>FQREST is a tuple of trees representing the match to the structural index ( one element of the value returned byL PROCES ) SC is the structural change component of a transformation In addition , KOMP , which ( for binary trans formations ) holds the embedded sentence and its transformational history , is passed from XFPARSE to IMPOSE as a global variable .</sentence>
				<definiendum id="0">KOMP</definiendum>
				<definiens id="0">a tuple of trees representing the match to the structural index ( one element of the value returned byL PROCES ) SC is the structural change component of a transformation In addition</definiens>
				<definiens id="1">a global variable</definiens>
			</definition>
			<definition id="25">
				<sentence>Thus SETL contains both a general dath vb ject ( the set ) and other operationally more efficient structures known as atoms ; among these is a vector-like object known as a tuple , Atoms ( 1 ) 12 ) ( 3 ) ( 4 ) ( 5 ) integers ( .1276 ) character strings ( 'hel.10 , pally ' ) bit strings ( 10101b ) boolean constants ( true lbr false E Ob ) blank atoms ( created by the function NEWAT , the SETL equivalent of the LISP GENSYM ) Q , the undefined atom labels ( labels precede s tatcments , separated by a colon ) subroutines and functions tuples ( one-dimensional arrays of variable length ; i. e. , ordsred lists ; written as &lt; 1r 2 , ' threeJ &gt; ; the null tuple is designated nult ) Sets are unordered collections of elements , written as { 1,2 , ' three ' ) : he null set is designated nR Oper at OPS Integers arithmetic + * , comparison ( eq , ne , it , gt , lc , gel max , min , abs Booleans and , or , hot ( abbreviated n ) , cq , ne Character and bit strings concatenatiton * ( +I , Length # , substriqq ( S ( 1 : K ) .</sentence>
				<definiendum id="0">SETL</definiendum>
				<definiens id="0">contains both a general dath vb ject ( the set ) and other operationally more efficient structures known as atoms</definiens>
				<definiens id="1">5 ) integers ( .1276 ) character strings ( 'hel.10 , pally ' ) bit strings ( 10101b ) boolean constants ( true lbr false E Ob ) blank atoms ( created by the function NEWAT , the SETL equivalent of the LISP GENSYM ) Q , the undefined atom labels ( labels precede s tatcments , separated by a colon ) subroutines and functions tuples ( one-dimensional arrays of variable length ; i. e. , ordsred lists</definiens>
				<definiens id="2">the null tuple is designated nult ) Sets are unordered collections of elements , written as { 1,2 , ' three ' ) : he null set is designated nR Oper at OPS Integers arithmetic + * , comparison ( eq , ne , it , gt , lc , gel max , min , abs Booleans and , or , hot ( abbreviated n ) , cq , ne Character and bit strings concatenatiton *</definiens>
			</definition>
			<definition id="26">
				<sentence>is the string of length X starting with the Ith element , like tb~ PL/I s &amp; string function ) Tuples A tuple is a sequence of components Cl , ,C2 , C3 , . . . , all but a finite number of which are equal to R , the undefined atom ( 1 ) T ( K ) is the Kth component of T ( 2 ) T ( 1 : K ) is the tuple of length K starting with the Ith element ( 3 ) # T ds the index of the last defined component of T ( 4 ) hd T E T ( 1 ) tR T I T ( 2 : ( # T-1 ) ) T -+ U is the concatenation of tuples T and U Tuples are often used as push-down stacks , using T ( # Ttl ) = X to push X on the stack and T ( # T ) = 8 to pop the stack .</sentence>
				<definiendum id="0">Tuples A tuple</definiendum>
				<definiens id="0">a sequence of components Cl , ,C2 , C3 , . . . , all but a finite number of which are equal to R , the undefined atom ( 1 ) T ( K ) is the Kth component of T ( 2 ) T ( 1 : K ) is the tuple of length K starting with the Ith element ( 3 ) # T ds the index of the last defined component of T ( 4 ) hd T E T ( 1 ) tR T I T ( 2 : ( # T-1 ) ) T -+ U is the concatenation of tuples T and U Tuples are often used as push-down stacks , using T ( # Ttl ) = X to push X on the stack and T ( # T ) = 8 to pop the stack</definiens>
			</definition>
			<definition id="27">
				<sentence>A R ( difference , set ) # S ( numbernof elements in set S ) A with B 2 A U ( B ) A less B = Aw { B } sets may be compared using eq , ne , incs ( in'cludes ) Precedence There .</sentence>
				<definiendum id="0">R</definiendum>
			</definition>
			<definition id="28">
				<sentence>The range-restriction is a series of items , one for each of the X of the form i For example , Two abbreviated forms are allowed : { X E S I C ( X ) ] foe , Ix , ,X E S I 'C ( X ) I and IEXPR ( X ) , XES } for { E ?</sentence>
				<definiendum id="0">range-restriction</definiendum>
				<definiens id="0">a series of items</definiens>
			</definition>
			<definition id="29">
				<sentence>if X gt 0 then Y else X + Y is analyzed as ( if X gt 0 then Y else X ) + Y Functional Application and Sets If F is a set and A any set or atom then ( 1 ) F { A ] ( if # P gt 2 then tR P else P ( 2 ) , P E F I ( `` P is a tuple '' ) and ( # P gt 2 ) and ( P ( 1 ) eq A ) 1 e.g. , if F is a set of pairs , F { A ) is the set of all X such that &lt; A , X &gt; E F. ( 2 ) F ( A ) if # F { A } eq 1 then grb F { A ) else $ 2 .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">else X ) + Y Functional Application and Sets If F is a set and A any set</definiens>
				<definiens id="1">a tuple ''</definiens>
				<definiens id="2">a set of pairs , F { A ) is the set of all X such that &lt; A , X &gt; E F. ( 2 ) F ( A ) if # F { A } eq 1 then grb F {</definiens>
			</definition>
			<definition id="30">
				<sentence>Assignment A = EXPR ; &lt; ArB , C &gt; = EXPR ; is the same as A=EXPR ( l ) ; B=EXPR ( 2 ) ; C=EXPR ( 3 ) t Assignment may also be done with the operator `` is '' : `` EXPR is V '' is an expression with value &amp; XPR and the side effect of assigning this value to V X in S ; is S = S with X ; X from S ; is X=avb S ; S = S lcss X ; X out S ; is S = S less X ; Transfer go to LABEL ; Conditional if BOOLl then BLOCK , else if BOLL2 then ... else BLOCK ; n ~teration ( while BOOL ) BLOCK ; ( vxl Sit X2 E S2 ( X1 ) , .</sentence>
				<definiendum id="0">EXPR</definiendum>
				<definiendum id="1">n ~teration</definiendum>
				<definiens id="0">X=avb S ; S = S lcss X</definiens>
			</definition>
			<definition id="31">
				<sentence>Scope of Conditionals and Iterators The BLOCK indicated above as the scope of a SETL conditional statement , or iterator is any sequence of SETL statements .</sentence>
				<definiendum id="0">iterator</definiendum>
				<definiens id="0">the scope of a SETL conditional statement , or</definiens>
			</definition>
			<definition id="32">
				<sentence>Functions defined by definef FCN ( X , Y , Z ) ; BLOCK end FCNr invoked by FCN ( A , B , C ) exit from function by return EXPR ; Infix operator definition defined by X infixop Y ; BLOCK end A infixop B ; Scoping local X , Y , Z ; defines X , Y , and Z as local to the current subroutine or function ( these variables are allocated on entry to the routine ) .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiendum id="1">function</definiendum>
				<definiens id="0">local to the current subroutine or</definiens>
			</definition>
			<definition id="33">
				<sentence>[ Loveman 19711 D. Loveman , J. Moyne , and R. Tobey , `` CUE : A Preprocessor System for Restricted , Natural English .</sentence>
				<definiendum id="0">CUE</definiendum>
				<definiens id="0">A Preprocessor System for Restricted</definiens>
			</definition>
			<definition id="34">
				<sentence>[ Shapiro 19711 PShapiro and Dw Stermole , `` ACOEUl ( Automatic Coder Report Narrative ) : An Automatied NaturalLanguage Question-Answering System for Surgicm Reports , `` Computers and Automation , Feb. 1971 , p. 13 .</sentence>
				<definiendum id="0">ACOEUl</definiendum>
				<definiendum id="1">Narrative )</definiendum>
				<definiens id="0">An Automatied NaturalLanguage Question-Answering System</definiens>
			</definition>
</paper>

		<paper id="1057">
			<definition id="0">
				<sentence>Possible decompositionsof the word `` formally '' are 1 t detected as foklows ( R represents root1 ' and $ , tlsuf-fix '' ) : form ( R ) + a1 ( S ) + ly ( S ) f om ( R ) + ally ( R ) for .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">represents root1 ' and $ , tlsuf-fix '' ) : form ( R ) + a1 ( S ) + ly ( S ) f om ( R ) + ally</definiens>
			</definition>
			<definition id="1">
				<sentence>( R ) , + mall ( R ) + y ( S ) form ( R ) + all ( R ) + y ( S ) It is clear that the correct decomposition is the only candidate having the form of a single root followed by suffixes .</sentence>
				<definiendum id="0">decomposition</definiendum>
				<definiens id="0">+ mall ( R ) + y ( S ) form ( R ) + all ( R ) + y ( S ) It is clear that the correct</definiens>
				<definiens id="1">the only candidate having the form of a single root followed by suffixes</definiens>
			</definition>
			<definition id="2">
				<sentence>Stressed Syllable Rule ( cyclic ) Conditions : ( 1 ) Y contains no primary stress ( 2 ) no stress placement to the left of a prefix boundary Case 1 .</sentence>
				<definiendum id="0">Stressed Syllable Rule ( cyclic</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">contains no primary stress ( 2 ) no stress placement to the left of a prefix boundary Case 1</definiens>
			</definition>
			<definition id="3">
				<sentence>Modificakibn : The single required consonant preceding the ~rimary stressed vowel has been changed from C ; ( zero oz one consonane to C one consonant ) so that pre-vocalic vowels are not shotcened .</sentence>
				<definiendum id="0">Modificakibn</definiendum>
				<definiens id="0">The single required consonant preceding the ~rimary stressed vowel has been changed from C</definiens>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>We may define an automaton as a quadruple ( f , 9 , 9Int , Suc ) , in which 9 is a ( finite or infinite ) set of states , &amp; is a ( finite or infinite ) language ( i.e. set qf strings of symbols ) , Int is a partial function from 9 X 2 ( the Cartesian product of 9 with $ ) into f ( the input function ) , apd Suc is a relation on f P , -e .</sentence>
				<definiendum id="0">Int</definiendum>
				<definiens id="0">a ( finite or infinite ) set of states , &amp; is a ( finite or infinite ) language ( i.e. set qf strings of symbols ) ,</definiens>
				<definiens id="1">a relation on f P , -e</definiens>
			</definition>
			<definition id="1">
				<sentence>Ibe semantic representation ( * ) , on the assumption 'that istsq have argued that : the relation between sentences and their semantic represeatations is defined by the transformational rules revealed by independently-motivated syntactic analysis fe .</sentence>
				<definiendum id="0">Ibe semantic representation</definiendum>
				<definiens id="0">the relation between sentences and their semantic represeatations is defined by the transformational rules revealed by independently-motivated syntactic analysis fe</definiens>
			</definition>
			<definition id="2">
				<sentence>We begin by defining the set First , we recursively define a set of APL-prop &amp; ties : any positive or negative real number is a numeric APLproperty of dimension # ; any character on the APL keyboard ( i.e. any of a-fipite set of characters whose identity does not concern us ) is a literal &amp; property of dimension @ ; for any integer I n and integer-string D , any n-length string over the set of numerio ( literal ) APL-properties of dimedion D is A a numeric ( literal ) APL-property of dimension -D % . '</sentence>
				<definiendum id="0">keyboard</definiendum>
				<definiens id="0">any positive or negative real number is a numeric APLproperty of dimension # ; any character on the APL</definiens>
			</definition>
			<definition id="3">
				<sentence>An APEstate is a finite set of APL-objects in which no distinct objects bear the same identifier .</sentence>
				<definiendum id="0">APEstate</definiendum>
				<definiens id="0">a finite set of APL-objects in which no distinct objects bear the same identifier</definiens>
			</definition>
			<definition id="4">
				<sentence>~r denotes the function taking any programming act into a etring of integers representing the time of day at which it occurs .</sentence>
				<definiendum id="0">~r</definiendum>
				<definiens id="0">the function taking any programming act into a etring of integers representing the time of day at which it occurs</definiens>
			</definition>
			<definition id="5">
				<sentence>SucdpL is the empty relation : every -state is a stopping state .</sentence>
				<definiendum id="0">SucdpL</definiendum>
				<definiendum id="1">relation</definiendum>
				<definiens id="0">the empty</definiens>
			</definition>
			<definition id="6">
				<sentence>( Ct is a moot point within linguistics whether the dee structures of English sentences have 'the ordering subject-ver _ % -obJect or verb-subjectobject . )</sentence>
				<definiendum id="0">Ct</definiendum>
				<definiens id="0">a moot point within linguistics whether the dee structures</definiens>
			</definition>
			<definition id="7">
				<sentence>Thus , subordinate clauses ( non-root 'Sf constituents ) have that prefixed to them ( replacing the in case the latter w appears ) ; nouns not preceded by the are pupplied with -a/= ; 'the NP of IEf may become 'IE 's HE '' in some cases ; wh is real+ I+IW ized as who , which , or that and is fronted .</sentence>
				<definiendum id="0">non-root 'Sf constituents</definiendum>
				<definiendum id="1">wh</definiendum>
				<definiens id="0">real+ I+IW ized as who , which , or that and is fronted</definiens>
			</definition>
			<definition id="8">
				<sentence>Then a pair 24 ( M , Foc ) in which ( i ) I , M is a aemiforest over Pred such that 23~ , treat the distinction between he and s e as determined rather than as needing to be marked in % e seman + ic representation : in the standard use of English pronouns ( leaving out of account the special rules operating under contrastive stress ) , &amp; is appropriate only if the intended referent is the nearest individual referent of all to the hea .</sentence>
				<definiendum id="0">M</definiendum>
				<definiens id="0">a aemiforest over Pred such that 23~ , treat the distinction between he and s e as determined rather than as needing to be marked in % e seman + ic representation</definiens>
				<definiens id="1">the special rules operating under contrastive stress</definiens>
			</definition>
			<definition id="9">
				<sentence>A semiforest over a vocabulary V-is a triple ( D , 6 , # ) where D is a set st oodea , 8 is a part-izl function of immediate domin'ce iron D Sntxings over D such that every node is dodnated ( not necessarily immedigtely -dominate is the ancestral of 'imedistely dominate ' ) by at least one root ( i. e. undominated node ) , anQ oc is a partial function of lamin from D into V. Nodes outside the domain of 6 are leaves -- Y-+ or ermina'l : noded : Note teat , b $ defining the range '6s containing strings , I have built left-to-right ordering into my aefinition ; semiforests as defined here are ~stringsemiforests .</sentence>
				<definiendum id="0">D</definiendum>
				<definiendum id="1">anQ oc</definiendum>
				<definiens id="0">a set st oodea , 8 is a part-izl function of immediate domin'ce iron D Sntxings over D such that every node is dodnated ( not necessarily immedigtely -dominate is the ancestral of 'imedistely dominate ' ) by at least one root ( i. e. undominated node</definiens>
			</definition>
			<definition id="10">
				<sentence>R~~ ( NP~ ) is T r 2 ; by R3 , since % is two edges from 2 while I &amp; is -3 ' -6 eight edges from r2 , Ref ( IE6 ) is fr3 ] ( John1 -s fish denotes the fish that John ate , on this omasion ) .</sentence>
				<definiendum id="0">R~~</definiendum>
				<definiens id="0">T r 2 ; by R3 , since % is two edges from 2 while I &amp; is -3 ' -6 eight edges from r2</definiens>
			</definition>
			<definition id="11">
				<sentence>IUerdag , then according to the rules I have laid down his topicon acquires a § ( oar ) ~rhk referent representing John 's new car .</sentence>
				<definiendum id="0">IUerdag</definiendum>
				<definiens id="0">~rhk referent representing John 's new car</definiens>
			</definition>
			<definition id="12">
				<sentence>The fact that the referent of Baskolnikov will have the property $ ( fictional ) while that of Richard Nixon has the property P -§ ( real ) is no mode reason to distinguish sentences ( 27 ) and ( 28 ) from sentences about Richard Nixon and Spiro Agnew syntactically than is the fact that the referent of Raskolnikov has the property J ( ~ussian ) while that of : Nixon has the property § ( ~merican ) .</sentence>
				<definiendum id="0">Nixon</definiendum>
				<definiens id="0">no mode reason to distinguish sentences ( 27 ) and ( 28 ) from sentences about Richard Nixon and Spiro Agnew syntactically than is the fact that the referent of Raskolnikov has the property J ( ~ussian ) while that of :</definiens>
			</definition>
</paper>

		<paper id="1052">
			<definition id="0">
				<sentence>rmors ( AND + SUBJECT ) conjoined Hearsay ( SUBJECT ) the ASSERTION string , which consists of the elements SUBJECT + TENSE + VERB + OBJECT .</sentence>
				<definiendum id="0">ASSERTION string</definiendum>
				<definiens id="0">consists of the elements SUBJECT + TENSE + VERB + OBJECT</definiens>
			</definition>
			<definition id="1">
				<sentence>ANDSTG consists of and followed by the general conjunctional string Q-CONJ .</sentence>
				<definiendum id="0">ANDSTG</definiendum>
				<definiens id="0">consists of and followed by the general conjunctional string Q-CONJ</definiens>
			</definition>
			<definition id="2">
				<sentence>Q-CONJ contains a restriction which generates a definition for Q-GQNJ .</sentence>
				<definiendum id="0">Q-CONJ</definiendum>
				<definiens id="0">contains a restriction which generates a definition for Q-GQNJ</definiens>
			</definition>
			<definition id="3">
				<sentence>The LSP grammar consists of approximately 3500 lines .</sentence>
				<definiendum id="0">LSP grammar</definiendum>
			</definition>
			<definition id="4">
				<sentence>The OBJECT ( the rumors ) has no ' conjunct but the VERB does .</sentence>
				<definiendum id="0">OBJECT</definiendum>
			</definition>
			<definition id="5">
				<sentence>i 1 ) NULLC is in a conjunctional string -- the string headed by but .</sentence>
				<definiendum id="0">NULLC</definiendum>
				<definiens id="0">in a conjunctional string -- the string headed by but</definiens>
			</definition>
</paper>

		<paper id="1044">
			<definition id="0">
				<sentence>The conceptual categories between which the various conceptdal dependencies exist are ACT , PP ( lfpicture produceru ) and PA ( `` picture assistcr~ ) , At tho eyntaoti~ level , these categories are sometimes em premed in the English language by verbs , nouns and adjectives respectively .</sentence>
				<definiendum id="0">PA</definiendum>
				<definiens id="0">sometimes em premed in the English language by verbs , nouns and adjectives respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus 'thinkt in the sense of mentd activity ( 'think about ' ) involves an l1activeW abject : md says &lt; ornething about the present state of the thinking person , but 'believet or 'know1 represents a llstorcdu rather th'tn an active object. This diLierence is expressed through representation of 1 ; as CP ( Conscious 1hcessor ) and UIEi for ' think an3 'believe respectivcly. There is no value ssigned to cl for this sense of 'thinkv , slnce o truth value is not assigned to a I.LE ; T.~L object e : ; cept in the process of rorning n bclief or making an assumption. The SL~ ? -~ORY level can be illustrated bficfly by reference to the rel , rcscntation of conccptual attributes in terr~.s of this level. 'Be jut if ul ' is dm'ined by prir-itivc components on the 'visualt sublevel : 'oE : 'hOK\ ; ( cye ) VAL : AV=+ ' or , 'a visually perceived , ac. ; thetically positive attribute of an objectt. All three non- ? : iYSIGJ , levels involve objects G which are non-mterial , i.e. not PPa. Rather the object is a form of inf ormction , inage or control for the IIZNTAL , SLYSOX and CONTR ) L levels rcspectivcly. .JL of thebc objects , which night bt thought of conceptually as verb : 1 or attrizutive concepts , hove a l'relationshipU only to a true exeriencer , i.e. an animate B. .it the r'hY &amp; IC &amp; level , on the other hand , R need not be animate. The PHYbXCAL level reflects only the physical nspcct of the relationship expressed by a VE1.B ; R may h. , ppen to be animate , but the animate aspcct is irrelevant to khis lcvel. This rnezins thLtt 'have in the genr ; e John has the ncwspapert is nssicned to the CON'IXOL lcvel rather thi~n to the PIT~~uAL. However , a IJIIYsItiAL relationhip , as exoressed by ' John has the newspaper on his head1 or ' ... in front of himt , could be derived 3s an inference of the CONTJiO Llevel * have *. Representative verb forxs for LtlA. : '' Gs at the PHY , IL~AL level follow : ACTUAI , POTENT I &amp; R have as part contain have on 0 be connected to be in be on be at be ne.tr VAL be almost be be -value &gt; e , g. be red The Rand 0-VERBS correspond to relctions between PPs identified in ( 5 ) ( IN , ON , AT , PRDX ) , whereas the VAL VERBS are conceptual attributes -- PA dependencies on IPS , The ACTUAL/ liQTWIAL distinction as described above does not strictly apply to the IJIIYbIC~ &amp; level , for in one sense all P : IYSIC ; LL relationships are nactuellf .</sentence>
				<definiendum id="0">mentd activity</definiendum>
				<definiendum id="1">l1activeW abject</definiendum>
				<definiens id="0">levels involve objects G which are non-mterial , i.e. not PPa. Rather the object is a form of inf ormction , inage or control for the IIZNTAL , SLYSOX and CONTR ) L levels rcspectivcly. .JL of thebc objects , which night bt thought of conceptually as verb : 1 or attrizutive concepts</definiens>
				<definiens id="1">whereas the VAL VERBS are conceptual attributes -- PA dependencies on IPS</definiens>
			</definition>
			<definition id="2">
				<sentence>To a large extent , the. ; c expectations are concerncu with finding in the sentence being pdrsed an object which conf~ms to basic sem : nric re uirements ~ovcrning t'-e depenuenc of that object on a verb which has appeared in the sentence .</sentence>
				<definiendum id="0">c expectations</definiendum>
				<definiens id="0">concerncu with finding in the sentence being pdrsed an object which conf~ms to basic sem : nric re uirements ~ovcrning t'-e depenuenc of that object on a verb which has appeared in the sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>ty came to the country Not interpreted : rrosperity was occupi~d Prosperity cimo to : -he choir d ) Level Shift with R-0 Switch ( tried when nc &gt; base -interpretation is found ur when implied source ( goal ) is not explicitly present ) : 1 ) Source or goo1 ( temporarily assigned rolc kt ) has level bLNT '' U , , sF : Kx ?</sentence>
				<definiendum id="0">base -interpretation</definiendum>
				<definiens id="0">-he choir d ) Level Shift with R-0 Switch ( tried when nc &gt;</definiens>
			</definition>
			<definition id="4">
				<sentence>SEIQSORY CONTROL : Their rights disappeared one by one .</sentence>
				<definiendum id="0">SEIQSORY CONTROL</definiendum>
				<definiens id="0">Their rights disappeared one by one</definiens>
			</definition>
			<definition id="5">
				<sentence>rch is the hnglish verb v think1 , which x~ould corres !</sentence>
				<definiendum id="0">rch</definiendum>
				<definiens id="0">the hnglish verb v think1 , which x~ould corres</definiens>
			</definition>
			<definition id="6">
				<sentence>il is TK ( : iT. ; TE ( 0 AT R ) ) .</sentence>
				<definiendum id="0">TK</definiendum>
			</definition>
			<definition id="7">
				<sentence>: 2 ) ( EI , U~D - ) ( CX - ) ( ANIM + ) ( ) IZI - ) ( DYN + ) ( FX : AC~IPR ( LIYS ) ) 1 ) ( NIND ( ( zI~S P ) ( PAIIT ( ANIN +j ) ( COST + ) ( FIYSD + ) ( 11 ) + ) ( SII=IPE + ) ' ( FI , UID - ) ( CX + ) ( , &lt; XIM t ) ( 1 - ) ( DYX + ) ( FN. ( T~IIUK ) ) ) ) [ SHIP ( ( PII ) ( ~~111~ - ) ( CONT + ) ( FISI : ~~ - ) ( ID i ) 5 ( 2~ - ) ( s ! I , 'IF &amp; + ) ( sIzS 3 ) ( FL-UID - ) ( CY i ) ( ASI ? I - ) ( &gt; I ? !</sentence>
				<definiendum id="0">NIND</definiendum>
				<definiens id="0">U~D - ) ( CX - ) ( ANIM + ) ( ) IZI - ) ( DYN + )</definiens>
			</definition>
			<definition id="8">
				<sentence>I + ) ( FN IiYT ( 1~ ) ) ( - ) ) ) ( I.AND ( ( PIT ] 1 - ) ( CONT + ) ( FlX13D + ) [ 1 4 ) ( 2D + ) ( ~11.11'~ - ) ( SIZE ) -3 ) ( F~ , UID - ) ( CY - ) IS I ( UYN t ) ( F : ACTIVE ( I ) RODUCS ) ) ) ) ( SEA ( ( ~11 ) ( P-~RT - ) ( CONT + ) ( FIS~ &lt; II + ) ( 2~ i- ) ( 2~ t ) ( SITAPT + ) ( SIZE 4 ) ( FLUID + ) ( CX - ) ( .~IJI - ) ( 3~s - ) ( DW t ) ( FN : LOC ( IE ) ) ) ) [ COUNTRY ( ( PII ) ( PART - ) CON^ + ) ( FIXED + ) ( ID t- ) ( 2~ + ) ( S ! L ! PB + ) ( sIzS 4 ) ( FLUID - ) ( CX + ) ( ITUW.IN i ) ( I t ) ( &gt; iX + ) ( FN : LOC ( IN AT ) ) ( DYX i ) ( ) ) ) ( IKDIFFERENcE E A ) ( STATE ( 0 AT R ) ( v.4~ +- ) ) ) ( ~'ROSPERITY ( ( CO B PlI ) ( STA~E ( 0 AT R ) ( VAL + ) ( XYT &gt; ) ) ) FIGURE 2Cont inucd ( DISINTEGRATE ( ( PI { ) TR-L ( STATE ( 0 BE ) ) ( ROLE 0 ) ( AGBNT - ) ( 0 ( NRW ( BRD 1 ) 1 ) ( LEAP-TO ( ( PII ) TR-E ( STATE '0 AT R ) ) ( INTNS ) ( ~01 .</sentence>
				<definiendum id="0">IKDIFFERENcE E A )</definiendum>
				<definiendum id="1">STATE (</definiendum>
				<definiendum id="2">LEAP-TO</definiendum>
				<definiens id="0">ACTIVE ( I ) RODUCS ) ) ) ) ( SEA ( ( ~11 ) ( P-~RT - ) ( CONT + ) ( FIS~ &lt; II + ) ( 2~ i- ) ( 2~ t ) ( SITAPT + )</definiens>
				<definiens id="1">DW t ) ( FN : LOC ( IE ) ) ) ) [ COUNTRY ( ( PII ) ( PART - ) CON^ + ) ( FIXED + )</definiens>
				<definiens id="2">FLUID - ) ( CX + )</definiens>
				<definiens id="3">0 AT R ) ( v.4~ +- ) ) ) ( ~'ROSPERITY ( ( CO B PlI ) ( STA~E ( 0 AT R ) ( VAL + ) ( XYT &gt; ) ) ) FIGURE 2Cont inucd ( DISINTEGRATE ( ( PI { ) TR-L ( STATE ( 0 BE ) ) ( ROLE 0 )</definiens>
			</definition>
</paper>

		<paper id="1071">
			<definition id="0">
				<sentence>An SR can either reference a static locatioh ( the Location case ) , place of origin ( the Source case ) , place of termination ( the Goal case ) , or location of intermediate motion ( the Path case ) .</sentence>
				<definiendum id="0">static locatioh</definiendum>
				<definiens id="0">the Location case ) , place of origin ( the Source case ) , place of termination ( the Goal case ) , or location of intermediate motion</definiens>
			</definition>
			<definition id="1">
				<sentence>V. Static Adjunct , Complement and Qualifier usages Section I describes our basic claim : the source of the locations being referenced by SB 's can be represented as being the locations of events and states of affairs .</sentence>
				<definiendum id="0">SB</definiendum>
				<definiens id="0">the source of the locations being referenced by</definiens>
			</definition>
			<definition id="2">
				<sentence>Motional events involve the location over time of moving objects .</sentence>
				<definiendum id="0">Motional events</definiendum>
				<definiens id="0">involve the location over time of moving objects</definiens>
			</definition>
			<definition id="3">
				<sentence>BILL REGULATING EFTS ImRODUCED IN HOUSE A bill that would extend Federal regulation to include control over electronic funds transfer systems ( EFTS ) was introduced in the House of ~e~resentatives in July by Rep. Wary Rose maker ( D-Ohio ) .</sentence>
				<definiendum id="0">BILL REGULATING EFTS ImRODUCED IN HOUSE</definiendum>
				<definiens id="0">A bill that would extend Federal regulation to include control over electronic funds transfer systems ( EFTS ) was introduced in the House of ~e~resentatives in July by Rep. Wary Rose maker</definiens>
			</definition>
			<definition id="4">
				<sentence>NASA , ILLINOIS INSI'IlUTE OF 'TECHNOLOGY SURVEY USER NEEDS FOR VLSCS The Ames Research Center of the National Aeronautics and Space Administration ( NASA ] and the Illinois Institute of Technology last month began conducting OCTOBER , 1977 AF I PS ' WASI-1INGTON REPORT a survey to detehaine projected user needs for very large scientific 831 computer systems ( VLSCS ) which might become available in the 1985-1990 time period .</sentence>
				<definiendum id="0">VLSCS</definiendum>
				<definiens id="0">a survey to detehaine projected user needs for very large scientific 831 computer systems</definiens>
			</definition>
			<definition id="5">
				<sentence>The National Science Foundat ion ' s ( NSF ) Research Applied to National Needs ( RANN ) program has been discontinued ; according to an article in the September 5 , 1977 , issue of Chemical &amp; mgineering News , NSF Director Richard C. Atkinson abolished the program because he is said to favor distribution of RANN projects throughout the NSF .</sentence>
				<definiendum id="0">NSF</definiendum>
				<definiens id="0">NSF Director Richard C. Atkinson abolished the program because he is said to favor distribution of RANN projects throughout the NSF</definiens>
			</definition>
			<definition id="6">
				<sentence>Apparently disregarding an earlier statement contained in its interim report that it may become appropriate to have a Governmental operational role in point-of-sale ( POS ) switching and clearing facilities to insure an effective national payments system , the Commission ( in its final report ) concluded that the Federal government should `` not be involved 84 operationally , at present or in the forseeable futurev in POS switches .</sentence>
				<definiendum id="0">Commission</definiendum>
			</definition>
			<definition id="7">
				<sentence>, [ as well as ] standardize invoice and billing systems.11 In the area of security , the Commission recommends joint state and Federal action to develop uniform security regulation and security supervision .</sentence>
				<definiendum id="0">Commission</definiendum>
				<definiens id="0">recommends joint state and Federal action to develop uniform security regulation and security supervision</definiens>
			</definition>
			<definition id="8">
				<sentence>UMMENT OF DATA CQMMUNICATICNS Thc Fedem1 Ctmunmications Commission ( FCC ) should develop standard measurerat of the quality and reliability of data colmrmnications service provided by specialized cmon carriers , the Department of Commerce 's Office of Telscaunicaticms ( OT ) said in an August filing to the FCC .</sentence>
				<definiendum id="0">UMMENT OF DATA CQMMUNICATICNS Thc Fedem1 Ctmunmications Commission</definiendum>
				<definiens id="0">develop standard measurerat of the quality and reliability of data colmrmnications service provided by specialized cmon carriers , the Department of Commerce 's Office of Telscaunicaticms ( OT ) said in an August filing to the FCC</definiens>
			</definition>
			<definition id="9">
				<sentence>Established in 1961 , ADAPSO is a trade association representing the computer services industry , i. e. , companies engaged in providing timesharing , facilities management , software systems and products , and data center services .</sentence>
				<definiendum id="0">ADAPSO</definiendum>
				<definiens id="0">a trade association representing the computer services industry , i. e. , companies engaged in providing timesharing , facilities management , software systems and products , and data center services</definiens>
			</definition>
			<definition id="10">
				<sentence>With national headquarters in Montvale , New Jersey , the association consists of a professional staff directed by Mr. Jerome L. Dreyer , executive vice president , who is responsible for overall operat ions .</sentence>
				<definiendum id="0">association</definiendum>
				<definiens id="0">consists of a professional staff directed by Mr. Jerome L. Dreyer , executive vice president , who is responsible for overall operat ions</definiens>
			</definition>
</paper>

		<paper id="1055">
			<definition id="0">
				<sentence>It is hoped that the newly reactivated membership* CoKtmfttee , under the chairmanship of John liqoyne , will be able to devise creative ansNers to this chronic problem , In an organization such as Oars , where the association 1s almost entirely dependent On the payment of annual dues , even a slight drop in membership causes serious problems , This years financial situation was further exacerbated bv three additional things : ACL secretary-Treasurer s Report , h , Uctober 197b Page 8 I. he coptinued , unreal st ically low dues rare of s~O , for whipp members .</sentence>
				<definiendum id="0">ACL secretary-Treasurer</definiendum>
				<definiens id="0">s Report , h</definiens>
			</definition>
			<definition id="1">
				<sentence>~cprovcntation and Understanding 24 I11 1 dcscribcs thc scopc , has ic ~llc~tl~odology , : ind : ic ] ~jcvcmcnt s of SII , n kno~~rlrdgc-l~ : ~sc~cl computr~ ; ~idcd instrustion ( CAI ) by asking qucstions , : ~nswcr .</sentence>
				<definiendum id="0">~cprovcntation</definiendum>
				<definiens id="0">thc scopc , has ic ~llc~tl~odology , : ind : ic ] ~jcvcmcnt s of SII</definiens>
			</definition>
			<definition id="2">
				<sentence>innate auditory templates in humans .</sentence>
				<definiendum id="0">innate auditory</definiendum>
				<definiens id="0">templates in humans</definiens>
			</definition>
			<definition id="3">
				<sentence>Studdert-Kennedy provides a The Role of Speech in Lilnyuayc careful survey of the current empirical evidence concerning the perceptual processing of consonants and vowels , from which he concludes that the `` human cortex is supplied with sets of acoustic detectors tuned to speech , each inhibited from output to the phonetic system in the absence of collateral response in other detectors '' .</sentence>
				<definiendum id="0">Studdert-Kennedy</definiendum>
				<definiens id="0">provides a The Role of Speech in Lilnyuayc careful survey of the current empirical evidence concerning the perceptual processing of consonants</definiens>
			</definition>
			<definition id="4">
				<sentence>The polynomials we will use have terms of the form ( Z , A ) , where Z is a string aver aa extended alphabet and A represents a sequence of productions of G. The process begins with a polynomial of ordered pairs representing X , the string to be parsed .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiens id="0">the string to be parsed</definiens>
			</definition>
			<definition id="5">
				<sentence>If the resulting polynomial contains a term ( S , A ) where S is the starting symbol in G , then A repLresents the production sequence used in generating x Esom S. If no such pair occurs , then x is not in L ( G ) , and if multiple pairs I occur ( S hl ) , ( 5 'A2 ) . . . then x is ambiguous and the A s specify the several parses .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">the starting symbol in G , then A repLresents the production sequence used in generating x Esom S. If no such pair occurs</definiens>
			</definition>
			<definition id="6">
				<sentence>Algebraic preliminaqies , and notation A semigroup is formally defined as an ordered pair &lt; S , -i where S is a set ( the carrier ) znd ' is an associative binary operation. Similarly , a monoid is a triple consisting of a set , an operation and a two-sided identity ( e.g. , s , ) We will feel free to denote a monoid or semigroup by its cerrier. * For any set V , V denotes the free monoid generated by V ; * * + V = &lt; V , concatenation , n &gt; .</sentence>
				<definiendum id="0">Algebraic preliminaqies</definiendum>
				<definiendum id="1">notation A semigroup</definiendum>
				<definiendum id="2">monoid</definiendum>
				<definiendum id="3">V</definiendum>
				<definiens id="0">an ordered pair &lt; S , -i where S is a set ( the carrier</definiens>
				<definiens id="1">a triple consisting of a set , an operation and a two-sided identity ( e.g. , s , ) We will feel free to denote a monoid or semigroup by its cerrier. * For any set V ,</definiens>
				<definiens id="2">the free monoid generated by V ; * * + V = &lt; V , concatenation , n &gt;</definiens>
			</definition>
			<definition id="7">
				<sentence>Similarly , V denotes the -free semigroup + generated by .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the -free semigroup + generated by</definiens>
			</definition>
			<definition id="8">
				<sentence>r ; V+ = &lt; V , concatenat ion ) . We denote the length of a * + string X in 7 or V by 1x1. For an arbitrary alphabet V , we define = E ; ~V~VI. The free half-group generated by V , H ( V ) , is defined to be the monoid generated by V u 9 together'with the relation aa = 1 , where 1 is the monoid identity and a s any element of V. Note that in H ( V ) the elements of 7 are left inverses but not right inverses of the co.rresponding elements of V. We denote the extended alphabet If T = &lt; ~ , *,1 &gt; and Q = &lt; ~ , +,0 &gt; are monoids , we deno .</sentence>
				<definiendum id="0">1</definiendum>
				<definiens id="0">= &lt; V , concatenat ion ) . We denote the length of a * + string X in 7 or V by 1x1. For an arbitrary alphabet V</definiens>
				<definiens id="1">the monoid identity and a s any element of V. Note that in H ( V ) the elements of 7 are left inverses but not right inverses of the co.rresponding elements of V. We denote the extended alphabet If T</definiens>
			</definition>
			<definition id="9">
				<sentence>The carrier of T Q is the cartesian product T Q and the operation @ is defined to be the component-wise operation of T and 0 : A semiring is an alzebraic system &lt; S , + , , O &gt; such that &lt; S , + , O &gt; is a commutative monoid , &lt; S , m &gt; is a semigroup , and the operation distributes over + : am .</sentence>
				<definiendum id="0">semiring</definiendum>
				<definiens id="0">an alzebraic system &lt; S , + ,</definiens>
			</definition>
			<definition id="10">
				<sentence>( b+c ) = a*b + aec , ( a+b ) *c = a-c + b*c. A semiring is commutative if the operation is commutative , A semiring with identity is a system &lt; ~ , + ; ,0,1 &gt; where &lt; s , + ; , O ) is a monoid. The semirings used in this paper are commutati~re and have identities. Furthermore , in each case the additive identity is a multiplicative zero : 0-x = x-0 = 0. The boolean sem % ring B consists of the carrier { 0,1 ] under the comrn~tat~ve operations + and * , where 1-1 = l+x = I. and 0+0 = O*x = 0 for all x E I0 , l ) . For an arbitrary monoid M we denote by R ( M ) the baniring of polynomials described as follows : 1 ) Each tern is of the form ca where c E B ( the boolean serniring of coefficients ) and rx E M. 2 ) Each polynomial is a formula sum ( under + ) of a finite number of terms. 3 ) Addition and multiplication of terms is defined as follows : a ) bu + crx = ( b -fc ) a b ) ( ba ) ( cB ) = ( be ) bP ) . 4 ) Addition a , nd multiplication of polynomials is performed in the usual manner consistent with 3 ) . Note that all coef iicients of R ( M ) arc either 1 or 0. We wi 11 adopt the usual convention of not explicitly writing 1 for the terms with that coefficient and omitting telms with a coefficient of 0. A -- context-free grammar is a system G = &lt; VN , VT , P , S &gt; where VN and V are finite , disjoint , non erlpty sets denoted non-terminal and T terminal symbols respectively .</sentence>
				<definiendum id="0">, O )</definiendum>
				<definiens id="0">a*b + aec , ( a+b ) *c = a-c + b*c. A semiring is commutative if the operation is commutative , A semiring with identity is a system &lt; ~ , + ; ,0,1 &gt; where &lt; s , + ;</definiens>
				<definiens id="1">a monoid. The semirings used in this paper are commutati~re and have identities. Furthermore , in each case the additive identity is a multiplicative zero : 0-x = x-0 = 0. The boolean sem % ring B consists of the carrier { 0,1 ] under the comrn~tat~ve operations + and * , where 1-1 = l+x = I. and 0+0 = O*x = 0 for all x E I0 , l ) . For an arbitrary monoid M we denote by R ( M ) the baniring of polynomials described as follows : 1 ) Each tern is of the form ca where c E B ( the boolean serniring of coefficients ) and rx E M. 2 ) Each polynomial is a formula sum ( under + ) of a finite number of terms. 3 ) Addition and multiplication of terms is defined as follows : a ) bu + crx = ( b -fc ) a b ) ( ba ) ( cB ) = ( be ) bP ) . 4 ) Addition a , nd multiplication of polynomials is performed in the usual manner consistent with 3 ) . Note that all coef iicients of R ( M ) arc either 1 or 0. We wi 11 adopt the usual convention of not explicitly writing 1 for the terms with that coefficient and omitting telms with a coefficient of 0. A -- context-free grammar is a system G = &lt; VN , VT , P , S &gt; where VN and V are finite , disjoint , non erlpty sets denoted non-terminal and T terminal symbols respectively</definiens>
			</definition>
			<definition id="11">
				<sentence>The N symbol S is the distinguished nonterminal from which all derivations begin , and P 2s the set of productions of G. A context-free grammer is proper if it does not contain productions of thz form A -+ c ( erasures ) or A B where A and E are both nonterminals .</sentence>
				<definiendum id="0">N symbol S</definiendum>
				<definiendum id="1">E</definiendum>
				<definiens id="0">the distinguished nonterminal from which all derivations begin , and P 2s the set of productions of G. A context-free grammer is proper if it does not contain productions of thz form A -+ c ( erasures ) or A B where A and</definiens>
			</definition>
			<definition id="12">
				<sentence>The algebraic structure used in this work is the semiring of polynomials R ( H I* ) where H = H ( v ) I the free half -group generated by V , and I is the in'dex set of the set of proJuctions P. We will .</sentence>
				<definiendum id="0">I</definiendum>
				<definiens id="0">the semiring of polynomials R ( H I* ) where H = H ( v ) I the free half -group generated by V , and</definiens>
			</definition>
			<definition id="13">
				<sentence>An algebraic parsing theorem Theorem ( version 1 ) : Let G = &lt; VN , vT , S , P ) be a proper contextfree grammar. Then there exist homomorphisms L , , g , and ( 5 , 2 '' * and a special polynomial p E R r I ) such that for every T X cz VT ' X = XI -- • X , . Xi ' VT , contains a term A if and only if A is a leftmost derivatim of x from S. Construction for the proof : Let V = v1 IJ Vg be an arbitrary exhaustive division of V : The construction is most economfcal when V and V are disjoint , but 1 2 th $ s is not required. The function v is the homomorphism induced by the following : * v ( a ) = ( a , A ) , a E V and fl is the identity in I . Since v is a homomorphism , v ( A ) = A. The function g is the homomorphism induced by defi-ning g on the generators of the domain as follows : 2i g ( a , A ) contains the term ( a , A ) ; a c V th 2ii. If A -+ abl ... b is the i production n of P and a E V then g ( a , A ) contains 1 2iii. There are no other terns in ga ( a , L ) . Note that because g is a hombmorphism , g ( A ) = 4 , where . ? . * * is the identity of the monoid ( X I ) The function 6 is the canonical homomorphism wh'ich * * coalesces a product in ( C T ) into a single ordered pair by component-wi se mcltiplicati3n of the first entries ( thus allowing cancellation in H ) and catenation of the second entries. For example , * 3 % d. The ~olynomial p is an element of ( .. ' I : ) defined as follows : th 1 r~ production of P then p contains the summand k We adopt the convention that p = A for k ' 0. k Note that since p contains X , p contains A as well as all summands of pJ for j ' k. For notational convenience we adopt the followiag conventions. * * First ; where no ambiguity can result , products in R ( T : T ) of the form will be abbreviated as : No cancellation is implied by this notation since cancellation can not * * occur in R ( c I ) . Second , we define the function 'Yk as follows : where ai E V and p is the polynpmial defined above. Note that. if k &lt; 0 , then y ( a a ... an ) = v ( ala2 , .. a ) and Y~ ( A ) = A. Using k 12 n this notation , we can re-state the theorem as follows : Theorem ( version 2 ) : Let C = &lt; VN , v~ ' P , S &gt; be a proper context-free grammar .</sentence>
				<definiendum id="0">algebraic parsing theorem Theorem</definiendum>
				<definiendum id="1">function v</definiendum>
				<definiendum id="2">v</definiendum>
				<definiendum id="3">function g</definiendum>
				<definiendum id="4">b</definiendum>
				<definiendum id="5">g</definiendum>
				<definiendum id="6">~olynomial p</definiendum>
				<definiendum id="7">function 'Yk</definiendum>
				<definiens id="0">( version 1 ) : Let G = &lt; VN , vT , S , P ) be a proper contextfree grammar. Then there exist homomorphisms L , , g , and ( 5 , 2 '' * and a special polynomial p E R r I ) such that for every T X cz VT ' X = XI -- • X , . Xi ' VT , contains a term A if and only if A is a leftmost derivatim of x from S. Construction for the proof : Let V = v1 IJ Vg be an arbitrary exhaustive division of V : The construction is most economfcal when V and V are disjoint</definiens>
				<definiens id="1">the homomorphism induced by the following : * v ( a ) = ( a , A ) , a E V and fl is the identity in I</definiens>
				<definiens id="2">the homomorphism induced by defi-ning g on the generators of the domain as follows : 2i g ( a , A ) contains the term ( a , A ) ; a c V th 2ii. If A -+ abl ...</definiens>
				<definiens id="3">the canonical homomorphism wh'ich * * coalesces a product in ( C T ) into a single ordered pair by component-wi se mcltiplicati3n of the first entries</definiens>
				<definiens id="4">an element of ( .. ' I : ) defined as follows : th 1 r~ production of P then p contains the summand k We adopt the convention that p = A for k ' 0. k Note that since p contains X , p contains A as well as all summands of pJ for j ' k. For notational convenience we adopt the followiag conventions. * * First ; where no ambiguity can result , products in R ( T : T ) of the form will be abbreviated as : No cancellation is implied by this notation since cancellation can not * * occur in R ( c I )</definiens>
				<definiens id="5">where ai E V and p is the polynpmial defined above. Note that. if k &lt; 0 , then y ( a a ... an ) = v ( ala2 , .. a ) and Y~ ( A ) = A. Using k 12 n this notation , we can re-state the theorem as follows : Theorem ( version 2 ) : Let C = &lt; VN , v~ ' P , S &gt; be a proper context-free grammar</definiens>
			</definition>
			<definition id="14">
				<sentence>+ Lemma J : Let M E V , n A E V , and A -M. Then for all k ' h ( A ) , k 6g \Ykcm ) contains ( A , A ) .</sentence>
				<definiendum id="0">A -M. Then</definiendum>
				<definiens id="0">Let M E V , n A E V</definiens>
			</definition>
			<definition id="15">
				<sentence>If pi represents an arbitrary summand of p other than PL , then every k term of g Y ( a ) can be represented in the form k where 0 r n &lt; k and n denotes the number of nontrivial summands of p which are factors of the term .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of nontrivial summands of p which are factors of the term</definiens>
			</definition>
			<definition id="16">
				<sentence>* Recall is the proportion of relevant material retrieved while precision is the proportion of retrieved material that is relevant .</sentence>
				<definiendum id="0">* Recall</definiendum>
				<definiendum id="1">precision</definiendum>
				<definiens id="0">the proportion of relevant material retrieved while</definiens>
			</definition>
			<definition id="17">
				<sentence>Specifically ; if Q is the density of the document space without term k present among the content indicators , and Qk is the density after term k is assigned , then for a good term Q Qk &gt; 0 , since the space will have spread after term k is assigned .</sentence>
				<definiendum id="0">Qk</definiendum>
				<definiens id="0">the density of the document space without term k present among the content indicators</definiens>
				<definiens id="1">the density after term k is assigned</definiens>
			</definition>
			<definition id="18">
				<sentence>tion value : [ 5 ] a ) terms with yery Low documeht fiequenay that may be assigned to very feQ documents in a collection are generally poor discriminators ; when the terms are arranged in decreasing order of their discriminamtion values ( where rank 1 is asdgned to the best discriminator , rank 2 to the next best , and so on ) such terms exhibit ranks in excess of t/2 for a total of t existing terms ; b ) term3 with high document frequencies , comprising those that are assigned to more than 10 percent of the documents of a collection are the worst discriminators , with average discrimination ranks ( ranks in decreasing discriminatioh value order ) near t ; c ) the best discriminators are those whose document frequency is neither €QO high nor too low -with document frequencies between n/100 and n/10 for n documentq ; their average discrimination ranks are generally belaw t/5 for t terms .</sentence>
				<definiendum id="0">average discrimination ranks</definiendum>
				<definiens id="0">the next best , and so on ) such terms exhibit ranks in excess of t/2 for a total of t existing terms</definiens>
				<definiens id="1">neither €QO high nor too low -with document frequencies between n/100 and n/10 for n documentq ; their average discrimination ranks are generally belaw t/5 for t terms</definiens>
			</definition>
			<definition id="19">
				<sentence>the terBm releva~ke TR ( k ) may be defined as where r and hk are the number of documents containing term k that are k relevant and nonrelevant respect ively to query Q , and I R I and I I I ire the total number of relevant and nonrelevant documents for that query. ; ' When a term k occurs in more than one query , its term relevance may be taken as the average of the relevance values obtained for the various queries .</sentence>
				<definiendum id="0">terBm releva~ke TR ( k )</definiendum>
				<definiens id="0">the number of documents containing term k that are k relevant and nonrelevant respect ively to query Q , and I R I and I I I ire the total number of relevant and nonrelevant documents for that query. ; ' When a term k occurs in more than one query , its term relevance may be taken as the average of the relevance values obtained for the various queries</definiens>
			</definition>
			<definition id="20">
				<sentence>C Example 2 , 90 ANGAS NOLT PHICASE NP POS ADJ KOM DET PL PL T NUH THWA POPNP EOC E &amp; D ANGAS LEXICON LC-AS ' ) = ' ( NOUN ) ( ENG DOG ) * L &lt; 'MAT ' &gt; = ' .</sentence>
				<definiendum id="0">ANGAS NOLT PHICASE NP POS ADJ KOM DET PL PL T NUH THWA POPNP EOC E</definiendum>
				<definiens id="0">&amp; D ANGAS LEXICON LC-AS ' ) = ' ( NOUN ) ( ENG DOG ) * L &lt; 'MAT ' &gt; = '</definiens>
			</definition>
			<definition id="21">
				<sentence>~ ( , VFI~V'~GEZF~'AZJ ) S'~~ tCTO ( , PAS ) ) IS ( TESIF ( *IF ' ) l PA~SECESO ) : F ( FRETUFW , j NP = Q t ( FETURN1 GETF ( , VFp 'V ' , Q ) SE'IF ( , tF , `` TNSr , GETF [ fTUS* ) ] CAT [ 'V ' ) tFCTO ( , TADJ ] ) kORO 'INGC iStTo ( , ING ) I IS [ GETF ( 'VTYP @ ) ) ~'TRANSC ) tFCFRETUPN ) GETF ( 'TNS* ) 'PPRTf tS ( TPPAS ) P [ FRETURN ) VF\z SkTF ( @ VPr 'AUX'r 'RE ' ) Sp-TF ( , VEr 'TMS'r 'PPRG ' ) SETP ( , VP , *VCIQ ) FAPSE ( NP ( ) ) ISCTO~~PRNP ) ) VF = ~~ILUS ( *VP ) PAFSECPFC ) ) ~FGRETURN ) VP = VP 0 tCTO [ , PRPp ) ) SETF ( , VP , *PPNPrpG ] t ( rO ( , POPVP ) ) VP = 'AUXpr 'BE ' ) 'TYFE ' ) , '€2 ' ) SETR ( , VPp 'TNS ' , *PPRTU ) VPES TFPP FIO PNPTS'I PNP FIOL POPVF * I0 IOTO ADD , TO XOFOF TES TWV POPES END CETF ( 'V- ' ) SETP ( ; VP , -p~ ' , ~ ) FAFSECIQ ( ) ) * .</sentence>
				<definiendum id="0">FETURN1 GETF</definiendum>
				<definiendum id="1">rO</definiendum>
				<definiendum id="2">TO XOFOF TES TWV POPES END CETF</definiendum>
				<definiens id="0">VF\z SkTF ( @ VPr 'AUX'r 'RE ' ) Sp-TF ( , VEr 'TMS'r 'PPRG ' ) SETP ( , VP , *VCIQ ) FAPSE ( NP ( ) ) ISCTO~~PRNP ) ) VF = ~~ILUS ( *VP ) PAFSECPFC</definiens>
			</definition>
</paper>

		<paper id="1043">
			<definition id="0">
				<sentence>The use of the symbol `` NULL '' is illustrated in the rule : PPH = NULL This will cause the symbol `` PPH '' to be deleted from any string in which occurs .</sentence>
				<definiendum id="0">NULL</definiendum>
				<definiens id="0">deleted from any string in which occurs</definiens>
			</definition>
			<definition id="1">
				<sentence>The NTIS on-line data base consists of Federally sponsored research reports conlpleted from 1964 to date .</sentence>
				<definiendum id="0">NTIS on-line</definiendum>
				<definiens id="0">data base consists of Federally sponsored research reports conlpleted from 1964 to date</definiens>
			</definition>
			<definition id="2">
				<sentence>FCC APPROVES WESTERN UNION REQUEST TO PROVIDE PACKET-SWITCHED SERVICE The FCC has approved a request from Western Union International to provide a packetswitched service between the United States and the United Kingdom , for the Advanced Research Project Agency ( ARPA ) in the Oepartment of Defense .</sentence>
				<definiendum id="0">FCC APPROVES WESTERN UNION REQUEST TO PROVIDE PACKET-SWITCHED</definiendum>
			</definition>
			<definition id="3">
				<sentence>Executive director Carole Parsons enumerated a list of areas possibly appropriate for the Comission 's attention , which included : mailing lists ; private sector usage of universal identifiers ; valuntary private sector compliance with Federal regulations ; data collection criteria ; credit card and reservation systems ; Freedom of Information Act litigation ; health and medical records ; multi-jurisdictional data systems ; consumer reporting services ; credit issuance and insurance ; statistics and research ; social services ; employment and personnel matters ; oversight , enforcement and remedies regarding privacy policies ; international implications ( including mu1 ti-national corporations ) ; cost factors in imp1 ementing privacy safeguards ; and the Federal-state relationship in privacy regulation .</sentence>
				<definiendum id="0">international implications</definiendum>
				<definiens id="0">included : mailing lists ; private sector usage of universal identifiers ; valuntary private sector compliance with Federal regulations ; data collection criteria ; credit card and reservation systems ; Freedom of Information Act litigation ; health and medical records ; multi-jurisdictional data systems</definiens>
			</definition>
			<definition id="4">
				<sentence>TUNNEY HEARINGS ON WHITE HOUSE COMPUTERS The Senate Subcornnittee on Constitutional Rights , chaired by Sen. John Tunney , held fact-finding hearings on September 9 to investigate computer usage ( pertaining to personal data files ) by the White House and'the Federal Preparedness Agency ( FPA ) .</sentence>
				<definiendum id="0">TUNNEY HEARINGS</definiendum>
			</definition>
			<definition id="5">
				<sentence>Recent exploratory meetings have been held with several groups which have indicated a definite interest in access to technical information through AFIPS , e.g. , the Congressional Office of Technology Assessment , the Air Force Systems Comnand , and the Office of Automated Data Processing Management in the General Services Administration .</sentence>
				<definiendum id="0">Recent exploratory meetings</definiendum>
			</definition>
			<definition id="6">
				<sentence>Specific objectives are to `` k ] ncourage the private sector . . . to become an active partner in the development of the National Program , '' as well as to ensure adequate library and infomation services , provide adequate special services , strengthen state resources , ensure education of related personnel , coordinate Federal programs , and establish a locus of Federal responsibility for the National Program .</sentence>
				<definiendum id="0">Specific objectives</definiendum>
				<definiens id="0">an active partner in the development of the National Program , '' as well as to ensure adequate library and infomation services</definiens>
			</definition>
			<definition id="7">
				<sentence>As a result of the delay the Commission will have less than a year to complete its work , unless the Congress passes an amendment ( presently pending ) which would extend its period of activity .</sentence>
				<definiendum id="0">Congress</definiendum>
				<definiens id="0">passes an amendment ( presently pending</definiens>
			</definition>
			<definition id="8">
				<sentence>IBM , Comsat General , and Aetna Life E Casualty have proposed ta the FCC a partnership arrangement in which each would become an equal owner in ML Satellite , a corporation being organized to provide satellite data comunications ; the proposal corresponds to the `` balanced option '' for CML , approved by the FCC in an earlier ruling .</sentence>
				<definiendum id="0">IBM</definiendum>
				<definiens id="0">a corporation being organized to provide satellite data comunications</definiens>
			</definition>
			<definition id="9">
				<sentence>Thc proposed scrvice , to be known as Corn-Pak , is a packet-switched system which woul 'd be cap .</sentence>
				<definiendum id="0">Thc proposed scrvice</definiendum>
				<definiens id="0">a packet-switched system which woul 'd be cap</definiens>
			</definition>
			<definition id="10">
				<sentence>In FY 77 , ARPA will have substantially reduced expenditures in its progrms relating to the ILLIAC IV , and the ARPANET ( which is now treated as an operational network under the Defense Communications Agency ) .</sentence>
				<definiendum id="0">ARPANET</definiendum>
			</definition>
			<definition id="11">
				<sentence>The U.S. cooperates in this program of export control with its 13 NATO allies and Japan in a group called the Coordinating Committee ( COCOM ) , which maintains an International Commodity List of items which are banned from export to social t countries .</sentence>
				<definiendum id="0">U.S. cooperates</definiendum>
			</definition>
</paper>

		<paper id="1049">
			<definition id="0">
				<sentence>Lt is a description of a model which works , To be more specific , it is a description of a large program , written in FORTRAN , which runs on a 960-40 .</sentence>
				<definiendum id="0">Lt</definiendum>
				<definiens id="0">a description of a model which works</definiens>
				<definiens id="1">a description of a large program , written in FORTRAN , which runs on a 960-40</definiens>
			</definition>
			<definition id="1">
				<sentence>The program breaks this down into four EPs , as follows : EP 1 EP 2 EP 3 EP 4 lead word snores man with nose subsidiary word man the nose a subsidiary word always with long An EP contains one lead word plus a number of subsidiaries , and is classified according to the nature of the lead word .</sentence>
				<definiendum id="0">EP</definiendum>
				<definiens id="0">contains one lead word plus a number of subsidiaries , and is classified according to the nature of the lead word</definiens>
			</definition>
			<definition id="2">
				<sentence>, 'Many is then read , and EP2 and also EP1 &lt; are updated. At this point there are two alternative continuations. Either EP2 could be continued , as in fact happens , or EP2 could be closed '' and EP1 continued. Therefore on going to the next word , EPs 1 aqd 2 are both open. So the process is continued through the sentence. As shown in the flowchart , there are three subroutines which operate on each word -- CON , UPIX and OACR. CON takes each EP which is open , and tests each sense of the word against each possible continuation of the EP. If the word could satisfy a position , it then looks to see whether a form match is necessary. In general , in English , a form test is only necessary between subject and verb , when the number and person must agree. If this hurdle is overcome , CON then proceeds to a semantic match. In general , the lead word of an EP must be matched semantically with every subsidiary word of that EP. For example a sub '' jct must ' be matched with a verb. So i % check is performed , to see if that particular noun taken in that particular sense could be the subject of that particular verb taken in that particular sense. Having found all the possible solutions , CON then gives way to UPDT. UPDT updates each EP according to the solutions found in CII_ CON. It reproduces EPs as necessary where more than one solution has Been found , and discards EPs which have becorne defunct because no solution has been found. It also determines which lqter positions of ' an EP either can or must be filled as a result of the current word becoming a part of the EP. Tt Lllen hands over to OACR. OACR ( open and Close ~outine ) determines which EPs must be kept for the next word. It also perforrns some juggling with EPs in certain rather tricky cases such as relative clauses. It then returns control to the root PTOgXaIn for the next word. When all the words of the sentence have been processed , ENDR is entered. This examines all existing solutions. It discards any that are incomplete , and perfornls sorne housekeeping on those which : are complete in order to separate them , In future , it will make a choice between alternative solutions , although this part of the program has not yet been written. After ENDR , the sentence has been reduced to one ( or more ) sets of connecked EPs. Within an EP , for each subsidiary word the relationship to the lead word ( eg. verb/ob ject , verb/timenoun , noun/article , etc. ) is specified , as are the code ( s ) remaining as a result of the semantic matches which that word has undergone during the analysis. After this brief description of the functions of the various subroutilies , a Inore detailed explanation of the semmtic match follows. We thon show l~ow tho progrnrrl deals wit11 sams af the. more co~nplsx probllsr~ls ~~~'hiclr~ it silco~nt~t~rs. SerriariCic Mat ching 111 or*dsx* to illustrate tho rriotllcsd , ; I sixllplified exarnple is given , using the word i . Take the sexltence , She walked i.11 fields ixi Nay , Suppose after READ , tho following coclos aro i.11 store : The last digibs , 1 to 6 , refer to the word number. 'Int is words 3 and 5 with codc nunibers 4-9 , 1 1 16. Suppose the codes have the same meanings as shown ascribed to 1 1-16. Suppose further that `` places11 start n with digits 2127 , and that 'fieJdl is 21274 , also that `` time periods '' start with digits 223 , and that lfrnonths't start 11.,521 ... ... 5 adverb 12 .. 621 .. ; ... 5 place preposition object place 13 .. 6211. ... .5 place preposition object city 14 .. 6212 ... ..5 place preposition object country 15..631 ... ... 5 time preposition object time period 16 .. 6311 . ' ... .5 time preposition object month 17..22355 ... . 6 , It may well be asked why the distinction has been made between the three place prepositions and betweer1 the two time prepositions. There could be two reasons : either that the concept of the preposition changes ( which is probably not true here ) , .or that the tranaIation is different in spme target language. If it is only the second case , the distinctian could have been left for the , program which generatds the target languwe to draw. However , it is more economical to deal with it @ ring the semantic ntatching. Now let us see how the disambiguation procoas works. This example is simplified because it does not shaw the semantib matching acTOSS prepositions , between 'walked1 and 'fields1 , and between 'walked1 and 'Mayt. Although sometimes necessary for complete disambiguation , it is not so in this example , and as i.4 ; complicates the explanation , I will omlt it here for the sake of simplicity , After the second word , there is only one EP open. Cbde range ( ? ? he meaning of `` code EP 1 lead wdk 2-2 range1* will appear subject she 1-1 prgsently. ) The thipd word , in1 , has two syntactic classes , ad'verb or preposition. Both are acceptable at this point in the verb EP. So a semantic match is performed between each class of 'in ' and the lea4 word 'walk'. Suppose that one SP gives 114 5 52 , another gives 1 1 6 62 , and another gives 11 6 63. All the codes of 'in ' are accepted-code 4 by the first SP , codes 5 , 6 and 7 by the second SP , and codes 8 and 9 by the third The EP has to be reproduced because there are two syntactic classes of 'in'. We therefore have the following : code range code ranges EP 1 lead walk 2-2 EP2 lead walk 2-2 2-2 subject she 1-1 subject she 1-1 1 1 adverb in 44 preposition in 5-7 819 in EP2 there are two code ranges , one for r ; he place preposition and one for the tinis prepositiong. EP3 , a preposition EP attackled to EP2 , is now opened , and for the next word this preposition EP and EP1 are open , but EP2 is closed , The next word , 'fields ' , is a place noun. It is not accepted in EP1 , which is therefore disca-rded. It is accewted in EP3 as the object of the preposition , so a sernantlc match IS performed between 'in1 and 'fields ' , Suppose there is an SP , 62 2 2127 , Codes 5-7 are then accepted by this SP , and EP3 then looks like this : code range EP 3 lead in 5-7 object &lt; field 10-10 A reconciliation is now carried out between the codes of 'inf in EP3 and EP2 , As a result , the second code range in EP2 1s elirninat ed. The next word , 'in1 again , IS now read , and the process is repeated , EP2 now looks like this : lead walk 2-2 2-2 subject she 1-1 1-1 preposition in 57 5-7 preposition in 12-14 15-16 This time , on 'May ' , the relevant SP is 6311 2 2235. There would also be an SP like this : 63 2 223. But the first SP gives a narrower code range ( 16-16 instead of 15-16 ) , and so it is preferred. This time , on recgnciliation , the first code range in EP2 is eliminated and the second is reduced. So at the end , the three EPs are thus : EP2 lead walk 2-2 EP3 lead in 5-7 EP~ lead in 16-16 subject she 1-1 object fields 10-10 object May 17-17 preposition in 5-7 preposition in 1616 We are now left with a code range for the first 'in1 containing three codes , In such eases , it is the first code of the range which 1s selected. So 'in ' has been dlsambfguated to 621 in the first case , and tg 6311 in the second. Syntactic Complexities Of course , it is all very well for a program to be able to digest , She walked in fields in May. But can it also cope with this ? The farmers we were talking about grew , and the greengrocers , thieves and liars , sold those apples. In other words , the program must be capable of being expanded to deal with the myriad complexities and exceptions of natural language. However sound the principles underlying a program may be , such expansion involves a deal of intricate and detaiJ.ed work. At every stage , , flexibility and rigidity liave to be balmced. The program must be flexible enough ta e'nvisage possibilities , but rigid enough to exclude impossibilities and to latch onto the right solution when it appears. The programmer 's task resembles a tailor's. Let out an inch or two mare , taka in a couple thore. It .c~.ould be satisfactory inaeed if an algorithm could be Pound both concise and comprehensive which would encompass all the requirements , but language is such a barnacled growth that this seems on the face of it improbable , It would be surpri.sing if excrescences in the program were not necessary to deal with excrescences in the language. In the development of this program , when the treatment of a new structure has been added , whenever possible the original framework has been adapted to incorporate it , thereby avoid~ng the necessity of adding large sections of program. This is only commonsensical. Nevertheless , the program has grown considerably with its c~pacity to handle largerareas of language. Here is perhaps a suitable point to emphasise that , since this is a multiple-path analyser ' , at sach point all the available information , syntact'ic and semantic , has been deployed to eliminate incorrect paths. This has been done not only to avoid unnecessary computatian , but also because the storage limits have made i $ essential. There are only 25 EPs. Frequently during testing this store overflowed , but interestingly enough ~t has always been possible to bring the demand on it back within bounds by finding some restriction which had been overlooked and which cut out one of the paths. It had originally been feared that 25 EPs would not be nearly enough. One of the satisfying discoveries of the program is that it'i.3. Of course the deployment of all available information is nod &amp; he only approach. Most of the earlier program concentrated on the syntax and paid little heed to the semantics. Wilks , on the other hand , is relying primarily on the semantics suzd is tbaking from the syntax only what is absolutely necessary. It will be fascinating if his research is able to deternine exackly how much of the syntax is unnecessary. There are obvious redundancies in the form of unnecessary safe-guards in language , No one who has struggled with German case endings is ignorant of this , In English , we have the concord between subject and verb in the third perSbn of the present , patently unnecessary since it exists only in this one instance , There are many sentences in which the semantics alone are clearly sufficient. In the sentence , `` The man ate the steak with a fork , '' , the words could appear in any sequence and the meaning would be decipherable , although it might take longer to decipher. The interesting question is what features of the syntax can be consistently ignored , without occasional sentences cropping up which can only be deciphered with the help of these features. There now follows a description of the treatment of three notoriotisly awkward problems-relative clauses , pronouns , and conjunction. Relative Clauses Six cases are distinguished : . The man who ( m ) you met. 6. The man you gave it to. 4 , The man to whom you gave it. After the lead of a noun EP , a relative pronoun ( 94 ) , a preposition ( 6 ) , and a contact noun ( 2~ ) are all possible continuations. lWhol has three relative pronoun codes , starting with , 941 , subject of relative clause , 942 , object of relative clause , 943 , object of prepositicm in relative clause , 'Whom ' ~bviously only has the last two. EP1 man EP2 man EP3 man EP~ -- the the the ( man ) ( subject ) who 9-41 who 942 who 943 EP5 -- EP~ -- A EP7 -- ( a ) ( object ) -- ( man ) ( preposition object ) When a relative pronoun is recognised , the noun EP , EP1 , is reproduced to EPs 2 and 3 , and the codes 941 , 942 , and 943 are to added to separate noun EPs. Then in OACR , new EPs 4 6 are opened dependent uppn the noun EPs. In the case of 941 and 942 , the lead of the noun EP , *mant , is Bntered in the neQ EPs , as subject and objec-k respectively. They are marked so as to avoid translation , but they are necessary for semantic matching in the relative clause. In the case of 943 , an additional new preposition EP , EP7 , is opened dependent upon the relative clause EP , and the lead of the noun EP , 'man ' , is entered as the object of this prepositiatn EP. The relative clause EP is marked as waiting for a fldating preposition , although when a preposition comes this EP is reproduced , and in one EP the preposition is taken as the floating preposition , while in the other EP it is talcen as another preposition. This is necessary to allow for such clauses as , the man wliom you gave tile book in the end to. In the cases of 941 , 942 and 943 , the only EP which is open for the next word is the relative clause EP. For 941 the next necessary word in the EP is the lead verb , while for 942 and 943 the next necessary word is the subject. In practice , one or more of these EPs is usually eliminated on the next word. When a contact noun is recognised , it is marked in the noun EP as being in reality a relative pronoun. Then the procedure for 942 and 943 above is followed ; but in addition , the contact noun is entered as the subject of the relative clause EP. When a prepusition is recognised , the noun EP is reproduced once , because the preposition might be in the noun EP , like dog in a manger , or it might be in a relative clause. For the relative clause path , a preposition EP and a relative clause EP are opened. Only the preposition EP is left open for the next word , which must be a relative pronoun , For indirect questions , I do n't know which house he bought. I do n't know what he lived in. etc the treatment is somewhat similar to that for relative clauses. Pronouns For either a translation or a questio~l-a~isweri~lg program , the noun which the pronoun replaces , called here the replacement noun , has to be identified. In a questionallawering program , the reasons are obvious enough. In a translation progrml , it is necsssary for sertiantic ~natchlng and also because in many target languages the gender of the prohoun varies with that of the replacement noun. The replacement noun might ; be in the same sentence as the pronoun , or in a previous sentence. Therefore , in dealing with pronouns , the program must be able to refer to preceding sentences. So after ENDR , the essential information for the sentence just processed is extracted from the first chain of EPs and stored. At present , th $ s is only done for one chain of EPs , i , e. one solution. This essential information consists of a tree , containing one code for each word and the relatlon of each word to the code to which it is attached. Reverting to , The mail with a long nose always snores. , the information is as follows , snores ... . , ... l ... ..e.1175 tense ... ... ... Z ... ... .tense , mood , code. , .T 1 m~.. ... ~..t..3e.~~~~m211021~e~~~o~~m~e1 1 ... ... ... .. the 4 ... ..~..4032 ... ... ... ... ... ... 3 with .*C ... ... .5e.e ... .6~ 7e ... e.e*.0***.0 ... .3 ... ... ... . nqse 6e ... m~~212ee~eem~e~~~e~~~~~~e5 a ... ... ~ .m ... m7mee~~~~4~331~m~~me~~~m~~om~~~ 6 ... ... ... . long 8 ... ... . 4176.a.~ ... e.~e.e~*..m 6 r alwgYs ... ... ..9 ... ... .33 6e..- ... ... ... ..e.m.1 The fasr ; co~umn polrl~s b~ tile code to which the word is attached. The previous column contains any relationship information not implicit in the code itself or , in the case of a pronoun , a pointer to the code of the replacement noun , 1 % is important to notice that the code itself usually does provide the relationship information. For example 61 , the first two digits of 'witht , specify with some precision the relationship of 'witht to 'man ' , With the preceding sentences available in this form , the processing of a pronoun works as fo1 ; lows. When the pronoun is first encountered for a semqntic match , all the possime replacement nouns are found ; that is to say , all those nouns which agree in number and person with the pronoun and which are either before the pronoun in the same sentende but not in the same clause , or in a preceding.sentence. The program only goes back through the preceding sentences until suitable noun has been found , If for example there werB one or more suitable nouns in the second sentence before the current one , 38 it would not examine the third sentence besore the current one. Consider the following sentences. The man went into the shop where he had seen the raincoat. He bought a hat an4 took it away. For 'het , the only possible replacement noun is 'man ' because it is the only noun which agrees in person. For it , the program firids 'hat1 , 'raincoatt , and 'shopt as possible replacement nouns , If there were a preceding sentence , it would not bother to search it. Semantic matches are then carried out between 'take ' and each of the three nouns and all three nouns are accepted , so they are all entered into the EP after it. But the code ranges for 'shop ' are more restricted than for 'hat1 and 'raincoat1 , because the physicalmovement meaning of 'taker is excluded with 'shopt because 'shopt is imrnoveable. When 'away ' is read and matched with 'taket , all meanings of 'take ' except the physical-movement meaning are eliminated. tShopt is now left dangling , so to speak , and is eliminated as a possible replacement noun. So when the end of the sentence is reached , there are two possible swviving replacement nouns , 'hat ' and 'raincoat'. There is no semantic reason for preferring one of these to the other , becaase the number of digits matched in the semantic match with 'take ' is the same in both cases. Therefore in ENDR a choice is made according to a formula of priorities and 'hatt is selected , as ; a rmre recent verb object. This `` formula of prioritiesv , which is only applied if there is no semantic preference for one noun , is probably at 39 the moment .a rather blunt instrumeat. It is concerned with two factors -which noun occurred in a 1-ater clause , and which noun has the same function as the pronoun ; subject , objept , preposition object , or object of the same preposition. In the majority of cases it produces the correct answer , but it is possible to think up examples in which it doesn't. With experience of use , the formula will be refined. A complication is addea ~y rhe possibility that , when a subdect , 'itt may be impersonal. This sense is treated essentially as one possible replacement noun. There is still work to be done in developing the for , mula of priorities. CLAM extracts the information required to solve the pronoun problem. The question is , how to use it. Conjunction No mt of the program is more complex than that dealing with conjunct'fon. The principles are clear , Qeven simple , enough ; but applying them has demanded a considerable amount of care. Consider the fragment , He cleaned the carpets in the bedroom and ... ... When 'and1 is read , the EPs are as follows : EPI cleaned EP2 carpets EP3 in EP~ bedroom he the bedroom the carpets in All four of these EPs are alive , which is to say that the next word might be a continuation of any of them. On recognising a conjunction , the program looks for nnssible continuations in all alive EPs , from the beginning of the EP up to the point which has been reached. It carries out the necessary semantic matches , it opens a new `` conjeptt or conjunctive EP for each solution , and it enters dummy words in both the conjep and the EPs above it in the chain where necessary. To clarify this prooedure , we will consider two possible continuations. ( a ) ... .. and I ... ... '1 ' can only be the subject of a verb EP , so the conjep. , EP5 , must be joined to EP1. The program adds a 5 ( : entry , and opens EP5 thus : EP1 cleaned EP5 -- -- carpets EP5 is dependent on EPI at the subject position K5 ( b ) ... .. and curtains. 'Curtainsf could be joined to EP2 as the lead , or JSY~ as the object. The conjep IS attached to the lower EP , EP2 , but a dummy word is entered in EP1 and the semantic match is carried out between the dummy word , 'curtains ' , and the lead of the EP , 'cleanedt , EP1 cleaned EP2 carpets EP5 curtains he the theX carpets in EP5 is dependent on EP2 at the X curtains K5 lead position , 'The1 ris entered as a dummy word in EP5 because it comes before the point at which EP5 is dependent on EP2. A semantic match is carried out be % w ; een 'thev and 'curtainst. 'CurtainsT might also be the subject of a verb EP , so EPI is reproduced and another conjep started , attached to the reproduced EP at - % he subject position , as for ... ..and I ... ... aboqe. This path is unlikely to be correct , and will probably soon b~ eliminated , An attempt is also made to attach curtainst to EP~ in the lead position , but it fails because a dummy word curtainsi is then put into EP3 , and the semantic match between 'int and 'curtains1 is tried +and fails , Now let us see what the EPs 1ookd.ike at the end of a more complex conjunctive sentence : I , you and Nellie saw , watched and greeted the men , women and tired children. EPI saw EP2 I EP5 watched EP~ greeted EP7 men I K3 the ~4~ X youX YOU K8 ~e1li.e~ EP3 you el lie^ el lie^ 1c9 K5 ~4 ~6 men EP8 women X ~6 EP~ Nellie X X men women theX X men women childi-enx Kg X women childrenX EP9 children tired It will be seen that control passes from the conjeps 5 and 6 up to EP1 before 'men ' , so that 'men ' is entered as a word in EPI. But it is also entered as a dummy word in EPs 5 and 6 , and semantic matches are carried out with 'watched1 and 'greeted1. Also 'woment and 'children ' , although only dummy words in EPI , are entered as dummy words in EPs 5 and 6 as well , A c~njep remains open , and the EP ofi which it depends 42 remains closed until the last necessary word up to the branch has been filled. If the sentence had read , 1 you and Nellie saw , and 'he1 watched and greeted. , etc. EP5 would have opened with 'he'. I , 'you1 and 'Nellie1 would not have been entered in it as durnrny WQ~~S. El ? would flclvo remained open , and EP1 closed until arter tho lead w~rd twa-l ; chedlm A coma is treated as a possible conjunction or as FI possible braclcst. Bocauso of the dual role of c.i corntrln , tllc programming associated with it is rather awlc~qard. To sum up the treatment of conjunction , the possible continuations from a conjunction , particularly if'there have been previous conj~mctions in the sentence , can be numerous. But by the strict use of dumrriy entries and their associated semantic matches , false continuat~ons are usually quickly nosed out and eliminated. Also , for the recordirlg of the full meaning of a corij~uictive senterice fortho purpose of later interrogation , the dummy entry system is of course essential. And in the special case of comparative sente~~ces , it is only by such a system that it can be clearly established exactly what is being compared. Summary. I conclude this section with an assessment of what the analysis can and can not achieve. The purpose of analysis might be described as follows : to select , from among all the possible meanings of each word in the passage , its correct meaning in the context , and to determine what semantic relationships exist between '~qhich words , CLAN can do thzs with considerable efficiency within the confines of 9 single sentence. It is just beginning to enlarge its horizens to deal with longer texts. To clarify this statement let us consider the aids which enable us to select one meaning of a word raeher than another , and see which of them CLAM applies. the mechhic finishes his wo'rlc. Here tho word 'worlc ' is evidehtly a verb on the first occasion and 3 noun on the second. CLAM can usually deal easily enough with this type of ambiguity. discussed at some length.. The rules are both semantic and syntactic. When the rules are determined , CLAM will be in a position to apply th6m. of'words which exclude one meaning. Example : `` He took off his g~andmother.~ Here the two word verb 'take offt mugt me'mimicl. The personal subject and the existence of an object excludes the sense of a plane taking off , 'Grandmother1 as object excludes the sense of taking off clothes , Such restrictions are the basis of CLAM 'S semantic match , and ambiguities of this sort are resolved as a matter of course. pairs of words khich give preference to one meaning. Example : `` I killed ths man with a gun. '' Here , there is a synta~tic as well as a semantic ambiguity. It is less straightforward than the previous example because the ambiguous word is 'with ' , whlch might be ~JI instrument preposition attached to the verb kill1 , or a possessicon preposition attached to the noun Vrnanl. The semantic relationships which determine the choice , however , ~nly involve 'witht indl ectly. They are between 'kill1 and 'gun1 in one case , and between 'man1 and 'gun1 in the other , NormalLy tlXle preference would be for the instrunlent ; interpretation because lg~pl ' is more strongly associated with 'killt as an instrument than with 'man1 as a possession. CLISrcI chooses the stronger association by taking the 'deepert semadtic match , ar 2n other words the match involving the Larger number of digits. It does this correctly , but as we shall see in a moment , it is not always correct to do so , 5 , Remoter contextual environment. Sometimes the factors enabling a choice to be made are more remote from the word in question than In the examples given above , In order to find these factors , a longer journey has to be made into the environment of the word , Examples : ( i ) `` The mayor hit the alderman so hard that he fell down. '' The normal rules for selection of pronotin antecedents would prefer 'mayor ' as the antecedent of 'he ' because it is the subjec-tt , but in the environment of hitting , it is much more likely to be the person hit who falls down rather than tb hitter , so 'alderman ' must be preferred. ( ii ) `` Two men came in. One had a gun and tho other had a knife. I killed the man with a gun. '' Here 'withT is obviously not an instrument preposition attached to lkilll , but a possession preposition attached to 'menv. This is so because the definite article 'thet attached to vmpn ' implies that 'man1 has already been defined , But in fact two men have already been defined , and more information is needed to determine which of them is referred to. The only possible additional information which could satisfy this requirement is 'with a gunr , whioh does suffice to distinguish one of the previously determined men. Therefore this phrase must be attached to 'manv , At present , CLAM could not resolve either sf these ambiguities. In order to do so it would need , in the fix '' st case , more information about the environment of 'hitt than is contained in the semantic restrictions now at its disposal , and in the second case , both a better memory and a routine for dealing with definition of nouns. Work is in progress on these vital additions. They will involve adding to the type and range of the semantic relationships between pairs of words referred to in the definition of the purpose of analysis given at the beginning of this summary. At present , CLAM only holds semantic relationships be-tween words which are syntactically related. This is not enough. Adding to the types of relationships held , and extending them to pairs of words which are syntactically remote , will greatly increase the scope of the model. GENERATION OF TFIE FIXENCFI TRANSLATION As shown in the flowchart , the sentence is operated on sequentially by four subroutines -- TWEN , ITRN , FRORM and PRIN. Briefly the function of each of these subroutines is as follows. TWEN examines all the verbs. It welds them ( joins auxiliaries to main verbs ) , and determines their tense in French. Thls is not of course necessarily the sane as in English. Other features of the sentence often have to be examined. Thus , `` When he arrives we will meet him '' , becomes in French , `` When he will arrive we will meet him '' . And `` I have been here for five years '' becomes `` I am here since five years. ! ! Gerunds , infinitives and participles are also dealt with by TWEN , It may well be asked why the weld part of this routine is thus left until the French generation. Should it not be done avring the reduction of the English sentence to base fo'rm ? The answer is that logically it should , and it will sooner or later be transferred , probably to ENDR. But at present it does n't matter. The part of the program described in the section on pronouns which stores the base form of the last sentences is in fact performed after the French translation has been generated , and therefore , after the verbs have been welded. ITRN takes each word in the sentence in turn. I ; t finds the code number in FRILE , the French dictionary file , and extracts the French word ( s ) . Sometimes of course there is more than one , Sometimes there is zero because the English word does not have to be translated. Any particular French word may not have the same function in the sentence as the English word. In such cases , the French word entry in FRILE is followed by a code which specifies the word 's function in x'glation to the English word being translated. For example , if 2.32237 isl the code for 'potato ' , -t ; hen'FR1LE entry will be 212237 POMME F DE 6 TERRE 6x2. The F after POMME shows that it is feminine. The 6 after DE shows that its x'unc $ ion is as a plcepqsition in the EP of which POMME is the lead. The 6x2 after TEW shows that it is the object in the EP of which DE is the lead , Sometimes it isaecessary to go up Che tree. Fop example Y1x5 means an adverb ( 5 ) in the verb EP ( 1 ) of which the English word is a subsidiary ( Y ) . It is thus possible to generate a French sentdnce of a radically different shape from English. ITRY also finds a French sequence code for each word. This is a code which provides the ordering of words within an EP. All lead words have the code 200. A pre-noun adjective may have a code 140 , and a post-noun adjective 350. So these codes do not determine what is the actual sequence of words in the sentence , but they do provide the basic information from which the sequence is derived in FRORM. FRORM first derives the actual sequence of words in % he , sentence. It then takes each French word and puts it into the correct rorrn. Obviously the most arduous part of this tqsk is finding the forms of the verbs. FRORM refers to tables which contain the verb endrings for both irregular bd regular verbs , and the irregular feminine and plural endings for nouns and adjectives. PRIN prints the French translation , haying made any necessary elisions. If there is more than one solution , it prints alterna-bive translations of particular words on subsequen.1 ; linss or , if appropriate , it will print complete alternative sentences. CONCLUSION Programming Details and Future Developments Programmersmay be interested in some details. The program runs on a 360-40 using 146~ of core store. The program is mitten in FORTRAN IV , not an ideal choice but the best available in the circumstances. The reduction of the English to base form requires about 6,000 instructions , and the French generation about 2,500. At present all the files are 1cep-k in core store except for the two large dictionary files VOCAB and FRILE , which are accessed on disk. It will eventually be necessary to Keep JSP also on disk. At present the processing takes about 15 seconds per word on average , of which READ takes 4076 , the semantic and syntactic analysis about 20 % , and the French generation 40 % . No serims attempt has yet been made to optimise the program and this time could certainly be peduced. But the reduction would be offset by the eventual need to keep JSP on disk. So as a practical proposition for translating texts , it would be necessary for the processing time to be reduced by a factor of about 10. Presumably this will come sooner or later with improvement in hardware. There are certain improvements which would have -bo be made to the pogram before it could be used , apart from the extension of the vocabulary. Most obvious : ( a ) there are some syntactic structures such as inversion after negatives which the program does not at present recognise ; ( b ) a , selection routine must be incorporated in ENDR to choose between alternative solutions if more than one emerges ; ( c ) if no solution emerges the program should try again , selectively suppressing semantic matching , allowing words to be used outside their normal sense ; ( d ) the sizes of some of the temporary stores would have to be increased. No particular dirficulty is anticipated with any of these developments , in that they involve no methodology fundamentally different from what has already been applied. It is primarily a matter of time and priorities. However with a fifth development , namely the extension of the memory as outlined at the end of the section oh analysis , new ground must be covered , and work on this is at present in progress. APPENDIX Coding System : Principal Categori , es Digkt I st 1 verb 2 noun 3 pr , onoun 4 adjective 2nd 3rd 1 intransi-tive 2 noun object 3 clause predicate I noun + part part. 2 noun + to + infin. 3 noun + gerund 5 noun clause 4 verb sequel 5 noun + clause predicate 6 complement sequel 7 be ( pres. cont. ) 8 1 concrete 2 abstract 1 infinitive 2 to + infinitive 3 gerund 1 noun + infinitive 2 noun + to + 1nfi.n. 4 noun + prep. + gerund 5 noun + noun clause 0 qualify concrete or abstract noun 1 be ( passive ) 2 have ( pres. perf. ) 1 animate 2 inanimate 1 qualify concrete 0 animate or noun inanirnat e 1 animate 2 inanimate 2 qualify abstract noun 4 question 5 possessive 1 time 2 place 3 purpose 4 question 5 manner 6 degree 7 probability 8 frequency 6 pfeposition 1 predetermined 1 by verb 2 by noun 3 by adjective 2 post determined 1 time 2 place 3 purpose 4 reason 5 manner 6 instrument 3rd 7 association 8 past 9 concession A subject matter 7 conjunct ; ioll 1 link : 2 contxagt 'j comparison 9 clause word 2 noun clause 4 relative clause 6 adverbial clause 1 time 2 place 3 purpose 4 reason 5 manner 8 condition 9 concession Amencan Journal of Computational Linguistics ~icrofiche 49 : 53 Slate Universily of New York REQUEST FOR PROPOSAL Federal Research &amp; Development by Contract WASHINGTON OFFICE STATE UNIVERSITY OF NEW YORK SEPTEMBER 1974 AJCL EDITOR 'S NOTE The document reproduced on these frames came to the Editor 's attention recently , in spite of the publication date. AJCL thanks the State University of New ~orE , copyright holder , and Mr. Mort Grant , Director of the Research Foundation of SUNY ; Ms. Winifred R. Widmer , Assistant Director for Administration ; Mr. William F1. Claire , Director of the SUNY Washington Office ; Mr. Jim Kalas and Ms. Susan G. , Sorrels of that Office ; for their several contributions to the appearance here of RFP. Some of the names and telephone numbers must no longer be correct ; but ACL and AJCL do not have the means to bring them up to date. The general understanding of the-system which this document provides is valuable to any ACL member who chooses to make use of it. Broader Federal support for the usepof computers in linguistics is probably the only way to bring the field to a much higher level of activity. Individual copies are available to all autlorized State University of New York personnel free of charge. Bulk orders , or other requests for copies can be arranged at a cost-of-print~ng charge of $ 1.50 per copy. All requests regarding this publication should be directed to the Washington Office , -State University of New -- York , Suite 500 , 1730 Rhode Island Avenue , N.W. , Washington , D.C. 20036 ( 202 , 659-2330 ) . Checks should be made payable to the Research Foundation of State University of New York. William F. Claire , Director Susan G. Sorrels , Edltor Carole K. Combs , Administrative Ass~stant Q State University of New York 1974 TABLE OF CONTENTS I , FEDERAL PROCUREMENJ ' FOR RESEARCH AND DEVELOPMENT : AN EXPLANATION OF THE RFP CONTRACT MECHANISM 11 , ALPHABETICAL LISTING OF FEDERAL AGENCIES WHICH CONTRACT FOR RESEARCH AND DEVELOPMENT Department of Agriculture Atomic Energy Commission Depart men t of Commerce Department of Defense Environmental Protection Agency Department of Health , Education , and welfare Department of Hous~ng and Urban Development Department of the Interior Department of Justice Department of Labor Department of Transportation Nationd Aeronautics and Space Administration National Science Foundation Srnithsonian instituhon United States Information Agency 111. GLOSSARY OF TERMS IV , INDEX OF AGENCIES AND DEPARTMENTS WITH FEDERAL CIVILIAN AND MILITARY RESEARCH AND DEVELOPMENT ACTIVITIES V. APPENDIX A Sample of Standard Form 129 Sample of Standard Form DOD 558-1 VI. BIBLIOGRAPHY ORIGINAL PAGE \rJUMBERS ARE AT THE BOTTOM OF THE FRAME INTRODUCTION In view of an incredsing interest in government agencies in pinpointing thclr rrscach needs , the Washington Office of State University of New York feels that it is appropn.ltc for its campuses to familiarize themselves withQ what is commonly c ; dled the RFP plocrss. Thr `` request for proposal , '' or the governrnetlt way of saylrlg th~t it is putr~r~g out bids to fulfill a specific need , is bccoming something that all cnnlpuses sllould bc awnrc of in thri efforts to secure all possible funding for research xnd devdopment from outside sources. Fcder 'd contracting out , as it were , can be a complicated process , but we hope that potcnt1.J 1nvcstig.rtors dl rcgard this information as preliminary. Aftcr that , there is n't ~riy substitute for dic .unount of work involved. Tlus booklct is dcsylcd to givc carnyur rcp~esent~~ti\lcs L~rl ovr.nr1eiv of tlic ngerlclm involved , as wen as ill1 undc~stnndin~ of '~nd cspla~l~~tlon of the RFP contract mrch ; wnm. We II~VC listed 15 sepalate agncics c~irrerltly invo1vt.d m this contrdct rncchnnisrn. thelr irltcrcst ~nd appropriate addresses for more inforrliation. We have also included a glossav of tcrnls .IS Ll guide and all index of the v , xious offices and bureaus within each of the 15 agencies. The time span from inception of an idea to actnnl publication IS always a lengthy one and many people have been involved with thls report. Willi.lrn Hedbcrq. L Susan Sorrcls. Jim Kalas , ~nd Carole Combs have all participated in its dcvelopmcnt. Bryan Sw.lrtz. \vlio lvined our office in the summer of 1974 as an lntcln from the Stony Brook campus. dcscrvcs sFcclal pralsc for his coordination of many activities leading to the publlcatlo~i of the book. Witllout Ms dedication to the project , it might have bcen delc~ ) red considcrnbl~. We are grateful to .dl of these people for thcir assistance. Wc hope tfi.~t the book w~ll prow GI v.duable \r ! nrLing glide for anyone interested in thc contrLIct system. Thc Wbwhlngton Office would bc plc~scd to provlde additional in€orm.~tion about thc c~ge~~clcs lnvolvcd. I. FEDERAL PRQCUREMENT FOR RESEARCH AND DEVBLOPMENT : AN EXPLANATION OF THE RFP CONTRACT MECHANISM Each year the federal government contracts for billions of dollars of work to support efforts deemed to be in the national interest. A significant percentage of the contract services are in the form of Research and ~evelopment ( R &amp; D ) or programmatic work which colleges and universities are particularly wcll-suited to perform. The government commits these funds in eithet of two WAYS : grants or contracts. University researchers are generally more familiar with the grant procedure than with the contract procedure. Under a grant program , a given federal agency is authorized to grant funds to non-profit institutions , frequently educational institutions , for the purpose of supporting research or a in a given general area. A body of general conditions are established by the Congress and refined by the applicable agency to set parameters for the pro $ am as a whole. A specific grant for a program can be made so long as it fits within the gevral stpndards ( the Guidelines ) of the program and meets whatever qualitative standards for review that have been established. Since grant funds , particularly in research areas , have been inc~asingly competitive in recent years , the university community ' is turning its attention to potential support through the contract mechanismi. A contract , unlike a grant , is generally awarded for the purpose of meeting a specific reqwrement that a federal agency has determined to be important to the achievement of .the agency : s responsibilities. The contract will tend , therefore , to be specific in terms of the agency 's needs , and in the case of research , wdl usually be for the purpose of `` applied '' rather than `` basic '' research. The contract , also unlike the grant , can be negotiated with any organization that is legally constituted to do business w~th the government , whether non-profit or profit-making. Government procurement m its present massive scope is a relatively new phenomenon , having emerged fin as prpscnt form in the past quarter of a century. Each of the many federal agencies involved in procurement and most are developed a set of standards'and procedures to administer the contracting process. While the procedures used by any gven agency tend to be relativel ) orderly in terms of that agency 's requirements , they will not necessarily conform to the practices of anoJler agency. Looking at the federal government as a whole , however , the set of. practices is varied , highly technical and often confusing. The general descriptions offered in 'this statement , therefore , are subject to the differing qualifications and refinements established by individd government agencies. In recent years there has been an attempt to bring mter-agency consistency to the procurement ' process. A speclal government task force has recommended legislation -which would bring uniformity in procurement policy. Congress is considering such legislation , which will be discussed later. Basic contractual agreements with the federal government are developed in one of four ways : A. Sole Sotrrce I'roclrrement. The government negotiates with one and only one provider on the grounds that the product or service is uniqucly provided by the organization in question. B. Sitlqlc Solrrco Procir r ( wlolt Thc governmcot ncgotlatcs with onc and onl ) . onc profidel in ir~stances whcrc tllcrc could bc cnmpctlttve Lids but becnusc of f'ictors such .IS locnnon , co~lvenienc~ or spoc1.d urgency competitive bidding 16 unwarranted. C. Cutrlpc &gt; titi~~e Nrgothltiotr In instances where providers are few and known to the government , cornpetltion is litnited to tllc known promders and publicity reg , uding thr availability of .</sentence>
				<definiendum id="0">SP</definiendum>
				<definiendum id="1">prioritiesv</definiendum>
				<definiens id="0">in fact happens , or EP2 could be closed '' and EP1 continued. Therefore on going to the next word , EPs 1 aqd 2 are both open. So the process is continued through the sentence. As shown in the flowchart , there are three subroutines which operate on each word -- CON , UPIX and OACR. CON takes each EP which is open , and tests each sense of the word against each possible continuation of the EP. If the word could satisfy a position , it then looks to see whether a form match is necessary. In general , in English , a form test is only necessary between subject and verb</definiens>
				<definiens id="1">proceeds to a semantic match. In general , the lead word of an EP must be matched semantically with every subsidiary word of that EP. For example a sub '' jct must ' be matched with a verb. So i % check is performed , to see if that particular noun taken in that particular sense could be the subject of that particular verb taken in that particular sense. Having found all the possible solutions , CON then gives way to UPDT. UPDT updates each EP according to the solutions found in CII_ CON. It reproduces EPs as necessary where more than one solution has Been found , and discards EPs which have becorne defunct because no solution has been found. It also determines which lqter positions of ' an EP either can or must be filled as a result of the current word becoming a part of the EP. Tt Lllen hands over to OACR. OACR ( open and Close ~outine ) determines which EPs must be kept for the next word. It also perforrns some juggling with EPs in certain rather tricky cases such as relative clauses. It then returns control to the root PTOgXaIn for the next word. When all the words of the sentence have been processed , ENDR is entered. This examines all existing solutions. It discards any that are incomplete , and perfornls sorne housekeeping on those which : are complete in order to separate them , In future , it will make a choice between alternative solutions , although this part of the program has not yet been written. After ENDR , the sentence has been reduced to one ( or more ) sets of connecked EPs. Within an EP , for each subsidiary word the relationship to the lead word ( eg. verb/ob ject , verb/timenoun , noun/article , etc. ) is specified , as are the code ( s ) remaining as a result of the semantic matches which that word has undergone during the analysis. After this brief description of the functions of the various subroutilies , a Inore detailed explanation of the semmtic match follows. We thon show l~ow tho progrnrrl deals wit11 sams af the. more co~nplsx probllsr~ls ~~~'hiclr~ it silco~nt~t~rs. SerriariCic Mat ching 111 or*dsx* to illustrate tho rriotllcsd , ; I sixllplified exarnple is given , using the word i . Take the sexltence , She walked i.11 fields ixi Nay , Suppose after READ</definiens>
				<definiens id="2">place preposition object place 13 .. 6211. ... .5 place preposition object city 14 .. 6212 ... ..5 place preposition object country 15..631 ... ... 5 time preposition object time period 16 .. 6311 . ' ... .5 time preposition object month 17..22355 ... . 6 , It may well be asked why the distinction has been made between the three place prepositions and betweer1 the two time prepositions. There could be two reasons : either that the concept of the preposition changes ( which is probably not true here ) , .or that the tranaIation is different in spme target language. If it is only the second case , the distinctian could have been left for the , program which generatds the target languwe to draw. However , it is more economical to deal with it @ ring the semantic ntatching. Now let us see how the disambiguation procoas works. This example is simplified because it does not shaw the semantib matching acTOSS prepositions , between 'walked1 and 'fields1 , and between 'walked1 and 'Mayt. Although sometimes necessary for complete disambiguation</definiens>
				<definiens id="3">thipd word , in1 , has two syntactic classes , ad'verb or preposition. Both are acceptable at this point in the verb EP. So a semantic match is performed between each class of 'in ' and the lea4 word 'walk'. Suppose that one SP gives 114 5 52 , another gives 1 1 6 62 , and another gives 11 6 63. All the codes of 'in ' are accepted-code 4 by the first SP , codes 5 , 6 and 7 by the second SP , and codes 8 and 9 by the third The EP has to be reproduced because there</definiens>
				<definiens id="4">a preposition EP attackled to EP2 , is now opened , and for the next word this preposition EP and EP1 are open , but EP2 is closed , The next word , 'fields ' , is a place noun. It is not accepted in EP1 , which is therefore disca-rded. It is accewted in EP3 as the object of the preposition , so a sernantlc match IS performed between 'in1 and 'fields '</definiens>
				<definiens id="5">next word , 'in1 again , IS now read</definiens>
				<definiens id="6">gives a narrower code range ( 16-16 instead of 15-16 ) , and so it is preferred. This time , on recgnciliation , the first code range in EP2 is eliminated and the second is reduced. So at the end , the three EPs are thus : EP2 lead walk 2-2 EP3 lead in 5-7 EP~ lead in 16-16 subject she 1-1 object fields 10-10 object May 17-17 preposition in 5-7 preposition in 1616 We are now left with a code range for the first 'in1 containing three codes</definiens>
				<definiens id="7">capable of being expanded to deal with the myriad complexities and exceptions of natural language. However sound the principles underlying a program may be , such expansion involves a deal of intricate and detaiJ.ed work. At every stage , , flexibility and rigidity liave to be balmced. The program must be flexible enough ta e'nvisage possibilities , but rigid enough to exclude impossibilities and to latch onto the right solution when it appears. The programmer 's task resembles a tailor's. Let out an inch or two mare , taka in a couple thore. It .c~.ould be satisfactory inaeed if an algorithm could be Pound both concise and comprehensive which would encompass all the requirements , but language is such a barnacled growth that this seems on the face of it improbable</definiens>
				<definiens id="8">the program has grown considerably with its c~pacity to handle largerareas of language. Here is perhaps a suitable point to emphasise that , since this is a multiple-path analyser ' , at sach point all the available information , syntact'ic and semantic , has been deployed to eliminate incorrect paths. This has been done not only to avoid unnecessary computatian , but also because the storage limits have made i $ essential. There are only 25 EPs. Frequently during testing this store overflowed , but interestingly enough ~t has always been possible to bring the demand on it back within bounds by finding some restriction which had been overlooked and which cut out one of the paths. It had originally been feared that 25 EPs would not be nearly enough. One of the satisfying discoveries of the program is that it'i.3. Of course the deployment of all available information is nod &amp; he only approach. Most of the earlier program concentrated on the syntax and paid little heed to the semantics. Wilks , on the other hand , is relying primarily on the semantics suzd is tbaking from the syntax only what is absolutely necessary. It will be fascinating if his research is able to deternine exackly how much of the syntax is unnecessary. There are obvious redundancies in the form of unnecessary safe-guards in language</definiens>
				<definiens id="9">the concord between subject and verb in the third perSbn of the present</definiens>
				<definiens id="10">what features of the syntax can be consistently ignored , without occasional sentences cropping up which can only be deciphered with the help of these features. There now follows a description of the treatment of three notoriotisly awkward problems-relative clauses , pronouns , and conjunction. Relative Clauses Six cases are distinguished</definiens>
				<definiens id="11">all possible continuations. lWhol has three relative pronoun codes , starting with , 941 , subject of relative clause , 942 , object of relative clause , 943 , object of prepositicm in relative clause</definiens>
				<definiens id="12">the the the ( man ) ( subject ) who 9-41 who 942 who 943 EP5 -- EP~ -- A EP7 -- ( a ) ( object ) -- ( man ) ( preposition object ) When a relative pronoun is recognised , the noun EP , EP1 , is reproduced to EPs 2 and 3 , and the codes 941 , 942 , and 943 are to added to separate noun EPs. Then in OACR , new EPs 4 6 are opened dependent uppn the noun EPs. In the case of 941 and 942 , the lead of the noun EP , *mant , is Bntered in the neQ EPs , as subject and objec-k respectively. They are marked so as to avoid translation , but they are necessary for semantic matching in the relative clause. In the case of 943 , an additional new preposition EP , EP7 , is opened dependent upon the relative clause EP , and the lead of the noun EP , 'man '</definiens>
				<definiens id="13">necessary to allow for such clauses as , the man wliom you gave tile book in the end to. In the cases of 941 , 942 and 943 , the only EP which is open for the next word is the relative clause EP. For 941 the next necessary word in the EP is the lead verb</definiens>
				<definiens id="14">the subject. In practice , one or more of these EPs is usually eliminated on the next word. When a contact noun is recognised , it is marked in the noun EP as being in reality a relative pronoun. Then the procedure for 942 and 943 above is followed ; but in addition , the contact noun is entered as the subject of the relative clause EP. When a prepusition is recognised , the noun EP is reproduced once , because the preposition might be in the noun EP , like dog in a manger , or it might be in a relative clause. For the relative clause path , a preposition EP and a relative clause EP are opened. Only the preposition EP is left open for the next word , which must be a relative pronoun , For indirect questions , I do n't know which house he bought. I do n't know what he lived in. etc the treatment is somewhat similar to that for relative clauses. Pronouns For either a translation or a questio~l-a~isweri~lg program , the noun which the pronoun replaces , called here the replacement noun</definiens>
				<definiens id="15">necsssary for sertiantic ~natchlng and also because in many target languages the gender of the prohoun varies with that of the replacement noun. The replacement noun might ; be in the same sentence as the pronoun , or in a previous sentence. Therefore , in dealing with pronouns , the program must be able to refer to preceding sentences. So after ENDR , the essential information for the sentence just processed is extracted from the first chain of EPs and stored. At present , th $ s is only done for one chain of EPs , i , e. one solution. This essential information consists of a tree , containing one code for each word and the relatlon of each word to the code to which it is attached. Reverting to , The mail with a long nose always snores. , the information is as follows , snores ... . , ... l ... ..e.1175 tense ... ... ... Z ... ... .tense , mood</definiens>
				<definiens id="16">contains any relationship information not implicit in the code itself or , in the case of a pronoun , a pointer to the code of the replacement noun , 1 % is important to notice that the code itself usually does provide the relationship information. For example 61 , the first two digits of 'witht , specify with some precision the relationship of 'witht to 'man ' , With the preceding sentences available in this form , the processing of a pronoun works as fo1 ; lows. When the pronoun is first encountered for a semqntic match , all the possime replacement nouns are found ; that is to say , all those nouns which agree in number and person with the pronoun and which are either before the pronoun in the same sentende but not in the same clause , or in a preceding.sentence. The program only goes back through the preceding sentences until suitable noun has been found , If for example there werB one or more suitable nouns in the second sentence before the current one , 38 it would not examine the third sentence besore the current one. Consider the following sentences. The man went into the shop where he had seen the raincoat. He bought a hat an4 took it away. For 'het</definiens>
				<definiens id="17">agrees in person. For it , the program firids 'hat1 , 'raincoatt , and 'shopt as possible replacement nouns , If there were a preceding sentence , it would not bother to search it. Semantic matches are then carried out between 'take ' and each of the three nouns and all three nouns are accepted , so they are all entered into the EP after it. But the code ranges for 'shop ' are more restricted than for 'hat1 and 'raincoat1 , because the physicalmovement meaning of 'taker is excluded with 'shopt because 'shopt is imrnoveable. When 'away ' is read and matched with 'taket , all meanings of 'take ' except the physical-movement meaning are eliminated. tShopt is now left dangling , so to speak , and is eliminated as a possible replacement noun. So when the end of the sentence is reached , there are two possible swviving replacement nouns , 'hat ' and 'raincoat'. There is no semantic reason for preferring one of these to the other , becaase the number of digits matched in the semantic match with 'take ' is the same in both cases. Therefore in ENDR a choice is made according to a formula of priorities</definiens>
				<definiens id="18">probably at 39 the moment .a rather blunt instrumeat. It is concerned with two factors -which noun occurred in a 1-ater clause , and which noun has the same function as the pronoun ; subject , objept , preposition object , or object of the same preposition. In the majority of cases it produces the correct answer , but it is possible to think up examples in which it doesn't. With experience of use , the formula will be refined. A complication is addea ~y rhe possibility that , when a subdect , 'itt may be impersonal. This sense is treated essentially as one possible replacement noun. There is still work to be done in developing the for , mula of priorities. CLAM extracts the information required to solve the pronoun problem. The question is , how to use it. Conjunction No mt of the program is more complex than that dealing with conjunct'fon. The principles are clear , Qeven simple , enough ; but applying them has demanded a considerable amount of care. Consider the fragment , He cleaned the carpets in the bedroom and ... ... When 'and1 is read , the EPs are as follows : EPI cleaned EP2 carpets EP3 in EP~ bedroom he the bedroom the carpets in All four of these EPs are alive , which is to say that the next word might be a continuation of any of them. On recognising a conjunction , the program looks for nnssible continuations in all alive EPs , from the beginning of the EP up to the point which has been reached. It carries out the necessary semantic matches</definiens>
				<definiens id="19">the subject of a verb EP , so the conjep.</definiens>
				<definiens id="20">entry , and opens EP5 thus : EP1 cleaned EP5 -- -- carpets EP5 is dependent on EPI at the subject position K5 ( b ) ... ..</definiens>
				<definiens id="21">the lead , or JSY~ as the object. The conjep IS attached to the lower EP , EP2 , but a dummy word is entered in EP1 and the semantic match is carried out between the dummy word , 'curtains ' , and the lead of the EP , 'cleanedt , EP1 cleaned EP2 carpets EP5 curtains he the theX carpets in EP5 is dependent on EP2 at the X curtains K5 lead position , 'The1 ris entered as a dummy word in EP5 because it comes before the point at which EP5 is dependent on EP2. A semantic match is carried out be % w ; een 'thev and 'curtainst. 'CurtainsT might also be the subject of a verb EP , so EPI is reproduced and another conjep started , attached to the reproduced EP at - % he subject position , as for ... ..and I ... ... aboqe. This path is unlikely to be correct , and will probably soon b~ eliminated , An attempt is also made to attach curtainst to EP~ in the lead position , but it fails because a dummy word curtainsi is then put into EP3 , and the semantic match between 'int and 'curtains1 is tried +and fails , Now let us see what the EPs 1ookd.ike at the end of a more complex conjunctive sentence : I , you and Nellie saw , watched and greeted the men , women and tired children. EPI saw EP2 I EP5 watched EP~ greeted EP7 men I K3 the ~4~ X youX YOU K8 ~e1li.e~ EP3 you el lie^ el lie^ 1c9 K5 ~4 ~6 men EP8 women X ~6 EP~ Nellie X X men women theX X men women childi-enx Kg X women childrenX EP9 children tired It will be seen that control passes from the conjeps 5 and 6 up to EP1 before 'men ' , so that 'men ' is entered as a word in EPI. But it is also entered as a dummy word in EPs 5 and 6 , and semantic matches are carried out with 'watched1 and 'greeted1. Also 'woment and 'children ' , although only dummy words in EPI , are entered as dummy words in EPs 5 and 6 as well , A c~njep remains open , and the EP ofi which it depends 42 remains closed until the last necessary word up to the branch has been filled. If the sentence had read , 1 you and Nellie saw , and 'he1 watched</definiens>
				<definiens id="22">open , and EP1 closed until arter tho lead w~rd twa-l ; chedlm A coma is treated as a possible conjunction or as FI possible braclcst. Bocauso of the dual role of c.i corntrln , tllc programming associated with it is rather awlc~qard. To sum up the treatment of conjunction , the possible continuations from a conjunction , particularly if'there have been previous conj~mctions in the sentence , can be numerous. But by the strict use of dumrriy entries and their associated semantic matches , false continuat~ons are usually quickly nosed out and eliminated. Also , for the recordirlg of the full meaning of a corij~uictive senterice fortho purpose of later interrogation , the dummy entry system is of course essential. And in the special case of comparative sente~~ces , it is only by such a system that it can be clearly established exactly what is being compared. Summary. I conclude this section with an assessment of what the analysis can and can not achieve. The purpose of analysis might be described as follows : to select , from among all the possible meanings of each word in the passage , its correct meaning in the context , and to determine what semantic relationships exist between '~qhich words , CLAN can do thzs with considerable efficiency within the confines of 9 single sentence. It is just beginning to enlarge its horizens to deal with longer texts. To clarify this statement let us consider the aids which enable us to select one meaning of a word raeher than another , and see which of them CLAM applies. the mechhic finishes his wo'rlc. Here tho word 'worlc ' is evidehtly a verb on the first occasion and 3 noun on the second. CLAM can usually deal easily enough with this type of ambiguity. discussed at some length.. The rules are both semantic and syntactic. When the rules are determined , CLAM will be in a position to apply th6m. of'words which exclude one meaning. Example : `` He took off his g~andmother.~ Here the two word verb 'take offt mugt me'mimicl. The personal subject and the existence of an object excludes the sense of a plane taking off , 'Grandmother1 as object excludes the sense of taking off clothes , Such restrictions are the basis of CLAM 'S semantic match</definiens>
				<definiens id="23">a semantic ambiguity. It is less straightforward than the previous example because the ambiguous word is 'with ' , whlch might be ~JI instrument preposition attached to the verb kill1 , or a possessicon preposition attached to the noun Vrnanl. The semantic relationships which determine the choice , however , ~nly involve 'witht indl ectly. They are between 'kill1 and 'gun1 in one case , and between 'man1 and 'gun1 in the other , NormalLy tlXle preference would be for the instrunlent ; interpretation because lg~pl ' is more strongly associated with 'killt as an instrument than with 'man1 as a possession. CLISrcI chooses the stronger association by taking the 'deepert semadtic match , ar 2n other words the match involving the Larger number of digits. It does this correctly , but as we shall see in a moment , it is not always correct to do so , 5 , Remoter contextual environment. Sometimes the factors enabling a choice to be made are more remote from the word in question than In the examples given above , In order to find these factors , a longer journey has to be made into the environment of the word , Examples : ( i ) `` The mayor hit the alderman so hard that he fell down. '' The normal rules for selection of pronotin antecedents would prefer 'mayor ' as the antecedent of 'he ' because it is the subjec-tt , but in the environment of hitting , it is much more likely to be the person hit who falls down rather than tb hitter , so 'alderman ' must be preferred. ( ii ) `` Two men came in. One had a gun and tho other had a knife. I killed the man with a gun. '' Here 'withT is obviously not an instrument preposition attached to lkilll , but a possession preposition attached to 'menv. This is so because the definite article 'thet attached to vmpn ' implies that 'man1 has already been defined , But in fact two men have already been defined , and more information is needed to determine which of them is referred to. The only possible additional information which could satisfy this requirement is 'with a gunr , whioh does suffice to distinguish one of the previously determined men. Therefore this phrase must be attached to 'manv , At present , CLAM could not resolve either sf these ambiguities. In order to do so it would need , in the fix '' st case , more information about the environment of 'hitt than is contained in the semantic restrictions now at its disposal , and in the second case , both a better memory and a routine for dealing with definition of nouns. Work is in progress on these vital additions. They will involve adding to the type and range of the semantic relationships between pairs of words referred to in the definition of the purpose of analysis given at the beginning of this summary. At present , CLAM only holds semantic relationships be-tween words which are syntactically related. This is not enough. Adding to the types of relationships held , and extending them to pairs of words which are syntactically remote , will greatly increase the scope of the model. GENERATION OF TFIE FIXENCFI TRANSLATION As shown in the flowchart , the sentence is operated on sequentially by four subroutines -- TWEN , ITRN , FRORM and PRIN. Briefly the function of each of these subroutines is as follows. TWEN examines all the verbs. It welds them ( joins auxiliaries to main verbs ) , and determines their tense in French. Thls is not of course necessarily the sane as in English. Other features of the sentence often have to be examined. Thus , `` When he arrives we will meet him '' , becomes in French , `` When he will arrive we will meet him '' . And `` I have been here for five years '' becomes `` I am here since five years. ! ! Gerunds , infinitives and participles are also dealt with by TWEN , It may well be asked why the weld part of this routine is thus left until the French generation. Should it not be done avring the reduction of the English sentence to base fo'rm ? The answer is that logically it should , and it will sooner or later be transferred , probably to ENDR. But at present it does n't matter. The part of the program described in the section on pronouns which stores the base form of the last sentences is in fact performed after the French translation has been generated , and therefore , after the verbs have been welded. ITRN takes each word in the sentence in turn. I ; t finds the code number in FRILE , the French dictionary file , and extracts the French word ( s ) . Sometimes of course there is more than one</definiens>
				<definiens id="24">translated. Any particular French word may not have the same function in the sentence as the English word. In such cases , the French word entry in FRILE is followed by a code which specifies the word 's function in x'glation to the English word being translated. For example , if 2.32237 isl the code for 'potato '</definiens>
				<definiens id="25">a plcepqsition in the EP of which POMME is the lead. The 6x2 after TEW shows that it is the object in the EP of which DE is the lead , Sometimes it isaecessary to go up Che tree. Fop example Y1x5 means an adverb ( 5 ) in the verb EP ( 1 ) of which the English word is a subsidiary ( Y ) . It is thus possible to generate a French sentdnce of a radically different shape from English. ITRY also finds a French sequence code for each word. This is a code which provides the ordering of words within an EP. All lead words have the code 200. A pre-noun adjective may have a code 140 , and a post-noun adjective 350. So these codes do not determine what is the actual sequence of words in the sentence , but they do provide the basic information from which the sequence is derived in FRORM. FRORM first derives the actual sequence of words in % he , sentence. It then takes each French word and puts it into the correct rorrn. Obviously the most arduous part of this tqsk is finding the forms of the verbs. FRORM refers to tables which contain the verb endrings for both irregular bd regular verbs , and the irregular feminine and plural endings for nouns and adjectives. PRIN prints the French translation , haying made any necessary elisions. If there is more than one solution , it prints alterna-bive translations of particular words on subsequen.1 ; linss or , if appropriate , it will print complete alternative sentences. CONCLUSION Programming Details and Future Developments Programmersmay be interested in some details. The program runs on a 360-40 using 146~ of core store. The program is mitten in FORTRAN IV , not an ideal choice but the best available in the circumstances. The reduction of the English to base form requires about 6,000 instructions , and the French generation about 2,500. At present all the files are 1cep-k in core store except for the two large dictionary files VOCAB and FRILE , which are accessed on disk. It will eventually be necessary to Keep JSP also on disk. At present the processing takes about 15 seconds per word on average , of which READ takes 4076 , the semantic and syntactic analysis about 20 % , and the French generation 40 % . No serims attempt has yet been made to optimise the program and this time could certainly be peduced. But the reduction would be offset by the eventual need to keep JSP on disk. So as a practical proposition for translating texts , it would be necessary for the processing time to be reduced by a factor of about 10. Presumably this will come sooner or later with improvement in hardware. There are certain improvements which would have -bo be made to the pogram before it could be used , apart from the extension of the vocabulary. Most obvious : ( a ) there are some syntactic structures such as inversion after negatives which the program does not at present recognise ; ( b ) a , selection routine must be incorporated in ENDR to choose between alternative solutions if more than one emerges ; ( c ) if no solution emerges the program should try again , selectively suppressing semantic matching , allowing words to be used outside their normal sense ; ( d ) the sizes of some of the temporary stores would have to be increased. No particular dirficulty is anticipated with any of these developments , in that they involve no methodology fundamentally different from what has already been applied. It is primarily a matter of time and priorities. However with a fifth development , namely the extension of the memory as outlined at the end of the section oh analysis , new ground must be covered</definiens>
				<definiens id="26">adverbial clause 1 time 2 place 3 purpose 4 reason 5 manner 8 condition 9 concession Amencan Journal of Computational Linguistics ~icrofiche 49 : 53 Slate Universily of New York REQUEST FOR PROPOSAL Federal Research &amp; Development by Contract WASHINGTON OFFICE STATE UNIVERSITY OF NEW YORK SEPTEMBER 1974 AJCL EDITOR 'S NOTE The document reproduced on these frames came to the Editor 's attention recently , in spite of the publication date. AJCL thanks the State University of New ~orE , copyright holder , and Mr. Mort Grant , Director of the Research Foundation of SUNY ; Ms. Winifred R. Widmer , Assistant Director for Administration ; Mr. William F1. Claire , Director of the SUNY Washington Office ; Mr. Jim Kalas and Ms. Susan G. , Sorrels of that Office ; for their several contributions to the appearance here of RFP. Some of the names and telephone numbers must no longer be correct ; but ACL and AJCL do not have the means to bring them up to date. The general understanding of the-system which this document provides is valuable to any ACL member who chooses to make use of it. Broader Federal support for the usepof computers in linguistics is probably the only way to bring the field to a much higher level of activity. Individual copies are available to all autlorized State University of New York personnel free of charge. Bulk orders , or other requests for copies can be arranged at a cost-of-print~ng charge of $ 1.50 per copy. All requests regarding this publication should be directed to the Washington Office , -State University of New -- York , Suite 500 , 1730 Rhode Island Avenue , N.W. , Washington , D.C. 20036 ( 202 , 659-2330 ) . Checks should be made payable to the Research Foundation of State University of New York. William F. Claire , Director Susan G. Sorrels , Edltor Carole K. Combs , Administrative Ass~stant Q State University of New York 1974 TABLE OF CONTENTS I , FEDERAL PROCUREMENJ ' FOR RESEARCH AND DEVELOPMENT : AN EXPLANATION OF THE RFP CONTRACT MECHANISM 11 , ALPHABETICAL LISTING OF FEDERAL AGENCIES WHICH CONTRACT FOR RESEARCH AND DEVELOPMENT Department of Agriculture Atomic Energy Commission Depart men t of Commerce Department of Defense Environmental Protection Agency Department of Health , Education , and welfare Department of Hous~ng and Urban Development Department of the Interior Department of Justice Department of Labor Department of Transportation Nationd Aeronautics and Space Administration National Science Foundation Srnithsonian instituhon United States Information Agency 111. GLOSSARY OF TERMS IV , INDEX OF AGENCIES AND DEPARTMENTS WITH FEDERAL CIVILIAN AND MILITARY RESEARCH AND DEVELOPMENT ACTIVITIES V. APPENDIX A Sample of Standard Form 129 Sample of Standard Form DOD 558-1 VI. BIBLIOGRAPHY ORIGINAL PAGE \rJUMBERS ARE AT THE BOTTOM OF THE FRAME INTRODUCTION In view of an incredsing interest in government agencies in pinpointing thclr rrscach needs , the Washington Office of State University of New York feels that it is appropn.ltc for its campuses to familiarize themselves withQ what is commonly c ; dled the RFP plocrss. Thr `` request for proposal , '' or the governrnetlt way of saylrlg th~t it is putr~r~g out bids to fulfill a specific need , is bccoming something that all cnnlpuses sllould bc awnrc of in thri efforts to secure all possible funding for research xnd devdopment from outside sources. Fcder 'd contracting out , as it were , can be a complicated process , but we hope that potcnt1.J 1nvcstig.rtors dl rcgard this information as preliminary. Aftcr that , there is n't ~riy substitute for dic .unount of work involved. Tlus booklct is dcsylcd to givc carnyur rcp~esent~~ti\lcs L~rl ovr.nr1eiv of tlic ngerlclm involved , as wen as ill1 undc~stnndin~ of '~nd cspla~l~~tlon of the RFP contract mrch ; wnm. We II~VC listed 15 sepalate agncics c~irrerltly invo1vt.d m this contrdct rncchnnisrn. thelr irltcrcst ~nd appropriate addresses for more inforrliation. We have also included a glossav of tcrnls .IS Ll guide and all index of the v , xious offices and bureaus within each of the 15 agencies. The time span from inception of an idea to actnnl publication IS always a lengthy one and many people have been involved with thls report. Willi.lrn Hedbcrq. L Susan Sorrcls. Jim Kalas , ~nd Carole Combs have all participated in its dcvelopmcnt. Bryan Sw.lrtz. \vlio lvined our office in the summer of 1974 as an lntcln from the Stony Brook campus. dcscrvcs sFcclal pralsc for his coordination of many activities leading to the publlcatlo~i of the book. Witllout Ms dedication to the project , it might have bcen delc~ ) red considcrnbl~. We are grateful to .dl of these people for thcir assistance. Wc hope tfi.~t the book w~ll prow GI v.duable \r ! nrLing glide for anyone interested in thc contrLIct system. Thc Wbwhlngton Office would bc plc~scd to provlde additional in€orm.~tion about thc c~ge~~clcs lnvolvcd. I. FEDERAL PRQCUREMENT FOR RESEARCH AND DEVBLOPMENT : AN EXPLANATION OF THE RFP CONTRACT MECHANISM Each year the federal government contracts for billions of dollars of work to support efforts deemed to be in the national interest. A significant percentage of the contract services are in the form of Research and ~evelopment ( R &amp; D ) or programmatic work which colleges and universities are particularly wcll-suited to perform. The government commits these funds in eithet of two WAYS : grants or contracts. University researchers are generally more familiar with the grant procedure than with the contract procedure. Under a grant program , a given federal agency is authorized to grant funds to non-profit institutions , frequently educational institutions , for the purpose of supporting research or a in a given general area. A body of general conditions are established by the Congress and refined by the applicable agency to set parameters for the pro $ am as a whole. A specific grant for a program can be made so long as it fits within the gevral stpndards ( the Guidelines ) of the program and meets whatever qualitative standards for review that have been established. Since grant funds</definiens>
				<definiens id="27">generally awarded for the purpose of meeting a specific reqwrement that a federal agency has determined to be important to the achievement of .the agency : s responsibilities. The contract will tend , therefore , to be specific in terms of the agency 's needs , and in the case of research , wdl usually be for the purpose of `` applied '' rather than `` basic '' research. The contract , also unlike the grant , can be negotiated with any organization that is legally constituted to do business w~th the government , whether non-profit or profit-making. Government procurement m its present massive scope is a relatively new phenomenon , having emerged fin as prpscnt form in the past quarter of a century. Each of the many federal agencies involved in procurement and most are developed a set of standards'and procedures to administer the contracting process. While the procedures used by any gven agency tend to be relativel ) orderly in terms of that agency 's requirements , they will not necessarily conform to the practices of anoJler agency. Looking at the federal government as a whole , however , the set of. practices is varied , highly technical and often confusing. The general descriptions offered in 'this statement , therefore , are subject to the differing qualifications and refinements established by individd government agencies. In recent years there has been an attempt to bring mter-agency consistency to the procurement ' process. A speclal government task force has recommended legislation -which would bring uniformity in procurement policy. Congress is considering such legislation , which will be discussed later. Basic contractual agreements with the federal government are developed in one of four ways : A. Sole Sotrrce I'roclrrement. The government negotiates with one and only one provider on the grounds that the product or service is uniqucly provided by the organization in question. B. Sitlqlc Solrrco Procir r ( wlolt Thc governmcot ncgotlatcs with onc and onl ) . onc profidel in ir~stances whcrc tllcrc could bc cnmpctlttve Lids but becnusc of f'ictors such .IS locnnon , co~lvenienc~ or spoc1.d urgency competitive bidding 16 unwarranted. C. Cutrlpc &gt; titi~~e Nrgothltiotr In instances where providers are few and known to the government , cornpetltion is litnited to tllc known promders and publicity reg , uding thr availability of</definiens>
			</definition>
			<definition id="3">
				<sentence>Address : Associate Drector fot ~xtramurd and Collaborative Programs National Eye Institute Builmng 31 , Room 6A-04 Bethesda , Md. 20014 el : 301 , 496-4903 National Heart and Lung Institute Irlterests : Research in lipid me tabolisrn : materials that are compat~bre wth blood and other tissues , instrumeatation for improved diagnosis and monitoring of patients , and devlces for the treatment of patients with mad &lt; quate or fading circulatory or pulmonary functions ; cause , treatment and prevention of myocar &amp; al infarction ; supply , . safety , utdization , distribution and use of blood ; respiratory chseases ; and sickle cell anemia. Address : Dxec tor , ~ational Heart and Lung Illstitute ~uddin~ 31 , Room 5A52 Bethesda , Md. 20014 Tel : 301 , 496-5166 National Library of Med~clne Interests Application of advanced communicanon and computer techniques to meet the information needs of health care professionals. Inforrnatlon storage and retrieval systems , micro &lt; dm systems , clearinghouses , data banks , timesharing computer networks. Cable , microwave and satellite com~unications networks for voice , video , and data transmission. Computer and communicatiqns terminals , facsimile , slowscan vldeo Evaluation of interation of communications technology and health care systems. Address. Aector , National L~brary of ~edicine Room M-101 Bethesda , Md. 20014 Tel : 301 , 496-6221 Clinical Center hiterests. Provldes patlcnt care in support of the clincial investigations conducted by thc categor1ca.l Institutcs. A dciress : nrector , Cllnical Center National ltlstitutcs of Health 9000 Rockvillc Pike Building 10 , Room IN212 Bethesda , Md. 20014 Tel. 301 , 496-4114 Division of Res &amp; rch Sex-v~ces In retests Provldes Faclllties , equipplent , and a wlde vanety of scientific and tcchn~cal servlces essential to ; he needs of the medical investigatots and lesearch admirlistratorq at NIH. Address nrec tor , Dvision of Research Services , ~a tional Institutes of Health 9000 Rockvllle Prke ~ullding 12A , Room 4007 Bethesda , , Md. 20014 Tel : 301 , 496-5793 Division of Research Graats Interests ' evel lops , coordinates , and implements policies and procedures governmg management of public Health Service extramural grants programs. Address : Director , D~vlslon ~f ~csearch Grants Westwood ~fiilding 5401 Wcstbard Avenue Room 452 Washington , D. C. 20016 'Tcl : 301 , 496-7381 Division of kesearch Resotrrccs lritcrcsts : Axds institution ~n thc cc-nstructlorl of tlcw and icrnodclccl n~cdic , ~l rcscnrch facilitics : llclps thcrn cstablisl~ .~ttd opetatc .I tlut11bcr of gellcr.d clinical rese'u-ch centers : su y plics a va~iety of unuru , d .uid liigllly special resea~cll scraces and cquipn~crlt such as computers : suyports regional prirn'xto research centers , and stir~~ulates well-balanced institutional rescarch programs through grants for genernl blomedicd research support mntical and other computer-related sciences. l~lcludln~ inforsilation proces~r ; ~ , in support of NIH programs. *-l~l~ll~~ $ .c ; 131 cctor , Chvislon of Co~nputcr Rcsc u '11 and Tecllnology N , I~~OI~A~ I~lstitute of Health 9000 Rockvillc Pike ~uildin~ 12A. Rootil 3033 ~cthesda , Md. 20014 Tcl : 301 , 496-5703 Fogarty International Ccn tcr Ivltert &gt; xtx Provides the Rcd~c ) for dlscusslon .</sentence>
				<definiendum id="0">Address</definiendum>
				<definiens id="0">Associate Drector fot ~xtramurd</definiens>
			</definition>
			<definition id="4">
				<sentence>and Welfare ( continued ) Division of Research Services 16 Divlsion of Research Grants 16 Division of Research Resources 17 Division of Computer ~escarch and ~echnology 17 Fogarty International Center 17 Health ~esoureei Administration17 Bureau of ~edth Services Research 17 Division of Health Cilre information Systems and Technology 18 Dvision of Hedth Systems ~esearch and Development 18 Division of Hedth Services Design and ~evelopment 18 division of Health Services Qudity Resewch 18 Division of Health Services Rcsearch and Analysis 18 Division of Long Term care 18 Bureau of ~edth Resources Dcvclopment 18 Division of Associated Health ~rofessions 18 Ih~ion of Dentistry 18 Diwion of Nursing 18 Division of Medicine 18 Division of Comprehensive Health Planning 18 National Center for Health Statistics f 9 Alcohol , Drug Abuse , and Mental Heatlh Administration 19 National Institute of Mental Health 19 National Institute of Alcohol Abuse and Alcoholism 69 ~ationd Institute on Drug Abuse 19 Food and Drug Administration 19 Office of Education 20 Social and Rehabilitation Servlce 20 Department of Houslng and Urban Development 20 Department of the interior 20 Bureau sf Mines 21 office of Water Resources Research 21 Office of Assistant Secretary Energy and Minerals Research 21 National Park Service 21 office of Cod Research 21 United States Fish and wildlife Servlce 21 Department of Justice 22 Law ~nforcement Assistance Administration 22 National lnstltute of Law ~nforcement and Crmlnd Just~ce 22 Department of Labor 23 Office of Administrative Semces office of the Assistant Secretary 23 Bureau of Labor Statistics 23 Department of Labor ( continued ) Labor Management Services Administrat~on 23 Occupational safety and ~ealth Administrat~on 23 ~mployment Standards ~dmimstrat~on 23 Manpower Administration 23 office of Policy , Eduation and Research 23 Bureau of International ~ffaks 24 Department of Transportation 24 office gf the Secretary for University Research 24 Office of the Assistant -Secretary for Pohcy and Internationid ~ffairs 24 office of the Assistant Secretary for Environment and Urban Systems 24 office of the Assistant Secretary for Systems l ?</sentence>
				<definiendum id="0">Welfare</definiendum>
				<definiens id="0">Bureau sf Mines 21 office of Water Resources Research 21 Office of Assistant Secretary Energy and Minerals Research 21 National Park Service 21 office of Cod</definiens>
			</definition>
			<definition id="5">
				<sentence>D. SERVICE ESTABLISHMENT means a concsrn ( or person ) which owns , operates , or maintains any type of buslness which is princlpally .</sentence>
				<definiendum id="0">D. SERVICE ESTABLISHMENT</definiendum>
				<definiens id="0">means a concsrn ( or person ) which owns , operates , or maintains any type of buslness which is princlpally</definiens>
			</definition>
			<definition id="6">
				<sentence>Busmess concerns are affil~ates of each other when either directly or indirectly ( I ) one concern controls or has the power to control the other , or ( 11 ) a third party controls or has the power to control both In determining whether concerns are independently , owned and operated and whether or not affiliation exists , consideration is given to all appropriate factots including common ownership , cornmon management , and contrcrctual relat onshlp ( See items Nos. 6 and 10 . )</sentence>
				<definiendum id="0">Busmess concerns</definiendum>
				<definiens id="0">a third party controls or has the power to control both In determining whether concerns are independently , owned and operated and whether or not affiliation exists</definiens>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>The plus signs under the categories PV ( verbal predicate ) and SV ( verbal sentence ) stand for adjunction , one of the basic types of junction recognized by Junction Grammar .</sentence>
				<definiendum id="0">SV</definiendum>
				<definiens id="0">verbal sentence ) stand for adjunction , one of the basic types of junction recognized by Junction Grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , the rule A+BC allows the well-formed structure A Further , the rule n B C A -- BC/F G is construed as saying that a subtree with A immediately dominating the sequence BC is a well-formed subtree provided that elsewhere in the tree a node F immediately precedes A and A immediately precedes a node G. Thus , as an example , the following tree is well-formed from the rules indicated .</sentence>
				<definiendum id="0">BC</definiendum>
				<definiens id="0">the rule n B C A -- BC/F G is construed as saying that a subtree with A immediately dominating the sequence</definiens>
				<definiens id="1">a well-formed subtree provided that elsewhere in the tree a node F</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , if John is tall ( as a person ) and John is a basketball player , we can not conclude that John is a tall basketball player .</sentence>
				<definiendum id="0">John</definiendum>
				<definiens id="0">tall ( as a person ) and</definiens>
				<definiens id="1">a basketball player</definiens>
				<definiens id="2">a tall basketball player</definiens>
			</definition>
			<definition id="3">
				<sentence>The analysis step must accept natural language input and produce the appropriate junction tree for each segment of text ( normally , but not necessarily , a segment is a sentence ) , according to the context of that segment .</sentence>
				<definiendum id="0">segment</definiendum>
				<definiens id="0">a sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>A.Jane The order rule representat ion : ( N + ( V + N ) ) ( N + ( V + N ) ) N ( it ) * N ( girl ) V ( surprised ) N ( Aunt Jane ) V ( loves ) N ( car ) 0 * ( The operation of full sub j unct ion ) 0 0 A variation of the complement response is : `` He came after we ate dinner . '</sentence>
				<definiendum id="0">N ( Aunt Jane ) V</definiendum>
				<definiens id="0">N + ( V + N ) ) ( N + ( V + N ) ) N ( it ) * N ( girl</definiens>
			</definition>
			<definition id="5">
				<sentence>B. Transfer Withih the context of Junction Grammar , a transfer grammar from a source language S to a target language T is an algorithm which inputs a junction tree from an analysis grammar of S and outputs the junction tree , with any needed adjustments , to a synthesis grammar of T. In the present implementation , we are developing transfer grammars from English into Spanish , German , French , and Portuguese ( abbreviated SSP , GER , FRN , and POR ) .</sentence>
				<definiendum id="0">Portuguese</definiendum>
				<definiendum id="1">POR</definiendum>
				<definiens id="0">a transfer grammar from a source language S to a target language T is an algorithm which inputs a junction tree from an analysis grammar of S and outputs the junction tree</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus , a transfer grammar can be made machine executable simply by loading records into the key files and the transfer program files .</sentence>
				<definiendum id="0">transfer grammar</definiendum>
				<definiens id="0">executable simply by loading records into the key files and the transfer program files</definiens>
			</definition>
			<definition id="7">
				<sentence>The TL loader compiles the programs into a pseudo-machine language which is stored in the transfer program file and is interpreted at execution time in the second phase of transfer .</sentence>
				<definiendum id="0">TL loader</definiendum>
				<definiens id="0">compiles the programs into a pseudo-machine language which is stored in the transfer program file</definiens>
			</definition>
			<definition id="8">
				<sentence>GENERAL STRUCTURE OF TL TL is a free-format , block-structure , list-processing language similar in general form to PL/I or ALGOL .</sentence>
				<definiendum id="0">GENERAL STRUCTURE OF TL TL</definiendum>
				<definiens id="0">a free-format , block-structure , list-processing language similar in general form to PL/I or ALGOL</definiens>
			</definition>
			<definition id="9">
				<sentence>As previously mentioned , a transfer grammar is a set of keys and transfer programs .</sentence>
				<definiendum id="0">transfer grammar</definiendum>
			</definition>
			<definition id="10">
				<sentence>The built-in fanction A moves to the next level of adjunction ( e.g. from a V to its PV ) and Y moves down the tree to the right brother Other built-in functions include X [ which moves down to the left brother ) , L ( which moves up to the father ) , B ( which moves down successive sons , or left brothers , until reaching a terminal node ) , S ( which moves from the father of a point of intersection in a ranking tree to the corresponding father node in the subordinate tree ) , R ( which moves from subordinate trees to ranking trees ) , and C ( which moves to the SV governing the start node ) .</sentence>
				<definiendum id="0">built-in fanction A moves</definiendum>
				<definiendum id="1">B</definiendum>
				<definiendum id="2">S</definiendum>
				<definiendum id="3">R</definiendum>
				<definiens id="0">moves from subordinate trees to ranking trees ) , and C ( which moves to the SV governing the start node )</definiens>
			</definition>
			<definition id="11">
				<sentence>The statement ON CONDITION ( N0-LABEL ) TRANSFER 1 sets up an ON UNIT so that if at any time during transfer on the current node an attempt is made to move up from a node without a label , transfer 1 will be executed .</sentence>
				<definiendum id="0">statement ON CONDITION</definiendum>
			</definition>
			<definition id="12">
				<sentence>. . . '' Here it is assumed MATCH has been defined as a keyword so that this statement is equivalent to the pair of statements : LET C49 BE SMATCH ( =2 , =3 ) IF C49 IS TRUE . . . The built-in function SMATCH checks the parameters of the stimulating key against the index of the node pointed to by the first argument ( 52 ) .</sentence>
				<definiendum id="0">LET C49 BE SMATCH</definiendum>
				<definiendum id="1">built-in function SMATCH</definiendum>
				<definiens id="0">checks the parameters of the stimulating key against the index of the node pointed to by the first argument ( 52 )</definiens>
			</definition>
			<definition id="13">
				<sentence>V * PA n A+E SP A* PV=Z ( passive by John participle ) V + N=4 @ assive constituent ) give The above description of Transfer Language and the sample transfers should convey some idea of transfer within Junction Grammar , but it should also point out the difficulty of comparing Junction Grammar transfer with the intermediate adjustment phase of some other translation system ( e.g. [ ll ] , [ 12 ] , [ 13 ] ) .</sentence>
				<definiendum id="0">V * PA n A+E SP A* PV=Z</definiendum>
				<definiens id="0">Grammar transfer with the intermediate adjustment phase of some other translation system</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>Associated with the PARSER is a network LOCATOR , which determines whether a ckrent user description refers to an existing topic at some level in the network .</sentence>
				<definiendum id="0">PARSER</definiendum>
				<definiens id="0">a network LOCATOR , which determines whether a ckrent user</definiens>
			</definition>
			<definition id="1">
				<sentence>To locate 1t , the PARSER fgrs't deterdaes tlie focus phrase , the active phrase at the highest dependency level .</sentence>
				<definiendum id="0">PARSER fgrs't</definiendum>
				<definiens id="0">deterdaes tlie focus phrase , the active phrase at the highest dependency level</definiens>
			</definition>
			<definition id="2">
				<sentence>The centrab objective is to provide the user with framework for defining the important topics or informational objects he deals with , and to enable him to easily associate items in his data base with these entities .</sentence>
				<definiendum id="0">centrab objective</definiendum>
				<definiens id="0">the important topics or informational objects he deals with , and to enable him to easily associate items in his data base with these entities</definiens>
			</definition>
			<definition id="3">
				<sentence>AUTONOTE is an on-line retrieval system that runs a &amp; a user program under the Michigan Terminal System ( MTS ) , a time-oharing system implemented on the IBM 370/168 .</sentence>
				<definiendum id="0">AUTONOTE</definiendum>
			</definition>
			<definition id="4">
				<sentence>AUTONOTE makes extensive use of the WS disk file system EiflIS disk files ( line files ) may be read or written either sequentially or in an indexed fashion by specifying a line file number .</sentence>
				<definiendum id="0">AUTONOTE</definiendum>
				<definiens id="0">makes extensive use of the WS disk file system EiflIS disk files ( line files</definiens>
			</definition>
			<definition id="5">
				<sentence>L AND SYSTEMS adds a new descriptor , SIRS , to the index that references each item having the words INFORMATION , RETRI~vAL , and SYSTEMS as descriptors .</sentence>
				<definiendum id="0">SYSTEMS</definiendum>
				<definiens id="0">a new descriptor , SIRS , to the index that references each item having the words INFORMATION , RETRI~vAL , and</definiens>
			</definition>
			<definition id="6">
				<sentence>AllTONOTE provides a grouping facility which permits the user to organize text items in several useful ways .</sentence>
				<definiendum id="0">AllTONOTE</definiendum>
				<definiens id="0">provides a grouping facility which permits the user to organize text items in several useful ways</definiens>
			</definition>
			<definition id="7">
				<sentence>At any time , the single command : RETRIEVE USERS-WAL causes the entire updated data base to be displayed in organieed fom : Command modifiers .</sentence>
				<definiendum id="0">RETRIEVE USERS-WAL</definiendum>
			</definition>
			<definition id="8">
				<sentence>Each simple phrase consists of a subject noun and a modifier word .</sentence>
				<definiendum id="0">simple phrase</definiendum>
				<definiens id="0">consists of a subject noun and a modifier word</definiens>
			</definition>
			<definition id="9">
				<sentence>Additioaally , the simple phrase THE ACM CONFERENCE is subordinate TO THE PAPER FOR TWE CONFERENCE .</sentence>
				<definiendum id="0">simple phrase THE ACM CONFERENCE</definiendum>
				<definiens id="0">subordinate TO THE PAPER FOR TWE CONFERENCE</definiens>
			</definition>
			<definition id="10">
				<sentence>Simple phrases identifying the confer~nce will describe a subordinate node due to the syntactic dependency of `` conference '' upon `` paper '' in a phrase of the form , PAPER AT THE ... CONFERENCE .</sentence>
				<definiendum id="0">Simple phrases</definiendum>
				<definiens id="0">identifying the confer~nce will describe a subordinate node due to the syntactic dependency of `` conference '' upon `` paper '' in a phrase of the form , PAPER AT THE ... CONFERENCE</definiens>
			</definition>
			<definition id="11">
				<sentence>Associated with each instance of a simple phrase is a po9nter to the node where item references are stored , Finally , bookkeeping information stored with each text item includes pointers to each topic node with which the item is associated .</sentence>
				<definiendum id="0">simple phrase</definiendum>
				<definiens id="0">a po9nter to the node where item references are stored , Finally , bookkeeping information stored with each text item includes pointers to each topic node with which the item is associated</definiens>
			</definition>
			<definition id="12">
				<sentence>I£ the current description is THE PAPER , for example , the system would use the word directory to locate those simple phrases where PAPER is the subject noun .</sentence>
				<definiendum id="0">THE PAPER</definiendum>
				<definiendum id="1">PAPER</definiendum>
				<definiens id="0">the subject noun</definiens>
			</definition>
			<definition id="13">
				<sentence>The matching routine uses a list of the candidate nodes , a list of the active phrases in the description , and the current contents of the representational network .</sentence>
				<definiendum id="0">matching routine</definiendum>
				<definiens id="0">uses a list of the candidate nodes , a list of the active phrases in the description</definiens>
			</definition>
			<definition id="14">
				<sentence>While working in the context of a particular paper , for example , the user may describe a new item as THE ORGANIZATION OF THE PAPER , where ORGANIZATION OF PAPER is a non-active phrase .</sentence>
				<definiendum id="0">ORGANIZATION OF PAPER</definiendum>
				<definiens id="0">a non-active phrase</definiens>
			</definition>
			<definition id="15">
				<sentence>The wrd directory is first searched for simple phrases in which the word appears as the subject and , if necessary , the modifier .</sentence>
				<definiendum id="0">wrd directory</definiendum>
				<definiens id="0">simple phrases in which the word appears as the subject</definiens>
			</definition>
			<definition id="16">
				<sentence>The SPEAKER Conrpanent As we have seen , SPEAKER is invoked during many phases of AUTONOTE2 's operation .</sentence>
				<definiendum id="0">SPEAKER</definiendum>
			</definition>
			<definition id="17">
				<sentence>For example , suppose a topic is first defined as SAMPLE DESCRIPTIONS FOR USE IN THE ACM PRESENTATION , and later is referred to as SAMPLE DESCRIPTIONS FOR USE IN THE NSF PROPOSAL .</sentence>
				<definiendum id="0">topic</definiendum>
			</definition>
			<definition id="18">
				<sentence>USER : YES DO YOU WANT : A. ML 'S TALK AT THE CONFERENCE ON THE REPRESENTATION OF A PROBLEM SOLVING SYSTEM B. ROBINSON 'S TALK AT THE CONFERENCE ON THEOREM PROVING SYSTEMS C. LIN 'S PAPER AT THE CONFERENCE ON THE HEURISTIC SOLUTION OF 'LARGE COMBINATORIAL PROBLEMS D. BANERJI 'S OVERVIEW OF GAME PLAYING PROGRAMS AT THE CONFERENCE E. SIMMONS REVIEW OF QUESTION ANSWERING SYSTEMS AT THE CONFERENCE F. OTHER TALKS AT THE CONFERENCE G. SLAGLE 'S DISCUSSION AT THE CONFERENCE ON HEURISTIC SEARCH PROGRAMS He FImS PRESENTATION AT THE CONFE'IIENCE OF AN ALGOL-LIKE LANGUAGE FOR PROBLEM SOLVING PROCEDURES I. FEIGENBAUM 'S DISCUSSION AT THE CONFERENCE OF THE DENDRAL J. BANERJI 'S Fig .</sentence>
				<definiendum id="0">USER</definiendum>
			</definition>
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>T11ia fotms an important paet uf s question-answering system under de~ @ logmnt with natural language ( Japanese ) input .</sentence>
				<definiendum id="0">T11ia</definiendum>
				<definiens id="0">fotms an important paet uf s question-answering system under de~ @ logmnt with natural language ( Japanese ) input</definiens>
			</definition>
			<definition id="1">
				<sentence>The paxscr cottsists essrntisll wf four fixed cornp~ &gt; pcArs* I $ The grammar consists of rules written in PLATDE ; , PLATOK 1s a new programming language which is a variant of the sqqtem deuelwped by Woods ( 1970 ) called 'Augmented Tkansitlon Network PLATON has add~tlonal facilities for pat tern matching and flexible backtr ackinp , A grammatical rule in PIATOW consists of two parts pattern rewrite which 1s expressed as a pair of syntactic patterns , and semantic and contextual check bhich is an arbitrary LISP function .</sentence>
				<definiendum id="0">grammar</definiendum>
			</definition>
			<definition id="2">
				<sentence>Ffllen a rule is to be applied , the semantic and contehtual chech is emplnved to determine whether the rule is mwnr ically and csnteutuallv feasihlo , For the present we have about two hundred rules for the analysis of Japanese sentences , These rules are devised to combine Various syntactic patterns in Japanese with appropriate sewntlc and contevt ual checklng functlohs , PLATON is presented in more detall In another papec by Nagao and Tsujil ( 1976 ) .</sentence>
				<definiendum id="0">PLATON</definiendum>
				<definiens id="0">devised to combine Various syntactic patterns in Japanese with appropriate sewntlc and contevt ual checklng functlohs</definiens>
			</definition>
			<definition id="3">
				<sentence>Contcxtnal fu~~ctiuns votk on these Sis ts to seaxck appropriate nudes of the semantic ne twark correseend to the referents sf snaphosic expressions or the unex~sessed rLewnts of sentences , ( 4 ) Selaant~c and Contextual functions are propmmned in LISP These functions are lncorposated in the PLATON rules along with rewrltlng patterns A contextual function takes as arguments the seaantls constsalnts a target node must satisfy and returns the node when an appropriate node rs found from the semantic network A senwntic fu~ction cheeks dcscriptiuns in tt~c dic ~~QII , ILY te7 dc turnline ~~hcrt~er tEw cwrnhin , ~t ion of two 'r~ards is sen~anticallv pedwsibl~ , For analp zing nourl-nc7tnl combir~ations , wc provide sixteen semantxc functions .</sentence>
				<definiendum id="0">senwntic fu~ction</definiendum>
				<definiens id="0">an appropriate node rs found from the semantic network A</definiens>
			</definition>
			<definition id="4">
				<sentence>Tna verbs FUERU [ increase ) and MERU ( deciease ) are such &amp; xamples gf verbs .</sentence>
				<definiendum id="0">MERU</definiendum>
			</definition>
			<definition id="5">
				<sentence>kR erntTncr is rr~ardad aa ACT .</sentence>
				<definiendum id="0">kR erntTncr</definiendum>
				<definiens id="0">rr~ardad aa ACT</definiens>
			</definition>
			<definition id="6">
				<sentence>gas volume -ti'C~ $ increase The volume sf th @ gas incrwses -Cb ) IOU -MA KIIROI sulfur -- ( SUB~ : , -- vellow ( 3 ) OBJ OOBJect is the ~ecci d11g end of an octiwitv .</sentence>
				<definiendum id="0">OBJ OOBJect</definiendum>
				<definiens id="0">the ~ecci d11g end of an octiwitv</definiens>
			</definition>
			<definition id="7">
				<sentence>( 1 HZU -GA SUIJOUKI -MI UQV , water - ( SUBJ ) , $ team - ( RESULT ) becw The water becomes steam ( 7 ) INST ; IWSTrumant is an object used as the tool or device by which sn aerfwlcg is carried ~ut asra-pasar ( a ) -- BE MTZU -0 WSSmW .</sentence>
				<definiendum id="0">IWSTrumant</definiendum>
			</definition>
			<definition id="8">
				<sentence>( 11 ) IN , IN indicates a mre specific relation tp PLACE .</sentence>
				<definiendum id="0">IN</definiendum>
				<definiens id="0">indicates a mre specific relation tp PLACE</definiens>
			</definition>
			<definition id="9">
				<sentence>In our system the influenre on the objects is described by the following three expressions : ( a ) ( ADD case a-set-of- ( A V ) -pairs ) ( b ) ( DELETE case a-set-of-attributes ) ( c ) ( CREATE lexical-nam-of-an-objec t a-se t-of ( A Vj -pairs ) ( a ) mans that the object rn the case indicated by the second element comes to have a set of prgpertles lndrcated by the thasd element .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">Vj -pairs )</definiendum>
				<definiens id="0">the object rn the case indicated by the second element comes to have a set of prgpertles lndrcated by the thasd element</definiens>
			</definition>
			<definition id="10">
				<sentence>JDUTAl ( ststel in the second example dig'lgnatea en attribute of SANS0 ( oxygen ) , and the w~rd EKITAl doee not correspond to a real object but is used to specify the attribute 'state ' of the oxygen .</sentence>
				<definiendum id="0">JDUTAl</definiendum>
				<definiens id="0">a real object but is used to specify the attribute 'state ' of the oxygen</definiens>
			</definition>
			<definition id="11">
				<sentence>( t ) They check whether a new at hand Bsn salve the1 problems in TL , ( ii ) If it can do so ; they update the dlta ( for example , iE the function F1 is the function which searches thp words in TL for fdling in the ?</sentence>
				<definiendum id="0">F1</definiendum>
			</definition>
			<definition id="12">
				<sentence>KOMO -NI test tube ( ACT SUBJ ) exist in ( PUCE , RESULT ) There is a test tube , In the ( test tube ) 1 The ncrw WKA ( in ) is a pzeposdtiurtaS , noun which require8 B container1 or 'liquid ' , We em easily racopite the test huleict se s Ssvar concept noun sf 'clontainar , ' Therefore wc aasum tha word ROgO is uad f~r the test tube , Xf we find no such nouns , wet gupposc that the axtiel @ KOw i~ not of thle eacpbnd usage But of the first .</sentence>
				<definiendum id="0">KOMO -NI test tube</definiendum>
				<definiens id="0">a test tube</definiens>
				<definiens id="1">uad f~r the test tube</definiens>
			</definition>
</paper>

		<paper id="1074">
			<definition id="0">
				<sentence>: ... ... ... 48 ABSTRACT The semantics of Moritague 's The proper treatment of quantification in ordinary English ( PTQ ) uses an intensional model to evaluate formulas .</sentence>
				<definiendum id="0">PTQ )</definiendum>
				<definiens id="0">uses an intensional model to evaluate formulas</definiens>
			</definition>
			<definition id="1">
				<sentence>~tz~vj dngrish ( PTQ ) , Richard Montague sets up a system which uses model-theoretic semantics to provide meanings for English sentences .</sentence>
				<definiendum id="0">PTQ</definiendum>
				<definiendum id="1">Richard Montague</definiendum>
				<definiens id="0">sets up a system which uses model-theoretic semantics to provide meanings for English sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>and PYu'nicoriz , ' ) ( i I and F ( r~alk ' ) ( i ) E D &amp; s , e ) : t &gt; In the model , there are 16 meinbers of 9 and we use , e &gt; , t &gt; BOt * , rB15 a $ their names ; they are defined by : There are 16L = 256 members of D 0 , &lt; cbe &gt; , t &gt; ) and they wlll not be enumerated here .</sentence>
				<definiendum id="0">PYu'nicoriz</definiendum>
				<definiens id="0">r~alk ' ) ( i ) E D &amp; s , e ) : t &gt; In the model</definiens>
			</definition>
			<definition id="3">
				<sentence>The set ofentities , A = D , is also known as the set of e individuals .</sentence>
				<definiendum id="0">set ofentities</definiendum>
			</definition>
			<definition id="4">
				<sentence>( x ) t- , [ `` MI ( `` rc ) I I d , i , gr is 1 iff for all x E D ds , $ 7 [ wcr~k ' ( x ) t , [ `` MI ( `` r ) ] ] m Ji3 ( ] '' is 1 where gfl is a a-assignment like g ' except that 9 . ''</sentence>
				<definiendum id="0">MI</definiendum>
				<definiendum id="1">gfl</definiendum>
			</definition>
			<definition id="5">
				<sentence>A fram &amp; sed 2 ; 5 is an indexed family of danotatlbn-sets , ( D-a ) a E typx ?</sentence>
				<definiendum id="0">D-a</definiendum>
				<definiens id="0">an indexed family of danotatlbn-sets</definiens>
			</definition>
			<definition id="6">
				<sentence>3 war on 4 -- and rrrrixJ is a pdir C ( 2 a ) a saps F &gt; where , , I 1 ) ( D-3 ) BE ; ~ &amp; ~s is a Frame based an A apd IxJ , where I is a set of p~ssihle wcsl~ !</sentence>
				<definiendum id="0">rrrrixJ</definiendum>
				<definiendum id="1">~s</definiendum>
				<definiens id="0">a Frame based an A apd IxJ</definiens>
			</definition>
			<definition id="7">
				<sentence>s and J is an ordered set of nomznts in time .</sentence>
				<definiendum id="0">J</definiendum>
				<definiens id="0">an ordered set of nomznts in time</definiens>
			</definition>
			<definition id="8">
				<sentence>2 ) F is the hsaninq function which assigns to ezcn LOQIC~L constant ~f type 2 an elzment of the denotation-set D &lt; ; , a &gt; , Zv3luation -- -- c -- -- Evaluation is a rcla tionship hatueen .</sentence>
				<definiendum id="0">Evaluation</definiendum>
				<definiens id="0">a rcla tionship hatueen</definiens>
			</definition>
			<definition id="9">
				<sentence>: I a and V is a variable of type b , then d [ ( LABBD.4 v B ) , j g ] is thaf fulr~tion h with domain D-b such that whenever x is i h that donlain , h Qx ) is d [ ~ ; ~ , i , j , qt Ir where qt is a variable assignment like CJ except EM the possible differance that gt ( V ) is x , 4 ) ~f ncYE &lt; arb &gt; and C ~b !</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">qt</definiendum>
				<definiendum id="2">V</definiendum>
				<definiens id="0">a variable of type b</definiens>
				<definiens id="1">a variable assignment like CJ except EM the possible differance that gt (</definiens>
			</definition>
			<definition id="10">
				<sentence>, g ] is 1 for some j1 such that j1 &lt; j , 9 ) If PC Mg TS and V is a variableof type a , then a [ ( THEFL-IS V P ) ; ? !</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">a variableof type a , then a [ ( THEFL-IS V P )</definiens>
			</definition>
			<definition id="11">
				<sentence>I ) a , then d [ ( IAX ) ; -ti , i , j , g ] is that function h with doma in IxJ such that whenever &lt; i ' , j E IxJ , Standard Eodels -. -- u.IIICI*r ) .-r -- I -- A atandaha ffaag bdsed qg _-_ dn3 _ S is a frame based on A and S in which all possibl~ functicns xcur in the denotation-sets , D a D S that is , &lt; atL ) &gt; = 3 fr and Z !</sentence>
				<definiendum id="0">IAX</definiendum>
				<definiens id="0">a frame based on A and S in which all possibl~ functicns xcur in the denotation-sets</definiens>
			</definition>
			<definition id="12">
				<sentence>We therefore introduc2 a r , cw formal defihition of 'named models ' , This dezinition allows a model that map be smaller than a ymod @ l , but expands toward a q-model when new functions are A named mo ; iel ( n-model ) is based on a frame which need not be closed undzr valuation , The valuation function d is a partial function , undefin~d where the valuation function as defined above take $ a value not in the model .</sentence>
				<definiendum id="0">valuation function d</definiendum>
				<definiens id="0">a model that map be smaller than a ymod @ l , but expands toward a q-model when new functions are A named mo ; iel ( n-model ) is based on a frame which need not be closed undzr valuation</definiens>
			</definition>
			<definition id="13">
				<sentence>Where PTQ uses special symbols , e.g. , iV , IV , for the cogpound syntactic catqories , 5/ @ , , V/TZ , we also use these special symbols , Flpwaver , there are types that ja not corcesponil to syntactic cat~ .</sentence>
				<definiendum id="0">PTQ</definiendum>
				<definiens id="0">uses special symbols , e.g. , iV , IV , for the cogpound syntactic catqories</definiens>
			</definition>
			<definition id="14">
				<sentence>P~A-ex~r~ssioj~s and INT-expressions can add r , ew elements to the model , The aenotation of a LAYBDAexprassior , , Such as ( L'AYP~R X ( WALK X ) ) + is a function Elhose aFguments are the possible denotatiurlz that can be assigned to the variable , .</sentence>
				<definiendum id="0">L'AYP~R X</definiendum>
				<definiens id="0">a function Elhose aFguments are the possible denotatiurlz that can be assigned to the variable ,</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>( VAT creates first the following representation : ) C J-REASON CC-1002 CC-1003 ( and immediately applies a scored syntactic alf~orithm that changes it to : ) V : HOW IS dC-1003 SUBCONCEPTUALIZED ?</sentence>
				<definiendum id="0">VAT</definiendum>
			</definition>
			<definition id="1">
				<sentence>Suppose= u '' Z-1053 is a concentual chunk that will eventually be vzrbalized with the sentence : 28 ) Krs .</sentence>
				<definiendum id="0">Suppose= u '' Z-1053</definiendum>
				<definiens id="0">a concentual chunk that will eventually be vzrbalized with the sentence : 28 ) Krs</definiens>
			</definition>
			<definition id="2">
				<sentence>A PI is the concept of n concrete object , be it animate of inanimate , or of 3n abstraction which has been reif ied and is being treated linguistically in w. &amp; ys ~~~O~~OIIS to the treatment of physical objects .</sentence>
				<definiendum id="0">PI</definiendum>
				<definiens id="0">the concept of n concrete object , be it animate of inanimate , or of 3n abstraction which has been reif ied and is being treated linguistically in w. &amp; ys ~~~O~~OIIS to the treatment of physical objects</definiens>
			</definition>
			<definition id="3">
				<sentence>This classif lc ; ltif3n includes human beings , but also nadled animals such as pets .</sentence>
				<definiendum id="0">ltif3n</definiendum>
				<definiens id="0">includes human beings</definiens>
			</definition>
			<definition id="4">
				<sentence>Otherwise it rnust find the sex of this refere~lt : 't5 ) ' V : IS PI-123 IMALE OR P9IlLLE1 md lexicalize it as IJTd- '' HiS '' or EN- '' 6 : IZ '' accordingly .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">IS PI-123 IMALE OR P9IlLLE1 md lexicalize it as IJTd- '' HiS '' or EN- '' 6 : IZ '' accordingly</definiens>
			</definition>
			<definition id="5">
				<sentence>X &gt; then ~ives the case frane , saying that there will be a clause contaming r ; ne verb `` LIFTtt ac3 : ~rnpanied by an age1 , t ( PI-B ) and a patient ( PI-c ) .</sentence>
				<definiendum id="0">ne verb</definiendum>
				<definiens id="0">~rnpanied by an age1 , t ( PI-B ) and a patient ( PI-c )</definiens>
			</definition>
			<definition id="6">
				<sentence>CC-C is a transfer in which t'he roles of PI-D and PI-P ( and hence their relation to the variables in 52 ) ) are reversed .</sentence>
				<definiendum id="0">CC-C</definiendum>
				<definiens id="0">a transfer in which t'he roles of PI-D and PI-P ( and hence their relation to the variables in 52 ) ) are reversed</definiens>
			</definition>
			<definition id="7">
				<sentence>we may ex~ect that it will have a tail ( although some dogs do mt ) , that it will bm , ana that it will chase cuts : 60 ) PI-A O &gt; UG- '' BEA ( ; Li. , '' L ' &gt; y1-A 3 &gt; UC-ltD ( ) GH E : VBLHAT~-AS-PIL~~T ( IPI-B ) PI-B z &gt; uC-t'T.ti.zj-btt E : VB-BARK ( YI-A ) E : VB-3 &amp; dB ( 11-A , PI- &lt; ) PI-c C &gt; T~c-t~dji~tl It nay be that E : should be expressed as a probab~lity ; s~at is , that there is a ao~tinuous range over which we nay expect ~omething to be entailed , with necessary entailnrent being one extreme .</sentence>
				<definiendum id="0">GH E</definiendum>
				<definiendum id="1">VBLHAT~-AS-PIL~~T ( IPI-B</definiendum>
				<definiens id="0">a ao~tinuous range over which we nay expect ~omething to be entailed , with necessary entailnrent being one extreme</definiens>
			</definition>
			<definition id="8">
				<sentence>dhen , during a 1 : :ter sentence , VjiT coaos to the nuestion : 68 ) V : DOLS US- '' HJY 2 , ; '' P131 : NTIE'Y kJ1-19873 as in 50 ) above , it is in a position to provide sts own answer without recourse to the user .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">:ter sentence</definiens>
			</definition>
			<definition id="9">
				<sentence>V : IS PI-2001 GIVEN ?</sentence>
				<definiendum id="0">V</definiendum>
			</definition>
			<definition id="10">
				<sentence>V : DOES PI-2003 HAVE A NAPEJ 31 V : HOW IS PI-2003 .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">DOES PI-2003 HAVE A NAPEJ 31 V : HOW IS PI-2003</definiens>
			</definition>
			<definition id="11">
				<sentence>Li-SPd~~'11 ( ILI~ '' IVL. , ( I , 1'1-B ) -VI E -1 ( 1 3 PI -C ) That is , Ud- ' , 'dKIIHS- '' is , th'e c &lt; ) tecory chor , Bn if the bcneficiqry of the giving is socivilly close tothe speaker , closer to the sneak~r than athe aqent ofl the giving , and the agent in not socially hiqher than the henef'ic-Ta~y. In translatint &lt; texts where such infornXtion is relevant , 71iT will bitller h3ve to store a n : -~twork o : social relation5 linkin ( ; all the relevant I ndlvld~~ls , a network which nav - ; n c ?</sentence>
				<definiendum id="0">Li-SPd~~'11</definiendum>
				<definiendum id="1">'dKIIHS- ''</definiendum>
			</definition>
</paper>

		<paper id="1083">
			<definition id="0">
				<sentence>Semantic fields defined by relations are used to handle prablems of ambiguity and context .</sentence>
				<definiendum id="0">Semantic fields</definiendum>
				<definiens id="0">defined by relations are used to handle prablems of ambiguity and context</definiens>
			</definition>
			<definition id="1">
				<sentence>SIR inputs simph English sentences , translates them into node-relation-node form , uses a relational calculys to prove theorems , asks for more information , if needed , and answers questions using those inferences .</sentence>
				<definiendum id="0">SIR</definiendum>
				<definiens id="0">inputs simph English sentences , translates them into node-relation-node form , uses a relational calculys to prove theorems , asks for more information</definiens>
			</definition>
			<definition id="2">
				<sentence>owng [ x ; y ] ( Every y owns an x. ) own [ x ; y ] ( y owns an x. ) partg [ x ; y ] ( Some x is part of every y. ) part [ x ; y ] ( An x is part of y. ) right [ r ; y ] ( x is to the right of y. ) jright [ x ; y ] ( xBs just to the right of y. ) ( ibid , p. 92 ) Each relation R has an inverse z. If aRb then the pair ( R , b ) is stored C on the property list of a and ( ~ , a ) is stored on the property list of b. For each relation there are axioms .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">owns an x. ) own [ x ; y ] ( y owns an x. ) partg [ x ; y ] ( Some x is part of every y. ) part [ x ; y ] ( An x is part of y. ) right [ r ; y ] ( x is to the right of y. ) jright [ x ; y ] ( xBs just to the right of y. ) ( ibid , p. 92 ) Each relation R has an inverse z. If aRb then the pair ( R , b ) is stored C on the property</definiens>
			</definition>
			<definition id="3">
				<sentence>1 ) CompZempntar &lt; ty , isolated by Lyons ( 1968 ) , is the kind of oppositeness that holds between single and married or male and fmaze. The denial of one implies the assertion of the other : me assertion of one implies the denial of the other. If John is married , then John is not single. If John is not married , then John is single If John imsiggle , then John is not married. If John is not single , then John is married , j€ '' his kind of relation seems to hold primarily between two adjectives or two adverbs belonging to the same primitive concept. If we set up a lexical relation COW , then the appropriate axiom schemes seem to be , for &amp; he case where Ad j COW Ad j 2 , if Z 2 , looked at along dimension Z1 , has property Adj , then it also has the property Not ( Adj 2 ) and vice versa. 7 In the notation used for the bemantic representations in the questionanswering system this is stated : if , on the other hand , it has the property ~ot ( Adjl ) then it 21 ao has the property Adj2 and vice ogrsa. ( and similarly for adverbs ) . : OMP is a symmetric relation. If A C ( IMP B , then B COW A. In other words it is its own inverse , jn this lexlcon ~f A is marked COW B , then B fs.marked COMP A and so inferences are available in both directions. Anything marriageable is either married or single4 nokboth ; if me tern applies , the other must not. where the assertion of one implies the denial of the other , but the denial of one does not imply the assertion of the other. ~ed and green are antonyms in this sense. If X is red , it is not green. OR the other hand , if X is not red it does not have to be green. It could be blue or yellow instead. IIot or cold behave in the same way. If X is hot then it is not cold , but if X is not hot we do not know for sure that it is cold ; it may just be lukewarm. We set up a lexical relation ANTI to express this kind of antonymy . Again it applies par ticularlj to ad j ec tives and adverbs belonging to the same primitive concept. The lexical entry for ANTI gives an appropriate axiom scheme for the case in which Adjl ANTI Adj~ : If Z2 is Adjl then it is not Adj2. Hozd~ ( P ( Z1 , ~2 , Adjl ) ) ~otds ( P ( z~rz~ , ~~~t ( ~dj~ ) ) ) ( similarly for adverbs. ) Verbs may be included in this kind of antonymy. Consider the pairs love-hate and open-shut. For a child , at least , `` X loves Yt ' may imply lC.X hates'~. '' The appropriate axiom scheme for verbl ANTI verbZ would be : if a simple sentence containing verbl is true , then the negation , is true when verb2 is substituted for verbl floZds ( R ( verbl , Zl , Z* , z3 , Z4 ) ) ~H~lds ( R ( verb~ , ~~ , ~~ , Z~ , ~~ ) ) Since such verb pairs do not appear in our examples such problematical inferences have been avoided. There are some important semantic realities here which are not being captured. There is a set of inrnmpatible color terms : red , orange , peZZow , peen , blue , purple , brw , bhk , white. One can describe any small area of a physical object in one of these terms if it is forbidden to use hedges Like turquoise and pink. Hot and cold , like big and smaZZ , are opposite ends of a scale. Between hot and cotd , wm ? n and cool can be placed somewhere. Binary lexical relations are not adequate here , Perhaps developments in the theory of fuzzy sets will eventually provide a better descriptdon. There are logical problems here too. If the story says the toy is red , then we want to answer `` no '' to the question `` Is the toy green ? '' But toys can be both red and green in spots , patches , or stripeer JE the story says that the toy is red and green , we do not want tl ) get lost inba self-contradiction. Adjectives which imply grading ( cf section c below ) involve potential self-contradictions of a slightly different kind. Lyons discusses the sentence reference `` A small elephant is a large animal. '' The current representation for that sentence in pur system would be : ZVl =Ncorn ( elephant , X1 ) PI =P.P ( size , X1 , small ) &amp; =Ncom ( animal , X1 ) P2 =P ( size , XI , large ) For more details see the section on semantic representations. But 8man ANTI large so w must conclude from P1 that P ( size , X1 , Not ( large ) ) . The problem is that when we call something a small elephant we imply a comparison with some norm for elephants. However , this comparison does no€ appear in our representation. ( This di£+itulty has also been discussed by Bierwisch 1969 and S ; Lmmons 1973 , ) Cm~erseness. This is Lyons ' name for a third kind of antonymy. As examples he gives the pairs buy-se2Z aod husband- &amp; fee his kind of oppositeness does not seem to involve negation at all. Rather it involves some kind of permutation of the associated individuals. Dale calls this relation reciprocity and explains it this way : Buy and sell are reciprocals , as are give and receive. What die tinguishes these from antonyms ( which they are , in a sense ) is that whenever a sentence using one of them is appropriate , there is another appropriate sentence using the other member of the pair. For example , John h9e books from Bill has the same meaning as BiZZ sells books to John. He guve flowers to her has the same meaning as She received flowers from him. This is a sort of `` semantic passivet ' -- like the passive transformation in syntax , it presents the saiie meaning from a different point of view. ( 1972 : 144 ) Wether ale 's sentences have exactly the same meaning or not is debatable , but anyone would agree that one implies the other , What is needed is some compact way to indicate what these other appropriate sentences are and to V derive them when they are needed. Zolkovsky and ~ei'xuk , ( 1970 ) have a clever way of doing this for verbs. They use a flotation of the form : Buy CONV ( 3 2 1 4 ) Sell to indicate that % buys Y2 from X3 for X4 becomes X sells X2 to XI for X4 3 We have borrowed this notation , applying it to cases rather than subjects and objects. It is interesting that the Soviets include regular syntactic passives in their discussion of this relation. Since in this systesn inferences are made on the basis of the fully formed semantic representations from which passives have been eliminated , they need not be included here. treating kinship relations as functions of several arguments then wemc'ould have used CONV for pairs like husband-wzfe also. Since kinship and social relationships like teacher-student are expressed in terms of have , however , it makes sense to posit a new felation RECK far RECiprocal Kinship and other social terms. Husband and wife relationships are represented this way : Len is Martha 's husband , R $ % gtve , XI , X2 , husband ) Martha is Len 's wife R ( have , X2 , X1 , wife ) We want to be able to derive one of theselsentences from the other , using the lexical information husband RECK wife , i.e. if X1 has X2 as husbond then X2 has X1 as wife. The axiom scheme for A WCR B says that if X1 has X2 as A then X2 has XI as B. HoZdaIR ( have , X1 , X2 , A ) ) HoZds ( R ( have , X2 , X1 , B ) ) Ocher kxnds of converseness or reciprocity have not occurred often e~ough to warrant a separate relation and a sephrate axiom scheme. They are entered as individual Inferences in each entry. Antonymy seems to be a highly diverse lexical concept. With further study it may spawn still more lexical relations. Grading relations like antonymy relations involve alternatives of some kind. Graded alternatives appear to be organized in lists or other kinds of formal structures. Our collection of grading relations is in a state of fLux , many aspects of grading are still not properly defined. The notation Q is borrowed from Werner but used in a very restricted sense to connect adjacent items on lists , as in on day Q hcesw. It could be read `` is immediately followed by. '' elements , e.g. flock SET sheep. This is the relation which the Soviets call Mult , This relation seems to be particularly well-founded psycholo-. gically , for English has many special words of this type pride of lions , Bevy of maidens , gaggle of geese , and it is certainly a source of word-pla : 3 . ) Marrzfestatzm. By contrasf the STAGE relation , as in zce STAGE water , seems very shaky , The axiom schemes are not satisfactory and some of the territory is covered by the CHILD relation described in the section on attribute relatfons. There seems to be a gap in our collection here. We have no parallel to the comparison relation of CWlagrande and dale ( 1967 ) . Of course in the most common type of examples where the items related are taxonomic Brothers , or cohyponyms as they are soaetimes callea , the comparison relation can be =pressed by a combination of T and T. Recent work by Litowitz ( 1977 ) suggests that comparisons are an important component of the defining strategy of children. The boundary between the grading relations and the attribute relations described in the next section is also uncomfortably arbitrary. d , Aetrzbute ReZa $ zons. According to Caeagrande and Hale ( 1967 168 ) whenever `` X is defined with respect to one or more distinctive ow characteristic attributes Y '' . 48 a definition is `` attributive '' . Given this all-inclusive description it is not surprising that the attributive category was the largest in their sample. They propose several subcategories including stimulus properties like size and color , distinctive markers , habitat , behavior , sex , generation , and line of descent. But in order to fatilitate inference we need to associate axiom schemes with each relation. Thus we have broken these subcategories into still more precise relatlns. culine t~ the unmarked term. We want to be able to infer that if something is a drake , then it is a duck and it i~ male , i.e. Ncom ( dralce , Z1 ) + Ncom ( duck , Z1 ) A P ( sex , Zl , male ) This axiom can be derived when needed from an axiom scheme in the lexical entry for maze which says that whenever ZN1 MALE ZN2 then a ZN1 is also a ZN2 and if is male ; i. e. , Ncom ( ZN1 , Z1 ) + Ncom ( ZN2 , ZI ) A P ( sex , Zl , male ) the dame of the femade ta the unmarked term. 3 . ) Tern6 for juveniZes. The most common attribute relation in our vocabulary is CHILD , which relates the term for the offspring tn the term for its parent , as in puppy CHILD dog , kitten CHILD cat , lamb CHILD sheep. The lexical entry for CHILD contains the axiom scheme Ncom ( ZN1 , Z1 ) + Ncom ( ZN2 , Zl ) A P ( age , Zl , young ) men puppy and dog have been substituted for ZN1 and ZNp respectively we get an axiom that tells us that if Z1 id a puppy then Z1 is a dog and Z1 is young. 49 The habitat relation we have called HOME , so thai Awca HOME th. The relation SON was borrowed from the Soviets. SON relates an object and the verb expressing the kind of sound it produces. to bark SON dog to roar SON Zion to meow SON cat to choa choo SON truin This relation seas to underlie a crucial part the vocabulary of young children. Wby is such a tremendous amount of time spent teaching children words like mem ? Was this tntormation once lif e-preserving or is it a way of teaching how sound is structured into words , the phonology of the language ? For whatever reason , children who never see a farm are carefully kaught to associate the sound moo with c &amp; ws. 6 . ) Etcbs-t ; ance. The relation we call MADEOF as in ski MADEOE wood relates an object to the substance of which it is made. Casagrande and Hale classify as provenience both batea : `` which is made out of meequite '' and milk : `` we get it from a cow1 ' ( 1967:184 ) . Since in-English these. relationships* are expressed in different ways , for example , the ski is made ~f woad wooden ski , but milk comes from a caw cow 's milk , and since the appropriate inferences are different ( the milk was once in the cow but the ski was not in the wood ) , we chose to classify them separately. As the vocabulary-expands we expect the list of attrfbute relations to expamt. Litowitz ( 1977 ) is current1 y collecting defihitions-from children and isolating further relations. Smith : and Maxwell ( 1977 ) have identified certain attribute relations which occur repeatedly in defining a formulae in Webster 's Seventh : COLOR , TIME , LOCIATION , SIZE , and QUALITY. These relations , among others , will be added eventually to our lexicon , e. Parts and Wh6Zes. hetop to car we call PART : finger PART carburetor PART car The PART relation seems to be crucial in the definition of many every day objects. While it is clearly important-in computer models of memory , it seems hard to isolate from natural English sentences , Raphael 's ( 1968 ) SIR model used some subtle heuristics to determine whether a particular instance of the verb have should be represented by the pmt relation or the cp~n relation. Sometimes dialog with a human is necessary to resolve the asiguity. Simmons ( 1973 ) recognizes a three-way ambiguity in have which is represented variously as HASPART , POSSess , and ASSOC ( 1973:76 ) Mary has long fingers HASPART Mary has money POSSess Mary has fun in the park ASSOC Apparently the part-whole relation is hard to identify in Papago also. Casagrande and Hale do not find it in their Papago sample. They classjfy tl as exemplification deffnitionZwhich , are translated inta English as cows I1 have horns '' and `` horses have tails. However , on , the basis of intuition and t_he word-association data of Russell and Jenkins ( 1954 ) they posit a fourteenth relation ( 1967:191 ) : Constituent : X is defined as being a constituent or part of Y. The example given is cheek-face. Apresyan , Me1 hk an 'd 3olkovsky do not have an explicit part-whole relation but they do include tGo relations in this same area. We have borrowed chief CAP tribe organization or object they serve* crw EQUIP ship out of a mass also belungs to the part-whole family. For example , lwnp PIECE sugar item PIECE net38 Jespersen was intrigued by this mechanisa which he named individuatizat &lt; on ( 1933:209 ) ; he discovered and listed many such examples. This seems to be the relation which the ECD calls SING ( Apresyan et al. , 1970:11 ) . milk COMESPROM cad. This is one aspect of the relation which Casagrade and Hale ( 1967 ) call provenience. ( It should passibly be listed as an attribute relation along with its close cousin MADEOF. ) ' Our current lexicon contains only two axioms for the part-whole relation. One is transitivity : if X PART Y and Y PART Z , then X PART 2. The other , borrowed from Raphael , connects PART and Taxonomy. Essentially 52 it says that if all X 's are Y 's and allY1s have 2 's as parts , then all X 's also have 2'6 as parts. There is an extensive philosophical literature involving this relation. Martin ( 1971 ) presents a system of axioms for part-whole and a review of work by Lesniewski , Woodger , and Tarski. f. TypicaZ-Case ReZatwns . Casagrande and Hale discovered that certain familiar objects , body parts , foods , tools , and other objects of material culture were most often defined not by the relations discussed above but rather by their use in daily life , by common activities associated with them. For example , under the I1functiontl relation they classify examples in which `` X is defined as the means of effecting Y '' such as eye : `` . . .with which we see things '' money : If. . .we buy things with it '' ( 1967 : 175 ) The `` operational1 ' class includes examples in which X is defined as `` the characteristic goal or recipient '' of action Y bridle : `` . . .which they put on horses '' ( 1967 :178 ) What they call the `` spatial '' relation also seem to be of this same type , grindstone : `` ... on which a knife is sharpened '' ( 1967:177 ) Folk definitions collected from speakers of English often are of this variety , sometimes combined with taxonomy , e.g. `` a house is a building in whfch people reside '' ( Evens 1975:340 ) . Children in particular seem to prefer functional definitions ( cf. Ruth ~rauss ' collection of children 's definitions , A Bole is to Dig , 1952 ) . Apresyan , Mel1c ! uk , and Zolkovsky 's system includes a family of fundions S1 , S2 , Sg , $ 4 which relate nouns and verbs or adjectives. Their semantic structures are based on grammatical relations. For verbs these are a subject relation , a direct object relation , and two kinds of indirect object relatiotls. The functions S1 , S2 , Sj , and S4 correspond to these grammatical relations. S1 relates the verb to its generic subject. S2 relates the verb to its generic direct object , etc. For example ( 1970 : lO : S ( to se1l ) ~seller 1 S2 ( to sell ) =goods ( that which is sold ) S ( to sell ) =buyw , client , customer ( the one to whom the goods 3are sold ) S4 ( to sell ) =price ( that for which the goods are sold ) The Em also contains four other substantive relations ( 1970 : ll ) . The values are nouns. The arguments can apparently be verbs , adjectives or Rouns. First is Smod whxch gives the noun denoting the ? mode of action &gt; % od ( to write ) =hmdwritzng .</sentence>
				<definiendum id="0">OMP</definiendum>
				<definiendum id="1">X1 ) PI =P.P</definiendum>
				<definiens id="0">the kind of oppositeness that holds between single and married or male and fmaze. The denial of one implies the assertion of the other : me assertion of one implies the denial of the other. If John is married , then John is not single. If John is not married</definiens>
				<definiens id="1">not married. If John is not single , then John is married , j€ '' his kind of relation seems to hold primarily between two adjectives or two adverbs belonging to the same primitive concept. If we set up a lexical relation COW , then the appropriate axiom schemes seem to be , for &amp; he case where Ad j COW Ad j 2 , if Z 2 , looked at along dimension Z1 , has property Adj</definiens>
				<definiens id="2">the notation used for the bemantic representations in the questionanswering system this</definiens>
				<definiens id="3">a symmetric relation. If A C ( IMP B , then B COW A. In other words it is its own inverse , jn this lexlcon ~f A is marked COW B , then B fs.marked COMP A and so inferences are available in both directions. Anything marriageable is either married or single4 nokboth ; if me tern applies , the other must not. where the assertion of one implies the denial of the other , but the denial of one does not imply the assertion of the other. ~ed and green are antonyms in this sense. If X is red</definiens>
				<definiens id="4">or yellow instead. IIot or cold behave in the same way. If X is hot then it is not cold , but if X is not hot we do not know for sure that it is cold ; it may just be lukewarm. We set up a lexical relation ANTI to express this kind of antonymy . Again it applies par ticularlj to ad j ec tives and adverbs belonging to the same primitive concept. The lexical entry for ANTI gives an appropriate axiom scheme for the case in which Adjl ANTI Adj~ : If Z2 is Adjl then it is not Adj2. Hozd~ ( P ( Z1 , ~2 , Adjl ) ) ~otds ( P ( z~rz~ , ~~~t ( ~dj~ ) ) ) ( similarly for adverbs.</definiens>
				<definiens id="5">if a simple sentence containing verbl is true , then the negation , is true when verb2 is substituted for verbl floZds ( R ( verbl , Zl , Z* , z3 , Z4 ) ) ~H~lds ( R ( verb~ , ~~ , ~~ , Z~ , ~~ ) ) Since such verb pairs do not appear in our examples such problematical inferences have been avoided. There are some important semantic realities here which are not being captured. There is a set of inrnmpatible color terms : red , orange , peZZow , peen , blue , purple , brw , bhk , white. One can describe any small area of a physical object in one of these terms if it is forbidden to use hedges Like turquoise and pink. Hot and cold , like big and smaZZ , are opposite ends of a scale. Between hot and cotd , wm ? n and cool can be placed somewhere. Binary lexical relations are not adequate here , Perhaps developments in the theory of fuzzy sets will eventually provide a better descriptdon. There are logical problems here too. If the story says the toy is red , then we want to answer `` no '' to the question `` Is the toy green ? '' But toys can be both red and green in spots , patches , or stripeer JE the story says that the toy is red and green , we do not want tl ) get lost inba self-contradiction. Adjectives which imply grading ( cf section c below ) involve potential self-contradictions of a slightly different kind. Lyons discusses the sentence reference `` A small elephant is a large animal. '' The current representation for that sentence in pur system would be : ZVl =Ncorn ( elephant ,</definiens>
				<definiens id="6">animal , X1 ) P2 =P ( size , XI , large ) For more details see the section on semantic representations. But 8man ANTI large so w must conclude from P1 that P ( size , X1 , Not ( large )</definiens>
				<definiens id="7">This di£+itulty has also been discussed by Bierwisch 1969 and S ; Lmmons 1973 , ) Cm~erseness. This is Lyons ' name for a third kind of antonymy. As examples he gives the pairs buy-se2Z aod husband- &amp; fee his kind of oppositeness does not seem to involve negation at all. Rather it involves some kind of permutation of the associated individuals. Dale calls this relation reciprocity and explains it this way : Buy and sell are reciprocals , as are give and receive. What die tinguishes these from antonyms ( which they are , in a sense ) is that whenever a sentence using one of them is appropriate , there is another appropriate sentence using the other member of the pair. For example , John h9e books from Bill has the same meaning as BiZZ sells books to John. He guve flowers to her has the same meaning as She received flowers from him. This is a sort of `` semantic passivet ' -- like the passive transformation in syntax , it presents the saiie meaning from a different point of view. ( 1972 : 144 ) Wether ale 's sentences have exactly the same meaning or not is debatable , but anyone would agree that one implies the other , What is needed is some compact way to indicate what these other appropriate sentences are and to V derive them when they are needed. Zolkovsky and ~ei'xuk , ( 1970 ) have a clever way of doing this for verbs. They use a flotation of the form : Buy CONV</definiens>
				<definiens id="8">interesting that the Soviets include regular syntactic passives in their discussion of this relation. Since in this systesn inferences are made on the basis of the fully formed semantic representations from which passives have been eliminated , they need not be included here. treating kinship relations as functions of several arguments then wemc'ould have used CONV for pairs like husband-wzfe also. Since kinship and social relationships like teacher-student are expressed in terms of have , however , it makes sense to posit a new felation RECK far RECiprocal Kinship and other social terms. Husband and wife relationships are represented this way : Len is Martha 's husband , R $ % gtve , XI , X2 , husband ) Martha is Len 's wife R ( have , X2 , X1 , wife ) We want to be able to derive one of theselsentences from the other , using the lexical information husband RECK wife , i.e. if X1 has X2 as husbond then X2 has X1 as wife. The axiom scheme for A WCR B says that if X1 has X2 as A then X2 has XI as B. HoZdaIR ( have , X1 , X2 , A ) ) HoZds ( R ( have , X2 , X1 , B ) ) Ocher kxnds of converseness or reciprocity have not occurred often e~ough to warrant a separate relation and a sephrate axiom scheme. They are entered as individual Inferences in each entry. Antonymy seems to be a highly diverse lexical concept. With further study it may spawn still more lexical relations. Grading relations like antonymy relations involve alternatives of some kind. Graded alternatives appear to be organized in lists or other kinds of formal structures. Our collection of grading relations is in a state of fLux , many aspects of grading are still not properly defined. The notation Q is borrowed from Werner but used in a very restricted sense to connect adjacent items on lists</definiens>
				<definiens id="9">immediately followed by. '' elements , e.g. flock SET sheep. This is the relation which the Soviets call Mult , This relation seems to be particularly well-founded psycholo-. gically , for English has many special words of this type pride of lions</definiens>
				<definiens id="10">The axiom schemes are not satisfactory and some of the territory is covered by the CHILD relation described in the section on attribute relatfons. There seems to be a gap in our collection here. We have no parallel to the comparison relation of CWlagrande and dale ( 1967 ) . Of course in the most common type of examples where the items related are taxonomic Brothers , or cohyponyms as they are soaetimes callea , the comparison relation can be =pressed by a combination of T and T. Recent work by Litowitz ( 1977 ) suggests that comparisons are an important component of the defining strategy of children. The boundary between the grading relations and the attribute relations described in the next section is also uncomfortably arbitrary. d</definiens>
				<definiens id="11">respect to one or more distinctive ow characteristic attributes Y ''</definiens>
				<definiens id="12">the largest in their sample. They propose several subcategories including stimulus properties like size and color , distinctive markers , habitat , behavior , sex , generation , and line of descent. But in order to fatilitate inference we need to associate axiom schemes with each relation. Thus we have broken these subcategories into still more precise relatlns. culine t~ the unmarked term. We want to be able to infer that if something is a drake , then it is a duck and it i~ male , i.e. Ncom ( dralce , Z1 ) + Ncom ( duck , Z1 ) A P ( sex , Zl , male ) This axiom can be derived when needed from an axiom scheme in the lexical entry for maze which says that whenever ZN1 MALE ZN2 then a ZN1 is also a ZN2 and if is male ; i. e. , Ncom ( ZN1 , Z1 ) + Ncom ( ZN2 , ZI ) A P ( sex , Zl , male ) the dame of the femade ta the unmarked term. 3 . ) Tern6 for juveniZes. The most common attribute relation in our vocabulary is CHILD , which relates the term for the offspring tn the term for its parent , as in puppy CHILD dog , kitten CHILD cat , lamb CHILD sheep. The lexical entry for CHILD contains the axiom scheme Ncom ( ZN1 , Z1 ) + Ncom ( ZN2 , Zl ) A P ( age , Zl , young ) men puppy and dog have been substituted for ZN1 and ZNp respectively we get an axiom that tells us that if Z1 id a puppy then Z1 is a dog and Z1 is young. 49 The habitat relation we have called HOME , so thai Awca HOME th. The relation SON was borrowed from the Soviets. SON relates an object and the verb expressing the kind of sound it produces. to bark SON dog to roar SON Zion to meow SON cat to choa choo SON truin This relation seas to underlie a crucial part the vocabulary of young children. Wby is such a tremendous amount of time spent teaching children words like mem ? Was this tntormation once lif e-preserving or is it a way of teaching how sound is structured into words , the phonology of the language ? For whatever reason , children who never see a farm are carefully kaught to associate the sound moo with c &amp; ws. 6 . ) Etcbs-t ; ance. The relation we call MADEOF as in ski MADEOE wood relates an object to the substance of which it is made. Casagrande and Hale classify as provenience both batea : `` which is made out of meequite '' and milk : `` we get it from a cow1 ' ( 1967:184 ) . Since in-English these. relationships* are expressed in different ways , for example , the ski is made ~f woad wooden ski , but milk comes from a caw cow 's milk , and since the appropriate inferences are different ( the milk was once in the cow but the ski was not in the wood ) , we chose to classify them separately. As the vocabulary-expands we expect the list of attrfbute relations to expamt. Litowitz ( 1977 ) is current1 y collecting defihitions-from children and isolating further relations. Smith : and Maxwell ( 1977 ) have identified certain attribute relations which occur repeatedly in defining a formulae in Webster 's Seventh : COLOR , TIME , LOCIATION , SIZE , and QUALITY. These relations , among others</definiens>
				<definiens id="13">finger PART carburetor PART car The PART relation seems to be crucial in the definition of many every day objects. While it is clearly important-in computer models of memory , it seems hard to isolate from natural English sentences , Raphael 's ( 1968 ) SIR model used some subtle heuristics to determine whether a particular instance of the verb have should be represented by the pmt relation or the cp~n relation. Sometimes dialog with a human is necessary to resolve the asiguity. Simmons ( 1973 ) recognizes a three-way ambiguity in have which is represented variously as HASPART , POSSess , and ASSOC ( 1973:76 ) Mary has long fingers HASPART Mary has money POSSess Mary has fun in the park ASSOC Apparently the part-whole relation is hard to identify in Papago also. Casagrande and Hale do not find it in their Papago sample. They classjfy tl as exemplification deffnitionZwhich , are translated inta English as cows I1 have horns '' and `` horses have tails. However , on , the basis of intuition and t_he word-association data of Russell and Jenkins ( 1954 ) they posit a fourteenth relation ( 1967:191 ) : Constituent : X is defined as being a constituent or part of Y. The example given is cheek-face. Apresyan , Me1 hk an 'd 3olkovsky do not have an explicit part-whole relation but they do include tGo relations in this same area. We have borrowed chief CAP tribe organization or object they serve* crw EQUIP ship out of a mass also belungs to the part-whole family. For example , lwnp PIECE sugar item PIECE net38 Jespersen was intrigued by this mechanisa which he named individuatizat &lt; on ( 1933:209 ) ; he discovered and listed many such examples. This seems to be the relation which the ECD calls SING ( Apresyan et al. , 1970:11 ) . milk COMESPROM cad. This is one aspect of the relation which Casagrade and Hale ( 1967 ) call provenience. ( It should passibly be listed as an attribute relation along with its close cousin MADEOF. ) ' Our current lexicon contains only two axioms for the part-whole relation. One is transitivity : if X PART Y and Y PART Z , then X PART 2. The other , borrowed from Raphael , connects PART and Taxonomy. Essentially 52 it says that if all X 's are Y 's and allY1s have 2 's as parts , then all X 's also have 2'6 as parts. There is an extensive philosophical literature involving this relation. Martin ( 1971 ) presents a system of axioms for part-whole and a review of work by Lesniewski , Woodger , and Tarski. f. TypicaZ-Case ReZatwns . Casagrande and Hale discovered that certain familiar objects , body parts , foods , tools , and other objects of material culture were most often defined not by the relations discussed above but rather by their use in daily life , by common activities associated with them. For example , under the I1functiontl relation they classify examples in which `` X</definiens>
				<definiens id="14">a knife is sharpened '' ( 1967:177 ) Folk definitions collected from speakers of English often are of this variety , sometimes combined with taxonomy</definiens>
				<definiens id="15">a building in whfch people reside '' ( Evens 1975:340 ) . Children in particular seem to prefer functional definitions ( cf. Ruth ~rauss ' collection of children 's definitions , A Bole is to Dig , 1952 ) . Apresyan , Mel1c ! uk , and Zolkovsky 's system includes a family of fundions S1 , S2 , Sg , $ 4 which relate nouns and verbs or adjectives. Their semantic structures are based on grammatical relations. For verbs these are a subject relation , a direct object relation , and two kinds of indirect object relatiotls. The functions S1 , S2 , Sj , and S4 correspond to these grammatical relations. S1 relates the verb to its generic subject. S2 relates the verb to its generic direct object , etc. For example ( 1970 : lO : S ( to se1l ) ~seller 1 S2 ( to sell ) =goods ( that which is sold ) S ( to sell ) =buyw , client , customer ( the one to whom the goods 3are sold ) S4 ( to sell ) =price ( that for which the goods are sold ) The Em also contains four other substantive relations ( 1970 : ll )</definiens>
			</definition>
			<definition id="4">
				<sentence>The typical-case relation relates the verb to typical fillers of that case argument slot .</sentence>
				<definiendum id="0">typical-case relation</definiendum>
				<definiens id="0">relates the verb to typical fillers of that case argument slot</definiens>
			</definition>
			<definition id="5">
				<sentence>The relation PREPAR relates a noun and the verb which means to prepare the object , to make it ready for use .</sentence>
				<definiendum id="0">relation PREPAR</definiendum>
				<definiens id="0">relates a noun and the verb which means to prepare the object , to make it ready for use</definiens>
			</definition>
			<definition id="6">
				<sentence>awl BECOME 0x2 redden BECOME red *Pm 2 BECOME @ m 1 If verbl BECOME adjl ; then if the sentence containing verbl holds , then the object that did the becoming must now have the property expressed by the adjective , i.a ~oZds ( ~ ( verb~ , ~~ , Z~ , Z~ , Z~ ) ) * ~oZds ( r ) ( ~~~ , ~~ , adj~ ) ) where ZC1 is the primitive concept corresponding to adgl .</sentence>
				<definiendum id="0">ZC1</definiendum>
				<definiens id="0">the primitive concept corresponding to adgl</definiens>
			</definition>
			<definition id="7">
				<sentence>BECOME relates the verb of becoming and the predicate adjective , BE relates the verb of being and the predicate adjective .</sentence>
				<definiendum id="0">BECOME</definiendum>
				<definiens id="0">relates the verb of becoming and the predicate adjective , BE relates the verb of being and the predicate adjective</definiens>
			</definition>
			<definition id="8">
				<sentence>The lexical entry for pet dncludes the information that a pet is an animal which is owned by a human mcom ( animal , Z1 ) A Ncom ( human , Z2 ) A R ( m ; Z2 , Zl ) This becomes the @ xiom HoZds ( Ncom ( pet , Z1 ) ) -r Holds ( Neom ( animal , Z1 ) ) A HoZds ( Ncom ( human , Z2 ) ) A HoZds ( R ( own , ~~ , Z~ ) ) If an hdividual 21 is a Pet , then 21 is an animal and is owned by a human Z2 , Thus this lexicon is a relational network model with words and Lexical relations as semantic primes .</sentence>
				<definiendum id="0">Ncom</definiendum>
				<definiendum id="1">HoZds</definiendum>
				<definiens id="0">a relational network model with words and Lexical relations as semantic primes</definiens>
			</definition>
			<definition id="9">
				<sentence>Here we have seven individual objects : XI Peter X5 Astore X2 meow X3 Mother X4 kitten X6 milk X7 lollipop We can write Ncom ( lollipop , X7 ) to signify that X7 is a lollipop since ZoZZipop is the common noun that names X7 .</sentence>
				<definiendum id="0">X7</definiendum>
				<definiendum id="1">ZoZZipop</definiendum>
				<definiens id="0">a lollipop since</definiens>
			</definition>
			<definition id="10">
				<sentence>It contains an axio111 scheme which when filled in tells us that X is a puppy if and only if X is a dog and X is young Ncbm ( puppy , X ) means that Ncom ( dog , X ) and also P ( age , X , ygung ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">X )</definiendum>
				<definiens id="0">a puppy if and only if X is a dog and</definiens>
			</definition>
			<definition id="11">
				<sentence>Pet , on the other hand , has a definition Ncom ( pet , Z1 ) Ncom ( animal , Zl ) A Rcom ( human , Z2 ) A R ( own , Z2 , Z1 ) When thxs def mition is retrieved it is transformed into the axiom Hdds ( Ncom ( pet , Z1 ) ) + RoZds ( Neom Canunal , Z1 ) ) A Holdb ( Ncom ( human , z2 ) ) h BoZds ( R ( own , ~~ , Z~ ) ) In other words , if some indivxdual 21 is a pet , then Zl is an anmal owned by some human Z2 , Omitted from this lexicon are the examples which are an important and valuable part of other diczionaries .</sentence>
				<definiendum id="0">Pet</definiendum>
				<definiendum id="1">Holdb ( Ncom</definiendum>
				<definiendum id="2">h BoZds</definiendum>
				<definiendum id="3">R</definiendum>
				<definiens id="0">animal , Zl ) A Rcom ( human , Z2 ) A R ( own , Z2 , Z1 ) When thxs def mition is retrieved it is transformed into the axiom Hdds</definiens>
				<definiens id="1">an important and valuable part of other diczionaries</definiens>
			</definition>
			<definition id="12">
				<sentence>Nouns : Taxonomy seems to be the most important lexical elation Eor nouns , but many others appear in the texts as well .</sentence>
				<definiendum id="0">Taxonomy</definiendum>
				<definiens id="0">seems to be the most important lexical elation Eor nouns , but many others appear in the texts as well</definiens>
			</definition>
			<definition id="13">
				<sentence>The feature information can be expressed compactly as a vector of 1 's and 0 's .</sentence>
				<definiendum id="0">feature information</definiendum>
			</definition>
			<definition id="14">
				<sentence>( iv ) Selection preferences : the top node of the taxonomy subtree .</sentence>
				<definiendum id="0">Selection preferences</definiendum>
				<definiens id="0">the top node of the taxonomy subtree</definiens>
			</definition>
			<definition id="15">
				<sentence>Ncom : Common nouns X objects + names Ncom ( boy , X1 ) The boy went home .</sentence>
				<definiendum id="0">Ncom</definiendum>
				<definiens id="0">Common nouns X objects + names Ncom ( boy</definiens>
			</definition>
			<definition id="16">
				<sentence>The notation ''PI =P ( manner , xl , kind ) It merely indicates that P ( manner , X , kind ) is the first property formed in the representation of a particular story .</sentence>
				<definiendum id="0">notation ''PI =P</definiendum>
				<definiens id="0">the first property formed in the representation of a particular story</definiens>
			</definition>
</paper>

		<paper id="1060">
			<definition id="0">
				<sentence>The J-tree ( a semantico-syntactic representation ) is consistent with the version of Junction Grammar described by Lytle ( 1975 ) .</sentence>
				<definiendum id="0">J-tree</definiendum>
				<definiens id="0">consistent with the version of Junction Grammar described by Lytle ( 1975 )</definiens>
			</definition>
			<definition id="1">
				<sentence>EVALUATION AFD DISCUSSION We produced a demonstration tape of LPC synthesized speech using natural , monotone , and rule-generated pitch contours .</sentence>
				<definiendum id="0">EVALUATION AFD DISCUSSION We</definiendum>
				<definiens id="0">produced a demonstration tape of LPC synthesized speech using natural , monotone</definiens>
			</definition>
			<definition id="2">
				<sentence>ACOUSTIC SPEECH PROCESSING : ( 1 ) The Speech Chain , P.B. Denes and E.N. Pinson , ( Garden City , N.Y. : Doubleday Anchor Books , 1973 ) ( an excellent non-technical ovwview ) ( 2 ) Speech Analysis Synthesis and Perception , J.L. Flanagan , ( New York : Springer-~erlag , '1972 ) ( a thorough technical presentation ) ( 3 ) Speech Synthesis , edited by J. Flanagan and Lo Rabiner , ( Stroudshllrg , Penn. : Dowden , Hutrhinson and Ross , 1973 ) ( a cdllection of key historical and current professional articles ) JUNCTION GRAMMAR : ( 1 ) A Grammar of Subordinate Structures in English , ( Lytle , 1974 ) ( A Description of Junction Grammar .</sentence>
				<definiendum id="0">ACOUSTIC SPEECH PROCESSING</definiendum>
				<definiens id="0">a cdllection of key historical and current professional articles ) JUNCTION GRAMMAR : ( 1 ) A Grammar of Subordinate Structures in English</definiens>
			</definition>
			<definition id="3">
				<sentence>Ling 426 is an introductory course and Ling2501 is an intermediate class .</sentence>
				<definiendum id="0">Ling2501</definiendum>
				<definiens id="0">an intermediate class</definiens>
			</definition>
			<definition id="4">
				<sentence>Specifically , if A-trees are in some senge a reflection of actual articulatory processes , then phonological representations whfch do not use trees wili consist of an intermixture of functional and categorial lables ( features ) .</sentence>
				<definiendum id="0">A-trees</definiendum>
				<definiens id="0">are in some senge a reflection of actual articulatory processes , then phonological representations whfch do not use trees wili consist of an intermixture of functional and categorial lables ( features )</definiens>
			</definition>
			<definition id="5">
				<sentence>Acoustica1 Society of Ameraea , November 1975 Melby , A. et al. ( 1976 ) `` Generating Pftch Contours from Syiltacto-Semantic Representations , '' Brigham Young University LinguisticS Symposium , March 1976 Olive , J.P. ( 1975 ) `` Fbndamental frequency rules for the synthesis of simple declarative English sentences , '' J. Acouat .</sentence>
				<definiendum id="0">Fbndamental frequency</definiendum>
				<definiens id="0">rules for the synthesis of simple declarative English sentences , '' J. Acouat</definiens>
			</definition>
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>The SQAP data base consists of a network of nodes correspdnding to objects , properties , and events in the real .</sentence>
				<definiendum id="0">SQAP data base</definiendum>
			</definition>
			<definition id="1">
				<sentence>Deduction can be performed , and deduction rules can be input in natural language and stored in the data base .</sentence>
				<definiendum id="0">deduction rules</definiendum>
				<definiens id="0">natural language and stored in the data base</definiens>
			</definition>
			<definition id="2">
				<sentence>MOTORBOAT-P &gt; steer away ) ) na motorboat , A THAT MgF-1 DEF THAT IFTHEN DEF FROM / THAT I DEF PRED \L S AILINGBOAT-P Figure 8 nIf a motorboat meets a sailingboat , then the motorboat mdst steer away from tke sailingboatn 18 To the left is the pattern of three nodes corinected by sholit relations wikh DEF on both ends of the relations .</sentence>
				<definiendum id="0">THAT MgF-1 DEF THAT IFTHEN DEF FROM</definiendum>
			</definition>
			<definition id="3">
				<sentence>use it for many set relationships , Some exmaples : ALL A QUAC ALL B means that the sets A and B me equal and contain not more than one element each .</sentence>
				<definiendum id="0">QUAC ALL B</definiendum>
				<definiens id="0">means that the sets A and B me equal and contain not more than one element each</definiens>
			</definition>
			<definition id="4">
				<sentence>ITS A EQUAL ALL B means that A is a subset of B. ITS A EQUAL ITS B means that A and B overlap .</sentence>
				<definiendum id="0">EQUAL ALL B</definiendum>
				<definiens id="0">means that A is a subset of B. ITS A EQUAL ITS B means that A and B overlap</definiens>
			</definition>
			<definition id="5">
				<sentence>You could sw that W*P is the property of being a man , while M.AN*S is the set of all men .</sentence>
				<definiendum id="0">W*P</definiendum>
				<definiendum id="1">M.AN*S</definiendum>
				<definiens id="0">the set of all men</definiens>
			</definition>
			<definition id="6">
				<sentence>We also introduce the relation COMPLW which goes from a composite object to a predicate which applies not necessarily to the composite , but which applies to all its elements .</sentence>
				<definiendum id="0">relation COMPLW</definiendum>
			</definition>
			<definition id="7">
				<sentence>Se example in figure A4 , Example : `` The road and railway between Stockholm and Gothenburg is blockedetf STOCKHOLM-P RAILWAY -P T PRED T NAME DEF DEF ) ) ~tockholm ) ) ) ) The railway ) ) TWEEN DEF DEF BLOCKE &lt; PRED ) The rdad and railway ) ) a~tockholm and Gothenburgr I ) ) The road ) ) ELEME DEF DEF PRED DEF ELEMENT ROAD-P DEF NAME GOTHENBURG-P Figure 14 As seen from the picture , between goes from the elementary parts Itthe roadtf and `` the railway '' to the composite object IIS t ockholm and Gothenburg '' . 17. Noun , phYases with just a number and nothing more Some natural languages contains constructs where a noun phrase consists of only a number , usually followed by a preposition. Example `` One of the horsesf1 or `` Two of the horsesff , Rere , as usual `` one '' creates a singular set , while any number except 'bonen creates a composite object , The relation `` ofn is in this case translated into Noun phrase before the ! I Of It A composite object No coapasi-be object 36 Noun phrase after the `` ofu A composite object No composite object PART ELEMENT ITS REV ELEMENT ' EQUAL ITS Examples : Two of the horses : PART One of the horses : REV ELENIENT Two of dl horses : ELmT ITS One of all horses : EQUAL ITS 18 , S-ome examples of translations of sentences with plural nouns ILL-P HOR-P 1 DEF ELEMENT ) ) the horses ) ) ( DUMMY ) ) ) One of the horses is ill ) ) Figure 15 ) ) two ) ) ( DUMMY ) ) ) Two of the horses are ill ) ) Figure 16 Figure 17 ) ) The girls ) ) &gt; &gt; ; iSwdln ; ) DEF INSIDE EQUAL ) ) The girls in wede en are beautiful ) ) M~T NUM\ 1 COMPLEX PART\ / CASE ) ) the lines ) ) ) ) are ... p ( DUMMY ) BY / son EQUAL PATTERN-P the lines are making a pattern ) ) HIGH-P HUMIDITY-P RAINY-P DAY-P ) ) The humidity ) ) ( DUMMY ) INSIDE TROPIC-P &lt; rthe tropics ) ) PRED DEF Figure 19 ) ) The hurnldit~ on rajny days in the tropics is high ) ) COME-P PARENT-P 3 STUDENT-P PRED rparents of ) ) ) ) the three students ) ) ( VARIABLE ) ( DUMMY ) ELEMENT DEF DEF nall parents ) ) ( VARIABLE ) ( VARIABLE ) ) ) All parents of each of the three students are coming ) ) Figure 20 39 Figure 21 E AT-P ) ) John is eating three eggs , and one of them is rotten ) ) EGG-P &gt; John is eating ... ) ) &gt; ) three eggs ) ) rr C ( M ergc JOHN-P ) SOME ) ) them ) ) ( DUMB \ nar - .</sentence>
				<definiendum id="0">Gothenburg</definiendum>
				<definiens id="0">blockedetf STOCKHOLM-P RAILWAY -P T PRED T NAME DEF DEF ) ) ~tockholm ) ) ) ) The railway ) ) TWEEN DEF DEF BLOCKE &lt; PRED ) The rdad and railway ) ) a~tockholm and Gothenburgr I ) ) The road ) ) ELEME DEF DEF PRED DEF ELEMENT ROAD-P DEF NAME GOTHENBURG-P Figure 14 As seen from the picture , between goes from the elementary parts Itthe roadtf and `` the railway '' to the composite object IIS t ockholm and Gothenburg ''</definiens>
				<definiens id="1">usual `` one '' creates a singular set , while any number except 'bonen creates a composite object , The relation `` ofn is in this case translated into Noun phrase before the ! I Of It A composite object No coapasi-be object 36 Noun phrase after the `` ofu A composite object No composite object PART ELEMENT ITS REV ELEMENT ' EQUAL ITS Examples : Two of the horses : PART One of the horses : REV ELENIENT Two of dl horses : ELmT ITS One of all horses : EQUAL ITS 18 , S-ome examples of translations of sentences with plural nouns ILL-P HOR-P 1 DEF ELEMENT ) ) the horses ) ) ( DUMMY ) ) ) One of the horses is ill ) ) Figure 15 ) ) two ) ) ( DUMMY ) ) ) Two of the horses are ill ) ) Figure 16 Figure 17 ) ) The girls ) ) &gt; &gt; ; iSwdln ; ) DEF INSIDE EQUAL ) ) The girls in wede en are beautiful ) ) M~T NUM\ 1 COMPLEX PART\ / CASE ) ) the lines ) ) ) ) are ... p ( DUMMY ) BY / son EQUAL PATTERN-P the lines are making a pattern ) ) HIGH-P HUMIDITY-P RAINY-P DAY-P ) ) The humidity ) ) ( DUMMY ) INSIDE TROPIC-P &lt; rthe tropics ) ) PRED DEF Figure 19 ) ) The hurnldit~ on rajny days in the tropics is high ) ) COME-P PARENT-P 3 STUDENT-P PRED rparents of ) ) ) ) the three students ) ) ( VARIABLE ) ( DUMMY ) ELEMENT DEF DEF nall parents ) ) ( VARIABLE ) ( VARIABLE ) ) ) All parents of each of the three students are coming ) ) Figure 20 39 Figure 21 E AT-P ) ) John is eating three eggs , and one of them is rotten</definiens>
			</definition>
			<definition id="8">
				<sentence>SM goes between two composite objects , or between a composite object and a non-composite object .</sentence>
				<definiendum id="0">SM</definiendum>
			</definition>
			<definition id="9">
				<sentence>&amp; ample : `` TWQ girls are citizens of Norway '' would be translated like in figure 24 , ALL OBJCOMPLEX ITS , The two glrlsn ) Citizens of Norway , ( A composite DUMMY ) ' ( A defined set VARIABLE ) ) ) TWO guls are cituens of Norway ) ) 43 Second example : `` All people in the roam aro thd two girlstt is translated into figure 25 ; OB JCOMPLEX ~11 people in the ) ) The two girls~ room ) ) ( A non-composite ( A composite DUMMY ) VARIABLE ) ) ) All people in the room are the two gjrlsr Figure 25 predicate complement noun composite Subject noun non-composite composite non-composite SAME OB JCOMPLEX REV EQUAL OB JCOMPLEX Relations between predicates Predicates form an hierarchical structure , e .</sentence>
				<definiendum id="0">non-composite</definiendum>
				<definiens id="0">A composite DUMMY ) ' ( A defined set VARIABLE ) ) ) TWO guls are cituens of Norway</definiens>
			</definition>
			<definition id="10">
				<sentence>g. VERTEBRATE*P is a special case of ANIMAL*P , HUMAN*P is a special case of VERTEBRATE*P , KMG*P is a special case of HUMAN*P a.s.0 .</sentence>
				<definiendum id="0">g. VERTEBRATE*P</definiendum>
				<definiendum id="1">HUMAN*P</definiendum>
				<definiendum id="2">KMG*P</definiendum>
				<definiens id="0">a special case of ANIMAL*P</definiens>
			</definition>
			<definition id="11">
				<sentence>MAN-P DEPRESSED-P PASS &lt; DEPRESS-P .The always depressed man3 ( DUMMY ) Figure 32 The direct relation OBJPRED from `` the always depressed mann to DEPRESS*P is thus not created by input translation , but it can of course easily be deduced. In the same way , `` The bike is ridden by John '' is translated like in figure 33 , [ T~F.~-P IC PASS \ RIDE-P I PASSCASE ) ) The bike is ridden by John ) ) JOHN-P BIKE-P DEF Figure 33 48 The CASE relation from the event to RIDW is not output explicitly , but can of course easily be deduced. One could argue that we could avoid passive verbs altogether in our data base by always using the CASE and OBJPRED relations. There are two arguments against thls : a ) 1.t is valuable always to have the relatlon PRED from a noun to all properties on that noun , It is not systematic to need the relation OBJPRED to some properties , b ) Our representation makes it very easy to represent statements like `` Someone who is killed , is deadu simply by KILLED*P SUBATTR DW*P which otherwise would have to be represented by a VARIABLE in the way in figure 34. ) ) Someone who 1s k~lled , is deadr KILL-P DEAD-P Y ; , gEDl PED ) ) Someone who is killed ) ) Figure 34 23. Putting restrictions on equality One can see event nodes as a way of adding restrictions in time and space etc on PRED relations. The event nodes are necessary because our data base does not permit us to put short relations on short relations. Sometimes there , is a need to extend the SUBSET relation in the same way. PRED and SUBSET are very si..milar relations , 49 although PRED goes to a predicate , SUBSET to an object set. Since SUBSM ! is a special case of the EQUAL relation , it is really the EQUAL relation which we want to extend into an event. We therefore introduce a new relation OBJCASE so that y BY X &amp; Y OBJCASE Z implies X EQUAL Z whenever the event Y is true or valid. The relations thus form the triangle in figure 35. Figure 35 EQUAL The OBJCASE relation is used when natural language equality has +o be translated into relations between object nodes. AII example is given in figure 36. ) ) Every evening , John is a singer in the clubn JOHN-P NAME DEF Figure 36 ) ) Every evening ) ) AT-TIME / SINGER-P &gt; &gt; ... is ... &gt; &gt; DEF ) ) John ) ) ) ) singer in the clubr club ) ) 50 From this network , we can deduce that if the event is valid , e.g. in the evening , then llJohnlf is a SUBSET of `` singer in the clubt1 .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiendum id="1">John</definiendum>
				<definiendum id="2">llJohnlf</definiendum>
				<definiens id="0">a way of adding restrictions in time and space etc on PRED relations. The event nodes are necessary because our data base does not permit us to put short relations on short relations. Sometimes there , is a need to extend the SUBSET relation in the same way. PRED and SUBSET are very si..milar relations , 49 although PRED goes to a predicate</definiens>
				<definiens id="1">a special case of the EQUAL relation , it is really the EQUAL relation which we want to extend into an event. We therefore introduce a new relation OBJCASE so that y BY X &amp; Y OBJCASE Z implies X EQUAL Z whenever the event</definiens>
				<definiens id="2">a singer in the clubn JOHN-P NAME DEF Figure 36 ) ) Every evening ) ) AT-TIME / SINGER-P &gt; &gt; ... is ... &gt; &gt; DEF ) ) John ) ) ) ) singer in the clubr club</definiens>
			</definition>
			<definition id="12">
				<sentence>For example , `` After 1972 , Britain is a part of EECM requires us to expand the PART relation between Britaln and EEC into an event , to be able to add a time limitation to that PART relation .</sentence>
				<definiendum id="0">Britain</definiendum>
				<definiens id="0">a part of EECM requires us to expand the PART relation between Britaln and EEC into an event</definiens>
			</definition>
			<definition id="13">
				<sentence>ten ) DEF TO DEF DEF BY D Figure 41 CHH. , D-P &lt; pall the childrenr PRED DEF ) ) Is the father of all the children of any of ~ohn 's daughters married to that daughter ? r Look at the OF relation from `` the fathern to `` all the childrenn. This OF relation should single out just the ahildren of his wife , not the children of all her sisters. We have not yet found out how to do this. We hope that this complex kind of questions will not be common. 26. DUMMIES = temporw variables fBr data base merging A shart presentation of the concept of a DU ? @ fY was made in ~ection 8. I ) lDdIdI : ES and problems with them will be more fully treated here. When natural language uses constructs like `` HeVt or `` the manw or `` this object in the sk ; yV thm this usually refers to something which the reciever is supposed to know already. Often , the thing referred to has been mentioned a short time ago in the previous natural 1 anguage input. We therefore introduce a special kind of VARIABLE. This is call-ed a DUMMY. An ordinary VARIABLE is kept in the data base to be used at some later time for deduc.tion. A DUMMY causes an immediate search in the data base for a matching previously known object. The order of this search is important. If there are several previous objects matching the descriptions , the last-mentioned one shall usually be found. However , the subject usually goes before other noun phrases. If we say llI£ a card is below $ 1 mother card , then it can not be seen. '' then refers to the subject `` a cardw , not to the prepositional % nother card '' even though this was mentioned later. Our program will therefore make a list , the so-called CURRENT list , of previous-mentioned ob jeets. This is searched backwards. We have at present two search routines for DUMMY matching , the `` theu routine and the tlthis '' routine. One difference between them is that if no matching node is found , the `` thist1 routine will ask the user to rephrase his statement. The `` thet1 routine will in that case accept that this is something which the user knows , but not the computer. It will therefore enter a new node if no previous-mentioned is found. ke pxoroblem whlch we 80 fsr liare not completely solved is how to do with patterns of DUMMIES. If we soy `` the behind Johnw then there sre two nstttrd way8 to translate this into oar da $ a base t a ) &amp; o DWOBIE8 , one independent ( for `` ~ohn '' ) and another bependent ( for `` =the man '' ) as in figure 42. MAN-P PRED DEF JOHN-P NAME DEF , The mann % % &gt; uJohn , DEF BEHIND ALL Figure 42 nThe man behind Johnn 62 b ) A pattern key of tao mnfually depenqent DUBMtES , whexe qE3 ' BEElXD ALLw 5n the figure 42 is uhanged to `` DEF BEfflMD DEF '' , 'Fhe first translation +a neoe88~ in those oases where only one of the DUMKE hes a match in the data baae , e , g. for a atatement like `` Lf a man is late , then the man behind him is even later . ''</sentence>
				<definiendum id="0">base merging A shart</definiendum>
				<definiens id="0">a match in the data baae , e</definiens>
			</definition>
			<definition id="14">
				<sentence>64 This means that the `` the '' qwnmy algorithm must be able to decide if a CONSTANT or a VARIABLE is to be created when a DUMMY fihds no explicit match , 28 , The problem of dual representation We have of course during the writing of the SQAP system encountered many problems , For some of them we have found solutions , for some not , Many of the problems have &amp; ready been presented in this paper , and those problernswhich belong more to input `` canslation or -t ; o deduction than to data base structure do not fit into the subject of this paper , Looking at the problems we have met , there seems to be one problem which recurs several times , Th , is is the fact that the same natural language construct can be represented in several ways in our data base , We have found that this is unavoidable , since one yepresentation is necessary in some cases and another in other cases .</sentence>
				<definiendum id="0">VARIABLE</definiendum>
				<definiens id="0">to be created when a DUMMY fihds no explicit match</definiens>
			</definition>
			<definition id="15">
				<sentence>65 This means that whenever both BOOMP and BOOK*S occurs in our data base , the relation between them also exists .</sentence>
				<definiendum id="0">BOOK*S</definiendum>
				<definiens id="0">occurs in our data base , the relation between them also exists</definiens>
			</definition>
			<definition id="16">
				<sentence>Shapiro , Stumt Charles 1971 : The MIND system : A Data Structure for Semantic Information Processing .</sentence>
				<definiendum id="0">MIND system</definiendum>
				<definiens id="0">A Data Structure for Semantic Information Processing</definiens>
			</definition>
</paper>

		<paper id="1081">
			<definition id="0">
				<sentence>To be precise , a relation R defined on a set S is said to be a trana~t &lt; ve relation if whenever b and c are R-related and also c and d are I ? related then b and d staAd in a relation R also , Synonyniy is a transitive relation just as transitivity is. The preposition in behaves in the same way. If Sam is in the kitchen and the kitchen is in the hotel , then we know that Sam is in the hotel. The time interrelation before behaves like this , too. If Zorro arrived before the posse did and the posse arrived before thz explosion , then we know thgt Zorro arrived before the explosion. A relation R defined on a set S is said to have the refZez &lt; ue property if all the elements of S are R-related to thenl~elves , that is , if mRm is true for all members m of the set S , The synonymy relation has this property a word means the same thin % as itself. The antonymy relation ANTI does not have this property. It is not rrue tha &amp; , hot ANTI be , for example. A relation R defined on a set S is said to be e~stric if whenever , b and c are R-related then so are c and b ; that is , R is symme.tric if and only if bRc always implies cRb. Synonymy also has this property. If b is synonymous with c , then c is synonymous with b. So has antonfly. Given that hot ANTI sold , we immediately know that= cdd ANTI hot. Taxonomy ie not eymmetric , however. A lion is a kind of mammal , but a mammal is not a kind of lion. In question answering we may be just as Interested in drawing negative conclusions as positive-ones. Thus i~rmay be important to know tliat tf bRc is true then cRb must be falae. The term asynmrstrio is used to describe a relation R for which bRc and cRb are never both true , at $ east when b and c are different elements of the stt S. Taxonomy is asymmetric and so is the thug interrelation before. If the question asks , `` Did c happen before b ? '' and we know that b happened before r , we can answer with a confident no. For want of a better term we will say that the relr Sion R is mn-synonetrio if it is neither symmetric or &amp; symmetric. In this case bRc and cRb are sometimes both true and sometfmes not. Shilarly , he term imefz.exive is used for the case in which mRm is never true , while the term nonreflexit ) e is used for the case in which mRm is sometfmes true and sometimes not. In the same way intransiti~e is taken to mean that if bRc and cRd , we can conclude that b and d are not R-related , while nantrcrnsitive will mean that bRd is sometimes true if bRc and cRd , butnot always. Each lexical relation itself ; has a lexical entry. The reflexivity , symmetry , and transitivity properties of the relation are listed in this entry , as they are in the entries for interrelational operators and prepositions and other lexical item for which they are relevant. There are also lexical entries under the property names , refldvs , irr~~~~vr , etc. listing the appropriate axioms. The motivation behind laical entries for properties is first of all greater generality. Secondly , it makes it much easier to add lexical relations and to add other properties which turn out to be useful. At this stage of development there are several transitivity axioms : For lexical relations Rel , like taxonomy b Re1 c c Re4 d ' b Re1 d For interrelations J , like bsfbre lloZdsfI ( ~ , ~ , ,Z , ) ) A RoZda ( I ( J , Z2 , Z3 ) ) Holds ( I ( J , Z~ , z $ ) For prepositions Q like in or abave Intuitively these are all instances of the same concept , transitivity. Theze should be some single way of expressing it. It is a defect of this representation system that there is not. A relation that is reflexive , symmetric , and transitive Ls called an equivalence relation. The synonymy relation is an equivalence relation since it has all three properties. If R is an equivalence relation , then a subset consistrlng of all the elements which are R-related to a partirtllar element x by the7equivalence relation is called an equivalence class. In an equivalence class all the elements are R-related to each other. An equi vaf ence relation partitions a set into equivalence classes ; each element of the set belongs to exactly one equivalence claas. The synonymy relation paftitions the items in the lexicon Ln just this way. There Is a class consisting of stcsp % oion and all the words synonymous with 8148phion , like mistmcet and dozibt. These synonymy classes are disjoint ; each word sense in the lexicon belongs to exactly one of them ( cf. Edrrmndson and Epstein 1972 , Palmer 1976 ) . With this ge a basis an equivalence relation of paxaphrasability between sentences can be established. Sentence S1 is a paraphrase of sentence S2 if one is obtained from the other 3y substituting synonyms for each other. d Mr. Kennedy viewed Lady Laura with suspicion. Mr. Kennedy regarded Lady Laura with mistrust. We might also allow substitution of conversives , nominalizations , etc. Nancy was Sally 's student. Sally was ~ancy 's teacher. Sally taught Nancy. The equivalence classes of this relation , each one of which is the set of all pamaphrases of a given sentence have a definite theoretical importance and some practical significance in question answering. One member of a class might well 'be part of the story ; another the right answer to* a question. I This representation system can be viewed as defining a relation P such that S1 P S2 if and only if S1 and S2 have the same representation. If the representation system is well defined , then P should define the same equivalence classes as the paraphrasabilitv relatior b. Xttt ) srses , The inverse R of the relation R is the relation which `` goes in the opposite direction '' from R ; that is , bRc if and only if cRb. Thus , bake T make and mke T bake are two ways of saying the same thing. Both pieces of information are stated in the lexicon. However , the lexical entry for Eake includes T nuke ; the lexical entry for naks includes T hake. Why bother to say the same thing in different places ? There are two reasons for this. First of all , the inversa relation may be a relation that is conm~nly and easily verbalized , worth naming in its own right. This is certainly true of the CHILD relation , as in pu~py CHILD 20g. Instead of asking `` What is a baby dog called ? '' , we could ask ''What is a grow ? puppy talled ? '' or `` What does a puppy grow up to be ? '' The second reason is that putting this information in both entries can &amp; e searches easier and much faster , We may only have one half of the pair and need the other. We may have dog and pppy. This is easy if we have the information CHILD pppz~ in the dog entry. Othewise we might have to search the whole lexicon , In other situations we have two words but no direct connection between them. For example , suppose the system knows twn T mama2 and maZ T vertebrate and is then asked , `` Is a lion a vertebrate ? '' The connection betwen Zion and vertebrate can be found much more quickly if the search starts *om both the vertebrate end and the Zion end of the chain at the same time , but to do this there must be s pointer to m~mmaZ in the oertebrute entry. Another question comes to mind. Why call the inverse relation to CHILD by the clumsy name CAaD instead of its propel name PARENT ? The ECD uses t~o different names for a relation and its inverse ( So and Vo ace inverses , for example ) . If this were dane here , two versions of the appropriate axiom schemes would be needed , one in the CHILD entry and one in the PMNT entry. Since a relation R is called symmetric if bRc alwaye implies cRb , it follows that a symmetric relation ie its own inverse. The syaonymy relation S and antonymy relation ANTI are both self-inverse in thie sense. 7 For this reason we never need the spnbol ANTI , etc. ANTI is MITI The entry for hot includes ANTI cold , the entry for cold includes ANTI hot. Raphael ( 1968 ) has proposed a property which seems extremely useful. He calls it m6qus-Z $ nkuge ( U ) . Nathematicians usually.refer to such relatdons as one-to-one. A relation R has the unique-linkage property if whenever xRy then bRy is false for any bk and xRc is false for any cry , i.e. any object is R-related to at most one other. ~aphael 's example of unique-linkage is the relation `` just to the right of '' . The behavior ie especially characteristic of the queuing relation , e.g. with days of the week , Monday Q Tuesday , etc.Some relations may be uniquely linked on one side only , e.g. mother-child is uniquely linked on the left. We can define UL unique-linkage on the left and UR unique linkage on the fight. ( A relation which is UR is a single-valued function. If R has the UL property , then its inverse is a single-valued function. ) Raphael also proposed for SIR-1 ( ibid , p. 101 ) a property which he calls ixreflexive. R is set-nunreflexive if ( \lx M ) -- WBcX ) 6 ! acX ) @ RBI In the SIR model both the 'X is a part of Y ' and the 'X is owned by Yf relations hwe this property. What $ t qays is that every set in the model has a minimal element with respect to the relation R. A siapler version of th &amp; s property is sufficient for our purposes. Minimum ~cM ) ( ) 'Y i X ) ( 32 X ) { ZRY ) Condition Every noneslpty subset has a minLmum. Maximum WXcM ) - ( qr X ) ( 3 Z X ) ( YRZ ) Condition Every nonempty subset has a maximum. The part-whole relation ' has both properties in our model. In any nonempty subset in the model there is something in it that is not a proper subpart of anything else in that subset , and also something that has no proper subpart. A relation that has this property stops samewhere. It is not reflexive and not circular , A search that goes on looking for links of this kind will stop somewhere. The relation 'is an ancestor of ' has this property. We will eventually run out of ancestors in one direction and descendants in the other , at least , inside a finite model. The properties of relations are summarized in Table 4. Table 4. properties of Relations WL'erW symmetric 'asymmetric reflexive ixreflexive transitive intransitive unique1 y linked ~EM ) WY tM ) ( XRY ' YRX ) ~xLM ) NY LM ) ( XRP '' YRX ) ~XE bl ) WY t M ) ( ~ZE M ) ( XRY A YRZ - , XRZ ) uniquely linked on the left WEM ) WY M ) ( XRY - ' WZ EM ) ( ZRY ' Z=X ) ) uniquely linked on the right wXEM ) ( 4/Y fM ) XRY4 WZ EM ) { XRZ4 Z=Y ) ) d. Pmtial Ordering. Any transitive relation defines a partial ordering. Several of the lexisgl relatiohs discueeed earl , ier are transitive ; many lexical items are transitive too. One important reason for.repr*senting time in terns of the transitive interrelatEton before is to allow one to make the same kinds of sdmple deductions about time that one can make about taxonomy. Some transitive relations , like taxonomy , are alsb reflexive. In this case we talk about a weak order &lt; ng. ( X s : Y for numbers is a weak ordering. ) Some are not reflexive , these are called strong ordering relations. ( X &lt; Y for numbers is a strong ordering. ) The time relation before 5s a strong order3ng relation. For any weak ordering there is a strong ordering and conversely , Starting with the taxonomy relation T , for example , a relation TI or proper , taxonomyl ' can be defined consisting of the pairs x and y for which xTy but x and y are different. Then~Tly means that x is a kind of y but different from y. If instead one starts with strong ordering relation before , one can deane a weak relation `` beforel '' for which x beforel y means that either x before y or x cooccured with y. The queuing relation Q is nat itself a partla3 ordering but a partial ordering can 'be derived from it. Monday Q Tuesday anLTuesday Q Wednesday , but it is false that Monday Q Wednesday. Queuing is an 'immediate successor *lation like the relatxon between a natural number n and the next number n+l. A relation Q ' can be defined such that xQ1y if either xQy or there are some objects cl , z2 , . .. , z , such that xQzl , z1Qz2 , ... znQy. It follows immediately that if bQc and cQd then bQ1d. Q ' , the 'successor ' relation , 95 2 4 ie now transitive , for if # ltc and cQ1d , then one can find s chain of Q-related objects linking b and d just bv cbncatenating the chain linking c and d , Rapbl 's pair of relations jright and right behave this way. The relations `` is a child of '' and `` is a descendant of '' are alga pafred in this way , Kenneth C. Litkowski 16729 Shea Lane Gaithersburg , Maryland 20760 Yummnry 4 I. Introduction t* ? . lttitudes Toward 1 ) Cction 'iriee t ? h. Pasip Flodel 1h &amp; The Ultimate Bsdel : Foints as Concepts 30 1O.Helationshi~ to Xfforts to Sepresent Enowledge in Frames 44 1 1 , Final Remarks 47 4ef erences 4s Pr pure s basic model and multi ple definitions Table SUMM ( 9 l $ X Ordinary dictionaries have not been given their due , either AH 80ur~e8 of material for natural language understanding syetema or as corpora that can be used to unravel the complexities of meaning and how it is represented. If either of these goal8 are aver to be ~chieved , I believe that investigators must develop methods for extracting the semantic content of dictionaries ( or at least for transforming it into a more useful form ) . It is argued that definitions contain a great deal of information about the semantic characteristics which should be attached to a lexeme , To extract or surfacke such infarmation , it will be necessary to systematize definitions and what they represent , probably using semantic primitives. In this paper , I deecribe procedures which I have developed in an attempt to accomplish these objectives for the set of verbs in Websterle Third New Intern~tional Dictionary ( ~3 ) . I describe ( 4 ) how I have'used the structure of the dictionary itself in an attempt find semantic primi tive s and how appears that the systematization must incorporate a capability for word sense diecrimination and must capture the knowledge contained in a definition. The body of the paper is concerned with demonstrating that semantic information can be surf aced through a rigorous analysis of dictionary definitions. The first step in this process reaviresa clom~phenaive framw~arkwithin WkLch def iait ions can be an~ly~ed. In , dcvelopinp thls framework , we must r~membrr thqt ~qch wordlu~erl. in I definl tion is .ilm dc1 ineci in the rl~ctionqry , so that we must be qble to uncsvpr ~nd dc..~ ? kit ! ! v1cious circles , The framework must llso be cwable oi rerrt-senting traditionql nations of q~nerative grammar to de3l wiTh the syntnct~c structure of definltlon~ , s~ritable framework , IFPears to be arovided bv the theory of lqbrled directrd ( T~PILP ( di , graphs ) . Using points to represent dictionqry entries ~nd lines to represent the relation `` is used to defi.neV , two models of the dictionary are described. ? rro theee models and from digrwh theory , we cqn conclude that there may exist orimi-tive units of meaning from which 911 concepts in the dictionary can be derlved. To determine arimitive concepts , it is necessarv to subject definitiuns to syntactic and semantic nsrsinp in order to identify characteristics that should be att~chkd to each definition. Syntactic parsing such as that implemented for systemic grammar by Minograd is the first stea. semantic parser must next be developed. Tt appears that definitions themselves , and particularly definitions of prep~si.ti~ns ( which are used to express sense relations ) , will be of sipi , ficant help : in develop ; ing such a Darser , Further work is necessary to develon procedures for surfacing from definitions i.nformation about the context which must be associ.ated with each sense. It wpears as ib this Darser wlll have more ~eneral use for ordlnary discourse. 5 These notions lead to the ultimate model of a dictionary , where points represent concepts ( which nay be verbalized and symbolized in more than one lay ) and lines represent relations ( synta~ti , c or aemantk-c ) between canoepts. Ba ~ed on these models , procedures for f i , nding prirniti-ve concepts are described , using the set of verbs and their definitions from W3. Specific rules are described , based on some elementary graph-th6qre tic principles , structural characteristics of dictionary de'finitiohs , and the parsing of the definitions. These rules have thus far reduced the initial eet of 20,000 verbs to fewer than 4,000 , with further reduction to cone as all rules are applied , It is argued that this approach bears a~ strong relationship to efforts to represent knowledge in framecr. Although much work is needed on the parser and on a computerized version of this approach , there is some hope that the parser , if expectations are borne out , will be capable of transforming ordinary discourse into canonical frame representations , 6 1 . INTRODUCTION During the pa~t 15 years. scientists in many fields have been building a reservoir of knowledge about the semantic char acteristics of natural language. Perhaps somewhat inexplicably znese developments have for the most part Agnored the semantic contenl of dictionaries , despite the fact that even a small one contain8 a vast amount of material. Some attempts have been made to dent these repositories , but the steps t'aken have been tentative and have not yet borne significant fruit , perhaps because che sheer volume and scope of a dictionary is so overwhelming. As a result , most studies have dealt with only a few definitions wj % hout a comprehensive assault on the whole. While such studies have led to many insights , it seems that the full ugerulness of a dictionary 's cantents will be realized only when a comprehensive model of its semantic structure is dweloped , Any system intended to provide natural language understanding must necessarily include a dictiona~. If any such system is to achieve broad applicability , its dictionary lnust cover a substantial pat of the natural language lexicon. For this to occur , the developers of a system must either create a dictionary from scratch or be able to incorporate an existing dictxonary. Given the amount of effort that usually goes into development of an ordinary dictionary , the former a1 ternative is rather impractical. Bowever , little has been done toward meetinn the latter alternative ; with wnat follows , I will 7 describe the approach which I believe must be followed in transforming the contents of an ordinary dictionary for us6 In a true naturaX language system , In order to be used in a language understanding system , a dictionary 's semantic contents must be systematized in a way that the sense in which a word ia being used can be identified. Bbfore thi~ can be done , it is necessary to characterize what 1s already cantained in each definition. To do this , it seems necessary to write the meaning of each definition in terms of serpantic and syntac5ic primitives. My purpose in this paper ia ( 1 ) to describe how to use the dictionary itself to move toward idhntification of the primitives , at the same time ( 2 ) showing how this process can be used ( a ) to provide the capability for discriminating among word senses ( i. e. characterizing ; the frames into which a given word sense will fit ) and ( b ) to characteriee knowledge contained or presupposed in a definition. Before elhbarking on the description , it- $ 8 necessary tc paint out some limitations whZch shaad be kept in mind as Dhe reader proceeds. First , in trying to @ resent an overview of my approach , I have had to forgo describing the detailed steps which I have followed to date. Second , even had I presented a full description , I would still have been short of providing sufficient details to enable computer implementation of any procedures. Third , Since the approach presumgs that cancepts represented by the lexicon are tne realizations of many as yet unknovin-rrecursive functions to be dl scovered by stripping away 8 one-layer at a t~me , results other than procedures to be used An stripplpg will not emerge untll all layers have been removed. ( However , I do wrae that the llstripplngm procedures are inherently useful , in that they will constitute a parser even in the intermea~ase stages. ) Fourth , since I have not ha @ access to a computer , which has become essentlalLfor significant further progress , I have been unable to determine how far the grocedures I have developed would take me , so there iLs an inherent uncertain-ty as to how much further development as needed. Notw~thstandlng these limitations , I am hopeful that what is prenented will provide a satisfactof.y framework for further iLnvestigations into the contents of dictlonarles. I will comment further on these limitahions and how they might be overcome at the end of the paper. 2 , ATTITUDB'3 TOWARD DICTION4RIE5 Many of +he siqnifxcant contributors to the present understandxng of rneanlng ( such as Xatz and Fodor 1963 , Plllmore 1968 and 7971 , CHafe 1970 , Jackendoff 1974 , wlnograd 1972 , and Schank 9972 ) have generally lgnored dictlonarles. Yet , each has presented a formulai~ structure for lexical entrhe5 to serve as a bas= for the creation of a rlew dictionary 4lthough their perceptions abouti the nature of language are well-established , thei ? formellsms for lexxcal entries have not taken advantage of the equally well-establ~shed praetlces of lexicography. The rationale underlslng the development of new fommalisms~ ex~rer~sed in some cases and ~m~llcrt t ; n others , ids that lexlcal 9 entries in dictionaries am unsatisfactory DeCAuse they do not contain sufficient infomation. These formali-sms thus require that semantic features such as 1lanirnateft or `` statew be appended* to particular ent*ies. While it is true that ordinary diotionary entries do not overtly identify all appropriate features , this may be lees a dlfficulhg inherent in definitions than the fact thst no one has developed the necessary mechanisms for surfacing features from definitions. Thus , for examp3.e. ltnurse1 ' may not have the feature llanLmatew in its definition , but t ? nuraew is defined as a ltwomanw which fs defined ad a tlpersonw ~hich is defined as a 1 '' beingfl '' which `` Ys defined as a `` living thingw ; this string seems sufficieht te estabaish `` nurseN as `` anirnatell. In general , it seems that , if a semantic feature is essential to the meaning ofa particular entry , it is similarly necessary % Hat the feature be discoverable within the semantic structure of a dictionary , Otherwise , there is a defect in one or more definitione , or the dictionarycontains some internal inconsistency. ( Clearly , it is beyond expectation that any pre~nt dictionary will be free of these problems. ) The possibility of defective definitions has also gene^-ated crf ticiams , more direct than above , on the potential usefulness Of a dictionary. On one Hand definitions are viewed as `` deficient in the presentation of relevant dataw since they provide meaninbv ueing `` substitutable words ( i.e. by synonyms ) , rather than by listing distinctive femtureafl ( Nida 1975 : 172 ) . On another hand- , the proliferation of meanings 10 attached to an entry is viewed as only a case of `` apparent polyeenyN which obscures the more general meaning of a lexeme by the addition of `` redundant features already determined by the environmentft ( Bennett 1975:4-1.1 ) . Both objections may have much validity and ts that extent would necessitate revisions to iqdividu &amp; or sets of definitions. However , neither viewpoint is sufficient ' to preclude an analysis of what actually appears in any dictionary. It is possible that a cbmprehensive analysis might more readily surface such difficulties and make their amelioration ( and the consequent improvement of definitions ) that mu &amp; easier , Xven though dictionaries are viewed somewhat askance by many who study meaning , it seems that this viewpdint is influenced more by the difficulty o* systematically tapping their contents than by my substantive objections which conclusively establish themas ~seless repositories of semantic content. However , it is necessary to demonstrate that a spstematic app~oach exists and can yield useful results. 3 , PREVIOUS RESXARCN ON DICTXONARIES Notwithstanaing the foregoing direct and indirect criticisms. some attempts have been made to probc the nature and &amp; structure of dictionary definitions. A review of relevant aspects QItwo such studus will help the niaterial presented here stand out in sharper relief. Olney 1968 describes the conceptual baais of many pro $ eetted routines for processing a machine-readable transcript of 11 Webster ' s Seveqth New Collq &amp; ate Dictionary ( ~7 ) . The primary objectives of these routines were the development of `` ( a ) rules for obtaining c-ertain of the senses described for W7 entries from other senses described for the same entries or from senses described for other W7 entries from which the first ( at least in typical cases ) were derived morphologically ; and ( b ) semantic wmponents and rules for combining them to yield specifications of senses that can not conveniently be obtained br rules refer~ed to in ( a ) above. '' ( ibid. : 6 ) Although these objectives me reasonable , they do not take advantage of the possibility that the semantic structure of a dlictionary might be a unlfied whole. As a\ result , an8 routines that are developed seem to require the serendipitous perception of patterns. Further , i0 a dictionary does have a unified semantle stpucture , it is not clear that a rule relating meaning to form wil-1 be relevant toga model ' of the semantic structure even though interesting results might emerge. It seems n-cessary to have some comprehensive view that will permit un to kaW whether a particular rule is well-formed. This lack of objective criteria also im~erils any anaIysisthat selects a subset of definrrions for detailed analysis. The selection of a subset of the dictionary shoulcl. arise from wll-defined a priori considerations mmer than an intuition that a particular 12 wbset seems to be related , An example of this intuitive agproach appears ~JI Simmons 1975 and 1976. rn Quillian 1968 , the analysis of dictionary definitions was part of a study of semantic memory , and for that reason was noP concerned with the full development of a dictionary model. In that study , a person determined the mesning of a concept when he `` looked up the 'patriarch1 ward in a dictionary , then looked up every word in each of its definitions , then looked up every word f6hnd-in each of those , and so on , continually branching outward until every word he could reach by this process had been Looked up once. '' This process was never actually carried out because ( 1 ) not all words in a dictionary were used in the computer files , ( 2 ) the process was terminated when a common word was found in comparing the meanings of two words , and ( 3 ) there was a bellef that there are no primitive ward concepts. The termination of a search 3x designed was necessary in any event since , without my restrictions , it is likely that a large part of the dhztionary would have been reached on every occasion , More importantly , Quillian did not fully consider wHat was happening when branching led to a word already encountered , namely , that a definitional circularity was thereby uncovere6 Such circularities which mi-ght be vicious cir-cles , must be treatea specially ( as will be shown below ) , and hence , Quillian8 s unrestricted branching should have been mdifbed. Quill ian also overlooked the. possibility that a concept common to two qatriarchs is more primitive than either. The continued comparison of more and more primitive concepts , along with restricti~ns on the outward branching , implies that primitiive concepts actually do Based on these observations , I take , as a working hypothesis , the assumption that a dictionary may be a unified whole with underlying primitive conce~ts. ' With thin beginning , it is necessary to articulate a mod &amp; of the dictionary which will permit an identifiqatian of the primitive concepts through the application of well-defiaea rules or procedures. It is proposed that what follows constitutes the first steps toward meeting this objective , Since a dictionary contains much material , it is first necessary to delineate exactly what is to be modeled- ? For thi~s purpose , it is assumed that the semantic content of a dictionary essentially resides within its defi.nitions , thereby excluding from formal analysis such things as the pronunciation , the etymol~gy , and illwtrative examples. s presently concelvea , the analysis will focus on the ward belng defined ( hereafter called Ehe main entry ) , the definitions ( including sense numbers and letters used as delimiters ) , part-of-speech I No dictianary is likely ta satisfy thls assumption , which is only a theoretically desirable characteristic. The assumption enables us to exclude the definienda from the models , 2 In the interests of space , I have glossed over B large number of intricacies that would have to be dealt with in arriving at a machine-readable hnscript suitable for analysis. Several pages would be reqyired to describe them fully. labels , status or usage labels , and usage notes. The manner in which these features will be employed will be made clear as the analysis proceeds. The hypothesized unified nature of a dictionary arises from the fact that definitions are expressed by werds which are 3 4180 defined ( i. , there is no semantic metalangua~e ) . If we wish to understand the meaning of a given definition , then we must first understand the meanings of its constituent w &amp; dse Since each constituent corresponds to a main entry , then , in order to understand the meaning of the given definition , we mus % understand the meaning of the constituent wards1 definitions , Continued repetition of the process is nothing more than , the outward branching process described by Quillian ; however , as mentioned before , we must make this branching more disciplined in order to deal with vicious circles and avoid unwanted circularities , If we are to have a fully consistent dictiona~y , its model must show how each definition is related to all others. Thus , for each definition , X , the model should enable to identify ( 1 ) those definitions of the constituent wordr of X that apply and those that do not apply , and ( 2 ) the production rules that generated X from these definitions. For exampl , e , in the definition of tqe noun broadcast , `` the act of spreading abroadu , 4 it There are some exceptions to this assertion , such as groper names , . biological caxa , and other special symbols , a s pointed out by the Journal 's referee. 15 is necessary that the model indicate ( 1 ) which of the definitions of -- the , act , of , spread , and abroad apply , and ( 2 ) the production rules by which the and ___I_ act and all other collocations ) occur together. If this can be done for each definition in the dict~onary , and if any inconsistencies are reconciled , then , as will be shown , it should be possible to find the primitive concepts in the dictionary and to transform each definition mto a canonical f Drm. 5 , BJSIC MODEL The theory of ( labeled ) directed graphs ( digraphs ) 5 is used as the formalism for the modds. Digraph 'theory deals wj th the abstract notions of lfpointsff and `` directed linest1 ; its applicability to the problem before us therefore depends on how these notions are interpreted. In this respect , it 1s important to distinguish tpe manner in which this theory is used here from the manner in which it previously has been used in semantics and linguistics. The two most common uses are ( 1 ) where trees display phrase and syntactic structures ( cf. Kate and Fodor 1963 ) , or ( 2 ) where directed graphs portray the seguena tial generation of words in a se~tence or phrase lcf. Simmons 1972 ) . In these cases and others ( cf. Quillian 1968 and Bennett 1975 ) graphs are used primarily as a vehicle for display All definitmns ueed in this paver are taken from Websterts . Third New International ~iction &amp; ry , Eficyclopaed~a Britannica , Chicago , 1965. Terminolqy for digraphs follows Rarary 1965. 16 and no results from graph theorv are expPicitly employed to d &gt; aw further inferences .</sentence>
				<definiendum id="0">Synonyniy</definiendum>
				<definiendum id="1">however. A lion</definiendum>
				<definiendum id="2">bRc</definiendum>
				<definiendum id="3">synonymy relation</definiendum>
				<definiendum id="4">ANTI</definiendum>
				<definiendum id="5">xRc</definiendum>
				<definiendum id="6">'X</definiendum>
				<definiendum id="7">Ultimate Bsdel</definiendum>
				<definiendum id="8">def iait ions</definiendum>
				<definiens id="0">a relation R defined on a set S is said to be a trana~t &lt; ve relation if whenever b and c are R-related and also c and d are I ? related then b and d staAd in a relation R also ,</definiens>
				<definiens id="1">a transitive relation just as transitivity is. The preposition in behaves in the same way. If Sam is in the kitchen and the kitchen is in the hotel , then we know that Sam is in the hotel. The time interrelation before behaves like this , too. If Zorro arrived before the posse did and the posse arrived before thz explosion , then we know thgt Zorro arrived before the explosion. A relation R defined on a set S is said to have the refZez &lt; ue property if all the elements of S are R-related to thenl~elves , that is , if mRm is true for all members m of the set S , The synonymy relation has this property a word means the same thin % as itself. The antonymy relation ANTI does not have this property. It is not rrue tha &amp; , hot ANTI be , for example. A relation R defined on a set S is said to be e~stric if whenever , b and c are R-related then so are c and b ; that is , R is symme.tric if and only if bRc always implies cRb. Synonymy also has this property. If b is synonymous with c , then c is synonymous with b. So has antonfly. Given that hot ANTI sold</definiens>
				<definiens id="2">Interested in drawing negative conclusions as positive-ones. Thus i~rmay be important to know tliat tf</definiens>
				<definiens id="3">true then cRb must be falae. The term asynmrstrio is used to describe a relation R for which bRc and cRb are never both true , at $ east when b and c are different elements of the stt S. Taxonomy is asymmetric and so is the thug interrelation before. If the question asks , `` Did c happen before b ? '' and we know that b happened before r , we can answer with a confident no. For want of a better term we will say that the relr Sion R is mn-synonetrio if it is neither symmetric or &amp; symmetric. In this case bRc and cRb are sometimes both true and sometfmes not. Shilarly , he term imefz.exive is used for the case in which mRm is never true , while the term nonreflexit ) e is used for the case in which mRm is sometfmes true and sometimes not. In the same way intransiti~e is taken to mean that if bRc and cRd , we can conclude that b and d are not R-related , while nantrcrnsitive will mean that bRd is sometimes true if bRc and cRd , butnot always. Each lexical relation itself ; has a lexical entry. The reflexivity , symmetry , and transitivity properties of the relation are listed in this entry , as they are in the entries for interrelational operators and prepositions and other lexical item for which they are relevant. There are also lexical entries under the property names , refldvs , irr~~~~vr , etc. listing the appropriate axioms. The motivation behind laical entries for properties is first of all greater generality. Secondly , it makes it much easier to add lexical relations and to add other properties which turn out to be useful. At this stage of development there are several transitivity axioms : For lexical relations Rel , like taxonomy b Re1 c c Re4 d ' b Re1 d For interrelations J , like bsfbre lloZdsfI ( ~ , ~ , ,Z , ) ) A RoZda ( I ( J , Z2 , Z3 ) ) Holds ( I ( J , Z~ , z $ ) For prepositions Q like in or abave Intuitively these are all instances of the same concept , transitivity. Theze should be some single way of expressing it. It is a defect of this representation system that there is not. A relation that is reflexive , symmetric , and transitive Ls called an equivalence</definiens>
				<definiens id="4">an equivalence relation since it has all three properties. If R is an equivalence relation , then a subset consistrlng of all the elements which are R-related to a partirtllar element x by the7equivalence relation is called an equivalence class. In an equivalence class all the elements are R-related to each other. An equi vaf ence relation partitions a set into equivalence classes ; each element of the set belongs to exactly one equivalence claas. The synonymy relation paftitions the items in the lexicon Ln just this way. There Is a class consisting of stcsp % oion and all the words synonymous with 8148phion , like mistmcet and dozibt. These synonymy classes are disjoint ; each word sense in the lexicon belongs to exactly one of them ( cf. Edrrmndson and Epstein 1972 , Palmer 1976 ) . With this ge a basis an equivalence relation of paxaphrasability between sentences can be established. Sentence S1 is a paraphrase of sentence S2 if one is obtained from the other 3y substituting synonyms for each other. d Mr. Kennedy viewed Lady Laura with suspicion. Mr. Kennedy regarded Lady Laura with mistrust. We might also allow substitution of conversives , nominalizations , etc. Nancy was Sally 's student. Sally was ~ancy 's teacher. Sally taught Nancy. The equivalence classes of this relation , each one of which is the set of all pamaphrases of a given sentence have a definite theoretical importance and some practical significance in question answering. One member of a class might well 'be part of the story ; another the right answer to* a question. I This representation system can be viewed as defining a relation P such that S1 P S2 if and only if S1 and S2 have the same representation. If the representation system is well defined , then P should define the same equivalence classes as the paraphrasabilitv relatior b. Xttt ) srses , The inverse R of the relation R is the relation which `` goes in the opposite direction '' from R ; that is , bRc if and only if cRb. Thus , bake T make and mke T bake are two ways of saying the same thing. Both pieces of information are stated in the lexicon. However , the lexical entry for Eake includes T nuke ; the lexical entry for naks includes T hake. Why bother to say the same thing in different places ? There are two reasons for this. First of all , the inversa relation may be a relation that is conm~nly and easily verbalized , worth naming in its own right. This is certainly true of the CHILD relation , as in pu~py CHILD 20g. Instead of asking</definiens>
				<definiens id="5">suppose the system knows twn T mama2 and maZ T vertebrate and is then asked , `` Is a lion a vertebrate ? '' The connection betwen Zion and vertebrate can be found much more quickly if the search starts *om both the vertebrate end and the Zion end of the chain at the same time , but to do this there must be s pointer to m~mmaZ in the oertebrute entry. Another question comes to mind. Why call the inverse relation to CHILD by the clumsy name CAaD instead of its propel name PARENT ? The ECD uses t~o different names for a relation and its inverse ( So and Vo ace inverses , for example ) . If this were dane here , two versions of the appropriate axiom schemes would be needed , one in the CHILD entry and one in the PMNT entry. Since a relation R is called symmetric if bRc alwaye implies cRb , it follows that a symmetric relation ie its own inverse. The syaonymy relation S and antonymy relation</definiens>
				<definiens id="6">MITI The entry for hot includes ANTI cold , the entry for cold includes ANTI hot. Raphael ( 1968 ) has proposed a property which seems extremely useful. He calls it m6qus-Z $ nkuge ( U ) . Nathematicians usually.refer to such relatdons as one-to-one. A relation R has the unique-linkage property if whenever xRy then bRy is false for any bk and</definiens>
				<definiens id="7">the relation `` just to the right of '' . The behavior ie especially characteristic of the queuing relation , e.g. with days of the week , Monday Q Tuesday , etc.Some relations may be uniquely linked on one side only , e.g. mother-child is uniquely linked on the left. We can define UL unique-linkage on the left and UR unique linkage on the fight. ( A relation which is UR is a single-valued function. If R has the UL property</definiens>
				<definiens id="8">a single-valued function. ) Raphael also proposed for SIR-1 ( ibid , p. 101 ) a property which he calls ixreflexive. R is set-nunreflexive if ( \lx M ) -- WBcX</definiens>
				<definiens id="9">a part of Y ' and the 'X is owned by Yf relations hwe this property. What $ t qays is that every set in the model has a minimal element with respect to the relation R. A siapler version of th &amp; s property is sufficient for our purposes. Minimum ~cM ) ( ) 'Y i X ) ( 32 X ) { ZRY ) Condition Every noneslpty subset has a minLmum. Maximum WXcM ) - ( qr X ) ( 3 Z X ) ( YRZ ) Condition Every nonempty subset has a maximum. The part-whole relation ' has both properties in our model. In any nonempty subset in the model there is something in it that is not a proper subpart of anything else in that subset , and also something that has no proper subpart. A relation that has this property stops samewhere. It is not reflexive and not circular , A search that goes on looking for links of this kind will stop somewhere. The relation 'is an ancestor of ' has this property. We will eventually run out of ancestors in one direction and descendants in the other , at least , inside a finite model. The properties of relations are summarized in Table 4. Table 4. properties of Relations WL'erW symmetric 'asymmetric reflexive ixreflexive transitive intransitive unique1 y linked ~EM ) WY tM ) ( XRY ' YRX ) ~xLM ) NY LM ) ( XRP '' YRX ) ~XE bl ) WY t M ) ( ~ZE M ) ( XRY A YRZ - , XRZ ) uniquely linked on the left WEM ) WY M ) ( XRY - ' WZ EM ) ( ZRY ' Z=X ) ) uniquely linked on the right wXEM ) ( 4/Y fM ) XRY4 WZ EM ) { XRZ4 Z=Y ) ) d. Pmtial Ordering. Any transitive relation defines a partial ordering. Several of the lexisgl relatiohs discueeed earl , ier are transitive ; many lexical items are transitive too. One important reason for.repr*senting time in terns of the transitive interrelatEton before is to allow one to make the same kinds of sdmple deductions about time that one can make about taxonomy. Some transitive relations , like taxonomy</definiens>
				<definiens id="10">a strong ordering. ) The time relation before 5s a strong order3ng relation. For any weak ordering there is a strong ordering and conversely , Starting with the taxonomy relation T , for example , a relation TI or proper , taxonomyl ' can be defined consisting of the pairs x and y for which xTy but x and y are different. Then~Tly means that x is a kind of y but different from y. If instead one starts with strong ordering relation before , one can deane a weak relation `` beforel '' for which x beforel y means that either x before y or x cooccured with y. The queuing relation Q is nat itself a partla3 ordering but a partial ordering can 'be derived from it. Monday Q Tuesday anLTuesday Q Wednesday , but it is false that Monday Q Wednesday. Queuing is an 'immediate successor *lation like the relatxon between a natural number n and the next number n+l. A relation Q ' can be defined such that xQ1y if either xQy or there are some objects cl , z2 , . .. , z , such that xQzl , z1Qz2 , ... znQy. It follows immediately that if bQc and cQd then bQ1d. Q ' , the 'successor ' relation , 95 2 4 ie now transitive , for if # ltc and cQ1d , then one can find s chain of Q-related objects linking b and d just bv cbncatenating the chain linking c and d , Rapbl 's pair of relations jright and right behave this way. The relations `` is a child of '' and `` is a descendant of '' are alga pafred in this way</definiens>
				<definiens id="11">Foints as Concepts 30 1O.Helationshi~ to Xfforts to Sepresent Enowledge in Frames 44 1 1 , Final Remarks 47 4ef erences 4s Pr pure s basic model and multi ple definitions Table SUMM ( 9 l $ X Ordinary dictionaries have not been given their due , either AH 80ur~e8 of material for natural language understanding syetema or as corpora that can be used to unravel the complexities of meaning and how it is represented. If either of these goal8 are aver to be ~chieved , I believe that investigators must develop methods for extracting the semantic content of dictionaries ( or at least for transforming it into a more useful form ) . It is argued that definitions contain a great deal of information about the semantic characteristics which should be attached to a lexeme , To extract or surfacke such infarmation , it will be necessary to systematize definitions and what they represent , probably using semantic primitives. In this paper , I deecribe procedures which I have developed in an attempt to accomplish these objectives for the set of verbs in Websterle Third New Intern~tional Dictionary ( ~3 ) . I describe ( 4 ) how I have'used the structure of the dictionary itself in an attempt find semantic primi tive s and how appears that the systematization must incorporate a capability for word sense diecrimination and must capture the knowledge contained in a definition. The body of the paper is concerned with demonstrating that semantic information can be surf aced through a rigorous analysis of dictionary definitions. The first step in this process reaviresa clom~phenaive framw~arkwithin WkLch</definiens>
				<definiens id="12">cwable oi rerrt-senting traditionql nations of q~nerative grammar to de3l wiTh the syntnct~c structure of definltlon~ , s~ritable framework , IFPears to be arovided bv the theory of lqbrled directrd ( T~PILP ( di , graphs ) . Using points to represent dictionqry entries ~nd lines to represent the relation</definiens>
				<definiens id="13">units of meaning from which 911 concepts in the dictionary can be derlved. To determine arimitive concepts , it is necessarv to subject definitiuns to syntactic and semantic nsrsinp in order to identify characteristics that should be att~chkd to each definition. Syntactic parsing such as that implemented for systemic grammar by Minograd is the first stea. semantic parser must next be developed. Tt appears that definitions themselves , and particularly definitions of prep~si.ti~ns ( which are used to express sense relations ) , will be of sipi , ficant help : in develop ; ing such a Darser , Further work is necessary to develon procedures for surfacing from definitions i.nformation about the context which must be associ.ated with each sense. It wpears as ib this Darser wlll have more ~eneral use for ordlnary discourse. 5 These notions lead to the ultimate model of a dictionary , where points represent concepts ( which nay be verbalized and symbolized in more than one lay ) and lines represent relations ( synta~ti , c or aemantk-c ) between canoepts. Ba ~ed on these models , procedures for f i , nding prirniti-ve concepts are described , using the set of verbs and their definitions from W3. Specific rules are described , based on some elementary graph-th6qre tic principles , structural characteristics of dictionary de'finitiohs , and the parsing of the definitions. These rules have thus far reduced the initial eet of 20,000 verbs to fewer than 4,000 , with further reduction to cone as all rules are applied , It is argued that this approach bears a~ strong relationship to efforts to represent knowledge in framecr. Although much work is needed on the parser and on a computerized version of this approach</definiens>
				<definiens id="14">borne out , will be capable of transforming ordinary discourse into canonical frame representations , 6 1 . INTRODUCTION During the pa~t 15 years. scientists in many fields have been building a reservoir of knowledge about the semantic char acteristics of natural language. Perhaps somewhat inexplicably znese developments have for the most part Agnored the semantic contenl of dictionaries , despite the fact that even a small one contain8 a vast amount of material. Some attempts have been made to dent these repositories , but the steps t'aken have been tentative and have not yet borne significant fruit , perhaps because che sheer volume and scope of a dictionary is so overwhelming. As a result , most studies have dealt with only a few definitions wj % hout a comprehensive assault on the whole. While such studies have led to many insights , it seems that the full ugerulness of a dictionary 's cantents will be realized only when a comprehensive model of its semantic structure is dweloped , Any system intended to provide natural language understanding must necessarily include a dictiona~. If any such system is to achieve broad applicability , its dictionary lnust cover a substantial pat of the natural language lexicon. For this to occur , the developers of a system must either create a dictionary from scratch or be able to incorporate an existing dictxonary. Given the amount of effort that usually goes into development of an ordinary dictionary , the former a1 ternative is rather impractical. Bowever , little has been done toward meetinn the latter alternative ; with wnat follows , I will 7 describe the approach which I believe must be followed in transforming the contents of an ordinary dictionary for us6 In a true naturaX language system , In order to be used in a language understanding system , a dictionary 's semantic contents must be systematized in a way that the sense in which a word ia being used can be identified. Bbfore thi~ can be done , it is necessary to characterize what 1s already cantained in each definition. To do this , it seems necessary to write the meaning of each definition in terms of serpantic and syntac5ic primitives. My purpose in this paper ia ( 1 ) to describe how to use the dictionary itself to move toward idhntification of the primitives , at the same time ( 2 ) showing how this process can be used ( a ) to provide the capability for discriminating among word senses ( i. e. characterizing ; the frames into which a given word sense will fit ) and ( b ) to characteriee knowledge contained or presupposed in a definition. Before elhbarking on the description , it- $ 8 necessary tc paint out some limitations whZch shaad be kept in mind as Dhe reader proceeds. First , in trying to @ resent an overview of my approach , I have had to forgo describing the detailed steps which I have followed to date. Second , even had I presented a full description , I would still have been short of providing sufficient details to enable computer implementation of any procedures. Third , Since the approach presumgs that cancepts represented by the lexicon are tne realizations of many as yet unknovin-rrecursive functions to be dl scovered by stripping away 8 one-layer at a t~me , results other than procedures to be used An stripplpg will not emerge untll all layers have been removed. ( However , I do wrae that the llstripplngm procedures are inherently useful , in that they will constitute a parser even in the intermea~ase stages. ) Fourth , since I have not ha @ access to a computer , which has become essentlalLfor significant further progress , I have been unable to determine how far the grocedures I have developed would take me , so there iLs an inherent uncertain-ty as to how much further development as needed. Notw~thstandlng these limitations , I am hopeful that what is prenented will provide a satisfactof.y framework for further iLnvestigations into the contents of dictlonarles. I will comment further on these limitahions and how they might be overcome at the end of the paper. 2 , ATTITUDB'3 TOWARD DICTION4RIE5 Many of +he siqnifxcant contributors to the present understandxng of rneanlng ( such as Xatz and Fodor 1963 , Plllmore 1968 and 7971 , CHafe 1970 , Jackendoff 1974 , wlnograd 1972 , and Schank 9972 ) have generally lgnored dictlonarles. Yet , each has presented a formulai~ structure for lexical entrhe5 to serve as a bas= for the creation of a rlew dictionary 4lthough their perceptions abouti the nature of language are well-established , thei ? formellsms for lexxcal entries have not taken advantage of the equally well-establ~shed praetlces of lexicography. The rationale underlslng the development of new fommalisms~ ex~rer~sed in some cases and ~m~llcrt t ; n others , ids that lexlcal 9 entries in dictionaries am unsatisfactory DeCAuse they do not contain sufficient infomation. These formali-sms thus require that semantic features such as 1lanirnateft or `` statew be appended* to particular ent*ies. While it is true that ordinary diotionary entries do not overtly identify all appropriate features</definiens>
				<definiens id="15">a ltwomanw which fs defined ad a tlpersonw ~hich is defined as a 1 '' beingfl '' which `` Ys defined as a `` living thingw ; this string seems sufficieht te estabaish `` nurseN as `` anirnatell. In general , it seems that , if a semantic feature is essential to the meaning ofa particular entry , it is similarly necessary % Hat the feature be discoverable within the semantic structure of a dictionary , Otherwise , there is a defect in one or more definitione , or the dictionarycontains some internal inconsistency. ( Clearly , it is beyond expectation that any pre~nt dictionary will be free of these problems. ) The possibility of defective definitions has also gene^-ated crf ticiams , more direct than above , on the potential usefulness Of a dictionary. On one Hand definitions are viewed as `` deficient in the presentation of relevant dataw since they provide meaninbv ueing `` substitutable words ( i.e. by synonyms ) , rather than by listing distinctive femtureafl ( Nida 1975 : 172 ) . On another hand- , the proliferation of meanings 10 attached to an entry is viewed as only a case of `` apparent polyeenyN which obscures the more general meaning of a lexeme by the addition of `` redundant features already determined by the environmentft ( Bennett 1975:4-1.1 ) . Both objections may have much validity and ts that extent would necessitate revisions to iqdividu &amp; or sets of definitions. However , neither viewpoint is sufficient ' to preclude an analysis of what actually appears in any dictionary. It is possible that a cbmprehensive analysis might more readily surface such difficulties and make their amelioration ( and the consequent improvement of definitions ) that mu &amp; easier , Xven though dictionaries are viewed somewhat askance by many who study meaning , it seems that this viewpdint is influenced more by the difficulty o* systematically tapping their contents than by my substantive objections which conclusively establish themas ~seless repositories of semantic content. However , it is necessary to demonstrate that a spstematic app~oach exists and can yield useful results. 3 , PREVIOUS RESXARCN ON DICTXONARIES Notwithstanaing the foregoing direct and indirect criticisms. some attempts have been made to probc the nature and &amp; structure of dictionary definitions. A review of relevant aspects QItwo such studus will help the niaterial presented here stand out in sharper relief. Olney 1968 describes the conceptual baais of many pro $ eetted routines for processing a machine-readable transcript of 11 Webster ' s Seveqth New Collq &amp; ate Dictionary ( ~7 ) . The primary objectives of these routines were the development of `` ( a ) rules for obtaining c-ertain of the senses described for W7 entries from other senses described for the same entries or from senses described for other W7 entries from which the first ( at least in typical cases ) were derived morphologically ; and ( b ) semantic wmponents and rules for combining them to yield specifications of senses that can not conveniently be obtained br rules refer~ed to in ( a ) above. '' ( ibid. : 6 ) Although these objectives me reasonable , they do not take advantage of the possibility that the semantic structure of a dlictionary might be a unlfied whole. As a\ result , an8 routines that are developed seem to require the serendipitous perception of patterns. Further , i0 a dictionary does have a unified semantle stpucture , it is not clear that a rule relating meaning to form wil-1 be relevant toga model ' of the semantic structure even though interesting results might emerge. It seems n-cessary to have some comprehensive view that will permit un to kaW whether a particular rule is well-formed. This lack of objective criteria also im~erils any anaIysisthat selects a subset of definrrions for detailed analysis. The selection of a subset of the dictionary shoulcl. arise from wll-defined a priori considerations mmer than an intuition that a particular 12 wbset seems to be related , An example of this intuitive agproach appears ~JI Simmons 1975 and 1976. rn Quillian 1968 , the analysis of dictionary definitions was part of a study of semantic memory , and for that reason was noP concerned with the full development of a dictionary model. In that study , a person determined the mesning of a concept when he `` looked up the 'patriarch1 ward in a dictionary , then looked up every word in each of its definitions , then looked up every word f6hnd-in each of those , and so on , continually branching outward until every word he could reach by this process had been Looked up once. '' This process was never actually carried out because ( 1 ) not all words in a dictionary were used in the computer files , ( 2 ) the process was terminated when a common word was found in comparing the meanings of two words , and ( 3 ) there was a bellef that there are no primitive ward concepts. The termination of a search 3x designed was necessary in any event since , without my restrictions , it is likely that a large part of the dhztionary would have been reached on every occasion , More importantly , Quillian did not fully consider wHat was happening when branching led to a word already encountered , namely , that a definitional circularity was thereby uncovere6 Such circularities which mi-ght be vicious cir-cles</definiens>
				<definiens id="16">Quill ian also overlooked the. possibility that a concept common to two qatriarchs is more primitive than either. The continued comparison of more and more primitive concepts , along with restricti~ns on the outward branching , implies that primitiive concepts actually do Based on these observations , I take , as a working hypothesis , the assumption that a dictionary may be a unified whole with underlying primitive conce~ts. ' With thin beginning , it is necessary to articulate a mod &amp; of the dictionary which will permit an identifiqatian of the primitive concepts through the application of well-defiaea rules or procedures. It is proposed that what follows constitutes the first steps toward meeting this objective</definiens>
				<definiens id="17">necessary to delineate exactly what is to be modeled- ? For thi~s purpose , it is assumed that the semantic content of a dictionary essentially resides within its defi.nitions , thereby excluding from formal analysis such things as the pronunciation , the etymol~gy , and illwtrative examples. s presently concelvea , the analysis will focus on the ward belng defined ( hereafter called Ehe main entry ) , the definitions ( including sense numbers and letters used as delimiters ) , part-of-speech I No dictianary is likely ta satisfy thls assumption , which is only a theoretically desirable characteristic. The assumption enables us to exclude the definienda from the models , 2 In the interests of space , I have glossed over B large number of intricacies that would have to be dealt with in arriving at a machine-readable hnscript suitable for analysis. Several pages would be reqyired to describe them fully. labels , status or usage labels , and usage notes. The manner in which these features will be employed will be made clear as the analysis proceeds. The hypothesized unified nature of a dictionary arises from the fact that definitions are expressed by werds which are 3 4180 defined ( i. , there is no semantic metalangua~e ) . If we wish to understand the meaning of a given definition</definiens>
				<definiens id="18">a main entry , then , in order to understand the meaning of the given definition , we mus % understand the meaning of the constituent wards1 definitions , Continued repetition of the process is nothing more than , the outward branching process described by Quillian ; however , as mentioned before , we must make this branching more disciplined in order to deal with vicious circles and avoid unwanted circularities , If we are to have a fully consistent dictiona~y , its model must show how each definition is related to all others. Thus , for each definition , X , the model should enable to identify ( 1 ) those definitions of the constituent wordr of X that apply and those that do not apply , and ( 2 ) the production rules that generated X from these definitions. For exampl , e , in the definition of tqe noun broadcast , `` the act of spreading abroadu , 4 it There are some exceptions to this assertion , such as groper names , . biological caxa , and other special symbols , a s pointed out by the Journal 's referee. 15 is necessary that the model indicate ( 1 ) which of the definitions of -- the , act , of , spread , and abroad apply , and ( 2 ) the production rules by which the and ___I_ act and all other collocations ) occur together. If this can be done for each definition in the dict~onary , and if any inconsistencies are reconciled , then , as will be shown , it should be possible to find the primitive concepts in the dictionary and to transform each definition mto a canonical f Drm. 5 , BJSIC MODEL The theory of ( labeled ) directed graphs ( digraphs ) 5 is used as the formalism for the modds. Digraph 'theory deals wj th the abstract notions of lfpointsff and `` directed linest1 ; its applicability to the problem before us therefore depends on how these notions</definiens>
				<definiens id="19">important to distinguish tpe manner in which this theory is used here from the manner in which it previously has been used in semantics and linguistics. The two most common uses are ( 1 ) where trees display phrase and syntactic structures ( cf. Kate and Fodor 1963 ) , or ( 2 ) where directed graphs portray the seguena tial generation of words in a se~tence or phrase lcf. Simmons 1972 ) . In these cases and others ( cf. Quillian 1968 and Bennett 1975 ) graphs are used primarily as a vehicle for display All definitmns ueed in this paver are taken from Websterts . Third New International ~iction &amp; ry , Eficyclopaed~a Britannica , Chicago , 1965. Terminolqy for digraphs follows Rarary 1965. 16 and no results from graph theorv are expPicitly employed to d &gt; aw further inferences</definiens>
			</definition>
			<definition id="1">
				<sentence>My examination of verb defintions containing prepositions haa led to the observation of many noticeable word patterns , i.e. collocations , which appear to be uaful xh the recognition ~f cases .</sentence>
				<definiendum id="0">i.e. collocations</definiendum>
				<definiens id="0">the observation of many noticeable word patterns</definiens>
			</definition>
			<definition id="2">
				<sentence>Essentially , the assertion that a word or definition is non-prim~tive requires a showlng that it is derived from a more primitive concept and that a primitive cannut be derived from 58 34 it .</sentence>
				<definiendum id="0">non-prim~tive</definiendum>
				<definiens id="0">requires a showlng that it is derived from a more primitive concept and that a primitive cannut be derived from 58 34 it</definiens>
			</definition>
			<definition id="3">
				<sentence>The Drafting Grow of the Organization of Economic Cooperation G Development ( OECD ) met December 6-8 in Paris to consider a new draft of ~ransborder Data Flow Guidelines prepared by Peter Seipel , consultant to the OECD Secretariat ( WashCngton Report , January , 1979 , p. 1 ) .</sentence>
				<definiendum id="0">Drafting Grow</definiendum>
				<definiens id="0">of the Organization of Economic Cooperation G Development ( OECD ) met December 6-8 in Paris to consider a new draft of ~ransborder Data Flow Guidelines prepared by Peter Seipel , consultant to the OECD Secretariat ( WashCngton Report , January , 1979 , p. 1 )</definiens>
			</definition>
			<definition id="4">
				<sentence>In December , the Postal Service Buard of Governors authorized temporary implementation of E-COM service , an electronic message service ( EMS ) for large-volume users ( see Washington Report , 11/78 , -p. 3 ) ; in November , Postmaster General William F. Bolger approved a four hllion dollar electronic mail experiment beginning this year ; also in November , Xerox COT .</sentence>
				<definiendum id="0">EMS</definiendum>
				<definiens id="0">the Postal Service Buard of Governors authorized temporary implementation of E-COM service , an electronic message service</definiens>
			</definition>
			<definition id="5">
				<sentence>The General Accounting Office ( GAO ) is preparing to release a new study entitled Security of Automated Information Systems of Federa2 Agencies ; according to ia tentative outline of the GAO report , obtained by the AFIPS Washington Off ice , I1organizatiwnal structures1\ are I1inadequatelt and lfcomprehensive procedures '' are nonexistent in current Federal security precautions .</sentence>
				<definiendum id="0">General Accounting Office</definiendum>
				<definiens id="0">preparing to release a new study entitled Security of Automated Information Systems of Federa2 Agencies ; according to ia tentative outline of the GAO report , obtained by the AFIPS Washington Off ice</definiens>
			</definition>
			<definition id="6">
				<sentence>The Supreme Court is eonsidering whether , under the Freedom of '' Infomation Act , individuals `` can obtain confidential business data ; in November , the High Court let stand a U.S. Court of Appeals decision ( Washington Report , 6/78 , p. 4 ) allowing MCI Communications Corp. to use AT6T1 s local phone conn'ection to impleme , nt Execunet , hlCI1 s long distance telephone service providing voice and data communications .</sentence>
				<definiendum id="0">Supreme Court</definiendum>
			</definition>
			<definition id="7">
				<sentence>Requests should specify the da &lt; e ( s ) of the Report in which the document ( s ) appeared. Where price is noted , make checks paybble to `` AFIPS .I ' A Alexander D Roth D~reclor Wash~nglon Ofl~ce Pender M McCarter Ed~tor d ! Washington Report rnerlcan Federalon of Inlormat~on Process~ng Soc~el~es Inc Wash~nglon Ofllce 1815 North Lynn Street Sude Bna~rl~ngton Vlrglnla 22209 703 243 3000 Vol. V , No. 3 March , 1979 WASHINGTON DEVELOPMENTS PRESIDENT , CONGRESS ADDPESS INFORMATION POLICY ISSUES Amidst predict ions thatthe 96th Congress is concentrating on oversight of existing Government programs , there is no dearth of information policy-related legislation on the Congressional Calendar , sustaining the momentum of the 95th Congress which enacted 74 new laws affecting U. S. informat ion pol icy. [ ~ditor ? s Note : A House of Represent at ives committee Print describing these laws is available on request to the MIPS Washington Off ice. ] Privacy Legislation. Much of the information policy-related legislation ceoters on privacy issues. President Carter referred to planned privacy legislation affecting Government access to records in the medical and financial sectors ( see Washington Report , 12/78 , p. 1 ) in his Supplemental State of the Union Address delivered to the Congress on January 25th. Under the heading of `` Civil Liberties : Privacy , the President said : Government and privateinstitutions collect increasingly large amounts of personal data and use them to make many crucial decisions about indfviduals. Much of this 'information is needed to enforce laws , deliver benefits , provide credit , and conduct similar , important services. ~bwever , these interests must be balanced against the individuals right to privacy and against the harm that unfair uses of infarmation can cause. Individuals shoul 'd be able to know what information organizations collect and maintain about them ; they should be able to correct inaccbrate records ; and there should be limits on the disclosure of particularly sensitive personal information. IN THIS ISSUE PRESIDENT , CONGRESS ADDRESS INFORMATION POLICY ISSUES . . . . . . . . 1 AFIPS IN WASHINGTON t CIVIL SERVICE SHOULD REVISE PROPOSED STANDARDS FOR COMPUTER-RELATED OCCUPATIONS . . . . . . 5 CONSUMER LIABILITY COULD BE LIMITED TO $ 500 IN EFT. . . . . . . . 6 NEWS BRIEFS . . . . . . . . . . , . . . . . . . . . . . . . . , . . . 81 I 85 ? Mr. Carter concluded defining planned administrative measures implementing privacy protections ( see Washinqton Report , ,2/79 , p. 2 ) , as fol lows : My Administration is develaping a comprehensive privacy policy to address these concerns. Last year , legislation was enacted which established restrictions on . . . Government access to financial records. Early in 1979 ; I will propose privacy legislation to cover medical , financial , and other sensitive personal records. I will also take administrative actions to strengthen privacy controls for Federal agencies ' records. NTIA Proposals. The National Telecommunications E Informat ion Administration ( NTIA ) is said to be preparing legislation for introduction this month ( in March ) , implementing what is being ' called the President s Privacy Initiative. A principle underlying the legislation , according to an NTIA staff member , is that information collected for research ancl statistical purposes `` should not be used [ by Government ] to make decisions about people. HEW Bill. The Department of ilealth , Education d Welfare ( HEW ) is also reported to be drafting legislation on Government access to medical records. Rep : Richardson Preyer ( D-N. C . ) , chairman of the House Subcommit tee on ~overnment Information E ~ndividual Rights , has previohsly expressed interest in considering privacy measures concerningmedical recoids ( see Washington Report , 2/79 , p. 2 ) . Goldwater Legislation. On January 18th Rep. Barry M. Goldwater , Jr. ( R-Calif . ) reintroduced privacy legislation imp1 ement ing recommendat ions of the Privacy Protection Study Commission ( Washingto~z Report , 8/ 77 , p. l ) , including a bill to amend the Fair Credit Reporting Act. Mr. Goldwater 's legislation is listed as follows : H.R. 344. A blll to amend the Fair Credit Reporting Act dealing with depository institutions and privacy , and for other purposep ; to the Committee on Banking , Finance E Urban Affairs. H. R , 345. A bill to amend the Fair Credit Reporting Act dealing with consumer &amp; edit and privacy ; to the Committee on Banking , Finance 6 Urban Affairs. H.R. 346. A bill to amend the Fair Cr.ed &lt; t Reporting Act dealing with hGrance institutions and privacy ; to the Committee on Banking , Finance ti Urban Affairs. H. R. 347. A bill to amend the FdZy Educati~naZ Rights and Privacy Act to provide for the protection of the privacy of personal information , and for other purposes ; to the Committee on Education E Labor. H.R , 349. A bill to amend the Privacy Actof 1974 ; to the Committee on Government Operations. H.R. 350 , A bill to establish a Federal Information Practices Board to review and report on fair information and privacy practices of Governmental and nnngovernment a1 entities ; to the Commit tee on Government Operat ions. MARCH , 1979 2 AF I PSe WSH INGTON REPORT H. R. 354. 4 bill to amend the Intern2 Revenue Code of I058 dealing with privacy ; to-the Committee on Ways t ; Means. H.R. 358. A bill to restrkt the use of SociaZ Secukty Act account numbers as Governmental or universal personal identifiers ; to the Comrnittee'on Ways 6 Means. Ha R. 359. Arbill to provide for the privacy of certain public assistance and social service records used or maintained , by state and private agencies under programs receiving Federal financial assistance ; jointly , to the Committees on Agriculture , Inters-te G Foreign Commerce , and Ways 8 Means. P H. R. 360. A bill to amend Title XI of .the Sock2 SeewYity Act to provide for the confidentiality of personal medical information createa or maintained -by medtcal care institutions providing service : under the Medicare or Medicaid firo'grams , and for bther purposes ; jointly , to the Committees on Interstate E Foreign Commerce , and Ways G Means. H.R. 362. A bill to amend the Social Secuf.ity Act to provide for the protection of the privacy of personal medical information maintained by certain medical care iastitutions ; jointly , to the Committees on Ways 6 Means , and Interstate 8 Foreigr Commerce. The Californi'a Congressnpn has been quoted as saying that Congress must legislate in the privacy area whenevef private enterprise fails to act. Golduater has served as a member , of the Privacy Protect ion Study Commissioh Chances fox Passage of Privacy Legislation. Chances for , passage of privacy legislation are unpredictable given the customary , formidable Congressional procedures as well as p~eoccupation with fareign relations and the domestic economy. Among the scores of privacy-related bills introduced in the 95th Congress , only the R.ight to Financia2 Prhacy Act ( see washington Report , 12/78 , p. 1 ) passed in ' the early morning hours of the last day &amp; of Congress. A bemused Cartter offi~ial recently goted that a bill affecting Government access tq medical records may originate in as many as four different Congressional subcommittees. Similarly , one Cmgressional staffer stated that information policy is 'lmade in / disparate environments. Harry M. ( Chip ) Shooshan $ 11 , chief counsel , House , Communications Subcomibree , tbld e January meeting of the American Library AsSociation that this disparity results in vvcogptrary policies. l1 [ At lemt some Cbhgressmen are reconsidering support for one section of the Right to FinrmoiaZ PrYivaqj Act following a Citibank survey which estimates that compliance withP the bils 's notice requireqents by financial insdltutions cou , ld cost as mcn as one billion dollars , reoalling pimilay high ( and , according to some privacy advocates , ultimately incorrect ) estimates of costs to implement the Privacy Act of 1974. Sen. William Proxmire ( D-Wisc. ) , for example , has introduced S. 37 repead ing Section 1104 [ dI of the Act which statos that , `` All fi A ancial instautions shall prolnptly notifx all of , their customers of tleir rights under this ~tle. '' A similar bill , ,II.R. 1777 , has been introduced in the House , in~erting I1activef1 after `` notify all of theirml ' s.37 passed the Senate last month. ] MARCH , 1979 &amp; IPS WASHINGTON REPURT Additional Informaticn. Policy-Related Legislation. OtheY legislation 86 introduced this year in the informrition policy area includes , at press t-ime i Communications Actt Rewrite* A new bill ils scheduled to be introduced the fivst of this month ( in March ) with the `` basic philosophyw intkt. [ Editor 's Note : At least one bill is being cons'idered , H.R. 2580 , that would `` reaffirm the authority of the states to regulate terminal and station equipment used for telephone exchange. service ili certain instancps . . . , recalling the Conswner Comnun3cations Refom Act , also known in the 95th Congress as the `` Bell Bill J1l Federal Computer Systems Prdtection Act . ' Reintroduced January 25th by Sen. Abraham A. Ribicoff ( D-Conn. ) , S. 840 ( # ) provides for a stri-cter financial penalty for compuber crime than the previous '' vprsjcm , stipulating that a fine could amount to as much as two and one-mew .bimes that of the theft. Ih short , the bill would make it a Federal crime to access a computer for fraudulent purposes such as theft , sabotage or embezzlement. EFT Legislation. Introdbced January 23rd as S , 108 ( # ) and H. R. 2289 ( # ) , the Truth ln Und5ng Simplification and Reform Act provjdes that all of the provisions of the EFT Act ( see ~asJ % ngton &amp; po '' rt , 12/78 , p. 1 ) would become effective thj s June instead of May , 1980 , as provided in the EFT Act. support ; rs in the House and Senate are pred &amp; cting early passage with the President 's approval expected in `` late Spring. `` In addit ion , n. R. 852 would implemwt additional EFT ~ivacy legislation. Electronic Mail. In his Supplementary State of the Union Message , Presidenx Carter alfluded to Itproposals on the role of the Postal Service in providing electronic &amp; .I. services. I ' The House Commit tee on Post Off ice 6 Civil Setvice is planning hearings on electronic mil , though not in connection with any legislat-ion , according to Michael F. Cavanagh. , staff assistant , House Subcommittee on Postal Personnel Modernization. Copyright Protection H.R. 1007 would amend the Copyriqht Act of 1976 to provide copyright protection for imprinted deslgn patterns on semiconductor chips. Unsolicited Comneweial Telephone Calls. H. R. 377 woula amend the Commmicat $ ons Act of 1934 to 'prohibit making unsolicited commercial telephone calls to persons who have indicated they do not'wish to receive such ca 11 s . `` NSF Science Education Functions. S. 210 , a bill to establish a separate Department of Education , would transfer to the new secretary of l ; h proposed department programs relating to science education. of the NSF or the d % ector of the NSF. '' The legrslation would exempt such/functions and programs as those dating to `` ethical , value , and sciehce policy issuesw or wcommunicating science ihformation to n~nscientists. ff MARCH , 1979 RFIPS WASHINGTON REPORT Oversight Hearings. Consistent with the observation that the 96th 87 Congress is concentrating on oversight of existing Government programs , budget hearings on the NTIA , the Office of Science E Technology Policy , the National Bureau of Standards , and the Off lce of Technology Assessment have been scheduled through this month. tContentiousl Session. Overall , a 'lcontentiousll session is predicted for the 96th Congress. Majority leader James C. Wright ( D-Tex. ) has been quoted as saying , the kresldent T1still has n't learned to consui t [ with ] Congressional 1 eaders . `` Primary emphasis is expected to be on the budget and related legislation. [ Editor 's Note : DP aspects of the Fiscal Year 1980 budget will be anavzed m next month ' s AFlPS Wash.ington Report. ] AFIPS IN WASHINGTON Standards Do Not Cover Recent Developments In Information ~rocessing , AFIPS Panel Says CIVIL SERVICESHOULD REVISE PROPOSED STANDARDS FOR COMPUTERRELATED OCCUPAT IONS Pro osed Civil Service standards ( # ) affecting Government recruitment of Y emp oyees In computer-xelated occupations , f ~rst announced In 1978. are already several years out of date and should be rev~sed , according to comments ( # ) released last month by an AFlPS panel. h AFIPS PANEL MEMBERS JOHN HAMBLEN ( L ) , EDMUND SAWYER ( R ) MARCH , 1979 AF IPS WASHINGTON REPORT ~bcent Dtyrelopnents in Information Processing. According t b the AFIPS 88 pant $ , the pro'posed standards 40 not cover such recent developments in the information processing field as the creation of distributive networks , advances in felecomunzcations the use of 'igtelligent terminals the widespread application of minicomputers and microcomputers , and the existence 0 % online numerio and bibliograahic data bases. Panel Recommendations. TIPe AFIPS panel recommended that the OPM ( 1 ) consult with outside sources to upflafe computer occupatidn standards ; ( 2 ) revise classif icatioa ~tandards $ 05 computer-related occupations at least every five years until at least 1999 ; and ( 3 ) insure that the proposed standards conform with [ existingT Civil Service law and regulations. The group notes the pervasiveness of cornput &amp; technology in Government , the interaction of citizens with computers empioyed by the U. S. in various programs , and tAe need for highly skilled and motivated personnel to e~ploit the technology. Panel Organization. The AFIPS Civil Service Standards Review Panel was formed 1 % response to a special invitation by the U.S. Civil Service Commission , now the office of Personnel Management ( OPM ) , to comment on tentaf ive standards for , the Computer Spcialist Series ( GS-334 ) and. the Computer Clerk and Assistant serfeg ( GS-335 ) . me Federal government empleys ' sthdards to 'clasMfy employees in payJlevels according to difficulty , remonsibility , and qualif icatiens required for the wo~k . The panel reflects a variety of backgrounds including curricu , lar work In computer science , analysis of computer occupations for personpel purposes , and computer usage. Comments reflect the views of the panel members , not necessar , ily those of AFIPS , the Federation 's constituent societies , or the emphyers of the individuals involved. Panel Members. Members of the panel were : Dr. Frances Berger , Psychometrics Los Angeles ; Dr. ' Karen Duncan , Mitre Corp. , McLean , Va. ; Dr. John 1-Iamblen , University of Missouri-Iioqla ; Charles D. LaBelle , Manufacturers Hanover Trust CB. , New York ; Will*iam P. LaPlant , J. US. Air Force , ~rlington , Va. ; Alexander D. Roth , Esq. , AFIPS , Arlington , Va. ; Dr. Terry Sttaeter. NASA , Hampton , Vg. ; Edmund Sawyer , U.S. Genepal Accounting Office , Washington , D. C. ; and Sidney Welnstein , Association for Computing Mach~nery , New York . New Draft. OPM 1s expected to issue another draft of its proposed standards incorporating comments from groups such as AFI PS. AFIPS Subcommittee Presents Comments to Fed on ' EFT Acti CONSUMER LIABILITY COULD BEp LIMITED TO $ 5001-N ALL EFT TRANSACTIONS Proposed regulations ( # I of the Board of Governors of the Federal -Reserve System ( FRS ) may misconstrue 'the EZe *tronir Funde Transfer ( EFT ) Act [ # ) I to povide unlimited cop6umer liabi ity in cases of unauthor~zed EFT transfer , according to comments ( # ) reIeased last month by an AFIPS EFT Subcommittee. Passed by Congress last year , two sect ions of the EFT Act pertaining to liability became effective February 8th The Subcommittee ~ommmats reflect the views of the panel mpmbe-rs and not necessarily those of AFIPS , the liederation 's constituent societies , the AFIPS Washington Off ice , or the employers of the participants. AFIPS WASHINGTON REPORT Unlimited Liability Que~t~ioned. According to two AFIPS Subcommittee members , a ' '' thorough readingf1 of the law `` gives theimpression that consumer liability in 9 case is limited to $ 500.00.1f The ~oard interpretation* contained in regulations published last December in the Federa2 Register , states , `` If the consumer fails to report within 60 days of : Transmittal of the periodic statement any unauthorized electronic fund transfer which appears on th~ statement , the consumer may be liable fop the amount of any unauthorized transfer whlch , the financial institution estabAishes would not have occurred but for the failure of the cmsumer to notify the financial institution. '' Subconunittee Recommendat ions. Citing `` adverse economic consequences of unauthorized use , '' a Subcommittee majority recommended that a demand deposit account snould be established for the lfexpress , purposeu of EFT. The-majority also held that the provisions of the regulations interpreting the consumer 's liability section of the EFT Act should require actual. notice to the consumer before any debiting in excess of $ 500.00 According to the AFIPS Subcommittee majority , llEvolving constitutional doctrines affecting prehearing remedies for creditors suggest that in . . . [ extreme cases ] there may be a constitutional requirement of prehearing notice and an opportunity for a hearing to contest the proposed debiting before such a taking1 may be effected. lf 'Finally , the Subcommittee recommended that the issuance of llaccess devicesf1 which serve as combined debit or credit cards shoug be prohibited , recognizing the increased risk of technical failure in the transaction terminal , Subcommittee Members. The Ad Hoc Subcommittee consists of four members chosen by the chairman of the AFIPS Special Committee on EFTS. William enw wick , Esq. , of Davis , Staf ford , ~Alrnalr 6 enw wick , &gt; palo ~lio , Calif .</sentence>
				<definiendum id="0">CONGRESS ADDPESS INFORMATION POLICY ISSUES Amidst predict</definiendum>
				<definiendum id="1">My Administration</definiendum>
				<definiens id="0">s ) of the Report in which the document ( s ) appeared. Where price is noted</definiens>
				<definiens id="1">sustaining the momentum of the 95th Congress which enacted 74 new laws affecting U. S. informat ion pol icy. [ ~ditor ? s Note : A House of Represent at ives committee Print describing these laws is available on request to the MIPS Washington Off ice. ] Privacy Legislation. Much of the information policy-related legislation ceoters on privacy issues. President Carter referred to planned privacy legislation affecting Government access to records in the medical and financial sectors ( see Washington Report , 12/78 , p. 1 ) in his Supplemental State of the Union Address delivered to the Congress on January 25th. Under the heading of `` Civil Liberties : Privacy , the President said : Government and privateinstitutions collect increasingly large amounts of personal data and use them to make many crucial decisions about indfviduals. Much of this 'information is needed to enforce laws , deliver benefits , provide credit , and conduct similar , important services. ~bwever , these interests must be balanced against the individuals right to privacy and against the harm that unfair uses of infarmation can cause. Individuals shoul 'd be able to know what information organizations collect and maintain about them ; they should be able to correct inaccbrate records</definiens>
				<definiens id="2">develaping a comprehensive privacy policy to address these concerns. Last year , legislation was enacted which established restrictions on . . . Government access to financial records. Early in 1979 ; I will propose privacy legislation to cover medical , financial , and other sensitive personal records. I will also take administrative actions to strengthen privacy controls for Federal agencies ' records. NTIA Proposals. The National Telecommunications E Informat ion Administration ( NTIA ) is said to be preparing legislation for introduction this month ( in March ) , implementing what is being ' called the President s Privacy Initiative. A principle underlying the legislation , according to an NTIA staff member , is that information collected for research ancl statistical purposes `` should not be used [ by Government ] to make decisions about people. HEW Bill. The Department of ilealth , Education d Welfare ( HEW ) is also reported to be drafting legislation on Government access to medical records. Rep : Richardson Preyer ( D-N. C . ) , chairman of the House Subcommit tee on ~overnment Information E ~ndividual Rights , has previohsly expressed interest in considering privacy measures concerningmedical recoids ( see Washington Report , 2/79 , p. 2 ) . Goldwater Legislation. On January 18th Rep. Barry M. Goldwater , Jr. ( R-Calif . ) reintroduced privacy legislation imp1 ement ing recommendat ions of the Privacy Protection Study Commission ( Washingto~z Report , 8/ 77 , p. l ) , including a bill to amend the Fair Credit Reporting Act. Mr. Goldwater 's legislation is listed as follows : H.R. 344. A blll to amend the Fair Credit Reporting Act dealing with depository institutions and privacy , and for other purposep ; to the Committee on Banking , Finance E Urban Affairs. H. R , 345. A bill to amend the Fair Credit Reporting Act dealing with consumer &amp; edit and privacy ; to the Committee on Banking , Finance 6 Urban Affairs. H.R. 346. A bill to amend the Fair Cr.ed &lt; t Reporting Act dealing with hGrance institutions and privacy ; to the Committee on Banking , Finance ti Urban Affairs. H. R. 347. A bill to amend the FdZy Educati~naZ Rights and Privacy Act to provide for the protection of the privacy of personal information , and for other purposes ; to the Committee on Education E Labor. H.R , 349. A bill to amend the Privacy Actof 1974 ; to the Committee on Government Operations. H.R. 350 , A bill to establish a Federal Information Practices Board to review and report on fair information and privacy practices of Governmental and nnngovernment a1 entities ; to the Commit tee on Government Operat ions. MARCH , 1979 2 AF I PSe WSH INGTON REPORT H. R. 354. 4 bill to amend the Intern2 Revenue Code of I058 dealing with privacy ; to-the Committee on Ways t ; Means. H.R. 358. A bill to restrkt the use of SociaZ Secukty Act account numbers as Governmental or universal personal identifiers ; to the Comrnittee'on Ways 6 Means. Ha R. 359. Arbill to provide for the privacy of certain public assistance and social service records used or maintained , by state and private agencies under programs receiving Federal financial assistance ; jointly , to the Committees on Agriculture , Inters-te G Foreign Commerce , and Ways 8 Means. P H. R. 360. A bill to amend Title XI of .the Sock2 SeewYity Act to provide for the confidentiality of personal medical information createa or maintained -by medtcal care institutions providing service : under the Medicare or Medicaid firo'grams , and for bther purposes ; jointly , to the Committees on Interstate E Foreign Commerce , and Ways G Means. H.R. 362. A bill to amend the Social Secuf.ity Act to provide for the protection of the privacy of personal medical information maintained by certain medical care iastitutions</definiens>
				<definiens id="3">a member , of the Privacy Protect ion Study Commissioh Chances fox Passage of Privacy Legislation. Chances for , passage of privacy legislation are unpredictable given the customary , formidable Congressional procedures as well as p~eoccupation with fareign relations and the domestic economy. Among the scores of privacy-related bills introduced in the 95th Congress , only the R.ight to Financia2 Prhacy Act ( see washington Report , 12/78 , p. 1 ) passed in ' the early morning hours of the last day &amp; of Congress. A bemused Cartter offi~ial recently goted that a bill affecting Government access tq medical records may originate in as many as four different Congressional subcommittees. Similarly , one Cmgressional staffer stated that information policy is 'lmade in / disparate environments. Harry M. ( Chip ) Shooshan $ 11 , chief counsel , House , Communications Subcomibree , tbld e January meeting of the American Library AsSociation that this disparity results in vvcogptrary policies. l1 [ At lemt some Cbhgressmen are reconsidering support for one section of the Right to FinrmoiaZ PrYivaqj Act following a Citibank survey which estimates that compliance withP the bils 's notice requireqents by financial insdltutions cou , ld cost as mcn as one billion dollars , reoalling pimilay high ( and , according to some privacy advocates , ultimately incorrect ) estimates of costs to implement the Privacy Act of 1974. Sen. William Proxmire ( D-Wisc. ) , for example , has introduced S. 37 repead ing Section 1104 [ dI of the Act which statos that , `` All fi A ancial instautions shall prolnptly notifx all of , their customers of tleir rights under this ~tle. '' A similar bill , ,II.R. 1777 , has been introduced in the House , in~erting I1activef1 after `` notify all of theirml ' s.37 passed the Senate last month. ] MARCH , 1979 &amp; IPS WASHINGTON REPURT Additional Informaticn. Policy-Related Legislation. OtheY legislation 86 introduced this year in the informrition policy area includes , at press t-ime i Communications Actt Rewrite* A new bill ils scheduled to be introduced the fivst of this month ( in March ) with the `` basic philosophyw intkt. [ Editor 's Note : At least one bill is being cons'idered , H.R. 2580 , that would `` reaffirm the authority of the states to regulate terminal and station equipment used for telephone exchange. service ili certain instancps . . . , recalling the Conswner Comnun3cations Refom Act , also known in the 95th Congress as the `` Bell Bill J1l Federal Computer Systems Prdtection Act</definiens>
				<definiens id="4">become effective thj s June instead of May , 1980 , as provided in the EFT Act. support ; rs in the House and Senate are pred &amp; cting early passage with the President 's approval expected in `` late Spring. `` In addit ion , n. R. 852 would implemwt additional EFT ~ivacy legislation. Electronic Mail. In his Supplementary State of the Union Message , Presidenx Carter alfluded to Itproposals on the role of the Postal Service in providing electronic &amp; .I. services. I ' The House Commit tee on Post Off ice 6 Civil Setvice is planning hearings on electronic mil , though not in connection with any legislat-ion , according to Michael F. Cavanagh. , staff assistant , House Subcommittee on Postal Personnel Modernization. Copyright Protection H.R. 1007 would amend the Copyriqht Act of 1976 to provide copyright protection for imprinted deslgn patterns on semiconductor chips. Unsolicited Comneweial Telephone Calls. H. R. 377 woula amend the Commmicat $ ons Act of 1934 to 'prohibit making unsolicited commercial telephone calls to persons who have indicated they do not'wish to receive such ca 11 s . `` NSF Science Education Functions. S. 210 , a bill to establish a separate Department of Education , would transfer to the new secretary of l ; h proposed department programs relating to science education. of the NSF or the d % ector of the NSF. '' The legrslation would exempt such/functions and programs as those dating to `` ethical , value , and sciehce policy issuesw or wcommunicating science ihformation to n~nscientists. ff MARCH , 1979 RFIPS WASHINGTON REPORT Oversight Hearings. Consistent with the observation that the 96th 87 Congress is concentrating on oversight of existing Government programs , budget hearings on the NTIA , the Office of Science E Technology Policy , the National Bureau of Standards , and the Off lce of Technology Assessment have been scheduled through this month. tContentiousl Session. Overall , a 'lcontentiousll session is predicted for the 96th Congress. Majority leader James C. Wright ( D-Tex. ) has been quoted as saying , the kresldent T1still has n't learned to consui t [ with ] Congressional 1 eaders . `` Primary emphasis is expected to be on the budget and related legislation. [ Editor 's Note : DP aspects of the Fiscal Year 1980 budget will be anavzed m next month ' s AFlPS Wash.ington Report. ] AFIPS IN WASHINGTON Standards Do Not Cover Recent Developments In Information ~rocessing , AFIPS Panel Says CIVIL SERVICESHOULD REVISE PROPOSED STANDARDS FOR COMPUTERRELATED OCCUPAT IONS Pro osed Civil Service standards ( # ) affecting Government recruitment of Y emp oyees In computer-xelated occupations , f ~rst announced In 1978. are already several years out of date and should be rev~sed , according to comments ( # ) released last month by an AFlPS panel. h AFIPS PANEL MEMBERS JOHN HAMBLEN ( L ) , EDMUND SAWYER ( R ) MARCH , 1979 AF IPS WASHINGTON REPORT ~bcent Dtyrelopnents in Information Processing. According t b the AFIPS 88 pant $ , the pro'posed standards 40 not cover such recent developments in the information processing field as the creation of distributive networks , advances in felecomunzcations the use of 'igtelligent terminals the widespread application of minicomputers and microcomputers , and the existence 0 % online numerio and bibliograahic data bases. Panel Recommendations. TIPe AFIPS panel recommended that the OPM ( 1 ) consult with outside sources to upflafe computer occupatidn standards</definiens>
				<definiens id="5">insure that the proposed standards conform with [ existingT Civil Service law and regulations. The group notes the pervasiveness of cornput &amp; technology in Government , the interaction of citizens with computers empioyed by the U. S. in various programs , and tAe need for highly skilled and motivated personnel to e~ploit the technology. Panel Organization. The AFIPS Civil Service Standards Review Panel was formed 1 % response to a special invitation by the U.S. Civil Service Commission , now the office of Personnel Management ( OPM ) , to comment on tentaf ive standards for , the Computer Spcialist Series ( GS-334 ) and. the Computer Clerk and Assistant serfeg ( GS-335 ) . me Federal government empleys ' sthdards to 'clasMfy employees in payJlevels according to difficulty , remonsibility , and qualif icatiens required for the wo~k . The panel reflects a variety of backgrounds including curricu , lar work In computer science , analysis of computer occupations for personpel purposes , and computer usage. Comments reflect the views of the panel members , not necessar , ily those of AFIPS , the Federation 's constituent societies , or the emphyers of the individuals involved. Panel Members. Members of the panel were : Dr. Frances Berger , Psychometrics Los Angeles</definiens>
				<definiens id="6"># I of the Board of Governors of the Federal -Reserve System ( FRS ) may misconstrue 'the EZe *tronir Funde Transfer ( EFT ) Act [ # ) I to povide unlimited cop6umer liabi ity in cases of unauthor~zed EFT transfer , according to comments ( # ) reIeased last month by an AFIPS EFT Subcommittee. Passed by Congress last year , two sect ions of the EFT Act pertaining to liability became effective February 8th The Subcommittee ~ommmats reflect the views of the panel mpmbe-rs and not necessarily those of AFIPS , the liederation 's constituent societies , the AFIPS Washington Off ice , or the employers of the participants. AFIPS WASHINGTON REPORT Unlimited Liability Que~t~ioned. According to two AFIPS Subcommittee members , a ' '' thorough readingf1 of the law `` gives theimpression that consumer liability in 9 case is limited to $ 500.00.1f The ~oard interpretation* contained in regulations published last December in the Federa2 Register , states , `` If the consumer fails to report within 60 days of : Transmittal of the periodic statement any unauthorized electronic fund transfer which appears on th~ statement , the consumer may be liable fop the amount of any unauthorized transfer whlch , the financial institution estabAishes would not have occurred but for the failure of the cmsumer to notify the financial institution. '' Subconunittee Recommendat ions. Citing `` adverse economic consequences of unauthorized use , '' a Subcommittee majority recommended that a demand deposit account snould be established for the lfexpress , purposeu of EFT. The-majority also held that the provisions of the regulations interpreting the consumer 's liability section of the EFT Act should require actual. notice to the consumer before any debiting in excess of $ 500.00 According to the AFIPS Subcommittee majority</definiens>
				<definiens id="7">the Subcommittee recommended that the issuance of llaccess devicesf1 which serve as combined debit or credit cards shoug be prohibited , recognizing the increased risk of technical failure in the transaction terminal , Subcommittee Members. The Ad Hoc Subcommittee consists of four members chosen by the chairman of the AFIPS Special Committee on EFTS. William enw wick</definiens>
			</definition>
			<definition id="8">
				<sentence>APRIL , 1979 AFIPS WASHINGTON REPORT In February , the National Association of Wade E Technical Schools filed suit to contest the Federql Trade Commissionvs ( FTC ) rules ( gee Washington Reparts 3/79 , p. 8 ) which will give a prc mats refund to students who drop out of vocational schools ; the association contends the FTC has used out dfited information in formulating the rules which become effective next year .</sentence>
				<definiendum id="0">Trade Commissionvs</definiendum>
				<definiens id="0">the National Association of Wade E Technical Schools filed suit to contest the Federql</definiens>
			</definition>
			<definition id="9">
				<sentence>Schank , R.C. Conceptual dependency : A theory of ' natural bnguage understanding .</sentence>
				<definiendum id="0">Schank , R.C. Conceptual dependency</definiendum>
				<definiens id="0">A theory of ' natural bnguage understanding</definiens>
			</definition>
</paper>

		<paper id="1036">
			<definition id="0">
				<sentence>% bje CJ ' ( i ) The noun-object focus the set of tokens of a noun meaning representation~ of the focus of S ( where S is the bentence currently .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">the bentence currently</definiens>
			</definition>
			<definition id="1">
				<sentence>being processed ) ( ii ) The event focus -a set aontaining , for every sentence W in the focus of S , the object EVENT ( F ) , where F is the meaninq representation of W , and EVENT is a function which maps the meaning of a formula , F , into a noun-like object whose meaning is `` the event ( or fact ) that F '' ( iii ) The time focus a set containing taken8 for all time references ( e. g , yesterday , five olclock , etc. ) occurring in the meaninq representation of the focus of S. The reader may question our inclusion of every object appearing in the meaning xepresentation of the focus of S in one of the above focus sets , i. e. in the set of potential referents .</sentence>
				<definiendum id="0">object EVENT</definiendum>
				<definiendum id="1">F</definiendum>
				<definiendum id="2">EVENT</definiendum>
				<definiens id="0">the meaninq representation of W , and</definiens>
				<definiens id="1">a function which maps the meaning of a formula , F , into a noun-like object whose meaning is `` the event</definiens>
				<definiens id="2">all time references ( e. g , yesterday , five olclock , etc. ) occurring in the meaninq representation of the focus of S. The reader may question our inclusion of every object appearing in the meaning xepresentation of the focus of S in one of the above focus sets , i. e. in the set of potential referents</definiens>
			</definition>
			<definition id="2">
				<sentence>A set , H , is formed containing all tuples of t &amp; e form ( N1 , N2 , P ) such 'that N1 is a nominal item occurring in ( the meaning representation of S , Nz is an object occurring in the focus set ( noun-object , event , or time ) appropriate to N1 , and is a member of R ; H is the set of all current refewnce hypotheses arising-from S. III .</sentence>
				<definiendum id="0">Nz</definiendum>
				<definiendum id="1">H</definiendum>
				<definiens id="0">a nominal item occurring in ( the meaning representation of S</definiens>
				<definiens id="1">an object occurring in the focus set ( noun-object , event , or time ) appropriate to N1 , and is a member of R</definiens>
			</definition>
			<definition id="3">
				<sentence>The brackethg in the notation [ A ] , where A is a pointer to a definition , is meant to be a function which takes A into an object whose meaning ie the class of items satisfying the meaning pointed to by A. Once the translation of the first sentence of sequence 1 into its meaning representation has been completed on the assumption that that sentence is at the beginning of the text being processed the various focus sem will contain the followkg : no.object focus : [ xl , xz ) ; event fbcps. : [ ( cfic21\~/\chcd\~~ ) 3 ; time focus [ YESTERDAY ] .</sentence>
				<definiendum id="0">event fbcps.</definiendum>
				<definiens id="0">meant to be a function which takes A into an object whose meaning ie the class of items satisfying the meaning pointed to by A. Once the translation of the first sentence of sequence 1 into its meaning representation has been completed on the assumption that that sentence is at the beginning of the text being processed the various focus sem will contain the followkg : no.object focus : [ xl , xz ) ;</definiens>
			</definition>
			<definition id="4">
				<sentence>Identify between yl and either XI or x2 can be ruled out on the basis of MEMBER ( yl , y3 ) which tells us that yl is an ihdividual and SUBSET ( x1 , [ BOY ] ) , SUBSET ( x2 , [ DOG ] ) , GREATER ( SIZE ( x , ) , l ) , and GREATER ( SIZE ( xz ) , 11 , which tell us that xl and x2 are sets containing more than one object .</sentence>
				<definiendum id="0">GREATER</definiendum>
			</definition>
			<definition id="5">
				<sentence>Prt denotes a predicate variable .</sentence>
				<definiendum id="0">Prt</definiendum>
			</definition>
			<definition id="6">
				<sentence>The form class files are groupings of the various keywords which may occur in the data .</sentence>
				<definiendum id="0">form class files</definiendum>
				<definiens id="0">groupings of the various keywords which may occur in the data</definiens>
			</definition>
			<definition id="7">
				<sentence>The system is instructed to produce a classification file by a statement of the form : CLASS = ( classification file name ) , ( 4 expression list &gt; ) where ( classification file name ) is the name by which the file will be known , and each expression in &lt; eqression list 7 is a Boolean expression. For example : CLASS = HINDI , ( AGE = 5 e LANG = HINDi , AGE = 5 4 LmG + HIND11 will produce the classification file given earlier as an example. The side conditions refer to items ih the parse trees which must occur if the tree is to be i~~cludd in a given analysis. For example , if only affirmative active uHerances are to be analysed the side condition Q. 7 AFM AC171 is used. me patrern to be used is stated in a manner similar to that used in specifying the input data. Thus , the pattern description PRED r .. . + AUX.. . ; GR : @ CTN , NEUT TM , @ PROG , PATT Pdicates that the sub-tree PRED ( GR : @ CTN , NEUT TM , @ FROG , PATT ) is of interest , subject to the convention that both the order of node descriptors ( where given ) and node descriptors not mentioned in the pattern are to be Lgnored. The occurrence of keyword FORM = &lt; form class file name ) indicates that the contents of the stated form class file are to form an additional dimension to the final tabulations. Thus the pattern AUX -- + [ ? I FORM = OKFILE where OKFILE contains the keywords OK and NOK and is an abbreviation Sor the pair of patterns. AUX -P [ ? I OK AUX+ [ ? I NOK The symbol ? indicates that the items found there are also to add an additional dimension to the tabulations. The output of each tabulation may also be used to construct a classification file of the informants , to be used in further analyses. CONCLUSION In respect of performance of groups with different socio-linguistic descriptions , for purposes of this study , it is assumed that the frequency of occurrence of particular basic parse trees is a meaningful indicator of differences in speech patterns. A major difficulty is that no two trees in the study are identical but at the same time if we strip too much information from each node there are too few trees to make an analysis worthwhile , and in part , the study aims at determining the degree to which strippilrp of information at interior nodes is necessary if the Gomputer is to be a qseful aid. American Journal of Computational Linguistics Microfiche 36 : 52 DAVID BRILL AND BEATRICE T. OSHIKA Speech Communications Research Laboratory , Inc. 800A Mirarnonte Drive Santa Barbara , California 93109 ABSTRACT A set of SAIL programs has been implemented for analyzing large bodies of natural language data in which associations exist between strings and sets of strings. These programs include facilities for compiling information such as frequency of occurrence of strings ( e.g. word frequencies ) or substrings ( e.g. consonant cluster frequencies ) , and describing relationships among strings ( e.g. various phonological realizations af a word ) . Also , an associative data base may be interactively accessed on the basis of keys corresponding to different types of data elements , and a pattern matcher allows retrieval of incompletely specified elements. Applications Of this natural language processing package include analysis of phonological variation for specifying and testing phonological rules , and comparison across languages for historical reconstruction. f , NATURAL LANGUAGE PROCESSING PACKAGE A. General characteristics The natural language processing package implemented at the Speech Communications Research Laboratoqy ( SCIU ; ) is currently wed in the analysis of associated lists @ f string data such as discourse transcriptions or pronouncing dictionaries. The package consists of a ) a set of `` batchw programs which provide frequency and context information on the lexical and phonological forms appearing in the input ; and b ) a system for interactively accessing the data dn the basis of orthographic and phonological patterns. All of the programs in this package are written in SAIL , an ALGOL-based language offering extended string and set manipulation operations and an associative data base. The programs run on a DEC PDP-10 at Carnegie-Mellon University via the Advanced Research Projects Agency ( ARPA ) computer network ( ARPANET ) . The ARPANET is accessed by the ELI ? operating system developed by SCRL , which runs on a local PDP-11 [ I ] . While the processing package is applicable to various types of natural language data , it has been used most extensively at SCRL in the analysis of discourse transcriptions. The discourses consist of conversational speech gathered in interviews with adult speakers of various dialects of American English. More than twenty-five discourses , transcribed orthographically and phonologically , have been prmssed , yielding detailed information on over 28,000 utterances representing about 3,500 distinct lexicalitems. All examples in this section are taken from a typical discburse. B. `` Batchw Facility Discourse processing usually begins with the generation of a transcription reference file in which orthographic and phonological representations are listed in discourse order , as illustrated in Figure 1. WELL LET ' S TRY CLASSIFYING THEM ACCORDING= TO THE EXCUSES 086 TRAY 887 KLAES $ CFAYIHNS 888 DHAXM 88s //AXK $ ORDIHN/TUW// Figure 1 In this example , the phonological realization of TRY is /tray/ ( coded TRAY ) . The phonological code shown is a basic ARPA phonemic alphabet augmented by special symbols indicatim some phonetic detail , such as vowel height. The realization of THE , for example , is coded DH $ I , indicating that the vowel fell between /i/ and /I/. Figure 2 In Figure 2 , for example , HAVE occurred eight times , and was pronounced ( /av/ ) three times and HHAEV v three times. Using the reference numbers associated with these pronunciations , it is possible to establish the discourse context. One would find that the tbree AXV pronunciations ( i.e. utterances 11 , 337 and 703 ) all involved the auxiliary construction in `` , . , may have felt , , , seemed to have been which have since been. .. II ENVIRN tallies occurrences of phonological segments and environments in the discourse transcriptions. The output of this program lists frequencies of all phonemes appearing in &amp; he input file , as illustrated in Figure 3. Figure 3 Glottal stop , coded Q , occurred a total of thirty times in the discourse , The immediate environments of Q are listed alphabetically by left context , with word boundaries indicated by slash / , and a frequency count and reference numbers are given for each environment. For example , Q appeared eight times in the context EH -- EN ( E-n , and a check of the reference list shows that all these occurrences were in the word sentence ( s ) . ENVIRN output also provides a frequency ordered liSt of phonemes , with frequency totals brokerr down according to occurrence in word initial , medial and final position. CLUSTR , the third of the `` batch '' programs , is used in the analysis of phoneme cluster distribution in the discourse data. All clusters are indexed by each of their component phonemes , so that the cluster NDZ ( fndz ) ' ) which is listed under D in Figure 4 also appears under N ad 2 in the full output. DENTS 1 699 DQENTS 1 486 D V 2 1417 , 1445 D Z 5 278 , 284 , 837 , 1341 , 1350 NDZ 1 1429 Figure 4 Separate output may be generated for clusters occurring within woxds or across word boundariesCurrently , consonant and vawel clusters are tallied , but the program can be easily modified to handle sequences of phonemes belonging to arbitrary user-defined classes ( e.g. voiced sounds , , nasals , unvoiced stops , etc. ) . For each phoneme belonging to a selected class , CLUSTR provides a count of the number of times that the phoneme appears in clusters , an alphabetically sorted list of those clusters , and a frequency count and reference numbers for each cluster. Figure 4 , a sample of CLUSTR output for within-word consonant clusters , shows that D appeared in clusters a total of 70 times , New York , New Yofk 10012 ABSTRACT ~inguistic mechanisms of compression are used when making notes within a context where the objects and meanings are known. Mechanisms of compressidn in medical records for a collaborative study of breast cancer are described. The syntactic devices were mainly deletion of words having a special status in the grammar of the whole language and deletion in particular positions of word+ having a special sta &amp; us in the sublanguage. The deIeted forms are described and sublanguage Qord classes defined. A subcorpus of the medical records was parsed by an existing computer parsing system ; a component covering the deletion-forms was added to the granunar. Modifications to t , he computer grammar are discussed and the parsing results are summarized. Introduction All 1anguages '' have mechanisms of compression. Sentences may be embedded within other sentenaes by means of nominalization and complementation. Various grammatical transformations involve deletion of certain parts of the sentence. In medical records , we find entries such as no evidence of metastases , which may be said to be derived Trea something like There is no evidence of metastases. Such incomplete sentences are not common in the spoken language of the medical records ( i.e. dictated reports ) . However when physiciakrs themselves are requirbd to writematerial for records , compression mechanisms are qmmonly use &amp; . Although this paper will deal with a mific corpus , similar devices would I often be used for compression in other s-ations where there is pressure to write as little as possible , Legal , educational , and scientific recordg where informal notes are kept woum be other examples of this class of sitqations. The original motivation for this study was to develop effective methods for storing &amp; e information in a medical record and to be able to retrieve this information for purposes of research , medical care , or administration. Fsoan previous research , the feasibility of verbatim input of dictated narrative has been established , Computerized extraction of the information has been shown to be feaeible i~ a test system ACORN ( Automated Coding of Report ~arrative ) . his system has been described in detail in a series of previous papers. 1dt3 1 For a highly structured medical record where the entries are single words or very restricted sentences , the feasibility'of computer-assisted editing and coding has also been established. A procedure for typing in the entdes verbatim in a medical record , called 'TICPIS ' ( Type-In Coding and Editing System ) 4 ha8 been reported e1sew ) rere. However , the thitd , intermediate class of material can not be handled by ACORN or by TICES. Therefore , a linguistic analysis of this type of material has been undertaken with the ultimate objective of setting up a comprehensive eomputer system that can handle almost everything in the medical records. In the earlier effoxts to develop natural language technology , the work was facilitated by the fact that the documents involved were strictly for the trans5 mission of factual information. Such documents are regarded as important both by the persons who are filling them out and by the persons who read them. In this no-nonsense situation where the record may be critically reviewed by the peers of the person who is reporting the information , unambiguous and informative transmission of information is a critical need. Some of the simplicities in the present analysis may be~eculiar to ws type of situatfon. The existence of a subculture with shared training , objectives , and experience may facilitate the note-taking process in somewhat the same way that a person taking notes for himself can somehow be more concise without ambiguity. .. Howeveb , r many other note-taking situations would involve subculture , though not necessarily a medical one , and the findings here might be expected to have sdne general applicability. Source of Material The medical &amp; es discussed here are ffom tjhe records of the Surgical Adjutrant Breast Project , a nationwide collaborative study involving 36 medical institutions. The records were filled out by medical and paramedical personnel at the participating institutions and cehtralized at Ro $ glell Park Nemri &amp; l Institute in a Statistical unit under thq direction\of-Dr. Nelson S-lack. A sample of approximately 50 was taken from the 2734 cage histories of patients in the program and is being used in the lbguistic analysis. Each case history ordinarily consiats df 3-6 pages of detailed information on the patient 's initial status , treatment , pathology report , nledicai problems , and subsequent fate. When the structured information in the record was excluded , each case history had between 6 and 26 notated items , each item consisting of 1 t6 5 partial-sentences. While this material is speckalized to me purposes of the collaborative study , this type of information iq fairly typical of what is found in the usual hospital record. The notes were typed vexbath using An IBM Mag Card Communicator so as to obtain simultaneously a typed paper document and a record in computer-usable form. This device is used in the data-input sgstem of T~CES ; an existing system for handling completely structured records. It would presumably be usea in any extension of TICES which would handle medical nates. In eis'analysis the computer was used to reorganize the material in a fbrmmore convenient for manual analysis by the linguist. Anderson analyzed the linguistic structure of the entries in a sample of the medical records involving radiation findings , A discussion of this analysis will take up the next part of the paper. Sager and associates used some of the findings from this study to develop methods for processing these same medical records by computef , adapting % program and grananar which had been developed fok parsing science articles. This project will be discussed in the final part of the paper. Linguistic Characteristics of Medical Notes Many of the entries on the medical records are in the form of notes which are neither complete sentences nor single word entries , but linguistic strings of an intermediate type , which we will hereafter call fragments , Fragments are a compressed typ of linguistic material resulting from various transformations which have the effect of making linguistic strings shorter by reducing or deleting materihl. The writer of these stretches of material must make his entries brief , in order to save time and effort , but also make them informative and unambiguous. For this reason the deleted material has to be easily recoverable , or in other words it must not contain much information. An analysis of the fragments shows that deletion is maiinly of a small class of sentence parts : ( 1 ) tense and the verb be ( t be ) ; ( 2 ) subject , tense and the verb be ; ( 3 ) the subject ; and ( 4 ) subject , tense , and verb ( V ) other than be. A second characteristic of fragments which makes deleted material recoverable is that both the meted material and the remainders consist of words in easily defined subclasses , based on both distributional and semantic criteria. These subclasses are easily defined because of the nature of the sublanguage ; in general the vocabulary is limited and each word has a limited semantic range. The question on a form khich is being answered can also be used as a basis for retoring deleted material. One of the most commonly deleted items in the medical records is t be ( 1 and 2 ) . Tense is perhaps the most important information be gives. The deletion of tense in the medical records causes no ambiguity because usually the physician describes the situation at the time of filling out the report , Otherwise he gives the time in a time phrase : x-rays on November 2. Fragment Types In Table 1 we list the fragment types , giving an example of each , but not with all occurring word subcl &amp; ! 3ses. The types will Sirst be given according to what material is deleted and then will be futther subclassed according to the highest nodes of the tree structure of the remainder. The material in brackets is the word subclasses which are assumed .So have been deldted. TABU3 1. FRAGMENT TYPES S trudurs Material Deleted of Fragment Example N-physician physician ] N Adj chest films [ were ] nonnal NPN patient [ was ] without cough 1 N to V this form [ is ] to be used . . . N Ving wound [ is ] healing well be Ven [ N-disease was ] aspirated once Ads [ N-Patient is ] dead to be Ven [ N-patient is ] to be seen by gynecologist Ving [ N-patient is ] doing well 3a. N-physician Subject 3b. N-patient Subject 3c. N-disease Subject ( rare 1 4a. N-physician t Object V-diecover 4b. N-physician Object t V-do 4c. N-patient Object t have [ I ] found osteochondritis in , rib ( 5th right ) [ N-patient ] had period one week ago [ N-disease ] invades skin [ N-disease ] seems minor [ I V-discovered ] no bony metastases [ N-ghysician did ] excision of ( r ) 5th costal cartilage [ N-patient has ] no bone pain Word Subclasses The word subclassbs should have three characteristics : ( 1 ) they should enable deleted material to be recovered , ( 2 ) they should make it possible to 6 extract and store informational units such as those in ACORN and ( 3 ) they should be defined so that a linguistically unsophisticated person can easily put words into their subclasses. The word subclasses ate based on both semantic and distributional criteria. To a large extent nouns can conveniently be subclassed on a semantic basis and verbs can be subclassed on a distributional basis , according ta the subclasses of nouns which they take as subject and object. Due to the nature of the sublanguage there is relatively little overlap ( e.g. , a given verb is likely to take only one noun subclass as shject ) compared to what we would find in the language as a whole. Two impoftant subclasses of h-n nouns used in the medical records are N-physician and N-patieht. Each has only a few members , but is important because many verbs chqacteristically take it as subject or object , and also because both , but particularly N-physician , are usually deleted. It is on the basis of the verbs which characteristically take them as subject or object that they can usually be recovered without ambiguity. Other noun subclasses concern more directly the subject matter of the reports , the concrete objects with which the physician is dealing. Unlike Nphysician and N-patient , these classes usually have many mmbers and they are seldom deleted. As with N-physician and N-patient , certain uerb subclasses char~cteristically take them as subject or object. Table 2 gives some of the word subclasses with examples of each. 6~ross et al. `` Information in Natural Languages : A New Approach , '' 1969. TABLE 2. SOME WORD SUBCLASSES N-bwa $ t N-change I R-dimas ion N-disease N-exam N-locatibrl N-patient Nphysician N-therapy N-time V-be-equivalent V-change V-discer V-patient-object V-patient-subject V-physician-subject V-show Ad j -bodypart Adj-changed Adj-degree Ad j -discover Adj-disease quality abdomen , axilla , bone , Br-t , cervix , pelvis change , elevation , enlargement , gab , increase pressure , ' rate , rhythm , size , weight carcinoma , cough , disease , edema , fibxosis 6iopsy , exam , film , qamogram ; scan , x-xay area , field , floor , lobe , neck , part , regionr she , her , patient , lady , woman doctor , he , him , his , I , *M.D. , radiologist drug , insulin , medication , medicine , radiation date , month , the , visit , winter , year appear , feel , indicate , remain , represent , seem alter , clear , change , enlarge , heal , progress detect , find , identify , ncyte , observe , see ah= , give , leave , place , readmit , see , transfer , trqat complain , come , moperate , enter , feel , gain , go , have , refuse , show , suf f ; r , take feel , have , place , tel.1 , t'kansfer , treat , See show , demonstrate , indicate , reveal , suggest axillary , bony , clavicular , lumbar , pelvic elevated , enlarged , healed , stable , unchanged. considerable , extensive , intermittent , little absent , evident , Fnown , possible , present active , bad , benign , degenerative , firm , hard , malignant , metastatpc , nodular adjoining , distal , dorsal , frontal , left clear , free , healthy , negative , normal Computer Parsing of Medical Records ' To test the linguistic analysis , a subset of the manually analyzed corpus of medical records was parsed by computer , using the NYU Linguistic String Parser. 8 The LSP grqmmar of English is based on the same linguistic principles as the ACORN grammar. Hence it could also serve to test the feasibility of adding a note-handling capability to the ACORN-TICES system. The LSY sylr which was designed for text-processinQ , was adapted to the parsing of medical records by deleting portions of the grammar which are not required for this type of material and adding a section covering sentence fragments. These change $ are described below , followed by the parsing resultb. The corpus which was parsed consisted of 12 sections of the Radiation Findings extracted in their order of appearance from the medical records. These sections contained 245 sentences or sentence fragments ( word sequences ending in a period ) . Of these , 37 were complete English sentences and 205 were fragments ; 3 were combinations of both types. 21 entries were identical to others in the corpus , accounting in all for 139 of the sentences ox sentence fragments. Of the complete sentences , same were quite long , e.g. , Reexamination shows some scarring and thickening over the right apex which is perhaps slightly more evident than it was before , but nothing is seen that is typical of tumor involvement. Typical sxorter sentences are Chest films on 10-25-68 and 12-14-68 do not show any essential changes sincelast reports , Liver scan 1-29-69 was normal. Fragments were , as predicted , of the types listed in Table 1 , above , though not all tyMs were represent-ed in the parsed corpus. Table 3 shows the new definitions or redefinitioqd which were added to the LSP grammar to cover fragments. These definitions are written in ~ahs-Naur Form ( BNF ) , as ilze all the ca. 180 definitions which comprise the context-free-part of the LSP English grammar. The BNF definitions are used by the parser to construct a tree representing the structure of the input sentence. In addition to BNF definitions , the grammar contains restrictions , which test the sentence trees for grammatical and selectional well-formedness. The 9 For more explanation of the LSP system and grammar , see N. Sager and TABLE 3. DEFINITIONS ADDED TO THE LSP GRAMMAR TO COVER SENTENm FRAGMENTS ( SENTENCE ) &lt; TExTILET &gt; COLD-SENTENCE ?</sentence>
				<definiendum id="0">AGE</definiendum>
				<definiendum id="1">NEUT TM , @ FROG , PATT )</definiendum>
				<definiendum id="2">phonological code shown</definiendum>
				<definiens id="0">instructed to produce a classification file by a statement of the form : CLASS = ( classification file name ) , ( 4 expression list &gt; ) where ( classification file name ) is the name by which the file will be known , and each expression in &lt; eqression list 7 is a Boolean expression. For example : CLASS = HINDI , ( AGE = 5 e LANG = HINDi ,</definiens>
				<definiens id="1">produce the classification file given earlier as an example. The side conditions refer to items ih the parse trees which must occur if the tree is to be i~~cludd in a given analysis. For example , if only affirmative active uHerances are to be analysed the side condition Q. 7 AFM AC171 is used. me patrern to be used is stated in a manner similar to that used in specifying the input data. Thus , the pattern description PRED r .. . + AUX.. . ; GR : @ CTN , NEUT TM , @ PROG , PATT Pdicates that the sub-tree PRED ( GR : @ CTN</definiens>
				<definiens id="2">of interest , subject to the convention that both the order of node descriptors ( where given ) and node descriptors not mentioned in the pattern are to be Lgnored. The occurrence of keyword FORM = &lt; form class file name ) indicates that the contents of the stated form class file are to form an additional dimension to the final tabulations. Thus the pattern AUX -- + [ ? I FORM = OKFILE where OKFILE contains the keywords OK and NOK and is an abbreviation Sor the pair of patterns. AUX -P [ ? I OK AUX+ [ ? I NOK The symbol ? indicates that the items found there are also to add an additional dimension to the tabulations. The output of each tabulation may also be used to construct a classification file of the informants , to be used in further analyses. CONCLUSION In respect of performance of groups with different socio-linguistic descriptions , for purposes of this study , it is assumed that the frequency of occurrence of particular basic parse trees is a meaningful indicator of differences in speech patterns. A major difficulty is that no two trees in the study are identical but at the same time if we strip too much information from each node there are too few trees to make an analysis worthwhile , and in part , the study aims at determining the degree to which strippilrp of information at interior nodes is necessary if the Gomputer is to be a qseful aid. American Journal of Computational Linguistics Microfiche 36 : 52 DAVID BRILL AND BEATRICE T. OSHIKA Speech Communications Research Laboratory , Inc. 800A Mirarnonte Drive Santa Barbara , California 93109 ABSTRACT A set of SAIL programs has been implemented for analyzing large bodies of natural language data in which associations exist between strings and sets of strings. These programs include facilities for compiling information such as frequency of occurrence of strings ( e.g. word frequencies ) or substrings ( e.g. consonant cluster frequencies ) , and describing relationships among strings ( e.g. various phonological realizations af a word ) . Also , an associative data base may be interactively accessed on the basis of keys corresponding to different types of data elements , and a pattern matcher allows retrieval of incompletely specified elements. Applications Of this natural language processing package include analysis of phonological variation for specifying and testing phonological rules , and comparison across languages for historical reconstruction. f , NATURAL LANGUAGE PROCESSING PACKAGE A. General characteristics The natural language processing package implemented at the Speech Communications Research Laboratoqy ( SCIU ; ) is currently wed in the analysis of associated lists @ f string data such as discourse transcriptions or pronouncing dictionaries. The package consists of a ) a set of `` batchw programs which provide frequency and context information on the lexical and phonological forms appearing in the input ; and b ) a system for interactively accessing the data dn the basis of orthographic and phonological patterns. All of the programs in this package are written in SAIL , an ALGOL-based language offering extended string and set manipulation operations and an associative data base. The programs run on a DEC PDP-10 at Carnegie-Mellon University via the Advanced Research Projects Agency ( ARPA ) computer network ( ARPANET ) . The ARPANET is accessed by the ELI ? operating system developed by SCRL , which runs on a local PDP-11 [ I ] . While the processing package is applicable to various types of natural language data , it has been used most extensively at SCRL in the analysis of discourse transcriptions. The discourses consist of conversational speech gathered in interviews with adult speakers of various dialects of American English. More than twenty-five discourses , transcribed orthographically and phonologically , have been prmssed , yielding detailed information on over 28,000 utterances representing about 3,500 distinct lexicalitems. All examples in this section are taken from a typical discburse. B. `` Batchw Facility Discourse processing usually begins with the generation of a transcription reference file in which orthographic and phonological representations are listed in discourse order , as illustrated in Figure 1. WELL LET ' S TRY CLASSIFYING THEM ACCORDING= TO THE EXCUSES</definiens>
			</definition>
			<definition id="8">
				<sentence>In the LSP grammar , ASTG ( Adjective strind is an option of OBJBE , and VEWASS ( V-en passive string ) is also permitted after -C be and in other places .</sentence>
				<definiendum id="0">ASTG ( Adjective strind</definiendum>
				<definiens id="0">an option of OBJBE , and VEWASS ( V-en passive string ) is also permitted after -C be and in other places</definiens>
			</definition>
</paper>

		<paper id="1033">
			<definition id="0">
				<sentence>The component receives messages describing what is to be said formulated in the representation of the main prograr and produces fluent English utterances appropriate to the current discourse situation .</sentence>
				<definiendum id="0">component</definiendum>
			</definition>
			<definition id="1">
				<sentence>( prediction ) event ( event actor ( Winston ) action ( fit person-into dull schedule &gt; the ( 31-10-75 , gar-12am ) hedge &lt; fs possible ) aim-at-audience hedge Messages have features describing the program 's communicative intentions what sort of utterance is this to be ; what effect is it to have. Messages list the objects to be desert-bed ( the right hand column ) along with annotations for each object ( left hand co1u.n ) to show how they relate to the rest of the message. The phrases on the right in angle brackets represent actual structures from the scheduler wf th those The Lexicon Translatl~n ftor tho internal reprcscntai ton of s coaputcr program to natural language has the same sort of problew as translating betw~en two natural languages. Tk same concepts nay not be available as prim1 tivos in both rcpresents.tions , and the conventions of the target Isnguape my require additional information that was not in the source. Generally speaking translation can not be one for one. What English phrase is best for a particular element in a program 's message will depend on what is in the rest of the message and of what the external context is. In such circunstances , translation by tablelookup is inadequate. In this component , in order to allow all factors to be considered , the translation of each element ias done by individualized procedures called wcorposersH. For each main program that the linguistic component becomes associated with , a lexicon must be created which will list the elements of the rain program 's representation that could appear in a message ( 1. C. wprCdl~tl~nH , `` eventw , w &lt; WinstonP , etc. ) . With each element is recorded the composer that will be run when the time comes to produce en English description for it ( examples will be given shortly ) . Some conposers nay be applicable for a whole class of elements , such as `` eventsw. They would know the structure that all events have in common ( e.g. actor , actlon , tine ) and would know how to interpret the idiosyncratic details of each event by using data in the lexicon associated with them. The Grammar strategies The bulk of the grauar con &amp; ists of `` strategiesw. Strategies arc associated with particular languages rather than with particular main prograas as composers are. A given strategy may be used for several different purposes. A typical case is the strategy use-s , ? mp~resenttense : a clause in the simple present ( `` prices risew ) my be understood as future , cond'itlonal , or timeless , according to what other phrases arc present , Each composer ray know of several strategies , or Coabinatlons of strategies which it could use in dcscrlbing an ele.cnt from the message , It wiT1 choose between the &amp; according to the context usually details of the element or syntactic constraints iaposed by previously selected strategies. The strategies themselves do no reasoning ; they are implemented as functions which the corposers call to do all the actual corsst'ruction of the utterance. The Tr~nslation Prooesa At this point. the out1 ine of the data-dr Iven translation process can be su~rnriztd. A message is glven for translation. The ele~ents of the aessage are associated in a lexicon with procedures to describe the.. The procedures are run ; they call grs~latica1 strategies ; and the strategies construct the English utterance. Of course , if this were all there was to it , the process would never run , betause all of the subprocesses aust be throughly coordinated if they are not to `` trip over their own feet '' , or , for that ~atter , if ordinary human beings are to bo able to design the.. In a system where the knowledge of what to do is distributed over a large number of separate procedures , control structure assumes central. iaportance. Plans Before dt~cribing the control structure , I must lay out some additional aspects of the design of the ilngulstlcs coaponent. There is no interlingua or intermediate level of structure co~parablc to the dkep structures of Transformttlonal Gra~sar , or the sewntlc nets of Sl~aons ( 73 ) or Goldban ( 74 ) . Detorminln~ the appropriate sutface structure , however , requires plannfnp , if for no other reason than that the Message can only be examined one piece ax a the. The entire utterance must be organized before a detailed analysis and translation can get underway. As this is done , the wproto-utterancew is represented in terns of a sort of scaffolding a representatiqp of the ultimate surface structure tree insofar as its details are known with extensive annotation , explicit and implicit , to point out where elements that are not yet described may be positioned , and to implement the graamatical restrictions on possible future details as dictated by what has already been done. The scaffolding that is constructed in the translation of each message is called its wp4a0w. Plans are made up of syntactic nodes of the usual sort clauses , noun groups , etc , and nodes may have features in the Banner of tysteni ; grammar Winograd '72~ Nodes have subplans consisting of a list of named slots marking the possible potftlons for sub-constituents , given in the order ~f tho eventual surface structure. Possible slots would be wsubJectw , *. % in verbw , `` noun headw , wpre-verb-adverbw , and so on. The syntactic node types will each have a nuaber of -possible plans , corresponding '' to the different possible arrangements or sub-consti tuents that may occur wl th tho different combinations of features that tho Mdc may have , Depending on tho rtage of the translation process , a slot may bc `` fl1lodw with a pointer to an lnternal object fro. the message , a syntactic node , a word or idior , ar nothing. The translation proaaea Tho translation is done in two phases. The second phase does not begin until the first is coapletely finished. During the first phase , a plan is selected and the eleaents of the message are transferred , largely untouched ; to the slots of the plan and features added to its nodes. During the second phase , the plan is wwalktdR topdown and from left to right. Conpostrs for mssage ele~ehts in the plan 's slots are activated to produce English descriptions for the elcments as they are reached in turn. Both processes are data-directed , the first by the particular contents of the message and the second by the structure of the plan and the contents of its slots. There are sound linguistic reasons for this two stage processing. Most parts of a lessage Bay be translated in terms of very modular sysltactic and lexical units. But other parts are translated in terms of relations between such units , expressed usually by ordering or clauselevel syntactic aechanislps. The exact for @ of the s~aller units can not be deternlned until their larger scale relations have been fixed. Accordingly , the objective of the first phase is to determine what global relationships are required and to choose the plan , features , and positions of message elemnts within the plan 's slots that will realfzt those relationships. Once this has been done , Engl tsh descriptions for the elements can be made Independent of each other and will not need to be changed after they arc initially created. One of the lost iaportant features of natural language is the ability to omit , prono~inal ize , or otherwise abbreviate elements in certain contexts. The only known rules and hllristlcs for using this feature rro phrased in terms of Surface structure configurations and temporal ordering. Because the second ~hase works directly in thcse terms , stating and using the available heuristics becoaos a straight£ orwsrd , tractable problem. `` Maybe he can eg.ueeze you in tommoww morning '' The rest of this paper will try to put solae flesh on your picture of how this linguistics conponent works by following the translation of the message given in the beginning to the sentence above. The message was this. Massage1 features* ( prediction ) event ( event actor &lt; Winston &gt; action .</sentence>
				<definiendum id="0">event actor</definiendum>
				<definiendum id="1">utterance</definiendum>
				<definiens id="0">Messages list the objects to be desert-bed ( the right hand column ) along with annotations for each object</definiens>
				<definiens id="1">the element or syntactic constraints iaposed by previously selected strategies. The strategies themselves do no reasoning</definiens>
			</definition>
			<definition id="2">
				<sentence>The action is `` &lt; fit person into full schedulerw , and it will have two relevant properties in the lexicon : `` plan* , and `` .appingW. klan is either the nane of a standard plan to be used ; or an actual plan , partially filled with words ( 1. e. it can be a phrase ) . `` Mappingw is an association list showing how the subelements of the message are to be transferred to the plan. &lt; fit person into full schedule ) PLAN node-i ( clause trans1 particle ) slots frontings nil subject nil vg node-j ( verb-group particle ) slots modal nil pre-vb-adv nil mvb `` squeezew prt `` inw object1 &lt; person being talked about ) post-modifiers nil MAPP I NG ( ( actor subject ) ( time post-modifiers ) ) The event composer proceeds to instanticte the nodes in the phrase and make the transfers ; the prediction composer then takes the resulting plan , and makes it the plan of the whole utterance. Two message elements remain , but actually there is only one , because waim-at-audiancew is supplying additional informati~n about the hedge. The annotation means that the contents of the hedge ( &lt; is possible &gt; ) ere pore something that we want to tell the audience than a detail of the prediction .</sentence>
				<definiendum id="0">Mappingw</definiendum>
				<definiendum id="1">NG ( ( actor</definiendum>
				<definiendum id="2">annotation</definiendum>
				<definiens id="0">an association list showing how the subelements of the message are to be transferred to the plan. &lt; fit person into full schedule</definiens>
				<definiens id="1">the nodes in the phrase and make the transfers</definiens>
				<definiens id="2">means that the contents of the hedge ( &lt; is possible &gt;</definiens>
			</definition>
			<definition id="3">
				<sentence>The prediction composer looks in the lexicon to see what grammatical unit will be used to realize &lt; is possible , , and sees , let us say , two possibilities involving different configurations of the adverb wn &amp; ybcn and the modal `` can be able ton , with the differences hinging on the placement of the adverb. Theoretically , adverbs can be positioned in a nunber of places in a clause , depending on their characteristics. In this instance , the choice is forced because of a heuristic written into the grammar of adverbs and accessible to the composer , that says that when the intent of an adverb is directed to the audience , it should be in the first position ( the `` frontiogsW slot ) . This choice implies putting `` canw In the modal slot directly. The alternative with w~ybe* in the pre-vb-adv slot would have necessitated a different form of the .o8al , yielding `` ray be able ton , These details would have been taken care of by syntactic routines associated with the verb group node. A11 the message ererents have been placed and the first phase is over. The plan is now as below. n4e-l ( clause trans1 particle ) slats fmntfngs `` 8aybeW subject twinston &gt; vg node-2 ( verb-group par tic1 el slots modal `` canw pre-vb-adv nil mvb `` squeezen prt `` inw object1 cperson being talked about ) post-modifiers nil The second phase controller is a simple dispaching function that mves from slot to slot .</sentence>
				<definiendum id="0">prediction composer</definiendum>
				<definiens id="0">possible , , and sees , let us say , two possibilities involving different configurations of the adverb wn &amp; ybcn and the modal `` can be able ton , with the differences hinging on the placement of the adverb. Theoretically , adverbs can be positioned in a nunber of places in a clause</definiens>
				<definiens id="1">taken care of by syntactic routines associated with the verb group node. A11 the message ererents</definiens>
				<definiens id="2">a simple dispaching function that mves from slot to slot</definiens>
			</definition>
			<definition id="4">
				<sentence>wSttbjectw contains an internal object , so the controller should go to the lexicon for its composer and then come back to handle whatever the composer replaced the clement with , However , there is always an lhtervening step to check for the possibility of pronominalizing .</sentence>
				<definiendum id="0">wSttbjectw</definiendum>
				<definiens id="0">contains an internal object</definiens>
			</definition>
			<definition id="5">
				<sentence>At the moaent &lt; September , 19751 , the data and control structures ~cntioned have been fully iep1e~ented and tests are underway on gedanken data. Hopefully , by the end of 1975 the component will have a reasonable gramar and will be working with messages and lexicons form the two programs mentioned before. A MI7 A. I. lab technical report describing this work in depth should be ready in the spring of next year. David McDonald Cambridge , Mass. American Journal of Computational Linguistics Microfiche 33 : 28 RODGER KNAUS Systems of tware Division Social and Economic Statistics Administration Bureau of the Census Washington , D. C. 20233 A human who learns a language can both parse and generate sentences in the language. In contrast most artificial language processors operate in one direction only or requtre separate grammars for parsing and generation. This paper describes a model for human language processing which uses a single language description for parsing and generation. A number of constraints limit the processors suitable as models of human language processing. Because short term memory is limited. the listener must absorb incoming words into larger chunks as the sentence is heard. Also because he is expected to reply within a couple seconds after the speaker finishes , regardless of length of the speaker 's utterance , the listener must do much of the semantic processfng of a sentence as he hears it. 19 Bever and Hatt point out that the difficulty in understanding a sentence S is not predicted by the number of transformations used to generate S. Furthermore the process of detransforrnation appears too time-consuming ( petrick ) for the approximately two seconds before a listeaer is expected to reply. A depth first transition network parser ( Woods , ~aplan ) , in which parsing difficulty is measured by the number of arcs traversed , correctly predicts the relative di fficul ty of active and passive sentences progressive and adjectival present participle sentences and the extreme difficulty of multiple center embeddings. However a syntactically directed depth first parser does not explain why syntactically similar sentences such as ( 5A ) The horse sold at the fair escaped. ( 5 % ) The horse raced past the barn fell. vary in difficulty , nor does it explain experiments on the completion and veriftcation of ambiguous sentences ( MacKay , Olsen and MacKay ) which suggest that a pruned breadth first strategy is used to par ce sentences. Sentences with two equal ly plausible a1 ternatives took longer to process than sentences with only one likely interpretation. This extra processing time may be attributed to the construction of two alternate interpretations over a 1onge~ portion of the sentence when more than one interpretation is plausible. In addition subjects somet~mes become confused by the two interpretations of an ambiguous sentence. Finally in experiments in which subjects hear an ambiguous sentence in ode ear and a disfrnbiguating sentence simultaneously in the other ear ( Garrett ) the interpretation af the ambiguity actually percelved by the subject may be switched between the possibilities by changing the disambiguating sentences. Step 3 ( a ) : ( S NP ( N mail ) ( N Boxes ) ) [ V like ) ( .NP ) ( PP* ) ) ( b ) : ( S ( NP ( NP ( N mall ) ( N Boxes ) ) ( PP ( PREP like ) NP ' ) ( PP* ) ) V ( NP ) fpp* ) ) ( c ) : ( S ( NP ( N mail ) ) ( V Boxes ) I PP ( PREP like ) NP ) ( PP* ) ) ( d ) : ( S V mail ) ( NP ( N Boxes ) ) ( PP ( PREP like ) NP ) ( PP* ) ) ( e ) : ( S ( V mail ) ( NP ( NP ( N Boxes ) ) ( PP ( PREP like ) NP ) ( PP* ) ) ( pp* 1 ) After completing the sentence after Step 4 , the parser produces phrase markers from a , c , d and e by adding the last word and deleting unfilled optional nodes. The phrase marker obtained from 48 is rejected because it contains an unfilled obligatory V node. The incremental parser adds each successive sentence word to the partially completed phrase markers built from the earlier part of the sentence. The new word is added at the leftmost oblig unfilled node of each partial phrase marker and at all optional nodes to the left of this node. Three different operations are used to add a new word to a partial parse. The word may be directly added to an unexpanded node , as in Step 3a above. A1 ternatively , a new word may be attached to an unfilled node with a left branching acyclic tree built from the grammar such as ( PP PREP NP ) or ( S ( NP N , IN* ) ) V ( NP ) ( PP* ) ) . Attaching occurs in steps 1 and 3c. Finally a subtrbe of an existing partial phrase marker may be 4eft embedded in a larger structure of the same grammatjcal category , as in steps 3b and 3e above. The embedding operation uses at most two left branching trees bui1 t from the gr'ammar : a tree TI with a single cycle on the left branch is used to replace the existing subtree E being embedded. In step 3e , for example , the structure ( S ( V mail ) ( NP NP ( PP* ) ) ( PP* ) ) would be obtained. The E is used to expand the leftmost unexpanded node of TI : for 3 b this results in : 3e. ( S ( V mail ) ( NP ( NP ( N Boxes ) ( N* ) ) PP* ) ( PP* ) ) . Finally to the resulting structure the new sentence word is added through direct node expansion or attaching with an acyclic left branching tree ; in the example above this produces 3e from 3el ' Using direct expanston attaching and embedding , the incremental parser finds a1 1 the phrase markers of sentences fn context free or regular expression language ; a formal definition of the parser and a proof of its correctness appear in [ lo ] . Sometlmes , as at steps 3b and 3e , the same structure ( a prepositiobnal phrase in step 2 ) is used in more than one partial parse. Following Earley 's Algo'rithm , the incremental parser builds a single copy of the shared substructure Sf ! ! and maintains pofnters lfnking Sb to nodes in larger structures which $ 9 expands. Far all its tree building operations the incremental parser uses a flnlte set of trees. e. , the trees with only left subnodes expanded and at most onelcycle on the leftmost branch. These trees may be computed djrectly from the grammar and referenced by root and leftmost unexpanded node during the parse. Using these preconstructed trees , the incremental parser requires only a fixed number of operations to add a new word to a partial parse : a retrieval on a doubly indexed set , copying the left branching tree , and at most four structure changing operations +o paste words and trees together. Like Earley 's Algorithm , IP processes each word proportionally to sentence length. However on sentences satisfying a depth difference bound , the parsing time per word is constant. Because humans ca n't remember large numbers of sentence words but must , process speech at an approximately constant rate , a constant parsing time per ward is a necessary property of any algorithm model i ng human language processing. Let the depth of constituent C in phrase marker P be defined as the length of the path from the root of C to the root of P. If TI and T2 are tuo adjacent terminals with TI preceding T2. the depth difference from 11 to T2 is defined as the difference in depth between 11 and the root ~f the smallest tree containing TI and T2. For exarn~le in the phrase marker ( 9 ) ( S ( NP NP ( DET the ) ( N telephone ) ) [ PP ( PREP IN ) ( F ( P ( DET the ) ( N room ) ) ) ( V rang ) ( ADV loudly ) ) the depth difference between `` the '' and `` telephone '' ' is 1 and between `` roam '' and `` rang '' is 3. The depth difference between 11 and T2 is the number of nodes from TI to the node expanded when adding T2 on a postorder traversal from TI in the partial phrase marker containing TI but not T2. The depth difference between TI and T2 also represents the number of constituents of which TI is the rightmost ward. A proof ( requiring a forma.1 def ini tion of the i ncremental parse ) that parsing time per word is constant in depth difference bounded sentences appears in [ lo ] . Informally the depth difference bound places a bound both on the number of next nodes to expand which may follow a given terminal and on the amount of tree traversal which the parser must perform to ffnd each next unexpanded node. Sfnce each modification requires only a fi'xed number of operati-ons , , each of which is bounded on the finite set of at most once cyclic left branching trees , the computation adding a new word to existing partial parses is bounded inde pendently of sentence length. Natural language sentences tend to have small depth differences. Both right branching sentences and left branching sentences ( found in Japanese for example ) have an average depth difference over each three or four word segment of two or less. On the other hand sentences are difficult to understand when they have two consecutive large depth differences , such as the mu1 ti ple center embedding ( 10 ) The rat the cat the dog bit chased diedb or the complex noun phrase in The pad on a clarfnet in the last row whicn 1 fixed earlier far Eb fe7l out. Furthermore in amhlguous sentences such as ( 11 ) Joe figured that it was time to take the cat out. Kimball observes that subjects prifer the reading with the smaller depth difference. Flnally , Blumenthal found that subjects tended to understand a multfple center embedded sentence as a conjunct1 ve sentence. The conjunctive sentence ~ontains a rearrangement. with lower depth differences of the constituents of the center embedded sentence. The syntactic form given to a sentence depends on the information being communicated in a sentence and on the cultural context in which the sentence appears. Clark and Haviland show that a speaker uses various syntactic devices sentences to place the `` given '' informatian known to the listener before the information `` new '' to the listener. Particular syntactic structures are also used to emphasize or suppress particular kinds of information ; for example newspaper traffic accident reports usually begin with a passive sentence such as ( 12 ) An elderly Lakewood man was injured when.. . , presumably to emphasize the result of the accident. To capture the dependence of syntax on semantic content and bocjal context , the sentence generator uses function-like grammar rules of the form ( Rul erame Cat Variables Predicate Forms ) . Rulename is the name of the rule and cat is the grammatieal category of the constituent generated by the rul em Variables is a list of formal parameters. Usually the variable list contains a varfable bound during rule execution to a node in a semantic network and another variable bound to a control association list containing information about the context in which the generated constituent will appear and possibly the syntactic form the constituent should have. Predicate is a Boolean-valued form on the parameters in Variables. A rule is used only when Predicate is true. Forms is a list of forms depending on Variables which generate terminals or calls to the grammar for subconstituerits of CAT. An example of a generation rule is ( SPI SI ( X Y ) ( Equal ( Voice Y ) ( Quote Passive ) ) ( NP ( Object X ) Y ) t Beverb X ) Pap ( Action X ) ) ( M* X Y ) ) which generates simple passive sentences. The variable X is bound to a node in a semantic network and Y to a control association list. The rule is applied only if the control alist contains a passfve flag and if the semantic node has an object and action ; in general a rule is applied only if the semantic subnodes called in the rule body appear in the semantic net. The form ( NP ( Obj X ) Y ) generates a form ( NP XI fl ) , where XB is the semantic node on the object indicator from X. and Yj3 fs the value of Y. Beverb and Pap are procedures which generate respectively a form ~f the verb `` to be '' and a past particfple form of the verb Action ( X ) . M* is a procedure which generates a list depending on X and Y such as ( PP~Value of Tlme ( X ) &gt; &lt; Value of Y &gt; ) for generating optional prepositi~nal phrases or relatf vc clauses .</sentence>
				<definiendum id="0">T2</definiendum>
				<definiendum id="1">XB</definiendum>
				<definiens id="0">iep1e~ented and tests are underway on gedanken data. Hopefully , by the end of 1975 the component will have a reasonable gramar and will be working with messages and lexicons form the two programs mentioned before. A MI7 A. I. lab technical report describing this work in depth should be ready in the spring of next year. David McDonald Cambridge , Mass. American Journal of Computational Linguistics Microfiche 33 : 28 RODGER KNAUS Systems of tware Division Social and Economic Statistics Administration Bureau of the Census Washington , D. C. 20233 A human who learns a language can both parse and generate sentences in the language. In contrast most artificial language processors operate in one direction only or requtre separate grammars for parsing and generation. This paper describes a model for human language processing which uses a single language description for parsing and generation. A number of constraints limit the processors suitable as models of human language processing. Because short term memory is limited. the listener must absorb incoming words into larger chunks as the sentence is heard. Also because he is expected to reply within a couple seconds after the speaker finishes , regardless of length of the speaker 's utterance , the listener must do much of the semantic processfng of a sentence as he hears it. 19 Bever and Hatt point out that the difficulty in understanding a sentence S is not predicted by the number of transformations used to generate S. Furthermore the process of detransforrnation appears too time-consuming ( petrick ) for the approximately two seconds before a listeaer is expected to reply. A depth first transition network parser ( Woods , ~aplan ) , in which parsing difficulty is measured by the number of arcs traversed , correctly predicts the relative di fficul ty of active and passive sentences progressive and adjectival present participle sentences and the extreme difficulty of multiple center embeddings. However a syntactically directed depth first parser does not explain why syntactically similar sentences such as ( 5A ) The horse sold at the fair escaped. ( 5 % ) The horse raced past the barn fell. vary in difficulty , nor does it explain experiments on the completion and veriftcation of ambiguous sentences ( MacKay , Olsen and MacKay ) which suggest that a pruned breadth first strategy is used to par ce sentences. Sentences with two equal ly plausible a1 ternatives took longer to process than sentences with only one likely interpretation. This extra processing time may be attributed to the construction of two alternate interpretations over a 1onge~ portion of the sentence when more than one interpretation is plausible. In addition subjects somet~mes become confused by the two interpretations of an ambiguous sentence. Finally in experiments in which subjects hear an ambiguous sentence in ode ear and a disfrnbiguating sentence simultaneously in the other ear ( Garrett ) the interpretation af the ambiguity actually percelved by the subject may be switched between the possibilities by changing the disambiguating sentences. Step 3 ( a ) : ( S NP ( N mail ) ( N Boxes ) ) [ V like ) ( .NP ) ( PP* ) ) ( b ) : ( S ( NP ( NP ( N mall ) ( N Boxes ) ) ( PP ( PREP like ) NP ' ) ( PP* ) ) V ( NP ) fpp* ) ) ( c ) : ( S ( NP ( N mail ) ) ( V Boxes ) I PP ( PREP like ) NP ) ( PP* ) ) ( d ) : ( S V mail ) ( NP ( N Boxes ) ) ( PP ( PREP like ) NP ) ( PP* ) ) ( e ) : ( S ( V mail ) ( NP ( NP ( N Boxes ) ) ( PP ( PREP like ) NP ) ( PP* ) ) ( pp* 1 ) After completing the sentence after Step 4 , the parser produces phrase markers from a , c , d and e by adding the last word and deleting unfilled optional nodes. The phrase marker obtained from 48 is rejected because it contains an unfilled obligatory V node. The incremental parser adds each successive sentence word to the partially completed phrase markers built from the earlier part of the sentence. The new word is added at the leftmost oblig unfilled node of each partial phrase marker and at all optional nodes to the left of this node. Three different operations are used to add a new word to a partial parse. The word may be directly added to an unexpanded node , as in Step 3a above. A1 ternatively , a new word may be attached to an unfilled node with a left branching acyclic tree built from the grammar such as ( PP PREP NP ) or ( S ( NP N , IN* ) ) V ( NP ) ( PP* ) ) . Attaching occurs in steps 1 and 3c. Finally a subtrbe of an existing partial phrase marker may be 4eft embedded in a larger structure of the same grammatjcal category , as in steps 3b and 3e above. The embedding operation uses at most two left branching trees bui1 t from the gr'ammar : a tree TI with a single cycle on the left branch is used to replace the existing subtree E being embedded. In step 3e , for example , the structure ( S ( V mail ) ( NP NP ( PP* ) ) ( PP* ) ) would be obtained. The E is used to expand the leftmost unexpanded node of TI : for 3 b this results in : 3e. ( S ( V mail ) ( NP ( NP ( N Boxes ) ( N* ) ) PP* ) ( PP* ) ) . Finally to the resulting structure the new sentence word is added through direct node expansion or attaching with an acyclic left branching tree ; in the example above this produces 3e from 3el ' Using direct expanston attaching and embedding , the incremental parser finds a1 1 the phrase markers of sentences fn context free or regular expression language ; a formal definition of the parser and a proof of its correctness appear in [ lo ] . Sometlmes , as at steps 3b and 3e , the same structure ( a prepositiobnal phrase in step 2 ) is used in more than one partial parse. Following Earley 's Algo'rithm , the incremental parser builds a single copy of the shared substructure Sf ! ! and maintains pofnters lfnking Sb to nodes in larger structures which $ 9 expands. Far all its tree building operations the incremental parser uses a flnlte set of trees. e. , the trees with only left subnodes expanded and at most onelcycle on the leftmost branch. These trees may be computed djrectly from the grammar and referenced by root and leftmost unexpanded node during the parse. Using these preconstructed trees , the incremental parser requires only a fixed number of operations to add a new word to a partial parse : a retrieval on a doubly indexed set , copying the left branching tree , and at most four structure changing operations +o paste words and trees together. Like Earley 's Algorithm , IP processes each word proportionally to sentence length. However on sentences satisfying a depth difference bound , the parsing time per word is constant. Because humans ca n't remember large numbers of sentence words but must , process speech at an approximately constant rate , a constant parsing time per ward is a necessary property of any algorithm model i ng human language processing. Let the depth of constituent C in phrase marker P be defined as the length of the path from the root of C to the root of P. If TI and T2 are tuo adjacent terminals with TI preceding T2. the depth difference from 11 to T2 is defined as the difference in depth between 11 and the root ~f the smallest tree containing TI and T2. For exarn~le in the phrase marker ( 9 ) ( S ( NP NP ( DET the ) ( N telephone ) ) [ PP ( PREP IN ) ( F ( P ( DET the ) ( N room ) ) ) ( V rang ) ( ADV loudly ) ) the depth difference between `` the '' and `` telephone '' ' is 1 and between `` roam '' and `` rang '' is 3. The depth difference between 11 and</definiens>
				<definiens id="1">the number of nodes from TI to the node expanded when adding T2 on a postorder traversal from TI in the partial phrase marker containing TI but not T2. The depth difference between TI and T2 also represents the number of constituents of which TI is the rightmost ward. A proof ( requiring a forma.1 def ini tion of the i ncremental parse ) that parsing time per word is constant in depth difference bounded sentences appears in [ lo ] . Informally the depth difference bound places a bound both on the number of next nodes to expand which may follow a given terminal and on the amount of tree traversal which the parser must perform to ffnd each next unexpanded node. Sfnce each modification requires only a fi'xed number of operati-ons , , each of which is bounded on the finite set of at most once cyclic left branching trees , the computation adding a new word to existing partial parses is bounded inde pendently of sentence length. Natural language sentences tend to have small depth differences. Both right branching sentences and left branching sentences ( found in Japanese for example ) have an average depth difference over each three or four word segment of two or less. On the other hand sentences are difficult to understand when they have two consecutive large depth differences , such as the mu1 ti ple center embedding ( 10 ) The rat the cat the dog bit chased diedb or the complex noun phrase in The pad on a clarfnet in the last row whicn 1 fixed earlier far Eb fe7l out. Furthermore in amhlguous sentences such as ( 11 ) Joe figured that it was time to take the cat out. Kimball observes that subjects prifer the reading with the smaller depth difference. Flnally , Blumenthal found that subjects tended to understand a multfple center embedded sentence as a conjunct1 ve sentence. The conjunctive sentence ~ontains a rearrangement. with lower depth differences of the constituents of the center embedded sentence. The syntactic form given to a sentence depends on the information being communicated in a sentence and on the cultural context in which the sentence appears. Clark and Haviland show that a speaker uses various syntactic devices sentences to place the `` given '' informatian known to the listener before the information `` new '' to the listener. Particular syntactic structures are also used to emphasize or suppress particular kinds of information ; for example newspaper traffic accident reports usually begin with a passive sentence such as ( 12 ) An elderly Lakewood man was injured when.. . , presumably to emphasize the result of the accident. To capture the dependence of syntax on semantic content and bocjal context , the sentence generator uses function-like grammar rules of the form ( Rul erame Cat Variables Predicate Forms ) . Rulename is the name of the rule and cat is the grammatieal category of the constituent generated by the rul em Variables is a list of formal parameters. Usually the variable list contains a varfable bound during rule execution to a node in a semantic network and another variable bound to a control association list containing information about the context in which the generated constituent will appear and possibly the syntactic form the constituent should have. Predicate is a Boolean-valued form on the parameters in Variables. A rule is used only when Predicate is true. Forms is a list of forms depending on Variables which generate terminals or calls to the grammar for subconstituerits of CAT. An example of a generation rule is ( SPI SI ( X Y ) ( Equal ( Voice Y ) ( Quote Passive ) ) ( NP ( Object X ) Y ) t Beverb X ) Pap ( Action X ) ) ( M* X Y ) ) which generates simple passive sentences. The variable X is bound to a node in a semantic network and Y to a control association list. The rule is applied only if the control alist contains a passfve flag and if the semantic node has an object and action ; in general a rule is applied only if the semantic subnodes called in the rule body appear in the semantic net. The form ( NP ( Obj X ) Y ) generates a form ( NP XI fl ) , where</definiens>
				<definiens id="2">the semantic node on the object indicator from X. and Yj3 fs the value of Y. Beverb and Pap are procedures which generate respectively a form ~f the verb `` to be '' and a past particfple form of the verb Action ( X ) . M* is a procedure which generates a list depending on X and Y such as ( PP~Value of Tlme ( X ) &gt; &lt; Value of Y &gt; ) for generating optional prepositi~nal phrases or relatf vc clauses</definiens>
			</definition>
			<definition id="6">
				<sentence>When the parser visits a syntactically complete constituent C , it applies a function INVERT to find the semantic preimages of C. In finding the semantic structure of C , INVERT has available not only the syntactic structure of C , but also the semantic preimages which it found for subconstituents of C. 'INVERT finds the set of generation rules which might proruce a constituent having the same syntactic form as C. For each such rule R. , INVERT constructs all the possible parings between each outputgenerating form F of R and the constituents of C which F might produce .</sentence>
				<definiendum id="0">'INVERT</definiendum>
				<definiendum id="1">INVERT</definiendum>
				<definiens id="0">available not only the syntactic structure of C , but also the semantic preimages which it found for subconstituents of C.</definiens>
				<definiens id="1">constructs all the possible parings between each outputgenerating form F of R and the constituents of C which F might produce</definiens>
			</definition>
			<definition id="7">
				<sentence>Each indicidual pair P in s-uch a pairing of a rule form and rule form outputs is processed by a function FIND which returns an association list containing possible values of the rule parameters ( X and Y in the example above ) which would produce the output appearing in P. For the example above FIND would produce ( X ( ( Object Man ) Y NIL ) ) ( 1 x ( ( rime past ) Y NIL ) ) ( ( X NIL ) ( Y ( ( Cases Nil ) ) ) ) .</sentence>
				<definiendum id="0">function FIND</definiendum>
				<definiens id="0">produce ( X ( ( Object Man ) Y NIL ) ) ( 1 x ( ( rime past ) Y NIL ) ) ( ( X NIL ) ( Y ( ( Cases Nil ) ) ) )</definiens>
			</definition>
			<definition id="8">
				<sentence>( ( X NIL ) ( Y ( ( Voice Passive ) ) ) ) Using an extension to association lists of the computational logic Unification Algorithm , these association lists are unified into a single association list , which for the example is ( ( X ( ( Agent man ) ( Time Past ) ( Action Injure ) ) ( ( Y ( ( Cases Nil ) ( Voice Passive ) ) ) ) Finally INVERT creates a grammar rule call , ( S ( ( Agent man ) ( Time Past ) ( Action Injure ) ) ( ( Cases Nil ) ( Voice Passive ) ) ) ) from the association list and stores the result in the inverse image of C. In finding a semantic preimaqe , the INVERT function must know which grammar rules might produce a parti cul ar grammati cal constf tuent .</sentence>
				<definiendum id="0">INVERT function must know</definiendum>
				<definiens id="0">a grammar rule call , ( S ( ( Agent man ) ( Time Past ) ( Action Injure ) ) ( ( Cases Nil ) ( Voice Passive</definiens>
			</definition>
			<definition id="9">
				<sentence>ETERM takes advantage of the similar syntax of most grammar rule forms , and is defined in simplified form ( with comments in angle brackets ) as Eterm ( form ) = if atom ( form ) then NIL &lt; terminates recurs ion &gt; else if car ( form ) is a grammatical category then list ( Ifst ( car ( form ) ) ) &lt; these forms generate a single grammar call &gt; elsa if car ( form ) = FUNCTION ar LAMBDA then ETERM ( cadr ( form ) ) else if car ( form ) = LAMBDA then ETERM ( caddr ( form ) ) else if car ( form ) = LlST if form is not properly contained in a LIST expression then Mapcar ( ( Function Concatenate ) ( Cartesian ( ( Mapcar ( Function ETERM ) cdr ( form ) ) ) ) &lt; outer LISTS are used to create lists of grammar calls &gt; else if farm Is inside e LIST expression ETERM ( cadr ( form ) ) &lt; inner lists are used to create grammatically &gt; else if car ( form ) = MAPCONC then make optional and repeatable all the nonterrninals returned in ETERM ( [ function argument of MAPCONC ] ) else if car ( form ) = COND then MAPCONC ( ( LAMBDA ( X ) ETERH ( [ last form in XI ) ( cdr form ) &lt; returns alternatives from each branch of the COND &gt; else if car ( form ) is a user-defined function then ETERM ( [ definition of function ] ) else if there is a stored value for ETERM ( form ) then that value else ask the the user for help The function FIND which returns possible bindings for rule variables when given a rule form and its output is defined below .</sentence>
				<definiendum id="0">ETERM</definiendum>
				<definiendum id="1">ETERM ( caddr</definiendum>
				<definiens id="0">takes advantage of the similar syntax of most grammar rule forms</definiens>
				<definiens id="1">if car ( form ) = LlST if form is not properly contained in a LIST expression then Mapcar ( ( Function Concatenate ) ( Cartesian ( ( Mapcar ( Function ETERM ) cdr ( form ) ) ) ) &lt; outer LISTS are used to create lists of grammar calls &gt; else if farm Is inside e LIST expression ETERM ( cadr ( form ) ) &lt; inner lists are used to create grammatically &gt; else if car ( form ) = MAPCONC then make optional and repeatable all the nonterrninals returned in ETERM</definiens>
				<definiens id="2">a stored value for ETERM ( form ) then that value else ask the the user for help The function FIND which returns possible bindings for rule variables when given a rule form</definiens>
			</definition>
			<definition id="10">
				<sentence>The variable AL1 , ST holds the value of the association list being hypothesized by FIND ; this variable is NIL when FIND is called from INVERT .</sentence>
				<definiendum id="0">ST</definiendum>
				<definiens id="0">holds the value of the association list being hypothesized by FIND ; this variable is NIL when FIND is called from INVERT</definiens>
			</definition>
			<definition id="11">
				<sentence>FIND ( Alist form value ) = if eval ( form a1 fst ) =val ue then l i st ( A1 ist ) else if recursion depth exceeded , then NIL else if atom ( form ) then list ( Merge ( list ( cons ( form Value ) ) Alist ) else if car ( form ) = COND let L = clauses which might be entered by evaluating form then Mapconc ( FM 1 ) where FM ( clause ) = list ( Merge Find ( Alist Car ( c1ause ) T ) Find ( Alist last ( clause ) ) ) else if car ( form ) = Quote then if cadr ( form ) = value then Alist else NIL else if car ( form ) is a defined function then FIND ( Alist ( Substitute cdr ( form ) for formal parameters in definition of car ( form ) ) Value ) else if car ( form ) = MAPCONC ( fn 1st ) then Me'rge ( Find ( Alist 1st value ) For each X in 1st .</sentence>
				<definiendum id="0">FIND</definiendum>
				<definiens id="0">cons ( form Value ) ) Alist ) else if car ( form ) = COND let L = clauses which might be entered by evaluating form then Mapconc ( FM 1 ) where FM ( clause ) = list ( Merge Find ( Alist Car ( c1ause ) T ) Find ( Alist last ( clause ) ) ) else if car ( form ) = Quote then if cadr ( form ) = value then Alist else NIL else if car ( form ) is a defined function then FIND ( Alist ( Substitute cdr ( form ) for formal parameters in definition of car ( form ) ) Value ) else if car ( form ) = MAPCONC ( fn 1st ) then Me'rge ( Find ( Alist 1st value ) For each X in 1st</definiens>
			</definition>
			<definition id="12">
				<sentence>Merge ( Alist for X ) ) &lt; this clause makes the assumption , which works in practice , that fn generates either one-element or empty lists , else NIL With a definition of FIND similar to the one above , the parser found the preimage ( 3 ( ( ( place ( ( class ( park ) ) ) ) ( agent ( [ class ( man ) ) ) ) ( action ( walked ] [ the extra parentheses den3te lists of alternatives ] for the sentence ( 13 ) The man walked in the park. generated by the grammar [ Sp S ( X ) T ( NP ( Agent X ) ) ( V ( Action X ) ) ( Optional ( PP ( Place X ) ( ( Case Place ] [ NPfl NP ( X ) T ( Det X ) t N ( Class XI [ ppa PP ( XY ) T ( Prep XY ) ( NPX ] and the preposition function Prep ( XY ) = Selectq ( Assoc CASE Y ) ( Place IN ) ( Instrument WITH ) ( Source FROM ] The processors described in this paper have been programmed in University of California , Irvine , LISP and run in about 45K on a PDP-10 computer. American Journal of Computational Linguistics Microfiche 33 : 33 Department of Computer Science University of Houston Houston , Texas 77004 ABSTRACT A theoretical model for nominal compound formation in English is presented in which the rul-es are representations of lexical processes. It is argued that such rules can be generalized to account for many nominal compounds with similar structure and to enable new compounds to be produced and understood. It is shown that nominal compounding depends crucially on the existence of a llcharacteristic '' relationship between a nominal and the vexb which occurs in a relative clause paraphrase of a compound which contains the nominal. A computer implementation of the model is presented and the problems of binding and rule selection are discussed. Linguistic Issues. Nominal compounds are sequences of two or more nominals which have the semantic effect of noun phrases with attached relative clauses. The rightmost nominal is generally i he primary referent of the compound the other nominals restrict the reference of the rightmost nominal in much the same fashion that a relative clause does. Tbeae are , of course , exceptions in which the rightmost nominal is figurative or euphemistic ( e.g. family jewels ) . Compounds occur frequently in English and Germanic languages , but infrequently in the Romance languages where their function is largely performed by nominal-prepositionnominal sequences ( e. g. chemin de fer , agent de change ) . __C The syntact kc structure nominal compounds is quite simple -- the three variants are NAN , N-participle-N , and N-gerund-N. In the N-N form , either 0 % the two nominals may in fact be yet another nominal compound , giving a structure like ( N-N ) -N or N- ( N-N ) ; the first of these forms seems to occur much more often than the second ( examples of each type are : typewriter mechanic , liquid roach poison ) . I assume that the process of nominal compounding is syntactically a process in which a relative clause is reduced by deleting all elements of the relative clause but one and preposing the single remaining element in front of the antecedent nominal. In addition , the clause verb may be nominalized 4nd preposed. Other linguists have proposed different derivations for nominal compounds ; Lees [ 3 ] , for example , derives nominal compounds from nominal-preposition-nominal sequences. There are two reasons why I feel that Lees approach is wrong : ( 1 ) there are English compounds for which no reasonable equivalent nominal-prepos it ionnominal paraphrase can be given ( e.g. windmill ) , and ( 2 ) there are subtle meaning differences between the nominal compounds and their nominal-preposition-nominal counterparts ( county clerk vs. clerk for the county ) . If nominal compounds and nominal-preposition-nominal sequences are derived from forms like relative clauses , then the differences in meaning can be accounted for by deriving each form from a distinct relative clause ; the relative clauses may , of course , be quite closely related to each other. I have spoken rather loosely about deriving nominal compounds from relative clauses ; I am not proposing a derivation system which operates on surface forms of the language , and what I intend that the reader should understand is that an underlying form for a nominal compound is derived from an underlying form for a relative clause by a language process which I term a lexical rule because , as we shall see , the operation of such rules depends crucially on the specific lexical items which are present in the underlying structures. Linguists have identified a number of lexical processes in English ; some examples of such processes may be found in [ I ] and [ 2 ] . The underlying forms associated with relative clauves and nominal compounds in the model of nominal c om pounding being presented here are networks ( trees for the most part ) defined in terms of a case grammar which is closely related to that used by Simon8 [ 51. The cases which appear in this system fall into two general categories : ( 1 ) cases of the clause verb , which are the following -Performer , Object , Goal , Source , Location , Means , Cause , and Enabler -and ( 2 ) structural cases , which are REEL ( relative clause ) and COMP ( compound ) . I will not explain these cases in detail , as that is the subject of a forthcoming paper. But the following observations will illuminate the case system for verb cases. The case system distinguishes the immediate performer of an act from a remote cause or agent of the act. The reason for this distinction lies in an intimate connection between verbs and the assumed or habitual performer of the act which is the reference of the verb. The case system also distinguishes an active causative agent of an act from an agent which merely permits thk act to occur ; this distinction in the case system permits two classes of verbs to be distinguished according Po whether the surface subject commonly causes the act or permits the act to occur. The case system used in the present model of nominal campounding is not a deep case system ; on the contrary , it Seems that nominal compounding is a lexical process which occurs rather near the surface in a derivatidnal grammar model. An example which can be given to support this is the compound ignition key ; this is a key Vhich turns a switch which enables a complex sequence of events to take place that ultimately result in the ignition of a fuel/air mixture in an engine , ar one may describe it equivaaently as a key which causes ignition. The first aescription corresponds to a deep case level of description while the second corresponds to the level at which the compound ignition key is formed. I would argue tHat if one takes the deep case approach , then one is forced to include a great deal of structure in the rules for nominal compounding ; in particular , the rule for ignition key must remove all af the links in the causal chain leading to the ignition act. The deletion of this intermediate information mast be done to obtain the description given in the second case , and to include the deletion procedure in both a compounding rule and in the rule process which leads to the shorter description means unnecessarily duplicating the procedure. Moreover , if one derives compounds from paradigm relative clauses of the second sort , e.g. key which causes an action to occur , then it is possible to generalize compound forming rules so that a siqgle rule may produce several compounds. It will not be possible to do this if deep cases are used as the deep case structure of firing key will be quite different from that of ignition key. In order tb understand the model of compounding whfch is being presented here , it is essential to consider the function of wmpounding in language. In my view , compounding is a process which allows a speaker to systematic8lly deLete information from an utterance just when the speaker has reason to expect that the hearer can reconstruct that information. In effect , I consider compounding ( and a great many other linguistic procesbes ) ro be examples of linguistic encoding which are used to speed up communication , and the grammar shared by the speaker and hearer must include the encodihg and decoding functions. Consider the nominal compound steam distillation , which refers to the distillation of same substance with steam ; the hearer of the compound steam distillation knows that distillation is the derived nominal form of distill. The hearep also knows what the common or characteristic cases of the verb distill are : the agent is invariably a person or machine ( this would be the occupant of the Cause case slot in my system ) , the instrument ( or Means ) may be an apparatus or a heated medium such as steam and the Goal is a liquid which is missing some of the constituents that it entered the distillation process with. It happens that in English , whenever a , derived nominal of an act is the right element in a compound , then the left element is almbst always an occupant of one of the case slots of the verb. In order to recreate the underlying relative clause structure , it is only necessary for the hearer to properly choose the case for the nominal steam. A great deal of lexical information can be brought to bear on this question ; for example , steam is not a liquid , is water vapor and thus can not substance or the end product of a distillation process. Steam might be the Cause of the act of distillation except that there do not seem to be any compounds in English which have distillation as the right element and a Cause as the left element. Thus the hearer can assign steam to the Means case with some assurance. In another example , shrimp boat , the hearer can ascertain by lexical relations involving the word boat , that boats are characteristically used to catch marine life. One choice eor the main verb in a synonymous relative clause is catch , which will have boat as an element of the Means case. The Cause for catch is commonly a person or perhaps a sophisticated machine designed to oatch things ( i.e. a trap ) . The Object-is characteristically an animal. There is a strong characteristic relation between the animal being caught and the means used to catch it , for example mink is trapped , calves are roped , birds are netted , and fish are caught with a boat. This relation exists as a rule in the lbxfcon of both the speaker and the hearer and it enables the speaker to produce the nominal compound and the hearer to understand it. Furthermore , shrimp boat is one member of a class of closely related nominal compounds whioh includes lobster boat , whale boat tuna boat and many others. It would be most - ' interesting if a single rule could be formulated which would generate all of these cqpounds. A lobster boat is a boat which is used to catch lobster , a tuna boat is a boat which is used to catch tuna , and so forth. All of these examples are identical except for the particular marine animal being caught. The logical next step is the creation of a rule which generalizes the individual marine anfmals to the cbmmon category of marine animal. This rule fill state that a marine animal boat is a boat which is used to catch marine animals , In making this generalization , I have given the rule the power to help interpret novel compounds and to generate them. With this power comes a difficulty , Which is constraining the rule so that it does not generate bad compounds or produce incorrect interpretations. The key to this constra'int lies in what I will term the characteristic or habitual aspect of nominal compomds. In the case of the boat compounds , a boat will only be a shrimp boat if it is characteristically , usually , habitually or invarfably used to catch shrimp. So the operation of a compounding rule is enabled only if a characteristic aspect is associated with the verb ; in English , this is usually indicated by an adverb or an adverbial phrase. If the speaker is willing to assert that a boat is characteristically used to catch turtles , then the nominal compound turtle boat may be used. The hearer sill use the general rule to place turtle and boat in the proper case slots , and because a compound was used by the speaker , the hearer will infer Qhat the boat is one which is characteristically used to catch turtles , There are other problems which arise with the generalization of rules ; for example , compounding never produces a compound in which the lert element is a proper noun , unless the proper noun ie the name of a process ( e.g. Harkov process ) or is a Source , Performer , or Goal of an act of giving. It also seems to be true that compounds are not generally formed when a lexical item is several levels below the general term which appears in the rule ( e.g. repaimidget ) or when a cross-classificatory term is used ( e.g. automobile Indian as an Indian who repairs automobiles ) . With all of the preceding discussion in mind , I would now like to turn to the model of nominal compounding which I have presently implemented and running. The Computer Model The computer model of compounding accepts relative clause structures as input and produces nominal compound structures as output when the input is appropriate. It is written in a language with many parentheses the language was chosen for its program development facilities , i.e. built-in editor , rather than for its interpretive capabilities. The program which produces nominal compounds is a pattern matching interpreter ; it applies a rule of compound formation by matching one side of the rule with the input structure , and if certain criteria are satisfied by the match , items from the input structure are bound into the rule , transferred to the other side of the rule , and a copy is then maae af the other side of the rule. The result is a nominal compound structure. The model has two components : a rule interpreter and a lexicon of rules for compounding. There is nothing tricky about rule application. Consider the nominal compound flower market and its associated relative clause paraphrase market where flowers are characteristically sold. These phrases have in my system the underlying structures shown in Figure 1. The notation in square braces means that the verb sell has the characteristic aspect in this instance. market I RELCL sell [ +char ] m / \Jmarket flowers Figure 1. market flower These two structures can be made into a rule by linking them together. Whenever a relative clause structure identical to that in Figure 1 is received , the rule applies and a copy is created of the nominal compound flower market. The matching procedure is a relatively straightforward , top down , recursive process which has backtracking capability in the event that a structure or case occurs more than once at any given level of the structure. There are two problems which arise ; however : if e rule is generalized to account for compounds other than flower market , then the lexical items in the rule will behave as variables and some provisions must be made for binding of values to these variables ; also , the rule interpreter must have some heuristics for selecting appropriate rules if the time required to produce a compound is not to increase exponentially with the size of the lexicon. The present version of the model only partly solves the binding problem. Consider the rule given in Figure 2 which is a generalization of that given in Figure 1. market I sell [ +char ] LOC market goods market I COW goods Figure 2. If this rule is to apply to the relative clause structure glven in Figure 1 and generate the compound flower market , then the rule interpreter must recognize that the relative clause in Figure 1 is an instance of that given in Figure 2. The matching procedure does this by determining that the reference set of the nominal flowers is a subset of the reference set of the nominal goods. In addition , the nominal flowers must be carried across to the other side of the rule and substituted there for goods before the other side of the rule is copied. Thus market and goods must be bound across the rule so that whatever lexical item matches either of these nominals becomes the value associated with these nominals on the other side of the rule. In the initial version of the model , this binding was established explicitly when the rule was entered into the lexicon , but this seemed unsatisfactorily ad hoc. In a subsequent version , -the identity of the lexical items on both sides of the rule was the relation used to establish binding relationships. Consider , however , the structure shown in F : Lgure 3. person I RELCL steal [ +char ] PERF/ \ OBJ person valuables Figure 3 thief Here person should be bound to thief but the previous technique is not able to establish this binding. The reason that we know that person and thief should be bound is because we know that a thief is a person who steals characteristically. In the most recent version pf the model , this information is used to find the binding relationships when the rule of identity doe $ not work. The lexicon is searched for a rule which can be used to establish this bindiag. The rule which is used in the example shown in Figure 3 is displayed below in Figure 4. person I RELCL thief steal [ +char ] I PERF person Figure 4 From the structures given in Figure 4 , one can see that person shduld be bound to thief because the rule states that the reference set of thief is the same as the reference set of person as restricted by the relative clause. The technique of using lexical rules to establish bindings works in virtually every instance , but it has the defect of requiring that the information that a thief is a person who steals things be represented in the lexicon twice at least. A new model is under construction which attempts to reduce this redundancy by allowing the rules to have multiple left and right parts. The problem of selecting appr~priate rules is rather easier to solve. In most compounds in English , there is a characteristic association between the right element of the nominal compound and the main verb of the associated relative clause paraphrase. These two elements which occur on opposite sides of the compounding rule supply a great deal of information about the possibilities for application of the rule. So , in the model , each rule in the lexicon is indexed by the main verb of the relative clause and by the right element of the nominal compaund. This index actually contains some environmental information as well ; for the clause verb , this environmental information is the case frame of the verb and the fact that it is the main verb of the relative clause -for the compound nominal , the environmental information is just the fact that the nominal is the rightmost one in a nominal compound. The basic model has been tested with a set of several hundred nominal compounds and is very successful in coping with a wide vqriety of compound types. The productivity of the rules varies greatly ; some rules may produce hundreds of compounds while other rules may only result in one or two compounds. Frozen forms such as keel boat are handled by a rule which generates only one compound ; there is a rule for each frozen form. The rule structures contain exclusion lists associated with each lexical item in the rule , and these exclusion lists prevent the rule from operating whenever a lexical item matches one Of the items on an exclhsion list if the items occur at corresponding locations in the structures. The model is quite quick in operation ; on a high speed dibplay console , it will generally produce compounds much faster , than a person sitting at the console can conveniently read them. vi~ is mainly due to the rule selection heuristic , but the match procedure has been carefully optimized as well. Conclusions The model program is an excellent demonstration of the appropriateness of the basic theory ; moreover , the rules themselves can be generalized to deal with syntactic processes , so there is no discontinuity in the grammar model between the lexical processes and the syntactic processes. It seems clear that the rules could also be used to represent other lexical processes in language and this is currently being pursugd. There is no reason why the rules could not be used for recognition as well as for the production of nominal compounds. The bindings are not one-way , and the matching procedure will work equally well for compound structures. The reasons why the computer model is a production model are : ( 1 ) that the computer model assumes the semantic correctness of the input relative clause structures , and ( 2 ) that compounds are often ambiguous and may be paraphrased by two or more relative clauses , while the converse of this is almost never true. A recognition model would have to generate underlying relative clause structures for each ambiguity and a semantic component would have to~screen the relative clauses for semantic errors. I hope that the reader has noticed the avoidance of rule procedures in this model. When I began working on the design of the computer programs , I had in mind the creation of a model which once implemented in LISP could be extended merely by adding new ~ules without having to construct any additional LISP programs. I ultimately wanted to have a model which could lllearntl new rules by systematic generalization and restriction of existing rules. I feel that this would be relatively easy with rule structures and extremely difficult with rule procedures written in a programming language. Furthermore , I subscribe to Karl Popper 's icfeas of scientific endeavour , and rule structures appealed because it would be more difficult to bury flaws or ill understood aspects of compounding and rule processes in structures than in procedures where the computational power of the programming language permits and even encourages -ad hoc solutions to be found to problems. Acknowledgements I would like to here acknowledge the suggestions made by Robert F. Simmons , Carlota Smith , Mary Boss T. Rhyne , Uurent Siklossy , and Stanley Peters which have helped tsprbve my understanding of nominal compounding. American Journal of Computational Linguistics Microfiche 33 : 45 Computer Science Department Indiana University Bloonlington 47401 ABSTRACT Generation of English surface strings from a semantic network is viewed as the creation of a linear surface string that describes a node of the semantic network. The form of the surface string is controlled by a recursive augmented transition network grammar , which is capable of examining the form and content of the semantic network connected to the semantic node being described. A single node of the grammar network may result in different forms of surface strings depending on the semantic node it is given , and a single semantic node may be described by different surface strings depending on the grammar node it is given to. Since generation from a semantPc network rather than from disconnected phrase markers , , the surface string may be generated directly , left to right. Introduction In this paper , we discuss the approach being taken in the Engllsh generation subsystem of a natural language understanding system presently under development at Indiana University. The core of the understander is a semantic network processing system , SNePS ( Shapiro , 1975 ) , which is a descendant of the MENTAL semantio subsystem ( Shapiro , 1971a , 1971b ) of the MIND system ( Kay , 1973 ) . The role of the generator 13 to describe , in English , any oP the nodes in the sernantjc network , all of which represent concepts of the understanding aystem. 46 and other computations are ~equired in the process of pasting these trees tog ther in appropriate places until a 'single phrase marker Is attained which will lead to the surface string. Since we are generating from a semantic network , aL1 the pasting together is already done. Grabbing the network by the node of interest and letting the network dangl-e from it gives a structure mich may be searched apppogriately in order to generate the surface strfng directly in left to right fashion. Our system bears a superficial resemblance to that described fn Simmons and Slocum , 1972 and in Simmons , 1973. That system , however , stores surface information such as tense and voice in its semantic rietwork and its ATN takes as input a linear list containing the semantic node and a generation pattern consisting of a `` series of constraints on the moclalltyfl ( Simmons et al. , 1973 , p. 92 The generator d.escribed in Schank et al. , 1973 , translates from a `` conceptual structuref1 into a network of the form of Simmons ' network which is then given to a version of Simmons generation program. The two stages use different mechanisms. Our system amounts to a unificatio of these two stages. The generator , as described in this pager , as well as SNePS , a parser and an inference mechanism have been written in LISP 1.6 and are running Interactively on a DEC system-10 on the Indiana University Computing Network. Representation in the Semantic_Network Conceptual information derived from parsed sentences or deduced from other information ( or input directly via the SNePS user 's language ) is stored in a semantic network. The nodes in the network represent concepts which may be discussed and reasoned abaat. The edges represent semantic but non-conceptual binarx relations between nodes. There are also auxiliary nodes which SNePS can use or which the user can use as SNePS variables. ( For a more complete diecussion of SNePS and the network nee Zhapiro , 1975. ) The semantic network representation being used does not in47 olude information considered .t.6 be features of ' the surface string such as tense , voice or main vs. relative clause. Ihstead of tense , temporal information is stored PeIative to a growing time line in a manner similar to that of Bruce , 1972. From this information a tense can be generated for an output sentence , but it may be a different tense than that of the original input sentence if time has progressed iri % he 5nterim. The voice of a generated sentence is usually determined by the top level call to the generator function. However , sometimes it is determined by the generator grammar. For example , when generating a relative clause , voice is determined by whether the nodn being modified-is the agent or object of the action described by the relative clause. The Main clawe of a generated sentence depends on which semantic node is given to the generator in the top level call. Other nodes connected to it may result in relative clauses being generated. These roles may be reversed in other top level calls to the generator. The generator is driven by two sets of data : the semantic network and a grammar in the form of a recursive augmented transition network ( ATN ) similar to that of Woods , 1973. The edges on our ATN are somewhat different from those of Woods since our view is that the generator is a tranducer from a network into a linear string , whereas a parser Is a transducer from a linear string into a tree or network. The changes this entails are discussed below. During any point in generation , the generator is working on some particular semantic node. Functions on the edges of the ATN can examine the network connecteb to this node and fail or succeed accordingly. In this way , nodes of the ATN can `` decide '' what surface form is most appropriate for describing a semantic node , while different ATN nodes may generate different surface foI ? ms to describe the same semantic node. A common assumption among linguists is that generation begin3 with a set of disconnected deep phrase markers. Trnnuf o~-matlon~ LEX Fizure 1 : Semantic Network RepresentatLon for `` Charlie believes that a dog kissed sweet young Lucy , '' `` Charlie is a person , '' and `` Lucy is a person. , .Af=rmation considered to be features of surface strings are not stored in the semantic network , but are used by the parser in constructing the network rrom the input sentence and by the generator for generating a surface string from the network. For example , tense is mapped into and from temporal relations between a node representing that some action has , is , or will occur and a growing time line. Restrictive relative clauses are used by the parser to Identify a node being discussed , while non-restrictive relative clauses may result in new information being added to the network. The example used in this paper is designed to illustrate the generation issues being discussed. Although it also illustrates our general approach to representational issues , some details will * ( SNEG MOOLb ) ( CHARLIE IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY ) , * ( SNEG M0023 ) ( A DOG KISSED SWEET YOUNG LUCY ) * ( SNEG M0007 ) ( CHARLIE WHO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY ) `` ( SNEG i4OOd ; j ( CHARLIE IS A PERSON WXO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY ) * ( SNEG M0006 ) ( CHRRLIE~WHO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY IS A PERSON ) ( SNEG M0008 ) ( THE BELJEVING THAT A DOG KISSED SWEET YOUNG LUCY BY CHARLIE ) * ( SNEG M0011 ) ( A DOG WHICH KISSED SWEET YOUNG LUCY ) * ( SNEG ~0OlOj ( THAT WHICH KISSED SWEET YOYNG LUCY IS A DOG ) * ( SNEG M0012 ) ( THE KISSING OF SWEET YOUNG LUCY BY k DOG ) @ ( SNEG M0020 ) ( SWEET YOUNG LUCY WHO WAS KISSED BY A DOG ) * ( SNEG M0014 ) ( LUCY IS A SWEET YOUNG PERSON WHO NAS KISSED BY A DOG ) * ( SWG M0015 ) ( SWEET YOUNG LUCY HH3 WAS KISSED BY A DOG IS A PERSON ) * ( SNEG M0017 ) ( SWEET LUCY WHO WAS KLSSED BY A DOG IS YOUNG ) * ( SNEG M0019 ) ( YOUNG LUCY WHO WAS KISSED BY A DOG IS SWEET ) Figure 2 : Results of calls to the generator with nodes from Figure I* User input is on lines beginning with *. certainly change as work progresses. Figure 1 shows the semantic network representation for the information in the sefitencesb , `` Charlie believes that a dog kissed sweet young Lucy , '' `` Charlie is a person , '' and `` Lucy is a person. '' Converse edges are not shown , but in all cases the label of a converse edge is the label of the forward edge with '* ' appended exoept for BEFORE , whose converse edge is labelled AFTER. LEX pointers point to nodes containing ; lexical entries. STIME points to the starting time of an action and ETIME to its ending time. Nodes representing instants of time are related to each other by the BEFORE/AFTER edges. The auxiliary node NOW has a : VAL pointer to the current instant of time. Figure 2 shows the generator 's output for many of the nadcs of Figure 1. Figure 3 shows the Lcxicon uncd in the example. ( BELIEVE ( ( CTGY.V ) ( I~BELIEVE ) ( PRES.BELIEVES ) ( PAST.BELIEVED ) ( PASTP.BELIEVED ) ( PRESP.BELIE~JING ) ) ) ( CHARLIE ( ( CTGY . NPR ) ( PI . CHARLIE ) 1 ' ) ( DO~ ' ( ( CTQY.N ) ( SING.DOG ) ( PLUR.DOGS ) ) ) ( K~SS ( ( CTGY .v ) CINF.KISS ) ~PRES.KISSES ) ~PP.ST.KISSED~~PASTP.KISSED ) ( PRESP.KISSING~~ ) ( LUCY- ( ( CTGY.NPR ) ( PI.LUCY ) ) ) ( PERSON ( ( CTGY.N ! ( sING.PERSON ) ( PLUR.PEOPLE ) ~~ ( SWEET ( ~CTGY.ADJ ) ( PI.SUEET ) 1 ) ( YO~NG ( ( CTGY.ADJ ) ( PI.YOUNG ) ) ) Figure 3 : The lexicon used in the example of Figures 1 and 2. Generation as Parsing Normal pa~sing involves taking input from a linear string and producing a tree or network structure as output. Viewing this in terns of an ATN grammar as described in Woods , 1973 , there is a well-defined next input function which simply places successive word6 into the** register. The output function , however , is more complicated , uslng BUILDQ to build pieces of trees , or , as in our parser , a BUILD function to build pieces of network. If we now consider generating in these terms , we see that there is no simple next input function. The generator will focus on some semantic node for a while , recursively shifting its attention to adjacent nodes and back. Since there are several adjacent nodes , connected by variously labelled edges , the grammar author must specify which edge to follow when the generator is to move to another semantic node. For these reasons , the same focal semantic node is used when traversing edges of the grammar network and a new semantic node isspecified by gl , ving a path from the current semantic node when pushing to a new grammar node. The register SNODE is usedto hold the current semantic node. The output function of generation is straightforward , simply being concatenation onto a growing string. Since the output string is analogous to the parser 's Input string , we store it in the reggarc : : = ( TEST test [ action ] * ( TO gnode ) ) ( JUMP [ action ] * ( TO gnode ) ) ( mM wform ( wqrd* ) test [ action ] * ( TO gnode ) ) ( NOTMEM wform ( word # ) test [ action ] * ( T~ gnode ) ) ( TRANSR ( [ regname ] regname regname ) test [ action ] * ( TO gnode ) ) ( GEN gnode sform [ action ] *regnarne [ action ] * ( TO gnode ) ) sform : := wform SNODE wform : : = ( CONCAT f~~m form* ) ( GETF sarc [ aform ] ) ( GETR re gname ) ( LEXLOOK lf e at [ sf orm ] ) sexp form - : : = wform sform act ion : : = ( SETR regname f om ( ADDTO regname form* ) ( ADDON regname f om* ) sexp test : : ( MEMS form form ) ( PAT23 sform sarc* sform ) form sexp gnode : : = &lt; any LISP atom which represents a grammar node &gt; word : : = &lt; any LISP atom &gt; regname : := &lt; any non-numeric LISP atom used as a register name &gt; sarc : := &lt; any LISP atom used as a semantic arc label &gt; lfeat : : = &lt; any LISP atom used as a lexical feature &gt; sexp : : = &lt; any LISP s-expression &gt; Figure 4 : Syntax of edged of generator ATN grammars ister * .</sentence>
				<definiendum id="0">Merge</definiendum>
				<definiendum id="1">Class XI [ ppa PP ( XY ) T ( Prep XY )</definiendum>
				<definiendum id="2">Place IN )</definiendum>
				<definiendum id="3">Goal</definiendum>
				<definiendum id="4">matching procedure</definiendum>
				<definiendum id="5">Stanley Peters</definiendum>
				<definiendum id="6">`` Lucy</definiendum>
				<definiendum id="7">`` Lucy</definiendum>
				<definiendum id="8">LISP atom</definiendum>
				<definiens id="0">works in practice , that fn generates either one-element or empty lists</definiens>
				<definiens id="1">a nominal and the vexb which occurs in a relative clause paraphrase of a compound which contains the nominal. A computer implementation of the model is presented and the problems of binding and rule selection are discussed. Linguistic Issues. Nominal compounds are sequences of two or more nominals</definiens>
				<definiens id="2">the reference of the verb. The case system also distinguishes an active causative agent of an act from an agent which merely permits thk act to occur</definiens>
				<definiens id="3">a key Vhich turns a switch which enables a complex sequence of events to take place that ultimately result in the ignition of a fuel/air mixture in an engine</definiens>
				<definiens id="4">a person or perhaps a sophisticated machine designed to oatch things</definiens>
				<definiens id="5">a boat which is used to catch marine animals</definiens>
				<definiens id="6">characteristically used to catch turtles , There are other problems which arise with the generalization of rules</definiens>
				<definiens id="7">a Source , Performer , or Goal of an act of giving. It also seems to be true that compounds are not generally formed when a lexical item is several levels below the general term which appears in the rule ( e.g. repaimidget</definiens>
				<definiens id="8">a pattern matching interpreter</definiens>
				<definiens id="9">an excellent demonstration of the appropriateness of the basic theory</definiens>
				<definiens id="10">45 Computer Science Department Indiana University Bloonlington 47401 ABSTRACT Generation of English surface strings from a semantic network is viewed as the creation of a linear surface string that describes a node of the semantic network. The form of the surface string is controlled by a recursive augmented transition network grammar , which is capable of examining the form and content of the semantic network connected to the semantic node being described. A single node of the grammar network may result in different forms of surface strings depending on the semantic node it is given</definiens>
				<definiens id="11">a semantic network processing system</definiens>
				<definiens id="12">stores surface information such as tense and voice in its semantic rietwork and its ATN takes as input a linear list containing the semantic node and a generation pattern consisting of a `` series of constraints on the moclalltyfl ( Simmons et al. , 1973</definiens>
				<definiens id="13">DEC system-10 on the Indiana University Computing Network. Representation in the Semantic_Network Conceptual information derived from parsed sentences or deduced from other information ( or input directly via the SNePS user 's language ) is stored in a semantic network. The nodes in the network represent concepts which may be discussed and reasoned abaat. The edges represent semantic but non-conceptual binarx relations between nodes. There are also auxiliary nodes which SNePS can use or which the user can use as SNePS variables. ( For a more complete diecussion of SNePS and the network nee Zhapiro</definiens>
				<definiens id="14">usually determined by the top level call to the generator function. However , sometimes it is determined by the generator grammar. For example , when generating a relative clause , voice is determined by whether the nodn being modified-is the agent or object of the action described by the relative clause. The Main clawe of a generated sentence depends on which semantic node</definiens>
				<definiens id="15">the semantic network and a grammar in the form of a recursive augmented transition network</definiens>
				<definiens id="16">a person , '' and</definiens>
				<definiens id="17">not stored in the semantic network , but are used by the parser in constructing the network rrom the input sentence and by the generator for generating a surface string from the network. For example , tense is mapped into and from temporal relations between a node representing that some action has , is , or will occur</definiens>
				<definiens id="18">CHARLIE IS A PERSON WXO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY ) * ( SNEG M0006 ) ( CHRRLIE~WHO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY IS A PERSON ) ( SNEG M0008 ) ( THE BELJEVING THAT A DOG KISSED SWEET YOUNG LUCY BY CHARLIE ) * ( SNEG M0011 ) ( A DOG WHICH KISSED SWEET YOUNG LUCY ) * ( SNEG ~0OlOj ( THAT WHICH KISSED SWEET YOYNG LUCY IS A DOG ) * ( SNEG M0012 ) ( THE KISSING OF SWEET YOUNG LUCY BY k DOG ) @ ( SNEG M0020 ) ( SWEET YOUNG LUCY WHO WAS KISSED BY A DOG ) * ( SNEG M0014 ) ( LUCY IS A SWEET YOUNG PERSON WHO NAS KISSED BY A DOG ) * ( SWG M0015 ) ( SWEET YOUNG LUCY HH3 WAS KISSED BY A DOG IS A PERSON ) * ( SNEG M0017 ) ( SWEET LUCY WHO WAS KLSSED BY A DOG IS YOUNG ) *</definiens>
				<definiens id="19">a person , '' and</definiens>
			</definition>
			<definition id="13">
				<sentence>TEST ( GETF OBJECT ~PREDOBJ ) UMP cpmDAm GEN KLNP ( GETF AGENT ) REG ( ADDON * ( GETR 'REG ) ) CpRGDOB3 GEN NCLNP ( GETF OBJECT ) REG ( ADDON * ( GETR REG ) ) I Figure 9 : Generating the surface object .</sentence>
				<definiendum id="0">TEST ( GETF OBJECT ~PREDOBJ ) UMP cpmDAm GEN KLNP</definiendum>
				<definiens id="0">Generating the surface object</definiens>
			</definition>
			<definition id="14">
				<sentence>SNODE ) CLASS ( FIND LEX PERSON ) ) ) is a call to a SNePS function that determines if the object is known to be a person , in ~hich case `` WHO '' is used rather than `` 'WHICHft .</sentence>
				<definiendum id="0">SNODE ) CLASS</definiendum>
				<definiens id="0">a call to a SNePS function that determines if the object is known to be a person</definiens>
			</definition>
			<definition id="15">
				<sentence>nDJs7JUMP ( SETR ADJS ( GETF WEICH* ) ) Figure 13 , : The network for generating a string of adjectives .</sentence>
				<definiendum id="0">nDJs7JUMP ( SETR ADJS</definiendum>
				<definiens id="0">The network for generating a string of adjectives</definiens>
			</definition>
			<definition id="16">
				<sentence>TNTRQDUCTXON It computer6 rtr to canmonicrtr eftretlvcly with people , they nust spark , or at irart write , the urcr*r nrtur61 Language , The bulk ot the work in co~pytatlonrl Llnguilticr has been drvotrd to computer undcrstandlnq of natutal language input # but relatively littie rtfo &lt; rt ha8 been e % pend @ d in developin $ natural Language output. Mort Enplirh output systems hrve been along the line of nfill In the blanku with Perhap &amp; soma semantic cenrtrrint6 imporad ! thera have bean few attempts at language generation from what one could crLl wsamrntic netR structures [ 8g @ aon8 and 8locua , 1972 ; Sloeuar 1973 ; Goldman , 19741 , PeFh &amp; p @ generation is canrldered a much aasisr problem , The ruccrrr of understanding efforts ir generally bclisvtd to drprnd on rome warkrble theory of Rdlrcaurrr 6rganlzatlonc which would rccbunt gar affect8 of context and would ahow how iniphoric ~~pren8l~ns ( pronoun # and noun phrases ) are resolved and how # rnt*nCeS rro order84 tn the bUtPUtr As tt hrppdnot there m @ chanlr @ r are pr~L # *lY those that r wrr8ponre g~nerrtor~ must Incorporate it it 1s to appear Lntrlligent. Tha lrtudy of qrnrtrtion rill play an important rots in rolving the problem of undrrttandino if it ern draonrtrrte &amp; mapping t~om derp ramantic rtrUctura6 to rutface rtrtngr , bet ua briefly outlina gome relevant preccrrrs in the # peach understanding system bring drYcL0~1d by 8RI and SDC ( Walker at a1.t 1915~ and Rite. , 1915 ) . The urar inltlatrs rrrrton by rrtrblirhtng conmunLc~tion with the ryrtrmf all subarqurnt dialog ( input and output ) is manlter @ d by a Wdircaurae madula8 ( Dautacb , 11975 ) to maintain rn accurate ca~ntrerskition41 context , An exeeuttvc eserdinata # variaur Knarladge sauxcos 4cWrti~r prosodic , syntactic , r~mrntie , pzagmrtlc , and di~eeurrc to Bunderotrnbw cuccersivt utt @ rane @ rr The analyzed UttaFlnge iQ then Pas8rB la ZRa `` resPandarw PBItll another eamponrnt of the dileaurtc module. The responder may call the pucrtlonransrcrrr it the lnput ir a question ! it may call 4 data bead update Program It ths input is r otatcmant of fact1 or it may drcldr an romc other rppropriatc reply. Tha content ab the r @ DpDnD @ Is prrora to the gsnaratar~ perhapa # i $ h Some tndicrtian of hsa it is to be tarmulat @ ds TRa reply may bs a rtsrcatypsd rsrpsnss ( wy @ 8Bp `` noM , `` 1 @ e @ C ) I noun phrars ( nodel , r o @ nt+nes ( verb node ) r Orr e~~ntu111y~ a paragraph , The qen~PaQ~r outputs stettotyped raspanreg Pmmed $ atslyt if ! the rcrpanrr ir nor @ complicated [ a `` nounB nab @ , *verbR nads , ar rvcnturlly r nrtwork ) , r mbrr detallcd proptam ir ragulrcd. This program nbLl dctrrmina exactly how the responge is ts bs bormulrtad ma &amp; g NBI 61 OH teqUIRCQ 8f St ! it may bb ~d~~lr6d to Chooag Verb @ and noun @ with which to @ Xgs @ @ @ the deep ClSc nae ctructurrr , rr wall r8 a ryntaetlc from. for the genaration. The g~narator P~O~UCII tha rrrponrr in wfrxtw form1 thir in turn ir p &amp; gsad to a B~OIC~ tynthrllr program tar trrnrtarmatlon and cutput by r comn @ rCial VOTRAX rprach rynthe~izar. Curr~ntly no IsntQner intenstion sr rtr~as con % sWing i~ being p @ rt~rmed , 8tnea the major Bntmsost at this papsr it in `` textH ganaratlane further reference to the synfhcrlg rtrp rill be meden CQNSTRAXNTS Or ? RESPONDING There are several censLdcr8tianr involved in responding appropriateby to an utterance. First , therc are *conver : ctlanal Po~tUl &amp; te # '' ( Gordon and Lakoff , 19751 8harsd by the u6ers a£ e Lanuurprt there pottu2ater serve to canstrain the content and form of ca~~unicationr from the speaker to the heerare For instance , the rperker should not tall the hearer re~sthing the hearer all @ &amp; dy knows , lcrt he be bore61 yet the speaker can not tell the hcarer samething the hearer knows ab~olutely nathlnq about , or the hearer rlll not comprehend. The ggenkee chould relate knt ncwa in his marsaga to the prtor knowledgs of the hearer ; this requires the rperkcr te have ti model of ! the haarcf There heuristic6 murt operate in canjunctbon w~th c w~~c~~nc~ producerw to constrain what may be output by a q~entcncen generatore We are only beginning to understanG how to lncorparrtt there partuiater in a languagc groce6~bng kygtcm , Then there Is the matter of con8tructlng the batic sentence Normal English ryntax rcquirrr at ltaat ant verb In the santcncaf chooring a mrln verb constrains the rurfdct Rtructure , For inltrncer in thr rblcncr of campounds any verbs other than the main vwb will have to appear in another Fornr nominal , infinitive , gerundr p~rtLcIpL @ ~ or subordinate Cfauce , How daec the relevant fnfarmatlon centaintd In &amp; gementic net Indicate tha rpproprlate farm ? The traditlondl answer Is `` by meann of tht laxiC0nrU We will QXplorQ the relationship between net @ r~d lexicon and rdvsnce a methodology far raprelcntlng a map tram deep case structura ta surface structure , Thlr prgrr ~OCULII an a philosophy ot sLnglam6cnfencr farmattinqr cmeaaing a main vatbr choosing tna grass structure st the output scntencer and deciding how to generate spgropriata noun phraras , Qur exarnpl~a will anB1oY limPlifia4 semantic net rtrueturrr , remcrhat like those in the actual 5RI ~aartitianad BlarntP~ neta 8ystam lHandrlxr 19751 , MMes In the net may raprerant phylicrl objects , rcllttonshipr , evantr , sbtr , rulas , ar uttsrencesr a0 in the Qxempla balaw , Directad lab @ Pled areg conncct nsdaa and rsprasant certain wprimi % iran tlmc-invariant ralat tsnrhtpa , In the n @ t Lrrqm~nt above , the U.8. an4 thr U , K. rra elcmrntl ( a ) of the gat of CQMW~~~ @ @ , as EXP @ tisnt @ rr they baeh participate in OWNLng rlfurtionl lnvolvlnp as OBJlctr particular rubmariner ) reeh rubmarlnt 11 an rlcmsnt of same class ot subm &amp; r1ntsr rnd te~plafes fat Engllah rtntcner8 , Bc choa~e a simple verb for dernmstrrtfin a= OWN , Wa not @ that our verb h $ @ v &amp; t &amp; 1 VynanymrRr WAVE , POSSESS , and BELONG C10L Slmc clfh of thcsc verb8 ( including OWN1 ha8 other Ssnsr meanings , re Darlt a node tense they have in Comment this node will be &amp; ha m~rototypZcrlE OWHI in thst It w112 incarpareta the umsrnin~R of the altuatlsn and Ln that all inaerncrs af owning rituatians will b4 rerat~d PQ POSSESSt HIVEI BELONG ] and trmplatrr , Wsts that one template rill hat rufftea Ear all dour verbs ; For inatanesr the subject 0 % the subject ir the FXPeriencQsr EXP own &amp; OBJ 1 0BJ is owned by EXP EXP poroass~a OBJ OBJ 1s Pabl @ lldd by EXB EXP hrr aBJ OBJ Gdronv to EXP tOWK ( EXP V &amp; ct OBJ ) ( OBJ Vprr BY EXD ] ) [ PO3SES8 ( EX $ Yact OBJ ) ( 063 Ypar BY EXPI ] fHAVE ( EXP Vact OBJ ) ] IBEbON6 ( 084 Vact TO EXP ) ] New # in Order tb rpcilc about a particular Owning sltuatbonr nt t % dWr BELONG ) and an ag~oe1ated template ( OBJ VaeE TO EXPI , and But we have 4 problem ! there is no indication of how tho EXP and OBd Qrgumcntt &amp; re to be generated , NP will not always rofticrr note for inrtanec that the predicate argument of in % ? shn hapad to go homen must ba an Infinltlva PhP48e ( rather than the QetUfid phrree that NP might producal , Even a cursory 8tUdY of a few hundred verbs in th @ language shawl that they have very defintts Cand regular1 Consttaint &amp; on the syntactic form 0 % tnrrr canststucntr , Thaas constraint8 appear ts bc matters % or the lexicon rrthar than the grammar , we associate net ) rather than imwemsnt them via QP4MmBF TUI~II and wg cxpllcltly incorporate ths conrtltutnt types in the tamplatcst COWM ( ( NP EXP ) Va~t ( NP OBJ ) ) ( CNP OBJ ) Ypar BY ( NP EXP ) ) I ( POSSES6 ( ( NP EXP ) Vact ( NP OBJ ) ) ( ( NP OBJ ) Vpe8 BY ( NP EXP ) ) ] [ HAVE ( ( HP EXPI Vact ( NP OBJ ) ) ] [ BELONG ( ( NP OBJ ] Yaet TO ( NP EXP ) ) I A act of patterns liLe thtra is associated *Ith rvsry `` PIO~~YP. verbn nods in the knswZ~dg @ bra @ * $ t would seam that mll ra need is an Pntnrgsebr tkab giv~n any w~e~b instanceR node fn the knowb @ dg @ b~ger l0bko up the psttbrns PQT that type of ! nodh C~OQGQ~ Q VQtbr 1 eOrraapdnding tsmglate for the verb @ and then Proeaedr ts *evrluatan fha patterno verb [ OWN , S-38 , DWNI sms bQl~n $ tamp [ ( MP OBJ ) Vact TQ ( NP EXpll ( NP Odd ) 913 the S~awoLf YIC~ -13 Bclonqs TO -- 3 to ( NP GXP ) the u , s , But us ttlil run into trouble with our rimplc cchema , Consldsr the rent @ ncc , *John burned the taarf black , '' \ ACT \~BJ colorl By uging the simple pattern UNP AGT ) Vact ( HP OBJI ) we could easily generate the *Lncorrrctw sentence , rJahn burned the black tmr ; trW since ( NP QBJ ) might include the color of the te8ltt8 Me need a pattern more llke ( ( NP AG , T ) Vact [ NP OW ) ( nod R~SIII Zn which the RESult of the action wflk bc directly related to the verb. Ha*rvcrr thlr 1 % not quite enough a= rt laart , not Wtthout a very c0mpfic.tad Lntcrpretcr -* because the interpreter must RnoW that ( NF OBJ ) can not inelude ha vrabPs RE8 ergurnawl [ black ) . Thus # by convention , nay indicate an extra argument to bs Passed to r eon6tttuant qansrdor ( such as the Ounetisn NP ) te denote the item ( @ ) not te appear in the resultant canrtiturnta ( INP ACT ) Vact ( HP OBJ RES ) ( Nod RES ) ) *he pattern ( NP OBJ RES ) mrrnr Vgrnaratr an NP using the OBJsct of the VQrbr but do n~t inelude tha RESult of ths verb in the pattarno ( Leer a pattern copy far every porr/blr *mmlrrLngfl constituent ) , This level of detail would be unrdasonable id f @ w other verbs could we this template ; however , there are rnt ? t @ khan rstrtlvaly few tern~lrtarr baCh shw~d by several tang BB hundred @ of verbs , the urt of templates proves to ba quit* hefpfull There ? rrr other roureqr ot potantla1 pattern proltfarati~n~ an impattant one being the cambindtorial arrangamants of CQea arguments of time , manner , and athar such ~B~Wbi~llr &amp; it well aa other ( pot8iblY non*advrrbiall ease arguments such as sourer , $ 041 , inttrumrnt , etc. Some at $ ha @ @ arguma~td are rath @ r censtralnsd In their paaitiona in the rantencar but others may `` esterday the ship satled from the lighthouse to the dock , '' `` The # hip sailrd from ths lighthau8a to the dock yesterday. '' wYast @ rday the ship railed to the dock from the llghthour~.~ gt is af cauara unrsrranabl @ ta try to maintain all the ~as8ibXe prftrrnr ! Lnefcad rs leave Lnrsrtlon of fhrte rdvcrbiaf rrguncntr to r ring11 heuristic routine ( dcreribcd below ) , There are rrvcral jurtitlcations for thjl , amanp them8 ti ) the particular farm 09 the verb can not be grneobatsd until the subject bbject ( a5 ) @ r~rt @ L possible PL &amp; CI~~ and ( 31 theta rta some heuristic one may question whether passive tenplatao ahould be atore41 c @ tt @ inlyr they could be derivedr On the other hand , neglecting t~ rtare thorn woWd farce ur to Ind % bat @ wAth each Verb ( 84n03 ) ~ whether Lt can ( or , ronrtimar , must ) be parrivizcd , Indicating `` tr.n~ltlv @ Vir naf enough since there are tranritlvc vrrbr ( i.a , , vcrbr that taka an object ) that can not bc pssslvizad. 8incs we hava to rtora the information anywayp we Can rave dame cads and Coaput $ np tiar by storing thr parslvr ternplat @ . There arr rtvsrrl rraronr for gcnrrafinq the verb after the mafor @ rgumentr. Ftr~t the lubjret auat be panerrfad ro that the verb can br mrdc to aprrr in nuabnr. Second , certain rare trnrrr 8tr true of vrrb-prrticlr conblnitionc rkiir not cL the icolatrd verb , Btncr , in addition , prrticl @ c must appear rfttr object8 that F Short ( like pranownrl but bsf~rs abjaete that are long ( like noun phraras ) , the particle nurt be positionad after the object jS grncrrtcd. FfnaL1~1 inocrtian af soma advarbirbr tr.~ , annot '' rrqulrrr an ruxllirry verb Ithug verb grnaratlon aurt fotlor rdvrrbirl grncratlon , VERB PATTERNS This # tudy started with the 25 Verb pattcrnr '' prcrcntcd by Hornby ( 1954 ) . The~e Ln turn crwr from a dlctgonary by Hornby ct el. , ( 1948 ) . VctM in the dict $ onary &amp; re cZ &amp; irltird &amp; c~ording ta their gross syntactic prttrrn~ af lubjrctp abjrct ( s1 , end com~~raentCs ) ~ most ot the ~aftqrnr rra rub-dlvgdade Thc rutkorr cl @ La that there patfrrnr WXXNnt for all conttruetlanr involving &amp; I &amp; the verbs In theLr 4ietianary dndr by Nttnefon , In the IangUagr , I tl &amp; SrifiertLon is not Zmmcdi &amp; telY useful to C~thpUtdhti~nal lingulrtr rlnca it doas not addrags underlying ~emaatics~ Havatkhele~~~ it $ r clarr that it can ssrve ae ths brrlr for r &amp; artvatIan ol Und @ rlYlng carr rtructuhar prrtlculatly , &amp; r a bar16 for Vplnrrrtion tcngl &amp; tro , * There pattern8 &amp; re b @ lng canvartad inta tamplet @ @ much llkt tho # * derived arrlfetr tha tnrlyris is Baing perfarmed with ralD*Ct t4 300b V6tbl drawn fr~~ the dtctionary ( S~OCUW~ to appear ) , There templatea serve ro tho major portion of a modular *gan @ ratLon grammarr* with the r @ aarlnder in thr farm of hsutia ; tic tunctianr tor constructing syntactic constituentr , NOUN PHRASES What to IncluBb Ln a noun phrase should be another mrttar far the dircaurte module to judge , There are no w~1l~Earm~laCad fulrl eccountlng far anaphorl In EngliShj indead , there arc trw wsflee8trbliehad parameters ather than that % ha hearer must ba able to r~aalva tho ( pto ) nouns to their reforants , The &amp; D @ ak @ a ? p Should tmploy anaphoxa In order to avola t @ petitlonr but only Pt his B0deX of ! the hearer indicrto~ that the ~~QPCP can tdsolvd the ambiguity , Thcrc arc same lawcpowrr ptaneminalization ruler that could be directly incarp0ratsd in a generator rafg @ x $ v % zalPanr for s~11p10. NcV~P~~B~~SS~ ft IS impastant LO P~BZIZB that When r generator ir unaware of the eanvcrtafl~nal context , it lhauld not indepsndantLy decide haw to ganaratr noun phpa1481 It CQR only decide when to d6 roe This rbtuatlon har not been univ+roalLy r @ caqnfiedr but It 1s becoming hnercarlngZY clear thrt a QZ~csurte msduh must be canrubtsd during the ~snarrtlan phrrs. The direourre modal. will not know ahead of timr what NPI are % O be pr~due @ d un~ @ sg $ t p4rforrn\ @ many of ths gem @ ~Poratiana that the paneratar would do anyr4y. Yat the cantcxt-8cnritivo decirion strrt~g~ may h.ve to resorb ts rush maarutbr ar dlaewb $ quating the proporrb output uoLwg khs model of &amp; he hrsrer in order ta d~termbnr what rnaphdra if4 teseavabla , t % Ir unr @ rsanrble ts ancarporrte thlg strrt~gy in ths gancratsr~ rinca for rany rrrsonr it nurt be part of the dlrcourrr modulc , Therefate thr genrrrtor Should pa6S any RncunUconstitucnt to th @ dJscourre module ( plrhspt rith its rrcommcndation about how to PIgdUce the constituent , ; th~ nodule must dctcrminr if a pronoun or b &amp; ga noun it ambiguour to the hearer , and , if so , what to add to the noun ln order to makt the desired referent elear , Ln the current SRI system , noun prttcrnr [ Slocum , ta rpPcar ) ara USI~ to control noun phrase grnrrrtian , Much like verb patterns , noun prttcrnr order the ~on~tlfu @ nt8 in the phrarr and indicate how each eon8tLturnf Is to be generated by naming a functicn to be Called with the nQtwerK ~anstftuentf ( ( DET ] [ Ad3 QUA &amp; ) ( Adj SIZE ) ( Adj SHRFE ) ( Ad1 COLOR ) ( N ) ] Batttrhr like thir era dirtributrd about the network hi @ r @ rehyj in the future @ th @ QL~c~urrc aadulc rill dccLde tor each pqttrrn constituent whather ft i8 to appear in the phrrcs , MEURZSTXC RULES R~rnby d+rcrlb @ r three bsrlc porltlanr far advcrbr in the clrussr `` rentff pa # b $ tionp R~tdn pssltlonr and @ andu ~eritlon~ Front poritgen rdvrrbr occur batare the subjrctt wVerta~day h @ want hornat from these ha took a taxi , * The intorroqltiwa rdvarbr ( a , g , now , when ? rrr typically constrdkn~d to front Pooitionl other8 miy rpprrt thrrr tat purporrr of rmpharla cr eantralt. Mid perleion rdvarba occur virh the verb ( atringlt Sf there ar* medal sr ru # ilLrrv varhrs the dbvrrls occurs aftor the first one , Oth @ twi8r the rd~~rb w~LL appear btk~r @ the Verbl cxcapt fbr *un11tre8 # aQ~ fhlte~ of bar and 401 '~4 O~~QR $ 36 thararl @ oh @ if8 typi~llly buw8 ] *he It 1t11I waiting , @ End position adverbs occur rttrr the verb and after any dbteet or indirect object pteacnt , While talativ~ly fen clrurss have mare thrh one adVQrb in tront parttian or mara thrn sns In @ id porltianr it ir common tat rrvcrrl .dV @ rbS to appear in and ~arltlon in tha rams clausal *thaV play the Piana PeerlY tagcthrrw , hdvarblrlr of time ( rnrrrring the 4uartiont wrh @ n ? w ) usually deeut in and poaltion , but may appear In grsnt position far aaphrrtr or contrast. kdverbialr of frequency ( anrwsrlng tka quettbon , wRaw ~ftan ? ~l can be split inQ two groups , The first group is comgo @ @ d ~f ringla-nerd adverbs that tyalcally seeui fn &amp; id porition but aIro may br in ind patLtianj th @ sacand ir eosparsd a $ multipls=word phrrrrr that dgp &amp; ar Pn end parition er~ &amp; err Lrr9UrntlYr in trent Position. Adverbs of duration [ Vlf~rl hew lonqtw ) udu~lly have end parltlan , wbth % song p6sBtPon fbr empha8fs or csntxartr Adverb8 of place and diraetlen narrnall~ hivQ and porition. Advcrbr of 4rgrca and manner have mid or and ~OSI~LQRI depbnding on thr advarb , Along With ruah ruler con~~rnlng the BarLtionr OL Vsriout types of advrrbr , there murt br a mcchanirm to 0rd.f the rdvcrbr that arr La s~cur In tha `` maQn petitLon , Thrrr rra eome h @ ualrticl~ among rdverbi.11 of time Car pla~11 the smallat unit 81 ururlly pL4ccb tlrlt , unlrrl it tr 44604 48 &amp; R sftarthauphtl @ the army attaeksd thr village in farce an a hot Augutt @ ftrrnoon , just attar riertaH , Adv @ rbialr of placa end diroetton usually precede thore of frequency , which in turn praeode thoo~ at time , There rule8 re iaplrmontsd in th @ raRr rautLn~ Mat produce @ the verb1 when @ template is firat fnearprcked =NWh eo B 8equencc of function erllr the RVa~tw or `` Vpao kaya arc lonored. once the lUbjCCt , ~bjCCt ( S1 and compltmcnt ( a ) lndicrtrd by the tcnplrtr rrr Oanrrrfrdr this *clean upm routine $ 6 called. Et employg the hauxittiek d~rcrfbed abava La add the adverbial C~rt &amp; tftU @ nt &amp; and VhFbr then concatsnatss the canstbtutnts ta produce r complete @ IruseI DXSCUSSTON fn theory , the set of porsiblc EnpLlrh rantcncrs i a inf fnZtsr Tha obvlaor qusatlbn man ~t @ @ @ r Olf sne tries to account ror them with tarnplitrrr won t there bc an infinite number eL taaplatt~ ? ~ The simple antxcr irr `` Nor tor romc of the Sam @ rell~nl that allow a finite grammar to gcnrrata an intlnite number of itr2ngr.R One can preduca rantrncer of arbitrary Length by ( 1 ) ~T'bltt'at~ anb @ ddlngr and ( 21 arbitrary conjuncttan @ Caw @ Boto not do so by includdng arbitrary numbers sf distinct car @ erpuacntl. Evrn ra the numbcr ot basic patterns could be tnl~amelY Iaf gc , Evidrnca , horevrrr il tc the contrary ! the lVentUII nUnbqr of t @ Bpl.t @ # would appear to br reveral time8 the number OI pltternr~ awing to thr SUbltitUtion of parttcular pra~aritlone Ear npr~pw In the r~~tictlc attaro or , and tha arrlgnaent ot dltfetent crle nancr to a particular canstitusnt depending on the prrticular vrgb ur @ d. American Journal of Computational Linguistic8 Microfiche 33 : 78 Yale University New Haven , Connectiuct 06511 ABSTRACT TALE-SPIN is s program which makes up stories by using planning structures as part of its world knowledge. Planning structures represent goals and the methods of achieving those goals. Requirements for aparticular method depend on static and dynamic facts about the world. TALE-SPIN changes the state of the world by creating new characters and presenting obstacles to goals. The reader / listener makes certain plot decisions during the telling of the story. The story is generated using the notation of Conceptual Dependency and is fed to another program which translates it into English. INTRODUCTION TALE-SPIN is a computer program which makes up stories about characters who plan how to solve certain problems This work was supported in part by the Adudnced Research Projects Agency of the Department of Defense and monitored by the Office of Naval Research under contract N00014-75-C-1111. and then carry out their plans. The planning procedures interact with a data base of knowledge about other characters and objects in the world , memory , and the personal relationships which exist between characters. The stories are represented in Conceptual Dependency and are passed to a program which expresses them in English. The reader is asked to make certain decisions about the story during the process of generation. Here is an example. JOE BEAR WAS FAMISHED , HE DECIDED HE WOULD BE FULL IF HE ATE SOME HONEY , HE WANTED TO FIND OUT WHERE THE HONEY WAS , HE THOUGHT TRAT IRVING BIRD WOULD TELL HIM WHERE THE HONEY WAS. JOE BEAR WALKED TO THE TREE WHERE IRVING BIRD WAS. HE ASKED IRVING BIRD IF HE WOULD TELL HIM WHERE THE HONEY WAS. &gt; &gt; DECIDE : DOES *IRVINGBIRD* AGREE ?</sentence>
				<definiendum id="0">SDC</definiendum>
				<definiendum id="1">traditlondl answer</definiendum>
				<definiendum id="2">Thlr prgrr ~OCULII</definiendum>
				<definiendum id="3">MP OBJ ) Vact TQ</definiendum>
				<definiendum id="4">Ln</definiendum>
				<definiendum id="5">frequency</definiendum>
				<definiens id="0">ruccrrr of understanding efforts ir generally bclisvtd to drprnd on rome warkrble theory of Rdlrcaurrr 6rganlzatlonc which would rccbunt gar affect8 of context and would ahow how iniphoric ~~pren8l~ns ( pronoun # and noun phrases</definiens>
				<definiens id="1">1s to appear Lntrlligent. Tha lrtudy of qrnrtrtion rill play an important rots in rolving the problem of undrrttandino if it ern draonrtrrte &amp; mapping t~om derp ramantic rtrUctura6 to rutface rtrtngr , bet ua briefly outlina gome relevant preccrrrs in the # peach understanding system bring drYcL0~1d by 8RI and</definiens>
				<definiens id="2">several censLdcr8tianr involved in responding appropriateby to an utterance. First , therc are *conver : ctlanal Po~tUl &amp; te # '' ( Gordon and Lakoff , 19751 8harsd by the u6ers a£ e Lanuurprt there pottu2ater serve to canstrain the content and form of ca~~unicationr from the speaker to the heerare For instance , the rperker should not tall the hearer re~sthing the hearer all @ &amp; dy knows , lcrt he be bore61 yet the speaker can not tell the hcarer samething the hearer knows ab~olutely nathlnq about</definiens>
				<definiens id="3">an a philosophy ot sLnglam6cnfencr farmattinqr cmeaaing a main vatbr choosing tna grass structure st the output scntencer and deciding how to generate spgropriata noun phraras</definiens>
				<definiens id="4">the net may raprerant phylicrl objects , rcllttonshipr , evantr , sbtr , rulas , ar uttsrencesr a0 in the Qxempla balaw</definiens>
				<definiens id="5">the umsrnin~R of the altuatlsn and Ln that all inaerncrs af owning rituatians will b4 rerat~d PQ POSSESSt HIVEI BELONG ] and trmplatrr , Wsts that one template rill hat rufftea Ear all dour verbs ; For inatanesr the subject 0 % the subject ir the FXPeriencQsr EXP own &amp; OBJ 1 0BJ is owned by EXP EXP poroass~a OBJ OBJ 1s Pabl @ lldd by EXB EXP hrr aBJ OBJ Gdronv to EXP tOWK ( EXP V &amp; ct OBJ ) ( OBJ Vprr BY EXD ] ) [ PO3SES8 ( EX $ Yact OBJ ) ( 063 Ypar BY EXPI ] fHAVE ( EXP Vact OBJ ) ] IBEbON6 ( 084 Vact TO EXP ) ] New # in Order tb rpcilc about a particular Owning sltuatbonr nt t % dWr BELONG ) and an ag~oe1ated template ( OBJ VaeE TO EXPI</definiens>
				<definiens id="6">a few hundred verbs in th @ language shawl that they have very defintts Cand regular1 Consttaint &amp; on the syntactic form 0 % tnrrr canststucntr</definiens>
				<definiens id="7">NP EXP ) Va~t ( NP OBJ ) ) ( CNP OBJ ) Ypar BY ( NP EXP ) ) I ( POSSES6 ( ( NP EXP ) Vact ( NP OBJ ) ) ( ( NP OBJ ) Vpe8 BY ( NP EXP ) ) ] [ HAVE ( ( HP EXPI Vact ( NP OBJ ) ) ] [ BELONG ( ( NP OBJ ] Yaet TO ( NP EXP ) ) I A act of patterns liLe thtra is associated *Ith rvsry</definiens>
				<definiens id="8">the rent @ ncc , *John burned the taarf black , '' \ ACT \~BJ colorl By uging the simple pattern UNP AGT ) Vact ( HP OBJI ) we could easily generate the *Lncorrrctw sentence , rJahn burned the black tmr ; trW since ( NP QBJ ) might include the color of the te8ltt8 Me need a pattern more llke ( ( NP AG , T ) Vact [ NP OW ) ( nod R~SIII Zn which the RESult of the action wflk bc directly related to the verb. Ha*rvcrr thlr 1 % not quite enough a= rt laart , not Wtthout a very c0mpfic.tad Lntcrpretcr -* because the interpreter must RnoW that ( NF OBJ ) can not inelude ha vrabPs RE8 ergurnawl [ black ) . Thus # by convention , nay indicate an extra argument to bs Passed to r eon6tttuant qansrdor ( such as the Ounetisn NP ) te denote the item ( @ ) not te appear in the resultant canrtiturnta ( INP ACT ) Vact ( HP OBJ RES ) ( Nod RES ) ) *he pattern ( NP OBJ RES ) mrrnr Vgrnaratr an NP using the OBJsct of the VQrbr but do n~t inelude tha RESult of ths verb in the pattarno ( Leer a pattern copy far every porr/blr *mmlrrLngfl constituent</definiens>
				<definiens id="9">the particle nurt be positionad after the object jS grncrrtcd. FfnaL1~1 inocrtian af soma advarbirbr tr.~ , annot '' rrqulrrr an ruxllirry verb Ithug verb grnaratlon aurt fotlor rdvrrbirl grncratlon</definiens>
				<definiens id="10">all conttruetlanr involving &amp; I &amp; the verbs In theLr 4ietianary dndr by Nttnefon</definiens>
				<definiens id="11">the current SRI system , noun prttcrnr [ Slocum , ta rpPcar ) ara USI~ to control noun phrase grnrrrtian , Much like verb patterns , noun prttcrnr order the ~on~tlfu @ nt8 in the phrarr and indicate how each eon8tLturnf Is to be generated by naming a functicn to be Called with the nQtwerK ~anstftuentf ( ( DET ] [ Ad3 QUA &amp; ) ( Adj SIZE ) ( Adj SHRFE ) ( Ad1 COLOR ) ( N ) ] Batttrhr like thir era dirtributrd about the network hi @ r @ rehyj in the future @ th @ QL~c~urrc aadulc rill dccLde tor each pqttrrn constituent whather ft i8 to appear in the phrrcs</definiens>
				<definiens id="12">adverbs occur rttrr the verb and after any dbteet or indirect object pteacnt , While talativ~ly fen clrurss have mare thrh one adVQrb in tront parttian or mara thrn sns In @ id porltianr it ir common tat rrvcrrl .dV @ rbS to appear in and ~arltlon in tha rams clausal *thaV play the Piana PeerlY tagcthrrw , hdvarblrlr of time ( rnrrrring the 4uartiont wrh @ n ? w</definiens>
				<definiens id="13">in turn praeode thoo~ at time , There rule8 re iaplrmontsd in th @ raRr rautLn~ Mat produce @ the verb1 when @ template is firat fnearprcked =NWh eo B 8equencc of function erllr the RVa~tw or `` Vpao kaya arc lonored. once the lUbjCCt</definiens>
			</definition>
			<definition id="17">
				<sentence>&gt; &gt; DECIDE : DOES *IRVINGBIRD* AGREE ?</sentence>
				<definiendum id="0">&gt; &gt; DECIDE</definiendum>
			</definition>
			<definition id="18">
				<sentence>DECIDE : DOES *IRVINGBIRD* AGREE ?</sentence>
				<definiendum id="0">DECIDE</definiendum>
			</definition>
			<definition id="19">
				<sentence>JOE BEAR TOLD IRVING BIRD HE XS GOING TO STRIKE HIM IF HE DOES NOT TELL HIM WHERE THE HONEY WAS .</sentence>
				<definiendum id="0">JOE BEAR TOLD IRVING BIRD HE XS GOING TO STRIKE HIM IF HE</definiendum>
				<definiens id="0">DOES NOT TELL HIM WHERE THE HONEY WAS</definiens>
			</definition>
			<definition id="20">
				<sentence>Some of the Conceptual Dependency ( CD ) structures are passed on to a program which expresses them in English .</sentence>
				<definiendum id="0">Conceptual Dependency</definiendum>
				<definiens id="0">passed on to a program which expresses them in English</definiens>
			</definition>
			<definition id="21">
				<sentence>PERSUADE asks Memory whether Joe thinksthat Irving can not answer the question .</sentence>
				<definiendum id="0">PERSUADE</definiendum>
				<definiens id="0">asks Memory whether Joe thinksthat Irving can not answer the question</definiens>
			</definition>
			<definition id="22">
				<sentence>PERSUADE calls dPROX ( , Irving ) , since Joe needs to speak to Irving .</sentence>
				<definiendum id="0">dPROX</definiendum>
				<definiens id="0">since Joe needs to speak to Irving</definiens>
			</definition>
			<definition id="23">
				<sentence>( 1 ) Bargaining , as it exists now in TALE-SPIN , is a pretty one-sided affair , with the main character making all the proposals .</sentence>
				<definiendum id="0">Bargaining</definiendum>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>Tho paranoid nlodel ( PARRY21 consists of a RECOGNIZE nioclu la which performe the task of recognizing the input and a RESPOND modulo which decides how to respond .</sentence>
				<definiendum id="0">Tho paranoid nlodel</definiendum>
				<definiendum id="1">PARRY21</definiendum>
				<definiens id="0">consists of a RECOGNIZE nioclu la which performe the task of recognizing the input and a RESPOND modulo which decides how to respond</definiens>
			</definition>
			<definition id="1">
				<sentence>ALTO TOWN CITY CE TY CITY CAN ' T CAN NOT CANT WON ' T WONT CLEAR DDY I OUS UNDERSTOOD CLEAR CLEAR CLEAR CAN COULD RAY HI GHT MUST SHALL SHOULD SUPPOSE TO UILL WOULD COLBY COLBY COLLEGE COLLE BLACK COLrlR GREEN RACE WHI TE COLOR COLOR COLOFI COLOR COLOR CRAH SHOVE STICK ENTER COME IN AOHI TTED COME BERSERK 61 ZAUHli CRALY DELUS I ON DELUSIONAL EMOTI UNAL FL I PPED s CASE MENTAL NU T NUTTY OFF YOUR ROCKER PARANOT A PARANO I D PSYCt I1 ATR I C PSYCHOS 1 S PSYCt IOT I C SANE 'SANI TY SCI I I ZOPt-IiKN 1 A SCI I I ZOPl IREN I C SCREW I-OOSE SCREWY SICK SICKIE YOYO CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY DAD -a FAN1 LY -B FAMLY 3 FATHER 4 FOLKS + PARENT + DAD DAD DAD DAD DAD DAD DATE 3 DAY HOUR R I NUTE MONTH SEASON TIRE WEEK YEAR DAY DAY DAY .</sentence>
				<definiendum id="0">SCREWY SICK SICKIE YOYO CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY CRAZY DAD</definiendum>
			</definition>
			<definition id="2">
				<sentence>m -+ PRES-I DEN J 3 WHITE HOUSE 3 PRAY PRAY PRAY PRAY PRAY PRAY PRAY PRAY PRAY PRAY PAY PAY PAY PAY EARN PAID PAY SALARY ANYnODY ANYONE EVERY M3DY EVERYONE MEMIER NOBODY ONE PART I ES PEOPLE SOCIETY SOMEBUUY SOME0 E U d PEOPL PEOPL PEOPL PEOPL PRES PRES PEOPL PEOPL PE~PL pEoPL PEOPL PEOPL PRES EV l DEFICE + PROOF 4 PROOF PROOF CONFUSE PUZZLE PUZZL PUZZL PICK PICK BAV ntnnows + HORSE17 ACE 4 RACES + RACETRACK 3 RACING 3 SWEEPSTAKES 3 TRAGIC * RACES RACES RACES RACES RACES RACES RACES PILLS PILLS P I LLS PILLS PILLS P I LLS SEDAT I VE THERAPY THORAZI NE TREATMENT PILLS PILLS BOOK READ READ READ ANYWHERE PLAOB AVERAGE EXIST FAMILIAR NATURAL NORMAL REAL REGULAR SAME REAL REAL REAL REAL REAL REAL REAL REAL PLANS PLANS AHBI TI ON PLANS MINUS PLUS T I RES PLUS PLUS PLUS SAY SAY ANSWER + REPI-Y + RFSP~NI~ 4 YES I1R NO 4 REPLY REPLY REP1 .</sentence>
				<definiendum id="0">PRAY PRAY PRAY PRAY PRAY PRAY PRAY PRAY PRAY PRAY PAY PAY PAY PAY EARN PAID PAY SALARY ANYnODY ANYONE EVERY M3DY EVERYONE MEMIER NOBODY ONE PART</definiendum>
				<definiendum id="1">PEOPL PEOPL PEOPL PEOPL PRES PRES PEOPL PEOPL PE~PL pEoPL PEOPL PEOPL</definiendum>
				<definiens id="0">NE TREATMENT PILLS PILLS BOOK READ READ READ ANYWHERE PLAOB AVERAGE EXIST FAMILIAR NATURAL NORMAL REAL REGULAR SAME REAL REAL REAL REAL REAL REAL REAL REAL PLANS PLANS AHBI TI ON PLANS MINUS PLUS</definiens>
			</definition>
			<definition id="3">
				<sentence>GOOD IN SEX IN TELL SEX IN YnU SE-K SEX MAKE YOU NERVE MllAT SEX YT ) U WHt1 l4E YOU SEX YOU 1 I KE HALE YOU SCREW YOU SEX YOU SEX CXPER YOU SEX FEEL YOU SEX IDEAS YOU SEX UPSET DE YOU TALL TALL tIUM TALL BE YOU llOW TALL YOU WI-IAT HE YOU WEIGH LIKE UE YOU FRlEN $ j9Kk y ; yTRAN YOO LIKE STRAN OR DRING YOU LIR HAKE YOU COME tIOW BE iT YOU CONE tIOW YOU COME HOW YOU GET IN WAnD VOLUN PFOT'I IIRI NG YOU PkUPL MAKE YOU COME wi 10 un1 ~ , c YOU WHO MAKE YOU COhE WHY FllLZ HHING YOU YUU DRING YOU YOU COHE THAT BAC ) TI-IA-T SAD YOU THAT UPSET YOU HE PFCPL FRIEN BE YOU LIKE llOW BE PEOPL TREAT YOU HOW PEOPL FEEL IIOW PEOPL =EAT YOU tlOW PEOPL \ ( b~ HOW YOU FRIEN FEEL PEOPL GOOD YOU PEOPL LIKE PEOPI LIKE YOU PEOPL TREAT YOU PCOPL TREAT YOU WELL Yo11 ~fi TREAT YOU lREAT IIOW rEorL BLAME YOU W AT OATE YOU COHE LJ k 'N YOU COME IN WARD OFTEN YOU UE LIMY ODD OFTEN YOU OFTEN WARD nE IT OFlBN DAY YOU RE OE 1 T YOU OFTEN WARD YOU DE PATIE QFTEN YPIlJ flE TtlFRE OFTEN COlJLD .</sentence>
				<definiendum id="0">PEOPL FEEL IIOW PEOPL =EAT YOU tlOW PEOPL \</definiendum>
				<definiens id="0">c YOU WHO MAKE YOU COhE WHY FllLZ HHING YOU YUU DRING YOU YOU COHE THAT BAC ) TI-IA-T SAD YOU THAT UPSET YOU HE PFCPL FRIEN BE YOU LIKE llOW BE PEOPL TREAT YOU HOW</definiens>
			</definition>
			<definition id="4">
				<sentence>BE SPY YOU PEOPIHAHM 'YOU PEUI'I , SPY PEOPL SPY HATE YOU PFOPI SPY YOU THAT YOU HE SPY YOU BE SPY YOU SPYBE THERE PEOPL YOU TRUST IN SUSPI SUSP I YOU 11E SUSPI YOU DI STR PEOPL YOU SEEM SUSPI YOU TRUST PEOPL WlIAT YOU DISTR ' WIiO IIE YOU SUSPI WHO YOU DISTR YtIY BE YOU SUSPI WtIY ITALY SEEN MJD IN rTALY I TALY I TALY I T WHAT ITALY ITALY UPSET YOU YOU FEAR ITALY RE YOU JEW WHAT BE YOU PRAY WllAT DE YOU PRAY ANCES WHAT PRA'Y BE YOU BE YOU PRAY IN PnAv TI IERL DE GUIJ yo11 rn~v ' WIA C ; IAIE t3E YOU WllAT STATE YOU LIFE I ICII lr IAl YUU HOME Y ClU t lUllE YOU LIE \II~A r RE vuu HOME WIIAT IIUME LIE YOU WI IAT IiQME YOU COME GItIAT HOME YOU LIFE WI lcnc : :E voP IlORE Wil [ IRL DE YOU LIFE WIiFRE YUll CORE wtitnt YOU HONE WtIEREZ YOU LIFE LIWY RE YOU HOME BAD Y &amp; LIKE IIOHE YOU LIKE YOU DE LIFE RE HONE FRIEN You LIFE ALONE WIIAT DE YOU CtiILD NAME YOU CHILD YOtl 1-1 KE YOU CtII LD COULD YOU SPELL IiOW YOU KILL YOU IN SLIICI LIE DC SUICI SEFH 'IUICI SUlCl YOU SUICI BE !</sentence>
				<definiendum id="0">SPY PEOPL SPY HATE</definiendum>
				<definiens id="0">YOU PFOPI SPY YOU THAT YOU HE SPY YOU BE SPY YOU SPYBE THERE PEOPL YOU TRUST IN SUSPI SUSP I YOU 11E SUSPI YOU DI STR PEOPL YOU SEEM SUSPI YOU TRUST PEOPL WlIAT YOU DISTR ' WIiO IIE YOU SUSPI WHO YOU DISTR YtIY BE YOU SUSPI WtIY ITALY SEEN MJD IN rTALY I TALY I TALY I T WHAT ITALY ITALY UPSET YOU YOU FEAR ITALY RE YOU JEW WHAT BE YOU PRAY WllAT DE YOU PRAY ANCES WHAT PRA'Y BE YOU BE YOU PRAY IN PnAv TI IERL DE GUIJ yo11 rn~v ' WIA C</definiens>
			</definition>
			<definition id="5">
				<sentence>IT I HI SlJN YOU YOU ~*UZZL HE BE YOU HISUN YOU BE MISUN YOU MISUN YOU SEEM MISUN I , TRUST I TRUST YOU BE I STRAN JN BE STRAN YOU TRUST ME WHY I COULD TRUST YOU DISTR YOU aISTR ME I WANT YOU WUSf TRUST ME I GIVE YOU I UORD -D 4 4 -D -P + -D 3 4 + -D 4 + + YOU 3 3 I ) YOU COULD TRUST E ; -B OU COULD TRUST ME -B OW COULD 1 GET YOU TRUSJ I ) IN TRUST HZ 4 WHAT C ULD MAKE YOU TRUST ME + WPIAT I4 KE , YOU DJSTR HE + WI-IY YOU TRmT BE + I LIKE YOU IN E3E FRIEN IN BE YOU FRIEN WE 13E FRIEN WE LIKE COULD YOU LIKE RE you LIKE HE I HATE YOU WHY COULD I LIKE YOU HATE ME BE I UPSET YOU I BE HAPPY I B ANGRY ANGER RE V Y $ ARGUE YOU ' BLAME ANGRY BE YOU ANGRY I ANGRY YOU IN ANGER YQU BE ' ANGRY YOU RIGHT BE ANGRY YOU SEEM ANGRY IN ANGER YOU WHAT ANGRY YOU WHY BE YOU ANGRY I BE CALM HE YOU CALPI , CALM IN SCARE YOU YOU HE CALH YOU COULD CALH YOU SEEN CALfl I. HE WARY BE I BEAT BE YOU WAR4 I MAKE YQU MARY I 3CAIlE YOU IN E3E WARY IN FEEIR WARY YdU BE WARY YOtl kEAR ME YOU SEEN WARY YOU WARY WHY RE YOU WHO WHY YOU OE ~ARY n @ mu cnow BE YOU I'XED LUCKY I HE r ' ; oflIl DH I EIE DAD i nE ODD I HE SEX COULD YOU LIKE DATE COULD YOU LIKE SCREW IN SCRFW I iU SCREW ME IN SCREW YOU WE LIATE WE SCREW BE YOU BAD BE YOU OFTEN IT BAD IY BE BAD YOU DAD YOU DAO RRAI N YOU BAO LOOKS r OAD YOU E BAD HUMAN YOU 000 LOOKS YOU SEEfl BAD BE ODD BE YOU nno I FINO YOU nno OM YOl [ BE f1DD YOU RLAHC HE YOU INTER ME YO41 ClOD YOU OFTEN BE ODD YClU SEER ODD RE YOU GOO0 BE YOU GO013 RRLE I r ; n I IGIMCI I YOU 1 DEAS 1JtlAT AGE YOU SCHOO WIICN YOU SCUOO WI4AT SCtIIIO UI inr SCH &amp; YOU WtICRt OE YOU SCt100 I T MAKE YOU FEAT1 PEOPL WI-IAT RE YOU WARY WIIAT MAKE YOU WARY YOU FEAR IT BE you KILL IN IIARN PEOPL IN KILL PEOPL L IKE WARM PEOPL LIKE KILL PEOPL YOU GET KILL YOU HARM PEOPL I T , SEEM REAL WIIEHIHF YOU YESTE Bt YOU IIYPER HYPER I N .</sentence>
				<definiendum id="0">-B OU COULD TRUST ME -B OW COULD</definiendum>
				<definiens id="0">C ULD MAKE YOU TRUST ME + WPIAT I4 KE , YOU DJSTR HE + WI-IY YOU TRmT BE + I LIKE YOU IN E3E FRIEN IN BE YOU FRIEN WE 13E FRIEN WE LIKE COULD YOU LIKE RE you LIKE HE I HATE YOU WHY COULD I LIKE YOU HATE ME BE I UPSET YOU I BE HAPPY I B ANGRY ANGER RE V Y $ ARGUE YOU ' BLAME ANGRY BE YOU ANGRY I ANGRY YOU IN ANGER YQU BE ' ANGRY YOU RIGHT BE ANGRY YOU SEEM ANGRY IN ANGER YOU WHAT ANGRY YOU WHY BE YOU ANGRY I BE CALM HE YOU CALPI , CALM IN SCARE YOU YOU HE CALH YOU COULD CALH YOU SEEN CALfl I. HE WARY BE I BEAT BE YOU WAR4 I MAKE YQU MARY I 3CAIlE YOU IN E3E WARY IN FEEIR WARY YdU BE WARY YOtl kEAR ME YOU SEEN WARY YOU WARY WHY RE YOU WHO WHY YOU OE ~ARY n</definiens>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>One of them is SIR , which can deduce set relationships anong objects described by natural language .</sentence>
				<definiendum id="0">SIR</definiendum>
				<definiens id="0">can deduce set relationships anong objects described by natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>Deductive systems can be divided into general systems which add a flrst-order predicate-calculus theorem-proving capability to limited-loglc systems to improve the complexity oE the facts they can `` infer '' , and proccdurnl systcms which enable other computations to obtain complex information The theorem-proving capability is designed to work Erom a group of logical statements given as input ( or statements consistent with the'se input s-tements ) However , facts INCONSISTENT with the original statements can not always be detected and deductive systems quickly become impractical as the number of input statements ( elementary facts , axioms ) becomes large [ b , 7 , 161 , since the time to obtain a proof grows to an impractical length .</sentence>
				<definiendum id="0">Deductive systems</definiendum>
				<definiens id="0">information The theorem-proving capability is designed to work Erom a group of logical statements given as input ( or statements consistent with the'se input s-tements ) However , facts INCONSISTENT with the original statements can not always be detected</definiens>
			</definition>
			<definition id="2">
				<sentence>The example there begins with P1 P4 given : P1 if x is part of v , and if v is part of y , then x is part of y ; P2 a finger is part of a hand ; P3 a hand is part of an arm ; P4 an arm is part of a man A pr'oof that P9 a finger is part of a man is derived by steps , such as combining P1 and P2 to get P6 if a hand is part of y , then a finger is part of y Unfortunately , it is easy to move outside the domain where the computer can make useful deductions , and the formal resolution process is extremely lengthy and thus prohibitively costly in computer time .</sentence>
				<definiendum id="0">P4 an arm</definiendum>
				<definiens id="0">part of y , then x is part of y ; P2 a finger is part of a hand ; P3 a hand is part of an arm ;</definiens>
			</definition>
			<definition id="3">
				<sentence>eful `` understanding '' capability Furthermore , tbere is a reql potential for use ot the `` understanding '' in an interactive node to facilitate use of computers by nonspecialists and to tap fhe more sophisticated human understanding capabilities Research and computer program development desrgned to store multitudes of facts so that they can be accessed [ 29 ] qx combined [ 301 and `` unders , tood ( see pp .</sentence>
				<definiendum id="0">tood</definiendum>
				<definiens id="0">a reql potential for use ot the `` understanding '' in an interactive node to facilitate use of computers by nonspecialists and to tap fhe more sophisticated human understanding capabilities Research and computer program development desrgned to store multitudes of facts so that they can be accessed</definiens>
			</definition>
			<definition id="4">
				<sentence>Augmented phrase structure grammars consist of phrase structure rules with embedded conditions and structure building actions Data structures are records consisting of attribute-value pairs .</sentence>
				<definiendum id="0">Augmented phrase structure grammars</definiendum>
			</definition>
			<definition id="5">
				<sentence>An eqample of a logical connective is 'Cause ' ; a theme is a generalized pattern that is associated with a single word , e.g. , 'poison ' is describable as 'Someone ingests something that causes him to become ill ' .</sentence>
				<definiendum id="0">theme</definiendum>
				<definiens id="0">describable as 'Someone ingests something that causes him to become ill '</definiens>
			</definition>
			<definition id="6">
				<sentence>The 12 primitive actions are ATRANS , transfer of possession ; PTRANS , transfer of physical location ; MTRANS , transfer of information ; PROPEL , application of physical force ; M13UILD construction of new conteptual information ; INGEST , taking in of an object by an animal ; GRASP , to grasp ; ATTEND , to focus sense organ on an object ; SPEAK , to make a noise ; MOVE , to move a b.ody part ; &amp; WEL , to push something out of the body ; and PLAN , which characterizes the ability to form a course of action that leads to a goal .</sentence>
				<definiendum id="0">PLAN</definiendum>
				<definiens id="0">transfer of possession ; PTRANS , transfer of physical location ; MTRANS , transfer of information ; PROPEL , application of physical force ; M13UILD construction of new conteptual information ; INGEST , taking in of an object by an animal</definiens>
			</definition>
			<definition id="7">
				<sentence>Comprehension is a memory process ; breaking computational under standing into sccbyrob-leem af parsirig and semantic iktetpretation has hindered progress with much effort wasted on the construction of parsers .</sentence>
				<definiendum id="0">Comprehension</definiendum>
				<definiens id="0">a memory process ; breaking computational under standing into sccbyrob-leem af parsirig and semantic iktetpretation has hindered progress with much effort wasted on the construction of parsers</definiens>
			</definition>
			<definition id="8">
				<sentence>Semantics Discourse : Comprehension COMPUTERS AND NATURAL LANGUAGE A. Y. Pratt , M. G. Pacak , M. Epstein and G. Dunham National Institutes of Health Division of Computer Research and Technology Bethesda , Maryland Journal of Clinical Conlputihq , 3 , 85-99 , 1973 The Systematized Nomenclature of Pathology ( SNOP ) , in use at NIH , consists of about 15,000 entries in four lists : topography , morphology , etiology , and function .</sentence>
				<definiendum id="0">Semantics Discourse</definiendum>
				<definiens id="0">consists of about 15,000 entries in four lists : topography , morphology , etiology , and function</definiens>
			</definition>
			<definition id="9">
				<sentence>kSoc*al Actioii Paradigm is a model of the flow of social actions .</sentence>
				<definiendum id="0">kSoc*al Actioii Paradigm</definiendum>
				<definiens id="0">a model of the flow of social actions</definiens>
			</definition>
			<definition id="10">
				<sentence>Cognitive science includes elements of psychology , computer science , linguistics , philosophy , and education , but it is more than the intersection of these disciplines .</sentence>
				<definiendum id="0">Cognitive science</definiendum>
				<definiens id="0">includes elements of psychology , computer science , linguistics , philosophy</definiens>
			</definition>
			<definition id="11">
				<sentence>Semantics Discourse : Memory A FORMALISM FOR RELATING LEXICAL AND PRAGMATIC INFORMATI ON : ITS RELEVANCE TO RECOGNITION AND GENERATION Aravind K. Joshi and Stanley J. Rosenschein The Moore School of Electrical Engineering University of Pennsylvania Philadelphia , 19174 In : R. Schank and B.L. Nash-Webbet , eds. , Theoretical Issues in Natural Language Processing , 1975 , 79-83 .</sentence>
				<definiendum id="0">Semantics Discourse</definiendum>
				<definiens id="0">Memory A FORMALISM FOR RELATING LEXICAL AND PRAGMATIC INFORMATI ON : ITS RELEVANCE TO RECOGNITION AND GENERATION Aravind K.</definiens>
			</definition>
			<definition id="12">
				<sentence>The National Drug Code is a list of manufacturers and products .</sentence>
				<definiendum id="0">National Drug Code</definiendum>
			</definition>
			<definition id="13">
				<sentence>T. provides a hierarchically organized concordance to a literary corpus of 10,600,000 words of Latin Texts ; by comparison , the CaLvin concordance contains 405,338 words of Latin text in a single sequence .</sentence>
				<definiendum id="0">T.</definiendum>
				<definiens id="0">provides a hierarchically organized concordance to a literary corpus of 10,600,000 words of Latin Texts</definiens>
			</definition>
			<definition id="14">
				<sentence>Atcti~iciaG Krzte &amp; Xges~cc , Stanford , Calif , , 1973 , Carbontlll , J. TI. , `` AT in CAI : An Artificial IntBll igence lZ~proach to Conputer-Assisted Instruct ion , '' l EEE T~116 .</sentence>
				<definiendum id="0">CAI</definiendum>
				<definiens id="0">An Artificial IntBll igence lZ~proach to Conputer-Assisted Instruct ion</definiens>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>A varlab3e letter maps the elements of the partition into the Rumanian alphabet A , A , A , B , ... , 2 , j3 ( here pl represents the empty letter ) .</sentence>
				<definiendum id="0">varlab3e letter</definiendum>
				<definiens id="0">maps the elements of the partition into the Rumanian alphabet A , A , A , B , ... , 2 , j3 ( here pl represents the empty letter )</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>ABSTRACT The REQUEST System is an experimental natural language query system based on r. large transfo~ational grammar of English .</sentence>
				<definiendum id="0">REQUEST System</definiendum>
				<definiens id="0">an experimental natural language query system based on r. large transfo~ational grammar of English</definiens>
			</definition>
			<definition id="1">
				<sentence>The REQUEST System consists of a set of programs written in LlSF grammar , semantic interpretation rules and data base .</sentence>
				<definiendum id="0">REQUEST System</definiendum>
			</definition>
			<definition id="2">
				<sentence>The transformational component , which serves to analyze input strings and con $ pute their underlying structures , consists of two main parts : a preprocessor and a parser .</sentence>
				<definiendum id="0">transformational component</definiendum>
				<definiens id="0">consists of two main parts : a preprocessor and a parser</definiens>
			</definition>
			<definition id="3">
				<sentence>Each NOUN dominates an INDEX node which is specified as a constant ( t CONST ) in the case of proper nouns and as a variable ( CONST ) other wise .</sentence>
				<definiendum id="0">NOUN</definiendum>
				<definiens id="0">dominates an INDEX node which is specified as a constant ( t CONST ) in the case of proper nouns and as a variable ( CONST ) other wise</definiens>
			</definition>
			<definition id="4">
				<sentence>Two other classifier-deleting string transformations which are very similar to `` C &lt; ty , State , Year Classifier '' are the rules `` Year Cltissifier'l ( Y RCLASFR ) and `` Company Classifier '' ( COCLASFR ) The former de lctes the lesical trees corresponding to the underlined material in examples like `` . . . the year 1968. . . `` , while the latter does the same I thing in examples such as . . . bhe ) American Can Company. . . . Although the underlyidg predicate COMPANY is the only one specified in the struttural pattern of COCLASFR , the rule actually applies to instances where 11 a form of either of the words company '' or '' 'corpoi.ation '' has been uwd in the input string , owing to the fact that the lexicon assigns the same underlying predicate to both in recognition of their synonymity `` City State Blockff ( CSBLOCK ) and `` City State '' ( CITYSTATJ are ttyo rules , related to the preceding ones , which illustrate additional aspects of the system. Both of these rules follow CSYCLSFR in the list of string kransformations. As indicated by its header information- , ( Figure 3 ( a ) ) , CSBLOCK is a blocking rule ( BLOCK ) , which entails that it is obligatory ( OB ) and will result in termination of the current analysis path if the structural pattern matches the preprocessed string at least once. The structural pattern +s identical to that for CSYCLSFR save for the omission of the alternatives relatigg to €he predicat'e YEAR and the feature ( t YEAR ) Due to the parallelism of the structural patterns and the relative ordering of thc two rules , it is necessarily the case \hat CSB.LOCK -Header : ( CSBLOCK BLOCK OB QNE ) Stl'uctural Pattern : ( ( X. 1 ( THE. 2 ) NOUN ( OF . 5 ) ( ( INDEX . 6 ) ( x. 7 ) ) /\ ( ORX ( 4CITY + STATE ) ) ) V ( INDEX . 4 ) Stru~turat Change : NI L Feature Change : NIL Header : ( CLTYSTAT STRING OB ALL ) Structural Pattern : Condition : NIL ( ( X . 1 ) ( ( INDEX . 6 ) ( t CONST Structural Change : 1 ( COMMA. 3 ) ( INDEX ( + CONST Feature Change : , ( ( INSERT 6 ( ( t CITYSTATE ) ) ) ) ( b I ( X t CITY ) ) f t STATE ) ) ( w 2 ) l NIL ( w 4 ) Figure 3 : The Rules CSBLOCK and CITYSTAT will apply if and only if the classifier and the following proper noun do not correspond ( any corresponding c lassifiers having already been dcleted by CSYCLSFR ) . Thus CSBLOCK has the effect of aborting analyses where a proper name known to the system as designating a state has been classified as denoting a city , or vice-versa The rule CITYSTAT does not refer to classifiers as such , but it does deal with a proper noun construction even more important for our particular subset : the precise identification of a specific city by appending the appropriate state name to the city name. This construction is essential in distinguishing among such cities as Portland , Maine and Portland , Oregon , not to mention the eighteen varieties of Springfield in the con.I. .I . , ' . , E tinental United States The structural pattern of the rule ( Figure 3 ( b ) ) specifies a domain consisting of a city name ( ( INDEX . 6 ) ( + CONST + CITY ) ) followed by an optional comma , followed by a state name ( INDEX ( t CONST *** t STATE ) ) , where the actual city name is a single tree ( W . 2 ) and the I Such a situation would always arise in processing such inputs as City `` the 1 1 ol Ncw York '' , effectively resolving the ambiguity of the State 8 proper noun , if the user were not previously asked by the system to resolve it , as is our current practice , ** Cf , rxerence 15. * : k # The structural variable W is employed in struct\iral patterns in place of the more usual X whenever one wishes to specify the occurrence of precisely one unknown tree. state name a single tree ( W . 4 ) . As indicated by the structural change , each match results in the replacement of the tree labelled 2 by a list of trees consisting of itself and the tree labelled 4 , thereby pairing the state name with the city name by what amounts to right sister adjunction. The optional. comma ( COMMA 3 ) and the state name ( W . 4 ) -plus , by the convention cited earlier , the structure dominating r~ -are deleted. Finally , the feature ( t CITYSTATE ) is added to the featurg'list of the node ( INDEX . 6 ) , where its presence wilL eventually be noted by the semantic interpreter as rewiring a match on both elements of a ( cityname , statename ) pair in the data base. As far as the transformational corriponent is concerned , the net effect of the rulg is , .to make `` city , state '' constructions pass through both fhe surface parser and the inverse transformatiohs as though they were simple city names , `` Stranded Preposition Prevention '' ( Figuse 4 ) is a string transforrnatibn designed to prevent surface structure parses in which non-stranded prepositions are erroneously anaalyzed as stranded ones. Since most prepasitions , whether stranded or not. are obligatorily present in surface structures , this rule necessarily reflects an approach very different from the `` recognize and delete '' strategy employed in the string transformations involving classifiers. What is done here is to assign new word class codes to those prepositions determined to be non-strandable , and towrite the surface struct'ure rules for the new codes in such a way that they are only allowed to combine with a following noun phrase. Expressed in ~dinary English , the statement of the rule reads about as follows : `` Replace the word class code of each preposition by the cdrresponding code for nonstrandable prepositions except where the preposition immedihtely precedes an auxiliary , a punctuation mark , a verb form , or another ~repn~ition , assign any locative feature associated with the original word class code to the new word class code '' . As staicd -and as currently implemented -the rule may well be at once both too weak and too strong , at least in+an absolute sense. It is probably too weak in that it will fail to label as non-strandable any preposition which immediately precedes a noun phrase beginning with an adjective ( VADJ ) , as , for example ; in the sequence `` to large companies '' . This sort of deficiency is of littLe consequence , however , since the rule will serve its purpose well if it fails to catch an occasional non-strandable preposition , leaving things as ambiguous as before in those cases. Excessive strength , in the sense of marking some stranded prepsition as non-strandable , is potentially a much more serious flaw , since it precludes obtaining a correct analysis in such instances. Examples such as ( 9 ) , where SPRPPREV would fail in just this way by applying Header : ( SPRPPREV STRING 033 ALL ) Structural Pattern : ( PREP . I 'PREPOF Condition : ( NOT ( ANALYSIS 4 NIL ( QUOTE ( Structural Chanrre p ( ( BAUX ) ) ( ( COMMA 1 ) ( ' ( DAUX 1 ) ( ( PREP ' ) ) ( ( \PUNC T ) ) ( ( V ) ) ( ( VADJ ) ) C ( ( V'ING 1 ) ( ( CONU ( 2 ( COND ( ( ANALYS1S 2 NIL ( QUOTE ( ( ( PREP ( ( + LOCZ ) ) ) ) ) ) ) ( REPLACE ( ( NSP GI ? ( ( + LOC2 ) ) ) ) 2 ) ) P ( 3 ( REPLACE ( NSPREPOF ) 3 ) ) ) ) I Feature Change : NIL Figure 4 : The String Transformation `` Stranded Preposition Preventio~ incorrectly , are not particularly difficult to think up.. However , the ( 9 ) Was the company XYZ bought ballbearings from a subsidiarv 01 Universal Nut &amp; Bolt ? great majority of such examples -including ( 9 ) -seem to be irrelevant to the present REQUEST data base. Thus , while it is clear that our initial rule for stranded preposition prevention does not provide anything approaching a general solution to the problem , it does appear to be working satisfactorily for the moment in eliminating artificial surface ambiguities within a narrow domain of discourse. One of the sinlpiest and yet most useful of the 33 strlng transformations inl the current version of REQUEST is the rule `` Ordinal Formation '' ( ORDFORM ) . Its function is to match on each string consisting of an arabic numeal immediately followed by any member of the set of English ordinal-forming suffixes { d , nd , rd , st , th ) and mark the sequence as an 0-rdinal numeral. The operation of ORDFORM ( Figure 5 ) is entirely straightforward. By this poht in the analysis process , all arabicnumerals have already been assigned lexical trees dominated by the node ( VADJ ( t CARD ) ) -the combination denoting a cardinal numeral -during the input scanning phase of the preprocessor ; while the ordinal-forming suffixes have been assigned .trees dominated by the category ORD during ' Header : ( ORDFORM STRING OB ALL ) Structural Pattern : ( ( X . 1 ) ( ( VADJ-. 2 ) ( + CARD ) ) ( ORD 3 ) ( X . 4 ) ) Condition : NIL Structural Change : ( ( DELETE 3 ) ) Feature Chtinge : ( ( DELETE 2 ( CARDL ) ( INSERT 2 ( ( 4ORD ) ) ) ) Figure 5 : The String Transformation ''Ordinal Formation '' the lexical Lookup phase. ORDFORM simply finds each instance in the preprocessed string where a ( VADJ ( t CARD ) ) immediately precedes an ORD , hletes the ORD tree , and changes the feature on the VADJ from ( t CARD ) to ( t O.RD ) , thereby identifying that item as an ordinal numeral rather than a cardinal. The approach just described has the advantage of putting an unlimited set of ordinals at the disposal of the user at negligible cost , involving a few very minor additions to the lexicon and none at all to either the surface grammar or the preprocessor. The alternate of using a postcyclic transformation instead of a string transformation to achieve the same coverage was avoided because it would have imposed the additional requirement that the surface grammar be significantly enlarged through the inclusion of at least three new category symbols ( for cardinals , ordinals , and ordinal suffixes ) along with a set of context-free rules describing their distribution. Although identification of ordinal numerals of this type could also have been effected by buildingrthe appropriate tests directly into the preproce*s sor , the Zatte r altcrnatlve would have been much less attractwe than the string transformation approach for at least two reasons : First , it is inhere-ntly pessier to bury suc-11 operations in a special program subroutine than to deal with them as just another transformational rule. Second , and more important , is the fact that the latter approach makes the system less general and flexible , since material specific to English is directly reflected in the. structure of the program itself , rather than being confined to the grammar , where it is readily accessible to the liaguist who may wish to modify it -or replaceit by material describing some other natural language. Another string transformation currently employed to resolve word class homography on the basis of local context is the rule `` Cardinal Noun ' ( CARDNOUN ) , which will be discussed only briefly here. The rule distinguishes instances where a cardinal numeral functions as a proper noun ( 1 0 ) from those in which it serves as a nu~nerical quantifier pf a following nominal expression ( 1 1 ) . It does so by checking the immediatd right-hand cbntext of each ( VADJ ( + CARD ) ) for the presence of ( 10 ) Is the number of companies in Chicago greater than 16 ? ( 1 1 ) WPat companies employed at least 200 , 000 people in 19737 items ( such as articles , ausiliarie si punctuation , and verbs ) which are incompatible with the latter possibility , replacing the VADJ structure by a correspondilrg proper noun structure whenever a match occurs. ( CARDNOUN follows ORDFORM in the list of string transformations in order to take advantage of the latter 's replacement of certain cardinals by corresponding ordinals. ) By their very definition , idiomatic expressions are items which present problems in grammatical analysis , sernan'tic interpretation , or both. Although it would be very tempting to exclude all constructions of this sort from the English subset of REQUEST , the currency and naturalness of many idioms is so great that such a prohibition would entail abandonment of our goal of permitting future users to employ their normal patterns of expression. For idioms such as `` make money '' , ( in the. sense of `` be profitable '' ) , where the components are adjacent and the number of paradigmatic variants are few , one possible approach is to deal with the problem by putting appropriate entries in the phrase lexicon. For example , the entry for `` makes money '' in our present lexicon treats that combination as aan intransitive verb in the present tense and singular number which dominates the same underlying predicate and has the same selectional features as the adjective `` profitable '' . Even in such a relatively straightforward case , however , it is not difficult to think of minor extensions , such as the inclusion of negatives ( `` make no money '' ) , which will at least require another set of pHrasa1 entries. Moreover , the phrase lexicon approach breaks down con~plctely as soon as one deals with an idiomatic construction : hat includes afl open class as one of its components , producing a situation parallel to that encountered earlier for classifier constructions. The attempt to provide broad coverage of constructions involving notions of rank and ordinalitty Led to the consideration of a number of comnlon idiomatic j~atterns inc luding arbitrary cardinal or ordinal numer als. These patterns , three of which are illustrated in ( 1 2 ) , were eventually dealt with succe s sfully by the development of string trans forma tions designed not-only to cope with ther syntactic peculiarities but to ( 12 ) ( a ) What company nufi ? ber 18 in 1972 sales ? ( b ) What were the 25 1 '' highest 1 ranking companies with respecbto earnings in 1969 ( c ) List the top LO companies in 1973 growth rate ! set the stage for corfect semantic processing as well. The nature of these idiom-proces sing transformations is perhaps best illustrated by considering €he rule `` Top n '' ( TOPN ) , whose statement appears in Figure 6. The structural pattern of TOPN specities a sequence of elements consisting of an initial arbitrary string of trees ( X . 1 ) followed in order by an occurrence of the definlte article `` the '' ( THE . 2 ) B the word `` topf ' ( TOP 3 ) , a cardinal numeral ( ( VAD'J . 4 ) ( + CARD ) ) , a ndminal expression ( NOM . 5 ) , either of the prepositions `` in '' ( IN . 6 ) or `` with respect to '' . ( WITH RESPECT TO . 6 ) , and a Header : ( TOPN STRING OB ALL ) Structural pattern : Condition : NIL Structural Change.. ( X. 7 1 ( ( X . 1 ) ( THE . 2 ) ( TOP . 3r ( ( VADJ . 4 ) ( NOM , 5 ) ( t CARD ) ) ( W. 8 ) I f ( IN. 6 ) ( WITH RESPECT 6. 6 ) ( DELETE 3 ) ( DELETE 4 ) ) ( . ( REPLACE ( 5 ( VING ( + ADJ ( VADJ ( + ADJ PR'E P ( VADJ ( + ADJ ) 5 ) Feature Change : NIL Figlire 6 : The Rule ! 'Topn '' it ORD ) ) + INC ) ) RANK [ NQUOTE 1 ) THROUGH 8 + ORD ) ) final arbitrary string of trees ( X . 7 ) . The structudal change includes a replacement and two deletions. The syntax of a replacement operation is of the form ( REPLACE &lt; list of trees &gt; &lt; tree &gt; ) ; its execution results in the replacement of klqe item corresponding to tree by the items corresponding to list of trees .</sentence>
				<definiendum id="0">CSBLOCK</definiendum>
				<definiendum id="1">COND</definiendum>
				<definiendum id="2">REPLACE</definiendum>
				<definiendum id="3">String Transformation</definiendum>
				<definiendum id="4">structudal change</definiendum>
				<definiens id="0">the only one specified in the struttural pattern of COCLASFR , the rule actually applies to instances where 11 a form of either of the words company '' or '' 'corpoi.ation '' has been uwd in the input string</definiens>
				<definiens id="1">illustrate additional aspects of the system. Both of these rules follow CSYCLSFR in the list of string kransformations. As indicated by its header information-</definiens>
				<definiens id="2">a blocking rule</definiens>
				<definiens id="3">NI L Feature Change : NIL Header : ( CLTYSTAT STRING OB ALL ) Structural Pattern : Condition : NIL ( ( X</definiens>
				<definiens id="4">INDEX ( + CONST Feature Change : , ( ( INSERT 6 ( ( t CITYSTATE</definiens>
				<definiens id="5">essential in distinguishing among such cities as Portland , Maine and Portland , Oregon , not to mention the eighteen varieties of Springfield in the con.I. .I . , ' . , E tinental United States The structural pattern of the rule ( Figure 3 ( b ) ) specifies a domain consisting of a city name ( ( INDEX . 6 ) ( + CONST + CITY ) ) followed by an optional comma , followed by a state name ( INDEX ( t CONST *** t STATE</definiens>
				<definiens id="6">a string transforrnatibn designed to prevent surface structure parses in which non-stranded prepositions are erroneously anaalyzed as stranded ones. Since most prepasitions , whether stranded or not. are obligatorily present in surface structures</definiens>
				<definiens id="7">Chanrre p ( ( BAUX ) ) ( ( COMMA 1 ) ( ' ( DAUX 1 ) ( ( PREP ' ) ) ( ( \PUNC T ) ) ( ( V ) ) ( ( VADJ</definiens>
				<definiens id="8">to match on each string consisting of an arabic numeal immediately followed by any member of the set of English ordinal-forming suffixes { d , nd , rd , st , th</definiens>
				<definiens id="9">assigned .trees dominated by the category ORD during ' Header : ( ORDFORM STRING OB ALL ) Structural Pattern : ( ( X</definiens>
				<definiens id="10">a nu~nerical quantifier pf a following nominal expression ( 1 1 ) . It does so by checking the immediatd right-hand cbntext of each ( VADJ ( + CARD</definiens>
				<definiens id="11">people in 19737 items ( such as articles , ausiliarie si punctuation , and verbs ) which are incompatible with the latter possibility , replacing the VADJ structure by a correspondilrg proper noun structure whenever a match occurs. ( CARDNOUN follows ORDFORM in the list of string transformations in order to take advantage of the latter 's replacement of certain cardinals by corresponding ordinals. ) By their very definition , idiomatic expressions are items which present problems in grammatical analysis , sernan'tic interpretation</definiens>
				<definiens id="12">structural pattern of TOPN specities a sequence of elements consisting of an initial arbitrary string of trees</definiens>
				<definiens id="13">a Header : ( TOPN STRING OB ALL ) Structural pattern : Condition : NIL Structural Change..</definiens>
				<definiens id="14">The Rule ! 'Topn '' it ORD ) ) + INC ) ) RANK [ NQUOTE 1 ) THROUGH 8 + ORD ) ) final arbitrary string of trees</definiens>
			</definition>
			<definition id="5">
				<sentence>I. lengthv whicy consists entirely of aq alternating seQuence of proper nouns and'commas , provl'ded that all the proper nouns are members of the same * 4 : semantic class The pattern elements falowihg the Kleene star expression specify that it must be followed by : ( $ another instance of a proper noun of the appropriate class { this will be the initial instance if the null value of the Kleene star expression is the on % y one that matches ) ; Jr 9 .</sentence>
				<definiendum id="0">I. lengthv whicy</definiendum>
				<definiendum id="1">star expression</definiendum>
				<definiens id="0">consists entirely of aq alternating seQuence of proper nouns and'commas , provl'ded that all the proper nouns are members of the same * 4 : semantic class The pattern elements falowihg the Kleene star expression specify that it must be followed by : ( $ another instance of a proper noun of the appropriate class { this will be the initial instance if the null value of the Kleene</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus in `` dressed '' notation the `` peeled'expressions ( A B C .</sentence>
				<definiendum id="0">notation the `` peeled'expressions</definiendum>
			</definition>
			<definition id="7">
				<sentence>6 ) I NIL ( ( REPLA'CE ( , 5 ( ( VING ( ( + LOC2 ) ( + ADJ ) ( + ING ) ) ) ( ( C~ANK ) ) ) 3 4 1 5 1 ( DELETE 3 ) ( DELETE 4 ) 1 NIL 1 -- IL -- II -- -- -- -- .</sentence>
				<definiendum id="0">VING</definiendum>
				<definiens id="0">DELETE 4 ) 1 NIL 1 -- IL -- II -- -- -- --</definiens>
			</definition>
			<definition id="8">
				<sentence>REP ( ( + LOC2 ) ) ) ( ( 1N ) r I ( ( VADJ t ( + ADJ ) ( + ORD ) . ) )</sentence>
				<definiendum id="0">REP</definiendum>
				<definiens id="0">VADJ t ( + ADJ ) ( + ORD</definiens>
			</definition>
			<definition id="9">
				<sentence>€3 ) ( ( NOPI ) ( ( NOUN ( ( + SG ) ( - ' HUMAN ) ( + PLACE ) ) ) ( ( V ) ( PLACE ) 1 ) 7 ) ) ) 3 1 ( DELETE 4 ) 1 NIL j -L.yII -- -- I -- -- -- -- ... -- -- -- -- -- - ( ( RNKINTVL STRING 00 ALL ) ( ( X 1 ) ( OR ( ( BETW~EN .</sentence>
				<definiendum id="0">€3 ) (</definiendum>
				<definiens id="0">( NOPI ) ( ( NOUN ( ( + SG ) ( - ' HUMAN ) ( + PLACE ) ) ) ( ( V ) ( PLACE ) 1 ) 7 ) ) ) 3 1 ( DELETE 4 ) 1 NIL j -L.yII -- -- I -- -- -- -- ... -- -- --</definiens>
			</definition>
			<definition id="10">
				<sentence>5 ) 1 1 ( X rn 6 ) ) NIL ( ( REPLACE ( 2 ( ( PREP ( ( + LOC2 1 ) ( ( IN ) ) 1 1 2 1 ( REPLACE ( ( ( VADJ I ( + A031 ( + ORD ) ) ) ( t'INQUOTE 1 ) 1 1 G ( ( NOMI ( ( NOUN ( ( + SG ) ( HUMAN ) ( + PLACE ) ) ) ( ( V ) ( ( PLACE ) ) ) ( ( INDEX ( f CONST 1 ) ( ( XN ) ) 1 ) ) 4 ) ) NIL f -- -CI- .</sentence>
				<definiendum id="0">NIL</definiendum>
				<definiendum id="1">PREP</definiendum>
				<definiendum id="2">REPLACE</definiendum>
			</definition>
			<definition id="11">
				<sentence>~ 6 ) ( 4 EST ) ) HIGH ) ) NIL ( ( NOM IT NOUN ( V PLACE ) INDEX ) ) ( OR ( ( IN 1 ) ( ( WITH-RESPECT-TO m 8111 ( x'* 9 ) 1 Q NIL ( ( COND ( 6 ( REPLACE ( ( ( PP ) 3 ( ( NPJ ( ( THE1 ( ( NOM ) ( ( V ) ( ( ADV ( t+ EXTI ) ) 5 ) 6 1 7 ) ) ) ) 511 t T ( REPLACF ( ( ( PP ) 3 ( ( NP ) ( ( THE ) ( ( NOMI ( ( V ) ( ( ADV ( ( + EXTI ) ) 5 ) ( ( V ( ( + AD .</sentence>
				<definiendum id="0">EST ) ) HIGH ) ) NIL ( ( NOM IT NOUN</definiendum>
				<definiendum id="1">Q NIL ( ( COND</definiendum>
				<definiendum id="2">REPLACE</definiendum>
				<definiendum id="3">NPJ ( ( THE1 ( ( NOM ) ( ( V ) ( ( ADV</definiendum>
				<definiendum id="4">REPLACF</definiendum>
				<definiens id="0">THE ) ( ( NOMI ( ( V ) ( ( ADV ( ( + EXTI ) ) 5 ) ( ( V ( ( + AD</definiens>
			</definition>
			<definition id="12">
				<sentence>6 ) ( NOT ( ANALYSIS 1 7 ( QUOTE ( ( ( XI ) ( fFROM ) ) ) ) 1 ( tCOND ( ( AND 2 ( NOT ( ANALYSIS 1 T ( ( ( XI ) ( ( PREP ) 1 ( ( THE ) ) ( OR f ( ( NOUN ( ( SG ) ) ) ( ( V ) ( ( YEAR ) ) ) IlfNDEX ) 9 ( ( ( NOUN ( ( + SG ) ) ) ( ( V ) ( ( PERIOD ) ) ) ( ( INDEX ) ) 1 T ) 1 1 ( REPLACE ( ( ( PREP I ( + LOC2j 1 ) ( ( IN ) ) 1 ) 2 ) ) ( T ( DELETE 2 ) ) ( DELETE 3 ) { DELETE 41 ( *REPLACE ( 3 5 ) 5 ) 1 ( ( INSERT 7 ( ( + INTERVAL ) ) ) ) ) ( ( CSYCLSFR STRING OB ALL ) t ( X a 1 ) ( THE a 2 ) ( NOUN ( V ( OR CITY .</sentence>
				<definiendum id="0">QUOTE ( ( ( XI )</definiendum>
				<definiendum id="1">tCOND</definiendum>
				<definiendum id="2">REPLACE</definiendum>
				<definiendum id="3">NOUN</definiendum>
				<definiens id="0">OR f ( ( NOUN ( ( SG ) ) ) ( ( V ) ( ( YEAR ) ) ) IlfNDEX ) 9 ( ( ( NOUN ( ( + SG ) ) ) ( ( V ) ( ( PERIOD ) ) ) ( ( INDEX</definiens>
			</definition>
			<definition id="13">
				<sentence>1 ) ( * ( ( &amp; NOEX ( ORX ( + CITY + STATE + YEAR + CO ) ) ) ( W .</sentence>
				<definiendum id="0">NOEX ( ORX</definiendum>
			</definition>
			<definition id="14">
				<sentence>9 ) ( NOT ( ANALYSIS 1 T ( QUOf E ( ( ( XI ) ( ( IN~EX ( ORX ) ) ) ( ( GENAF ) 1 ( ( COMMA ) ) 1 1 ( 1.2345678u ) ( 1 0 0 0 0 0 ( 2'7 ) 8 9 ) I ( COND ( 5 ( ( fNSERT 11 ( ( + ANDSET ) ) ) ( INSERT UO ( ( 0 SG ) ) ) ( 6 ( INSERT I1 ( ( + ORSET ) ) ) 1 ) 1 ) rrc -- -- -- - ... . -- -- -- -- T-d .</sentence>
				<definiendum id="0">QUOf E ( ( ( XI ) ( ( IN~EX</definiendum>
				<definiendum id="1">INSERT I1</definiendum>
				<definiens id="0">+ ANDSET ) ) ) ( INSERT UO ( ( 0 SG )</definiens>
			</definition>
			<definition id="15">
				<sentence>1 ) ( * ( OR ( ( PREP ( W rn 2 ) ) ) ( ( PREPOF ( W 2 ) ) ) 1 ( ( INDEX ( ORX ( + CITY + STATE + YEAR + CO ) ) ) ( W 3 ) ) ( COMMA 1 4 ) ) ( OR ( ( PREP ( W 2 ) ) ) ( ( PREPOF ( W .</sentence>
				<definiendum id="0">PREP</definiendum>
				<definiendum id="1">PREPOF</definiendum>
				<definiendum id="2">PREP</definiendum>
				<definiendum id="3">PREPOF</definiendum>
				<definiens id="0">INDEX ( ORX ( + CITY + STATE + YEAR + CO</definiens>
			</definition>
			<definition id="16">
				<sentence>2 ) ) ) ( ( INDEX ( ORX ( +CITY + STATE + YFAP + CO ) ) ) ( We 3 ) ) ( OR ( ( CQMNX 4 ) ) NIL ) ( OR ( ( AND 5 ) ) { ( ORR 6 ) ) ) ( OR ( ( PREP ( W m 7 ) ) ) ( ( PREPOF ( W rn 7 ) ) ) 1 ( ( ( NOUN 10 ) ( + SG ) ) ( ( fINDEX .</sentence>
				<definiendum id="0">PREP</definiendum>
				<definiendum id="1">PREPOF</definiendum>
				<definiens id="0">INDEX ( ORX ( +CITY + STATE + YFAP + CO ) ) ) ( We 3 ) ) ( OR ( ( CQMNX 4 ) ) NIL ) ( OR ( ( AND 5</definiens>
			</definition>
			<definition id="17">
				<sentence>2 ) ( NOUN ( INDEX ( + YEAR ) ) ) ) ( NMNL ( + PERIODIC ) ) ( OR ( ( OR ( PREP ) ( PREPOF ) ) ( INDEX ( + CO ) ) NIL ( * COMMA ( ( NMNL 3 ) ( + PERIODIC ) ) ( OK ' ( ( OR ( ( PREP ) ) ( ( PREPOF ) ) ) ( INDEX ( + CO ) ) NIL ) I OR ( ( OR ( ( COMMA 5 ) ) NIL ) AND ( ( NMNL .</sentence>
				<definiendum id="0">NOUN</definiendum>
			</definition>
			<definition id="18">
				<sentence>4 ) ( + PERIODIC ) ) ( COMMA ( ( NMNL 4 ) ( + PERIOD1 I OR ( ( OR ( ( PREP ) ) ( ( PRlE ( INDEX ( + CO ) ) 1 NIL ( * COMMA ( ( NMNL 6 ) ( + PER10 ( OR ( ( OR ( ( PREP ) ) ( ( P ( INDEX ( + CO ) ) NIL ) ( OR ( ( CUMMA .</sentence>
				<definiendum id="0">COMMA</definiendum>
			</definition>
			<definition id="19">
				<sentence>7 ) ) NIL ) AND ( NMNL ( + PERIODIC ) ) 1 1 ( X 8 ) 1 ( AND ( NOT ( ANALYSIS 8 T ( QUOTE ( ( OR ( ( ( PREP ) ) ( ( INDEX ( ( + YEARI ) ) ) ( ( X ) ) ( OR ( ( ( PREP ) ) ) ( ( ( PREPOF ) ) ) 1 ( ( INDEX 4 ( + CO ) 1.1 1 ( ( PREP ) 1 ( ( INDEX ( ( + YEAR ) ) ) ) ( ( XI ) 1 ) 1 ) 1 ) ( CON0 ( 5 3 1 ( T T ) ) ) ( ( REPLACE ( 2 4 ) 4 ) 1 NIL 1 -- -- -- -- -- -- -- .</sentence>
				<definiendum id="0">INDEX</definiendum>
				<definiens id="0">OR ( ( ( PREP ) ) ( ( INDEX ( ( + YEARI ) ) ) ( ( X ) ) ( OR ( ( ( PREP ) ) ) ( ( ( PREPOF )</definiens>
			</definition>
			<definition id="20">
				<sentence>3 ) ( + PERfODIC ) ) 1 ( ( OR ( THE ) NIL ) ( ( NMNL rn 3 ) ( +PERIODIC ) ) ( OR ( ( OR ( PREP ) ( PREPOF ) ( INDEX ( + CO ) ) 1 NIL I 1 1 ( * COMMA ( OR ( ( INDEX ( + CO ) ) GENAF ( NMNL ( + PERIODIC ) ) ) ( OR ( THE ) NIL ) ( NMNL ( + PERIODIC ) ) ( OR ( ( OR ( PREP ) ( PREPOF ) ) ( INDEX ( + CO ) ) 1 NIL 1 1 'COMMA ( OR ( ( TNDEX ( + CO ) ) GENAF ( ( NMNL 2 ) ( + PERIODIC ) ) ( ( OR ( THE ) NIL ) ( ( NMNL .</sentence>
				<definiendum id="0">) ( OR ( ( OR ( PREP ) ( PREPOF ) ) ( INDEX</definiendum>
				<definiens id="0">* COMMA ( OR ( ( INDEX ( + CO ) ) GENAF ( NMNL ( + PERIODIC ) ) ) ( OR ( THE ) NIL ) ( NMNL ( + PERIODIC )</definiens>
			</definition>
			<definition id="21">
				<sentence>~ ITHE ) NIL ) ( NMNL ( + PERIODIC ) ) ( OR ( ( OR ( PREP ) ( PREPOF ) ) ( INDEX t+ C0 ) ) ( PREP 6 ) ( ( PROPNOM 7 ) ( NOUN ( INDEX ( + YEAR ) ) , ) ) 1 ( ( PREP 6 ) ( ( PROPNOM rn 7 ) ( NOUN ( INDEX ( + YEAR ) ) ) ) ( OR ( PREP ) ( PREPOF ) ) ( INDEX r+ CO1 ) 1 1 1 ( X 8 ) ) ( AND ( NOT ( ANALYSIS 1 T ( QUOTE 1 ( OR ( ( ( XI ) ( ( INDEX ( ( + CO ) ) ) ) ( ( GENAF ) ) ) ( ( ( X ) ) ( ( THE ) ) ) t 1 ( X ) ) ( ( NMNL ( ( + PERIODIC ) ) ) ) ( OR I ( OR ( ( ( PREP ) ) ) ( ( ( PREPOF ) ) ) 1 ( ( INDEX t ( + CQI ) ) ) ) NIL ( ( COMMA ) ) 1 ) 1 ) ) 1 ( COND ( 53 1 ( 7 TI ) ) ( ( COND ( 4 ( RFPLACE ( 4 6 7 ) 4 ) ) ( T ( REPLACE ( 2 6 7 ) 21 1 1 1 NIL -- -~ .</sentence>
				<definiendum id="0">OR ( ( OR ( PREP ) ( PREPOF ) ) ( INDEX t+ C0 ) )</definiendum>
				<definiendum id="1">NOUN</definiendum>
				<definiendum id="2">NOUN</definiendum>
				<definiendum id="3">COND</definiendum>
				<definiendum id="4">TI ) ) ( ( COND</definiendum>
				<definiens id="0">XI ) ( ( INDEX ( ( + CO ) ) ) ) ( ( GENAF ) ) ) ( ( ( X ) ) ( ( THE ) ) ) t 1 ( X ) ) ( ( NMNL ( ( + PERIODIC ) ) ) ) ( OR I ( OR ( ( ( PREP ) ) ) ( ( ( PREPOF ) ) ) 1 ( ( INDEX t ( + CQI ) ) ) ) NIL ( ( COMMA ) ) 1 ) 1</definiens>
			</definition>
			<definition id="22">
				<sentence>( OR ( PREP ( INDE'X ( + YEAR ) ) ) NIL ) 1 1 1 COMMA ( OR ( THE ) NIL1 OR ( ( INDEX ( + YEAR ) ) ( CNMNL 2 ) ( + PERIODIC ) ) ( ( ( NMNL 2 ) ( + PERIODIC ) ) ( OR ( PREP ( INDEX ( + YEAR ) ) ) NIL ) 1 1 ( * COMMA ( OR ( THE ) NIL ) ( OR ( ( INDEX ( + YEAR ) ) ( ( NMNL , .</sentence>
				<definiendum id="0">PREP</definiendum>
				<definiendum id="1">COMMA ( OR</definiendum>
				<definiens id="0">+ PERIODIC ) ) ( OR ( PREP ( INDEX ( + YEAR ) ) ) NIL ) 1 1 ( * COMMA ( OR ( THE ) NIL ) ( OR ( ( INDEX ( + YEAR</definiens>
			</definition>
			<definition id="23">
				<sentence>5 ) ) ) ( INPRQPNOM 6 ) ( NOL'N ( INDEX ( +CO ) ) ) ) tx , 7 ) ) ( AND ( NOT ( ANALYSIS 1 T t QUO1 E ( ( OR ( ( ( XI ) ( ( THE ) ) ) ( ( ( XI ) ( INMNL ( ( + PERIODIC ) ) ) ) ( OR ( ( + YEAR ) ) ) ) NIL ( ( COMMA ) ) ( ( ( lo ) ( ( INDEX ( ( +YEAR ) ) ) ) 1 ) 1 ) 1 ) ( COND ( 4 3 ) ( T TI ) ) ( ( REPLACE ( 2 5 6 ) 2 ) ) NIL 1 ( ( CARDNOUN STRING 08 ALL ) ( IX .</sentence>
				<definiendum id="0">COND</definiendum>
				<definiens id="0">AND ( NOT ( ANALYSIS 1 T t QUO1 E ( ( OR ( ( ( XI ) ( ( THE ) ) ) ( ( ( XI ) ( INMNL ( ( + PERIODIC</definiens>
			</definition>
			<definition id="24">
				<sentence>3 ) PREP ) ( ( VPART 3 ) ) ( X 4 ) ( NOT AND ( ANALYSIS 3 NIL ( QUQTE t ( ( ~ ) ) ) ) ) ( ANALYSIS 4 T ( QUOTE ( ( ( INDEX ( ( CONST ) 1 ) ( ( X ) ) 1 ) 1 ) 1 ( ( REPLACE ( t ( NP1 ( ( NOMI ( ( NOUN ( ( + SG ) ( HUMAN ) ) ) ( ( INDEX ( ( + CONSTI ( + CARD ) ) ) 5 ) 1 1 1 2 ) ) NIL ' 1 ( ( ABTAPPRX STRING 06 ALL ) ( ( X `` 1 ) ( ( PREP 2 ) ABOUT ) ( OR I ( IVAD3 e 3 ) ( + CARD ) ) ) ( ( EQUAL 3 ) ) ( ( WH .</sentence>
				<definiendum id="0">REPLACE</definiendum>
				<definiens id="0">( t ( NP1 ( ( NOMI ( ( NOUN ( ( + SG ) ( HUMAN ) ) ) ( ( INDEX ( ( + CONSTI ( + CARD</definiens>
			</definition>
			<definition id="25">
				<sentence>10 ) ( NOT ( ANALYSIS 1 Nf L ( QUOTE ( lW ( ( ( NrSS ) ) ( ( ( NOT ) ) ) 1 1 ) 1 ( ( COND ( ( AND 6 ( NOT 5 ) ) ( REPLACE I 4tADV ) ( ( V ( ( + ADS ) ( + COMP ) ( + TWOARGS ) ( + NMA3X ) ) ) ( ( GREATERTHAN ) 1 ) 9 9 ) ( ( AND f ( NOT 5 ) ) ( REPLACE ( ( ( ADV ) ( ( V ( ( + A031 ( + COMP ) ( + TWOARGS ) ( + NMA3X ) ) ) ( LESSTHAN ) 1 ) ?</sentence>
				<definiendum id="0">QUOTE ( lW ( ( ( NrSS ) ) ( ( ( NOT</definiendum>
				<definiendum id="1">COND</definiendum>
			</definition>
			<definition id="26">
				<sentence>2 ) ( V WH SOME ) ) ( ( VADJ 2 ) LARGE ) ( A 2 ) ( ( NOMQ 3 ) ( NOUN I v ( OR ( ( NUMBER 7 ) ) [ ( AMOUNT 81 ) ) 1 ( INDEX 9 ) 1 ) ( OR ( ( OF 4 ) ( THE 5 ) ) ( ( OF 0 4 ) ) NIL 1 ( X m 6 ) [ AND ( NOT ( ANALYSIS 6 IS1 ( QUOTE ( ( OR ( ( ( OF ) ) ( ( X ) ) ) ( ( ( THE ) ) ( ( XI ) ) 1 ) 1 ( COND ( ( NULL 4 ) 8 ) T TI ) ) ( ( COND ( 4 fCOND ( 7 ( REPLACE ( ( ( WHADJ ) ( ( ADV ( ( + EXTI ) ) ( ( V ( ( + AD31 + QUANT ) ) ) ( ( WH ) ( ( SOME ) ) 1 1 ( ( V ( ( + ADJ ) ( + QUANT ) ( + POL ) ) ) ( IYANY ) ) 1 1 3 ) 1 ( 8 ( REPLACE ( ( { WHADJ ) ( ( ADV ( ( + EXTI ) ) ( ( V I ( + AD31 f+ QUANTJ ) ) I ( WH ) ( ( SOME ) ) 1 1 ( ( V ( ( + A031 + QUANf ) ( + POL ) ) ) ( ( MUCH ) ) 1 1 3 ) ) ) ) ( T ( REPLACE ( ( ( ONOM ) ( /ADV ( ( + EXTI ) ) ( ( V ( ( + AOJ ) ( + QUANT ) ) ) ( ( WH ) ( ( SOME ) ) 1 f ( NOM ) ( ( NOUN ( ( 0 HUMAN ) ( + SG ) ] ) ( ( V ( ( + ADJ ) ( + QUANT ) ( + POL ) ) ) ( ( MUCH ) ) 91111 3 ) 1 ) ( CONO ( ( AND 4 ( NOT 5 ) ) ( DELETE 4 ) ( DELETE 2 ) ) NIL 1 -- -- -rr .</sentence>
				<definiendum id="0">V WH SOME ) )</definiendum>
				<definiendum id="1">AND ( NOT</definiendum>
				<definiendum id="2">QUOTE ( ( OR ( (</definiendum>
				<definiendum id="3">REPLACE</definiendum>
				<definiendum id="4">ADV</definiendum>
				<definiendum id="5">V</definiendum>
				<definiendum id="6">CONO</definiendum>
				<definiens id="0">( OF ) ) ( ( X ) ) ) ( ( ( THE ) ) ( ( XI ) ) 1 ) 1 ( COND ( ( NULL 4 ) 8 ) T TI</definiens>
				<definiens id="1">REPLACE ( ( { WHADJ ) ( ( ADV ( ( + EXTI ) ) ( ( V I ( + AD31 f+ QUANTJ ) ) I ( WH ) ( ( SOME ) ) 1 1 ( ( V ( ( + A031 + QUANf ) ( + POL ) ) ) ( ( MUCH ) ) 1 1 3 ) ) ) ) ( T ( REPLACE ( ( ( ONOM ) ( /ADV ( ( + EXTI ) ) ( ( V ( ( + AOJ ) ( + QUANT ) ) ) ( ( WH ) ( ( SOME ) ) 1 f ( NOM ) ( ( NOUN ( ( 0 HUMAN ) ( + SG ) ] ) ( ( V ( ( + ADJ</definiens>
			</definition>
			<definition id="27">
				<sentence>4 ) NIL ( ( REPLACE ( ( ( NMNL ) 2 3 ) ) 31 ( DELETE 2 ) 1 NIL 3 ( ( RANKCMPD STRING OR ALL ) ( ( X , 11 ( NMNL 2 ) ( ( NMNL 3 ) ( V PLACE RANK ) INDEX ) ( X .</sentence>
				<definiendum id="0">NIL ( ( REPLACE</definiendum>
			</definition>
			<definition id="28">
				<sentence>E ( ( ( GENAF ) ) ( ( X ) ) ) 1 1 ( AND ( ANALYSIS 5 /Sl ( QUOTE ( ( ( NMNL ( ( + PERIODIC ) ) ) ) f. ( X ) ) 1 1 1 ( ANALYSIS 4 YIL I QUOTE ( ( ( PROPNOMI ( ( NOUN ) ( ( INDEX ( t+ YEAR ) ) ) ) 1 1 1 1 1 1 1 1 I ( CON0 ( 2 ( REPLACE ( ( ( PPI 2 ( ( NP ) 4 ) ) 1 2 ) ) ( 3 ( REPLACE ( ( ( PPOF ) 3 ( ( NP ) 4 ) ) 31 1 ) ( DELETE 4 ) 1 NIL ( ( XI ) 'I 1 T TI ) ( COND ( ( NOT 5 ) ( ANALYSIS 1 T ( QUOTE [ ( ( XI ) ( ( GENAF ) ) ) ( T TI11 ( ( COND t 2 ( REPLACE ( ( ( NOMI 2 ( ( 21 ) 5 6 ) ) 2 ) ) ( 3 REPLACE ( ( ( NOMN ) ( ( N~~MNI 3 ) ( ( Z1 ) 5 6 ) 1 3 1 , 1 14 ( REPLACE ( ( ( NOMN ) ( ( NOMN ) 4 ) ( ( 21 ) 5 6 ) ) 1 4 ) 1 ) ( DELETE 5 ) ( DELETE '6 ) 1 NIL1 ) C-1 -- -CI -- -ILI -- C-LII -- -- -- -C-1 -- .</sentence>
				<definiendum id="0">E ( (</definiendum>
				<definiendum id="1">REPLACE</definiendum>
				<definiendum id="2">NIL</definiendum>
				<definiendum id="3">COND</definiendum>
				<definiendum id="4">XI ) ( ( GENAF ) ) ) ( T TI11</definiendum>
				<definiendum id="5">REPLACE</definiendum>
				<definiens id="0">REPLACE ( ( ( NOMN ) ( ( N~~MNI 3 ) ( ( Z1 ) 5 6 ) 1 3 1 , 1 14 ( REPLACE ( ( ( NOMN ) ( ( NOMN</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>Frequency is the vertical axis , time the horizontal , and darker marks indicate more energy .</sentence>
				<definiendum id="0">Frequency</definiendum>
				<definiens id="0">the vertical axis , time the horizontal , and darker marks indicate more energy</definiens>
			</definition>
			<definition id="1">
				<sentence>WRITB is a subroutine to write the contents of the array NBUF onto tape or disk .</sentence>
				<definiendum id="0">WRITB</definiendum>
				<definiens id="0">a subroutine to write the contents of the array NBUF onto tape or disk</definiens>
			</definition>
			<definition id="2">
				<sentence>The subroutine uses the common area to store several variables , which or course could he declared as formal parameters insteqd , ISWV is a voicing switch used in the logic internal to GLOT .</sentence>
				<definiendum id="0">ISWV</definiendum>
			</definition>
			<definition id="3">
				<sentence>TDEL is the period between output sample points in milliseconds ; in the over-all initialization of the program , its value should be caloulated as 1000.0SR .</sentence>
				<definiendum id="0">TDEL</definiendum>
				<definiens id="0">the period between output sample points in milliseconds</definiens>
			</definition>
			<definition id="4">
				<sentence>TP , TI , and T2 are durations ( in millisecond^ ) from the hegirining or the glottal pulse , calculated and used by GLQT : TP is the duration of the pulse .</sentence>
				<definiendum id="0">TP</definiendum>
				<definiens id="0">the duration of the pulse</definiens>
			</definition>
			<definition id="5">
				<sentence>la07 4087 $ P &amp; c~H UhU6 &lt; UORPM~ZLO ? Figure 6. Wave Shape and Spectral Analysis of a Polynomial Approximatioa to a Glottal Wave. FOX details of the display , cf. Fiqure 4. Figure ruNevxaN CLOT ( P , ~AV ) COMMON ~~uV~TDFL~TG~TP , ~~ , TD~OPTR~CLTR~AV~AVE C C PRODUCES A POLYNOMIAL 4PPROXIHATfON TO L GLOTTAL WAVE C WITH CON~TANT WAVE $ HAPf ! c c uacs THE ~OL~O~XNG VARIAR~E~ man COMMONI XSWV , C TDfC~TC , tP , TlrT2 , aPTR , CLTR , Av1AVt ; C C PlR8T 8EC IP HI ! NEED TO RLmINIIIALItL~ C FOR BLGfNHlNG OF GLbTTAL HAVE C C ARC Wt HOW GENERATING VOftET rr ( X~MVI ~BE , I ? ~ , { ~ c YES -. 31 HE ARE NOT AT THE END or A ruLaC , C PARAMETERS ARE OeK , C OTHERWl3E YE NEED TO CHECK'AV Tb SEE c xr HE NEED ANOTHER PULSE 1 0 IF ITG+0,5*WEL-TP ) 5B128p20 C EITHER HE HAVE NOT BEEN GENERATING VOICE OR C WE HAVE JUST FINISHED A PULSE rr C IF ' AV P 0 , XNITIALXZE TO GENERATE A ( NOTHER ] PULIL C AND RESEt ISYV TO 1 C OTHERWISE ( REj8ET ISHV TO B 28 IP* ( Av ) 30 ; 30,40 3d 2Suv.a GO TO 50 C INITIALIZE FOR ANOTHER PULSE 48 ISWVll hVSAVE8 AV t6aB.B TP.lB0BeG9/P TlmOPTRtTP TSmTl*CLtR*TP 58 CONTINUE C C END Of PARAMETER SETTING c c BEGINNING OF L~GXC TO GENERATE GCQTIAL WAVE C IF ( IJWY ) 571S5t57 55 Y.R18 to to 108 57 CONTINUE C C fr TG TI , Y.AV* ( ~* ( TC/T~I~*~-~+ ( TG/T~ ] **J ) 138 I. # ( TG.Tll 148 , ) SAP 15R 149 Y~AvSAVE* ( J , B* ( [ TG/Tl ) **2 ) -2,8* ( ( TC/tl ) c*3~ ) GO 70 180 C ELSE IF TS * 72 , Y~AV* ( l~ ( ( ( TG~fl ) / ( T2~Tl ) ) **2 ) ) 159 IF ( TG*T2 ) 16G1178a17B c ELSE rue 178 Y.fl , fl GO TO A80 c C EN0 OF GLOTTAL PULSE GENERATION C RETURN VALUE OP GLOTTAL NAVE d AND XNCREHENT TG C 189 G~O~DY TG.TG+JtIEL REYURN C c ERROR IN VALUE OF xsrv C- ' 900 UR ! TE ( I,9i @ ) 13UV 010 FORHAT ( `` * ERR IN GLDTll ~~YvR~~ , I ! J ) CALL HOLD CALL EXIT €NO C GCOT Fort ran Function Generate Glottal Waves ratio '' ) i8 the tractlon or tne wave oacuplea by The opening phase , and CLTR is the fraotion occupied by cl~cring. In the over-all initialiaettion , OPTR ehould be set to .40 and CLTR Lo .16 , values which maximize naturalness according to Rosenbergfs paper. Sf the instantaneous values of A\I were used by GLOT , the standard , wave shape would be altered if AV were changing during generation of a glottal wave. To keep the wave shape constant , GLOT uses the variable AVSAVE to atore the value of AV at the beginning of each pitch period , and during the generation of the pulse , AVSAVE is used as the ( constant ) amplitude. Between calls to GLOT , the values of Ismt TG , TP , T1 , T2 , and AVSAVE should not be altered , Rosenbergls equations for the polynomial approximation are used in GLOT ; to get the linear approximation , the following two lines of Fortran should be substituted in GLOT for lines number 60 and 64 : Almost any reasonably good random-number generator can be used as a source of white noise. If the spectrum of the random numbers produced is flat , it will be easier to shape into the desired spectra fox the different fricative sounds. The algorithm we use was developed for use in synthetic speech work : it is very fast , and produces noise with a quite flat spectrum. Its presentation by Rader , Rabiner , Schafer , and perryl is easy to fellow and implement. The logic of the algorithm is formally stated in Fortran in Figure 8 , page 18 , but if possible this should be one function coded in alssembly language : if the right machine instructions are available , it will be snap , but `` bit in Fortran is very slow. Our function IRN4 ( X ) -X is a dummy variable required by our Fortran compiler -contains this algorithm in assembly language , producing on successive calls a series of random numbers with a uniform distribution over the interval from -2047 ta +2047. To implement a white noise generator , only this line of coding is needed : where AN is a variable whose value is the amplitude of noise desired. A typical stretch of noise produced in this manner , along with its spectrum , is given as Figure 9 , page 19. Note that there does not appear to be any significant deviation from flatness in the spectrum intensity. B. Spectral Shaping Elements We use recursive equations , a technique developed by electrical engineers , to simulate resonant. and anti-resonant ( notch ) filters as elements to shape spectra. Each individual filter can be represented by a second-order linear differential and Rabiner ( 1972 ) FUNCTION IRN4 ( X ) COMMON NM1 ( 19 ) , NM2 ( 19 ) DlMENsION NX1 ( 19 ) , NX2 [ 19 ) C FORM BIT-WISE EXCLUSIVE OR OF NMl , NM2 DO 10 I=1,19 10 ~Xl ( f ) -MOR ( NM1 ( 1 : ) , NM2 ( I ) C ROTATE NXI , 8 PLACES TO TI.B RIGHT DO 20 I=l , ll 20 NX2 ( I+B ) =NXl ( I ) DO 30 I=12,19 30 NX2 ( 1-11 ) =NXl ( I ) C SHIm PAST VALUES DO 40 I=l,19 NM2 ( I ) =NMl ( I ) 40 NMl ( I ) ==NX2 ( II C RETURN VALUE OF LEFT-MOST 12 BITS OF NX2 IRN4=MINT ( PfX2 ) C END ] HETURN END Figure 8. Random Number Generator Documented In k'ortran. NMl ( 19 ) and NM2 ( 19 ) are ! arrays whose elements have either the value 0 or 1. MOR ( Nl , N2 ) is a function returning the exclusive or of N1 and N2 , variables having either the value 0 or 1. MINT ( N ) is a function whose argument N is a bitstring array such as NM1 and which returns a 12-bit integer value consisting of the left-most 12 elements of N packed into a single word. 80 80 'to 20 Figure 9. Typical Wave Form and Spectral Analysis of the Output From the White Noise Generator. For details of the display cf. Figure 4. equation , giving only one resonance or anti-resonance. FOX those who feel at home in the s-plane , the recent book 8p ? .eCh -Synthesis . -- edited by Flanagan and Rabiner contains rsprinta of pawrs developing the theory of recursive equation filter simulation : for the rest of us , the paper by Lovell et al. ( 1973 ) is a clear presentation , with some more general Fortran algorithms than will be given here. Figure 10 , Rage 21 , gives one Fortran subroutine and two Fortran functions which we use to simulate resonant and anti-resonant tllter8. The functions RE3 and ARES return the output values of simple resonant ( conjugate pole pair ) and anti-resonant ( con jugate zero pair ) filters. respectively. AO , Al , and A2 are coefficients used in the recursive equations. I and Y'M2 axe remembered previous values of the signal , and Y is the input to the filter. AO , Al , and R2 determine the characteristics of the filter : center frequency and bandwidth. Each simulated filter should have its own variables in which to save the values of YM1 and YM2 , and between calls to the fdnction simulating that filter , the values of these variables ahould not be changed. The subroutine COEFF is used to calculate appropriate values for AO , Al , and A2 , based on CF , the center frequency , and BW , the bandwidth. of the resonance or anti-resonance. 1 SR is the output sample rate , and MPZ tells the subroutine A.C.L. meeting , there was an error in line 16 of subroutine COEFF ~UBRQUTXNL ~o~e~ccr , aw , ~s , rr , ~a , s~ , ~rz~ C C ! COMPUTE8 THE R~CURbIVE EQUATION EQEFPXCIENT8 C A0 , AIIAQ FOR EXf'HER A RESONANT OR AN'TIRPBONATL PILTCR C ~IPEC~ $ '~~U 0Y CENTER FRl ! ! OULNCY CF AND BANbWtOTH IW ( HZ. ) C 8R 18 THE SAMPLE RATE ( ~AMPCESI~EC } S IP WPLqI , FILTER WIlL BE ? A RPIONANCE C IF MPZ80 , CXLfER WILL BE AH ANTTRCBONANCE ? X~3 , t4159Q66 AaPXlrcBW/SR Bs2,8*PI*CP/SR AO~EXP Cm2 , B*Aj A~~ &amp; , B+EXP ( a41 +CO5 CB3 &amp; 0mlnBrA1+A2 IF ( MPZ ) 2flulflrQ0 10 AO @ l , B/AB 20 RETURN END QUNCPIQN RESCYtYM11YM2rA0 , Alra2 ] C C SIMULATES RE80NATOR ( CONJUGATE POLE PAIR1 C GXYENpBY RECURSIVE EQUATION COEFPZCIENTS ABPA1 , A2 C YMi khlD VM2 ARE PAST VALUE $ OF YI THEIR VALUES C MUST BE SAVED YRESrnABtY+Al *YM~uA~*YM $ YM2aYMt YMtrVRES ISESrVRES RETURN END FUNCTION AREJ ( V~YMIpYM2 , A01hlCA2J C C SIMULATES ANTIRESONATOR ( CONJUGATE ZERO PAIR ] C GIVEN BV RECURSlVE EQUATION COLfPfCIEN79 AB , Ai , A2 C Jn ! AN0 YM2 ARE PAST VALUES OF Yt THEIR VALUU C MUST BE SAVED TEHPaY+A0 ARESeTEMP*Al*YMl*A2+YM2 YMZ ! 3YMf YMlrTEMP RE*~URN END Figure 10. Fortran Implementation of Elemental Filters whether to compute ~oeffi~i0nt~ fsr B rasonancs or an antiXBEI onance The spectral effect of a resonance with center frequenay of 3000 He and bandwidth of 200 Ha is illustrated in Figure 11 , page 23 , while Figure 12 , page 23 , is a similar illustration of the , effect sf an anti-resonance of the same center freq'uency and bafidwidth. In these figures , the fixst graph shows output for an impulse input and the second graph shows the normalized intensity spectrum , of that output. The effect~on the spectrum of , the radiation of sound from the lips through a short stretch of air can be reasonably approximated by a differentiat0r.l Figure 13 , page 24 , gives a simple Fortran function KAD simuLating this effect. Y is the speech mve input to the simulater , YM1 is the remembered immediately previous value of Y , hfid G is a normalizing gain control which should be calculated in the over-all initiaLization as a direct function of the output sample xake , some K times OSR. The spectral effect of RAID , approximately a 6 dI3/octave rise , is illustrated in Figure 14 , page 24. IV. Organization of Elements A. The Simplest Model The simplest reasonable model f~r connecting these elements , which we have taken to calling `` Mode3 TI ' , fs given in block diagram form in Figure 15 , page 25. We use this organization In our currently ru'nning synthesizer. The three vdriable -. ... . '' r '' '' * `` `` + -- -- a-2011 -. *I -- -- . , -- ~1.m mrc. I 28.11 treac~ unvc &lt; nounn~ t ZED ) Figure 11. Spectral Shaping Effect of an Elemental Resonant Filter with CF=3000 'Hz and BW=200 Hz. Figure 12. Spectral Shaping Effect of an Elemental Anti-Resonant Filter with CF=3000 Hz and BW-200 He. RAD~O*~YIYMII YMlnY RETURN END Figure 13. Fortran Function to Simulate Radiation Ef feat. OU 2K YK BK 8 % low FREQUENCY , KHz. ~WTL~~~ZTY ~CECTRUH ~W~R~~LIZED , nhx. camr. r a+. 76 or. , Figure 14. Spectral Shaping Effect of Radiation as Simulated by Function RAD. resonant filtexs are used to make tha formants of voiaad speech and , in a rather strained fashion , toshape the noise spectrum during frication and aspiration. AIL of the elements in this figure should now be familiar except the one called `` higher otder correction filter.^^ This is a series of resonant filters of fixed center frequency and bandwidth which cornpensat e for the effect of higher -f requency resonances present in a real vocal tract but absent in a digital simulation of this kind. Their use is discussed in Rabiner ( '1968. ) from which the values presented in Figure 16 , page 27 , were taken. These are the values to use for center frequency and bandwidth of the higher order correcting filters. Only higher-order fjlters with center frequency less than &amp; khe output sample rate should be used. The xecursive equation coefficients AO , Al , and A2 need be calculated only once , in the over-all initialiaation. Theoretically , the arder of computation of the series elements such as those in the main stem of Model T , makes no difference. However , because the digital numbers are finite in length round-off or truncation errors are introduced at each step of ' the computation The overall error increases as the number of computational steps increase. Some types of computation such as differentiation tend to increase the error , while other types such as integration tend ro aecrease -me error. For this reason , overall system error is related in a complex way to the order of computation. An understandin of error buildup and testing of the various algorithms will help in choosing the computational sequence that results in smallest errors In the case of cascaded resonators. it is better to perform the computation in reverse order from that implied by Fig. 15 radiation effect first , then higher order filters in descending center frequency order , then formant filters. Resonator No. Center Freq. ( Hal Bandwidth ( Hz ) Figure 16. Higher Order Correction Filter Center Frequencies and Bandwidths. From Rabiner ( 1 968 ) C ZERO VARIABLE HOLDING NEXT SPEECH WAVE POINT YN=O -0 C ADD GLOTTAL WAW YN-YN-tGLOT ( P , AV ) C ADD FRICATIVE NOISE YN=YN+AN* ( FLOAT ( IRN4 ( X ) ) /2047mO ) C -PLY FORMANT FILTERS W 200 I=1,3 200 YN==S ( YN , ml ( I ) , YM2 { IJ , AO ( I ) , Al ( I ) , A2 ( I ) 1 C APPLY HIGHER ORDER CORREZTING FILTERS DO 250 I=l,7 250 YN=RES ( YN , ~~ ( ~ ) , ~~ ( I ; ) , HAO ( I ) , HA~ ( I ) .~~ ( I ) CaAPPLY IRADIANCE EFFBCT YN=RAD ( YN , RYM1 , GRAD ) Figure 37. Model T Logic in Fortran. The conversion of the Model T block diagram into Fortran is illustrated by Figure 17 , page 27 , the series elemel~ts being here computed in their natural order. This coding is an example of what should be inserted into the over-all logic ( Figure 3 , page 9 ) following the comment lines `` GENERATE NEXT SPEECH WAVE I I POINT. , . . B. Control In the Model T organization , nine control parameters are available -P ( pitch ) , AV ( amplitude of voicing ) , AN ( amplitude of noise ) and the center frequency and bandwidth of three variable formant filters. In the main loop , just before generating the next speecn wave point , a subroutine ( it can be in-line code , of course ) calculating values of these parameters is needed. If at the beginning of the program the variable T ( time ) is initialized to zero and lncremented by TDEL at the end of the main loop , it can serve as a simulated-time clock on which to base calculation of the , control parameters. The simplest method of control is to formulate the desired control parameter curves algebraically and just include Fortran statements in this sedtion calculating their values as in the algebraic equations. For example , suppose we mnted the pitch to rise linearly from 80 to 120 Hz in the first 100 msec , stay constant at 120 Hz for 200 msec , then fall linearly ta 100 Hz in the next 100 msec and stay at that value from then on. The following Fortran statements can be used to calculate P : 60 TO 270 260 P=lOO , O 270 CONTINUE When new values of CF and BW are computed for the three variable formant filters , subroutine COEFF should be called to translate these into the coefficients AO , Al , and A2 actually used by function RE $ . If new valQes of thi control parameters are calculated every sample point , the execution time of the program will be very long There ape several obvious ways to speed up this calculation. One way is to calculate new values for P and AV only at the. beginning of each pitch period , since this is the only time GLOT uses them. With some error introduoed. the control parameters can be re-computed only every so many meeo to speed things up. A variable used as a time clock in the same way that TG is used by GLOT can control this period. Computing the source control parameters ( P , AV , and AN ) this way introduces error only in that the actual parameter curves will follow the desired curve in s step-wise fashion , but changing the characteristics of the formant filters this way will introduce another type of error , which comes out sounding like clicks or static if the change in filter characteristics is too large. Our currently-implemented a~sembly-language synthesizer reads a fil'e of tabled values created by another program as values representing the parameter curves. The period between tabled parameter values is changeable , but on the order of 5 to 10 msec. In computing the actual parameter values used , t % e synthesizer interpolates linearly along the tabled parameter data curves. The step size of the interpolation can be easily changed , allowing a smooth trade-off between accuracy and execution time. To sum up , computing new control parameter values fox each sample point generated is the easiest and most accurate way , but alternative schemes allowing a convenient trade of accuracy for speed are easily programmed C. Other Models We will briefly describe several alternative organizations of the elements , although most of our practical experience has been with the Model T organization. 1 , Parallel Formant One model used in some synthesizers la the parallel formant model , whose block diagram is given as Figure 18 , page 32. In serial formant models such as Model T , no independent control of the relative i~teensities of formants is possible , since the order of operatiom is immaterial. It has been shorn that the relative intensities of formants in a serial svnthesis closely match those found in natural speech , 1 which is some justification of the serial model as an analog of the vocal tract. But in a parallel formant arrangement , each parallel channel must have a separate gain control. This is fine if voulre investigating the perception of relative formant intensities , but not many have chosen this model for general speech synthesis Rabiner ( 1968 ) contains a worthwhile discussion of the relative merits of serial and parallel synthesis. If you decide to try a parallel formant model , the higher order correcting filters are apparently unnecessary , and Rabiner ( 1968 ) mentions that zeros -anti-resonances -are introduced into the spectrum. In Model T , the sqme three filters are used to make the formants ot voiced speech and to shape the spectrum of noise during unvoiced speech. This is cumbersome and difficult , and a simple alternative is illustrated in Figure 19 , page 34. I GLOTTAL WAVE^^ AV RADIATION EFFECT . 1 1 I h -. Figure 18. Parallel Formant Organization Model RESONANCE CF1 RESONANCE -CF2 NO , 1 NO. 2 BW1 m L * RESQNANCE NO. 3 CF3 BW3 A separate channel ie devoted to nolae , with its own resonant and anti-resonant filters for spectral shaping. It haa been suggested that one remnance and one anti-resonance axe sufficient to nodel me $ English fricatives. 1 Of course , this model adds two new control parameters ta be computed. Model T does not use anti-resonances ; they are not typical of voiced speech , but rather are present in the spectra of faicatives and nasalized segments. For making nasal sounds , a parallel nasal channel whose input is the glottal wave and whose output is added in just before the radiance effect calculation can be added. The spectral shaping filters needed in this channel are not obvious from published reports , but one variable anti resonance and several fixed resonances are probably a minimum complement. A multitude of more complex models can be seen in the literature , -Rabiner ( 1968 ) . to take one example , includes a special a'rrangement for generating voiced fricatives. D. A Complete Example To illustrate the capabilities of the ~implest synthesis model , on the following pages we present as Figure 20 a complete Fortran program for synthesizing the wrd llseatll ( sith ] ) . We tried to duplicate one particular token utterance of , this word. Spectrograms of the original sound used as a model and the synthesized sound calculated by the Fortran program are shown in -- GLOTTAL WAVE PARAMETERS RESONANCES VOCAL TRACT PARAMETERSNTI-RESONANCEFigure 19. Block Diagram of Model With Separate Noise Shaping Channel Figme 21 , page 44. Deriving the parameter curvQa from the token utterance took a lot of work , but as Figure 21 shows , the rssulkihg ~lynthetic word is a reasonably close copy of the original. For those who may want to use , this program as a beginning to their work , several features of it will be explained. The basic model used is the simplest , model W '' f ( Figure 15 , page 25 ) with one addition : the noise signal is multiplied by a relative gain constant ( GFRIC ) before entering the vocal tract ( variable filter ) section. The output sound wave is stored a block at a time in file WWRK1. This file is opened by the subroutine called in line 43 written into in line 455 , and closed in line 470. Parameter values are periodically calculated from piecewise polvnomial algebraic speciffications in the section called ! lGPARfI , lines 142 to 415. The periods between parameter re-calculations are controlled by twa variables serving as clocks , TVOC for voicing parametexs and TFRIC for frication parameters. The values of PVOC and PFRIC are the times in msec between re-calculations of vocalic and fricative parameter values , respectively. These parameter values can be reset more often by merely changing the values assigned to PVOC and PFRIC in lines 93 and 37 ; at present frication parameters are reset every The Fortran logic calculating the parameters was coded for clarity , not economy , and though lengthy should be easy to follow. The primitive subroutine TPOW returns pawrs of a variable for ease in calculating polynomial functions of time : after calling TPOW ( T , N , TX ) ~x ( I ) =T~ , TX ( Z ) =T~. . . . TX ( NI=TN Certain paramaters are constant during aome of the sounds , e.g. , spectral parameters during ft3fN. As a minolr concession to exeoution speed , these constant parameters are not reset after the first entry into the section during which they are constant The variables 19W1 , ISW2 , and 1SW3 are irst-time-through '' switches , used tb remember whether or not the tempora1 : il.y constant parametei-s have hen calculated yet. We have found that duplicating a token of natural speech using thLs simple basic synthesis model , though possible , can be quite difficult , requiring much trial-and-error work. Fortunately , much research on speech perception does not require exact duplication of given utterances , but instead uses simpler sets of parameter curves. An example of such a program , which synthesizes the vowel /it with constant pitch and intensity can be made by substituting the following code for the `` GPARfl Section , lines 151 to 411 of ' the sample program. IF ( ISW1 ) 150,100,150 ISWl=l P=lOO. 0 AVDB-15 0.0 AV==~O.O~* ( AVDB/~O.O ) DO 110 I=1,3 CALL COEFF ( CF ( I ) , BW ( I ) , AO ( I ) , Al ( 1 ) 4A~ ( ~ ) , ~~~ , 1 ) CONTI : NUE FORTRAN SYNTHESIS TE3TER W~YN~~~ , YO SYNTH5SXZES VSEAT '' CQMqON ISWV , DT~TGcTP , T~ , T2~TRpCITRtAVS~VE DXMENSION IRUF ( 256 ) , C.F ( 181 , BW ( In ) # A @ II91I A1 [ I @ ) # ~P ( 10 ) , YH~ ( 101 , YM ? ( t0 ) , rn ti @ ) C C C OVERALL XNITXALZZATlON C C C SET OUTPUT SAMPLE RATE IN SAMPLESlSEC OSRa2 &amp; 7Glfl @ ,8 C SET OUTPUT BLOCK SIZE AND NO , OF BLOCKS NBSXZEo256 NI ) LKSxSI C SET WAVE SHAPE CONSTANTS FOR GLOTTAL WAVE GENERATION QPTR=Q ) ,49 CtfR=C3,16 C SET OVERALL TIME CLOCK AND DELTA T IN MSEC , Tan @ DT~1QBG¶ , @ SR C SET PARAMETER~RES~TTZNG Cl.OtK FOR PRXCATXON TFRlCltRI , QI c SET PARAMETERaRESEfTXNG PERIOD FOR FRIXATION PFRIC=a , i C SET PARAMET ERnRESETTING CLOCK f OR YOJCING TVOC=M , Q1 C SET PARAMETER~RESE~TING PERIOD F PVOC~c ) ,2 c OPEN OUTPUT STORAGE FILE c OUTPUT BUFFER IS ARRAY ISUF NQUTa5 CALI , , OPENR ( NOUT~ '' RAf'wRK1 'InOD '' clcLENG , XflUFt % l @ ) GO TO 20 C ERROR HANDLING IF OUTPUT FILE CAN NOT BE OPENED 191 WRXTECI , 15 ) 15 FORHATCH *** ERROR OPENING WORK FfLE*I GO 7'0 9CaB C FILE OPENED O , K , t CHECK IF BIG ENOUGH 28 IF ( NR ( .US*lENG ) 35135,25 C ERROR HANDLIHG -FZLE NOT BIG ENOUOlI 23 WRfTE ( lr3B ) 3g FCIRMAII~~ +++ WOR~ FILE NOT elCi ENQUGHII ) GO 70 9PP ) C IIllTPUT WORK FILE READY TO GO C SET VOICING SHITCY OFF 35 tswv=0 C INITIALIZE HIGHER ORDER FILTER VALUES C IN REVERSE ORDER BY CENTER FREQUENCY CF ( 4 ) zQSCI0 , B CF ( 51 =ssce , a CF ( 61 =75Qla,0 Cf ( 7 ) n65C30.0 CF ( 8 ) ~5588,8 CF ( 9 ) t4SG90 , B Figure 20. Example Program Synthesizing Weat If. : IF FIRST ENTRY INTO WSI ' ROUTINE , 9ET CONSTANT PARAMETERS F ( xswI1 l~s , lss , ¶l5 La5 AVmOl , t ? l CF ( I ) a40flBn0 EP f ? ) *37fl0 , B CF ( 3 ) `` 98flfl. @ 8WCt ) tlSfl @ .fl BW ( 2 ) 93VIVI6 , Pl 8W ( 3 ) m49Pfl*8 DO 210 I=ld3 110 CALL , CQEFF ( CFC~ ) ~B~~I~~A~~CI~IA~~I ) IA~~I~IO~R~~ ) ISWl~l C IF TIME TO DO SB , RESET VARIABLE ~ARAMETERS 115 IF [ TFRXC ) 12e , 12mg 125 12C3 CCINTINUE G IF t*5 , NO NOISE IF ( 7-5.n ) la ; ; rr i24 , i24 $ 22 ANJQ ) , ~ GO TO 126 124 CALI. TPOH ( Te4 , TX1 ANOl3~+3~ ! 50*1~6375+TX C1l~OJ~02O32*TXC2l+B~~ @ 0~I~~*T % ( 3 ) 1 -0.~1~91~191~~2242wTXt4 ) ANmlBIB** ( ANDB/2Gl,0 ) 125 CONT~NUE GO 10 @ 50 C C END OF 99 '' c C uEAu VOWEL ? 2041 tQ ( Tm448m981 2flSr31Br316 C C PEA '' C C IF FXRST TIHE THRU , SET CONSTANT PARAMETERS 205 IF CXSw2 ) 2101210,215 210 AN= @ , @ 8W C11=54.0 BW C23 s55 , B 0W C3 &gt; +170 , G ISN2sl C IP TIME , RESET VARIABLE PARAMETERS 215 IF GTVOC ) 220p22flt659 220 CONTINUE c PITCH CALL TPOW~TU~~~ , ~ , ~ , ~XI P~146,243*0 , A25185d*TX~t ) ~ @ mQlQIP ) 1925P ) 78fT % [ 2 ) 1 mG.OBR @ G5R18408+TX ( 3 ) mBe~0 @ 0 @ 42d6ld68 1 *TX ( 4 ) C AMPLITUDE OF VOICING IF [ Te24Sa01 41 @ 0410,420 410 GALL TPOW ( T~219~51~3~tX~ A~~A~43,493+B , fi19573*TX ( 11~0 , QI2476343+TXCZ ) 1 *0,00 &amp; 72638669+TX ( 3 ) GO TO SIB 420 IF CT~29flaf11 A38r4300440 430 AVOB~47,34963~B , l457143*CT~245 , .8 ) GO TO 518 440 fFCTm33Sm8 ) 458,450,468 Figure 20 .</sentence>
				<definiendum id="0">aPTR</definiendum>
				<definiendum id="1">GLbTTAL HAVE C C ARC Wt HOW GENERATING VOftET rr ( X~MVI ~BE</definiendum>
				<definiendum id="2">CLTR</definiendum>
				<definiendum id="3">GLOT</definiendum>
				<definiendum id="4">perryl</definiendum>
				<definiendum id="5">Y</definiendum>
				<definiendum id="6">BW</definiendum>
				<definiendum id="7">MPZ</definiendum>
				<definiendum id="8">RPIONANCE</definiendum>
				<definiendum id="9">YM1</definiendum>
				<definiendum id="10">HAO</definiendum>
				<definiendum id="11">PFRIC</definiendum>
				<definiendum id="12">CF</definiendum>
				<definiens id="0">AT THE END or A ruLaC , C PARAMETERS ARE OeK , C OTHERWl3E YE NEED TO CHECK'AV Tb SEE c xr HE NEED ANOTHER PULSE 1 0 IF ITG+0,5*WEL-TP ) 5B128p20 C EITHER HE HAVE NOT BEEN GENERATING VOICE OR C WE HAVE JUST FINISHED A PULSE rr C IF ' AV P 0</definiens>
				<definiens id="1">uses the variable AVSAVE to atore the value of AV at the beginning of each pitch period , and during the generation of the pulse</definiens>
				<definiens id="2">it is very fast , and produces noise with a quite flat spectrum. Its presentation by Rader , Rabiner , Schafer , and</definiens>
				<definiens id="3">a dummy variable required by our Fortran compiler -contains this algorithm in assembly language , producing on successive calls a series of random numbers with a uniform distribution over the interval from -2047 ta +2047. To implement a white noise generator</definiens>
				<definiens id="4">a function returning the exclusive or of N1 and N2 , variables having either the value 0 or 1. MINT ( N ) is a function whose argument N is a bitstring array such as NM1 and which returns a 12-bit integer value consisting of the left-most 12 elements of N packed into a</definiens>
				<definiens id="5">functions RE3 and ARES return the output values of simple resonant ( conjugate pole pair ) and anti-resonant ( con jugate zero pair ) filters. respectively. AO , Al , and A2 are coefficients used in the recursive equations. I and Y'M2 axe remembered previous values of the signal</definiens>
				<definiens id="6">the input to the filter. AO , Al , and R2 determine the characteristics of the filter : center frequency and bandwidth. Each simulated filter should have its own variables in which to save the values of YM1 and YM2 , and between calls to the fdnction simulating that filter , the values of these variables ahould not be changed. The subroutine COEFF is used to calculate appropriate values for AO , Al , and A2 , based on CF , the center frequency</definiens>
				<definiens id="7">the remembered immediately previous value of Y , hfid G is a normalizing gain control which should be calculated in the over-all initiaLization as a direct function of the output sample xake , some K times OSR. The spectral effect of RAID</definiens>
				<definiens id="8">~1.m mrc. I 28.11 treac~ unvc &lt; nounn~ t ZED ) Figure 11. Spectral Shaping Effect of an Elemental Resonant Filter with CF=3000 'Hz and BW=200 Hz. Figure 12. Spectral Shaping Effect of an Elemental Anti-Resonant Filter with CF=3000 Hz and BW-200 He. RAD~O*~YIYMII YMlnY RETURN END Figure 13. Fortran Function</definiens>
				<definiens id="9">used to make tha formants of voiaad speech and , in a rather strained fashion , toshape the noise spectrum during frication</definiens>
				<definiens id="10">a series of resonant filters of fixed center frequency and bandwidth which cornpensat e for the effect of higher -f requency resonances present in a real vocal tract</definiens>
				<definiens id="11">xecursive equation coefficients AO , Al , and A2 need be calculated only once , in the over-all initialiaation. Theoretically , the arder of computation of the series elements such as those in the main stem of Model T , makes no difference. However , because the digital numbers are finite in length round-off or truncation errors are introduced at each step of ' the computation The overall error increases as the number of computational steps increase. Some types of computation such as differentiation tend to increase the error</definiens>
				<definiens id="12">needed. If at the beginning of the program the variable T ( time</definiens>
				<definiens id="13">comes out sounding like clicks or static if the change in filter characteristics is too large. Our currently-implemented a~sembly-language synthesizer reads a fil'e of tabled values created by another program as values representing the parameter curves. The period between tabled parameter values is changeable , but on the order of 5 to 10 msec. In computing the actual parameter values used</definiens>
				<definiens id="14">zeros -anti-resonances -are introduced into the spectrum. In Model T , the sqme three filters are used to make the formants ot voiced speech and to shape the spectrum of noise during unvoiced speech. This is cumbersome and difficult</definiens>
				<definiens id="15">separate channel ie devoted to nolae , with its own resonant and anti-resonant filters for spectral shaping. It haa been suggested that one remnance</definiens>
				<definiens id="16">a complete Fortran program for synthesizing the wrd llseatll ( sith ] ) . We tried to duplicate one particular token utterance of , this word. Spectrograms of the original sound used as a model and the synthesized sound calculated by the Fortran program are shown in -- GLOTTAL WAVE PARAMETERS RESONANCES VOCAL TRACT PARAMETERSNTI-RESONANCEFigure 19. Block Diagram of Model With Separate Noise Shaping Channel Figme 21</definiens>
				<definiens id="17">the times in msec between re-calculations of vocalic and fricative parameter values</definiens>
				<definiens id="18">constant during aome of the sounds , e.g. , spectral parameters during ft3fN. As a minolr concession to exeoution speed , these constant parameters are not reset after the first entry into the section during which they are constant The variables 19W1 , ISW2 , and 1SW3 are irst-time-through '' switches , used tb remember whether or not the tempora1 : il.y constant parametei-s have hen calculated yet. We have found that duplicating a token of natural speech using thLs simple basic synthesis model</definiens>
				<definiens id="19">rn ti @ ) C C C OVERALL XNITXALZZATlON C C C SET OUTPUT SAMPLE RATE IN SAMPLESlSEC OSRa2 &amp; 7Glfl @ ,8 C SET OUTPUT BLOCK SIZE AND NO , OF BLOCKS NBSXZEo256 NI ) LKSxSI C SET WAVE SHAPE CONSTANTS FOR GLOTTAL WAVE GENERATION QPTR=Q ) ,49 CtfR=C3,16 C SET OVERALL TIME CLOCK AND DELTA T IN MSEC</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>Ncn S'orlq University Thc NTTT Linguistic String 1 &gt; arscr ( 1 , SI ' ) is a ~vorldng system for the syntactic analysis of Ehglish scicntifie tests .</sentence>
				<definiendum id="0">SI ' )</definiendum>
				<definiens id="0">a ~vorldng system for the syntactic analysis of Ehglish scicntifie tests</definiens>
			</definition>
			<definition id="1">
				<sentence>A string grammar makes restrictions as to which subclasses can co-occur .</sentence>
				<definiendum id="0">string grammar</definiendum>
				<definiens id="0">makes restrictions as to which subclasses can co-occur</definiens>
			</definition>
			<definition id="2">
				<sentence>The BNF definitions define the center and adjunct strings of the language as well as sentence nominalization ( embedded sentence ) strings u ; hich may occur in subject , object or complement position .</sentence>
				<definiendum id="0">BNF definitions</definiendum>
				<definiens id="0">define the center and adjunct strings of the language as well as sentence nominalization ( embedded sentence ) strings u ; hich may occur in subject , object or complement position</definiens>
			</definition>
			<definition id="3">
				<sentence>Fbr esample , the adjective clear , which can occur as the predicate of a , sentential subject , is in the subclass AS ENT1 .</sentence>
				<definiendum id="0">adjective clear</definiendum>
				<definiens id="0">the predicate of a , sentential subject , is in the subclass AS ENT1</definiens>
			</definition>
			<definition id="4">
				<sentence>It should be noted that while the entries in the lexicoh are by word rather than stem the word entries based on a particular stem can refer to portions of a basic entry which they share in common , e.g. , the object list of a verb ( OBJLIST ) is specified once for all forms df the verb ( tensed verb tV , present participle Ving , past participle Ven and infinitive V ) .</sentence>
				<definiendum id="0">OBJLIST</definiendum>
			</definition>
			<definition id="5">
				<sentence>ec1 term ) is the class being subclassed in the frame where the frame also contains a particular lexical item ( X ) in a franc !</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">the class being subclassed in the frame where the frame also contains a particular lexical item (</definiens>
			</definition>
			<definition id="6">
				<sentence>Sager , `` i Computer String Grammar of Ehglish '' , ring Program Report No. 4 , Linguistic String Project , New York University , 1968 ) , diagnostic frames prepared for LSP use by Barbara Anderson , and classification work by many members of the LSP staff over the years .</sentence>
				<definiendum id="0">Sager</definiendum>
				<definiens id="0">diagnostic frames prepared for LSP use by Barbara Anderson , and classification work by many members of the LSP staff over the years</definiens>
			</definition>
			<definition id="7">
				<sentence>AASP : an adjective is in AASP if it occurs N be Addj to V OBJ only witti the non-sentential ( non-SNI right adjunct to V QBJ ( SN an embedded , or EXamples : contained , sentence ) ( DSNG , 7 ) : John is free to leave .</sentence>
				<definiendum id="0">AASP</definiendum>
				<definiendum id="1">adjective</definiendum>
				<definiens id="0">free to leave</definiens>
			</definition>
			<definition id="8">
				<sentence>Adjectives \Yhich occur with both nonIt is a &gt; to be assumed that John left .</sentence>
				<definiendum id="0">nonIt</definiendum>
				<definiens id="0">a &gt; to be assumed that John left</definiens>
			</definition>
			<definition id="9">
				<sentence>( Adj is not comparative ) occur to the right of the measure scquencc QN in which N is in suhclass NUNIT ( inches , Fhamylcs : feet , pounds , years , etc. ) &amp; i7Q2 ) , e.g. , long in The line is 10 inches long .</sentence>
				<definiendum id="0">Fhamylcs</definiendum>
				<definiens id="0">the right of the measure scquencc QN in which N is in suhclass NUNIT ( inches ,</definiens>
			</definition>
			<definition id="10">
				<sentence>COMPARATIVE : an adjective is in the subclass COMPARATNE if it can occur in the environment N1 t be -than N , : John is happier than Bill .</sentence>
				<definiendum id="0">COMPARATIVE</definiendum>
				<definiendum id="1">adjective</definiendum>
				<definiens id="0">happier than Bill</definiens>
			</definition>
			<definition id="11">
				<sentence>SUPERLATIVE : an adjective is in the subclass SI1LyPF : R LATIYE if it occurs with the suffis ( ekt TNQN before a cluantifier which is a left adjunct of 'N ( MrN5 ) , e.g. : the ~t~orst ten days the tallest three boys Cf. APQE : Q. Fkamples : TI~ose were the Lvorst tep clays of my life .</sentence>
				<definiendum id="0">SUPERLATIVE</definiendum>
				<definiens id="0">an adjective is in the subclass SI1LyPF : R LATIYE if it occurs with the suffis ( ekt TNQN before a cluantifier which is a left adjunct of 'N</definiens>
				<definiens id="1">the ~t~orst ten days the tallest three boys Cf. APQE : Q. Fkamples : TI~ose were the Lvorst tep clays of my life</definiens>
			</definition>
			<definition id="12">
				<sentence>An AGGREGATE ; : noun callnot occur as a prrtlicate of bc \\ , hen the suhiect of tho sentence is singular ( WAIGll EIZ ) : ,3 ' Ele is a group .</sentence>
				<definiendum id="0">Ele</definiendum>
				<definiens id="0">a prrtlicate of bc \\ , hen the suhiect of tho sentence is singular ( WAIGll EIZ ) : ,3 '</definiens>
				<definiens id="1">a group</definiens>
			</definition>
			<definition id="13">
				<sentence>WORD LIST : aggregate , assembly , block , board , couple , e~~scmble , family , group .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
			</definition>
			<definition id="14">
				<sentence>INITIAL ( abmic clas~ ) : used for abbreviation of proper names ( harry S. Truman ) , names of organizations ( A. F. of L. ) , etc .</sentence>
				<definiendum id="0">INITIAL ( abmic clas~ ) :</definiendum>
			</definition>
			<definition id="15">
				<sentence>WORD LIST : qct , advance , agent , amount , amphibian , analogve , animal , antidiuretic , associate , auricle , author , back , can , case , cat , cation , cause , chemical , chief , claim , collaborator , complex , compound , conclusion , controversy , correlate .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
			</definition>
			<definition id="16">
				<sentence>WORD LIST : abilities , ages , combinations , data , effects , groups , measures , mucosae , observations , parallels , problems , rises , seconds , tries , uncertainties , uses .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
				<definiens id="0">abilities , ages , combinations , data , effects , groups , measures , mucosae , observations , parallels , problems</definiens>
			</definition>
			<definition id="17">
				<sentence>WORD LET : age , altitude , area , breadth , height , intensity , length , luminosity , strength , volume , wavelength , width , circumfrence , diameter , thickness .</sentence>
				<definiendum id="0">WORD LET</definiendum>
			</definition>
			<definition id="18">
				<sentence>WORD LIST : account , advantage , concern , consequence , csscncc , inlportancc , int crest , r~lorneilt , necessity , note , value , weight .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
			</definition>
			<definition id="19">
				<sentence>c. , 1 ) NSENql : ( A FORTO ) The plan for him to go .</sentence>
				<definiendum id="0">FORTO</definiendum>
				<definiens id="0">plan for him to go</definiens>
			</definition>
			<definition id="20">
				<sentence>WORD LIST : demand , move , notice , order , suggestion , direction , analysis , asSumption , charge , claim , conclusion , criticism , doubt , estimate , fact , finding , hypothesis , idea , interpretation , hovvledge , observation , position , postulate , report , representation , response , theory , thought , view , alternative , question .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
				<definiens id="0">demand , move , notice , order , suggestion , direction , analysis , asSumption , charge , claim , conclusion , criticism , doubt , estimate , fact , finding , hypothesis , idea , interpretation , hovvledge , observation , position , postulate , report , representation , response , theory</definiens>
			</definition>
			<definition id="21">
				<sentence>WORD LIST : ability , age , combination , data , digital is , excitability , poup , Gunther , 1 actone , liberation , measure , mucosa , observation , plasma , rise , sodium , t~'y , uncertainty , use , valency , want , year .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
				<definiens id="0">ability , age , combination , data , digital is , excitability , poup , Gunther , 1 actone , liberation , measure , mucosa , observation , plasma , rise , sodium , t~'y , uncertainty , use , valency , want , year</definiens>
			</definition>
			<definition id="22">
				<sentence>II'OIED LIST : block , centimeter , * ccntllry , coltlmn , clay , fooS , hand , hour , inch , kg. , mile , millisecotld , momcnt , morning , nights , pound , row , section , segment , i~celi , yars .</sentence>
				<definiendum id="0">II'OIED LIST</definiendum>
				<definiens id="0">block , centimeter , * ccntllry , coltlmn , clay , fooS , hand , hour , inch , kg. , mile , millisecotld , momcnt , morning , nights , pound , row , section , segment</definiens>
			</definition>
			<definition id="23">
				<sentence>WORD LIST : appear , apply , arise , begin , Continue , enter , exist , fail , function , p , occur , originate , participate , remain , train .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
			</definition>
			<definition id="24">
				<sentence>OBJLIST : ( ASSERTION ) : The verbs classified as OBJLIST : ( ASSERTIDhy are a subset of the verbs classified as OBJLIST : ( THATS ) , i.e. : Frame : SUBJ tV ( that ) S She Ino~vs John is an `` An student .</sentence>
				<definiendum id="0">ASSERTIDhy</definiendum>
				<definiens id="0">a subset of the verbs classified as OBJLIST : ( THATS ) , i.e. : Frame : SUBJ tV ( that ) S She Ino~vs John is an `` An student</definiens>
			</definition>
			<definition id="25">
				<sentence>h the WORD LIST , the arrow ( - &gt; ) follows the set of DPs specified for each verb and precedes the set of Ps specified for that verb .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
				<definiens id="0">the set of DPs specified for each verb and precedes the set of Ps specified for that verb</definiens>
			</definition>
			<definition id="26">
				<sentence>WORD LIST : add ( in- ) with ) , bind ( up+ with ) , call ( away- , to ) , chain ( down , up+ to ) , divide ( up+ with ) , end ( up* in , with ) , follow ( up+ with ) , link ( up- ) to , with ) , pair ( up , off* with , into ] , play ( off+ against ) , separate ( out , off+ from ) sign ( ovei-+ to ) , single ( out* for ) , take ( up+ with ) , trace ( back+ to ) , yield ( up+ to ) .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
				<definiens id="0">add ( in-</definiens>
			</definition>
			<definition id="27">
				<sentence>In the WORD LIST , the arrow ( ( 9 ) Dictionary Entry : follows the set of DPs specified for each MOVE .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
				<definiens id="0">follows the set of DPs specified for each MOVE</definiens>
			</definition>
			<definition id="28">
				<sentence>WORD LIST : act ( out ) , add ' ( in , on , up ) , ask ( in , out , over , up ) , back ( up ) , beat ( up ) , bend ( back , up ) , bin &amp; ( down , off , over , up ) , block ( in , off , out , up ) , bring ( about , off , out , up ) , carry ( out , through ) , clear ( away , off , out , up ) , cool ( down , off ) , cover ( up ) , deal ( out ) , divide ( LIP ) , draw ( back , down , in , off , out , up ) , dry ( off , out ) , drive ( in , off , out ) , eat ( away , up ) , factor ( out ) figure ( out ) , find ( out ) , fish ( out , up ) , fit ( 'in ) , follow ( up ) , give ( away , back , in , out , over , up ) , OIRJIJIST : ( DSTG ) : applies to small subclasses of verbs which occur with narticular adverb subclasses .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
			</definition>
			<definition id="29">
				<sentence>left adjunct of Viiq ( specified in the frame as Na is either an overt subject Examp1 es : I told him about Maiy 's leaving .</sentence>
				<definiendum id="0">Viiq</definiendum>
				<definiens id="0">either an overt subject Examp1 es : I told him about Maiy 's leaving</definiens>
			</definition>
			<definition id="30">
				<sentence>lic11 occur only with special noun objects ( usually nominal transforms of the verb of the sentence : IIe slept a good sleep ) arc classifi'ed as OBJLIST : ( NULLOBJ ) only .</sentence>
				<definiendum id="0">OBJLIST</definiendum>
				<definiens id="0">usually nominal transforms of the verb of the sentence : IIe slept a good sleep</definiens>
			</definition>
			<definition id="31">
				<sentence>WORD LIST : ask , believe , combine , divide , eat , face , , fish , group , like , mean , number , order , part , place , prefer , provide , question , run , relax , require , say , skin , substitute , suppose , take , tell , try , underestimate , vary , want , work , write .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
				<definiens id="0">ask , believe , combine , divide , eat , face , , fish , group , like , mean , number , order , part , place</definiens>
			</definition>
			<definition id="32">
				<sentence>OBJLIST : ( NTI-IATS ) : The noun object of a is NIlUMAN ( Wsw Note : a verb tvlxic'h takes a sentence string as its subject .</sentence>
				<definiendum id="0">OBJLIST : ( NTI-IATS )</definiendum>
				<definiens id="0">a verb tvlxic'h takes a sentence string as its subject</definiens>
			</definition>
			<definition id="33">
				<sentence>OBJLTST : ( OWB ICj : Frame : In the object strong OBJBE , the OBJBE N1 tV OBJUE is the predicate of N1 .</sentence>
				<definiendum id="0">OBJBE N1 tV OBJUE</definiendum>
				<definiens id="0">the predicate of N1</definiens>
			</definition>
			<definition id="34">
				<sentence>Hc : became ecstatic tvhen I told him .</sentence>
				<definiendum id="0">Hc</definiendum>
				<definiens id="0">became ecstatic tvhen I told him</definiens>
			</definition>
			<definition id="35">
				<sentence>adjectiye , adverb or PN string ( cf. OBJLIST : ( OBJBE ) : He is 2 carpenter .</sentence>
				<definiendum id="0">PN string</definiendum>
				<definiens id="0">cf. OBJLIST : ( OBJBE ) : He is 2 carpenter</definiens>
			</definition>
			<definition id="36">
				<sentence>OBJLIST : , ( PNHOWS ) : includes those verbs which occur with how S but not wit11 SNWH , e.g. : N tV ( PN ) 1101il S ( and not N tV , whether S ) IIe , liked how it was done .</sentence>
				<definiendum id="0">OBJLIST</definiendum>
				<definiendum id="1">PNHOWS</definiendum>
				<definiens id="0">includes those verbs which occur with how S but not wit11 SNWH</definiens>
			</definition>
			<definition id="37">
				<sentence>( IRJLIST f ( SOBJBE ) : Frame : LQ the object sirii~g SOBJBE the OBJBE : N , tV K9 OBTBI : is the prtiicate of N2 .</sentence>
				<definiendum id="0">IRJLIST f ( SOBJBE</definiendum>
				<definiens id="0">the prtiicate of N2</definiens>
			</definition>
			<definition id="38">
				<sentence>SUBJ tV N2 V ( Om Note : to avoid confusioll with OB JLIST : Bcamples : ( ClSHOU-LD ) ( I ; crggest he go ) , use pronouns br N , in the test frame for SVO .</sentence>
				<definiendum id="0">SUBJ tV N2 V</definiendum>
				<definiendum id="1">ClSHOU-LD )</definiendum>
				<definiens id="0">pronouns br N , in the test frame for SVO</definiens>
			</definition>
			<definition id="39">
				<sentence>QBJLIST : ( THATS ) : Frame : The verb of the embedded sentence is N tV that S ( V of emhtdded S tV ) tensed .</sentence>
				<definiendum id="0">QBJLIST : ( THATS )</definiendum>
				<definiens id="0">The verb of the embedded sentence is N tV that S ( V of emhtdded S tV ) tensed</definiens>
			</definition>
			<definition id="40">
				<sentence>WORD LIST : add , agree , allow , answer , appear , argue , assume , believe , calculate , charge , claim , conclude , confirm , consider , demonstrate , deny , denote , ,detect , determine , discover , doubt , establish , estimate , evidence , expect , explain , feel , figure , find , follow , happen , imply , infer , intimate , know , learn , maintain , matter , mean , mention , note , notice , observe , provide , read , reason , report , rule , say , see , seem , sense , show , state , suggest , think , u~lderstand , write .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
				<definiens id="0">add , agree , allow , answer , appear , argue , assume , believe , calculate , charge , claim , conclude , confirm , consider , demonstrate , deny , denote , ,detect , determine , discover , doubt , establish , estimate , evidence , expect , explain , feel , figure , find , follow , happen , imply , infer , intimate , know , learn , maintain , matter , mean , mention , note , notice , observe , provide , read , reason , report , rule</definiens>
			</definition>
			<definition id="41">
				<sentence>WORD LIST : accumulate , cluster , collect , diffuse , gather , mass , scatter .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
			</definition>
			<definition id="42">
				<sentence>WORD LIST : give , have , make , present , augment , compound , complicate , increase , limit , modify , restrict .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
			</definition>
			<definition id="43">
				<sentence>WORD LIST : affect , antagonize , concern , confound , content , disturb , encourage , excite , interest , Mrigue , matter , move , occur , shock , suit , surprise , trouble .</sentence>
				<definiendum id="0">WORD LIST</definiendum>
				<definiens id="0">affect , antagonize , concern , confound , content , disturb , encourage , excite , interest , Mrigue , matter , move , occur , shock , suit , surprise , trouble</definiens>
			</definition>
			<definition id="44">
				<sentence>VSENT4 : a verb is in VSENT4 if it occurs in the environment It - , SN buttdoes not occur in the environment SN - ( DSNT3 ) : L It seems that he left .</sentence>
				<definiendum id="0">VSENT4</definiendum>
				<definiens id="0">a verb is in VSENT4 if it occurs in the environment It - , SN buttdoes not occur in the environment SN - ( DSNT3 ) : L It seems that he left</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>OR 3 25 ) ) 3 ( INDEPENDENT 2 ( OR IMPERATIVE 26 ) ) 2 5 ( DEPENDENT 2 27 ) 26 ( INDICATIVE 3 27 ) 27 ( ( OR 25 26 ) ( AND 4 8 ) 4 ( 2 7 ( OR DECLARATIVE 5 ) ) 5 ( INTERROGATI VE 4 ( OR POLAR 2811 2 8 ( NON-POLAR 5 ( AND 6 7 ) ) 6 ( 2 8 ( OR WH 4LTERNATIVE ) ) 7 ( 0 2 8 ( OR SUBJECT-FOCUS NON-SUBJECT-FOCUS ) ) 8 ( 2 7 ( OR MODAL NON-MODAL ) ) 9 ( 23 ( OR 10 11 ) ) 10 ( INTRANSITIVE 9 ( OR ATTRIBUTIVE NOH-ATTRIBUTIVE ) ) 11 ( TRANSITIVE 9 ( OR ACTIVE 12 ) ) 12 ( PASSIVE 11 ( OR ACTOR-SPECIFIED ACTOR-UNSPECIFIED ) 24 ( PHRASE I ( AND 13 14 ) ) 13 ( 24 ( OR NOMINAL ADJECTIVAL ADVERBIAL PREPOSIT13NAL ) 14 ( 24 ( *OR NON-QUESTIONING QUESTIONING ) ) 15 ( WORD 1 ( OR 29 CONJUNCTEON 1 29 ( VERB 15 ( AND 16 19 ) ) 16 ( 29 ( *OR 17 18 ) ) 17 ( NON-FINITE-VERB 16 ( *OR FORM-0 EN-FORM ING-FORM ) ) 18 ( FINITE-WRB 16 ( OR PAST-VERB PRESENT-VERB ) ) 19 ( 29 ( *OR 20 22 ) ) 20 ~GRAHMATI @ AL-VERB 19 ( *OR 21 MODAL-VERB ) ) 21 ( NON-MODAL-VERB 20 ( &amp; OR DO BE HAVE ) ) 22 ( LEXICAL-VERB 19 ( OR COPULAR-VERB INTRANSITIVE-VERB TRANSITIVE-VERB ) ) the 8ystem are so numbered ta correspond with Hudson 's labellings Cpg .</sentence>
				<definiendum id="0">NOMINAL ADJECTIVAL ADVERBIAL PREPOSIT13NAL</definiendum>
			</definition>
			<definition id="1">
				<sentence>The fntegratiori Frocess , which places iritsrprstatians on pror-ouns , also irlterprets duf inite occ , urrences of 'nrmodifiad E nofi-specific touns as rsp3titions of i~revioutly mentionad mcrz specific ( or more modified ) nouns , fills FR dslated ~o~itals on thA basis of prior context &amp; iatcrpr~ts gareric or unaodifid verbs as r~potitions of more specific verbs previously aenticnod .</sentence>
				<definiendum id="0">fntegratiori Frocess</definiendum>
				<definiens id="0">places iritsrprstatians on pror-ouns , also irlterprets duf inite occ , urrences of 'nrmodifiad E nofi-specific touns as rsp3titions of i~revioutly mentionad mcrz specific ( or more modified ) nouns , fills FR dslated ~o~itals on thA basis of prior context &amp; iatcrpr~ts gareric or unaodifid verbs as r~potitions of more specific verbs previously aenticnod</definiens>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>Yerkish is a visual language with a lexicon of gsaplric word symbols ( lexigrams ) , each of whicl ; l is a combination of discrete recursive-design elements .</sentence>
				<definiendum id="0">Yerkish</definiendum>
				<definiendum id="1">l</definiendum>
				<definiens id="0">a visual language with a lexicon of gsaplric word symbols ( lexigrams ) , each of whicl ;</definiens>
				<definiens id="1">a combination of discrete recursive-design elements</definiens>
			</definition>
			<definition id="1">
				<sentence>Yerkish is an artificial language that was designed for a specific and peculiar purpose to explorbe to what extent apparentry non-linguistic organisms could acquire linguistic skills if they were placed in an environment in which the use of linguistic communication would be to their advantage .</sentence>
				<definiendum id="0">Yerkish</definiendum>
				<definiens id="0">an artificial language that was designed for a specific and peculiar purpose to explorbe to what extent apparentry non-linguistic organisms could acquire linguistic skills if they were placed in an environment in</definiens>
			</definition>
			<definition id="2">
				<sentence>nerativeU properties , nor is it transformational '' in the Chomskyan sense of that term .</sentence>
				<definiendum id="0">nerativeU</definiendum>
			</definition>
			<definition id="3">
				<sentence>Strictly speaking , a correlator is a connective fgnction that links conceptual items on the cognitiverepresentational level .</sentence>
				<definiendum id="0">correlator</definiendum>
				<definiens id="0">a connective fgnction that links conceptual items on the cognitiverepresentational level</definiens>
			</definition>
			<definition id="4">
				<sentence>If It is recorded there by means of correlation indices '' ( IC1s ) , which consist of the number of the potential correlator plus the indication whether the items to which this I , is assigned can function as LH-piece or as w-piece .</sentence>
				<definiendum id="0">IC1s</definiendum>
				<definiens id="0">consist of the number of the potential correlator plus the indication whether the items to which this I</definiens>
			</definition>
			<definition id="5">
				<sentence>Thus , while the lexigram EAT , in the present Yerkish lexicon , is the only member of the class VE ( 'active ingestion of solids ' ) , the lexigrarr RAISIN is one of several in the class EU ( 'solid food stuff1 ) .</sentence>
				<definiendum id="0">EAT</definiendum>
				<definiendum id="1">lexigrarr RAISIN</definiendum>
				<definiendum id="2">EU</definiendum>
				<definiens id="0">one of several in the class</definiens>
			</definition>
			<definition id="6">
				<sentence>It is used for the ostensive definition of new lexigrams which areplaced at the beginning of a string of the form : XX NME-OF THISi 11 XX is the name of this1 ' .</sentence>
				<definiendum id="0">XX</definiendum>
				<definiens id="0">the name of this1 '</definiens>
			</definition>
			<definition id="7">
				<sentence>( where LY is the new Icx~gram ) Two English coQstructions that have a specificatory restrictive function. , i. e. for instance , `` the red ball ' !</sentence>
				<definiendum id="0">LY</definiendum>
				<definiens id="0">the new Icx~gram ) Two English coQstructions that have a specificatory restrictive function.</definiens>
			</definition>
			<definition id="8">
				<sentence>The receiver , however , can be made explicit by adding a prepositional phrase , which yields the correlational structure : PLEASE TIM GIVE MILK TO LANAP -17 -- 1 224 -21Lh0L5 I It English resultative verbs , e.g. to open '' , `` to clean '' , ete. , are , broken up in Yerkish .</sentence>
				<definiendum id="0">prepositional phrase</definiendum>
				<definiens id="0">yields the correlational structure : PLEASE TIM GIVE MILK TO LANAP -17 -- 1 224 -21Lh0L5 I It English resultative verbs , e.g. to open ''</definiens>
			</definition>
			<definition id="9">
				<sentence>Schank , Eager ( 1972 ) , Conceptual dependency : A theory of natural language understanding , Cognitive Psychology , 3 , 4 , 552-631 .</sentence>
				<definiendum id="0">Conceptual dependency</definiendum>
				<definiens id="0">A theory of natural language understanding</definiens>
			</definition>
</paper>

		<paper id="1061">
			<definition id="0">
				<sentence>A parse network is a small collection of nodes of the same format , and connected in the same fashion , as the nodes in MEMORY .</sentence>
				<definiendum id="0">parse network</definiendum>
				<definiens id="0">a small collection of nodes of the same format , and connected in the same fashion</definiens>
			</definition>
			<definition id="1">
				<sentence>STM is the short term memory component for the program .</sentence>
				<definiendum id="0">STM</definiendum>
				<definiens id="0">the short term memory component for the program</definiens>
			</definition>
			<definition id="2">
				<sentence>Transitivity is a property of hierarchies as implemented by the program .</sentence>
				<definiendum id="0">Transitivity</definiendum>
				<definiens id="0">a property of hierarchies as implemented by the program</definiens>
			</definition>
			<definition id="3">
				<sentence>The GENERIC BRANDT is a set of one element .</sentence>
				<definiendum id="0">GENERIC BRANDT</definiendum>
				<definiens id="0">a set of one element</definiens>
			</definition>
			<definition id="4">
				<sentence>However , examination of the hierarchies discloses that RED ( ISA ) COLOR which is a property that TIIINGk ( BOOK ( ISA ) THING ) can have .</sentence>
				<definiendum id="0">RED ( ISA ) COLOR</definiendum>
				<definiendum id="1">BOOK</definiendum>
				<definiens id="0">a property that TIIINGk</definiens>
			</definition>
			<definition id="5">
				<sentence>A triple ( ACTION node ) is a node through which passes three separate chains , one each for ACTOR , ACT , and OBJECT .</sentence>
				<definiendum id="0">ACTION node )</definiendum>
				<definiens id="0">a node through which passes three separate chains , one each for ACTOR , ACT , and OBJECT</definiens>
			</definition>
			<definition id="6">
				<sentence>In the TYPE node for the symbol is the root for the chain througli the TYPE nodes for NOUN , PRONOUN , VERB , etc .</sentence>
				<definiendum id="0">TYPE node</definiendum>
			</definition>
			<definition id="7">
				<sentence>These nodes are connected to one another by the same kinds of attributes , e.g. , the ACTION INSTANCE node has links to the ACTOR , ACT and OBJECT INSTANCE nodes , the SIMPLE INSTANCE nodes contain MODIFY and CNTXT links to other SIMPLE nodes or CONTEXT nodes , respectively , etc .</sentence>
				<definiendum id="0">OBJECT INSTANCE</definiendum>
			</definition>
			<definition id="8">
				<sentence>MEMORY ACTOR is a member , i. e. , MEMORY ACTOR ( ISA ) input ACTOR .</sentence>
				<definiendum id="0">MEMORY ACTOR</definiendum>
				<definiendum id="1">MEMORY ACTOR</definiendum>
				<definiens id="0">a member</definiens>
			</definition>
			<definition id="9">
				<sentence>The adequacy of the match between input and MEMORY is the memory match score -- the accumulation of many component scores which measure the silpilarity of corresponding parts of two structures .</sentence>
				<definiendum id="0">MEMORY</definiendum>
				<definiens id="0">the memory match score -- the accumulation of many component scores which measure the silpilarity of corresponding parts of two structures</definiens>
			</definition>
			<definition id="10">
				<sentence>The HWIM parser can be viewed as a bi-directional generalization of Earley s algorithm extended to handle context-sensitive , ATN grammars .</sentence>
				<definiendum id="0">HWIM parser</definiendum>
			</definition>
			<definition id="11">
				<sentence>( A segment is a partial parse that is contained completrry within one level of the transition network grammar . )</sentence>
				<definiendum id="0">segment</definiendum>
				<definiens id="0">a partial parse that is contained completrry within one level of the transition network grammar</definiens>
			</definition>
			<definition id="12">
				<sentence>ilNTICS The notion of a phrase structure linguistic description is introduced -a pair , D = ( ( 1 , s ) where G is an arbitrary phrase structure grammar and S is a formal semantics ( defined in the paper ) .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">1 , s ) where G is an arbitrary phrase structure grammar</definiens>
			</definition>
			<definition id="13">
				<sentence>The ( phrase structure ) language of D , L ( D ) , is the set of ordered pairs ( w , m ) where w is a sentence of G and m is a meaning assigned to w by S. We prove the following results : The set of phrase structure languages is just the set of products of r.e. sets .</sentence>
				<definiendum id="0">w</definiendum>
			</definition>
			<definition id="14">
				<sentence>For a syntax-controlled translation which produces a ACL Meeting 1977 single target sentence having a meaning in common with the source sentence , the time complexity is 0 ( ptw ) where p is parsing time and w is the weight of the source phrase structure .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the weight of the source phrase structure</definiens>
			</definition>
			<definition id="15">
				<sentence>f ( pi-cn ) 3 tihe , where c and d are constants , n is the source sentence length , f is the time to check for semantic validity of a parse , and p is the time to prcduce all parses .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">c</definiendum>
				<definiendum id="2">n</definiendum>
				<definiendum id="3">f</definiendum>
				<definiendum id="4">p</definiendum>
				<definiens id="0">the source sentence length ,</definiens>
			</definition>
			<definition id="16">
				<sentence>The REL English grammar , which includes an extensive arithmetical compclnent , has been improved and extended .</sentence>
				<definiendum id="0">REL English grammar</definiendum>
				<definiens id="0">includes an extensive arithmetical compclnent , has been improved and extended</definiens>
			</definition>
			<definition id="17">
				<sentence>The objective of the investigation is to determine the mechanisms whereby process inforniatian is communicated and to assess the oft-asserted ( but empirically untesied ) I1 imprecision '' and `` ambiguity '' of natural language usage in procedural donlains Potentially , such an investigation could result in an alternative to formal programming languages for the linguistic man-machine interface -e , g. , Natural Language Procedure Specification .</sentence>
				<definiendum id="0">objective of the investigation</definiendum>
				<definiens id="0">to determine the mechanisms whereby process inforniatian is communicated and to assess the oft-asserted ( but empirically untesied ) I1 imprecision '' and `` ambiguity '' of natural language usage in procedural donlains Potentially , such an investigation could result in an alternative to formal programming languages for the linguistic man-machine interface -e , g. , Natural Language Procedure Specification</definiens>
			</definition>
			<definition id="18">
				<sentence>[ 13 ] Schank , Roger , `` Conceptual Dependency : A Theory of Natural Langauge Understanding , '' Cognitive PSYC~O~ORY , vol .</sentence>
				<definiendum id="0">Conceptual Dependency</definiendum>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>= a , or va = N , or , 10qv 1 if we set = k , k V=LJ , a Since the vocabulary of a language , however , is supposed to be restricted , so argues Maas , the existence of a limiting value is to be postulated : V , = lim f ( N ) N+m As the derivative of f at a given value of N represents the relative increase in V -1 it is to be stated that f ' ( N ) approaches 0 with increasing N , The derivative of a f at the point 1 is assumed to be 1 because a text of length 1 has a vocabulary consisting of one word , hence Therefore f ' is a function that decreases mnotonically from 1 to As a consequence of the above speculations , in the expression V = N~ k can not be constant. '</sentence>
				<definiendum id="0">k V=LJ</definiendum>
				<definiens id="0">the vocabulary of a language , however , is supposed to be restricted , so argues Maas , the existence of a limiting value is to be postulated : V , = lim f ( N ) N+m As the derivative of f at a given value of N represents the relative increase in V -1 it is to be stated that f '</definiens>
			</definition>
			<definition id="1">
				<sentence>Polysemy is the exact opposite of synonymy .</sentence>
				<definiendum id="0">Polysemy</definiendum>
				<definiens id="0">the exact opposite of synonymy</definiens>
			</definition>
			<definition id="2">
				<sentence>I1 contains the design of the program for case ( b ) .</sentence>
				<definiendum id="0">I1</definiendum>
				<definiens id="0">contains the design of the program for case ( b )</definiens>
			</definition>
			<definition id="3">
				<sentence>I't contains a wide variety of expressions that do not directly contribute anything to the content of the definition hut only indicate grammatical and logical rel .</sentence>
				<definiendum id="0">I't</definiendum>
				<definiens id="0">contains a wide variety of expressions that do not directly contribute anything to the content of the definition hut only indicate grammatical and logical rel</definiens>
			</definition>
			<definition id="4">
				<sentence>Data-base entry : ABSOCODING Definition : PROGRAM INSTRUCT10 ( which ) ONE WRITE ( in ) ABSOLUCODE ( and whic5 not ) REQUIRE FURTHER PROCESSING ( before ) INTELIGIBL ( to ) COMPUTER Note that the first predicate in the relative clause , third person plural perfect indicative passive , is represented by the singnlar indefinite pronoun `` one '' as subject , followed by the standard plural active verb .</sentence>
				<definiendum id="0">PROGRAM INSTRUCT10</definiendum>
				<definiendum id="1">COMPUTER Note</definiendum>
				<definiens id="0">subject , followed by the standard plural active verb</definiens>
			</definition>
			<definition id="5">
				<sentence>ic vocabulary ( type 2 ) , the routine bypasses it and takes the next entry .</sentence>
				<definiendum id="0">ic vocabulary</definiendum>
				<definiens id="0">the routine bypasses it and takes the next entry</definiens>
			</definition>
</paper>

		<paper id="1070">
			<definition id="0">
				<sentence>His logical network consists of relations drawn from propositional logic plus causality , and he proposes several modal operators .</sentence>
				<definiendum id="0">logical network</definiendum>
				<definiens id="0">consists of relations drawn from propositional logic plus causality , and he proposes several modal operators</definiens>
			</definition>
			<definition id="1">
				<sentence>, Me , describes a model of discourse processing in which he makes a distinction between episodic and semantic memory , argues that the processing operations must be well defined ( he suggests pattern matching and completion , abstraction and generation ) and argues that recall is essentially a different pmcess from recognition in that recall requires input organization while recognition does not , Kintsch reports a number of experiments undertaken to test aspects of h ; i $ theory .</sentence>
				<definiendum id="0">Kintsch</definiendum>
				<definiens id="0">describes a model of discourse processing in which he makes a distinction between episodic and semantic memory</definiens>
				<definiens id="1">pattern matching and completion , abstraction and generation</definiens>
			</definition>
			<definition id="2">
				<sentence>A final conclusion conce ms the presence of inferred in£ ormation in memory .</sentence>
				<definiendum id="0">final conclusion conce</definiendum>
				<definiens id="0">ms the presence of inferred in£ ormation in memory</definiens>
			</definition>
			<definition id="3">
				<sentence>Thorndyke uses recognition tests after the presentation of the story to compare inferences that have been reinforced by a continuation sentence with neutral and inapp rop riate inferences .</sentence>
				<definiendum id="0">Thorndyke</definiendum>
				<definiens id="0">uses recognition tests after the presentation of the story to compare inferences that have been reinforced by a continuation sentence with neutral and inapp rop riate inferences</definiens>
			</definition>
			<definition id="4">
				<sentence>Beginning at the lowest level , a discourse representation consists of a set of propositions .</sentence>
				<definiendum id="0">discourse representation</definiendum>
				<definiens id="0">consists of a set of propositions</definiens>
			</definition>
			<definition id="5">
				<sentence>Page 29 Finally , recall is a retrieval process which operates on the current form of the rep resentation .</sentence>
				<definiendum id="0">retrieval process</definiendum>
				<definiens id="0">operates on the current form of the rep resentation</definiens>
			</definition>
			<definition id="6">
				<sentence>For example , Absentation is the function that describes the situation in which one ~f the members of the family absents himself from home , and Trickery is the function which describes a villain 's attempt to deceive his victim in order to take possession of him or his belongings .</sentence>
				<definiendum id="0">Absentation</definiendum>
				<definiendum id="1">Trickery</definiendum>
				<definiens id="0">the function that describes the situation in which one ~f the members of the family absents himself from home</definiens>
			</definition>
			<definition id="7">
				<sentence>sizcd predicates for now ) : STORY I -I -- -- -- LILICILICIIIIII I I SETTING ( AND ) EPISODE ( INITIATE ) I I -I -- -- -- -- -- -- -- -- -- -- I I EVENT ( CAUSE ) REACTION ( MOTIVATE ) I I ( propositions describing ~argie 's I balloon being popped ) I I L-1 -- -- -- -- -- -- -- 11 -- -- -- -- I I XNTERNAL-RESPONSE OVERT-RESPONSE I I Margie is sad Margie cries Associated with most syntacrtc story rules are semantic rules which are used to generate a corresponding semantic structure for the story , The semantic rules for the syntactic rules given above are : 1 , ALLOW ( SETTING , EPISODE ) 2 , INITIATE ( EVENT , REACTION ) where the semantic predicates are intended to mean what is suggested by their names ( e.g. the SETTING ALLOWS the EPISODE to occur ) .</sentence>
				<definiendum id="0">sizcd</definiendum>
				<definiendum id="1">Margie</definiendum>
				<definiendum id="2">ALLOW</definiendum>
				<definiens id="0">predicates for now ) : STORY I -I -- -- -- LILICILICIIIIII I I SETTING ( AND ) EPISODE ( INITIATE ) I I -I -- -- -- -- -- -- -- -- -- -- I I EVENT ( CAUSE ) REACTION ( MOTIVATE ) I I ( propositions describing ~argie 's I balloon being popped ) I I L-1 -- -- -- -- -- -- -- 11 -- -- -- -- I I XNTERNAL-RESPONSE OVERT-RESPONSE I I</definiens>
				<definiens id="1">sad Margie cries Associated with most syntacrtc story rules are semantic rules which are used to generate a corresponding semantic structure for the story</definiens>
				<definiens id="2">the semantic predicates are intended to mean what is suggested by their names ( e.g. the SETTING ALLOWS the EPISODE to occur )</definiens>
			</definition>
			<definition id="8">
				<sentence>( Rumelhart uses a completely separate semantic structure , ) Page 38 Rumelhart digcusses some elementary summarization rules that operate on the semantic structure of a story .</sentence>
				<definiendum id="0">Rumelhart</definiendum>
				<definiens id="0">uses a completely separate semantic structure , ) Page 38 Rumelhart digcusses some elementary summarization rules that operate on the semantic structure of a story</definiens>
			</definition>
			<definition id="9">
				<sentence>Hopefully , this is only the beginning stage of validation of the proposed model* An interesting result from this experinlent is the probability of recall of a proposition as a function of its role For university students , Settings ( introduction of characters ) and Beginnings ( initiation of event sequences ) were best remembered* Attempts and Outcomes ( which together formed Goal Paths ) were next best recalled* Reactions ( mental events ) and Endings ( which were usually either very predictable or omitted in the stories used ) were least well recalled .</sentence>
				<definiendum id="0">Beginnings</definiendum>
				<definiendum id="1">Endings</definiendum>
				<definiens id="0">the probability of recall of a proposition as a function of its role For university students</definiens>
				<definiens id="1">together formed Goal Paths ) were next best recalled* Reactions ( mental events</definiens>
			</definition>
			<definition id="10">
				<sentence>Thesc are a normal Form of the story , a story with the Theme moved to the end , a story with the Theme omitted and a descriptive version which omits causal and temporal continuity .</sentence>
				<definiendum id="0">Thesc</definiendum>
				<definiens id="0">a normal Form of the story , a story with the Theme moved to the end , a story with the Theme omitted and a descriptive version which omits causal and temporal continuity</definiens>
			</definition>
			<definition id="11">
				<sentence>The semantic interpretation of a sentence ia defined as the set of conclusions that can be inferred from that sentence .</sentence>
				<definiendum id="0">semantic interpretation of a sentence ia</definiendum>
				<definiens id="0">the set of conclusions that can be inferred from that sentence</definiens>
			</definition>
			<definition id="12">
				<sentence>The fir~lt part is the translation of natural l'anguage into a farm that is convenient for use in making deductions .</sentence>
				<definiendum id="0">fir~lt part</definiendum>
				<definiens id="0">the translation of natural l'anguage into a farm that is convenient for use in making deductions</definiens>
			</definition>
			<definition id="13">
				<sentence>Charniak calls this looking fomard , and it is handled correctly by antecedent theorems .</sentence>
				<definiendum id="0">Charniak</definiendum>
				<definiens id="0">calls this looking fomard , and it is handled correctly by antecedent theorems</definiens>
			</definition>
			<definition id="14">
				<sentence>Re designates these additional pieces of information inferences , and agrees with Charniak that they should be made whenever possible Rieger discusses the use of in£ erences in handling problems such as reference , but the bulk of his work is specification of the inferences , themselves , and it is here that the main value of his work is found .</sentence>
				<definiendum id="0">Re</definiendum>
				<definiens id="0">designates these additional pieces of information inferences</definiens>
			</definition>
			<definition id="15">
				<sentence>In order to be able to recognize instances of missing links and to be able to supply them , Schank develops a classification of types of causality and characterizes their form and meaning .</sentence>
				<definiendum id="0">Schank</definiendum>
				<definiens id="0">develops a classification of types of causality and characterizes their form and meaning</definiens>
			</definition>
			<definition id="16">
				<sentence>Schank suggests that other knowledge is used to find the connection , and this suggestion seems to indicate a far more general approach to understanding English expressions of causality than any syntactic approach , Schank suggests that a person would , if possible , find a reasonable connection such as that the hurricane probably blew down the speaker 's house which caused him to lose money which caused him to become depressed , In order to accomplish this elaboration a person would have to use a great deal of world knowledge .</sentence>
				<definiendum id="0">Schank</definiendum>
				<definiens id="0">the hurricane probably blew down the speaker 's house which caused him to lose money which caused him to become depressed</definiens>
			</definition>
			<definition id="17">
				<sentence>A script is a sequence of actions that provide knowledge about the typical occurrence of some situation .</sentence>
				<definiendum id="0">script</definiendum>
				<definiens id="0">a sequence of actions that provide knowledge about the typical occurrence of some situation</definiens>
			</definition>
			<definition id="18">
				<sentence>The following is a partial description of the script for going to a restaurant : Script : Restaurant Track : Coffee shop Roles : Custome r , Waitress , Chef , CasKier Props : Tables , Menu , Food , Check , Money Reason : To get food to eat Entry conditions : Customer ( is hungry ; has money ) Results : Customer ( is not hungry ; has less money ; is pleased ) Cashier ( has more money ) Scene 1 : Entering Go to restaurant Find an ernp ty table Page 69 Decide where to sit Go to table Sit down [ MAINCON ] Scene 2r Ordering Receive menu Read menu Decide what to eat Tell Waitress what is wanted [ MAINCON ] Scene 3 : Eating @ em Scepe 4 : Exiting 1 * .</sentence>
				<definiendum id="0">Customer</definiendum>
				<definiens id="0">a partial description of the script for going to a restaurant : Script : Restaurant Track : Coffee shop Roles : Custome r</definiens>
				<definiens id="1">Entering Go to restaurant Find an ernp ty table Page 69 Decide where to sit Go to table Sit down [ MAINCON ] Scene 2r Ordering Receive menu Read menu Decide what to eat Tell Waitress what is wanted [ MAINCON ] Scene 3 : Eating @ em Scepe 4 : Exiting 1 *</definiens>
			</definition>
			<definition id="19">
				<sentence>For example , D-KNOW has an ASK planbox ( as a highly likely method ) which specifies the actual act of asking the appropriate question , the intended result ( fee .</sentence>
				<definiendum id="0">D-KNOW</definiendum>
			</definition>
			<definition id="20">
				<sentence>A theme is a prescribed pattern ( represented by a Metalingual construction ) to which a discourse may conform .</sentence>
				<definiendum id="0">theme</definiendum>
				<definiens id="0">a prescribed pattern ( represented by a Metalingual construction ) to which a discourse may conform</definiens>
			</definition>
			<definition id="21">
				<sentence>Sentence Memory : A Constructive versus Interpretive Approach .</sentence>
				<definiendum id="0">Sentence Memory</definiendum>
			</definition>
			<definition id="22">
				<sentence>Narrative Analysis : Oral Versions of Personal Experiences .</sentence>
				<definiendum id="0">Narrative Analysis</definiendum>
			</definition>
			<definition id="23">
				<sentence>SAM : A Story Understander .</sentence>
				<definiendum id="0">SAM</definiendum>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>The first triple can be read as follows : Look for an agent which lust be human .</sentence>
				<definiendum id="0">Look for</definiendum>
				<definiens id="0">an agent which lust be human</definiens>
			</definition>
			<definition id="1">
				<sentence>BUILDQ takes a variable number of argu~ents .</sentence>
				<definiendum id="0">BUILDQ</definiendum>
				<definiens id="0">takes a variable number of argu~ents</definiens>
			</definition>
			<definition id="2">
				<sentence>DESCRIPTIVE is a special case vhich is used for preposition phrases which modify noons .</sentence>
				<definiendum id="0">DESCRIPTIVE</definiendum>
				<definiens id="0">a special case vhich is used for preposition phrases which modify noons</definiens>
			</definition>
			<definition id="3">
				<sentence>The process begins again with IF , The beginning is the same , but this tine he first invocation of AGERT will succeed , because the test ( AND ( SHOULD-BE BUSZCIAIQ ) ( HUST-BE HUBAZII ) ) succeeds , The structure it returns is put in the register AG , IF continues with the second triple of parameters , and the form ( PATIENT ( HOST-BE HOSICAL-IISTBTJMEIIT~ ) is EVALed .</sentence>
				<definiendum id="0">PATIENT</definiendum>
				<definiendum id="1">HOST-BE HOSICAL-IISTBTJMEIIT~</definiendum>
				<definiens id="0">the register AG , IF continues with the second triple of parameters , and the form</definiens>
			</definition>
			<definition id="4">
				<sentence>patient of the verb , It then applies its TEST to it , In an active sentence , such as our example , the candidate for PATIEIT is the first noun phrase after the verb , The pianon is found , and since it gasses the test ( MUST-BE HUSICALIEJS'ERUBElrlT ) .</sentence>
				<definiendum id="0">PATIEIT</definiendum>
				<definiens id="0">the first noun phrase after the verb</definiens>
			</definition>
			<definition id="5">
				<sentence>PARSE : s VP NIL PRO IT SUBJ OBJ RUHBER SG VP IIL THS PRESENT VOICE ACTIVE V BE &lt; -ADJNIL IDIOTIC THAT-COHP NIL &lt; == &gt; NPB FRED PAST &lt; HOVE &lt; -SOUaCESOREPLACE &lt; -DESTIl ? ATIONNPB INDIA &lt; -PURPOSE &lt; == &gt; NPR FRED PR ES EMT &lt; -PLAY B FOOTBALL NUMBER SG &lt; == &gt; &lt; z= &gt; NPR FRED PAST &lt; -HOVE &lt; SOUBCESOMEPLACE &lt; -DESTf RBTIONHPB INDIA &lt; -PU RPOSE &lt; == &gt; NPR FRED PRESERT &lt; -=PLAY N FOOTBALL % UMBER SG PRESENT &lt; -HaVE-PROP IDIOTIC There is a small .</sentence>
				<definiendum id="0">PARSE</definiendum>
				<definiens id="0">s VP NIL PRO IT SUBJ OBJ RUHBER SG VP IIL THS PRESENT VOICE ACTIVE V BE &lt;</definiens>
			</definition>
			<definition id="6">
				<sentence>Fhe test is an arbitrary fosm .</sentence>
				<definiendum id="0">Fhe test</definiendum>
				<definiens id="0">an arbitrary fosm</definiens>
			</definition>
</paper>

		<paper id="1056">
			<definition id="0">
				<sentence>Each of the casg primitives above will have a dependent , which is a type of entity for all the case prirfiitives except WAY and GOAL , which take an assertion as dependent , The case primitive and its dependent ( entity or assertion ) fom a case group which is in turn dependent on a primitive action ( except for WITH and POSS which depended on an entity , and may therefore .</sentence>
				<definiendum id="0">GOAL</definiendum>
				<definiens id="0">in turn dependent on a primitive action ( except for WITH and POSS which depended on an entity , and may therefore</definiens>
			</definition>
			<definition id="1">
				<sentence>This interpre~ation can be constructed from the following _generaL rules for the building and interpretation of formulas : i ) Each subgroup in the formulacons~sts of a left mernber depending on a right member , and left or right may be either a single prim~tive element or another group , Thus , in ( *EIUM SUBJ ) we have a case group , known to be such because the rightmost member of its pair is the governor and SUBJ is the primitive element naming the Agent caqe .</sentence>
				<definiendum id="0">SUBJ</definiendum>
			</definition>
			<definition id="2">
				<sentence>*PHYSOB is a name ~f a class of primitive elements which includes THING , but also other primitives like MAN .</sentence>
				<definiendum id="0">*PHYSOB</definiendum>
				<definiens id="0">a name ~f a class of primitive elements which includes THING , but also other primitives like MAN</definiens>
			</definition>
			<definition id="3">
				<sentence>This proviso does not apply In the formula above since the agent is the same for CAUSE and STRIK , and CAUSE takes an assertion as object , but within a formula a group ( MAN STRIK ) would always be interpreted as an group , MAN being an unmarked agent of STRIK , and not as a man being struck which would require a marked object in the action group i , e , ( ( MAN OBJE ) STRIK ) .</sentence>
				<definiendum id="0">CAUSE</definiendum>
				<definiens id="0">takes an assertion as object , but within a formula a group</definiens>
			</definition>
			<definition id="4">
				<sentence>I have followed Fillmore 's ( 1975j device here of making ( 13 ) easier to read by putting ~t in SVO rather than the usual VSO ( predicate first ) form , It will be seen that it is pretty similar to the above fnmula for `` break1 ' except that , in order to avoid case notation , they have had to resort to such philosophically suspect devices as separating the act of using from the basic 'act ' inside the tree , even though there was really only one action in the whole business An extreme version of the view that case frames belong only to the underlying structure is Schank 's ( 1973 ) view that case frames awe for underlying primitive acts and that all cases that a primitive act takes , it takes obligatorily .</sentence>
				<definiendum id="0">VSO</definiendum>
				<definiens id="0">separating the act of using from the basic 'act ' inside the tree</definiens>
			</definition>
			<definition id="5">
				<sentence>One of the best efforts is to be found in~yons ' ( 1968 , p.155 ) , But , although it is easy t~ see the productive role of , say , illm more 's subject selection rule ( SSR ) , it is very hard to see what analytic signrficance it could have ; the surface subject is , after all , usually revealed by simple methods not requiring the notion of case .</sentence>
				<definiendum id="0">SSR</definiendum>
				<definiens id="0">illm more 's subject selection rule</definiens>
			</definition>
			<definition id="6">
				<sentence>Schank has no equivalent to formulas for nouns or adjectives , or any part of speech other than verbs .</sentence>
				<definiendum id="0">Schank</definiendum>
				<definiens id="0">has no equivalent to formulas for nouns or adjectives</definiens>
			</definition>
			<definition id="7">
				<sentence>So , if we were representing `` ~ohn picked up the statue made oul of wood on the table after lunch '' we would expect paraplates for the various case dependencies to create ties as follows : [ John picked + up the + statue1 c on the + table 1 Y-~c [ after TLOCA luach I where SOUR indicates source case , and TLOCA , time location .</sentence>
				<definiendum id="0">TLOCA</definiendum>
				<definiens id="0">follows : [ John picked + up the + statue1 c on the + table 1 Y-~c [ after TLOCA luach I where SOUR indicates source case , and</definiens>
			</definition>
			<definition id="8">
				<sentence>So , for example , Schank is perfectly well aware of the case ambiguity of the preposition `` with '' , and even lists four forms of it ( ibid , p. 231 ) corresponding to diff~rent cases , aloqg with four 11 c~ncepttual realizations for the syntactic item 'with ( noun ) ' `` , and specifies that they should be checked in order `` for conceptual validityu , just as paraplates are , The correspondence to the notions described In this paper ( and in Wilks 1973 , in , the same volume ) is reasohably clear : the inference of an instrument from PROPEL corresponds to an instrument specification in a formula for `` shoot '' ( and for Schank 1 it also comes from shoot ' : rather than more generally from PROPEL , since otherwise it could not be so specific about the instrument being a gun , as PROPEL does not deal generally in guns ) ; whereas the ordered list of case possibilities for `` with '' is not developed , but corresponds roughly to a paraplate stack for `` with '' , But here is the problem : in Schank ( 1973 ) the two forms of information do not actually meet in any general way , Schank mites as if the list of possible case functions of `` with '' is general ( i.e. action independent ) , but we have shown that it may well be specific to different primitive actions , in that there may well be a separate paraplate substack for e~rh primitive action , and may be no short gel .</sentence>
				<definiendum id="0">Schank</definiendum>
				<definiens id="0">the two forms of information do not actually meet in any general way</definiens>
			</definition>
			<definition id="9">
				<sentence>( iv ) Theproduction argument , Charniak argues that thenotion of case for Fillmore is es sentially connected with its productive generative role in controlling surface grammaticality , and that since AI systems are preoccupied with analysis , they are not making use of case , ( v ) The case-content argument , Charniak argues that we are never told what it is to be an agent as such , This is a subargument of ( iii ) above that one can not compute MEANING ( AGENT ) independently , ( vi ) The surface analysis argument .</sentence>
				<definiendum id="0">Charniak</definiendum>
				<definiens id="0">argues that we are never told what it is to be an agent</definiens>
			</definition>
			<definition id="10">
				<sentence>lnsfers ( EF'I ' ) Srtwccn rcgiunal autom , itcd clcaringhouscs ( AClI1s ] l'hc project will i~lvotvc Fedcr , j 1 Rcr , orve districts for Boston , Ncw York , Cl~vela~~d , Atlanta , l ) Allas , and Sdn I'r~ncisco , 'She systcrn will utilize the ~cderai Reserve s o~isting co~r~nunications network , 'Ted # ire , '' and the PRCS Bulk Data c.ip .</sentence>
				<definiendum id="0">lnsfers</definiendum>
			</definition>
			<definition id="11">
				<sentence>Mr. McCaster comes to AFIPS from his position as edltor of : EFTS -- Idustry Report ; Peripherals weekly ; aid Software Hgest ; a1 l pub1 ications of EDP News Services of Washington .</sentence>
				<definiendum id="0">Mr. McCaster</definiendum>
				<definiens id="0">comes to AFIPS from his position as edltor of : EFTS -- Idustry Report</definiens>
			</definition>
			<definition id="12">
				<sentence>( New York : Hol t , Rinehart Fillmore , C. ( 1971 ) Some problems for case grammar , in ( ed ) ~'~rien , Linguisticics : developments of the sixties ( Washington DC : Georgetown UP ) , 35-56 , Fillmore , C. ( 1972 ) Subjects , speakers and roles , in ( eds ) Davidson &amp; Haman , Semantics of Natural Language ( Dordrecht : ~eide1 ) ,1-24 .</sentence>
				<definiendum id="0">Linguisticics</definiendum>
				<definiens id="0">developments of the sixties ( Washington DC : Georgetown UP</definiens>
			</definition>
</paper>

		<paper id="1027">
</paper>

		<paper id="1077">
			<definition id="0">
				<sentence>Revesz : A note on the relation of turing machines to phrase structure grammars P.B. Schneck : A new program optimization B. ~omijlke Formal description of software components E. Santa-Toth : by structured abstract models G. Fay : H .</sentence>
				<definiendum id="0">Revesz</definiendum>
			</definition>
			<definition id="1">
				<sentence>ALPAC ( Automatic Language Processing Advisory Committee ) 1966 Lanquage and Machines Computers in Translation and Linguistics National Academy of Sciences , National Research Counci 1 : Washington , D.C. American Mathehatical Society 1968 `` Research on Machine Aids toan Editor of Scientific Translations . ''</sentence>
				<definiendum id="0">ALPAC</definiendum>
				<definiens id="0">Automatic Language Processing Advisory Committee ) 1966 Lanquage and Machines Computers in Translation and Linguistics National Academy of Sciences</definiens>
			</definition>
			<definition id="2">
				<sentence>Cherry gives the impression that infomation theory , statistics , Fourier analysis , and perhaps a little logic are the most important fonnal tools for the analysis of natural language .</sentence>
				<definiendum id="0">Cherry</definiendum>
				<definiens id="0">gives the impression that infomation theory , statistics , Fourier analysis</definiens>
			</definition>
			<definition id="3">
				<sentence>Qualities are restrictions imposed for ordering , appearance or non appearance of sentence fragments .</sentence>
				<definiendum id="0">Qualities</definiendum>
				<definiens id="0">restrictions imposed for ordering , appearance or non appearance of sentence fragments</definiens>
			</definition>
			<definition id="4">
				<sentence>Kunze constructs a list which enumerates the category responsible for their relations , e.g. a noun is paradigmatically related to its apposite through case .</sentence>
				<definiendum id="0">Kunze</definiendum>
				<definiens id="0">constructs a list which enumerates the category responsible for their relations</definiens>
			</definition>
			<definition id="5">
				<sentence>A bundle is a tree used to represent not a sentence but a set of sentences , i.e. trees .</sentence>
				<definiendum id="0">bundle</definiendum>
			</definition>
			<definition id="6">
				<sentence>More specifically , realization connects adjacent tactics G and Gj+l j by matching sentences u in the language generated by G with those sentences j v in the language of Gj+l which can be derived from u by using rules from R. An important property of the linguistic realization relation is the fact that ' every structure on some stratum can have only a finite number of llrealizates '' on the next stratum .</sentence>
				<definiendum id="0">realization relation</definiendum>
				<definiens id="0">connects adjacent tactics G and Gj+l j by matching sentences u in the language generated by G with those sentences j v in the language of Gj+l which can be derived from u by using rules from R. An important property of the linguistic</definiens>
			</definition>
			<definition id="7">
				<sentence>+ A vocabulary V is a finite set of symbols , and we use V to denote the set of all nbn-null strings consisting of symbols * from V ; using e to denote the null string , we also define V to be A rewrite system RW is a pair ( V , R ) where V is a vocabulary and R is a finite set of rules ( productions ) of the form u + v , + * where u E V and v E V ; u is known as the left hand slde of the production ( Ihs . )</sentence>
				<definiendum id="0">+ A vocabulary V</definiendum>
				<definiendum id="1">RW</definiendum>
				<definiendum id="2">R</definiendum>
				<definiens id="0">a finite set of symbols , and we use V to denote the set of all nbn-null strings consisting of symbols * from V ; using e to denote the null string , we also define V to be A rewrite system</definiens>
				<definiens id="1">a pair ( V , R ) where V is a vocabulary and</definiens>
			</definition>
			<definition id="8">
				<sentence>R-derivation ( or R R n simply a derivation ) of w from w n 1 ' * Given a rewrite system RW = ( V , R ) and a subset AX of V the language generated by R from axiom set AX with free derivations is defined to be the set ~ ( AX , RW ) = { wlueAx , u=* &gt; w ) .</sentence>
				<definiendum id="0">R-derivation</definiendum>
				<definiens id="0">a derivation ) of w from w n 1 ' * Given a rewrite system RW = ( V , R ) and a subset AX of V the language generated by R from axiom set AX with free derivations</definiens>
			</definition>
			<definition id="9">
				<sentence>R Given the rewrite system RW = ( V , R ) , define the domjnance relation &lt; on V x V by : d &lt; b iff xby + udv is one of the productions in R ( for some strings x , y , u , v ) or if there exists some c in V such that d &lt; c and c &lt; b. Then RW is defined to be acyclic ( abbreviated a . iff the relation &lt; is anti-symmetric and anti-reflexive. If u + v is a production in a fewrite system , it will be called a null rule if v is the null string e , and it will be called context-free if 11.11 , the length of u , is 1. A rewrite grammar G is a quadruple ( N , T , S , P ) where N and T are the sets of nonterminals and terminals respectively , distinguished nonterminal and f = ( NUT ) P ) is a rewrite system. In this case , if =* ? w then this is called a G-derivation , or a derivation in G , and the language generated by , G , denoted by * L ( G ) , is defined to be the set ( tl~ =* &gt; t in G , t6T .</sentence>
				<definiendum id="0">v</definiendum>
				<definiens id="0">the rewrite system RW = ( V , R ) , define the domjnance relation &lt; on V x V by : d &lt; b iff xby + udv is one of the productions in R ( for some strings x , y , u , v ) or if there exists some c in V such that d &lt; c and c &lt; b. Then RW is defined to be acyclic ( abbreviated a . iff the relation &lt; is anti-symmetric and anti-reflexive. If u +</definiens>
				<definiens id="1">the null string e , and it will be called context-free if 11.11 , the length of u , is 1. A rewrite grammar G is a quadruple ( N , T , S , P ) where N and T are the sets of nonterminals and terminals respectively , distinguished nonterminal and f = ( NUT</definiens>
				<definiens id="2">a G-derivation , or a derivation in G , and the language generated by , G , denoted by * L ( G )</definiens>
			</definition>
			<definition id="10">
				<sentence>One such mapping is the substitution s which associates with every symbol b of some alphabet T , a set of words ~ ( b ) over another alphabet Tt ; &amp; fining s ( xy ) = s ( x ) s ( y ) and s ( e ) = e , a substitution can be extended to strings .</sentence>
				<definiendum id="0">substitution</definiendum>
				<definiens id="0">the substitution s which associates with every symbol b of some alphabet T , a set of words ~ ( b ) over another alphabet Tt ; &amp; fining s ( xy ) = s ( x ) s ( y ) and s ( e ) = e , a</definiens>
			</definition>
			<definition id="11">
				<sentence>The a-transducer M = [ K , T , T , k F , ) is an extension 12 of the finite automaton , where T1 and T2 are the input and output 'dr * alphabets , and T is a finite subset of K x T1 x T2 x K ( the transi* * tion set ) .</sentence>
				<definiendum id="0">T</definiendum>
				<definiendum id="1">K</definiendum>
				<definiens id="0">an extension 12 of the finite automaton , where T1 and T2 are the input and output 'dr * alphabets , and</definiens>
				<definiens id="1">a finite subset of K x T1 x T2 x</definiens>
			</definition>
			<definition id="12">
				<sentence>, Gn ) is a vector of n rewrite grammars , and RLZ = ( RO , R1 , ... , R ) is a n vector of ~+1 acyclic rewrite systems .</sentence>
				<definiendum id="0">Gn )</definiendum>
				<definiens id="0">a vector of n rewrite grammars</definiens>
				<definiens id="1">a n vector of ~+1 acyclic rewrite systems</definiens>
			</definition>
			<definition id="13">
				<sentence>The transduction perfo~med + by such a grammar will be defined by T-RSTRAT ( RST ) = { ( u , v ) lw0=u~vC , * * W n+l =vcVE , there exist w c L ( G. ) such that w = &gt; w~+~ j via R J j j derivations for j = 0,1 , .</sentence>
				<definiendum id="0">T-RSTRAT</definiendum>
			</definition>
			<definition id="14">
				<sentence>a1 ' on the rhs. ; to begin with , let Pi+l contain P. , 1 and Ni+l contain Ni ; IF b+cd is a production in Ry THEN for every A+bB in P ( i , b ) , ADD ta N , +l a nonterminal [ A ; B ; b+cd ] , and ADD to P i+l productions A+c [ A ; B ; b+cd~-and [ A ; B ; b+cd ] +dB ; IF b+e is ih R , THEN for every A+bB in P- ( i , b ) ADD production A+B tp Pi+l ; IF bc+d is in R , THEN for every pair of productions A+bB in P ( i , b ) , and C+cD in P ( i , c ) , ADD to Pi+l the new production A+dD if B= &gt; *c in Gi ; END ; Suppose that we were able to establish that From the construction it is easy to see that P is always a subi set of Pi+l ( and hence L ( G. ) c L ( Gi+l ) ) , and if 1 G =G for some index m m m+ 1 ( i.e. no new productions are added to G in Construction I ) , then m G would be equal to G for every j &gt; m. I m But , if such an m exists then L ( L ( G ) ; R ) = U L ( G. ) = L ( G ) i=l 1 m and G is the type.3 grammar we are looking for .</sentence>
				<definiendum id="0">IF b+cd</definiendum>
				<definiendum id="1">IF b+e</definiendum>
				<definiendum id="2">IF bc+d</definiendum>
				<definiendum id="3">G</definiendum>
				<definiens id="0">L ( G ) ; R ) = U L ( G. ) = L ( G ) i=l 1 m and</definiens>
			</definition>
			<definition id="15">
				<sentence>To , prove ( I ) , we first define a new type of derivation ( `` singl &amp; , left-right pass '' ) relation `` =o &gt; ~ `` as follows : =Q='~ v iff there exists integer n such that for j = l , ... , n x + y. is a rule in R and z is some string with the property that J J j u = z x z ' .</sentence>
				<definiendum id="0">y.</definiendum>
				<definiendum id="1">z</definiendum>
				<definiens id="0">a rule in R and</definiens>
			</definition>
			<definition id="16">
				<sentence>This approach unfortunately runs into the following problem : the addition of a new production to G in step 4 , allows new pairs of i variables B ' and C ' to be connected by a derivation B '= &gt; *c 9 this may aPlow new production A'+dD1 to be added to Gi+14 in step 5 , which in turn may eventually allow step 4 to add a new rule to for some The above compels us to look for an alternative prod of ( 2 ) : exhibiting a grammar GO such that every Gi is a subgrammar of GO .</sentence>
				<definiendum id="0">Gi</definiendum>
				<definiens id="0">the addition of a new production to G in step 4 , allows new pairs of i variables B '</definiens>
				<definiens id="1">a subgrammar of GO</definiens>
			</definition>
			<definition id="17">
				<sentence>Suppose the highest index value assigned is n. Then GO will be c~nstructed from G by repeated modification in n passes through the following : CONSTRUCTION 2 : Let GO = ( N ' , T ' , s , P ' ) be G initially ; FOR i=l toqn DO * in the i-th pass , add to GO all possible productions representing derivations by index i rules */ I let P ( d ) be the set of all productions currently 0 In G , with 'd ' on the rhs. ; I ( b ) i ) , THEN alter GO in exact.1~ the same way as in steps 3 ( or 4 ) of CONSTRUCTION 1 ; ( except that PO and NO are used instead of Pi+l and N ) .</sentence>
				<definiendum id="0">; I</definiendum>
				<definiens id="0">s , P ' ) be G initially ; FOR i=l toqn DO * in the i-th pass , add to GO all possible productions representing derivations by index i rules */ I let P ( d ) be the set of all productions currently 0 In G , with 'd ' on the rhs.</definiens>
			</definition>
			<definition id="18">
				<sentence>Then the following theorem is an obvious consequence of the definition of L-RSTRAT : Theorem 4.1 If RST = ( n ( G G ) , ( Ro , ... , n R- ) , VC , VE ) is an n n-RSTRAT gramman , and TOP ( RST ) is the ( n1 ) -RSTRAT grammar ( n-l , ( G1 , ... , G ' ) , ( Ro , ... , R n1 n1 ) , .</sentence>
				<definiendum id="0">VE )</definiendum>
				<definiendum id="1">RST )</definiendum>
				<definiens id="0">an obvious consequence of the definition of L-RSTRAT : Theorem 4.1 If RST = ( n ( G G</definiens>
			</definition>
</paper>

		<paper id="1054">
			<definition id="0">
				<sentence>The second type of situational coherency is more subtle , it consists of applying the addresse ' s knowledge to fill up some relations mi tted in the sender s message , This is needed e. g. in the text ( Bellert 1972:79 ) ( 2 ) ~nn 's eldest son has left Warsaw for a scholarship study in the Sorbonne , ( 3 ) France is an interesting co-mtr~ to study in .</sentence>
				<definiendum id="0">France</definiendum>
				<definiens id="0">an interesting co-mtr~ to study in</definiens>
			</definition>
			<definition id="1">
				<sentence>First is a theoretical one : I Peel strongly that it is the analysis which bs the primary activity and that the generation is driven by the evaluation of the re-analysis of a generated text .</sentence>
				<definiendum id="0">First</definiendum>
				<definiens id="0">a theoretical one : I Peel strongly that it is the analysis which bs the primary activity and that the generation is driven by the evaluation of the re-analysis of a generated text</definiens>
			</definition>
			<definition id="2">
				<sentence>It has been noted by Winograd ( 1972 : 147 ) with respct to the tine reference , e. g. : ( 53 ) Idany rich men made their fortunes during the depression , ( 54 ) Idany rich men lost their fortunes during the depression , ( 55 ) Many rich men worked in restaurants during the depression , \ In these sentences the rich men '' phrase is to be evaluated in the present time environment for ( 53 ) , in the past tine environment for ( 54 ) , and the sentence ( 55 ) is ambiguou : : when taken out of a larger context .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">the rich men ''</definiens>
			</definition>
</paper>

		<paper id="1075">
			<definition id="0">
				<sentence>testfct is a predicate which is true for the appropriate X7sr but wha $ 1s the candidate set of X75 which should be tested ?</sentence>
				<definiendum id="0">testfct</definiendum>
				<definiens id="0">a predicate which is true for the appropriate X7sr but wha $ 1s the candidate set of X75 which should be tested</definiens>
			</definition>
			<definition id="1">
				<sentence>7524 LOGICAL FORM : Csetx 'X2 ( and C3oratleast 1 'X39 ( setx 'X5 ' ( tkstfct X5 ' ( 'PARAREA X2 ' 1976 ) '= 1 1 Vgreatexthan Y39 '5500001 1 ( parcel ~21 1 1 Figure 5 Figure 5 , it calls the setx specialist , which adds X2 to the ( null ) list of set variables and the ( null ) list of query vakiables , and calls EVALUA with the associated setx predicate , : 'andvr .</sentence>
				<definiendum id="0">setx specialist</definiendum>
				<definiens id="0">adds X2 to the ( null ) list of set variables and the ( null ) list of query vakiables , and calls EVALUA with the associated setx predicate</definiens>
			</definition>
			<definition id="2">
				<sentence>THE PRESS offers no free literature , but is preparing to issbe a Newsletter .</sentence>
				<definiendum id="0">PRESS</definiendum>
				<definiens id="0">offers no free literature , but is preparing to issbe a Newsletter</definiens>
			</definition>
			<definition id="3">
				<sentence>J. FILLMORE , .Scenes-and-Frames Semantics EVA HAJICOVA , Fotus and Negation DAVID G. IIAYS , Cognition : The Linguistic Approach IfARTLN KAY , Morphological and Syntactic Analysis FERENC KliEFER , Some ObservatiUns Concerning the Differences Between Sentence and Text JOHN LYONS , Statements , Questions , and Comands BARBARA H. PARTEE , John is Easy to Please S.R. PETRICK , On Natural Language Based Computer Systems YORICK # ILKS , Natural Language Understanding Systems Within the A.I. Paradigm : A Survey and Some Comparisons TERRY WINOGRAD , Five Lectures on Artificial Intelligence W.A. WOODS , Lunar Rocks in Natural English : Explorations in Natural Language Question An~wering American Journal of Computational Linguistics Microfiche 75 : 76 NATURAL LANGUAGE IN INFORflATIOIJ SCIENCE SKRIPTOR , Stockholm , Sweden , 1977 FID Publication 551 This book presents the results of a Workshop on Linguistics and Information Science organized by the Committee on Linguistics in Documentation of the International Federation for Documentation , ( FID/LD ) and by the UAL Institute for Information Science .</sentence>
				<definiendum id="0">Paradigm</definiendum>
				<definiens id="0">Easy to Please S.R. PETRICK , On Natural Language Based Computer Systems YORICK # ILKS , Natural Language Understanding Systems Within the A.I.</definiens>
			</definition>
			<definition id="4">
				<sentence>Lt contains a aeries of papers that provide perspectives on linguist5cs and information science from the vantage points of information science ( F. W. Lancaster , Univel-sity of Illinois ) , library science ( Derek Austin , The British Library ) , quantitative linguistics ( Wolf Moskovich , Hebrew University of Jeru3aPem ) , computational linguistic8 ( Naomi Sager , New York University ) , linguistics ( Petr Sgall , Charles University ) , o~mplex semantic information processing ( Tew A. van Dijk , University , of Amsterdam ) , and terminology ( J. Ooetschalckz , Commission of the European Comm~nities ) .</sentence>
				<definiendum id="0">Lt</definiendum>
				<definiendum id="1">quantitative linguistics</definiendum>
				<definiendum id="2">terminology</definiendum>
				<definiens id="0">contains a aeries of papers that provide perspectives on linguist5cs and information science from the vantage points of information science</definiens>
				<definiens id="1">linguistics ( Petr Sgall , Charles University ) , o~mplex semantic information processing ( Tew A. van Dijk , University , of Amsterdam ) , and</definiens>
			</definition>
</paper>

		<paper id="1037">
			<definition id="0">
				<sentence>Our principal apparatus was an Owens-Illinois Digivue Plasma Display Unit attached to a Nova 1220 minicomputer The Digivue Display Unit is an electronic device with a gasfilled display matrix and activating circuitry .</sentence>
				<definiendum id="0">Digivue Display Unit</definiendum>
				<definiens id="0">an electronic device with a gasfilled display matrix and activating circuitry</definiens>
			</definition>
			<definition id="1">
				<sentence>The program language used was Graphic Basic , a version of Data General Corporation 's time-shared BASIC , modified for use with the Digivue Display Unit ( Fulton , 1974 ) .</sentence>
				<definiendum id="0">Display Unit</definiendum>
				<definiens id="0">a version of Data General Corporation 's time-shared BASIC , modified for use with the Digivue</definiens>
			</definition>
			<definition id="2">
				<sentence>LINGOL , developed by V. Pratt ( 1973 ) at MIT , is a language appropriate to syntaxsemantics interface and in which it is easy to write grammars in the form of rewriting rules .</sentence>
				<definiendum id="0">LINGOL</definiendum>
				<definiens id="0">a language appropriate to syntaxsemantics interface and in which it is easy to write grammars in the form of rewriting rules</definiens>
			</definition>
			<definition id="3">
				<sentence>However ATN has the following shortcomings , especially when we apply it to the parsing of Japanese sentences : sentence , checks the applicability of a rule , and makes the transition from one state to another .</sentence>
				<definiendum id="0">ATN</definiendum>
				<definiens id="0">sentence , checks the applicability of a rule</definiens>
			</definition>
			<definition id="4">
				<sentence>Variables in patterns are indicated as : X ( X is an arbitrary LISP atom ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">an arbitrary LISP atom )</definiens>
			</definition>
			<definition id="5">
				<sentence>I ( TR / ) 1 ARBITRARY LISP FORM &lt; variable : : = : X ( X is an arbitrary LISP atom ) name 7 &lt; register : : = /X ( X is an arbitrary LISP atom ) name ) shows that a rule is applicable no matter what the structure under process is The variables used in ( structure-1 ) are bound to corresponding substructures when matching succeeds. The results of Example 1 ( See Figure 2 ) indicate that the variable : K is bound to the substructure ( * ( B ( R1 C ) ) D ) The scope of variable binding is limited to within the realm of the particular rule. The same variable name in different rules has different interpretations. In this sense , : X-type variables in &lt; s tructure-I &gt; are called Local Variables .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">an arbitrary LISP atom</definiens>
			</definition>
			<definition id="6">
				<sentence>They are represented by the symbols /X ( X is an arbitrary LISP atom ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">an arbitrary LISP atom )</definiens>
			</definition>
			<definition id="7">
				<sentence>the result of the evaluation of the 2nd argument A the result of the evaluation of the 2nd argument the content of the register the value of the variable I &lt; structure-2 , or / , rregis ter-name , LISP 4 form ) Cregis ter-name LISP &lt; form &gt; ( register-name &gt; 4 regis ter-name &gt; LISP 4 form ) , TR transforms the varizbles and registers in the structural pattern into their values .</sentence>
				<definiendum id="0">TR</definiendum>
			</definition>
			<definition id="8">
				<sentence>GU gets the content of the register of the higher level .</sentence>
				<definiendum id="0">GU</definiendum>
				<definiens id="0">gets the content of the register of the higher level</definiens>
			</definition>
			<definition id="9">
				<sentence>( SR r regis ter-name &gt; ( CONS 4 form , ( GR &lt; registername3 1 1 ) the result of the evaluation of the 2nd argument the content of the register the result of the evaluation of the 2nd argument For example , suppose strx = ( ADJ ( TOK : N ) ) ( N ( TOK : N1 ) ) : I ) con = ( SEM : N : N1 ) Here TOK is the link between a word and its part of speech. : N and : N1 are the words of an input sentence. SEM is a function defined by the user which checks the semantic co-ordination between the adjective : N and the noun : N1. By this function SEM , we can search , if necessary , through both lexical entries and the contextual data bases. Uith this approach , if a certain syntactic pattern is found in the input structure , it is possible for an appropriate semantic runction to be called. Hence the intimate iiitcrcctions between syntactic and semantic components can be obtained easily without destroying the clarity of natural language grammars. Arbitrary LISP-forms can be also used in &lt; act &gt; -portion .</sentence>
				<definiendum id="0">ter-name &gt;</definiendum>
				<definiens id="0">CONS 4 form , ( GR &lt; registername3 1 1 ) the result of the evaluation of the 2nd argument the content of the register the result of the evaluation of the 2nd argument For example , suppose strx = ( ADJ ( TOK : N ) ) ( N ( TOK : N1 ) ) : I ) con = ( SEM : N : N1 ) Here TOK is the link between a word and its part of speech. : N and : N1 are the words of an input sentence. SEM is a function defined by the user which checks the semantic co-ordination between the adjective : N and the noun : N1. By this function SEM , we can search , if necessary , through both lexical entries and the contextual data bases. Uith this approach , if a certain syntactic pattern is found in the input structure , it is possible for an appropriate semantic runction to be called. Hence the intimate iiitcrcctions between syntactic and semantic components can be obtained easily without destroying the clarity of natural language grammars. Arbitrary LISP-forms can be also used in &lt; act &gt; -portion</definiens>
			</definition>
			<definition id="10">
				<sentence>Japanese is a typical example ofan SOV-language in which the object and other constituents governed by a verb usually appear before : he verb in s sentence .</sentence>
				<definiendum id="0">Japanese</definiendum>
			</definition>
			<definition id="11">
				<sentence>&lt; um-N. set 05 rules is shown in the following. The corresponding statediagram is shown in Figure 7. START NEXTB POP NEXT Fipure 7 State Mapram of a Si wple Example SL ? -1strx : = : I : I1 ( X ( SUM : N ) ) : J ) con : = ( GREATERP 10 ( PLUS : N : 11 ) ) act : = ( ( SV : N ( PLUS : N : I1 ) ) ( PUSHR /REG : Ill ) end : = ( NEXT SUMLm C ) c : I ( X ( SUM : N ) ) : J ) ) -2strx : = ( * : I ( X ( SUM : N ) ) rJ ) con : = ( CONTEXTCHECK /RESULT ( TR ( X ( SUM : N ) ) ) ) act : = NIL end : = ( NEXT BACKTRACK / ) -3strx : = ( % : I ( X ( SLW : N ) ) : J ) con : = : T act : = NIL end : = ( FM-ERROR ) -4strx : = ( 8 ) con : = T act : = ( ( SR /RESULT ( CONS 'X /RESULT ) ) ) end : = ( POP /RESULT ) BACKTRACK -1strx : = : I ( X ( SLW : PI ) ) : .J ) con : = T act : = ( ( SR /REG NIL ) ( SR /RESULT ( APPEND /RESULT ( TR ( X ( SUM : N ) ) ) ) ) ) end : = ( NEXTB SUMUP ( S # : I : J ) ) -2strx : = ( * : I ( X ( SUM : N ) ) : J ) con : = T act : = ( ( POPR /TEMP /REG ) ( SV : N ( MINUS : N /TEMP ) ) ) end : = ( NEXT BACKTRACK 01 : : I /TEMP ( X ( SUM : N ) ) : J ) ) The input string is the ! list shown in Figure 6. Since the start state is SWP , the first rule attached to this state is applied. This rule will find the leftmost 'x ' and an integer just before the 'x ' ( by SUMUP -I- , strx ) . The variable : I1 is bound to tius integer. This integer is added to the sum of the integers , : N , if the total does not exceed ten ( SUMUP -I- , con ) . PUSHR , used in the &lt; act &gt; -part , is a PLATON function which puts the second argument on the head of the first argument ( SUMUP -I- , act ) After this rule is applied , the control will enter the state SUMUP again ( SW -I- , end ) .</sentence>
				<definiendum id="0">input string</definiendum>
				<definiendum id="1">SW -I-</definiendum>
				<definiens id="0">N ) ) : J ) con : = : T act : = NIL end : = ( FM-ERROR ) -4strx : = ( 8 ) con : = T act : = ( ( SR /RESULT ( CONS 'X /RESULT ) ) ) end : = ( POP /RESULT ) BACKTRACK -1strx : = : I ( X ( SLW : PI ) ) : .J ) con : = T act : = ( ( SR /REG NIL</definiens>
			</definition>
</paper>

		<paper id="1082">
			<definition id="0">
				<sentence>edfie 'have bccn d &lt; welopeb for use In computatioraal env-dr : ,nmcnts .. Samp arc. fc~ nrcstr ic tt.d dl-~mrai.rrz ; ( Black , 1908 : Ebbrow , 1968 ; Colby , 1973 ; Raphael , 1968 ; Winograd , 1W1 ; etc. ) The present model is raore'in the tradition of Klein , Oakley , Suurballe , and Ziesemer ( 1 972 ) , Quillian ( 1 969 ) , Rumelhar t , Lindsay , and Normaa ( 1972 ) , Schank ( 1975ai , Shapiro ( 1971 ) , Simmons ( 1970 ) , and Wllks ( 1972 ) , where no particular context is prescrfbed* It will be apparent that at many points the present model draws upon these earlier syatems. Some of the differences between systems are probably differences in notationHowever no system Is at a stage of co~staney or completeness that makes it worthwhile to devote much effort to establishing the equivalences Although it wauld be possib1.e to present only the paws that I believe to be novel , giving the whole system in a common notation will ease the task of the readerThe model , hereafter called the encyclopedia , endeavors to be consistent with available psychological and linguistic views of the structure of language and t'hought , for any automated language system must closely imitate the ttorkings of human cognition to be successful ( Collins &amp; Quillfan , 1972 ) . The encyclopedia encodes common knowledge sf the world which may differ from scientifically accurate descriptions. Putnam ( 1975 ) calls such knowledge `` stereotypical '' : The fact that a feature . . . le , included in the stereotype associated with a word X does not mean that it is an analytic truth that all Xs have that feature , nor that most Xtl have that feature , nor that all normal Xs have that feature , nor that some Xs have that feature. . . Dtwovering that our stereotype is based on nonnormal or unrepresentative members of a natural. kind is not discovering a logical contradiction. a . [ but ) The fact is that we could hardly communicate if moat of our stereotypes were n't pretty accurate as far as they goe ( pp. 250-251 ) The encyclopedia is achematized and ihplemented as a directed graph ; in current parlance it is a network model. Nodes characterize concepts and arcs relations between conceptsv The most general statement to make about the model is that relations and aoneept types are the necessary system primitives ; some concepts may be primitive , but the model does not depend on the* existence of primitive concepts Discussion wi2 1 cover the nodes and relations of the model. Attention will also be given to network processes. No psychol~gical validity is claimed for the content of any of the structures shown ; the claim extends only to the relational sttucture Questions of content must be answered empiricallyNodes There are four types o.f nodes : -9 event Yr entit .-attribute , and modality. The first three correspond to simple verb simple noun , and simple modifier , respectively. The fourth type of node is novel Its rale in *he system will become clear after a description of arcs * For the meantime it will , have to suffice to say that it is used in the spatio-temporal causal , belief , and hiersrchic organization of knowledge * Its ancestor in linguistic theory is `` modal '' in the model/proposition dichotomy of Fillmore ( 1969 ) . Sch~bert ( 1976 ) has predicate nodes that are similar in motivation , but different in use from modality nodes. -6 Nodes of the encyclopedia are not labeled ( Collins &amp; Quillian , 1972 ) . An arc , termed name , points from a node into a dictionary of print names. For clarity nodes in diagrams will be annotated , but this should not be taken as representing the implementation , which is as shown in Figure 1. rock I DICTIONARY I ENCYCLOPEDIA I I person Peter Adnt Sally I Figure 1 Labeling nodes In all the following figures is an event , entity or attribute nodeAnnotations on these nodes are enclosed in 1 , &lt; &gt; , and [ I , respectivelyModality nodes appear as o and are never annotated .</sentence>
				<definiendum id="0">respectivelyModality</definiendum>
				<definiens id="0">the necessary system primitives ; some concepts may be primitive , but the model does not depend on the* existence of primitive concepts Discussion wi2 1 cover the nodes and relations of the model. Attention will also be given to network processes. No psychol~gical validity is claimed for the content of any of the structures</definiens>
				<definiens id="1">predicate nodes that are similar in motivation</definiens>
			</definition>
			<definition id="1">
				<sentence>Others ( Schank , 1975a ; Halllday &amp; Haaan , 1975 ) distinguish three kinds ~f causation : reason , result , and purpose .</sentence>
				<definiendum id="0">Others</definiendum>
				<definiens id="0">~f causation : reason , result , and purpose</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus the matrix proposition has an unnamed participant in objective or instrumental role and this nsde is defined by a metalingual arc to the modality of the contained propositiono For example ( 1 ) Peter believes Fred chased the cat* is represented as in Figure 7 .</sentence>
				<definiendum id="0">matrix proposition</definiendum>
				<definiens id="0">has an unnamed participant in objective or instrumental role and this nsde is defined by a metalingual arc to the modality of the contained propositiono For example ( 1 ) Peter believes Fred chased the cat*</definiens>
			</definition>
			<definition id="3">
				<sentence>In modeling behavior , these goals provide the situations that other b ehaviotal actions are intended to contribute towards achieving Negation Negation is a property that is marked on 4 modality .</sentence>
				<definiendum id="0">Negation Negation</definiendum>
			</definition>
			<definition id="4">
				<sentence>The quantification can also be characterized episodically by every manifestat &lt; on of a concept having the property. Interpreting `` all '' ( Woods , 1975 ) , could call upon either systemic or episodic facts* A question containing a universal quantifier may be answered by either examining a varietal node ( Are all moil-boxes blue ? ) , or by = examining every mhifestation ( Do a11 mail-bo~es stand at street corners ? ) . It should be noted that `` all '' requires that the predicacron be true only at some time , e.g. , All people die ; it does not require continuity in time , e .g. , All birds have wings. Thus untiversal quantification is also true if the predication is found for a manffestation of the varietal node , os is found for every instance of the concept. Processes in the Network -The model for knowledge described above is only part of a system to model cognitive behavior. Thought is simulated by processing knowledge. Different aspects of behavior correspond to different processes , but with one and the same encyclopedia common to all. A system for discourse analysis requires processes that use the encyclopedia to find patterns of organization in a discourse. It would be possible to describe solely the requirements of discourse analysis , but greater overall insight is garned through a preliminary general examination and classification of cognitive processes. Once this is accomplished , discourse analy4s is seen not to be a unique process but as composed of more basic general ones. Simulation of many asp'ec ts of cognitive behavior can he porfomed by complexes of these general processes : discourse analysis is just an6 such complex Processes can be classified in various ways : functionally , by complexity , or by the class of relation involved. The ftlnction of some processes is external ; they deal with input and output. Some internal processes find relations between new information and knowledge already in the encycloppdia , others investigate the va1idi.t~ of new knowledge , etc. Processes are of two type oE complexity , either path-tracini or pattern-*. The dichdtomy is justified by showing that there are tasks that can only be done by pattern-matching* This topic i.s considered in detail later. Of the infinite number of possible ordered sets of arcs , only some define significant paths in the network. An example of a relevant set of arcs is the arcs of a paradigmatic path ; this defines possible inheritances. Other significant sets are causal chains , whi-ch are represented by a string of cause arcs between modalities. Th~s suggests that processes that use tile same kind of relati , ons or identical relations are significant. A functronal classification of processes does nqt give a deeper understanding of3 cognitive processes. However , classification by complexity and by kind of arc is revealing. Path-tracing and patternmatching differ in power. For the tormer , subpaths can be defined by the kind of arc found in the subpath. Henceforth processes in the network wilt be described according as they are path-tracers or pattern-matchers. Path-tracing Path-tracing processes try to establish paths between nodes along arcs of the network. Quillian ( 1969 ) established this methodology for semantic nets. A particularly common type of path is the paradigmatic path. In rigure 3 there is a paradigmatic path betweqn `` Ford ( as President ) '' and `` thing '' , but not between `` rock '' and `` soul '' . The definition of a paradigmatic path is valid for entities , events , and attributes. Any paradigmatic path in the network will conform to the structure sl~own in Flgure 11 where * indicates any number of occurrences including zero of the marked relation. Figure 11 Paradigmatic paths The structure follows directly from the iterativity of variety , manifestation , and typical arcs and their posbible relative orien ta~ tions. Strings of arc labels representing paths throwh the tree are obviously regular expressions , Lee , the strings are sentences of a type 3 language* Paradigmatic path-tracing can thus be characterized by a finite sVate automaton ( Hopcroft &amp; Ullman , 1969 ) . Any process that can he characterized by a finite state automaton is formally termed a path-tracing prwess in the system* One such process is testing the applicability of an attribute to an entity , e .go , whether `` fresh fish '' or `` round smoke '' is acceptable when the relationship is not explicitly in the encyclopedia . Assuming the named entry points to the encyclopedia are at vari-ety or instance nodes , an entity F1 ( e.g. , horse ) can inherit properties from an entity C2 ( e.g. , animal ) if there is a path between F1 and T2 of the form ( I- ) iiihR* , where indicates a relation that is the converse of X and ) ind~cate an optional arc. Properties may be attached to E2 either directly ar with typical and/or manifestation arcs , ime. , the path from Cp to the node F3 in the representation of the property has the form TYP* MAN*. Thus the path from El to Eg has the form ( m ) WR* TYP* MAN*. Analogously , an attribute Al can apply to an entlty if there is a similar path to an attribute that : is encoded as applying to the entity. Thus if there is a path ( 8 ) ' &lt; El &gt; ( ET ) KW TYP* MAN* GE IIAN* TYP* VAK* ( IST ) [ Al I then A , can feasibly apply to El .</sentence>
				<definiendum id="0">property. Interpreting `` all ''</definiendum>
				<definiendum id="1">Ford</definiendum>
				<definiens id="0">call upon either systemic or episodic facts* A question containing a universal quantifier may be answered by either examining a varietal node ( Are all moil-boxes blue ? ) , or by = examining every mhifestation ( Do a11 mail-bo~es stand at street corners ? )</definiens>
				<definiens id="1">does not require continuity in time , e .g. , All birds have wings. Thus untiversal quantification is also true if the predication is found for a manffestation of the varietal node , os is found for every instance of the concept. Processes in the Network -The model for knowledge described above is only part of a system to model cognitive behavior. Thought is simulated by processing knowledge. Different aspects of behavior correspond to different processes , but with one and the same encyclopedia common to all. A system for discourse analysis requires processes that use the encyclopedia to find patterns of organization in a discourse. It would be possible to describe solely the requirements of discourse analysis , but greater overall insight is garned through a preliminary general examination and classification of cognitive processes. Once this is accomplished , discourse analy4s is seen not to be a unique process but as composed of more basic general ones. Simulation of many asp'ec ts of cognitive behavior can he porfomed by complexes of these general processes : discourse analysis is just an6 such complex Processes can be classified in various ways : functionally , by complexity , or by the class of relation involved. The ftlnction of some processes is external ; they deal with input and output. Some internal processes find relations between new information and knowledge already in the encycloppdia , others investigate the va1idi.t~ of new knowledge , etc. Processes are of two type oE complexity , either path-tracini or pattern-*. The dichdtomy is justified by showing that there are tasks that can only be done by pattern-matching* This topic i.s considered in detail later. Of the infinite number of possible ordered sets of arcs , only some define significant paths in the network. An example of a relevant set of arcs is the arcs of a paradigmatic path ; this defines possible inheritances. Other significant sets are causal chains , whi-ch are represented by a string of cause arcs between modalities. Th~s suggests that processes that use tile same kind of relati , ons or identical relations are significant. A functronal classification of processes does nqt give a deeper understanding of3 cognitive processes. However , classification by complexity and by kind of arc is revealing. Path-tracing and patternmatching differ in power. For the tormer , subpaths can be defined by the kind of arc found in the subpath. Henceforth processes in the network wilt be described according as they are path-tracers or pattern-matchers. Path-tracing Path-tracing processes try to establish paths between nodes along arcs of the network. Quillian</definiens>
			</definition>
			<definition id="5">
				<sentence>The case correspondences are essential information for the prot ess of abstraction and for its inverse , decomposition , which produces a less abstract description from a network containing a term that has a metalingual definition .</sentence>
				<definiendum id="0">decomposition</definiendum>
				<definiens id="0">produces a less abstract description from a network containing a term that has a metalingual definition</definiens>
			</definition>
			<definition id="6">
				<sentence>The net then has all the informa &lt; ion for paraphrases between the two abstract terms as well as for decomposition and abstraction* There is no productive relationship between the roles of the same participant at different Levels of abstraction. Case relations represent only the causal/animate perception of participation in an event. More detailed descriptions of the roles of participants can only be If given in context. For example , money '' is perceived as instrumental in `` buytt , but at the next level of decomposition , it is in an objectiue role in `` give '' . The outputs of both abstractton and decomposition are structurally indistinguishable from any other proposition in the encyclopedia and therefore can again be subject to either of the processes. As patternmatching is a recursive process this ability for output of the process to be accepted as input is essential. The distinction between path-tracing and pattern-matching processes may be psychologically significant Inhelder and Piaget ( 1 964 ) find that prepuberty children can not use logical equations such as - ( A AB ) 3 -A V -Be The equations involve cgreference and hence their application requires a pattern-matching process . It could be speculated that this more powerful process only appear &amp; at maturation. DISCOURSE ANALYS IS The Structure of Coherent Discourse In this section the hypothesrs concerning the kinds of organization present in coherent discourse is outlined. A fuller description can be found elsewhere ( Phillips , 1975 ) . The role of the encyclopedia in discourse is then exemplified. A discourse is judged coherent if its constituent propositions are connected . Various types of cohesive links are observed in discourse : anaphoric , spatial , temporal , causal , and thematic. I will formally describe the structure of a well-formed discourse in terms of these connect vesL Anaphora A discourse has reference to objects. Coherence is given by repetition of the reference. Two kinds of anaphora can be distinguished. The first is marked by the presence of a proform ( or by repetition of the fonn ) : [ It is usual for coherent d.lscourse to exhibit several kinds of cohe'sive links . Thus the examples invariably contain more than the one specifically being illustrated. ] ( 10 ) Henry travels too much. He is getting a foreign accent. Antecedents may bm nominal , verbal , or clausal . The second kind of anaphore has a dependent that is an abstract term for the antecedent. for example I1 ( 11 ) John put the car into reverse '' instead of `` drive '' . The mistake cost him $ 300 to repair. `` Plistake '' in ( 11 ) is an abstract characterization of the gear selection expressed in the first sentence. Nagao anti Tsujii ( 1976 ) address this issue. A conventi-onal way to label the recurring characters in discourse t f is as dramatis personaetf. Ifowever , cohesion can result not only from multiple appearances of people ( lo ) , but of any concept , as in ( 11 ) . Spatial , Temporal , and Causal Cohesion Space , time , and cause give coherence to a set of clauses or sentence ( 12 ) The King was in the counting house , counting out his money. The Queen was in the parlor , eating bread and honey. The actions in ( 12 ) . are set in different rooms , but of .the same 11 palace '' . ( 13 ) After Richard talked to the reporter , he went to lunch. The temporal sequence of events in ( 13 ) is expressed by `` after '' . ( 14 ) John eats garlic. Martha avoids him* To nun-aficionados garlic is known anly f.or its aroma , detection of which causes evasive '~c tion. Cat~sc , illustrated in ( 14 ) , is an important discourse connective ( Schank , 1975b ) . Ttle importance is perhaps ethnocentric ; in other cultures different positions may have to be taken , for mcain~le. n teleogical world view ( khi te , 1975 ) . The causal chaYn of propositions in discourse is termed its plot structure. Thematicity Coherent discourse is expected to have a theme , to have a topic* tor example ( 15 ) DF drowned today in IlB resevoir after restuing his son who had fallen into the water while on a fishing trip. is a news story 6rom the New York Times with a theme that I will call t t tragedy '' . In this section I wish to justify the claim that a thematic structure condition is universal by examining different exarnrles and analyses of general discourse for evidertce. The notion of theme is much used but not often defined with clar'ity. It is variously stated to be `` The subject of discourse . . a topic1 ' ( Oxford English Dictionary ) ; `` the playwright 's point of view towards his material1 ' ( Elabley , 1972 , p. 14 ) , etc. In Abelson ( 1973 ) there is a list of themes ( admitted to be neither fixed nor exhaustive ) : admiration , devotion , appreciation , cooperation , love , alienation , betrayal , victory , dominance , rebellion , mutual antagonism , opposition , and conflict . Occasionally one finds overt comment pn the lack of a thege : `` The thing that puzzled me most about The Last Remake of Beau Geste was its lack of a point of view '' ( Barry -- Took , `` cinema '' pPunch , December 7 , 1977 ) . Equally Infrequently one can find a succinct amplification of the structure of a thehe : `` On the other hand , the suspension of disbelief is what thrillers are about. It ( Sheridan Horlqy , heatre re '' 8Punch , November 19 , 1975 ) . A theme may be explicitly stated in discourse. In technical writing it is quite usual to express a complete definition , def iniendum-def iniens : Kuhn ( 1 962 ) defines `` paradigm '' as an `` achievement '' that is `` sufficiently unprecedented ta attract an enduring group of adherents away from competing scientific activity [ and ] sufficiently open ended to leave all sorts of problems for the redefined group of practioners to resolve '' ( p. 10 ) . Much of the rest of the book then discusses paradigms as models for sclen tific revolut &amp; ons. If a discourse has an implicit theme , it has to be inferred by the reader. An author , therefore , should use themes that are know to the reader . One possibilty is that there is only a finite number of themes. But lacking evidence for this positfon , I will hypothesise that the number of themes may be unlimited in the same way that the vocabulary of a language is open. A reader may not know a word that is used by an author ; in a similar fashion he may not recognize a theme. There are studies that indicate the existence of abstract themes in language. In folk-tales , Propp ( 1968 ) analyses a render 's expectancies about the structure of the tale. Propp starts by comparing the followin8 events from different tales : eagle carries the hero away to another kingdom* a from otrt of the ring carry Ivan into another kingdom. Propp infers that `` a tale often attributes identical actions to varhus personages. This makes possible the study of the folk tale according td the functions of the dramatis personae '' ( pa 20 ) . Falk tales are analysed in terms of Eunct'ions. The above examples are described as It con'taining two functions : `` Aquisi tion of a magical agent '' and Transference to a designated place '' . An example of Propp s analysis is ( 22 ) ACTION A tsar , three daughters. The daughters go walking , overstay in the garden. A dragon kidnaps them . A call for aid. Quest of the three heroes. Thxee battles with the dragon. Rescue of the mazdens. Return. WedcFing. FUNCTION INITIAL SITUATION AB SENTATION VIOLATION VILLAINY PlEDIATION CONSENT ' TO COUNTERACTION DEPARTURF STRUGGLE VICTORY IN IT IAL MISPORTUNE LIQUIDATED RETURN WEDDING ( p* 128 ) Functions correspond to metali , ngually defined concepts of the encyclopedia. Propp show that thi.s genre 01 discourse can be analysed as an ordered string of abstract concepts. -4 8Linde ( 1974 ) finds that there is a prescribed pattern in verbal descriptions of apartments. Only two discourse strategies are used by her subjects to express the spatial structures , and of these , one is considerably more frequent than the other : There are at least two logical possibilities for . . . [ the overall description of apartment layouts ] . . the speaker may describe a map of the apartment. or he may describe a tour of it. Fxmples of each are the following : I 'd say it 's laid out in a huge square pattern , broken down into four units. If you were looking down at this apartment from a height , it would be like . . . like I said before , a huge square with two lines drawn through the center to make four smaller squares. Now on the ends . . uh . . . in the two boxes facing out on the street you have the living room and a bedroom. In between thC ? se two boxes youhavea bathroom. Now between the next two boxes , facing the courtyard you have a small foyer and then two boxes , one of which is a bedroom and the other of which is a kitchen and a small foyer a . . . a little beyond that. Well you walk in the door and there 's a kitchen and then off the kitchen is one bedroom. As you go straieht in from the doorway throught the kitchen you go into the living room. And then to the left of the living room aye two bedrooms. The two bedrooms are on the same side of the building and the living room and the kitchen are on the same side of the building. Both of these descriptions are reasonable agsyers to the question `` would you describe the lgyout of your apartment ? '' Our intuition certainly informs us that both speakers have fulfilled cne task that was proposed them. What our intuitions do not tell us is that descriptions like [ the first ] are extremely rare , while descriptions like [ the second ] are extremely common. Of 72 apartment descriptions , only 3 are of the form of a map . . * while 69 are the form of a tour ( pp , 8-9 ) The tour may be a composition of separate episodic events of moving between rooms of the apartment . The plan is more obviously systemic , involving spatial ( left , right , e tc * ) and comnonential ( part-whole ) organiea tion. Longacre ( 1968 ) notes that in a given language there is a finite number of discourse types which can never be mixed or confused. Discourse from various Philippine languages suggest four contrasting discourse prose genres : Narrative : recounts some sort of stofy Procedural : tells how to do something. Expository : any sort of explanatory essay. Hortatory : attempts to influence or to change conduct* Narrative discourse is composed of the following tagmemes : APERTURE provides temporal and spatial setting and introduces some of the principal dramatis personae. CLOSURE gives final commentary on the main participants , `` they lived happily ever after '' . Nuclear tagmemes EPISODE , DENOUEMENT , anti ANTIDENOUEEIENT show a great variety of exponence * . typically any paragraph type may be an exponent plus embedded drscourse of the PROCEDURAL or EXPOSITORY genre. A correspondence can be informally recognized between some of It Propp 's functions and Longacre 's tagmemes. For example , between Initial Situation1 ' and `` ~~er ture '' , and `` Reward '' and losu sure '' . For Propp the peak of the discourse is in the function `` Initial PIisfortune Liquidated '' , and for Longacre it is in the tagmeme `` Anti-Denouement '' e The idea of a hierarkhic orkanization of tagmemes mentioned by Longacre , above , is paralleled in Lakof f 's ( 1992 ) transf : ormational generative nodel that uses Propp 's set of functions. A phrase struc11 ture component generates a deep structure '' . For example , the tale of ( 22 ) may be represented by the tree stxuc ture of Figure 17. -50SITUATION REUARD S~N QUEST RESCUE CALL FOR AID RELEASE MEDIATION CW~ERDEPARTURE STRUGGLE VICTORY MI SFORTUNE RETURN WEDDING ACTION ilaimm Figure 17 Textual deep structure The conclusion is that there are prescibed patterns in all genres of discourse ; I term these patterns `` themes '' . I do not offer a complete inventory of themes ; their discovery is a matter of empirical investigation Any extended discourse is unlikely to be organized according to a single theme* I hypothesise that a coherent aiscourse is characterized by a single rooted tree of themes , as schematized in Figure 17. All themes must be proper subthemes of the matrix theme. A text with an overlapping thematic structure is incoherent : ( 23 ) Eating fish made John sick. He caught measles last May* -51shown schematically in Figure 18. John eat a Jd h n 's poisoning 4 ' n John 's illnesses John alck John he8 meaales Figure 18 Incoherent thematic structure An important point to conclude this section. The inferred connections may not correspond with those intended by the author. Thi~ is another problem. Here I only address the analysis of a story by a reader. If he connects it in the manner described above , then it is coherent for him. The Rqle of the Encyclopedia -- -Not all of discourse structure is overtly stated ; discourse is highly elliptic . In ( 1 3 ) tha discourse connective `` sf ter '' is present to mark a temporal sequence , but in ( 14 ) there is no realizati~n of the causal relation between the two prapositions. Normally one assumes that a discourse is coherent ; hence ( 12 ) is most acceptable if the rooms are taken within the same habitation. Evidently a reader must infer omitted structure. The inferences are made from his cognitive store of world knowledge. There is much discussion at present about inference as part of understanding. To make inferences is easy ; the problem is to make the right ones. It helps to have a goal. It is suggested that discourse can be said to have been undetstood when it has been judged coherent , as defined above. In the next sections are presented the role of the encyclopedia in determining and representing the dimensions of coherence spelled out above. Anaphora If the dependent is a proform then part of understanding is to determine the correct antecedent . There are syntactic constraints ( Langacker , 1969 ) which serve to narrow down choices for antecedents and to give an order of preference. Winograd ( 1971 ) also established an ordering for the choice of antecedents. Nash-Webber ( 1976 ) used lambda abstraction to establish possible antecedents The chosen antecedent , when substituted for the proform , must produce a meaningful proposition that is coherent in context. A meaningful proposition is 1 one that has a counterpart in the encyclopedia. Wilks ( 1975 ) discusses a method of finding the most semantically acceptable antecedent. In encycloped~c terms , the counterpart may be the self-same proposition , o ? , more likely , a systemic proposition. The process of finding such a proposition has been described earlier. If no generalization is found , the input proposition is not consistent with encyclopedic knowledge. Abstract terms can be defined by complexes of general propositions , each having sufficient conceptual content to define situations in which they apply. For example , a definition of `` mistake '' must be such thar it applies to part of the first sentence in ( 11 1. The process of abstraction needed here was presented above. Spatial , Temporal , and Causal Cohesion To in£ er omitted spa tiotemporal and causal relations , i .e . , the discursive relations of the encyclopedia , it is also necessary to locate general propositions. Systemic memory , of course , includes these relations. Schematically , Figure 19 , from a discourse proposition PI we can locate P2 , by the means already described. P2 may have a discursive relatlon R to another systemic proposition P3. A proposition Pq , a particularized version of P3 , and the relation R , 'between P2 and P3 , can be added to the discourse. Of ten Pq will be a proposition already stated in the discourse , then merely the relation need be inferred co augment the plot structure. R P2 * ENCYCLOPEDIA R P1 P4 DISCOURSE Figure 19 inference of discursive structure It may may , however , be necessary to infer a chain of propositionn to link the propositions of the original discourse Intuitively there must be a limit on the number of propositions that can be inferred in a sensible path , but at present no % might can be offered. To exemplify the process in greater detail , let us consider some of the knowledge that is used in the analysis of ( 15 ) : `` In water and not ah1 e to act causes drowning '' . In Figure 20 the network form of this knowledge is presented. Figure 20 Example of causal inference Prom the discourse propositions `` DF in watert ' and `` DF can not act '' , paradigmatic structure enables the systemic propositions A and B to be found. mere is e coreferentiality condition that must be tested in the manner described earlier . The discourse propositions pass the test , so the complex represented by the modality C exists in the discourse. Ttle discursive relation cause can be followed from C to D. The latter is a pla~isible inference , and in fact , o specific equivolerlt of D is one of the original propositions of the discourse , i.em , `` DF drom '' . The concepts of the sys.temic propositions .ire linked to thcr rest of the encyclopedia by typical orLsm It is so because of the nature of the hnowledge. is such that it is only son~ething that could happen in the given c ircun~stanc es . The indications from the testing of Thorndyke ( 1976 ) are that. ~nierences are a psychological reality in understanding natural language texts. Thematicity In , the present system , a thematic concept is defined structurally , it is anything having a metalingual definition* 1\ theme is theretore a complex of generalized propositions. The process of detecting the apgllcability of abstract terms , and hence of finding themes , is abstrac tion , described above. Abstraction is a recursive process and IS thus one way to capture the embedding of themes hypothesised to exist in discourse. The paraphrases ellcited by Pfandler , Johnson , and DeForest ( 1'976 and Rumelhart ( 1976 ) show that subjects do create descriptions of texts that vary in abstractness in accord with the hierarchy of themes proposed here. IMPLEMENTATION In thiq section the imple~nentation of the structures and processes presented above is described* The original program was written in SNOBOL for a CDC6400. In a complete system there should , of course , be a parser. For the present this does not exist ; the system only embodies the cognitive component. This means that the overall organization is not as it would be in a complete text analysis system , where interaction between the syptac tic and semantic components is essential ( Woods , 1971 ; Schank , 1975a ; Winograd , 1971 ; Erdman , 1975 ) The justification for this ommission is that for the present I am seeking to establish only the nature of the semantic organization of a coherent discourse. Once this structure has been identified it will provide the goal for a complete systernInput to the spcern is accordingly in a cognipive form that retains the logital ellipsis of the surface form. Most of the processin8 is performed by `` Nonnalizer '' which infers omitted logical and thema~ic structure. A judgement of coherence is then a simple task : if the discourse is not logically connected or does not have a single theme , then it is incoherent ; otherwise the matrix theme indEcates the topic of the discourse. Processes A component of all processes is a breadth first path-tracing routine , called `` Ripple '' . A search path is defined by a sequence of arc types A path does not explicitly state whether an arc can be repeated. The network is assumed to be syntactically well-formed and this controls repetitions. An arc can be marked as obligatory ; otherwise it is optional. A goal of the search can be defined. This may be a particular node , or a node marked with a specified `` activation tag '' , i .e. , a node reached by another path , when seeking an intersection. Paradipiatic path , -tracinq Paradigmatic path-tracing is implemented by Ripple with a path sequence VAR IST TYP MAN ( see Figure 11 ) . A converse paradigmatic path -- -is 'EfAN TYP IST VAR. The properties associated with a varietal concept may be found by Ripple with a path TYP MAN starting from the concept. Causal connectivity condition This process uses Ripple with cause as the path definition* It also has to include P-W arid P-W to be able to reach from and to conj unc ts. Discovery of gener a1 and spec if ic propo si ti ons All propositions of a discourse must match general propositions in the encyclopedia. The procedure is to make cyclic calls of Ripple. The first is from the modality node of the discourse proposition. Each node reached , other than the modality , initiates another search in the encyclopedia. For example , given the discourse and encyclopedia of Figure 12 , the process is as follows : from `` gobblef ' node 1 , a converse paradigmatic path plus a typical arc plus manifestation ia followed to , for example , node 2 in the encyclopedia. Ripplipg from `` gobble '' in the If discourse gives nodes `` Marv '' and caviar '' . The syntagmatic arcs traversed are noted. From `` Marv '' , node A , a converse paradigmatic path plus typical plus manifestation plus converse agent is followed , with a goal of a node activated from the prior discourse node , i ~e. , `` gobble '' . [ Not all of these arcs have to be present , they are optional except £0 , tt the syntagmatic arc. ] Node 2 satisfies this goal. From caviar '' node B , a converse paradigmatic path plus typical plus manifestation plus converse objective is followed with a g~al of a node activated from the prior discourse node `` gobbleff* Again node 2 satisfies the goal. Thus the proposition at 2 is a generalization of tihe discourse proposition. The condition on an acceptable generalized match is that it must contain all the syntagmatic informirtion of the discourse proposition , ; the generalizatdon may contain more information but it can not contain less Separate searches are made for syntagmetic structure and for spa tio-temporal information on the modality of a proposition. It is only necessary to change the path description from that used in Figure 12 from converse paradigmatic path to paradigmatic path for the routine to local e more specific propositions. kietalingual decomposition The search for general propositions also flags nodes that have metalingual definitions. New propositions having the structure of the definiens are made by copying the definiens but with node names drawn from the proposition that is being paraphrased These new propositions are then considered as part of the discourse. To make the copy , the bresdth first search routine is used to pass through the definiens. For each ode and arc in the definition , an equivalent structure is created The end of scanning a proposition of the definiens is marked by reaching a typical arc , i.e. , at the point at which the definition is linked into paradigmatic organization. If a participant in the generalized proposition matches a participant in the discourse proposition then this participant fits into the corresponding role slot in the definiendum , otherwise the concept in the definiendm is used. For example , given `` Peter buys a bicycle from Jane '' and the definition of `` buy '' as in rigure 16. In locating the systemic definiendm , the correspondences of `` ~eter '' to `` A '' , etc . , are also found. When copying reaches the node that matched `` peter '' , this name is inserted into the t 1 paraphrase. There is no correspondence for the instrument , so money '' 1s the inserted from the definiiendum , MetaLin~ual abstraction In searching for general propositions , some may be found that are components of metalingual definitions. These have modalities that are pdinted to by a part-whole arc. -60The proqess that tests coreference and contextual requirements uses Ripple to traverse in parallel the candidate discourse propositions and those of the definiens. Typical arcs in the definiens limit the search. Each node of the definiens is compared with equivalent nodes in the discourse propositions at each step. A proposition is rejected if a node has no equivalent or it does not possess all the properties of the nodes of the definiens , including arcs to nodes matched in the previous step , See. , if nodes x ( systemic ) and Y ( discourse ) were taken as corresponding nodes at one step , then if on the next step a node of the definition has an arc to X then the discourse must have the same arc to Ya Only those propositions that match the definiens will not have been rejected and can be rewritten using the abstrwt term. The process can -be illustrated using the definition of `` poison '' given in Figure 14b , and its application to the discourse in Figure 14a. The crux of the test is at that node of the definition having the two manifestations arcs emanating from it* If the discourse proposition did not have two manifestations it would be rejected This is how `` John 's eating the worms made Fred sick '' is eliminated* Or if it does have two manifestations , they must point to nodes that were satisfied Qn the previous step of the comparison. Thus if one of the manifestations pointed into another proposition the test would fail. Inference I of omitted discursive relations A search along discursive arcs in systemic memory from counterparts of discourse propositions may lend to a proposition that is flagged as a generaliz~tion of another discourse proposl tion. If this is so then the discusive arc may be added between the discourse propositions. If the proposition reached is not flagged then it and the discursive arc are copied , and added to the discourse. Ttle copying routine was given in the discussion of decomposition. The System The flow chart of the analysts fs shown in Figure 21. The meanings of the annotations are : OLDINFO has a discourse proposition as its argument. It finds systemic equivalents. It calls a routine SPACETIME to cornpare spatio-temporal contexts. SPACETLME is also called during the search for general propositions when a non-event node is found with an attached modality. If OLDINFO is presented with a modality that has only part-whole relations ta other nodes , it does nothing. LOGCON has a systemic proposition as its argumfnt. It succeeds if it finds d link to a general proposition corresponding to a proposition of the discourse ( including propositions added by inference ) . It also generates INTERLIST , a list of causal inferences from propositions of the discourse. IKST is a list of nodes found to have metalingual definitions. CONJLIST is a list of conjoined propositions. When a discourse proposition is matched against the encyclopedia , it sees if the encycl opedic proposition is a constituent of another modality. A CONJUNCTION TEST routine uses CONJLIST to locate discourse propositions that can be grouped. TRANSFORM has two modes . In one it is used to decompose propositions that contain a metalingually defiries concept* A second mode c eates causally inferred propositions . / \ / I \ Y 'C / / \ / \ CONJUNCTION \ Figure 21 Flow chart of the system nNALYSIS OF SOME STORIES I want to show that abstract patterns are quite general , that all linguistic behavior is based on such patterns. Obviously such a claim must be substantiated by the discovery of such patterns. A number of stories of drowning were used to test this hypothesis. The second claim of proper embedding , of themes was also tested by a more complex drowning story. In the examples a refined hypo thesis of discourse connectedness is used. One habit in discourse is to set the stage ( kropp 's `` Initial Situation '' , ~on~acre 's `` Aperture '' ) . In terms of the model thin aspect should be recognizable by the occurrence of space and time relations. ? I We find todayf ' , `` in MB resevoir '' , `` On October 11 , 1974 '' . `` DF of Quekns '' , etc. A greater stru~tural complexity of expression is to be expected elsewhere in the stories ( see Longacre 's comments on nuclear tagmemes , above ) . Longacre ( 1972 ) includes in the nmural outline of a discourse , recognition of a peak within the discourse. Various surface markings for the peak are given : tense change , extra long sentences , rhetorical underlinings , etc. Taking an ethnocentric view of the world ( cf. White 's teleogical commune ) , it is suggested that In the underlying form , the peak will lie within causally related propositions. It is thus expected to find the theme within the causal structure and so I focus on this organization. This would be inappropriate if the stories were aescriptions of the kind elicited by Linde , above. Common patterns Shart factual accounts of drowning8 were elicited from freshmen fn Linguistics and English. The instructions given sought only to define a topic and an approleimate length : `` Write a drowning story that , for example , you might expect to find as a column filler in the New York Times. '' A sample is ( Story 1 ) The body of Horatio Smith was found last night in the Niagar a River He was drowned when his boat overturned on the river . The hypothesis formed is that an acceptable drowning story must give the following information : ( a ) Why the victim was in the water. ( b ) Why the victim was not able to save himself The rationales for these requisites are : ( c ) A person is not usually found in water , and therefore some explanation of this location is expected. ( d ) By an instinct of self-preservation , one would expect the victim to try to extricate himself from his predicament. The story should say why he couldn't. Figure 22 shows the cognitive form of this requirement. MTL @ &lt; drowning CAUSE E CAUSE 1 CAUSE Idrow act 1 &lt; person &gt; Figure 22 The drowning theme The empty modalities indicate that a matching story must have something that stand in a causal relationship to the other propositions , Lee , explain why they happened ( what caused them ) If not originally explicit , this information must be recoverable through encyclopedic knowledge .</sentence>
				<definiendum id="0">; their discovery</definiendum>
				<definiens id="0">the informa &lt; ion for paraphrases between the two abstract terms as well as for decomposition and abstraction* There is no productive relationship between the roles of the same participant at different Levels of abstraction. Case relations represent only the causal/animate perception of participation in an event. More detailed descriptions of the roles of participants can only be If given in context. For example , money '' is perceived as instrumental in `` buytt , but at the next level of decomposition , it is in an objectiue role in `` give '' . The outputs of both abstractton and decomposition are structurally indistinguishable from any other proposition in the encyclopedia and therefore can again be subject to either of the processes. As patternmatching is a recursive process this ability for output of the process to be accepted as input is essential. The distinction between path-tracing and pattern-matching processes may be psychologically significant Inhelder and Piaget ( 1 964 ) find that prepuberty children can not use logical equations such as - ( A AB ) 3 -A V -Be The equations involve cgreference and hence their application requires a pattern-matching process . It could be speculated that this more powerful process only appear &amp; at maturation. DISCOURSE ANALYS IS The Structure of Coherent Discourse In this section the hypothesrs concerning the kinds of organization present in coherent discourse is outlined. A fuller description can be found elsewhere ( Phillips , 1975 ) . The role of the encyclopedia in discourse is then exemplified. A discourse is judged coherent if its constituent propositions are connected . Various types of cohesive links are observed in discourse : anaphoric , spatial , temporal , causal , and thematic. I will formally describe the structure of a well-formed discourse in terms of these connect vesL Anaphora A discourse has reference to objects. Coherence is given by repetition of the reference. Two kinds of anaphora can be distinguished. The first is marked by the presence of a proform ( or by repetition of the fonn ) : [ It is usual for coherent d.lscourse to exhibit several kinds of cohe'sive links . Thus the examples invariably contain more than the one specifically being illustrated. ] ( 10 ) Henry travels too much. He is getting a foreign accent. Antecedents may bm nominal , verbal , or clausal</definiens>
				<definiens id="1">an abstract term for the antecedent. for example I1 ( 11 ) John put the car into reverse</definiens>
				<definiens id="2">an abstract characterization of the gear selection expressed in the first sentence. Nagao anti Tsujii ( 1976 ) address this issue. A conventi-onal way to label the recurring characters in discourse t f is as dramatis personaetf. Ifowever , cohesion can result not only from multiple appearances of people ( lo ) , but of any concept , as in ( 11 ) . Spatial , Temporal , and Causal Cohesion Space , time , and cause give coherence to a set of clauses or sentence ( 12 ) The King was in the counting house , counting out his money. The Queen was in the parlor , eating bread and honey. The actions in ( 12 ) . are set in different rooms , but of .the same 11 palace '' . ( 13 ) After Richard talked to the reporter , he went to lunch. The temporal sequence of events in ( 13 ) is expressed by `` after '' . ( 14 ) John eats garlic. Martha avoids him* To nun-aficionados garlic is known anly f.or its aroma , detection of which causes evasive '~c tion. Cat~sc , illustrated in ( 14 ) , is an important discourse connective ( Schank , 1975b ) . Ttle importance is perhaps ethnocentric ; in other cultures different positions may have to be taken , for mcain~le. n teleogical world view ( khi te , 1975 ) . The causal chaYn of propositions in discourse is termed its plot structure. Thematicity Coherent discourse is expected to have a theme , to have a topic* tor example ( 15 ) DF drowned today in IlB resevoir after restuing his son who had fallen into the water while on a fishing trip. is a news story 6rom the New York Times with a theme that I will call t t tragedy ''</definiens>
				<definiens id="3">universal by examining different exarnrles and analyses of general discourse for evidertce. The notion of theme is much used but not often defined with clar'ity. It is variously stated to be `` The subject of discourse . . a topic1 ' ( Oxford English Dictionary ) ; `` the playwright 's point of view towards his material1 ' ( Elabley , 1972 , p. 14 ) , etc. In Abelson ( 1973 ) there is a list of themes ( admitted to be neither fixed nor exhaustive ) : admiration , devotion , appreciation , cooperation , love , alienation , betrayal , victory , dominance , rebellion , mutual antagonism , opposition , and conflict . Occasionally one finds overt comment pn the lack of a thege : `` The thing that puzzled me most about The Last Remake of Beau Geste was its lack of a point of view '' ( Barry -- Took , `` cinema '' pPunch , December 7 , 1977 ) . Equally Infrequently one can find a succinct amplification of the structure of a thehe : `` On the other hand , the suspension of disbelief is what thrillers are about. It ( Sheridan Horlqy , heatre re '' 8Punch , November 19 , 1975 ) . A theme may be explicitly stated in discourse. In technical writing it is quite usual to express a complete definition , def iniendum-def iniens : Kuhn ( 1 962 ) defines `` paradigm '' as an `` achievement '' that is `` sufficiently unprecedented ta attract an enduring group of adherents away from competing scientific activity [ and ] sufficiently open ended to leave all sorts of problems for the redefined group of practioners to resolve '' ( p. 10 ) . Much of the rest of the book then discusses paradigms as models for sclen tific revolut &amp; ons. If a discourse has an implicit theme , it has to be inferred by the reader. An author</definiens>
				<definiens id="4">the number of themes may be unlimited in the same way that the vocabulary of a language is open. A reader may not know a word that is used by an author ; in a similar fashion he may not recognize a theme. There are studies that indicate the existence of abstract themes in language. In folk-tales , Propp ( 1968 ) analyses a render 's expectancies about the structure of the tale. Propp starts by comparing the followin8 events from different tales : eagle carries the hero away to another kingdom* a from otrt of the ring carry Ivan into another kingdom. Propp infers that `` a tale often attributes identical actions to varhus personages. This makes possible the study of the folk tale according td the functions of the dramatis personae '' ( pa 20 ) . Falk tales are analysed in terms of Eunct'ions. The above examples are described as It con'taining two functions : `` Aquisi tion of a magical agent '' and Transference to a designated place '' . An example of Propp s analysis is ( 22 ) ACTION A tsar , three daughters. The daughters go walking , overstay in the garden. A dragon kidnaps them . A call for aid. Quest of the three heroes. Thxee battles with the dragon. Rescue of the mazdens. Return. WedcFing. FUNCTION INITIAL SITUATION AB SENTATION VIOLATION VILLAINY PlEDIATION CONSENT ' TO COUNTERACTION DEPARTURF STRUGGLE VICTORY IN IT IAL MISPORTUNE LIQUIDATED RETURN WEDDING ( p* 128 ) Functions correspond to metali , ngually defined concepts of the encyclopedia. Propp show that thi.s genre 01 discourse can be analysed as an ordered string of abstract concepts. -4 8Linde ( 1974 ) finds that there is a prescribed pattern in verbal descriptions of apartments. Only two discourse strategies are used by her subjects to express the spatial structures</definiens>
				<definiens id="5">the speaker may describe a map of the apartment. or he may describe a tour of it. Fxmples of each are the following : I 'd say it 's laid out in a huge square pattern</definiens>
				<definiens id="6">a huge square with two lines drawn through the center to make four smaller squares. Now on the ends . . uh . . . in the two boxes facing out on the street you have the living room and a bedroom. In between thC ? se two boxes youhavea bathroom. Now between the next two boxes , facing the courtyard you have a small foyer and then two boxes , one of which is a bedroom and the other of which is a kitchen and a small foyer a . . . a little beyond that. Well you walk in the door and there 's a kitchen and then off the kitchen is one bedroom. As you go straieht in from the doorway throught the kitchen you go into the living room. And then to the left of the living room aye two bedrooms. The two bedrooms are on the same side of the building and the living room and the kitchen are on the same side of the building. Both of these descriptions are reasonable agsyers to the question `` would you describe the lgyout of your apartment ? '' Our intuition certainly informs us that both speakers have fulfilled cne task that was proposed them. What our intuitions do not tell us is that descriptions like [ the first ] are extremely rare , while descriptions like [ the second ] are extremely common. Of 72 apartment descriptions , only 3 are of the form of a map . . * while 69 are the form of a tour ( pp , 8-9 ) The tour may be a composition of separate episodic events of moving between rooms of the apartment . The plan is more obviously systemic , involving spatial ( left , right , e tc * ) and comnonential ( part-whole ) organiea tion. Longacre ( 1968 ) notes that in a given language there is a finite number of discourse types which can never be mixed or confused. Discourse from various Philippine languages suggest four contrasting discourse prose genres : Narrative : recounts some sort of stofy Procedural : tells how to do something. Expository : any sort of explanatory essay. Hortatory : attempts to influence or to change conduct* Narrative discourse is composed of the following tagmemes : APERTURE provides temporal and spatial setting and introduces some of the principal dramatis personae. CLOSURE gives final commentary on the main participants , `` they lived happily ever after '' . Nuclear tagmemes EPISODE , DENOUEMENT , anti ANTIDENOUEEIENT show a great variety of exponence * . typically any paragraph type may be an exponent plus embedded drscourse of the PROCEDURAL or EXPOSITORY genre. A correspondence can be informally recognized between some of It Propp 's functions and Longacre 's tagmemes. For example , between Initial Situation1 ' and `` ~~er ture '' , and `` Reward '' and losu sure '' . For Propp the peak of the discourse is in the function `` Initial PIisfortune Liquidated '' , and for Longacre it is in the tagmeme `` Anti-Denouement '' e The idea of a hierarkhic orkanization of tagmemes mentioned by Longacre , above , is paralleled in Lakof f 's ( 1992 ) transf : ormational generative nodel that uses Propp 's set of functions. A phrase struc11 ture component generates a deep structure '' . For example , the tale of ( 22 ) may be represented by the tree stxuc ture of Figure 17. -50SITUATION REUARD S~N QUEST RESCUE CALL FOR AID RELEASE MEDIATION CW~ERDEPARTURE STRUGGLE VICTORY MI SFORTUNE RETURN WEDDING ACTION ilaimm Figure 17 Textual deep structure The conclusion is that there are prescibed patterns in all genres of discourse ; I term these patterns `` themes '' . I do not offer a complete inventory of themes</definiens>
			</definition>
			<definition id="7">
				<sentence>The theme `` tragedy '' fits , the rescue is a ( partial ) cause of the demisem Rescue is a variety of act and good can apply to it and Brown is a variety of die .</sentence>
				<definiendum id="0">Rescue</definiendum>
				<definiendum id="1">Brown</definiendum>
				<definiens id="0">a variety of act and good can apply to it and</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>A 6 recent paper ( CalZins , mrnock and Passafime ) discusses a technique for combining protocol analysis with program synthesis as applied to tutorial dialogues .</sentence>
				<definiendum id="0">Passafime )</definiendum>
				<definiens id="0">discusses a technique for combining protocol analysis with program synthesis as applied to tutorial dialogues</definiens>
			</definition>
			<definition id="1">
				<sentence>There are many observable things people do that we do not how how to simulate , Semantics .1x1 this section we will discuss , very briefly , same pertinent aspects of SCBO a mixed-initiative instructional system .</sentence>
				<definiendum id="0">SCBO</definiendum>
				<definiens id="0">a mixed-initiative instructional system</definiens>
			</definition>
			<definition id="2">
				<sentence>SCHOLAR s knowledge about any subject matter is in the form of a static semantic network of facts , concepts , and procedures .</sentence>
				<definiendum id="0">SCHOLAR</definiendum>
				<definiens id="0">s knowledge about any subject matter is in the form of a static semantic network of facts , concepts , and procedures</definiens>
			</definition>
			<definition id="3">
				<sentence>Attributes are usually English words , but there is a set of special attributes for i rtant relations , like SUPERC ( for superconcept or superardinate , e.g. , Lima is a city and a capf tal ) , SUPERP ( for superpart , e.g. , Lima ia a part of Peru and South ~merica ) , SUPERA ( for superattribute , e , g , , fertile refers to soil and soil refers to topagraphy ) , APPLIEDFO ( color applies to things , *PROBABLY SPANISH* `` TELL ME SOFIETHING ABOUT PERU* PERU IS A COUNTRY , IT IS IN WESTERN SOUTH RSCCA w IT IS ON THE COAST OF THE PACIFIC , THE ITRL IS L a THE MOUNTAINS ARE W OUS .</sentence>
				<definiendum id="0">Attributes</definiendum>
				<definiendum id="1">Lima</definiendum>
				<definiens id="0">a city and a capf tal )</definiens>
			</definition>
			<definition id="4">
				<sentence>Somawhat related to incompleteness and relevancy is the eference problem ( see Olsonl ' ) Referring to a colleague , we nay 'define8 him as the father of Jack and Jill , or the author of that paper on self-referential otatments , or tihe tall thin fellufth glasses .</sentence>
				<definiendum id="0">relevancy</definiendum>
				<definiens id="0">the father of Jack and Jill , or the author of that paper on self-referential otatments , or tihe tall thin fellufth glasses</definiens>
			</definition>
			<definition id="5">
				<sentence>ystam ( Hoods ) , a blocks world ( Winograd F , or a lunar rocks catalogue ( Woods , Kaplan , and ~ash-~e~erl~ ) , there is a closed aet of objects , attributes , and rmluel~ to deal with .</sentence>
				<definiendum id="0">ystam ( Hoods</definiendum>
				<definiendum id="1">~ash-~e~erl~</definiendum>
				<definiens id="0">a blocks world ( Winograd F , or a lunar rocks catalogue ( Woods , Kaplan , and</definiens>
				<definiens id="1">a closed aet of objects , attributes , and rmluel~ to deal with</definiens>
			</definition>
			<definition id="6">
				<sentence>Functional knowledge , which includes knowledge about functional determinants and their intgractions , ie learned , just as is factual knowledge , and therefore is stored in SCHOLAR 'S data base under concept8 such as climate or agricultural products .</sentence>
				<definiendum id="0">Functional knowledge</definiendum>
				<definiens id="0">includes knowledge about functional determinants and their intgractions</definiens>
				<definiens id="1">factual knowledge , and therefore is stored in SCHOLAR 'S data base under concept8 such as climate or agricultural products</definiens>
			</definition>
			<definition id="7">
				<sentence>B. Raphael , *SIR : A Computer Program for Semantic Information Retrievaln in M. L. Minsky ( Ed. )</sentence>
				<definiendum id="0">*SIR</definiendum>
				<definiendum id="1">Minsky</definiendum>
				<definiens id="0">A Computer Program for Semantic Information Retrievaln in M. L.</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>The ATEF system analyzes the words and thus employs dictionaries A dictionary is a set of segments ( character strings ) , ~th each of which is associated a label , a processing pointer , and a lexical unit pointer .</sentence>
				<definiendum id="0">ATEF system</definiendum>
				<definiens id="0">analyzes the words and thus employs dictionaries A dictionary is a set of segments ( character strings ) , ~th each of which is associated a label , a processing pointer</definiens>
			</definition>
			<definition id="1">
				<sentence>p -A fi , A &gt; * solution 1 I solution &amp; phrase I ph~ase I phrase p phrase p The solution for a sentence ( ~hrase ) consists of a string of labels ( one for each word of the sentence ) , each of which represents an interpretation of a ward of this sentence .</sentence>
				<definiendum id="0">p -A fi</definiendum>
				<definiens id="0">A &gt; * solution 1 I solution &amp; phrase I ph~ase I phrase p phrase p The solution for a sentence ( ~hrase ) consists of a string of labels ( one for each word of the sentence ) , each of which represents an interpretation of a ward of this sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>listics CONCEPTUAL ANALYSIS INVENTORY AND ANALYSIS OF TERMINOLOGY IN POLITICAL SCI ENCE Box 1830 , Station B , Varlderbil t University Nashville , Tennessee 37235 At the 1970 International Political Science Associatio~ Congress in Munich , the first informal meeting was held of what became Research Cornittee Number One of the Association , the Committee on Conceptual and Tem~nological Analysis ( COCTA ) This committee ( which includes political scient ists , sociologists , anthropologists , linguists , and philosophers ) has been moving toward several objectives of concept clarification in political and social analysis .</sentence>
				<definiendum id="0">CONCEPTUAL ANALYSIS INVENTORY AND ANALYSIS OF TERMINOLOGY IN POLITICAL SCI ENCE Box</definiendum>
				<definiens id="0">the Committee on Conceptual and Tem~nological Analysis ( COCTA ) This committee ( which includes political scient ists , sociologists , anthropologists , linguists , and philosophers</definiens>
			</definition>
			<definition id="3">
				<sentence>FIELD DESCRIPTION OF CONTENTS 1 THE TERM USED BY THE AUTHQR TO REFERENCE A CONCEPT , e.g consensus ' ( IE the term is not English , it shauld be followed by a coma and the closest English translation If the term and definition are in a language other than English , the definition should be followed by an EXACT 3~he UPSIS is a special abstracting and retrieval system of political science articles , books , papers , etc. , published in the United States which are indexed and retrieved by using the American Political Science Association 's Political science Thesaurus , eds .</sentence>
				<definiendum id="0">UPSIS</definiendum>
				<definiens id="0">a special abstracting and retrieval system of political science articles , books , papers</definiens>
			</definition>
			<definition id="4">
				<sentence>Each related concept ( identified by terms ) listed should be preceded by BC , NC , RC , or OC as follows : BC BROADER CONCEPT of which the recorded concept is a less extensive definition NC NARROWER COWCEPT of which the recorded concept is a more extensive definition RC RELATED CONCEPT of which the recorded concept is on the same LEVEL of extension , though different in extension OC OVERUAPPING CONCEPT of which the recorded concept shares extension INDICATOR should be noted simply by entering either ' !</sentence>
				<definiendum id="0">concept</definiendum>
				<definiendum id="1">concept</definiendum>
				<definiens id="0">identified by terms ) listed should be preceded by BC , NC , RC , or OC as follows : BC BROADER CONCEPT of which the recorded</definiens>
				<definiens id="1">a less extensive definition NC NARROWER COWCEPT of which the recorded</definiens>
			</definition>
			<definition id="5">
				<sentence>`` drinkl ' can be thought of as an entity at a template action node , selecting a liquid object , that is to say a formula with FLOW STUFF as its head , to be put at the object node of the template ( sentence structure ) .</sentence>
				<definiendum id="0">drinkl</definiendum>
				<definiens id="0">an entity at a template action node , selecting a liquid object , that is to say a formula with FLOW STUFF as its head , to be put at the object node of the template ( sentence structure )</definiens>
			</definition>
			<definition id="6">
				<sentence>Wilks went on : An interesting and difficult question that then arises is whether those who concentrate on central and less central areas of discourse could , in principle , weld their bodies of inference together in such a way as to create a wider system ; whether , to put the matter another way , natural language is a whole that can be built up fr~m parts .</sentence>
				<definiendum id="0">language</definiendum>
				<definiens id="0">An interesting and difficult question that then arises is whether those who concentrate on central and less central areas of discourse could , in principle , weld their bodies of inference together in such a way as to create a wider system ; whether , to put the matter another way , natural</definiens>
			</definition>
			<definition id="7">
				<sentence>FOPC consists of a+ language for expressing facts and rules for deriving new facts from old .</sentence>
				<definiendum id="0">FOPC</definiendum>
				<definiens id="0">consists of a+ language for expressing facts and rules for deriving new facts from old</definiens>
			</definition>
			<definition id="8">
				<sentence>The language consists of constants , variables , predicates , functions , logical connectives , and quantifiers .</sentence>
				<definiendum id="0">language</definiendum>
				<definiens id="0">consists of constants , variables , predicates , functions , logical connectives , and quantifiers</definiens>
			</definition>
			<definition id="9">
				<sentence>He first puts the predicate calculus representation of the statement into SKOLEM FORM ( a form which has no existential quantifiers and with alluniversal quantlfiers outside 05 the body of the express-ion ) , Any node that is existentially TUTORItAL ON COMPUTATIONAL SEMANTICS 64 quantified but dependent an a universally quantified node is connected to that governing node .</sentence>
				<definiendum id="0">Any node</definiendum>
				<definiens id="0">a form which has no existential quantifiers and with alluniversal quantlfiers outside 05 the body of the express-ion )</definiens>
			</definition>
			<definition id="10">
				<sentence>~ -- -~~ '' -- '' '' -- -- -- -- '' -- -- '' '' '' '' '' i.iiiiii '' iiiiiiiii '' 1 .</sentence>
				<definiendum id="0">i.iiiiii</definiendum>
				<definiens id="0">'' -- '' '' -- -- -- -- '' -- -- '' '' '' '' ''</definiens>
			</definition>
			<definition id="11">
				<sentence>One of the basic usages of formulae conSist 's of naming by formula A some individual object a belonging to some class b of objects such that there exists some noun block Cl ( A ) that names b. For example , i'n the expression 'set R ' the formula *R ' names some individual set belonging to the class of % etsN- .</sentence>
				<definiendum id="0">formula *R</definiendum>
				<definiens id="0">the basic usages of formulae conSist 's of naming by formula A some individual object a belonging to some class b of objects such that there exists some noun block Cl ( A ) that names b. For example , i'n the expression 'set R ' the</definiens>
			</definition>
			<definition id="12">
				<sentence>`` Function LO H ( R ) is defined by* ... ) Here @ H ( R ) @ is an attribute of *Function9 , and @ t9 is an apposition modif-ying the same word .</sentence>
				<definiendum id="0">Function LO H ( R )</definiendum>
				<definiendum id="1">@ t9</definiendum>
				<definiens id="0">an apposition modif-ying the same word</definiens>
			</definition>
			<definition id="13">
				<sentence>The Arnedcan Federation of lnformafion Processing Societies acts on behalf of 15 national organizati~ns engaged in the &amp; sigh and/or application of computers and information processing systems .</sentence>
				<definiendum id="0">Arnedcan Federation of lnformafion Processing Societies</definiendum>
				<definiens id="0">acts on behalf of 15 national organizati~ns engaged in the &amp; sigh and/or application of computers and information processing systems</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>ce is one of the cues to a bundle of infornation known by both hi^ arid the system about scheduling trips .</sentence>
				<definiendum id="0">ce</definiendum>
				<definiens id="0">one of the cues to a bundle of infornation known by both hi^ arid the system about scheduling trips</definiens>
			</definition>
			<definition id="1">
				<sentence>Cause , illustrated in ( 5 ) is an important discourse connective .</sentence>
				<definiendum id="0">Cause</definiendum>
			</definition>
			<definition id="2">
				<sentence>A misleading inference indicates poor writing by the author ; he has misjudged the knowledge of his audience .</sentence>
				<definiendum id="0">misleading inference</definiendum>
			</definition>
			<definition id="3">
				<sentence>In more complicated stories , SAM handles the invocation and closing of parallel , nested and sequential scripts .</sentence>
				<definiendum id="0">SAM</definiendum>
				<definiens id="0">handles the invocation and closing of parallel , nested and sequential scripts</definiens>
			</definition>
			<definition id="4">
				<sentence>Next is a typical boring restaurant story conforming closely to expected scriptal data : Story I1 John went to a restaurant .</sentence>
				<definiendum id="0">Next</definiendum>
				<definiens id="0">a typical boring restaurant story conforming closely to expected scriptal data : Story I1 John went to a restaurant</definiens>
			</definition>
			<definition id="5">
				<sentence>( 5 ) The primitive ACT SDO is an extension of the primitive dummy CD ACT DO , and stands for an actor performing his script for a given situation , in this case the bus script ( $ BUS ) .</sentence>
				<definiendum id="0">bus script</definiendum>
				<definiens id="0">an extension of the primitive dummy CD ACT DO , and stands for an actor performing his script for a given situation</definiens>
			</definition>
			<definition id="6">
				<sentence>The output of the script applier consists of linked story segments , one per script invoked , giving the particular script paths traversed by the input story .</sentence>
				<definiendum id="0">output of the script applier</definiendum>
				<definiens id="0">consists of linked story segments , one per script invoked , giving the particular script paths traversed by the input story</definiens>
			</definition>
			<definition id="7">
				<sentence>Events are the basic building blocks of the conceptual description , and our events indicate the motion .</sentence>
				<definiendum id="0">Events</definiendum>
				<definiens id="0">the basic building blocks of the conceptual description</definiens>
			</definition>
			<definition id="8">
				<sentence>WESTWARD ACROSS , AGAINST , ALONG , APART , AROUND , AM , AMY -FROM , BEHIND , BY , F'ROM , IN , rnO , OFF , OW-OF , ON , ONTO , OUT , OUT-OF , OVER , THROUGH , TO , TOGETHER , UNDm AWY-F'ROM , IN-THE-DIRECTION-OF IN ( WARD ) , QUT ( WARD ) , TOWARD 4 5 6 indicative of source and target between the path of an object and other ( mving ) objects between an event and a previous event AFTER , AHEAD-OF , ALONG , APART TOGEmER , WITH BACK-AMTFOm , TO-AND-FRO , UP-AND-DOWN BACK .</sentence>
				<definiendum id="0">UNDm AWY-F'ROM</definiendum>
				<definiendum id="1">ALONG , APART TOGEmER , WITH BACK-AMTFOm</definiendum>
				<definiens id="0">BEHIND , BY , F'ROM , IN , rnO , OFF , OW-OF , ON , ONTO , OUT , OUT-OF , OVER , THROUGH , TO , TOGETHER ,</definiens>
			</definition>
			<definition id="9">
				<sentence>INSTRUMENT : A moving object which contacts the SUBJECT .</sentence>
				<definiendum id="0">INSTRUMENT</definiendum>
				<definiens id="0">A moving object which contacts the SUBJECT</definiens>
			</definition>
			<definition id="10">
				<sentence>REFERENCE : A pair of object features ( on a fixed object ) which are used to fix absolute directions independent of the observer 's position .</sentence>
				<definiendum id="0">REFERENCE</definiendum>
			</definition>
			<definition id="11">
				<sentence>AXIS : The spatial direction of an axis of an orientation change ( rotation ) of the SUBJECT .</sentence>
				<definiendum id="0">AXIS</definiendum>
				<definiens id="0">The spatial direction of an axis of an orientation change</definiens>
			</definition>
			<definition id="12">
				<sentence>STARTITIME : The time of the onset of the event .</sentence>
				<definiendum id="0">STARTITIME</definiendum>
				<definiens id="0">The time of the onset of the event</definiens>
			</definition>
			<definition id="13">
				<sentence>The function CREATE-EVENT-NODE ( property pairs ) creates an event node with the indicated case values , returning the node as a result .</sentence>
				<definiendum id="0">function CREATE-EVENT-NODE ( property pairs )</definiendum>
				<definiens id="0">creates an event node with the indicated case values</definiens>
			</definition>
			<definition id="14">
				<sentence>( START -TIME NIL ) ( END-TIME ( * TN TN ) ) ) .</sentence>
				<definiendum id="0">START -TIME NIL ) ( END-TIME</definiendum>
			</definition>
			<definition id="15">
				<sentence>TC : = CURRENT-END-TIME ( EP ) ; E : = CREATE -EVENT -NODE ( ( SUBJECT object-part-node ) ( AGENT parentobject-node ) ( INSTRUMENT joint-node ) ( REFERENCE . . . ) ( DIlsECTION . . . ) ( TRAJECTORY , .</sentence>
				<definiendum id="0">TC</definiendum>
				<definiens id="0">= CURRENT-END-TIME ( EP ) ; E : = CREATE -EVENT -NODE ( ( SUBJECT object-part-node ) ( AGENT parentobject-node ) ( INSTRUMENT joint-node ) ( REFERENCE . .</definiens>
			</definition>
			<definition id="16">
				<sentence>TC : = CURRENT-END-TIME ( E 1 ) ; NEXT ( E1 ) : = CREATE-EVENT-NODE ( ( SUBJECT .</sentence>
				<definiendum id="0">TC</definiendum>
			</definition>
			<definition id="17">
				<sentence>, ) ( TRAJECTORY SHLFT ' ( TRAJECT'0RY ( E 1 ) ) ) ( VE MCITY SHIFT ( VELOC1TY ( E 1 ) ) ) ( AXIS SHLFT ( AXIS ( E I ) ) ) ( ANGULAR-VELOCITY SHIFT ( ANGULARVELOCITY ( E 1 ) ) ) ( START-TIME TC ) ( END-TIME SHIFT ( END-TIME ( E 1 ) ) ) ; E2 : = NEXT ( E 1 ) .</sentence>
				<definiendum id="0">AXIS SHLFT ( AXIS</definiendum>
				<definiendum id="1">ANGULAR-VELOCITY SHIFT ( ANGULARVELOCITY</definiendum>
			</definition>
			<definition id="18">
				<sentence>ASL is *e language of many deaf people in the US .</sentence>
				<definiendum id="0">ASL</definiendum>
				<definiens id="0">*e language of many deaf people in the US</definiens>
			</definition>
			<definition id="19">
				<sentence>ASL is a manual language composed of signs , fingerspelling , and occasional initialization of signs .</sentence>
				<definiendum id="0">ASL</definiendum>
				<definiens id="0">a manual language composed of signs</definiens>
			</definition>
			<definition id="20">
				<sentence>ASL is a visual language .</sentence>
				<definiendum id="0">ASL</definiendum>
				<definiens id="0">a visual language</definiens>
			</definition>
			<definition id="21">
				<sentence>The notion of subject can be related to what Friedman calls the Agent ( AGENT-PATI ENT ) or what Reid cal l s the causer ( CAUSER-AFFECTED ELEMENT-RANGE ) .</sentence>
				<definiendum id="0">CAUSER-AFFECTED ELEMENT-RANGE</definiendum>
				<definiens id="0">related to what Friedman calls the Agent ( AGENT-PATI ENT ) or what Reid cal l s the causer</definiens>
			</definition>
			<definition id="22">
				<sentence>Rehearsal is the process of repetition of the stored material during which the material is decoded , i.e. , grouped into meaningful segments .</sentence>
				<definiendum id="0">Rehearsal</definiendum>
				<definiens id="0">the process of repetition of the stored material during which the material is decoded , i.e. , grouped into meaningful segments</definiens>
			</definition>
			<definition id="23">
				<sentence>Frame analysis is a method for representing language as a system of frames .</sentence>
				<definiendum id="0">Frame analysis</definiendum>
				<definiens id="0">a method for representing language as a system of frames</definiens>
			</definition>
			<definition id="24">
				<sentence>Once the SIF contains all the requisite information , B is said to have understood what A signed to him .</sentence>
				<definiendum id="0">SIF</definiendum>
				<definiens id="0">contains all the requisite information</definiens>
			</definition>
			<definition id="25">
				<sentence>Indexing is a process in ASL which parallels pronominalization and deixis ( this , that , here , there ) in spoken language .</sentence>
				<definiendum id="0">Indexing</definiendum>
				<definiens id="0">a process in ASL which parallels pronominalization and deixis</definiens>
			</definition>
			<definition id="26">
				<sentence>Besides NEUTRAL POSITION , there is another PAUSE SlGN which aids in the delineation of discourse and , therefore , in the discovery of frames .</sentence>
				<definiendum id="0">PAUSE SlGN</definiendum>
				<definiens id="0">aids in the delineation of discourse and , therefore , in the discovery of frames</definiens>
			</definition>
			<definition id="27">
				<sentence>Abstract Definition in the Cognitive Network : The Metaphysical Terminology of a Contemporary Millenarian Community .</sentence>
				<definiendum id="0">Abstract Definition</definiendum>
				<definiens id="0">The Metaphysical Terminology of a Contemporary Millenarian Community</definiens>
			</definition>
</paper>

		<paper id="1040">
			<definition id="0">
				<sentence>AI , too , is much concerned with the structure of linguistic processes , independent of any particular implementation , ** ** Vide : `` Artificial Intellige~ce is the s.tudy of intellectual mechanisms apart from applications and apart fra how such mechanisms are realised in the human or in animals. ''</sentence>
				<definiendum id="0">AI</definiendum>
			</definition>
			<definition id="1">
				<sentence>ful1 sentence about John would be represented by the larger set of triples : ( Cl TOK break1 ( C1 CAl C2 ) ( Cl TEIEf3E C3 ) ( Cl -2 C4 ) ( C2 TOK Joh ) ( C2 DET Pef ) ( C2 NBR S ) ( C3 'ToK Window ) ( C3 DET Def ) ( C3 NBR S ; ( C4 TOK Bamer ) ( CC DET Indef ) ( C4 .</sentence>
				<definiendum id="0">C4 TOK Bamer ) ( CC DET Indef )</definiendum>
				<definiens id="0">Cl -2 C4 ) ( C2 TOK Joh ) ( C2 DET Pef ) ( C2 NBR S ) ( C3 'ToK Window ) ( C3 DET Def ) ( C3 NBR S ;</definiens>
			</definition>
			<definition id="2">
				<sentence>Sehank SchanScqa is a rich system of semantic representation , developed aver a psiad of six yeaxsf with the collaboration af a number of talented students .</sentence>
				<definiendum id="0">Sehank SchanScqa</definiendum>
				<definiens id="0">a rich system of semantic representation</definiens>
			</definition>
			<definition id="3">
				<sentence>The next stage of the notation involves an extended case notation and a set of primitive ACTS , as well as a nqer of it : ems suoh as PHYSWNT which indicate ather stqtes , and items of a fairly simplified psychological theory ( the dictionary entry for 'advise ' , for example , contains a subgraph telling us that Y 'will benefit ' as part of the meaning of 'X advises Y ' [ Schank '73 ) .</sentence>
				<definiendum id="0">primitive ACTS</definiendum>
				<definiens id="0">a nqer of it : ems suoh as PHYSWNT which indicate ather stqtes , and items of a fairly simplified psychological theory</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , in the sentence 'John sho the girl with h riflet , the variables will be filled in frcm context and the case inference will be made fm the main act PROPEL , which is that its hstruuent is lkSOVEI GRASP or PFtOPRL , and so we will arrive at the whole conceatualieation : John PROPEL 4bullet &lt; bullet ===PKYSccxrr PROPEL girl rifLe girl This case inference muSF b~ made , according to Schank , in order to achieve an admate zepresentation. There is , in the last diag~am , a cextain redundancy of expression , but as we shall see tn the next section this often happens with deeper semantic notations. More recently , Schank , together with Rieger , has developed a new class of causal inferences which deepen the diagrams still further. So , in the analysis of 'John 's cold improvPQ1 because I gave him an vplel ( Lrt Scfrank '74a ) the extended diagram contains at Ih~t four yet lower levels of causal =rowing , including one corresponding L.ht the notion of Juh cans+Ncting the idea ( WBUTLD ) that he wants to ea % an apple. So we can see that the undexlying explication of mean* here is not only in the serlso of Iinpulistlc prLmltLws , but in tern of a theory of mental acts as well. Now Ulsra ate a number of genuine ~positi6na ] . difficulties here for the euml &amp; tator faced with a epstm of this complexity , One aspect of thi~ is the atages of developnt pf the ~ystam itself , which can bc seen ae a consimtcntpmcesa of produrlng what was argued for in advance. For ekampla , Schank claimed early on to be a constructing system of semantic mtructures undatlyirrp the 'surface of natural language ' , alehaugh initially them were no primitives at all , and qa late as ( Schank et a1 '70 ) there was only a single primitive TRANS , and most of the entries in the dictionary conmisted of the Bnylish wards coded , together with subscripts. Since than the primitive system has b &amp; ossomed and &amp; ere are now twelve primitives tor hCTS including three Ebr the original TRANS itself. Each axposition of the system recounts its preceding phrases , from the original primitive-free one , throuqh to the present causal inference form ; rather as each human foetus is said to relive in the womb all the evolutionqy stages of the human race. The only trouble with this , fxm an outsider 's point of view , is khat at each stage the representation has been claimed , to be the correct one , while at the same tiSchd admits , in moments of candor ( Schank '731 , that there is no ad to the conceptual diagrrVbraing oE a sentence. This difficulty my well reflect genuine problems in language itself , and , in its acuteat form concerns a three-way confusion between an attractive notation for displaying the 'meanings of wordsv , the course of events in the real world , ad , finally , iibtual procedures for analysis to be based on the diagrams , This raises the , to me , inrportant question of the application of a semantkc system , that I shall touch on again later. Schank , for example , dues mention in passing the questions of wd-sense ambiguity , and the awful ambiguity of English prepositions , but there are in no way central for him , and he assumes that with the availability of 'the correct repxesentationWt his sysh when UnpleIm ? nted must inevitably soive thtraditional and vexing questions. M procedures are hinted at along with the graphs as to how tnrs is to be done. A distinction cof importance may be becoming apparent here batween Schank s work and Riegerls : in Riagar 's thesis ( RLqer '74 ) the rules of inference appear to craatg clclparata and new rubprrphr wnicn may swd in an lnfersntial celatlon to each other so as tsl produce cloncluaiona &amp; but : ~~~~~a of , gayt pronoun rabr~ence , etc. But in Schmk 's cormsponUng papers the sihfctrsncss urn not applid ke actual problems ( Schank '74a ) but only beto amplaxity th. conceptual graphs yet further. Closely connected witla this raattex is the quaation af the survival of the mlvface sr'tructure in tho diagrams. Until very recently p~~h , itiuisation applied only to verbs , tht of nouns being Left to Mehr [ Wekwr 272 ) Most recently , though , noun wds have been disappearf ng from dfagraps and been replaced by.categorfes such as +PZIYS0=* But At is cleax that the swface is only slowly disappearing , rathex than having been abhorred all along. In a mra recent publication CSchank '74b ) there are signs that this. trend of infinitely proliferating diagrams ( for indivihal sentences ) is feversing. In it Schank considsrs the application of his approach to the repraqentation of text , and concl : des , correctly in my tP4etq , that the representations of parts of the text must be interconnected. by causal arrows , and that , inlordm to present @ 1rv.cidity , the conceptual diagrams for individoal sentences and their partvi must be abbreviatedr as by triples such as POEPLE PplWS PEOPLE. her^ indeed , the surface simply has to surviw in the representation un1esF one is prepared to camit oneself to the axeme view that the ordering OF sentences in a text is a purely superficial and arbitrary matter. The Fensein wnich this is a welcome reversal of a trend should be clear , because in the 'causation inference ' development , mentioned earlier , all the consequences and effects oE a conceptualization had to be drawn within itself. Thus , in the extreme case , each sentence of a text 7 should have been represented by a diagram containing most or all of We text of which it was a part. Thusthe representation of a text would haye been impossible on such prihciples. Pay own system constructs a semantic representation for small natural language texts : the basic representation is applied directly to the text and can then be 'massaged ' by various forms of inference to became as deep as is necessary for well defined tasks demonstrating understanding. It is a uniform representation , in that information that might convenionall~ be considerea as syntactic , s-ntic , factual ox rnrerencial LS weu axpressed within a single type of struwra. The fundamental unit in the mnatructioe of th2s beaning representation is the template , which is intmded to correspond to an intuitive notion of a basic message of agent-action-object fom. Templates are rigid format networks of more basic butldlnp blocks called fomulas , which correspond to senscln of individual worde. In order to cohskruet a cctnplete text representation templates ate bound byethat by two kinds of higher level structures called paplates and inference rules. The templates themselves are built up as the construction of the representation proceeds , but the. formulas , paraplates and jlnference rules are all present in the system , at the outset and each of these three types of pre-stored structure is ultirpately constructed frm an inventory of eighty semantic primitive elements , and from functions and predicates ranging over those elements. The system runs on-line as a package of LXSP , k &amp; ISP and MLISP2 program , Wing as input small paragraphs of English , that can -be made up by the uber from a vocabulary of about 6QO word senses , and prduzfng a good French t : ransL &amp; tion as output. This environment provides a pretty clear teat of lmguage undarstding , bcauaa E'rench translations for everyday. pmse are either right or wmng , and can be seen ' to be 910 , while at the same titPe , the mfot difficulttee of understanding ptogtams word sense ambigratty , case anbigufty , difficult pronoun reference , etc. can all be represented within a machine translation environment by , for example , choosing the words of Lhe input sentence containing a pronoun reference difficulty so th &amp; E the potsible alternative references have different genders in French. In that way the French output mdkes quite clear whether or not the program has made the correct inferences in order to understand what it is transla_ting. The program is reasonably robust in agtual prformance , and will even tolerate a certain amount ob bad grammar in the input , since it does not pzfbm a syrkax a~LysI ; s &amp; = % he sense , hut snnkn message forms representable &amp; XI the semantic smctures employed. vpical input would ble a sentence such as 'John lives out : QE tQtm hi &amp; inks his wine out of a bottle , Mo than throws the httlas out uf Uae for each of tke thraa occurrences of 'out oft , since it raslisarrs that they diffexenco must be reflected in the Fwonch , A sentonce such as , *Give Use monkeys b ; mands although they are not ripe because they ay~ very I~wQry ' produces a translation with different equivalontd fur t ) ra tm eccurrmwr of lUaey1 , bocause the syslm oorr @ ctlp realiasst iraQlSI wlrat 4 shall describe below at preference considerations , that tlae most sensible intct~retaticn is one in which the first they ' refers to the bananas and the second tc the monkeys , +and bananas and monkeys~have different genders in French. These two exmph are dealt with in : the 'basic de ' of the system. ( Wilks 73a ) Inmany cases itcmotxesolve pronoun ambiguities by the sort of straightforward 'preference considerations1 used in the last exaaple , where , roughly speaking , 'ripeness ' prefers to &amp; -predicated of plant-like things , and hunger of animate things , Even in a sentence as sbple as 'John drank the wine on the table and it was gdtt such considerations aye inadequate to resolve the anbigtlity of 'it ' between wine and table , since both my be good things. In such cases , 02 inability to ras~lve within its basic moder the program deepens the xepresentatio~ of the text so as to tq and set up chains of inference that will reach , and su prefer , only one of the possible referents. I will return to these pzocesses in a nment , but first I shall give sane brief description of the basic representation set up for English. For each sense of a word in its dictionqxy the program sees a fohula. This is a tree structure of semantic primitives , and is to be interpreted formally using dependency relations. The main element in any fonnula is the rightmost , called its head , and that is the fundamental category to which the fonnula belongs , In the formulas for actions , for example , the head will always be one of the primitives PICK , CAUSE , CHANGE , FEEL , HAVE , PIXME , PAIRl SENSE , USE , , WANT , TELL , BE , 5X ) , FQRCE , W , THINk , FLOW , W , DROP , STRZK , FUNC or HAPN. Here 18 tnts eLee stxuctufe for the. action of drinking : ( mu PART ) Qace again , it is n~t necessary to explain the formalism in any detail , to see that this sense of Idrink* is being expressed as a causing to mve a liqyid object ( F'WH m ) by an animate agent , into that saine agent ( containment case indicated by IN , and formula syntax identifies SELF with thB +gent ) and via ( direction case ) an aperture ( TLIRU PART ) of the agent. Template structures , which actually represent sentences and their parts are built up as netwcrks of formulas like the one above. Templates always consiat of an agent nude , and action node and an object node , and other : nodes ttat laay depend on these. Sot in building a template for 'John drinks , wine ' , the whole of the above tree-formula for 'drinks ' would be piaced at the central action node , another tree structure for 'John ' at the agent node and so on. The complexity of the system comes from the way in which the formulas , considered as active entities , dictate how other places hn the same template should be filled. Thus , the 'drink1 formula above can be thought of as an entity that fits at a template action node , and seeks a liquid object , that is ~ say a f~rmula with ( FLOW STUFF ) as its right-most bzanch , to put at the object noda of the same template. This seeking is preferential , in that formulas not satisfying that requirement will be accepted. but only if nothing misf actan ca lXZ'-fotUEa. TIie -€Elliplate Uif ly esWIisned Tm 3 Tragment of text is the one in which the most formulas hive their preferences satisfied. There is a general principle at work here , that the right interpretation 'says the least1 in inforreation-carrying terns , T ) rh wry simple device is able to do much of the work of a syntax and wxdysnse wzibigukty resa1vi ; tap pxagraa Pnar cusq~e , LZ the a , mteme kd been 'John drank s whole pitcher1 , the fomulr tor th. 'pitcher of klquidb wuld hawe hen pr.rsEerreCI to that for thar human , sfm the subf~mS ; a ( FLOW STUFF ) could be apprtopriateAy located uithirr it. A tonsidarable tamwnt af squeezing af this sbapl~ eansnkcal Lorn of template is necessary to We it fit tha mmplexfty of language : texts have to bt Eraymented initfalLy ? then. in fragments which am. say , grapositional phrases there is a daaay agent Lapasad , and the prepsitions1 phrases thexe is a dummy agent imposed , and the gremsiticmai LomuLa functions as a pseuda-action. There are special 'less preferred1 oaliers to deal with fragments not in agent-acti~n-object order , and so on. men the local inferences have been done that set up the agest-action object templates for fragments of input text , Shd system attempts tm tie these templates together so as to provide an overall initial structure fox the input. One form of this is the anaph , oxa tie , o-f the sort discussed fog the monkeys and bananas example above , but the =re general £om is the case tie. Assignment of these would result in the template far the last clause of 'He ran the mile in a paper bag ' being tid to the action &amp; e of the template for the first clause ( 'He ran the mile ' ) , and the tie king l~~~ed CONTaiment. These case ties are made with the aid of-another class of ordered stxuctues , essentially equivalen* to FMlrPore s case f ruses , called praplates and which are attahea t~ the formulas for English prepositions8. SO , for 'outof ' , for =aaple , there h-ould be at Least six ordered paraplates , each of which Is a string of functions that seek inside templates for information. In general , paraplates range across two , nat necessarily contiguous , templates. So , in analysing 'He put the nuhr he thought of in the table ' , the successfully matching paxaplatz would pin down the dependence OP the template for the last of the three clauses as DIREctior. , by Wing as ampment only that particular template for the last clause that contained the formula for 'a numerical table ' , ( and not a template repxesenting a kitchen table ) and at would do that because of a function in that paraplate seeking a similarity , of head ( SIGN in this case ) between the tt~m appropriate objecr , ConqularJ for ~numbarl and 'tabla'. The other template cumtaining the tfurnftuzsq formula for 'table* would naturally not satisfy the function brcaure SIGN would niok ba the kesa of this amme foxmula for % able9 , The structure of mtuailly cc~nnected templatars that has hen put togsthax thua fu conetitutau a 'atmiantic blockg , and , if it can h con &amp; txucted , then ar far as the mystrtm is concerned all osmsntic and referential ambiguity has hen reaolvd an8 it will begin to generate French by unwrapping the bldck again. ? '' ha generation arrpects of this work have hen dracriW in ( Hor~akovitr 73 . One aspect of the general notion of preference is that the aystan should never construct a deeper or mre elaborate oqmattc rraprssantation than is necessary. fox the task in hand and , FE the initial block can be constructed and a generation of F ; rich &amp; one , rto 'deepening* of the representation will , be attempted , HOW~V~X , wmy exmples can not be resolved by the methods of this 'baeic mode ' and , in particular , if a ward sense arPbiguity , or pronoun reference , i~ still unresolved , then a unique semantic block of templates canrnot be constructed and the 'extended mode ' will be entered. '' In this &amp; a , new template-like forms are extracted fran existing ones , and then added to Me template pool ftom which further inferences can be made. So , in Ula tm~lata derived earlier for 'John drinks wine ' , the system enters the Loarula for 'drinks ' , and draws inferences corresponding to coach case sub-Eorrmula. In this t~xtmple it will derive template-like forms equivalent to , in omJf~ry English , 'The wine is in Jobt , 'The wine entered John via an aperture ' and so on. The extracted templates express information already implicitly preser.t in the text , wen though many of them are partial inferences : anes that may not necessaxily , be true. -n-sense inference rules are then brought down , which attempt , by a s-fe strertegy , ta construct the shortest possible chain of rule-linked tmmplate fo-8 from one containing an ambiguous pronoun , say , 50 one c2ntainhg one of its ~ssible referents. Such a chain then constitutes a solution ta the ambiguity problem , and the preference approach assumes that the shartest chain is always [ the right one. So , Yn the case of 'Jahn drank tha wine /on the table/ and it was good ' , ( in three temprate-matching fragmenb as shewn ) the camact chain t~ 'wine ' uses the two rules * Wibo '73b , and @ n preera ) . ( C*AN~ 1 ) CCSW LHI CWVE c~us~ ) ) t+m 2r r + tr testaw ; ) 2 ) om , in Cswi-EngPfah [ mhta-1 cauaa-ko-mov~-in-sel : -object-21 +* il * ) *r 211 r 2. ( I m ( GoWKZMQ ) ~ RI+ iCLAkOl 2 ) WWT 1 , BXt again 8 C1 is g &amp; l * [ anate-2 umtr 11 Th.5~ ru1.0 uc ~nLy ptha &amp; , that kr cu sky , tlwy corrraFnd 4wly to wht wa may xeao~rmbPy Iwk out tor in a gkvrn rttutkon , net ? to ubt WSP happn. Tha hypotl , .sir irere btrt wderrtahl &amp; np can only trkr plracs oh the baefs of .akpptble rufoo that : are mafixred by the eunlext af ap~lication. In this axample the chain constructed uy ba expressed as ( w8srinq the &amp; ova sguam bracket rmtaatio~~ to cont &amp; bn nut a representation , but sisxxply an indiedtion , in BngldsA , of the template contents ) : ~30hn drank the-wine ] -Bate J , I [ JQM wants backwards lvine is inf The assmption here : is mat tw ehain ushq ather inference niles wttl , d have reached the ' t &amp; 1q1 solution by using less ~.aa two sules , The chief drawback sf this sp ! irm is that dings consisting entirely of primitives have a considerable amount of bo'eh vagueness and redundancy For example , ns reasonable coding in terms of structured primitives could be expected to distinguish , say , 'hmerl and 'mallet'. That my net matter provided the cdings can distinquish iapostantly differe~ ' : of words. Again , a template for the sentente s he sheperd tended his flock ' would contain considerable repetition , each node sf the template trying , as it were , to tell , the whola story by itself , again , the ~refasence cziteria are not in any weighted , which might seegn a dxahcack , and the prefexential chad LET @ I criteria for hference chains miqht v~ff seem too crude. Whether or not such a , system can remain s-le with a WrutderabLe vecabulary. of say several thousand words , has yet to be trrtd. ft will ba ovidrnt tso any reader that Zha laat twa systems described , Bch.nktm ud my moun , share a great deal in cccpmon. IWsn tha apparent Qtff*rence In notation is reduced if one see $ the topological similarity mat rorults from mnrlderfng the head of a formula as functioning rather lLko a Schwk bait action. If one thinks of khe dependencies of the case eubprte of a fornula , rot &amp; ranged 1 lneargy along the. .bottom of a tree , but radiating out Exthe head in the centre , then the two diagtsms actually have identical topologies under interpretation. A difference vises in that the 'filled-in entity ' for Schgnk is the conceptualization centred on the basic action , though for me it is the network oE formulas placed in relation La a t~lopLate , whexe there is indeed a basic action , the he &amp; of the action formula , but there is also a basic entity in the agent formula and SO on. OX , to put FL another way , both what-is and what-is-expected are represented in the templates : the agent formula represents the agent , Pox exampla , but the left-hand pact of the action formula alsp represent3 what atgrant was expected or sought , as in the ( *ANT SUM ) sub-formula of the * &amp; inkt formula , A~thou~h developed in isolation initially , these twlo systems have also influenced each other in more recent years , probably unconsciously. For eatample , conceptual dependency now emphasises the agent-action-object far~rcrt -re than befoxe , and is less iverb-cent.red ' and t~heless while , ronvez-sely , rrty own system now Wes much more overt uuc= of ~les of wtfa1 LnfcanaaUun than in its earlier versions. Again , b~th systems have intellectual conneotions that go back before either generation of A1 systeam. In my view , both these systems have roots in the better parts of the Computational Linguistics movement of the Fifties : in the case of Scfrank 's systm , cane may think of the earlier systems of ( Hays '64 ) and ( Lasrb '661 , and the arkow-structured primitive system of ( Farradene '66 ) ~~EB &amp; e~~OLa3s-~~~prcceaents.Fnthp .Parkex &amp; odes '61 ) system of classiffc &amp; ion awl the early seamtic structures of ( Richens '61 ) and ( Casrsterman '61 ) . In 1961 the last author was arguing that 'what is needed is a disoiplina that will study suantlc nsolrge camaction in a , way malogous to that in which r &amp; nrba # omatfes now rtudiro ~~thmtLcal connaetion , and to that in which ~Ulm~tLcal Ilngulstic~ AQW studla8 SPUC~~C CWU3acti08l1 * ( LUd. , p. 31 This historical pint x &amp; fsrso s final bns that is , I feel , of prgsing interest. Then seem t~ bs two rsscarch styles in this field : one is what sight b9 callled the 'fully finished style1 , is whish ma wxA exists only in one ccmphte fow , and is not issued in iaerly ar dove1 vets iodns , The best example of this io Winoptad 's wrk. The other type , examplified by all the other authots di8scussad hate , to same extent , is the det-eloying style : work which appears in a n-r of vlersiens over tke years , one bps with gxadual hprovt ? ments , perkraps in attmpts ta tackle a wider range of lfncpistic or other inferential phenomena. There are &amp; vatages to both styles , but even in the latter one hws that any proposed stxuctura ox system will , in the end , be found wanting ! in Lhe balances of language , so it can only be a question of when one will have to abandon ~t. The interesting question , and one to which no answer could possibly h given here , is just how far is it worth pushing any given structural approach before starting again fram scratch ? 6 , Sane Cormpisans~ , CVkd , . - , l'qn- $ r-ass In this sactivn X shall -para and co~~trast , under some nine interconnected headings , the projects ae. ; cribed in be My of the papex , This is not easy to do , particularly when , the pxesent author is among the writers discussed , though that is easily mrdied by be reader 's Wing an appropriate discount. A more serious problem is thb , at this stage of research in artificial intelligence and r : ztural language , the most atCtractive # istinctions dissolve on more ds~ailed scrutiny , laxgely because of the lack of any p~ecise theoretical statement in =st , if not a11 , 'tha major prn jects. There are those who think that it therefore follows that this is not me lzrwrent for any form of critical camprison in this field , and that no more is needed than a 'psitive attitudey towards all possible pxwjeeb. OrtZythsewho feel tht , .-wt theemkrary , any kbe is asgod @ Len arms at2 u~ @ puo *Xqoa ayr7 aaoqa puey am am @ a-1 TB~~~PU xo , ; uo~~~uasexdax 30 TaheT aawj~dcmdd~ ay ? surojum iimpmxdd~ uo~qarauab puoaaii ay7 B ? mm zcpdqg 7na=rxnr , p vt up~3o3-a-w 60 p- '' z -sn.lrwlm a3=Tpla ; rd u ? passardxa msXs s , auo axaw qua ; EPdstrea aq pvcm q~a3 aqq p anbv -yaaq bu~~ozd-asxoaqq pzapu~qs Xxa~ awzs 73123 q axaw sanljmwtfazapq s , euo qew zea3 am aq pTn= 'aldmoxa ro3 &amp; uossaz peq B : asam azo~dbm a eaqd am qcm sdeqrad araq put ? uo~qqolu prams e bqp~oha xoz stmmaz PW ~ltl~ P6 tn~ am *SPP~F~ a3e3~~33d ~aha lo ( EL , fl-~ LD ax- ) sap= tmoTasnpcud tq passaxdxa eren smq9Xs sqq yo ; I~T xaysaa qanm aq X~xwl3'.p~na~ &amp; pd s~w 30 3saqq 316511 &amp; XPB 03 SF 1.pssnasTp siayrm yamem ftm 49 pasn smzbalp pua rpuopqou aulsla33fp so qa~ew s~ 3apzw-q s2swxauo~ gua suomrrodans wyqe0~130. ) 38,03 raqqoyy 'pax.dB03 aq 03 suarcud atp Xluo pup naantm tp~yrr Am ! 30 qasqno am qle # nap S'J qj 0s tsaq3euzdd~ ~to~~ ? riruo6 5~2~3 saw0 UP TTarJI sta `` yrm UMO s , Pz ) Z~~~U~ ranX~upqxa ; r pTnm qupkl pumas oy7 *raho -arw -7nq qndu~ am u~ X~q~q'ldxa quasard qw us~~wo3u~ qqm uraauoa TTe pawaqasa re3 os seq aq log Jpuo3as ar ( ; ) ~TM swtriqs xou 4auydI asx~y en WTn Aqlq ) zo ye~lrr~w xanru qw mnon , lpooxdd~ , n11~j # w 30 uo~qdyrasap a ~szauab os uam *7mq r ) ndu~ am u~ quasaxd i~~s~~dbte aw ST q~qq a6pa~n~t.q pixTeaq plro ~snqdaaucm bu~quasoz8ez ormqs~r awm-6~~3 U'flpqUUJ ( t ) PUP 'r ) ndu~ 30 , aXnXlru78 ejQJm8 , ow -8 3* @ IaJJTP X~2-3 - ? g~uB ? s em 7qxaq 30 uayq~uasexdsz am 303 8W ? Q3Ic $ S snasrs xqa -ma uTtzquoa ( '~3314~ smqsXa aaoy7 se qsns 'aazaq ~orauw -an awm uf ( m5~pwqe ! ~y am trTqqTn aknbuP~ Tsrnqou 30 Lpnaa am u~ ) BQP~~BX* mTV2 -auob puaaoo au~3ap aq que~ +o~dwpx* 303 * ? qb~m , wT~P ; L~u~ &amp; qs3t~j , s , ppxbotq~ lo as* ~7s apnloxe pw 48.q~xamap sqaag~td am TTW apn~~u~ *aaea s~m uy 'p~nm qm~ iruo : suoT-J.yuljlep 33f-a XUP XQ pwaJaP 20UU93 ~WSP~ 3UBqYa 4 ~0~330~e8 am yaj~.~o rfimwAn WTW~ -a45 paxf '' qszt3 uponaaq uo~qau~aun ? a , WX-TH WTT 'qroqs pesew ST^ sqaaf.wd 30 '' ~01 '' 33b~a~ am 3q AWMB F27T-m W 3snm 31 *uer plnoyla 4ssazfWd 30 adoq % w UT TOWhJOTTOwT SP UOTSSWSTP OW law0 XW holds that his staactsues =a f &amp; pess &amp; ent d ury pu % kcmbw Qi ( l qp resentatfm , er rather , that they whd a # r xrtrlilard at a 8c at &amp; ma &amp; of magrssentaths~ , d~pendimg on th mbjer=t area. khm &amp; a bubt a86 the r.egg~scntathw in terns M -isriatam tBm % bm im 'B $ s ~lrk mar , $ to 31e Ln we-tow cxxrorpwdbam vlsh ropLM m. The slsaqest how-kewl appmach fs -y ht ollrcm ; t $ J dm that this dispute is ultimateby one oE degree , simx no aae clnilr that every lccution recognized by an $ nltelligaat rrylart br i.Qpd hto a 'deep ' representation. To taka an extmme auab amy -tam tikt uag @ 'Gxd W8rninqT into a deep sewm % hc represemgltkm that the carsect sespsns8 was also rGcad &amp; arnhxjt wauld $ Ch &amp; seirfms thesretical mistake. Hawever , themst serious arqument fa ira mn-tqpar % fshr $ -tmUm Ss mt in kerns 09 the av~Hdaqam of ammbm~ d % g % % dUw , &amp; closely tied to the defence of se &amp; anthc pahb2hwm % EI m , u &amp; % &amp; Ps a large subject not to be unde~taken here. Cbe a % the tmxUes &amp; tic prh , itivqs is that they are open ka bad &amp; e % eaces , ihumua z ; cW than increase their plausibility. For -e , users a ; JF fur linguistic representation have declared them to hve scme d -WU existence and have implied that there is a 'right sett ~Wwes bpq to ernpiriqal discovery. On that view the essentially hqd.sUc of structures sf prbitives is lost , because % t is an usmwkLd fe &amp; are af a language that we can ch-e its vocabuhry as function ui &amp; dLt &amp; matf.a vocabularies. But if there is a zight set of prLmiUwm , utmt~ mk~~ % are the awes of brain-items , then that essential SF=uxald km h &amp; tWhat is the is that there is a considerable amount of psychologicill evidence that Geople a2e able to recall. the content of uhat they hear and understand without being able to recall either the actual words or the syntactic structure used , Thare is large literature on this subject , from which two sample references would be [ Wettler '73 ) and ( Johnson-Laird '74 ) . Thesc results are , of course , no proof df the existence of semantic primitives , but they are undoubtedly supportkng evidence of their plausibility , ao is , on a different plane , the remlt from the encoding of the whole Weboter 's Third International Dictionary at Systmv Develagmefit Corporation , where it was found that a rank-ordered frequency count of the words usad to define other words in that vast dictionary was a list ( omitting 'the1 and a which corresponded almost item-for-item to a plausible list of ssmantic primitives , derived q ptioxi , by those actualhy concerned to.codel the structure of wmd md sentence meanings. Zt is important to distineish the dispute Ibout level from the , closely connected , topic that I shall call the centrality of khe # nowledge required by a language understanding system. Centrality What X aria calling the centrality of certain kinds of information concerns not its level of representation but its non-specifidty : again a contrast can be dram between the sorts of infomiltion required by Charniakls s~st~ , 0x1 on @ hand , and that required bySchankls* and my om on the obhar. Charniak 's examples suggest that .the fundemental form of information is highly spacific** to particular situations , Like parties and the giving of presents , while the sorts a£ information central to Schank 's and my own systems are general partial hssertions abut human wants , expectations , and scr on , my of which ' are so general as to be almost vacuous which , one misht argue , is why their zple in understanding has been ignored for so long. * Though as noted earlier , Schank in 1975 has adopted Rbelson9s ( 1973 ) notion of 'script ' , as a largar-scale 'frame1 , in such a way as to incorporate much less 'central1 knowledge. **In a recent paper ( 1974 ) , Charniak gives much more general-rules , such as his 'rule of significant sub-action ' , mentioned earliw. If I were a reasanably Eluent spaker of , say , G8man , 1 might we13 not understand a Gem conversation about birthday presents unless Z had tietailed 8factuaS. information &amp; but : hw Gens~~~ns organixa the giving of ! presents , which Plight be considerably different the way we do it , Converselys aP course , 3 migl.rt umiarstd much og a twkmlcal artLcle abut a subject in which I was an expert , even th~~rgh 1 knew wry Ifttka af the language in which it was written , These az'e certainky wnrL3exatians that tall Lox Charniak 's approach , and it La perhaps a paradox that the s~rt of r~aturrl language understalridler that wuld tend to COJIP~~ his apswp , t tons ~muld be one concerned with disooursa &amp; L.r ; ) ut , say , the details aL reyapking a t $ Otor CU , where factual. infsmathon is what is centsalt yetr imnically , Charniak has concehtrated on something as general as childtents stories , with their need of deep assumptions about hurwn desires and khaviour. In the end 'this difference may again turn out to be one of enphasisj and of what is most appropriate to diSSerent subject areas ' , though there niay be a vexy general issue lurkiw somewhere here. It seems to me not a fuolish question to ask whether much of what appears to be about natural language in A.I. research is in fact about language at all , Even if it is nbt that may in no way detract fran its value. Newell ( blolore , Newoll q73 ) has argued that A.1. work is in fact 'theoretical psychology ' , in which case it ceul8 hardly be research on natural language , When describing Winograd 's work earlier in the paper , Z raised this question in a weak farm by asking whether his definition of Ipickup1 had anything to da with the natural language use of the word , or whether it was rather a description of how his system picked samething up , a quite different matter. Suppose we generalize this query samewhat , by asking the apparentky absurd question of what would be wrong with calling , say , Charniakls work an essay on the 'Socio-Economic Behaviour of American Children Under Stress ? In the case of Charniak 's work this is a facetious question , asked only in order to make a point , but with an increasing number of systems in A.I. being designed not essentially to do research on natural language , but in order to have a natural language 'front end ' to a systm that is essentially intended to predict chemical spectra , or play snakes and ladders or whatever the question becomes a serious one. It seems to me a good time to ask whether we ahould expect advance in understanding natural language from those tackling the problems head on , or those coroncerned to build a 'fr8nt andv. It i~ cLtt , xly the case that anpiece coulL bp esrcntial to the understanding of sane story. The question is , does it follow that the epehifict.tion , organieation and formalization of that knowldge la &amp; a studf oP l : .aga , because if it is then all human enquiry ftm physics and history to medicine is a linguistic enterprise. And , of cowrr , that poaskbility has actually been entertained within certain strains of darn philosophy. itowaver , I am not wing hefa , to breathe fresh life into a philosophical distinction , batween being aLuut lmpunge and not being about language , but tather introducing a practical distinction , ( which is also a consideration in favour of optiqg , a3 I have , to work on very general and central areas of howledge ) between specific knowledge , and central knowledge without which a syartem could not be said to unilexsttind the language at all. For 1 example , I might know nothing of the arrangement of American birthday parties , but could not be accused of not understanding English even though I failed understand sme pazticular 'children 's story. Yet , if I did not have available acme very general partial inference such as the ane people bainq hurt an8 fallingr or one about people e*avouring to possess things that they want , then it quite possible that my lack of understanding of quits airtple aentencee would cause observers to think that I did not underrW Englbsh. An interesting and difficult question that then arises is whether those who concentrate on central and less central areas of discouse could , in principle , weld their bodies of inferences together in such a : gay as to create a wider system : whether , to put the matter another way , natural language is a whole that can be built up fxm parts ? Pken-noloqica level Another distinction that can be confused with the central-specific one is that of the lphencmenological levels1 of inferences in an understanding system. I mean nothing daunting by the phrase : consider the action eating which is , as smatter of matmica1 fact , quite often an act of bringing the bones of my ulna and radius ( in my arm ) close to that of my lower mandible ( my jaw ) . Yet clearly , any syatQIP OP CCEPgeK ) .n sense inferences that considered such a truth when reasoning about eating would be making a mistake. One might say Ulat the phenoeenolqtcrl lrvrL of the anraly_sis was mng even thourgh all the InF'amznces it : ! ! ad8 ware Uue ones , The stme wuld be true of any W.I. system that wade everyday inferences about physical objects by mnsiQaring their quantum structure. Schank 's analysis of eating rontaias the inf'matian &amp; st it la done by uovirsg the hands to the mukh , and it might be argued that yven ulis is goisrg too far ftom the ' @ aaningl of eating , whataver that my bar towsrds generally true information about ma act which , if always inferred &amp; ut aU acts of qating , will carry the systesrs nruamageably fax. Therq is no denying that this sort of infomatioar might be useEul to have around somewhere ; Wt , in Minsky 's terms , the 'default1 value of the instrument for eating is the hand brought to the mouth , so that , if we have no contrary infomation , then that is the way to assue that any gfvm act of eating was performed. Nonetheless , there clearly is a danger , and that is all X am drawing attention to here , of taking inferences to a phenolnencw ldgical level beyond that of uammn sense. A clearer case , in my view , would be Schank 's analysis ( 1974a ) of mental. activity in which all actions , such as kicking a ball , say , are preceded by a rsrenta9 action af conc~iving or deciding to kick a ball. This is clearly a level of analysis untrue to caumn sense , and which can have only harmful effects in a systea intended to mimic corxlaPon sense reasoning and understanding. Demupling Another general issue in dispute concerns what I shall call demupling , which is whethex ox not the actual parsing of text or dialogue into an 'understanding system. ' is essential. Charniak and Minsky believe that this initial 'parsing1 can be effectively decoupled from the interesting inferential work and simply Qssumed. But , in my view , that is not so , because many of the later inferences would actually have to be done already , in order to have achieved the initial parsing. For example , in analysing 'He shot her with a colt ' , we can not ascribe any structure at all until we'can make the infexences that guns rather than horses are instruments for shooting , and so such a sentence can not be represented by an 'inference-but-no-parsing ' structure , without aremithat language doas not have one of its esgential charaeteristlca , namely ayptemrrtie ambiguity. The essence of decoupling is allowing roprersntational etructures to have significance quite indtlpendant of theirapplication , and that may lead one to a eituatMh lot essentially ditfstont frm that of the logician who simply asserts that ouch-and-much ie the 'right structuxel of sme sentence. The inferences required to resolve word aense ambiguities , and those ad tb reaolva pronoun reference pxobletast are not of different typos1 oftan the two pmblaas occur in a eingle sentence and must be resolved together. But Chatniak 's decoupling has the effect of completely separating these two closely related liniguistic phenomena in what seems to me an unraallstic aanner. His system does inferencing to resolve pronoun ambig2 uttfes , while sense ambiguity is presumably to be done in the future by sapre other , ulti.mately remupled , syste'~.* Wodulari ty Madularity concerns the deccwposability af a firogran or system into ( interacting ) parts , and fhe nature of the relationship between t+e parts. Winograd 's program , as we saw , contains syntactic , semantic and deductive BegmentJ which interact in a way he describes as 'heterarchicl ( as oppo $ ed to 'hierarchic8 ) which means that different wents can be in controlaat dif foreht tiswc . Qn the other hand , ScW and Wilks have argued that it is not necesaaty ta absarve efther the syntactic-semantic , or the semantic-deductive , dlatfnctlon in an understanding program. On that view there 0 no part ; icular , virtue in integrating syntax and semantic rbutlnes , since +here was no need tm separate them. Charniak , h~~verr wbld argue that , in same sensg , one should makq a syntax-setplantics distinction here if one c+n. This would be consisterit with his view on decoupling , and for him it wuld be convenient to decouple at a module , as it were , such as syntactic analysis. But decoup* Although Chaxniak would aque that sense ambiguity could be introduced into his system in its present fona. and s-ng modularity are not the same thing , Wineqrsldi1s progru , for example , is madulak but not at all ddcouplecl kropp SUX~~C ? ! trxt , Ava &amp; lability of suxEaee at.ruct : ura An issue close ho that of the spproprlcrtp level of repreaer\letlun in a system i $ that aP the availabflity of ! Qa surface sbuctum FP the language mcnlysedt or , to put it more crutlely , Ute availability during subsequent analysis of tho actual words &amp; wing antlkysed , Tt~ee~s axe thtrerty available in ~olby , and ar~ indirectly availabh in S ns7 , Nkrxq~ad'~~ and my awn system* but Schank mkos a pulrat uf Uaa iiqwrtance af their nmavailability , on the grounds that an ided r-epresentalhcn skmuld be totally independent of the. input surface structuxta and wrds , There axe Sxrth theoretical and pxactf cal aspects to aims claim sf ScbcEk % : f r. the lhf t , the osder of the sentences of a text is part a£ its surface structure , and pres\rm &amp; ly it is not intended ta &amp; andon this 'superficial inf~rmaticn ' In one of his recent papers 91974bI Schank sems to have accepted sme limitation on the abandonment Of surface structuse. The other , practical , pint concerns the form of representation employed : in the ( 1973 ) hnplementation of Schank 's systffi using an analyser of input text , a matwry and a generator of responses , it was intandd that nothing should ha transferred fxan the input program to the eufyut pr~yriuw -cept a rapresentatian ded in the structures sf primitives discu : : : dl earlitlr , * The question that arises is , can # at structure specify and disting~ ish word-senses adequately without tuansf erring inf~m~ticn spcifically associated^ with the input word ? Schank clearly believes the answer to this question is yes , but that can not be considered established by the scale of cmputations yet described in print. A suitable envir-ent in which to consider tke question is that of translation from one language to another : suppose we are analyging a sentence containing the word 'nail1 meaning a physical object. It is clear that the translation of that word into ~rench should not be the same * '~nis point is to some extent hypothetical since , as we saw , Schankls conceptualizations still do ccntain , cr aspear t~ c~ztain , 3aF.y surface items ; in particular nouns , adjectives an3 adverbs. Iizwever , tLis is a transitional'natter and Lley are in the course of r'epkace.zezt , as noted , by non-superficial items. as the translation for 'screw or 'peg1. Yet is it plausible that any dascription of the function of these three entities entirely in terms of arawmtf~ prWtima1 ma without any explicit mention of the wrb name and its connection to its French equivalent , will be sufffcienG t43 ensure that only the right match is made ? Blication 'Shis pint ia a ganeralioation of the last Lwp , and concerns tho way in which differant ryutaa8 display , in the etzructures they manipulate , the actuel. Ipracdltres of application of those structures ta input text or dialogue , 'Thiri is a matter dlEferent from computer implementation of the aystm. Xn the case of Colby 's patterns , for example , the form of their application to the input English is clear , even theugh the @ a &amp; hing involved could be achieved by many different implementation algorithms. Xn the case of my awn system , I hold the same tio Be true of the template stzructurres , even though the time the input has reached the canonical template form it is considerably different from the input surface structure. The system at We extxeme end of any scale of perspicuity of application is Wincgradls wheke the procedural notation , by its nature , tries to make clear the way FR which the structures are applied. At the other end are the sys~QSS of Schank end Charniak , whaxe no application is specified , which means that tha regrslrrentatfono are not only cmpatible with many hapiementation aLporitba , which doers mtmtter , but axe also compatible with many syste~ls of : Ilnguiskic NILS , W~IOO~ specification is an essential piece of inquiry , and whose subsequent production may cause the basic system to be fuhdamentally dFf Perent. Application is thus different fram decoupling , for SChankls system is clearly coupled to language text by Riesbeck'sqarser , though his stzuctures do mt express their own =lication to language text. English pxepusitions will serve as an example : in Schaxk 's case notation there is no indication of how the case discriminations are actually to be applied to English prepositions in text. So , for example , the preposition *in1 can correspond to the containment case , time location , and spatial loeatioqw amow others. As wa saw earlier , tiha B1serhinatian rnvolved in actual analysis is a matter of apciEying wry delioat. srmtic rulss ranging ovex the basic atatahtic otxvctursw the structures iLlEd case aytltem thmseL~as B~BLP~ to mh to bg leoaantlally dependent on the nature and apphicabiUlty olP such EU~~S~ and as this application of tlae sy8tem should have an obvious place in the ~Ve~aLli structuxas , It is nat sawthing to be delegated to ta mra ' impl9s~entation ' It epugh of the linguistic intractablasfi of English analysis we= to be delegated out of this segmtlentatiun , &amp; .I , muld be uffexlny no more to the analysis of nature1 language than the hgiciarts tllho pmEEer the predicate calculus as a p ] rausibLe strircture for English. In sane of his -re recent writing 's 'Minograd has begun to develop a view that is considerably stronger khan this 'application1 one : in his view the control structure of an undkrstanding progran is itself of theoretical significance , for only in that way , he believes , can natural laForward inference great outstanding dispute perspicuous. whether one should make massive forward inferences as one goes through a text , keeping all one 's expectations intact , as Charniak and Schank hold , 0s whether , as I hold , , one should adopt some 'laziness hypothesis1 &amp; ut understanding , and generate deeper inferences only when the system is unable to salve , say a referential problem by mre superEicia1 methods. Of , in other terns , should an understanding system be ~roblern- , or data- , driven. * This is not meant to be just bland assertion. I have written at same length on the relations between application and the theoretical status of linguistic theories in ( Wilks '74 ) . **The differences between Minsky 's ( 19741 notion of 'default value ' and what I have called 'prefexence ' can be pointed up in terms of application. MhsQ suggests 'gunt as the default value of the instrument of % he action of shooting , but I would claim that , in an example like the earlier 'He shot her with a colt ' , we heed to be able to see in the structure assigned whether or not what is offered as the apparent instrument is in fact an instrument and whether it 'is the default or riot. In other words , we need sufficient structure of application to see not only that 'shcotlng1 prefers an instrument &amp; at is a gun , but also why it will chaose the sense of 'colt1 thatcis a gun rather than the one which is a horse. ATtlx &gt; ugh Schank sametinee writes of a system making 'all possible1 inferences a8 it p10ceBd8 though a textt this ie not in fact the heart ot tho dispute , since no one would want ta defend my atmng definittior oL the tom 'all poesibla infetences ' .</sentence>
				<definiendum id="0">XI</definiendum>
				<definiendum id="1">tWhat</definiendum>
				<definiendum id="2">Thare</definiendum>
				<definiendum id="3">Schank</definiendum>
				<definiendum id="4">tLis</definiendum>
				<definiendum id="5">'Thiri</definiendum>
				<definiendum id="6">W~IOO~ specification</definiendum>
				<definiens id="0">the main act PROPEL , which is that its hstruuent is lkSOVEI GRASP or PFtOPRL , and so we will arrive at the whole conceatualieation : John PROPEL 4bullet &lt; bullet ===PKYSccxrr PROPEL girl rifLe girl This case inference muSF b~ made , according to Schank , in order to achieve an admate zepresentation. There is , in the last diag~am</definiens>
				<definiens id="1">deeper semantic notations. More recently , Schank , together with Rieger , has developed a new class of causal inferences which deepen the diagrams still further. So , in the analysis of 'John 's cold improvPQ1 because I gave him an vplel ( Lrt Scfrank '74a ) the extended diagram contains at Ih~t four yet lower levels of causal =rowing , including one corresponding L.ht the notion of Juh cans+Ncting the idea ( WBUTLD ) that he wants to ea % an apple. So we can see that the undexlying explication of mean* here is not only in the serlso of Iinpulistlc prLmltLws , but in tern of a theory of mental acts as well. Now Ulsra ate a number of genuine ~positi6na ]</definiens>
				<definiens id="2">the atages of developnt pf the ~ystam itself , which can bc seen ae a consimtcntpmcesa of produrlng what was argued for in advance. For ekampla , Schank claimed early on to be a constructing system of semantic mtructures undatlyirrp the 'surface of natural language ' , alehaugh initially them were no primitives at all , and qa late as ( Schank et a1 '70 ) there was only a single primitive TRANS , and most of the entries in the dictionary conmisted of the Bnylish wards coded , together with subscripts. Since than the primitive system has b &amp; ossomed and &amp; ere are now twelve primitives tor hCTS including three Ebr the original TRANS itself. Each axposition of the system recounts its preceding phrases , from the original primitive-free one , throuqh to the present causal inference form</definiens>
				<definiens id="3">problems in language itself , and , in its acuteat form concerns a three-way confusion between an attractive notation for displaying the 'meanings of wordsv , the course of events in the real world , ad , finally , iibtual procedures for analysis to be based on the diagrams , This raises the , to me , inrportant question of the application of a semantkc system , that I shall touch on again later. Schank , for example , dues mention in passing the questions of wd-sense ambiguity , and the awful ambiguity of English prepositions , but there are in no way central for him , and he assumes that with the availability of 'the correct repxesentationWt his sysh when UnpleIm ? nted must inevitably soive thtraditional and vexing questions. M procedures are hinted at along with the graphs as to how tnrs is to be done. A distinction cof importance may be becoming apparent here batween Schank s work and Riegerls : in Riagar 's thesis ( RLqer '74 ) the rules of inference appear to craatg clclparata and new rubprrphr wnicn may swd in an lnfersntial celatlon to each other so as tsl produce cloncluaiona &amp; but : ~~~~~a of , gayt pronoun rabr~ence , etc. But in Schmk 's cormsponUng papers the sihfctrsncss urn not applid ke actual problems ( Schank '74a ) but only beto amplaxity th. conceptual graphs yet further. Closely connected witla this raattex is the quaation af the survival of the mlvface sr'tructure in tho diagrams. Until very recently p~~h , itiuisation applied only to verbs , tht of nouns being Left to Mehr [ Wekwr 272 ) Most recently , though</definiens>
				<definiens id="4">this. trend of infinitely proliferating diagrams ( for indivihal sentences ) is feversing. In it Schank considsrs the application of his approach to the repraqentation of text , and concl : des , correctly in my tP4etq , that the representations of parts of the text must be interconnected. by causal arrows , and that , inlordm to present @ 1rv.cidity , the conceptual diagrams for individoal sentences and their partvi must be abbreviatedr as by triples such as POEPLE PplWS PEOPLE. her^ indeed , the surface simply has to surviw in the representation un1esF one is prepared to camit oneself to the axeme view that the ordering OF sentences in a</definiens>
				<definiens id="5">a conceptualization had to be drawn within itself. Thus , in the extreme case , each sentence of a text 7 should have been represented by a diagram containing most or all of We text of which it was a part. Thusthe representation of a text would haye been impossible on such prihciples. Pay own system constructs a semantic representation for small natural language texts : the basic representation is applied directly to the text and can then be 'massaged ' by various forms of inference to became as deep as is necessary for well defined tasks demonstrating understanding. It is a uniform representation , in that information that might convenionall~ be considerea as syntactic , s-ntic , factual ox rnrerencial LS weu axpressed within a single type of struwra. The fundamental unit in the mnatructioe of th2s beaning representation is the template , which is intmded to correspond to an intuitive notion of a basic message of agent-action-object fom. Templates are rigid format networks of more basic butldlnp blocks called fomulas , which correspond to senscln of individual worde. In order to cohskruet a cctnplete text representation templates ate bound byethat by two kinds of higher level structures called paplates and inference rules. The templates themselves are built up as the construction of the representation proceeds , but the. formulas , paraplates and jlnference rules are all present in the system</definiens>
				<definiens id="6">an inventory of eighty semantic primitive elements , and from functions and predicates ranging over those elements. The system runs on-line as a package of LXSP , k &amp; ISP and MLISP2 program , Wing as input small paragraphs of English , that can -be made up by the uber from a vocabulary of about 6QO word senses</definiens>
				<definiens id="7">the mfot difficulttee of understanding ptogtams word sense ambigratty , case anbigufty , difficult pronoun reference , etc. can all be represented within a machine translation environment by , for example , choosing the words of Lhe input sentence containing a pronoun reference difficulty so th &amp; E the potsible alternative references have different genders in French. In that way the French output mdkes quite clear whether or not the program has made the correct inferences in order to understand what it</definiens>
				<definiens id="8">the semantic smctures employed. vpical input would ble a sentence such as 'John lives out : QE tQtm hi &amp; inks his wine out of a bottle</definiens>
				<definiens id="9">the 'basic de ' of the system. ( Wilks 73a ) Inmany cases itcmotxesolve pronoun ambiguities by the sort of straightforward 'preference considerations1 used in the last exaaple , where , roughly speaking , 'ripeness ' prefers to &amp; -predicated of plant-like things , and hunger of animate things , Even in a sentence as sbple as 'John drank the wine on the table and it was gdtt such considerations aye inadequate to resolve the anbigtlity of 'it ' between wine and table , since both my be good things. In such cases , 02 inability to ras~lve within its basic moder the program deepens the xepresentatio~ of the text so as to tq and set up chains of inference that will reach</definiens>
				<definiens id="10">a tree structure of semantic primitives , and is to be interpreted formally using</definiens>
				<definiens id="11">one of the primitives PICK , CAUSE , CHANGE , FEEL , HAVE , PIXME , PAIRl SENSE , USE , , WANT , TELL , BE , 5X ) , FQRCE , W , THINk , FLOW , W , DROP , STRZK , FUNC or HAPN. Here 18 tnts eLee stxuctufe for the. action of drinking : ( mu PART ) Qace again , it is n~t necessary to explain the formalism in any detail , to see that this sense of Idrink* is being expressed as a causing to mve a liqyid object ( F'WH m ) by an animate agent , into that saine agent ( containment case indicated by IN , and formula syntax identifies SELF with thB +gent ) and via ( direction case ) an aperture ( TLIRU PART ) of the agent. Template structures , which actually represent sentences and their parts are built up as netwcrks of formulas like the one above. Templates always consiat of an agent nude , and action node and an object node , and other : nodes ttat laay depend on these. Sot in building a template for 'John drinks , wine ' , the whole of the above tree-formula for 'drinks ' would be piaced at the central action node , another tree structure for 'John ' at the agent node and so on. The complexity of the system comes from the way in which the formulas , considered as active entities , dictate how other places hn the same template should be filled. Thus , the 'drink1 formula above can be thought of as an entity that fits at a template action node , and seeks a liquid object</definiens>
				<definiens id="12">the one in which the most formulas hive their preferences satisfied. There is a general principle at work here , that the right interpretation 'says the least1 in inforreation-carrying terns , T ) rh wry simple device is able to do much of the work of a syntax and wxdysnse wzibigukty resa1vi</definiens>
				<definiens id="13">a dummy agent imposed , and the gremsiticmai LomuLa functions as a pseuda-action. There are special 'less preferred1 oaliers to deal with fragments not in agent-acti~n-object order , and so on. men the local inferences have been done that set up the agest-action object templates for fragments of input text , Shd system attempts tm tie these templates together so as to provide an overall initial structure fox the input. One form of</definiens>
				<definiens id="14">the case tie. Assignment of these would result in the template far the last clause of 'He ran the mile in a paper bag ' being tid to the action &amp; e of the template for the first clause ( 'He ran the mile ' ) , and the tie king l~~~ed CONTaiment. These case ties are made with the aid of-another class of ordered stxuctues , essentially equivalen* to FMlrPore s case f ruses</definiens>
				<definiens id="15">Is a string of functions that seek inside templates for information. In general , paraplates range across two</definiens>
				<definiens id="16">the last clause that contained the formula for 'a numerical table ' , ( and not a template repxesenting a kitchen table</definiens>
				<definiens id="17">structure of mtuailly cc~nnected templatars that has hen put togsthax thua fu conetitutau a 'atmiantic blockg</definiens>
				<definiens id="18">new template-like forms are extracted fran existing ones , and then added to Me template pool ftom which further inferences can be made. So , in Ula tm~lata derived earlier for 'John drinks wine ' , the system enters the Loarula for 'drinks ' , and draws inferences corresponding to coach case sub-Eorrmula. In this t~xtmple it will derive template-like forms equivalent to , in omJf~ry English , 'The wine is in Jobt , 'The wine entered John via an aperture ' and so on. The extracted templates express information already implicitly preser.t in the text , wen though many of them are partial inferences : anes that may not necessaxily , be true. -n-sense inference rules are then brought down , which attempt , by a s-fe strertegy , ta construct the shortest possible chain of rule-linked tmmplate fo-8 from one containing an ambiguous pronoun</definiens>
				<definiens id="19">dings consisting entirely of primitives have a considerable amount of bo'eh vagueness and redundancy For example , ns reasonable coding in terms of structured primitives could be expected to distinguish , say , 'hmerl and 'mallet'. That my net matter provided the cdings can distinquish iapostantly differe~ ' : of words. Again , a template for the sentente s he sheperd tended his flock ' would contain considerable repetition , each node sf the template trying , as it were , to tell , the whola story by itself</definiens>
				<definiens id="20">the conceptualization centred on the basic action</definiens>
				<definiens id="21">a basic action , the he &amp; of the action formula , but there is also a basic entity in the agent formula and SO on. OX , to put FL another way , both what-is and what-is-expected are represented in the templates : the agent formula represents the agent , Pox exampla , but the left-hand pact of the action formula alsp represent3 what atgrant was expected or sought , as in the ( *ANT SUM ) sub-formula of the * &amp; inkt formula , A~thou~h developed in isolation initially</definiens>
				<definiens id="22">roots in the better parts of the Computational Linguistics movement of the Fifties : in the case of Scfrank 's systm , cane may think of the earlier systems of ( Hays '64 ) and ( Lasrb '661 , and the arkow-structured primitive system of ( Farradene '66 ) ~~EB &amp; e~~OLa3s-~~~prcceaents.Fnthp .Parkex &amp; odes '61 ) system of classiffc &amp; ion awl the early seamtic structures of ( Richens '61 ) and ( Casrsterman '61 )</definiens>
				<definiens id="23">a disoiplina that will study suantlc nsolrge camaction in a , way malogous to that in which r &amp; nrba # omatfes now rtudiro ~~thmtLcal connaetion , and to that in which ~Ulm~tLcal Ilngulstic~ AQW studla8 SPUC~~C CWU3acti08l1 * ( LUd. , p. 31 This historical pint x &amp; fsrso s final bns that is , I feel , of prgsing interest. Then seem t~ bs two rsscarch styles in this field : one is what sight b9 callled the 'fully finished style1 , is whish ma wxA exists only in one ccmphte fow</definiens>
				<definiens id="24">the det-eloying style : work which appears in a n-r of vlersiens over tke years</definiens>
				<definiens id="25">interesting question , and one to which no answer could possibly h given here , is just how far is it worth pushing any given structural approach before starting again fram scratch ? 6</definiens>
				<definiens id="26">an appropriate discount. A more serious problem is thb , at this stage of research in artificial intelligence and r : ztural language , the most atCtractive # istinctions dissolve on more ds~ailed scrutiny</definiens>
				<definiens id="27">the content of uhat they hear and understand without being able to recall either the actual words or the syntactic structure used</definiens>
				<definiens id="28">the existence of semantic primitives , but they are undoubtedly supportkng evidence of their plausibility , ao is , on a different plane , the remlt from the encoding of the whole Weboter 's Third International Dictionary at Systmv Develagmefit Corporation , where it was found that a rank-ordered frequency count of the words usad to define other words in that vast dictionary was a list ( omitting 'the1 and a which corresponded almost item-for-item to a plausible list of ssmantic primitives , derived q ptioxi , by those actualhy concerned to.codel the structure of wmd md sentence meanings. Zt is important to distineish the dispute Ibout level from the , closely connected , topic that I shall call the centrality of khe # nowledge required by a language understanding system. Centrality What X aria calling the centrality of certain kinds of information concerns not its level of representation but its non-specifidty : again a contrast can be dram between the sorts of infomiltion required by Charniakls s~st~ , 0x1 on @ hand , and that required bySchankls* and my om on the obhar. Charniak 's examples suggest that .the fundemental form of information is highly spacific** to particular situations , Like parties and the giving of presents , while the sorts a£ information central to Schank 's and my own systems are general partial hssertions abut human wants , expectations , and scr on , my of which ' are so general as to be almost vacuous which , one misht argue , is why their zple in understanding has been ignored for so long. * Though as noted earlier , Schank in 1975 has adopted Rbelson9s ( 1973 ) notion of 'script ' , as a largar-scale 'frame1 , in such a way as to incorporate much less 'central1 knowledge. **In a recent paper ( 1974 ) , Charniak gives much more general-rules , such as his 'rule of significant sub-action ' , mentioned earliw. If I were a reasanably Eluent spaker of , say , G8man , 1 might we13 not understand a Gem conversation about birthday presents unless Z had tietailed 8factuaS. information &amp; but : hw Gens~~~ns organixa the giving of ! presents</definiens>
				<definiens id="29">tall Lox Charniak 's approach , and it La perhaps a paradox that the s~rt of r~aturrl language understalridler that wuld tend to COJIP~~ his apswp , t tons ~muld be one concerned with disooursa &amp; L.r ; ) ut , say , the details aL reyapking a t $ Otor CU , where factual. infsmathon is what is centsalt yetr imnically , Charniak has concehtrated on something as general as childtents stories , with their need of deep assumptions about hurwn desires</definiens>
				<definiens id="30">a fuolish question to ask whether much of what appears to be about natural language in A.I. research is in fact about language at all</definiens>
				<definiens id="31">in which case it ceul8 hardly be research on natural language , When describing Winograd 's work earlier in the paper , Z raised this question in a weak farm by asking whether his definition of Ipickup1 had anything to da with the natural language use of the word , or whether it was rather a description of how his system picked samething up , a quite different matter. Suppose we generalize this query samewhat , by asking the apparentky absurd question of what would be wrong with calling , say</definiens>
				<definiens id="32">an increasing number of systems in A.I. being designed not essentially to do research on natural language , but in order to have a natural language 'front end ' to a systm that is essentially intended to predict chemical spectra , or play snakes and ladders or whatever the question becomes a serious one. It seems to me a good time to ask whether we ahould expect advance in understanding natural language from those tackling the problems head on , or those coroncerned to build a 'fr8nt andv. It i~ cLtt</definiens>
				<definiens id="33">a linguistic enterprise. And , of cowrr , that poaskbility has actually been entertained within certain strains of darn philosophy. itowaver , I am not wing hefa , to breathe fresh life into a philosophical distinction , batween being aLuut lmpunge and not being about language , but tather introducing a practical distinction , ( which is also a consideration in favour of optiqg , a3 I have , to work on very general and central areas of howledge ) between specific knowledge , and central knowledge without which a syartem could not be said to unilexsttind the language at all. For 1 example , I might know nothing of the arrangement of American birthday parties , but could not be accused of not understanding English even though I failed understand sme pazticular 'children 's story. Yet , if I did not have available acme very general partial inference such as the ane people bainq hurt an8 fallingr or one about people e*avouring to possess things that they want , then it quite possible that my lack of understanding of quits airtple aentencee would cause observers to think that I did not underrW Englbsh. An interesting and difficult question that then arises is whether those who concentrate on central and less central areas of discouse could , in principle , weld their bodies of inferences together in such a : gay as to create a wider system : whether , to put the matter another way , natural language is a whole that can be built up fxm parts ? Pken-noloqica level Another distinction that can be confused with the central-specific one is that of the lphencmenological levels1 of inferences in an understanding system. I mean nothing daunting by the phrase : consider the action eating which is , as smatter of matmica1 fact , quite often an act of bringing the bones of my ulna and radius ( in my arm ) close to that of my lower mandible ( my jaw ) . Yet clearly , any syatQIP OP CCEPgeK ) .n sense inferences</definiens>
				<definiens id="34">W.I. system that wade everyday inferences about physical objects by mnsiQaring their quantum structure. Schank 's analysis of eating rontaias the inf'matian &amp; st it la done by uovirsg the hands to the mukh , and it might be argued that yven ulis is goisrg too far ftom the ' @ aaningl of eating , whataver that my bar towsrds generally true information about ma act which , if always inferred &amp; ut aU acts of qating , will carry the systesrs nruamageably fax. Therq is no denying that this sort of infomatioar might be useEul to have around somewhere</definiens>
				<definiens id="35">inferences required to resolve word aense ambiguities , and those ad tb reaolva pronoun reference pxobletast are not of different typos1 oftan the two pmblaas occur in a eingle sentence and must be resolved together. But Chatniak 's decoupling has the effect of completely separating these two closely related liniguistic phenomena in what seems to me an unraallstic aanner. His system does inferencing to resolve pronoun ambig2 uttfes , while sense ambiguity is presumably to be done in the future by sapre other , ulti.mately remupled , syste'~.* Wodulari ty Madularity concerns the deccwposability af a firogran or system into ( interacting ) parts , and fhe nature of the relationship between t+e parts. Winograd 's program , as we saw , contains syntactic , semantic and deductive BegmentJ which interact in a way he describes as 'heterarchicl ( as oppo $ ed to 'hierarchic8 ) which means that different wents can be in controlaat dif foreht tiswc . Qn the other hand , ScW and Wilks have argued that it is not necesaaty ta absarve efther the syntactic-semantic , or the semantic-deductive , dlatfnctlon in an understanding program. On that view there 0 no part ; icular , virtue in integrating syntax and semantic rbutlnes</definiens>
				<definiens id="36">the language mcnlysedt or , to put it more crutlely , Ute availability during subsequent analysis of tho actual words &amp; wing antlkysed</definiens>
				<definiens id="37">mkos a pulrat uf Uaa iiqwrtance af their nmavailability , on the grounds that an ided r-epresentalhcn skmuld be totally independent of the. input surface structuxta and wrds , There axe Sxrth theoretical and pxactf cal aspects to aims claim sf ScbcEk % : f r. the lhf t , the osder of the sentences of a text is part a£ its surface structure , and pres\rm &amp; ly it is not intended ta &amp; andon this 'superficial inf~rmaticn ' In one of his recent papers 91974bI Schank sems to have accepted sme limitation on the abandonment Of surface structuse. The other , practical , pint concerns the form of representation employed : in the ( 1973 ) hnplementation of Schank 's systffi using an analyser of input text , a matwry and a generator of responses</definiens>
				<definiens id="38">yes , but that can not be considered established by the scale of cmputations yet described in print. A suitable envir-ent in which to consider tke question is that of translation from one language to another : suppose we are analyging a sentence containing the word 'nail1 meaning a physical object. It is clear that the translation of that word into ~rench should not be the same * '~nis point is to some extent hypothetical since , as we saw , Schankls conceptualizations still do ccntain , cr aspear t~ c~ztain , 3aF.y surface items ; in particular nouns , adjectives an3 adverbs. Iizwever ,</definiens>
				<definiens id="39">a transitional'natter and Lley are in the course of r'epkace.zezt , as noted , by non-superficial items. as the translation for 'screw or 'peg1. Yet is it plausible that any dascription of the function of these three entities entirely in terms of arawmtf~ prWtima1 ma without any explicit mention of the wrb name and its connection to its French equivalent , will be sufffcienG t43 ensure that only the right match is made ? Blication 'Shis pint ia a ganeralioation of the last Lwp , and concerns tho way in which differant ryutaa8 display , in the etzructures they manipulate , the actuel. Ipracdltres of application of those structures ta input text or dialogue ,</definiens>
				<definiens id="40">a matter dlEferent from computer implementation of the aystm. Xn the case of Colby 's patterns , for example , the form of their application to the input English is clear</definiens>
				<definiens id="41">Wincgradls wheke the procedural notation , by its nature , tries to make clear the way FR which the structures are applied. At the other end are the sys~QSS of Schank end Charniak , whaxe no application is specified , which means that tha regrslrrentatfono are not only cmpatible with many hapiementation aLporitba , which doers mtmtter , but axe also compatible with many syste~ls of : Ilnguiskic NILS</definiens>
				<definiens id="42">an essential piece of inquiry , and whose subsequent production may cause the basic system to be fuhdamentally dFf Perent. Application is thus different fram decoupling , for SChankls system is clearly coupled to language text by Riesbeck'sqarser , though his stzuctures do mt express their own =lication to language text. English pxepusitions will serve as an example : in Schaxk 's case notation there is no indication of how the case discriminations are actually to be applied to English prepositions in text. So , for example , the preposition *in1 can correspond to the containment case , time location , and spatial loeatioqw amow others. As wa saw earlier , tiha B1serhinatian rnvolved in actual analysis is a matter of apciEying wry delioat. srmtic rulss ranging ovex the basic atatahtic otxvctursw the structures iLlEd case aytltem thmseL~as B~BLP~ to mh to bg leoaantlally dependent on the nature and apphicabiUlty olP such EU~~S~ and as this application of tlae sy8tem should have an obvious place in the ~Ve~aLli structuxas , It is nat sawthing to be delegated to ta mra</definiens>
				<definiens id="43">a p ] rausibLe strircture for English. In sane of his -re recent writing 's 'Minograd has begun to develop a view that is considerably stronger khan this 'application1 one : in his view the control structure of an undkrstanding progran is itself of theoretical significance , for only in that way , he believes , can natural laForward inference great outstanding dispute perspicuous. whether one should make massive forward inferences as one goes through a text , keeping all one 's expectations intact , as Charniak and Schank hold , 0s whether , as I hold , , one should adopt some 'laziness hypothesis1 &amp; ut understanding , and generate deeper inferences only when the system is unable to salve</definiens>
				<definiens id="44">same length on the relations between application and the theoretical status of linguistic theories in ( Wilks '74 ) . **The differences between Minsky 's ( 19741 notion of 'default value ' and what I have called 'prefexence ' can be pointed up in terms of application. MhsQ suggests 'gunt as the default value of the instrument of % he action of shooting , but I would claim that , in an example like the earlier 'He shot her with a colt ' , we heed to be able to see in the structure assigned whether or not what is offered as the apparent instrument is in fact an instrument and whether it 'is the default</definiens>
				<definiens id="45">a horse. ATtlx &gt; ugh Schank sametinee writes of a system making 'all possible1 inferences a8 it p10ceBd8 though a textt this ie not in fact the heart ot tho dispute</definiens>
			</definition>
</paper>

		<paper id="1062">
			<definition id="0">
				<sentence>the reasoning-status checker ( RSC ) to be used during the consultation , and the general question answerqr ( GQA ) to be used during the consultation or after the system has ~rinted its results .</sentence>
				<definiendum id="0">reasoning-status checker</definiendum>
			</definition>
			<definition id="1">
				<sentence>For example , AGE is a clinical parameter of the patient ; IDENTITY is a clinical parameter of an oreanism , with STRFPTOCOCCUS as a possible value ; SITE is a parameter of a culture , with BLOOD as a possible value .</sentence>
				<definiendum id="0">AGE</definiendum>
				<definiendum id="1">IDENTITY</definiendum>
				<definiendum id="2">SITE</definiendum>
				<definiens id="0">a clinical parameter of the patient ;</definiens>
				<definiens id="1">a clinical parameter of an oreanism , with STRFPTOCOCCUS as a possible value</definiens>
				<definiens id="2">a parameter of a culture</definiens>
			</definition>
			<definition id="2">
				<sentence>-- -- 111 ( PREMISE ) If : 1 ) T @ e site of the culture is blood , and 2 ) The portal of entry of the organism is GI , and 3 ) The patient is a compromised host ( ACTION ) Then : It 1s definlte ( 1 -0 ) that bacteroides is an organism for which therapy should cover Associated with each attribute-object-value triple is a certainty factor -a number between -1 and 1 inclusive which indicates how stronqly the system belleves that the attribute of the object has the indicated value .</sentence>
				<definiendum id="0">patient</definiendum>
			</definition>
			<definition id="3">
				<sentence>Factual knowled~e consists of facts which are medically valid inde~endent of the ~ayticular case .</sentence>
				<definiendum id="0">Factual knowled~e</definiendum>
				<definiens id="0">consists of facts which are medically valid inde~endent of the ~ayticular case</definiens>
			</definition>
			<definition id="4">
				<sentence>COLI GRAMNEG DOSE GENTAMICIN 1.7 mq kg q8h IV ( or IM ) The remainder of the factual knowledge consists of lists and tables : pieces of aedical knowledge , organized m such a way that they can be used to augment the producbion rules .</sentence>
				<definiendum id="0">COLI GRAMNEG DOSE GENTAMICIN 1.7 mq kg q8h IV</definiendum>
				<definiens id="0">The remainder of the factual knowledge consists of lists and tables : pieces of aedical knowledge , organized m such a way that they can be used to augment the producbion rules</definiens>
			</definition>
			<definition id="5">
				<sentence>Each specialist knows how the relevant part of the control structure works and what pieces of knowledge it uses .</sentence>
				<definiendum id="0">specialist</definiendum>
				<definiens id="0">knows how the relevant part of the control structure works and what pieces of knowledge it uses</definiens>
			</definition>
			<definition id="6">
				<sentence>Terminal words may have properties indicating : 1 ) that this word is an acceptable value for some clinical parameter ( s ) 2 ) that this word always implicates a certain clinical parameter , system list , or table ( e.g. the word `` identitvll always implicates the parameter IDENTITY , which means the identity of an organism ) 3 ) that this word might Xmplicate a certain parameter , system list , or table ( e.3 .</sentence>
				<definiendum id="0">IDENTITY</definiendum>
				<definiens id="0">means the identity of an organism</definiens>
			</definition>
			<definition id="7">
				<sentence>the word tlpositiven might implicate the parameter NUMPOS , which means the number of positive cultures in a series ) 4 ) that this word is part of a phrase which can be thought of as a sinqle word ( examples of such phrases are `` transtracheal aspirationw , Ithow longw , and llnot sterilev1 .</sentence>
				<definiendum id="0">NUMPOS</definiendum>
				<definiens id="0">means the number of positive cultures in a series ) 4 ) that this word is part of a phrase which can be thought of as a sinqle word ( examples of such phrases</definiens>
			</definition>
			<definition id="8">
				<sentence>Usinq propertv 4 ( see Table 1 ) of the terminal words in this list , the function identifies a phrase and replaces it with a single synonymous terminal word ( whose dictionary properties may be important in determining the meaning of the question ) .</sentence>
				<definiendum id="0">function</definiendum>
				<definiens id="0">identifies a phrase and replaces it with a single synonymous terminal word ( whose dictionary properties may be important in determining the meaning of the question )</definiens>
			</definition>
			<definition id="9">
				<sentence>3 ) &lt; value &gt; One of the terminal words in the question has a diationary property indicating that it is a legal value for the parameter ( property 1 , Table 1 -e , q. THRDAT is a legal value for the parameter SITE ) .</sentence>
				<definiendum id="0">q. THRDAT</definiendum>
				<definiens id="0">a legal value for the parameter SITE</definiens>
			</definition>
			<definition id="10">
				<sentence>4 ) &lt; parm &gt; All of the words in the list are examined to see if they implicate any clinical parameters , Strong implicatians come from words with properties showinrf that the word is an acceptable value of the parameter , or that the word always implicates that parameter ( properties 1 and 2 , Table 1 ) .</sentence>
				<definiendum id="0">Strong implicatians</definiendum>
				<definiens id="0">any clinical parameters</definiens>
				<definiens id="1">an acceptable value of the parameter , or that the word always implicates that parameter ( properties 1 and 2</definiens>
			</definition>
			<definition id="11">
				<sentence>Weak implications come from words with nroperties showing that : they might implicate the parameter ( property 3 , Table 1 ) .</sentence>
				<definiendum id="0">Weak implications</definiendum>
				<definiens id="0">come from words with nroperties showing that : they might implicate the parameter ( property 3</definiens>
			</definition>
			<definition id="12">
				<sentence>IV , needs to know not only how to find the svecific rules which might use a parameter , but also how a ~arameter can cause a rule to fail 2nd how one parameter can prevent another from being used .</sentence>
				<definiendum id="0">IV</definiendum>
				<definiens id="0">needs to know not only how to find the svecific rules which might use a parameter , but also how a ~arameter can cause a rule to fail 2nd how one parameter can prevent another from being used</definiens>
			</definition>
			<definition id="13">
				<sentence>The National Communi-cations System ( NCS ) last month announced proposed Federal standards for data communications interfaces ; the proposed standards specify the general purpose electrical characteristics to be applied to data comrnunicatons interfaces .</sentence>
				<definiendum id="0">National Communi-cations System</definiendum>
			</definition>
			<definition id="14">
				<sentence>FEDERAL ENERGY ADMINISTRATION ASSISTS WITH COMPUTERIZED CONSTRUCTION FORE , CASTING SYSTEM The Federal Engergy Administration ( FEA ) is assisting in developing a computerbased system to permit national and regional projections of construction labor needs in relation to energy development .</sentence>
				<definiendum id="0">FEDERAL ENERGY ADMINISTRATION ASSISTS WITH COMPUTERIZED CONSTRUCTION FORE</definiendum>
				<definiens id="0">assisting in developing a computerbased system to permit national and regional projections of construction labor needs in relation to energy development</definiens>
			</definition>
			<definition id="15">
				<sentence>liThe NatiomZ C &lt; viZ Serv &amp; ? s LeagUeCareer SsrzJ % ce Award for 2976 was presented last month to Dr. Ruth M. Davis , Director of the Department of Commerce 's National Bureau of Standards CNBS ) Institute for Computer Sciences and Technology ( ICST ) AFIPS IN WASHINGTON FCC COMPUTER COMJNICATIONS PLANNING CONFERENCE : 'NO LOGICAL TECHNICAL BOUNDARY ' BETWl ! EN COMPUTING AND CO~ICATIONS Summarizing the technical presentations at the FCC P~unning C'onfermee on Comter Colmnurica6~ons Novenber 8-9 in Washington , organized by the AFIPS Washington Office , rrr. Vinton G. Cerf of the Information Processing Techniques Office , Defense Advanced Research Projects Agency ( ARPA ] , noted : ( 1 ) There is no `` logical technical boundary ' ? between computing and communications ; ( 2 ) Packet switching is having an ttimportant effectw on computer comnmications today , and will have a ftprofound effect '' on frequency allocation in the future ; ( 3 ) High local access costs , international link costs , and user learning costs are ( Ilimiting '' the growth of computer communications services ; ( 4 ) The prime opportunities for network costs and tariff improvement lie in the development of new facilities for local access and for intercontinental links ; and ( 5 ) A regulatory climate is needed `` which encourages innovation , ensures reliable interconnection of primary services , and promotes the acquisition of capital for growth.11 Witey says FCC p02ioy deoisions must be bused on under8tunding of technoZogy. Opening the conference , FCC Chairman Richard E. Wiley stated his view that a computer is a comunications device , not a data processing device , when it is used in a traditional communications service. However , Wiley also noted that the use of computer technology may result in an enhanced service , offering more than traditional communications. He predicted that Similar technological forces will develop in several areas of communications service. Wiley said : `` 1 firmly believe that , in this grbat free enterprise society of ours , government regulations must not be permitted to stand in the way of thchnological development. If the new technology creates administrative difficulties for the government , it is the regulations that must be conformed and not the technology. '' According to the FCC chairman , `` We will see more instances in the future where , as here , the technology is developing in a manner that blurs traditional interfaces. In cases of this sort , the policymakers mu8t have direct access to technical experts and decisions must be based upon an understanding of the technology. Wiley also said , `` It is our belief that AFIPS is a particularly appropriate entity to present this conference fur the Commission , in view of the Federation 's sponsorship of the National Computer Conference , and the Joint Comput el ' Conferences prior to that. Moreover , it is also our view that AFIPS is a basically impartial organization in relation to our policy concerns , bringing to us the objective views of a group of highly qualified experts .'I Computer communieutions aceaunts for 20 per cent of a22 acpenditmes in computgr fietd. In the conference Is first presentation on `` Computer Communications ; An Introduct $ on and Overview , '' Lynn Hopewell ( chairman , IEEE Computer Society Technical Committee on Computer Communications ; and senior member , executive staff , Coihputer Sciences Corp. ] said that computer communications systems had first been used in control I i n g ~lcomplexfl operations of industry and government. Hopewell added that the most common use of computer commun2cations is in data base applicat ions. The speaker suggested that the computer communications industry accounts for 20 per cent of all expenditures in the computer field , Examples of industrial areas affected by computer communications technology were listed as law enforcement , securities brokerage , insurance , reservations systems and banking. Hopewell said that 75 per cent of the top 500 industry corporations are now using camputer communications. Distributing samples of a microcomputer-on-a-chip , he noted technological changes that have produced a 1976 microcomputer CPU costing $ 20 in contrast to a 1960 IBM CPU costing $ 30,000. Hopewell added that microprocessors which cost $ 20 today cost $ 100 only a year ago. He indicated that such differentials represent only the beginning of extremely low cost computing. Hopewell said that the proposed definitions employed in the new `` Computer Inquiryff aid in qlclarifying the permitted uses of computers by common carriers , but in no way allow the proposed abandonment of the 'hybrid1 service concept He noted that the hybrid concept should be retained `` because some service offerings have mixes .ob both computing and communications function^ , ^ ' not because of unclear definitions. Since `` hybrid services will become even more common in the future , '' Hopewell continued , elimination of the hybrid concept will `` ineyitably suppress innovation because any services that have communication factions inextricably bound into them will be defined as subject to regulation. '' The speaker concluded that he saw no `` technological or economic reason for the regulation of the resale industry. ? l Te~htu , Z~gy $ 8 'mov ; ng td8 tntegmted &amp; deband 8ehes. ' In his presentation on `` Research Topics in Computer Conwnmicati~n , '' Vinton G. Cerf summarized t ethnological factors influencing the development of computer comhunicat ions , : the availability of wideband transmission media ; the use of computers to control the switching and allocation of transmission bandwidth ; the trend towards all-digital telephone networks ; and interconnection of computer cornmuhications networks. Cerf said the `` technology is leading away from separate , distinct narrowband services . . twoards integrated widenband services. The potential social impact is pervasive ; the possibilities for new wealth-creating activity , almost incalculable ; and the need for regulatory adjustment , inevitableeft With the juxtaposition of computing and connnunication , he suggested the FCC could : reallocate the radio spectrum using computer-controlled demand access ; mandate computer communication network interconnection through the enformcement of interconnection standards ; and consider proposals by =plated carriers as well as others `` to provide previously impossible combinat ions of information processing and traditional communication services. 'Boundary betueen corrmunicat~ng und computhg wit2 become mare bZurred. ' In his presentation on the MDimensions of t &amp; e Need for Computer Communications , '' Alex Cupan , president , BNR , Inc. , suggested that domestic users must seek to reduce the cost of network access for smaller users , especially in the ltsmaller urban centers . ' ! FCC Interconnection Chief Louis Feldenr , in a question-and-answer period following Currants presentation , stressed the Itneed for computer powervf in rural areas. In his formal presentation , Curran continued that the cost of intercontinental transmission must also be reduced. According to the speaker , these measnres would help to insure that Ifthe common carrier networks can cope with the data communications traffic of commercial users.11 Curran stated that some of the office and home services associated with computer communications could require reintegration of voice and data capabilities. He provided several current examples of personal computing including : Vieuduta , the embryonic electronic newspaper in the ' United Kingdom ; Icasthzg , instantaneous voting and data collectio~~ in Canada ; MzCZgram , a precursor of electronic mail in the U. S. ; and CAJ , computer-assisted instruction. Curran also said that other services will require switching machines `` capable of recognizing information [ interest ] specifications as valid addresses For example , swi thcing machines could recognize selective informat ion dissemination interest profiles as valid addresses , he noted. Curran concluded : 'Thus , the boundary between communicating and computing will become more blurred. There are economic arwents for suggesting that the boundary definitions be relaxed to encourage a new cycle of innovation FCC decisGm8 my ZMt the growth of carr % ers , not necessaAZy the g~oth of wegu &amp; % t @ d supptiero in data pmoeseSng. In his presentation , titled frLimitations on the Growth of Computer-Communication service^ , ^^ Prof. Donald A. Dunn , Engineering Economic Systems Department , Stanford University , indicated that user learning costs will limit the rate at which new computer ~ommunication services can be introduced to markets serving non-computer professionals. Dunn suggested that , in future regulatory decisions , integrated service packages ( designed to minimize user learning and operation costs ) might be used in lieu of individual component services as the unit of , service that is judged cohnnunications or data processing. He added that regulatory limitations 'on the rate of return and regulatory policies on depreciation allowances can restrict technological change as well as limit the rate of introduction of new equipment by carriers. According to the speaker , the earliext ftComputer Inquiry '' rule , requiring data processing $ entices to be provided by carriers through a separate affiliate , may limit the growth of carriers. But he added that the rule does not affect the growth of the data processing industry since unregulated suppliers can respond to this market. Dunn also noted that the resale and sharing decision , imposing regulation on resale carriers , would not necessarily inhibit the growth of the industry Itsince separate data processing affiliates will not be required of resale carriers that do not provide monopoly services. '' He stated that the resale and sharing decision `` removed some of the most serious limits to the growth of this industry by opeining the market for network services to essentially any firm willing to operate as a resale carrier. '' Dunn concluded : `` Pressures are likely to develop soon to regulate providers of information service packages that may offer computer message services to users that obtain network service from resale carriers. Such regulation would inhibit the growth of the industry , and is not needed to protect the interests of users. lf `` There is no mtmZ bozbzdary ' bsttdem cormnm~cat &lt; ons and computtnq. In their presentation on `` The Future of Computer Communications . '' Vinton G. Cerf and Alex Curran said that `` we can not offer a solution to the definition of a boundary between communicating and computing -- in fact , technical considerations convince us that there is no natural boundary. '' Cerf and Curran urged the FCC to support the development of ffcompetitive servicestt ; to insure that a ''sufficient setf1 of standards is created to facilitate interconnection of 'prime servicesf1 ; create a climate in which both computing and carrier interests profit from the installation of `` reliablefv facilities ; and broaden the base for the acquisition of capital so as to eliminate a possible constraint on growth. Conference preeenutiom oiZZ become prt of fumt record of Caputer InquCry. The conference , open td the public , was attended by over two hundred people , including those who watched the proceedings via closed circuit television in an adjoining room. As previously announced. the presentations will become part of the formal record in the FCC 's tlComputer Inquiry.'l A Proceedings containing all the papers is available at $ 10 per set from AFIPS Headquarters , 210 Sumtit Avenue , hlontvale , New Jersey 07645. Headquarters telephone number is ( 201 ) 391-9810. AFIPS PAN ) % mMsEM COktbfENT ON USE OF SOCIAL SECURITY NUMBER AT REQUEST OF PRIVACY COPMISSION Members of the AFIPS panel on private sector usage of the Social Security Number ( SSN ) , organized at the request of the Privacy Protection Study Commission ( washington Report , 2/76 ) , last October responded individua lly to a staff memo copcerning the use of the SSN , submitted to them by Privacy Commission Executive Director Caroler W. Parsons. Daniel D. McCracken , independent consultant , said he favors legislation ? 'to prohibit unauthorized matchihg of records '' through use of the SSN as a universal identifier . McCracken wrote Parsons , saying that lacking such legislation , `` 1 would argue for restrictions on the use of the SSN as a partial subsititue , and as a way to keep the more basic issue alive and visible. '' McCracken , who is ACM vice-president , is responsible for passage of an ACM resolution opposing the use of the SSN as a universal identifier. , Herbert S. Bright , president , Computation Planning Inc. , who also filed a response to the memo , said use of the SSN in licensing drivers opens SSN files to insurance companies as well as list compilers and 6ther vendors. Bright added : `` Continuing progress in cross-linking practice between insurance companies is increasing the justification for vigorous efforts by the Commission to examine such attacks on privacy and to place the facts before the public and the Congress . '' Bright is also a member of ACM. Willard E. Hick , auditor , Massachusetts Mutual Life Insurance Co. , Springfield , Massachusetts , responding to the memo , wrote that the Commissionts statement supporting continued use of the personal identifier tlshould emphasize need and not conaentrate on counteracting sugges*ions that have been made .I1 Hick questioned why the Conunission does not `` address in more detail the reason universal identifiers are necessary on a positive rather than negative note. '' He told AFIPS Washington Report that , to the best of his knowledge , there is no I1crosslinkingw between insurance companies. Hick is a member of the Institute of Internal Auditors. Also responding to the memo , with letters not available at press time , were : Jeffrey V. White , president , The Credit hreau , Inc. , Atlanta , Georgia ; John J. Stiglemeier , director , Information Center on Education ; Roger E. Creel , assistant vice president-Syst ems 6 Processing , Employers Insurance Co. of Wasau , Wausau , Wisconsin ; Alden R. Dalzell , director of Data Processing , Ohio University , Athens , Ohio ; J. M. Moore , section head , Exxon Corp. , Florham Park , New Jersey ; and William E. Perry , director of EDP and Research , the Institute of Internal Auditors , Orlando , Florida. -- &gt; -- -- -- -- -Am Washington Report is researched and writte a by Pender M. McCarter , Research Associate , AFIPS Washington Office .</sentence>
				<definiendum id="0">Packet switching</definiendum>
				<definiendum id="1">AFIPS</definiendum>
				<definiendum id="2">CAJ</definiendum>
				<definiens id="0">the Department of Commerce 's National Bureau of Standards CNBS ) Institute for Computer Sciences and Technology ( ICST ) AFIPS IN WASHINGTON FCC COMPUTER COMJNICATIONS PLANNING CONFERENCE : 'NO LOGICAL TECHNICAL BOUNDARY ' BETWl ! EN COMPUTING AND CO~ICATIONS Summarizing the technical presentations at the FCC P~unning C'onfermee on Comter Colmnurica6~ons Novenber 8-9 in Washington , organized by the AFIPS Washington Office , rrr. Vinton G. Cerf of the Information Processing Techniques Office</definiens>
				<definiens id="1">having an ttimportant effectw on computer comnmications today , and will have a ftprofound effect '' on frequency allocation in the future ; ( 3 ) High local access costs , international link costs , and user learning costs are ( Ilimiting '' the growth of computer communications services ; ( 4 ) The prime opportunities for network costs and tariff improvement lie in the development of new facilities for local access and for intercontinental links ; and ( 5 ) A regulatory climate is needed `` which encourages innovation , ensures reliable interconnection of primary services , and promotes the acquisition of capital for growth.11 Witey says FCC p02ioy deoisions must be bused on under8tunding of technoZogy. Opening the conference , FCC Chairman Richard E. Wiley stated his view that a computer is a comunications device , not a data processing device , when it is used in a traditional communications service. However , Wiley also noted that the use of computer technology may result in an enhanced service , offering more than traditional communications. He predicted that Similar technological forces will develop in several areas of communications service. Wiley said : `` 1 firmly believe that , in this grbat free enterprise society of ours , government regulations must not be permitted to stand in the way of thchnological development. If the new technology creates administrative difficulties for the government</definiens>
				<definiens id="2">a particularly appropriate entity to present this conference fur the Commission , in view of the Federation 's sponsorship of the National Computer Conference</definiens>
				<definiens id="3">a basically impartial organization in relation to our policy concerns , bringing to us the objective views of a group of highly qualified experts .'I Computer communieutions aceaunts for 20 per cent of a22 acpenditmes in computgr fietd. In the conference Is first presentation on `` Computer Communications ; An Introduct $ on and Overview , '' Lynn Hopewell ( chairman , IEEE Computer Society Technical Committee on Computer Communications ; and senior member , executive staff , Coihputer Sciences Corp. ] said that computer communications systems had first been used in control I i n g ~lcomplexfl operations of industry and government. Hopewell added that the most common use of computer commun2cations is in data base applicat ions. The speaker suggested that the computer communications industry accounts for 20 per cent of all expenditures in the computer field , Examples of industrial areas affected by computer communications technology were listed as law enforcement , securities brokerage , insurance , reservations systems</definiens>
				<definiens id="4">a year ago. He indicated that such differentials represent only the beginning of extremely low cost computing. Hopewell said that the proposed definitions employed in the new `` Computer Inquiryff aid in qlclarifying the permitted uses of computers by common carriers , but in no way allow the proposed abandonment of the 'hybrid1 service concept He noted that the hybrid concept</definiens>
				<definiens id="5">Research Topics in Computer Conwnmicati~n , '' Vinton G. Cerf summarized t ethnological factors influencing the development of computer comhunicat ions , : the availability of wideband transmission media ; the use of computers to control the switching and allocation of transmission bandwidth ; the trend towards all-digital telephone networks</definiens>
				<definiens id="6">the radio spectrum using computer-controlled demand access ; mandate computer communication network interconnection through the enformcement of interconnection standards ; and consider proposals by =plated carriers as well as others `` to provide previously impossible combinat ions of information processing and traditional communication services. 'Boundary betueen corrmunicat~ng und computhg wit2 become mare bZurred. ' In his presentation on the MDimensions of t &amp; e Need for Computer Communications , '' Alex Cupan , president , BNR , Inc. , suggested that domestic users must seek to reduce the cost of network access for smaller users</definiens>
				<definiens id="7">help to insure that Ifthe common carrier networks can cope with the data communications traffic of commercial users.11 Curran stated that some of the office and home services associated with computer communications could require reintegration of voice and data capabilities. He provided several current examples of personal computing including : Vieuduta , the embryonic electronic newspaper in the ' United Kingdom ; Icasthzg , instantaneous voting and data collectio~~ in Canada</definiens>
				<definiens id="8">a precursor of electronic mail in the U. S.</definiens>
				<definiens id="9">Computer-Communication service^ , ^^ Prof. Donald A. Dunn , Engineering Economic Systems Department , Stanford University , indicated that user learning costs will limit the rate at which new computer ~ommunication services can be introduced to markets serving non-computer professionals. Dunn suggested that , in future regulatory decisions , integrated service packages ( designed to minimize user learning and operation costs ) might be used in lieu of individual component services as the unit of , service that is judged cohnnunications or data processing. He added that regulatory limitations 'on the rate of return and regulatory policies on depreciation allowances can restrict technological change as well as limit the rate of introduction of new equipment by carriers. According to the speaker , the earliext ftComputer Inquiry '' rule , requiring data processing $ entices to be provided by carriers through a separate affiliate , may limit the growth of carriers. But he added that the rule does not affect the growth of the data processing industry since unregulated suppliers can respond to this market. Dunn also noted that the resale and sharing decision , imposing regulation on resale carriers , would not necessarily inhibit the growth of the industry Itsince separate data processing affiliates will not be required of resale carriers that do not provide monopoly services. '' He stated that the resale and sharing decision `` removed some of the most serious limits to the growth of this industry by opeining the market for network services to essentially any firm willing to operate as a resale carrier. '' Dunn concluded : `` Pressures are likely to develop soon to regulate providers of information service packages that may offer computer message services to users that obtain network service from resale carriers. Such regulation would inhibit the growth of the industry , and is not needed to protect the interests of users. lf</definiens>
				<definiens id="10">Future of Computer Communications . '' Vinton G. Cerf and Alex Curran said that `` we can not offer a solution to the definition of a boundary between communicating and computing -- in fact , technical considerations convince us that there is no natural boundary. '' Cerf and Curran urged the FCC to support the development of ffcompetitive servicestt ; to insure that a ''sufficient setf1 of standards is created to facilitate interconnection of 'prime servicesf1 ; create a climate in which both computing and carrier interests profit from the installation of `` reliablefv facilities</definiens>
				<definiens id="11">open td the public , was attended by over two hundred people , including those who watched the proceedings via closed circuit television in an adjoining room. As previously announced. the presentations will become part of the formal record in the FCC 's tlComputer Inquiry.'l A Proceedings containing all the papers</definiens>
				<definiens id="12">AFIPS PAN ) % mMsEM COktbfENT ON USE OF SOCIAL SECURITY NUMBER AT REQUEST OF PRIVACY COPMISSION Members of the AFIPS panel on private sector usage of the Social Security Number ( SSN ) , organized at the request of the Privacy Protection Study Commission ( washington Report , 2/76 ) , last October responded individua lly to a staff memo copcerning the use of the SSN , submitted to them by Privacy Commission Executive Director Caroler W. Parsons. Daniel D. McCracken , independent consultant , said he favors legislation ? 'to prohibit unauthorized matchihg of records '' through use of the SSN as a universal identifier</definiens>
				<definiens id="13">a partial subsititue , and as a way to keep the more basic issue alive and visible. '' McCracken , who is ACM vice-president , is responsible for passage of an ACM resolution opposing the use of the SSN as a universal identifier. , Herbert S. Bright , president</definiens>
				<definiens id="14">increasing the justification for vigorous efforts by the Commission to examine such attacks on privacy and to place the facts before the public and the Congress . '' Bright is also a member of ACM. Willard E. Hick , auditor , Massachusetts Mutual Life Insurance Co. , Springfield , Massachusetts , responding to the memo , wrote that the Commissionts statement supporting continued use of the personal identifier tlshould emphasize need and not conaentrate on counteracting sugges*ions that have been made .I1 Hick questioned why the Conunission does not `` address in more detail the reason universal identifiers are necessary on a positive rather than negative note. '' He told AFIPS Washington Report that , to the best of his knowledge</definiens>
				<definiens id="15">a member of the Institute of Internal Auditors. Also responding to the memo , with letters not available at press time , were : Jeffrey V. White , president</definiens>
			</definition>
			<definition id="16">
				<sentence>COMMERCE SECKETARY RECOMMENDS USPS COMPROMISE ON-PAGE CHARGES FOR NONPROFIT SCIENTIFIC , ENGINEERING , AND TECHNICAL JOURNALS AND PERIODICALS The U.S. Postal Service ( USPS ) is ItwillSng to modify1 ' the USPS regulation requiring reading matter in all non-profit , second class publications to be marked ~ladvertisementv when contributors are required to pay page charges on their submissions , Dr. Betsy Ancker-Johnson , the Department of Commercets Assistant Secretary for Science and Technology , last month said the USPS is llwilling to modify the regulation so long as contributions to publishing costs arenlt mandatary but vol~ntary .</sentence>
				<definiendum id="0">COMMERCE SECKETARY RECOMMENDS USPS COMPROMISE ON-PAGE CHARGES FOR NONPROFIT SCIENTIFIC</definiendum>
				<definiendum id="1">Dr. Betsy Ancker-Johnson</definiendum>
				<definiens id="0">required to pay page charges on their submissions ,</definiens>
			</definition>
			<definition id="17">
				<sentence>171 Shortliffe , E.H. MYCIN : A Rule-Based Computer Proqram to Advise Physicians Regardinq Antimicrobial Therapy Selection .</sentence>
				<definiendum id="0">E.H. MYCIN</definiendum>
			</definition>
</paper>

		<paper id="1050">
			<definition id="0">
				<sentence>Included is a sketch of how various types of grammatical anri semantic `` attributes '' fit into thc scheme .</sentence>
				<definiendum id="0">Included</definiendum>
				<definiens id="0">a sketch of how various types of grammatical anri semantic `` attributes '' fit into thc scheme</definiens>
			</definition>
			<definition id="1">
				<sentence>The speech recognition system is a real time , syntax directed , limited vocabulary , highly cost effective scheme specifically tailored to this environment .</sentence>
				<definiendum id="0">speech recognition system</definiendum>
				<definiens id="0">a real time</definiens>
			</definition>
			<definition id="2">
				<sentence>An intonation pattern is a com~ii~ation of pitch patterns .</sentence>
				<definiendum id="0">intonation pattern</definiendum>
				<definiens id="0">a com~ii~ation of pitch patterns</definiens>
			</definition>
			<definition id="3">
				<sentence>Graphemic synthesis is a procedure by which logographs are niechanically produced in a manner simulating the nwnla1 writing procedure .</sentence>
				<definiendum id="0">Graphemic synthesis</definiendum>
				<definiens id="0">a procedure by which logographs are niechanically produced in a manner simulating the nwnla1 writing procedure</definiens>
			</definition>
			<definition id="4">
				<sentence>AII encoding schenie offers a unique code word for each character ( signature ) of a dictionary of about 6.000 items .</sentence>
				<definiendum id="0">AII encoding schenie</definiendum>
				<definiens id="0">offers a unique code word for each character ( signature ) of a dictionary of about 6.000 items</definiens>
			</definition>
			<definition id="5">
				<sentence>The correction processing generates the corrected data concr rn ing errors in the test and layout data and this corrected data is again input to the FCL .</sentence>
				<definiendum id="0">correction processing</definiendum>
				<definiens id="0">generates the corrected data concr rn ing errors in the test and layout data and this corrected data is again input to the FCL</definiens>
			</definition>
			<definition id="6">
				<sentence>The FRAME program is the portion of the layout control system which defines paragraph groups which have the same character and shape .</sentence>
				<definiendum id="0">FRAME program</definiendum>
				<definiens id="0">the portion of the layout control system which defines paragraph groups which have the same character and shape</definiens>
			</definition>
			<definition id="7">
				<sentence>WRITING : SYNTHESIS : CHINESE Photo-Electrostatic Kanji Printer Atsushi Ishi , Yoichi Hagiwara , Woshimitsu'Masui , and Yoshiyuki Aida Fujitsu Ltd. , Minato-Ru , Tokyo , Japail S. Could , Ed. , Proceedings of the First international Symposium on Computers and Chinese Inputufput Systems , Academia Sinica , 969-981 This Kanji printer consists of a character generator and a printer .</sentence>
				<definiendum id="0">Kanji printer</definiendum>
				<definiens id="0">CHINESE Photo-Electrostatic Kanji Printer Atsushi Ishi , Yoichi Hagiwara , Woshimitsu'Masui , and Yoshiyuki Aida Fujitsu Ltd. , Minato-Ru , Tokyo , Japail S. Could , Ed. , Proceedings of the First international Symposium on Computers and Chinese Input/Oufput Systems</definiens>
			</definition>
			<definition id="8">
				<sentence>The file structure for the PEACE system consists of a character file and a phrase file .</sentence>
				<definiendum id="0">PEACE system</definiendum>
			</definition>
			<definition id="9">
				<sentence>Chinese characters maybe defined as objects produced by a generative grammar suitably extended to two din~ensions .</sentence>
				<definiendum id="0">Chinese characters</definiendum>
				<definiens id="0">objects produced by a generative grammar suitably extended to two din~ensions</definiens>
			</definition>
			<definition id="10">
				<sentence>Radicals with fewer strokes are given srn ; illcr weights : those with conlplicatcd strokes are given greater weights , so t hiit the character obtr1ir1s .</sentence>
				<definiendum id="0">illcr weights</definiendum>
				<definiens id="0">those with conlplicatcd strokes are given greater weights , so t hiit the character obtr1ir1s</definiens>
			</definition>
			<definition id="11">
				<sentence>Each rgcord contairis a 2-bvte key and 34n bytes of data where n is the nunlbsr of Chinese character patterns cotitainei in the record .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the nunlbsr of Chinese character patterns cotitainei in the record</definiens>
			</definition>
			<definition id="12">
				<sentence>WRITING : CHINESE An Melligent Terminal for Chinese Character Processing F. F. Fang , C. N. Liu , and D. T. Tang IBM Thomas J. CVatson Research Center , Yorktowrt Heights , New York S. Gould , Ed. , Proceedings of the First International Symposiunr on Conlputers and Chinese Input utput Systems , Acadernia Sinica , 103114 The proposed terminal system consists of three modules : Input Output .</sentence>
				<definiendum id="0">WRITING</definiendum>
				<definiens id="0">CHINESE An Melligent Terminal for Chinese Character Processing F. F. Fang , C. N. Liu , and D. T. Tang IBM Thomas J. CVatson Research Center , Yorktowrt Heights , New York S. Gould , Ed. , Proceedings of the First International Symposiunr on Conlputers and Chinese Input /Output Systems , Acadernia Sinica , 103114 The proposed terminal system consists of three modules : Input Output</definiens>
			</definition>
			<definition id="13">
				<sentence>The use of the proper statistical techniques ( a measure due to HasslerGoransson which is defined as the chi-square value divided by the number of degrees of freedom is suggested ) makes it possible to study the way in which words enter and leave the scene in a pattern which characterizes the text in mircl~ the satlie way as the intrclt s and exit s determine a play , Using more sopliisticated methods it is possible to study the strength of connection between any two parts of the text and a segmentation of the text into internally mote strongly connected and mutually more loosely connected portions can be tested or even tnechanically suggested .</sentence>
				<definiendum id="0">segmentation of</definiendum>
				<definiens id="0">the chi-square value divided by the number of degrees of freedom is suggested ) makes it possible to study the way in which words enter and leave the scene in a pattern which characterizes the text in mircl~ the satlie way as the intrclt s and exit s determine a play</definiens>
			</definition>
			<definition id="14">
				<sentence>DOCUMENTATION : RETRIEVAL An Efficient Retrieval Method for a Hierarchical Fact-Retrieval System and its Evaluation Fujio Nishid : ~ , and Shinobu Takanlntsu Faculty o/ Engineering , Unirersi~y of Osaka Prefecture , Sakai-shi , 591 Japan Systems-Computers-Conlrol 6 , No. 1.92-60 , 1975 A fact-retrieval system consisting of a data base , axiom set and inference system can deduce answers to questions by combining a certain number of facts .</sentence>
				<definiendum id="0">DOCUMENTATION</definiendum>
				<definiens id="0">A fact-retrieval system consisting of a data base , axiom set and inference system can deduce answers to questions by combining a certain number of facts</definiens>
			</definition>
			<definition id="15">
				<sentence>SOCIAL-BEHAVIORAL SCIENCE : PSYCHOLOGY Computer Simulation of a Language Acquistion System : A First Report John R. Anderson Human Performance Center , University of hiichigan Roberr 1 .</sentence>
				<definiendum id="0">SOCIAL-BEHAVIORAL SCIENCE</definiendum>
				<definiendum id="1">PSYCHOLOGY Computer Simulation</definiendum>
				<definiens id="0">of a Language Acquistion System : A First Report John R. Anderson Human Performance Center</definiens>
			</definition>
			<definition id="16">
				<sentence>SOCIAL-BEHAVIORAL SCIENCE ; PSYCHOLOGY : LEARNING A Mathematical Theory of Learning Transformational Grammar Henry H ; ~~~~burgcr , end licniicth Wrslcr Sclroo/ a f Sociill Services , lhriversity o J Cul ifurniu , lrvine Journal of dlatilert~aticol Ps !</sentence>
				<definiendum id="0">PSYCHOLOGY</definiendum>
				<definiens id="0">LEARNING A Mathematical Theory of Learning Transformational Grammar Henry H</definiens>
			</definition>
			<definition id="17">
				<sentence>g , of G can be discovered by applying procedure P to information of type 1 about g. The sense in which g is `` discovered '' milst be made precise by a formal criterion C , and the proof must hold for arbitrary g in G. The system presented converges : that is , the learning process learns the language to a formal criterion .</sentence>
				<definiendum id="0">learning process</definiendum>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>That is , if we regard the conceptual analyzer as a specialized component of a larger memory , then the allocation of memory resources in reaction to each sentence follows the pattern : ( phase 1 ) get the sentence into a form which is understandable , then ( phase 2 ) understand it !</sentence>
				<definiendum id="0">conceptual analyzer</definiendum>
				<definiens id="0">the allocation of memory resources in reaction to each sentence follows the pattern : ( phase 1 ) get the sentence into a form which is understandable</definiens>
			</definition>
			<definition id="1">
				<sentence>However , since they were developed concurrently with a larger moiiel of conceptual memory ( R1 ) which is functionally a part of a language comprehension system involving a conceptual analyzer and generator ( MARGIE ( S3 ) ) , it will help make the following presentation more concrete if we first have a brief look at the operation and goals of the conceptual memory , in the context of the com~lete language comprehension system .</sentence>
				<definiendum id="0">conceptual memory</definiendum>
				<definiendum id="1">generator ( MARGIE</definiendum>
				<definiens id="0">a part of a language comprehension system involving a conceptual analyzer</definiens>
				<definiens id="1">the com~lete language comprehension system</definiens>
			</definition>
			<definition id="2">
				<sentence>CD is a theory of meaning representation which posits the existence of a small number of primitive actions ( eleven are used by the conceptual memory ) , a number of primitive states , and a small set of connectives ( links ) which can join the actlons and states together into conceptual graphs ( networks ) .</sentence>
				<definiendum id="0">CD</definiendum>
				<definiens id="0">a theory of meaning representation which posits the existence of a small number of primitive actions ( eleven are used by the conceptual memory ) , a number of primitive states , and a small set of connectives ( links ) which can join the actlons and states together into conceptual graphs ( networks )</definiens>
			</definition>
			<definition id="3">
				<sentence>First is an initial attempt to replace the symbols ( JOHN , MARY , BILL , X , etc. ) by pointers to actual memory cance'pts and tokens of concepts .</sentence>
				<definiendum id="0">First</definiendum>
				<definiens id="0">an initial attempt to replace the symbols ( JOHN , MARY , BILL , X</definiens>
			</definition>
			<definition id="4">
				<sentence>inference molecule is a structured LISP program which can perform arbitrary discrimination test 's on a relevant dependency structure 's features and features of all involved concepts and tokens , and ~d~ich &amp; an call on specialist programs to car1-y out standard test information retrieval functions .</sentence>
				<definiendum id="0">inference molecule</definiendum>
				<definiens id="0">a structured LISP program which can perform arbitrary discrimination test 's on a relevant dependency structure 's features and features of all involved concepts and tokens</definiens>
			</definition>
			<definition id="5">
				<sentence>This is ridiculously oversimplified , but it represents a certain philosophy 1 \ &lt; ill digress a moment to reveal. I , as many other people ( see W1 , H1 , C1 , for anstance ) , have come to be1 ieve that passive data structures are fundamentally awkward for repre/ senting knowledge in any detail , partitularly for the purposes typified by ( SPROG *-PROPEL* ( UN v AC 08 OF lw # ( XI xz ~31 ( This is a simp1 i f ied speci'f'ier ( COND ( ( NULL ( CADR V ) molecule co~itaining 'just an3 ob'ect ( COND ( [ AND dSETQ XI -CC ( 6ISA @ d % HAND ) specit-iw atom. ( NULL ( CAPR v ) ] is @ PART oACII ) I test for lack of object s~eci f icat io ( ether specifier atonls go here ) 1 ( RETURN V ) 1 ) FIGURE 6 If0 unsp'cifiea , the aton ! locates the hand of the acto+ , assighing it to X1. It then checks to sea if an $ h , ing is located in XI. If sq : lsth~nc_l is found , it is bound to X2 , and the LOC structure which expresses this infornlat i on is. bound to X3. If nothing 4s located in the actor 's hand , hls hand itself ( XI ) is inferred. The ( LIST X3 ) in the first SP cal l is the list of REASOPJS ( just.one here ) j.ustifying the specificatibn ~f the-object the actor uas'h~lding as th2 03joct of ths PROPEL , The PROPEL specifier molecule. this sinil ? le P1lOPLL exanplc. The needs for `` special. case heuristics '' in cvcn such a hodest ppcrat ion as this quicltly overtaEc one s prol~~rss at dcvis ing fJeclarativef ' Ilremorx strucrures . Programs , on the other hand ; are quick ant1 to the point , quite flexible , and have-as much `` aesthetic potelltiB1 '' a.s e-ven the most elegant deatarative structures. life-sire procedure for this very narrow process of specifying the lnissillg object -of a PROPEL action ivould obviously rec~fiirc-many more tests for related contexts ( `` Jolm was racing clown. the hill on lzis bike. He hit ill. ) But independ-cnt of the f idel ity with ~ , lhicil any given S-molecule executes its task , there is a vcry important claim buried hoth here and in the other inferential procedures in tile ( 31. It is that there are certain ccqtral tasks in wIi.ic11 the ~lecision -proccs , ~ ~~lust seek out the contcxt , rather tlli11 context seeking out the qpropriate decision process. In other ~qords , much of* the inference cal2ability requircs specialists I~IO ino~\r a priori exactly rihat dimensions of context could yossibly affect thc generation of cvery potential inference , and tl-lcse specialists carry out active probes to search. for those dbnensions before ory inference is generated. I can imagine no `` uniform contcxt mechanism '' which accounts for the i~uman 's diverse ab2lity to attend to the relevant and ignore the sul &gt; erfluous .</sentence>
				<definiendum id="0">speci'f'ier ( COND ( ( NULL</definiendum>
				<definiendum id="1">COND</definiendum>
				<definiendum id="2">ether specifier atonls</definiendum>
				<definiens id="0">If nothing 4s located in the actor 's hand , hls hand itself</definiens>
			</definition>
			<definition id="6">
				<sentence>( inference ) Fhry \ &lt; ill pick Billy qff the ground ( IhTER\l : \TIox ) She ran after him ... DISCUSSION : Closely related ta the other enabling inferences , these forms attempt to apply horiledge about enilblement relations to infer the cause of an action 's failure ( in the case of MISSING LWLBlEEVT ) , , or to predict a \L'h\'T XOTSTATE lihich can lead b~act ion predict ion inference to possible actions of intervention on the part of the 1\A\Ter. In the second example above , Pkry ( and the 01 ' first niust realize ( via RESULTATWE inferences ) the potentially undesirable consequencesof Billy 's running action ( i.e. , possible hZGCWUGE for Billy ) From th.is , the CbI can retrace , lo~ate the running action ~chich could lead to such a hTGmtYGE , collect its enabling states. , then conj-ecture that Mary might desire , to annul one or more af them. Mong them tor instance would be that Billy 's feet be in intermittent PkB'SCOhT with the ground. From the ( \\'ANT ( NOT ( EIIYSCONI ' FEET GROUbLD ) ) ) structure , asubsequent ACTION PN3ICTION inference can arise , predicting thnt bhryjmight put an end to ( PtIYSCOK FEET GROUND ) . This jvill in turn ~C~UJ 1-c1 her to be located near Billy , and that prediction \ &lt; ill match the RliSUIJT12TIi7~ inicrence made from her directed running ( the ncxt utterance input ) , hitting the two thoughts together. CLASS 11 : KNOWLEDGE PROPBAGATION INFERENCES PK1NCIPL ; l ' : Based on what the 01 knows an actor -to know , it can often infer othcr knoideledge whicll must also be available to the adtor. Since nost conceptual inferences involve the intentioris lof actors , this modeling of .howledge is crucial. LwPUS : **John sa\i Maly beating Pete with a baseball bat. ( interence ) Johj probably s knew that Pete was getting ' hurt. **Betty asked Bill ior .tKe aspif in. ( inference ) Bill probably surmised tjiab Betty uasn ' ! t feel ing well. DISCUSSION : Nodeling the knowiedge of potential actors is fundamentally difficult . Yet it is essential , since most all intention/prediction-related inferences n~ust be based in part on guesses about what Mo~ilcdge each actor has available to him at various times. The ChI currently models others ' howledge by `` introspecting '' on its orm : assuming another person P has access to'the same kinds of information ns the 01 , P might be expected. to makc some of the sanlc inferences. the 81 does. Since the 01 preserks n logical connecti.~ : ity mng all its inferred structures ( by the PJL~SOXS and OFFSPRT ? 6 properties of each structure ) , after inferences of othca types ha , ve arisen fro111 so~ne mit of information U , the C ? ! can retbrn , determine \iho the original fact U , locate U 's OFFSPI ? I ? PG ( those other nemory structures which arose by inference from U ) , , then infer that P may also be asare of each of the offspring. hs with btDTIVATIOW inferences ( ~\~hi.ch rely on the WSULTATIPE inf crcnces from a structure ) , mOlr ; LT.I ) GE .PROPACLATION inferences are implemented in the procedure POSTSCASwhicl~ runs after the initial breadthf ir'st inference expansion by the monitor. ? .lodeling o thcrs ' ho~cledgc denancls n rich klo\iledgc of .what is normal in Tile ~corld. ( `` does John Smith how that kissing is n sitgn .of gffcct ion ? '' ) . In fact , all inferences must rely upon default ossunyti~np~ ahoutit nonylit ? ; , sincc most of the Q ? s .ho~~~ledgc ' ( and presumal~ly a. laman ' s ) csists in the folm of general ~atterns , rather than specific relations among specific concepts and tokens. The next lass of .infcrcnce 111yl-anents my l~elief that patterns , just as inficrences , should bc rcalizcd in 'the 01 1 , ) . active rrog~nms rather tlla11 by rxissive dccltlrat ivc data structures. PPINCIPU : The 01 lnust mke heavy relia~lce.upon programs wnlnl , encode comonsense pattern inionnation about the modeled ~iorld. Wlcn the retrieval ~d a sought-after wit of infonilation fails , the relevant normality program should be cxccuted on ( pattern applied to ) fiat infohnation to asscss its likelihood in 'the absence of cxpl icit inf orhat ion .. ~uip~s : * **Does Jolm Smith o~m a book ? J ( inference ) Probably so ; middled-class business executives normal lg om boob . **\Pas John Likely to have been aslc-ep at 3 p~n yesterdmr ? ( inference ) bbst likely .not , since he has a qormnl dayt'imc job , and yesterday was a 'workday. DISCUSSION : There are several lo\ ( -level information retrieval p.roceclures in the 01 \ ; i~ich search for explicit i~~folmat ion units as Girccted by spccif ic ixferellce inolecules. Sucll sci+l.ches are on the i ? nsl s of forn~ alone , and successesresult in precise matches , while failures are total. If there were no recourse for such failures , the Cll would quickly ~rind to a halt , being unable to makc intelligent assumptions There must be so~s nnre positive and flexible n : echanism to -ameliorate `` syntactiLt'-. Lookup failures. In the Of , Ellis ability $ 0 , make intelligent assumptions is ip ? , lementi ed by having the lo\\*-level 1-oolup procedures defer control to the appropriate normality molecule ( N-molecule ) which will perform systemmatic tests organized in single-responw discrimination nets , to the unlocatable in^ formation. The goal is to arxive at. a terminal node in the. net d~cre a real number between r and 1 is 1-ocated. 11 swc sequence of tests leads to such a number , the K-inolccule returns'. it as the asscsscd likeli hood ( `` compatibility '' in fuzzy logic t.eiminolo~. ) ' ( ZI ) , ) sf X beins true. Nthough the test in the N-molecules are themselves ciiscrete , they result in the fuzzy compatibility. The point of course is that the tests can encode quite diverse ad very -specific heurist.ics peculiar to each small domain of patterns ; For instance , based on hbwn ( or N-molecule infcrrab1e.-one N-molecule can call upon otherq in its testing p.rocess ! ) features of either Jo ) m or the hammer , we ~voulcl suspect athe compatiba ? lity of each of thc follo\~ing four conj ectures. to form a decreasing sequence : on his age , society in which he lives , ctc . ) related to featurcsaof Jolin , such as his profession ) ( maybe , but again dependent on featurcs of John and models o'f hmcrs in general -i .c. , IIOK likely is any given , hanmer to have a claw and icoodcn l~andle ? ) steel-reinforced \cooden hnndle and a. tack pulleron the claw.. ( likelihood is quite low unlcss the K-moleculc can locate some specific hints , such as that * __-7 -Jolln ~suall~~bui's~o~d equipment , etc . ) A successful N-molecule assessrn6nt results in the* creation of .the assessed information .as a per~~anent\l , eeyl ici t memory set ructure \cl : hose STRISGTI i is the assessed compatibility.. 'This structure is thc normatire inference. One is quickly arced by his om ability to rotc ( usually quite nccuratc1 ) -1 comonsensc conjecture s~ic11 as these , and. thcprocess sccms usually to hc quite sensitive to features of the entities invol~cd -n tllc conjecture. It is my feeling that importahT insights. can bc gni~lecl via a ~fi~rc thorough tt investigation of the normative inference '' process -i 11 huntms . ' A.not11cr role of K-molcculcs is ' menr ioncd in ( 111 ) ~ith rcspcct to the infercncc-rcfercnce cycle I vill dcscril &gt; c shortly .</sentence>
				<definiendum id="0">\\'ANT</definiendum>
				<definiendum id="1">IIOK likely</definiendum>
				<definiens id="0">N-molecule ) which will perform systemmatic tests organized in single-responw discrimination nets</definiens>
			</definition>
			<definition id="7">
				<sentence>( inference ) Andy is a youngster .</sentence>
				<definiendum id="0">Andy</definiendum>
				<definiens id="0">a youngster</definiens>
			</definition>
			<definition id="8">
				<sentence>JOHN BECAUSE HE HI T 0.1 LL ( I ( CON ( ( -CON ( ( ACTOR ( JOHN ) c= &gt; ( *PROPEL* ) OBJECT ( uPHYSOBJ* SPEC ( yU* ) ) FROM ( JOHN ) 'TO ( BILL ) ) TINE ( TIt101 ) 1 &lt; = ( ( ACTOR ( *PHYSOBJ % SPEC ( XU # ) - ) &lt; z &gt; ( *PHYSCONTs VAL ( BILL ) ) ) TIME ( TIN05 ) ) 11 cs ( ( CON ( ( ACTOR ( MARY1 &lt; = &gt; ( *DO* ) ) TlflE tTIMB2 ) SPEC U &lt; ( ( ACTOR ( *LIPS* PART LMARY ) ce &gt; ( *PHYSCONT* VAL ( JOHN ) 1 ) TIME ( TIM00 ( ( YAL f-W ) i ( TIN01 ( ( BEFORE TIM02 X ) ) ) ( TIM02 ( ( BEFORE TIM00 XI ) ) ntence .</sentence>
				<definiendum id="0">CON ( ( -CON ( ( ACTOR</definiendum>
				<definiendum id="1">ACTOR</definiendum>
				<definiens id="0">VAL ( BILL ) ) ) TIME ( TIN05 ) ) 11 cs ( ( CON ( ( ACTOR</definiens>
			</definition>
			<definition id="9">
				<sentence>C0121 represents the cause of B i l l 's anger as bei n C0086 , hi s knowing 'about t'he k I ssi ng event .</sentence>
				<definiendum id="0">C0121</definiendum>
				<definiens id="0">the cause of B i l l 's anger as bei n C0086 , hi s knowing 'about t'he k I ssi ng event</definiens>
			</definition>
			<definition id="10">
				<sentence>ini , MIT Press , cambridge Mass. , 1968 ( Rl ) Rieger , C. , `` @ nceptual Memory : A Theory and Computer Program for ~rncessing the MeaningXontent of Natural Language Utterances , '' Doctoral ~is , sertation ; Stanfdrd , 19'74 ( ~2 ) Riesbeck , 3. , `` ~omputational Understanding : Analysis of Sentences and Context , '' Doctoral Dissertation , Stanford , 1974 ( ~1 ) Schank , R. , `` Conceptual Dependency : A Therory of Natural Language Understanding , ' '' ~ognitiye ' Psychology , 3 ( 4 ) , '1972 ( 52 Schank , R. , Goldman .</sentence>
				<definiendum id="0">Memory</definiendum>
				<definiens id="0">A Theory and Computer Program for ~rncessing the MeaningXontent of Natural Language Utterances , '' Doctoral ~is , sertation</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>I -- -- -- -I Sinca these two exhibit a non-raciprocal grammatical cocccuzience restriction bstueen voic~ and v~rb type -- passive voice im~lies a trarsitive verb but not vice versa -- it is ~ossitle +hat the paucity of eassive -- -- ccnstructiohs in ficticr , 3s sia~ly ax arte'act of the rrequency of in'trancitiva verbs in cth~r uozds , we must ask whether -- -- -- z -- - , , ,* passive sentences occur less in fiction than in non-fiction sim~ly because they have less o~portunity to do so , or whether nch-~assiveness is an independent syntactic feature of fiction style .</sentence>
				<definiendum id="0">nch-~assiveness</definiendum>
				<definiens id="0">a non-raciprocal grammatical cocccuzience restriction bstueen voic~ and v~rb type -- passive voice im~lies a trarsitive verb</definiens>
			</definition>
			<definition id="1">
				<sentence>Cne possible explanation , which suggests a sirnpl~ characterizatic~ of fiction style , cculd be based on analyzing a large subset ( if not the whole class ) of verbs usually callfa intransii~zg 2s items which can occur both wlth nc ohjact ( traditionally called intransitivs verbs ) and with cns cr two objects ( traditionalfy called tracsitives ) .</sentence>
				<definiendum id="0">Cne possible explanation</definiendum>
				<definiens id="0">suggests a sirnpl~ characterizatic~ of fiction style</definiens>
				<definiens id="1">if not the whole class ) of verbs usually callfa intransii~zg 2s items which can occur both wlth nc ohjact ( traditionally called intransitivs verbs ) and with cns cr two objects ( traditionalfy called tracsitives )</definiens>
			</definition>
</paper>

	</volume>
