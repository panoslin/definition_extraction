<?xml version="1.0" encoding="UTF-8"?>
	<volume id="P06">

		<paper id="1008">
			<definition id="0">
				<sentence>More precisely , the idea consists in verifying , for each subset of constituents , the properties for which they are relevant ( i.e. the constraints that can be evaluated ) .</sentence>
				<definiendum id="0">idea</definiendum>
				<definiens id="0">consists in verifying , for each subset of constituents , the properties for which they are relevant ( i.e. the constraints that can be evaluated )</definiens>
			</definition>
			<definition id="1">
				<sentence>This information is computed as follows : Let C a construction defined in the grammar by means of a set of properties SC , let AC an assignment for the construction C , • P+ = set of satisfied properties for AC • P− = set of violated properties for AC • N+ : number of satisfied properties N+ = card ( P+ ) • N− : number of violated properties N− = card ( P− ) • Satisfaction ratio ( SR ) : the number of satisfied properties divided by the number of evaluated properties SR = N+E The SR value varies between 0 and 1 , the two extreme values indicating that no properties are satisfied ( SR=0 ) or none of them are violated ( SR=1 ) .</sentence>
				<definiendum id="0">SR )</definiendum>
				<definiens id="0">the number of satisfied properties divided by the number of evaluated properties SR = N+E The SR value varies between 0</definiens>
			</definition>
			<definition id="2">
				<sentence>The grammaticality index is a little bit higher because a lot of constraints are also satisfied .</sentence>
				<definiendum id="0">grammaticality index</definiendum>
				<definiens id="0">a little bit higher because a lot of constraints are also satisfied</definiens>
			</definition>
</paper>

		<paper id="1044">
			<definition id="0">
				<sentence>Lexical verb classes have been used to support various ( multilingual ) tasks , such as computational lexicography , language generation , machine translation , word sense disambiguation , semantic role labeling , and subcategorization acquisition ( Dorr , 1997 ; Prescher et al. , 2000 ; Korhonen , 2002 ) .</sentence>
				<definiendum id="0">Lexical verb classes</definiendum>
				<definiens id="0">computational lexicography , language generation , machine translation , word sense disambiguation , semantic role labeling , and subcategorization acquisition ( Dorr , 1997 ; Prescher et al. , 2000</definiens>
			</definition>
			<definition id="1">
				<sentence>The system incorporates RASP , a domain-independent robust statistical parser ( Briscoe and Carroll , 2002 ) , which tags , lemmatizes and parses data yielding complete though shallow parses and a SCF classifier which incorporates an extensive inventory of 163 verbal SCFs3 .</sentence>
				<definiendum id="0">RASP</definiendum>
				<definiens id="0">tags , lemmatizes and parses data yielding complete though shallow parses and a SCF classifier which incorporates an extensive inventory of 163 verbal SCFs3</definiens>
			</definition>
			<definition id="2">
				<sentence>PLSA uses Expectation Maximization ( EM ) to find the distribution ˜p ( SCFs|Clusters , Verbs ) which maximises the likelihood of the observed counts .</sentence>
				<definiendum id="0">Verbs )</definiendum>
				<definiens id="0">maximises the likelihood of the observed counts</definiens>
			</definition>
			<definition id="3">
				<sentence>The Information Bottleneck ( Tishby et al. , 1999 ) ( IB ) is an information-theoretic method which controls the balance between : ( i ) the loss of information by representing verbs as clusters ( I ( Clusters ; Verbs ) ) , which has to be minimal , and ( ii ) the relevance of the output clusters for representing the SCF distribution ( I ( Clusters ; SCFs ) ) which has to be maximal .</sentence>
				<definiendum id="0">Information Bottleneck</definiendum>
				<definiendum id="1">IB</definiendum>
				<definiendum id="2">)</definiendum>
				<definiendum id="3">SCFs )</definiendum>
				<definiens id="0">an information-theoretic method which controls the balance between : ( i ) the loss of information by representing verbs as clusters ( I ( Clusters ; Verbs )</definiens>
			</definition>
			<definition id="4">
				<sentence>The trade-off between the two constraints is realized through minimising the cost function : LIB = I ( Clusters ; Verbs ) −βI ( Clusters ; SCFs ) , where β is a parameter that balances the constraints .</sentence>
				<definiendum id="0">SCFs</definiendum>
				<definiendum id="1">β</definiendum>
				<definiens id="0">realized through minimising the cost function : LIB = I ( Clusters ; Verbs ) −βI ( Clusters ;</definiens>
				<definiens id="1">a parameter that balances the constraints</definiens>
			</definition>
			<definition id="5">
				<sentence>IB takes three inputs : ( i ) SCF-verb distributions , ( ii ) the desired number of clusters K , and ( iii ) the initial value of β .</sentence>
				<definiendum id="0">IB</definiendum>
				<definiens id="0">takes three inputs : ( i ) SCF-verb distributions</definiens>
			</definition>
			<definition id="6">
				<sentence>Consider the following clusters : A : inject , transfect , microinfect , contransfect ( 6 ) B : harvest , select , collect ( 7.1 ) centrifuge , process , recover ( 7.2 ) C : wash , rinse ( 4.1.1 ) immunoblot ( 4.1.3 ) overlap ( 5 ) D : activate ( 1.1.1 ) When looking at coarse-grained outputs , interestingly , K as low as 8 learned the broad distinction between biomedical and general language verbs ( the two verb types appeared only rarely in the same clusters ) and produced large semantically meaningful groups of classes ( e.g. the coarse-grained classes EXPERIMENTAL PROCEDURES , TRANSFECT and COLLECT were mapped together ) .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">low as 8 learned the broad distinction between biomedical and general language verbs ( the two verb types appeared only rarely in the same clusters ) and produced large semantically meaningful groups of classes ( e.g. the coarse-grained classes EXPERIMENTAL PROCEDURES , TRANSFECT and COLLECT were mapped together )</definiens>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>Definition 2 A partially ordered set 〈P , ≤〉 is a bounded complete partial order ( BCPO ) if for every S ⊆ P such that Su negationslash= ∅ , Su has a least element , called a least upper bound ( lub ) .</sentence>
				<definiendum id="0">Su</definiendum>
				<definiens id="0">a bounded complete partial order</definiens>
			</definition>
			<definition id="1">
				<sentence>The solution we propose below satisfies these requirements.1 We define partially specified signatures ( PSSs ) , also referred to as modules below , which are structures containing partial information about a signature : part of the subsumption relation and part of the appropriateness specification .</sentence>
				<definiendum id="0">partially specified signatures</definiendum>
				<definiendum id="1">PSSs</definiendum>
				<definiens id="0">structures containing partial information about a signature : part of the subsumption relation and part of the appropriateness specification</definiens>
			</definition>
			<definition id="2">
				<sentence>Definition 5 A partially labeled graph ( PLG ) over TYPE and FEAT is a finite , directed labeled graph S = 〈Q , T , precedesequal , Ap〉 , where : from TYPE and FEAT .</sentence>
				<definiendum id="0">PLG</definiendum>
				<definiendum id="1">FEAT</definiendum>
				<definiens id="0">a finite , directed labeled graph S = 〈Q , T , precedesequal , Ap〉 , where : from TYPE and FEAT</definiens>
			</definition>
			<definition id="3">
				<sentence>Definition 6 A partially specified signature ( PSS ) over TYPE and FEAT is a PLG S = 〈Q , T , precedesequal , Ap〉 , where : closure , denoted ‘ ∗precedesequal’ , is antisymmetric .</sentence>
				<definiendum id="0">PSS</definiendum>
				<definiendum id="1">FEAT</definiendum>
				<definiens id="0">a PLG S = 〈Q , T , precedesequal , Ap〉</definiens>
			</definition>
			<definition id="4">
				<sentence>A PSS is a finite directed graph whose nodes denote types and whose edges denote the subsumption and appropriateness relations .</sentence>
				<definiendum id="0">PSS</definiendum>
				<definiens id="0">a finite directed graph whose nodes denote types and whose edges denote the subsumption and appropriateness relations</definiens>
			</definition>
			<definition id="5">
				<sentence>Module combination is a commutative and associative operation which meets all the desiderata listed in section 4 .</sentence>
				<definiendum id="0">Module combination</definiendum>
				<definiens id="0">a commutative and associative operation which meets all the desiderata listed in section 4</definiens>
			</definition>
</paper>

		<paper id="2063">
			<definition id="0">
				<sentence>Subjectivity detection is the task of identifying subjective words , expressions , and sentences .</sentence>
				<definiendum id="0">Subjectivity detection</definiendum>
			</definition>
			<definition id="1">
				<sentence>Semantic orientation classification is a task of determining positive or negative sentiment of words ( Hatzivassiloglou and McKeown , 1997 ; Turney , 2002 ; Esuli and Sebastiani , 2005 ) .</sentence>
				<definiendum id="0">Semantic orientation classification</definiendum>
				<definiens id="0">a task of determining positive or negative sentiment of words</definiens>
			</definition>
			<definition id="2">
				<sentence>Word level opinion analysis includes word sentiment classification , which views single lexical items ( such as good or bad ) as sentiment carriers , allowing one to classify words into positive and negative semantic categories .</sentence>
				<definiendum id="0">Word level opinion analysis</definiendum>
				<definiens id="0">includes word sentiment classification , which views single lexical items ( such as good or bad</definiens>
			</definition>
			<definition id="3">
				<sentence>A review document in epinions.com consists of a topic ( a product model , restaurant name , travel destination , etc. ) , pros and cons ( mostly a few keywords but sometimes complete sentences ) , and the review text .</sentence>
				<definiendum id="0">review document</definiendum>
			</definition>
			<definition id="4">
				<sentence>We modeled the conditional probability of a class c given a feature vector x as follows : ) ) , ( exp ( 1 ) | ( ∑ = i ii x xcf Z xcp λ where x Z is a normalization factor which can be calculated by the following : ∑ ∑ = ci iix xcfZ ) ) , ( exp ( λ In the first equation , ) , ( xcf i is a feature function which has a binary value , 0 or 1 .</sentence>
				<definiendum id="0">x Z</definiendum>
				<definiendum id="1">xcf i</definiendum>
				<definiens id="0">the conditional probability of a class c given a feature vector x as follows : ) )</definiens>
				<definiens id="1">a normalization factor which can be calculated by the following : ∑ ∑ = ci iix xcfZ</definiens>
			</definition>
			<definition id="5">
				<sentence>Table 7 : System results on Complaint.com reviews ( A , B : The first and the second annotator of each set ) Testset 1 Testset 2 Testset 3 A B A B A B Avg Acc ( % ) 65.8 63.0 67.6 61.0 77.6 72.9 68.0 Prec ( % ) 50.0 60.7 68.6 62.9 67.9 60.7 61.8 Recl ( % ) 56.0 51.5 51.1 44.0 65.5 58.6 54.5 489 The experimental results further show that pro and con sentences are a mixture of opinions and facts , making identifying them in online reviews a distinct problem from opinion sentence identification .</sentence>
				<definiendum id="0">B A B A B Avg Acc</definiendum>
			</definition>
</paper>

		<paper id="1051">
			<definition id="0">
				<sentence>More precisely , let C be the set of all bijective mappings from aprime ⊆ Aprime : |aprime| = |Aprimeprime| to Aprimeprime , an element c ∈ C is a substitution function .</sentence>
				<definiendum id="0">element c ∈ C</definiendum>
			</definition>
			<definition id="1">
				<sentence>Second , we can use one of the WordNet ( Miller , 1995 ) similarities indicated with d ( lw , lwprime ) ( in line with what was done in ( Corley and Mihalcea , 2005 ) ) and different relation between words such as the lexical entailment between verbs ( Ent ) and derivationally relation between words ( Der ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">the lexical entailment between verbs ( Ent ) and derivationally relation between words</definiens>
			</definition>
			<definition id="2">
				<sentence>A treekernel function over t1 and t2 is KT ( t1 , t2 ) =summationtext n1∈Nt1 summationtext n2∈Nt2 ∆ ( n1 , n2 ) , where Nt1 and Nt2 are the sets of the t1’s and t2’s nodes , respectively .</sentence>
				<definiendum id="0">treekernel function</definiendum>
				<definiendum id="1">KT</definiendum>
				<definiendum id="2">Nt2</definiendum>
			</definition>
			<definition id="3">
				<sentence>D2 ( 50 % ) prime and D2 ( 50 % ) primeprime is a random split of D2 .</sentence>
				<definiendum id="0">primeprime</definiendum>
			</definition>
			<definition id="4">
				<sentence>SVM-light-TK3 ( Moschitti , 2006 ) which encodes the basic tree kernel function , KT , in SVMlight ( Joachims , 1999 ) .</sentence>
				<definiendum id="0">SVM-light-TK3</definiendum>
				<definiens id="0">encodes the basic tree kernel function</definiens>
			</definition>
			<definition id="5">
				<sentence>H “Saudi Arabia is the world’s biggest oil exporter.”</sentence>
				<definiendum id="0">H “Saudi Arabia</definiendum>
			</definition>
			<definition id="6">
				<sentence>H “Harvey Weinstein is the co-chairman of Miramax.”</sentence>
				<definiendum id="0">H “Harvey Weinstein</definiendum>
			</definition>
			<definition id="7">
				<sentence>H “Christopher Yavelow is the queen of Holland.”</sentence>
				<definiendum id="0">H “Christopher Yavelow</definiendum>
			</definition>
</paper>

		<paper id="1091">
			<definition id="0">
				<sentence>A block is a pair of phrases which are translations of each other .</sentence>
				<definiendum id="0">block</definiendum>
				<definiens id="0">a pair of phrases</definiens>
			</definition>
			<definition id="1">
				<sentence>Here , a85 is the number of blocks in the translation .</sentence>
				<definiendum id="0">a85</definiendum>
				<definiens id="0">the number of blocks in the translation</definiens>
			</definition>
			<definition id="2">
				<sentence>There are phrase-based and word-based features : a75 a11a39a99a78a99a78a99 a7 a0 a67 a12 a1 a67 a12a76a0 a67a69a77 a11 a14 a55 a55 a98 block a0 a67 consists of target phrase ’violate’ and source phrase ’tnthk’ a94 otherwise a75 a11a39a99a78a99a18a11 a7 a0 a67 a12 a1 a67 a12a76a0 a67a69a77 a11 a14 a55 a55 a98 ’Lebanese’ is a word in the target phrase of block a0 a67 and ’AllbnAny’ is a word in the source phrase a94 otherwise The feature a75 a11a39a99a78a99a78a99 is a ’unigram’ phrase-based feature capturing the identity of a block .</sentence>
				<definiendum id="0">’AllbnAny’</definiendum>
				<definiens id="0">phrase-based and word-based features : a75 a11a39a99a78a99a78a99 a7 a0 a67 a12 a1 a67 a12a76a0 a67a69a77 a11 a14 a55 a55 a98 block a0 a67 consists of target phrase ’violate’ and source phrase ’tnthk’ a94 otherwise a75 a11a39a99a78a99a18a11 a7 a0 a67 a12 a1 a67 a12a76a0 a67a69a77 a11 a14 a55 a55 a98 ’Lebanese’ is a word in the target phrase of block a0 a67 and</definiens>
			</definition>
			<definition id="3">
				<sentence>We look for a weight vector a70 that minimize the following training criterion : a117 a70 a55a58a118a63a119a27a120a142a122a144a143 a145 a5 a98 a57 a134 a67a69a68 a11a147a146 a7 a70 a12 a114 a138 a7a6a113 a67 a14a78a12 a114a116a7a6a113 a67 a14a78a14 a148a150a149 a70 a59 ( 3 ) a146 a7 a70 a12 a114a151a138 a12 a114 a14 a55 a98 a139 a126a89a127a25a129a30a152 a122a144a118a63a125 a126a154a153a39a127a25a129 a77 a129a30a152a156a155 a7 a70 a12 a107 a12 a107 a2 a14 a155 a7 a70 a12 a107 a12 a107 a2 a14 a55a58a157 a7a78a4 a5 a7a112a107 a14a78a12 a108a110a109a39a7a112a107 a14a78a158 a4 a5 a7a112a107 a2 a14a78a12 a108a110a109a111a7a112a107 a2 a14a78a14a78a12 where a157 is a non-negative real-valued loss function ( whose specific choice is not critical for the purposes of this paper ) , and a149a160a159 a94 is a regularization parameter .</sentence>
				<definiendum id="0">a157</definiendum>
				<definiens id="0">a non-negative real-valued loss function</definiens>
				<definiens id="1">a regularization parameter</definiens>
			</definition>
			<definition id="4">
				<sentence>5 in ( ** ) can be implemented using stochastic gradient descent ( SGD ) , where we may simply update a70 as : a70a197a196a198a70 a140a200a199a194a201 a5 a155 a7 a70 a12 a107a89a191 a12 a190 a107a15a191 a14 a92 The parameter a199a202a166 a94 is a fixed constant often referred to as learning rate .</sentence>
				<definiendum id="0">SGD</definiendum>
				<definiens id="0">a fixed constant often referred to as learning rate</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>The phrases “to focus on the past year’s achievements , which , ” and “sa se concentreze pe succesele anului trecut , care , ” are mostly underlined ( the lexicon is unaware of the fact that “achievements” and “succesele” are in fact translations of each other , because “succesele” is a morphologically inflected form which does not cooccur with “achievements” in our initial parallel corpus ) .</sentence>
				<definiendum id="0">“succesele”</definiendum>
				<definiens id="0">a morphologically inflected form which does not cooccur with “achievements” in our initial parallel corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Our test data consists of news articles from the Time Bank corpus , which were translated into Romanian , and has 1000 sentences .</sentence>
				<definiendum id="0">test data</definiendum>
				<definiens id="0">consists of news articles from the Time Bank corpus , which were translated into Romanian , and has 1000 sentences</definiens>
			</definition>
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>We explore the use of restricted dialogue contexts in reinforcement learning ( RL ) of effective dialogue strategies for information seeking spoken dialogue systems ( e.g. COMMUNICATOR ( Walker et al. , 2001 ) ) .</sentence>
				<definiendum id="0">RL</definiendum>
			</definition>
			<definition id="1">
				<sentence>The rst parameter is the stepparameter α which may be a value between 0 and 1 , or speci ed as decreasing .</sentence>
				<definiendum id="0">rst parameter</definiendum>
				<definiens id="0">the stepparameter α which may be a value between 0 and 1 , or speci ed as decreasing</definiens>
			</definition>
			<definition id="2">
				<sentence>( a ) = strategy trained using 4-gram and tested with 5-gram ; ( b ) = strategy trained with 5-gram and tested with 4-gram ; ( av ) = average ; * signi cance level p &lt; 0.025 ; ** signi cance level p &lt; 0.005 ; *** Note : The Hybrid RL scores ( here updated from ( Henderson et al. , 2005 ) ) are not directly comparable since that system has a larger action set and fewer policy constraints .</sentence>
				<definiendum id="0">Hybrid RL scores</definiendum>
				<definiens id="0">a larger action set and fewer policy constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>BASELINE STRATEGY State : [ emp , emp , emp , emp ] Action : askSlot2 STRATEGY 2 ( UDM ) State : [ emp , emp , emp , emp , user ( quiet ) ] Action : askSlot3 State : [ emp , emp , emp , emp , user ( null ) ] Action : askSlot1 STRATEGY 3 ( USDM ) State : [ emp , emp , emp , emp , askSlot3 , user ( quiet ) ] Action : askSlot3 State : [ emp , emp , emp , emp , askSlot3 , user ( null ) ] Action : giveHelp State : [ emp , emp , emp , emp , giveHelp , user ( quiet ) ] Action : askSlot3 State : [ emp , emp , emp , emp , giveHelp , user ( null ) ] Action : askSlot3 Figure 3 : Examples of the different learned strategies and emergent behaviours : focus switching ( for UDM ) and giving help ( for USDM ) Here we can see that should the user responses continue to fail to provide a slot value , the baseline’s state will be unchanged and so the strategy will simply ask for slot 2 again .</sentence>
				<definiendum id="0">BASELINE STRATEGY State</definiendum>
				<definiendum id="1">UDM</definiendum>
				<definiendum id="2">Action</definiendum>
				<definiens id="0">) State : [ emp , emp , emp , emp , user ( quiet ) ] Action : askSlot3 State : [ emp , emp , emp , emp , user ( null ) ]</definiens>
				<definiens id="1">USDM ) State : [ emp , emp , emp , emp , askSlot3 , user ( quiet ) ] Action : askSlot3 State : [ emp , emp , emp , emp , askSlot3 , user ( null ) ] Action : giveHelp State : [ emp , emp , emp , emp , giveHelp , user ( quiet ) ] Action : askSlot3 State : [ emp , emp , emp , emp</definiens>
			</definition>
</paper>

		<paper id="3002">
			<definition id="0">
				<sentence>Contexts are the feature words appearing in the immediate neighbourhood of a word .</sentence>
				<definiendum id="0">Contexts</definiendum>
				<definiens id="0">the feature words appearing in the immediate neighbourhood of a word</definiens>
			</definition>
			<definition id="1">
				<sentence>Further , CW is parameter-free , operates locally and results in a partitioning of the graph , excluding singletons ( i.e. nodes without edges ) .</sentence>
				<definiendum id="0">CW</definiendum>
				<definiens id="0">nodes without edges</definiens>
			</definition>
</paper>

		<paper id="1138">
</paper>

		<paper id="2054">
			<definition id="0">
				<sentence>A semantic frame ( or template ) is a well-formed and machine readable structure of extracted information consisting of slot/value pairs .</sentence>
				<definiendum id="0">semantic frame</definiendum>
				<definiendum id="1">template )</definiendum>
				<definiens id="0">a well-formed and machine readable structure of extracted information consisting of slot/value pairs</definiens>
			</definition>
			<definition id="1">
				<sentence>A trigger pair is the basic element for extracting information from the long-distance document history .</sentence>
				<definiendum id="0">trigger pair</definiendum>
			</definition>
			<definition id="2">
				<sentence>In this scheme , the MI score of one pair is MI ( A ; B ) = P ( A , B ) log P ( B|A ) P ( B ) +P ( A , ¯B ) log P ( ¯B|A ) P ( ¯B ) + P ( ¯A , B ) log P ( B| ¯A ) P ( ¯B ) +P ( ¯A , ¯B ) log P ( ¯B| ¯A ) P ( ¯B ) .</sentence>
				<definiendum id="0">MI score</definiendum>
				<definiendum id="1">MI</definiendum>
				<definiens id="0">A ; B ) = P ( A , B ) log P ( B|A ) P ( B ) +P ( A , ¯B ) log P ( ¯B|A ) P ( ¯B ) + P</definiens>
			</definition>
			<definition id="3">
				<sentence>The gain of the trigger feature is defined as the improvement in log-likelihood of the current model Λ ( i ) at the i-th iteration according to the following formula : ˆGΛ ( i ) ( g ) = max µ GΛ ( i ) ( g , µ ) = maxµ braceleftBig LΛ ( i ) +g , µ −LΛ ( i ) bracerightBig where µ is a parameter of a trigger feature to be found and g is a corresponding trigger feature function .</sentence>
				<definiendum id="0">gain of the trigger feature</definiendum>
			</definition>
			<definition id="4">
				<sentence>A final model ( a first-order linear chain CRF ) is trained for 100 iterations with a Gaussian prior variance of 20 , and 200 or fewer trigger features ( down to a gain threshold of 1.0 ) for each round of inducing iteration ( 100 iterations of L-BFGS for the ME inducer and 10∼20 iterations of L-BFGS for the CRF inducer ) .</sentence>
				<definiendum id="0">final model</definiendum>
				<definiens id="0">a first-order linear chain CRF ) is trained for 100 iterations with a Gaussian prior variance of 20</definiens>
			</definition>
			<definition id="5">
				<sentence>To capture long-distance dependency , HVS uses a context-free model , which increases the complexity of models .</sentence>
				<definiendum id="0">HVS</definiendum>
				<definiens id="0">uses a context-free model , which increases the complexity of models</definiens>
			</definition>
</paper>

		<paper id="1112">
			<definition id="0">
				<sentence>Answer Extraction is one of basic modules in open domain Question Answering ( QA ) .</sentence>
				<definiendum id="0">Answer Extraction</definiendum>
			</definition>
			<definition id="1">
				<sentence>On one hand , NER reduces the number of candidate answers and eases answer ranking .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">reduces the number of candidate answers and eases answer ranking</definiens>
			</definition>
			<definition id="2">
				<sentence>Dependency relation path is defined as a structure P = &lt; N1 , R , N2 &gt; where , N1 , N2 are two phrases and R is a relation sequence R = &lt; r1 , ... , ri &gt; in which ri is one of the predefined dependency relations .</sentence>
				<definiendum id="0">Dependency relation path</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">a structure P = &lt; N1 , R , N2 &gt; where , N1 , N2 are two phrases and</definiens>
				<definiens id="1">a relation sequence R = &lt; r1 , ... , ri &gt; in which ri is one of the predefined dependency relations</definiens>
			</definition>
			<definition id="3">
				<sentence>DTW is to find an optimal alignment between two sequences which maximizes the accumulated correlation between two sequences .</sentence>
				<definiendum id="0">DTW</definiendum>
				<definiens id="0">to find an optimal alignment between two sequences which maximizes the accumulated correlation between two sequences</definiens>
			</definition>
			<definition id="4">
				<sentence>Cor ( r1 , r2 ) denotes the correlation between two individual relations r1 , r2 , which is estimated by a statistical model during training ( Section 3.3 ) .</sentence>
				<definiendum id="0">Cor</definiendum>
				<definiendum id="1">r2 )</definiendum>
			</definition>
			<definition id="5">
				<sentence>The similarity between two BNPs Sim ( BNPq , BNPs ) is defined as : Sim ( BNPq , BNPs ) = λSim ( Hq , Hs ) + ( 1−λ ) Sim ( Mq , Ms ) Sim ( Hq , Hs ) = summationtext hi∈Hq summationtext hj∈Hs Sim ( hi , hj ) |Hq uniontext Hs| Sim ( Mq , Ms ) = summationtext mi∈Mq summationtext mj∈Ms Sim ( mi , mj ) |Mq uniontext Ms| Furthermore , the similarity between two heads Sim ( hi , hj ) are defined as : • Sim = 1 , if hi = hj after stemming ; • Sim = 1 , if hi = hj after format alternation ; • Sim = SemSim ( hi , hj ) These items consider morphological , format and semantic variations respectively .</sentence>
				<definiendum id="0">BNPs )</definiendum>
				<definiendum id="1">|Hq uniontext Hs| Sim</definiendum>
				<definiens id="0">if hi = hj after stemming ; • Sim = 1 , if hi = hj after format alternation ; • Sim = SemSim ( hi , hj ) These items consider morphological , format and semantic variations respectively</definiens>
			</definition>
			<definition id="6">
				<sentence>Target is a kind of word which indicates the expected answer type of the question , such as ”party” in ”What party led Australia from 1983 to 1996 ? ”</sentence>
				<definiendum id="0">Target</definiendum>
				<definiens id="0">a kind of word which indicates the expected answer type of the question</definiens>
			</definition>
			<definition id="7">
				<sentence>Re-rank formula is defined as follows : Score ( answer ) = α× summationdisplay i Cor ( Pi1 , Pi2 ) where , α is answer ranking score .</sentence>
				<definiendum id="0">Re-rank formula</definiendum>
				<definiens id="0">follows : Score ( answer ) = α× summationdisplay i Cor ( Pi1 , Pi2 ) where , α is answer ranking score</definiens>
			</definition>
			<definition id="8">
				<sentence>The goal of answer extraction is to identify exact answers from given candidate sentence collections for questions .</sentence>
				<definiendum id="0">answer extraction</definiendum>
				<definiens id="0">to identify exact answers from given candidate sentence collections for questions</definiens>
			</definition>
			<definition id="9">
				<sentence>SynPattern matches relation sequences of candidate answers with the predefined relation sequences extracted from a training data set , while StrictMatch matches relation sequences of candidate answers with the corresponding relation sequences in questions .</sentence>
				<definiendum id="0">SynPattern</definiendum>
			</definition>
</paper>

		<paper id="2015">
			<definition id="0">
				<sentence>This assumption comes from the fact that accent pattern in Farsi is in a any that the last or the farthest member of the group ( phrase ) takes the accent , except in marked structures ; and as prepositions do not occur at the end of the phrase ( PPs are head-first , as the other phrases in Farsi ) , they never take the accent .</sentence>
				<definiendum id="0">PPs</definiendum>
				<definiens id="0">the last or the farthest member of the group ( phrase ) takes the accent</definiens>
			</definition>
</paper>

		<paper id="4015">
			<definition id="0">
				<sentence>SAMMIE supports interaction in German and English .</sentence>
				<definiendum id="0">SAMMIE</definiendum>
			</definition>
			<definition id="1">
				<sentence>Our system architecture follows the classical approach ( Bunt et al. , 2005 ) of a pipelined architecture with multimodal interpretation ( fusion ) and 57 U : Show me the Beatles albums .</sentence>
				<definiendum id="0">system architecture</definiendum>
				<definiens id="0">follows the classical approach ( Bunt et al. , 2005 ) of a pipelined architecture with multimodal interpretation</definiens>
			</definition>
			<definition id="2">
				<sentence>The dialogue manager decides on the next system move , based on its model of the tasks as collaborative problem solving , the current context and also the results from calls to the MP3 database .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">decides on the next system move</definiens>
			</definition>
			<definition id="3">
				<sentence>Turn planning takes a set of CPS-specific conversational acts generated by the dialogue manager and maps them to modalityspecific communicative acts .</sentence>
				<definiendum id="0">Turn planning</definiendum>
				<definiens id="0">takes a set of CPS-specific conversational acts generated by the dialogue manager and maps them to modalityspecific communicative acts</definiens>
			</definition>
			<definition id="4">
				<sentence>contextual-info :            last-user-utterance : : bracketleftBigg interp : set ( grounding-acts ) modality-requested : modality modalities-used : set ( msInput ) bracketrightBigg discourse-history : : list ( discourse-objects ) modality-info : : bracketleftBig speech : speechInfo graphic : graphicInfo bracketrightBig user-info : : bracketleftBig cognitive-load : cogLoadInfo user-expertise : expertiseInfo bracketrightBig            task-info : bracketleftBig cps-state : c-situation ( see below for details ) pending-sys-utt : list ( grounding-acts ) bracketrightBig Figure 3 : SAMMIE Information State structure .</sentence>
				<definiendum id="0">msInput</definiendum>
				<definiens id="0">graphicInfo bracketrightBig user-info : : bracketleftBig cognitive-load : cogLoadInfo user-expertise : expertiseInfo bracketrightBig            task-info</definiens>
				<definiens id="1">SAMMIE Information State structure</definiens>
			</definition>
			<definition id="5">
				<sentence>Thereby PATE provides an efficient and elegant way to create more generic presentation planning rules .</sentence>
				<definiendum id="0">PATE</definiendum>
				<definiens id="0">provides an efficient and elegant way to create more generic presentation planning rules</definiens>
			</definition>
</paper>

		<paper id="2060">
			<definition id="0">
				<sentence>At-Least-N Voting induces a spectrum of combi461 nation methods ranging from a Majority Vote ( when N is more than half of the total number of classifiers ) to a scheme , where the evidence of any structure by even one classifier is believed ( At-Least-1 Voting ) .</sentence>
				<definiendum id="0">At-Least-N Voting</definiendum>
				<definiens id="0">induces a spectrum of combi461 nation methods ranging from a Majority Vote ( when N is more than half of the total number of classifiers ) to a scheme , where the evidence of any structure by even one classifier is believed ( At-Least-1 Voting )</definiens>
			</definition>
</paper>

		<paper id="2092">
			<definition id="0">
				<sentence>Aligning parallel text , i.e. automatically setting the sentences or words in one text into correspondence with their equivalents in a translation , is a very useful preprocessing step for a range of applications , including but not limited to machine translation ( Brown et al. , 1993 ) , cross-language information retrieval ( Hiemstra , 1996 ) , dictionary creation ( Smadja et al. , 1996 ) and induction of NLP-tools ( Kuhn , 2004 ) .</sentence>
				<definiendum id="0">induction of NLP-tools</definiendum>
				<definiens id="0">automatically setting the sentences or words in one text into correspondence with their equivalents in a translation , is a very useful preprocessing step for a range of applications , including but not limited to machine translation ( Brown et al. , 1993 ) , cross-language information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>The core component adds all new information to its knowledge bases , and hands it over to appropriate alignment modules for further computation .</sentence>
				<definiendum id="0">core component</definiendum>
				<definiens id="0">adds all new information to its knowledge bases , and hands it over to appropriate alignment modules for further computation</definiens>
			</definition>
			<definition id="2">
				<sentence>Europarl consists of roughly 30 million tokens per language and is tokenized and sentencealigned .</sentence>
				<definiendum id="0">Europarl</definiendum>
				<definiens id="0">consists of roughly 30 million tokens per language and is tokenized and sentencealigned</definiens>
			</definition>
</paper>

		<paper id="1058">
			<definition id="0">
				<sentence>Word sense disambiguation ( WSD ) has been a hot topic in natural language processing , which is to determine the sense of an ambiguous word in a specific context .</sentence>
				<definiendum id="0">Word sense disambiguation ( WSD</definiendum>
				<definiens id="0">a hot topic in natural language processing , which is to determine the sense of an ambiguous word in a specific context</definiens>
			</definition>
			<definition id="1">
				<sentence>Automatic corpus tagging is a solution to WSD , which generates large-scale corpus from a small seed corpus .</sentence>
				<definiendum id="0">Automatic corpus tagging</definiendum>
				<definiens id="0">a solution to WSD , which generates large-scale corpus from a small seed corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>Synonymous Monosemous Words for the Ambiguous Word `` 把握 `` The equivalence of the EP with the real ambiguous word is a kind of semantic synonym or similarity , which demands a maximum similarity between the two words .</sentence>
				<definiendum id="0">Synonymous Monosemous Words for the Ambiguous Word `` 把握</definiendum>
				<definiens id="0">a kind of semantic synonym or similarity , which demands a maximum similarity between the two words</definiens>
			</definition>
			<definition id="3">
				<sentence>EP is a solution to data sparseness for lack of human tagging in WSD .</sentence>
				<definiendum id="0">EP</definiendum>
				<definiens id="0">a solution to data sparseness for lack of human tagging in WSD</definiens>
			</definition>
			<definition id="4">
				<sentence>This is a remarkable feature of the EP , which originates from its equivalent linguistic function with the original word .</sentence>
				<definiendum id="0">EP</definiendum>
				<definiens id="0">originates from its equivalent linguistic function with the original word</definiens>
			</definition>
			<definition id="5">
				<sentence>Words in the same fifth level node have the same sense and linguistic function , which ensures that they can substitute for each other without leading to any change in the meaning of a sentence .</sentence>
				<definiendum id="0">linguistic function</definiendum>
				<definiens id="0">ensures that they can substitute for each other without leading to any change in the meaning of a sentence</definiens>
			</definition>
			<definition id="6">
				<sentence>An EP is described as follows : i ikiiii k k WWWWS WWWWS WWWWS L MMMMMM L L , , , : , , , : , , , : 321 22322212 11312111 2 1 W EP —————————— Where W EP is the EP word , S i is a sense of the ambiguous word , and W ik is a morpheme word of the EP .</sentence>
				<definiendum id="0">W EP</definiendum>
				<definiendum id="1">W ik</definiendum>
				<definiens id="0">a morpheme word of the EP</definiens>
			</definition>
			<definition id="7">
				<sentence>The F-measure for the Supervised WSD EP is a solution to the semantic knowledge acquisition problem , and it does not limit the choice of statistical learning methods .</sentence>
				<definiendum id="0">F-measure for the Supervised WSD EP</definiendum>
				<definiens id="0">a solution to the semantic knowledge acquisition problem</definiens>
			</definition>
			<definition id="8">
				<sentence>The Bayesian classifier used in this paper is described in ( 1 ) ⎥ ⎥ ⎦ ⎤ ⎢ ⎢ ⎣ ⎡ += ∑ ∈ ij k cv kjkSi SvPSPwS ) | ( log ) ( logmaxarg ) ( ( 1 ) Where w i is the ambiguous word , is the occurrence probability of the sense S ) ( k SP k , is the conditional probability of the context word v ) | ( kj SvP j , and c i is the set of the context words .</sentence>
				<definiendum id="0">Bayesian classifier</definiendum>
				<definiendum id="1">c i</definiendum>
				<definiens id="0">the conditional probability of the context word v</definiens>
				<definiens id="1">the set of the context words</definiens>
			</definition>
			<definition id="9">
				<sentence>RP RP F + ×× = 2 ( 2 ) 461 Where P and R refer to the precision and recall of the sense tagging respectively , which are calculated as shown in ( 3 ) and ( 4 ) ) tagged ( ) correct ( C C P = ( 3 ) ) all ( ) correct ( C C R = ( 4 ) Where C ( tagged ) is the number of tagged instances of senses , C ( correct ) is the number of correct tags , and C ( all ) is the number of tags in the gold standard set .</sentence>
				<definiendum id="0">C ( correct )</definiendum>
				<definiendum id="1">C ( all )</definiendum>
				<definiens id="0">the number of tagged instances of senses</definiens>
				<definiens id="1">the number of correct tags , and</definiens>
				<definiens id="2">the number of tags in the gold standard set</definiens>
			</definition>
			<definition id="10">
				<sentence>Exploiting Parallel Texts for Word Sense Disambiguation : An Empirical Study .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
			</definition>
			<definition id="11">
				<sentence>Decision Lists for Lexical Ambiguity Resolution : Application to Accent Restoration in Spanish and French .</sentence>
				<definiendum id="0">Decision Lists</definiendum>
			</definition>
</paper>

		<paper id="1079">
			<definition id="0">
				<sentence>Zero-anaphora is a gap in a sentence that has an anaphoric function similar to a pro-form ( e.g. pronoun ) and is often described as “referring back” to an expression that supplies the information necessary for interpreting the sentence .</sentence>
				<definiendum id="0">Zero-anaphora</definiendum>
				<definiens id="0">a gap in a sentence that has an anaphoric function similar to a pro-form ( e.g. pronoun</definiens>
			</definition>
			<definition id="1">
				<sentence>In AR , the research trend has been shifting from rulebased approaches ( Baldwin , 1995 ; Lappin and Leass , 1994 ; Mitkov , 1997 , etc. ) to empirical , or corpus-based , approaches ( McCarthy and Lehnert , 1995 ; Ng and Cardie , 2002a ; Soon et al. , 2001 ; Strube and M¨uller , 2003 ; Yang et al. , 2003 ) because the latter are shown to be a cost-efficient solution achieving a performance that is comparable to best performing rule-based systems ( see the Coreference task in MUC1 and the Entity Detection and Tracking task in the ACE program2 ) .</sentence>
				<definiendum id="0">Entity Detection</definiendum>
			</definition>
			<definition id="2">
				<sentence>Finally , to encode the order of siblings and reduce data sparseness , we further transform the extracted path as in Figure 1 ( c ) : • A path is represented by a subtree consisting of backbone nodes : φ ( zero-pronoun ) , Ant ( antecedent ) , Node ( the lowest common ancestor ) , LeftNode ( left-branch node ) and RightNode .</sentence>
				<definiendum id="0">Node (</definiendum>
				<definiens id="0">the lowest common ancestor ) , LeftNode ( left-branch node ) and RightNode</definiens>
			</definition>
			<definition id="3">
				<sentence>Each decision stump is associated with tuple 〈t , l , w〉 , where t is a subtree appearing in the training set , l a label , and w a weight , indicating that if a given input includes t , it gives w votes to l. The strength of this algorithm is that it deals with structured feature and allows us to analyze the utility of features .</sentence>
				<definiendum id="0">t</definiendum>
				<definiens id="0">it deals with structured feature and allows us to analyze the utility of features</definiens>
			</definition>
			<definition id="4">
				<sentence>Analogously , for anaphoricity determination , we use trees ( TC , f1 , ... , fn ) , where TC denotes a path subtree as in Figure 1 ( c ) .</sentence>
				<definiendum id="0">TC</definiendum>
				<definiens id="0">trees ( TC , f1 , ... , fn ) , where</definiens>
				<definiens id="1">a path subtree as in Figure 1 ( c )</definiens>
			</definition>
			<definition id="5">
				<sentence>( 262 zero-pronouns ) and the rest ( 733 zeropronouns ) , where “IN Q” denotes the former ( inquote zero-pronouns ) and “OUT Q” the latter .</sentence>
				<definiendum id="0">“IN Q”</definiendum>
				<definiens id="0">the former ( inquote zero-pronouns</definiens>
			</definition>
</paper>

		<paper id="1122">
			<definition id="0">
				<sentence>A clustering of the lexicon is a unique mapping CF : F → CF defined for allf ∈ F where , in addition to all source types observed in the parallel training corpus , F may include items seen in other monolingual corpora ( and , in the case of the source lexicon only , the development and test data ) .</sentence>
				<definiendum id="0">clustering of the lexicon</definiendum>
			</definition>
			<definition id="1">
				<sentence>We optimise a conditional model of target tokens from word-aligned parallel corpora , D = { Dc0 , ... , DcN } , where Dci represents the set of target words that were aligned to the set of source types in cluster ci .</sentence>
				<definiendum id="0">Dci</definiendum>
				<definiens id="0">the set of target words that were aligned to the set of source types in cluster ci</definiens>
			</definition>
			<definition id="2">
				<sentence>Given a clustering , the Dirichlet prior , and independent parameters , the distribution over data and parameters factorises , p ( D , µ|CF , α ) = productdisplay cf∈CF p ( Dcf , µcf|cf , α ) ∝ productdisplay cf∈CF productdisplay e∈E µα−1+ # cf ( e ) cf , e We optimise cluster assignments with respect to the marginal likelihood which averages the likelihood of the set of counts assigned to a cluster , Dcf , under the current model over the prior , p ( Dcf|α , cf ) = integraldisplay p ( µcf|α ) p ( Dcf|µcf , cf ) dµcf .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the Dirichlet prior , and independent parameters , the distribution over data and parameters factorises , p ( D , µ|CF , α ) = productdisplay cf∈CF p</definiens>
				<definiens id="1">averages the likelihood of the set of counts assigned to a cluster , Dcf , under the current model over the prior</definiens>
			</definition>
			<definition id="3">
				<sentence>1 shows a section of the complete model including the MRF prior for a Welsh source lexicon ; shading denotes cluster assignments and English target tokens are shown as directed nodes.2 From the Markov property it follows that this prior decomposes over neighbourhoods , pMRF ( C ) ∝eβ summationtext f∈F summationtext fprime∈Nf summationtext iλiψi ( f , f prime , cf , cprime f ) Here Nf is the set of neighbours of source typef ; iindexes a set of functionsψi ( · ) that pick out features of a clique ; each function has a parameterλi 2The plates represent repeated sampling ; each Welsh source type may be aligned to multiple English tokens .</sentence>
				<definiendum id="0">Nf</definiendum>
				<definiens id="0">a section of the complete model including the MRF prior for a Welsh source lexicon ; shading denotes cluster assignments and English target tokens are shown as directed nodes.2 From the Markov property it follows that this prior decomposes over neighbourhoods , pMRF ( C ) ∝eβ summationtext f∈F summationtext fprime∈Nf summationtext iλiψi</definiens>
				<definiens id="1">the set of neighbours of source typef</definiens>
			</definition>
			<definition id="4">
				<sentence>β is a free parameter used to control the overall contribution of the prior in Eq .</sentence>
				<definiendum id="0">β</definiendum>
				<definiens id="0">a free parameter used to control the overall contribution of the prior in Eq</definiens>
			</definition>
			<definition id="5">
				<sentence>The algorithm has two free parameters : αdetermining the strength of the Dirichlet prior used in the marginal likelihood , p ( D|C ) , andβ which determines the contribution ofpMRF ( C ) to Eq .</sentence>
				<definiendum id="0">ofpMRF</definiendum>
				<definiens id="0">two free parameters : αdetermining the strength of the Dirichlet prior used in the marginal likelihood , p ( D|C )</definiens>
			</definition>
			<definition id="6">
				<sentence>Phrase-based SMT systems have been shown to outperform word-based approaches ( Koehn et al. , 2003 ) .</sentence>
				<definiendum id="0">Phrase-based SMT systems</definiendum>
			</definition>
</paper>

		<paper id="1105">
			<definition id="0">
				<sentence>Like ( Shirai , 1998 ) , to take into account the reliance of the co-occurrence probability of the particle set on the syntactic property of a verb , instead of using P ( rsi ( T ) |vi ( T ) ) in Equation ( 5 ) , we use P ( rsi ( T ) |syni ( T ) , vi ( T ) ) , where syni ( T ) is the syntactic property of the i-th verb in T and takes one of the following three values : ‘verb’ when v modiﬁes another verb ‘noun’ when v modiﬁes a noun ‘main’ when v modiﬁes nothing ( when it is at the end of the sentence , and is the main verb ) Here , weillustratetheprocessofapplyingourproposed model to the example sentence in Figure 1 , for which there are four possible combinations of dependency relations .</sentence>
				<definiendum id="0">syni</definiendum>
				<definiendum id="1">T )</definiendum>
				<definiens id="0">rsi ( T ) |syni ( T ) , vi ( T ) )</definiens>
				<definiens id="1">the syntactic property of the i-th verb in T and takes one of the following three values</definiens>
			</definition>
			<definition id="1">
				<sentence>Therefore the variance of the reranking model ( Equation [ 8 ] ) , which is the combination of our proposed model and the posterior context model , is close to that of the test data .</sentence>
				<definiendum id="0">] )</definiendum>
			</definition>
</paper>

		<paper id="2074">
			<definition id="0">
				<sentence>Information Extraction ( IE ) is a fundamental technology for NLP .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
				<definiens id="0">a fundamental technology for NLP</definiens>
			</definition>
			<definition id="1">
				<sentence>Information Extraction ( IE ) is one of the fundamental problems of natural language processing .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE )</definiendum>
				<definiens id="0">one of the fundamental problems of natural language processing</definiens>
			</definition>
			<definition id="2">
				<sentence>The terrorism template consists of slots Perpetrator , Victim and Target ; the slots in the management succession template are Org , PersonIn , PersonOut and Post .</sentence>
				<definiendum id="0">terrorism template</definiendum>
				<definiens id="0">consists of slots Perpetrator , Victim and Target ; the slots in the management succession template are Org , PersonIn , PersonOut and Post</definiens>
			</definition>
			<definition id="3">
				<sentence>Features Perpetrator_Cue ( A ) Action_Cue ( D ) Victim_Cue ( A ) Target_Cue ( A ) Lexical ( Head noun ) terrorists , individuals , soldiers attacked , murder , massacre mayor , general , priests bridge , house , ministry Part-ofSpeech Noun Verb Noun Noun Named Entities Soldiers ( PERSON ) Jesuit priests ( PERSON ) WTC ( OBJECT ) Synonyms Synset 130 , 166 Synset 22 Synset 68 Synset 71 Concept Class ID 2 , 3 ID 9 ID 22 , 43 ID 61 , 48 Coreferenced entity He - &gt; terrorist , soldier They - &gt; peasants Table 1 .</sentence>
				<definiendum id="0">Features Perpetrator_Cue</definiendum>
				<definiens id="0">general , priests bridge , house , ministry Part-ofSpeech Noun Verb Noun Noun Named Entities Soldiers ( PERSON ) Jesuit priests ( PERSON</definiens>
			</definition>
			<definition id="4">
				<sentence>We use the following formula to capture the quality of a relation Rel which gives higher weight to more frequently occurring relations : ) 3 ( || } | { || || } , | { || ) , , ( 21 ∑ ∑ ∈ =∈ = S iii S iii SRR elRRRRR AAleRQuality where S is a set of sentences containing relation Rel , anchors A 1 and A 2 ; R denotes relation path connecting A 1 and A 2 in a sentence S i ; ||X|| denotes size of the set X. Second , we need to take into account the entity height in the dependency tree .</sentence>
				<definiendum id="0">relation Rel</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">R</definiendum>
				<definiens id="0">a set of sentences containing relation Rel , anchors A 1 and A 2 ;</definiens>
			</definition>
			<definition id="5">
				<sentence>Therefore , we give a slightly higher weight to the links that are closer to the root node as follows : Height s ( Rel ) = log 2 ( Const – Distance ( Root , Rel ) ) ( 4 ) where Const is set to be larger than the depth of nodes in the tree .</sentence>
				<definiendum id="0">Height s</definiendum>
				<definiens id="0">set to be larger than the depth of nodes in the tree</definiens>
			</definition>
			<definition id="6">
				<sentence>The path score of R i- &gt; j depends on both quality and height of participating relations : Score s ( A i , A j ) =Σ Ri∈R { Height s ( R i ) *Quality ( R i ) } /Length ij ( 5 ) where Length ij is the length of path R i- &gt; j .</sentence>
				<definiendum id="0">Score s</definiendum>
				<definiens id="0">the length of path R i- &gt; j</definiens>
			</definition>
			<definition id="7">
				<sentence>Based on the previously defined Score S ( A i , A j ) , it is possible to rank all the fillings in F. For each filling F i ∈F we calculate the aggregate score for all the involved anchor pairs : ) 7 ( ) , ( ) ( _ ,1 M AAcoreS FScoreelationR jiS Kji iS ∑ ≤≤ = where K is number of slot types and M denotes the number of relation paths between anchors in F i .</sentence>
				<definiendum id="0">M</definiendum>
				<definiens id="0">the aggregate score for all the involved anchor pairs : ) 7 ( ) , ( ) ( _ ,1 M AAcoreS FScoreelationR jiS Kji iS ∑ ≤≤ = where K is number of slot types</definiens>
				<definiens id="1">the number of relation paths between anchors in F i</definiens>
			</definition>
			<definition id="8">
				<sentence>Category 1 is when the potential SVO’s are connected directly to each other ( simple category ) ; Category 2 is when S or O is one link away from V in terms of nouns or verbs ( average category ) ; and Category 3 is when the path distances between potential S , V , and Os are more than 2 links away ( hard category ) .</sentence>
				<definiendum id="0">Os</definiendum>
				<definiens id="0">one link away from V in terms of nouns or verbs ( average category</definiens>
			</definition>
			<definition id="9">
				<sentence>We notice that in the simple category , the perpetrator cue ( ‘terrorists’ ) is always a subject , action cue ( ‘kidnapped’ ) a verb , and victim cue ( ‘peasants’ ) an object .</sentence>
				<definiendum id="0">perpetrator cue</definiendum>
				<definiens id="0">always a subject , action cue ( ‘kidnapped’ ) a verb , and victim cue ( ‘peasants’ ) an object</definiens>
			</definition>
			<definition id="10">
				<sentence>The input of the algorithm consists of sentences S 1 …S N and two sets of tokens V neg , V pos co-occurring with anchor cue of type D. V neg and V pos are automatically tagged as irrelevant and relevant respectively based on preliminary marked keys in the training instances .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">V pos</definiendum>
			</definition>
			<definition id="11">
				<sentence>The algorithm output represents the importance value between 0 to 1 .</sentence>
				<definiendum id="0">algorithm output</definiendum>
				<definiens id="0">the importance value between 0 to 1</definiens>
			</definition>
			<definition id="12">
				<sentence>CalculateImportance ( W , D ) 1 ) Select sentences that contain anchor cue D 2 ) Extract linguistic features of V pos , V neg and D 3 ) Train using SVM on instances ( V pos , D ) and instances ( V neg , D ) 4 ) Return Importance ( W ) using SVM FindOptimalPromotion ( F i ) 1 ) Z = ∅ 2 ) For each A i ( j1 ) , A i ( j2 ) ∈ F i Z = Z ∪ P j1- &gt; j2 End_for 3 ) Output Top ( Z ) 576 In order to evaluate the efficiency of our method , we conduct our experiments in 2 domains : MUC4 ( Kaufmann , 1992 ) and MUC6 ( Kaufmann , 1995 ) .</sentence>
				<definiendum id="0">CalculateImportance</definiendum>
				<definiendum id="1">V pos</definiendum>
				<definiendum id="2">MUC4</definiendum>
				<definiens id="0">sentences that contain anchor cue D 2 ) Extract linguistic features of V pos , V neg</definiens>
			</definition>
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>CRFs are basically defined as a discriminative model of Markov random fields conditioned on inputs ( observations ) x. Unlike generative models , CRFs model only the output y’s distribution over x. This allows CRFs to use flexible features such as complicated functions of multiple observations .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiens id="0">a discriminative model of Markov random fields conditioned on inputs ( observations ) x. Unlike generative models , CRFs model only the output y’s distribution over x. This allows CRFs to use flexible features such as complicated functions of multiple observations</definiens>
			</definition>
			<definition id="1">
				<sentence>The maximum a posteriori ( MAP ) criterion over parameters , λ , given x and y is the natural choice for reducing over-fitting ( Sha and Pereira , 2003 ) .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">maximum a posteriori ( MAP ) criterion over parameters , λ , given x</definiens>
			</definition>
			<definition id="2">
				<sentence>Zλ ( x ) =summationtext ˜y∈Y producttext c∈C ( ˜y , x ) Φc ( ˜y , x ; λ ) is a normalization factor over all output values , Y. Following the definitions of ( Sha and Pereira , 2003 ) , a log-linear combination of weighted features , Φc ( y , x ; λ ) = exp ( λ fc ( y , x ) ) , is used as individual potential functions , where fc represents a feature vector obtained from the corresponding clique c. That is , producttextc∈C ( y , x ) Φc ( y , x ) = exp ( λ F ( y , x ) ) , where F ( y , x ) =summationtextc fc ( y , x ) is the CRF’s global feature vector for x and y. The most probable output ˆy is given by ˆy = arg maxy∈Y p ( yjx ; λ ) .</sentence>
				<definiendum id="0">Zλ ( x ) =summationtext ˜y∈Y producttext c∈C</definiendum>
				<definiendum id="1">λ )</definiendum>
				<definiendum id="2">fc</definiendum>
				<definiendum id="3">y , x )</definiendum>
				<definiens id="0">a normalization factor over all output values</definiens>
			</definition>
			<definition id="3">
				<sentence>( 1 ) The maximum ( log- ) likelihood ( ML ) of the conditional probability p ( yjx ; λ ) of training data f ( xk , y∗k ) gNk=1 w.r.t. parameters λ is the most basic CRF training criterion , that is , arg maxλ summationtextk logp ( y∗kjxk ; λ ) , where y∗k is the correct output for the given xk .</sentence>
				<definiendum id="0">y∗k</definiendum>
				<definiens id="0">log- ) likelihood ( ML ) of the conditional probability p ( yjx ; λ ) of training data f ( xk , y∗k ) gNk=1 w.r.t. parameters λ is the most basic CRF training criterion , that is , arg maxλ summationtextk logp</definiens>
			</definition>
			<definition id="4">
				<sentence>The Minimum Classification Error ( MCE ) framework first arose out of a broader family of approaches to pattern classifier design known as Generalized Probabilistic Descent ( GPD ) ( Katagiri et al. , 1991 ) .</sentence>
				<definiendum id="0">Minimum Classification Error ( MCE</definiendum>
				<definiendum id="1">Generalized Probabilistic Descent ( GPD</definiendum>
			</definition>
			<definition id="5">
				<sentence>The MCE criterion minimizes an empirical loss corresponding to a smooth approximation of the classification error .</sentence>
				<definiendum id="0">MCE criterion</definiendum>
				<definiens id="0">minimizes an empirical loss corresponding to a smooth approximation of the classification error</definiens>
			</definition>
			<definition id="6">
				<sentence>ψ is a positive constant that represents Lψ-norm .</sentence>
				<definiendum id="0">ψ</definiendum>
			</definition>
			<definition id="7">
				<sentence>7 w.r.t. parameters λ is written in this form : ∂d ( ) ∂ = − Zλ ( x , ψ ) Zλ ( x , ψ ) −exp ( ψg∗ ) ·F ( y ∗ , x ) + summationdisplay y∈Y bracketleftbigg exp ( ψg ) Zλ ( x , ψ ) −exp ( ψg∗ ) ·F ( y , x ) bracketrightbigg ( 12 ) where g = λ F ( y , x ) , g∗ = λ F ( y∗ , x ) , and Zλ ( x , ψ ) =summationtexty∈Y exp ( ψg ) .</sentence>
				<definiendum id="0">Zλ</definiendum>
				<definiens id="0">∂d ( ) ∂ = − Zλ ( x , ψ ) Zλ ( x , ψ ) −exp ( ψg∗ ) ·F ( y ∗ , x ) + summationdisplay y∈Y bracketleftbigg exp</definiens>
			</definition>
			<definition id="8">
				<sentence>Sequential segmentation tasks ( SSTs ) , such as text chunking ( Chunking ) and named entity recognition ( NER ) , which constitute the shared tasks of the Conference of Natural Language Learning ( CoNLL ) 2000 , 2002 and 2003 , are typical CRF applications .</sentence>
				<definiendum id="0">Sequential segmentation tasks ( SSTs</definiendum>
			</definition>
			<definition id="9">
				<sentence>B-ORG I-ORG O OOB-PER I-PER B-LOC O x : y : Seg. : ORG PER LOC Text Chunking Named Entity Recognition y1 y2 y3 y4 y5 y6 y7 y8 y9 y10 y11 y12 y13 y14Dep. : y1 y2 y3 y4 y5 y6 y7 y8 y9Dep. : Figure 1 : Examples of sequential segmentation tasks ( SSTs ) : text chunking ( Chunking ) and named entity recognition ( NER ) .</sentence>
				<definiendum id="0">B-ORG I-ORG O OOB-PER I-PER B-LOC O x</definiendum>
				<definiens id="0">Examples of sequential segmentation tasks ( SSTs ) : text chunking ( Chunking ) and named entity recognition</definiens>
			</definition>
			<definition id="10">
				<sentence>The point-wise discriminant function can be written as follows : g ( y , x , i , ) = maxyprime ∈Y|y| [ yi ] ·F ( yprime , x ) ( 14 ) where Yj represents a set of all y whose length is j , and Y [ yi ] represents a set of all y that contain yi in the i’th position .</sentence>
				<definiendum id="0">Yj</definiendum>
				<definiens id="0">a set of all y whose length is j</definiens>
			</definition>
			<definition id="11">
				<sentence>Let ysj be an output sequence corresponding to the j-th segment of y , where sj represents a sequence of indices of y , that is , sj = ( sj,1 , ... , sj , |sj| ) .</sentence>
				<definiendum id="0">sj</definiendum>
				<definiens id="0">a sequence of indices of y , that is , sj = ( sj,1 , ... , sj , |sj| )</definiens>
			</definition>
			<definition id="12">
				<sentence>Then , approximated evaluation functions of TP , FP and FN can be defined as follows : TPl = summationdisplay k summationdisplay s∗j∈s∗k bracketleftBig 1−l ( d ( y∗k , xk , s∗j , ) ) bracketrightBig ·δ ( s∗j ) FPl = summationdisplay k summationdisplay sprimej∈S ( xk ) \s∗k l ( d ( y∗k , xk , sprimej , ) ) ·δ ( sprimej ) FNl = summationdisplay k summationdisplay s∗j∈s∗k l ( d ( y∗k , xk , s∗j , ) ) ·δ ( s∗j ) where δ ( sj ) returns 1 if segment sj is a target segment , and returns 0 otherwise .</sentence>
				<definiendum id="0">segment sj</definiendum>
				<definiens id="0">approximated evaluation functions of TP , FP and FN can be defined as follows : TPl = summationdisplay k summationdisplay s∗j∈s∗k bracketleftBig 1−l ( d ( y∗k , xk , s∗j , ) ) bracketrightBig ·δ ( s∗j ) FPl = summationdisplay k summationdisplay sprimej∈S ( xk ) \s∗k l ( d ( y∗k , xk , sprimej , ) ) ·δ ( sprimej ) FNl = summationdisplay k summationdisplay s∗j∈s∗k l ( d ( y∗k , xk , s∗j , ) ) ·δ ( s∗j ) where δ</definiens>
				<definiens id="1">a target segment , and returns 0 otherwise</definiens>
			</definition>
			<definition id="13">
				<sentence>Chunking data was obtained from the Wall Street Journal ( WSJ ) corpus : sections 15-18 as training data ( 8,936 sentences and 211,727 tokens ) , and section 20 as test data ( 2,012 sentences and 47,377 tokens ) , with 11 different chunk-tags , such as NP and VP plus the ‘O’ tag , which represents the outside of any target chunk ( segment ) .</sentence>
				<definiendum id="0">‘O’ tag</definiendum>
				<definiens id="0">8,936 sentences and 211,727 tokens ) , and section 20 as test data ( 2,012 sentences and 47,377 tokens ) , with 11 different chunk-tags</definiens>
			</definition>
			<definition id="14">
				<sentence>The data consists of 203,621 , 51,362 and 46,435 tokens from 14,987 , 3,466 and 3,684 sentences in training , development and test data , respectively , with four named entity tags , PERSON , LOCATION , ORGANIZATION and MISC , plus the ‘O’ tag .</sentence>
				<definiendum id="0">data</definiendum>
				<definiens id="0">consists of 203,621 , 51,362 and 46,435 tokens from 14,987 , 3,466 and 3,684 sentences in training , development and test data , respectively , with four named entity tags , PERSON , LOCATION , ORGANIZATION and MISC , plus the ‘O’ tag</definiens>
			</definition>
			<definition id="15">
				<sentence>We selected a value of C from 1.0 10n where n takes a value from -5 to 5 in intervals 1 by development data3 .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">takes a value from -5 to 5 in intervals 1 by development data3</definiens>
			</definition>
			<definition id="16">
				<sentence>The only difference between MCE ( sig ) and MCE-F is the objective function .</sentence>
				<definiendum id="0">MCE-F</definiendum>
			</definition>
</paper>

		<paper id="2116">
			<definition id="0">
				<sentence>Certainly there are hierarchical relationship between attributes ; for example , Ass1 is a subtype of Assignments .</sentence>
				<definiendum id="0">Ass1</definiendum>
				<definiens id="0">a subtype of Assignments</definiens>
			</definition>
			<definition id="1">
				<sentence>A nested model can be seen as a generalization of the flat model , in which attributes may be related through composition or inheritance .</sentence>
				<definiendum id="0">nested model</definiendum>
				<definiens id="0">a generalization of the flat model , in which attributes may be related through composition or inheritance</definiens>
			</definition>
			<definition id="2">
				<sentence>First , the probabilistic grammar approach permits a cleaner encapsulation and generalization of the kind of knowledge that previous models attempted to capture within their ad hoc heuristics .</sentence>
				<definiendum id="0">probabilistic grammar approach</definiendum>
				<definiens id="0">permits a cleaner encapsulation and generalization of the kind of knowledge that previous models attempted to capture within their ad hoc heuristics</definiens>
			</definition>
			<definition id="3">
				<sentence>Each type is a tuple of the form ( R , O , S ) , where R is the relevant data model , O is the reading orientation of R , and S is a boolean saying if a schema ( i.e. attributes ) exist in the table .</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">O</definiendum>
				<definiendum id="2">S</definiendum>
				<definiens id="0">a tuple of the form ( R , O , S ) , where</definiens>
				<definiens id="1">the relevant data model</definiens>
				<definiens id="2">the reading orientation of R , and</definiens>
				<definiens id="3">a boolean saying if a schema ( i.e. attributes ) exist in the table</definiens>
			</definition>
</paper>

		<paper id="4014">
			<definition id="0">
				<sentence>Broadly speaking , MRS is a at , eventbased ( neo-Davidsonian ) framework for computational semantics .</sentence>
				<definiendum id="0">MRS</definiendum>
				<definiens id="0">a at , eventbased ( neo-Davidsonian ) framework for computational semantics</definiens>
			</definition>
			<definition id="1">
				<sentence>Likewise , the SEM-I incorporates some ontological information , e.g. a classi cation of temporal entities , though crucially only to the extent that is actually grammaticized in the language proper .</sentence>
				<definiendum id="0">SEM-I</definiendum>
				<definiens id="0">incorporates some ontological information</definiens>
			</definition>
			<definition id="2">
				<sentence>To deal with competing hypotheses at all processing levels , LOGON incorporates various stochastic processes for disambiguation .</sentence>
				<definiendum id="0">LOGON</definiendum>
				<definiens id="0">incorporates various stochastic processes for disambiguation</definiens>
			</definition>
			<definition id="3">
				<sentence>Realization Ranking At an average of more than fty English realizations per input MRS ( see Table 1 ) , ranking generator outputs is a vital part of the LOGON pipeline .</sentence>
				<definiendum id="0">Realization Ranking At</definiendum>
				<definiens id="0">a vital part of the LOGON pipeline</definiens>
			</definition>
			<definition id="4">
				<sentence>By association to the international open-source DELPHIN effort2 and with its strong emphasis on reusability , LOGON aims to help build a repository of open-source precision tools .</sentence>
				<definiendum id="0">LOGON</definiendum>
				<definiens id="0">aims to help build a repository of open-source precision tools</definiens>
			</definition>
</paper>

		<paper id="2101">
			<definition id="0">
				<sentence>The log of this likelihood is a convex function of the parameters θ : max θ summationdisplay i logpθ ( y∗i | xi ) ( 4 ) where y∗i is the true analysis of sentence xi .</sentence>
				<definiendum id="0">summationdisplay i logpθ</definiendum>
				<definiendum id="1">y∗i</definiendum>
				<definiens id="0">a convex function of the parameters θ : max θ</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure3 shows how the smoothing is gradually weakened to reach the risk objective ( 3 ) as γ → 1 and approach the true error objective ( 2 ) as γ → ∞ .</sentence>
				<definiendum id="0">Figure3</definiendum>
				<definiens id="0">shows how the smoothing is gradually weakened to reach the risk objective ( 3 ) as γ → 1 and approach the true error objective ( 2 ) as γ → ∞</definiens>
			</definition>
			<definition id="2">
				<sentence>A linear metric is a sum ( or other linear combination ) of the loss or gain on individual sentences .</sentence>
				<definiendum id="0">linear metric</definiendum>
				<definiens id="0">a sum ( or other linear combination ) of the loss or gain on individual sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>One common example is precision , P def= summationtexti ci/summationtexti ai , where ci is the number of correctly posited elements , and ai is the total number of posited elements , in the decoding of sentence i. ( Depending on the task , the elements may be words , bigrams , labeled constituents , etc. ) Our goal is to maximize P , so during a step of deterministic annealing , we need to maximize the expectation of P when the sentences are decoded randomly according to equation ( 5 ) .</sentence>
				<definiendum id="0">ci</definiendum>
				<definiendum id="1">ai</definiendum>
				<definiens id="0">the number of correctly posited elements</definiens>
			</definition>
			<definition id="4">
				<sentence>To approximate E [ g ( A ) ] , where g is any twicedifferentiable function ( here g = log ) , we can approximate g locally by a quadratic , given by the Taylorexpansionofg aboutA’smeanµA = E [ A ] : E [ g ( A ) ] ≈ E [ g ( µA ) + ( A−µA ) gprime ( µA ) +12 ( A−µA ) 2gprimeprime ( µA ) ] = g ( µA ) + E [ A−µA ] gprime ( µA ) +12E [ ( A−µA ) 2 ] gprimeprime ( µA ) = g ( µA ) + 12σ2Agprimeprime ( µA ) .</sentence>
				<definiendum id="0">g</definiendum>
				<definiens id="0">any twicedifferentiable function ( here g = log )</definiens>
			</definition>
			<definition id="5">
				<sentence>Similar techniques can be used to compute the expected logarithms of some other non-linear metrics , such as F-measure ( the harmonic mean of precision and recall ) 6 and Papineni et al. ( 2002 ) ’s 5This changes the trajectory that DA takes through parameter space , but ultimately the objective is the same : as γ → ∞ over the course of DA , minimizing E [ −logP ] becomes indistinguishable from maximizing E [ P ] .</sentence>
				<definiendum id="0">Similar techniques</definiendum>
			</definition>
			<definition id="6">
				<sentence>790 BLEU translation metric ( the geometric mean of several precisions ) .</sentence>
				<definiendum id="0">BLEU translation metric</definiendum>
			</definition>
			<definition id="7">
				<sentence>In particular , the expectation of log BLEU distributes over its N +1 summands : log BLEU = min ( 1 − rA 1 ,0 ) + Nsummationdisplay n=1 wn logPn where Pn is the precision of the n-gram elements in the decoding.7 As is standard in MT research , we take wn = 1/N and N = 4 .</sentence>
				<definiendum id="0">Pn</definiendum>
				<definiens id="0">the precision of the n-gram elements in the</definiens>
			</definition>
</paper>

		<paper id="2099">
			<definition id="0">
				<sentence>In the figure , “expression” is a linguistic expression for the action ; “action plan” is a sequence of action primitives , which are the minimum action units for animation generation .</sentence>
				<definiendum id="0">“expression”</definiendum>
				<definiendum id="1">“action plan”</definiendum>
				<definiens id="0">a linguistic expression for the action ;</definiens>
				<definiens id="1">a sequence of action primitives , which are the minimum action units for animation generation</definiens>
			</definition>
</paper>

		<paper id="1089">
			<definition id="0">
				<sentence>Part-of-speech ( POS ) tagging is a fundamental language analysis task .</sentence>
				<definiendum id="0">Part-of-speech</definiendum>
				<definiens id="0">a fundamental language analysis task</definiens>
			</definition>
			<definition id="1">
				<sentence>A possibility-based POS tag is a POS tag that represents all the possible properties of the word ( e.g. , a verbal noun is used as a noun or a verb ) , rather than a property of each instance of the word .</sentence>
				<definiendum id="0">possibility-based POS tag</definiendum>
				<definiens id="0">a POS tag that represents all the possible properties of the word</definiens>
			</definition>
			<definition id="2">
				<sentence>In the physical model , if the state of the system is s and the energy of the system is E ( s ) , the probability distribution of s is known to be represented by the following Boltzmann distribution : P ( s ) = 1Z exp { −βE ( s ) } , ( 1 ) where β is inverse temperature and Z is a normalizing constant defined as follows : Z= summationdisplay s exp { −βE ( s ) } .</sentence>
				<definiendum id="0">Z</definiendum>
				<definiens id="0">if the state of the system is s and the energy of the system is E ( s ) , the probability distribution of s is known to be represented by the following Boltzmann distribution : P ( s ) = 1Z exp { −βE ( s ) } , ( 1 ) where β is inverse temperature and</definiens>
			</definition>
			<definition id="3">
				<sentence>The distribution of t is then obtained from Equation ( 1 ) , ( 2 ) and ( 3 ) as follows : P ( t|w ) = 1Z ( w ) p0 ( t|w ) exp braceleftBigg 1 2 Ksummationdisplay k=1 Ksummationdisplay kprime=1 kprimenegationslash=k λtk , tkprime bracerightBigg , ( 4 ) Z ( w ) = summationdisplay t∈T ( w ) p0 ( t|w ) exp braceleftBigg 1 2 Ksummationdisplay k=1 Ksummationdisplay kprime=1 kprimenegationslash=k λtk , tkprime bracerightBigg , ( 5 ) p0 ( t|w ) ≡ Kproductdisplay k=1 p0 ( tk|wk ) , ( 6 ) where T ( w ) is the set of possible configurations of POS tags given w. The size of T ( w ) is NK , because there are K occurrences of the unknownwords and each unknown word can have one of N POS tags .</sentence>
				<definiendum id="0">T ( w )</definiendum>
			</definition>
			<definition id="4">
				<sentence>Although HMMs , MEMMs , and CRFs use dynamic programming and some studies with probabilistic models which have specific structures use efficient algorithms ( Wang et al. , 2005 ) , such methods can not be applied here because we are considering interactions ( dependencies ) between all POS tags , and their joint distribution can not be decomposed .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiens id="0">use dynamic programming and some studies with probabilistic models which have specific structures use efficient algorithms ( Wang et al. , 2005 ) , such methods can not be applied here because we are considering interactions ( dependencies ) between all POS tags , and their joint distribution can not be decomposed</definiens>
			</definition>
			<definition id="5">
				<sentence>We can obtain a solution ˆt = { ˆt1 , ··· , ˆtK } as follows : ˆtk=argmax t Pk ( t|w ) , ( 11 ) where Pk ( t|w ) is the marginal distribution of the part-of-speech of the kth occurrence of the unknown words given a set of local contexts w , and is calculated as an expected value over the distribution of the unknown words as follows : Pk ( t|w ) = summationdisplay t1 , ··· , tk−1 , tk+1 , ··· , tK tk=t P ( t|w ) , = summationdisplay t∈T ( w ) δ ( tk , t ) P ( t|w ) .</sentence>
				<definiendum id="0">Pk ( t|w )</definiendum>
				<definiens id="0">the marginal distribution of the part-of-speech of the kth occurrence of the unknown words given a set of local contexts w , and is calculated as an expected value over the distribution of the unknown words as follows : Pk ( t|w ) = summationdisplay t1</definiens>
			</definition>
			<definition id="6">
				<sentence>Suppose that A ( x ) is a function of a random variable x , P ( x ) initialize t ( 1 ) for m : = 2 to M for k : = 1 to K t ( m ) k ∼ P ( tk|w , t ( m ) 1 , ··· , t ( m ) k−1 , t ( m−1 ) k+1 , ··· , t ( m−1 ) K ) Figure 1 : Gibbs Sampling is a distribution of x , and { x ( 1 ) , ··· , x ( M ) } are M samples generated from P ( x ) .</sentence>
				<definiendum id="0">A ( x )</definiendum>
				<definiendum id="1">P ( x</definiendum>
				<definiendum id="2">Gibbs Sampling</definiendum>
				<definiens id="0">a function of a random variable x</definiens>
				<definiens id="1">a distribution of x , and { x ( 1 ) , ···</definiens>
			</definition>
			<definition id="7">
				<sentence>Gibbs sampling is one of the Markov chain Monte Carlo ( MCMC ) methods , which can generate samples efficiently from highdimensional probability distributions ( Andrieu et al. , 2003 ) .</sentence>
				<definiendum id="0">Gibbs sampling</definiendum>
			</definition>
			<definition id="8">
				<sentence>The optimal solution obtained by Equation ( 11 ) maximizes the probability of each POS tag given w , and this kind of approach is known as the maximum posterior marginal ( MPM ) estimate ( Marroquin , 1985 ) .</sentence>
				<definiendum id="0">maximum posterior marginal ( MPM</definiendum>
			</definition>
			<definition id="9">
				<sentence>We define the following objective function LΛ , and find Λ which maximizes LΛ ( the subscript Λ denotes being parameterized by Λ ) : LΛ = log Lproductdisplay l=1 PΛ ( tl|wl ) +logP ( Λ ) , = log Lproductdisplay l=1 1 ZΛ ( wl ) p0 ( t l|wl ) exp braceleftBigg Nsummationdisplay i=1 Nsummationdisplay j=1 λi , jfi , j ( tl ) bracerightBigg +logP ( Λ ) , = Lsummationdisplay l=1 bracketleftBigg −logZΛ ( wl ) +logp0 ( tl|wl ) + Nsummationdisplay i=1 Nsummationdisplay j=1 λi , jfi , j ( tl ) bracketrightBigg +logP ( Λ ) .</sentence>
				<definiendum id="0">bracerightBigg +logP</definiendum>
				<definiendum id="1">wl ) +logp0</definiendum>
				<definiens id="0">the following objective function LΛ , and find Λ which maximizes LΛ ( the subscript Λ denotes being parameterized by Λ ) : LΛ = log Lproductdisplay l=1 PΛ ( tl|wl ) +logP ( Λ ) , = log Lproductdisplay l=1 1 ZΛ ( wl ) p0 ( t l|wl ) exp braceleftBigg Nsummationdisplay i=1 Nsummationdisplay j=1 λi , jfi , j ( tl )</definiens>
			</definition>
			<definition id="10">
				<sentence>where C is a constant and σ is set to 1 in laterexperiments .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a constant and σ is set to 1 in laterexperiments</definiens>
			</definition>
			<definition id="11">
				<sentence>We use eight corpora for our experiments ; the Penn Chinese Treebank corpus 2.0 ( CTB ) , a part of the PFR corpus ( PFR ) , the EDR corpus ( EDR ) , the Kyoto University corpus version 2 ( KUC ) , the RWCP corpus ( RWC ) , the GENIA corpus 3.02p ( GEN ) , the SUSANNE corpus ( SUS ) and the Penn Treebank WSJ corpus ( WSJ ) , ( cf. Table 1 ) .</sentence>
				<definiendum id="0">CTB</definiendum>
				<definiendum id="1">Kyoto University</definiendum>
				<definiendum id="2">KUC</definiendum>
				<definiendum id="3">RWCP corpus</definiendum>
				<definiendum id="4">GENIA</definiendum>
				<definiendum id="5">GEN</definiendum>
				<definiendum id="6">SUSANNE corpus</definiendum>
				<definiendum id="7">Penn Treebank WSJ corpus</definiendum>
				<definiens id="0">a part of the PFR corpus ( PFR ) , the EDR corpus ( EDR ) , the</definiens>
			</definition>
			<definition id="12">
				<sentence>POS tags that these pseudo unknown words have are defined as open class tags , and only the open class tags are considered as candidate POS tags for unknown words in the test data ( i.e. , N is equal to the number of the open class tags ) .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">open class tags , and only the open class tags are considered as candidate POS tags for unknown words in the test data</definiens>
				<definiens id="1">equal to the number of the open class tags )</definiens>
			</definition>
			<definition id="13">
				<sentence>[ p-value ] 〈 # of Non-unique Unknown Words〉 local local+global local+global w/ unlabeled CTB 0.7423 ( 193 ) 0.7717 ( 171 ) 0.7704 ( 172 ) ( C ) [ 0.0000 ] 〈344〉 [ 0.0001 ] 〈361〉 PFR 0.6499 ( 9723 ) 0.6690 ( 9193 ) 0.6785 ( 8930 ) ( C ) [ 0.0000 ] 〈16019〉 [ 0.0000 ] 〈18861〉 EDR 0.9639 ( 874 ) 0.9643 ( 863 ) 0.9651 ( 844 ) ( J ) [ 0.1775 ] 〈4903〉 [ 0.0034 ] 〈7770〉 KUC 0.7501 ( 619 ) 0.7634 ( 586 ) 0.7562 ( 604 ) ( J ) [ 0.0000 ] 〈788〉 [ 0.0872 ] 〈936〉 RWC 0.7699 ( 2572 ) 0.7785 ( 2476 ) 0.7787 ( 2474 ) ( J ) [ 0.0000 ] 〈5044〉 [ 0.0000 ] 〈5878〉 GEN 0.8836 ( 905 ) 0.8837 ( 904 ) 0.8863 ( 884 ) ( E ) [ 1.0000 ] 〈4094〉 [ 0.0244 ] 〈4515〉 SUS 0.7934 ( 1190 ) 0.7957 ( 1177 ) 0.7979 ( 1164 ) ( E ) [ 0.1878 ] 〈3210〉 [ 0.0116 ] 〈3583〉 WSJ 0.8345 ( 704 ) 0.8368 ( 694 ) 0.8352 ( 701 ) ( E ) [ 0.0162 ] 〈1412〉 [ 0.7103 ] 〈1627〉 Table 3 : Results of POS Guessing of Unknown Words Corpus Mean±Standard Deviation ( Lang . )</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">Results of POS Guessing of Unknown Words Corpus Mean±Standard Deviation ( Lang .</definiens>
			</definition>
</paper>

		<paper id="1126">
			<definition id="0">
				<sentence>Full-bigram model is the unpruned model containing all seen bigrams in training corpus .</sentence>
				<definiendum id="0">Full-bigram model</definiendum>
				<definiens id="0">the unpruned model containing all seen bigrams in training corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>Growing Algorithm for Language Model Pruning Given a Chinese character string S , a word segmentation system chooses a sequence of words W* as the segmentation result , satisfying : ) ) | ( log ) ( ( logmaxarg* WSPWPW W += ( 4 ) The sum of the two logarithm probabilities in equation ( 4 ) is called discriminant function : ) | ( log ) ( log ) , ; , ( WSPWPWSg +=ΓΛ ( 5 ) Where Г denotes a language model that is used to compute P ( W ) , and Λ denotes a generative model that is used to compute P ( S|W ) .</sentence>
				<definiendum id="0">Λ</definiendum>
				<definiens id="0">a Chinese character string S , a word segmentation system chooses a sequence of words W* as the segmentation result , satisfying : ) ) | ( log ) ( ( logmaxarg* WSPWPW W += ( 4 ) The sum of the two logarithm probabilities in equation ( 4 ) is called discriminant function : ) | ( log ) ( log )</definiens>
				<definiens id="1">a language model that is used to compute P ( W ) , and</definiens>
			</definition>
			<definition id="2">
				<sentence>The variation of the misclassification function is computed as : ) ] ( log ) ( [ log ) ] ( log ) ( [ log ) , ; ( ) , ; ( ) ; ( ** ** BBB FBF Byx WPWP WPWP SdSdwwSd −′− −′= Γ′Λ−ΓΛ=Δ ( 11 ) Because the only difference between base model and model Г′ is that model Г′ involves the bigram probability P′ ( w y |w x ) , we have : ) ] ( log ) ( log ) | ( ) [ log , ( ] | ( log ) | ( [ log ) ( log ) ( log * * ) 1 ( * ) ( * ) 1 ( * ) ( ** xB yBxyyxF i iFiFBiFiF FBF w wPwwPwwWn wwPwwP WPWP α− −′= −′= −′ ∑ −− ( 12 ) Where denotes the number of times the bigram w ) , ( * yxF wwWn x w y appears in sequence .</sentence>
				<definiendum id="0">bigram probability P′</definiendum>
				<definiens id="0">the number of times the bigram w )</definiens>
			</definition>
</paper>

		<paper id="1092">
			<definition id="0">
				<sentence>The most famous LM is an D2-gram model based on words .</sentence>
				<definiendum id="0">most famous LM</definiendum>
				<definiens id="0">an D2-gram model based on words</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , when DB CX is outside of the vocabulary CF , C8B4DB CX CYDB CXA0BD CXA0D2B7BD B5BPC5 DCBND2 B4DB CX B5C8B4CDCFCYDB CXA0BD CXA0D2B7BD B5BM Nagata ( 1994 ) proposed a stochastic word segmenter based on a word D2-gram model to solve the word segmentation problem .</sentence>
				<definiendum id="0">DB CX</definiendum>
				<definiens id="0">outside of the vocabulary CF , C8B4DB CX CYDB CXA0BD CXA0D2B7BD B5BPC5 DCBND2 B4DB CX B5C8B4CDCFCYDB CXA0BD CXA0D2B7BD B5BM Nagata ( 1994 ) proposed a stochastic word segmenter based on a word D2-gram model to solve the word segmentation problem</definiens>
			</definition>
			<definition id="2">
				<sentence>A phoneme-to-text transcription system based on an LM CC ( Mori et al. , 1999 ) receives a phoneme sequence DD and returns a list of candidate sentences B4DC BD BN DC BE BN A1A1A1B5 in descending order of the probability C8B4DCCYDDB5 : CCB4DDB5BPB4DC BD BN DC BE BN A1A1A1B5BN where CX AK CY B8 C8B4DC CX CYDDB5 AL C8B4DC CY CYDDB5BM Similar to speech recognition , the probability is decomposed into two independent parts : a pronunciation model ( PM ) and an LM .</sentence>
				<definiendum id="0">LM CC</definiendum>
				<definiens id="0">returns a list of candidate sentences B4DC BD BN DC BE BN A1A1A1B5 in descending order of the probability C8B4DCCYDDB5 : CCB4DDB5BPB4DC BD BN DC BE BN A1A1A1B5BN where CX AK CY B8 C8B4DC CX CYDDB5 AL C8B4DC CY CYDDB5BM Similar to speech recognition , the probability is decomposed into two independent parts : a pronunciation model ( PM</definiens>
			</definition>
			<definition id="3">
				<sentence>C8B4DC CX CYDDB5 AL C8B4DC CY CYDDB5 B8 C8B4DDCYDC CX B5C8B4DC CX B5 C8B4DDB5 AL C8B4DDCYDC CY B5C8B4DC CY B5 C8B4DDB5 B8 C8B4DDCYDC CX B5C8B4DC CX B5 AL C8B4DDCYDC CY B5C8B4DC CY B5 ( 2 ) B4 A1 A1 A1 C8B4DDB5 is independent of DC CX and DC CY BMB5 In this formula C8B4DCB5 is an LM representing the likelihood of a sentence DC .</sentence>
				<definiendum id="0">C8B4DCB5</definiendum>
				<definiens id="0">independent of DC CX and DC CY BMB5 In this formula</definiens>
			</definition>
			<definition id="4">
				<sentence>731 xk+1xbnnex bn+1 x wn x i xb 1 xe 1 xb 2 e 2 x 1ww2 1-P bn ( ) 1-P bn+1 ( ) P nePP ie 1 P e 2 b 2 1-P ( ) 1-P b 1 ( ) r 1 n f ( w ) = Figure 1 : Word D2-gram frequency in a stochastically segmented corpus ( SSC ) .</sentence>
				<definiendum id="0">Word D2-gram frequency</definiendum>
				<definiendum id="1">SSC</definiendum>
				<definiens id="0">in a stochastically segmented corpus (</definiens>
			</definition>
			<definition id="5">
				<sentence>A stochastically segmented corpus ( SSC ) is defined as a combination of a raw corpus BV D6 ( hereafter referred to as the character sequence DC D2 D6 BD ) and word boundary probabilities C8 CX that a word boundary exists between two characters DC CX and DC CXB7BD .</sentence>
				<definiendum id="0">stochastically segmented corpus ( SSC</definiendum>
			</definition>
			<definition id="6">
				<sentence>Word D2-gram frequencies on an SSC is calculated as follows : Word 0-gram frequency : This is defined as an expected number of words in the SSC : CUB4A1B5BPBDB7 D2 D6 A0BD CG CXBPBD C8 CX BM Word D2-gram frequency ( D2 AL BD ) : Let us think of a situation ( see Figure 1 ) in which a word sequence DB D2 BD occurs in the SSC as a subsequence beginning at the B4CX B7BDB5-th character and ending at the CZ-th character and each word DB D1 in the word sequence is equal to the character sequence beginning at the CQ D1 -th character and ending at the CT D1 -th character ( DC CT D1 CQ D1 BP DB D1 BN BD AK BKD1 AK D2 ; CT D1 B7BDBP CQ D1B7BD BN BD AKBKD1 AK D2A0 BD ; CQ BD BP CX B7BD ; CT D2 BP CZ ) .</sentence>
				<definiendum id="0">Word D2-gram frequencies on an SSC</definiendum>
				<definiendum id="1">Word 0-gram frequency</definiendum>
				<definiendum id="2">CT D1 B7BDBP CQ D1B7BD BN BD AKBKD1 AK D2A0 BD ; CQ BD BP</definiendum>
				<definiens id="0">an expected number of words in the SSC : CUB4A1B5BPBDB7 D2 D6 A0BD CG CXBPBD C8 CX BM Word D2-gram frequency ( D2 AL BD ) : Let us think of a situation ( see Figure 1 ) in which a word sequence DB D2 BD occurs in the SSC as a subsequence beginning at the B4CX B7BDB5-th character and ending at the CZ-th character and each word DB D1 in the word sequence is equal to the character sequence beginning at the CQ D1 -th character and ending at the CT D1 -th character ( DC CT D1 CQ D1 BP DB D1 BN BD AK BKD1 AK D2</definiens>
			</definition>
			<definition id="7">
				<sentence>The word D2-gram frequency of a word sequence CU D6 B4DB D2 BD B5 in the SSC is defined by the summation of the stochastic frequency at each occurrence of the character sequence of the word sequence DB D2 BD over all of the occurrences in the SSC : CU D6 B4DB D2 BD B5BP CG B4CXBNCT D2 BD B5BEC7 D2 C8 CX BE BG D2 CH D1BPBD BK BO BM CT D1 A0BD CH CYBPCQ D1 B4BDA0C8 CY B5 BL BP BN C8 CT D1 BF BH BN where CT D2 BD BP B4CT BD BNCT BE BNA1A1A1BNCT D2 B5 and C7 D2 BP CUB4CXBNCT D2 BD B5CYDC CT D1 CQ D1 BP DB D1 BNBD AK D1 AK D2CV .</sentence>
				<definiendum id="0">word D2-gram frequency of a word sequence CU D6 B4DB D2 BD B5</definiendum>
				<definiendum id="1">BG D2 CH D1BPBD BK BO BM CT D1 A0BD CH CYBPCQ D1 B4BDA0C8 CY B5 BL BP BN C8 CT D1 BF BH BN</definiendum>
				<definiens id="0">the summation of the stochastic frequency at each occurrence of the character sequence of the word sequence DB D2 BD over all of the occurrences in the SSC : CU D6 B4DB D2 BD B5BP CG B4CXBNCT D2 BD B5BEC7 D2 C8 CX BE</definiens>
			</definition>
			<definition id="8">
				<sentence>Thus we use the following interpolation technique : C8B4DB CX CYC0 CX B5BPAL D7 C8 D7 B4DB CX CYC0 CX B5B7AL D6 C8 D6 B4DB CX CYC0 CX B5BN where C0 CX is history before DB CX , C8 D7 is the probability estimated from a segmented corpus BV D7 , and C8 D6 is the probability estimated by our method from a raw corpus BV D6 .</sentence>
				<definiendum id="0">C8 D7</definiendum>
				<definiendum id="1">C8 D6</definiendum>
				<definiens id="0">the probability estimated from a segmented corpus BV D7 , and</definiens>
			</definition>
			<definition id="9">
				<sentence>Thus the phoneme-to-text transcription system of our new framework refers to the following LM to measure the likelihood of word sequences : C8B4DB CX B5 ( 7 ) BP BK BQ BQ BQ BQ BQ BQ BQ BO BQ BQ BQ BQ BQ BQ BQ BM AL D7 C8 D7 B4DB CX CYDB CXA0BD B5B7AL D6 C8 D6 B4DB CX CYDB CXA0BD B5 if DB CX BECFBN AL D7 C8 D7 B4CDCFCYDB CXA0BD B5C5 DCBND2 B4DB CX B5B7AL D6 C8 D6 B4DB CX CYDB CXA0BD B5 if DB CX BIBECFCMDB CX BECB D6 BN AL D7 C8 D7 B4CDCFCYDB CXA0BD B5C5 DCBND2 B4DB CX B5BN A1 A1 A1 C8 D6 B4DB CX B5BPBC if DB CX BIBECFCMDB CX BIBECB D6 BN where CB D6 is the set of all subsequences appearing in the SSC .</sentence>
				<definiendum id="0">BP BK BQ BQ BQ BQ BQ BQ BQ BO BQ BQ BQ BQ BQ BQ BQ BM AL</definiendum>
				<definiens id="0">D7 C8 D7 B4DB CX CYDB CXA0BD B5B7AL D6 C8 D6 B4DB CX CYDB CXA0BD B5 if DB CX BECFBN AL D7 C8 D7 B4CDCFCYDB CXA0BD B5C5 DCBND2 B4DB CX B5B7AL D6 C8 D6 B4DB CX CYDB CXA0BD B5 if DB CX BIBECFCMDB CX BECB D6 BN AL D7 C8 D7 B4CDCFCYDB CXA0BD B5C5 DCBND2 B4DB CX B5BN A1 A1 A1 C8 D6 B4DB CX B5BPBC if DB CX BIBECFCMDB CX BIBECB D6 BN where CB D6 is the set of all subsequences appearing in the SSC</definiens>
			</definition>
			<definition id="10">
				<sentence>Infinite Vocabulary Finally , the transcription system with an infinite vocabulary enumerates candidate sentence DC BP DB BD DB BE A1A1A1DB CW in the descending order of the following evaluation function value composed of an LM C8B4DB CX B5 defined by Equation ( 7 ) and a PM C8B4DD CX CYDB CX B5 defined by Equation ( 9 ) : C8B4DDCYDCB5C8B4DCB5BP CW CH CXBPBD C8B4DD CX CYDB CX B5C8B4DB CX B5 Note that there are only three cases since the case decompositions in Equation ( 7 ) and Equation ( 9 ) are identical .</sentence>
				<definiendum id="0">Equation</definiendum>
				<definiens id="0">the transcription system with an infinite vocabulary enumerates candidate sentence DC BP DB BD DB BE A1A1A1DB CW in the descending order of the following evaluation function value composed of an LM C8B4DB CX B5 defined by Equation ( 7 ) and a PM C8B4DD CX CYDB CX B5 defined by Equation ( 9 ) : C8B4DDCYDCB5C8B4DCB5BP CW CH CXBPBD C8B4DD CX CYDB CX B5C8B4DB CX B5 Note that there are only three cases since the case decompositions in Equation ( 7 ) and</definiens>
			</definition>
			<definition id="11">
				<sentence>Raw corpus size Precision Recall BDBMBJBIBHA2BDBC BH chars ( 1/100 ) 89.18 % 92.32 % BDBMBJBIBHA2BDBC BI chars ( 1/10 ) 90.33 % 93.40 % BDBMBJBIBHA2BDBC BJ chars ( 1/1 ) 91.10 % 94.09 % our phoneme model PM is able to enumerate transcription candidates for out-of-vocabulary words and word D2-gram probabilities estimated from the SSC helps the model choose the appropriate ones .</sentence>
				<definiendum id="0">Raw corpus size Precision Recall BDBMBJBIBHA2BDBC BH</definiendum>
				<definiens id="0">able to enumerate transcription candidates for out-of-vocabulary words and word D2-gram probabilities estimated from the SSC helps the model choose the appropriate ones</definiens>
			</definition>
</paper>

		<paper id="1068">
			<definition id="0">
				<sentence>One approach extracts all noun phrase ( NP ) chunks , and the other all terms matching any of a set of empirically defined PoS patterns ( frequently occurring patterns of manual keywords ) .</sentence>
				<definiendum id="0">noun phrase</definiendum>
				<definiendum id="1">NP</definiendum>
			</definition>
			<definition id="1">
				<sentence>The evaluation measures are precision ( how many of the automatically assigned keywords that are also manually assigned keywords ) and recall ( how many of the manually assigned keywords that are found by the automatic indexer ) .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">how many of the automatically assigned keywords that are also manually assigned keywords</definiens>
			</definition>
			<definition id="2">
				<sentence>For the text categorization experiments we used the Reuters-21578 corpus , which contains 20 000 newswire articles in English with multiple categories ( Lewis , 1997 ) .</sentence>
				<definiendum id="0">Reuters-21578 corpus</definiendum>
			</definition>
</paper>

		<paper id="2069">
			<definition id="0">
				<sentence>Function words make ‘noisy’ index terms , and are usually ignored during the retrieval process .</sentence>
				<definiendum id="0">Function words</definiendum>
				<definiens id="0">make ‘noisy’ index terms , and are usually ignored during the retrieval process</definiens>
			</definition>
			<definition id="1">
				<sentence>TB TBR JJ , JJR , JJS JJ RB , RBR , RBS RB CD , LS CD CC CC DT , WDT , PDT DT FW FW MD , VB , VBD , VBG , VBN , VBP , VBZ , VH , VHD , VHG , VHN , VHP , VHZ MD NN , NNS , NP , NPS NN PP , WP , PP $ , WP $ , EX , WRB PP IN , TO IN POS PO RP RP SYM SY UH UH VV , VVD , VVG , VVN , VVP , VVZ VB ( Marcus et al. , 1993 ) .</sentence>
				<definiendum id="0">LS CD CC CC</definiendum>
				<definiendum id="1">TO IN POS PO RP RP SYM SY UH UH VV</definiendum>
				<definiens id="0">DT , WDT , PDT DT FW FW MD , VB , VBD , VBG , VBN , VBP , VBZ , VH , VHD , VHG</definiens>
			</definition>
			<definition id="2">
				<sentence>We retrieve relevant documents from two standard TREC test collections , namely WT2G ( 2GB ) and WT10G ( 10GB ) , from the 1999 and 2000 TREC Web tracks , respectively .</sentence>
				<definiendum id="0">TREC Web</definiendum>
				<definiens id="0">retrieve relevant documents from two standard TREC test collections</definiens>
				<definiens id="1">tracks , respectively</definiens>
			</definition>
			<definition id="3">
				<sentence>The narrative part consists of sentences denoting key concepts to be considered or ignored .</sentence>
				<definiendum id="0">narrative part</definiendum>
			</definition>
			<definition id="4">
				<sentence>In IR , term weighting schemes estimate the relevance a0a2a1a4a3a6a5a8a7a10a9 of a document a3 for a query a7 , as : a0a2a1a4a3a11a5a8a7a12a9a14a13a16a15 a0a4a17a19a18a21a20a23a22a25a24a27a26a28a24 a1 a22 a5a29a3a30a9 , where a22 is a term in a7 , a20a23a22a25a24 is the query term weight , and a24 a1 a22 a5a29a3a31a9 is the weight of document a3 for term a22 .</sentence>
				<definiendum id="0">a22</definiendum>
				<definiendum id="1">a20a23a22a25a24</definiendum>
				<definiens id="0">a term in a7</definiens>
				<definiens id="1">the query term weight</definiens>
				<definiens id="2">the weight of document a3 for term a22</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , we use the classical TF IDF weighting scheme ( Sparck-Jones , 1972 ; Robertson et al. , 1995 ) : a24 a1 a22 a5a29a3a31a9a12a13 a22a33a32 a0 a26a35a34a37a36a35a38a40a39a42a41 a43a37a44a46a45a48a47 , where a22a33a32 a0 is the normalised term frequency in a document : a22a49a32 a0 a13 a50a46a51a33a52 a0 a44 a0 a44a46a45 a50a53a51a49a54 a47a49a55a11a56a57a45a58a56a60a59 a61a49a62a64a63 a59a57a65 ; a22a49a32 is the frequency of a term in a document ; a66a58a67 , and a68 are parameters ; a69 and a70a72a71a72a73 a69 are the document length and the average document length in the collection , respectively ; a74 is the number of documents in the collection ; and a3 a32 is the number of documents containing the term a22 .</sentence>
				<definiendum id="0">a22a49a32</definiendum>
				<definiendum id="1">a74</definiendum>
				<definiens id="0">the normalised term frequency in a document : a22a49a32 a0 a13 a50a46a51a33a52 a0 a44 a0 a44a46a45 a50a53a51a49a54 a47a49a55a11a56a57a45a58a56a60a59 a61a49a62a64a63 a59a57a65 ;</definiens>
				<definiens id="1">the frequency of a term in a document</definiens>
				<definiens id="2">the number of documents containing the term a22</definiens>
			</definition>
			<definition id="6">
				<sentence>For all weighting schemes we use , a20a23a22a75a24 a13 a76 a0 a44 a76 a0 a44a25a77 a61a49a78 , where a20a28a22a49a32 is the query term frequency , and a20a23a22a33a32a19a79a81a80a29a82 is the maximum a20a23a22a49a32 among all query terms .</sentence>
				<definiendum id="0">a20a28a22a49a32</definiendum>
				<definiendum id="1">a20a23a22a33a32a19a79a81a80a29a82</definiendum>
				<definiens id="0">the query term frequency , and</definiens>
				<definiens id="1">the maximum a20a23a22a49a32 among all query terms</definiens>
			</definition>
			<definition id="7">
				<sentence>We present all evaluation results in tables , the format of which is as follows : GT and LA indicate Good-Turing and Laplace respectively , and a96a98a97 denotes the % difference in MAP from the baseline .</sentence>
				<definiendum id="0">a96a98a97</definiendum>
				<definiens id="0">the % difference in MAP from the baseline</definiens>
			</definition>
			<definition id="8">
				<sentence>with Query Expansion Query expansion ( QE ) is a performanceboosting technique often used in IR , which consists in extracting the most relevant terms from the top retrieved documents , and in using these terms to expand the initial query .</sentence>
				<definiendum id="0">Query Expansion Query expansion ( QE )</definiendum>
				<definiens id="0">a performanceboosting technique often used in IR , which consists in extracting the most relevant terms from the top retrieved documents , and in using these terms to expand the initial query</definiens>
			</definition>
</paper>

		<paper id="2118">
			<definition id="0">
				<sentence>The English data used for the SENSEVAL exercises , arguably the most widely used data to train and test WSD systems , are annotated based on very fine-grained distinctions defined in WordNet ( Fellbaum , 1998 ) , with human inter-annotator agreement at a little over seventy percent and the top-ranked systems� performances falling between 60 % ~70 % ( Palmer , et al. , 2001 ; Mihalcea et al. , 2004 ) .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">The English data used for the SENSEVAL exercises , arguably the most widely used data to train and test</definiens>
			</definition>
			<definition id="1">
				<sentence>System Similar to our English WSD system , which achieved the best published results on SENSEVAL2 English verbs for both finegrained and coarse-grained senses ( Chen and Palmer , 2005 ) , our Chinese WSD system uses the same smoothed MaxEnt machine learning model and linguistically motivated features for Chinese verb sense disambiguation .</sentence>
				<definiendum id="0">WSD system</definiendum>
				<definiens id="0">uses the same smoothed MaxEnt machine learning model</definiens>
			</definition>
			<definition id="2">
				<sentence>The data we used for our experiments are developed as part of the OntoNotes project ( Hovy et al. , 2006 ) and they come from a variety of sources .</sentence>
				<definiendum id="0">OntoNotes project</definiendum>
			</definition>
			<definition id="3">
				<sentence>The Chinese Senseval dataset includes both nouns and verbs .</sentence>
				<definiendum id="0">Chinese Senseval dataset</definiendum>
			</definition>
			<definition id="4">
				<sentence>( log ) ( 1 i n i i sensePsenseP ∑ = − ( 1 ) Where n is the number of senses of a verb in our data ; ) ( i senseP is the probability of the ith sense of the verb , which is estimated based on the frequency count of the verb�s senses in the data .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">senseP</definiendum>
				<definiens id="0">the number of senses of a verb in our data ; ) ( i</definiens>
				<definiens id="1">the probability of the ith sense of the verb , which is estimated based on the frequency count of the verb�s senses in the data</definiens>
			</definition>
			<definition id="5">
				<sentence>Extracting features from the gold 2 In their definition , a collocation is a recurrent and conventional fixed expression of words that holds syntactic and semantic relations .</sentence>
				<definiendum id="0">collocation</definiendum>
				<definiens id="0">a recurrent and conventional fixed expression of words that holds syntactic and semantic relations</definiens>
			</definition>
			<definition id="6">
				<sentence>The Proposition Bank : An Annotated Corpus of Semantic Roles , Computational Linguistics , 31 ( 1 ) : 71�106 .</sentence>
				<definiendum id="0">Proposition Bank</definiendum>
				<definiens id="0">An Annotated</definiens>
			</definition>
</paper>

		<paper id="2027">
			<definition id="0">
				<sentence>Open-ended question-answering ( QA ) systems typically produce a response containing a variety of specific facts proscribed by the question type .</sentence>
				<definiendum id="0">Open-ended question-answering</definiendum>
				<definiens id="0">a response containing a variety of specific facts proscribed by the question type</definiens>
			</definition>
			<definition id="1">
				<sentence>To measure interannotator agreement we use the Jaccard metric , which does not require knowledge of the expected or chance agreement .</sentence>
				<definiendum id="0">Jaccard metric</definiendum>
				<definiens id="0">does not require knowledge of the expected or chance agreement</definiens>
			</definition>
			<definition id="2">
				<sentence>Jaccard metric values are calculated as Jaccard ( domaind ) = |QS d i ∩ QS d j| |QSdi ∪ QSdj| ( 3 ) where QSdi and QSdj are the sets of questions created by subjects i and j for domain d. For the airplane crash and presidential election domains we averaged the three pairwise Jaccard metric values .</sentence>
				<definiendum id="0">QSdj</definiendum>
				<definiens id="0">the sets of questions created by subjects i and j for domain d. For the airplane crash and presidential election domains we averaged the three pairwise Jaccard metric values</definiens>
			</definition>
</paper>

		<paper id="1072">
			<definition id="0">
				<sentence>x0 is a special “wall” symbol , $ , on the left of every sentence .</sentence>
				<definiendum id="0">x0</definiendum>
				<definiens id="0">a special “wall” symbol</definiens>
			</definition>
			<definition id="1">
				<sentence>A tree y is defined by a pair of functions yleft and yright ( both { 0,1,2 , ... , n } → 2 { 1,2 , ... , n } ) that map each word to its sets of left and right dependents , respectively .</sentence>
				<definiendum id="0">tree y</definiendum>
			</definition>
			<definition id="2">
				<sentence>Keeping our original model , we will simply multiply into the probability of each tree another factor that penalizes long dependencies , giving : pprimeΘ ( x , y ) ∝ pΘ ( x , y ) ·e   δ nsummationdisplay i=1 summationdisplay j∈y ( i ) |i−j|    ( 2 ) where y ( i ) = yleft ( i ) ∪ yright ( i ) .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">pprimeΘ ( x , y ) ∝ pΘ ( x , y ) ·e   δ nsummationdisplay i=1 summationdisplay j∈y</definiens>
			</definition>
			<definition id="3">
				<sentence>For the latter , we use an inside-outside algorithm that computes a score for every parse tree by computing the scores of items , or partial structures , through a bottom-up process .</sentence>
				<definiendum id="0">inside-outside algorithm</definiendum>
				<definiens id="0">computes a score for every parse tree by computing the scores of items , or partial structures</definiens>
			</definition>
			<definition id="4">
				<sentence>Boldface marks scores better than EM-trained models selected the same way ( Table 1 ) .</sentence>
				<definiendum id="0">Boldface</definiendum>
			</definition>
			<definition id="5">
				<sentence>This method , then , 7Performance measures are given using a full parser that finds the single best parse of the sentence with the learned parsing parameters .</sentence>
				<definiendum id="0">full parser</definiendum>
				<definiens id="0">finds the single best parse of the sentence with the learned parsing parameters</definiens>
			</definition>
</paper>

		<paper id="2009">
			<definition id="0">
				<sentence>A pipeline process over the decisions of learned classi ers is a common computational strategy in natural language processing .</sentence>
				<definiendum id="0">pipeline process</definiendum>
				<definiens id="0">a common computational strategy in natural language processing</definiens>
			</definition>
			<definition id="1">
				<sentence>The pipeline model is a standard model of computation in natural language processing for good reasons .</sentence>
				<definiendum id="0">pipeline model</definiendum>
				<definiens id="0">a standard model of computation in natural language processing for good reasons</definiens>
			</definition>
			<definition id="2">
				<sentence>A pipeline process is one in which decisions made in the ith stage ( 1 ) depend on earlier decisions and ( 2 ) feed on input that depends on earlier decisions .</sentence>
				<definiendum id="0">pipeline process</definiendum>
				<definiens id="0">one in which decisions made in the ith stage</definiens>
			</definition>
			<definition id="3">
				<sentence>For words x , y in the sentence T we introduce the following notations : x → y : x is the direct parent of y. x →∗ y : x is an ancestor of y ; x ↔ y : x → y or y → x. x &lt; y : x is to the left of y in T. De nition 1 ( Projective Language ) ( Nivre , 2003 ) ∀a , b , c ∈ T , a ↔ b and a &lt; c &lt; b imply that a →∗ c or b →∗ c. Our parsing algorithm is a modi ed shift-reduce parser that makes use of the actions described below and applies them in a left to right manner on consecutive pairs of words ( a , b ) ( a &lt; b ) in the sentence .</sentence>
				<definiendum id="0">x</definiendum>
				<definiendum id="1">x</definiendum>
				<definiens id="0">an ancestor of y ; x ↔ y : x → y or y → x. x &lt; y : x is to the left of y in T. De nition 1 ( Projective Language</definiens>
				<definiens id="1">a modi ed shift-reduce parser that makes use of the actions described below and applies them in a left to right manner on consecutive pairs of words</definiens>
			</definition>
			<definition id="4">
				<sentence>getFeatures extracts the features describing the word pair currently considered ; getAction determines the appropriate action for the pair ; assignParent assigns a parent for the child word based on the action ; and deleteWord deletes the child word in T at the focus once the action is taken .</sentence>
				<definiendum id="0">getAction</definiendum>
				<definiendum id="1">deleteWord</definiendum>
				<definiens id="0">determines the appropriate action for the pair ; assignParent assigns a parent for the child word based on the action</definiens>
			</definition>
			<definition id="5">
				<sentence>Formally , De nition 2 ( free pair ) A pair ( a , b ) considered by the algorithm is a free pair , if it satis es the following conditions : the original sentence ) .</sentence>
				<definiendum id="0">pair</definiendum>
				<definiens id="0">a free pair , if it satis es the following conditions : the original sentence )</definiens>
			</definition>
			<definition id="6">
				<sentence>SNoW uses softmax over the raw activation values as its con dence measure , which can be shown to produce a reliable approximation of the labels’ conditional probabilities .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiens id="0">uses softmax over the raw activation values as its con dence measure</definiens>
			</definition>
			<definition id="7">
				<sentence>Dependency accuracy ( DA ) is the proportion of non-root words that are assigned the correct head .</sentence>
				<definiendum id="0">Dependency accuracy</definiendum>
				<definiendum id="1">DA</definiendum>
				<definiens id="0">the proportion of non-root words</definiens>
			</definition>
			<definition id="8">
				<sentence>Complete accuracy ( CA ) indicates the fraction of sentences that have a complete correct analysis .</sentence>
				<definiendum id="0">Complete accuracy</definiendum>
				<definiendum id="1">CA )</definiendum>
				<definiens id="0">indicates the fraction of sentences that have a complete correct analysis</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>Language modeling ( LM ) is fundamental to a wide range of applications .</sentence>
				<definiendum id="0">Language modeling ( LM</definiendum>
			</definition>
			<definition id="1">
				<sentence>Lasso is a regularization method for parameter estimation in linear models .</sentence>
				<definiendum id="0">Lasso</definiendum>
				<definiens id="0">a regularization method for parameter estimation in linear models</definiens>
			</definition>
			<definition id="2">
				<sentence>Performance on IME is measured in terms of the character error rate ( CER ) , which is the number of characters wrongly converted from the phonetic string divided by the number of characters in the correct transcript .</sentence>
				<definiendum id="0">CER</definiendum>
				<definiens id="0">measured in terms of the character error rate</definiens>
			</definition>
			<definition id="3">
				<sentence>f 0 ( W ) is called the base feature , and is defined in our case as the log probability that the word trigram model assigns to W. Other features ( f d ( W ) , for d = 1…D ) are defined as the counts of word n-grams ( n = 1 and 2 in our experiments ) in W. • Finally , the parameters of the model form a vector of D+1 dimensions , each for one feature function , λ = [ λ 0 , λ 1 , … , λ D ] .</sentence>
				<definiendum id="0">f d ( W</definiendum>
				<definiens id="0">the counts of word n-grams ( n = 1 and 2 in our experiments ) in W. • Finally , the parameters of the model form a vector of D+1 dimensions , each for one feature function , λ = [ λ 0 , λ 1 , … , λ D ]</definiens>
			</definition>
			<definition id="4">
				<sentence>Shrinkage is a simple approach to dealing with the overfitting problem .</sentence>
				<definiendum id="0">Shrinkage</definiendum>
				<definiens id="0">a simple approach to dealing with the overfitting problem</definiens>
			</definition>
			<definition id="5">
				<sentence>It has been proved that ( 1 ) it guarantees that it is safe for BLasso to start with an initial α which is the largest α that would allow an ε step away from 0 ( i.e. , larger α’s correspond to T ( λ ) =0 ) ; ( 2 ) for each value of α , BLasso performs coordinate descent ( i.e. , reduces ExpLoss by updating the weight of a feature ) until there is no descent step ; and ( 3 ) for each step where the value of α decreases , it guarantees that the lasso loss is reduced .</sentence>
				<definiendum id="0">BLasso</definiendum>
				<definiens id="0">performs coordinate descent ( i.e. , reduces ExpLoss by updating the weight of a feature</definiens>
			</definition>
			<definition id="6">
				<sentence>We used four adaptation domains : Yomiuri ( newspaper corpus ) , TuneUp ( balanced corpus containing newspapers and other sources of text ) , Encarta ( encyclopedia ) and Shincho ( collection of novels ) .</sentence>
				<definiendum id="0">TuneUp (</definiendum>
				<definiendum id="1">Encarta ( encyclopedia</definiendum>
				<definiens id="0">balanced corpus containing newspapers and other sources of text )</definiens>
			</definition>
			<definition id="7">
				<sentence>Our implementation takes the form of linear interpolation as described in Bacchiani et al. ( 2004 ) : P ( w i |h ) = λ P b ( w i |h ) + ( 1-λ ) P a ( w i |h ) , where P b is the probability of the background model , P a is the probability trained on adaptation data using MLE and the history h corresponds to two preceding words ( i.e. P b and P a are trigram probabilities ) .</sentence>
				<definiendum id="0">P b</definiendum>
				<definiens id="0">the probability of the background model</definiens>
			</definition>
			<definition id="8">
				<sentence>At each iteration , we used the following update for the kth feature ZC ZC k k k ε ε δ + + = + _ log 2 1 ( 16 ) where C k + is a value increasing exponentially with the sum of margins of ( W R , W ) pairs over the set where f k is seen in W R but not in W ; C k is the value related to the sum of margins over the set where f k is seen in W but not in W R .</sentence>
				<definiendum id="0">C k +</definiendum>
				<definiendum id="1">C k</definiendum>
				<definiendum id="2">f k</definiendum>
				<definiens id="0">a value increasing exponentially with the sum of margins of ( W R</definiens>
			</definition>
			<definition id="9">
				<sentence>ε is a smoothing factor ( whose value is optimized on held-out data ) and Z is a normalization constant ( whose value is the ExpLoss ( . )</sentence>
				<definiendum id="0">ε</definiendum>
				<definiendum id="1">Z</definiendum>
				<definiens id="0">a smoothing factor ( whose value is optimized on held-out data ) and</definiens>
			</definition>
			<definition id="10">
				<sentence>Comparing the algorithms in Figures 1 and 2 , we notice three differences between BLasso and Boosting : ( i ) the use of backward steps in BLasso ; ( ii ) BLasso uses the grid search ( fixed step size ) for feature selection in Equation ( 12 ) while Boosting uses the continuous search ( optimal step size ) in Equation ( 7 ) ; and ( iii ) BLasso uses a fixed step size for feature update in Equation ( 13 ) while Boosting uses an optimal step size in Equation ( 8 ) .</sentence>
				<definiendum id="0">BLasso</definiendum>
				<definiendum id="1">BLasso</definiendum>
				<definiens id="0">uses the grid search ( fixed step size</definiens>
			</definition>
			<definition id="11">
				<sentence>BLasso outperforms the boosting algorithm significantly in terms of CER reduction on all experimental settings .</sentence>
				<definiendum id="0">BLasso</definiendum>
				<definiens id="0">outperforms the boosting algorithm significantly in terms of CER reduction on all experimental settings</definiens>
			</definition>
</paper>

		<paper id="1124">
			<definition id="0">
				<sentence>In particular , for a vocabulary of unbounded size and for d &gt; 0 , the number of unique words scales as O ( θTd ) where T is the total number of words .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the total number of words</definiens>
			</definition>
			<definition id="1">
				<sentence>Given a context u , let Gu ( w ) be the probability of the current word taking on value w. We use a Pitman-Yor process as the prior for Gu [ Gu ( w ) ] w∈W , in particular , Gu ∼ PY ( d|u| , θ|u| , Gpi ( u ) ) ( 3 ) where pi ( u ) is the suffix of u consisting of all but the earliest word .</sentence>
				<definiendum id="0">pi ( u )</definiendum>
				<definiens id="0">the probability of the current word taking on value w. We use a Pitman-Yor process as the prior for Gu</definiens>
				<definiens id="1">the suffix of u consisting of all but the earliest word</definiens>
			</definition>
			<definition id="2">
				<sentence>The strength and discount parameters are functions of the length|u|of the context , while the mean vector is Gpi ( u ) , the vector of probabilities of the current word given all but the earliest word in the context .</sentence>
				<definiendum id="0">discount parameters</definiendum>
				<definiens id="0">the mean vector is Gpi ( u ) , the vector of probabilities of the current word given all but the earliest word in the context</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally we place a prior on G∅ : G∅ ∼ PY ( d0 , θ0 , G0 ) ( 4 ) where G0 is the global mean vector , given a uniform value of G0 ( w ) = 1/V for all w ∈W. Finally , we place a uniform prior on the discount parameters and a Gamma ( 1,1 ) prior on the strength parameters .</sentence>
				<definiendum id="0">G0</definiendum>
				<definiens id="0">the global mean vector</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , cu·k is the number of xul’s assigned the value of yuk , cuw· is the number of xul’s with value w , and tu·· is the current number of draws yuk from Gpi ( u ) .</sentence>
				<definiendum id="0">cu·k</definiendum>
				<definiendum id="1">cuw·</definiendum>
				<definiendum id="2">tu··</definiendum>
				<definiens id="0">the number of xul’s with value w</definiens>
			</definition>
			<definition id="5">
				<sentence>Let w←DrawWord ( pi ( u ) ) ; set tuwknew = cuwknew = 1 ; return w. Function WordProb ( u , w ) : Returns the probability that the next word after context u will be w. If u = 0 , return G0 ( w ) .</sentence>
				<definiendum id="0">w←DrawWord ( pi</definiendum>
				<definiens id="0">Returns the probability that the next word after context u will be w. If u = 0 , return G0 ( w )</definiens>
			</definition>
			<definition id="6">
				<sentence>Given the training data D , we are interested in the posterior distribution over the latent vectors G = { Gv : all contexts v } and parameters Θ = { θm , dm : 0≤m≤n−1 } : p ( G , Θ|D ) = p ( G , Θ , D ) /p ( D ) ( 7 ) As mentioned previously , the hierarchical Chinese restaurant process marginalizes out each Gu , replacing it with the seating arrangement in the corresponding restaurant , which we shall denote by Su .</sentence>
				<definiendum id="0">restaurant</definiendum>
				<definiens id="0">interested in the posterior distribution over the latent vectors G = { Gv : all contexts v } and parameters Θ = { θm , dm : 0≤m≤n−1 } : p ( G , Θ|D ) = p ( G , Θ</definiens>
			</definition>
			<definition id="7">
				<sentence>The overall sampling scheme for an n-gram hierarchical Pitman-Yor language model takes O ( nT ) time and requires O ( M ) space per iteration , where T is the number of words in the training set , and M is the number of unique n-grams .</sentence>
				<definiendum id="0">T</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">the number of words in the training set</definiens>
				<definiens id="1">the number of unique n-grams</definiens>
			</definition>
			<definition id="8">
				<sentence>The hierarchical Pitman-Yor process is a natural generalization of the recently proposed hierarchical Dirichlet process ( Teh et al. , 2006 ) .</sentence>
				<definiendum id="0">hierarchical Pitman-Yor process</definiendum>
			</definition>
			<definition id="9">
				<sentence>Acknowledgement I wish to thank the Lee Kuan Yew Endowment Fund for funding , Joshua Goodman for answering many questions regarding interpolated KneserNey and smoothing techniques , John Blitzer and Yoshua Bengio for help with datasets , Anoop Sarkar for interesting discussion , and Hal Daume III , Min Yen Kan and the anonymous reviewers for 991 0 10 20 30 40 500 1 2 3 4 5 6 Count of n−grams Average Discount IKN MKN HPYLM 2 4 6 8 10−0.01 −0.005 0 Cross−Entropy Differences from MKN Count of words in test set IKN MKN HPYLM HPYCV Figure 2 : Left : Average discounts as a function of n-gram counts in IKN ( bottom line ) , MKN ( middle step function ) , and HPYLM ( top curve ) .</sentence>
				<definiendum id="0">HPYLM ( top curve</definiendum>
				<definiens id="0">thank the Lee Kuan Yew Endowment Fund for funding , Joshua Goodman for answering many questions regarding interpolated KneserNey and smoothing techniques , John Blitzer and Yoshua Bengio for help with datasets</definiens>
			</definition>
			<definition id="10">
				<sentence>Plotted is the sum over test words which occurred c times of cross-entropies of IKN , MKN , HPYLM and HPYCV , where c is as given on the x-axis and MKN is used as a baseline .</sentence>
				<definiendum id="0">Plotted</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">the sum over test words which occurred c times of cross-entropies of IKN</definiens>
			</definition>
</paper>

		<paper id="2080">
			<definition id="0">
				<sentence>Structured classification is the problem of predicting y from x in the case where y has a meaningful internal structure .</sentence>
				<definiendum id="0">Structured classification</definiendum>
				<definiens id="0">the problem of predicting y from x in the case where y has a meaningful internal structure</definiens>
			</definition>
			<definition id="1">
				<sentence>ComposeMR assigns their meaning representation ( MR ) to fill the arguments in the head’s MR to construct the complete MR for the node .</sentence>
				<definiendum id="0">ComposeMR</definiendum>
				<definiens id="0">assigns their meaning representation ( MR ) to fill the arguments in the head’s MR to construct the complete MR for the node</definiens>
			</definition>
			<definition id="2">
				<sentence>622 Input : The root node N of a SAPT Predicate knowledge K Notation : XMR is the MR of node X Output : NMR Begin Ci= the ith child node of N Ch= GETsemanticHEAD ( N ) ChMR =BuildMR ( Ch , K ) for each other child Ci where inegationslash= h do CiMR =BuildMR ( Ci , K ) ComposeMR ( ChMR , CiMR , K ) end NMR=ChMR End Algorithm 1 : BuildMR ( N , K ) : Computing a logical form form an SAPT ( Ge and Mooney , 2005 ) Input : S = ( xi ; yi ; zi ) , i = 1,2 , ... , l in which xi is1 the sentence and yi , zi is the pair of tree structure and its logical form Output : SSVM model2 repeat3 for i = 1 to n do4 5 SVM∆s1 : H ( y , z ) ≡ ( 1−〈δψi ( y ) , w〉 ) ∆ ( zi , z ) SVM∆s2 : H ( y , z ) ≡ ( 1−〈δψi ( y ) , w〉 ) radicalbig ∆ ( zi , z ) SVM∆m1 : H ( y , z ) ≡ ( ∆ ( zi , z ) −〈δψi ( y ) , w〉 ) SVM∆m2 : H ( y , z ) ≡ ( radicalbig ∆ ( zi , z ) −〈δψi ( y ) , w〉 ) compute &lt; y∗ , z∗ &gt; = argmaxy , z∈Y , Z H ( Y , Z ) ; 6 compute ξi = max { 0 , maxy , z∈Si H ( y , z ) } ; 7 if H ( y∗ , z∗ ) &gt; ξi +ε then8 Si←Si∪y∗ , z∗ ; 9 solving optimization with SVM ; 10 end11 end12 until no Si has changed during iteration ; 13 Algorithm 2 : Algorithm of SSVM learning for semantic parsing .</sentence>
				<definiendum id="0">XMR</definiendum>
				<definiendum id="1">K ) ComposeMR ( ChMR , CiMR , K ) end NMR=ChMR</definiendum>
				<definiendum id="2">BuildMR</definiendum>
				<definiens id="0">The root node N of a SAPT Predicate knowledge K Notation</definiens>
				<definiens id="1">Computing a logical form form an SAPT ( Ge and Mooney , 2005</definiens>
				<definiens id="2">1−〈δψi ( y ) , w〉 ) radicalbig ∆</definiens>
			</definition>
			<definition id="3">
				<sentence>The structured SVM ensemble consists of a training and a testing phase .</sentence>
				<definiendum id="0">structured SVM ensemble</definiendum>
			</definition>
			<definition id="4">
				<sentence>The bagging method ( Breiman , 1996 ) is simply created K bootstrap with sampling m items from the training data of sentences and their logical forms with replacement .</sentence>
				<definiendum id="0">bagging method</definiendum>
			</definition>
			<definition id="5">
				<sentence>We then applied the SSVM learning in the K generated training data to create K semantic parser .</sentence>
				<definiendum id="0">SSVM learning</definiendum>
				<definiens id="0">in the K generated training data to create K semantic parser</definiens>
			</definition>
			<definition id="6">
				<sentence>Lett1 , t2 , ... , tK be a set of candidate parse trees produced by an ensemble of K parsers .</sentence>
				<definiendum id="0">t2 , ... , tK</definiendum>
			</definition>
			<definition id="7">
				<sentence>The CLANG consists of 37 non-terminal and 133 productions ; the corpus for CLANG includes 300 sentences and their structured representation in SAPT ( Kate et al. , 2005 ) , then the logical form representations were built from the trees .</sentence>
				<definiendum id="0">CLANG</definiendum>
			</definition>
			<definition id="8">
				<sentence>This indicates that CLANG is the hard corpus .</sentence>
				<definiendum id="0">CLANG</definiendum>
				<definiens id="0">the hard corpus</definiens>
			</definition>
			<definition id="9">
				<sentence>precision = # correct−representation # completed−representation recall = # correct−representation # sentences Table 4 shows the results of SSVM , the SCSISSOR system ( Ge and Mooney , 2005 ) , and the SILT system ( Kate et al. , 2005 ) on the CLANG corpus , respectively .</sentence>
				<definiendum id="0">SCSISSOR system</definiendum>
				<definiendum id="1">SILT system</definiendum>
				<definiens id="0">Kate et al. , 2005 ) on the CLANG corpus , respectively</definiens>
			</definition>
			<definition id="10">
				<sentence>Each SSVM ensemble consists of 10 individual SSVM .</sentence>
				<definiendum id="0">SSVM ensemble</definiendum>
			</definition>
</paper>

		<paper id="1123">
</paper>

		<paper id="2079">
			<definition id="0">
				<sentence>Sentiment analysis involves the identification of positive and negative opinions from a text segment .</sentence>
				<definiendum id="0">Sentiment analysis</definiendum>
				<definiens id="0">involves the identification of positive and negative opinions from a text segment</definiens>
			</definition>
			<definition id="1">
				<sentence>Although studied fairly extensively , polarity classification remains a challenge to natural language processing systems .</sentence>
				<definiendum id="0">polarity classification</definiendum>
				<definiens id="0">remains a challenge to natural language processing systems</definiens>
			</definition>
</paper>

		<paper id="1133">
			<definition id="0">
				<sentence>( 2 ) Bush : I believe the ideal world is one in which every child is protected in law and welcomed to life .</sentence>
				<definiendum id="0">ideal world</definiendum>
				<definiens id="0">one in which every child is protected in law and welcomed to life</definiens>
			</definition>
			<definition id="1">
				<sentence>A subjectivity classifier may successfully identify all subjective sentences in the document collection pair A and B , but knowing the number of subjective sentences in A and B does not necessarily tell us if they convey opposing perspectives .</sentence>
				<definiendum id="0">subjectivity classifier</definiendum>
				<definiens id="0">all subjective sentences in the document collection pair A and B , but knowing the number of subjective sentences in A and B does not necessarily tell us if they convey opposing perspectives</definiens>
			</definition>
			<definition id="2">
				<sentence>1058 in a V -dimensional space , where V is vocabulary size .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">vocabulary size</definiens>
			</definition>
			<definition id="3">
				<sentence>We first sample a V -dimensional vector θ from a Dirichlet prior distribution with a hyperparameter α , and then sample a document yi repeatedly from a Multinomial distribution conditioned on the parameter θ , where ni is the document length of the ith document in the collection and assumed to be known and fixed .</sentence>
				<definiendum id="0">ni</definiendum>
				<definiens id="0">distribution conditioned on the parameter θ</definiens>
				<definiens id="1">the document length of the ith document in the collection and assumed to be known and fixed</definiens>
			</definition>
			<definition id="4">
				<sentence>One common way to measure the difference between two distributions is Kullback-Leibler ( KL ) divergence ( Kullback and Leibler , 1951 ) , defined as follows , D ( p ( θ|A ) ||p ( θ|B ) ) = integraldisplay p ( θ|A ) log p ( θ|A ) p ( θ|B ) dθ .</sentence>
				<definiendum id="0">D ( p</definiendum>
				<definiens id="0">θ|A ) ||p ( θ|B ) ) = integraldisplay p ( θ|A ) log p ( θ|A ) p ( θ|B ) dθ</definiens>
			</definition>
			<definition id="5">
				<sentence>The second perspective corpus consists of the transcripts of the three Bush-Kerry presidential debates in 2004 .</sentence>
				<definiendum id="0">second perspective corpus</definiendum>
				<definiens id="0">consists of the transcripts of the three Bush-Kerry presidential debates in 2004</definiens>
			</definition>
			<definition id="6">
				<sentence>Reuters-215786 is one of the most common testbeds for text categorization .</sentence>
				<definiendum id="0">Reuters-215786</definiendum>
				<definiens id="0">one of the most common testbeds for text categorization</definiens>
			</definition>
</paper>

		<paper id="1141">
			<definition id="0">
				<sentence>Named entity recognition ( NER ) seeks to locate and classify atomic elements in unstructured text into predefined entities such as the names of persons , organizations , locations , expressions of times , quantities , monetary values , percentages , etc .</sentence>
				<definiendum id="0">NER</definiendum>
			</definition>
			<definition id="1">
				<sentence>Label consistency is an example of a non-local dependency important in NER .</sentence>
				<definiendum id="0">Label consistency</definiendum>
				<definiens id="0">an example of a non-local dependency important in NER</definiens>
			</definition>
			<definition id="2">
				<sentence>• Most existing work to capture labelconsistency , has attempted to create all parenleftbign2parenrightbig pairwise dependencies between the different occurrences of an entity , ( Finkel et al. , 2005 ; Sutton and McCallum , 2004 ) , where n is the number of occurrences of the given entity .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">has attempted to create all parenleftbign2parenrightbig pairwise dependencies between the different occurrences of an entity</definiens>
				<definiens id="1">the number of occurrences of the given entity</definiens>
			</definition>
</paper>

		<paper id="2021">
			<definition id="0">
				<sentence>Rosario et al. make use of the MeSH ( Medical Subject Headings ) hierarchy , which provides detailed coverage of the biomedical domain they focus on .</sentence>
				<definiendum id="0">MeSH</definiendum>
				<definiens id="0">provides detailed coverage of the biomedical domain they focus on</definiens>
			</definition>
			<definition id="1">
				<sentence>The compound storm damage , for example , is best defined by the relation causes ( ‘damage caused by a storm’ ) , but also falls under the relations makes ( ‘damage made by a storm’ ) andderivedfrom ( ‘damagederivedfromastorm’ ) : most people would agree that these paraphrases all acceptably describe the meaning of the compound ( Devereux &amp; Costello , 2005 ) .</sentence>
				<definiendum id="0">compound storm damage</definiendum>
			</definition>
</paper>

		<paper id="2008">
			<definition id="0">
				<sentence>Interactive question answering ( QA ) has been identified as one of the important directions in QA research ( Burger et al. , 2001 ) .</sentence>
				<definiendum id="0">Interactive question answering</definiendum>
			</definition>
			<definition id="1">
				<sentence>Open domain question answering ( QA ) systems are designed to automatically locate answers from large collections of documents to users’ natural language questions .</sentence>
				<definiendum id="0">Open domain question answering</definiendum>
			</definition>
			<definition id="2">
				<sentence>Named entity matching ( NEM ) : a binary feature indicating whether all the named entities in Q i+1 also appear in Q i .</sentence>
				<definiendum id="0">Named entity matching</definiendum>
				<definiendum id="1">NEM</definiendum>
				<definiens id="0">a binary feature indicating whether all the named entities in Q i+1 also appear in Q i</definiens>
			</definition>
			<definition id="3">
				<sentence>In fact , this approach finds the best sequence of user intent C ∗ for Q 1 up to Q t based on a sequence of observations f 1 , f 2 , ... , f t as follows : C ∗ =argmax C∈I tP ( C|f 1 , f 2 , ... , f t ) where C is a sequence of intent and I t is the set of all possible sequences of intent with length t. To find this sequence of intent C ∗ , MEMM keeps a variable α t ( i ) which is defined to be the maximum probability of seeing a particular sequence of intent ending at intent i ( i ∈ I ) for question Q t , given the observation sequence for questions Q 1 up to Q t : α t ( i ) = max c 1 , ... , c t−1 P ( c 1 , ... , c t−1 , c t = i|f 1 , ... , f t ) This variable can be calculated by a dynamic optimization procedure similar to the Viterbi algorithm in the Hidden Markov Model : α t ( i ) =max j α t−1 ( j ) × P ( c t = i|c t−1 = j , f t ) where P ( c t = i|c t−1 = j , f t ) is estimated by the Maximum Entropy Model .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">I t</definiendum>
				<definiendum id="2">MEMM</definiendum>
				<definiens id="0">a sequence of intent and</definiens>
				<definiens id="1">max c 1 , ... , c t−1 P ( c 1 , ... , c t−1 , c t = i|f 1 , ... , f t ) This variable can be calculated by a dynamic optimization procedure similar to the Viterbi algorithm in the Hidden Markov Model : α t ( i ) =max j α t−1 ( j ) × P ( c t = i|c t−1 = j , f t ) where P ( c t = i|c t−1 = j , f t ) is estimated by the Maximum Entropy Model</definiens>
			</definition>
</paper>

		<paper id="1142">
			<definition id="0">
				<sentence>Transliteration is a process of translating a foreign word into a native language by preserving its pronunciation in the original language , otherwise known as translation-bysound .</sentence>
				<definiendum id="0">Transliteration</definiendum>
				<definiens id="0">a process of translating a foreign word into a native language by preserving its pronunciation in the original language</definiens>
			</definition>
			<definition id="1">
				<sentence>Suppose that EW is an English word and CW is its prospective Chinese transliteration .</sentence>
				<definiendum id="0">EW</definiendum>
				<definiendum id="1">CW</definiendum>
				<definiens id="0">an English word</definiens>
			</definition>
			<definition id="2">
				<sentence>Li et al ( 2004 ) took a different approach by introducing a joint source-channel model for direct orthography mapping ( DOM ) , which treats transliteration as a statistical machine translation problem under monotonic constraints .</sentence>
				<definiendum id="0">DOM</definiendum>
				<definiens id="0">treats transliteration as a statistical machine translation problem under monotonic constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>Chinese is a syllabic language where each Chinese character is a syllable in either consonant-vowel ( CV ) or consonant-vowel-nasal ( CVN ) structure .</sentence>
				<definiendum id="0">Chinese</definiendum>
				<definiendum id="1">Chinese character</definiendum>
				<definiendum id="2">CV</definiendum>
				<definiens id="0">a syllabic language where each</definiens>
			</definition>
			<definition id="4">
				<sentence>A Chinese word consists of a sequence of characters , phonetically a sequence of syllables .</sentence>
				<definiendum id="0">Chinese word</definiendum>
				<definiens id="0">consists of a sequence of characters , phonetically a sequence of syllables</definiens>
			</definition>
			<definition id="5">
				<sentence>EW and CW is a transliteration pair .</sentence>
				<definiendum id="0">CW</definiendum>
				<definiens id="0">a transliteration pair</definiens>
			</definition>
			<definition id="6">
				<sentence>( / ) PEWCW is estimated to characterize the noisy channel , known as the transliteration probability .</sentence>
				<definiendum id="0">/ ) PEWCW</definiendum>
			</definition>
			<definition id="7">
				<sentence>( ) PCW is a language model to characterize the source language .</sentence>
				<definiendum id="0">PCW</definiendum>
				<definiens id="0">a language model to characterize the source language</definiens>
			</definition>
			<definition id="8">
				<sentence>Applying Bayes’ rule , we have ( / ) ( / ) ( ) / ( ) PCWEWPEWCWPCWPEW= ( 1 ) Following the translation-by-sound principle , the transliteration probability ( / ) PEWCW can be approximated by the phonetic confusion probability ( / ) PESCS , which is given as ( / ) max ( , / ) , PESCSPESCS D�F =D ( 2 ) where F is the set of all possible alignment paths between ES and CS .</sentence>
				<definiendum id="0">transliteration probability</definiendum>
				<definiendum id="1">F</definiendum>
			</definition>
			<definition id="9">
				<sentence>A final PSM is a linear combination of the PSA-based PSM ( PSA-PSM ) and the GSA-based PSM ( GSA-PSM ) .</sentence>
				<definiendum id="0">final PSM</definiendum>
				<definiendum id="1">PSA-based PSM</definiendum>
				<definiendum id="2">GSA-based PSM</definiendum>
				<definiens id="0">a linear combination of the</definiens>
			</definition>
			<definition id="10">
				<sentence>The U_HF curve reflects the learning progress of using E-C pairs that occur more than once in the SET1 corpus ( high F-rank ) .</sentence>
				<definiendum id="0">U_HF curve</definiendum>
				<definiens id="0">reflects the learning progress of using E-C pairs that occur more than once in the SET1 corpus ( high F-rank )</definiens>
			</definition>
</paper>

		<paper id="2001">
			<definition id="0">
				<sentence>Evaluation Results are shown using the standard measures in this area : precision , recall and f­measure2 , which are calculated based on the test corpus .</sentence>
				<definiendum id="0">Evaluation Results</definiendum>
				<definiens id="0">precision , recall and f­measure2 , which are calculated based on the test corpus</definiens>
			</definition>
</paper>

		<paper id="1039">
			<definition id="0">
				<sentence>That is , BAYESUM is a statistically justified query expansion method in the language modeling for IR framework ( Ponte and Croft , 1998 ) .</sentence>
				<definiendum id="0">BAYESUM</definiendum>
				<definiens id="0">a statistically justified query expansion method in the language modeling for IR framework</definiens>
			</definition>
			<definition id="1">
				<sentence>Expectation propagation ( EP ) is an inference technique introduced by Minka ( 2001 ) as a generalization of both belief propagation and assumed density filtering .</sentence>
				<definiendum id="0">Expectation propagation</definiendum>
				<definiendum id="1">EP</definiendum>
				<definiens id="0">an inference technique introduced by Minka ( 2001 ) as a generalization of both belief propagation and assumed density filtering</definiens>
			</definition>
			<definition id="2">
				<sentence>MAP is computed by calculating precision at every sentence as ordered by the system up until all relevant sentences are selected and averaged .</sentence>
				<definiendum id="0">MAP</definiendum>
				<definiens id="0">computed by calculating precision at every sentence as ordered by the system up until all relevant sentences are selected and averaged</definiens>
			</definition>
			<definition id="3">
				<sentence>MRR is the reciprocal of the rank of the first relevant sentence .</sentence>
				<definiendum id="0">MRR</definiendum>
				<definiens id="0">the reciprocal of the rank of the first relevant sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>The X-axis is the R-precision of the IR engine and the Y-axis is the summarization performance in MAP .</sentence>
				<definiendum id="0">X-axis</definiendum>
				<definiens id="0">the R-precision of the IR engine and the Y-axis is the summarization performance in MAP</definiens>
			</definition>
</paper>

		<paper id="2097">
			<definition id="0">
				<sentence>Identified topics lead to video segmentation and can be utilized for video summarization .</sentence>
				<definiendum id="0">Identified topics</definiendum>
				<definiens id="0">lead to video segmentation and can be utilized for video summarization</definiens>
			</definition>
			<definition id="1">
				<sentence>( An underlined phrase means a pattern for recognizing utterance type . )</sentence>
				<definiendum id="0">underlined phrase</definiendum>
				<definiens id="0">means a pattern for recognizing utterance type</definiens>
			</definition>
			<definition id="2">
				<sentence>background image b j ( R , G , B ) : the probability that background image b j ( R , G , B ) is emitted by state s j .</sentence>
				<definiendum id="0">B )</definiendum>
				<definiendum id="1">B</definiendum>
				<definiens id="0">the probability that background image b j ( R , G ,</definiens>
			</definition>
</paper>

		<paper id="2031">
			<definition id="0">
				<sentence>We suggest that in addition to dictionaries , bilingual frame semantics ( word sense dictionary ) is a useful resource for lexical selection in the translation process of a statistical machine translation system .</sentence>
				<definiendum id="0">bilingual frame semantics</definiendum>
				<definiendum id="1">word sense dictionary )</definiendum>
				<definiens id="0">a useful resource for lexical selection in the translation process of a statistical machine translation system</definiens>
			</definition>
			<definition id="1">
				<sentence>FrameNet ( Baker et al. 1998 ) is a collection of lexical entries grouped by frame semantics .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">a collection of lexical entries grouped by frame semantics</definiens>
			</definition>
			<definition id="2">
				<sentence>Each lexical entry represents an individual word sense , and is associated with semantic roles and some annotated sentences .</sentence>
				<definiendum id="0">lexical entry</definiendum>
				<definiens id="0">represents an individual word sense , and is associated with semantic roles and some annotated sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>A bilingual frame , as shown in Figure 1 , simulates the semantic system of a bilingual speaker by having lexical items in two languages attached to the frame .</sentence>
				<definiendum id="0">bilingual frame</definiendum>
				<definiens id="0">simulates the semantic system of a bilingual speaker by having lexical items in two languages attached to the frame</definiens>
			</definition>
			<definition id="4">
				<sentence>The bilingual ontology is generated from iteratively estimating and maximizing the probability of a word translation given frame mapping , and that of frame mapping given word translations .</sentence>
				<definiendum id="0">bilingual ontology</definiendum>
				<definiens id="0">generated from iteratively estimating and maximizing the probability of a word translation given frame mapping , and that of frame mapping given word translations</definiens>
			</definition>
</paper>

		<paper id="2081">
			<definition id="0">
				<sentence>Baseline is the majority classification .</sentence>
				<definiendum id="0">Baseline</definiendum>
				<definiens id="0">the majority classification</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>Here , e′i is the ith subsequence of the English phone string , and c′i is the ith subsequence of the Chinese phone string .</sentence>
				<definiendum id="0">e′i</definiendum>
				<definiendum id="1">c′i</definiendum>
				<definiens id="0">the ith subsequence of the English phone string</definiens>
			</definition>
</paper>

		<paper id="1043">
			<definition id="0">
				<sentence>Thus , parser adaptation attempts to leverage existing labeled data from one domain and create a parser capable of parsing a different domain .</sentence>
				<definiendum id="0">parser adaptation</definiendum>
				<definiens id="0">attempts to leverage existing labeled data from one domain and create a parser capable of parsing a different domain</definiens>
			</definition>
			<definition id="1">
				<sentence>Gildea evaluates on sentences of length ≤ 40 , Bacchiani on all sentences .</sentence>
				<definiendum id="0">Gildea</definiendum>
				<definiens id="0">evaluates on sentences of length ≤ 40</definiens>
			</definition>
			<definition id="2">
				<sentence>The BROWN corpus ( Francis and Kuˇcera , 1979 ) consists of many different genres of text , intended to approximate a “balanced” corpus .</sentence>
				<definiendum id="0">BROWN corpus</definiendum>
				<definiens id="0">consists of many different genres of text , intended to approximate a “balanced” corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>While the full corpus consists of fiction and nonfiction domains , the sections that have been annotated in Treebank II bracketing are primarily those containing fiction .</sentence>
				<definiendum id="0">full corpus</definiendum>
				<definiens id="0">consists of fiction and nonfiction domains , the sections that have been annotated in Treebank II bracketing are primarily those containing fiction</definiens>
			</definition>
			<definition id="4">
				<sentence>Each division of the corpus consists of sentences from all available genres .</sentence>
				<definiendum id="0">division of the corpus</definiendum>
				<definiens id="0">consists of sentences from all available genres</definiens>
			</definition>
			<definition id="5">
				<sentence>The training division consists of approximately 80 % of the data , while held-out development and testing divisions each make up 10 % of the data .</sentence>
				<definiendum id="0">training division</definiendum>
			</definition>
			<definition id="6">
				<sentence>NANC contains no syntactic information and sentence boundaries are induced by a simple discriminative model .</sentence>
				<definiendum id="0">NANC</definiendum>
				<definiens id="0">contains no syntactic information and sentence boundaries are induced by a simple discriminative model</definiens>
			</definition>
			<definition id="7">
				<sentence>We conducted randomization tests for the significance of the difference in corpus f-score , based on the randomization version of the paired sample ttest described by Cohen ( 1995 ) .</sentence>
				<definiendum id="0">randomization tests</definiendum>
			</definition>
			<definition id="8">
				<sentence>The feature IN is the number prepositions in the sentence , while ID identifies the Brown subcorpus that the sentence comes from .</sentence>
				<definiendum id="0">Brown</definiendum>
				<definiens id="0">the number prepositions in the sentence</definiens>
			</definition>
</paper>

		<paper id="1080">
			<definition id="0">
				<sentence>An automatic word spacing is one of the important tasks in Korean language processing and information retrieval .</sentence>
				<definiendum id="0">automatic word spacing</definiendum>
				<definiens id="0">one of the important tasks in Korean language processing and information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>In this representation , DC CX is a contextual representation of a syllable DB CX .</sentence>
				<definiendum id="0">DC CX</definiendum>
			</definition>
			<definition id="2">
				<sentence>DC CX corresponds to DB CXA0BD DB CX when D2 BP BE .</sentence>
				<definiendum id="0">DC CX</definiendum>
				<definiens id="0">corresponds to DB CXA0BD DB CX when D2 BP BE</definiens>
			</definition>
			<definition id="3">
				<sentence>Then , the probability C8B4DC CX CYDD CX B5 is represented as C8B4DB CXA0BD DB CX CYDD CX B5 , and is computed by C8B4DB CXA0BD DB CX CYDD CX B5 BP C8B4DB CXA0BD DB CX B2DD CX B5 C8B4DD CX B5 ( 1 ) BP BVB4DB CXA0BD DB CX B2DD CX B5 BVB4DD CX B5 BN 0 1e+06 2e+06 3e+06 4e+06 5e+06 6e+06 7e+06 8e+06 Accuracy ( % ) No. of Training Examples unigram bigram trigram 4-gram 5-gram 6-gram 7-gram 8-gram 9-gram 10-gram Figure 1 : The performance of D2-gram models according to the values of D2 in automatic word spacing .</sentence>
				<definiendum id="0">probability C8B4DC CX CYDD CX B5</definiendum>
				<definiens id="0">C8B4DB CXA0BD DB CX CYDD CX B5 , and is computed by C8B4DB CXA0BD DB CX CYDD CX B5 BP C8B4DB CXA0BD DB CX B2DD CX B5 C8B4DD CX B5</definiens>
			</definition>
			<definition id="4">
				<sentence>where BV is a counting function .</sentence>
				<definiendum id="0">BV</definiendum>
			</definition>
			<definition id="5">
				<sentence>Function HowSmallShrink ( DC D2 ) Input : DC D2 : D2-grams Output : an integer for shrinking size D2A0BD for DC D2 .</sentence>
				<definiendum id="0">Function HowSmallShrink</definiendum>
			</definition>
			<definition id="6">
				<sentence>The best sequence of word spacing for the sentence is defined as DD A3 BDBNC6 BP CPD6CVD1CPDC DD BDBNC6 C8B4DD BDBNC6 CYDC BDBNC6 B5 BP CPD6CVD1CPDC DD BDBNC6 C8B4DC BDBNC6 CYDD BDBNC6 B5C8B4DD BDBNC6 B5 C8B4DC BDBNC6 B5 BP CPD6CVD1CPDC DD BDBNC6 C8B4DC BDBNC6 CYDD BDBNC6 B5C8B4DD BDBNC6 B5 by where C6 is a sentence length .</sentence>
				<definiendum id="0">word spacing for the sentence</definiendum>
			</definition>
			<definition id="7">
				<sentence>The D2-gram model is one of the most widely used methods in natural language processing and information retrieval .</sentence>
				<definiendum id="0">D2-gram model</definiendum>
				<definiens id="0">one of the most widely used methods in natural language processing and information retrieval</definiens>
			</definition>
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>Research into computer feedback for ESL writers remains largely focused on smallscale pedagogical systems implemented within the framework of CALL ( Computer Aided Language Learning ) ( Reuer 2003 ; Vanderventer Faltin , 2003 ) , while commercial ESL grammar checkers remain brittle and difficult to customize to meet the needs of ESL writers of different first-language ( L1 ) backgrounds and skill levels .</sentence>
				<definiendum id="0">Computer Aided Language Learning )</definiendum>
				<definiens id="0">difficult to customize to meet the needs of ESL writers of different first-language ( L1 ) backgrounds and skill levels</definiens>
			</definition>
			<definition id="1">
				<sentence>A correction counted as Whole if the system produced a contextually plausible substitution meeting two criteria : 1 ) number and 2 ) determiner/quantifier selection ( e.g. , many informations null much information ) .</sentence>
				<definiendum id="0">Whole</definiendum>
				<definiens id="0">if the system produced a contextually plausible substitution meeting two criteria : 1 ) number and 2 ) determiner/quantifier selection ( e.g. , many informations null much information )</definiens>
			</definition>
			<definition id="2">
				<sentence>Replacement percentages ( per sentence basis ) using different training data sets 252 equipments null an equipment versus the targeted bare noun equipment ) .</sentence>
				<definiendum id="0">Replacement percentages</definiendum>
				<definiens id="0">per sentence basis ) using different training data sets 252 equipments null an equipment versus the targeted bare noun equipment )</definiens>
			</definition>
			<definition id="3">
				<sentence>The SMT system has an inherent bias against deletion , with the result that unwanted determiners tended not to be deleted , especially in the smaller training sets .</sentence>
				<definiendum id="0">SMT system</definiendum>
				<definiens id="0">has an inherent bias against deletion , with the result that unwanted determiners tended not to be deleted , especially in the smaller training sets</definiens>
			</definition>
</paper>

		<paper id="2096">
			<definition id="0">
				<sentence>The Levenshtein Edit Distance ( LED ) is a measure of similarity between two strings named after the Russian scientist Vladimir Levenshtein , who devised the algorithm in 1965 .</sentence>
				<definiendum id="0">Levenshtein Edit Distance ( LED )</definiendum>
				<definiens id="0">a measure of similarity between two strings named after the Russian scientist Vladimir Levenshtein , who devised the algorithm in 1965</definiens>
			</definition>
			<definition id="1">
				<sentence>Similar to LED , MLED computation produces an M+1 by N+1 distance matrix , D , given two input sentences of length M and N respectively .</sentence>
				<definiendum id="0">MLED computation</definiendum>
				<definiens id="0">produces an M+1 by N+1 distance matrix , D , given two input sentences of length M and N respectively</definiens>
			</definition>
</paper>

		<paper id="2013">
			<definition id="0">
				<sentence>Additionally , many machine learning approaches , such as Support Vector Machines ( SVMs ) ( Vapnik , 1995 ) , Conditional Random Fields ( CRFs ) ( Lafferty et al. , 2001 ) , Memory-based Learning ( MBL ) ( Park and Zhang , 2003 ) , Transformation-based Learning ( TBL ) ( Brill , 1995 ) , and Hidden Markov Models ( HMMs ) ( Zhou et al. , 2000 ) , have been applied to text chunking ( Sang and Buchholz , 2000 ; Hammerton et al. , 2002 ) .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs )</definiendum>
				<definiendum id="1">Transformation-based Learning</definiendum>
				<definiendum id="2">Hidden Markov Models</definiendum>
				<definiens id="0">Lafferty et al. , 2001 ) , Memory-based Learning ( MBL )</definiens>
			</definition>
			<definition id="1">
				<sentence>Type Definition ADJP Adjective Phrase ADVP Adverbial Phrase CLP Classifier Phrase DNP DEG Phrase DP Determiner Phrase DVP DEV phrase LCP Localizer Phrase LST List Marker NP Noun Phrase PP Prepositional Phrase QP Quantifier Phrase VP Verb Phrase Table 1 : Definition of Chunks To represent the chunks clearly , we represent the data with an IOB-based model as the CoNLL00 shared task did , in which every word is to be tagged with a chunk type label extended with I ( inside a chunk ) , O ( outside a chunk ) , and B ( inside a chunk , but also the first word of the chunk ) .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">inside a chunk</definiens>
				<definiens id="1">outside a chunk</definiens>
			</definition>
			<definition id="2">
				<sentence>/ Here S1 denotes that the sentence is tagged with chunk types , and S2 denotes that the sentence is tagged with chunk tags based on the IOB-based model .</sentence>
				<definiendum id="0">S2</definiendum>
				<definiens id="0">that the sentence is tagged with chunk tags based on the IOB-based model</definiens>
			</definition>
			<definition id="3">
				<sentence>CTB4 dataset consists of 838 files .</sentence>
				<definiendum id="0">CTB4 dataset</definiendum>
			</definition>
			<definition id="4">
				<sentence>98 Support Vector Machines ( SVMs ) is a powerful supervised learning paradigm based on the Structured Risk Minimization principle from computational learning theory ( Vapnik , 1995 ) .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs )</definiendum>
				<definiens id="0">a powerful supervised learning paradigm based on the Structured Risk Minimization principle from computational learning theory</definiens>
			</definition>
			<definition id="5">
				<sentence>Conditional Random Fields is a powerful sequence labeling model ( Lafferty et al. , 2001 ) that combine the advantages of both the generative model and the classification model .</sentence>
				<definiendum id="0">Conditional Random Fields</definiendum>
				<definiens id="0">a powerful sequence labeling model ( Lafferty et al. , 2001 ) that combine the advantages of both the generative model and the classification model</definiens>
			</definition>
			<definition id="6">
				<sentence>html Memory-based Learning ( also called instance based learning ) is a non-parametric inductive learning paradigm that stores training instances in a memory structure on which predictions of new instances are based ( Walter et al. , 1999 ) .</sentence>
				<definiendum id="0">html Memory-based Learning</definiendum>
			</definition>
			<definition id="7">
				<sentence>where n is a predefined number to denote window size .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a predefined number to denote window size</definiens>
			</definition>
			<definition id="8">
				<sentence>Therefore , we define a tag-extension function fs in order to extend the chunk tags as follows : Te = fs ( T , Q ) = T ·Q ( 1 ) where , T denotes the original tag set , Q denotes the problem set , and Te denotes the extended tag set .</sentence>
				<definiendum id="0">tag-extension function fs</definiendum>
				<definiendum id="1">T</definiendum>
				<definiendum id="2">Q</definiendum>
				<definiendum id="3">Te</definiendum>
				<definiens id="0">in order to extend the chunk tags as follows : Te = fs ( T , Q ) = T ·Q ( 1 ) where ,</definiens>
				<definiens id="1">the original tag set</definiens>
				<definiens id="2">the problem set , and</definiens>
				<definiens id="3">the extended tag set</definiens>
			</definition>
			<definition id="9">
				<sentence>Figure 1 shows the experimental results , where xtics denotes the size of the training data , ”WP” refers to WORD+POS , ”P” refers to POS .</sentence>
				<definiendum id="0">xtics</definiendum>
				<definiendum id="1">”WP”</definiendum>
				<definiendum id="2">”P”</definiendum>
				<definiens id="0">the size of the training data</definiens>
			</definition>
			<definition id="10">
				<sentence>With WORD+POS , SVMs provided higher accuracy than CRFs in all training sizes .</sentence>
				<definiendum id="0">SVMs</definiendum>
			</definition>
			<definition id="11">
				<sentence>Mallet : A machine learning for language toolkit .</sentence>
				<definiendum id="0">Mallet</definiendum>
			</definition>
</paper>

		<paper id="2114">
			<definition id="0">
				<sentence>The corresponding aspirated symbols of letters ක , ග , ච , ජ , ට , ඩ , ත , ද , ප , බ namely ඛ , ඝ , ඡ , ඣ , ඪ , ථ , ධ , ඵ , භ respectively are pronounced like the corresponding unaspirates ( Karunatillake , 2004 ) .</sentence>
				<definiendum id="0">corresponding aspirated</definiendum>
				<definiens id="0">symbols of letters ක , ග , ච , ජ , ට , ඩ , ත , ද , ප , බ namely ඛ , ඝ , ඡ , ඣ , ඪ , ථ , ධ</definiens>
			</definition>
			<definition id="1">
				<sentence>A lexicon consists of a large list of words together with their pronunciation .</sentence>
				<definiendum id="0">lexicon</definiendum>
			</definition>
			<definition id="2">
				<sentence>However , when associating /ə / with consonants , /ə / should associate only with consonant graphemes excluding the graphemes “◌ං ” , “ඞ ” and “◌ඃ ” , which do not contain any vowel modifier or diacritic Hal marker .</sentence>
				<definiendum id="0">”</definiendum>
				<definiens id="0">graphemes excluding the graphemes “◌ං ” , “ඞ ” and “◌ඃ</definiens>
			</definition>
			<definition id="3">
				<sentence>A demonstration tool of the proposed G2P module integrated with Sinhala syllabification algorithm proposed by Weerasinghe et al. ( 2005 ) is available for download from : http : //www.ucsc.cmb.ac.lk/ltrl/downloads.html Acknowledgement This work has been supported through the PAN Localization Project , ( http : //www.PANL10n.net ) grant from the International Development Research Center ( IDRC ) , Ottawa , Canada , administered through the Center for Research in Urdu Language Processing , National University of Computer and Emerging Sciences , Pakistan .</sentence>
				<definiendum id="0">demonstration tool</definiendum>
				<definiens id="0">http : //www.PANL10n.net ) grant from the International Development Research Center ( IDRC ) , Ottawa , Canada , administered through the Center for Research in Urdu Language Processing , National University of Computer and Emerging Sciences , Pakistan</definiens>
			</definition>
</paper>

		<paper id="2115">
</paper>

		<paper id="1098">
			<definition id="0">
				<sentence>In the state of the art statistical machine translation , the posterior probability Pr ( eI1|f J1 ) is directly maximized using a log-linear combination of feature functions ( Och and Ney , 2002 ) : ˆeI1 = argmax eI1 exp parenleftBigsummationtextM m=1 λmhm ( e I 1 , f J 1 ) parenrightBig summationtext e′I′1 exp parenleftBigsummationtextM m=1 λmhm ( e′ I′ 1 , f J 1 ) parenrightBig ( 3 ) where hm ( eI1 , f J1 ) is a feature function , such as a ngram language model or a translation model .</sentence>
				<definiendum id="0">parenrightBig</definiendum>
				<definiens id="0">a feature function , such as a ngram language model or a translation model</definiens>
			</definition>
			<definition id="1">
				<sentence>A phrase-based translation model is one of the modern approaches which exploits a phrase , a contiguous sequence of words , as a unit of translation ( Koehn et al. , 2003 ; Zens and Ney , 2003 ; Tillman , 2004 ) .</sentence>
				<definiendum id="0">phrase-based translation model</definiendum>
				<definiens id="0">one of the modern approaches which exploits a phrase , a contiguous sequence of words , as a unit of translation ( Koehn et al. , 2003</definiens>
			</definition>
			<definition id="2">
				<sentence>The model is a class of a hierarchical phrase-based model , but constrained so that the English part of the right-hand side is restricted to a Greibach Normal Form ( GNF ) like structure : A contiguous sequence of terminals , or a phrase , is followed by a string of nonterminals .</sentence>
				<definiendum id="0">model</definiendum>
			</definition>
			<definition id="3">
				<sentence>A weighted synchronous-CFG is a rewrite system consisting of production rules whose right-hand side is paired ( Aho and Ullman , 1969 ) : X ←〈γ , α , ∼〉 ( 4 ) where X is a non-terminal , γ and α are strings of terminals and non-terminals .</sentence>
				<definiendum id="0">weighted synchronous-CFG</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">a rewrite system consisting of production rules whose right-hand side is paired ( Aho and Ullman , 1969 ) : X ←〈γ , α</definiens>
			</definition>
			<definition id="4">
				<sentence>∼ is a one-to-one correspondence for the non-terminals appeared in γ and α .</sentence>
				<definiendum id="0">∼</definiendum>
				<definiens id="0">a one-to-one correspondence for the non-terminals appeared in γ and α</definiens>
			</definition>
			<definition id="5">
				<sentence>Our model is based on Chiang ( 2005 ) ’s framework , but further restricts the form of production rules so that the aligned right-hand side α follows a GNF-like structure : X ← angbracketleftBig γ , ¯bβ , ∼ angbracketrightBig ( 7 ) where ¯b is a string of terminals , or a phrase , and beta is a ( possibly empty ) string of nonterminals .</sentence>
				<definiendum id="0">¯b</definiendum>
				<definiendum id="1">beta</definiendum>
				<definiens id="0">the form of production rules so that the aligned right-hand side α follows a GNF-like structure : X ← angbracketleftBig γ , ¯bβ</definiens>
				<definiens id="1">a string of terminals , or a phrase</definiens>
				<definiens id="2">a ( possibly empty ) string of nonterminals</definiens>
			</definition>
</paper>

		<paper id="4002">
			<definition id="0">
				<sentence>One of the most famous HCC systems , ELIZA ( Weizenbaum , 1966 ) , uses the template lling approach to generate the system’s response to a user input .</sentence>
				<definiendum id="0">ELIZA</definiendum>
				<definiens id="0">uses the template lling approach to generate the system’s response to a user input</definiens>
			</definition>
			<definition id="1">
				<sentence>During the mutation process , each one of the phrases of the selected initial population is mutated at a rate of a2a4a3a6a5 , where N is the total number of words in the phrase .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of words in the phrase</definiens>
			</definition>
			<definition id="2">
				<sentence>A phrase is evaluated according to the following algorithm10 : ifa17a19a18a21a20a23a22a25a24a27a26a25a28a30a29a31a24a33a32a35a34a36a18a21a37 , then a20a23a22a25a24a33a26a25a28 weakly accepted elsifa20a23a22a25a24a33a26a25a28a38a29a31a24a6a32a35a34a15a39a21a37 , thena20a23a22a25a24a27a26a25a28 accepted else a20a40a22a25a24a33a26a25a28 rejected where , a41 and a42 are thresholds that vary according to the n-gram type , and a5a44a43a46a45a48a47a50a49a44a13a51a45a10a52a25a53 is the frequency , or number of hits , returned by the search engine for a given n-gram .</sentence>
				<definiendum id="0">a5a44a43a46a45a48a47a50a49a44a13a51a45a10a52a25a53</definiendum>
				<definiens id="0">ifa17a19a18a21a20a23a22a25a24a27a26a25a28a30a29a31a24a33a32a35a34a36a18a21a37 , then a20a23a22a25a24a33a26a25a28 weakly accepted elsifa20a23a22a25a24a33a26a25a28a38a29a31a24a6a32a35a34a15a39a21a37 , thena20a23a22a25a24a27a26a25a28 accepted else a20a40a22a25a24a33a26a25a28 rejected where</definiens>
				<definiens id="1">the frequency , or number of hits</definiens>
			</definition>
			<definition id="3">
				<sentence>N-Gram Frequency ( hits ) System Eval .</sentence>
				<definiendum id="0">N-Gram Frequency</definiendum>
				<definiens id="0">hits ) System Eval</definiens>
			</definition>
			<definition id="4">
				<sentence>Recall is the rate of the well-generated phrases given as accepted by the system divided by the total number of well-generated phrases .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the rate of the well-generated phrases given as accepted by the system divided by the total number of well-generated phrases</definiens>
			</definition>
			<definition id="5">
				<sentence>An in uential factor in the system precision and recall is the selection of new features to be used during the mutation process .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">the selection of new features to be used during the mutation process</definiens>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>Let G = { V , E } be an undirected , weighted graph , where V is the set of nodes corresponding to sentences in the text and E is the set of weighted edges ( See Figure 2 ) .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">E</definiendum>
				<definiens id="0">the set of nodes corresponding to sentences in the text</definiens>
				<definiens id="1">the set of weighted edges ( See Figure 2 )</definiens>
			</definition>
			<definition id="1">
				<sentence>The volume of the partition is the sum of its edges to the whole graph : vol ( A ) = summationdisplay u∈A , v∈V w ( u , v ) The normalized cut criterion ( Ncut ) is then defined as follows : Ncut ( A , B ) = cut ( A , B ) vol ( A ) + cut ( A , B ) vol ( B ) By minimizing this objective we simultaneously minimize the similarity across partitions and maximize the similarity within partitions .</sentence>
				<definiendum id="0">volume of the partition</definiendum>
			</definition>
			<definition id="2">
				<sentence>This criterion is naturally extended to a k-way normalized cut : Ncutk ( V ) = cut ( A1 , V −A1 ) vol ( A 1 ) + ... + cut ( Ak , V −Ak ) vol ( A k ) where A1 ... Ak form a partition of the graph , and V −Ak is the set difference between the entire graph and partition k. Decoding Papadimitriou proved that the problem of minimizing normalized cuts on graphs is NP-complete ( Shi and Malik , 2000 ) .</sentence>
				<definiendum id="0">V −Ak</definiendum>
				<definiens id="0">A k ) where A1 ... Ak form a partition of the graph</definiens>
				<definiens id="1">the set difference between the entire graph and partition k. Decoding Papadimitriou proved that the problem of minimizing normalized cuts on graphs</definiens>
			</definition>
			<definition id="3">
				<sentence>The time complexity of the dynamic programming algorithm is O ( KN2 ) , where K is the number of partitions and N is the number of nodes in the graph or sentences in the transcript .</sentence>
				<definiendum id="0">K</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the number of partitions</definiens>
				<definiens id="1">the number of nodes in the graph or sentences in the transcript</definiens>
			</definition>
			<definition id="4">
				<sentence>These counts are weighted in accordance to their distance from the current sentence : ˜si = i+ksummationdisplay j=i e−α ( j−i ) sj , where si are vectors of word counts , and α is a parameter that controls the degree of smoothing .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">weighted in accordance to their distance from the current sentence : ˜si = i+ksummationdisplay j=i e−α ( j−i ) sj , where si are vectors of word counts</definiens>
				<definiens id="1">a parameter that controls the degree of smoothing</definiens>
			</definition>
</paper>

		<paper id="1097">
			<definition id="0">
				<sentence>Like Ittycheriah and Roukos ( 2005 ) , we converted the alignment discriminative training corpus links into a special corpus consisting of parallel sentences where each sentence consists only of a single word involved in the link .</sentence>
				<definiendum id="0">alignment discriminative training</definiendum>
				<definiens id="0">corpus links into a special corpus consisting of parallel sentences where each sentence consists only of a single word involved in the link</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>Type : whether the pronominal anaphor is a male-person pronoun ( like he ) , female-person pronoun ( like she ) , single gender-neuter pronoun ( like it ) , or plural gender-neuter pronoun ( like they ) Subject : whether the candidate is a subject of a sentence , a subject of a clause , or not .</sentence>
				<definiendum id="0">Type</definiendum>
				<definiendum id="1">female-person pronoun</definiendum>
				<definiens id="0">or plural gender-neuter pronoun ( like they ) Subject : whether the candidate is a subject of a sentence , a subject of a clause</definiens>
			</definition>
			<definition id="1">
				<sentence>Distance : the sentence distance between the candidate and the pronominal anaphor .</sentence>
				<definiendum id="0">Distance</definiendum>
				<definiens id="0">the sentence distance between the candidate and the pronominal anaphor</definiens>
			</definition>
			<definition id="2">
				<sentence>Parallelism : whether the candidate has an identical collocation pattern with the pronominal anaphor .</sentence>
				<definiendum id="0">Parallelism</definiendum>
				<definiens id="0">whether the candidate has an identical collocation pattern with the pronominal anaphor</definiens>
			</definition>
			<definition id="3">
				<sentence>In our study we define the composite kernel as follows : Kc ( x1 , x2 ) = Kn ( x1 , x2 ) |K n ( x1 , x2 ) | ∗ Kt ( x1 , x2 ) |K t ( x1 , x2 ) | ( 2 ) where Kt is the convolution tree kernel defined for the structured feature , and Kn is the kernel applied on the normal features .</sentence>
				<definiendum id="0">Kt</definiendum>
				<definiendum id="1">Kn</definiendum>
				<definiens id="0">the kernel applied on the normal features</definiens>
			</definition>
			<definition id="4">
				<sentence>The new composite kernel Kc , defined as the 4The length of a kernel K is defined as |K ( x1 , x2 ) | =radicalbig K ( x1 , x1 ) ∗K ( x2 , x2 ) 44 multiplier of normalized Kt and Kn , will return a value close to 1 only if both the structured features and the normal features from the two vectors have high similarity under their respective kernels .</sentence>
				<definiendum id="0">=radicalbig K</definiendum>
				<definiens id="0">return a value close to 1 only if both the structured features and the normal features from the two vectors have high similarity under their respective kernels</definiens>
			</definition>
</paper>

		<paper id="2053">
			<definition id="0">
				<sentence>Or Enron’s employee’s assistance Program ( EAP ) , sending an email to all employees , letting them know that in case of finding themselves in stressful situations they can use some of the services that Enron provides for them or their families .</sentence>
				<definiendum id="0">Enron’s employee’s assistance Program</definiendum>
				<definiens id="0">sending an email to all employees , letting them know that in case of finding themselves in stressful situations they can use some of the services that Enron provides for them or their families</definiens>
			</definition>
			<definition id="1">
				<sentence>The Core Business class contains 4,000 messages ( approx 900,000 words ) , while Close Personal contains approximately 1,000 messages ( 220,000 words ) .</sentence>
				<definiendum id="0">Core Business class</definiendum>
				<definiens id="0">contains 4,000 messages ( approx 900,000 words ) , while Close Personal contains approximately 1,000 messages ( 220,000 words )</definiens>
			</definition>
			<definition id="2">
				<sentence>The Enron Corpus : A New Data Set for Email Classification Research .</sentence>
				<definiendum id="0">Enron Corpus</definiendum>
			</definition>
</paper>

		<paper id="2113">
			<definition id="0">
				<sentence>Spoken Language Understanding ( SLU ) addresses the problem of extracting semantic meaning conveyed in an utterance .</sentence>
				<definiendum id="0">SLU )</definiendum>
				<definiens id="0">addresses the problem of extracting semantic meaning conveyed in an utterance</definiens>
			</definition>
			<definition id="1">
				<sentence>A generative HMM/CFG composite model , which integrates easy-toobtain domain knowledge into a data-driven statistical learning framework , has previously been introduced to reduce data requirement .</sentence>
				<definiendum id="0">generative HMM/CFG composite model</definiendum>
				<definiens id="0">integrates easy-toobtain domain knowledge into a data-driven statistical learning framework , has previously been introduced to reduce data requirement</definiens>
			</definition>
			<definition id="2">
				<sentence>Experimental results show that the conditional models achieve more than 20 % relative reduction in slot error rate over the HMM/CFG model , which had already achieved an SLU accuracy at the same level as the best results reported on the ATIS data .</sentence>
				<definiendum id="0">HMM/CFG model</definiendum>
				<definiens id="0">the conditional models achieve more than 20 % relative reduction in slot error rate over the</definiens>
			</definition>
			<definition id="3">
				<sentence>Spoken Language Understanding ( SLU ) addresses the problem of extracting meaning conveyed in an utterance .</sentence>
				<definiendum id="0">SLU )</definiendum>
				<definiens id="0">addresses the problem of extracting meaning conveyed in an utterance</definiens>
			</definition>
			<definition id="4">
				<sentence>The semantic representation for “Show me the flights departing from Seattle arriving at Boston” is an instantiation of the semantic frames in Figure 1 .</sentence>
				<definiendum id="0">Boston”</definiendum>
				<definiens id="0">an instantiation of the semantic frames in Figure 1</definiens>
			</definition>
			<definition id="5">
				<sentence>With the flat start initialization ( top curve ) , the error rate never comes close to the 5 % baseline error rate of the HMM/CFG model .</sentence>
				<definiendum id="0">error rate</definiendum>
				<definiens id="0">top curve</definiens>
			</definition>
			<definition id="6">
				<sentence>1 ( , , 1 ) ostΘ − is the set of k words ( where k is an adjustable window size ) in front of the longest sequence that ends at position 1t − and that is CFG-covered by 1 Slot ( ) s .</sentence>
				<definiendum id="0">k</definiendum>
			</definition>
</paper>

		<paper id="4020">
			<definition id="0">
				<sentence>The first public release of the RASP system ( Briscoe &amp; Carroll , 2002 ) has been downloaded by over 120 sites and used in diverse natural language processing tasks , such as anaphora resolution , word sense disambiguation , identifying rhetorical relations , resolving metonymy , detecting compositionality in phrasal verbs , and diverse applications , such as topic and sentiment classification , text anonymisation , summarisation , information extraction , and open domain question answering .</sentence>
				<definiendum id="0">RASP system</definiendum>
				<definiens id="0">downloaded by over 120 sites and used in diverse natural language processing tasks , such as anaphora resolution , word sense disambiguation , identifying rhetorical relations , resolving metonymy , detecting compositionality in phrasal verbs , and diverse applications , such as topic and sentiment classification , text anonymisation , summarisation , information extraction</definiens>
			</definition>
</paper>

		<paper id="3007">
			<definition id="0">
				<sentence>Automatic summarization is a powerful way to overcome such difficulty .</sentence>
				<definiendum id="0">Automatic summarization</definiendum>
				<definiens id="0">a powerful way to overcome such difficulty</definiens>
			</definition>
			<definition id="1">
				<sentence>ROUGE compares the machine-generated summaries with manually provided summaries , based on unigram overlap , bigram overlap , and overlap with long distance .</sentence>
				<definiendum id="0">ROUGE</definiendum>
				<definiens id="0">compares the machine-generated summaries with manually provided summaries , based on unigram overlap , bigram overlap</definiens>
			</definition>
			<definition id="2">
				<sentence>Centroid is a successful term-based summarization approach .</sentence>
				<definiendum id="0">Centroid</definiendum>
				<definiens id="0">a successful term-based summarization approach</definiens>
			</definition>
</paper>

		<paper id="2093">
			<definition id="0">
				<sentence>The inputs to the neural network are the indices of the n−1 previous words in the vocabulary hj=wj−n+1 , ... , wj−2 , wj−1 and the outputs are the posterior probabilities of all words of the vocabulary : P ( wj = i|hj ) ∀i ∈ [ 1 , N ] ( 2 ) where N is the size of the vocabulary .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the indices of the n−1 previous words in the vocabulary hj=wj−n+1 , ...</definiens>
			</definition>
			<definition id="1">
				<sentence>Training is performed with the standard back-propagation algorithm minimizing the following error function : E = Nsummationdisplay i=1 ti logpi +β  summationdisplay jl m2jl +summationdisplay ij v2ij   ( 6 ) where ti denotes the desired output , i.e. , the probability should be 1.0 for the next word in the training sentence and 0.0 for all the other ones .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiens id="0">the desired output</definiens>
			</definition>
			<definition id="2">
				<sentence>P is the size of one projection and H , N is the size of the hidden and output layer respectively .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the size of the hidden</definiens>
			</definition>
			<definition id="3">
				<sentence>The training material consists of the minutes edited by the European Parliament in several languages , also known as the Final Text Editions ( Gollan et al. , 2005 ) .</sentence>
				<definiendum id="0">training material</definiendum>
			</definition>
			<definition id="4">
				<sentence>Some SMT decoders have an execution complexity that increases rapidly with the length of the sentences to be translated , which are usually split 729 into smaller chunks and translated separately .</sentence>
				<definiendum id="0">SMT decoders</definiendum>
				<definiendum id="1">execution complexity</definiendum>
				<definiens id="0">increases rapidly with the length of the sentences to be translated</definiens>
			</definition>
</paper>

		<paper id="1030">
			<definition id="0">
				<sentence>Erater ( Burstein et al. , 1998 ) , developed by the Educational Testing Service , began being used for operational scoring of the Analytical Writing Assessment in the Graduate Management Admission Test ( GMAT ) , an entrance examination for business graduate schools , in February 1999 , and it has scored approximately 360,000 essays per year .</sentence>
				<definiendum id="0">Erater</definiendum>
				<definiens id="0">developed by the Educational Testing Service , began being used for operational scoring of the Analytical Writing Assessment in the Graduate Management Admission Test ( GMAT</definiens>
			</definition>
			<definition id="1">
				<sentence>The Intelligent Essay Assessor ( IEA ) is a set of software tools for scoring the quality of the conceptual content of essays based on latent semantic analysis ( Foltz et al. , 1999 ) .</sentence>
				<definiendum id="0">Intelligent Essay Assessor ( IEA )</definiendum>
				<definiens id="0">a set of software tools for scoring the quality of the conceptual content of essays based on latent semantic analysis</definiens>
			</definition>
			<definition id="2">
				<sentence>The Bayesian Essay Test Scoring sYstem ( BETSY ) is a windows-based program that classifies text based on trained material .</sentence>
				<definiendum id="0">Bayesian Essay Test Scoring sYstem ( BETSY )</definiendum>
				<definiens id="0">a windows-based program that classifies text based on trained material</definiens>
			</definition>
			<definition id="3">
				<sentence>These include JUMAN ( http : //www-lab25.kuee.kyotou.ac.jp/nlresource/juman.html ) , developed by the Language Media Laboratory of Kyoto University , and ChaSen ( http : //chasen.aist-nara.ac.jp/ , used in this study ) from the Matsumoto Laboratory of the Nara Institute of Science and Technology .</sentence>
				<definiendum id="0">JUMAN ( http</definiendum>
				<definiendum id="1">ChaSen ( http</definiendum>
				<definiens id="0">//www-lab25.kuee.kyotou.ac.jp/nlresource/juman.html ) , developed by the Language Media Laboratory of Kyoto University</definiens>
				<definiens id="1">//chasen.aist-nara.ac.jp/ , used in this study ) from the Matsumoto Laboratory of the Nara Institute of Science and Technology</definiens>
			</definition>
			<definition id="4">
				<sentence>In addition , ( 8 ) sentence structure and ( 11 ) logic/consistency , which is deeply related to “organization , ” had correlation coefficients of of “rhetoric , ” and ( 6 ) topic relevance and ( 14 ) nuance , which are though to be deeply related to “content , ” had correlation coefficients of 0.27 and Our system , Jess , is the first automated Japanese essay scorer and has become most famous in Japan , since it was introduced in February 2005 in a headline in the Asahi Daily News , which is well known as the most reliable and most representative newspaper of Japan .</sentence>
				<definiendum id="0">logic/consistency</definiendum>
				<definiendum id="1">nuance</definiendum>
				<definiens id="0">the most reliable and most representative newspaper of Japan</definiens>
			</definition>
			<definition id="5">
				<sentence>As metrics to portray rhetoric , Jess uses ( 1 ) ease of reading , ( 2 ) diversity of vocabulary , ( 3 ) percentage of big words ( long , difficult words ) , and ( 4 ) percentage of passive sentences , in accordance with Maekawa ( 1995 ) and Nagao ( 1996 ) .</sentence>
				<definiendum id="0">Jess</definiendum>
				<definiens id="0">uses ( 1 ) ease of reading , ( 2 ) diversity of vocabulary , ( 3 ) percentage of big words ( long , difficult words ) , and ( 4 ) percentage of passive sentences</definiens>
			</definition>
			<definition id="6">
				<sentence>An “outlier” is an item of data more than 1.5 times the interquartile range .</sentence>
				<definiendum id="0">“outlier”</definiendum>
				<definiens id="0">an item of data more than 1.5 times the interquartile range</definiens>
			</definition>
			<definition id="7">
				<sentence>Explanation : A conjunctive relationship typified by words and phrases such as “namely , ” “in short , ” “in other words , ” and “in summary.”</sentence>
				<definiendum id="0">Explanation</definiendum>
				<definiens id="0">A conjunctive relationship typified by words</definiens>
			</definition>
			<definition id="8">
				<sentence>Illustration : A conjunctive relationship most typified by the phrase “for example” having a structure that either explains or demonstrates by example .</sentence>
				<definiendum id="0">Illustration</definiendum>
				<definiens id="0">A conjunctive relationship most typified by the phrase “for example” having a structure that either explains or demonstrates by example</definiens>
			</definition>
			<definition id="9">
				<sentence>Here , a difference appears between e-rater and Jess , which uses the point-deduction system for scoring .</sentence>
				<definiendum id="0">Jess</definiendum>
				<definiens id="0">uses the point-deduction system for scoring</definiens>
			</definition>
</paper>

		<paper id="2036">
			<definition id="0">
				<sentence>Synchronous Context-Free Grammars ( SCFGs ) have been successfully exploited as translation models in machine translation applications .</sentence>
				<definiendum id="0">Synchronous Context-Free Grammars ( SCFGs</definiendum>
				<definiens id="0">translation models in machine translation applications</definiens>
			</definition>
			<definition id="1">
				<sentence>Synchronous Context-Free Grammars ( SCFGs ) are a generalization of the Context-Free Grammar ( CFG ) formalism to simultaneously produce strings in two languages .</sentence>
				<definiendum id="0">Synchronous Context-Free Grammars ( SCFGs )</definiendum>
			</definition>
			<definition id="2">
				<sentence>A synchronous context-free grammar ( SCFG ) is de ned as a CFG , with the difference that it uses synchronous rules of the form [ A1 →α1 , A2 →α2 ] , with A1 , A2 nonterminals and α1 , α2 synchronous strings .</sentence>
				<definiendum id="0">synchronous context-free grammar ( SCFG</definiendum>
				<definiens id="0">a CFG , with the difference that it uses synchronous rules of the form [ A1 →α1 , A2 →α2 ] , with A1 , A2 nonterminals and α1 , α2 synchronous strings</definiens>
			</definition>
			<definition id="3">
				<sentence>REDUCE : commits reduction by updating min and max arrays .</sentence>
				<definiendum id="0">REDUCE</definiendum>
			</definition>
			<definition id="4">
				<sentence>maintain two arrays : h , which maps from vertical to horizontal positions within the current subsequence , and v which maps from horizontal to vertical positions .</sentence>
				<definiendum id="0">h</definiendum>
				<definiens id="0">maps from vertical to horizontal positions within the current subsequence , and v which maps from horizontal to vertical positions</definiens>
			</definition>
</paper>

		<paper id="2035">
			<definition id="0">
				<sentence>Another field of interest is the constitution of multilingual lexical databases such as the project planned by the European Commission 's Joint Research Centre ( JRC ) or the more established Papillon project .</sentence>
				<definiendum id="0">JRC</definiendum>
				<definiens id="0">the constitution of multilingual lexical databases such as the project planned by the European Commission 's Joint Research Centre (</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , each bitext is a quadruple &lt; T1 , T2 , Fs , C &gt; where T1 and T2 are the two texts , Fs is the function that reduces T1 to an element set Fs ( T1 ) and also reduces T2 to an element set Fs ( T2 ) , and C is a subset of the Cartesian product of Fs ( T1 ) x Fs ( T2 ) ( Harris , 1988 ) .</sentence>
				<definiendum id="0">Fs</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">T2 )</definiendum>
				<definiens id="0">a quadruple &lt; T1 , T2 , Fs , C &gt; where T1 and T2 are the two texts</definiens>
				<definiens id="1">the function that reduces T1 to an element set Fs ( T1 ) and also reduces T2 to an element set Fs ( T2 ) , and</definiens>
				<definiens id="2">a subset of the Cartesian product of Fs ( T1 ) x Fs</definiens>
			</definition>
			<definition id="2">
				<sentence>“thyroid cancer” : list of segments where the sequence appears 45 , 46 , 46 , 48 , 51 , 51 Then we convert this list in a n L -dimension vector v L , where n L is the number of textual segments of the document of language L. Each dimension contains the number of occurrences present in the segment .</sentence>
				<definiendum id="0">n L</definiendum>
				<definiens id="0">the number of textual segments of the document of language L. Each dimension contains the number of occurrences present in the segment</definiens>
			</definition>
</paper>

		<paper id="2110">
			<definition id="0">
				<sentence>Latent semantic analysis ( LSA ) is the most well-known method that uses the frequency of words in a fraction of documents to assess the coordinates of word vectors and singular value decomposition ( SVD ) to reduce the dimension .</sentence>
				<definiendum id="0">Latent semantic analysis</definiendum>
				<definiendum id="1">LSA</definiendum>
				<definiens id="0">the most well-known method that uses the frequency of words in a fraction of documents to assess the coordinates of word vectors and singular value decomposition ( SVD ) to reduce the dimension</definiens>
			</definition>
			<definition id="1">
				<sentence>wij = tfij × parenleftbigg log mdf i + 1 parenrightbigg ( 3 ) In this formula , tfij denotes the number of times the word ti occurs in a piece of text sj , and dfi denotes the number of pieces in which the word ti occurs .</sentence>
				<definiendum id="0">tfij</definiendum>
				<definiendum id="1">dfi</definiendum>
				<definiens id="0">the number of times the word ti occurs in a piece of text sj , and</definiens>
				<definiens id="1">the number of pieces in which the word ti occurs</definiens>
			</definition>
			<definition id="2">
				<sentence>Cooccurrence-based method ( COO ) In the cooccurrence-based method , a vector element wij is assessed as the number of times words ti and tj occur in the same piece of text , and thus M is an n × n symmetric matrix .</sentence>
				<definiendum id="0">Cooccurrence-based method</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">an n × n symmetric matrix</definiens>
			</definition>
			<definition id="3">
				<sentence>Dictionary-based method ( DIC ) In the dictionary-based method , a vector element wij is assessed by the following formula : wij =  fij + α radicalBiggsummationdisplay k fikfkj + βfji  × log n dfj ( 4 ) where fij denotes the number of times the word tj occurs in the sense definitions of the word ti , and dfj denotes the number of words whose sense definitions contain the word tj .</sentence>
				<definiendum id="0">Dictionary-based method</definiendum>
				<definiendum id="1">fij</definiendum>
				<definiendum id="2">dfj</definiendum>
				<definiens id="0">the number of times the word tj occurs in the sense definitions of the word ti</definiens>
				<definiens id="1">the number of words whose sense definitions contain the word tj</definiens>
			</definition>
			<definition id="4">
				<sentence>Precision is the ratio of the number of human-produced associates chosen by computer to the number i of computer-chosen associates .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio of the number of human-produced associates chosen by computer to the number i of computer-chosen associates</definiens>
			</definition>
			<definition id="5">
				<sentence>0 100 200 300 400 500 600 700 800 9001000 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12 a11a12× × × × × × × × × × × × × × × × × × × × a13 a13 a13 a13 a13 a13 a13 a13 a13 a13a14a13 a13 a13 a13 a13 a13 a13 a13 a13 a13 + ++ +++++++++++++++++ a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a15a16 a17a18a17 LSA ( Ave ) a19a20 a19a20 LSA ( Max ) + + COO ( Ave ) × × COO ( Max ) a21a22 a21a22 DIC Number of Dimensions Mean Precision Figure 4 : Average precision of word association judgment for familiar words the cooccurrence-based vector spaces reflect associative similarity between words more than the dictionary-based space .</sentence>
				<definiendum id="0">cooccurrence-based vector spaces</definiendum>
				<definiens id="0">Average precision of word association judgment for familiar words the</definiens>
			</definition>
</paper>

		<paper id="2120">
			<definition id="0">
				<sentence>Both semantic relations and roles are defined in many knowledge resources or ontologies , such as FrameNet ( Baker et al. , 2004 ) and HowNet with 65,000 concepts in Chinese and close to 75,000 English equivalents , is a bilingual knowledge-base describing relations between concepts and relations between the attributes of concepts with ontological view ( Dong and Dong 2006 ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">a bilingual knowledge-base describing relations between concepts and relations between the attributes of concepts with ontological view</definiens>
			</definition>
			<definition id="1">
				<sentence>The dependency graph which is composed of a set of dependency relations in the word sequence W is defined as 111 222 1 1 ( 1 ) ( ) { ( , ) , ( , ) , ... , ( , ) } ii i ihhmmh D W DR w w DR w w DR w w −− − = .</sentence>
				<definiendum id="0">dependency graph</definiendum>
				<definiens id="0">composed of a set of dependency relations in the word sequence W is defined as 111 222 1 1 ( 1 ) ( ) { ( , ) , ( , ) , ... , ( , ) } ii i ihhmmh D W DR w</definiens>
			</definition>
			<definition id="2">
				<sentence>( ) ( ) ( ) ( ) *1 1 11 arg ax | , arg ax , | , arg ax | , , | , t t i t i tt SA tt i SA D tt t ii SA D SA m P SA W H mPSADWH mPSADWHPDWH − − −− = = =× ∑ ∑ where SA * and SA t are the most probable speech act and the potential speech act at the t-th dialogue turn , respectively .</sentence>
				<definiendum id="0">SA *</definiendum>
				<definiens id="0">arg ax | , arg ax , | , arg ax | , , | , t t</definiens>
			</definition>
			<definition id="3">
				<sentence>( ) ( ) 11 | , , | , tt tt ii PSA DWH PSA DH −− ≅ ( 2 ) According to Bayes’ rule , the probability ( ) 1 | , tt i PSA DH − can be rewritten as : ( ) ( ) ( ) ( ) ( ) 1 1 1 , | | , , | l tt t i tt i t ill SA PDH SA PSA PSA DH PDH SA PSA − − − = ∑ ( 3 ) As the history is defined as the speech act sequence , the joint probability of D i and H t-1 given the speech act SA t can be expressed as Equation ( 4 ) .</sentence>
				<definiendum id="0">tt tt ii PSA DWH PSA DH</definiendum>
				<definiendum id="1">SA PDH SA PSA PSA DH PDH SA PSA</definiendum>
				<definiens id="0">the probability ( ) 1 | , tt i PSA DH − can be rewritten as : ( ) ( ) ( ) ( ) ( ) 1 1 1 , | |</definiens>
			</definition>
			<definition id="4">
				<sentence>The probabilities of the headwords are estimated according to the probabilistic context free grammar ( PCFG ) trained on the Treebank developed by Sinica ( Chen et al. , 2001 ) .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">estimated according to the probabilistic context free grammar (</definiens>
			</definition>
</paper>

		<paper id="2121">
			<definition id="0">
				<sentence>However , an ontology is a static knowledge resource , which may not reflect the dynamic characteristics of language .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">a static knowledge resource , which may not reflect the dynamic characteristics of language</definiens>
			</definition>
			<definition id="1">
				<sentence>The HAL model , which is a cognitive motivated model , provides an informative infrastructure to make the CIP capable of learning from unannotated corpora .</sentence>
				<definiendum id="0">HAL model</definiendum>
				<definiens id="0">a cognitive motivated model , provides an informative infrastructure to make the CIP capable of learning from unannotated corpora</definiens>
			</definition>
			<definition id="2">
				<sentence>The HAL model represents each word in the vocabulary using a vector representation .</sentence>
				<definiendum id="0">HAL model</definiendum>
				<definiens id="0">each word in the vocabulary using a vector representation</definiens>
			</definition>
			<definition id="3">
				<sentence>The HAL space views the corpus as a sequence of words .</sentence>
				<definiendum id="0">HAL space</definiendum>
				<definiens id="0">views the corpus as a sequence of words</definiens>
			</definition>
			<definition id="4">
				<sentence>The resultant HAL space is an N N× matrix , where N is the vocabulary size .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the vocabulary size</definiens>
			</definition>
			<definition id="5">
				<sentence>the weight of the j-th dimension ( j t ) of a vector , and N is the dimensionality of a vector , i.e. , vocabulary size .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the dimensionality of a vector , i.e. , vocabulary size</definiens>
			</definition>
			<definition id="6">
				<sentence>*log , ( ) ij ij vector ct ct j N ww vf t = ( 2 ) where vector N denotes the total number of vectors , and ( ) j vf t denotes the number of vectors with j t as the dimension .</sentence>
				<definiendum id="0">vector N</definiendum>
				<definiendum id="1">( ) j vf t</definiendum>
				<definiens id="0">the total number of vectors , and</definiens>
				<definiens id="1">the number of vectors with j t as the dimension</definiens>
			</definition>
			<definition id="7">
				<sentence>Let 1 ( , ... , ) S spc c= be a semantic pattern with S constituent concepts , i.e. , length S. The concept combination is defined as 12 3 ( ( ... ( ) ) ... ) , sS cccc c⊕ ≡⊕⊕⊕⊕ ( 4 ) where ⊕ denotes the symbol representing the combination operator over the HAL space , s c⊕ denotes a new concept generated by the concept combination .</sentence>
				<definiendum id="0">1 ( , ... , ) S spc</definiendum>
				<definiens id="0">a semantic pattern with S constituent concepts , i.e. , length</definiens>
			</definition>
			<definition id="8">
				<sentence>Given a seed pattern , the CIP is to induce a set of relevant semantic patterns with variable lengths ( from 2 to k ) .</sentence>
				<definiendum id="0">CIP</definiendum>
				<definiens id="0">to induce a set of relevant semantic patterns with variable lengths</definiens>
			</definition>
			<definition id="9">
				<sentence>Let 1 ( , ... , ) S spc c= be a semantic pattern and 1 ( , ... , ) seed R spcc= be a given seed pattern , their distance is defined as ( ) , ( , ) , seed s r Dist sp sp Dist c c=⊕⊕ ( 8 ) where ( , ) s r Dist c c⊕⊕ denotes the distance between two semantic patterns in the HAL space .</sentence>
				<definiendum id="0">1 ( , ... , ) S spc</definiendum>
				<definiendum id="1">Dist c c⊕⊕</definiendum>
				<definiens id="0">a semantic pattern and 1 ( , ... , ) seed R spcc= be a given seed pattern , their distance is defined as ( ) , ( , )</definiens>
				<definiens id="1">the distance between two semantic patterns in the HAL space</definiens>
			</definition>
			<definition id="10">
				<sentence>sr s r left left Right Right seed c c c c Dist sp sp Dist v v Dist v v ⊕⊕ ⊕ ⊕ =+ ( 9 ) Because the weights of the vectors are represented using a probabilistic framework , each vector of a concept can be considered as a probabilistic distribution of the context words .</sentence>
				<definiendum id="0">probabilistic framework</definiendum>
				<definiens id="0">s r left left Right Right seed c c c</definiens>
				<definiens id="1">a probabilistic distribution of the context words</definiens>
			</definition>
			<definition id="11">
				<sentence>, ) log ( ) k kk k i i Pw w MI w w P w w Pw = = ∏ ( 16 ) where 1 ( , ... ) k Pw w is the probability of the k words co-occurring in a sentence in the training set , and ( ) i Pw is the probability of a single word occurring in the training set .</sentence>
				<definiendum id="0">Pw</definiendum>
				<definiens id="0">the probability of the k words co-occurring in a sentence in the training set , and ( ) i</definiens>
				<definiens id="1">the probability of a single word occurring in the training set</definiens>
			</definition>
</paper>

		<paper id="4004">
			<definition id="0">
				<sentence>The task of sense annotation consists in the assignment of the appropriate senses to words in context .</sentence>
				<definiendum id="0">sense annotation</definiendum>
				<definiens id="0">consists in the assignment of the appropriate senses to words in context</definiens>
			</definition>
			<definition id="1">
				<sentence>Unfortunately , WordNet is a fine-grained resource , which encodes possibly subtle sense distictions .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a fine-grained resource , which encodes possibly subtle sense distictions</definiens>
			</definition>
			<definition id="2">
				<sentence>The validation task can be defined as follows : let w be a word in a sentence , previously annotated by a set of annotators A = fa1 ; a2 ; : : : ; ang each providing a sense for w , and let SA = fs1 ; s2 ; : : : ; smg Senses ( w ) be the set of senses chosen for w by the annotators in A , where Senses ( w ) is the set of senses of w in the reference inventory ( e.g. WordNet ) .</sentence>
				<definiendum id="0">validation task</definiendum>
				<definiendum id="1">Senses ( w )</definiendum>
				<definiens id="0">follows : let w be a word in a sentence , previously annotated by a set of annotators A = fa1 ; a2 ; : : : ; ang each providing a sense for w , and let SA = fs1 ; s2 ; : : : ; smg Senses ( w ) be the set of senses chosen for w by the annotators in A</definiens>
			</definition>
			<definition id="3">
				<sentence>SSI exploits an extensive lexical knowledge base , built upon the WordNet lexicon and enriched with collocation information representing seman1SSI is available online at http : //lcl.di.uniroma1.it/ssi .</sentence>
				<definiendum id="0">SSI</definiendum>
				<definiens id="0">exploits an extensive lexical knowledge base</definiens>
			</definition>
			<definition id="4">
				<sentence>Given a word context C = fw1 ; : : : ; wkg , SSI builds a graph G = ( V ; E ) such that V = kS i=1 SensesWN ( wi ) and ( s ; s0 ) 2 E if there is at least one semantic interconnection between s and s0 in the lexical knowledge base .</sentence>
				<definiendum id="0">SSI</definiendum>
				<definiens id="0">builds a graph G = ( V ; E ) such that V = kS i=1 SensesWN ( wi</definiens>
			</definition>
			<definition id="5">
				<sentence>A semantic interconnection pattern is a relevant sequence of edges selected according to a manually-created contextfree grammar , i.e. a path connecting a pair of word senses , possibly including a number of intermediate concepts .</sentence>
				<definiendum id="0">semantic interconnection pattern</definiendum>
				<definiens id="0">a relevant sequence of edges selected according to a manually-created contextfree grammar , i.e. a path connecting a pair of word senses , possibly including a number of intermediate concepts</definiens>
			</definition>
			<definition id="6">
				<sentence>The grammar consists of a small number of rules , inspired by the notion of lexical chains ( Morris and Hirst , 1991 ) .</sentence>
				<definiendum id="0">grammar</definiendum>
			</definition>
			<definition id="7">
				<sentence>esimilarityS3jeantonymyS3jesimilarityjeantonymy ( adjectives ) Table 1 : An excerpt of the context-free grammar for the recognition of semantic interconnections .</sentence>
				<definiendum id="0">esimilarityS3jeantonymyS3jesimilarityjeantonymy ( adjectives</definiendum>
				<definiens id="0">An excerpt of the context-free grammar for the recognition of semantic interconnections</definiens>
			</definition>
</paper>

		<paper id="1062">
			<definition id="0">
				<sentence>The synchronous tree substitution grammar ( STSG ) presented in ( Hajic etc. 2004 ) is a simplified version of STAG which allows tree substitution operation , but prohibits the operation of tree adjunction .</sentence>
				<definiendum id="0">synchronous tree substitution grammar ( STSG</definiendum>
				<definiens id="0">a simplified version of STAG which allows tree substitution operation , but prohibits the operation of tree adjunction</definiens>
			</definition>
			<definition id="1">
				<sentence>Finally NULL refers to the empty node introduced for node deletion .</sentence>
				<definiendum id="0">NULL</definiendum>
				<definiens id="0">the empty node introduced for node deletion</definiens>
			</definition>
			<definition id="2">
				<sentence>Given two HTML documents F ( in French ) and E ( in English ) , the tree alignment task is defined as searching for A which maximizes the following probability : ( ) ( ) ( ) EEFEF TAATTTTA Pr , Pr , Pr ( 1 ) where ( ) ETAPr represents the prior knowledge of the alignment configurations .</sentence>
				<definiendum id="0">HTML documents F</definiendum>
				<definiendum id="1">E</definiendum>
				<definiendum id="2">( ) ETAPr</definiendum>
			</definition>
			<definition id="3">
				<sentence>By introducing dp which refers to the probability of a source or target node deletion occurring in an alignment configuration , the alignment prior ( ) ETAPr is assumed as the following binominal distribution : ( ) ( ) MdLdE ppTA 1Pr where L is the count of non-empty alignments in A , and M is the count of source and target node deletions in A. As to ( ) ATT EF , Pr , we can estimate as ( ) ( ) ATTATT EFEF , Pr , Pr 11= , and ( ) ATTr EiFl , P can be calculated recursively depending on the alignment configuration of A : ( 1 ) If FlN is aligned with EiN , and the children of F lN are aligned with the children of E iN , then we have ( ) ( ) [ ] = ATCNTCNNN ATT K E iK F l E i F l E i F l , .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">the probability of a source or target node deletion occurring in an alignment configuration</definiens>
			</definition>
			<definition id="4">
				<sentence>PrPr , Pr ,1= where K is the degree of FlN ( 3 ) If EiN is deleted , and FlN is aligned with the children of EiN , then ( ) ( ) ATCTTATT KEiFlEiFl , .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the degree of FlN ( 3 ) If EiN is deleted , and FlN is aligned with the children of EiN</definiens>
			</definition>
			<definition id="5">
				<sentence>Pr , Pr ] ,1 [ = where K is the degree of EiN .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the degree of EiN</definiens>
			</definition>
			<definition id="6">
				<sentence>The time complexity of the decoding algorithm is ) ) ) ( degree ) ( ( degree|||TO ( | 2F EFE TTT +·· , where the degree of a tree is defined as the largest degree of its nodes .</sentence>
				<definiendum id="0">time complexity of the decoding algorithm</definiendum>
			</definition>
			<definition id="7">
				<sentence>Then , a minimum edit distance between the two tag strings associated with the candidate pair is computed , and the HMTL tag similarity score is defined as the ratio of match operation number to the total operation number .</sentence>
				<definiendum id="0">HMTL tag similarity score</definiendum>
				<definiens id="0">the ratio of match operation number to the total operation number</definiens>
			</definition>
			<definition id="8">
				<sentence>The sentence alignment score is defined as the ratio of the number of aligned sentences and the total number of sentences in both files .</sentence>
				<definiendum id="0">sentence alignment score</definiendum>
				<definiens id="0">the ratio of the number of aligned sentences and the total number of sentences in both files</definiens>
			</definition>
			<definition id="9">
				<sentence>Following ( Nie et al 1999 ; Ma and Liberman 1999 ; Chen , Chau and Yeh 2004 ) , the URL pattern-based mining consists of three steps : ( i ) host crawling for URL collection ; ( ii ) candidate pair identification by pre-defined URL pattern matching ; ( iii ) candidate pair verification .</sentence>
				<definiendum id="0">URL pattern-based mining</definiendum>
				<definiens id="0">consists of three steps : ( i ) host crawling for URL collection ; ( ii ) candidate pair identification by pre-defined URL pattern matching ; ( iii ) candidate pair verification</definiens>
			</definition>
</paper>

		<paper id="3010">
			<definition id="0">
				<sentence>ILP employs techniques of both Machine Learning and Logic Programming to build firstorder logic theories from examples and background knowledge , which are also represented by means of first-order logic clauses .</sentence>
				<definiendum id="0">ILP</definiendum>
				<definiens id="0">employs techniques of both Machine Learning and Logic Programming to build firstorder logic theories from examples</definiens>
			</definition>
			<definition id="1">
				<sentence>To implement our approach we chose Aleph ( Srinivasan , 2000 ) , an ILP system which provides a complete relational learning inference engine and various customization options .</sentence>
				<definiendum id="0">ILP system</definiendum>
				<definiens id="0">provides a complete relational learning inference engine and various customization options</definiens>
			</definition>
			<definition id="2">
				<sentence>KS1 : Bag-of-words – a list of ±5 words ( lemmas ) surrounding the verb for every sentence ( sent_id ) .</sentence>
				<definiendum id="0">KS1</definiendum>
				<definiens id="0">Bag-of-words – a list of ±5 words ( lemmas ) surrounding the verb for every sentence ( sent_id )</definiens>
			</definition>
			<definition id="3">
				<sentence>In Table 2 we show the accuracy of the theory learned for each verb , as well as accuracy achieved by two propositional machine learning algorithms on the same data : Decision Trees ( C4.5 ) and Support Vector Machine ( SVM ) , all according to a 10-fold cross-validation strategy .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">accuracy achieved by two propositional machine learning algorithms on the same data : Decision Trees ( C4.5 ) and Support Vector Machine (</definiens>
			</definition>
			<definition id="4">
				<sentence>WordNet : An On-line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="2109">
			<definition id="0">
				<sentence>Sentence compression is a task of creating a short grammatical sentence by removing extraneous words or phrases from an original sentence while preserving its meaning .</sentence>
				<definiendum id="0">Sentence compression</definiendum>
				<definiens id="0">a task of creating a short grammatical sentence by removing extraneous words or phrases from an original sentence while preserving its meaning</definiens>
			</definition>
			<definition id="1">
				<sentence>The expression P ( ljs ) is the channel model , which gives the probability that s is expanded to l. When s does not include important words of l , P ( ljs ) has a low value .</sentence>
				<definiendum id="0">expression P</definiendum>
				<definiens id="0">the channel model , which gives the probability that s is expanded to l. When s does not include important words of l</definiens>
			</definition>
			<definition id="2">
				<sentence>In the Knight and Marcu’s model , a probabilistic context-free grammar ( PCFG ) score and a word-bigram score are incorporated as the source model .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">a probabilistic context-free grammar (</definiens>
			</definition>
			<definition id="3">
				<sentence>To estimate the channel model , Knight and Marcu used the Ziff-Davis parallel corpus , which contains long sentences and corresponding short sentences compressed by humans .</sentence>
				<definiendum id="0">Ziff-Davis parallel corpus</definiendum>
				<definiens id="0">contains long sentences and corresponding short sentences compressed by humans</definiens>
			</definition>
			<definition id="4">
				<sentence>Then , each probability is assumed to be independent of the others , and the channel model , P ( ljs ) , is calculated as the product of all expansion probabilities of joint events and PCFG scores of new A B C E FD d g h f c A B C FD d f c G H Figure 1 : Examples of original and compressed parse trees .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
			<definition id="5">
				<sentence>subtrees : P ( ljs ) = productdisplay ( rl , rs ) ∈R Pexpand ( rljrs ) productdisplay r∈Rprime Pcfg ( r ) , where R is the set of rule pairs , and Rprime is the set of generation rules in new subtrees .</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">Rprime</definiendum>
				<definiens id="0">the set of rule pairs</definiens>
				<definiens id="1">the set of generation rules in new subtrees</definiens>
			</definition>
			<definition id="6">
				<sentence>P ( sjl ) = productdisplay ( rs , rl ) ∈R Ptrim ( rsjrl ) , where R is the set of compressed and original rule pairs in joint events .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the set of compressed and original rule pairs in joint events</definiens>
			</definition>
			<definition id="7">
				<sentence>We introduce a length parameter , α , and de ne a score Sα as Sα ( s ) = length ( s ) α log P ( sjl ) , where l is an input sentence to be shortened , and s is a 852 summary candidate .</sentence>
				<definiendum id="0">l</definiendum>
				<definiendum id="1">s</definiendum>
				<definiens id="0">a length parameter , α , and de ne a score Sα as Sα ( s ) = length ( s ) α log P ( sjl )</definiens>
			</definition>
			<definition id="8">
				<sentence>A complex sentence is a sentence that includes another sentence as a part .</sentence>
				<definiendum id="0">complex sentence</definiendum>
				<definiens id="0">a sentence that includes another sentence as a part</definiens>
			</definition>
			<definition id="9">
				<sentence>ROUGE-L uses the length of the longest common subsequence ( LCS ) of the original and summarized sentences .</sentence>
				<definiendum id="0">ROUGE-L</definiendum>
				<definiens id="0">uses the length of the longest common subsequence ( LCS ) of the original and summarized sentences</definiens>
			</definition>
</paper>

		<paper id="1104">
			<definition id="0">
				<sentence>The composite kernel consists of two individual kernels : an entity kernel that allows for entity-related features and a convolution parse tree kernel that models syntactic information of relation examples .</sentence>
				<definiendum id="0">composite kernel</definiendum>
				<definiens id="0">consists of two individual kernels : an entity kernel that allows for entity-related features and a convolution parse tree kernel that models syntactic information of relation examples</definiens>
			</definition>
			<definition id="1">
				<sentence>According to the ACE Program , an entity is an object or set of objects in the world and a relation is an explicitly or implicitly stated relationship among entities .</sentence>
				<definiendum id="0">relation</definiendum>
				<definiens id="0">an object or set of objects in the world</definiens>
			</definition>
			<definition id="2">
				<sentence>The composite kernel consists of an entity kernel and a convolution parse tree kernel .</sentence>
				<definiendum id="0">composite kernel</definiendum>
				<definiens id="0">consists of an entity kernel and a convolution parse tree kernel</definiens>
			</definition>
			<definition id="3">
				<sentence>Therefore , although this kernel shows performance improvement over the previous one ( Culotta and Sorensen , 2004 ) , the constraint makes the two dependency kernels share the similar behavior : good precision but much lower recall on the ACE corpus .</sentence>
				<definiendum id="0">constraint</definiendum>
			</definition>
			<definition id="4">
				<sentence>Our composite kernel consists of an entity kernel and a convolution parse tree kernel .</sentence>
				<definiendum id="0">composite kernel</definiendum>
				<definiens id="0">consists of an entity kernel and a convolution parse tree kernel</definiens>
			</definition>
			<definition id="5">
				<sentence>LEi i KRR KRERE = = ∑ ( 1 ) where 1 R and 2 R stands for two relation instances , E i means the i th entity of a relation instance , and 826 ( , ) E K •• is a simple kernel function over the features of entities : 12 1 2 ( , ) ( .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">stands for two relation instances , E i means the i th entity of a relation instance , and 826 ( , ) E K •• is a simple kernel function over the features of entities</definiens>
			</definition>
			<definition id="6">
				<sentence>11 2 2 11 2 2 12 1 2 12 12 ( , ) ( ) , ( ) # ( ) # ( ) ( ) ( ) ( , ) ( ) ii i subtree subtree inN nN nN nN KTT T T subtree T subtree T In In nn φ φ ∈∈ ∈∈ = &lt; &gt; = = =∆ ⋅ ⋅ ∑ ∑∑ ∑ ∑∑ ( 3 ) where N 1 and N 2 are the sets of nodes in trees T 1 and T 2 , respectively , and ( ) i subtree In is a function that is 1 iff the subtree i occurs with root at node n and zero otherwise , and 12 ( , ) nn∆ is the number of the common subtrees rooted at n 1 and n 2 , i.e. 12 1 2 ( , ) ( ) ( ) ii subtree subtree i nn I n I n∆= ⋅ ∑ 12 ( , ) nn∆ can be computed by the following recursive rules : ( 1 ) if the productions ( CFP rules ) at 1 n and 2 n are different , 12 ( , ) 0nn∆= ; ( 2 ) else if both 1 n and 2 n are pre-terminals ( POS tags ) , 12 ( , ) 1nn λ∆=× ; ( 3 ) else , 1 ( ) 12 1 2 1 ( , ) ( 1 ( ( , ) , ( , ) ) nc n j n n ch n j ch n jλ = ∆= +∆ ∏ , where 1 ( ) nc n is the child number of 1 n , ch ( n , j ) is the j th child of node n andλ ( 0 &lt; λ &lt; 1 ) is the decay factor in order to make the kernel value less variable with respect to the subtree sizes .</sentence>
				<definiendum id="0">) ( ) ( )</definiendum>
				<definiendum id="1">12 ( , ) nn∆</definiendum>
				<definiendum id="2">1 ( ) nc n</definiendum>
				<definiendum id="3">)</definiendum>
				<definiens id="0">( , ) ( ) ii i subtree subtree inN nN nN nN KTT T T subtree T subtree T In In nn φ φ</definiens>
				<definiens id="1">a function that is 1 iff the subtree i occurs with root at node n and zero otherwise , and</definiens>
				<definiens id="2">) ( ) ( ) ii subtree subtree i nn I n I n∆= ⋅ ∑ 12 ( , ) nn∆ can be computed by the following recursive rules : ( 1 ) if the productions ( CFP rules ) at 1 n and 2 n are different</definiens>
				<definiens id="3">1 ( ( , ) , ( , ) ) nc n j n n ch n j ch n jλ = ∆= +∆ ∏</definiens>
				<definiens id="4">the child number of 1 n , ch ( n , j ) is the j th child of node n andλ ( 0 &lt; λ &lt; 1</definiens>
			</definition>
			<definition id="7">
				<sentence>In this paper , two composite kernels are defined by combing the above two individual kernels in the following ways : 1 ) Linear combination : 112 12 12 ˆˆ ( , ) ( , ) ( 1 ) ( , ) L KRR K RR KTTαα••=+− ( 4 ) Here , ˆ ( , ) K • • is the normalized 3 ( , ) K •• and α is the coefficient .</sentence>
				<definiendum id="0">L KRR K RR KTTαα••=+−</definiendum>
				<definiendum id="1">α</definiendum>
				<definiens id="0">combing the above two individual kernels in the following ways : 1 ) Linear combination : 112 12 12 ˆˆ ( , ) ( , ) ( 1 ) ( , )</definiens>
			</definition>
			<definition id="8">
				<sentence>2 ) Polynomial expansion : 212 12 12 ˆˆ ( , ) ( , ) ( 1 ) ( , ) P L KRR K RR KTTαα••=+− ( 5 ) Here , ˆ ( , ) K • • is the normalized ( , ) K •• , ( , ) p K • • is the polynomial expansion of ( , ) K •• with degree d=2 , i.e. 2 ( , ) ( ( , ) 1 ) p KK•• ••=+ , and α is the coefficient .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">the normalized ( , ) K •• , ( , ) p K • • is the polynomial expansion of</definiens>
			</definition>
			<definition id="9">
				<sentence>( 2 ) Path-enclosed Tree ( PT ) : the smallest common sub-tree including the two entities .</sentence>
				<definiendum id="0">PT )</definiendum>
				<definiens id="0">the smallest common sub-tree including the two entities</definiens>
			</definition>
			<definition id="10">
				<sentence>( 5 ) Flattened CPT ( FCPT ) : the CPT with the single in and out arcs of non-terminal nodes ( except POS nodes ) removed .</sentence>
				<definiendum id="0">FCPT )</definiendum>
				<definiens id="0">the CPT with the single in and out arcs of non-terminal nodes ( except POS nodes ) removed</definiens>
			</definition>
			<definition id="11">
				<sentence>Different representations of a relation instance in the example sentence “…provide benefits to 200 domestic partners of their own workers in New York” , where the phrase type “E1-PER” denotes that the current node is the 1 st entity with type “PERSON” , and likewise for the others .</sentence>
				<definiendum id="0">“E1-PER”</definiendum>
				<definiens id="0">Different representations of a relation instance in the example sentence “…provide benefits to 200 domestic partners of their own workers in New York” , where the phrase type</definiens>
			</definition>
			<definition id="12">
				<sentence>In the ACE 2003 data , the training set consists of 674 documents and 9683 relation instances while the test set consists of 97 documents and 1386 relation instances .</sentence>
				<definiendum id="0">training set</definiendum>
				<definiens id="0">consists of 674 documents and 9683 relation instances while the test set consists of 97 documents and 1386 relation instances</definiens>
			</definition>
			<definition id="13">
				<sentence>, “merge” is a critical context word ) , the context information is helpful .</sentence>
				<definiendum id="0">“merge”</definiendum>
				<definiens id="0">a critical context word</definiens>
			</definition>
</paper>

		<paper id="4005">
			<definition id="0">
				<sentence>A predicate-argument relation is defined as a tuple 〈σ , wh , a , wa〉 , where σ is the predicate type ( e.g. , adjective , intransitive verb ) , wh is the head word of the predicate , a is the argument label ( MOD , ARG1 , ... , ARG4 ) , and wa is the head word of the argument .</sentence>
				<definiendum id="0">predicate-argument relation</definiendum>
				<definiendum id="1">σ</definiendum>
				<definiendum id="2">MOD , ARG1 , ... , ARG4</definiendum>
				<definiendum id="3">wa</definiendum>
				<definiens id="0">a tuple 〈σ , wh , a , wa〉 , where</definiens>
				<definiens id="1">the predicate type ( e.g. , adjective , intransitive verb ) , wh is the head word of the predicate</definiens>
			</definition>
			<definition id="1">
				<sentence>Precision/recall is the ratio of tuples correctly identified by the parser .</sentence>
				<definiendum id="0">Precision/recall</definiendum>
				<definiens id="0">the ratio of tuples correctly identified by the parser</definiens>
			</definition>
			<definition id="2">
				<sentence>The GENIA treebank ( Tateisi et al. , 2005 ) consists of 500 abstracts ( 4,446 sentences ) extracted from MEDLINE .</sentence>
				<definiendum id="0">GENIA treebank</definiendum>
				<definiens id="0">consists of 500 abstracts ( 4,446 sentences ) extracted from MEDLINE</definiens>
			</definition>
			<definition id="3">
				<sentence>MEDIE is an intelligent search engine for the accurate retrieval of relational concepts from MEDLINE 2 ( Miyao et al. , 2006 ) .</sentence>
				<definiendum id="0">MEDIE</definiendum>
			</definition>
			<definition id="4">
				<sentence>The HPSG parser generates parse trees in a stand-off format that can be converted to XML by combining it with the original text .</sentence>
				<definiendum id="0">HPSG parser</definiendum>
			</definition>
			<definition id="5">
				<sentence>MEDIE provides three types of search , semantic search , keyword search , GCL search .</sentence>
				<definiendum id="0">MEDIE</definiendum>
				<definiens id="0">provides three types of search , semantic search , keyword search</definiens>
			</definition>
			<definition id="6">
				<sentence>MEDIE retrieves sentences which include event verbs of ‘cause’ and noun ‘dystrophin’ such that ‘dystrophin’ is the subject of the event verbs .</sentence>
				<definiendum id="0">MEDIE retrieves</definiendum>
			</definition>
			<definition id="7">
				<sentence>We adopted PASs derived by Enju and constructed extraction patterns on specific verbs and their arguments based on the derived PASs ( Yakusiji , 2006 ) .</sentence>
				<definiendum id="0">PASs</definiendum>
			</definition>
			<definition id="8">
				<sentence>Drag an InteractionBox to ‘ContentViewer’ to see the content of the box ( Figure 6 ) .</sentence>
				<definiendum id="0">Drag an InteractionBox</definiendum>
			</definition>
			<definition id="9">
				<sentence>An InteractionBox is a set of SentenceBoxes .</sentence>
				<definiendum id="0">InteractionBox</definiendum>
				<definiens id="0">a set of SentenceBoxes</definiens>
			</definition>
			<definition id="10">
				<sentence>A SentenceBox indicates whether the co-occurrence in the sentence is direct evidence of interaction or not .</sentence>
				<definiendum id="0">SentenceBox</definiendum>
				<definiens id="0">indicates whether the co-occurrence in the sentence is direct evidence of interaction or not</definiens>
			</definition>
</paper>

		<paper id="1108">
			<definition id="0">
				<sentence>The φ most frequent events in “Excellent” stories are called the Important Event Structure , which represents the “important” events in the story in temporal order .</sentence>
				<definiendum id="0">Important Event Structure</definiendum>
				<definiens id="0">represents the “important” events in the story in temporal order</definiens>
			</definition>
			<definition id="1">
				<sentence>M is a binary vector used to store the success of a match with index i. The ADV function , given an event , generates one adAlgorithm for w∈W do                  M =∅ i = 0 for r∈R do             if w = r or SY N ( r ) then mi = 1 else mi = 0 i = i + 1 for nw ∈Nw do      for nr ∈Nr do      if nw = SYN ( nr ) or nr then mi ←1 else mi ←0 i = i + 1 ADV ( w , M ) Figure 2 : Advice Generation Algorithm vice statement to be given to the student .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">SY N ( r</definiendum>
				<definiens id="0">a binary vector used to store the success of a match with index</definiens>
			</definition>
</paper>

		<paper id="2108">
			<definition id="0">
				<sentence>The experimental results show that : ( 1 ) the WSM is able to achieve tonal ( syllables input with four tones ) and toneless ( syllables input without four tones ) syllable-to-word ( STW ) accuracies of 99 % and 92 % , respectively , among the converted words ; and ( 2 ) while applying the WSM as an adaptation processing , together with the Microsoft Input Method Editor 2003 ( MSIME ) and an optimized bigram model , the average tonal and toneless STW improvements are 37 % and 35 % , respectively .</sentence>
				<definiendum id="0">STW</definiendum>
				<definiendum id="1">MSIME</definiendum>
				<definiens id="0">an adaptation processing</definiens>
			</definition>
			<definition id="1">
				<sentence>The objective of this study is to illustrate a word support model ( WSM ) that is able to improve our WP-identifier by achieving better identified character ratio and STW accuracy on the identified poly-syllabic words with the same word-pair database .</sentence>
				<definiendum id="0">WSM</definiendum>
				<definiens id="0">WP-identifier by achieving better identified character ratio and STW accuracy on the identified poly-syllabic words with the same word-pair database</definiens>
			</definition>
			<definition id="2">
				<sentence>The WS degree is defined to be the total number of the word found in the WP set .</sentence>
				<definiendum id="0">WS degree</definiendum>
				<definiens id="0">the total number of the word found in the WP set</definiens>
			</definition>
			<definition id="3">
				<sentence>Ms Ms+WP ( I ) a Ms+WSM ( I ) b Tonal 94.5 % 95.5 % ( 18.9 % ) 95.9 % ( 25.6 % ) Toneless 85.9 % 87.4 % ( 10.1 % ) 88.3 % ( 16.6 % ) a STW accuracies and improvements of the words identified by the MSIME ( Ms ) with the WP identifier b STW accuracies and improvements of the words identified by the MSIME ( Ms ) with the WSM Table 3a .</sentence>
				<definiendum id="0">Ms Ms+WP</definiendum>
				<definiendum id="1">STW</definiendum>
				<definiens id="0">accuracies and improvements of the words identified by the MSIME ( Ms ) with the WP identifier b STW accuracies and improvements of the words identified by the MSIME ( Ms ) with the WSM Table 3a</definiens>
			</definition>
			<definition id="4">
				<sentence>845 Bi Bi+WP ( I ) a Bi+WSM ( I ) b Tonal 96.0 % 96.4 % ( 8.6 % ) 96.7 % ( 17.1 % ) Toneless 83.9 % 85.8 % ( 11.9 % ) 87.5 % ( 22.0 % ) a STW accuracies and improvements of the words identified by the BiGram ( Bi ) with the WP identifier b STW accuracies and improvements of the words identified by the BiGram ( Bi ) with the WSM Table 3b .</sentence>
				<definiendum id="0">STW</definiendum>
			</definition>
			<definition id="5">
				<sentence>Ms+WSM ( ICR , I ) a Bi+WSM ( ICR , I ) b Tonal 96.8 % ( 71.4 % , 41.7 % ) 97.3 % ( 71.4 % , 32.6 % ) Toneless 90.6 % ( 74.6 % , 33.2 % ) 97.3 % ( 74.9 % , 36.0 % ) a STW accuracies , ICRs and improvements of the words identified by the MSIME ( Ms ) with the WSM b STW accuracies , ICRs and improvements of the words identified by the BiGram ( Bi ) with the WSM Table 3c .</sentence>
				<definiendum id="0">Ms+WSM</definiendum>
				<definiens id="0">a STW accuracies , ICRs and improvements of the words identified by the MSIME ( Ms ) with the WSM b STW accuracies , ICRs and improvements of the words identified by the BiGram ( Bi ) with the WSM Table 3c</definiens>
			</definition>
			<definition id="6">
				<sentence>( 2 ) Inadequate Syllable-Word Segmentation ( ISWS ) problem : When an error is caused by ambiguous syllable-word segmentation ( including overlapping and combination ambiguities ) , we call it inadequate syllableword segmentation problem .</sentence>
				<definiendum id="0">Inadequate Syllable-Word Segmentation</definiendum>
				<definiens id="0">When an error is caused by ambiguous syllable-word segmentation ( including overlapping and combination ambiguities</definiens>
			</definition>
			<definition id="7">
				<sentence>Case I. ( a ) Tonal STW results for the Chinese tonal syllables “guan1 yu2 liang4 xing2 suo3 sheng1 zhi1 shi4 shi2” of the Chinese sentence “關於量 刑所生之事實” Methods STW results WP set 關於-知識/4 ( key WP ) , 關於-量刑/3 , 量刑-事實/1 , 關於-事實/1 WSM Set 關於 ( guan1 yu2 ) /3 , 量刑 ( liang4 xing2 ) /2 , 事實 ( shi4 shi2 ) /2 , 知識 ( zhi1 shi4 ) /1 WP-sentence 關於liang4 xing2 suo3 sheng1知識shi2 WSM-sentence 關於量刑suo3 sheng1 zhi1事實 MSIME 關於量行所生之事實 MSIME+WP 關於量行所生知識實 MSIME+WSM 關於量刑所生之事實 BiGram 關於量刑所生之事時 BiGram+WP 關於量刑所生知識時 BiGram+WSM 關於量刑所生之事實 ( b ) Toneless STW results for the Chinese toneless syllables “guan yu liang xing suo sheng zhi shi shi” of the Chinese sentence “關於量刑所生 之事實” Methods STW results WP set 關於/實施/4 ( key WP ) , 關於/知識/4 , 關於/量刑/3 , 兩性/知識/2 , 兩性/實施/2 , 關於/失事/2 , 量刑/事實/1 , 關於/兩性/1 , 關與/實施/1 , 生殖/實施/1 , 關於/事實/1 , 關於/史實/1 WSM Set 關於 ( guan yu ) /7 , 實施 ( shi shi ) /4 , 兩性 ( liang xing ) /3 , 量刑 ( liang xing ) /2 , 知識 ( zhi shi ) /2 , 事實 ( shi shi ) /2 , 失事 ( shi shi ) /1 , 關與 ( guan yu ) /1 , 生殖 ( shengzhi ) /1 WP-sentence 關於liang xing suo sheng zhi實施 WSM-sentence 關於兩性suo生殖實施 MSIME 關於兩性所生之事實 MSIME+WP 關於兩性所生之實施 MSIME+WSM 關於兩性所生殖實施 BiGram 貫譽良興所升值施事 BiGram+WP 關於良興所升值實施 BiGram+WSM 關於兩性所生殖實施 Case II .</sentence>
				<definiendum id="0">MSIME 關於量行所生之事實 MSIME+WP 關於量行所生知識實 MSIME+WSM 關於量刑所生之事實 BiGram 關於量刑所生之事時 BiGram+WP 關於量刑所生知識時 BiGram+WSM 關於量刑所生之事實</definiendum>
				<definiens id="0">results WP set 關於/實施/4 ( key WP ) , 關於/知識/4 , 關於/量刑/3 , 兩性/知識/2 , 兩性/實施/2 , 關於/失事/2 , 量刑/事實/1 , 關於/兩性/1 , 關與/實施/1 , 生殖/實施/1 , 關於/事實/1 , 關於/史實/1 WSM Set 關於 ( guan yu ) /7 , 實施</definiens>
			</definition>
</paper>

		<paper id="1115">
			<definition id="0">
				<sentence>Kernel methods ( Cristianini and Shawe-Taylor , 2000 ) are particularly suitable for semantic parsing because it involves mapping phrases of natural language ( NL ) sentences to semantic concepts in a meaning representation language ( MRL ) .</sentence>
				<definiendum id="0">Kernel methods</definiendum>
				<definiendum id="1">MRL</definiendum>
				<definiens id="0">semantic parsing because it involves mapping phrases of natural language ( NL ) sentences to semantic concepts in a meaning representation language</definiens>
			</definition>
			<definition id="1">
				<sentence>Our system , KRISP ( Kernel-based Robust Interpretation for Semantic Parsing ) , takes NL sentences paired with their formal meaning representationsastrainingdata .</sentence>
				<definiendum id="0">KRISP</definiendum>
				<definiens id="0">takes NL sentences paired with their formal meaning representationsastrainingdata</definiens>
			</definition>
			<definition id="2">
				<sentence>We call the process of mapping natural language ( NL ) utterances into their computer-executable meaning representations ( MRs ) as semantic parsing .</sentence>
				<definiendum id="0">MRs</definiendum>
				<definiens id="0">the process of mapping natural language ( NL ) utterances into their computer-executable meaning representations</definiens>
			</definition>
			<definition id="3">
				<sentence>CLANG ( Chen et al. , 2003 ) is the standard formal coach language in which coaching advice is given to soccer agents which compete on a simulated soccer field in the RoboCup 1 Coach Competition .</sentence>
				<definiendum id="0">CLANG</definiendum>
				<definiens id="0">the standard formal coach language in which coaching</definiens>
			</definition>
			<definition id="4">
				<sentence>KRISP does semantic parsing using the notion of a semantic derivation of an NL sentence .</sentence>
				<definiendum id="0">KRISP</definiendum>
				<definiens id="0">does semantic parsing using the notion of a semantic derivation of an NL sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>j ] of s ( i.e. the substring from the ith word to the jth word ) , and we say that the node or its production covers the substring s [ i..</sentence>
				<definiendum id="0">of s</definiendum>
			</definition>
			<definition id="6">
				<sentence>Let Ppi ( u ) denote the probability that a production pi of the MRL grammar covers the NL substring u. In other words , the NL substring u expresses the semantic concept of a production pi with probability Ppi ( u ) .</sentence>
				<definiendum id="0">Ppi ( u</definiendum>
				<definiendum id="1">NL substring u</definiendum>
				<definiens id="0">expresses the semantic concept of a production pi with probability Ppi ( u )</definiens>
			</definition>
			<definition id="7">
				<sentence>Our extended Earley’s algorithm does a beam search and attempts to find theω ( a parameter ) most probable semantic derivationsofanNLsentencesusingtheprobabilities Ppi ( s [ i..</sentence>
				<definiendum id="0">extended Earley’s algorithm</definiendum>
			</definition>
			<definition id="8">
				<sentence>KRISP learns a semantic parser iteratively , each iteration improving upon the parser learned in the previous iteration .</sentence>
				<definiendum id="0">KRISP</definiendum>
				<definiens id="0">learns a semantic parser iteratively , each iteration improving upon the parser learned in the previous iteration</definiens>
			</definition>
			<definition id="9">
				<sentence>The GEOQUERY corpus contains 880 English queries collected from undergraduatesand fromreal usersofaweb-based interface ( Tang and Mooney , 2001 ) .</sentence>
				<definiendum id="0">GEOQUERY corpus</definiendum>
			</definition>
			<definition id="10">
				<sentence>These were manually translated into their MRs. The average length of an NL sentence in the CLANG corpus is 22.52 words while in the GEOQUERY corpus it is 7.48 words , which indicates that CLANG is the harder corpus .</sentence>
				<definiendum id="0">CLANG</definiendum>
				<definiens id="0">the harder corpus</definiens>
			</definition>
			<definition id="11">
				<sentence>We compared our system’s performance with the following existing systems : the string and tree versions of SILT ( Kate et al. , 2005 ) , a system that learns transformation rules relating NL phrases to MRL expressions ; WASP ( Wong and Mooney , 2006 ) , a system that learns transformation rules using statistical machine translation techniques ; SCISSOR ( Ge and Mooney , 2005 ) , a system that learns an integrated syntactic-semantic parser ; and CHILL ( Tang and Mooney , 2001 ) an ILP-based semantic parser .</sentence>
				<definiendum id="0">WASP</definiendum>
				<definiendum id="1">CHILL</definiendum>
				<definiens id="0">a system that learns transformation rules relating NL phrases to MRL expressions ;</definiens>
				<definiens id="1">a system that learns transformation rules using statistical machine translation techniques</definiens>
				<definiens id="2">a system that learns an integrated syntactic-semantic parser</definiens>
			</definition>
			<definition id="12">
				<sentence>50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 Precision Recall KRISP WASP SCISSOR SILT-tree SILT-string CHILL Zettlemoyer et al. ( 2005 ) Figure 7 : Results on the GEOQUERY corpus .</sentence>
				<definiendum id="0">Precision Recall KRISP WASP SCISSOR SILT-tree SILT-string CHILL</definiendum>
			</definition>
			<definition id="13">
				<sentence>Overall , the results show that KRISP performs better than deterministic rule-based semantic parsers like CHILL and SILT and performs comparable to other statistical semantic parsers like WASP and SCISSOR .</sentence>
				<definiendum id="0">KRISP</definiendum>
				<definiens id="0">performs better than deterministic rule-based semantic parsers like CHILL and SILT and performs comparable to other statistical semantic parsers like WASP and SCISSOR</definiens>
			</definition>
			<definition id="14">
				<sentence>ulate this type of noise by substituting a word in the corpus by another word , w , with probability ped ( w ) ∗P ( w ) , wherepisaparameter , ed ( w ) isw’s editdistance ( Levenshtein , 1966 ) fromtheoriginal word and P ( w ) is w’s probability proportional to its word frequency .</sentence>
				<definiendum id="0">P ( w )</definiendum>
				<definiens id="0">w’s probability proportional to its word frequency</definiens>
			</definition>
</paper>

		<paper id="1036">
			<definition id="0">
				<sentence>Readability is hampered by at least two factors : high connectivity ( the great number of links or associations emanating from each word ) , and distribution : conceptually related nodes , that is , nodes activated by the same kind of association are scattered around , that is , they do not necessarily occur next to each other , which is quite confusing for the user .</sentence>
				<definiendum id="0">Readability</definiendum>
				<definiendum id="1">high connectivity</definiendum>
				<definiens id="0">the great number of links or associations emanating from each word )</definiens>
			</definition>
			<definition id="1">
				<sentence>282 DENTIST assistant near-synonym GYNECOLOGIST PHYSICIAN HEALTH INSTITUTION CLINIC DOCTOR SANATORIUM PSYCHIATRIC HOSPITAL MILITARY HOSPITAL ASYLUM treat AOK take care of treat HOSPITAL PATIENT INMATE TIORA synonym ISA A OK A OK AOK AOK ISA ISA ISA ISA ISA TIORA TIORA nurse Internal Representation Figure 1 : Search based on navigating in a network ( internal representation ) AKO : a kind of ; ISA : subtype ; TIORA : Typically Involved Object , Relation or Actor .</sentence>
				<definiendum id="0">synonym ISA A OK A OK AOK AOK ISA ISA ISA ISA ISA TIORA</definiendum>
				<definiens id="0">TIORA nurse Internal Representation Figure 1 : Search based on navigating in a network ( internal representation ) AKO : a kind of ; ISA : subtype ; TIORA : Typically Involved Object , Relation or Actor</definiens>
			</definition>
			<definition id="2">
				<sentence>Synonymy , hypernymy or meronymy fall clearly in this latter category , and well known resources like WordNet ( Miller , 1995 ) , EuroWordNet ( Vossen , 1998 ) or MindNet ( Richardson et al. , 1998 ) contain them .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
				<definiendum id="1">MindNet</definiendum>
			</definition>
			<definition id="3">
				<sentence>Other researchers used external sources : Mandala et al. ( 1999 ) integrated co-occurrences and a thesaurus to WordNet for query expansion ; Agirre et al. ( 2001 ) built topic signatures from texts in relation to synsets ; Magnini and Cavagliá ( 2000 ) annotated the synsets with Subject Field Codes .</sentence>
				<definiendum id="0">external sources</definiendum>
				<definiens id="0">co-occurrences and a thesaurus to WordNet for query expansion ; Agirre et al. ( 2001 ) built topic signatures from texts in relation to synsets</definiens>
			</definition>
			<definition id="4">
				<sentence>This network is used by TOPICOLL ( Ferret , 2002 ) , a topic analyzer , which performs simultaneously three tasks , relevant for this goal : it segments texts into topically homogeneous segments ; it selects in each segment the most representative words of its topic ; 7 Such a network is only another view of a set of cooccurrences : its nodes are the co-occurrent words and its edges are the co-occurrence relations .</sentence>
				<definiendum id="0">topic analyzer</definiendum>
				<definiens id="0">performs simultaneously three tasks , relevant for this goal : it segments texts into topically homogeneous segments ; it selects in each segment the most representative words of its topic</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , Mel’cuk’s lexical functions ( Mel’cuk , 1995 ) , Fillmore’s FRAMENET 10 , work on ontologies ( CYC ) , thesaurus ( Roget ) , WordNets ( the original version from Princeton , various Euro-WordNets , BalkaNet ) , HowNet 11 , the work done by MICRA , the FACTOTUM project 12 , or the Wordsmyth dictionary/thesaurus 13 .</sentence>
				<definiendum id="0">CYC</definiendum>
				<definiens id="0">the original version from Princeton , various Euro-WordNets</definiens>
			</definition>
			<definition id="6">
				<sentence>EuroWordNet : A Multilingual Database with Lexical Semantic Networks .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
			</definition>
</paper>

		<paper id="3004">
			<definition id="0">
				<sentence>NeGra contains about 20,000 sentences , T¨uBa-D/Z about 15,000 , both consist of newspaper text .</sentence>
				<definiendum id="0">NeGra</definiendum>
				<definiendum id="1">T¨uBa-D/Z</definiendum>
				<definiens id="0">contains about 20,000 sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>Apart from the average tree height , the dimensions of T¨uBa-D/Z with flattened phrases and without unary productions ( T¨u f NU ) resemble those of the unmodified NeGra treebank , which indicates their similarity .</sentence>
				<definiendum id="0">NeGra treebank</definiendum>
			</definition>
</paper>

		<paper id="2086">
			<definition id="0">
				<sentence>In order to minimize the huge manual effort involved with building information extraction systems , we have designed and developed URES ( Unsupervised Relation Extraction System ) which learns a set of patterns to extract relations from the web in a totally unsupervised way .</sentence>
				<definiendum id="0">URES ( Unsupervised Relation Extraction System )</definiendum>
				<definiens id="0">learns a set of patterns to extract relations from the web in a totally unsupervised way</definiens>
			</definition>
			<definition id="1">
				<sentence>TEG is a hybrid rule-based and statistical IE system .</sentence>
				<definiendum id="0">TEG</definiendum>
			</definition>
			<definition id="2">
				<sentence>In Section 3 we outline the general design principles of URES and the architecture of the system and then describe the different components of URES in details while giving examples to the input and output of each component .</sentence>
				<definiendum id="0">URES</definiendum>
				<definiens id="0">the general design principles of URES and the architecture of the system and then describe the different components of</definiens>
			</definition>
			<definition id="3">
				<sentence>Snowball ( Agichtein and Gravano 2000 ) is an unsupervised system for learning relations from document collections .</sentence>
				<definiendum id="0">Snowball</definiendum>
			</definition>
			<definition id="4">
				<sentence>KnowItAll system is a direct predecessor of URES .</sentence>
				<definiendum id="0">KnowItAll system</definiendum>
				<definiens id="0">a direct predecessor of URES</definiens>
			</definition>
			<definition id="5">
				<sentence>KnowItAll is an autonomous , domain-independent system that extracts facts from the Web .</sentence>
				<definiendum id="0">KnowItAll</definiendum>
				<definiens id="0">an autonomous , domain-independent system that extracts facts from the Web</definiens>
			</definition>
			<definition id="6">
				<sentence>KnowItAll uses a set of manually-built generic rules , which are instantiated with the target predicate names , producing queries , patterns and discriminator phrases .</sentence>
				<definiendum id="0">KnowItAll</definiendum>
				<definiens id="0">uses a set of manually-built generic rules , which are instantiated with the target predicate names , producing queries , patterns and discriminator phrases</definiens>
			</definition>
			<definition id="7">
				<sentence>The Sentence Classifier filters the set of sentences , removing those that are unlikely to contain instances of the target relations .</sentence>
				<definiendum id="0">Sentence Classifier</definiendum>
				<definiens id="0">filters the set of sentences , removing those that are unlikely to contain instances of the target relations</definiens>
			</definition>
			<definition id="8">
				<sentence>The Instance Extractor extracts the attributes of the instances from the sentences , and generates the output of the system .</sentence>
				<definiendum id="0">Instance Extractor</definiendum>
				<definiens id="0">extracts the attributes of the instances from the sentences , and generates the output of the system</definiens>
			</definition>
			<definition id="9">
				<sentence>The task of the Pattern Learner is to learn the patterns of occurrence of relation instances .</sentence>
				<definiendum id="0">Pattern Learner</definiendum>
				<definiens id="0">to learn the patterns of occurrence of relation instances</definiens>
			</definition>
			<definition id="10">
				<sentence>The Generalize ( s 1 , s 2 ) function takes two patterns ( note , that sentences in the positive and negative sets are patterns without skips ) and generates the least ( most specific ) common generalization of both .</sentence>
				<definiendum id="0">Generalize</definiendum>
				<definiens id="0">s 1 , s 2 ) function takes two patterns ( note , that sentences in the positive and negative sets are patterns without skips</definiens>
			</definition>
			<definition id="11">
				<sentence>The function does a dynamical programming search for the best match between the two patterns ( Optimal String Alignment algorithm ) , with the cost of the match defined as the sum of costs of matches for all elements .</sentence>
				<definiendum id="0">function</definiendum>
			</definition>
			<definition id="12">
				<sentence>The task of the Instance Extractor is to use the patterns generated by the Pattern Learner on the sentences that were passed through by the Sentence Classifier .</sentence>
				<definiendum id="0">Instance Extractor</definiendum>
				<definiens id="0">to use the patterns generated by the Pattern Learner on the sentences that were passed through by the Sentence Classifier</definiens>
			</definition>
			<definition id="13">
				<sentence>TEG mode TEG ( Trainable Extraction Grammars ) ( Rosenfeld , Feldman et al. 2004 ) is general671 purpose hybrid rule-based and statistical IE system , able to extract entities and relations at the sentence level .</sentence>
				<definiendum id="0">TEG mode TEG</definiendum>
				<definiendum id="1">Trainable Extraction Grammars )</definiendum>
				<definiens id="0">general671 purpose hybrid rule-based and statistical IE system , able to extract entities and relations at the sentence level</definiens>
			</definition>
			<definition id="14">
				<sentence>The TEG rule language is a straightforward extension of a context-free grammar syntax .</sentence>
				<definiendum id="0">TEG rule language</definiendum>
				<definiens id="0">a straightforward extension of a context-free grammar syntax</definiens>
			</definition>
			<definition id="15">
				<sentence>Wherever such nonterminal occurs in a final parse of a sentence , TEG generates an output label .</sentence>
				<definiendum id="0">TEG</definiendum>
				<definiens id="0">generates an output label</definiens>
			</definition>
			<definition id="16">
				<sentence>Merger is symmetric predicate , in the sense that the order of its attributes does not matter .</sentence>
				<definiendum id="0">Merger</definiendum>
				<definiens id="0">symmetric predicate , in the sense that the order of its attributes does not matter</definiens>
			</definition>
</paper>

		<paper id="1052">
			<definition id="0">
				<sentence>A dominance chart for the graph G is a mapping of weakly connected subgraphs of G to sets of splits ( see Fig .</sentence>
				<definiendum id="0">dominance chart for the graph G</definiendum>
				<definiens id="0">a mapping of weakly connected subgraphs of G to sets of splits</definiens>
			</definition>
			<definition id="1">
				<sentence>A permutation system R is a system of rewrite rules over the signature Σ of the following form : f1 ( x [ 1 , i ) , f2 ( y [ 1 , k ) , z , y ( k , m ] ) , x ( i , n ] ) → f2 ( y [ 1 , k ) , f1 ( x [ 1 , i ) , z , x ( i , n ] ) , y ( k , m ] ) The permutability relation P ( R ) is the binary relation P ( R ) ⊆ ( Σ×N ) 2 which contains exactly the tuples ( ( f1 , i ) , ( f2 , k ) ) and ( ( f2 , k ) , ( f1 , i ) ) for each suchrewriterule .</sentence>
				<definiendum id="0">permutation system R</definiendum>
				<definiens id="0">a system of rewrite rules over the signature Σ of the following form</definiens>
			</definition>
			<definition id="2">
				<sentence>Twotermsareequivalent withrespect to R , s≈R t , iff there is a sequence of rewrite steps and inverse rewrite steps that rewrite s into t. If G is a graph over Σ and R a permutation system , then we write SCR ( G ) for the set of equivalence classes Conf ( G ) /≈R , where Conf ( G ) is the set of configurations of G. The rewrite rule ( 3 ) above is an instance of this schema , as are the other three permutations of existential quantifiers .</sentence>
				<definiendum id="0">Conf</definiendum>
				<definiens id="0">a sequence of rewrite steps and inverse rewrite steps that rewrite s into t. If G is a graph over Σ and R a permutation system , then we write SCR ( G ) for the set of equivalence classes Conf ( G ) /≈R , where</definiens>
			</definition>
			<definition id="3">
				<sentence>Let G be a hnc graph , F1 and F2 be R-permutable fragments with root labels f1 and f2 , and C1 any configuration of G of the form C ( f1 ( ... , f2 ( ... ) , ... ) ) ( where C is the context of the subterm ) .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the context of the subterm )</definiens>
			</definition>
			<definition id="4">
				<sentence>A split S= ( F , ... , hi mapsto→Gi , ... ) of a graph G is called eliminable in a chartCh if some Gi contains a fragment Fprime such that ( a ) Ch contains a split Sprime of G with root fragment Fprime , and ( b ) Fprime is R-permutable with F and all possible dominators of Fprime in Gi .</sentence>
				<definiendum id="0">split S=</definiendum>
				<definiens id="0">a fragment Fprime such that ( a ) Ch contains a split Sprime of G with root fragment Fprime</definiens>
				<definiens id="1">R-permutable with F and all possible dominators of Fprime in Gi</definiens>
			</definition>
			<definition id="5">
				<sentence>The overall runtime for the algorithm is O ( n2S ) , where S is the number of splits in Ch and n is the number of nodes in the graph .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of nodes in the graph</definiens>
			</definition>
			<definition id="6">
				<sentence>The upper bound is the true number of 414 1 10 100 1000 10000 100000 012345678910111213 log ( # configurations ) Factor AlgorithmBaselineClasses Figure 5 : Mean reduction factor on Rondane .</sentence>
				<definiendum id="0">upper bound</definiendum>
				<definiens id="0">the true number of 414 1 10 100 1000 10000 100000 012345678910111213 log ( # configurations ) Factor AlgorithmBaselineClasses Figure 5 : Mean reduction factor on Rondane</definiens>
			</definition>
</paper>

		<paper id="2104">
			<definition id="0">
				<sentence>Recent statistical approaches to automated predicateargument annotation have utilized parse tree paths as predictive features , which encode the path between a verb predicate and a node in the parse tree that governs its argument .</sentence>
				<definiendum id="0">parse tree paths</definiendum>
			</definition>
			<definition id="1">
				<sentence>Predicates are typically assumed to be specific target words ( usually verbs ) , and arguments are assumed to be a span of words in the sentence that are governed by a single node in the parse tree .</sentence>
				<definiendum id="0">Predicates</definiendum>
				<definiens id="0">typically assumed to be specific target words ( usually verbs ) , and arguments are assumed to be a span of words in the sentence that are governed by a single node in the parse tree</definiens>
			</definition>
			<definition id="2">
				<sentence>These four verbs were chosen because of the synonymy among the first two , and the reflexivity of the second two , and because all four have straightforward argument structures when viewed as predicates , as folows : predicate : believe arg0 : the believer arg1 : the thing that is believed predicate : think arg0 : the thinker arg1 : the thing that is thought predicate : give arg0 : the giver arg1 : the thing that is given arg2 : the receiver predicate : receive arg0 : the receiver arg1 : the thing that is received arg2 : the giver This corpus of sentences was then annotated with semantic role information by the authors of this paper .</sentence>
				<definiendum id="0">arg1</definiendum>
				<definiens id="0">the thing that is believed predicate : think arg0 : the thinker arg1 : the thing that is thought predicate : give arg0 : the giver arg1 : the thing that is given arg2 : the receiver predicate : receive arg0 : the receiver</definiens>
			</definition>
			<definition id="3">
				<sentence>Adjusted recall is the sum of all of these adjusted credits divided by the total number of correct answers posible .</sentence>
				<definiendum id="0">Adjusted recall</definiendum>
			</definition>
			<definition id="4">
				<sentence>Acros each of our four predicates , arg0 is the agent of the predication ( e.g. the person that has the belief or is doing the giving ) , and arg1 is the thing that is acted upon by the agent ( e.g. the thing that is believed or the thing that is given ) .</sentence>
				<definiendum id="0">arg0</definiendum>
				<definiendum id="1">arg1</definiendum>
				<definiens id="0">the agent of the predication</definiens>
				<definiens id="1">the thing that is acted upon by the agent ( e.g. the thing that is believed or the thing that is given )</definiens>
			</definition>
</paper>

		<paper id="1117">
			<definition id="0">
				<sentence>A very good candidate seems to be the Intersective Levin class ( ILC ) ( Dang et al. , 1998 ) that can be found as well in other predicate resources like PB and VerbNet ( VN ) ( Kipper et al. , 2000 ) .</sentence>
				<definiendum id="0">VerbNet ( VN )</definiendum>
				<definiens id="0">the Intersective Levin class ( ILC ) ( Dang et al. , 1998 ) that can be found as well in other predicate resources like PB</definiens>
			</definition>
			<definition id="1">
				<sentence>At the same time , ILC provides better predicate coverage as it can also be learned from other corpora ( e.g. PB ) .</sentence>
				<definiendum id="0">ILC</definiendum>
			</definition>
			<definition id="2">
				<sentence>As FN is annotated with frame-specific semantic roles , we manually mapped these roles into the VN set of theINPUT VN = { C|C is a VerbNet class } VN Class C = { v|c is a verb of C } FN = { F|F is a FrameNet frame } FN frame F = { v|v is a verb of F } OUTPUT Pairs = { 〈F , C〉|F ∈ FN , C ∈ VN : F maps to C } COMPUTE PAIRS : Let Pairs = ∅ for each F ∈ FN ( I ) compute C∗ = argmaxC∈VN |F ∩ C| ( II ) if |F ∩ C∗| ≥ 3 then Pairs = Pairs∪〈F , C∗〉 Table 1 : Linking FrameNet frames and VerbNet classes .</sentence>
				<definiendum id="0">v|v</definiendum>
				<definiendum id="1">argmaxC∈VN |F ∩ C|</definiendum>
				<definiens id="0">a VerbNet class } VN Class C = { v|c is a verb of C } FN = { F|F is a FrameNet frame } FN frame F = {</definiens>
			</definition>
			<definition id="3">
				<sentence>Our good results show that we have defined an effective framework which is a promising step toward the design of more robust semantic parsers .</sentence>
				<definiendum id="0">effective framework</definiendum>
				<definiens id="0">a promising step toward the design of more robust semantic parsers</definiens>
			</definition>
</paper>

		<paper id="1038">
			<definition id="0">
				<sentence>A lexical category is a set of words that share a significant aspect of their meaning , e.g. , sets of words denoting vehicles , types of food , tool names , etc .</sentence>
				<definiendum id="0">lexical category</definiendum>
			</definition>
			<definition id="1">
				<sentence>We define a high frequency word ( HFW ) as a word appearing more than TH times per million words , and a content word ( CW ) as a word appearing less than TC times per a million words4 .</sentence>
				<definiendum id="0">high frequency word</definiendum>
				<definiendum id="1">HFW</definiendum>
				<definiendum id="2">CW</definiendum>
				<definiens id="0">a word appearing more than TH times per million words</definiens>
				<definiens id="1">a word appearing less than TC times per a million words4</definiens>
			</definition>
			<definition id="2">
				<sentence>A clique Q defines a category that contains the nodes in Q plus all of the nodes that are ( 1 ) at least unidirectionally connected to all nodes in Q , and ( 2 ) bidirectionally connected to at least one node in Q. In practice we use 2-cliques .</sentence>
				<definiendum id="0">clique Q</definiendum>
				<definiens id="0">defines a category that contains the nodes in Q plus all of the nodes that are ( 1 ) at least unidirectionally connected to all nodes in Q , and ( 2 ) bidirectionally connected to at least one node</definiens>
			</definition>
			<definition id="3">
				<sentence>The arc ( A , B ) yields a category { A , B , C , D } , and the arc ( A , C ) yields a category { A , C , B , E } .</sentence>
				<definiendum id="0">B</definiendum>
				<definiendum id="1">C )</definiendum>
			</definition>
			<definition id="4">
				<sentence>V is the total number of different words in the corpus .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the total number of different words in the corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>W is the number of words belonging to at least one of our categories .</sentence>
				<definiendum id="0">W</definiendum>
			</definition>
			<definition id="6">
				<sentence>C is the number of categories ( after merging and windowing . )</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the number of categories ( after merging and windowing</definiens>
			</definition>
			<definition id="7">
				<sentence>For each found category C containing N words , we computed the following ( see Table 2 ) : ( 1 ) Precision : the number of words present in both C and WN divided by N ; ( 2 ) Precision* : the number of correct words divided by N. Correct words are either words that appear in the WN subtree , or words whose entry in the American Heritage Dictionary or the Britannica directly defines them as belonging to the given class ( e.g. , ‘keyboard’ is defined as ‘a piano’ ; ‘mitt’ is defined by ‘a type of glove’ . )</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">‘mitt’</definiendum>
				<definiens id="0">the number of words present in both C and WN divided by N ; ( 2 ) Precision* : the number of correct words divided by N. Correct words are either words that appear in the WN subtree , or words whose entry in the American Heritage Dictionary or the Britannica directly defines them as belonging to the given class ( e.g. , ‘keyboard’ is defined as ‘a piano’ ;</definiens>
			</definition>
			<definition id="8">
				<sentence>This was done in order to overcome the relative poorness of WordNet ; ( 3 ) Recall : the number of words present in both C and WN divided by the number of ( single ) words in WN ; ( 4 ) The number of correctly discovered words ( New ) that are not in WN .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the number of words present in both C and WN divided by the number of ( single ) words in WN ; ( 4 ) The number of correctly discovered words ( New ) that are not in WN</definiens>
			</definition>
</paper>

		<paper id="1076">
			<definition id="0">
				<sentence>The most common corpus weighting scheme is the term frequency ( TF ) x inverse document frequency ( IDF ) , where TF is the number of times a term appears in a document , and IDF reflects the distribution of terms within the corpus ( Salton and Buckley , 1988 ) .</sentence>
				<definiendum id="0">most common corpus weighting scheme</definiendum>
				<definiendum id="1">term frequency</definiendum>
				<definiendum id="2">TF ) x inverse document frequency</definiendum>
				<definiendum id="3">IDF</definiendum>
				<definiendum id="4">TF</definiendum>
				<definiendum id="5">IDF</definiendum>
				<definiens id="0">the number of times a term appears in a document , and</definiens>
				<definiens id="1">reflects the distribution of terms within the corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>The most common language model is the Inverse Document Frequency ( IDF ) , which considers the distribution of terms between documents ( see equation ( 1 ) ) .</sentence>
				<definiendum id="0">most common language model</definiendum>
				<definiendum id="1">IDF )</definiendum>
			</definition>
			<definition id="2">
				<sentence>IDF ( t i ) =log 2 ( N ) –log 2 ( n i ) +1 ( 1 ) N is the total number of corpus documents ; n i is the number of documents that contain at least one occurrence of the term t i ; and t i is a term , which is typically stemmed .</sentence>
				<definiendum id="0">IDF</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the total number of corpus documents ; n i is the number of documents that contain at least one occurrence of the term t i</definiens>
			</definition>
			<definition id="3">
				<sentence>That is , the system should replace IDF with the Inverse Sentence Frequency ( ISF ) , where N in ( 1 ) is the total number of sentences and n i is the number of sentences with term i. Similarly , if the system retrieves terms or phrases then IDF should be replaced with the Inverse Term Frequency ( ITF ) , where N in ( 1 ) is the vocabulary size , and n i is the number of times a term or phrases appears in the corpus .</sentence>
				<definiendum id="0">ISF</definiendum>
				<definiendum id="1">n i</definiendum>
				<definiens id="0">the total number of sentences</definiens>
				<definiens id="1">the vocabulary size , and</definiens>
				<definiens id="2">the number of times a term or phrases appears in the corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>It is not clear which of the two components in equation ( 1 ) , the log 2 ( N ) , which reflects the number of documents , or the log 2 ( n i ) , which reflects the distribution of terms between documents within the corpus will dominate the equation .</sentence>
				<definiendum id="0">N )</definiendum>
				<definiens id="0">reflects the number of documents</definiens>
				<definiens id="1">reflects the distribution of terms between documents within the corpus will dominate the equation</definiens>
			</definition>
			<definition id="5">
				<sentence>Zipf’s Law is a special case of the power law , where θ is close to 1 ( Zipf , 1949 ) .</sentence>
				<definiendum id="0">Zipf’s Law</definiendum>
				<definiendum id="1">θ</definiendum>
				<definiens id="0">a special case of the power law</definiens>
			</definition>
			<definition id="6">
				<sentence>Figure 2B compares the document ( x ) and average term freqFrequency A Document vs. Sentence Document Frequency ( Log scale ) Ave r ag e Se n t e n ce F r eq u e n c y ( L o g sc ale ) B Document vs. Term Document Frequency ( Log scale ) A verag e T e rm F r e q u e n cy ( L o g scale ) C Sentence vs.Term Sentence Frequency ( Log scale ) A verag e T e rm F r e q u e n cy ( L o g scale ) Standard Deviation Error D Document vs. Sentence Document Frequency ( Log scale ) Sen ten ce S t an d a r d D e vi a t i o n ( L o g sc al e ) E Document vs. Term Document Frequency ( Log scale ) T e r m Sta n d a r d Devi at io n ( L o g sca le ) F Sentence vs. Term Sentence Frequency ( Log scale ) Te rm S t a n d a rd De v i a t i on ( Log s c a l e ) Figure 2 .</sentence>
				<definiendum id="0">verag</definiendum>
				<definiens id="0">Log scale ) Ave r ag e Se n t e n ce F r eq u e n c y ( L o g sc ale ) B Document vs. Term Document Frequency ( Log scale ) A verag e T e rm F r e q u e n cy ( L o g scale</definiens>
				<definiens id="1">L o g sca le ) F Sentence vs. Term Sentence Frequency ( Log scale ) Te rm S t a n d a rd De v i a t i on ( Log s c a l e</definiens>
			</definition>
			<definition id="7">
				<sentence>Raw frequency correlation between document , sentence , and term spaces .</sentence>
				<definiendum id="0">Raw frequency correlation</definiendum>
				<definiens id="0">between document , sentence , and term spaces</definiens>
			</definition>
			<definition id="8">
				<sentence>Figure 2C shows the sentence frequency ( x ) and average term frequency ( y ) , demonstrating that the sentence and term spaces are highly correlated .</sentence>
				<definiendum id="0">sentence frequency</definiendum>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>Examining a corpus of Dutch picture descriptions , Levelt proposes a bi-conditional wellformedness rule for repairs ( WFR ) that relates the structure of repairs to the structure of conjunctions .</sentence>
				<definiendum id="0">Levelt</definiendum>
				<definiens id="0">proposes a bi-conditional wellformedness rule for repairs ( WFR ) that relates the structure of repairs to the structure of conjunctions</definiens>
			</definition>
			<definition id="1">
				<sentence>The WFR conceptualizes repairs as the conjunction of an unfinished reparandum string ( α ) with a properly finished repair ( γ ) .</sentence>
				<definiendum id="0">WFR conceptualizes</definiendum>
				<definiens id="0">repairs as the conjunction of an unfinished reparandum string ( α ) with a properly finished repair ( γ )</definiens>
			</definition>
			<definition id="2">
				<sentence>Well-formedness rule for repairs ( WFR ) A repair 〈αγ〉 is well-formed if and only if there is a string β such that the string 〈αβ and∗ γ〉 is well-formed , where β is a completion of the constituent directly dominating the last element of α .</sentence>
				<definiendum id="0">Well-formedness rule for repairs</definiendum>
				<definiendum id="1">WFR</definiendum>
				<definiendum id="2">β</definiendum>
				<definiens id="0">a string β such that the string 〈αβ and∗ γ〉 is well-formed , where</definiens>
				<definiens id="1">a completion of the constituent directly dominating the last element of α</definiens>
			</definition>
			<definition id="3">
				<sentence>The other key element of Levelt’s WFR is the idea of conjunction of elements that are in some sense the same .</sentence>
				<definiendum id="0">WFR</definiendum>
				<definiens id="0">the idea of conjunction of elements that are in some sense the same</definiens>
			</definition>
			<definition id="4">
				<sentence>The prosodic annotation helps on its own and in combination with the daughter annotation that implements Levelt’s WFR .</sentence>
				<definiendum id="0">prosodic annotation</definiendum>
			</definition>
</paper>

		<paper id="2091">
			<definition id="0">
				<sentence>The present paper proposes a method by which to translate outputs of a robust HPSG parser into semantic representations of Typed Dynamic Logic ( TDL ) , a dynamic plural semantics defined in typed lambda calculus .</sentence>
				<definiendum id="0">Dynamic Logic</definiendum>
				<definiens id="0">a method by which to translate outputs of a robust HPSG parser into semantic representations of Typed</definiens>
				<definiens id="1">a dynamic plural semantics defined in typed lambda calculus</definiens>
			</definition>
			<definition id="1">
				<sentence>Typed Dynamic Logic is a dynamic plural semantics that formalizes the structure underlying the semantic interactions between quantification , plurality , bound variable/E-type anaphora 707 r e×···×e7→ t x i 1 ···x i n ≡ λG ( i7→ e ) 7→ t .</sentence>
				<definiendum id="0">Typed Dynamic Logic</definiendum>
				<definiens id="0">a dynamic plural semantics that formalizes the structure underlying the semantic interactions between quantification , plurality , bound variable/E-type anaphora 707 r e×···×e7→ t</definiens>
			</definition>
			<definition id="2">
				<sentence>Typed Dynamic Logic is described in typed lambda calculus ( Gödel’s System T ) with four ground types : e ( entity ) , i ( index ) , n ( natural number ) , and t ( truth ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">natural number ) , and t</definiens>
			</definition>
			<definition id="3">
				<sentence>Next , the mother node , which dominates the two items , ⎡ ⎢ ⎣ PHON “John runs” HEAD 1 SUBJ hi COMPS hi ⎤ ⎥ ⎦ ⎡ ⎢ ⎣ PHON “John” HEAD noun SUBJ hi COMPS hi ⎤ ⎥ ⎦ : 2 ⎡ ⎢ ⎢ ⎣ PHON “runs” HEAD verb : 1 SUBJ h 2 i COMPS hi ⎤ ⎥ ⎥ ⎦ John runs Figure 4 : An HPSG parse tree is generated by the application of Subject-Head Schema .</sentence>
				<definiendum id="0">mother node</definiendum>
				<definiens id="0">dominates the two items</definiens>
			</definition>
			<definition id="4">
				<sentence>Basically , we first assign TDL representations to lexical items that are terminal nodes of a parse tree , and then compose the TDL representation for the entire tree according to the tree structure ( Figure 5 ) .</sentence>
				<definiendum id="0">TDL</definiendum>
				<definiens id="0">representations to lexical items that are terminal nodes of a parse tree</definiens>
			</definition>
			<definition id="5">
				<sentence>ref ( x 1 ) [ John 0 x 1 s 1 ] `` run 0 es agent 0 ex 1 φ # ∗run _empty_ + Composition Rules normal composition word formation nonlocal application unary derivation ⎡ ⎣ PHON “John” HEAD noun SUBJ hi COMPS hi ⎤ ⎦ : 2 ⎡ ⎢ ⎣ PHON “runs” HEAD verb : 1 SUBJ h 2 i COMPS hi ⎤ ⎥ ⎦ Assignment Rules ¿ λw .</sentence>
				<definiendum id="0">ref ( x 1</definiendum>
				<definiens id="0">run 0 es agent 0 ex 1 φ # ∗run _empty_ + Composition Rules normal composition word formation nonlocal application unary derivation ⎡ ⎣ PHON “John” HEAD noun SUBJ hi COMPS hi ⎤ ⎦ : 2 ⎡ ⎢ ⎣ PHON “runs” HEAD verb : 1 SUBJ h 2 i COMPS hi ⎤ ⎥ ⎦ Assignment Rules ¿ λw</definiens>
			</definition>
			<definition id="6">
				<sentence>In addition , we defined extended TDL semantic representations , referred to as TDL Extended Structures ( TDLESs ) , to be paired with the extended composition rules .</sentence>
				<definiendum id="0">Structures</definiendum>
				<definiens id="0">to be paired with the extended composition rules</definiens>
			</definition>
			<definition id="7">
				<sentence>A TDLES is a tuple hT , p , ni , whereT is an extended TDL term , which can be either a TDL term or a special value ω .</sentence>
				<definiendum id="0">TDLES</definiendum>
				<definiendum id="1">whereT</definiendum>
				<definiens id="0">a tuple hT , p , ni ,</definiens>
				<definiens id="1">an extended TDL term , which can be either a TDL term or a special value ω</definiens>
			</definition>
			<definition id="8">
				<sentence>In addition , p and n are the necessary information for extended composition rules , where p is a matrix predicate in T andisusedbytheword formation rule , and n is a nonlocal argument , which takes either a variable occurring in T or an empty value .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the necessary information for extended composition rules</definiens>
				<definiens id="1">a matrix predicate in T andisusedbytheword formation rule</definiens>
				<definiens id="2">takes either a variable occurring in T or an empty value</definiens>
			</definition>
			<definition id="9">
				<sentence>Finally , n is an empty value .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">an empty value</definiens>
			</definition>
			<definition id="10">
				<sentence>Here , POS is a noun .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">a noun</definiens>
			</definition>
			<definition id="11">
				<sentence>If Type ¡ T L ¢ = α and Type ¡ T R ¢ = α 7→ β then S M = * T R T L p R union ¡ n L , n R ¢ + Else if Type ¡ T L ¢ =α 7→ β and Type ¡ T R ¢ =α then S M = * T L T R p L union ¡ n L , n R ¢ + In Definition 3.1 , Type ( T ) is a function that returns the type of TDL term T , and union ( n L , n R ) is defined as : union ¡ n L , n R ¢ = ⎧ ⎪ ⎨ ⎪ ⎩ empty if n L = n R = _empty_ ni L = n , n R = _empty_ fn L = _empty_ , n R = n undefined if n L 6= _empty_ , n R 6= _empty_ This function corresponds to the behavior of the union of SLASH in HPSG .</sentence>
				<definiendum id="0">T )</definiendum>
				<definiens id="0">T L ¢ = α and Type ¡ T R ¢ = α 7→ β then S M = * T R T L p R union ¡ n L , n R ¢ + Else if Type ¡ T L ¢ =α 7→ β and Type ¡ T R ¢ =α then S M = * T L T R p L union ¡ n L , n R ¢ + In Definition 3.1</definiens>
				<definiens id="1">a function that returns the type of TDL term T , and union ( n L , n R ) is defined as : union ¡ n L , n R ¢ = ⎧ ⎪ ⎨ ⎪ ⎩ empty if n L = n R = _empty_ ni L = n , n R = _empty_ fn L = _empty_ , n R = n undefined if n L 6= _empty_ , n R 6= _empty_ This function corresponds to the behavior of the union of SLASH in HPSG</definiens>
			</definition>
			<definition id="12">
				<sentence>If the notion of robustness serves as a criterion not only for the practical usefulness of natural language processing but also for the validity of linguistic theories , then the compositional transparency that penetrates all levels of syntax , sentential semantics , and discourse semantics , beyond the superficial difference between the laws that govern each of the levels , might be reconsidered as an essential principle of linguistic theories .</sentence>
				<definiendum id="0">discourse semantics</definiendum>
				<definiens id="0">penetrates all levels of syntax , sentential semantics</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>Normally , the filler node is a sister node of an ancestor node of the trace , i.e. the filler c-commands the trace node , but in case of clausal fillers it is also possible that the filler dominates the trace .</sentence>
				<definiendum id="0">filler node</definiendum>
				<definiens id="0">a sister node of an ancestor node of the trace</definiens>
			</definition>
			<definition id="1">
				<sentence>Base NPs NPs dominating a node of category NN , NNS , NNP , NNPS , DT , CD , JJ , JJR , JJS , PRP , RB , or EX are marked as base NPs .</sentence>
				<definiendum id="0">EX</definiendum>
				<definiens id="0">dominating a node of category NN , NNS , NNP , NNPS , DT , CD , JJ , JJR , JJS , PRP , RB , or</definiens>
			</definition>
			<definition id="2">
				<sentence>TMP features Each node on the path between an NP-TMP or PP-TMP node and its nominal head is labeled with the feature tmp .</sentence>
				<definiendum id="0">TMP</definiendum>
				<definiens id="0">features Each node on the path between an NP-TMP or PP-TMP node</definiens>
			</definition>
			<definition id="3">
				<sentence>The gap and domV features described above were also used by Klein and Manning ( 2003 ) .</sentence>
				<definiendum id="0">domV</definiendum>
			</definition>
			<definition id="4">
				<sentence>f. 0.07 -0.07 0.00 LST feature 0.12 -0.12 -0.11 NP-pp feature 0.13 -0.57 -0.39 Table 4 : Differences between the baseline f-scores for labeled bracketing , EC prediction , and coindexation ( CI ) and the f-scores without the specified feature .</sentence>
				<definiendum id="0">CI</definiendum>
				<definiens id="0">Differences between the baseline f-scores for labeled bracketing</definiens>
			</definition>
</paper>

		<paper id="2071">
			<definition id="0">
				<sentence>ISD differs from word sense discrimination and disambiguation ( WSD ) by increased complexity in several respects .</sentence>
				<definiendum id="0">ISD</definiendum>
				<definiendum id="1">WSD</definiendum>
				<definiens id="0">differs from word sense discrimination and disambiguation (</definiens>
			</definition>
			<definition id="1">
				<sentence>images ) QueryTerms Senses Coverage Examples of visual annotation cues BASS ( 2881 ) 5 : bass , bass guitar , bass instrument , bass fishing , sea bass CRANE ( 2650 ) 5 : crane , construction cranes , whooping crane , sandhill crane , origami cranes SQUASH ( 1948 ) 10 : squash+ : rules , butternut , vegetable , grow , game of , spaghetti , winter , types of , summer Table 1 : Web images for three ambiguous query terms were annotated manually out of context ( without considering the web page document ) .</sentence>
				<definiendum id="0">images</definiendum>
				<definiendum id="1">winter</definiendum>
				<definiens id="0">squash+ : rules , butternut , vegetable , grow , game of , spaghetti ,</definiens>
			</definition>
			<definition id="2">
				<sentence>When using image features , grayscale images ( no color histograms ) and images without salient regions ( no keypoints detected ) were also removed .</sentence>
				<definiendum id="0">grayscale images</definiendum>
				<definiens id="0">no color histograms ) and images without salient regions ( no keypoints detected ) were also removed</definiens>
			</definition>
			<definition id="3">
				<sentence>χ2i , j = 12 512summationdisplay k=1 ( hi ( k ) −hj ( k ) ) 2 hi ( k ) +hj ( k ) ( 1 ) Spectral clustering is a powerful way to separate non-convex groups of data .</sentence>
				<definiendum id="0">Spectral clustering</definiendum>
				<definiens id="0">a powerful way to separate non-convex groups of data</definiens>
			</definition>
</paper>

		<paper id="2005">
			<definition id="0">
				<sentence>We view the SMS language as a variant of English language with some derivations in vocabulary and grammar .</sentence>
				<definiendum id="0">SMS language</definiendum>
				<definiens id="0">a variant of English language with some derivations in vocabulary and grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>Finally , the SMS normalization model consists of two sub-models : a word-based language model ( LM ) , characterized by 1 ( | ) nn P ee − ) k and a phrasebased lexical mapping model ( channel model ) , characterized by ( | k P se ) k enullnull ) k enullnull nullnull .</sentence>
				<definiendum id="0">SMS normalization model</definiendum>
				<definiens id="0">consists of two sub-models : a word-based language model ( LM ) , characterized by 1 ( | ) nn P ee − ) k and a phrasebased lexical mapping model ( channel model ) , characterized by ( | k P se ) k enullnull ) k enullnull nullnull</definiens>
			</definition>
</paper>

		<paper id="1129">
			<definition id="0">
				<sentence>Taking bigram model for example , c is a correction candidate containing n terms , ncccc …21= , then P ( c ) can be written as the product of consecutive bigram probabilities : ∏ −= ) | ( ) ( 1ii ccPcP 1027 Similarly , the error model probability of a query is decomposed into generation probabilities of individual terms which are assumed to be independently generated : ∏= ) | ( ) | ( ii cqPcqP Previous proposed methods for error model estimation are all based on the similarity between the character strings of qi and ci as described in based method for this problem .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">error model estimation are all based on the similarity between the character strings of qi and ci as described in based</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , confusion probability cP estimates the possibility that one word w1 can be replaced by another word w2 : ∑= w c wPwwPwP wwPwwP ) ( ) | ( ) ( ) | ( ) | ( 22 1 12 ( 3 ) where w belongs to the set of words that cooccur with both w1 and w2 .</sentence>
				<definiendum id="0">confusion probability cP</definiendum>
				<definiens id="0">estimates the possibility that one word w1</definiens>
			</definition>
			<definition id="2">
				<sentence>To solve this problem , we define the final error model probability as the linear combination of confusion probability and a string edit-based error model probability ) | ( cqPed : ) | ( ) 1 ( ) | ( ) | ( cqPcqPcqP edc λλ −+= ( 5 ) where λ is the interpolation parameter between 0 and 1 that can be experimentally optimized on a development data set .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiens id="0">the final error model probability as the linear combination of confusion probability and a string edit-based error model probability ) | ( cqPed : ) | ( ) 1 ( ) | ( ) |</definiens>
			</definition>
			<definition id="3">
				<sentence>For our task , the maximum entropy model defines a posterior probabilistic distribution ) | ( qcP over a set of feature functions fi ( q , c ) defined on an input query q and its correction candidate c : ∑ ∑ ∑ = == c N i ii N i ii qcf qcfqcP 1 1 ) , ( exp ) , ( exp ) | ( λ λ ( 6 ) 1028 where λs are feature weights , which can be optimized by maximizing the posterior probability on the training set : ∑ ∈ = TDqt qtP ) , ( ) | ( logmaxarg* λ λ λ where TD denotes the set of training samples in the form of query-truth pairs presented to the training algorithm .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
				<definiendum id="1">TD</definiendum>
				<definiens id="0">a posterior probabilistic distribution ) | ( qcP over a set of feature functions fi ( q , c ) defined on an input query q and its correction candidate c : ∑ ∑ ∑ = == c</definiens>
				<definiens id="1">feature weights , which can be optimized by maximizing the posterior probability on the training set : ∑ ∈ = TDqt qtP ) , ( ) | ( logmaxarg* λ λ λ where</definiens>
				<definiens id="2">the set of training samples in the form of query-truth pairs presented to the training algorithm</definiens>
			</definition>
			<definition id="4">
				<sentence>For each of the experiments , the performance is evaluated by the following metrics : Accuracy : The number of correct outputs generated by the system divided by the total number of queries in the test set ; Recall : The number of correct suggestions for misspelled queries generated by the system divided by the total number of misspelled queries in the test set ; Precision : The number of correct suggestions for misspelled queries generated by the system divided by the total number of suggestions made by the system .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiendum id="1">Precision</definiendum>
				<definiens id="0">The number of correct outputs generated by the system divided by the total number of queries in the test set ;</definiens>
				<definiens id="1">The number of correct suggestions for misspelled queries generated by the system divided by the total number of suggestions made by the system</definiens>
			</definition>
			<definition id="5">
				<sentence>MENoSim is the model trained only with baseline features .</sentence>
				<definiendum id="0">MENoSim</definiendum>
				<definiens id="0">the model trained only with baseline features</definiens>
			</definition>
</paper>

		<paper id="1049">
			<definition id="0">
				<sentence>Hence , we introduce a function f ( A follows B ) to represent the direction and strength of the association of two segments A and B , f ( A follows B ) = braceleftbiggp ( if A precedes B ) 0 ( if B precedes A ) , ( 2 ) where p ( 0 ≤ p ≤ 1 ) denotes the association strength of the segments A and B. The association strengths of the two segments with different directions , eg , f ( A follows B ) and f ( B follows A ) , are not always identical in our definition , f ( A follows B ) negationslash= f ( B follows A ) .</sentence>
				<definiendum id="0">function f</definiendum>
				<definiendum id="1">f</definiendum>
				<definiens id="0">A follows B ) to represent the direction and strength of the association of two segments A and B , f ( A follows B ) = braceleftbiggp ( if A precedes B ) 0 ( if B precedes A )</definiens>
				<definiens id="1">the association strength of the segments A and B. The association strengths of the two segments with different directions , eg , f ( A follows B ) and f ( B follows A )</definiens>
			</definition>
			<definition id="1">
				<sentence>( 8 ) Here , am represents the last sentence in segment A ; b1 represents the first sentence in segment B ; T ( s ) is the publication date of the sentence s ; D ( s ) is the unique identifier of the document to which sentence s belongs : and N ( s ) denotes the line number of sentence s in the original document .</sentence>
				<definiendum id="0">; b1</definiendum>
				<definiendum id="1">N ( s )</definiendum>
				<definiens id="0">the last sentence in segment A</definiens>
				<definiens id="1">the first sentence in segment B</definiens>
				<definiens id="2">the unique identifier of the document to which sentence s belongs</definiens>
			</definition>
			<definition id="2">
				<sentence>We define the topical closeness of two segments A and B as follows , ftopic ( A follows B ) = 1|B| summationdisplay b∈B maxa∈A sim ( a , b ) .</sentence>
				<definiendum id="0">b∈B maxa∈A sim</definiendum>
				<definiens id="0">follows , ftopic ( A follows B ) = 1|B| summationdisplay</definiens>
			</definition>
			<definition id="3">
				<sentence>For sentence b ∈ B , maxa∈A sim ( a , b ) chooses the sentence a ∈ A most similar to sentence b and yields the similarity .</sentence>
				<definiendum id="0">maxa∈A sim</definiendum>
				<definiens id="0">chooses the sentence a ∈ A most similar to sentence b and yields the similarity</definiens>
			</definition>
			<definition id="4">
				<sentence>The topical-closeness criterion ftopic ( A follows B ) assigns a higher value when the topic referred by segment B is the same as segment A. Let us think of the case where we arrange segment A before B. Each sentence in segment B has the presuppositional information that should be conveyed to a reader in advance .</sentence>
				<definiendum id="0">topical-closeness criterion ftopic</definiendum>
				<definiens id="0">A follows B ) assigns a higher value when the topic referred by segment B is the same as segment A. Let us think of the case where we arrange segment A before B. Each sentence in segment B has the presuppositional information that should be conveyed to a reader in advance</definiens>
			</definition>
			<definition id="5">
				<sentence>Precedence criterion measures the substitutability of the presuppositional information of segment B ( eg , the sentences appearing before sentence b ) as segment A. This criterion is a formalization of the sentence-ordering algorithm proposed by Okazaki et al , ( 2004 ) .</sentence>
				<definiendum id="0">Precedence criterion</definiendum>
				<definiens id="0">measures the substitutability of the presuppositional information of segment B ( eg , the sentences appearing before sentence b</definiens>
			</definition>
			<definition id="6">
				<sentence>( 10 ) Here , Pb is a set of sentences appearing before sentence b in the original article ; and sim ( a , b ) denotes the cosine similarity of sentences a and b ( defined as in the topical-closeness criterion ) .</sentence>
				<definiendum id="0">Pb</definiendum>
				<definiens id="0">a set of sentences appearing before sentence b in the original article</definiens>
				<definiens id="1">the cosine similarity of sentences a and b ( defined as in the topical-closeness criterion )</definiens>
			</definition>
			<definition id="7">
				<sentence>( 11 ) Here , Sa is a set of sentences appearing after sentence a in the original article ; and sim ( a , b ) denotes the cosine similarity of sentences a and b ( defined as in the topical-closeness criterion ) .</sentence>
				<definiendum id="0">Sa</definiendum>
				<definiens id="0">a set of sentences appearing after sentence a in the original article ; and sim ( a , b ) denotes the cosine similarity of sentences a and b ( defined as in the topical-closeness criterion )</definiens>
			</definition>
			<definition id="8">
				<sentence>Figure 3 shows an example of calculating the succession criterion to arrange segments B after A. The succession criterion measures the substitutability of the succedent information ( eg , the sentences appearing after the sentence a ∈ A ) as segment B. criterion We integrate the four criteria described above to define the function f ( A follows B ) to represent the association direction and strength of the two segments A and B ( Formula 2 ) .</sentence>
				<definiendum id="0">succession criterion</definiendum>
				<definiendum id="1">function f</definiendum>
				<definiendum id="2">B</definiendum>
				<definiens id="0">measures the substitutability of the succedent information ( eg , the sentences appearing after the sentence a ∈ A</definiens>
				<definiens id="1">A follows B ) to represent the association direction and strength of the two segments A and</definiens>
			</definition>
			<definition id="9">
				<sentence>More specifically , given the two segments A and B , function f ( A follows B ) is defined to yield the integrated association strength from four values , fchro ( A follows B ) , ftopic ( A follows B ) , fpre ( A follows B ) , and fsucc ( A follows B ) .</sentence>
				<definiendum id="0">function f</definiendum>
			</definition>
			<definition id="10">
				<sentence>Similarly , segment +1 : [ fchro ( A follows B ) , ftopic ( A follows B ) , fpre ( A follows B ) , fsucc ( A follows B ) ] −1 : [ fchro ( B follows A ) , ftopic ( B follows A ) , fpre ( B follows A ) , fsucc ( B follows A ) ] Figure 5 : Two vectors in a training data generated from two ordered segments A follows B pairs , { ( b ) , ( c ) } , { ( a follows b ) , ( c ) } , { ( b ) , ( c follows d ) } , { ( a follows b ) , ( c follows d ) } , are obtained from the partitioning point between sentence b and c. Collecting the segment pairs from the partitioning point between sentences c and d ( i.e. , { ( c ) , ( d ) } , { ( b follows c ) , ( d ) } and { ( a follows b follows c ) , ( d ) } ) , we identify ten pairs in total form the four ordered sentences .</sentence>
				<definiendum id="0">fsucc ( B</definiendum>
				<definiens id="0">A follows B ) , ftopic ( A follows B ) , fpre ( A follows B ) , fsucc ( A follows B ) ] −1 : [ fchro ( B follows A ) , ftopic ( B follows A ) , fpre ( B follows A )</definiens>
				<definiens id="1">Two vectors in a training data generated from two ordered segments A follows B pairs , { ( b ) , ( c ) } , { ( a follows b ) , ( c ) } , { ( b ) , ( c follows d ) } , { ( a follows b ) , ( c follows d ) }</definiens>
			</definition>
			<definition id="11">
				<sentence>Given a pair of two segments A and B arranged in an order A follows B , we calculate four values , fchro ( A follows B ) , ftopic ( A follows B ) , fpre ( A follows B ) , and fsucc ( A follows B ) to obtain the instance with the four-dimensional vector ( Figure 5 ) .</sentence>
				<definiendum id="0">fchro</definiendum>
				<definiendum id="1">fsucc</definiendum>
				<definiens id="0">A follows B ) , ftopic ( A follows B ) , fpre ( A follows B ) , and</definiens>
			</definition>
			<definition id="12">
				<sentence>The SVM classifier yields the association direction of two segments ( eg , A follows B or B follows A ) with the class information ( ie , +1 or −1 ) .</sentence>
				<definiendum id="0">SVM classifier</definiendum>
				<definiens id="0">yields the association direction of two segments ( eg , A follows B or B follows A ) with the class information</definiens>
			</definition>
			<definition id="13">
				<sentence>We describe briefly the seven algorithms ( including the proposed method ) : Agglomerative ordering ( AGL ) is an ordering arranged by the proposed method ; Random ordering ( RND ) is the lowest anchor , in which sentences are arranged randomly ; Human-made ordering ( HUM ) is the highest anchor , in which sentences are arranged by a human subject ; Chronological ordering ( CHR ) arranges sentences with the chronology criterion defined in Formula 8 .</sentence>
				<definiendum id="0">AGL</definiendum>
				<definiendum id="1">Random ordering</definiendum>
				<definiendum id="2">Human-made ordering</definiendum>
				<definiendum id="3">HUM</definiendum>
				<definiendum id="4">Chronological ordering</definiendum>
				<definiens id="0">the lowest anchor , in which sentences are arranged randomly</definiens>
				<definiens id="1">the highest anchor , in which sentences are arranged by a human subject</definiens>
			</definition>
			<definition id="14">
				<sentence>Each set of or390 Teval = ( e follows a follows b follows c follows d ) Tref = ( a follows b follows c follows d follows e ) Figure 7 : An example of an ordering under evaluation Teval and its reference Tref .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">follows a follows b follows c follows d ) Tref = ( a follows b follows c follows d follows e</definiens>
			</definition>
			<definition id="15">
				<sentence>In addition to Spearman’s and Kendall’s rank correlation coefficients , we propose an average continuity metric , which extends the idea of the continuity metric to continuous k sentences .</sentence>
				<definiendum id="0">average continuity metric</definiendum>
				<definiens id="0">extends the idea of the continuity metric to continuous k sentences</definiens>
			</definition>
			<definition id="16">
				<sentence>( 12 ) Here , N is the number of sentences in the reference ordering ; n is the length of continuous sentences on which we are evaluating ; m is the number of continuous sentences that appear in both the evaluation and reference orderings .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">m</definiendum>
				<definiens id="0">the number of sentences in the reference ordering</definiens>
				<definiens id="1">the length of continuous sentences on which we are evaluating</definiens>
			</definition>
			<definition id="17">
				<sentence>( 13 ) The Average Continuity ( AC ) is defined as the logarithmic average of Pn over 2 to k : AC = exp parenleftBigg 1 k−1 ksummationdisplay n=2 log ( Pn +α ) parenrightBigg .</sentence>
				<definiendum id="0">Average Continuity ( AC )</definiendum>
			</definition>
			<definition id="18">
				<sentence>The proposed method ( AGL ) outperforms the 391 AG LCHRSUCPRETO PRND 8765432 Precision P n Length n Figure 8 : Precision vs unit of measuring continuity .</sentence>
				<definiendum id="0">AGL</definiendum>
				<definiens id="0">Precision vs unit of measuring continuity</definiens>
			</definition>
</paper>

		<paper id="1114">
			<definition id="0">
				<sentence>Open-Domain Question Answering ( Q/A ) systems return a textual expression , identi ed from a vast document collection , as a response to a question asked in natural language .</sentence>
				<definiendum id="0">Open-Domain Question Answering</definiendum>
				<definiens id="0">a textual expression , identi ed from a vast document collection , as a response to a question asked in natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>q. By establishing TE between a question and AGQs derived from passages identi ed by the Q/A system for that question , we expect we can identify a set of answer passages that contain correct answers to the original question .</sentence>
				<definiendum id="0">AGQs</definiendum>
				<definiendum id="1">Q/A system</definiendum>
				<definiens id="0">identify a set of answer passages that contain correct answers to the original question</definiens>
			</definition>
			<definition id="2">
				<sentence>Our TE system consists of ( 1 ) a Preprocessing Module , which derives linguistic knowledge from the text pair ; ( 2 ) an Alignment Module , which takes advantage of the notions of lexical alignment 907 Classifier YES NOTextual Input 2 Textual Input 1 Preprocessing Training Corpora Features Alignment Dependency Features Paraphrase Features Semantic/ Pragmatic Features Coreference Coreference NEAliasing Concept Paraphrase Acquisition WWW Lexical Alignment Alignment Module Feature Extraction Classification Module Lexico−Semantic PoS/ NER Synonyms/ Antonyms Normalization Syntactic Semantic Temporal Parsing Modality Detection Speech Act Recognition Pragmatics Factivity Detection Belief Recognition Figure 2 : Textual Entailment Architecture .</sentence>
				<definiendum id="0">TE system</definiendum>
				<definiens id="0">consists of ( 1 ) a Preprocessing Module , which derives linguistic knowledge from the text pair ; ( 2 ) an Alignment Module , which takes advantage of the notions of lexical alignment 907 Classifier YES NOTextual Input 2 Textual Input 1 Preprocessing Training Corpora Features Alignment Dependency Features Paraphrase Features Semantic/ Pragmatic Features Coreference Coreference NEAliasing Concept Paraphrase Acquisition WWW Lexical Alignment Alignment Module Feature Extraction Classification Module Lexico−Semantic PoS/ NER Synonyms/ Antonyms Normalization Syntactic Semantic Temporal Parsing Modality Detection Speech Act Recognition Pragmatics Factivity Detection Belief Recognition Figure 2 : Textual Entailment Architecture</definiens>
			</definition>
			<definition id="3">
				<sentence>and textual paraphrases ; and ( 3 ) a Classi cation Module , which uses a machine learning classi er ( based on decision trees ) to make an entailment judgment for each pair of texts .</sentence>
				<definiendum id="0">Classi cation Module</definiendum>
				<definiens id="0">uses a machine learning classi er ( based on decision trees ) to make an entailment judgment for each pair of texts</definiens>
			</definition>
			<definition id="4">
				<sentence>Following preprocessing , texts are sent to an Alignment Module which uses a Maximum Entropy-based classi er in order to estimate the probability that pairs of constituents selected from texts encode corresponding information that could be used to inform an entailment judgment .</sentence>
				<definiendum id="0">Alignment Module</definiendum>
				<definiens id="0">uses a Maximum Entropy-based classi er in order to estimate the probability that pairs of constituents selected from texts encode corresponding information that could be used to inform an entailment judgment</definiens>
			</definition>
			<definition id="5">
				<sentence>Based on these features , the classi er outputs both an entailment judgment ( either yes or no ) and a con dence value , which is used to rank answers or paragraphs in the architecture illustrated in Figure 1 .</sentence>
				<definiendum id="0">entailment judgment</definiendum>
				<definiens id="0">used to rank answers or paragraphs in the architecture illustrated in Figure 1</definiens>
			</definition>
			<definition id="6">
				<sentence>DEPENDENCY FEATURES : These four features are computed from the PropBank-style annotations assigned by the semantic parser .</sentence>
				<definiendum id="0">DEPENDENCY FEATURES</definiendum>
				<definiens id="0">the PropBank-style annotations assigned by the semantic parser</definiens>
			</definition>
			<definition id="7">
				<sentence>diamondmath3diamondmath CATEGORY MATCH : This is a boolean feature which red when paraphrases could be found from the same paraphrase cluster that matched both texts .</sentence>
				<definiendum id="0">diamondmath3diamondmath CATEGORY MATCH</definiendum>
				<definiens id="0">a boolean feature which red when paraphrases could be found from the same paraphrase cluster that matched both texts</definiens>
			</definition>
			<definition id="8">
				<sentence>diamondmath4diamondmath NUMBER OF GLOSSES : This feature is a vector representing the number of Gloss relations used in each antonymy chain .</sentence>
				<definiendum id="0">diamondmath4diamondmath NUMBER OF GLOSSES</definiendum>
				<definiens id="0">a vector representing the number of Gloss relations used in each antonymy chain</definiens>
			</definition>
			<definition id="9">
				<sentence>diamondmath5diamondmath NUMBER OF MORPHOLOGICAL CHANGES : This feature is a vector representing the number of Morphological-Derivation relations found in each antonymy chain .</sentence>
				<definiendum id="0">diamondmath5diamondmath NUMBER OF MORPHOLOGICAL CHANGES</definiendum>
				<definiens id="0">a vector representing the number of Morphological-Derivation relations found in each antonymy chain</definiens>
			</definition>
			<definition id="10">
				<sentence>diamondmath6diamondmath NUMBER OF NODES WITH DEPENDENCIES : This feature is a vector indexing the number of nodes in each antonymy chain that contain dependency relations .</sentence>
				<definiendum id="0">diamondmath6diamondmath NUMBER OF NODES WITH DEPENDENCIES</definiendum>
				<definiens id="0">a vector indexing the number of nodes in each antonymy chain that contain dependency relations</definiens>
			</definition>
			<definition id="11">
				<sentence>diamondmath7diamondmath TRUTH-VALUE MISMATCH : This is a boolean feature which red when two aligned predicates differed in any truth value .</sentence>
				<definiendum id="0">diamondmath7diamondmath TRUTH-VALUE MISMATCH</definiendum>
				<definiens id="0">a boolean feature which red when two aligned predicates differed in any truth value</definiens>
			</definition>
			<definition id="12">
				<sentence>diamondmath8diamondmath POLARITY MISMATCH : This is a boolean feature which red when predicates were assigned opposite polarity values .</sentence>
				<definiendum id="0">diamondmath8diamondmath POLARITY MISMATCH</definiendum>
				<definiens id="0">a boolean feature which red when predicates were assigned opposite polarity values</definiens>
			</definition>
			<definition id="13">
				<sentence>In order to provide a baseline for our experiments , we ran a version of our Q/A system , known as FERRET ( Harabagiu et al. , 2005a ) , that does not make use of textual entailment information when identifying answers to questions .</sentence>
				<definiendum id="0">FERRET</definiendum>
			</definition>
</paper>

		<paper id="4003">
			<definition id="0">
				<sentence>LeXFlow is a web-based application that enables the cooperative and distributed management of computational lexicons .</sentence>
				<definiendum id="0">LeXFlow</definiendum>
				<definiens id="0">a web-based application that enables the cooperative and distributed management of computational lexicons</definiens>
			</definition>
			<definition id="1">
				<sentence>LeXFlow is a workflow management system aimed at enabling the semi-automatic management of computational lexicons .</sentence>
				<definiendum id="0">LeXFlow</definiendum>
				<definiens id="0">a workflow management system aimed at enabling the semi-automatic management of computational lexicons</definiens>
			</definition>
			<definition id="2">
				<sentence>The DW environment is the set of human and software agents participating to at least one DW .</sentence>
				<definiendum id="0">DW environment</definiendum>
				<definiens id="0">the set of human and software agents participating to at least one DW</definiens>
			</definition>
			<definition id="3">
				<sentence>Cocoon is a publishing framework that uses the power of XML .</sentence>
				<definiendum id="0">Cocoon</definiendum>
				<definiens id="0">a publishing framework that uses the power of XML</definiens>
			</definition>
</paper>

		<paper id="3011">
			<definition id="0">
				<sentence>A computer system , which has to understand and generate natural language , needs knowledge about the real world .</sentence>
				<definiendum id="0">computer system</definiendum>
				<definiens id="0">has to understand and generate natural language , needs knowledge about the real world</definiens>
			</definition>
			<definition id="1">
				<sentence>OntoLearn ( Missikoff et al. , 2002 ) uses specialized web site texts as a corpus to extract terminology , which is filtered by statistical techniques and then used to create a domain concept forest with the help of a semantic interpretation and the detection of taxonomic and similarity relations .</sentence>
				<definiendum id="0">OntoLearn</definiendum>
				<definiens id="0">uses specialized web site texts as a corpus to extract terminology , which is filtered by statistical techniques and then used to create a domain concept forest with the help of a semantic interpretation and the detection of taxonomic and similarity relations</definiens>
			</definition>
			<definition id="2">
				<sentence>KAON Text-To-Onto ( Maedche and Staab , 2004 ) applies text mining algorithms for English and German texts to semi-automatically create an ontology , which includes algorithms for term extraction , for concept association extraction and for ontology pruning .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">includes algorithms for term extraction</definiens>
			</definition>
			<definition id="3">
				<sentence>The SmartWeb Project into which On2L will be integrated as well , aims at constructing an opendomain spoken dialog system ( Wahlster , 2004 ) and includes different techniques to learn ontological knowledge for the system’s ontology .</sentence>
				<definiendum id="0">SmartWeb Project</definiendum>
				<definiens id="0">aims at constructing an opendomain spoken dialog system ( Wahlster , 2004 ) and includes different techniques to learn ontological knowledge for the system’s ontology</definiens>
			</definition>
			<definition id="4">
				<sentence>RelExt ( Schutz and Buitelaar , 2005 ) automatically identifies highly relevant pairs of concepts connected by a relation over concepts from an existing ontology .</sentence>
				<definiendum id="0">RelExt</definiendum>
				<definiens id="0">identifies highly relevant pairs of concepts connected by a relation over concepts from an existing ontology</definiens>
			</definition>
			<definition id="5">
				<sentence>Relext : A tool for relation extraction in ontology extension .</sentence>
				<definiendum id="0">Relext</definiendum>
				<definiens id="0">A tool for relation extraction in ontology extension</definiens>
			</definition>
</paper>

		<paper id="1084">
			<definition id="0">
				<sentence>In this model , we found 834 entries for the Π vector ( which models the distribution of tags in first position in sentences ) out of possibly N = 1934 , about 250K entries for the A matrix ( which models the transition probabilities from tag to tag ) out of possibly N2 ≈ 3.7M , and about 300K entries for the B matrix ( which models 3Transcription according to Ornan ( 2002 ) .</sentence>
				<definiendum id="0">Π vector</definiendum>
				<definiendum id="1">matrix</definiendum>
				<definiens id="0">models the distribution of tags in first position in sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>A morpheme is represented by a tuple ( symbol , state , prev , next ) , where symbol denotes a morpheme , state is one possible tag for this morpheme , prev and next are sets of indexes , denoting the indexes of the morphemes ( of the previous and the next vectors ) that precede and follow the current morpheme in the overall lattice , representing the sentence .</sentence>
				<definiendum id="0">symbol</definiendum>
				<definiendum id="1">state</definiendum>
			</definition>
			<definition id="2">
				<sentence>In order to meet the condition of Baum-Eagon inequality ( Baum , 1972 ) that the polynomial P ( O|µ ) – which represents the probability of an observed sequence O given a model µ – be homogeneous , we must add a sequence of special EOS ( end of sentence ) symbols at the end of each path up to the last vector , so that all the paths reach the same length .</sentence>
				<definiendum id="0">Baum-Eagon inequality</definiendum>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>Here , a102 is a tradeoff parameter that controls the influence of the unlabeled data .</sentence>
				<definiendum id="0">a102</definiendum>
				<definiens id="0">a tradeoff parameter that controls the influence of the unlabeled data</definiens>
			</definition>
			<definition id="1">
				<sentence>The total overlap over all possible label sequences can be defined as a63a32a76 a2 a12 a48a50a49 a12a15a24a37a51a14a45a28 a1 a48 a12a15a14a45a28a34a94 a1 a48 a12a15a14a45a28a25a28 a8 a63a34a76 a63 a3a5a4a7a6a9a8 a48a50a49 a12a15a24a37a51a14a45a28 a1 a48 a12a15a14a45a28 a84a87a86a89a88 a48a50a49 a12a15a24a37a51a14a45a28 a1 a48 a12a15a14a45a28 a1 a48 a12a15a14a45a28 a8 a63 a3a5a4a7a6a10a8 a1 a48 a12a15a14a45a28 a63a34a76 a48a50a49 a12a15a24a37a51a14a45a28 a84 a86a89a88 a48a50a49 a12a15a24a37a51a14a45a28 which motivates the negative entropy term in ( 2 ) .</sentence>
				<definiendum id="0">total overlap over all possible label sequences</definiendum>
			</definition>
			<definition id="2">
				<sentence>To see why , note that the entropy regularizer can be seen as a composition , a11 a12 a66 a28 a8 a68 a12a13a12 a12 a66 a28a25a28 , where a68 a14a16a15a18a17a19a20a17a22a21 a15 , a68 a12a13a12a60a28 a8 a23 a76 a12 a76 a84a87a86a89a88 a12 a76 and a12 a76 a14a24a15 a61 a21 a15 , a12 a76 a12 a66 a28 a8 a18 a25a27a26 a16 a3 a20 a55a58a57a60a59 a10 a23 a61 a64a32a65 a18 a66 a64a70a68a70a64 a12a15a14a39a22a25a24a56a28 a40 .</sentence>
				<definiendum id="0">entropy regularizer</definiendum>
				<definiens id="0">a composition</definiens>
			</definition>
			<definition id="3">
				<sentence>Once we obtain the gradient of the objective function ( 2 ) , we use limited-memory L-BFGS , a quasi-Newton optimization algorithm ( McCallum 2002 ; Nocedal and Wright 2000 ) , to find the local maxima with the initial value being set to be the optimal solution of the supervised CRF on labeled data .</sentence>
				<definiendum id="0">quasi-Newton optimization algorithm</definiendum>
			</definition>
</paper>

		<paper id="4009">
			<definition id="0">
				<sentence>This is demonstrated in the following examples ; T-VAL is the attribute we use for intermediate TIMEX values produced by the recognition process .</sentence>
				<definiendum id="0">T-VAL</definiendum>
				<definiens id="0">values produced by the recognition process</definiens>
			</definition>
</paper>

		<paper id="1056">
			<definition id="0">
				<sentence>Tufis et al. ( 2004 ) used cross-lingual lexicalization , wordnets alignment for several languages , and a clustering algorithm to perform WSD on a set of polysemous English words .</sentence>
				<definiendum id="0">cross-lingual lexicalization</definiendum>
				<definiendum id="1">wordnets alignment</definiendum>
				<definiens id="0">for several languages , and a clustering algorithm to perform WSD on a set of polysemous English words</definiens>
			</definition>
			<definition id="1">
				<sentence>WSD is a task that has attracted researchers since 1950 and it is still a topic of high interest .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">a task that has attracted researchers since 1950</definiens>
			</definition>
</paper>

		<paper id="3012">
			<definition id="0">
				<sentence>The LKB system generates the semantic information which is represented by MRS representation .</sentence>
				<definiendum id="0">LKB system</definiendum>
				<definiens id="0">generates the semantic information which is represented by MRS representation</definiens>
			</definition>
			<definition id="1">
				<sentence>The last node in the list of objects is defined as the focus position to emphasize tone ( FETobj ) , see figure 2 ( a ) .</sentence>
				<definiendum id="0">last node in the list of objects</definiendum>
				<definiendum id="1">FETobj</definiendum>
				<definiens id="0">the focus position to emphasize tone (</definiens>
			</definition>
			<definition id="2">
				<sentence>A focus wordstructure ( focus-word ) containsthefocuscriterion ( fcgroup ) , speech act code ( spcode ) , sentence mood ( stmood ) and focus position ( focuspos ) in a focus part .</sentence>
				<definiendum id="0">focus wordstructure</definiendum>
				<definiens id="0">focus-word ) containsthefocuscriterion ( fcgroup ) , speech act code ( spcode ) , sentence mood ( stmood ) and focus position ( focuspos ) in a focus part</definiens>
			</definition>
			<definition id="3">
				<sentence>In figure 4 , “Kim” is a actor part while “bought” is an act part .</sentence>
				<definiendum id="0">“Kim”</definiendum>
				<definiens id="0">a actor part while “bought” is an act part</definiens>
			</definition>
			<definition id="4">
				<sentence>The feat-struc structure is composed of six main subfeature structures : ( i ) focus category structure ( focus-cat ) is a set of constraints which are the combinations of a focus part and a focus criterion such as act g , actor g , actee g , and so on , ( ii ) focus part structure ( focus-part ) classifies act part and non-act part as actor part or actee part , ( iii ) focus structure ( focus-struc ) is a subfeature structure of focus-word and focus-phrase , ( iv ) checking whether prosodic marks can be marked ( prosody ) , ( v ) prosodic mark ( prosody-mark ) structure maps between types of prosodic mark and accent and boundary tones : no-mark , hEm Sh-break , etc , ( vi ) a set of prosodic marks ( prosody-set ) is a set of combinations between accent and boundary tones .</sentence>
				<definiendum id="0">boundary tones : no-mark , hEm Sh-break</definiendum>
				<definiens id="0">a set of constraints which are the combinations of a focus part and a focus criterion such as act g , actor g , actee g , and so on , ( ii ) focus part structure ( focus-part ) classifies act part and non-act part as actor part or actee part</definiens>
			</definition>
			<definition id="5">
				<sentence>The ARGS represents a list of words in the sentence .</sentence>
				<definiendum id="0">ARGS</definiendum>
				<definiens id="0">a list of words in the sentence</definiens>
			</definition>
			<definition id="6">
				<sentence>ORTH : Kim Focus : actor-part ACCENT_TONE1 : NOACCENT BOUND_TONE1 : NOBOUND ORTH : bought Focus : act-part ACCENT_TONE1 : NOACCENT BOUND_TONE1 : NOBOUND ORTH : a Focus : actee-part ACCENT_TONE1 : NOACCENT BOUND_TONE1 : NOBOUND ORTH : flower Focus : actee-part ACCENT_TONE1 : L+H* BOUND_TONE1 : L-L % Figure 9 : A set of words and their tone marks We design the FET system based on the small number of sentences from a part of the CMU communicator dataset ( 2002 ) .</sentence>
				<definiendum id="0">ORTH</definiendum>
				<definiens id="0">actor-part ACCENT_TONE1 : NOACCENT BOUND_TONE1 : NOBOUND ORTH : bought Focus : act-part ACCENT_TONE1 : NOACCENT BOUND_TONE1 : NOBOUND ORTH : a Focus : actee-part ACCENT_TONE1</definiens>
			</definition>
</paper>

		<paper id="2020">
			<definition id="0">
				<sentence>SumBasic produced extract summaries which performed nearly as well as the best machine systems for generic100wordsummaries , asevaluatedinDUC 2003 and 2004 , as well as the Multi-lingual Summarization Evaluation ( MSE 2005 ) .</sentence>
				<definiendum id="0">SumBasic</definiendum>
				<definiendum id="1">Multi-lingual Summarization Evaluation</definiendum>
				<definiens id="0">produced extract summaries which performed nearly as well as the best machine systems for generic100wordsummaries</definiens>
			</definition>
			<definition id="1">
				<sentence>The oracle score for a sentence x , ω ( x ) , can then be defined in terms of 153 P : ω ( x ) = 1|x|summationdisplay t∈T x ( t ) P ( t|τ ) where |x| is the number of distinct terms sentence x contains , T is the universal set of all terms used in the topic τ and x ( t ) = 1 if the sentence x contains the term t and 0 otherwise .</sentence>
				<definiendum id="0">oracle score</definiendum>
				<definiendum id="1">|x|</definiendum>
				<definiendum id="2">T</definiendum>
				<definiens id="0">the number of distinct terms sentence x contains ,</definiens>
				<definiens id="1">the universal set of all terms used in the topic τ and x ( t ) = 1 if the sentence x contains the term t and 0 otherwise</definiens>
			</definition>
			<definition id="2">
				<sentence>The letter “O” represents the ROUGE-2 scores for extract summaries produced by the oracle score , ˆω .</sentence>
				<definiendum id="0">letter “O”</definiendum>
				<definiens id="0">the ROUGE-2 scores for extract summaries produced by the oracle score</definiens>
			</definition>
			<definition id="3">
				<sentence>Given a collection of query terms and signature terms , we can readily estimate our target objective , P ( t|τ ) by the following : Pqs ( t|τ ) = 12qt ( τ ) + 12st ( τ ) 155 Set d408c : ahmed , allison , andrew , bahamas , bangladesh , bn , caribbean , carolina , caused , cent , coast , coastal , croix , cyclone , damage , destroyed , devastated , disaster , dollars , drowned , flood , flooded , flooding , floods , florida , gulf , ham , hit , homeless , homes , hugo , hurricane , insurance , insurers , island , islands , lloyd , losses , louisiana , manila , miles , nicaragua , north , port , pounds , rain , rains , rebuild , rebuilding , relief , remnants , residents , roared , salt , st , storm , storms , supplies , tourists , trees , tropical , typhoon , virgin , volunteers , weather , west , winds , yesterday .</sentence>
				<definiendum id="0">croix</definiendum>
				<definiens id="0">flood , flooded , flooding , floods , florida , gulf , ham , hit , homeless , homes , hugo , hurricane , insurance , insurers , island , islands , lloyd , losses , louisiana , manila , miles , nicaragua , north , port , pounds , rain , rains , rebuild , rebuilding , relief , remnants , residents , roared , salt , st , storm , storms , supplies , tourists , trees , tropical , typhoon , virgin , volunteers</definiens>
			</definition>
			<definition id="4">
				<sentence>Similarly , we estimate the oracle score of a sentence’s expected number of human abstract terms as ωqs ( x ) = 1|x|summationdisplay t∈T x ( t ) Pqs ( t|τ ) where |x| is the number of distinct terms that sentence x contains , T is the universal set of all terms and x ( t ) = 1 if the sentence x contains the term t and 0 otherwise .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the oracle score of a sentence’s expected number of human abstract terms as ωqs ( x ) = 1|x|summationdisplay t∈T x ( t ) Pqs ( t|τ ) where |x| is the number of distinct terms that sentence x contains ,</definiens>
				<definiens id="1">the universal set of all terms and x ( t ) = 1 if the sentence x contains the term t and 0 otherwise</definiens>
			</definition>
			<definition id="5">
				<sentence>Wecallthisnormalizedterm sentence matrix A. Given a normalized term-sentence matrix A , QR factorization attempts to select columns of A in the order of their importance in spanning the subspace spanned by all of the columns .</sentence>
				<definiendum id="0">QR factorization</definiendum>
				<definiens id="0">attempts to select columns of A in the order of their importance in spanning the subspace spanned by all of the columns</definiens>
			</definition>
			<definition id="6">
				<sentence>We thendemonstratedthatanapproximationoftheoracle score based upon query terms and signature termsgivesrisetoanautomaticmethodofsummarization , which outperforms the systems entered in DUC05 .</sentence>
				<definiendum id="0">signature termsgivesrisetoanautomaticmethodofsummarization</definiendum>
				<definiens id="0">outperforms the systems entered in DUC05</definiens>
			</definition>
</paper>

		<paper id="1065">
			<definition id="0">
				<sentence>We estimated these probabilities using a discounted maximum likelihood estimate , in which a small fixed amount was subtracted from each link count : LPd ( w1 , ... , wk ) = links1 ( w1 , ... , wk ) −dcooc ( w 1 , ... , wk ) LPd ( w1 , ... , wk ) represents the estimated conditional link probability for the cluster of words w1 , ... , wk ; links1 ( w1 , ... , wk ) is the number of times they are linked by the stage 1 model , d is the discount ; and cooc ( w1 , ... , wk ) is the number of times they co-occur .</sentence>
				<definiendum id="0">wk</definiendum>
				<definiendum id="1">cooc ( w1 , ... , wk )</definiendum>
				<definiens id="0">the estimated conditional link probability for the cluster of words w1 , ... , wk</definiens>
			</definition>
			<definition id="1">
				<sentence>The feature values consist of the sum of the scaled log odds of the jumps between consecutive links in a hypothesized alignment , computed in both source sentence and target sentence order .</sentence>
				<definiendum id="0">feature values</definiendum>
				<definiens id="0">consist of the sum of the scaled log odds of the jumps between consecutive links in a hypothesized alignment , computed in both source sentence and target sentence order</definiens>
			</definition>
</paper>

		<paper id="1131">
			<definition id="0">
				<sentence>The relative salience of an object is the average of its visual salience ( S vis ) and discourse salience ( S disc ) , salience ( L ) = ( S vis ( L ) + S disc ( L ) ) /2 ( 1 ) Visual salience S vis is computed using the algorithm of ( Kelleher and van Genabith , 2004 ) .</sentence>
				<definiendum id="0">relative salience of an object</definiendum>
			</definition>
			<definition id="1">
				<sentence>Here again , the contrastive-relative distinc3 See inter alia ( Talmy , 1983 ; Herskovits , 1986 ; Vandeloise , 1991 ; Fillmore , 1997 ; Garrod et al. , 1999 ) for more discussion on these differences 1044 tion is dependent on the number of objects within the region of space defined by the preposition .</sentence>
				<definiendum id="0">inter alia</definiendum>
			</definition>
			<definition id="2">
				<sentence>A distractor landmark is a member of the candidate landmark set that stands in the considered relation to a distractor object .</sentence>
				<definiendum id="0">distractor landmark</definiendum>
			</definition>
</paper>

		<paper id="2028">
			<definition id="0">
				<sentence>An ME-system for WSD that operates on similar principles to our system ( Suarez , 2002 ) was based on an array of local features that included the words/POS tags/lemmas occurring in a window of +/-3 words of the word being disambiguated .</sentence>
				<definiendum id="0">ME-system for WSD</definiendum>
				<definiens id="0">features that included the words/POS tags/lemmas occurring in a window of +/-3 words of the word being disambiguated</definiens>
			</definition>
			<definition id="1">
				<sentence>The test corpus consists of 53,367 words sampled from the same domains as , and in approximately the same proportions as the training data , and labeled with a set of up to 6 allowable tags for each word .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiens id="0">consists of 53,367 words sampled from the same domains as , and in approximately the same proportions as the training data , and labeled with a set of up to 6 allowable tags for each word</definiens>
			</definition>
			<definition id="2">
				<sentence>Our tagging framework is based on a maximum entropy model of the following form : p ( t , c ) = γ Kproductdisplay k=0 αfk ( c , t ) k p0 ( 1 ) where : 216 ( _ ( Please_RRCONCESSIVE Mention_VVIVERBAL-ACT this_DD1 coupon_NN1DOCUMENT when_CSWHEN ordering_VVGINTER-ACT OR_CCOR ONE_MC1WORD FREE_JJMONEY FANTAIL_NN1ANIMAL SHRIMPS_NN1FOOD Figure 1 : Two ATR Treebank Sentences from a Take–Out Food Flier t is tag being predicted ; c is the context of t ; γ is a normalization coefficient that ensures : ΣLt=0γproducttextKk=0 αfk ( c , t ) k p0 = 1 ; K is the number of features in the model ; L is the number of tags in our tag set ; αk is the weight of feature fk ; fk are feature functions and fkepsilon1 { 0,1 } ; p0 is the default tagging model ( in our case , the uniform distribution , since all of the information in the model is specified using ME constraints ) .</sentence>
				<definiendum id="0">c</definiendum>
				<definiendum id="1">γ</definiendum>
				<definiendum id="2">K</definiendum>
				<definiendum id="3">L</definiendum>
				<definiendum id="4">p0</definiendum>
				<definiens id="0">a normalization coefficient that ensures : ΣLt=0γproducttextKk=0 αfk ( c</definiens>
				<definiens id="1">the number of features in the model ;</definiens>
				<definiens id="2">the number of tags in our tag set ; αk is the weight of feature fk ; fk are feature functions and fkepsilon1 { 0,1 } ;</definiens>
			</definition>
			<definition id="3">
				<sentence>Our baseline model contains the following feature predecate set : w0 t−1 pos0 pref1 ( w0 ) w−1 t−2 pos−1 pref2 ( w0 ) w−2 pos−2 pref3 ( w0 ) w+1 pos+1 suff1 ( w0 ) w+2 pos+2 suff2 ( w0 ) suff3 ( w0 ) where : wn is the word at offset n relative to the word whose tag is being predicted ; tn is the tag at offset n ; posn is the syntax-only tag at offset n assigned by a syntax-only tagger ; prefn ( w0 ) is the first n characters of w0 ; suffn ( w0 ) is the last n characters of w0 ; This feature set contains a typical selection of n-gram and basic morphological features .</sentence>
				<definiendum id="0">tn</definiendum>
				<definiendum id="1">posn</definiendum>
				<definiens id="0">the word at offset n relative to the word whose tag is being predicted ;</definiens>
				<definiens id="1">the syntax-only tag at offset n assigned by a syntax-only tagger</definiens>
				<definiens id="2">the first n characters of w0</definiens>
			</definition>
			<definition id="4">
				<sentence>Each predicate is effectively a question which asks whether the word ( or word being used in a particular sense in the case of the WordNet hierarchy ) is a descendent of the node to which the predicate applies .</sentence>
				<definiendum id="0">WordNet hierarchy )</definiendum>
				<definiens id="0">a question which asks whether the word ( or word being used in a particular</definiens>
				<definiens id="1">a descendent of the node to which the predicate applies</definiens>
			</definition>
			<definition id="5">
				<sentence>Moreover , the clustering process considers all types that actually occur in the corpus , and not just those words that might appear in a dictionary ( we will return to this later ) .</sentence>
				<definiendum id="0">clustering process</definiendum>
				<definiens id="0">considers all types that actually occur in the corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>One possible explanation for this is that overall , the coverage of both techniques is similar , but for rarer words , the MI clustering can be inconsistent due to lack of data ( for an example , see Figure 5.2 : the word newsstand is a member of a cluster of words that appear to be commodities ) , whereas the WordNet clustering remains consistent even for rare words .</sentence>
				<definiendum id="0">MI clustering</definiendum>
				<definiens id="0">a member of a cluster of words that appear to be commodities ) , whereas the WordNet clustering remains consistent even for rare words</definiens>
			</definition>
			<definition id="7">
				<sentence>221 # Model Accuracy ( ± c.i. ) OOV’s Nouns Verbs Adj/Adv 2 + Dependencies ( link grammar ) 82.74± 0.32 30.92 68.18 74.96 73.02 4 + Dependencies ( Collins’ parser ) 83.37± 0.31 31.24 69.36 75.78 72.62 5 + Automatically acquired ontology 83.71± 0.31 35.08 71.89 75.83 75.34 6 + WordNet ontology 83.90± 0.31 36.18 72.28 76.29 74.47 7 + Model 4 + Model 6 84.90± 0.31 37.02 72.80 78.36 76.16 Table 1 : Tagging accuracy ( % ) , ‘+’ being shorthand for “Baseline +” , ‘c.i.’ denotes the confidence interval of the mean at a 95 % significance level , calculated using bootstrap resampling .</sentence>
				<definiendum id="0">Tagging accuracy</definiendum>
				<definiendum id="1">‘c.i.’</definiendum>
				<definiens id="0">the confidence interval of the mean</definiens>
			</definition>
</paper>

		<paper id="1116">
			<definition id="0">
				<sentence>However , systems that use cue phrases usually rely on manually compiled lists , the acquisition of which is time-consuming and error-prone and results in cue phrases which are genre-speci c. Methods for nding cue phrases automatically include Hovy and Lin ( 1998 ) ( using the ratio of word frequency counts in summaries and their corresponding texts ) , Teufel ( 1998 ) ( using the most frequent n-grams ) , and Paice ( 1981 ) ( using a pattern matching grammar and a lexicon of manually collected equivalence classes ) .</sentence>
				<definiendum id="0">Paice</definiendum>
				<definiens id="0">time-consuming and error-prone and results in cue phrases which are genre-speci c. Methods for nding cue phrases automatically include Hovy and Lin ( 1998 ) ( using the ratio of word frequency counts in summaries and their corresponding texts</definiens>
			</definition>
			<definition id="1">
				<sentence>Unsupervised methods for similar tasks include Agichtein and Gravano’s ( 2000 ) work , which shows that clusters of vector-spacebased patterns can be successfully employed to detect speci c IE relationships ( companies and their headquarters ) , and Ravichandran and Hovy’s ( 2002 ) algorithm for nding patterns for a Question Answering ( QA ) task .</sentence>
				<definiendum id="0">Ravichandran</definiendum>
				<definiens id="0">shows that clusters of vector-spacebased patterns can be successfully employed to detect speci c IE relationships ( companies and their headquarters ) , and</definiens>
			</definition>
			<definition id="2">
				<sentence>( iii ) Accumulate : Add the top s items of the concept-B candidate set to the concept-B accumulator list ( based on empirical results , s is the rank of the candidate set during the initial iteration and 50 for the remaining iterations ) .</sentence>
				<definiendum id="0">s</definiendum>
				<definiens id="0">the rank of the candidate set during the initial iteration</definiens>
			</definition>
			<definition id="3">
				<sentence>Documents were manually annotated by the second author for ( possibly more than one ) goal-type sentence ; annotation of that type has been previously shown to be reliable at K=.71 ( Teufel , 1999 ) .</sentence>
				<definiendum id="0">annotation</definiendum>
				<definiens id="0">possibly more than one ) goal-type sentence</definiens>
			</definition>
</paper>

		<paper id="2048">
			<definition id="0">
				<sentence>The domain of a variable X will be denoted dom ( X ) , and typically we will use the lower-case correspondent ( in this case , x ) to denote a value in the domain of X. A partial assignment ( or simply assignment ) of a set X of variables is a function w that maps a subset W of the variables of X to values in their respective domains .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a value in the domain of X. A partial assignment ( or simply assignment ) of a set X of variables is a function w that maps a subset W of the variables of X to values in their respective domains</definiens>
			</definition>
			<definition id="1">
				<sentence>De ne a hierarchical labeling process ( HLP ) as a 5-tuple 〈L , &lt; , A , F , P〉 where : • L = { L1 , L2 , ... , Lm } is a nite set of labeling schemes .</sentence>
				<definiendum id="0">HLP</definiendum>
				<definiens id="0">a 5-tuple 〈L , &lt; , A , F , P〉 where : • L = { L1 , L2 , ... , Lm } is a nite set of labeling schemes</definiens>
			</definition>
			<definition id="2">
				<sentence>• F = { FS , F1 , F2 , ... , Fm } is a set of feature functions .</sentence>
				<definiendum id="0">F2 , ... , Fm }</definiendum>
				<definiens id="0">a set of feature functions</definiens>
			</definition>
			<definition id="3">
				<sentence>Speci cally , Fk ( resp. , FS ) takes four arguments : a partial assignment x of VL , and integers i , j , n such that 1 ≤ i ≤ j ≤ n. It maps this 4-tuple to a full assignment fk ( resp. , fS ) of some nite set Fk ( resp. , FS ) of feature variables .</sentence>
				<definiendum id="0">FS )</definiendum>
				<definiens id="0">takes four arguments : a partial assignment x of VL</definiens>
			</definition>
			<definition id="4">
				<sentence>PN is a marginal probability distribution over the set of positive integers , whereas { PS , P1 , P2 , ... , Pm } are conditional probability distributions .</sentence>
				<definiendum id="0">PN</definiendum>
				<definiens id="0">a marginal probability distribution over the set of positive integers</definiens>
			</definition>
			<definition id="5">
				<sentence>Speci cally , Pk ( respectively , PS ) is a function that takes as its argument a full assignment fk ( resp. , fS ) of feature set Fk ( resp. , 372 A ( variable Y , assignment x , int n ) : overlapping model variable Skl such that x ( Skl ) = true , then return 〈true , false〉 .</sentence>
				<definiendum id="0">PS )</definiendum>
				<definiens id="0">a function that takes as its argument a full assignment fk</definiens>
			</definition>
			<definition id="6">
				<sentence>Taking an HLP H = 〈L , &lt; , A , F , P〉 as input , HLPGEN outputs an integer n , and an H-labeling x of length n , de ned as a full assignment of VnL .</sentence>
				<definiendum id="0">HLPGEN</definiendum>
				<definiens id="0">outputs an integer n , and an H-labeling x of length n , de ned as a full assignment of VnL</definiens>
			</definition>
			<definition id="7">
				<sentence>The generative story from the previous section allows us to express the probability of a labeled tree as P ( n , x ) , where x is an H-labeling of length n. For model variable X , de ne V &lt; L ( X ) as the subset of VL appearing before X in model order &lt; .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">the subset of VL appearing before X in model order &lt;</definiens>
			</definition>
			<definition id="8">
				<sentence>With the help of this terminology , we can decompose P ( n , x ) into the following product : P0 ( n ) · productdisplay Sij∈Y PS ( x ( Sij ) |fSij ) · productdisplay Lkij∈Y Pk ( x ( Lkij ) |fkij ) where fSij = FS ( x|V &lt; L ( Sij ) , i , j , n ) and fkij = Fk ( x|V &lt; L ( L k ij ) , i , j , n ) and Y is the subset of VnL that was not automatically assigned by HLPGEN .</sentence>
				<definiendum id="0">· productdisplay Sij∈Y PS ( x ( Sij</definiendum>
				<definiendum id="1">fSij</definiendum>
				<definiendum id="2">Y</definiendum>
				<definiens id="0">the subset of VnL that was not automatically assigned by HLPGEN</definiens>
			</definition>
			<definition id="9">
				<sentence>n , then : let xbest = x ; let pbest = p. length n , then : ( a ) Let Y be the earliest variable in VnL ( according to model order &lt; ) unassigned by x. ( b ) If Y ∈ dom ( w ) , then push pair 〈x [ Y = w ( Y ) ] , p〉 onto stack S. ( c ) Else if A ( Y , x , n ) = 〈true , y〉 for some value y ∈ dom ( Y ) , then push pair 〈x [ Y = y ] , p〉 onto stack S. ( d ) Otherwise for every value y ∈ dom ( Y ) , push pair 〈x [ Y = y ] , p·q ( y ) 〉 onto stack S in ascending order of the value of q ( y ) , where : q ( y ) = braceleftBigPS ( y|FS ( x , i , j , n ) ) if Y = Sij Pk ( y|Fk ( x , i , j , n ) ) if Y = Lkij Figure 6 : Pseudocode for the decoder .</sentence>
				<definiendum id="0">VnL</definiendum>
				<definiens id="0">let xbest = x ; let pbest = p. length n</definiens>
				<definiens id="1">y ] , p〉 onto stack S. ( d ) Otherwise for every value y ∈ dom ( Y ) , push pair 〈x [ Y = y ] , p·q ( y ) 〉 onto stack S in ascending order of the value of q ( y )</definiens>
			</definition>
			<definition id="10">
				<sentence>The crossbracketing score of a set of candidate parses with 374 word ( i+k ) = w word ( j+k ) = w preterminal ( i+k ) = p preterminal ( j+k ) = p label ( i+k ) = l label ( j+k ) = l category ( i+k ) = c category ( j+k ) = c signature ( i , i+k ) = s Figure 7 : Basic feature templates used to determine constituency and labeling of span ( i , j ) .</sentence>
				<definiendum id="0">crossbracketing score</definiendum>
				<definiens id="0">Basic feature templates used to determine constituency and labeling of span</definiens>
			</definition>
			<definition id="11">
				<sentence>k is an arbitrary integer .</sentence>
				<definiendum id="0">k</definiendum>
				<definiens id="0">an arbitrary integer</definiens>
			</definition>
			<definition id="12">
				<sentence>Thus the object of our computation was HLPDECODE ( H , n , w ) , where n was the length of the sentence , and partial assignment w specied the word and PT labels of the leaves .</sentence>
				<definiendum id="0">HLPDECODE ( H</definiendum>
			</definition>
			<definition id="13">
				<sentence>CB denotes the average cross-bracketing , i.e. the overall percentage of candidate constituents that properly overlap with a constituent in the gold parse .</sentence>
				<definiendum id="0">CB</definiendum>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>Many words have multiple meanings , and the process of identifying the correct meaning , or sense of a word in context , is known as word sense disambiguation ( WSD ) .</sentence>
				<definiendum id="0">Many words</definiendum>
				<definiens id="0">have multiple meanings , and the process of identifying the correct meaning , or sense of a word in context , is known as word sense disambiguation ( WSD )</definiens>
			</definition>
			<definition id="1">
				<sentence>To investigate this , Escudero et al. ( 2000 ) conducted experiments using the DSO corpus , which contains sentences drawn from two different corpora , namely Brown Corpus ( BC ) and Wall Street Journal ( WSJ ) .</sentence>
				<definiendum id="0">DSO corpus</definiendum>
			</definition>
			<definition id="2">
				<sentence>Assuming we initialize a38 a20 a41 a44 a43 a1a39a27 a26 a11a45a15 a38 a20 a0 a1a39a27 a26 a11 , then for each instance a2 a18 in Da40 and each class a27 a26 , the EM 90 algorithm provides the following iterative steps : a38 a20 a41 a42 a43 a1a39a27 a26 a31 a2 a18 a11 a15 a38 a20 a0 a1a39a27 a26 a31 a2 a18 a11 a38a1a3a2a5a4a7a6 a41 a8a10a9 a43 a38 a1a11 a41 a8a12a9 a43 a13 a23 a14a9a19 a3 a38 a20 a0 a1a33a27 a14 a31 a2 a18 a11 a38 a1a2a5a4a7a6 a41 a8a15 a43 a38 a1a11 a41 a8a15 a43 ( 2 ) a38 a20 a41 a42a17a16 a3 a43 a1a39a27 a26 a11 a15 a18 a19 a10 a25 a18 a19 a3 a38 a20 a41 a42 a43 a1a33a27 a26 a31 a2 a18 a11 ( 3 ) where Equation ( 2 ) represents the expectation Estep , Equation ( 3 ) represents the maximization Mstep , and N represents the number of instances in Da40 .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of instances in Da40</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally , the calibrated binary-class probability estimates are combined to obtain multiclass probabilities , computed by a simple normalization of the calibrated estimates from each binary classifier , as suggested by Zadrozny and Elkan ( 2002 ) .</sentence>
				<definiendum id="0">binary-class probability estimates</definiendum>
				<definiens id="0">combined to obtain multiclass probabilities , computed by a simple normalization of the calibrated estimates from each binary classifier</definiens>
			</definition>
			<definition id="4">
				<sentence>The widely used SEMCOR ( SC ) corpus ( Miller et al. , 1994 ) is one of the few currently available manually sense-annotated corpora for WSD .</sentence>
				<definiendum id="0">SEMCOR</definiendum>
				<definiendum id="1">SC ) corpus</definiendum>
				<definiens id="0">one of the few currently available manually sense-annotated corpora for WSD</definiens>
			</definition>
			<definition id="5">
				<sentence>SEMCOR is a subset of BC .</sentence>
				<definiendum id="0">SEMCOR</definiendum>
				<definiens id="0">a subset of BC</definiens>
			</definition>
			<definition id="6">
				<sentence>Scalability is a problem faced by current supervised WSD systems , as they usually rely on manually annotated data for training .</sentence>
				<definiendum id="0">Scalability</definiendum>
				<definiens id="0">a problem faced by current supervised WSD systems , as they usually rely on manually annotated data for training</definiens>
			</definition>
			<definition id="7">
				<sentence>The methods in Table 4 are represented in the form a1-a2 , where a1 denotes adjusting the predictions of which classifier , and a2 denotes how the sense priors are estimated .</sentence>
				<definiendum id="0">a1</definiendum>
				<definiens id="0">adjusting the predictions of which classifier , and a2 denotes how the sense priors are estimated</definiens>
			</definition>
</paper>

		<paper id="2056">
			<definition id="0">
				<sentence>In this paper , we report our study on applying this assumption to Chinese word segFigure 1 : Intuitive illustration of a variety of successive tokens and a word boundary mentation by formalizing the uncertainty of successive tokens via the branching entropy ( which we mathematically de ne in the next section ) .</sentence>
				<definiendum id="0">entropy</definiendum>
				<definiens id="0">Intuitive illustration of a variety of successive tokens and a word boundary mentation by formalizing the uncertainty of successive tokens via the branching</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , Figure 2 shows how H ( XjX n ) shifts when n increases from 1 to 8 characters , where n is the length of a word pre x. This is calculated for all words existing in the test corpus , with the entropy being measuredin the learning data ( thelearning and test data are de ned in x4 ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">shows how H ( XjX n ) shifts when n increases from 1 to 8 characters</definiens>
			</definition>
			<definition id="2">
				<sentence>For such exact veri cation , we have to scan through all possible substrings ofan input , which amounts to O ( n 2 ) computational complexity , where n indicates the input length of characters .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">indicates the input length of characters</definiens>
			</definition>
			<definition id="3">
				<sentence>Precisely , there are three boundary conditions : B max h ( x n ) &gt; valmax , where h ( x n ) takes a local maximum , B increase h ( x n+1 ) BnZrh ( x n ) &gt; valdelta , B ordinary h ( x n ) &gt; val , where valmax , valdelta , and val are arbitrary thresholds .</sentence>
				<definiendum id="0">h ( x n )</definiendum>
				<definiendum id="1">B increase h</definiendum>
				<definiendum id="2">val</definiendum>
				<definiens id="0">takes a local maximum</definiens>
			</definition>
			<definition id="4">
				<sentence>Precisely , Precision = N correct N test ( 6 ) Recall = N correct N true ; where ( 7 ) N correct is the number of correct boundaries in the result , N test is the number of boundaries in the test result , and , N true is the number of boundaries in the golden standard .</sentence>
				<definiendum id="0">test</definiendum>
				<definiendum id="1">, N true</definiendum>
				<definiens id="0">the number of boundaries in the test result , and</definiens>
			</definition>
			<definition id="5">
				<sentence>In this sense , assumption ( A ) or ( B ) is a general assumption about a boundary ( of a sentence , phrase , word , morpheme ) .</sentence>
				<definiendum id="0">assumption</definiendum>
				<definiens id="0">a general assumption about a boundary ( of a sentence , phrase , word , morpheme )</definiens>
			</definition>
</paper>

		<paper id="2030">
			<definition id="0">
				<sentence>We thus use the Bayesian Information Criterion ( BIC ) as the splitting criterion , and select the proper number for k. Most of the work which addresses the small number of positive training stories applies statistical techniques based on word distribution and ML techniques .</sentence>
				<definiendum id="0">Bayesian Information Criterion</definiendum>
				<definiens id="0">the splitting criterion , and select the proper number for k. Most of the work which addresses the small number of positive training stories applies statistical techniques based on word distribution</definiens>
			</definition>
			<definition id="1">
				<sentence>The TDT English corpus consists of training and test stories .</sentence>
				<definiendum id="0">TDT English corpus</definiendum>
			</definition>
			<definition id="2">
				<sentence>More precisely , let E i be an English story ( 1 ≤ i ≤ n ) , where n is the number of stories in the collection , and S i J denote the set of Japanese stories with cosine similarities higher than a certain threshold value θ : S i J = { J j | cos ( E i , J j ) ≥ θ } .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of stories in the collection , and S i J denote the set of Japanese stories with cosine similarities higher than a certain threshold value θ : S i J = { J j | cos ( E i , J j ) ≥ θ }</definiens>
			</definition>
			<definition id="3">
				<sentence>The EM is a method of finding the maximum-likelihood estimate ( MLE ) of the parameters of an underlying distribution from a set of observed data that has missing value .</sentence>
				<definiendum id="0">EM</definiendum>
				<definiens id="0">a method of finding the maximum-likelihood estimate ( MLE ) of the parameters of an underlying distribution from a set of observed data that has missing value</definiens>
			</definition>
			<definition id="4">
				<sentence>BIC ( k = l ) = ˆ ll l ( X ) − p l 2 · log N ( 3 ) where ˆ ll l ( X ) is the log-likelihood of X according to the number of k is l , N is the total number of training stories , and p l is the number of parameters in k = l. We set p l to the sum of k class probabilities , summationtext k m=1 ˆ ll ( X m ) , the number of n · k centroid coordinates , and the MLE for the variance , ˆρ 2 .</sentence>
				<definiendum id="0">BIC</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">p l</definiendum>
				<definiens id="0">the log-likelihood of X according to the number of k is l ,</definiens>
				<definiens id="1">the total number of training stories</definiens>
				<definiens id="2">the number of parameters in k = l. We set p l to the sum of k class probabilities</definiens>
				<definiens id="3">X m ) , the number of n · k centroid coordinates</definiens>
			</definition>
			<definition id="5">
				<sentence>MIN denotes MIN ( C Det ) Norm which is the value of ( C Det ) Norm at the best possible threshold .</sentence>
				<definiendum id="0">MIN</definiendum>
				<definiens id="0">MIN ( C Det ) Norm which is the value of ( C Det ) Norm at the best possible threshold</definiens>
			</definition>
			<definition id="6">
				<sentence>The contribution of the extracted story pairs , especially the use of two types of story pairs , bilingual and monolingual , is best explained by looking at the two results : ( i ) the tracking results with two types of story pairs , with only English and 236 Table 3 : Basic results TDT1 ( Kobe Japan Quake ) Baseline Bilingual corpora &amp; clustering N t Miss F/A Recall Precision F MIN N t Miss F/A Recall Precision F MIN 1 27 % .15 % 73 % 67 % .70 .055 1 10 % .42 % 90 % 74 % .81 .023 2 20 % .12 % 80 % 73 % .76 .042 2 6 % .27 % 93 % 76 % .83 .013 4 9 % .09 % 91 % 80 % .85 .039 4 5 % .18 % 96 % 81 % .88 .012 TDT2 &amp; TDT3 ( 23 topics ) Baseline Bilingual corpora &amp; clustering N t Miss F/A Recall Precision F MIN N t Miss F/A Recall Precision F MIN 1 41 % .17 % 59 % 60 % .60 .089 1 29 % .25 % 71 % 54 % .61 .059 2 40 % .16 % 60 % 62 % .61 .072 2 27 % .25 % 73 % 55 % .63 .054 4 29 % .12 % 71 % 72 % .71 .057 4 20 % .13 % 80 % 73 % .76 .041 1 2 5 10 20 40 60 80 90 .01 .02 .05 0.1 0.2 0.5 1 2 5 10 20 40 60 80 90 Miss Probability ( in % ) False Alarm Probability ( in % ) random performance With story pairs ( Japan ) Baseline ( Japan ) Figure 4 : 3 topics concerning to Japan 1 2 5 10 20 40 60 80 90 .01 .02 .05 0.1 0.2 0.5 1 2 5 10 20 40 60 80 90 Miss Probability ( in % ) False Alarm Probability ( in % ) random performance two types of story pairs With only J-E story pairs Without story pairs Figure 5 : With and without story pairs Japanese stories in question , and without story pairs , and ( ii ) the results of story pairs by varying values of N t .</sentence>
				<definiendum id="0">Miss F/A Recall Precision F MIN N t Miss F/A Recall Precision</definiendum>
				<definiendum id="1">Miss F/A Recall Precision F MIN N t Miss F/A Recall Precision F MIN</definiendum>
				<definiens id="0">23 topics ) Baseline Bilingual corpora &amp; clustering N t</definiens>
			</definition>
			<definition id="7">
				<sentence>Y-axis shows the precision which is the ratio of correct term pairs by the system divided by the total number of system’s assignments .</sentence>
				<definiendum id="0">Y-axis</definiendum>
			</definition>
</paper>

		<paper id="1054">
			<definition id="0">
				<sentence>Syntactic parsing is one of the most fundamental tasks in Natural Language Processing ( NLP ) .</sentence>
				<definiendum id="0">Syntactic parsing</definiendum>
			</definition>
			<definition id="1">
				<sentence>Like other deterministic parsers , our parser assumes input has already been segmented and tagged with part-of-speech ( POS ) information during a preprocessing step1 .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">) information during a preprocessing step1</definiens>
			</definition>
			<definition id="2">
				<sentence>A reduce action is in the form of Reduce- { Binary|Unary } X , where { Binary|Unary } denotes whether one or two items are to be removed from the stack , and X is the label of a new tree node that will be dominating the removed items .</sentence>
				<definiendum id="0">reduce action</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">in the form of Reduce- { Binary|Unary } X , where { Binary|Unary } denotes whether one or two items are to be removed from the stack</definiens>
				<definiens id="1">the label of a new tree node that will be dominating the removed items</definiens>
			</definition>
			<definition id="3">
				<sentence>Node ( NR_d_2504_d_3370 ) becomes the head of the new NP node and this information is marked by brackets .</sentence>
				<definiendum id="0">Node</definiendum>
				<definiens id="0">becomes the head of the new NP node and this information is marked by brackets</definiens>
			</definition>
			<definition id="4">
				<sentence>Decision Tree Classifier : Statistical decision tree is a classic machine learning technique that has been extensively applied to NLP .</sentence>
				<definiendum id="0">Decision Tree Classifier</definiendum>
				<definiens id="0">a classic machine learning technique that has been extensively applied to NLP</definiens>
			</definition>
			<definition id="5">
				<sentence>Memory-Based Learning : Memory-Based Learning approaches the classification problem by storing training examples explicitly in memory , and classifying the current case by finding the most similar stored cases ( using k-nearestneighbors ) .</sentence>
				<definiendum id="0">Memory-Based Learning</definiendum>
				<definiens id="0">Memory-Based Learning approaches the classification problem by storing training examples explicitly in memory , and classifying the current case by finding the most similar stored cases ( using k-nearestneighbors )</definiens>
			</definition>
			<definition id="6">
				<sentence>In all our experiments , we used labeled recall ( LR ) , labeled precision ( LP ) and F1 score ( harmonic mean of LR and LP ) as our evaluation metrics .</sentence>
				<definiendum id="0">recall ( LR</definiendum>
				<definiendum id="1">precision</definiendum>
				<definiens id="0">harmonic mean of LR and LP</definiens>
			</definition>
</paper>

		<paper id="1103">
			<definition id="0">
				<sentence>Named Entity recognition ( NER ) is an important part of many natural language processing tasks .</sentence>
				<definiendum id="0">NER</definiendum>
			</definition>
</paper>

		<paper id="1125">
			<definition id="0">
				<sentence>The source channel model ( SCM ) is a successful statistical approach in speech recognition and machine translation ( Brown , 1990 ) .</sentence>
				<definiendum id="0">SCM</definiendum>
			</definition>
			<definition id="1">
				<sentence>In our case , SCM aims to find the character string nii cC , ... ,2,1 } { = = that the given input chat text nji tT , ... ,2,1 } { = = is most probably translated to , i.e. ii ct → , as follows. )</sentence>
				<definiendum id="0">SCM</definiendum>
				<definiens id="0">aims to find the character string nii cC</definiens>
			</definition>
			<definition id="2">
				<sentence>( ) ( ) | ( maxarg ) | ( maxarg ˆ Tp CpCTp TCpC CC == ( 1 ) Since ) ( Tp is a constant for C , so C ˆ should also maximize ) ( ) | ( CpCTp .</sentence>
				<definiendum id="0">Tp</definiendum>
			</definition>
			<definition id="3">
				<sentence>For example , “介 ⎯⎯⎯⎯→⎯ ) 56.0 , , ( jiezhe 这 ” is the phonetic mapping connecting “这 ( this , zhe4 ) ” and “介 ( interrupt , jie4 ) ” , in which “zhe” and “jie” are Chinese Pinyin for “这 ” and “介 ” respectively .</sentence>
				<definiendum id="0">jiezhe 这 ”</definiendum>
				<definiens id="0">the phonetic mapping connecting “这 ( this , zhe4 ) ” and “介 ( interrupt , jie4 ) ” , in which “zhe” and “jie” are Chinese Pinyin for “这 ” and “介 ” respectively</definiens>
			</definition>
			<definition id="4">
				<sentence>The phonetic mapping model is a five-tuple , i.e. &gt; &lt; ) | ( Pr ) , ( ) , ( , , CTCptTptCT pm , which comprises of chat term character T , standard counterpart character C , phonetic transcription of T and C , i.e. ) ( Tpt and ) ( Cpt , and the mapping probability ) | ( Pr CT pm that T is mapped to C via the phonetic mapping ( ) CT CTCptTpt pm ⎯⎯⎯⎯⎯⎯⎯→⎯ ) | ( Pr ) , ( ) , ( ( hereafter briefed by CT M ⎯→⎯ ) .</sentence>
				<definiendum id="0">phonetic mapping model</definiendum>
				<definiendum id="1">CTCptTptCT pm</definiendum>
				<definiens id="0">comprises of chat term character T , standard counterpart character C , phonetic transcription of T and C</definiens>
			</definition>
			<definition id="5">
				<sentence>It is a three-tuple , i.e. &gt; &lt; ) | ( Pr , , CTCT cm , which comprises of chat term character T , standard counterpart character C and the mapping probability ) | ( Pr CT cm that T is mapped to C via this character mapping .</sentence>
				<definiendum id="0">CTCT cm</definiendum>
				<definiens id="0">comprises of chat term character T , standard counterpart character C and the mapping probability ) | ( Pr CT cm that T is mapped to C via this character mapping</definiens>
			</definition>
			<definition id="6">
				<sentence>Test Sets Test sets are used to prove that chat language is dynamic and XSCM is effective and robust in normalizing dynamic chat language terms .</sentence>
				<definiendum id="0">Test Sets Test sets</definiendum>
				<definiendum id="1">XSCM</definiendum>
				<definiens id="0">used to prove that chat language is dynamic and</definiens>
			</definition>
			<definition id="7">
				<sentence>2 rp rp f zx x r yx x p + ×× = + = + = ( 7 ) where x denotes the number of true positives , y the false positives and z the true negatives .</sentence>
				<definiendum id="0">rp rp f zx x r yx</definiendum>
				<definiendum id="1">x</definiendum>
				<definiens id="0">the number of true positives , y the false positives and z the true negatives</definiens>
			</definition>
			<definition id="8">
				<sentence>So extending the chat language corpus should be one choice to improve quality of chat language term normalization .</sentence>
				<definiendum id="0">chat language corpus</definiendum>
				<definiens id="0">choice to improve quality of chat language term normalization</definiens>
			</definition>
</paper>

		<paper id="2003">
			<definition id="0">
				<sentence>QUEENa86a11a87a89a88 is defined as the probability , over a85a91a90a60a85a92a90a60a85 , that for every metric a93 in a given metric set a94 the automatic translation a87 is more similar to a human reference than two other references to each other : QUEENa95a97a96a98a97a86a11a87a81a88a100a99 a101 a86a103a102a13a93a19a104a18a94a79a105a46a93a9a86a11a87a13a106a57a107a61a88a109a108a56a93a110a86a35a107a47a111a35a106a57a107a112a111a111a113a88a57a88 where a87 is the automatic translation being evaluated , a114a35a107a47a106a57a107 a111 a106a57a107 a111a111a103a115 are three different human references in a85 , and a93a9a86a11a87a13a106a57a107a61a88 stands for the similarity of a107 to a87 .</sentence>
				<definiendum id="0">QUEENa86a11a87a89a88</definiendum>
				<definiendum id="1">a87</definiendum>
				<definiens id="0">the probability , over a85a91a90a60a85a92a90a60a85 , that for every metric a93 in a given metric set a94 the automatic translation</definiens>
			</definition>
</paper>

		<paper id="2095">
			<definition id="0">
				<sentence>TF consists of similarity classes produced for all translations : S ( T ( S ( s0 ) ) ) .</sentence>
				<definiendum id="0">TF</definiendum>
				<definiens id="0">consists of similarity classes produced for all translations : S ( T ( S ( s0 ) ) )</definiens>
			</definition>
			<definition id="1">
				<sentence>The number of elements in the set of theoretically possible combinations is usually very large : producttext Ti , where Ti is the number of words in the translation class of each word of the original MWE .</sentence>
				<definiendum id="0">Ti</definiendum>
				<definiens id="0">the number of words in the translation class of each word of the original MWE</definiens>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>A successful dialog system relies on the synergistic working of several components : speech recognition ( ASR ) , spoken language understanding ( SLU ) , dialog management ( DM ) , language generation ( LG ) and text-to-speech synthesis ( TTS ) .</sentence>
				<definiendum id="0">text-to-speech synthesis ( TTS</definiendum>
				<definiens id="0">speech recognition ( ASR ) , spoken language understanding ( SLU ) , dialog management ( DM ) , language generation</definiens>
			</definition>
			<definition id="1">
				<sentence>Several disambiguation methods ( n-gram models , hidden Markov models , maximum entropy models ) that include a variety of features ( cue phrases , speaker ID , word n-grams , prosodic features , syntactic features , dialog history ) have been used .</sentence>
				<definiendum id="0">Several disambiguation methods ( n-gram models</definiendum>
				<definiendum id="1">maximum entropy models</definiendum>
				<definiens id="0">include a variety of features ( cue phrases , speaker ID , word n-grams</definiens>
			</definition>
			<definition id="2">
				<sentence>Most recently , Henderson et al. showed that it is possible to automatically learn good dialog management strategies from automatically labeled data over a large potential space of dialog states ( Henderson et al. , 2005 ) ; and Frampton and Lemon showed that the use of context information ( the user’s last dialog act ) can improve the performance of learned strategies ( Frampton and Lemon , 2005 ) .</sentence>
				<definiendum id="0">dialog states</definiendum>
				<definiens id="0">the user’s last dialog act</definiens>
			</definition>
			<definition id="3">
				<sentence>However , in order to cope with the prediction errors of the classi er , we approximate a74a51a18a77a76 a28 with an a80 -gram language model on sequences of the re ned tag labels : a38a58a39 a41 a81 a43a82a44a47a46a83a48a47a50a75a44a15a52 a53a9a54a49a84 a53a9a54a83a84a49a85a9a86a13a87a89a88a91a90 a55a57a56 a38a40a39 a81 a59a60a42a61 ( 2 ) a92 a44a47a46a83a48a47a50a75a44a15a52 a53a9a54 a84 a53a9a54a83a84a49a85a9a86a13a87a89a88a91a90 a93 a94a96a95 a55a57a56a98a97a66a99 a95 a59a100a27a61 ( 3 ) In order to estimate the conditional distribution a101 a18a20a19a15a21 a1 a68 a72 a28 we use the general technique of choosing the maximum entropy ( maxent ) distribution that properly estimates the average of each feature over the training data ( Berger et al. , 1996 ) .</sentence>
				<definiendum id="0">maximum entropy</definiendum>
			</definition>
			<definition id="4">
				<sentence>This can be written as a Gibbs distribution parameterized with weights a102 , where a103 is the size of the label set .</sentence>
				<definiendum id="0">a103</definiendum>
				<definiens id="0">the size of the label set</definiens>
			</definition>
			<definition id="5">
				<sentence>For each dialog we then created a80 -best sequences ( 100-best for these experiments ) of subtask labels ; these were parsed and ( re- ) ranked by the parser.3 We combine the weights of the subtask label sequences assigned by the classi er with the parse score assigned by the parser and select the top 3Ideally , we would have parsed the subtask label lattice directly , however , the parser has to be reimplemented to parse such lattice inputs .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">has to be reimplemented to parse such lattice inputs</definiens>
			</definition>
</paper>

		<paper id="1109">
			<definition id="0">
				<sentence>NNS VBD Investors suffered X X S VBD suffered X X NNS NNS Investors losses X X S JJ NNS heavy losses XX S JJ NNS heavy losses X NNS VBD Investors suffered X VBD JJ suffered heavy X Figure 5 .</sentence>
				<definiendum id="0">NNS VBD</definiendum>
			</definition>
			<definition id="1">
				<sentence>The EM algorithm for this ML-DOP model is related to the Inside-Outside algorithm for context-free grammars , but the reestimation formula is complicated by the presence of subtrees of depth greater than 1 .</sentence>
				<definiendum id="0">EM algorithm</definiendum>
				<definiens id="0">context-free grammars , but the reestimation formula is complicated by the presence of subtrees of depth greater than 1</definiens>
			</definition>
			<definition id="2">
				<sentence>The update formula for the count of a subtree t is ( where r ( t ) is the root label of t ) : 868 ct ( t ) = Σ β ( st ) α ( st ) P ( t | r ( t ) ) f b α ( sgoal ) st : ∃st , tb°t=tf b f The updated probability distribution , P ' ( t | r ( t ) ) , is defined to be P ' ( t | r ( t ) ) = ct ( t ) ct ( r ( t ) ) where ct ( r ( t ) ) is defined as ct ( r ( t ) ) = Σ ct ( t ' ) t ' : r ( t ' ) =r ( t ) In practice , ML-DOP starts out by assigning the same relative frequencies to the subtrees as DOP1 , which are next reestimated by the formulas above .</sentence>
				<definiendum id="0">update formula</definiendum>
				<definiendum id="1">r ( t )</definiendum>
				<definiendum id="2">)</definiendum>
				<definiendum id="3">ct ( r</definiendum>
				<definiens id="0">the root label of t ) : 868 ct ( t ) = Σ β ( st ) α ( st ) P ( t | r ( t ) ) f b α ( sgoal ) st : ∃st , tb°t=tf b f The updated probability distribution , P ' ( t | r ( t ) ) , is defined to be P ' ( t | r ( t ) ) = ct ( t ) ct ( r ( t ) ) where ct ( r ( t )</definiens>
				<definiens id="1">ML-DOP starts out by assigning the same relative frequencies to the subtrees as DOP1 , which are next reestimated by the formulas above</definiens>
			</definition>
			<definition id="3">
				<sentence>To avoid overtraining , ML-DOP uses the subtrees from one half of the training set to be trained on the other half , and vice versa .</sentence>
				<definiendum id="0">ML-DOP</definiendum>
				<definiens id="0">uses the subtrees from one half of the training set to be trained on the other half , and vice versa</definiens>
			</definition>
			<definition id="4">
				<sentence>5 UML-DOP Analogous to U-DOP , UML-DOP is an unsupervised generalization of ML-DOP : it first assigns all unlabeled binary trees to a set of sentences and next extracts a large ( random ) set of subtrees from this tree set .</sentence>
				<definiendum id="0">UML-DOP</definiendum>
				<definiens id="0">an unsupervised generalization of ML-DOP : it first assigns all unlabeled binary trees to a set of sentences and next extracts a large ( random ) set of subtrees from this tree set</definiens>
			</definition>
			<definition id="5">
				<sentence>To compare UML-DOP to U-DOP , we started out with the WSJ10 corpus , which contains 7422 sentences ≤ 10 words after removing empty elements and punctuation .</sentence>
				<definiendum id="0">WSJ10 corpus</definiendum>
				<definiens id="0">contains 7422 sentences ≤ 10 words after removing empty elements and punctuation</definiens>
			</definition>
			<definition id="6">
				<sentence>The two metrics of UP and UR are combined by the unlabeled f score F1 which is defined as the harmonic mean of UP and UR : F1 = 2*UP*UR/ ( UP+UR ) .</sentence>
				<definiendum id="0">unlabeled f score F1</definiendum>
				<definiens id="0">the harmonic mean of UP and UR</definiens>
			</definition>
</paper>

		<paper id="2014">
			<definition id="0">
				<sentence>Crossings occur when the projections of two disjoint phrases overlap .</sentence>
				<definiendum id="0">Crossings</definiendum>
				<definiens id="0">occur when the projections of two disjoint phrases overlap</definiens>
			</definition>
			<definition id="1">
				<sentence>ITGs perform string-to-string alignment , but do so through a parsing algorithm that will allow us to inform the objective function of our dependency tree .</sentence>
				<definiendum id="0">ITGs</definiendum>
				<definiens id="0">perform string-to-string alignment , but do so through a parsing algorithm that will allow us to inform the objective function of our dependency tree</definiens>
			</definition>
			<definition id="2">
				<sentence>We also assume that our Ψ ( x , y ) decomposes in such a way that the features can guide a search to recover the structure y from x. That is : struct ( x ; vectorw ) = argmaxy∈Y〈vectorw , Ψ ( x , y ) 〉 ( 1 ) is computable , where Y is the set of all possible structures , and vectorw is a vector that assigns weights to each component of Ψ ( x , y ) .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiendum id="1">vectorw</definiendum>
				<definiens id="0">the set of all possible structures</definiens>
				<definiens id="1">a vector that assigns weights to each component of Ψ ( x , y )</definiens>
			</definition>
			<definition id="3">
				<sentence>Our required components are as follows : of production rules , r. Ψ is a function of the decomposition specified by y : Ψ ( x , y ) =summationtext r∈yψT ( r ) .</sentence>
				<definiendum id="0">r. Ψ</definiendum>
				<definiens id="0">of production rules</definiens>
				<definiens id="1">a function of the decomposition specified by y : Ψ ( x , y ) =summationtext r∈yψT</definiens>
			</definition>
			<definition id="4">
				<sentence>They maximize summed link values v ( l ) , where v ( l ) is defined as follows for an l = ( Ej , Fk ) : v ( l ) = φ2 ( Ej , Fk ) −10−5abs parenleftbigg j |E|− k |F| parenrightbigg All three aligners link based on φ2 correlation scores , breaking ties in favor of closer pairs .</sentence>
				<definiendum id="0">v</definiendum>
			</definition>
			<definition id="5">
				<sentence>The ITG is the bottleneck , so training time could be improved by optimizing the parser .</sentence>
				<definiendum id="0">ITG</definiendum>
				<definiens id="0">the bottleneck , so training time</definiens>
			</definition>
</paper>

		<paper id="2119">
			<definition id="0">
				<sentence>semantic similarity Sussna ( 1993 ) utilized the semantic network of nouns in WordNet to disambiguate term senses to improve the precision of SMART information retrieval at the stage of indexing , in which he assigned two different weights for both directions of edges in the network to compute the similarity of two nodes .</sentence>
				<definiendum id="0">retrieval</definiendum>
				<definiens id="0">utilized the semantic network of nouns in WordNet to disambiguate term senses to improve the precision of SMART information</definiens>
			</definition>
			<definition id="1">
				<sentence>WordNet ( Fellbaum , 1998 ) provides a finegrained enumerative semantic net that is commonly used to tag the instances of English target words in the tasks of SENSEVAL with different senses ( WordNet synset numbers ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">provides a finegrained enumerative semantic net that is commonly used to tag the instances of English target words in the tasks of SENSEVAL with different senses</definiens>
			</definition>
			<definition id="2">
				<sentence>The Edinburgh Association Thesaurus 2 ( EAT ) provides an associative network to account for word relationship in human cognition after collecting the first response words for the stimulus words list ( Kiss et al. , 1973 ) .</sentence>
				<definiendum id="0">EAT )</definiendum>
			</definition>
</paper>

		<paper id="1139">
			<definition id="0">
				<sentence>For example , if a5a95a6 a62a28a63a19a64a68a18a48a96 a37a98a97 a21 , a99 a64a101a100a94a102a17a103a32a104a106a105a39a107a108a45a109a111a110a112a104a106a105a39a107a110a41a113 , its semantics is a probability distribution a9a13a10a11a12a15a14a41a16a82a18a20a5a22a21 over a25a28a27a30a29 a31 a6a106a43a45a96 a37a98a97 a46 , defined by a114a68a115a68a116a117a119a118a88a120a122a121a124a123a119a120a88a125a41a123 a100 a99 a64 a120a103 a123 a100 a105a39a107a108 and a114 a115a73a116a117a126a118a120a122a121a124a123a119a120a128a127a65a123 a100 a99 a64 a120 a110 a123 a100a4a105a39a107a110 .</sentence>
				<definiendum id="0">semantics</definiendum>
			</definition>
			<definition id="1">
				<sentence>Its semantics is a probability distribution a9a124a10a13a12a15a14a17a16a82a18a20a5a22a21a4a23 a25a28a27a30a29a32a31a83a33 a35a36a30a37a39a38a41a40 , where a25a28a27a30a29a133a31 is the set of all strings that obey the precedence imposed over the arguments , and the probability values are induced by a9a47a10a13a12a15a14a17a16a48a18a20a5a134a55a41a21 and a9a47a10a13a12a15a14a17a16a82a18a20a5a66a129a45a21 .</sentence>
				<definiendum id="0">a25a28a27a30a29a133a31</definiendum>
				<definiens id="0">the set of all strings that obey the precedence imposed over the arguments , and the probability values are induced by a9a47a10a13a12a15a14a17a16a48a18a20a5a134a55a41a21 and a9a47a10a13a12a15a14a17a16a82a18a20a5a66a129a45a21</definiens>
			</definition>
			<definition id="2">
				<sentence>WIDL-expressions with Language Models Algorithm WIDL-NGLM-Aa86 ( Figure 3 ) solves the search problem defined by Equation 2 for a WIDL-expression a5 ( which provides feature function a62 a67 ) and a87 a0 -gram language models ( which provide feature functions a62a167a55 a37a53a57a53a57a53a57a58a37 a62 a63 a21 .</sentence>
				<definiendum id="0">WIDL-expression a5</definiendum>
				<definiens id="0">provides feature function a62 a67 ) and a87 a0 -gram language models ( which provide feature functions a62a167a55 a37a53a57a53a57a53a57a58a37 a62 a63 a21</definiens>
			</definition>
			<definition id="3">
				<sentence>Additionally , EVALUATE uses an admissible heuristic function to compute future ( admissible ) scores for the a98a73a99a92a101a71a102a108a103a107a104 states .</sentence>
				<definiendum id="0">EVALUATE</definiendum>
			</definition>
			<definition id="4">
				<sentence>We also employ a word-count model ( which counts the number of words in a proposed realization ) and a phrase-count model ( which counts the number of phrases in a proposed realization ) , which allow us to learn to produce headlines that have restrictions in the number of words allowed ( 10 , in our case ) .</sentence>
				<definiendum id="0">word-count model</definiendum>
				<definiens id="0">counts the number of words in a proposed realization ) and a phrase-count model ( which counts the number of phrases in a proposed realization )</definiens>
			</definition>
			<definition id="5">
				<sentence>For the extractive algorithms , Lead10 is a baseline which simply proposes as headline the lead sentence , cut after the first 10 words .</sentence>
				<definiendum id="0">Lead10</definiendum>
				<definiens id="0">a baseline which simply proposes as headline the lead sentence</definiens>
			</definition>
			<definition id="6">
				<sentence>For the abstractive algorithms , Keywords is a baseline that proposes as headline the sequence of topic keywords , Webcl is the system THREE GORGES PROJECT IN CHINA HAS WON APPROVAL WATER IS LINK BETWEEN CLUSTER OF E. COLI CASES SRI LANKA ’S JOINT VENTURE TO EXPAND EXPORTS OPPOSITION TO EUROPEAN UNION SINGLE CURRENCY EURO OF INDIA AND BANGLADESH WATER BARRAGE Figure 5 : Headlines generated automatically using a WIDL-based sentence realization system .</sentence>
				<definiendum id="0">Keywords</definiendum>
				<definiendum id="1">Webcl</definiendum>
				<definiens id="0">a baseline that proposes as headline the sequence of topic keywords</definiens>
				<definiens id="1">the system THREE GORGES PROJECT IN CHINA HAS WON APPROVAL WATER IS LINK BETWEEN CLUSTER OF E. COLI CASES SRI LANKA ’S JOINT VENTURE TO EXPAND EXPORTS OPPOSITION TO EUROPEAN UNION SINGLE CURRENCY EURO OF INDIA AND BANGLADESH WATER BARRAGE Figure 5 : Headlines generated automatically using a WIDL-based sentence realization system</definiens>
			</definition>
			<definition id="7">
				<sentence>Matador : A large-scale SpanishEnglish GHMT system .</sentence>
				<definiendum id="0">Matador</definiendum>
			</definition>
			<definition id="8">
				<sentence>Pharaoh : a beam search decoder for phrase-based statistical machine transltion models .</sentence>
				<definiendum id="0">Pharaoh</definiendum>
				<definiens id="0">a beam search decoder for phrase-based statistical machine transltion models</definiens>
			</definition>
</paper>

		<paper id="2065">
			<definition id="0">
				<sentence>We then set up a uniform P ( c | p ) , which also happens to be a 499 ( a ) ingcmpnqsnwf cv fpn owoktvcv hu ihgzsnwfv rqcffnw cw owgcnwf kowazoanv ... ( b ) wecitherkent is the analysis of wocoments pritten in ancient buncquges ... ( c ) decipherment is the analysis of documents written in ancient languages ... Figure 3 : Letter substitution decipherment .</sentence>
				<definiendum id="0">wecitherkent</definiendum>
				<definiendum id="1">c ) decipherment</definiendum>
				<definiens id="0">c | p ) , which also happens to be a 499 ( a ) ingcmpnqsnwf cv fpn owoktvcv hu ihgzsnwfv rqcffnw cw owgcnwf kowazoanv ... ( b )</definiens>
			</definition>
			<definition id="1">
				<sentence>Our ciphertext c is a stream of bytes in an unknown encoding , with space separators ; we use integers to represent these bytes , as in Figure 5 ( a ) .</sentence>
				<definiendum id="0">ciphertext c</definiendum>
				<definiens id="0">a stream of bytes in an unknown encoding , with space separators</definiens>
			</definition>
			<definition id="2">
				<sentence>UTF8 builds complex Hindi character chunks out of up to 3 simple and combining characters .</sentence>
				<definiendum id="0">UTF8</definiendum>
				<definiens id="0">builds complex Hindi character chunks out of up to 3 simple and combining characters</definiens>
			</definition>
			<definition id="3">
				<sentence>A Hindi word is a sequence of chunks , and words are separated by spaces .</sentence>
				<definiendum id="0">Hindi word</definiendum>
				<definiens id="0">a sequence of chunks , and words are separated by spaces</definiens>
			</definition>
			<definition id="4">
				<sentence>The labeled portion of our ciphertext consists of 59 running words ( 281 ciphertext bytes and 201 UTF8 characters ) .</sentence>
				<definiendum id="0">ciphertext</definiendum>
				<definiens id="0">consists of 59 running words ( 281 ciphertext bytes and 201 UTF8 characters )</definiens>
			</definition>
			<definition id="5">
				<sentence>Here we show the sound and character inventories : Sounds : B , D , G , J ( ny as in canyon ) , L ( y as in yarn ) , T ( th as in thin ) , a , b , d , e , f , g , i , k , l , m , n , o , p , r , rr ( trilled ) , s , t , tS ( ch as in chin ) , u , x ( h as in hat ) 502 ( a ) primera parte del ingenioso hidalgo don quijote de la mancha ( b ) primera parte des intenioso liDasto don fuiLote de la manTia ( c ) primera parte del inGenioso biDalGo don fuiLote de la manTia ( d ) primera parte del inxenioso iDalGo don kixote de la manSa * Figure 7 : Phonetic decipherment .</sentence>
				<definiendum id="0">tS</definiendum>
				<definiendum id="1">inGenioso biDalGo don fuiLote</definiendum>
				<definiens id="0">the sound and character inventories : Sounds : B , D , G , J ( ny as in canyon )</definiens>
				<definiens id="1">l , m , n , o , p , r</definiens>
			</definition>
			<definition id="6">
				<sentence>( b ) is an unsupervised consonant-vowel decipherment , ( c ) is a decipherment informed by syllable structure , ( d ) is an improved decipherment , and ( e ) is a decipherment that also attempts to distinguish sonorous ( S ) and non-sonorous ( N ) consonants .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiens id="0">an unsupervised consonant-vowel decipherment</definiens>
				<definiens id="1">a decipherment that also attempts to distinguish sonorous ( S</definiens>
			</definition>
			<definition id="7">
				<sentence>A universal tendency ( the sonority hierarchy ) is that syllables have a sonority peak in the middle , which falls off to the left and right .</sentence>
				<definiendum id="0">universal tendency</definiendum>
				<definiens id="0">falls off to the left and right</definiens>
			</definition>
</paper>

		<paper id="2068">
			<definition id="0">
				<sentence>In contrast to factoid questions , which can be answered by short phrases found within an individual document , there is a large class of questions whose answers require synthesis of information from multiple sources .</sentence>
				<definiendum id="0">factoid questions</definiendum>
				<definiens id="0">class of questions whose answers require synthesis of information from multiple sources</definiens>
			</definition>
			<definition id="1">
				<sentence>vital Raul Castro was formally designated his brother’s successor vital Raul is the head of the Armed Forces okay Raul is five years younger than Castro okay Raul has enjoyed a more public role in running Cuba’s Government .</sentence>
				<definiendum id="0">Raul</definiendum>
				<definiens id="0">the head of the Armed Forces okay</definiens>
			</definition>
			<definition id="2">
				<sentence>Answers consist of units of information called “nuggets” , which assessors manually create from system submissions and their own research ( see example in Figure 1 ) .</sentence>
				<definiendum id="0">Answers</definiendum>
			</definition>
			<definition id="3">
				<sentence>We measured Mean Average Precision ( MAP ) , the most informative single-point metric for ranked retrieval , and recall , since it places an upper bound on the number of relevant documents available for subsequent downstream processing .</sentence>
				<definiendum id="0">Mean Average Precision</definiendum>
				<definiens id="0">the most informative single-point metric for ranked retrieval</definiens>
			</definition>
			<definition id="4">
				<sentence>For sentence-based features , we experimented with the following : • Passage match score , which sums the idf values of unique terms that appear in both the candidate sentence ( S ) and the question ( Q ) : summationdisplay t∈S∩Q idf ( t ) • Term idf precision and recall scores ; cf. ( Katz et al. , 2005 ) : P = summationtext t∈S∩Q idf ( t ) summationtext t∈A idf ( t ) , R = summationtext t∈S∩Q idf ( t ) summationtext t∈Q idf ( t ) • Length of the sentence ( in non-whitespace characters ) .</sentence>
				<definiendum id="0">R = summationtext t∈S∩Q idf</definiendum>
				<definiendum id="1">t∈Q idf</definiendum>
				<definiens id="0">sums the idf values of unique terms that appear in both the candidate sentence ( S ) and the question ( Q ) : summationdisplay t∈S∩Q idf ( t ) • Term idf precision and recall scores ; cf. ( Katz et al. , 2005 ) : P = summationtext t∈S∩Q idf ( t ) summationtext t∈A idf ( t ) ,</definiens>
			</definition>
			<definition id="5">
				<sentence>Instead of selecting sentences for inclusion in the answer based on relevance alone , we implemented a simple utility model , which takes into account sentences that have already been added to the answer A. For each candidate c , utility is defined as follows : Utility ( c ) = Relevance ( c ) −λmax s∈A sim ( s , c ) This model is the baseline variant of the Maximal Marginal Relevance method for summarization ( Goldstein et al. , 2000 ) .</sentence>
				<definiendum id="0">simple utility model</definiendum>
				<definiendum id="1">c ) −λmax s∈A sim</definiendum>
				<definiendum id="2">c ) This model</definiendum>
				<definiens id="0">takes into account sentences that have already been added to the answer A. For each candidate c , utility is defined as follows : Utility ( c ) = Relevance (</definiens>
			</definition>
			<definition id="6">
				<sentence>The current setup of the task , where answers consist of unordered strings , does not place any value on coherence and readability of the responses , which will be important if the answers are intended for human consumption .</sentence>
				<definiendum id="0">answers</definiendum>
				<definiens id="0">consist of unordered strings , does not place any value on coherence and readability of the responses , which will be important if the answers are intended for human consumption</definiens>
			</definition>
</paper>

		<paper id="1143">
			<definition id="0">
				<sentence>Punjabi Machine Transliteration ( PMT ) is a special case of machine transliteration and is a process of converting a word from Shahmukhi ( based on Arabic script ) to Gurmukhi ( derivation of Landa , Shardha and Takri , old scripts of Indian subcontinent ) , two scripts of Punjabi , irrespective of the type of word .</sentence>
				<definiendum id="0">PMT</definiendum>
				<definiens id="0">a special case of machine transliteration and is a process of converting a word from Shahmukhi ( based on Arabic script ) to Gurmukhi ( derivation of Landa , Shardha and Takri , old scripts of Indian subcontinent ) , two scripts of Punjabi , irrespective of the type of word</definiens>
			</definition>
			<definition id="1">
				<sentence>Punjabi is the mother tongue of more than 110 million people of Pakistan ( 66 million ) , India ( 44 million ) and many millions in America , Canada and Europe .</sentence>
				<definiendum id="0">Punjabi</definiendum>
			</definition>
			<definition id="2">
				<sentence>PMT is a special kind of machine transliteration .</sentence>
				<definiendum id="0">PMT</definiendum>
			</definition>
			<definition id="3">
				<sentence>PMT is a special type of Machine Transliteration in which a word is transliterated across two different writing systems used for the same language .</sentence>
				<definiendum id="0">PMT</definiendum>
				<definiens id="0">a special type of Machine Transliteration in which a word is transliterated across two different writing systems used for the same language</definiens>
			</definition>
			<definition id="4">
				<sentence>A sentence illustrating Shahmukhi is given below : X } Z Ìáââ y6– ÌÐâ &lt; ڻ 6– ~ @ null ð ÌÌ6=null P It has 49 consonants , 16 diacritical marks and 16 vowels , etc. ( Malik 2005 ) Gurmukhi derives its character set from old scripts of the Indian Sub-continent i.e. Landa ( script of North West ) , Sharda ( script of Kashmir ) and Takri ( script of western Himalaya ) .</sentence>
				<definiendum id="0">sentence illustrating Shahmukhi</definiendum>
				<definiendum id="1">Sub-continent i.e. Landa</definiendum>
				<definiens id="0">49 consonants , 16 diacritical marks and 16 vowels , etc. ( Malik 2005 ) Gurmukhi derives its character set from old scripts of the Indian</definiens>
			</definition>
			<definition id="5">
				<sentence>PMT is an endeavor to bridge the ethnical , cultural and geographical divisions between the Punjabi speaking communities .</sentence>
				<definiendum id="0">PMT</definiendum>
				<definiens id="0">an endeavor to bridge the ethnical , cultural and geographical divisions between the Punjabi speaking communities</definiens>
			</definition>
</paper>

		<paper id="2038">
			<definition id="0">
				<sentence>Chart parsing is a method of building a parse tree that systematically explores combinations based on a set of grammatical rules , while using a chart to store partial results .</sentence>
				<definiendum id="0">Chart parsing</definiendum>
				<definiens id="0">a method of building a parse tree that systematically explores combinations based on a set of grammatical rules , while using a chart to store partial results</definiens>
			</definition>
			<definition id="1">
				<sentence>The CYK algorithm considers all possible combinations .</sentence>
				<definiendum id="0">CYK algorithm</definiendum>
				<definiens id="0">considers all possible combinations</definiens>
			</definition>
			<definition id="2">
				<sentence>Syntactic Chunking is the partial parsing process of segmenting a sentence into non295 ( 1,5 ) ( 1,4 ) ( 2,5 ) ( 1,3 ) ( 2,4 ) ( 3,5 ) ( 1,2 ) ( 2,3 ) ( 3,4 ) ( 4,5 ) ( 1,1 ) ( 2,2 ) ( 3,3 ) ( 4,4 ) ( 5,5 ) red balloon flew awayThe Figure 1 : The CYK parse visualized as a pyramid .</sentence>
				<definiendum id="0">Syntactic Chunking</definiendum>
				<definiens id="0">the partial parsing process of segmenting a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>First , we de ne a span to be a pair c = ( s , t ) , where s is the index of the rst word in the span and t is the index of the last word in the span .</sentence>
				<definiendum id="0">t</definiendum>
				<definiens id="0">the index of the rst word in the span and</definiens>
			</definition>
			<definition id="4">
				<sentence>We say that c1 and c2 overlap iff s1 &lt; s2 t1 &lt; t2 or s2 &lt; s1 t2 &lt; t1 , and we note it as c1 c2.2 When using the output of a chunker , S is the set of spans that describe the non-VP , non-PP chunks where ti si &gt; 0 .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">the set of spans that describe the non-VP , non-PP chunks where ti si &gt; 0</definiens>
			</definition>
</paper>

		<paper id="3009">
			<definition id="0">
				<sentence>Speci cally , Semitic languages demonstrate strong interaction between morphological and syntactic processing , which limits the applicability of standard tools for , e.g. , parsing .</sentence>
				<definiendum id="0">Semitic languages</definiendum>
				<definiens id="0">limits the applicability of standard tools for , e.g. , parsing</definiens>
			</definition>
			<definition id="1">
				<sentence>A MH word may coincide with a single constituent , as in ‘ica’3 ( go out ) , it may overlap with an entire phrase , as in ‘h ild’ ( the boy ) , or it may span across phrases as in ‘w kf m h bit’ ( and when from the house ) .</sentence>
				<definiendum id="0">MH word</definiendum>
				<definiendum id="1">entire phrase</definiendum>
				<definiens id="0">the boy ) , or it may span across phrases as in ‘w kf m h bit’</definiens>
			</definition>
			<definition id="2">
				<sentence>Derivational morphology is a non-concatenative process in which verbs , nouns , and adjectives are derived from ( tri- ) consonantal roots plugged into templates of consonant/vowel skeletons .</sentence>
				<definiendum id="0">Derivational morphology</definiendum>
				<definiens id="0">a non-concatenative process in which verbs , nouns , and adjectives</definiens>
			</definition>
			<definition id="3">
				<sentence>Formally , we de ne the task as ( 1 ) , where seg ( wm1 ) is the set of segmentations resulting from all possible morphological analyses of wn1 .</sentence>
				<definiendum id="0">seg</definiendum>
				<definiens id="0">the set of segmentations resulting from all possible morphological analyses of wn1</definiens>
			</definition>
			<definition id="4">
				<sentence>Out of vocabulary ( OOV ) words are treated by the morphological analyzer , which proposes all possible segmentations assuming that the stem is a proper noun .</sentence>
				<definiendum id="0">morphological analyzer</definiendum>
				<definiens id="0">proposes all possible segmentations assuming that the stem is a proper noun</definiens>
			</definition>
			<definition id="5">
				<sentence>11We further developed a third model , Model III , which is a more faithful approximation , yet computationally affordable , of equation ( 9 ) .</sentence>
				<definiendum id="0">Model III</definiendum>
			</definition>
</paper>

		<paper id="2072">
			<definition id="0">
				<sentence>In the example above triste ( sad ) denotes an accidental property , but in an expression like um livro triste ( a sad book ) it denotes a permanent property .</sentence>
				<definiendum id="0">sad )</definiendum>
				<definiens id="0">an accidental property , but in an expression like um livro triste ( a sad book ) it denotes a permanent property</definiens>
			</definition>
			<definition id="1">
				<sentence>roWordNet Hyponymy is the main structuring relation both in WordNet and in EuroWordNet .</sentence>
				<definiendum id="0">roWordNet Hyponymy</definiendum>
				<definiens id="0">the main structuring relation both in WordNet and in EuroWordNet</definiens>
			</definition>
			<definition id="2">
				<sentence>The SIMPLE project addresses the semantics of adjectives in a similar way , identifying a set of common features relevant for classifying and describing adjective behavior .</sentence>
				<definiendum id="0">SIMPLE project</definiendum>
				<definiens id="0">addresses the semantics of adjectives in a similar way , identifying a set of common features relevant for classifying and describing adjective behavior</definiens>
			</definition>
			<definition id="3">
				<sentence>However , extending wordnets to all the main POS involves a revision of certain commonly used relations and the specification of several cross-POS relations .</sentence>
				<definiendum id="0">main POS</definiendum>
				<definiens id="0">involves a revision of certain commonly used relations and the specification of several cross-POS relations</definiens>
			</definition>
			<definition id="4">
				<sentence>and Grammar : an Introduction to Semantics , Cambridge , MA : The MIT Press .</sentence>
				<definiendum id="0">Grammar</definiendum>
			</definition>
			<definition id="5">
				<sentence>EuroWordNet : A Multilingual Database with Lexical Semantic Networks .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
			</definition>
			<definition id="6">
				<sentence>Portuguese WordNet : general architecture and internal semantic relations .</sentence>
				<definiendum id="0">Portuguese WordNet</definiendum>
				<definiens id="0">general architecture and internal semantic relations</definiens>
			</definition>
			<definition id="7">
				<sentence>WordNet : an on-line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="8">
				<sentence>WordNet : an electronic lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">an electronic lexical database</definiens>
			</definition>
			<definition id="9">
				<sentence>EuroWordNet : A Multilingual Database with Lexical Semantic Networks , Dordrecht : Kluwer Academic Publishers .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
				<definiens id="0">A Multilingual Database with Lexical Semantic Networks , Dordrecht : Kluwer Academic Publishers</definiens>
			</definition>
</paper>

		<paper id="1111">
			<definition id="0">
				<sentence>The PCFG rules were of the following forms : • X → Y Z , for nonterminal types X , Y , and Z , with Y negationslash= X or Z negationslash= X • X → t Y , X → Y t , for each terminal t • X → t tprime , for terminals t and tprime For a given sentence S , our CFG generates labeled trees T over S.2 Each tree consists of binary 1Incaseswheremultiplegoldlabelsexistinthegoldtrees , precision and recall were calculated as in Collins ( 1999 ) .</sentence>
				<definiendum id="0">PCFG rules</definiendum>
				<definiens id="0">were of the following forms : • X → Y Z , for nonterminal types X , Y , and Z , with Y negationslash= X or Z negationslash= X • X → t Y , X → Y t , for each terminal t • X → t tprime , for terminals t and tprime For a given sentence S , our CFG generates labeled trees T over S.2 Each tree consists of binary 1Incaseswheremultiplegoldlabelsexistinthegoldtrees , precision</definiens>
			</definition>
			<definition id="1">
				<sentence>productions X ( i , j ) → α over constituent spans ( i , j ) , where α is a pair of non-terminal and/or terminal symbols in the grammar .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">a pair of non-terminal and/or terminal symbols in the grammar</definiens>
			</definition>
			<definition id="2">
				<sentence>The generative probability of a tree T for S is : PCFG ( T , S ) = productdisplay X ( i , j ) →α∈T P ( α|X ) In the inside-outside algorithm , we iteratively compute posterior expectations over production occurences at each training span , then use those expectations to re-estimate production probabilities .</sentence>
				<definiendum id="0">generative probability</definiendum>
				<definiens id="0">posterior expectations over production occurences at each training span</definiens>
			</definition>
			<definition id="3">
				<sentence>For a given sentence S , the CCM generates a bracket matrix , B , which for each span ( i , j ) , indicates whether or not it is a constituent ( Bij = c ) or a distituent ( Bij = d ) .</sentence>
				<definiendum id="0">CCM</definiendum>
				<definiens id="0">generates a bracket matrix , B , which for each span ( i , j ) , indicates whether or not it is a constituent ( Bij = c ) or a distituent</definiens>
			</definition>
			<definition id="4">
				<sentence>In addition , it generates a feature map Fprime , which for each span ( i , j ) in S specifies a pair of features , Fprimeij = ( yij , cij ) , where yij is the POS yield of the span , and cij is the context of the span , i.e identity of the conjoined left and right POS tags : PCCM ( B , Fprime ) = P ( B ) productdisplay ( i , j ) P ( yij|Bij ) P ( cij|Bij ) The distribution P ( B ) only places mass on bracketings which correspond to binary trees .</sentence>
				<definiendum id="0">yij</definiendum>
				<definiendum id="1">cij</definiendum>
				<definiens id="0">generates a feature map Fprime , which for each span ( i , j ) in S specifies a pair of features</definiens>
			</definition>
			<definition id="5">
				<sentence>For each possible labeled tree over a sentenceS , our generative model for a labeled tree T is given as follows : P ( T , F , Fprime ) = ( 4 ) PCFG+ ( T , F ) PCCM ( B ( T ) , Fprime ) where B ( T ) corresponds to the bracketing matrix determined by T. The EM algorithm for the product model will maximize : P ( S , F , Fprime ) = summationdisplay T∈T ( S ) PCCM ( B , Fprime ) PCFG+ ( T , F ) = summationdisplay B PCCM ( B , Fprime ) summationdisplay T∈T ( B , S ) PCFG+ ( T , F ) where T ( S ) is the set of labeled trees consistent with the sentence S and T ( B , S ) is the set of labeled trees consistent with the bracketing matrix B and the sentence S. Notice that this quantity increases as the CCM and CFG+ models place probability mass on compatible latent structures , giving an intuitive justification for the success of this approach .</sentence>
				<definiendum id="0">B ( T</definiendum>
				<definiendum id="1">S ) PCFG+</definiendum>
				<definiendum id="2">T ( S )</definiendum>
				<definiendum id="3">S )</definiendum>
				<definiens id="0">the set of labeled trees consistent with the sentence S and T ( B ,</definiens>
				<definiens id="1">the set of labeled trees consistent with the bracketing</definiens>
			</definition>
			<definition id="6">
				<sentence>The tree in ( a ) is the Treebank parse , ( b ) is the parse with PROTO × CCM model , and c ) is the parse with the BEST model ( added prototype categories ) , which fixes the possesive NP and infinitival VP problems , but not the PP attachment .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiens id="0">the parse with PROTO × CCM model , and</definiens>
			</definition>
			<definition id="7">
				<sentence>edge , which has learned CFGs in an unsupervised or semi-supervised setting and can parse natural language language text with any reasonable accuracy .</sentence>
				<definiendum id="0">edge</definiendum>
				<definiens id="0">has learned CFGs in an unsupervised or semi-supervised setting and can parse natural language language text with any reasonable accuracy</definiens>
			</definition>
</paper>

		<paper id="2123">
			<definition id="0">
				<sentence>Under the scheme , each character of a word is labeled as ”B” if it is the first character of a multiple-character word , or ”I” otherwise , and ”O” if the character functioned as an independent word .</sentence>
				<definiendum id="0">”O”</definiendum>
				<definiens id="0">if the character functioned as an independent word</definiens>
			</definition>
			<definition id="1">
				<sentence>The mathematical expression for the MaxEnt model is P ( t|h ) = exp    summationdisplay i λi fi ( h , t )   /Z , Z = summationdisplay t P ( t|h ) ( 2 ) where t is a tag , “I , O , B , ” of the current word ; h , the context surrounding the current word , including word and tag sequences ; fi , a binary feature equal to 1 if the i-th defined feature is activated and 0 otherwise ; Z , a normalization coefficient ; and λi , the weight of the i-th feature .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">t</definiendum>
				<definiendum id="2">fi</definiendum>
				<definiens id="0">a tag , “I , O , B , ” of the current word ; h , the context surrounding the current word , including word and tag sequences</definiens>
			</definition>
			<definition id="2">
				<sentence>Features using word length are listed below , where l0 means the word length of the current word .</sentence>
				<definiendum id="0">l0</definiendum>
				<definiens id="0">the word length of the current word</definiens>
			</definition>
			<definition id="3">
				<sentence>Its calculation is defined as : CM ( tiob|w ) = αCMiob ( tiob|w ) + ( 1−α ) δ ( tw , tiob ) ng ( 3 ) where tiob is the word w’s IOB tag assigned by the IOB tagging ; tw , a prior IOB tag determined by the results of the dictionary-based segmentation .</sentence>
				<definiendum id="0">tiob</definiendum>
				<definiens id="0">the word w’s IOB tag assigned by the IOB tagging ; tw , a prior IOB tag determined by the results of the dictionary-based segmentation</definiens>
			</definition>
			<definition id="4">
				<sentence>CMiob ( t|w ) , a confidence probability derived in the process of IOB tagging , which is defined as CMiob ( t|w ) = summationtext hi P ( t|w , hi ) summationtext t summationtext hi P ( t|w , hi ) where hi is a hypothesis in the beam search .</sentence>
				<definiendum id="0">CMiob</definiendum>
				<definiendum id="1">hi</definiendum>
				<definiens id="0">a confidence probability derived in the process of IOB tagging , which is defined as CMiob ( t|w ) = summationtext hi P ( t|w , hi ) summationtext t summationtext hi P ( t|w , hi ) where</definiens>
				<definiens id="1">a hypothesis in the beam search</definiens>
			</definition>
			<definition id="5">
				<sentence>δ ( tw , tiob ) ng is a Kronecker delta function defined as δ ( tw , tiob ) ng = { 1 if tw = tiob0 otherwise In Eq .</sentence>
				<definiendum id="0">tiob ) ng</definiendum>
				<definiens id="0">δ ( tw , tiob ) ng = { 1 if tw = tiob0 otherwise In Eq</definiens>
			</definition>
			<definition id="6">
				<sentence>Encodings Training size ( words ) Test size ( words ) Academia Sinica AS Big5/Unicode 5.45M 122K Beijing University PKU CP936/Unicode 1.1M 104K City University of Hong Kong CITYU Big5/Unicode 1.46M 41K Microsoft Research ( Beijing ) MSR CP936/Unicode 2.37M 107K Table 1 : Corpus statistics in Sighan Bakeoff 2005 We obtained a word list from the training data as the vocabulary for dictionary-based segmentation .</sentence>
				<definiendum id="0">Encodings Training size ( words ) Test size</definiendum>
				<definiens id="0">Corpus statistics in Sighan Bakeoff 2005 We obtained a word list from the training data as the vocabulary for dictionary-based segmentation</definiens>
			</definition>
			<definition id="7">
				<sentence>s1 contains all the characters .</sentence>
				<definiendum id="0">s1</definiendum>
				<definiens id="0">contains all the characters</definiens>
			</definition>
</paper>

		<paper id="1085">
			<definition id="0">
				<sentence>Venkataraman uses standard unigram , bigram , and trigram language models in three versions of his system , which we refer to as n-gram Segmentation ( NGS ) .</sentence>
				<definiendum id="0">Venkataraman</definiendum>
				<definiens id="0">uses standard unigram , bigram , and trigram language models in three versions of his system</definiens>
			</definition>
			<definition id="1">
				<sentence>where u consists of the words w1 ... wn and p $ is the probability of the utterance boundary marker $ .</sentence>
				<definiendum id="0">u</definiendum>
				<definiens id="0">consists of the words w1 ... wn and p $ is the probability of the utterance boundary marker $</definiens>
			</definition>
			<definition id="2">
				<sentence>To see why not , consider the solution in which p $ = 1 and each utterance is a single ‘word’ , with probability equal to the empirical probability of that utterance .</sentence>
				<definiendum id="0">utterance</definiendum>
				<definiens id="0">a single ‘word’ , with probability equal to the empirical probability of that utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>Our unigram model of word frequencies is defined as wi|G ∼ G G|α0 , P0 ∼ DP ( α0 , P0 ) where the concentration parameter α0 and the base distribution P0 are parameters of the model .</sentence>
				<definiendum id="0">unigram model of word frequencies</definiendum>
				<definiens id="0">wi|G ∼ G G|α0 , P0 ∼ DP ( α0 , P0 ) where the concentration parameter α0 and the base distribution P0 are parameters of the model</definiens>
			</definition>
			<definition id="4">
				<sentence>We take a Bayesian approach and integrate over all possible values of G. The conditional probability of choosing to generate a word from a particular lexical entry is then given by a simple stochastic process known as the Chinese restaurant process ( CRP ) ( Aldous , 1985 ) .</sentence>
				<definiendum id="0">restaurant process</definiendum>
				<definiens id="0">a Bayesian approach and integrate over all possible values of G. The conditional probability of choosing to generate a word from a</definiens>
			</definition>
			<definition id="5">
				<sentence>Then P ( zi|z−i ) =    n ( z−i ) k i−1+α0 0 ≤ k &lt; K ( z−i ) α0 i−1+α0 k = K ( z−i ) ( 2 ) where z−i = z1 ... zi−1 , n ( z−i ) k is the number of customers already sitting at table k , and K ( z−i ) is the total number of occupied tables .</sentence>
				<definiendum id="0">k</definiendum>
				<definiendum id="1">K ( z−i )</definiendum>
				<definiens id="0">the total number of occupied tables</definiens>
			</definition>
			<definition id="6">
				<sentence>Summing over all the tables labeled with the same word yields the probability distribution for the ith word given previously observed words w−i : P ( wi|w−i ) = n ( w−i ) wi i−1 + α0 + α0P0 ( wi ) i−1 + α0 ( 3 ) where n ( w−i ) w is the number of instances of w observed in w−i. The first term is the probability of generating w from the cache ( i.e. , sitting at an occupied table ) , and the second term is the probability of generating it anew ( sitting at an unoccupied table ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the probability of generating w from the cache ( i.e. , sitting at an occupied table</definiens>
			</definition>
			<definition id="7">
				<sentence>Also , P ( h2|h− , d ) = P ( r , w2 , w3|h− , d ) = P ( r|h− , d ) P ( w2|h− , d ) P ( w3|w2 , h− , d ) = nr + τ 2 n− + 1 + τ · n ( h− ) w2 + α0P0 ( w2 ) n− + α0 ·n ( h− ) w3 + I ( w2 = w3 ) + α0P0 ( w3 ) n− + 1 + α0 ( 6 ) where nr is the number of branching rules r = U → W U in h− , and I ( . )</sentence>
				<definiendum id="0">nr</definiendum>
				<definiens id="0">h− ) w2 + α0P0 ( w2 ) n− + α0 ·n ( h− ) w3 + I ( w2 = w3</definiens>
				<definiens id="1">the number of branching rules r = U → W U in h−</definiens>
			</definition>
</paper>

		<paper id="1037">
			<definition id="0">
				<sentence>Weighted Constraint Dependency Grammar ( WCDG ) is a formalism in which declarative constraints can be formulated that describe well-formed dependency trees in a particular natural language .</sentence>
				<definiendum id="0">Weighted Constraint Dependency Grammar ( WCDG )</definiendum>
				<definiens id="0">a formalism in which declarative constraints can be formulated that describe well-formed dependency trees in a particular natural language</definiens>
			</definition>
</paper>

		<paper id="2073">
			<definition id="0">
				<sentence>A dialogue system is usually defined as a computer system that can interact with a human being through dialogue in order to complete a specific task ( e.g. , ticket reservation , timetable consultation , bank operations , ... ) ( Aust et al. , 1995 ; Hardy et al. , 2002 ) .</sentence>
				<definiendum id="0">dialogue system</definiendum>
			</definition>
			<definition id="1">
				<sentence>Most of these strategies are rule-based , i.e. , the dialogue strategy is defined by rules that are usually defined by a human expert ( Gorin et al. , 1997 ; Hardy et al. , 2003 ) .</sentence>
				<definiendum id="0">rule-based</definiendum>
				<definiendum id="1">dialogue strategy</definiendum>
			</definition>
			<definition id="2">
				<sentence>A DA is a label that defines the function of the annotated utterance with respect to the dialogue process .</sentence>
				<definiendum id="0">DA</definiendum>
				<definiens id="0">a label that defines the function of the annotated utterance with respect to the dialogue process</definiens>
			</definition>
			<definition id="3">
				<sentence>For the sequence of words W , a segmentation is defined as sr1 = s0s1 ... sr , where s0 = 0 and W = Ws1s0+1Ws2s1+1 ... Wsrsr−1+1 .</sentence>
				<definiendum id="0">segmentation</definiendum>
				<definiens id="0">sr1 = s0s1 ... sr , where s0 = 0 and W = Ws1s0+1Ws2s1+1 ... Wsrsr−1+1</definiens>
			</definition>
			<definition id="4">
				<sentence>The SwitchBoard database consists of human-human conversations by telephone with no directed tasks .</sentence>
				<definiendum id="0">SwitchBoard database</definiendum>
				<definiens id="0">consists of human-human conversations by telephone with no directed tasks</definiens>
			</definition>
</paper>

		<paper id="1095">
			<definition id="0">
				<sentence>TimeML ( Pustejovsky et al. 2005 ) ( www.timeml.org ) is an annotation scheme for markup of events , times , and their temporal relations in news articles .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">an annotation scheme for markup of events , times , and their temporal relations in news articles</definiens>
			</definition>
			<definition id="1">
				<sentence>TimeML uses 14 temporal relations in the TLINK RelTypes , which reduce to a disjunctive classification of 6 temporal relations RelTypes = { SIMULTANEOUS , IBEFORE , BEFORE , BEGINS , ENDS , INCLUDES } .</sentence>
				<definiendum id="0">TimeML</definiendum>
				<definiens id="0">uses 14 temporal relations in the TLINK RelTypes , which reduce to a disjunctive classification of 6 temporal relations RelTypes = { SIMULTANEOUS , IBEFORE , BEFORE , BEGINS , ENDS</definiens>
			</definition>
			<definition id="2">
				<sentence>In order to have a disjunctive classification , SIMULTANEOUS and IDENTITY are collapsed , since IDENTITY is a subtype of SIMULTANEOUS .</sentence>
				<definiendum id="0">IDENTITY</definiendum>
				<definiens id="0">a subtype of SIMULTANEOUS</definiens>
			</definition>
			<definition id="3">
				<sentence>GTag takes a document with TimeML tags , along with syntactic information from part-of-speech tagging and chunking from Carafe , and then uses 187 syntactic and lexical rules to infer and label TLINKs between tagged events and other tagged events or times .</sentence>
				<definiendum id="0">GTag</definiendum>
				<definiens id="0">takes a document with TimeML tags</definiens>
			</definition>
			<definition id="4">
				<sentence>Table 4 ( line GTag+closure+ME-C ) shows the results of closing the TLINKs produced by GTag’s annotation and then training ME from the resulting data .</sentence>
				<definiendum id="0">line GTag+closure+ME-C )</definiendum>
				<definiens id="0">shows the results of closing the TLINKs produced by GTag’s annotation and then training ME from the resulting data</definiens>
			</definition>
</paper>

		<paper id="2122">
			<definition id="0">
				<sentence>ITG consists of unary production rules that generate English/foreign word pairs e/f : X → e/f and binary production rules in two forms that generate subtree pairs , written : X → [ Y Z ] and X → 〈Y Z〉 The square brackets indicate the right hand side rewriting order is the same for both languages .</sentence>
				<definiendum id="0">ITG</definiendum>
				<definiens id="0">consists of unary production rules that generate English/foreign word pairs e/f : X → e/f and binary production rules in two forms that generate subtree pairs , written : X → [ Y Z ] and X</definiens>
			</definition>
			<definition id="1">
				<sentence>The original Stochastic ITG is the counterpart of Stochastic CFG in the bitext space .</sentence>
				<definiendum id="0">Stochastic ITG</definiendum>
				<definiens id="0">the counterpart of Stochastic CFG in the bitext space</definiens>
			</definition>
			<definition id="2">
				<sentence>However , modeling complete bilingual bilexical dependencies as theorized in Melamed ( 2003 ) implies a huge parameter space of O ( |V |2|T|2 ) , where |V | and |T| are the vocabulary sizes of the two languages .</sentence>
				<definiendum id="0">|T|</definiendum>
			</definition>
			<definition id="3">
				<sentence>So , instead of modeling cross-language word translations and within-language word dependencies in 954 C B C A see/vois them/les I/Je S C C ( I/Je ) C C ( them/les ) C B ( see/vois ) A ( see/vois ) C ( see/vois ) S S C ( I ) C ( them ) them/les I/Je C ( see ) see/vois B ( see ) A ( see ) Figure 1 : Parses for an example sentence pair under unlexicalized ITG ( left ) , cross-language bilexicalization ( center ) , and head-modi er bilexicaliztion ( right ) .</sentence>
				<definiendum id="0">head-modi er bilexicaliztion</definiendum>
				<definiens id="0">Parses for an example sentence pair under unlexicalized ITG ( left ) , cross-language bilexicalization ( center )</definiens>
			</definition>
			<definition id="4">
				<sentence>EC ( e → [ eprimee ] ) = summationdisplay s , t , u , v , S , U parenleftbigP ( [ eprimee ] | e ) · β 3 ( eprime ) · α ( e ) · β1 ( e ) parenrightbig = summationdisplay s , S , u , U  P ( [ eprimee ] | e ) · β3 ( eprime ) ·  summationdisplay t , v α · β1     = summationdisplay s , S , u , U parenleftBig P ( [ eprimee ] | e ) · β3 ( eprime ) · α+3 ( e ) parenrightBig which can be computed in O ( n6 ) as long as we have α+3 ready in a table .</sentence>
				<definiendum id="0">parenleftbigP</definiendum>
				<definiendum id="1">U  P</definiendum>
				<definiendum id="2">parenrightBig</definiendum>
				<definiens id="0">parenrightbig = summationdisplay s , S , u</definiens>
			</definition>
			<definition id="5">
				<sentence>Namely , there are O ( |V |2 ) dependency probabilities and O ( |V ||T| ) translation probabilities , where |V | is the size of English vocabulary and |T| is the size of the foreign language vocabulary .</sentence>
				<definiendum id="0">|V |</definiendum>
				<definiens id="0">the size of English vocabulary and |T| is the size of the foreign language vocabulary</definiens>
			</definition>
			<definition id="6">
				<sentence>For scoring the Viterbi alignments of each system against gold-standard annotated alignments , we use the alignment error rate ( AER ) of Och and Ney ( 2000 ) , which measures agreement at the level of pairs of words : AER = 1 − |A ∩ GP| + |A ∩ GS||A| + |G S| where A is the set of word pairs aligned by the automatic system , GS is the set marked in the gold standard as sure , and GP is the set marked as possible ( including the sure pairs ) .</sentence>
				<definiendum id="0">AER</definiendum>
				<definiendum id="1">GS</definiendum>
				<definiendum id="2">GP</definiendum>
				<definiens id="0">the set of word pairs aligned by the automatic system ,</definiens>
			</definition>
			<definition id="7">
				<sentence>BLITG is the within-English Bilexical ITG .</sentence>
				<definiendum id="0">BLITG</definiendum>
				<definiens id="0">the within-English Bilexical ITG</definiens>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>Spoken monologues feature greater sentence length and structural complexity than do spoken dialogues .</sentence>
				<definiendum id="0">Spoken monologues</definiendum>
				<definiens id="0">feature greater sentence length and structural complexity than do spoken dialogues</definiens>
			</definition>
			<definition id="1">
				<sentence>A bunsetsu consists of one independent word and more than zero ancillary words .</sentence>
				<definiendum id="0">bunsetsu</definiendum>
			</definition>
			<definition id="2">
				<sentence>Here , the specification of the partsof-speech is in accordance with that of the IPA parts-of-speech used in the ChaSen morphological analyzer ( Matsumoto et al. , 1999 ) , the rules of the bunsetsu segmentation with those of CSJ ( Maekawa et al. , 2000 ) , the rules of the clause boundary analysis with those of Maruyama et al. ( Maruyama et al. , 2004 ) , and the dependency grammar with that of the Kyoto Corpus ( Kurohashi and Nagao , 1997 ) .</sentence>
				<definiendum id="0">Kyoto Corpus</definiendum>
				<definiens id="0">in accordance with that of the IPA parts-of-speech used in the ChaSen morphological analyzer</definiens>
			</definition>
			<definition id="3">
				<sentence>The dependency 3Asu-Wo-Yomu is a collection of transcriptions of a TV commentary program of the Japan Broadcasting Corporation ( NHK ) .</sentence>
				<definiendum id="0">dependency 3Asu-Wo-Yomu</definiendum>
			</definition>
			<definition id="4">
				<sentence>Assuming that each dependency is independent of the others , P ( Si|Bi ) can be calculated as follows : P ( Si|Bi ) = ni−1productdisplay k=1 P ( bik rel→ bil|Bi ) , ( 1 ) 171 where P ( bik rel→ bil|Bi ) is the probability that a bunsetsu bik depends on a bunsetsu bil when the sequence of bunsetsus Bi is provided .</sentence>
				<definiendum id="0">P ( Si|Bi</definiendum>
				<definiens id="0">the probability that a bunsetsu</definiens>
			</definition>
			<definition id="5">
				<sentence>Unlike the conventional stochastic sentence-by-sentence dependency parsing method , in our method , Bi is the sequence of bunsetsus that constitutes not a sentence but a clause .</sentence>
				<definiendum id="0">Bi</definiendum>
				<definiens id="0">the sequence of bunsetsus that constitutes not a sentence but a clause</definiens>
			</definition>
			<definition id="6">
				<sentence>Let B ( =B1···Bn ) be the sequence of bunsetsus of one sentence and Sfin be a set of dependency relations whose dependent bunsetsu is the final bunsetsu of a clause boundary unit , { dep ( b1n1 ) , ··· , dep ( bm−1nm−1 ) } ; then Sfin , which makes P ( Sfin|B ) the maximum , is calculated by DP .</sentence>
				<definiendum id="0">B ( =B1···Bn )</definiendum>
				<definiens id="0">the final bunsetsu of a clause boundary unit , { dep ( b1n1 ) , ···</definiens>
			</definition>
</paper>

		<paper id="3008">
			<definition id="0">
				<sentence>Punctuation marks ( PMs ) have been proven useful in RST annotation as well as in many other NLP tasks such as Part-of-Speech tagging , Word Sense Disambiguation , Near-duplicate detection , bilingual alignment ( e.g. Chuang and Yeh , 2005 ) , etc .</sentence>
				<definiendum id="0">Punctuation marks</definiendum>
				<definiendum id="1">PMs</definiendum>
				<definiendum id="2">Word Sense Disambiguation</definiendum>
			</definition>
			<definition id="1">
				<sentence>under construction For the purpose of language engineering and linguistic investigation , we are constructing a Chinese corpus comparable to the English WSJ-RST treebank and the German Potsdam Commentary Corpus ( Carlson et al. 2003 ; Stede 2004 ) .</sentence>
				<definiendum id="0">Potsdam Commentary Corpus</definiendum>
				<definiens id="0">WSJ-RST treebank and the German</definiens>
			</definition>
			<definition id="2">
				<sentence>“+” means one or more occurrences , “*” means zero or more occurrences .</sentence>
				<definiendum id="0">“+”</definiendum>
			</definition>
			<definition id="3">
				<sentence>The intra-coder accuracy rate ( R v ) for a particular variable is defined as R v = *100 % 2* ( AT-AS ) TT-TS Where AT= number of agreed tags ; TT= number of total tags ; TS= number of total tags for structural elements ; AS= number of agreed tags for structural elements .</sentence>
				<definiendum id="0">intra-coder accuracy rate ( R v</definiendum>
				<definiendum id="1">AT-AS ) TT-TS</definiendum>
				<definiens id="0">Where AT= number of agreed tags ; TT= number of total tags ; TS= number of total tags for structural elements ; AS= number of agreed tags for structural elements</definiens>
			</definition>
			<definition id="4">
				<sentence>45 Relation ( C-！ ) P ( r|pm ) P ( pm|r ) Addition-S 5.26 % 14.29 % Conjunction-M 15.79 % 0.58 % Elaboration-S 5.26 % 0.55 % Evaluation-S 10.53 % 1.44 % Evidence10.53 % 2.33 % Joint-M 5.26 % 1.72 % Justify-N 5.26 0.44 % Justify-S 5.26 % 0.44 % Nonvolitional-cause-N 5.26 % 0.71 % Solutionhood-N 5.26 1.33 % Volitional-cause-S 5.26 % 1.32 % Structural elements 21.05 % 0.57 % TTL 100.00 % N/A Table 3 : Rhetorical pattern of C-Exclamation Relation ( C-： ) P ( r|pm ) P ( pm|r ) Attribution-S 10.93 % 68.00 % Background-N 0.64 % 3.39 % Background-S 0.32 1.69 % Concession-N 0.32 % 1.04 % Elaboration-N 18.97 % 32.42 % Evaluation-N 0.64 % 1.44 % Justify-S 0.32 0.44 % Nonvolitional-cause-N 0.32 % 0.71 % Preparation-S 4.18 13.40 % Same-unit-S 0.32 % 4.35 % Volitional-cause-N 0.32 % 1.32 % Structural elements 62.70 % 11 27.70 % TTL 100.00 % N/A Table 4 : Rhetorical pattern of C-Colon Relation ( C-； ) P ( r|pm ) P ( pm|r ) Antithesis-S 1.00 % 2.70 % Background-N 1.00 1.69 % Background-S 1.00 % 1.69 % Conjunction-M 59.00 % 11.46 % Contrast-M 7.00 % 7.69 % Disjunction-M 2.00 18.18 % List-M 23.00 % 24.73 % Purpose-N 1.00 % 6.67 % Same-unit-M 2.00 8.70 % Sequence-M 3.00 % 6.12 % TTL 100.00 % N/A Table 5 : Rhetorical pattern of C-Semicolon Relation ( C-…… ) P ( r|pm ) P ( pm|r ) Conjunction-M 12.50 % 0.19 % Disjunction-M 12.50 % 9.09 % Elaboration-S 25.00 % 1.10 % Evidence-S 25.00 % 2.33 % 11 This is higher than the overall 42.93 % rate for colons used in structural elements , for we’ve only finished 97 shortest ones from the 197 randomly selected files .</sentence>
				<definiendum id="0">C-Colon Relation ( C-； ) P ( r|pm ) P ( pm|r</definiendum>
			</definition>
</paper>

		<paper id="1113">
			<definition id="0">
				<sentence>The HYPONYMY relation is the reverse of HYPERNYMY and links one verb synset to a more specific one .</sentence>
				<definiendum id="0">HYPONYMY relation</definiendum>
				<definiens id="0">the reverse of HYPERNYMY and links one verb synset to a more specific one</definiens>
			</definition>
			<definition id="1">
				<sentence>The CAUSATION relation puts certain restrictions on the syntactic patterns of the two verb synsets .</sentence>
				<definiendum id="0">CAUSATION relation</definiendum>
				<definiens id="0">puts certain restrictions on the syntactic patterns of the two verb synsets</definiens>
			</definition>
</paper>

		<paper id="1093">
			<definition id="0">
				<sentence>Call center is a general term for help desks , information lines and customer service centers .</sentence>
				<definiendum id="0">Call center</definiendum>
				<definiens id="0">a general term for help desks , information lines and customer service centers</definiens>
			</definition>
			<definition id="1">
				<sentence>The Clusterer generates individual levels of the taxonomy by using text clustering .</sentence>
				<definiendum id="0">Clusterer</definiendum>
				<definiens id="0">generates individual levels of the taxonomy by using text clustering</definiens>
			</definition>
			<definition id="2">
				<sentence>Q : would you like to have your ticket A : ticket number is two thank you for calling and have a great day thank you for calling bye bye anything else i can help you with have a great day you too Figure 4 : Topic specific information useful to present them in the order of their appearance .</sentence>
				<definiendum id="0">Q</definiendum>
			</definition>
</paper>

		<paper id="1066">
			<definition id="0">
				<sentence>For the two merging rules straight and inverted , applying them on two consecutive blocks A1 and A2 is assigned a probability Prm ( A ) Prm ( A ) = ΩλΩ ·triangleλLMpLM ( A1 , A2 ) ( 4 ) where the Ω is the reordering score of block A1 and A2 , λΩ is its weight , and trianglepLM ( A1 , A2 ) is the increment of the language model score of the two blocks according to their final order , λLM is its weight .</sentence>
				<definiendum id="0">trianglepLM</definiendum>
				<definiendum id="1">A2 )</definiendum>
				<definiens id="0">the reordering score of block A1 and A2</definiens>
				<definiens id="1">the increment of the language model score of the two blocks according to their final order , λLM is its weight</definiens>
			</definition>
			<definition id="1">
				<sentence>The second one is a distortion style reordering model , which is formulated as Ω = braceleftBigg exp ( 0 ) , o = straight exp ( |A1| ) + ( |A2| ) , o = inverted where |Ai| denotes the number of words on the source side of blocks .</sentence>
				<definiendum id="0">|Ai|</definiendum>
				<definiens id="0">a distortion style reordering model , which is formulated as Ω = braceleftBigg exp ( 0 ) , o = straight exp ( |A1| ) + ( |A2| ) , o = inverted where</definiens>
				<definiens id="1">the number of words on the source side of blocks</definiens>
			</definition>
			<definition id="2">
				<sentence>The IGR is the measure used in the decision tree learning to select features ( Quinlan , 1993 ) .</sentence>
				<definiendum id="0">IGR</definiendum>
				<definiens id="0">the measure used in the decision tree learning to select features</definiens>
			</definition>
			<definition id="3">
				<sentence>For feature f and class c , the IGR ( f , c ) IGR ( f , c ) = En ( c ) −En ( c|f ) En ( f ) ( 11 ) where En ( · ) is the entropy and En ( ·|· ) is the conditional entropy .</sentence>
				<definiendum id="0">IGR</definiendum>
				<definiendum id="1">En ( · )</definiendum>
				<definiens id="0">the entropy</definiens>
				<definiens id="1">the conditional entropy</definiens>
			</definition>
			<definition id="4">
				<sentence>The trigram language model training data consists of English texts mostly derived from the English side of the UN corpus ( catalog number LDC2004E12 ) , which totally contains 81M English words .</sentence>
				<definiendum id="0">trigram language model training data</definiendum>
				<definiens id="0">consists of English texts mostly derived from the English side of the UN corpus ( catalog number LDC2004E12 ) , which totally contains 81M English words</definiens>
			</definition>
</paper>

		<paper id="2067">
			<definition id="0">
				<sentence>label clause type desired SCCs gerundive ( NP ) -GERUND S small clause NP-NP , ( NP ) -ADJP control ( NP ) -INF-to control ( NP ) -INF-wh-to SBAR with a complementizer ( NP ) -S-wh , ( NP ) -S-that without a complementizer ( NP ) -S-that Table 1 : SCCs for different clauses we eliminated from the two test corpora all sentences that do not contain verbs .</sentence>
				<definiendum id="0">SCCs gerundive</definiendum>
			</definition>
			<definition id="1">
				<sentence>SR and SP are defined as follows : SR = number of correct cues from the parser’s outputnumber of cues from treebank parse ( 1 ) 516 WSJ model LR/LP SR/SP punc 87.92 % /88.29 % 76.93 % /77.70 % no-punc 86.25 % /86.91 % 76.96 % /76.47 % punc-no-punc 82.31 % /83.70 % 74.62 % /74.88 % Switchboard model LR/LP SR/SP punc 83.14 % /83.80 % 79.04 % /78.62 % no-punc 82.42 % /83.74 % 78.81 % /78.37 % punc-no-punc 78.62 % /80.68 % 75.51 % /75.02 % Table 2 : Results of parsing and extraction of SCCs SP = number of correct cues from the parser’s outputnumber of cues from the parser’s output ( 2 ) SCC Balanced F-measure = 2∗SR∗SPSR +SP ( 3 ) The results for parsing WSJ and Switchboard and extracting SCCs are summarized in Table 2 .</sentence>
				<definiendum id="0">LR/LP SR/SP</definiendum>
				<definiens id="0">follows : SR = number of correct cues from the parser’s outputnumber of cues from treebank parse ( 1 ) 516 WSJ model</definiens>
			</definition>
			<definition id="2">
				<sentence>Type precision is the percentage of SCF types that our system proposes which are correct according some gold standard and type recall is the percentage of correct SCF types proposed by our system that are listed in the gold standard .</sentence>
				<definiendum id="0">Type precision</definiendum>
				<definiendum id="1">type recall</definiendum>
				<definiens id="0">the percentage of SCF types that our system proposes which are correct according some gold standard and</definiens>
				<definiens id="1">the percentage of correct SCF types proposed by our system that are listed in the gold standard</definiens>
			</definition>
			<definition id="3">
				<sentence>The conventional accuracy metrics for parsing ( LR/LP ) should not be taken as the only metrics in determining the feasibility of applying statistical parsers to spoken language .</sentence>
				<definiendum id="0">conventional accuracy metrics for parsing</definiendum>
				<definiens id="0">the only metrics in determining the feasibility of applying statistical parsers to spoken language</definiens>
			</definition>
</paper>

		<paper id="2055">
			<definition id="0">
				<sentence>In Figure 1 we report the identification F-Measure for the baseline ( the first hypothesis ) , and the N-best upper bound , the best of the N hypotheses 1 , using different models : English MonoCase ( EN-Mono , without capitalization ) , English Mixed Case ( EN-Mix , with capitalization ) , Chinese without the usable character restriction ( CH-NoRes ) and Chinese with the usable character restriction ( CH-WithRes ) .</sentence>
				<definiendum id="0">MonoCase</definiendum>
				<definiens id="0">EN-Mono , without capitalization ) , English Mixed Case ( EN-Mix , with capitalization ) , Chinese without the usable character restriction ( CH-NoRes</definiens>
			</definition>
			<definition id="1">
				<sentence>tion Extraction Stages Name tagging is typically one of the first stages 2 If the key included an 'other ' class of names , these would be classification errors ; since it does not -since these names are not tagged in the key -the automatic scorer treats them as spurious names .</sentence>
				<definiendum id="0">tion Extraction Stages Name tagging</definiendum>
				<definiens id="0">not tagged in the key -the automatic scorer treats them as spurious names</definiens>
			</definition>
			<definition id="2">
				<sentence>The nominal mention tagger ( noun phrase chunker ) uses a maximum entropy model .</sentence>
				<definiendum id="0">nominal mention tagger ( noun phrase chunker )</definiendum>
				<definiens id="0">uses a maximum entropy model</definiens>
			</definition>
			<definition id="3">
				<sentence>HighConfidence Ranking Best Name Hypothesis Event based Re-Ranking Cross-document Coreference based Re-Ranking Coref Resolver Event Patterns Raw Sentence HMM Name Tagger and Name Structure Parser Multiple name hypotheses Name Structure based Re-Ranking Relation Tagger Mentions Relation based Re-Ranking Nominal Tagger 424 Re-Ranker Property for comparing names N ik and N jk HMMMargin scaled margin value from HMM Idiom ik -1 if N ik is part of an idiom ; otherwise 0 PERContext ik the number of PER context words if N ik and N jk are both PER ; otherwise 0 ORGSuffix ik 1 if N ik is tagged as ORG and it includes a suffix word ; otherwise 0 PERCharacter ik -1 if N ik is tagged as PER without family name , and it does not consist entirely of transliterated person name characters ; otherwise 0 Titlestructure ik -1 if N ik = title word + family name while N jk = title word + family name + given name ; otherwise 0 Digit ik -1 if N ik is PER or GPE and it includes digits or punctuation ; otherwise 0 AbbPER ik -1 if N ik = little/old + family name + given name while N jk = little/old + family name ; otherwise 0 SegmentPER ik -1 if N ik is GPE ( PER ) * GPE , while N jk is PER* ; otherwise 0 Voting ik the voting rate among all the candidate hypotheses 6 Name Structure Based FamousName ik 1 if N ik is tagged as the same type in one of the famous name lists 7 ; otherwise 0 Probability1 i scaled ranking probability for ( h i , h j ) from name structure based re-ranker Relation Constraint ik If N ik is in relation R ( N ik = EntityType 1 , M 2 = EntityType 2 ) , compute Prob ( EntityType 1 |EntityType 2 , R ) from training data and scale it ; otherwise 0 Relation Based Conjunction of InRelation i &amp; Probability1 i Inrelation ik is 1 if N ik and N jk have different name types , and N ik is in a definite relation while N jk is not ; otherwise 0 .</sentence>
				<definiendum id="0">HighConfidence Ranking</definiendum>
				<definiendum id="1">N jk</definiendum>
				<definiendum id="2">GPE</definiendum>
				<definiendum id="3">N ik</definiendum>
				<definiens id="0">Best Name Hypothesis Event based Re-Ranking Cross-document Coreference based Re-Ranking Coref Resolver Event Patterns Raw Sentence HMM Name Tagger and Name Structure Parser Multiple name hypotheses Name Structure based Re-Ranking Relation Tagger Mentions Relation based Re-Ranking Nominal Tagger 424 Re-Ranker Property for comparing names N ik and N jk HMMMargin scaled margin value from HMM Idiom ik -1 if N ik is part of an idiom ; otherwise 0 PERContext ik the number of PER context words if N ik</definiens>
			</definition>
			<definition id="4">
				<sentence>The annotator scores ( when measured against a final key produced by review and adjudication of the two annotations ) were F=92.5 for one annotator and F=92.7 for the other .</sentence>
				<definiendum id="0">annotator scores</definiendum>
				<definiens id="0">when measured against a final key produced by review and adjudication of the two annotations ) were F=92.5 for one annotator</definiens>
			</definition>
</paper>

		<paper id="1107">
			<definition id="0">
				<sentence>The Distributional Hypothesis suggests a generic equivalence between words .</sentence>
				<definiendum id="0">Distributional Hypothesis</definiendum>
			</definition>
			<definition id="1">
				<sentence>Troponymy represents the hyponymy relation between verbs .</sentence>
				<definiendum id="0">Troponymy</definiendum>
			</definition>
			<definition id="2">
				<sentence>agent ( v ) is the noun deriving from the agentification of the verb v. Elements such as l|f1 , ... , fN are the tokens generated from lemmas l by applying constraints expressed via the feature-value pairs f1 , ... , fN .</sentence>
				<definiendum id="0">agent ( v )</definiendum>
				<definiens id="0">the noun deriving from the agentification of the verb v. Elements such as l|f1 , ...</definiens>
			</definition>
			<definition id="3">
				<sentence>The measure Snom ( vt , vh ) indicates the relatedness between two elements composing a pair , in line with ( Chklovski and Pantel , 2004 ; Glickman et al. , 2005 ) ( see Sec .</sentence>
				<definiendum id="0">vh )</definiendum>
				<definiens id="0">indicates the relatedness between two elements composing a pair</definiens>
			</definition>
			<definition id="4">
				<sentence>For both approaches , the strength indicator Shb ( vt , vh ) and Spe ( vt , vh ) are computed as follows : Sy ( vt , vh ) = logp ( vt , vh|y ) p ( v t ) p ( vh ) ( 6 ) where y is hb for the happens-before patterns and pe for the probabilistic entailment patterns .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">the probabilistic entailment patterns</definiens>
			</definition>
			<definition id="5">
				<sentence>Given a threshold t , Se ( t ) is the probability of a candidate pair ( vh , vt ) to belong to True Set if the test is positive , while Sp ( t ) is the probability of belonging to ControlSet if the test is negative , i.e. : Se ( t ) = p ( ( vh , vt ) ∈ TS|S ( vh , vt ) &gt; t ) Sp ( t ) = p ( ( vh , vt ) ∈ CS|S ( vh , vt ) &lt; t ) The ROC curve ( Se ( t ) vs. 1 − Sp ( t ) ) naturally follows ( see Fig .</sentence>
				<definiendum id="0">ROC curve</definiendum>
				<definiens id="0">the probability of a candidate pair</definiens>
				<definiens id="1">the probability of belonging to ControlSet if the test is negative , i.e. : Se ( t ) = p ( ( vh , vt ) ∈ TS|S ( vh , vt ) &gt; t ) Sp ( t ) = p ( ( vh , vt ) ∈ CS|S ( vh</definiens>
			</definition>
			<definition id="6">
				<sentence>That is , each pair of synsets ( St , Sh ) is an oriented entailment relation between St and Sh .</sentence>
				<definiendum id="0">Sh )</definiendum>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>Preprocessing includes different kinds of tokenization , stemming , part-of-speech ( POS ) tagging and lemmatization .</sentence>
				<definiendum id="0">Preprocessing</definiendum>
				<definiens id="0">includes different kinds of tokenization , stemming , part-of-speech ( POS ) tagging and lemmatization</definiens>
			</definition>
			<definition id="1">
				<sentence>L1 uses the simple POS tags advocated by Habash and Rambow ( 2005 ) ( 15 tags ) ; while L2 uses the reduced tag set used by Diab et al. ( 2004 ) ( 24 tags ) .</sentence>
				<definiendum id="0">L1</definiendum>
				<definiens id="0">uses the simple POS tags advocated by Habash and Rambow ( 2005 ) ( 15 tags ) ; while L2 uses the reduced tag set used by Diab et al. ( 2004 ) ( 24 tags )</definiens>
			</definition>
			<definition id="2">
				<sentence>In the rest of this section we describe two successful methods for system combination of different schemes : rescoring-only combination ( ROC ) and decoding-plus-rescoring combination ( DRC ) .</sentence>
				<definiendum id="0">ROC</definiendum>
				<definiens id="0">successful methods for system combination of different schemes : rescoring-only combination</definiens>
			</definition>
</paper>

		<paper id="1140">
			<definition id="0">
				<sentence>In their approach , a template-based generator produces a word lattice with intonational phrase breaks .</sentence>
				<definiendum id="0">template-based generator</definiendum>
			</definition>
			<definition id="1">
				<sentence>In COMIC , the sentence planner uses XSLT to generate disjunctive logical forms ( LFs ) , which specify a range of possible paraphrases in a nested free-choice form ( Foster and White , 2004 ) .</sentence>
				<definiendum id="0">LFs</definiendum>
				<definiens id="0">specify a range of possible paraphrases in a nested free-choice form</definiens>
			</definition>
			<definition id="2">
				<sentence>OpenCCG includes an extensible API for integrating language modeling and realization .</sentence>
				<definiendum id="0">OpenCCG</definiendum>
				<definiens id="0">includes an extensible API for integrating language modeling and realization</definiens>
			</definition>
			<definition id="3">
				<sentence>Festival uses the prosodic markup in the text analysis phase of synthesis in place of the structures that it would otherwise have to predict from the text .</sentence>
				<definiendum id="0">Festival</definiendum>
				<definiens id="0">uses the prosodic markup in the text analysis phase of synthesis in place of the structures</definiens>
			</definition>
			<definition id="4">
				<sentence>To encode the ranking task as an SVM constraint optimization problem , each paraphrase a106 of a sentence a105 is represented by a feature vector a8a40a115a105a106a41 a61 a104a102a49a40a115a105a106a41a59a58a58a58a59a102a109a40a115a105a106a41a105 , where a109 is the number of features .</sentence>
				<definiendum id="0">a109</definiendum>
				<definiens id="0">the number of features</definiens>
			</definition>
			<definition id="5">
				<sentence>There are also two WORDS feature sets ( shown in the second column ) : WORDS-BI , which includes NGRAMS plus a feature for every possible unigram and bigram , where the value of the feature is the count of the unigram or bigram in a given realization ; and WORDS-TRI , which includes all the features in WORDS-BI , plus a feature for every possible trigram .</sentence>
				<definiendum id="0">WORDS-TRI</definiendum>
				<definiens id="0">WORDS-BI , which includes NGRAMS plus a feature for every possible unigram</definiens>
				<definiens id="1">the count of the unigram or bigram in a given realization ; and</definiens>
			</definition>
			<definition id="6">
				<sentence>As mentioned in Section 3.4 , the ordering accuracy of the ranker using a given feature set is determined by a99a61a78 , where a99 is the number of correctly ordered pairs ( of each paraphrase , not just the top ranked one ) produced by the ranker , and a78 is the total number of human-ranked ordered pairs .</sentence>
				<definiendum id="0">a99</definiendum>
				<definiendum id="1">a78</definiendum>
				<definiens id="0">the number of correctly ordered pairs</definiens>
				<definiens id="1">the total number of human-ranked ordered pairs</definiens>
			</definition>
</paper>

		<paper id="1101">
			<definition id="0">
				<sentence>Constraints We define a taxonomy T as a set of pairwise relations R over some domain of objects DT .</sentence>
				<definiendum id="0">taxonomy T</definiendum>
			</definition>
			<definition id="1">
				<sentence>We propose that the event Rij ∈ T has some prior probability P ( Rij ∈ T ) , and P ( Rij ∈ 2A least common subsumer LCS ( i , j ) is defined as a synset that is an ancestor in the hypernym hierarchy of both i and j which has no child that is also an ancestor of both i and j. When there is more than one LCS ( due to multiple inheritance ) , we refer to the closest LCS , i.e. , the LCS that minimizes the maximum distance to i and j. 3An ( m , n ) -cousin for m ≥ 2 corresponds to the English kinship relation “ ( m−1 ) -th cousin |m−n|-times removed.”</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">m , n</definiendum>
				<definiendum id="2">the English kinship relation “</definiendum>
				<definiens id="0">the event Rij ∈ T has some prior probability P ( Rij ∈ T ) , and</definiens>
				<definiens id="1">a synset that is an ancestor in the hypernym hierarchy of both i and j which has no child that is also an ancestor of both i and j. When there is more than one LCS ( due to multiple inheritance )</definiens>
			</definition>
			<definition id="2">
				<sentence>We define the probability of the taxonomy as a whole as the joint probability of its component relations ; given a partition of all possible relations R = { A , B } where A ∈ T and B negationslash∈ T , we define : P ( T ) = P ( A ∈ T , B negationslash∈ T ) .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">the probability of the taxonomy as a whole as the joint probability of its component relations ; given a partition of all possible relations R = { A , B } where A ∈ T and B negationslash∈ T</definiens>
			</definition>
			<definition id="3">
				<sentence>Further , we assume that each item of observed evidence ERij depends on the taxonomy T only by way of the corresponding relation Rij , i.e. , P ( ERij|T ) = braceleftbigg P ( ER ij|Rij ∈ T ) if Rij ∈ T P ( ERij|Rij negationslash∈ T ) if Rij negationslash∈ T For example , if our evidence EHij is a set of observed lexico-syntactic patterns indicative of hypernymy between two words i and j , we assume that whatever dependence the relations in T have on our observations may be explained entirely by dependence on the existence or non-existence of the single hypernym relation H ( i , j ) .</sentence>
				<definiendum id="0">EHij</definiendum>
				<definiens id="0">each item of observed evidence ERij depends on the taxonomy T only by way of the corresponding relation Rij , i.e. , P ( ERij|T ) = braceleftbigg P ( ER ij|Rij ∈ T ) if Rij ∈ T P ( ERij|Rij negationslash∈ T</definiens>
				<definiens id="1">a set of observed lexico-syntactic patterns indicative of hypernymy between two words i and j</definiens>
			</definition>
			<definition id="4">
				<sentence>803 This definition leads to the following best-first search algorithm for hyponym acquisition , which at each iteration defines the new taxonomy as the union of the previous taxonomy T and the set of novel relations implied by the relation Rij that maximizes ∆T ( I ( Rij ) ) and thus maximizes the conditional probability of the evidence over all possible single relations : WHILE max Rijnegationslash∈T ∆T ( I ( Rij ) ) &gt; 1 T ← T∪I ( arg max Rijnegationslash∈T ∆T ( I ( Rij ) ) ) .</sentence>
				<definiendum id="0">hyponym acquisition</definiendum>
			</definition>
			<definition id="5">
				<sentence>When computing the conditional probability of a specific new relation Rkl ∈ I ( Rab ) , we assume that the relevant sense pair k0 , l0 is the one which maximizes the probability of the new relation , i.e. for k ∈ senses ( i ) , l ∈ senses ( j ) , ( k0 , l0 ) = argmax k , l P ( Rkl ∈ T|ERij ) .</sentence>
				<definiendum id="0">l0</definiendum>
				<definiens id="0">the one which maximizes the probability of the new relation</definiens>
			</definition>
</paper>

		<paper id="1067">
			<definition id="0">
				<sentence>A language model is a statistical model that gives a probability distribution over possible sequences of words .</sentence>
				<definiendum id="0">language model</definiendum>
				<definiens id="0">a statistical model that gives a probability distribution over possible sequences of words</definiens>
			</definition>
			<definition id="1">
				<sentence>An n-gram language model is an n-th order Markov model where the probability of generating a given word depends only on the last n 1 words immediately preceding it and is given by the following equation : P ( wk1 ) = P ( w1 ) P ( w2jw1 ) P ( wnjwn−11 ) ( 1 ) where k &gt; = n. N-gram language models have been successfully used in Automatic Speech Recognition ( ASR ) as was first proposed by ( Bahl et al. , 1983 ) .</sentence>
				<definiendum id="0">n-gram language model</definiendum>
				<definiens id="0">an n-th order Markov model where the probability of generating a given word depends only on the last n 1 words immediately preceding it and is given by the following equation : P ( wk1 ) = P ( w1 ) P ( w2jw1 ) P ( wnjwn−11 ) ( 1 ) where k &gt; = n. N-gram language models</definiens>
			</definition>
			<definition id="2">
				<sentence>N-gram language models have also been used in Statistical Machine Translation ( SMT ) as proposed by ( Brown et al. , 1990 ; Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">N-gram language</definiendum>
			</definition>
			<definition id="3">
				<sentence>SMT decoders attempt to generate translations in the proper word order by attempting many possible 529 word reorderings during the translation process .</sentence>
				<definiendum id="0">SMT</definiendum>
				<definiens id="0">decoders attempt to generate translations in the proper word order by attempting many possible 529 word reorderings during the translation process</definiens>
			</definition>
			<definition id="4">
				<sentence>Formally , our distortion model components are defined as follows : Outbound Distortion : Po ( δjfi ) = C ( δjfi ) summationtext k C ( δk jfi ) ( 2 ) where fi is a foreign word ( i.e. , Arabic in our case ) , δ is the step size , and C ( δjfi ) is the observed count of this parameter over all word alignments in the training data .</sentence>
				<definiendum id="0">distortion model components</definiendum>
				<definiendum id="1">δ</definiendum>
				<definiendum id="2">C ( δjfi )</definiendum>
				<definiens id="0">follows : Outbound Distortion : Po ( δjfi ) = C ( δjfi ) summationtext k C ( δk jfi ) ( 2 ) where fi is a foreign word</definiens>
				<definiens id="1">the step size , and</definiens>
				<definiens id="2">the observed count of this parameter over all word alignments in the training data</definiens>
			</definition>
			<definition id="5">
				<sentence>The outbound distortion cost is defined as : Co ( δjfi ) = logfαPo ( δjfi ) + ( 1 α ) Ps ( δ ) g ( 5 ) where Ps ( δ ) is a smoothing distribution 7 and α is a linear-mixture parameter 8 .</sentence>
				<definiendum id="0">outbound distortion cost</definiendum>
				<definiendum id="1">Ps ( δ )</definiendum>
			</definition>
			<definition id="6">
				<sentence>Also , suppose that our phrase dictionary provided the translation Washington State , with internal word alignment a = ( a1 = 2 , a2 = 1 ) ( i.e. , a= ( &lt; Washington , wA $ nTn &gt; , &lt; State , wlAyp &gt; ) , then the outbound phrase cost is defined as : Co ( p , n , m , a ) =Co ( δ = ( m n ) jfn ) + l−1summationdisplay i=1 Co ( δ = ( ai+1 ai ) jfai ) ( 6 ) where l is the length of the target phrase , a is the internal word alignment , fn is source word at position n ( in the sentence ) , and fai is the source word that is aligned to the i-th word in the target side of the phrase ( not the sentence ) .</sentence>
				<definiendum id="0">fai</definiendum>
				<definiens id="0">suppose that our phrase dictionary provided the translation Washington State , with internal word alignment a =</definiens>
				<definiens id="1">p , n , m , a ) =Co ( δ = ( m n ) jfn ) + l−1summationdisplay i=1 Co ( δ = ( ai+1 ai ) jfai ) ( 6 ) where l is the length of the target phrase , a is the internal word alignment , fn is source word at position n ( in the sentence ) , and</definiens>
			</definition>
			<definition id="7">
				<sentence>It is a multistack , multi-beam search decoder with n stacks ( where n is the length of the source sentence being decoded ) 532 s 0 1 1 1 1 1 2 2 2 2 w 0 4 6 8 10 12 4 6 8 10 BLEUr1n4c 0.5617 0.6507 0.6443 0.6430 0.6461 0.6456 0.6831 0.6706 0.6609 0.6596 2 3 3 3 3 3 4 4 4 4 4 12 4 6 8 10 12 4 6 8 10 12 Table 3 : BLEU scores for the word order restoration task .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the length of the source sentence being decoded</definiens>
			</definition>
			<definition id="8">
				<sentence>A hypothesis covers a subset of the source words .</sentence>
				<definiendum id="0">hypothesis</definiendum>
			</definition>
			<definition id="9">
				<sentence>The main components of the cost of extension e can be defined by the following equation : C ( e ) = λ1CLM ( e ) + λ2CTM ( e ) + λ3CD ( e ) where CLM ( e ) is the language model cost , CTM ( e ) is the translation model cost , and CD ( e ) is the distortion cost .</sentence>
				<definiendum id="0">extension e</definiendum>
				<definiendum id="1">, CTM ( e )</definiendum>
				<definiendum id="2">CD ( e )</definiendum>
				<definiens id="0">the following equation : C ( e ) = λ1CLM ( e ) + λ2CTM ( e ) + λ3CD ( e ) where CLM ( e ) is the language model cost</definiens>
			</definition>
			<definition id="10">
				<sentence>The second parameter is the window width w , which is defined as the distance ( in number of source words ) between the left-most uncovered source word and the right-most covered source word .</sentence>
				<definiendum id="0">window width w</definiendum>
			</definition>
			<definition id="11">
				<sentence>The source sentence is a reordered English sentence in the same manner we described in Section 3 .</sentence>
				<definiendum id="0">source sentence</definiendum>
			</definition>
</paper>

		<paper id="2026">
			<definition id="0">
				<sentence>Term expansion is to use predictive semanticallyrelevant terms of target language as the expansion of queries , and therefore resolve the issue that top retrieved Web pages seldom contain effective English annotations .</sentence>
				<definiendum id="0">Term expansion</definiendum>
				<definiens id="0">to use predictive semanticallyrelevant terms of target language as the expansion of queries</definiens>
			</definition>
			<definition id="1">
				<sentence>The whole procedure consists of three steps : unit segmentation , item translation knowledge base construction , and expansion knowledge base evaluation .</sentence>
				<definiendum id="0">whole procedure</definiendum>
				<definiens id="0">consists of three steps : unit segmentation , item translation knowledge base construction , and expansion knowledge base evaluation</definiens>
			</definition>
			<definition id="2">
				<sentence>Though pseudo-relevance feedback ( PRF ) has been successfully used in the information retrieval ( IR ) , whether PRF in single-language IR or pre-translation PRF and post-translation PRF in CLIR , the feedback results are from source language to source language or target language to target language , that is , the language of feedback units is same as the retrieval language .</sentence>
				<definiendum id="0">PRF</definiendum>
				<definiendum id="1">information retrieval</definiendum>
				<definiendum id="2">IR</definiendum>
				<definiens id="0">the feedback results are from source language to source language or target language to target language</definiens>
			</definition>
			<definition id="3">
				<sentence>The evaluation method is defined as follows : 1 ) ( 1 ) ( ) ( +∆ += t tftw , where N tsD t N i i ∑ =∆ =1 ) , ( ) ( ( 1 ) Δ ( t ) represents the average length between the source word s and the target candidate t. If the greater that the average length is , the relevance degree between source terms and candidates will become lower .</sentence>
				<definiendum id="0">N tsD</definiendum>
				<definiens id="0">the average length between the source word s and the target candidate t. If the greater that the average length is , the relevance degree between source terms</definiens>
			</definition>
			<definition id="4">
				<sentence>D i ( s , t ) denotes the byte distance between source words and target candidates , and N represents the total number of candidate occurrences in the estimated Web pages .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
			<definition id="5">
				<sentence>N denotes the total number of Web pages that contain candidates , and partly reflects the distribution information of candidates in different Web pages .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of Web pages that contain candidates</definiens>
			</definition>
			<definition id="6">
				<sentence>The distance relation ) , ( jip D is defined as the distance contribution probability of the jth source-candidate pair on the ith Web pages , which is impacted on every word pair emerged on the Web in the point of micro-view .</sentence>
				<definiendum id="0">distance relation</definiendum>
				<definiens id="0">the distance contribution probability of the jth source-candidate pair on the ith Web pages , which is impacted on every word pair emerged on the Web in the point of micro-view</definiens>
			</definition>
			<definition id="7">
				<sentence>The weights of 1 λ and 2 λ represent the proportion of term frequency and term distribution , and 1 λ denotes the weight of the total number of one candidate occurrences , and 2 λ represents the weight of counting the nearest distance occurrence for each Web page .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiens id="0">The weights of 1 λ and 2 λ represent the proportion of term frequency and term distribution</definiens>
				<definiens id="1">the weight of the total number of one candidate occurrences</definiens>
			</definition>
			<definition id="8">
				<sentence>wji ) , ( δ is the contribution probability of keywords , key symbols and boundary information .</sentence>
				<definiendum id="0">δ</definiendum>
				<definiens id="0">the contribution probability of keywords , key symbols and boundary information</definiens>
			</definition>
			<definition id="9">
				<sentence>The top n accuracy is defined as the 204 percentage of terms whose top n translations include correct translations in the term pairs .</sentence>
				<definiendum id="0">top n accuracy</definiendum>
			</definition>
</paper>

		<paper id="3006">
			<definition id="0">
				<sentence>The back-end is a reasoning system which takes a sequence of moves and finds the destination in the map .</sentence>
				<definiendum id="0">back-end</definiendum>
				<definiens id="0">a reasoning system which takes a sequence of moves and finds the destination in the map</definiens>
			</definition>
			<definition id="1">
				<sentence>A transition part encodes a transition .</sentence>
				<definiendum id="0">transition part</definiendum>
				<definiens id="0">encodes a transition</definiens>
			</definition>
			<definition id="2">
				<sentence>The sum of the weights of all the parts is the score of the pair ( xi , yi ) .</sentence>
				<definiendum id="0">sum of the weights of all the parts</definiendum>
				<definiens id="0">the score of the pair ( xi , yi )</definiens>
			</definition>
			<definition id="3">
				<sentence>We assume the probability of seeing y given x is P ( y|x ) = exp ( s ( x , y ) ) summationtext y′ exp ( s ( x , y′ ) ) where y′ is all possible labeling for x , Now , given a training set T = { ( xiyi ) } mi=1 , We can learn the weights by maximizing the log-likelihood , summationtext i logP ( yi|xi ) .</sentence>
				<definiendum id="0">y′</definiendum>
				<definiens id="0">all possible labeling for x , Now , given a training set T = { ( xiyi ) } mi=1 , We can learn the weights by maximizing the log-likelihood , summationtext i logP ( yi|xi )</definiens>
			</definition>
			<definition id="4">
				<sentence>Overlap match is a lenient measure that considers a segmentation or labeling to be cor35 Exact Match Recall Precision F-1 CRFs 66.0 % 67.0 % 66.5 % Overlap Match Recall Precision F-1 Baseline 62.8 % 49.9 % 55.6 % CRFs 85.7 % 87.0 % 86.3 % Instruction Follow Through success rate Baseline 39.5 % CRFs 73.7 % Table 4 : Recall , Precision , F-1 and Success Rate rect if it overlaps with any of the annotated labels .</sentence>
				<definiendum id="0">Overlap match</definiendum>
				<definiens id="0">Recall , Precision , F-1 and Success Rate rect if it overlaps with any of the annotated labels</definiens>
			</definition>
</paper>

		<paper id="1145">
			<definition id="0">
				<sentence>, | , θ ( 1 ) where ( ) xP denotes the probability that a sentence of length x occurs , denotes the number of occurrences of w in text ( xwN , ) x .</sentence>
				<definiendum id="0">( ) xP</definiendum>
				<definiens id="0">the probability that a sentence of length x occurs , denotes the number of occurrences of w in text ( xwN , ) x</definiens>
			</definition>
			<definition id="1">
				<sentence>The EM algorithm ( Dempster et al. , 1977 ) is a method to estimate a model that has the maximal likelihood of the data when some variables can not be observed ( these variables are called latent variables ) .</sentence>
				<definiendum id="0">EM algorithm</definiendum>
			</definition>
			<definition id="2">
				<sentence>Suppose , for example , “breakfast” is a strong clue for the morning class , i.e. the word is a time-associated word of morning .</sentence>
				<definiendum id="0">“breakfast”</definiendum>
				<definiens id="0">a time-associated word of morning</definiens>
			</definition>
			<definition id="3">
				<sentence>E-step : ( ) ( ) ( ) ( ) ( ) , , || , || , | ∑ = c cxPcP cxPcP xcP θθ θθ θ ( 5 ) M-step : ( ) ( ) ( ) ( ) , 1 , |1 DC xcP cP Dx +− +− = ∑ ∈ α θα ( 6 ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) , , ,|1 , ,|1 | ∑∑ ∑ ∈ ∈ +− +− = wDx Dx xwNxcPW xwNxcP cwP θα θα ( 7 ) where C denotes the number of categories , W denotes the number of features variety .</sentence>
				<definiendum id="0">6 ) ( ) ( ) ( ) ( ) ( ) ( ) ( )</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">W</definiendum>
				<definiens id="0">the number of categories ,</definiens>
				<definiens id="1">the number of features variety</definiens>
			</definition>
			<definition id="4">
				<sentence>From this table , we can see Method A works well for classification of morning , daytime , evening , and night , but has some difficulty in 4 http : //www.chasen.org/~taku/software/YamCha Table 6 : Comparison of the methods for five class classification Figure 2 : Change of # sentences that have timeassociated words : “Explicit” indicates the number of sentences including explicit temporal expressions , “NE-TIME” indicates the number of sentences including NE-TIME tag .</sentence>
				<definiendum id="0">“Explicit”</definiendum>
				<definiendum id="1">“NE-TIME”</definiendum>
				<definiens id="0">the number of sentences including NE-TIME tag</definiens>
			</definition>
			<definition id="5">
				<sentence>Meaningless ( non-word ) strings caused by morMethod Conclusive accuracy Explicit 0.833 Baseline 0.821 Method A ( NORMAL ) 0.864 Method A ( CONTEXT ) 0.862 Method B 0.823 0 1000 2000 3000 4000 5000 1 10203040506070809010 # time-associated words ( N-best ) # s e nt e nc e s i nc l udi ng t i m e as s o ciat ed w o r d s Explicit NE-TIME # time-unknown sentences correctly classified by the time-unknown filter # known sentences correctly classified by the time-slot classifier + # sentences with a time-slot tag value 1159 phological analysis error are presented as the symbol “ -- -” .</sentence>
				<definiendum id="0">Meaningless</definiendum>
			</definition>
</paper>

		<paper id="1090">
			<definition id="0">
				<sentence>The translation probability is calculated from the relative frequency as , a34a35a4 a29 a0 a6 a29 a2 a8 a10 a57a59a58a22a60a62a61a64a63 a4 a29 a0a5a65 a29 a2 a8 a66a68a67 a69 a57a59a58a70a60a37a61a64a63 a4 a29 a0a5a65 a29 a2 a8 ( 2 ) where a57a59a58a22a60a62a61a64a63 a4 a29 a0a5a65 a29 a2 a8 is the frequency of alignments between the source phrase a29 a0 and the target phrase a29 a2 .</sentence>
				<definiendum id="0">translation probability</definiendum>
			</definition>
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>We constructed a probabilistic shift-reduce parser ( SR ) for labelled dependency trees using the model described by ( Nivre , 2003 ) : from all available dependency trees , we reconstructed the series of parse actions ( shift , reduce and attach ) that would have constructed the tree , and then trained a simple maximum-likelihood model that predicts parse actions based on features of the current state such as the categories of the current and following words , the environment of the top stack word constructed so far , and the distance between the top word and the next word .</sentence>
				<definiendum id="0">SR</definiendum>
				<definiens id="0">a simple maximum-likelihood model that predicts parse actions based on features of the current state such as the categories of the current and following words</definiens>
			</definition>
</paper>

		<paper id="2124">
			<definition id="0">
				<sentence>Parallel data has been treated as sets of unrelated sentence-pairs in state-of-the-art statistical machine translation ( SMT ) models .</sentence>
				<definiendum id="0">SMT</definiendum>
				<definiens id="0">treated as sets of unrelated sentence-pairs in state-of-the-art statistical machine translation (</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , we define the following terms1 : • A word-pair ( fj , ei ) is the basic unit for word alignment , where fj is a French word and ei is an English word ; j and i are the position indices in the corresponding French sentence f and English sentence e. • A sentence-pair ( f , e ) contains the source sentence f of a sentence length of J ; a target sentence e of length I. The two sentences f and e are translations of each other .</sentence>
				<definiendum id="0">word-pair</definiendum>
				<definiendum id="1">fj</definiendum>
				<definiendum id="2">ei</definiendum>
				<definiens id="0">the basic unit for word alignment</definiens>
				<definiens id="1">a French word</definiens>
				<definiens id="2">the position indices in the corresponding French sentence f and English sentence e. • A sentence-pair ( f , e ) contains the source sentence f of a sentence length of J ; a target sentence e of length I. The two sentences f</definiens>
			</definition>
			<definition id="2">
				<sentence>This generative process , for a document-pair ( Fd , Ed ) , is summarized as below : ( a ) Sample sentence-length Jn from Poisson ( δ ) ; ( b ) Sample a topic zdn from a Multinomial ( θd ) ; ( c ) Sample ej from a monolingual model p ( ej ) ; ( d ) Sample each word alignment link aj from a uniform model p ( aj ) ( or an HMM ) ; ( e ) Sample each fj according to a topic-specific translation lexicon p ( fj|e , aj , zn , B ) .</sentence>
				<definiendum id="0">Multinomial</definiendum>
				<definiendum id="1">B</definiendum>
				<definiens id="0">d ) Sample each word alignment link aj from a uniform model p ( aj ) ( or an HMM ) ; ( e ) Sample each fj according to a topic-specific translation lexicon p ( fj|e , aj , zn ,</definiens>
			</definition>
			<definition id="3">
				<sentence>Given the parameters α , B , and the English part E , the joint conditional distribution of the topic-weight vector θ , the topic indicators z , the alignment vectors A , and the document F can be written as : p ( F , A , θ , z|E , α , B ) = p ( θ|α ) Nproductdisplay n=1 p ( zn|θ ) p ( fn , an|en , α , Bzn ) , ( 4 ) where N is the number of the sentence-pair .</sentence>
				<definiendum id="0">document F</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">Given the parameters α , B , and the English part E , the joint conditional distribution of the topic-weight vector θ</definiens>
				<definiens id="1">z|E , α , B ) = p ( θ|α</definiens>
			</definition>
			<definition id="4">
				<sentence>In the M-step , we update α and B so that they improve a lower bound of the log-likelihood defined bellow : L ( γ , φ , ϕ ; α , B ) =Eq [ logp ( θ|α ) ] +Eq [ logp ( z|θ ) ] +Eq [ logp ( a ) ] +Eq [ logp ( f|z , a , B ) ] −Eq [ logq ( θ ) ] −Eq [ logq ( z ) ] −Eq [ logq ( a ) ] .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">improve a lower bound of the log-likelihood defined bellow : L ( γ , φ , ϕ ; α ,</definiens>
			</definition>
			<definition id="5">
				<sentence>Topic A is about Us-China economic relationships ; Topic B relates to Chinese companies’ merging ; Topic C shows the sports of handicapped people .</sentence>
				<definiendum id="0">Topic B</definiendum>
				<definiendum id="1">Topic C</definiendum>
				<definiens id="0">relates to Chinese companies’ merging ;</definiens>
			</definition>
			<definition id="6">
				<sentence>Notably , BiTAM allows to test alignments in two directions : English-to-Chinese ( EC ) and Chinese-to-English ( CE ) .</sentence>
				<definiendum id="0">BiTAM</definiendum>
			</definition>
			<definition id="7">
				<sentence>Inter takes the intersection of the two directions and generates high-precision alignments ; the 974 SETTING IBM-1 HMM IBM-4 BITAM-1 BITAM-2 BITAM-3UDA BDA UDA BDA UDA BDA CE ( % ) 36.27 43.00 45.00 40.13 48.26 40.26 48.63 40.47 49.02 EC ( % ) 32.94 44.26 45.96 36.52 46.61 37.35 46.30 37.54 46.62 REFINED ( % ) 41.71 44.40 48.42 45.06 49.02 47.20 47.61 47.46 48.18 UNION ( % ) 32.18 42.94 43.75 35.87 48.66 36.07 48.99 36.26 49.35 INTER ( % ) 39.86 44.87 48.65 43.65 43.85 44.91 45.18 45.13 45.48 NIST 6.458 6.822 6.926 6.937 6.954 6.904 6.976 6.967 6.962 BLEU 15.70 17.70 18.25 17.93 18.14 18.13 18.05 18.11 18.25 Table 4 : Word Alignment Accuracy ( F-measure ) and Machine Translation Quality for BiTAM Models , comparing with IBM Models , and HMMs with a training scheme of 18h743 on the Treebank data listed in Table 1 .</sentence>
				<definiendum id="0">Inter</definiendum>
				<definiens id="0">takes the intersection of the two directions and generates high-precision alignments</definiens>
			</definition>
</paper>

		<paper id="2025">
			<definition id="0">
				<sentence>The transliteration units in Bengali words take the pattern C+M where C represents a vowel or a consonant or a conjunct and M represents the vowel modifier or matra .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">a vowel or a consonant or a conjunct</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus B2E transliteration can be formulated as β = argmax P ( α , β , γ ) ( 4 ) β , γ and similarly the E2B back-transliteration as 193 α = argmax P ( α , β , γ ) ( 5 ) α , γ An n-gram transliteration model is defined as the conditional probability or transliteration probability of a transliteration pair &lt; b , e &gt; k depending on its immediate n predecessor pairs : P ( B , E ) = P ( α , β , γ ) K = ∏ P ( &lt; b , e &gt; k│ &lt; b , e &gt; k-n+1k-1 ) ( 6 ) k=1 Scheme Machine transliteration has been viewed as a sense disambiguation problem .</sentence>
				<definiendum id="0">B2E transliteration</definiendum>
				<definiendum id="1">n-gram transliteration model</definiendum>
				<definiens id="0">β = argmax P ( α , β , γ ) ( 4 ) β , γ and similarly the E2B back-transliteration as 193 α = argmax P ( α , β , γ ) ( 5 ) α , γ An</definiens>
				<definiens id="1">the conditional probability or transliteration probability of a transliteration pair &lt; b , e &gt; k depending on its immediate n predecessor pairs : P ( B , E ) = P ( α , β , γ ) K = ∏ P ( &lt; b , e &gt; k│ &lt; b , e &gt; k-n+1k-1 ) ( 6 ) k=1 Scheme Machine transliteration has been viewed as a sense disambiguation problem</definiens>
			</definition>
			<definition id="2">
				<sentence>The Bengali word is divided into Transliteration Units ( TU ) that have the pattern C+M , where C represents a vowel or a consonant or conjunct and M represents the vowel modifier or matra .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">a vowel or a consonant or conjunct</definiens>
			</definition>
			<definition id="3">
				<sentence>An English word is divided into TUs that have the pattern C*V* , where C represents a consonant and V represents a vowel .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">a consonant and</definiens>
			</definition>
			<definition id="4">
				<sentence>TUAR is defined as , TUAR = ( L-Err ) / L , where L is the number of TUs in E , and Err is the number of wrongly transliterated TUs in E/ generated by the system .</sentence>
				<definiendum id="0">TUAR</definiendum>
				<definiendum id="1">L</definiendum>
				<definiendum id="2">Err</definiendum>
				<definiens id="0">the number of TUs in E , and</definiens>
				<definiens id="1">the number of wrongly transliterated TUs in E/ generated by the system</definiens>
			</definition>
			<definition id="5">
				<sentence>WAR is defined as , WAR= ( S-Err/ ) / S , where S is the test sample size and Err/ is is the number of erroneous names generated by the system ( when E/ does not match with E ) .</sentence>
				<definiendum id="0">WAR</definiendum>
				<definiendum id="1">WAR= ( S-Err/</definiendum>
				<definiendum id="2">S</definiendum>
				<definiendum id="3">Err/</definiendum>
				<definiens id="0">the test sample size and</definiens>
			</definition>
			<definition id="6">
				<sentence>The modified joint source-channel model ( Model F ) that incorporates linguistic knowledge performs best among all the models with a Word Agreement Ratio ( WAR ) of 69.3 % and a Transliteration Unit Agreement Ratio ( TUAR ) of 89.8 % .</sentence>
				<definiendum id="0">Transliteration Unit Agreement Ratio</definiendum>
				<definiens id="0">incorporates linguistic knowledge performs best among all the models with a Word Agreement Ratio ( WAR ) of 69.3 % and a</definiens>
			</definition>
			<definition id="7">
				<sentence>Model Error in TUs ( Err ) Error words ( Err/ ) A 990 615 B 795 512 C 880 532 D 814 471 E 604 413 F 486 369 Table 1 : Value of Err and Err/ for each model ( B2E transliteration ) Model WAR ( in % ) TUAR ( in % ) A 48.8 79.2 B 57.4 83.3 C 55.7 81.5 D 60.8 82.9 E 65.6 87.3 F 69.3 89.8 Table 2 : Results with Evaluation Metrics ( B2E transliteration ) Model WAR ( in % ) TUAR ( in % ) A 49.6 79.8 B 56.2 83.8 C 53.9 82.2 D 58.2 83.2 E 64.7 87.5 F 67.9 89.0 Table 3 : Results with Evaluation Metrics ( E2B transliteration ) It has been observed that the modified joint source-channel model with linguistic knowledge performs best in terms of Word Agreement Ratio ( WAR ) and Transliteration Unit Agreement Ratio ( TUAR ) .</sentence>
				<definiendum id="0">B2E transliteration ) Model WAR</definiendum>
				<definiendum id="1">TUAR</definiendum>
				<definiendum id="2">B2E transliteration ) Model WAR</definiendum>
			</definition>
</paper>

		<paper id="2061">
			<definition id="0">
				<sentence>A desired feature of computer-assisted translation ( CAT ) systems is the integration of the human speech into the system , as skilled human translators are faster at dictating than typing the translations ( Brown et al. , 1994 ) .</sentence>
				<definiendum id="0">CAT</definiendum>
			</definition>
			<definition id="1">
				<sentence>A statistical prediction engine provides the completions to what a human translator types ( Foster et al. , 1997 ; Och et al. , 2003 ) .</sentence>
				<definiendum id="0">statistical prediction engine</definiendum>
			</definition>
			<definition id="2">
				<sentence>The target language speech is a human-produced translation of the source language text .</sentence>
				<definiendum id="0">target language speech</definiendum>
			</definition>
			<definition id="3">
				<sentence>The decision rule is given by : ˆeˆI1 = argmax I , eI1 braceleftBig Msummationdisplay m=1 λmhm ( eI1 , fJ1 , xT1 ) bracerightBig ( 3 ) Each of the terms hm ( eI1 , fJ1 , xT1 ) denotes one of the various models which are involved in the recognition procedure .</sentence>
				<definiendum id="0">xT1 )</definiendum>
				<definiens id="0">one of the various models which are involved in the recognition procedure</definiens>
			</definition>
			<definition id="4">
				<sentence>Then , we are able to use FSA algorithms to integrate MT and ASR word graphs .</sentence>
				<definiendum id="0">FSA</definiendum>
				<definiens id="0">algorithms to integrate MT and ASR word graphs</definiens>
			</definition>
</paper>

		<paper id="2017">
			<definition id="0">
				<sentence>In this work we attempt to represent the crosslinguistic similarities that exist in the consonant inventories of the world’s languages through a bipartite network named PlaNet ( the Phoneme Language Network ) .</sentence>
				<definiendum id="0">PlaNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>Network We define the network of consonants and languages , PlaNet , as a bipartite graph represented as G = 〈VL , VC , E〉 where VL is the set of nodes labeled by the languages and VC is the set of nodes labeled by the consonants .</sentence>
				<definiendum id="0">PlaNet</definiendum>
				<definiendum id="1">VL</definiendum>
				<definiendum id="2">VC</definiendum>
				<definiens id="0">the set of nodes labeled by the languages and</definiens>
			</definition>
			<definition id="2">
				<sentence>E is the set of edges that run between VL and VC .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">the set of edges that run between VL and VC</definiens>
			</definition>
			<definition id="3">
				<sentence>The degree of a node u , denoted by ku is defined as the number of edges connected to u. The term degree distribution is used to denote the way degrees ( ku ) are distributed over the nodes ( u ) .</sentence>
				<definiendum id="0">degree of a node u</definiendum>
			</definition>
			<definition id="4">
				<sentence>Degree distribution of the nodes in VL : Figure 2 shows the degree distribution of the nodes in VL where the x-axis denotes the degree of each node expressed as a fraction of the maximum degree and the y-axis denotes the number of nodes having a given degree expressed as a fraction of the total number of nodes in VL .</sentence>
				<definiendum id="0">Degree distribution of the nodes</definiendum>
				<definiendum id="1">y-axis</definiendum>
				<definiens id="0">the degree distribution of the nodes in VL where the x-axis denotes the degree of each node expressed as a fraction of the maximum degree and the</definiens>
				<definiens id="1">a fraction of the total number of nodes in VL</definiens>
			</definition>
			<definition id="5">
				<sentence>Γ ( · ) is the Euler’s gamma function .</sentence>
				<definiendum id="0">Γ ( · )</definiendum>
			</definition>
			<definition id="6">
				<sentence>Degree distribution of the nodes in VC : Figure 3 illustrates two different types of degree distribution plots for the nodes in VC ; Figure 3 ( a ) corresponding to the rank , i.e. , the sorted order of degrees , ( x-axis ) versus degree ( y-axis ) and Figure 3 ( b ) corresponding to the degree ( k ) ( x-axis ) versus Pk ( y-axis ) where Pk is the fraction of nodes having degree greater than or equal to k. Figure 3 clearly shows that both the curves have two distinct regimes and the distribution is scalefree .</sentence>
				<definiendum id="0">Degree distribution of the nodes</definiendum>
				<definiendum id="1">x-axis ) versus degree</definiendum>
				<definiendum id="2">Pk</definiendum>
				<definiens id="0">a ) corresponding to the rank , i.e. , the sorted order of degrees</definiens>
			</definition>
			<definition id="7">
				<sentence>The probability Pr ( i ) with which the node Lj gets attached to i depends on the current degree of i and is given by Pr ( i ) = ki +epsilon1summationtext iprime∈Vj ( kiprime +epsilon1 ) where ki is the current degree of the node i , Vj is the set of nodes in VC to which Lj is not already connected and epsilon1 is the smoothing parameter which is used to reduce bias and favor at least a few attachments with nodes in Vj that do not have a high Pr ( i ) .</sentence>
				<definiendum id="0">ki</definiendum>
				<definiendum id="1">Vj</definiendum>
				<definiendum id="2">epsilon1</definiendum>
				<definiens id="0">the current degree of the node i</definiens>
				<definiens id="1">the set of nodes in VC to which Lj is not already connected and</definiens>
				<definiens id="2">the smoothing parameter which is used to reduce bias and favor at least a few attachments with nodes in Vj that do not have a high Pr ( i )</definiens>
			</definition>
			<definition id="8">
				<sentence>Good fits emerge repeat for j = 1 to 317 do if there is a node Lj ∈ VL with at least one or more consonants to be chosen from VC then Compute Vj = VC-V ( Lj ) , where V ( Lj ) is the set of nodes in VC to which Lj is already connected ; end for each node i ∈ Vj do Pr ( i ) = ki +epsilon1summationtext iprime∈Vj ( kiprime +epsilon1 ) where ki is the current degree of the node i and epsilon1 is the model parameter .</sentence>
				<definiendum id="0">= ki +epsilon1summationtext iprime∈Vj</definiendum>
				<definiendum id="1">ki</definiendum>
				<definiendum id="2">epsilon1</definiendum>
				<definiens id="0">a node Lj ∈ VL with at least one or more consonants to be chosen from VC then Compute Vj = VC-V ( Lj ) , where V ( Lj ) is the set of nodes in VC to which Lj is already connected ; end for each node i ∈ Vj do Pr ( i )</definiens>
				<definiens id="1">the model parameter</definiens>
			</definition>
			<definition id="9">
				<sentence>Pr ( i ) is the probability of connecting Lj to i. end Connect Lj to a node i ∈ Vj following the distribution Pr ( i ) ; end until all languages complete their inventory quota ; Algorithm 1 : Algorithm for synthesis of PlaNet based on preferential attachment Figure 6 : A partial step of the synthesis process .</sentence>
				<definiendum id="0">Pr ( i )</definiendum>
				<definiens id="0">A partial step of the synthesis process</definiens>
			</definition>
			<definition id="10">
				<sentence>We dedicated the preceding sections essentially to , • Represent the consonant inventories through a bipartite network called PlaNet , • Provide a systematic study of certain important properties of the consonant inventories with the help of PlaNet , • Propose analytical explanations for the two regime power law curves ( obtained from PlaNet ) on the basis of the distribution of the consonant inventory size over languages together with the principle of preferential attachment , 3Mean error is defined as the average difference between the ordinate pairs where the abscissas are equal .</sentence>
				<definiendum id="0">Represent</definiendum>
				<definiens id="0">the consonant inventories through a bipartite network called PlaNet , • Provide a systematic study of certain important properties of the consonant inventories with the help of PlaNet</definiens>
			</definition>
</paper>

		<paper id="2023">
			<definition id="0">
				<sentence>Meanwhile the language also develops larger lexical units to carry speciﬁc meanings ; speciﬁcally MWE’s , which include compounds , phrases , technical terms , idioms and collocations , etc .</sentence>
				<definiendum id="0">speciﬁcally MWE’s</definiendum>
			</definition>
			<definition id="1">
				<sentence>For example , a textual sequence s = w1w2···wi···wn , may contain two kinds of patterns : Strict pattern : pi = wiwi+1wi+2 Flexiblepattern : pj = wiunionsqwi+2unionsqwi+4 , pk = wi unionsqunionsqwi+3wi+4 where unionsq denotes the variational or active element in pattern .</sentence>
				<definiendum id="0">unionsq</definiendum>
				<definiens id="0">the variational or active element in pattern</definiens>
			</definition>
			<definition id="2">
				<sentence>EBP is the base phrase in a gap ( Changning,2000 ) .</sentence>
				<definiendum id="0">EBP</definiendum>
				<definiendum id="1">phrase</definiendum>
				<definiens id="0">the base</definiens>
			</definition>
			<definition id="3">
				<sentence>True mutual infor179 Table 1 : Close Test for N-gram and LCS Approaches Measure N-Gram LCS Precision Recall F-Measure Precision Recall F-Measure ( % ) ( % ) ( % ) ( % ) ( % ) ( % ) Frequency 35.2 38.0 36.0 32.1 48.2 38.4 TMI 44.7 56.2 49.1 43.2 62.1 51.4 ME 51.6 52.6 51.2 44.7 65.2 52.0 Rankratio 62.1 61.5 61.1 57.0 83.1 68.5 mation ( TMI ) concerns mutual information with logarithm ( Manning,1999 ) .</sentence>
				<definiendum id="0">Precision Recall F-Measure Precision Recall F-Measure</definiendum>
				<definiens id="0">Close Test for N-gram and LCS Approaches Measure N-Gram LCS</definiens>
			</definition>
</paper>

		<paper id="1134">
			<definition id="0">
				<sentence>Thus , classifying a sense as O means that , when the sense is used in a text or conversation , we do not expect it to express subjectivity and , if the phrase or sentence containing it is subjective , the subjectivity is due to something else .</sentence>
				<definiendum id="0">O</definiendum>
				<definiens id="0">do not expect it to express subjectivity and , if the phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>The corpus we use is the MPQA Opinion Corpus , which consists of over 10,000 sentences from the world press annotated for subjective expressions ( all three types of subjective expressions described in Section 2 ) .6 ilarity which measures similarity between words , rather than word senses , here we needed a similarity measure that also takes into account word senses as defined in a sense inventory such as WordNet .</sentence>
				<definiendum id="0">MPQA Opinion Corpus</definiendum>
				<definiens id="0">consists of over 10,000 sentences from the world press annotated for subjective expressions ( all three types of subjective expressions described in Section 2 ) .6 ilarity which measures similarity between words</definiens>
			</definition>
			<definition id="2">
				<sentence>The subjectivity score is a value in the interval [ -1 , +1 ] with +1 corresponding to highly subjective and -1 corresponding to highly objective .</sentence>
				<definiendum id="0">subjectivity score</definiendum>
				<definiens id="0">a value in the interval [ -1 , +1 ] with +1 corresponding to highly subjective and -1 corresponding to highly objective</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>3 But , above all , PUG is a well-adapted formalism for writing grammars and it is capable of strongly simulating many classic formalisms .</sentence>
				<definiendum id="0">PUG</definiendum>
				<definiens id="0">a well-adapted formalism for writing grammars and it is capable of strongly simulating many classic formalisms</definiens>
			</definition>
			<definition id="1">
				<sentence>An n-graph is a graph whose nodes are edges of a ( n-1 ) -graph and a 1-graph is a standard graph .</sentence>
				<definiendum id="0">n-graph</definiendum>
				<definiens id="0">a graph whose nodes are edges of a</definiens>
			</definition>
			<definition id="2">
				<sentence>A Polarized Unification Gramar ( PUG ) is defined by a finite family T of types of objects , a set of maps attached to the objects of each type , a system ( P , . )</sentence>
				<definiendum id="0">Polarized Unification Gramar ( PUG</definiendum>
				<definiens id="0">a finite family T of types of objects , a set of maps attached to the objects of each type , a system ( P , .</definiens>
			</definition>
			<definition id="3">
				<sentence>In this paper we wil use the system of polarities P = { ■ , □ , – , + , ■ } ( which are called like this : ■ = black = saturated , + = positive , – = negative , □ = white = obligatory context and ■ = grey = absolutely neutral ) , with N = { ■ , ■ } , and a product defined by the folowing array ( where ⊥ represents the imposibility to combine ) .</sentence>
				<definiendum id="0">⊥</definiendum>
				<definiens id="0">the system of polarities P = { ■ , □ , – , + , ■ } ( which are called like this : ■ = black = saturated , + = positive , – = negative , □ = white = obligatory context</definiens>
			</definition>
			<definition id="4">
				<sentence>7 A substitution node ( like D↓ ) gives a negative node , which wil unify with the root of an α tree .</sentence>
				<definiendum id="0">substitution node</definiendum>
				<definiens id="0">wil unify with the root of an α tree</definiens>
			</definition>
			<definition id="5">
				<sentence>A β-tree gives a white root node and a black foot node , which wil unify with the uper and the lower part of a split node .</sentence>
				<definiendum id="0">β-tree</definiendum>
				<definiens id="0">gives a white root node and a black foot node , which wil unify with the uper and the lower part of a split node</definiens>
			</definition>
			<definition id="6">
				<sentence>8 For the sake of clarification of HSPG structures , we chose to translate structural features such as HDTR and NHDTR , which give the phrase structure and which never unify with other “features” , by edges and other features by maps ( which wil be represented by hashed arrows ) .</sentence>
				<definiendum id="0">NHDTR</definiendum>
				<definiens id="0">give the phrase structure and which never unify with other “features” , by edges and other features by maps ( which wil be represented by hashed arrows</definiens>
			</definition>
			<definition id="7">
				<sentence>The subcat list of the head daughter phrase ( HDTR ) is the concatenation , noted ⊕ , of two lists : a list with one element that is the description of the non-head daughter phrase and the SUBCAT list of the whole phrase .</sentence>
				<definiendum id="0">subcat list of the head daughter phrase</definiendum>
				<definiendum id="1">HDTR</definiendum>
				<definiens id="0">the concatenation , noted ⊕ , of two lists : a list with one element that is the description of the non-head daughter phrase and the SUBCAT list of the whole phrase</definiens>
			</definition>
			<definition id="8">
				<sentence>LFG synchronizes two structures ( a phrase structure or c-structure and a dependency/functional structure or f-structure ) and it can be viewed as the synchronization of a phrase structure grammar and a dependency grammar .</sentence>
				<definiendum id="0">LFG</definiendum>
				<definiens id="0">synchronizes two structures ( a phrase structure or c-structure and a dependency/functional structure or f-structure ) and it can be viewed as the synchronization of a phrase structure grammar and a dependency grammar</definiens>
			</definition>
			<definition id="9">
				<sentence>The functional equation ↑SUBJ = ↑ VCOMP SUBJ introduces a white edge SUBJ between the nodes ↑ SUBJ and ↑VCOMP ( and is therefore to be interpreted very differently from the constraints of [ 1 ] , which introduce black synchronization links . )</sentence>
				<definiendum id="0">VCOMP SUBJ</definiendum>
				<definiens id="0">introduces a white edge SUBJ between the nodes ↑ SUBJ and ↑VCOMP ( and is therefore to be interpreted very differently from the constraints of [ 1 ] , which introduce black synchronization links</definiens>
			</definition>
</paper>

		<paper id="2102">
			<definition id="0">
				<sentence>The Levin Hypothesis ( LH ) contends that verbs that exhibit similar syntactic behavior share element ( s ) of meaning .</sentence>
				<definiendum id="0">Levin Hypothesis ( LH )</definiendum>
				<definiens id="0">contends that verbs that exhibit similar syntactic behavior share element ( s ) of meaning</definiens>
			</definition>
			<definition id="1">
				<sentence>Arabic verbal morphology provides an interesting piece of explicit lexical semantic information in the lexical form of the verb .</sentence>
				<definiendum id="0">Arabic verbal morphology</definiendum>
				<definiens id="0">provides an interesting piece of explicit lexical semantic information in the lexical form of the verb</definiens>
			</definition>
			<definition id="2">
				<sentence>This membership is sometimes represented in a probabilistic framework by a distributionP ( xi , c ) , which characterizes the probability that a verb xi is a member of cluster c. Syntactic frames The syntactic frames are defined as the sister constituents of the verb in a Verb Phrase ( VP ) constituent , namely , Noun Phrases ( NP ) , Prepositional Phrases ( PP ) , and Sentential Complements ( SBARs and Ss ) .</sentence>
				<definiendum id="0">Prepositional Phrases</definiendum>
				<definiendum id="1">Sentential Complements</definiendum>
				<definiens id="0">a probabilistic framework by a distributionP ( xi , c ) , which characterizes the probability that a verb xi is a member of cluster c. Syntactic frames The syntactic frames are defined as the sister constituents of the verb in a Verb Phrase ( VP ) constituent</definiens>
			</definition>
			<definition id="3">
				<sentence>The ATB is a collection of 1800 stories of newswire text from three different press agencies , comprising a total of 800,000 Arabic tokens after clitic segmentation .</sentence>
				<definiendum id="0">ATB</definiendum>
				<definiens id="0">a collection of 1800 stories of newswire text from three different press agencies</definiens>
			</definition>
			<definition id="4">
				<sentence>The AG corpus is morphologically disambiguated using MADA.5 MADA is an SVM based system that disambiguates among different morphological analyses produced by BAMA .</sentence>
				<definiendum id="0">AG corpus</definiendum>
				<definiendum id="1">MADA</definiendum>
				<definiens id="0">an SVM based system that disambiguates among different morphological analyses produced by BAMA</definiens>
			</definition>
			<definition id="5">
				<sentence>Infomap constructs a word similarity matrixindocumentspace , thenreducesthedimensionality of the data using SVD .</sentence>
				<definiendum id="0">Infomap</definiendum>
				<definiens id="0">constructs a word similarity matrixindocumentspace , thenreducesthedimensionality of the data using SVD</definiens>
			</definition>
			<definition id="6">
				<sentence>The result is an Fβ measure , where β is the coefficient of the relative strengths of precision and recall .</sentence>
				<definiendum id="0">β</definiendum>
				<definiens id="0">the coefficient of the relative strengths of precision and recall</definiens>
			</definition>
			<definition id="7">
				<sentence>The score measures the maximum overlap between a hypothesized cluster ( HYP ) and a corresponding gold standard cluster ( GOLD ) , and computes a weighted average across all the GOLD clusters : Fβ = summationdisplay C∈C bardblCbardbl Vtot maxA∈A ( β2 +1 ) bardblA∩Cbardbl β2bardblCbardbl+bardblAbardbl A is the set of HYP clusters , C is the set of GOLD clusters , and Vtot = summationdisplay C∈C bardblCbardbl is the total number of verbs to be clustered .</sentence>
				<definiendum id="0">score</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">measures the maximum overlap between a hypothesized cluster ( HYP ) and a corresponding gold standard cluster ( GOLD ) , and computes a weighted average across all the GOLD clusters : Fβ = summationdisplay C∈C bardblCbardbl Vtot maxA∈A ( β2 +1 ) bardblA∩Cbardbl β2bardblCbardbl+bardblAbardbl A is the set of HYP clusters ,</definiens>
				<definiens id="1">the total number of verbs to be clustered</definiens>
			</definition>
			<definition id="8">
				<sentence>The ANOVA analyzes the effects of syntactic frame , LSAvectors , subjectanimacy , verbpattern , verb number , cluster number , and threshold .</sentence>
				<definiendum id="0">ANOVA</definiendum>
				<definiens id="0">analyzes the effects of syntactic frame , LSAvectors , subjectanimacy , verbpattern , verb number , cluster number , and threshold</definiens>
			</definition>
			<definition id="9">
				<sentence>In doing this , we find that the quality of the clusters is sensitive to the inclusion of information about the syntactic frames , word co-occurence ( LSA ) , and animacy of the subject , as well as parameters of the clustering algorithm such as the number of clusters , and number of verbs clustered .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">the number of clusters , and number of verbs clustered</definiens>
			</definition>
</paper>

		<paper id="2022">
			<definition id="0">
				<sentence>Because of this , detecting nominal event mentions , like those in ( 1 ) , can increase the recall of event extraction systems , in particular for the most important events in a document.1 ( 1 ) The slain journalist was a main organizer of the massive demonstrations that forced Syria to withdraw its troops from Lebanon last April , after Assad was widely accusedofplanningHariri’sassassinationinaFebruary car bombing that was similar to today’s blast .</sentence>
				<definiendum id="0">event extraction systems</definiendum>
			</definition>
			<definition id="1">
				<sentence>Format of data : Each instantiation is in the form of a dependency triple , ( wa , R , wb ) , where R is the relation type and where each argument is represented just by its syntactic head , wn .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">Each instantiation is in the form of a dependency triple</definiens>
				<definiens id="1">the relation type</definiens>
			</definition>
			<definition id="2">
				<sentence>Desideratum ( I ) is addressed by having each component of the mixture model assigning a multinomial probability to the vector , v. For the ith mixture component built around the ith seed , s ( i ) , the probability is p ( v|s ( i ) ) = Fproductdisplay f=1 parenleftBig s ( i ) f parenrightBigvf , where s ( i ) f is defined as the proportion of the times the seed was seen with feature f compared to the number of times the seed was seen with any feature fprime ∈ F. Thus s ( i ) f is simply the ( i , f ) th entry in a row-sum normalized count matrix , s ( i ) f = s ( i ) fsummationtext F fprime=1 s ( i ) fprime .</sentence>
				<definiendum id="0">Desideratum</definiendum>
				<definiendum id="1">s</definiendum>
				<definiens id="0">the probability is p ( v|s ( i ) ) = Fproductdisplay f=1 parenleftBig s ( i ) f parenrightBigvf</definiens>
			</definition>
			<definition id="3">
				<sentence>In the second row ( FAIR ) , undecided answers ( d = 0 ) are left out of the total , so the number of correct answers stays the same , but the percentage of correct answers increases.4 Scores are measured in terms of accuracy on the EVENT instances , accuracy on the NONEVENT instances , TOTAL accuracy across all instances , and the simple AVERAGE of accuracies on non-events and events ( last column ) .</sentence>
				<definiendum id="0">FAIR</definiendum>
				<definiens id="0">the number of correct answers stays the same , but the percentage of correct answers increases.4 Scores are measured in terms of accuracy on the EVENT instances , accuracy on the NONEVENT instances , TOTAL accuracy across all instances , and the simple AVERAGE of accuracies on non-events and events ( last column )</definiens>
			</definition>
			<definition id="4">
				<sentence>EXP2 : Results on ACE 2005 event data In addition to using the data set created specifically for this project , we also used a subset of the anno4Note that Att ( % ) does not change with bootstrapping— an artifact of the sparsity of certain feature vectors in the training and test data , and not the model’s constituents seeds .</sentence>
				<definiendum id="0">EXP2</definiendum>
				<definiens id="0">vectors in the training and test data</definiens>
			</definition>
			<definition id="5">
				<sentence>This is correct , but highlights the sometimes misleading interpretation of the total accuracy : in this case the model is defaulting to classifying anything as a non-event ( the majority class ) , and has a considerably impoverished event model .</sentence>
				<definiendum id="0">total accuracy</definiendum>
				<definiens id="0">the majority class )</definiens>
			</definition>
			<definition id="6">
				<sentence>Rather than having to spend the considerable person-years it takes to create resources like FrameNet , CELEX , and WordNet , a better alternative will be to use weakly-supervised semantic labelers like the one described here .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">takes to create resources like FrameNet , CELEX , and</definiens>
			</definition>
</paper>

		<paper id="4013">
			<definition id="0">
				<sentence>The actual experiment consists of two parts in which the user gets a mixed set of short-answer and true-false questions to solve using the system .</sentence>
				<definiendum id="0">actual experiment</definiendum>
				<definiens id="0">consists of two parts in which the user gets a mixed set of short-answer and true-false questions to solve using the system</definiens>
			</definition>
</paper>

		<paper id="3003">
			<definition id="0">
				<sentence>For example , the JapaneseEnglish BTEC corpus has more than 11 million unique English ( word- ) substrings and more than 8 million unique Japanese ( character- ) substrings .</sentence>
				<definiendum id="0">JapaneseEnglish BTEC</definiendum>
				<definiens id="0">corpus has more than 11 million unique English ( word- ) substrings and more than 8 million unique Japanese ( character- ) substrings</definiens>
			</definition>
			<definition id="1">
				<sentence>Basically , a Suffix Array is a very simple data structure : it is the sorted list of all the suffixes of a text .</sentence>
				<definiendum id="0">Suffix Array</definiendum>
				<definiens id="0">a very simple data structure : it is the sorted list of all the suffixes of a text</definiens>
			</definition>
</paper>

		<paper id="2062">
			<definition id="0">
				<sentence>GF resource grammars have been built in parallel for eleven languages and share a common interface , which simplifies multilingual applications .</sentence>
				<definiendum id="0">GF resource grammars</definiendum>
			</definition>
			<definition id="1">
				<sentence>Grammatical Framework ( GF ) ( Ranta , 2004 ) is a grammar formalism designed in particular to serve as an interlingua platform for natural language applications in sublanguage domains .</sentence>
				<definiendum id="0">Grammatical Framework ( GF )</definiendum>
				<definiens id="0">a grammar formalism designed in particular to serve as an interlingua platform for natural language applications in sublanguage domains</definiens>
			</definition>
			<definition id="2">
				<sentence>While in English the only parameter would be comparison degree ( Degree ) , in Russian we have many more parameters : • Case , for example : bolьxie doma – bolьxih domov ( big houses – big houses’ ) .</sentence>
				<definiendum id="0">Degree</definiendum>
				<definiens id="0">bolьxie doma – bolьxih domov ( big houses – big houses’ )</definiens>
			</definition>
			<definition id="3">
				<sentence>• Animacy only plays a role in the accusative case ( Acc ) in masculine ( Masc ) singular ( ASingular ) and in plural forms ( APlural ) , namely , accusative animate form is the same as genitive ( Gen ) form , while accusative inanimate form is the same as nominative ( Nom ) : Ya lyublyu bolьxie doma – ya lyublyu bolьxih muжqin ( I love big houses – I love big men ) .</sentence>
				<definiendum id="0">Acc</definiendum>
				<definiens id="0">I love big houses – I love big men )</definiens>
			</definition>
			<definition id="4">
				<sentence>• Degree can be more complex , since most Russian adjectives have two comparative ( Comp ) forms : declinable attributive and indeclinable predicative1 : bolee vysokiishort ( more high ) – vyxe ( higher ) , and more than one superlative ( Super ) forms : samyishort vysokiishort ( the most high ) – naivysxiishort ( the highest ) .</sentence>
				<definiendum id="0">samyishort vysokiishort</definiendum>
				<definiens id="0">declinable attributive and indeclinable predicative1 : bolee vysokiishort ( more high ) – vyxe ( higher ) , and more than one superlative</definiens>
			</definition>
			<definition id="5">
				<sentence>Implementation details ( the inflection table ) are hidden .</sentence>
				<definiendum id="0">Implementation details</definiendum>
				<definiens id="0">the inflection table ) are hidden</definiens>
			</definition>
			<definition id="6">
				<sentence>Alternatively , an extra argument ( NumberVal ) , denoting the actual number value , can be introduced into the numeral modification function ( IndefNumNP ) to tell apart numbers with the last digit between 2 and 4 from other natural numbers : oper IndefNumNP : NumberVal - &gt; Numeral - &gt; CN - &gt; NP ; Unfortunately , this would require changing the language-independent API ( adding the NumberVal argument ) and consequent adjustments in all other languages that do not need this information .</sentence>
				<definiendum id="0">NumberVal</definiendum>
				<definiens id="0">NumberVal - &gt; Numeral - &gt; CN - &gt; NP</definiens>
			</definition>
			<definition id="7">
				<sentence>-sign denotes the selection operation ) .</sentence>
				<definiendum id="0">-sign</definiendum>
				<definiens id="0">the selection operation )</definiens>
			</definition>
			<definition id="8">
				<sentence>The adjective Needed agrees with the noun Help , so Help’s gender ( g ) and number ( n ) are used to build an appropriate adjective form ( AF Short Help .</sentence>
				<definiendum id="0">adjective Needed</definiendum>
				<definiens id="0">agrees with the noun Help , so Help’s gender ( g ) and number ( n ) are used to build an appropriate adjective form ( AF Short Help</definiens>
			</definition>
</paper>

		<paper id="2047">
			<definition id="0">
				<sentence>The dependency graph ( DG ) is a packed shared data structure which consists of the nodes corresponding to the words in a sentence and the arcs showing dependency relations between the nodes .</sentence>
				<definiendum id="0">DG</definiendum>
			</definition>
			<definition id="1">
				<sentence>As shown below , the combination of the DF and the graph branch algorithm enables the treatment of non-projective dependency analysis and optimum solution search satisfying the single valence occupation constraint , which are out of the scope of most of the DP ( dynamic programming ) based parsing methods .</sentence>
				<definiendum id="0">single valence occupation constraint</definiendum>
				<definiendum id="1">DP</definiendum>
				<definiens id="0">dynamic programming ) based parsing methods</definiens>
			</definition>
			<definition id="2">
				<sentence>The well-formed dependency tree constraint is a set of well-formed constraints which should be satisfied by all dependency trees representing sentence interpretations .</sentence>
				<definiendum id="0">well-formed dependency tree constraint</definiendum>
				<definiens id="0">a set of well-formed constraints which should be satisfied by all dependency trees representing sentence interpretations</definiens>
			</definition>
			<definition id="3">
				<sentence>The score of a dependency tree is the sum total of arc scores .</sentence>
				<definiendum id="0">score of a dependency tree</definiendum>
				<definiens id="0">the sum total of arc scores</definiens>
			</definition>
			<definition id="4">
				<sentence>( C1 ) Coverage constraint : Every input word has a corresponding node in the tree ( C2 ) Single role constraint ( SRC ) : No two nodes in a dependency tree occupy the same input position 2WPP is a pair of a word and a part of speech ( POS ) .</sentence>
				<definiendum id="0">Coverage constraint</definiendum>
				<definiendum id="1">SRC</definiendum>
				<definiens id="0">a pair of a word and a part of speech ( POS )</definiens>
			</definition>
			<definition id="5">
				<sentence>( C3 ) Projectivity constraint ( PJC ) : No arc crosses another arc5 ( C4 ) Single valence occupation constraint ( SVOC ) : No two arcs in a tree occupy the same valence of a predicate ( C1 ) and ( C2 ) , collectively referred to as “covering constraint” , are basic constraints adopted by almost all dependency parsers .</sentence>
				<definiendum id="0">Projectivity constraint</definiendum>
				<definiendum id="1">PJC</definiendum>
				<definiendum id="2">valence occupation constraint</definiendum>
				<definiendum id="3">SVOC</definiendum>
				<definiens id="0">basic constraints adopted by almost all dependency parsers</definiens>
			</definition>
			<definition id="6">
				<sentence>MCPM is a generalization of ( Ozeki , 1994 ) and ( Katoh and Ehara , 1989 ) which compute the optimum dependency tree in a scored DG .</sentence>
				<definiendum id="0">MCPM</definiendum>
				<definiens id="0">a generalization of</definiens>
			</definition>
</paper>

		<paper id="2045">
			<definition id="0">
				<sentence>The compiled list of unknown-word candidates is to be verified by a group of participants .</sentence>
				<definiendum id="0">unknown-word candidates</definiendum>
				<definiens id="0">to be verified by a group of participants</definiens>
			</definition>
			<definition id="1">
				<sentence>Features used in constructing the decision trees are , for example , POS ( Part-Of-Speech ) , word length , edit distance and character sequence frequency .</sentence>
				<definiendum id="0">Features</definiendum>
				<definiens id="0">word length , edit distance and character sequence frequency</definiens>
			</definition>
			<definition id="2">
				<sentence>Word segmentation module receives text strings from the information agent and segments them into a list of words .</sentence>
				<definiendum id="0">Word segmentation module</definiendum>
				<definiens id="0">receives text strings from the information agent and segments them into a list of words</definiens>
			</definition>
			<definition id="3">
				<sentence>The performance metric is the word-boundary identification accuracy which is equal to the number of unknown words correctly extracted divided by the total number of tested unknown segments .</sentence>
				<definiendum id="0">performance metric</definiendum>
				<definiens id="0">the word-boundary identification accuracy which is equal to the number of unknown words correctly extracted divided by the total number of tested unknown segments</definiens>
			</definition>
			<definition id="4">
				<sentence>The unknownword analyzer involves two processes : unknownword detection and unknown-word boundary identification .</sentence>
				<definiendum id="0">unknownword analyzer</definiendum>
				<definiens id="0">involves two processes : unknownword detection and unknown-word boundary identification</definiens>
			</definition>
</paper>

		<paper id="2057">
			<definition id="0">
				<sentence>FrameNet ( Baker et al. , 1998 ) is a lexical database that describes English words using Frame Semantics ( Fillmore , 1976 ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>FrameNet consists of the following main parts : • An ontology consisting of a set of frames , frame elements for each frame , and relations ( such as inheritance and causative-of ) between frames .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">consists of the following main parts : • An ontology consisting of a set of frames , frame elements for each frame , and relations ( such as inheritance and causative-of ) between frames</definiens>
			</definition>
			<definition id="2">
				<sentence>Padó and Lapata ( 2005 ) avoid this problem by using heuristics based on a target-language FrameNet to select sentences that are close in meaning .</sentence>
				<definiendum id="0">Padó</definiendum>
				<definiens id="0">a target-language FrameNet to select sentences that are close in meaning</definiens>
			</definition>
</paper>

		<paper id="2103">
			<definition id="0">
				<sentence>( A similar intuition holds for the Machine Translation models generically known as the IBM models ( Brown et al. , 1993 ) , which assume that certain words in a source language sentence tend to trigger the usage of certain words in a target language translation of that sentence . )</sentence>
				<definiendum id="0">similar intuition</definiendum>
				<definiens id="0">holds for the Machine Translation models generically known as the IBM models ( Brown et al. , 1993 ) , which assume that certain words in a source language sentence tend to trigger the usage of certain words in a target language translation of that sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>−Name− ( −Name− ) a strong earthquake hit the −Name− −Name− in northwestern −Name− early −Name− the official −Name− −Name− −Name− reported # # −−−−−−−−−SXXOSXOXSSS− '' γ : informationinjuriesdamagemagnitudequakearea GMTIt BC−China ... Altai S −− −− X −− S X −− X −− X −− O −− X −− − WednesdayXinhuaNewsAgency S S − −− − BC−China−Earthquake|Urgent Earthquake rocks northwestern Xinjiang Mountains APEarthquakenorthwesternXinjiangMountainsBeijing O O O X X − − − − − S X − − O S S − S − −− − XO − − S − B : C : ( a ) `` it said no information had been received about injuries or damage from the magnitude + .</sentence>
				<definiendum id="0">−Name−</definiendum>
			</definition>
			<definition id="2">
				<sentence>The entity-based model ( EB ) ( Section 2 ) , for instance , makes use of a syntactic parser to determine the syntactic role played by each detected entity ( Figure 1 ( b ) ) .</sentence>
				<definiendum id="0">entity-based model ( EB )</definiendum>
				<definiens id="0">for instance , makes use of a syntactic parser to determine the syntactic role played by each detected entity ( Figure 1 ( b ) )</definiens>
			</definition>
			<definition id="3">
				<sentence>These terms act like building blocks for IDLexpressions , as in the following example : a15 a28a16a0a2a1a4a3a17a5a18a7 a24 a67 a5a69a68 a5a70a34a26a19a5a10a0a12a11a13a1a4a3 a15 uses the a7 ( Interleave ) operator to create a bagof-units representation .</sentence>
				<definiendum id="0">IDLexpressions</definiendum>
				<definiens id="0">a15 a28a16a0a2a1a4a3a17a5a18a7 a24 a67 a5a69a68 a5a70a34a26a19a5a10a0a12a11a13a1a4a3 a15 uses the a7 ( Interleave ) operator to create a bagof-units representation</definiens>
			</definition>
			<definition id="4">
				<sentence>a66 is the set of future ( visible ) conditions for state a34 , which can be obtained from a59 ( any non-final future event may become a future conditioning event ) , by eliminating a0a12a11a13a1a14a3 and adding the current conditioning event of a34 .</sentence>
				<definiendum id="0">a66</definiendum>
				<definiens id="0">the set of future ( visible ) conditions for state a34 , which can be obtained from a59 ( any non-final future event may become a future conditioning event ) , by eliminating a0a12a11a13a1a14a3 and adding the current conditioning event of a34</definiens>
			</definition>
			<definition id="5">
				<sentence>In fact , Barzilay et al. ( 2002 ) formulate the multi-document summarization problem as an information ordering problem , and show that naive ordering algorithms such as majority ordering ( select most frequent orders across input documents ) and chronological ordering ( order facts according to publication date ) do not always yield coherent summaries .</sentence>
				<definiendum id="0">chronological ordering</definiendum>
				<definiens id="0">facts according to publication date ) do not always yield coherent summaries</definiens>
			</definition>
			<definition id="6">
				<sentence>We measure search performance using an Estimated Search Error ( ESE ) figure , which reports the percentage of times when the search algorithm proposes a sentence order which scores lower than Overall performance TAU QUAKES ACCID .</sentence>
				<definiendum id="0">Estimated Search Error</definiendum>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .</sentence>
				<definiendum id="0">discriminative model</definiendum>
				<definiens id="0">is estimated on a small supervised training set</definiens>
			</definition>
			<definition id="1">
				<sentence>Moreover , the CRF has efficient training and decoding processes which both find globally optimal solutions .</sentence>
				<definiendum id="0">CRF</definiendum>
				<definiens id="0">has efficient training</definiens>
			</definition>
			<definition id="2">
				<sentence>These models treat word alignment as a hidden process , and maximise the probability of the observed ( e , f ) sentence pairs1 using the expectation maximisation ( EM ) algorithm .</sentence>
				<definiendum id="0">expectation maximisation</definiendum>
				<definiens id="0">a hidden process , and maximise the probability of the observed ( e , f ) sentence pairs1 using the</definiens>
			</definition>
			<definition id="3">
				<sentence>We use a conditional random field ( CRF ) sequence model , which allows for globally optimal training and decoding ( Lafferty et al. , 2001 ) .</sentence>
				<definiendum id="0">CRF</definiendum>
			</definition>
			<definition id="4">
				<sentence>We use L-BFGS , an iterative quasi-Newton optimisation method , which performs well for training log-linear models ( Malouf , 2002 ; Sha and Pereira , 2003 ) .</sentence>
				<definiendum id="0">iterative quasi-Newton optimisation method</definiendum>
				<definiens id="0">performs well for training log-linear models</definiens>
			</definition>
			<definition id="5">
				<sentence>A common measure of word association is the Dice coefficient ( Dice , 1945 ) : Dice ( e , f ) = 2×CEF ( e , f ) C E ( e ) + CF ( e ) where CE and CF are counts of the occurrences of the words e and f in the corpus , while CEF is theirco-occurrencecount .</sentence>
				<definiendum id="0">Dice coefficient</definiendum>
				<definiens id="0">e , f ) C E ( e ) + CF ( e ) where CE and CF are counts of the occurrences of the words e and f in the corpus</definiens>
			</definition>
</paper>

		<paper id="1106">
			<definition id="0">
				<sentence>EBM is a widely-accepted paradigm for medical practice that involves the explicit use of current best evidence , i.e. , high-quality patient-centered clinical researchreportedintheprimarymedicalliterature , to make decisions about patient care .</sentence>
				<definiendum id="0">EBM</definiendum>
				<definiens id="0">a widely-accepted paradigm for medical practice that involves the explicit use of current best evidence , i.e. , high-quality patient-centered clinical researchreportedintheprimarymedicalliterature , to make decisions about patient care</definiens>
			</definition>
			<definition id="1">
				<sentence>Toobtainmoredetail , the physician can pull up the complete abstract text , and finally the electronic version of the entire article ( if available ) .</sentence>
				<definiendum id="0">Toobtainmoredetail</definiendum>
				<definiens id="0">the physician can pull up the complete abstract text , and finally the electronic version of the entire article</definiens>
			</definition>
			<definition id="2">
				<sentence>Ascanbeseen , thissemanticresourceprovides a powerful tool for organizing search results .</sentence>
				<definiendum id="0">Ascanbeseen</definiendum>
			</definition>
</paper>

		<paper id="1005">
</paper>

		<paper id="1064">
			<definition id="0">
				<sentence>Tiger is better suited for the extraction of subcategorization information ( and thus the translation into “deep” grammars of any kind ) , since it distinguishes between PP complements and modifiers , and includes “secondary” edges to indicate shared arguments in coordinate constructions .</sentence>
				<definiendum id="0">Tiger</definiendum>
				<definiens id="0">distinguishes between PP complements and modifiers , and includes “secondary” edges to indicate shared arguments in coordinate constructions</definiens>
			</definition>
			<definition id="1">
				<sentence>Non-orderpreserving type-raising is used for topicalization : Application : CGBPCH CH B5 CG CH CGD2CH B5 CG Composition : CGBPCH CHBPCI B5 BU CGBPCI CGBPCH CHD2CI B5 BU CGD2CI CHD2CI CGD2CH B5 BU CGD2CI CHBPCI CGD2CH B5 BU CGBPCI Type-raising : CG B5 CC CCD2B4CCBPCGB5 Topicalization : CG B5 CC CCBPB4CCBPCGB5 Hockenmaier and Steedman ( 2005 ) advocate the use of additional “type-changing” rules to deal with complex adjunct categories ( e.g. B4C6C8D2C6C8B5 B5 CBCJD2CVCLD2C6C8 for ing-VPs that act as noun phrase modifiers ) .</sentence>
				<definiendum id="0">Non-orderpreserving type-raising</definiendum>
				<definiendum id="1">CGBPCH CH B5 CG CH CGD2CH B5 CG Composition</definiendum>
				<definiendum id="2">CGBPCH CHBPCI B5 BU CGBPCI CGBPCH CHD2CI B5 BU CGD2CI CHD2CI CGD2CH B5 BU CGD2CI CHBPCI CGD2CH B5 BU CGBPCI Type-raising</definiendum>
				<definiens id="0">CG B5 CC CCD2B4CCBPCGB5 Topicalization : CG B5 CC CCBPB4CCBPCGB5 Hockenmaier and Steedman ( 2005 ) advocate the use of additional “type-changing” rules to deal with complex adjunct categories ( e.g. B4C6C8D2C6C8B5 B5 CBCJD2CVCLD2C6C8 for ing-VPs that act as noun phrase modifiers )</definiens>
			</definition>
			<definition id="2">
				<sentence>The relative pronoun is a dative object ( edge label DA ) of the embedded infinitive , and is therefore attached at the VP level .</sentence>
				<definiendum id="0">relative pronoun</definiendum>
				<definiens id="0">a dative object ( edge label DA ) of the embedded infinitive</definiens>
			</definition>
			<definition id="3">
				<sentence>We insert NPs into PPs , nouns into NPs 3 , and change sentences whose first element is a complementizer ( dass , ob , etc. ) into an SBAR ( a category which does not exist in the original Tiger annotation ) with S argu3 The span of nouns is given by the NK edge label .</sentence>
				<definiendum id="0">SBAR</definiendum>
				<definiens id="0">a category which does not exist in the original Tiger annotation ) with S argu3 The span of nouns is given by the NK edge label</definiens>
			</definition>
			<definition id="4">
				<sentence>N C BD C BE ... C CX ... C D2A0BD C D2 Assuming the CCG category of C6 is CG , and its head position is CX , the algorithm traverses first the left nodes BV BD ... BV CXA0BD from left to right to create a right-branching derivation tree , and then the right nodes ( BV D2 ... BV CXB7BD ) from right to left to create a left-branching tree .</sentence>
				<definiendum id="0">CX</definiendum>
				<definiens id="0">the left nodes BV BD ... BV CXA0BD from left to right to create a right-branching derivation tree , and then the right nodes ( BV D2 ... BV CXB7BD ) from right to left to create a left-branching tree</definiens>
			</definition>
			<definition id="5">
				<sentence>Relative clauses , wh-questions and free relatives are all annotated as S-nodes , and the wh-word is a normal argument of the verb .</sentence>
				<definiendum id="0">wh-word</definiendum>
				<definiens id="0">a normal argument of the verb</definiens>
			</definition>
			<definition id="6">
				<sentence>CCG uses type-raising and composition to combine the incomplete conjuncts into one constituent which combines with the shared element : liest immer und beantwortet gerne jeden Brief .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiens id="0">uses type-raising and composition to combine the incomplete conjuncts into one constituent which combines with the shared element</definiens>
			</definition>
			<definition id="7">
				<sentence>Since the Tiger corpus contains complete morphological and lemma information for all words , future work will address the question of how to identify and apply a set of ( non-recursive ) lexical rules ( Carpenter , 1992 ) to the extracted CCG lexicon to create a much larger lexicon .</sentence>
				<definiendum id="0">non-recursive ) lexical rules</definiendum>
				<definiens id="0">contains complete morphological and lemma information for all words</definiens>
			</definition>
</paper>

		<paper id="2016">
			<definition id="0">
				<sentence>A HHMM is a structured multi-level stochastic process , and can be visualised as a tree structured HMM ( see Figure 1 ( b ) ) .</sentence>
				<definiendum id="0">HHMM</definiendum>
				<definiens id="0">a structured multi-level stochastic process</definiens>
			</definition>
			<definition id="1">
				<sentence>I. Calculate the observation probabilities ¯O : Every observation in each internal state Si is re-calculated by summing up all the observation probabilities in each production state Sj as : ¯Oi , t = Nisummationdisplay j=1 Oj , t , ( 1 ) where time t corresponds to a position in the sequence , O is an observation sequence over t , Oj , t is the observation probability for state Sj at time t , and Ni represents the number of production states for internal state Si .</sentence>
				<definiendum id="0">O</definiendum>
				<definiendum id="1">Ni</definiendum>
				<definiens id="0">an observation sequence over t</definiens>
			</definition>
			<definition id="2">
				<sentence>Reform transition probability ¯A ( i ) : Each internal state Si reforms a new 3 × 3 transition probability matrix ¯A , which records the transition status for the transform matrix .</sentence>
				<definiendum id="0">Reform transition probability ¯A ( i )</definiendum>
				<definiendum id="1">transition probability matrix ¯A</definiendum>
				<definiens id="0">records the transition status for the transform matrix</definiens>
			</definition>
			<definition id="3">
				<sentence>The formula for the estimated cells in ¯A are : ¯A ( i ) in , stay = Nisummationdisplay j=1 pij ( 5 ) ¯A ( i ) in , out = Nisummationdisplay j=1 pij 2 ( 6 ) ¯A ( i ) stay , stay = Ni , Nisummationdisplay k=1 , j=1 Ak , j ( 7 ) ¯A ( i ) stay , out = Nisummationdisplay j=1 τj ( 8 ) where Ni is the number of child states for state Si , ¯A ( i ) in , stay is estimated by summing 122 up all entry state probabilities for state Si , ¯A ( i ) in , out is estimated from the observation that 50 % of sequences transit from state s ( i ) in directly to state s ( i ) out , ¯A ( i ) stay , stay is the sum of all the internal transition probabilities within state Si , and ¯A ( i ) stay , out is the sum of all exit state probabilities .</sentence>
				<definiendum id="0">Ni</definiendum>
				<definiendum id="1">stay</definiendum>
				<definiens id="0">the number of child states for state Si</definiens>
			</definition>
			<definition id="4">
				<sentence>Partial flattening is a process for reducing the depth of hierarchical structure trees .</sentence>
				<definiendum id="0">Partial flattening</definiendum>
			</definition>
			<definition id="5">
				<sentence>The log-likelihood ratio of x and y is defined as : logL ( x , y ) = ll ( k1n 1 , k1 , n1 ) + ll ( k2n 2 , k2 , n2 ) −ll ( k1 + k2n 1 + n2 , k1 , n1 ) −ll ( k1 + k2n 1 + n2 , k2 , n2 ) ( 10 ) where k1 = C ( x , y ) , n1 = C ( x , ∗ ) , k2 = C ( ¬x , y ) , n2 = C ( ¬x , ∗ ) and ll ( p , k , n ) = klog ( p ) + ( n−k ) log ( 1−p ) ( 11 ) The system computes dependency values between states ( tree nodes ) or observations ( tree leaves ) in the tree in the same way .</sentence>
				<definiendum id="0">y</definiendum>
				<definiendum id="1">k2 = C</definiendum>
				<definiens id="0">p , k , n ) = klog ( p ) + ( n−k ) log ( 1−p ) ( 11 ) The system computes dependency values between states ( tree nodes ) or observations ( tree leaves ) in the tree in the same way</definiens>
			</definition>
			<definition id="6">
				<sentence>term dependency value NN1 IO 570.55 IO JJ 570.55 JJ CC 570.55 CC JJ 570.55 JJ NN2 295.24 AT1 JJ 294.25 JJ NN1 294.25 Table 1 : Observation dependency values of partof-speech tags This paper determines the high dependency values by selecting the top n values from a list of all possible terms ranked by either observation or state dependency values , where n is a parameter that can be configured by the user for better performance .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a parameter that can be configured by the user for better performance</definiens>
			</definition>
			<definition id="7">
				<sentence>The first evaluation presents preliminary evidence that the merged hierarchical hidden Markov Model ( MHHMM ) is able to produce more accurate results either a plain HHMM or a HMM during the text chunking task .</sentence>
				<definiendum id="0">MHHMM</definiendum>
				<definiens id="0">able to produce more accurate results either a plain HHMM or a HMM during the text chunking task</definiens>
			</definition>
			<definition id="8">
				<sentence>50 100 150 200 0 20 40 60 80 number of sentences seconds A : HHMM B : HHMM−tree C : HMM Figure 7 : The average processing time for text chunking Figure 7 represents the average processing time for testing ( in seconds ) for the 10-fold cross validation .</sentence>
				<definiendum id="0">HHMM B</definiendum>
				<definiens id="0">the average processing time for testing ( in seconds</definiens>
			</definition>
</paper>

		<paper id="2049">
			<definition id="0">
				<sentence>ACT : Container TERM : A.PAT : Containee Figure 2 : Interpreted representation of the utterance all A are contained in K ( B ) The linguistic analysis consists of semantic parsing followed by contextually motivated embedding and enhancements .</sentence>
				<definiendum id="0">Container TERM</definiendum>
				<definiens id="0">Interpreted representation of the utterance all A are contained in K ( B ) The linguistic analysis consists of semantic parsing followed by contextually motivated embedding and enhancements</definiens>
			</definition>
			<definition id="1">
				<sentence>The rules consist of a pattern and an action part .</sentence>
				<definiendum id="0">rules</definiendum>
			</definition>
			<definition id="2">
				<sentence>Within a proposition , arguments and modi ers are accessed by Case ( x , y ) , where y speci es the ller of Case in x , and indices express constraints on identity or distinctiveness of the relations .</sentence>
				<definiendum id="0">y speci</definiendum>
				<definiens id="0">es the ller of Case in x , and indices express constraints on identity or distinctiveness of the relations</definiens>
			</definition>
			<definition id="3">
				<sentence>The procedure consists of two main parts ( see Figure 6 ) .</sentence>
				<definiendum id="0">procedure</definiendum>
			</definition>
			<definition id="4">
				<sentence>The call &lt; X − swap ( Scope1 ) &gt; , with X being either Case , Argument , Mixed , or Prop expresses building a set of all possible instantiations of the pattern speci ed when applied to Scope1 .</sentence>
				<definiendum id="0">Prop</definiendum>
			</definition>
</paper>

		<paper id="4018">
			<definition id="0">
				<sentence>The Natural Language Toolkit is a suite of program modules , data sets and tutorials supporting research and teaching in computational linguistics and natural language processing .</sentence>
				<definiendum id="0">Natural Language Toolkit</definiendum>
				<definiens id="0">a suite of program modules , data sets and tutorials supporting research and teaching in computational linguistics and natural language processing</definiens>
			</definition>
			<definition id="1">
				<sentence>NLTK is written in Python and distributed under the GPL open source license .</sentence>
				<definiendum id="0">NLTK</definiendum>
			</definition>
			<definition id="2">
				<sentence>NLTK has been used successfully as a teaching tool , as an individual study tool , and as a platform for prototyping and building research systems ( Liddy and McCracken , 2005 ; Sætre et al. , 2005 ) .</sentence>
				<definiendum id="0">NLTK</definiendum>
				<definiens id="0">a teaching tool , as an individual study tool</definiens>
			</definition>
			<definition id="3">
				<sentence>As an object-oriented language , Python permits data and code to be encapsulated and re-used easily .</sentence>
				<definiendum id="0">Python</definiendum>
				<definiens id="0">permits data and code to be encapsulated and re-used easily</definiens>
			</definition>
			<definition id="4">
				<sentence>The regular expression tagger assigns a tag to a token according to a series of string patterns .</sentence>
				<definiendum id="0">regular expression tagger</definiendum>
				<definiens id="0">assigns a tag to a token according to a series of string patterns</definiens>
			</definition>
			<definition id="5">
				<sentence>tag ( tokens ) ) [ ( ’John’ , ’np’ ) , ( ’saw’ , ’vbd’ ) , ( ’the’ , ’at’ ) , ( ’books’ , ’nns’ ) , ( ’on’ , ’in’ ) , ( ’the’ , ’at’ ) , ( ’table’ , ’nn’ ) ] We can go on to define and train a bigram tagger , as shown below : &gt; &gt; &gt; bigram_tagger =\ ... tag .</sentence>
				<definiendum id="0">tag</definiendum>
				<definiens id="0">shown below : &gt; &gt; &gt; bigram_tagger =\ ... tag</definiens>
			</definition>
			<definition id="6">
				<sentence>70 Chunking is a technique for shallow syntactic analysis of ( tagged ) text .</sentence>
				<definiendum id="0">Chunking</definiendum>
			</definition>
			<definition id="7">
				<sentence>NLTK provides several parsers for context-free phrase-structure grammars .</sentence>
				<definiendum id="0">NLTK</definiendum>
			</definition>
			<definition id="8">
				<sentence>NLTK also supports probabilistic context free grammars , and provides a Viterbi-style PCFG parser , together with a suite of bottom-up probabilistic chart parsers .</sentence>
				<definiendum id="0">NLTK</definiendum>
				<definiens id="0">supports probabilistic context free grammars , and provides a Viterbi-style PCFG parser</definiens>
			</definition>
			<definition id="9">
				<sentence>NLTK provides interactive graphical user interfaces , making it possible to view program state and to study program execution step-by-step ( e.g. see Figure 1 ) .</sentence>
				<definiendum id="0">NLTK</definiendum>
				<definiens id="0">provides interactive graphical user interfaces</definiens>
			</definition>
			<definition id="10">
				<sentence>NLTK is a unique framework for teaching natural language processing .</sentence>
				<definiendum id="0">NLTK</definiendum>
			</definition>
</paper>

		<paper id="3014">
			<definition id="0">
				<sentence>The conventional accuracy metrics for parsing ( LR/LP ) should not be taken as the only metrics in determining the feasibility of applying statistical parsers to spoken language .</sentence>
				<definiendum id="0">conventional accuracy metrics for parsing</definiendum>
				<definiens id="0">the only metrics in determining the feasibility of applying statistical parsers to spoken language</definiens>
			</definition>
</paper>

		<paper id="1046">
			<definition id="0">
				<sentence>361 A context relation is defined as a tuple ( w , r , wprime ) where w is a term , which occurs in some grammatical relation r with another word wprime in some sentence .</sentence>
				<definiendum id="0">context relation</definiendum>
				<definiendum id="1">w</definiendum>
				<definiens id="0">a term , which occurs in some grammatical relation r with another word wprime in some sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Random Indexing ( RI ) is a hashing technique based on Sparse Distributed Memory ( Kanerva , 1993 ) .</sentence>
				<definiendum id="0">RI )</definiendum>
			</definition>
			<definition id="2">
				<sentence>Karlgren and Sahlgren ( 2001 ) showed RI produces results similar to LSA using the Test of English as a Foreign Language ( TOEFL ) evaluation .</sentence>
				<definiendum id="0">RI</definiendum>
				<definiens id="0">produces results similar to LSA using the Test of English as a Foreign Language</definiens>
			</definition>
			<definition id="3">
				<sentence>The vectors consist of a large number of 0s and small number ( epsilon1 ) number of randomly distributed 1s .</sentence>
				<definiendum id="0">vectors</definiendum>
				<definiens id="0">consist of a large number of 0s and small number ( epsilon1 ) number of randomly distributed 1s</definiens>
			</definition>
			<definition id="4">
				<sentence>LSH is a probabilistic technique that allows the approximation of a similarity function .</sentence>
				<definiendum id="0">LSH</definiendum>
				<definiens id="0">a probabilistic technique that allows the approximation of a similarity function</definiens>
			</definition>
			<definition id="5">
				<sentence>PLEB is a randomised structure that uses the bit signatures generated by LSH .</sentence>
				<definiendum id="0">PLEB</definiendum>
				<definiens id="0">a randomised structure that uses the bit signatures generated by LSH</definiens>
			</definition>
			<definition id="6">
				<sentence>The SASH is a directed , edge-weighted graph with the following properties ( see Figure 1 ) : Each term corresponds to a unique node .</sentence>
				<definiendum id="0">SASH</definiendum>
				<definiens id="0">a directed , edge-weighted graph with the following properties</definiens>
			</definition>
			<definition id="7">
				<sentence>Construction begins with the nodes being randomly distributed between the levels .</sentence>
				<definiendum id="0">Construction</definiendum>
			</definition>
			<definition id="8">
				<sentence>DIRECT is the percentage of returned synonyms found in the gold standard .</sentence>
				<definiendum id="0">DIRECT</definiendum>
				<definiens id="0">the percentage of returned synonyms found in the gold standard</definiens>
			</definition>
			<definition id="9">
				<sentence>INVR is the sum of the inverse rank of each matching synonym , e.g. matches at ranks 3 , 5 and 28 365 CORPUS CUT-OFF TERMS AVERAGE RELATIONS PER TERM BNC 0 246,067 43 5 88,926 116 100 14,862 617 LARGE 0 541,722 97 5 184,494 281 100 35,618 1,400 Table 1 : Extracted Context Information give an inverse rank score of 13 + 15 + 128 .</sentence>
				<definiendum id="0">INVR</definiendum>
				<definiens id="0">the sum of the inverse rank of each matching synonym</definiens>
				<definiens id="1">Extracted Context Information give an inverse rank score of 13 + 15 + 128</definiens>
			</definition>
			<definition id="10">
				<sentence>SASH allows the free use of weight and measure functions , but RI is constrained by having to transform any context space into a RI space .</sentence>
				<definiendum id="0">SASH</definiendum>
				<definiendum id="1">RI</definiendum>
				<definiens id="0">allows the free use of weight and measure functions , but</definiens>
			</definition>
</paper>

		<paper id="2098">
			<definition id="0">
				<sentence>If the tokens at index r − 1 and r are in the same chunk , and C is the label of that chunk , the first layer also includes part 〈C , P0 , P , r−1 , r〉 ( where P0 and P are the POS tags of the tokens at r − 1 and r Token First Layer ( POS ) Second Layer ( NP ) U.K. 〈I , JADJ,0〉 〈I , JADJ , NOUN,0,1〉 base 〈I , NOUN,1〉 〈I , NOUN , NOUN,1,2〉 rates 〈I , NOUN,2〉 〈I,0,2〉 〈I , O,2,3〉 are 〈O , VERB,3〉 〈O , VERB , OTHER,3,4〉 at 〈O , OTHER,4〉 〈O,3,4〉 〈O , I,4,5〉 their 〈I , OTHER,5〉 〈I , OTHER , JADJ,5,6〉 highest 〈I , JADJ,6〉 〈I , JADJ , NOUN,6,7〉 level 〈I , NOUN,7〉 〈I,5,7〉 〈I , O,7,8〉 in 〈O , OTHER,8〉 〈O,8,8〉 〈O , I,8,9〉 eight 〈I , OTHER,9〉 〈I , OTHER , NOUN,9,10〉 years 〈I , NOUN,10〉 〈I,9,10〉 〈I , O,10,11〉 .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">r Token First Layer ( POS ) Second Layer</definiendum>
				<definiendum id="2">NOUN</definiendum>
				<definiendum id="3">〈I , OTHER,5〉 〈I</definiendum>
				<definiens id="0">the label of that chunk , the first layer also includes part 〈C , P0 , P , r−1 , r〉 ( where P0 and P are the POS tags of the tokens at r − 1 and</definiens>
			</definition>
			<definition id="1">
				<sentence>( 2nd Layer , NP ) score : = score + s ( 〈C , q , r − 1〉 ) ; if ( index start &lt; q ) # Add the score of the chunk transition from q-1 to q. ( 2nd Layer , NP ) score : = score + s ( 〈C0 , C , q − 1 , q〉 ) + chunk table [ q ] [ C0 ] ; if ( score &gt; = chunk table [ r ] [ C ] ) chunk table [ r ] [ C ] : = score ; end for end for end for end for end for end for score : = 0 ; for each C in chunk tags if ( chunk table [ index end ] [ C ] &gt; = score ) score : = chunk table [ index end ] [ C ] ; last symbol : = C ; end for return ( score ) Note : Since the scoring function s ( p ) is defined as w⊤f ( xi , { p } ) , the input sequence xi and the weight vector w are also the inputs to the algorithm .</sentence>
				<definiendum id="0">end for return</definiendum>
				<definiens id="0">〈C , q , r − 1〉 ) ; if ( index start &lt; q ) # Add the score of the chunk transition from q-1 to q. ( 2nd Layer , NP ) score : = score + s ( 〈C0 , C , q − 1 , q〉 ) + chunk table [ q ] [ C0 ] ; if ( score &gt; = chunk table [ r ] [ C ] ) chunk table [ r ] [ C ] : = score</definiens>
				<definiens id="1">in chunk tags if ( chunk table [ index end ] [ C ] &gt; = score ) score : = chunk table [ index end ] [ C ] ; last symbol : = C ;</definiens>
				<definiens id="2">w⊤f ( xi , { p } ) , the input sequence xi and the weight vector w are also the inputs to the algorithm</definiens>
			</definition>
</paper>

		<paper id="1061">
			<definition id="0">
				<sentence>Hidden Markov models ( HMMs ) are powerful statistical models that have found successful applications in Information Extraction ( IE ) .</sentence>
				<definiendum id="0">Hidden Markov models</definiendum>
				<definiendum id="1">HMMs</definiendum>
			</definition>
			<definition id="1">
				<sentence>Formally , a hidden Markov model ( HMM ) is specified by a five-tuple ( S , K , Π , A , B ) , where S is a set of states ; K is the alphabet of observation symbols ; Π is the initial state distribution ; A is the probability distribution of state transitions ; and B is the probability distribution of symbol emissions .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiendum id="1">B</definiendum>
				<definiendum id="2">S</definiendum>
				<definiendum id="3">K</definiendum>
				<definiendum id="4">Π</definiendum>
				<definiendum id="5">B</definiendum>
				<definiens id="0">a set of states ;</definiens>
				<definiens id="1">the alphabet of observation symbols</definiens>
			</definition>
			<definition id="2">
				<sentence>The Simple Good-Turning ( SGT ) smoothing ( Gale and Sampson , 1995 ) is a simple version of Good-Turning approach , which is a population frequency estimator used to adjust the observed term frequencies to estimate the real population term frequencies .</sentence>
				<definiendum id="0">Simple Good-Turning ( SGT ) smoothing</definiendum>
				<definiens id="0">a simple version of Good-Turning approach , which is a population frequency estimator used to adjust the observed term frequencies to estimate the real population term frequencies</definiens>
			</definition>
			<definition id="3">
				<sentence>For each r observed in the sample , the GoodTurning method gives an estimation for its real population frequency as r∗ = ( r + 1 ) E ( nr+1 ) E ( nr ) , where E ( nr ) is the expected number of terms with frequency r. For unseen events , an amount of probability P0 is assigned to all these unseen events , P0 = E ( n1 ) N ≈ n1N , where N is the total number of term occurrences in the sample .</sentence>
				<definiendum id="0">E ( nr )</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the expected number of terms with frequency r. For unseen events</definiens>
				<definiens id="1">the total number of term occurrences in the sample</definiens>
			</definition>
			<definition id="4">
				<sentence>The data set consists of 485 annotated seminar announcements , with the fillers for the following four slots specified for each seminar : location ( the location of a seminar ) , speaker ( the speaker of a seminar ) , stime ( the starting time of a seminar ) and etime ( the ending time of a seminar ) .</sentence>
				<definiendum id="0">etime</definiendum>
				<definiens id="0">the location of a seminar ) , speaker ( the speaker of a seminar ) , stime ( the starting time of a seminar</definiens>
				<definiens id="1">the ending time of a seminar )</definiens>
			</definition>
			<definition id="5">
				<sentence>The performance numbers from other HMM IE systems ( Freitag and McCallum , 1999 ) are also listed in Table 1 for comparison , where HMM None is their HMM IE system that uses absolute discounting but with no shrinkage , and HMM Global is the representative version of their HMM IE system with shrinkage .</sentence>
				<definiendum id="0">HMM None</definiendum>
				<definiendum id="1">HMM Global</definiendum>
				<definiens id="0">their HMM IE system that uses absolute discounting but with no shrinkage</definiens>
				<definiens id="1">the representative version of their HMM IE system with shrinkage</definiens>
			</definition>
			<definition id="6">
				<sentence>l ( s ) = logparenleftbigmax all Q P ( Q , s|λ ) parenrightbig× 1n , ( 1 ) where λ is the HMM and Q is any possible state sequence associated with s. All the retrieved segments are then ranked according to their l ( s ) , and the segment with the highest l ( s ) number is selected and the extraction is identified from its labelled state sequence by the segment HMM .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiendum id="1">Q</definiendum>
				<definiens id="0">ranked according to their l ( s ) , and the segment with the highest l ( s ) number is selected and the extraction is identified from its labelled state sequence by the segment HMM</definiens>
			</definition>
			<definition id="7">
				<sentence>Let s = O1O2···OT , where T is the length of s in tokens .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the length of s in tokens</definiens>
			</definition>
			<definition id="8">
				<sentence>The probability of s following this particular background state path Qbg can be easily calculated with respect to the HMM λ as follows : P ( s , Qbg|λ ) =piqbgbqbg ( O1 ) aqbgqbgbqbg ( O2 ) ···aqbgqbgbqbg ( OT ) , where pii is the initial state probability for state i , bi ( Ot ) is the emission probability of symbol Ot at state i , and aij is the state transition probability from state i to state j. We know that the probability of observing s given the HMM λ actually sums over the probabilities of observing s on all the possible state sequences given the HMM , i.e. , P ( s|λ ) = summationdisplay all Q P ( s , Q|λ ) Let Qfiller denote the set of state sequences that pass through any filler states .</sentence>
				<definiendum id="0">HMM λ</definiendum>
				<definiendum id="1">OT</definiendum>
				<definiendum id="2">pii</definiendum>
				<definiendum id="3">aij</definiendum>
				<definiens id="0">the state transition probability from state i to state j. We know that the probability of observing s given the HMM λ actually sums over the probabilities of observing s on all the possible state sequences given the HMM , i.e. , P ( s|λ ) = summationdisplay all Q P ( s , Q|λ ) Let Qfiller denote the set of state sequences that pass through any filler states</definiens>
			</definition>
			<definition id="9">
				<sentence>P ( s|λ ) can be calculated efficiently using the forward-backward procedure which makes the estimate for the total probability of all state paths that go through filler states straightforward to be : P ( s , Qfiller|λ ) ∆= summationdisplay allQ∈Qfiller P ( s , Q|λ ) = P ( s|λ ) −P ( s , Qbg|λ ) .</sentence>
				<definiendum id="0">P ( s|λ )</definiendum>
			</definition>
			<definition id="10">
				<sentence>A document is least correctly filtered by the segment retrieval system when at least one of the extraction relevant segments in that document has been retrieved by the system ; otherwise , we say the system fails on that document .</sentence>
				<definiendum id="0">document</definiendum>
				<definiens id="0">least correctly filtered by the segment retrieval system when at least one of the extraction relevant segments in that document has been retrieved by the system</definiens>
			</definition>
			<definition id="11">
				<sentence>The overall segment retrieval performance is measured by retrieval precision ( i.e. , ratio of the number of correctly filtered documents to the number of documents from which the system has retrieved at least one segments ) and retrieval recall ( i.e. , ratio of the number of correctly filtered documents to the number of documents that contain relevant segments ) .</sentence>
				<definiendum id="0">retrieval precision</definiendum>
				<definiendum id="1">retrieval recall</definiendum>
				<definiens id="0">the system has retrieved at least one segments</definiens>
			</definition>
</paper>

		<paper id="1102">
			<definition id="0">
				<sentence>where Simi is the similarity of the component word at position i in the phrase , and C1 and C2 are scaling constants such that C2lessmuchC1 .</sentence>
				<definiendum id="0">Simi</definiendum>
				<definiens id="0">the similarity of the component word at position i in the phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>In turn , the similarity score of a component word Simi is higher if : a ) the computed word-toword similarity scores are higher relative to words at the same position i in the seeds ; and b ) the component word is similar to words from more than one seed fact .</sentence>
				<definiendum id="0">b</definiendum>
				<definiens id="0">higher if : a ) the computed word-toword similarity scores are higher relative to words at the same position i in the seeds</definiens>
			</definition>
</paper>

		<paper id="2066">
			<definition id="0">
				<sentence>A gap is a discontinuity in the projection of a node in a dependency graph ( Plátek et al. , 2001 ) .</sentence>
				<definiendum id="0">gap</definiendum>
			</definition>
			<definition id="1">
				<sentence>G/ , is the maximum among the gap degrees of its nodes .</sentence>
				<definiendum id="0">G/</definiendum>
			</definition>
			<definition id="2">
				<sentence>The non-projective dependency grammar of Kahane et al. ( 1998 ) is based on an operation on dependency trees called lifting : a ‘lift’ of a tree T is the new tree that is obtained when one replaces one 2We use the term edge degree instead of the original simple term degree from Nivre ( 2006 ) to mark the distinction from the notion of gap degree .</sentence>
				<definiendum id="0">non-projective dependency grammar</definiendum>
				<definiens id="0">based on an operation on dependency trees called lifting : a ‘lift’ of a tree T is the new tree that is obtained when one replaces one 2We use the term edge degree instead of the original simple term degree from Nivre</definiens>
			</definition>
			<definition id="3">
				<sentence>In particular , chart-based parsers for grammar formalisms in which derivations obey the well-nestedness constraint ( such as Tree Adjoining Grammar ) are not hampered by the ‘crossing configurations’ to which Satta ( 1992 ) attributes the fact that the universal recognition problem of Linear Context-Free Rewriting Systems isNP-complete .</sentence>
				<definiendum id="0">well-nestedness constraint</definiendum>
				<definiens id="0">such as Tree Adjoining Grammar</definiens>
			</definition>
			<definition id="4">
				<sentence>DDT comprises 100k words of text selected from the Danish PAROLE corpus , with annotation 511 Table 1 : Experimental results for DDT and PDT property DDT PDT all structures n D 4393 n D 73088 gap degree 0 3732 84.95 % 56168 76.85 % gap degree 1 654 14.89 % 16608 22.72 % gap degree 2 7 0.16 % 307 0.42 % gap degree 3 – – 4 0.01 % gap degree 4 – – 1 &lt; 0.01 % edge degree 0 3732 84.95 % 56168 76.85 % edge degree 1 584 13.29 % 16585 22.69 % edge degree 2 58 1.32 % 259 0.35 % edge degree 3 17 0.39 % 63 0.09 % edge degree 4 2 0.05 % 10 0.01 % edge degree 5 – – 2 &lt; 0.01 % edge degree 6 – – 1 &lt; 0.01 % projective 3732 84.95 % 56168 76.85 % planar 3796 86.41 % 60048 82.16 % well-nested 4388 99.89 % 73010 99.89 % non-projective structures only n D 661 n D 16920 planar 64 9.68 % 3880 22.93 % well-nested 656 99.24 % 16842 99.54 % of primary and secondary dependencies based on Discontinuous Grammar ( Kromann , 2003 ) .</sentence>
				<definiendum id="0">Danish PAROLE corpus</definiendum>
				<definiendum id="1">PDT property DDT PDT all</definiendum>
			</definition>
			<definition id="5">
				<sentence>For the parametric constraints ( gap degree , edge degree ) , we report the number and percentage of structures having degree d ( d NAK 0 ) , where degree 0 is equivalent ( for both gap degree and edge degree ) to projectivity .</sentence>
				<definiendum id="0">degree</definiendum>
				<definiens id="0">edge degree</definiens>
				<definiens id="1">equivalent ( for both gap degree and edge degree ) to projectivity</definiens>
			</definition>
			<definition id="6">
				<sentence>The planarity constraint appears to be of little use as a generalization of projectivity : enforcing it excludes more than 75a37 of the non-projective data in PDT , and 90a37of the data in DDT .</sentence>
				<definiendum id="0">planarity constraint</definiendum>
				<definiens id="0">a generalization of projectivity : enforcing it excludes more than 75a37 of the non-projective data in PDT</definiens>
			</definition>
</paper>

		<paper id="2107">
			<definition id="0">
				<sentence>In our implementation for the monotone model , we define a hypothesis search as the triple ( Jprime , tIprime1 , g ) , where Jprime is the length of the source prefix we are translating ( i.e. sJprime1 ) ; the sequence of Iprime words , tIprime1 , is the target prefix that has been generated and g is the score of the hypothesis ( g = Pr ( tIprime1 ) ·Pr ( tIprime1 |sJprime1 ) λ ) .</sentence>
				<definiendum id="0">g</definiendum>
				<definiens id="0">a hypothesis search as the triple ( Jprime , tIprime1 , g ) , where Jprime is the length of the source prefix we are translating ( i.e. sJprime1 ) ; the sequence of Iprime words</definiens>
				<definiens id="1">the score of the hypothesis</definiens>
			</definition>
			<definition id="1">
				<sentence>The algorithm consists of an iterative process .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiens id="0">consists of an iterative process</definiens>
			</definition>
			<definition id="2">
				<sentence>The extension consists in selecting one ( or more ) untranslated word ( s ) in the source and selecting one ( or more ) target word ( s ) that are attached to the existing output prefix .</sentence>
				<definiendum id="0">extension</definiendum>
				<definiens id="0">consists in selecting one ( or more ) untranslated word ( s ) in the source and selecting one ( or more ) target word ( s ) that are attached to the existing output prefix</definiens>
			</definition>
</paper>

		<paper id="1048">
			<definition id="0">
				<sentence>The decision-tree model operates over parallel corpora and offers an intuitive formulation of sentence compression in terms of tree rewriting .</sentence>
				<definiendum id="0">decision-tree model</definiendum>
				<definiens id="0">operates over parallel corpora and offers an intuitive formulation of sentence compression in terms of tree rewriting</definiens>
			</definition>
			<definition id="1">
				<sentence>The original score measures the signi cance of each word ( I ) in the compression and the linguistic likelihood ( L ) of the resulting word combinations.2 We add some linguistic knowledge to this formulation through a function ( SOV ) that captures information about subjects , objects and verbs .</sentence>
				<definiendum id="0">original score</definiendum>
				<definiens id="0">measures the signi cance of each word ( I ) in the compression</definiens>
				<definiens id="1">some linguistic knowledge to this formulation through a function ( SOV ) that captures information about subjects , objects and verbs</definiens>
			</definition>
			<definition id="2">
				<sentence>The lambdas ( λI , λSOV , λL ) weight the contribution of the individual scores : S ( V ) = M∑ i=1 λII ( vi ) + λsovSOV ( vi ) +λLL ( vi|vi¡1 , vi¡2 ) ( 1 ) The sentence V = v1 , v2 , ... , vm ( of M words ) that maximises the score S ( V ) is the best compression for an original sentence consisting of N words ( M &lt; N ) .</sentence>
				<definiendum id="0">λSOV , λL )</definiendum>
				<definiens id="0">weight the contribution of the individual scores : S ( V ) = M∑ i=1 λII ( vi ) + λsovSOV</definiens>
				<definiens id="1">the best compression for an original sentence consisting of N words ( M &lt; N )</definiens>
			</definition>
			<definition id="3">
				<sentence>Where wi is the topic word of interest ( topic words are either nouns or verbs ) , fi is the frequency of wi in the document , Fi is the corpus frequency of wi and FA is the sum of all topic word occurrences in the corpus ( ∑i Fi ) .</sentence>
				<definiendum id="0">wi</definiendum>
				<definiendum id="1">Fi</definiendum>
				<definiendum id="2">FA</definiendum>
				<definiens id="0">the topic word of interest ( topic words are either nouns or verbs ) , fi is the frequency of wi in the document</definiens>
				<definiens id="1">the corpus frequency of wi and</definiens>
			</definition>
			<definition id="4">
				<sentence>Ziff-Davis Comp % 88.0 79.0 87.0 84.4 97.0 CompR 73.1 79.0 70.0 73.0 47.0 Table 2 : Compression Rates ( Comp % measures the percentage of sentences compressed ; CompR is the mean compression rate of all sentences ) 1 2 3 4 5 6 7 8 9 10 Length of word span dropped 0 Relative number of drops Annotator 1 Annotator 2 Annotator 3 Ziff-Davis + Figure 1 : Distribution of span of words dropped Comparisons Following the classi cation scheme adopted in the British National Corpus ( Burnard 2000 ) , we assume throughout this paper that Broadcast News and Ziff-Davis belong to different domains ( spoken vs. written text ) whereas they represent the same genre ( i.e. , news ) .</sentence>
				<definiendum id="0">CompR</definiendum>
				<definiendum id="1">same genre</definiendum>
				<definiens id="0">Comp % measures the percentage of sentences compressed</definiens>
				<definiens id="1">the mean compression rate of all sentences</definiens>
				<definiens id="2">Distribution of span of words dropped Comparisons Following the classi cation scheme adopted in the British National Corpus ( Burnard 2000 )</definiens>
			</definition>
			<definition id="5">
				<sentence>It is de ned in ( 4 ) where R is the length of the gold standard string .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the length of the gold standard string</definiens>
			</definition>
			<definition id="6">
				<sentence>RASP failed on 17 sentences from the Broadcast news corpus and 33 from the Ziff-Davis corpus ; Charniak’s ( 2000 ) parser successfully parsed the Broadcast News corpus but failed on three sentences from the Ziff-Davis corpus .</sentence>
				<definiendum id="0">RASP</definiendum>
			</definition>
</paper>

		<paper id="4019">
			<definition id="0">
				<sentence>Our morphosyntactic tagger takes a segmented text as an input ; each form ( simple or compound ) is assigned a set of possible tags , extracted from 5This test and further tests have been carried out on a PC with a 2.8 GHz Intel Pentium Processor and a 512 Mb RAM .</sentence>
				<definiendum id="0">morphosyntactic tagger</definiendum>
				<definiens id="0">takes a segmented text as an input</definiens>
			</definition>
			<definition id="1">
				<sentence>fr/english/ , follow links Linguistic data then Dictionnaries .</sentence>
				<definiendum id="0">fr/english/</definiendum>
			</definition>
			<definition id="2">
				<sentence>Outilex uses a minimal formalism : Recursive Transition Network ( RTN ) ( Woods , 1970 ) that are represented in the form of recursive automata ( automata that call other automata ) .</sentence>
				<definiendum id="0">Outilex</definiendum>
				<definiens id="0">uses a minimal formalism : Recursive Transition Network ( RTN ) ( Woods , 1970 ) that are represented in the form of recursive automata</definiens>
			</definition>
			<definition id="3">
				<sentence>The concordancer is a valuable tool for linguists who are interested in finding the different uses of linguistic forms in corpora .</sentence>
				<definiendum id="0">concordancer</definiendum>
				<definiens id="0">a valuable tool for linguists who are interested in finding the different uses of linguistic forms in corpora</definiens>
			</definition>
</paper>

		<paper id="2083">
			<definition id="0">
				<sentence>Existing terminological resources and scientific databases ( such as Swiss-Prot1 , SGD2 , FlyBase3 , and UniProt4 ) can not keep up-to-date with the growth of neologisms ( Pustejovsky et al. , 2001 ) .</sentence>
				<definiendum id="0">UniProt4</definiendum>
				<definiens id="0">such as Swiss-Prot1 , SGD2 , FlyBase3 , and</definiens>
			</definition>
			<definition id="1">
				<sentence>The tree consists of expressions collected from all sentences with the acronym in parentheses and appearing before the acronym .</sentence>
				<definiendum id="0">tree</definiendum>
				<definiens id="0">consists of expressions collected from all sentences with the acronym in parentheses and appearing before the acronym</definiens>
			</definition>
			<definition id="2">
				<sentence>A node represents a word , and a path from any node to TTF-1 represents a long-form candidate9 .</sentence>
				<definiendum id="0">node</definiendum>
				<definiens id="0">a word , and a path from any node to TTF-1 represents a long-form candidate9</definiens>
			</definition>
			<definition id="3">
				<sentence>HMM Hexamethylmelamine ( HMM ) is a cytotoxic agent demonstrated to have broad antitumor activity .</sentence>
				<definiendum id="0">HMM Hexamethylmelamine ( HMM )</definiendum>
				<definiens id="0">a cytotoxic agent demonstrated to have broad antitumor activity</definiens>
			</definition>
			<definition id="4">
				<sentence>C-value is a domain-independent method for automatic term recognition ( ATR ) which combines linguistic and statistical information , emphasis being placed on the statistical part .</sentence>
				<definiendum id="0">C-value</definiendum>
				<definiens id="0">a domain-independent method for automatic term recognition ( ATR ) which combines linguistic and statistical information , emphasis being placed on the statistical part</definiens>
			</definition>
			<definition id="5">
				<sentence>( 2 ) Therein : w is a long-form candidate ; freq ( x ) denotes the frequency of occurrence of a candidate x in the contextual sentences ( i.e. , co-occurrence frequency with a short form ) ; Tw is a set of nested candidates , long-form candidates each of which consists of a preceding word followed by the candidate w ; and freq ( Tw ) represents the total frequency of such candidates Tw .</sentence>
				<definiendum id="0">w</definiendum>
				<definiendum id="1">freq ( x )</definiendum>
				<definiendum id="2">; Tw</definiendum>
				<definiendum id="3">freq</definiendum>
				<definiens id="0">a long-form candidate ;</definiens>
				<definiens id="1">the frequency of occurrence of a candidate x in the contextual sentences ( i.e. , co-occurrence frequency with a short form )</definiens>
				<definiens id="2">a set of nested candidates , long-form candidates each of which consists of a preceding word followed by the candidate w</definiens>
				<definiens id="3">the total frequency of such candidates Tw</definiens>
			</definition>
			<definition id="6">
				<sentence>The Medstract Gold Standard Evaluation Corpus , which consists of 166 alias pairs annotated to 201 MEDLINE abstracts , is widely used for evaluation ( Chang and Sch¨utze , 2006 ; Schwartz and Hearst , 2003 ) .</sentence>
				<definiendum id="0">Medstract Gold Standard Evaluation Corpus</definiendum>
				<definiens id="0">consists of 166 alias pairs annotated to 201 MEDLINE abstracts</definiens>
			</definition>
</paper>

		<paper id="1034">
			<definition id="0">
				<sentence>Our automatically created generation dictionary consists of triples ( U , R , S ) representing a mapping between the original utterance U in the user review , its semantic representation R ( U ) , and its syntactic structure S ( U ) .</sentence>
				<definiendum id="0">generation dictionary</definiendum>
				<definiens id="0">consists of triples ( U , R , S ) representing a mapping between the original utterance U in the user review , its semantic representation R ( U )</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , the domain ontology consists of the relations : ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ RESTAURANT has foodquality RESTAURANT has servicequality RESTAURANT has valuequality RESTAURANT has atmospherequality RESTAURANT has overallquality RESTAURANT has foodtype RESTAURANT has location We assume that , although users may discuss other attributes of the entity , at least some of the utterancesin the reviewsrealizethe relations specified in the ontology .</sentence>
				<definiendum id="0">domain ontology</definiendum>
				<definiens id="0">consists of the relations : ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ RESTAURANT has foodquality RESTAURANT has servicequality RESTAURANT has valuequality RESTAURANT has atmospherequality RESTAURANT has overallquality RESTAURANT has foodtype RESTAURANT has location We assume that , although users may discuss other attributes of the entity , at least some of the utterancesin the reviewsrealizethe relations specified in the ontology</definiens>
			</definition>
			<definition id="2">
				<sentence>We test the hypothesis that , if an utterance U contains named-entities corresponding to the distinguished attributes , thatR for that utterance includes the relation concerning that attribute in the domain ontology .</sentence>
				<definiendum id="0">thatR</definiendum>
				<definiens id="0">if an utterance U contains named-entities corresponding to the distinguished attributes</definiens>
			</definition>
			<definition id="3">
				<sentence>266 filter filtered retained No Relations Filter 7,947 10,519 Other Relations Filter 5,351 5,168 Contextual Filter 2,973 2,195 Unknown Words Filter 1,467 728 Parsing Filter 216 512 Table 2 : Filtering statistics : the number of sentences filtered and retained by each filter .</sentence>
				<definiendum id="0">Filtering statistics</definiendum>
				<definiens id="0">the number of sentences filtered and retained by each filter</definiens>
			</definition>
			<definition id="4">
				<sentence>Our procedurefor derivingsemanticrepresentationsis based on the hypothesisthat ifU containsnamed-entities that realizethe distinguishedattributes , thatRwill include the relevant relation in the domain ontology .</sentence>
				<definiendum id="0">thatRwill</definiendum>
				<definiens id="0">include the relevant relation in the domain ontology</definiens>
			</definition>
			<definition id="5">
				<sentence>Table 5 shows the most common syntactic patterns ( more than 10 occurrences ) , indicating that 30 % of the learned patterns consist of the simple form “X is ADJ”whereADJ is an adjective , or “X is RB ADJ , ” where RB is a degree modifier .</sentence>
				<definiendum id="0">RB</definiendum>
				<definiens id="0">more than 10 occurrences ) , indicating that 30 % of the learned patterns consist of the simple form “X is ADJ”whereADJ is an adjective , or “X is RB ADJ , ” where</definiens>
				<definiens id="1">a degree modifier</definiens>
			</definition>
			<definition id="6">
				<sentence>Another interesting aspect of the learned mappings is the wide variety of adjectival phrases ( APs ) inthecommonpatterns .</sentence>
				<definiendum id="0">APs</definiendum>
				<definiens id="0">the wide variety of adjectival phrases</definiens>
			</definition>
			<definition id="7">
				<sentence>We evaluate the obtained mappings in two respects : the consistency between the automatically derived semantic representation and the realizafood=1 awful , bad , burnt , cold , very ordinary food=2 acceptable , bad , flavored , not enough , very bland , very good food=3 adequate , bland and mediocre , flavorful but cold , pretty good , rather bland , very good food=4 absolutely wonderful , awesome , decent , excellent , good , good and generous , great , outstanding , rather good , really good , traditional , very fresh and tasty , very good , very very good food=5 absolutely delicious , absolutely fantastic , absolutely great , absolutely terrific , ample , well seasoned and hot , awesome , best , delectable and plentiful , delicious , delicious but simple , excellent , exquisite , fabulous , fancy but tasty , fantastic , fresh , good , great , hot , incredible , just fantastic , large and satisfying , outstanding , plentiful and outstanding , plentiful and tasty , quick and hot , simply great , so delicious , so very tasty , superb , terrific , tremendous , very good , wonderful Table 7 : Adjectival phrases ( APs ) in single scalarvalued relation mappings for foodquality .</sentence>
				<definiendum id="0">Adjectival phrases</definiendum>
				<definiendum id="1">APs</definiendum>
				<definiens id="0">the obtained mappings in two respects : the consistency between the automatically derived semantic representation and the realizafood=1 awful , bad , burnt , cold</definiens>
			</definition>
			<definition id="8">
				<sentence>This gave a total of 173 baseline utterances , which together with 451 learned mappings , 269 service=1 awful , bad , great , horrendous , horrible , inattentive , forgetful and slow , marginal , really slow , silly and inattentive , still marginal , terrible , young service=2 overly slow , very slow and inattentive service=3 bad , bland and mediocre , friendly and knowledgeable , good , pleasant , prompt , very friendly service=4 all very warm and welcoming , attentive , extremely friendly and good , extremely pleasant , fantastic , friendly , friendly and helpful , good , great , great and courteous , prompt and friendly , really friendly , so nice , swift and friendly , very friendly , very friendly and accommodating service=5 all courteous , excellent , excellent and friendly , extremely friendly , fabulous , fantastic , friendly , friendly and helpful , friendly and very attentive , good , great , great , prompt and courteous , happy and friendly , impeccable , intrusive , legendary , outstanding , pleasant , polite , attentive and prompt , prompt and courteous , prompt and pleasant , quick and cheerful , stupendous , superb , the most attentive , unbelievable , very attentive , very congenial , very courteous , very friendly , very friendly and helpful , very friendly and pleasant , very friendly and totally personal , very friendly and welcoming , very good , very helpful , very timely , warm and friendly , wonderful Table 8 : Adjectival phrases ( APs ) in single scalarvalued relation mappings for servicequality .</sentence>
				<definiendum id="0">Adjectival phrases</definiendum>
				<definiendum id="1">APs</definiendum>
				<definiens id="0">courteous , prompt and friendly , really friendly , so nice , swift and friendly , very friendly , very friendly and accommodating service=5 all courteous , excellent , excellent and friendly , extremely friendly , fabulous , fantastic , friendly , friendly and helpful , friendly and very attentive , good , great , great , prompt and courteous , happy and friendly , impeccable , intrusive , legendary , outstanding , pleasant , polite , attentive and prompt , prompt and courteous , prompt and pleasant , quick and cheerful , stupendous , superb</definiens>
			</definition>
</paper>

		<paper id="4016">
			<definition id="0">
				<sentence>TwicPen is a terminology-assistance system for readers of printed ( ie .</sentence>
				<definiendum id="0">TwicPen</definiendum>
			</definition>
			<definition id="1">
				<sentence>Fips is a robust multilingual parser which is based on generative grammar concepts for its linguistic component and object-oriented design for its implementation .</sentence>
				<definiendum id="0">Fips</definiendum>
				<definiens id="0">a robust multilingual parser which is based on generative grammar concepts for its linguistic component and object-oriented design for its implementation</definiens>
			</definition>
			<definition id="2">
				<sentence>The syntactic structures built by Fips are all of the same pattern , that is : [ XP L X R ] , where L stands for the possibly empty list of left constituents , X for the ( possibly empty ) head of the phrase and R for the ( possibly empty ) list of right constituents .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">the ( possibly empty ) head of the phrase and R for the ( possibly empty ) list of right constituents</definiens>
			</definition>
			<definition id="3">
				<sentence>Nevertheless , as Figure 3 shows , TwicPen is capable of identifying the collocation .</sentence>
				<definiendum id="0">TwicPen</definiendum>
				<definiens id="0">capable of identifying the collocation</definiens>
			</definition>
			<definition id="4">
				<sentence>Verbmobil : A Translation System for Face-toFace Dialog , Lecture Notes 33 , Stanford , CSLI .</sentence>
				<definiendum id="0">Verbmobil</definiendum>
				<definiens id="0">A Translation System for Face-toFace Dialog , Lecture Notes 33 , Stanford , CSLI</definiens>
			</definition>
			<definition id="5">
				<sentence>“Multi-word collocation extraction by syntactic composition of collocation bigrams” , in Nicolas Nicolov et al. ( eds ) , Recent Advances in Natural Language Processing III : Selected Papers from RANLP 2003 , Amsterdam , John Benjamins , 91-100 .</sentence>
				<definiendum id="0">“Multi-word collocation extraction</definiendum>
				<definiendum id="1">collocation bigrams”</definiendum>
				<definiens id="0">eds ) , Recent Advances in Natural Language Processing III : Selected Papers from RANLP 2003</definiens>
			</definition>
</paper>

		<paper id="2105">
			<definition id="0">
				<sentence>Another important change that we introduced in our extension of WordNet is the refinement of the DERIVATION relation which links verbs with their corresponding nominalized nouns .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">the refinement of the DERIVATION relation which links verbs with their corresponding nominalized nouns</definiens>
			</definition>
			<definition id="1">
				<sentence>and a0 : Pope Benedict XVI is the new leader of the Roman Catholic Church .</sentence>
				<definiendum id="0">Benedict XVI</definiendum>
			</definition>
			<definition id="2">
				<sentence>A semantic axiom which combines two relations , a1 a30 and a1a3a2 , is devised by observing the semantic connection between the a4 a4 and a4a6a5 words for which there exists at least one other word , a4 a6 , such that a1 a30 a3a7a4 a4 a4a8a4 a6 a6 ( a4 a4 a9 a59 a16 a4 a6 ) and a1a10a2 a3a7a4 a6 a4a8a4a10a5 a6 ( a4 a6 a9a12a11 a16 a4a10a5 ) hold true .</sentence>
				<definiendum id="0">semantic axiom</definiendum>
				<definiens id="0">such that a1 a30 a3a7a4 a4 a4a8a4 a6 a6 ( a4 a4 a9 a59 a16 a4 a6 ) and a1a10a2 a3a7a4 a6 a4a8a4a10a5 a6 ( a4 a6 a9a12a11 a16 a4a10a5 ) hold true</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , if a1 states explicitly the KINSHIP ( KIN ) relations between Nicholas Cage and Alice Kim Cage and between Alice Kim Cage and Kal-el Coppola Cage , the logic prover uses the KIN SR ( x1 , x2 ) &amp; KIN SR ( x2 , x3 ) a16 KIN SR ( x1 , x3 ) semantic axiom ( the transitivity of the blood relation ) and the symmetry of this relationship ( KIN SR ( x1 , x2 ) 9For example , the axiom country NE ( x1 ) &amp; negotiator NN ( x2 ) &amp; nn NNC ( x3 , x1 , x2 ) a17 work VB ( e1 , x2 , x4 ) &amp; for IN ( e1 , x1 ) helps the prover infer that Christopher Hill works for the US from top US negotiator , Christopher Hill .</sentence>
				<definiendum id="0">KINSHIP</definiendum>
				<definiendum id="1">KIN SR</definiendum>
				<definiendum id="2">KIN SR</definiendum>
				<definiens id="0">the transitivity of the blood relation</definiens>
			</definition>
</paper>

		<paper id="1121">
			<definition id="0">
				<sentence>The span of a node n is defined by the indices of the first and last word in f that are reachable from n. The complement span of n is the union of the spans of all nodes nprime in G that are neither descendants nor ancestors of n. Nodes of G whose spans and complement spans are nonoverlapping form the frontier set F ∈ G. What is particularly interesting about the frontier set ?</sentence>
				<definiendum id="0">span of a node n</definiendum>
				<definiendum id="1">complement span of n</definiendum>
				<definiens id="0">the union of the spans of all nodes nprime in G that are neither descendants nor ancestors of n. Nodes of G whose spans and complement spans are nonoverlapping form the frontier set F ∈ G.</definiens>
			</definition>
			<definition id="1">
				<sentence>Conversely , NP ( x0 : DT , x1 : CD : ,x2 : NNS ) is not the lhs of any rule extractible from G , since its frontier constituents CD [ 2 ] and NNS [ 2 ] have overlapping spans.3 Finally , the GHKM procedure produces a single derivation from G , which is shown in Table 1 .</sentence>
				<definiendum id="0">GHKM procedure</definiendum>
				<definiens id="0">produces a single derivation from G</definiens>
			</definition>
			<definition id="2">
				<sentence>The preprocessing step consists of assigning spans and complement spans to nodes of G , in the first case by a bottom-up exploration of the graph , and in the latter by a top-down traversal .</sentence>
				<definiendum id="0">preprocessing step</definiendum>
				<definiens id="0">consists of assigning spans and complement spans to nodes of G , in the first case by a bottom-up exploration of the graph , and in the latter by a top-down traversal</definiens>
			</definition>
			<definition id="3">
				<sentence>The overall goal of our translation system is to transform a given source-language sentence f into an appropriate translation e in the set E of all possible target-language sentences .</sentence>
				<definiendum id="0">translation system</definiendum>
				<definiens id="0">to transform a given source-language sentence f into an appropriate translation e in the set E of all possible target-language sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>The function to optimize becomes : ˆe = argmax e∈E braceleftBig Pr ( e ) · summationdisplay pi∈τ ( e ) Pr ( f|pi ) ·Pr ( pi|e ) bracerightBig ( 2 ) τ ( e ) is the set of all English trees that yield the given sentence e. Estimating Pr ( pi|e ) is a problem equivalent to syntactic parsing and thus is not discussed here .</sentence>
				<definiendum id="0">·Pr ( pi|e</definiendum>
				<definiendum id="1">e )</definiendum>
				<definiendum id="2">pi|e )</definiendum>
				<definiens id="0">the set of all English trees that yield the given sentence e. Estimating Pr (</definiens>
				<definiens id="1">a problem equivalent to syntactic parsing</definiens>
			</definition>
			<definition id="5">
				<sentence>Estimating Pr ( f|pi ) is the task of syntax-based translation models ( SBTM ) .</sentence>
				<definiendum id="0">Estimating Pr ( f|pi )</definiendum>
				<definiendum id="1">SBTM</definiendum>
				<definiens id="0">the task of syntax-based translation models</definiens>
			</definition>
			<definition id="6">
				<sentence>Given a rule set R , our SBTM makes the common assumption that left-most compositions of xRs rules θi = r1 ◦ ... ◦ rn are independent from one another in a given derivation θi ∈ Θ , where Θ is the set of all derivations constructible from G = ( pi , f , a ) using rules of R. Assuming that Λ is the set of all subtree decompositions of pi corresponding to derivations in Θ , we define the estimate : Pr ( f|pi ) = 1|Λ| summationdisplay θi∈Θ productdisplay rj∈θi p ( rhs ( rj ) |lhs ( rj ) ) ( 3 ) under the assumption : summationdisplay rj∈R : lhs ( rj ) =lhs ( ri ) p ( rhs ( rj ) |lhs ( rj ) ) = 1 ( 4 ) It is important to notice that the probability distribution defined in Equation 3 requires a normalization factor ( |Λ| ) in order to be tight , i.e. , sum to 1 over all strings fi ∈ F that can be derived 4We denote general probability distributions with Pr ( · ) and use p ( · ) for probabilities assigned by our models .</sentence>
				<definiendum id="0">SBTM</definiendum>
				<definiendum id="1">Θ</definiendum>
				<definiendum id="2">p ( rhs ( rj ) |lhs ( rj</definiendum>
				<definiendum id="3">summationdisplay rj∈R</definiendum>
				<definiens id="0">makes the common assumption that left-most compositions of xRs rules θi = r1 ◦ ... ◦ rn are independent from one another in a given derivation θi ∈ Θ</definiens>
				<definiens id="1">the set of all derivations constructible from G = ( pi , f , a ) using rules of R. Assuming that Λ is the set of all subtree decompositions of pi corresponding to derivations in Θ , we define the estimate : Pr ( f|pi ) = 1|Λ| summationdisplay θi∈Θ productdisplay rj∈θi</definiens>
			</definition>
			<definition id="7">
				<sentence>The first one is the relative frequency estimator conditioning on left hand sides : p ( rhs ( r ) |lhs ( r ) ) = f ( r ) summationtext rprime : lhs ( rprime ) =lhs ( r ) f ( rprime ) ( 5 ) f ( r ) represents the number of times rule r occurred in the derivations of the training corpus .</sentence>
				<definiendum id="0">lhs</definiendum>
				<definiens id="0">the number of times rule r occurred in the derivations of the training corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>Since all rules in that example have probability 1 , and 5If each tree fragment in pi is the lhs of some rule in R , then we have |Λ| = 2n , where n is the number of nodes of the frontier set F ∈ G ( each node is a binary choice point ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of nodes of the frontier set F ∈ G</definiens>
			</definition>
			<definition id="9">
				<sentence>→ x0 x1 x2 .845 ( b ) NP-C ( x0 : NPB ) → x0 .82 ( c ) NPB ( DT ( the ) x0 : NNS ) → x0 .507 ( d ) NNS ( gunmen ) →a170a75 .559 ( e ) VP ( VBD ( were ) x0 : VP-C ) → x0 .434 ( f ) VP-C ( x0 : VBN x1 : PP ) → x1 x0 .374 ( g ) PP ( x0 : IN x1 : NP-C ) → x0 x1 .64 ( h ) IN ( by ) →a171 .0067 ( i ) NP-C ( x0 : NPB ) → x0 .82 ( j ) NPB ( DT ( the ) x0 : NN ) → x0 .586 ( k ) NN ( police ) →a102a185 .0429 ( l ) VBN ( killed ) →a251a217 .0072 ( m ) .</sentence>
				<definiendum id="0">DT</definiendum>
				<definiendum id="1">NNS</definiendum>
				<definiens id="0">VBN x1 : PP ) → x1 x0 .374 ( g ) PP ( x0 : IN x1 : NP-C ) → x0 x1 .64 ( h ) IN</definiens>
				<definiens id="1">the ) x0 : NN ) → x0 .586 ( k ) NN</definiens>
			</definition>
			<definition id="10">
				<sentence>1 ( p ) VP ( VBD ( were ) VP-C ( x0 : VBN PP ( IN ( by ) x1 : NP-C ) ) ) →a171x1 x0 0.00724 ( q ) NP-C ( NPB ( DT ( the ) NN ( police ) ) ) →a102a185 0.173 ( r ) VBN ( killed ) →a251a217 0.00719 Figure 4 : Two most probable derivations for the graph on the right : the top table restricted to minimal rules ; the bottom one , much more probable , using a large set of composed rules .</sentence>
				<definiendum id="0">p ) VP</definiendum>
				<definiendum id="1">NPB</definiendum>
				<definiens id="0">the top table restricted to minimal rules</definiens>
			</definition>
			<definition id="11">
				<sentence>extracted the most probable one ( Viterbi ) for each sentence pair ( based on an automatic alignment produced by GIZA ) .</sentence>
				<definiendum id="0">Viterbi</definiendum>
			</definition>
</paper>

		<paper id="2087">
			<definition id="0">
				<sentence>During our participation in different international evaluation campaigns such as the TREC Genomics track ( Hersh , 2005 ) , the BioCreative initiative ( Hirschman et al. , 2005 ) , as well as in our attempts to deliver advanced search tools for biologists ( Ruch , 2006 ) and healthcare providers ( Ruch , 2002 ) ( Ruch , 2004 ) , we were more concerned with domain-specific information retrieval in which systems must return a ranked list of MEDLINE records in response to an expert’s information request .</sentence>
				<definiendum id="0">BioCreative initiative</definiendum>
				<definiens id="0">concerned with domain-specific information retrieval in which systems must return a ranked list of MEDLINE records in response to an expert’s information request</definiens>
			</definition>
			<definition id="1">
				<sentence>Originally inspired by corpus linguistics studies ( Orasan , 2001 ) , which suggests that scientific reports ( in chemistry , linguistics , computer sciences , medicine ... ) exhibit a very regular logical distribution -confirmed by studies conducted on biomedical corpora ( Swales , 1990 ) and by ANSI/ISO professional standards the argumentative model we experiment is based on four disjunct classes : PURPOSE , METHODS , RESULTS , CONCLUSION .</sentence>
				<definiendum id="0">METHODS</definiendum>
				<definiens id="0">suggests that scientific reports ( in chemistry , linguistics , computer sciences</definiens>
			</definition>
			<definition id="2">
				<sentence>Recent empirical studies conducted in the context of the TREC Genomics track , using the OHSUGEN collection ( Hersh , 2005 ) , show that neither blind expansion ( Rocchio ) , nor domain-specific query expansion ( thesaurus-based Gene and Protein expansion ) seem appropriate to improve retrieval effectiveness ( Aronson et al. , 2006 ) ( Abdou et al. , 2006 ) .</sentence>
				<definiendum id="0">domain-specific query expansion</definiendum>
				<definiens id="0">thesaurus-based Gene and Protein expansion ) seem appropriate to improve retrieval effectiveness</definiens>
			</definition>
			<definition id="3">
				<sentence>To test our hypothesis , we used the OHSUMED collection ( Hersh et al. , 1994 ) , originally developed for the TREC topic detection track , which is the most popular information retrieval collection for evaluating information search in library corpora .</sentence>
				<definiendum id="0">OHSUMED collection</definiendum>
				<definiens id="0">originally developed for the TREC topic detection track , which is the most popular information retrieval collection for evaluating information search in library corpora</definiens>
			</definition>
			<definition id="4">
				<sentence>As usual in information retrieval evaluations , the mean average precision , which computes the precision of the engine at different levels ( 0 % , 10 % , 20 % ... 100 % ) of recall , will be used in our experiments .</sentence>
				<definiendum id="0">mean average precision</definiendum>
				<definiens id="0">computes the precision of the engine at different levels</definiens>
			</definition>
			<definition id="5">
				<sentence>Abstract : A computerized data acquisition tool , the special purpose radiology understanding system ( SPRUS ) , has been implemented as a module in the Health Evaluation through Logical Processing Hospital Information System .</sentence>
				<definiendum id="0">Abstract</definiendum>
				<definiendum id="1">SPRUS</definiendum>
				<definiens id="0">A computerized data acquisition tool , the special purpose radiology understanding system</definiens>
				<definiens id="1">a module in the Health Evaluation through Logical Processing Hospital Information System</definiens>
			</definition>
			<definition id="6">
				<sentence>The easyIR system is a standard vector-space engine ( Ruch , 2004 ) , which computes stateof-the-art tf .</sentence>
				<definiendum id="0">easyIR system</definiendum>
				<definiens id="0">computes stateof-the-art tf</definiens>
			</definition>
			<definition id="7">
				<sentence>To implement our argumentative categorizer , we rely on four binary Bayesian classifiers , which use lexical features , and a Markov model , which models the logical distribution of the argumentative classes in MEDLINE abstracts .</sentence>
				<definiendum id="0">Markov model</definiendum>
			</definition>
			<definition id="8">
				<sentence>The basic segment is the sentence ; therefore the abstract is split into a set of sentences before being processed by the argumentative classifier .</sentence>
				<definiendum id="0">basic segment</definiendum>
				<definiens id="0">the sentence</definiens>
			</definition>
</paper>

		<paper id="1053">
			<definition id="0">
				<sentence>To keep our model as simple as possible , each formulation is based on an unlexicalized probabilistic context free grammar ( PCFG ) .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">simple as possible , each formulation is based on an unlexicalized probabilistic context free grammar (</definiens>
			</definition>
			<definition id="1">
				<sentence>A PCFG assigns trees probabilities by treating each rule expansion as conditionally independent given the parent node .</sentence>
				<definiendum id="0">PCFG assigns</definiendum>
				<definiens id="0">trees probabilities by treating each rule expansion as conditionally independent given the parent node</definiens>
			</definition>
			<definition id="2">
				<sentence>The probability of a rule LHS → RHS is estimated as : P ( RHS|LHS ) = c ( LHS → RHS ) c ( LHS ) The rst model we introduce is a probabilistic variant of Frazier and Clifton’s ( 2001 ) copying mechanism : it models parallelism in coordination and nothing else .</sentence>
				<definiendum id="0">LHS</definiendum>
				<definiens id="0">a probabilistic variant of Frazier and Clifton’s ( 2001 ) copying mechanism : it models parallelism in coordination and nothing else</definiens>
			</definition>
			<definition id="3">
				<sentence>This value may be estimated directly from a corpus using the formula pident = cidentc total Here , cident is the number of coordinate structures in which the two conjuncts have the same internal structure and ctotal is the total number of coordinate structures .</sentence>
				<definiendum id="0">cident</definiendum>
				<definiens id="0">the total number of coordinate structures</definiens>
			</definition>
			<definition id="4">
				<sentence>A probabilistic parser may be considered to be a sentence processing model via a ‘linking hypothesis’ , which links the parser’s word-by-word behavior to human reading behavior .</sentence>
				<definiendum id="0">probabilistic parser</definiendum>
				<definiens id="0">links the parser’s word-by-word behavior to human reading behavior</definiens>
			</definition>
</paper>

		<paper id="1082">
			<definition id="0">
				<sentence>Typically , Vw is of the form 〈p1p2 ... pk〉 , where the pis indicate the positions of the word w in a text T. A new vector Rw , called the recency vector , is computed using the position vector Vw , and is defined as 〈p2−p1 , p3−p2 , ... , pk−pk−1〉 .</sentence>
				<definiendum id="0">Vw</definiendum>
			</definition>
			<definition id="1">
				<sentence>Note that vl ( k ) denotes the kth entry of the vector vl , for l = 1 and 2 .</sentence>
				<definiendum id="0">k )</definiendum>
				<definiens id="0">the kth entry of the vector vl , for l = 1 and 2</definiens>
			</definition>
			<definition id="2">
				<sentence>Here , T is some predefined threshold : is : 12 ∗f2 &lt; f1 &lt; 2∗f2 , where f1 and f2 are the frequencies of occurrence of w1 and w2 , in their respective texts .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">some predefined threshold : is : 12 ∗f2 &lt; f1 &lt; 2∗f2 , where f1 and f2 are the frequencies of occurrence of w1 and w2 , in their respective texts</definiens>
			</definition>
			<definition id="3">
				<sentence>The Multiple Alignment Selection ( MAS ) filter takes care of situations where a single target language word is aligned with the number of source 650 Corpora English corpus Hindi corpus Total words Distinct words Total words Distinct words Storybook corpus 6545 1079 7381 1587 Sentence corpus 8541 1186 9070 1461 Advertisement corpus 3709 1307 4009 1410 Table 1 : Details of English-Hindi Parallel Corpora Range Available Proposed Correct P % R % F-score 50 516 430 34 7.91 6.59 0.077 150 516 481 51 10.60 09.88 0.102 250 516 506 98 19.37 18.99 0.192 500 516 514 100 19.46 19.38 0.194 700 516 515 94 18.25 18.22 0.182 800 516 515 108 20.97 20.93 0.209 900 516 515 88 17.09 17.05 0.171 1000 516 516 100 19.38 19.38 0.194 2000 516 516 81 15.70 15.70 0.157 4535 516 516 76 14.73 14.73 0.147 Table 2 : Results of DK-vec Algorithm on Sentence Corpus for different range language words .</sentence>
				<definiendum id="0">Multiple Alignment Selection</definiendum>
				<definiens id="0">takes care of situations where a single target language word is aligned with the number of source 650 Corpora English corpus Hindi corpus Total words Distinct words Total words Distinct words Storybook corpus</definiens>
			</definition>
</paper>

		<paper id="3013">
			<definition id="0">
				<sentence>An electronic grammar is an interface between the complexity and the diversity of natural language and the regularity and the effectiveness of a language processing , and it is one of the most important elements in the natural language processing .</sentence>
				<definiendum id="0">electronic grammar</definiendum>
				<definiens id="0">an interface between the complexity and the diversity of natural language and the regularity and the effectiveness of a language processing , and it is one of the most important elements in the natural language processing</definiens>
			</definition>
			<definition id="1">
				<sentence>SJTree contains 32,054 eojeols ( the unity of segmentation in the Korean sentence ) , that is , 2,526 sentences .</sentence>
				<definiendum id="0">SJTree</definiendum>
				<definiens id="0">contains 32,054 eojeols ( the unity of segmentation in the Korean sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>SJTree uses 43 part-of-speech tags and 55 syntactic tags .</sentence>
				<definiendum id="0">SJTree</definiendum>
			</definition>
			<definition id="3">
				<sentence>Among 55 syntactic tag in SJTree , nodes labeled with NP ( noun phrase ) , S ( sentence ) , VNP ( copular phrase ) and VP ( verb phrase ) which end with _CMP ( attribute ) , _OBJ ( object ) , and _SJB ( subject ) would be marked for substitution operation , and nodes labeled with the other syntactic tags except a head node would be marked for adjunction operation .</sentence>
				<definiendum id="0">VP ( verb phrase</definiendum>
				<definiendum id="1">_SJB ( subject</definiendum>
				<definiens id="0">nodes labeled with NP ( noun phrase ) , S ( sentence ) , VNP ( copular phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>In this distinction , some VNP and VP phrases might be marked for substitution operation , which means that VNP and VP phrases are arguments of a head , because SJTree labels VNP and VP instead of NP for the nominalization forms of VNP and VP .</sentence>
				<definiendum id="0">substitution operation</definiendum>
				<definiendum id="1">VP phrases</definiendum>
				<definiens id="0">the nominalization forms of VNP and VP</definiens>
			</definition>
			<definition id="5">
				<sentence>da ( ‘announced’ ) In this paper , we extract not only lexicalized trees without modification of a Treebank , but also extract grammars with modifications of a Treebank using some constraints to improve the lexical coverage in extracted grammars .</sentence>
				<definiendum id="0">da</definiendum>
				<definiens id="0">lexicalized trees without modification of a Treebank , but also extract grammars with modifications of a Treebank using some constraints to improve the lexical coverage in extracted grammars</definiens>
			</definition>
			<definition id="6">
				<sentence>Extracted lexicalized grammars G 2 trees We extract feature-based lexicalized trees using reduced tagset because FB-LTAG grammars contain their syntactic information in features structures .</sentence>
				<definiendum id="0">Extracted lexicalized</definiendum>
				<definiens id="0">extract feature-based lexicalized trees using reduced tagset because FB-LTAG grammars contain their syntactic information in features structures</definiens>
			</definition>
			<definition id="7">
				<sentence>Extraction des grammaires LTAG à partir d’un corpus étiquette syntaxiquement .</sentence>
				<definiendum id="0">Extraction des</definiendum>
				<definiens id="0">grammaires LTAG à partir d’un corpus étiquette syntaxiquement</definiens>
			</definition>
			<definition id="8">
				<sentence>A Uniform Method for Automatically Extracting Stochastic Lexicalized Tree Grammar from Treebank and HPSG , In A. Abeillé ( ed ) Treebanks : Building and Using Parsed Corpora , Kluwer , Dordrecht .</sentence>
				<definiendum id="0">Uniform Method</definiendum>
				<definiens id="0">for Automatically Extracting Stochastic Lexicalized Tree Grammar from Treebank and HPSG</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>Manual alignments are represented by two sets : Probable ( P ) alignments and Sure ( S ) alignments , where S ⊆ P. Given A , P and S , the most commonly used metrics—precision ( Pr ) , recall ( Rc ) and alignment error rate ( AER ) —are defined as follows : Pr = |A∩P||A| Rc = |A∩S||S| AER = 1− |A∩S|+|A∩P||A|+|S| Another approach to evaluating alignments is to measure their impact on an external application , e.g. , statistical MT. In recent years , phrase-based systems ( Koehn , 2004 ; Chiang , 2005 ) have been shown to outperform word-based MT systems ; therefore , inthispaper , weuseapublicly-available phrase-based MT system , Pharaoh ( Koehn , 2004 ) , to investigate the impact of different alignments .</sentence>
				<definiendum id="0">Manual alignments</definiendum>
				<definiendum id="1">phrase-based systems</definiendum>
				<definiens id="0">represented by two sets : Probable ( P ) alignments and Sure ( S ) alignments , where S ⊆ P. Given A , P and S , the most commonly used metrics—precision ( Pr ) , recall ( Rc ) and alignment error rate ( AER ) —are defined as follows : Pr = |A∩P||A| Rc = |A∩S||S| AER = 1− |A∩S|+|A∩P||A|+|S| Another approach to evaluating alignments is to measure their impact on an external application , e.g. , statistical MT. In recent years</definiens>
				<definiens id="1">shown to outperform word-based MT systems ; therefore , inthispaper , weuseapublicly-available phrase-based MT system , Pharaoh ( Koehn , 2004 ) , to investigate the impact of different alignments</definiens>
			</definition>
			<definition id="1">
				<sentence>We evaluate alignments in terms of precision , recall , alignment error rate ( AER ) , and a new measure called consistent phrase error rate ( CPER ) .</sentence>
				<definiendum id="0">CPER</definiendum>
				<definiens id="0">alignments in terms of precision , recall , alignment error rate ( AER ) , and a new measure called consistent phrase error rate</definiens>
			</definition>
			<definition id="2">
				<sentence>Each uni-directional alignment is the result of running GIZA++ ( Och , 2000b ) in one of two directions ( source-to-target and vice versa ) with default configurations .</sentence>
				<definiendum id="0">uni-directional alignment</definiendum>
				<definiens id="0">the result of running GIZA++ ( Och , 2000b ) in one of two directions ( source-to-target and vice versa ) with default configurations</definiens>
			</definition>
			<definition id="3">
				<sentence>SB is an improved version of SA which attempts to increase recall without a significant sacrifice in precision .</sentence>
				<definiendum id="0">SB</definiendum>
				<definiens id="0">an improved version of SA which attempts to increase recall without a significant sacrifice in precision</definiens>
			</definition>
			<definition id="4">
				<sentence>Pr Rc AER Pr Rc AER SU 58.3 84.5 31.6 56.0 84.1 32.8 SG 61.9 82.6 29.7 60.2 83.0 30.2 SI 94.8 53.6 31.2 96.1 57.1 28.4 SA 87.0 74.6 19.5 88.6 71.1 21.1 SB 87.8 80.5 15.9 90.1 76.1 17.5 Table 2 : Comparison of 5 Different Alignments using AER ( on English-Chinese and English-Arabic ) In this section , we present a new method , called consistent phrase error rate ( CPER ) , for evaluating word alignments in the context of phrasebased MT. The idea is to compare phrases consistent with a given alignment against phrases that would be consistent with human alignments .</sentence>
				<definiendum id="0">CPER</definiendum>
				<definiens id="0">to compare phrases consistent with a given alignment against phrases that would be consistent with human alignments</definiens>
			</definition>
			<definition id="5">
				<sentence>Increasing the phrase length increases the BLEU scores for all systems by nearly 0.7 points and increasing the size of the training data increases the BLEU scores by 1.5-2 points for all systems .</sentence>
				<definiendum id="0">Increasing the phrase length</definiendum>
				<definiens id="0">increases the BLEU scores for all systems by nearly 0.7 points and increasing the size of the training data increases the BLEU scores by 1.5-2 points for all systems</definiens>
			</definition>
			<definition id="6">
				<sentence>In both languages , SB outperforms SG significantly when loose phrases are used .</sentence>
				<definiendum id="0">SB</definiendum>
				<definiens id="0">outperforms SG significantly when loose phrases are used</definiens>
			</definition>
			<definition id="7">
				<sentence>Increasing the training data size reduces the percentage of untranslated words by nearly half with all five alignments .</sentence>
				<definiendum id="0">Increasing the training data size</definiendum>
				<definiens id="0">reduces the percentage of untranslated words by nearly half with all five alignments</definiens>
			</definition>
			<definition id="8">
				<sentence>As a result , for both languages , SU and SG yield a much smaller Chinese Arabic Alignment MPL=3 MPL=7 MPL=3 MPL=7 SU 106 122 32 38 SG 161 181 48 55 SI 1331 3498 377 984 SA 954 1856 297 594 SB 876 1624 262 486 Table 7 : Number of Phrases in the Phrase Table Filtered for MTEval’2003 Test Sets ( in thousands ) phrase table than the other three alignments .</sentence>
				<definiendum id="0">SU</definiendum>
				<definiens id="0">Number of Phrases in the Phrase Table Filtered for MTEval’2003 Test Sets ( in thousands</definiens>
			</definition>
			<definition id="9">
				<sentence>NotethatSI , SA andSB useonlyasmallportion ofthephraseswithmorethan3wordsalthoughthe majority of the phrase table contains phrases with more than 3 words on one side .</sentence>
				<definiendum id="0">NotethatSI , SA</definiendum>
				<definiens id="0">andSB useonlyasmallportion ofthephraseswithmorethan3wordsalthoughthe majority of the phrase table contains phrases with more than 3 words on one side</definiens>
			</definition>
			<definition id="10">
				<sentence>15 This paper investigated how different alignments change the behavior of phrase-based MT. We showed that AER is a poor indicator of MT performance because it penalizes incorrect links less than is reflected in the corresponding phrasebased MT. During phrase-based MT , an incorrect alignment link might prevent extraction of several phrases , but the number of phrases affected by that link depends on the context .</sentence>
				<definiendum id="0">AER</definiendum>
			</definition>
</paper>

		<paper id="2075">
			<definition id="0">
				<sentence>Learning lexical semantic relationships is a fundamental task needed for most text understanding applications .</sentence>
				<definiendum id="0">Learning lexical semantic relationships</definiendum>
			</definition>
			<definition id="1">
				<sentence>Aggregated Conditional Pattern Probability : This single feature is the conditional probability that any of the patterns match in a retrieved sentence , given that the two terms appear in it .</sentence>
				<definiendum id="0">Aggregated Conditional Pattern Probability</definiendum>
				<definiens id="0">the conditional probability that any of the patterns match in a retrieved sentence , given that the two terms appear in it</definiens>
			</definition>
</paper>

		<paper id="2033">
			<definition id="0">
				<sentence>IA searches along an ordered list of attributes , selecting properties of the intended referents that remove some distractors .</sentence>
				<definiendum id="0">IA</definiendum>
				<definiens id="0">searches along an ordered list of attributes , selecting properties of the intended referents that remove some distractors</definiens>
			</definition>
			<definition id="1">
				<sentence>High-VS ( HVS ) pairs had a mean rating ≥ 6 ; Low-VS LVS ) pairs had mean ratings ≤ 2 .</sentence>
				<definiendum id="0">High-VS</definiendum>
				<definiens id="0">HVS ) pairs had a mean rating ≥ 6 ; Low-VS LVS ) pairs had mean ratings ≤ 2</definiens>
			</definition>
			<definition id="2">
				<sentence>Participants saw a series of discourses , in which three entities ( e1 , e2 , e3 ) were introduced , each with two distinguishing properties .</sentence>
				<definiendum id="0">Participants</definiendum>
				<definiens id="0">saw a series of discourses , in which three entities ( e1 , e2 , e3 ) were introduced</definiens>
			</definition>
			<definition id="3">
				<sentence>Perspective A perspective P is a convex subset of S , i.e. : ∀t , t′ , t′′ ∈ T : { t , t′ } ⊆ P ∧σ ( t , t′′ ) ≥ σ ( t , t′ ) → t′′ ∈ P The aims of the algorithm are to describe elements of R using types from the same perspective , failing which , it attempts to minimise the distance between the perspectives from which types are selected in the disjunctions of D. Distance between perspectives is defined below .</sentence>
				<definiendum id="0">perspective P</definiendum>
				<definiens id="0">a convex subset of S</definiens>
			</definition>
			<definition id="4">
				<sentence>Note that T and M need not be disjoint , and entities can have more than one type property T : { lecturer , professor } T : { woman , man } M : { plump , thin } T : { geologist , physicist , biologist , chemist } 3 2 1 1 0.6 1 Figure 3 : Perspective Graph 〈P , M′〉 where P is a perspective , and M′ ⊆ M. The distance δ ( A , B ) between two clusters A and B is defined straightforwardly in terms of the distance between their perspectives PA and PB : δ ( A , B ) = 1 1 + P x∈PA , y∈PB σ ( x , y ) |PA×PB| ( 2 ) Finally , a weighted , connected graph G = 〈V , E , δ〉 is created , where V is the set of clusters , and E is the set of edges with edge weights defined as the semantic distance between perspectives .</sentence>
				<definiendum id="0">B</definiendum>
				<definiendum id="1">P x∈PA , y∈PB σ</definiendum>
				<definiendum id="2">V</definiendum>
				<definiendum id="3">E</definiendum>
				<definiens id="0">Note that T and M need not be disjoint , and entities can have more than one type property T : { lecturer , professor } T : { woman , man } M : { plump , thin } T : { geologist , physicist , biologist , chemist } 3 2 1 1 0.6 1 Figure 3 : Perspective Graph 〈P , M′〉 where P is a perspective</definiens>
				<definiens id="1">defined straightforwardly in terms of the distance between their perspectives PA and PB : δ ( A , B ) = 1 1 +</definiens>
				<definiens id="2">a weighted , connected graph G = 〈V , E , δ〉 is created , where</definiens>
				<definiens id="3">the set of clusters , and</definiens>
			</definition>
			<definition id="5">
				<sentence>Given a DNF description D , we shall say that a perspective P is realised in D if there is at least one type t ∈ P which is in D. Let PD be the set of perspectives realised in D. Since G is connected , PD determines a connected subgraph of G. The total weight of D , w ( D ) is the sum of weights of the edges in PD .</sentence>
				<definiendum id="0">PD</definiendum>
				<definiens id="0">determines a connected subgraph of G. The total weight of D</definiens>
				<definiens id="1">the sum of weights of the edges in PD</definiens>
			</definition>
</paper>

		<paper id="1087">
			<definition id="0">
				<sentence>NP chunking is the task of labelling noun phrases in natural language text .</sentence>
				<definiendum id="0">NP chunking</definiendum>
			</definition>
			<definition id="1">
				<sentence>The NP chunks in the shared task data are base-NP chunks – which are non-recursive NPs , a definition first proposed by Ramshaw and Marcus ( 1995 ) .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">chunks in the shared task data are base-NP chunks – which are non-recursive NPs</definiens>
			</definition>
			<definition id="2">
				<sentence>The Hebrew Treebank is annotated over a segmented version of the text , in which prefixes and suffixes appear as separate lexical units .</sentence>
				<definiendum id="0">Hebrew Treebank</definiendum>
				<definiens id="0">annotated over a segmented version of the text , in which prefixes and suffixes appear as separate lexical units</definiens>
			</definition>
			<definition id="3">
				<sentence>SVM is a supervised machine learning algorithm which can handle gracefully a large set of overlapping features .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">a supervised machine learning algorithm which can handle gracefully a large set of overlapping features</definiens>
			</definition>
			<definition id="4">
				<sentence>The Hebrew TreeBank6 consists of 4,995 hand annotated sentences from the Ha’aretz newspaper .</sentence>
				<definiendum id="0">Hebrew TreeBank6</definiendum>
			</definition>
			<definition id="5">
				<sentence>In the first experiment ( denoted WP ) we considered the word and PoS tags of the context tokens to be part of the feature set .</sentence>
				<definiendum id="0">PoS</definiendum>
				<definiens id="0">tags of the context tokens to be part of the feature set</definiens>
			</definition>
			<definition id="6">
				<sentence>Split errors : bracketing [ a ] [ b ] instead of [ a b ] Merge errors : bracketing [ a b ] instead of [ a ] [ b ] Short errors : bracketing “a [ b ] ” or “ [ a ] b” instead of [ a b ] Long errors : bracketing “ [ a b ] ” instead of “ [ a ] b” or “a [ b ] ” Whole Chunk errors : either missing a whole chunk , or bracketing something which doesn’t overlap with a chunk at all ( extra chunk ) .</sentence>
				<definiendum id="0">Split errors</definiendum>
			</definition>
			<definition id="7">
				<sentence>Missing/ExtraToken errors : this is a generalized form of conjunction errors : either “ [ a ] T [ b ] ” instead of “ [ a T b ] ” or vice versa , where T is a single token .</sentence>
				<definiendum id="0">Missing/ExtraToken errors</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">a single token</definiens>
			</definition>
</paper>

		<paper id="1132">
			<definition id="0">
				<sentence>Let PID ( c|b ) and PCLS ( c|b ) denote the probability of class c for bunsetsu b according to the identification and classification models , respectively .</sentence>
				<definiendum id="0">PID</definiendum>
				<definiendum id="1">PCLS</definiendum>
				<definiens id="0">the probability of class c for bunsetsu b according to the identification and classification models</definiens>
			</definition>
			<definition id="1">
				<sentence>Toutanova et al. ( 2005 ) report a substantial improvement in performance on the semantic role labeling task by building a joint classifier , which takes the labels of other phrases into account when classifying a given phrase .</sentence>
				<definiendum id="0">joint classifier</definiendum>
				<definiens id="0">takes the labels of other phrases into account when classifying a given phrase</definiens>
			</definition>
			<definition id="2">
				<sentence>With a count cut-off of 2 ( i.e. , features must occur at least twice to be in the model ) , we have 724,264 features in the identification Basic features for phrases ( self , parent ) HeadPOS , PrevHeadPOS , NextHeadPOS PrevPOS , Prev2POS , NextPOS , Next2POS HeadNounSubPos : time , formal nouns , adverbial HeadLemma HeadWord , PrevHeadWord , NextHeadWord PrevWord , Prev2Word , NextWord , Next2Word LastWordLemma ( excluding case markers ) LastWordInfl ( excluding case markers ) IsFiniteClause IsDateExpression IsNumberExpression HasPredicateNominal HasNominalizer HasPunctuation : comma , period HasFiniteClausalModifier RelativePosition : sole , first , mid , last NSiblings ( number of siblings ) Position ( absolute position among siblings ) Voice : pass , caus , passcaus Negation Basic features for phrase relations ( parent-child pair ) DependencyType : D , P , A , I Distance : linear distance in bunsetsu , 1 , 2-5 , &gt; 6 Subcat : POS tag of parent + POS tag of all children + indication for current Combined features ( selected ) HeadPOS + HeadLemma ParentLemma + HeadLemma Position + NSiblings IsFiniteClause + GrandparentNounSubPos Table 2 : Basic and combined features for local classifiers 1052 model , and 3,963,096 features in the classification model .</sentence>
				<definiendum id="0">NextWord</definiendum>
				<definiendum id="1">last NSiblings</definiendum>
				<definiens id="0">absolute position among siblings ) Voice : pass , caus , passcaus Negation Basic features for phrase relations ( parent-child pair ) DependencyType : D , P , A</definiens>
				<definiens id="1">POS tag of parent + POS tag of all children + indication for current Combined features ( selected ) HeadPOS + HeadLemma ParentLemma + HeadLemma Position + NSiblings IsFiniteClause + GrandparentNounSubPos</definiens>
			</definition>
			<definition id="3">
				<sentence>Devtest : contains news articles of January 12-13 and editorial article of September .</sentence>
				<definiendum id="0">Devtest</definiendum>
			</definition>
			<definition id="4">
				<sentence>Test : contains news articles of January 14-17 and editorial articles of October-December .</sentence>
				<definiendum id="0">Test</definiendum>
				<definiens id="0">contains news articles of January 14-17 and editorial articles of October-December</definiens>
			</definition>
			<definition id="5">
				<sentence>Compared to the language model trained on the same data ( 15kLM ) , our Monolingual features Feature Example HeadWord /HeadPOS saabisu/NN PrevWord/PrevPOS kono/AND Prev2Word/Prev2WordPOS none/none NextWord/NextPOS seefu/NN Next2Word/Net2POS moodo/NN PrevHeadWord/PrevHeadPOS kono/AND NextHeadWord/NextHeadPOS seefu/NN ParentHeadWord/ParentHeadPOS kaishi/VN Subcat : POS tags of all sisters and parent NN-c , NN , VN-h NSiblings ( including self ) 2 Distance 1 Direction left Alternative Parent Word /POS saabisu/NN Bilingual features Feature Example Word/POS of source words aligned to the head of the phrase service/NN Word/POS of all source words aligned to any word in the phrase service/NN Word/POS of all source words aligned to the head word of the parent phrase started/VERB Word/POS of all source words aligned to alternative parent words of the phrase service/NN , started/VERB All source preposition words in Word/POS of parent of source word aligned to any word in the phrase started/VERB Aligned Subcat NN-c , VERB , VERB , VERB-h , PREP Aligned NSiblings 4 Aligned Distance 2 Aligned Direction left Table 4 : Monolingual and bilingual features Model Test data baseline ( frequency ) 62.0 baseline ( 15kLM ) 79.0 baseline ( 450kLM ) 83.6 log-linear monolingual 85.3 log-linear bilingual 92.3 Table 5 : Accuracy of bilingual case prediction ( % ) 1055 monolingual model performs significantly better , achieving a 30 % error reduction ( 85.3 % vs. 79.0 % ) .</sentence>
				<definiendum id="0">VN-h NSiblings</definiendum>
				<definiens id="0">features Feature Example Word/POS of source words aligned to the head of the phrase service/NN Word/POS of all source words aligned to any word in the phrase service/NN Word/POS of all source words aligned to the head word of the parent phrase started/VERB Word/POS of all source words aligned to alternative parent words of the phrase service/NN , started/VERB All source preposition words in Word/POS of parent of source word aligned to any word in the phrase started/VERB Aligned Subcat NN-c , VERB , VERB , VERB-h , PREP Aligned NSiblings 4 Aligned Distance 2 Aligned Direction left Table 4 : Monolingual and bilingual features Model Test data baseline</definiens>
			</definition>
			<definition id="6">
				<sentence>The Proposition Bank : An Annotated Corpus of Semantic Roles .</sentence>
				<definiendum id="0">Proposition Bank</definiendum>
			</definition>
</paper>

		<paper id="2019">
			<definition id="0">
				<sentence>Sentence compression is a complex paraphrasing task with information loss involving substitution , deletion , insertion , and reordering operations .</sentence>
				<definiendum id="0">Sentence compression</definiendum>
				<definiens id="0">a complex paraphrasing task with information loss involving substitution , deletion , insertion , and reordering operations</definiens>
			</definition>
			<definition id="1">
				<sentence>Generative approaches ( Knight and Marcu 2002 ; Turner and Charniak 2005 ) are instantiations of the noisy-channel model : given a long sentence l , the aim is to nd the corresponding short sentence s which maximises the conditional probability P ( s|l ) .</sentence>
				<definiendum id="0">Generative approaches</definiendum>
			</definition>
			<definition id="2">
				<sentence>The IP formulation allows us to capture global sentence properties and can be easily manipulated to provide compressions tailored for speci c applications .</sentence>
				<definiendum id="0">IP formulation</definiendum>
				<definiens id="0">allows us to capture global sentence properties and can be easily manipulated to provide compressions tailored for speci c applications</definiens>
			</definition>
			<definition id="3">
				<sentence>Our formulation consists of two basic components : a language model ( scoring function ) and a small number of constraints ensuring that the resulting compressions are structurally and semantically valid .</sentence>
				<definiendum id="0">formulation</definiendum>
				<definiens id="0">consists of two basic components : a language model ( scoring function ) and a small number of constraints ensuring that the resulting compressions are structurally and semantically valid</definiens>
			</definition>
			<definition id="4">
				<sentence>Linear Programming ( LP ) is a tool for solving optimisation problems in which the aim is to maximise ( or minimise ) a given function with respect to a set of constraints .</sentence>
				<definiendum id="0">Linear Programming ( LP )</definiendum>
				<definiens id="0">a tool for solving optimisation problems in which the aim is to maximise</definiens>
			</definition>
			<definition id="5">
				<sentence>Integer Programming is an extension of linear programming where all decision variables must take integer values .</sentence>
				<definiendum id="0">Integer Programming</definiendum>
				<definiens id="0">an extension of linear programming where all decision variables must take integer values</definiens>
			</definition>
			<definition id="6">
				<sentence>Table 1 : Compression examples ( O : original sentence , LM : compression with the trigram model , Mod : compression with LM and modi er constraints , Sen : compression with LM , Mod and sentential constraints , Sig : compression with LM , Mod , Sen , and signi cance score ) its current state does a reasonable job of modelling local word dependencies , but is unable to capture syntactic dependencies that could potentially allow more meaningful compressions .</sentence>
				<definiendum id="0">Sen</definiendum>
				<definiens id="0">compression with LM , Mod , Sen , and signi cance score</definiens>
			</definition>
			<definition id="7">
				<sentence>The latter usually contains the gist of the original sentence : I ( wi ) = lN · fi log FaF i ( 23 ) The signi cance score above is computed using a large corpus where wi is a topic word ( i.e. , a noun or verb ) , fi and Fi are the frequency of wi in the document and corpus respectively , and Fa is the sum of all topic words in the corpus .</sentence>
				<definiendum id="0">Fi</definiendum>
				<definiendum id="1">Fa</definiendum>
				<definiens id="0">the frequency of wi in the document and corpus respectively , and</definiens>
				<definiens id="1">the sum of all topic words in the corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>l is the number of clause constituents above wi , and N is the deepest level of embedding .</sentence>
				<definiendum id="0">l</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the deepest level of embedding</definiens>
			</definition>
			<definition id="9">
				<sentence>The rst is the compression corpus of Knight and Marcu ( 2002 ) derived automatically from document-abstract pairs of the Ziff-Davis corpus .</sentence>
				<definiendum id="0">rst</definiendum>
			</definition>
			<definition id="10">
				<sentence>D : A career in television .</sentence>
				<definiendum id="0">D</definiendum>
				<definiens id="0">A career in television</definiens>
			</definition>
			<definition id="11">
				<sentence>Table 2 : Compression examples ( O : original sentence , G : Gold standard , D : Decision-tree , LM : IP language model , Sig : IP language model with signi cance score ) Model CompR Rating Decision-tree 56.1 % 2.22⁄ LangModel 49.0 % 2.23⁄ LangModel+Signi cance 73.6 % 2.83⁄ Gold Standard 62.3 % 3.68 Table 3 : Compression results ; compression rate ( CompR ) and average human judgements ( Rating ) ; ⁄ : sig .</sentence>
				<definiendum id="0">compression rate</definiendum>
				<definiendum id="1">CompR</definiendum>
				<definiens id="0">Decision-tree , LM : IP language model , Sig : IP language model with signi cance score</definiens>
			</definition>
</paper>

		<paper id="1083">
			<definition id="0">
				<sentence>A phrase consists of a content word and one or more suffixes , such as postpositional particles .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">consists of a content word and one or more suffixes , such as postpositional particles</definiens>
			</definition>
			<definition id="1">
				<sentence>The suffix dictionary consists of 37 suffixes that can concatenate with nouns .</sentence>
				<definiendum id="0">suffix dictionary</definiendum>
			</definition>
			<definition id="2">
				<sentence>vc dvdc +× +×× − α α ) ( 2 1 ( 1 ) Here , dc and dv denote the number of differences in consonants and vowels , respectively , and α is a parametric consonant used to control the importance of the consonants .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">1 ) Here , dc and dv denote the number of differences in consonants and vowels , respectively , and</definiens>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>The corpus analyzed in this paper consists of 95 experimentally obtained spoken tutoring dialogues between 20 students and our system ITSPOKE ( Litman and Forbes-Riley , 2004 ) , a speech-enabled version of the text-based WHY2 conceptual physics tutoring system ( VanLehn et al. , 2002 ) .</sentence>
				<definiendum id="0">ITSPOKE</definiendum>
			</definition>
			<definition id="1">
				<sentence>For our χ 2 analysis , we define the REJ variable with two values : Rej ( a rejection occurred in the turn ) and noRej ( no rejection occurred in the turn ) .</sentence>
				<definiendum id="0">Rej</definiendum>
				<definiens id="0">a rejection occurred in the turn</definiens>
			</definition>
			<definition id="2">
				<sentence>We define Semantic Misrecognition as cases where ITSPOKE was confident in its recognition hypothesis and the correctness interpretation of the recognition hypothesis is different from the correctness interpretation of the manual transcript ( Figure 1 , STD 1 ) .</sentence>
				<definiendum id="0">Semantic Misrecognition</definiendum>
				<definiens id="0">cases where ITSPOKE was confident in its recognition hypothesis</definiens>
			</definition>
			<definition id="3">
				<sentence>We believe that our correctness annotation ( CRCT ) is reliable due to the simplicity of the task : the annotator uses his language understanding to match the human transcript to a list of correct/incorrect answers .</sentence>
				<definiendum id="0">CRCT</definiendum>
				<definiens id="0">reliable due to the simplicity of the task : the annotator uses his language understanding to match the human transcript to a list of correct/incorrect answers</definiens>
			</definition>
</paper>

		<paper id="1135">
			<definition id="0">
				<sentence>Inferencing is a core requirement of systems that participate in the current PASCAL Recognizing Textual Entailment ( RTE ) challenge ( see http : //www.pascal-network.org/Challenges/RTE and ... /RTE2 ) .</sentence>
				<definiendum id="0">Inferencing</definiendum>
				<definiens id="0">a core requirement of systems that participate in the current PASCAL Recognizing Textual Entailment ( RTE ) challenge ( see http : //www.pascal-network.org/Challenges/RTE and ... /RTE2 )</definiens>
			</definition>
			<definition id="1">
				<sentence>The LCC system ( Moldovan &amp; Rus , 2001 ) uses a Logic Prover to establish the connection between a candidate answer passage and the question .</sentence>
				<definiendum id="0">LCC system</definiendum>
				<definiens id="0">uses a Logic Prover to establish the connection between a candidate answer passage and the question</definiens>
			</definition>
			<definition id="2">
				<sentence>The QFrame contains the list of terms and phrases in the question , along with their properties , such as POS and NE-type ( if it exists ) , and a list of syntactic relationship tuples .</sentence>
				<definiendum id="0">QFrame</definiendum>
				<definiens id="0">contains the list of terms</definiens>
			</definition>
			<definition id="3">
				<sentence>The output of QS2 after processing the inverted QFrame is a list of answers to the inverted question , which by extension of the nomenclature we call “inverted answers.”</sentence>
				<definiendum id="0">QFrame</definiendum>
				<definiens id="0">a list of answers to the inverted question</definiens>
			</definition>
			<definition id="4">
				<sentence>The ANSWER SELECTION module takes these passages and proposes a candidate answer list .</sentence>
				<definiendum id="0">ANSWER SELECTION module</definiendum>
				<definiens id="0">takes these passages and proposes a candidate answer list</definiens>
			</definition>
</paper>

		<paper id="2024">
			<definition id="0">
				<sentence>The XML data model is a good foundation for this project as only written texts are analyzed , but SFL annotation requires multiple annotation layers with overlapping hierarchies .</sentence>
				<definiendum id="0">XML data model</definiendum>
				<definiens id="0">a good foundation for this project as only written texts are analyzed , but SFL annotation requires multiple annotation layers with overlapping hierarchies</definiens>
			</definition>
			<definition id="1">
				<sentence>184 The NITE XML toolkit ( NXT ) ( Carletta et al. , 04 ) was created with the intention to provide a framework for building applications working with annotatedmulti-modaldata .</sentence>
				<definiendum id="0">NITE XML toolkit</definiendum>
				<definiendum id="1">NXT</definiendum>
			</definition>
			<definition id="2">
				<sentence>NXTisbasedontheNITE Object Model ( NOM ) which is an extension of the XML data model .</sentence>
				<definiendum id="0">NXTisbasedontheNITE Object Model ( NOM</definiendum>
				<definiens id="0">an extension of the XML data model</definiens>
			</definition>
			<definition id="3">
				<sentence>NOM features a similar separation of tiers as the PACE-Ling data model , but is more general .</sentence>
				<definiendum id="0">NOM</definiendum>
				<definiens id="0">features a similar separation of tiers as the PACE-Ling data model , but is more general</definiens>
			</definition>
			<definition id="4">
				<sentence>NOM uses a continuous timeline to coordinate annotations .</sentence>
				<definiendum id="0">NOM</definiendum>
			</definition>
			<definition id="5">
				<sentence>NOM introduces a new structural relation between annotation elements .</sentence>
				<definiendum id="0">NOM</definiendum>
			</definition>
			<definition id="6">
				<sentence>DDD defines how alignments are modeled , thus elevating them from the level of structural annotation to an independent object in the structural tier : analignmentasasetofelementsorsegments , each of which is associated with a role .</sentence>
				<definiendum id="0">DDD</definiendum>
				<definiens id="0">defines how alignments are modeled</definiens>
			</definition>
			<definition id="7">
				<sentence>The ATLAS project ( Laprun et al. , 02 ) implements a three tier data model model , resembling the separation of medial , locational and annotation tiers .</sentence>
				<definiendum id="0">ATLAS project</definiendum>
				<definiens id="0">implements a three tier data model model , resembling the separation of medial , locational and annotation tiers</definiens>
			</definition>
			<definition id="8">
				<sentence>A pointer is a typed directed reference to one or more elements .</sentence>
				<definiendum id="0">pointer</definiendum>
			</definition>
			<definition id="9">
				<sentence>E.g. XPath provides a weakly typed system that provides such operators .</sentence>
				<definiendum id="0">E.g. XPath</definiendum>
				<definiens id="0">provides a weakly typed system that provides such operators</definiens>
			</definition>
			<definition id="10">
				<sentence>signal ( ’plaintext’ ) /’rapid’ Result : a set of segments .</sentence>
				<definiendum id="0">Result</definiendum>
				<definiens id="0">a set of segments</definiens>
			</definition>
			<definition id="11">
				<sentence>The anchored operator takes an annotation element and returns true if the element is anchored .</sentence>
				<definiendum id="0">anchored operator</definiendum>
				<definiens id="0">takes an annotation element</definiens>
			</definition>
			<definition id="12">
				<sentence>The contains operator takes two sets of segments a and b and returns all segments from set b that are contained in an area covered by any segment in set a. The grow operator takes a set of segments and returns a segment , which starts at the smallest offset and ends at the largest offset present in any segment of the input list .</sentence>
				<definiendum id="0">grow operator</definiendum>
				<definiendum id="1">segment</definiendum>
				<definiens id="0">contains operator takes two sets of segments a and b and returns all segments from set b that are contained in an</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>DIPRE ( Dual Iterative Pattern Relation Expansion ) ( Brin , 1998 ) is a bootstrapping-based system that used a pattern matching system as classifier to exploit the duality between sets of patterns and relations .</sentence>
				<definiendum id="0">DIPRE ( Dual Iterative Pattern Relation Expansion )</definiendum>
				<definiens id="0">a bootstrapping-based system that used a pattern matching system as classifier to exploit the duality between sets of patterns and relations</definiens>
			</definition>
			<definition id="1">
				<sentence>1 http : //www.ldc.upenn.edu/Projects/ACE/ , Three tasks of ACE program : Entity Detection and Tracking ( EDT ) , Relation Detection and Characterization ( RDC ) , and Event Detection and Characterization ( EDC ) The problem of relation extraction is to assign an appropriate relation type to an occurrence of two entity pairs in a given context .</sentence>
				<definiendum id="0">Entity Detection</definiendum>
				<definiens id="0">to assign an appropriate relation type to an occurrence of two entity pairs in a given context</definiens>
			</definition>
			<definition id="2">
				<sentence>It can be represented as follows : R → ( Cpre , e1 , Cmid , e2 , Cpost ) ( 1 ) where e1 and e2 denote the entity mentions , and Cpre , Cmid , and Cpost are the contexts before , between and after the entity mention pairs .</sentence>
				<definiendum id="0">Cpost</definiendum>
				<definiens id="0">follows : R → ( Cpre , e1 , Cmid , e2 , Cpost ) ( 1 ) where e1 and e2 denote the entity mentions</definiens>
			</definition>
			<definition id="3">
				<sentence>Let X = { xi } ni=1 be a set of contexts of occurrences of all the entity mention pairs , where xi represents the contexts of the i-th occurrence , and n is the total number of occurrences .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the total number of occurrences</definiens>
			</definition>
			<definition id="4">
				<sentence>The first l examples ( or contexts ) are labeled as yg ( yg ∈ { rj } Rj=1 , rj denotes relation type and R is the total number of relation types ) .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">yg ( yg ∈ { rj } Rj=1 , rj denotes relation type and</definiens>
			</definition>
			<definition id="5">
				<sentence>Hence , the weights are defined as follows : Wij = exp ( −s 2ij α2 ) ( 2 ) where sij is the similarity between xi and xj calculated by some similarity measures , e.g. , cosine similarity , and α is used to scale the weights .</sentence>
				<definiendum id="0">sij</definiendum>
				<definiens id="0">the similarity between xi and xj calculated by some similarity measures , e.g. , cosine similarity , and α is used to scale the weights</definiens>
			</definition>
			<definition id="6">
				<sentence>Define an n×n probabilistic transition matrix T Tij = P ( j → i ) = wijsummationtextn k=1 wkj ( 3 ) where Tij is the probability to jump from vertex xj to vertex xi .</sentence>
				<definiendum id="0">Define an n×n probabilistic transition matrix</definiendum>
				<definiendum id="1">Tij</definiendum>
				<definiens id="0">the probability to jump from vertex xj to vertex xi</definiens>
			</definition>
			<definition id="7">
				<sentence>Step 2 : Propagate the labels of any vertex to nearby vertices by Y t+1 = TY t , where T is the row-normalized matrix of T , i.e. Tij = Tij/summationtextk Tik , which can maintain the class probability interpretation .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the row-normalized matrix of T , i.e. Tij = Tij/summationtextk Tik , which can maintain the class probability interpretation</definiens>
			</definition>
			<definition id="8">
				<sentence>Cosine similarity is commonly used semantic distance , which measures the angle between two feature vectors .</sentence>
				<definiendum id="0">semantic distance</definiendum>
				<definiens id="0">measures the angle between two feature vectors</definiens>
			</definition>
			<definition id="9">
				<sentence>JS divergence has ever been used as distance measure for document clustering , which outperforms cosine similarity based document clustering ( Slonim et al. , 2002 ) .</sentence>
				<definiendum id="0">document clustering</definiendum>
			</definition>
			<definition id="10">
				<sentence>JS divergence is defined as follows : Table 1 : Frequency of Relation SubTypes in the ACE training and devtest corpus .</sentence>
				<definiendum id="0">JS divergence</definiendum>
				<definiens id="0">Table 1 : Frequency of Relation SubTypes in the ACE training and devtest corpus</definiens>
			</definition>
			<definition id="11">
				<sentence>Table 1 lists the types and subtypes of relations for the ACE Relation Detection and Characterization ( RDC ) task , along with their 132 Table 2 : The Performance of SVM and LP algorithm with different sizes of labeled data for relation detection on relation subtypes .</sentence>
				<definiendum id="0">ACE Relation Detection</definiendum>
				<definiens id="0">The Performance of SVM and LP algorithm with different sizes of labeled data for relation detection on relation subtypes</definiens>
			</definition>
			<definition id="12">
				<sentence>Support Vector Machine ( SVM ) is a state of the art technique for relation extraction task .</sentence>
				<definiendum id="0">Support Vector Machine ( SVM )</definiendum>
				<definiens id="0">a state of the art technique for relation extraction task</definiens>
			</definition>
			<definition id="13">
				<sentence>Then construct labeled datasets with different sampling set size l , including 1 % ×Ntrain , 10 % ×Ntrain , 25 % × Ntrain , 50 % ×Ntrain , 75 % ×Ntrain , 100 % ×Ntrain ( Ntrain is the number of examples in the ACE train3LIBSVM : a library for support vector machines .</sentence>
				<definiendum id="0">Ntrain</definiendum>
			</definition>
			<definition id="14">
				<sentence>Figure 2 ( c ) reports the classification result on test set by SVM ( accuracy = 415 = 26.7 % ) , and Figure 2 ( d ) gives the classification result on both training set and test set by LP ( accuracy = 1115 = 73.3 % ) .</sentence>
				<definiendum id="0">d )</definiendum>
				<definiens id="0">gives the classification result on both training set and test set by LP ( accuracy = 1115 = 73.3 % )</definiens>
			</definition>
</paper>

		<paper id="1050">
			<definition id="0">
				<sentence>P ( A ) P ( E ) Kappa Table 4 : Inter-Annotator Agreement for Binary Event Durations .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
			<definition id="1">
				<sentence>For the “signed” event in sentence ( 1 ) , the extracted WordNet hypernym features for the event ( “signed” ) , its subject ( “presidents” ) , and its object ( “plan” ) are shown in Table 3 , and the feature vector is [ write , communicate , interact , corporate_executive , executive , administrator , idea , content , cognition ] .</sentence>
				<definiendum id="0">feature vector</definiendum>
			</definition>
			<definition id="2">
				<sentence>P ( A ) P ( E ) Kappa Table 9 : Inter-Annotator Agreement for Most Likely Temporal Unit .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>We show how Bayesian inference in this generative model can be used to simultaneously address the problems of topic segmentation and topic identification : automatically segmenting multi-party meetings into topically coherent segments with performance which compares well with previous unsupervised segmentation-only methods ( Galley et al. , 2003 ) while simultaneously extractingtopicswhichratehighlywhenassessed for coherence by human judges .</sentence>
				<definiendum id="0">topic identification</definiendum>
				<definiens id="0">automatically segmenting multi-party meetings into topically coherent segments with performance which compares well with previous unsupervised segmentation-only methods</definiens>
			</definition>
			<definition id="1">
				<sentence>The uth utterance consists of Nu words , chosen from a vocabulary of size W. The set of words associated with the uth utterance are denoted wu , and indexed as wu , i. The entire corpus is represented by w. Following previous work on probabilistic topic models ( Hofmann , 1999 ; Blei et al. , 2003 ; GriffithsandSteyvers , 2004 ) , wemodeleachutterance as being generated from a particular distribution over topics , where each topic is a probability distribution over words .</sentence>
				<definiendum id="0">uth utterance</definiendum>
				<definiens id="0">a probability distribution over words</definiens>
			</definition>
			<definition id="2">
				<sentence>As in ( Hofmann , 1999 ; Blei et al. , 2003 ; Griffiths and Steyvers , 2004 ) , each topic Tj is a multinomial distribution φ ( j ) over words , and the probability of the word w under that topic is φ ( j ) w .</sentence>
				<definiendum id="0">topic Tj</definiendum>
				<definiens id="0">a multinomial distribution φ ( j ) over words</definiens>
			</definition>
			<definition id="3">
				<sentence>Specifically , we have : P ( c ) = R10 P ( c|pi ) P ( pi ) dpi = Γ ( 2γ ) Γ ( γ ) 2 Γ ( n1+γ ) Γ ( n0+γ ) Γ ( N+2γ ) ( 2 ) where n1 is the number of utterances for which cu = 1 , and n0 is the number of utterances for whichcu = 0 .</sentence>
				<definiendum id="0">n0</definiendum>
				<definiens id="0">the number of utterances for which cu = 1</definiens>
				<definiens id="1">the number of utterances for whichcu = 0</definiens>
			</definition>
			<definition id="4">
				<sentence>ComputingP ( w|z ) proceedsalong similar lines : P ( w|z ) = R∆T W P ( w|z , φ ) P ( φ ) dφ = “ Γ ( Wβ ) Γ ( β ) W ”T Q T t=1 QW w=1 Γ ( n ( t ) w +β ) Γ ( n ( t ) · +Wβ ) ( 3 ) where ∆TW is the T-dimensional cross-product of the multinomial simplex on W points , n ( t ) w is the number of times word w is assigned to topic t in z , and n ( t ) · is the total number of words assigned to topic t in z. To evaluate P ( z|c ) we have : P ( z|c ) = Z ∆UT P ( z|θ ) P ( θ|c ) dθ ( 4 ) The fact that the cu variables effectively divide the sequence of utterances into segments that use thesamedistributionovertopicssimplifiessolving the integral and we obtain : P ( z|c ) = „Γ ( Tα ) Γ ( α ) T «n1 Y u∈U1 QT t=1 Γ ( n ( Su ) t + α ) Γ ( n ( Su ) · + Tα ) .</sentence>
				<definiendum id="0">ComputingP</definiendum>
				<definiendum id="1">∆TW</definiendum>
				<definiendum id="2">n</definiendum>
				<definiendum id="3">n</definiendum>
				<definiens id="0">the total number of words assigned to topic t in z. To evaluate P ( z|c</definiens>
				<definiens id="1">z|c ) = „Γ ( Tα ) Γ ( α ) T «n1 Y u∈U1 QT t=1 Γ ( n ( Su ) t + α ) Γ ( n ( Su ) · + Tα )</definiens>
			</definition>
			<definition id="5">
				<sentence>( 5 ) 19 P ( cu|c−u , z , w ) ∝ 8 &gt; &gt; &lt; &gt; &gt; : QT t=1 Γ ( n ( S0u ) t +α ) Γ ( n ( S 0u ) · +Tα ) n0+γ N+2γ cu = 0 Γ ( Tα ) Γ ( α ) T QT t=1 Γ ( n ( S1u−1 ) t +α ) Γ ( n ( S1u−1 ) · +Tα ) QT t=1 Γ ( n ( S1u ) t +α ) Γ ( n ( S 1u ) · +Tα ) n1+γ N+2γ cu = 1 ( 7 ) where U1 = { u|cu = 1 } , U0 = { u|cu = 0 } , Su denotes the set of utterances that share the same topicdistribution ( i.e. belongtothesamesegment ) as u , and n ( Su ) t is the number of times topic t appears in the segment Su ( i.e. in the values of zuprime corresponding for uprime ∈ Su ) .</sentence>
				<definiendum id="0">QT t=1 Γ ( n</definiendum>
				<definiendum id="1">Su</definiendum>
				<definiens id="0">the set of utterances that share the same topicdistribution ( i.e. belongtothesamesegment ) as u , and n ( Su ) t is the number of times topic t appears in the segment Su ( i.e. in the values of zuprime corresponding for uprime ∈ Su )</definiens>
			</definition>
			<definition id="6">
				<sentence>21 Figure 3 : Results from the ICSI corpus : A ) the words most indicative for each topic ; B ) Probability of a segment boundary , compared with human segmentation , for an arbitrary subset of the data ; C ) Receiveroperator characteristic ( ROC ) curves for predicting human segmentation , and conditional probabilities of placing a boundary at an offset from a human boundary ; D ) subjective topic coherence ratings .</sentence>
				<definiendum id="0">C ) Receiveroperator characteristic</definiendum>
				<definiens id="0">Results from the ICSI corpus : A ) the words most indicative for each topic ; B ) Probability of a segment boundary , compared with human segmentation , for an arbitrary subset of the data ;</definiens>
			</definition>
			<definition id="7">
				<sentence>Others reflect general classes of words which are independent of subject matter ( topic 4 ) .</sentence>
				<definiendum id="0">Others</definiendum>
				<definiens id="0">reflect general classes of words which are independent of subject matter</definiens>
			</definition>
			<definition id="8">
				<sentence>Galley et al. ( 2003 ) annotated these sections explicitly , together with the ICSI “digit-task” sections ( participants read sequences of digits to provide data for speech recognition experiments ) , and removed them from their data , as did we in Experiment 1 above .</sentence>
				<definiendum id="0">ICSI “digit-task”</definiendum>
				<definiens id="0">sections ( participants read sequences of digits to provide data for speech recognition experiments ) , and removed them from their data</definiens>
			</definition>
</paper>

		<paper id="2043">
			<definition id="0">
				<sentence>null A pattern extractor , which extracts subcategorization patterns , i.e. local syntactic frames , including the syntactic frames , including the syntactic categories and head lemmas .</sentence>
				<definiendum id="0">pattern extractor</definiendum>
				<definiens id="0">extracts subcategorization patterns</definiens>
			</definition>
			<definition id="1">
				<sentence>null A pattern classifier , which assigns patterns to SCFs or rejects them as unclassifiable .</sentence>
				<definiendum id="0">pattern classifier</definiendum>
				<definiens id="0">assigns patterns to SCFs or rejects them as unclassifiable</definiens>
			</definition>
			<definition id="2">
				<sentence>null A SCF filter , which evaluates sets of SCFs gathered for a predicate verb .</sentence>
				<definiendum id="0">SCF filter</definiendum>
				<definiens id="0">evaluates sets of SCFs gathered for a predicate verb</definiens>
			</definition>
			<definition id="3">
				<sentence>Generally , precision is the percentage of SCFs that the system proposes correctly , while recall is the percentage of SCFs in the gold standard that the system proposes : Precision = Recall = F-measure = Here , true positives are correct SCF types proposed by the system , false positives are incorrect SCF types proposed by system , and false negatives are correct SCF types not proposed by the system .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the percentage of SCFs in the gold standard that the system proposes : Precision = Recall = F-measure = Here , true positives are correct SCF types proposed by the system , false positives are incorrect SCF types proposed by system , and false negatives are correct SCF types not proposed by the system</definiens>
			</definition>
</paper>

		<paper id="1060">
			<definition id="0">
				<sentence>Information extraction is a crucial step toward understanding and processing natural language data , its goal being to identify and categorize important information conveyed in a discourse .</sentence>
				<definiendum id="0">Information extraction</definiendum>
				<definiens id="0">a crucial step toward understanding and processing natural language data , its goal being to identify and categorize important information conveyed in a discourse</definiens>
			</definition>
			<definition id="1">
				<sentence>In a similar spirit to the approach presented in this article , Florian ( 2002 ) considers the task of named entity recognition as a two-step process : the first is the identification of mention boundaries and the second is the classification of the identified chunks , therefore considering a label for each word being formed from two sub-labels : one that specifies the position of the current word relative in a mention ( outside any mentions , starts a mention , is inside a mention ) and a label specifying the mention type .</sentence>
				<definiendum id="0">second</definiendum>
				<definiens id="0">word being formed from two sub-labels : one that specifies the position of the current word relative in a mention</definiens>
				<definiens id="1">inside a mention ) and a label specifying the mention type</definiens>
			</definition>
			<definition id="2">
				<sentence>The cascade model is essentially a factorization of individual classifiers for the sub-tasks ; in this framework , we will assume that there is a more or less natural dependency structure among subtasks , and that models for each of the subtasks will be built and applied in the order defined by the dependency structure .</sentence>
				<definiendum id="0">cascade model</definiendum>
				<definiens id="0">a factorization of individual classifiers for the sub-tasks</definiens>
				<definiens id="1">a more or less natural dependency structure among subtasks , and that models for each of the subtasks will be built and applied in the order defined by the dependency structure</definiens>
			</definition>
			<definition id="3">
				<sentence>To facilitate a fair comparison , we will incorporate it in an indirect way : we train a classifier C on the additional training data T prime , which we then use to classify the original training data T. Then we train the allin-one classifier on the original training data T , adding the features defined on the output of applying the classifier C on T. The situation is better for the joint model : the new training data T prime can be incorporated directly into the training data T.10 The maximum entropy model estimates the model parameters by maximizing the data log-likelihood L = summationdisplay ( x , y ) ˆp ( x , y ) logqλ ( y|x ) where ˆp ( x , y ) is the observed probability distribution of the pair ( x , y ) and qλ ( y|x ) = 1 Z producttext j exp ( λj ·fj ( x , y ) ) is the conditional MEprobability distribution as computed by the model .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
				<definiendum id="1">log-likelihood L = summationdisplay</definiendum>
				<definiendum id="2">ˆp</definiendum>
				<definiens id="0">the conditional MEprobability distribution as computed by the model</definiens>
			</definition>
			<definition id="4">
				<sentence>11For instance , the full label B-PER is consistent with the partial label B , but not with O or I. Language Training Test Arabic 511 178 Chinese 480 166 English 2003 658 139 English 2004 337 114 Table 2 : Datasets size ( number of documents ) Each word in the training data is labeled with one of the following properties:12 • if it is not part of any entity , it’s labeled as O • if it is part of an entity , it contains a tag specifying whether it starts a mention ( B- ) or is inside a mention ( I- ) .</sentence>
				<definiendum id="0">Datasets size</definiendum>
				<definiens id="0">inside a mention ( I- )</definiens>
			</definition>
</paper>

		<paper id="1137">
			<definition id="0">
				<sentence>Unification grammars ( UG ) ( Shieber , 1986 ; Shieber , 1992 ; Carpenter , 1992 ) have originated as an extension of context-free grammars , the basic idea being to augment the context-free rules with non context-free annotations ( feature structures ) in order to express additional information .</sentence>
				<definiendum id="0">Unification grammars</definiendum>
				<definiendum id="1">UG )</definiendum>
				<definiens id="0">an extension of context-free grammars , the basic idea being to augment the context-free rules with non context-free annotations ( feature structures</definiens>
			</definition>
			<definition id="1">
				<sentence>Unification grammars are Turing equivalent : determining whether a given string is generated by a given grammar is as hard as deciding whether a Turing machine halts on the empty input ( Johnson , 1988 ) .</sentence>
				<definiendum id="0">Unification grammars</definiendum>
				<definiens id="0">determining whether a given string</definiens>
			</definition>
			<definition id="2">
				<sentence>To ensure its decidability , several constraints on unification grammars , commonly known as the off-line parsability ( OLP ) constraints , were suggested , such that the recognition problem is decidable for off-line parsable grammars ( Jaeger et al. , 2005 ) .</sentence>
				<definiendum id="0">OLP</definiendum>
			</definition>
			<definition id="3">
				<sentence>A CFG is a four-tuple Gcf = 〈VN , Vt , Rcf , S〉 where Vt is a set of terminals , VN is a set of non1The term mildly context-sensitive was coined by Joshi ( 1985 ) , in reference to a less formally defined class of languages .</sentence>
				<definiendum id="0">CFG</definiendum>
				<definiendum id="1">VN</definiendum>
				<definiens id="0">a four-tuple Gcf = 〈VN , Vt , Rcf , S〉 where Vt is a set of terminals</definiens>
				<definiens id="1">a set of non1The term mildly context-sensitive was coined by Joshi ( 1985 ) , in reference to a less formally defined class of languages</definiens>
			</definition>
			<definition id="4">
				<sentence>terminals , including the start symbol S , and Rcf is a set of productions , assumed to be in a normal form where each rule has either ( zero or more ) non-terminals or a single terminal in its body , and where the start symbol never occurs in the right hand side of rules .</sentence>
				<definiendum id="0">Rcf</definiendum>
				<definiens id="0">a set of productions , assumed to be in a normal form where each rule has either ( zero or more ) non-terminals or a single terminal in its body , and where the start symbol never occurs in the right hand side of rules</definiens>
			</definition>
			<definition id="5">
				<sentence>In a linear indexed grammar ( LIG ) ,2 strings are derived from nonterminals with an associated stack denoted A [ l1 ... ln ] , where A is a nonterminal , each li is a stack symbol , and l1 is the top of the stack .</sentence>
				<definiendum id="0">l1</definiendum>
				<definiens id="0">a stack symbol</definiens>
			</definition>
			<definition id="6">
				<sentence>A Linear Indexed Grammar is a five tuple Gli = 〈VN , Vt , Vs , Rli , S〉 where Vt , VN and S are as above , Vs is a finite set of indices ( stack symbols ) and Rli is a finite set of productions in one of the following two forms : • fixed stack : Ni [ p1 ... pn ] → α • unbounded stack : Ni [ p1 ... pn ∞ ] → α or Ni [ p1 ... pn ∞ ] → αNj [ q1 ... qm ∞ ] β where Ni , Nj ∈ VN , p1 ... pn , q1 ... qm ∈ Vs , n , m ≥ 0 and α , β ∈ ( Vt ∪VN [ V ∗s ] ) ∗ .</sentence>
				<definiendum id="0">Linear Indexed Grammar</definiendum>
				<definiendum id="1">Rli</definiendum>
				<definiens id="0">a five tuple Gli = 〈VN , Vt , Vs , Rli , S〉 where Vt , VN and S are as above , Vs is a finite set of indices ( stack symbols</definiens>
				<definiens id="1">a finite set of productions in one of the following two forms : • fixed stack : Ni [ p1 ... pn ] → α • unbounded stack : Ni [ p1 ... pn ∞ ] → α or Ni [ p1 ... pn ∞ ] → αNj [ q1 ... qm ∞ ] β where Ni , Nj ∈ VN , p1 ... pn , q1 ... qm ∈ Vs , n , m ≥ 0 and α</definiens>
			</definition>
			<definition id="7">
				<sentence>Given a LIG 〈VN , Vt , Vs , Rli , S〉 , the derivation relation ‘⇒li’ is defined as follows : for all Ψ1 , Ψ2 ∈ ( VN [ V ∗s ] ∪Vt ) ∗ and η ∈ V ∗s , • If Ni [ p1 ... pn ] → α ∈ Rli then Ψ1Ni [ p1 ... pn ] Ψ2 ⇒li Ψ1αΨ2 • If Ni [ p1 ... pn ∞ ] → α ∈ Rli then Ψ1Ni [ p1 ... pnη ] Ψ2 ⇒li Ψ1αΨ2 • If Ni [ p1 ... pn ∞ ] → αNj [ q1 ... qm ∞ ] β ∈ Rli then Ψ1Ni [ p1 ... pnη ] Ψ2 ⇒li Ψ1αNj [ q1 ... qmη ] βΨ2 2The definition is based on Vijay-Shanker and Weir ( 1994 ) .</sentence>
				<definiendum id="0">derivation relation ‘⇒li’</definiendum>
			</definition>
			<definition id="8">
				<sentence>A unification grammar is a tuple Gu = 〈Ru , As , L〉 where Ru is a finite set of rules , each of which is an MRS of length n ≥ 1 , L is a lexicon , which associates with every word w ∈ WORDS a finite set of feature structures , L ( w ) , and As is a feature structure , the start symbol .</sentence>
				<definiendum id="0">unification grammar</definiendum>
				<definiendum id="1">Ru</definiendum>
				<definiendum id="2">L</definiendum>
				<definiendum id="3">L</definiendum>
				<definiens id="0">a finite set of rules , each of which is an MRS of length n ≥ 1 ,</definiens>
				<definiens id="1">associates with every word w ∈ WORDS a finite set of feature structures</definiens>
			</definition>
			<definition id="9">
				<sentence>A unification grammar 〈Ru , As , L〉 over the signature 〈ATOMS , FEATS , WORDS〉 is non-reentrant iff for any rule ru ∈ Ru , ru is non-reentrant .</sentence>
				<definiendum id="0">WORDS〉</definiendum>
				<definiens id="0">non-reentrant iff for any rule ru ∈ Ru</definiens>
			</definition>
			<definition id="10">
				<sentence>VN is the set of all the feature structures occurring in any of the rules or the lexicon of Gu .</sentence>
				<definiendum id="0">VN</definiendum>
				<definiens id="0">the set of all the feature structures occurring in any of the rules or the lexicon of Gu</definiens>
			</definition>
			<definition id="11">
				<sentence>When a feature structure which is represented as an unbounded list ( a list that is not terminated by elist ) is unifiable with an image of a LIG symbol , the former is a prefix of the latter .</sentence>
				<definiendum id="0">former</definiendum>
				<definiens id="0">a prefix of the latter</definiens>
			</definition>
			<definition id="12">
				<sentence>Let lig2ug be a mapping of LIGS to UG1r , such that if Gli = 〈VN , Vt , Vs , Rli , S〉 and Gu = 〈Ru , As , L〉 = lig2ug ( Gli ) then Gu is over the signature τ ( definition 7 ) , As = toFs ( S [ ] ) , for all t ∈ Vt , L ( t ) = { toFs ( t ) } and Ru is defined by : • A LIG rule of the form X0 → α is mapped to the unification rule toFs ( X0 ) → toFs ( α ) • A LIG rule of the form Ni [ p1 , ... , pn ∞ ] → α Nj [ q1 , ... , qm ∞ ] β is mapped to the unification rule 〈Ni , p1 , ... , pn , 1 〉 → toFs ( α ) 〈Nj , q1 , ... , qm , 1 〉 toFs ( β ) Evidently , lig2ug ( Gli ) ∈ UG1r for any LIG Gli .</sentence>
				<definiendum id="0">Ru</definiendum>
				<definiens id="0">LIG rule of the form Ni [ p1 , ... , pn ∞ ] → α Nj [ q1 , ... , qm ∞ ] β is mapped to the unification rule 〈Ni , p1 , ... , pn , 1 〉 → toFs ( α ) 〈Nj , q1 , ... , qm , 1 〉 toFs ( β ) Evidently , lig2ug ( Gli ) ∈ UG1r for any LIG Gli</definiens>
			</definition>
			<definition id="13">
				<sentence>The set consists of all features in FEATS and all the non-reentrant feature structures whose height is limited by the maximal height of the unification grammar .</sentence>
				<definiendum id="0">set</definiendum>
				<definiens id="0">consists of all features in FEATS and all the non-reentrant feature structures whose height is limited by the maximal height of the unification grammar</definiens>
			</definition>
			<definition id="14">
				<sentence>Let Ψ : NRFSS × PATHS mapsto→ ( FEATS ∪ NRFSS ) ∗ be a mapping such that if A is a non-reentrant FS and pi = 〈F1 , ... , Fn〉 ∈ ΠA , then the cord Ψ ( A , pi ) is 〈A1 , F1 , ... , An , Fn , An+1〉 , where for 1 ≤ i ≤ n +1 , Ai are non-reentrant FSs such that : • ΠAi = { 〈G〉 · pi | 〈F1 , ... , Fi−1 , G〉 · pi ∈ ΠA , i ≤ n , G negationslash= Fi } ∪ { ε } • ΘAi ( pi ) = ΘA ( 〈F1 , ... , Fi−1〉·pi ) ( if it is defined ) .</sentence>
				<definiendum id="0">Fi−1〉·pi )</definiendum>
				<definiens id="0">a non-reentrant FS and pi = 〈F1 , ... , Fn〉 ∈ ΠA</definiens>
				<definiens id="1">〈A1 , F1 , ... , An , Fn , An+1〉 , where for 1 ≤ i ≤ n +1 , Ai are non-reentrant FSs such that : • ΠAi = { 〈G〉 · pi | 〈F1 , ... , Fi−1</definiens>
			</definition>
			<definition id="15">
				<sentence>The length of a cord is the length of the base path .</sentence>
				<definiendum id="0">length of a cord</definiendum>
				<definiens id="0">the length of the base path</definiens>
			</definition>
			<definition id="16">
				<sentence>We now define , for a feature structure C ( which is a head of a rule ) and some path pi , the set that includes all feature structures that are both unifiable with C and can be represented as a cord whose height is limited by the grammar height and whose base path is pi .</sentence>
				<definiendum id="0">base path</definiendum>
				<definiens id="0">a cord whose height is limited by the grammar height and whose</definiens>
			</definition>
			<definition id="17">
				<sentence>Given a non-reentrant feature structure C , a path pi = 〈F1 , ... , Fn〉 ∈ ΠC and a natural number h , the compatibility set , Γ ( C , pi , h ) , is defined as the set of all feature structures A such that C unionsq A negationslash= latticetop , pi ∈ ΠA , and |Ψ ( A , pi ) | ≤ h. The compatibility set is defined for a feature structure and a given path ( when h is taken to be the grammar height ) .</sentence>
				<definiendum id="0">|Ψ</definiendum>
				<definiens id="0">a path pi = 〈F1 , ... , Fn〉 ∈ ΠC and a natural number h , the compatibility set , Γ ( C , pi , h )</definiens>
				<definiens id="1">the set of all feature structures A such that C unionsq A negationslash= latticetop , pi ∈ ΠA , and</definiens>
			</definition>
			<definition id="18">
				<sentence>Each such member is a prefix of the stack of potential elements of sentential forms that the LIG rule can be applied to .</sentence>
				<definiendum id="0">LIG rule</definiendum>
				<definiens id="0">a prefix of the stack of potential elements of sentential forms that the</definiens>
			</definition>
			<definition id="19">
				<sentence>The major complication is the contents 1094 of this stack , which varies according to the cord representations of C0 and Ce and to the reentrant paths .</sentence>
				<definiendum id="0">major complication</definiendum>
				<definiens id="0">varies according to the cord representations of C0 and Ce and to the reentrant paths</definiens>
			</definition>
			<definition id="20">
				<sentence>The major difference is the head of the rule , X0 , which is defined as explained above .</sentence>
				<definiendum id="0">major difference</definiendum>
				<definiens id="0">the head of the rule</definiens>
			</definition>
			<definition id="21">
				<sentence>One-reentrant rules are simulated similarly to non-reentrant ones , the only difference being the selected element of the rule body , Xe , which is defined as follows .</sentence>
				<definiendum id="0">Xe</definiendum>
				<definiens id="0">simulated similarly to non-reentrant ones , the only difference being the selected element of the rule body</definiens>
			</definition>
			<definition id="22">
				<sentence>Let ug2lig be a mapping of UG1r to LIGS , such that if Gu = 〈Ru , As , L〉 ∈ UG1r then ug2lig ( Gu ) = 〈VN , Vt , Vs , Rli , S〉 , where VN = { N , S } ( fresh symbols ) , Vt = WORDS , Vs = FEATS ∪ { A | A ∈ NRFSS , |A| ≤ maxHt ( Gu ) } , and Rli is defined as follows:3 { C0 } and for every pi0 ∈ ΠC0 , the rule N [ Ψ ( C0 , pi0 ) ] → w is in Rli .</sentence>
				<definiendum id="0">|A| ≤ maxHt</definiendum>
				<definiendum id="1">Rli</definiendum>
				<definiendum id="2">rule N [ Ψ</definiendum>
				<definiens id="0">Gu ) = 〈VN , Vt , Vs , Rli , S〉 , where VN = { N , S } ( fresh symbols ) , Vt = WORDS , Vs = FEATS ∪ { A | A ∈ NRFSS</definiens>
			</definition>
			<definition id="23">
				<sentence>( e , µe ) , where 1 ≤ e ≤ n. Then for every X0 ∈ LIGHEAD ( C0 ) the rule X0 → N [ Ψ ( C1 , ε ) ] ... N [ Ψ ( Ce−1 , ε ) ] Xe N [ Ψ ( Ce+1 , ε ) ] ... N [ Ψ ( Cn , ε ) ] 3For a non-reentrant FS C0 , we define : LIGHEAD ( C0 ) as { N [ η ] | η ∈ FH ( C0 , maxHt ( Gu ) ) } ∪ { N [ η ∞ ] | η ∈ UH ( C0 , maxHt ( Gu ) ) } is in Rli , where Xe is defined as follows .</sentence>
				<definiendum id="0">maxHt ( Gu ) ) }</definiendum>
				<definiendum id="1">Xe</definiendum>
				<definiens id="0">µe ) , where 1 ≤ e ≤ n. Then for every X0 ∈ LIGHEAD ( C0 ) the rule X0 → N [ Ψ ( C1 , ε ) ] ... N [ Ψ ( Ce−1 , ε ) ] Xe N [ Ψ ( Ce+1 , ε ) ] ... N [ Ψ</definiens>
				<definiens id="1">LIGHEAD ( C0 ) as { N [ η ] | η ∈ FH ( C0 , maxHt ( Gu ) ) } ∪ { N [ η ∞ ] | η ∈ UH</definiens>
			</definition>
</paper>

		<paper id="2100">
</paper>

		<paper id="2029">
			<definition id="0">
				<sentence>We chose an inverse mapping based on the logarithm of lexical attraction ( cf. Figure 2 ) : p ( w , p ) = max ( 1 , min ( 0.8,1− ( 2−log3 ( LA ( w , p ) ) ) /50 ) ) µ where µ is a normalization constant that scales the highest occurring value of LA to 1 .</sentence>
				<definiendum id="0">LA</definiendum>
				<definiendum id="1">µ</definiendum>
				<definiens id="0">a normalization constant that scales the highest occurring value of LA to 1</definiens>
			</definition>
</paper>

		<paper id="1033">
			<definition id="0">
				<sentence>• A dependency graph for a string of words W = w1 ... wn is a labeled directed graph G = ( W , A ) , where : – W is the set of nodes , i.e. word tokens in the input string , ordered by a linear precedence relation &lt; .</sentence>
				<definiendum id="0">wn</definiendum>
				<definiendum id="1">– W</definiendum>
				<definiens id="0">the set of nodes , i.e. word tokens in the input string , ordered by a linear precedence relation &lt;</definiens>
			</definition>
			<definition id="1">
				<sentence>258 ( “The final of the tournament was distinguished by great fighting spirit and unexpected hardness” ) A7 Velkou great a63 Atr N7 bojovnost´ı fighting-spirit a63 Obj Co Jˆ a and a63 Coord A7 neˇcekanou unexpected a63 Atr N7 tvrdost´ı hardness a63 Obj Co P4 se itself a63 AuxT Vp vyznaˇcovalo distinguished N2 fin´ale final a63 Sb N2 turnaje of-the-tournament a63 Atr Figure 1 : Dependency graph for a Czech sentence from the Prague Dependency Treebank ( “The final of the tournament was distinguished by great fighting spirit and unexpected hardness” ) A7 Velkou great a63 Atr N7 bojovnost´ı fighting-spirit a63 Obj Jˆ a and a63 Coord A7 neˇcekanou unexpected a63 Atr N7 tvrdost´ı hardness a63 Obj P4 se itself a63 AuxT Vp vyznaˇcovalo distinguished N2 fin´ale final a63 Sb N2 turnaje of-the-tournament a63 Atr Figure 2 : Transformed dependency graph for a Czech sentence from the Prague Dependency Treebank this to MS is one of the hypotheses explored in the experimental study below .</sentence>
				<definiendum id="0">MS</definiendum>
				<definiens id="0">neˇcekanou unexpected a63 Atr N7 tvrdost´ı hardness a63 Obj Co P4 se itself a63 AuxT Vp vyznaˇcovalo distinguished N2 fin´ale final a63 Sb N2 turnaje of-the-tournament a63 Atr Figure 1 : Dependency graph for a Czech sentence from the Prague Dependency Treebank</definiens>
				<definiens id="1">a and a63 Coord A7 neˇcekanou unexpected a63 Atr N7 tvrdost´ı hardness a63 Obj P4 se itself a63 AuxT Vp vyznaˇcovalo distinguished N2 fin´ale final a63 Sb N2 turnaje</definiens>
			</definition>
			<definition id="2">
				<sentence>The PS-to-MS transformation for coordination will be designated τc ( ∆ ) , where ∆ is a data set .</sentence>
				<definiendum id="0">PS-to-MS transformation for coordination</definiendum>
				<definiendum id="1">∆</definiendum>
				<definiens id="0">a data set</definiens>
			</definition>
			<definition id="3">
				<sentence>Let C1 , ... , Cn be the elements of C , ordered by linear precedence , and let S1i , ... , Smi be the separators occurring between Ci and Ci+1 .</sentence>
				<definiendum id="0">C1 , ... , Cn be</definiendum>
				<definiendum id="1">, Smi</definiendum>
				<definiens id="0">the elements of C , ordered by linear precedence , and let S1i , ...</definiens>
			</definition>
			<definition id="4">
				<sentence>Then every Ci becomes the head of S1i , ... , Smi , Smi becomes the head of Ci+1 , and C1 becomes the only dependent of the original head of the base conjunction .</sentence>
				<definiendum id="0">C1</definiendum>
				<definiens id="0">the head of S1i , ... , Smi , Smi becomes the head of Ci+1 , and</definiens>
			</definition>
</paper>

		<paper id="2011">
			<definition id="0">
				<sentence>“ 紅 ( red ) 樓 ( chamber ) 夢 ( dream ) ” and “The Dream of the Red Chamber” Translating by Phonetic Values for Some Parts and by Meaning for the Others The entire NE is supposed to be translated by its meaning and the name parts are transliterated .</sentence>
				<definiendum id="0">“The Dream</definiendum>
				<definiens id="0">of the Red Chamber” Translating by Phonetic Values for Some Parts and by Meaning for the Others The entire NE is supposed to be translated by its meaning and the name parts are transliterated</definiens>
			</definition>
			<definition id="1">
				<sentence>SScore ( Ci , GN ) concerns both recurrences information and relative positions to evaluate the statistical relationship between Ci and GN .</sentence>
				<definiendum id="0">SScore</definiendum>
				<definiens id="0">concerns both recurrences information and relative positions to evaluate the statistical relationship between Ci and GN</definiens>
			</definition>
			<definition id="2">
				<sentence>A fragment unit of GN can be written as GNab , which denotes the ath to bth characters of GN , and b a &lt; 4 .</sentence>
				<definiendum id="0">GNab</definiendum>
				<definiens id="0">the ath to bth characters of GN , and b a &lt; 4</definiens>
			</definition>
			<definition id="3">
				<sentence>The linguistic similarity score between two fragments is : ) } , ( ) , , ( { ) , ( ijabijab ijab CGNWSSimCGNPVSimMax CGNLSim = Where PVSim ( ) estimates the similarity in phonetic values while WSSim ( ) estimate it in word senses .</sentence>
				<definiendum id="0">PVSim ( )</definiendum>
				<definiens id="0">estimates the similarity in phonetic values while WSSim ( ) estimate it in word senses</definiens>
			</definition>
			<definition id="4">
				<sentence>Edit distances are usually used to estimate the surface similarity between strings .</sentence>
				<definiendum id="0">Edit distances</definiendum>
				<definiens id="0">usually used to estimate the surface similarity between strings</definiens>
			</definition>
			<definition id="5">
				<sentence>Finally , the modified edit distance between two strings A and B is defined as follow :   ==  =      +−− +− +− = = = → → → → → → else BAiftsRep consonantaisBif vowlaisBiftIns tsReptsED tsED tInstsED tsED ssED ttED ts t t BA BA BA BA BA BA ,1 ,0 ) , ( ,1 ,0 ) ( ) , ( ) 1,1 ( ,1 ) ,1 ( ) , ( ) 1 , ( min ) , ( ) 0 , ( ) ,0 ( The modified edit distances are then transformed to similarity scores : ) } ( ) , ( max { ) ) ( ) , ( ( 1 ) , ( BLenALen BLenALenEDBAPVSim BA→−= Len ( ) denotes the length of the string .</sentence>
				<definiendum id="0">modified edit distance between two</definiendum>
				<definiendum id="1">B</definiendum>
				<definiendum id="2">tsED tInstsED tsED ssED ttED</definiendum>
				<definiendum id="3">BLenALen BLenALenEDBAPVSim BA→−= Len ( )</definiendum>
				<definiens id="0">ts t t BA BA BA BA BA BA ,1 ,0 ) , ( ,1 ,0 ) ( ) , ( ) 1,1 ( ,1 ) ,1 ( ) , ( ) 1 , ( min ) , ( ) 0 , ( ) ,0 ( The modified edit distances are then transformed to similarity scores : ) } ( )</definiens>
			</definition>
			<definition id="6">
				<sentence>Entropy function here concerns the possible cases of the most adjacent word at both ends of the candidate , as the following equation suggests :   ⋅− = = ∑ i iCT irNPTir i NCNCTNCNCT CEntropy else , /log/ 1context possible of # while,1 ) ofContext ( Where NCTr and NCi denote the appearing times of the rth context CTr and the candidate Ci in the returned snippets respectively , and NPTi denotes the total number of different cases of the context of Ci .</sentence>
				<definiendum id="0">Entropy function</definiendum>
				<definiendum id="1">NPTi</definiendum>
				<definiens id="0">Where NCTr and NCi denote the appearing times of the rth context CTr and the candidate Ci in the returned snippets respectively , and</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , assuming the context of “David” comprises three times of ( Craig , OTHER ) , three times of ( OTHER , Stern ) , and six times of ( OTHER , OTHER ) , then : 946.0 ) 126log126123log123123log123 ( ) David '' '' ofContext ( 333 =⋅+⋅+− =Entropy Next we use Entropy ( Context of Ci ) to weight the primitive score PSS ( Ci , GN ) to obtain the final statistical score. : ) ( ) ofContext ( ) ( , GNCPSSCEntropy , GNCSScore ii i ⋅ = In evaluating candidate , we concern only the appearing frequencies of candidates when the NE to be translated is presented .</sentence>
				<definiendum id="0">OTHER</definiendum>
				<definiendum id="1">OTHER</definiendum>
				<definiendum id="2">126log126123log123123log123 ( ) David '' '' ofContext</definiendum>
				<definiens id="0">the final statistical score. : ) ( ) ofContext ( ) ( , GNCPSSCEntropy</definiens>
			</definition>
</paper>

		<paper id="4007">
			<definition id="0">
				<sentence>This paper describes FERRET , an interactive question-answering ( Q/A ) system designed to address the challenges of integrating automatic Q/A applications into real-world environments .</sentence>
				<definiendum id="0">FERRET</definiendum>
				<definiens id="0">an interactive question-answering ( Q/A ) system designed to address the challenges of integrating automatic Q/A applications into real-world environments</definiens>
			</definition>
			<definition id="1">
				<sentence>FERRET utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions ( and answers ) that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario .</sentence>
				<definiendum id="0">FERRET</definiendum>
				<definiens id="0">utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the questions ( and answers ) that users need by analyzing how a user interacts with a system while gathering information related to a particular scenario</definiens>
			</definition>
			<definition id="2">
				<sentence>25 Figure 1 : The FERRET Interactive Q/A System Question-Answering System This section provides a basic overview of the functionality provided by the FERRET interactive Q/A system .</sentence>
				<definiendum id="0">FERRET Interactive Q/A System Question-Answering</definiendum>
				<definiens id="0">a basic overview of the functionality provided by the FERRET interactive Q/A system</definiens>
			</definition>
			<definition id="3">
				<sentence>First , FERRET utilizes an automatic Q/A system to nd answers to users’ questions in a document collection .</sentence>
				<definiendum id="0">FERRET</definiendum>
				<definiens id="0">utilizes an automatic Q/A system to nd answers to users’ questions in a document collection</definiens>
			</definition>
			<definition id="4">
				<sentence>As was mentioned in Section 2 , FERRET uses a special dialogue-optimized version of an automatic question-answering system in order to nd high-precision answers to users’ questions in a document collection .</sentence>
				<definiendum id="0">FERRET</definiendum>
				<definiens id="0">uses a special dialogue-optimized version of an automatic question-answering system in order to nd high-precision answers to users’ questions in a document collection</definiens>
			</definition>
			<definition id="5">
				<sentence>Unlike with syntactic decomposition , FERRET combines answers from semantically decomposed question automatically and presents users with a single set of answers that represents the contributions of each question .</sentence>
				<definiendum id="0">FERRET</definiendum>
				<definiens id="0">combines answers from semantically decomposed question automatically and presents users with a single set of answers that represents the contributions of each question</definiens>
			</definition>
</paper>

		<paper id="2112">
			<definition id="0">
				<sentence>The unlimited resource consists of a translation dictionary extracted from the alignment of Romanian and English WordNet .</sentence>
				<definiendum id="0">unlimited resource</definiendum>
				<definiens id="0">consists of a translation dictionary extracted from the alignment of Romanian and English WordNet</definiens>
			</definition>
			<definition id="1">
				<sentence>, ,|Pr ( ) , , , |Pr ( ) , , , ,| ( Pr ( ) , ,| , Pr ( ) , , , ,|Pr ( ) , ,| , ,Pr ( ) , ,| ( , , , CJ mlinmlink mlinkj mlinkmlinkj mlinkj mlijd nk nk nk ⋅ ⋅= ⋅= = ∑ ∑ ∑ ( 9 ) Where , is the estimated distortion probability .</sentence>
				<definiendum id="0">,|Pr</definiendum>
				<definiens id="0">( ) , , , |Pr ( ) , , , ,| ( Pr ( ) , ,| , Pr ( ) , , , ,|Pr ( ) , ,| , ,Pr ( ) , ,| ( , , , CJ mlinmlink mlinkj mlinkmlinkj mlinkj mlijd nk nk nk ⋅ ⋅= ⋅= = ∑ ∑ ∑ ( 9 ) Where , is the estimated distortion probability</definiens>
			</definition>
			<definition id="2">
				<sentence>n is the introduced length of an English sentence. )</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="3">
				<sentence>( Pr O c|fa , ) ( Pr I c|fa , λ is an interpolation weight .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiens id="0">an interpolation weight</definiens>
			</definition>
			<definition id="4">
				<sentence>n λ represents the weights for fertility probability .</sentence>
				<definiendum id="0">n λ</definiendum>
			</definition>
</paper>

		<paper id="2042">
			<definition id="0">
				<sentence>The CSJ is the biggest spontaneous speech corpus in the world , consisting of roughly 7M words with the total speech length of 700 hours , and is a collection of monologues such as academic presentations and simulated public speeches .</sentence>
				<definiendum id="0">CSJ</definiendum>
				<definiens id="0">the biggest spontaneous speech corpus in the world , consisting of roughly 7M words with the total speech length of 700 hours</definiens>
			</definition>
			<definition id="1">
				<sentence>The CSJ includes transcriptions of the speeches as well as audio recordings of them .</sentence>
				<definiendum id="0">CSJ</definiendum>
			</definition>
			<definition id="2">
				<sentence>We used YamCha ( Kudo and Matsumoto , 2001 ) as a text chunker , which is based on Support Vector Machine ( SVM ) .</sentence>
				<definiendum id="0">YamCha</definiendum>
			</definition>
</paper>

		<paper id="2085">
			<definition id="0">
				<sentence>id Context ( turns ) acc/ wfscore majority ( % ) acc/ wf-score Na¨ıve Bayes ( % ) 1 only current turn 83.0/54.9 81.0/68.3 2 current and next 71.3/50.4 72.01/68.2 3 current and previous 60.50/59.8 76.0*/75.3 4 previous , current , next 67.8/48.9 76.9*/ 74.8 Table 1 : Comparison of context definitions for local features ( * denotes p &lt; .05 ) also considered the current turn and the turn following ( and is thus not a “runtime” context ) .</sentence>
				<definiendum id="0">Context</definiendum>
				<definiens id="0">p &lt; .05 ) also considered the current turn and the turn following</definiens>
			</definition>
			<definition id="1">
				<sentence>In the next two sections we describe feature engineering techniques , namely discretising methods for dimensionality reduction and feature selection methods , which help to reduce the feature space to a subset which is most predictive of multimodal clarification .</sentence>
				<definiendum id="0">feature selection methods</definiendum>
				<definiens id="0">help to reduce the feature space to a subset which is most predictive of multimodal clarification</definiens>
			</definition>
			<definition id="2">
				<sentence>We chose Na¨ıve Bayes as a joint ( generative ) probabilistic model , using the WEKA implementation of ( John and Langley , 1995 ) ’s classifier ; Bayesian Networks as a graphical generative model , again using the WEKA implementation ; and we chose maxEnt as a discriminative ( conditional ) model , using the Maximum Entropy toolkit ( Le , 2003 ) .</sentence>
				<definiendum id="0">Na¨ıve Bayes</definiendum>
				<definiendum id="1">discriminative</definiendum>
				<definiens id="0">’s classifier ; Bayesian Networks as a graphical generative model</definiens>
			</definition>
			<definition id="3">
				<sentence>As a rule induction algorithm we used JRIP , the WEKA implementation of ( Cohen , 1995 ) ’s Repeated Incremental Pruning to Produce Error Reduction ( RIPPER ) .</sentence>
				<definiendum id="0">JRIP</definiendum>
			</definition>
			<definition id="4">
				<sentence>These rules ( in combination with the low thresholds ) say that if you have already shown a screen output to this particular user in any previous turn ( i.e. screenUser &gt; 1 ) , then do so again if the previous user speech act was a command ( i.e. userSpeechAct=command ) or if you have already shown a screen output in a previous turn in this dialogue ( i.e. screenHist &gt; 0.5 ) .</sentence>
				<definiendum id="0">rules</definiendum>
				<definiens id="0">in combination with the low thresholds</definiens>
			</definition>
</paper>

		<paper id="1128">
			<definition id="0">
				<sentence>“Synonym” is a list of synonyms and name variations .</sentence>
				<definiendum id="0">“Synonym”</definiendum>
				<definiens id="0">a list of synonyms and name variations</definiens>
			</definition>
			<definition id="1">
				<sentence>For biomedical terms other than genes/gene products , the Unified Medical Language System ( UMLS ) meta-thesaurus ( Lindberg et al. , 1993 ) is a large database that contains various names of biomedical and health-related concepts .</sentence>
				<definiendum id="0">Unified Medical Language System</definiendum>
				<definiens id="0">a large database that contains various names of biomedical and health-related concepts</definiens>
			</definition>
			<definition id="2">
				<sentence>Region algebra is defined as a set of operators on regions , i.e. , word sequences .</sentence>
				<definiendum id="0">Region algebra</definiendum>
				<definiens id="0">a set of operators on regions , i.e. , word sequences</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , “A &amp; B” denotes a region that includes both A and B. Four containment operators , &gt; , &gt; &gt; , &lt; , and &lt; &lt; , represent ancestor/descendant relations in XML .</sentence>
				<definiendum id="0">B”</definiendum>
				<definiens id="0">a region that includes both A and B. Four containment operators , &gt; , &gt; &gt; , &lt; , and &lt; &lt; , represent ancestor/descendant relations in XML</definiens>
			</definition>
			<definition id="4">
				<sentence>MEDLINE is an exhaustive database covering nearly 4,500 journals in the life sciences and includes the bibliographies of articles , about half of which have abstracts .</sentence>
				<definiendum id="0">MEDLINE</definiendum>
				<definiens id="0">an exhaustive database covering nearly 4,500 journals in the life sciences and includes the bibliographies of articles</definiens>
			</definition>
			<definition id="5">
				<sentence>Nominal keywords , i.e. , x and y , are replaced by [ entity_name gene_id= '' n '' ] or [ entity_name disease_id= '' n '' ] , where n is the ontological identifier of x or y. For verbal keywords , base= '' v '' is replaced by rel_type= '' r '' , where r is the event type of v. Our system is evaluated with respect to speed and accuracy .</sentence>
				<definiendum id="0">Nominal keywords</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">r</definiendum>
				<definiens id="0">the ontological identifier of x or y. For verbal keywords</definiens>
			</definition>
			<definition id="6">
				<sentence>The former is a traditional style of IR , in which sentences are retrieved by matching words in a query with words in sentences .</sentence>
				<definiendum id="0">former</definiendum>
				<definiens id="0">a traditional style of IR , in which sentences are retrieved by matching words in a query with words in sentences</definiens>
			</definition>
			<definition id="7">
				<sentence>Table 8 shows the precision attained by keyword/semantic search and n-precision , which denotes the precision of the keyword search , in which the same number , n , of outputs is taken as the semantic search .</sentence>
				<definiendum id="0">n-precision</definiendum>
				<definiens id="0">the precision of the keyword search , in which the same number , n , of outputs is taken as the semantic search</definiens>
			</definition>
			<definition id="8">
				<sentence>We demonstrated a text retrieval system for MEDLINE that exploits pre-computed semantic annotations5 .</sentence>
				<definiendum id="0">MEDLINE</definiendum>
				<definiens id="0">exploits pre-computed semantic annotations5</definiens>
			</definition>
</paper>

		<paper id="2117">
			<definition id="0">
				<sentence>1 A cept is defined as the set of target words connected to a source word ( Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">cept</definiendum>
			</definition>
			<definition id="1">
				<sentence>( Pr S e|fa , ) ( Pr U e|fa , λ is an interpolation weight .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiens id="0">an interpolation weight</definiens>
			</definition>
			<definition id="2">
				<sentence>L l to1= ( 3 ) For each sentence pair i , normalize the weights on the training set : ∑ == j lll mijwiwip , ... ,1 ) , ( / ) ( ) ( ( 4 ) Update the word alignment model based on the weighted training data .</sentence>
				<definiendum id="0">Update</definiendum>
				<definiens id="0">the word alignment model based on the weighted training data</definiens>
			</definition>
			<definition id="3">
				<sentence>|S| |SS| G CG ∩ =precision ( 12 ) |S| |SS| C CG ∩ =recall ( 11 ) ( 13 ) |||| ||2 CG CG SS SS fmeasure + ∩× = Where is the combined hypothesis for word alignment .</sentence>
				<definiendum id="0">|S| |SS| G CG ∩ =precision</definiendum>
				<definiens id="0">13 ) |||| ||2 CG CG SS SS fmeasure + ∩× = Where is the combined hypothesis for word alignment</definiens>
			</definition>
			<definition id="4">
				<sentence>`` Combination '' denotes the method described in section 4.4 , which combines `` Method 1 '' and `` Method 2 '' .</sentence>
				<definiendum id="0">Combination</definiendum>
				<definiens id="0">combines `` Method 1 '' and `` Method 2 ''</definiens>
			</definition>
</paper>

		<paper id="2078">
			<definition id="0">
				<sentence>ROUGE-N ( Lin , 2004 ) This measure compares n-grams of two summaries , and counts the number of matches .</sentence>
				<definiendum id="0">ROUGE-N</definiendum>
				<definiens id="0">n-grams of two summaries , and counts the number of matches</definiens>
			</definition>
			<definition id="1">
				<sentence>∑∑ ∑ ∑ ∈∈ ∈∈ =− RSSgram N RSSgram Nmatch N N gramCount gramCount NROUGE ) ( ) ( ( 3 ) where Count ( gram N ) is the number of an N-gram and Count match ( gram N ) denotes the number of ngram co-occurrences in two summaries .</sentence>
				<definiendum id="0">RSSgram N RSSgram Nmatch N N gramCount gramCount NROUGE ) ( )</definiendum>
				<definiens id="0">the number of an N-gram and Count match ( gram N ) denotes the number of ngram co-occurrences in two summaries</definiens>
			</definition>
			<definition id="2">
				<sentence>ROUGE-L ( Lin , 2004 ) This measure evaluates summaries by longest common subsequence ( LCS ) defined by Equation 4 .</sentence>
				<definiendum id="0">ROUGE-L</definiendum>
				<definiendum id="1">LCS</definiendum>
				<definiens id="0">This measure evaluates summaries by longest common subsequence (</definiens>
			</definition>
			<definition id="3">
				<sentence>m CrLCS LROUGE u ii i∑ = ∪ =− ) , ( ( 4 ) where LCS U ( r i , C ) is the LCS score of the union’s longest common subsequence between reference sentences r i and the summary to be evaluated , and m is the number of words contained in a reference summary .</sentence>
				<definiendum id="0">LCS U</definiendum>
				<definiendum id="1">m</definiendum>
				<definiens id="0">the number of words contained in a reference summary</definiens>
			</definition>
			<definition id="4">
				<sentence>m yxs Gap m k kk∑ = − = 1 | ) ( | ( 7 ) where x k is the k th system , s ( x k ) is a score of x k by Yasuda’s method , and y k is the manual score for the k th system .</sentence>
				<definiendum id="0">x k</definiendum>
				<definiendum id="1">y k</definiendum>
				<definiens id="0">the k th system , s ( x k ) is a score of x k by Yasuda’s method</definiens>
				<definiens id="1">the manual score for the k th system</definiens>
			</definition>
			<definition id="5">
				<sentence>Yasuda et al. ( 2003 ) tested DP matching ( Su et al. , 1992 ) , BLEU ( Papineni et al. , 2002 ) , and NIST 3 , as automatic methods used in their evaluation .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">Papineni et al. , 2002 ) , and NIST 3 , as automatic methods used in their evaluation</definiens>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>Recent attention to knowledge-rich problems such as question answering ( Pasca and Harabagiu 2001 ) and textual entailment ( Geffet and Dagan 2005 ) has encouraged natural language processing researchers to develop algorithms for automatically harvesting shallow semantic resources .</sentence>
				<definiendum id="0">question answering</definiendum>
				<definiens id="0">textual entailment ( Geffet and Dagan 2005 ) has encouraged natural language processing researchers to develop algorithms for automatically harvesting shallow semantic resources</definiens>
			</definition>
			<definition id="1">
				<sentence>Espresso uses a similar approach to infer patterns , but we make use of generic patterns and apply refining techniques to deal with wide variety of relations .</sentence>
				<definiendum id="0">Espresso</definiendum>
				<definiens id="0">uses a similar approach to infer patterns</definiens>
			</definition>
			<definition id="2">
				<sentence>Espresso ranks all patterns in P according to reliability r π and discards all but the top-k , where k is set to the number of patterns from the previous iteration plus one .</sentence>
				<definiendum id="0">Espresso</definiendum>
				<definiens id="0">ranks all patterns in P according to reliability r π and discards all but the top-k , where k is set to the number of patterns from the previous iteration plus one</definiens>
			</definition>
			<definition id="3">
				<sentence>Pointwise mutual information ( Cover and Thomas 1991 ) is a commonly used metric for measuring this strength of association between two events x and y : ( ) ( ) ( ) ( ) yPxP yxP yxpmi , log , = We define the reliability of a pattern p , r π ( p ) , as its average strength of association across each input instance i in I , weighted by the reliability of each instance i : ( ) ( ) I ir pipmi pr Ii pmi ∑ ∈ ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ ∗ = ι π max ) , ( where r ι ( i ) is the reliability of instance i ( defined below ) and max pmi is the maximum pointwise mutual information between all patterns and all instances .</sentence>
				<definiendum id="0">Pointwise mutual information</definiendum>
				<definiens id="0">a commonly used metric for measuring this strength of association between two events x</definiens>
			</definition>
			<definition id="4">
				<sentence>The pointwise mutual information between instance i = { x , y } and pattern p is estimated using the following formula : ( ) , ** , ,* , , , log , pyx ypx pipmi = where |x , p , y| is the frequency of pattern p instantiated with terms x and y and where the asterisk ( * ) represents a wildcard .</sentence>
				<definiendum id="0">y|</definiendum>
				<definiens id="0">y } and pattern p is estimated using the following formula : ( ) , ** , ,* , , , log , pyx ypx pipmi = where |x , p ,</definiens>
				<definiens id="1">the frequency of pattern p instantiated with terms x and y and where the asterisk ( *</definiens>
			</definition>
			<definition id="5">
				<sentence>Hence , analogous to our pattern reliability measure , we define the reliability of an instance i , r ι ( i ) , as : ( ) ( ) P pr pipmi ir Pp pmi ∑ ′∈ ∗ = π ι max ) , ( where r π ( p ) is the reliability of pattern p ( defined earlier ) and max pmi is as before .</sentence>
				<definiendum id="0">max pmi</definiendum>
				<definiens id="0">the reliability of pattern p</definiens>
			</definition>
			<definition id="6">
				<sentence>At a given Espresso iteration , where P R represents the set of previously selected reliable patterns , this intuition is captured by the following measure of confidence in an instance i = { x , y } : ( ) ( ) ( ) ∑ ∈ ×= R Pp p T pr iSiS π where T is the sum of the reliability scores r π ( p ) for each pattern p ∈ P R , and ( ) ( ) , ** , ,* , , , log , pyx ypx pipmiiS p × == 116 where pointwise mutual information between instance i and pattern p is estimated with Google as follows : ( ) pyx ypx iS p ×× ≈ , , An instance i is rejected if S ( i ) is smaller than some threshold τ .</sentence>
				<definiendum id="0">P R</definiendum>
				<definiens id="0">the set of previously selected reliable patterns</definiens>
				<definiens id="1">Pp p T pr iSiS π where T is the sum of the reliability scores r π ( p ) for each pattern p ∈ P R , and ( ) ( ) , ** , ,* , , , log</definiens>
			</definition>
			<definition id="7">
				<sentence>The sample consists of 5,951,432 words extracted from the following data files : AP890101 – AP890131 , AP890201 – AP890228 , and AP890310 – AP890319 .</sentence>
				<definiendum id="0">sample</definiendum>
				<definiens id="0">consists of 5,951,432 words extracted from the following data files : AP890101 – AP890131</definiens>
			</definition>
			<definition id="8">
				<sentence>Following ( Pantel et al. 2004 ) , we define the relative recall of system A given system B , R A|B , as : BP AP C C R R R B A B A C C C C B A BA B A × × ==== | where R A is the recall of A , C A is the number of correct instances extracted by A , C is the ( unknown ) total number of correct instances in the corpus , P A is A’s precision in our experiments , 2 The kappa statistic jumps to Κ = 0.79 if we treat partially correct classifications as correct .</sentence>
				<definiendum id="0">R A</definiendum>
				<definiendum id="1">C A</definiendum>
				<definiendum id="2">C</definiendum>
				<definiens id="0">the relative recall of system A given system B , R A|B , as : BP AP C C R R R B A B A C C C C B A BA B A × × ==== | where</definiens>
				<definiens id="1">the number of correct instances extracted by A ,</definiens>
			</definition>
			<definition id="9">
				<sentence>Espresso is the first system , to our knowledge , to emphasize concurrently performance , minimal supervision , breadth , and generality .</sentence>
				<definiendum id="0">Espresso</definiendum>
				<definiens id="0">the first system , to our knowledge , to emphasize concurrently performance , minimal supervision , breadth , and generality</definiens>
			</definition>
</paper>

		<paper id="4006">
			<definition id="0">
				<sentence>The growing number of electronically available knowledge sources ( KSs ) emphasizes the importance of developing flexible and efficient tools for automatic knowledge acquisition and structuring in terms of knowledge integration .</sentence>
				<definiendum id="0">KSs )</definiendum>
				<definiens id="0">emphasizes the importance of developing flexible and efficient tools for automatic knowledge acquisition and structuring in terms of knowledge integration</definiens>
			</definition>
			<definition id="1">
				<sentence>The main goal of literature mining is to retrieve knowledge that is “buried” in a text and to present the distilled knowledge to users in a concise form .</sentence>
				<definiendum id="0">literature mining</definiendum>
				<definiens id="0">to retrieve knowledge that is “buried” in a text and to present the distilled knowledge to users in a concise form</definiens>
			</definition>
			<definition id="2">
				<sentence>In this paper , we introduce a knowledge structuring system ( KSS ) we designed , in which terminology-driven knowledge acquisition ( KA ) , knowledge retrieval ( KR ) and knowledge visualization ( KV ) are combined using automatic term recognition , automatic term clustering and terminology-based similarity calculation is explained .</sentence>
				<definiendum id="0">knowledge retrieval</definiendum>
				<definiendum id="1">knowledge visualization</definiendum>
				<definiens id="0">combined using automatic term recognition , automatic term clustering and terminology-based similarity calculation is explained</definiens>
			</definition>
			<definition id="3">
				<sentence>Our approach to structuring knowledge is based on : • automatic term recognition ( ATR ) • automatic term clustering ( ATC ) as an ontology 1 development • ontology-based similarity calculation • visualization of relationships among documents ( KSs ) One of our definitions to structuring knowledge is discovery of relevance between documents ( KSs ) and its visualization .</sentence>
				<definiendum id="0">KSs</definiendum>
				<definiens id="0">• automatic term recognition ( ATR ) • automatic term clustering ( ATC ) as an ontology 1 development • ontology-based similarity calculation • visualization of relationships among documents</definiens>
				<definiens id="1">discovery of relevance between documents</definiens>
			</definition>
			<definition id="4">
				<sentence>Term variants ( i.e. synonymous terms ) are dealt with in the initial phase of ATR when term candidates are singled out , as opposed to other approaches ( e.g. FASTR handles variants subsequently by applying transformation rules to extracted terms ) .</sentence>
				<definiendum id="0">Term variants</definiendum>
				<definiens id="0">i.e. synonymous terms ) are dealt with in the initial phase of ATR when term candidates are singled out</definiens>
			</definition>
			<definition id="5">
				<sentence>MIMA Search extracts the contents from the listed syllabuses , rearrange these syllabuses according to semantic relations of the contents and display the results graphically , whereas conventional search engines simply list the syllabuses that are related to the keywords .</sentence>
				<definiendum id="0">MIMA Search</definiendum>
				<definiens id="0">extracts the contents from the listed syllabuses</definiens>
			</definition>
</paper>

		<paper id="4011">
			<definition id="0">
				<sentence>Figure2 : The results of tagging performance with different setting of weight and threshold for applicable collocations ( Note that C_T denotes the frequency threshold of collocation ) The goal of the CARE System is to allow a learner to look for instances of sentences labeled with moves .</sentence>
				<definiendum id="0">Figure2</definiendum>
				<definiendum id="1">C_T</definiendum>
				<definiens id="0">the frequency threshold of collocation ) The goal of the CARE System is to allow a learner to look for instances of sentences labeled with moves</definiens>
			</definition>
</paper>

		<paper id="2077">
			<definition id="0">
				<sentence>On average , MCD achieves an improvement of approximately 10 % in accuracy over the baseline .</sentence>
				<definiendum id="0">MCD</definiendum>
				<definiens id="0">achieves an improvement of approximately 10 % in accuracy over the baseline</definiens>
			</definition>
</paper>

		<paper id="2094">
			<definition id="0">
				<sentence>We propose a new paradigm of Information Extraction which operates 'on demand ' in response to a user 's query .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiens id="0">operates 'on demand ' in response to a user 's query</definiens>
			</definition>
			<definition id="1">
				<sentence>The goal of information extraction ( IE ) is to extract such information : to make these regular structures explicit , in forms such as tabular databases .</sentence>
				<definiendum id="0">information extraction</definiendum>
				<definiens id="0">to extract such information : to make these regular structures explicit</definiens>
			</definition>
</paper>

		<paper id="2007">
			<definition id="0">
				<sentence>WordNet is a large lexical database of English words .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>Lexico-syntactic Patterns ( Hearst , 1992 ) A substring occurring between the two segments extracted from text in nodes in which both segments appear .</sentence>
				<definiendum id="0">Lexico-syntactic Patterns</definiendum>
				<definiens id="0">A substring occurring between the two segments extracted from text in nodes in which both segments appear</definiens>
			</definition>
</paper>

		<paper id="4017">
</paper>

		<paper id="1057">
			<definition id="0">
				<sentence>The SVMLight ( Joachims , 1999 ) classifier was used in the supervised settings with its default parameters .</sentence>
				<definiendum id="0">SVMLight</definiendum>
				<definiens id="0">used in the supervised settings with its default parameters</definiens>
			</definition>
			<definition id="1">
				<sentence>The Lesk algorithm is one of the first algorithms developed for semantic disambiguation of all-words in unrestricted text .</sentence>
				<definiendum id="0">Lesk algorithm</definiendum>
			</definition>
			<definition id="2">
				<sentence>The algorithm looks for words in the sense definitions that overlap with context words in the given sentence , and chooses the sense that yields maximal word overlap .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiens id="0">looks for words in the sense definitions that overlap with context words in the given sentence , and chooses the sense that yields maximal word overlap</definiens>
			</definition>
</paper>

		<paper id="3015">
			<definition id="0">
				<sentence>CLAVIUS is the result of an effort to combine sensing technologies for several modality types , speech and video-tracked gestures chief among them , within the immersive virtual environment ( Boussemart,2004 ) showninFigure1 .</sentence>
				<definiendum id="0">CLAVIUS</definiendum>
			</definition>
			<definition id="1">
				<sentence>Whereas existing bi-directional chart parsers maintain fully-qualified edges by incrementally adding adjacent input words to the agenda , CLAVIUS has the ability to construct parses that instantiate only a subset of their constituents , so Γabc also parses the input “B” , for example .</sentence>
				<definiendum id="0">CLAVIUS</definiendum>
				<definiens id="0">has the ability to construct parses that instantiate only a subset of their constituents</definiens>
			</definition>
			<definition id="2">
				<sentence>CLAVIUS expands parses according to a best-first process where newly expanded edges are ordered according to trainable criteria of multimodal language , as discussed in §3 .</sentence>
				<definiendum id="0">CLAVIUS expands</definiendum>
				<definiens id="0">parses according to a best-first process where newly expanded edges</definiens>
			</definition>
			<definition id="3">
				<sentence>The COGNITION thread monitors the best sentence-level hypothesis , ΨB , in Ξ [ SInact ] , and terminates the search process once ΨB has remained unchallenged by new competing parses for some period of time .</sentence>
				<definiendum id="0">COGNITION thread</definiendum>
				<definiens id="0">monitors the best sentence-level hypothesis</definiens>
			</definition>
			<definition id="4">
				<sentence>We emphasise more common grammatical constructions by augmenting each grammar rule with an associated probability , P ( Γi ) , and assigning κ3 ( Ψ ) = P ( RULE ( Ψ ) ) ·productdisplay Ψc=constituent of Ψ κ3 ( Ψc ) where RULE is the top-level expansion of Ψ .</sentence>
				<definiendum id="0">RULE</definiendum>
				<definiens id="0">the top-level expansion of Ψ</definiens>
			</definition>
			<definition id="5">
				<sentence>To test whether the best-first approach compensates for CLAVIUS ’ looser constraints ( §1.2 ) , a simple bottom-up multichart parser ( §1.1 ) was constructed and the average number of edges it produces on sentences of varying length was measured .</sentence>
				<definiendum id="0">looser constraints</definiendum>
				<definiens id="0">a simple bottom-up multichart parser ( §1.1 ) was constructed and the average number of edges it produces on sentences of varying length was measured</definiens>
			</definition>
</paper>

		<paper id="1096">
			<definition id="0">
				<sentence>In their model , the correspondence h consists of ( 1 ) the segmentation of the input sentence into phrases , ( 2 ) the segmentation of the output sentence into the same number of phrases , and ( 3 ) a bijection between the input and output phrases .</sentence>
				<definiendum id="0">correspondence h</definiendum>
			</definition>
			<definition id="1">
				<sentence>At the end we ran our models once on TEST to get final numbers.2 Our experiments used phrase-based models ( Koehn et al. , 2003 ) , which require a translation table and language model for decoding and feature computation .</sentence>
				<definiendum id="0">phrase-based models</definiendum>
				<definiens id="0">require a translation table and language model for decoding and feature computation</definiens>
			</definition>
			<definition id="2">
				<sentence>Lexical language model features have been exploited successfully in discriminative language modeling to improve speech recognition performance ( Roark et al. , 2004 ) .</sentence>
				<definiendum id="0">Lexical language model features</definiendum>
			</definition>
			<definition id="3">
				<sentence>We confirm the utility of the two kinds of lexical features : BLANKET+LEX achieves a BLEU score of 35.0 , an improvement of 1.6 over BLANKET .</sentence>
				<definiendum id="0">BLANKET+LEX</definiendum>
				<definiens id="0">achieves a BLEU score of 35.0 , an improvement of 1.6 over BLANKET</definiens>
			</definition>
			<definition id="4">
				<sentence>An interesting statistic is the number of nonzero feature weights that were learned using each feature set .</sentence>
				<definiendum id="0">statistic</definiendum>
				<definiens id="0">the number of nonzero feature weights that were learned using each feature set</definiens>
			</definition>
</paper>

		<paper id="2034">
			<definition id="0">
				<sentence>GEOQUERY is a logical query language for a small database of U.S. geography containing about 800 facts .</sentence>
				<definiendum id="0">GEOQUERY</definiendum>
				<definiens id="0">a logical query language for a small database of U.S. geography containing about 800 facts</definiens>
			</definition>
			<definition id="1">
				<sentence>The GEOQUERY language consists of Prolog queries augmented with several meta-predicates ( Zelle and Mooney , 1996 ) .</sentence>
				<definiendum id="0">GEOQUERY language</definiendum>
				<definiens id="0">consists of Prolog queries augmented with several meta-predicates</definiens>
			</definition>
			<definition id="2">
				<sentence>The symbols P , H and Li are the semantic label of the parent , head , and the ith left child , w is the head word of the parent , t is the semantic label of the head word , δ is the distance between the head and the modifier , and LC is the left semantic subcat .</sentence>
				<definiendum id="0">w</definiendum>
				<definiendum id="1">LC</definiendum>
				<definiens id="0">the semantic label of the head word</definiens>
				<definiens id="1">the left semantic subcat</definiens>
			</definition>
			<definition id="3">
				<sentence>The model is composed of three parts ( Collins , 2002a ) : a set of candidate SAPTs GEN , which is the top n SAPTs of a sentence from SCISSOR ; a function Φ that maps a sentence Inputs : A set of training examples ( xi , y∗i ) , i = 1 ... n , where xi is a sentence , and y∗i is a candidate SAPT that has the highest similarity score with the gold-standard SAPT Initialization : Set ¯W = 0 Algorithm : For t = 1 ... T , i = 1 ... n Calculate yi = argmaxy∈GEN ( xi ) Φ ( xi , y ) · ¯W If ( yi negationslash= y∗i ) then ¯W = ¯W +Φ ( xi , y∗i ) − Φ ( xi , yi ) Output : The parameter vector ¯W Figure 2 : The perceptron training algorithm .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiendum id="1">y∗i</definiendum>
				<definiens id="0">the top n SAPTs of a sentence from SCISSOR ; a function Φ that maps a sentence Inputs : A set of training examples</definiens>
				<definiens id="1">a sentence</definiens>
				<definiens id="2">a candidate SAPT that has the highest similarity score with the gold-standard SAPT Initialization : Set ¯W = 0 Algorithm : For t = 1 ... T , i = 1 ... n Calculate yi = argmaxy∈GEN ( xi ) Φ ( xi , y ) · ¯W If ( yi negationslash= y∗i ) then ¯W = ¯W +Φ ( xi , y∗i ) − Φ ( xi , yi ) Output : The parameter vector ¯W Figure 2 : The perceptron training algorithm</definiens>
			</definition>
			<definition id="4">
				<sentence>The example in Figure 3 has the feature f ( [ PRN→ -LRBNP COMMA NP -RRB- ] , NP ) =1 , where NP is the syntactic label above the rule “PRN→ -LRBNP COMMA NP -RRB-” .</sentence>
				<definiendum id="0">NP</definiendum>
			</definition>
			<definition id="5">
				<sentence>The example in Figure 3 has the feature f ( [ NP COMMA , right , PRN ] , NP ) =1 , where NP is the syntactic label above the constituent PRN .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">the syntactic label above the constituent PRN</definiens>
			</definition>
			<definition id="6">
				<sentence>ure 3 has the feature f ( [ NUM1 NUM2 , right , POINT ] , POINT ) =1 , where the last POINT is the semantic label above the POINT associated with PRN .</sentence>
				<definiendum id="0">POINT</definiendum>
				<definiens id="0">the semantic label above the POINT associated with PRN</definiens>
			</definition>
			<definition id="7">
				<sentence>n 1 2 5 10 20 50 CLANG 78.0 81.3 83.0 84.0 85.0 85.3 GEOQUERY 77.2 77.6 80.0 81.2 81.6 81.6 Table 3 : Oracle recalls on CLANG and GEOQUERY as a function of number n of n-best SAPTs .</sentence>
				<definiendum id="0">Oracle</definiendum>
				<definiens id="0">recalls on CLANG and GEOQUERY as a function of number n of n-best SAPTs</definiens>
			</definition>
			<definition id="8">
				<sentence>The symbol SEM1 and SEM2 refer to the semantic feature sets in Section 3.2.1 and 3.2.1 respectively , and SYN refers to the syntactic feature set in Section 3.1 .</sentence>
				<definiendum id="0">SYN</definiendum>
				<definiens id="0">the semantic feature sets in Section 3.2.1 and 3.2.1 respectively , and</definiens>
			</definition>
</paper>

		<paper id="1088">
			<definition id="0">
				<sentence>The tagger uses conditional probabilities of the form P ( y|x ) where y is a tag and x is a local context containing y. The conditional probabilities have the following log-linear form : P ( y|x ) = 1Z ( x ) e summationtext i λifi ( x , y ) ( 1 ) where Z ( x ) is a normalisation constant which ensures a proper probability distribution for each context x. The feature functions fi ( x , y ) are binaryvalued , returning either 0 or 1 depending on the tag y and the value of a particular contextual predicate given the context x. Contextual predicates identify elements of the context which might be useful for predicting the tag .</sentence>
				<definiendum id="0">y</definiendum>
				<definiendum id="1">Z ( x )</definiendum>
				<definiens id="0">a normalisation constant which ensures a proper probability distribution for each context x. The feature functions fi ( x , y ) are binaryvalued , returning either 0 or 1 depending on the tag y and the value of a particular contextual predicate given the context x. Contextual predicates identify elements of the context which might be useful for predicting the tag</definiens>
			</definition>
			<definition id="1">
				<sentence>MLE has a tendency to overfit the training data .</sentence>
				<definiendum id="0">MLE</definiendum>
			</definition>
			<definition id="2">
				<sentence>Our multi-tagging approach follows that of Clark and Curran ( 2004a ) and Charniak et al. ( 1996 ) : assign all categories to a word whose probabilities are within a factor , β , of the probability of the most probable category for that word : Ci = { c | P ( Ci = c|S ) &gt; β P ( Ci = cmax|S ) } Ci is the set of categories assigned to the ith word ; Ci istherandomvariablecorrespondingtothecategory of the ith word ; cmax is the category with the highest probability of being the category of the ith word ; andS is the sentence .</sentence>
				<definiendum id="0">Ci</definiendum>
				<definiendum id="1">cmax</definiendum>
				<definiendum id="2">andS</definiendum>
				<definiens id="0">assign all categories to a word whose probabilities are within a factor , β , of the probability of the most probable category for that word : Ci = { c | P ( Ci = c|S ) &gt; β P ( Ci = cmax|S ) }</definiens>
				<definiens id="1">the set of categories assigned to the ith word ; Ci istherandomvariablecorrespondingtothecategory of the ith word ;</definiens>
			</definition>
			<definition id="3">
				<sentence>Parsing using CCG can be viewed as a two-stage process : firstassignlexicalcategoriestothewords in the sentence , and then combine the categories 699 The WSJ is a paper that I enjoy reading NP/N N ( S [ dcl ] \NP ) /NP NP/N N ( NP\NP ) / ( S [ dcl ] /NP ) NP ( S [ dcl ] \NP ) / ( S [ ng ] \NP ) ( S [ ng ] \NP ) /NP Figure 1 : Example sentence with CCG lexical categories .</sentence>
				<definiendum id="0">WSJ</definiendum>
				<definiens id="0">a two-stage process : firstassignlexicalcategoriestothewords in the sentence</definiens>
			</definition>
</paper>

		<paper id="2090">
			<definition id="0">
				<sentence>For Shepherd and Watters ( 1998 ) and the practical implementation Shepherd et al. ( 2004 ) , cybergenres or web genres are characterized by the triple &lt; content , form , functionality &gt; , where functionality is a key evolutionary aspect afforded by the web .</sentence>
				<definiendum id="0">functionality</definiendum>
				<definiens id="0">characterized by the triple &lt; content , form , functionality &gt;</definiens>
				<definiens id="1">a key evolutionary aspect afforded by the web</definiens>
			</definition>
			<definition id="1">
				<sentence>The attributes &lt; linguistic features , HTML tags , text types &gt; of the tuple represent the computationally tractable version of the combination &lt; purpose , form &gt; often used to define the concept of genre ( e.g. cf. Roussinov et al. 2001 ) .</sentence>
				<definiendum id="0">HTML</definiendum>
			</definition>
			<definition id="2">
				<sentence>Argumentation is a rhetorical pattern , or text type , expressed by a combination of linguistic features .</sentence>
				<definiendum id="0">Argumentation</definiendum>
				<definiens id="0">a rhetorical pattern , or text type , expressed by a combination of linguistic features</definiens>
			</definition>
			<definition id="3">
				<sentence>Odds is a number that tells us how much more likely one hypothesis is than the other .</sentence>
				<definiendum id="0">Odds</definiendum>
			</definition>
			<definition id="4">
				<sentence>That is , if a web page has description_narration and argumentation_persuasion as the two predominant text types , and the page length is &gt; 500 words ( LONG ) , and the probability value for blog words is &gt; =0.5 ( blog words are terms such as web log , weblog , blog , journal , diary , posted by , comments , archive plus names of the days and months ) , then this web page is a good blog candidate .</sentence>
				<definiendum id="0">LONG</definiendum>
				<definiens id="0">terms such as web log , weblog , blog , journal , diary , posted by , comments , archive plus names of the days and months</definiens>
			</definition>
			<definition id="5">
				<sentence>Cybergenre : Automatic Identification of Home Pages on the Web .</sentence>
				<definiendum id="0">Cybergenre</definiendum>
			</definition>
</paper>

		<paper id="1070">
			<definition id="0">
				<sentence>Cross-language Text Categorization is the task of assigning semantic classes to documents written in a target language ( e.g. English ) while the system is trained using labeled documents in a source language ( e.g. Italian ) .</sentence>
				<definiendum id="0">Cross-language Text Categorization</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the worldwide scenario of the Web age , multilinguality is a crucial issue to deal with and to investigate , leading us to reformulate most of the classical Natural Language Processing ( NLP ) problems into a multilingual setting .</sentence>
				<definiendum id="0">multilinguality</definiendum>
				<definiens id="0">a crucial issue to deal with and to investigate , leading us to reformulate most of the classical Natural Language Processing ( NLP ) problems into a multilingual setting</definiens>
			</definition>
			<definition id="2">
				<sentence>In a more precise way , let L = fL1 , L2 , ... , Llg be a set of languages , let Ti = fti1 , ti2 , ... , ting be a collection of texts expressed in the language Li 2 L , and let ψ ( tjh , tiz ) be a function that returns 1 if tiz is the translation of tjh and 0 otherwise .</sentence>
				<definiendum id="0">L2 , ... , Llg</definiendum>
				<definiens id="0">a function that returns 1 if tiz is the translation of tjh and 0 otherwise</definiens>
			</definition>
			<definition id="3">
				<sentence>In the monolingual settings , the Vector Space Model ( VSM ) is a k-dimensional space Rk , in which the text tj 2 T is represented by means of the vector vectortj such that the zth component of vectortj is the frequency of wz in tj .</sentence>
				<definiendum id="0">Vector Space Model</definiendum>
				<definiendum id="1">VSM )</definiendum>
				<definiendum id="2">vectortj</definiendum>
				<definiens id="0">a k-dimensional space Rk , in which the text tj 2 T is represented by means of the vector vectortj such that the zth component of</definiens>
			</definition>
			<definition id="4">
				<sentence>A MDM is a multilingual extension of the concept of Domain Model .</sentence>
				<definiendum id="0">MDM</definiendum>
				<definiens id="0">a multilingual extension of the concept of Domain Model</definiens>
			</definition>
			<definition id="5">
				<sentence>Each cluster represents a semantic domain , i.e. a set of terms that often co-occur in texts having similar topics .</sentence>
				<definiendum id="0">cluster</definiendum>
				<definiens id="0">a semantic domain</definiens>
			</definition>
			<definition id="6">
				<sentence>The function D is de ned by2 D ( vectortj ) = vectortj ( IIDFD ) = vectortprimej ( 1 ) where IIDF is a diagonal matrix such that iIDFi , l = IDF ( wli ) , vectortj is represented as a row vector , and IDF ( wli ) is the Inverse Document Frequency of 2In ( Wong et al. , 1985 ) the formula 1 is used to de ne a Generalized Vector Space Model , of which the Domain VSM is a particular instance .</sentence>
				<definiendum id="0">IIDF</definiendum>
				<definiendum id="1">IDF ( wli )</definiendum>
				<definiens id="0">the Inverse Document Frequency of 2In ( Wong et al. , 1985 ) the formula 1 is used to de ne a Generalized Vector Space Model , of which the Domain VSM is a particular instance</definiens>
			</definition>
			<definition id="7">
				<sentence>LSA is an unsupervised technique for estimating the similarity among texts and terms in a large corpus .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">an unsupervised technique for estimating the similarity among texts and terms in a large corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>The BoW kernel is a particular case of the Domain Kernel , in which D = I , and I is the identity matrix .</sentence>
				<definiendum id="0">BoW kernel</definiendum>
				<definiens id="0">a particular case of the Domain Kernel , in which D = I</definiens>
			</definition>
</paper>

		<paper id="3005">
			<definition id="0">
				<sentence>The BNC was chosen for training the model because it is a POS-annotated corpus , which allows supervised training .</sentence>
				<definiendum id="0">POS-annotated corpus</definiendum>
				<definiens id="0">allows supervised training</definiens>
			</definition>
</paper>

		<paper id="2012">
			<definition id="0">
				<sentence>Let X = { xi } ni=1 be the set of context vectors of occurrences of all entity mention pairs , where xi represents the context vector of the i-th occurrence , and n is the total number of occurrences of all entity mention pairs .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the total number of occurrences of all entity mention pairs</definiens>
			</definition>
			<definition id="1">
				<sentence>Input : A set of context vectors X = { x1 , x2 , ... , xn } , X ∈Rfracturn×d ; Output : Clustered data and number of clusters ; 2 ij σ2 ) if i negationslash=j , 0 if i = j. Here , s ij is the similarity between xi and xj calculated by Cosine similarity measure .</sentence>
				<definiendum id="0">Input</definiendum>
				<definiens id="0">A set of context vectors X = { x1 , x2 , ... , xn }</definiens>
			</definition>
			<definition id="2">
				<sentence>and the free distance parameter σ2 is used to scale the weights ; D−1/2AD−1/2 , where D is a diagonal matrix whose ( i , i ) element is the sum of A’s ith row ; Arrange them in a matrix Y .</sentence>
				<definiendum id="0">D</definiendum>
				<definiens id="0">a diagonal matrix whose ( i , i ) element is the sum of A’s ith row ; Arrange them in a matrix Y</definiens>
			</definition>
			<definition id="3">
				<sentence>Table 1 shows the details of the whole algorithm for context clustering , which contains two main stages : 1 ) Transformation of Clustering Space ( Step 1-4 ) ; 2 ) Clustering in the transformed space using Elongated K-means algorithm ( Step 5-6 ) .</sentence>
				<definiendum id="0">context clustering</definiendum>
				<definiens id="0">contains two main stages : 1</definiens>
			</definition>
			<definition id="4">
				<sentence>The elongated K-means algorithm computes the distance of point x from the center ci as follows : • If the center is not very near the origin , cTi ci &gt; epsilon1 ( epsilon1 is a parameter to be fixed by the user ) , the distances are calculated as : edist ( x , ci ) = ( x − ci ) TM ( x− ci ) , where M = 1λ ( Iq − cicTicT i ci ) +λcicTicT i ci , λ is the sharpness parameter that controls the elongation ( the smaller , the more elongated the clusters ) 2 .</sentence>
				<definiendum id="0">epsilon1</definiendum>
				<definiendum id="1">λ</definiendum>
				<definiens id="0">a parameter to be fixed by the user ) , the distances are calculated as : edist ( x , ci ) = ( x − ci ) TM ( x− ci )</definiens>
			</definition>
			<definition id="5">
				<sentence>P W is the within-cluster scatter matrix as : PW = summationtextcj=1summationtextX i∈χj ( Xi − mj ) ( Xi − mj ) t and PB is the between-cluster scatter matrix as : PB = summationtextcj=1 ( mj − m ) ( mj − m ) t , where m is the total mean vector and mj is the mean vector for jth cluster and ( Xj − mj ) t is the matrix transpose of the column vector ( Xj −mj ) .</sentence>
				<definiendum id="0">P W</definiendum>
				<definiendum id="1">PB</definiendum>
				<definiendum id="2">m</definiendum>
				<definiendum id="3">mj</definiendum>
				<definiens id="0">the within-cluster scatter matrix as : PW = summationtextcj=1summationtextX i∈χj ( Xi − mj ) ( Xi − mj ) t and</definiens>
				<definiens id="1">the between-cluster scatter matrix as : PB = summationtextcj=1</definiens>
				<definiens id="2">the total mean vector and</definiens>
				<definiens id="3">the mean vector for jth cluster</definiens>
			</definition>
</paper>

		<paper id="2050">
			<definition id="0">
				<sentence>Briefly , HanziNet is consisted of two main parts : 387 Figure 2 : The Schematic Representation of character-triggered tree-like conceptual hierarchy and word-based semantic network a character-stored machine-readable lexicon and a top-level character ontology .</sentence>
				<definiendum id="0">HanziNet</definiendum>
				<definiendum id="1">Schematic Representation</definiendum>
				<definiens id="0">character-triggered tree-like conceptual hierarchy and word-based semantic network a character-stored machine-readable lexicon and a top-level character ontology</definiens>
			</definition>
			<definition id="1">
				<sentence>However , as we argued previously , HanziNet takes a different perspective in locating theoretical roles of Hanzi .</sentence>
				<definiendum id="0">HanziNet</definiendum>
			</definition>
			<definition id="2">
				<sentence>uni0052uni004Funi004Funi0054 uni004Funi0042uni004A uni0053uni0055uni0042uni004A uni0043uni004Funi004Euni0043uni0052uni0045uni0054uni0045 uni0041uni0042uni0053uni0054uni0052uni0041uni0043uni0054 uni0045uni0058uni0049uni0053uni0054uni0045uni004Euni0043uni0045 uni0041uni0052uni0054uni0049uni0046uni0041uni0043uni0054 uni0045uni0058uni0043uni0049uni0054uni0041uni0042uni004Cuni0045 uni0043uni004Funi0047uni004Euni0049uni0054uni0049uni0056uni0045 uni0053uni0045uni004Duni0049uni004Funi0054uni0049uni0043 uni0052uni0045uni004Cuni0041uni0054uni0049uni004Funi004Euni0041uni004C uni0053uni0045uni004Euni0053uni0041uni0054uni0049uni004Funi004E uni0053uni0054uni0041uni0054uni0045 uni0049uni004Euni004Euni0041uni0054uni0045 uni0053uni004Funi0043uni0049uni0041uni004C uni0063uni006Funi006Euni0073uni0065uni0074uni0020uni0031 uni0063uni006Funi006Euni0073uni0065uni0074uni0020uni0033uni0030uni0039 uni0063uni006Funi006Euni0073uni0065uni0074uni0020uni0032uni0063uni006Funi006Euni0073uni0065uni0074uni0020uni0033uni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni0063uni006Funi006Euni0073uni0065uni0074uni0020uni0033uni0030uni0038uni0063uni006Funi006Euni0073uni0065uni0074uni0020uni0033uni0030uni0037 uni007Buni91D1uni9280uni9285uni9435uni932Buni6C27uni78B3uni92C1uni78F7uni7812uni6C2Buni6C2Euni007D uni007Buni6D77uni6D0Buni6CBCuni6FA4uni6E56uni6CCAuni6C60uni5858uni6F6Duni6EAAuni6CB3uni85EAuni007D uni007Buni990Auni4FDDuni8892uni8B77uni5E87uni4F51uni8F14uni885Buni9867uni5ED5uni620Cuni007D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002Duni002D uni002Duni002Duni002Duni002Duni002Duni002D uni007Buni96FBuni6CE2uni78C1uni007D uni007Buni8B1Duni8FADuni62D2uni99C1uni63A8uni7D55uni916Cuni4EA4uni7DE0uni7D50uni8655uni9080uni7D04uni966Auni4F34uni8FCEuni007Duni007Buni5C60uni6C7Auni622Euni52E6uni527Funi8A85uni6BB2uni5937uni6BC0uni6EC5uni6CEFuni5BB0uni6BBAuni6B8Auni007D Figure 4 : The character ontology : a snapshot In addition , an experiment concerning the character network that was based on the meaning aspects of characters , was performed from a statistical point of view .</sentence>
				<definiendum id="0">character ontology</definiendum>
				<definiens id="0">a snapshot In addition , an experiment concerning the character network that was based on the meaning aspects of characters</definiens>
			</definition>
			<definition id="3">
				<sentence>Table 1 : Statistical characteristics of the character network : N is the total number of nodes ( characters ) , k istheaveragenumberoflinks per node , C is the clustering coefficient , and L is the average shortest-path length , and Lmax is the maximum length of the shortest path between a pair of characters in the network .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">L</definiendum>
				<definiendum id="2">Lmax</definiendum>
				<definiens id="0">Statistical characteristics of the character network : N is the total number of nodes ( characters ) , k istheaveragenumberoflinks per node</definiens>
				<definiens id="1">the clustering coefficient , and</definiens>
				<definiens id="2">the average shortest-path length , and</definiens>
				<definiens id="3">the maximum length of the shortest path between a pair of characters in the network</definiens>
			</definition>
			<definition id="4">
				<sentence>N is the total number of nodes ( characters ) , k is the average number of links per node , C is the clustering coefficient , andLis the average shortest path .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the total number of nodes ( characters ) , k is the average number of links per node ,</definiens>
				<definiens id="1">the clustering coefficient</definiens>
			</definition>
</paper>

		<paper id="2070">
			<definition id="0">
				<sentence>METEOR is essentially a unigram based metric , which prefers the monotonic word alignment between MT output and the references by penalizing crossing word alignments .</sentence>
				<definiendum id="0">METEOR</definiendum>
				<definiendum id="1">metric</definiendum>
				<definiens id="0">prefers the monotonic word alignment between MT output</definiens>
			</definition>
			<definition id="1">
				<sentence>METEOR is a metric sitting in the middle of the n-gram based metrics and the loose se540 mt1 : Life is like one nice chocolate in box ref : Life is just like a box of tasty chocolate ref : Life is just like a box of tasty chocolate mt2 : Life is of one nice chocolate in box Figure 2 : Alignment Example for METEOR quence based metrics .</sentence>
				<definiendum id="0">METEOR</definiendum>
				<definiens id="0">a metric sitting in the middle of the n-gram based metrics</definiens>
			</definition>
			<definition id="2">
				<sentence>Though the two alignments have the same number of word mappings , mt2 gets more crossed word mappings than mt1 , thus it will get less credits in METEOR .</sentence>
				<definiendum id="0">mt2</definiendum>
				<definiens id="0">gets more crossed word mappings than mt1</definiens>
			</definition>
			<definition id="3">
				<sentence>The subroutine COMPUTE SCORE , which computes the score gained from the current aligned positions , is shown in Figure 4 .</sentence>
				<definiendum id="0">subroutine COMPUTE SCORE</definiendum>
				<definiens id="0">computes the score gained from the current aligned positions</definiens>
			</definition>
			<definition id="4">
				<sentence>2Although the marginalized probability ( over all French words ) of an English word given the other English word ( PNk=1 p ( ei|fk ) p ( fk|ej ) ) is a more intuitive way of measuring the similarity , the dot product of the vectors p ( e|f ) described above performed slightly better in our experiments .</sentence>
				<definiendum id="0">marginalized probability</definiendum>
				<definiens id="0">over all French words</definiens>
			</definition>
			<definition id="5">
				<sentence>BLEU-n denotes the BLEU metric with the longest n-gram of length n. F denotes uency , A denotes adequacy , and O denotes overall .</sentence>
				<definiendum id="0">BLEU-n</definiendum>
				<definiendum id="1">O</definiendum>
				<definiens id="0">the BLEU metric with the longest n-gram of length n. F denotes uency , A denotes adequacy , and</definiens>
			</definition>
			<definition id="6">
				<sentence>SIA is designed to take the advantage of loosesequence-based metrics without losing word-level information .</sentence>
				<definiendum id="0">SIA</definiendum>
				<definiens id="0">designed to take the advantage of loosesequence-based metrics without losing word-level information</definiens>
			</definition>
			<definition id="7">
				<sentence>B3 denotes BLEU-3 ; R 1 denotes the skipped bigram based ROUGE metric which considers all skip distances and uses PORTER-STEM ; R 2 denotes ROUGE-W with PORTER-STEM ; M denotes the METEOR metric using PORTER-STEM and WORD-NET synonym ; S denotes SIA .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">; S</definiendum>
				<definiens id="0">the skipped bigram based ROUGE metric which considers all skip distances and uses PORTER-STEM</definiens>
				<definiens id="1">the METEOR metric using PORTER-STEM and WORD-NET synonym</definiens>
			</definition>
			<definition id="8">
				<sentence>To estimate the significance of the correlations , bootstrap resampling ( Koehn , 2004 ) is used to randomly select 5514 sentences with replacement out of the whole test set of 5514 sentences , and then the correlation coef cients are computed based on the selected sentence set .</sentence>
				<definiendum id="0">bootstrap resampling</definiendum>
				<definiens id="0">computed based on the selected sentence set</definiens>
			</definition>
			<definition id="9">
				<sentence>SIA uses stochastic word mapping to allow soft or partial matches between the MT hypotheses and the references .</sentence>
				<definiendum id="0">SIA</definiendum>
				<definiens id="0">uses stochastic word mapping to allow soft or partial matches between the MT hypotheses and the references</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>The BNC was chosen for training the model because it is a POS-annotated corpus , which allows supervised training .</sentence>
				<definiendum id="0">POS-annotated corpus</definiendum>
				<definiens id="0">allows supervised training</definiens>
			</definition>
			<definition id="1">
				<sentence>Currently , probability re-ranking is one way to make systematic module-internal predictions about the garden-path effect .</sentence>
				<definiendum id="0">probability re-ranking</definiendum>
				<definiens id="0">one way to make systematic module-internal predictions about the garden-path effect</definiens>
			</definition>
			<definition id="2">
				<sentence>A SuperTag is an elementary syntactic tree , or simply a structural description composed of features like POS , the number of complements , category of each complement , and the position of complements .</sentence>
				<definiendum id="0">SuperTag</definiendum>
				<definiens id="0">an elementary syntactic tree , or simply a structural description composed of features like POS , the number of complements</definiens>
			</definition>
</paper>

		<paper id="4001">
			<definition id="0">
				<sentence>Multiple-choice test format on grammaticality consists of two kinds : one is the traditional multiple-choice test and the other is the error detection test .</sentence>
				<definiendum id="0">Multiple-choice test format on grammaticality</definiendum>
				<definiens id="0">consists of two kinds : one is the traditional multiple-choice test and the other is the error detection test</definiens>
			</definition>
			<definition id="1">
				<sentence>On the other hand , error detection item consists of a partially underlined sentence ( stem ) where one choice of the underlined part represents the error ( key ) and the other underlined parts act as distractors to distract test takers .</sentence>
				<definiendum id="0">error detection item</definiendum>
			</definition>
			<definition id="2">
				<sentence>, “writing” is the pivot word according to the construct pattern { * VBD VBG * } .</sentence>
				<definiendum id="0">“writing”</definiendum>
				<definiens id="0">the pivot word according to the construct pattern { * VBD VBG * }</definiens>
			</definition>
</paper>

		<paper id="2084">
			<definition id="0">
				<sentence>in tf·idf vector space zi=f ( wi|Cz ) · Ndf ( wi ) ; df ( wi ) =| { x : wiepsilon1Cx } | a=f ( xy ) b=f ( x¯y ) f ( x∗ ) c=f ( ¯xy ) d=f ( ¯x¯y ) f ( ¯x∗ ) f ( ∗y ) f ( ∗¯y ) N A contingency table contains observed frequencies and marginal frequencies for a bigram xy ; ¯w stands for any word except w ; ∗ stands for any word ; N is a total number of bigrams .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">a total number of bigrams</definiens>
			</definition>
			<definition id="1">
				<sentence>For each cross-validation data fold we define average precision ( AP ) as the expected value of precision for all possible values of recall ( assuming uniform distribution ) and mean average precision ( MAP ) as a mean of this measure computed for each data fold .</sentence>
				<definiendum id="0">average precision</definiendum>
				<definiendum id="1">AP</definiendum>
				<definiendum id="2">MAP</definiendum>
				<definiens id="0">the expected value of precision for all possible values of recall ( assuming uniform distribution ) and mean average precision</definiens>
			</definition>
			<definition id="2">
				<sentence>Each collocation candidate xi can be described by the feature vector xi = ( xi1 , ... , xi82 ) T consisting of 82 association scores from Table 1 and assigned a label yi ∈ { 0,1 } which indicates whether the bigram is considered to be a collocation ( y =1 ) or not ( y = 0 ) .</sentence>
				<definiendum id="0">collocation candidate xi</definiendum>
				<definiens id="0">the feature vector xi = ( xi1 , ... , xi82 ) T consisting of 82 association scores from Table 1 and assigned a label yi ∈ { 0,1 } which indicates whether the bigram</definiens>
			</definition>
			<definition id="3">
				<sentence>where logit ( pi ) =log ( pi/ ( 1−pi ) ) is a canonical link function for odds-ratio and pi ∈ ( 0,1 ) is a conditional probability for positive response given a vector x. The estimation of β0 and β is done by maximum likelihood method which is solved by the iteratively reweighted least squares algorithm .</sentence>
				<definiendum id="0">logit ( pi</definiendum>
				<definiens id="0">a conditional probability for positive response given a vector x. The estimation of β0 and β is done by maximum likelihood method which is solved by the iteratively reweighted least squares algorithm</definiens>
			</definition>
			<definition id="4">
				<sentence>The basic idea of Fisher’s linear discriminant analysis ( LDA ) is to find a one-dimensional projection defined by a vector c so that for the projected combination cTx the ratio of the between variance B to the within variance W is maximized : maxc c TBc cTWc After projection , cTxcan be directly used as ranker .</sentence>
				<definiendum id="0">LDA</definiendum>
				<definiens id="0">to find a one-dimensional projection defined by a vector c so that for the projected combination cTx the ratio of the between variance B to the within variance W is maximized : maxc c TBc cTWc After projection</definiens>
			</definition>
			<definition id="5">
				<sentence>The goal in support vector machines ( SVM ) is to estimate a function f ( x ) =β0+βTxand find a classifier y ( x ) = signparenleftbigf ( x ) parenrightbig which can be solved through the following convex optimization : min β0 , β nsummationdisplay i=1 bracketleftbig1−yi ( β 0 +βT xi ) bracketrightbig++ λ 2||β|| 2 with λ as a regularization parameter .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">to estimate a function f ( x ) =β0+βTxand find a classifier y ( x ) = signparenleftbigf ( x ) parenrightbig which can be solved through the following convex optimization : min β0 , β nsummationdisplay i=1 bracketleftbig1−yi ( β 0 +βT xi ) bracketrightbig++ λ 2||β|| 2 with λ as a regularization parameter</definiens>
			</definition>
			<definition id="6">
				<sentence>As an alternative to a often inappropriate grid Recall Average precision Neural network ( 5 units ) Support vector machine ( linear ) Linear discriminant analysis Neural network ( 1 unit ) Linear logistic regression Cosine context similarity in boolean vector space ( 77 ) Unigram subtuple measure ( 39 ) Figure 4 : Precision-recall curves of selected methods combining all association measures compared with curves of two best measures employed individually on the same data sets .</sentence>
				<definiendum id="0">vector machine</definiendum>
				<definiens id="0">Precision-recall curves of selected methods combining all association measures compared with curves of two best measures employed individually on the same data sets</definiens>
			</definition>
			<definition id="7">
				<sentence>search , Hastie ( 2004 ) proposed an effective algorithm which fits the entire SVM regularization path [ β0 ( λ ) , β ( λ ) ] and gave us the option to choose the optimal value of λ .</sentence>
				<definiendum id="0">effective algorithm</definiendum>
			</definition>
</paper>

		<paper id="2044">
			<definition id="0">
				<sentence>In general , a noun consists of a root and a single affix , which provides a combination of gender and number marking .</sentence>
				<definiendum id="0">single affix</definiendum>
			</definition>
			<definition id="1">
				<sentence>Some plural forms involve reduplication of some part of the word ending , e.g. declension 4 nouns form their plural by adding ‘aC’ where ‘C’ is the final consonant of the root , but this can easily be handled by using spelling rules .</sentence>
				<definiendum id="0">‘C’</definiendum>
				<definiens id="0">Some plural forms involve reduplication of some part of the word ending</definiens>
			</definition>
			<definition id="2">
				<sentence>Again , a typical verb consists of a root plus a number of affixes .</sentence>
				<definiendum id="0">typical verb</definiendum>
				<definiens id="0">consists of a root plus a number of affixes</definiens>
			</definition>
			<definition id="3">
				<sentence>English transitive verb ( SOV ) { syn ( nonfoot ( head ( cat ( xbar ( +v , -n ) ) ) ) , subcat ( args ( [ −−−−−−→”NP” ( obj ) , ←−−−−−−−”NP” ( subj ) ] ) ) ) } Persian transitive verb ( SOV ) { syn ( nonfoot ( head ( cat ( xbar ( +v , -n ) ) ) ) , subcat ( args ( [ ←−−−−−−”NP” ( obj ) , ←−−−−−−−”NP” ( subj ) ] ) ) ) } Arabic transitive verb ( VSO ) { syn ( nonfoot ( head ( cat ( xbar ( +v , -n ) ) ) ) , subcat ( args ( [ −−−−−−−→”NP” ( subj ) , −−−−−−→”NP” ( obj ) ] ) ) ) } Figure 3 : Subcat frames Items such as adjectival phrases , PPs and relative clauses which add information about some target item combine via a principle captured in Fig .</sentence>
				<definiendum id="0">PPs</definiendum>
				<definiens id="0">Subcat frames Items such as adjectival phrases</definiens>
			</definition>
			<definition id="4">
				<sentence>sug++++aa 0 object 0 agent somaliTopic nim+ k+a det baa comp ( baa ) somaliTopic focus bare+ k+a det Figure 12 : Parse tree for ( 6 ) topical ( ref ( λC ( NIM ( C ) ) ) ) &amp; focus ( ref ( λD ( BARE ( D ) ) ) ) &amp; claim ( ∃B : { aspect ( now , simple , B ) } θ ( B , object , ref ( λEthing ( E ) ) ) &amp; θ ( B , agent , ref ( λGspeaker ( G ) ) ) &amp; SUG ( B ) ) Figure 13 : Interpretation for ( 6 ) Treating ‘baa’ as an item which looks first to its left for an NP and then acts as a sentence modifier gives us a fairly simple analysis of ( 6 ) , ensuring that when we have ‘baa’ we do indeed have a 341 focused item , and also accounting for its complementary distribution with ‘waa’ .</sentence>
				<definiendum id="0">SUG</definiendum>
				<definiens id="0">simple , B ) } θ ( B , object , ref ( λEthing ( E ) ) ) &amp; θ ( B , agent , ref ( λGspeaker ( G ) )</definiens>
			</definition>
			<definition id="5">
				<sentence>Somali allows for scarenominal sentences consisting of just a pair of NPs .</sentence>
				<definiendum id="0">Somali</definiendum>
				<definiens id="0">allows for scarenominal sentences consisting of just a pair of NPs</definiens>
			</definition>
			<definition id="6">
				<sentence>Gender polarity : Theoretical aspects of Somali nominal morphology .</sentence>
				<definiendum id="0">Gender polarity</definiendum>
				<definiens id="0">Theoretical aspects of Somali nominal morphology</definiens>
			</definition>
</paper>

		<paper id="1118">
			<definition id="0">
				<sentence>All services provided by the platform are organised as classical 3-tier architectures with a presentation layer ( in charge of the interface with users ) , a business layer ( which provides the services per se ) and a data layer ( in charge of the storage of persistent data ) .</sentence>
				<definiendum id="0">business layer</definiendum>
				<definiens id="0">provides the services per se ) and a data layer ( in charge of the storage of persistent data )</definiens>
			</definition>
			<definition id="1">
				<sentence>The LexALP term bank consists in 5 volumes ( forFrench , German , Italian , SloveneandEnglish ) containing all term descriptions ( grammatical information , definition , contexts etc. ) .</sentence>
				<definiendum id="0">LexALP term bank</definiendum>
			</definition>
			<definition id="2">
				<sentence>An interlingual acception ( or axie ) is a place holder for relations .</sentence>
				<definiendum id="0">interlingual acception</definiendum>
				<definiens id="0">a place holder for relations</definiens>
			</definition>
</paper>

		<paper id="2089">
			<definition id="0">
				<sentence>The deterministic parsing algorithm involves two main data structures : a stack S , and a queue W. Items in S may be terminal nodes ( part-ofspeech-tagged words ) , or ( lexicalized ) subtrees of the final parse tree for the input string .</sentence>
				<definiendum id="0">deterministic parsing algorithm</definiendum>
				<definiens id="0">involves two main data structures : a stack S , and a queue W. Items in S may be terminal nodes ( part-ofspeech-tagged words ) , or ( lexicalized ) subtrees of the final parse tree for the input string</definiens>
			</definition>
			<definition id="1">
				<sentence>Classes have one of the following forms : SHIFT : represents a shift action ; REDUCE-UNARY-XX : represents a unary reduce action , where the root of the new subtree pushed onto S is of type XX ( where XX is a non-terminal symbol , typically NP , VP , PP , for example ) ; REDUCE-LEFT-XX : represents a binary reduce action , where the root of the new sub693 tree pushed onto S is of non-terminal type XX .</sentence>
				<definiendum id="0">XX</definiendum>
				<definiens id="0">a non-terminal symbol</definiens>
				<definiens id="1">a binary reduce action , where the root of the new sub693 tree pushed onto S is of non-terminal type XX</definiens>
			</definition>
			<definition id="2">
				<sentence>Ratnaparkhi’s parser uses maximum-entropy models to determine the actions of a parser based to some extent on the shift-reduce framework , and it is also capable of pursuing several paths and returning the topn highest scoring parses for a sentence .</sentence>
				<definiendum id="0">Ratnaparkhi’s parser</definiendum>
				<definiens id="0">uses maximum-entropy models to determine the actions of a parser based to some extent on the shift-reduce framework</definiens>
			</definition>
</paper>

		<paper id="1069">
			<definition id="0">
				<sentence>Few similar comparative studies have been reported for Text Categorization ( Li et al. , 2003 ) so far in literature .</sentence>
				<definiendum id="0">Text Categorization</definiendum>
				<definiens id="0">Li et al. , 2003 ) so far in literature</definiens>
			</definition>
			<definition id="1">
				<sentence>ICTCLAS is one of the best word segmentation systems ( SIGHAN 2003 ) and reaches a segmentation precision of more than 97 % , so we choose it as a representative of state-of-the-art schemes for automatic word-indexing of document ) .</sentence>
				<definiendum id="0">ICTCLAS</definiendum>
			</definition>
			<definition id="2">
				<sentence>Support Vector Machine ( SVM ) is one of the best classifiers at present ( Vapnik , 1995 ; Joachims , 1998 ) , so we choose it as the main classifier in this study .</sentence>
				<definiendum id="0">Support Vector Machine ( SVM )</definiendum>
				<definiens id="0">one of the best classifiers at present</definiens>
			</definition>
			<definition id="3">
				<sentence>Good ( representative ) sub-bigrams of a word are quite likely to be ranked close to the word itself .</sentence>
				<definiendum id="0">Good</definiendum>
				<definiens id="0">the word itself</definiens>
			</definition>
			<definition id="4">
				<sentence>Feature Quantity ( Aizawa , 2000 ) is suitable for this purpose because it comes from information theory and is additive ; tfidf was also reported as an appropriate metric of feature quantity ( defined as “probability ⋅ information” ) .</sentence>
				<definiendum id="0">Feature Quantity</definiendum>
				<definiens id="0">suitable for this purpose because it comes from information theory and is additive ; tfidf was also reported as an appropriate metric of feature quantity ( defined as “probability ⋅ information” )</definiens>
			</definition>
</paper>

		<paper id="2125">
			<definition id="0">
				<sentence>An HMM for discrete symbol observations is characterized by the following : the state set Q = { qi } , where 1 ≤ i ≤ N , N is the number of states the number of distinct observation symbol per state M -the state-transition probability distribution A= { aij } , where aij=P [ qt+1=j|qt=i ] , 1 ≤ i , j ≤ N -the observation symbol probability distribution B= { bj ( k ) } , where ] | [ ) ( jqvoPkb tktj === , 1 ≤ i , j ≤ N the initial state distribution pi= { pii } , where pii =P [ ot=vk|qt=j ] , 1 ≤ i , j ≤ M .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the number of states the number of distinct observation symbol per state M -the state-transition probability distribution A= { aij }</definiens>
			</definition>
			<definition id="1">
				<sentence>The following expressions are used to implement calculations , State probability distribution , Ni ≤≤1 Fi is the occurring times of state qi the state-transition probability distribution } { jiaA = , i ij ij F Fa ≈ , Nji ≤≤ ,1 , Fij is the occurring times of state pair ( qi , qj ) .</sentence>
				<definiendum id="0">State probability distribution</definiendum>
				<definiendum id="1">Ni ≤≤1 Fi</definiendum>
				<definiendum id="2">Fij</definiendum>
				<definiens id="0">the occurring times of state qi the state-transition probability distribution }</definiens>
			</definition>
			<definition id="2">
				<sentence>termination : = = N i T iOP 1 ) ( ) | ( αλ where T is the number of observations .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the number of observations</definiens>
			</definition>
			<definition id="3">
				<sentence>B BSS a − −= 1 where S is the ratio of the number of correct word pairs to the total number of word pairs ; B is the ratio of non-breaks to the number of word-pairs .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">B</definiendum>
				<definiens id="0">the ratio of non-breaks to the number of word-pairs</definiens>
			</definition>
</paper>

		<paper id="1086">
			<definition id="0">
				<sentence>We present MAGEAD , a morphological analyzer and generator for the Arabic language family .</sentence>
				<definiendum id="0">MAGEAD</definiendum>
				<definiens id="0">a morphological analyzer and generator for the Arabic language family</definiens>
			</definition>
			<definition id="1">
				<sentence>Modern Standard Arabic ( MSA ) is the shared written language from Morocco to the Gulf , but it is not a native language of anyone .</sentence>
				<definiendum id="0">MSA )</definiendum>
				<definiens id="0">the shared written language from Morocco to the Gulf , but it is not a native language of anyone</definiens>
			</definition>
			<definition id="2">
				<sentence>In unscripted situations where spoken MSA would normally be required ( such as talk shows on TV ) , speakers usually resort to repeated code-switching between their dialect and MSA , as nearly all native speakers of Arabic are unable to produce sustained spontaneous discourse in MSA .</sentence>
				<definiendum id="0">MSA</definiendum>
				<definiens id="0">nearly all native speakers of Arabic are unable to produce sustained spontaneous discourse in MSA</definiens>
			</definition>
			<definition id="3">
				<sentence>The root morpheme is a sequence of three , four , or five consonants ( termed radicals ) that signifies some abstract meaning shared by all its derivations .</sentence>
				<definiendum id="0">root morpheme</definiendum>
			</definition>
			<definition id="4">
				<sentence>The pattern morpheme is an abstract template in which roots and vocalisms are inserted .</sentence>
				<definiendum id="0">pattern morpheme</definiendum>
				<definiens id="0">an abstract template in which roots and vocalisms are inserted</definiens>
			</definition>
			<definition id="5">
				<sentence>An example of a phonological rewrite rule is the voicing of the /t/ of the verbal pattern V1tV2V3 ( Form VIII ) when the first root radical is /z/ , /d/ , or /*/ ( a32 , a33 , or a34 ) : the verbal stem zhr+V1tV2V3+iaa is realized phonologically as /izdahar/ ( orthographically : a35a37a36a38a33a39a32a38a40 ) ‘flourish’ not /iztahar/ ( orthographically : a35a37a24a41a4a6a32a42a40 ) .</sentence>
				<definiendum id="0">a34</definiendum>
				<definiens id="0">/z/ , /d/ , or /*/ ( a32 , a33 , or</definiens>
			</definition>
			<definition id="6">
				<sentence>The lexeme-and-features representation of this word form is as follows : ( 2 ) Root : zhr MBC : verb-VIII POS : V PER:3 GEN : F NUM : SG ASPECT : PERF An MBC maps sets of linguistic feature-value pairs to sets of abstract morphemes .</sentence>
				<definiendum id="0">zhr MBC</definiendum>
				<definiendum id="1">verb-VIII POS</definiendum>
				<definiens id="0">V PER:3 GEN : F NUM : SG ASPECT : PERF An MBC maps sets of linguistic feature-value pairs to sets of abstract morphemes</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , MBC verb-VIII maps the feature-value pair ASPECT : PERF to the abstract root morpheme [ PAT PV : VIII ] , which in MSA corresponds to the concrete root morpheme AV1tV2V3 , while the MBC verb-I maps ASPECT : PERF to the abstract root morpheme [ PAT PV : I ] , which in MSA corresponds to the concrete root morpheme 1V2V3 .</sentence>
				<definiendum id="0">MBC verb-VIII</definiendum>
			</definition>
			<definition id="8">
				<sentence>For example , the root node of our MBC hierarchy is a word , and all Arabic words share certain mappings , such as that from the linguistic feature conj : w to the clitic w+ .</sentence>
				<definiendum id="0">MBC hierarchy</definiendum>
				<definiens id="0">a word , and all Arabic words share certain mappings</definiens>
			</definition>
</paper>

		<paper id="2032">
			<definition id="0">
				<sentence>We then show that XMG ( eXtensible MetaGrammar ) provides a sophisticated treatment of identifiers which is effective in supporting a linguist-friendly grammar design .</sentence>
				<definiendum id="0">XMG</definiendum>
				<definiendum id="1">eXtensible MetaGrammar )</definiendum>
				<definiens id="0">provides a sophisticated treatment of identifiers which is effective in supporting a linguist-friendly grammar design</definiens>
			</definition>
			<definition id="1">
				<sentence>The semantic representation language is a flat semantic representation language ( Bos , 1995 ) with the following syntax : Description : := lscript : p ( E1 , ... , En ) | ¬lscript : p ( E1 , ... , En ) | Ei lessmuch Ej Description ∧ Description ( 2 ) where lscript is a label , p is a predicate and E1 , .</sentence>
				<definiendum id="0">semantic representation language</definiendum>
				<definiendum id="1">En</definiendum>
				<definiendum id="2">lscript</definiendum>
				<definiendum id="3">p</definiendum>
				<definiens id="0">a flat semantic representation language ( Bos , 1995 ) with the following syntax : Description : := lscript : p ( E1 , ... , En ) | ¬lscript : p ( E1 , ... ,</definiens>
			</definition>
			<definition id="2">
				<sentence>Specifically , a Class associates a name with a content : Class : := Name → { Content } ( 3 ) A Content is either a Description ( i.e. , a tree description , a semantic formula or both ) , a class name , a conjunction or a disjunction of class name : Content : := Description | Name | Name ∨ Name | Name ∧ Name ( 4 ) Further , XMG allows multiple inheritance : a given class can import or inherit one or more classes ( written Ci here ) : 3By large , we mean the transitive reflexive closure of dominance .</sentence>
				<definiendum id="0">Class</definiendum>
				<definiendum id="1">Content</definiendum>
				<definiens id="0">associates a name with a content : Class : := Name → { Content }</definiens>
				<definiens id="1">Content : := Description | Name | Name ∨ Name | Name ∧ Name</definiens>
			</definition>
			<definition id="3">
				<sentence>X is visible in B. In case of multiple inheritance 4Note that disjunctive inheritance is not supported which would allow a block to be defined as importing one or more classes from a given set of imported classes 5Similarly , import declaration can be used to restrict the set of accessible identifiers to a subset of it .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">the set of accessible identifiers to a subset of it</definiens>
			</definition>
			<definition id="4">
				<sentence>Finally , XMG provides a very economical way of identifying node variables based on the use of colours ( also called polarities in the literature ) .</sentence>
				<definiendum id="0">XMG</definiendum>
				<definiens id="0">provides a very economical way of identifying node variables based on the use of colours ( also called polarities in the literature )</definiens>
			</definition>
			<definition id="5">
				<sentence>Recall ( cf. section 4.2 ) that exported identifiers are best used within restricted , linguistically well defined hierarchies .</sentence>
				<definiendum id="0">Recall</definiendum>
			</definition>
			<definition id="6">
				<sentence>DyALog : a tabular logic programming based environment for NLP .</sentence>
				<definiendum id="0">DyALog</definiendum>
				<definiens id="0">a tabular logic programming based environment for NLP</definiens>
			</definition>
</paper>

		<paper id="2018">
			<definition id="0">
				<sentence>Cast3LB contains around 3,500 constituency trees ( 100,000 words ) taken from different genres of European and Latin American Spanish .</sentence>
				<definiendum id="0">Cast3LB</definiendum>
				<definiens id="0">contains around 3,500 constituency trees ( 100,000 words ) taken from different genres of European and Latin American Spanish</definiens>
			</definition>
			<definition id="1">
				<sentence>MBL and MaxEnt show a very similar performance , while SVM outperforms both , t t t t t log ( n ) Accuracy s s s s s m m m m m Figure 4 : Learning curves for TiMBL ( t ) , MaxEnt ( m ) and SVM ( s ) .</sentence>
				<definiendum id="0">MBL</definiendum>
				<definiendum id="1">SVM</definiendum>
				<definiendum id="2">SVM</definiendum>
				<definiens id="0">outperforms both , t t t t t log ( n ) Accuracy s s s s s m m m m m Figure 4 : Learning curves for TiMBL ( t )</definiens>
			</definition>
			<definition id="2">
				<sentence>Following Crouch et al. ( 2002 ) , we convert the f-structures to triples of the form 〈GF , Pi , Pj〉 , where Pi is the value of the PRED attribute of the f-structure , GF is an LFG grammatical function attribute , and Pj is the value of the PRED attribute of the f-structure which is the value of the GF attribute .</sentence>
				<definiendum id="0">Pi</definiendum>
				<definiendum id="1">GF</definiendum>
				<definiendum id="2">Pj</definiendum>
				<definiens id="0">the value of the PRED attribute of the f-structure</definiens>
				<definiens id="1">an LFG grammatical function attribute , and</definiens>
				<definiens id="2">the value of the PRED attribute of the f-structure which is the value of the GF attribute</definiens>
			</definition>
</paper>

		<paper id="1059">
			<definition id="0">
				<sentence>Formally , the computational cost of training semiCRFs is O ( KLN ) , where L is the upper bound length of entities , N is the length of sentence and K is the size of label set .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">N</definiendum>
				<definiendum id="2">K</definiendum>
				<definiens id="0">the upper bound length of entities</definiens>
				<definiens id="1">the length of sentence and</definiens>
				<definiens id="2">the size of label set</definiens>
			</definition>
			<definition id="1">
				<sentence>CRFs allow both discriminative training and bi-directional flow of probabilistic information along the sequence .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiens id="0">both discriminative training and bi-directional flow of probabilistic information along the sequence</definiens>
			</definition>
			<definition id="2">
				<sentence>In NER , we often use linear-chain CRFs , which define the conditional probability of a state sequence y = y1 , ... , yn given the observed sequence x = x1 , ... , xn by : p ( y|x , λ ) = 1Z ( x ) exp ( Σni=1Σjλjfj ( yi−1 , yi , x , i ) ) , ( 1 ) where fj ( yi−1 , yi , x , i ) is a feature function and Z ( x ) is the normalization factor over all the state sequences for the sequence x. The model parameters are a set of real-valued weights λ = { λj } , each of which represents the weight of a feature .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiens id="0">define the conditional probability of a state sequence y = y1 , ... , yn given the observed sequence x = x1 , ... , xn by : p ( y|x , λ ) = 1Z ( x ) exp ( Σni=1Σjλjfj ( yi−1 , yi</definiens>
			</definition>
			<definition id="3">
				<sentence>Semi-CRFs define a conditional probability of a state sequence y given an observed sequence x by : p ( y|x , λ ) = 1Z ( x ) exp ( ΣjΣiλifi ( sj ) ) , ( 2 ) where fi ( sj ) : = fi ( yj−1 , yj , x , tj , uj ) is a feature function and Z ( x ) is the normalization factor as defined for CRFs .</sentence>
				<definiendum id="0">Semi-CRFs</definiendum>
				<definiendum id="1">uj )</definiendum>
				<definiens id="0">a feature function</definiens>
				<definiens id="1">the normalization factor as defined for CRFs</definiens>
			</definition>
			<definition id="4">
				<sentence>The computational cost for semi-CRFs is O ( KLN ) where L is the upper bound length of entities , N is the length of sentence and K is the number of label set .</sentence>
				<definiendum id="0">computational cost for semi-CRFs</definiendum>
				<definiendum id="1">L</definiendum>
				<definiendum id="2">N</definiendum>
				<definiendum id="3">K</definiendum>
				<definiens id="0">the upper bound length of entities</definiens>
				<definiens id="1">the length of sentence and</definiens>
				<definiens id="2">the number of label set</definiens>
			</definition>
			<definition id="5">
				<sentence>This makes it difficult for us to use semi-CRFs for biomedical NER , because we have to set L to be eight or larger , where L is the upper bound of the length of possible chunks in semi-CRFs .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">the upper bound of the length of possible chunks in semi-CRFs</definiens>
			</definition>
			<definition id="6">
				<sentence>A feature forest is an “and/or” graph : in Figure 3 , circles represent 468 “and” nodes ( conjunctive nodes ) , while boxes denote “or” nodes ( disjunctive nodes ) .</sentence>
				<definiendum id="0">feature forest</definiendum>
				<definiens id="0">an “and/or” graph : in Figure 3 , circles represent 468 “and” nodes ( conjunctive nodes ) , while boxes denote “or” nodes ( disjunctive nodes )</definiens>
			</definition>
			<definition id="7">
				<sentence>We set L = 10 for training and evaluation when we do not state L explicitly , where L is the upper bound of the length of possible chunks in semiCRFs .</sentence>
				<definiendum id="0">L</definiendum>
			</definition>
			<definition id="8">
				<sentence>“Count feature” captures the tendency for named entities to appear repeatedly in the same sentence .</sentence>
				<definiendum id="0">“Count feature”</definiendum>
				<definiens id="0">captures the tendency for named entities to appear repeatedly in the same sentence</definiens>
			</definition>
			<definition id="9">
				<sentence>pi is the part of speech tag of wi and sci is the shallow parse result of wi .</sentence>
				<definiendum id="0">pi</definiendum>
				<definiendum id="1">sci</definiendum>
				<definiens id="0">the part of speech tag of wi and</definiens>
			</definition>
			<definition id="10">
				<sentence>L means the upper bound of the length of possible chunks in semiCRFs .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">means the upper bound of the length of possible chunks in semiCRFs</definiens>
			</definition>
			<definition id="11">
				<sentence>L is the upper bound of the length of possible chunks in semi-CRFs .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">the upper bound of the length of possible chunks in semi-CRFs</definiens>
			</definition>
</paper>

		<paper id="1127">
			<definition id="0">
				<sentence>The Web is a heterogeneous document collection .</sentence>
				<definiendum id="0">Web</definiendum>
				<definiens id="0">a heterogeneous document collection</definiens>
			</definition>
			<definition id="1">
				<sentence>Search engine provides some way to return useful information .</sentence>
				<definiendum id="0">Search engine</definiendum>
				<definiens id="0">provides some way to return useful information</definiens>
			</definition>
			<definition id="2">
				<sentence>A snippet consists of a title , a short summary of a web page and a hyperlink to the web page .</sentence>
				<definiendum id="0">snippet</definiendum>
				<definiens id="0">consists of a title , a short summary of a web page and a hyperlink to the web page</definiens>
			</definition>
			<definition id="3">
				<sentence>The data set consists of 65 word pairs .</sentence>
				<definiendum id="0">data set</definiendum>
			</definition>
			<definition id="4">
				<sentence>( ) ( ) , ( * YXf YXf YXCoffJaccard s s ∪ ∩ = ( 8 ) Where f s ( X∩Y ) is the number of snippets in which X and Y co-occur in the top N snippets of query “X and Y” ; f s ( X∪Y ) is the number of snippets containing X or Y in the top N snippets of query “X or Y” .</sentence>
				<definiendum id="0">f s ( X∩Y )</definiendum>
				<definiendum id="1">f s</definiendum>
				<definiens id="0">the number of snippets in which X and Y co-occur in the top N snippets of query “X and Y” ;</definiens>
			</definition>
			<definition id="5">
				<sentence>Although the correlation coefficient of WSDC model built on the web is a little worse than that of the model built on WordNet , the Web provides live vocabulary , in particular , named entities .</sentence>
				<definiendum id="0">Web</definiendum>
				<definiens id="0">provides live vocabulary</definiens>
			</definition>
			<definition id="6">
				<sentence>CODC ( Formula 5 ) , which behaves the best in computing association of common words , still achieves the better performance on different numbers of snippets in named entity clustering .</sentence>
				<definiendum id="0">CODC</definiendum>
				<definiens id="0">behaves the best in computing association of common words</definiens>
			</definition>
			<definition id="7">
				<sentence>( ) ( 1 ) , ( 1 ii s i qj pnscoreCpncount r cNEscore ×= ∑ = ( 9 ) ) , ( maxarg ) kq1 ( c q qj cNEscorec ≤≤ = ( 10 ) Where pn 1 , pn 2 , … , pn s are names which appear in both Community ( NE j ) and Community ( c q ) ; count ( pn i ) is total occurrences of pn i in Community ( c q ) ; r is total occurrences of names in Community ( NE j ) ; Cscore ( pn i ) is community score of pn i .</sentence>
				<definiendum id="0">count ( pn i )</definiendum>
				<definiens id="0">total occurrences of pn i in Community ( c q ) ; r is total occurrences of names in Community ( NE j</definiens>
			</definition>
			<definition id="8">
				<sentence>Thus , CN is an unbiased corpus .</sentence>
				<definiendum id="0">CN</definiendum>
				<definiens id="0">an unbiased corpus</definiens>
			</definition>
</paper>

		<paper id="3001">
			<definition id="0">
				<sentence>Natural Language Generation ( NLG ) is a way to automatically realize a correct expression in response to a communicative goal .</sentence>
				<definiendum id="0">Natural Language Generation</definiendum>
				<definiens id="0">a way to automatically realize a correct expression in response to a communicative goal</definiens>
			</definition>
			<definition id="1">
				<sentence>‘Natural Language Generation’ also known as ‘Automated Discourse Generation’ or simply ‘Text Generation’ , is a branch of computational linguistics , which deals with automatic generation of text in natural human language by the machine .</sentence>
				<definiendum id="0">‘Natural Language Generation’</definiendum>
				<definiens id="0">‘Automated Discourse Generation’ or simply ‘Text Generation’ , is a branch of computational linguistics , which deals with automatic generation of text in natural human language by the machine</definiens>
			</definition>
			<definition id="2">
				<sentence>The D2S system uses a tree structured template organization that resembles Tag Adjoining Grammar ( TAG ) structure .</sentence>
				<definiendum id="0">D2S system</definiendum>
				<definiens id="0">uses a tree structured template organization that resembles Tag Adjoining Grammar ( TAG ) structure</definiens>
			</definition>
			<definition id="3">
				<sentence>As for example , CHAT ( Alm , 1992 ) software is an attempt to develop a predictive conversation model to achieve higher communication rate during conversation .</sentence>
				<definiendum id="0">software</definiendum>
				<definiens id="0">an attempt to develop a predictive conversation model to achieve higher communication rate during conversation</definiens>
			</definition>
			<definition id="4">
				<sentence>PAULINE has been described that is capable of generating different texts for the same communicative goals based on pragmatics .</sentence>
				<definiendum id="0">PAULINE</definiendum>
				<definiens id="0">capable of generating different texts for the same communicative goals based on pragmatics</definiens>
			</definition>
			<definition id="5">
				<sentence>Based on the counter value of each template , we have calculated the rank of each phrase as the minimum counter value of its constituent templates i.e. Rank ( Pi ) =Minimum ( Counter ( Tj ) ) for all j in Pi Now before sentence realization the phrases are ordered according to their rank .</sentence>
				<definiendum id="0">Rank ( Pi ) =Minimum ( Counter ( Tj ) )</definiendum>
				<definiens id="0">for all j in Pi Now before sentence realization the phrases are ordered according to their rank</definiens>
			</definition>
			<definition id="6">
				<sentence>The input consists of words , tense choice , mood option and sense choice given by user .</sentence>
				<definiendum id="0">input</definiendum>
			</definition>
</paper>

		<paper id="1078">
			<definition id="0">
				<sentence>Named entity recognition ( NER ) is a key technique for IE and other natural language processing tasks .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">a key technique for IE and other natural language processing tasks</definiens>
			</definition>
			<definition id="1">
				<sentence>Named entities ( NEs ) are the proper expressions for things such as peoples’ names , locations’ names , and dates , and NER identifies those expressions and their categories .</sentence>
				<definiendum id="0">Named entities ( NEs )</definiendum>
				<definiendum id="1">NER</definiendum>
			</definition>
			<definition id="2">
				<sentence>On the other hand , in text-based NER , better results are obtained using discriminative schemes such as maximum entropy ( ME ) models ( Borthwick , 1999 ; Chieu and Ng , 2003 ) , support vector machines ( SVMs ) ( Isozaki and Kazawa , 2002 ) , and conditional random fields ( CRFs ) ( McCallum and Li , 2003 ) .</sentence>
				<definiendum id="0">SVMs )</definiendum>
			</definition>
			<definition id="3">
				<sentence>NER is a kind of chunking problem that can be solved by classifying words into NE classes that consist of name categories and such chunking states as PERSON-BEGIN ( the beginning of a person’s name ) and LOCATION-MIDDLE ( the middle of a location’s name ) .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiendum id="1">PERSON-BEGIN</definiendum>
				<definiens id="0">the beginning of a person’s name ) and LOCATION-MIDDLE ( the middle of a location’s name )</definiens>
			</definition>
			<definition id="4">
				<sentence>In the NER of ASR results , ASR errors cause NEs to be missed and erroneous NEs to be recognized .</sentence>
				<definiendum id="0">ASR errors</definiendum>
			</definition>
			<definition id="5">
				<sentence>Word posterior probability p ( [ w ; τ , t ] |X ) of word w at time interval [ τ , t ] for speech signal X is calculated as follows ( Wessel et al. , 2001 ) : p ( [ w ; τ , t ] |X ) = summationdisplay W∈W [ w ; τ , t ] braceleftBig p ( X|W ) ( p ( W ) ) β bracerightBigα p ( X ) , ( 1 ) where W is a sentence hypothesis , W [ w ; τ , t ] is the set of sentence hypotheses that include w in [ τ , t ] , p ( X|W ) is a acoustic model score , p ( W ) is a language model score , α is a scaling parameter ( α &lt; 1 ) , and β is a language model weight .</sentence>
				<definiendum id="0">Word posterior probability p</definiendum>
				<definiendum id="1">β</definiendum>
				<definiens id="0">|X ) of word w at time interval [ τ , t ] for speech signal X is calculated as follows ( Wessel et al. , 2001 ) : p ( [ w ; τ , t ] |X ) = summationdisplay W∈W [ w ; τ , t ] braceleftBig p ( X|W ) ( p ( W ) ) β bracerightBigα p ( X ) , ( 1 ) where W is a sentence hypothesis</definiens>
				<definiens id="1">the set of sentence hypotheses that include w in [ τ , t ] , p ( X|W ) is a acoustic model score , p ( W ) is a language model score , α is a scaling parameter ( α &lt; 1 ) , and</definiens>
				<definiens id="2">a language model weight</definiens>
			</definition>
			<definition id="6">
				<sentence>p ( X ) is approximated by the sum over all sentence hypotheses and is denoted as p ( X ) = summationdisplay W braceleftBig p ( X|W ) ( p ( W ) ) β bracerightBigα .</sentence>
				<definiendum id="0">p ( X</definiendum>
				<definiendum id="1">X|W )</definiendum>
				<definiens id="0">approximated by the sum over all sentence hypotheses and</definiens>
			</definition>
			<definition id="7">
				<sentence>We used the training data of the Information Retrieval and Extraction Exercise ( IREX ) workshop ( Sekine and Eriguchi , 2000 ) as the text corpus , which consisted of 1,174 Japanese newspaper articles ( 10,718 sentences ) and 18,200 NEs in eight categories ( artifact , organization , location , person , date , time , money , and percent ) .</sentence>
				<definiendum id="0">Extraction Exercise</definiendum>
			</definition>
			<definition id="8">
				<sentence>Since three different kinds of characters are used in Japanese , the character types used as features included : single-kanji ( words written in a single Chinese character ) , all-kanji ( longer words written in Chinese characters ) , hiragana ( words written in hiragana Japanese phonograms ) , katakana ( words written in katakana Japanese phonograms ) , number , single-capital ( words with a single capitalized letter ) , all-capital , capitalized ( only the first letter is capitalized ) , roman ( other roman character words ) , and others ( all other words ) .</sentence>
				<definiendum id="0">single-capital</definiendum>
			</definition>
			<definition id="9">
				<sentence>The chunking states included in the NE classes were : BEGIN ( beginning of a NE ) , MIDDLE ( middle of a NE ) , END ( ending of a NE ) , and SINGLE ( a single-word NE ) .</sentence>
				<definiendum id="0">SINGLE</definiendum>
			</definition>
			<definition id="10">
				<sentence>Conf-UB assumes perfect ASR confidence scoring , so the ASR errors in the test set are known .</sentence>
				<definiendum id="0">Conf-UB</definiendum>
				<definiens id="0">assumes perfect ASR confidence scoring , so the ASR errors in the test set are known</definiens>
			</definition>
</paper>

		<paper id="2039">
			<definition id="0">
				<sentence>Link grammar ( LG ) is a theory of syntax which builds simple relations between pairs of words , rather than constructing constituents in tree-like hierarchy .</sentence>
				<definiendum id="0">Link grammar</definiendum>
				<definiendum id="1">LG</definiendum>
				<definiens id="0">a theory of syntax which builds simple relations between pairs of words</definiens>
			</definition>
			<definition id="1">
				<sentence>In third and the last level , Jp is the Inter-phrase relationship and Dmc is the Intraphrase relation ( corresponding to “of” and “the boys” ) .</sentence>
				<definiendum id="0">Jp</definiendum>
				<definiendum id="1">Dmc</definiendum>
				<definiens id="0">the Inter-phrase relationship and</definiens>
			</definition>
			<definition id="2">
				<sentence>Direct Projection Algorithm 302 ( DPA ) , which is based on DCA , is a straightforward projection procedure in which the dependencies in an English sentence are projected to the sentence’s translation , using the word-level alignments as a bridge .</sentence>
				<definiendum id="0">DPA )</definiendum>
				<definiens id="0">a straightforward projection procedure in which the dependencies in an</definiens>
			</definition>
			<definition id="3">
				<sentence>The pDPA works in the following way .</sentence>
				<definiendum id="0">pDPA</definiendum>
				<definiens id="0">works in the following way</definiens>
			</definition>
			<definition id="4">
				<sentence>304 ProjectFrom ( Sprime , Tprime ) : // Sprime is a source // language sentence or phrase , Tprime ∼ Sprime { IF Tprime ∈P THEN Parse ( Tprime ) ; ELSE Sprime = { S1 , S2 , ... , Sn } ; // Sis are //constituent phrases/words of Sprime Tprime = { T1 , T2 , ... , Tn } // Ti ∼ Si Find all Ψij = 〈Si , Sj , L〉 from Sprime and corresponding Ψprimeij = { Ti , Tj } from Tprime ; Φij = 〈Ψij , Ψprimeij〉 For all i , j , push ( S , Φij ) ; While !</sentence>
				<definiendum id="0">// Sprime</definiendum>
				<definiendum id="1">Ti ∼ Si Find</definiendum>
				<definiens id="0">a source // language sentence or phrase , Tprime ∼ Sprime { IF Tprime ∈P THEN Parse ( Tprime ) ; ELSE Sprime = { S1 , S2 , ... , Sn } ; // Sis are //constituent phrases/words of Sprime Tprime = { T1 , T2 , ... , Tn } //</definiens>
			</definition>
			<definition id="5">
				<sentence>If the sentence is not complex , then the corresponding Hindi link may be one ofMA ( adjective ) , MP ( postposition phrase ) , MT ( present participle ) , ME ( past participle ) , or MW ( waalaa/waale/waalii-adjective ) .</sentence>
				<definiendum id="0">MW</definiendum>
				<definiens id="0">postposition phrase ) , MT ( present participle ) , ME ( past participle ) , or</definiens>
			</definition>
			<definition id="6">
				<sentence>ProjectFrom ( S1 , T1 ) : S1 = { S11 , S12 } , where S11 and S12 are the girl and in the room , respectively .</sentence>
				<definiendum id="0">ProjectFrom</definiendum>
				<definiens id="0">the girl and in the room , respectively</definiens>
			</definition>
			<definition id="7">
				<sentence>Use of rules at the projection level gives more robust parsing and reduces the need of post-editing .</sentence>
				<definiendum id="0">projection level</definiendum>
				<definiens id="0">gives more robust parsing and reduces the need of post-editing</definiens>
			</definition>
</paper>

		<paper id="1119">
			<definition id="0">
				<sentence>MeSH ( Medical Subject Headings ) serves as a good example of such an ontology ; it is a hierarchicallyarranged collection of controlled vocabulary terms manually assigned to medical abstracts in a number of databases .</sentence>
				<definiendum id="0">MeSH</definiendum>
				<definiens id="0">a good example of such an ontology ; it is a hierarchicallyarranged collection of controlled vocabulary terms manually assigned to medical abstracts in a number of databases</definiens>
			</definition>
			<definition id="1">
				<sentence>The Shoah Foundation uses a hierarchically arranged thesaurus of 56,000 keyword phrases representing domain-specific concepts .</sentence>
				<definiendum id="0">Shoah Foundation</definiendum>
				<definiens id="0">uses a hierarchically arranged thesaurus of 56,000 keyword phrases representing domain-specific concepts</definiens>
			</definition>
</paper>

		<paper id="1074">
			<definition id="0">
				<sentence>The formulation for re-computing hub scores is as follows : ( 1 ) : : ( ) ( ) ' k ji i jn ji jn k j j n w w t r t r t r y x t r + ∀ → ∀ → → = → ∑ ∑ ( 4 ) Where x` i ( k+1 ) is the hub score of a representative term t i after ( k+1 ) th iteration ; y j k is the authority score of an unseen search result r j after kth iteration ; “∀j : t i →r j ” indicates the set of all unseen search results those t i occurs in ; “∀n : t n →r j ” indicates the set of all representative terms those r j contains .</sentence>
				<definiendum id="0">y j k</definiendum>
				<definiens id="0">the hub score of a representative term t i after ( k+1 ) th iteration</definiens>
				<definiens id="1">the authority score of an unseen search result r j after kth iteration ; “∀j : t i →r j ” indicates the set of all unseen search results those t i occurs in ; “∀n : t n →r j ” indicates the set of all representative terms those r j contains</definiens>
			</definition>
			<definition id="1">
				<sentence>The formulation is as follows : ( ) ( ) N ii ii r dd wd xx tf idf x x =× × ( 9 ) Where tf xi dr is the term frequency of term x i in the viewed results set d r ; tf xi dr is the inverse document frequency of x i in the entire seen results set d N .</sentence>
				<definiendum id="0">tf xi dr</definiendum>
				<definiendum id="1">tf xi dr</definiendum>
				<definiens id="0">the term frequency of term x i in the viewed results set d r</definiens>
				<definiens id="1">the inverse document frequency of x i in the entire seen results set d N</definiens>
			</definition>
			<definition id="2">
				<sentence>And the discriminant value d ( x i ) of x i is computed using the weighting schemes F2 ( S. E. Robertson and K. Sparck Jones , 1976 ) as follows : ( ) ln ( ) ( ) i rR d nr NR x = − − ( 10 ) Where r is the number of the immediately viewed documents containing term x i ; n is the number of the seen results containing term x i ; R is the number of the immediately viewed documents in the query ; N is the number of the entire seen results .</sentence>
				<definiendum id="0">r</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">R</definiendum>
				<definiendum id="3">N</definiendum>
				<definiens id="0">the number of the immediately viewed documents containing term x i</definiens>
				<definiens id="1">the number of the seen results containing term x i</definiens>
				<definiens id="2">the number of the immediately viewed documents in the query ;</definiens>
			</definition>
</paper>

		<paper id="1136">
			<definition id="0">
				<sentence>A language model is a probability distribution that captures the statistical regularities of natural language use .</sentence>
				<definiendum id="0">language model</definiendum>
				<definiens id="0">a probability distribution that captures the statistical regularities of natural language use</definiens>
			</definition>
			<definition id="1">
				<sentence>For factoid QA task , AskMSR ( Brill et al. , 2001 ) ranks the answers by counting the occurrences of candidate answers returned from a search engine .</sentence>
				<definiendum id="0">AskMSR</definiendum>
			</definition>
			<definition id="2">
				<sentence>Candi2 http : //www.wikipedia.org date answers were reranked based on their similarity ( TFIDF score ) to the centroid vector .</sentence>
				<definiendum id="0">Candi2 http</definiendum>
				<definiens id="0">//www.wikipedia.org date answers were reranked based on their similarity ( TFIDF score ) to the centroid vector</definiens>
			</definition>
			<definition id="3">
				<sentence>( 6 ) 1 ,1minexp          −= A ref L LBP where Lref is a constant standing for the length of reference answer ( i.e. , centroid vector ) .</sentence>
				<definiendum id="0">Lref</definiendum>
				<definiens id="0">a constant standing for the length of reference answer ( i.e. , centroid vector )</definiens>
			</definition>
			<definition id="4">
				<sentence>LA is the length of the candidate answer .</sentence>
				<definiendum id="0">LA</definiendum>
				<definiens id="0">the length of the candidate answer</definiens>
			</definition>
			<definition id="5">
				<sentence>( 8 ) ) ( ) | ( OC iOC i N tCountOCtP = ( 9 ) ) ( ) , ( ) , | ( 1 1 1 − − − = iOC iiOC ii tCount ttCountOCttP where CountOC ( X ) is the occurrences of the string X in the ordered centroid and NOC stands for the total number of tokens in the ordered centroid .</sentence>
				<definiendum id="0">CountOC ( X )</definiendum>
				<definiens id="0">the occurrences of the string X in the ordered centroid and NOC stands for the total number of tokens in the ordered centroid</definiens>
			</definition>
			<definition id="6">
				<sentence>Target ( e.g. , Aaron Copland ) Ordered centroid list ( e.g. , born Nov 14 1900 ) Candidate answers Removing redundant answers Extracting candidate answers Answers ( e.g. , American composer ) Learning ordered centroid Answer reranking Training language model AQUAINT Web Stage 1 Training language model Stage 3 Removing redundancies Stage 2 Reranking using LM Figure 1 .</sentence>
				<definiendum id="0">Target</definiendum>
				<definiens id="0">answers Removing redundant answers Extracting candidate answers Answers ( e.g. , American composer ) Learning ordered centroid Answer reranking Training language model AQUAINT Web Stage 1 Training language</definiens>
			</definition>
			<definition id="7">
				<sentence>( 13 ) ) ( ) 1 ) ( log ( ) 1 ) ( log ( ) 1 ) , ( log ( ) ( tidfTCounttCount TtCotWeight ×+++ += where Co ( t , T ) denotes the number of sentences in which t co-occurs with the target T , and Count ( t ) gives the number of sentences containing the word t. We also use the inverse document frequency of t , idf ( t ) 5 , as a measurement of the global importance of the word ; 3 ) Extracting ordered centroid .</sentence>
				<definiendum id="0">Co</definiendum>
				<definiendum id="1">T )</definiendum>
				<definiendum id="2">idf</definiendum>
				<definiens id="0">the number of sentences in which t co-occurs with the target T , and Count ( t ) gives the number of sentences containing the word t. We also use the inverse document frequency of t</definiens>
			</definition>
			<definition id="8">
				<sentence>( 17 ) ln iiiii DF NTFIDFTFweight ∗=∗= where TFi gives the occurrences of term i. DF i 7 is the number of documents containing term i. N gives the total number of documents .</sentence>
				<definiendum id="0">TFi</definiendum>
				<definiens id="0">the number of documents containing term i. N gives the total number of documents</definiens>
			</definition>
			<definition id="9">
				<sentence>From Table 2 , we observe that , with QE , the bigram and biterm still outperform the baseline system ( VSM ) significantly by 12.1 % ( p8=0.03 ) and 14.9 % ( p=0.004 ) in F ( 5 ) .</sentence>
				<definiendum id="0">VSM</definiendum>
				<definiens id="0">the bigram and biterm still outperform the baseline system</definiens>
			</definition>
</paper>

		<paper id="2040">
</paper>

		<paper id="2088">
			<definition id="0">
				<sentence>1 A bunsetsu is one of the linguistic units in Japanese , and roughly corresponds to a basic phrase in English .</sentence>
				<definiendum id="0">bunsetsu</definiendum>
				<definiens id="0">one of the linguistic units in Japanese , and roughly corresponds to a basic phrase in English</definiens>
			</definition>
			<definition id="1">
				<sentence>A bunsetsu consists of one independent word and more than zero ancillary words .</sentence>
				<definiendum id="0">bunsetsu</definiendum>
			</definition>
			<definition id="2">
				<sentence>If the head chunk ( e.g. “from” ) of a child node ( e.g. PP ( from ) ) differs from that of its parent node ( e.g. VP ( want-to-fly ) ) , the head chunk ( e.g. “from” ) of the child node depends on the head chunk ( e.g. “want-to-fly” ) of the parent node .</sentence>
				<definiendum id="0">e.g. PP</definiendum>
				<definiens id="0">e.g. “from” ) of a child node</definiens>
				<definiens id="1">the head chunk ( e.g. “from” ) of the child node depends on the head chunk ( e.g. “want-to-fly” ) of the parent node</definiens>
			</definition>
			<definition id="3">
				<sentence>The virtual elapsed time increases by one unit of time whenever a chunk is input , n is the total number of chunks in all of the test sentences .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">The virtual elapsed time increases by one unit of time whenever a chunk is input</definiens>
				<definiens id="1">the total number of chunks in all of the test sentences</definiens>
			</definition>
</paper>

		<paper id="2082">
			<definition id="0">
				<sentence>One is the Kyoto Text Corpus , which consists of newspaper articles , and the other one is the IPAL corpus , which contains sentences extracted from the “example of use” section of the enties in several dictionaries for computers .</sentence>
				<definiendum id="0">Kyoto Text Corpus</definiendum>
				<definiendum id="1">IPAL corpus</definiendum>
				<definiens id="0">consists of newspaper articles</definiens>
				<definiens id="1">contains sentences extracted from the “example of use” section of the enties in several dictionaries for computers</definiens>
			</definition>
			<definition id="1">
				<sentence>Kyoto Text Corpus ( General ) ( Editorial ) # of sentences 19,669 18,714 # of bunsetu 192,154 171,461 # of morphemes 542,334 480,005 vocabulary size 29,542 17,730 bunsetu / sentence 9.769 9.162 Table 1 : Kyoto Text Corpus IPAL ( IPA , Information-technology Promotion Agency , Lexicon of the Japanese language for computers ) dictionaries consist of three dictionaries , the IPAL noun dictionary , the IPAL verb dictionary and the IPAL adjective dictionary .</sentence>
				<definiendum id="0">Kyoto Text Corpus</definiendum>
				<definiens id="0">Kyoto Text Corpus IPAL ( IPA , Information-technology Promotion Agency , Lexicon of the Japanese language for computers ) dictionaries consist of three dictionaries</definiens>
			</definition>
			<definition id="2">
				<sentence>In Table 3 “Learning” indicates the learning corpus , “Test” represents the test corpus , and “Degree” denotes the degree of the polynomial function .</sentence>
				<definiendum id="0">“Test”</definiendum>
				<definiendum id="1">“Degree”</definiendum>
				<definiens id="0">the test corpus , and</definiens>
			</definition>
			<definition id="3">
				<sentence>K-mag includes a wide variety articles , and the average sentence length is longer than in newspapers .</sentence>
				<definiendum id="0">K-mag</definiendum>
				<definiens id="0">includes a wide variety articles , and the average sentence length is longer than in newspapers</definiens>
			</definition>
</paper>

		<paper id="1144">
			<definition id="0">
				<sentence>Multilingual Document Clustering ( MDC ) involves dividing a set of n documents , written in different languages , into a specified number k of clusters , so the documents that are similar to other documents are in the same cluster .</sentence>
				<definiendum id="0">Multilingual Document Clustering ( MDC</definiendum>
				<definiens id="0">dividing a set of n documents , written in different languages , into a specified number k of clusters , so the documents that are similar to other documents are in the same cluster</definiens>
			</definition>
			<definition id="1">
				<sentence>Transformations are the one-step operations of insertion , deletion and substitution .</sentence>
				<definiendum id="0">Transformations</definiendum>
				<definiens id="0">the one-step operations of insertion , deletion and substitution</definiens>
			</definition>
			<definition id="2">
				<sentence>A Comparable Corpus is a collection of similar texts in different languages or in different varieties of a language .</sentence>
				<definiendum id="0">Comparable Corpus</definiendum>
				<definiens id="0">a collection of similar texts in different languages or in different varieties of a language</definiens>
			</definition>
			<definition id="3">
				<sentence>The F-measure combines the precision and recall measures : F ( i , j ) = 2×Recall ( i , j ) ×Precision ( i , j ) ( Precision ( i , j ) +Recall ( i , j ) ) , ( 1 ) where Recall ( i , j ) = nijni , Precision ( i , j ) = nijnj , nij is the number of members of cluster human solution i in cluster j , nj is the number of members of cluster j and ni is the number of members of cluster human solution i. For all the clusters : F = summationdisplay i ni n max { F ( i ) } ( 2 ) The closer to 1 the F-measure value the better .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiendum id="1">nij</definiendum>
				<definiendum id="2">nj</definiendum>
				<definiendum id="3">ni</definiendum>
				<definiens id="0">the number of members of cluster human solution i in cluster j</definiens>
				<definiens id="1">the number of members of cluster j and</definiens>
				<definiens id="2">the number of members of cluster human solution i. For all the clusters : F = summationdisplay i ni n max { F ( i</definiens>
			</definition>
			<definition id="4">
				<sentence>The first column of both tables indicates the features used in clustering : NOM ( nouns ) , VER ( verbs ) , ADJ ( adjectives ) , ALL ( all the lemmas ) , NE ( named entities ) , and 1rst PAR ( those of the first paragraph of the previous categories ) .</sentence>
				<definiendum id="0">NOM</definiendum>
				<definiendum id="1">VER</definiendum>
				<definiens id="0">verbs ) , ADJ ( adjectives ) , ALL ( all the lemmas ) , NE ( named entities</definiens>
			</definition>
</paper>

		<paper id="4008">
			<definition id="0">
				<sentence>K-QARD is a framework for implementing a fully automated question answering system including the Web information extraction ( IE ) .</sentence>
				<definiendum id="0">K-QARD</definiendum>
				<definiens id="0">a framework for implementing a fully automated question answering system including the Web information extraction ( IE )</definiens>
			</definition>
			<definition id="1">
				<sentence>For the domain portability , K-QARD is designed as a domain-independent architecture and it keeps all domain-dependent elements in external resources .</sentence>
				<definiendum id="0">K-QARD</definiendum>
				<definiens id="0">a domain-independent architecture and it keeps all domain-dependent elements in external resources</definiens>
			</definition>
			<definition id="2">
				<sentence>The Web information extraction ( IE ) component extracts the domain-specific information for question answering from Web pages and stores the information into the relational database .</sentence>
				<definiendum id="0">Web information extraction</definiendum>
				<definiendum id="1">component</definiendum>
				<definiens id="0">extracts the domain-specific information for question answering from Web pages and stores the information into the relational database</definiens>
			</definition>
			<definition id="3">
				<sentence>In the answer finding component , K-QARD retrieves the answers from the database using the SQL generation script defined in each semantic frame .</sentence>
				<definiendum id="0">K-QARD</definiendum>
				<definiendum id="1">SQL generation script</definiendum>
				<definiens id="0">retrieves the answers from the database using the</definiens>
			</definition>
			<definition id="4">
				<sentence>The answer generation component provides the answer to the user as a natural language sentence or a table by using the generation rules and the answer frames which consist of canned texts .</sentence>
				<definiendum id="0">answer generation component</definiendum>
				<definiens id="0">provides the answer to the user as a natural language sentence or a table by using the generation rules and the answer frames which consist of canned texts</definiens>
			</definition>
			<definition id="5">
				<sentence>We define a question focus as a type of information that a user wants to know .</sentence>
				<definiendum id="0">question focus</definiendum>
				<definiens id="0">a type of information that a user wants to know</definiens>
			</definition>
</paper>

		<paper id="1073">
			<definition id="0">
				<sentence>A diacritization system that restores the diacritics of scripts , i.e. supply the full diacritical markings , would be of interest to these applications .</sentence>
				<definiendum id="0">diacritization system</definiendum>
				<definiens id="0">restores the diacritics of scripts</definiens>
			</definition>
			<definition id="1">
				<sentence>The Arabic alphabet consists of 28 letters that can be extended to a set of 90 by additional shapes , marks , and vowels ( Tayli and Al-Salamah , 1990 ) .</sentence>
				<definiendum id="0">Arabic alphabet</definiendum>
			</definition>
			<definition id="2">
				<sentence>Diacritization is treated as an unsupervised tagging problem where each word is tagged as one of the many possible forms provided by the Buckwalter’s morphological analyzer ( Buckwalter , 2002 ) .</sentence>
				<definiendum id="0">Diacritization</definiendum>
			</definition>
			<definition id="3">
				<sentence>MaxEnt can be used for sequence classification , by converting the activation scores into probabilities ( through the soft-max function , for instance ) and using the standard dynamic programming search algorithm ( also known as Viterbi search ) .</sentence>
				<definiendum id="0">MaxEnt</definiendum>
				<definiens id="0">sequence classification , by converting the activation scores into probabilities</definiens>
			</definition>
			<definition id="4">
				<sentence>Given these weights , the model computes the probability distribution over labels for a particular example x as follows : P ( y|x ) = 1Z ( x ) mproductdisplay j=1 αfj ( x ) ij , Z ( x ) = summationdisplay i productdisplay j αfj ( x ) ij where Z ( X ) is a normalization factor .</sentence>
				<definiendum id="0">Z ( X )</definiendum>
				<definiens id="0">a normalization factor</definiens>
			</definition>
			<definition id="5">
				<sentence>The DER is the proportion of incorrectly restored diacritics .</sentence>
				<definiendum id="0">DER</definiendum>
			</definition>
			<definition id="6">
				<sentence>The WER is the percentage of incorrectly diacritized white-space delimited words : in order to be counted as incorrect , at least one character in the word must have a diacritization error .</sentence>
				<definiendum id="0">WER</definiendum>
				<definiens id="0">the percentage of incorrectly diacritized white-space delimited words : in order to be counted as incorrect , at least one character in the word must have a diacritization error</definiens>
			</definition>
			<definition id="7">
				<sentence>The approach we propose is based on the Maximum entropy framework , which gives the system the ability to integrate different sources of knowledge .</sentence>
				<definiendum id="0">Maximum entropy framework</definiendum>
				<definiens id="0">gives the system the ability to integrate different sources of knowledge</definiens>
			</definition>
</paper>

		<paper id="1110">
			<definition id="0">
				<sentence>A span is a range over contiguous words in the input .</sentence>
				<definiendum id="0">span</definiendum>
				<definiens id="0">a range over contiguous words in the input</definiens>
			</definition>
			<definition id="1">
				<sentence>The frontier of a state consists of the items with no parents yet .</sentence>
				<definiendum id="0">frontier of a state</definiendum>
				<definiens id="0">consists of the items with no parents yet</definiens>
			</definition>
			<definition id="2">
				<sentence>Given input sentence s , the parser searches for parse ˆp out of the possible parses P ( s ) : ˆp = arg min p∈P ( s ) CΘ ( p ) ( 1 ) where CΘ ( p ) is the cost of parse p under model Θ : CΘ ( p ) = summationdisplay i∈p cΘ ( i ) ( 2 ) Section 3.1 describes how to compute cΘ ( i ) .</sentence>
				<definiendum id="0">CΘ ( p )</definiendum>
				<definiens id="0">the cost of parse p under model Θ : CΘ ( p ) = summationdisplay i∈p cΘ ( i ) ( 2 ) Section 3.1 describes how to compute cΘ ( i )</definiens>
			</definition>
			<definition id="3">
				<sentence>Each leaf node n keeps track of the parameter value Θϕ ( n ) .3 The score hΘ ( i ) given to an inference i by the whole ensemble is the sum of the confidences returned by the trees in the ensemble .</sentence>
				<definiendum id="0">ensemble</definiendum>
				<definiens id="0">the sum of the confidences returned by the trees in the ensemble</definiens>
			</definition>
</paper>

		<paper id="2106">
			<definition id="0">
				<sentence>interoperability of lexicons The ISLE ( International Standards for Language Engineering ) Computational Lexicon Working Group has consensually defined the MILE ( Multilingual ISLE Lexical Entry ) as a standardized infrastructure to develop multilingual lexical resources for HLT applications , with particular attention toMachine Translation ( MT ) andCrosslingual Information Retrieval ( CLIR ) application systems .</sentence>
				<definiendum id="0">ISLE</definiendum>
				<definiens id="0">International Standards for Language Engineering ) Computational Lexicon Working Group has consensually defined the MILE ( Multilingual ISLE Lexical Entry ) as a standardized infrastructure to develop multilingual lexical resources for HLT applications , with particular attention toMachine Translation ( MT ) andCrosslingual Information Retrieval ( CLIR ) application systems</definiens>
			</definition>
			<definition id="1">
				<sentence>The MILE is a general architecture devised for the encoding of multilingual lexical information , a meta-entry acting as a common representational layer for multilingual lexicons , by allowing integration and interoperability between different monolingual lexicons 3 .</sentence>
				<definiendum id="0">MILE</definiendum>
				<definiens id="0">a general architecture devised for the encoding of multilingual lexical information</definiens>
			</definition>
			<definition id="2">
				<sentence>As concerns the horizontal organization , the MLM consists of two independent , but interlinked primary components , the monolingual and the multilingual modules .</sentence>
				<definiendum id="0">MLM</definiendum>
				<definiens id="0">consists of two independent , but interlinked primary components , the monolingual and the multilingual modules</definiens>
			</definition>
			<definition id="3">
				<sentence>“NP” and “VP” are data category instances of the class SyntacticPhrase , whereas and “subj” and “obj” are data category instances of the class SyntacticFunction .</sentence>
				<definiendum id="0">“NP”</definiendum>
				<definiens id="0">data category instances of the class SyntacticPhrase , whereas and “subj” and “obj” are data category instances of the class SyntacticFunction</definiens>
			</definition>
			<definition id="4">
				<sentence>Note that the Swadesh list consists of terms that embody human direct experience , with culture-specific terms avoided .</sentence>
				<definiendum id="0">Swadesh list</definiendum>
				<definiens id="0">consists of terms that embody human direct experience , with culture-specific terms avoided</definiens>
			</definition>
			<definition id="5">
				<sentence>AwordXw i is translated into a set of English words EXw ij by referring to the bilingual dictionary , where X denotes one of our languages , J , C or T. We can obtain mappings as in ( 1 ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">one of our languages , J</definiens>
			</definition>
			<definition id="6">
				<sentence>Query expansion is a well-known technique which expands user’s queryterms intoaset ofsimilar and related terms by referring to ontologies .</sentence>
				<definiendum id="0">Query expansion</definiendum>
			</definition>
			<definition id="7">
				<sentence>We believe our efforts contribute to international activities like ISOTC37/SC4 6 ( Francopoulo et al. , 2006 ) and to the revision of the ISO Data Category Registry ( ISO 12620 ) , making it possible to come close to the ideal international standard of language resources .</sentence>
				<definiendum id="0">Data Category Registry</definiendum>
				<definiens id="0">Francopoulo et al. , 2006 ) and to the revision of the ISO</definiens>
			</definition>
</paper>

		<paper id="1081">
			<definition id="0">
				<sentence>The distance information is a valuable factor to be considered .</sentence>
				<definiendum id="0">distance information</definiendum>
				<definiens id="0">a valuable factor to be considered</definiens>
			</definition>
			<definition id="1">
				<sentence>The formula to calculate the ranking score for a candidate is as follows : 1 ( ) ( , ) ( , ) ( 1 ) max max kiki FL i len Freq len len c d q c wqc αα − =× +− × ∑ where ( , ) ki dqc is the word distance between the English phrase q and the candidate i c in the kth occurrence of candidate in the search-result pages .</sentence>
				<definiendum id="0">ki dqc</definiendum>
			</definition>
			<definition id="2">
				<sentence>The objective is to find a set of mappings between the English word ( s ) in the key phrase and the local language word ( s ) in candidates , which maximize the sum of the semantic and phonetic mapping weights .</sentence>
				<definiendum id="0">s</definiendum>
				<definiens id="0">) in the key phrase and the local language word ( s ) in candidates , which maximize the sum of the semantic and phonetic mapping weights</definiens>
			</definition>
			<definition id="3">
				<sentence>Phonetic weight is the transliteration probability between English and candidates in local language .</sentence>
				<definiendum id="0">Phonetic weight</definiendum>
				<definiens id="0">the transliteration probability between English and candidates in local language</definiens>
			</definition>
			<definition id="4">
				<sentence>Google provides a machine translation function to translate text such as Web pages .</sentence>
				<definiendum id="0">Google</definiendum>
			</definition>
			<definition id="5">
				<sentence>For instance , “Jordan” is the English translation of Korean term “요르단” , which ranks 2nd and 5th in ( 2 χ ) and ( 2 χ +CV ) , respectively .</sentence>
				<definiendum id="0">“Jordan”</definiendum>
				<definiens id="0">the English translation of Korean term “요르단” , which ranks 2nd and 5th in ( 2 χ ) and ( 2 χ +CV ) , respectively</definiens>
			</definition>
</paper>

		<paper id="1040">
			<definition id="0">
				<sentence>The patterns are sorted by pertinence , where the pertinence of a pattern iP for a word pair YX : is the expected relational similarity between the given pair and typical pairs for iP .</sentence>
				<definiendum id="0">YX</definiendum>
				<definiens id="0">sorted by pertinence , where the pertinence of a pattern iP for a word pair</definiens>
				<definiens id="1">the expected relational similarity between the given pair and typical pairs for iP</definiens>
			</definition>
			<definition id="1">
				<sentence>The ranked list of patterns for a word pair YX : gives the relations between X and Y in the corpus , sorted with the most pertinent ( i.e. , characteristic , distinctive , unambiguous ) relations first .</sentence>
				<definiendum id="0">ranked list of patterns</definiendum>
				<definiens id="0">gives the relations between X</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , instead of the literal string pattern “Y such as the X” , where X and Y are words , Hearst ( 1992 ) used the more abstract pattern “ 0NP such as 1NP ” , where iNP represents a noun phrase .</sentence>
				<definiendum id="0">iNP</definiendum>
				<definiens id="0">a noun phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>For the sake of simplicity , we have avoided part-of-speech tagging , which limits us to literal patterns .</sentence>
				<definiendum id="0">part-of-speech tagging</definiendum>
				<definiens id="0">limits us to literal patterns</definiens>
			</definition>
			<definition id="4">
				<sentence>SVD decomposes X into a product of three matrices TVUΣ , where U and V are in column orthonormal form ( i.e. , the columns are orthogonal and have unit length ) and Σ is a diagonal matrix of singular values ( hence SVD ) .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiendum id="1">Σ</definiendum>
				<definiens id="0">decomposes X into a product of three matrices TVUΣ , where U and V are in column orthonormal form</definiens>
			</definition>
			<definition id="5">
				<sentence>Let kΣ , where rk &lt; , be the diagonal matrix formed from the top k singular values , and let kU and kV be the matrices produced by selecting the corresponding columns from U and V .</sentence>
				<definiendum id="0">rk &lt;</definiendum>
				<definiens id="0">the matrices produced by selecting the corresponding columns from U and V</definiens>
			</definition>
			<definition id="6">
				<sentence>SVD is used to reduce noise and compensate for sparseness ( Landauer and Dumais , 1997 ) .</sentence>
				<definiendum id="0">SVD</definiendum>
			</definition>
			<definition id="7">
				<sentence>Calculate conditional probabilities : Using Bayes’ Theorem ( see Section 2 ) and the raw frequency data in the matrix X from Step 6 , before log and entropy transforms , calculate the conditional probability ) : ( p jii PYX for every row ( word pair ) and every column ( pattern ) .</sentence>
				<definiendum id="0">raw frequency</definiendum>
				<definiens id="0">data in the matrix X from Step 6 , before log and entropy transforms , calculate the conditional probability ) : ( p jii PYX for every row</definiens>
			</definition>
			<definition id="8">
				<sentence>Precision is defined as the percentage of correct answers out of the questions that were answered ( not skipped ) .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the percentage of correct answers out of the questions that were answered ( not skipped )</definiens>
			</definition>
			<definition id="9">
				<sentence>Recall is the percentage of correct answers out of the maximum possible number correct ( 374 ) .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the percentage of correct answers out of the maximum possible number correct ( 374 )</definiens>
			</definition>
			<definition id="10">
				<sentence>The F measure is the harmonic mean of precision and recall .</sentence>
				<definiendum id="0">F measure</definiendum>
				<definiens id="0">the harmonic mean of precision and recall</definiens>
			</definition>
			<definition id="11">
				<sentence>For the tf-idf methods in Table 4 , f is the pattern frequency , n is the pair frequency , F is the maximum f for all patterns for the given word pair , and N is the total number of word pairs .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">F</definiendum>
				<definiendum id="2">N</definiendum>
				<definiens id="0">the pair frequency</definiens>
				<definiens id="1">the maximum f for all patterns for the given word pair</definiens>
				<definiens id="2">the total number of word pairs</definiens>
			</definition>
			<definition id="12">
				<sentence>In effect , 319 LRA is a black box .</sentence>
				<definiendum id="0">LRA</definiendum>
				<definiens id="0">a black box</definiens>
			</definition>
			<definition id="13">
				<sentence>The main contribution of this paper is the idea of pertinence , which allows us to take an opaque measure of relational similarity and use it to find patterns that express the implicit semantic relations between two words .</sentence>
				<definiendum id="0">pertinence</definiendum>
				<definiens id="0">allows us to take an opaque measure of relational similarity and use it to find patterns that express the implicit semantic relations between two words</definiens>
			</definition>
</paper>

		<paper id="2010">
			<definition id="0">
				<sentence>The hybrid kernel consists of two individual convolution kernels : a Path kernel , which captures predicateargument link features , and a Constituent Structure kernel , which captures the syntactic structure features of arguments .</sentence>
				<definiendum id="0">hybrid kernel</definiendum>
				<definiendum id="1">Constituent Structure kernel</definiendum>
				<definiens id="0">consists of two individual convolution kernels : a Path kernel , which captures predicateargument link features</definiens>
				<definiens id="1">captures the syntactic structure features of arguments</definiens>
			</definition>
			<definition id="1">
				<sentence>In addition , some machine learning algorithms with dual form , such as Perceptron and Support Vector Machines ( SVM ) ( Cristianini and Shawe-Taylor , 2000 ) , which do not need know the exact presentation of objects and only need compute their kernel functions during the process of learning and prediction .</sentence>
				<definiendum id="0">Support Vector Machines</definiendum>
				<definiens id="0">do not need know the exact presentation of objects and only need compute their kernel functions during the process of learning and prediction</definiens>
			</definition>
			<definition id="2">
				<sentence>Our hybrid kernel method using Voted Perceptron kernel machine outperforms the PAF kernel in the development sets of CoNLL-2005 SRL shared task .</sentence>
				<definiendum id="0">PAF kernel</definiendum>
				<definiens id="0">in the development sets of CoNLL-2005 SRL shared task</definiens>
			</definition>
			<definition id="3">
				<sentence>The kernel function is defined as following : K ( T1 , T2 ) = 〈Φ ( T1 ) , Φ ( T2 ) 〉 =summationtexti φi ( T1 ) , φi ( T2 ) =summationtextn1∈N1 summationtextn2∈N2 summationtexti Ii ( n1 ) ∗Ii ( n2 ) where N1 and N2 are the sets of all nodes in trees T1 and T2 , respectively , and Ii ( n ) is the indicator function whose value is 1 if and only if there is a sub-tree of type i rooted at node n and 0 otherwise .</sentence>
				<definiendum id="0">kernel function</definiendum>
				<definiens id="0">following : K ( T1 , T2 ) = 〈Φ ( T1 ) , Φ ( T2 ) 〉 =summationtexti φi ( T1 ) , φi ( T2 ) =summationtextn1∈N1 summationtextn2∈N2 summationtexti Ii ( n1 ) ∗Ii ( n2 ) where N1 and N2 are the sets of all nodes in trees T1 and T2 , respectively , and Ii ( n ) is the indicator function whose value is 1 if and only if there is a sub-tree of type i rooted at node n and 0 otherwise</definiens>
			</definition>
			<definition id="4">
				<sentence>Collins and Duffy ( 2001 ) show that K ( T1 , T2 ) is an instance of convolution kernels over tree structures , which can be computed in O ( |N1| × |N2| ) by the following recursive definitions ( Let ∆ ( n1 , n2 ) = summationtexti Ii ( n1 ) ∗Ii ( n2 ) ) : ( 1 ) if the children of n1 and n2 are different then ∆ ( n1 , n2 ) = 0 ; ( 2 ) else if their children are the same and they are leaves , then ∆ ( n1 , n2 ) = µ ; ( 3 ) else ∆ ( n1 , n2 ) = µproducttextnc ( n1 ) j=1 ( 1 + ∆ ( ch ( n1 , j ) , ch ( n2 , j ) ) ) where nc ( n1 ) is the number of the children of n1 , ch ( n , j ) is the jth child of node n and µ ( 0 &lt; µ &lt; 1 ) is the decay factor in order to make the kernel value less variable with respect to the tree sizes .</sentence>
				<definiendum id="0">T2 )</definiendum>
				<definiendum id="1">1 + ∆ ( ch</definiendum>
				<definiendum id="2">nc</definiendum>
				<definiens id="0">an instance of convolution kernels over tree structures</definiens>
				<definiens id="1">the jth child of node n and µ ( 0 &lt; µ &lt; 1</definiens>
			</definition>
			<definition id="5">
				<sentence>Here , believes is a predicate and A1 is a long sub-sentence .</sentence>
				<definiendum id="0">A1</definiendum>
				<definiens id="0">a predicate</definiens>
			</definition>
			<definition id="6">
				<sentence>The data consist of sections of the Wall Street Journal ( WSJ ) part of the Penn TreeBank ( Marcus et al. , 1993 ) , with information on predicate-argument structures extracted from the PropBank corpus ( Palmer et al. , 2005 ) .</sentence>
				<definiendum id="0">data</definiendum>
			</definition>
			<definition id="7">
				<sentence>Precision ( p ) is the proportion of arguments predicted by a system which are correct .</sentence>
				<definiendum id="0">Precision ( p )</definiendum>
				<definiens id="0">the proportion of arguments predicted by a system which are correct</definiens>
			</definition>
			<definition id="8">
				<sentence>Recall ( r ) is the proportion of correct arguments which are predicted by a system .</sentence>
				<definiendum id="0">Recall ( r )</definiendum>
				<definiens id="0">the proportion of correct arguments which are predicted by a system</definiens>
			</definition>
			<definition id="9">
				<sentence>Fβ=1 computes the harmonic mean of precision and recall , which is the final measure to evaluate the performances of systems .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">the final measure to evaluate the performances of systems</definiens>
			</definition>
			<definition id="10">
				<sentence>pl2 is the official program of the CoNLL-2005 SRL shared task to evaluate a system performance .</sentence>
				<definiendum id="0">pl2</definiendum>
				<definiens id="0">the official program of the CoNLL-2005 SRL shared task to evaluate a system performance</definiens>
			</definition>
			<definition id="11">
				<sentence>The Voted Perceptron is a binary classifier .</sentence>
				<definiendum id="0">Voted Perceptron</definiendum>
				<definiens id="0">a binary classifier</definiens>
			</definition>
</paper>

		<paper id="1077">
			<definition id="0">
				<sentence>In phrase-based models , phrases are usually strings of adjacent words instead of syntactic constituents , excelling at capturing local reordering and performing translations that are localized to 1The mathematical notation we use in this paper is taken from that paper : a source string fJ1 = f1 , ... , fj , ... , fJ is to be translated into a target string eI1 = e1 , ... , ei , ... , eI .</sentence>
				<definiendum id="0">fJ</definiendum>
				<definiens id="0">a source string fJ1 = f1 , ... , fj , ... ,</definiens>
			</definition>
			<definition id="1">
				<sentence>Here , I is the length of the target string , and J is the length of the source string .</sentence>
				<definiendum id="0">J</definiendum>
			</definition>
			<definition id="2">
				<sentence>A tree-to-string alignment template z is a triple 〈˜T , ˜S , ˜A〉 , which describes the alignment ˜A between a source parse tree ˜T = T ( FJprime1 ) 2 and a target string ˜S = EIprime1 .</sentence>
				<definiendum id="0">tree-to-string alignment template z</definiendum>
				<definiens id="0">describes the alignment ˜A between a source parse tree ˜T = T</definiens>
			</definition>
			<definition id="3">
				<sentence>A source string FJprime1 , which is the sequence of leaf nodes of T ( FJprime1 ) , consists of both terminals ( source words ) and nonterminals ( phrasal categories ) .</sentence>
				<definiendum id="0">source string FJprime1</definiendum>
				<definiens id="0">consists of both terminals ( source words ) and nonterminals ( phrasal categories )</definiens>
			</definition>
			<definition id="4">
				<sentence>An alignment ˜A is defined as a subset of the Cartesian product of source and target symbol positions : ˜A ⊆ { ( j , i ) : j = 1 , ... , Jprime ; i = 1 , ... , Iprime } ( 1 ) 2We use T ( · ) to denote a parse tree .</sentence>
				<definiendum id="0">alignment ˜A</definiendum>
				<definiens id="0">a subset of the Cartesian product of source and target symbol positions : ˜A ⊆ { ( j , i ) : j = 1 , ... , Jprime ; i = 1 , ... , Iprime } ( 1 ) 2We use T ( · ) to denote a parse tree</definiens>
			</definition>
			<definition id="5">
				<sentence>A TSA is a triple 〈T ( fj2j1 ) , ei2i1 , ¯A ) 〉 that is in accordance with the following constraints : Given a TSA 〈T ( fj2j1 ) , ei2i1 , ¯A〉 , a triple 〈T ( fj4j3 ) , ei4i3 , ˆA〉 is its sub TSA if and only if : the root node of T ( fj1j2 ) Basically , we extract TATs from a TSA 〈T ( fj2j1 ) , ei2i1 , ¯A〉 using the following two rules : then 〈T ( fj2j1 ) , ei2i1 , ¯A〉 is a TAT then build TATs using those extracted from sub TSAs of 〈T ( fj2j1 ) , ei2i1 , ¯A〉 .</sentence>
				<definiendum id="0">TSA</definiendum>
				<definiendum id="1">TSA 〈T</definiendum>
				<definiendum id="2">triple 〈T</definiendum>
				<definiendum id="3">ˆA〉</definiendum>
				<definiendum id="4">¯A〉</definiendum>
				<definiens id="0">a triple 〈T ( fj2j1 ) , ei2i1 , ¯A ) 〉 that is in accordance with the following constraints : Given a</definiens>
			</definition>
			<definition id="6">
				<sentence>The training corpus consists of 31,149 sentence pairs with 843,256 Chinese words and 613 System Features BLEU4 d + φ ( e|f ) 0.0573 ± 0.0033 Pharaoh d + lm + φ ( e|f ) + wp 0.2019 ± 0.0083 d + lm + φ ( f|e ) + lex ( f|e ) + φ ( e|f ) + lex ( e|f ) + pp + wp 0.2089 ± 0.0089 h1 0.1639 ± 0.0077 Lynx h1 + h6 + h7 0.2100 ± 0.0089 h1 + h2 + h3 + h4 + h5 + h6 + h7 0.2178 ± 0.0080 Table 2 : Comparison of Pharaoh and Lynx with different feature settings on the test corpus 949,583 English words .</sentence>
				<definiendum id="0">training corpus</definiendum>
				<definiens id="0">consists of 31,149 sentence pairs with 843,256 Chinese words and 613 System Features BLEU4 d + φ ( e|f ) 0.0573 ± 0.0033 Pharaoh d + lm + φ ( e|f ) + wp 0.2019 ± 0.0083 d + lm + φ ( f|e ) + lex ( f|e ) + φ ( e|f ) + lex ( e|f ) + pp + wp 0.2089 ± 0.0089 h1 0.1639 ± 0.0077 Lynx h1 + h6 + h7 0.2100 ± 0.0089 h1 + h2 + h3 + h4 + h5 + h6 + h7 0.2178 ± 0.0080 Table 2 : Comparison of Pharaoh and Lynx with different feature settings on the test corpus 949,583 English words</definiens>
			</definition>
</paper>

		<paper id="2046">
			<definition id="0">
				<sentence>7 A bunsetu is a syntactic unit in Japanese , consisting of one independent word and more than zero ancillary words .</sentence>
				<definiendum id="0">bunsetu</definiendum>
				<definiens id="0">a syntactic unit in Japanese , consisting of one independent word and more than zero ancillary words</definiens>
			</definition>
			<definition id="1">
				<sentence>Particle’s change represents attachment of topic or restrictive particles .</sentence>
				<definiendum id="0">Particle’s change</definiendum>
				<definiens id="0">represents attachment of topic or restrictive particles</definiens>
			</definition>
			<definition id="2">
				<sentence>Note that we ignore , among constituent words , endings of a predicate and case particles , ga ( NOM ) and o ( ACC ) , since they could change their forms or disappear .</sentence>
				<definiendum id="0">NOM</definiendum>
				<definiendum id="1">ACC</definiendum>
				<definiens id="0">among constituent words , endings of a predicate and case particles , ga (</definiens>
			</definition>
			<definition id="3">
				<sentence>355 Recognition Difficulty POS Internal Structure Japanese Idioms Class C Verb ( N/P V ) hone-o bone-ACC oru break ‘make an effort’ ( N/P N/P V ) mune-ni chest-DAT te-o hand-ACC ateru put ‘think over’ ··· Adj ( N/P A ) atama-ga head-NOM itai ache ‘be in trouble’ ··· Class B yaku-ni part-DAT tatu stand ‘serve the purpose’ Class A mizu-mo water-TOO sitataru drip ‘extremely handsome’ Figure 3 : Classification of Japanese Idioms for the Recognition Task ( 6 ) Disambiguation Knowledge for the Verbal ( N/P V ) Idioms a. Adnominal Modification Constraints I. Relative Clause Prohibition II .</sentence>
				<definiendum id="0">Recognition Difficulty POS Internal Structure Japanese Idioms Class C Verb ( N/P V</definiendum>
				<definiens id="0">Japanese Idioms for the Recognition Task ( 6 ) Disambiguation Knowledge for the Verbal ( N/P V ) Idioms a. Adnominal Modification Constraints I. Relative Clause Prohibition II</definiens>
			</definition>
			<definition id="4">
				<sentence>The idiom recognizer looks up dependency patterns in the dictionary that match a part of the dependency structure of a sentence ( Figure 4 ) .</sentence>
				<definiendum id="0">idiom recognizer</definiendum>
			</definition>
			<definition id="5">
				<sentence>356 Input yaku-ni-wa part-DAT-TOP mattaku totally tat-anai stand-NEG Morphology &amp; Dependency Analysis Dependency Matching yaku part /ni DAT /wa TOP mattaku totally tatu stand / nai NEG Output yaku part / ni DAT /wa TOP mattaku totally tatu stand / nai NEG Idiom Recognizer Idiom Dictionary ··· yaku part /ni DAT tatu stand ··· Dependency Pattern Figure 4 : Internal Working of the Idiom Recognizer Input Output Idiom Recognizer ChaSen Morphology Analysis CaboCha Dependency Analysis TGrep2 Dependency Matching Dependency Pattern Generator Pattern DB Idiom Dictionary Figure 5 : Organization of the System As in Figure 5 , we use ChaSen as a morphology analyzer and CaboCha ( Kudo and Matsumoto , 2002 ) as a dependency analyzer .</sentence>
				<definiendum id="0">CaboCha</definiendum>
				<definiens id="0">Internal Working of the Idiom Recognizer Input Output Idiom Recognizer ChaSen Morphology Analysis CaboCha Dependency Analysis TGrep2 Dependency Matching Dependency Pattern Generator Pattern DB Idiom Dictionary Figure 5 : Organization of the System</definiens>
			</definition>
			<definition id="6">
				<sentence>The dependency pattern of Class B consists of only its dependency knowledge , while that of Class C consists of not only its dependency knowledge but also its disambiguation knowledge ( Figure 6 ) .</sentence>
				<definiendum id="0">dependency pattern of Class B</definiendum>
			</definition>
			<definition id="7">
				<sentence>The idiom dictionary consists of 100 idioms , which are all verbal ( N/P V ) and belong to either Class B or C. Among the knowledge in ( 6 ) , the Selectional Restriction has not been implemented yet .</sentence>
				<definiendum id="0">idiom dictionary</definiendum>
				<definiens id="0">consists of 100 idioms , which are all verbal ( N/P V ) and belong to either Class B or C. Among the knowledge in ( 6 ) , the Selectional Restriction has not been implemented yet</definiens>
			</definition>
</paper>

		<paper id="2037">
			<definition id="0">
				<sentence>em ( original signal ) which produced f. We need to estimate P ( e|f ) , the probability that a translator produces f as a translation of e. By applying Bayes’ rule it is decomposed into : P ( e|f ) = P ( f|e ) ∗P ( e ) P ( f ) .</sentence>
				<definiendum id="0">em</definiendum>
				<definiens id="0">original signal ) which produced f. We need to estimate P ( e|f ) , the probability that a translator produces f as a translation of e. By applying Bayes’ rule it is decomposed into : P ( e|f ) = P ( f|e ) ∗P</definiens>
			</definition>
			<definition id="1">
				<sentence>This problem is significantly alleviated by phrase-based models ( Och , 2002 ) , which represent nowadays the state-of-the-art in SMT .</sentence>
				<definiendum id="0">phrase-based models</definiendum>
				<definiens id="0">represent nowadays the state-of-the-art in SMT</definiens>
			</definition>
			<definition id="2">
				<sentence>We have computed the BLEU score ( accumulated up to 4-grams ) ( Papineni et al. , 2001 ) , the NIST score ( accumulated up to 5-grams ) ( Doddington , 2002 ) , the General Text Matching ( GTM ) F-measure ( e = 1,2 ) ( Melamed et al. , 2003 ) , and the METEOR measure ( Banerjee and Lavie , 2005 ) .</sentence>
				<definiendum id="0">Text Matching</definiendum>
				<definiens id="0">computed the BLEU score ( accumulated up to 4-grams ) ( Papineni et al. , 2001 ) , the NIST score ( accumulated up to 5-grams ) ( Doddington , 2002 ) , the General</definiens>
			</definition>
			<definition id="3">
				<sentence>In particular , we have worked on specialized language and translation models and on their combination with general models in order to achieve a proper balance between precision ( specialized in-domain models ) and recall ( general out-of-domain models ) .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">worked on specialized language and translation models and on their combination with general models in order to achieve a proper balance between precision ( specialized in-domain models</definiens>
			</definition>
</paper>

		<paper id="1055">
			<definition id="0">
				<sentence>cursively : PIN ( r , t , Ax ) = summationdisplay y , z β ( Ax → ByCz ) ×PIN ( r , s , By ) PIN ( s , t , Cz ) POUT ( r , s , By ) = summationdisplay x , z β ( Ax → ByCz ) ×POUT ( r , t , Ax ) PIN ( s , t , Cz ) POUT ( s , t , Cz ) = summationdisplay x , y β ( Ax → ByCz ) ×POUT ( r , t , Ax ) PIN ( r , s , By ) Although we show only the binary component here , of course there are both binary and unary productions that are included .</sentence>
				<definiendum id="0">y β</definiendum>
				<definiens id="0">s , By ) PIN ( s , t</definiens>
			</definition>
			<definition id="1">
				<sentence>These posterior rule probabilities are still given by ( 1 ) , but , since the structure of the tree is no longer known , we must sum over it when computing the inside and outside probabilities : PIN ( r , t , Ax ) = summationdisplay B , C , s summationdisplay y , z β ( Ax → ByCz ) × PIN ( r , s , By ) PIN ( s , t , Cz ) POUT ( r , s , By ) = summationdisplay A , C , t summationdisplay x , z β ( Ax → ByCz ) × POUT ( r , t , Ax ) PIN ( s , t , Cz ) POUT ( s , t , Cz ) = summationdisplay A , B , r summationdisplay x , y β ( Ax → ByCz ) × POUT ( r , t , Ax ) PIN ( r , s , By ) For efficiency reasons , we use a coarse-to-fine pruning scheme like that of Caraballo and Charniak ( 1998 ) .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">s , By ) = summationdisplay A ,</definiens>
				<definiens id="1">s , t</definiens>
			</definition>
			<definition id="2">
				<sentence>Nominal categories are the most heavily split ( see Table 2 ) , and have the splits which are most semantic in nature ( though not without syntactic correlations ) .</sentence>
				<definiendum id="0">Nominal categories</definiendum>
				<definiens id="0">most semantic in nature ( though not without syntactic correlations )</definiens>
			</definition>
			<definition id="3">
				<sentence>Relative adverbs ( RBR ) are split into a different three categories , corresponding to ( usually metaphorical ) distance ( further ) , degree ( more ) , and time ( earlier ) .</sentence>
				<definiendum id="0">Relative adverbs</definiendum>
				<definiens id="0">usually metaphorical ) distance ( further ) , degree ( more ) , and time ( earlier )</definiens>
			</definition>
			<definition id="4">
				<sentence>Personal pronouns ( PRP ) are well-divided into three categories , roughly : nominative case , accusative case , and sentence-initial nominative case , which each correlate very strongly with syntactic position .</sentence>
				<definiendum id="0">Personal pronouns</definiendum>
			</definition>
</paper>

		<paper id="1146">
			<definition id="0">
				<sentence>Given a parallel corpus , semantic projection attempts to transfer semantic role annotations from one language to another , typically by exploiting word alignments .</sentence>
				<definiendum id="0">semantic projection</definiendum>
				<definiens id="0">attempts to transfer semantic role annotations from one language to another</definiens>
			</definition>
			<definition id="1">
				<sentence>A bipartite graph is a graph G = ( V , E ) whose node set V is partitioned into two nonempty sets V1 and V2 in such a way that every edge E joins a node in V1 to a node in V2 .</sentence>
				<definiendum id="0">bipartite graph</definiendum>
				<definiens id="0">a graph G = ( V , E ) whose node set V is partitioned into two nonempty sets V1 and V2 in such a way that every edge E joins a node in V1 to a node in V2</definiens>
			</definition>
			<definition id="2">
				<sentence>An edge cover is a subgraph of a bipartite graph so that each node is linked to at least one node of the other partition .</sentence>
				<definiendum id="0">edge cover</definiendum>
				<definiens id="0">a subgraph of a bipartite graph so that each node is linked to at least one node of the other partition</definiens>
			</definition>
			<definition id="3">
				<sentence>A minimum weight edge cover is an edge cover with the least possible sum of edge weights .</sentence>
				<definiendum id="0">minimum weight edge cover</definiendum>
				<definiens id="0">an edge cover with the least possible sum of edge weights</definiens>
			</definition>
			<definition id="4">
				<sentence>This set of likely arguments consists of all constituents which are a child of some ancestor of the predicate , provided that ( a ) they do not dominate the predicate themselves and ( b ) there is no sentence boundary between a constituent and its predicate .</sentence>
				<definiendum id="0">likely arguments</definiendum>
				<definiens id="0">consists of all constituents which are a child of some ancestor of the predicate , provided that ( a ) they do not dominate the predicate themselves and ( b ) there is no sentence boundary between a constituent and its predicate</definiens>
			</definition>
			<definition id="5">
				<sentence>Let y ( cs ) and y ( ct ) denote the yield of a source and target constituent , respectively , and al ( T ) the union of all word alignments for a token set T : sim ( cs , ct ) = |y ( ct ) ∩al ( y ( cs ) ) ||y ( c s ) | |y ( cs ) ∩al ( y ( ct ) ) | |y ( ct ) | We examined three filtering procedures ( see Section 4 ) : removing non-aligned words ( NA ) , removing non-content words ( NC ) , and removing unlikely arguments ( Arg ) .</sentence>
				<definiendum id="0">y ( cs</definiendum>
				<definiens id="0">the yield of a source and target constituent , respectively , and al ( T ) the union of all word alignments for a token set T : sim ( cs , ct ) = |y ( ct ) ∩al ( y ( cs ) ) ||y ( c s ) | |y ( cs ) ∩al ( y ( ct ) ) | |y ( ct ) | We examined three filtering procedures ( see Section 4 ) : removing non-aligned words ( NA ) , removing non-content words ( NC ) , and removing unlikely arguments ( Arg )</definiens>
			</definition>
</paper>

		<paper id="2058">
			<definition id="0">
				<sentence>In the disputed papers , “whilst” occurs in 6 of the documents ( 9 times total ) and “while” occurs in none .</sentence>
				<definiendum id="0">“whilst”</definiendum>
				<definiens id="0">occurs in 6 of the documents ( 9 times total ) and “while” occurs in none</definiens>
			</definition>
			<definition id="1">
				<sentence>The process of feature selection is one of the most crucial aspects of authorship attribution .</sentence>
				<definiendum id="0">feature selection</definiendum>
				<definiens id="0">one of the most crucial aspects of authorship attribution</definiens>
			</definition>
			<definition id="2">
				<sentence>The second requirement is that we need a threshold value so that the author knows how much the feature frequency needs to be adjusted .</sentence>
				<definiendum id="0">frequency</definiendum>
				<definiens id="0">needs to be adjusted</definiens>
			</definition>
			<definition id="3">
				<sentence>For the early experiments described in the previous section we used SVM30 , which incorporates the final set of 30 terms that Mosteller &amp; Wallace used for their study .</sentence>
				<definiendum id="0">SVM30</definiendum>
			</definition>
			<definition id="4">
				<sentence>The y-axis plots the accuracy of a classifier trained to distinguish between two authors ; the x-axis plots each iteration of the unmasking process .</sentence>
				<definiendum id="0">y-axis</definiendum>
				<definiens id="0">plots the accuracy of a classifier trained to distinguish between two authors ; the x-axis plots each iteration of the unmasking process</definiens>
			</definition>
</paper>

		<paper id="1100">
			<definition id="0">
				<sentence>Let S x and S y be the sets of all WordNet senses of x and y. A sense pair , s xy , is defined as any pair of senses of x and y : s xy = { s x , s y } where s x ∈S x and s y ∈S y .</sentence>
				<definiendum id="0">S x</definiendum>
				<definiendum id="1">S y</definiendum>
				<definiendum id="2">y. A sense pair</definiendum>
				<definiens id="0">the sets of all WordNet senses of x and</definiens>
				<definiens id="1">any pair of senses of x and y : s xy = { s x , s y } where s x ∈S x and s y ∈S y</definiens>
			</definition>
			<definition id="1">
				<sentence>The set of all sense pairs S xy consists of all permutations between senses in S x and S y .</sentence>
				<definiendum id="0">set of all sense pairs S xy</definiendum>
				<definiens id="0">consists of all permutations between senses in S x and S y</definiens>
			</definition>
			<definition id="2">
				<sentence>Given an instance ( x , r , y ) , this approach fixes the term y , called the anchor , and then disambiguates x by looking at all other terms that occur in the relation r with y. Based on the principle of distributional similarity ( Harris 1985 ) , the algorithm assumes that the words that occur in the same relation r with y will be more similar to the correct sense ( s ) of x than the incorrect ones .</sentence>
				<definiendum id="0">s</definiendum>
				<definiens id="0">disambiguates x by looking at all other terms that occur in the relation r with y. Based on the principle of distributional similarity</definiens>
			</definition>
			<definition id="3">
				<sentence>For each sense pair { s x , s x ' } ∈ S xx ' , a similarity score r ( s x , s x ' ) is calculated using WordNet : ) ( 1 ) , ( 1 ) , ( ' ' ' x xx xx sf ssd ssr × + = where the distance d ( s x , s x ' ) is the length of the shortest path connecting the two synsets in the hypernymy hierarchy of WordNet , and f ( s x ' ) is the number of times sense s x ' occurs in any of the instances of X ' .</sentence>
				<definiendum id="0">)</definiendum>
				<definiendum id="1">)</definiendum>
				<definiens id="0">s x , s x ' } ∈ S xx ' , a similarity score r ( s x , s x '</definiens>
				<definiens id="1">s x , s x '</definiens>
				<definiens id="2">the length of the shortest path connecting the two synsets in the hypernymy hierarchy of WordNet , and f ( s x '</definiens>
				<definiens id="3">the number of times sense s x ' occurs in any of the instances of X '</definiens>
			</definition>
			<definition id="4">
				<sentence>A semantic cluster is defined by the set of instances that have a common semantic generalization .</sentence>
				<definiendum id="0">semantic cluster</definiendum>
				<definiens id="0">the set of instances that have a common semantic generalization</definiens>
			</definition>
			<definition id="5">
				<sentence>A good cluster is one that : • achieves a good trade-off between generality and specificity ; and • disambiguates among the senses of x and y using the other instances’ senses as support .</sentence>
				<definiendum id="0">good cluster</definiendum>
			</definition>
			<definition id="6">
				<sentence>Each candidate conceptual instance , c= { c x , c y } , is scored by its degree of generalization as follows : ) 1 ( ) 1 ( 1 ) ( +×+ = yx nn cr where n i is the number of hypernymy links needed to go from s i to c i , for i ∈ { x , y } .</sentence>
				<definiendum id="0">n i</definiendum>
				<definiens id="0">c y } , is scored by its degree of generalization as follows</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , below are two possible conceptual instances for the part-of relation : [ person # 1 , PART-OF , organization # 1 ] [ act # 1 , PART-OF , plan # 1 ] The first conceptual instance in the example subsumes all the part-of instances in which one or more persons are part of an organization , such as : ( president Brown , PART-OF , executive council ) ( representatives , PART-OF , organization ) ( students , PART-OF , orchestra ) ( players , PART-OF , Metro League ) Below , we present three possible ways of exploiting these conceptual instances .</sentence>
				<definiendum id="0">PART-OF</definiendum>
				<definiens id="0">subsumes all the part-of instances in which one or more persons are part of an organization , such as : ( president Brown , PART-OF , executive council</definiens>
			</definition>
</paper>

		<paper id="1047">
			<definition id="0">
				<sentence>In this paper , we define an event as one or more event terms along with the named entities associated , and present a novel approach to derive intraand interevent relevance using the information of internal association , semantic relatedness , distributional similarity and named entity clustering .</sentence>
				<definiendum id="0">event</definiendum>
				<definiens id="0">one or more event terms along with the named entities associated</definiens>
				<definiens id="1">the information of internal association , semantic relatedness , distributional similarity and named entity clustering</definiens>
			</definition>
			<definition id="1">
				<sentence>While traditional linguistics work on semantic theory of events and the semantic structures of verbs , studies in information retrieval ( IR ) within topic detection and tracking framework look at events as narrowly defined topics which can be categorized or clustered as a set of related documents ( TDT ) .</sentence>
				<definiendum id="0">IR</definiendum>
				<definiens id="0">work on semantic theory of events and the semantic structures of verbs , studies in information retrieval</definiens>
				<definiens id="1">a set of related documents</definiens>
			</definition>
			<definition id="2">
				<sentence>In the information extraction ( IE ) community , events are defined as the pre-specified and structured templates that relate an action to its participants , times , locations and other entities involved ( MUC-7 ) .</sentence>
				<definiendum id="0">information extraction</definiendum>
				<definiens id="0">the pre-specified and structured templates that relate an action to its participants , times , locations and other entities involved ( MUC-7 )</definiens>
			</definition>
			<definition id="3">
				<sentence>Events can be broadly defined as “Who did What to Whom When and Where” .</sentence>
				<definiendum id="0">Events</definiendum>
			</definition>
			<definition id="4">
				<sentence>Event terms ( ET ) are indicated by rectangles and named entities ( NE ) are indicated by ellipses .</sentence>
				<definiendum id="0">Event terms</definiendum>
				<definiens id="0">indicated by rectangles and named entities ( NE ) are indicated by ellipses</definiens>
			</definition>
			<definition id="5">
				<sentence>Intra-event relevance measures how an action itself is associated with its associated arguments .</sentence>
				<definiendum id="0">Intra-event relevance</definiendum>
				<definiens id="0">measures how an action itself is associated with its associated arguments</definiens>
			</definition>
			<definition id="6">
				<sentence>Event Term ( ET ) Named Entity ( NE ) Event Term ( ET ) ) , ( ETETR ) , ( NEETR Named Entity ( NE ) ) , ( ETNER ) , ( NENER Table 1 Relevance Matrix The complete relevance matrix is : ⎥ ⎦ ⎤ ⎢ ⎣ ⎡ = ) , ( ) , ( ) , ( ) , ( NENERETNER NEETRETETR R The intra-event relevance ) , ( NEETR can be simply established by counting how many times i et and j ne are associated , i.e. ) , ( ) , ( jijiDocument neetfreqneetr = ( E1 ) One way to measure the term relevance is to make use of a general language knowledge base , such as WordNet ( Fellbaum 1998 ) .</sentence>
				<definiendum id="0">Event Term ( ET ) Named Entity</definiendum>
				<definiendum id="1">ETETR</definiendum>
				<definiens id="0">to make use of a general language knowledge base</definiens>
			</definition>
			<definition id="7">
				<sentence>WordNet : :Similarity is a freely available software package that makes it possible to measure the semantic relatedness between a pair of concepts , or in our case event terms , based on WordNet ( Pedersen , Patwardhan and Michelizzi , 2004 ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiendum id="1">:Similarity</definiendum>
				<definiens id="0">a freely available software package that makes it possible to measure the semantic relatedness between a pair of concepts</definiens>
			</definition>
			<definition id="8">
				<sentence>| ) ( ) ( | ) , ( jijiDocument etNEetNEetetr ∩= ( E3 ) Where ) ( i etNE is the set of named entities i et associate .</sentence>
				<definiendum id="0">| ) ( )</definiendum>
				<definiendum id="1">jijiDocument etNEetNEetetr ∩=</definiendum>
				<definiendum id="2">etNE</definiendum>
			</definition>
			<definition id="9">
				<sentence>ROUGE is a recall-based metric for fixed length summaries .</sentence>
				<definiendum id="0">ROUGE</definiendum>
				<definiens id="0">a recall-based metric for fixed length summaries</definiens>
			</definition>
</paper>

		<paper id="2051">
</paper>

		<paper id="2006">
			<definition id="0">
				<sentence>On the other hand , DepBank includes an adjunct relation between meanwhile and call ( ed ) , while the GR annotation treats meanwhile as a text adjunct ( ta ) of governors , delimitedbybalancedcommas , followingNunberg’s ( 1990 ) text grammar but conveying less information here .</sentence>
				<definiendum id="0">DepBank</definiendum>
				<definiendum id="1">followingNunberg’s</definiendum>
				<definiens id="0">includes an adjunct relation between meanwhile and call ( ed ) , while the GR annotation treats meanwhile as a text adjunct ( ta ) of governors , delimitedbybalancedcommas</definiens>
			</definition>
			<definition id="1">
				<sentence>The GR scheme includes one feature in DepBank ( passive ) , several splits of relations in DepBank , such as adjunct , adds some of DepBank’s featural information , such as subord form , as a subtype slot of a relation ( ccomp ) , merges DepBank’s oblique with iobj , and so forth .</sentence>
				<definiendum id="0">GR scheme</definiendum>
				<definiens id="0">includes one feature in DepBank ( passive ) , several splits of relations in DepBank , such as adjunct , adds some of DepBank’s featural information , such as subord form</definiens>
			</definition>
			<definition id="2">
				<sentence>However , DepBank treats the majority of prenominal modifiers as adjectives rather than nouns and , therefore , associates them with an adegree rather than a num feature .</sentence>
				<definiendum id="0">DepBank</definiendum>
				<definiens id="0">treats the majority of prenominal modifiers as adjectives rather than nouns and , therefore</definiens>
			</definition>
</paper>

		<paper id="1130">
			<definition id="0">
				<sentence>Lexical Functional Grammar ( LFG ) ( Kaplan and Bresnan , 1982 ) is a constraint-based theory of grammar .</sentence>
				<definiendum id="0">Lexical Functional Grammar ( LFG )</definiendum>
				<definiens id="0">a constraint-based theory of grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>In the pipeline architecture , a PCFG ( or a history-based lexicalised generative parser ) is extracted from the treebank and used to parse unseen text into trees , the resulting trees are annotated with f-structure equations by the f-structure annotation algorithm and a constraint solver produces an f-structure .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">extracted from the treebank and used to parse unseen text into trees , the resulting trees are annotated with f-structure equations by the f-structure annotation algorithm and a constraint solver produces an f-structure</definiens>
			</definition>
			<definition id="2">
				<sentence>Lexical rules ( rules expanding preterminals ) are conditioned on the full set of ( atomic ) feature-value pairs φ-linked to the RHS .</sentence>
				<definiendum id="0">Lexical rules</definiendum>
				<definiens id="0">rules expanding preterminals</definiens>
			</definition>
			<definition id="3">
				<sentence>Our backoff uses the built-in lexical macros4 of the automatic fstructure annotation algorithm of Cahill et al. ( 2004 ) to identify potential part-of-speech categories corresponding to a particular set of features .</sentence>
				<definiendum id="0">backoff</definiendum>
				<definiens id="0">uses the built-in lexical macros4 of the automatic fstructure annotation algorithm of Cahill et al. ( 2004 ) to identify potential part-of-speech categories corresponding to a particular set of features</definiens>
			</definition>
			<definition id="4">
				<sentence>BLEU is the weighted average of n-gram precision against the gold standard sentences .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">the weighted average of n-gram precision against the gold standard sentences</definiens>
			</definition>
			<definition id="5">
				<sentence>Partial output is a robustness feature for cases where a sub-fstructure component fails to generate a string and the system outputs a concatenation of the strings generated by the remaining components , rather than fail completely .</sentence>
				<definiendum id="0">Partial output</definiendum>
				<definiens id="0">a robustness feature for cases where a sub-fstructure component fails to generate a string and the system outputs a concatenation of the strings generated by the remaining components</definiens>
			</definition>
</paper>

		<paper id="2052">
			<definition id="0">
				<sentence>Tree Kernel defines the similarity between two syntactic structures as the number of shared subtrees .</sentence>
				<definiendum id="0">Tree Kernel</definiendum>
				<definiens id="0">defines the similarity between two syntactic structures as the number of shared subtrees</definiens>
			</definition>
			<definition id="1">
				<sentence>KC ( T1 , T2 ) = maxn 1∈N1 , n2∈N2 C ( n1 , n2 ) ( 1 ) where C ( n1 , n2 ) is the number of shared subtrees by two trees rooted at nodes n1 and n2 .</sentence>
				<definiendum id="0">KC</definiendum>
				<definiendum id="1">C</definiendum>
			</definition>
			<definition id="2">
				<sentence>• If the productions at n1 and n2 are different C ( n1 , n2 ) = 0 • If the productions at n1 and n2 are the same , and n1 and n2 are pre-terminals , then C ( n1 , n2 ) = 1 • Else if the productions at n1 and n2 are the same and n1 and n2 are not pre-terminals , C ( n1 , n2 ) = nc ( n1 ) productdisplay i=1 ( 1 + C ( ch ( n1 , i ) , ch ( n2 , i ) ) ) ( 2 ) where nc ( n ) is the number of children of node n and ch ( n , i ) is the i’th child node of n. Equation ( 2 ) recursively calculates C on its child node , and calculating Cs in postorder avoids recalculation .</sentence>
				<definiendum id="0">Else</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">nc</definiendum>
				<definiens id="0">if the productions at n1</definiens>
				<definiens id="1">the number of children of node n and ch</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus , the time complexity of KC ( T1 , T2 ) is O ( mn ) , where m and n are the numbers of nodes in T1 and T2 respectively .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the numbers of nodes in T1 and T2 respectively</definiens>
			</definition>
			<definition id="4">
				<sentence>Tree Kernel exploits all subtrees shared by trees .</sentence>
				<definiendum id="0">Tree Kernel</definiendum>
			</definition>
			<definition id="5">
				<sentence>L ( n1 , n2 ) represents a set of pairs of nodes which overlap each other when putting n1 on n2 .</sentence>
				<definiendum id="0">n2 )</definiendum>
				<definiens id="0">a set of pairs of nodes which overlap each other when putting n1 on n2</definiens>
			</definition>
			<definition id="6">
				<sentence>CTO ( n1 , n2 ) = vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle     ( m1 , m2 ) vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle m1 ∈ NT ( T1 ) ∧ m2 ∈ NT ( T2 ) ∧ ( m1 , m2 ) ∈ L ( n1 , n2 ) ∧ PR ( m1 ) = PR ( m2 )     vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle , ( 3 ) where NT ( T ) is a set of nonterminal nodes in tree T , PR ( n ) is a production rule rooted at node n. Tree Overlapping similarity STO ( T1 , T2 ) is defined as follows by using CTO ( n1 , n2 ) .</sentence>
				<definiendum id="0">CTO</definiendum>
				<definiendum id="1">NT ( T )</definiendum>
				<definiendum id="2">PR ( n )</definiendum>
				<definiendum id="3">T2</definiendum>
				<definiens id="0">vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle     ( m1 , m2 ) vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle m1 ∈ NT ( T1 ) ∧ m2 ∈ NT ( T2 ) ∧ ( m1 , m2 ) ∈ L ( n1 , n2 ) ∧ PR ( m1 ) = PR ( m2 )     vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle</definiens>
				<definiens id="1">a set of nonterminal nodes in tree T</definiens>
				<definiens id="2">a production rule rooted at node n. Tree Overlapping similarity STO ( T1 ,</definiens>
			</definition>
			<definition id="7">
				<sentence>I [ p ] =   m vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle T ∈ F ∧ m ∈ NT ( T ) ∧ p = PR ( m )    ( 5 ) where F is the corpus ( here { T1 , T2 } ) and the meaning of other symbols is the same as the definition of CTO ( equation ( 3 ) ) .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">vextendsinglevextendsingle vextendsinglevextendsingle vextendsinglevextendsingle vextendsingle T ∈ F ∧ m ∈ NT ( T ) ∧ p = PR</definiens>
				<definiens id="1">the corpus</definiens>
			</definition>
			<definition id="8">
				<sentence>function top ( n , m ) ; begin ( nprime , mprime ) : = ( n , m ) while order ( nprime ) = order ( mprime ) do nprime : = parent ( nprime ) mprime : = parent ( mprime ) end return ( nprime , mprime ) end where parent ( n ) is the parent node of n , and order ( n ) is the order of node n among its siblings .</sentence>
				<definiendum id="0">function top</definiendum>
				<definiendum id="1">n )</definiendum>
				<definiendum id="2">order</definiendum>
				<definiens id="0">the parent node of n , and</definiens>
				<definiens id="1">the order of node n among its siblings</definiens>
			</definition>
			<definition id="9">
				<sentence>Suppose T0 is a query tree , TS is a set of trees in the corpus and P ( T ) is a set of subpaths of T. We can build an index table I [ p ] for each production rule p as follows .</sentence>
				<definiendum id="0">TS</definiendum>
				<definiens id="0">a query tree</definiens>
				<definiens id="1">a set of trees in the corpus and P ( T ) is a set of subpaths of T. We can build an index table</definiens>
			</definition>
			<definition id="10">
				<sentence>The number of indexes is bounded above by L × D2 where L is the maximum number of leaves of trees ( the number of words in a sentence ) and D is the maximum depth of syntactic trees .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">D</definiendum>
				<definiens id="0">the number of words in a sentence</definiens>
			</definition>
</paper>

		<paper id="4010">
			<definition id="0">
				<sentence>Information Extraction ( IE ) is an innovative language technology for accurately acquiring crucial information from documents .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
				<definiens id="0">an innovative language technology for accurately acquiring crucial information from documents</definiens>
			</definition>
			<definition id="1">
				<sentence>For the former NEs , a shallow parsing mechanism , i.e. , finitestate cascades ( FSC ) ( Abney , 1996 ) which are automatically constructed by sets of NE recognition rules , is adopted for reliably identifying different categories of NEs .</sentence>
				<definiendum id="0">finitestate cascades</definiendum>
				<definiens id="0">a shallow parsing mechanism</definiens>
				<definiens id="1">constructed by sets of NE recognition rules , is adopted for reliably identifying different categories of NEs</definiens>
			</definition>
			<definition id="2">
				<sentence>and POS Tags NER Identification Resources NE-Recognized Texts NE Recognition Resources Lexical Ontology NER-Identified Texts 38 used in the system development .</sentence>
				<definiendum id="0">POS Tags NER Identification</definiendum>
				<definiens id="0">Resources NE-Recognized Texts NE Recognition Resources Lexical Ontology NER-Identified Texts 38 used in the system development</definiens>
			</definition>
			<definition id="3">
				<sentence>In the first experiment , the training set consists of 94 texts including 3473 sentences collected stem from the soccer matches of the Jie Fang Daily ( http : //www.jfdaily.com/ ) in 2001 .</sentence>
				<definiendum id="0">training set</definiendum>
				<definiens id="0">consists of 94 texts including 3473 sentences collected stem from the soccer matches of the Jie Fang Daily ( http : //www.jfdaily.com/ ) in 2001</definiens>
			</definition>
			<definition id="4">
				<sentence>The lexical sports ontology plays an important role in the identification of NEs and NERs , such as determination of the boundary of N ation for NE with special constructons and calculation of similarity for the features ( e.g. semantic distance ) .</sentence>
				<definiendum id="0">lexical sports ontology</definiendum>
				<definiens id="0">plays an important role in the identification of NEs and NERs , such as determination of the boundary of N ation for NE with special constructons and calculation of similarity for the features ( e.g. semantic distance )</definiens>
			</definition>
</paper>

		<paper id="1063">
			<definition id="0">
				<sentence>Bikel’s parser is a history-based parser which uses a lexicalised generative model to parse sentences .</sentence>
				<definiendum id="0">Bikel’s parser</definiendum>
				<definiens id="0">a history-based parser which uses a lexicalised generative model to parse sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>The training set for the parser consists of a xed amount of Penn-II Treebank data ( Sections 02-21 ) and a reducing amount of question data from the 3600 question training set .</sentence>
				<definiendum id="0">training set for the parser</definiendum>
				<definiens id="0">consists of a xed amount of Penn-II Treebank data ( Sections 02-21 ) and a reducing amount of question data from the 3600 question training set</definiens>
			</definition>
			<definition id="2">
				<sentence>SBARQ WHNP-1 WP Who SQ NP *T*-1 VP VBD killed NP Harvey Oswald ( a ) SBARQ WHNP-1 WP Who SQ AUX did NP Harvey Oswald VP VB kill NP *T*-1 ( b ) Figure 8 : LDD resolved treebank style trees With few exceptions5 the trees produced by current treebank-based probabilistic parsers do not represent long distance dependencies ( Figure 9 ) .</sentence>
				<definiendum id="0">SBARQ WHNP-1 WP Who SQ NP *T*-1 VP VBD</definiendum>
			</definition>
</paper>

		<paper id="4012">
			<definition id="0">
				<sentence>This interactive presentation describes LexNet , a graphical environment for graph-based NLP developed at the University of Michigan .</sentence>
				<definiendum id="0">LexNet</definiendum>
				<definiens id="0">a graphical environment for graph-based NLP developed at the University of Michigan</definiens>
			</definition>
			<definition id="1">
				<sentence>Hence transductive methods are of great potential for NLP problems and , as a result , LexNet includes a number of transductive methods .</sentence>
				<definiendum id="0">Hence transductive methods</definiendum>
				<definiendum id="1">LexNet</definiendum>
				<definiens id="0">includes a number of transductive methods</definiens>
			</definition>
			<definition id="2">
				<sentence>The basic idea behind Biased LexRank is to label a small number of sentences ( or passages ) that are relevant to a particular query and then propagate relevance from these sentences to other ( unannotated ) sentences .</sentence>
				<definiendum id="0">Biased LexRank</definiendum>
				<definiens id="0">to label a small number of sentences ( or passages ) that are relevant to a particular query</definiens>
			</definition>
			<definition id="3">
				<sentence>The XML DTD allows layout information to be encoded along with algorithmic information such as label and polarity .</sentence>
				<definiendum id="0">XML DTD</definiendum>
				<definiens id="0">allows layout information to be encoded along with algorithmic information such as label and polarity</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>s = ( AF ( u ) 2 + BF ( u ) + C ) e−D.d ( u , v ) ( 1 ) We have adapted this model slightly , in line with NAM , taking the similarity s to be the probability of confusing stimulus v with form u. Also , as our data usually offers no frequency information , we have adopted the maximum entropy assumption , namely , that all relative frequencies are equal .</sentence>
				<definiendum id="0">maximum entropy assumption</definiendum>
				<definiens id="0">taking the similarity s to be the probability of confusing stimulus</definiens>
			</definition>
			<definition id="1">
				<sentence>P ( w|ws ) = e−d ( w , ws ) /N ( ws ) ( 2 ) The normalising constant N ( s ) is the sum of the non-normalised values for e−d ( w , ws ) for all words w. N ( ws ) = summationdisplay w∈W e−d ( u , v ) Kidd and Watson ( 1992 ) have shown that discriminability of frequency and of duration of tones in a tone sequence depends on its length as a proportion of the length of the sequence .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">the sum of the non-normalised values for e−d ( w , ws ) for all words w. N ( ws ) = summationdisplay w∈W e−d ( u , v</definiens>
			</definition>
			<definition id="2">
				<sentence>R ( ¯w|α ) = P ( ¯w ) αQ ( ¯w ) 1−α/k ( α ; P , Q ) ( 6 ) The function k ( α ; P , Q ) is a normaliser for the conditional distribution , being the sum of the weighted geometric means of values from P and Q ( equation 7 ) .</sentence>
				<definiendum id="0">R</definiendum>
			</definition>
			<definition id="3">
				<sentence>Gypsy is an Indian language , related to Hindi .</sentence>
				<definiendum id="0">Gypsy</definiendum>
			</definition>
</paper>

		<paper id="1094">
			<definition id="0">
				<sentence>The relative salience of an object is the average of its visual salience ( S vis ) and discourse salience ( S disc ) , salience ( L ) = ( S vis ( L ) + S disc ( L ) ) /2 ( 2 ) Visual salience S vis is computed using the algorithm of Kelleher and van Genabith ( 2004 ) .</sentence>
				<definiendum id="0">relative salience of an object</definiendum>
				<definiens id="0">the average of its visual salience ( S vis ) and discourse salience ( S disc ) , salience ( L ) = ( S vis ( L ) + S disc</definiens>
			</definition>
			<definition id="1">
				<sentence>Second , the relative proximity field for some landmark is a function of that landmark’s salience .</sentence>
				<definiendum id="0">relative proximity field for some landmark</definiendum>
				<definiens id="0">a function of that landmark’s salience</definiens>
			</definition>
</paper>

		<paper id="2041">
			<definition id="0">
				<sentence>A dependency graph is a labeled directed graph , the nodes of which are indices corresponding to the tokens of a sentence .</sentence>
				<definiendum id="0">dependency graph</definiendum>
				<definiens id="0">a labeled directed graph , the nodes of which are indices corresponding to the tokens of a sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Definition 3 Given a set R = { r0 , r1 , ... rm } of dependency types and a sentence x = ( w1 , ... , wn ) , a parser configuration for x is a quadruple c = ( σ , τ , h , d ) , where : to nodes .</sentence>
				<definiendum id="0">)</definiendum>
				<definiens id="0">a sentence x = ( w1 , ... , wn</definiens>
			</definition>
			<definition id="2">
				<sentence>MBL is a lazy learning method , based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems ( Daelemans and Van den Bosch , 2005 ) .</sentence>
				<definiendum id="0">MBL</definiendum>
				<definiens id="0">a lazy learning method , based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems</definiens>
			</definition>
			<definition id="3">
				<sentence>We have performed an empirical comparison of MBL ( TIMBL ) and SVM ( LIBSVM ) as learning methods for classifier-based deterministic dependency parsing , using data from three languages and feature models of varying complexity .</sentence>
				<definiendum id="0">TIMBL</definiendum>
				<definiendum id="1">SVM</definiendum>
				<definiens id="0">learning methods for classifier-based deterministic dependency parsing , using data from three languages and feature models of varying complexity</definiens>
			</definition>
</paper>

		<paper id="1071">
			<definition id="0">
				<sentence>This results in the following exponential model : ( ) ( ) ( ) ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ = ∑ j jj yxf xZ xyp , exp 1 λ ( 3 ) where λ j is the weight corresponding to the feature f j , and Z ( x ) is a normalization factor .</sentence>
				<definiendum id="0">Z ( x )</definiendum>
				<definiens id="0">the weight corresponding to the feature f j</definiens>
				<definiens id="1">a normalization factor</definiens>
			</definition>
			<definition id="1">
				<sentence>Given : Feature space F ( 0 ) = { f 1 ( 0 ) , f 2 ( 0 ) , … , f N ( 0 ) } , step_num = m , select_factor = s 1 parts { F 1 ( 1 ) , F 2 ( 1 ) , … , F N1 ( 1 ) } = split ( F ( 0 ) ) //2.1 Feature selection for each feature space F i ( k ) do FS i ( k ) = SGC ( F i ( k ) , s ) //2.2 Combine selected features { F 1 ( k+1 ) , … , F Nk+1 ( k+1 ) } = merge ( FS 1 ( k ) , … , FS Nk ( k ) ) F ( m ) = merge ( FS 1 ( m-1 ) , … , FS Nm-1 ( m-1 ) ) FS ( m ) = SGC ( F ( m ) , s ) M final = Opt ( FS ( m ) ) Table 1 .</sentence>
				<definiendum id="0">FS Nk</definiendum>
				<definiens id="0">k ) , s ) //2.2 Combine selected features { F 1 ( k+1 ) , … , F Nk+1 ( k+1 ) } = merge ( FS 1 ( k ) , … ,</definiens>
			</definition>
			<definition id="2">
				<sentence>The re-segmented UW Switchboard corpus is labeled with a simplified subset of the ToBI prosodic system ( Ostendorf et al. , 2001 ) .</sentence>
				<definiendum id="0">re-segmented UW Switchboard corpus</definiendum>
			</definition>
</paper>

		<paper id="2076">
			<definition id="0">
				<sentence>Table 1 : Features F1 part of speech ( POS ) of P F2 main word of P F3 word of P F4 first 1 , 2 , 3 , 4 , 5 , and 7 digits of category number of P 5 F5 auxiliary verb attached to P F6 word of N F7 first 1 , 2 , 3 , 4 , 5 , and 7 digits of category number of N F8 case particles and words of nominals that have dependency relationship with P and are other than N F9 first 1 , 2 , 3 , 4 , 5 , and 7 digits of category number of nominals that have dependency relationship with P and are other than N F10 case particles of nominals that have dependency relationship with P and are other than N F11 the words appearing in the same sentence F12 first 3 and 5 digits of category number of words appearing in same sentence F13 case particle taken by N ( source case particle ) F14 target case particle output by KNP ( Kurohashi , 1998 ) F15 target case particle output with Kondo’s method ( Kondo et al. , 2001 ) F16 case patterns defined in IPAL dictionary ( IPAL ) ( IPA , 1987 ) F17 combination of predicate semantic primitives defined in IPAL F18 predicate semantic primitives defined in IPAL F19 combination of semantic primitives of N defined in IPAL F20 semantic primitives of N defined in IPAL F21 whether P is defined in IPAL or not F22 whether P can be in passive form defined in VDIC 6 F23 case particles of P defined in VDIC F24 type of P defined in VDIC F25 transformation rule used for P and N in Kondo’s method F26 whether P is defined in VDIC or not F27 pattern of case particles of nominals that have dependency relationship with P F28 pair of case particles of nominals that have dependency relationship with P F29 case particles of nominals that have dependency relationship with P and appear before N F30 case particles of nominals that have dependency relationship with P and appear after N F31 case particles of nominals that have dependency relationship with P and appear just before N F32 case particles of nominals that have dependency relationship with P and appear just after N 589 Table 2 : Frequently occurring target case particles in source case particles Source case particle Occurrence rate Frequent target case Occurrence rate particles in in source case particles source case particles ni ( indirect object ) 27.57 % ( 493/1788 ) ni ( indirect object ) 70.79 % ( 349/493 ) ga ( subject ) 27.38 % ( 135/493 ) ga ( subject ) 26.96 % ( 482/1788 ) wo ( direct object ) 96.47 % ( 465/482 ) de ( with ) 17.17 % ( 307/1788 ) ga ( subject ) 79.15 % ( 243/307 ) de ( with ) 13.36 % ( 41/307 ) to ( with ) 16.11 % ( 288/1788 ) to ( with ) 99.31 % ( 286/288 ) wo ( direct object ) 6.77 % ( 121/1788 ) wo ( direct object ) 99.17 % ( 120/121 ) kara ( from ) 4.53 % ( 81/1788 ) ga ( subject ) 49.38 % ( 40/ 81 ) kara ( from ) 44.44 % ( 36/ 81 ) made ( to ) 0.78 % ( 14/1788 ) made ( to ) 100.00 % ( 14/ 14 ) he ( to ) 0.06 % ( 1/1788 ) ga ( subject ) 100.00 % ( 1/ 1 ) no ( subject ) 0.06 % ( 1/1788 ) wo ( direct object ) 100.00 % ( 1/ 1 ) Support vector machines are capable of handling data consisting of two categories .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">Features F1 part of speech (</definiens>
				<definiens id="1">IPAL dictionary ( IPAL ) ( IPA , 1987 ) F17 combination of predicate semantic primitives defined in IPAL F18 predicate semantic primitives defined in IPAL F19 combination of semantic primitives of N defined in IPAL F20 semantic primitives of N</definiens>
			</definition>
			<definition id="1">
				<sentence>KNP indicates the results that the Japanese syntactic parser , KNP ( Kurohashi , 1998 ) , output .</sentence>
				<definiendum id="0">KNP</definiendum>
				<definiens id="0">indicates the results that the Japanese syntactic parser</definiens>
			</definition>
			<definition id="2">
				<sentence>“Division” , which separates training data for all source particles , obtained a high accuracy rate ( 88.36 % ) even when the number of training data was small .</sentence>
				<definiendum id="0">“Division”</definiendum>
				<definiens id="0">separates training data for all source particles , obtained a high accuracy rate</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>Information Extraction ( IE ) is such a technology that IE systems are expected to identify relevant information ( usually of predefined types ) from text documents in a certain domain and put them in a structured format .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
				<definiens id="0">such a technology that IE systems are expected to identify relevant information ( usually of predefined types ) from text documents in a certain domain and put them in a structured format</definiens>
			</definition>
			<definition id="1">
				<sentence>Kambhatla ( 2004 ) employed maximum entropy models with features derived from word , entity type , mention level , overlap , dependency tree , parse tree and achieved Fmeasure of 52.8 on the 24 relation subtypes in the ACE RDC 2003 corpus .</sentence>
				<definiendum id="0">maximum entropy</definiendum>
				<definiens id="0">models with features derived from word , entity type , mention level , overlap , dependency tree , parse tree and achieved Fmeasure of 52.8 on the 24 relation subtypes in the ACE RDC 2003 corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>10 20 30 40 50 60 70 2 00 40 0 60 0 80 0 10 0 0 1 20 0 14 0 0 1 60 0 18 0 0 2 00 0 Training Data Size F m e as ur e HS : General-Staff FS : General-Staff HS : Part-Of FS : Part-Of HS : Located FS : Located Figure 2 : Learning curve of the hierarchical strategy and its comparison with the flat strategy for some major relation subtypes ( Note : FS for the flat strategy and HS for the hierarchical strategy ) Performance System P R F Our : Perceptron Algorithm + Hierarchical Strategy 63.6 53.6 58.2 Zhou et al ( 2005 ) : SVM + Flat Strategy 63.1 49.5 55.5 Kambhatla ( 2004 ) : Maximum Entropy + Flat Strategy 63.5 45.2 52.8 Table 5 : Comparison of our system with other best-reported systems 127 This paper proposes a novel hierarchical learning strategy to deal with the data sparseness problem in relation extraction by modeling the commonality among related classes .</sentence>
				<definiendum id="0">General-Staff FS</definiendum>
				<definiendum id="1">General-Staff HS</definiendum>
				<definiendum id="2">Part-Of FS</definiendum>
				<definiendum id="3">Part-Of HS</definiendum>
				<definiens id="0">Located FS : Located Figure 2 : Learning curve of the hierarchical strategy and its comparison with the flat strategy for some major relation subtypes ( Note : FS for the flat strategy and HS for the hierarchical strategy ) Performance System</definiens>
			</definition>
</paper>

		<paper id="2111">
			<definition id="0">
				<sentence>Dice is a well-known combinatorial measure that computes the ratio between the size of the intersection of two feature sets and the sum of the sizes of the individual feature sets .</sentence>
				<definiendum id="0">Dice</definiendum>
				<definiens id="0">a well-known combinatorial measure that computes the ratio between the size of the intersection of two feature sets and the sum of the sizes of the individual feature sets</definiens>
			</definition>
			<definition id="1">
				<sentence>Dicey is a measure that incorporates weighted frequency counts .</sentence>
				<definiendum id="0">Dicey</definiendum>
			</definition>
			<definition id="2">
				<sentence>Dice† = 2 summationtext f min ( I ( W1 , f ) , I ( W2 , f ) ) summationtext f I ( W1 , f ) + I ( W2 , f ) , where f is the feature W1 and W2 are the two words that are being compared , and I is a weight assigned to the frequency counts .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">W2</definiendum>
				<definiendum id="2">I</definiendum>
				<definiens id="0">I ( W1 , f ) , I ( W2 , f ) ) summationtext f I ( W1 , f ) + I ( W2 , f )</definiens>
			</definition>
			<definition id="3">
				<sentence>I ( W , f ) = log P ( W , f ) P ( W ) P ( f ) , where W is the target word P ( W ) is the probability of seeing the word P ( f ) is the probability of seeing the feature P ( W , f ) is the probability of seeing the word and the feature together .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">the probability of seeing the word and the feature together</definiens>
			</definition>
			<definition id="4">
				<sentence>Hence , our gold standard consists of a list of all nouns found in EWN and their corresponding synonyms extracted by taking the union of all synsets for each word .</sentence>
				<definiendum id="0">gold standard</definiendum>
				<definiens id="0">consists of a list of all nouns found in EWN and their corresponding synonyms extracted by taking the union of all synsets for each word</definiens>
			</definition>
			<definition id="5">
				<sentence>Recall is the percentage of the synonyms according to EWN that are indeed found by the system .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the percentage of the synonyms according to EWN that are indeed found by the system</definiens>
			</definition>
			<definition id="6">
				<sentence>As our data we used the Dutch CLEF QA corpus , which consists of 78 million words of Dutch 2Note that we use the part of EWN that contains only nouns 3We have determined the optimum in F-score for the alignment-based method , the syntax-based method and the combination independently by using a development set of 1000 words that has no overlap with the test set used in evaluation .</sentence>
				<definiendum id="0">CLEF QA corpus</definiendum>
				<definiens id="0">consists of 78 million words</definiens>
				<definiens id="1">a development set of 1000 words that has no overlap with the test set used in evaluation</definiens>
			</definition>
			<definition id="7">
				<sentence>Secondly , the fact that Finnish is a language that has a lot of cases for nouns , might lead to data sparseness and worse accuracy in word alignment .</sentence>
				<definiendum id="0">Finnish</definiendum>
				<definiens id="0">a language that has a lot of cases for nouns , might lead to data sparseness and worse accuracy in word alignment</definiens>
			</definition>
</paper>

		<paper id="1120">
			<definition id="0">
				<sentence>This is because the parser-based methods return less , but better pairs ( i.e. , only the pairs identified as grammatical ) , and because collocations are a subset of the grammatical pairs .</sentence>
				<definiendum id="0">collocations</definiendum>
				<definiens id="0">the parser-based methods return less , but better pairs</definiens>
			</definition>
</paper>

		<paper id="1147">
			<definition id="0">
				<sentence>Among the topic-related passages , the pointwise mutual information ( PMI ) of attribute values were calculated which consequently formed a symmetric mutual information matrix .</sentence>
				<definiendum id="0">PMI</definiendum>
				<definiens id="0">calculated which consequently formed a symmetric mutual information matrix</definiens>
			</definition>
			<definition id="1">
				<sentence>Let Num ( ti ... tj ) denotes the number of all matched n-grams , d ( E , ti ... tj ) denotes the word distance between the named entity and the matched n-gram , W1 ( ti ... tj ) denotes the topic weight of the matched n-gram , W2 ( ti ... tj ) denotes the length weight of the matched n-gram .</sentence>
				<definiendum id="0">tj )</definiendum>
				<definiendum id="1">tj )</definiendum>
				<definiens id="0">the number of all matched n-grams , d ( E , ti ... tj ) denotes the word distance between the named entity and the matched n-gram</definiens>
				<definiens id="1">the topic weight of the matched n-gram</definiens>
			</definition>
			<definition id="2">
				<sentence>The classification process consists of two steps : topic categorization and question mapping .</sentence>
				<definiendum id="0">classification process</definiendum>
			</definition>
</paper>

		<paper id="2002">
			<definition id="0">
				<sentence>In this paper , we describe a rote extractor that learns patterns for finding semantic relationships in unrestricted text , with new procedures for pattern generalization and scoring .</sentence>
				<definiendum id="0">rote extractor</definiendum>
				<definiens id="0">learns patterns for finding semantic relationships in unrestricted text , with new procedures for pattern generalization and scoring</definiens>
			</definition>
			<definition id="1">
				<sentence>The distance between two patterns A and B is defined as the minimum number of changes ( insertion , addition or replacement ) that have to be done to the first one in order to obtain the second one .</sentence>
				<definiendum id="0">distance between two</definiendum>
				<definiendum id="1">B</definiendum>
				<definiens id="0">the minimum number of changes ( insertion , addition or replacement</definiens>
			</definition>
			<definition id="2">
				<sentence>AandB are two word patterns ; Mis the matrix in which the edit distance is calculated , andD is the matrix indicating the choice that produced the minimal distance for each cell inM .</sentence>
				<definiendum id="0">andD</definiendum>
				<definiens id="0">the matrix indicating the choice that produced the minimal distance for each cell inM</definiens>
			</definition>
			<definition id="3">
				<sentence>( 1 ) HOOK , / , returned|travelled|born/VBN to|in/IN TARGET It is interesting that , among the three relationships with the smaller number of extracted patterns , one of them did not produce any result , and Ravichandran Relation Our approach and Hovy’s Actor-film 76.84 % 1.71 % Writer-book 28.13 % 8.55 % Birth-year 79.67 % 49.49 % Birth-place 14.56 % 88.66 % Country-capital 72.43 % 24.79 % Country-president 81.40 % 16.13 % Death-year 96.71 % 35.35 % Director-film 84.91 % 1.01 % Painter-picture 0.85 % Player-team 52.50 % 44.44 % Table 5 : Inclusion precision on the same test corpus for our approach and Ravichandran and Hovy ( 2002 ) ’s .</sentence>
				<definiendum id="0">HOOK , / , returned|travelled|born/VBN to|in/IN TARGET It</definiendum>
				<definiens id="0">Inclusion precision on the same test corpus for our approach</definiens>
			</definition>
</paper>

		<paper id="1045">
			<definition id="0">
				<sentence>Lexical knowledge is one of the most important resources in natural language applications , making it almost indispensable for higher levels of syntactical and semantic processing .</sentence>
				<definiendum id="0">Lexical knowledge</definiendum>
				<definiens id="0">one of the most important resources in natural language applications , making it almost indispensable for higher levels of syntactical and semantic processing</definiens>
			</definition>
			<definition id="1">
				<sentence>However , whereas many methods which adopt the hypothesis are based on contextual clues concerning words , and there has been much consideration on the language models such as Latent Semantic Indexing ( Deerwester et al. , 1990 ) and Probabilistic LSI ( Hofmann , 1999 ) and synonym acquisition method , almost no attention has been paid to what kind of categories of contextual information , or their combinations , are useful for word featuring in terms of synonym acquisition .</sentence>
				<definiendum id="0">Probabilistic LSI</definiendum>
				<definiens id="0">useful for word featuring in terms of synonym acquisition</definiens>
			</definition>
			<definition id="2">
				<sentence>RASP outputs the extracted GRs as n-ary relations as follows : ( ncsubj note Department obj ) ( ncsubj be Shipment _ ) ( xcomp _ be level ) ( mod _ level relatively ) ( aux _ be have ) ( ncmod since be January ) ( mod _ Department note ) ( ncmod _ Department Commerce ) 354 ( detmod _ Department the ) ( ncmod _ be Department ) While most of GRs extracted by RASP are binary relations of head and dependent , there are some relations that contain additional slot or extra information regarding the relations , as shown “ncsubj” and “ncmod” in the above example .</sentence>
				<definiendum id="0">RASP</definiendum>
				<definiendum id="1">GRs</definiendum>
				<definiendum id="2">ncmod</definiendum>
				<definiens id="0">outputs the extracted</definiens>
				<definiens id="1">since be January ) ( mod _ Department note ) ( ncmod _ Department Commerce ) 354 ( detmod _ Department the ) ( ncmod _ be Department ) While most of GRs extracted by RASP are binary relations of head</definiens>
			</definition>
			<definition id="3">
				<sentence>The contexts for the previous example sentence , when the window radius is 3 , are then : shipment R1 : have shipment R2 : be shipment R3 : relatively January L1 : since January L2 : level January L3 : relatively January R1 : , January R2 : the January R3 : Commerce Commerce L1 : the Commerce L2 : , Commerce L3 : January Commerce R1 : Department ... Note that the proximity includes tokens such as punctuation marks as context , because we suppose they offer useful contextual information as well .</sentence>
				<definiendum id="0">Commerce L2</definiendum>
				<definiens id="0">the January R3 : Commerce Commerce L1 : the</definiens>
			</definition>
			<definition id="4">
				<sentence>The purpose of the current study is to investigate the impact of the contextual information selection , not the language model itself , we employed one of the most commonly used method : vector space model ( VSM ) and tf·idf weighting scheme .</sentence>
				<definiendum id="0">VSM</definiendum>
				<definiens id="0">to investigate the impact of the contextual information selection , not the language model itself</definiens>
			</definition>
			<definition id="5">
				<sentence>( 4 ) The similarity between word w with senses w1 , ... , wn and word v with senses v1 , ... , vm is defined as the maximum similarity between all the pairs of word senses : sim ( w , v ) = maxi , j sim ( wi , vj ) , ( 5 ) whose idea came from Lin’s method ( Lin , 1998 ) .</sentence>
				<definiendum id="0">, vm</definiendum>
				<definiens id="0">The similarity between word w with senses w1 , ... , wn and word v with senses v1 , ...</definiens>
			</definition>
			<definition id="6">
				<sentence>The following four groups 357 65.0 % 65.5 % 66.0 % 66.5 % 67.0 % 67.5 % 68.0 % 68.5 % dis crim ina tio n ra te ( DR ) a cor rela tio n c oef fici ent ( C C ) ) DR CC dep sent prox dep sent dep prox sent prox all ( 1 ) WSJ DR = 52.8 % CC = -0.0029 sent : 65.0 % 65.5 % 66.0 % 66.5 % 67.0 % 67.5 % 68.0 % 68.5 % 69.0 % dis crim ina tio n ra te ( DR ) a cor rela tio n c oef fici ent ( C C ) ) DR CC dep sent prox dep sent dep prox sent prox all ( 2 ) BROWN DR = 53.8 % CC = 0.060 sent : 66.0 % 66.5 % 67.0 % 67.5 % 68.0 % 68.5 % 69.0 % dis crim ina tio n ra te ( DR ) a cor rela tio n c oef fici ent ( C C ) ) DR CC dep sent prox dep sent dep prox sent prox all ( 3 ) WB DR = 52.2 % CC = 0.0066 sent : Figure 4 : Contextual information selection performances Discrimination rate ( DR ) and correlation coefficient ( CC ) for ( 1 ) Wall Street Journal corpus , ( 2 ) Brown Corpus , and ( 3 ) WordBank .</sentence>
				<definiendum id="0">CC dep sent prox</definiendum>
				<definiens id="0">ina tio n ra te ( DR ) a cor rela tio n c oef fici ent ( C C )</definiens>
				<definiens id="1">a cor rela tio n c oef fici ent ( C C</definiens>
				<definiens id="2">a cor rela tio n c oef fici ent ( C C ) ) DR CC dep sent prox dep sent dep prox sent prox all ( 3 ) WB DR = 52.2 % CC = 0.0066 sent : Figure 4 : Contextual information selection performances Discrimination rate ( DR ) and correlation coefficient ( CC ) for ( 1 ) Wall Street Journal corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>To do this , we broke down the mod group into these five categories according to modifying word’s category : ( 1 ) detmod , when the GR label is “det358 54.0 % 56.0 % 58.0 % 60.0 % 62.0 % 64.0 % 66.0 % 68.0 % dis crim ina tio n ra te ( DR ) a cor rela tio n c oef fici ent ( C C ) ) DR CC subj obj mod etc subjobj subjobj mod all ( 1 ) WSJ 54.0 % 56.0 % 58.0 % 60.0 % 62.0 % 64.0 % 66.0 % 68.0 % dis crim ina tio n ra te ( DR ) a cor rela tio n c oef fici ent ( C C ) ) DR CC subj obj mod etc subjobj subjobj mod all ( 2 ) BROWN 54.0 % 56.0 % 58.0 % 60.0 % 62.0 % 64.0 % 66.0 % 68.0 % 70.0 % dis crim ina tio n ra te ( DR ) a cor rela tio n c oef fici ent ( C C ) ) DR CC subj obj mod etc subjobj subjobj mod all ( 3 ) WB Figure 5 : Dependency selection performances Discrimination rate ( DR ) and correlation coefficient ( CC ) for ( 1 ) Wall Street Journal corpus , ( 2 ) Brown Corpus , and ( 3 ) WordBank .</sentence>
				<definiendum id="0">DR</definiendum>
				<definiendum id="1">C C ) ) DR CC subj</definiendum>
				<definiens id="0">crim ina tio n ra te ( DR ) a cor rela tio n c oef fici ent ( C C ) ) DR CC subj obj mod etc subjobj subjobj mod all</definiens>
				<definiens id="1">crim ina tio n ra te ( DR ) a cor rela tio n c oef fici ent ( C C ) ) DR CC subj obj mod etc subjobj subjobj mod all</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>Word Sense Disambiguation ( WSD ) is undoubtedly one of the hardest tasks in the field of Natural Language Processing .</sentence>
				<definiendum id="0">Word Sense Disambiguation ( WSD</definiendum>
				<definiens id="0">undoubtedly one of the hardest tasks in the field of Natural Language Processing</definiens>
			</definition>
			<definition id="1">
				<sentence>Unfortunately , WordNet is a fine-grained resource , encoding sense distinctions that are often difficult to recognize even for human annotators ( Edmonds and Kilgariff , 1998 ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a fine-grained resource , encoding sense distinctions</definiens>
			</definition>
			<definition id="2">
				<sentence>WordNet ( Fellbaum , 1998 ) is a computational lexicon of English which encodes concepts as synonym sets ( synsets ) , according to psycholinguistic principles .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="3">
				<sentence>Also , the ODE provides a sense ( ginger 1The ODE was kindly made available by Ken Litkowski ( CL Research ) in the context of a license agreement .</sentence>
				<definiendum id="0">ODE</definiendum>
				<definiens id="0">provides a sense ( ginger 1The ODE was kindly made available by Ken Litkowski ( CL Research ) in the context of a license agreement</definiens>
			</definition>
			<definition id="4">
				<sentence>2In the following , we denote a WordNet sense with the convention w # p # i where w is a word , p a part of speech and i is a sense number ; analogously , we denote an ODE sense with the convention w # p # h : k where h is the homonym number and k is the k-th polysemous entry under homonym h. root ) which is not taken into account in WordNet .</sentence>
				<definiendum id="0">w</definiendum>
				<definiendum id="1">h</definiendum>
				<definiendum id="2">k</definiendum>
				<definiens id="0">a word , p a part of speech</definiens>
				<definiens id="1">the k-th polysemous entry under homonym h. root ) which is not taken into account in WordNet</definiens>
			</definition>
			<definition id="5">
				<sentence>For each word w , and for each sense S of w in a given dictionary D 2 fWORDNET ; ODEg , we construct a sense description dD ( S ) as a bag of words : dD ( S ) = def D ( S ) [ hyperD ( S ) [ domainsD ( S ) where : † def D ( S ) is the set of words in the textual definition of S ( excluding usage examples ) , automatically lemmatized and partof-speech tagged with the RASP statistical parser ( Briscoe and Carroll , 2002 ) ; † hyperD ( S ) is the set of direct hypernyms of S in the taxonomy hierarchy of D ( ; if hypernymy is not available ) ; † domainsD ( S ) includes the set of domain labels possibly assigned to sense S ( ; when no domain is assigned ) .</sentence>
				<definiendum id="0">def D ( S )</definiendum>
				<definiendum id="1">RASP statistical parser</definiendum>
				<definiens id="0">a bag of words : dD ( S ) = def D ( S ) [ hyperD ( S ) [ domainsD ( S ) where : †</definiens>
			</definition>
			<definition id="6">
				<sentence>race # n ( ODE ) # 1.1 Core : SPORT A competition between runners , horses , vehicles , etc. † RACING A series of such competitions for horses or dogs † A situation in which individuals or groups compete ( !</sentence>
				<definiendum id="0">ODE</definiendum>
				<definiens id="0">SPORT A competition between runners , horses , vehicles , etc. † RACING A series of such competitions for horses or dogs † A situation in which individuals</definiens>
			</definition>
			<definition id="7">
				<sentence>SensesODE [ f†g , where SensesD is the set of senses in the dictionary D and † is a special element assigned when no plausible option is available for mapping ( e.g. when the ODE encodes no entry corresponding to a WordNet sense ) .</sentence>
				<definiendum id="0">SensesODE</definiendum>
				<definiendum id="1">SensesD</definiendum>
				<definiens id="0">the set of senses in the dictionary D and † is a special element assigned when no plausible option is available for mapping ( e.g. when the ODE encodes no entry corresponding to a WordNet sense )</definiens>
			</definition>
			<definition id="8">
				<sentence>SSI3 exploits an extensive lexical knowledge base , built upon the WordNet lexicon and enriched with collocation information representing semantic relatedness between sense pairs .</sentence>
				<definiendum id="0">SSI3</definiendum>
				<definiens id="0">exploits an extensive lexical knowledge base</definiens>
			</definition>
			<definition id="9">
				<sentence>A semantic interconnection pattern is a relevant sequence of edges selected according to a manually-created context-free grammar , i.e. a path connecting a pair of word senses , possibly including a number of intermediate concepts .</sentence>
				<definiendum id="0">semantic interconnection pattern</definiendum>
				<definiens id="0">a relevant sequence of edges selected according to a manually-created context-free grammar , i.e. a path connecting a pair of word senses , possibly including a number of intermediate concepts</definiens>
			</definition>
			<definition id="10">
				<sentence>The grammar consists of a small number of rules , inspired by the notion of lexical chains ( Morris and Hirst , 1991 ) .</sentence>
				<definiendum id="0">grammar</definiendum>
			</definition>
			<definition id="11">
				<sentence>At each step , for each sense S in C , the algorithm calculates a score of the degree of connectivity between S and the other senses in C : 3Available online from : http : //lcl.di.uniroma1.it/ssi ScoreSSI ( S ; C ) = P S02CnfSg P i2IC ( S ; S0 ) 1 length ( i ) P S02CnfSg jIC ( S ; S0 ) j where IC ( S ; S0 ) is the set of interconnections between senses S and S0 .</sentence>
				<definiendum id="0">IC</definiendum>
				<definiens id="0">the set of interconnections between senses S and S0</definiens>
			</definition>
			<definition id="12">
				<sentence>We chose SSI for the semantic matching function as it has the best performance among untrained systems on unconstrained WSD ( cf. Section 4.1 ) .</sentence>
				<definiendum id="0">SSI</definiendum>
			</definition>
			<definition id="13">
				<sentence>The entropy quantifies the distribution of the senses of a group over manually-defined groups , while the purity measures the extent to which a group contains senses primarily from one manual group .</sentence>
				<definiendum id="0">entropy</definiendum>
				<definiens id="0">quantifies the distribution of the senses of a group over manually-defined groups , while the purity measures the extent to which a group contains senses primarily from one manual group</definiens>
			</definition>
			<definition id="14">
				<sentence>Given a word w , and a sense group G 2 c ( w ) , the entropy of G is defined as : H ( G ) = ¡ 1log j^c ( w ) j P ^G2^c ( w ) j^G\Gj j^Gj log ( j^G\Gj j^Gj ) i.e. , the entropy4 of the distribution of senses of group G over the groups of the manual clustering ^c ( w ) .</sentence>
				<definiendum id="0">w )</definiendum>
				<definiens id="0">the entropy4 of the distribution of senses of group G over the groups of the manual clustering ^c ( w )</definiens>
			</definition>
			<definition id="15">
				<sentence>The entropy of an entire clustering c ( w ) is defined as : Entropy ( c ( w ) ) = P G2c ( w ) jGj jSensesWN ( w ) jH ( G ) that is , the entropy of each group weighted by its size .</sentence>
				<definiendum id="0">entropy of an entire clustering c ( w )</definiendum>
				<definiens id="0">Entropy ( c ( w ) ) = P G2c ( w ) jGj jSensesWN ( w ) jH ( G ) that is , the entropy of each group weighted by its size</definiens>
			</definition>
			<definition id="16">
				<sentence>The purity of a sense group G 2 c ( w ) is defined as : Pu ( G ) = 1jGj max ^G2^c ( w ) j^G\Gj i.e. , the normalized size of the largest subset of G contained in a single group ^G of the manual clustering .</sentence>
				<definiendum id="0">purity of a sense</definiendum>
				<definiens id="0">Pu ( G ) = 1jGj max ^G2^c ( w ) j^G\Gj i.e. , the normalized size of the largest subset of G contained in a single group ^G of the manual clustering</definiens>
			</definition>
			<definition id="17">
				<sentence>The overall purity of a clustering is obtained as a weighted sum of the individual cluster purities : Purity ( c ( w ) ) = P G2c ( w ) jGj jSensesWN ( w ) jPu ( G ) We calculated the entropy and purity of the clustering produced automatically with the lexical and the semantic method , when compared to the grouping induced by our manual mapping ( ODE ) , and to the grouping manually produced for the English all-words task at Senseval-2 ( 3,499 senses of 403 nouns ) .</sentence>
				<definiendum id="0">jGj jSensesWN</definiendum>
				<definiendum id="1">ODE</definiendum>
				<definiens id="0">( w ) jPu ( G ) We calculated the entropy and purity of the clustering produced automatically with the lexical and the semantic method</definiens>
			</definition>
			<definition id="18">
				<sentence>We compared the performance of 110 Table 5 : Performance of SSI on coarse inventories ( SSI⁄ uses a coarse-grained knowledge base ) .</sentence>
				<definiendum id="0">SSI⁄</definiendum>
				<definiens id="0">uses a coarse-grained knowledge base</definiens>
			</definition>
			<definition id="19">
				<sentence>WordNet : an Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>A decision list consists of a set of rules .</sentence>
				<definiendum id="0">decision list</definiendum>
				<definiens id="0">consists of a set of rules</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 1 : Framework of the tagging rules Table 1 : Words used in the tagging rules ( a ) ( b ) ( c ) the inde nite article much the de nite article another less demonstrative adjectives one enough possessive adjectives each suf cient interrogative adjectives quanti ers ’s genitives three types of a2 : a14a8a22 , a23a25a24 , and a26a27a24 that denote the contexts consisting of the noun phrase that the target noun heads , a24 words to the left of the noun phrase , and a24 words to its right , respectively .</sentence>
				<definiendum id="0">tagging rules</definiendum>
				<definiens id="0">Words used in the</definiens>
			</definition>
			<definition id="2">
				<sentence>It is de ned by2 a57 a11a46a58 a22a60a59 a1a56a2a62a61 a18 a28a60a63 a22a60a59 a1a56a2a62a61 a18 a28a60a63 ( 4 ) where a1a56a2 is the exclusive event of a1a3a2 and a22a64a59 a1a3a2a65a61 a18 a28a55a63 is the probability that the target noun is used as a1a56a2 when a18 appears in the context a2 .</sentence>
				<definiendum id="0">a1a56a2</definiendum>
			</definition>
			<definition id="3">
				<sentence>244 Table 4 : Detection rules ( ii ) Singular Plural a/an the a93 a/an the a93 Mass a90 a90 a90 a90 Count a90 a90 ( e.g. , *an expensive ) .</sentence>
				<definiendum id="0">Detection rules</definiendum>
				<definiens id="0">Singular Plural a/an the a93 a/an the a93 Mass a90 a90 a90 a90 Count a90 a90 ( e.g. , *an expensive )</definiens>
			</definition>
			<definition id="4">
				<sentence>Variance is calculated by a22a64a59 a82a95a23 a22 a63 a14 ( 6 ) where a14 denotes the number of samples used for calculating the ratio .</sentence>
				<definiendum id="0">Variance</definiendum>
				<definiendum id="1">a14</definiendum>
				<definiens id="0">the number of samples used for calculating the ratio</definiens>
			</definition>
</paper>

		<paper id="1042">
			<definition id="0">
				<sentence>They share : • the Lefff 2 syntactic lexicon for French ( Sagot et al. , 2005 ) , that contains 500,000 entries ( representing 400,000 different forms ) ; each lexical entry contains morphological information , sub-categorization frames ( when relevant ) , and complementary syntactic information , in particular for verbal forms ( controls , attributives , impersonals , . . . ) , • the SXPipe pre-syntactic processing chain ( Sagot and Boullier , 2005 ) , that converts a raw text in a sequence of DAGs of forms that are present in the Lefff ; SXPipe contains , among other modules , a sentence-level segmenter , a tokenization and spelling-error correction module , named-entities recognizers , and a non-deterministic multi-word identifier .</sentence>
				<definiendum id="0">sentence-level segmenter</definiendum>
				<definiens id="0">contains morphological information , sub-categorization frames ( when relevant ) , and complementary syntactic information , in particular for verbal forms ( controls , attributives , impersonals , . . . ) , • the SXPipe pre-syntactic processing chain</definiens>
				<definiens id="1">a raw text in a sequence of DAGs of forms that are present in the Lefff</definiens>
			</definition>
			<definition id="1">
				<sentence>The EASy corpus contains several sub-corpora of varied style : journalistic , literacy , legal , medical , transcription of oral , email , questions , etc .</sentence>
				<definiendum id="0">EASy corpus</definiendum>
			</definition>
			<definition id="2">
				<sentence>It has the form of an HTML page that uses dynamic generation methods , in particular javascript .</sentence>
				<definiendum id="0">HTML page</definiendum>
				<definiens id="0">uses dynamic generation methods</definiens>
			</definition>
			<definition id="3">
				<sentence>It outputs 18,334 relevant suspicious forms ( out of the 327,785 possible ones ) , where a relevant suspicious form is defined as a form f that satisfies the following arbitrary constraints:6 S ( imax ) f &gt; 1,5 · S and |Of| &gt; 5 .</sentence>
				<definiendum id="0">S ( imax</definiendum>
				<definiens id="0">outputs 18,334 relevant suspicious forms ( out of the 327,785 possible ones ) , where a relevant suspicious form is defined as a form f that satisfies the following arbitrary constraints:6</definiens>
			</definition>
</paper>

		<paper id="2059">
			<definition id="0">
				<sentence>The polarity of an adjective is defined by its shortest paths from the node corresponding to ’good’ and ’bad’ .</sentence>
				<definiendum id="0">polarity of an adjective</definiendum>
			</definition>
</paper>

		<paper id="1099">
			<definition id="0">
				<sentence>While there have been lots of approaches to come up with a fully adequate ATR/CE metric ( cf. Section 2 ) , we have made observations in our experiments that seem to indicate that simplicity rules , i.e. , frequency of occurrence is the dominating factor for the ranking in the result lists even when much smarter statistical machinery is employed .</sentence>
				<definiendum id="0">adequate ATR/CE metric</definiendum>
			</definition>
			<definition id="1">
				<sentence>Collocations Terms domain newspaper biomedicine language German English linguistic type PP-Verb noun phrases combinations ( trigrams ) corpus size 114 million 104 million cutoff 10 8 # candidates 8,644 31,017 # true positives 1,180 ( 13.7 % ) 3,590 ( 11.6 % ) # true negatives 7,464 ( 86.3 % ) 27,427 ( 88.4 % ) Table 1 : Data sets for Collocation Extraction ( CE ) and Automatic Term Dioscovery ( ATR ) 3The UMLS Metathesaurus is an extensive and carefully curated terminological resource for the biomedical domain .</sentence>
				<definiendum id="0">PP-Verb noun phrases combinations</definiendum>
				<definiens id="0">an extensive and carefully curated terminological resource for the biomedical domain</definiens>
			</definition>
			<definition id="2">
				<sentence>LSM exploits the well-known linguistic property that collocations are much less modifiable with additional lexical material ( supplements ) than non-collocations .</sentence>
				<definiendum id="0">LSM</definiendum>
				<definiens id="0">exploits the well-known linguistic property that collocations are much less modifiable with additional lexical material ( supplements ) than non-collocations</definiens>
			</definition>
</paper>

		<paper id="1075">
			<definition id="0">
				<sentence>Cross-Language Information Retrieval ( CLIR ) enables users to construct queries in one language and search the documents in another language .</sentence>
				<definiendum id="0">Cross-Language Information Retrieval</definiendum>
				<definiendum id="1">CLIR</definiendum>
				<definiens id="0">enables users to construct queries in one language and search the documents in another language</definiens>
			</definition>
			<definition id="1">
				<sentence>The rule base consists of rules of different functions such as analysis , transfer and generation .</sentence>
				<definiendum id="0">rule base</definiendum>
				<definiens id="0">consists of rules of different functions such as analysis , transfer and generation</definiens>
			</definition>
			<definition id="2">
				<sentence>KIDS is an information retrieval engine that is based on morphological analysis ( Sakai et al. , 2003 ) .</sentence>
				<definiendum id="0">KIDS</definiendum>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>Word sense disambiguation ( WSD ) , the task of identifying the intended meanings ( senses ) of words in context , holds promise for many NLP applications requiring broad-coverage language understanding .</sentence>
				<definiendum id="0">Word sense disambiguation ( WSD</definiendum>
				<definiens id="0">the task of identifying the intended meanings ( senses ) of words in context , holds promise for many NLP applications requiring broad-coverage language understanding</definiens>
			</definition>
			<definition id="1">
				<sentence>Unsupervised WSD algorithms fall into two general classes : those that perform token-based WSD by exploiting the similarity or relatedness between an ambiguous word and its context ( e.g. , Lesk 1986 ) ; and those that perform type-based WSD , simply by assigning all instances of an ambiguous word its most frequent ( i.e. , predominant ) sense ( e.g. , McCarthy et al. 2004 ; Galley and McKeown 2003 ) .</sentence>
				<definiendum id="0">WSD algorithms</definiendum>
				<definiendum id="1">Galley</definiendum>
				<definiens id="0">fall into two general classes : those that perform token-based WSD by exploiting the similarity or relatedness between an ambiguous word and its context ( e.g. , Lesk 1986 ) ; and those that perform type-based WSD , simply by assigning all instances of an ambiguous word its most frequent ( i.e. , predominant ) sense ( e.g. , McCarthy et al. 2004 ;</definiens>
			</definition>
			<definition id="2">
				<sentence>We selected methods that vary along the following dimensions : ( a ) the type of WSD performed ( i.e. , token-based vs. type-based ) , ( b ) the representation and size of the context surrounding an ambiguous word ( i.e. , graph-based vs. word-based , document vs. sentence ) , and ( c ) the number and type of semantic relations considered for disambiguation .</sentence>
				<definiendum id="0">( c )</definiendum>
				<definiens id="0">a ) the type of WSD performed ( i.e. , token-based vs. type-based ) , ( b ) the representation and size of the context surrounding an ambiguous word ( i.e. , graph-based vs. word-based , document vs. sentence ) , and</definiens>
				<definiens id="1">the number and type of semantic relations considered for disambiguation</definiens>
			</definition>
			<definition id="3">
				<sentence>For every sense sk of the target word we estimate : SenseScore ( sk ) = ∑ Rel∈Relations Overlap ( context , Rel ( sk ) ) where context is a simple ( space separated ) concatenation of all words wi for n i n , i 6= 0 in a context window of length n around the target word w0 .</sentence>
				<definiendum id="0">context</definiendum>
				<definiens id="0">a simple ( space separated ) concatenation of all words wi for n i n , i 6= 0 in a context window of length n around the target word w0</definiens>
			</definition>
			<definition id="4">
				<sentence>Given a local word context C = fw1 , ... , wng , SSI builds a graph G = ( V , E ) such that V = nS i=1 senses ( wi ) and ( s , sprime ) 2 E if there is at least one interconnection j between s ( a sense of the word ) and sprime ( a sense of its context ) in the lexical knowledge base .</sentence>
				<definiendum id="0">SSI</definiendum>
				<definiens id="0">builds a graph G = ( V , E ) such that V = nS i=1 senses ( wi</definiens>
			</definition>
			<definition id="5">
				<sentence>At each step , for each sense s of a word in C ( the set of senses of words yet to be disambiguated ) , SSI determines the degree of connectivity between s and the other senses in C : SSIScore ( s ) = ∑ s02Cnfsg ∑ j2Interconn ( s ; s0 ) 1 length ( j ) ∑ s02Cnfsg |Interconn ( s ; s0 ) | where Interconn ( s , sprime ) is the set of interconnections between senses s and sprime .</sentence>
				<definiendum id="0">)</definiendum>
				<definiens id="0">the set of senses of words yet to be disambiguated ) , SSI determines the degree of connectivity between s and the other senses in C</definiens>
				<definiens id="1">s ; s0 ) | where Interconn ( s , sprime</definiens>
				<definiens id="2">the set of interconnections between senses s and sprime</definiens>
			</definition>
			<definition id="6">
				<sentence>SSI and Extended Gloss Overlap ( Overlap ) rely on sentencelevel information for disambiguation whereas McCarthy et al. ( 2004 ) ( Similarity ) and Galley and McKeown ( 2003 ) ( LexChains ) utilize the entire document or corpus .</sentence>
				<definiendum id="0">SSI</definiendum>
				<definiendum id="1">Similarity</definiendum>
				<definiens id="0">LexChains ) utilize the entire document or corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>Our rst set of experiments was conducted on the SemCor corpus , on the same 2,595 polysemous nouns ( 53,674 tokens ) used as a test set by McCarthy et al. ( 2004 ) .</sentence>
				<definiendum id="0">SemCor corpus</definiendum>
			</definition>
			<definition id="8">
				<sentence>Finally , T ( w ) is the set of tokens of w and senses ( t ) denotes the sense assigned to token t according to SemCor .</sentence>
				<definiendum id="0">T ( w )</definiendum>
				<definiens id="0">the set of tokens of w and senses ( t ) denotes the sense assigned to token t according to SemCor</definiens>
			</definition>
			<definition id="9">
				<sentence>Score ( Ranking ( fMigki=1 ) , s ) ) = k∑ i=1 ( 1 ) Placei ( s ) where Placei ( s ) is the number of distinct scores that are larger or equal to Score ( Mi , s ) .</sentence>
				<definiendum id="0">Score</definiendum>
				<definiens id="0">s ) where Placei ( s ) is the number of distinct scores</definiens>
			</definition>
			<definition id="10">
				<sentence>For each disagreed word w , and for each sense s of w assigned by any of the systems in the ensemble fMigki=1 , we calculate the following score : Score ( Arbiter ( fMigki=1 ) , s ) = SSIScore∗ ( s ) where SSIScore∗ ( s ) is a modi ed version of the score introduced in Section 2 which exploits as a context for s the set of agreed senses and the remaining words of each sentence .</sentence>
				<definiendum id="0">SSIScore∗ ( s )</definiendum>
				<definiens id="0">a modi ed version of the score introduced in Section</definiens>
			</definition>
			<definition id="11">
				<sentence>Speci cally , the approach com1-4 5-9 10-19 20-99 100+ Noun frequency bands 40 42 44 46 48 50 52 54 WSD Accuracy ( % ) Similarity SSI Arbiter Voting ProbMix Ranking Figure 1 : WSD accuracy as a function of noun frequency in SemCor Method Precision Recall Fscore Baseline 36.8 36.8 36.8 SSI 62.5 62.5 62.5 IRST-DDD 63.3 62.2 61.2 Rank-based 63.9 63.9 63.9 UpperBnd 68.7 68.7 68.7 Table 6 : Results of individual disambiguation algorithms and rank-based ensemble on Senseval-3 nouns pares the domain of the context surrounding the target word with the domains of its senses and uses a version of WordNet augmented with domain labels ( e.g. , economy , geography ) .</sentence>
				<definiendum id="0">WSD accuracy</definiendum>
				<definiens id="0">Results of individual disambiguation algorithms and rank-based ensemble on Senseval-3 nouns pares the domain of the context surrounding the target word with the domains of its senses and uses a version of WordNet augmented with domain labels ( e.g. , economy , geography )</definiens>
			</definition>
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>Lexical functional grammar ( LFG ) ( Kaplan and Bresnan , 1982 ) is a theory representing the syntax in two parallel levels : Constituent structures ( c-structures ) have the form of context-free phrase structure trees .</sentence>
				<definiendum id="0">Lexical functional grammar</definiendum>
				<definiendum id="1">LFG )</definiendum>
				<definiendum id="2">Constituent structures ( c-structures</definiendum>
				<definiens id="0">a theory representing the syntax in two parallel levels</definiens>
			</definition>
			<definition id="1">
				<sentence>Functional structures ( f-structures ) are sets of pairs of attributes and values ; attributes may be features , such as tense and gender , or functions , such as subject and object .</sentence>
				<definiendum id="0">Functional structures</definiendum>
				<definiens id="0">tense and gender , or functions , such as subject and object</definiens>
			</definition>
			<definition id="2">
				<sentence>Turkish is an agglutinative language where a sequence of inflectional and derivational morphemes get affixed to a root ( Oflazer , 1994 ) .</sentence>
				<definiendum id="0">Turkish</definiendum>
			</definition>
			<definition id="3">
				<sentence>then each IG CX denotes the relevant sequence of inflectional features including the part-of-speech for the root ( in IG BD ) and for any of the derived forms .</sentence>
				<definiendum id="0">IG CX</definiendum>
			</definition>
			<definition id="4">
				<sentence>The fourth IG indicates the derivation of a passive verb with positive polarity from the previous verb .</sentence>
				<definiendum id="0">fourth IG</definiendum>
				<definiens id="0">indicates the derivation of a passive verb with positive polarity from the previous verb</definiens>
			</definition>
			<definition id="5">
				<sentence>Finally the last IG represents a derivation into future participle which will function as a modifier in the sentence .</sentence>
				<definiendum id="0">IG</definiendum>
				<definiens id="0">a derivation into future participle which will function as a modifier in the sentence</definiens>
			</definition>
			<definition id="6">
				<sentence>The simple phrase eski kitaplarımdaki hikayeler ( the stories in my old books ) in Figure 1 will help clarify how IGs are involved in syntactic relations : Here , eski ( old ) modifies kitap ( book ) and not hikayeler ( stories ) , 4 and the locative phrase eski 3 The morphological features other than the obvious partof-speech features are : +A3sg : 3sg number-person agreement , +Pnon : no possesive agreement , +Nom : Nominative case , +Acquire : acquire verb , +Caus : causative verb , +Pass : passive verb , +FutPart : Derived future participle , +Pos : Positive Polarity .</sentence>
				<definiendum id="0">simple phrase eski kitaplarımdaki hikayeler</definiendum>
				<definiendum id="1">+Pnon</definiendum>
				<definiendum id="2">+Acquire</definiendum>
				<definiens id="0">no possesive agreement</definiens>
				<definiens id="1">Derived future participle</definiens>
			</definition>
			<definition id="7">
				<sentence>4 Though looking at just the last POS of the words one sees an +Adj +Adj +Noun sequence which may imply that both adjectives modify the noun hikayeler kitaplarımda ( in my old books ) modifies hikayeler with the help of derivational suffix -ki .</sentence>
				<definiendum id="0">+Adj +Adj +Noun</definiendum>
				<definiens id="0">in my old books ) modifies hikayeler with the help of derivational suffix -ki</definiens>
			</definition>
			<definition id="8">
				<sentence>( 2 ) BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘hikaye’ ADJUNCT BE BI BI BI BI BI BI BI BI BG PRED ‘relCWkitapCX’ OBJ BE BI BI BI BG PRED ‘kitap’ ADJUNCT AK PRED ‘eski’ ATYPE attributive AL CASE loc , NUM pl BF BJ BJ BJ BH ATYPE attributive BF BJ BJ BJ BJ BJ BJ BJ BJ BH CASE NOM , NUM PL BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH ( 3 ) NP C8 C8 C8 C8 AG AG AG AG AP C8 C8 C8 C8 AG AG AG AG NP C0 C0 C0 A8 A8 A8 AP A eski NP N kitaplarımda DS ki NP N hikayeler Figure 2 shows the modifier-head relations for a more complex example given in Example ( 4 ) where we observe a chain/hierarchy of relations between IGs ( 4 ) mavi blue renkli color-WITH elbiselideki dress-WITH-LOC-REL kitap book 5 Note that placing the sublexical units of a word in separate nodes goes against the Lexical Integrity principle of LFG ( Dalrymple , 2001 ) .</sentence>
				<definiendum id="0">IGs</definiendum>
				<definiens id="0">BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘hikaye’ ADJUNCT BE BI BI BI BI BI BI BI BI BG PRED ‘relCWkitapCX’ OBJ BE BI BI BI BG PRED ‘kitap’ ADJUNCT AK PRED ‘eski’ ATYPE attributive AL CASE loc , NUM pl BF BJ BJ BJ BH ATYPE attributive BF BJ BJ BJ BJ BJ BJ BJ BJ BH CASE NOM , NUM PL BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH ( 3 ) NP C8 C8 C8 C8 AG AG AG AG AP C8 C8 C8 C8 AG AG AG AG NP C0 C0 C0 A8 A8 A8 AP A eski</definiens>
			</definition>
			<definition id="9">
				<sentence>If an IG contains the root morpheme of a word , then the node corresponding to that IG is named as one of the syntactic category symbols .</sentence>
				<definiendum id="0">IG</definiendum>
				<definiens id="0">contains the root morpheme of a word , then the node corresponding to that IG is named as one of the syntactic category symbols</definiens>
			</definition>
			<definition id="10">
				<sentence>( 9 ) BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘s¨oyleCWmanav , araCX’ SUBJ AK PRED ‘manav’ CASE nom , NUM sg , PERS 3 AL OBJ BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘araCWkAGz , adamCX’ SUBJ AK PRED ‘kAGz’ CASE gen , NUM sg , PERS 3 AL OBJ AK PRED ‘adam’ CASE acc , NUM sg , PERS 3 AL CHECK CW PART pastpart CX CASE acc , NUM sg , PERS 3 , VTYPE main CLAUSE-TYPE nom BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH TNS-ASP CW TENSE past CX NUM SG , PERS 3 , VTYPE MAIN BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH Relative clauses also admit to a similar mechanism .</sentence>
				<definiendum id="0">BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘araCWkAGz</definiendum>
				<definiendum id="1">VTYPE MAIN BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH</definiendum>
				<definiens id="0">BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘s¨oyleCWmanav</definiens>
			</definition>
			<definition id="11">
				<sentence>( 11 ) BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ’adam’ BD ADJUNCT BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘s¨oyleCWmanav , araCX’ SUBJ AK PRED ‘manav’ CASE gen , NUM sg , PERS 3 AL OBJ BE BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘araCWkAGz , adamCX’ SUBJ AK PRED ‘kAGz’ CASE gen , NUM sg , PERS 3 AL OBJ CW PRED ‘adam’ CX BD CHECK CW PART pastpart CX CASE acc , NUM sg , PERS 3 , VTYPE main CLAUSE-TYPE nom BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH CHECK CW PART pastpart CX NUM sg , PERS 3 , VTYPE main ADJUNCT-TYPE relative BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH CASE NOM , NUM SG , PERS3 BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH Turkish verbal morphotactics allows the production multiply causative forms for verbs .</sentence>
				<definiendum id="0">VTYPE main CLAUSE-TYPE nom BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH CHECK CW PART pastpart CX NUM sg</definiendum>
				<definiens id="0">BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ’adam’ BD ADJUNCT BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘s¨oyleCWmanav</definiens>
				<definiens id="1">VTYPE main ADJUNCT-TYPE relative BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH CASE NOM , NUM SG , PERS3 BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH Turkish verbal morphotactics allows the production multiply causative forms for verbs</definiens>
			</definition>
			<definition id="12">
				<sentence>( 13 ) BE BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘araCWkAGz , adamCX’ SUBJ AK PRED ‘kAGz’ CASE nom , NUM sg , PERS 3 AL OBJ AK PRED ‘adam’ CASE acc , NUM sg , PERS 3 AL TNS-ASP CW TENSE past CX NUM SG , PERS 3 , VTYPE MAIN BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH ( 14 ) BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘causCWmanav , kAGz , adam , araCWkAGz , adamCXCX’ SUBJ CW PRED ‘manav’ CX OBJ CW PRED ‘kAGz’ CX BD OBJTH CW PRED ‘adam’ CX BE XCOMP BE BI BI BI BI BI BI BI BI BG PRED ‘araCWkAGz , adamCX’ SUBJ AK PRED ‘kAGz’ CASE dat , NUM sg , PERS 3 AL BD OBJ AK PRED ‘adam’ CASE acc , NUM sg , PERS 3 AL BE VTYPE main BF BJ BJ BJ BJ BJ BJ BJ BJ BH TNS-ASP CW TENSE past CX NUM SG , PERS 3 , VTYPE MAIN BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BH The end-result of processing an IG which has a verb with a causative form is to create a larger fstructure whose PRED feature has a SUBJect , an OBJect and a XCOMPlement .</sentence>
				<definiendum id="0">BF BJ BJ BJ BJ BJ BJ BJ BJ BH TNS-ASP CW TENSE past CX NUM SG</definiendum>
				<definiendum id="1">VTYPE MAIN BF BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ BJ</definiendum>
				<definiens id="0">BE BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BI BG PRED ‘causCWmanav , kAGz , adam , araCWkAGz , adamCXCX’ SUBJ CW PRED ‘manav’ CX OBJ CW PRED ‘kAGz’ CX BD OBJTH CW PRED ‘adam’ CX BE XCOMP BE BI BI BI BI BI BI BI BI BG PRED ‘araCWkAGz , adamCX’ SUBJ AK PRED ‘kAGz’ CASE dat</definiens>
			</definition>
			<definition id="13">
				<sentence>hit-CAUS-PAST ‘ ( s/he ) made the man hit the woman’ All other derivational phenomena can be solved in a similar way by establishing the appropriate semantic representation for the derived IG and its effect on the semantic representation .</sentence>
				<definiendum id="0">hit-CAUS-PAST ‘</definiendum>
				<definiens id="0">a similar way by establishing the appropriate semantic representation for the derived IG and its effect on the semantic representation</definiens>
			</definition>
</paper>

		<paper id="2004">
			<definition id="0">
				<sentence>An RC attachment ambiguity was defined as a sentence containing the pattern NP1 Prep NP2 which .</sentence>
				<definiendum id="0">RC attachment ambiguity</definiendum>
			</definition>
			<definition id="1">
				<sentence>A PP attachment ambiguity was defined as a subtree matching either [ VP [ NP PP ] ] or [ VP NP PP ] .</sentence>
				<definiendum id="0">PP attachment ambiguity</definiendum>
			</definition>
			<definition id="2">
				<sentence>For example , “john subj buy” , the analysis returned by minipar for John buys , is stored as “john buy john &lt; subj 26 subj &lt; buy john &lt; subj &lt; buy”. All words , dependencies and partial dependencies of a sentence are stored together as one document. This storage mechanism enables fast on-line queries for lexical and dependency statistics , e.g. , how many sentences contain the dependency “john subj buy” , how often does john occur as a subject , how often does buy have john as a subject and car as an object etc. Query results are approximate because double occurrences are only counted once and structures giving rise to the same set of dependencies ( a piece of a tile of a roof of a house vs. a piece of a roof of a tile of a house ) can not be distinguished. We believe that an inverted index is the most efficient data structure for our purposes. For example , we need not compute expensive joins as would be required in a database implementation. Our long-term goal is to use this inverted index of dependencies as a versatile component of NLP systems in analogy to the increasingly important role of search engines for association and word count statistics in NLP. A total of three inverted indexes were created , one each for the 10 % , 50 % and 100 % Reuters subset. Lattice-Based Disambiguation. Our disambiguation method is Lattice-Based Disambiguation ( LBD , ( Atterer and Sch¨utze , 2006 ) ) . We formalize a possible attachment as a triple &lt; R , i , X &gt; where X is ( the parse of ) a phrase with two or more possible attachment nodes in a sentence S , i is one of these attachment nodes and R is ( the relevant part of a parse of ) S with X removed .</sentence>
				<definiendum id="0">Lattice-Based Disambiguation</definiendum>
				<definiendum id="1">X</definiendum>
				<definiendum id="2">R</definiendum>
				<definiens id="0">fast on-line queries for lexical and dependency statistics , e.g. , how many sentences contain the dependency “john subj buy” , how often does john occur as a subject , how often does buy have john as a subject</definiens>
				<definiens id="1">the relevant part of a parse of ) S with X removed</definiens>
			</definition>
			<definition id="3">
				<sentence>We decide between attachment possibilities based on pointwise mutual information , the well-known measure of how surprising it is to see R and X together given their individual frequencies : MI ( &lt; R , i , X &gt; ) = log2 P ( &lt; R , i , X &gt; ) P ( R ) P ( X ) for P ( &lt; R , i , X &gt; ) , P ( R ) , P ( X ) negationslash= 0 MI ( &lt; R , i , X &gt; ) = 0 otherwise where the probabilities of the dependency structures &lt; R , i , X &gt; , R and X are estimated on the unlabeled corpus by querying the in0 : p MN : pN N : pM N : p N : pN MN : p MN : pMN : pMN MN : pMN Figure 1 : Lattice of pairs of potential attachment site ( NP ) and attachment phrase ( PP ) .</sentence>
				<definiendum id="0">attachment phrase</definiendum>
				<definiens id="0">to see R and X together given their individual frequencies : MI ( &lt; R , i</definiens>
			</definition>
			<definition id="4">
				<sentence>The second lattice for PP attachment , the lattice for attachment to the verb , has a structure identical to Figure 1 , but the attachment node is SV instead of MN , where S denotes the subject and V the verb .</sentence>
				<definiendum id="0">S</definiendum>
			</definition>
			<definition id="5">
				<sentence>ment , choose high attachment ( this only occurs if NP1 Prep NP2 is a named entity ) .</sentence>
				<definiendum id="0">high attachment</definiendum>
				<definiens id="0">a named entity )</definiens>
			</definition>
			<definition id="6">
				<sentence>LBD uses more context and can , in principle , accommodate arbitrarily large contexts .</sentence>
				<definiendum id="0">LBD</definiendum>
				<definiens id="0">uses more context and can , in principle , accommodate arbitrarily large contexts</definiens>
			</definition>
</paper>

		<paper id="2064">
			<definition id="0">
				<sentence>Examples for POSSESSOR are : S ( { have , own , possess } V , M SUBJ , H OBJ ) ( 5 ) S ( { belong to } V , H SUBJ , M OBJ ) ( 6 ) whereV is the set of seed verbs , M is the modiﬁer and H is the head noun .</sentence>
				<definiendum id="0">whereV</definiendum>
				<definiendum id="1">M</definiendum>
				<definiendum id="2">H</definiendum>
				<definiens id="0">the set of seed verbs</definiens>
			</definition>
			<definition id="1">
				<sentence>In the case of TIME , we consider coordinated occur494 ACTBENEFIT HAVE USE PLAYPERFORM ... ... Seed verbsaccept act agree HOLD ... .. Verb−MappingMethods AGENTBENEFICIARY CONTAINER OBJECTPOSSESSOR INSTRUMENT ... ... ... Semantic RelationsOriginal verbs accommodate Figure 2 : Verb mapping rences of the modiﬁer and head noun ( e.g. coach and player for player coach ) as evidence for the relation.3 We thus separately collate statistics from coordinated NPs for each NC , and from this compute a weight for each NC based on mutual information : TIME ( NCi ) = −log2freq ( coord ( Mi , Hi ) ) freqM i × freq ( Hi ) ( 7 ) where Mi and Hi are the modiﬁer and head of NCi , respectively , and freq ( coord ( Mi , Hi ) ) is the frequency of occurrence of Mi and Hi in coordinated NPs .</sentence>
				<definiendum id="0">Hi</definiendum>
				<definiendum id="1">freq</definiendum>
				<definiens id="0">the frequency of occurrence of Mi and Hi in coordinated NPs</definiens>
			</definition>
			<definition id="2">
				<sentence>Second , we used Moby’s thesaurus to extract both direct synonyms ( D-SYNONYM ) and a combination of direct and second-level indirect synonyms of verbs ( ISYNONYM ) , and from this , calculate the closestmatching seed verb ( s ) for a given verb .</sentence>
				<definiendum id="0">Moby’s</definiendum>
				<definiens id="0">thesaurus to extract both direct synonyms ( D-SYNONYM ) and a combination of direct and second-level indirect synonyms of verbs</definiens>
			</definition>
			<definition id="3">
				<sentence>Verbs found in the various contexts in the 3Note the order of the modiﬁer and head in coordinated NPs is considered to be irrelevant , i.e. player and coach and coach and player are equally evidence for an EQUATIVE interpretation for player coach ( and coach player ) .</sentence>
				<definiendum id="0">Verbs</definiendum>
				<definiens id="0">found in the various contexts in the 3Note the order of the modiﬁer and head in coordinated NPs is considered to be irrelevant , i.e. player and coach and coach and player are equally evidence for an EQUATIVE interpretation for player coach</definiens>
			</definition>
</paper>

	</volume>
