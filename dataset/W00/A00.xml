<?xml version="1.0" encoding="UTF-8"?>
<volume id="A00">

    <paper id="1022">
        <definition id="0">
            <sentence>It is implemented within the ICe-MAIL system , which is an assistance system for call center
                agents that is currently used in a commercial setting .
            </sentence>
            <definiendum id="0">ICe-MAIL system</definiendum>
            <definiens id="0">an assistance system for call center agents that is currently used in a commercial
                setting
            </definiens>
        </definition>
        <definition id="1">
            <sentence>While we have 5008 documents , TOPICS consists of 13321 instances 2 .</sentence>
            <definiendum id="0">TOPICS</definiendum>
            <definiens id="0">consists of 13321 instances 2</definiens>
        </definition>
        <definition id="2">
            <sentence>SML promises low costs both in analyzing and modeling the application at the expense of a lower
                accuracy .
            </sentence>
            <definiendum id="0">SML</definiendum>
            <definiens id="0">promises low costs both in analyzing and modeling the application at the expense of a
                lower accuracy
            </definiens>
        </definition>
        <definition id="3">
            <sentence>In general , SML tools work with a vector representation of data .</sentence>
            <definiendum id="0">SML tools</definiendum>
        </definition>
        <definition id="4">
            <sentence>The workflow of the system consists of a learning step carried out off-line ( the light gray box )
                and an online categorization step ( the dark gray box ) .
            </sentence>
            <definiendum id="0">workflow of the system</definiendum>
            <definiens id="0">consists of a learning step carried out off-line ( the light gray box ) and an online
                categorization step ( the dark gray box )
            </definiens>
        </definition>
        <definition id="5">
            <sentence>Several SML tools representing different learning paradigms have been selected and evaluated in
                different settings of our domain : Lazy Learning : Lazy Learners are also known as memory-based ,
                instance-based , exemplarbased , case-based , experience-based , or knearest neighbor algorithms .
            </sentence>
            <definiendum id="0">Several SML</definiendum>
            <definiens id="0">tools representing different learning paradigms have been selected and evaluated in
                different settings of our domain : Lazy Learning : Lazy Learners are also known as memory-based ,
                instance-based , exemplarbased , case-based , experience-based , or knearest neighbor algorithms
            </definiens>
        </definition>
        <definition id="6">
            <sentence>The relevancy vector consists of all selected results , where doubles are eliminated .</sentence>
            <definiendum id="0">relevancy vector</definiendum>
            <definiens id="0">consists of all selected results , where doubles are eliminated</definiens>
        </definition>
        <definition id="7">
            <sentence>MorphAna : Morphological Analysis provided by sines yields the word stems of nouns , verbs and
                adjectives , as well as the full forms of unknown words .
            </sentence>
            <definiendum id="0">MorphAna</definiendum>
            <definiens id="0">Morphological Analysis provided by sines yields the word stems of nouns , verbs and
                adjectives
            </definiens>
        </definition>
        <definition id="8">
            <sentence>KG , which answers requests about the German version of AOL software .</sentence>
            <definiendum id="0">KG</definiendum>
            <definiens id="0">answers requests about the German version of AOL software</definiens>
        </definition>
        <definition id="9">
            <sentence>A client/server solution was built that allows the call center agents to connect as clients to the
                ICe-MAIL server , which implements the system described in Section 3 .
            </sentence>
            <definiendum id="0">ICe-MAIL server</definiendum>
        </definition>
        <definition id="10">
            <sentence>MLC++ Machine Learning library in C++ .</sentence>
            <definiendum id="0">MLC++ Machine</definiendum>
            <definiens id="0">Learning library in C++</definiens>
        </definition>
    </paper>

    <paper id="1018">
        <definition id="0">
            <sentence>To warn the unsuspecting translator , TransCheck incorporates a repository of that nature .
            </sentence>
            <definiendum id="0">TransCheck</definiendum>
            <definiens id="0">incorporates a repository of that nature</definiens>
        </definition>
        <definition id="1">
            <sentence>Calques consist of sequences of legitimate words that incorrectly mimic the structure of the other
                language by being sort of literal translations .
            </sentence>
            <definiendum id="0">Calques</definiendum>
            <definiens id="0">consist of sequences of legitimate words that incorrectly mimic the structure of the other
                language by being sort of literal translations
            </definiens>
        </definition>
    </paper>

    <paper id="1004">
        <definition id="0">
            <sentence>Another utilization is in cross-language information retrieval ( CLIR ) where queries have to be
                translated from one language to another language in which the documents are written .
            </sentence>
            <definiendum id="0">utilization</definiendum>
            <definiens id="0">cross-language information retrieval ( CLIR ) where queries have to be translated from one
                language to another language in which the documents are written
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Therefore , CLIR is a suitable application for such a translation model .</sentence>
            <definiendum id="0">CLIR</definiendum>
            <definiens id="0">a suitable application for such a translation model</definiens>
        </definition>
        <definition id="2">
            <sentence>SILC is a language and encoding identification system developed by the RALI laboratory at the
                University of Montreal .
            </sentence>
            <definiendum id="0">SILC</definiendum>
            <definiens id="0">a language and encoding identification system developed by the RALI laboratory at the
                University of Montreal
            </definiens>
        </definition>
        <definition id="3">
            <sentence>In the simplest case ( model 1 ) , the model learns the probability , p ( tls ) , of having a word
                t in the translation of a sentence containing a word s. For an input sentence , the model then
                calculates a sequence of words that are most probable to appear in its translation .
            </sentence>
            <definiendum id="0">model 1</definiendum>
            <definiens id="0">the probability , p ( tls ) , of having a word t in the translation of a sentence
                containing a word s. For an input sentence , the model then calculates a sequence of words that are most
                probable to appear in its translation
            </definiens>
        </definition>
        <definition id="4">
            <sentence>Stop-list is a set of the most frequent words that we remove from the train3.5 English word t/f
                access adaptation add adopt agent agree airline amendment , appliance apply attendance auditor , average
                base_on t t t t t t t t t t t/f t t t t t t t t t t Translation office protection report prepare local
                follow standard adult inadequate part financial visit bill vehicle saving Figure 4 : Part of the
                evaluation lexicons .
            </sentence>
            <definiendum id="0">Stop-list</definiendum>
            <definiens id="0">a set of the most frequent words that we remove from the train3.5 English word t/f access
                adaptation add adopt agent agree airline amendment , appliance apply attendance auditor , average
                base_on t t t t t t t t t t t/f t t t t t t t t t
            </definiens>
        </definition>
    </paper>

    <paper id="2014">
        <definition id="0">
            <sentence>The CDG parser parses the word graph to identify the best sentence consistent with both the
                acoustics of the utterance and its own additional knowledge .
            </sentence>
            <definiendum id="0">CDG parser</definiendum>
            <definiens id="0">parses the word graph to identify the best sentence consistent with both the acoustics of
                the utterance and its own additional knowledge
            </definiens>
        </definition>
        <definition id="1">
            <sentence>A CDG is defined as a five-tuple , ( 2E , R , L , C , T ) , where ~ = { al , ... , c % } is a
                finite set of lexical categories ( e.g. , determiner ) , R = { rl , ... , rp } is a finite set of
                uniquely named roles or role ids ( e.g. , governor , needl , need2 ) , L = { ll , ... , lq } is a finite
                set of labels ( e.g. , subject ) , C is a constraint formula , and T is a table that specifies allowable
                category-role-label combinations .
            </sentence>
            <definiendum id="0">CDG</definiendum>
            <definiendum id="1">, rp }</definiendum>
            <definiendum id="2">C</definiendum>
            <definiendum id="3">T</definiendum>
            <definiens id="0">a five-tuple , ( 2E , R , L , C , T ) , where ~ = { al , ... , c % } is a finite set of
                lexical categories ( e.g. , determiner ) , R = { rl , ...
            </definiens>
            <definiens id="1">a finite set of uniquely named roles or role ids ( e.g. , governor , needl</definiens>
            <definiens id="2">{ ll , ... , lq } is a finite set of labels ( e.g. , subject ) ,</definiens>
            <definiens id="3">a constraint formula , and</definiens>
            <definiens id="4">a table that specifies allowable category-role-label combinations</definiens>
        </definition>
        <definition id="2">
            <sentence>A sentence s WlW2W3 ... wn has length n and is an element of ~* .</sentence>
            <definiendum id="0">sentence</definiendum>
            <definiens id="0">s WlW2W3 ... wn has length n and is an element of ~*</definiens>
        </definition>
        <definition id="3">
            <sentence>C is a firstorder predicate calculus formula over all roles that requires that an assignment of
                role values to roles be consistent with the formula ; those role values inconsistent with C can be
                eliminated .
            </sentence>
            <definiendum id="0">C</definiendum>
            <definiens id="0">a firstorder predicate calculus formula over all roles that requires that an assignment of
                role values to roles be consistent with the formula
            </definiens>
        </definition>
        <definition id="4">
            <sentence>A subformula P~ of C is a predicate involving = , &lt; , or &gt; , or predicates joined by the
                logical connectives and , or , if , or not .
            </sentence>
            <definiendum id="0">subformula P~ of C</definiendum>
            <definiens id="0">a predicate involving = , &lt; , or &gt; , or predicates joined by the logical connectives
                and
            </definiens>
        </definition>
        <definition id="5">
            <sentence>A CDG has an arity parameter a , which indicates the maximum number of variables in the
                subformulas of C , and a degree parameter d , which is the number of roles in the grammar .
            </sentence>
            <definiendum id="0">CDG</definiendum>
            <definiens id="0">indicates the maximum number of variables in the subformulas of C</definiens>
            <definiens id="1">the number of roles in the grammar</definiens>
        </definition>
        <definition id="6">
            <sentence>x RxPOSxLxMODx Ftx ... x Fk , where k is the number of feature types , Fi represents the set of
                feature values for that type , POS = { 1 , 2 , ... , n } is the set of possible positions , MOD = { 1 ,
                2 , ... , n } is the set of possible modiflees , and n is sentence length ( which can be any arbitrary
                natural number ) , then unary constraints partition $ 1 into grammatical and ungrammatical role values .
            </sentence>
            <definiendum id="0">k</definiendum>
            <definiendum id="1">Fi</definiendum>
            <definiendum id="2">n }</definiendum>
            <definiendum id="3">n }</definiendum>
            <definiens id="0">the number of feature types</definiens>
            <definiens id="1">the set of possible modiflees , and n is sentence length ( which can be any arbitrary
                natural number
            </definiens>
        </definition>
        <definition id="7">
            <sentence>Formally , an ARV for a particular grammar G = ( ~ , , R , L , C , T , Ft , ... , Fk ) is an
                element of the set : .
            </sentence>
            <definiendum id="0">Ft , ... , Fk )</definiendum>
            <definiens id="0">an element of the set</definiens>
        </definition>
        <definition id="8">
            <sentence>dl = ExR× L xFt × ... xFkxUC , where UC encodes the three possible positional relations between
                Pxl and Mxl .
            </sentence>
            <definiendum id="0">UC</definiendum>
            <definiens id="0">encodes the three possible positional relations between Pxl and Mxl</definiens>
        </definition>
        <definition id="9">
            <sentence>x Fk x BC , where BC encodes the positional relations among Pxl , Mxt , Px2 , and Mx2 , provides
                an alternative definition for the binary constraints 2 .
            </sentence>
            <definiendum id="0">BC</definiendum>
            <definiens id="0">encodes the positional relations among Pxl , Mxt , Px2</definiens>
        </definition>
        <definition id="10">
            <sentence>RM contains 5,190 separate utterances ( 3,990 testing , 1,200 training ) of 2,845 distinct
                sentences ( 2,245 training , 600 testing ) .
            </sentence>
            <definiendum id="0">RM</definiendum>
            <definiens id="0">contains 5,190 separate utterances ( 3,990 testing , 1,200 training ) of 2,845 distinct
                sentences ( 2,245 training , 600 testing )
            </definiens>
        </definition>
        <definition id="11">
            <sentence>The corpus-based CDGs were created by extracting the allowable grammar relationships from the RM
                sentences that were annotated by language experts using the SENATOR annotation tool , a CGI ( Common
                Gateway Interace ) HTML script written in GNU C++ version 2.8.1 ( White , 2000 ) .
            </sentence>
            <definiendum id="0">CGI</definiendum>
            <definiens id="0">created by extracting the allowable grammar relationships from the RM sentences that were
                annotated by language experts using the SENATOR annotation tool , a
            </definiens>
        </definition>
        <definition id="12">
            <sentence>Note that percent correct words is calculated using N-D-S and word accuracy using N N-D-S-I where
                N is the number of words , D is N the number of deletions , S is the number of substitutions , and I is
                the number of insertions .
            </sentence>
            <definiendum id="0">N</definiendum>
            <definiendum id="1">S</definiendum>
            <definiens id="0">the number of words</definiens>
            <definiens id="1">the number of substitutions</definiens>
        </definition>
        <definition id="13">
            <sentence>RVs 19.51 ( 8.32 ) 19.93 ( 8.76 ) 20.32 ( 8.86 ) 20.77 ( 9.47 ) 21.43 ( 10.49 ) 21.81 ( 11.17 )
                23.41 ( 12.72 ) 24.47 ( 14.41 ) 22.79 ( 13.44 ) 22.95 ( 13.34 ) 32.85 ( 34.65 ) 33.36 ( 35.66 ) 77.19 (
                76.26 ) Table 3 : Average parse times ( SD ) , number of paths ( SD ) , number of nodes ( SD ) , and
                number of role values ( SD ) remaining after parsing the 1,080 word graphs of 50 or fewer word nodes
                produced for the RM test set using the 13 CDGs .
            </sentence>
            <definiendum id="0">Average parse times</definiendum>
            <definiendum id="1">SD</definiendum>
            <definiendum id="2">SD</definiendum>
        </definition>
        <definition id="14">
            <sentence>ARVP Variation Sentence Accuracy ~o Correct Words Word Accuracy Full Mod Template Full Mod Full
                Template Full Feature Mod Template Feature Mod Feature Template Feature Direct Mod Template Direct Mod
                Direct Template Direct Conventional 91.94 % 91.57 % 91.57 % 91.20 % 90.56 % 90.19 % 90.28 % 89.91 %
                90.46 % 90.09 % 89.91 % 89.44 % 81.20 % 98.55 % 98.50 % 98.49 % 98.45 % 98.38 % 98.34 % 98,35 % 98.29 %
                98.37 % 98.32 % 98.30 % 98.25 % 97.11 % 98.19 % 98.14 % 98.11 % 98.05 % 97.95 % 97.90 % 97.91 % 97.85 %
                97.91 % 97.86 % 97.82 % 97.75 % 96.10 % Table 4 : The sentence accuracy , percent correct words , and
                word accuracy from parsing 1,080 word graphs of 50 or fewer word nodes produced for the RM test set
                using the 13 CDGs .
            </sentence>
            <definiendum id="0">Mod Template Full Mod Full Template Full Feature Mod Template Feature Mod Feature
                Template Feature Direct Mod Template Direct Mod Direct Template
            </definiendum>
        </definition>
        <definition id="15">
            <sentence>MUSE CSP : An extension to the constraint satisfaction problem .</sentence>
            <definiendum id="0">MUSE CSP</definiendum>
            <definiens id="0">An extension to the constraint satisfaction problem</definiens>
        </definition>
        <definition id="16">
            <sentence>TINA : A natural language system for spoken language applications .</sentence>
            <definiendum id="0">TINA</definiendum>
        </definition>
        <definition id="17">
            <sentence>Token passing : a simple conceptual model for connected speech recognition systems .</sentence>
            <definiendum id="0">Token passing</definiendum>
            <definiens id="0">a simple conceptual model for connected speech recognition systems</definiens>
        </definition>
    </paper>

    <paper id="1007">
    </paper>

    <paper id="2021">
        <definition id="0">
            <sentence>`` Unification-based '' Grammars ( UBGs ) can capture a wide variety of linguistically important
                syntactic and semantic constraints .
            </sentence>
            <definiendum id="0">UBGs</definiendum>
            <definiens id="0">capture a wide variety of linguistically important syntactic and semantic constraints
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Finally , note that neither Jelinek 's nor our estimation procedures require that an auxiliary or
                reference distribution Q be a prob154 ability distribution ; i.e. , it is not necessary that Q ( i2 ) -1
                , where f~ is the set of well-formed linguistic structures .
            </sentence>
            <definiendum id="0">f~</definiendum>
            <definiens id="0">the set of well-formed linguistic structures</definiens>
        </definition>
        <definition id="2">
            <sentence>f ( oj ) ( 1 ) where f ( w ) E R m is a vector of feature values , ) ~ E It m is a vector of
                adjustable feature parameters , Q is a function of w ( which Jelinek ( 1997 ) calls a reference
                distribution when it is not an indicator function ) , and ZA = fn Q ( w ) ex'f ( ~ ) dw is a
                normalization factor called the partition function .
            </sentence>
            <definiendum id="0">f ( oj )</definiendum>
            <definiendum id="1">f</definiendum>
            <definiendum id="2">Q</definiendum>
            <definiens id="0">a vector of feature values , ) ~ E It m is a vector of adjustable feature parameters
            </definiens>
            <definiens id="1">a function of w</definiens>
        </definition>
        <definition id="3">
            <sentence>For example , the class of distributions obtained by varying the parameters of a PCFG is an
                exponential family .
            </sentence>
            <definiendum id="0">PCFG</definiendum>
            <definiens id="0">an exponential family</definiens>
        </definition>
        <definition id="4">
            <sentence>Thus an SUBG is a triple ( G , f , A ) , where G is a UBG which generates a set of wellformed
                linguistic structures i2 , and f and A are vectors of feature functions and feature parameters as above
                .
            </sentence>
            <definiendum id="0">SUBG</definiendum>
            <definiens id="0">a triple ( G , f , A ) , where G is a UBG which generates a set of wellformed linguistic
                structures i2 , and f
            </definiens>
        </definition>
        <definition id="5">
            <sentence>Grammar Stochastic Lexical-Functional Grammar ( SLFG ) is a stochastic extension of
                LexicalFunctional Grammar ( LFG ) , a UBG formalism developed by Kaplan and Bresnan ( 1982 ) .
            </sentence>
            <definiendum id="0">Grammar Stochastic Lexical-Functional Grammar ( SLFG )</definiendum>
            <definiens id="0">a stochastic extension of LexicalFunctional Grammar ( LFG ) , a UBG formalism developed by
                Kaplan and Bresnan ( 1982 )
            </definiens>
        </definition>
        <definition id="6">
            <sentence>unification-based grammars Suppose ~ = Wl , ... , Wn is a corpus of n syntactic structures .
            </sentence>
            <definiendum id="0">Wn</definiendum>
            <definiens id="0">a corpus of n syntactic structures</definiens>
        </definition>
        <definition id="7">
            <sentence>Letting fj ( fJ ) = ~ -- ~=1 fj ( oJi ) and assuming each wi E 12 , the likelihood of the corpus
                L~ ( &amp; ) is : T~ L~ ( ~ ) = 1-I Px ( w , ) i=1 = e ~/ ( c~ ) Z-~ n ( 2 ) 0 logan ( &amp; ) = fj ( Co
                ) -nEa ( fj ) ( 3 ) 0Aj where E~ ( fj ) is the expected value of f~ under the distribution P~ .
            </sentence>
            <definiendum id="0">E~ ( fj )</definiendum>
            <definiens id="0">the expected value of f~ under the distribution P~</definiens>
        </definition>
        <definition id="8">
            <sentence>However , Johnson et al. observe that parsing applications require only the conditional
                probability distribution P~ ( wly ) , where y is the terminal string or yield being parsed , and that
                this can be estimated by maximizing the pseudolikelihood of the corpus PL~ ( SJ ) : rz PLx ( SJ ) = II
                P~ ( wilyi ) i=-I n = eA'f ( w ) ~I Z ; l ( yi ) i=1 In ( 4 ) , Yi is the yield of wi and Z~ ( yi ) = f~
                ( y , ) e~I ( ~ ) dw , ( 4 ) where f~ ( Yi ) is the set of all syntactic structures in f~ with yield yi
                ( i.e. , all parses of Yi generated by the base UBG ) .
            </sentence>
            <definiendum id="0">conditional probability distribution P~</definiendum>
            <definiendum id="1">y</definiendum>
            <definiendum id="2">Yi</definiendum>
            <definiendum id="3">) e~I</definiendum>
            <definiendum id="4">UBG</definiendum>
            <definiens id="0">the terminal string or yield being parsed , and that this can be estimated by maximizing
                the pseudolikelihood of the corpus PL~ ( SJ ) : rz PLx ( SJ ) = II P~ ( wilyi ) i=-I n = eA'f ( w ) ~I Z
            </definiens>
            <definiens id="1">the yield of wi and Z~ ( yi ) = f~ ( y ,</definiens>
            <definiens id="2">the set of all syntactic structures in f~ with yield yi ( i.e. , all parses of Yi
                generated by the base
            </definiens>
        </definition>
        <definition id="9">
            <sentence>Comparing ( 6 ) with ( 1 ) on page 2 , we see that the two equations become identical if the
                reference distribution Q in ( 1 ) is replaced by a geometric mixture of the auxiliary distributions Qj ,
                i.e. , if : k Q ( w ) = ~I Q~ ( w ) xm+ij=l The parameter associated with an auxiliary feature
                represents the weight of that feature in the mixture .
            </sentence>
            <definiendum id="0">auxiliary feature</definiendum>
            <definiens id="0">represents the weight of that feature in the mixture</definiens>
        </definition>
        <definition id="10">
            <sentence>We set fc ( w ) to be the number of tuples in w , i.e. : fc ( w ) = Z n ( g , r , a ) ( w ) • ( g
                , r , a ) Then we set .
            </sentence>
            <definiendum id="0">fc ( w )</definiendum>
            <definiens id="0">the number of tuples in w</definiens>
        </definition>
        <definition id="11">
            <sentence>The pseudolikelihood measure is the pseudo-likelihood of test set parses ; i.e. , the conditional
                probability of the test parses given their yields .
            </sentence>
            <definiendum id="0">pseudolikelihood measure</definiendum>
            <definiens id="0">the pseudo-likelihood of test set parses</definiens>
        </definition>
        <definition id="12">
            <sentence>Lexical-Functional Grammar : A formal system for grammatical representation .</sentence>
            <definiendum id="0">Lexical-Functional Grammar</definiendum>
            <definiens id="0">A formal system for grammatical representation</definiens>
        </definition>
    </paper>

    <paper id="1046">
        <definition id="0">
            <sentence>333 QuickSet is a multimodal ( pen/voice ) interface for map-based tasks .</sentence>
            <definiendum id="0">QuickSet</definiendum>
            <definiens id="0">a multimodal ( pen/voice</definiens>
        </definition>
        <definition id="1">
            <sentence>In response , QuickSet creates the appropriate military icon on its map and asks for confirmation
                .
            </sentence>
            <definiendum id="0">QuickSet</definiendum>
            <definiens id="0">creates the appropriate military icon on its map and asks for confirmation</definiens>
        </definition>
        <definition id="2">
            <sentence>Moore , R. , Dowding , J. , Bratt , H. , Gawron , J. , Gorfu , Y. , Cheyer , A. , CommandTalk : A
                Spoken-Language Interface for Battlefield Simulations , Proc .
            </sentence>
            <definiendum id="0">CommandTalk</definiendum>
        </definition>
    </paper>

    <paper id="1029">
        <definition id="0">
            <sentence>The above algorithm for grammar modification has a time complexity of O ( m*2 k ) rule creation (
                or modification ) steps for removing a counterexample , where m is the number of production rules in the
                parse tree of the counter-example and k is the largest number of non-terminals on the right hand side of
                any of these production 212 rules .
            </sentence>
            <definiendum id="0">m</definiendum>
            <definiendum id="1">k</definiendum>
            <definiens id="0">the largest number of non-terminals on the right hand side of any of these production 212
                rules
            </definiens>
        </definition>
        <definition id="1">
            <sentence>The MDL principle ( Rissanen ( 1982 ) ) selects that description ( theory ) of data , which
                minimizes the sum of the length , in bits , of the description of the theory , and the length , in bits
                , of data when encoded using the theory .
            </sentence>
            <definiendum id="0">MDL principle</definiendum>
            <definiens id="0">selects that description ( theory ) of data , which minimizes the sum of the length , in
                bits , of the description of the theory
            </definiens>
        </definition>
        <definition id="2">
            <sentence>A grammar developer ( a human ) interacts with the tool and either inputs counterexamples selected
                from speech recognition error logs or selects counter-examples like the ones listed above .
            </sentence>
            <definiendum id="0">grammar developer</definiendum>
            <definiens id="0">a human ) interacts with the tool and either inputs counterexamples selected from speech
                recognition
            </definiens>
        </definition>
        <definition id="3">
            <sentence>TINA : A natural language system for spoken language applications , Computational Linguistics , 18
                : p61-86 .
            </sentence>
            <definiendum id="0">TINA</definiendum>
            <definiens id="0">A natural language system for spoken language applications</definiens>
        </definition>
    </paper>

    <paper id="2006">
        <definition id="0">
            <sentence>Introduction The Princeton WordNet ( henceforth WN ) is a lexical semantic network in which the
                meanings of words are represented in terms of their conceptual and lexical relations to other words .
            </sentence>
            <definiendum id="0">Princeton WordNet</definiendum>
            <definiens id="0">a lexical semantic network in which the meanings of words are represented in terms of
                their conceptual and lexical relations to other words
            </definiens>
        </definition>
        <definition id="1">
            <sentence>The links among the wordnets of different languages were realized by means of an
                Interlingual-Index ( ILI ) , constituted by an unstructured list of the Princeton WN ( version
                language-independent concepts , reflecting fundamental semantic distinctions ( e.g. , Object and
                Substance , Dynamic and Static , Cause , Manner , etc. ) , was built : the Top Ontology ( TO ) .
            </sentence>
            <definiendum id="0">ILI</definiendum>
            <definiendum id="1">Princeton WN ( version language-independent concepts</definiendum>
        </definition>
        <definition id="2">
            <sentence>The TO consists of language-independent features which may ( or may not ) be lexicalized in
                various ways , or according to different patterns , in different languages ( Rodriguez et al. 1998 ) .
            </sentence>
            <definiendum id="0">TO</definiendum>
        </definition>
        <definition id="3">
            <sentence>Synonymy is the basic relation encoded for all the PoSs ( since it is used to build synsets ) .
            </sentence>
            <definiendum id="0">Synonymy</definiendum>
            <definiens id="0">the basic relation encoded for all the PoSs ( since it is used to build synsets )
            </definiens>
        </definition>
        <definition id="4">
            <sentence>: GRAD ANTONYMY COMP ANTONYMY HYPONYMY PERTAINS TO IS A VALUE_OF INVOLVED CAUSE LIABLE_TO adj/adj
                adj/adj adj/adj adj/noun adj/noun adj/noun adj/verb ; adj/noun adj/verb ; adj/noun beautiful/u~ly
                alive/dead watery/containing chemical/chemistry tail/stature dental/tooth depurative/ to depurate
                triable/to judge In the EWN TO all the entities belonging to the 2 nd order have been organized into two
                different classification schemes , which represent the first division below 2 nd Order Entity : •
                Situation Type : the event-structure or Aktionsart ( or lexical aspect ) of a situation ; • Situation
                Components : the most salient semantic components that characterize situations .
            </sentence>
            <definiendum id="0">GRAD ANTONYMY COMP ANTONYMY HYPONYMY PERTAINS TO</definiendum>
            <definiens id="0">the event-structure or Aktionsart ( or lexical aspect ) of a situation ; • Situation
                Components : the most salient semantic components that characterize situations
            </definiens>
        </definition>
        <definition id="5">
            <sentence>The Situation Types provide a classification of 2oes in terms of the event-structure ( or
                Aktionsart ) of the situation they refer to : a basic distinction was drawn between Static and Dynamic .
            </sentence>
            <definiendum id="0">Aktionsart</definiendum>
            <definiens id="0">a basic distinction was drawn between Static and Dynamic</definiens>
        </definition>
        <definition id="6">
            <sentence>ItalWordNet : a Large Semantic Database for Italian .</sentence>
            <definiendum id="0">ItalWordNet</definiendum>
            <definiens id="0">a Large Semantic Database for Italian</definiens>
        </definition>
        <definition id="7">
            <sentence>Miller G. , Beckwith R. , Fellbaum C. , Gross D. , Miller K.J ( 1990 ) Introduction to WordNet :
                An Online Lexical Database .
            </sentence>
            <definiendum id="0">WordNet</definiendum>
        </definition>
    </paper>

    <paper id="1006">
        <definition id="0">
            <sentence>The source pattern consists of variables and constituent boundaries ( Furuse and Iida , 1996 ) .
            </sentence>
            <definiendum id="0">source pattern</definiendum>
            <definiens id="0">consists of variables and constituent boundaries</definiens>
        </definition>
        <definition id="1">
            <sentence>The target pattern consists of variables that correspond to variables in the source pattern and
                words of the target language .
            </sentence>
            <definiendum id="0">target pattern</definiendum>
            <definiens id="0">consists of variables that correspond to variables in the source pattern and words of the
                target language
            </definiens>
        </definition>
        <definition id="2">
            <sentence>The source example consists of words that come from utterances referred to when a person creates
                transfer rules ( we call such utterances closed utterances ) .
            </sentence>
            <definiendum id="0">source example</definiendum>
            <definiens id="0">consists of words that come from utterances referred to when a person creates transfer
                rules ( we call such utterances closed utterances )
            </definiens>
        </definition>
        <definition id="3">
            <sentence>( X ( V-CN ) Y ) Figure 8 : Transfer rule example with a participant 's role ( ( ( `` p a y m e n
                t `` ) -- ~ ( `` oshiharai '' ) : s-role clerk ( `` payment '' ) -- -* ( `` shiharai '' ) ) ( ( `` we ''
                ) -- * ( `` w a t a s h i d o m o `` ) : s-role clerk ( `` we '' ) -- ~ ( `` watashltachi '' ) ) )
                Figure 9 : Transfer dictionary example with a speaker 's role Even though we do not have rules and
                entries for pattern conditions and word conditions according to another participant 's information ,
                such as `` : s-role customer ' ( which means the speaker 's role is a customer ) and `` : s-gender male
                '' ( which means the speaker 's gender is male ) , T D M T can translate expressions corresponding to
                this information too .
            </sentence>
            <definiendum id="0">X</definiendum>
            <definiens id="0">a customer ) and `` : s-gender male '' ( which means the speaker 's gender is male )
            </definiens>
        </definition>
        <definition id="4">
            <sentence>The evaluation criteria are recall and precision , which are defined as follows : Recall = number
                of utterances whose impression is better number of utterances which should be more polite 41 Eng :
                Standard : Clerk : Customer : Gloss : Very good , please let me confirm them wakarimasita
                shouchiitashimasita soredekekkoudesu very good kakunin kakunin kakunin let me kudasai itadakimasu
                kudasai please Table 3 : Evaluation on using the speaker 's role Impression The number Necessity ~ of
                utterances of change Yes better 68 same 5 ( lo4 ) worse 3 no-diff 28 better No 0 s alTle 3 ( 166 ) worse
                0 no-diff 163 b e t t e r : Impression of a translation is better .
            </sentence>
            <definiendum id="0">precision</definiendum>
            <definiens id="0">follows : Recall = number of utterances whose impression is better number of utterances
                which should be more polite 41 Eng : Standard : Clerk : Customer : Gloss : Very good , please let me
                confirm them wakarimasita shouchiitashimasita soredekekkoudesu very good kakunin kakunin kakunin let me
                kudasai itadakimasu kudasai please Table 3 : Evaluation on using the speaker 's role Impression The
                number Necessity ~ of utterances of change Yes better 68 same 5 ( lo4 ) worse 3 no-diff 28 better No 0 s
                alTle 3 ( 166 ) worse 0 no-diff 163 b e t t e r : Impression of a translation is better
            </definiens>
        </definition>
    </paper>

    <paper id="2028">
        <definition id="0">
            <sentence>Research prototypes exist for applications such as personal email and calendars , travel and
                restaurant information , and personal banking ( Baggia et al. , 1998 ; Walker et al. , 1998 ; Seneff et
                al. , 1995 ; Sanderman et al. , 1998 ; Chu-Carroll and Carpenter , 1999 ) inter alia .
            </sentence>
            <definiendum id="0">Research prototypes</definiendum>
            <definiens id="0">exist for applications such as personal email and calendars , travel and restaurant
                information
            </definiens>
        </definition>
        <definition id="1">
            <sentence>The natural language understanding ( NLU ) module takes as input a transcription of the user 's
                utterance from ASR and produces 15 confidence scores representing the likelihood that the caller 's task
                is one of the 15 task types .
            </sentence>
            <definiendum id="0">NLU</definiendum>
            <definiens id="0">input a transcription of the user 's utterance from ASR and produces 15 confidence scores
                representing the likelihood that the caller 's task is one of the 15 task types
            </definiens>
        </definition>
        <definition id="2">
            <sentence>Learning optimal dialogue strategies : A ease study of a spoken dialogue agent for email .
            </sentence>
            <definiendum id="0">Learning optimal dialogue strategies</definiendum>
            <definiens id="0">A ease study of a spoken dialogue agent for email</definiens>
        </definition>
    </paper>

    <paper id="1031">
        <definition id="0">
            <sentence>Trigrams'n'Tags ( TnT ) is an efficient statistical part-of-speech tagger .</sentence>
            <definiendum id="0">Trigrams'n'Tags</definiendum>
            <definiendum id="1">TnT )</definiendum>
            <definiens id="0">an efficient statistical part-of-speech tagger</definiens>
        </definition>
        <definition id="1">
            <sentence>N is the total number of tokens in the training corpus .</sentence>
            <definiendum id="0">N</definiendum>
            <definiens id="0">the total number of tokens in the training corpus</definiens>
        </definition>
        <definition id="2">
            <sentence>The recursiou formula is P ( tll , _i+l , . . . ln ) = P ( tlln-i+l , ... In ) + OiP ( tll~- , ...
                , ln ) ( 7 ) 1 +0~ 225 set ) % 1 -- - ) % 2 = ) % 3 = 0 foreach trigram tl , t2 , t3 with f ( tl , t2 ,
                t3 ) &gt; 0 depending on the maximum of the following three values : f ( tl , t2 , ts ) -1 case f ( h ,
                t2 ) -I `` increment ) % 3 by f ( tl , t2 , t3 ) f ( t2 , t3 ) -I case f ( t2 ) -I `` increment ) % 2 by
                f ( tl , t2 , ts ) f ( t3 ) -- i case N-1 `` increment ) % 1 by f ( tl , t2 , t3 ) end end normalize ) %
                1 , ) % 2 , ) % 3 Figure 1 : Algorithm for calculting the weights for context-independent linear
                interpolation ) % 1 , ) % 2 , ) % 3 when the n-gram frequencies are known .
            </sentence>
            <definiendum id="0">t2 , t3 ) f</definiendum>
            <definiens id="0">tl , t2 , ts ) f ( t3 ) -- i case N-1 `` increment ) % 1 by f ( tl</definiens>
        </definition>
        <definition id="3">
            <sentence>Tags are usually not informative about capitalization , but probability distributions of tags
                around capitalized words are different from those not capitalized .
            </sentence>
            <definiendum id="0">Tags</definiendum>
            <definiens id="0">informative about capitalization , but probability distributions of tags around
                capitalized words are different from those not capitalized
            </definiens>
        </definition>
        <definition id="4">
            <sentence>The German NEGRA corpus consists of 20,000 sentences ( 355,000 tokens ) of newspaper texts (
                Frankfurter Rundschau ) that are annotated with parts-ofspeech and predicate-argument structures ( Skut
                et al. , 1997 ) .
            </sentence>
            <definiendum id="0">German NEGRA corpus</definiendum>
        </definition>
        <definition id="5">
            <sentence>The annotation consists of four parts : 1 ) a context-free structure augmented with traces to mark
                movement and discontinuous constituents , 2 ) phrasal categories that are annotated as node labels , 3 )
                a small set of grammatical functions that are annotated as extensions to the node labels , and 4 )
                part-of-speech tags ( Marcus et al. , 1993 ) .
            </sentence>
            <definiendum id="0">annotation</definiendum>
        </definition>
        <definition id="6">
            <sentence>Mbt : A memory-based part of speech tagger-generator .</sentence>
            <definiendum id="0">Mbt</definiendum>
            <definiens id="0">A memory-based part of speech tagger-generator</definiens>
        </definition>
    </paper>

    <paper id="2023">
        <definition id="0">
            <sentence>The task of sentence generation involves mapping from an abstract representation of meaning or
                syntax to a linear ordering of words .
            </sentence>
            <definiendum id="0">sentence generation</definiendum>
            <definiens id="0">involves mapping from an abstract representation of meaning or syntax to a linear ordering
                of words
            </definiens>
        </definition>
        <definition id="1">
            <sentence>A lattice is a graph where each arc is labeled with a word .</sentence>
            <definiendum id="0">lattice</definiendum>
            <definiens id="0">a graph where each arc is labeled with a word</definiens>
        </definition>
        <definition id="2">
            <sentence>The X-axis is the number of paths ( loglo scale ) , and the Y-axis is the time in seconds .
            </sentence>
            <definiendum id="0">X-axis</definiendum>
            <definiendum id="1">Y-axis</definiendum>
            <definiens id="0">the number of paths ( loglo scale ) , and the</definiens>
            <definiens id="1">the time in seconds</definiens>
        </definition>
        <definition id="3">
            <sentence>The X-axis is the number of paths ( log~o scale ) , and the Y-axis is the size in bytes .
            </sentence>
            <definiendum id="0">X-axis</definiendum>
            <definiendum id="1">Y-axis</definiendum>
            <definiens id="0">the number of paths ( log~o scale ) , and the</definiens>
            <definiens id="1">the size in bytes</definiens>
        </definition>
    </paper>

    <paper id="2030">
        <definition id="0">
            <sentence>TR builds on TE in that TR reports binary relations between elements of TE .</sentence>
            <definiendum id="0">TR</definiendum>
            <definiens id="0">builds on TE in that TR reports binary relations between elements of TE</definiens>
        </definition>
    </paper>

    <paper id="3005">
    </paper>

    <paper id="2001">
        <definition id="0">
            <sentence>In addition to this customisable notion of information state , TrindiKit provides a few system
                variables that can also used for intermodule communication .
            </sentence>
            <definiendum id="0">TrindiKit</definiendum>
            <definiens id="0">provides a few system variables that can also used for intermodule communication
            </definiens>
        </definition>
        <definition id="1">
            <sentence>The DME performs the processing needed to integrate the observed dialogue moves with the IS , and
                to select new moves for the system to perform .
            </sentence>
            <definiendum id="0">DME</definiendum>
            <definiens id="0">performs the processing needed to integrate the observed dialogue moves with the IS , and
                to select new moves for the system to perform
            </definiens>
        </definition>
        <definition id="2">
            <sentence>There are also two modules outside the DME proper , but still crucial to a complete system :
                INTERPRETATION , which consumes the input and produces a list of dialogue acts in the latest_moves
                variable ( potentially making reference to the current information state ) , and GENERATION , which
                produces NL output from the dialogue acts in the next_moves variable .
            </sentence>
            <definiendum id="0">INTERPRETATION</definiendum>
            <definiendum id="1">GENERATION</definiendum>
            <definiens id="0">consumes the input and produces a list of dialogue acts in the latest_moves variable (
                potentially making reference to the current information state
            </definiens>
        </definition>
        <definition id="3">
            <sentence>GND contains the information that has already been grounded ; the other fields contain information
                about the contributions still to be grounded .
            </sentence>
            <definiendum id="0">GND</definiendum>
            <definiens id="0">contains the information that has already been grounded ; the other fields contain
                information about the contributions still to be grounded
            </definiens>
        </definition>
        <definition id="4">
            <sentence>The CDU contains the information in the latest contribution , while the PDU contains information
                from the penultimate contribution .
            </sentence>
            <definiendum id="0">CDU</definiendum>
            <definiens id="0">contains the information in the latest contribution</definiens>
        </definition>
        <definition id="5">
            <sentence>When a dialogue participant takes a turn and produces an utterance , the interpretation module
                sets the system variable latest_moves to contain a representation of the dialogue acts performed with
                the utterance .
            </sentence>
            <definiendum id="0">dialogue participant</definiendum>
            <definiens id="0">takes a turn and produces an utterance , the interpretation module sets the system
                variable latest_moves to contain a representation of the dialogue acts performed with the utterance
            </definiens>
        </definition>
        <definition id="6">
            <sentence>tognd ) effect remove ( DU1 , UDUS ) act ID:2 , agree ( DP , ID2 ) effect push ( scP , scp ( DP ,
                P ( ID2 ) ) ) act ID:2 , answer ( DP , ID2 , ID3 ) effect push ( scP , ans ( DP , Q ( ID2 ) , P ( ID2 )
                ) ) act ID:2 , assert ( DP , PROP ) effect push ( scP , sep ( DP , PROP ) ) effect push ( COND , accept
                ( o ( DP ) , ID ) -+ scp ( o ( DP ) , PROP ) ) act ID : I , assert ( DP , PROP ) effect push ( COND ,
                accept ( o ( DP ) , ID ) -~ scp ( o ( DP ) , PROP ) ) act ID:2 , check ( DP , PROP ) effect push ( OSL ,
                address ( o ( DP ) , ID ) ) effect push ( COND , agree ( o ( DP ) , ID ) -- ~ scp ( DP , PROP ) ) act
                ID:2 , direct ( DP , Act ) effect push ( OBL , address ( o ( DP ) , ID ) ) effect push ( CONI ) , accept
                ( o ( DP ) , ID ) -~ obl ( o ( DP ) , Act ) ) act ID:2 , info_request ( DP , Q ) effect push ( osL ,
                address ( o ( DP ) , ID ) ) The ack act is the only backward grounding act implemented at the moment .
            </sentence>
            <definiendum id="0">PROP ) effect push</definiendum>
            <definiendum id="1">PROP</definiendum>
            <definiendum id="2">DP ) , PROP</definiendum>
            <definiendum id="3">DP , PROP ) effect push</definiendum>
            <definiendum id="4">COND</definiendum>
            <definiendum id="5">DP</definiendum>
            <definiendum id="6">ack act</definiendum>
            <definiens id="0">o ( DP ) , ID ) ) effect push ( CONI ) , accept ( o ( DP )</definiens>
        </definition>
        <definition id="7">
            <sentence>The main effect of an ack is to merge the information in the acknowledged DU ( assumed to be PDU )
                into GND , also removing this DU from UDUS .
            </sentence>
            <definiendum id="0">main effect of an ack</definiendum>
            <definiens id="0">to merge the information in the acknowledged DU ( assumed to be PDU ) into GND</definiens>
        </definition>
        <definition id="8">
            <sentence>add an intention to acknowledge ( W , CDU ) , given an obligation to perform a u-act , if
                everything in CDU is sufficiently understood ( i.e. , to level 2 ) ; swer a question as the result of an
                obligation to address a dialogue act ; COND contains a conditional that will establish an obligation to
                perform the action , and the antecedent of this conditional is another action that is already intended .
            </sentence>
            <definiendum id="0">COND</definiendum>
            <definiens id="0">contains a conditional that will establish an obligation to perform the action</definiens>
        </definition>
    </paper>

    <paper id="2005">
        <definition id="0">
            <sentence>Algorithm : Bagging A Parser ( 2 ) Given : A corpus ( again as a function ) C : S×T ~ N , S is the
                set of possible sentences , and T is the set of trees , with size m = \ [ C\ ] = ~s , t C ( s , t ) and
                parser induction algorithm g. containing m samples of ( s , t ) pairs randomly 34 picked from the domain
                of C according to the distribution D ( s , t ) = C ( s , t ) /\ ] C\ ] .
            </sentence>
            <definiendum id="0">S</definiendum>
            <definiendum id="1">T</definiendum>
            <definiens id="0">A corpus ( again as a function</definiens>
            <definiens id="1">the set of possible sentences , and</definiens>
            <definiens id="2">the set of trees , with size m</definiens>
        </definition>
        <definition id="1">
            <sentence>Each bootstrap replicate is a bag of samples , where each sample in a bag is drawn randomly with
                replacement from the bag corresponding to C. the collection of hypotheses ti = fi ( Stest ) using the
                unweighted constituent voting scheme of Henderson and Brill ( 1999 ) .
            </sentence>
            <definiendum id="0">bootstrap replicate</definiendum>
            <definiens id="0">a bag of samples , where each sample in a bag is drawn randomly with replacement from the
                bag corresponding to C. the collection of hypotheses ti
            </definiens>
        </definition>
        <definition id="2">
            <sentence>In the table , the Initial row shows the performance achieved when the ensemble contained only one
                bag , Final ( X ) shows the performance when the ensemble contained X bags , BestF gives the performance
                of the ensemble size that gave the best F-measure score .
            </sentence>
            <definiendum id="0">Final ( X</definiendum>
            <definiendum id="1">BestF</definiendum>
            <definiens id="0">gives the performance of the ensemble size that gave the best F-measure score</definiens>
        </definition>
        <definition id="3">
            <sentence>Let ~ ( T , c ) be a function indicating that c is in parse tree r , and ITI is the number of
                constituents in tree T. T ( s ) is the set of constituents that are found in the reference or
                hypothesized annotation for s. Dt+l ( i ) : 1 , cET ( si ) ing the individual constituents .
            </sentence>
            <definiendum id="0">c )</definiendum>
            <definiendum id="1">ITI</definiendum>
            <definiendum id="2">Dt+l</definiendum>
            <definiens id="0">the number of constituents in tree T. T ( s ) is the set of constituents that are found in
                the reference or hypothesized annotation for s.
            </definiens>
        </definition>
        <definition id="4">
            <sentence>Inconsistent annotations are those that appear plausible in isolation , but which conflict with
                annotation decisions made elsewhere in the corpus .
            </sentence>
            <definiendum id="0">Inconsistent annotations</definiendum>
            <definiens id="0">those that appear plausible in isolation , but which conflict with annotation decisions
                made elsewhere in the corpus
            </definiens>
        </definition>
        <definition id="5">
            <sentence>Boostexter : A boosting-based system for text categorization .</sentence>
            <definiendum id="0">Boostexter</definiendum>
            <definiens id="0">A boosting-based system for text categorization</definiens>
        </definition>
    </paper>

    <paper id="1044">
        <definition id="0">
            <sentence>The real-world challenge , however , is pointed out in Palmer and Day ( 1997 ) : `` It is also
                unknown how the existing high-scoring systems would perform on less well-behaved texts , such as
                single-case texts , non-newswire texts , or text obtained via optical character recognition ( OCR ) . ''
            </sentence>
            <definiendum id="0">OCR</definiendum>
            <definiens id="0">single-case texts , non-newswire texts , or text obtained via optical character
                recognition (
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Figure 4-1 shows IdentiFinder 's performance under 4 conditions of varying word error rate ( WER )
                : images ( 2.7 % WER ) weak character language model ( 19.1 % WER ) For the second and third conditions
                , 1.3M characters of Wall Street Journal were used for 318 OCR language model training : the fourth
                condition used a much weaker character language model , which accounts for the poorer performance .
            </sentence>
            <definiendum id="0">WER )</definiendum>
            <definiens id="0">characters of Wall Street Journal were used for 318 OCR language model training : the
                fourth condition used a much weaker character language model
            </definiens>
        </definition>
        <definition id="2">
            <sentence>Once an example is in the training , IdentiFinder is able to extract it and use it in test .
            </sentence>
            <definiendum id="0">IdentiFinder</definiendum>
            <definiens id="0">able to extract it and use it in test</definiens>
        </definition>
        <definition id="3">
            <sentence>Of the four systems , IdentiFinder represents state-of-the-art performance .</sentence>
            <definiendum id="0">IdentiFinder</definiendum>
            <definiens id="0">state-of-the-art performance</definiens>
        </definition>
    </paper>

    <paper id="1009">
        <definition id="0">
            <sentence>However , we extrapolate from this theory when we use the term conceptual dependency ( tree )
                structure , which has no equivalent in MTT ( and is unrelated to Shank 's CD structures proposed in the
                1970s ) .
            </sentence>
            <definiendum id="0">conceptual dependency</definiendum>
        </definition>
    </paper>

    <paper id="2022">
        <definition id="0">
            <sentence>The body may be executed up to N times where N is the number of nodes in the smaller of the two
                feature structures .
            </sentence>
            <definiendum id="0">N</definiendum>
            <definiens id="0">the number of nodes in the smaller of the two feature structures</definiens>
        </definition>
        <definition id="1">
            <sentence>The CLE encoding , in fact , does not record the actual daughters used in building a phrase ( e.g.
                as unique references or pointers , as we do ) , but instead preserves the category information ( i.e. a
                description ) of those daughters .
            </sentence>
            <definiendum id="0">CLE encoding</definiendum>
            <definiens id="0">does not record the actual daughters used in building a phrase</definiens>
        </definition>
        <definition id="2">
            <sentence>For a newly derived edge new , packed-edge-pO tests mutual subsumption against all passive edges
                that span the same portion of the input string .
            </sentence>
            <definiendum id="0">packed-edge-pO</definiendum>
            <definiens id="0">tests mutual subsumption against all passive edges that span the same portion of the input
                string
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Eliminating all semantics ( i.e. the entire HPSG C0NT value ) , on the other hand , results in
                overgeneralisation : with less information in the feature structures we achieve the highest number of
                packings , but at the same time rules apply much more freely , resulting in a larger chart compared to
                parsing with a partial semantics ; moreover , unpacking takes longer because the parse forest now
                contains inconsistent analyses .
            </sentence>
            <definiendum id="0">Eliminating all semantics</definiendum>
            <definiens id="0">the entire HPSG C0NT value</definiens>
        </definition>
        <definition id="4">
            <sentence>9 Finally , 9There is room for further investigation here : partly for theory-internal reasons ,
                current development of the LinGO grammar is working towards a stricter separation of restrictive (
                selectional ) and constructive ( compositional ) constraints in 167 1-10 words I Passive Packed Parser
                Edges Trees no semantics partial semantics full semantics no packing 116 111 149 160 no semantics 622
                1.2 &gt; 10 partial semantics 575 1.0 words full semantics 1693 33-9 no packing 2075 99-9 I Packings CPU
                Time ( sec ) = I -D± p se I unpack 15 '' 5 4 '' 1 2 '' 6 1 '' 8 0 '' 37 \ ] 0 '' 05 12 '' 0 3 '' 6 2 ''
                4 1 '' 4 0 '' 33 1 0 '' 05 2 '' 1 0 '' 4 0 '' 2 0 '' 1 0 '' 60 0 '' 04 ... . 0 '' 44 179 '' 0 42 '' 1 23
                '' 8 26 '' 0 2 '' 37 0 '' 70 134 '' 9 35 '' 0 20 '' 6 18 '' 9 1 '' 97 0 '' 63 38 '' 3 3 '' 4 2 '' 9 3 ''
                2 29 '' 40 0 '' 56 ... . 6 '' 46 Table 2 : Contrasting various grammar restrictors on short ( top ) and
                medium-length ( bottom ) inputs ; all numbers are averaged over 1,000 items per class ; packings are ,
                from left to right : equivalence ( '- ' ) , pro ( '-~ ' ) and retroactive ( 'r ' ) packings , and the
                number of edges that were frozen ( '± ' ) .
            </sentence>
            <definiendum id="0">constructive</definiendum>
            <definiens id="0">compositional ) constraints in 167 1-10 words I Passive Packed Parser Edges Trees no
                semantics partial semantics full semantics no packing 116 111 149 160 no semantics 622 1.2 &gt; 10
                partial semantics 575 1.0 words full semantics 1693 33-9 no packing 2075 99-9 I Packings CPU Time ( sec
                ) = I -D± p se I unpack 15 '' 5 4 '' 1 2 '' 6 1 '' 8 0 '' 37 \ ] 0 '' 05 12 '' 0 3 '' 6 2 '' 4 1 '' 4 0
                '' 33 1 0 '' 05 2 '' 1 0 '' 4 0 '' 2 0 '' 1 0 '' 60 0 '' 04 ... . 0 '' 44 179 '' 0 42 '' 1 23 '' 8 26 ''
                0 2 '' 37 0 '' 70 134 '' 9 35 '' 0 20 '' 6 18 '' 9 1 '' 97 0 '' 63 38 '' 3 3 '' 4 2 '' 9 3 '' 2 29 '' 40
                0 '' 56 ... . 6 '' 46 Table 2 : Contrasting various grammar restrictors on short ( top ) and
                medium-length ( bottom ) inputs ; all numbers are averaged over 1,000 items per class ; packings are ,
                from left to right : equivalence ( '- '
            </definiens>
        </definition>
        <definition id="5">
            <sentence>All the results in Table 2 were obtained with a 'right corner ' strategy which aims to exhaust
                computation for any suffix of the input string before moving the input pointer to the left ; this is
                achieved by start ( where start means of a scoring function end -Wand end are the vertices of the
                derivation that would result from the computation , and n is the total input length ) that orders parser
                tasks in the agenda .
            </sentence>
            <definiendum id="0">n</definiendum>
            <definiens id="0">aims to exhaust computation for any suffix of the input string before moving the input
                pointer to the left
            </definiens>
            <definiens id="1">the total input length ) that orders parser tasks in the agenda</definiens>
        </definition>
    </paper>

    <paper id="1011">
        <definition id="0">
            <sentence>`` Relations '' covers what in MUC-7 are called Template Elements ( TEs ) and Template Relations (
                TRs ) .
            </sentence>
            <definiendum id="0">Relations</definiendum>
        </definition>
        <definition id="1">
            <sentence>While MUC TE 's only dealt with singular entities , REES extracts both singular and plural
                entities ( e.g. , `` five executives '' ) .
            </sentence>
            <definiendum id="0">REES</definiendum>
            <definiens id="0">extracts both singular and plural entities</definiens>
        </definition>
        <definition id="2">
            <sentence>&lt; ATTACK TARGET-AP8804160078-12 &gt; : = TYPE : CONFLICT SUBTYPE : ATTACK TARGET ATTACKER : [
                TE for `` an Iraqi warplane '' ] TARGET : [ TE for `` the frigate Stark '' ] WEAPON : [ TE for ``
                missiles '' ] TIME : `` May 17 , 1987 '' PLACE : [ TE for `` the gulf ' ] COMMENT : `` attacked ''
                Events Vehicle Vehicle departs Vehicle arrives Spacecraft launch Vehicle crash Personnel Change Hire
                Terminate contract Promote Succeed Start office Transaction Buy artifact Sell artifact Import artifact
                Export artifact Give money Business Start business Close business Make artifact Acquire company Sell
                company Sue organization Merge company Financial Currency moves up Currency moves down Stock moves up
                Stock moves down Stock market moves up Stock market moves down Stock index moves up Stock index moves
                down Conflict Kill Injure Hijack vehicle Hold hostages Attack target Fire weapon Weapon hit Invade land
                Move forces Retreat Surrender Evacuate Figure 2 : Example of Event Template Crime Sexual assault Steal
                money Seize drug Indict Arrest Try Convict Sentence Jail Political Nominate Appoint Elect Expel person
                Reach agreement Hold meeting Impose embargo Topple Family Die Marry System Architecture and Components
                Figure 3 illustrates the REES system architecture .
            </sentence>
            <definiendum id="0">CONFLICT SUBTYPE</definiendum>
            <definiendum id="1">ATTACK TARGET ATTACKER</definiendum>
            <definiens id="0">Vehicle arrives Spacecraft launch Vehicle crash Personnel Change Hire Terminate contract
                Promote Succeed Start office Transaction Buy artifact Sell artifact Import artifact Export
            </definiens>
        </definition>
        <definition id="3">
            <sentence>REES consists of three main components : a tagging component ( cf. Section 2.1 ) , a co-reference
                resolution module ( cf. Section 2.2 ) , and a template generation module ( cf. Section 2.3 ) .
            </sentence>
            <definiendum id="0">REES</definiendum>
        </definition>
        <definition id="4">
            <sentence>Subsequent pattems try to find additional arguments as well as place and time adjunct information
                for the tagged event .
            </sentence>
            <definiendum id="0">Subsequent pattems</definiendum>
            <definiens id="0">try to find additional arguments as well as place and time adjunct information for the
                tagged event
            </definiens>
        </definition>
    </paper>

    <paper id="2033">
        <definition id="0">
            <sentence>A nonterminal is left recursive if it is a proper left corner of itself ; a nonterminal is
                directly left recursive if it is a direct left corner of itself ; and a nonterminal is indirectly left
                recursive if it is left recursive , but not directly left recursive .
            </sentence>
            <definiendum id="0">nonterminal</definiendum>
            <definiens id="0">indirectly left recursive if it is left recursive , but not directly left recursive
            </definiens>
        </definition>
        <definition id="1">
            <sentence>written for CommandTalk ( Moore et al. , 1997 ) , a spoken-language interface to a military
                simulation system .
            </sentence>
            <definiendum id="0">CommandTalk</definiendum>
            <definiens id="0">a spoken-language interface to a military simulation system</definiens>
        </definition>
        <definition id="2">
            <sentence>We could eliminate replacements that are useless in removing left recursion if we could order the
                nonterminals of the grammar so that , if i &gt; j and Aj is a direct left corner of Ai , then Ai is also
                a left corner of Aj .
            </sentence>
            <definiendum id="0">Aj</definiendum>
            <definiens id="0">a direct left corner of Ai</definiens>
        </definition>
        <definition id="3">
            <sentence>In addition , since we defined the left-corner relation to be reflexive , B is a left corner of
                itself .
            </sentence>
            <definiendum id="0">B</definiendum>
            <definiens id="0">a left corner of itself</definiens>
        </definition>
        <definition id="4">
            <sentence>This transformation , which we might call `` non-left-recursion grouping '' ( NLRG ) , can be
                defined as follows : NLRG : For each left-recursive nonterminal A , let al , ... , an be all the
                expansions of A that do not have a left recursive nonterminal as the left most symbol .
            </sentence>
            <definiendum id="0">non-left-recursion grouping</definiendum>
            <definiendum id="1">NLRG</definiendum>
            <definiendum id="2">NLRG</definiendum>
            <definiens id="0">For each left-recursive nonterminal A , let al , ... , an be all the expansions of A that
                do not have a left recursive nonterminal as the left most symbol
            </definiens>
        </definition>
        <definition id="5">
            <sentence>More precisely , we can retain in the transformed grammar all the productions expanding
                nonleft-recursive nonterminals of the original grammar , and for the purposes of the LC transform , we
                can treat nomleft-recursive nonterminals as if they were terminals : terminal X is a proper left corner
                of a retained left-recursive nonterminal A in the original grammar , add A -+ XA-X to the transformed
                grammar .
            </sentence>
            <definiendum id="0">X</definiendum>
            <definiens id="0">a proper left corner of a retained left-recursive nonterminal A in the original grammar
            </definiens>
        </definition>
    </paper>

    <paper id="2024">
        <definition id="0">
            <sentence>To do this analysis , we developed an automatic system that can match a phrase in a human-written
                abstract to the corresponding phrase in the article , identifying its most likely location .
            </sentence>
            <definiendum id="0">automatic</definiendum>
            <definiens id="0">system that can match a phrase in a human-written abstract to the corresponding phrase in
                the article , identifying its most likely location
            </definiens>
        </definition>
        <definition id="1">
            <sentence>A phrase in the summary sentence is annotated as ( FNUM : SNUM actual-text ) , where FNUM is the
                sequential number of the phrase and SNUM is the number of the document sentence where the phrase comes
                from .
            </sentence>
            <definiendum id="0">FNUM</definiendum>
            <definiendum id="1">SNUM</definiendum>
            <definiens id="0">the sequential number of the phrase</definiens>
        </definition>
        <definition id="2">
            <sentence>This score is then normal182 Categories Combination Operations Add descriptions or names for
                people or organizations Aggregations Substitute incoherent phrases Substitute phrases with more general
                or specific information add description ( see Figure 5 ) add name extract common subjects or objects (
                see Figure 5 ) change one sentence to a clause add connectives ( e.g. , and or while ) add punctuations
                ( e.g. , `` ; '' ) substitute dangling anaphora substitute dangling noun phrases substitute adverbs (
                e.g. , here ) remove connectives substitute with more general information substitute with more specific
                information Mixed operations combination of any of above operations ( see Figure 2 ) Table 1 :
                Combination operations Rule 1 : IF : ( ( a person or an organization is mentioned the first time ) and (
                the full name or the full description of the person or the organization exists somewhere in the original
                article but is missing in the summary ) ) THEN '' replace the phrase with the full name plus the full
                description Rule 2 : IF : ( ( two sentences are close to each other in the original article ) and (
                their subjects refer to the same entity ) and ( at least one of the sentences is the reduced form
                resulting from sentence reduction ) ) THEN : merge the two sentences by removing the subject in the
                second sentence , and then combining it with the first sentence using connective `` and '' .
            </sentence>
            <definiendum id="0">Mixed</definiendum>
            <definiens id="0">e.g. , here ) remove connectives substitute with more general information substitute with
                more specific information
            </definiens>
            <definiens id="1">the full name or the full description of the person or the organization exists somewhere
                in the original article but is missing in the summary ) ) THEN '' replace the phrase with the full name
                plus the full description
            </definiens>
            <definiens id="2">the reduced form resulting from sentence reduction ) ) THEN : merge the two sentences by
                removing the subject in the second sentence
            </definiens>
        </definition>
    </paper>

    <paper id="2015">
        <definition id="0">
            <sentence>function words part of the chunk ( bunsetsu ) is one of the following types : Null .</sentence>
            <definiendum id="0">function words part of the chunk</definiendum>
        </definition>
        <definition id="1">
            <sentence>Roughly speaking , the first corresponds to the case where Clause2 inherently has a scope of the
                same or a broader breadth compared with that of Clause1 , while the second corresponds to the case where
                Clause2 inherently has a narrower scope compared with that of Clause1.7 A decision list ( Yarowsky ,
                1994 ) is a sorted list of the decision rules each of which decides the value of a decision D given some
                evidence E. Each decision rule in a decision list is sorted TOur modeling is slightly different from
                those of other standard approaches to statistical dependency analysis ( Collins , 1996 ; Fujio and
                Matsumoto , 1998 ; Haruno et al. , 1998 ) which simply distinguish the two cases : the case where
                dependency relation holds between the given two vp chunks or clauses , and the case where dependency
                relation does not hold .
            </sentence>
            <definiendum id="0">decision list</definiendum>
            <definiens id="0">the case where dependency relation holds between the given two vp chunks or clauses , and
                the case where dependency relation does not hold
            </definiens>
        </definition>
        <definition id="2">
            <sentence>( b ) Feature Expression of Head VP Chunk of Subordinate Clauses Head VP Chunk of Subordinate
                Clause Feature Set Seg 1 : `` neage-suru-ga- , '' Se92 : `` 3 % -ha-node- , '' Feature Set ~-z = ~f
                with-comma , predicate-conjunctive-particle ( chunk-final ) , k predicate-conjunctive-particle (
                chunk-final ) - '' ga '' } ~'2 = I with-comma , chunk-final-conjugative-word-te-form } ( c )
                Evidence-Decision Pairs for Decision List Learning Evidence E ( E= 1 ) ( feature names are abbreviated )
                El with-comma I with-comma re-form with-comma , te-form with-comma ... with-comma .
            </sentence>
            <definiendum id="0">c ) Evidence-Decision</definiendum>
        </definition>
        <definition id="3">
            <sentence>More specifically , let Seg\ ] and Seg2 be the head vp chunks of the given two subordinate clauses
                ( Segl is the anterior and Seg2 is the posterior ) .
            </sentence>
            <definiendum id="0">Segl</definiendum>
            <definiendum id="1">Seg2</definiendum>
            <definiens id="0">the posterior )</definiens>
        </definition>
        <definition id="4">
            <sentence>14Coverage : the rate of the pairs of subordinate clauses whose dependencies are decided by the
                decision list , against the total pairs of subordinate clauses , Precision : the rate of the pairs of
                subordinate clauses whose dependencies are correctly decided by the decision list , against those
                covered pairs of subordinate clauses .
            </sentence>
            <definiendum id="0">Precision</definiendum>
            <definiens id="0">the rate of the pairs of subordinate clauses whose dependencies</definiens>
        </definition>
        <definition id="5">
            <sentence>Grammatical trigrams : A probabilistic model of link grammar .</sentence>
            <definiendum id="0">Grammatical trigrams</definiendum>
            <definiens id="0">A probabilistic model of link grammar</definiens>
        </definition>
        <definition id="6">
            <sentence>Decision lists for lexical ambiguity resolution : Application to accent restoration in Spanish and
                French .
            </sentence>
            <definiendum id="0">Decision lists</definiendum>
        </definition>
    </paper>

    <paper id="3003">
        <definition id="0">
            <sentence>Under these circumstances , un-nested implications ( i.e. , binary disjunctions ) are simple
                enough that the reader is likely to expect them to be reported .
            </sentence>
            <definiendum id="0">un-nested implications</definiendum>
            <definiendum id="1">binary disjunctions</definiendum>
            <definiens id="0">likely to expect them to be reported</definiens>
        </definition>
    </paper>

    <paper id="1017">
        <definition id="0">
            <sentence>The system we chose was the Caption Generation System ( CGS ) ( Mittal et al. , 1995 ; Mittal et
                al. , 1998 ) .
            </sentence>
            <definiendum id="0">Caption Generation System</definiendum>
        </definition>
        <definition id="1">
            <sentence>SemRep ) Figure 1 : The partial semantic representation of `` The second chart shows the number of
                days on the market '' As an example , consider Figure 1 , which shows a semantic representation ( SemRep
                ) from the CGS reimplementation .
            </sentence>
            <definiendum id="0">SemRep</definiendum>
            <definiens id="0">shows a semantic representation</definiens>
        </definition>
        <definition id="2">
            <sentence>The whiteboard is an active database server .</sentence>
            <definiendum id="0">whiteboard</definiendum>
            <definiens id="0">an active database server</definiens>
        </definition>
        <definition id="3">
            <sentence>CGS is a system developed at the University of Pittsburgh , which takes input from the SAGE
                graphics presentation system ( Roth et al. , 1994 ) and generates captions for the graphics SAGE
                produces .
            </sentence>
            <definiendum id="0">CGS</definiendum>
            <definiens id="0">a system developed at the University of Pittsburgh , which takes input from the SAGE
                graphics presentation system
            </definiens>
        </definition>
        <definition id="4">
            <sentence>The CGS Centering module reasons about the entities that will be referred to in each sentence and
                produces a representation which records the forward and backward-looking centers ( Grosz et al. , 1995 )
                .
            </sentence>
            <definiendum id="0">CGS Centering module</definiendum>
        </definition>
    </paper>

    <paper id="1028">
        <definition id="0">
            <sentence>The French grammar consists of 133 rule schemata , the English grammar of 8.5 rule schemata .
            </sentence>
            <definiendum id="0">French grammar</definiendum>
            <definiens id="0">consists of 133 rule schemata , the English grammar of 8.5 rule schemata</definiens>
        </definition>
        <definition id="1">
            <sentence>Samuelsson ( Samuelsson , 1994 ) proposes a technique to automatically selects what subtrees to
                retain .
            </sentence>
            <definiendum id="0">Samuelsson</definiendum>
            <definiens id="0">proposes a technique to automatically selects what subtrees to retain</definiens>
        </definition>
    </paper>

    <paper id="2042">
        <definition id="0">
            <sentence>( 5 ) RCPIAO ~-APAR ( \ [ P\ [ &gt; 2 A Vx ( P ( x ) =v 3y p ( y ) ^ x # y ^ ( R ( x , v ) v R ( V
                , x ) ) ) ) This definition only adequately characterises examples such as ( 4 ) .
            </sentence>
            <definiendum id="0">RCPIAO ~-APAR</definiendum>
            <definiendum id="1">Vx ( P</definiendum>
            <definiens id="0">( x ) =v 3y p ( y ) ^ x # y ^ ( R ( x , v ) v R ( V , x )</definiens>
        </definition>
        <definition id="1">
            <sentence>Based on these observations , the principle determining the actual logical contribution of a
                reciprocal statement can be stated as follows : Maximise Meaning Hypothesis ( MMH ) : The valid
                interpretations of a reciprocal sentence S in a context F ( where I '' includes knowledge about the
                previous discourse , the discourse situation and the world ) are those which ( a ) are consistent both
                with the IAO form of reciprocity and the information provided by F , and ( b ) whose contributions to
                the scope relation are the strongest .
            </sentence>
            <definiendum id="0">Maximise Meaning Hypothesis</definiendum>
            <definiens id="0">The valid interpretations of a reciprocal sentence S in a context F ( where I '' includes
                knowledge about the previous discourse , the discourse situation and the world
            </definiens>
        </definition>
        <definition id="2">
            <sentence>The MMH selects from the set of interpretations that are consistent with IAO and contextual
                knowledge , those that maximise the scope relation .
            </sentence>
            <definiendum id="0">MMH</definiendum>
            <definiens id="0">selects from the set of interpretations that are consistent with IAO and contextual
                knowledge , those that maximise the scope relation
            </definiens>
        </definition>
        <definition id="3">
            <sentence>b. { love ( bugs , bunny ) } As shown in ( Gardent and Konrad , To appear ) , model generators (
                i.e. , programs that compute some of the models satisfying a finite set of logical formulas ) can be
                used to provide DRT , and more generally model-theoretic approaches to natural language semantics , with
                a procedural interpretation : Given the semantic representation of a discourse and the relevant world
                knowledge ( I ) ( i.e. , a finite set of logical formulas ) , a model generator proves that ( I ) is
                satisfiable by generating some of its models .
            </sentence>
            <definiendum id="0">model generators</definiendum>
            <definiens id="0">programs that compute some of the models satisfying a finite set of logical formulas ) can
                be used to provide DRT , and more generally model-theoretic approaches to natural language semantics ,
                with a procedural interpretation : Given the semantic representation of a discourse and the relevant
                world knowledge ( I )
            </definiens>
        </definition>
        <definition id="4">
            <sentence>( 11 ) RcP =__ ) ~P ) ~R ( RCPIAo ( P ) ( R ) A VxVy ( e ( x ) A P ( y ) A x ¢ y A -~R ( x , y )
                ~=~ $ R ( x , y ) ) ) The first conjunct says that a reciprocal sentence has as weakest possible meaning
                an IAO reading .
            </sentence>
            <definiendum id="0">VxVy ( e</definiendum>
            <definiendum id="1">P ( y</definiendum>
            <definiendum id="2">-~R</definiendum>
            <definiens id="0">weakest possible meaning an IAO reading</definiens>
        </definition>
        <definition id="5">
            <sentence>Conservative minireality is a combination of local minimality and cost minimisation that correctly
                identifies the preferred interpretation of reciprocal sentences .
            </sentence>
            <definiendum id="0">Conservative minireality</definiendum>
            <definiens id="0">a combination of local minimality and cost minimisation that correctly identifies the
                preferred interpretation of reciprocal sentences
            </definiens>
        </definition>
    </paper>

    <paper id="1015">
        <definition id="0">
            <sentence>The grammars used in JAvox are based on the Java Speech Grammar Format ( JSGF ) ; JAVOX grammars
                have an additional semantic component based on our JAVOX Scripting Language ( JSL ) .
            </sentence>
            <definiendum id="0">grammars</definiendum>
            <definiendum id="1">JAVOX grammars</definiendum>
            <definiens id="0">used in JAvox are based on the Java Speech Grammar Format ( JSGF )</definiens>
        </definition>
        <definition id="1">
            <sentence>JAVOX grammars axe based on Sun 's Java Speech Grammar Format ( JSGF ) ( Sun Microsystems , Inc. ,
                1998 ) .
            </sentence>
            <definiendum id="0">JAVOX</definiendum>
        </definition>
        <definition id="2">
            <sentence>JSGF is a rule-based , speech-recognition grammar , designed to specify acceptable input to a
                recognizer .
            </sentence>
            <definiendum id="0">JSGF</definiendum>
            <definiens id="0">a rule-based , speech-recognition grammar , designed to specify acceptable input to a
                recognizer
            </definiens>
        </definition>
        <definition id="3">
            <sentence>TRANSLATOR receives the raw utterance from the recognizer and translates it into the appropriate
                semantic representation .
            </sentence>
            <definiendum id="0">TRANSLATOR</definiendum>
            <definiens id="0">receives the raw utterance from the recognizer and translates it into the appropriate
                semantic representation
            </definiens>
        </definition>
        <definition id="4">
            <sentence>Rule names are valid Java identifiers enclosed within angle brackets ; the left-hand side ( LHS )
                is everything to the left of the equality sign and the right-hand side ( RHS ) is everything to the
                right .
            </sentence>
            <definiendum id="0">left-hand side</definiendum>
            <definiendum id="1">right-hand side</definiendum>
            <definiendum id="2">RHS</definiendum>
            <definiens id="0">everything to the right</definiens>
        </definition>
        <definition id="5">
            <sentence>Syntactically , sub-rules are numbered with a series of single quotes3 : public &lt; LINE &gt; =
                make a line from &lt; POINT ' &gt; to &lt; POINT '' &gt; : ... The JAVOX Scripting Language ( JSL ) is a
                standalone programming language , developed for use with the JAVOX infrastructure .
            </sentence>
            <definiendum id="0">JAVOX Scripting Language ( JSL )</definiendum>
            <definiens id="0">a standalone programming language , developed for use with the JAVOX infrastructure
            </definiens>
        </definition>
        <definition id="6">
            <sentence>JSL supports Java 's primitive types , Java 's reference types ( objects ) , and Lisp-like lists
                .
            </sentence>
            <definiendum id="0">JSL</definiendum>
            <definiens id="0">supports Java 's primitive types , Java 's reference types ( objects ) , and Lisp-like
                lists
            </definiens>
        </definition>
        <definition id="7">
            <sentence>108 From the application 's perspective , JAVOX operates at the systems-level and sits between the
                application and the operating system ( virtual machine ) , as shown in Figure 1 .
            </sentence>
            <definiendum id="0">JAVOX</definiendum>
            <definiens id="0">operates at the systems-level and sits between the application and the operating system (
                virtual machine )
            </definiens>
        </definition>
        <definition id="8">
            <sentence>JAVOX uses reflection to ( 1 ) map from the JSL-textual representation of an object to the actual
                instance in the running program ; ( 2 ) find the appropriate j ava .
            </sentence>
            <definiendum id="0">JAVOX</definiendum>
            <definiens id="0">uses reflection to ( 1 ) map from the JSL-textual representation of an object to the
                actual instance in the running program ; ( 2 ) find the appropriate j ava
            </definiens>
        </definition>
        <definition id="9">
            <sentence>To obtain pointers to the objects , JAVOX uses JOIE , a load-time transformation tool ( Cohen et
                al. , 1998 ) .
            </sentence>
            <definiendum id="0">JAVOX</definiendum>
        </definition>
        <definition id="10">
            <sentence>JOIE allows us to modify each application class as it is loaded into the virtual machine .
            </sentence>
            <definiendum id="0">JOIE</definiendum>
            <definiens id="0">allows us to modify each application class as it is loaded into the virtual machine
            </definiens>
        </definition>
        <definition id="11">
            <sentence>The JAVOX transform adds code to every constructor in the application that registers the new
                object with Executer .
            </sentence>
            <definiendum id="0">JAVOX transform</definiendum>
            <definiens id="0">adds code to every constructor in the application that registers the new object with
                Executer
            </definiens>
        </definition>
    </paper>

    <paper id="2038">
        <definition id="0">
            <sentence>Also , the triangle inequality does not hold in all cases ; for example : p ( e , i ) = 30 and p (
                i , y ) = 10 , but p ( e , y ) = 100 , where p ( x , y ) is the penalty for aligning \ [ xl with lyl .
            </sentence>
            <definiendum id="0">p</definiendum>
            <definiens id="0">the penalty for aligning \ [ xl with lyl</definiens>
        </definition>
        <definition id="1">
            <sentence>The penalty for a substitution is defined as the Hamming distance between two feature vectors .
            </sentence>
            <definiendum id="0">penalty for a substitution</definiendum>
            <definiens id="0">the Hamming distance between two feature vectors</definiens>
        </definition>
        <definition id="2">
            <sentence>One solution is to use an affine function of the form gap ( x ) = r + sx , where r is the penalty
                for the introduction of a gap , and s is the penalty for each symbol in the gap .
            </sentence>
            <definiendum id="0">r</definiendum>
            <definiendum id="1">s</definiendum>
            <definiens id="0">the penalty for each symbol in the gap</definiens>
        </definition>
        <definition id="3">
            <sentence>Cvwt determines the relative weight of consonants and vowels .</sentence>
            <definiendum id="0">Cvwt</definiendum>
        </definition>
        <definition id="4">
            <sentence>The diff function returns the difference between segments p and q for a given feature f. Set Rv
                contains features relevant for comparing two vowels : Syllabic , Nasal , Retroflex , High , Back , Round
                , and Long .
            </sentence>
            <definiendum id="0">diff function</definiendum>
            <definiens id="0">returns the difference between segments p and q for a given feature f. Set Rv contains
                features relevant for comparing two vowels : Syllabic , Nasal , Retroflex , High
            </definiens>
        </definition>
        <definition id="5">
            <sentence>ALINE represents phonetic segments as vectors of feature values .</sentence>
            <definiendum id="0">ALINE</definiendum>
            <definiens id="0">represents phonetic segments as vectors of feature values</definiens>
        </definition>
    </paper>

    <paper id="1013">
        <definition id="0">
            <sentence>Since they can be difficult to detect , DP is a useful tool for questionnaire designer .
            </sentence>
            <definiendum id="0">DP</definiendum>
            <definiens id="0">a useful tool for questionnaire designer</definiens>
        </definition>
        <definition id="1">
            <sentence>The detector for presuppositions ( DP ) is part of the computer tool QUAID ( Graesser ,
                WiemerHastings , Kreuz , Wiemer-Hastings &amp; Marquis , in press ) , which helps survey methodologists
                design questions that are easy to process .
            </sentence>
            <definiendum id="0">detector for presuppositions</definiendum>
            <definiens id="0">helps survey methodologists design questions that are easy to process</definiens>
        </definition>
        <definition id="2">
            <sentence>DP uses the expressions in the right column in Table 2 , selected in accordance with the
                indicators , and fills them into the brackets in its output ( see Figure 1 ) .
            </sentence>
            <definiendum id="0">DP</definiendum>
        </definition>
        <definition id="3">
            <sentence>The recall rate indicates how many presuppositions DP detects out of the presuppositions reported
                by the human rating criterion ( computed as hits , divided by the sum of hits and misses ) .
            </sentence>
            <definiendum id="0">recall rate</definiendum>
            <definiens id="0">indicates how many presuppositions DP detects out of the presuppositions reported by the
                human rating criterion ( computed as hits , divided by the sum of hits and misses )
            </definiens>
        </definition>
        <definition id="4">
            <sentence>The precision score ( computed as hits , divided by the sum of hits and false alarms ) measures
                how many presuppositions reported by DP are actually present , as reported by the human ratings .
            </sentence>
            <definiendum id="0">precision score</definiendum>
            <definiens id="0">computed as hits , divided by the sum of hits and false alarms</definiens>
        </definition>
        <definition id="5">
            <sentence>Thus , the updated DP is an improvement over the first version .</sentence>
            <definiendum id="0">DP</definiendum>
            <definiens id="0">an improvement over the first version</definiens>
        </definition>
        <definition id="6">
            <sentence>CI uses a semantic network that represents an entity in the discourse focus ( such as `` this
                person '' ) through higher activations of its links to other concept nodes .
            </sentence>
            <definiendum id="0">CI</definiendum>
            <definiens id="0">uses a semantic network that represents an entity in the discourse focus</definiens>
        </definition>
        <definition id="7">
            <sentence>LSA measures the semantic similarity of text units ( such as questions ) by computing vector
                cosines .
            </sentence>
            <definiendum id="0">LSA</definiendum>
            <definiens id="0">measures the semantic similarity of text units ( such as questions ) by computing vector
                cosines
            </definiens>
        </definition>
        <definition id="8">
            <sentence>, Answering questions : Methods of determining cognitive and communicative processes in survey
                research ( pp .
            </sentence>
            <definiendum id="0">Answering questions</definiendum>
            <definiens id="0">Methods of determining cognitive and communicative processes in survey research ( pp
            </definiens>
        </definition>
    </paper>

    <paper id="3006">
        <definition id="0">
            <sentence>It is implemented as a confusion matrix , which associates a probability with each input/output
                character pair , representing the probability of the input character being replaced by the output
                character .
            </sentence>
            <definiendum id="0">confusion matrix</definiendum>
            <definiens id="0">associates a probability with each input/output character pair , representing the
                probability of the input character being replaced by the output character
            </definiens>
        </definition>
    </paper>

    <paper id="2040">
        <definition id="0">
            <sentence>Gerdemann and van Noord ( 1999 ) implement leftmost longest-match replacement in FSA as the
                operator replace ( Target , LeftContext , RightContext ) , where Target is a transducer defining the
                actual replacement , and LeftContext and RightContext are regular expressions defining the leftand
                rightcontext of the rule , respectively .
            </sentence>
            <definiendum id="0">Target</definiendum>
            <definiens id="0">a transducer defining the actual replacement , and LeftContext and RightContext are
                regular expressions defining the leftand rightcontext of the rule
            </definiens>
        </definition>
        <definition id="1">
            <sentence>The final step ( clean_up ) removes all markers .</sentence>
            <definiendum id="0">clean_up</definiendum>
        </definition>
        <definition id="2">
            <sentence>Segmentation attaches the marker '- ' to each grapheme .</sentence>
            <definiendum id="0">Segmentation</definiendum>
            <definiens id="0">attaches the marker '- ' to each grapheme</definiens>
        </definition>
        <definition id="3">
            <sentence>For the alignment between graphemes ( and , idiWord aalbessen ( currants ) GR aa1be sse nsP a + 1b
                @ + s + ~ @ + cp a 1 b E s @ Figure 3 : Alignment rectly , the system output ) and the correct phoneme
                strings ( as found in Celex ) , we used the 'handseeded ' probabilistic alignment procedure described by
                Black et al. ( 1998 ) ~ .
            </sentence>
            <definiendum id="0">idiWord aalbessen</definiendum>
            <definiens id="0">Alignment rectly , the system output</definiens>
        </definition>
    </paper>

    <paper id="2039">
        <definition id="0">
            <sentence>Reduplication , a central instance of prosodic morphology , is particularly challenging for
                state-ofthe-art computational morphology , since it involves copying of some part of a phonological
                string .
            </sentence>
            <definiendum id="0">Reduplication</definiendum>
            <definiens id="0">involves copying of some part of a phonological string</definiens>
        </definition>
        <definition id="1">
            <sentence>This gives us a segment-independent handle on those edges and a regular expression seg : l seg :
                o* seg : l for the whole synchronized portion ( seg abbreviates the set of phonological segments ) .
            </sentence>
            <definiendum id="0">seg</definiendum>
            <definiens id="0">abbreviates the set of phonological segments</definiens>
        </definition>
        <definition id="2">
            <sentence>tion o , hence also for our operation of intersection ( An B = range ( identity ( A ) o identity (
                B ) ) ) .
            </sentence>
            <definiendum id="0">intersection</definiendum>
            <definiens id="0">An B = range ( identity ( A ) o identity ( B ) ) )</definiens>
        </definition>
        <definition id="3">
            <sentence>FSA Utilities is a Prolog-based finite-state toolkit and extendible regular expression compiler
                .
            </sentence>
            <definiendum id="0">FSA Utilities</definiendum>
            <definiens id="0">a Prolog-based finite-state toolkit and extendible regular expression compiler</definiens>
        </definition>
        <definition id="4">
            <sentence>The main part now is the reduplicative morpheme itself ( 35 ) , which looks like a mixture of
                Bambara and Semai : the spellout of the base is followed by iterated repeats ( 36 ) to move back to its
                synchronized initial position ( 37 ) , which recall/h/is required to be consonantal .
            </sentence>
            <definiendum id="0">Semai</definiendum>
            <definiens id="0">looks like a mixture of Bambara and</definiens>
        </definition>
        <definition id="5">
            <sentence>Two-Level Morphology : A General Computational Model for Word-Form Recognition and Production .
            </sentence>
            <definiendum id="0">Two-Level Morphology</definiendum>
        </definition>
        <definition id="6">
            <sentence>FSA Utilities : A toolbox to manipulate finite-state automata .</sentence>
            <definiendum id="0">FSA Utilities</definiendum>
            <definiens id="0">A toolbox to manipulate finite-state automata</definiens>
        </definition>
    </paper>

    <paper id="1038">
        <definition id="0">
            <sentence>A controlled vocabulary term ( CVT ) is a consistently specified topic indicator that users can
                incorporate into their queries in order to retrieve documents about the corresponding topic .
            </sentence>
            <definiendum id="0">controlled vocabulary term</definiendum>
            <definiendum id="1">CVT</definiendum>
            <definiens id="0">a consistently specified topic indicator that users can incorporate into their queries in
                order to retrieve documents about the corresponding topic
            </definiens>
        </definition>
        <definition id="1">
            <sentence>The Carnegie Group 's Text Categorization Shell ( TCS ) ( Hayes , 1992 ) uses shallow knowledge
                engineering techniques to categorize documents with respect to large sets of predefined topics .
            </sentence>
            <definiendum id="0">Text Categorization Shell</definiendum>
        </definition>
        <definition id="2">
            <sentence>SRA 's NameTag ( Krupka , 1995 ) uses a pattem recognition process that combines a rule base with
                lexicons to identify and extract targeted token classes in text , such as company , people and place
                names .
            </sentence>
            <definiendum id="0">NameTag</definiendum>
            <definiens id="0">uses a pattem recognition process that combines a rule base with lexicons to identify and
                extract targeted token classes in text , such as company , people and place names
            </definiens>
        </definition>
        <definition id="3">
            <sentence>A definition includes terms to look up , term weights , term frequency thresholds , document
                selection scoring thresholds , one or more CVTs , and source-specific document structure information .
            </sentence>
            <definiendum id="0">definition</definiendum>
            <definiens id="0">includes terms to look up , term weights , term frequency thresholds , document selection
                scoring thresholds , one or more CVTs , and source-specific document structure information
            </definiens>
        </definition>
        <definition id="4">
            <sentence>A lookup step applies the table to a document and records term frequency information .</sentence>
            <definiendum id="0">lookup step</definiendum>
            <definiens id="0">applies the table to a document and records term frequency information</definiens>
        </definition>
        <definition id="5">
            <sentence>If the same term is in several definitions ( e.g. , American is a short name variant in hundreds
                of definitions ) , frequency information is recorded for each definition .
            </sentence>
            <definiendum id="0">American</definiendum>
            <definiens id="0">a short name variant in hundreds of definitions</definiens>
        </definition>
        <definition id="6">
            <sentence>Entity Indexing applies these definitions during a single pass of the data , processing more than
                86,000 characters ( approximately 16 news documents ) per CPU second .
            </sentence>
            <definiendum id="0">Entity Indexing</definiendum>
            <definiens id="0">applies these definitions during a single pass of the data , processing more than 86,000
                characters ( approximately 16 news documents ) per CPU second
            </definiens>
        </definition>
    </paper>

    <paper id="3004">
        <definition id="0">
            <sentence>We are considering the Information Extraction ( I.E. ) problem as a semantic annotation problem :
                extracting information is finding the relevant terms that contribute to describe an appropriate semantic
                structure of the text .
            </sentence>
            <definiendum id="0">Information Extraction</definiendum>
            <definiens id="0">a semantic annotation problem : extracting information is finding the relevant terms that
                contribute to describe an appropriate semantic structure of the text
            </definiens>
        </definition>
        <definition id="1">
            <sentence>For syntactic analysis , ISSCO developed a Feature Unification Grammar based on a small sample of
                the Polyphone data .
            </sentence>
            <definiendum id="0">ISSCO</definiendum>
        </definition>
        <definition id="2">
            <sentence>Fastus : a cascaded finite-state transducer for extracting information from natural-language text
                .
            </sentence>
            <definiendum id="0">Fastus</definiendum>
            <definiens id="0">a cascaded finite-state transducer for extracting information from natural-language text
            </definiens>
        </definition>
    </paper>

    <paper id="2019">
        <definition id="0">
            <sentence>ALEK has been developed using the Test of English as a Foreign Language ( TOEFL ) administered by
                the Educational Testing Service .
            </sentence>
            <definiendum id="0">ALEK</definiendum>
            <definiens id="0">developed using the Test of English as a Foreign Language ( TOEFL ) administered by the
                Educational Testing Service
            </definiens>
        </definition>
        <definition id="1">
            <sentence>corpus : The system computes mutual information comparing the proportion of observed occurrences
                of bigrams in the general corpus to the proportion expected based on the assumption of independence , as
                shown below : P ( A ) × P ( B ) ) Here , P ( AB ) is the probability of the occurrence of the AB bigram
                , estimated from its frequency in the general corpus , and P ( A ) and P ( B ) are the probabilities of
                the first and second elements of the bigram , also estimated from the general corpus .
            </sentence>
            <definiendum id="0">P ( AB )</definiendum>
            <definiendum id="1">P</definiendum>
            <definiens id="0">The system computes mutual information comparing the proportion of observed occurrences of
                bigrams in the general corpus to the proportion expected based on the assumption of independence
            </definiens>
            <definiens id="1">the probability of the occurrence of the AB bigram , estimated from its frequency in the
                general corpus
            </definiens>
        </definition>
        <definition id="2">
            <sentence>In addition to bigram and trigram measures , ALEK compares the target word 's part-ofspeech tag in
                the word-specific corpus and in the general corpus .
            </sentence>
            <definiendum id="0">ALEK</definiendum>
            <definiens id="0">compares the target word 's part-ofspeech tag in the word-specific corpus and in the
                general corpus
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Candidate errors were those local context sequences that produced a mutual information value of
                less than -3.60 based on the general corpus ; mutual information of less than -5.00 for the
                specific/general comparisons ; or a X2 value greater than 12.82 with an effect size greater than 0.30 .
            </sentence>
            <definiendum id="0">Candidate errors</definiendum>
            <definiens id="0">were those local context sequences that produced a mutual information value of less than
                -3.60 based on the general corpus ; mutual information of less than -5.00 for the specific/general
                comparisons
            </definiens>
        </definition>
        <definition id="4">
            <sentence>`` Total Recall '' is an estimate that extrapolates from the human judgements of the sample to the
                entire test set .
            </sentence>
            <definiendum id="0">Total Recall</definiendum>
            <definiens id="0">an estimate that extrapolates from the human judgements of the sample to the entire test
                set
            </definiens>
        </definition>
        <definition id="5">
            <sentence>ALEK recognizes all of these types of errors .</sentence>
            <definiendum id="0">ALEK</definiendum>
            <definiens id="0">recognizes all of these types of errors</definiens>
        </definition>
        <definition id="6">
            <sentence>ALEK is sensitive to open-class word confusions ( affect vs effect ) where the part of speech
                differs or where the target word is confused with another word ( *ln this aspect , ... instead ofln this
                respect , ... ) .
            </sentence>
            <definiendum id="0">ALEK</definiendum>
            <definiens id="0">sensitive to open-class word confusions ( affect vs effect ) where the part of speech
                differs or where the target word is confused with another word
            </definiens>
        </definition>
        <definition id="7">
            <sentence>ALEK is being developed as a diagnostic tool for students who are learning English as a foreign
                language .
            </sentence>
            <definiendum id="0">ALEK</definiendum>
            <definiens id="0">a diagnostic tool for students who are learning English as a foreign language</definiens>
        </definition>
    </paper>

    <paper id="3007">
        <definition id="0">
            <sentence>This algorithm is to be used in a cross-language information retrieval system , CINDOR , which
                indexes queries and documents in a language-neutral concept representation based on WordNet synsets .
            </sentence>
            <definiendum id="0">CINDOR</definiendum>
            <definiens id="0">to be used in a cross-language information retrieval system</definiens>
        </definition>
        <definition id="1">
            <sentence>This conceptual interlingua is a hierarchically organized multilingual concept lexicon , which is
                structured following WordNet ( Miller , 1990 ) .
            </sentence>
            <definiendum id="0">conceptual interlingua</definiendum>
            <definiens id="0">a hierarchically organized multilingual concept lexicon</definiens>
        </definition>
        <definition id="2">
            <sentence>They are calculated using following formulas : M\ [ w , Ix\ ] Po ( wilx ) -LwM\ [ wIx\ ] ( 3 )
                where wi is a stem , x is a given synset , M\ [ w\ ] \ [ x\ ] is a cell in the correlation matrix that
                corresponds to word w and synset x , and Z. , , , ,M\ [ wlx\ ] P~ ( x ) = Z , ,~w.y~rM\ [ wly \ ] ( 4 )
                where w is any stem in the collection , x is a given symet , y is any synset ever occurred in collection
                .
            </sentence>
            <definiendum id="0">wi</definiendum>
            <definiendum id="1">y</definiendum>
            <definiens id="0">a given synset</definiens>
            <definiens id="1">a cell in the correlation matrix that corresponds to word w and synset x</definiens>
        </definition>
        <definition id="3">
            <sentence>For each document d in collection read in a noun stem w from d for each synset s in which w occurs
                get the column b in the association matrix M that corresponds to s if the column already exists ; create
                a new column for s otherwise for each word stem j appearing in the 100-word window around w get the row
                a in M that corresponds to j if the row already exists ; create a new row for j otherwise add a
                distance-adjusted weight to M\ [ a\ ] \ [ b\ ] Figure 1 : WSD Algorithm : the training phase Set value =
                1 For each word w to be disambiguated get synsets of w for each synset x ofw for each wi in the context
                ofw ( within the 100-window around w ) calculate Pc ( wilx ) value *= ( 1 Pc ( wilx ) ) P ( context ( w
                ) lx ) = 1 value Calculate pc ( x ) P ( xlcontext ( w ) ) = p~ ( x ) * P ( eontext ( w ) lx ) display a
                ranked list of the synsets arranged according to their P ( xlcontext ( w ) ) in decreasing order Figure
                2 : WSD Algorithm : the sense prediction phase 37 As suggested by the WSD literature , evaluation of
                word sense disambiguation systems is not yet standardized ( Resnik and Yarowsky , 1997 ) .
            </sentence>
            <definiendum id="0">WSD Algorithm</definiendum>
            <definiens id="0">the training phase Set value = 1 For each word w to be disambiguated get synsets of w for
                each synset x ofw for each wi in the context ofw
            </definiens>
        </definition>
        <definition id="4">
            <sentence>The population consists of all the nouns in WordNet , after removal of monoseanous nouns , and
                after removal of a problematic class of polysemous nouns .
            </sentence>
            <definiendum id="0">population</definiendum>
        </definition>
        <definition id="5">
            <sentence>The training document set consists of all the documents in the AP corpus excluding the
                above-mentioned 867 documents .
            </sentence>
            <definiendum id="0">training document set</definiendum>
            <definiens id="0">consists of all the documents in the AP corpus excluding the above-mentioned 867
                documents
            </definiens>
        </definition>
        <definition id="6">
            <sentence>We have developed a WSD algorithm that uses all the words in a WordNet symet as evidence of a
                given sense and builds an association matrix to learn the co-occurrence between words and senses .
            </sentence>
            <definiendum id="0">WSD algorithm</definiendum>
            <definiens id="0">uses all the words in a WordNet symet as evidence of a given sense and builds an
                association matrix to learn the co-occurrence between words and senses
            </definiens>
        </definition>
        <definition id="7">
            <sentence>WordNet : An Electronic Lexical Database .</sentence>
            <definiendum id="0">WordNet</definiendum>
        </definition>
        <definition id="8">
            <sentence>WordNet : An On-line Lexical Database .</sentence>
            <definiendum id="0">WordNet</definiendum>
        </definition>
    </paper>

    <paper id="1027">
        <definition id="0">
            <sentence>~It is the size of POS tagged corpus currently publicized by ETRI ( Electronics and
                Telecommunications Research Institute ) project .
            </sentence>
            <definiendum id="0">~It</definiendum>
            <definiens id="0">the size of POS tagged corpus currently publicized by ETRI ( Electronics and
                Telecommunications Research Institute ) project
            </definiens>
        </definition>
        <definition id="1">
            <sentence>In other words , nouns prominent in documents can be defined as frequently occurred ones , which
                we call distinct nouns .
            </sentence>
            <definiendum id="0">nouns prominent in documents</definiendum>
        </definition>
        <definition id="2">
            <sentence>, sj ) Iq~ ( 1 ) In the formula , fq ( s~ , ... sj ) is the frequency of the syllable si ... sj ,
                which is obtained from SND constructed on the stages of lexical data extraction .
            </sentence>
            <definiendum id="0">fq</definiendum>
            <definiendum id="1">sj</definiendum>
            <definiens id="0">the frequency of the syllable si ...</definiens>
        </definition>
        <definition id="3">
            <sentence>And , fqN is the total sum of frequencies of simple nouns .</sentence>
            <definiendum id="0">fqN</definiendum>
        </definition>
        <definition id="4">
            <sentence>( 2 ) using both the built-in dictionary and the segmentation algorithm which reflects system
                accuracy as a whole .
            </sentence>
            <definiendum id="0">segmentation algorithm</definiendum>
            <definiens id="0">reflects system accuracy as a whole</definiens>
        </definition>
        <definition id="5">
            <sentence>First , we proposed the lexical acquisition for compound noun analysis , which consists of the
                manually constructed segmentation dictionary ( HBSD ) and the dictionary for applying the segmentation
                algorithm ( SND ) .
            </sentence>
            <definiendum id="0">segmentation algorithm</definiendum>
            <definiens id="0">consists of the manually constructed segmentation dictionary</definiens>
        </definition>
    </paper>

    <paper id="2034">
        <definition id="0">
            <sentence>Different diathesis alternations give different emphasis and nuances of meaning to the same basic
                content .
            </sentence>
            <definiendum id="0">Different diathesis alternations</definiendum>
            <definiens id="0">give different emphasis and nuances of meaning to the same basic content</definiens>
        </definition>
        <definition id="1">
            <sentence>To ensure the TCM covers all the word senses in WordNet , we modify Li and Abe 's original scheme
                by creating hyponym leaf classes below all WordNet 's hypernym ( internal ) classes .
            </sentence>
            <definiendum id="0">TCM</definiendum>
            <definiens id="0">covers all the word senses in WordNet</definiens>
        </definition>
        <definition id="2">
            <sentence>The minimum description length principle ( MDL ) ( Rissanen , 1978 ) is used to find the best TCM
                by consid257 ering the cost ( in bits ) of describing both the model and the argument head data encoded
                in the model .
            </sentence>
            <definiendum id="0">minimum description length principle</definiendum>
            <definiendum id="1">MDL</definiendum>
            <definiens id="0">used to find the best TCM by consid257 ering the cost ( in bits ) of describing both the
                model and the argument head data encoded in the model
            </definiens>
        </definition>
        <definition id="3">
            <sentence>1 This measure , defined in equation 2 , is a smoothed version of the Kulback-Liebler divergence ,
                pl ( x ) and p2 ( x ) are the two probability distributions which are being compared .
            </sentence>
            <definiendum id="0">pl</definiendum>
            <definiendum id="1">p2 ( x )</definiendum>
            <definiens id="0">the two probability distributions which are being compared</definiens>
        </definition>
        <definition id="4">
            <sentence>For example , if one slot contained the argument heads { person , person , person , child , man ,
                spokeswoman } , and the other slot contained { person , person , child , chair , collection } , then the
                intersection would be { person , per3 son , child } , and LO would be g. This measure ranges between
                zero ( no overlap ) and I ( where one set is a proper subset of that at the other slot ) .
            </sentence>
            <definiendum id="0">LO</definiendum>
            <definiens id="0">a proper subset of that at the other slot )</definiens>
        </definition>
        <definition id="5">
            <sentence>Selection and Information : A Class-Based Approach to Lexical Relationships .</sentence>
            <definiendum id="0">Selection</definiendum>
            <definiendum id="1">Information</definiendum>
        </definition>
    </paper>

    <paper id="2029">
    </paper>

    <paper id="1034">
        <definition id="0">
            <sentence>MaxEnt includes external gazetteers in the system .</sentence>
            <definiendum id="0">MaxEnt</definiendum>
        </definition>
        <definition id="1">
            <sentence>Introduction Named entity ( NE ) tagging is a task in which location names , person names ,
                organization names , monetary amounts , time and percentage expressions are recognized and classified in
                unformatted text documents .
            </sentence>
            <definiendum id="0">NE ) tagging</definiendum>
            <definiens id="0">a task in which location names , person names , organization names , monetary amounts ,
                time and percentage expressions are recognized and classified in unformatted text documents
            </definiens>
        </definition>
        <definition id="2">
            <sentence>MaxEnt is a powerful tool to be used in situations where several ambiguous information sources
                need to be combined .
            </sentence>
            <definiendum id="0">MaxEnt</definiendum>
        </definition>
        <definition id="3">
            <sentence>HMM generates the standard MUC tags , person , location and organization .</sentence>
            <definiendum id="0">HMM</definiendum>
            <definiens id="0">generates the standard MUC tags , person , location and organization</definiens>
        </definition>
        <definition id="4">
            <sentence>The location gazetteer consists of 250,000 location names with their categories such as CITY ,
                PROVINCE , COUNTRY , AIRPORT , etc .
            </sentence>
            <definiendum id="0">location gazetteer</definiendum>
        </definition>
        <definition id="5">
            <sentence>We first define `` LFEATURE '' based on occurrence in the location gazetteer as follows : 249
                COUNTRY USSTATE MULTITOKEN of multiple tokens ) BIGCITY in OXFD dictionary ) COEXIST ( country name ) (
                US state name ) ( a location name consisting ( a location name occurring ( where COEXIST ( A , B ) is
                true iff A and B are in the same US state , or in the same foreign country ) OTHER There is precedence
                from the first LFEATURE to the last one .
            </sentence>
            <definiendum id="0">COEXIST ( A , B )</definiendum>
            <definiens id="0">LFEATURE '' based on occurrence in the location gazetteer as follows : 249 COUNTRY USSTATE
                MULTITOKEN of multiple tokens
            </definiens>
            <definiens id="1">true iff A and B are in the same US state , or in the same foreign country</definiens>
        </definition>
        <definition id="6">
            <sentence>We also define `` NFEATURE '' based on occurrence in the name gazetteer as follows : FAMILY MALE
                FEMALE FAMILYANDMALE name ) FAMILYANDFEMALE name ) OTHER ( family name ) ( male name ) ( female name ) (
                family and male ( family and female With these two extra features , every token in the document is
                regarded as a three-component vector ( word , LFEATURE , NFEATURE ) .
            </sentence>
            <definiendum id="0">three-component vector</definiendum>
            <definiens id="0">NFEATURE '' based on occurrence in the name gazetteer as follows : FAMILY MALE FEMALE
                FAMILYANDMALE name
            </definiens>
        </definition>
        <definition id="7">
            <sentence>The resulting probability distribution ( 2 ) possesses the maximum entropy among all the
                probability distributions consistent with the constraints imposed by feature function average values .
            </sentence>
            <definiendum id="0">maximum entropy</definiendum>
            <definiens id="0">among all the probability distributions consistent with the constraints imposed by feature
                function average values
            </definiens>
        </definition>
        <definition id="8">
            <sentence>We have the following seven feature function templates : 10 if MUC_tag = _ , and tag = _ f (
                history , tag ) = else { 10 if MUC_tag = _ , LFEATURE = _ , and tag = _ f ( history , tag ) = else 1 if
                contain word ( __ ) , MUC tag ( history ) = _ , and tag = f ( history , tag ) = 0 else 10 if
                Previous_Word = _ , MUC_tag = _ , and tag = _ f ( history , tag ) = else f ( history , tag ) = { 10 if
                following_Word= _ , MUC_tag = _ , andelse tag=_ f ( history , tag ) = { lo ifMUC_tag= ,
                contain_male_name , and tag 252 = 1l if , oc_ta =_ , co. .
            </sentence>
            <definiendum id="0">MUC tag</definiendum>
            <definiens id="0">10 if MUC_tag = _ , and tag = _ f</definiens>
        </definition>
        <definition id="9">
            <sentence>MaxEnt has been demonstrated to be a viable technique for integrating diverse sources of
                information and has been used in NE sub-categorization .
            </sentence>
            <definiendum id="0">MaxEnt</definiendum>
            <definiens id="0">a viable technique for integrating diverse sources of information and has been used in NE
                sub-categorization
            </definiens>
        </definition>
        <definition id="10">
            <sentence>FASTUS : A System for Extracting Information from Text , Proceedings of the DARPA workshop on
                Human Language Technology '' , Princeton , NJ , pp .
            </sentence>
            <definiendum id="0">FASTUS</definiendum>
            <definiens id="0">A System for Extracting Information from Text</definiens>
        </definition>
    </paper>

    <paper id="2003">
        <definition id="0">
            <sentence>Co-specification-level factors depend on information about sequences of referring expressions 19
                Person Group PhysObj Concept Loc Time Event Action State Property one or more human beings
                institutionalized group of human beings physical object abstract concept geographical location date ,
                time span sth .
            </sentence>
            <definiendum id="0">Co-specification-level factors</definiendum>
            <definiens id="0">depend on information about sequences of referring expressions 19 Person Group PhysObj
                Concept Loc Time Event Action State Property one or more human beings institutionalized group of human
                beings physical object abstract concept geographical location date , time span sth
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Each MCU consists of a major clause C plus any subordinate clauses and any coordinated major
                clauses whose subject is the same as that of C and where that subject has been elided .
            </sentence>
            <definiendum id="0">MCU</definiendum>
        </definition>
        <definition id="2">
            <sentence>Dist provides the number of MCUs between the current and the last previous mention of a discourse
                entity .
            </sentence>
            <definiendum id="0">Dist</definiendum>
        </definition>
        <definition id="3">
            <sentence>Ambiguity is defined as the number of all discourse entities with the same agreement features that
                occur in the previous unit or in the same unit before the current referring expression .
            </sentence>
            <definiendum id="0">Ambiguity</definiendum>
            <definiens id="0">the number of all discourse entities with the same agreement features that occur in the
                previous unit or in the same unit before the current referring expression
            </definiens>
        </definition>
        <definition id="4">
            <sentence>WordNet : An Electronic Lexical Database .</sentence>
            <definiendum id="0">WordNet</definiendum>
        </definition>
        <definition id="5">
            <sentence>R : A language for data analysis and graphics .</sentence>
            <definiendum id="0">R</definiendum>
        </definition>
        <definition id="6">
            <sentence>EuroWordNet : A Multilingual Database with Lexical Semantic Networks .</sentence>
            <definiendum id="0">EuroWordNet</definiendum>
        </definition>
    </paper>

    <paper id="2002">
        <definition id="0">
            <sentence>Figure I presents in the style of Mann and Thompson ( 1988 ) the discourse structures of text
                fragments ( 1 ) and ( 3 ) , Each discourse structure is a tree whose leaves correspond to the edus and
                whose internal nodes correspond to contiguous text spans .
            </sentence>
            <definiendum id="0">discourse structure</definiendum>
            <definiens id="0">a tree whose leaves correspond to the edus and whose internal nodes correspond to
                contiguous text spans
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Each node is characterized by a status ( NUCLEUS or SATELLITE ) and a rhetorical relation , which
                is a relation that holds between two non-overlapping text spans .
            </sentence>
            <definiendum id="0">rhetorical relation</definiendum>
            <definiens id="0">a relation that holds between two non-overlapping text spans</definiens>
        </definition>
        <definition id="2">
            <sentence>In order to provide a better estimate of how close two discourse trees were , we computed
                PositionDependent and -Independent recall and precision figures for the sentential level ( where units
                are given by edus and spans are given by sets of edus or single sentences ) ; paragraph level ( where
                units are given by sentences and spans are given by sets of sentences or single paragraphs ) ; and text
                level ( where units are given by paragraphs and spans are given by sets of paragraphs ) .
            </sentence>
            <definiendum id="0">sentential level</definiendum>
            <definiendum id="1">paragraph level</definiendum>
            <definiendum id="2">text level</definiendum>
            <definiens id="0">where units are given by edus and spans are given by sets of edus or single sentences
            </definiens>
            <definiens id="1">where units are given by sentences and spans are given by sets of sentences or single
                paragraphs
            </definiens>
            <definiens id="2">where units are given by paragraphs and spans are given by sets of paragraphs</definiens>
        </definition>
        <definition id="3">
            <sentence>The discourse transfer module uses the C4.5 program ( Quinlan , 1993 ) in order to learn decision
                trees and rules that specify how Japanese discourse trees should be mapped into English-like trees .
            </sentence>
            <definiendum id="0">discourse transfer module</definiendum>
        </definition>
    </paper>

    <paper id="1043">
        <definition id="0">
            <sentence>The reduction process can be considered as a series of decision-making process along the edges of
                a sentence parse tree .
            </sentence>
            <definiendum id="0">reduction process</definiendum>
            <definiens id="0">a series of decision-making process along the edges of a sentence parse tree</definiens>
        </definition>
        <definition id="1">
            <sentence>A D t B E G C F H Reduced : A B D G H Figure 3 : Reduced form by a human D B E G A C F H Reduced :
                B C D Input : A B C D E F G H Figure 4 : Reduced form by the program Figure 2 : Sample sentence and
                parse tree Suppose we have an input sentence ( ABCDEFGH ) , which has a parse tree shown in Figure 2 .
            </sentence>
            <definiendum id="0">ABCDEFGH</definiendum>
            <definiens id="0">A B D G H Figure 3 : Reduced form by a human D B E G A C F H Reduced : B C D Input : A B C
                D E F G H
            </definiens>
        </definition>
        <definition id="2">
            <sentence>Introduction to WordNet : An on-line lexical database .</sentence>
            <definiendum id="0">WordNet</definiendum>
        </definition>
    </paper>

    <paper id="1033">
        <definition id="0">
            <sentence>The shallow divide-and-conquer parser ( DCPARSER ) is supported by means of powerful morphological
                processing ( including on-line compound analysis ) , efficient POS-filtering and named entity
                recognition .
            </sentence>
            <definiendum id="0">shallow divide-and-conquer parser</definiendum>
            <definiendum id="1">DCPARSER</definiendum>
            <definiens id="0">supported by means of powerful morphological processing ( including on-line compound
                analysis ) , efficient POS-filtering and named entity recognition
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Two sorts of recursion can be distinguished : 1 ) middle field ( MF ) recursion , where the
                embedded base clause is framed by the left and right verb parts of the embedding sentence , and 2 ) the
                rest field ( RF ) recursion , where the embedded clause follows the right verb part of the embedding
                sentence .
            </sentence>
            <definiendum id="0">middle field</definiendum>
            <definiens id="0">the right verb part of the embedding sentence</definiens>
        </definition>
        <definition id="2">
            <sentence>The FRAGMENT RECOGNIZER uses finite state grammars in order to extract nominal and prepositional
                phrases , where the named entities recognized by the preprocessor are integrated into appropriate places
                ( unplausibte phrases are rejected by agreement checking ; see ( Neumann et al. , 1997 ) for more 243
                details ) ) .
            </sentence>
            <definiendum id="0">FRAGMENT RECOGNIZER</definiendum>
            <definiens id="0">uses finite state grammars in order to extract nominal and prepositional phrases , where
                the named entities recognized by the preprocessor are integrated into appropriate places ( unplausibte
                phrases are rejected by agreement checking ; see ( Neumann et al. , 1997 ) for more 243 details
            </definiens>
        </definition>
        <definition id="3">
            <sentence>An UDS is a flat dependency-based structure of a sentence , where only upper bounds for attachment
                and scoping of modifiers are expressed .
            </sentence>
            <definiendum id="0">UDS</definiendum>
            <definiens id="0">a flat dependency-based structure of a sentence , where only upper bounds for attachment
                and scoping of modifiers are expressed
            </definiens>
        </definition>
    </paper>

    <paper id="1021">
        <definition id="0">
            <sentence>Question Answering is a task that calls for a combination of techniques from Information Retrieval
                and Natural Language Processing .
            </sentence>
            <definiendum id="0">Question Answering</definiendum>
        </definition>
        <definition id="1">
            <sentence>NLP tackles the semantics , but tends to be computationally expensive .</sentence>
            <definiendum id="0">NLP</definiendum>
            <definiens id="0">tackles the semantics , but tends to be computationally expensive</definiens>
        </definition>
        <definition id="2">
            <sentence>Our system ( Figure 1 ) consists of two pieces : an IR component ( GuruQA ) that which returns
                matching texts , and an answer selection compo150 neat ( AnSel/Werlect ) that extracts and ranks
                potential answers from these texts .
            </sentence>
            <definiendum id="0">Figure 1 )</definiendum>
            <definiens id="0">consists of two pieces : an IR component ( GuruQA ) that which returns matching texts
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Thus the text `` for 5 centuries '' matches the DURATIONS pattern `` for : CARDINAL _timeperiod ''
                , where : CARDINAL is the label for cardinal numbers , and _timeperiod marks a time expression .
            </sentence>
            <definiendum id="0">DURATIONS</definiendum>
            <definiendum id="1">CARDINAL</definiendum>
            <definiens id="0">the label for cardinal numbers , and _timeperiod marks a time expression</definiens>
        </definition>
        <definition id="4">
            <sentence>The output of either system consists of five text extracts per question that contain the likeliest
                answers to the questions .
            </sentence>
            <definiendum id="0">output of either system</definiendum>
        </definition>
        <definition id="5">
            <sentence>Avgdst : the average distance in words between the beginning of the span and query words that also
                appear in the passage .
            </sentence>
            <definiendum id="0">Avgdst</definiendum>
            <definiens id="0">the average distance in words between the beginning of the span and query words that also
                appear in the passage
            </definiens>
        </definition>
        <definition id="6">
            <sentence>Number : the position of the span among all retrieved spans .</sentence>
            <definiendum id="0">Number</definiendum>
            <definiens id="0">the position of the span among all retrieved spans</definiens>
        </definition>
        <definition id="7">
            <sentence>Frequency : how often the span occurs across different passages .</sentence>
            <definiendum id="0">Frequency</definiendum>
            <definiens id="0">how often the span occurs across different passages</definiens>
        </definition>
    </paper>

    <paper id="1042">
        <definition id="0">
            <sentence>We compare three shallow processing methods for identifying index terms : • Keywords ( KW ) are
                terms identified by counting frequency of stemmed words in a document ; Technical terms ( TT ) are noun
                phrases ( NPs ) or subparts of NPs repeated more than twice in a document \ [ Justeson and Katz 1995\ ]
                ; Head sorted terms ( HS ) are identified by a method in which simplex noun phrases ( as defined below )
                are sorted by head and then ranked in decreasing order of frequency \ [ Wacholder 1998\ ] .
            </sentence>
            <definiendum id="0">• Keywords</definiendum>
            <definiendum id="1">HS</definiendum>
            <definiens id="0">terms identified by counting frequency of stemmed words in a document ; Technical terms (
                TT ) are noun phrases ( NPs ) or subparts of NPs repeated more than twice in a document \ [ Justeson and
                Katz 1995\ ] ; Head sorted terms
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Luhn 's premise was that emphasis , as indicated by repetition of words and collocation is an
                indicator of significance .
            </sentence>
            <definiendum id="0">collocation</definiendum>
            <definiens id="0">an indicator of significance</definiens>
        </definition>
        <definition id="2">
            <sentence>TTs are defined as those NPs , or their subparts , which occur above some frequency threshold in a
                corpus .
            </sentence>
            <definiendum id="0">TTs</definiendum>
            <definiens id="0">those NPs , or their subparts , which occur above some frequency threshold in a corpus
            </definiens>
        </definition>
        <definition id="3">
            <sentence>For common NPs ( NPs whose head is a common noun ) , an SNP is a maximal NP that includes
                premodifiers such as determiners and possessives but not post-nominal constituents such as prepositions
                or relativizers .
            </sentence>
            <definiendum id="0">SNP</definiendum>
            <definiens id="0">a maximal NP that includes premodifiers such as determiners</definiens>
        </definition>
        <definition id="4">
            <sentence>For proper names , an SNP is a name that refers to a single entity .</sentence>
            <definiendum id="0">SNP</definiendum>
            <definiens id="0">a name that refers to a single entity</definiens>
        </definition>
        <definition id="5">
            <sentence>Powerful corpus processing techniques have been developed to measure deviance from an average
                occurrence or co-occurrence in the corpus .
            </sentence>
            <definiendum id="0">Powerful corpus processing techniques</definiendum>
            <definiens id="0">developed to measure deviance from an average occurrence or co-occurrence in the corpus
            </definiens>
        </definition>
        <definition id="6">
            <sentence>The X axis represents ratings awarded by subjects .</sentence>
            <definiendum id="0">X axis</definiendum>
        </definition>
        <definition id="7">
            <sentence>The Y axis reflects the percentage of terms receiving a given rank or better .</sentence>
            <definiendum id="0">Y axis</definiendum>
            <definiens id="0">reflects the percentage of terms receiving a given rank or better</definiens>
        </definition>
        <definition id="8">
            <sentence>The KW list and HS list overlap when the SNP consists only of a single word ( the head ) or only
                of a head modified by determiners .
            </sentence>
            <definiendum id="0">KW list</definiendum>
            <definiendum id="1">HS list overlap</definiendum>
            <definiens id="0">the head ) or only of a head modified by determiners</definiens>
        </definition>
        <definition id="9">
            <sentence>We found that in about half of the cases ( 21 of 40 ) , the phrase as a whole and the individual
                words in the phrase received similar scores , as in Example 1 in Figure 6 .
            </sentence>
            <definiendum id="0">phrase</definiendum>
            <definiens id="0">a whole and the individual words in the phrase received similar scores</definiens>
        </definition>
    </paper>

    <paper id="2027">
        <definition id="0">
            <sentence>The comparison between MIMIC and MIMIC-SI 204 Utterance ( 38 ) S : ( 39 ) ( 40 ) U : ( 41 ) S : (
                42 ) U : ( 43 ) S : ( 44 ) U : ( 45 ) S : ( 46 ) U : ( 47 ) S : ( 48 ) U : ( 49 ) S : ( 50 ) U : ( 51 )
                S : ( 52 ) U : ( 53 ) S : ( 54 ) ( 55 ) ( 56 ) ( 57 ) U : S : Hello , this is MIMIC , the movie
                information system .
            </sentence>
            <definiendum id="0">MIMIC</definiendum>
            <definiens id="0">40 ) U : ( 41 ) S : ( 42 ) U : ( 43 ) S : ( 44 ) U : ( 45 ) S : ( 46 ) U : ( 47 ) S : ( 48
                ) U : ( 49 ) S : ( 50 ) U : ( 51 ) S : ( 52 ) U : ( 53 ) S : ( 54 ) ( 55 ) ( 56 ) ( 57 ) U
            </definiens>
            <definiens id="1">the movie information system</definiens>
        </definition>
        <definition id="1">
            <sentence>MIMIC : An adaptive mixed initiative spoken dialogue system for information queries .</sentence>
            <definiendum id="0">MIMIC</definiendum>
            <definiens id="0">An adaptive mixed initiative spoken dialogue system for information queries</definiens>
        </definition>
        <definition id="2">
            <sentence>PARADISE : A framework for evaluating spoken dialogue agents .</sentence>
            <definiendum id="0">PARADISE</definiendum>
        </definition>
    </paper>

    <paper id="2018">
        <definition id="0">
            <sentence>p ( e ( c ) i l ( c ) , t ( c ) , h ( c ) , H ( c ) ) where l ( c ) is the label of c ( e.g. ,
                whether it is a noun phrase ( np ) , verb-phrase , etc. ) and H ( c ) is the relevant history of c
                -information outside c that our probability model deems important in determining the probability in
                question .
            </sentence>
            <definiendum id="0">p ( e</definiendum>
            <definiendum id="1">l ( c )</definiendum>
            <definiendum id="2">H ( c )</definiendum>
            <definiens id="0">the relevant history of c -information outside c that our probability model deems
                important in determining the probability in question
            </definiens>
        </definition>
        <definition id="1">
            <sentence>M ( c ) is the constituent from which the head lexical item h is obtained according to
                deterministic rules that pick the head of a constituent from among the heads of its children .
            </sentence>
            <definiendum id="0">M ( c )</definiendum>
        </definition>
        <definition id="2">
            <sentence>In particular , we measure labeled precision ( LP ) and recall ( LR ) , average number of
                crossbrackets per sentence ( CB ) , percentage of sentences with zero cross brackets ( 0CB ) , and
                percentage of sentences with &lt; 2 cross brackets ( 2CB ) .
            </sentence>
            <definiendum id="0">precision ( LP</definiendum>
            <definiendum id="1">recall ( LR</definiendum>
        </definition>
    </paper>

    <paper id="1023">
        <definition id="0">
            <sentence>We believe that QA is an ideal test bed for demonstrating the power of IE .</sentence>
            <definiendum id="0">QA</definiendum>
            <definiens id="0">an ideal test bed for demonstrating the power of IE</definiens>
        </definition>
        <definition id="1">
            <sentence>-- -| ... . Apptication Modutes NE : NIiml~ EnlilyTitl~klll QA : Que~tlon Answering CE : Come ,
                led Entity ExtrmClkm BR : In~lllgenl ~wslng GE : Gcn~mI Evenl Ex~ct~on AS ; Auio~ SUllen co : cemfcmnc
                ~1 momiall s ~ p~ Figure 1 : Textract IE System Architecture The core of the system consists of three
                kernel IE modules and six linguistic modules .
            </sentence>
            <definiendum id="0">Apptication Modutes NE</definiendum>
            <definiendum id="1">Que~tlon Answering CE</definiendum>
            <definiendum id="2">Entity ExtrmClkm BR</definiendum>
            <definiendum id="3">SUllen co</definiendum>
            <definiens id="0">In~lllgenl ~wslng GE : Gcn~mI Evenl Ex~ct~on AS</definiens>
        </definition>
        <definition id="2">
            <sentence>The Text Matcher module links the two processing results and tries to find answers to the
                processed question .
            </sentence>
            <definiendum id="0">Text Matcher module</definiendum>
            <definiens id="0">links the two processing results and tries to find answers to the processed question
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Rule \ [ 9\ ] is a catch-all rule : if the NP is not of class person ( person_w ) or organization
                ( org_w ) , then the asking point is a proper name ( default NE ) , often realized in English in
                capitalized string of words .
            </sentence>
            <definiendum id="0">asking point</definiendum>
            <definiens id="0">a proper name ( default NE ) , often realized in English in capitalized string of words
            </definiens>
        </definition>
        <definition id="4">
            <sentence>_point list attempts to find an infinitive by checking the word to followed by a verb ( with the
                part-of-speech tag VB ) .
            </sentence>
            <definiendum id="0">_point list</definiendum>
            <definiens id="0">attempts to find an infinitive by checking the word to followed by a verb</definiens>
        </definition>
        <definition id="5">
            <sentence>Kupiec J. ( 1993 ) MURAX : A Robust Linguistic Approach For Question Answering Using An On-Line
                Encyclopaedia , `` Proceedings of SIGIR-93 93 '' Pittsburgh , Penna .
            </sentence>
            <definiendum id="0">MURAX</definiendum>
            <definiens id="0">A Robust Linguistic Approach For Question Answering Using An On-Line Encyclopaedia , ``
                Proceedings of SIGIR-93 93 '' Pittsburgh
            </definiens>
        </definition>
    </paper>

    <paper id="1036">
        <definition id="0">
            <sentence>Table 1 shows that for this task , the relaxationranking passage retrieval algorithm without its
                supplementary knowledge sources ( Recall II w/o knowledge ) is roughly comparable in performance ( 42.9
                % versus 44.0 % success rate ) to a state-of-the-art commercial search engine ( SearchIt ) at the pure
                document retrieval task ( neglecting the added benefit of locating the specific passages ) .
            </sentence>
            <definiendum id="0">SearchIt</definiendum>
            <definiens id="0">the relaxationranking passage retrieval algorithm without its supplementary knowledge
                sources ( Recall II w/o knowledge
            </definiens>
        </definition>
        <definition id="1">
            <sentence>UNIX is a registered trademark in the United States and other countries , exclusively licensed
                through Xpen Company , Ltd .
            </sentence>
            <definiendum id="0">UNIX</definiendum>
            <definiens id="0">a registered trademark in the United States and other countries</definiens>
        </definition>
    </paper>

    <paper id="1026">
        <definition id="0">
            <sentence>ARBITER is a Prolog program that extracts assertions about macromolecular binding relationships
                from biomedical text .
            </sentence>
            <definiendum id="0">ARBITER</definiendum>
        </definition>
        <definition id="1">
            <sentence>( 1 ) CC chemokine receptor 1 ( CCR1 ) is expressed in neutrophils , monocytes , lymphocytes , and
                eosinophils , and binds the leukocyte chemoattractant and hematopoiesis regulator macrophage
                inflammatory protein ( MIP ) 1 alpha , as well as several related CC chemokines .
            </sentence>
            <definiendum id="0">CCR1</definiendum>
            <definiens id="0">expressed in neutrophils , monocytes , lymphocytes , and eosinophils , and binds the
                leukocyte chemoattractant and hematopoiesis regulator macrophage inflammatory protein
            </definiens>
        </definition>
        <definition id="2">
            <sentence>The SPECIALIST Lexicon ( with associated lexical access tools ) supplies syntactic information for
                a large compilation of biomedical and general English terms .
            </sentence>
            <definiendum id="0">SPECIALIST Lexicon</definiendum>
            <definiens id="0">associated lexical access tools ) supplies syntactic information for a large compilation
                of biomedical and general English terms
            </definiens>
        </definition>
        <definition id="3">
            <sentence>The SPECIALIST minimal commitment parser relies on the SPECIALIST Lexicon as well as the Xerox
                stochastic tagger ( Cutting et al. 1992 ) .
            </sentence>
            <definiendum id="0">SPECIALIST minimal commitment parser</definiendum>
        </definition>
        <definition id="4">
            <sentence>( 4 ) \ [ binding_term ( \ [ head ( Je142 ) \ ] , { Morphology Shape Rule } \ [ aux0s ) \ ] , \ [
                det ( an ) , head ( IgG ) \ ] { Metathesaurus } ) , \ [ pron ( which ) \ ] , \ [ verb ( binds ) \ ] ,
                binding_term ( \ [ prep ( to ) , det ( the ) , mod ( small ) , mod ( bacterial ) , head ( protein ) ,
                punc ( , ) \ ] , { Metathesaurus } \ [ head ( HPr ) \ ] { Morphology Shape Rule } ) , \ [ conj ( and ) \
                ] , \ [ det ( the ) , head ( structure ) I , binding_term ( \ [ prep ( of ) , det ( the ) , head (
                complex ) \ ] { General Binding Word } ) , \ [ aux ( is ) \ ] , \ [ verb ( known ) \ ] , \ [ prep ( at )
                , mod ( high ) , head ( resolution ) , punc ( . )
            </sentence>
            <definiendum id="0">mod</definiendum>
            <definiendum id="1">mod</definiendum>
            <definiens id="0">an ) , head ( IgG ) \ ] { Metathesaurus } ) , \ [ pron ( which ) \ ] , \ [ verb ( binds )
                \ ]
            </definiens>
            <definiens id="1">head ( protein ) , punc ( , ) \ ] , { Metathesaurus } \ [ head ( HPr ) \ ] { Morphology
                Shape Rule }
            </definiens>
            <definiens id="2">complex ) \ ] { General Binding Word } ) , \ [ aux ( is ) \ ] , \ [ verb ( known ) \ ]
            </definiens>
        </definition>
    </paper>

    <paper id="1030">
        <definition id="0">
            <sentence>Before trying pattern-based rules for suffixes , prefixes , and lexical compounds , the
                morphological analyzer makes a number of tests for special forms that require idiosyncratic treatment .
            </sentence>
            <definiendum id="0">morphological analyzer</definiendum>
            <definiens id="0">makes a number of tests for special forms that require idiosyncratic treatment</definiens>
        </definition>
        <definition id="1">
            <sentence>These tests include the following : • number ( including integer , floating , and exponential
                notations , including numbers too large to be represented internally as numbers in the machine ) , •
                Roman numeral ( vii , mcm ) , • ordinal ( 1st , 2nd , twenty-third ) , • alphanum ( Al203 , 79D ) , •
                letter ( b , x ) , • initial ( B. ) , • phone number ( 123-4567 ) , • hyphenated adjective (
                all-volunteer ) , • ratio ( s/S , V/R ) , • multiword lexical item ( snake_in_the_grass ) , • special
                proper nouns ( gls @ mit.edu , /usr/bin , http : //www.sun.com , C+ + ) Suffix rules in this system are
                pattern-action rules that specify : the word to be analyzed , and/or a sequence of characters to add to
                form a root ( or base form ) , possible interpretations of a word matching this pattern. '
            </sentence>
            <definiendum id="0">http</definiendum>
        </definition>
        <definition id="2">
            <sentence>The rules within a block of suffix rules will typically try for interpretations in roughly the
                following order : named inflectional paradigm ( paradigmatic ) with unknown inflectional paradigm some
                other category right category less of category haps suffix , without identifiable root vocabulary is not
                comprehensive ) The last rule in this sequence is a default guessing rule that depends on a flag that
                tells it whether it is running with a core lexicon that is believed to contain most nonobvious verbs .
            </sentence>
            <definiendum id="0">inflectional paradigm</definiendum>
        </definition>
    </paper>

    <paper id="1016">
        <definition id="0">
            <sentence>CommandTalk ( Moore et al. , 1997 ) , Circuit Fix-It Shop ( Smith , 1997 ) and TRAINS-96 ( Traum
                and Allen , 1994 ; Tranm and Andersen , 1999 ) are spoken language systems but they interface to
                simulation or help facilities rather than semi-autonomous agents .
            </sentence>
            <definiendum id="0">CommandTalk</definiendum>
            <definiendum id="1">Circuit Fix-It Shop</definiendum>
            <definiens id="0">spoken language systems but they interface to simulation or help facilities rather than
                semi-autonomous agents
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Logic is indeed an excellent way to think about representing static relationships like database
                queries , but it is much less clear that it is a good way to represent commands .
            </sentence>
            <definiendum id="0">Logic</definiendum>
            <definiens id="0">an excellent way to think about representing static relationships like database queries
            </definiens>
        </definition>
        <definition id="2">
            <sentence>The real PSA is a miniature robot currently being developed at NASA Ames Research Center , which
                is intended for deployment on the Space Shuttle and/or International Space Station .
            </sentence>
            <definiendum id="0">PSA</definiendum>
            <definiens id="0">a miniature robot currently being developed at NASA Ames Research Center , which is
                intended for deployment on the Space Shuttle and/or International Space Station
            </definiens>
        </definition>
        <definition id="3">
            <sentence>The initial PSA speech interface demo consists of a simple simulation of the Shuttle .</sentence>
            <definiendum id="0">PSA speech interface demo</definiendum>
        </definition>
        <definition id="4">
            <sentence>State parameters include the PSA 's current position , some environmental variables such as local
                temperature , pressure and carbon dioxide levels , and the status of the Shuttle 's doors ( open/closed
                ) .
            </sentence>
            <definiendum id="0">State parameters</definiendum>
            <definiens id="0">include the PSA 's current position , some environmental variables such as local
                temperature , pressure and carbon dioxide levels , and the status of the Shuttle 's doors ( open/closed
                )
            </definiens>
        </definition>
        <definition id="5">
            <sentence>There is one script interpreter , which functions both as a script executive and a script
                evaluator , and one set of rules which defines the procedural semantics of script actions .
            </sentence>
            <definiendum id="0">script interpreter</definiendum>
            <definiendum id="1">rules</definiendum>
            <definiens id="0">functions both as a script executive and a script evaluator</definiens>
            <definiens id="1">defines the procedural semantics of script actions</definiens>
        </definition>
        <definition id="6">
            <sentence>\ [ PSA starts moving to commander 's seat\ ] 10 .</sentence>
            <definiendum id="0">PSA</definiendum>
        </definition>
        <definition id="7">
            <sentence>Gemini : A natural language system for spoken language understanding .</sentence>
            <definiendum id="0">Gemini</definiendum>
        </definition>
    </paper>

    <paper id="2026">
        <definition id="0">
            <sentence>NLG1 serves a baseline system and uses phrase frequencies to generate a whole phrase in one step ,
                while NLG2 and NLG3 use maximum entropy probability models to individually generate each word in the
                phrase .
            </sentence>
            <definiendum id="0">NLG1</definiendum>
            <definiens id="0">serves a baseline system and uses phrase frequencies to generate a whole phrase in one
                step
            </definiens>
        </definition>
        <definition id="1">
            <sentence>There are more sophisticated surface generation packages , such as FUF/SURGE ( Elhadad and Robin ,
                1996 ) , KPML ( Bateman , 1996 ) , MUMBLE ( Meteer et al. , 1987 ) , and RealPro ( Lavoie and Rambow ,
                1997 ) , which produce natural language text from an abstract semantic representation .
            </sentence>
            <definiendum id="0">MUMBLE</definiendum>
            <definiens id="0">produce natural language text from an abstract semantic representation</definiens>
        </definition>
        <definition id="2">
            <sentence>The motivation for a trainable surface generator is to solve the above two problems in a way that
                reflects the observed usage of language in a corpus , but without the manual effort needed to construct
                a grammar or knowledge base .
            </sentence>
            <definiendum id="0">generator</definiendum>
            <definiens id="0">reflects the observed usage of language in a corpus , but without the manual effort needed
                to construct a grammar or knowledge base
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Specifically , nlgl ( A ) returns the phrase that corresponds to the attribute set A : nlgl ( A )
                = { argInaXphraseeTA\ [ empty string\ ] C ( phrase , A ) TATA = where TA are the phrases that have
                occurred with A in the training data , and where C ( phrase , A ) is the training data frequency of the
                natural language phrase phrase and the set of attributes A. NLG1 will fail to generate anything if A is
                a novel combination of attributes .
            </sentence>
            <definiendum id="0">nlgl</definiendum>
            <definiendum id="1">C ( phrase</definiendum>
            <definiendum id="2">A )</definiendum>
            <definiens id="0">A ) returns the phrase that corresponds to the attribute set A : nlgl ( A ) = {
                argInaXphraseeTA\ [ empty string\ ] C ( phrase , A ) TATA = where TA are the phrases that have occurred
                with A in the training data , and where
            </definiens>
            <definiens id="1">the training data frequency of the natural language phrase phrase and the set of
                attributes A. NLG1 will fail to generate anything if A is a novel combination of attributes
            </definiens>
        </definition>
        <definition id="4">
            <sentence>The probability model in NLG2 is a conditional distribution over V U * stop , , where V is the
                generation vocabulary and where .
            </sentence>
            <definiendum id="0">V</definiendum>
            <definiens id="0">a conditional distribution over V U * stop , , where</definiens>
        </definition>
        <definition id="5">
            <sentence>The generation vocabulary V consists of all the words seen in the training data .</sentence>
            <definiendum id="0">generation vocabulary V</definiendum>
        </definition>
        <definition id="6">
            <sentence>and { wi-l , wi-2 , attri } is the history , where wi denotes the ith word in the phrase , and
                attri denotes the attributes that remain to be generated at position i in the phrase .
            </sentence>
            <definiendum id="0">wi</definiendum>
            <definiens id="0">the ith word in the phrase , and attri denotes the attributes that remain to be generated
                at position i in the phrase
            </definiens>
        </definition>
        <definition id="7">
            <sentence>The search procedure attempts to find a word sequence wl ... wn of any length n ~ M for the input
                attribute set A such that once once and where M is an heuristically set maximum phrase length .
            </sentence>
            <definiendum id="0">search procedure</definiendum>
        </definition>
        <definition id="8">
            <sentence>Just as in NLG2 , p is a distribution over V t2 .</sentence>
            <definiendum id="0">p</definiendum>
        </definition>
        <definition id="9">
            <sentence>The expression chi ( w ) denotes the ith closest child to the headword w , par ( w ) denotes the
                parent of the headword w , dir E { left , right } denotes the direction of the child relative to the
                parent , and attrw , i denotes the attributes that remain to be generated in the tree when headword w is
                predicting its ith child .
            </sentence>
            <definiendum id="0">expression chi ( w )</definiendum>
            <definiens id="0">the parent of the headword w , dir E { left , right } denotes the direction of the child
                relative to the parent
            </definiens>
        </definition>
        <definition id="10">
            <sentence>Low frequency features involving word n-grams tend to be unreliable ; the NLG3 system therefore
                only uses features which occur K times or more in the training data .
            </sentence>
            <definiendum id="0">NLG3 system</definiendum>
            <definiens id="0">occur K times or more in the training data</definiens>
        </definition>
        <definition id="11">
            <sentence>NLG3 chooses the best answer to express the attribute set A as follows : nlga ( A ) = argmax Pr (
                TIA ) TET .
            </sentence>
            <definiendum id="0">NLG3</definiendum>
        </definition>
        <definition id="12">
            <sentence>Iga where Tntga are the completed dependency trees that satisfy the conditions of the NLG3 search
                described above .
            </sentence>
            <definiendum id="0">Tntga</definiendum>
            <definiens id="0">the completed dependency trees that satisfy the conditions of the NLG3 search described
                above
            </definiens>
        </definition>
        <definition id="13">
            <sentence>I-Ik YJ ( chi\ [ t° ) 'to'chi -- l ( ~ ) 'chi -- 2 ( ~ ) 'Pa~ ( ~ ) 'dtr'att~o , i ) p ( chiCw ) \
                [ w , chi1 ( w ) , chi-2 ( w ) , par ( w ) , dir , attr~ , i ) ~ '' Jffi ' ~ J -Z ( w , chi_ 1 ( w ) ,
                chi2 ( w ) , par ( w ) , di~ , attrtu , i ) Z ( w , ehi_l ( w ) , chi_2 ( w ) , par ( w ) , dir ,
                attrw,4 ) = ~v , , l-\ [ j=lk OL~/J ( w '' w'chi-l ( *Z ) 'chl-2 ( w ) 'par ( tv ) 'dir'att*'~'i )
                Figure 2 : NLG3 : Equations for the probability of the ith child of head word w , or chi ( w ) Pr ( TIA
                ) Prl¢lt ( wlA ) Prri~ht ( w\ [ A ) = YI~eTPrl~ft ( wlA ) Prr~ght ( wl A ) -- -Pr ( # of left children =
                n ) YL=ln p ( chi ( w ) lw , chi-l ( w ) , chi-2 ( w ) , par ( w ) , dir = left , attr~ , i ) = Pr ( ~
                of right children = n ) rI~=l p ( chi ( w ) lw , chi-1 ( w ) , chi-2 ( w ) , par ( w ) , dir = right ,
                attrw , ~ ) Figure 3 : NLG3 : Equations for the probability of a dependency tree T Description Siblings
                Parent + sibling Parent + grandparent Feature f ( chi ( w ) , w , ch~_ 1 ( w ) , chi_2 ( w ) , par ( w )
                , dir , attrw , i ) = ... 1 if chi ( w ) = ?
            </sentence>
            <definiendum id="0">I-Ik YJ</definiendum>
            <definiendum id="1">wlA ) Prri~ht ( w\ [ A )</definiendum>
            <definiens id="0">Equations for the probability of the ith child of head word w</definiens>
            <definiens id="1">wl A ) -- -Pr ( # of left children = n ) YL=ln p</definiens>
        </definition>
    </paper>

    <paper id="2037">
    </paper>

    <paper id="1010">
        <definition id="0">
            <sentence>We describe Talk'n'Travel , a spoken dialogue language system for making air travel plans over the
                telephone .
            </sentence>
            <definiendum id="0">Talk'n'Travel</definiendum>
            <definiens id="0">a spoken dialogue language system for making air travel plans over the telephone
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Talk'n'Travel is a fully conversational , mixed-initiative system that allows the user to specify
                the constraints on his travel plan in arbitrary order , ask questions , etc. , in general spoken English
                .
            </sentence>
            <definiendum id="0">Talk'n'Travel</definiendum>
            <definiens id="0">a fully conversational , mixed-initiative system that allows the user to specify the
                constraints on his travel plan in arbitrary order , ask questions , etc. , in general spoken English
            </definiens>
        </definition>
        <definition id="2">
            <sentence>Talk'n'Travel is a research prototype system sponsored under the DARPA Communicator program (
                MITRE , 1999 ) .
            </sentence>
            <definiendum id="0">Talk'n'Travel</definiendum>
        </definition>
        <definition id="3">
            <sentence>A path constraint is an expression of the form : ( &lt; path &gt; &lt; relation &gt; &lt;
                arguments &gt; * ) The path is a compositional chain of one or more attributes , and relations are
                1-place or higher predicates , whose first argument is implicitly the path .
            </sentence>
            <definiendum id="0">path constraint</definiendum>
            <definiens id="0">an expression of the form : ( &lt; path &gt; &lt; relation &gt; &lt; arguments &gt; *
            </definiens>
            <definiens id="1">a compositional chain of one or more attributes , and relations are 1-place or higher
                predicates
            </definiens>
        </definition>
        <definition id="4">
            <sentence>The agenda stack is in turn determined by an application-dependent library of plans .</sentence>
            <definiendum id="0">agenda stack</definiendum>
            <definiens id="0">in turn determined by an application-dependent library of plans</definiens>
        </definition>
        <definition id="5">
            <sentence>The language generator takes a meaning frame from the dialogue manager , and generates a text
                string in English for it .
            </sentence>
            <definiendum id="0">language generator</definiendum>
            <definiens id="0">takes a meaning frame from the dialogue manager , and generates a text string in English
                for it
            </definiens>
        </definition>
    </paper>

    <paper id="1040">
        <definition id="0">
            <sentence>Named entity ( NE ) recognition is the process of identifying and categorising names in text .
            </sentence>
            <definiendum id="0">recognition</definiendum>
            <definiens id="0">Named entity ( NE )</definiens>
        </definition>
        <definition id="1">
            <sentence>These metrics are often combined using a weighted harmonic called the F-measure ( F ) calculated
                according to formula 1 where fl is a weighting constant often set to 1 .
            </sentence>
            <definiendum id="0">F-measure</definiendum>
            <definiendum id="1">fl</definiendum>
            <definiens id="0">a weighting constant often set to 1</definiens>
        </definition>
        <definition id="2">
            <sentence>For example , there is a rule which says that a phrase consisting of a person first name followed
                by a word part of speech tagged as a proper noun is a person name .
            </sentence>
            <definiendum id="0">noun</definiendum>
            <definiens id="0">a rule which says that a phrase consisting of a person first name followed by a word part
                of speech tagged as a proper
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Adding a name to a list will lead to a recall score of 1 for that name and a precision of Pr (
                where Pr is the probability value estimated from the training corpus ) which implies an F-measure of
                ~.2Pr 1 Therefore the probabilities can be used to filter out candidate list items which imply low
                F-measure scores .
            </sentence>
            <definiendum id="0">Pr</definiendum>
            <definiens id="0">the probability value estimated from the training corpus</definiens>
        </definition>
    </paper>

    <paper id="1012">
        <definition id="0">
            <sentence>4F-measure ( F ) is a weighted harmonic combining precision ( P ) and recall ( R ) via the formula
                2PR PTR `` very low result in comparison to the expert annotation .
            </sentence>
            <definiendum id="0">4F-measure ( F )</definiendum>
            <definiendum id="1">recall</definiendum>
            <definiens id="0">a weighted harmonic combining precision</definiens>
        </definition>
        <definition id="1">
            <sentence>It is calculated according to formula 1 , where Pr ( A ) is the proportion of times the annotators
                agree and Pr ( E ) the proportion which would be expected by chance .
            </sentence>
            <definiendum id="0">Pr ( A )</definiendum>
            <definiens id="0">the proportion of times the annotators agree and Pr ( E ) the proportion which would be
                expected by chance
            </definiens>
        </definition>
        <definition id="2">
            <sentence>Pr ( A ) Pr ( E ) = ( 1 ) 1 Pr ( E ) The value of the kappa statistic ranges between 1 ( perfect
                agreement ) and 0 ( the level which would be expected by chance ) .
            </sentence>
            <definiendum id="0">Pr</definiendum>
            <definiens id="0">The value of the kappa statistic ranges between 1 ( perfect agreement</definiens>
            <definiens id="1">the level which would be expected by chance )</definiens>
        </definition>
        <definition id="3">
            <sentence>Memory-based learning , also known as case-based and lazy learning , operates by memorising a set
                of training examples and categorising new cases by assigning them the class of the most similar learned
                example .
            </sentence>
            <definiendum id="0">Memory-based learning</definiendum>
            <definiens id="0">case-based and lazy learning , operates by memorising a set of training examples and
                categorising new cases by assigning them the class of the most similar learned example
            </definiens>
        </definition>
        <definition id="4">
            <sentence>CYBERPUNC : A lightweight punctuation annotation system for speech .</sentence>
            <definiendum id="0">CYBERPUNC</definiendum>
            <definiens id="0">A lightweight punctuation annotation system for speech</definiens>
        </definition>
        <definition id="5">
            <sentence>In C. Fellbaum , editor , WordNet : An electronic lexical database and some applications .
            </sentence>
            <definiendum id="0">WordNet</definiendum>
            <definiens id="0">An electronic lexical database and some applications</definiens>
        </definition>
        <definition id="6">
            <sentence>CommandTalk : A Spokcaa-Language Interface to Battlefield Simulations .</sentence>
            <definiendum id="0">CommandTalk</definiendum>
        </definition>
    </paper>

    <paper id="1008">
        <definition id="0">
            <sentence>APE has full unification and can handle arbitrarily nested discourse constructs , making it more
                powerful than dialogue managers based on finitestate machines .
            </sentence>
            <definiendum id="0">APE</definiendum>
            <definiens id="0">has full unification and can handle arbitrarily nested discourse constructs , making it
                more powerful than dialogue managers based on finitestate machines
            </definiens>
        </definition>
        <definition id="1">
            <sentence>APE is a domainand task-independent system .</sentence>
            <definiendum id="0">APE</definiendum>
            <definiens id="0">a domainand task-independent system</definiens>
        </definition>
        <definition id="2">
            <sentence>Bratman uses the term `` practical reason '' to describe his analysis since he is concerned with
                how to reason about practical matters .
            </sentence>
            <definiendum id="0">Bratman</definiendum>
            <definiens id="0">uses the term `` practical reason '' to describe his analysis since he is concerned with
                how to reason about practical matters
            </definiens>
        </definition>
    </paper>

    <paper id="1035">
        <definition id="0">
            <sentence>As was mentioned early , SCARRIE has a facility for guessing unknown proper names on the basis of
                their frequency of occurrence in the text .
            </sentence>
            <definiendum id="0">SCARRIE</definiendum>
            <definiens id="0">a facility for guessing unknown proper names on the basis of their frequency of occurrence
                in the text
            </definiens>
        </definition>
        <definition id="1">
            <sentence>But since the test corpus consists of Short unrelated excerpts , a large number of proper names
                only occur once or twice .
            </sentence>
            <definiendum id="0">the test corpus</definiendum>
            <definiens id="0">consists of Short unrelated excerpts , a large number of proper names only occur once or
                twice
            </definiens>
        </definition>
        <definition id="2">
            <sentence>GramCheck : A grammar and style checker .</sentence>
            <definiendum id="0">GramCheck</definiendum>
            <definiens id="0">A grammar and style checker</definiens>
        </definition>
    </paper>

    <paper id="2010">
        <definition id="0">
            <sentence>Tile cut elimination property of sequent calculus also appears intrinsically in the proof net
                formalism with a sire '' /1131 70 Table 1 : Links Name Axiom Tensor Par Cut Link CI C2 ~ 2 C ~ , g2 ``
                '\l// C P , 'cmises none t ) 1 , P2 Pl , P2 Pl , P2 Conclusions cl , c2 c none C 1 : A + o , :APl : ,4P2
                : B + e : ( A -o B ) + C Pl : A + P2 : /3c : ( A -- -0 B ) , ,O I : AP2 : A+ Types Table 2 :
                Cut-elimination rewriting rules x x y y i ... ... ... ... ... ... ... ... . !
            </sentence>
            <definiendum id="0">Pl</definiendum>
            <definiens id="0">A -o B ) + C</definiens>
        </definition>
        <definition id="1">
            <sentence>: VP ) = e 7¢ ( A\B ) = `` K ( A ) ~ `` H ( B ) `` H ( , ~ ' ) = t `` H ( A/B ) = `` H ( B ) -- o
                `` H ( A ) And for a lexical item , given its syntactic type , we asSUlne its semantic proof net to
                verify : • the type of its unique output conclusion is the homomorplaic image of the syntactic type : •
                its input conclusions ( if any ) are decorated with typed constants .
            </sentence>
            <definiendum id="0">K</definiendum>
            <definiendum id="1">H</definiendum>
            <definiendum id="2">H</definiendum>
            <definiens id="0">A ) And for a lexical item , given its syntactic type</definiens>
        </definition>
        <definition id="2">
            <sentence>The generation problem ( see figure 5 ) is to find a matching M of atomic formulas of F such that
                : F ' ) is a correct proof net ; ing these cuts , we obtain H0 .
            </sentence>
            <definiendum id="0">)</definiendum>
            <definiens id="0">to find a matching M of atomic formulas of F such that : F '</definiens>
        </definition>
    </paper>

    <paper id="2009">
        <definition id="0">
            <sentence>A learning algorithm induces a representative model from these features which is employed as a
                classifier to perform disambiguation .
            </sentence>
            <definiendum id="0">learning algorithm</definiendum>
            <definiens id="0">a classifier to perform disambiguation</definiens>
        </definition>
        <definition id="1">
            <sentence>The selected model was used as a probabilistic classifier on a held-out set of test data and
                achieved accuracy of 78 % .
            </sentence>
            <definiendum id="0">accuracy</definiendum>
            <definiens id="0">a probabilistic classifier on a held-out set of test data and achieved</definiens>
        </definition>
    </paper>

    <paper id="2032">
        <definition id="0">
            <sentence>, where # ( x ) denotes the number of occurrences of x in the ( unsegmented ) training corpus .
            </sentence>
            <definiendum id="0"># ( x )</definiendum>
            <definiens id="0">the number of occurrences of x in the ( unsegmented ) training corpus</definiens>
        </definition>
        <definition id="1">
            <sentence>Treating a proposed segmentation as a non-nested bracketing ( e.g. , `` lAB ICI '' corresponds to
                the bracketing `` [ AB ] [ C ] '' ) , word precision ( P ) is defined as the percentage of proposed
                brackets that exactly match word-level brackets in the annotation ; word recall ( R ) is the percentage
                of word-level annotation brackets that are proposed by the algorithm in question ; and word F combines
                precision and recall : F = 2PR/ ( P + R ) .
            </sentence>
            <definiendum id="0">Treating a proposed segmentation as a non-nested bracketing</definiendum>
            <definiendum id="1">word recall</definiendum>
            <definiendum id="2">R</definiendum>
            <definiens id="0">the bracketing `` [ AB ] [ C ] '' ) , word precision</definiens>
            <definiens id="1">the percentage of proposed brackets that exactly match word-level brackets in the
                annotation ;
            </definiens>
            <definiens id="2">the percentage of word-level annotation brackets that are proposed by the algorithm in
                question ; and word F combines precision and recall : F = 2PR/ ( P + R )
            </definiens>
        </definition>
        <definition id="2">
            <sentence>In our algorithm , a location k is deemed a word boundary if VN ( k ) is either ( 1 ) a local
                maximum or ( 2 ) at least as big as the threshold t. It is natural to ask whether we really need two
                conditions , or whether just one would suffice .
            </sentence>
            <definiendum id="0">k )</definiendum>
            <definiens id="0">natural to ask whether we really need two conditions , or whether just one would suffice
            </definiens>
        </definition>
        <definition id="3">
            <sentence>In a later paper , Palmer ( 1997 ) presents a transformation-based algorithm , which requires
                pre-segmented training data .
            </sentence>
            <definiendum id="0">transformation-based algorithm</definiendum>
            <definiens id="0">requires pre-segmented training data</definiens>
        </definition>
        <definition id="4">
            <sentence>LINGSTAT : An interactive , machine-aided translation system .</sentence>
            <definiendum id="0">LINGSTAT</definiendum>
            <definiens id="0">An interactive , machine-aided translation system</definiens>
        </definition>
    </paper>

    <paper id="1003">
        <definition id="0">
            <sentence>The phrase recognizer identifies meaningful phrases ( e.g. fire engine ) and handles them as a
                unit .
            </sentence>
            <definiendum id="0">phrase recognizer</definiendum>
            <definiens id="0">identifies meaningful phrases ( e.g. fire engine ) and handles them as a unit</definiens>
        </definition>
        <definition id="1">
            <sentence>The pattern matcher recognizes core noun phrases and makes it more likely that they will match
                correctly .
            </sentence>
            <definiendum id="0">pattern matcher</definiendum>
            <definiens id="0">recognizes core noun phrases and makes it more likely that they will match correctly
            </definiens>
        </definition>
        <definition id="2">
            <sentence>The PictureQuest fisystem uses a semantic net based on WordNet ( Fellbaum 1998 ) to expand terms
                .
            </sentence>
            <definiendum id="0">PictureQuest fisystem</definiendum>
            <definiens id="0">uses a semantic net based on WordNet ( Fellbaum 1998 ) to expand terms</definiens>
        </definition>
        <definition id="3">
            <sentence>WordNet : An Electronic Lexical Database .</sentence>
            <definiendum id="0">WordNet</definiendum>
        </definition>
    </paper>

    <paper id="2016">
        <definition id="0">
            <sentence>Like Japanese , Korean is a head-final agglutinative language .</sentence>
            <definiendum id="0">Korean</definiendum>
            <definiens id="0">a head-final agglutinative language</definiens>
        </definition>
        <definition id="1">
            <sentence>A conflict set is a set of training examples that have identical values for all features , yet
                differ in their classification ( = parse action ) .
            </sentence>
            <definiendum id="0">conflict set</definiendum>
            <definiens id="0">a set of training examples that have identical values for all features , yet differ in
                their classification ( = parse action )
            </definiens>
        </definition>
        <definition id="2">
            <sentence>Learning Parse and Translation Decisions From Examples With Rich Context .</sentence>
            <definiendum id="0">Learning Parse</definiendum>
            <definiens id="0">and Translation Decisions From Examples With Rich Context</definiens>
        </definition>
        <definition id="3">
            <sentence>Learning Parse and Translation Decisions From Examples With Rich Context .</sentence>
            <definiendum id="0">Learning Parse</definiendum>
            <definiens id="0">and Translation Decisions From Examples With Rich Context</definiens>
        </definition>
        <definition id="4">
            <sentence>C4.5 Programs for Machine Learning .</sentence>
            <definiendum id="0">C4.5 Programs</definiendum>
        </definition>
    </paper>

    <paper id="1020">
        <definition id="0">
            <sentence>SWIZZLE is a multilingual enhancement of COCKTAIL ( Harabagiu and Maiorano , 1999 ) , a
                coreference resolution system that operates on a mixture of heuristics that combine semantic and textual
                cohesive information 2 .
            </sentence>
            <definiendum id="0">SWIZZLE</definiendum>
        </definition>
        <definition id="1">
            <sentence>SWIZZLE , moreover , adds new heuristics , discovered from the bilingual aligned corpus .
            </sentence>
            <definiendum id="0">SWIZZLE</definiendum>
            <definiens id="0">adds new heuristics , discovered from the bilingual aligned corpus</definiens>
        </definition>
        <definition id="2">
            <sentence>For a coreference chain of length l with nodes nl , n2 , ... nt+l , each node nk ( l &lt; k~/ )
                can be connected to any of the l k nodes preceding it. From this observation , we find that a number of
                1 x 2 x ... x ( l k ) ... x I = l ! coreference structures can generate the same coreference chain. This
                result is very important , since it allows for the automatic generation of coreference data. For each
                coreference relation T~ from an annotated corpus we created a median of ( l 1 ) ! new coreference
                relations , where l is the length of the coreference chain containing relation 7~. This observation gave
                us the possibility of expanding the test data provided by the coreference keys available in the MUC-6
                and MUC7 competitions ( MUC-6 1996 ) , ( MUC-7 1998 ) . The MUC-6 coreference annotated corpus contains
                1626 coreference relations , while the MUC-7 corpus has 2245 relations. The average length of a
                coreference chain is 7.21 for the MUC-6 data , and 8.57 for the MUC-7 data. We were able to expand the
                number of annotated coreference relations to 6,095,142 for the MUC-6 corpus and to 8,269,403 relations
                for the MUC-7 corpus ; this represents an expansion factor of 3,710. We are not aware of any other
                automated way of creating coreference annotated data , and we believe that much of the COCKTAIL 's
                impressive performance is due to the plethora of data provided by this method. 143 Heuristics for 3rd
                person pronouns oHeuristie 1-Pronoun ( H1Pron ) Search in the same sentence for the same 3rd person
                pronoun Pros ' if ( Pron ' belongs to coreference chain CC ) and there is an element from CC which is
                closest to Pron in Text , Pick that element. else Pick Pron'. oHeuristic 2-Pronoun ( H2Pron ) Search for
                PN , the closest proper name from Pron if ( PN agrees in number and gender with Pros ) if ( PN belongs
                to coreference chain CC ) then Pick the element from CC which is closest to Pros in Text. else Pick PN.
                o Heuristic 3Pronoun ( H3Pron ) Search for Noun , the closest noun from Pros if ( Noun agrees in number
                and gender with Pros ) if ( Noun belongs to coreference chain CC ) and there is an element from CC which
                is closest to Pros in Text , Pick that element. else Pick Noun Heuristics for nominal reference o
                Heuristic 1-Nominal ( HINom ) if ( Noun is the head of an appositive ) then Pick the preceding NP.
                oHeuristic 2-Nominal ( H2Nom ) if ( Noun belongs to an NP , Search for NP ' such that Noun'=same_name (
                head ( NP ) , head ( NP ' ) ) or Noun ' -- same_name ( adjunct ( NP ) , adjunct ( NP ' ) ) ) then if (
                Noun ' belongs to coreference chain CC ) then Pick the element from CC which is closest to Noun in Text.
                else Pick Noun'. oHeuristic 3-Nominal ( H3Nom ) if Noun is the head of an NP then Search for proper name
                PN such that head ( PN ) =Noun if ( PN belongs to coreference chain CC ) and there is an element from CC
                which is closest to Noun in Text , Pick that element. else Pick PN. Table 1 : Best performing heuristics
                implemented in COCKTAIL Resolution The result of our data-driven methodology is the set of heuristics
                implemented in COCKTAIL which cover both nominal and pronoun coreference. Each heuristic represents a
                pattern of coreference that was mined from the large set of coreference data. COCKTAIL uses
                knowledge-poor methods because ( a ) it is based only on a limited number of heuristics and ( b ) text
                processing is limited to part-of-speech tagging , named-entity recognition , and approximate phrasal
                parsing. The heuristics from COCKTAIL can be classified along two directions. First of all , they can be
                grouped according to the type of coreference they resolve , e.g. , heuristics that resolve the anaphors
                of reflexive pronouns operate differently than those resolving bare nominals. Currently , in COCKTAIL
                there are heuristics that resolve five types of pronouns ( personal , possessive , reflexive ,
                demonstrative and relative ) and three forms of nominals ( definite , bare and indefinite ) . Secondly ,
                for each type of coreference , there are three classes of heuristics categorized according to their
                suitability to resolve coreference. The first class is comprised of strong indicators of coreference.
                This class resulted from the analysis of the distribution of the antecedents in the MUC annotated data.
                For example , repetitions of named entities and appositives account for the majority of the nominal
                coreferences , and , therefore , represent anchors for the first class of heuristics. The second class
                of coreference covers cases in which the arguments are recognized to be semantically consistent.
                COCKTAIL 's test of semantic consistency blends together information available from WordNet and
                statistics gathered from Treebank. Different consistency checks are modeled for each of the heuristics.
                Example of the application of heuristic H2Pron Mr. Adams1 , 69 years old , is the retired chairman of
                Canadian-based Emco Ltd. , a maker of plumbing and petroleum equipment ; he1 has served on the Woolworth
                board since 1981. Example of the application of heuristic H3Pron `` We have got to stop pointing our
                fingers at these kids2 who have no future , '' he said , `` and reach our hands out to them2. Example of
                the application of heuristic H2Nom The chairman and the chief executive officer3 of Woolworth Corp. have
                temporarily relinquished their posts while the retailer conducts its investigation into alleged
                accounting irregularities4. Woolworth 's board named John W. Adams , an outsider , to serve as interim
                chairman and executive officer3 , while a special committee , appointed by the board last week and led
                by Mr. Adams , investigates the alleged irregularities4. Table 2 : Examples of coreference resolution.
                The same annotated index indicates coreference. The third class of heuristics resolves coreference by
                coercing nominals. Sometimes coercions involve only derivational morphology linking verbs with their
                nominalizations. On other occasions , coercions are obtained as paths of meronyms ( e.g. is-part
                relations ) and hypernyms ( e.g. is-a relations ) . Con144. sistency checks implemented for this class
                of coreference are conservative : either the adjuncts must be identical or the adjunct of the referent
                must be less specific than the antecedent. Table 1 lists the top performing heuristics of COCKTAIL for
                pronominal and nominal coreference. Examples of the heuristics operation on the MUC data are presented
                presented in Table 2. Details of the top performing heuristics of COCKTAIL were reported in ( Harabagiu
                and Maiorano , 1999 ) . Resolution One of the major drawbacks of existing coreference resolution systems
                is their inability to recognize many forms of coreference displayed by many real-world texts. Recall
                measures of current systems range between 36 % and 59 % for both knowledgebased and statistical
                techniques. Knowledge basedsystems would perform better if more coreference constraints were available
                whereas statistical methods would be improved if more annotated data were available. Since
                knowledge-based techniques outperform inductive methods , we used high-precision coreference heuristics
                as knowledge seeds for machine learning techniques that operate on large amounts of unlabeled data. One
                such technique is bootstrapping , which was recently presented in ( Riloff and Jones 1999 ) , ( Jones et
                a1.1999 ) as an ideal framework for text learning tasks that have knowledge seeds. The method does not
                require large training sets. We extended COCKTAIL by using metabootstrapping of both new heuristics and
                clusters of nouns that display semantic consistency for coreference. The coreference heuristics are the
                seeds of our bootstrapping framework for coreference resolution. When applied to large collections of
                texts , the heuristics determine classes of coreferring expressions. By generating coreference chains
                out of all these coreferring expressions , often new heuristics are uncovered. For example , Figure 2
                illustrates the application of three heuristics and the generation of data for a new heuristic rule. In
                COCKTAIL , after a heuristic is applied , a new coreference chain is calculated. For the example
                illustrated in Figure 2 , if the reference of expression A is sought , heuristic H1 indicates expression
                B to be the antecedent. When the coreference chain is built , expression A is directly linked to
                expression D , thus uncovering a new heuristic H0. As a rule of thumb , we do not consider a new
                heuristic unless there is massive evidence of its coverage in the data. To measure the coverage we use
                the FOIL_Gain measure , as introduced by the FOIL inductive algorithm ( Cameron-Jones and Quinlan 1993 )
                . Let Ho be the new heuristic and/-/1 a heuristic that is already in the seed set. Let P0 be the number
                of positive coreference examples of Hn~w ( i.e. the number of coreference relations produced by the
                heuristic that can be found in the test data ) and no the number of negative examples of/-/new ( i.e.
                the number of relations generated by the heuristic which can not be found in the test data ) . Similarly
                , Pl and nl are the positive and negative examples of Ha. The new heuristics are scored by their
                FOIL_Gain distance to the existing set of heuristics , and the best scoring one is added to the COCKTAIL
                system. The FOIL_Gain formula is : log2 -- -~ ) FOIL_Gain ( H1 , Ho ) = k ( log2 Pl nl Po -k no where k
                is the number of positive examples covered by both//1 and Ho. Heuristic Ho is added to the seed set if
                there is no other heuristic providing larger FOIL_Gain to any of the seed heuristics. H3.j ... ~IB B \ [
                ~ HO New Heuristic Figure 2 : Bootstrapping new heuristics. Since in COCKTAIL , semantic consistency of
                coreferring expressions is checked by comparing the similarity of noun classes , each new heuristic
                determines the adjustment of the similarity threshold of all known coreferring noun classes. The steps
                of the bootstrapping algorithm that learns both new heuristics and adjusts the similarity threshold of
                coreferential expressions is : MUTUAL BOOTSTRAPPING LOOP , f. Adjust semantic similarity threshold for
                semantic consistency o\ [ coreferring nouns degrade under minimal performance. ( Riloff and Jones 1999 )
                note that the bootstrapping algorithm works well but its performance can deteriorate rapidly when
                non-coreferring data enter as candidate heuristics. To make the algorithm more robust , a second level
                of bootstrapping can be introduced. The outer bootstrapping mechanism , called 145 recta-bootstrapping
                compiles the results of the inner ( mutual ) bootstrapping process and identifies the k most reliable
                heuristics , where k is a number determined experimentally. These k heuristics are retained and the rest
                of them are discarded. To study the performance of a data-driven multilingual coreference resolution
                system , we prepared a corpus of Romanian texts by translating the MUC-6 and MUC-7 coreference training
                texts. The translations were performed by a group of four Romanian native speakers , and were checked
                for style by a certified translator from Romania. In addition , the Romanian texts were annotated with
                coreference keys. Two rules were followed when the annotations were done : o 1 : Whenever an expression
                ER represents a translation of an expression EE from the corresponding English text , if Es is tagged as
                a coreference key with identification number ID , then the Romanian expression ER is also tagged with
                the same ID number. This rule allows for translations in which the textual position of the referent and
                the antecedent have been swapped. o2 : Since the translations often introduce new coreferring
                expressions in the same chain , the new expressions are given new , unused ID numbers. For example ,
                Table 3 lists corresponding English and Romanian fragments of coreference chains from the original MUC-6
                Wall Street Journal document DOCNO : 930729-0143. Table 3 also shows the original MUC coreference SGML
                annotations. Whenever present , the REF tag indicates the ID of the antecedent , whereas the MIN tag
                indicates the minimal reference expression. The multilingual coreference resolution method implemented
                in SWIZZLE incorporates the heuristics derived from COKCTAIL 's monolingual coreference resolution
                processing in both languages. To this end , COCKTAIL required both sets of texts to be tagged for
                part-of-speech and to recognize the noun phrases. The English texts were parsed with Brill 's
                part-ofspeech tagger ( Brill 1992 ) and the noun phrases were identified by the grammar rules
                implemented in the phrasal parser of FASTUS ( Appelt et al. , 1993 ) . Corresponding resources are not
                available in Romanian. To minimize COCKTAIL 's configuration for processing Romanian texts , we
                implemented a Romanian part-of-speech rule-based tagger that used the same Economic adviser Gene
                Sperling described &lt; COREF ID= '' 29 '' TYPE='IDENT '' REF- '' 30 '' &gt; it &lt; /COREF &gt; as `` a
                true full-court press '' to pass &lt; COREF ID= '' 31 '' TYPE= '' IDENT '' REF= '' 26 '' MIN='bilr '
                &gt; the &lt; COREF ID= '' 32 '' TYPE= '' IDENT '' REF -- -- - '' 10 '' MIN= '' reduction '' &gt; &lt;
                COREF ID= '' 33 '' TYPE= '' IDENT '' REF= '' 12 '' &gt; deficit &lt; /COREF &gt; -reduction &lt; /COREF
                &gt; bill , the final version of which is now being hammered out by &lt; COREF ID= '' 43 '' &gt; House
                &lt; /COREF &gt; and &lt; COREF ID= '' 41 '' &gt; Senate &lt; /COREF &gt; negotiators &lt; /COREF &gt; .
            </sentence>
            <definiendum id="0">node nk</definiendum>
            <definiendum id="1">l</definiendum>
            <definiendum id="2">MUC7</definiendum>
            <definiendum id="3">coreference heuristics</definiendum>
            <definiendum id="4">k</definiendum>
            <definiendum id="5">Ho. Heuristic Ho</definiendum>
            <definiendum id="6">k</definiendum>
            <definiendum id="7">expression ER</definiendum>
            <definiendum id="8">REF tag</definiendum>
            <definiendum id="9">TYPE= '' IDENT</definiendum>
            <definiens id="0">the possibility of expanding the test data provided by the coreference keys available in
                the MUC-6 and
            </definiens>
            <definiens id="1">7.21 for the MUC-6 data , and 8.57 for the MUC-7 data. We were able to expand the number
                of annotated coreference relations to 6,095,142 for the MUC-6 corpus and to 8,269,403 relations for the
                MUC-7 corpus
            </definiens>
            <definiens id="2">the set of heuristics implemented in COCKTAIL which cover both nominal and pronoun
                coreference. Each heuristic represents a pattern of coreference that was mined from the large set of
                coreference data. COCKTAIL uses knowledge-poor methods because ( a ) it is based only on a limited
                number of heuristics
            </definiens>
            <definiens id="3">personal , possessive , reflexive , demonstrative and relative ) and three forms of
                nominals ( definite , bare and indefinite )
            </definiens>
            <definiens id="4">distribution of the antecedents in the MUC annotated data. For example , repetitions of
                named entities and appositives account for the majority of the nominal coreferences , and
            </definiens>
            <definiens id="5">recognized to be semantically consistent. COCKTAIL 's test of semantic consistency blends
                together information available from WordNet and statistics gathered from Treebank. Different consistency
                checks
            </definiens>
            <definiens id="6">pronominal and nominal coreference. Examples of the heuristics operation on the MUC data
                are presented presented in Table 2. Details of the top performing heuristics of COCKTAIL were reported
                in ( Harabagiu and Maiorano , 1999 ) . Resolution One of the major drawbacks of existing coreference
                resolution systems is their inability to recognize many forms of coreference displayed by many
                real-world texts. Recall measures of current systems range between 36 % and 59 % for both knowledgebased
                and statistical techniques. Knowledge basedsystems would perform better if more coreference constraints
                were available whereas statistical methods would be improved if more annotated data were available.
                Since knowledge-based techniques outperform inductive methods
            </definiens>
            <definiens id="7">the number of coreference relations produced by the heuristic that can be found in the
                test data
            </definiens>
            <definiens id="8">the number of relations generated by the heuristic which can not be found in the test data
                ) . Similarly
            </definiens>
            <definiens id="9">the number of positive examples covered by both//1 and</definiens>
            <definiens id="10">MUTUAL BOOTSTRAPPING LOOP , f. Adjust semantic similarity threshold for semantic
                consistency o\ [ coreferring nouns degrade under minimal performance. ( Riloff and Jones 1999 ) note
                that the bootstrapping algorithm works well but its performance can deteriorate rapidly when
                non-coreferring data enter as candidate heuristics. To make the algorithm more robust , a second level
                of bootstrapping can be introduced. The outer bootstrapping mechanism , called 145 recta-bootstrapping
                compiles the results of the inner ( mutual ) bootstrapping process and identifies the k most reliable
                heuristics
            </definiens>
            <definiens id="11">a number determined experimentally. These k heuristics are retained and the rest of them
                are discarded. To study the performance of a data-driven multilingual coreference resolution system , we
                prepared a corpus of Romanian texts by translating the MUC-6 and MUC-7 coreference training texts. The
                translations were performed by a group of four Romanian native speakers
            </definiens>
            <definiens id="12">part-of-speech rule-based tagger that used the same Economic adviser Gene Sperling
                described &lt; COREF ID= '' 29 '' TYPE='IDENT '' REF- '' 30 '' &gt; it &lt; /COREF &gt; as `` a true
                full-court press '' to pass &lt; COREF ID= '' 31 '' TYPE= '' IDENT '' REF= '' 26 '' MIN='bilr ' &gt; the
                &lt; COREF ID= '' 32 '' TYPE= '' IDENT '' REF -- -- - '' 10 '' MIN= '' reduction '' &gt; &lt; COREF ID=
                '' 33 ''
            </definiens>
        </definition>
        <definition id="3">
            <sentence>WordNet : A Lexical Database .</sentence>
            <definiendum id="0">WordNet</definiendum>
        </definition>
    </paper>

    <paper id="2036">
        <definition id="0">
            <sentence>A context-free grammar ( CFG ) is a tuple G = ( VN , VT , P , S ) , where VN and VT are finite ,
                disjoint sets of nonterminal and terminal symbols , respectively , S E VN is the start symbol , and P is
                a finite set of productions having the form A -+ a , where A E VN and a E ( VN t3 VT ) * .
            </sentence>
            <definiendum id="0">context-free grammar ( CFG )</definiendum>
            <definiendum id="1">S E VN</definiendum>
            <definiendum id="2">P</definiendum>
            <definiens id="0">a tuple G = ( VN , VT , P , S ) , where VN and VT are finite , disjoint sets of
                nonterminal and terminal symbols , respectively ,
            </definiens>
            <definiens id="1">the start symbol</definiens>
            <definiens id="2">a finite set of productions having the form A -+ a , where A E VN and a E ( VN t3 VT ) *
            </definiens>
        </definition>
        <definition id="1">
            <sentence>If every production in P has the form A -- + BC or A -- + a , for A , B , C E VN , a E VT , then G
                is said to be in Chomsky Normal Form ( CNF ) .
            </sentence>
            <definiendum id="0">CNF</definiendum>
            <definiens id="0">the form A -- + BC or A -- + a , for A , B , C E VN , a E VT</definiens>
        </definition>
        <definition id="2">
            <sentence>A generic string over VT is denoted as w = al `` -an , with n _ &gt; 0 and ai E VT ( 1 &lt; i &lt;
                n ) ; in case n = 0 , w equals the empty string e. For integers i and j with 1 &lt; i &lt; j &lt; n , we
                write w\ [ i , j\ ] to denote string aiai+l '' .
            </sentence>
            <definiendum id="0">generic string over VT</definiendum>
            <definiens id="0">with n _ &gt; 0 and ai E VT ( 1 &lt; i &lt; n ) ; in case n = 0 , w equals the empty
                string e. For integers i
            </definiens>
        </definition>
        <definition id="3">
            <sentence>A recognizer for the CFG class is an algorithm R that , on input ( G , w ) , decides whether w E L
                ( G ) .
            </sentence>
            <definiendum id="0">recognizer for the CFG class</definiendum>
        </definition>
        <definition id="4">
            <sentence>No recognizer for bilexical context-free grammars that satisfies the CPP can run on input ( G , wl
                in an amount of time bounded by f ( \ [ VDI , \ [ W\ [ ) , where VD is the set of delexicatized
                nonterminals of G. Proof .
            </sentence>
            <definiendum id="0">VD</definiendum>
            <definiens id="0">the set of delexicatized nonterminals of G. Proof</definiens>
        </definition>
        <definition id="5">
            <sentence>A nondeterministic finite automaton ( FA ) is a tuple M = ( Q , E , 5 , q0 , F ) , where Q and P.
                are finite , disjoint sets of state and alphabet symbols , respectively , qo E Q and F _C Q are the
                initial state and the set of final states , respectively , and is a total function mapping Q x ~ to 2 Q
                , the powerset of Q. Function 5 represents the transitions of the automaton .
            </sentence>
            <definiendum id="0">nondeterministic finite automaton</definiendum>
            <definiendum id="1">FA )</definiendum>
            <definiens id="0">a tuple M = ( Q , E , 5 , q0 , F ) , where Q and P. are finite , disjoint sets of state
                and alphabet symbols , respectively , qo E Q and F _C Q are the initial state
            </definiens>
        </definition>
        <definition id="6">
            <sentence>Given a string w = al `` '' an , n &gt; O , an accepting computation in M for w is a sequence qo ,
                al , ql , a2 , q2 ... . , an , q , , such that qi E 5 ( qi-l , ai ) for 1 &lt; i &lt; n , and q~ E F.
                The languageL ( M ) is the set of all strings in E* that admit at least one accepting computation in M.
                The size of M is defined as \ ] M\ ] = ~qeQ , ae~ I~ ( q , a ) l. The automaton M is deterministic if ,
                for every q E Q and a E ~ , we have IS ( q , a ) \ ] = 1. We call quasi-determinizer any algorithm A
                that satisfies the following two conditions : ( Q , ~ , 5 , qo , F ) and produces as output a device DM
                that , when given a string w as input , decides whether w E L ( M ) ; and 2More precisely , the running
                time for these algorithms is O ( IVDI 3 Iw\ [ 3min { \ [ VT\ [ , \ [ w\ [ } ) . In cases of practical
                interest , we always have Iw\ [ &lt; IVT\ [ . DM runs in an amount of time bounded by PA ( Iwl ) . We
                remark that , given a nondeterministic FA M specified as above , known algorithms allow simulation of M
                on an input string w in time O ( IM I IwI ) ( see for instance ( Aho et al. , 1974 , Thin. 9.5 ) or (
                Sippu and Soisalon-Soininen , 1988 , Thm. 3.38 ) ) . In contrast , a quasi-determinizer produces a
                device that simulates M in an amount of time independent of the size of M itself. A standard example of
                a quasi-determinizer is the so called power-set construction , used to convert a nondeterministic FA
                into a language-equivalent deterministic FA ( see for instance ( Hopcroft and Ullman , 1979 , Thin. 2.1
                ) or ( Sippu and SoisalonSoininen , 1988 , Thm. 3.30 ) ) . In fact , there exist constants c and d such
                that any deterministic FA can be simulated on input string w in an amount of time bounded by c \ ] w I +
                d. This requires function to be stored as a IQ\ ] x \ ] El , 2-dimensional array with values in Q. This
                is a standard representation for automata-like structures ; see ( Gusfield , 1997 , : Sect. We now pose
                the question of the time efficiency of a quasi-determinizer , and consider the amount of time needed in
                the construction of DM. In ( Meyer and Fisher , 1971 ; Stearns and Hunt , 1981 ) it is shown that there
                exist ( infinitely many ) nondeterministic FAs with state set Q , such that any language-equivalent
                deterministic FA must have at least 2 IQ } states. This means that the power-set construction can not
                work in polynomial time in the size of the input FA. Despite of much effort , no algorithm has been
                found , up to the authors ' knowledge , that can simulate a nondeterministic FA on an input string w in
                linear time in ' Iwl and independently of IMI , if only polynomial-time precompilation of M is allowed.
                Even in case we relax the linear-time restriction and consider recognition of w in polynomial time , for
                some fixed polynomial , it seems unlikely that the problem can be solved if only polynomialtime
                precompilation of M is allowed. Furthermore , if we consider precompilation of nondeterministic FAs into
                `` partially determinized '' FAs that would allow recognition in polynomial ( or even exponential ) time
                in Iw\ ] , it seems unlikely that the analysis required for this precompilation could consider less than
                exponentially many combinations of states that may be active at the same time for the original
                nondeterministic FA. Finally , although more powerful formalisms have been shown to represent some
                regular languages much more succinctly than FAs ( Meyer and Fisher , 1971 ) , while allowing
                polynomial-time parsing , it seem unlikely that this could hold for regular languages in general. 275
                Conjecture There is no quasi-determinizer that works in polynomial time in the size of the input
                automaton. Before turning to our main result , we need to develop some additional machinery. Let M = ( Q
                , E,6 , qo , F ) be a nondeterministic FA and let w = al..-an E L ( M ) , where n &gt; 0 .
            </sentence>
            <definiendum id="0">DM</definiendum>
            <definiens id="0">a sequence qo , al , ql , a2 , q2 ... . , an , q , , such that qi E 5 ( qi-l , ai ) for 1
                &lt; i &lt; n , and q~ E F. The languageL ( M ) is the set of all strings in E* that admit at least one
                accepting computation in M. The size of M is defined as \ ] M\ ] = ~qeQ , ae~ I~
            </definiens>
            <definiens id="1">deterministic if , for every q E Q and a E ~ , we have IS ( q , a ) \ ] = 1. We call
                quasi-determinizer any algorithm A that satisfies the following two conditions : ( Q , ~ , 5 , qo , F )
                and produces as output a device DM that , when given a string w as input , decides whether w E L ( M )
            </definiens>
            <definiens id="2">runs in an amount of time bounded by PA ( Iwl ) . We remark that , given a
                nondeterministic FA M specified as above , known algorithms allow simulation of M on an input string w
                in time O ( IM I IwI ) ( see for instance ( Aho et al. , 1974 , Thin. 9.5 ) or ( Sippu and
                Soisalon-Soininen , 1988 , Thm. 3.38 ) ) . In contrast , a quasi-determinizer produces a device that
                simulates M in an amount of time independent of the size of M itself. A standard example of a
                quasi-determinizer is the so called power-set construction , used to convert a nondeterministic FA into
                a language-equivalent deterministic FA ( see for instance ( Hopcroft and Ullman , 1979 , Thin. 2.1 ) or
                ( Sippu and SoisalonSoininen , 1988 , Thm. 3.30 ) ) . In fact , there exist constants c and d such that
                any deterministic FA can be simulated on input string w in an amount of time bounded by c \ ] w I + d.
                This requires function to be stored as a IQ\ ] x \ ] El , 2-dimensional array with values in Q. This is
                a standard representation for automata-like structures ; see ( Gusfield , 1997 , : Sect. We now pose the
                question of the time efficiency of a quasi-determinizer , and consider the amount of time needed in the
                construction of DM. In ( Meyer and Fisher , 1971 ; Stearns and Hunt , 1981 ) it is shown that there
                exist ( infinitely many ) nondeterministic FAs with state set Q , such that any language-equivalent
                deterministic FA must have at least 2 IQ } states. This means that the power-set construction can not
                work in polynomial time in the size of the input FA. Despite of much effort , no algorithm has been
                found , up to the authors ' knowledge , that can simulate a nondeterministic FA on an input string w in
                linear time in ' Iwl and independently of IMI , if only polynomial-time precompilation of M is allowed.
                Even in case we relax the linear-time restriction and consider recognition of w in polynomial time , for
                some fixed polynomial
            </definiens>
            <definiens id="3">combinations of states that may be active at the same time for the original
                nondeterministic FA. Finally , although more powerful formalisms have been shown to represent some
                regular languages much more succinctly than FAs ( Meyer and Fisher
            </definiens>
            <definiens id="4">regular languages in general. 275 Conjecture There is no quasi-determinizer that works in
                polynomial time in the size of the input automaton. Before turning to our main result , we need to
                develop some additional machinery. Let M = ( Q , E,6 , qo , F ) be a nondeterministic FA and let w =
                al..-an E L ( M ) , where n &gt; 0
            </definiens>
        </definition>
        <definition id="7">
            <sentence>A recognizer for the CFG class is an algorithm R that has random access to some data structure C (
                G ) obtained by means of some off-line precompilation of a CFG G. On input w , which is a string on the
                terminal symbols of G , R decides whether w E L ( G ) .
            </sentence>
            <definiendum id="0">recognizer for the CFG class</definiendum>
            <definiens id="0">an algorithm R that has random access to some data structure C ( G ) obtained by means of
                some off-line precompilation of a CFG G. On input w
            </definiens>
            <definiens id="1">a string on the terminal symbols of G , R decides whether w E L ( G )</definiens>
        </definition>
        <definition id="8">
            <sentence>276 ( i ) has random access to data structure C ( G ) precompiled from a bilexical CFG G in
                polynomial time in IGI , ( ii ) runs in an amount of time bounded by p ( IVDI , Iwl ) , where VD is the
                set of delexicalized nonterminals of G and w is the input string , and ( iii ) satisfies the CPP .
            </sentence>
            <definiendum id="0">VD</definiendum>
            <definiendum id="1">w</definiendum>
            <definiens id="0">random access to data structure C ( G ) precompiled from a bilexical CFG G in polynomial
                time in IGI
            </definiens>
            <definiens id="1">the set of delexicalized nonterminals of G and</definiens>
        </definition>
        <definition id="9">
            <sentence>The recognition algorithm consists in an incremental construction of a ( n + 1 ) x ( n + 1 ) ,
                2-dimensional table T , where n is the length of the input string .
            </sentence>
            <definiendum id="0">recognition algorithm</definiendum>
            <definiendum id="1">n</definiendum>
            <definiens id="0">consists in an incremental construction of a ( n + 1 ) x ( n + 1 ) , 2-dimensional table T
                , where
            </definiens>
            <definiens id="1">the length of the input string</definiens>
        </definition>
    </paper>

    <paper id="1039">
        <definition id="0">
            <sentence>The task of Information Extraction ( I-E ) is the selective extraction of meaning from free
                natural language text .
            </sentence>
            <definiendum id="0">Information Extraction ( I-E )</definiendum>
            <definiens id="0">the selective extraction of meaning from free natural language text</definiens>
        </definition>
        <definition id="1">
            <sentence>The idea is to consider those candidate patterns , p , which meet the density , criterion : IHnRI
                IRI -- &gt; &gt; IHnUI IUI where H = H ( p ) is the set of documents where p hits .
            </sentence>
            <definiendum id="0">p</definiendum>
            <definiens id="0">meet the density , criterion : IHnRI IRI -- &gt;</definiens>
            <definiens id="1">the set of documents where p hits</definiens>
        </definition>
        <definition id="2">
            <sentence>During a single iteration , we compute the score s , L ( p ) , for each candidate pattern p : L (
                p ) = Pc ( P ) '' log { H A R\ ] ( 1 ) where R denotes the relevant subset , and H -H ( p ) the
                documents matching p , as above , and \ [ gnR\ [ Pc ( P ) -Igl is the conditional probability of
                relevance .
            </sentence>
            <definiendum id="0">R</definiendum>
            <definiens id="0">the score s , L ( p ) , for each candidate pattern p : L ( p ) = Pc ( P ) '' log { H A R\
                ] ( 1 ) where
            </definiens>
            <definiens id="1">the relevant subset , and H -H ( p ) the documents matching p , as above , and \ [ gnR\ [
                Pc ( P ) -Igl is the conditional probability of relevance
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Preci+l ( p ) = 1 { H ( p ) { ~ Reli ( d ) ( 2 ) dEH ( p ) where Reli ( d ) is the relevance of
                the document from the previous iteration , and H ( p ) is the set of documents where p matched .
            </sentence>
            <definiendum id="0">dEH</definiendum>
        </definition>
        <definition id="4">
            <sentence>More generally , if K is a classifier consisting of a set of patterns , we can define H ( K ) as
                the set of documents where all of patterns p E K match , and the `` cumulative '' precision 11 of K as
                Preci+l ( K ) = 1 ~ Reli ( d ) ( 3 ) IH ( K ) \ [ riCH ( K ) Once the new winning pattern is accepted ,
                the relevance scores of the documents are readjusted as follows .
            </sentence>
            <definiendum id="0">Reli</definiendum>
            <definiendum id="1">IH</definiendum>
            <definiens id="0">a classifier consisting of a set of patterns</definiens>
            <definiens id="1">the set of documents where all of patterns p E K match</definiens>
        </definition>
        <definition id="5">
            <sentence>Considering recall and precision separately , the discovery procedure attains values comparable to
                those achieved by some of the participants , all of which were either heavily-supervised or manually
                coded systems .
            </sentence>
            <definiendum id="0">discovery procedure</definiendum>
            <definiens id="0">attains values comparable to those achieved by some of the participants , all of which
                were either heavily-supervised or manually coded systems
            </definiens>
        </definition>
    </paper>

    <paper id="2017">
        <definition id="0">
            <sentence>=lPr ( wi\ [ hi ) where hi is the relevant history when predicting wi .</sentence>
            <definiendum id="0">hi</definiendum>
            <definiens id="0">the relevant history when predicting wi</definiens>
        </definition>
        <definition id="1">
            <sentence>In this view , the feature space consists of simple functions ( e.g. , n-grams ) over the the
                original data so as to allow for expressive enough representations using a simple functional form ( e.g.
                , a linear function ) .
            </sentence>
            <definiendum id="0">feature space</definiendum>
            <definiens id="0">consists of simple functions ( e.g. , n-grams ) over the the original data so as to allow
                for expressive enough representations using a simple functional form ( e.g. , a linear function )
            </definiens>
        </definition>
        <definition id="2">
            <sentence>Example 2 Let s be the sentence &lt; John , X , at , the , clock , to , see , what , time , it ,
                is &gt; Let ~= { word , pos , subj-verb } , with the interpretation that word is a unary predicate that
                returns the value of the word in its domain ; pos is a unary predicate that returns the value of the pos
                of the word in its domain , in the context of the sentence ; subjverb is a binary predicate that returns
                the value of the two words in its domain if the second is a verb in the sentence and the first is its
                subject ; it returns ¢ otherwise .
            </sentence>
            <definiendum id="0">; subjverb</definiendum>
            <definiens id="0">a unary predicate that returns the value of the pos of the word in its domain , in the
                context of the sentence
            </definiens>
            <definiens id="1">a verb in the sentence and the first is its subject ; it returns ¢ otherwise</definiens>
        </definition>
        <definition id="3">
            <sentence>SIS ( s ) ) , the Structural Information source ( s ) available for the sentence s , is a tuple (
                s , E1 , ... , Ek ) of directed acyclic graphs with s as the set of vertices and Ei 's , a set of edges
                in s. Example 6 ( Linear Structure ) The simplest SIS is the one corresponding to the linear structure
                of the sentence .
            </sentence>
            <definiendum id="0">SIS</definiendum>
            <definiendum id="1">Structural Information</definiendum>
            <definiens id="0">source ( s ) available for the sentence s , is a tuple ( s , E1 , ... , Ek ) of directed
                acyclic graphs with s as the set of vertices and Ei 's , a set of edges in s. Example 6 ( Linear
                Structure
            </definiens>
        </definition>
        <definition id="4">
            <sentence>Definition 8 ( Collocation ) Let fl , ... fk be feature definitions , col locc ( f l , f 2 , . . .
                f k ) is a restricted conjunctive operator that is evaluated on a chain C of length k in a graph .
            </sentence>
            <definiendum id="0">Collocation</definiendum>
            <definiendum id="1">col locc</definiendum>
            <definiendum id="2">f k )</definiendum>
            <definiens id="0">a restricted conjunctive operator that is evaluated on a chain C of length k in a graph
            </definiens>
        </definition>
        <definition id="5">
            <sentence>DG ( s ) described the dependency graph of the sentence s. An edge ( wi , wj ) in DG ( s )
                represent a dependency between the two words .
            </sentence>
            <definiendum id="0">DG</definiendum>
            <definiens id="0">s ) described the dependency graph of the sentence s. An edge ( wi , wj ) in DG ( s )
                represent a dependency between the two words
            </definiens>
        </definition>
        <definition id="6">
            <sentence>The SNo W architecture is a sparse network of linear units over a common pre-defined or
                incrementally learned feature space .
            </sentence>
            <definiendum id="0">SNo W architecture</definiendum>
            <definiens id="0">a sparse network of linear units over a common pre-defined or incrementally learned
                feature space
            </definiens>
        </definition>
    </paper>

    <paper id="2043">
        <definition id="0">
            <sentence>Fhrthermore , we take advantage of the powerful inference engine of DL systems , the description
                classifier , which turns out to be essential for embedded reasoning during the semantic interpretation
                process .
            </sentence>
            <definiendum id="0">description classifier</definiendum>
            <definiens id="0">turns out to be essential for embedded reasoning during the semantic interpretation
                process
            </definiens>
        </definition>
        <definition id="1">
            <sentence>For instance , Bean et al. ( 1998 ) narrow semantic interpretation down to a very limited range of
                spatial relations in anatomy , while Gomez et al. ( 1997 ) bias the result by preselecting only those
                phrases that were already covered by their domain models , thus optimizing for precision while shunting
                aside recall considerations .
            </sentence>
            <definiendum id="0">domain models</definiendum>
            <definiens id="0">narrow semantic interpretation down to a very limited range of spatial relations in
                anatomy
            </definiens>
        </definition>
    </paper>

    <paper id="3001">
        <definition id="0">
            <sentence>Another type of center transition that appears frequently in museum descriptions is associate
                shifting , where the description starts with an object and then moves to a closely associated object or
                perspectives of that object .
            </sentence>
            <definiendum id="0">center transition</definiendum>
            <definiens id="0">associate shifting , where the description starts with an object and then moves to a
                closely associated object or perspectives of that object
            </definiens>
        </definition>
        <definition id="1">
            <sentence>A good embedding is one satisfying all following conditions : a demonstrative or a bridging
                description ( as defined in ( Poesio et al. , 1997 ) ) .
            </sentence>
            <definiendum id="0">good embedding</definiendum>
            <definiens id="0">a demonstrative or a bridging description</definiens>
        </definition>
        <definition id="2">
            <sentence>A bad embedding consists of all those left .</sentence>
            <definiendum id="0">bad embedding</definiendum>
            <definiens id="0">consists of all those left</definiens>
        </definition>
    </paper>

    <paper id="1002">
    </paper>

    <paper id="1041">
        <definition id="0">
            <sentence>The information retrieval stage consists of a 296 single component , passage retrieval , and the
                linguistic processing stage circumscribes four components : entity extraction , entity classification ,
                query classification , and entity ranking .
            </sentence>
            <definiendum id="0">information retrieval stage</definiendum>
        </definition>
        <definition id="1">
            <sentence>Entity Extraction Extract a candidate set of possible answers from the passages .</sentence>
            <definiendum id="0">Entity Extraction Extract</definiendum>
        </definition>
        <definition id="2">
            <sentence>In some cases ( dates , quantities , linear measures ) , entity classification is a side effect of
                entity extraction , but in other cases ( proper nouns , which may be people , locations , or
                organizations ) , there is a separate classification step after extraction .
            </sentence>
            <definiendum id="0">entity classification</definiendum>
            <definiens id="0">a side effect of entity extraction , but in other cases ( proper nouns , which may be
                people , locations , or organizations
            </definiens>
        </definition>
        <definition id="3">
            <sentence>The score for passage i was calculated as 1 ¼Si-z + ½Si + ~ 'S , +1 ( 1 ) where Sj , the score for
                sentence j , is the sum of IDF weights of non-stop terms that it shares with the query , plus an
                additional bonus for pairs of words ( bigrams ) that the sentence and query have in common .
            </sentence>
            <definiendum id="0">Sj</definiendum>
            <definiens id="0">the sum of IDF weights of non-stop terms that it shares with the query , plus an
                additional bonus for pairs of words ( bigrams ) that the sentence
            </definiens>
        </definition>
    </paper>

    <paper id="1032">
        <definition id="0">
            <sentence>This string is known as graphic word which is defined as `` a string of contiguous alphanumeric
                characters with space on either side ; may include hyphens and apostrophes , but no other punctuation
                marks '' ( Ku~era and Francis , 1967 ) .
            </sentence>
            <definiendum id="0">graphic word</definiendum>
        </definition>
        <definition id="1">
            <sentence>The morpho-fragments ( MFs ) of a language is defined as the smallest set of strings of the
                alphabet which can compose all lexemes in the dictionary .
            </sentence>
            <definiendum id="0">The morpho-fragments ( MFs ) of a language</definiendum>
        </definition>
        <definition id="2">
            <sentence>~/Noun ( sidewalk ) I ~• -- , :~/Noun ( footbridge ) LXS NSP NOR MF Figure 3 : Japanese Trie
                Structured Dictionary Segmentation POS Tagging Analysis Time ( Recall / Precision ) ( Recall / Precision
                ) ( Ratio ) 100 96.98 1.0 99.52 / 99.67 96.52 / 96.69 4.3 99.87 / 99.91 96.84 / 96.88 4.2 99.88 / 99.93
                96.85 / 96.91 1.4 Table 1 : Results of Experiments characters and lexemes ( see Figure 1 and Figure 2 )
                .
            </sentence>
            <definiendum id="0">Precision )</definiendum>
            <definiens id="0">Japanese Trie Structured Dictionary Segmentation POS Tagging Analysis Time ( Recall /
                Precision ) ( Recall /
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Though Korean sentences are separated by spaces into phrasal segments , Korean is a non-segmented
                language essentially , since each phrasal segment does not have lexeme boundaries .
            </sentence>
            <definiendum id="0">Korean</definiendum>
            <definiens id="0">separated by spaces into phrasal segments</definiens>
        </definition>
    </paper>

    <paper id="1019">
        <definition id="0">
            <sentence>TRANSTYPE is part of a project set up to explore an appealing solution to Interactive Machine
                Translation ( IMT ) .
            </sentence>
            <definiendum id="0">TRANSTYPE</definiendum>
        </definition>
        <definition id="1">
            <sentence>The core of TRANSTYPE is a completion engine which comprises two main parts : an evaluator which
                assigns probabilistic scores to completion hypotheses and a generator which uses the evaluation function
                to select the best candidate for completion .
            </sentence>
            <definiendum id="0">core of TRANSTYPE</definiendum>
            <definiens id="0">a completion engine which comprises two main parts : an evaluator which assigns
                probabilistic scores to completion hypotheses and a generator which uses the evaluation function to
                select the best candidate for completion
            </definiens>
        </definition>
        <definition id="2">
            <sentence>The evaluator is a function p ( t\ [ t ' , s ) which assigns to each target-text unit t an
                estimate of its probability given a source text s and the tokens t ' which precede t in the current
                translation of s. 1 Our approach to modeling this distribution is based to a large extent on that of the
                IBM group ( Brown et al. , 1993 ) , but it differs in one significant aspect : whereas the IBM model
                involves a `` noisy channel '' decomposition , we use a linear combination of separate predictions from
                a language model p ( tlt ~ ) and a translation model p ( tls ) .
            </sentence>
            <definiendum id="0">evaluator</definiendum>
        </definition>
        <definition id="3">
            <sentence>voil~ ce que • qu ' est c ' est • , et • le premier ministre disait Table 2 : Role of the
                generator for a sample pair of sentences ( t is the translation of s in our corpus ) .
            </sentence>
            <definiendum id="0">t</definiendum>
            <definiens id="0">the translation of s in our corpus )</definiens>
        </definition>
        <definition id="4">
            <sentence>In this work , the strength of association of a sequence of words w\ [ = wl , ... , wn is computed
                by two measures : a likelihood-based one p ( w'~ ) ( where g is the likelihood ratio given in ( Dunning
                , 93 ) ) and an entropy-based one e ( w'~ ) ( Shimohata et al. , 1997 ) .
            </sentence>
            <definiendum id="0">g</definiendum>
            <definiens id="0">the strength of association of a sequence of words w\ [ = wl , ... , wn is computed by two
                measures : a likelihood-based one p ( w'~ )
            </definiens>
        </definition>
        <definition id="5">
            <sentence>In E3 any parameter of the model that involves a token is removed ( that is , p ( tls ) = 0 if t
                or s is a token ) .
            </sentence>
            <definiendum id="0">s</definiendum>
            <definiens id="0">a token )</definiens>
        </definition>
        <definition id="6">
            <sentence>Acknowlegments TRANSTYPE is a project funded by the Natural Sciences and Engineering Research
                Council of Canada .
            </sentence>
            <definiendum id="0">Acknowlegments TRANSTYPE</definiendum>
            <definiens id="0">a project funded by the Natural Sciences and Engineering Research Council of Canada
            </definiens>
        </definition>
    </paper>

    <paper id="2007">
        <definition id="0">
            <sentence>In memory-based learning the training data is stored and a new item is classified by the most
                frequent classification among training items which are closest to this new item .
            </sentence>
            <definiendum id="0">memory-based learning</definiendum>
            <definiens id="0">the training data is stored and a new item is classified by the most frequent
                classification among training items which are closest to this new item
            </definiens>
        </definition>
        <definition id="1">
            <sentence>The fourth method uses the tag precision weights as well but it subtracts from them the recall
                values of the competing classifier results .
            </sentence>
            <definiendum id="0">fourth method</definiendum>
        </definition>
        <definition id="2">
            <sentence>The first processing stage ( top ) contains a word and POS context of four left and four right
                while the second processing stage ( bottom ) contains a word and POS context of three and a chunk tag
                context of two .
            </sentence>
            <definiendum id="0">POS</definiendum>
            <definiens id="0">contains a word and POS context of three and a chunk tag context of two</definiens>
        </definition>
        <definition id="3">
            <sentence>Majority voting outperforms all earlier reported results for the two data sets .</sentence>
            <definiendum id="0">Majority voting</definiendum>
        </definition>
    </paper>

    <paper id="2031">
    </paper>

    <paper id="1001">
        <definition id="0">
            <sentence>A system is developed that can answer queries about bus routes , stated as natural language texts
                , and made public through the Internet World Wide Web is a myth that natural language is a better way of
                communication because it is `` natural language '' .
            </sentence>
            <definiendum id="0">Internet World Wide Web</definiendum>
            <definiens id="0">a myth that natural language is a better way of communication because it is `` natural
                language ''
            </definiens>
        </definition>
        <definition id="1">
            <sentence>HSQL produced a Prolog-like code FOL ( First Order Logic ) for execution .</sentence>
            <definiendum id="0">HSQL</definiendum>
            <definiens id="0">produced a Prolog-like code FOL ( First Order Logic ) for execution</definiens>
        </definition>
    </paper>

    <paper id="1025">
        <definition id="0">
            <sentence>The Baseline QA System : The Smart Vector Space Model .</sentence>
            <definiendum id="0">Baseline QA System</definiendum>
            <definiens id="0">The Smart Vector Space Model</definiens>
        </definition>
        <definition id="1">
            <sentence>Given a question , Smart returns a ranked list of the documents most relevant to the question .
            </sentence>
            <definiendum id="0">Smart</definiendum>
            <definiens id="0">returns a ranked list of the documents most relevant to the question</definiens>
        </definition>
        <definition id="2">
            <sentence>The filter operates on the ordered list of summary extracts for a particular question and produces
                a list of answer hypotheses , one for each noun phrase ( NP ) in the extracts in the left-to-right order
                in which they appeared .
            </sentence>
            <definiendum id="0">NP</definiendum>
            <definiens id="0">in the extracts in the left-to-right order in which they appeared</definiens>
        </definition>
        <definition id="3">
            <sentence>The weight w ( E ) is a number between 0 and 1 that is based on the retrieval rank r of the
                document that contains E : w ( E ) = max ( m , 1 p. r ) In our experiments , m = 0.5 and p = 0.1 .
            </sentence>
            <definiendum id="0">weight w ( E )</definiendum>
            <definiens id="0">a number between 0 and 1 that is based on the retrieval rank r of the document that
                contains E : w ( E ) = max
            </definiens>
        </definition>
        <definition id="4">
            <sentence>In addition , SyncMatcher uses a broad-coverage dependency parser to enforce phrase relationship
                constraints .
            </sentence>
            <definiendum id="0">SyncMatcher</definiendum>
            <definiens id="0">uses a broad-coverage dependency parser to enforce phrase relationship constraints
            </definiens>
        </definition>
        <definition id="5">
            <sentence>WordNet : An Electronical Lexiced Database .</sentence>
            <definiendum id="0">WordNet</definiendum>
        </definition>
        <definition id="6">
            <sentence>MURAX : A Robust Linguistic approach For Question Answering Using An On-Line Encyclopedia .
            </sentence>
            <definiendum id="0">MURAX</definiendum>
            <definiens id="0">A Robust Linguistic approach For Question Answering Using An On-Line Encyclopedia
            </definiens>
        </definition>
        <definition id="7">
            <sentence>LASSO : A Tool for Surfing the Answer Net .</sentence>
            <definiendum id="0">LASSO</definiendum>
        </definition>
    </paper>

    <paper id="2020">
        <definition id="0">
            <sentence>Our distribution for the data , D , is then : D - ( 1 A ) M + AA ( I ) where M is the majority
                distribution , and A is the anomalous distribution .
            </sentence>
            <definiendum id="0">M</definiendum>
            <definiendum id="1">A</definiendum>
            <definiens id="0">the majority distribution</definiens>
        </definition>
        <definition id="1">
            <sentence>Typically M is a structured distribution which is estimated over the data using a machine learning
                technique , while A is a uniform ( random ) distribution representing elements which do not fit into M.
                In the corpus error detection problem , we are assuming that for each tag in the corpus with probability
                ( 1 A ) the human annotator markes the corpus with the correct tag and with probability A the human
                annotator makes an error .
            </sentence>
            <definiendum id="0">M</definiendum>
            <definiens id="0">a structured distribution which is estimated over the data using a machine learning
                technique
            </definiens>
            <definiens id="1">assuming that for each tag in the corpus with probability ( 1 A ) the human annotator
                markes the corpus with the correct tag and with probability A the human annotator makes an error
            </definiens>
        </definition>
        <definition id="2">
            <sentence>The likelihood , L , of distribution D with probability function P over elements Xl , ... , XN is
                defined as follows : N L ( D ) = l'I PD ( Xi ) = ( 2 ) i -- -- -1 Since the product of small numbers is
                difficult to compute , we instead compute the log likelihood , LL .
            </sentence>
            <definiendum id="0">, XN</definiendum>
            <definiendum id="1">l'I PD ( Xi )</definiendum>
            <definiendum id="2">LL</definiendum>
            <definiens id="0">probability function P over elements Xl , ...</definiens>
        </definition>
        <definition id="3">
            <sentence>Sparse Markov transducers compute probabilistic mappings over sparse data .</sentence>
            <definiendum id="0">Sparse Markov transducers</definiendum>
        </definition>
        <definition id="4">
            <sentence>A Markov transducer of order L is the conditional probability distribution of the form : P ( Yt\ [
                XtXt_lXt_2Xt_3 ... Xt_ ( L_l ) ) ( 4 ) where Xk are random variables over the input alphabet Ei , ~ and
                Yk is a random variable over the output alphabet Eout .
            </sentence>
            <definiendum id="0">Yk</definiendum>
            <definiens id="0">the conditional probability distribution of the form : P ( Yt\ [ XtXt_lXt_2Xt_3 ... Xt_ (
                L_l ) ) ( 4 ) where Xk are random variables over the input alphabet Ei
            </definiens>
            <definiens id="1">a random variable over the output alphabet Eout</definiens>
        </definition>
        <definition id="5">
            <sentence>A sparse Markov transducer is a conditional probability of the form : ( 5 ) where ¢ represents a
                wild card symbol and ti = t~=lnJ ( i1 ) .
            </sentence>
            <definiendum id="0">sparse Markov transducer</definiendum>
        </definition>
    </paper>

    <paper id="1005">
        <definition id="0">
            <sentence>Each template is an internal representation of a part in the database .</sentence>
            <definiendum id="0">template</definiendum>
            <definiens id="0">an internal representation of a part in the database</definiens>
        </definition>
        <definition id="1">
            <sentence>The DM receives as input from the filler the set of templates which are checked off .</sentence>
            <definiendum id="0">DM</definiendum>
            <definiens id="0">receives as input from the filler the set of templates which are checked off</definiens>
        </definition>
        <definition id="2">
            <sentence>If there are more than 4 templates in the joint intersection , the DM ranks the templates based
                upon word overlap with the description words uttered by the user .
            </sentence>
            <definiendum id="0">DM</definiendum>
            <definiens id="0">ranks the templates based upon word overlap with the description words uttered by the
                user
            </definiens>
        </definition>
        <definition id="3">
            <sentence>If the joint intersection is empty , or in the highly unlikely case of there being more than 4
                top-ranked templates in ( 7 ) , the DM asks the user to enter additional disambiguating information .
            </sentence>
            <definiendum id="0">DM</definiendum>
            <definiens id="0">asks the user to enter additional disambiguating information</definiens>
        </definition>
        <definition id="4">
            <sentence>The DM , in this case , takes a union of the sets of parts corresponding to the description
                fiwords thereby ensuring that the template corresponding to the desired part is in the union .
            </sentence>
            <definiendum id="0">DM</definiendum>
            <definiens id="0">takes a union of the sets of parts corresponding to the description fiwords thereby
                ensuring that the template corresponding to the desired part is in the union
            </definiens>
        </definition>
        <definition id="5">
            <sentence>The presentation module works in one of two possible modes : over the phone , and over the web .
            </sentence>
            <definiendum id="0">presentation module</definiendum>
            <definiens id="0">works in one of two possible modes : over the phone , and over the web</definiens>
        </definition>
        <definition id="6">
            <sentence>Bagga , A. , Stein G. C. , and Strzalkowski , T. ( 2000 ) FidelityXPress : A Multi-Modal System
                for Financial Transactions .
            </sentence>
            <definiendum id="0">FidelityXPress</definiendum>
            <definiens id="0">A Multi-Modal System for Financial Transactions</definiens>
        </definition>
    </paper>

    <paper id="2041">
        <definition id="0">
            <sentence>While previous approaches to robust interpretation have offered robust parsers paired with
                separate repair modules~ with separate knowledge sources for each , AUTOSEM is a single unified
                framework that can operate both at parse time and repair time .
            </sentence>
            <definiendum id="0">AUTOSEM</definiendum>
            <definiens id="0">a single unified framework that can operate both at parse time and repair time</definiens>
        </definition>
        <definition id="1">
            <sentence>Time ( : type &lt; cancel &gt; : isa ( &lt; *event &gt; ) : instances nil : vats ( agent activity
                time polarity ) : spec ( ( frame *cancel ) ( engagement &lt; *event &gt; activity ) ) ) Figure 2 :
                Meaning representation definition of &lt; cancel &gt; ( : morph cancel : syntax ( ( cat vlex ) ( root
                cancel ) ( vform bare ) ( irreg-past + ) ( irreg-pastpart + ) ( irreg-prespart + ) ( subcat ( *or*
                intrans np ) ) ( semtag cancel1 ) ) : semantics ( cancel1 &lt; cancel &gt; ( ( subject agent ) ( object
                activity ) ( tempadjunct time ) ( negation polarity ) ) ) ) Figure 3 : Lexical entry for the verb ``
                cancel '' As an extension to LCFLEx 's LFG-like pseudounification grammar formalism , AUTOSEM provides
                the insert-role function as an interface to allow semantic interpretation to operate in parallel with
                syntactic interpretation at parse time .
            </sentence>
            <definiendum id="0">Time</definiendum>
            <definiens id="0">irreg-past + ) ( irreg-pastpart + ) ( irreg-prespart + ) ( subcat ( *or* intrans np ) ) (
                semtag cancel1 ) ) : semantics ( cancel1 &lt; cancel &gt; ( ( subject agent ) ( object activity ) (
                tempadjunct time ) ( negation polarity
            </definiens>
            <definiens id="1">Lexical entry for the verb `` cancel '' As an extension to LCFLEx 's LFG-like
                pseudounification grammar formalism , AUTOSEM provides the insert-role function as an interface to allow
                semantic interpretation to operate in parallel with syntactic interpretation at parse time
            </definiens>
        </definition>
        <definition id="2">
            <sentence>Functions : ( &lt; SCHEDULE &gt; NIL T NIL NIL NIL NIL NIL NIL T NIL NIL : STR ( ( FRAME *SCHEDULE
                ) ( ATTITUDE *LET-S ) ( WHAT ( ( FRAME *IT ) ) ) ) : COV ( 6 5 4 3 2 1 ) : SCORE 1.4012985e-45 ) ( &lt;
                SCHEDULE &gt; NIL T NIL NIL NIL T T NIL NIL NIL NIL : STR ( ( FRAME *SCHEDULE ) ( WHAT ( ( FRAME *IT ) )
                ) ( NEGATIVE + ) ( WHO ( ( FRAME *WE ) ) ) ) : COV ( 6 5 4 3 2 ) : SCORE 3.05483e-43 ) ( &lt; SCHEDULE
                &gt; NIL NIL NIL NIL NIL NIL NIL NIL T NIL NIL : STR ( ( FRAME *SCHEDULE ) ( ATTITUDE *LET-S ) ) : COV (
                5 4 3 2 1 ) : SCORE 1.4012985e-45 ) ( &lt; INTERVAL &gt; NIL T T T : STR ( ( END ( ( FRAME *SIMPLE-TIME
                ) ( HOUR 1 ) ) ) ( START ( ( FRAME *SIMPLE-TIME ) ( HOUR 11 ) ) ) ( INCL-EXCL INCLUSIVE ) ( FRAME
                *INTERVAL ) ) : COV ( 11 10 9 ) : SCORE 1.2102125e-38 ) ( &lt; SCHEDULE &gt; NIL NIL NIL NIL NIL T T NIL
                NIL NIL NIL : STR ( ( FRAME *SCHEDULE ) ( NEGATIVE + ) ( WHO ( ( FRAME *WE ) ) ) ) : COV ( 5 4 3 2 ) :
                SCORE 2.2584231e-37 ) ( &lt; SCHEDULE &gt; NIL T NIL NIL NIL T NIL NIL NIL NIL NIL : STR ( ( FRAME
                *SCHEDULE ) ( WHAT ( ( FRAME *IT ) ) ) ( WHO ( ( FRAME *WE ) ) ) ) : COV ( 6 5 4 ) : SCORE 1.861576e-27
                ) ( &lt; PRO &gt; NIL NIL NIL : STR ( ( FRAME *PRO ) ) : COV ( II ) : SCORE 2.2223547e-18 ) ( &lt;
                SIMPLE-TIME &gt; NIL NIL NIL NIL NIL NIL T NIL : STR ( ( FRAME *SIMPLE-TIME ) ( HOUR 1 ) ) : C0V ( 11 )
                : SCORE 2.2223547e-18 ) ( &lt; SIMPLE-TIME &gt; NIL NIL NIL NIL NIL NIL T NIL : STR ( ( FRAME
                *SIMPLE-TIME ) ( HOUR II ) ) : COV ( 9 ) : SCORE 1.0090891e-22 ) ( &lt; IT &gt; : STR ( ( FRAME *IT ) )
                : COV ( 6 ) : SCORE 2.593466e-13 ) Ideal Program : ( &lt; SCHEDULE &gt; NIL NIL NIL NIL NIL NIL NIL (
                &lt; INTERVAL &gt; NIL NIL NIL NIL : STR ( ( END ( ( FRAME *SIMPLE-TIME ) ( HOUR I ) ) ) ( START ( (
                FRAME *SIMPLE-TIME ) ( HOUR Ii ) ) ) ( INCL-EXCL INCLUSIVE ) ( FRAME *INTERVAL ) ) : COV ( II I0 9 ) :
                SCORE 1.2102125e-38 ) NIL NIL NIL : STR ( ( FRAME *SCHEDULE ) ( ATTITUDE *LET-S ) ( WHAT ( ( FRAME *IT )
                ) ) ) : COV ( 6 5 4 3 2 I ) : SCORE 1.4012985e-45 ) Interpretation : Let 's schedule it for from eleven
                o'clock till one o'clock Figure 4 : Repair example 314 .
            </sentence>
            <definiendum id="0">SCHEDULE &gt; NIL T NIL NIL NIL T T NIL NIL NIL NIL</definiendum>
            <definiendum id="1">WHAT</definiendum>
            <definiendum id="2">SCHEDULE &gt; NIL NIL NIL NIL NIL NIL NIL NIL T NIL NIL</definiendum>
            <definiendum id="3">START</definiendum>
            <definiendum id="4">SCHEDULE &gt; NIL T NIL NIL NIL T NIL NIL NIL NIL NIL : STR ( ( FRAME *SCHEDULE
            </definiendum>
            <definiens id="0">( &lt; SCHEDULE &gt; NIL T NIL NIL NIL NIL NIL NIL T NIL NIL : STR ( ( FRAME *SCHEDULE )
            </definiens>
            <definiens id="1">INTERVAL &gt; NIL T T T : STR ( ( END ( ( FRAME *SIMPLE-TIME )</definiens>
            <definiens id="2">STR ( ( FRAME *SCHEDULE ) ( NEGATIVE + ) ( WHO ( ( FRAME *WE ) ) ) )</definiens>
            <definiens id="3">PRO &gt; NIL NIL NIL : STR ( ( FRAME *PRO ) ) : COV ( II ) : SCORE 2.2223547e-18 ) ( &lt;
                SIMPLE-TIME &gt; NIL NIL NIL NIL NIL NIL T NIL : STR ( ( FRAME *SIMPLE-TIME ) ( HOUR 1 ) ) : C0V
            </definiens>
            <definiens id="4">STR ( ( FRAME *SIMPLE-TIME ) ( HOUR II ) ) : COV ( 9 ) : SCORE 1.0090891e-22 ) ( &lt; IT
                &gt; : STR ( ( FRAME *IT ) ) : COV ( 6 ) : SCORE 2.593466e-13 ) Ideal Program : ( &lt; SCHEDULE &gt; NIL
                NIL NIL NIL NIL NIL NIL ( &lt; INTERVAL &gt; NIL NIL NIL NIL : STR ( ( END ( ( FRAME *SIMPLE-TIME ) (
                HOUR I ) ) ) ( START ( ( FRAME *SIMPLE-TIME ) ( HOUR Ii ) ) ) ( INCL-EXCL INCLUSIVE ) ( FRAME *INTERVAL
                ) ) : COV ( II I0 9 ) : SCORE 1.2102125e-38 ) NIL NIL NIL : STR ( ( FRAME *SCHEDULE ) ( ATTITUDE *LET-S
                ) ( WHAT ( ( FRAME *IT
            </definiens>
        </definition>
        <definition id="3">
            <sentence>The SCORE field contains the statistical score assigned by the parser 's statistical
                disambiguation procedure described in ( Ros~ and Lavie , to appear ) .
            </sentence>
            <definiendum id="0">SCORE field</definiendum>
            <definiens id="0">contains the statistical score assigned by the parser 's statistical disambiguation
                procedure described in ( Ros~ and Lavie , to appear )
            </definiens>
        </definition>
    </paper>

    <paper id="2013">
        <definition id="0">
            <sentence>Training Data We use the Multext-East-annotated version of the Orwell 's 1984 novel in Czech ,
                Estonian , Hungarian , 94 Romanian and Slovene I. The annotation uses a single SGML-based formal scheme
                , and even common guidelines for tagset design and annotation , nevertheless the tagsets differ
                substantially since the languages differ as well : Romanian is a French-like romance language ,
                Hungarian is agglutinative , and the other languages are more or less inflectionaltype languages 2 .
            </sentence>
            <definiendum id="0">Hungarian</definiendum>
            <definiens id="0">a French-like romance language</definiens>
        </definition>
        <definition id="1">
            <sentence>The model described in ( Haji~ and Hladk~ , 1998 ) is a general exponential ( specifically , a
                log-linear ) model ( such as the one used for Maximum Entropybased models ) : pAc ( ylx ) = exp ( ~\ ]
                in_1AJi ( y , x ) ) z ( x ) ( 1 ) where fi ( y , x ) is a binary-valued feature of the event value being
                predicted and its context , A~ is a weight of the feature fi , and Z ( x ) is the natural normalization
                factor .
            </sentence>
            <definiendum id="0">fi ( y , x )</definiendum>
            <definiendum id="1">A~</definiendum>
            <definiendum id="2">Z ( x )</definiendum>
            <definiens id="0">a binary-valued feature of the event value being predicted and its context</definiens>
            <definiens id="1">a weight of the feature fi</definiens>
            <definiens id="2">the natural normalization factor</definiens>
        </definition>
        <definition id="2">
            <sentence>An ambiguity class is a set of values ( such as genitive and accusative ) of a single category (
                such as CASE ) which arises for some word forms as a result of morphological analysis .
            </sentence>
            <definiendum id="0">ambiguity class</definiendum>
            <definiens id="0">a set of values ( such as genitive and accusative ) of a single category ( such as CASE )
                which arises for some word forms as a result of morphological analysis
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Even though the full computation of the appropriate feature weight is still prohibitive ( the more
                so when the general features are added ) , the learner is now allowed to vary the weights ( in several
                discrete steps ) during feature selection , as a ( somewhat crude ) attempt to depart from the Naive
                Bayes simplification to the approximation of the `` correct '' Maximum Entropy estimation .
            </sentence>
            <definiendum id="0">prohibitive</definiendum>
        </definition>
        <definition id="4">
            <sentence>MBT : A memory-based part of speech tagger generator .</sentence>
            <definiendum id="0">MBT</definiendum>
            <definiens id="0">A memory-based part of speech tagger generator</definiens>
        </definition>
    </paper>

    <paper id="2012">
        <definition id="0">
            <sentence>Introduction Morphologically , Arabic is a non-concatenative language .</sentence>
            <definiendum id="0">Arabic</definiendum>
            <definiens id="0">a non-concatenative language</definiens>
        </definition>
        <definition id="1">
            <sentence>Stem changes combine with suffixes in the perfect indicative ( e.g. , katab-naa 'we wrote ' ,
                kutib-a 'it was written ' ) and the imperative ( e.g. uktub-uu 'write ' , plural ) , and with both
                prefixes and suffixes for the imperfect tense in the indicative , subjunctive , and jussive moods ( e.g.
                ya-ktub-na 'they write , feminine plural ' ) and in the energetic mood ( e.g. ya-ktub-unna or ya-ktub-un
                'he certainly writes ' ) .
            </sentence>
            <definiendum id="0">Stem changes</definiendum>
            <definiens id="0">combine with suffixes in the perfect indicative ( e.g. , katab-naa 'we wrote '</definiens>
        </definition>
        <definition id="2">
            <sentence>MORPHE ( Leavitt , 1994 ) is a tool that compiles morphological transformation rules into either a
                word parsing program or a word generation program .
            </sentence>
            <definiendum id="0">MORPHE</definiendum>
            <definiens id="0">a tool that compiles morphological transformation rules into either a word parsing program
                or a word generation program
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Input is a feature structure ( FS ) which describes the item that MORPHE must transform .
            </sentence>
            <definiendum id="0">Input</definiendum>
            <definiens id="0">a feature structure ( FS ) which describes the item that MORPHE must transform</definiens>
        </definition>
        <definition id="4">
            <sentence>A FS is implemented as a recursive Lisp list .</sentence>
            <definiendum id="0">FS</definiendum>
            <definiens id="0">a recursive Lisp list</definiens>
        </definition>
        <definition id="5">
            <sentence>Each element of the FS is a feature-value pair ( FVP ) , where the value can be atomic or complex
                .
            </sentence>
            <definiendum id="0">FS</definiendum>
            <definiendum id="1">FVP</definiendum>
            <definiens id="0">a feature-value pair (</definiens>
        </definition>
        <definition id="6">
            <sentence>A rule attached to each leaf node of the MFH effects the desired morphological transformations for
                that node .
            </sentence>
            <definiendum id="0">MFH</definiendum>
            <definiens id="0">effects the desired morphological transformations for that node</definiens>
        </definition>
        <definition id="7">
            <sentence>A rule consists of one or more mutually exclusive clauses .</sentence>
            <definiendum id="0">rule</definiendum>
            <definiens id="0">consists of one or more mutually exclusive clauses</definiens>
        </definition>
        <definition id="8">
            <sentence>problems is a constraint of MORPHE 's implementation , which does not permit multiple trees with
                separate roots .
            </sentence>
            <definiendum id="0">problems</definiendum>
            <definiens id="0">a constraint of MORPHE 's implementation , which does not permit multiple trees with
                separate roots
            </definiens>
        </definition>
        <definition id="9">
            <sentence>Multi-tape Two-level Morphology : A Case study in Semitic Non-Linear Morphology .</sentence>
            <definiendum id="0">Multi-tape Two-level Morphology</definiendum>
        </definition>
        <definition id="10">
            <sentence>Two-level morphology : A General Computational Model for Word-Form Recognition and Production .
            </sentence>
            <definiendum id="0">Two-level morphology</definiendum>
        </definition>
        <definition id="11">
            <sentence>MORPHE : A Morphological Rule Compiler .</sentence>
            <definiendum id="0">MORPHE</definiendum>
        </definition>
        <definition id="12">
            <sentence>Foot and Word in Prosodic Morphology : The Arabic Broken Plural .</sentence>
            <definiendum id="0">Foot</definiendum>
        </definition>
    </paper>

    <paper id="3008">
        <definition id="0">
            <sentence>Markers Preliminary tests using the British National Corpus ( BNC ) and Knott 's ( 1995 ) taxonomy
                of discourse markers suggested that the order of multiple markers cueing a single relation is affected
                by their position in the taxonomy ; those higher in the taxonomy always precede those lower in the
                taxonomy ( see figure 1 and examples 6-7 ) ; ( 6 ) This blood-line was particularly helpful to the early
                breeders because the line was in-bred , his parents being brother and sister of excellent breeding and
                so consequently true to type .
            </sentence>
            <definiendum id="0">British National Corpus ( BNC</definiendum>
            <definiens id="0">taxonomy of discourse markers suggested that the order of multiple markers cueing a single
                relation is affected by their position in the taxonomy
            </definiens>
        </definition>
    </paper>

    <paper id="3002">
    </paper>

    <paper id="2011">
        <definition id="0">
            <sentence>Word-for-word glossing is the process of directly translating each word or term in a document
                without considering the word order .
            </sentence>
            <definiendum id="0">Word-for-word glossing</definiendum>
            <definiens id="0">the process of directly translating each word or term in a document without considering
                the word order
            </definiens>
        </definition>
        <definition id="1">
            <sentence>Given a word w in a dependency relationship ( such as subject or object ) , the collocation
                database can be used to retrieve the words that occurred in that relationship with w , in a large corpus
                , along with their frequencies 2 .
            </sentence>
            <definiendum id="0">collocation database</definiendum>
            <definiens id="0">such as subject or object ) , the</definiens>
        </definition>
        <definition id="2">
            <sentence>CONTEXT CONTEXTUALLY SIMILAR WORDS OF DUTY corporate duty fee , function , levy , liability ,
                obligation , personnel , responsibility , rule , staff , tax , training obligation , requirement ,
                responsibility , role fiducia~ duty the responsibility and tax senses of duty , reflecting the fact that
                the meaning of duty is indeed ambiguous if corporate duty is its sole context .
            </sentence>
            <definiendum id="0">CONTEXT CONTEXTUALLY SIMILAR WORDS OF DUTY</definiendum>
            <definiens id="0">corporate duty fee , function , levy , liability , obligation , personnel , responsibility
                , rule , staff , tax , training obligation , requirement , responsibility , role fiducia~ duty the
                responsibility and tax senses of duty
            </definiens>
        </definition>
        <definition id="3">
            <sentence>GI and G2 are describable by graphs where the vertices are the words and each weighted edge
                between vertices wl and w2 represents the similarity , sim ( wl , w2 ) , between the words wl and Wz .
            </sentence>
            <definiendum id="0">vertices</definiendum>
            <definiens id="0">describable by graphs where the</definiens>
        </definition>
        <definition id="4">
            <sentence>The absolute interconnectivity between G t and G 2 , AI ( G t , G2 ) , is defined as the aggregate
                similarity between the two groups : x~Gi YEG2 The absolute closeness between G~ and G2 , AC ( G~ , G2 )
                , is defined as the average similarity between a pair of elements , one from each group : Ic , lc l 81
                Table 4 .
            </sentence>
            <definiendum id="0">G2 )</definiendum>
            <definiendum id="1">, AC</definiendum>
            <definiens id="0">The absolute interconnectivity between G t and G 2 , AI ( G t ,</definiens>
            <definiens id="1">the aggregate similarity between the two groups : x~Gi YEG2 The absolute closeness between
                G~ and G2
            </definiens>
        </definition>
        <definition id="5">
            <sentence>The internal interconnectivity of G , II ( G ) , is defined as II ( G ) = AI ( G ' , G '' ) and
                the internal closeness of G , IC ( G ) , as IC ( G ) = AC ( G ' , G '' ) .
            </sentence>
            <definiendum id="0">internal interconnectivity of G , II</definiendum>
            <definiens id="0">II ( G ) = AI ( G ' , G '' ) and the internal closeness of G , IC ( G ) , as IC ( G ) = AC
                ( G ' , G '' )
            </definiens>
        </definition>
        <definition id="6">
            <sentence>The similarity between G1 and G2 is then defined as follows : groupSim ( G , , G2 ) = R/ ( G , ,
                G2 ) × RC ( G , , G 2 ) where 2AI ( G , ,G2 ) xI ( G , ) + II ( G ) is the relative interconnectivity
                and RC ( G , ,G2 ) = AC ( G , ,G ) IG'I IC ( G , ) 4 IG2I IC ( G2 ) IG , I+IG=I IG , I÷IG21 is the
                relative closeness .
            </sentence>
            <definiendum id="0">I+IG=I IG</definiendum>
            <definiens id="0">follows : groupSim ( G , , G2 ) = R/ ( G , , G2 ) × RC ( G , , G 2 ) where 2AI ( G , ,G2 )
                xI ( G , ) + II ( G ) is the relative interconnectivity and RC ( G , ,G2 ) = AC ( G , ,G ) IG'I IC ( G ,
                ) 4 IG2I IC ( G2 ) IG ,
            </definiens>
        </definition>
        <definition id="7">
            <sentence>Chameleon : A Hierarchical Clustering Algorithm Using Dynamic Modeling .</sentence>
            <definiendum id="0">Chameleon</definiendum>
        </definition>
    </paper>

    <paper id="1037">
        <definition id="0">
            <sentence>The MindNet ( Richardson 1998 ) project at Microsoft is an attempt to transform the Longman
                Dictionary of Contemporary English ( LDOCE ) into a form of knowledge base for text processing .
            </sentence>
            <definiendum id="0">MindNet</definiendum>
            <definiens id="0">an attempt to transform the Longman Dictionary of Contemporary English ( LDOCE ) into a
                form of knowledge base for text processing
            </definiens>
        </definition>
        <definition id="1">
            <sentence>For example , mortgage_interest_rate is a kind of interest_rate , thus linked by a relation
                nYPERNYMY ( interest_rate , mortgage_interest_rate ) .
            </sentence>
            <definiendum id="0">mortgage_interest_rate</definiendum>
            <definiens id="0">a kind of interest_rate</definiens>
        </definition>
        <definition id="2">
            <sentence>components ; y/ radio components automobile components / automobile radio components Figure 3 :
                Classification of a compound concept with respect to its ~ concepts Since we do not deal here with the
                sentence semantics , it is not possible to completely determine the meaning of \ [ word1 word2 head\ ] ,
                as it may be either \ [ ( ( word1 word2 ) head ) \ ] or \ [ ( word1 ( words head ) ) \ ] often depending
                on the sentence context .
            </sentence>
            <definiendum id="0">y/ radio components</definiendum>
            <definiens id="0">words head ) ) \ ] often depending on the sentence context</definiens>
        </definition>
        <definition id="3">
            <sentence>Most of the 273 \ [ I Relations I Lexico-syntactic Patterns Examples H WordNet Relations HYPERNYMY
                I NP1 \ [ &lt; be &gt; \ ] a kind of NP2 Thus , LIBOR is a kind of interest rate , as it is charged I :
                :~ HYPERNYMY ( NPI , NP2 ) on deposits between banks in the Eurodolar market .
            </sentence>
            <definiendum id="0">LIBOR</definiendum>
            <definiens id="0">a kind of interest rate</definiens>
        </definition>
    </paper>

    <paper id="1014">
        <definition id="0">
            <sentence>This paper describes MIMIC , an adaptive mixed initiative spoken dialogue system that provides
                movie showtime information .
            </sentence>
            <definiendum id="0">MIMIC</definiendum>
            <definiens id="0">an adaptive mixed initiative spoken dialogue system that provides movie showtime
                information
            </definiens>
        </definition>
        <definition id="1">
            <sentence>In our information query application domain , the system has task ( and thus dialogue ) initiative
                if its utterances provide helpful guidance toward achieving the user 's domain goal , as in utterances (
                6 ) and ( 7 ) where MIMIC provided valid response choices to its query intending to solicit a theater
                name , while the system has 97 dialogue but not task initiative if its utterances only specify the
                current discourse goal , as in utterance ( 4 ) .
            </sentence>
            <definiendum id="0">MIMIC</definiendum>
            <definiens id="0">helpful guidance toward achieving the user 's domain goal</definiens>
        </definition>
        <definition id="2">
            <sentence>Information Consultant MIMIC is a telephone-based dialogue system that provides movie showtime
                information .
            </sentence>
            <definiendum id="0">Information Consultant MIMIC</definiendum>
            <definiens id="0">a telephone-based dialogue system that provides movie showtime information</definiens>
        </definition>
        <definition id="3">
            <sentence>Speech recognizer : the recognizer receives audio data from the telephony server and generates the
                word string hypothesis that best matches the audio input .
            </sentence>
            <definiendum id="0">Speech recognizer</definiendum>
            <definiens id="0">the recognizer receives audio data from the telephony server and generates the word string
                hypothesis that best matches the audio input
            </definiens>
        </definition>
        <definition id="4">
            <sentence>We used the Bell Labs TTS system ( Sproat , 1998 ) , which in addition to converting plain text
                into speech , accepts text strings annotated to override default pitch height , accent placement ,
                speaking rate , etc. 2 MIMIC utilizes a non-recursive frame-based semantic representation commonly used
                in spoken dialogue systems ( e.g. ( Seneff et al. , 1991 ; Lamel , 1998 ) ) , which represents an
                utterance as a set of attribute-value pairs .
            </sentence>
            <definiendum id="0">Bell Labs TTS system</definiendum>
            <definiens id="0">in addition to converting plain text into speech , accepts text strings annotated to
                override default pitch height
            </definiens>
        </definition>
        <definition id="5">
            <sentence>Question-Type : When Movie : Analyze This Theater : null Town : Montclair ( a ) Semantic
                Representation Question-Type : When Movie : mandatory Theater : mandatory Town : optional ( b ) Task
                Specification Figure 2 : Semantic Representation and Task Specification in Montclair ? ''
            </sentence>
            <definiendum id="0">Question-Type</definiendum>
            <definiendum id="1">Movie</definiendum>
            <definiens id="0">a ) Semantic Representation Question-Type : When Movie : mandatory Theater : mandatory
                Town : optional ( b ) Task Specification Figure 2 : Semantic Representation
            </definiens>
        </definition>
        <definition id="6">
            <sentence>`` INN 100 Cue Class Discourse Analytical Cue TakeOverTask NoNewlnfo InvalidAction
                lnvalidActionResolved AmbiguousAction AmbiguousActionResolved BPA mt-tot ( { speaker } ) = 0.35 ; mr-tot
                ( O ) = 0.65 mt- , ~ni ( { hearer } ) = 0.35 ; mt-nn~ ( O ) = 0.65 mt-i~ ( { hearer } ) = 0.35 ; mt-ia (
                O ) = 0.65 mt-iar ( { hearer } ) = 0.35 ; mt-iar ( O ) = 0.65 mt-aa ( { hearer } ) = 0.35 ; mt-a~ ( O )
                = 0.65 mt ... . ( { speaker } ) = 0.35 ; mt ... . ( O ) = 0.65 ( a ) Task Initiative Cue Class Discourse
                Analytical Cue TakeOverTask NoNewlnfo lnvalidAction InvalidActionResolved AmbiguousAction
                AmbiguousActionResolved BPA md-tot ( { speaker } ) = 0.35 ; ma-tot ( O ) = 0.65 md-nni ( { hearer } ) =
                0.35 ; md-nni ( O ) -~0.65 md-ia ( { hearer } ) = 0.7 ; md-ia ( O ) = 0.3 ma-iar ( { hearer } ) = 0.7 ;
                ma-iar ( O ) = 0.3 ma-aa ( { hearer } ) = 0.7 ; md_a~ ( O ) = 0.3 ma ... . ( { speaker } ) = 0.7 ; md
                ... . ( O ) = 0.3 ( b ) Dialogue Initiative Figure 3 : Cues and BPAs for Modeling Initiative in MIMIC
                Seleet-Goal ( SemRep ) : ( 1 ) IfAmbiguousAction detected ( 2 ) ambiguous-attr +-get-ambiguous ( SemRep
                ) /* get name of ambiguous attribute */ ( 3 ) If ( number-values ( ambiguous-attr ) == 0 ) /* attribute
                unspecified *,1 ( 4 ) Instantiate ( ambiguous-attr ) ( 5 ) Else/* more than one value specified */ ( 6 )
                Constrain ( ambiguous-attr ) ( 7 ) Else if lnvalidAction detected ( 8 ) ProvideNegativeAnswer ( SemRep )
                ( 9 ) Else/* well-formed query */ ( 10 ) answer +-database-query ( SemRep ) ( 11 ) ProvideAnswer (
                answer ) Figure 4 : Goal Selection Algorithm user queries ( steps 1-8 ) 5 ( van Beeket al. , 1993 ;
                Raskutti and Zukerman , 1993 ; Qu and Beale , 1999 ) , and 2 ) providing answers to well-formed queries
                ( steps 9-11 ) .
            </sentence>
            <definiendum id="0">Cue Class Discourse Analytical Cue TakeOverTask NoNewlnfo InvalidAction
                lnvalidActionResolved AmbiguousAction AmbiguousActionResolved BPA mt-tot
            </definiendum>
            <definiendum id="1">Discourse Analytical Cue TakeOverTask NoNewlnfo lnvalidAction InvalidActionResolved
                AmbiguousAction AmbiguousActionResolved BPA md-tot
            </definiendum>
            <definiens id="0">b ) Dialogue Initiative Figure 3 : Cues and BPAs for Modeling Initiative in MIMIC
                Seleet-Goal ( SemRep ) : ( 1 ) IfAmbiguousAction detected
            </definiens>
        </definition>
        <definition id="7">
            <sentence>When MIMIC has both initiatives , however , in addition to NotifyFailure , it suggests an
                alternative close to the user 's original query and provides a limited prompt .
            </sentence>
            <definiendum id="0">MIMIC</definiendum>
            <definiens id="0">an alternative close to the user 's original query and provides a limited prompt
            </definiens>
        </definition>
        <definition id="8">
            <sentence>MIMIC employs a simple template-driven utterance generation approach .</sentence>
            <definiendum id="0">MIMIC</definiendum>
            <definiens id="0">employs a simple template-driven utterance generation approach</definiens>
        </definition>
        <definition id="9">
            <sentence>101 Task + Dialogue Dialogue None Constrain Clarify Clarify Acknowledge Instantiate GiveOptions
                lnfoSeek Acknowledge InfoSeek ProvideAnswer Answer Answer Answer LimitedPrompt OpenPrompt
                ProvideNegativeAnswer NotifyFailure NotifyFailure NotifyFailure SuggestAltemative OpenPrompt
                LimitedPrompt Table 1 : Strategy Selection Based on Goal and Initiative Distribution Dialogue Act
                Clarify Acknowledge GiveOptions InfoSeek Answer OpenPrompt LimitedPrompt NotifyFailure SuggestAltemative
                Template `` Did you say &lt; valuel &gt; ... . or &lt; valuen &gt; .9 '' `` Uh-huh . ''
            </sentence>
            <definiendum id="0">SuggestAltemative Template</definiendum>
            <definiens id="0">Strategy Selection Based on Goal and Initiative Distribution Dialogue Act Clarify
                Acknowledge GiveOptions InfoSeek Answer OpenPrompt LimitedPrompt NotifyFailure
            </definiens>
        </definition>
        <definition id="10">
            <sentence>Thus , MIMIC answers the query and switches to an open-ended prompt in ( 13 ) , relinquishing task
                initiative to the user .
            </sentence>
            <definiendum id="0">MIMIC</definiendum>
            <definiens id="0">answers the query</definiens>
        </definition>
        <definition id="11">
            <sentence>PARADISE : A framework for evaluating spoken dialogue agents .</sentence>
            <definiendum id="0">PARADISE</definiendum>
        </definition>
    </paper>

    <paper id="2004">
        <definition id="0">
            <sentence>Our segmentation algorithm takes a list of tokenized sentences as input .</sentence>
            <definiendum id="0">segmentation algorithm</definiendum>
            <definiens id="0">takes a list of tokenized sentences as input</definiens>
        </definition>
        <definition id="1">
            <sentence>Figure 4 illustrates the more subtle effects of our ranking scheme , r ( x ) is the rank ( 1 x 11
                mask ) of f ( x ) which is a sine wave with decaying mean , amplitude and frequency ( equation 3 ) .
            </sentence>
            <definiendum id="0">r ( x )</definiendum>
        </definition>
        <definition id="2">
            <sentence>A sample is a concatenation of ten text segments .</sentence>
            <definiendum id="0">sample</definiendum>
        </definition>
        <definition id="3">
            <sentence>A segment is the first n sentences of a randomly selected document from the Brown corpus 4 .
            </sentence>
            <definiendum id="0">segment</definiendum>
            <definiens id="0">the first n sentences of a randomly selected document from the Brown corpus 4</definiens>
        </definition>
        <definition id="4">
            <sentence>Word similarity is a function of word cooccurrence statistics in the given document .</sentence>
            <definiendum id="0">Word similarity</definiendum>
            <definiens id="0">a function of word cooccurrence statistics in the given document</definiens>
        </definition>
        <definition id="5">
            <sentence>The former is an exact implementation of the algorithm described in this paper .</sentence>
            <definiendum id="0">former</definiendum>
            <definiens id="0">an exact implementation of the algorithm described in this paper</definiens>
        </definition>
        <definition id="6">
            <sentence>Our spread activation based semantic measure ( R98 ( ... .. , ) ) improved a.ccura ( : y. This
                confirms that although Kozima 's apl ) roaeh ( Kozima , 1993 ) is computationally expensive , it does
                produce more precise segmentation .
            </sentence>
            <definiendum id="0">R98</definiendum>
            <definiens id="0">although Kozima 's apl ) roaeh ( Kozima , 1993 ) is computationally expensive , it does
                produce more precise segmentation
            </definiens>
        </definition>
        <definition id="7">
            <sentence>Thanks are due to my parents and department tbr making this work possible ; Jeffrey Reynar for
                discussions and guidance on the segmentation problem ; Hideki Kozima for help on the spread activation
                nmasure ; Min-Yen Kan and Marti Hearst for their segmentation algorithms ; Daniel Orain for references
                to image processing techniques ; Magnus Rattray and Stephen Marsland for help on statistics and
                mathematics .
            </sentence>
            <definiendum id="0">Jeffrey Reynar</definiendum>
        </definition>
        <definition id="8">
            <sentence>Dotplot : A program for exploring self-similarity in millions of lines of text and code .
            </sentence>
            <definiendum id="0">Dotplot</definiendum>
            <definiens id="0">A program for exploring self-similarity in millions of lines of text and code</definiens>
        </definition>
        <definition id="9">
            <sentence>Char_align : A trigram for aligning parallel texts at the character level .</sentence>
            <definiendum id="0">Char_align</definiendum>
            <definiens id="0">A trigram for aligning parallel texts at the character level</definiens>
        </definition>
        <definition id="10">
            <sentence>Eagle : An extensible architecture for general linguistic engineering .</sentence>
            <definiendum id="0">Eagle</definiendum>
            <definiens id="0">An extensible architecture for general linguistic engineering</definiens>
        </definition>
    </paper>

    <paper id="2008">
        <definition id="0">
            <sentence>Frame semantics characterizes the semantic and syntactic properties of predicating words by
                relating them to semantic frames .
            </sentence>
            <definiendum id="0">Frame semantics</definiendum>
            <definiens id="0">characterizes the semantic and syntactic properties of predicating words by relating them
                to semantic frames
            </definiens>
        </definition>
        <definition id="1">
            <sentence>NP Noun phrase ( the witness ) N Non-maximal nominal ( personal chat ) Poss Possessive NP ( the
                child 's decision ) There Expletive there ( there was a fight ) It Expletive it ( it 's nice that you
                came ) PP Prepositional phrase ( look at me ) Ping PP with gerundive object ( keep from laughing ) Part
                Particle ( look it up ) VPfin Finite verb phrase ( we atefish ) VPbrst Bare stem VP ( let us eatfish )
                VPto To-marked infinitive VP ( we want to eat sh ) VPwh WH-VP ( we know how to win ) VPing Gerundive VP
                ( we like winning ) Sfin Swh Sif Sing Sto Sforto Sbrst Finite clause ( it 's nice thatyou came )
                WH-clause ( ask who won ) lflwhether clause ( ask if we won ) Gerundive clause ( we saw them running )
                To-marked clause ( we want them to win ) For-to-marked clause ( we would like for them to win ) Bare
                stem clause ( we insist that they win ) 57 In certain cases FrameNet marks as two constituents what are
                treated as `` small clauses '' in some analyses .
            </sentence>
            <definiendum id="0">NP Noun phrase</definiendum>
            <definiendum id="1">PP Prepositional phrase</definiendum>
            <definiens id="0">the witness ) N Non-maximal nominal ( personal chat</definiens>
            <definiens id="1">look at me ) Ping PP with gerundive object ( keep from laughing ) Part Particle ( look it
                up ) VPfin Finite verb phrase
            </definiens>
        </definition>
        <definition id="2">
            <sentence>AjP Adjective phrase ( an interesting idea ) AdvP Adverb phrase ( you put that nicely ) Quo Quote
                ( `` Indeed , `` she said ) Below is a list of the FrameNet GFs .
            </sentence>
            <definiendum id="0">AjP Adjective phrase</definiendum>
            <definiendum id="1">Below</definiendum>
            <definiens id="0">an interesting idea ) AdvP Adverb phrase ( you put that nicely</definiens>
        </definition>
        <definition id="3">
            <sentence>The following FEs consistently appear in frames relating to verbal communication : Speaker ( A
                person who performs an act of verbal communication ) Addressee ( An actual or intended recipient of a
                verbal message ) Message ( A communicated proposition ) Topic ( The subject matter of a message ) Medium
                ( A physical channel of communication ) Code ( The language or other code used to communicate ) These
                FEs all derive their meaning from the concept of a basic communicative event .
            </sentence>
            <definiendum id="0">Speaker</definiendum>
            <definiendum id="1">Addressee</definiendum>
            <definiendum id="2">Medium</definiendum>
            <definiendum id="3">Code</definiendum>
            <definiens id="0">An actual or intended recipient of a verbal message ) Message ( A communicated proposition
                ) Topic ( The subject matter of a message
            </definiens>
            <definiens id="1">A physical channel of communication )</definiens>
            <definiens id="2">The language or other code used to communicate ) These FEs all derive their meaning from
                the concept of a basic communicative event
            </definiens>
        </definition>
        <definition id="4">
            <sentence>resources FrameNet annotations provide more detail than existing lexical resources about the way
                in which particular semantic roles ( i.e. FEs ) are linked with particular means of syntactic expression
                .
            </sentence>
            <definiendum id="0">resources FrameNet</definiendum>
            <definiens id="0">annotations provide more detail than existing lexical resources about the way in which
                particular semantic roles
            </definiens>
        </definition>
        <definition id="5">
            <sentence>For example , WordNet gives the same sentence frames for Senses 1 and 2 , while in the FrameNet
                database , the senses of argue defined relative to the Statement and Conversation frames are
                characterized by different argument structures : only Statement argue allows finite clausal complements
                expressing Message ; Conversation argue has the properties of other reciprocal communication words ,
                which Statement argue lacks , and does not allow clausal Complements ( or any other expression of
                Message ) .
            </sentence>
            <definiendum id="0">WordNet</definiendum>
            <definiens id="0">the properties of other reciprocal communication words</definiens>
        </definition>
        <definition id="6">
            <sentence>COMLEX ( Meyers et al. 1995 ) recognizes the syntactic frames in which argue occurs , but does not
                provide information about the linking of syntactic constituents with semantic roles , or about the
                different complementation properties of different senses of ambiguous words .
            </sentence>
            <definiendum id="0">COMLEX</definiendum>
            <definiens id="0">recognizes the syntactic frames in which argue occurs , but does not provide information
                about the linking of syntactic constituents with semantic roles , or about the different complementation
                properties of different senses of ambiguous words
            </definiens>
        </definition>
        <definition id="7">
            <sentence>Conclusion FrameNet semantic annotation captures human knowledge about the ways in which semantic
                roles ( FEs ) are conventionally expressed by different words in various word classes and domains .
            </sentence>
            <definiendum id="0">Conclusion FrameNet</definiendum>
        </definition>
        <definition id="8">
            <sentence>Fellbaum , Christiane ( 1987 ) WordNet : An electronic lexical database .</sentence>
            <definiendum id="0">WordNet</definiendum>
        </definition>
    </paper>

    <paper id="2025">
        <definition id="0">
            <sentence>Both similarity metrics ( sire1 , sire2 ) are inner vector products of ( _stemmed ) term
                frequencies ( see equations 2 to 4 ) ; tft is a vector of stem frequencies in a turn ; f , are
                in-segment frequencies of a stem ; f , rna= are maximal segment frequencies of any stem in the topical
                segment , sirnl can be normalized or not .
            </sentence>
            <definiendum id="0">tft</definiendum>
            <definiens id="0">inner vector products of ( _stemmed ) term frequencies</definiens>
            <definiens id="1">a vector of stem frequencies in a turn ; f , are in-segment frequencies of a stem ; f ,
                rna= are maximal segment frequencies of any stem in the topical segment
            </definiens>
        </definition>
        <definition id="1">
            <sentence>The scores are computed as follows : • When summarizing the reference : Here , the word error rate
                is trivially 0.0 ; the summary accuracy sa is the sum of all relevance scores ( -6.0 ) divided by the
                maximal achievable score with the same number of words ( n = 7 ) .
            </sentence>
            <definiendum id="0">summary accuracy sa</definiendum>
            <definiens id="0">the sum of all relevance scores ( -6.0 ) divided by the maximal achievable score with the
                same number of words
            </definiens>
        </definition>
        <definition id="2">
            <sentence>5For EXP , we define 0 ° -- -O. 188 TURN re1 : REF : HYP : err : con : TURN rel : REF : HYP : err
                : con : 1 : this is to illustrate the idea *** this is to ILLUMINATE *** idea C C C S D C I 1 1 1 0.9
                0.8 0.8 2 : 0 1 1 1 1 1 1 and here we have very relevant information and HE ** BEHAVES **** IRREVERENT
                FORMATION C S D S D S S Figure 1 : Simplified example of two turns ( for score computation ) BACK ( i }
                sum -0.43 ( ii ) average -0.53 Off ) scores &gt; 0.95 -0.55 ( iv ) normalized ( iii ) -0.58 ( v )
                geometric mean -0.53 19CENT BUCHANAN -0.51 -0.12 -0.52 -0.43 -0.48 -0.35 -0.48 -0.48 -0.53 -0.42 GRAY
                -0.03 -0.42 -0.25 -0.44 -0.38 Table 1 : Pearson r correlation between WER and confidence scores racy
                when the word error rate is reduced , this is not necessarily the case .
            </sentence>
            <definiendum id="0">HE</definiendum>
            <definiens id="0">relevant information and</definiens>
        </definition>
        <definition id="3">
            <sentence>As explained in the example in section 4 , the accuracy score is defined as the fraction of the
                sum of all individual word relevance scores ( as de189 TV show number of speakers speaker turns words in
                transcript length in minutes topical segments word error rate ( in % ) BACK 19CENT BUCHANAN GR .
            </sentence>
            <definiendum id="0">accuracy score</definiendum>
            <definiens id="0">the fraction of the sum of all individual word relevance scores ( as de189 TV show number
                of speakers speaker turns words in transcript length in minutes topical segments word error rate
            </definiens>
        </definition>
    </paper>

    <paper id="1045">
    </paper>

    <paper id="2035">
        <definition id="0">
            <sentence>Sentence boundary disambiguation ( SBD ) is an important aspect in developing virtually any
                practical text processing application syntactic parsing , Information Extraction , Machine Translation ,
                Text Alignment , Document Summarization , etc .
            </sentence>
            <definiendum id="0">Sentence boundary disambiguation</definiendum>
            <definiendum id="1">SBD</definiendum>
        </definition>
        <definition id="1">
            <sentence>For instance , the Alembic workbench ( Aberdeen et al. , 1995 ) contains a sentence splitting
                module which employs over 100 regular-expression rules written in Flex .
            </sentence>
            <definiendum id="0">Alembic workbench</definiendum>
            <definiens id="0">contains a sentence splitting module which employs over 100 regular-expression rules
                written in Flex
            </definiens>
        </definition>
        <definition id="2">
            <sentence>Brown Corpus WSJ Corpu s the POS trigrams : hypothesized current POS tag and partially
                disambiguated POS tags of two previous word-tokens .
            </sentence>
            <definiendum id="0">Corpus WSJ Corpu</definiendum>
            <definiens id="0">s the POS trigrams : hypothesized current POS tag and partially disambiguated POS tags of
                two previous word-tokens
            </definiens>
        </definition>
        <definition id="3">
            <sentence>Mandatory positions are positions which might require a word to be capitalized e.g. after a period
                , quotes , brackets , in all-capitalized titles , etc .
            </sentence>
            <definiendum id="0">Mandatory positions</definiendum>
        </definition>
    </paper>

    <paper id="1024">
        <definition id="0">
            <sentence>Edit distance : Edit-distance is a metric for identifying the orthographic similarity of two words
                .
            </sentence>
            <definiendum id="0">Edit distance</definiendum>
            <definiendum id="1">Edit-distance</definiendum>
            <definiens id="0">a metric for identifying the orthographic similarity of two words</definiens>
        </definition>
        <definition id="1">
            <sentence>The test data consists of ten samples of 2100 records selected randomly with replacement from the
                test corpus .
            </sentence>
            <definiendum id="0">test data</definiendum>
            <definiens id="0">consists of ten samples of 2100 records selected randomly with replacement from the test
                corpus
            </definiens>
        </definition>
    </paper>

</volume>
