<?xml version="1.0" encoding="UTF-8"?>
	<volume id="I05">

		<paper id="2028">
			<definition id="0">
				<sentence>A deterministic finite-state automaton ( DFSA ) is a quintuple M = ( Q ; § ; – ; q0 ; F ) , where Q is a finite set of states , § is the alphabet of M , – : Q £ § !</sentence>
				<definiendum id="0">deterministic finite-state automaton</definiendum>
				<definiendum id="1">DFSA</definiendum>
				<definiendum id="2">Q</definiendum>
				<definiendum id="3">§</definiendum>
				<definiens id="0">a finite set of states</definiens>
			</definition>
			<definition id="1">
				<sentence>Q is the transition function , q0 is the initial state and F Q is the set of final states .</sentence>
				<definiendum id="0">Q</definiendum>
				<definiendum id="1">q0</definiendum>
				<definiens id="0">the transition function ,</definiens>
				<definiens id="1">the initial state</definiens>
				<definiens id="2">the set of final states</definiens>
			</definition>
			<definition id="2">
				<sentence>A path in a DFSA M is a sequence of triples h ( p0 ; a0 ; p1 ) ; : : : ; ( pk¡1 ; ak¡1 ; pk ) i , where ( pi¡1 ; ai¡1 ; pi ) 2 Q£§£Q and – ( pi ; ai ) = pi+1 for 1 • i &lt; k. The string a0a1 : : : ak is the label of the path .</sentence>
				<definiendum id="0">ak</definiendum>
				<definiens id="0">a sequence of triples h ( p0 ; a0 ; p1</definiens>
			</definition>
			<definition id="3">
				<sentence>Minimal acyclic DFSA ( MADFSA ) are the most compact data structure for storing and efficiently recognizing a finite set of words .</sentence>
				<definiendum id="0">Minimal acyclic DFSA</definiendum>
				<definiens id="0">the most compact data structure for storing and efficiently recognizing a finite set of words</definiens>
			</definition>
			<definition id="4">
				<sentence>In order to distinguish between keywords and different attribute values we extend the indexing automaton so that it has n+1 initial states , where n is the number of attributes .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="5">
				<sentence>In our example , the entry for the word Washington ( city ) yields the following subentries : Washington # 1 NAM ( subtype ) VAL ( cap_city ) NAM ( type ) VAL ( city ) Washington # 1 NAM ( variant ) WASHINGTON Washington # 1 NAM ( location ) USA Washington # 1 NAM ( full-name ) Washington D.C. where NAM maps attribute names to single univocal characters not appearing elsewhere in the original gazetteer and VAL denotes a mapping which converts the values of the closed-class attributes into single characters which represent these values .</sentence>
				<definiendum id="0">VAL</definiendum>
				<definiens id="0">a mapping which converts the values of the closed-class attributes into single characters which represent these values</definiens>
			</definition>
</paper>

		<paper id="2027">
			<definition id="0">
				<sentence>Topiary-style headlines consist of a number of general topic labels followed by a compressed version of the lead sentence of a news story .</sentence>
				<definiendum id="0">Topiary-style headlines</definiendum>
				<definiens id="0">consist of a number of general topic labels followed by a compressed version of the lead sentence of a news story</definiens>
			</definition>
			<definition id="1">
				<sentence>A Topiarystyle headline consists of a set of topic labels followed by a compressed version of the lead sentence .</sentence>
				<definiendum id="0">Topiarystyle headline</definiendum>
				<definiens id="0">consists of a set of topic labels followed by a compressed version of the lead sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Hence , the Topiary system views headline generation as a two-step process : first , create a compressed version of the lead sentence of the source text , and second , find a set of topic descriptors that adequately describe the general topic of the news story .</sentence>
				<definiendum id="0">Topiary system views headline generation</definiendum>
				<definiens id="0">first , create a compressed version of the lead sentence of the source text</definiens>
			</definition>
			<definition id="3">
				<sentence>The compression algorithm begins by removing determiners , time expressions and other low content words .</sentence>
				<definiendum id="0">compression algorithm</definiendum>
			</definition>
			<definition id="4">
				<sentence>1 1 The part of speech tags in the example are explained as follows : S represents a simple declarative clause ; SBAR represents a clause introduced by a ( possibly empty ) subordinating conjunction ; NP is a noun phrase ; VP is a verb phrase ; ADVP is an adverbial phrase .</sentence>
				<definiendum id="0">SBAR</definiendum>
				<definiendum id="1">NP</definiendum>
				<definiendum id="2">VP</definiendum>
				<definiendum id="3">ADVP</definiendum>
				<definiens id="0">a simple declarative clause</definiens>
				<definiens id="1">a noun phrase</definiens>
				<definiens id="2">a verb phrase</definiens>
				<definiens id="3">an adverbial phrase</definiens>
			</definition>
			<definition id="5">
				<sentence>A decision tree is a powerful and popular tool for classification and prediction and can be used to classify an instance by starting at the root of the tree and moving down the tree branch until reaching a leaf node .</sentence>
				<definiendum id="0">decision tree</definiendum>
				<definiens id="0">a powerful and popular tool for classification and prediction</definiens>
			</definition>
			<definition id="6">
				<sentence>Lexical chaining is a method of clustering words in a document that are semantically similar with the aid of a thesaurus , in our case WordNet .</sentence>
				<definiendum id="0">Lexical chaining</definiendum>
				<definiens id="0">a method of clustering words in a document that are semantically similar with the aid of a thesaurus</definiens>
			</definition>
			<definition id="7">
				<sentence>where reps i is the frequency of word i in the text , and rel ( i , j ) is a score assigned based on the strength of the relationship between word i and j. More information on the chaining process and cohesion score can be found in Doran et al. ( 2004a ) and Stokes ( 2004 ) .</sentence>
				<definiendum id="0">cohesion score</definiendum>
				<definiens id="0">a score assigned based on the strength of the relationship between word i</definiens>
			</definition>
			<definition id="8">
				<sentence>The DUC 2004 corpus consists of 500 Associated Press and New York Times newswire documents .</sentence>
				<definiendum id="0">DUC 2004 corpus</definiendum>
				<definiens id="0">consists of 500 Associated Press and New York Times newswire documents</definiens>
			</definition>
			<definition id="9">
				<sentence>∑ += ) ) , ( * ) ( ( ) ( jirelrepsrepschainScore ji ( 1 ) 158 sub-string between the system summaries and the models , and ROUGE-W is a weighted version of the LCS measure .</sentence>
				<definiendum id="0">ROUGE-W</definiendum>
				<definiens id="0">a weighted version of the LCS measure</definiens>
			</definition>
			<definition id="10">
				<sentence>TF system is a baseline system that chooses high frequency content words as topic descriptors .</sentence>
				<definiendum id="0">TF system</definiendum>
				<definiens id="0">a baseline system that chooses high frequency content words as topic descriptors</definiens>
			</definition>
</paper>

		<paper id="3030">
			<definition id="0">
				<sentence>Word is a logical semantic and syntactic unit in natural language .</sentence>
				<definiendum id="0">Word</definiendum>
				<definiens id="0">a logical semantic and syntactic unit in natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>HMM model ( one order ) is described as : � n i iiii TTT TTPTWP n 1 1 # ) | ( ) | ( maxarg 21 T , where iT represents the tag of current word , Viterbi algorithm is used to search the best path .</sentence>
				<definiendum id="0">HMM model</definiendum>
				<definiens id="0">described as : � n i iiii TTT TTPTWP n 1 1 # ) | ( ) | ( maxarg 21 T , where iT represents the tag of current word</definiens>
			</definition>
			<definition id="2">
				<sentence>in segmentation disambiguation , where H is the set of possible contexts around target word that will be tagged , and T is the set of allowable tags .</sentence>
				<definiendum id="0">H</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the set of possible contexts around target word that will be tagged</definiens>
				<definiens id="1">the set of allowable tags</definiens>
			</definition>
			<definition id="3">
				<sentence>where h is current context and t is one of the possible tags .</sentence>
				<definiendum id="0">h</definiendum>
				<definiens id="0">current context and t is one of the possible tags</definiens>
			</definition>
</paper>

		<paper id="3023">
			<definition id="0">
				<sentence>Finallyaworddelimiter ( often a blank space , depending on particular corpus ) was added to the right of one character ifit was not the last character of a sentence and it was predicted as end character of word or as a single character word .</sentence>
				<definiendum id="0">Finallyaworddelimiter</definiendum>
				<definiens id="0">the last character of a sentence and it was predicted as end character of word or as a single character word</definiens>
			</definition>
			<definition id="1">
				<sentence>Perceptron is a simple and effective learning algorithm .</sentence>
				<definiendum id="0">Perceptron</definiendum>
				<definiens id="0">a simple and effective learning algorithm</definiens>
			</definition>
			<definition id="2">
				<sentence>C1 C2 C3 C4 as 95.64 90.07 95.47 95.27 cityu 96.64 90.06 96.43 95.14 msr 96.36 89.79 96.00 94.99 pku 96.09 89.99 96.18 94.12 Support vector machines ( SVM ) is a popular learning algorithm , which has been successfully applied to many classification problems in natural language processing .</sentence>
				<definiendum id="0">SVM )</definiendum>
				<definiens id="0">a popular learning algorithm , which has been successfully applied to many classification problems in natural language processing</definiens>
			</definition>
			<definition id="3">
				<sentence>Similar to the PAUM , SVM is a maximal margin algorithm .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">a maximal margin algorithm</definiens>
			</definition>
</paper>

		<paper id="2046">
			<definition id="0">
				<sentence>For example , one can have unknown acronyms , abbreviations , or words containing hyphens , digits , letters , and Greek letters ; Adjectives preceding an NE may or may not be part of that NE depending on the context and applications ; NEs with the same orthographical features may fall into different categories ; An NE may also belong to multiple categories intrinsically ; An NE of one category may contain an NE of another category inside it .</sentence>
				<definiendum id="0">Greek</definiendum>
				<definiendum id="1">Adjectives preceding</definiendum>
			</definition>
			<definition id="1">
				<sentence>The NER problem can then be phrased as the problem of assigning one of 2n + 1 tags to each token , where n is the number of NE categories .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="2">
				<sentence>Formally , we can represent this feature as follows : f ( h , o ) =    1 : if W0-AllCaps ( h ) =true and o=B-protein 0 : otherwise ( 1 ) Here , W0-AllCaps ( h ) is a binary function that returns the value true if all alphabets of the current token in the history h are capitalized .</sentence>
				<definiendum id="0">W0-AllCaps ( h )</definiendum>
				<definiens id="0">a binary function that returns the value true if all alphabets of the current token in the history h are capitalized</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally , the probability of a tag sequence y1 ... yn given a sentence w1 ... wn is approximated as follows : p ( o1 ... on|w1 ... wn ) ≈ nproductdisplay j=1 p ( oj|hj ) ( 4 ) where hj is the context for word wj .</sentence>
				<definiendum id="0">hj</definiendum>
				<definiens id="0">the context for word wj</definiens>
			</definition>
</paper>

		<paper id="2049">
			<definition id="0">
				<sentence>Prof. Wu serves as Associate Editor of ACM Transactions on Speech and Language Processing , Machine Translation , Journal of Natural Language Engineering , and Communications of COLIPS .</sentence>
				<definiendum id="0">Prof. Wu</definiendum>
				<definiens id="0">serves as Associate Editor of ACM Transactions on Speech and Language Processing , Machine Translation , Journal of Natural Language Engineering , and Communications of COLIPS</definiens>
			</definition>
</paper>

		<paper id="3021">
</paper>

		<paper id="4004">
			<definition id="0">
				<sentence>The British National Corpus ( BNC ) is a 100 million word collection of samples of written and spoken language from a wide range of sources , designed to represent a wide crosssection of current British English , both spoken and written .</sentence>
				<definiendum id="0">British National Corpus ( BNC )</definiendum>
				<definiens id="0">a 100 million word collection of samples of written and spoken language from a wide range of sources , designed to represent a wide crosssection of current British English , both spoken and written</definiens>
			</definition>
			<definition id="1">
				<sentence>ISO1179 is an international standard about developing metadata .</sentence>
				<definiendum id="0">ISO1179</definiendum>
				<definiens id="0">an international standard about developing metadata</definiens>
			</definition>
			<definition id="2">
				<sentence>Name is a sting of English letter .</sentence>
				<definiendum id="0">Name</definiendum>
				<definiens id="0">a sting of English letter</definiens>
			</definition>
			<definition id="3">
				<sentence>Publish File : Standard of corpus metadata XML is a widely used language for defining data formats .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">a widely used language for defining data formats</definiens>
			</definition>
			<definition id="4">
				<sentence>As long as a programmer has the XML definition for a collection of data ( often called a `` schema '' ) , they can create a program to process any data format according to those rules .</sentence>
				<definiendum id="0">XML definition</definiendum>
				<definiens id="0">for a collection of data ( often called a `` schema '' ) , they can create a program to process any data format according to those rules</definiens>
			</definition>
</paper>

		<paper id="2014">
			<definition id="0">
				<sentence>For a given maximal order N , a baseline BLEUwN score is the product of two factors : a brevity penalty and the geometric average of modified n-gram precisions computed for all ngrams up to N. BLEUwN score = BP × N vu ut NY n=1 pn The brevity penalty is the exponential of the relative variation in length against the closest reference : BP = ( 1 if |C| &gt; |Rclosest| e1−r/c if |C|≤|Rclosest| where C is the candidate and Rclosest is the closest reference to the candidate according to its length .</sentence>
				<definiendum id="0">brevity penalty</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">Rclosest</definiendum>
				<definiens id="0">the candidate and</definiens>
			</definition>
			<definition id="1">
				<sentence>|S| is the length of a sentence S in words .</sentence>
				<definiendum id="0">|S|</definiendum>
				<definiens id="0">the length of a sentence S in words</definiens>
			</definition>
</paper>

		<paper id="3003">
			<definition id="0">
				<sentence>Support Vector Machines ( SVMs ) are utilized to determine the word dependency relations .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs</definiendum>
				<definiens id="0">utilized to determine the word dependency relations</definiens>
			</definition>
			<definition id="1">
				<sentence>The algorithm consists of two major procedures : ( i ) Extract the surrounding features for the focused node ( or node pair ) .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiens id="0">consists of two major procedures : ( i ) Extract the surrounding features for the focused node ( or node pair )</definiens>
			</definition>
			<definition id="2">
				<sentence>The operations of the Nivre algorithm � recaptured VV F��s ( name ) NR S I � recaptured VV F��s ( name ) NR S I Right S I � recaptured VV F��s ( name ) NR S I Left S I S I Reduce S I S I Shift � recaptured VV F��s ( name ) NR � $ R Taiwan NR � $ R Taiwan NR � recaptured VV F��s ( name ) NR � $ R Taiwan NR � recaptured VV F��s ( name ) NR � $ R Taiwan NR , X DE DEG , X DE DEG � recaptured VV F��s ( name ) NR � $ R Taiwan NR � recaptured VV F��s ( name ) NR � $ R Taiwan NR �� great VA , X DE DEG �� great VA , X DE DEG s� Triumph NN �� great VA �� great VA , X DE DEG , X DE DEG �� great VA � $ R Taiwan NR � $ R Taiwan NR position t-1 position n position n+1position t t-1 n n+1t t-1 n n+1t t-1 n n+1t t-1 n n+1t t-1 n n+1t t-1 n n+1t t-1 n n+1t A { } A { F��s- &gt; � } A { F��s- &gt; � } A { F��s- &gt; � , � $ R- &gt; � } A { F��s- &gt; � , � $ R- &gt; � } A { F��s- &gt; � , � $ R- &gt; � } A { F��s- &gt; � , � $ R- &gt; � } A { F��s- &gt; � , � $ R- &gt; � } 18 We utilize a bottom-up deterministic algorithm proposed by ( Nivre and Scholz , 2004 ) in our analyzer .</sentence>
				<definiendum id="0">VV F��s</definiendum>
				<definiens id="0">( name ) NR S I � recaptured VV F��s ( name ) NR S I Right S I � recaptured VV F��s ( name ) NR S I Left S I S I Reduce S I S I Shift � recaptured VV F��s ( name ) NR � $ R Taiwan NR � $ R Taiwan NR � recaptured VV F��s ( name ) NR � $ R Taiwan NR � recaptured VV F��s ( name ) NR � $ R Taiwan NR , X DE DEG , X DE DEG � recaptured VV F��s ( name ) NR � $ R Taiwan NR �</definiens>
				<definiens id="1">great VA � $ R Taiwan NR � $ R Taiwan NR position t-1 position n position n+1position t t-1 n n+1t t-1 n n+1t t-1 n n+1t t-1 n n+1t t-1 n n+1t t-1 n n+1t t-1 n n+1t A { } A { F��s- &gt; � } A { F��s- &gt; � } A { F��s- &gt; �</definiens>
			</definition>
			<definition id="3">
				<sentence>S and I are stacks , S keeps the words being in consideration , and I keeps the words to be processed .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">keeps the words being in consideration</definiens>
			</definition>
			<definition id="4">
				<sentence>( zx , K is a kernel function which maps vectors into a higher dimensional space .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">a kernel function which maps vectors into a higher dimensional space</definiens>
			</definition>
			<definition id="5">
				<sentence>2 , for example , the analyzer is considering the relation between focused words “ A� ( tell ) ” and “� ( he ) ” .</sentence>
				<definiendum id="0">analyzer</definiendum>
				<definiens id="0">considering the relation between focused words “ A� ( tell</definiens>
			</definition>
			<definition id="6">
				<sentence>Our dependency analyzer is a bottom-up deterministic analyzer .</sentence>
				<definiendum id="0">dependency analyzer</definiendum>
			</definition>
			<definition id="7">
				<sentence>The root finder analyzes each word in the sentence and gives the tag “true” or “false” to indicate the root word .</sentence>
				<definiendum id="0">root finder</definiendum>
				<definiens id="0">analyzes each word in the sentence and gives the tag “true” or “false” to indicate the root word</definiens>
			</definition>
</paper>

		<paper id="2033">
			<definition id="0">
				<sentence>Transformation Based Learning is a rule-based method that we will discuss in depth in Section 2 .</sentence>
				<definiendum id="0">Transformation Based Learning</definiendum>
			</definition>
			<definition id="1">
				<sentence>Brill’s implementation consists of two processing steps .</sentence>
				<definiendum id="0">Brill’s implementation</definiendum>
				<definiens id="0">consists of two processing steps</definiens>
			</definition>
			<definition id="2">
				<sentence>TBL belongs to the group of learners that generates abstract information , i.e. only the class label of the source instance .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">the group of learners that generates abstract information</definiens>
			</definition>
			<definition id="3">
				<sentence>TBL operates on words , but words are not treated as independent instances .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">operates on words</definiens>
			</definition>
</paper>

		<paper id="2029">
			<definition id="0">
				<sentence>Our virtual photos consist of three major parts : the image , the object locator map and the object descriptors .</sentence>
				<definiendum id="0">virtual photos</definiendum>
				<definiens id="0">consist of three major parts : the image , the object locator map and the object descriptors</definiens>
			</definition>
			<definition id="1">
				<sentence>The object locator map ( OLM ) is an imagespace map that corresponds 1-to-1 with the pixels in the virtual photograph image .</sentence>
				<definiendum id="0">OLM</definiendum>
				<definiens id="0">an imagespace map that corresponds 1-to-1 with the pixels in the virtual photograph image</definiens>
			</definition>
			<definition id="2">
				<sentence>The object descriptors contain the semantic description of the objects plus some metadata that helps determine how the player and NPC can interact with the objects in the photo .</sentence>
				<definiendum id="0">object descriptors</definiendum>
				<definiens id="0">the semantic description of the objects plus some metadata that helps determine how the player</definiens>
			</definition>
</paper>

		<paper id="3034">
			<definition id="0">
				<sentence>PER iff Wi is a person name LOC iff Wi is a location name ORG iff Wi is an organization name NUM iff Wi is a numeral expression TIME iff Wi is a time expression Figure 1 : Class Definition of word Wi In constructing the graph , PCWS detect the ambiguities of the segmentation and classify the ambiguities into two classes : the false ambiguity and the true ambiguity .</sentence>
				<definiendum id="0">PER iff Wi</definiendum>
				<definiendum id="1">Wi</definiendum>
				<definiens id="0">a numeral expression TIME iff</definiens>
			</definition>
			<definition id="1">
				<sentence>If S is a Chinese sentence which is a character sequence , W is the all possible word sequences given S , ) � # = { W1 ) �W2 ) �… ) �WN } is a word sequence , ) �= { C1 ) �C2 ) �… ) �CN } is a corresponding class sequence of ) � # .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">a Chinese sentence which is a character sequence ,</definiens>
				<definiens id="1">the all possible word sequences given S</definiens>
				<definiens id="2">a word sequence</definiens>
			</definition>
			<definition id="2">
				<sentence>-logP ( | ) iff PER 0 else e Here generate-logP ( | ) iff LOCgenloc ( | ) = 0 else i i i i i w c cw c</sentence>
				<definiendum id="0">iff LOCgenloc</definiendum>
				<definiens id="0">-logP ( | ) iff PER 0 else e Here generate-logP ( | )</definiens>
			</definition>
</paper>

		<paper id="5011">
			<definition id="0">
				<sentence>Here , an NE instance pair is any pair of NEs separated by at most 4 syntactic chunks ; for example , “IBM plans to acquire Lotus” .</sentence>
				<definiendum id="0">NE instance pair</definiendum>
				<definiens id="0">any pair of NEs separated by at most 4 syntactic chunks ; for example</definiens>
			</definition>
			<definition id="1">
				<sentence>Here , the term frequency ( TF ) is the frequency of a word in the bag and the inverse term frequency ( ITF ) is the inverse of the log of the frequency in the entire corpus .</sentence>
				<definiendum id="0">term frequency</definiendum>
				<definiendum id="1">TF</definiendum>
				<definiendum id="2">inverse term frequency</definiendum>
				<definiendum id="3">ITF</definiendum>
				<definiens id="0">the frequency of a word in the bag and the</definiens>
				<definiens id="1">the inverse of the log of the frequency in the entire corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>Here , “EG” represents “Eastern Group Plc” .</sentence>
				<definiendum id="0">“EG”</definiendum>
			</definition>
			<definition id="3">
				<sentence>Notice that the CC-domain is a special case .</sentence>
				<definiendum id="0">CC-domain</definiendum>
				<definiens id="0">a special case</definiens>
			</definition>
			<definition id="4">
				<sentence>This research was supported in part by the Defense Advanced Research Projects Agency as part of the Translingual Information Detection , Extraction and Summarization ( TIDES ) program , under Grant N66001-001-1-8917 from the Space and Naval Warfare Systems Center , San Diego , and by the National Science Foundation under Grant IIS-00325657 .</sentence>
				<definiendum id="0">Extraction</definiendum>
				<definiens id="0">supported in part by the Defense Advanced Research Projects Agency as part of the Translingual Information Detection</definiens>
			</definition>
</paper>

		<paper id="6008">
			<definition id="0">
				<sentence>watch’ , variation affects verb tense inflection , adjective modifiers ( close , better , regular , daily ) , noun number morpheme ( tab ( s ) ) and the location of the on complement phrase that may be separate from the object NP .</sentence>
				<definiendum id="0">adjective modifiers</definiendum>
			</definition>
			<definition id="1">
				<sentence>These observations suggest that : ( i ) not all fixed expressions and idioms are frozen word combinations given that , parts of the expression participate in syntactic operations ; ( ii ) some lexemes ( in ‘fixed’ expressions ) are subject to morphological processes ; and ( iii ) , some fixed expressions still preserve underlying semantic structure .</sentence>
				<definiendum id="0">lexemes</definiendum>
				<definiens id="0">all fixed expressions and idioms are frozen word combinations given that , parts of the expression participate in syntactic operations</definiens>
			</definition>
			<definition id="2">
				<sentence>A P N V triple represents an abstraction of a support verb construction ( LVC ) .</sentence>
				<definiendum id="0">P N V triple</definiendum>
				<definiendum id="1">LVC</definiendum>
				<definiens id="0">represents an abstraction of a support verb construction</definiens>
			</definition>
			<definition id="3">
				<sentence>Negative evidence ( noise ) typically includes sentences where the VERB and the PP occur within the same clause but not in the LVC context ( in its literal use ) .</sentence>
				<definiendum id="0">Negative evidence</definiendum>
				<definiens id="0">includes sentences where the VERB and the PP occur within the same clause</definiens>
			</definition>
			<definition id="4">
				<sentence>Often , the PP is an adjunct or a complement of another verb .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">an adjunct or a complement of another verb</definiens>
			</definition>
			<definition id="5">
				<sentence>Once we have a list of PREPOSITION NOUN VERB triples , methods described in the literature on automatic acquisition of subcategorization information might be successful in finding out the remaining LVC syntactic requirements .</sentence>
				<definiendum id="0">PREPOSITION NOUN VERB</definiendum>
				<definiens id="0">triples , methods described in the</definiens>
			</definition>
			<definition id="6">
				<sentence>4 An extended subcategorization frame consists of two parts : ( a ) list of syntactic dependents and ( b ) syntactic operations that the LVC ( dis ) allows .</sentence>
				<definiendum id="0">extended subcategorization frame</definiendum>
			</definition>
			<definition id="7">
				<sentence>68 lexicalized phrase is a string of lexemes – each in their surface form – and is represented within ‘ [ ] ’ : houden 〈 dat , [ de , hand ] , [ boven , het , hoofd ] 〉 houden 〈 refl , [ van , de , domme ] 〉 Partially lexicalized phrases declare the type of argument they introduce e.g. accusative , semifixed prepositional phrase , predicative argument .</sentence>
				<definiendum id="0">lexicalized phrase</definiendum>
				<definiens id="0">a string of lexemes – each in their surface form – and is represented within ‘ [ ] ’ : houden 〈 dat , [ de , hand ]</definiens>
			</definition>
</paper>

		<paper id="2038">
			<definition id="0">
				<sentence>Now that focus of information extraction is shifting from extraction of “nominal” information such as named entity to “verbal” information such as relations of entities including events and functions , syntactic analysis is an important issue of NLP application in biomedical domain .</sentence>
				<definiendum id="0">information extraction</definiendum>
				<definiens id="0">an important issue of NLP application in biomedical domain</definiens>
			</definition>
			<definition id="1">
				<sentence>GTB is the addition of syntactic information to the GENIA corpus .</sentence>
				<definiendum id="0">GTB</definiendum>
			</definition>
			<definition id="2">
				<sentence>Similar attempt of constructing integrated corpora is being done in University of Pennsylvania , where a corpus of MEDLINE abstracts in CYP450 and oncology domains where annotated for named entities , POS , and tree structure of sentences ( Kulick et al , 2004 ) .</sentence>
				<definiendum id="0">MEDLINE</definiendum>
				<definiens id="0">abstracts in CYP450 and oncology domains where annotated for named entities , POS , and tree structure of sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>Currently the accuracy of the parser drops down to 82 % on GTB-beta , and although proper quantitative analysis is yet to be done , it was found that the mismatches between labels of the treebank and the GENIA POS corpus ( e.g. an –ing form labeled as noun in the POS corpus and as the head of a verb phrase in the tree corpus ) are a major source of parse error .</sentence>
				<definiendum id="0">GENIA POS corpus</definiendum>
				<definiens id="0">the head of a verb phrase in the tree corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>The GENIA term corpus annotates the full form of a technical term whose part is omitted in the surface as an attribute of the ‘ &lt; cons &gt; ’ element indicating a technical term ( Kim et al. , 2003 ) .</sentence>
				<definiendum id="0">GENIA term corpus</definiendum>
			</definition>
</paper>

		<paper id="4009">
			<definition id="0">
				<sentence>Open-Domain Question Answering System ( QA ) has gain great popularities among scholars who care the above problem ( Li , et al. 2002 ; Moldovan , et al. 2003 ; Zhang , et al. 2003 ) , for QA can meet users’ demand by offering compact and accurate answers , rather than text with corresponding answers , to the questions presented in natural language .</sentence>
				<definiendum id="0">Open-Domain Question Answering System</definiendum>
			</definition>
			<definition id="1">
				<sentence>QC is an essential part of QA , for to correctly answer users’ questions , the system has to know what the users are looking for , and it is QC that presents important searching clues for the system .</sentence>
				<definiendum id="0">QC</definiendum>
				<definiens id="0">an essential part of QA , for to correctly answer users’ questions , the system has to know what the users are looking for , and it is QC that presents important searching clues for the system</definiens>
			</definition>
			<definition id="2">
				<sentence>Therefore to obtain higher classifying accuracy , QC has to make further analysis of sentences , namely QC has to extend interrogative sentence with syntactic and semantic knowledge , replacing or extending the vocabulary of the question with the semantic meaning of every words .</sentence>
				<definiendum id="0">QC</definiendum>
				<definiens id="0">has to make further analysis of sentences , namely QC has to extend interrogative sentence with syntactic and semantic knowledge , replacing or extending the vocabulary of the question with the semantic meaning of every words</definiens>
			</definition>
			<definition id="3">
				<sentence>analyzer , which can analyze the dependency relation of words in sentences .</sentence>
				<definiendum id="0">analyzer</definiendum>
				<definiens id="0">can analyze the dependency relation of words in sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>“Word” is a word in the input sentence .</sentence>
				<definiendum id="0">“Word”</definiendum>
				<definiens id="0">a word in the input sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>TBL is a true machine learning technique .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">a true machine learning technique</definiens>
			</definition>
			<definition id="6">
				<sentence>TBL generates all of the potential rules that would make at least one tag in the training corpus correct .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">generates all of the potential rules that would make at least one tag in the training corpus correct</definiens>
			</definition>
			<definition id="7">
				<sentence>Adaboost ( Schapire 1997 ; Schapire 1999 ) is an effective classifier combination method .</sentence>
				<definiendum id="0">Adaboost</definiendum>
				<definiens id="0">an effective classifier combination method</definiens>
			</definition>
</paper>

		<paper id="4002">
			<definition id="0">
				<sentence>Parsing is one of the important processes for natural language processing and , in general , a large-scale CFG is used to parse a wide variety of sentences .</sentence>
				<definiendum id="0">Parsing</definiendum>
				<definiens id="0">one of the important processes for natural language processing and , in general , a large-scale CFG is used to parse a wide variety of sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>Parsing is one of the important processes for natural language processing and , in general , a largescale CFG is used to parse a wide variety of sentences .</sentence>
				<definiendum id="0">Parsing</definiendum>
				<definiens id="0">one of the important processes for natural language processing and , in general , a largescale CFG is used to parse a wide variety of sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>We used the EDR corpus ( EDR , 1994 ) for developing our annotation policy , and annotated 8,911 sentences in the corpus and 20,190 sentences in the RWC corpus ( Hashida et al. , 1998 ) .</sentence>
				<definiendum id="0">EDR corpus</definiendum>
			</definition>
			<definition id="3">
				<sentence>A CFG is derived from all sentences in our corpus , with which we parsed 6,931 sentences ( POS sequences ) in the Kyoto corpus 1 by MSLR parser ( Shirai et al. , 2000 ) .</sentence>
				<definiendum id="0">CFG</definiendum>
			</definition>
			<definition id="4">
				<sentence>Structure ambiguity of adnominal phrase attachment needs to be disambiguated in extracting dependency relations in step ( 4 ) since it is represented as the same structure according to our policy 2 .</sentence>
				<definiendum id="0">Structure ambiguity of adnominal phrase attachment</definiendum>
			</definition>
			<definition id="5">
				<sentence>In this case , “NEAREST” means only PGLR model was used for disambiguation without any other information ( e.g. lexical infor13 Table 1 : Segmentation , dependency , and sentence accuracy ( D2 BP BD ) Segmentation Dependency Sentence NEAREST 65.68 % 87.88 % 50.47 % BEST 65.68 % 90.27 % 57.73 % KNP 96.90 % 91.32 % 60.07 % CaboCha 84.88 % 92.88 % 64.48 % 45 50 55 60 65 70 75 80 85 90 95 100 0 10 20 30 40 50 60 70 80 90 100 Segmentation / Dependency / Sentence Accuracy ( % ) Rank by PGLR model ( top-n parse results ) 76.53 93.10 66.85 95.24 75.72 Segmentation Accuracy Dependency Accuracy ( NEAREST ) Dependency Accuracy ( BEST ) Sentence Accuracy ( NEAREST ) Sentence Accuracy ( BEST ) Figure 6 : Segmentation , dependency , and sentence accuracy ( D2 BP BDBMBMBMBDBCBC ) mation , semantic information , etc. ) On the other hand , “BEST” means only disambiguation of adnominal phrase attachment was done in the subsequent processing .</sentence>
				<definiendum id="0">Segmentation</definiendum>
				<definiendum id="1">sentence accuracy</definiendum>
				<definiens id="0">Segmentation , dependency , and sentence accuracy</definiens>
			</definition>
</paper>

		<paper id="3007">
			<definition id="0">
				<sentence>In terms of size and completeness of extracted data , Sinica Corpus returns all matched examples .</sentence>
				<definiendum id="0">Sinica Corpus</definiendum>
				<definiens id="0">returns all matched examples</definiens>
			</definition>
			<definition id="1">
				<sentence>The Sketch Engine has a versatile query system .</sentence>
				<definiendum id="0">Sketch Engine</definiendum>
				<definiens id="0">a versatile query system</definiens>
			</definition>
			<definition id="2">
				<sentence>Most of all , the Sketch Engine produces a Word Sketch ( Kilgarriff and Tugwell , 2002 ) that is an automatically generated grammatical description of a lemma in terms of corpus collocations .</sentence>
				<definiendum id="0">Sketch Engine</definiendum>
				<definiens id="0">an automatically generated grammatical description of a lemma in terms of corpus collocations</definiens>
			</definition>
			<definition id="3">
				<sentence>A Word Sketch is a one-page list of a keyword’s functional distribution and collocation in the corpus .</sentence>
				<definiendum id="0">Word Sketch</definiendum>
				<definiens id="0">a one-page list of a keyword’s functional distribution and collocation in the corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>Word Sketch uses regular expressions over POS-tags to formalize rules of collocation patterns , e.g. ( 2 ) is used to retrieve the verb-object relation in English : The expression in ( 2 ) says : extract the data containing a verb followed by a noun regardless of how many determiners , numerals , adjectives , adverbs and nouns preceding the noun .</sentence>
				<definiendum id="0">Word Sketch</definiendum>
				<definiens id="0">uses regular expressions over POS-tags to formalize rules of collocation patterns</definiens>
				<definiens id="1">The expression in ( 2 ) says : extract the data containing a verb followed by a noun regardless of how many determiners</definiens>
			</definition>
			<definition id="5">
				<sentence>The Chinese Sketch Engine inserted space after segmentation , which helps to visualize words .</sentence>
				<definiendum id="0">Chinese Sketch Engine</definiendum>
				<definiendum id="1">segmentation</definiendum>
			</definition>
			<definition id="6">
				<sentence>The Sketch Engine relies on collocation patterns , such as ( 2 ) above , to extract collocations .</sentence>
				<definiendum id="0">Sketch Engine</definiendum>
				<definiens id="0">relies on collocation patterns</definiens>
			</definition>
			<definition id="7">
				<sentence>These ICG frames , called Basic Patterns and Adjunct Patterns , have already been fully annotated lexically and tested on the Sinica Corpus .</sentence>
				<definiendum id="0">ICG</definiendum>
			</definition>
</paper>

		<paper id="2040">
			<definition id="0">
				<sentence>The task of Entity Detection and Tracking ( EDT ) is suggested by the Automatic Content Extraction ( ACE ) project ( NIST , 2003 ) .</sentence>
				<definiendum id="0">Entity Detection</definiendum>
				<definiendum id="1">Tracking ( EDT</definiendum>
			</definition>
			<definition id="1">
				<sentence>The model consists of two sub models : a mention detection model and a coreference model .</sentence>
				<definiendum id="0">model</definiendum>
				<definiens id="0">consists of two sub models : a mention detection model and a coreference model</definiens>
			</definition>
			<definition id="2">
				<sentence>The EDT system is a unified system that uses the TBL scheme .</sentence>
				<definiendum id="0">EDT system</definiendum>
			</definition>
			<definition id="3">
				<sentence>Mention Type ( MT ) : Its possible values are NAME , NOMINAL , or PRONOUN .</sentence>
				<definiendum id="0">Mention Type</definiendum>
			</definition>
			<definition id="4">
				<sentence>Entity Type ( ET ) : Its possible values are PER , GPE , ORG , LOC , or FAC .</sentence>
				<definiendum id="0">Entity Type</definiendum>
				<definiens id="0">Its possible values are PER , GPE , ORG , LOC , or FAC</definiens>
			</definition>
			<definition id="5">
				<sentence>PDD : presents the combination of the mention type and entity type of the mention in discourse .</sentence>
				<definiendum id="0">PDD</definiendum>
				<definiens id="0">presents the combination of the mention type and entity type of the mention in discourse</definiens>
			</definition>
</paper>

		<paper id="2002">
			<definition id="0">
				<sentence>Chinese pause mark is the evident mark with the exclusive usage is to separate coordinate words or simple phrases , so it is easier to get coordinate words or simple phrases in Chinese sentences .</sentence>
				<definiendum id="0">Chinese pause mark</definiendum>
				<definiens id="0">to separate coordinate words or simple phrases , so it is easier to get coordinate words or simple phrases in Chinese sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>Chinese Sentences In essence , English is a kind of hypotaxis language , so an intact syntax structure denotes a sentence .</sentence>
				<definiendum id="0">English</definiendum>
				<definiens id="0">a kind of hypotaxis language , so an intact syntax structure denotes a sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Differently , Chinese is a kind of parataxis language , and the language unit which expresses a complete thought is an intact Chinese sentence .</sentence>
				<definiendum id="0">Chinese</definiendum>
				<definiens id="0">a kind of parataxis language , and the language unit which expresses a complete thought is an intact Chinese sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Sub-tree adjoining operation Then the execution conditions and results of such adjoining operation are summarized as following rules : [ ] [ ... ] [ [ [ ] ] ... ] ++ ⇒S XYY SXXX YYXg712g450 g712g450 X = { NP , VP , AP , DP } , S stands for sentence , Y = * ( any legal POS ) ( 2 ) [ ... ] [ ] [ ... [ [ ] ] ] ++ ⇒SY Y X SY Y X X XXg450g712 g450 g712 X = { NP , VP , AP , DP } , S stands for sentence , Y = * ( any legal POS ) ( 3 ) 10 The execution conditions of both Rule ( 2 ) and ( 3 ) are defined as follows : all X should be coordinate phrases with the same syntactic categories .</sentence>
				<definiendum id="0">Sub-tree adjoining operation</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">] ] ++ ⇒SY Y X SY Y X</definiendum>
				<definiendum id="3">S</definiendum>
				<definiendum id="4">POS )</definiendum>
				<definiens id="0">stands for sentence</definiens>
				<definiens id="1">stands for sentence</definiens>
				<definiens id="2">follows : all X should be coordinate phrases with the same syntactic categories</definiens>
			</definition>
</paper>

		<paper id="7008">
</paper>

		<paper id="2042">
			<definition id="0">
				<sentence>BEG INT ADV ENG JPN ENG JPN ENG JPN CHU * * * √ * * RUB * * * √ * * MT * * * √ * √ E &amp; MT √ * * * * * Table 5 .</sentence>
				<definiendum id="0">BEG INT ADV ENG JPN ENG JPN ENG JPN CHU</definiendum>
				<definiens id="0">* * * √ * * RUB * * * √ * * MT * * * √ * √ E &amp; MT √ * * * * * Table 5</definiens>
			</definition>
</paper>

		<paper id="6001">
			<definition id="0">
				<sentence>The TIGER-DB has been derived semiautomatically from ( a subset of ) the TIGERLFG Bank of Forst ( 2003 ) , which is in turn derived from the TIGER treebank .</sentence>
				<definiendum id="0">TIGER-DB</definiendum>
				<definiens id="0">in turn derived from the TIGER treebank</definiens>
			</definition>
			<definition id="1">
				<sentence>So-called dependency triples are sets of two-place predicates that encode grammatical relations , the arguments representingthe head of the dependency and the dependent , respectively .</sentence>
				<definiendum id="0">So-called dependency triples</definiendum>
				<definiens id="0">sets of two-place predicates that encode grammatical relations , the arguments representingthe head of the dependency and the dependent</definiens>
			</definition>
			<definition id="2">
				<sentence>The semantic representation of a phrase is defined as the assembly and combination of the RMRSs of its daughters , according to semantic constraints , which apply in parallel with syntactic constraints .</sentence>
				<definiendum id="0">semantic representation of a phrase</definiendum>
				<definiens id="0">the assembly and combination of the RMRSs of its daughters , according to semantic constraints , which apply in parallel with syntactic constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>Construction Copestake et al. ( 2001 ) define a semantic entity as a 5-tuple 〈s1 , s2 , s3 , s4 , s5〉 such that s1 is a hook , s2 is a ( possibly empty ) set of holes , s3 and s4 are bags of Elementary Predications ( EPs ) and handle constraints , respectively , and s5 is a set of equalities holding between variables .</sentence>
				<definiendum id="0">s2</definiendum>
				<definiendum id="1">s5</definiendum>
				<definiens id="0">a semantic entity as a 5-tuple 〈s1 , s2 , s3 , s4 , s5〉 such that s1 is a hook</definiens>
				<definiens id="1">a ( possibly empty ) set of holes</definiens>
				<definiens id="2">a set of equalities holding between variables</definiens>
			</definition>
			<definition id="4">
				<sentence>An EP h : r ( a1 , ... , an , sa1 , ... , sam ) consists of the EP’s handle ( or label ) h , a relation r , and a list of zero or more variable arguments a1 , ... , an , followed by zero or more scopal arguments sa1 , ... , sam ( denoting handles ) of the relation .</sentence>
				<definiendum id="0">EP h</definiendum>
				<definiendum id="1">a1 , ... , an , sa1 , ... , sam )</definiendum>
				<definiens id="0">consists of the EP’s handle ( or label ) h , a relation r , and a list of zero or more variable arguments a1 , ... , an , followed by zero or more scopal arguments sa1 , ... , sam ( denoting handles ) of the relation</definiens>
			</definition>
			<definition id="5">
				<sentence>The operators of semantic composition opl1 , ... , oplk are drawn from Σ × Σ → Σ , where Σ is the set of all semantic entities , and l1 , ... , lk correspond to the labels on holes : An operator opli defines the composition of a semantic head which has a hole labelled li with the argument filling that hole as follows : The result of opli ( a1 , a2 ) is undefined if a2 has no hole labelled li , otherwise : holeslprime ( a2 ) for all labels lprime negationslash= li ; { hook ( a1 ) = holeli ( a2 ) } ) ; where Tr stands for the transitive closure .</sentence>
				<definiendum id="0">Σ</definiendum>
				<definiendum id="1">Tr</definiendum>
				<definiens id="0">the set of all semantic entities , and l1 , ... , lk correspond to the labels on holes : An operator opli defines the composition of a semantic head</definiens>
				<definiens id="1">all labels lprime negationslash= li ; { hook ( a1 ) = holeli ( a2 ) } ) ; where</definiens>
			</definition>
			<definition id="6">
				<sentence>Lexical RMRSs are semantic entities which consist of only a hook ( i.e. a label and a variable ) , that makes the entity available for reference by subsequent ( composition ) rules , whereas the basic semantic content ( which is determined on the basis of the predicate’s category , and comprises , at least , EPs for the relation and the ARG0 ) 5 is uniformly maintained in the bags of the global RMRS , yet still anchored to the lexical hook labels and variables .</sentence>
				<definiendum id="0">Lexical RMRSs</definiendum>
				<definiendum id="1">EPs for</definiendum>
				<definiens id="0">semantic entities which consist of only a hook ( i.e. a label and a variable ) , that makes the entity available for reference by subsequent ( composition ) rules , whereas the basic semantic content ( which is determined on the basis of the predicate’s category</definiens>
				<definiens id="1">the relation and the ARG0 ) 5 is uniformly maintained in the bags of the global RMRS , yet still anchored to the lexical hook labels and variables</definiens>
			</definition>
			<definition id="7">
				<sentence>tively.6 We interpret the arg-predicate as a slot/hole of the functor , such that the binding of the argument to the functor comes down to filling the hole , in the sense of the algebra described above : This is steered by the previously defined hooks of the two semantic entities , in that the matching rule introduces an EP with an attribute ARGN that is anchored to the externalised label in the functor’s hook .</sentence>
				<definiendum id="0">matching rule</definiendum>
				<definiens id="0">introduces an EP with an attribute ARGN that is anchored to the externalised label in the functor’s hook</definiens>
			</definition>
			<definition id="8">
				<sentence>comp_form ( _ , ob ) ) , and we can fully determine the kind of message relation from its lexical form , i.e. , prpstn m rel for declarative and int m rel for interrogative ones .</sentence>
				<definiendum id="0">comp_form</definiendum>
				<definiens id="0">the kind of message relation from its lexical form , i.e. , prpstn m rel for declarative and int m rel for interrogative ones</definiens>
			</definition>
			<definition id="9">
				<sentence>Related work in Dyvik et al. ( 2005 ) presents MRS construction from LFG grammars in a correspondence architecture , where semantics is defined as a projection in individual syntactic rules .</sentence>
				<definiendum id="0">semantics</definiendum>
				<definiens id="0">presents MRS construction from LFG grammars in a correspondence architecture</definiens>
				<definiens id="1">a projection in individual syntactic rules</definiens>
			</definition>
</paper>

		<paper id="5003">
			<definition id="0">
				<sentence>Position-independent word error rate ( PER ) ( Tillmann et al. , 1997 ) is similar to WER except that word order is not taken into account , both sentences are treated as bags of words : PER ( si , ri ) = max [ diff ( si , ri ) , diff ( ri , si ) ] |r i| where diff ( si , ri ) is the number of words observed only in si .</sentence>
				<definiendum id="0">PER )</definiendum>
				<definiens id="0">the number of words observed only in si</definiens>
			</definition>
			<definition id="1">
				<sentence>I ngram∈si where count ( ngram ) is the count of ngram found in both si and ri and countsys ( ngram ) is the count of ngram in si .</sentence>
				<definiendum id="0">count ( ngram )</definiendum>
				<definiens id="0">the count of ngram found in both si</definiens>
			</definition>
			<definition id="2">
				<sentence>The brevity penalty BP penalizes MT output for being shorter than the corresponding references and is given by : BP = exp bracketleftBigg min bracketleftBigg 1− LrefL sys ,1 bracketrightBiggbracketrightBigg where Lsys is the number of words in the MT output sentences and Lref is the number of words in the corresponding references .</sentence>
				<definiendum id="0">Lsys</definiendum>
				<definiendum id="1">Lref</definiendum>
				<definiens id="0">the number of words in the MT output sentences and</definiens>
			</definition>
			<definition id="3">
				<sentence>The NIST score ( Doddington , 2002 ) also uses n-gram precision , differing in that an arithmetic mean is used , weights are used to emphasize informative word sequences and a different brevity penalty is used : NIST = Nsummationdisplay n=1 BP × summationtext info ( ngram ) all ngram that co−occursummationtext 1 ngram∈si 18 Sentence pair 1 ( semantically equivalent ) : Sentence pair 2 ( not semantically equivalent ) : Sentence pair 3 ( semantically equivalent ) : Figure 1 : Example sentences from the Microsoft Research Paraphrase Corpus ( MSRP ) info is defined to be : info ( ngram ) = log2 bracketleftbiggcount ( ( n−1 ) gram ) count ( ngram ) bracketrightbigg where count ( ngram ) is the count of ngram = w1w2 ... wn in all the reference translations , and ( n−1 ) gram is w1w2 ... wn−1 .</sentence>
				<definiendum id="0">NIST score</definiendum>
				<definiendum id="1">Paraphrase Corpus</definiendum>
				<definiens id="0">n-gram precision , differing in that an arithmetic mean is used , weights are used to emphasize informative word sequences and a different brevity penalty is used : NIST = Nsummationdisplay n=1 BP × summationtext info ( ngram ) all ngram that co−occursummationtext 1 ngram∈si 18 Sentence pair 1 ( semantically equivalent ) : Sentence pair 2 ( not semantically equivalent ) : Sentence pair 3 ( semantically equivalent ) : Figure 1 : Example sentences from the Microsoft Research</definiens>
				<definiens id="1">the count of ngram = w1w2 ... wn in all the reference translations</definiens>
			</definition>
			<definition id="4">
				<sentence>For NIST the brevity penalty is computed on a segment-by-segment basis and is given by : BP = exp bracketleftBigg β log2min bracketleftBigg Lsys Lref ,1 bracketrightBiggbracketrightBigg where Lsys is the length of the MT system output , Lref is the average number of words in a reference translation and β is chosen to make BP = 0.5 when LsysL ref = 23 .</sentence>
				<definiendum id="0">Lsys</definiendum>
				<definiendum id="1">Lref</definiendum>
				<definiens id="0">the length of the MT system output</definiens>
			</definition>
			<definition id="5">
				<sentence>The value of the feature vector vectorf− corresponding to the contribution to the PER from POS tag t is given by : f−t = summationtext w∈W− count − t ( w ) |si| where count−t ( w ) is the number of times word w occurs in W− with tag t. The feature vector defined above characterizes the nature of the words in the sentences that do not match .</sentence>
				<definiendum id="0">count−t ( w )</definiendum>
				<definiens id="0">the number of times word w occurs in W− with tag t. The feature vector defined above characterizes the nature of the words in the sentences that do not match</definiens>
			</definition>
			<definition id="6">
				<sentence>The MSRP corpus consists of 5801 sentence pairs drawn from a corpus of news articles from the internet .</sentence>
				<definiendum id="0">MSRP corpus</definiendum>
				<definiens id="0">consists of 5801 sentence pairs drawn from a corpus of news articles from the internet</definiens>
			</definition>
			<definition id="7">
				<sentence>ThePASCALdataconsistsof567development sentences and 800 test sentences drawn from 7 domains : comparable document ( CD ) , information extraction ( IE ) , machine translation ( MT ) , questionanswering ( QA ) , readingcomprehension ( RC ) , paraphrasing ( PP ) and information retrieval ( IR ) .</sentence>
				<definiendum id="0">RC</definiendum>
				<definiendum id="1">information retrieval</definiendum>
				<definiendum id="2">IR</definiendum>
				<definiens id="0">800 test sentences drawn from 7 domains : comparable document ( CD ) , information extraction ( IE ) , machine translation</definiens>
			</definition>
			<definition id="8">
				<sentence>WER 68.80±0.90 69.89±1.08 94.20±0.99 80.22±0.69 PER 71.25±1.03 72.05±1.23 93.58±0.59 81.39±0.72 POS70.99±1.16 72.07±1.43 92.99±1.52 81.15±0.79 PER POS72.71±1.34 73.99±1.47 91.67±0.53 81.86±0.97 POS+ 71.56±0.99 72.51±1.20 93.02±1.50 81.46±0.74 POS 74.18±0.94 75.52±1.16 91.13±0.59 82.58±0.76 BLEU1 72.30±1.10 73.71±1.30 91.41±0.70 81.59±0.83 BLEU2 70.26±1.37 71.55±1.46 92.65±0.66 80.72±0.95 BLEU3 68.30±1.42 69.40±1.25 94.54±0.87 80.03±0.97 BLEU4 67.64±1.22 68.46±1.13 96.18±0.67 79.97±0.86 NIST1 71.78±1.44 73.95±1.55 89.65±1.06 81.02±1.04 NIST2 71.64±1.12 73.64±1.43 90.13±0.25 81.03±0.81 NIST3 71.59±1.17 72.94±1.36 91.82±0.39 81.28±0.87 NIST4 71.56±1.17 72.82±1.35 92.08±0.38 81.30±0.87 NIST5 71.52±1.14 72.75±1.33 92.18±0.45 81.30±0.85 ALL 75.35±1.13 77.35±1.10 89.54±0.90 82.99±0.89 Table 2 : Experimental Results ( 10-fold Jackknifing ) Accuracy Precision Recall F-measure WER 68.29 69.35 93.72 79.71 PER 71.88 72.30 93.55 81.56 POS70.96 72.09 91.89 80.79 PER POS73.33 74.14 91.98 82.10 POS+ 70.96 72.09 91.89 80.79 POS 74.20 75.29 91.11 82.45 BLEU1 73.22 74.17 91.63 81.98 BLEU2 70.96 71.62 93.29 81.03 BLEU3 68.93 69.45 95.12 80.28 BLEU4 67.88 68.13 97.12 80.08 NIST1 72.35 73.83 90.50 81.32 NIST2 71.59 73.09 90.67 80.94 NIST3 71.01 72.17 91.80 80.81 NIST4 70.96 72.09 91.89 80.79 NIST5 70.75 71.89 91.67 80.58 ALL 74.96 76.58 89.80 82.66 Table 3 : Experimental Results ( Microsoft’s Provided Train and Test Set ) sorted the sentences pairs of the MSRP corpus according to the length difference ratio ( LDR ) defined in Section 3 , and partitioned the sorted corpusintotwo : lowandhighLDR .</sentence>
				<definiendum id="0">Experimental Results</definiendum>
				<definiens id="0">Microsoft’s Provided Train and Test Set ) sorted the sentences pairs of the MSRP corpus according to the length difference ratio</definiens>
			</definition>
</paper>

		<paper id="2023">
			<definition id="0">
				<sentence>Relation extraction ( RE ) is a basic and important problem in information extraction field .</sentence>
				<definiendum id="0">Relation extraction</definiendum>
				<definiens id="0">a basic and important problem in information extraction field</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , in the Chinese sentence “R V , ^IBM ��� b” ( Gerstner is the chairman of IBM Corporation . )</sentence>
				<definiendum id="0">Gerstner</definiendum>
				<definiens id="0">the chairman of IBM Corporation</definiens>
			</definition>
			<definition id="2">
				<sentence>The automatic learning methods ( Miller et al. , 1998 ; Soderland , 1999 ) are not necessary to have someone on hand with detailed knowledge of how the RE system works , or how to write rules for it .</sentence>
				<definiendum id="0">automatic learning methods</definiendum>
				<definiens id="0">of how the RE system works , or how to write rules for it</definiens>
			</definition>
			<definition id="3">
				<sentence>Different from the feature-based learning methods , the kernel-based methods do not need to extract the features from the original text , but retain the original representation of objects and use the objects in algorithms only via computing a kernel ( similarity ) function between a pair of objects .</sentence>
				<definiendum id="0">feature-based learning methods</definiendum>
				<definiens id="0">the original text , but retain the original representation of objects and use the objects in algorithms only via computing a kernel ( similarity ) function between a pair of objects</definiens>
			</definition>
			<definition id="4">
				<sentence>The kernel methods retain the original representation of objects and use the object only via computing a kernel function between a pair of objects .</sentence>
				<definiendum id="0">kernel methods</definiendum>
				<definiens id="0">the original representation of objects and use the object only via computing a kernel function between a pair of objects</definiens>
			</definition>
			<definition id="5">
				<sentence>The semantic distance between word A and word B can be defined as : Dist ( A , B ) = min a2A ; b2B dist ( a ; b ) where A and B are the semantic sets of word A and word B respectively .</sentence>
				<definiendum id="0">Dist</definiendum>
				<definiens id="0">A , B ) = min a2A ; b2B dist ( a ; b ) where A and B are the semantic sets of word A and word B respectively</definiens>
			</definition>
</paper>

		<paper id="2039">
			<definition id="0">
				<sentence>227 bicorpus The BTEC is a collection of sentences originating from 197 sets ( one set originating from one phrasebook ) of basic travel expressions .</sentence>
				<definiendum id="0">BTEC</definiendum>
				<definiens id="0">a collection of sentences originating from 197 sets ( one set originating from one phrasebook ) of basic travel expressions</definiens>
			</definition>
			<definition id="1">
				<sentence>228 0 0.2 0.4 0.6 0.8 10 100 200 300 400 500 600 700 800 Japanese BTEC Coefficients Occurrences 0 0.2 0.4 0.6 0.8 10 100 200 300 400 500 600 700 800 English BTEC Coefficients Occurrences Line levelPhrasebook level Line levelPhrasebook level Figure 1 : Distributions of similarity coefficients at the sentence level ( thin line ) and at the phrasebook level ( thick line ) , respectively for Japanese and English .</sentence>
				<definiendum id="0">phrasebook level</definiendum>
				<definiens id="0">Distributions of similarity coefficients at the sentence level ( thin line</definiens>
			</definition>
</paper>

		<paper id="3010">
</paper>

		<paper id="2024">
			<definition id="0">
				<sentence>The visualization process classifies the query and retrieval results and places them on a two-dimensional map in topological order according to the similarity between them .</sentence>
				<definiendum id="0">visualization process</definiendum>
				<definiens id="0">classifies the query and retrieval results and places them on a two-dimensional map in topological order according to the similarity between them</definiens>
			</definition>
			<definition id="1">
				<sentence>Suppose we have a set of queries : Q = fQ i ( i = 1 ; ¢¢¢ ; q ) g ; ( 1 ) where q is the total number of queries , and a set of documents : A = fAi j ( i = 1 ; ¢¢¢ ; q ; j = 1 ; ¢¢¢ ; ai ) g ; ( 2 ) where ai is the total number of documents related to Q i. For simplicity , where there is no need to distinguish between queries and documents , we use the same term “documents” and the same notation Di to represent either a query Q i or a document Ai j. That is , we define a new set D = fDi ( i = 1 ; ¢¢¢ ; d ) g = Q [ A ( 3 ) which includes all queries and documents .</sentence>
				<definiendum id="0">q</definiendum>
				<definiendum id="1">q</definiendum>
				<definiendum id="2">ai</definiendum>
				<definiens id="0">the total number of queries , and a set of documents : A = fAi j ( i = 1 ; ¢¢¢ ;</definiens>
				<definiens id="1">the total number of documents related to Q i. For simplicity</definiens>
				<definiens id="2">the same term “documents” and the same notation Di to represent either a query Q i or a document Ai j. That</definiens>
				<definiens id="3">A ( 3 ) which includes all queries and documents</definiens>
			</definition>
			<definition id="2">
				<sentence>We can then code document Di with the elements in the i-th row of the correlative matrix as V ( Di ) = [ di1 ; di2 ; ¢¢¢ ; did ] T : ( 8 ) The V ( Di ) 2 &lt; d is the input to the SOM. Therefore , the method to compute the similarity distance dij is the key to creating the maps. Note that the individual dij of vector V ( Di ) only reflects the relationships between a pair of documents when they are considered independently. To establish the relationships between the document Di and all other documents , representations such as vector V ( Di ) are required. Even if we have these high-dimensional vectors for all the documents , it is still difficult to establish their global relationships. We therefore need to use an SOM to reveal the relationships between these high-dimensional vectors and represent them two-dimensionally. In other words , the role of the SOM is merely to self-organize vectors ; the quality of the maps created depends on the vectors provided. In computing the similarity distance dij between documents , we take two factors into account : ( 1 ) the larger the number of common nouns in two documents , the more similar the two documents should be ( i.e. , the shorter the similarity distance ) ; ( 2 ) the distance between any two queries should be based on their application to the IR processing ; i.e. , by considering the procedure used to rank the documents relating to each query from the map. For this reason , the documentsimilarity distance between queries should be set to the largest value. To satisfy these two factors , dij is calculated as follows : dij = 8 &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; : 1 if both Di and Dj are queries 1¡ jCijjjDij+jDjj¡jCijj not the case mentioned above and i 6= j 0 ; if i=j ( 9 ) where jDij and jDjj are values ( the numbers of elements ) of sets of documents Di and Dj defined by Eq .</sentence>
				<definiendum id="0">distance dij</definiendum>
				<definiens id="0">code document Di with the elements in the i-th row of the correlative matrix as V ( Di ) = [ di1 ; di2 ; ¢¢¢ ; did ] T : ( 8 ) The V ( Di ) 2 &lt; d is the input to the SOM. Therefore , the method to compute the similarity</definiens>
			</definition>
			<definition id="3">
				<sentence>( 5 ) and jCijj is the value of the intersection Cij of the two sets Di and Dj .</sentence>
				<definiendum id="0">jCijj</definiendum>
				<definiens id="0">the value of the intersection Cij of the two sets Di and Dj</definiens>
			</definition>
			<definition id="4">
				<sentence>P = 1q qX i=1 # related to Q i in the retrieved ai documents ai ; ( 17 ) where q is the total number of queries , # means number , and ai is the total number of documents related to Q i as shown in Table 1 .</sentence>
				<definiendum id="0">q</definiendum>
				<definiendum id="1">ai</definiendum>
				<definiens id="0">the total number of queries , # means number</definiens>
			</definition>
</paper>

		<paper id="2001">
			<definition id="0">
				<sentence>Given a multi-category word with a context window of size D0 , suppose the number of preceding ( following ) words is D2 ( i.e. , D0 BP BED2 B7 BD ) , the position attribute vector CE CG of the multi-category word is given by CE CG BP B4CS BD BNBMBMBMBNCS D2 BNCS D2B7BD BNCS D2B7BE BNBMBMBMBNCS D0 B5 , where CS D2B7BD is the value of the position attribute of the multicategory word and CS D2B7BDA0CX ( CS D2B7BDB7CX ) is the value of the position attribute of the CXth preceding ( following ) word .</sentence>
				<definiendum id="0">D2</definiendum>
				<definiendum id="1">CE CG BP B4CS BD BNBMBMBMBNCS D2 BNCS D2B7BD BNCS D2B7BE BNBMBMBMBNCS D0 B5</definiendum>
				<definiendum id="2">CS D2B7BD</definiendum>
				<definiens id="0">the position attribute vector CE CG of the multi-category word is given by</definiens>
				<definiens id="1">the value of the position attribute of the multicategory word and CS D2B7BDA0CX ( CS D2B7BDB7CX ) is the value of the position attribute of the CXth preceding ( following ) word</definiens>
			</definition>
			<definition id="1">
				<sentence>Given a tag set of size D1 B4CR BD BNCR BE BNBMBMBMBNCR D1 B5 , the transition probability table CC is an D1 by D1 matrix and given by : CC CXBNCY BP C8 CC B4CR CX BNCR CY B5 BP CUB4CR CX BNCR CY B5 CUB4CR CX B5 BN where CUB4CR CX BNCR CY B5 is the frequency of the POS tag CR CY appears after the POS tag CR CX in the entire corpus ; CUB4CR CX B5 is the frequency of the POS tag CR CX appears in the entire corpus ; and C8CC is the transition probability .</sentence>
				<definiendum id="0">transition probability table CC</definiendum>
				<definiendum id="1">CUB4CR CX B5</definiendum>
				<definiendum id="2">C8CC</definiendum>
				<definiens id="0">an D1 by D1 matrix and given by : CC CXBNCY BP C8 CC B4CR CX BNCR CY B5 BP CUB4CR CX BNCR CY B5 CUB4CR CX B5 BN where CUB4CR CX BNCR CY B5 is the frequency of the POS tag CR CY appears after the POS tag CR CX in the entire corpus</definiens>
				<definiens id="1">the frequency of the POS tag CR CX appears in the entire corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>Given a tag set of size D1 B4CR BD BNCR BE BNBMBMBMBNCR D1 B5 , the emission probability table BX is an D1 by D1 matrix and given by : BX CXBNCY BP C8 BX B4CR CX BNCR CY B5 BP CUB4CR CX BNCR CY B5 CUB4CR CY B5 BN where CUB4CR CX BNCR CY B5 is the frequency of the POS tag CR CX appears before the POS tag CR CY in the entire corpus ; CUB4CR CY B5 is the frequency of the POS tag CR CY appears in the entire corpus ; and C8BX is the emission probability .</sentence>
				<definiendum id="0">emission probability table BX</definiendum>
				<definiendum id="1">CUB4CR CY B5</definiendum>
				<definiendum id="2">C8BX</definiendum>
				<definiens id="0">an D1 by D1 matrix and given by : BX CXBNCY BP C8 BX B4CR CX BNCR CY B5 BP CUB4CR CX BNCR CY B5 CUB4CR CY B5 BN where CUB4CR CX BNCR CY B5 is the frequency of the POS tag CR CX appears before the POS tag CR CY in the entire corpus</definiens>
				<definiens id="1">the frequency of the POS tag CR CY appears in the entire corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>The first one is the probability of the appearance of the POS tag D8 BG of the multi-category word , which we can write as follows : C8 BVCG B4D8 BG B5 BP CUB4DB BG is tagged as D8 BG B5BPCUB4DB BG B5BN ( 1 ) 3 where CUB4DB BG B5 is the frequency of the appearance of the multi-category word DB BG in the entire corpus and CUB4DB BG CXD7D8CPCVCVCTCSCPD7D8 BG B5 is the frequency of the appearance where the word DB BG is tagged as D8 BG in the entire corpus .</sentence>
				<definiendum id="0">CUB4DB BG B5</definiendum>
				<definiendum id="1">BG B5</definiendum>
				<definiens id="0">the probability of the appearance of the POS tag D8 BG of the multi-category word</definiens>
				<definiens id="1">the frequency of the appearance of the multi-category word DB BG in the entire corpus</definiens>
				<definiens id="2">the frequency of the appearance where the word DB BG is tagged as D8 BG in the entire corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>The second one is transition probability , which is the probability of the appearance of the POS tag D8 CXB7BD in the CX B7 BD position after the POS tag D8 CX in the CX position and shown in Eqn .</sentence>
				<definiendum id="0">transition probability</definiendum>
				<definiens id="0">the probability of the appearance of the POS tag D8 CXB7BD in the CX B7 BD position after the POS tag D8 CX in the CX position and shown in Eqn</definiens>
			</definition>
			<definition id="5">
				<sentence>Multi-category Words After constructing context vectors for all multicategory words from their context windows and POS tagging sequences , the similarity of two context vectors is defined as the Euclidean Distance between the two vectors .</sentence>
				<definiendum id="0">POS tagging sequences</definiendum>
				<definiens id="0">the Euclidean Distance between the two vectors</definiens>
			</definition>
			<definition id="6">
				<sentence>Classification is a process to assign objects that need to be classified to a certain class .</sentence>
				<definiendum id="0">Classification</definiendum>
				<definiens id="0">a process to assign objects that need to be classified to a certain class</definiens>
			</definition>
			<definition id="7">
				<sentence>Define the discriminant function of the class AX CX as CS CX B4DCB5 BP CZ CX BNCX BP BDBNBEBNBMBMBMBNCRBM Then , the discriminant rule of determining the class of the object DC can be defined as follows : CS D1 DC BP D1CPDC CXBPBDBNBEBNBMBMBMBNCR CS CX B4DCB5 B5 DC BE AX D1 In this section , we describe the steps of our classification-based consistency check algorithm in detail .</sentence>
				<definiendum id="0">Define the discriminant function of the class AX CX as CS CX B4DCB5 BP CZ CX BNCX BP BDBNBEBNBMBMBMBNCRBM Then</definiendum>
				<definiens id="0">the discriminant rule of determining the class of the object DC can be defined as follows : CS D1 DC BP D1CPDC CXBPBDBNBEBNBMBMBMBNCR CS CX B4DCB5 B5 DC BE AX D1 In this section , we describe the steps of our classification-based consistency check algorithm in detail</definiens>
			</definition>
			<definition id="8">
				<sentence>Step4 : Comparing the POS of the multi-category word CR in the class that the CZ-NN algorithm assigns DC to and the POS tag of CR .</sentence>
				<definiendum id="0">Step4</definiendum>
				<definiens id="0">Comparing the POS of the multi-category word CR in the class that the CZ-NN algorithm assigns DC to and the POS tag of CR</definiens>
			</definition>
			<definition id="9">
				<sentence>The precision values are closed 5 Table 1 : Experimental Results Number of Number of Number of Test Test multi-category the true the identified Recall Precision corpora type words inconsistencies inconsistencies ( % ) ( % ) 1M-word closed 127,210 1,147 1,219 ( 156 ) 92.67 87.20 500K-word open 64,467 579 583 ( 86 ) 85.84 85.24 test results on our 1M-word training corpus , and were obtained by using AB BP BCBMBG and AC BP BCBMBI in the context vector model .</sentence>
				<definiendum id="0">Recall Precision corpora</definiendum>
				<definiens id="0">Experimental Results Number of Number of Number of Test Test multi-category the true the identified</definiens>
			</definition>
</paper>

		<paper id="7011">
</paper>

		<paper id="5007">
			<definition id="0">
				<sentence>A paraphrases template is a pair of natural language phrases with variables standing in for certain grammatical constructs in ( Daumé and * : Supported by the Key Project of National Natural Science Foundation of China under Grant No. 60435020 49 Marcu , 2003 ) .</sentence>
				<definiendum id="0">paraphrases template</definiendum>
			</definition>
			<definition id="1">
				<sentence>We define two metrics : Strict_Reasonability = S / N Loose_Reasonability = ( L + S ) / N Where N is the total number of the instantiated examples ; S is the number of the paraphrase examples which two phrases in it can be matched all ; L is the number of paraphrase examples only one phrase in a paraphrase can be matched .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">L</definiendum>
				<definiens id="0">the total number of the instantiated examples ;</definiens>
				<definiens id="1">the number of the paraphrase examples which two phrases in it can be matched all ;</definiens>
				<definiens id="2">the number of paraphrase examples only one phrase in a paraphrase can be matched</definiens>
			</definition>
			<definition id="2">
				<sentence>If we sample n examples from a template , the precision of a paraphrase template can be calculated by : Precision = R / ( 4 * n ) Where , R is the number of sentences which is considered to be correct by the evaluator .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the number of sentences which is considered to be correct by the evaluator</definiens>
			</definition>
			<definition id="3">
				<sentence>Evaluators extract every sentence which can be replaced with the correspondent phrase in a paraphrase and the new sentences retain the origin meaning .</sentence>
				<definiendum id="0">Evaluators</definiendum>
				<definiens id="0">extract every sentence which can be replaced with the correspondent phrase in a paraphrase and the new sentences retain the origin meaning</definiens>
			</definition>
			<definition id="4">
				<sentence>Then we define two metrics : Surface_Coverage = M / NS Semantic_Coverage = Map ( K ) / ( Map ( NS-M ) + Map ( K ) ) Where , NS is the number of all manually tagged right words , M is the number of words which can be instantiated from a paraphrase template , K is the number of all the words that generalized the template at the front .</sentence>
				<definiendum id="0">NS</definiendum>
				<definiendum id="1">M</definiendum>
				<definiendum id="2">K</definiendum>
				<definiens id="0">the number of all manually tagged right words</definiens>
				<definiens id="1">the number of words which can be instantiated from a paraphrase template</definiens>
				<definiens id="2">the number of all the words</definiens>
			</definition>
			<definition id="5">
				<sentence>Map ( X ) is the total word number of the word clusters which derived from X word in the semantic dictionary of Cilin ( EV ) .</sentence>
				<definiendum id="0">Map</definiendum>
			</definition>
</paper>

		<paper id="5004">
			<definition id="0">
				<sentence>In example ( 1 ) , a verb phrase , “shigeki-o uketa ( to receive an inspiration ) , ” is paraphrased into a verbalized form of the noun , “shigeki-s-are-ta ( to be inspired ) .”</sentence>
				<definiendum id="0">“shigeki-o uketa</definiendum>
				<definiens id="0">a verb phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>For instance , from example ( 1 ) , we derive a paraphrasing pattern for paraphrasing of light-verb constructions : ( 6 ) s. N-o ( ⇒V ) V N-ACC V t. V ( N ) V ( N ) whereN is avariable which matcheswith a noun , V a verb , V ( N ) denotes the verbalized form of 27 ( e ) confirmed ( revised ) paraphrase ( ) fir ( r i ) r r ( c ) annotator’s judge ( correct / incorrect ) ( ) t t r’ j ( rr t / i rr t ) ( d ) error tags ( ) rr r t ( a ) source sentence ( ) r t ( b ) automatically generated paraphrase ( ) t ti ll r t r r ( c ) second opinion ( correct / incorrect ) ( ) i i ( rr t / i rr t ) Given Obligatory Obligatory Optional ( f ) free comments ( f ) fr t Optional Figure 1 : Annotation schema .</sentence>
				<definiendum id="0">N )</definiendum>
				<definiendum id="1">c ) annotator’s judge</definiendum>
				<definiens id="0">a paraphrasing pattern for paraphrasing of light-verb constructions : ( 6 ) s. N-o ( ⇒V ) V N-ACC V t. V ( N ) V ( N ) whereN is avariable which matcheswith a noun</definiens>
				<definiens id="1">the verbalized form of 27 ( e ) confirmed ( revised ) paraphrase ( ) fir ( r i ) r r</definiens>
			</definition>
			<definition id="2">
				<sentence>Annotators judge each candidate paraphrase with a view of an RDB-based annotation tool ( Figure 1 ) .</sentence>
				<definiendum id="0">Annotators</definiendum>
				<definiens id="0">judge each candidate paraphrase with a view of an RDB-based annotation tool ( Figure 1 )</definiens>
			</definition>
</paper>

		<paper id="4006">
			<definition id="0">
				<sentence>Due to the advantages of the dialogue40 0022 01:37:398-01:41:513 F : D : I : C : ( F g16907g17079g16934g16939 ) [ FILLER : well ] &amp; ( F g16995g17079g17022g17027 ) g16909g16903g16922g16903 [ delicious ] &amp; g16997g16991g17010g17079 g16909g16905g16940g16982g16945 [ Udon ] &amp; g16997g16993g17028g17070g17033 g16909g5163 [ restaurant ] &amp; g16997g17050g17014 g11541g16912g16930g16903g16982g16938g16924g16911 &lt; SB &gt; [ want to go ] &amp; g16991g17000g17018g16991g17070g17026g17012g16999 &lt; SB &gt; 0023 01:42:368-01:49:961 F : O : I : C : g16946g16903 [ well ] &amp; g17034g16991 g16918g16945 [ this area ] &amp; g17006g17033 g12589g16914g16938g16924g16939 [ near ] &amp; g17020g16998g17002g17026g17012g17027 g11946g11824g4848 [ SUWAYA ] &amp; g17012g17066g17055 g3490g9395g12094g6572g16911 [ “CHIKUSA HOUGETSU” ] &amp; g17020g17002g17008g17046g17079g17005g17023g16999 g16919g16921g16903g16961g16924g16911 &lt; SB &gt; [ there are ] &amp; g17007g17009g16991g17049g17012g16999 &lt; SB &gt; Figure 2 : Transcription of in-car dialogue speech Discourse act Action Object Express ( Exp ) Propose ( Pro ) Request ( Req ) Statement ( Sta ) Suggest ( Sug ) Confirm ( Con ) Exhibit ( Exh ) Guide ( Gui ) ReSearch ( ReS ) Reserve ( Rev ) Search ( Sea ) Select ( Sel ) ExhibitDetail ( ExD ) Genre ( Gen ) IntentDetail ( InD ) Parking ( Par ) ParkingInfo ( PaI ) RequestDetail ( ReD ) ReserveInfo ( ReI ) SearchResult ( SeR ) SelectDetail ( SeD ) Shop ( Sho ) ShopInfo ( ShI ) Figure 3 : A part of the LIT structural rules being represented by context free grammars , we were able to use an existing technique for natural language processing to reduce the annotation burden .</sentence>
				<definiendum id="0">Confirm ( Con ) Exhibit ( Exh ) Guide ( Gui ) ReSearch ( ReS ) Reserve</definiendum>
				<definiendum id="1">ExD ) Genre ( Gen ) IntentDetail ( InD ) Parking ( Par ) ParkingInfo ( PaI ) RequestDetail ( ReD ) ReserveInfo ( ReI ) SearchResult ( SeR ) SelectDetail ( SeD ) Shop</definiendum>
				<definiens id="0">A part of the LIT structural rules being represented by context free grammars</definiens>
			</definition>
			<definition id="1">
				<sentence>LIT consists of four layers : “Discourse act” , “Action” , “Object” , and “Argument” .</sentence>
				<definiendum id="0">LIT</definiendum>
			</definition>
</paper>

		<paper id="3013">
			<definition id="0">
				<sentence>Chinese Pinyin is a popular approach to Chinese character input .</sentence>
				<definiendum id="0">Chinese Pinyin</definiendum>
				<definiens id="0">a popular approach to Chinese character input</definiens>
			</definition>
			<definition id="1">
				<sentence>NER is a key technology for NLP applications such as IE and question &amp; answering .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">a key technology for NLP applications such as IE and question &amp; answering</definiens>
			</definition>
			<definition id="2">
				<sentence>The knowledge mining tool is a text processing program that extracts NIL expressions and their attributes and contextual information , i.e. n-grams , from the NIL corpus .</sentence>
				<definiendum id="0">knowledge mining tool</definiendum>
				<definiens id="0">a text processing program that extracts NIL expressions and their attributes and contextual information</definiens>
			</definition>
			<definition id="3">
				<sentence>The NIL corpus is a collection of network informal sentences which provides training data for NIL dictionary and statistical NIL features .</sentence>
				<definiendum id="0">NIL corpus</definiendum>
			</definition>
			<definition id="4">
				<sentence>where NILEX is the SGML tag to label a NIL expression , which entails NIL linguistic attributes including class , normal , pinyin , segments , pos , and posseg ( see Section 4.2 ) .</sentence>
				<definiendum id="0">NILEX</definiendum>
				<definiens id="0">the SGML tag to label a NIL expression , which entails NIL linguistic attributes including class , normal , pinyin , segments , pos</definiens>
			</definition>
			<definition id="5">
				<sentence>The NIL dictionary is a structured databank that contains NIL expression entries .</sentence>
				<definiendum id="0">NIL dictionary</definiendum>
				<definiens id="0">a structured databank that contains NIL expression entries</definiens>
			</definition>
			<definition id="6">
				<sentence>, ( zxK is a kernel function that implicNIL Dictionary NIL Features Chat Text NIL Expression List NIL Expression Recognizer Word Segmentation Word POS Tagging ( ICTCLAS ) Figure 2 : Architecture of NILER system .</sentence>
				<definiendum id="0">zxK</definiendum>
			</definition>
			<definition id="7">
				<sentence>In fact , “2G , Q ” is an unseen NIL expression .</sentence>
				<definiendum id="0">Q ”</definiendum>
			</definition>
</paper>

		<paper id="6007">
			<definition id="0">
				<sentence>We examine the Attribution relation , which is of particular interest for the following reasons : a2 It appears quite frequently in the RST Treebank ( 15 % of all relations , according to Marcu et al. ( 1999 ) ) a2 It always appears within , rather than across , sentence boundaries a2 It conflicts with Penn Treebank syntax , always relating text spans that do not correspond to nodes in the syntax tree We describe a system that identifies Attributions by simple , clearly defined syntactic features .</sentence>
				<definiendum id="0">Attribution relation</definiendum>
				<definiens id="0">than across , sentence boundaries a2 It conflicts with Penn Treebank syntax , always relating text spans that do not correspond to nodes in the syntax tree We describe a system that identifies Attributions by simple , clearly defined syntactic features</definiens>
			</definition>
			<definition id="1">
				<sentence>The satellite is the source of the attribution ( a clause containing a reporting verb , or a phrase beginning with according to ) , and the nucleus is the content of the reported message ( which must be in a separate clause ) .</sentence>
				<definiendum id="0">satellite</definiendum>
				<definiendum id="1">nucleus</definiendum>
				<definiens id="0">the source of the attribution ( a clause containing a reporting verb , or a phrase beginning with according to )</definiens>
				<definiens id="1">the content of the reported message ( which must be in a separate clause )</definiens>
			</definition>
			<definition id="2">
				<sentence>( 7 ) ( ( S ( ADVP-TMP ( RB Now ) ) ( , , ) ( PP ( VBG according ) ( PP ( TO to ) ( NP ( NP ( DT a ) ( NNP Kidder ) ( NNP World ) ( NN story ) ) ( PP ( IN about ) ( NP ( NNP Mr. ) ( NNP Megargel ) ) ) ) ) ) ( , , ) ( NP-SBJ ( NP ( DT all ) ) ( SBAR ( WHNP-1 ( -NONE0 ) ) ( S ( NP-SBJ-2 ( DT the ) ( NN firm ) ) ( VP ( VBZ has ) ( S ( NP-SBJ ( -NONE*-2 ) ) ( VP ( TO to ) ( VP ( VB do ) ( NP ( -NONE*T*-1 ) ) ) ) ) ) ) ) ) ( VP ( VBZ is ) ( ‘‘ ‘‘ ) ( VP ( VB position ) ( NP ( PRP ourselves ) ) ( ADVP-MNR ( RBR more ) ( PP ( IN in ) ( NP ( DT the ) ( NN deal ) ( NN flow ) ) ) ) ) ) ( .</sentence>
				<definiendum id="0">NNP Kidder )</definiendum>
				<definiendum id="1">VP</definiendum>
				<definiens id="0">NN deal ) ( NN flow</definiens>
			</definition>
</paper>

		<paper id="7002">
</paper>

		<paper id="4007">
			<definition id="0">
				<sentence>A knowledgebase which systemizes lexical and conceptual information of human knowledge is a basic infrastructure for Natural Language Processing ( NLP ) applications .</sentence>
				<definiendum id="0">knowledgebase</definiendum>
			</definition>
			<definition id="1">
				<sentence>Equivalents Databases ( ECTED ) The basic idea of ECTED is to provide the Chinese translation equivalents for each APPROACHI Given fully annotated monolingual wordents with synsets and LSRs Fully annotated parallel wordnet APPROACHII Given fully annotated WN of language A ; and bilingual translation equivalents annotated with LSR Map LSR-annotated synsets in Language A to Language B through translation LSRs ( T-LSR’s ) Grow LSR links among Language B synsets by using language A LSR and cross-lingual LSR inference rules Map and pair Language A and Language B synsets with cross-lingual LSRs 49 WN English synset .</sentence>
				<definiendum id="0">Equivalents Databases</definiendum>
			</definition>
			<definition id="2">
				<sentence>In other words , WN resembles an ontology system and links all the semantic relations of words .</sentence>
				<definiendum id="0">WN</definiendum>
				<definiens id="0">resembles an ontology system and links all the semantic relations of words</definiens>
			</definition>
			<definition id="3">
				<sentence>Translation-mediated LSR ( the complete model ) In Diagram1 , EW1 and EW2 are head words for two different English synsets .</sentence>
				<definiendum id="0">Translation-mediated LSR</definiendum>
				<definiens id="0">the complete model ) In Diagram1 , EW1 and EW2 are head words for two different English synsets</definiens>
			</definition>
			<definition id="4">
				<sentence>Translation-mediated LSR ( the reduced model ) Synonym , hypernym , hyponym , holonym , meronym and near-synonym are the main semantic relations that we will discuss in the following sections .</sentence>
				<definiendum id="0">Translation-mediated LSR</definiendum>
				<definiens id="0">the reduced model ) Synonym , hypernym , hyponym , holonym , meronym and near-synonym are the main semantic relations that we will discuss in the following sections</definiens>
			</definition>
			<definition id="5">
				<sentence>For instance , if A is a hypernym of B , B is a hyponym of A. For instance , as shown in diagram 5 , the English word ‘nick’ is the hypernym of the Chinese term ‘shang1kou3’ and ‘cut’ is the hypernym of ‘nick’ in WN and the exact translation equivalent of ‘cut’ in Chinese is ‘jian3kai1.’</sentence>
				<definiendum id="0">B</definiendum>
				<definiendum id="1">‘cut’</definiendum>
				<definiens id="0">a hyponym of A. For instance</definiens>
			</definition>
			<definition id="6">
				<sentence>( c ) IF x= NSYN LSR y = HPO+NSYN =HPO ( CW2 is the hyponym of CW1 . )</sentence>
				<definiendum id="0">CW2</definiendum>
				<definiens id="0">the hyponym of CW1</definiens>
			</definition>
			<definition id="7">
				<sentence>( Undecided ) gao1dian3 pastry ( 05670938N ) baklava ( 05674827N ) =guo3ren2mi4tang2qian1ceng2bing3 y i= HPO x= HPO The unknown LSR y = i + x =HPO +HPO =HPO ( ‘guo3ren2mi4tang2qian1ceng2bing3’ is the hyponym of ‘gao1dian3’ ) shang1kou3 nick ( 00248910N ) cut ( 00248688N ) =jian3kai1 y i= HYP ( ‘nick’ is the hypernym of ‘shang1kou3’ ) x= HYP ( ‘cut’ is the hypernym of ‘nick’ ) The unknown LSR y = i + x =HYP +HYP =HYP ( ‘jian3kai1’ is the hypernym of ‘shang1kou3’ ) 53 Near-Synonym ( NSYN ) ( a ) IF x=ANT LSR y = NSYN+ANT =ANT ( CW2 is the antonym of CW1 . )</sentence>
				<definiendum id="0">‘jian3kai1’</definiendum>
				<definiens id="0">the antonym of CW1</definiens>
			</definition>
			<definition id="8">
				<sentence>( f ) IF x = HOL LSR y = NSYN+HOL =HOL ( CW2 is the holonym of CW1 . )</sentence>
				<definiendum id="0">NSYN+HOL =HOL</definiendum>
				<definiendum id="1">CW2</definiendum>
				<definiens id="0">the holonym of CW1</definiens>
			</definition>
			<definition id="9">
				<sentence>Holonym ( HOL ) ( a ) IF x=ANT LSR y = HOL+ANT =ANT ( CW2 is the antonym of CW1 . )</sentence>
				<definiendum id="0">Holonym</definiendum>
				<definiens id="0">the antonym of CW1</definiens>
			</definition>
			<definition id="10">
				<sentence>( c ) IF x= NSYN LSR y = HOL+NSYN =HOL ( CW2 is the holonym of CW1 . )</sentence>
				<definiendum id="0">CW2</definiendum>
				<definiens id="0">the holonym of CW1</definiens>
			</definition>
			<definition id="11">
				<sentence>( b ) IF x=HPO LSR y = MER+HPO =HPO ( CW2 is the hyponym of CW1 . )</sentence>
				<definiendum id="0">CW2</definiendum>
				<definiens id="0">the hyponym of CW1</definiens>
			</definition>
			<definition id="12">
				<sentence>One is that there is a possible prediction and another one is the correct LSR is different from the predicted one .</sentence>
				<definiendum id="0">LSR</definiendum>
				<definiens id="0">different from the predicted one</definiens>
			</definition>
</paper>

		<paper id="5006">
</paper>

		<paper id="2032">
			<definition id="0">
				<sentence>my The Malaysian Language is a formation of subject , predicate and object .</sentence>
				<definiendum id="0">Malaysian Language</definiendum>
			</definition>
			<definition id="1">
				<sentence>The postSubject describes the subject .</sentence>
				<definiendum id="0">postSubject</definiendum>
				<definiens id="0">describes the subject</definiens>
			</definition>
			<definition id="2">
				<sentence>-- ( 4 ) The terminal for the Verb Phrase is a verb .</sentence>
				<definiendum id="0">Verb Phrase</definiendum>
				<definiens id="0">a verb</definiens>
			</definition>
			<definition id="3">
				<sentence>It is a mathematical model of a system represented as : ( Q , ∑ , S , R ) , where Q is a finite set of states ∑ is a finite set of input S is the initial state R is the transition relational which maps the input and states The states are the adjunct , subject , postSubject ( postSub ) , conjunction ( conj ) , and predicate .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">a mathematical model of a system represented as : ( Q , ∑ , S , R ) , where Q is a finite set of states ∑ is a finite set of input S is the initial state</definiens>
				<definiens id="1">the transition relational which maps the input and states The states are the adjunct , subject , postSubject ( postSub ) , conjunction ( conj ) , and predicate</definiens>
			</definition>
			<definition id="4">
				<sentence>But , the Chomskyian revolution makes the linguist to produce a Context Free format for the language .</sentence>
				<definiendum id="0">Chomskyian revolution</definiendum>
				<definiens id="0">makes the linguist to produce a Context Free format for the language</definiens>
			</definition>
			<definition id="5">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="5001">
			<definition id="0">
				<sentence>Paraphrase detection—the ability to determine whether or not two formally distinct strings are similar in meaning—is increasingly recognized as crucial to future applications in multiple fields including Information Retrieval , Question Answering , and Summarization .</sentence>
				<definiendum id="0">Paraphrase</definiendum>
			</definition>
			<definition id="1">
				<sentence>The L12 dataset represents the best case achieved so far , with Alignment Error Rates beginning to approach those reported for alignment of closely parallel bilingual corpora .</sentence>
				<definiendum id="0">L12 dataset</definiendum>
				<definiens id="0">represents the best case achieved so far , with Alignment Error Rates beginning to approach those reported for alignment of closely parallel bilingual corpora</definiens>
			</definition>
			<definition id="2">
				<sentence>L12 represents the best case , followed respectively by F3 and F2 .</sentence>
				<definiendum id="0">L12</definiendum>
				<definiens id="0">the best case , followed respectively by F3 and F2</definiens>
			</definition>
</paper>

		<paper id="7012">
</paper>

		<paper id="6004">
			<definition id="0">
				<sentence>A typical lexical item consists of an identifier , and then a triple consisting of the orthography , lexical-type and predicate : e.g. , inu n 1 = 〈 “ : ” , common-noun-lex , dog n animal〉 .</sentence>
				<definiendum id="0">typical lexical item</definiendum>
			</definition>
			<definition id="1">
				<sentence>The leaves of the parse data consist of words , and their lexicon IDs , stored with the ID of the sentence in which the word appears .</sentence>
				<definiendum id="0">The leaves of the parse data</definiendum>
				<definiens id="0">consist of words , and their lexicon IDs , stored with the ID of the sentence in which the word appears</definiens>
			</definition>
			<definition id="2">
				<sentence>V , ga-wo-ni-p-lex ( � , � , ) Linguistic Discussion ga-wo-ni-p-lex particles attach to a noun and indicate what grammatical relation ( e.g. , subject or object ) the noun takes on in relation to a predicate .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">ga-wo-ni-p-lex ( � , � , ) Linguistic Discussion ga-wo-ni-p-lex particles attach to a noun and indicate what grammatical relation ( e.g. , subject or object</definiens>
			</definition>
			<definition id="3">
				<sentence>The lexical-type documentation gives bottom up documentation .</sentence>
				<definiendum id="0">lexical-type documentation</definiendum>
			</definition>
			<definition id="4">
				<sentence>In parallel to this , collaborators who are 37 Development ( refinement ) GRAMMAR Treebanking ( manual annotation ) TREEBANK automatic parsingfeedback LEXICAL TYPE DATABASE WWW Linguistic Resource In this section , we discuss some of the ways the database can benefit people other than treebank annotators and grammar developers .</sentence>
				<definiendum id="0">GRAMMAR Treebanking</definiendum>
				<definiens id="0">manual annotation ) TREEBANK automatic parsingfeedback LEXICAL TYPE DATABASE WWW Linguistic</definiens>
			</definition>
</paper>

		<paper id="3025">
			<definition id="0">
				<sentence>Each Chinese character can be assigned one of four possible boundary tags : s for a character that occurs as a single-character word , b for a character that begins a multi-character ( i.e. , two or more characters ) word , e for a character that ends a multi-character word , and m for a character that is neither the first nor last in a multi-character word .</sentence>
				<definiendum id="0">Chinese character</definiendum>
				<definiens id="0">s for a character that occurs as a single-character word , b for a character that begins a multi-character ( i.e. , two or more characters ) word , e for a character that ends a multi-character word</definiens>
			</definition>
			<definition id="1">
				<sentence>Templates ( a ) – ( c ) refer to a context of five characters ( the current character and two characters to its left and right ) .</sentence>
				<definiendum id="0">Templates</definiendum>
				<definiens id="0">the current character and two characters to its left and right</definiens>
			</definition>
			<definition id="2">
				<sentence>C0 denotes the current character , Cn ( C−n ) denotes the character n positions to the right ( left ) of the current character .</sentence>
				<definiendum id="0">C0</definiendum>
				<definiendum id="1">Cn ( C−n )</definiendum>
				<definiens id="0">the current character</definiens>
				<definiens id="1">the character n positions to the right ( left ) of the current character</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , when considering the character “_d_2543” in the character sequence “_d_1010_d_7235 _d_2543_d_1082R” , the feature T ( C−2 ) ... T ( C2 ) = 11243 1http : //maxent.sourceforge.net/ 161 will be set to 1 ( “_d_1010” is the Chinese character for “9” and “_d_7235” is the Chinese character for “0” ) .</sentence>
				<definiendum id="0">“_d_1010”</definiendum>
				<definiendum id="1">“_d_7235”</definiendum>
				<definiens id="0">the Chinese character for “9” and</definiens>
			</definition>
			<definition id="4">
				<sentence>We note that characters like punctuation symbols and Arabic digits have different character codes in the ASCII , GB , and BIG5 encoding standard , although they mean the same thing .</sentence>
				<definiendum id="0">Arabic digits</definiendum>
				<definiens id="0">have different character codes in the ASCII , GB , and BIG5 encoding standard , although they mean the same thing</definiens>
			</definition>
			<definition id="5">
				<sentence>A major difficulty faced by a Chinese word segmenter is the presence of out-of-vocabulary ( OOV ) words .</sentence>
				<definiendum id="0">Chinese word segmenter</definiendum>
			</definition>
			<definition id="6">
				<sentence>The necessary character encoding conversion between GB and BIG5 is performed , and the probability threshold θ is set to θ to a higher value did not further improve segmentation accuracy , but would instead increase the training set size and incur longer training time .</sentence>
				<definiendum id="0">BIG5</definiendum>
				<definiens id="0">The necessary character encoding conversion between GB and</definiens>
			</definition>
</paper>

		<paper id="3006">
			<definition id="0">
				<sentence>Previous study on NER is mainly focused either on the proper name identification of person ( PER ) , location ( LOC ) , organization ( ORG ) , time ( TIM ) and numeral ( NUM ) expressions almost in news domain , which can be viewed as general NER , or other named entity ( NE ) recognition in specific domain such as biology .</sentence>
				<definiendum id="0">PER</definiendum>
				<definiendum id="1">LOC</definiendum>
				<definiendum id="2">ORG</definiendum>
				<definiendum id="3">TIM</definiendum>
			</definition>
			<definition id="1">
				<sentence>Product Type is a kind of product named entities indicating version or series information of product , which can consist of numbers , English characters , or other symbols such as “+” and “” etc.In our study , two principles should be followed .</sentence>
				<definiendum id="0">Product Type</definiendum>
				<definiens id="0">a kind of product named entities indicating version or series information of product , which can consist of numbers , English characters</definiens>
			</definition>
			<definition id="2">
				<sentence>Product named entity recognition involves the identification of product-related proper names in free text and their classification into different kinds of product named entities , referring to PRO , TYP and BRA in this paper .</sentence>
				<definiendum id="0">Product named entity recognition</definiendum>
				<definiens id="0">involves the identification of product-related proper names in free text and their classification into different kinds of product named entities</definiens>
			</definition>
			<definition id="3">
				<sentence>We choose hierarchical hidden Markov model ( HHMM ) [ S. Fine et al. 1998 ] for its more powerful ability to model the multiplicity of length scales and recursive nature of sequences .</sentence>
				<definiendum id="0">HHMM</definiendum>
				<definiens id="0">] for its more powerful ability to model the multiplicity of length scales and recursive nature of sequences</definiens>
			</definition>
			<definition id="4">
				<sentence>Our HHMM structure actually consists of three level approximately illustrated as figure 2 in which IS denotes internal state , PS denotes production state and ES denote end state at every level .</sentence>
				<definiendum id="0">PS</definiendum>
				<definiens id="0">internal state</definiens>
			</definition>
			<definition id="5">
				<sentence>For our application , an input sequence from our SegNer2.0 toolkit can be formalized as w1/t1w2/t2 . . . wi/ti . . . wn/tn , among which wi and ti is the ith word and its part-ofspeech , n is the number of words .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of words</definiens>
			</definition>
			<definition id="6">
				<sentence>P ( Q ) ∼= p ( qk1|qk−1m ) bracehtipupleft bracehtipdownrightbracehtipdownleft bracehtipupright vertical transition horizontal transitionbracehtipdownleft bracehtipuprightbracehtipupleft bracehtipdownright p ( qk2|qk1 ) |qk|productdisplay j=3 p ( qkj|qkj−1 , qkj−2 ) ( 2 ) P ( W|Q ) =       ∼= |q k PS|producttext j=1 p ( [ wqk j −begin ... wqk j −end ] |qkj ) if qkj /∈ { IS } activate other states recursively if qkj ∈ { IS } ( 3 ) Where |qk| is the number of all states and |qkPS| is the number of production states in the kth level ; wqk j −begin ... wqk j −end indicates the word sequence corresponding to the state qkj .</sentence>
				<definiendum id="0">|qk|</definiendum>
				<definiens id="0">P ( Q ) ∼= p ( qk1|qk−1m ) bracehtipupleft bracehtipdownrightbracehtipdownleft bracehtipupright vertical transition horizontal transitionbracehtipdownleft bracehtipuprightbracehtipupleft bracehtipdownright p</definiens>
				<definiens id="1">the number of all states and |qkPS| is the number of production states in the kth level</definiens>
			</definition>
			<definition id="7">
				<sentence>( Q∗ , Q∗II ) = argmax Q , QII { log ( P ( Q ) ) + log ( P ( W|Q ) ) + β [ log ( P ( QII ) ) + log ( P ( T|QII ) ) ] } ( 6 ) Where β is a tuning parameter for adjusting the weight of two models .</sentence>
				<definiendum id="0">β</definiendum>
				<definiens id="0">a tuning parameter for adjusting the weight of two models</definiens>
			</definition>
</paper>

		<paper id="3029">
			<definition id="0">
				<sentence>It is thus evident that the comparison and replacement by means of BMM and FMM offers a substantial achievement in the accuracy of the segmentation process .</sentence>
				<definiendum id="0">FMM</definiendum>
				<definiens id="0">offers a substantial achievement in the accuracy of the segmentation process</definiens>
			</definition>
</paper>

		<paper id="2036">
			<definition id="0">
				<sentence>VerbNet ( Kipper et al. , 2000 ) is a computational verb lexicon , based on Levin’s verb classes , that contains syntactic and semantic information for English verbs .</sentence>
				<definiendum id="0">VerbNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>Each VerbNet class defines a list of members , a list of possible thematic roles , and a list of frames ( patterns ) of how these semantic roles can be realized in a sentence .</sentence>
				<definiendum id="0">VerbNet class</definiendum>
				<definiens id="0">defines a list of members , a list of possible thematic roles , and a list of frames ( patterns ) of how these semantic roles can be realized in a sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>WordNet ( Fellbaum , 1998 ) is an English lexical database containing about 120 000 entries of nouns , verbs , adjectives and adverbs , hierarchically organized in synonym groups ( called synsets ) , and linked with relations such as hypernym , hyponym , holonym and others .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">an English lexical database containing about 120 000 entries of nouns , verbs , adjectives and adverbs , hierarchically organized in synonym groups ( called synsets ) , and linked with relations such as hypernym , hyponym , holonym and others</definiens>
			</definition>
			<definition id="3">
				<sentence>For such cases the use of a dependency parser ( such as a Link Grammar parser or a Functional Dependency Grammar parser ) would be required .</sentence>
				<definiendum id="0">dependency parser</definiendum>
				<definiens id="0">a Link Grammar parser or a Functional Dependency Grammar parser</definiens>
			</definition>
			<definition id="4">
				<sentence>The total score for a solution is the sum of the scores for each identified roles .</sentence>
				<definiendum id="0">total score</definiendum>
				<definiens id="0">the sum of the scores for each identified roles</definiens>
			</definition>
			<definition id="5">
				<sentence>The SQ represents the rest of the sentence .</sentence>
				<definiendum id="0">SQ</definiendum>
				<definiens id="0">the rest of the sentence</definiens>
			</definition>
</paper>

		<paper id="2007">
			<definition id="0">
				<sentence>Korean is an agglutinative language .</sentence>
				<definiendum id="0">Korean</definiendum>
				<definiens id="0">an agglutinative language</definiens>
			</definition>
			<definition id="1">
				<sentence>Korean is one of the most studied agglutinative languages in the world .</sentence>
				<definiendum id="0">Korean</definiendum>
				<definiens id="0">one of the most studied agglutinative languages in the world</definiens>
			</definition>
</paper>

		<paper id="6006">
			<definition id="0">
				<sentence>50 According to Figure 2 , we know that [ 12 ] is a parsing unit ( PU ) realised by a clause ( CL ) , which governs three daughter nodes : SU NP ( NP as subject ) , VB VP ( VP as verbal ) , and OD NP ( NP as direct object ) .</sentence>
				<definiendum id="0">VB VP</definiendum>
				<definiens id="0">a parsing unit ( PU ) realised by a clause ( CL ) , which governs three daughter nodes : SU NP ( NP as subject )</definiens>
				<definiens id="1">direct object )</definiens>
			</definition>
			<definition id="1">
				<sentence>The grammar consists of two sets of rules .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiens id="0">consists of two sets of rules</definiens>
			</definition>
			<definition id="2">
				<sentence>As is shown , the parsed corpus resulted in excellent grammar sets for the canonical phrases , AJP , AVP , NP , PP , and VP : except for PPs , all the phrase structure rules achieved a wide coverage of about 99 % .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">the canonical phrases , AJP , AVP , NP , PP , and</definiens>
			</definition>
			<definition id="3">
				<sentence>AUTASYS is an automatic wordclass tagging system that applies the ICE tags to words in the input text with an accuracy rate of about 94 % ( Fang 1996a ) .</sentence>
				<definiendum id="0">AUTASYS</definiendum>
			</definition>
			<definition id="4">
				<sentence>The parsing model is one that tries to identify an analogy between the input string and a sentence is that already syntactically analysed and stored in a database ( Fang 1996b and 2000 ) .</sentence>
				<definiendum id="0">parsing model</definiendum>
			</definition>
			<definition id="5">
				<sentence>An especially advantageous feature of the metric is the calculation of an overall parser performance rate that takes into account the total number of insertions in the parse tree , an important structural distortion factor when calculating the similarity between two trees .</sentence>
				<definiendum id="0">metric</definiendum>
			</definition>
</paper>

		<paper id="4003">
			<definition id="0">
				<sentence>In the Sinica Treebank ( CKIP ) , thematic roles are also labeled in the CKIP to provide deeper information .</sentence>
				<definiendum id="0">Sinica Treebank</definiendum>
				<definiens id="0">thematic roles are also labeled in the CKIP to provide deeper information</definiens>
			</definition>
			<definition id="1">
				<sentence>The phrase “DENP” is a special nominal phrase which has no word after the auxiliary 18 word “ , X ( DE ) ” , and it is usually put at the end of the utterance .</sentence>
				<definiendum id="0">phrase “DENP”</definiendum>
				<definiens id="0">a special nominal phrase which has no word after the auxiliary 18 word “ , X ( DE ) ” , and it is usually put at the end of the utterance</definiens>
			</definition>
</paper>

		<paper id="2005">
			<definition id="0">
				<sentence>Our content consistency maintenance method consists of a technique that prevents the tampering of contents and a method that maintains consistency between the following : sharing system and exchange of contents .</sentence>
				<definiendum id="0">content consistency maintenance method</definiendum>
				<definiens id="0">consists of a technique that prevents the tampering of contents and a method that maintains consistency between the following : sharing system and exchange of contents</definiens>
			</definition>
			<definition id="1">
				<sentence>Napster , which is a centralized P2P content sharing system similar to our system , uses a download protocol by which the clients send a download request to the central server before they download the content from another client .</sentence>
				<definiendum id="0">Napster</definiendum>
				<definiens id="0">a centralized P2P content sharing system similar to our system , uses a download protocol by which the clients send a download request to the central server before they download the content from another client</definiens>
			</definition>
			<definition id="2">
				<sentence>We describe this procedure by the following pseudo codes , where download is a function that requests the download of a document , nodeId is the ID of a client that requests the download , update is a function that requests the update of a document , and getNodeId is a function that gets the ID of a client that downloads a document whose ID is docId .</sentence>
				<definiendum id="0">download</definiendum>
				<definiendum id="1">nodeId</definiendum>
				<definiendum id="2">getNodeId</definiendum>
				<definiens id="0">the ID of a client that requests the download , update is a function that requests the update of a document , and</definiens>
				<definiens id="1">a function that gets the ID of a client that downloads a document whose ID is docId</definiens>
			</definition>
</paper>

		<paper id="7006">
</paper>

		<paper id="2034">
			<definition id="0">
				<sentence>The jobs to do in morphological analysis are as follows : AF Separating an Eojeol into morphemes AF Assigning the morpho-syntactic category to each morpheme 1 Eojeol is the surface level form of Korean and is the spacing unit delimited by a whitespace .</sentence>
				<definiendum id="0">AF Separating</definiendum>
				<definiendum id="1">Eojeol</definiendum>
				<definiens id="0">the surface level form of Korean and is the spacing unit delimited by a whitespace</definiens>
			</definition>
			<definition id="1">
				<sentence>The morpheme-unit morphological analysis model is derived as follows by introducing lexical form D0 : C8B4CACYDBB5 BP C8B4D0CYDBB5C8B4CACYD0BNDBB5 ( 2 ) where D0 should satisfy the following condition : D0 BE C4 DB CKC8B4D0CYCAB5BPBD where C4 DB is a set of lexical forms that can be derived from the surface form DB .</sentence>
				<definiendum id="0">C4 DB</definiendum>
			</definition>
			<definition id="2">
				<sentence>This information can be acquired by the following steps : If a surface form ( Eojeol ) and its lexical form are the same , each syllable pair of them is mapped one-to-one and extracted .</sentence>
				<definiendum id="0">Eojeol</definiendum>
				<definiens id="0">the same , each syllable pair of them is mapped one-to-one and extracted</definiens>
			</definition>
			<definition id="3">
				<sentence>The syllable-unit model is derived from Equation 4 as follows : C8B4D0CYDBB5C8B4CAB5BPC8B4D0CYDBB5C8B4BVBNCDB5 ( 8 ) where BV BP CR BDBND1 is the syllable sequence of the lexical form , and CD BP D9 BDBND1 is its corresponding syllable tag sequence .</sentence>
				<definiendum id="0">BV BP CR BDBND1</definiendum>
				<definiens id="0">the syllable sequence of the lexical form</definiens>
			</definition>
			<definition id="4">
				<sentence>The POS assignment model is to assign the D1 syllables to the D1 syllable tags : C8B4BVBNCDB5 BP C8B4CR BDBND1 BND9 BDBND1 B5 ( 9 ) AP D1 CH CXBPBD AW C8B4CR CX CYCR CXA0BEBNCXA0BD BND9 CXA0BEBNCXA0BD B5 C8B4D9 CX CYCR CXA0BDBNCX BND9 CXA0BEBNCXA0BD B5 AX A2C8B4CR BXC7CF CYCR D1A0BDBND1 BND9 D1A0BDBND1 B5 A2C8B4D9 BXC7CF CYCR D1 BNCR BXC7CF BND9 D1A0BDBND1 B5 ( 10 ) In Equation 10 , when CX is less than or equal to zero , CR CX s and D9 CX s denote the pseudo syllables and the pseudo tags , respectively .</sentence>
				<definiendum id="0">POS assignment model</definiendum>
				<definiendum id="1">CYCR D1 BNCR BXC7CF BND9 D1A0BDBND1 B5</definiendum>
				<definiendum id="2">CX</definiendum>
				<definiens id="0">to assign the D1 syllables to the D1 syllable tags : C8B4BVBNCDB5 BP C8B4CR BDBND1 BND9 BDBND1 B5 ( 9 ) AP D1 CH CXBPBD AW C8B4CR CX CYCR CXA0BEBNCXA0BD BND9 CXA0BEBNCXA0BD B5 C8B4D9 CX CYCR CXA0BDBNCX BND9 CXA0BEBNCXA0BD B5 AX A2C8B4CR BXC7CF CYCR D1A0BDBND1 BND9 D1A0BDBND1 B5 A2C8B4D9 BXC7CF</definiens>
			</definition>
			<definition id="5">
				<sentence>Analogously , CR BXC7CF and D9 BXC7CF denote the pseudo syllables and the pseudo tags to indicate the end of Eojeol , respectively .</sentence>
				<definiendum id="0">CR BXC7CF</definiendum>
				<definiens id="0">the end of Eojeol , respectively</definiens>
			</definition>
			<definition id="6">
				<sentence>In order to convert the syllable sequence BV and the syllable tag sequence CD to the morpheme sequence C5 and the morpheme tag sequence CC , we can use two additional symbols ( “B” and “I” ) to indicate the boundary of morphemes : a “B” denotes the first syllable of a morpheme and an “I” any non-initial syllable .</sentence>
				<definiendum id="0">“B”</definiendum>
			</definition>
			<definition id="7">
				<sentence>Table 4 : Summary of the data Corpus ETRI KAIST Sejong # of Eojeols 288,291 175,468 2,015,860 # of tags 27 54 41 In this paper , we use the following measures in order to evaluate the system : 200 Table 3 : Examples of syllable tagging with BI symbols Eojeol na-neun ‘I’ hag-gyo-e ‘to school’ gan-da ‘go’ Tagged Eojeol na/np+neun/jx hag-gyo/nc+e/jc ga/pv+n-da/ef Morpheme na neun hag-gyo e ga n-da Morpheme tag np jx nc jc pv ef Syllable na neun hag gyo e ga n da Syllable tag B-np B-jx B-nc I-nc B-jc B-pv B-ef I-ef Answer inclusion rate ( AIR ) is defined as the number of Eojeols among whose results contain the gold standard over the entire Eojeols in the test data .</sentence>
				<definiendum id="0">AIR</definiendum>
				<definiens id="0">Summary of the data Corpus ETRI KAIST Sejong # of Eojeols 288,291 175,468 2,015,860 # of</definiens>
				<definiens id="1">Examples of syllable tagging with BI symbols Eojeol na-neun ‘I’ hag-gyo-e ‘to school’ gan-da ‘go’ Tagged Eojeol na/np+neun/jx hag-gyo/nc+e/jc ga/pv+n-da/ef Morpheme na neun hag-gyo e ga n-da Morpheme tag np jx nc jc pv ef Syllable na neun hag gyo e ga n da Syllable tag B-np B-jx B-nc I-nc B-jc B-pv B-ef I-ef Answer inclusion rate</definiens>
			</definition>
			<definition id="8">
				<sentence>Average ambiguity ( AA ) is defined as the average number of returned results per Eojeol by the system .</sentence>
				<definiendum id="0">Average ambiguity ( AA</definiendum>
				<definiens id="0">the average number of returned results per Eojeol by the system</definiens>
			</definition>
			<definition id="9">
				<sentence>Failure rate ( FR ) is defined as the number of Eojeols whose outputs are not produced over the number of Eojeols in the test data .</sentence>
				<definiendum id="0">Failure rate</definiendum>
				<definiendum id="1">FR</definiendum>
			</definition>
			<definition id="10">
				<sentence>1-best tagging accuracy ( 1A ) is defined as the number of Eojeols of which only one interpretation with highest probability per Eojeol is matched to the gold standard over the entire Eojeols in the test data .</sentence>
				<definiendum id="0">1A )</definiendum>
			</definition>
</paper>

		<paper id="6009">
			<definition id="0">
				<sentence>The primary purpose of learner corpora is to offer Second Language Acquisition ( SLA ) researchers and language teaching professionals resources for their research .</sentence>
				<definiendum id="0">learner corpora</definiendum>
			</definition>
			<definition id="1">
				<sentence>Some of the existing learner corpora are annotated for errors , and our learner corpus called the “NICT JLE ( Japanese Learner English ) Corpus” is one of them .</sentence>
				<definiendum id="0">“NICT JLE</definiendum>
				<definiens id="0">one of them</definiens>
			</definition>
			<definition id="2">
				<sentence>The learner language including errors can be defined as “interlanguage” , which lies between L1 and L2 ( Selinker , 1972 ) .</sentence>
				<definiendum id="0">learner language including errors</definiendum>
			</definition>
			<definition id="3">
				<sentence>Degneaux , et al. ( 1998 ) call EA based on learner corpora “computer-aided error analysis ( CEA ) ” , and expect that the rapid progress of computing technology and learner corpora will be able to solve the problems and overcome the limitations of traditional EA .</sentence>
				<definiendum id="0">learner corpora</definiendum>
				<definiens id="0">error analysis ( CEA ) ” , and expect that the rapid progress of computing technology and</definiens>
			</definition>
			<definition id="4">
				<sentence>The Cambridge Learners’ Corpus ( CLC ) , which has been compiled by Cambridge University Press and Cambridge ESOL ( English for Speakers of Other Languages ) , is also an error-coded learner corpus .</sentence>
				<definiendum id="0">Cambridge Learners’ Corpus ( CLC )</definiendum>
				<definiens id="0">Other Languages ) , is also an error-coded learner corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>Structure of an Error Tag and an Example of an Error-tagged Sentence The tags are based on XML ( extensible markup language ) syntax .</sentence>
				<definiendum id="0">Structure of an Error Tag</definiendum>
				<definiens id="0">extensible markup language ) syntax</definiens>
			</definition>
</paper>

		<paper id="4010">
			<definition id="0">
				<sentence>The bilingual texts of the laws of Hong Kong have been made available to the public in recent years by the Justice Department of the HKSAR through the bilingual laws information system ( BLIS ) .</sentence>
				<definiendum id="0">BLIS</definiendum>
				<definiens id="0">the public in recent years by the Justice Department of the HKSAR through the bilingual laws information system</definiens>
			</definition>
			<definition id="1">
				<sentence>BLIS provides the most comprehensive documentation of HK legislation .</sentence>
				<definiendum id="0">BLIS</definiendum>
			</definition>
			<definition id="2">
				<sentence>The assigned number for a subsidiary legislation chapter consists of a chapter number and a following uppercase letter , e.g. , CAP 5C HIGH COURT CIVIL PROCEDURE ( USE OF LANGUAGE ) RULES /�5Cc��E� � Y� � ( 3G� '' =� ) 2 '' c. The content of an ordinance , exclusive of its long title , is divided and identified according to a very rigid numbering system which encodes the hierarchy of the texts of the laws .</sentence>
				<definiendum id="0">assigned number for a subsidiary legislation chapter</definiendum>
				<definiens id="0">consists of a chapter number and a following uppercase letter , e.g. , CAP 5C HIGH COURT CIVIL PROCEDURE ( USE OF LANGUAGE ) RULES /�5Cc��E� � Y� � ( 3G� '' =� ) 2 '' c. The content of an ordinance , exclusive of its long title , is divided and identified according to a very rigid numbering system which encodes the hierarchy of the texts of the laws</definiens>
			</definition>
</paper>

		<paper id="3016">
			<definition id="0">
				<sentence>The CTB consists of Xinhua news articles that have been segmented , partof-speech tagged , and bracketed with syntactic labels and functional tags ( Xue et al. , 2004 ) 1 .</sentence>
				<definiendum id="0">CTB</definiendum>
				<definiens id="0">consists of Xinhua news articles that have been segmented , partof-speech tagged , and bracketed with syntactic labels and functional tags ( Xue et al. , 2004 ) 1</definiens>
			</definition>
			<definition id="1">
				<sentence>The decision was made to put the index for a complex NP referent on the entire complex NP rather than on just the head of the phrase 1http : //www.cis.upenn.edu/˜ chinese 2Linguists beware : this is far more general than the arbitrary in “arbitrary PRO” ( IP ( ADVP ( AD ) ) ( PU ) ( IP ( IP ( NP # 2-SBJ ( NP ( NP ( DP ( DT ) ) ( NP ( NN ) ) ) ( NP ( NN ) ( NN ) ) ) ( NP ( NN ) ( NN ) ) ) ( VP ( VE ) ( AS ) ( NP-OBJ ( CP ( WHNP-1 ( -NONE*OP* ) ) ( IP ( NP-SBJ ( -NONE*T*-1 ) ) ( VP ( ADVP ( AD ) ) ( VP ( VA ) ) ) ) ) ( NP ( NN ) ) ) ) ) ( PU ) ( IP ( NP # 2-SBJ ( -NONE*pro* ) ) ( VP ( NP-LOC ( QP ( CLP ( M ) ) ) ( NP ( NN ) ) ) ( VP ( VRD ( VV ) ( VV ) ) ( IP-OBJ ( NP-SBJ ( -NONE*PRO* ) ) ( VP ( VV ) ( LCP-OBJ ( QP ( DNP ( NP ( NP ( NP ( QP ( CD ) ) ( NP ( NN ) ) ) ( NP ( NN ) ) ) ( NP ( NN ) ) ) ( DEG ) ) ( QP ( CD ) ) ) ( LC ) ) ) ) ) ) ) ) ( PU ) ) At the same time , there has been a comparatively large increase in the entire country’s monthly rent for public housing in cities and townships a0 , with thata0 in a portion of the regions increasing to account for about 10 % of the income of dual income families .</sentence>
				<definiendum id="0">IP</definiendum>
				<definiendum id="1">AS ) ( NP-OBJ ( CP ( WHNP-1</definiendum>
				<definiendum id="2">QP ( DNP ( NP ( NP</definiendum>
				<definiens id="0">CD ) ) ( NP ( NN ) ) ) ( NP ( NN ) ) ) ( NP ( NN ) ) ) ( DEG ) ) ( QP ( CD ) ) ) ( LC ) ) ) ) ) ) ) ) ( PU ) ) At the same time</definiens>
			</definition>
			<definition id="2">
				<sentence>Naive Hobbs Algorithm This algorithm traverses the surface parse tree , searching for a noun phrase of the correct gender and number using the following traversal order : 1 ) begin at NP node immediately dominating the pronoun 2 ) go up the tree to the first NP or S node encountered call this node X call the path to reach X `` p '' 3 ) traverse all branches below node X to the left of path p , in left-to-right , breadth-first manner propose as the antecedent any NP node that is encountered that has an NP or an S node between it and X 4 ) if node X is the highest S node in the sentence traverse the parse trees of previous sentences in order of recency ( the most recent first ) , from left-to-right , breadth-first and propose as antecedent the first NP encountered else goto step ( 5 ) 5 ) from node X go up the tree to the first NP or S node encountered call this new node ’X’ , and call the path traversed to reach it from the original X ’p’ 6 ) if X is an NP node AND if the path p to X did not pass through the N-bar node that X immediately dominates , propose X as the antecedent 7 ) traverse all branches below node X to the *left* of path p , left-to-right , breadth-first 121 propose any NP node encountered as the antecedent 8 ) if X is an S node traverse all branches of node X to the *right* of path p , ’ left-to-right , breadth-first , but do not go below any NP or S encountered propose any NP node encountered as the antecedent 9 ) goto step 4</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">the first NP encountered else goto step ( 5 ) 5 ) from node X go up the tree to the first NP or S node encountered call this new node ’X’ , and call the path traversed to reach it from the original X ’p’ 6 ) if X is an NP node AND if the path p to X did not pass through the N-bar node that X immediately dominates , propose</definiens>
			</definition>
</paper>

		<paper id="3019">
			<definition id="0">
				<sentence>The first element in the run id is the corpus name , as referring to the Academia Sinica corpus , cityu the City University of Hong Kong corpus , pku the Peking University Corpus , and msr the Microsoft Research corpus .</sentence>
				<definiendum id="0">Academia Sinica</definiendum>
			</definition>
			<definition id="1">
				<sentence>The segmentation dictionary consists of the words in the training data with occurrence frequency compiled from the training data .</sentence>
				<definiendum id="0">segmentation dictionary</definiendum>
				<definiens id="0">consists of the words in the training data with occurrence frequency compiled from the training data</definiens>
			</definition>
</paper>

		<paper id="2045">
			<definition id="0">
				<sentence>This paper presents an unsupervised relation extraction algorithm , which induces relations between entity pairs by grouping them into a “natural” number of clusters based on the similarity of their contexts .</sentence>
				<definiendum id="0">unsupervised relation extraction algorithm</definiendum>
			</definition>
			<definition id="1">
				<sentence>Relation extraction is the task of finding relationships between two entities from text contents .</sentence>
				<definiendum id="0">Relation extraction</definiendum>
				<definiens id="0">the task of finding relationships between two entities from text contents</definiens>
			</definition>
			<definition id="2">
				<sentence>Clustering solution that is stable against resampling will give rise to a local optimum of MFk ; k , which indicates both important feature subset and the true cluster number .</sentence>
				<definiendum id="0">k</definiendum>
				<definiens id="0">indicates both important feature subset and the true cluster number</definiens>
			</definition>
			<definition id="3">
				<sentence>We assume pn , 1 • n • N , lies in feature space W , and the dimension of feature space is Table 1 : Model Selection Algorithm for Relation Extraction Input : Corpus D tagged with Entities ( E1 ; E2 ) ; Output : Feature subset and Model Order ( number of relation types ) ; corpus D , namely P ; in section 2.1 ; relation clusters ; sented in section 2.2 ; them , namely MF ; k ; Step 7 ; score of the merit MF ; k ; M. Then the similarity between i-th data point pi and j-th data point pj is given by the equation : Si ; j = exp ( ¡fi ⁄ Di ; j ) , where Di ; j is the Euclidean distance between pi and pj , and fi is a positive constant , its value is ¡ln0:5D , where D is the average distance among the data points .</sentence>
				<definiendum id="0">M. Then</definiendum>
				<definiendum id="1">j</definiendum>
				<definiendum id="2">fi</definiendum>
				<definiendum id="3">D</definiendum>
				<definiens id="0">lies in feature space W , and the dimension of feature space is Table 1 : Model Selection Algorithm for Relation Extraction Input : Corpus D tagged with Entities ( E1 ; E2 ) ; Output : Feature subset and Model Order ( number of relation types ) ; corpus D</definiens>
				<definiens id="1">the similarity between i-th data point pi and j-th data point pj is given by the equation : Si ; j = exp ( ¡fi ⁄ Di ; j ) , where Di</definiens>
			</definition>
			<definition id="4">
				<sentence>Then the entropy of data set P with N data points is defined as : E = ¡ NX i=1 NX j=1 ( Si ; j logSi ; j + ( 1¡Si ; j ) log ( 1¡Si ; j ) ) ( 1 ) For ranking of features , the importance of each word I ( wk ) is defined as entropy of the data after discarding feature wk .</sentence>
				<definiendum id="0">I</definiendum>
				<definiens id="0">the entropy of data set P with N data points is defined as : E = ¡ NX i=1 NX j=1 ( Si ; j logSi ; j + ( 1¡Si ; j ) log ( 1¡Si ; j ) ) ( 1 ) For ranking of features , the importance of each word</definiens>
				<definiens id="1">entropy of the data after discarding feature wk</definiens>
			</definition>
			<definition id="5">
				<sentence>Assume Wr = ff1 ; : : : ; fMg is the sorted feature list .</sentence>
				<definiendum id="0">fMg</definiendum>
				<definiens id="0">the sorted feature list</definiens>
			</definition>
			<definition id="6">
				<sentence>Here , ^Fk is the optimal feature subset , F and k are the feature subset and the value of cluster number under evaluation , and the criterion is set up based on resamplingbased stability , as Table 2 shows .</sentence>
				<definiendum id="0">^Fk</definiendum>
				<definiens id="0">the optimal feature subset</definiens>
			</definition>
			<definition id="7">
				<sentence>Then the stability is dematrix as : PW = Pcj=1PX i2´j ( Xi ¡ mj ) ( Xj ¡ mj ) t and PB is the between-cluster scatter matrix as : PB =Pc j=1 ( mj ¡m ) ( mj ¡m ) t , where m is the total mean vector and mj is the mean vector for jth cluster and ( Xj¡mj ) t is the matrix transpose of the column vector ( Xj ¡mj ) .</sentence>
				<definiendum id="0">PB</definiendum>
				<definiendum id="1">m</definiendum>
				<definiendum id="2">mj</definiendum>
				<definiens id="0">dematrix as : PW = Pcj=1PX i2´j ( Xi ¡ mj ) ( Xj ¡ mj ) t and</definiens>
				<definiens id="1">the between-cluster scatter matrix as : PB =Pc j=1 ( mj ¡m ) ( mj ¡m</definiens>
				<definiens id="2">the total mean vector and</definiens>
			</definition>
			<definition id="8">
				<sentence>To weight a feature fi within a category , we take into account the following information : 264 Table 3 : Three domains of entity pairs : frequency distribution for different relation types PER-ORG # of pairs:786 ORG-GPE # of pairs:262 ORG-ORG # of pairs:580 Relation types Percentage Relation types Percentage Relation types Percentage Management 36.39 % Based-In 46.56 % Member 27.76 % General-staff 29.90 % Located 35.11 % Subsidiary 19.83 % Member 19.34 % Member 11.07 % Part-Of 18.79 % Owner 4.45 % Affiliate-Partner 3.44 % Affiliate-Partner 17.93 % Located 3.28 % Part-Of 2.29 % Owner 8.79 % Client 1.91 % Owner 1.53 % Client 2.59 % Other 1.91 % Management 2.59 % Affiliate-Partner 1.53 % Other 1.21 % Founder 0.76 % Other 0.52 % † The relative importance of fi within a cluster is defined as : WCi ; k = log2 ( pfi ; k+1 ) log 2 ( Nk+1 ) , where pfi ; k is the number of those entity pairs which contain feature fi in cluster k. Nk is the total number of term pairs in cluster k. † The relative importance of fi across clusters is given by : CCi = log N¢maxk2CifWCi ; kgPN k=1 WCi ; k ¢ 1logN , where Ci is the set of clusters which contain feature fi .</sentence>
				<definiendum id="0">pfi ; k</definiendum>
				<definiendum id="1">Ci</definiendum>
				<definiens id="0">Three domains of entity pairs : frequency distribution for different relation types PER-ORG # of pairs:786 ORG-GPE # of pairs:262 ORG-ORG # of pairs:580 Relation types Percentage Relation types Percentage Relation types Percentage Management</definiens>
				<definiens id="1">the number of those entity pairs which contain feature fi in cluster k. Nk is the total number of term pairs in cluster k. † The relative importance of fi across clusters is given by : CCi = log N¢maxk2CifWCi ; kgPN k=1 WCi ; k ¢ 1logN , where</definiens>
				<definiens id="2">the set of clusters which contain feature fi</definiens>
			</definition>
			<definition id="9">
				<sentence>N is the total number of clusters .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of clusters</definiens>
			</definition>
			<definition id="10">
				<sentence>Since there was no relation type tags for each cluster in our clustering results , we adopted a permutation procedure to assign different relation type tags to only min ( jECj , jTCj ) clusters , where jECj is the estimated number of clusters , and jTCj is the number of ground truth classes 3http : //www.ldc.upenn.edu/Projects/ACE/ ( relation types ) .</sentence>
				<definiendum id="0">jECj</definiendum>
				<definiendum id="1">jTCj</definiendum>
				<definiens id="0">the estimated number of clusters , and</definiens>
			</definition>
			<definition id="11">
				<sentence>To perform the mapping , we construct a contingency table T , where each entry ti ; j gives the number of the instances that belong to both the i-th cluster and j-th ground truth class .</sentence>
				<definiendum id="0">j</definiendum>
				<definiens id="0">gives the number of the instances that belong to both the i-th cluster and j-th ground truth class</definiens>
			</definition>
			<definition id="12">
				<sentence>Then the mapping procedure can be formulated as : ^› = argmax›PjTCjj=1 t› ( j ) ; j , where › ( j ) is the index of the estimated cluster associated with the j-th class .</sentence>
				<definiendum id="0">mapping procedure</definiendum>
				<definiens id="0">the index of the estimated cluster associated with the j-th class</definiens>
			</definition>
			<definition id="13">
				<sentence>Here , ( T ) denotes the identified relation labels from ground truth classes .</sentence>
				<definiendum id="0">T )</definiendum>
				<definiens id="0">the identified relation labels from ground truth classes</definiens>
			</definition>
			<definition id="14">
				<sentence>( E ) is the identified relation labels from our estimated clusters .</sentence>
				<definiendum id="0">E</definiendum>
			</definition>
			<definition id="15">
				<sentence>‘Ave ( T-H ) ’ denotes the average relatedness between ( T ) and ( H ) .</sentence>
				<definiendum id="0">‘Ave ( T-H ) ’</definiendum>
			</definition>
			<definition id="16">
				<sentence>‘Max ( T-H ) ’ denotes the maximum relatedness between ( T ) and ( H ) .</sentence>
				<definiendum id="0">‘Max ( T-H ) ’</definiendum>
			</definition>
</paper>

		<paper id="2008">
			<definition id="0">
				<sentence>Ex.1 shows a question about particle , Japanese postposition , which asks to select the most appropriate particle for the sentence .</sentence>
				<definiendum id="0">Japanese postposition</definiendum>
				<definiens id="0">asks to select the most appropriate particle for the sentence</definiens>
			</definition>
</paper>

		<paper id="3015">
			<definition id="0">
				<sentence>A DAT is a word or a phrase ( compound words ) that enable humans to recognize intuitively a topic of text with their domain knowledge .</sentence>
				<definiendum id="0">DAT</definiendum>
				<definiens id="0">a word or a phrase ( compound words ) that enable humans to recognize intuitively a topic of text with their domain knowledge</definiens>
			</definition>
			<definition id="1">
				<sentence>The DL is the top level which defines many domains , such as “ ' 6� ( Sports ) ” , “o_ ( Military Affairs ) ” .</sentence>
				<definiendum id="0">DL</definiendum>
			</definition>
			<definition id="2">
				<sentence>The DATL is the third level which defines many domain associated terms .</sentence>
				<definiendum id="0">DATL</definiendum>
				<definiens id="0">the third level which defines many domain associated terms</definiens>
			</definition>
			<definition id="3">
				<sentence>In the evaluation step of FLB algorithm , RlogF metric method ( Ellen Riloff , Rosie Jones , 1999 ) is used as evaluation function which assigns a score to a word ( candidate DAT ) .</sentence>
				<definiendum id="0">RlogF metric method</definiendum>
			</definition>
			<definition id="4">
				<sentence>) , ( ) ( 2 ( 1 ) Where F ( wi , X ) is the frequency of co-occurrence of word wi and X ( set of seed words ) in the same sentence , F ( wi ) is the frequency of wi in the corpus , and Ri=F ( wi , X ) /F ( wi ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">F ( wi )</definiendum>
				<definiens id="0">the frequency of co-occurrence of word wi</definiens>
				<definiens id="1">the frequency of wi in the corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>The similarity of a word wt and a topic cluster fj is defined as | | 1 ( ) ( ( , ) ( , ) ) ( ) ( ) ( ) ( ) | | t t t j j t j t j t L i i S w w w f f w f N w N fw N f W O</sentence>
				<definiendum id="0">similarity of a word wt</definiendum>
				<definiendum id="1">topic cluster fj</definiendum>
				<definiendum id="2">| 1 ( ) (</definiendum>
				<definiens id="0">( , ) ( , ) ) ( ) ( ) ( ) ( ) | | t t t j j t j t j t</definiens>
			</definition>
			<definition id="6">
				<sentence>� ( 2 ) Where ( ) ( , ) ( ) ( ) ( ( | ) || ( | ) ) ( ) ( , ) ( ) ( ) ( ( | ) || ( | ) ) t t t j t j t t j j j t j t j j t j P ww w f P w P f D P C w P C w f P ff w f P w P f D P C f P C w f [ [ � u</sentence>
				<definiendum id="0">Where ( )</definiendum>
				<definiens id="0">( , ) ( ) ( ) ( ( | ) || ( | ) ) ( ) ( , ) ( ) ( ) ( ( | ) || ( | ) ) t t t j t j t t j j j t j t j j t j P ww w</definiens>
			</definition>
			<definition id="7">
				<sentence>Where we define the distribution P ( C|wt ) as the random variable over classes C , and its distribution given a particular word wt .</sentence>
				<definiendum id="0">distribution P ( C|wt</definiendum>
			</definition>
			<definition id="8">
				<sentence>N ( fi ) denote the number of words in the topic cluster fi , W is the list of candidate words .</sentence>
				<definiendum id="0">N ( fi</definiendum>
				<definiendum id="1">W</definiendum>
				<definiens id="0">the number of words in the topic cluster fi ,</definiens>
				<definiens id="1">the list of candidate words</definiens>
			</definition>
			<definition id="9">
				<sentence>2 2 1 2 2 2 1 1 1 2 1 ( | ) ( | ) ( ) ( | ) ( ) ( ) ( ) ( | ) ( ) ( ) P C f P C w f P w P C w P w P f P f P C f P w P f � ( 3 ) We turn back the question about how to measure the difference between two probability distributions .</sentence>
				<definiendum id="0">| ) ( ) ( | ) ( ) ( ) ( ) ( | ) ( )</definiendum>
				<definiens id="0">turn back the question about how to measure the difference between two probability distributions</definiens>
			</definition>
			<definition id="10">
				<sentence>The KL divergence between two class distributions induced by wt and ws is written as | | 1 ( ( | ) || ( | ) ) ( | ) ( | ) log ( ) ( | ) t s C j t j t j j s D P C w P C w P c wP c w P c w � ( 4 ) In preprocessing step , the CHI statistic measures the lack of independence of feature t and category c. D ) B ) ( CD ) ( AC ) ( B ( A BC ) -N ( ADc ) 2 ( t , 2 F Where t refers to a feature and c refers to a category , A is the number of times t and c co-occur , B is the number of times t occurs without c , C is the number of times c occurs without t , D is the number of times neither c nor t co-occur , and N is the total number of documents .</sentence>
				<definiendum id="0">KL divergence</definiendum>
				<definiendum id="1">CHI statistic</definiendum>
				<definiendum id="2">c co-occur , B</definiendum>
				<definiendum id="3">C</definiendum>
				<definiendum id="4">D</definiendum>
				<definiendum id="5">N</definiendum>
				<definiens id="0">measures the lack of independence of feature t and category c. D ) B ) ( CD ) ( AC ) ( B ( A BC ) -N ( ADc</definiens>
				<definiens id="1">the number of times t occurs without c ,</definiens>
				<definiens id="2">the number of times c occurs without t</definiens>
				<definiens id="3">the number of times neither c nor t co-occur , and</definiens>
				<definiens id="4">the total number of documents</definiens>
			</definition>
			<definition id="11">
				<sentence>Where N ( ti|d ) is the frequency of word ti in document d , T is the vocabulary and |T| is the 113 size of T , ti is the ith word in the vocabulary , and P ( ti|c ) thus represents the probability that a randomly drawn word from a randomly drawn document in category c will be the word ti .</sentence>
				<definiendum id="0">N ( ti|d )</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the frequency of word ti in document d ,</definiens>
				<definiens id="1">the vocabulary and |T| is the 113 size of T , ti is the ith word in the vocabulary , and P ( ti|c ) thus represents the probability that a randomly drawn word from a randomly drawn document in category c will be the word ti</definiens>
			</definition>
			<definition id="12">
				<sentence>Precision is the ratio of correct assignments by the system divided by the total number of the system’s assignments .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio of correct assignments by the system divided by the total number of the system’s assignments</definiens>
			</definition>
</paper>

		<paper id="2009">
			<definition id="0">
				<sentence>( 4 ) Scan the n summary words from left to right and find the path on the trellis that maximizes the score of formula ( 1 ) .</sentence>
				<definiendum id="0">Scan</definiendum>
			</definition>
</paper>

		<paper id="5010">
			<definition id="0">
				<sentence>The following is a simple example , containing one nucleus-satellite relation ( REASON ) and one multinuclear relation ( CONJUNCTION1 ) : reason NUCLEUS : recommend ( doctors , elixir ) SATELLITE : conjunction 1 : quick-results ( elixir ) 2 : few-side-effects ( elixir ) Ignoring variations in the wording of propositions , ICONOCLAST generates over 20 texts realising this input ( or many more if a larger repertoire of discourse connectives is allowed ) .</sentence>
				<definiendum id="0">quick-results</definiendum>
				<definiens id="0">a simple example , containing one nucleus-satellite relation ( REASON ) and one multinuclear relation ( CONJUNCTION1 ) : reason NUCLEUS</definiens>
			</definition>
			<definition id="1">
				<sentence>Text structuring is controlled by hard constraints , which determine the set of solutions that can be generated , and by preferences ( or soft constraints ) , which allow a ranking of solutions from best to worst .</sentence>
				<definiendum id="0">Text structuring</definiendum>
				<definiens id="0">determine the set of solutions that can be generated , and by preferences ( or soft constraints ) , which allow a ranking of solutions from best to worst</definiens>
			</definition>
</paper>

		<paper id="5008">
			<definition id="0">
				<sentence>By definition , paraphrase is an equivalence in meaning , thus , different sentences having the same translation ought to be considered equivalent in meaning , i.e. , they are paraphrases2 .</sentence>
				<definiendum id="0">paraphrase</definiendum>
				<definiens id="0">an equivalence in meaning , thus , different sentences having the same translation ought to be considered equivalent in meaning</definiens>
			</definition>
			<definition id="1">
				<sentence>BLEU tends to measure the quality in form of expression ( fluency ) , while NIST6 tends to measure quality in meaning ( adequacy ) .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">tends to measure the quality in form of expression ( fluency ) , while NIST6 tends to measure quality in meaning ( adequacy )</definiens>
			</definition>
			<definition id="2">
				<sentence>The scores in BLEU and NIST ( both on a scale from 0 to 1 ) shown in Figure 2 are interpreted 6Formally , NIST is an open scale .</sentence>
				<definiendum id="0">NIST</definiendum>
				<definiens id="0">an open scale</definiens>
			</definition>
</paper>

		<paper id="2030">
			<definition id="0">
				<sentence>Anaphoricity determination is the task of judging whether a given NP is anaphoric or nonanaphoric .</sentence>
				<definiendum id="0">Anaphoricity determination</definiendum>
				<definiens id="0">the task of judging whether a given NP is anaphoric or nonanaphoric</definiens>
			</definition>
			<definition id="1">
				<sentence>In these experiments , we define an opinion as follows : An opinion is a description that expresses the writer’s subjective evaluation of a particular subject or a certain aspect of it .</sentence>
				<definiendum id="0">opinion</definiendum>
				<definiendum id="1">opinion</definiendum>
			</definition>
</paper>

		<paper id="3004">
			<definition id="0">
				<sentence>A binary SVM is a maximum margin classifier .</sentence>
				<definiendum id="0">binary SVM</definiendum>
				<definiens id="0">a maximum margin classifier</definiens>
			</definition>
			<definition id="1">
				<sentence>LIBSVM uses the “one-against-one” approach in which k ( k−1 ) /2 classifiers are constructed and each one trains on data from two different classes ( Hsu and Lin , 2002 ) .</sentence>
				<definiendum id="0">LIBSVM</definiendum>
				<definiens id="0">uses the “one-against-one” approach in which k ( k−1 ) /2 classifiers are constructed and each one trains on data from two different classes</definiens>
			</definition>
			<definition id="2">
				<sentence>An example noun phrase ( translation : ‘a major commercial waterway’ ) is : ( IP ... . ( NP ( QP ( CD_d_948 ) ( CLP ( M_d_3403 ) ) ) ( NP ( NN_d_3762_d_6655 ) ) ( ADJP ( JJ_d_2101 ) ) ( NP ( NN_d_1452_d_5471 ) ) ) ... ) The word in ( CLP ( M_d_3403 [ tiao ] ) ) is the classifier and the head noun of the noun phrase is ( NN _d_1452 _d_5471 ) .</sentence>
				<definiendum id="0">example noun phrase</definiendum>
				<definiens id="0">‘a major commercial waterway’</definiens>
			</definition>
			<definition id="3">
				<sentence>HowNet is a bilingual Chinese-English lexicon and ontology .</sentence>
				<definiendum id="0">HowNet</definiendum>
				<definiens id="0">a bilingual Chinese-English lexicon and ontology</definiens>
			</definition>
			<definition id="4">
				<sentence>The sememe at the first position , ‘human ( _d_1054 ) ’ , is the categorical attribute , which describes the general category of the concept .</sentence>
				<definiendum id="0">categorical attribute</definiendum>
				<definiens id="0">describes the general category of the concept</definiens>
			</definition>
			<definition id="5">
				<sentence>We assign to each noun in the testing data its most fre27 No. : 114303 W C ( word in Chinese ) : _d_1144_d_2319 E C ( example in Chinese ) : G C ( POS tag in Chinese ) : N W E ( word in English ) : writer E E ( example in English ) : G E ( POS tag in English ) : N DEF ( concept definition ) : human ( _d_1054 ) , # occupation ( _d_5385_d_1132 ) , *compile ( _d_5249_d_6625 ) , # readings ( _d_6321_d_4266 ) , literature ( _d_3230 ) Table 1 : An entry in HowNet Lexical Features Syntactic Features noun POS of noun first premod POS of first premod second premod POS of second premod main verb POS of main verb total number of premodifiers sentType embedded in vp or pp quoted or not Table 2 : Features extracted from training data quently co-occurring classifier ( c.f. ( Sornlertlamvanich et al. , 1994 ) ) .</sentence>
				<definiendum id="0">N DEF</definiendum>
				<definiens id="0">word in English ) : writer E E ( example in English ) : G E ( POS tag in English</definiens>
			</definition>
			<definition id="6">
				<sentence>We tried the four types of kernel function in LIBSVM : linear , polynomial , radial basis function ( RBF ) and sigmoid , then selected the RBF kernal K ( x , y ) = e−γ||x−y||2 , which gives the 28 Algorithm All nouns Nouns occuring 2+ times Baseline 50.76 % 50.69 % ( 1 ) noun only 57.81 % ( c = 4 , γ = 0.5 ) 59.34 % ( c = 16 , γ = 0.125 ) ( 2 ) ontology only 58.69 % ( c = 4 , γ = 0.5 ) 60.68 % ( c = 256 , γ = 0.125 ) ( 3 ) noun and ontology 57.81 % ( c = 16 , γ = 0.5 ) 59.46 % ( c = 16 , γ = 0.125 ) ( 4 ) noun or ontology 58.71 % 60.55 % ( 5 ) noun , syntactic and lexical features 52.14 % ( c = 1024 , γ = 0.5 ) 53.51 % ( c = 16 , γ = 0.5 ) ( 6 ) all features 52.06 % ( c = 1024 , γ = 0.075 ) 53.55 % ( c = 16 , γ = 0.5 ) Table 3 : Accuracy of different algorithms Most common noun _d_1132 [ wei ] _d_3664 [ ci ] _d_977 [ ge ] _d_1613 [ ming ] _d_2384 [ jie ] _d_7303 [ xiang ] _d_1132 [ wei ] _d_2299_d_1661 ( official ) 24.1 ( 57.1 ) 14.7 ( 34.7 ) _d_3664 [ ci ] _d_2101_d_1109 ( convention ) 22.3 ( 53.3 ) 1.1 ( 2.6 ) 7.6 ( 18.2 ) _d_977 [ ge ] _d_7303_d_4649 ( project ) 1.0 ( 7.0 ) 0.7 ( 5.2 ) 0.2 ( 1.7 ) 3.3 ( 24.4 ) _d_1613 [ ming ] _d_1054_d_1661 ( person ) 31.7 ( 55.2 ) 23.8 ( 41.4 ) _d_2384 [ jie ] _d_6655_d_1452_d_1109 ( sports tournament ) _d_7303 [ xiang ] _d_2884_d_3428 ( achievement ) Table 4 : Most commonly misclassified classifiers ; Cell shows percentage of total occurrences of row value misclassified as column value and ( percentage of total misclassifications of row value misclassified as column value ) highest accuracy .</sentence>
				<definiendum id="0">RBF kernal K</definiendum>
				<definiens id="0">gives the 28 Algorithm All nouns Nouns occuring</definiens>
				<definiens id="1">Most commonly misclassified classifiers ; Cell shows percentage of total occurrences of row value misclassified as column value and ( percentage of total misclassifications of row value misclassified as column value ) highest accuracy</definiens>
			</definition>
</paper>

		<paper id="2026">
			<definition id="0">
				<sentence>Barzilay and Elhadad [ 1 ] used lexical chains for text summarization ; they identified important sentences in a document by retrieving strong chains .</sentence>
				<definiendum id="0">lexical chains</definiendum>
				<definiens id="0">for text summarization ; they identified important sentences in a document by retrieving strong chains</definiens>
			</definition>
			<definition id="1">
				<sentence>Silber and McCoy’s algorithm computes all of the scored metachains for all senses of each word in the document and attributes the word to the metachain to which it contributes the most .</sentence>
				<definiendum id="0">McCoy’s algorithm</definiendum>
				<definiens id="0">computes all of the scored metachains for all senses of each word in the document and attributes the word to the metachain to which it contributes the most</definiens>
			</definition>
</paper>

		<paper id="2013">
			<definition id="0">
				<sentence>This pattern corresponds to two syntactic analyses : ( 4b ) in which il is impersonal and the infinitival phrase de &lt; V : K &gt; is subcategorized by difficile , and ( 4c ) in which il is anaphoric and the infinitival phrase is part of an NP .</sentence>
				<definiendum id="0">infinitival phrase</definiendum>
				<definiens id="0">two syntactic analyses : ( 4b ) in which il is impersonal and the infinitival phrase de &lt; V : K &gt; is subcategorized by difficile , and ( 4c ) in which il is anaphoric and the</definiens>
			</definition>
</paper>

		<paper id="3008">
			<definition id="0">
				<sentence>E.g , Ús ( “electric-mail” ; e-mail ) is a kind of mail .</sentence>
				<definiendum id="0">e-mail )</definiendum>
				<definiens id="0">a kind of mail</definiens>
			</definition>
			<definition id="1">
				<sentence>CILIN Thesaurus is a tree-structured taxonomic semantic structure of Chinese words , which can be seen as a special case of semantic network .</sentence>
				<definiendum id="0">CILIN Thesaurus</definiendum>
				<definiens id="0">a tree-structured taxonomic semantic structure of Chinese words , which can be seen as a special case of semantic network</definiens>
			</definition>
			<definition id="2">
				<sentence>f is the frequency of the semantic classes , and the denominator is the total value of numerator for the purpose of normalization .</sentence>
				<definiendum id="0">f</definiendum>
				<definiens id="0">the frequency of the semantic classes</definiens>
			</definition>
			<definition id="3">
				<sentence>The Information Load ( IL ) of a semantic class sc is defined in Chen and Chen ( 2004 ) : IL ( sc ) = Entropy ( system ) −Entropy ( sc ) ( 3 ) similarequal ( −1q summationdisplay log2 1q ) − ( −1p summationdisplay log2 1p ) = log2 q − log2 p = −log2 ( pq ) , if there is q the number of the minimal semantic classes in the system,8 p is the number of the semantic classes subordinate sc .</sentence>
				<definiendum id="0">Information Load ( IL ) of a semantic class sc</definiendum>
				<definiens id="0">the number of the semantic classes subordinate sc</definiens>
			</definition>
</paper>

		<paper id="5002">
			<definition id="0">
				<sentence>The Microsoft Research Paraphrase Corpus ( MSRP ) , available for download at http : //research.microsoft.com/research/nlp/msr_ paraphrase .</sentence>
				<definiendum id="0">Microsoft Research Paraphrase Corpus</definiendum>
				<definiens id="0">available for download at http : //research.microsoft.com/research/nlp/msr_ paraphrase</definiens>
			</definition>
			<definition id="1">
				<sentence>htm , consists of 5801 pairs of sentences , each accompanied by a binary judgment indicating whether human raters considered the pair of sentences to be similar enough in meaning to be considered close paraphrases .</sentence>
				<definiendum id="0">htm</definiendum>
				<definiens id="0">consists of 5801 pairs of sentences , each accompanied by a binary judgment indicating whether human raters considered the pair of sentences to be similar enough in meaning to be considered close paraphrases</definiens>
			</definition>
			<definition id="2">
				<sentence>These , however , tend to be rather restricted in their domain ( e.g. the ATR English-Chinese paraphrase corpus , which con9 sists of translations of travel phrases ( Zhang &amp; Yamamoto , 2002 ) ) , are limited to short handcrafted predicates ( e.g. the ATR JapaneseEnglish corpus ( Shirai , et al. , 2002 ) ) , or exhibit quality problems stemming from insufficient command of the target language by the translators of the documents in question , e.g. the Linguistic Data Consortium’s Multiple-Translation Chinese Corpus ( Huang et al. , 2002 ) .</sentence>
				<definiendum id="0">ATR English-Chinese paraphrase corpus</definiendum>
				<definiens id="0">con9 sists of translations of travel phrases</definiens>
				<definiens id="1">limited to short handcrafted predicates ( e.g. the ATR JapaneseEnglish corpus ( Shirai , et al. , 2002 ) ) , or exhibit quality problems stemming from insufficient command of the target language by the translators of the documents in question</definiens>
			</definition>
			<definition id="3">
				<sentence>The Microsoft Research Paraphrase Corpus ( MSRP ) is distilled from a database of 13,127,938 sentence pairs , extracted from 9,516,684 sentences in 32,408 news clusters collected from the World Wide Web over a 2year period , The methods and assumptions used in building this initial data set are discussed in Quirk et al. ( 2004 ) and Dolan et al. ( 2004 ) .</sentence>
				<definiendum id="0">Microsoft Research Paraphrase Corpus ( MSRP</definiendum>
				<definiens id="0">distilled from a database of 13,127,938 sentence pairs , extracted from 9,516,684 sentences in 32,408 news clusters collected from the World Wide Web over a 2year period</definiens>
			</definition>
</paper>

		<paper id="2031">
			<definition id="0">
				<sentence>On the other hand , it is a question whether the typological differences between Czech and English justify the transfer being performed at the tectogrammatical ( deep syntactic ) level .</sentence>
				<definiendum id="0">tectogrammatical</definiendum>
				<definiens id="0">a question whether the typological differences between Czech and English justify the transfer being performed at the</definiens>
			</definition>
			<definition id="1">
				<sentence>The grammar framework , similarly as the formally a bit weaker platform SProUT ( Bering et al. , 2003 ) , 182 uses finite-state techniques and unification , i.e. , a grammar consists of pattern/action rules , where the left-hand side is a regular expression over typed feature structures ( TFS ) with variables , representing the recognition pattern , and the righthand side is a TFS specification of the output structure .</sentence>
				<definiendum id="0">righthand side</definiendum>
				<definiens id="0">a regular expression over typed feature structures ( TFS ) with variables , representing the recognition pattern</definiens>
				<definiens id="1">a TFS specification of the output structure</definiens>
			</definition>
</paper>

		<paper id="2020">
			<definition id="0">
				<sentence>As the definition of the confidence score q ( 〈s , t〉 ) of a translation pair 〈s , t〉 , in this paper , we use the following : q ( 〈s , t〉 ) = ⎧ ⎪ ⎨ ⎪ ⎩ 10 ( compo ( s ) −1 ) ( 〈s , t〉 in Eijiro ) log 10 f p ( 〈s , t〉 ) ( 〈s , t〉 in B P ) log 10 f s ( 〈s , t〉 ) ( 〈s , t〉 in B S ) ( 1 ) where compo ( s ) denotes the word ( in English ) or morpheme ( in Japanese ) count of s , f p ( 〈s , t〉 ) the frequency of 〈s , t〉 as the first constituent in P 2 , and f s ( 〈s , t〉 ) the frequency of 〈s , t〉 as the second constituent in P 2 .</sentence>
				<definiendum id="0">compo ( s )</definiendum>
				<definiendum id="1">f p</definiendum>
				<definiens id="0">〈s , t〉 ) the frequency of 〈s</definiens>
				<definiens id="1">〈s , t〉 ) the frequency of 〈s</definiens>
			</definition>
			<definition id="1">
				<sentence>T ) translation set ( language T ) web ( language S ) web ( language S ) existing bilingual lexicon X S M ( # of translations is more than one ) Y S ( # of translations is zero ) web ( language T ) web ( language T ) looking up bilingual lexicon validating translation candidates Figure 4 : Experimental Evaluation of Translation Estimation for Technical Terms with/without the Domain/Topic Specific Corpus ( taken from Figure 1 ) constituent translation pairs 〈s 1 , t 1 〉 , ··· , 〈s n , t n 〉 .</sentence>
				<definiendum id="0">Specific Corpus</definiendum>
				<definiens id="0">translation set ( language T ) web ( language S ) web ( language S</definiens>
				<definiens id="1">zero ) web ( language T ) web ( language T</definiens>
				<definiens id="2">Experimental Evaluation of Translation Estimation for Technical Terms with/without the Domain/Topic</definiens>
			</definition>
			<definition id="2">
				<sentence>Q ( y t ) = n productdisplay i=1 q ( 〈s i , t i 〉 ) ( 2 ) If a translation candidate is generated from more than one sequence of translation pairs , the score of the translation candidate is defined as the sum of the score of each sequence .</sentence>
				<definiendum id="0">score of the translation candidate</definiendum>
				<definiens id="0">the sum of the score of each sequence</definiens>
			</definition>
</paper>

		<paper id="4001">
			<definition id="0">
				<sentence>A term is a kind of phrases , whose components are close related .</sentence>
				<definiendum id="0">term</definiendum>
				<definiens id="0">a kind of phrases</definiens>
			</definition>
			<definition id="1">
				<sentence>8� ( Interface Technology Specification ) ” as a term , while ignore “ y � T ( Interface Technology” , although it may be also a term in other context .</sentence>
				<definiendum id="0">Interface Technology”</definiendum>
				<definiens id="0">Interface Technology Specification ) ” as a term</definiens>
			</definition>
</paper>

		<paper id="2006">
			<definition id="0">
				<sentence>Wrong information is a central problem of developing a knowledge base by using natural language 31 documents .</sentence>
				<definiendum id="0">Wrong information</definiendum>
				<definiens id="0">a central problem of developing a knowledge base by using natural language 31 documents</definiens>
			</definition>
			<definition id="1">
				<sentence>The system consists of the following modules : Knowledge Base It consists of † question and answer mails ( 50846 mails ) , † significant sentences ( 26334 sentences : 8964 , 13094 , and 4276 sentences were extracted from question , DA , and QR mails , respectively ) , † confirmation labels ( 4276 labels were given to 3613 sets of a question and its DA mail ) , and † synonym dictionary ( 519 words ) .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of the following modules : Knowledge Base It consists of † question and answer mails ( 50846 mails ) , † significant sentences ( 26334 sentences : 8964 , 13094 , and 4276 sentences were extracted from question , DA , and QR mails , respectively ) , † confirmation labels ( 4276 labels were given to 3613 sets of a question and its DA mail ) , and † synonym dictionary ( 519 words )</definiens>
			</definition>
			<definition id="2">
				<sentence>Similarity calculator calculates the similarity between user’s question and a significant sentence in a question mail posted to a mailing list by comparing their common content words and dependency trees in the next way : The weight of a common content word t which occurs in user’s question Q and significant sentence Si in the mails Mi ( i = 1¢ ¢ ¢N ) is : wWORD ( t ; Mi ) = tf ( t ; Si ) log Ndf ( t ) where tf ( t ; Si ) denotes the number of times content word t occurs in significant sentence Si , N denotes the number of significant sentences , and df ( t ) denotes the number of significant sentences in which content word t occurs .</sentence>
				<definiendum id="0">Similarity calculator</definiendum>
				<definiendum id="1">Si</definiendum>
				<definiendum id="2">tf</definiendum>
				<definiendum id="3">Si )</definiendum>
				<definiendum id="4">N</definiendum>
				<definiendum id="5">df</definiendum>
				<definiens id="0">calculates the similarity between user’s question and a significant sentence in a question mail posted to a mailing list by comparing their common content words and dependency trees in the next way : The weight of a common content word t which occurs in user’s question Q and significant sentence</definiens>
				<definiens id="1">the number of times content word t occurs in significant sentence Si ,</definiens>
				<definiens id="2">the number of significant sentences</definiens>
			</definition>
</paper>

		<paper id="4008">
			<definition id="0">
				<sentence>1 Data Collection Taiwan Child Language Corpus ( TAICORP ) is a corpus of text files transcribed from the child speech recorded between October 1997 through May 2000 .</sentence>
				<definiendum id="0">Data Collection Taiwan Child Language Corpus ( TAICORP )</definiendum>
				<definiens id="0">a corpus of text files transcribed from the child speech recorded between October 1997 through May 2000</definiens>
			</definition>
			<definition id="1">
				<sentence>These headers begin with @ , for example : Obligatory headers : @ Begin @ End @ Participants Constant headers : @ Age of XXX : @ Birth of XXX : @ Coder : @ Educ of XXX : @ Filename : @ ID : @ Language : @ Language of XXX : @ SES of XXX : social and economic status of a specific speaker @ Sex of XXX : @ Warning : the defects of the file Changeable headers : @ Activities : @ Comment : @ Date : @ Location : @ New Episode : @ Room Layout : @ Situation : @ Tape Location : @ Time Duration : @ Time Start : The content of a file is presented in tiers , including main tiers and dependent tiers .</sentence>
				<definiendum id="0">Start</definiendum>
				<definiens id="0">the defects of the file Changeable headers : @ Activities : @ Comment : @ Date : @ Location : @ New Episode : @ Room Layout : @ Situation : @ Tape Location : @ Time Duration : @ Time</definiens>
			</definition>
			<definition id="2">
				<sentence>A main tier , indicated by * , contains the utterance of the speaker .</sentence>
				<definiendum id="0">main tier</definiendum>
				<definiens id="0">indicated by * , contains the utterance of the speaker</definiens>
			</definition>
			<definition id="3">
				<sentence>Main tiers The main tiers used in TAICORP include the following : @ � INV : the utterance of the investigator @ � CHI : the utterance of the target child @ � MOT : the utterance of mother @ � FAT : the utterance of father @ � SIS : the utterance of sister @ � BRO : the utterance of brother @ � GRM : the utterance of grandmother @ � GRF : the utterance of grandfather @ � OTH : the utterance of other people The main tier is the most important tier because it is where the utterances are listed .</sentence>
				<definiendum id="0">SIS</definiendum>
				<definiendum id="1">BRO</definiendum>
				<definiens id="0">the utterance of the investigator @ � CHI : the utterance of the target child @ � MOT : the utterance of mother @ � FAT : the utterance of father @ �</definiens>
				<definiens id="1">the utterance of sister @ �</definiens>
			</definition>
			<definition id="4">
				<sentence>The romanization system used in TAICORP is the Taiwan Southern Min Phonetic Alphabetic ( also known as Taiwan Language Phonetic Alphabet , TLPA , originally proposed by the Taiwan Language Society in 1991 ) announced officially by the Ministry of Education of Taiwan in 1998 .</sentence>
				<definiendum id="0">romanization system</definiendum>
			</definition>
</paper>

		<paper id="2044">
			<definition id="0">
				<sentence>SVM is one of the binary classifiers based on maximum margin strategy introduced by Vapnik [ 16 ] .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">one of the binary classifiers based on maximum margin strategy introduced by</definiens>
			</definition>
</paper>

		<paper id="3028">
			<definition id="0">
				<sentence>IRLAS consists of several basic components and multiple postprocessors .</sentence>
				<definiendum id="0">IRLAS</definiendum>
			</definition>
			<definition id="1">
				<sentence>tion , X is surname , S is the first character of given name , W is the second character of given name , N is the word following a person name , and O is other remote context .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">W</definiendum>
				<definiendum id="3">N</definiendum>
				<definiendum id="4">O</definiendum>
				<definiens id="0">the first character of given name</definiens>
				<definiens id="1">the second character of given name ,</definiens>
				<definiens id="2">the word following a person name , and</definiens>
			</definition>
</paper>

		<paper id="7004">
</paper>

		<paper id="3022">
</paper>

		<paper id="7001">
</paper>

		<paper id="7003">
</paper>

		<paper id="2017">
			<definition id="0">
				<sentence>Our grammar , named KPSG ( Korean Phrase Structure Grammar ) , first assumes that a nominal with -nim and a verbal with -si bear the head feature specification [ HON + ] .</sentence>
				<definiendum id="0">KPSG</definiendum>
				<definiens id="0">( Korean Phrase Structure Grammar ) , first assumes that a nominal with -nim and a verbal with -si bear the head feature specification [ HON + ]</definiens>
			</definition>
</paper>

		<paper id="3009">
			<definition id="0">
				<sentence>the Key Technology : An Inter-Domain Entropy Approach Since the terms ( words or compound words ) in the documents include general terms as well as domain-specific terms , the only problem then is an effective model to exclude those domain-independent terms from the implicit tagging process .</sentence>
				<definiendum id="0">Key Technology</definiendum>
				<definiens id="0">An Inter-Domain Entropy Approach Since the terms ( words or compound words ) in the documents include general terms as well as domain-specific terms</definiens>
				<definiens id="1">an effective model to exclude those domain-independent terms from the implicit tagging process</definiens>
			</definition>
			<definition id="1">
				<sentence>where N is the total number of domains .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
			<definition id="2">
				<sentence>-u ( foul ) �� �x ( baseball team ) I ~ ( Ho-Hsin TVStation ) � ( shot ) �G � ( marketatmosphere ) � o ( manager ) J ] ( governmentinformation office ) �W4 ( male team )  &gt; 1� ( destination ) � � ( practicing ) r { �� ( defense ) L� ( car delivery ) ( Hsin-Lung team ) n ( channel ) � �� ( championship ) u M ( of the same grade ) �� ( course ; diamond ) = .</sentence>
				<definiendum id="0">-u</definiendum>
				<definiens id="0">male team )  &gt; 1� ( destination ) � � ( practicing ) r { �� ( defense ) L� ( car delivery ) ( Hsin-Lung team ) n ( channel ) � �� ( championship ) u M ( of the same grade</definiens>
			</definition>
			<definition id="3">
				<sentence>( video )  � ( Wallace ) �� ( trunk ) �z ( the Sun team ) aW ( entertainment ) D � ( Philadelphia ) �� ( c.c. ) Table 1 .</sentence>
				<definiendum id="0">Wallace</definiendum>
				<definiens id="0">the Sun team ) aW ( entertainment ) D � ( Philadelphia ) �� ( c.c.</definiens>
			</definition>
			<definition id="4">
				<sentence>`` An Unsupervised Iterative Method for Chinese New Lexicon Extraction '' , International Journal of Computational Linguistics and Chinese Language Processing ( CLCLP ) , 2 ( 2 ) :97-148 .</sentence>
				<definiendum id="0">An Unsupervised Iterative Method</definiendum>
				<definiens id="0">for Chinese New Lexicon Extraction ''</definiens>
			</definition>
</paper>

		<paper id="3031">
			<definition id="0">
				<sentence>Tag S means the character is a “single-character” word .</sentence>
				<definiendum id="0">Tag S</definiendum>
				<definiens id="0">means the character is a “single-character” word</definiens>
			</definition>
			<definition id="1">
				<sentence>Tag Description L Character is at the beginning of the word ( or the character is the leftmost character in the word ) M Character is in the middle of the word R Character is at the end of the word ( or the character is the rightmost character in the word ) S Character is a ”single-character” word Inthissection , weintroduceourTwo-PhaseLMRRC Tagging used to perform Chinese Text Segmentation .</sentence>
				<definiendum id="0">S Character</definiendum>
				<definiendum id="1">weintroduceourTwo-PhaseLMRRC Tagging</definiendum>
				<definiens id="0">at the beginning of the word ( or the character is the leftmost character in the word ) M Character is in the middle of the word R Character is at the end of the word ( or the character is the rightmost character in the word )</definiens>
				<definiens id="1">a ”single-character” word Inthissection</definiens>
			</definition>
			<definition id="2">
				<sentence>Let TrainModel : O → P , where P is the set of models , be the “model generating” function .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">the set of models</definiens>
			</definition>
</paper>

		<paper id="3014">
			<definition id="0">
				<sentence>DLT is a domain taxonomy enriched with domain lexica .</sentence>
				<definiendum id="0">DLT</definiendum>
				<definiens id="0">a domain taxonomy enriched with domain lexica</definiens>
			</definition>
			<definition id="1">
				<sentence>Second , the DLT offers the most reliable evidence for deciding the domain of a new text since these lexical clues belong to the general lexicon and do occur reliably in all texts .</sentence>
				<definiendum id="0">DLT</definiendum>
				<definiens id="0">offers the most reliable evidence for deciding the domain of a new text since these lexical clues belong to the general lexicon and do occur reliably in all texts</definiens>
			</definition>
			<definition id="2">
				<sentence>“Introduction to WordNet : An On-line Lexical Database , ” In Proceedings of the fifteenth International Joint Conference on 108 Artificial Intelligence .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An On-line Lexical Database</definiens>
			</definition>
</paper>

		<paper id="2021">
			<definition id="0">
				<sentence>Much effort has been put in designing and evaluating dedicated word sense disambiguation ( WSD ) models , in particular with the Senseval series of workshops .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">put in designing and evaluating dedicated word sense disambiguation (</definiens>
			</definition>
			<definition id="1">
				<sentence>BLEU score with low order n-grams can be seen as an evaluation of the translation adequacy , which suggests that as SMT systems achieve higher BLEU score , their ability to disambiguate word translations improves .</sentence>
				<definiendum id="0">translation adequacy</definiendum>
			</definition>
			<definition id="2">
				<sentence>To improve accuracy , dedicated WSD models typically employ features that are not limited to the local context , and that include more linguistic information than the surface form of words .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">models typically employ features that are not limited to the local context , and that include more linguistic information than the surface form of words</definiens>
			</definition>
			<definition id="3">
				<sentence>The ISI ReWrite decoder ( Germann , 2003 ) , which implements an efficient greedy decoding algorithm , is used to translate the Chinese sentences , using the alignment model and language model previously described .</sentence>
				<definiendum id="0">ISI ReWrite decoder</definiendum>
				<definiens id="0">implements an efficient greedy decoding algorithm , is used to translate the Chinese sentences , using the alignment model and language model previously described</definiens>
			</definition>
			<definition id="4">
				<sentence>Since the training set consists of sense-annotated Chinese sentences , and not of Chinese-English bisentences , we artificially create sentence pairs for each training instance , where the Chinese sentence consists of the Chinese target word , and the English sense is the English gloss given by HowNet for that particular target word and HowNet sense .</sentence>
				<definiendum id="0">sense</definiendum>
			</definition>
</paper>

		<paper id="5009">
			<definition id="0">
				<sentence>Inaddition , wecanconstruct an example-based or a Statistical Machine Translation ( SMT ) -like paraphrasing system that utilizes paraphrasing examples .</sentence>
				<definiendum id="0">Inaddition</definiendum>
				<definiens id="0">wecanconstruct an example-based or a Statistical Machine Translation ( SMT ) -like paraphrasing system that utilizes paraphrasing examples</definiens>
			</definition>
			<definition id="1">
				<sentence>In this paper , however , as a first step to evaluate paraphrasing pairs , we focus on the evaluation of contextual dependency by usingprobabilisticLatentSemanticIndexing ( pLSI ) ( Hofmann , 1999 ) and Latent Dirichlet Allocation ( LDA ) ( Blei et al. , 2003 ) as text models with latent variables .</sentence>
				<definiendum id="0">pLSI )</definiendum>
				<definiens id="0">Blei et al. , 2003 ) as text models with latent variables</definiens>
			</definition>
			<definition id="2">
				<sentence>PLSI is a latent variable model for general cooccurrence data that associates an unobserved topic variable z ∈ Z = { z1 , ··· , zK } with each observation , i.e. , with each occurrence of word w ∈ W = { w1 , ··· , wM } in document d ∈ D = { d1 , ···dN } .</sentence>
				<definiendum id="0">PLSI</definiendum>
				<definiens id="0">a latent variable model for general cooccurrence data that associates an unobserved topic variable z ∈ Z = { z1 , ··· , zK } with each observation</definiens>
			</definition>
			<definition id="3">
				<sentence>PLSI gives joint probability for a word and a document as follows : P ( d , w ) = P ( d ) P ( w|d ) , ( 1 ) where P ( w|d ) = summationdisplay z∈Z P ( w|z ) P ( z|d ) .</sentence>
				<definiendum id="0">PLSI</definiendum>
			</definition>
			<definition id="4">
				<sentence>From ( Hofmann , 1999 ) , we can derive the following formulas : P ( z|d , w ) ∝ P ( z ) P ( d|z ) P ( w|z ) ( 3 ) and P ( d|z ) ∝summationdisplay w n ( d , w ) P ( z|d , w ) , ( 4 ) where n ( d , w ) denotes term frequency , which is the number of times w occurs in d. Assuming that P ( d|z ) =producttextw∈d P ( w|z ) , the probability of a topic under document ( P ( z|d ) ) is proportional to the following formula : P ( z ) 2 productdisplay w∈d P ( w|z ) summationdisplay w n ( d , w ) P ( w|z ) .</sentence>
				<definiendum id="0">w ) denotes term frequency</definiendum>
				<definiens id="0">the number of times w occurs in d. Assuming that P ( d|z ) =producttextw∈d P ( w|z ) , the probability of a topic under document ( P ( z|d )</definiens>
			</definition>
			<definition id="5">
				<sentence>A topic z that maximizes Formula 5 is inferred as the topic of document d. Latent Dirichlet Allocation ( LDA ) is a generative probabilistic model of a corpus .</sentence>
				<definiendum id="0">topic z</definiendum>
				<definiendum id="1">LDA</definiendum>
				<definiens id="0">a generative probabilistic model of a corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>LDA gives us the marginal distribution of a document ( p ( d|α , β ) , d = ( w1 , w2 , ···wN ) ) by the following formula : integraldisplay p ( θ|α ) parenleftBigg Nproductdisplay n=1 summationdisplay zn p ( zn|θ ) p ( wn|zn , β ) parenrightBigg dθ , ( 6 ) where α parameterizes Dirichlet random variable θ and β parameterizes the word probabilities , and zn indicates a topic variable zn ∈ Z = { z1 , z2 , ··· , zN } .</sentence>
				<definiendum id="0">LDA</definiendum>
				<definiendum id="1">zn</definiendum>
				<definiens id="0">gives us the marginal distribution of a document ( p ( d|α , β )</definiens>
			</definition>
			<definition id="7">
				<sentence>Table 6 Table 6 : Window size and Kappa statistics for first-level annotation window pLSI LDA size ( 20 topics ) ( 20 topics ) 5 0.4580 0.2527 11 0.5085 0.5185 15 0.5165 0.5440 21 0.4613 0.5396 25 0.3286 0.5286 31 0.1730 0.5157 shows the experimental results .</sentence>
				<definiendum id="0">Kappa statistics</definiendum>
				<definiens id="0">Window size</definiens>
			</definition>
			<definition id="8">
				<sentence>On the other hand , Sdep denotes a set that consists of paraphrasing pairs that are judged as having the same topic , but are contextually dependent .</sentence>
				<definiendum id="0">Sdep</definiendum>
				<definiens id="0">a set that consists of paraphrasing pairs that are judged as having the same topic</definiens>
			</definition>
			<definition id="9">
				<sentence>Table 7 shows that in spite of the difference in programing language , pLSI is faster than LDA in practice .</sentence>
				<definiendum id="0">pLSI</definiendum>
				<definiens id="0">in spite of the difference in programing language</definiens>
			</definition>
			<definition id="10">
				<sentence>The smallest error rate is the following formula : |Dindep|+|Sdep|−C # of judged pairs−C , ( 8 ) where C denotes the correction value that corresponds to the number of paraphrasing pairs judged incorrectly with only contextual information .</sentence>
				<definiendum id="0">smallest error rate</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the correction value that corresponds to the number of paraphrasing pairs judged incorrectly with only contextual information</definiens>
			</definition>
			<definition id="11">
				<sentence>However , they have slightly different characteristics : LDA is robust against noisy sentences with long context , while pLSI is robust against information shortage due to short context .</sentence>
				<definiendum id="0">LDA</definiendum>
				<definiens id="0">robust against information shortage due to short context</definiens>
			</definition>
</paper>

		<paper id="2011">
			<definition id="0">
				<sentence>The following equation represents this approach : ( 1 ) ) ... .. , | ( maxarg ) | ( maxarg 21 n c c synsynsyncP wcP ≅ where c is a category ( opinion-bearing or nonopinion-bearing ) , w is the target word , and syn n is the synonyms or antonyms of the given word by WordNet .</sentence>
				<definiendum id="0">c</definiendum>
				<definiendum id="1">w</definiendum>
				<definiendum id="2">syn n</definiendum>
				<definiens id="0">the synonyms or antonyms of the given word by WordNet</definiens>
			</definition>
			<definition id="1">
				<sentence>To compute equation ( 1 ) , we built a classification model , equation ( 2 ) : ( 2 ) ) | ( ) ( maxarg ) | ( ) ( maxarg ) | ( ) ( maxarg ) | ( maxarg 1 ) ) ( , ( ... 3 2 1 ∏ = = = = m k wsynsetfcount k c n c cc k cfPcP csynsynsynsynPcP cwPcPwcP where k f is the k th feature of category c which is also a member of the synonym set of the target word w , and count ( f k , synset ( w ) ) means the total number of occurrences of f k in the synonym set of w. The motivation for this model is document classification .</sentence>
				<definiendum id="0">count</definiendum>
				<definiendum id="1">synset</definiendum>
				<definiens id="0">the k th feature of category c which is also a member of the synonym set of the target word w</definiens>
			</definition>
			<definition id="2">
				<sentence>Determining λ and performance for various models on gold standard data [ λ : cutoff parameter , R : recall , P : precision , F : F-score , A : accuracy ] Development Test set A Development Test set B Model1 Model2 Model1 Model2 λ R P F A R P F A R P F A R P F A 64 Table 4 .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">gold standard data [ λ : cutoff parameter</definiens>
				<definiens id="1">F-score , A : accuracy ] Development Test set A Development Test set B Model1 Model2 Model1 Model2 λ R P F A R P F A R P F A R P F A 64 Table 4</definiens>
			</definition>
			<definition id="3">
				<sentence>Introduction to WordNet : An On-Line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="4">
				<sentence>The New Rhetoric : A Theory of Practical Reasoning .</sentence>
				<definiendum id="0">New Rhetoric</definiendum>
			</definition>
</paper>

		<paper id="3001">
			<definition id="0">
				<sentence>From Table 1 , we can find 221 error tokens in all error instances ( EIs ) after removing the 26 redundant ones in PK test data ( 17194 tokens ) .</sentence>
				<definiendum id="0">EIs</definiendum>
				<definiens id="0">after removing the 26 redundant ones in PK test data ( 17194 tokens )</definiens>
			</definition>
</paper>

		<paper id="3011">
</paper>

		<paper id="3017">
			<definition id="0">
				<sentence>The CityU data was segmented using the LIVAC corpus standard , and the MSR data to Microsoft 's internal standard .</sentence>
				<definiendum id="0">MSR</definiendum>
				<definiens id="0">data to Microsoft 's internal standard</definiens>
			</definition>
			<definition id="1">
				<sentence>Sites participating in an open test were required to describe this external data in their system description .</sentence>
				<definiendum id="0">Sites</definiendum>
				<definiens id="0">participating in an open test were required to describe this external data in their system description</definiens>
			</definition>
			<definition id="2">
				<sentence>g0002 ( p Participant Run ID Word Count R Cr P Cp F OOV Roov Riv 14 40936 0.941 ±0.00233 0.946 ±0.00223 0.943 0.074 0.698 0.961 15 a 40936 0.942 ±0.00231 0.941 ±0.00233 0.942 0.074 0.629 0.967 15 b 40936 0.937 ±0.00240 0.946 ±0.00223 0.941 0.074 0.736 0.953 27 40936 0.949 ±0.00217 0.931 ±0.00251 0.94 0.074 0.561 0.98 7 40936 0.944 ±0.00227 0.933 ±0.00247 0.939 0.074 0.626 0.969 12 40936 0.931 ±0.00251 0.941 ±0.00233 0.936 0.074 0.657 0.953 29 d 40936 0.937 ±0.00240 0.922 ±0.00265 0.929 0.074 0.698 0.956 15 c 40936 0.915 ±0.00276 0.94 ±0.00235 0.928 0.074 0.598 0.94 29 a 40936 0.938 ±0.00238 0.915 ±0.00276 0.927 0.074 0.658 0.961 29 b 40936 0.936 ±0.00242 0.913 ±0.00279 0.925 0.074 0.656 0.959 21 40936 0.917 ±0.00273 0.925 ±0.00260 0.921 0.074 0.539 0.948 29 c 40936 0.925 ±0.00260 0.896 ±0.00302 0.91 0.074 0.639 0.948 4 40936 0.934 ±0.00245 0.865 ±0.00338 0.898 0.074 0.248 0.989 5 40936 0.932 ±0.00249 0.862 ±0.00341 0.895 0.074 0.215 0.989 3 40936 0.814 ±0.00385 0.711 ±0.00448 0.759 0.074 0.227 0.86 Table 7 : City University of Hong Kong — Closed ( italics indicate performance below baseline ) Participant Run ID Word Count R Cr P Cp F OOV Roov Riv 19 40936 0.967 ±0.00177 0.956 ±0.00203 0.962 0.074 0.806 0.98 16 40936 0.958 ±0.00198 0.95 ±0.00215 0.954 0.074 0.775 0.973 27 40936 0.952 ±0.00211 0.937 ±0.00240 0.945 0.074 0.608 0.98 7 40936 0.944 ±0.00227 0.938 ±0.00238 0.941 0.074 0.667 0.966 12 40936 0.933 ±0.00247 0.94 ±0.00235 0.936 0.074 0.653 0.955 4 40936 0.946 ±0.00223 0.898 ±0.00299 0.922 0.074 0.417 0.989 5 40936 0.94 ±0.00235 0.901 ±0.00295 0.92 0.074 0.41 0.982 3 40936 0.014 ±0.00116 0.013 ±0.00112 0.013 0.074 0.029 0.012 Table 8 : City University of Hong Kong — Open ( italics indicate performance below baseline ) 128 ( 1 p ) /n ) where n is the number of words .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">0.944 ±0.00227 0.938 ±0.00238 0.941 0.074 0.667 0.966 12 40936 0.933 ±0.00247 0.94 ±0.00235 0.936 0.074 0.653 0.955 4 40936 0.946 ±0.00223 0.898 ±0.00299 0.922 0.074 0.417 0.989 5 40936 0.94 ±0.00235 0.901 ±0.00295 0.92 0.074 0.41 0.982 3 40936 0.014 ±0.00116 0.013 ±0.00112 0.013 0.074 0.029 0.012 Table 8 : City University of Hong Kong — Open ( italics indicate performance below baseline ) 128 ( 1 p ) /n ) where</definiens>
				<definiens id="1">the number of words</definiens>
			</definition>
</paper>

		<paper id="3026">
			<definition id="0">
				<sentence>Actually , known word segmentation is a process of disambiguation .</sentence>
				<definiendum id="0">word segmentation</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the Academia Sinica ( AS ) open test and the Peking University ( PKU ) open test , our system is trained respectively using the Sinica Corpus ( 3.0 ) and the PFR Corpus .</sentence>
				<definiendum id="0">Academia Sinica ( AS</definiendum>
				<definiens id="0">) open test and the Peking University ( PKU ) open test , our system is trained respectively using the Sinica Corpus ( 3.0 ) and the PFR Corpus</definiens>
			</definition>
</paper>

		<paper id="3035">
			<definition id="0">
				<sentence>The basic segmentation is a process of labeling each hanzi with a tag given the features derived from its surrounding context .</sentence>
				<definiendum id="0">basic segmentation</definiendum>
				<definiens id="0">a process of labeling each hanzi with a tag given the features derived from its surrounding context</definiens>
			</definition>
			<definition id="1">
				<sentence>The in-word probability of a character is a probability that the character occurs as a part of a word of two or more characters .</sentence>
				<definiendum id="0">in-word probability of a character</definiendum>
				<definiens id="0">a probability that the character occurs as a part of a word of two or more characters</definiens>
			</definition>
			<definition id="2">
				<sentence>PKU ( open ) PKU ( closed ) MSR ( open ) MSR ( closed ) Precision 0.970 0.950 0.971 0.956 Recall 0.964 0.941 0.959 0.959 F 0.967 0.946 0.965 0.957 OOV 0.058 0.058 0.026 0.026 Recall on OOV 0.864 0.813 0.785 0.496 Table 1 : Official Bakeoff Outcome It’s a pity that we make a careless mistake ( a program bug ) which led to 752 left quotation marks concatenated to the words following it in the closed and open tracks on Microsoft research corpus .</sentence>
				<definiendum id="0">PKU</definiendum>
				<definiens id="0">a program bug ) which led to 752 left quotation marks concatenated to the words following it in the closed and open tracks on Microsoft research corpus</definiens>
			</definition>
</paper>

		<paper id="2010">
			<definition id="0">
				<sentence>An illustration of a SWP-sentence for the Chinese syllables “shu3 dou1 shu3 bu4 qing1 ( 數 [ count ] 都 [ always ] 數不清 [ innumerable ] ) ” Step # Results Step.1 shu3 dou1 shu3 bu4 qing1 ( 數 都 數 不 清 ) Step.2 The specific word-pairs found : 數 ( shu3 ) -都 ( dou1 ) /BEGIN pair 都 ( dou1 ) -數不清 ( shu3 ) /END pair Step.3 The selected specific word-pairs : 數 ( shu3 ) -都 ( dou1 ) /BEGIN pair 都 ( dou1 ) -數不清 ( shu3 ) /END pair Step.4 SWP-sentence : 數 都 shu3 bu4 qing1 ( “shu3 dou1” replace with the BEGIN pair of Step 3 ) 數 都 數 不 清 ( “shu3 bu4 qing1” replace with the END pair of Step 3 ) The steps of auto-generating common word-pair ( AUTO-CWP ) for a given Chinese sentence : Step 1 .</sentence>
				<definiendum id="0">illustration of a SWP-sentence</definiendum>
				<definiens id="0">] ) ” Step # Results Step.1 shu3 dou1 shu3 bu4 qing1 ( 數 都 數 不 清 ) Step.2 The specific word-pairs found : 數 ( shu3 ) -都 ( dou1 ) /BEGIN pair 都 ( dou1 ) -數不清</definiens>
			</definition>
			<definition id="1">
				<sentence>UDN , On-Line United Daily News , “http : //udnnews.com/NEWS/” Appendix A. Input syllables “ji2fu4qi2min2zu2te4se4” of the Chinese sentence “極富 ( abundance ) 其 ( it ) 民族 ( folk ) 特色 ( characteristic ) ” Tonal STW results Methods STW results 民族/特色 ( 13 ) ( Key WP ) 極富/特色 ( 11 ) ( Co-occurrence WP ) WP-sentence 極富qi2民族特色 MSIME 及復其民族特色 MSIME+WP 極富其民族特色 BiGram 極富期民族特色 BiGram+WP 極富期民族特色 Toneless STW results Methods STW results 民族/特色 ( 13 ) ( Key WP ) 極富/特色 ( 11 ) ( Co-occurrence WP ) WP-sentence 極富qi民族特色 MSIME 及夫妻民族特色 MSIME+WP 極富妻民族特色 BiGram 及夫妻民族特色 BiGram+WP 極富妻民族特色 60</sentence>
				<definiendum id="0">UDN</definiendum>
			</definition>
</paper>

		<paper id="2022">
			<definition id="0">
				<sentence>The rst sub-problem is to build a chunker that takes a text in which words are tagged with part of speech ( POS ) tags as its input , and marks the chunk boundaries in its output .</sentence>
				<definiendum id="0">rst sub-problem</definiendum>
				<definiendum id="1">POS</definiendum>
				<definiens id="0">to build a chunker that takes a text in which words are tagged with part of speech (</definiens>
			</definition>
			<definition id="1">
				<sentence>Given a sequence of words W n = ( w1 ; w2 ; ; wn ) ; wi 2 W , where W is the word set and the sequence of corresponding part of speech ( POS ) tags T n = ( t1 ; t2 ; ; tn ) ; ti 2 T where T is the POS tag set , the aim is to create most probable chunks of the sequence W n. The chunks are marked with chunk tag sequence Cn = ( c1 ; c2 ; ; cn ) where ci stands for the chunk tag corresponding to each word wi , ci 2 C. C here is the chunk tag set which may consist of symbols such as STRT and CNT for each word marking it as the start or continuation of a chunk .</sentence>
				<definiendum id="0">W</definiendum>
				<definiendum id="1">T</definiendum>
				<definiendum id="2">ci</definiendum>
				<definiens id="0">the word set and the sequence of corresponding part of speech ( POS ) tags T n = ( t1 ; t2 ; ; tn ) ; ti 2 T where</definiens>
				<definiens id="1">the chunk tag set which may consist of symbols such as STRT and CNT for each word marking it as the start or continuation of a chunk</definiens>
			</definition>
			<definition id="2">
				<sentence>STRT STPg where tags stand for : STRT : A chunk starts at this token CNT : This token lies in the middle of a chunk STP : This token lies at the end of a chunk STRT STP : This token lies in a chunk of its own We illustrate the three tag schemes using part of the earlier example sentence .</sentence>
				<definiendum id="0">tags</definiendum>
				<definiendum id="1">STP</definiendum>
				<definiens id="0">This token lies in the middle of a chunk</definiens>
			</definition>
			<definition id="3">
				<sentence>It was found that seven groups of words PRP , QF ( quantiers ) , QW , RB ( adverbs ) , VRB , VAUX ( auxillary verbs ) and RP ( particles ) performed better with a combination of word and POS tag as the token .</sentence>
				<definiendum id="0">RB</definiendum>
				<definiendum id="1">RP</definiendum>
				<definiendum id="2">POS tag</definiendum>
				<definiens id="0">particles ) performed better with a combination of word and</definiens>
			</definition>
</paper>

		<paper id="4005">
			<definition id="0">
				<sentence>Type : the genre of the content of the Yami language sound track .</sentence>
				<definiendum id="0">Type</definiendum>
				<definiens id="0">the genre of the content of the Yami language sound track</definiens>
			</definition>
			<definition id="1">
				<sentence>Format : the digital data type of the Yami language sound track .</sentence>
				<definiendum id="0">Format</definiendum>
				<definiens id="0">the digital data type of the Yami language sound track</definiens>
			</definition>
			<definition id="2">
				<sentence>( 3 ) Build a special annotated database and use the Yami language to annotate the image data .</sentence>
				<definiendum id="0">Build</definiendum>
				<definiens id="0">a special annotated database and use the Yami language to annotate the image data</definiens>
			</definition>
			<definition id="3">
				<sentence>e-Learning consists of self-access , reference sources , discussion forum , and virtual learning classrooms .</sentence>
				<definiendum id="0">e-Learning</definiendum>
				<definiens id="0">consists of self-access , reference sources , discussion forum , and virtual learning classrooms</definiens>
			</definition>
</paper>

		<paper id="2016">
			<definition id="0">
				<sentence>The speech recognition module receives the user’s speech input and generates a sequence of words .</sentence>
				<definiendum id="0">speech recognition module</definiendum>
				<definiens id="0">receives the user’s speech input and generates a sequence of words</definiens>
			</definition>
			<definition id="1">
				<sentence>Scoring Referent identified no yes no no yes Resolve anaphora by case matching no yes yes Figure 3 : Anaphora resolution algorithm SPACE object is designed to behave as a symbolic object in the macro-planning by referring to its unique identifier .</sentence>
				<definiendum id="0">Scoring Referent</definiendum>
				<definiens id="0">identified no yes no no yes Resolve anaphora by case matching no yes yes Figure 3 : Anaphora resolution algorithm SPACE object is designed to behave as a symbolic object in the macro-planning by referring to its unique identifier</definiens>
			</definition>
			<definition id="2">
				<sentence>In step ( B ) , the method matchObjects ( ) returns a list of objects located in the potential field of space # 1 shown in Fig .</sentence>
				<definiendum id="0">method matchObjects ( )</definiendum>
				<definiens id="0">returns a list of objects located in the potential field of space # 1 shown in Fig</definiens>
			</definition>
			<definition id="3">
				<sentence>In step ( C ) , the most plausible object satisfying the type constraint ( BALL ) is selected by the method getFirstMatch ( ) .</sentence>
				<definiendum id="0">BALL</definiendum>
				<definiens id="0">the most plausible object satisfying the type constraint</definiens>
			</definition>
</paper>

		<paper id="3012">
			<definition id="0">
				<sentence>Z � �x ” ( “terrorists burned down the gene laboratory” ) , the influence of contextual word “ � � ” ( “gene” ) should be reduced to work on the target word “� $ ” because “ $ �� $ ” is a collocation whereas “� $ ” and “ � � ” are not collocations even though they do co-occur .</sentence>
				<definiendum id="0">Z � �x ”</definiendum>
				<definiens id="0">“terrorists burned down the gene laboratory” ) , the influence of contextual word “ � � ”</definiens>
			</definition>
			<definition id="1">
				<sentence>The collocation information is a pre-prepared collocation list obtained from a collocation extraction system and verified with syntactic and semantic methods ( [ 21 ] , [ 24 ] ) .</sentence>
				<definiendum id="0">collocation information</definiendum>
				<definiens id="0">a pre-prepared collocation list obtained from a collocation extraction system and verified with syntactic and semantic methods</definiens>
			</definition>
			<definition id="2">
				<sentence>A collocation is a recurrent and conventional fixed expression of words which holds syntactic and semantic relations [ 21 ] .</sentence>
				<definiendum id="0">collocation</definiendum>
			</definition>
			<definition id="3">
				<sentence>We consider all the features in the features set F = Ft ∪Fl = { f1 , f2 , … , fm } as independent , where Ft stands for the topical contextual features set , and Fl stands for the local collocation features set .</sentence>
				<definiendum id="0">Ft</definiendum>
				<definiens id="0">the local collocation features set</definiens>
			</definition>
			<definition id="4">
				<sentence>Average Precision ( 5/6 training , 1/6 test ) of system A on People’s Daily News Amb .</sentence>
				<definiendum id="0">Average Precision</definiendum>
				<definiens id="0">1/6 test ) of system A on People’s Daily News Amb</definiens>
			</definition>
			<definition id="5">
				<sentence>Average Precision ( 5/6 training , 1/6 test ) of system B on People’s Daily News Amb .</sentence>
				<definiendum id="0">Average Precision</definiendum>
				<definiens id="0">1/6 test ) of system B on People’s Daily News Amb</definiens>
			</definition>
</paper>

		<paper id="6010">
			<definition id="0">
				<sentence>Treebanks consist of language samples annotated with structural information centrally , the grammatical structure of the samples , though some resources include categories of information other than grammar sensu stricto .</sentence>
				<definiendum id="0">Treebanks</definiendum>
				<definiens id="0">consist of language samples annotated with structural information centrally , the grammatical structure of the samples</definiens>
			</definition>
			<definition id="1">
				<sentence>For German , the first initiative in the field of treebanks was the NEGRA Corpus ( cf. ( Skut et al. , 1998 ) ) which contains approximately 20.000 sentences of syntactically interpreted newspaper text .</sentence>
				<definiendum id="0">NEGRA Corpus</definiendum>
				<definiens id="0">contains approximately 20.000 sentences of syntactically interpreted newspaper text</definiens>
			</definition>
			<definition id="2">
				<sentence>TIGER ( cf. ( Brants et al. , 2002 ) ) is the largest and most exhaustively annotated treebank for German .</sentence>
				<definiendum id="0">TIGER</definiendum>
				<definiens id="0">the largest and most exhaustively annotated treebank for German</definiens>
			</definition>
			<definition id="3">
				<sentence>Quantifying Noun Group ( quanNG ) The German quantifying noun group ( quanNG ) is composed of a numeral ( Num ) , a nominal constituent used for quantification ( quanN ) and a nominal constituent denoting the quantified element or substance ( ElemN ) ( cf. figure 1 ) .</sentence>
				<definiendum id="0">quanNG</definiendum>
			</definition>
			<definition id="4">
				<sentence>Thus , quanNG consists of a quantifying constituent ( e.g. , ein Klumpen in example 1 ) and a quantified constituent ( e.g. , Lehm in example 1 ) .</sentence>
				<definiendum id="0">quanNG</definiendum>
				<definiens id="0">consists of a quantifying constituent ( e.g. , ein Klumpen in example 1 ) and a quantified constituent</definiens>
			</definition>
			<definition id="5">
				<sentence>83 CATEGORY EXAMPLES ( 1 ) numeral noun construction Dutzend ( dozen ) , Million ( million ) ( 2 ) quantum noun construction Menge ( number ) , Unmenge ( vast number ) , Unsumme ( amount ) , Vielzahl ( multitude ) ( 3 ) count construction : ( a ) count noun construction : ( i ) numeral classifier construction Stück ( piece ) ( ii ) shape noun construction Tropfen ( drop ) , Laib ( loaf ) , Scheibe ( slice ) ( iii ) container noun construction Glas ( glass ) , Tasse ( cup ) , Kiste ( crate ) ( iv ) singulative construction Halm ( blade ) , Korn ( grain ) ( b ) sort noun construction Sorte ( kind ) , Art ( type ) ( c ) collective noun construction : ( i ) configuration construction Stapel ( stack ) , Haufen ( heap ) ( ii ) group collective construction Herde ( herd ) , Gruppe ( group ) , Paar ( pair ) ( 4 ) measure construction : ( a ) measuring unit construction ( muc ) : ( i ) abstract muc Meter ( meter ) , Grad ( degree ) , Euro ( euro ) ( ii ) concrete muc : container noun construction Glas ( glass ) , Tasse ( cup ) , Kiste ( crate ) action noun construction Schluck ( gulp/mouthful ) , Schritt ( step ) ( iii ) relative muc Prozent ( percent ) Table 1 : Categorization of quanNG with respect to quanN a measure object u that determines the value of a property P ( such as weight or temperature ) .</sentence>
				<definiendum id="0">Gruppe ( group ) , Paar</definiendum>
				<definiendum id="1">muc ) : ( i ) abstract muc Meter</definiendum>
				<definiens id="0">determines the value of a property P ( such as weight or temperature )</definiens>
			</definition>
			<definition id="6">
				<sentence>A scale is a totally ordered set of degrees .</sentence>
				<definiendum id="0">scale</definiendum>
				<definiens id="0">a totally ordered set of degrees</definiens>
			</definition>
</paper>

		<paper id="6011">
			<definition id="0">
				<sentence>The projection of honorifics extends over the vocabulary of verbs , adjectives , and nouns as well as sentence structures , to elevate a person or humble oneself .</sentence>
				<definiendum id="0">projection of honorifics</definiendum>
				<definiens id="0">extends over the vocabulary of verbs , adjectives , and nouns as well as sentence structures</definiens>
			</definition>
			<definition id="1">
				<sentence>Honorifics is a term used to represent words that convey esteem or respect .</sentence>
				<definiendum id="0">Honorifics</definiendum>
				<definiens id="0">a term used to represent words that convey esteem or respect</definiens>
			</definition>
			<definition id="2">
				<sentence>We used Lexeed ( Bond et al. 2004 ) a manually built self-contained lexicon , to extract verbs and verbal nouns with such referential restrictions .</sentence>
				<definiendum id="0">Lexeed</definiendum>
				<definiens id="0">a manually built self-contained lexicon , to extract verbs and verbal nouns with such referential restrictions</definiens>
			</definition>
			<definition id="3">
				<sentence>The notion of polarity is used to denote the three types of value ; a polarity value “+” means a subject honorific form , “-“ denotes a non-subject honorific form , and “bool” is indeterminate .</sentence>
				<definiendum id="0">“bool”</definiendum>
				<definiens id="0">a non-subject honorific form , and</definiens>
			</definition>
</paper>

		<paper id="2019">
</paper>

		<paper id="6003">
			<definition id="0">
				<sentence>In many natural language processing ( NLP ) applications , such as information retrieval , knowledge discovery , example-based machine translation ( EBMT ) and text summarization , can benefit with chunks ( Le et al. , 2003 ; Munoz et al. , 1999 ; Oliver , 2001 ; Zhou and Su , 2003 ) .</sentence>
				<definiendum id="0">NLP</definiendum>
				<definiendum id="1">EBMT</definiendum>
				<definiens id="0">information retrieval , knowledge discovery , example-based machine translation (</definiens>
			</definition>
			<definition id="1">
				<sentence>Following these trends of Chinese chunking and parsing , the goals of this paper are : ( 1 ) Define a Word-Layer Matrix and generate the Bottom-to-Top Mapping ( BTM ) dataset to auto-derive useful patterns and templates with probabilities from Chinese Treebank 21 ( CTB ) as rules for chunking ; ( 2 ) Develop a BTM model with the BTM dataset to identify the chunks ( i.e. phrase boundaries ) for a given segmented and POS-tagged Chinese sentence ; ( 3 ) Show the chunk bracketing performance of the BTM model is high and stable against training corpus size , perfect and actual input ; ( 4 ) Show the BTM model can improve the performance ( F-measure ) of N-gram models on chunk bracketing .</sentence>
				<definiendum id="0">CTB</definiendum>
				<definiens id="0">a BTM model with the BTM dataset to identify the chunks ( i.e. phrase boundaries ) for a given segmented and POS-tagged Chinese sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>A Chinese Treebank ( CTB ) is a segmented , POS-tagged and fully bracketed Chinese corpus with morphological , syntactic , semantic and discourse structures .</sentence>
				<definiendum id="0">Chinese Treebank</definiendum>
				<definiendum id="1">CTB )</definiendum>
				<definiens id="0">a segmented , POS-tagged and fully bracketed Chinese corpus with morphological , syntactic , semantic and discourse structures</definiens>
			</definition>
			<definition id="3">
				<sentence>The CCTB uses Information-based Case Grammar ( ICG ) as the language framework to express both syntactic and semantic descriptions ( Chen and Huang , 1996 ) .</sentence>
				<definiendum id="0">CCTB</definiendum>
				<definiens id="0">uses Information-based Case Grammar</definiens>
			</definition>
			<definition id="4">
				<sentence>The PCTB uses Head-driven Phrase Structure Grammar ( HPSG ) to create Chinese texts with syntactic bracketing ( Xia et al , 2000 ; Xue et al , 2002 ) .</sentence>
				<definiendum id="0">PCTB</definiendum>
				<definiens id="0">uses Head-driven Phrase Structure Grammar ( HPSG ) to create Chinese texts with syntactic bracketing</definiens>
			</definition>
			<definition id="5">
				<sentence>G ( colorful ) �/� ( interesting ) ” ( Note that the content of the nodes between the root and the words is [ Thematic role : Syntactic category ] ) ( 1 ) Generation of BTM dataset from CCTB2.1 : Figure 1 shows the tree structure of CCTB2.1 for the Chinese sentence “5� ( movie ) '' � ( of ) !</sentence>
				<definiendum id="0">G</definiendum>
				<definiens id="0">interesting ) ” ( Note that the content of the nodes between the root and the words is [ Thematic role : Syntactic category ] ) ( 1 ) Generation of BTM dataset from CCTB2.1</definiens>
			</definition>
			<definition id="6">
				<sentence>G ( colorful ) �/� ( interesting ) ” Type Content BL Word pattern &lt; 5�\ '' �\ !</sentence>
				<definiendum id="0">G</definiendum>
			</definition>
			<definition id="7">
				<sentence>The CKIP POS tagging is a hierarchical system .</sentence>
				<definiendum id="0">CKIP POS tagging</definiendum>
				<definiens id="0">a hierarchical system</definiens>
			</definition>
			<definition id="8">
				<sentence>U ( major ) � &gt; &lt; ( agent ) � ( appear ) ” Type Content BL Word pattern &lt; ��\ ?</sentence>
				<definiendum id="0">U</definiendum>
				<definiens id="0">appear ) ” Type Content BL Word pattern &lt; ��\</definiens>
			</definition>
			<definition id="9">
				<sentence>We use BTM ( value1 , value2 , value3 ) to express the function of our BTM model , where value1 is the BTM threshold value , value2 is the POS layer number and value3 is the BTM training size .</sentence>
				<definiendum id="0">value1</definiendum>
				<definiendum id="1">value2</definiendum>
				<definiendum id="2">value3</definiendum>
				<definiens id="0">the BTM threshold value</definiens>
			</definition>
			<definition id="10">
				<sentence>To evaluate the performance of our BTM model , we use recall ( R ) , precision ( P ) , and Fmeasure ( F ) ( Manning and Schuetze , 1999 ) , which are defined as follows : Recall ( R ) = ( # of correctly identified chunk brackets ) / ( # of chunk brackets ) ( 1 ) Precision ( P ) = ( # of correctly identified chunk brackets ) / ( # of identified chunk brackets ) ( 2 ) F-measure ( F ) = ( 2 × recall × precision ) / ( recall + precision ) ( 3 ) In addition , we use coverage ratio ( CR ) to represent the size of matching sentences ( or say , matching set ) of our BTM model .</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">precision</definiendum>
				<definiendum id="2">Fmeasure ( F ) ( Manning</definiendum>
				<definiendum id="3">matching sentences</definiendum>
				<definiens id="0">follows : Recall ( R ) = ( # of correctly identified chunk brackets ) / ( # of chunk brackets ) ( 1 ) Precision ( P ) = ( # of correctly identified chunk brackets ) / ( # of identified chunk brackets</definiens>
			</definition>
			<definition id="11">
				<sentence>SRILM is a freely available collection of C++ libraries , executable programs , and helper scripts designed to allow both production of , and experimentation with , statistical language models for speech recognition and other NLP applications ( Stolcke , 2002 ) .</sentence>
				<definiendum id="0">SRILM</definiendum>
			</definition>
</paper>

		<paper id="2012">
			<definition id="0">
				<sentence>If ‘seong’ is recognized as a conceptual unit by itself in the context , like ‘hyang-chuk ( adaxial ) / seong ( sex ) / bun-yeol+jo-jik ( meris1 In this paper , a conceptual unit is defined as the linguistic unit representing a domain specific concept .</sentence>
				<definiendum id="0">‘hyang-chuk</definiendum>
				<definiens id="0">a conceptual unit by itself in the context</definiens>
				<definiens id="1">the linguistic unit representing a domain specific concept</definiens>
			</definition>
			<definition id="1">
				<sentence>Equation ( 2 ) describes the IBM Model depends on word translation probability t ( f j |e i ) and one English word was aligned to one French word ( 1:1 alignment ) .</sentence>
				<definiendum id="0">IBM Model</definiendum>
				<definiens id="0">depends on word translation probability t</definiens>
			</definition>
			<definition id="2">
				<sentence>IBM Model 3 adopts fertility ( How likely is a source language word to align to k target language words ) as its parameter for 1 : n alignment .</sentence>
				<definiendum id="0">likely</definiendum>
			</definition>
			<definition id="3">
				<sentence>For a given English term E=e 1 , … , e n , composed of n English term constituents and its corresponding Korean term K=k 1 , … , k m , composed of m Korean term constituents , the task is to find alignment set , A= { a 1 , ... . , a t ; a p = ( e i , i+w ( p ) , , k j ( p ) ) } , maximizing probability P ( A|K , E ) , where e i is the i th term constituent of E , k j is the j th term constituent of K , and a p represents the p th alignment relation between English and Korean term constituents .</sentence>
				<definiendum id="0">a p</definiendum>
				<definiens id="0">the p th alignment relation between English and Korean term constituents</definiens>
			</definition>
			<definition id="4">
				<sentence>In equation ( 4 ) , a ( i|j , n , t ) represents position information , which is a binary-valued function and supports the constraint p = a ( e i , i+w ( p ) , k j ( p ) ) is cross-alignment , which is not allowed by constraint 1 , otherwise a ( i|j , n , m , t ) = 1 .</sentence>
				<definiendum id="0">position information</definiendum>
				<definiens id="0">a binary-valued function and supports the constraint p = a ( e i , i+w ( p ) , k j</definiens>
			</definition>
			<definition id="5">
				<sentence>The basic idea underlying the EM algorithm is to iterate through a series of expectation ( E-step ) and maximization ( M-step ) steps where the estimation of the parameters of the model is progressively refined until convergence ( Lopez et al. , 1999 ) .</sentence>
				<definiendum id="0">EM algorithm</definiendum>
				<definiens id="0">to iterate through a series of expectation ( E-step ) and maximization ( M-step ) steps where the</definiens>
			</definition>
			<definition id="6">
				<sentence>Seed data , which contains alignment relations derived from E=e 1 , … , e n and E’s Korean translation K=k 1 , … , k m , where n =1 or m = 1 , was selected among data for term constituent alignment .</sentence>
				<definiendum id="0">Seed data</definiendum>
				<definiens id="0">was selected among data for term constituent alignment</definiens>
			</definition>
			<definition id="7">
				<sentence>With the seed data we can get the initial alignment relation set A ( 0 ) and then the initial parameter θ ( 0 ) is estimated with A ( 0 ) , where A ( k ) represents the alignment relation set and θ ( k ) represents the estimated parameter set derived from the k th iteration .</sentence>
				<definiendum id="0">A ( k )</definiendum>
				<definiens id="0">represents the alignment relation set and θ ( k ) represents the estimated parameter set derived from the k th iteration</definiens>
			</definition>
			<definition id="8">
				<sentence>( ; ( || ) ) ( ; , ( 1 ) ) ( ; | ( , , , kAeCE kAekC kAekp wii wii j t wii j t + + + + + = ( 7 ) ) ) ( ; , ( |||| ) ) ( ; , , ( 1 ) ) ( ; , | ( , , , kAekCET kAekkC kAekkp wii j t wii j t j w wii j t j w + + + ++ + = ( 8 ) where C ( x ) represents frequency of x , |E| represents the number of unique English term constituents in A ( k ) , |T| represents the number of unique POS tags of Korean term constituents in A ( k ) .</sentence>
				<definiendum id="0">|E|</definiendum>
				<definiens id="0">the number of unique English term constituents in A ( k ) , |T| represents the number of unique POS tags of Korean term constituents in A ( k )</definiens>
			</definition>
			<definition id="9">
				<sentence>Characteristics experimental data ( the number of bilingual term pairs ) We compare our model with IBM Model 2 ( IBM-2 ) , and IBM Model 4 ( IBM-4 ) implemented by GIZA++ ( Och et al. , 2003 ) .</sentence>
				<definiendum id="0">Characteristics experimental data</definiendum>
				<definiens id="0">the number of bilingual term pairs</definiens>
			</definition>
			<definition id="10">
				<sentence>We evaluate results with the alignment error rate ( AER ) of Och and Ney ( Och et al. , 2003 ) , which measures agreement at the level of pairs of term constituents .</sentence>
				<definiendum id="0">AER</definiendum>
				<definiens id="0">measures agreement at the level of pairs of term constituents</definiens>
			</definition>
			<definition id="11">
				<sentence>5 |||| ||2 1 GA GA AER + ∩× −= ( 9 ) where A is the set of term constituent pairs aligned by the automatic system , and G is the set aligned in the gold standard .</sentence>
				<definiendum id="0">G</definiendum>
				<definiens id="0">the set of term constituent pairs aligned by the automatic system , and</definiens>
				<definiens id="1">the set aligned in the gold standard</definiens>
			</definition>
</paper>

		<paper id="5005">
</paper>

		<paper id="2037">
			<definition id="0">
				<sentence>Ellipsis is a linguistic phenomenon that people omit a word or phrase not to repeat a same word or phrase in a sentence or a document .</sentence>
				<definiendum id="0">Ellipsis</definiendum>
				<definiens id="0">a linguistic phenomenon that people omit a word or phrase not to repeat a same word or phrase in a sentence or a document</definiens>
			</definition>
			<definition id="1">
				<sentence>Ellipsis is a pervasive phenomenon in natural languages .</sentence>
				<definiendum id="0">Ellipsis</definiendum>
			</definition>
			<definition id="2">
				<sentence>They only try to detect of elliptical verbs using four different machine learning techniques , Transformation-based learning , Maximum entropy modeling , Decision Tree Learning , Memory Based Learning .</sentence>
				<definiendum id="0">Transformation-based</definiendum>
			</definition>
			<definition id="3">
				<sentence>Ratnaparkhi ( Ratnaparkhi 98 ) makes a strong argument for the use of maximum entropy modes , and demonstrates their use in a variety of NLP tasks .</sentence>
				<definiendum id="0">Ratnaparkhi</definiendum>
				<definiendum id="1">maximum entropy</definiendum>
			</definition>
			<definition id="4">
				<sentence>Each feature consists of subfeatures : Lexical feature ; Verb_lex : lexeme of a target verb Verb_e_lex : lexeme of a suffix attatched to a target verb POS feature ; Verb_pos : pos of a target verb Verb_e_pos : pos of a suffix attatch to a target verb Sense feature ; 1 Downloadable from http : //homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.ht ml 217 Ti_res_code : where sense of an entry word is included in acceptable sense class Verb_cf_subj , obj : whether a sense of entry word is included in caseframe of a targe verb Ti_sense : sense class of entry word Syntactic feature ; Tree_posi : position of parse tree Rel_type : relation type between verbs in a sentence Sen_subj , sen_obj : existence of subject or object Hybrid feature ; Pair = ( sense class of entry word , verb ) Table 5 shows an example of features that we use for finding an elided entry word .</sentence>
				<definiendum id="0">Verb_pos</definiendum>
				<definiens id="0">consists of subfeatures : Lexical feature ; Verb_lex : lexeme of a target verb Verb_e_lex : lexeme of a suffix attatched to a target verb POS feature ;</definiens>
				<definiens id="1">whether a sense of entry word is included in caseframe of a targe verb Ti_sense : sense class of entry word Syntactic feature ; Tree_posi : position of parse tree Rel_type : relation type between verbs in a sentence Sen_subj , sen_obj : existence of subject or object Hybrid feature ; Pair = ( sense class of entry word</definiens>
			</definition>
			<definition id="5">
				<sentence>The training set consists of 2895 sentences : 916 sentences for restoring an entry word as a subject , 232 sentences for restoring an entry word as an object , 1756 sentences for not restoring any .</sentence>
				<definiendum id="0">training set</definiendum>
				<definiens id="0">consists of 2895 sentences : 916 sentences for restoring an entry word as a subject , 232 sentences for restoring an entry word as an object , 1756 sentences for not restoring any</definiens>
			</definition>
			<definition id="6">
				<sentence>Our proposed approach ( ASC_CF_ME ) gives the best results among all experiments , with an F-measure of 68.1 % , followed closely by ASC_ME .</sentence>
				<definiendum id="0">ASC_CF_ME )</definiendum>
				<definiens id="0">gives the best results among all experiments , with an F-measure of 68.1 % , followed closely by ASC_ME</definiens>
			</definition>
</paper>

		<paper id="3005">
			<definition id="0">
				<sentence>Chinese Treebank 5.0 ( CTB ) contains 500K words of newspaper and magazine articles annotated with segmentation , part-of-speech , and syntactic constituency information .</sentence>
				<definiendum id="0">CTB</definiendum>
				<definiens id="0">contains 500K words of newspaper and magazine articles annotated with segmentation , part-of-speech , and syntactic constituency information</definiens>
			</definition>
			<definition id="1">
				<sentence>proper nouns , NN ( noun ) and NNS ( noun plural ) as other nouns , and V* as verbs in WSJ .</sentence>
				<definiendum id="0">NN</definiendum>
				<definiens id="0">other nouns , and V* as verbs in WSJ</definiens>
			</definition>
			<definition id="2">
				<sentence>We treat NE ( Eigennamen ) as proper nouns , NN ( Normales Nomen ) as other nouns , and V* as verbs in NEGRA .</sentence>
				<definiendum id="0">NN</definiendum>
				<definiens id="0">other nouns , and V* as verbs in NEGRA</definiens>
			</definition>
			<definition id="3">
				<sentence>Chinese prefixes include items such as gui ( “noble” ) in guixing ( “your name” ) , bu ( “not” ) in budaode ( “immoral” ) , and lao ( “senior” ) in laohu ( “tiger” ) and laoshu ( “mouse” ) .</sentence>
				<definiendum id="0">lao</definiendum>
				<definiens id="0">items such as gui ( “noble” ) in guixing ( “your name” ) , bu ( “not” ) in budaode ( “immoral” )</definiens>
			</definition>
			<definition id="4">
				<sentence>For example the Academic Sinica Balanced Corpus11 contains POS-tagged data from a different variety ( Taiwanese Mandarin ) .</sentence>
				<definiendum id="0">Academic Sinica Balanced Corpus11</definiendum>
			</definition>
			<definition id="5">
				<sentence>TnT : a statistical part-ofspeech tagger .</sentence>
				<definiendum id="0">TnT</definiendum>
				<definiens id="0">a statistical part-ofspeech tagger</definiens>
			</definition>
</paper>

		<paper id="2041">
			<definition id="0">
				<sentence>The labeled precision ( LP ) indicates the ratio of correct candidate constituents from candidate constituents generated by the parser , and the labeled recall ( LR ) indicates the ratio of correct candidate constituents from constituents in the treebank ( Goodman , 1996 ) .</sentence>
				<definiendum id="0">LP</definiendum>
				<definiens id="0">the ratio of correct candidate constituents from candidate constituents generated by the parser</definiens>
			</definition>
			<definition id="1">
				<sentence>In this experiment , we compare the manual effort of the four methods : the manual tree annotation tool ( only human ) , the tree annotation tool using the parser ( no segmentation ) , the tree annotation tool using the parser with the clause-based sentence segmentation ( clause-based segmentation ) , and the tree annotation tool using the parser with the length-based sentence segmentation ( lengthbased segmentation ) where the segment length is 9 words .</sentence>
				<definiendum id="0">segment length</definiendum>
				<definiens id="0">the manual tree annotation tool ( only human ) , the tree annotation tool using the parser ( no segmentation ) , the tree annotation tool using the parser with the clause-based sentence segmentation ( clause-based segmentation ) , and the tree annotation tool using the parser with the length-based sentence segmentation ( lengthbased segmentation ) where the</definiens>
			</definition>
</paper>

		<paper id="2035">
			<definition id="0">
				<sentence>Wide-coverage grammars representing deep linguistic analysis exist in several frameworks , including Head-Driven Phrase Structure Grammar ( HPSG ) , Lexical-Functional Grammar , and Lexicalized Tree Adjoining Grammar .</sentence>
				<definiendum id="0">Wide-coverage grammars</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Grammar Matrix is an attempt to distill the wisdom of existing grammars and document it in a form that can be used as the basis for new grammars .</sentence>
				<definiendum id="0">Grammar Matrix</definiendum>
				<definiens id="0">an attempt to distill the wisdom of existing grammars and document it in a form that can be used as the basis for new grammars</definiens>
			</definition>
			<definition id="2">
				<sentence>The original Grammar Matrix consisted of types defining the basic feature geometry , types associated with Minimal Recursion Semantics ( e.g. , ( Copestake et al. , 2001 ) ) , types for lex203 ical and syntactic rules , and configuration files for the LKB grammar development environment ( Copestake , 2002 ) and the PET system ( Callmeier , 2000 ) .</sentence>
				<definiendum id="0">original Grammar Matrix</definiendum>
				<definiens id="0">Copestake et al. , 2001 ) ) , types for lex203 ical and syntactic rules , and configuration files for the LKB grammar development environment</definiens>
			</definition>
			<definition id="3">
				<sentence>Inversion of the subject and the main verb is implemented with a lexical rule which relocates the subject ( the value of SUBJ in the valence specifications ) to be the first on the COMPS list , and further assigns a positive value for an additional feature INV ( inverted ) on verbs .</sentence>
				<definiendum id="0">further</definiendum>
			</definition>
			<definition id="4">
				<sentence>The grammatical and ungrammatical examples in each test suite use a small , artificial lexicon , and reflect the typological properties of each language along the dimensions of basic word order , sentential negation , and yes-no questions ( Table 1 ) .</sentence>
				<definiendum id="0">yes-no questions</definiendum>
				<definiens id="0">The grammatical and ungrammatical examples in each test suite use a small , artificial lexicon , and reflect the typological properties of each language along the dimensions of basic word order , sentential negation , and</definiens>
			</definition>
</paper>

		<paper id="7005">
</paper>

		<paper id="6005">
			<definition id="0">
				<sentence>NExT is a well-known tool in Japan for rule-based named entity recognition .</sentence>
				<definiendum id="0">NExT</definiendum>
				<definiens id="0">a well-known tool in Japan for rule-based named entity recognition</definiens>
			</definition>
			<definition id="1">
				<sentence>“�qb� ( jiritsu-suru ) ” means “standing walk” if it is narrated in a conversation among nurses , but it means “to earn one’s living by oneself” in general , as when it is narrated in a conversation between a nurse and a patient’s family .</sentence>
				<definiendum id="0">“�qb� ( jiritsu-suru ) ”</definiendum>
				<definiens id="0">means “standing walk” if it is narrated in a conversation among nurses , but it means “to earn one’s living by oneself” in general , as when it is narrated in a conversation between a nurse and a patient’s family</definiens>
			</definition>
			<definition id="2">
				<sentence>• abbreviated expressions – “���an�”ymeans ampule – “���miri ) ” means milliliter or milligram – “ �y ( bun-ni ) ” means half or two times – “����� ( nobo-aaru ) ” means Novolin R , which is a medication for diabetes These types of expressions seem to be used for quick communication .</sentence>
				<definiendum id="0">• abbreviated expressions –</definiendum>
				<definiens id="0">“���an�”ymeans ampule – “���miri ) ” means milliliter or milligram – “ �y ( bun-ni ) ” means half or two times – “����� ( nobo-aaru ) ” means Novolin R , which is a medication for diabetes These types of expressions seem to be used for quick communication</definiens>
			</definition>
</paper>

		<paper id="2025">
			<definition id="0">
				<sentence>SUB-BNC is a sub-corpus of BNC ( British National Corpus ) .</sentence>
				<definiendum id="0">SUB-BNC</definiendum>
			</definition>
			<definition id="1">
				<sentence>R represents discourse relation of the embedding structure .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">represents discourse relation of the embedding structure</definiens>
			</definition>
			<definition id="2">
				<sentence>Bs represents the structure of the span containing the relation signaled by because .</sentence>
				<definiendum id="0">Bs</definiendum>
				<definiens id="0">the structure of the span containing the relation signaled by because</definiens>
			</definition>
			<definition id="3">
				<sentence>Table 2 : Experiment results using feature R in Experiment Set 1 147 Nt St Nv Sv Ng Sg Ns Ss R C N-S P Bs Os Result 1 x x x x x x x x 29.2 4.9 2 x x x x x x 27.6 5.2 3 x x x x x x 30.8 4.2 4 x x x x 27.3 3.0 Table 3 : Feature sets and 95 % -confidence intervals for the error rates ( % ) of classification models in Experiment Set 2 Nt St Nv Sv Ng Sg Ns Ss R C N-S P Bs Os Result 1 x x x x x x x x x x x x x x 23.5 2.5 2 x x x x x 31.7 2.6 3 x x x x x x x x x 33.3 3.3 4 x x x x x x x x x x 26.9 3.0 Table 4 : Feature sets and 95 % -confidence intervals for the error rates ( % ) of classification models in Experiment Set 3 Experiment Set 2 had four subsets .</sentence>
				<definiendum id="0">x x x x x x x</definiendum>
				<definiens id="0">Nv Sv Ng Sg Ns Ss R C N-S P Bs Os Result 1 x x x x x x x x x x x x x x 23.5 2.5 2 x x x x x 31.7 2.6 3 x</definiens>
			</definition>
</paper>

		<paper id="3024">
			<definition id="0">
				<sentence>The system consists of a base segmentation algorithm and the refining procedures for the undecided character sequences .</sentence>
				<definiendum id="0">system</definiendum>
			</definition>
			<definition id="1">
				<sentence>For example , XY consists of the frequencies of “0X0Y0” , “0X0Y1” , “0X1Y0” , “0X1Y1” , “1X0Y0” , “1X0Y1” , “1X1Y0” , and “1X1Y1” .</sentence>
				<definiendum id="0">XY</definiendum>
			</definition>
			<definition id="2">
				<sentence>T 3 T ‘0’ is a non-space tag and ‘1’ is a space tag .</sentence>
				<definiendum id="0">‘1’</definiendum>
				<definiens id="0">a non-space tag and</definiens>
				<definiens id="1">a space tag</definiens>
			</definition>
</paper>

		<paper id="2004">
			<definition id="0">
				<sentence>Unlike other graph ranking algorithms , PageRank integrates the impact of both incoming and outgoing links into one single model , and therefore it produces only one set of scores : PR ( Vi ) = ( 1¡d ) +d⁄ X Vj2In ( Vi ) PR ( Vj ) jOut ( Vj ) j ( 1 ) where d is a parameter set between 0 and 1 .</sentence>
				<definiendum id="0">PageRank</definiendum>
				<definiens id="0">integrates the impact of both incoming and outgoing links into one single model , and therefore it produces only one set of scores</definiens>
				<definiens id="1">a parameter set between 0 and 1</definiens>
			</definition>
			<definition id="1">
				<sentence>HITS ( Hyperlinked Induced Topic Search ) ( Kleinberg , 1999 ) is an iterative algorithm that was designed for ranking Web pages according to their degree of “authority” .</sentence>
				<definiendum id="0">HITS</definiendum>
				<definiens id="0">an iterative algorithm that was designed for ranking Web pages according to their degree of “authority”</definiens>
			</definition>
</paper>

		<paper id="6002">
			<definition id="0">
				<sentence>In the task , a Japanese word is first translated into an English word or phrase , E. E is one of the lexical units that evoked a particular semantic frame , F , in the BFN database .</sentence>
				<definiendum id="0">E. E</definiendum>
				<definiens id="0">one of the lexical units that evoked a particular semantic frame , F , in the BFN database</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus far , BFN has produced “a lexical database that currently contains more than 8,900 lexical units , more than 6,100 of which are fully annotated , in more than 625 semantic frames , exemplified in more than 135,000 annotated sentences” ( cited from the FrameNet web page ) .</sentence>
				<definiendum id="0">BFN</definiendum>
				<definiens id="0">has produced “a lexical database that currently contains more than 8,900 lexical units , more than 6,100 of which are fully annotated , in more than 625 semantic frames , exemplified in more than 135,000 annotated sentences” ( cited from the FrameNet web page )</definiens>
			</definition>
			<definition id="2">
				<sentence>12 Based on Frame Semantics ( Fillmore , 1982 ) , BFN posits that a semantic frame is an organization of “semantic roles , ” which BFN terms as “Frame Elements” ( FEs ) .</sentence>
				<definiendum id="0">BFN</definiendum>
				<definiens id="0">posits that a semantic frame is an organization of “semantic roles , ” which BFN terms as “Frame Elements” ( FEs )</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , in Jack ordered a hamburger at McDonald’s , hamburger is a noun that evokes the 〈Cooking creation〉 frame .</sentence>
				<definiendum id="0">hamburger</definiendum>
				<definiens id="0">a noun that evokes the 〈Cooking creation〉 frame</definiens>
			</definition>
			<definition id="4">
				<sentence>14 body part itai ( body ) , soshiki ( organization ) plant dansei ( man ) , josei ( woman ) , soshiki ( tissue ) space genba ( field ) , chiiki ( region ) , mokuteki ( purpose ) , hokubu ( northern area ) , shinai ( city center ) amount gruupu ( group ) relation jijou ( circumstances ) , keesu ( case ) , jitai ( matter ) , jiken ( incident ) , ryakushiki ( informality ) , kankei ( relationship ) , mokuteki ( purpose ) , genkou ( current ) , . . . activity jisatsu ( suicide ) , satsugai ( slaying ) , shougai ( injury ) , juushou ( serious injuries ) , ishiki ( consciousness ) , utagai ( doubt ) , yougi ( suspicion ) , sousa ( investigation ) , sousaku ( search ) , shirabe ( investigation ) , . . . Based on the generic semantic groupings produced by msort , we classified nouns into subclasses by intution , so that they corresponded to the FEs of the BFN frames in the following way : Recall that a semantic frame is a collection of semantic roles , or FEs .</sentence>
				<definiendum id="0">mokuteki</definiendum>
				<definiens id="0">serious injuries ) , ishiki ( consciousness ) , utagai ( doubt ) , yougi ( suspicion ) , sousa ( investigation ) , sousaku ( search ) , shirabe ( investigation ) , . . . Based on the generic semantic groupings produced by msort , we classified nouns into subclasses by intution , so that they corresponded to the FEs of the BFN frames in the following way : Recall that a semantic frame is a collection of semantic roles , or FEs</definiens>
			</definition>
			<definition id="5">
				<sentence>When the procedure was applied to 〈Attack〉 , 〈Cause harm〉 and 〈Cause impact〉 , the following Japanese LUs for their major FEs were specified : 〈Assailant〉 : dansei ( man ) , goutou ( burglary/burglar , robbery/robber ) , heishi ( soldier ) , hikoku ( accused person ) , . . . 〈Victim〉 : danshi ( boy ) , josei ( woman ) , fujo ( girls and women ) , joshi ( girl ) , danji ( young boy ) , . . . 〈Place〉 : genba ( field ) , chiiki ( region ) , hokubu ( northern part ) , shinai ( city center ) 〈Weapon〉 : naifu ( knife ) , shoujuu ( rifle ) , tanjuu ( pistol ) 〈Body part〉 : senaka ( back ) 〈Impactee〉 : doru ( dollar ) , shijou ( market ) , ginkou ( bank ) , shokoku ( some countries ) 〈Impactor〉 : saigai ( disaster ) , jishin ( earthquake ) , fukyou ( depression ) , dageki ( damage ) To evaluate our results , we compared them with other Japanese resources and methods for analysis , i.e. , IPAL ( IPA , 1987 ) and Nihongo Goi Taikei ( a Japanese lexicon ) ( hereafter called Goi Taikei ) ( Ikehara et al. , 1997 ) , which are widely used lexical resources , and semantic frame analysis by FOCAL ( Nakamoto et al. , to appear ; Kuroda et al. , 2004 ) , which is a recent framework being developed with the aim of providing BFN-style semantic annotation and analysis for Japanese independent of the Japanese FrameNet ( Ohara et al. , 2003 ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">a Japanese lexicon ) ( hereafter called Goi Taikei ) ( Ikehara et al. , 1997 ) , which are widely used lexical resources , and semantic frame analysis</definiens>
				<definiens id="1">a recent framework being developed with the aim of providing BFN-style semantic annotation and analysis</definiens>
			</definition>
			<definition id="6">
				<sentence>FOCAL is a theoretical framework for semantic analysis and annotation .</sentence>
				<definiendum id="0">FOCAL</definiendum>
			</definition>
			<definition id="7">
				<sentence>In the case of X-ga Y-wo osou , FOCAL recognizes 15 frames in total , listed in Table 4 , specifying their hierarchical organization.14 These frames are identified and classified based on the semantic co-variations between 〈Harm Cause ( r ) ) 〉 X , a special case of 〈Cause ( r ) 〉 , and 〈Harm Experiencer〉 Y , a special case of 〈Experiencer〉 .</sentence>
				<definiendum id="0">FOCAL</definiendum>
				<definiens id="0">recognizes 15 frames in total , listed in Table 4 , specifying their hierarchical organization.14 These frames are identified and classified based on the semantic co-variations between 〈Harm Cause ( r</definiens>
			</definition>
			<definition id="8">
				<sentence>Given R is a set of situation-specific roles { r1 , . . . , rn } , which are called semantic roles in BFN .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">a set of situation-specific roles { r1 , . . . , rn } , which are called semantic roles in BFN</definiens>
			</definition>
			<definition id="9">
				<sentence>For example , F06 , as a subclass of the 〈Attack〉 class event is defined as follows : Definition of F06 : Attack ( R ) = Attack ( Predator ( X ) , Prey ( Y ) ) = Hunt ( Hunter ( X ) , Target ( Y ) , Purpose ( Z ) ) where Z = Eat ( Eater ( X ) , Food ( Y ) , Purpose ( Zprime ) ) ; where Zprime = Satisfy ( r1 ( Z ) , Hunger ) There seems to be no English noun that names r1 .</sentence>
				<definiendum id="0">〈Attack〉 class event</definiendum>
				<definiendum id="1">Zprime = Satisfy ( r1</definiendum>
				<definiens id="0">follows : Definition of F06 : Attack ( R ) = Attack</definiens>
			</definition>
			<definition id="10">
				<sentence>The BFN identifies 3 frames relevant to the semantics of osou , while FOCAL uses a total of 15 frames to determine the range of situations against which people understand the sentences whose main verb is osou .</sentence>
				<definiendum id="0">FOCAL</definiendum>
			</definition>
			<definition id="11">
				<sentence>FrameSQL : A software tool for FrameNet .</sentence>
				<definiendum id="0">FrameSQL</definiendum>
				<definiens id="0">A software tool for FrameNet</definiens>
			</definition>
</paper>

		<paper id="2043">
</paper>

		<paper id="3027">
			<definition id="0">
				<sentence>∈Cc k c cXYkkXZXYP f , ,exp ) ( 1| λ λ Y is the label sequence for the sentence , X is the sequence of unsegmented characters , Z ( X ) is a normalization term , fk is a feature function , and c indexes into characters in the sequence being labeled .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiendum id="1">X</definiendum>
				<definiendum id="2">Z ( X )</definiendum>
				<definiendum id="3">fk</definiendum>
				<definiens id="0">the label sequence for the sentence</definiens>
				<definiens id="1">the sequence of unsegmented characters</definiens>
				<definiens id="2">a normalization term ,</definiens>
			</definition>
			<definition id="1">
				<sentence>Our final system achieved a F-score of 0.947 ( AS ) , 0.943 ( HK ) , Thanks to Kristina Toutanova for her generous help and to Jenny Rose Finkel who developed such a great conditional random field package .</sentence>
				<definiendum id="0">HK</definiendum>
				<definiens id="0">her generous help and to Jenny Rose Finkel who developed such a great conditional random field package</definiens>
			</definition>
</paper>

		<paper id="7009">
</paper>

		<paper id="2018">
			<definition id="0">
				<sentence>Countability is the semantic property that determines whether a noun can occur in singular and plural forms .</sentence>
				<definiendum id="0">Countability</definiendum>
				<definiens id="0">the semantic property that determines whether a noun can occur in singular and plural forms</definiens>
			</definition>
			<definition id="1">
				<sentence>A compound noun is a noun that is made up of two or more words .</sentence>
				<definiendum id="0">compound noun</definiendum>
			</definition>
			<definition id="2">
				<sentence>θ≥ ) ( ) ( Nf Nsf ( 1 ) In ( 1 ) , we use the frequency of a word in the plural form against that in the singular form .</sentence>
				<definiendum id="0">θ≥ ) ( )</definiendum>
				<definiens id="0">the frequency of a word in the plural form against that in the singular form</definiens>
			</definition>
			<definition id="3">
				<sentence>For one experiment with a certain threshold pair , A stands for the number of plural found correctly ; AB stands for the total number of plural only compound nouns in training set ( 80 words ) ; AC stands for the total number of compound nouns found .</sentence>
				<definiendum id="0">AB</definiendum>
				<definiendum id="1">AC</definiendum>
				<definiens id="0">the total number of plural only compound nouns in training set ( 80 words ) ;</definiens>
			</definition>
</paper>

		<paper id="7007">
</paper>

		<paper id="2015">
			<definition id="0">
				<sentence>A parallel corpus is a collection of articles , paragraphs , or sentences in two different languages .</sentence>
				<definiendum id="0">parallel corpus</definiendum>
				<definiens id="0">a collection of articles , paragraphs , or sentences in two different languages</definiens>
			</definition>
			<definition id="1">
				<sentence>( 1 ) Proper nouns When proper nouns did not exist in JapaneseChinese dictionaries , new translations were created and then confirmed using the Chinese web .</sentence>
				<definiendum id="0">Proper</definiendum>
				<definiens id="0">nouns When proper nouns did not exist in JapaneseChinese dictionaries</definiens>
			</definition>
			<definition id="2">
				<sentence>Annotation consists of automatic analyses and manual revision .</sentence>
				<definiendum id="0">Annotation</definiendum>
				<definiens id="0">consists of automatic analyses and manual revision</definiens>
			</definition>
			<definition id="3">
				<sentence>For manual revision , we also developed an assisting tool , which consist of a graphical interface and internal data management .</sentence>
				<definiendum id="0">assisting tool</definiendum>
			</definition>
</paper>

		<paper id="3032">
			<definition id="0">
				<sentence>CRFs are arbitrary undirected graphical models trained to maximize the conditional probability of the desired outputs given the corresponding inputs .</sentence>
				<definiendum id="0">CRFs</definiendum>
				<definiens id="0">arbitrary undirected graphical models trained to maximize the conditional probability of the desired outputs given the corresponding inputs</definiens>
			</definition>
			<definition id="1">
				<sentence>The conditional probability for the tag sequence given a input Chinese sentence is defined by a linear-chain CRF with parameters 1 2 ... nT t t t 1 2 ... nC c c c ^</sentence>
				<definiendum id="0">conditional probability for the tag sequence</definiendum>
			</definition>
			<definition id="2">
				<sentence>� � Where cZ is the per-input normalization that makes the probability of all state sequences sum to one .</sentence>
				<definiendum id="0">� � Where cZ</definiendum>
			</definition>
</paper>

		<paper id="7013">
</paper>

		<paper id="3020">
			<definition id="0">
				<sentence>According to the scored results of the MSR closed testing track and our analysis , it shows that our BMM-based CWS with the context-based UWI is a simple and effective system to achieve high Chinese word segmentation performance of more than 95.5 % F-measure .</sentence>
				<definiendum id="0">UWI</definiendum>
				<definiens id="0">a simple and effective system to achieve high Chinese word segmentation performance of more than 95.5 % F-measure</definiens>
			</definition>
			<definition id="1">
				<sentence>In the research fields of Chinese natural language processing ( NLP ) , a high-performance Chinese word segmentor ( CWS ) is a useful preprocessing stage to produce an intermediate result for later processes , such as search engines , text mining and speech recognition , etc .</sentence>
				<definiendum id="0">NLP</definiendum>
				<definiendum id="1">CWS</definiendum>
			</definition>
			<definition id="2">
				<sentence>Meantime , there are two types of error segmentation caused by unknown word problem : ( 1 ) Lack of unknown word ( LUW ) , it means the error segmentation occurred by lack of an unknown word in the system dictionary , such as “D�/Y'/at5W” ; ( 2 ) Error identified word ( EIW ) , it means the error segmentation occurred by an error identified unknown words , such as “ !</sentence>
				<definiendum id="0">EIW</definiendum>
				<definiens id="0">error segmentation caused by unknown word problem : ( 1 ) Lack of unknown word ( LUW ) , it means the error segmentation occurred by lack of an unknown word in the system dictionary , such as “D�/Y'/at5W” ; ( 2 ) Error identified word</definiens>
			</definition>
			<definition id="3">
				<sentence>The descriptions of symbols used in our CWS are given as below : &lt; BOS &gt; : begin of sentence ; &lt; EOS &gt; : end of sentence ; &lt; BOW &gt; : begin of word ; &lt; EOW &gt; : end of word ; / : word boundary ; + : inner word boundaries of the segmentation of a system word segmented by BMM technique with the system dictionary exclusive of this system word ; SWS ( stop word string ) : for a system word ( such as “F , ( of ) ” ) , if the ratio ( non-SWS probability ) of total frequency of the other system words including it ( such as “O6F , ( beautiful ) ” ) and its character string frequency is less than or equal to 1 % , it is a SWS ; SWBS ( stop word bigram string ) : for a word bigram ( such as “1� ( just ) /P� ( can ) ” ) , if the ratio ( non-SWBS probability ) of its character string ( such as “1�P� ( ability ) ” frequency and its character string frequency is less than or equal to 1 % , it is a SWBS ; BMM-ASM ( BMM ambiguity string mapping table : the BMM-ASM table lists all the pairs of correct SS ( given in training corpus ) and the error BMM SS ( generated by BMM with the training system dictionary ) .</sentence>
				<definiendum id="0">SWS</definiendum>
				<definiendum id="1">non-SWS probability</definiendum>
				<definiendum id="2">character string frequency</definiendum>
				<definiendum id="3">frequency</definiendum>
				<definiens id="0">below : &lt; BOS &gt; : begin of sentence ; &lt; EOS &gt; : end of sentence ; &lt; BOW &gt; : begin of word ; &lt; EOW &gt; : end of word ; / : word boundary ; + : inner word boundaries of the segmentation of a system word segmented by BMM technique with the system dictionary exclusive of this system word</definiens>
				<definiens id="1">non-SWBS probability ) of its character string ( such as “1�P� ( ability ) ” frequency and its character string</definiens>
				<definiens id="2">the BMM-ASM table lists all the pairs of correct SS ( given in training corpus ) and the error BMM SS ( generated by BMM with the training system dictionary )</definiens>
			</definition>
			<definition id="4">
				<sentence>As per its MSR-standard segmentation “4�7D ( effect ) /F� ( really ) / ) % ( good ) ” and its BMM segmentation “4� ( follow ) /7DF� ( indeed ) / ) % ( good ) , ” the pair “4�7D/F�”“4�/7DF�” is a BMM-ASM ; TCT ( triple context template ) : a TCT comprised of three items from left to right are : the left word , the segmented system word and the right word , where the system word is not a mono-syllabic Chinese word .</sentence>
				<definiendum id="0">MSR-standard segmentation “4�7D</definiendum>
				<definiendum id="1">TCT</definiendum>
				<definiens id="0">a BMM-ASM ;</definiens>
				<definiens id="1">a TCT comprised of three items from left to right are : the left word , the segmented system word and the right word</definiens>
			</definition>
			<definition id="5">
				<sentence>The two generated TCT are : “ &lt; BOS &gt; /4�+1-char-word/F�” “ &lt; BOS &gt; /1-char-word+7D/F�” ; and WCT ( word context template ) : a WCT comprised of three items from left to right are : “ &lt; BOW &gt; ” , the segmented system word and “ &lt; EOW &gt; ” , where the system word is not a mono-syllabic word .</sentence>
				<definiendum id="0">WCT</definiendum>
				<definiens id="0">a WCT comprised of three items from left to right are : “ &lt; BOW &gt; ” , the segmented system word</definiens>
			</definition>
			<definition id="6">
				<sentence>( 4 ) We will continue to expand our CWS with other linguistic knowledge ( such as part-ofspeech information and morphology ) and BTM model ( Tsai 2005 ) to improve our BMM-based CWS for attending the third International Chinese Word Segmentation Bakeoff in both closed and open testing tracks .</sentence>
				<definiendum id="0">BTM model</definiendum>
				<definiens id="0">part-ofspeech information and morphology</definiens>
			</definition>
</paper>

		<paper id="3002">
			<definition id="0">
				<sentence>The UDN2001 corpus ( Tsai and Hsu 2002 ) is a collection of 4,539,624 Chinese sentences extracted from whole 2001 articles on the United Daily News Website ( UDN ) in Taiwan .</sentence>
				<definiendum id="0">UDN2001 corpus</definiendum>
				<definiens id="0">a collection of 4,539,624 Chinese sentences extracted from whole 2001 articles on the United Daily News Website ( UDN ) in Taiwan</definiens>
			</definition>
			<definition id="1">
				<sentence>As per ( Gao et al. 2002 ) , MSIME is a trigam-like Chinese input system .</sentence>
				<definiendum id="0">MSIME</definiendum>
				<definiens id="0">a trigam-like Chinese input system</definiens>
			</definition>
			<definition id="2">
				<sentence>Segmentation : Generate the word segmentation for a given Chinese sentence by backward maximum matching ( BMM ) techniques ( Chen et al. 1986 ) with the system dictionary .</sentence>
				<definiendum id="0">Segmentation</definiendum>
			</definition>
			<definition id="3">
				<sentence>The frequency of a wordpair is the number of sentences that contain the word-pair with the same word-pair order in the training corpus .</sentence>
				<definiendum id="0">frequency of a wordpair</definiendum>
				<definiens id="0">the number of sentences that contain the word-pair with the same word-pair order in the training corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>( 2 ) STW improvement ( i.e. STW error reduction rate ) = ( accuracy of STW system with WP – accuracy of STW system ) ) / ( 1 – accuracy of STW system ) .</sentence>
				<definiendum id="0">STW improvement</definiendum>
				<definiens id="0">STW error reduction rate ) = ( accuracy of STW system with WP – accuracy of STW system ) ) / ( 1 – accuracy of STW system )</definiens>
			</definition>
			<definition id="5">
				<sentence>Our experimental results show that , by applying the WP identifier together with MSIME ( a trigram-like model ) and BiGram ( an optimized bigram model ) , the tonal and toneless STW improvements of the two Chinese input systems are 27.5 % /22.1 % and 18.9 % /18.8 % , respectively .</sentence>
				<definiendum id="0">BiGram (</definiendum>
				<definiens id="0">an optimized bigram model</definiens>
			</definition>
</paper>

		<paper id="2003">
			<definition id="0">
				<sentence>Language modeling is a description of natural language and a good language model can help to improve the performance of the natural language processing .</sentence>
				<definiendum id="0">Language modeling</definiendum>
				<definiens id="0">a description of natural language and a good language model can help to improve the performance of the natural language processing</definiens>
			</definition>
			<definition id="1">
				<sentence>Traditional SLM is make use to estimate the likelihood ( or probability ) of a word string , in 13 this study , we determined the structure of Chinese language model , first , we gave the ontology description framework of Chinese word and the representation of Chinese lingual ontology knowledge , and then , automatically acquired the usage of a word with its co-occurrence of context in using semantic , pragmatics , syntactic , etc from the corpus to act as Chinese lingual ontology knowledge bank .</sentence>
				<definiendum id="0">Traditional SLM</definiendum>
				<definiens id="0">make use to estimate the likelihood ( or probability ) of a word string</definiens>
			</definition>
			<definition id="2">
				<sentence>Segmentation , POS and Semantic tagging Items Results ( “游客 ” acts as keyword ) Chinese sentence 外国游客来北京游玩。 Words segmentation 外国 游客 来 北京 游玩 。 POS tagging 外国 nd/ 游客 Keyword/来 vg/ 北京 nd/ 游玩 vg/ 。 wj/ Semantic label tagging 外国 nd/021243 游客 Keyword/070366 来 vg/017545 北京 nd/021243 游玩 vg/092317 。 wj/-1 Characteristic string nd/021243 游客 Keyword/070366 vg/017545 nd/021243 vg/092317 Explanation of Semantic label 021243 represents “地方 ” , 070366 represents “人 ” , 092317 represents “ 闲消 ” , “-1” represents not to be defined or exist this semantic in HowNet .</sentence>
				<definiendum id="0">Semantic tagging Items Results</definiendum>
				<definiens id="0">Semantic label 021243 represents “地方 ” , 070366 represents “人 ” , 092317 represents “ 闲消 ” , “-1” represents not to be defined or exist this semantic in HowNet</definiens>
			</definition>
			<definition id="3">
				<sentence>( ) ( ) ( ) ⎟ ⎟ ⎠ ⎞ ⎜ ⎜ ⎝ ⎛ == UU n r rrr m l lll CLPOSSemCLPOSSemontologyKeyWord 11 , , , , , , , , Where , KeyWord ( ontology ) is the ontology description of a Chinese word , ( ) iii CLPOSSem , , , is the left co-occurrence knowledge of a Chinese word got from its context and ( ) iii CLPOSSem , , , is the right co-occurrence knowledge .</sentence>
				<definiendum id="0">KeyWord ( ontology )</definiendum>
				<definiens id="0">the ontology description of a Chinese word , ( ) iii CLPOSSem , , , is the left co-occurrence knowledge of a Chinese word got from its context</definiens>
			</definition>
			<definition id="4">
				<sentence>PreAt10 is the average precision of 36 topics in precision of top 10 ranking documents , while PreAt100 is top 100 ranking documents .</sentence>
				<definiendum id="0">PreAt10</definiendum>
				<definiens id="0">top 100 ranking documents</definiens>
			</definition>
</paper>

		<paper id="3018">
			<definition id="0">
				<sentence>Finally , a CRFs-based word segmenter produces the final results using either of the voted list ( Model a ) or the merged list ( Model c ) .</sentence>
				<definiendum id="0">CRFs-based word segmenter</definiendum>
				<definiens id="0">produces the final results using either of the voted list ( Model a ) or the merged list ( Model c )</definiens>
			</definition>
			<definition id="1">
				<sentence>( 2/11 ) ( 2/15 ) ( 16/29 ) ( 10/23 ) Model b Char.-based tagging Char.-based tagging Char.-based tagging Char.-based tagging ( 1/11 ) ( 3/15 ) ( 6/29 ) ( 7/23 ) Model c CRF + Merged Unk .</sentence>
				<definiendum id="0">Char.-based tagging Char.-based tagging Char.-based tagging Char.-based tagging</definiendum>
				<definiens id="0">7/23 ) Model c CRF + Merged Unk</definiens>
			</definition>
</paper>

		<paper id="2047">
			<definition id="0">
				<sentence>Biography Chin-Yew Lin is a senior research scientist at the Information Sciences Institute of the University of Southern California .</sentence>
				<definiendum id="0">Biography Chin-Yew Lin</definiendum>
				<definiens id="0">a senior research scientist at the Information Sciences Institute of the University of Southern California</definiens>
			</definition>
</paper>

		<paper id="5012">
			<definition id="0">
				<sentence>Often the summary sentence is a paraphrase of a sentence in the source text , or else a combination of phrases and words from important sentences that have been pieced together to form a new sentence .</sentence>
				<definiendum id="0">summary sentence</definiendum>
				<definiens id="0">a paraphrase of a sentence in the source text , or else a combination of phrases and words from important sentences that have been pieced together to form a new sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The Viterbi algorithm ( for a comprehensive overview , see ( Manning and Sch¨utze , 1999 ) ) is used to search for the best path across a network of nodes , where each node represents a word in the vocabulary .</sentence>
				<definiendum id="0">Viterbi algorithm</definiendum>
				<definiens id="0">a word in the vocabulary</definiens>
			</definition>
			<definition id="2">
				<sentence>Inthissection , wedescribe twosmallexperiments designed to evaluate whether a dependencybased statistical generator improves grammaticality .</sentence>
				<definiendum id="0">Inthissection</definiendum>
				<definiens id="0">wedescribe twosmallexperiments designed to evaluate whether a dependencybased statistical generator improves grammaticality</definiens>
			</definition>
			<definition id="3">
				<sentence>A relation match consists of an identical head , and also an identical modifier .</sentence>
				<definiendum id="0">relation match</definiendum>
				<definiens id="0">consists of an identical head , and also an identical modifier</definiens>
			</definition>
</paper>

		<paper id="7010">
</paper>

		<paper id="3033">
			<definition id="0">
				<sentence>The segmenter consists of two components : a tagging component that uses the transformation-based learning algorithm to tag each character with its position in a word , and a merging component that transforms a tagged character sequence into a word-segmented sentence .</sentence>
				<definiendum id="0">segmenter</definiendum>
				<definiens id="0">consists of two components : a tagging component that uses the transformation-based learning algorithm to tag each character with its position in a word , and a merging component that transforms a tagged character sequence into a word-segmented sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The segmenter consists of two major components .</sentence>
				<definiendum id="0">segmenter</definiendum>
				<definiens id="0">consists of two major components</definiens>
			</definition>
			<definition id="2">
				<sentence>First , a tagging component tags each individual character in a sentence with a position-ofcharacter ( POC ) tag that indicates the position of the character in a word .</sentence>
				<definiendum id="0">tagging component</definiendum>
				<definiens id="0">tags each individual character in a sentence with a position-ofcharacter ( POC ) tag that indicates the position of the character in a word</definiens>
			</definition>
			<definition id="3">
				<sentence>tt n 1 1 1maxarg − = ∏ ( 1 ) where ti denotes the ith tag in the tag sequence and wi denotes the ith character in the character sequence .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiens id="0">the ith tag in the tag sequence and wi denotes the ith character in the character sequence</definiens>
			</definition>
</paper>

		<paper id="2048">
			<definition id="0">
				<sentence>Over the last few years dramatic improvements have been made , and a number of comparative evaluations have shown , that SMT gives competitive results to rule-based translation systems , requiring significantly less development time .</sentence>
				<definiendum id="0">SMT</definiendum>
				<definiens id="0">gives competitive results to rule-based translation systems , requiring significantly less development time</definiens>
			</definition>
</paper>

	</volume>
