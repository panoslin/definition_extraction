<?xml version="1.0" encoding="UTF-8"?>
	<volume id="W00">

		<paper id="0726">
			<definition id="0">
				<sentence>Text chunking consists of dividing a text into phrases in such a way that syntactically related words become member of the same phrase .</sentence>
				<definiendum id="0">Text chunking</definiendum>
				<definiens id="0">dividing a text into phrases in such a way that syntactically related words become member of the same phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>INs can also constitute an SBAR chunk ( see below ) and some PP chunks contain more than one word .</sentence>
				<definiendum id="0">SBAR chunk</definiendum>
				<definiens id="0">chunks contain more than one word</definiens>
			</definition>
			<definition id="2">
				<sentence>The Treebank uses the PRT constituent to annotate verb particles , and our PRT chunk does the same .</sentence>
				<definiendum id="0">Treebank</definiendum>
				<definiens id="0">uses the PRT constituent to annotate verb particles</definiens>
			</definition>
			<definition id="3">
				<sentence>The UCP chunk is reminiscent of the UCP ( unlike coordinated phrase ) constituent in the Treebank .</sentence>
				<definiendum id="0">UCP chunk</definiendum>
				<definiendum id="1">UCP</definiendum>
				<definiens id="0">unlike coordinated phrase ) constituent in the Treebank</definiens>
			</definition>
</paper>

		<paper id="0307">
</paper>

		<paper id="1415">
			<definition id="0">
				<sentence>`` A non-restrictive component gives additional information to a head that has already been viewed as unique or as a member of a class that has been independently identified , -mud therefoee is not ' essml ; tial for the identification of the head '' ( Quirk et al. , 1985 ) .</sentence>
				<definiendum id="0">non-restrictive component</definiendum>
				<definiens id="0">gives additional information to a head that has already been viewed as unique or as a member of a class that has been independently identified , -mud therefoee is not ' essml ; tial for the identification of the head ''</definiens>
			</definition>
			<definition id="1">
				<sentence>2This corpus is collected and annotated for the GNOME project ( Poesio , 2000 ) , which aims at developing general algorithms for generating nominal expressions .</sentence>
				<definiendum id="0">GNOME project</definiendum>
				<definiens id="0">aims at developing general algorithms for generating nominal expressions</definiens>
			</definition>
			<definition id="2">
				<sentence>For the convenience of discussion , we define some terminology to be used throughout the paper : An NR construction/sentence : a sentence that has a main clause and a subordinate NR modifier attached to one of its NPs ( e.g. ( 4b ) of Figure 2 ) .</sentence>
				<definiendum id="0">NR construction/sentence</definiendum>
				<definiens id="0">a sentence that has a main clause</definiens>
			</definition>
			<definition id="3">
				<sentence>A hypotactic construction/sentence : a sentence that has a main clause and a dependent clause , connected by a cue phrase .</sentence>
				<definiendum id="0">hypotactic construction/sentence</definiendum>
				<definiens id="0">a sentence that has a main clause and a dependent clause , connected by a cue phrase</definiens>
			</definition>
</paper>

		<paper id="1433">
			<definition id="0">
				<sentence>RST is a descriptive theory of hierarchical structure in discourse that identifies functional relationships between discourse parts based on the intentions behind their production ( Mann and Thompson , 1987 ) .</sentence>
				<definiendum id="0">RST</definiendum>
			</definition>
			<definition id="1">
				<sentence>RDA is an annotation scheme for identifying rhetorical structure in explanatory texts in the SHERLOCK domain ( Moser et al. , 1996 ) .</sentence>
				<definiendum id="0">RDA</definiendum>
				<definiens id="0">an annotation scheme for identifying rhetorical structure in explanatory texts in the SHERLOCK domain</definiens>
			</definition>
			<definition id="2">
				<sentence>Marcu uses discourse-cuesto '' automa~ically uncover rhetorical relations in text ( 1997 ) .</sentence>
				<definiendum id="0">Marcu</definiendum>
			</definition>
</paper>

		<paper id="0733">
			<definition id="0">
				<sentence>In memory-based learning the training data is stored and a new item is classified by the most frequent classification among training items which are closest to this new item .</sentence>
				<definiendum id="0">memory-based learning</definiendum>
				<definiens id="0">the training data is stored and a new item is classified by the most frequent classification among training items which are closest to this new item</definiens>
			</definition>
</paper>

		<paper id="1429">
			<definition id="0">
				<sentence>The STOP system generates personalised smokingcessation leaflets , based on the recipient 's responses to a questionnaire about smoking beliefs , concerns , and experiences .</sentence>
				<definiendum id="0">STOP system</definiendum>
				<definiens id="0">generates personalised smokingcessation leaflets , based on the recipient 's responses to a questionnaire about smoking beliefs , concerns , and experiences</definiens>
			</definition>
			<definition id="1">
				<sentence>STOP leaflets consist of four A5 pages , of which only the two inside pages are fully generated ; an example of the inside pages of a STOP leaflet are shown in Figure 2 .</sentence>
				<definiendum id="0">STOP leaflets</definiendum>
				<definiens id="0">consist of four A5 pages , of which only the two inside pages are fully generated</definiens>
			</definition>
			<definition id="2">
				<sentence>Internally , STOP is a fairly conventional shallow NLG system , with its main innovation being the processing used to control the length of leaflets ( Reiter , 2000 ) .</sentence>
				<definiendum id="0">STOP</definiendum>
				<definiens id="0">a fairly conventional shallow NLG system , with its main innovation being the processing used to control the length of leaflets</definiens>
			</definition>
			<definition id="3">
				<sentence>STOP has been evaluated in a clinical trial , which compared cessation rates among smokers who received STOP leaflets ; smokers who received a non-personalised leaflet with similar structure and appearance to a STOP leaflet : and smokers who did not receive any leaflet ( but did fill out a questionnaire ) .</sentence>
				<definiendum id="0">STOP</definiendum>
				<definiens id="0">compared cessation rates among smokers who received STOP leaflets ; smokers who received a non-personalised leaflet with similar structure and appearance to a STOP leaflet : and smokers who did not receive any leaflet ( but did fill out a questionnaire )</definiens>
			</definition>
			<definition id="4">
				<sentence>STOP is a different type of application in that ( 1 ) there are many possible leaflets which can be generated ( and the system can not tell which is best ) , and ( 2 ) no human currently writes personalised smoking-cessation leaflets ( because manually writing such leaflets is too expensive ) .</sentence>
				<definiendum id="0">STOP</definiendum>
				<definiens id="0">a different type of application in that ( 1 ) there are many possible leaflets which can be generated ( and the system can not tell which is best ) , and ( 2 ) no human currently writes personalised smoking-cessation leaflets ( because manually writing such leaflets is too expensive )</definiens>
			</definition>
			<definition id="5">
				<sentence>For people who answered Not Sure or Yes , we looked at their decisional balance , that is the number of likes and dislikes they had about smoking , and placed them into Lacks Confidence if their dislikes clearly outnumbered their likes , and Classic Precontemplator otherwise .</sentence>
				<definiendum id="0">decisional balance</definiendum>
				<definiens id="0">the number of likes and dislikes they had about smoking</definiens>
			</definition>
</paper>

		<paper id="1215">
			<definition id="0">
				<sentence>Only if we could see the same word ; ~1~ ~L ( /zousi/ , smuggle ) semantically different in 1 ) and 2 ) , we could add another dependent tree 8 ) to code 5 ) , with 6 ) and 7 ) corresponding with 3 ) and 4 ) respectively .</sentence>
				<definiendum id="0">~1~ ~L</definiendum>
				<definiens id="0">corresponding with 3 ) and 4 ) respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>20 , But there will be no appropriate annotation for 18 ) , because on the one hand , ~ ( /qiche/ , car ) should be coded as a head due to its relationship with ~g~ ( /piaoliang/ , beautiful ) , on the other hand , it 's role as the object of the verb ~L ( /zousi/ , smuggle ) makes it illegal to be a head .</sentence>
				<definiendum id="0">~L</definiendum>
				<definiens id="0">the object of the verb</definiens>
			</definition>
			<definition id="2">
				<sentence>Suppose Pi~-Po , Ei ( ~-Po ) is the set of the edges between points in P1 , Ri ( ~ ( PlX El ) ) is the set of relations between points in PI and edges in Et s , then : s Here , Edges are also points .</sentence>
				<definiendum id="0">Ei ( ~-Po )</definiendum>
				<definiendum id="1">Ri ( ~ ( PlX El ) )</definiendum>
				<definiens id="0">the set of the edges between points in P1</definiens>
				<definiens id="1">the set of relations between points in PI and edges in Et s</definiens>
			</definition>
			<definition id="3">
				<sentence>i ) &lt; P1 , El , Ri &gt; is a I-level compositional graph ; ii ) &lt; &lt; Pi , El , R~ &gt; , p &gt; ( peP9 is a 1level point-headed graph ; iii ) &lt; &lt; P1 , El , R/ &gt; , e &gt; ( e~E1 ) is a 1level edge-headed graph ; iv ) 1-level concepts comprise 1-1evel compositional graphs , l-level point-headed graphs , and 1-level edge-headed graphs .</sentence>
				<definiendum id="0">El , Ri &gt;</definiendum>
				<definiendum id="1">&gt; ( peP9</definiendum>
				<definiens id="0">a I-level compositional graph</definiens>
				<definiens id="1">a 1level point-headed graph</definiens>
				<definiens id="2">a 1level edge-headed graph</definiens>
			</definition>
			<definition id="4">
				<sentence>ouZiu ... . , Za4 ) , ( PnnXn.1 ) ¢NIL , En ( C-Pn ) is the set of the edges between points in P~ , Rn ( C ( P=x En ) ) is the set of relations between points in P= and edges in En , then : v ) vi ) vii ) viii ) &lt; P~ , E~ , Rn &gt; is a n-level compositional graph ; &lt; &lt; en , En , Rn &gt; , p &gt; ( P~Pn ) is a nlevel point-headed graph ; &lt; &lt; P~ , E~ , Rn &gt; , e &gt; ( e~En ) is a nlevel edge-headed graph ; n-level concepts comprise n-level compositional graphs , n-level point-headed graphs , and n-level edge-headed graphs .</sentence>
				<definiendum id="0">En ( C-Pn )</definiendum>
				<definiendum id="1">Rn ( C ( P=x En ) )</definiendum>
				<definiendum id="2">Rn &gt;</definiendum>
				<definiendum id="3">n-level concepts</definiendum>
				<definiens id="0">the set of the edges between points in P~</definiens>
				<definiens id="1">the set of relations between points in P= and edges in En</definiens>
				<definiens id="2">a n-level compositional graph</definiens>
			</definition>
			<definition id="5">
				<sentence>In general , Chinese phrases can roughly be classified into five categories , i.e. , subpredicate , verb-object , modifier-center , verbcomplement , and coordinate .</sentence>
				<definiendum id="0">Chinese phrases</definiendum>
				<definiens id="0">classified into five categories , i.e. , subpredicate , verb-object , modifier-center , verbcomplement , and coordinate</definiens>
			</definition>
			<definition id="6">
				<sentence>~b~ ( /waimao/ , appearance ) denotes a relation between concepts and relationships .</sentence>
				<definiendum id="0">~b~</definiendum>
				<definiens id="0">a relation between concepts and relationships</definiens>
			</definition>
</paper>

		<paper id="0310">
			<definition id="0">
				<sentence>MIMIC '' provides movie listing information involving knowledge about towns , theaters , movies and showtimes , as demonstrated in Figure 1 .</sentence>
				<definiendum id="0">MIMIC</definiendum>
				<definiens id="0">provides movie listing information involving knowledge about towns , theaters , movies and showtimes</definiens>
			</definition>
			<definition id="1">
				<sentence>MIMIC currently utilizes templatedriven text generation , and passes on text strings to a stand-alone TTS system .</sentence>
				<definiendum id="0">MIMIC</definiendum>
				<definiens id="0">utilizes templatedriven text generation , and passes on text strings to a stand-alone TTS system</definiens>
			</definition>
			<definition id="2">
				<sentence>Semantic Representations MIMIC employs a statistically-driven semantic interpretation engine to `` spot '' values for key attributes that make up a valid MIMIC query in a robust fashion ) To simplify matters , for each utterance , MIMIC computes an attribute-value matrix ( AVM ) -~epresentation , identifying important pieces of information for accomplishing a given set of tasks .</sentence>
				<definiendum id="0">Semantic Representations MIMIC</definiendum>
				<definiendum id="1">MIMIC</definiendum>
				<definiens id="0">employs a statistically-driven semantic interpretation engine to `` spot '' values for key attributes</definiens>
				<definiens id="1">computes an attribute-value matrix ( AVM ) -~epresentation , identifying important pieces of information for accomplishing a given set of tasks</definiens>
			</definition>
			<definition id="3">
				<sentence>Attribute 11 Value Task Movie Theatre Town Time when October Sky Hoboken Cinema Hoboken Figure 2 : Attribute Value Matrix ( AVM ) , computed by MIMIC 's semantic interpreter .</sentence>
				<definiendum id="0">Attribute Value Matrix</definiendum>
				<definiens id="0">computed by MIMIC 's semantic interpreter</definiens>
			</definition>
			<definition id="4">
				<sentence>HEARER-NEW information ( c.f. ( Prince , 1988 ) ) is that which is requested by the user , and constitutes the only new information on the scale .</sentence>
				<definiendum id="0">HEARER-NEW information</definiendum>
				<definiens id="0">that which is requested by the user</definiens>
			</definition>
			<definition id="5">
				<sentence>MIMIC-CTS contains additional prosodic rules for logical connectives , and clarification and confirmation suhdialogues .</sentence>
				<definiendum id="0">MIMIC-CTS</definiendum>
				<definiens id="0">contains additional prosodic rules for logical connectives , and clarification and confirmation suhdialogues</definiens>
			</definition>
</paper>

		<paper id="0730">
			<definition id="0">
				<sentence>SVMs are so-called large margin classifiers and are well-known as their good generalization performance .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">large margin classifiers and are well-known as their good generalization performance</definiens>
			</definition>
			<definition id="1">
				<sentence>Support Vector Machines ( SVMs ) , first introduced by Vapnik ( Cortes and Vapnik , 1995 ; Vapnik , 1995 ) , are relatively new learning approaches for solving two-class pattern recognition problems .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs )</definiendum>
				<definiens id="0">relatively new learning approaches for solving two-class pattern recognition problems</definiens>
			</definition>
			<definition id="2">
				<sentence>SVMs can be regarded as an optimization problem ; finding w and b which minimize \ [ \ [ w\ [ \ [ under the constraints : yi\ [ ( w • xi ) + b\ ] &gt; 1 .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">an optimization problem ; finding w and b which minimize \ [ \ [ w\ [ \ [ under the constraints : yi\ [ ( w • xi ) + b\ ] &gt; 1</definiens>
			</definition>
			<definition id="3">
				<sentence>The chunks in the CoNLL-2000 shared task are represented with IOB based model , in which every word is to be tagged with a chunk label extended with I ( inside a chunk ) , O ( outside a chunk ) and B ( inside a chunk , but the preceding word is in another chunk ) .</sentence>
				<definiendum id="0">I</definiendum>
				<definiendum id="1">O</definiendum>
				<definiendum id="2">B</definiendum>
				<definiens id="0">inside a chunk</definiens>
				<definiens id="1">outside a chunk</definiens>
				<definiens id="2">inside a chunk , but the preceding word is in another chunk</definiens>
			</definition>
			<definition id="4">
				<sentence>More precisely , we give the following for the features to identify chunk label ci at i-th word : w j , tj cj ( j = i-2 , i-1 , i , i+1 , i+ 2 ) ( j = i-2 , i-1 ) where wi is the word appearing at i-th word , ti is the POS tag of wi , and c/ is the ( extended ) chunk label at i-th word .</sentence>
				<definiendum id="0">wi</definiendum>
				<definiendum id="1">ti</definiendum>
				<definiendum id="2">c/</definiendum>
				<definiens id="0">the ( extended ) chunk label at i-th word</definiens>
			</definition>
			<definition id="5">
				<sentence>We defined the certainty score as the number of votes for the class ( tag ) obtained through the pairwise voting .</sentence>
				<definiendum id="0">certainty score</definiendum>
				<definiens id="0">the number of votes for the class ( tag ) obtained through the pairwise voting</definiens>
			</definition>
</paper>

		<paper id="0802">
			<definition id="0">
				<sentence>WordNet ( Miller et al. , 1990 ) and EuroWordNet ( Vossen , 1998 ) , as most large-coverage electronic dictionaries and semantic networks , are not designed for a specific Natural Language Processing ( NLP ) application .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiendum id="1">EuroWordNet</definiendum>
				<definiens id="0">most large-coverage electronic dictionaries and semantic networks , are not designed for a specific Natural Language Processing ( NLP ) application</definiens>
			</definition>
			<definition id="1">
				<sentence>In EWN , each monolingual database is linked , via CrossLanguage equivalence relations , to the InterLingual Index ( ILI ) which is the superset of all concepts occurring in all languages .</sentence>
				<definiendum id="0">InterLingual Index ( ILI )</definiendum>
			</definition>
			<definition id="2">
				<sentence>The ILI permits finding equivalent synsets between any pair of languages included in the database .</sentence>
				<definiendum id="0">ILI permits</definiendum>
				<definiens id="0">finding equivalent synsets between any pair of languages included in the database</definiens>
			</definition>
</paper>

		<paper id="1109">
			<definition id="0">
				<sentence>Information Extraction ( IE ) systems provide better presentation of results ( e.g. tables , database records etc. ) , and tend to include more precise searches which depend upon not just finding keywords but finding them in particular positions or in particular grammatical relationships .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
			</definition>
			<definition id="1">
				<sentence>Highlight ( Thomas et al. , 2000 ) is a generalpurpose IE engine for use in commercial applications .</sentence>
				<definiendum id="0">Highlight</definiendum>
				<definiens id="0">a generalpurpose IE engine for use in commercial applications</definiens>
			</definition>
			<definition id="2">
				<sentence>Keyword based search is a special case where the user specifies one or more keywords which they want to find in a document .</sentence>
				<definiendum id="0">Keyword based search</definiendum>
				<definiens id="0">a special case where the user specifies one or more keywords which they want to find in a document</definiens>
			</definition>
			<definition id="3">
				<sentence>Positional constraints can include any kind of inter-item constraints e.g. precedes , same sentence .</sentence>
				<definiendum id="0">Positional constraints</definiendum>
				<definiens id="0">include any kind of inter-item constraints e.g. precedes , same sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>Hits denotes how many of the files passed to IE actually had at least one template in them and Templates shows how many templates were extracted as a result of the query .</sentence>
				<definiendum id="0">Hits</definiendum>
				<definiens id="0">how many of the files passed to IE actually had at least one template in them and Templates shows how many templates were extracted as a result of the query</definiens>
			</definition>
			<definition id="5">
				<sentence>Time is the total time for the query in seconds .</sentence>
				<definiendum id="0">Time</definiendum>
				<definiens id="0">the total time for the query in seconds</definiens>
			</definition>
</paper>

		<paper id="1409">
			<definition id="0">
				<sentence>The RAGS architecture ( Cahill et al. , 1999 ) is a reference architecture for natural language generation systems .</sentence>
				<definiendum id="0">RAGS architecture</definiendum>
				<definiens id="0">a reference architecture for natural language generation systems</definiens>
			</definition>
			<definition id="1">
				<sentence>Robustness inside the Microplanner and the Syntactic Generator additionally helps to get rid of some generation gap problems : Contradictions to Generation Constraints : The knowledge bases of the generator ( mieroplanning rules , grammar and lexicon ) describe constraints on the structure of the output utterance that might conflict with the input .</sentence>
				<definiendum id="0">Syntactic Generator</definiendum>
				<definiens id="0">The knowledge bases of the generator ( mieroplanning rules , grammar and lexicon ) describe constraints on the structure of the output utterance that might conflict with the input</definiens>
			</definition>
</paper>

		<paper id="1401">
			<definition id="0">
				<sentence>FERCUS , a realization module , follows Knight and Langkilde 's seminal work in using an n-gram language model , but we augment it with a tree-based stochastic model and a lexicalized syntactic grammar .</sentence>
				<definiendum id="0">FERCUS</definiendum>
				<definiens id="0">a realization module , follows Knight and Langkilde 's seminal work in using an n-gram language model</definiens>
			</definition>
			<definition id="1">
				<sentence>2 The Tree Chooser uses a stochastic tree model to choose syntactic properties ( expressed as trees in a Tree Adjoining Grammar ) for the nodes in the input structure .</sentence>
				<definiendum id="0">Tree Chooser</definiendum>
				<definiens id="0">uses a stochastic tree model to choose syntactic properties ( expressed as trees in a Tree Adjoining Grammar ) for the nodes in the input structure</definiens>
			</definition>
			<definition id="2">
				<sentence>The first metric , simple accuracy , is the same string distance metric used for measuring speech recognition accuracy .</sentence>
				<definiendum id="0">simple accuracy</definiendum>
				<definiens id="0">the same string distance metric used for measuring speech recognition accuracy</definiens>
			</definition>
			<definition id="3">
				<sentence>Simple accuracy is the number of insertion ( I ) , deletion ( D ) and substitutions ( S ) errors between the reference strings in the test corpus and the strings produced by the generation model .</sentence>
				<definiendum id="0">Simple accuracy</definiendum>
				<definiens id="0">the number of insertion ( I ) , deletion ( D ) and substitutions ( S ) errors between the reference strings in the test corpus and the strings produced by the generation model</definiens>
			</definition>
			<definition id="4">
				<sentence>The alignment algorithm attempts to find the set of operations that minimizes the cost of aligning the generated string to tile reference string .</sentence>
				<definiendum id="0">alignment algorithm</definiendum>
				<definiens id="0">attempts to find the set of operations that minimizes the cost of aligning the generated string to tile reference string</definiens>
			</definition>
			<definition id="5">
				<sentence>The test corpus is a randomly chosen subset of 100 sentences from the Section 20 of WSJ .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiens id="0">a randomly chosen subset of 100 sentences from the Section 20 of WSJ</definiens>
			</definition>
			<definition id="6">
				<sentence>A substitution represents a case in the string metrics in which not only a word is in the wrong place , but the word that should have been in that place is somewhere else , Therefore , substitutions , more than moves or insertions or deletions , represent grave cases of word order anomalies .</sentence>
				<definiendum id="0">substitution</definiendum>
				<definiens id="0">a case in the string metrics in which not only a word is in the wrong place</definiens>
			</definition>
			<definition id="7">
				<sentence>FERGUS currently can perform punctuation and function word insertion , and morphology and lexical choice are under development . )</sentence>
				<definiendum id="0">FERGUS</definiendum>
				<definiens id="0">perform punctuation and function word insertion , and morphology and lexical choice are under development</definiens>
			</definition>
			<definition id="8">
				<sentence>Thus , as long as the goal of the realizer is to enmlate as closely as possible a given corpus ( rather than provide a maximal range of paraphrastic capability ) , then our approach can be used for evaluation , r As in the case of machine translation , evaluation in generation is a complex issue .</sentence>
				<definiendum id="0">realizer</definiendum>
				<definiens id="0">to enmlate as closely as possible a given corpus</definiens>
			</definition>
</paper>

		<paper id="0711">
			<definition id="0">
				<sentence>A computational framework is presented which is used to model the process by which human language learners acquire the syntactic component of their native language .</sentence>
				<definiendum id="0">computational framework</definiendum>
				<definiens id="0">used to model the process by which human language learners acquire the syntactic component of their native language</definiens>
			</definition>
			<definition id="1">
				<sentence>Discussion centers around an application to Fodor 's Structural Trigger 's Learner ( STL ) ( 1998 ) 1 and concludes with the proposal that successful computational modeling requires a parallel psycholinguistic investigation of the distribution of ambiguity across the domain of human languages .</sentence>
				<definiendum id="0">Discussion</definiendum>
				<definiendum id="1">STL</definiendum>
				<definiens id="0">centers around an application to Fodor 's Structural Trigger 's Learner (</definiens>
			</definition>
			<definition id="2">
				<sentence>Chomsky ( 1981 ) ( and elsewhere ) has proposed that all natural languages share the same innate universal principles ( Universal Grammar -UG ) and differ only with respect to the settings of a finite number of parameters .</sentence>
				<definiendum id="0">Universal Grammar -UG</definiendum>
				<definiens id="0">all natural languages share the same innate universal principles</definiens>
			</definition>
			<definition id="3">
				<sentence>The set of human 1The STL is an acquisition model in the principles and parameters paradigm .</sentence>
				<definiendum id="0">STL</definiendum>
				<definiens id="0">an acquisition model in the principles and parameters paradigm</definiens>
			</definition>
			<definition id="4">
				<sentence>grammars is the set of all possible combinations of parameter values ( and lexicon ) .</sentence>
				<definiendum id="0">grammars</definiendum>
				<definiens id="0">the set of all possible combinations of parameter values</definiens>
			</definition>
			<definition id="5">
				<sentence>Ambiguity is a natural enemy of efficient language acquisition .</sentence>
				<definiendum id="0">Ambiguity</definiendum>
			</definition>
			<definition id="6">
				<sentence>our purposes , the number of relevant parameters , r , is the total number of parameters that need to be set in order to license all and only the sentences of the target language .</sentence>
				<definiendum id="0">r</definiendum>
				<definiens id="0">the total number of parameters that need to be set in order to license all and only the sentences of the target language</definiens>
			</definition>
			<definition id="7">
				<sentence>Let H ( wlt , r , e ) be the probability that an arbitrary input sentence expresses w new ( i.e. as yet unset ) parameters , out of the e parameters expressed , given that the learner has already set t parameters ( correctly ) , for a domain in which there are r total parameters that need to be set .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">the probability that an arbitrary input sentence expresses w new ( i.e. as yet unset ) parameters , out of the e parameters expressed , given that the learner has already set t parameters</definiens>
			</definition>
			<definition id="8">
				<sentence>E is given by the following recurrence relation : 5 E ( So ) = 1/e'¢ E ( Zn ) = II ( 1-P ( Sn -- -- ~Sn ) ) ~ P ( Si-'-~Sn ) ( Si ) i~rt~e ( 5 ) The expected total is simply : r -- 1 Etot=E ( So ) + ~ E ( Si ) ( 4 ) i=e which is equal to the expected number to be consumed before any parameters have been set 5The functional E is derived from basic properties of Markov Chains .</sentence>
				<definiendum id="0">Si</definiendum>
				<definiens id="0">equal to the expected number to be consumed before any parameters have been set 5The functional E is derived from basic properties of Markov Chains</definiens>
			</definition>
			<definition id="9">
				<sentence>Let Di ( x ) denote the probability distribution of expression of the input sample .</sentence>
				<definiendum id="0">Di ( x ) denote</definiendum>
				<definiens id="0">the probability distribution of expression of the input sample</definiens>
			</definition>
			<definition id="10">
				<sentence>For example , if Di imposes a uniform distribution , then DI ( x ) = 1/emax where every sentence expresses at least 1 parameter and emax is the maximum number of parameters expressed by any sentence .</sentence>
				<definiendum id="0">emax</definiendum>
				<definiens id="0">the maximum number of parameters expressed by any sentence</definiens>
			</definition>
			<definition id="11">
				<sentence>These studies frequently involve the construction of an idealized language sample which is ( at best ) an accurate subset of sentences that a child might hear .</sentence>
				<definiendum id="0">idealized language sample</definiendum>
				<definiens id="0">an accurate subset of sentences that a child might hear</definiens>
			</definition>
			<definition id="12">
				<sentence>Ultimately , whether a particular acquisition model is successful is an empirical issue and depends on the exact conditions under which the model performs well and the extent to which those favorable conditions are in line with the facts of human language .</sentence>
				<definiendum id="0">successful</definiendum>
				<definiens id="0">an empirical issue and depends on the exact conditions under which the model performs well and the extent to which those favorable conditions are in line with the facts of human language</definiens>
			</definition>
</paper>

		<paper id="0742">
			<definition id="0">
				<sentence>In this paper , we propose an Inductive Logic Programming learning method which aims at automatically extracting special Noun-Verb ( NV ) pairs from a corpus in order to build up semantic lexicons based on Pustejovsky 's Generative Lexicon ( GL ) principles ( Pustejovsky , 1995 ) .</sentence>
				<definiendum id="0">Inductive Logic Programming learning method</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Inductive Logic Programming learning method that we have developed enables us to automatically extract from a corpus N-V pairs whose elements axe linked by one of the semantic relations defined in the qualia structure in GL , and to distinguish them , in terms of surrounding categorial context from N-V pairs also present in sentences of the corpus but not relevant .</sentence>
				<definiendum id="0">Inductive Logic Programming learning method</definiendum>
				<definiens id="0">automatically extract from a corpus N-V pairs whose elements axe linked by one of the semantic relations defined in the qualia structure in GL , and to distinguish them , in terms of surrounding categorial context from N-V pairs also present in sentences of the corpus but not relevant</definiens>
			</definition>
			<definition id="2">
				<sentence>The quality of these systems is usually measured with the help of two criteria : the recall rate , which corresponds to the proportion of relevant answers that have been given by the system compared to the total number of relevant answers in the database , and the precision rate , which denotes the proportion of relevant answers that are present among the given answers .</sentence>
				<definiendum id="0">recall rate</definiendum>
				<definiendum id="1">precision rate</definiendum>
				<definiens id="0">the proportion of relevant answers that have been given by the system compared to the total number of relevant answers in the database</definiens>
			</definition>
			<definition id="3">
				<sentence>In GL formalism , lexical entries consist in structured sets of predicates that define a word .</sentence>
				<definiendum id="0">lexical entries</definiendum>
				<definiens id="0">consist in structured sets of predicates that define a word</definiens>
			</definition>
			<definition id="4">
				<sentence>We assert that these N-V links are especially relevant for index expansion in IR systems ( Fabre and S~billot , 1999 ) , and what we call a relevant N-V pair afterwards in the paper is a pair composed of a N and a V which are related by one of the four semantic relations defined in the qualia structure in GL .</sentence>
				<definiendum id="0">relevant N-V pair</definiendum>
				<definiens id="0">a pair composed of a N and a V which are related by one of the four semantic relations defined in the qualia structure in GL</definiens>
			</definition>
			<definition id="5">
				<sentence>In this perspective , GL has been preferred to existing lexical resources such as WordNet ( Fellbaum , 1998 ) for two main reasons : lexical relations that we want to exhibit namely N-V links are unavailable in WordNet , which focuses on paradigmatic lexical relations ; WordNet is a domain-independent , static resource , which can not be used as such to describe lexical associations in specific texts , considering the great variability of semantic associations from one domain to another .</sentence>
				<definiendum id="0">GL</definiendum>
				<definiendum id="1">WordNet</definiendum>
				<definiens id="0">lexical relations that we want to exhibit namely N-V links are unavailable in WordNet , which focuses on paradigmatic lexical relations</definiens>
				<definiens id="1">a domain-independent , static resource</definiens>
			</definition>
			<definition id="6">
				<sentence>Among different machine learning techniques , we have chosen the Inductive Logic Programming framework ( ILP ) ( Muggleton and DeRaedt , 1994 ) to learn from a textual corpus N-V pairs that are related in terms of one of the relations defined in the qualia structure in GL .</sentence>
				<definiendum id="0">Inductive Logic Programming framework</definiendum>
				<definiendum id="1">ILP )</definiendum>
				<definiens id="0">a textual corpus N-V pairs that are related in terms of one of the relations defined in the qualia structure in GL</definiens>
			</definition>
			<definition id="7">
				<sentence>This corpus has been POS-tagged with the help of annotation tools developed in the MULTEXT project ( Armstrong , 1996 ) ; sentences and words are first segmented with MtSeg ; words are analyzed and lemmatized with Mmorph ( Petitpierre and Russell , 1998 ; Bouillon et al. , 1998 ) , and finally disambiguated by the Tatoo tool , a Hidden Markov Model tagger ( Armstrong et al. , 1995 ) .</sentence>
				<definiendum id="0">Tatoo tool</definiendum>
			</definition>
			<definition id="8">
				<sentence>where V_type indicates if the V is an infinitive form , etc. , distance corresponds to the number 6 ( nut , tighten ) .</sentence>
				<definiendum id="0">V_type</definiendum>
				<definiens id="0">an infinitive form</definiens>
			</definition>
			<definition id="9">
				<sentence>means that a N-V pair , in which the N is surrounded with an infinitive verb on its left ( VRBINF ) and a preposition de s ( P.DE ) on its right , in which the V is preceded by nothing 9 ( VID ) 1° and is an infinitive one ( VRBINF ) , in which no verb exists between the N and the V ( 0 ) , and in which the V appears before the N in the sentence ( POS ) , is a relevant pair ( for example , in ouvrir la porte de ... ) .</sentence>
				<definiendum id="0">N-V pair</definiendum>
				<definiendum id="1">VRBINF</definiendum>
				<definiens id="0">in which no verb exists between the N and the V ( 0 ) , and in which the V appears before the N in the sentence</definiens>
			</definition>
			<definition id="10">
				<sentence>means that a N-V pair , in which the N has nothing on its left ( VID ) and a preposition par n ( P_PAR ) on its right , in which the V is preceded by a noun ( NC ) and is a past participle ( VRBPP ) , in which no verb exists between the N and the V ( 0 ) , and in which the V appears after the N in the sentence ( NEG ) , is an irrelevant pair ( for example , in freinage par goupilles fendues ) .</sentence>
				<definiendum id="0">N-V pair</definiendum>
				<definiens id="0">in which the N has nothing on its left ( VID ) and a preposition par n ( P_PAR ) on its right , in which the V is preceded by a noun ( NC ) and is a past participle ( VRBPP ) , in which no verb exists between the N and the V ( 0 ) , and in which the V appears after the N in the sentence ( NEG ) , is an irrelevant pair</definiens>
			</definition>
			<definition id="11">
				<sentence>verbe ( V ) : conjugue ( V ) .</sentence>
				<definiendum id="0">V</definiendum>
			</definition>
			<definition id="12">
				<sentence>203 which means that N-V pairs ( i ) in which the category before the N is a locative preposition ( PREPOSITIONLIEU ( A ) ) , ( ii ) in which there is nothing after the N and before the V ( VIDE ( C ) for the second and third arguments ) , ( iii ) in which the V is an infinitive one ( VERBINF ( D ) ) , and ( iv ) in which there is no verb between the N and the V ( proximity denoted by P : aEs ( E ) 14 ) , are relevant .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">a locative preposition ( PREPOSITIONLIEU ( A ) ) , ( ii ) in which there is nothing after the N and before the V ( VIDE ( C ) for the second and third arguments ) , ( iii ) in which the</definiens>
			</definition>
			<definition id="13">
				<sentence>The theoretical generality of a generalized clause is the number of not generalized clauses ( E + ) that this clause can cover .</sentence>
				<definiendum id="0">theoretical generality</definiendum>
				<definiens id="0">the number of not generalized clauses ( E + ) that this clause can cover</definiens>
			</definition>
</paper>

		<paper id="1306">
			<definition id="0">
				<sentence>L is a set of labeled training examples .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">a set of labeled training examples</definiens>
			</definition>
			<definition id="1">
				<sentence>C is the current hypothesis .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the current hypothesis</definiens>
			</definition>
			<definition id="2">
				<sentence>The learning algorithm we use is a variant of the Inside-Outside algorithm that induces grammars expressed in the Probabilistic Lexicalized Tree Insertion Grammar representation ( Schabes and Waters , 1993 ; Hwa , 1998 ) .</sentence>
				<definiendum id="0">Inside-Outside algorithm</definiendum>
				<definiens id="0">induces grammars expressed in the Probabilistic Lexicalized Tree Insertion Grammar representation</definiens>
			</definition>
			<definition id="3">
				<sentence>Entropy measures the uncertainty of assigning a value to a random variable over a distribution .</sentence>
				<definiendum id="0">Entropy</definiendum>
				<definiens id="0">measures the uncertainty of assigning a value to a random variable over a distribution</definiens>
			</definition>
			<definition id="4">
				<sentence>The entropy H ( V ) is the expected negative log likelihood of random variable V : H ( V ) = -EX ( logdv ( V ) ) ) .</sentence>
				<definiendum id="0">entropy H</definiendum>
				<definiens id="0">the expected negative log likelihood of random variable V : H ( V ) = -EX ( logdv ( V ) ) )</definiens>
			</definition>
			<definition id="5">
				<sentence>TE ( s , G ) Ire ( s , G ) = length ( s ) '' We now derive the expression for TE ( s , G ) .</sentence>
				<definiendum id="0">G ) Ire (</definiendum>
			</definition>
			<definition id="6">
				<sentence>vEY Note that Pr ( v \ [ G ) reflects the probability of one particular parse tree , v , in the grammar out of all possible parse trees for all possible sentences that G accepts .</sentence>
				<definiendum id="0">vEY</definiendum>
			</definition>
			<definition id="7">
				<sentence>, s I G ) = Vr ( v I G ) Pr ( s I G ) Pr ( s I G ) '' Replacing the generic density function term in the entropy definition , we derive the expression for TE ( s , G ) , the tree entropy of s : TE ( s , G ) = H ( V ) -- -- Z PCv ) Iog2P ( V ) vEV = P ( s I a ) log2 ( ?</sentence>
				<definiendum id="0">G )</definiendum>
				<definiens id="0">s I G ) = Vr ( v I G ) Pr ( s I G ) Pr ( s I G ) '' Replacing the generic density function term in the entropy definition</definiens>
			</definition>
</paper>

		<paper id="0110">
			<definition id="0">
				<sentence>Let us consider the Japanese phrase `` KANASHII KIMOCHI ( sad feeling ) '' and `` YOROKOBI NO KIMOCHI ( feeling of delight ) '' as examples .</sentence>
				<definiendum id="0">KANASHII KIMOCHI</definiendum>
				<definiens id="0">feeling of delight ) '' as examples</definiens>
			</definition>
			<definition id="1">
				<sentence>`` KUMORI ( cloudiness ) '' is a natural phenomenon which can be pointed to concretely .</sentence>
				<definiendum id="0">KUMORI ( cloudiness ) ''</definiendum>
				<definiens id="0">a natural phenomenon which can be pointed to concretely</definiens>
			</definition>
			<definition id="2">
				<sentence>In this example , `` KUMORI NO ( of cloudiness ) '' modifies `` NISSU ( the amount ) , '' and does not represent a state but the possessor of the amount .</sentence>
				<definiendum id="0">NISSU</definiendum>
				<definiens id="0">the amount ) , ''</definiens>
			</definition>
			<definition id="3">
				<sentence>`` KOUGYOU TOSHI ( industry city ) '' is an example of a compound noun where the last word `` TOSHI ( city ) '' determines the properties .</sentence>
				<definiendum id="0">TOSHI</definiendum>
			</definition>
			<definition id="4">
				<sentence>`` Noun + NO '' structures , which have this kind of semantic ; category , are similar to adjectives and nominal adjectivals , as both represent the content of the human mind .</sentence>
				<definiendum id="0">Noun + NO '' structures</definiendum>
				<definiens id="0">both represent the content of the human mind</definiens>
			</definition>
			<definition id="5">
				<sentence>64 Table 3 : The modified nouns and adjectives , nominal adjectivals , and `` noun + NO '' collected in the semantic category , &lt; mental state &gt; Modified nouns KANJI ( feeling ) , KAN ( sensation ) , OMOI ( thought ) , KI ( intention ) , NEN ( inclination ) , KIMOCHI ( mind ) , KIBUN ( mood ) , KANJO ( emotion ) , JO ( passion ) Adjectives and nominal adjectivals AWARE_NA ( poor ) , IJIRASHII ( moving ) , HOKORASHII ( triumphant ) , KINODOKU_NA ( unfortunate ) , SHIAWASE_NA ( happy ) , ZANNEN_NA ( disappointing ) , URESHII ( pleasurable ) , ... and so on .</sentence>
				<definiendum id="0">URESHII</definiendum>
				<definiens id="0">The modified nouns and adjectives , nominal adjectivals , and `` noun + NO '' collected in the semantic category , &lt; mental state &gt; Modified nouns KANJI ( feeling )</definiens>
			</definition>
			<definition id="6">
				<sentence>b ) nominalizations HOSHIN ( self-defense ) , CHIKUZAI ( moneymaking ) , INTAI ( retirement ) , HIHAN ( criticism ) , HIYAKU ( rapid progress ) , ... and so on egory created by these adnominal constituents and their modified nouns `` Feeling . ''</sentence>
				<definiendum id="0">INTAI ( retirement</definiendum>
				<definiendum id="1">HIHAN</definiendum>
				<definiens id="0">( criticism ) , HIYAKU ( rapid progress</definiens>
			</definition>
			<definition id="7">
				<sentence>In this example , the semantic relation between `` KOUGYOUTOSHI NO ( of industry city ) '' and `` YUKYUTI ( the vacant land ) '' indicate the relation of possession so that it is not a semantic relation that adjectives can represent .</sentence>
				<definiendum id="0">YUKYUTI</definiendum>
				<definiens id="0">the vacant land ) '' indicate the relation of possession so that it is not a semantic relation that adjectives can represent</definiens>
			</definition>
			<definition id="8">
				<sentence>4Note that some words which are nouns in Japanese ( e.g. industry , high quality ) must be translated as adjectiw~ in English ( e.g. industrial , high-quality ) &lt; city-SUZUKA-SHI &gt; KOUGYOUTOSHI NO SUZUKA SHI ( industry city ) ( of ) ( SUZUKA city ) SUZUKA city which is an industrial city &lt; item-diamonds &gt; KOUKYUUHIN NO DAIYA ( high quality item ) ( of ) ( diamond ) Diamonds are a high-quality item &lt; company-IBM &gt; YURYOUGAISHA NO ( excellent company ) ( of ) IBM is an excellent company IBM When the modified noun is an instance of the last word of the modifying compound noun , the semantic function of the whole compound noun is similar to that of adjectives because , in this type of compound , we focus on the adjectival semantic element .</sentence>
				<definiendum id="0">noun</definiendum>
				<definiens id="0">industry city ) ( of ) ( SUZUKA city ) SUZUKA city which is an industrial city &lt; item-diamonds &gt; KOUKYUUHIN NO DAIYA ( high quality item ) ( of ) ( diamond ) Diamonds are a high-quality item &lt; company-IBM &gt; YURYOUGAISHA NO ( excellent company ) ( of ) IBM is an excellent company IBM When the modified</definiens>
			</definition>
</paper>

		<paper id="0744">
			<definition id="0">
				<sentence>Such a group is obviously compound of auxiliary and full-meaning verbs , e.g. budu se um~vat where budu is auxiliary verb ( like will in English ) , se is the reflexive pronoun and um~vat means to wash .</sentence>
				<definiendum id="0">budu</definiendum>
				<definiendum id="1">se</definiendum>
				<definiens id="0">auxiliary verb</definiens>
				<definiens id="1">the reflexive pronoun and um~vat means to wash</definiens>
			</definition>
			<definition id="1">
				<sentence>DESAM ( Pala et al. , 1997 ) , the annotated and fully disambiguated corpus of Czech newspaper texts , has been used as the source of learning data .</sentence>
				<definiendum id="0">DESAM</definiendum>
				<definiens id="0">the annotated and fully disambiguated corpus of Czech newspaper texts</definiens>
			</definition>
			<definition id="2">
				<sentence>The meanings of non-terminals used in the rule are following : 221 be ( ) represents auxiliary verb b~t , cond ( ) represents various forms of conditionals by , aby , kdyby , reflex_pron ( ) stands for reflexive pronoun se ( si ) , gap ( ) is a special predicate for manipulation with gaps , and k5 ( ) stands for arbitrary non-auxiliary verb .</sentence>
				<definiendum id="0">non-terminals</definiendum>
				<definiendum id="1">be ( )</definiendum>
				<definiendum id="2">cond ( )</definiendum>
				<definiendum id="3">reflex_pron ( )</definiendum>
				<definiendum id="4">gap ( )</definiendum>
				<definiendum id="5">k5 ( )</definiendum>
				<definiens id="0">auxiliary verb b~t</definiens>
				<definiens id="1">various forms of conditionals by , aby , kdyby</definiens>
				<definiens id="2">reflexive pronoun se ( si )</definiens>
				<definiens id="3">a special predicate for manipulation with gaps</definiens>
				<definiens id="4">arbitrary non-auxiliary verb</definiens>
			</definition>
			<definition id="3">
				<sentence>They used transformation-based learning and achieved recall and precision rates 93 % for base noun phrase ( non-recursive noun phrase ) and 88 % for chunks that partition the sentence .</sentence>
				<definiendum id="0">base noun phrase</definiendum>
				<definiens id="0">non-recursive noun phrase ) and 88 % for chunks that partition the sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>Second , Czech language is a free word-order language what implies that the process of recognition of the verb group structure is much more difficult .</sentence>
				<definiendum id="0">Czech language</definiendum>
				<definiens id="0">a free word-order language</definiens>
			</definition>
</paper>

		<paper id="0727">
			<definition id="0">
				<sentence>ALLiS ( Architecture for Learning Linguistic Structure ) ( D6jean , 2000a ) , ( D6jean , 2000b ) is a symbolic machine learning system .</sentence>
				<definiendum id="0">ALLiS ( Architecture for Learning Linguistic Structure )</definiendum>
				<definiens id="0">a symbolic machine learning system</definiens>
			</definition>
			<definition id="1">
				<sentence>CASS : the CASS system ( Abney , 1996 ) provides a very fast parser which uses Regular Expression Grammar .</sentence>
				<definiendum id="0">CASS</definiendum>
				<definiendum id="1">CASS system</definiendum>
				<definiens id="0">uses Regular Expression Grammar</definiens>
			</definition>
			<definition id="2">
				<sentence>LT TTT : the last tool tried , LT TTT ( Grover et al. , 1999 ) , is a text tokenisation system and toolset .</sentence>
				<definiendum id="0">LT TTT</definiendum>
				<definiens id="0">a text tokenisation system and toolset</definiens>
			</definition>
			<definition id="3">
				<sentence>Using XML properties , the grammar has easily access to all the levels of the document ( word , tag , phrase , and higher structures ) .</sentence>
				<definiendum id="0">levels of the document</definiendum>
				<definiens id="0">word , tag , phrase , and higher structures</definiens>
			</definition>
			<definition id="4">
				<sentence>LT TTT is a good trade-off between the rapidity of CASS and the rich formalism of XFST .</sentence>
				<definiendum id="0">LT TTT</definiendum>
				<definiens id="0">a good</definiens>
			</definition>
			<definition id="5">
				<sentence>XML Path Language provides an easy way of addressing nodes of an XML document .</sentence>
				<definiendum id="0">XML Path Language</definiendum>
			</definition>
</paper>

		<paper id="0724">
			<definition id="0">
				<sentence>Weighted Probability Distribution Voting ( WPDV ) is a newly designed machine learning algorithm , for which research is currently aimed at the determination of good weighting schemes .</sentence>
				<definiendum id="0">Weighted Probability Distribution Voting</definiendum>
				<definiendum id="1">WPDV</definiendum>
				<definiens id="0">a newly designed machine learning algorithm , for which research is currently aimed at the determination of good weighting schemes</definiens>
			</definition>
			<definition id="1">
				<sentence>Weighted Probability Distribution Voting ( WPDV ) is a supervised learning approach to classification .</sentence>
				<definiendum id="0">Weighted Probability Distribution Voting</definiendum>
				<definiendum id="1">WPDV</definiendum>
			</definition>
			<definition id="2">
				<sentence>To be exact , the probability of class C for Fcase is estimated as a weighted sum over all possible subsets Fsub of Fcase : w /req ( CJF b ) P ( C ) = N ( C ) /req ( F b ) FsubCFcase with the frequencies ( freq ) measured on the training data , and N ( C ) a normalizing factor such that ~/5 ( C ) = 1 .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the frequencies ( freq ) measured on the training data</definiens>
			</definition>
			<definition id="3">
				<sentence>A measure related to this is Information Gain , which represents the difference between the entropy of the choice with and without knowledge of the presence of a feature ( cf. Quinlan ( 1986 ) ) .</sentence>
				<definiendum id="0">Information Gain</definiendum>
			</definition>
			<definition id="4">
				<sentence>In order to determine the quality of the WPDV system , using first order weights as described above , I run a series of experiments , using tasks introduced by Daelemans et al. ( 1999 ) : 3 The Part-of-speech tagging task ( POS ) is to determine a wordclass tag on the basis of disambiguated tags of two preceding tokens and undisambiguated tags for the focus and two following tokens .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">to determine a wordclass tag on the basis of disambiguated tags of two preceding tokens and undisambiguated tags for the focus and two following tokens</definiens>
			</definition>
			<definition id="5">
				<sentence>The PP attachment task ( PP ) is prepositional phrase attachment to either a preceding verb or a preceding noun , on the basis of the verb , the noun , the preposition in question and the head noun of the prepositional complement .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">prepositional phrase attachment to either a preceding verb or a preceding noun</definiens>
			</definition>
			<definition id="6">
				<sentence>121 Table 3 : Accuracies for the PP task ( with the training set ah tested in leave-one-out mode ) Table 4 : Accuracies for the NP task ( with the training set ah tested in leave-one-out mode ) Weighting scheme Test set ah i Comparison Naive Bayes TiMBL ( k=l ) Maccent ( freq=2 ; iter=150 ) Maccent ( freq=l ; iter=300 ) WPDV 0 ~h order weights 1 k~ 82.68 82.64 83.43 81.97 81.00 80.25 79.41 79.79 80.83 82.26 81.46 80.76 82.30 81.30 WPDV initial 18t order tune = ah ( 21GR ) 82.89 83.64 82.38 tune = i ( 15GR ) 82.82 83.81 82.55 tune = j ( llGR ) 82.60 83.26 82.76 WPDV with hill-climbing tune -- ah ( 19 steps ) 83.10 83.72 82.68 tune = i ( 18 steps ) 82.95 84.06 82.80 tune = j ( 16 steps ) 82.65 83.10 82.93 Weighting scheme i Test set ah i j Comparison Naive Bayes TiMBL ( k=3 ) Maccent ( freq=2 ; iter=150 ) Maccent ( freq=l ; iter=300 ) WPDV 0 th order weights 1 k~ 96.52 96.49 98.34 98.22 97.89 97.75 97.66 97.45 97.56 97.77 97.69 97.74 97.97 97.87 WPDV initial I st order tune = ah ( 380GR ) 98.19 98.38 98.26 tune = i ( 60GR ) 98.14 98.39 98.17 tune = j ( 360GR ) 98.19 98.38 98.27 WPDV with hill-climbing tune = ah ( 50 steps ) 98.36 98.54 98.44 tune = i ( 34 steps ) 98.25 98.57 98.33 tune = j ( 12 steps ) 98.19 98.38 98.27 comparison systems .</sentence>
				<definiendum id="0">Test set ah i j Comparison Naive Bayes TiMBL ( k=3 ) Maccent</definiendum>
				<definiens id="0">th order weights 1 k~ 96.52 96.49 98.34 98.22 97.89 97.75 97.66 97.45 97.56 97.77 97.69 97.74 97.97 97.87 WPDV initial I st order tune</definiens>
			</definition>
</paper>

		<paper id="0708">
			<definition id="0">
				<sentence>embedding the NP : If the category of the constituent embedding the NP is associated with one or more functional tags , they are used as features .</sentence>
				<definiendum id="0">embedding the NP</definiendum>
				<definiens id="0">If the category of the constituent embedding the NP is associated with one or more functional tags , they are used as features</definiens>
			</definition>
			<definition id="1">
				<sentence>We used six values for the countability feature : FC ( fully countable ) for nouns that have both singular and plural forms and can be directly modified by numerals and modifiers such as many ; UC ( uncountable ) for nouns that have no plural form and can be modified by much ; SC ( strongly countable ) for nouns that are more often countable than uncountable ; WC ( weakly countable ) for nouns that are more often uncountable than countable ; and PT ( pluralia tantum ) for nouns that only have plural forms , such as for example , scissors ( Bond et al. , 1994 ) .</sentence>
				<definiendum id="0">FC</definiendum>
				<definiendum id="1">SC</definiendum>
				<definiendum id="2">PT</definiendum>
			</definition>
			<definition id="2">
				<sentence>Memory-based learning reads all training instances into memory and classifies test instances by extrapolating a class from the most similar instance ( s ) in memory .</sentence>
				<definiendum id="0">Memory-based learning</definiendum>
				<definiens id="0">reads all training instances into memory and classifies test instances by extrapolating a class from the most similar instance ( s ) in memory</definiens>
			</definition>
			<definition id="3">
				<sentence>The first , IB1 is a k-nearest neighbour algorithm .</sentence>
				<definiendum id="0">IB1</definiendum>
				<definiens id="0">a k-nearest neighbour algorithm</definiens>
			</definition>
</paper>

		<paper id="0406">
			<definition id="0">
				<sentence>Procedural ( how-to ) training was optional , but 50 I I I I I I approximately 70 users opted to receive a oneon-one hands-on demonstration ( about fortyfive minutes in length ) on texts that the new user had retrieved .</sentence>
				<definiendum id="0">Procedural</definiendum>
				<definiens id="0">fortyfive minutes in length ) on texts that the new user had retrieved</definiens>
			</definition>
			<definition id="1">
				<sentence>Defined as `` an optimized body of coordinated on-line methods and resources that enable and maintain a person 's or an organization 's performance , '' EPSS interventions range from simple help systems to intelligent wizard-types of support .</sentence>
				<definiendum id="0">EPSS</definiendum>
				<definiens id="0">an optimized body of coordinated on-line methods and resources that enable and maintain a person 's or an organization 's performance , ''</definiens>
			</definition>
</paper>

		<paper id="0405">
			<definition id="0">
				<sentence>Generating an effective summary requires the summarizer to select , evaluate , order and aggregate items of information according to their relevance to a particular subject or purpose .</sentence>
				<definiendum id="0">effective summary</definiendum>
				<definiens id="0">requires the summarizer to select , evaluate , order and aggregate items of information according to their relevance to a particular subject or purpose</definiens>
			</definition>
			<definition id="1">
				<sentence>Following is a list of requirements for multi-document summarization : • clustering : The ability to cluster similar documents and passages to find related information .</sentence>
				<definiendum id="0">clustering</definiendum>
				<definiens id="0">The ability to cluster similar documents and passages to find related information</definiens>
			</definition>
			<definition id="2">
				<sentence>Relevant novelty is a metric for minimizing redundancy and maximizing both relevance and diversity .</sentence>
				<definiendum id="0">Relevant novelty</definiendum>
				<definiens id="0">a metric for minimizing redundancy and maximizing both relevance and diversity</definiens>
			</definition>
			<definition id="3">
				<sentence>/ eonlent ( Pij ) = ~ wtvp , ( W ) WEPij tirnesiarap ( D , ,a=tim , ) timestamp ( Di ) time_sequ_ence ( Di , D ) = timestamp ( Dmaxtime ) tiraestamp ( D , nintime ) clusters_selected ( C~ , S ) = IC~ n L.J cv=l v , w : P , , , ~ES documents_selected ( Di , S ) = ~ = where Sire1 is the similarity metric for relevance ranking Sim~ is the anti-redundancy metric D is a document collection P is the passages from the documents in that collection ( e.g. , ~j is passage j from document Di ) Q is a query or user profile R = IR ( D , P , Q , 8 ) , i.e. , the ranked list of passages from documents retrieved by an IR system , given D , P , Q and a ' relevance threshold O , below which it will not retrieve passages ( O can be degree of match or number of passages ) .</sentence>
				<definiendum id="0">~ES documents_selected</definiendum>
				<definiendum id="1">Sire1</definiendum>
				<definiendum id="2">Sim~</definiendum>
				<definiens id="0">the similarity metric for relevance ranking</definiens>
				<definiens id="1">a query or user profile R = IR</definiens>
				<definiens id="2">the ranked list of passages from documents retrieved by an IR system</definiens>
			</definition>
			<definition id="4">
				<sentence>_5 '' is the subset of passages in R already selected R\S is the set difference , i.e. , the set of as yet unselected passages in R ' C is the set of passage clusters for the set of documents ( 7vw is the subset of clusters of ( 7 that contains passage Pvw ( 7~ is the subset of clusters that contain passages from document D~ Ikl is the number of passages in the individual cluster k IC~ , ~ N Cijl is the number of clusters in the intersection of ( 7 , , , nand ( Tij wi .</sentence>
				<definiendum id="0">_5 ''</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">7~</definiendum>
				<definiendum id="3">N Cijl</definiendum>
				<definiens id="0">the subset of passages in R already selected R\S is the set difference , i.e. , the set of as yet unselected passages in R '</definiens>
				<definiens id="1">the set of passage clusters for the set of documents</definiens>
				<definiens id="2">the subset of clusters that contain passages from document D~ Ikl is the number of passages in the individual cluster k IC~</definiens>
				<definiens id="3">the number of clusters in the intersection of ( 7 , , , nand ( Tij wi</definiens>
			</definition>
			<definition id="5">
				<sentence>and end apartheid , the system of racial segregation in which South Africa 's black majority has no vote in national affairs .</sentence>
				<definiendum id="0">end apartheid</definiendum>
				<definiens id="0">the system of racial segregation in which South Africa 's black majority has no vote in national affairs</definiens>
			</definition>
			<definition id="6">
				<sentence>The ANC wants a simple one-man , one-vote majority rule system , while the government claims that will lead to black domination and insists on constitutional protection of the rights of minorities , including the whites .</sentence>
				<definiendum id="0">ANC</definiendum>
				<definiens id="0">wants a simple one-man , one-vote majority rule system</definiens>
			</definition>
</paper>

		<paper id="1432">
			<definition id="0">
				<sentence>Artificial neural networks are a classification technique that is robust and resistant to noisy input , and learns to classify inputs on the basis of training examples , without specific rules that describe how the classification is to be done .</sentence>
				<definiendum id="0">Artificial neural networks</definiendum>
				<definiens id="0">a classification technique that is robust and resistant to noisy input , and learns to classify inputs on the basis of training examples , without specific rules that describe how the classification is to be done</definiens>
			</definition>
			<definition id="1">
				<sentence>The hotel Regina is a small hotel .</sentence>
				<definiendum id="0">hotel Regina</definiendum>
				<definiens id="0">a small hotel</definiens>
			</definition>
			<definition id="2">
				<sentence>The hotel Regina has thirty single rooms The hotel Regina is an expensive hotel .</sentence>
				<definiendum id="0">hotel Regina</definiendum>
				<definiens id="0">an expensive hotel</definiens>
			</definition>
			<definition id="3">
				<sentence>Kukich has an example of two phrases in her system corresponding to the exact same semantic values ( or `` sememes '' ) .</sentence>
				<definiendum id="0">Kukich</definiendum>
				<definiens id="0">has an example of two phrases in her system corresponding to the exact same semantic values</definiens>
			</definition>
			<definition id="4">
				<sentence>Our model can now be represented like this : 241 Database ( DB ) Facts about hotels \ ] I Discourse Model ... I ~ ( Level of generalisation , \ ] I '' '- '' '' -~- '' '' '' ' -- \ ] ~_____ .</sentence>
				<definiendum id="0">-~- '' '' ''</definiendum>
				<definiens id="0">generalisation , \ ] I '' '- '' ''</definiens>
			</definition>
			<definition id="5">
				<sentence>The biological brain consists of a great number of interacting elements , neuron .</sentence>
				<definiendum id="0">biological brain</definiendum>
				<definiens id="0">consists of a great number of interacting elements , neuron</definiens>
			</definition>
			<definition id="6">
				<sentence>100 PRICE 0001101 RABBIT 0001110 REASONABLE 0001111 REGINA 0010000 ROOM 0010001 SINGLE ROOM 0010010 SMALL In table 2 are some example inputs and outputs , a 1 represents activation on an input or output node .</sentence>
				<definiendum id="0">1</definiendum>
				<definiens id="0">represents activation on an input or output node</definiens>
			</definition>
			<definition id="7">
				<sentence>6 ) The hotel Ariadne is a cheap hotel in the city centre .</sentence>
				<definiendum id="0">hotel Ariadne</definiendum>
				<definiens id="0">a cheap hotel in the city centre</definiens>
			</definition>
			<definition id="8">
				<sentence>If we assume that the output ofNN I now serves as the input for NN lI , this will be our desired output ( only the activated nodes are shown here ) : II : REGINA^SG^HAVE^20^SINGLE ROOM O1 : REGINA^DEF^SG^HAVE^SG^20^PLUR^SIN GLE ROOM^INDEF^PLUR After post-processing : The hotel Regina has nventy single rooms 12 : REG1N AASINGASMALLAHOTELASING 2 ) 3 ) The hotel Regina is a small hotel .</sentence>
				<definiendum id="0">hotel Regina</definiendum>
				<definiens id="0">a small hotel</definiens>
			</definition>
			<definition id="9">
				<sentence>01 : REG1N A^DE F^SINGABEAS1NG^SMA LL^SIN GAINDEF^HOTEL^INDEFASING After post-processing : The Hotel Regina is a small hotel and so on ... 244 After a look-up in an English dictionary we find that the singular form of BE is is , and the plural form of SINGLE_ROOM is single rooms .</sentence>
				<definiendum id="0">Hotel Regina</definiendum>
				<definiens id="0">a small hotel</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>Grounding is the process by which information contributed by participants in interaction is taken to have entered the 'common ground ' , or mutual knowledge of the participants ( Clark &amp; Schaefer 1989 , Clark 1996 , Traum 1994 ) .</sentence>
				<definiendum id="0">Grounding</definiendum>
				<definiens id="0">the process by which information contributed by participants in interaction is taken to have entered the 'common ground ' , or mutual knowledge of the participants</definiens>
			</definition>
			<definition id="1">
				<sentence>CGUs , which represent grounding at the 'illocutionary level ' ( Clark 1996 ) , have been proposed as a meso-level dialogue structure roughly the same level that dialogue games ( Carletta et al , 1997 ) or adjacency pairs ( eg .</sentence>
				<definiendum id="0">CGUs</definiendum>
				<definiens id="0">a meso-level dialogue structure roughly the same level that dialogue games ( Carletta et al , 1997 ) or adjacency pairs</definiens>
			</definition>
			<definition id="2">
				<sentence>c ) CGUs which contained more than one acknowledgment by the same speaker ( as in ( 3 ) below ) d ) CGUs which negotiated information at different levels of communication lower than the 'illocutionary ' level ( eg .</sentence>
				<definiendum id="0">c ) CGUs</definiendum>
				<definiendum id="1">level</definiendum>
				<definiens id="0">contained more than one acknowledgment by the same speaker ( as in ( 3 ) below ) d ) CGUs which negotiated information at different levels of communication lower than the 'illocutionary '</definiens>
			</definition>
</paper>

		<paper id="1413">
			<definition id="0">
				<sentence>l will call it the hyperonym problem \ [ ... \ ] : When lemma A 's meaning entails lemma B 's meaning , B is a hyperonym of A. If A 's conceptual conditions are met , then B 's are necessarily also satisfied .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">When lemma A 's meaning entails lemma B 's meaning</definiens>
				<definiens id="1">a hyperonym of A. If A 's conceptual conditions are met , then B 's are necessarily also satisfied</definiens>
			</definition>
			<definition id="1">
				<sentence>The relation of hyperonymy is generally regarded as transitive : If A is a hyperonym of B , and B is a hyperonym of C , then A is a hyperonym of C. Following common practice , we call A a direct hyperonym of B , while it is only an indirect hyperonym of C. The same holds for the inverse relation , hyponymy .</sentence>
				<definiendum id="0">direct hyperonym</definiendum>
				<definiens id="0">If A is a hyperonym of B , and B is a hyperonym of C , then A is a hyperonym</definiens>
			</definition>
			<definition id="2">
				<sentence>ate here ; the less specific No , Terry is a man is better since it does not prompt the hearer to draw ally conclusions as to tile particular relevance of Terry 's marital status for the present Lc0 : n~ersa , tion , Reiter ?</sentence>
				<definiendum id="0">Terry</definiendum>
				<definiens id="0">a man is better since it does not prompt the hearer to draw ally conclusions as to tile particular relevance of Terry 's marital status for the present Lc0 : n~ersa , tion</definiens>
			</definition>
			<definition id="3">
				<sentence>-In conclusion , NLG systems , employ a mixture of constraints and preferences in their approaches to hyperonymy .</sentence>
				<definiendum id="0">NLG systems</definiendum>
				<definiens id="0">employ a mixture of constraints and preferences in their approaches to hyperonymy</definiens>
			</definition>
			<definition id="4">
				<sentence>coneepCu : at.van @ - : lexical inhe~itance important is the generic level , which holds orDue to the very different motivations , different dinary everyday names like cat , apple , church , cup .</sentence>
				<definiendum id="0">coneepCu</definiendum>
				<definiendum id="1">generic level</definiendum>
				<definiens id="0">holds orDue to the very different motivations , different dinary everyday names like cat , apple , church , cup</definiens>
			</definition>
</paper>

		<paper id="1209">
			<definition id="0">
				<sentence>Word sense disambiguafion ( WSD ) is a difficult problem in natural language processing .</sentence>
				<definiendum id="0">Word sense disambiguafion ( WSD</definiendum>
				<definiens id="0">a difficult problem in natural language processing</definiens>
			</definition>
			<definition id="1">
				<sentence>Keywords word sense disambiguation , Hownet , sememe , co-occurrence Word sense disarnbiguafion ( WSD ) is one of • the most difficult problems in NLP .</sentence>
				<definiendum id="0">WSD )</definiendum>
				<definiens id="0">one of • the most difficult problems in NLP</definiens>
			</definition>
			<definition id="2">
				<sentence>Hownet is a knowledge base which was released recently on Intemet .</sentence>
				<definiendum id="0">Hownet</definiendum>
				<definiens id="0">a knowledge base which was released recently on Intemet</definiens>
			</definition>
			<definition id="3">
				<sentence>The sememe co-occurrence frequency database is a table of two dimension .</sentence>
				<definiendum id="0">sememe co-occurrence frequency database</definiendum>
			</definition>
			<definition id="4">
				<sentence>score ( S , C ) ( 1 ) = score ( SS , C ' ) score ( SS , GlobalSS ) Where S is a sense item of polysemouse word W , C is the context containing W , SS is the corresponding sememe set of S , C ' is the set of sememe expansion of words in C and GlobalSS is the sememe set that containing all of the sememe defined in Hownet .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">SS</definiendum>
				<definiendum id="3">C '</definiendum>
				<definiendum id="4">GlobalSS</definiendum>
				<definiens id="0">a sense item of polysemouse word W</definiens>
				<definiens id="1">the context containing W ,</definiens>
				<definiens id="2">the set of sememe expansion of words in C</definiens>
				<definiens id="3">the sememe set that containing all of the sememe defined in Hownet</definiens>
			</definition>
			<definition id="5">
				<sentence>N ~ g ( SU ) , g ( SU ' ) ( 7 ) Where f ( SU , SU ' ) is the co-occurrence frequency corresponding to sememe pair ( SU , SU ' ) in SCFD .</sentence>
				<definiendum id="0">f ( SU</definiendum>
				<definiendum id="1">SU ' )</definiendum>
				<definiens id="0">the co-occurrence frequency corresponding to sememe pair ( SU , SU ' ) in SCFD</definiens>
			</definition>
			<definition id="6">
				<sentence>VSU , VSU '' When disambiguation , we tag the sememe T that satisfying the following equation to polysemous word W. T = arg max score ( S , C ) ( 10 ) s Database We have created a mutual information database according to ( 7 ) , ( 8 ) and ( 9 ) Here is some examples : The examples in table 1 have a high mutual information .</sentence>
				<definiendum id="0">Here</definiendum>
				<definiens id="0">satisfying the following equation to polysemous word W. T = arg max score ( S , C ) ( 10 ) s Database We have created a mutual information database according to</definiens>
			</definition>
</paper>

		<paper id="1431">
			<definition id="0">
				<sentence>GTAG is a multilingual text generation formalism derived from the Tree Adjoining Grammar model ( ( Joshi and al. , 1975 ) , ( Shabes and Shieber,1994 ) ) .</sentence>
				<definiendum id="0">GTAG</definiendum>
				<definiens id="0">a multilingual text generation formalism derived from the Tree Adjoining Grammar model ( (</definiens>
			</definition>
			<definition id="1">
				<sentence>Then , we will give a presentation of the CLEF generation algorithm that yields a nearly-surfacic syntactic representation from the conceptual representation ( a post-processing phase takes care of the final output ) .</sentence>
				<definiendum id="0">CLEF generation algorithm</definiendum>
				<definiens id="0">a post-processing phase takes care of the final output )</definiens>
			</definition>
			<definition id="2">
				<sentence>GTAG specifies an additional constraint on the model : the existence of three generic concepts used to divide the conceptual domain , as follows .</sentence>
				<definiendum id="0">GTAG</definiendum>
				<definiens id="0">specifies an additional constraint on the model : the existence of three generic concepts used to divide the conceptual domain</definiens>
			</definition>
			<definition id="3">
				<sentence>o Entities , representing objects ( individuals ) of the world .</sentence>
				<definiendum id="0">Entities</definiendum>
				<definiens id="0">representing objects ( individuals ) of the world</definiens>
			</definition>
			<definition id="4">
				<sentence>o G-derivation structures , which correspond to underspecified derivation trees .</sentence>
				<definiendum id="0">o G-derivation structures</definiendum>
			</definition>
			<definition id="5">
				<sentence>RAGS ( rags , 1999 ) proposes a standard architecture for the data , but leaves the ~Eeature ; or on .</sentence>
				<definiendum id="0">RAGS</definiendum>
				<definiens id="0">proposes a standard architecture for the data , but leaves the ~Eeature ; or on</definiens>
			</definition>
			<definition id="6">
				<sentence>_ : imposes some syntactic constraint ) .</sentence>
				<definiendum id="0">_</definiendum>
				<definiens id="0">imposes some syntactic constraint )</definiens>
			</definition>
</paper>

		<paper id="1218">
			<definition id="0">
				<sentence>In order to measure the distance between clusters of the same part of speech , we use the following equations : 1 \ [ ~'\ [ `` 1~/I ( 1 ) disa ( Ai , Aj ) and lie , U % l ( 2 ) where O~ is the distribution environment of ~ and is make up of nouns which can be collocated with distribution environment composed of adjectives collocated with N i .</sentence>
				<definiendum id="0">O~</definiendum>
				<definiens id="0">the distribution environment of ~ and is make up of nouns which can be collocated with distribution environment composed of adjectives collocated with N i</definiens>
			</definition>
			<definition id="1">
				<sentence>The coUocational degree is defined as the ratio of the existing collocation instances between the cluster and its distribution envffonment to all possible collocations generated by them .</sentence>
				<definiendum id="0">coUocational degree</definiendum>
				<definiens id="0">the ratio of the existing collocation instances between the cluster and its distribution envffonment to all possible collocations generated by them</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus , deg~ = I ( a¢ I a 4 , ¢ ¢ , ,a¢ c } l 1411- , I ( 3 ) and degN~ -I ( -v IN , ,v , nV , sC } l ( 4 ) IN , till where C is the set of all existing instances .</sentence>
				<definiendum id="0">I</definiendum>
				<definiendum id="1">degN~ -I</definiendum>
				<definiendum id="2">C</definiendum>
				<definiens id="0">the set of all existing instances</definiens>
			</definition>
			<definition id="3">
				<sentence>According to MDL , the best probability model for a given set of data is a model that uses the shortest code length for encoding the model itself and the given data relative to it \ [ 4\ ] \ [ 5\ ] .</sentence>
				<definiendum id="0">best probability model</definiendum>
				<definiens id="0">a model that uses the shortest code length for encoding the model itself and the given data relative to it</definiens>
			</definition>
			<definition id="4">
				<sentence>The objective function is defined as the sum of the code length for the model ( `` model description length '' ) and that for the data ( `` data description length '' ) .</sentence>
				<definiendum id="0">objective function</definiendum>
				<definiens id="0">the sum of the code length for the model ( `` model description length '' ) and that for the data ( `` data description length '' )</definiens>
			</definition>
</paper>

		<paper id="0743">
			<definition id="0">
				<sentence>The learning system is equipped with a UG and associated parameters , encoded as a Unification-Based Generalised Categorial Grammar , and a learning algorithm that fixes the values of the parameters to a particular language .</sentence>
				<definiendum id="0">learning algorithm</definiendum>
				<definiens id="0">encoded as a Unification-Based Generalised Categorial Grammar</definiens>
				<definiens id="1">fixes the values of the parameters to a particular language</definiens>
			</definition>
			<definition id="1">
				<sentence>The learning system is composed of a language learner equipped with a UG and a learning algorithm that updates the initial parameter settings , based on exposure to a corpus of utterances .</sentence>
				<definiendum id="0">learning algorithm</definiendum>
				<definiens id="0">updates the initial parameter settings , based on exposure to a corpus of utterances</definiens>
			</definition>
			<definition id="2">
				<sentence>The UG consists of principles and parameters , and the latter are set according to the linguistic environment ( Chomsky 1981 ) .</sentence>
				<definiendum id="0">UG</definiendum>
			</definition>
			<definition id="3">
				<sentence>We concentrate on the description of word order parameters , which reiiect the basic order in which constituents occur in different languages .</sentence>
				<definiendum id="0">word order parameters</definiendum>
				<definiens id="0">reiiect the basic order in which constituents occur in different languages</definiens>
			</definition>
			<definition id="4">
				<sentence>In figure 1 , subjdir is a parameter specifying that the np subject is to be combined backwards .</sentence>
				<definiendum id="0">subjdir</definiendum>
				<definiens id="0">a parameter specifying that the np subject is to be combined backwards</definiens>
			</definition>
			<definition id="5">
				<sentence>Among the subtypes , we have subjdir , which specifies the direction of the subject , vargdir , which specifies the direction of the other verbal arguments and ndir , which specifies the direction of nominal caregories .</sentence>
				<definiendum id="0">vargdir</definiendum>
				<definiens id="0">specifies the direction of the subject</definiens>
				<definiens id="1">specifies the direction of nominal caregories</definiens>
			</definition>
			<definition id="6">
				<sentence>Then an intransitive verb , which has the direction of the subject specified by subjdir , will be defined as S/NP , with subjdir having default value forward .</sentence>
				<definiendum id="0">intransitive verb</definiendum>
				<definiens id="0">has the direction of the subject specified by subjdir</definiens>
			</definition>
			<definition id="7">
				<sentence>As a result , intransitive verbs are defined as S\NP , figure 1 , for the grammar to account for these sentences .</sentence>
				<definiendum id="0">S\NP</definiendum>
				<definiens id="0">intransitive verbs</definiens>
			</definition>
</paper>

		<paper id="1435">
			<definition id="0">
				<sentence>ILEX is a tool for dynamic browsing of databasedefined information : it allows a user to browse through the information in a database using hypertext .</sentence>
				<definiendum id="0">ILEX</definiendum>
				<definiens id="0">a tool for dynamic browsing of databasedefined information : it allows a user to browse through the information in a database using hypertext</definiens>
			</definition>
			<definition id="1">
				<sentence>We start initially with a relational database , as defined by a set of tab-delimited database files , plus some minimal semantics .</sentence>
				<definiendum id="0">relational database</definiendum>
				<definiens id="0">defined by a set of tab-delimited database files , plus some minimal semantics</definiens>
			</definition>
			<definition id="2">
				<sentence>Mapping Domain taxonomy onto Upper Model : ILEX uses an Upper Model ( a domainindependent semantic taxonomy , see Bateman ( 1990 ) ) , which supports the grammatical expression of entities , e.g. , selection of pronoun , differentiation between mass and count entities , between things and qualities , etc .</sentence>
				<definiendum id="0">Upper Model</definiendum>
			</definition>
</paper>

		<paper id="1317">
			<definition id="0">
				<sentence>For example , largest ( X , Goal ) states that the object X satisfies Goal and is the largest object that does so , using the appropriate measure of size for objects of its type ( e.g. area for states , population for cities ) .</sentence>
				<definiendum id="0">largest ( X , Goal )</definiendum>
				<definiens id="0">the object X satisfies Goal and is the largest object that does so , using the appropriate measure of size for objects of its type</definiens>
			</definition>
			<definition id="1">
				<sentence>Our semantic parser employs a shift-reduce architecture that maintains a stack of previously built semantic constituents and a buffer of remaining words in the input .</sentence>
				<definiendum id="0">semantic parser</definiendum>
				<definiens id="0">employs a shift-reduce architecture that maintains a stack of previously built semantic constituents and a buffer of remaining words in the input</definiens>
			</definition>
			<definition id="2">
				<sentence>INTRODUCE pushes a predicate onto the stack based on a word appearing in the input and information about its possible meanings in the lexicon .</sentence>
				<definiendum id="0">INTRODUCE</definiendum>
				<definiens id="0">pushes a predicate onto the stack based on a word appearing in the input</definiens>
			</definition>
			<definition id="3">
				<sentence>DROP_CONJ ( or LIFT_CON J ) takes a predicate on the stack and puts it into one of the arguments of a meta-predicate on the stack .</sentence>
				<definiendum id="0">DROP_CONJ</definiendum>
				<definiendum id="1">LIFT_CON J )</definiendum>
				<definiens id="0">takes a predicate on the stack and puts it into one of the arguments of a meta-predicate on the stack</definiens>
			</definition>
			<definition id="4">
				<sentence>Most ILP methods use a set-covering method to learn one clause ( rule ) at a time and construct clauses using either a strictly top-down ( general to specific ) or bottom-up ( specific to general ) search through the space of possible rules ( Lavrac and Dzeroski , 1994 ) .</sentence>
				<definiendum id="0">top-down</definiendum>
				<definiendum id="1">bottom-up</definiendum>
				<definiens id="0">general to specific</definiens>
				<definiens id="1">specific to general</definiens>
			</definition>
			<definition id="5">
				<sentence>135 Procedure Tabulate Input : t ( X , , ... , Xn ) : the target concept to learn ~+ : the ( B examples ~- : the ( 9 examples Output : Q : a queue of learned theories Theoryo : = { E '¢'-I E E ~+ } /* the initial theory */ T ( No ) : = Theoryo /* theory of node No */ C ( No ) : = empty /* the clause being built */ Q : = \ [ No\ ] /* the search queue */ Repeat CO ¢ Fo_ .</sentence>
				<definiendum id="0">... , Xn )</definiendum>
				<definiens id="0">a queue of learned theories Theoryo : = { E '¢'-I E E ~+ } /* the initial theory */ T ( No ) : = Theoryo /* theory of node No */ C ( No ) : = empty /* the clause being built */ Q : = \</definiens>
			</definition>
			<definition id="6">
				<sentence>We measure accuracy using the m-estimate ( Cestnik , 1990 ) , a smoothed measure of accuracy on the training data which in the case of a two-class problem is defined as : accuracy ( H ) s + m. p+ = ( 1 ) n , -Irrt where s is the n-tuber of positive examples covered by the hypothesis H , n is the total number of examples covered , p+ is the prior probability of the class ( 9 , and m is a smoothing parameter .</sentence>
				<definiendum id="0">s</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">p+</definiendum>
				<definiendum id="3">m</definiendum>
				<definiens id="0">a smoothed measure of accuracy on the training data which in the case of a two-class problem is defined as : accuracy ( H ) s + m. p+ = ( 1 ) n , -Irrt</definiens>
				<definiens id="1">the n-tuber of positive examples covered by the hypothesis H</definiens>
				<definiens id="2">the total number of examples covered</definiens>
				<definiens id="3">the prior probability of the class</definiens>
				<definiens id="4">a smoothing parameter</definiens>
			</definition>
			<definition id="7">
				<sentence>The size of a theory is the sum of the sizes of its clauses .</sentence>
				<definiendum id="0">size of a theory</definiendum>
				<definiens id="0">the sum of the sizes of its clauses</definiens>
			</definition>
			<definition id="8">
				<sentence>The metric M ( H ) used as the search heuristic is defined as : M ( H ) = accuracy ( H ) + C log 2 size ( H ) ( 4 ) where C is a constant used to control the relative weight of accuracy vs. complexity .</sentence>
				<definiendum id="0">metric M ( H )</definiendum>
				<definiens id="0">M ( H ) = accuracy ( H ) + C log 2 size ( H ) ( 4 ) where C is a constant used to control the relative weight of accuracy vs. complexity</definiens>
			</definition>
			<definition id="9">
				<sentence>__.2_ &gt; ( 6 ) p+n where p is the number of positive examples covered by the clause , n is the number of negative examples covered and -1 &lt; /~ _ &lt; 1 is a parameter .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of positive examples covered by the clause</definiens>
			</definition>
			<definition id="10">
				<sentence>A parser is a relation Parser C_ Sentences x Queries where Sentences and Queries are the sets of natural language sentences and database queries respectively .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">a relation Parser C_ Sentences x Queries where Sentences and Queries are the sets of natural language sentences and database queries respectively</definiens>
			</definition>
			<definition id="11">
				<sentence>Suppose our learned parser has n different parsing actions , the ith action a/is a function a/ ( s ) : ISi -+ OSi where ISi G S is the set of states to which the action is applicable and OSi C_ S is the set of states constructed by the action .</sentence>
				<definiendum id="0">ISi G S</definiendum>
				<definiens id="0">the set of states to which the action is applicable and OSi C_ S is the set of states constructed by the action</definiens>
			</definition>
			<definition id="12">
				<sentence>Suppose q = an+l ( Sm ) , we have : P ( q 6 Q ( l ) ) ( 10 ) = P ( s~ • F~ ) ... = P ( s , n • FS + l sm-1 •/St , _a ) ... P ( s~ • OS~_ , I sj-1 • Is~_ , ) ... P ( s2 • Ob~ , Is1 • IS~ , ) P ( 'I • IS~ , ) where ak denotes the index of which action is applied at the kth step .</sentence>
				<definiendum id="0">ak</definiendum>
				<definiens id="0">the index of which action is applied at the kth step</definiens>
			</definition>
			<definition id="13">
				<sentence>po , ( i ) -I ~ AkP ( ~Cs ) 60b~ ~ I h~ ) hk~H~ ( 12 ) where s is a given parse state , pos ( i ) is the position of the action ai in the list of actions applicable to state s , Ak and 0 &lt; /~ &lt; 1 are weighting parameters , z Hi is the set of hypotheses learned for the action ai , and ~k A~ = 1 .</sentence>
				<definiendum id="0">s</definiendum>
				<definiendum id="1">z Hi</definiendum>
				<definiens id="0">a given parse state</definiens>
				<definiens id="1">the set of hypotheses learned for the action ai , and ~k A~ = 1</definiens>
			</definition>
			<definition id="14">
				<sentence>/9 is the probability that a negative example is mislabelled and its value can be estimated given # ( in equation ( 6 ) ) and the total nnrnber of positive and negative examples .</sentence>
				<definiendum id="0">/9</definiendum>
				<definiens id="0">the probability that a negative example is mislabelled and its value can be estimated given # ( in equation ( 6 ) ) and the total nnrnber of positive and negative examples</definiens>
			</definition>
			<definition id="15">
				<sentence>Prob-Parser ( B ) is the probabilistic parser using a beam width of B. TABULATE is CHILL using the TABULATE induction algorithm with determ ; nistic parsing .</sentence>
				<definiendum id="0">Prob-Parser ( B )</definiendum>
				<definiens id="0">the probabilistic parser using a beam width</definiens>
			</definition>
</paper>

		<paper id="0735">
			<definition id="0">
				<sentence>After the instance base is built , new ( test ) instances axe classified by matching them to all instances in the instance base , and by calculating with each match the distance between the new instance X and the memory instance Y. The most basic metric for patterns with symbolic features is the Overlap metric given in equation 1 ; where A ( X , Y ) is the distance between patterns X and Y , represented by n features , wi is a weight for feature i , and 5 is the distance per feature .</sentence>
				<definiendum id="0">Y )</definiendum>
				<definiendum id="1">wi</definiendum>
				<definiens id="0">new ( test ) instances axe classified by matching them to all instances in the instance base , and by calculating with each match the distance between the new instance X and the memory instance Y. The most basic metric for patterns with symbolic features</definiens>
				<definiens id="1">the distance between patterns X and Y , represented by n features ,</definiens>
			</definition>
			<definition id="1">
				<sentence>The Information Gain of feature f is measured by computing the difference in uncertainty ( i.e. entropy ) between the situations without and with knowledge of the value of that feature .</sentence>
				<definiendum id="0">Information Gain of feature f</definiendum>
				<definiens id="0">measured by computing the difference in uncertainty ( i.e. entropy ) between the situations without and with knowledge of the value of that feature</definiens>
			</definition>
</paper>

		<paper id="0801">
			<definition id="0">
				<sentence>The required linguistic knowledge resource is a lexical ontology that has the words in the target language and a listing of their associated senses .</sentence>
				<definiendum id="0">linguistic knowledge resource</definiendum>
				<definiens id="0">a lexical ontology that has the words in the target language and a listing of their associated senses</definiens>
			</definition>
			<definition id="1">
				<sentence>WordNet is a lexical ontology a variant on semantic networks with more of a hierarchical structure , even though some of the nodes can have multiple parents that was manually constructed for the English language .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a lexical ontology a variant on semantic networks with more of a hierarchical structure</definiens>
			</definition>
			<definition id="2">
				<sentence>Moreover , we decided to use more than one language since polysemous words can be translated in different ways in different languages , i.e. an ambiguous word that has two senses could be translated into two distinct words into one language but into one word in another language .</sentence>
				<definiendum id="0">i.e.</definiendum>
				<definiens id="0">an ambiguous word that has two senses could be translated into two distinct words into one language but into one word in another language</definiens>
			</definition>
			<definition id="3">
				<sentence>GIZA is an intermediate program in a statistical machine translation system , EGYPT .</sentence>
				<definiendum id="0">GIZA</definiendum>
				<definiens id="0">an intermediate program in a statistical machine translation system</definiens>
			</definition>
			<definition id="4">
				<sentence>Due to processing limitations , GIZA ignores sentences that exceed 50 words in length , therefore it ignored -3000 sentences on average per parallel corpus alignment .</sentence>
				<definiendum id="0">GIZA</definiendum>
				<definiens id="0">ignores sentences that exceed 50 words in length</definiens>
			</definition>
			<definition id="5">
				<sentence>Finally , we compressed the source-target list to have the following format : Src wdi trgt_nnl , trgt_nnz , ... , trgt_nn , where Src wdi is a word J in the source corpus and trgt_nnj is the noun 4 it aligned to in the target corpus .</sentence>
				<definiendum id="0">trgt_nnj</definiendum>
				<definiens id="0">a word J in the source corpus and</definiens>
			</definition>
			<definition id="6">
				<sentence>R assigns a confidence score based on shared information content of the sense combinations , which is measured via the most informative subsumer in the taxonomy .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">assigns a confidence score based on shared information content of the sense combinations , which is measured via the most informative subsumer in the taxonomy</definiens>
			</definition>
			<definition id="7">
				<sentence>FG is the French translation of the Brown corpus rendered by the MT system GL ; GG is the German translation by GL ; SG is the Spanish translation by GL ; SS is the Spanish translation by the MT system SYS ; and MSp is the merged Spanish translations from both NIT systems .</sentence>
				<definiendum id="0">FG</definiendum>
				<definiendum id="1">GG</definiendum>
				<definiendum id="2">SG</definiendum>
				<definiendum id="3">SS</definiendum>
				<definiendum id="4">MSp</definiendum>
				<definiens id="0">the French translation of the Brown corpus rendered by the MT system GL</definiens>
				<definiens id="1">the German translation by GL</definiens>
				<definiens id="2">the Spanish translation by GL</definiens>
				<definiens id="3">the Spanish translation by the MT system SYS</definiens>
				<definiens id="4">the merged Spanish translations from both NIT systems</definiens>
			</definition>
			<definition id="8">
				<sentence>RBL is the random baseline , while DBL is the default baseline .</sentence>
				<definiendum id="0">RBL</definiendum>
				<definiendum id="1">DBL</definiendum>
				<definiens id="0">the random baseline</definiens>
			</definition>
			<definition id="9">
				<sentence>Ide classifies translation types based on how much they vary in what they align with in translation , for example , if a word aligns with a single word or a phrase or nothing , etc .</sentence>
				<definiendum id="0">Ide</definiendum>
				<definiens id="0">classifies translation types based on how much they vary in what they align with in translation</definiens>
			</definition>
</paper>

		<paper id="0717">
			<definition id="0">
				<sentence>Finch and Chater ( 1992 ) , ( 1995 ) and Schfitze ( 1993 ) , ( 1997 ) use a set of features derived from the co-occurrence statistics of common words together with standard clustering and information extraction techniques .</sentence>
				<definiendum id="0">Finch</definiendum>
				<definiens id="0">use a set of features derived from the co-occurrence statistics of common words together with standard clustering and information extraction techniques</definiens>
			</definition>
			<definition id="1">
				<sentence>I therefore chose to use an objective statistical measure , the perplexity of a very simple finite state model , to compare the tags generated with this clustering technique against the BNC tags , which uses the CLAWS-4 tag set ( Leech et al. , 1994 ) which had 76 tags .</sentence>
				<definiendum id="0">BNC tags</definiendum>
				<definiens id="0">uses the CLAWS-4 tag set ( Leech et al. , 1994 ) which had 76 tags</definiens>
			</definition>
</paper>

		<paper id="0703">
			<definition id="0">
				<sentence>Here , we use an extended and improved version of the system described by Dedina and Nusbaum ( 1991 ) , which consists of four components : the ( uncompressed and previously aligned ) lexical database , the matcher which compares the target input to all the words in the database , the pronunciation lattice ( a data structure representing possible pronunciations ) , and the decision function , which selects the 'best ' pronunciation among the set of possible ones .</sentence>
				<definiendum id="0">pronunciation lattice</definiendum>
				<definiendum id="1">decision function</definiendum>
				<definiens id="0">selects the 'best ' pronunciation among the set of possible ones</definiens>
			</definition>
			<definition id="1">
				<sentence>Pronunciation Lattice : A node of the lattice represents a matched letter , Li , at some position , i , in the input .</sentence>
				<definiendum id="0">Pronunciation Lattice</definiendum>
				<definiens id="0">A node of the lattice represents a matched letter</definiens>
			</definition>
			<definition id="2">
				<sentence>Decision Function : A possible pronunciation for the input corresponds to a complete path through its lattice , from Start to End nodes , with the output string assembled by concatenating the phoneme labels on the nodes/arcs in the order that they are traversed .</sentence>
				<definiendum id="0">Decision Function</definiendum>
				<definiens id="0">nodes , with the output string assembled by concatenating the phoneme labels on the nodes/arcs in the order that they are traversed</definiens>
			</definition>
</paper>

		<paper id="0741">
			<definition id="0">
				<sentence>INTHELEX learns theories , from positive and negative examples described in the same language .</sentence>
				<definiendum id="0">INTHELEX</definiendum>
				<definiens id="0">learns theories , from positive and negative examples described in the same language</definiens>
			</definition>
			<definition id="1">
				<sentence>In the formal representation of texts , we used the following descriptors : • sent ( el , e2 ) e2 is a sentence fi : om el • subj ( el , e2 ) e2 is the subject of el • obj ( el , e2 ) e2 is the ( direct ) object of el • indirect_obj ( el , e2 ) e2 is an indirect object of el • rel_subj ( el , e2 ) e2 is a clause related to the subject el • rel_obj ( el , e2 ) e2 is a clause related to the object el • verb ( el , e2 ) e2 is the verb of el • lemma ( e2 ) word e2 has lemma lemma • infinite ( e2 ) verb e2 is in an infinite mood • finite ( e2 ) verb e2 is in a finite mood • affirmative ( e2 ) verb e2 is in an affirmative mood • negative ( e2 ) verb e2 is in a negative mood • np ( el , e2 ) e2 is a 2nd level NP of el • pp ( el , e2 ) e2 is a PP of el where lemma is a meta-predicate .</sentence>
				<definiendum id="0">e2 ) e2</definiendum>
				<definiendum id="1">e2 ) e2</definiendum>
				<definiendum id="2">e2 ) e2</definiendum>
				<definiendum id="3">lemma</definiendum>
				<definiens id="0">a sentence fi : om el • subj ( el , e2 ) e2 is the subject of el • obj ( el ,</definiens>
				<definiens id="1">the ( direct ) object of el • indirect_obj ( el ,</definiens>
				<definiens id="2">an indirect object of el • rel_subj ( el , e2 ) e2 is a clause related to the subject el</definiens>
				<definiens id="3">the verb of el • lemma ( e2 ) word e2 has lemma lemma • infinite ( e2 ) verb e2 is in an infinite mood</definiens>
				<definiens id="4">in an affirmative mood • negative ( e2 ) verb</definiens>
				<definiens id="5">a 2nd level NP of el • pp ( el ,</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus , the following Horn clause is an instance of an example : imports ( example ) ~-sent ( example , el ) , subj ( example , e2 ) , np ( e2 , e3 ) , impresa ( e3 ) , rel_subj ( el , e4 ) , verb ( e4 , e5 ) , specializzare ( e5 ) , infinite ( e5 ) , affirmative ( e5 ) , pp ( e4 , e6 ) , distrubuzione ( e6 ) , componente ( e6 ) , verb ( el , eT ) , interessare ( e7 ) , finite ( eT ) , affirmative ( eT ) , indirect_obj ( el , e8 ) , pp ( e8 , e9 ) , importazione ( eg ) , macchina ( e9 ) , produzione ( e9 ) , ombrello ( eg ) .</sentence>
				<definiendum id="0">subj</definiendum>
				<definiens id="0">an instance of an example : imports ( example ) ~-sent ( example , el )</definiens>
			</definition>
</paper>

		<paper id="1305">
			<definition id="0">
				<sentence>Topic analysis consists of two main tasks : topic identification and text segmentation ( based on topic changes ) .</sentence>
				<definiendum id="0">Topic analysis</definiendum>
				<definiens id="0">consists of two main tasks : topic identification and text segmentation</definiens>
			</definition>
			<definition id="1">
				<sentence>A segmentation method ( e.g. , TextTiling ( Hearst , 1997 ) ) generally segments a text into blocks ( paragraphs ) in accord with topic changes within the text , but it does not identify ( or label ) by itself the topics discussed in each of the blocks .</sentence>
				<definiendum id="0">segmentation method</definiendum>
				<definiens id="0">segments a text into blocks ( paragraphs ) in accord with topic changes within the text</definiens>
			</definition>
			<definition id="2">
				<sentence>The first level is a probability distribution of topics ( topic distribution ) .</sentence>
				<definiendum id="0">first level</definiendum>
				<definiens id="0">a probability distribution of topics ( topic distribution )</definiens>
			</definition>
			<definition id="3">
				<sentence>The second level consists of probability distributions of words included within topics ( word distributions ) .</sentence>
				<definiendum id="0">second level</definiendum>
			</definition>
			<definition id="4">
				<sentence>Then , for each topic k E K , we define a probability distribution of words P ( wik ) : ~ , ew P ( wlk ) = not included in k. We next define a Stochastic Topic Model ( STM ) as a finite mixture model , which is a linear combination of the word probability distributions P ( w\ [ k ) , with the topic distribution P ( k ) being used as the coefficient vector .</sentence>
				<definiendum id="0">probability distribution</definiendum>
				<definiendum id="1">Stochastic Topic Model</definiendum>
				<definiendum id="2">STM</definiendum>
				<definiens id="0">a linear combination of the word probability distributions P ( w\ [ k ) , with the topic distribution P ( k ) being used as the coefficient vector</definiens>
			</definition>
			<definition id="5">
				<sentence>Hence , STM is a natural representation of statistical word occurrence based on topics .</sentence>
				<definiendum id="0">STM</definiendum>
				<definiens id="0">a natural representation of statistical word occurrence based on topics</definiens>
			</definition>
			<definition id="6">
				<sentence>SC ( x m : M ) can be interpreted as the amount information included in x n relative to M. The tnbution which has specified paxameters but unspecified parameter values .</sentence>
				<definiendum id="0">SC</definiendum>
				<definiens id="0">the amount information included in x n relative to M. The tnbution which has specified paxameters but unspecified parameter values</definiens>
			</definition>
			<definition id="7">
				<sentence>36 MDL ( Minimum Description Length ) principle is a model selection criterion which asserts that , for a given data sequence , the lower a model 's SC value , the greater its likelihood of being a model which would have actually generated the data .</sentence>
				<definiendum id="0">MDL</definiendum>
				<definiendum id="1">Minimum Description Length ) principle</definiendum>
			</definition>
			<definition id="8">
				<sentence>~s denotes the number O 's in s m. The SC value of w m relative to a model D in which the presence or absence of w is dependent on those of s is then calculated as SC ( w ( s.u log ) : = + ~logT~ + + ( m '' sH ( -m'-'~'~'~ W ½1°g-m-='~ W l°gr ) 2~ where ms + denotes the number of l 's in wm ' , and w~+s the number of l 's in w m~ , .</sentence>
				<definiendum id="0">~s</definiendum>
				<definiendum id="1">SC ( w</definiendum>
				<definiens id="0">the number O 's in s m. The SC value of w m relative to a model D in which the presence</definiens>
			</definition>
			<definition id="9">
				<sentence>For example , Hofmann 's is of order O ( \ ] DIIWI2 ) , while ours is only of O ( ID I + \ ] WI2 ) , where IDI denotes the number of texts and IW\ ] the number of words .</sentence>
				<definiendum id="0">IDI</definiendum>
				<definiens id="0">the number of texts and IW\ ] the number of words</definiens>
			</definition>
			<definition id="10">
				<sentence>Our topic analysis consists of three processes : a pre-process called 'topic spotting , ' text segmentation , and topic identification .</sentence>
				<definiendum id="0">topic analysis</definiendum>
				<definiens id="0">consists of three processes : a pre-process called 'topic spotting , ' text segmentation , and topic identification</definiens>
			</definition>
			<definition id="11">
				<sentence>In topic SNote that the quantity within \ [ -- -\ ] in ( 1 ) is ( empirical ) mutual inyormation , which is an effective measure for word co-occurrence calculation ( cf. , ( Brown et al. , 1992 ) ) .</sentence>
				<definiendum id="0">mutual inyormation</definiendum>
				<definiens id="0">an effective measure for word co-occurrence calculation</definiens>
			</definition>
			<definition id="12">
				<sentence>The Shannon information of word w in text t is defined as I ( w ) = -N ( w ) logP ( w ) , where N ( w ) denotes the frequency of w in t , and P ( w ) the probability of the occurrence of w as estimated from corpus data .</sentence>
				<definiendum id="0">Shannon information of word w</definiendum>
				<definiendum id="1">N ( w )</definiendum>
				<definiendum id="2">P ( w )</definiendum>
				<definiens id="0">I ( w ) = -N ( w ) logP ( w )</definiens>
				<definiens id="1">the frequency of w in t</definiens>
				<definiens id="2">the probability of the occurrence of w as estimated from corpus data</definiens>
			</definition>
			<definition id="13">
				<sentence>, s ) , we calculate PU ) ( k ) PU ) ( wlk ) P ( Z+l ) ( klw ) = Ek~P ( ' ) ( k ) P ( ' ) ( wlk ) p ( l+l ) ( k ) = N ( w ) PU+l ) ( klw ) N P ( Z+l ) ( w\ ] k ) = N ( w ) P ( l+l ) ( k\ [ w ) ~wew g ( w ) P ( ~+ l ) ( k\ [ w ) N ( w ) denotes the frequency of word w in the data ; N = ~ew N ( w ) .</sentence>
				<definiendum id="0">P ( l+l )</definiendum>
				<definiens id="0">k ) PU ) ( wlk ) P ( Z+l ) ( klw ) = Ek~P ( ' ) ( k ) P ( ' ) ( wlk ) p ( l+l ) ( k ) = N ( w ) PU+l ) ( klw ) N P ( Z+l ) ( w\ ] k ) = N ( w )</definiens>
				<definiens id="1">the frequency of word w in the data ; N = ~ew N ( w )</definiens>
			</definition>
			<definition id="14">
				<sentence>Finite mixture models have been used in a variety of applications in text processing ( e.g. , ( Li and Yamanishi , 1997 ; Nigam et al. , 2000 ; Hofmann , 1999 ) ) , indicating that they are essential to text processing .</sentence>
				<definiendum id="0">Finite mixture models</definiendum>
				<definiens id="0">used in a variety of applications in text processing</definiens>
			</definition>
			<definition id="15">
				<sentence>For example , Li and Yamanishi propose to employ in text classification a mixture model ( Li and Yamanishi , 1997 ) defined over categories : P ( WIC ) = ~ P ( klc ) P ( wlk ) , w e W , c e C , kEK where W denotes a set of words , and C a set of categories .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">employ in text classification a mixture model ( Li and Yamanishi , 1997 ) defined over categories : P ( WIC ) = ~ P ( klc ) P ( wlk ) , w e W , c e C</definiens>
				<definiens id="1">a set of words</definiens>
			</definition>
			<definition id="16">
				<sentence>We have evaluated the performance of our topic analysis method ( STM ) in terms of three aspects : topic structure adequacy , text segmentation accuracy , and topic identification accuracy .</sentence>
				<definiendum id="0">STM</definiendum>
				<definiens id="0">topic structure adequacy , text segmentation accuracy , and topic identification accuracy</definiens>
			</definition>
			<definition id="17">
				<sentence>split of the data 'Apte split , ' which consists of 9603 texts for training and 3299 texts for test .</sentence>
				<definiendum id="0">'Apte split</definiendum>
				<definiens id="0">consists of 9603 texts for training and 3299 texts for test</definiens>
			</definition>
			<definition id="18">
				<sentence>When the key words for main topics contained at least one of the identification words , we viewed that text as having the corresponding main topic .</sentence>
				<definiendum id="0">corresponding main topic</definiendum>
				<definiens id="0">When the key words for main topics contained at least one of the identification words</definiens>
			</definition>
			<definition id="19">
				<sentence>Error probability is a metric for evaluating segmentation results proposed in ( Allan et ai. , 1998 ; Beeferman etal. , 1999 ) .</sentence>
				<definiendum id="0">Error probability</definiendum>
				<definiens id="0">a metric for evaluating segmentation results</definiens>
			</definition>
			<definition id="20">
				<sentence>Topic analysis consists of two main tasks : text segmentation and topic identification .</sentence>
				<definiendum id="0">Topic analysis</definiendum>
				<definiens id="0">consists of two main tasks : text segmentation and topic identification</definiens>
			</definition>
</paper>

		<paper id="1418">
			<definition id="0">
				<sentence>1 ILEX is a tool for •dynamic browsing of databasedefined information : it allows a user to browse through the information in a database using hyper1Earlier ILEX papers have been based on Ilex 2.0 , which was relatively domain-dependent .</sentence>
				<definiendum id="0">ILEX</definiendum>
				<definiens id="0">a tool for •dynamic browsing of databasedefined information : it allows a user to browse through the information in a database</definiens>
			</definition>
			<definition id="1">
				<sentence>A link file consists of two columns only , one identifying the entity , the other identifying the filler ( the name of the attribute is provided in the first line of the file , see figure 3 ) .</sentence>
				<definiendum id="0">link file</definiendum>
				<definiens id="0">consists of two columns only , one identifying the entity , the other identifying the filler</definiens>
			</definition>
			<definition id="2">
				<sentence>® Fact : each entry in a record defines what we call a fact about that entity , a A fact consists of three parts : its predicate name , and two arguments , being the entity of the record , and the filler of the slot .</sentence>
				<definiendum id="0">A fact</definiendum>
				<definiens id="0">consists of three parts : its predicate name , and two arguments , being the entity of the record , and the filler of the slot</definiens>
			</definition>
			<definition id="3">
				<sentence>ILEX allows the user to assert generalisations about types , e.g. , that Arts and Crafts jewellery tends to be made using enamel ( see section 5.4 ) .</sentence>
				<definiendum id="0">ILEX</definiendum>
				<definiens id="0">allows the user to assert generalisations about types</definiens>
			</definition>
			<definition id="4">
				<sentence>136 ( def-lexical-item : name professor-noun : spelling `` professor '' : grammatical-features ( common-noun count-noun ) ) Figure 5 : A Sample Lexical item Specification ... . ( defobject-structurejewellery '' ... .. : class : generic-type : subclass : generic-type : designer : entity-id : style : entity-id : material : generic-type : date : date : place : string : dimension : dimension ) Figure 6 : Specifying Field Semantics ( def-predicateClass : expression ( : verb be-verb ) ) Figure 8 : Simple Fact Expression Each field in a database record contains a string of characters .</sentence>
				<definiendum id="0">string</definiendum>
				<definiens id="0">Simple Fact Expression Each field in a database record contains a string of characters</definiens>
			</definition>
			<definition id="5">
				<sentence>With the level of domain semantics specified so far , ILEX is able to produce texts such as the two below , which provides an initial page describing database entity BUNDY01 , and then a subsequent page when more information was requested ( this from the Personnel domain ( Nowson , 1999 ) ) : o Page 1 : Alan Bundy is located in room F1 , which is in South Bridge .</sentence>
				<definiendum id="0">ILEX</definiendum>
				<definiens id="0">provides an initial page describing database entity BUNDY01</definiens>
			</definition>
</paper>

		<paper id="0101">
			<definition id="0">
				<sentence>Tagger dog-N herding-V sheepN dog-N , V ; herding-N , V ; sheep-N Morphology dog herd-ING sheep ( same ) NP Pattems small child wearing a small , child , wearing , hat hat green , swirls ( modifiers de-coupled from head green swirls nouns ) cat jumping into the air : cat-N ( 7 senses ) jumping-V ( 13 senses ) air-N ( 13 senses ) Semantic Expansion ( WordNetbased ) cat , jumping , air cat-N , V ( 9 senses ) jumping-N , V , Adj ( 16 senses ) air-N , V , Adj ( 20 senses ) Names George Bush , A1 Gore George , Bush , AI , Gore ( matches bush , gore ) Locations Arlington , Virginia Arlington , Virginia ( matches other Arlingtons in New England other states ) New , England ( matches England , new ) How do we determine what syntactic complexity is ?</sentence>
				<definiendum id="0">V , Adj</definiendum>
				<definiens id="0">cat-N ( 7 senses ) jumping-V ( 13 senses ) air-N ( 13 senses ) Semantic Expansion ( WordNetbased ) cat , jumping</definiens>
				<definiens id="1">16 senses ) air-N ,</definiens>
			</definition>
			<definition id="1">
				<sentence>The PictureQuest system uses a WordNetbased semantic net to expand the caption data .</sentence>
				<definiendum id="0">PictureQuest system</definiendum>
			</definition>
</paper>

		<paper id="0309">
			<definition id="0">
				<sentence>The Communicator handles a complex travel task , consisting of air travel , hotels and car reservations .</sentence>
				<definiendum id="0">Communicator</definiendum>
				<definiens id="0">handles a complex travel task , consisting of air travel , hotels and car reservations</definiens>
			</definition>
			<definition id="1">
				<sentence>Call-flow based systems ( more generally , graph-based systems ) handle the complexity of dialog management by explicitly enumerating all possible dialog states , as well as allowable transitions between states .</sentence>
				<definiendum id="0">Call-flow based systems</definiendum>
				<definiens id="0">graph-based systems ) handle the complexity of dialog management by explicitly enumerating all possible dialog states</definiens>
			</definition>
			<definition id="2">
				<sentence>The product consists of a tree of handlers , each handler encapsulates processing relevant to a particular schema .</sentence>
				<definiendum id="0">handler</definiendum>
				<definiens id="0">encapsulates processing relevant to a particular schema</definiens>
			</definition>
			<definition id="3">
				<sentence>A handler encapsulates knowledge n~cessary for interacting about a specific information slot , including specification of user and system language and of interactions with domain agents .</sentence>
				<definiendum id="0">handler</definiendum>
			</definition>
			<definition id="4">
				<sentence>We define tightly bound as those schema that users expect to discuss interchangeably , without explicit shifts in conversational focus .</sentence>
				<definiendum id="0">tightly bound</definiendum>
				<definiens id="0">those schema that users expect to discuss interchangeably , without explicit shifts in conversational focus</definiens>
			</definition>
</paper>

		<paper id="0504">
			<definition id="0">
				<sentence>MEI is one of the four projects selected for the Johns Hopkins University ( JHU ) Summer Workshop 2000.1 Our research focus is on the integration of speech recognition and embedded translation technologies in the context of translingual speech retrieval .</sentence>
				<definiendum id="0">MEI</definiendum>
				<definiens id="0">one of the four projects selected for the Johns Hopkins University ( JHU ) Summer Workshop 2000.1 Our research focus is on the integration of speech recognition and embedded translation technologies in the context of translingual speech retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>Mandarin , also known as Putonglma ( `` the common language '' ) , is the most widely used dialect .</sentence>
				<definiendum id="0">Mandarin</definiendum>
				<definiendum id="1">Putonglma ( ``</definiendum>
				<definiens id="0">the common language '' ) , is the most widely used dialect</definiens>
			</definition>
			<definition id="2">
				<sentence>Chinese is a syllable-based language , where each syllable carries a lexical tone .</sentence>
				<definiendum id="0">Chinese</definiendum>
				<definiens id="0">a syllable-based language , where each syllable carries a lexical tone</definiens>
			</definition>
			<definition id="3">
				<sentence>The structure of Mandarin ( base ) syllables is ( CG ) V ( X ) , where ( CG ) the syllable onset C the initial consonant , G is the optional medial glide , V is the nuclear vowel , and X is the coda ( which may be a glide , alveolar nasal or velar nasal ) .</sentence>
				<definiendum id="0">CG</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">G</definiendum>
				<definiendum id="3">V</definiendum>
				<definiendum id="4">X</definiendum>
				<definiens id="0">the syllable onset</definiens>
				<definiens id="1">the initial consonant</definiens>
				<definiens id="2">the optional medial glide</definiens>
				<definiens id="3">the nuclear vowel</definiens>
				<definiens id="4">the coda ( which may be a glide , alveolar nasal or velar nasal )</definiens>
			</definition>
			<definition id="4">
				<sentence>5 In its written form , Chinese is a sequence of characters .</sentence>
				<definiendum id="0">Chinese</definiendum>
				<definiens id="0">a sequence of characters</definiens>
			</definition>
			<definition id="5">
				<sentence>The problem of identifying the words string in a character sequence is known as the segmentation / tokenization problem .</sentence>
				<definiendum id="0">tokenization problem</definiendum>
				<definiens id="0">The problem of identifying the words string in a character sequence</definiens>
			</definition>
			<definition id="6">
				<sentence>Word segmentation is a natural by-product of large vocabulary Mandarin speech recognition , and white space provides word boundaries for the English queries .</sentence>
				<definiendum id="0">Word segmentation</definiendum>
				<definiens id="0">a natural by-product of large vocabulary Mandarin speech recognition</definiens>
			</definition>
			<definition id="7">
				<sentence>We thus plan to report ranked retrieval measures of effectiveness such as average precision in addition to the detection statistics ( miss and false alarm ) typically reported in TDT .</sentence>
				<definiendum id="0">detection statistics</definiendum>
				<definiens id="0">miss and false alarm</definiens>
			</definition>
</paper>

		<paper id="1404">
			<definition id="0">
				<sentence>An XML document is a mixture of structure ( the tags ) and surface ( text between the tags ) .</sentence>
				<definiendum id="0">XML document</definiendum>
				<definiens id="0">a mixture of structure ( the tags ) and surface ( text between the tags )</definiens>
			</definition>
			<definition id="1">
				<sentence>Authoring is seen as a. top-down interactive process of step-wise refinement of the root nonterminal ( corresponding to the whole document ) where the author iteratively selects a rule for expanding a lBut see ( Wood , 1995 : Prescod , 1998 ) for discussions of the differences .</sentence>
				<definiendum id="0">Authoring</definiendum>
			</definition>
			<definition id="2">
				<sentence>Thus , the author is terlingua ( specific to the class of documents being always overtly working in the language s/he nows , modelled ) , and it is the responsibility of appropribut is implicitly building a language-independent ate `` rendering '' mechanisms to produce actual text representation of the document content .</sentence>
				<definiendum id="0">terlingua</definiendum>
				<definiens id="0">specific to the class of documents being always overtly working in the language s/he nows</definiens>
			</definition>
			<definition id="3">
				<sentence>of ... .. of doeuments , -oand -- extends this-practice towards an the Multilingual Document Authoring ( MDA ) sysaccount of their m.icro-structure .</sentence>
				<definiendum id="0">-oand --</definiendum>
				<definiens id="0">extends this-practice towards an the Multilingual Document Authoring ( MDA ) sysaccount of their m.icro-structure</definiens>
			</definition>
			<definition id="4">
				<sentence>An example of such a tree is addressl ( city2 , country2 ) 4This kind of semantic representation stands i-n contrast to some representations commonly used in NLP , which tend to emphasize the fine-grained predicate-argument structure of sentences independently of the productivity of such analyses .</sentence>
				<definiendum id="0">NLP</definiendum>
				<definiens id="0">tend to emphasize the fine-grained predicate-argument structure of sentences independently of the productivity of such analyses</definiens>
			</definition>
			<definition id="5">
				<sentence>Documents Our corpus consists in drug notices extracted froln `` 'Le VIDAL®de la Famille '' ( Editions du Vidal .</sentence>
				<definiendum id="0">Documents Our corpus</definiendum>
				<definiens id="0">consists in drug notices extracted froln `` 'Le VIDAL®de la Famille '' ( Editions du Vidal</definiens>
			</definition>
</paper>

		<paper id="1307">
			<definition id="0">
				<sentence>In the last decade , LTAG has been used in several aspects of natural language understanding ( e.g. , parsing ( Schabes , 1990 ; Srinivas , 1997 ) , semantics ( Joshi and Vijay-Shanker , 1999 ; Kallmeyer and Joshi , 1999 ) , and discourse ( Webber and Joshi , 1998 ) ) and a number of NLP applications ( e.g. , machine translation ( Palmer et al. , 1998 ) , information retrieval ( Chandrasekar and Srinivas , 1997 ) , and generation ( Stone and Doran , 1997 ; McCoy et al. , 1992 ) .</sentence>
				<definiendum id="0">LTAG</definiendum>
				<definiendum id="1">discourse</definiendum>
				<definiendum id="2">generation</definiendum>
				<definiens id="0">a number of NLP applications ( e.g. , machine translation ( Palmer et al. , 1998 ) , information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>For each phrase structure in a Treebank , our system creates a fully bracketed phrase structure , a set of elementary trees and a derivation tree .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">creates a fully bracketed phrase structure , a set of elementary trees and a derivation tree</definiens>
			</definition>
			<definition id="2">
				<sentence>We choose LTAGs as our target grammars ( i.e. , the grammars to be extracted ) because LTAGs possess many desirable properties , such as the Extended Domain of Locality , which allows the encapsulation of all arguments of \ [ he anchor associated with an etree .</sentence>
				<definiendum id="0">target grammars</definiendum>
				<definiens id="0">the grammars to be extracted</definiens>
			</definition>
			<definition id="3">
				<sentence>An auxiliary tree represents recursive structure and has a unique leaf node , called the foot node , which has the same syntactic category as the root node .</sentence>
				<definiendum id="0">auxiliary tree</definiendum>
				<definiendum id="1">foot node</definiendum>
				<definiens id="0">has the same syntactic category as the root node</definiens>
			</definition>
			<definition id="4">
				<sentence>The core of LexTract is an extraction algorithm that takes a Treebank sentence such as the one in Figure 5 and produces the trees ( elementary trees , derived trees and derivation trees ) such as the ones in Figure 3 .</sentence>
				<definiendum id="0">extraction algorithm</definiendum>
				<definiens id="0">takes a Treebank sentence such as the one in Figure 5 and produces the trees ( elementary trees , derived trees and derivation trees ) such as the ones in Figure 3</definiens>
			</definition>
			<definition id="5">
				<sentence>X ° is the head of X m and the anchor of the etree .</sentence>
				<definiendum id="0">X °</definiendum>
				<definiens id="0">the head of X m and the anchor of the etree</definiens>
			</definition>
			<definition id="6">
				<sentence>Next , LexTract creates a spine-etree with the remaining unmarked nodes on the path and their siblings .</sentence>
				<definiendum id="0">LexTract</definiendum>
			</definition>
			<definition id="7">
				<sentence>draft ( # 5 ) a\ [ ( # 1 ) underwriters ( # 3 ) ~i11 ( # 4 ) policies ( # 6 ) using ( # 7 ) I I FNX ( # 2 ) pen ( # 9 ) fountain ( # 8 ) paper ( # 12 ) and ( # 10 ) bloldng ( # l I ) Figure 10 : The derivation tree for the sentence To summarize , LexTract is a languageindependent grammar extraction system , which takes Treebank-specific information ( see Section 3.2 ) and a ttree T , and creates 2Without this additional constraint , the derivation tree sometimes is not unique .</sentence>
				<definiendum id="0">LexTract</definiendum>
				<definiens id="0">The derivation tree for the sentence To summarize</definiens>
				<definiens id="1">a languageindependent grammar extraction system</definiens>
				<definiens id="2">takes Treebank-specific information</definiens>
			</definition>
			<definition id="8">
				<sentence>SThis decision may affect parsing accuracy of an LTAG parser which uses the derivation trees for training , but it will not affect the results reported in this paper .</sentence>
				<definiendum id="0">LTAG parser</definiendum>
				<definiens id="0">uses the derivation trees for training</definiens>
			</definition>
			<definition id="9">
				<sentence>Furthermore , Eset is the only tree set that satisfies all the following conditions : ( C1 ) Decomposition : The tree set is a decomposition of T* , that is , T* would be generated if the trees in the set were combined via the substitution and adjunction operations .</sentence>
				<definiendum id="0">Decomposition</definiendum>
				<definiens id="0">The tree set is a decomposition of T* , that is , T* would be generated if the trees in the set were combined via the substitution and adjunction operations</definiens>
			</definition>
			<definition id="10">
				<sentence>I I John left ( E l ) ( E2 ) \ [ &amp; ~m t lea lc~hn \ [ Icft ( E ) ( E , ) ( Es ) ( E6 ) Figure 11 : Tree sets for a fully bracketed ttree This uniqueness of the tree set may be quite surprising at first sight , considering that the number of possible decompositions of T* is ~ ( 2n ) , where n is the number of nodes in T* .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">E l ) ( E2 ) \ [ &amp; ~m t lea lc~hn \ [ Icft ( E ) ( E , ) ( Es ) ( E6 ) Figure 11 : Tree sets for a fully bracketed ttree This uniqueness of the tree set</definiens>
				<definiens id="1">the number of nodes in T*</definiens>
			</definition>
			<definition id="11">
				<sentence>In addition to extract LTAGs and CFGs , LexTract has been used to perform the following tasks : • We use the Treebank grammars produced by LexTract to evaluate the coverage of hand-crafted grammars .</sentence>
				<definiendum id="0">LexTract</definiendum>
				<definiens id="0">the Treebank grammars produced by LexTract to evaluate the coverage of hand-crafted grammars</definiens>
			</definition>
			<definition id="12">
				<sentence>hand-crafted grammars The XTAG grammar ( XTAG-Group , 1998 ) is a hand-crafted large-scale grammar for English , which has been developed at University of Pennsylvania in the last decade .</sentence>
				<definiendum id="0">XTAG grammar</definiendum>
				<definiens id="0">a hand-crafted large-scale grammar for English</definiens>
			</definition>
			<definition id="13">
				<sentence>A Supertagger ( Joshi and Srinivas , 1994 ; Srinivas , 1997 ) assigns an etree template to each word in a sentence .</sentence>
				<definiendum id="0">Supertagger</definiendum>
				<definiens id="0">assigns an etree template to each word in a sentence</definiens>
			</definition>
</paper>

		<paper id="0108">
</paper>

		<paper id="0731">
</paper>

		<paper id="0719">
			<definition id="0">
				<sentence>Spam , or more properly Unsolicited Commercial E-mail ( UCE ) , is an increasing threat to the viability of Internet E-mail and a danger to Internet commerce .</sentence>
				<definiendum id="0">Spam</definiendum>
				<definiendum id="1">Unsolicited Commercial E-mail</definiendum>
				<definiendum id="2">UCE</definiendum>
				<definiens id="0">an increasing threat to the viability of Internet E-mail and a danger to Internet commerce</definiens>
			</definition>
			<definition id="1">
				<sentence>UCE filtering is a text categorization task .</sentence>
				<definiendum id="0">UCE filtering</definiendum>
				<definiens id="0">a text categorization task</definiens>
			</definition>
			<definition id="2">
				<sentence>Weighted accuracy is a measure that weights higher the hits and misses 100 for the preferred class .</sentence>
				<definiendum id="0">Weighted accuracy</definiendum>
				<definiens id="0">a measure that weights higher the hits and misses 100 for the preferred class</definiens>
			</definition>
</paper>

		<paper id="1211">
			<definition id="0">
				<sentence>In English BNP ( base noun phrase ) is defined as simple and non-nesting noun phrases , i.e. noun phrases that do not contain other noun phrase descendants ( Church , 1988 ) .</sentence>
				<definiendum id="0">BNP</definiendum>
				<definiendum id="1">base noun phrase</definiendum>
			</definition>
			<definition id="1">
				<sentence>According to them a BNP in Chinese can be recursively defined as : BaseNP : := Determinative modifier + Noun I Nominalized verb ( NIO Determinative modifier : := Adjective I Differentiable Adjective ( DA ) I Verb I Noun I Location I String l Numeral + Classifier Inspired by these researches , we extend the concept of BNP to Base Phrase in Chinese .</sentence>
				<definiendum id="0">BNP</definiendum>
				<definiens id="0">BaseNP : := Determinative modifier + Noun I Nominalized verb ( NIO Determinative modifier : := Adjective I Differentiable Adjective ( DA ) I Verb I Noun I Location I String l Numeral + Classifier Inspired by these researches</definiens>
			</definition>
			<definition id="2">
				<sentence>CutTenfly , we are considering 7 Chinese base phrases in our research , namely base adjective phrase ( BADJP ) , base adverbial phrase ( BADVP ) , base noun phrase ( BNP ) , 73 base temporal phrase ( BTN ) , base location phrase ( BNS ) , base verb phrase ( BVP ) and base quantity phrase ( BMP ) Though theoretically definitions for these base phrases are still unavailable , Appendix I lists the preliminary illustrations for them in BNF format ( necessary account for POS annotation can also be found ) .</sentence>
				<definiendum id="0">base adjective phrase</definiendum>
				<definiendum id="1">BADJP</definiendum>
				<definiendum id="2">base adverbial phrase</definiendum>
				<definiendum id="3">BADVP</definiendum>
				<definiendum id="4">base noun phrase</definiendum>
				<definiendum id="5">BNP</definiendum>
				<definiendum id="6">base temporal phrase</definiendum>
				<definiendum id="7">BTN</definiendum>
				<definiendum id="8">base location phrase</definiendum>
				<definiendum id="9">BNS</definiendum>
				<definiendum id="10">BVP</definiendum>
				<definiendum id="11">base quantity phrase</definiendum>
				<definiendum id="12">BMP</definiendum>
				<definiens id="0">base verb phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>Definition 2 : Base phrase tag is the token representing the syntactic function of the phrase .</sentence>
				<definiendum id="0">Base phrase tag</definiendum>
				<definiens id="0">the token representing the syntactic function of the phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>At present , base tag either falls in one of the 7 Chinese base phrases we are considering or not : Phrase-Tag : := BADJP I BADVP I BNP I Br r l Bm I BrP I BMP I lVULL Definition 3 : Boundary tag denotes the possible relative position of a word to a base phrase .</sentence>
				<definiendum id="0">base tag either falls</definiendum>
				<definiendum id="1">Boundary tag</definiendum>
				<definiens id="0">the possible relative position of a word to a base phrase</definiens>
			</definition>
			<definition id="5">
				<sentence>A boundary tag for a gfven word is either L ( left boundary of a base phrase ) , R ( right boundary of a ) , I ( inside a base phrase ) or O ( outside the base phrase ) .</sentence>
				<definiendum id="0">boundary tag</definiendum>
				<definiendum id="1">O</definiendum>
				<definiens id="0">either L ( left boundary of a base phrase )</definiens>
				<definiens id="1">inside a base phrase ) or</definiens>
			</definition>
			<definition id="6">
				<sentence>The task is to find RC , a most possible sequence of duples formed by base phrase tags and boundary tags , among the POS sequence T. RC = ( &lt; ro , co &gt; ... ... .. &lt; rn , Cn &gt; ) , in whil~h ri ( l &lt; i &lt; =n ) indicates the boundary tags , ci represents the base phrase tags .</sentence>
				<definiendum id="0">RC</definiendum>
				<definiens id="0">a most possible sequence of duples formed by base phrase tags and boundary tags</definiens>
			</definition>
</paper>

		<paper id="0604">
			<definition id="0">
				<sentence>Reading comprehension tests are specifically designed to evaluate human reading skills , and these require vast amounts of world knowledge and common-sense reasoning capabilities .</sentence>
				<definiendum id="0">Reading comprehension tests</definiendum>
				<definiens id="0">specifically designed to evaluate human reading skills</definiens>
			</definition>
			<definition id="1">
				<sentence>Instead of generating the answer from the information given in the text ( possibly in implicit form only ) , an AE system will retrieve the specific sentence ( s ) in the text that contain ( s ) the explicit answer to the query .</sentence>
				<definiendum id="0">AE system</definiendum>
				<definiens id="0">s ) in the text that contain ( s ) the explicit answer to the query</definiens>
			</definition>
			<definition id="2">
				<sentence>a QA system will return : cp However , an AE system will return all the sentences in the text that directly answer the question , among them ( 1 ) .</sentence>
				<definiendum id="0">AE system</definiendum>
				<definiens id="0">return all the sentences in the text that directly answer the question</definiens>
			</definition>
			<definition id="3">
				<sentence>But AE has a number of important advantages over QA as a test paradigm .</sentence>
				<definiendum id="0">AE</definiendum>
				<definiens id="0">a number of important advantages over QA as a test paradigm</definiens>
			</definition>
			<definition id="4">
				<sentence>Recall is the number of correct answer sentences the system retrieved divided by the total number of correct answers in the entire document collection .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the number of correct answer sentences the system retrieved divided by the total number of correct answers in the entire document collection</definiens>
			</definition>
			<definition id="5">
				<sentence>Precision is the number of correct answer sentences the system retrieved divided by the total number of answers it returned .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the number of correct answer sentences the system retrieved divided by the total number of answers it returned</definiens>
			</definition>
			<definition id="6">
				<sentence>The ideal answer is a full sentence that contains the information given by the question and the information requested .</sentence>
				<definiendum id="0">ideal answer</definiendum>
				<definiens id="0">a full sentence that contains the information given by the question and the information requested</definiens>
			</definition>
			<definition id="7">
				<sentence>The overlap of the predicates ( overlap henceforth ) of two sentences is the maximum set of predicates that can be used as part of the logical form in both sentences .</sentence>
				<definiendum id="0">overlap of the predicates</definiendum>
				<definiens id="0">the maximum set of predicates that can be used as part of the logical form in both sentences</definiens>
			</definition>
			<definition id="8">
				<sentence>Succinctness of a sentence with respect to an ideal answer ( precision on the sentence level ) is the ratio between the overlap and the total number of predicates in the sentence .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the ratio between the overlap and the total number of predicates in the sentence</definiens>
			</definition>
			<definition id="9">
				<sentence>Correctness of a sentence with respect to an ideal answer ( recall on the sentence level ) is the ratio between the overlap and the number of predicates in the ideal answer .</sentence>
				<definiendum id="0">Correctness</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">the ratio between the overlap and the number of predicates in the ideal answer</definiens>
			</definition>
			<definition id="10">
				<sentence>AE aims at retrieving those exact passages of a document that directly answer a given user query .</sentence>
				<definiendum id="0">AE</definiendum>
				<definiens id="0">aims at retrieving those exact passages of a document that directly answer a given user query</definiens>
			</definition>
			<definition id="11">
				<sentence>Our test queries are real world queries that express a concrete information need .</sentence>
				<definiendum id="0">test queries</definiendum>
				<definiens id="0">real world queries that express a concrete information need</definiens>
			</definition>
</paper>

		<paper id="1107">
			<definition id="0">
				<sentence>REXTOR ( Relations EXtracTOR ) is an implementation of this model ; in one uniform framework , the system provides two separate grammars for extracting arbitrary patterns of text and building ternary expressions from them .</sentence>
				<definiendum id="0">REXTOR ( Relations EXtracTOR )</definiendum>
				<definiens id="0">an implementation of this model ; in one uniform framework , the system provides two separate grammars for extracting arbitrary patterns of text and building ternary expressions from them</definiens>
			</definition>
			<definition id="1">
				<sentence>Traditional information retrieval ( IR ) has been built on the `` bag-of-words '' assumption , which equates the weighted component keywords of a document with its semantic content .</sentence>
				<definiendum id="0">Traditional information retrieval</definiendum>
				<definiendum id="1">IR</definiendum>
				<definiens id="0">equates the weighted component keywords of a document with its semantic content</definiens>
			</definition>
			<definition id="2">
				<sentence>The application of natural language processing ( NLP ) techniques to information retrieval promises to generate representational structures that better capture the semantic content of documents .</sentence>
				<definiendum id="0">information retrieval</definiendum>
				<definiens id="0">promises to generate representational structures that better capture the semantic content of documents</definiens>
			</definition>
			<definition id="3">
				<sentence>REXTOR ( Relations EXtracTOR ) is a document content analysis system designed to unify and generalize many previous natural language information retrieval techniques into one single framework .</sentence>
				<definiendum id="0">REXTOR ( Relations EXtracTOR )</definiendum>
				<definiens id="0">a document content analysis system designed to unify and generalize many previous natural language information retrieval techniques into one single framework</definiens>
			</definition>
			<definition id="4">
				<sentence>The START System ( Katz , 1990 ; Katz , 1997 ) analyzes English text and builds a knowledge base from information found in the text .</sentence>
				<definiendum id="0">START System</definiendum>
				<definiens id="0">analyzes English text and builds a knowledge base from information found in the text</definiens>
			</definition>
			<definition id="5">
				<sentence>In order to bypass intractable complexities of language , START uses computer-analyzable natural language annotations , which consist of simplified English sentences and phrases , to describe various information segments ( which may be text , images , or even video and other multimedia content ) .</sentence>
				<definiendum id="0">START</definiendum>
				<definiens id="0">uses computer-analyzable natural language annotations , which consist of simplified English sentences and phrases , to describe various information segments ( which may be text , images , or even video and other multimedia content )</definiens>
			</definition>
			<definition id="6">
				<sentence>REXTOR attempts to eliminate the need for human involvement during content analysis , and also aims to serve as the foundation of a natural language information retrieval system .</sentence>
				<definiendum id="0">REXTOR</definiendum>
				<definiens id="0">attempts to eliminate the need for human involvement during content analysis , and also aims to serve as the foundation of a natural language information retrieval system</definiens>
			</definition>
			<definition id="7">
				<sentence>The REXTOR System utilizes an integrated model to systematically extract arbitrary textual patterns and relations ( ternary expressions ) from documents .</sentence>
				<definiendum id="0">REXTOR System</definiendum>
				<definiens id="0">utilizes an integrated model to systematically extract arbitrary textual patterns and relations ( ternary expressions ) from documents</definiens>
			</definition>
			<definition id="8">
				<sentence>Similarly , PLNLP ( Heidorn , 1972 ; Jensen et al. , 1993 ) is a programming language for writing phrase structure rules that include specific conditions under which the rule can be applied .</sentence>
				<definiendum id="0">PLNLP</definiendum>
				<definiens id="0">a programming language for writing phrase structure rules that include specific conditions under which the rule can be applied</definiens>
			</definition>
			<definition id="9">
				<sentence>However , Church ( 1980 ) demonstrated that the finitestate language model is adequate to describe a performance model of language ( i.e. , constrained by memory , attention , and other realistic limitations ) that approximates competence ( i.e. , language ability under optimal conditions without resource constraints ) .</sentence>
				<definiendum id="0">language</definiendum>
				<definiens id="0">constrained by memory , attention , and other realistic limitations ) that approximates competence ( i.e. , language ability under optimal conditions without resource constraints</definiens>
			</definition>
			<definition id="10">
				<sentence>Finite-state grammars have been used to extract entities such as proper nouns , names , locations , etc. , with relatively high precision .</sentence>
				<definiendum id="0">Finite-state grammars</definiendum>
				<definiens id="0">proper nouns , names , locations , etc. , with relatively high precision</definiens>
			</definition>
			<definition id="11">
				<sentence>Using its finite-state language model , the REXTOR System generates a set of ternary expressions that correspond to content of a part-of-speechtagged input document .</sentence>
				<definiendum id="0">REXTOR System</definiendum>
				<definiens id="0">generates a set of ternary expressions that correspond to content of a</definiens>
			</definition>
			<definition id="12">
				<sentence>The relations construction process consists of two distinct processes , each guided by its own externally specified grammar file .</sentence>
				<definiendum id="0">construction process</definiendum>
				<definiens id="0">consists of two distinct processes , each guided by its own externally specified grammar file</definiens>
			</definition>
			<definition id="13">
				<sentence>Extraction rules are applied to match arbitrary patterns of text , based either on one of thirty-nine POS tags or on exact words .</sentence>
				<definiendum id="0">Extraction rules</definiendum>
				<definiens id="0">applied to match arbitrary patterns of text , based either on one of thirty-nine POS tags or on exact words</definiens>
			</definition>
			<definition id="14">
				<sentence>Extraction rules are used to extract arbitrary patterns of text according to a grammar specification .</sentence>
				<definiendum id="0">Extraction rules</definiendum>
				<definiens id="0">used to extract arbitrary patterns of text according to a grammar specification</definiens>
			</definition>
			<definition id="15">
				<sentence>The extraction stage of the REXTOR System performs a no-lookahead left-to-right scan of every input sentence , identifies the longest matching pattern ( from any grammar rule ) , reduces the input sequence based on the matched rule , and continues with the next unmatched word .</sentence>
				<definiendum id="0">REXTOR System</definiendum>
				<definiens id="0">performs a no-lookahead left-to-right scan of every input sentence , identifies the longest matching pattern ( from any grammar rule ) , reduces the input sequence based on the matched rule , and continues with the next unmatched word</definiens>
			</definition>
			<definition id="16">
				<sentence>The template consists of a series of legal tokens , which are shown in Table 1 .</sentence>
				<definiendum id="0">template</definiendum>
				<definiens id="0">consists of a series of legal tokens</definiens>
			</definition>
			<definition id="17">
				<sentence>A relation rule takes the following form : EntityType : = &gt; &lt; atoml atom2 acorn3 &gt; ; The EntityType is the trigger for the relation , i.e. , the rule is applied whenever a string of that type is extracted .</sentence>
				<definiendum id="0">relation rule</definiendum>
				<definiendum id="1">EntityType</definiendum>
				<definiens id="0">EntityType : = &gt; &lt; atoml atom2 acorn3 &gt;</definiens>
				<definiens id="1">the trigger for the relation</definiens>
			</definition>
			<definition id="18">
				<sentence>( PRPZ is the part-of-speech tag for possessive pronouns , DT for determiners , JJX for adjectives , J JR for comparative adjectives , JJS for superlative adjectives , NNX for singular or mass nouns , NNS for plural nouns , NNPX for singular proper nouns , NNPS for plural proper nouns , IN for prepositions . )</sentence>
				<definiendum id="0">PRPZ</definiendum>
				<definiendum id="1">DT</definiendum>
				<definiendum id="2">JJX</definiendum>
				<definiendum id="3">JJS</definiendum>
				<definiendum id="4">NNX</definiendum>
				<definiendum id="5">NNS</definiendum>
				<definiendum id="6">NNPX</definiendum>
				<definiendum id="7">NNPS</definiendum>
				<definiendum id="8">IN</definiendum>
				<definiens id="0">determiners</definiens>
				<definiens id="1">adjectives</definiens>
				<definiens id="2">comparative adjectives</definiens>
				<definiens id="3">superlative adjectives</definiens>
				<definiens id="4">singular or mass nouns</definiens>
				<definiens id="5">plural nouns</definiens>
				<definiens id="6">singular proper nouns</definiens>
				<definiens id="7">plural proper nouns</definiens>
				<definiens id="8">prepositions</definiens>
			</definition>
			<definition id="19">
				<sentence>The first extraction rule defines a NounGroup as a sequence consisting of : an optional possessive pronoun or determiner , any number of adjectives , one or more nouns ( of any type ) .</sentence>
				<definiendum id="0">NounGroup</definiendum>
				<definiens id="0">a sequence consisting of : an optional possessive pronoun or determiner , any number of adjectives , one or more nouns ( of any type )</definiens>
			</definition>
			<definition id="20">
				<sentence>• Predicative adjectives can be recognized by the `` be '' verb and a succession of one or more adjectives ( or adjectival phrase ) .</sentence>
				<definiendum id="0">Predicative adjectives</definiendum>
				<definiens id="0">a succession of one or more adjectives ( or adjectival phrase )</definiens>
			</definition>
			<definition id="21">
				<sentence>However , many prior techniques used in natural language information retrieval ( e.g. , head/modifier pairs ) can be expressed within the ItEXTOR framework , and furthermore the system provides a playground for experimenting with new techniques .</sentence>
				<definiendum id="0">head/modifier pairs</definiendum>
				<definiens id="0">techniques used in natural language information retrieval</definiens>
			</definition>
</paper>

		<paper id="1326">
			<definition id="0">
				<sentence>The DSO collection ( Ng and Lee , 1996 ) focuses on 191 frequent and polysemous words ( nouns and verbs ) , and contains around 1,000 sentences per word .</sentence>
				<definiendum id="0">DSO collection</definiendum>
			</definition>
			<definition id="1">
				<sentence>We will pay special attention to localcontent collocations , as they are the strongest , and also closer to strict definitions of collocation .</sentence>
				<definiendum id="0">localcontent collocations</definiendum>
				<definiens id="0">the strongest , and also closer to strict definitions of collocation</definiens>
			</definition>
			<definition id="2">
				<sentence>N .650 1.00 -.011 .762 .486 -.002 V .634 1.00 -.001 .697 .494 -.040 Overall .644 1.00 -.011 .738 .489 -.017 Table 11 : Train on WSJ , tag WSJ , crossvalidation according to files Overall Local content pr .</sentence>
				<definiendum id="0">WSJ</definiendum>
				<definiens id="0">crossvalidation according to files Overall Local content pr</definiens>
			</definition>
			<definition id="3">
				<sentence>In-corpora In-corpora ( examples ) ( files ) Cross-corpora WSJ .652 .644 .489 BC .572 .514 .448 Table 13 : Overall results in different experiments Category WSJ Rest of BC local content local content pr .</sentence>
				<definiendum id="0">In-corpora In-corpora</definiendum>
				<definiens id="0">Overall results in different experiments Category WSJ Rest of BC local content local content pr</definiens>
			</definition>
</paper>

		<paper id="1304">
			<definition id="0">
				<sentence>One of the main advantages of probabilistic methods , on the other hand , is that they include a measure of uncertainty in their output .</sentence>
				<definiendum id="0">probabilistic methods</definiendum>
				<definiens id="0">include a measure of uncertainty in their output</definiens>
			</definition>
			<definition id="1">
				<sentence>Transformation-based learning ( TBL ) ( Brill , 1995 ) is a successful rule-based machine learning algorithm in natural language processing .</sentence>
				<definiendum id="0">Transformation-based learning ( TBL )</definiendum>
				<definiens id="0">a successful rule-based machine learning algorithm in natural language processing</definiens>
			</definition>
			<definition id="2">
				<sentence>These definitions and notation will be used throughout the paper : • X denotes the sample space ; • C denotes the set of possible classifications of the samples ; • The state space is defined as 8 = X x C. • 7r will usually denote a predicate defined on X ; • A rule r is defined as a predicate class label time tuple , ( ~r , c , t ) , c E C , t E N , where t is the learning iteration in which when the rule was learned , its position in the list .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">rule r</definiendum>
				<definiens id="0">the sample space ; •</definiens>
				<definiens id="1">the set of possible classifications of the samples</definiens>
				<definiens id="2">a predicate class label time tuple , ( ~r , c , t ) , c E C , t E N , where t is the learning iteration in which when the rule was learned , its position in the list</definiens>
			</definition>
			<definition id="3">
				<sentence>Soft decision-making is also useful when the system is one of the components in a larger decision-malting process , as is the case in speech recognition systems ( Bald et al. , 1989 ) , or in an ensemble system like AdaBoost ( Freund and Schapire , 1997 ) .</sentence>
				<definiendum id="0">speech recognition systems</definiendum>
				<definiendum id="1">AdaBoost</definiendum>
				<definiens id="0">a larger decision-malting process</definiens>
				<definiens id="1">an ensemble system</definiens>
			</definition>
			<definition id="4">
				<sentence>Let R ( z ) to be the set of rules r~ that applies to the state el ( z ) , R ( z ) = { ri ~ 7~Ir~ applies to si ( z ) } An equivalence class consists of all the samples z that have the same R ( z ) .</sentence>
				<definiendum id="0">R ( z )</definiendum>
				<definiendum id="1">equivalence class</definiendum>
				<definiens id="0">the set of rules r~ that applies to the state el ( z )</definiens>
				<definiens id="1">consists of all the samples z that have the same R ( z )</definiens>
			</definition>
			<definition id="5">
				<sentence>Class probability assignments are then estimated using statistics computed on the equivalence classes .</sentence>
				<definiendum id="0">Class probability assignments</definiendum>
				<definiens id="0">estimated using statistics computed on the equivalence classes</definiens>
			</definition>
			<definition id="6">
				<sentence>The parameter K is a constant that determines the minimum weight that a leaf is permitted to have , effectively pruning the tree during construction .</sentence>
				<definiendum id="0">parameter K</definiendum>
				<definiens id="0">a constant that determines the minimum weight that a leaf is permitted to have , effectively pruning the tree during construction</definiens>
			</definition>
			<definition id="7">
				<sentence>This alleviates the problem of overpartitioning of data , which is a widely-recognized concern during decision tree growth .</sentence>
				<definiendum id="0">overpartitioning of data</definiendum>
				<definiens id="0">a widely-recognized concern during decision tree growth</definiens>
			</definition>
			<definition id="8">
				<sentence>The most commonly used measure for evaluating tagging tasks is tag accuracy , lit is defined as Accuracy = # of correctly tagged examples of examples In syntactic parsing , though , since the task is to identify the phrasal components , it is more appropriate to measure the precision and recall : # of correct proposed phrases Precision = # of proposed phrases # of correct proposed phrases Recall = # of correct phrases To facilitate the comparison of systems with different precision and recall , the F-measure metric is computed as a weighted harmonic mean of precision and recall : ( 82 + 1 ) × Precision x Recall = 82 x Precision + Recall The ~ parameter is used to give more weight to precision or recall , as the task at hand requires .</sentence>
				<definiendum id="0">F-measure metric</definiendum>
				<definiens id="0">a weighted harmonic mean of precision and recall : ( 82 + 1 ) × Precision x Recall = 82 x Precision + Recall The ~ parameter is used to give more weight to precision or recall</definiens>
			</definition>
			<definition id="9">
				<sentence>Empirically , active learning has been applied to various NLP tasks such as text categorization ( Lewis and Gale , 1994 ; Lewis and Catlett , 1994 ; Liere and Tadepalli , 1997 ) , part-of-speech tagging ( Dagan and Engelson , 1995 ; Engelson and Dagan , 1996 ) , and base noun phrase chunbiug ( Ngai and Yarowsky , 2000 ) , resulting in significantly large reductions in the quantity of data needed to achieve comparable performance .</sentence>
				<definiendum id="0">base noun</definiendum>
				<definiens id="0">the quantity of data needed to achieve comparable performance</definiens>
			</definition>
			<definition id="10">
				<sentence>A probabilistic classifier , in contrast , offers information about the class probability distribution of a given sample .</sentence>
				<definiendum id="0">probabilistic classifier</definiendum>
				<definiens id="0">offers information about the class probability distribution of a given sample</definiens>
			</definition>
			<definition id="11">
				<sentence>Cross entropy is a goodness measure for probability estimates that takes into account the accuracy of the estimates as well as the classification accuracy of the system .</sentence>
				<definiendum id="0">Cross entropy</definiendum>
				<definiens id="0">a goodness measure for probability estimates that takes into account the accuracy of the estimates as well as the classification accuracy of the system</definiens>
			</definition>
			<definition id="12">
				<sentence>It measures the performance of a system trained on a set of samples distributed according to the probability distribution p when tested on a set following a probability distribution q. More specifically , we utilize conditional cross entropy , which is defined as n ( ClX ) = q ( = ) q ( cl= ) • log2 pC @ : ) zEX ¢EC where X is the set of examples and C is the set of chnnlr tags , q is the probability distribution on the 32 Chunk Type Accuracy ( % ) Precisionl Recall ( % ) I ( % ) Overall 95.23 92.02 92.50 ADJP 75.69 68.95 ADVP 80.88 78.64 CONJP 40.00 44.44 INTJ 50.00 50.00 LST 0.00 0.00 NP 92.18 92.72 PP 95.89 97.90 PRT 67.80 75.47 SBAR 88.71 82.24 VP 92.00 92.87 Fi 92.26 !</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">q</definiendum>
				<definiendum id="2">Precisionl Recall ( % ) I</definiendum>
				<definiens id="0">measures the performance of a system trained on a set of samples distributed according to the probability distribution p when tested on a set following a probability distribution q. More specifically , we utilize conditional cross entropy , which is defined as n ( ClX ) = q ( = ) q ( cl= ) • log2 pC @ : ) zEX ¢EC where X is the set of examples</definiens>
				<definiens id="1">the set of chnnlr tags</definiens>
				<definiens id="2">the probability distribution on the 32 Chunk Type Accuracy ( % )</definiens>
			</definition>
			<definition id="13">
				<sentence>The TBLDT outperforms both C4.5 systems , obtaining better cross-entropy and chunk tag perplexity .</sentence>
				<definiendum id="0">TBLDT</definiendum>
				<definiens id="0">outperforms both C4.5 systems , obtaining better cross-entropy and chunk tag perplexity</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>Classical dialogue systems like UC ( Wilensky et al. , 1984 ) utilized a formal language to represent knowledge , which requires the heavy cost of construction and maintenance and makes the scaling up quite difficult .</sentence>
				<definiendum id="0">Classical dialogue systems</definiendum>
				<definiens id="0">utilized a formal language to represent knowledge , which requires the heavy cost of construction and maintenance and makes the scaling up quite difficult</definiens>
			</definition>
			<definition id="1">
				<sentence>Each entry consists of a headword ( &lt; TITLE &gt; tag ) , synonyms ( &lt; SYN &gt; tag ) , an upper word ( &lt; BT &gt; tag ) , a definition of the headword ( &lt; DEF &gt; tag ) and several descriptions concerning the headword ( &lt; DESCRIPTION &gt; tag ; see Figure 1 ) .</sentence>
				<definiendum id="0">entry</definiendum>
			</definition>
			<definition id="2">
				<sentence>• Matching of the depth of the phrases in parse trees : 1 point • Matching of the type of the phrases ( phrase types differ depending on surface cases and verb conjugations , etc ) : 1 point user question are summed up and normalized by the maximum matching score ( MMS ) as follows ( the MMS is the similarity score with the same sentence ) : The sum of scores of~ 2 phrase similarities \ ] The MMS of ~ ( The MMS of~ the user question\ ] × \the KU case\ ] The above score is given to the KU as its certainty score .</sentence>
				<definiendum id="0">maximum matching score ( MMS )</definiendum>
				<definiens id="0">the MMS is the similarity score with the same sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>To decide this , the dialogue manager regard s the certainty score between the utterance and the most similar KU as an appropriateness measure of the interpretation .</sentence>
				<definiendum id="0">certainty score</definiendum>
				<definiens id="0">an appropriateness measure of the interpretation</definiens>
			</definition>
			<definition id="4">
				<sentence>UI : I want to send an email by Outlook .</sentence>
				<definiendum id="0">UI</definiendum>
				<definiens id="0">I want to send an email by Outlook</definiens>
			</definition>
</paper>

		<paper id="1108">
			<definition id="0">
				<sentence>The task of summarization is to identify informative evidence from a given document , which are most relevant to its content and create a shorter version of smnmary of the document from this information .</sentence>
				<definiendum id="0">summarization</definiendum>
				<definiens id="0">to identify informative evidence from a given document , which are most relevant to its content and create a shorter version of smnmary of the document from this information</definiens>
			</definition>
			<definition id="1">
				<sentence>The index contains features and a weighted value , W ( f , c ) , associated with each feature fin each category c. Given a document , d , a rank can be associated with each category with respect to d. Let Fc is the set of features , f , in category c. The ranking of category c with respect to document d , R ( c , d ) , is defined as equation 4 .</sentence>
				<definiendum id="0">index</definiendum>
				<definiens id="0">contains features and a weighted value , W ( f , c ) , associated with each feature fin each category c. Given a document , d , a rank can be associated with each category with respect to d. Let Fc is the set of features , f , in category c. The ranking of category c with respect to document d</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>In looking at the response , however , we have to be sensitive to effects like timeout ( e.g. , the DM is `` thinking '' too long ) and/or loops ( e.g. , the DM outputs the same item all the time ) .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiendum id="1">DM</definiendum>
				<definiens id="0">outputs the same item all the time )</definiens>
			</definition>
			<definition id="1">
				<sentence>The basic entity is a semantic object ( S ) which is an atomic item treated by the DM .</sentence>
				<definiendum id="0">basic entity</definiendum>
				<definiens id="0">a semantic object ( S ) which is an atomic item treated by the DM</definiens>
			</definition>
			<definition id="2">
				<sentence>Figure 3 shows how different parameter setting affects the cardinality of utterances for different values of M. The ( logarithmic ) yaxis represents the cardinality of utterances , and the ( linear ) x-axis the maximal number of semantic items in one utterance .</sentence>
				<definiendum id="0">logarithmic</definiendum>
				<definiendum id="1">linear ) x-axis</definiendum>
				<definiens id="0">the cardinality of utterances</definiens>
				<definiens id="1">the maximal number of semantic items in one utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>The exhaustive mode can be used when we know that the complexity of the automaton ( and utterances ) is testable VALDIA can compute the number of dialogues and compute an upper time limit based on the computational power of the DM .</sentence>
				<definiendum id="0">exhaustive mode</definiendum>
				<definiens id="0">testable VALDIA can compute the number of dialogues and compute an upper time limit based on the computational power of the DM</definiens>
			</definition>
			<definition id="4">
				<sentence>VALDIA produces huge amounts of ( huge ) trace files .</sentence>
				<definiendum id="0">VALDIA</definiendum>
			</definition>
</paper>

		<paper id="0701">
			<definition id="0">
				<sentence>Pr ( s ) = Pr ( wl , W2 , ... Wn ) -- -= H~=lPr ( wilwl , ... wi-1 ) = H~=lPr ( wilhi ) where hi is the relevant history when predicting wi , and s is any sequence of tokens , words , partof-speech ( pos ) tags or other terms .</sentence>
				<definiendum id="0">hi</definiendum>
				<definiendum id="1">s</definiendum>
				<definiendum id="2">partof-speech ( pos</definiendum>
				<definiens id="0">the relevant history when predicting wi</definiens>
			</definition>
			<definition id="1">
				<sentence>A feature is an indicator function X : X ~ { 0 , 1 } which defines a subset of the instance space all those elements in X which are mapped to 1 by XX denotes a class of such functions and can be viewed as a transformation of the instance space ; each example ( Xl , ... xn ) E X is mapped to an example ( Xi , ... Xlxl ) in the new space .</sentence>
				<definiendum id="0">feature</definiendum>
				<definiens id="0">an indicator function X : X ~ { 0 , 1 } which defines a subset of the instance space all those elements in X which are mapped to 1 by XX denotes a class of such functions</definiens>
			</definition>
			<definition id="2">
				<sentence>A statistical query has the form IX , l , 7-\ ] , where X 6 X is a feature , l 6 { 0 , 1 } is a further ( optional ) restriction imposed on the query and ~ '' is an error parameter .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a further ( optional ) restriction imposed on the query</definiens>
			</definition>
			<definition id="3">
				<sentence>A statistical queries algorithm is a learning algorithm that constructs its hypothesis only using information received from an SQ oracle .</sentence>
				<definiendum id="0">statistical queries algorithm</definiendum>
				<definiens id="0">a learning algorithm that constructs its hypothesis only using information received from an SQ oracle</definiens>
			</definition>
			<definition id="4">
				<sentence>Clearly , the LSQ is a linear discriminator over the feature space A ' , with coefficients f that are computed given ( potentially all ) the values ^D P\ [ x , t\ ] '' The definition generalizes naturally to non-binary classifiers ; in this case , the discriminator between predicting l and other values is linear .</sentence>
				<definiendum id="0">LSQ</definiendum>
				<definiendum id="1">^D P\</definiendum>
				<definiens id="0">a linear discriminator over the feature space A '</definiens>
			</definition>
			<definition id="5">
				<sentence>Consequently , the Bayes optimal prediction is given by : h ( x ) = argmaxteLH~n=l Pr ( xill ) Pr ( 1 ) , where Pr ( 1 ) denotes the prior probability of l ( the fraction of examples labeled l ) and Pr ( xill ) are the conditional feature probabilities ( the fraction of the examples labeled l in which the ith feature has value xi ) .</sentence>
				<definiendum id="0">the Bayes optimal prediction</definiendum>
				<definiens id="0">h ( x ) = argmaxteLH~n=l Pr ( xill ) Pr ( 1 ) , where Pr ( 1 ) denotes the prior probability of l ( the fraction of examples labeled l ) and Pr ( xill ) are the conditional feature probabilities ( the fraction of the examples labeled l in which the ith feature has value xi )</definiens>
			</definition>
			<definition id="6">
				<sentence>Decision lists and MBL methods have advantages in their ability to represent exceptions and small areas in the feature space .</sentence>
				<definiendum id="0">MBL</definiendum>
				<definiens id="0">advantages in their ability to represent exceptions and small areas in the feature space</definiens>
			</definition>
			<definition id="7">
				<sentence>Learning methods that attempt to find the best linear function ( relative to some loss function ) are typically more flexible .</sentence>
				<definiendum id="0">Learning</definiendum>
				<definiens id="0">methods that attempt to find the best linear function ( relative to some loss function</definiens>
			</definition>
			<definition id="8">
				<sentence>SNoW determines the features ' weights using an on-line algorithm that attempts to minimize the number of mistakes on the training data using a multiplicative weight update rule ( Lit88 ) .</sentence>
				<definiendum id="0">on-line algorithm</definiendum>
				<definiens id="0">attempts to minimize the number of mistakes on the training data using a multiplicative weight update rule</definiens>
			</definition>
			<definition id="9">
				<sentence>In domains with these characteristics , for a given number of training examples , SNoW generalizes better than additive update methods like perceptron and its close relative SVMs ( Ros58 ; FS98 ) ( and in general , it has better learning curves ) .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiens id="0">generalizes better than additive update methods like perceptron and its close relative SVMs</definiens>
			</definition>
			<definition id="10">
				<sentence>Finally , SNoW is a multi-class classifier .</sentence>
				<definiendum id="0">SNoW</definiendum>
				<definiens id="0">a multi-class classifier</definiens>
			</definition>
</paper>

		<paper id="0739">
			<definition id="0">
				<sentence>In the first case the representation theory is first order logic without structural rules , the formal learning theory from a logical point of view is inductive substructural logic programming and an example of a learning strategy in this framework is EMILE , a learning algorithm that learns categorial grammars ( Adriaans , 1992 ) .</sentence>
				<definiendum id="0">EMILE</definiendum>
				<definiens id="0">a learning algorithm that learns categorial grammars</definiens>
			</definition>
			<definition id="1">
				<sentence>EVb : _ ( Weak ) bAE=* , ggVb bAg=~aVb ( Sx ) E , b~EVb_ ( L^ ) ggAb~EVb ( Ex ) EAb=~aVb ( RA ) EAb~EVb ( E A b ) , ( E A b ) =-~ ( E V b ) A ( a V b ) ( a^ ) ( E A b ) , ( E A b ) , ( E A b ) ~ ( E V b ) A ( E V b ) A ( a V b ) ( Contr ) ( EAb ) , ( EAb ) ~ ( EVb ) A ( EVb ) A ( aVb ) ( ~A b ) =* ( ~Vb ) A ( EV b ) A ( a V b ) ( Contr ) Figure 3 : Proof to be found for boolean concept learning Now by ( LV ) we can prove the complete DNF to 2-CNF sequent ; i.e. vector1 V • • • V vector/ ~ clause1 A • • • A clausep It is easy to see that for the above algorithm the same complexity analysis holds as for the Valiant algorithm , because we have the same progression in l steps , an the individual steps have constant overhead .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">A b ) =-~ ( E V b ) A ( a V b ) ( a^ ) ( E A b ) , ( E A b ) , ( E A b ) ~ ( E V b ) A ( E V b ) A ( a V b ) ( Contr ) ( EAb ) , ( EAb ) ~</definiens>
			</definition>
			<definition id="2">
				<sentence>Suppose again the universe U = { al , ... , an } , and the concept f is a CNF expressible concept for vectors of length m. of zero literals ) clause1 , ... , clausem ( a ) pick an example al A..</sentence>
				<definiendum id="0">, clausem</definiendum>
				<definiens id="0">a CNF expressible concept for vectors of length m. of zero literals ) clause1 , ...</definiens>
			</definition>
			<definition id="3">
				<sentence>180 ~ ~ ( Ax ) ~vb b ~ b ( Ax ) b ~ b ( Ax ) ( RV ) ( RV ) b~Vb b~aVb ( at ) b , b =* ( ~V ) A ( a V b ) ( RV ) ( LA ) bAb~ ( gVD ) A ( aVb ) ( at ) ~ , b Ab ~ ( ~V b ) A ( ~V b ) A ( a V b ) gAbAb ~ ( ~Vb ) A ( ~Vb ) A ( aVb ) ( LA ) ( EAEA a ) V ( gAEA b ) V ( gA bAa ) V ( EA bA b ) V ( bAEA a ) V ( bAEA b ) V ( bA bA a ) V ( bA bA b ) ~ ( gVb ) A ( gV b ) A ( a V b ) ( LV ) Figure 4 : Proof to be found for string pattern learning Now let e = P ( fAf ~ ) be the error then again 5 = ( 1 e ) TM is the confidence parameter as we have m positions in the string .</sentence>
				<definiendum id="0">b~Vb b~aVb</definiendum>
				<definiendum id="1">TM</definiendum>
				<definiens id="0">gAEA b ) V ( gA bAa ) V ( EA bA b ) V ( bAEA a ) V ( bAEA b</definiens>
			</definition>
</paper>

		<paper id="1423">
			<definition id="0">
				<sentence>SPUD builds the utterance element-by-element ; at each stage of construction , SPUD 'S representation of the current , incomplete utterance specifies its syntax , semantics , interpretation and fit to context .</sentence>
				<definiendum id="0">SPUD</definiendum>
				<definiens id="0">builds the utterance element-by-element ; at each stage of construction , SPUD 'S representation of the current , incomplete utterance specifies its syntax , semantics , interpretation and fit to context</definiens>
			</definition>
			<definition id="1">
				<sentence>At each stage , then , SPUD selects the available option that offers the best immediate advance toward completing the utterance successfully .</sentence>
				<definiendum id="0">SPUD</definiendum>
				<definiens id="0">selects the available option that offers the best immediate advance toward completing the utterance successfully</definiens>
			</definition>
			<definition id="2">
				<sentence>REA 'S descriptors consist of entries that contribute to coverbal gestures , as well as revised entries for spoken words that allow for their coordination with gesture under appropriate discourse conditions .</sentence>
				<definiendum id="0">REA 'S descriptors</definiendum>
			</definition>
			<definition id="3">
				<sentence>Our device for this is a construction SYNC which pairs a description of a gesture G with the syntactic structure of a spoken constituent c : SYNC ( 2 ) G C The temporal interpretation of ( 2 ) mirrors the rules for surface synchrony between speech and gesture presented in ( Cassell et al. , 1994 ) .</sentence>
				<definiendum id="0">construction SYNC</definiendum>
				<definiens id="0">pairs a description of a gesture G with the syntactic structure of a spoken constituent c</definiens>
			</definition>
			<definition id="4">
				<sentence>( 3 ) a syntax : s NP VP NP : o V SYNC /have/ G : x I NP : x b semantics : have ( o , x ) c 'pragmaties : '' heardr-n-ew ( x ) A'theme { O ) ... .. ( 3 ) describes the use of have to introduce a new feature of ( a house ) o. The feature , indicated throughout the entry by the variable x , .</sentence>
				<definiendum id="0">b semantics</definiendum>
				<definiendum id="1">c 'pragmaties</definiendum>
				<definiens id="0">s NP VP NP : o V SYNC /have/ G : x I NP : x</definiens>
				<definiens id="1">a house ) o. The feature , indicated throughout the entry by the variable x ,</definiens>
			</definition>
			<definition id="5">
				<sentence>is realized as the object NP of the verb have , but x can also form the basis of a gesture G coordinated with the noun phrase ( as indicated by the SYNC constituent ) .</sentence>
				<definiendum id="0">noun phrase</definiendum>
				<definiens id="0">a gesture G coordinated with the</definiens>
			</definition>
			<definition id="6">
				<sentence>( 4 ) a syntax : G : x circular-trajectory RS : x l b syntax : NP NP. : x VP V NP : p j I surrounding c semantics : surround ( x.p ) ( 4a ) provides a structure that could substitute for the G node in ( 3 ) to produce semantically and pragmatically coordinated speech and gesture .</sentence>
				<definiendum id="0">x circular-trajectory RS</definiendum>
				<definiens id="0">NP NP. : x VP V NP : p j I surrounding c semantics : surround ( x.p ) ( 4a ) provides a structure that could substitute for the G node in ( 3 ) to produce semantically and pragmatically coordinated speech and gesture</definiens>
			</definition>
			<definition id="7">
				<sentence>Along with these goals , the dialogue manager supplies its communicative context , which represents the centrality of the house in attentional prominence , cognitive status and information structure .</sentence>
				<definiendum id="0">communicative context</definiendum>
				<definiens id="0">represents the centrality of the house in attentional prominence , cognitive status and information structure</definiens>
			</definition>
			<definition id="8">
				<sentence>In this paper , we have summarized the evidence for this view of human conversation , and shown how it informs the generation of communicative action in our artificial embodied conversational agent , REA .</sentence>
				<definiendum id="0">REA</definiendum>
				<definiens id="0">artificial embodied conversational agent</definiens>
			</definition>
			<definition id="9">
				<sentence>REA has a working implementation , which includes the modules described in this paper , and can engage in a variety of interactions including that in ( 5 ) .</sentence>
				<definiendum id="0">REA</definiendum>
				<definiens id="0">a working implementation , which includes the modules described in this paper , and can engage in a variety of interactions including that in ( 5 )</definiens>
			</definition>
</paper>

		<paper id="0736">
			<definition id="0">
				<sentence>The learning procedure is a reimplementation of Brill 's transformation-based approach ( Brill , 1993 ) , extended to cover approximately an order of magnitude more rule schemata .</sentence>
				<definiendum id="0">learning procedure</definiendum>
				<definiens id="0">a reimplementation of Brill 's transformation-based approach ( Brill , 1993 ) , extended to cover approximately an order of magnitude more rule schemata</definiens>
			</definition>
			<definition id="1">
				<sentence>The phraser also treats as atomic units the stereotypical combinations of named entities that one finds in newswire text , e.g. , the person-title-organization apposition `` U.N. secretary general Kofi Anan '' .</sentence>
				<definiendum id="0">person-title-organization apposition</definiendum>
				<definiens id="0">atomic units the stereotypical combinations of named entities that one finds in newswire text</definiens>
			</definition>
</paper>

		<paper id="0501">
			<definition id="0">
				<sentence>We describe preliminary work developing measures on system-internal components that assess : ( i ) the flow of words relevant to the filtering task and domain through the steps of document processing in our embedded MT system , and ( ii ) the level of `` noise , '' i.e. , processing errors , passing through the system .</sentence>
				<definiendum id="0">noise</definiendum>
			</definition>
			<definition id="1">
				<sentence>Forty-nine of the OCR-ed `` words '' are treated as `` not found words '' ( NFWs ) by the MT engine , even though they may in fact be actual Spanish words .</sentence>
				<definiendum id="0">NFWs</definiendum>
				<definiens id="0">not found words '' (</definiens>
			</definition>
			<definition id="2">
				<sentence>Y. MT Domain-Relevant Adequacy % of TL words generated by MT engine that are open class , semantically adequate in their translation , and domain-relevant ( L/G ) In all of the systems there was a slight gain in domain-relevant faltering performance from the OCR pass to the GT pass .</sentence>
				<definiendum id="0">domain-relevant</definiendum>
				<definiens id="0">Adequacy % of TL words generated by MT engine that are open class</definiens>
			</definition>
</paper>

		<paper id="0403">
			<definition id="0">
				<sentence>We present a multi-document summarizer , called MEAD , which generates summaries using cluster centroids produced by a topic detection and tracking system .</sentence>
				<definiendum id="0">MEAD</definiendum>
				<definiens id="0">generates summaries using cluster centroids produced by a topic detection and tracking system</definiens>
			</definition>
			<definition id="1">
				<sentence>An event cluster , produced by a TDT system , consists of chronologically ordered news articles from multiple sources , which describe an event as it develops over time .</sentence>
				<definiendum id="0">event cluster</definiendum>
				<definiens id="0">consists of chronologically ordered news articles from multiple sources , which describe an event as it develops over time</definiens>
			</definition>
			<definition id="2">
				<sentence>Cluster-based sentence utility ( CBSU , or utility ) refers to the degree of relevance ( from 0 to 10 ) of a `` particular sentence to the general topic of the entire cluster ( for a dis cussion of what is a topic , see \ [ Allan et al. 1998\ ] ) .</sentence>
				<definiendum id="0">Cluster-based sentence utility</definiendum>
				<definiendum id="1">CBSU</definiendum>
				<definiens id="0">the degree of relevance ( from 0 to 10 ) of a `` particular sentence to the general topic of the entire cluster</definiens>
			</definition>
			<definition id="3">
				<sentence>subsumption ( CSIS ) A related notion to CBSU is cross-sentence informational subsumption ( CSIS , or subsumption ) , which reflects that certain sentences repeat some of the information present in other sentences and may , therefore , be omitted during summarization .</sentence>
				<definiendum id="0">subsumption ( CSIS ) A related notion to CBSU</definiendum>
				<definiens id="0">cross-sentence informational subsumption ( CSIS , or subsumption ) , which reflects that certain sentences repeat some of the information present in other sentences and may</definiens>
			</definition>
			<definition id="4">
				<sentence>Maximal marginal relevance ( or MMR ) is a technique similar to CSIS and was introduced in \ [ Carbonell and Goldstein , 1998\ ] .</sentence>
				<definiendum id="0">Maximal marginal relevance</definiendum>
				<definiendum id="1">MMR</definiendum>
			</definition>
			<definition id="5">
				<sentence>SCORE ( s ) = Zi ( wcC , + + wpJ where i ( 1 ~ i ~_ n ) is the sentence number within the cluster .</sentence>
				<definiendum id="0">SCORE</definiendum>
				<definiens id="0">the sentence number within the cluster</definiens>
			</definition>
			<definition id="6">
				<sentence>MEAD uses information from the centroids of the clusters to select sentences that are most likely to be relevant to the cluster topic .</sentence>
				<definiendum id="0">MEAD</definiendum>
				<definiens id="0">uses information from the centroids of the clusters to select sentences that are most likely to be relevant to the cluster topic</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>Spoken language engineering products proliferate in the market , commercial and research applications constantly increasing in variety and sophistication .</sentence>
				<definiendum id="0">Spoken language engineering products</definiendum>
				<definiens id="0">proliferate in the market , commercial and research applications constantly increasing in variety and sophistication</definiens>
			</definition>
			<definition id="1">
				<sentence>uic.edu/orgs/tei/ and http : //etext.virginia.eduffEI.html ) , the Corpus Encoding Standard ( CES ) ( http : //www.cs.vassar.edu/CES/ ) , and the European Advisory Group for Language Engineering Standards ( EAGLES ) ( http : //www.19 ilc .</sentence>
				<definiendum id="0">Corpus Encoding Standard ( CES ) ( http</definiendum>
				<definiens id="0">: //www.cs.vassar.edu/CES/ ) , and the European Advisory Group for Language Engineering Standards ( EAGLES ) ( http : //www.19 ilc</definiens>
			</definition>
			<definition id="2">
				<sentence>The MATE markup framework is a conceptual model which basically prescribes ( i ) how files are structured , for instance to enable multi-level annotation , ( ii ) how tag sets arc ; represented in terms of elements and attributes , and ( iii ) how to provide essential information on markup , semantics , coding purpose etc .</sentence>
				<definiendum id="0">MATE markup framework</definiendum>
				<definiens id="0">a conceptual model which basically prescribes ( i ) how files are structured , for instance to enable multi-level annotation , ( ii ) how tag sets arc ; represented in terms of elements and attributes , and ( iii ) how to provide essential information on markup , semantics , coding purpose etc</definiens>
			</definition>
			<definition id="3">
				<sentence>Given a coding purpose , such as to identify all communication problems in a particular corpus , and a coding module , the actual coding consists in using syntactic markup to encode the relevant phenomena found in the data .</sentence>
				<definiendum id="0">actual coding</definiendum>
				<definiens id="0">consists in using syntactic markup to encode the relevant phenomena found in the data</definiens>
			</definition>
			<definition id="4">
				<sentence>The basic markup primitive is the dement ( a term inherited from TEI and SGML ) which represents a phenomenon such as a particular phoneme , word , utterance , dialogue act , or communication problem .</sentence>
				<definiendum id="0">basic markup primitive</definiendum>
				<definiens id="0">the dement ( a term inherited from TEI and SGML ) which represents a phenomenon such as a particular phoneme , word , utterance , dialogue act , or communication problem</definiens>
			</definition>
			<definition id="5">
				<sentence>Values are numbers or identifiers , and the declaration of the timeline states how to interpret them .</sentence>
				<definiendum id="0">Values</definiendum>
				<definiens id="0">numbers or identifiers , and the declaration of the timeline states how to interpret them</definiens>
			</definition>
			<definition id="6">
				<sentence>• HREF\ [ MODULE , ELEMENTLIST\ ] : Here MODULE is the name of another coding module , and ELEMENTLIST is a list of names of elements from MODULE .</sentence>
				<definiendum id="0">MODULE</definiendum>
				<definiendum id="1">ELEMENTLIST</definiendum>
				<definiens id="0">a list of names of elements from MODULE</definiens>
			</definition>
			<definition id="7">
				<sentence>Markup declaration : ELEMENT eornprob ATTRIBUTES vtype : REFERENCE ( Violation_types , vtype ) wref : REFERENCE ( Basic_orthographic transcription , ( w , w ) + ) uref : REFERENCE ( Basic_orthographic transcription , u+ ) caused by : REFERENCE ( this , eomprob ) temp : TEXT ELEMENT note ATTRIBUTES wref : REFERENCE ( Basic_orthographic_ transcription , ( w , w ) + ) uref : REFERENCE ( Basic_orthographic_ transcription , u+ ) Description : In order to annotate communication problems produced by inadequate system utterance design we use the element eomprob .</sentence>
				<definiendum id="0">ELEMENT eornprob ATTRIBUTES vtype</definiendum>
				<definiendum id="1">TEXT ELEMENT note ATTRIBUTES wref</definiendum>
				<definiens id="0">In order to annotate communication problems produced by inadequate system utterance design we use the element eomprob</definiens>
			</definition>
			<definition id="8">
				<sentence>25 The attribute vtype is mandatory , vtype is a reference to a description of a guideline violation in a file which contains the different kinds of violations of the individual guidelines .</sentence>
				<definiendum id="0">vtype</definiendum>
				<definiens id="0">a reference to a description of a guideline violation in a file which contains the different kinds of violations of the individual guidelines</definiens>
			</definition>
</paper>

		<paper id="1318">
			<definition id="0">
				<sentence>disambiguation As the mapping method described in this paper has been developed for combining multiple individual solutions , each single heuristic must be seen as a container for some part of the linguistic knowledge needed to disarnbiguate the * This research was supported by KOSEF special purpose basic research ( 1997.92000.8 # 970-1020-301-3 ) Corresponding author 142 ambiguous WordNet synsets .</sentence>
				<definiendum id="0">heuristic</definiendum>
				<definiens id="0">a container for some part of the linguistic knowledge needed to disarnbiguate the *</definiens>
			</definition>
			<definition id="1">
				<sentence>Hi ( s , ) = max support ( s , , ew~ ) 1 ~'~ , ( n-1 ) +a k , =l where EWi = ( ewl s , ~ synset ( ew ) } In this formula , Hi ( s ) is a heuristic score of synset s , s is a candidate synset , ew is a translation into English , n is the number of translations and synset ( ew ) is the set of synsets of the translation ew .</sentence>
				<definiendum id="0">ew</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">a heuristic score of synset s , s is a candidate synset</definiens>
				<definiens id="1">a translation into English</definiens>
				<definiens id="2">the number of translations</definiens>
				<definiens id="3">the set of synsets of the translation ew</definiens>
			</definition>
			<definition id="2">
				<sentence>So Ew becomes the set of translations which have the synset s r. The parameter tx controls the relative contribution of candidate synsets in different number of translations : as the value of a increases , the candidate synsets in smaller number of translations get relatively less weight ( a=0.5 was tuned experimentally ) , support ( s , ew ) calculates the maximum similarity with the synset s and the translation ew , which is defined as : support ( si , ew ) = max S ( si , s ) sEsynset ( ew ) S2 ) = ~ S im ( st , s2 ) if sire ( s , , s2 ) _ &gt; 0 S ( sl , l 0 otherwise Similarity measures lower than a threshold 0 are considered to be noise and are ignored .</sentence>
				<definiendum id="0">support ( s , ew )</definiendum>
				<definiendum id="1">S im</definiendum>
				<definiens id="0">calculates the maximum similarity with the synset s and the translation ew</definiens>
				<definiens id="1">support ( si , ew ) = max S ( si , s ) sEsynset ( ew ) S2 ) = ~</definiens>
			</definition>
			<definition id="3">
				<sentence>sim ( s , s2 ) computes the conceptual similarity between concepts s~ and sz as in the following formula : sim ( sl , s2 ) = 2 x level ( MSCA ( sl , s : ) ) level ( sO + level ( s2 ) where MSCA ( sl , s2 ) represents the most specific common ancestor of concepts s~ and s2 and level ( s ) refers to the depth of concept s from the root node in the WordNetL This heuristic provides prior probability to each sense of a single translation as score .</sentence>
				<definiendum id="0">MSCA</definiendum>
				<definiendum id="1">level</definiendum>
				<definiens id="0">the most specific common ancestor of concepts s~ and s2</definiens>
				<definiens id="1">the depth of concept s from the root node in the WordNetL This heuristic provides prior probability to each sense of a single translation as score</definiens>
			</definition>
			<definition id="4">
				<sentence>H2 ( s , ) = max P ( s , l ew ) ¢ , n , E EW~ where EWi = { ew I si ~ synset ( ew ) } -nj where si ~ synset ( ewj ) , nj = Isyr et ( w , ) l In this formula , n is the number of synsets of the translation e~t~ .</sentence>
				<definiendum id="0">H2</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">s , ) = max P ( s , l ew ) ¢ , n , E EW~ where EWi = { ew I si ~ synset ( ew ) } -nj where si ~ synset ( ewj )</definiens>
				<definiens id="1">the number of synsets of the translation e~t~</definiens>
			</definition>
			<definition id="5">
				<sentence>Hs ( si ) = max WM ( si , ew ) where EW~ = ( ewl s~ ~ synset ( ew ) } WM ( si , ew ) = sim ( X , Yi ) sim ( X , Y ) = IX n YI Ix rl In this formula , X is the set of content words in English examples of bilingual dictionary and Y is 144 the set of content words of definition and example of the synset s , in WordNet .</sentence>
				<definiendum id="0">Hs</definiendum>
				<definiendum id="1">EW~ =</definiendum>
				<definiendum id="2">X</definiendum>
				<definiendum id="3">Y</definiendum>
				<definiens id="0">the set of content words in English examples of bilingual dictionary and</definiens>
				<definiens id="1">144 the set of content words of definition and example of the synset s , in WordNet</definiens>
			</definition>
			<definition id="6">
				<sentence>We define 'precision ' as the proportion of correctly linked senses of Korean words to all the linked senses of Korean words in a test set .</sentence>
				<definiendum id="0">'precision</definiendum>
				<definiens id="0">the proportion of correctly linked senses of Korean words to all the linked senses of Korean words in a test set</definiens>
			</definition>
			<definition id="7">
				<sentence>The test set here consists of the 3260 manually classified senses .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of the 3260 manually classified senses</definiens>
			</definition>
			<definition id="8">
				<sentence>Summing is a way to simply sum all the scores of each heuristic .</sentence>
				<definiendum id="0">Summing</definiendum>
				<definiens id="0">a way to simply sum all the scores of each heuristic</definiens>
			</definition>
			<definition id="9">
				<sentence>Logistic regression , as described in ( Hosmer and Lemeshow , 1989 ) , is a popular technique for binary classification .</sentence>
				<definiendum id="0">Logistic regression</definiendum>
				<definiens id="0">a popular technique for binary classification</definiens>
			</definition>
</paper>

		<paper id="1219">
			<definition id="0">
				<sentence>Mutual information Ml ( x , y ) of a bi-gram ( x , y ) is estimated by : Ml ( x , y ) = f ( x , y ) f ( x ) + f ( y ) f ( x , y ) Where f ( x ) is the occurrence frequency of word x in the corpus , and fix , y ) is the occurrence frequency of the word pair ( x , y ) in the corpus .</sentence>
				<definiendum id="0">f ( x )</definiendum>
				<definiendum id="1">y )</definiendum>
				<definiens id="0">the occurrence frequency of word x in the corpus</definiens>
				<definiens id="1">the occurrence frequency of the word pair ( x , y ) in the corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>is frequency , L is the set of left adjacent strings of X , tz~L and ILl means the number of unique left adjacent strings .</sentence>
				<definiendum id="0">L</definiendum>
				<definiendum id="1">ILl</definiendum>
				<definiens id="0">the set of left adjacent strings of X</definiens>
				<definiens id="1">the number of unique left adjacent strings</definiens>
			</definition>
			<definition id="2">
				<sentence>is frequency , R is the set of right adjacent strings of X , tiER and \ [ R I means the number of unique left adjacent strings .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the set of right adjacent strings of X , tiER and \ [ R I means the number of unique left adjacent strings</definiens>
			</definition>
			<definition id="3">
				<sentence>Corpus A consists of local news with more than 325 million characters .</sentence>
				<definiendum id="0">Corpus A</definiendum>
				<definiens id="0">local news with more than 325 million characters</definiens>
			</definition>
			<definition id="4">
				<sentence>Corpus B consists of documents from different domains of novel , news , technique report , etc. , with approximately 650 million characters .</sentence>
				<definiendum id="0">Corpus B</definiendum>
				<definiens id="0">consists of documents from different domains of novel , news , technique report , etc. , with approximately 650 million characters</definiens>
			</definition>
			<definition id="5">
				<sentence>Corpus C consists of People 's Daily news and Xinhua news from TREC5 and TREC6 ( Harman and Voorhees , 1996 ) with 75 million characters .</sentence>
				<definiendum id="0">Corpus C</definiendum>
				<definiens id="0">consists of People 's Daily news and Xinhua news from TREC5 and TREC6 ( Harman and Voorhees , 1996 ) with 75 million characters</definiens>
			</definition>
			<definition id="6">
				<sentence>MI measures the correlation between adjacent words , and other four parameters , namely LSize , RSize , MaxL , and MaxR , measure the context dependency .</sentence>
				<definiendum id="0">MI</definiendum>
				<definiendum id="1">MaxR</definiendum>
				<definiens id="0">measures the correlation between adjacent words</definiens>
			</definition>
			<definition id="7">
				<sentence>SMART is a robust , efficient and flexible information retrieval system .</sentence>
				<definiendum id="0">SMART</definiendum>
				<definiens id="0">a robust , efficient and flexible information retrieval system</definiens>
			</definition>
</paper>

		<paper id="1405">
			<definition id="0">
				<sentence>DTDs determine the logical structure of documents and how to tag them accordingly .</sentence>
				<definiendum id="0">DTDs</definiendum>
				<definiens id="0">determine the logical structure of documents and how to tag them accordingly</definiens>
			</definition>
			<definition id="1">
				<sentence>TM1 consists of aligned sentences than can feed commercial TM software .</sentence>
				<definiendum id="0">TM1</definiendum>
				<definiens id="0">consists of aligned sentences than can feed commercial TM software</definiens>
			</definition>
			<definition id="2">
				<sentence>TM2 contains elements which are translation segments ranging from whole sections of a document or multisentence paragraphs to smaller units , such as short phrases or proper names .</sentence>
				<definiendum id="0">TM2</definiendum>
				<definiens id="0">contains elements which are translation segments ranging from whole sections of a document or multisentence paragraphs to smaller units , such as short phrases or proper names</definiens>
			</definition>
			<definition id="3">
				<sentence>SGML mark-up determines the logical structure of a document and its syntax in the form of a context-free grammar .</sentence>
				<definiendum id="0">SGML mark-up</definiendum>
				<definiens id="0">determines the logical structure of a document and its syntax in the form of a context-free grammar</definiens>
			</definition>
			<definition id="4">
				<sentence>TM2 is managed in tile form of a relational database -where segments are stored , as records .</sentence>
				<definiendum id="0">TM2</definiendum>
				<definiens id="0">managed in tile form of a relational database -where segments are stored</definiens>
			</definition>
			<definition id="5">
				<sentence>The &lt; rs &gt; tag can be considered to be the name of the varying element .</sentence>
				<definiendum id="0">&gt; tag</definiendum>
				<definiens id="0">the name of the varying element</definiens>
			</definition>
</paper>

		<paper id="0729">
			<definition id="0">
				<sentence>This information consists of frequencies of events relevant to the process .</sentence>
				<definiendum id="0">information</definiendum>
				<definiens id="0">consists of frequencies of events relevant to the process</definiens>
			</definition>
			<definition id="1">
				<sentence>e~ i Aifi ( h , w ) P ( wlh ) = Z ( h ) where fi ( h , w ) refers to a ( binary valued ) feature function that describes a certain event ; Ai is a parameter that indicates how important feature fi is for the model and Z ( h ) is a normalisation factor .</sentence>
				<definiendum id="0">fi ( h , w )</definiendum>
				<definiendum id="1">Ai</definiendum>
				<definiendum id="2">Z ( h )</definiendum>
				<definiens id="0">a ( binary valued ) feature function that describes a certain event</definiens>
				<definiens id="1">a parameter that indicates how important feature fi is for the model</definiens>
				<definiens id="2">a normalisation factor</definiens>
			</definition>
</paper>

		<paper id="1216">
			<definition id="0">
				<sentence>Text meaning representation is composed of a set of ontological concept instances along with ontological links among them .</sentence>
				<definiendum id="0">Text meaning representation</definiendum>
				<definiens id="0">a set of ontological concept instances along with ontological links among them</definiens>
			</definition>
			<definition id="1">
				<sentence>TIVIR captures the meanings of words in the text and represents them in a set of ontological concepts interconnected through ontological relations .</sentence>
				<definiendum id="0">TIVIR</definiendum>
				<definiens id="0">captures the meanings of words in the text and represents them in a set of ontological concepts interconnected through ontological relations</definiens>
			</definition>
			<definition id="2">
				<sentence>An ontology is a set of knowledge concepts about the world .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">a set of knowledge concepts about the world</definiens>
			</definition>
			<definition id="3">
				<sentence>A semantic parser uses information in the semantic lex/con and makes a decision on word sense disambiguation based on the strategy proposed by Beale et aI .</sentence>
				<definiendum id="0">semantic parser</definiendum>
				<definiens id="0">uses information in the semantic lex/con</definiens>
			</definition>
			<definition id="4">
				<sentence>An ontology is a body of knowledge about the world .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">a body of knowledge about the world</definiens>
			</definition>
			<definition id="5">
				<sentence>In the MikroKosmos project , 2 the ontological concepts consist of : OBJECT , the static things existing in the world ; EVENT , any activities happening in the world , and PROPERTY , the properties of OBJECTs and EVENTs .</sentence>
				<definiendum id="0">PROPERTY</definiendum>
				<definiens id="0">the ontological concepts consist of : OBJECT , the static things existing in the world ; EVENT , any activities happening in the world</definiens>
			</definition>
			<definition id="6">
				<sentence>The semantic zone maps a sense into an ontological concept in the case of single sense , or to several concepts in the case of multiple senses .</sentence>
				<definiendum id="0">semantic zone</definiendum>
				<definiens id="0">maps a sense into an ontological concept in the case of single sense , or to several concepts in the case of multiple senses</definiens>
			</definition>
			<definition id="7">
				<sentence>The syntactic analysis gives the following output : ( ( ROOT ~ ) ( CAT V ) ( TRANS open ) ( s~J ( MODS ~\ [ \ ] ) ( CAT N ) ( TRANS China ) ( ROOT ~'~ ) ( CAT N ) ( TRANS government ) ) ( 0BJ ( ~0DS ( HODS ~ ) ( CAT ADJ ) ( TRAILS foreign ) ( ROOT ~ ~ ) ( CAT N ) ( TRNAS trade ) ) ( ROOT ~ ) ( CAT N ) ( TRANS policy ) ) ) ~PUTTEX~ S'VHTACIlCpA .</sentence>
				<definiendum id="0">China )</definiendum>
				<definiendum id="1">CAT N )</definiendum>
				<definiens id="0">ROOT ~ ) ( CAT V ) ( TRANS open )</definiens>
			</definition>
			<definition id="8">
				<sentence>Through IS-A links it is found that LAW is a descendant of OBJECT .</sentence>
				<definiendum id="0">LAW</definiendum>
				<definiens id="0">a descendant of OBJECT</definiens>
			</definition>
			<definition id="9">
				<sentence>The search inside the ontology also involves looking for metonymic type links , such as FEDERATION in a metonymic relation with HUMAN through the property HASREPRESENTATIVE : Concep % : IS-A : DOMAIN : RANGE : INVERSE : HAS-REPRESENTATIVE ORGANIZATION-RELATION ORGANIZATION HUMAN BUSINESS-ROLE GOVERNMENTAL-ROLE REPRESENTATIVE-OF in which DOMAIN is ORGANIZATION that has subclass FEDERATION and RANGE is HUMAN .</sentence>
				<definiendum id="0">RANGE</definiendum>
				<definiens id="0">HAS-REPRESENTATIVE ORGANIZATION-RELATION ORGANIZATION HUMAN BUSINESS-ROLE GOVERNMENTAL-ROLE REPRESENTATIVE-OF in which DOMAIN is ORGANIZATION that has subclass FEDERATION</definiens>
			</definition>
			<definition id="10">
				<sentence>i text meaning representation ( TMR ) is a language-neutral description of the meaning conveyed in a text .</sentence>
				<definiendum id="0">TMR</definiendum>
			</definition>
			<definition id="11">
				<sentence>From the result of word sense disambiguation , TMR integrates lexical , ontological and textual information into a single hierarchical framework .</sentence>
				<definiendum id="0">TMR</definiendum>
				<definiens id="0">integrates lexical , ontological and textual information into a single hierarchical framework</definiens>
			</definition>
			<definition id="12">
				<sentence>A knowledge-based machine translation can be viewed as extracting and representing the meaning of a text and generating a text in target language based on the meaning presented .</sentence>
				<definiendum id="0">knowledge-based machine translation</definiendum>
				<definiens id="0">extracting and representing the meaning of a text and generating a text in target language based on the meaning presented</definiens>
			</definition>
			<definition id="13">
				<sentence>It is because TMR represents meaning deeper and broader than what the context presents .</sentence>
				<definiendum id="0">TMR</definiendum>
				<definiens id="0">represents meaning deeper and broader than what the context presents</definiens>
			</definition>
</paper>

		<paper id="0312">
			<definition id="0">
				<sentence>CommandTalk is a spoken-language interface to the ModSAF ( Modular Semi-Automated Forces ) battlefield simulator , developed with the goal of allowing military commanders to interact with simulated forces in a manner as similar as possible to the way they would command actual forces .</sentence>
				<definiendum id="0">CommandTalk</definiendum>
				<definiens id="0">a spoken-language interface to the ModSAF ( Modular Semi-Automated Forces ) battlefield simulator</definiens>
			</definition>
			<definition id="1">
				<sentence>CommandTalk allows the use of ordinary English commands and mouse gestures to • Create forces and control measures ( points and lines ) • Assign missions to forces • Modify missions during execution • Control ModSAF system functions , such as the map display • Get information about the state of the simulation CommandTalk consists of a number of independent , cooperating agents interacting through SRI 's Open Agent Architecture ( OAA ) ( Martin et al. , 1998 ) .</sentence>
				<definiendum id="0">CommandTalk</definiendum>
			</definition>
			<definition id="2">
				<sentence>OAA uses a facilitator agent that plans and coordinates interactions among agents during distributed computation .</sentence>
				<definiendum id="0">OAA</definiendum>
				<definiens id="0">uses a facilitator agent that plans and coordinates interactions among agents during distributed computation</definiens>
			</definition>
			<definition id="3">
				<sentence>We collected four measures of performance : • Recognition time , measured , in multiples of CPU real time ( CPURT ) .</sentence>
				<definiendum id="0">CPURT</definiendum>
				<definiens id="0">CPU real time (</definiens>
			</definition>
</paper>

		<paper id="1105">
			<definition id="0">
				<sentence>We can confwm that a term is good to discriminate subject concepts if relevant documents contain such terms and non-relevant documents do not contain them and that a term is noisy if the situation is the opposite .</sentence>
				<definiendum id="0">good to discriminate subject concepts</definiendum>
				<definiendum id="1">noisy</definiendum>
				<definiens id="0">if relevant documents contain such terms and non-relevant documents do not contain them</definiens>
				<definiens id="1">if the situation is the opposite</definiens>
			</definition>
			<definition id="1">
				<sentence>NACSIS test collection I ( NTCIR , 1999 ) , which consists of a collection of abstracts of scientific papers ( 330,000 records , 590MB in text ) , two sets of topic description ( 30 topics for training and 53 topics for evaluation ) and relevance judgement , provides us of a good opportunity for this purpose .</sentence>
				<definiendum id="0">NACSIS test collection I</definiendum>
				<definiens id="0">consists of a collection of abstracts of scientific papers ( 330,000 records , 590MB in text ) , two sets of topic description ( 30 topics for training and 53 topics for evaluation ) and relevance judgement , provides us of a good opportunity for this purpose</definiens>
			</definition>
			<definition id="2">
				<sentence>&lt; narrative &gt; fields consist of 3 to 12 sentences and contain detailed explanation of the topic , term definition , background knowledge , purpose of the search , preference in text types , criteria of relevance judgement and so on .</sentence>
				<definiendum id="0">&lt; narrative &gt; fields</definiendum>
				<definiens id="0">consist of 3 to 12 sentences and contain detailed explanation of the topic , term definition , background knowledge , purpose of the search , preference in text types , criteria of relevance judgement and so on</definiens>
			</definition>
			<definition id="3">
				<sentence>number number of total of phrasal terms terms 45.0 10.3 44.7 10.2 46.4 10.8 46.5 10.9 25.4 5.2 57.0 12.5 25.5 5.3 57.3 12.7 58.4 13.1 58.4 13.1 20.9 4.1 21.8 4.5 ueries combining 4 fields For the baseline run experiments , we utilized the engine of Coneeptbase Search 1.2 , a commercial based search engine adopting vector space model approach .</sentence>
				<definiendum id="0">Coneeptbase Search 1.2</definiendum>
				<definiens id="0">a commercial based search engine adopting vector space model approach</definiens>
			</definition>
			<definition id="4">
				<sentence>NTCIR topic description consists of four fields namely &lt; title &gt; , &lt; description &gt; , &lt; narrative &gt; and &lt; concepts &gt; as shown in the previous chapter .</sentence>
				<definiendum id="0">NTCIR topic description</definiendum>
			</definition>
			<definition id="5">
				<sentence>o ~i `` O.1 ~15 02 O~ O~ O~ Figure 1 : p ( occlrel ) as function of p ( oce ) Left above : short query single words , Right above : short query phrases Left below : long query single words , Right below : long query phrases Greiff presented an analysis of TREC data plotting each query terms in view of distributions in the whole document collection and in relevant document sets ( Greiff , 1998 ) and Pickens et al. applied this analysis for statistical phrases ( Pickens et al , 2000 ) • Adopting their plotting approach , we will try to clarify distribution characteristics of phrasal terms using mainly p ( occlrel ) and p ( occ ) which are computed as document frequencies of the term in relevant documents/the whole collection respectively divided by each number of documents .</sentence>
				<definiendum id="0">p ( occ</definiendum>
				<definiens id="0">) which are computed as document frequencies of the term in relevant documents/the whole collection respectively divided by each number of documents</definiens>
			</definition>
			<definition id="6">
				<sentence>This topic consists of two concepts namely `` interference detection '' and `` polyhedral representation '' and the supplemented phrasal tom `` ~i~ifls : ra~\ ] '' ( between polyhedral ) is part of the second concept .</sentence>
				<definiendum id="0">topic</definiendum>
				<definiens id="0">consists of two concepts namely `` interference detection '' and `` polyhedral representation '' and the supplemented phrasal tom `` ~i~ifls : ra~\ ] '' ( between polyhedral ) is part of the second concept</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>The Level Adjusting Agent controls the initial detection and dynamic shifting of user expertise level based on the interactions with the user .</sentence>
				<definiendum id="0">Level Adjusting Agent</definiendum>
				<definiens id="0">controls the initial detection and dynamic shifting of user expertise level based on the interactions with the user</definiens>
			</definition>
			<definition id="1">
				<sentence>The Action Planner identifies the problem node ( i.e. , dialog goal ) in the Acyclic Problem Graph and locates the optimal path to it .</sentence>
				<definiendum id="0">Action Planner</definiendum>
				<definiens id="0">identifies the problem node</definiens>
			</definition>
			<definition id="2">
				<sentence>The Content Selection component uses the Level Adjusting Agent and the Action Planner to select the content for the dialog .</sentence>
				<definiendum id="0">Content Selection component</definiendum>
				<definiens id="0">uses the Level Adjusting Agent and the Action Planner to select the content for the dialog</definiens>
			</definition>
			<definition id="3">
				<sentence>Remedy is the template that is used to generate natural language responses and explanations corresponding to a particular goal .</sentence>
				<definiendum id="0">Remedy</definiendum>
				<definiens id="0">the template that is used to generate natural language responses and explanations corresponding to a particular goal</definiens>
			</definition>
			<definition id="4">
				<sentence>Reward and Punishment are the utility metrics corresponding to each sub-goal ( Winlder , 95 1972 ) depending upon the \ ] hypothesis of uncertainty of understanding and the level of importance .</sentence>
				<definiendum id="0">Punishment</definiendum>
				<definiens id="0">the utility metrics corresponding to each sub-goal ( Winlder , 95 1972 ) depending upon the \ ] hypothesis of uncertainty of understanding and the level of importance</definiens>
			</definition>
			<definition id="5">
				<sentence>Similarly , the worst-case time is the system expectation for the worst ease .</sentence>
				<definiendum id="0">worst-case time</definiendum>
				<definiens id="0">the system expectation for the worst ease</definiens>
			</definition>
			<definition id="6">
				<sentence>The Dialog Manager can be broadly classified into two main modules : Content Selection and Content Realization .</sentence>
				<definiendum id="0">Dialog Manager</definiendum>
				<definiens id="0">Content Selection and Content Realization</definiens>
			</definition>
			<definition id="7">
				<sentence>The Content Selection Module consists of four components : Level-Adjusting Agent , UtilityUpdating Agent , Action Planner and Content Selector .</sentence>
				<definiendum id="0">Content Selection Module</definiendum>
				<definiens id="0">Level-Adjusting Agent , UtilityUpdating Agent , Action Planner and Content Selector</definiens>
			</definition>
			<definition id="8">
				<sentence>Response Complexity : There is a reward and a punishment associated with each system response that reflects the complexity of the content and realization of the system responses .</sentence>
				<definiendum id="0">Response Complexity</definiendum>
				<definiens id="0">There is a reward and a punishment associated with each system response that reflects the complexity of the content and realization of the system responses</definiens>
			</definition>
			<definition id="9">
				<sentence>Based on the above factors , the ACCUM VALUE can be calculated depending upon the conditions using the following formulae : ACCUM VALUE = ACCUlvLVALUE + f/response -complexity ( reward , punishment ) , sub-goal ( reward , punishmen0 , timeout ( reward , punishment ) \ ] In the prototype system , we have used the following : If a goal is accomplished by the user ( indicated by positive user confirmation ) , ACCUM_VALUE = ACCUM ... VALUE + \ [ responsecomplexity ( reward ) * sub-goal ( reward ) \ ] If a goal is not accomplished ( indicated by negative user confirmation ) , ACCUM_VALUE = ACCUM .</sentence>
				<definiendum id="0">ACCUM VALUE</definiendum>
				<definiens id="0">indicated by positive user confirmation ) , ACCUM_VALUE = ACCUM ... VALUE + \ [ responsecomplexity ( reward ) * sub-goal ( reward</definiens>
			</definition>
			<definition id="10">
				<sentence>The utility of a path in the graph is the summation of the reward/punishment ratio of all the nodes ( subgoals ) in that path .</sentence>
				<definiendum id="0">utility of a path</definiendum>
				<definiens id="0">the summation of the reward/punishment ratio of all the nodes ( subgoals ) in that path</definiens>
			</definition>
			<definition id="11">
				<sentence>Path utility ( start-node , goal ) = E ( r i / Pi ) n where i is a concept node in the path from the start node to the goal node , ri is the reward and pl is the punishment of the corresponding node i. The number of nodes n in the path acts as the normalizing factor .</sentence>
				<definiendum id="0">Path utility</definiendum>
				<definiendum id="1">ri</definiendum>
				<definiendum id="2">pl</definiendum>
				<definiens id="0">a concept node in the path from the start node to the goal node</definiens>
				<definiens id="1">the punishment of the corresponding node i. The number of nodes n in the path acts as the normalizing factor</definiens>
			</definition>
</paper>

		<paper id="0404">
			<definition id="0">
				<sentence>Here , an event is the subject of a document itself , i.e. a writer wants to express , in other words , notions of who , what , where , when .</sentence>
				<definiendum id="0">event</definiendum>
				<definiens id="0">the subject of a document itself , i.e. a writer wants to express</definiens>
			</definition>
			<definition id="1">
				<sentence>A particular document consists of several II I II 32 I I I i I I i I paragraphs .</sentence>
				<definiendum id="0">particular document</definiendum>
				<definiens id="0">consists of several II I II 32 I I I i I I i I paragraphs</definiens>
			</definition>
			<definition id="2">
				<sentence>Domain dependency of words is a measure showing how greatly each word features a given set of data .</sentence>
				<definiendum id="0">Domain dependency of words</definiendum>
				<definiens id="0">a measure showing how greatly each word features a given set of data</definiens>
			</definition>
			<definition id="3">
				<sentence>In a similar way , Wpit denotes TF*IDF of the term t in the i-th paragraph .</sentence>
				<definiendum id="0">Wpit</definiendum>
				<definiens id="0">TF*IDF of the term t in the i-th paragraph</definiens>
			</definition>
			<definition id="4">
				<sentence>N is the number of documents and Ndt is the number of do ( : uments where t occurs .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">Ndt</definiendum>
				<definiens id="0">the number of documents and</definiens>
			</definition>
			<definition id="5">
				<sentence>DispOt = /I/E'~=l ( I4 ; dit mean ' ) 2 ( 2 ) ¥ Tn De vdi , = ( Wdit meant ) ,10+50 ( 3 ) DispDt Formula ( 2 ) is dispersion value of term t in the level of Document which consists of m documents , and denotes how frequently t appears across documents .</sentence>
				<definiendum id="0">DispOt</definiendum>
				<definiendum id="1">/I/E'~=l</definiendum>
				<definiens id="0">dispersion value of term t in the level of Document which consists of m documents , and denotes how frequently t appears across documents</definiens>
			</definition>
			<definition id="6">
				<sentence>In ( 2 ) and ( 3 ) , meant is the mean of the total TF*IDF values of term t in the level of Document .</sentence>
				<definiendum id="0">meant</definiendum>
				<definiens id="0">the mean of the total TF*IDF values of term t in the level of Document</definiens>
			</definition>
			<definition id="7">
				<sentence>Pi is an element of di .</sentence>
				<definiendum id="0">Pi</definiendum>
				<definiens id="0">an element of di</definiens>
			</definition>
			<definition id="8">
				<sentence>'Rec ' ( Recall ) is the immber of correct events divided by the total mnnber of events which are selected by a human , and 'Prec ' ( Precision ) stands for the number of correctevents divided by the number of events which are selected by our method .</sentence>
				<definiendum id="0">'Rec ' ( Recall )</definiendum>
				<definiens id="0">the immber of correct events divided by the total mnnber of events which are selected by a human</definiens>
				<definiens id="1">the number of correctevents divided by the number of events which are selected by our method</definiens>
			</definition>
			<definition id="9">
				<sentence>f ( w ) denotes term frequency of word w. Represent other training and test documents as term vectors = .</sentence>
				<definiendum id="0">f ( w )</definiendum>
			</definition>
			<definition id="10">
				<sentence>Let $ 1 : -- ' , S , , be all the other training documents ( where m is the number of training documents which does not belong to the target event ) and Sx be a test docmnent which should be classified as to whether or not it discusses the target event .</sentence>
				<definiendum id="0">m</definiendum>
				<definiendum id="1">Sx</definiendum>
				<definiens id="0">the number of training documents which does not belong to the target event</definiens>
				<definiens id="1">a test docmnent which should be classified as to whether or not it discusses the target event</definiens>
			</definition>
			<definition id="11">
				<sentence>'F/A ' shows false alarm rate and 'FI ' is a measure that balances recall and precision .</sentence>
				<definiendum id="0">'FI</definiendum>
				<definiens id="0">a measure that balances recall and precision</definiens>
			</definition>
			<definition id="12">
				<sentence>'Rec ' ( Recall ) is the nmnbet of correct events divided by the total number of events which are selected by a humaa , and : Pree ~ ( Precision ) stands for the number of correct-events divided by the number of events which are selected by our method .</sentence>
				<definiendum id="0">'Rec ' ( Recall )</definiendum>
			</definition>
			<definition id="13">
				<sentence>a term vector For the results of topic extraction , all the documents that belong to the sanae topic are bundled into a single document S , p and represent it by a term vector as follows : ~tp -~ ttpl ttp2 • s.t. ttpj = ttpn { / ( t , pj ) ift , pj is atoplc of Stp 0 otherwise f ( w ) denotes term frequency of word w. term vectors 35 Let $ 1 , -- - , S , , , be all the other training documents ( where m is the number of training documents which does not belong to the target event ) and Sx be a test document which should be classified as to whether or not it discusses the target event .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">document S , p and represent it by a term vector as follows : ~tp -~ ttpl ttp2 • s.t. ttpj</definiens>
				<definiens id="1">the number of training documents which does not belong to the target event</definiens>
				<definiens id="2">a test document which should be classified as to whether or not it discusses the target event</definiens>
			</definition>
			<definition id="14">
				<sentence>'Rec ' denotes the demonstrate~ that the criterion , domain dependency ratio of the documents judged YES that were also of words effectively employed , i evaluated as YES , and Tree ' is the percent of the Figure 6 illustrates the DET ( Detection Evalua| documents that were evaluated as YES which corretion Tradeoff ) curves for a sample event ( event type spond to documents actually judged as YES .</sentence>
				<definiendum id="0">Tree</definiendum>
				<definiens id="0">the demonstrate~ that the criterion , domain dependency ratio of the documents judged YES that were also of words effectively employed</definiens>
				<definiens id="1">the percent of the Figure 6 illustrates the DET ( Detection Evalua| documents that were evaluated as YES which corretion Tradeoff ) curves for a sample event ( event type spond to documents actually judged as YES</definiens>
			</definition>
			<definition id="15">
				<sentence>A variety of approaches exist for determining the salient sentences in the text : statistical techniques based oll word distribution ( Kupiec et al. , 1995 ) , ( Zechner , 1996 ) , ( Salton et al. , 1991 ) , ( Teufell and Moens , 1997 ) , symbolic techniques based on discourse structure ( Marcu , 1997 ) and semantic relations between words ( Barzil~v and Elhadad , 1997 ) .</sentence>
				<definiendum id="0">variety of approaches</definiendum>
				<definiens id="0">exist for determining the salient sentences in the text : statistical techniques based oll word distribution</definiens>
			</definition>
</paper>

		<paper id="1403">
			<definition id="0">
				<sentence>°ckem ) 2 3 2 3 3 1 Loosen Change Loosen Change Change Alter ( Desserrer ) ( Deplacer ) ( Verschieben ) ( Verandert ) Figure 1 : Contrasting multilingual discourse structure representations ( Delin et al. , 1994 , p. 63 ) how discourse structures differ across languages , we manually built a parallel corpus of discourse trees of newspaper Japanese texts and their corresponding English translations .</sentence>
				<definiendum id="0">Loosen Change Loosen Change Change Alter ( Desserrer ) ( Deplacer ) ( Verschieben )</definiendum>
				<definiens id="0">Contrasting multilingual discourse structure representations ( Delin et al. , 1994 , p. 63 ) how discourse structures differ across languages</definiens>
			</definition>
			<definition id="1">
				<sentence>Each node is characterized by a status ( NUCLEUS or SATELLITE ) and a rhetorical relation , which is a relation that holds between two non-overlapping text spans .</sentence>
				<definiendum id="0">rhetorical relation</definiendum>
				<definiens id="0">a relation that holds between two non-overlapping text spans</definiens>
			</definition>
			<definition id="2">
				<sentence>In order to provide a better estimate of how close two discourse trees were , we computed PositionDependent and -Independent recall and precision figures for the sentential level ( where units are given by edus and spans are given by sets of edus or single sentences ) ; paragraph level ( where units are given by sentences and spans are given by sets of sentences or single paragraphs ) : and text level ( where units are given by paragraphs and spans are given by sets of paragraphs ) .</sentence>
				<definiendum id="0">sentential level</definiendum>
				<definiendum id="1">paragraph level</definiendum>
				<definiendum id="2">text level</definiendum>
				<definiens id="0">where units are given by edus and spans are given by sets of edus or single sentences</definiens>
				<definiens id="1">where units are given by sentences and spans are given by sets of sentences or single paragraphs</definiens>
				<definiens id="2">where units are given by paragraphs and spans are given by sets of paragraphs</definiens>
			</definition>
</paper>

		<paper id="1205">
			<definition id="0">
				<sentence>( 1 ) Phrasal Categories predicate ( i.e. S is the start symbol ) .</sentence>
				<definiendum id="0">i.e. S</definiendum>
				<definiens id="0">the start symbol</definiens>
			</definition>
			<definition id="1">
				<sentence>Currently , the beta site allows users specify a variety of conditions to search for structurally annotated sentences .</sentence>
				<definiendum id="0">beta site</definiendum>
				<definiens id="0">allows users specify a variety of conditions to search for structurally annotated sentences</definiens>
			</definition>
</paper>

		<paper id="1427">
			<definition id="0">
				<sentence>In addition , the generalisation-exception architecture can be used to specify -- and also override -- preferences in cases where a lemma has more than one possible surface word form given a particular inflectional type and PoS label .</sentence>
				<definiendum id="0">generalisation-exception architecture</definiendum>
				<definiens id="0">a lemma has more than one possible surface word form given a particular inflectional type and PoS label</definiens>
			</definition>
			<definition id="1">
				<sentence>It is based on efficient finite-state techniques , and is implemented using the widely available Unix Flex utility ( a reimplementation of the AT &amp; T Unix Lex tool ) ( Levine et al. , 1992 ) .</sentence>
				<definiendum id="0">Unix Flex utility</definiendum>
			</definition>
			<definition id="2">
				<sentence>The morphological generator covers the productive English affixes s for the plural form of nouns and the third person singular present tense of verbs , and ed for the past tense , en for the past participle , and ing for the present participle forms of verbs .</sentence>
				<definiendum id="0">morphological generator</definiendum>
			</definition>
			<definition id="3">
				<sentence>A Flex description -- the high-level description of a scanner that Flex takes as input -- consists of a set of 'rules ' : pairs of regular expression patterns ( which Flex compiles into deterministic finite-state automata ( Aho et al. , 1986 ) ) , and actions consisting of arbitrary C code .</sentence>
				<definiendum id="0">Flex description</definiendum>
				<definiens id="0">the high-level description of a scanner that Flex takes as input -- consists of a set of 'rules ' : pairs of regular expression patterns ( which Flex compiles into deterministic finite-state automata</definiens>
			</definition>
			<definition id="4">
				<sentence>Flex creates as output a C program which at run-time scans a text looking for occurrences of the regular expressions .</sentence>
				<definiendum id="0">Flex</definiendum>
				<definiens id="0">creates as output a C program which at run-time scans a text looking for occurrences of the regular expressions</definiens>
			</definition>
			<definition id="5">
				<sentence>The morphological generator expects to receive as input a sequence of tokens of the form lemma+inflection_label , where lemma specifies tim lemma of the word form to be generated , inflection specifies the type of inflection ( i.e. s , ed~ cn or ing ) , and label specifies the PoS of the word form .</sentence>
				<definiendum id="0">lemma</definiendum>
				<definiens id="0">s , ed~ cn or ing ) , and label specifies the PoS of the word form</definiens>
			</definition>
			<definition id="6">
				<sentence>The system comprises two main components : an analysis module which downloads the source newspaper texts from the web and computes syntactic analyses for the sentences in them , and a simplification module which operates on the output of the analyser to improve the comprehensit ) ility of the text .</sentence>
				<definiendum id="0">analysis module</definiendum>
				<definiendum id="1">simplification module</definiendum>
				<definiens id="0">downloads the source newspaper texts from the web and computes syntactic analyses for the sentences in them</definiens>
			</definition>
			<definition id="7">
				<sentence>The SRI Core Language Engine ( A1shawi , 1992 ) uses a set of declarative segmentation rules which are similar in content to our rules and are used in reverse to generate word forms .</sentence>
				<definiendum id="0">SRI Core Language Engine</definiendum>
				<definiens id="0">uses a set of declarative segmentation rules which are similar in content to our rules and are used in reverse to generate word forms</definiens>
			</definition>
</paper>

		<paper id="1414">
			<definition id="0">
				<sentence>Quantification is an active research topic in logic , language , and philosophy ( Carpenter , 1997 ; de Swart .</sentence>
				<definiendum id="0">Quantification</definiendum>
				<definiens id="0">an active research topic in logic , language , and philosophy ( Carpenter , 1997 ; de Swart</definiens>
			</definition>
			<definition id="1">
				<sentence>The sentence planner takes a set of propositions ( or predicate-argument structures ) with rhetorical relations from the content planner and uses linguistic information to make decisions about how to convey the propositions fluently .</sentence>
				<definiendum id="0">sentence planner</definiendum>
				<definiens id="0">takes a set of propositions ( or predicate-argument structures ) with rhetorical relations from the content planner and uses linguistic information to make decisions about how to convey the propositions fluently</definiens>
			</definition>
			<definition id="2">
				<sentence>The input to our quaatifica~omalgorit ; hm is a set of predicate-argument structures after the referring expression module selected the properties to identify the entities ( Dale , 1992 ; Dale and Reiter , 1995 ) , but without carrying out the assignment of quantifiers .</sentence>
				<definiendum id="0">hm</definiendum>
				<definiens id="0">a set of predicate-argument structures after the referring expression module selected the properties to identify the entities</definiens>
				<definiens id="1">but without carrying out the assignment of quantifiers</definiens>
			</definition>
			<definition id="3">
				<sentence>CLASSIC ( Borgida et al. , 1989 ) and is a subset of WordNet ( Miller et alL , 1990 ) and an online medical dictionary ( Cimino et al. , 1994 ) designed to support multiple applications across the medical institution .</sentence>
				<definiendum id="0">CLASSIC</definiendum>
				<definiens id="0">a subset of WordNet ( Miller et alL , 1990 ) and an online medical dictionary ( Cimino et al. , 1994 ) designed to support multiple applications across the medical institution</definiens>
			</definition>
</paper>

		<paper id="0401">
			<definition id="0">
				<sentence>The abstract includes a list of topics which are terms appearing in the automatic abstract ( e.g. WebShaman ) or obtained from the source document by the process of term expansion ( e.g. WWW technique obtained from technique ) .</sentence>
				<definiendum id="0">abstract</definiendum>
				<definiens id="0">includes a list of topics which are terms appearing in the automatic abstract ( e.g. WebShaman ) or obtained from the source document by the process of term expansion ( e.g. WWW technique obtained from technique )</definiens>
			</definition>
			<definition id="1">
				<sentence>Virtual prototyping is a technique which has been suggested for use in , for example , telecommunication product development as a high-end technology to achieve a quick digital model that could be used in the same way as a real prototype .</sentence>
				<definiendum id="0">Virtual prototyping</definiendum>
				<definiens id="0">a technique which has been suggested for use in , for example , telecommunication product development as a high-end technology to achieve a quick digital model that could be used in the same way as a real prototype</definiens>
			</definition>
			<definition id="2">
				<sentence>Given a sentence• S and a type of information T the system verifies if the sentence matches some of the patterns associated with type T. For each matched pattern , the system extracts information from the sentence and instantiates a template of type T. For example , the Content slot of the problem identification template is instantiated with all the sentence • : ( avoiding references , structural elements and parenthetical expressions ) while the What slot 'of the topic of the document template is instantiated with a parsed sentence fragment • to the left or to the right of the make known relation depending on the attribute voice of the verb ( active vs. passive ) .</sentence>
				<definiendum id="0">voice of the verb</definiendum>
				<definiens id="0">active vs. passive</definiens>
			</definition>
			<definition id="3">
				<sentence>The informative abstract is the information obtained by this process as it is shown in Figure 1 .</sentence>
				<definiendum id="0">informative abstract</definiendum>
				<definiens id="0">the information obtained by this process as it is shown in Figure 1</definiens>
			</definition>
			<definition id="4">
				<sentence>PAWS ( the programmable automated welding system ) was designed to provide an automated means of planning , controlling , and performing critical welding operations for improving productivity and quality .</sentence>
				<definiendum id="0">PAWS</definiendum>
				<definiens id="0">the programmable automated welding system ) was designed to provide an automated means of planning</definiens>
			</definition>
			<definition id="5">
				<sentence>The final prototype consists of two jointed harvesting arms mounted on a human guided vehicle as shown schematically in Figure 1 Configuration of the robotic .</sentence>
				<definiendum id="0">final prototype</definiendum>
				<definiens id="0">consists of two jointed harvesting arms mounted on a human guided vehicle as shown schematically in Figure 1 Configuration of the robotic</definiens>
			</definition>
			<definition id="6">
				<sentence>Source Documents : we used twelve source documents from the journal Industrial Robots found on the Emerald Electronic Library ( all technical articles ) .</sentence>
				<definiendum id="0">Source Documents</definiendum>
				<definiens id="0">documents from the journal Industrial Robots found on the Emerald Electronic Library ( all technical articles )</definiens>
			</definition>
</paper>

		<paper id="0716">
			<definition id="0">
				<sentence>The prosodic information consists of ToBI labeling of accents and breaks ( Silverman et al. , 1992 ) .</sentence>
				<definiendum id="0">prosodic information</definiendum>
			</definition>
			<definition id="1">
				<sentence>Therefore the tree distance can be defined as the cost of the sequence minimizing this sum .</sentence>
				<definiendum id="0">tree distance</definiendum>
				<definiens id="0">the cost of the sequence minimizing this sum</definiens>
			</definition>
			<definition id="2">
				<sentence>The simple method that we have firstly used is the nearest neighbour algorithm : given a new sentence , the closest match among the corpus of sentences of known prosody is retrieved and used to infer the prosody of the new sentence .</sentence>
				<definiendum id="0">nearest neighbour algorithm</definiendum>
				<definiens id="0">given a new sentence , the closest match among the corpus of sentences of known prosody is retrieved and used to infer the prosody of the new sentence</definiens>
			</definition>
</paper>

		<paper id="1419">
			<definition id="0">
				<sentence>A CL consists of a glossary and of writing rules for the linguistic aspect of the documentation .</sentence>
				<definiendum id="0">CL</definiendum>
				<definiens id="0">consists of a glossary and of writing rules for the linguistic aspect of the documentation</definiens>
			</definition>
			<definition id="1">
				<sentence>G-TAG thus seems a good candidate for producing technical documentation complying with the constraints of an ( EM ) CL .</sentence>
				<definiendum id="0">G-TAG</definiendum>
				<definiens id="0">a good candidate for producing technical documentation complying with the constraints of an ( EM ) CL</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus nothing has to be changed in the What to say component ( Section 2.1 ) going from one language to the other .</sentence>
				<definiendum id="0">nothing</definiendum>
			</definition>
</paper>

		<paper id="1303">
			<definition id="0">
				<sentence>Conventional parsing techniques based on Machine Learning framework , such as Decision Trees and Maximum Entropy Models , have difficulty in selecting useful features as well as finding appropriate combination of selected features .</sentence>
				<definiendum id="0">Decision Trees</definiendum>
				<definiendum id="1">Maximum Entropy Models</definiendum>
				<definiens id="0">Conventional parsing techniques based on Machine Learning framework</definiens>
			</definition>
			<definition id="1">
				<sentence>Yi is a scalar value that specifies the class ( positive ( +l ) or negative ( l ) class ) of i-th data .</sentence>
				<definiendum id="0">Yi</definiendum>
				<definiens id="0">a scalar value that specifies the class ( positive ( +l ) or negative ( l ) class ) of i-th data</definiens>
			</definition>
			<definition id="2">
				<sentence>Statistical dependency structure analysis is defined as a searching problem for the dependency pattern D that maximizes the conditional probability P ( DIB ) of the in20 put sequence under the above-mentioned constraints .</sentence>
				<definiendum id="0">Statistical dependency structure analysis</definiendum>
				<definiens id="0">a searching problem for the dependency pattern D that maximizes the conditional probability P ( DIB ) of the in20 put sequence under the above-mentioned constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>Sekine suggests an efficient parsing technique for Japanese sentences that parses from the end of a sentence ( Sekine et al. , 2000 ) .</sentence>
				<definiendum id="0">Sekine</definiendum>
			</definition>
			<definition id="4">
				<sentence>In order to use SVMs for dependency analysis , we need to prepare positive and negative examples since SVMs is a binary classifier .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">a binary classifier</definiens>
			</definition>
</paper>

		<paper id="1213">
			<definition id="0">
				<sentence>An information structure consists of two components : HowNet definitions and dependency relations .</sentence>
				<definiendum id="0">information structure</definiendum>
				<definiens id="0">consists of two components : HowNet definitions and dependency relations</definiens>
			</definition>
			<definition id="1">
				<sentence>The second one , the Sinica Treebank , which is derived from the Sinica corpus , contains 38,725 sentences with 1000 of them released to the public 1 ( CKIP , 2000 ) .</sentence>
				<definiendum id="0">Sinica Treebank</definiendum>
			</definition>
			<definition id="2">
				<sentence>HowNet is a bilingual general knowledge-base describing relations between concepts and relations between the attributes of concepts .</sentence>
				<definiendum id="0">HowNet</definiendum>
				<definiens id="0">a bilingual general knowledge-base describing relations between concepts and relations between the attributes of concepts</definiens>
			</definition>
			<definition id="3">
				<sentence>The pattern of information structure is specified in the following format : ( sememe ) \ [ DRel\ ] ~ \ [ DRel\ ] ( sememe ) , where DRel means the name of a dependency relation .</sentence>
				<definiendum id="0">DRel</definiendum>
				<definiens id="0">means the name of a dependency relation</definiens>
			</definition>
</paper>

		<paper id="0721">
			<definition id="0">
				<sentence>Given an input string O = &lt; ol , 02 , ... , On &gt; , a phrase is a substring of consecutive input symbols oi , oi+l , ... , oj .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">a substring of consecutive input symbols oi , oi+l , ... , oj</definiens>
			</definition>
			<definition id="1">
				<sentence>Local signals can indicate that an input symbol o is inside or outside a phrase ( IO modeling ) or they can indicate that an input symbol o opens or closes a phrase ( the OC modeling ) or some combination of the two .</sentence>
				<definiendum id="0">Local signals</definiendum>
				<definiens id="0">inside or outside a phrase ( IO modeling ) or they can indicate that an input symbol o opens or closes a phrase ( the OC modeling ) or some combination of the two</definiens>
			</definition>
			<definition id="2">
				<sentence>HMM is a probabilistic finite state automaton used to model the probabilistic generation of sequential processes .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">a probabilistic finite state automaton used to model the probabilistic generation of sequential processes</definiens>
			</definition>
			<definition id="3">
				<sentence>Pt ( s ) can be calculated by Pt ( s ) = Es'eS P ( sls ' ) Pt-l ( s ' ) where Pl ( s ) and P ( sls ' ) are the two required distribution for the HMM .</sentence>
				<definiendum id="0">Pt</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">s ) = Es'eS P ( sls ' ) Pt-l ( s ' ) where Pl ( s ) and</definiens>
			</definition>
			<definition id="4">
				<sentence>Hence , we associate a cost function c : E ~ \ [ 0,1\ ] with each variable , and then find a solution ~of f of minimum cost , c ( ~- ) = n Ei=l In phrase identification , the solution to the optimization problem corresponds to a shortest path in a directed acyclic graph constructed on the observation symbols , with legitimate phrases ( the variables in E ) as its edges and their costs as the weights .</sentence>
				<definiendum id="0">legitimate phrases</definiendum>
				<definiens id="0">a shortest path in a directed acyclic graph constructed on the observation symbols</definiens>
			</definition>
			<definition id="5">
				<sentence>The SNoW learning architecture learns a sparse network of linear functions , in which the targets ( states , in this case ) are represented as linear functions over a common feature space .</sentence>
				<definiendum id="0">SNoW learning architecture</definiendum>
				<definiens id="0">learns a sparse network of linear functions , in which the targets ( states , in this case ) are represented as linear functions over a common feature space</definiens>
			</definition>
			<definition id="6">
				<sentence>We experimented both with base noun phrases ( NP ) and subject-verb patterns ( SV ) and show results for two different representations of the observations ( that is , different feature sets for the classifiers ) part of speech ( POS ) tags only and POS with additional lexical information ( words ) .</sentence>
				<definiendum id="0">base noun phrases</definiendum>
				<definiens id="0">subject-verb patterns ( SV ) and show results for two different representations of the observations ( that is , different feature sets for the classifiers ) part of speech ( POS ) tags only and POS with additional lexical information ( words )</definiens>
			</definition>
			<definition id="7">
				<sentence>The NB ( naive Bayes ) and SNoW classifiers use the same feature set , conjunctions of size 3 of POS tags ( + words ) in a window of size 6 around the target word .</sentence>
				<definiendum id="0">NB</definiendum>
				<definiens id="0">naive Bayes ) and SNoW classifiers use the same feature set , conjunctions of size 3 of POS tags ( + words ) in a window of size 6 around the target word</definiens>
			</definition>
</paper>

		<paper id="1412">
			<definition id="0">
				<sentence>Language is the best conceivable means to transfer information as pointedly as possible .</sentence>
				<definiendum id="0">Language</definiendum>
				<definiens id="0">the best conceivable means to transfer information as pointedly as possible</definiens>
			</definition>
			<definition id="1">
				<sentence>Investigation is a rich source of occurrences that should not happen in civil aircraft WINDOW , TURNING THE HANDLE , PULL , and LET operations .</sentence>
				<definiendum id="0">Investigation</definiendum>
				<definiens id="0">a rich source of occurrences that should not happen in civil aircraft WINDOW</definiens>
			</definition>
			<definition id="2">
				<sentence>Incremental processing is the 'piecemeal ' and parallel processing of a sequential information stream .</sentence>
				<definiendum id="0">Incremental processing</definiendum>
				<definiens id="0">the 'piecemeal ' and parallel processing of a sequential information stream</definiens>
			</definition>
			<definition id="3">
				<sentence>Figure 2 sketches such a cascade of dependent parallel processes in our model of the conceptualizer : The cascade consists of the processes construction , selection , linearization , and pvm-generation ( preverbal-message-generation ) .</sentence>
				<definiendum id="0">cascade</definiendum>
				<definiens id="0">consists of the processes construction , selection , linearization , and pvm-generation ( preverbal-message-generation )</definiens>
			</definition>
			<definition id="4">
				<sentence>In addition to the cascaded processes there is a concept lexicon , accessible via a concept matcher : these modules , which are called by the construction process , find best matches for structures that can either be subsumed by a more complex concept or may represent still incomplete concepts .</sentence>
				<definiendum id="0">construction process</definiendum>
				<definiens id="0">find best matches for structures that can either be subsumed by a more complex concept or may represent still incomplete concepts</definiens>
			</definition>
			<definition id="5">
				<sentence>4 On the other hand , after the two nodes STARTi and CHPOS~ ( Figure 3 ) are constructed , these are given to the concept matcher for a subsumption test , which consists of trying to match the nodes onto more complex concepts .</sentence>
				<definiendum id="0">subsumption test</definiendum>
				<definiens id="0">consists of trying to match the nodes onto more complex concepts</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus , it informs the construction process that a STOP event ( STOPs ) will probably occur in the near future , which illustrates the second function of the matcher : the generation of expectations .</sentence>
				<definiendum id="0">construction process</definiendum>
				<definiendum id="1">STOPs</definiendum>
			</definition>
			<definition id="7">
				<sentence>The construction process takes basic entities as input and builds up a hierarchical knowledge representation of the perceived states of affairs in the CCR .</sentence>
				<definiendum id="0">construction process</definiendum>
				<definiens id="0">takes basic entities as input and builds up a hierarchical knowledge representation of the perceived states of affairs in the CCR</definiens>
			</definition>
			<definition id="8">
				<sentence>MOVE2 , for example , is temporally included in the event TAXI ( MOVE2 E TAXI ) , the event MOVEt is the temporal predecessor of MOVE2 ( MOVEi - &lt; MOVE ? )</sentence>
				<definiendum id="0">MOVE2</definiendum>
				<definiendum id="1">event MOVEt</definiendum>
				<definiens id="0">the temporal predecessor of MOVE2 ( MOVEi - &lt; MOVE ?</definiens>
			</definition>
			<definition id="9">
				<sentence>The Knowledge Representation for the Example ( STOP2 is only expected ) movement from position A to B. MOVE is a label for complex events that consists of maximally three sub-events , namely START , CHPOS ( CHANGE OF POSITION ) , and STOP , where the first and the last sub-event are optional and the middle event can be any kind of movement along a trajectory .</sentence>
				<definiendum id="0">Knowledge Representation</definiendum>
				<definiens id="0">only expected ) movement from position A to B. MOVE is a label for complex events that consists of maximally three sub-events , namely START , CHPOS ( CHANGE OF POSITION ) , and STOP , where the first and the last sub-event are optional and the middle event can be any kind of movement along a trajectory</definiens>
			</definition>
			<definition id="10">
				<sentence>START , CHPOS , and STOP nodes contain the sensor data nodes S. Temporal inclusion relates also TAXI and the basic events and MOVE and basic events , but are left : out in the figure to keep it readable .</sentence>
				<definiendum id="0">STOP nodes</definiendum>
				<definiens id="0">contain the sensor data nodes S. Temporal inclusion relates also TAXI and the basic events</definiens>
			</definition>
			<definition id="11">
				<sentence>The construction process , which builds up the representation of the actually registered events and to detect problems , can be realized by the following algorithm vided by the pre-processing unit .</sentence>
				<definiendum id="0">construction process</definiendum>
				<definiens id="0">builds up the representation of the actually registered events and to detect problems</definiens>
			</definition>
</paper>

		<paper id="1420">
			<definition id="0">
				<sentence>VERBMOBIL is a speech-to-speech translation project , which at present is approaching its end and in which over 100 researchers 1 at academic and industrial sites are developing a translation system for multilingual negotiation dialogues ( held face to face or via telephone ) using English , German , and Japanese .</sentence>
				<definiendum id="0">VERBMOBIL</definiendum>
				<definiens id="0">a speech-to-speech translation project , which at present is approaching its end and in which over 100 researchers 1 at academic and industrial sites are developing a translation system for multilingual negotiation dialogues ( held face to face or via telephone ) using English , German , and Japanese</definiens>
			</definition>
			<definition id="1">
				<sentence>The deep translation track consists of an HPSG based analysis , semantic transfer and finally a TAG-based generator ( VMGECO ) .</sentence>
				<definiendum id="0">deep translation track</definiendum>
				<definiens id="0">consists of an HPSG based analysis , semantic transfer and finally a TAG-based generator ( VMGECO )</definiens>
			</definition>
			<definition id="2">
				<sentence>The top object is a move with two roles : A source location ( which is a city Hanover ) , and a departure time ( which is a date day 1 ) .</sentence>
				<definiendum id="0">top object</definiendum>
			</definition>
			<definition id="3">
				<sentence>The task of the semantic constructor is to map the information about sentences computed by the plan processor to full semantic representations ( VITs ) .</sentence>
				<definiendum id="0">semantic constructor</definiendum>
				<definiens id="0">to map the information about sentences computed by the plan processor to full semantic representations ( VITs )</definiens>
			</definition>
			<definition id="4">
				<sentence>s ) ) ) Figure 6 : Example of sentence definition and generation ( ACCOMMODATION ( ACCEPTED ( HAS_SIZE VIT : &lt; Einzelzimmer &gt; ) ( HAS_PRICE VIT : &lt; 80-Euro-pro-Nacht &gt; ) ) ) Figure 7 : Exmnple of a plan processor output plan processor output it has to play different semantic roles in the sentence ( e.g. , verb-argument vs. verb-complement ) Additionally , the number of DtREx-VITs given within a building block for a sentence , influences the distribution of them to appropriate semantic roles .</sentence>
				<definiendum id="0">ACCOMMODATION</definiendum>
				<definiendum id="1">ACCEPTED</definiendum>
			</definition>
			<definition id="5">
				<sentence>During'the course of the generation , the plan processor incrementally constructs a context ( Dale , 1995 ) , which allows for the generation of , c.f. , anaphora or demonstratives for making the text fluent or contrasting purposes .</sentence>
				<definiendum id="0">plan processor</definiendum>
				<definiens id="0">allows for the generation of , c.f. , anaphora or demonstratives for making the text fluent or contrasting purposes</definiens>
			</definition>
</paper>

		<paper id="0710">
			<definition id="0">
				<sentence>Regression analysis of the experimental results reveals that , in order for ECOC to be successful for language learning , the use of the Modified Value Difference Metric ( MVDM ) is an important factor , which is explained in terms of population density of the class hyperspace .</sentence>
				<definiendum id="0">Modified Value Difference Metric</definiendum>
				<definiendum id="1">MVDM )</definiendum>
				<definiens id="0">an important factor , which is explained in terms of population density of the class hyperspace</definiens>
			</definition>
			<definition id="1">
				<sentence>Error-correcting output codes ( ECOC ) have been introduced to machine learning as a principled and successful approach to distributed class encoding ( Dietterich and Bakiri , 1995 ; Ricci and Aha , 1997 ; Berger , 1999 ) .</sentence>
				<definiendum id="0">Error-correcting output codes</definiendum>
				<definiendum id="1">ECOC</definiendum>
				<definiens id="0">introduced to machine learning as a principled and successful approach to distributed class encoding</definiens>
			</definition>
			<definition id="2">
				<sentence>Rows are the codewords corresponding to classes , and columns are binary subclassifications or bit functions fi such that , for an instance e , and its codeword vector C fi ( e ) = ~-i ( c ) ( 1 ) ( ~-i ( v ) the i-th coordinate of vector v ) .</sentence>
				<definiendum id="0">Rows</definiendum>
				<definiens id="0">the codewords corresponding to classes , and columns are binary subclassifications or bit functions fi such that , for an instance e</definiens>
			</definition>
			<definition id="3">
				<sentence>The communication channel consists of the trained classifier .</sentence>
				<definiendum id="0">communication channel</definiendum>
				<definiens id="0">consists of the trained classifier</definiens>
			</definition>
			<definition id="4">
				<sentence>The noise consists of the bias ( systematic error ) and variance ( training set-dependent error ) of the classifier , which together make up for the overall error 55 of the classifier .</sentence>
				<definiendum id="0">noise</definiendum>
				<definiendum id="1">variance</definiendum>
				<definiens id="0">consists of the bias ( systematic error</definiens>
			</definition>
			<definition id="5">
				<sentence>• Adding non-locality to 1-3 in the form of larger values for k. • The use of the Modified Value Difference Metric , which alters the distribution of instances over the hyperspace of features , yielding different class boundaries .</sentence>
				<definiendum id="0">Modified Value Difference Metric</definiendum>
				<definiens id="0">alters the distribution of instances over the hyperspace of features</definiens>
			</definition>
			<definition id="6">
				<sentence>The simplest distance metric is the overlap metric : k ( 3 ) 5 ( vi , vj ) = 0 if vi = vj 5 ( vi , vj ) = 1 if vi ¢ vj ( ~ri ( I ) is the i-th projection of the feature vector I. ) Another distance metric is the Modified Value Difference Metric ( MVDM ) ( Cost and Salzberg , 1993 ) .</sentence>
				<definiendum id="0">simplest distance metric</definiendum>
				<definiendum id="1">Value Difference Metric</definiendum>
				<definiendum id="2">MVDM )</definiendum>
				<definiens id="0">the i-th projection of the feature vector I. ) Another distance metric is the Modified</definiens>
			</definition>
			<definition id="7">
				<sentence>IBi-IG is a k-nearest distance classifier which employs a weighted overlap metric : ~ ( I~ , b ) = ~ wkS ( ~k ( /~ ) , ~ ( Ij ) ) ( 5 ) k In stead of drawing winners from the k-nearest neighbors pool , IBi-IG selects from a pool of instances for k nearest distances .</sentence>
				<definiendum id="0">IBi-IG</definiendum>
				<definiens id="0">a k-nearest distance classifier which employs a weighted overlap metric : ~ ( I~ , b ) = ~ wkS ( ~k ( /~ )</definiens>
			</definition>
			<definition id="8">
				<sentence>The first quantity is normalized with the a priori probabilities of the various feature values of feature F : H ( C ) Eveva es ( F ) P ( v ) × H ( QF=v\ ] ) ( 6 ) Here , H ( C ) is the class entropy , defined as H ( C ) =~ P ( c ) log 2P ( c ) .</sentence>
				<definiendum id="0">H ( C )</definiendum>
				<definiens id="0">the class entropy , defined as H ( C ) =~ P ( c ) log 2P ( c )</definiens>
			</definition>
			<definition id="9">
				<sentence>( 7 ) cEClass H ( C\ [ F=v\ ] ) is the class entropy computed over the subset of instances that have v as value for Fi .</sentence>
				<definiendum id="0">cEClass H</definiendum>
				<definiendum id="1">] )</definiendum>
			</definition>
			<definition id="10">
				<sentence>H ( C ) -- ~veValues ( Fi ) P ( v ) xH ( C\ [ F=v\ ] ) Wi -- -split_in f o ( Fi ) split info ( Fi ) = ~ P ( v ) log 2 P ( v ) vE Values ( Fi ) ( s ) IGTREE is a heuristic approximation of IB1IG which has comparable accuracy , but is optimized for speed .</sentence>
				<definiendum id="0">H</definiendum>
				<definiendum id="1">Fi ) P</definiendum>
				<definiens id="0">( v ) xH ( C\ [ F=v\ ] ) Wi -- -split_in f o ( Fi ) split info ( Fi ) = ~ P ( v ) log 2 P ( v ) vE Values ( Fi ) ( s ) IGTREE is a heuristic approximation of IB1IG which has comparable accuracy , but is optimized for speed</definiens>
			</definition>
			<definition id="11">
				<sentence>GRAPHON , finally , is a grapheme-to-phoneme conversion task for English based on the English Celex lexical database .</sentence>
				<definiendum id="0">GRAPHON</definiendum>
				<definiens id="0">is a grapheme-to-phoneme conversion task for English based on the English Celex lexical database</definiens>
			</definition>
			<definition id="12">
				<sentence>The results show that disALGORITHM DESCRIPTION E1 £2 E3 E4 £5 £6 £7 $ 8 ECOC , feature selection per bit ( 15 ) , k -- -- l , unweighted ECOC , feature selection per bit ( 15 ) , k -- -- l , weighted ECOC , feature selection per bit ( 15 ) , MVDM , k=l , unweighted ECOC , feature selection per bit ( 15 ) , MVDM , k=l , weighted ECOC , feature selection per bit ( 15 ) , MVDM , k -- -- 3 , unweighted ECOC , feature selection per bit ( 15 ) , MVDM , k=3 , weighted ECOC , voting ( 100 ) per bit ( 30 ) , MVDM , k=3 ECOC , voting ( 100 ) per bit block ( 15 ) , MVDM , k=3 Table 2 : Algorithms GRouP I II III IV IBi-IG IBi-IG IBi-IG IBi-IG ' k=l k=3 k=l k=3 MVDM MVDM 98.1±0.5 DIMIN STRESS MORPH NPVP GRAPHON 98.1±0.5 83.5±2.6 92.5±1.4 96.4±0.2 97.1±2.4 95.8±0.5 81.3±2.9 92.0±1.4 97.1±0.2 97.2±2.3 97.7±0.7 86.2±2.0 92.5±1.4 97.0±0.1 97.7±0.7 86.7±1.8 92.5±1.4 97.0±0.1 97.7±0.8 Table 3 : Generalization accuracies control groups .</sentence>
				<definiendum id="0">ECOC</definiendum>
				<definiendum id="1">Algorithms GRouP I II III IV IBi-IG IBi-IG IBi-IG IBi-IG</definiendum>
			</definition>
			<definition id="13">
				<sentence>These sets typically tend to benefit from the Modified Value Difference Metric , which creates a condensed hyperspace of features .</sentence>
				<definiendum id="0">Modified Value Difference Metric</definiendum>
				<definiens id="0">creates a condensed hyperspace of features</definiens>
			</definition>
</paper>

		<paper id="0740">
			<definition id="0">
				<sentence>Constraint Specialises Defined on Head features Yes Compiled Gap threading Yes Compiled RHS length No Compiled LHS ~ RHS No Compiled Head OK No Readable LHS not sigma No Needs LHS not new No Needs LHS not s No Needs Table h Linguistic constraints constraints Gap-threading is a technique originating with Pereira 's 'extraposition grammars ' ( Pereira , 1981 ) .</sentence>
				<definiendum id="0">Gap-threading</definiendum>
			</definition>
			<definition id="1">
				<sentence>In our case the meta-interpreter is the chart parser augmented with the generation of needs and the partial proof is represented by the chart augmented with the needs .</sentence>
				<definiendum id="0">meta-interpreter</definiendum>
				<definiens id="0">the chart parser augmented with the generation of needs</definiens>
			</definition>
			<definition id="2">
				<sentence>Translating his approach to the language of this paper , Wirth asks the user to verify that proposed needed atoms ( our needed edges ) are truly needed .</sentence>
				<definiendum id="0">Wirth</definiendum>
				<definiens id="0">asks the user to verify that proposed needed atoms ( our needed edges ) are truly needed</definiens>
			</definition>
			<definition id="3">
				<sentence>His approach is incremental and the induction of new rules is triggered by an unparsable sentence as follows : daughters are edges in the chart after the failed parse , and the mother is one of these daughters , possibly with its bar level raised .</sentence>
				<definiendum id="0">mother</definiendum>
				<definiens id="0">incremental and the induction of new rules is triggered by an unparsable sentence as follows : daughters are edges in the chart after the failed parse , and the</definiens>
			</definition>
</paper>

		<paper id="0902">
			<definition id="0">
				<sentence>WordSmith Tools ( Scott , 1998 ) offers a program for comparing corpora , known as KeyWords .</sentence>
				<definiendum id="0">WordSmith Tools</definiendum>
				<definiens id="0">offers a program for comparing corpora , known as KeyWords</definiens>
			</definition>
			<definition id="1">
				<sentence>Introduction WordSmith Tools ( Scott , 1998 ) offers a program for comparing corpora , known as KeyWords .</sentence>
				<definiendum id="0">WordSmith Tools</definiendum>
				<definiens id="0">offers a program for comparing corpora , known as KeyWords</definiens>
			</definition>
			<definition id="2">
				<sentence>A KeyWord list is a portion of the study corpus word list .</sentence>
				<definiendum id="0">KeyWord list</definiendum>
				<definiens id="0">a portion of the study corpus word list</definiens>
			</definition>
</paper>

		<paper id="1411">
			<definition id="0">
				<sentence>Text Planning is one of the distinct tasks identified in Reiter 's `` consensus '' architecture for Natural Language Generation ( Reiter 1994 , Reiter and Dale 1997 ) : Text Planningdeciding the content of a message , and organising the component propositions into a text tree ; Sentence Planning aggregating propositions into clausal units and choosing lexical items corresponding to concepts in the knowledge base ; Linguistic realisation surface details Such as agreement , orthography etc .</sentence>
				<definiendum id="0">Text Planning</definiendum>
				<definiens id="0">one of the distinct tasks identified in Reiter 's `` consensus '' architecture for Natural Language Generation ( Reiter 1994 , Reiter and Dale 1997 ) : Text Planningdeciding the content of a message , and organising the component propositions into a text tree ; Sentence Planning aggregating propositions into clausal units and choosing lexical items corresponding to concepts in the knowledge base</definiens>
			</definition>
			<definition id="1">
				<sentence>The center in an utterance Un is the most grammatically salient entity realised in U~_i which is also realised in Un .</sentence>
				<definiendum id="0">center in an utterance Un</definiendum>
				<definiens id="0">the most grammatically salient entity realised in U~_i which is also realised in Un</definiens>
			</definition>
			<definition id="2">
				<sentence>That is , the Text Planner would plan the content of Un+l by aiming to realise a proposition in the knowledge base which mentions an entity which is salient in Un .</sentence>
				<definiendum id="0">Text Planner</definiendum>
				<definiens id="0">plan the content of Un+l by aiming to realise a proposition in the knowledge base which mentions an entity which is salient in Un</definiens>
			</definition>
			<definition id="3">
				<sentence>Prince ( 1999 ) notes that definitions of `` topic '' in the literature do not provide objective tests for topichood and proposes that the topic should be identified with the centre of attention as defined by CT ; however , what would be needed here would be a more fimdamental definition which would , account for a particular entity being chosen to be tile centre of attention .</sentence>
				<definiendum id="0">Prince ( 1999 ) notes</definiendum>
				<definiens id="0">definitions of `` topic '' in the literature do not provide objective tests for topichood and proposes that the topic should be identified with the centre of attention as defined by CT ; however , what would be needed here would be a more fimdamental definition which would , account for a particular entity being chosen to be tile centre of attention</definiens>
			</definition>
			<definition id="4">
				<sentence>concession approve ( fda , elixir-plus ) cause NUCL~ S~LITE ban ( fda , elixir ) contain ( elixir , gestodene ) Figure 2 : Rhetorical structure The text planner has been developed within ICONOCLAST , a project which investigates applications of constraint-based reasoning in Natural Language Generation using as subjectmatter the domain of medical information leaflets .</sentence>
				<definiendum id="0">ICONOCLAST</definiendum>
				<definiens id="0">a project which investigates applications of constraint-based reasoning in Natural Language Generation using as subjectmatter the domain of medical information leaflets</definiens>
			</definition>
			<definition id="5">
				<sentence>The implementation of Centering reported here is a special case of text planning by constraint satisfaction , where the user has control over the different constraints , and this approach means that different strategies for e.g. clause ordering and pronominalisation can easily be compared by inspecting the resulting texts .</sentence>
				<definiendum id="0">Centering</definiendum>
				<definiens id="0">a special case of text planning by constraint satisfaction , where the user has control over the different constraints</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>A dialogue move engine updates the information state on the basis of observed dialogue moves and selects appropriate moves to be performed .</sentence>
				<definiendum id="0">dialogue move engine</definiendum>
				<definiens id="0">updates the information state on the basis of observed dialogue moves and selects appropriate moves to be performed</definiens>
			</definition>
			<definition id="1">
				<sentence>The ACTIONS field is a stack of ( domain ) actions which the user has been instructed to perform but has not yet performed .</sentence>
				<definiendum id="0">ACTIONS field</definiendum>
			</definition>
			<definition id="2">
				<sentence>The LU field contains information about the latest utterance .</sentence>
				<definiendum id="0">LU field</definiendum>
				<definiens id="0">contains information about the latest utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>RULE : integrateUsrConfirm CLASS : integrate val ( SHARED .</sentence>
				<definiendum id="0">integrateUsrConfirm CLASS</definiendum>
			</definition>
			<definition id="4">
				<sentence>BEL , clozte ( A ) ) This rule says that if the user performed a Confirm move , which has not yet been integrated , and A is the `` most salient '' action , then integrate the move by putting the proposition done ( A ) in the shared beliefs , and taking A off the action stack .</sentence>
				<definiendum id="0">BEL</definiendum>
				<definiens id="0">has not yet been integrated</definiens>
			</definition>
</paper>

		<paper id="1101">
			<definition id="0">
				<sentence>Assuming that a specific domain corresponds to a single SFC ( or a restricted set of SFCs , at most ) , the difference between SFC assignment and our task is that the former assigns one of many possible values to a given synset ( one of all possible SFCs ) , while the latter assigns one of two possible values ( the words belongs or does not belong to the SFC representing the domain ) .</sentence>
				<definiendum id="0">SFC</definiendum>
				<definiens id="0">a given synset ( one of all possible SFCs</definiens>
			</definition>
			<definition id="1">
				<sentence>We define a synonymy relation as a binary relation between two synonym terms ( with respect to • a particular sense ) .</sentence>
				<definiendum id="0">synonymy relation</definiendum>
				<definiens id="0">a binary relation between two synonym terms</definiens>
			</definition>
			<definition id="2">
				<sentence>The goal of ranking synonymy relations is to associate them with a score that estimates how often a synonymy relation is likely to be used in the specific domain .</sentence>
				<definiendum id="0">synonymy relation</definiendum>
				<definiens id="0">to associate them with a score that estimates how often a</definiens>
			</definition>
</paper>

		<paper id="0109">
</paper>

		<paper id="0901">
			<definition id="0">
				<sentence>A difference coefficient defined by Yule ( 1944 ) showed the relative frequency of a word in the two corpora .</sentence>
				<definiendum id="0">difference coefficient</definiendum>
				<definiens id="0">showed the relative frequency of a word in the two corpora</definiens>
			</definition>
			<definition id="1">
				<sentence>He selects the Mann-Whitney test that : uses ranks of frequency data rather than the frequency values themselves to compute the statistic .</sentence>
				<definiendum id="0">Mann-Whitney test</definiendum>
				<definiens id="0">uses ranks of frequency data rather than the frequency values themselves to compute the statistic</definiens>
			</definition>
			<definition id="2">
				<sentence>This is a subcorpus of circa 4.5 million words , in which speakers and respondents are identified by such factors as gender , age , social group and geographical region .</sentence>
				<definiendum id="0">circa 4.5 million words</definiendum>
				<definiens id="0">in which speakers and respondents are identified by such factors as gender , age , social group and geographical region</definiens>
			</definition>
			<definition id="3">
				<sentence>The text is analysed by a part-of-speech tagger , CLAWS ( Garside and Smith , 1997 ) , and a semantic analyser ( Rayson and Wilson , 1996 ) which assigns semantic tags that represent the semantic field ( word-sense ) of words from a lexicon of single words and an idiom list of multi-word combinations ( e.g. ~ a rule ) .</sentence>
				<definiendum id="0">semantic analyser</definiendum>
				<definiens id="0">assigns semantic tags that represent the semantic field ( word-sense ) of words from a lexicon of single words and an idiom list of multi-word combinations</definiens>
			</definition>
			<definition id="4">
				<sentence>The log-likelihood test is applied as described in the previous section and represents the semantic tag 's frequency deviation from the normative corpus .</sentence>
				<definiendum id="0">log-likelihood test</definiendum>
				<definiens id="0">described in the previous section and represents the semantic tag 's frequency deviation from the normative corpus</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>The preferences of an agent are expressed as functions which map states , represented as sets of attribute-value pairs , to real numbers ; an overall utility function , which consists of the weighted sum of the individual functions , expresses the utility of reaching the state depicted by a certain configuration of attributes , according to the results of the multi-attribute utility theory ( Haddawy and Hanks , 1998 ) .</sentence>
				<definiendum id="0">The preferences of an agent</definiendum>
				<definiens id="0">functions which map states , represented as sets of attribute-value pairs , to real numbers</definiens>
			</definition>
			<definition id="1">
				<sentence>On the basis of his goals and of the recipes he knows , an agent builds a set of plans , by selecting the recipes which have among their effects one ( or more ) of the goals in the set .</sentence>
				<definiendum id="0">agent</definiendum>
				<definiens id="0">builds a set of plans , by selecting the recipes which have among their effects one ( or more ) of the goals in the set</definiens>
			</definition>
			<definition id="2">
				<sentence>Obligations are pro-attitudes that impose less commitment than intentions ( so that they can be violated ) , while their social character explains why humans are solicited to act , in both cooperative and non cooperative contexts .</sentence>
				<definiendum id="0">Obligations</definiendum>
				<definiens id="0">pro-attitudes that impose less commitment than intentions ( so that they can be violated ) , while their social character explains why humans are solicited to act , in both cooperative and non cooperative contexts</definiens>
			</definition>
			<definition id="3">
				<sentence>~Led = 0 : irefusedL = 1 time= 6 REACT ( A ) REACT ( A ) ITB = 38'7 $ 3 A re8 = 19 off = 0 B tee = 42 goal = 1 S~ g'~ed = 1 ze~ed : 0 time : 9 = 448 Figure 4 : Two of B 's alternative plans in response to A 's request ( action React ( time = time + i ) ( res = res i ) ( offended = offended + ( not ( grounded ) ) * Wi + ( refused / cost ( action ) ) * W~ ) ) Figure 5 : The partner 's reaction Us= ( ress * Wi ) ( time * W~ ) ( offended * Ws ) + ( goal * We ) Figure 6 : The utilitY function of B utility function of B models a more balanced tra~ : le-off between the achievement of B 's private goMs and social preferences , B will decide to ground A 's request , at least , or to be fully cooperative by satisfying A 's request .</sentence>
				<definiendum id="0">) REACT</definiendum>
				<definiendum id="1">Wi + ( refused / cost</definiendum>
				<definiendum id="2">partner 's reaction Us=</definiendum>
				<definiens id="0">Two of B 's alternative plans in response to A 's request ( action React ( time = time + i )</definiens>
				<definiens id="1">le-off between the achievement of B 's private goMs and social preferences , B will decide to ground A 's request , at least , or to be fully cooperative by satisfying A 's request</definiens>
			</definition>
</paper>

		<paper id="0205">
			<definition id="0">
				<sentence>The LCS represents predicate argument structure abstracted away from languagespecific properties of semantics and syntax .</sentence>
				<definiendum id="0">LCS</definiendum>
				<definiens id="0">predicate argument structure abstracted away from languagespecific properties of semantics and syntax</definiens>
			</definition>
			<definition id="1">
				<sentence>This not only fails to recognize the regularities we see in English ( and other language ) LCS structures , for Chinese it merely pushes the problem back one step , as the set of implicitly realizable relations may vary from language to language and may result in some ungrammatical or misleading translations .</sentence>
				<definiendum id="0">LCS structures</definiendum>
				<definiens id="0">the set of implicitly realizable relations may vary from language to language and may result in some ungrammatical or misleading translations</definiens>
			</definition>
			<definition id="2">
				<sentence>The LCS framework consists of primitives ( GO , BE , STAY , etc. ) , types ( Event , State , Path , etc. ) and fields ( Loc ( ational ) , Temp ( oral ) , Foss ( essional ) , Ident ( ificational ) , Perc ( eptual ) , etc. ) .</sentence>
				<definiendum id="0">LCS framework</definiendum>
				<definiendum id="1">Loc</definiendum>
				<definiens id="0">consists of primitives ( GO , BE , STAY , etc. ) , types ( Event , State , Path , etc. ) and fields</definiens>
			</definition>
			<definition id="3">
				<sentence>The generation component consists of the following subcomponents : Decomposition and lexlcal selection First , primitive LCSes for words in the target language are matched against CLCSes , and tree structures of covering words are selected .</sentence>
				<definiendum id="0">generation component</definiendum>
				<definiens id="0">consists of the following subcomponents : Decomposition and lexlcal selection First , primitive LCSes for words in the target language are matched against CLCSes , and tree structures of covering words are selected</definiens>
			</definition>
			<definition id="4">
				<sentence>While these numbers are small , this preliminary data seems to suggest again that atelicity is a good cue for cotemporality , while telicity is not a sufficient cue .</sentence>
				<definiendum id="0">atelicity</definiendum>
				<definiens id="0">a good cue for cotemporality</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , is The President believed China to be a threat equivalent to The president believed China is a threat ) .</sentence>
				<definiendum id="0">China</definiendum>
				<definiens id="0">a threat )</definiens>
			</definition>
</paper>

		<paper id="1426">
			<definition id="0">
				<sentence>which makes the crucial distinction between nucleus , which is the most important part of a message , and satellite , which is the peripheral part of the message .</sentence>
				<definiendum id="0">nucleus</definiendum>
				<definiendum id="1">satellite</definiendum>
				<definiens id="0">the most important part of a message</definiens>
				<definiens id="1">the peripheral part of the message</definiens>
			</definition>
			<definition id="1">
				<sentence>These approaches share the idea that rhetorical representations are composed of propositions linked by rhetorical relations ; SDRT includes as well the logical apparatus of DRT , thus covering notions like necessity and logical scope which are missing from RST .</sentence>
				<definiendum id="0">SDRT</definiendum>
				<definiens id="0">includes as well the logical apparatus of DRT , thus covering notions like necessity and logical scope which are missing from RST</definiens>
			</definition>
			<definition id="2">
				<sentence>In the RAGS proposal , which aims to extract a useful common approach from current work in NLG , the DocRep comprises an ordered tree corresponding roughly to the 'logical markup ' in notations like HTML and LaTeX .</sentence>
				<definiendum id="0">RAGS proposal</definiendum>
				<definiendum id="1">DocRep</definiendum>
				<definiens id="0">comprises an ordered tree corresponding roughly to the 'logical markup ' in notations like HTML and LaTeX</definiens>
			</definition>
			<definition id="3">
				<sentence>Assuming that we are comparing two trees , the strongest notion of compatibility is isomorphism , which can be defined for our purposes as follows : DocRep is isomorphic with RhetRep if they group the elementary propositions in exactly the same way .</sentence>
				<definiendum id="0">DocRep</definiendum>
				<definiens id="0">isomorphic with RhetRep if they group the elementary propositions in exactly the same way</definiens>
			</definition>
			<definition id="4">
				<sentence>However , for some kinds of material ( e.g. , complex instructions ) , extraposition is a convenient rhetorical device which might improve the readability of the generated texts , so it is worth considering how a text planner might be configured so as to allow solutions that violate compatibility .</sentence>
				<definiendum id="0">extraposition</definiendum>
				<definiens id="0">a convenient rhetorical device which might improve the readability of the generated texts , so it is worth considering how a text planner might be configured so as to allow solutions that violate compatibility</definiens>
			</definition>
			<definition id="5">
				<sentence>The abstract representation AbsRhetRep expresses the rhetorical content of the underlying message , while the concrete RhetRep expresses the rhetorical structure directly realized in the text and corresponds to the representation used by Scott and Souza ( 1990 ) to discuss textual realisation .</sentence>
				<definiendum id="0">abstract representation AbsRhetRep</definiendum>
				<definiens id="0">expresses the rhetorical content of the underlying message</definiens>
			</definition>
			<definition id="6">
				<sentence>extraposition-iof. : a , proposition .</sentence>
				<definiendum id="0">extraposition-iof.</definiendum>
			</definition>
			<definition id="7">
				<sentence>The sometimes competing informational and intentional roles of discourse segments have been at the centre of the debate over the nucleus-satellite distinction ( Moore and Pollack , 1992 ; Moser and Moore , 1996 ; Bateman and Rondhius , 1997 ) ; the accessibility of discourse segments on the right frontier of a discourse structure is a phenomenon that has already been discussed by several researchers ( Webber , 1991 ; Asher , 1993 ) .</sentence>
				<definiendum id="0">discourse segments</definiendum>
			</definition>
</paper>

		<paper id="1402">
			<definition id="0">
				<sentence>The architecture of the argument generator is a typical pipelined architecture comprising a discourse planner , a microplanner and a sentence real izer .</sentence>
				<definiendum id="0">architecture of the argument generator</definiendum>
				<definiens id="0">a typical pipelined architecture comprising a discourse planner , a microplanner and a sentence real izer</definiens>
			</definition>
			<definition id="1">
				<sentence>However , evaluations based on judgements along these dimensions are clearly weaker than evaluations measuring actual attitudinal and Arguing an evaluation involves an intentional communicative act that attempts to affect the current or future behavior of the addressees by creating , changing or reinforcing the addressees ' attitudes .</sentence>
				<definiendum id="0">Arguing an evaluation</definiendum>
				<definiens id="0">involves an intentional communicative act that attempts to affect the current or future behavior of the addressees by creating , changing or reinforcing the addressees ' attitudes</definiens>
			</definition>
			<definition id="2">
				<sentence>The IDEA environment provides the user with a set of powerful visualization and direct manipulation techniques that facilitate user 's autonomous exploration of the set of alternatives and the selection of the preferred alternatives .</sentence>
				<definiendum id="0">IDEA environment</definiendum>
				<definiens id="0">provides the user with a set of powerful visualization and direct manipulation techniques that facilitate user 's autonomous exploration of the set of alternatives and the selection of the preferred alternatives</definiens>
			</definition>
</paper>

		<paper id="0402">
			<definition id="0">
				<sentence>\ [ Discourse Type Sufficiency Necessity Causality Deduction ¢\ [ dversativity Concession Conjunction Disjunction Progression Table Discourse Primary Marker ruguo 'if ' , name 'then ' zhiyou 'only if ' , cai 'only \ [ hen ' ¢inwei 'because ' , suoyi 'therefore ' iiran 'given that ' , name 'then ' suiran 'although ' , danshi 'but ' `` ishi 'even if ' , rengran 'still ' chule 'except ' , jianzhi 'also ' huozhe 'or ' , huozhe 'or ' ~udan 'not only ' , erqie 'but also ' / Examples of Discourse Markers Markers Discourse Type Summary Contrast fflustration Specification Generalization Digression rtemization Paraphrasing Equivalence Enquiry ludgment Secondary Marker zong er yan zhi 'in one word ' ~hishi shang 'in fact ' liru 'for example ' tebie shi 'in particular ' dati er yan 'in general ' wulun ruhe 'anyway ' shouxian 'first ' , qici `` next '' huan ju hua shuo 'in other words ' zhengru 'just as ' nandao ( 'does it mean ... ' ) kexi 'unfortunately ' and Associated Rhetorical Relations in Chinese It may be noted that our analysis of Chinese has yielded about 150 discourse markers , and that on the average , argumentative text ( e.g. editorials ) in Chinese shows more than one third of the discourse segments to contain discourse markers .</sentence>
				<definiendum id="0">Contrast fflustration Specification Generalization Digression rtemization Paraphrasing Equivalence Enquiry ludgment Secondary Marker</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the deeper linguistic analysis the two so 's may be related , for they refer to a situation involving excessive height with implied consequence which may or may not be stated .</sentence>
				<definiendum id="0">the two so 's</definiendum>
				<definiens id="0">a situation involving excessive height with implied consequence which may or may not be stated</definiens>
			</definition>
			<definition id="2">
				<sentence>OTi : the Order Type of RR ; .</sentence>
				<definiendum id="0">OTi</definiendum>
				<definiens id="0">the Order Type of RR ;</definiens>
			</definition>
			<definition id="3">
				<sentence>For Apparent Discourse Markers ( ADM ) that do not function as real discourse markers in a text , a different 3-tuple coding scheme is used to encode them : ADM~ = &lt; LIi , * , SNi &gt; where , LIi : the Lexical Item of the ADM. SNi : the Sequence Number of the ADM. To illustrate the above coding scheme consider the following examples of encoded sentences where every CDM has been tagged to be either a 7-tuple or a 3-tuple .</sentence>
				<definiendum id="0">LIi</definiendum>
				<definiendum id="1">SNi</definiendum>
				<definiens id="0">the Lexical Item of the ADM.</definiens>
			</definition>
			<definition id="4">
				<sentence>We denote this as a binary relation Causality ( FrontClause ( 2 ) , BaekClause ( 2 ) ) where FrontClause ( n ) denotes the discourse segment that is encapsulated by the Front discourse marker of the corresponding rhetorical relation whose sequence number is n. 15 BackClause ( n ) can be defined similarly .</sentence>
				<definiendum id="0">FrontClause</definiendum>
				<definiens id="0">the discourse segment that is encapsulated by the Front discourse marker of the corresponding rhetorical relation whose sequence number</definiens>
			</definition>
			<definition id="5">
				<sentence>From the above tagging , we can obtain the following discourse structure with embedding relations : A dversativity ( &amp; F ( 14 ) , Sufficiency ( F rontClause ( 15 ) , BackClause ( 15 ) ) ) where &amp; F ( n ) denotes the Front discourse segment of an inter-sentence rhetorical relation whose sequence number is n. We can define &amp; B ( n ) similarly .</sentence>
				<definiendum id="0">F ( n )</definiendum>
				<definiens id="0">denotes the Front discourse segment of an inter-sentence rhetorical relation whose sequence number is n. We can define &amp; B ( n ) similarly</definiens>
			</definition>
			<definition id="6">
				<sentence>The following are two examples : • `` , '' , dan 'but ' , youyu 'since ' , Xianggang 'Hong Kong ' , de 'of ' , T. • zhe 'this ' , yi 'also ' , zhishi 'is only ' , Xianggang 'Hong Kong ' , de 'of ' , F. where `` T '' denotes the CDM youyu as a discourse marker in the given context , and `` F '' denotes that zhishi is not a discourse marker .</sentence>
				<definiendum id="0">T ''</definiendum>
				<definiendum id="1">F</definiendum>
				<definiens id="0">a discourse marker in the given context , and ``</definiens>
			</definition>
			<definition id="7">
				<sentence>This information gain measures the expected reduction in entropy and defines one branch for the possible subset Si of the training examples .</sentence>
				<definiendum id="0">information gain</definiendum>
				<definiens id="0">measures the expected reduction in entropy and defines one branch for the possible subset Si of the training examples</definiens>
			</definition>
			<definition id="8">
				<sentence>If a CDM is the first , the second or the last word of a sentence , values of F2 , F1 , or B2 will be null , we denote a null-value as `` * '' .</sentence>
				<definiendum id="0">CDM</definiendum>
				<definiendum id="1">B2</definiendum>
				<definiens id="0">the first , the second or the last word of a sentence , values of F2 , F1 , or</definiens>
			</definition>
			<definition id="9">
				<sentence>( discourse sense ) Algorithm ( with C4.5 ) In Section 6 , we discuss how machine learning techniques have been applied to the problem of discourse marker disambiguation in Chinese .</sentence>
				<definiendum id="0">Algorithm</definiendum>
				<definiens id="0">machine learning techniques have been applied to the problem of discourse marker disambiguation in Chinese</definiens>
			</definition>
</paper>

		<paper id="0308">
			<definition id="0">
				<sentence>GsG exploits taskand language-dependent information but is fully taskand language-independent in its architecture and strategies .</sentence>
				<definiendum id="0">GsG</definiendum>
				<definiens id="0">exploits taskand language-dependent information but is fully taskand language-independent in its architecture and strategies</definiens>
			</definition>
			<definition id="1">
				<sentence>In this paper we report on GSG , a conversational system that partially addresses these issues by being able to dynamically extend its linguistic knowledge through simple , natural-language only interactions with non-expert users : On a purely on-need basis , i.e. , when the system does not understand what the user means , GSG makes educated guesses , poses confirmation and clarification questions , and learns new semantic mappings from the answers given by the users , as well as from other linguistic information that they may volunteer .</sentence>
				<definiendum id="0">GSG</definiendum>
				<definiens id="0">makes educated guesses , poses confirmation and clarification questions , and learns new semantic mappings from the answers given by the users</definiens>
			</definition>
			<definition id="2">
				<sentence>The Ontology is a directed acyelic graph automatically derived from the Grammar in which the nodes correspond to grammar nonterminals ( NTs ) and the arcs record immediate dominance relation , i.e. , the presence of , say , NTi in a right-hand side ( RHS ) alternative of NTj will result in an arc from NTi to NTj .</sentence>
				<definiendum id="0">Ontology</definiendum>
				<definiendum id="1">right-hand side</definiendum>
				<definiendum id="2">RHS</definiendum>
				<definiens id="0">a directed acyelic graph automatically derived from the Grammar in which the nodes correspond to grammar nonterminals ( NTs ) and the arcs record immediate dominance relation</definiens>
			</definition>
			<definition id="3">
				<sentence>Nodes are annotated as being `` Principal '' vs. `` Auxiliary '' ( via naming convention ) , `` Top-level '' vs. `` Non-top level '' ( i.e. , whether they are starting symbols of the grammar ) , and with having `` Only NT daughters '' vs. `` Only T daughters '' vs. `` Mixed '' ; arcs are annotated as being `` Is-a '' ( estimated from being the only non-optional NT in a RHS alternative ) vs. `` Expresses '' links , `` Always-required '' vs. `` Alwaysoptional '' vs. `` Mixed , '' and `` Never-repeatable '' vs. ZIn the work reported here , GsG 's interactions are textbased ( keyboard as input , text window as output ) , but GsG is being integrated with both a speech recognizer and a speech synthesizer .</sentence>
				<definiendum id="0">GsG</definiendum>
				<definiendum id="1">GsG</definiendum>
				<definiens id="0">'s interactions are textbased ( keyboard as input , text window as output ) , but</definiens>
			</definition>
			<definition id="4">
				<sentence>The GSG Engine manages the core of the systems ' `` intelligence , '' namely hypothesizing interpretations ( together with the Parse Tree Builder ) and on-line learning of semantic mappings .</sentence>
				<definiendum id="0">GSG Engine</definiendum>
				<definiens id="0">manages the core of the systems ' `` intelligence , '' namely hypothesizing interpretations ( together with the Parse Tree Builder ) and on-line learning of semantic mappings</definiens>
			</definition>
			<definition id="5">
				<sentence>ARGUMENT \ [ datePoiRt : DATE_RELATIVE\ ] I \ [ daZePoint : DATE_FIXED\ ] I ... \ [ DATE_RELATIVE : yesterday\ ] \ [ \ [ DATE_RELATIVE : tomorrow\ ] I ... yesterday Figure 3 : Grammar fragment for an e-mail client task. '</sentence>
				<definiendum id="0">ARGUMENT</definiendum>
			</definition>
			<definition id="6">
				<sentence>NILDCARD is a special NT that matches any out-of-vocabulary word or any in-vocabulary word present in a list for that purpose .</sentence>
				<definiendum id="0">NILDCARD</definiendum>
				<definiens id="0">a special NT that matches any out-of-vocabulary word or any in-vocabulary word present in a list for that purpose</definiens>
			</definition>
			<definition id="7">
				<sentence>A current limitation of GsG lies in the difficulty of segmenting long sequences of unparsed words : GSG uses POS tagging followed by noun-phrase bracketing ( via parsing with a shallow Syntactic Grammar ) , which represents an improvement over the Single Segment Assumption ( cf. ( Lehman , 1989 ) ) , but is still far from perfect and can disrupt the ensuing clarification dialogue .</sentence>
				<definiendum id="0">Segment Assumption</definiendum>
				<definiens id="0">via parsing with a shallow Syntactic Grammar ) , which represents an improvement over the Single</definiens>
			</definition>
</paper>

		<paper id="0725">
			<definition id="0">
				<sentence>Recent work ( Johnson , 1998 ) has explored the performance of parsers based on a probabilistic context-free grammar ( PCFG ) extracted from a training corpus .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">the performance of parsers based on a probabilistic context-free grammar (</definiens>
			</definition>
			<definition id="1">
				<sentence>The PCFG obtained in this way consists of rules that include information about the context where the rule is applied .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">consists of rules that include information about the context where the rule is applied</definiens>
			</definition>
</paper>

		<paper id="0718">
			<definition id="0">
				<sentence>We present ALLiS , a learning system for identifying syntactic structures which uses theory refinement .</sentence>
				<definiendum id="0">ALLiS</definiendum>
				<definiens id="0">a learning system for identifying syntactic structures which uses theory refinement</definiens>
			</definition>
			<definition id="1">
				<sentence>Theory refinement ( hereafter TR ) consists of improving an existing knowledge base so that it fits more with data .</sentence>
				<definiendum id="0">Theory refinement ( hereafter TR )</definiendum>
				<definiens id="0">consists of improving an existing knowledge base so that it fits more with data</definiens>
			</definition>
			<definition id="2">
				<sentence>ALLiS ( Architecture for Learning Linguistic Structures ) ( D~jean , 2000a ) is a symbolic machine learning system which generates categorisation rules from a tagged and bracketed corpus .</sentence>
				<definiendum id="0">ALLiS ( Architecture for Learning Linguistic Structures )</definiendum>
				<definiens id="0">a symbolic machine learning system which generates categorisation rules from a tagged and bracketed corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>The lexicalisation consists Context Tag Word Left Right W L R VBG operating NN 1 1 VBG recurring NNS 1 1 VBG continuing NNS 1 1 Table 3 : Lexicalisation of the tag VBG .</sentence>
				<definiendum id="0">lexicalisation</definiendum>
				<definiens id="0">consists Context Tag Word Left Right W L R VBG operating NN 1 1 VBG recurring NNS 1 1 VBG continuing NNS 1 1 Table 3 : Lexicalisation of the tag VBG</definiens>
			</definition>
			<definition id="4">
				<sentence>( 3 ) \ [ the_DT reawakening_VBG\ ] of_IN \ [ the_DT abortion-rights_NNS movement_NN\ ] Generalisation consists of accepting some sequences of elements which do no correspond to a whole structure ( S -- + AL* N AR* \ ] AL+ 1 AR+ ) .</sentence>
				<definiendum id="0">Generalisation</definiendum>
				<definiens id="0">consists of accepting some sequences of elements which do no correspond to a whole structure ( S -- +</definiens>
			</definition>
			<definition id="5">
				<sentence>ALLiS offers the best score for the symbolic systems .</sentence>
				<definiendum id="0">ALLiS</definiendum>
				<definiens id="0">offers the best score for the symbolic systems</definiens>
			</definition>
</paper>

		<paper id="1438">
			<definition id="0">
				<sentence>They used WordNet , a lexical database which contains some semantic information ( http : //www.cs.princeton.edu/wn ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiendum id="1">lexical database</definiendum>
				<definiens id="0">contains some semantic information ( http : //www.cs.princeton.edu/wn )</definiens>
			</definition>
			<definition id="1">
				<sentence>2~2 As mentioned above , WordNet is a lexical database that contains substantial semantic information .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a lexical database that contains substantial semantic information</definiens>
			</definition>
			<definition id="2">
				<sentence>A `` meta-chain '' is a representation of every possible lexical chain that can be computed starting with a word of a given sense .</sentence>
				<definiendum id="0">meta-chain ''</definiendum>
				<definiens id="0">a representation of every possible lexical chain that can be computed starting with a word of a given sense</definiens>
			</definition>
			<definition id="3">
				<sentence>Barzilay and Elhadad use the notion of strong chains ( i.e. , chains whose scores are in excess of two standard deviations above the mean of all scores ) to determine which chains to include in a summary .</sentence>
				<definiendum id="0">strong chains</definiendum>
				<definiens id="0">chains whose scores are in excess of two standard deviations above the mean of all scores</definiens>
			</definition>
</paper>

		<paper id="0202">
			<definition id="0">
				<sentence>Verbversus Satellite-framed languages Verb-Framed Languages ( VFL ) map the motion ( path or path + ground location ) onto the verb , and the manner either onto a satellite or an adjunct , while Satellite-Framed Languages ( SFL ) map the motion into the satellite , and the manner onto the main verb .</sentence>
				<definiendum id="0">Verbversus Satellite-framed languages Verb-Framed Languages</definiendum>
				<definiens id="0">VFL ) map the motion ( path or path + ground location ) onto the verb , and the manner either onto a satellite or an adjunct , while Satellite-Framed Languages ( SFL ) map the motion into the satellite , and the manner onto the main verb</definiens>
			</definition>
			<definition id="1">
				<sentence>English and other Germanic languages are considered satellite-framed languages , expressing the path in the satellite ; Spanish , among other Romance languages , is a verb-framed language and expresses the path in the main verb .</sentence>
				<definiendum id="0">satellite-framed languages</definiendum>
				<definiendum id="1">Spanish</definiendum>
				<definiens id="0">expressing the path in the satellite</definiens>
				<definiens id="1">a verb-framed language and expresses the path in the main verb</definiens>
			</definition>
			<definition id="2">
				<sentence>Motion is a type of framing event where the path is in the main verb for VFLs and in the satellite for SFLs .</sentence>
				<definiendum id="0">Motion</definiendum>
				<definiens id="0">a type of framing event where the path is in the main verb for VFLs and in the satellite for SFLs</definiens>
			</definition>
			<definition id="3">
				<sentence>5 Independent of which is the source language , the PAR schema selected is motion , the activity field , which determines how the action is performed ( in this case , by floating ) , is filled by float ( the main verb in English , or the adjunct in Spanish ) .</sentence>
				<definiendum id="0">activity field</definiendum>
				<definiendum id="1">float</definiendum>
				<definiens id="0">determines how the action is performed</definiens>
				<definiens id="1">the main verb in English , or the adjunct in Spanish</definiens>
			</definition>
			<definition id="4">
				<sentence>The termination condition , which says that action ends when the agent is in the object , is added from the preposition in English and is part of the semantics of the main verb to enter in Spanish .</sentence>
				<definiendum id="0">termination condition</definiendum>
				<definiens id="0">says that action ends when the agent is in the object , is added from the preposition in English and is part of the semantics of the main verb to enter in Spanish</definiens>
			</definition>
			<definition id="5">
				<sentence>( 4 ) Mary spoons chocolate over the ice cream Mary coloca chocolate sobre o sorvete coma colher ( Mary puts chocolate over the ice cream with a spoon ) PUT3 PAR activity : participants : agent : Mary objects : chocolate , icecresm , spoon preparatory_spec : get ( Mary , spoon ) termination_cond : over ( chocolate , icecream ) Figure 7 : Representation of the sentences in ( 4 ) Notice that the only connection between to spoon and its Portuguese translation would be the termination condition where the object of the verb , chocolate , has a new location which is over the ice cream .</sentence>
				<definiendum id="0">Mary</definiendum>
				<definiens id="0">puts chocolate over the ice cream with a spoon ) PUT3 PAR activity : participants : agent : Mary objects : chocolate , icecresm</definiens>
			</definition>
</paper>

		<paper id="1202">
			<definition id="0">
				<sentence>The widely available corpus is Academic Sinica Balanced Corpus abbreviated as ASBC hereafter ( I-Iuang and Chen , 1995 ) , which is a POS-tagged corpus .</sentence>
				<definiendum id="0">Academic Sinica Balanced Corpus</definiendum>
				<definiendum id="1">ASBC</definiendum>
				<definiens id="0">a POS-tagged corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>The degree of polysemy is defined as the average number of senses of words .</sentence>
				<definiendum id="0">degree of polysemy</definiendum>
				<definiens id="0">the average number of senses of words</definiens>
			</definition>
			<definition id="2">
				<sentence>Small categories ( more fine granularity ) are used to compute the distribution of word senses .</sentence>
				<definiendum id="0">Small categories</definiendum>
				<definiens id="0">more fine granularity ) are used to compute the distribution of word senses</definiens>
			</definition>
			<definition id="3">
				<sentence>Besides Cilin , ASBC is employed to count frequency of a word .</sentence>
				<definiendum id="0">ASBC</definiendum>
				<definiens id="0">employed to count frequency of a word</definiens>
			</definition>
			<definition id="4">
				<sentence>Of these , 5,922 words are polysemous , i.e. , they have more than one sense .</sentence>
				<definiendum id="0">polysemous</definiendum>
				<definiens id="0">they have more than one sense</definiens>
			</definition>
			<definition id="5">
				<sentence>A word token is an occurrence of a type in the corpus .</sentence>
				<definiendum id="0">word token</definiendum>
				<definiens id="0">an occurrence of a type in the corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>Low frequency denotes the number of occurrences less than 100 , middle frequency denotes the number of occurrences between 100 and 1000 , and high frequency denotes the number of occurrences more than 1000 .</sentence>
				<definiendum id="0">Low frequency</definiendum>
				<definiendum id="1">middle frequency</definiendum>
				<definiendum id="2">high frequency</definiendum>
				<definiens id="0">the number of occurrences less than 100</definiens>
				<definiens id="1">the number of occurrences between 100 and 1000</definiens>
				<definiens id="2">the number of occurrences more than 1000</definiens>
			</definition>
			<definition id="7">
				<sentence>, FW ( J'l'~ ~ ) , C ( i~l~j~q ) , T ( ~l~h~q ) , and I ( ~*~q ) are regarded as stop words .</sentence>
				<definiendum id="0">FW</definiendum>
				<definiens id="0">~*~q ) are regarded as stop words</definiens>
			</definition>
			<definition id="8">
				<sentence>A sense tag Ctag is in terms of a vector ( wl , w2 , ... , wn ) , where n is the vocabulary size and wi is a weight of word cw .</sentence>
				<definiendum id="0">sense tag Ctag</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">wi</definiendum>
				<definiens id="0">in terms of a vector ( wl , w2 , ... , wn )</definiens>
				<definiens id="1">the vocabulary size</definiens>
				<definiens id="2">a weight of word cw</definiens>
			</definition>
			<definition id="9">
				<sentence>( 1 ) MI metric ( Church , etal. , 1989 ) 34l ( Ctag , ew ) = P ( Ctag , cw ) log 2 P ( Ctag ) P ( cw ) = f ( Ctag , ew ) • l°g2 f ( Ctag ) f ( ew ) x zv where P ( Ctag ) is the probability of Crag , P ( cw ) is the probability of cw , P ( Ctag , cw ) is the cooccurrence probability of Crag and cw , J ( Ctag ) is the frequency of Ctag , .</sentence>
				<definiendum id="0">MI metric</definiendum>
				<definiendum id="1">P ( Ctag )</definiendum>
				<definiendum id="2">P ( cw )</definiendum>
				<definiendum id="3">P ( Ctag</definiendum>
				<definiens id="0">the probability of Crag</definiens>
				<definiens id="1">the cooccurrence probability of Crag and cw</definiens>
			</definition>
			<definition id="10">
				<sentence>£ew ) is the frequency of cw , ~Ctag , cw ) is the cooccurrence frequency of Ctag and cw , and N is total number of words in the corpus .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the cooccurrence frequency of Ctag and cw</definiens>
				<definiens id="1">total number of words in the corpus</definiens>
			</definition>
			<definition id="11">
				<sentence>( 1 ) IfSj is the only one syuset that has been mapped to Cilin tags , we choose a Cilin tag and map Si to it .</sentence>
				<definiendum id="0">IfSj</definiendum>
				<definiens id="0">the only one syuset that has been mapped to Cilin tags</definiens>
			</definition>
			<definition id="12">
				<sentence>M1 is the best because more restrictive mapping table reduces the possibility of mapping errors .</sentence>
				<definiendum id="0">M1</definiendum>
				<definiens id="0">the best because more restrictive mapping table reduces the possibility of mapping errors</definiens>
			</definition>
</paper>

		<paper id="0603">
			<definition id="0">
				<sentence>Quarc uses heuristic rules that look for lexical and semantic clues in the question and the story .</sentence>
				<definiendum id="0">Quarc</definiendum>
				<definiens id="0">uses heuristic rules that look for lexical and semantic clues in the question and the story</definiens>
			</definition>
			<definition id="1">
				<sentence>Given a story and a question , Quarc finds the sentence in the story that best answers the question .</sentence>
				<definiendum id="0">Quarc</definiendum>
				<definiens id="0">finds the sentence in the story that best answers the question</definiens>
			</definition>
			<definition id="2">
				<sentence>Quarc uses hand-crafted heuristic rules that look for lexical and semantic clues in the question and the story .</sentence>
				<definiendum id="0">Quarc</definiendum>
				<definiens id="0">uses hand-crafted heuristic rules that look for lexical and semantic clues in the question and the story</definiens>
			</definition>
			<definition id="3">
				<sentence>Answering Quarc ( QUestion Answering for Reading Comprehension ) is a rule-based system that uses lexical and semantic heuristics to look for evidence that a sentence contains the answer to a question .</sentence>
				<definiendum id="0">Answering Quarc ( QUestion Answering for Reading Comprehension )</definiendum>
				<definiens id="0">a rule-based system that uses lexical and semantic heuristics to look for evidence that a sentence contains the answer to a question</definiens>
			</definition>
			<definition id="4">
				<sentence>A mummy is a body wrapped in sheets .</sentence>
				<definiendum id="0">mummy</definiendum>
				<definiens id="0">a body wrapped in sheets</definiens>
			</definition>
			<definition id="5">
				<sentence>A PROPER__NOUN is defined as a noun phrase in which all words are capitalized .</sentence>
				<definiendum id="0">PROPER__NOUN</definiendum>
				<definiens id="0">a noun phrase in which all words are capitalized</definiens>
			</definition>
			<definition id="6">
				<sentence>A NAME is defined as a PROPER_NOUN that contains at least one HUMAN word .</sentence>
				<definiendum id="0">NAME</definiendum>
				<definiens id="0">a PROPER_NOUN that contains at least one HUMAN word</definiens>
			</definition>
			<definition id="7">
				<sentence>Quarc recognizes 21 prepositions as being associated with locations , such as `` in '' , `` at '' , `` near '' , and `` inside '' .</sentence>
				<definiendum id="0">Quarc</definiendum>
				<definiens id="0">recognizes 21 prepositions as being associated with locations</definiens>
			</definition>
			<definition id="8">
				<sentence>In the event of a tie , a WHY question chooses the sentence that appears latest in the story , and all other question types choose the sentence that appears earliest in the story .</sentence>
				<definiendum id="0">WHY question</definiendum>
				<definiens id="0">chooses the sentence that appears latest in the story</definiens>
				<definiens id="1">the sentence that appears earliest in the story</definiens>
			</definition>
			<definition id="9">
				<sentence>/ / I I t Word + Verb + Sem + Why/Dateline + Qtype Rules Figure 8 : Experimental Results more than one sentence is tied with the best score , Quarc selects the sentence that appears earliest in the story , except for WHY questions when Quarc chooses the sentence appearing latest in the story .</sentence>
				<definiendum id="0">Quarc</definiendum>
				<definiens id="0">selects the sentence that appears earliest in the story , except for WHY questions when Quarc chooses the sentence appearing latest in the story</definiens>
			</definition>
			<definition id="10">
				<sentence>Reading comprehension tests are a wonderful testbed for research in natural language processing because they require broad-coverage techniques and semantic knowledge .</sentence>
				<definiendum id="0">Reading comprehension tests</definiendum>
				<definiens id="0">a wonderful testbed for research in natural language processing because they require broad-coverage techniques and semantic knowledge</definiens>
			</definition>
</paper>

		<paper id="0106">
			<definition id="0">
				<sentence>Network : A network consists of a collection of nodes interconnected by an accompanying set of arcs .</sentence>
				<definiendum id="0">Network</definiendum>
				<definiens id="0">A network consists of a collection of nodes interconnected by an accompanying set of arcs</definiens>
			</definition>
			<definition id="1">
				<sentence>( Hendrix , 1979 ) A Partial Network : A partial network is a collection of nodes interconnected by an accompanying set of arcs where the collection of nodes is a subset of a collection of nodes forming a network , and the accompanying set of arcs is a subset of the se .</sentence>
				<definiendum id="0">Partial Network</definiendum>
				<definiens id="0">a collection of nodes interconnected by an accompanying set of arcs where the collection of nodes is a subset of a collection of nodes forming a network</definiens>
				<definiens id="1">a subset of the se</definiens>
			</definition>
			<definition id="2">
				<sentence>The level of a fact , F , in a piece of text is defined by the following algorithm : F. Suppose { xl , x~ , ... , Xn } are the nodes relevant to F. Let s be the partial network consisting of the set of nodes { xl , x~ , ... , x~ } interconnected by the set of arcs { tl , t2 , ... , tk } .</sentence>
				<definiendum id="0">level of a fact</definiendum>
				<definiens id="0">the following algorithm : F. Suppose { xl , x~ , ... , Xn } are the nodes relevant to F. Let s be the partial network consisting of the set of nodes { xl , x~ , ... , x~ } interconnected by the set of arcs { tl , t2 , ... , tk }</definiens>
			</definition>
			<definition id="3">
				<sentence>The semantic vicinity of a node in a network consists of the nodes and the arcs reachable from that node by traversing a small number of arcs .</sentence>
				<definiendum id="0">semantic vicinity of a node</definiendum>
				<definiens id="0">the nodes and the arcs reachable from that node by traversing a small number of arcs</definiens>
			</definition>
			<definition id="4">
				<sentence>• A level-0 fact consists of a single node ( i.e. no transitions ) in a network .</sentence>
				<definiendum id="0">level-0 fact</definiendum>
				<definiens id="0">consists of a single node ( i.e. no transitions ) in a network</definiens>
			</definition>
			<definition id="5">
				<sentence>• A level-k fact is a union of k level-1 facts : • Conjunctions/disjunctions increase the level of a fact .</sentence>
				<definiendum id="0">level-k fact</definiendum>
				<definiens id="0">a union of k level-1 facts : • Conjunctions/disjunctions increase the level of a fact</definiens>
			</definition>
			<definition id="6">
				<sentence>The attack designator ( the murder ) with its modifier ( two employees ) accounts for one level , while the connector between `` two employees '' and `` Bogota 's Daily E1 Espectador '' accounts for the other .</sentence>
				<definiendum id="0">attack designator</definiendum>
				<definiens id="0">the murder ) with its modifier ( two employees ) accounts for one level</definiens>
			</definition>
			<definition id="7">
				<sentence>However , instead of producing a single answer for each question , Qanda produces a list of answers listed in decreasing order of confidence .</sentence>
				<definiendum id="0">Qanda</definiendum>
				<definiens id="0">produces a list of answers listed in decreasing order of confidence</definiens>
			</definition>
			<definition id="8">
				<sentence>Therefore , MRAR for a reading comprehension test is the sum of the scores for answers corresponding to each question for that test .</sentence>
				<definiendum id="0">MRAR for a reading comprehension test</definiendum>
				<definiens id="0">the sum of the scores for answers corresponding to each question for that test</definiens>
			</definition>
			<definition id="9">
				<sentence>frequency of answers : The frequency of occurrence of facts in a collection of documents has an impact on the performance of systems .</sentence>
				<definiendum id="0">frequency of answers</definiendum>
				<definiens id="0">The frequency of occurrence of facts in a collection of documents has an impact on the performance of systems</definiens>
			</definition>
</paper>

		<paper id="0410">
			<definition id="0">
				<sentence>Each leaf node has an associated goal , which , when realized , provides content for that node .</sentence>
				<definiendum id="0">associated goal</definiendum>
				<definiens id="0">provides content for that node</definiens>
			</definition>
			<definition id="1">
				<sentence>The briefing generator takes the script as input .</sentence>
				<definiendum id="0">briefing generator</definiendum>
				<definiens id="0">takes the script as input</definiens>
			</definition>
			<definition id="2">
				<sentence>The Script Validator applies an XML parser to the script , to check for syntactic correctness .</sentence>
				<definiendum id="0">Script Validator</definiendum>
				<definiens id="0">applies an XML parser to the script , to check for syntactic correctness</definiens>
			</definition>
			<definition id="3">
				<sentence>Next , a Content Creator takes the input tree and expands it by introducing narrative-level goals including segues to content nodes , and rtmning text and captions describing media objects at content nodes .</sentence>
				<definiendum id="0">Content Creator</definiendum>
				<definiens id="0">takes the input tree and expands it by introducing narrative-level goals including segues to content nodes</definiens>
			</definition>
			<definition id="4">
				<sentence>Then , a Content Executor executes all the create and retrieve goals .</sentence>
				<definiendum id="0">Content Executor</definiendum>
			</definition>
			<definition id="5">
				<sentence>Finally , the Presentation Generator takes the tree which is output from Content Execution , along with its temporal ordering constraints , and generates the spatial layout of the presentation .</sentence>
				<definiendum id="0">Presentation Generator</definiendum>
				<definiens id="0">takes the tree which is output from Content Execution , along with its temporal ordering constraints , and generates the spatial layout of the presentation</definiens>
			</definition>
			<definition id="6">
				<sentence>Among the core technology standards that support this plug-and-play component assembly capability are ( a ) Java interfaces , used to specify functions that all summarization components must implement in order to be used in the system , ( b ) the JavaBeans standard , which allows the parameters and methods of individual components to be inspected by the system and revealed to the users ( c ) the XML markup standard , which we have adopted as an intercomponent communication language .</sentence>
				<definiendum id="0">JavaBeans standard</definiendum>
				<definiens id="0">allows the parameters and methods of individual components to be inspected by the system and revealed to the users ( c ) the XML markup standard</definiens>
				<definiens id="1">an intercomponent communication language</definiens>
			</definition>
			<definition id="7">
				<sentence>The Content Creator , when providing content for narrative nodes , uses a variety of different canned text patterns .</sentence>
				<definiendum id="0">Content Creator</definiendum>
				<definiens id="0">uses a variety of different canned text patterns</definiens>
			</definition>
			<definition id="8">
				<sentence>Victor Polay , also known as Comandante Rolando , is the Tupac Amaru founder , a Peruvian guerrilla commander , a former rebel leader , and the Tupac Amaru rebels ' top leader .</sentence>
				<definiendum id="0">Comandante Rolando</definiendum>
				<definiens id="0">the Tupac Amaru founder , a Peruvian guerrilla commander , a former rebel leader , and the Tupac Amaru rebels ' top leader</definiens>
			</definition>
</paper>

		<paper id="0706">
			<definition id="0">
				<sentence>Word Sense Disambiguation ( WSD ) is the problem of assigning the appropriate meaning ( or sense ) to a given word in a text or discourse .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
				<definiendum id="1">WSD</definiendum>
				<definiens id="0">the problem of assigning the appropriate meaning ( or sense ) to a given word in a text or discourse</definiens>
			</definition>
			<definition id="1">
				<sentence>Besides , WSD is one of the most important open problems in NLP .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">one of the most important open problems in NLP</definiens>
			</definition>
			<definition id="2">
				<sentence>Naive Bayes is intended as a simple representative of statistical learning methods .</sentence>
				<definiendum id="0">Naive Bayes</definiendum>
				<definiens id="0">a simple representative of statistical learning methods</definiens>
			</definition>
			<definition id="3">
				<sentence>In the SNo W architecture there is a winnow node for each class , which learns to separate that class from all the rest .</sentence>
				<definiendum id="0">winnow node</definiendum>
				<definiens id="0">learns to separate that class from all the rest</definiens>
			</definition>
			<definition id="4">
				<sentence>In this setting , a Decision List is a list of features extracted from the training examples and sorted by a log-likelihood measure .</sentence>
				<definiendum id="0">Decision List</definiendum>
				<definiens id="0">a list of features extracted from the training examples and sorted by a log-likelihood measure</definiens>
			</definition>
			<definition id="5">
				<sentence>Decision Lists were one of the most successful systems on the 1st Senseval competition for WSD ( Kilgarriff and Rosenzweig , 2000 ) .</sentence>
				<definiendum id="0">Decision Lists</definiendum>
				<definiens id="0">one of the most successful systems on the 1st Senseval competition for WSD</definiens>
			</definition>
			<definition id="6">
				<sentence>LazyBoosting ( Escudero et al. , 2000a ) is a simple modification of the AdaBoost .</sentence>
				<definiendum id="0">LazyBoosting</definiendum>
				<definiens id="0">a simple modification of the AdaBoost</definiens>
			</definition>
			<definition id="7">
				<sentence>MH algorithm , which consists in reducing the feature space that is explored when learning each weak classifier .</sentence>
				<definiendum id="0">MH algorithm</definiendum>
				<definiens id="0">consists in reducing the feature space that is explored when learning each weak classifier</definiens>
			</definition>
			<definition id="8">
				<sentence>A number of comparative experiments has been carried out on a subset of 21 highly ambiguous words of the DSO corpus , which is a semantically annotated English corpus collected by Ng and colleagues ( Ng and Lee , 1996 ) .</sentence>
				<definiendum id="0">DSO corpus</definiendum>
				<definiens id="0">a semantically annotated English corpus collected by Ng and colleagues</definiens>
			</definition>
			<definition id="9">
				<sentence>The DSO corpus contains sentences from two different corpora , namely Wall Street Journal ( WSJ ) and Brown Corpus ( BC ) .</sentence>
				<definiendum id="0">DSO corpus</definiendum>
			</definition>
			<definition id="10">
				<sentence>The topical context is formed by cl , ... , Cm , which stand for the unordered set of open class words appearing in the sentence 2 .</sentence>
				<definiendum id="0">... , Cm</definiendum>
			</definition>
			<definition id="11">
				<sentence>Among them , three groups can be observed : Ni3 , DL , and SN perform similarly ; LB outperforms all the other algorithms in all experiments ; and EB is somewhere in between .</sentence>
				<definiendum id="0">LB</definiendum>
				<definiendum id="1">EB</definiendum>
				<definiens id="0">outperforms all the other algorithms in all experiments</definiens>
			</definition>
			<definition id="12">
				<sentence>~The Kappa statistic ( Cohen , 1960 ) is a better measure of inter-annotator agreement which reduces the effect of chance agreement .</sentence>
				<definiendum id="0">Kappa statistic</definiendum>
				<definiens id="0">a better measure of inter-annotator agreement which reduces the effect of chance agreement</definiens>
			</definition>
			<definition id="13">
				<sentence>i5 58.96±1.86 A-B B-A 36.40 38.71 41.38 47.66 43.01 48.83 44.07 49.76 45.32 51.13 47.10 51.99 '' Table 1 : Accuracy results ( =h standard deviation ) of the methods on all training-test combinations A+B-A+B DSO MFC NB EB SN DL LB DSO -46.6 61.6 63.0 60.9 61.6 66.3 MFC -0.19 -73.9 60.0 55.9 64.9 54.9 NB 0.24 -0.09 -76.3 74.5 76.8 71.4 EB 0.36 -0.15 0.44 -69.6 70.7 72.5 SN 0.36 -0.17 0.44 0.44 -67.5 69.0 DL 0.32 -0.13 0.40 0.41 0.38 -69.9 LB 0.44 -0.17 0.37 0.50 0.46 0.42 -Table 2 : Kappa statistic ( below diagonal ) and % of agreement ( above diagonal ) between all methods in the A+B-A+B experiment that LB is the algorithm that better learns the behaviour of the DSO examples .</sentence>
				<definiendum id="0">DSO MFC NB EB SN DL LB</definiendum>
				<definiendum id="1">Kappa statistic</definiendum>
				<definiendum id="2">LB</definiendum>
			</definition>
			<definition id="14">
				<sentence>Exemplar-Base Word Sense Disambiguation : Some Recent Improvements .</sentence>
				<definiendum id="0">Exemplar-Base Word Sense Disambiguation</definiendum>
				<definiens id="0">Some Recent Improvements</definiens>
			</definition>
			<definition id="15">
				<sentence>Decision Lists for Lexical Ambiguity Resolution : Application to Accent Restoration in Spanish and French .</sentence>
				<definiendum id="0">Decision Lists</definiendum>
			</definition>
</paper>

		<paper id="1406">
			<definition id="0">
				<sentence>In this paper , we describe a mechanism which generates rebuttals to such rejoinders in the context of arguments generated from Bayesian networks ( BNs ) ( Pearl , 1988 ) .</sentence>
				<definiendum id="0">mechanism</definiendum>
			</definition>
			<definition id="1">
				<sentence>The interpretation process , where BIAS identifies the reasoning path intended by the user , takes place in the user model ; since , BIAS tries , to .</sentence>
				<definiendum id="0">BIAS</definiendum>
				<definiens id="0">identifies the reasoning path intended by the user , takes place in the user model</definiens>
			</definition>
			<definition id="2">
				<sentence>This path , called userPath , represents the line of reasoning intended by the user .</sentence>
				<definiendum id="0">userPath ,</definiendum>
				<definiens id="0">represents the line of reasoning intended by the user</definiens>
			</definition>
			<definition id="3">
				<sentence>The gap in this path contains nodes I and M ( in italics ) , which means that the user inferred E directly from R. Each path is assigned a score based on the following factors : the impact of R on BIAS ' argument along this path , whether path nodes are in the user 's attentional focus , and BIAS ' confidence in this path ( determined from the information source of the nodes in this path , e.g. , whether the user has seen the propositions in the path , asserted a belief about them or read them in BIAS ' arguments ) .</sentence>
				<definiendum id="0">BIAS</definiendum>
				<definiens id="0">means that the user inferred E directly from R. Each path is assigned a score based on the following factors : the impact of R on BIAS ' argument along this path , whether path nodes are in the user 's attentional focus</definiens>
			</definition>
			<definition id="4">
				<sentence>in'-R stated '' by the '' user , and set lastProposition to R. ( a ) If after lastProposition there is a proposition Pi EuserPath for which a sub-argument was generated ( SubAG ( Pi ) ¢ 0 ) , then i. Follow userPath from lastProposition-to-Pi .</sentence>
				<definiendum id="0">in'-R</definiendum>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>Natural language generation involves a number of processes ranging from planning the content to be expressed through making encoding decisions involving syntax , the lexicon and morphology .</sentence>
				<definiendum id="0">Natural language generation</definiendum>
				<definiens id="0">involves a number of processes ranging from planning the content to be expressed through making encoding decisions involving syntax , the lexicon and morphology</definiens>
			</definition>
			<definition id="1">
				<sentence>• \ [ RelC1\ ] The mention is a child of a relative clause .</sentence>
				<definiendum id="0">mention</definiendum>
				<definiens id="0">a child of a relative clause</definiens>
			</definition>
			<definition id="2">
				<sentence>Assuming that N ( S ) probabilities are needed to parameterize a tree with structure S , we use : p ( S ) = c. k Vector Machines ( Platt 2000 , Vapnik 1998 ) using a where 0 &lt; k _ &lt; 1 , and c is a constant such that p ( S ) sums to one .</sentence>
				<definiendum id="0">N ( S</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">p ( S ) = c. k Vector Machines ( Platt 2000</definiens>
			</definition>
			<definition id="3">
				<sentence>Prepositional phrase complements of NPs , however , are prototypically used to express attributes of the NP , e.g. `` the man with the red hat '' .</sentence>
				<definiendum id="0">Prepositional phrase</definiendum>
				<definiens id="0">complements of NPs</definiens>
			</definition>
</paper>

		<paper id="0722">
			<definition id="0">
				<sentence>Although some large-scale information retrieval ( IR ) evaluations , made on unrestricted corpora ( Hersh and al. , 1998 ) , and on medical texts ( Hersh , 1998 ) , are quite critical towards linguistic engineering , we believe that natural language processing is the best solution to face two major problems of text retrieval engines : expansion of the query and lexical disambiguation .</sentence>
				<definiendum id="0">IR</definiendum>
			</definition>
			<definition id="1">
				<sentence>5The MS tagset tends to follow the MULTEXT lexical description for French , modified within the GRACE action ( http : //www.limsi.fr/TLP/grace/doc/GTR-3description does not allow any morpheme annotation .</sentence>
				<definiendum id="0">MS tagset</definiendum>
				<definiens id="0">tends to follow the MULTEXT lexical description for French , modified within the GRACE action</definiens>
			</definition>
</paper>

		<paper id="0104">
			<definition id="0">
				<sentence>This paper describes an automatic method for extracting systematic polysemy from a hierarchically organized semantic lexicon ( WordNet ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a hierarchically organized semantic lexicon</definiens>
			</definition>
			<definition id="1">
				<sentence>Systematic polysemy is a set of word senses that are related in systematic and predictable ways .</sentence>
				<definiendum id="0">Systematic polysemy</definiendum>
				<definiens id="0">a set of word senses that are related in systematic and predictable ways</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , a CORELEX class AQU ( which represents a relation between ARTIFACT and QUANTITY ) contains words such as `` bottle '' , `` bucket '' and `` spoon '' .</sentence>
				<definiendum id="0">CORELEX class AQU</definiendum>
				<definiens id="0">represents a relation between ARTIFACT and QUANTITY</definiens>
			</definition>
			<definition id="3">
				<sentence>In this paper , we propose a method which automatically extracts systematic polysemy from a hierarchically organized semantic lexicon ( WordNet ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a method which automatically extracts systematic polysemy from a hierarchically organized semantic lexicon</definiens>
			</definition>
			<definition id="4">
				<sentence>A thesaurus tree is a hierarchically organized lexicon where leaf nodes encode lexical data 21 ( i.e. , words ) and internal nodes represent abstract semantic classes .</sentence>
				<definiendum id="0">thesaurus tree</definiendum>
				<definiens id="0">a hierarchically organized lexicon where leaf nodes encode lexical data 21 ( i.e. , words ) and internal nodes represent abstract semantic classes</definiens>
			</definition>
			<definition id="5">
				<sentence>A tree-cut is a partition of a thesaurus tree .</sentence>
				<definiendum id="0">tree-cut</definiendum>
				<definiens id="0">a partition of a thesaurus tree</definiens>
			</definition>
			<definition id="6">
				<sentence>It is a list of internal/leaf nodes in the tree , and each node represents a set of all leaf nodes in a subtree rooted by the node .</sentence>
				<definiendum id="0">node</definiendum>
				<definiens id="0">a set of all leaf nodes in a subtree rooted by the node</definiens>
			</definition>
			<definition id="7">
				<sentence>The MDL is a principle of data compression in Information Theory which states that , for a given dataset , the best model is the one which requires the minimum length ( often measured in bits ) to encode the model ( the model description length ) and the data ( the data description length ) .</sentence>
				<definiendum id="0">MDL</definiendum>
				<definiens id="0">a principle of data compression in Information Theory which states that , for a given dataset , the best model is the one which requires the minimum length ( often measured in bits ) to encode the model ( the model description length ) and the data ( the data description length )</definiens>
			</definition>
			<definition id="8">
				<sentence>Given a thesaurus tree T and a sample S consisting of the case frame instances , the total description length L ( M , S ) for a tree-cut model M = ( F , 0 ) is where Ci ( 1 &lt; i &lt; k ) is a cluster in the treecut , P ( Ci ) is the probability of a cluster Ci , and ~/k=l P ( Ci ) = 1 .</sentence>
				<definiendum id="0">P ( Ci )</definiendum>
				<definiens id="0">a cluster in the treecut</definiens>
				<definiens id="1">the probability of a cluster Ci</definiens>
			</definition>
			<definition id="9">
				<sentence>Note that P ( C ) is the probability of cluster C = { nl , .</sentence>
				<definiendum id="0">P ( C )</definiendum>
				<definiens id="0">the probability of cluster</definiens>
			</definition>
			<definition id="10">
				<sentence>L ( M , S ) =L ( F ) +L ( eT ) +L ( SJF , e ) ( 3 ) where L ( F ) is the model description length , L ( OIF ) is the parameter description length ( explained shortly ) , and L ( SIF , O ) is the data description length .</sentence>
				<definiendum id="0">L ( F )</definiendum>
				<definiendum id="1">OIF )</definiendum>
				<definiens id="0">the model description length</definiens>
				<definiens id="1">the parameter description length ( explained shortly</definiens>
				<definiens id="2">the data description length</definiens>
			</definition>
			<definition id="11">
				<sentence>5 The model description length L ( F ) is L ( r ) = log21GI ( 4 ) where G is the set of all cuts in T , and IG I denotes the size of G. This value is a constant for • SFor justification and detailed explanation of these formulas , see ( Li and Abe , 1998 ) .</sentence>
				<definiendum id="0">G</definiendum>
				<definiendum id="1">IG I</definiendum>
				<definiens id="0">the set of all cuts in T , and</definiens>
			</definition>
			<definition id="12">
				<sentence>It is the length required to encode the probability distribution of the clusters in the tree-cut F. It is calculated as k L ( Olr ) = x Zog21Sl ( 5 ) where k is the length of ® , and IS\ [ is the size of S. Finally , the data description length L ( SIF , O ) is the length required to encode the whole sample data .</sentence>
				<definiendum id="0">k</definiendum>
				<definiendum id="1">O )</definiendum>
				<definiens id="0">the length required to encode the probability distribution of the clusters in the tree-cut F. It is calculated as k L ( Olr ) = x Zog21Sl</definiens>
				<definiens id="1">the size of S. Finally , the data description length L</definiens>
			</definition>
			<definition id="13">
				<sentence>In the calculation of the data description length in equation ( 6 ) , each word in a cluster , observed or unobserved , is assigned an estimated probability , which is a uniform fraction of the probability of the cluster .</sentence>
				<definiendum id="0">estimated probability</definiendum>
				<definiens id="0">a uniform fraction of the probability of the cluster</definiens>
			</definition>
			<definition id="14">
				<sentence>This corresponds to the length required to encode all words in a cluster , for all clusters in a tree-cut , assuming Huffman 's algorithm ( Huffman , 1952 ) assigned a codeword of length -log2P ( Ci ) to each cluster C/ ( whose propor6We could also combine two ( or possibly more ) trees into one tree and apply clustering over that tree once .</sentence>
				<definiendum id="0">Ci</definiendum>
				<definiens id="0">) to each cluster C/ ( whose propor6We could also combine two ( or possibly more ) trees into one tree and apply clustering over that tree once</definiens>
			</definition>
			<definition id="15">
				<sentence>Such SActually , cousin is one of the three relations which indicate the grouping of related senses of a word .</sentence>
				<definiendum id="0">cousin</definiendum>
				<definiens id="0">one of the three relations which indicate the grouping of related senses of a word</definiens>
			</definition>
</paper>

		<paper id="0709">
			<definition id="0">
				<sentence>49 selection The task of parse selection involves selecting the best possible parse for a sentence from a set of possible parses produced by an AVG .</sentence>
				<definiendum id="0">parse selection</definiendum>
				<definiens id="0">selecting the best possible parse for a sentence from a set of possible parses produced by an AVG</definiens>
			</definition>
			<definition id="1">
				<sentence>In the present approach , parses are ranked according to their goodness by a statistical model built using the maximum entropy technique , which involves building a distribution over events which is the most uniform possible , given constraints derived from training data .</sentence>
				<definiendum id="0">maximum entropy technique</definiendum>
				<definiens id="0">involves building a distribution over events which is the most uniform possible , given constraints derived from training data</definiens>
			</definition>
</paper>

		<paper id="1416">
			<definition id="0">
				<sentence>We 'll use assignment variables like g to range over cases ; gx is the value of g for variable x.t Interpretations are defined in terms of sets of cases , naturally ; we 'll use F to range over a set of cases and write F ( x ) for { gx : g E F } .</sentence>
				<definiendum id="0">gx</definiendum>
				<definiens id="0">use assignment variables like g to range over cases ;</definiens>
			</definition>
			<definition id="1">
				<sentence>Let us say a set X is clustered around R if R is a singleton spatial location { r } and X is a group of sufficient cardinality and density located together at r. Then we might find three tuples of \ [ \ [ clustered ( x , r ) \ ] \ ] in the explicit depiction of ( 8 ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a singleton spatial location { r } and</definiens>
				<definiens id="1">a group of sufficient cardinality</definiens>
			</definition>
			<definition id="2">
				<sentence>Given such a relation C , the constraint @ cP -- read `` covered by C , p '' -- says that p is true on each of the cells of the cover specified by C. We will only consider the case where p is an atomic constraint F ( x ) .</sentence>
				<definiendum id="0">p</definiendum>
			</definition>
			<definition id="3">
				<sentence>In particular , consider a description L that consists of a list of constraints @ Li ( x ) formulated in terms of a tuple of variables x and atomic conditions on those variables Li ( x ) .</sentence>
				<definiendum id="0">constraints</definiendum>
				<definiendum id="1">Li ( x )</definiendum>
				<definiens id="0">formulated in terms of a tuple of variables x and atomic conditions on those variables Li ( x )</definiens>
			</definition>
			<definition id="4">
				<sentence>( ll ) a { ( x.r ) : x a square in the center top r } b { ( x , r ) : x a square in the lower right r } I I adopt the notation throughout that v is a tuple and v i is component i of v , where components may be indexed equiva ... ... ... ... ... .</sentence>
				<definiendum id="0">x.r )</definiendum>
				<definiendum id="1">v i</definiendum>
				<definiens id="0">x a square in the center top r } b { ( x , r ) : x a square in the lower right r } I I adopt the notation throughout that v is a tuple and</definiens>
			</definition>
</paper>

		<paper id="0707">
			<definition id="0">
				<sentence>This is very important for applications such as TransType ( Foster et al. , 1997 ; Langlais et al. , 2000 ) , where the task is to make real-time predictions of the text a human translator will type next , based on the source text under translation and some prefix of the target text that has already been typed .</sentence>
				<definiendum id="0">TransType</definiendum>
				<definiens id="0">to make real-time predictions of the text a human translator will type next , based on the source text under translation and some prefix of the target text that has already been typed</definiens>
			</definition>
			<definition id="1">
				<sentence>The standard `` noisy channel '' approach used in SMT , where p ( tls ) c &lt; p ( t ) p ( slt ) , is generally too expensive for such applications because it does not permit direct calculation of the probability of a word or sequence of words beginning at the current position .</sentence>
				<definiendum id="0">p (</definiendum>
			</definition>
			<definition id="2">
				<sentence>( 2 ) where p ( w\ [ hi ) is a language model , p ( wli , s ) is a translation model , and A E \ [ 0 , 1\ ] is a combining weight .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">a language model , p ( wli , s ) is a translation model</definiens>
				<definiens id="1">a combining weight</definiens>
			</definition>
			<definition id="3">
				<sentence>In previous work ( Foster , 2000 ) , I described a Maximum Entropy/Minimum Divergence ( MEMD ) model ( Berger et al. , 1996 ) for p ( w\ [ hi , s ) which incorporates a trigram language model and a translation component which is an analog of the well-known IBM translation model 1 ( Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">Maximum Entropy/Minimum Divergence</definiendum>
			</definition>
			<definition id="4">
				<sentence>The model consists of a set of word-pair parameters p ( t\ [ s ) and position parameters p ( j\ [ i , / ) ; in model 1 ( IBM1 ) the latter are fixed at 1/ ( 1 + 1 ) , as each position , including the empty position 0 , is considered equally likely to contain a translation for w. Maximum likelihood estimates for these parameters can be obtained with the EM algorithm over a bilingual training corpus , as described in ( Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">position parameters p (</definiendum>
			</definition>
			<definition id="5">
				<sentence>where q ( w\ [ hi , s ) is a reference distribution , f ( w , hi , s ) maps ( w , hi , s ) into an n-dimensional feature vector , ( ~ is a corresponding vector of feature weights ( the parameters of the model ) , and Z ( hi , s ) = ~w q ( w\ [ hi , s ) exp ( ( ~-f ( w , hi ) ) is a normalizing factor .</sentence>
				<definiendum id="0">q</definiendum>
				<definiendum id="1">~</definiendum>
				<definiendum id="2">Z</definiendum>
				<definiens id="0">a reference distribution , f ( w , hi , s ) maps ( w , hi , s ) into an n-dimensional feature vector</definiens>
				<definiens id="1">the parameters of the model</definiens>
			</definition>
			<definition id="6">
				<sentence>IBM2 incorporates position information by introducing a hidden position variable and making independence hypotheses .</sentence>
				<definiendum id="0">IBM2</definiendum>
				<definiens id="0">incorporates position information by introducing a hidden position variable and making independence hypotheses</definiens>
			</definition>
			<definition id="7">
				<sentence>p ( TIS ) -1~IT\ ] , where p is the model being evalThe model is : uated , and ( S , T ) is the test corpus , considered .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">( S , T )</definiendum>
				<definiens id="0">the test corpus , considered</definiens>
			</definition>
			<definition id="8">
				<sentence>Perplexity is a good indicator of Z ( hi , s ) where A ( i , Ss , l ) gives the partition for the current position , B ( s , t ) gives the partition for the current word pair , and following the usual convention , aA ( i , j~,0 , S ( s , t ) is zero if these are undefined .</sentence>
				<definiendum id="0">Perplexity</definiendum>
				<definiendum id="1">B ( s , t )</definiendum>
				<definiens id="0">a good indicator of Z ( hi , s ) where A ( i , Ss , l ) gives the partition for the current position</definiens>
				<definiens id="1">gives the partition for the current word pair</definiens>
			</definition>
			<definition id="9">
				<sentence>This work represents a novel approach to translation modeling which is most appropriate for applications like TransType which need to make rapid predictions of upcoming text .</sentence>
				<definiendum id="0">TransType</definiendum>
				<definiens id="0">need to make rapid predictions of upcoming text</definiens>
			</definition>
</paper>

		<paper id="0905">
</paper>

		<paper id="0206">
			<definition id="0">
				<sentence>SUPAR is a computational system focused on anaphora resolution .</sentence>
				<definiendum id="0">SUPAR</definiendum>
				<definiens id="0">a computational system focused on anaphora resolution</definiens>
			</definition>
			<definition id="1">
				<sentence>A grammar defined by means of the grammatical formalism SUG ( Slot Unification Grammar ) is used as input of SUPAR .</sentence>
				<definiendum id="0">SUG</definiendum>
				<definiens id="0">Slot Unification Grammar</definiens>
			</definition>
			<definition id="2">
				<sentence>SUPAR allows to carry out either a full or a partial parsing of the text , with the same parser and grammar .</sentence>
				<definiendum id="0">SUPAR</definiendum>
				<definiens id="0">allows to carry out either a full or a partial parsing of the text , with the same parser and grammar</definiens>
			</definition>
			<definition id="3">
				<sentence>As said before , the Interlingua system takes the SS of the sentence after applying the anaphora resolution module as input .</sentence>
				<definiendum id="0">Interlingua system</definiendum>
				<definiens id="0">takes the SS of the sentence after applying the anaphora resolution module as input</definiens>
			</definition>
			<definition id="4">
				<sentence>This system , named lnterlingua Slot Structure ( 1SS ) , generates an interlingua representation from the SS of the sentence .</sentence>
				<definiendum id="0">lnterlingua Slot Structure</definiendum>
				<definiens id="0">generates an interlingua representation from the SS of the sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>SUPAR generates one SS for each sentence from the whole text and it solves intrasentential and intersententiai anaphora .</sentence>
				<definiendum id="0">SUPAR</definiendum>
				<definiens id="0">generates one SS for each sentence from the whole text and it solves intrasentential and intersententiai anaphora</definiens>
			</definition>
			<definition id="6">
				<sentence>The semantic role THEME has the same attributes as the semantic role AGENT , i.e. the difference is that THEME is the object of the clause and AGENT is the subject .</sentence>
				<definiendum id="0">AGENT</definiendum>
				<definiens id="0">the object of the clause and</definiens>
				<definiens id="1">the subject</definiens>
			</definition>
			<definition id="7">
				<sentence>The Generation module takes the interlingua representation of the text as input and generates it into the target language .</sentence>
				<definiendum id="0">Generation module</definiendum>
				<definiens id="0">takes the interlingua representation of the text as input and generates it into the target language</definiens>
			</definition>
			<definition id="8">
				<sentence>The detection process depends on the knowledge about the structure of the language itself , which gives us clues to the use of each type of zero-pronoun .</sentence>
				<definiendum id="0">detection process</definiendum>
				<definiens id="0">depends on the knowledge about the structure of the language itself , which gives us clues to the use of each type of zero-pronoun</definiens>
			</definition>
			<definition id="9">
				<sentence>After the zero-pronoun has been detected , SUPAR inserts the pronoun ( with its information of person , gender and number ) in the position in which it has been omitted .</sentence>
				<definiendum id="0">SUPAR</definiendum>
				<definiens id="0">inserts the pronoun ( with its information of person , gender and number ) in the position in which it has been omitted</definiens>
			</definition>
			<definition id="10">
				<sentence>After that , ISS generates the interlingua representation of the text .</sentence>
				<definiendum id="0">ISS</definiendum>
				<definiens id="0">generates the interlingua representation of the text</definiens>
			</definition>
			<definition id="11">
				<sentence>A fragment of the English version of The Blue Book corpus ( 70,319 words ) containing 165 they are cataphoric ( the antecedent appears after the anaphor ) or exophoric ( the antecedent does not appear , linguistically , in the text ) .</sentence>
				<definiendum id="0">Blue Book</definiendum>
				<definiens id="0">corpus ( 70,319 words ) containing 165 they are cataphoric ( the antecedent appears after the anaphor ) or exophoric ( the antecedent does not appear , linguistically , in the text )</definiens>
			</definition>
</paper>

		<paper id="0734">
</paper>

		<paper id="0705">
			<definition id="0">
				<sentence>The problem goal is to separate language from non-language without dialogue , and learn something about the structure of language in the passing .</sentence>
				<definiendum id="0">problem goal</definiendum>
				<definiens id="0">to separate language from non-language without dialogue , and learn something about the structure of language in the passing</definiens>
			</definition>
			<definition id="1">
				<sentence>This can be computed for given word-pair type ( wl , w2 ) by recording each word-pair token ( wl , w2 , d ) in a corpus , where d is the distance or number of intervening words .</sentence>
				<definiendum id="0">d</definiendum>
				<definiens id="0">the distance or number of intervening words</definiens>
			</definition>
</paper>

		<paper id="0505">
			<definition id="0">
				<sentence>Extraction Pattem Library -which contains the set of extraction patterns learned in the lab , one set per scenario template -to extract specific types of information from the input Korean documents , once parsed .</sentence>
				<definiendum id="0">Extraction Pattem Library -which</definiendum>
				<definiens id="0">contains the set of extraction patterns learned in the lab , one set per scenario template -to extract specific types of information from the input Korean documents , once parsed</definiens>
			</definition>
			<definition id="1">
				<sentence>: : : : : : : : : : : : : : : : : : : : : : : : Extracted Information \ [ ( Korean ) Ordered Extracted Information ( Korean ) Parsed Document \ ] Machine `` lYanslation I ( ~l Component ( MT ) Ordered Extracted Information ( English ) User Input Data Presentation ( English ) Information Extraction Query ( English ) 1 i : rla0 Inf0rntauonl English-Korean 7 Transfer Lexicon J Korean-English Transfer Lexicon ) T Miiiiii ii ¢ Presentation ( English ) End user Document Processing Knowledge base component component D ( C ) OTS component \ [ \ ] Component created in Phase I \ [ \ ] Component created or improved in Phase II Figure 2 Corpus For our Phase I feasibility demonstration , we chose a minimal scenario template for meeting and negotiation events consisting of one or more participant slots plus optional date and location slots .</sentence>
				<definiendum id="0">lYanslation I</definiendum>
				<definiens id="0">scenario template for meeting and negotiation events consisting of one or more participant slots plus optional date</definiens>
			</definition>
			<definition id="2">
				<sentence>In this approach , extraction patterns are acquired 34 i. E : K : &lt; target-np &gt; = &lt; subject &gt; &lt; active voice verb &gt; &lt; participant &gt; MET &lt; target-np &gt; = &lt; subject &gt; &lt; active voice verb &gt; &lt; John-i &gt; MANNASSTA &lt; John-nom &gt; 'MET K : &lt; target-np &gt; = &lt; subject &gt; &lt; verb &gt; &lt; infinitive &gt; &lt; participant &gt; agreed to MEET &lt; target-np &gt; = &lt; subject &gt; &lt; verbl-ki-lo &gt; &lt; verb2 &gt; &lt; John-un &gt; MANNA-ki-lo hapuyhayssta &lt; John-nom &gt; MEET-ki-lo agreed ( -ki : nominalization ending , -io : an adverbial postposition ) Figure 3 via a one-shot general-to-specific learning algorithm designed specifically for the information extraction task .</sentence>
				<definiendum id="0">nominalization ending</definiendum>
				<definiens id="0">an adverbial postposition</definiens>
			</definition>
</paper>

		<paper id="1320">
			<definition id="0">
				<sentence>P~ are all lexicalized nonterminals , i.e. , of the form X ( w , t , fl , where X is a traditional CFG nonterminal and ( w , t , f/ is the word-part-of .</sentence>
				<definiendum id="0">P~</definiendum>
				<definiendum id="1">X</definiendum>
				<definiendum id="2">f/</definiendum>
				<definiens id="0">a traditional CFG nonterminal and ( w , t</definiens>
			</definition>
			<definition id="1">
				<sentence>PL ( Iz Ilz-l , p , h , wh ) , , e.g. , ( 4 ) PL ( NP I ADVP , S , VP , caught ) when generating the NP for NP ( boy-NN ) , and the probability of generating a right modifier r ; is PR ( r~ I ri-l , p , h , Wh ) , e.g. , ( 5 ) PR ( NP I + BEGIN+ , VP , VBD , caught ) when generating the NP for NP ( ball-NN ) .</sentence>
				<definiendum id="0">PL</definiendum>
				<definiens id="0">r~ I ri-l , p , h</definiens>
			</definition>
			<definition id="2">
				<sentence>E.g. , both twelve-foot and ten-foot get the word sense of foot_l ( the unit of measure equal to 12 inches ) .</sentence>
				<definiendum id="0">E.g.</definiendum>
				<definiens id="0">the unit of measure equal to 12 inches )</definiens>
			</definition>
			<definition id="3">
				<sentence>This is not as unreasonable as it may sound ; for example , vice_president is a lemma in WordNet and appears in SemCor , so the merged corpus has instances where the word president has the synset vice president l , but only when preceded by the word vice .</sentence>
				<definiendum id="0">vice_president</definiendum>
				<definiens id="0">a lemma in WordNet and appears in SemCor , so the merged corpus has instances where the word president has the synset vice president l , but only when preceded by the word vice</definiens>
			</definition>
</paper>

		<paper id="0714">
			<definition id="0">
				<sentence>The Maximum Entropy principle ( ME ) is an appropriate framework for combining information of a diverse nature from several sources into the same language model .</sentence>
				<definiendum id="0">Maximum Entropy principle ( ME )</definiendum>
				<definiens id="0">an appropriate framework for combining information of a diverse nature from several sources into the same language model</definiens>
			</definition>
			<definition id="1">
				<sentence>The language modeling problem may be defined as the problem of calculating the probability of a string , p ( w ) = p ( wl , ... , Wn ) .</sentence>
				<definiendum id="0">language modeling problem</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Maximum Entropy principle is an appropriate framework for combining information of a diverse nature from several sources into the same model : the Maximum Entropy model ( ME ) ( Rosenfeld , 1996 ) .</sentence>
				<definiendum id="0">Maximum Entropy principle</definiendum>
				<definiendum id="1">Maximum Entropy model ( ME )</definiendum>
				<definiens id="0">an appropriate framework for combining information of a diverse nature from several sources into the same model : the</definiens>
			</definition>
			<definition id="3">
				<sentence>The probability distribution is the distribution p that has the maximum entropy relative to a prior distribution P0 ( in other words : the distribution that minimize de divergence D ( pllpo ) ) ( Della Pietra et al. , 1995 ) .</sentence>
				<definiendum id="0">probability distribution</definiendum>
				<definiens id="0">the distribution p that has the maximum entropy relative to a prior distribution P0</definiens>
			</definition>
			<definition id="4">
				<sentence>• • , SM is a random sample from p ( w ) .</sentence>
				<definiendum id="0">SM</definiendum>
				<definiens id="0">a random sample from p ( w )</definiens>
			</definition>
			<definition id="5">
				<sentence>In this paper , we propose the application of another sampling technique in the parameter estimation process of the WSME model which was introduced by Propp and Wilson ( Propp and Wilson , 1996 ) : the Perfect Sampling ( PS ) .</sentence>
				<definiendum id="0">Perfect Sampling ( PS</definiendum>
				<definiens id="0">the application of another sampling technique in the parameter estimation process of the WSME model</definiens>
			</definition>
			<definition id="6">
				<sentence>In PS , we obtain a sample from the limit distribution of an ergodic Markov Chain X = { Xn ; n _ &gt; 0 } , taking values in the state space S ( in the WSME case , the state space is the set of possible sentences ) .</sentence>
				<definiendum id="0">state space</definiendum>
				<definiens id="0">the set of possible sentences</definiens>
			</definition>
			<definition id="7">
				<sentence>The traveler task consists in dialogs between travelers and hotel clerks .</sentence>
				<definiendum id="0">traveler task</definiendum>
			</definition>
			<definition id="8">
				<sentence>The second model used a 1EuTrans ESPRIT-LTR Project 20268 2IMH has been reported recently as the most useful MCMC algorithm used in the WSME training process .</sentence>
				<definiendum id="0">2IMH</definiendum>
				<definiens id="0">the most useful MCMC algorithm used in the WSME training process</definiens>
			</definition>
</paper>

		<paper id="0904">
			<definition id="0">
				<sentence>recogniser : NE-DT A decision tree is a type of classifier which has `` leaf nodes '' indicating classes and `` decision nodes '' that specify some test to be carried out , with one branch or subtree for each possible outcome of the test .</sentence>
				<definiendum id="0">recogniser</definiendum>
				<definiens id="0">a type of classifier which has `` leaf nodes '' indicating classes and `` decision nodes '' that specify some test to be carried out , with one branch or subtree for each possible outcome of the test</definiens>
			</definition>
			<definition id="1">
				<sentence>The corpus for MUC-6 ( MUC , 1995 ) contains 60 articles , from the test corpus for the dry and formalruns .</sentence>
				<definiendum id="0">corpus for MUC-6</definiendum>
				<definiens id="0">contains 60 articles , from the test corpus for the dry and formalruns</definiens>
			</definition>
			<definition id="2">
				<sentence>The MEDLINE database is an online collection of abstracts for published journal articles in biology and medicine and contains more than nine million articles .</sentence>
				<definiendum id="0">MEDLINE database</definiendum>
				<definiens id="0">an online collection of abstracts for published journal articles in biology and medicine and contains more than nine million articles</definiens>
			</definition>
			<definition id="3">
				<sentence>`` Recall '' is the percentage of answers proposed by the system that correspond to those in the human-made key set .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the percentage of answers proposed by the system that correspond to those in the human-made key set</definiens>
			</definition>
			<definition id="4">
				<sentence>`` Precision '' is the percentage of correct answers among the answers proposed by the system .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the percentage of correct answers among the answers proposed by the system</definiens>
			</definition>
			<definition id="5">
				<sentence>The entropy for NE classes H ( C ) is defined by = E p ( c ) log 2 p ( c ) H ( C ) cEC where : n ( O p ( c ) = `` N n ( c ) : the number of words in class c N : the total number of words in text We can calculate the entropy for features in the same way .</sentence>
				<definiendum id="0">entropy for NE classes H ( C )</definiendum>
				<definiendum id="1">n ( c )</definiendum>
				<definiendum id="2">N</definiendum>
				<definiens id="0">E p ( c ) log 2 p ( c ) H ( C ) cEC</definiens>
				<definiens id="1">the number of words in class c</definiens>
				<definiens id="2">the total number of words in text We can calculate the entropy for features in the same way</definiens>
			</definition>
			<definition id="6">
				<sentence>Information gain for NE classes and a feature I ( C ; F ) is given as follows : I ( C ; F ) = H ( C ) H ( CIF ) The information gain I ( C ; F ) shows how the feature F is related with NE classes C. When F is completely independent of C , the value of I ( C ; F ) becomes the minimum value O. The maximum value of I ( C ; _F ) is equivalent to that of H ( C ) , when the feature F gives sufficient information to recognize named entities .</sentence>
				<definiendum id="0">Information gain</definiendum>
				<definiens id="0">sufficient information to recognize named entities</definiens>
			</definition>
			<definition id="7">
				<sentence>The gain ratio GR ( C ; F ) is defined by GR ( C ; F ) = I ( C ; F ) H ( C ) The range of the gain ratio GR ( C ; F ) is 0 &lt; GR ( C ; F ) _~ 1 even when the class entropy is different in various corpora , so we can compare the values directly in the different NE recognition tasks .</sentence>
				<definiendum id="0">gain ratio GR</definiendum>
				<definiendum id="1">F</definiendum>
				<definiendum id="2">class entropy</definiendum>
				<definiens id="0">GR ( C ; F ) = I ( C ; F ) H ( C ) The range of the gain ratio GR ( C ;</definiens>
				<definiens id="1">different in various corpora , so we can compare the values directly in the different NE recognition tasks</definiens>
			</definition>
			<definition id="8">
				<sentence>Table 7 : Values of Entropy for words -- Entropy MUC-6 Biology H ( W ) 9.570 8.89O H ( C ) 0.890 1.264 H ( C , W ) 9.662 9.232 I ( C ; W ) 0.798 0.921 ~R ( C ; W ) 0.897 0.729 Table 8 : Values of Entropy for NEHMM features in the MUC-6 corpus GR Cross Entropy Coverage o.44 ( o.34-o.78 ) O. 77 ( 0.72-0.90 ) Features .</sentence>
				<definiendum id="0">GR Cross Entropy Coverage o.44</definiendum>
				<definiens id="0">Values of Entropy for words</definiens>
			</definition>
			<definition id="9">
				<sentence>Coverage means that how many pairs which appeared in a test set also appear in a trainlug set .</sentence>
				<definiendum id="0">Coverage</definiendum>
				<definiens id="0">how many pairs which appeared in a test set also appear in a trainlug set</definiens>
			</definition>
			<definition id="10">
				<sentence>cJ.5 Programs for Machine Learning .</sentence>
				<definiendum id="0">cJ.5 Programs</definiendum>
			</definition>
			<definition id="11">
				<sentence>The Eighth Text REtrieval Conference ( TREC-8 ) , Electronic version available at http : //trec.nist.gov/pubs.html .</sentence>
				<definiendum id="0">Eighth Text REtrieval Conference</definiendum>
			</definition>
</paper>

		<paper id="0737">
			<definition id="0">
				<sentence>163 For chunk tagger , we have gl = piwi where W~ = wlw2 '' '' Wn is the word sequence and P~ = PlP2 '' '' Pn is the part-of-speech ( POS ) sequence .</sentence>
				<definiendum id="0">Pn</definiendum>
				<definiens id="0">the word sequence and P~ = PlP2 '' ''</definiens>
			</definition>
			<definition id="1">
				<sentence>The basic idea of representing the structural tags is similar to Skut and Brants ( 1998 ) and the structural tag consists of three parts : 1 ) Structural relation .</sentence>
				<definiendum id="0">structural tag</definiendum>
				<definiens id="0">consists of three parts : 1 ) Structural relation</definiens>
			</definition>
			<definition id="2">
				<sentence>Given one of the N most probable chunk sequences extracted by the error-driven HMMbased chunk tagger , we can extract a set of chunk patterns , each of them with the format : XP 1 n n+l r~+l = poroPlrn Pn+l , where is the structural relation between Pi and Pi+l. As an example , from the bracketed and labeled sentence : \ [ NP He/PRP \ ] \ [ VP reckons/VSZ \ ] \ [ NP the/DT current/JJ account/NN deficit/NN \ ] \ [ VP will/MD narrow/VB \ ] \ [ PP to/TO\ ] \ [ NP only/RB # / # September/NNP \ ] \ [ O .</sentence>
				<definiendum id="0">chunk patterns</definiendum>
				<definiens id="0">with the format : XP 1 n n+l r~+l = poroPlrn Pn+l , where is the structural relation between Pi and Pi+l. As an example</definiens>
			</definition>
</paper>

		<paper id="0105">
			<definition id="0">
				<sentence>Word Sense Disambiguation ( WSD ) is a central task in the area of Natural Language Processing .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
				<definiendum id="1">WSD )</definiendum>
				<definiens id="0">a central task in the area of Natural Language Processing</definiens>
			</definition>
			<definition id="1">
				<sentence>complexity of learning task Formally , the problem of example-based learning of WSD models can be stated as follows : is either a hierarchy or a `` flat '' concept inventory ) , class H for a concept class C , where H : ~* -- ~C and ~ is a finite alphabet of symbols ( e.g. words or word tags ) , encodings of instances in the learner 's world , e.g. feature vectors representing contexts around words wj , where wj is a member of Ct , Given a training sample S of length m : S= ( ( xl , bl ) ... ( xm , bm ) ) xi eX , ~ e { O , l } where bl=l if xi is a positive example of Cl , characterize formally a function h ( C~ ) e H that assigns a word w to a concept Cl , given the sentence context x of w. The hypothesis may have the form of a Hidden Markov Model with estimated transition probabilities , a decision list , a cluster of points in a representation space , a logic formula , etc .</sentence>
				<definiendum id="0">~</definiendum>
				<definiendum id="1">wj</definiendum>
				<definiens id="0">the problem of example-based learning of WSD models can be stated as follows : is either a hierarchy or a `` flat '' concept inventory ) , class H for a concept class C , where H : ~* -- ~C and</definiens>
				<definiens id="1">a finite alphabet of symbols ( e.g. words or word tags ) , encodings of instances in the learner 's world</definiens>
			</definition>
			<definition id="2">
				<sentence>The theory of Probably Approximately Correct ( PAC ) learning , a relatively recent field at the borderline between Artificial Intelligence and Information Theory , states the conditions under which h reaches this objective , i.e. the conditions under which a computer derived hypothesis h 'probably ' represents Ct 'approximately ' .</sentence>
				<definiendum id="0">theory of Probably Approximately Correct</definiendum>
				<definiens id="0">states the conditions under which h reaches this objective</definiens>
			</definition>
			<definition id="3">
				<sentence>We say that C is PAC learnable if there exists an algorithm L with the following property : For every Ci~C , for every distribution D on X , and for all 0 &lt; e &lt; l/2 and 0 &lt; 8 &lt; 1/2 , if L is given access to EX ( C~ , D ) and inputs e and 8 , then with probability at least ( 1-8 ) , L outputs a hypothesis h for concept Cl , satisfying error ( h ) &lt; e. The parameters e and 5 have the following meaning : e is the probability that the learner produces a generalization of the sample that does not coincide with the target concept , while 5 is the probability , given D , that a particularly unrepresentative ( or noisy ) training sample is drawn. The objective of PAC theory is to predict the performance of learning systems by deriving a lower bound for m , as a function of the performance parameters e and Figure 1 ( from Russell and Norvig ( 1999 ) ) illustrates the `` intuitive '' meaning of PAC definition. After seeing m examples , the probability that Hbad includes consistent hypotheses is : P ( Hbad~Hco.s ) - &lt; \ [ Hbad \ [ ( l-l~ ) m- &lt; lH\ [ ( l-~ ) m H Hbad @ Figure I : e-sphere around the `` true '' function Ci And we want this to be : IHl ( 1-e ) m_ &lt; 6 we hence obtain a lower bound for the number of examples we need to submit to the learner in order to obtain the required accuracy : ( 1 ) m_ &gt; ~ ( ln~ +1 ~ I~ The inequality ( 1 ) establishes a sort of worstcase general bound , relating the size of the learning set with the complexity of the representation space \ [ HI .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">the probability that the learner produces a generalization of the sample that does not coincide with the target concept</definiens>
			</definition>
			<definition id="4">
				<sentence>W ... . Wn-l , Wn ) ) then H is any choice of _ &lt; k_ &lt; lV\ [ words over IVI elements , where \ [ V\ [ ( -- 10 s ) is the size of the vocabulary. We then have : the above expression , used in inequality ( 1 ) , produces an overly high bound for m , that can be hardly pursued especially in case the learning algorithm is supervised ! In PAC literature , the bound for m is often derived `` ad hoc '' for specific algorithms , in order to exploit knowledge on the precise learning conditions. It is also worth noticing that PAC literature has mostly a theoretical emphasis , and most applications concentrated on the field of neural networks and natural learning systems ( Hanson , Petsche , Kearns , Rivest ( 1994 ) ) . To the knowledge of the authors , the utility of this theory in the area of computer learning of natural language has not been explored. 30 In the following , we will derive a probabilistic expression for m in the track of ( 1 ) , for the case of a context-based WSD probabflistic learner , a learning method that includes a rather wide class of algorithms in the area of WSD. We believe that adapting our analysis to other example-based WSD systems will not require a significant effort. This relation allows it to establish , upon an a-priori analysis of the chosen conceptual model and of the language domain , a more precise relation between performance , complexity of the learning algorithm , and environmental conditions ( e.g. complexity of the language domain ) . Our objective is to show that an a-priori analysis of the learning model and language domain may help to tune precisely a WSD experiment and allows a more uniform comparison between different WSD systems. context-based probability WSD models A probabilistic context-based WSD learner may be described as follows : Let X be a space of feature vectors : fk= ( f ( all=vl , a21=v2 ... . ani=Vn ) e ~n , bik ) ) , b\ [ =1 if fk is a positive example of Ct under H. Each vector describes the context in which a word we Cl is found , with variable degree of complexity. For examples , arguments may be any combination of plain words and their morphologic , syntactic and semantic tags. We assume that arguments are not statistically independent ( in case they are , the representation of a concept is more simple , see Bruce and Wiebe , ( 1999 ) ) . An example ( Cucchiarelli , Luzi and Velardi ( 1998 ) ) is the case in which fk represents a syntactic relation between we C~ and another word in its context. For example , given the compound district banks the following feature is generated as an example of the category organization : ( ( N_N district bank ) , organization ( bank ) ) We further assume that observations of contexts are noisy , and the noise may be originated by several factors , such as tags ambiguity , and semantic ambiguity of the word whose context is observed. In the above feature vector , the syntactic tag ( first argument ) could be wrong because of syntactic ambiguity and limited coverage of available parsers , and the ambiguous word bank could not be , in a specific context , an instance of the category organization , though it is in the example above. Probabilistic learners usually associate to uncertain information a measure of the confidence the system has in that information. Therefore , we assume that each feature fk is associated to a concept Cl with a confidence qb ( i , k ) . The confidence may be calculated in several ways , depending upon the type of selected features for fk. For example , the Mutual Information measures the strength of a correlation between co-occurring arguments , and the Plausibility ( Cucchiarelli , Luzi and Velardi ( 1998 ) ) assigns a weight to a feature vector , depending upon the degree of ambiguity of its arguments and the frequency of its observations in a corpus. We assume here that ~ is adjusted to be a probability , i.e. ~l~ ( i , k ) =l. The factor ~ ( i , k ) represents hence an estimate of the probability that fk. is indeed a context of Ci. Under these hypotheses , a representation he H for a concept Ct is the following : h ( Cl ) : { fll..flm , } ( 2 ) fk-~h ( Cl ) iff qb ( i , k ) &gt; y A concept is hence represented by a set of features with associated probabilities 2 .</sentence>
				<definiendum id="0">syntactic tag</definiendum>
				<definiendum id="1">Mutual Information</definiendum>
				<definiendum id="2">Plausibility</definiendum>
				<definiens id="0">in order to exploit knowledge on the precise learning conditions. It is also worth noticing that PAC literature has mostly a theoretical emphasis , and most applications concentrated on the field of neural networks and natural learning systems</definiens>
				<definiens id="1">context-based probability WSD models A probabilistic context-based WSD learner may be described as follows</definiens>
				<definiens id="2">measures the strength of a correlation between co-occurring arguments</definiens>
			</definition>
			<definition id="5">
				<sentence>Notice however that in order to obtain a given accuracy of estimate , Chernoff bounds ( and other methods ) again impose a bound on the number of observed examples ( Kearns and Vazirani ( 1994 ) ) Since in ( 3.1 ) ( 1-~ ( i , k ) ) &lt; y , in ( 3.2 ) ~ ( i , k ) ) &gt; y , and in ( 3.3 ) ~ ( i , k ) ) _ &lt; l , we obtain the bound : P ( w ' is misclassified on the basis of f'k ) = &lt; _ Mi m -Ni ( l-y ) +_~ty +l~m ~m The expression ( 3 ) establishes interesting dependencies between the accuracy of a context-based probabilistic WSD model and certain environmental conditions. linguistic concepts In a complex language domain ( e.g. newspaper articles ) linguistic phenomena are far less repetitive than in a restricted language ( e.g. airline reservations ) . However , even in a relatively unrestricted domain certain categories are used in a more narrow sense. Let us consider the probabilistic context-based algorithm in Cucchiarelli , Luzi and Velardi ( 1998 ) , where a feature is defined by : fk : ( syntactic_relation , wl , wi ) ( e.g. ( N_N district bank ) ) fk ~C~ if w i reaches the hyperonym C~ in the WordNet on-line taxonomy , and ~ ( i , k ) &gt; y Using the 1 million word Wall Street Journal corpus , we estimated the following probabilities ( 3.3 ) of unseen feature vectors ( m in this experiment is O ( 105 ) ) : P ( unseen in artifact ) =0,7692 P ( unseen in person ) = 0,7161 P ( unseen in psychological feature ) =0.8598 complex function must be used in case contexts are considered similar if , for example , co-occurring words have some common hyperonym .</sentence>
				<definiendum id="0">Chernoff bounds</definiendum>
				<definiendum id="1">co-occurring words</definiendum>
				<definiens id="0">the accuracy of a context-based probabilistic WSD model and certain environmental conditions. linguistic concepts In a complex language domain ( e.g. newspaper articles ) linguistic phenomena are far less repetitive than in a restricted language ( e.g. airline reservations ) . However</definiens>
			</definition>
			<definition id="6">
				<sentence>• The experimental setting ( i.e. size of the training set ) must be tuned for each category and language domain , because the variability of contextual behavior may be significantly different , depending on domain complexity , e.g. the type and grain of the selected category , and the more or less restricted language domain • it is possible and indeed advisable , for a given WSD algorithm , to determine in a formal way the relation between expected accuracy of the WSD model and the domain and representation complexity .</sentence>
				<definiendum id="0">experimental setting</definiendum>
				<definiens id="0">a given WSD algorithm , to determine in a formal way the relation between expected accuracy of the WSD model and the domain</definiens>
			</definition>
</paper>

		<paper id="0702">
			<definition id="0">
				<sentence>To explore the space of possible grammars , a special treebank representation was developed , called a \ ] folded treebank , which allows the objective function to be computed very efficiently for each candidate grammar .</sentence>
				<definiendum id="0">\ ] folded treebank</definiendum>
				<definiens id="0">allows the objective function to be computed very efficiently for each candidate grammar</definiens>
			</definition>
			<definition id="1">
				<sentence>M + such that rhs ( r ) = aAfl , lal = k 1 , lhs ( r ' ) = A , rhs ( r ' ) = V. The rule adjunction of r I in the k th position of r is defined as a new rule RA ( r , k , r ~ ) = r ' , such that : lhs ( r '' ) = lhs ( r ) rhs ( r '' ) = aVfl For unification grammars , we instead require lhs ( r ' ) U rhs ( r ) ( k ) lhs ( r 1 ' ) = O ( lhs ( r ) ) rhs ( r '' ) = O ( oLTfl ) where rhs ( r ) ( k ) is the kth symbol of rhs ( r ) , where X t3 Y indicates that X and Y unify , and where 0 is the most general unifier of lhs ( r ~ ) and rhs ( r ) ( k ) .</sentence>
				<definiendum id="0">r ' ) U rhs ( r ) ( k ) lhs</definiendum>
				<definiens id="0">M + such that rhs ( r ) = aAfl , lal = k 1 , lhs ( r ' ) = A , rhs ( r ' ) = V. The rule adjunction of r I in the k th position of r is defined as a new rule RA ( r , k , r ~ ) = r ' , such that : lhs ( r '' ) = lhs ( r ) rhs ( r '' ) = aVfl For unification grammars</definiens>
				<definiens id="1">lhs ( r ) ) rhs ( r '' ) = O ( oLTfl ) where rhs ( r ) ( k ) is the kth symbol of rhs ( r ) , where X t3 Y indicates that X and Y unify , and where 0 is the most general unifier of lhs ( r ~ ) and rhs ( r ) ( k )</definiens>
			</definition>
			<definition id="2">
				<sentence>The objective 8 A C A-oc A_oc B `` -'~ '' D A `` -'P '' E F C A -- -~ '' E F C B -- -- -PE F A~ B ~ G Specialization Downward unfolding of A - &gt; B C on `` B '' A C j B -- -- -~ A D B `` '~ '' B C C `` 'D '' E B C B ' '' ~ A C `` '' -~E B C C ' '' ~ E A Specialization Upward unfolding of A - &gt; B C Figure 1 : Schematic examples of upward and downward unfolding of rules .</sentence>
				<definiendum id="0">C A-oc A_oc B `` -'~ '' D A `` -'P</definiendum>
				<definiendum id="1">C C</definiendum>
				<definiendum id="2">Specialization Upward unfolding</definiendum>
				<definiens id="0">'' E F C A -- -~ '' E F C B -- -- -PE F A~ B ~ G Specialization Downward unfolding of A - &gt; B C on `` B '' A C j B -- -- -~ A D B `` '~ '' B</definiens>
			</definition>
			<definition id="3">
				<sentence>function Score was thus formulated as follows : Scorea = Acorr Corra -Aine InCa ~size Sizea where Corr and Inc are the number of correct and incorrect parses allowed by the grammar , and Size is the size of the grammar measured as the total number of symbol occurrences in the right-hand sides of its rules .</sentence>
				<definiendum id="0">Size</definiendum>
				<definiens id="0">the size of the grammar measured as the total number of symbol occurrences in the right-hand sides of its rules</definiens>
			</definition>
			<definition id="4">
				<sentence>A folded treebank is a representation of a set of parse trees which allows an immediate assessment of the effects of inhibiting specific rule combinations .</sentence>
				<definiendum id="0">folded treebank</definiendum>
				<definiens id="0">a representation of a set of parse trees which allows an immediate assessment of the effects of inhibiting specific rule combinations</definiens>
			</definition>
			<definition id="5">
				<sentence>If the performed specialization is X C_ DRU ( r , k ) ~ { r } , 3 then the concatenation/or graph is updated as follows = nux\ { ~ ) ~r = ~r U { ( lhs ( r ) , ~ ) l~ E X } \ { ( lhs ( r ) , r ) } ~ ( r '' , i ) = { VR ( r '' , i ) , r '' ¢ X ~\ ] R ( r , i ) , r u E X , i &lt; k = VR ( r ' , i -k + 1 ) , r '' = aA ( r , k , r ' ) E X , k &lt; i &lt; k+m-1 , ~R ( r , i -m + 1 ) , r '' = RA ( r , k , r ' ) E X , i &gt; k+m-1 , where m = arity ( r ' ) = Irhs ( r ' ) l is the number of right-hand-side symbols of rule r ~ .</sentence>
				<definiendum id="0">X C_ DRU</definiendum>
				<definiendum id="1">m = arity</definiendum>
				<definiendum id="2">l</definiendum>
				<definiens id="0">r , k , r ' ) E X</definiens>
			</definition>
			<definition id="6">
				<sentence>Precision is the ratio between the number of correct parses produced by the specialized grammar and the total number of parses produced by the same grammar .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio between the number of correct parses produced by the specialized grammar and the total number of parses produced by the same grammar</definiens>
			</definition>
			<definition id="7">
				<sentence>The most aggressive form of spe4The F-score is the harmonic mean of recall and precision , where precision is weighted a and recall 1 a. 11 Avg .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the harmonic mean of recall and precision</definiens>
			</definition>
</paper>

		<paper id="1217">
			<definition id="0">
				<sentence>A syntactic form is the combination of token plus type .</sentence>
				<definiendum id="0">syntactic form</definiendum>
				<definiens id="0">the combination of token plus type</definiens>
			</definition>
</paper>

		<paper id="1201">
			<definition id="0">
				<sentence>Figure 2 illustrates all three of these operations , c~i is an initial tree which substitutes at the leftmost node labeled NP $ ; /~ is an auxiliary tree which adjoins at the node labeled VP .</sentence>
				<definiendum id="0">c~i</definiendum>
				<definiens id="0">an auxiliary tree which adjoins at the node labeled VP</definiens>
			</definition>
			<definition id="1">
				<sentence>Pi ( c~ ) is the probability of beginning a derivation with c~ ; Ps ( o~ I 77 ) is the probability of substituting o~ at 7 ; Pa ( /~ I r/ ) is the probability of adjoining ~ at 7/ ; finally , Pa ( NONE I 7 ) is the probability of nothing adjoining at ~/ .</sentence>
				<definiendum id="0">Pi ( c~ )</definiendum>
				<definiendum id="1">Ps ( o~ I 77 )</definiendum>
				<definiendum id="2">Pa ( /~ I r/ )</definiendum>
				<definiendum id="3">Pa ( NONE I 7 )</definiendum>
				<definiens id="0">the probability of beginning a derivation with c~</definiens>
				<definiens id="1">the probability of substituting o~ at 7</definiens>
				<definiens id="2">the probability of adjoining ~ at 7/</definiens>
				<definiens id="3">the probability of nothing adjoining at ~/</definiens>
			</definition>
			<definition id="2">
				<sentence>The Chinese Treebank consists of 4185 sentences of Xinhua newswire text .</sentence>
				<definiendum id="0">Chinese Treebank</definiendum>
			</definition>
</paper>

		<paper id="1208">
			<definition id="0">
				<sentence>An auxiliary tree represents a recursive structure and has a unique leaf node , called the foot node , which has the same syntactic category as the root node .</sentence>
				<definiendum id="0">auxiliary tree</definiendum>
				<definiendum id="1">foot node</definiendum>
				<definiens id="0">a recursive structure and has a unique leaf node</definiens>
				<definiens id="1">has the same syntactic category as the root node</definiens>
			</definition>
			<definition id="1">
				<sentence>X ° is the head of X m and the anchor of the etree .</sentence>
				<definiendum id="0">X °</definiendum>
				<definiens id="0">the head of X m and the anchor of the etree</definiens>
			</definition>
			<definition id="2">
				<sentence>The core of LexTract is an extraction algorithm that takes a Treebank sentence such as the one in Figure 1 and Treebank-specific information provided by the user of LexTract , and produces a set of etrees as in Figure 4 and a derivation tree .</sentence>
				<definiendum id="0">extraction algorithm</definiendum>
				<definiens id="0">takes a Treebank sentence such as the one in Figure 1 and Treebank-specific information provided by the user of LexTract , and produces a set of etrees as in Figure 4 and a derivation tree</definiens>
			</definition>
			<definition id="3">
				<sentence>Truly unmatched templates A truly unmatched template is a template that does not match any template in the other Treebank even if we assume both Treebanks are perfectly annotated .</sentence>
				<definiendum id="0">truly unmatched template</definiendum>
				<definiens id="0">a template that does not match any template in the other Treebank even if we assume both Treebanks are perfectly annotated</definiens>
			</definition>
</paper>

		<paper id="1302">
			<definition id="0">
				<sentence>BACKGROUND `` Part-of-speech tagging is the process of assigning grammatical categories to individual words in a corpus . ''</sentence>
				<definiendum id="0">BACKGROUND</definiendum>
				<definiendum id="1">Part-of-speech tagging</definiendum>
				<definiens id="0">the process of assigning grammatical categories to individual words in a corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>We measured stability ( the degree to which the same annotator will produce an annotation after 6 weeks ) and reproducibility ( the degree to which two unrelated annotators will produce the same annotation ) , using the Kappa coefficient K ( Siegel and Castellan , 1988 ; Carletta , 1996 ) , which controls agreement P ( A ) for chance agreement P ( E ) : K = P { A ) -P ( E ) 1-P ( Z ) Kappa is 0 for if agreement is only as would be expected by chance annotation following the same distribution as the observed distribution , and 1 for perfect agreement .</sentence>
				<definiendum id="0">stability</definiendum>
				<definiendum id="1">reproducibility</definiendum>
				<definiendum id="2">Kappa coefficient K</definiendum>
				<definiens id="0">the degree to which the same annotator will produce an annotation after 6 weeks</definiens>
				<definiens id="1">the degree to which two unrelated annotators will produce the same annotation</definiens>
				<definiens id="2">controls agreement P ( A ) for chance agreement P ( E ) : K = P { A ) -P ( E ) 1-P ( Z )</definiens>
			</definition>
			<definition id="2">
				<sentence>Our experiments show that humans can distinguish own , other specific and other general work with high stability ( K=.83 , .79 , .81 ; N=1248 ; k=2 , where K stands for the Kappa coefficient , N for the number of items ( sentences ) annotated and k for the number of annotators ) and reproducibility ( K=.78 , N=4031 , k=3 ) , corresponding to 94 % , 93 % , 93 % ( stability ) and 93 % ( reproducibility ) agreement .</sentence>
				<definiendum id="0">K</definiendum>
				<definiendum id="1">N for</definiendum>
				<definiens id="0">the number of items ( sentences ) annotated and k for the number of annotators</definiens>
			</definition>
			<definition id="3">
				<sentence>Evaluation B tests how well agent and action recognition helps us perform argumentative zoning automatically .</sentence>
				<definiendum id="0">Evaluation B</definiendum>
				<definiens id="0">tests how well agent and action</definiens>
			</definition>
			<definition id="4">
				<sentence>AIM and TEXTUAL sentences , stating knowledge claims and organizing the text respectively , are conventionalized to a high degree .</sentence>
				<definiendum id="0">TEXTUAL sentences</definiendum>
				<definiens id="0">stating knowledge claims and organizing the text respectively , are conventionalized to a high degree</definiens>
			</definition>
</paper>

		<paper id="1327">
			<definition id="0">
				<sentence>Yet parsers depend crucially on such information , and probabilistic parsers would greatly benefit from accurate information concerning the relative frequency of different subcategorization frames ( SCFs ) for a given predicate .</sentence>
				<definiendum id="0">SCFs</definiendum>
				<definiens id="0">such information , and probabilistic parsers would greatly benefit from accurate information concerning the relative frequency of different subcategorization frames</definiens>
			</definition>
			<definition id="1">
				<sentence>*Token recall is the percentage of SCF tokens in a sample of manually analysed text that were correctly acquired by the system .</sentence>
				<definiendum id="0">*Token recall</definiendum>
				<definiens id="0">the percentage of SCF tokens in a sample of manually analysed text that were correctly acquired by the system</definiens>
			</definition>
			<definition id="2">
				<sentence>The SCFs are a superset of classes found in the ANLT and COMLEX ( Grishman et al. , 1994 ) dictionaries .</sentence>
				<definiendum id="0">SCFs</definiendum>
				<definiens id="0">a superset of classes found in the ANLT and COMLEX ( Grishman et al. , 1994 ) dictionaries</definiens>
			</definition>
			<definition id="3">
				<sentence>The estimated probability of the SCF is given by P ( xn ) = Al ( p ( z , ~ ) ) + ) ~2 ( p ( xnp ) ) ( 3 ) where the Ai denotes weights for different context sizes ( obtained by optimising the smoothing performance on the training data for all zn ) and sum to 1 .</sentence>
				<definiendum id="0">estimated probability of the SCF</definiendum>
				<definiens id="0">weights for different context sizes ( obtained by optimising the smoothing performance on the training data for all zn</definiens>
			</definition>
			<definition id="4">
				<sentence>We calculated type precision ( percentage of SCFs acquired which were also exemplified in the manual analysis ) and recall ( percentage of the SCFs exemplified in the manual analysis which were also acquired automatically ) , and combined them into a single measure of overall performance using the F measure ( Manning and Schiitze , 1999 ) .</sentence>
				<definiendum id="0">type precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">percentage of SCFs acquired which were also exemplified in the manual analysis</definiens>
				<definiens id="1">percentage of the SCFs exemplified in the manual analysis which were also acquired automatically</definiens>
			</definition>
			<definition id="5">
				<sentence>Introduction to WordNet : An On-Line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0720">
			<definition id="0">
				<sentence>IGTREE is a variant in which an oblivious decision tree is created with features as tests , and in which tests are ordered according to information gain of the associated features .</sentence>
				<definiendum id="0">IGTREE</definiendum>
				<definiens id="0">a variant in which an oblivious decision tree is created with features as tests , and in which tests are ordered according to information gain of the associated features</definiens>
			</definition>
			<definition id="1">
				<sentence>Boldface marks the best results for each basic algorithm per data set .</sentence>
				<definiendum id="0">Boldface</definiendum>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>We introduce CST ( cross-document slructure theory ) , a paradigm for multidocument analysis .</sentence>
				<definiendum id="0">CST ( cross-document slructure theory )</definiendum>
				<definiens id="0">a paradigm for multidocument analysis</definiens>
			</definition>
			<definition id="1">
				<sentence>The Topic Detection and Tracking model ( TDT ) \ [ Allan et al. 98\ ] describes news events as they are reflected in news sources .</sentence>
				<definiendum id="0">Topic Detection</definiendum>
				<definiens id="0">and Tracking model ( TDT ) \ [ Allan et al. 98\ ] describes news events as they are reflected in news sources</definiens>
			</definition>
			<definition id="2">
				<sentence>RST posits the existence of relations among sentences .</sentence>
				<definiendum id="0">RST</definiendum>
				<definiens id="0">posits the existence of relations among sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>SUMMONS \ [ Radev &amp; McKeown 98\ ] is a knowledge-based multi-document summarization system , which produces summaries of a small number of news articles within the domain of terrorism .</sentence>
				<definiendum id="0">SUMMONS</definiendum>
				<definiens id="0">a knowledge-based multi-document summarization system , which produces summaries of a small number of news articles within the domain of terrorism</definiens>
			</definition>
			<definition id="4">
				<sentence>Def'mition A document unit U is a tuple ( t , s , p ) see Figure 3 ( b ) .</sentence>
				<definiendum id="0">document unit U</definiendum>
				<definiens id="0">a tuple ( t , s , p ) see Figure 3 ( b )</definiens>
			</definition>
			<definition id="5">
				<sentence>Definition A document D is a sequence of document units U1U2 ... Un which corresponds to a one-dimensional projection of a multidocument cube along the source and time dimensions .</sentence>
				<definiendum id="0">document D</definiendum>
				<definiens id="0">a sequence of document units U1U2 ... Un which corresponds to a one-dimensional projection of a multidocument cube along the source and time dimensions</definiens>
			</definition>
			<definition id="6">
				<sentence>Definition A snapshot is a slice of the multidocument cube over a period of time At see Figure 3 ( c ) .</sentence>
				<definiendum id="0">snapshot</definiendum>
				<definiens id="0">a slice of the multidocument cube over a period of time At see Figure 3 ( c )</definiens>
			</definition>
			<definition id="7">
				<sentence>Definition An extractive summary S of a cube C is a set of document units , S c C , see Figure 3 ( d ) .</sentence>
				<definiendum id="0">extractive summary S</definiendum>
				<definiens id="0">a set of document units , S c C</definiens>
			</definition>
			<definition id="8">
				<sentence>The third technique , information extraction [ Radev &amp; McKeown 98 ] identifies salient semantic roles in text ( e.g. , the place , perpetrator , and effect of a terrorist event ) and converts them to semantic templates .</sentence>
				<definiendum id="0">information extraction</definiendum>
				<definiens id="0">identifies salient semantic roles in text ( e.g. , the place , perpetrator , and effect of a terrorist event ) and converts them to semantic templates</definiens>
			</definition>
			<definition id="9">
				<sentence>A graph-based operator defines a transformation on a multi-document graph ( MDG ) G which preserves some of its properties while reducing the number of nodes .</sentence>
				<definiendum id="0">graph-based operator</definiendum>
				<definiens id="0">defines a transformation on a multi-document graph ( MDG ) G which preserves some of its properties while reducing the number of nodes</definiens>
			</definition>
			<definition id="10">
				<sentence>In the example , the shaded area represents the summary subgraph G '' of G that contains all four cross-document links and only these nodes and edges of G which are necessary to preserve the textual structure of G ' .</sentence>
				<definiendum id="0">summary subgraph G</definiendum>
				<definiens id="0">contains all four cross-document links and only these nodes and edges of G which are necessary to preserve the textual structure of G '</definiens>
			</definition>
</paper>

		<paper id="0204">
			<definition id="0">
				<sentence>What makes the interlingua UNL special is its intended use : as an electronic language for networks , it has to allow for high quality 2 conversation systems involving many languages .</sentence>
				<definiendum id="0">interlingua UNL</definiendum>
				<definiens id="0">an electronic language for networks</definiens>
			</definition>
			<definition id="1">
				<sentence>In addition to being consistent and complete to represent meaning , we also consider its sharing by researchers all around the world , which is an important bottleneck of the UNL Project , since information exchange by researchers during R &amp; D brings about the problems introduced by the interlingua UNL itself , concerning both its formalism and foundational issues .</sentence>
				<definiendum id="0">UNL</definiendum>
				<definiens id="0">an important bottleneck of the UNL Project , since information exchange by researchers during R &amp; D brings about the problems introduced by the interlingua</definiens>
			</definition>
			<definition id="2">
				<sentence>Its main strength lies on the development of the UNL , as a unique semantic ( or meaning ) representation that can be interchanged with the various languages to be integrated in the KBMT system .</sentence>
				<definiendum id="0">UNL</definiendum>
			</definition>
			<definition id="3">
				<sentence>In the UNL Project , plug-in software to encode NL texts onto UNL ones ( NL-UNL encoders ) and to decode UNL into NL texts ( UNL-NL decoders ) have been developed by R &amp; D groups in their own native languages .</sentence>
				<definiendum id="0">UNL Project</definiendum>
				<definiens id="0">plug-in software to encode NL texts onto UNL ones ( NL-UNL encoders ) and to decode UNL into NL texts ( UNL-NL decoders ) have been developed by R &amp; D groups in their own native languages</definiens>
			</definition>
			<definition id="4">
				<sentence>The UNL is a formal language designed for rendering automatic multilingual information exchange .</sentence>
				<definiendum id="0">UNL</definiendum>
				<definiens id="0">a formal language designed for rendering automatic multilingual information exchange</definiens>
			</definition>
			<definition id="5">
				<sentence>Granularity thus plays an important role in UNL lexical organization and brings flexibility into crosslinguistic lexical matching .</sentence>
				<definiendum id="0">Granularity</definiendum>
				<definiens id="0">an important role in UNL lexical organization and brings flexibility into crosslinguistic lexical matching</definiens>
			</definition>
			<definition id="6">
				<sentence>2 '' 7 UNL depicts sentence meaning as a fact composed by either a simple or a complex event , which is considered here the starting point of a UNL representation , i.e. , its minimal complete semantic unit .</sentence>
				<definiendum id="0">UNL</definiendum>
				<definiens id="0">depicts sentence meaning as a fact composed by either a simple or a complex event</definiens>
			</definition>
			<definition id="7">
				<sentence>Event actors are any animate or inanimate character playing any role in events , which can be the main or the coadjutant actors .</sentence>
				<definiendum id="0">Event actors</definiendum>
				<definiens id="0">any animate or inanimate character playing any role in events</definiens>
			</definition>
			<definition id="8">
				<sentence>There can be up to eight actors , signaled by the following RLs : agent ( agt ) , co-agent ( cag ) , object ( obj ) , co-object ( cob ) , object place ( opl ) , beneficiary ( ben ) , partner ( ptn ) and instrument ( ins ) .</sentence>
				<definiendum id="0">instrument</definiendum>
				<definiens id="0">eight actors , signaled by the following RLs : agent ( agt ) , co-agent ( cag )</definiens>
			</definition>
			<definition id="9">
				<sentence>28 The UNL system architecture consists of two main processes , the encoder and decoder , and several linguistic resources , each group of these corresponding to a NL embedded in the system , as depicted in Figure 3 .</sentence>
				<definiendum id="0">UNL system architecture</definiendum>
				<definiens id="0">consists of two main processes , the encoder and decoder , and several linguistic resources , each group of these corresponding to a NL embedded in the system</definiens>
			</definition>
			<definition id="10">
				<sentence>The NL-UNL encoding tool , or UNL Encoder , is generic enough to handle all the 29 languages included in the Project .</sentence>
				<definiendum id="0">UNL Encoder</definiendum>
				<definiens id="0">NL-UNL encoding tool</definiens>
			</definition>
			<definition id="11">
				<sentence>The UNL-NL decoding tool , or UNL Decoder , works in the opposite way to the Encoder .</sentence>
				<definiendum id="0">UNL Decoder</definiendum>
				<definiens id="0">works in the opposite way to the Encoder</definiens>
			</definition>
			<definition id="12">
				<sentence>In this respect , we have not been facing many problems in fitting Portuguese structures with UNL ones , since Portuguese , like English , is an inflectional language that also employs prepositional constructions .</sentence>
				<definiendum id="0">Portuguese</definiendum>
				<definiens id="0">an inflectional language that also employs prepositional constructions</definiens>
			</definition>
</paper>

		<paper id="0102">
			<definition id="0">
				<sentence>Table 1 : Semantic Categories ( SEMCATs ) Abbreviation 6 'CRTH Io FORM 11 GINV 12 INOM 13 MECO 14 MFRE 15 MIG 16 MOAF 17 MOCO 18 MOT 19 NOIC 2o NUM 21 OPIG 22 ORD 23 ORGM 24 PEAF Full Description Affection in General Antagonism Causation Change Conditional Intersocial Volition Creative Thought Dimensions Existence Extension of Thought Form General Inter social Volition Inorganic Matter Means of Communication Materials for Reasoning Matter in general Moral Affections Modes of Communication Motion Nature of Ideas Communicated Number Operations of Intelligence In General Order Organic Matter Personal Affections 25 26 PORE Possessive Relations PRCO 27 PRVO 28 QUAN 29 REAF 3o RELN 31 REOR 32 REPR 33 ROVO 34 SIG 35 SIVO 36 SYAF 37 TIME 38 VOAC 39 VOIG Precursory Conditions and Operations Prospective Volition Quantity Religious Affections Relation Reasoning Organization Reasoning Process Result of Voluntary Action Space in General Special Inter social Volition Sympathetic Affections Time Voluntary Action Volition in General Many of the most frequently occurring words in English , such as `` the , '' `` of , ... . and , '' `` to , '' etc. are non-discriminators with respect to information filtering .</sentence>
				<definiendum id="0">Semantic Categories</definiendum>
				<definiens id="0">General Antagonism Causation Change Conditional Intersocial Volition Creative Thought Dimensions Existence Extension of Thought Form General Inter social Volition Inorganic Matter Means of Communication Materials for Reasoning Matter in general Moral Affections Modes of Communication Motion Nature of Ideas Communicated Number Operations of Intelligence In General Order Organic Matter Personal Affections 25 26 PORE Possessive Relations</definiens>
				<definiens id="1">Operations Prospective Volition Quantity Religious Affections Relation Reasoning Organization Reasoning Process Result of Voluntary Action Space in General Special Inter social Volition Sympathetic Affections Time Voluntary Action Volition in General Many of the most frequently occurring words in English</definiens>
			</definition>
			<definition id="1">
				<sentence>One document `` Barbie '' in the Jang ( 1997 ) collection has a total of 1,468 words comprised of 755 content words and 713 function words .</sentence>
				<definiendum id="0">Barbie</definiendum>
				<definiens id="0">a total of 1,468 words comprised of 755 content words and 713 function words</definiens>
			</definition>
			<definition id="2">
				<sentence>Figurel : Preprocessed Text Document BARBIE * * * * FAVORITE COMPANION DETRACTORS LOVE * * * PLASTIC PERFECTION * * FASHION DOLL * * IMPOSSIBLE FIGURE * LONG * * * POPULAR GIRL * MATTEL * WORLD * TOYMAKER * PRODUCTS RANGE * FISHER PRICE INFANT * SALES * * * TALL MANNEQUIN * BARBIE * * AGE * * * BEST SELLING GIRLS BRAND * * POISED * STRUT * * * CHANGE * * MALE DOMINATED WORLD * MULTIMEDIA SOFTWARE * VIDEO GAMES In Figure 1 , asterisks occupy positions where function words were filtered out .</sentence>
				<definiendum id="0">Figurel</definiendum>
				<definiens id="0">Preprocessed Text Document BARBIE * * * * FAVORITE COMPANION DETRACTORS LOVE * * * PLASTIC PERFECTION * * FASHION DOLL * * IMPOSSIBLE FIGURE * LONG * * * POPULAR GIRL * MATTEL * WORLD * TOYMAKER * PRODUCTS RANGE * FISHER PRICE INFANT * SALES * * * TALL MANNEQUIN * BARBIE * * AGE * * * BEST SELLING GIRLS BRAND * * POISED * STRUT * * * CHANGE * * MALE DOMINATED WORLD * MULTIMEDIA SOFTWARE * VIDEO GAMES In Figure 1 , asterisks occupy positions where function words were filtered out</definiens>
			</definition>
			<definition id="3">
				<sentence>SEMCAT weights are calculated based on the following equations .</sentence>
				<definiendum id="0">SEMCAT weights</definiendum>
				<definiens id="0">calculated based on the following equations</definiens>
			</definition>
			<definition id="4">
				<sentence>We can write ; Swj= £ PO i=1 Eq.3 edwj ( Expected data weights in a paragraph ) Given a set of N content words ( data ) in a paragraph , the expected weight of the SEMCATs of long runs in a paragraph is : N edwj = E Po i=1 Eq.4 idwj ( Inverse data weights in a paragraph ) The inverse data weight of SEMCATs of long runs for a set of N content words in a paragraph is idwj= loglo ( ( e~wj\ ] ) Eq.5 Weight ( Wj ) The weight of SEMCAT Sj in .</sentence>
				<definiendum id="0">Expected</definiendum>
				<definiens id="0">data weights in a paragraph ) Given a set of N content words ( data ) in a paragraph , the expected weight of the SEMCATs of long runs in a paragraph is : N edwj = E Po i=1 Eq.4 idwj ( Inverse data weights in a paragraph</definiens>
			</definition>
			<definition id="5">
				<sentence>The following is a program output for calculating SEMCAT weights for an arbitrary long run : `` SEVEN INTERACTIVE PRODUCTS LED '' SEMCAT : EXOT Sw : 1.00 edw : 1.99 idw : SEMCAT : GINV Sw : 0.33 edw : 1.62 idw : SEMCAT : MOT Sw : 0.20 edw : 0.71 idw : SEMCAT : NUM Sw : 0.20 edw : 1.76 idw : SEMCAT : ORGM Sw : 0.20 edw : 1.67 idw : SEMCAT : PEAF Sw : 0.53 edw : 1.50 idw : SEMCAT : REAF Sw : 0.20 edw : 0.20 idw : SEMCAT : SYAF Sw : 0.33 edw : 1.19 idw : Total ( Swxidw ) : 4.79 The goal of employing probability and vector processing is to prove the linguistic basis that long runs of content words can be used as predictors of semantic intent But we also want to exploit the computational advantage of removing the function words from the document , which reduces the number of tokens processed by about 50 % and thus reduces vector space and probability computations .</sentence>
				<definiendum id="0">SEMCAT</definiendum>
			</definition>
</paper>

		<paper id="1321">
			<definition id="0">
				<sentence>Idioms are recognized prior to syntactic analysis and the part of a sentence for an idiom takes an edge in a chart ( Winograd , 1983 ) .</sentence>
				<definiendum id="0">Idioms</definiendum>
			</definition>
			<definition id="1">
				<sentence>Most context-free parsing algorithms have O ( n 3 ) parsing complexities in terms of time and space , where n is the length of a sentence ( Tomita , 1986 ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the length of a sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Pattern rules ( Li et al. , 1990 ) and sentence patterns ( Kim and Khn , 1995 ) were used to segment long English sentences .</sentence>
				<definiendum id="0">Pattern rules</definiendum>
				<definiens id="0">Li et al. , 1990 ) and sentence patterns</definiens>
			</definition>
			<definition id="3">
				<sentence>Maximum entropy is a technique for automatically acquiring knowledge from incomplete information , without making any unsubstantiated assumptions .</sentence>
				<definiendum id="0">Maximum entropy</definiendum>
				<definiens id="0">a technique for automatically acquiring knowledge from incomplete information , without making any unsubstantiated assumptions</definiens>
			</definition>
			<definition id="4">
				<sentence>We build a probability distribution p ( ylx ) , where y • { 0 , 1 } is a random variable specifying the potential segmentation position in a context x. A feature of a context is a binary-valued indicator function \ ] expressing the information about a specific context .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">a binary-valued indicator function \ ] expressing the information about a specific context</definiens>
			</definition>
			<definition id="5">
				<sentence>- , ( XN , YN ) , an empirical probability distribution can be defined as y ) = y ) N where # ( x , y ) is the number of occurrences of ( x , y ) .</sentence>
				<definiendum id="0">XN , YN )</definiendum>
				<definiendum id="1">empirical probability distribution</definiendum>
				<definiens id="0">y ) = y ) N where # ( x , y ) is the number of occurrences of ( x , y )</definiens>
			</definition>
			<definition id="6">
				<sentence>h ( x , y ) , x~y where l~ ( x ) is the empirical distribution of x in the corpus .</sentence>
				<definiendum id="0">l~ ( x )</definiendum>
				<definiens id="0">the empirical distribution of x in the corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>T , where Y is the set of candidate features .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">the set of candidate features</definiens>
			</definition>
			<definition id="8">
				<sentence>The uniformity of the probability distribution p ( ylx ) is measured by the conditional entropy : H ( p ) = ~p ( x , y ) logp ( ylx ) x~y = ( x ) PCulx ) logp ( ylx ) x , y Thus , the probability distribution with maximum entropy is the most uniform distribution .</sentence>
				<definiendum id="0">maximum entropy</definiendum>
				<definiens id="0">measured by the conditional entropy : H ( p ) = ~p ( x</definiens>
			</definition>
			<definition id="9">
				<sentence>The posi1Nonterminal symbols include the ones for phrases , such as NP ( noun phrase ) and VP ( verb phrase ) , tion of a word is called segmentable position that can be a starting position of a specific segment .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">( verb phrase ) , tion of a word is called segmentable position that can be a starting position of a specific segment</definiens>
			</definition>
			<definition id="10">
				<sentence>The position value posi_v of the ith word wi is calculated as pos _v = r × R\ ] , where n is the number of words and R 2 represents the number of regions in the sentence .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of words and R 2 represents the number of regions in the sentence</definiens>
			</definition>
			<definition id="11">
				<sentence>Region is the sequentially ordered block of and the ones for clauses like RLCL ( relative clause ) , SUBCL ( subordinate clause ) .</sentence>
				<definiendum id="0">Region</definiendum>
				<definiens id="0">the sequentially ordered block of and the ones for clauses like RLCL ( relative clause )</definiens>
			</definition>
			<definition id="12">
				<sentence>sit is a heuristically set value , and we set R as 4 .</sentence>
				<definiendum id="0">sit</definiendum>
				<definiens id="0">a heuristically set value , and we set R as 4</definiens>
			</definition>
			<definition id="13">
				<sentence>166 words in a sentence , and posi_v represents the region in which a word lies .</sentence>
				<definiendum id="0">posi_v</definiendum>
				<definiens id="0">the region in which a word lies</definiens>
			</definition>
			<definition id="14">
				<sentence>The consistency is defined as 1 if ( Ci=aiorCi='*r ) foralll &lt; i &lt; n k = 0 otherwise The algorithm for generating lexical contextual constraints is shown in Figure 4. • Input : a set of active lexical contexts LCw = { lcl ... lcn } for word w , where lcc/= ( al , ... , an ) . • Output : a set of lexical contextual constraints LCCw = { /ccl ... /cck } , where lcc/= ( C1 , ... , Cn ) . ( a ) For all lcj ( j # i ) , Count ( lcj ) = # of matched attributes with Ic/ ( b ) max_cnt = arg maxlc¢ eLC. Count ( Icj ) ( c ) For all lcj , where Count ( lcj ) = max..cnt , Icc= lc~ • lc~ , LCCw eLCC , U { /cc } Figure 4 : Algorithm for generating lexical contextual constraints. A Icc plays the role of a feature. Following is an example of a feature. f ( x , y ) = 1 if Xward = `` that '' and xi-1 = `` say '' and y = 1 0 otherwise We collect the statistics for each Icc. The frequency of each lcc is counted as the number of lexical contexts that satisfy the consistency operation with the lcc. n i=1 167 Identifying segmentable positions is performed with the consistency operation with the lexical context of word w and lcc E LCCw. The word whose lexical context is consistent with lcc is identified as a segmentable position. Segmentation Positions Segmentation positions are determined through two steps : identifying segmentable positions and selecting the most appropriate position among them. Segmentable positions are identified using the consistency operation. Maximum entropy model in Section 2 gives a probability to each position. Segmentation performance is measured in terms of coverage and accuracy. Coverage is the ratio of the number of actually segmented sentences to the number of segmentation target sentences that are longer than ot words , where o~ is a fixed constant distinguishing long sentences from short ones. Accuracy is evaluated in terms of the safe segmentation ratio. They are defined as follows : # of actually segmented Sent. coverage = ~ of Sent. to be segmented ( 3 ) # of Sent. with safe segmentation accuracy = ~ of actually segmented Sent. ( a ) No contextual information is used in identifying segmentable positions. They are empirically identified. A word that is tagged as a segmentation position more than 5 times is identified as a segmentable position. A set of segmentable positions , 9 , is as follows. ~D = { wi \ [ wi is tagged as segmentation position and # ( tagged wi ) &gt; _ 5 } In order to select the most appropriate position , the segmentation appropriateness of each position is evaluated by the probability of word wi : # of tagged wi p ( Wi ) = # of wi in the corpus p ( wi ) represents the tendency that word wi will be used as a segmentation position .</sentence>
				<definiendum id="0">Output</definiendum>
				<definiendum id="1">... , Cn</definiendum>
				<definiendum id="2">o~</definiendum>
				<definiens id="0">1 if ( Ci=aiorCi='*r ) foralll &lt; i &lt; n k = 0 otherwise The algorithm for generating lexical contextual constraints is shown in Figure 4. • Input : a set of active lexical contexts LCw = { lcl ... lcn } for word w , where lcc/= ( al , ... , an ) . •</definiens>
				<definiens id="1">a set of lexical contextual constraints LCCw = { /ccl ... /cck } , where lcc/= ( C1 ,</definiens>
				<definiens id="2">lcj ) = # of matched attributes with Ic/ ( b ) max_cnt = arg maxlc¢ eLC. Count ( Icj ) ( c ) For all lcj , where Count ( lcj ) = max..cnt , Icc= lc~ • lc~ , LCCw eLCC , U { /cc } Figure 4 : Algorithm for generating lexical contextual constraints. A Icc plays the role of a feature. Following is an example of a feature. f ( x , y ) = 1 if Xward = `` that '' and xi-1 = `` say '' and y = 1 0 otherwise We collect the statistics for each Icc. The frequency of each lcc is counted as the number of lexical contexts that satisfy the consistency operation with the lcc. n i=1 167 Identifying segmentable positions is performed with the consistency operation with the lexical context of word w and lcc E LCCw. The word whose lexical context is consistent with lcc is identified as a segmentable position. Segmentation Positions Segmentation positions are determined through two steps : identifying segmentable positions and selecting the most appropriate position among them. Segmentable positions are identified using the consistency operation. Maximum entropy model in Section 2 gives a probability to each position. Segmentation performance is measured in terms of coverage and accuracy. Coverage is the ratio of the number of actually segmented sentences to the number of segmentation target sentences that are longer than ot words</definiens>
			</definition>
			<definition id="15">
				<sentence>The set of segmentable positions T~ is defined somewhat differently as : : D = { wi , wsj I ( Icc , v , -= lcc~ , ) = 1 or ( Icws~ =-IcC .</sentence>
				<definiendum id="0">segmentable positions</definiendum>
				<definiens id="0">D = { wi , wsj I ( Icc , v , -= lcc~ , ) = 1 or ( Icws~ =-IcC</definiens>
			</definition>
			<definition id="16">
				<sentence>ws~ ) = 1 } , where wsj denotes a word set to which the jth word in a sentence belongs .</sentence>
				<definiendum id="0">wsj</definiendum>
				<definiens id="0">a word set to which the jth word in a sentence belongs</definiens>
			</definition>
			<definition id="17">
				<sentence>After generating lexical contextual constraints , we constructed the maximum entropy model p ( ylx ) , where x is a lexical contextual constraint and y E { 0,1 } .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">a lexical contextual constraint and y E { 0,1 }</definiens>
			</definition>
</paper>

		<paper id="0728">
</paper>

		<paper id="1301">
			<definition id="0">
				<sentence>Below we provide the standard definition for regular expressions , and then define a less expressive language formafism , which we will refer to as reduced regular expressions .</sentence>
				<definiendum id="0">reduced regular expressions</definiendum>
				<definiens id="0">a less expressive language formafism</definiens>
			</definition>
			<definition id="1">
				<sentence>Regular Expression ( RE ) : 1 Given a finite alphabet E , the set of regular expressions over that alphabet is defined as ( Hopcroft and Ullman 1979 ) : ( 1 ) Va~ E , a is a regular expression and denotes the set { a } ( 2 ) if r and s are regular expressions denoting the languages R and S , respectively , then ( r+s ) , ( rs ) , and ( r* ) are regular expressions that denote the sets R ~_~ S , RS and R* respectively .</sentence>
				<definiendum id="0">Regular Expression</definiendum>
				<definiendum id="1">RE</definiendum>
				<definiens id="0">the set of regular expressions over that alphabet is defined as ( Hopcroft and Ullman 1979 ) : ( 1 ) Va~ E , a is a regular expression and denotes the set { a } ( 2 ) if r and s are regular expressions denoting the languages R and S , respectively , then ( r+s ) , ( rs ) , and ( r* ) are regular expressions that denote the sets R ~_~ S , RS and R* respectively</definiens>
			</definition>
			<definition id="2">
				<sentence>Reduced Regular Expression ( R.RE ) : Given a finite alphabet ~ , the set of reduced regular expressions over that alphabet is defined as : ( 1 ) Va~ E : a is an RRE and denotes the set { a } a+ is an RRE and denotes the positive closure of the set { a } a* is an RRE and denotes the Kleene closure of the set { a } -a is an RRE and denotes the set ~ a ~a+ is an RRE and denotes the positive closure of the set Z a ~a* is an RRE and denotes the Kleene closure of the set E a ( 2 ) .</sentence>
				<definiendum id="0">Reduced Regular Expression ( R.RE )</definiendum>
				<definiens id="0">Given a finite alphabet ~ , the set of reduced regular expressions over that alphabet is defined as : ( 1 ) Va~ E : a is an RRE and denotes the set { a } a+ is an RRE and denotes the positive closure of the set { a } a* is an RRE and denotes the Kleene closure of the set { a } -a is an RRE and denotes the set ~ a ~a+ is an RRE and denotes the positive closure of the set Z a ~a* is an RRE and denotes the Kleene closure of the set E a ( 2 )</definiens>
			</definition>
			<definition id="3">
				<sentence>Corpus : A corpus is an ordered set of strings .</sentence>
				<definiendum id="0">Corpus</definiendum>
				<definiens id="0">A corpus is an ordered set of strings</definiens>
			</definition>
			<definition id="4">
				<sentence>A corpus position for a corpus C is a tuple ( j , k ) , meaning the k th symbol in the jtb string in the corpus , with the restrictions : 1 _ &lt; j _ &lt; \ [ C\ [ and 0 _ &lt; k _ &lt; \ [ CU\ ] \ [ .</sentence>
				<definiendum id="0">corpus position</definiendum>
				<definiens id="0">a tuple ( j , k ) , meaning the k th symbol in the jtb string in the corpus , with the restrictions : 1 _ &lt; j _ &lt; \ [ C\ [ and 0 _ &lt; k _ &lt; \ [ CU\ ] \ [</definiens>
			</definition>
			<definition id="5">
				<sentence>A Corpus Position Set is a set of corpus positions .</sentence>
				<definiendum id="0">Corpus Position Set</definiendum>
				<definiens id="0">a set of corpus positions</definiens>
			</definition>
			<definition id="6">
				<sentence>RRE-Tree : An RRE-Tree over E is a tree ( V , E ) , where V is a set of tuples &lt; v , S &gt; , v being a unique vertex identifier and S being a Corpus Position Set , and E is a set of labeled directed edges &lt; vi , vj , label &gt; , where vi and vj are vertex identifiers , label ~ LABEL_SET and LABEL SET = { dot , dot+ , dot* } U { a , a+ , a* , ~a , ~a+ , ~a* I 'Va ~ E } .2 Our implemented learner is based upon the transformation-based learning paradigm ( Bnll 1995 ) .</sentence>
				<definiendum id="0">RRE-Tree</definiendum>
				<definiendum id="1">V</definiendum>
				<definiendum id="2">E</definiendum>
				<definiens id="0">An RRE-Tree over E is a tree ( V , E ) , where</definiens>
				<definiens id="1">a set of tuples &lt; v , S &gt; , v being a unique vertex identifier and S being a Corpus Position Set , and</definiens>
				<definiens id="2">a set of labeled directed edges &lt; vi , vj , label &gt;</definiens>
			</definition>
			<definition id="7">
				<sentence>2 ( 1 ) A start-state annotator , which assigns an initial label to a string .</sentence>
				<definiendum id="0">start-state annotator</definiendum>
				<definiens id="0">assigns an initial label to a string</definiens>
			</definition>
			<definition id="8">
				<sentence>( 2 ) A sequence of rules of the form : Change the label of a string from m to n if C ( string ) , where C is a predicate over strings and m , n ~ L. A string is labelled by first applying the start-state annotator to it , and then applying each rule , in order .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">a predicate over strings</definiens>
			</definition>
			<definition id="9">
				<sentence>Very Reduced Regular Expression ( VRRE ) : Given a finite alphabet E , the set of very reduced regular expressions over that alphabet is defined as : ( 1 ) 'v'a~ E : a is a VRRE and denotes the set { a } ( 2 ) .</sentence>
				<definiendum id="0">Very Reduced Regular Expression ( VRRE )</definiendum>
				<definiens id="0">Given a finite alphabet E , the set of very reduced regular expressions over that alphabet is defined as : ( 1 ) 'v'a~ E : a is a VRRE and denotes the set { a } ( 2 )</definiens>
			</definition>
			<definition id="10">
				<sentence>The root node corresponds to the null RRE , and so the position set consists of the beginning of each string in the training set .</sentence>
				<definiendum id="0">position set</definiendum>
				<definiens id="0">the beginning of each string in the training set</definiens>
			</definition>
			<definition id="11">
				<sentence>Define GoodPotential 0 to I ( S ) as the number of sentences s in the training corpus for which Guess\ [ s\ ] =0 , Truth\ [ s\ ] = 1 and 3k : ( s , k ) ~ corpus_position_set ( S ) .</sentence>
				<definiendum id="0">GoodPotential</definiendum>
				<definiens id="0">the number of sentences s in the training corpus for which Guess\ [ s\ ] =0</definiens>
			</definition>
			<definition id="12">
				<sentence>We can similarly define GoodPotential 1 to0 ( S ) , and then define GoodPotential ( S ) = max ( GoodPotential 0 to_l ( S ) , GoodPotential 1 to O ( S ) ) As we construct the RRE-tree , we keep track of the largest Goodness ( S ) we have encountered .</sentence>
				<definiendum id="0">GoodPotential ( S )</definiendum>
				<definiens id="0">max ( GoodPotential 0 to_l ( S )</definiens>
			</definition>
			<definition id="13">
				<sentence>If that value is X , then for a state S ' , if GoodPotential ( S ' ) _ &lt; X , it is impossible for any path through S ' to reach a state with a better goodness score than the best found thus far. We can check this condition when pushing states onto the stack , and when popping off the stack to be processed , and if the pruning condition is met , the state is discarded. Optimization 2 : Merging states with identical corpus position sets. If we are going to push a state onto the stack when a state already exists with an identical corpus position set , we do not need to retain both states. We may use heuristics to decide which of the states with identical corpus position sets we should keep ( such as choosing the one with the shortest path to the root ) . To test whether learning RREs can improve disambiguafion accuracy , we explored the task of confusion set disambiguation ( Golding and Roth 1999 ) . We trained and applied two different rule sequence learners , one which used the standard feature set for this problem ( e.g. the identical feature set to that used in ( Golding and Roth 1999 ) and ( Mangu and Brill 1997 ) and described in the introduction , and one which learned RR.Es. 4 Because we wanted to deterinine what could be gained by using RREs , we ran an ablation study where we kept everything else constant across the two runs , and did not use performance enhancing techniques such as parameter tuning on held out data or classifier combination. Both learners were given a window of +/5 words surrounding the ambiguity site. Context was not allowed to cross sentence boundaries. The training and test set were derived by finding all instances of the confusable words in the Brown Corpus , using the Penn Treebank parts of speech and tokenization ( Marcus , Santorini et al. 1993 ) , and then dividing this set into 80 % for training and 20 % for testing. For the RRE-based system , we mapped the +/5 word window of context into a string as follows ( where wi is a word and ti is a part of speech tag ) : learned using the standard feature set. 5 Wi. 5 ti. 5 Wi-4 ti. 4 Wi. 3 ti. 3 Wi. 2 ti.2. Wi. I ti. 1 MIDDLE Wi+l ti+l wi+2 ti+2 wi+3 ti+3 wi+4 ti+4 wi+5 ti+5 where MIDDLE is the ambiguity site. Both for execution time and space considerations for the learner and for fear of overtraining , we put a bound on the length of the RRE that could be learned , s We define an atomic RRE as any RRE derived without any concatenation operations. Then the length of an RRE is defined as the number of atomic RREs which that RRE is made up of. The atom `` MIDDLE '' is not counted in length. Below we give two examples of rules that were learned for one confusion set : 6 ( 1 ) past ~ passed if .* ~DT MIDDLE DOT IN ( 2 ) past ~ passed if ( ~to ) * NN MIDDLE The first rule says to change the disambiguation guess to &lt; &lt; passed &gt; &gt; if the word before is not a determiner and the word after is a preposition .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">GoodPotential</definiendum>
				<definiendum id="2">ti</definiendum>
				<definiendum id="3">MIDDLE</definiendum>
				<definiendum id="4">RRE</definiendum>
				<definiens id="0">impossible for any path through S ' to reach a state with a better goodness score than the best found thus far. We can check this condition when pushing states onto the stack , and when popping off the stack to be processed , and if the pruning condition is met , the state is discarded. Optimization 2 : Merging states with identical corpus position sets. If we are going to push a state onto the stack when a state already exists with an identical corpus position set , we do not need to retain both states. We may use heuristics to decide which of the states with identical corpus position sets we should keep ( such as choosing the one with the shortest path to the root ) . To test whether learning RREs can improve disambiguafion accuracy , we explored the task of confusion set disambiguation ( Golding and Roth 1999 ) . We trained and applied two different rule sequence learners , one which used the standard feature set for this problem ( e.g. the identical feature set to that used in ( Golding and Roth 1999 ) and ( Mangu and Brill 1997 ) and described in the introduction , and one which learned RR.Es. 4 Because we wanted to deterinine what could be gained by using RREs , we ran an ablation study where we kept everything else constant across the two runs , and did not use performance enhancing techniques such as parameter tuning on held out data or classifier combination. Both learners were given a window of +/5 words surrounding the ambiguity site. Context was not allowed to cross sentence boundaries. The training and test set were derived by finding all instances of the confusable words in the Brown Corpus , using the Penn Treebank parts of speech and tokenization ( Marcus , Santorini et al. 1993 ) , and then dividing this set into 80 % for training and 20 % for testing. For the RRE-based system , we mapped the +/5 word window of context into a string as follows ( where wi is a word and</definiens>
				<definiens id="1">a part of speech tag</definiens>
				<definiens id="2">the ambiguity site. Both for execution time and space considerations for the learner and for fear of overtraining , we put a bound on the length of the RRE that could be learned , s We define an atomic RRE as any RRE derived without any concatenation operations. Then the length of an</definiens>
				<definiens id="3">the number of atomic RREs which that RRE is made up of. The atom `` MIDDLE '' is not counted in length. Below we give two examples of rules that were learned for one confusion set : 6 ( 1 ) past ~ passed if .* ~DT MIDDLE DOT IN ( 2 ) past ~ passed if ( ~to ) * NN MIDDLE The first rule says to change the disambiguation guess to &lt; &lt; passed &gt; &gt; if the word before is not a determiner and the word after is a preposition</definiens>
			</definition>
			<definition id="14">
				<sentence>Grammatical Inference : Learning Syntax from Sentences .</sentence>
				<definiendum id="0">Grammatical Inference</definiendum>
			</definition>
</paper>

		<paper id="1316">
			<definition id="0">
				<sentence>Each participant is to return a ranked list of the five best answer strings for each question , where each answer string is a string of 50 bytes ( or 250 bytes ) that contains an answer to the question .</sentence>
				<definiendum id="0">answer string</definiendum>
				<definiens id="0">a string of 50 bytes ( or 250 bytes ) that contains an answer to the question</definiens>
			</definition>
			<definition id="1">
				<sentence>Each story has an average of 20 sentences , and the question answering task as formulated for a computer program is to select a sentence in the story that answers to a question .</sentence>
				<definiendum id="0">question answering task</definiendum>
				<definiens id="0">to select a sentence in the story that answers to a question</definiens>
			</definition>
			<definition id="2">
				<sentence>Also , an answer as defined in the TREC-8 QA task is a 50-byte or 250byte answer string , whereas an answer is a complete sentence in the reading comprehension task .</sentence>
				<definiendum id="0">answer</definiendum>
				<definiendum id="1">answer</definiendum>
				<definiens id="0">a 50-byte or 250byte answer string</definiens>
				<definiens id="1">a complete sentence in the reading comprehension task</definiens>
			</definition>
			<definition id="3">
				<sentence>To compute these feature values for a sentence , we used the Remedia corpus provided by MITRE which has been hand-tagged with named entities .</sentence>
				<definiendum id="0">Remedia corpus</definiendum>
				<definiens id="0">hand-tagged with named entities</definiens>
			</definition>
			<definition id="4">
				<sentence>+ + N~- ) CN , + + N , _ ) ( N.+ + N , + ) 0V , + g , - ) where Nr+ ( Nn+ ) is the number of training story sentences that answer ( do not answer ) to the question type and in which the word w occurs , and Nr_ ( Nn_ ) is the number of training story sentences that answer ( do not answer ) to the question type and in which the word w does not occur .</sentence>
				<definiendum id="0">Nr+</definiendum>
				<definiens id="0">the number of training story sentences that answer ( do not answer ) to the question type and in which the word w occurs , and Nr_ ( Nn_ ) is the number of training story sentences that answer ( do not answer ) to the question type and in which the word</definiens>
			</definition>
			<definition id="5">
				<sentence>Note that the correlation metric C is the square root of the X 2 metric .</sentence>
				<definiendum id="0">correlation metric C</definiendum>
				<definiens id="0">the square root of the X 2 metric</definiens>
			</definition>
			<definition id="6">
				<sentence>The method is the same as what we used to discover the keywords in sentences , except that Nr+ ( Nn+ ) is the number of training story questions that have ( do not have ) dateline as an answer to the question , and in which the word w occurs , and Nr ( Nn- ) is the number of training story questions that have ( do not have ) dateline as an answer to the question and in which the word w does not occur .</sentence>
				<definiendum id="0">Nr ( Nn- )</definiendum>
				<definiens id="0">the number of training story questions that have</definiens>
			</definition>
			<definition id="7">
				<sentence>AQUAREAS breaks ties in favor of the sentence appearing earlier in the story .</sentence>
				<definiendum id="0">AQUAREAS</definiendum>
				<definiens id="0">breaks ties in favor of the sentence appearing earlier in the story</definiens>
			</definition>
			<definition id="8">
				<sentence>The training set consists of 28 stories from grade 2 and 27 stories from grade 5 .</sentence>
				<definiendum id="0">training set</definiendum>
			</definition>
			<definition id="9">
				<sentence>The test set consists of 30 stories from grade 3 and 30 stories from grade 4 .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of 30 stories from grade 3 and 30 stories from grade 4</definiens>
			</definition>
</paper>

		<paper id="1315">
			<definition id="0">
				<sentence>The column labeled idf is the mean idf for the terms in each bin .</sentence>
				<definiendum id="0">idf</definiendum>
				<definiens id="0">the mean idf for the terms in each bin</definiens>
			</definition>
			<definition id="1">
				<sentence>idf ( t ) tET Under the probabilistic retrieval model , documents are scored by summing a similar contribution for each term t. = ~ l P ( tJrel ) In this work , we use A to refer to term weights .</sentence>
				<definiendum id="0">idf ( t ) tET Under</definiendum>
				<definiens id="0">the probabilistic retrieval model</definiens>
			</definition>
			<definition id="2">
				<sentence>with tf ( t , d ) &gt; 1 ~re t is an estimate of the total number of relevant where : D ( description ) , E ( query expansion ) documents .</sentence>
				<definiendum id="0">tf</definiendum>
				<definiens id="0">an estimate of the total number of relevant where : D ( description ) , E ( query expansion ) documents</definiens>
			</definition>
			<definition id="3">
				<sentence>The estimation method starts with a training file which indicates , among other things , the number of relevant and irrelevant documents for each term t in each training query , q. That is , for each t and q , we are are given dr ( t , rel , tfo ) and dr ( t , tel , tfo ) , where dr ( t , tel , tfo ) is the number of relevant documents d with tf ( t , d ) = tfo , and df ( t , rel , tfo ) is the number of irrelevant documents d with tf ( t , d ) = tfo .</sentence>
				<definiendum id="0">dr</definiendum>
				<definiendum id="1">df</definiendum>
				<definiendum id="2">tfo )</definiendum>
				<definiens id="0">the number of relevant documents d with tf</definiens>
			</definition>
			<definition id="4">
				<sentence>~ _ dr ( bin , rel , t f ) P ( bin , triter ) ~ togs Nrel vant documents than others , N~t is computed by averaging : 1 tEbin To ensure that Nr~l + ~ '' ~/= N , where N is the number of documents in the collection , we define This estimation procedure is implemented with the simple awk program in figure 2 .</sentence>
				<definiendum id="0">N~t</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the number of documents in the collection</definiens>
			</definition>
			<definition id="5">
				<sentence>Kwok ( 1996 ) suggested average term frequency , avtf = TF ( t ) /df ( t ) , be used as a tie-breaker for cases like this , where TF ( t ) = ~a if ( t , d ) is the standard notion of frequency in the corpus-based NLP .</sentence>
				<definiendum id="0">average term frequency</definiendum>
				<definiens id="0">avtf = TF ( t ) /df ( t )</definiens>
			</definition>
			<definition id="6">
				<sentence>Two measures of performance are reported : ( 1 ) 11 point average precision and ( 2 ) R , precision after retrieving Nrd documents , where Nrd is the number of relevant documents .</sentence>
				<definiendum id="0">Nrd</definiendum>
				<definiens id="0">the number of relevant documents</definiens>
			</definition>
</paper>

		<paper id="1325">
			<definition id="0">
				<sentence>Research `` into the automatic acquisition of subcategorization frames ( SCFS ) from corpora is starting to produce large-scale computational lexicons which include valuable frequency information .</sentence>
				<definiendum id="0">SCFS</definiendum>
				<definiens id="0">starting to produce large-scale computational lexicons which include valuable frequency information</definiens>
			</definition>
			<definition id="1">
				<sentence>The SCFs are a superset of classes found in the Alvey NL Tools ( ANLT ) dictionary , Boguraev et al. ( 1987 ) and the COML~X Syntax dictionary , Grishman et al. ( 1994 ) .</sentence>
				<definiendum id="0">SCFs</definiendum>
				<definiens id="0">a superset of classes found in the Alvey NL Tools ( ANLT ) dictionary</definiens>
			</definition>
			<definition id="2">
				<sentence>pro ( 1 _p ) n-m ( 2 ) The probability of the event happening m or more times is : = ( 3 ) k=rn Finally , P ( m+ , n , p e ) is the probability that m or more occurrences of cues for scfi will occur with a verb which is not a member ofscfi , given n occurrences of that verb .</sentence>
				<definiendum id="0">P ( m+</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">p e )</definiendum>
				<definiens id="0">the probability that m or more occurrences of cues for scfi will occur with a verb which is not a member ofscfi , given n occurrences of that verb</definiens>
			</definition>
			<definition id="3">
				<sentence>Brent ( 1993 ) estimated the error probabilities for each SCF experimentally from the behaviour of his SCF extractor , which detected simple morpho-syntactic cues in the corpus data .</sentence>
				<definiendum id="0">SCF extractor</definiendum>
				<definiens id="0">detected simple morpho-syntactic cues in the corpus data</definiens>
			</definition>
			<definition id="4">
				<sentence>Following Briscoe and Carroll ( 1997 ) , we calculated precision ( percentage of SCFS acquired which were also exemplified in the manual analysis ) and recall ( percentage of the SCFs exemplified in the manual analysis which were acquired automatically ) .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">percentage of SCFS acquired which were also exemplified in the manual analysis</definiens>
				<definiens id="1">percentage of the SCFs exemplified in the manual analysis which were acquired automatically</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>The degree expression SPACE , with its associated negative POL -- MARKER , ( Staab and Hahn , 1997 ) is the trigger for recognizing the evaluative status of the matrix clause .</sentence>
				<definiendum id="0">SPACE</definiendum>
				<definiens id="0">the trigger for recognizing the evaluative status of the matrix clause</definiens>
			</definition>
			<definition id="1">
				<sentence>But actually the situation HAS-PART-STATE is a state in which only one is present , which is obviously `` little '' .</sentence>
				<definiendum id="0">situation HAS-PART-STATE</definiendum>
				<definiens id="0">a state in which only one is present</definiens>
			</definition>
			<definition id="2">
				<sentence>In the simplest case , the relation is one of Elaboration .</sentence>
				<definiendum id="0">relation</definiendum>
				<definiens id="0">one of Elaboration</definiens>
			</definition>
			<definition id="3">
				<sentence>51 tree : = tree ( centers_forward ( first ( clauses ) ) , NIL ) clauses : = rest ( clauses ) forall clause : = clauses do ana_nodes : = array of lists of nodes .</sentence>
				<definiendum id="0">centers_forward</definiendum>
				<definiens id="0">clauses ) forall clause : = clauses do ana_nodes : = array of lists of nodes</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>The anaphora resolution algorithm for third person singular neuter personal pronouns is the following ( Eckert and Strube , 1999a ) : case PRO is I-incompatible if resolveDiscourseDeictic ( P RO ) then classify as discourse deictic else classify as vague pronoun ; case PRO is A-incompatible if resolveIndividual ( PRO ) then classify as individual pronoun else classify as vague pronoun ; case PRO is ambiguous if resolveIndividual ( PRO ) then classify as individual pronoun else if resolveDiscourseDeictic ( PRO ) then classify as discourse deictic else classify as vague pronoun ; The same algorithm is used for demonstratives , with the exception that the last two if constructions in the algorithm for pronouns are reversed reflecting the preference for demonstratives to be discourse deictics ( Webber , 1991 ) .</sentence>
				<definiendum id="0">PRO</definiendum>
				<definiendum id="1">PRO</definiendum>
				<definiens id="0">I-incompatible if resolveDiscourseDeictic ( P RO ) then classify as discourse deictic else classify as vague pronoun ; case</definiens>
				<definiens id="1">A-incompatible if resolveIndividual ( PRO ) then classify as individual pronoun else classify as vague pronoun ; case</definiens>
				<definiens id="2">discourse deictic else classify as vague pronoun</definiens>
			</definition>
			<definition id="1">
				<sentence>12 On the basis of the deictics in the two Danish dialogue corpora , SL and PID I have established the following *I predicates for Danish : constructions where a pronoun is equated with an abstract object , e.g. , x er et forslag ( x is a suggestion ) copula constructions with adjectives which can only be applied to abstract entities , such as x er sandt ( x is true ) , x er usandt ( x is untrue ) , x er rigtigt ( x is correct ) arguments of verbs which take S'complements , e.g. , fro ( believe ) , antage ( ass-me ) , mene ( think ) , sige ( say ) anaphoric referent in constructions such as x er /ordi du er holdt op reed at ryge ( x is because you have stopped smoking ) x er pd grund af at duer gravid ( x is because you are pregnant ) • object of g # re ( do ) * subject complement with vmre ( be ) and blive ( become ) in answers 12I have not included in the description cataphoric deictic pronouns .</sentence>
				<definiendum id="0">x</definiendum>
				<definiendum id="1">antage</definiendum>
				<definiens id="0">a suggestion ) copula constructions with adjectives which can only be applied to abstract entities , such as x er sandt ( x is true ) , x er usandt</definiens>
			</definition>
			<definition id="2">
				<sentence>I have assumed the following *A predicates , which are mainly ' translations of the English ones : • constructions where a pronominal referent is equated with a concrete individual referent , such as x er en legemsdel ( x is a body part ) , x er et barn ( x is a baby ) • copula constructions with adjectives which can only be applied to concrete entities , such as x er rcdt ( x is red ) • arguments of verbs describing physical contact/stimulation , which can not be used anaphorically , e.g. spise x ( eat x ) , drikke x ( drink x ) As Eckert and Strube notice for English , also in Danish there are cases where the contexts of an anaphor can allow both an individual NP and an abstract object .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">a body part )</definiens>
				<definiens id="1">a baby ) • copula constructions with adjectives which can only be applied to concrete entities</definiens>
			</definition>
</paper>

		<paper id="1430">
			<definition id="0">
				<sentence>We use TG/2 , a rule-based engine that covers the continuum between templates and syntactic generation ( Busemann , 1996 ) .</sentence>
				<definiendum id="0">TG/2</definiendum>
				<definiens id="0">a rule-based engine that covers the continuum between templates and syntactic generation</definiens>
			</definition>
			<definition id="1">
				<sentence>Corpus analysis ( Rats , 1996 ) confirms the existence of a mechanism called topic , through which interlocutors strive at discourse coherence to reduce the cognitive effort of the hearer .</sentence>
				<definiendum id="0">Corpus analysis</definiendum>
				<definiens id="0">confirms the existence of a mechanism called topic , through which interlocutors strive at discourse coherence to reduce the cognitive effort of the hearer</definiens>
			</definition>
			<definition id="2">
				<sentence>Focus is the unpredictable part of tile utterance .</sentence>
				<definiendum id="0">Focus</definiendum>
				<definiens id="0">the unpredictable part of tile utterance</definiens>
			</definition>
</paper>

		<paper id="0502">
			<definition id="0">
				<sentence>This method allows for a prediction of how useful a particular system can be in a text-handling process stream , whether in integrated , MTembedded processes , or less integrated userintensive processes .</sentence>
				<definiendum id="0">MTembedded</definiendum>
				<definiens id="0">processes , or less integrated userintensive processes</definiens>
			</definition>
			<definition id="1">
				<sentence>Each document identification code includes a document number followed by the code of the MT system that produced it ( MT system codes can be found in the Corpus Composition section above ) .</sentence>
				<definiendum id="0">document identification code</definiendum>
			</definition>
			<definition id="2">
				<sentence>Recall was calculated by the number of possible named entities in a translation the user identified .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">calculated by the number of possible named entities in a translation the user identified</definiens>
			</definition>
			<definition id="3">
				<sentence>Precision was calculated by the number of items the user identified as being named entities that were actually named entities .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">calculated by the number of items the user identified as being named entities that were actually named entities</definiens>
			</definition>
			<definition id="4">
				<sentence>The pre-existing scale can help to resolve ambiguous results , or can be used to make scale-wide inferences from a subset of the exercises : it may be possible to perform just one exercise ( e.g. , triage ) and infer the actual position of the system on the scale by the degree of acceptability above or below the mlmmum acceptability for triage itself .</sentence>
				<definiendum id="0">infer</definiendum>
				<definiens id="0">the actual position of the system on the scale by the degree of acceptability above or below the mlmmum acceptability for triage itself</definiens>
			</definition>
</paper>

		<paper id="1212">
			<definition id="0">
				<sentence>3 , block-based dependency analysis consists of four modules , i.e. , word segmentation , part-of-speech tagging , block analysis and dependency analysis .</sentence>
				<definiendum id="0">block-based dependency analysis</definiendum>
				<definiens id="0">consists of four modules , i.e. , word segmentation , part-of-speech tagging , block analysis and dependency analysis</definiens>
			</definition>
			<definition id="1">
				<sentence>The block-based dependency parsing strategy is a novel integration of phrase structure partial approach and dependency parsing approach .</sentence>
				<definiendum id="0">block-based dependency parsing strategy</definiendum>
				<definiens id="0">a novel integration of phrase structure partial approach and dependency parsing approach</definiens>
			</definition>
</paper>

		<paper id="0408">
			<definition id="0">
				<sentence>Content-based measures increase the correlation of rankings induced by synonymous ground truths , and exhibit other desirable properties .</sentence>
				<definiendum id="0">Content-based measures</definiendum>
				<definiens id="0">increase the correlation of rankings induced by synonymous ground truths , and exhibit other desirable properties</definiens>
			</definition>
			<definition id="1">
				<sentence>The ranks assigned by an evaluation measure produce equivalence classes of extract summaries ; each rank equivalence class contains summaries which received the same score .</sentence>
				<definiendum id="0">rank equivalence class</definiendum>
				<definiens id="0">contains summaries which received the same score</definiens>
			</definition>
			<definition id="2">
				<sentence>With each of these pieces , Mr. Zuckerman takes over the movie and shows what it means to play his instrument with supreme dash .</sentence>
				<definiendum id="0">Mr. Zuckerman</definiendum>
				<definiens id="0">takes over the movie and shows what it means to play his instrument with supreme dash</definiens>
			</definition>
			<definition id="3">
				<sentence>LSI is a method of reducing the dimension of the vector space model using the singular value decomposition .</sentence>
				<definiendum id="0">LSI</definiendum>
				<definiens id="0">a method of reducing the dimension of the vector space model using the singular value decomposition</definiens>
			</definition>
			<definition id="4">
				<sentence>'There is wide variation in the rankings produced by recall scores from non-identical ground truths .</sentence>
				<definiendum id="0">'There</definiendum>
				<definiens id="0">wide variation in the rankings produced by recall scores from non-identical ground truths</definiens>
			</definition>
			<definition id="5">
				<sentence>Content-based measures assign different rankings when ground truths do disagree in focus .</sentence>
				<definiendum id="0">Content-based measures</definiendum>
				<definiens id="0">assign different rankings when ground truths do disagree in focus</definiens>
			</definition>
</paper>

		<paper id="1210">
			<definition id="0">
				<sentence>MBL entails a classification based supervised learning approach .</sentence>
				<definiendum id="0">MBL</definiendum>
				<definiens id="0">entails a classification based supervised learning approach</definiens>
			</definition>
			<definition id="1">
				<sentence>IG-Tree is a compressed representation of the training set that can be processed quickly in classification process .</sentence>
				<definiendum id="0">IG-Tree</definiendum>
				<definiens id="0">a compressed representation of the training set that can be processed quickly in classification process</definiens>
			</definition>
			<definition id="2">
				<sentence>The main dependency relations include verb-object ( the relation between a verb and its noun object ) , subject-verb ( the relation between a verb and its subject ) , subject-adj ( the relation between an adjective and its subject ) , adv-verb ( the relation between a verb and its adverbial modifier ) , adv-adj ( the relation between an adjective and its adverbial modifier ) , modifier-head ( the relation between a noun and its modifier .</sentence>
				<definiendum id="0">verb-object</definiendum>
				<definiendum id="1">modifier-head</definiendum>
				<definiens id="0">the relation between a verb and its noun object ) , subject-verb ( the relation between a verb and its subject )</definiens>
				<definiens id="1">the relation between a verb and its adverbial modifier</definiens>
				<definiens id="2">the relation between an adjective and its adverbial modifier</definiens>
			</definition>
			<definition id="3">
				<sentence>Their differences lie in that • MBL is a lazy learning algorithm that keeps all training data in memory and only abstracts at classification time by extrapolating a class from the most similar items in memory , therefore , its time complexity is much lower than C4.5 , especially when training data contains large number of features and examples .</sentence>
				<definiendum id="0">MBL</definiendum>
				<definiens id="0">a lazy learning algorithm that keeps all training data in memory and only abstracts at classification time by extrapolating a class from the most similar items in memory</definiens>
				<definiens id="1">much lower than C4.5 , especially when training data contains large number of features and examples</definiens>
			</definition>
</paper>

		<paper id="1220">
			<definition id="0">
				<sentence>Tense describes the relations between an event ( E ) , reference time ( R ) and speaking time ( S ) .</sentence>
				<definiendum id="0">Tense</definiendum>
				<definiens id="0">describes the relations between an event ( E ) , reference time ( R ) and speaking time ( S )</definiens>
			</definition>
			<definition id="1">
				<sentence>eln linguistics , telicity is a phase feature used in classifying .</sentence>
				<definiendum id="0">telicity</definiendum>
				<definiens id="0">a phase feature used in classifying</definiens>
			</definition>
</paper>

		<paper id="0903">
			<definition id="0">
				<sentence>Although , the target of our work ( Ruch and al. , 1999 , Bouillon and al. , 2000 ) is a free-grained semantic disambiguation of medical texts for IR purposes , we believe that the POS disambiguation is an important preliminary step .</sentence>
				<definiendum id="0">disambiguation</definiendum>
				<definiens id="0">a free-grained semantic disambiguation of medical texts for IR purposes</definiens>
			</definition>
			<definition id="1">
				<sentence>In parallel , we chose three types of medical texts to make up the medical corpus : it represents 16024 tokens , with 3 equal thirds : discharge summaries , surgical reports , and laboratory or test results ( in this case , tables were removed ) .</sentence>
				<definiendum id="0">medical corpus</definiendum>
				<definiens id="0">it represents 16024 tokens , with 3 equal thirds : discharge summaries , surgical reports , and laboratory or test results ( in this case , tables were removed )</definiens>
			</definition>
			<definition id="2">
				<sentence>The FIPSTAG lexicon is a general French lexicon , therefore it contains most well-formed French words .</sentence>
				<definiendum id="0">FIPSTAG lexicon</definiendum>
				<definiens id="0">a general French lexicon , therefore it contains most well-formed French words</definiens>
			</definition>
</paper>

		<paper id="1424">
			<definition id="0">
				<sentence>The present paper demonstrates how a Natural Language Generation ( NLG ) program can be enabled to -generate uniquely referring descriptions containing one gradable adjective , despite the vagueness of the adjective .</sentence>
				<definiendum id="0">present paper</definiendum>
				<definiens id="0">demonstrates how a Natural Language Generation</definiens>
			</definition>
			<definition id="1">
				<sentence>We will take them to be of the form n crn , where n is a positive natural number .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a positive natural number</definiens>
			</definition>
			<definition id="2">
				<sentence>An experimental ProFIT ( Erbach 1995 ) program has implemented the algorithms described so far , generating different descriptions , each of which would allow a reader/hearer to identify an object or a set of objects .</sentence>
				<definiendum id="0">experimental ProFIT</definiendum>
				<definiens id="0">allow a reader/hearer to identify an object or a set of objects</definiens>
			</definition>
			<definition id="3">
				<sentence>Appendix : A Supporting Experiment Human subjects were asked to judge the correctness of an utterance in a variety of situations .</sentence>
				<definiendum id="0">Appendix</definiendum>
				<definiens id="0">A Supporting Experiment Human subjects were asked to judge the correctness of an utterance in a variety of situations</definiens>
			</definition>
			<definition id="4">
				<sentence>Hypothesis ( = &gt; ) : In a situation in which the domain D represents the set of perceptually relevant objects , an expression of the form 'the n large CN ' ( where n 2 2 1 ) , can be used to refer to a set S of cardinality n if all objects in D S are smaller than anv of the n..</sentence>
				<definiendum id="0">Hypothesis</definiendum>
				<definiens id="0">the set of perceptually relevant objects , an expression of the form 'the n large CN '</definiens>
			</definition>
</paper>

		<paper id="0407">
			<definition id="0">
				<sentence>To avoid the burden of reading such long and complex sentences , we have developed the phrase-representation summarization method , which represents the outline of a document by a series of short and simple expressions ( `` phrases '' ) that contain key concepts .</sentence>
				<definiendum id="0">phrase-representation summarization method</definiendum>
				<definiens id="0">represents the outline of a document by a series of short and simple expressions ( `` phrases '' ) that contain key concepts</definiens>
			</definition>
			<definition id="1">
				<sentence>Task-based evaluation in general consists of the following three steps : ( l ) Data preparation : Assume an information need , create a query for the information need , and prepare simulated search results with different types of summaries .</sentence>
				<definiendum id="0">Task-based evaluation</definiendum>
				<definiens id="0">consists of the following three steps : ( l ) Data preparation : Assume an information need , create a query for the information need , and prepare simulated search results with different types of summaries</definiens>
			</definition>
			<definition id="2">
				<sentence>The F-measure is the balanced score of precision and recall , calculated as follows : 2 * precision * recall `` F-measure = precision + recall Figures 4 and 5 show that the phraserepresented summary ( C ) presents the highest performance .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiens id="0">the balanced score of precision and recall , calculated as follows : 2 * precision * recall `` F-measure = precision + recall</definiens>
			</definition>
			<definition id="3">
				<sentence>The time for Question-a is a sum of the times for Questions al and a2 .</sentence>
				<definiendum id="0">time for Question-a</definiendum>
				<definiens id="0">a sum of the times for Questions al and a2</definiens>
			</definition>
			<definition id="4">
				<sentence>Also Kanji is a kind of ideogram and each character has its own meaning .</sentence>
				<definiendum id="0">Kanji</definiendum>
				<definiens id="0">a kind of ideogram and each character has its own meaning</definiens>
			</definition>
</paper>

		<paper id="1203">
			<definition id="0">
				<sentence>The knowledge extraction process utilizes the structure property , statistical property as well as partial linguistic knowledge of the organization names to extract new organizations from domain texts .</sentence>
				<definiendum id="0">knowledge extraction process</definiendum>
				<definiens id="0">utilizes the structure property , statistical property as well as partial linguistic knowledge of the organization names to extract new organizations from domain texts</definiens>
			</definition>
			<definition id="1">
				<sentence>Each Chinese morpheme ( usually a single character ) carries meanings and most arc polyscmous .</sentence>
				<definiendum id="0">Chinese morpheme</definiendum>
				<definiens id="0">a single character ) carries meanings and most arc polyscmous</definiens>
			</definition>
			<definition id="2">
				<sentence>New words are easily constructed by combining morphemes and their meanings are the semantic composition of morpheme components .</sentence>
				<definiendum id="0">meanings</definiendum>
				<definiens id="0">the semantic composition of morpheme components</definiens>
			</definition>
			<definition id="3">
				<sentence>For the keywords of length 3,4 , and 5 , each keyword is divided into two parts X and Y. X is a candidate of proper name and 17 Y is a candidate of organization type .</sentence>
				<definiendum id="0">Y. X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">a candidate of proper name</definiens>
				<definiens id="1">a candidate of organization type</definiens>
			</definition>
			<definition id="4">
				<sentence>The X is the initial two-characters of the keyword and Y is the remained characters .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">the initial two-characters of the keyword</definiens>
				<definiens id="1">the remained characters</definiens>
			</definition>
			<definition id="5">
				<sentence>Since the structure of an organization name is a composition of X+Y , where X is a proper name and Y is a organization type .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">a proper name</definiens>
				<definiens id="1">a organization type</definiens>
			</definition>
			<definition id="6">
				<sentence>The knowledge sources for future identification of organizations are the accumulated lists of the organization names , the proper names of organizations and the organization types .</sentence>
				<definiendum id="0">knowledge sources</definiendum>
				<definiens id="0">the accumulated lists of the organization names , the proper names of organizations and the organization types</definiens>
			</definition>
			<definition id="7">
				<sentence>During the word segmentation process , an organization name is either identified immediately ( if it is a known organization name ) , or it will be segmented into two segments of X+Y or several segments of ( xl+x2+ ... +xn ) +Y , where X is a proper names , Y is the organization type .</sentence>
				<definiendum id="0">X</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">a proper names ,</definiens>
				<definiens id="1">the organization type</definiens>
			</definition>
</paper>

		<paper id="0723">
			<definition id="0">
				<sentence>The aim of an IE system consists in automatically extracting pieces of information from text , being this information relevant for a set of prescribed concepts ( scenario ) .</sentence>
				<definiendum id="0">aim of an IE system</definiendum>
				<definiens id="0">consists in automatically extracting pieces of information from text , being this information relevant for a set of prescribed concepts ( scenario )</definiens>
			</definition>
			<definition id="1">
				<sentence>In recent years , a variety of Machine Learning ( ML ) techniques has been used to improve the portability of IE systems to new domains , as in SRV ( Freitag , 1998 ) , RAPIER ( Califf and Mooney , 1997 ) , LIEP ( Huffman , 1996 ) , CRYSTAL ( Soderland et al. , 1995 ) and WHISK ( Soderland , 1999 ) .</sentence>
				<definiendum id="0">WHISK</definiendum>
				<definiens id="0">a variety of Machine Learning ( ML ) techniques has been used to improve the portability of IE systems to new domains</definiens>
			</definition>
			<definition id="2">
				<sentence>This paper describes EVIUS , a multi-concept learning system for free text that follows a multi-strategy constructive learning approach ( MCL ) ( Michalshi , 1993 ) and supports insufficient amounts of training corpora .</sentence>
				<definiendum id="0">EVIUS</definiendum>
				<definiens id="0">a multi-concept learning system for free text that follows a multi-strategy constructive learning approach ( MCL ) ( Michalshi , 1993 ) and supports insufficient amounts of training corpora</definiens>
			</definition>
			<definition id="3">
				<sentence>EVIUS is a component of a multilingual IE system , MTURBIO ( Turmo et al. , 1999 ) .</sentence>
				<definiendum id="0">EVIUS</definiendum>
				<definiens id="0">a component of a multilingual IE system</definiens>
			</definition>
			<definition id="4">
				<sentence>In order to learn set S of IE rule sets for the whole C , EVIUS uses an MCL approach integrating constructive learning , closed-loop learning and deductive restructuring ( Ko , 1998 ) .</sentence>
				<definiendum id="0">EVIUS</definiendum>
			</definition>
			<definition id="5">
				<sentence>to to from from Figure 1 : A single scenario for the colour domain In order to learn a rule set for a concept , EVIUS uses the relational learning method explained in section 3 , and defines the learning space by means of a dynamic predicate model .</sentence>
				<definiendum id="0">EVIUS</definiendum>
				<definiens id="0">uses the relational learning method explained in section 3 , and defines the learning space by means of a dynamic predicate model</definiens>
			</definition>
			<definition id="6">
				<sentence>_X ( A , B ) , stating that there are X terminal nodes , at most , between A and B , and c ) relational predicates : ancestor ( A , B ) , where B is the syntactic ancestor of A , and brother ( A , B ) , where B is the right brother node of A sharing the syntactic ancestor .</sentence>
				<definiendum id="0">_X</definiendum>
				<definiendum id="1">B</definiendum>
				<definiendum id="2">B</definiendum>
				<definiendum id="3">B</definiendum>
				<definiens id="0">at most , between A and B , and c ) relational predicates : ancestor ( A ,</definiens>
				<definiens id="1">the syntactic ancestor of A , and brother ( A , B ) , where B is the right brother node of A sharing the syntactic ancestor</definiens>
			</definition>
			<definition id="7">
				<sentence>Positive examples C + can be selected using a friendly environment either as : • text relations : c ( A : ,A2 ) where both A : and A2 are terminal nodes that exactly delimit a text value for c. For instance , both text relations colour ( n3 , n3 ) or colour ( n6 , nT ) in figure 2 , or as : • ontology relations : c ( A : ,A2 , ... , An ) where all Ai are terminal nodes which are instances of already learned concepts related to c in the scenario .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">• ontology relations : c ( A : ,A2 , ... , An ) where all Ai are terminal nodes which are instances of already learned concepts related to c in the scenario</definiens>
			</definition>
			<definition id="8">
				<sentence>This is done by iterating the process above while uncovered examples remain and the F1 score increment ( AF1 ) is greater than pre-defined constant a : select g+ and generate g7~0 = FOIL ( g+ , g - ) $ u + = uncover ed_ f r om ( 7~o ) = ( 7¢o ) while $ u + ~ 0 and AF1 &gt; a do g+ = g+ U pseudo-examples ( $ u + ) T¢~ = FOIL ( E+ , g - ) T~i+ l = combine_rules ( 7~i , T¢~ ) gu + = uncovered_f rom ( TQ+ l ) = El ( hi+l ) El ( hi ) endwhile if AF1 &gt; a then return `` ~i+1 else return 7~i endi/ examples Negative examples can be defined as any combination of terminal nodes out of g+ .</sentence>
				<definiendum id="0">F1 score increment</definiendum>
				<definiendum id="1">AF1</definiendum>
				<definiendum id="2">T¢~ = FOIL</definiendum>
				<definiendum id="3">El ( hi+l ) El</definiendum>
				<definiens id="0">a do g+ = g+ U pseudo-examples ( $ u + )</definiens>
			</definition>
			<definition id="9">
				<sentence>_X B~ , lemma-X sl , ... , lemma_X B~ , sem-X B1 , ... , sem_X B~ , context ) where B1 , ... , Bn are the unrepeated terminal nodes from A1 , ... , An , context is the set of all predicates subsumed by the syntactico-semantic structure between the nearest positive example on the left and the nearest one on the right , and sem_XB~ is the list of isa_X and has_hypernym_X predicates for Bi .</sentence>
				<definiendum id="0">sem-X B1 , ... , sem_X B~</definiendum>
				<definiendum id="1">B1 , ... , Bn</definiendum>
				<definiendum id="2">context</definiendum>
				<definiendum id="3">sem_XB~</definiendum>
				<definiens id="0">the unrepeated terminal nodes from A1 , ... , An</definiens>
				<definiens id="1">the set of all predicates subsumed by the syntactico-semantic structure between the nearest positive example on the left and the nearest one on the right , and</definiens>
			</definition>
			<definition id="10">
				<sentence>laF1T means the F1 value for training sets T. Set E + Fir Recall Prec .</sentence>
				<definiendum id="0">laF1T</definiendum>
			</definition>
</paper>

		<paper id="0203">
			<definition id="0">
				<sentence>IF ( Interchange Format ) , the interlingua used by the C-STAR consortium , is a speech-act based interlingua for task-oriented dialogue .</sentence>
				<definiendum id="0">interlingua used by the C-STAR consortium</definiendum>
				<definiens id="0">a speech-act based interlingua for task-oriented dialogue</definiens>
			</definition>
			<definition id="1">
				<sentence>Coverage was measured by having human IF specialists annotate unseen data .</sentence>
				<definiendum id="0">Coverage</definiendum>
				<definiens id="0">measured by having human IF specialists annotate unseen data</definiens>
			</definition>
			<definition id="2">
				<sentence>Consistency was measured by two means .</sentence>
				<definiendum id="0">Consistency</definiendum>
				<definiens id="0">measured by two means</definiens>
			</definition>
			<definition id="3">
				<sentence>In the following example , the DA consists of a speaker tag ( a : for agent ) , the speechact give-information , and two main concepts , +price and +room .</sentence>
				<definiendum id="0">DA</definiendum>
				<definiens id="0">consists of a speaker tag ( a : for agent ) , the speechact give-information , and two main concepts , +price and +room</definiens>
			</definition>
			<definition id="4">
				<sentence>An end-to-end evaluation includes an analyzer , which maps the source language input into IF and a generator , which maps IF into target language sentences .</sentence>
				<definiendum id="0">analyzer</definiendum>
				<definiendum id="1">generator</definiendum>
				<definiens id="0">maps the source language input into IF</definiens>
				<definiens id="1">maps IF into target language sentences</definiens>
			</definition>
			<definition id="5">
				<sentence>formation+price+room ( room-type=twin , price= ( currency=yen , quantity=f4000 ) ) Figure 5 : Examples of IF coding from CMU and IRST .</sentence>
				<definiendum id="0">formation+price+room</definiendum>
				<definiens id="0">Examples of IF coding from CMU and IRST</definiens>
			</definition>
			<definition id="6">
				<sentence>In Figure 6 , acceptable is the sum of perfect and ok scores , s Figure 6 shows the results of the intra-site and inter-site evaluations .</sentence>
				<definiendum id="0">acceptable</definiendum>
				<definiens id="0">the sum of perfect and ok scores</definiens>
			</definition>
</paper>

		<paper id="1314">
			<definition id="0">
				<sentence>The translation Relation probability of words are given by following equation : P~ L : ~ ( 1 ) L'L Where f¢ is the frequency of English word in whole corpus ; fc is the frequency of Chinese Word in whole corpus ; f~ is calculated by follow equation : N /ln ( 2Lay ) + ln ( Lav ) I L~i + Lci ( 2 ) Where Lmv is the average words number of all English chunks and all Chinese chunks which are related to the English word in whole Corpus ; L~i is the word number of the English chunk in which the English candidate words co-occur with the Chinese words ; ~ is the word number of the Chinese chunk in which the English candidate words co-occur with the Chinese words ; N is the total number of chunks in which the English word co-occur with the Chinese word ; 13¢e is the penalty value to indicate the POS change between the Engfish word and the Chinese word .</sentence>
				<definiendum id="0">translation Relation probability of words</definiendum>
				<definiendum id="1">f¢</definiendum>
				<definiendum id="2">fc</definiendum>
				<definiendum id="3">Lmv</definiendum>
				<definiendum id="4">L~i</definiendum>
				<definiendum id="5">~</definiendum>
				<definiendum id="6">N</definiendum>
				<definiens id="0">the frequency of English word in whole corpus</definiens>
				<definiens id="1">the average words number of all English chunks and all Chinese chunks which are related to the English word in whole Corpus ;</definiens>
				<definiens id="2">the word number of the English chunk in which the English candidate words co-occur with the Chinese words ;</definiens>
			</definition>
</paper>

		<paper id="1323">
			<definition id="0">
				<sentence>The parsers combine lexical indices such as discourse markers with formatting instructions ( HTML tags ) for analyzing enumerations and associated initializers .</sentence>
				<definiendum id="0">HTML tags</definiendum>
				<definiens id="0">discourse markers with formatting instructions</definiens>
			</definition>
			<definition id="1">
				<sentence>( a ) United Nations organs International Bank for Reconstruction and Development ( World Bank ) ( b ) lntergovernmental organizations Asian-African Legal Consultative Committee ( AALCC ) Inter-American Development Bank Internauonal Institute for the Umficauon of Private Law ( UNIDROIT ) International Organizations The following international organizations are collaborating on the Project : lp International Commission on Non-Ionizing Radiation Protection ( ICNIRP ) 1~ International Agency for Research on Cancer ( IARC ) United Nations Environment Programme ( UNEP ) Below is the list of international organizations that we distribute : EU ( European Union ) Books , documentation , periodicals on European legislation , economy , agriculture , industry , educatmn , norms , social pohtics , law .</sentence>
				<definiendum id="0">documentation</definiendum>
				<definiens id="0">collaborating on the Project : lp International Commission on Non-Ionizing Radiation Protection ( ICNIRP ) 1~ International Agency for Research on Cancer ( IARC ) United Nations Environment Programme ( UNEP ) Below is the list of international organizations</definiens>
				<definiens id="1">agriculture , industry , educatmn , norms , social pohtics , law</definiens>
			</definition>
			<definition id="2">
				<sentence>184 ORGANIZATION ( American companies , international organizations , universities , political organizations , international agencies , car makers , terrorist groups , financial institutions , museums , international companies , holdings , sects , and realtors ) , PERSON ( politicians , VIPs , actors , managers , celebrities , actresses , athletes , authors , film directors , top models , musicians , singers , and journalists ) , and LOCATION ( countries , regions , states , lakes , cities , rivers , mountains , and islands ) .</sentence>
				<definiendum id="0">PERSON</definiendum>
				<definiens id="0">politicians , VIPs , actors , managers , celebrities , actresses , athletes , authors , film directors , top models , musicians , singers , and journalists ) , and LOCATION ( countries , regions , states , lakes , cities , rivers , mountains , and islands )</definiens>
			</definition>
			<definition id="3">
				<sentence>For each candidate , AV is queried with a phrase containing the string of the NE .</sentence>
				<definiendum id="0">AV</definiendum>
				<definiens id="0">queried with a phrase containing the string of the NE</definiens>
			</definition>
</paper>

		<paper id="1103">
			<definition id="0">
				<sentence>A textual IR system stores a collection of documents and special data structures for effective searching .</sentence>
				<definiendum id="0">textual IR system</definiendum>
				<definiens id="0">stores a collection of documents and special data structures for effective searching</definiens>
			</definition>
			<definition id="1">
				<sentence>A textual document is a sequence of terms .</sentence>
				<definiendum id="0">textual document</definiendum>
				<definiens id="0">a sequence of terms</definiens>
			</definition>
			<definition id="2">
				<sentence>Ambiguity and synonymity of words is a property of natural language causing a very serious problem in IR .</sentence>
				<definiendum id="0">Ambiguity</definiendum>
				<definiens id="0">a property of natural language causing a very serious problem in IR</definiens>
			</definition>
			<definition id="3">
				<sentence>The knowledge of collocations can be used in IR for several purposes : making up contextual representations of words , resolving word ambiguity , estimating semantic word similarity , tuning the user 's query in interaction with the user and quantifying the significance of words for retrieval according to entropy of their contexts .</sentence>
				<definiendum id="0">knowledge of collocations</definiendum>
				<definiens id="0">estimating semantic word similarity , tuning the user 's query in interaction with the user and quantifying the significance of words for retrieval according to entropy of their contexts</definiens>
			</definition>
			<definition id="4">
				<sentence>Word senses are products of their interaction .</sentence>
				<definiendum id="0">Word senses</definiendum>
			</definition>
			<definition id="5">
				<sentence>The contextual representation of a word has been defined as a characterisation of the linguistic context in which a word appears .</sentence>
				<definiendum id="0">contextual representation of a word</definiendum>
				<definiens id="0">a characterisation of the linguistic context in which a word appears</definiens>
			</definition>
			<definition id="6">
				<sentence>The first step of the syntactic tagging consists in the building of the anatytic tree structure ( ATS ) representing the surface syntactic dependency relations in the sentence .</sentence>
				<definiendum id="0">syntactic tagging</definiendum>
				<definiens id="0">consists in the building of the anatytic tree structure ( ATS ) representing the surface syntactic dependency relations in the sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>The automatically created ATS is a labelled oriented acyclic graph with a single root ( dependency tree ) .</sentence>
				<definiendum id="0">ATS</definiendum>
				<definiens id="0">a labelled oriented acyclic graph with a single root ( dependency tree )</definiens>
			</definition>
			<definition id="8">
				<sentence>One of the attributes is the analytic function that expresses the syntactic function of the word .</sentence>
				<definiendum id="0">analytic function</definiendum>
				<definiens id="0">expresses the syntactic function of the word</definiens>
			</definition>
			<definition id="9">
				<sentence>The transduction of the ATS to the DMCS consists of the four procedures : elimination of the auxiliary nodes and joining the complex word forms into one node .</sentence>
				<definiendum id="0">transduction of the ATS to the DMCS</definiendum>
				<definiens id="0">consists of the four procedures : elimination of the auxiliary nodes and joining the complex word forms into one node</definiens>
			</definition>
			<definition id="10">
				<sentence>The constructions of coordination and apposition are represented by a special node ( usually the node of the coordinating conjunction or other expression ) that is the governor of the coordinated subtrees and their common complementation in the ATS .</sentence>
				<definiendum id="0">special node</definiendum>
				<definiens id="0">the governor of the coordinated subtrees and their common complementation in the ATS</definiens>
			</definition>
			<definition id="11">
				<sentence>The construction of the dependency microcontext is based on the identification of significant dependency relationships ( SDRs ) in the sentence .</sentence>
				<definiendum id="0">construction of the dependency microcontext</definiendum>
				<definiens id="0">based on the identification of significant dependency relationships ( SDRs ) in the sentence</definiens>
			</definition>
			<definition id="12">
				<sentence>An SDR consists of two words and a dependency type .</sentence>
				<definiendum id="0">SDR</definiendum>
				<definiens id="0">consists of two words and a dependency type</definiens>
			</definition>
			<definition id="13">
				<sentence>An SDR is a triple \ [ wl , DT , w2\ ] , where wl is a head word ( lexical unit ) , DT is a dependency type and w2 is a depending word ( lexical unit ) .</sentence>
				<definiendum id="0">SDR</definiendum>
				<definiendum id="1">wl</definiendum>
				<definiendum id="2">DT</definiendum>
				<definiendum id="3">w2</definiendum>
				<definiens id="0">a triple \ [ wl</definiens>
				<definiens id="1">a head word ( lexical unit )</definiens>
				<definiens id="2">a dependency type</definiens>
			</definition>
			<definition id="14">
				<sentence>A dependency type is a triple ( P1 , AF , P2 ) , where Pi is the part of speech of the head word , AF is an analytic function and P2 is the part of speech of the depending word .</sentence>
				<definiendum id="0">dependency type</definiendum>
				<definiendum id="1">Pi</definiendum>
				<definiendum id="2">AF</definiendum>
				<definiendum id="3">P2</definiendum>
				<definiens id="0">the part of speech of the head word</definiens>
				<definiens id="1">an analytic function</definiens>
				<definiens id="2">the part of speech of the depending word</definiens>
			</definition>
			<definition id="15">
				<sentence>A DMC of a given word w is a list of its microcontext elements ( MCEs ) .</sentence>
				<definiendum id="0">DMC of a given word w</definiendum>
				<definiens id="0">a list of its microcontext elements ( MCEs )</definiens>
			</definition>
			<definition id="16">
				<sentence>An MCE is a pair consisting of a word and a dependency type .</sentence>
				<definiendum id="0">MCE</definiendum>
				<definiens id="0">a pair consisting of a word and a dependency type</definiens>
			</definition>
			<definition id="17">
				<sentence>Word sense disambiguation is a central problem in NLP .</sentence>
				<definiendum id="0">Word sense disambiguation</definiendum>
				<definiens id="0">a central problem in NLP</definiens>
			</definition>
			<definition id="18">
				<sentence>dependency relations ( ATS ) contains information not relevant for the contexts extraction ( with respect to IR needs ) , therefore we reduce this structure and we gather a structure containing only the semantically significant words and 4 main types of syntactic dependencies .</sentence>
				<definiendum id="0">dependency relations ( ATS</definiendum>
				<definiens id="0">contains information not relevant for the contexts extraction</definiens>
			</definition>
			<definition id="19">
				<sentence>Uncertainty and vagueness in the text retrieval can not be eliminated entirely since they are caused primarily by the character of the human thinking necessarily determining also the character of natural language .</sentence>
				<definiendum id="0">Uncertainty</definiendum>
				<definiens id="0">caused primarily by the character of the human thinking necessarily determining also the character of natural language</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>We discuss these concepts and the way they are implemented in the architectural framework of the ADAM corpus , which is a corpus of 450 Italian spontaneous dialogues .</sentence>
				<definiendum id="0">ADAM corpus</definiendum>
				<definiens id="0">a corpus of 450 Italian spontaneous dialogues</definiens>
			</definition>
			<definition id="1">
				<sentence>We claim that two other requirements should be taken into account when designing and building an annotated corpus that aims at reusability , namely modularity of annotation , and use of annotation meta-schemes .</sentence>
				<definiendum id="0">annotated corpus</definiendum>
				<definiens id="0">aims at reusability , namely modularity of annotation , and use of annotation meta-schemes</definiens>
			</definition>
			<definition id="2">
				<sentence>A potential user of the ADAM Corpus is left free to select , among the proposed levels of annotation , those which best reflect his/her theoretical and practical interests .</sentence>
				<definiendum id="0">ADAM Corpus</definiendum>
				<definiens id="0">left free to select , among the proposed levels of annotation , those which best reflect his/her theoretical and practical interests</definiens>
			</definition>
			<definition id="3">
				<sentence>As it will be made clear in section 4 , for each of the five annotation layers envisaged for the ADAM Corpus , a particular annotation scheme has been designed and applied .</sentence>
				<definiendum id="0">ADAM Corpus</definiendum>
				<definiens id="0">a particular annotation scheme has been designed and applied</definiens>
			</definition>
			<definition id="4">
				<sentence>According to our view , an annotation meta-scheme is a general descriptive framework in which different annotation schemes can be accommodated .</sentence>
				<definiendum id="0">annotation meta-scheme</definiendum>
				<definiens id="0">a general descriptive framework in which different annotation schemes can be accommodated</definiens>
			</definition>
			<definition id="5">
				<sentence>However , at the best of our knowledge ADAM is the first corpus being architecturally designed by explicitly adopting the concept of annotation modularity and metascheme at different levels .</sentence>
				<definiendum id="0">ADAM</definiendum>
				<definiens id="0">the first corpus being architecturally designed by explicitly adopting the concept of annotation modularity and metascheme at different levels</definiens>
			</definition>
			<definition id="6">
				<sentence>ATLAS offers a threelayers solution to the problem of integrating different data storage formats by providing a logical level which consists of the language formalism and the API .</sentence>
				<definiendum id="0">ATLAS</definiendum>
				<definiens id="0">offers a threelayers solution to the problem of integrating different data storage formats by providing a logical level which consists of the language formalism and the API</definiens>
			</definition>
			<definition id="7">
				<sentence>Syntactic Levels The ADAM proposal for the morphosyntactic level is a two-layer annotation structure , containing respectively information on word category and morphosyntactic features ( pos tagging ) , and non recursive phrasal nuclei ( called chunks ) .</sentence>
				<definiendum id="0">ADAM proposal</definiendum>
				<definiendum id="1">morphosyntactic level</definiendum>
				<definiens id="0">a two-layer annotation structure , containing respectively information on word category and morphosyntactic features ( pos tagging ) , and non recursive phrasal nuclei ( called chunks )</definiens>
			</definition>
			<definition id="8">
				<sentence>The morphosyntactic annotation level encodes the following information : a ) identification of morphological words and linking to their corresponding orthographic counterparts ; b ) annotation of their pos-category ; c ) annotation of morphosyntactic features ( such as number , gender , person , tense , etc. ) ; d ) annotation of their corresponding lemma .</sentence>
				<definiendum id="0">morphosyntactic annotation level</definiendum>
				<definiens id="0">a ) identification of morphological words and linking to their corresponding orthographic counterparts ; b ) annotation of their pos-category ; c ) annotation of morphosyntactic features ( such as number , gender , person , tense , etc. ) ; d ) annotation of their corresponding lemma</definiens>
			</definition>
			<definition id="9">
				<sentence>Informally speaking , a dialogue act tag is a label belonging to a tag set which refers to a given iUocutionary dimension that may be performed by uttering a sentence .</sentence>
				<definiendum id="0">dialogue act tag</definiendum>
				<definiens id="0">a label belonging to a tag set which refers to a given iUocutionary dimension that may be performed by uttering a sentence</definiens>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>The reasoning model consists of the model of human motivational sphere , and of reasoning algorithms .</sentence>
				<definiendum id="0">reasoning model</definiendum>
				<definiens id="0">consists of the model of human motivational sphere , and of reasoning algorithms</definiens>
			</definition>
			<definition id="1">
				<sentence>Conversation agent is a kind of intelligent agent a computer program that is able to communicate with humans as another human being .</sentence>
				<definiendum id="0">Conversation agent</definiendum>
				<definiens id="0">a kind of intelligent agent a computer program that is able to communicate with humans as another human being</definiens>
			</definition>
			<definition id="2">
				<sentence>In our model , KB consists of 4 components : KB = ( KBw , KBL , KBD , KBs ) , where KBw contains world knowledge , KBL linguistic knowledge , KBD knowledge about dialogue and KBs knowledge about interacting subjects .</sentence>
				<definiendum id="0">KB</definiendum>
				<definiens id="0">consists of 4 components : KB = ( KBw , KBL , KBD , KBs ) , where KBw contains world knowledge , KBL linguistic knowledge , KBD knowledge about dialogue and KBs knowledge about interacting subjects</definiens>
			</definition>
			<definition id="3">
				<sentence>For instance , KBD contains definitions of communicative acts , turns and transactions ( declarative knowledge ) , and algorithms that are applied to reach communicative goals communicative strategies and tactics ( procedural knowledge ) ; KBs contains knowledge about evaluative dispositions of participants towards the world ( e.g. what do they consider as pleasant or unpleasant , useful or harmful ) , and , on the other hand , algorithms that are used to generate plans for acting on the world .</sentence>
				<definiendum id="0">KBD</definiendum>
				<definiens id="0">contains definitions of communicative acts , turns and transactions ( declarative knowledge ) , and algorithms that are applied to reach communicative goals communicative strategies and tactics ( procedural knowledge ) ; KBs contains knowledge about evaluative dispositions of participants towards the world ( e.g. what do they consider as pleasant or unpleasant , useful or harmful ) , and , on the other hand , algorithms that are used to generate plans for acting on the world</definiens>
			</definition>
			<definition id="4">
				<sentence>The reasoning model consists of two functionally linked parts : 1 ) a model of human motivational sphere ; 2 ) reasoning schemes .</sentence>
				<definiendum id="0">reasoning model</definiendum>
				<definiens id="0">consists of two functionally linked parts : 1 ) a model of human motivational sphere ; 2 ) reasoning schemes</definiens>
			</definition>
			<definition id="5">
				<sentence>A reasoning scheme represents steps that the agent goes through in his reasoning process ; these consist in computing and comparing the weights of 104 different aspects of D ; and the result is the decision to do or not to do D. Figure 1 presents the reasoning scheme that departs from the wish of a subject to do D. The scheme also illustrates one of the general principles referred to above .</sentence>
				<definiendum id="0">reasoning scheme</definiendum>
				<definiens id="0">the decision to do or not to do D. Figure 1 presents the reasoning scheme that departs from the wish of a subject to do D. The scheme also illustrates one of the general principles referred to above</definiens>
			</definition>
			<definition id="6">
				<sentence>First , the planner PL makes use of reasoning schemes and second , the KBs contains the vector w A ( A 's subjective evaluations of all possible actions ) as well as vectors w AB ( A 's beliefs concerning B 's evaluations , where B denotes agents A may communicate with ) .</sentence>
				<definiendum id="0">KBs</definiendum>
				<definiens id="0">contains the vector w A ( A 's subjective evaluations of all possible actions ) as well as vectors w AB ( A 's beliefs concerning B 's evaluations , where B denotes agents A may communicate with )</definiens>
			</definition>
			<definition id="7">
				<sentence>Communicative space is defined by a number of coordinates that characterise the relationships of participants in a communicative encounter .</sentence>
				<definiendum id="0">Communicative space</definiendum>
				<definiens id="0">a number of coordinates that characterise the relationships of participants in a communicative encounter</definiens>
			</definition>
			<definition id="8">
				<sentence>The static part consists of preconditions , goal , content ( immediate act ) and consequences .</sentence>
				<definiendum id="0">static part</definiendum>
				<definiens id="0">consists of preconditions , goal , content ( immediate act ) and consequences</definiens>
			</definition>
</paper>

		<paper id="1204">
			<definition id="0">
				<sentence>In parsing , we model a left-to-right shift-reduce automaton which builds a parse-tree constituent-by-constituent in a deterministic left -- to-right process .</sentence>
				<definiendum id="0">left-to-right shift-reduce automaton</definiendum>
				<definiens id="0">builds a parse-tree constituent-by-constituent in a deterministic left -- to-right process</definiens>
			</definition>
			<definition id="1">
				<sentence>The total of all the instantiations of all these templates presents a potentially huge feature set , so we rely on an important property of the SNoW architecture , that it can handle an indefinitely large set of 24 Predicate Schema POS ( Surface-word \ [ k\ ] ) = t Range of Parameters -I K k_ &lt; 2 POS ( Surface-word\ [ k\ ] ) = tl /~ POS ( Surface-word\ [ k + I\ ] ) = t2 -2 ~ k ~ 1 Category ( Stack\ [ k\ ] ) = c 0 ~ k ~ 1 Category ( Stack\ [ k\ ] ) = ci /k Category ( Stack \ [ k + I\ ] ) = c2 0 ~ k - &lt; 1 POS ( S-head ( Stack\ [ k\ ] ) ) = t 0 ~ k ~ 2 POS ( S-head ( Stack\ [ k\ ] ) ) =tl/k POS ( S-head ( Stack\ [ k+ I\ ] ) ) =t2 0 ~ k - &lt; 1 POS ( S-head ( Stack\ [ kx\ ] ) ) = tx /k POS ( Surface-word\ [ k2\ ] ) = t2 0 -- &lt; kx ~ 1 -I~ k2- &lt; 0 Category ( Stack\ [ kx\ ] ) = c /k POS ( C-head ( Stack\ [ kx\ ] ) ) = t~ /~ POS ( Surface-word \ [ k2\ ] ) = t2 .</sentence>
				<definiendum id="0">total of all the instantiations of all these templates</definiendum>
				<definiendum id="1">)</definiendum>
				<definiens id="0">Surface-word\ [ k + I\ ]</definiens>
			</definition>
			<definition id="2">
				<sentence>A Subset of the Feature Schemas in the Original Version of the Parser .</sentence>
				<definiendum id="0">Subset of</definiendum>
				<definiens id="0">the Feature Schemas in the Original Version of the Parser</definiens>
			</definition>
			<definition id="3">
				<sentence>c ( x~ , wz ) represents the count of the event that x and y occur adjacent and in this order in the training corpus .</sentence>
				<definiendum id="0">c ( x~</definiendum>
				<definiens id="0">the count of the event that x and y occur adjacent and in this order in the training corpus</definiens>
			</definition>
</paper>

		<paper id="1322">
			<definition id="0">
				<sentence>Keywords : Cross-corpus evaluation of Ni_P systems , Word Sense Disambiguation , Supervised Machine Learning Word Sense Disambiguation ( WSD ) is the problem of assigning the appropriate meaning ( sense ) to a given word in a text or discourse .</sentence>
				<definiendum id="0">WSD )</definiendum>
				<definiens id="0">Cross-corpus evaluation of Ni_P systems , Word Sense Disambiguation , Supervised Machine Learning Word Sense Disambiguation</definiens>
				<definiens id="1">the problem of assigning the appropriate meaning ( sense ) to a given word in a text or discourse</definiens>
			</definition>
			<definition id="1">
				<sentence>WSD is one of the most important open problems in NLP .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">one of the most important open problems in NLP</definiens>
			</definition>
			<definition id="2">
				<sentence>Although this methodology could be valid for certain NLP problems , such as English Part-of-Speech tagging , we think that there exists reasonable evidence to say that , in WSD , accuracy results can not be simply extrapolated to other domains ( contrary to the opinion of other authors ( Ng , 1997b ) ) : On the aSupervised approaches , also known as data-driven or corpus-dmven , are those that learn from a previously semantically annotated corpus .</sentence>
				<definiendum id="0">English Part-of-Speech</definiendum>
				<definiens id="0">exists reasonable evidence to say that , in WSD , accuracy results can not be simply extrapolated to other domains ( contrary to the opinion of other authors ( Ng , 1997b ) ) : On the aSupervised approaches , also known as data-driven or corpus-dmven , are those that learn from a previously semantically annotated corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>Naive Bayes is intended as a simple representative of statistical learning methods .</sentence>
				<definiendum id="0">Naive Bayes</definiendum>
				<definiens id="0">a simple representative of statistical learning methods</definiens>
			</definition>
			<definition id="4">
				<sentence>In the Snow architecture there is a winnow node for each class , which learns to separate that class from all the rest .</sentence>
				<definiendum id="0">winnow node</definiendum>
				<definiens id="0">learns to separate that class from all the rest</definiens>
			</definition>
			<definition id="5">
				<sentence>When classifying a new example , Snow is similar to a neural network which takes the input features and outputs the class with the highest activation .</sentence>
				<definiendum id="0">Snow</definiendum>
				<definiens id="0">similar to a neural network which takes the input features and outputs the class with the highest activation</definiens>
			</definition>
			<definition id="6">
				<sentence>The predicates used , which are the binarization of the attributes described in section 3.2 , are of the form `` f = v '' , where f is a feature and v is a value ( e.g : `` -r v '' p e mus_word = hospital '' ) .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">v</definiendum>
				<definiens id="0">a feature and</definiens>
			</definition>
			<definition id="7">
				<sentence>LazyBoosting ( Escudero et al. , 2000a ) , is a simple modification of the AdaBoost .</sentence>
				<definiendum id="0">LazyBoosting</definiendum>
				<definiens id="0">a simple modification of the AdaBoost</definiens>
			</definition>
			<definition id="8">
				<sentence>MH algorithm , which consists of reducing the feature space that is explored when learning each weak classifier .</sentence>
				<definiendum id="0">MH algorithm</definiendum>
				<definiens id="0">consists of reducing the feature space that is explored when learning each weak classifier</definiens>
			</definition>
			<definition id="9">
				<sentence>The DSO corpus is a semantically annotated corpus containing 192,800 occurrences of 121 nouns and 70 verbs , corresponding to the most frequent and ambiguous English words .</sentence>
				<definiendum id="0">DSO corpus</definiendum>
				<definiens id="0">a semantically annotated corpus containing 192,800 occurrences of 121 nouns and 70 verbs</definiens>
			</definition>
			<definition id="10">
				<sentence>The topical context is formed by Cl , ... , Cm , which stand for the unordered set of open class words appearing in the sentence 7 .</sentence>
				<definiendum id="0">Cl , ... , Cm</definiendum>
				<definiens id="0">stand for the unordered set of open class words appearing in the sentence</definiens>
			</definition>
			<definition id="11">
				<sentence>M FC stands for a Most-Frequent-sense Classifier , that is , a naive classifier that learns the most frequent sense of the training set and uses it to classify all examples of the test set .</sentence>
				<definiendum id="0">M FC</definiendum>
				<definiendum id="1">naive classifier</definiendum>
				<definiens id="0">learns the most frequent sense of the training set and uses it to classify all examples of the test set</definiens>
			</definition>
			<definition id="12">
				<sentence>Exemplar-Base Wbrd Sense Disambiguation : Some Recent Improvements .</sentence>
				<definiendum id="0">Exemplar-Base Wbrd Sense Disambiguation</definiendum>
				<definiens id="0">Some Recent Improvements</definiens>
			</definition>
			<definition id="13">
				<sentence>Decision Lists for Lexical Ambiguity Resolution : Application to Accent Restoration in Spanish and French .</sentence>
				<definiendum id="0">Decision Lists</definiendum>
			</definition>
</paper>

		<paper id="1437">
			<definition id="0">
				<sentence>YAG ( Yet Another Generator ) is a real-time , general-purpose , template-based generation system that will enable interactive applications to adapt natural language output to the interactive context without requiring developers to write all possible output strings ahead of time or to embed extensive knowledge of the grammar of the target language in the application .</sentence>
				<definiendum id="0">YAG</definiendum>
				<definiendum id="1">Yet Another Generator )</definiendum>
				<definiens id="0">a real-time , general-purpose , template-based generation system that will enable interactive applications to adapt natural language output to the interactive context without requiring developers to write all possible output strings ahead of time or to embed extensive knowledge of the grammar of the target language in the application</definiens>
			</definition>
			<definition id="1">
				<sentence>Expressiveness YAG offers an expressive language for specifying a generation grammar .</sentence>
				<definiendum id="0">Expressiveness YAG</definiendum>
				<definiens id="0">offers an expressive language for specifying a generation grammar</definiens>
			</definition>
			<definition id="2">
				<sentence>Language A template is a pre-defined form with parameters that are specified by either the user or the application at run-time .</sentence>
				<definiendum id="0">template</definiendum>
				<definiens id="0">a pre-defined form with parameters that are specified by either the user or the application at run-time</definiens>
			</definition>
			<definition id="3">
				<sentence>Template slots are parameters or variables that applications or users can fill with values .</sentence>
				<definiendum id="0">Template slots</definiendum>
				<definiens id="0">parameters or variables that applications or users can fill with values</definiens>
			</definition>
			<definition id="4">
				<sentence>In this representation , M2 is the proposition that the discourse entity B2 is a member of class `` dog '' .</sentence>
				<definiendum id="0">M2</definiendum>
				<definiens id="0">the proposition that the discourse entity B2 is a member of class `` dog ''</definiens>
			</definition>
			<definition id="5">
				<sentence>M5 is the proposition that the name of the discourse entity B2 is `` Pluto '' .</sentence>
				<definiendum id="0">M5</definiendum>
				<definiens id="0">the proposition that the name of the discourse entity B2 is `` Pluto ''</definiens>
			</definition>
			<definition id="6">
				<sentence>SNePS is a semantic network processing system ( Shapiro and Rapaport , 1992 ) .</sentence>
				<definiendum id="0">SNePS</definiendum>
				<definiens id="0">a semantic network processing system</definiens>
			</definition>
			<definition id="7">
				<sentence>( ( ( M2 ( AGENT B4 ) ( ACT ( MI ( ACTION `` take '' ) ( DOBJECT B6 ) ) ) ) ( MS ( OBJECT B4 ) ( PROPERNAME `` George '' ) ) ( MIi ( CLASS `` book '' ) ( MEMBER B6 ) ) ( ( form decl ) ( attitude action ) ( pronominal YES ( B6 B4 ) ) ( gender MASCULINE B4 ) ) ) ) To override the gender default ( NEUTRAL ) of B4 and generate `` He '' instead of `` It '' , Example 2 specifies B4 's gender as MASCULINE .</sentence>
				<definiendum id="0">( ( ( M2</definiendum>
				<definiens id="0">DOBJECT B6 ) ) ) ) ( MS ( OBJECT B4 ) ( PROPERNAME `` George '' ) ) ( MIi ( CLASS `` book '' ) ( MEMBER B6 ) ) ( ( form decl ) ( attitude action ) ( pronominal YES</definiens>
			</definition>
			<definition id="8">
				<sentence>( ( TEMPLATE CLAUSE ) ( PROCESS `` involve '' ) ( AGENT ( ( TEMPLATE NOUN-PHRASE ) ( HEAD `` blood pressure '' ) ( DEFINITE NOART ) ) ) ( AFFECTED ( ( TEMPLATE NOUN-PHRASE ) ( HEAD ( ( TEMPLATE CONJUNCTION ) ( SENTENCE NO ) ( FIRST ( ( TEMPLATE NOUN-PHRASE ) ( HEAD `` heart '' ) ( DEFINITE NOART ) ) ) ( SECOND ( ( TEMPLATE NOUN-PHRASE ) ( HEAD `` blood vessel '' ) ( NUMBER PLURAL ) ( DEFINITE NOART ) ) ) ) ) ( POSSESSOR ( ( TEMPLATE PRONOUN ) ( PERSON SECOND ) ) ) ) ) ) the agent slot , if its value were available ) are filled by defaults ( the defaults for number , person , and gender are SINGULAR , THIRD , and NEUTRAL , respectively . )</sentence>
				<definiendum id="0">DEFINITE NOART ) ) ) ( SECOND ( ( TEMPLATE NOUN-PHRASE )</definiendum>
				<definiendum id="1">NEUTRAL</definiendum>
				<definiens id="0">TEMPLATE CLAUSE ) ( PROCESS `` involve '' ) ( AGENT ( ( TEMPLATE NOUN-PHRASE ) ( HEAD `` blood pressure '' ) ( DEFINITE NOART ) ) ) ( AFFECTED ( ( TEMPLATE NOUN-PHRASE ) ( HEAD ( ( TEMPLATE CONJUNCTION ) ( SENTENCE NO ) ( FIRST ( ( TEMPLATE NOUN-PHRASE ) ( HEAD `` heart '' )</definiens>
				<definiens id="1">the defaults for number , person , and gender are SINGULAR , THIRD , and</definiens>
			</definition>
			<definition id="9">
				<sentence>YAG uses an expressive , declarative language for specifying a generation grammar .</sentence>
				<definiendum id="0">YAG</definiendum>
				<definiens id="0">uses an expressive , declarative language for specifying a generation grammar</definiens>
			</definition>
			<definition id="10">
				<sentence>In these ways , YAG provides the speed , robustness , flexibility , and maintainability needed by real-time natural language dialog systems .</sentence>
				<definiendum id="0">YAG</definiendum>
				<definiens id="0">provides the speed , robustness , flexibility , and maintainability needed by real-time natural language dialog systems</definiens>
			</definition>
</paper>

		<paper id="0715">
</paper>

		<paper id="1309">
			<definition id="0">
				<sentence>Precision is the percentage of predicted chunks that are actually correct while the recall is the percentage of correct chunks that are actually found .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the percentage of predicted chunks that are actually correct while the recall is the percentage of correct chunks that are actually found</definiens>
			</definition>
			<definition id="1">
				<sentence>By assuming that the mutual information between G~ and T1 ~ is equal to the summation of mutual information between G~ and the individual tag ti ( l_ &lt; i_ &lt; n ) : n log P ( TI '' ' G ? ) = ~ log P ( t , , G~ ) e ( Tln ) . P ( G~ ) i=1 P ( t , ) . P ( G ? ) or n n MI ( T~ ~ , G~ ) = ~ MI ( t , , G ? ) , i=l we have : log P ( T~ n I G~ ) = log P ( T1 n ) + ~ , log P ( ti ' G ? ) _ P ( t i ) . P ( G ? ) rl n = log P ( T1 ~ ) Z log P ( t , ) + ~ log P ( t , \ [ G ? ) i=1 i=1 The first item of above equation can be solved by using chain rules. Normally , each tag is assumed to be probabilistic dependent on the N-1 previous tags. Here , backoff bigram ( N=2 ) model is used. The second item is the summation of log probabilities of all the tags. Both the first item and second item correspond to the language model component of the tagger while the third item corresponds to the lexicon component of the tagger. Ideally the third item can be estimated by using the forward-backward algorithm ( Rabiner 1989 ) recursively for the first-order ( Rabiner 1989 ) or second-order HMMs ( Watson and Chunk 1992 ) . However , several approximations on it will be attempted later in this paper instead. The stochastic optimal tag sequence can be found by maxmizing the above equation over all the possible tag sequences. This is implemented by the Viterbi algorithm. The main difference between our tagger and other standard taggers lies in our tagger has a context-dependent lexicon while others use a context-independent lexicon. For chunk tagger , we haveg 1 = piwi where W~ n = w~w2 -- -w n is the word-sequence and P~ = PiP2 `` '' P~ is the part-of-speech 72 sequence. Here , we use structural tags to representing chunking ( bracketing and labelling ) structure. The basic idea of representing the structural tags is similar to Skut and Brants ( 1998 ) and the structural tag consists of three parts : 1 ) Structural relation. The basic idea is simple : structures of limited depth are encoded using a finite number of flags. Given a sequence of input tokens ( here , the word and part-of-speech pairs ) , we consider the structural relation between the previous input token and the current one. For the recognition of chunks , it is sufficient to distinguish the following four different structural relations which uniquely identify the sub-structures of depth l ( Skut and Brants used seven different structural relations to identify the sub-structures of depth 2 ) . 00 the current input token and the previous one have the same parent 90 one ancestor of the current input token and the previous input token have the same parent 09 the current input token and one ancestor of the previous input token have the same parent 99 one ancestor of the current input token and one ancestor of the previous input token have the same parent For example , in the following chunk tagged sentence ( NULL represents the beginning and end of the sentence ) : NULL \ [ NP He/PRP\ ] \ [ VP reckons/VBZ\ ] \ [ NP the/DT current/JJ account/NN deficit/NN\ ] \ [ VP will/MD narrow/VB\ ] \ [ PP to/TO\ ] \ [ NP only/RB # / # 1.8/CD billion/CD\ ] \ [ PP in/IN\ ] \ [ NP September/NNP\ ] \ [ O ./.\ ] NULL the corresponding structural relations between two adjacent input tokens are : 90 ( NULL He/PRP ) 99 ( He/PRP reckons/VBZ ) 99 ( reckons/VBZ the/DT ) 00 ( the/DT current/JJ ) 00 ( current/JJ account/NN ) 00 ( account/NN deficit/NN ) 99 ( deficit/NN will/MD ) 00 ( will/MD narrow/VB ) 99 ( narrow/VB to/TO ) 99 ( to/TO only/RB ) O0 ( only/RB # / # ) 00 ( # / # 1.8/CD ) 00 ( 1.8/CD billion/CD ) 99 ( billion/CD in/IN ) 99 ( in/IN september/NNP ) 99 ( september/NNP ./. ) 09 ( ./. NULL ) Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus ( 1995 ) , structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk , and structural relations 00 and 09 correspond to I-Chunk which represnts each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence. 2 ) Phrase category. This is used to identify the phrase categories of input tokens. 3 ) Part-of-speech. Because of the limited number of structural relations and phrase categories , the part-of-speech is added into the structural tag to represent more accurate models. For the above chunk tagged sentence , the structural tags for all the corresponding input tokens are : 90 PRt~NP ( He/PRP ) 99_VB Z_VP ( reckons/VBZ ) 99 DT NP ( the/DT ) O0 JJ NP ( currentJJJ ) 00_N/'~NP ( account/NN ) 00 N1NNP ( deficiffNN ) 99_MDSVP ( will/MD ) 00 VB_VP ( narrow/VB ) 99_TO PP ( to/TO ) 99_RB~ , IP ( only/RB ) oo_ # NP ( # / # ) 00 CD_NP ( 1.8/CD ) 0 ( ~CD~qP ( billion/CD ) 99_IN PP ( in/IN ) 99~lNP~ , lP ( september/NNP ) 99_._0 ( ./. ) As the baseline system , we assume P ( t i I G ? ) = P ( t i I pi ) . That is to say , only the current part-of-speech is used as a lexical entry to determine the current structural chunk tag. Here , we define : • • is the list of lexical entries in the chunking lexicon , 73 • \ [ @ \ [ is the number of lexical entries ( the size of the chunking lexicon ) • C is the training data. For the baseline system , we have : • @ = { pi , p~3C } , where Pi is a part-ofspeech existing in the tra\ ] Lning data C • \ ] @ \ [ =48 ( the number of part-of-speech tags in the training data ) . Table 1 gives an overview of the results of the chunking experiments. For convenience , precision , recall and F # _ 1 values are given seperately for the chunk types NP , VP , ADJP , ADVP and PP. Type Precision Recall Fa__~ Overall 87.01 89.68 88.32 NP 90.02 90.50 90.26 VP 89.86 93.14 91.47 ADJP 70.94 63.84 67.20 ADVP 57.98 80.33 I 67.35 PP 85.95 96.62 90.97 Table 1 : Results of chunking experiments with the lexical entry list : ~ = { pi , p~3C } In the last section , we only use current part-ofspeech as a lexical entry. In this section , we will attempt to add more contextual information to approximate P ( t i/G~ ) . This can be done by adding lexical entries with more contextual information into the lexicon ~. In the following , we will discuss five contextdependent lexicons which consider different contextual information. current word Here , we assume : e ( t i I G~ ) = I P ( ti I p~wi ) \ [ P ( tl I Pi ) where piwi ~ dp PiWi ~ dp ~= { piwi , piwi3C } + { pi , pi3C } and piwi is a part-of-speech and word pair existing in the training data C. In this case , the current part-of-speech and word pair is also used as a lexical entry to determine the current structural chunk tag and we have a total of about 49563 lexical entries ( \ [ • \ ] =49563 ) . Actually , the lexicon used here can be regarded as context-independent. The reason we discuss it in this section is to distinguish it from the context-independent lexicon used in the baseline system. Table 2 give an overview of the results of the chunking experiments on the test data. Type \ [ Precision Overall 90.32 NP 90.75 VP 90.88 ADJP 76.01 ADVP 72.67 PP 94.96 Table 2 : Results of chunking experiments the lexical entry = { piwi , Piwi3C } `` 1 '' { Pi '' Pi 3C } Recall Fa~.l 92.18 9i.24 92.14 91.44 92.78 91.82 70.00 72.88 88.33 79.74 96.48 95.71 with list : Table 2 shows that incorporation of current word information improves the overall F~=~ value by 2.9 % ( especially for the ADJP , ADVP and PP chunks ) , compared with Table 1 of the baseline system which only uses current part-ofspeech information. This result suggests that current word information plays a very important role in determining the current chunk tag. current part-of-speech Here , we assume : P ( t i / G~ ) I P ( ti / pi-lPi ) Pi-lPi E = \ [ P ( ti I Pi ) Pi- ! Pi ~ ~ where = { Pi-l Pi , P~-1Pi 3C } + { Pi , pi3C } and Pi-lPi is a pair of previous part-of-speech and current part-of-speech existing in the training data C. In this case , the previous part-of-speech and current part-of-speech pair is also used as a lexical entry to determine the current structural chunk tag and we have a total of about 1411 lexical entries ( l~\ ] =1411 ) . Table 3 give an overview of the results of the chunking experiments. 74 Type Overall Precision 88.63 NP 90.77 VP 92.46 ADJP 74.93 60.13 66.72 ADVP 71.65 73.21 72.42 PP 87.28 91.80 89.49 Table 3 : Results of chunking experiments with the lexical entry list : • = { Pi-lPi , Pi-lPi 3C } + { Pi , Pi 3C } Recall F # = I 89.00 88.82 91.18 90.97 92.98 92.72 Compared with Table 1 of the baseline system , Table 3 shows that additional contextual information of previous part-of-speech improves the overall F/~_~ value by 0.5 % . Especially , F/3_ ~ value for VP improves by 1.25 % , which indicates that previous part-of-speech information has a important role in determining the chunk type VP. Table 3 also shows that the recall rate for chunk type ADJP decrease by of-speech information makes ADJP chunks easier to merge with neibghbouring chunks. previous word and current part-of-speech Here , we assume : P ( t , / G~ ) IP ( ti / pi_lwi_lpi ) pi_lwi_lpl ~ dp I \ [ P ( ti \ [ Pi ) Pi-lWi-I Pi ~ ~ where = { Pi-i wi-l Pi , Pi-l wi-I Pi3 C } + { Pi , Pi 3 C } , where pi_lwi_lp~ is a triple pattern existing in the training corpus. In this case , the previous part-of-speech , previous word and current part-of-speech triple is also used as a lexical entry to determine the current structural chunk tag and } • 1=136164. Table 4 gives the results of the chunking experiments. Compared with Table 1 of the baseline system , Table 4 shows that additional 136116 new lexical entries of format Pi-lw~-lPi improves the overall F # = l value by system 2.2 which uses previous part-of-speech and current part-of-speech as a lexical entry , Table 4 shows that additional contextual information of previous word improves the overall Fa= 1 value by 2.8 % . Type Precision Recall F~=l Overall 91.23 92.03 91.63 NP 92.89 93.85 93.37 VP 94.10 94.23 94.16 ADJP 79.83 69.01 74.03 ADVP 76.91 80.53 78.68 PP 90.41 94.77 92.53 Table 4 : Results of chunking experiments with the lexical entry list : = { p , _lw~_~ p , , p , _~ w , _ip,3C } + { Pi , p~3C } part-of-speech and current word Here , we assume : P ( t i I G~ ) IP ( tt I Pi-i PiWi ) Pi-I piwi E dp \ [ P ( ti / Pi ) Pi-I Pi Wi ~ 1I ) where = { Pi-lPiWi , Pi-lP~W~ 3C } + { Pi , Pi3C } , where pi_lpiw~ is a triple pattern existing in the training and \ ] • \ [ =131416. Table 5 gives the results of the chunking experiments. Type Precision Recall F/3= 1 Overall 92.67 93.43 93.05 NP 93.35 94.10 93.73 VP 93.05 94.30 93.67 ADJP 80.65 72.27 76.23 ADVP 78.92 84.48 81.60 PP 95.30 96.67 95.98 Table 5 : Results of chunking experiments with the lexical entry list : = { Pi-lPiWi , P , -iP , w,3C } + { pi , Pi 3C } Compared with Table 2 of the extended system which uses current part-of-speech and current word as a lexical entry , Table 5 shows that additional contextual information of previous part-of-speech improves the overall Fa= 1 value by 1.8 % . previous word , current part-of-speech and current word Here , the context of previous part-of-speech , current part-of-speech and current word is used as a lexical entry to determine the current 75 structural chunk tag and qb = { Pi-l wi-lPiWi , Pi-lwi-~piwi 36 ' } + { Pi , Pi3C } , where p~_lWi_~P~W~ is a pattern existing in the training corpus. Due to memory limitation , only lexical entries which occurs : more than 1 times are kept. Out of 364365 possible lexical entries existing in the training data , 98489 are kept ( 1~ 1=98489 ) . = I P ( ti/Pi-\ ] wi- , PiWli ) \ [ P ( t , lp , ) pi_lwi_lpiwi ~ Table 6 gives the results of the chunking experiments. Type Overall NP VP ADJP ADVP PP Precision 92.28 93.50 92.62 81.39 75.09 94.12 Recall 93.04 93.53 94.07 72.17 86.23 97.12 F~=l 92.66 93.52 93.35 76.50 80.27 95.59 Table 6 : Results of chunking experiments with the lexical entry list : • = { Pi-l wi-\ ] PiWi , Pi-lwi-lpiwi3C } + { Pi , p~3C } Compared with Table 2 of the extended system which uses current part-of-speech and current word as a lexical entry , Table 6 shows that additional contextual information of previous part-of-speech improves the overall Ft3=l value by 1.8 % . Above experiments shows that adding more contextual information into lexicon significantly improves the chunking accuracy. However , this improvement is gained at the expense of a very large lexicon and we fred it difficult to merge all the above context-dependent lexicons in a single lexicon to further improve the chunking accurracy because of memory limitation. In order to reduce the size of lexicon effectively , an error-driven learning approach is adopted to examine the effectiveness of lexical entries and make it possible to further improve the chunking accuracy by merging all the above context-dependent lexicons in a single lexicon. This will be discussed in the next section. In section 2 , we implement a basefine system which only considers current part-of-speech as a lexical entry to dete , ufine the current chunk tag while in section 3 , we implement several extended systems which take more contextual information into consideration. Here , we will examine the effectiveness of lexical entries to reduce the size of lexicon and make it possible to further improve the chunking accuracy by merging several contextdependent lexicons in a single lexicon. For a new lexical entry e i , the effectiveness F~ ( e i ) is measured by the reduction in error which results from adding the lexical entry to -~ Error ( e , ) . the lexicon : F~ ( e i ) = F : rr°r ( e i ) o+Ao Here , F , ~ r~°r ( el ) is the chunking error number of the lexical entry e i for the old lexicon r~ Error / x and r~ , +~ te i ) is the chunking error number of the lexical entry e i for the new lexicon + AO where e~ e A~ ( A~ is the list of new lexical entries added to the old lexicon ~ ) . If F o ( e i ) &gt; 0 , we define the lexical entry ei as positive for lexicon ~ .</sentence>
				<definiendum id="0">NULL</definiendum>
				<definiendum id="1">corresponding input tokens</definiendum>
				<definiendum id="2">PRt~NP</definiendum>
				<definiendum id="3">Pi</definiendum>
				<definiendum id="4">piwi</definiendum>
				<definiendum id="5">p~_lWi_~P~W~</definiendum>
				<definiendum id="6">r~ , +~ te i )</definiendum>
				<definiens id="0">the mutual information between G~ and T1 ~ is equal to the summation of mutual information between G~ and the individual tag ti ( l_ &lt; i_ &lt; n ) : n log P ( TI '' ' G ? ) = ~ log P ( t , , G~ ) e ( Tln ) . P ( G~ ) i=1 P ( t , ) . P ( G ? ) or n n MI ( T~ ~ , G~ ) = ~ MI ( t , , G ? ) , i=l we have : log P ( T~ n I G~ ) = log P ( T1 n ) + ~ , log P ( ti ' G ? ) _ P ( t i ) . P ( G ? ) rl n = log P ( T1 ~ ) Z log P ( t , ) + ~ log P ( t , \ [ G ? ) i=1 i=1 The first item of above equation can be solved by using chain rules. Normally , each tag is assumed to be probabilistic dependent on the N-1 previous tags. Here , backoff bigram ( N=2 ) model is used. The second item is the summation of log probabilities of all the tags. Both the first item and second item correspond to the language model component of the tagger while the third item corresponds to the lexicon component of the tagger. Ideally the third item can be estimated by using the forward-backward algorithm ( Rabiner 1989 ) recursively for the first-order ( Rabiner 1989 ) or second-order HMMs ( Watson and Chunk 1992 ) . However , several approximations on it will be attempted later in this paper instead. The stochastic optimal tag sequence can be found by maxmizing the above equation over all the possible tag sequences. This is implemented by the Viterbi algorithm. The main difference between our tagger and other standard taggers lies in our tagger has a context-dependent lexicon while others use a context-independent lexicon. For chunk tagger , we haveg 1 = piwi where W~ n = w~w2 -- -w n is the word-sequence and P~ = PiP2 `` '' P~ is the part-of-speech 72 sequence. Here , we use structural tags to representing chunking ( bracketing and labelling ) structure. The basic idea of representing the structural tags is similar to Skut and Brants ( 1998 ) and the structural tag consists of three parts : 1 ) Structural relation. The basic idea is simple : structures of limited depth are encoded using a finite number of flags. Given a sequence of input tokens ( here , the word and part-of-speech pairs ) , we consider the structural relation between the previous input token and the current one. For the recognition of chunks , it is sufficient to distinguish the following four different structural relations which uniquely identify the sub-structures of depth l ( Skut and Brants used seven different structural relations to identify the sub-structures of depth 2 ) . 00 the current input token and the previous one have the same parent 90 one ancestor of the current input token and the previous input token have the same parent 09 the current input token and one ancestor of the previous input token have the same parent 99 one ancestor of the current input token and one ancestor of the previous input token have the same parent For example , in the following chunk tagged sentence</definiens>
				<definiens id="1">the beginning and end of the sentence ) : NULL \ [ NP He/PRP\ ] \ [ VP reckons/VBZ\ ] \ [ NP the/DT current/JJ account/NN deficit/NN\ ] \ [ VP will/MD narrow/VB\ ] \ [ PP to/TO\ ] \ [ NP only/RB # / # 1.8/CD billion/CD\ ] \ [ PP in/IN\ ] \ [ NP September/NNP\ ] \ [ O ./.\ ] NULL the corresponding structural relations between two adjacent input tokens</definiens>
				<definiens id="2">in/IN september/NNP ) 99 ( september/NNP ./. ) 09 ( ./. NULL ) Compared with the B-Chunk and I-Chunk used in Ramshaw and Marcus ( 1995 ) , structural relations 99 and 90 correspond to B-Chunk which represents the first word of the chunk , and structural relations 00 and 09 correspond to I-Chunk which represnts each other in the chunk while 90 also means the beginning of the sentence and 09 means the end of the sentence. 2 ) Phrase category. This is used to identify the phrase categories of input tokens. 3 ) Part-of-speech. Because of the limited number of structural relations and phrase categories , the part-of-speech is added into the structural tag to represent more accurate models. For the above chunk tagged sentence , the structural tags for all the</definiens>
				<definiens id="3">( t i I G ? ) = P ( t i I pi ) . That is to say , only the current part-of-speech is used as a lexical entry to determine the current structural chunk tag. Here</definiens>
				<definiens id="4">the list of lexical entries in the chunking lexicon , 73 • \ [ @ \ [ is the number of lexical entries ( the size of the chunking lexicon ) • C is the training data. For the baseline system</definiens>
				<definiens id="5">a part-ofspeech existing in the tra\ ] Lning data C • \ ] @ \ [ =48 ( the number of part-of-speech tags in the training data ) . Table 1 gives an overview of the results of the chunking experiments. For convenience , precision , recall and F # _ 1 values are given seperately for the chunk types NP , VP , ADJP , ADVP and PP. Type Precision Recall Fa__~ Overall</definiens>
				<definiens id="6">contextual information to approximate P ( t i/G~ ) . This can be done by adding lexical entries with more contextual information into the lexicon ~. In the following , we will discuss five contextdependent lexicons which consider different contextual information. current word Here , we assume : e ( t i I G~ ) = I P ( ti I p~wi ) \ [ P ( tl I Pi ) where piwi ~ dp PiWi ~ dp ~= { piwi , piwi3C } + { pi</definiens>
				<definiens id="7">a part-of-speech and word pair existing in the training data C. In this case , the current part-of-speech and word pair is also used as a lexical entry to determine the current structural chunk tag and we have a total of about 49563 lexical entries ( \ [ • \ ] =49563 ) . Actually , the lexicon used here can be regarded as context-independent. The reason we discuss it in this section is to distinguish it from the context-independent lexicon used in the baseline system. Table 2 give an overview of the results of the chunking experiments on the test data. Type \ [ Precision Overall</definiens>
				<definiens id="8">Results of chunking experiments the lexical entry = { piwi , Piwi3C } `` 1 '' { Pi '' Pi 3C } Recall Fa~.l 92.18 9i.24 92.14 91.44 92.78 91.82 70.00 72.88 88.33 79.74 96.48 95.71 with list : Table 2 shows that incorporation of current word information improves the overall F~=~ value by 2.9 % ( especially for the ADJP , ADVP and PP chunks ) , compared with Table 1 of the baseline system which only uses current part-ofspeech information. This result suggests that current word information plays a very important role in determining the current chunk tag. current part-of-speech Here , we assume : P ( t i / G~ ) I P ( ti / pi-lPi ) Pi-lPi E = \ [ P ( ti I Pi ) Pi- ! Pi ~ ~ where = { Pi-l Pi , P~-1Pi 3C } + { Pi , pi3C } and Pi-lPi is a pair of previous part-of-speech and current part-of-speech existing in the training data C. In this case , the previous part-of-speech and current part-of-speech pair is also used as a lexical entry to determine the current structural chunk tag</definiens>
				<definiens id="9">Results of chunking experiments with the lexical entry list : • = { Pi-lPi , Pi-lPi 3C } + { Pi , Pi 3C } Recall F # = I 89.00 88.82 91.18 90.97 92.98 92.72 Compared with Table 1 of the baseline system , Table 3 shows that additional contextual information of previous part-of-speech improves the overall F/~_~ value by 0.5 % . Especially , F/3_ ~ value for VP improves by 1.25 % , which indicates that previous part-of-speech information has a important role in determining the chunk type VP. Table 3 also shows that the recall rate for chunk type ADJP decrease by of-speech information makes ADJP chunks easier to merge with neibghbouring chunks. previous word and current part-of-speech Here , we assume : P ( t , / G~ ) IP ( ti / pi_lwi_lpi ) pi_lwi_lpl ~ dp I \ [ P ( ti \ [ Pi ) Pi-lWi-I Pi ~ ~ where = { Pi-i wi-l Pi , Pi-l wi-I Pi3 C } + { Pi , Pi 3 C } , where pi_lwi_lp~ is a triple pattern existing in the training corpus. In this case , the previous part-of-speech , previous word and current part-of-speech triple is also used as a lexical entry to determine the current structural chunk tag and } • 1=136164. Table 4 gives the results of the chunking experiments. Compared with Table 1 of the baseline system , Table 4 shows that additional 136116 new lexical entries of format Pi-lw~-lPi improves the overall F # = l value by system 2.2 which uses previous part-of-speech and current part-of-speech as a lexical entry , Table 4 shows that additional contextual information of previous word improves the overall Fa= 1 value by 2.8 % . Type Precision Recall F~=l Overall</definiens>
				<definiens id="10">Results of chunking experiments with the lexical entry list : = { p , _lw~_~ p , , p , _~ w , _ip,3C } + { Pi , p~3C } part-of-speech and current word Here , we assume : P ( t i I G~ ) IP ( tt I Pi-i PiWi ) Pi-I piwi E dp \ [ P ( ti / Pi ) Pi-I Pi Wi ~ 1I ) where = { Pi-lPiWi , Pi-lP~W~ 3C } + { Pi , Pi3C } , where pi_lpiw~ is a triple pattern existing in the training and \ ] • \ [ =131416. Table 5 gives the results of the chunking experiments. Type Precision Recall</definiens>
				<definiens id="11">Results of chunking experiments with the lexical entry list : = { Pi-lPiWi , P , -iP , w,3C } + { pi , Pi 3C } Compared with Table 2 of the extended system which uses current part-of-speech and current word as a lexical entry , Table 5 shows that additional contextual information of previous part-of-speech improves the overall Fa= 1 value by 1.8 % . previous word , current part-of-speech and current word Here , the context of previous part-of-speech , current part-of-speech and current word is used as a lexical entry to determine the current 75 structural chunk tag and qb = { Pi-l wi-lPiWi , Pi-lwi-~piwi 36 ' } + { Pi</definiens>
				<definiens id="12">a pattern existing in the training corpus. Due to memory limitation , only lexical entries which occurs : more than 1 times are kept. Out of 364365 possible lexical entries existing in the training data , 98489 are kept ( 1~ 1=98489 ) . = I P ( ti/Pi-\ ] wi- , PiWli ) \ [ P ( t , lp , ) pi_lwi_lpiwi ~ Table 6 gives the results of the chunking experiments. Type Overall NP VP ADJP ADVP PP Precision 92.28 93.50 92.62 81.39 75.09 94.12 Recall 93.04 93.53 94.07 72.17 86.23 97.12 F~=l 92.66 93.52 93.35 76.50 80.27 95.59 Table 6 : Results of chunking experiments with the lexical entry list : • = { Pi-l wi-\ ] PiWi , Pi-lwi-lpiwi3C } + { Pi , p~3C } Compared with Table 2 of the extended system which uses current part-of-speech and current word as a lexical entry , Table 6 shows that additional contextual information of previous part-of-speech improves the overall Ft3=l value by 1.8 % . Above experiments shows that adding more contextual information into lexicon significantly improves the chunking accuracy. However , this improvement is gained at the expense of a very large lexicon and we fred it difficult to merge all the above context-dependent lexicons in a single lexicon to further improve the chunking accurracy because of memory limitation. In order to reduce the size of lexicon effectively , an error-driven learning approach is adopted to examine the effectiveness of lexical entries and make it possible to further improve the chunking accuracy by merging all the above context-dependent lexicons in a single lexicon. This will be discussed in the next section. In section 2 , we implement a basefine system which only considers current part-of-speech as a lexical entry to dete , ufine the current chunk tag while in section 3 , we implement several extended systems which take more contextual information into consideration. Here , we will examine the effectiveness of lexical entries to reduce the size of lexicon and make it possible to further improve the chunking accuracy by merging several contextdependent lexicons in a single lexicon. For a new lexical entry e i , the effectiveness F~ ( e i ) is measured by the reduction in error which results from adding the lexical entry to -~ Error ( e , ) . the lexicon : F~ ( e i ) = F : rr°r ( e i ) o+Ao Here , F , ~ r~°r ( el ) is the chunking error number of the lexical entry e i for the old lexicon r~ Error / x</definiens>
				<definiens id="13">the chunking error number of the lexical entry e i for the new lexicon + AO where e~ e A~ ( A~ is the list of new lexical entries added to the old lexicon</definiens>
			</definition>
</paper>

		<paper id="0306">
			<definition id="0">
				<sentence>The model is the probability distribution P ( nk ) = P ( nklck ) , where nk is the number of attributes and Ck is the utterance class for system utte~anee k. This model will predict which attributes to use in a system utterance .</sentence>
				<definiendum id="0">model</definiendum>
				<definiendum id="1">nk</definiendum>
				<definiendum id="2">Ck</definiendum>
				<definiens id="0">the probability distribution P ( nk ) = P ( nklck )</definiens>
				<definiens id="1">the number of attributes</definiens>
				<definiens id="2">the utterance class for system utte~anee</definiens>
			</definition>
			<definition id="1">
				<sentence>In other words , W* = arg max P ( WIA ) = arg max P ( AI W ) Pr ( W ) where W is the string of words , wl , ... , wn , and A is the acoustic evidence ( Jelinek 1998 ) .</sentence>
				<definiendum id="0">W</definiendum>
				<definiendum id="1">A</definiendum>
				<definiens id="0">the string of words , wl , ... , wn</definiens>
				<definiens id="1">the acoustic evidence</definiens>
			</definition>
			<definition id="2">
				<sentence>( n.1 ) , U ) where u is the utterance class .</sentence>
				<definiendum id="0">u</definiendum>
				<definiens id="0">the utterance class</definiens>
			</definition>
			<definition id="3">
				<sentence>The generation engine generates a candidate utterance , scores it , keeping only the best-scored utterance up to that point .</sentence>
				<definiendum id="0">generation engine</definiendum>
				<definiens id="0">generates a candidate utterance</definiens>
			</definition>
</paper>

		<paper id="0409">
			<definition id="0">
				<sentence>There are a number of different studies that address graphical presentation of multi-document ( or document corpus visualization ) The VIBE System ( Olsen et al. , 1993 ; Korfhage and Olsen , 1995 ) , Galaxy ( Rennison , 1994 ) , SPIRE Themescapes ( Wise et al. , 1995 ) , LyberWodd ( Hemmje et al. , 1994 ) , and applications of self-organizing map utilizing neural network technique ( Kohonen , 1997 ; Lin , 1993 ; Lagus et al. , 1996 ) .</sentence>
				<definiendum id="0">VIBE System</definiendum>
				<definiendum id="1">LyberWodd</definiendum>
				<definiens id="0">a number of different studies that address graphical presentation of multi-document ( or document corpus visualization</definiens>
				<definiens id="1">Hemmje et al. , 1994 ) , and applications of self-organizing map utilizing neural network technique</definiens>
			</definition>
			<definition id="1">
				<sentence>A document map is a projection of document vectors onto a topic vector .</sentence>
				<definiendum id="0">document map</definiendum>
				<definiens id="0">a projection of document vectors onto a topic vector</definiens>
			</definition>
			<definition id="2">
				<sentence>Document # 3 : Mike Smith is a programmer for XYZ Corporation .</sentence>
				<definiendum id="0">Mike Smith</definiendum>
				<definiens id="0">a programmer for XYZ Corporation</definiens>
			</definition>
			<definition id="3">
				<sentence>The whole infrastructure ( hereafter referred to as TEXTRACT ) is designed from the ground up to perform a variety of linguistic feature extraction functions , ranging from straightforward , single pass , tokenization , lexical look-up and morphological analysis , to complex aggregation of representative ( salient ) phrasal units across large multidocument collections ( Boguraev and Neff , 2000 ) .</sentence>
				<definiendum id="0">whole infrastructure</definiendum>
				<definiens id="0">ranging from straightforward , single pass , tokenization , lexical look-up and morphological analysis , to complex aggregation of representative ( salient ) phrasal units across large multidocument collections</definiens>
			</definition>
			<definition id="4">
				<sentence>( s4 ) # 3 : Mike Smith is a programmer for XYZ corporation .</sentence>
				<definiendum id="0">Mike Smith</definiendum>
				<definiens id="0">a programmer for XYZ corporation</definiens>
			</definition>
			<definition id="5">
				<sentence>Regarding the number of terms contained in one sentence as a constant , topic sentences are ext : racted in O ( skh ) time where s is the total number of sentences in the document set .</sentence>
				<definiendum id="0">s</definiendum>
				<definiens id="0">the total number of sentences in the document set</definiens>
			</definition>
			<definition id="6">
				<sentence>Each leaf node has an associated goal , which , when realized , provides content for that node .</sentence>
				<definiendum id="0">associated goal</definiendum>
				<definiens id="0">provides content for that node</definiens>
			</definition>
			<definition id="7">
				<sentence>The briefing generator takes the script as input .</sentence>
				<definiendum id="0">briefing generator</definiendum>
				<definiens id="0">takes the script as input</definiens>
			</definition>
			<definition id="8">
				<sentence>The Script Validator applies an XML parser to the script , to check for syntactic correctness .</sentence>
				<definiendum id="0">Script Validator</definiendum>
				<definiens id="0">applies an XML parser to the script , to check for syntactic correctness</definiens>
			</definition>
			<definition id="9">
				<sentence>Next , a Content Creator takes the input tree and expands it by introducing narrative-level goals including segues to content nodes , and running text and captions describing media objects at content nodes .</sentence>
				<definiendum id="0">Content Creator</definiendum>
				<definiens id="0">takes the input tree and expands it by introducing narrative-level goals including segues to content nodes</definiens>
			</definition>
			<definition id="10">
				<sentence>Then , a Content Executor executes all the create and retrieve goals .</sentence>
				<definiendum id="0">Content Executor</definiendum>
			</definition>
			<definition id="11">
				<sentence>Finely , the Presentation Generator takes the tree which is output from Content Execution , along with its temporal ordering constraints , and generates the spatial layout of the presentation .</sentence>
				<definiendum id="0">Presentation Generator</definiendum>
				<definiens id="0">takes the tree which is output from Content Execution , along with its temporal ordering constraints , and generates the spatial layout of the presentation</definiens>
			</definition>
			<definition id="12">
				<sentence>Among the core technology standards that support this plug-and-play component assembly capability are ( a ) Java interfaces , used to specify functions that all summarization components must implement in order to be used in the system , ( b ) the JavaBeans standard , which allows the parameters and methods of individual components to be inspected by the system and revealed to the users ( c ) the XML markup standard , which we have adopted as an intercomponent communication language .</sentence>
				<definiendum id="0">JavaBeans standard</definiendum>
				<definiens id="0">allows the parameters and methods of individual components to be inspected by the system and revealed to the users ( c ) the XML markup standard</definiens>
				<definiens id="1">an intercomponent communication language</definiens>
			</definition>
			<definition id="13">
				<sentence>The Content Creator , when providing content for narrative nodes , uses a variety of different canned text patterns .</sentence>
				<definiendum id="0">Content Creator</definiendum>
				<definiens id="0">uses a variety of different canned text patterns</definiens>
			</definition>
			<definition id="14">
				<sentence>Victor Polay , also known as Comandante Rolando , is the Tupac Amaru founder , a Peruvianguerrilla commander , a former rebel leader , and the Tupac Amaru rebels ' top leader .</sentence>
				<definiendum id="0">Comandante Rolando</definiendum>
				<definiens id="0">the Tupac Amaru founder , a Peruvianguerrilla commander , a former rebel leader , and the Tupac Amaru rebels ' top leader</definiens>
			</definition>
</paper>

		<paper id="1421">
			<definition id="0">
				<sentence>Extrapositions are the linguistic means in German to separate sense units .</sentence>
				<definiendum id="0">Extrapositions</definiendum>
				<definiens id="0">the linguistic means in German to separate sense units</definiens>
			</definition>
			<definition id="1">
				<sentence>Generally , the realized word order of an utterance is the result of its embedding into the situative context , which finds expression in the use of linear precedence ( LP ) rules for word order determination during surface realization .</sentence>
				<definiendum id="0">realized word order of an utterance</definiendum>
				<definiens id="0">the result of its embedding into the situative context , which finds expression in the use of linear precedence ( LP ) rules for word order determination during surface realization</definiens>
			</definition>
			<definition id="2">
				<sentence>In our approach we derive the information necessary for the use of LP-rules from a discourse model that relates various aspects of a discourse to one another .</sentence>
				<definiendum id="0">discourse model</definiendum>
				<definiens id="0">relates various aspects of a discourse to one another</definiens>
			</definition>
			<definition id="3">
				<sentence>Our discourse model is a knowledge store consisting of two major registers .</sentence>
				<definiendum id="0">discourse model</definiendum>
				<definiens id="0">a knowledge store consisting of two major registers</definiens>
			</definition>
			<definition id="4">
				<sentence>H is a pair ( RA , RN } consisting of referents of tile directly preceding utterance and referents of all-other previous utterances .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">a pair</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , the input for realizing example ( 1 ) is as follows : focus : \ [ fallingDowa ( e , m ) , into ( e , s ) , stonePlateau ( s ) , definiteld ( s ) , refReEstablishment ( s ) \ ] ground : \ [ man ( m ) , anaphld ( m ) , refMaintenance ( m ) , topic ( m ) \ ] The constants m , s , and e are referents for a specific man , stone plateau , and tile evenl of falling down .</sentence>
				<definiendum id="0">stonePlateau</definiendum>
				<definiendum id="1">refMaintenance</definiendum>
				<definiens id="0">s ) , definiteld ( s ) , refReEstablishment ( s ) \ ] ground : \ [ man ( m ) , anaphld ( m ) ,</definiens>
			</definition>
			<definition id="6">
				<sentence>While tile realization of the focus domain is the task of converting the complete focus into one phrase , word order will be determined by LP-rules that pick up the pragmaticall2 , ' motivated literals on topichood , identifial ) ility , and referential movement .</sentence>
				<definiendum id="0">tile realization of the focus domain</definiendum>
				<definiens id="0">the task of converting the complete focus into one phrase</definiens>
			</definition>
			<definition id="7">
				<sentence>Let the content of the discourse model be as follows : RAo = @ RNo = { s , m , d , ... } A'O = { desertPlateau ( d ) , stonePlateau ( s ) , littleMan ( m ) , fallingDowll ( e , m ) , ... } Refo = { refMaintenance ( s ) , refReEstablishme~t ( m ) , ... } Alto = { alt ( stonePlatea , ( s ) , { desertPlateau ( d ) } ) , alt ( in ( e , s ) , { on ( e , s ) } ) } Id 0 = { definiteld ( m ) , definiteld ( s ) , ... } .1Note that determiners as bearers of nucleus accents do not constitute a problem for our system .</sentence>
				<definiendum id="0">stonePlateau</definiendum>
				<definiendum id="1">alt</definiendum>
				<definiens id="0">the content of the discourse model be as follows : RAo = @ RNo = { s , m , d</definiens>
			</definition>
</paper>

		<paper id="1434">
			<definition id="0">
				<sentence>RSTTool is a graphical tool for annotating a text in terms of its rhetorical structure .</sentence>
				<definiendum id="0">RSTTool</definiendum>
				<definiens id="0">a graphical tool for annotating a text in terms of its rhetorical structure</definiens>
			</definition>
			<definition id="1">
				<sentence>The tool can automatically segment at sentence boundaries ( with reasonable accuracy ) , and the user clicks on the text to add boundaries missed by the automatic segmenter ( or click on superfluous boundaries to remove them ) .</sentence>
				<definiendum id="0">automatic segmenter</definiendum>
				<definiens id="0">with reasonable accuracy ) , and the user clicks on the text to add boundaries missed by the</definiens>
			</definition>
			<definition id="2">
				<sentence>The Tool consists of four interfaces , which will be described in following sections : between text segments ; lations between these segments ; course relations , and schemas ; istics based on the analysis .</sentence>
				<definiendum id="0">Tool</definiendum>
				<definiens id="0">consists of four interfaces , which will be described in following sections : between text segments ; lations between these segments ; course relations , and schemas ; istics based on the analysis</definiens>
			</definition>
			<definition id="3">
				<sentence>The RSTTool is an analysis tool , but most users of the tool are researchers in the text generation field .</sentence>
				<definiendum id="0">RSTTool</definiendum>
				<definiens id="0">an analysis tool , but most users of the tool are researchers in the text generation field</definiens>
			</definition>
			<definition id="4">
				<sentence>Because RST-structures can become very elaborate , the RSTTool allows the user to collapse subtrees hiding the substructure under a node .</sentence>
				<definiendum id="0">RSTTool</definiendum>
				<definiens id="0">allows the user to collapse subtrees hiding the substructure under a node</definiens>
			</definition>
			<definition id="5">
				<sentence>RSTTool is a robust tool which facilitates manual analysis of a text 's rhetorical structure .</sentence>
				<definiendum id="0">RSTTool</definiendum>
				<definiens id="0">a robust tool which facilitates manual analysis of a text 's rhetorical structure</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>WIT features an incremental understanding mechanism that enables robust utterance understanding and realtime responses .</sentence>
				<definiendum id="0">WIT</definiendum>
				<definiens id="0">features an incremental understanding mechanism that enables robust utterance understanding and realtime responses</definiens>
			</definition>
			<definition id="1">
				<sentence>One is the CSLU Toolkit ( Sutton et al. , 1998 ) , which enables rapid prototyping of a spoken dialogue system that incorporates a finite-state dialogue model .</sentence>
				<definiendum id="0">CSLU Toolkit</definiendum>
				<definiens id="0">enables rapid prototyping of a spoken dialogue system that incorporates a finite-state dialogue model</definiens>
			</definition>
			<definition id="2">
				<sentence>This paper presents WIT 1 , which is a toolkit IWIT is an acronym of Workable spoken dialogue lnter150 for building spoken dialogue systems that integrate speech recognition , language understanding and generation , and speech output .</sentence>
				<definiendum id="0">IWIT</definiendum>
				<definiens id="0">an acronym of Workable spoken dialogue lnter150 for building spoken dialogue systems that integrate speech recognition , language understanding and generation , and speech output</definiens>
			</definition>
			<definition id="3">
				<sentence>WIT features an incremental understanding method ( Nakano et al. , 1999b ) that makes it possible to build a robust and real-time system .</sentence>
				<definiendum id="0">WIT</definiendum>
				<definiens id="0">features an incremental understanding method ( Nakano et al. , 1999b ) that makes it possible to build a robust and real-time system</definiens>
			</definition>
			<definition id="4">
				<sentence>The speech recognition module is a phonemeHMM-based speaker-independent continuous speech recognizer that incrementally outputs face Toolldt .</sentence>
				<definiendum id="0">speech recognition module</definiendum>
				<definiens id="0">a phonemeHMM-based speaker-independent continuous speech recognizer that incrementally outputs face Toolldt</definiens>
			</definition>
			<definition id="5">
				<sentence>The language model for speech recognition is a network ( regular ) grammar , and it allows each speech interval to be an arbitrary number of phrases .</sentence>
				<definiendum id="0">language model for speech recognition</definiendum>
				<definiens id="0">a network ( regular ) grammar , and it allows each speech interval to be an arbitrary number of phrases</definiens>
			</definition>
			<definition id="6">
				<sentence>A phrase is a sequence of words , which is to be defined in a domain-dependent way .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">a sequence of words , which is to be defined in a domain-dependent way</definiens>
			</definition>
			<definition id="7">
				<sentence>A bunsetsu consists of one content word and a number ( possibly zero ) of function words .</sentence>
				<definiendum id="0">bunsetsu</definiendum>
				<definiens id="0">consists of one content word and a number ( possibly zero ) of function words</definiens>
			</definition>
			<definition id="8">
				<sentence>The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search ) ( Nakano et al. , 1999b ) , which is an integrated parsing and discourse processing method .</sentence>
				<definiendum id="0">ISSS ( Incremental Significant-utterance Sequence Search )</definiendum>
				<definiens id="0">an integrated parsing and discourse processing method</definiens>
			</definition>
			<definition id="9">
				<sentence>The domain-dependent knowledge used in this module consists of a unification-based lexicon and phrase structure rules .</sentence>
				<definiendum id="0">domain-dependent knowledge</definiendum>
				<definiens id="0">a unification-based lexicon and phrase structure rules</definiens>
			</definition>
			<definition id="10">
				<sentence>The phrase structure rules specify what kind of phrase sequences can be considered as sentences , and they also enable computing the semantic representation for found sentences .</sentence>
				<definiendum id="0">phrase structure rules</definiendum>
				<definiens id="0">sentences , and they also enable computing the semantic representation for found sentences</definiens>
			</definition>
			<definition id="11">
				<sentence>Each definition is a pair comprising a phrase category name and a network of word categories .</sentence>
				<definiendum id="0">definition</definiendum>
				<definiens id="0">a pair comprising a phrase category name and a network of word categories</definiens>
			</definition>
			<definition id="12">
				<sentence>opt means an option and or means a disjunction .</sentence>
				<definiendum id="0">opt</definiendum>
				<definiens id="0">means an option and or means a disjunction</definiens>
			</definition>
			<definition id="13">
				<sentence>Phase Definitions : Each phase definition consists of a phase name , a network name , an initiative holder specification , an initial function , an action function , a maximum silence duration , and a time-out function .</sentence>
				<definiendum id="0">Phase Definitions</definiendum>
				<definiens id="0">Each phase definition consists of a phase name , a network name , an initiative holder specification</definiens>
			</definition>
			<definition id="14">
				<sentence>The network name is the identifier of the language model for the speech recognition .</sentence>
				<definiendum id="0">network name</definiendum>
				<definiens id="0">the identifier of the language model for the speech recognition</definiens>
			</definition>
			<definition id="15">
				<sentence>In this phase , the maximum silence duration is ten seconds and the name of the time-out function is requestphas et imeou t. ( request `` fmr_request '' moveto-reques t -phase request-phase-action 10.0 request-phaset imeout ) For the definitions of these functions , WIT provides functions for accessing the dialogue state , sending a request to speak to the speech output module , generating strings to be spoken using surface generation templates , shifting the dialogue phase , taking and releasing the initiative , and so on .</sentence>
				<definiendum id="0">WIT</definiendum>
				<definiens id="0">spoken using surface generation templates , shifting the dialogue phase , taking and releasing the initiative , and so on</definiens>
			</definition>
			<definition id="16">
				<sentence>Surface-generation Templates : Surfacegeneration templates are used by the surface generation library function , which converts a list-structured semantic representation to a sequence of strings .</sentence>
				<definiendum id="0">Surface-generation Templates</definiendum>
				<definiens id="0">converts a list-structured semantic representation to a sequence of strings</definiens>
			</definition>
			<definition id="17">
				<sentence>( ( date ( date-expression *month *day ) ) ( ( *month gatsu ) ( *day nichi ) ) ) The surface generation library function matches the input semantic representation with the first element of the template and checks if a sequences 155 of strings appear in the speech file list .</sentence>
				<definiendum id="0">surface generation library function</definiendum>
				<definiens id="0">matches the input semantic representation with the first element of the template and checks if a sequences 155 of strings appear in the speech file list</definiens>
			</definition>
			<definition id="18">
				<sentence>This paper described WIT , a toolkit for building spoken dialogue systems .</sentence>
				<definiendum id="0">WIT</definiendum>
				<definiens id="0">a toolkit for building spoken dialogue systems</definiens>
			</definition>
</paper>

		<paper id="0103">
			<definition id="0">
				<sentence>Introduction This paper presents an algorithm for finding systematic polysemous classes in WordNet ( Miller et al 1990 ) and GermaNet ( Hamp and Feldweg 1997 ) -a semantic database for German similar to WordNet .</sentence>
				<definiendum id="0">GermaNet</definiendum>
				<definiens id="0">-a semantic database for German similar to WordNet</definiens>
			</definition>
			<definition id="1">
				<sentence>Systematic Polysemous Classes In lexical semantics , a distinction can be made between senses that are of a contrastive and those that are of a complementary nature ( Weinreich 1964 ) .</sentence>
				<definiendum id="0">Systematic Polysemous Classes</definiendum>
			</definition>
</paper>

		<paper id="0311">
			<definition id="0">
				<sentence>Logic is indeed an excellent way to think about representing static relationships like database queries , but it is much less clear that it is a good way to represent commands .</sentence>
				<definiendum id="0">Logic</definiendum>
				<definiens id="0">an excellent way to think about representing static relationships like database queries</definiens>
			</definition>
			<definition id="1">
				<sentence>The real PSA is a miniature robot currently being developed at NASA Ames Research Center , which is intended for deployment on the Space Shuttle and/or International Space Station .</sentence>
				<definiendum id="0">PSA</definiendum>
				<definiens id="0">a miniature robot currently being developed at NASA Ames Research Center , which is intended for deployment on the Space Shuttle and/or International Space Station</definiens>
			</definition>
			<definition id="2">
				<sentence>The initial PSA speech interface demo consists of a simple simulation of the Shuttle .</sentence>
				<definiendum id="0">PSA speech interface demo</definiendum>
			</definition>
			<definition id="3">
				<sentence>State parameters include the PSA 's current position , some environmental variables such as local temperature , pressure and carbon dioxide levels , and the status of the Shuttle 's doors ( open/closed ) .</sentence>
				<definiendum id="0">State parameters</definiendum>
				<definiens id="0">include the PSA 's current position , some environmental variables such as local temperature , pressure and carbon dioxide levels , and the status of the Shuttle 's doors ( open/closed )</definiens>
			</definition>
			<definition id="4">
				<sentence>There is one script interpreter , which functions both as a script executive and a script evaluator , and one set of rules which defines the procedural semantics of script actions .</sentence>
				<definiendum id="0">script interpreter</definiendum>
				<definiendum id="1">rules</definiendum>
				<definiens id="0">functions both as a script executive and a script evaluator</definiens>
				<definiens id="1">defines the procedural semantics of script actions</definiens>
			</definition>
			<definition id="5">
				<sentence>\ [ PSA starts moving to commander 's seat\ ] 10 .</sentence>
				<definiendum id="0">PSA</definiendum>
			</definition>
</paper>

		<paper id="1214">
			<definition id="0">
				<sentence>During keyword extraction , the document is first segmented and converted into a keyword frequency vector ( t fl , t f2 , ... , t.f M ) , where tfi is the in-document term frequency of keyword wi , and M is the number of the keyword features selected .</sentence>
				<definiendum id="0">tfi</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">the in-document term frequency of keyword wi</definiens>
			</definition>
			<definition id="1">
				<sentence>frequency ( IDF ) ( Salton , 1988 ) and the L1norm~llzation are then applied on the frequency vector to produce the keyword feature vector ( Xl , X2 , • • , XM ) x = max { xi } ' ( i ) in which xi is computed by zi = ( 1 + log 2 tfi ) log2 ~ ( 2 ) ni ' where n is the number of documents in the whole training set , and ni is the number of training documents in which the keyword wi occurs at least once .</sentence>
				<definiendum id="0">frequency</definiendum>
				<definiendum id="1">IDF )</definiendum>
				<definiendum id="2">n</definiendum>
				<definiendum id="3">ni</definiendum>
				<definiens id="0">applied on the frequency vector to produce the keyword feature vector ( Xl , X2 , • • , XM ) x = max { xi } ' ( i ) in which xi is computed by zi = ( 1 + log 2 tfi</definiens>
				<definiens id="1">the number of documents in the whole training set</definiens>
				<definiens id="2">the number of training documents in which the keyword wi occurs at least once</definiens>
			</definition>
			<definition id="2">
				<sentence>In essence , kNN makes the prediction based on the k training patterns that are closest to the unseen ( test ) pattern , according to a distance metric .</sentence>
				<definiendum id="0">kNN</definiendum>
				<definiens id="0">makes the prediction based on the k training patterns that are closest to the unseen ( test ) pattern , according to a distance metric</definiens>
			</definition>
			<definition id="3">
				<sentence>arg'max , { n ( dj , ) ld. : j kNN } , ( 4 ) where n ( dj , ~ ) is the number of training pattern dj in the k nearest neighbor set that are associated with class c4 .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of training pattern dj in the k nearest neighbor set that are associated with class c4</definiens>
			</definition>
			<definition id="4">
				<sentence>Based on the structural risk minimization principle from the computational learning theory , SVM seeks a decision surface to separate the tralning data points into two classes and makes decisions based on the support vectors that are selected as the only effective elements from the training set .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">the only effective elements from the training set</definiens>
			</definition>
			<definition id="5">
				<sentence>The separating hyper-plane can be identified by the pair ( w , b ) that satisfies w-x+b=0 and yi ( w'xi + b ) &gt; l ( 5 ) for i = 1 , 2 , ... , N ; where the dot product operation • is defined by w. x -- -~ wixi ( 6 ) for vectors w and x. Thus the goal of the SVM learning is to find the optimal separating hyper-plane ( OSH ) that has the maximal margin to both sides .</sentence>
				<definiendum id="0">separating hyper-plane</definiendum>
				<definiens id="0">to find the optimal separating hyper-plane ( OSH ) that has the maximal margin to both sides</definiens>
			</definition>
			<definition id="6">
				<sentence>Figure 1 : Separating hyperplanes ( the set of solid lines ) , optimal separating hyperpIane ( the bold solid line ) , and support vectors ( data points on the dashed lines ) .</sentence>
				<definiendum id="0">Separating hyperplanes</definiendum>
				<definiendum id="1">hyperpIane</definiendum>
				<definiens id="0">the set of solid lines ) , optimal separating</definiens>
				<definiens id="1">the bold solid line ) , and support vectors ( data points on the dashed lines )</definiens>
			</definition>
			<definition id="7">
				<sentence>In recent years , Joachims has done much research on the application of SVM to text categorization ( Joachims , 1998 ) .</sentence>
				<definiendum id="0">Joachims</definiendum>
			</definition>
			<definition id="8">
				<sentence>Map Adaptive Resonance Associative Map ( ARAM ) is a class of predictive serforganizing neural networks that performs incremental supervised learning of recognition categories ( pattern classes ) and multidimensional maps of patterns .</sentence>
				<definiendum id="0">Map Adaptive Resonance Associative Map ( ARAM )</definiendum>
				<definiens id="0">a class of predictive serforganizing neural networks that performs incremental supervised learning of recognition categories ( pattern classes ) and multidimensional maps of patterns</definiens>
			</definition>
			<definition id="9">
				<sentence>qupervised categorization of two pattern sets , ARAM learns supervised mapping between the pattern sets .</sentence>
				<definiendum id="0">ARAM</definiendum>
			</definition>
			<definition id="10">
				<sentence>The ART modules used in ARAM can be ART 1 , which categorizes binary patterns , or analog ART modules such as ART 2 , ART 2A , and fuzzy ART , which categorize both binary and analog patterns .</sentence>
				<definiendum id="0">ART modules</definiendum>
				<definiendum id="1">analog ART</definiendum>
				<definiendum id="2">fuzzy ART</definiendum>
				<definiens id="0">categorizes binary patterns , or</definiens>
			</definition>
			<definition id="11">
				<sentence>Category choice : Given the F~ and F1 b input vectors A and B , for each F2 node j , the choice function Tj is defined by IA Aw~l IB A w~l = ~a~ + Iw~'l + ( 1 -- ~ ) ~b + Iw~l ' ( S ) where the fuzzy AND operation A is defined by ( p A q ) i -- ~ min ( pi , qi ) , ( 9 ) and where the norm I-I is defined by IPl -= ~Pi ( 10 ) i for vectors p and q. The system is said to make a choice when at most one F2 node can become active .</sentence>
				<definiendum id="0">fuzzy AND operation</definiendum>
				<definiens id="0">( p A q ) i -- ~ min ( pi , qi ) , ( 9 ) and where the norm I-I is defined by IPl -= ~Pi ( 10 ) i for vectors p</definiens>
			</definition>
			<definition id="12">
				<sentence>Learning : Once the search ends , the weight vectors w~ and w~ are updated according to the equations W~ ( new ) - ( 1 , ~ iRa ( old ) - .</sentence>
				<definiendum id="0">Learning</definiendum>
				<definiens id="0">Once the search ends , the weight vectors w~ and w~ are updated according to the</definiens>
			</definition>
			<definition id="13">
				<sentence>, bN ) = X b ( 18 ) where bi indicates the likelihood or confidence of assigning a pattern to category i. Rule insertion : Rule insertion proceeds in two phases .</sentence>
				<definiendum id="0">bi</definiendum>
				<definiens id="0">indicates the likelihood or confidence of assigning a pattern to category i. Rule insertion : Rule insertion proceeds in two phases</definiens>
			</definition>
			<definition id="14">
				<sentence>Based on the keyword feature table , the second phase of rule insertion translates each rule into a M-dimensional vector a and a N-dimensional vector b , where M is the total number of features in the keyword feature table and N is the number of categories .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the total number of features in the keyword feature table</definiens>
				<definiens id="1">the number of categories</definiens>
			</definition>
			<definition id="15">
				<sentence>, Yn where xt , ... , xm are antecedents and Yt , ... , Yn are consequences , the algorithm derives a pair of vectors a and b such that • for each index i = 1 , ... , M , 1 ifwi = xj for some j 6 { 1 , ... , m } ai = 0 otherwise ( 19 ) where wi is the i th entry in the keyword feature table ; and for each index i = 1 , ... , N , 1 ifwi = yj for some j E { 1 , ... , n } bi = 0 otherwise ( 20 ) where wi is the class label of the category i. The vector pairs derived from the rules are then used as training patterns to initialize a ARAM network .</sentence>
				<definiendum id="0">... , n</definiendum>
			</definition>
			<definition id="16">
				<sentence>~r~ ( rabbi ) : { ~ ( promotion ) ~ ( rrcal estate ) ~ : P ( cli~O : ~-~ ( undergradua~ ) -~-~ ( supervisor ) ~2N ( campus ) : ~ : ~k ( version ) ~ ( virus ) g/~k~ ( ffirewan ) ~ ( program ) : ~'~ ( lantern riddle ) : ~ ( health cam ) ~J~ ( pmscriplion ) \ [ ~ ( medical jurisprudence ) : ~fl ~ ~ ( supernaturalism ) ~ ( high technology ) kNN experiments used the plain Euclidean distance defined by equation ( 3 ) as the similaxity measure .</sentence>
				<definiendum id="0">~r~ ( rabbi )</definiendum>
				<definiens id="0">rrcal estate ) ~ : P ( cli~O : ~-~ ( undergradua~ ) -~-~ ( supervisor ) ~2N ( campus ) : ~ : ~k ( version ) ~ ( virus ) g/~k~ ( ffirewan ) ~ ( program ) : ~'~ ( lantern riddle ) : ~ ( health cam ) ~J~ ( pmscriplion ) \ [ ~ ( medical jurisprudence ) : ~fl ~ ~ ( supernaturalism ) ~ ( high technology ) kNN experiments used the plain Euclidean distance defined by equation ( 3 ) as the similaxity measure</definiens>
			</definition>
			<definition id="17">
				<sentence>Recall ( R ) is the percentage of the documents for a given category that are classified correctly .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the percentage of the documents for a given category that are classified correctly</definiens>
			</definition>
			<definition id="18">
				<sentence>Precision ( P ) is the percentage of the predicted documents for a given category that are classifted correctly .</sentence>
				<definiendum id="0">Precision ( P )</definiendum>
				<definiens id="0">the percentage of the predicted documents for a given category that are classifted correctly</definiens>
			</definition>
			<definition id="19">
				<sentence>Ft rating is one of the commonly used measures to combine R and P into a single rating , defined as 2RP Ft = ( R + P ) '' ( 21 ) These scores are calculated for a series of binary classification experiments , one for each category .</sentence>
				<definiendum id="0">Ft rating</definiendum>
				<definiens id="0">one of the commonly used measures to combine R and P into a single rating , defined as 2RP Ft = ( R + P ) '' ( 21 ) These scores are calculated for a series of binary classification experiments</definiens>
			</definition>
			<definition id="20">
				<sentence>kNN is a lazy learning method in the sense that it does not carry out any off-line learning to generate a particular category knowledge representation .</sentence>
				<definiendum id="0">kNN</definiendum>
				<definiens id="0">a lazy learning method in the sense that it does not carry out any off-line learning to generate a particular category knowledge representation</definiens>
			</definition>
			<definition id="21">
				<sentence>Instead , kNN performs online scoring to find the training patterns that are nearest to a test pattern and makes the decision based on the statistical presumption that patterns in the same category have similar feature representations .</sentence>
				<definiendum id="0">kNN</definiendum>
				<definiens id="0">performs online scoring to find the training patterns that are nearest to a test pattern and makes the decision based on the statistical presumption that patterns in the same category have similar feature representations</definiens>
			</definition>
			<definition id="22">
				<sentence>SVM identifies optimal separating hyperplane ( OSH ) across the training data points and makes classification decisions based on the representative data instances ( known as support vectors ) .</sentence>
				<definiendum id="0">SVM</definiendum>
			</definition>
</paper>

		<paper id="0804">
			<definition id="0">
				<sentence>A baseline algorithm for Word Domain Disambiguation is presented and then compared with a mutual help disambignation strategy , which takes advantages of the shared senses of parallel bilingual texts .</sentence>
				<definiendum id="0">mutual help disambignation strategy</definiendum>
				<definiens id="0">takes advantages of the shared senses of parallel bilingual texts</definiens>
			</definition>
			<definition id="1">
				<sentence>A baseline algorithm for Word Domain Disambignation is presented and then compared with a mutual help disambignation strategy , which makes use of the shared senses of parallel bilingual texts .</sentence>
				<definiendum id="0">mutual help disambignation strategy</definiendum>
				<definiens id="0">makes use of the shared senses of parallel bilingual texts</definiens>
			</definition>
			<definition id="2">
				<sentence>In this section we present two baseline algorithms for word domain disambiguation and we propose some variants of them to deal with WDD in the context of parallel texts .</sentence>
				<definiendum id="0">WDD</definiendum>
				<definiens id="0">word domain disambiguation</definiens>
			</definition>
			<definition id="3">
				<sentence>For the purposes of the experiment described in the next sections the FACTOTUM problem has been resolved with a slight modification at step 2 of the baseline algorithm : when FACTOTUM is the best selection for a word , also the second available choice is considered as a result of the disambiguation process .</sentence>
				<definiendum id="0">FACTOTUM</definiendum>
				<definiens id="0">the best selection for a word</definiens>
			</definition>
</paper>

		<paper id="1324">
			<definition id="0">
				<sentence>Examples are the Penn Treebank ( Marcus et al. , 1994 ; Bies et al. , 1995 ) annotated at the University of Pennsylvania , the Negra corpus ( Brauts et al. , 1999 ) developed in Saarbriicken , the Verbmobil treebank~ ( Hinrichs et al. , 2000 ) annotated in Tiibingen *The work presented here was done as part of a project in SFB 441 `` Linguistic Data Structures '' at the University of Tiibingen .</sentence>
				<definiendum id="0">Negra corpus</definiendum>
				<definiens id="0">annotated at the University of Pennsylvania , the</definiens>
			</definition>
			<definition id="1">
				<sentence>The Penn Treebank for example consists of trees with an additional coindexation relation , Negra allows crossing branches and in Verbmobil , an element ( a tree-like structure ) in the corpus might contain completely disconnected nodes .</sentence>
				<definiendum id="0">Penn Treebank</definiendum>
				<definiens id="0">consists of trees with an additional coindexation relation</definiens>
			</definition>
			<definition id="2">
				<sentence>The German Verbmobil corpus ( Stegmann et al. , 1998 ; Hinrichs et al. , 2000 ) is a treebank annotated at the University of Tiibingen SIMPX I VF !</sentence>
				<definiendum id="0">German Verbmobil corpus</definiendum>
				<definiens id="0">a treebank annotated at the University of Tiibingen</definiens>
			</definition>
			<definition id="3">
				<sentence>The Verbmobil corpus is part-of-speech tagged using the Stuttgart Tiibingen tagset ( STTS ) described in ( Schiller et al. , 1995 ) .</sentence>
				<definiendum id="0">Verbmobil corpus</definiendum>
			</definition>
			<definition id="4">
				<sentence>A model is a tuple ( /g , T ~ , T ) , £ , p , ~/ , a ) where/g is the set of nodes , 7 ~ , T~ and £ are the 192 SIMPX I I D D VF MF I I NX NX I I I I PWS NE wen Maria I E3 SIMPX \ ] I I D \ [ 3 I I LK MF LK I I I I I I VXFIN NX VXFIN I I I I I I WFIN PPER VVFIN glaubst du liebt Figure 2 : Annotation of ( 3 ) in Verbmobil format binary relations immediate dominance ( parent ) , dominance and linear precedence , # is a function assigning syntactic categories or part-of-speech tags to nodes , r/ is a function mapping edges to grammatical functions , and a assigns tokens to the leaves ( i.e. the nodes that do not dominate any other node ) .</sentence>
				<definiendum id="0">model</definiendum>
				<definiendum id="1">r/</definiendum>
				<definiens id="0">a function assigning syntactic categories or part-of-speech tags to nodes</definiens>
				<definiens id="1">a function mapping edges to grammatical functions</definiens>
			</definition>
			<definition id="5">
				<sentence>79 } ~ T is a total .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">a total</definiens>
			</definition>
			<definition id="6">
				<sentence>IF ~ cat ( 4 ) =NX &amp; fct ( 4 ) =0A ~ 3 &gt; &gt; 4 As already mentioned , the general idea of the query tool is to store the information one wants to search for in a relational database and then to translate an expression in the query language presented in the previous section into an SQL expression that is evaluated on the database .</sentence>
				<definiendum id="0">query tool</definiendum>
				<definiens id="0">to store the information one wants to search for in a relational database and then to translate an expression in the query language presented in the previous section into an SQL expression that is evaluated on the database</definiens>
			</definition>
			<definition id="7">
				<sentence>The colnmn cl_id in the table node_pair_/ , for example , is a foreign key referring to the colnmn clad in the table pair_class .</sentence>
				<definiendum id="0">colnmn cl_id</definiendum>
				<definiens id="0">a foreign key referring to the colnmn clad in the table pair_class</definiens>
			</definition>
			<definition id="8">
				<sentence>The query component takes an expression in the query language as input and translates this into a corresponding SQL expression , which is then passed to the database .</sentence>
				<definiendum id="0">query component</definiendum>
				<definiens id="0">takes an expression in the query language as input</definiens>
			</definition>
			<definition id="9">
				<sentence>In this paper , I have presented a query tool for syntactically annotated corpora that is developed for the German Verbmobil treebank annotated at the University of Tiibingen .</sentence>
				<definiendum id="0">syntactically annotated corpora</definiendum>
				<definiens id="0">developed for the German Verbmobil treebank annotated at the University of Tiibingen</definiens>
			</definition>
</paper>

		<paper id="1106">
			<definition id="0">
				<sentence>Table 2 : Typical hand-written compound noun indexing rule patterns for Korean Noun without case makers / Noun Noun with a genitive case maker / Noun Noun with a nominal case maker or an accusative case maker \ [ Verbal common noun or adjectival common noun Noun with an adnominal ending \ ] Noun Noun within predicate particle phrase / Noun ( The two nouns before and after a slash in the pattern can form a single compound noun . )</sentence>
				<definiendum id="0">Noun</definiendum>
				<definiens id="0">an adnominal ending \ ] Noun Noun within predicate particle phrase /</definiens>
			</definition>
			<definition id="1">
				<sentence>The compound noun indexing system proposed in this paper Consists of two major modules : one for automatically extracting compound noun indexing rules ( in Figure 1 ) and the other for indexing documents , filtering the automatically generated compound nouns , and weighting the indexed compound nouns ( in Figure 2 ) .</sentence>
				<definiendum id="0">compound noun indexing system</definiendum>
				<definiens id="0">one for automatically extracting compound noun indexing rules ( in Figure 1 ) and the other for indexing documents , filtering the automatically generated compound nouns , and weighting the indexed compound nouns ( in Figure 2 )</definiens>
			</definition>
			<definition id="2">
				<sentence>Distribution Example 2 tags 79.6 % MC MC 3 tags 12.6 % MC jO ( eui ) MC 4 tags 4.7 % MC y eCNMG MC 5 tags 1.5 % MC MC jO ( e ) DI &lt; sog-ha-neun ) MC over 6 tags 1.6 % The automatically extracted rules have more rule patterns and lexical items than human-made rules so they can cover more diverse types of compound nouns ( Table 8 ) . When checking the overlap between the two rule collections , we found that the manual linguistic rules are a subset of our automatically generated statistical rules. Table 9 shows some of the example rules newly generated from our extraction algorithm , which were originally missing in the manual rule patterns. Extracted Rules In the proposed method , we use the precision of rules to solve the compound noun overgeneration and the data sparseness problems. The precision of a rule can be defined by Table 8 : Comparison between the automatically extracted rules and the manual rules Method Manual linguistic method Our method No. of No. of general lexical terms rule patterns used in rule patterns 16 23 78 Table 9 : Examples of newly added rule patterns Rule Noun + bound noun / Noun Noun + suffix / Noun Noun + suffix + assignment verb + adnominal ending / Noun counting how many indexed compound noun candidates generated by the rule are actual compound nouns : Yactuat Prec ( rule ) = Ncandidate where Prec ( rule ) is the precision of a rule , Ndctual is the number of actual compound nouns , and Ncandidat e is the number of compound noun candidates generated by the automatic indexing rules. To calculate the precision , we need a defining measurement for compound noun identification. ( Su et al. , 1994 ) showed that the average mutual information of a compound noun tends to be higher than that of a noncompound noun , so we try to use the mutual information as the measure for identifying the compound nouns. If the mutual information of the compound noun candidate is higher than the average mutual information of the compound noun seeds , we decide that it is a compound noun. For mutual information ( MI ) , we use two different equations : one for two-element compound nouns ( Church and Hanks , 1990 ) and the other for three-element compound nouns ( Suet al. , 1994 ) . The equation for two-element compound nouns is as follow : P ( x , y ) I ( x ; y ) = log 2 P ( x ) x P ( y ) 61 where x and y are two words in the corpus , and I ( x ; y ) is the mutual information of these two words ( in this order ) . Table 10 shows the average MI value of the two and three elements. Table 10 : Average value of the mutual information ( MI ) of compound noun seeds .Number of elements \ [ 2 I 3 Average MI The MI was calculated from the statistics of the complete compound nouns collected from the tagged training corpus ( see Section 4.1 ) . However , complete compound nouns are continuous noun sequences and cause the data sparseness problem. Therefore , we need to expand the statistics. Figure 4 shows the architecture of the precision learning module by expanding the statistics of the complete compound nouns along with an algorithmic explanation ( Algorithm 3 ) of the process. Table 11 shows the improvement in the average precision during the repetitive execution of this learning process. Norm Statistical ) Compound Norm of Rules ~'~ Rule incision ( step 5 ) ( s~ 2.7 ) l~v v\ [ ( step s ) Figure 4 : Learning the precision of the compound noun indexing rules ( The steps are shown in Algorithm 3 ) Algorithm 3 : i. Calculate all rules ' initial precision using initial complete compound noun statistical information. of the rules. the frequency of the compound noun made by the rule. We call this value the modified frequency ( MF ) . sum all the modified frequencies for each compound noun. than a threshold , add this compound noun to the complete compound noun statistical information. using the changed complete compound noun statistical information. equal to the previous average precision , stop. Othervise , go to step 2. Table 11 : Improvement in the average precision of rules Learning 1 2 3 4 5 6 cycles Avg. prec. 0.19 0.23 0.39 0.44 0.45 0.45 of rules Filtering , and Weighting In this section , we explai n how to use the automatically extracted rules to actually index the compound nouns , and describe how to filter and weight the indexed compound nouns. To index compound nouns from documents , we use a natural language processing engine , SKOPE ( Standard KOrean Processing Engine ) ( Cha et al. , 1998 ) , which processes documents by analysing words into morphemes and tagging part-of-speeches. The tagging results are compared with the automatically learned compound noun indexing rules and , if they are coincident with each other , we index them as compound nouns. Figure 5 shows a process of the compound noun indexing with an example. Among the indexed compound nouns above , still there can be meaningless compound nouns , which increases the number of index terms and the search time. To solve compound noun over-generation problem , we experiment with seven different filtering methods ( shown in Table 12 ) by analyzing their 62 •. `` Tagging Result : bbal-li jeong-bo-leul B &lt; bbal-li &gt; geom-saeg-ha-netm ~ Auaty~ ~ .</sentence>
				<definiendum id="0">extraction algorithm</definiendum>
				<definiendum id="1">Ndctual</definiendum>
				<definiendum id="2">Ncandidat e</definiendum>
				<definiendum id="3">I ( x ; y )</definiendum>
				<definiendum id="4">Weighting In</definiendum>
				<definiens id="0">e ) DI &lt; sog-ha-neun ) MC over 6 tags 1.6 % The automatically extracted rules have more rule patterns and lexical items than human-made rules so they can cover more diverse types of compound nouns ( Table 8 ) . When checking the overlap between the two rule collections</definiens>
				<definiens id="1">the precision of rules to solve the compound noun overgeneration and the data sparseness problems. The precision of a rule can be defined by Table 8 : Comparison between the automatically extracted rules and the manual rules Method Manual linguistic method Our method No. of No. of general lexical terms rule patterns used in rule patterns 16 23 78 Table 9 : Examples of newly added rule patterns Rule Noun + bound noun / Noun Noun + suffix / Noun Noun + suffix + assignment verb + adnominal ending / Noun counting how many indexed compound noun candidates generated by the rule are actual compound nouns : Yactuat Prec ( rule ) = Ncandidate where Prec ( rule ) is the precision of a rule</definiens>
				<definiens id="2">the number of actual compound nouns</definiens>
				<definiens id="3">Su et al. , 1994 ) showed that the average mutual information of a compound noun tends to be higher than that of a noncompound noun , so we try to use the mutual information as the measure for identifying the compound nouns. If the mutual information of the compound noun candidate is higher than the average mutual information of the compound noun seeds</definiens>
				<definiens id="4">a compound noun. For mutual information ( MI ) , we use two different equations : one for two-element compound nouns ( Church and Hanks , 1990 ) and the other for three-element compound nouns ( Suet al. , 1994 ) . The equation for two-element compound nouns is as follow : P ( x , y ) I ( x ; y ) = log 2 P ( x ) x P ( y ) 61 where x and y are two words in the corpus</definiens>
				<definiens id="5">the mutual information of these two words</definiens>
				<definiens id="6">Average value of the mutual information ( MI ) of compound noun seeds .Number of elements \ [ 2 I 3 Average MI The MI was calculated from the statistics of the complete compound nouns collected from the tagged training corpus ( see Section 4.1 ) . However , complete compound nouns are continuous noun sequences and cause the data sparseness problem. Therefore , we need to expand the statistics. Figure 4 shows the architecture of the precision learning module by expanding the statistics of the complete compound nouns along with an algorithmic explanation ( Algorithm 3 ) of the process. Table 11 shows the improvement in the average precision during the repetitive execution of this learning process. Norm Statistical ) Compound Norm of Rules ~'~ Rule incision ( step 5 ) ( s~ 2.7 ) l~v v\ [ ( step s ) Figure 4 : Learning the precision of the compound noun indexing rules ( The steps are shown in Algorithm 3 ) Algorithm 3 : i. Calculate all rules ' initial precision using initial complete compound noun statistical information. of the rules. the frequency of the compound noun made by the rule. We call this value the modified frequency ( MF ) . sum all the modified frequencies for each compound noun. than a threshold , add this compound noun to the complete compound noun statistical information. using the changed complete compound noun statistical information. equal to the previous average precision , stop. Othervise , go to step 2. Table 11 : Improvement in the average precision of rules Learning 1 2 3 4 5 6 cycles Avg. prec. 0.19 0.23 0.39 0.44 0.45 0.45 of rules Filtering , and</definiens>
			</definition>
			<definition id="3">
				<sentence>MI ( Mutual Information ) is a measure of word association , and used under the assumption that a highly associated word n-gram is more likely to be a compound noun .</sentence>
				<definiendum id="0">MI</definiendum>
				<definiendum id="1">Mutual Information</definiendum>
				<definiens id="0">a measure of word association , and used under the assumption that a highly associated word n-gram is more likely to be a compound noun</definiens>
			</definition>
			<definition id="4">
				<sentence>Table 12 : Seven different filtering methods ( MI ) A. Mutual information of compound noun elements ( 0 ) ( MI ) B. Mutual information of compound noun elements ( average of MI of compound noun seeds ) ( FC ) C. Frequency of compound nouns in the training corpus ( 4 ) ( FC ) D. Frequency of compound nouns in the test corpus ( 2 ) ( FE ) E. Frequency of compound noun heads in the training corpus ( 5 ) ( FE ) F. Frequency of compound noun modifiers in the training corpus ( 5 ) G. No filtering ( The value in parantheses is a threshold . )</sentence>
				<definiendum id="0">FE</definiendum>
				<definiens id="0">FC ) D. Frequency of compound nouns in the test corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>On the basis of this filtering method , we develop a smoothing method by combining the precision of rules with the mutual information of the compound noun elements , and propose our final filtering method ( H ) as follows : P ( x , y ) + ~ × Precision T ( x , y ) = log 2 P ( x ) x P ( y ) where a is a weighting coefficient and Precision is the applied rules learned in Section 4.3 .</sentence>
				<definiendum id="0">P ( x ) x P</definiendum>
				<definiendum id="1">Precision</definiendum>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>The annotation information consists of speech , transcription delimited by slash units , prosodic , part of speech , dialogue acts and dialogue segmentation .</sentence>
				<definiendum id="0">annotation information</definiendum>
				<definiens id="0">consists of speech , transcription delimited by slash units , prosodic , part of speech , dialogue acts and dialogue segmentation</definiens>
			</definition>
			<definition id="1">
				<sentence>Prosody has been widely recognized as one of the important factors which relate to discourse structures , dialogue acts , information status , and so on .</sentence>
				<definiendum id="0">Prosody</definiendum>
				<definiens id="0">one of the important factors which relate to discourse structures , dialogue acts , information status</definiens>
			</definition>
			<definition id="2">
				<sentence>The part-of-speech is another basic information for speech recognition , syntactic/semantic parsing , and dialogue processing as well as linguistic and psycholinguistic analysis of spoken discourse .</sentence>
				<definiendum id="0">part-of-speech</definiendum>
				<definiens id="0">another basic information for speech recognition , syntactic/semantic parsing , and dialogue processing as well as linguistic and psycholinguistic analysis of spoken discourse</definiens>
			</definition>
			<definition id="3">
				<sentence>In the transcription , an utterance is defined as a continuous speech region delimited by pauses of 400 msec or longer .</sentence>
				<definiendum id="0">utterance</definiendum>
				<definiens id="0">a continuous speech region delimited by pauses of 400 msec or longer</definiens>
			</definition>
			<definition id="4">
				<sentence>Non sentence elements consist of 'aiduti ' , conjunction markers , discourse markers , fillers 3 f A : sukoshi dake itte / ( move a little ) B : ~2 / ( ok ) A : { D de } hidari naname shitani ( { D `` then } I ; o your lefv .</sentence>
				<definiendum id="0">Non sentence elements</definiendum>
				<definiens id="0">consist of 'aiduti ' , conjunction markers , discourse markers , fillers 3 f A : sukoshi dake itte / ( move a little</definiens>
			</definition>
			<definition id="5">
				<sentence>The DS tag consists of a topic break index ( TBI ) , a topic name and a segment relation .</sentence>
				<definiendum id="0">DS tag</definiendum>
				<definiens id="0">consists of a topic break index ( TBI ) , a topic name and a segment relation</definiens>
			</definition>
			<definition id="6">
				<sentence>Coupling is the pattern of \ [ A : I B : R\ ] \ [ B : I A : R\ ] .</sentence>
				<definiendum id="0">Coupling</definiendum>
			</definition>
			<definition id="7">
				<sentence>Elliptical coupling is the pattern of \ [ A : I\ ] \ [ B : I A : R\ ] , equivalent to the one in which B 's second response is omitted in coupling .</sentence>
				<definiendum id="0">Elliptical coupling</definiendum>
				<definiens id="0">the pattern of \ [ A : I\ ] \ [ B : I A : R\ ] , equivalent to the one in which B 's second response is omitted in coupling</definiens>
			</definition>
			<definition id="8">
				<sentence>The annotation information includes speech , transcription delimited by slash units , prosodic , part of speech , dialogue acts and dialogue segmentation .</sentence>
				<definiendum id="0">annotation information</definiendum>
				<definiens id="0">includes speech , transcription delimited by slash units , prosodic , part of speech , dialogue acts and dialogue segmentation</definiens>
			</definition>
</paper>

		<paper id="1425">
			<definition id="0">
				<sentence>In many NLG systems , aggregation is a post planning process whose preferences are only partially taken into account by the text planner .</sentence>
				<definiendum id="0">aggregation</definiendum>
				<definiens id="0">a post planning process whose preferences are only partially taken into account by the text planner</definiens>
			</definition>
			<definition id="1">
				<sentence>A good embedding is one satisfying all the following conditions : strative or a bridging description ( as defined in ( Poesio et al. , 1997 ) ) .</sentence>
				<definiendum id="0">good embedding</definiendum>
				<definiens id="0">one satisfying all the following conditions : strative or a bridging description</definiens>
			</definition>
			<definition id="2">
				<sentence>A normal embedding is one satisfying condition 1 , 3 and 4 and the embedded part is a relative clause which provides additional information about the referent .</sentence>
				<definiendum id="0">normal embedding</definiendum>
				<definiendum id="1">embedded part</definiendum>
				<definiens id="0">a relative clause which provides additional information about the referent</definiens>
			</definition>
			<definition id="3">
				<sentence>ILEX is an adaptive hypertext generation system , providing natural language descriptions for museum objects .</sentence>
				<definiendum id="0">ILEX</definiendum>
				<definiens id="0">an adaptive hypertext generation system , providing natural language descriptions for museum objects</definiens>
			</definition>
			<definition id="4">
				<sentence>Mutation selects a random segment of a sequence and moves it into a random position in the same sequence .</sentence>
				<definiendum id="0">Mutation</definiendum>
				<definiens id="0">selects a random segment of a sequence and moves it into a random position in the same sequence</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>Alternatively , the Dialogue Manager is the central unit of the system where the overall system behaviour is determined .</sentence>
				<definiendum id="0">Dialogue Manager</definiendum>
			</definition>
			<definition id="1">
				<sentence>XMALIN ( Multi-modal Application of LINLIN ) is a refinement of the LINLINsystem ( Ahrenberg et al. , 1990 ; JSnsson , 1997 ) to handle also multi-modal interaction and more advanced applications .</sentence>
				<definiendum id="0">XMALIN ( Multi-modal Application of LINLIN )</definiendum>
				<definiens id="0">a refinement of the LINLINsystem ( Ahrenberg et al. , 1990 ; JSnsson , 1997 ) to handle also multi-modal interaction and more advanced applications</definiens>
			</definition>
			<definition id="2">
				<sentence>For simple information requests we have identified two important concepts , termed Objects and Properties ( JSnsson , 1997 ) where Objects models the set of objects in the database and Properties denotes a complex predicate ascribed to this set .</sentence>
				<definiendum id="0">Objects</definiendum>
				<definiendum id="1">Properties</definiendum>
				<definiens id="0">the set of objects in the database</definiens>
				<definiens id="1">a complex predicate ascribed to this set</definiens>
			</definition>
			<definition id="3">
				<sentence>The Spatial Reasoning Agent utilises a Geographical Information System and reasoning mechanism used to deduce the relations between geographical objects ( Flycht-Eriksson and JSnsson , 1998 ) .</sentence>
				<definiendum id="0">Spatial Reasoning Agent</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Timetable Agent retrieves time-table information for local bus and train traffic from an Internet source .</sentence>
				<definiendum id="0">Timetable Agent</definiendum>
				<definiens id="0">retrieves time-table information for local bus and train traffic from an Internet source</definiens>
			</definition>
			<definition id="5">
				<sentence>A recipe is application specific and consists of a series of service calls from different agents , which are executed in order to construct an answer to a specific request , see figure 5 for an example .</sentence>
				<definiendum id="0">recipe</definiendum>
				<definiens id="0">application specific and consists of a series of service calls from different agents</definiens>
			</definition>
			<definition id="6">
				<sentence>DKM To illustrate how the Dialogue Manager ( DM ) and the Domain Knowledge Manager ( DKM ) cooperates in processing of requests and handling of clarifications , consider the hypothetical dialogue shown in figure 6 .</sentence>
				<definiendum id="0">DKM</definiendum>
				<definiens id="0">To illustrate how the Dialogue Manager ( DM ) and the Domain Knowledge Manager ( DKM ) cooperates in processing of requests and handling of clarifications</definiens>
			</definition>
			<definition id="7">
				<sentence>The utterance is a simple request and the DM utilises an OPM to model this , figure 10 .</sentence>
				<definiendum id="0">utterance</definiendum>
				<definiendum id="1">DM</definiendum>
				<definiens id="0">a simple request and the</definiens>
			</definition>
			<definition id="8">
				<sentence>Again the DM asks the DKM for domain validation of the partially specified ISF .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiens id="0">asks the DKM for domain validation of the partially specified ISF</definiens>
			</definition>
			<definition id="9">
				<sentence>The Domain Knowledge Manager is functional utilising a Spatial Reasoner for one sub-area of OstergStland and a Temporal Reasoner .</sentence>
				<definiendum id="0">Domain Knowledge Manager</definiendum>
				<definiens id="0">functional utilising a Spatial Reasoner for one sub-area of OstergStland and a Temporal Reasoner</definiens>
			</definition>
</paper>

		<paper id="0713">
			<definition id="0">
				<sentence>For example , ( Domingos , 1996 ) describes the RISE system , in which rules are ( carefully ) generalised from instances , and in which the k-NN classification rule searches for nearest neighbours within these rules when classifying new instances .</sentence>
				<definiendum id="0">RISE system</definiendum>
				<definiens id="0">in which rules are ( carefully ) generalised from instances , and in which the k-NN classification rule searches for nearest neighbours within these rules when classifying new instances</definiens>
			</definition>
			<definition id="1">
				<sentence>fl , f2 , and f3 represent the three features , c represents the class label .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">the class label</definiens>
			</definition>
			<definition id="2">
				<sentence>A new memory-based learning variant RBM , which stands for Rule-Based Memory , implements the ideas described in the previous section using the following procedure : given a training set and a test set of a certain classification task , ( 1 ) apply RIPPER ( Cohen , 1995 ) to the training set , and collect the set of induced rules ; ( 2 ) recode the instances in the training and test set according to these rules ; ( 3 ) apply the basic memory-based learning algorithm IBi-IG to the recoded training set , and k-NNclassify the recoded test set .</sentence>
				<definiendum id="0">memory-based learning variant RBM</definiendum>
				<definiens id="0">implements the ideas described in the previous section using the following procedure : given a training set and a test set of a certain classification task</definiens>
				<definiens id="1">recode the instances in the training and test set according to these rules ; ( 3 ) apply the basic memory-based learning algorithm IBi-IG to the recoded training set , and k-NNclassify the recoded test set</definiens>
			</definition>
			<definition id="3">
				<sentence>RIPPER ( Cohen , 1995 ) is a fast rule induction algorithm that splits the training set in two .</sentence>
				<definiendum id="0">RIPPER</definiendum>
				<definiens id="0">a fast rule induction algorithm that splits the training set in two</definiens>
			</definition>
			<definition id="4">
				<sentence>Base-NP chunking ( NPSM ) : the segmentation of sentences into non-recursive NPs .</sentence>
				<definiendum id="0">Base-NP chunking</definiendum>
				<definiendum id="1">NPSM</definiendum>
				<definiens id="0">the segmentation of sentences into non-recursive NPs</definiens>
			</definition>
			<definition id="5">
				<sentence>Part-of-speech tagging ( POSSM ) : the disambiguation of syntactic classes of words in PP particular contexts .</sentence>
				<definiendum id="0">Part-of-speech tagging</definiendum>
				<definiendum id="1">POSSM</definiendum>
				<definiens id="0">the disambiguation of syntactic classes of words in PP particular contexts</definiens>
			</definition>
			<definition id="6">
				<sentence>attachment ( PP ) : the attachment ofa PP in the sequence VP hip PP ( VP = verb phrase , 51P = noun phrase , PP = prepositional phrase ) .</sentence>
				<definiendum id="0">PP )</definiendum>
			</definition>
			<definition id="7">
				<sentence>The data consists of fourtuples of words , extracted from the Wall Street Journal Treebank .</sentence>
				<definiendum id="0">data</definiendum>
				<definiens id="0">consists of fourtuples of words , extracted from the Wall Street Journal Treebank</definiens>
			</definition>
			<definition id="8">
				<sentence>Table 2 lists the average ( 10-fold crossvalidation ) accuracies , measured in percentages of correctly classified test instances , of IBI-IG , RIPPER , and RBM on these five tasks .</sentence>
				<definiendum id="0">average</definiendum>
				<definiens id="0">10-fold crossvalidation ) accuracies , measured in percentages of correctly classified test instances</definiens>
			</definition>
</paper>

		<paper id="1310">
			<definition id="0">
				<sentence>One way of representing a context is statistical language nmdels which provide a word sequence probability , P ( w~ ) , where w~ denotes the sequence wi ... wj .</sentence>
				<definiendum id="0">w~</definiendum>
				<definiens id="0">statistical language nmdels which provide a word sequence probability</definiens>
			</definition>
			<definition id="1">
				<sentence>In other words , they provide the conditional probability of a word given with the previous word sequence , P ( wilw~-l ) , which shows the prediction of a word in a given context .</sentence>
				<definiendum id="0">P ( wilw~-l )</definiendum>
				<definiens id="0">the conditional probability of a word given with the previous word sequence</definiens>
			</definition>
			<definition id="2">
				<sentence>In this matrix : the rows and colunms correspond to words and the ith diagonal element denotes the number of documents in which the word wl appears , F ( wi ) .</sentence>
				<definiendum id="0">diagonal element</definiendum>
				<definiens id="0">the number of documents in which the word wl appears , F ( wi )</definiens>
			</definition>
			<definition id="3">
				<sentence>wcj ) wc ( 6 ) new -W C7 e~ : ilwcF wl I ( 7 ) The learning method by HNC is a rather simple approximation of the procedure , doing just one step of it .</sentence>
				<definiendum id="0">HNC</definiendum>
			</definition>
			<definition id="4">
				<sentence>The probability of a content word based on such dot products , called a context cooccurrence probability , can be calculated as follows : Pc ( wilw~_lcc ) = f ( cc~ -1 `` ~cl ) ~wjEcc f ( cc~ -1 '' ~vcj ) ( S ) where cc~ -1 denotes the context co-occurrence vector of the left context , Wl ... wi-1 , and Cc denotes a content word class .</sentence>
				<definiendum id="0">context cooccurrence probability</definiendum>
				<definiendum id="1">Pc</definiendum>
				<definiendum id="2">cc~ -1</definiendum>
				<definiendum id="3">Cc</definiendum>
				<definiens id="0">the context co-occurrence vector of the left context</definiens>
				<definiens id="1">a content word class</definiens>
			</definition>
			<definition id="5">
				<sentence>P ( Cc\ [ w~ -1 ) denotes the probability that a content word follows w~- : , which is approximated by a trigrmn nmdel .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">the probability that a content word follows w~- : , which is approximated by a trigrmn nmdel</definiens>
			</definition>
			<definition id="6">
				<sentence>wi\ [ w~-lcc ) denotes the probability that wi follows w~- : given that a content word follows w~- : , which is a linear interpolation of a standard trigram model and the context co-occurrence probabilities .</sentence>
				<definiendum id="0">w~-lcc )</definiendum>
				<definiens id="0">the probability that wi follows w~- : given that a content word follows w~- : , which is a linear interpolation of a standard trigram model and the context co-occurrence probabilities</definiens>
			</definition>
</paper>

		<paper id="1311">
			<definition id="0">
				<sentence>Introduction Language models are important post-processing modules to improve recognition accuracy of a wide variety of input , namely speech recognition ( Balh et al. , 1983 ) , handwritten recognition ( Elliman and Lancaster , 1990 ) and printed character recognition ( Sun , 1991 ) , for many human languages .</sentence>
				<definiendum id="0">Introduction Language models</definiendum>
				<definiens id="0">important post-processing modules to improve recognition accuracy of a wide variety of input</definiens>
			</definition>
			<definition id="1">
				<sentence>The recall is the number of errors identified by a particular feature divided by the total number of errors .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">the number of errors identified by a particular feature divided by the total number of errors</definiens>
			</definition>
			<definition id="2">
				<sentence>( x _/~ , ) log l , I +2 log p ( w c ) g , ( x ) = - ( x-lee ) r Z , -~ ( x-/~ , ) log\ ] Z~ \ ] +2log p ( w , ) Pc and , ue are the mean vectors of the class wc and we , respectively , ~ and ~ are the covariance matrices of the class wc and we , respectively , and 1-I is the determinant .</sentence>
				<definiendum id="0">ue</definiendum>
				<definiens id="0">the mean vectors of the class wc and we</definiens>
			</definition>
			<definition id="3">
				<sentence>The output of each node in the MLP is the weighted sum of its input , which is transformed by a sigmoidal function .</sentence>
				<definiendum id="0">MLP</definiendum>
				<definiens id="0">the weighted sum of its input</definiens>
			</definition>
			<definition id="4">
				<sentence>The recall is the number of identified errors over the total number of errors .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">the number of identified errors over the total number of errors</definiens>
			</definition>
			<definition id="5">
				<sentence>The precision is the number of identified errors over the total number of cases classified as errors .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the number of identified errors over the total number of cases classified as errors</definiens>
			</definition>
</paper>

		<paper id="0602">
			<definition id="0">
				<sentence>Audio comprehension tests are designed to help evaluate a listener 's understanding of a spoken passage and are frequently a key component of language competency exams .</sentence>
				<definiendum id="0">Audio comprehension tests</definiendum>
				<definiens id="0">designed to help evaluate a listener 's understanding of a spoken passage and are frequently a key component of language competency exams</definiens>
			</definition>
			<definition id="1">
				<sentence>Audio comprehension tests , on the other hand , are designed to help evaluate a listener 's understanding of a spoken passage and are an example of a spoken language processing task .</sentence>
				<definiendum id="0">Audio comprehension tests</definiendum>
				<definiens id="0">designed to help evaluate a listener 's understanding of a spoken passage</definiens>
			</definition>
			<definition id="2">
				<sentence>Audio comprehension systems that process this `` noisy '' third version as if it contained the actual spoken words could not possibly answer any of the sample questions above correctly , since the most important words ( MISTER REINECK ) are not present in the output .</sentence>
				<definiendum id="0">Audio comprehension systems</definiendum>
				<definiens id="0">if it contained the actual spoken words could not possibly answer any of the sample questions above correctly , since the most important words ( MISTER REINECK ) are not present in the output</definiens>
			</definition>
			<definition id="3">
				<sentence>Statistical language modeling , an essential component of most state-of-theart speech recognition systems , seeks to estimate the probability of the sequence of L spoken words , P ( wl ... WL ) .</sentence>
				<definiendum id="0">Statistical language modeling</definiendum>
				<definiens id="0">estimate the probability of the sequence of L spoken words</definiens>
			</definition>
			<definition id="4">
				<sentence>In this case `` Haider '' is an out-of-vocabulary word and would not be present elsewhere in the N-best list ; we will discuss this problem in Section 4 .</sentence>
				<definiendum id="0">Haider</definiendum>
				<definiens id="0">an out-of-vocabulary word and would not be present elsewhere in the N-best list</definiens>
			</definition>
</paper>

		<paper id="0803">
			<definition id="0">
				<sentence>This is due to the fact that unlike Latin alphabets , Han characters capture significant semantic information in them .</sentence>
				<definiendum id="0">Han characters</definiendum>
				<definiens id="0">semantic information in them</definiens>
			</definition>
			<definition id="1">
				<sentence>The Common CJK Ideograph section of the Unicode encoding scheme includes all characters encoded in each individual language and encoding scheme .</sentence>
				<definiendum id="0">The Common CJK Ideograph section</definiendum>
				<definiens id="0">includes all characters encoded in each individual language and encoding scheme</definiens>
			</definition>
			<definition id="2">
				<sentence>Chinese is a non-inflectional language and therefore morphological analysis is not essential .</sentence>
				<definiendum id="0">Chinese</definiendum>
				<definiens id="0">a non-inflectional language</definiens>
			</definition>
			<definition id="3">
				<sentence>However , in Chinese , gl~ represents postal stamp and the constituent characters represent `` postal '' and `` ticket '' , respectively .</sentence>
				<definiendum id="0">gl~</definiendum>
				<definiendum id="1">constituent characters</definiendum>
				<definiens id="0">postal stamp</definiens>
				<definiens id="1">'' and `` ticket '' , respectively</definiens>
			</definition>
			<definition id="4">
				<sentence>22 Table 1 : Enhancement of query or document vectors to create semantic association ( an example ) Document or Query Vector Representation ( partial ) Han Characters appeared in a Japanese or a Chinese docun~nt or a query : \ [ .</sentence>
				<definiendum id="0">semantic association</definiendum>
				<definiens id="0">an example ) Document or Query Vector Representation ( partial ) Han Characters appeared in a Japanese or a Chinese docun~nt or a query : \ [</definiens>
			</definition>
			<definition id="5">
				<sentence>language perspective The most popular IR model , the Vector Space Model , uses vectors to represent documents and queries .</sentence>
				<definiendum id="0">Vector Space Model</definiendum>
				<definiens id="0">uses vectors to represent documents and queries</definiens>
			</definition>
			<definition id="6">
				<sentence>The vector simply consists of an ordered list of terms , and therefore , the contextual cues have also disappeared .</sentence>
				<definiendum id="0">vector</definiendum>
				<definiens id="0">consists of an ordered list of terms</definiens>
			</definition>
			<definition id="7">
				<sentence>Dimensionality reduction techniques , chistedng , independent component analysis ( ICA ) and other mathematical methods can be exploited to 25 enhance Han character based l ) Xc , cessing of CJK languages .</sentence>
				<definiendum id="0">ICA</definiendum>
			</definition>
</paper>

		<paper id="1308">
			<definition id="0">
				<sentence>The expectation for a feature f is : E f= ~ ( h ) p ( tlh ) f ( h , t ) h~ H , tE T where H is the space of possible contexts h when predicting a part of speech tag t. Since the contexts contain sequences of words and tags and other information , the space H is huge .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">the space of possible contexts h when predicting a part of speech tag</definiens>
			</definition>
			<definition id="1">
				<sentence>Special feature templates exist for rare words in the training data , to increase the model 's predictioff-capacity for unknown words .</sentence>
				<definiendum id="0">Special feature templates</definiendum>
				<definiens id="0">exist for rare words in the training data , to increase the model 's predictioff-capacity for unknown words</definiens>
			</definition>
</paper>

		<paper id="0800">
</paper>

		<paper id="1408">
			<definition id="0">
				<sentence>( from Malthus , 1798 ) Reasoning by cases ( non-exclusive ) : Failing a test .</sentence>
				<definiendum id="0">non-exclusive )</definiendum>
				<definiens id="0">Failing a test</definiens>
			</definition>
			<definition id="1">
				<sentence>Fiof prospective arguments on two models : ( 1 ) a nornally , we illustrate the operation of our mechanism mative model , which represents NAG 's beliefs , and with an example , discuss results from our prelimi ( 2 ) a user model , which represents a user 's presumed beliefs .</sentence>
				<definiendum id="0">mechanism mative model</definiendum>
				<definiendum id="1">user model</definiendum>
				<definiens id="0">represents NAG 's beliefs</definiens>
			</definition>
			<definition id="2">
				<sentence>work ( BN ) ( Pearl , 1988 ) as its main representation ity to represent normatively correct reasoning unA general introduction to hypothetical reasoning , inder uncertainty ) .</sentence>
				<definiendum id="0">BN</definiendum>
				<definiens id="0">its main representation ity to represent normatively correct reasoning unA general introduction to hypothetical reasoning , inder uncertainty )</definiens>
			</definition>
			<definition id="3">
				<sentence>An argument is represented as an cluding a discussion of counterfactual reasoning and Argument Graph , which is a network of nodes that modality , may be found in ( Rescher , 1964 ) .</sentence>
				<definiendum id="0">Argument Graph</definiendum>
				<definiens id="0">a network of nodes that modality</definiens>
			</definition>
			<definition id="4">
				<sentence>The Analyzer uses a constrained Bayesian propagation scheme on the normative and user BNs , limiting the updates to the subnetworks represented in the Argument Graph .</sentence>
				<definiendum id="0">Analyzer</definiendum>
				<definiens id="0">uses a constrained Bayesian propagation scheme on the normative and user BNs</definiens>
			</definition>
			<definition id="5">
				<sentence>Generator , which adds to the current Argument Graph new information related to these subgoals .</sentence>
				<definiendum id="0">Generator</definiendum>
				<definiens id="0">adds to the current Argument Graph new information</definiens>
			</definition>
			<definition id="6">
				<sentence>The Strategist selects an argumentation strategy based on the Analyzer 's assessment of the effect of the nodes in the Argmnent Graph on the goal proposition ( and vice versa ) .</sentence>
				<definiendum id="0">Strategist</definiendum>
				<definiens id="0">selects an argumentation strategy based on the Analyzer 's assessment of the effect of the nodes in the Argmnent Graph on the goal proposition</definiens>
			</definition>
			<definition id="7">
				<sentence>When computing positive/negative effects for a particular node , the Bayesian propagation process uses the prior beliefs of the other nodes in the Argument Graph .</sentence>
				<definiendum id="0">Bayesian propagation process</definiendum>
				<definiens id="0">uses the prior beliefs of the other nodes in the Argument Graph</definiens>
			</definition>
			<definition id="8">
				<sentence>5 Reductio ad absurdum The negation of the goal G undermines a proposition Q which is firmly believed independently of the goal ( i.e. , P ( Q ) = High , where Q is a premise or inferred from premises ) .</sentence>
				<definiendum id="0">Q</definiendum>
				<definiens id="0">a premise or inferred from premises</definiens>
			</definition>
			<definition id="9">
				<sentence>Inference to the best explanation The assertion of the goal G supports a proposition Q which is firmly believed ( i.e. , P ( Q ) = High , where Q is a premise or inferred from premises ) , but which would be unexplained ( improbable ) without supposing the truth of the goal .</sentence>
				<definiendum id="0">Q</definiendum>
				<definiens id="0">a premise or inferred from premises</definiens>
			</definition>
			<definition id="10">
				<sentence>For each proposition Q which satisfies the conditions for reductio ad absurdum , the Strategist extracts from the Argument Graph the • subgraph whicbcorresponds to the line of reasoning going from the goal node ( which was ascribed a low level of belief ) to Q ( which has been contradicted 6This situation may be generalized so that any Qi consists of a subset of propositions which lead to the goal .</sentence>
				<definiendum id="0">Strategist</definiendum>
				<definiens id="0">satisfies the conditions for reductio ad absurdum , the</definiens>
			</definition>
			<definition id="11">
				<sentence>Given a preamble that establishes that there is evil in the world , and the goal to prove that there is no God , NAG obtains the Argument Graph in Figure 3 after one focusing-generation cycle , and produces the Argument Graphs corresponding to the arguments in Figure 4 ( the adverbs that indicate level of belief and the conjunctive expressions are italicized in the arguments for ease of comparison ) .9 These arguments are based on a definition of God that requires God to be both omnipotent and benevolent .</sentence>
				<definiendum id="0">NAG</definiendum>
				<definiens id="0">obtains the Argument Graph in Figure 3 after one focusing-generation cycle</definiens>
			</definition>
			<definition id="12">
				<sentence>God wants to prevent evil ( 4 ) .</sentence>
				<definiendum id="0">God</definiendum>
			</definition>
</paper>

		<paper id="1110">
			<definition id="0">
				<sentence>Our system , SNS ( pronounced `` essence '' ) , retrieves documents related to an unrestricted user query and summarizes a subset of them as selected by the user .</sentence>
				<definiendum id="0">SNS</definiendum>
				<definiens id="0">retrieves documents related to an unrestricted user query and summarizes a subset of them as selected by the user</definiens>
			</definition>
			<definition id="1">
				<sentence>MEAD , the summarization component produces a cross-document summary of the documents selected by the user from the hit list .</sentence>
				<definiendum id="0">MEAD</definiendum>
				<definiens id="0">a cross-document summary of the documents selected by the user from the hit list</definiens>
			</definition>
			<definition id="2">
				<sentence>MySearch utilizes a centralized relational database to store all the URL indexes and other related URL information .</sentence>
				<definiendum id="0">MySearch</definiendum>
				<definiens id="0">utilizes a centralized relational database to store all the URL indexes and other related URL information</definiens>
			</definition>
			<definition id="3">
				<sentence>We used a modified version of TFIDF : log ( or+O.5 ) *log ( N/df ) , where if means the number of times a term appeared in the content of an URL , N is the total number of documents in the text collection , and dfstands for the number of unique URLs in which a term appears in the entire collection .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of times a term appeared in the content of an URL</definiens>
				<definiens id="1">the total number of documents in the text collection , and dfstands for the number of unique URLs in which a term appears in the entire collection</definiens>
			</definition>
			<definition id="4">
				<sentence>The multi-document summarization algorithm attempts to identify these themes and to identify the most salient passages from the selected documents using a pseudo-document called the cluster centroid which is computed automatically from the entire list of hits selected by the user .</sentence>
				<definiendum id="0">multi-document summarization algorithm</definiendum>
				<definiens id="0">attempts to identify these themes and to identify the most salient passages from the selected documents using a pseudo-document called the cluster centroid which is computed automatically from the entire list of hits selected by the user</definiens>
			</definition>
			<definition id="5">
				<sentence>The TF column indicates the average term frequency of a given term within the cluster .</sentence>
				<definiendum id="0">TF column</definiendum>
				<definiens id="0">indicates the average term frequency of a given term within the cluster</definiens>
			</definition>
			<definition id="6">
				<sentence>Ci is the centroid score of the sentence , P~ is the positional score of the sentence , and F~ is the score of the sentence according to the overlap with the first sentence of the document .</sentence>
				<definiendum id="0">Ci</definiendum>
				<definiendum id="1">P~</definiendum>
				<definiendum id="2">F~</definiendum>
				<definiens id="0">the centroid score of the sentence</definiens>
				<definiens id="1">the positional score of the sentence</definiens>
				<definiens id="2">the score of the sentence according to the overlap with the first sentence of the document</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , the sentence `` President Clinton met with Vernon Jordon in January '' gets a score of 243.34 which is the sum of the individual eentroid values of the words ( clinton = 36.39 ; vernon = 47.54 ; jordan = 75.81 ; january = 83.60 ) .</sentence>
				<definiendum id="0">score</definiendum>
				<definiens id="0">the sum of the individual eentroid values of the words</definiens>
			</definition>
</paper>

		<paper id="0304">
			<definition id="0">
				<sentence>• Build an initial state-based training system that creates an exploratory data set .</sentence>
				<definiendum id="0">Build</definiendum>
				<definiens id="0">an initial state-based training system that creates an exploratory data set</definiens>
			</definition>
			<definition id="1">
				<sentence>NJFun is a reM-time spoken dialogue system that provides users with information about things to do in New Jersey .</sentence>
				<definiendum id="0">NJFun</definiendum>
				<definiens id="0">a reM-time spoken dialogue system that provides users with information about things to do in New Jersey</definiens>
			</definition>
			<definition id="2">
				<sentence>NJFun uses a speech recognizer with stochastic language models trained from example user utterances , and a TTS system based on concatenative diphone synthesis .</sentence>
				<definiendum id="0">NJFun</definiendum>
				<definiens id="0">uses a speech recognizer with stochastic language models trained from example user utterances</definiens>
			</definition>
			<definition id="3">
				<sentence>Finally , `` history '' represents whether NJFun had trouble understanding the user in the earlier part of the conversation ( bad=0 , good=l ) .</sentence>
				<definiendum id="0">history</definiendum>
				<definiens id="0">NJFun had trouble understanding the user in the earlier part of the conversation ( bad=0 , good=l )</definiens>
			</definition>
</paper>

		<paper id="0201">
			<definition id="0">
				<sentence>A TMR includes , among other representational objects , instantiations of object types , relation types and property types .</sentence>
				<definiendum id="0">TMR</definiendum>
				<definiens id="0">includes , among other representational objects , instantiations of object types , relation types and property types</definiens>
			</definition>
			<definition id="1">
				<sentence>For instance , the Spanish verb comprar ( to buy ) might be associated with the ontological concept named PURCHASE which is a generic frame structure corresponding to purchasing events .</sentence>
				<definiendum id="0">PURCHASE</definiendum>
				<definiens id="0">a generic frame structure corresponding to purchasing events</definiens>
			</definition>
			<definition id="2">
				<sentence>Of the pronominal expressions , 12 were pronouns ( Pron ) or deicties such as hey ( today ) , aqui ( here ) or ahora ( now ) , 3 were ellipted ( subject ) pronouns ( PRO ) and 5 were definite articles which function as possessive adjectives ( Det \ [ = Pron\ ] ) as in : El beneficio neto ... se elev6 ... . The\ [ = Its\ ] net profits ... increased ... . However , there are in addition 129 implicit references made which need to be resolved as well .</sentence>
				<definiendum id="0">Pron</definiendum>
				<definiens id="0">addition 129 implicit references made which need to be resolved as well</definiens>
			</definition>
</paper>

		<paper id="1319">
			<definition id="0">
				<sentence>The standard search engine performs the search against the targeted database using the reformulated query with N relevant documents returned in an order of the relevance to the query ( N is a number defined by the user and it is 10 by default ) .</sentence>
				<definiendum id="0">standard search engine</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">performs the search against the targeted database using the reformulated query with N relevant documents returned in an order of the relevance to the query</definiens>
				<definiens id="1">a number defined by the user and it is 10 by default )</definiens>
			</definition>
</paper>

		<paper id="0508">
			<definition id="0">
				<sentence>Finite-state models are attractive mechanisms for language processing since they are ( a ) efficiently learnable from data ( b ) generally effective for decoding ( c ) associated with a calculus for composing models which allows for straightforward integration of constraints from various levels of language processing .</sentence>
				<definiendum id="0">Finite-state models</definiendum>
			</definition>
			<definition id="1">
				<sentence>VT = argmax P ( Ws , WT ) ( 2 ) WT \ [ TV~ = arg max P ( I~VT I AT ) ( 3 ) WTE~W T where AT is the target language model and AWT are the different reorderings of WT .</sentence>
				<definiendum id="0">AT</definiendum>
				<definiendum id="1">AWT</definiendum>
				<definiens id="0">the target language model</definiens>
				<definiens id="1">the different reorderings of WT</definiens>
			</definition>
			<definition id="2">
				<sentence>The probability P ( Ws , WT ) = P ( R ) is computed in the same way as n-gram model : where wl E LsUe , zi E LTUe , e is the empty string and wi_zi is the symbol pair ( colons are the delimiters ) drawn from the source and target language .</sentence>
				<definiendum id="0">e</definiendum>
				<definiendum id="1">wi_zi</definiendum>
				<definiens id="0">computed in the same way as n-gram model : where wl E LsUe , zi E LTUe ,</definiens>
				<definiens id="1">the empty string and</definiens>
				<definiens id="2">the symbol pair ( colons are the delimiters ) drawn from the source and target language</definiens>
			</definition>
			<definition id="3">
				<sentence>A string in a bilanguage corpus consists of sequences of tokens where each token ( wi-xi ) is represented with two components : a source word ( \ ] possibly an empty word ) as the first component and the target word ( possibly an empty word ) that is the translation of the source word as the second component .</sentence>
				<definiendum id="0">string in a bilanguage corpus</definiendum>
				<definiens id="0">consists of sequences of tokens where each token ( wi-xi ) is represented with two components : a source word ( \ ] possibly an empty word ) as the first component and the target word ( possibly an empty word ) that is the translation of the source word as the second component</definiens>
			</definition>
			<definition id="4">
				<sentence>A VNSA is a non-deterministic Stochastic Finite-State Machine ( SFSM ) that allows for parsing any possible sequence of words drawn from a given vocabulary 12 .</sentence>
				<definiendum id="0">VNSA</definiendum>
				<definiens id="0">a non-deterministic Stochastic Finite-State Machine ( SFSM ) that allows for parsing any possible sequence of words drawn from a given vocabulary 12</definiens>
			</definition>
			<definition id="5">
				<sentence>state recognizes a symbol wi E lZU { e } , where e is the empty string .</sentence>
				<definiendum id="0">e</definiendum>
				<definiens id="0">the empty string</definiens>
			</definition>
			<definition id="6">
				<sentence>The c transition from state 4 to state 6 is a back-off transition to a lower order n-gram probability .</sentence>
				<definiendum id="0">c transition</definiendum>
			</definition>
			<definition id="7">
				<sentence>The most likely string ~V~ in the word lattice is then decoded as follows : ^ W~ = argmax ( ~T o ~WT ) = arg max P ( ~VT I ) ~T ) ( 6 ) Where o is the composition operation defined for weighted finite-state machines ( Pereira and Riley , 1997 ) .</sentence>
				<definiendum id="0">o</definiendum>
				<definiens id="0">decoded as follows : ^ W~ = argmax ( ~T o ~WT ) = arg max P ( ~VT I ) ~T )</definiens>
				<definiens id="1">the composition operation defined for weighted finite-state machines</definiens>
			</definition>
</paper>

		<paper id="0906">
			<definition id="0">
				<sentence>The PoS categories were adjectives , adjunedons , adverbs , articles , conjunctions , nouns , pronouns , numerals , particles , verbs and a hold-all category ( for non-classifiable entries ) , resulting in 11 variables expressed as percentages .</sentence>
				<definiendum id="0">PoS categories</definiendum>
			</definition>
			<definition id="1">
				<sentence>Corpus H is a subset of Corpus I. Each of the speeches included in Corpus II was delivered as an opening speech Cprotoloyia '' ) at a parliament session when at least two of the studied speakers delivered speeches .</sentence>
				<definiendum id="0">Corpus H</definiendum>
				<definiens id="0">a subset of Corpus I. Each of the speeches included in Corpus II was delivered as an opening speech Cprotoloyia '' ) at a parliament session when at least two of the studied speakers delivered speeches</definiens>
			</definition>
			<definition id="2">
				<sentence>To that end , three different approaches were used : ( i ) the full model : all variables were used to determine the discriminant functions ; 38 ( ii ) the forward model : starting from an empty model , variables were introduced in order to create a reduced model , with a small number of variables ; ( iii ) the backward model : starting from the full model , variables were eliminated to create a reduced model .</sentence>
				<definiendum id="0">full model</definiendum>
				<definiendum id="1">forward model</definiendum>
				<definiendum id="2">backward model</definiendum>
				<definiens id="0">all variables were used to determine the discriminant functions</definiens>
				<definiens id="1">starting from an empty model , variables were introduced in order to create a reduced model , with a small number of variables</definiens>
				<definiens id="2">starting from the full model , variables were eliminated to create a reduced model</definiens>
			</definition>
			<definition id="3">
				<sentence>Certain speakers ( e.g. speaker A ) are more consistently recognised than others ( e.g. speaker B ) while speaker B is similar to speaker C and speaker D is similar to speaker E. This indicates that additional variables may be required to improve the classification accuracy for all speakers .</sentence>
				<definiendum id="0">Certain speakers</definiendum>
				<definiens id="0">similar to speaker E. This indicates that additional variables may be required to improve the classification accuracy for all speakers</definiens>
			</definition>
</paper>

		<paper id="0506">
			<definition id="0">
				<sentence>Machine Translation ( MT ) technology can be embedded in a device to perform real time translation of closed captions included in TV signals .</sentence>
				<definiendum id="0">Machine Translation</definiendum>
				<definiens id="0">a device to perform real time translation of closed captions included in TV signals</definiens>
			</definition>
			<definition id="1">
				<sentence>Segmentation breaks a line into one or more segments , which are passed separately to subsequent modules ( Ejerhed , 1996 ) ( Beeferman et al. , 1997 ) .</sentence>
				<definiendum id="0">Segmentation</definiendum>
				<definiens id="0">breaks a line into one or more segments , which are passed separately to subsequent modules</definiens>
			</definition>
			<definition id="2">
				<sentence>LOG : an Introduction to Computational Linguistics .</sentence>
				<definiendum id="0">LOG</definiendum>
			</definition>
</paper>

		<paper id="0601">
			<definition id="0">
				<sentence>We discuss a variety of techniques that tend to give small improvements , ranging from the fairly simple ( give verbs more weight in answer selection ) to the fairly complex ( use specific techniques for answering specific kinds of questions ) .</sentence>
				<definiendum id="0">simple</definiendum>
				<definiens id="0">give verbs more weight in answer selection</definiens>
			</definition>
			<definition id="1">
				<sentence>In particular , we used the Remedia TM reading comprehension test data as annotated by a group at MITRE Corporation , henceforth called the Deep Read group \ [ 3\ ] .</sentence>
				<definiendum id="0">Remedia</definiendum>
			</definition>
			<definition id="2">
				<sentence>Of course , our application is sentence retrieval , not document retrieval , so we define term frequency as the number of times the word appears in the candidate sentence , and document frequency as the number of sentences in which this word appears .</sentence>
				<definiendum id="0">term frequency</definiendum>
				<definiendum id="1">document frequency</definiendum>
				<definiens id="0">the number of times the word appears in the candidate sentence</definiens>
				<definiens id="1">the number of sentences in which this word appears</definiens>
			</definition>
</paper>

		<paper id="1436">
			<definition id="0">
				<sentence>The generation process consists of a series of structure mappings between adjacent strata until the SMorph stratum is reached .</sentence>
				<definiendum id="0">generation process</definiendum>
				<definiens id="0">consists of a series of structure mappings between adjacent strata until the SMorph stratum is reached</definiens>
			</definition>
</paper>

		<paper id="1221">
</paper>

		<paper id="0605">
			<definition id="0">
				<sentence>We hypothesized that by using a combination of syntactic and semantic features and machine learning techniques , we could improve the accuracy of question answering on the test set of the Remedia corpus over the reported levels .</sentence>
				<definiendum id="0">Remedia</definiendum>
				<definiens id="0">corpus over the reported levels</definiens>
			</definition>
			<definition id="1">
				<sentence>The Deep Read reading comprehension prototype system ( Hirschman et al. , 1999 ) achieves a level of 36 % of the answers correct using a bag-of-words approach together with limited linguistic processing .</sentence>
				<definiendum id="0">Deep Read reading comprehension prototype system</definiendum>
				<definiens id="0">achieves a level of 36 % of the answers correct using a</definiens>
			</definition>
			<definition id="2">
				<sentence>This tagged text is then passed to the Name Identification Module , which updates the tags of named entities with semantic information and gender when appropriate . ''</sentence>
				<definiendum id="0">Name Identification Module</definiendum>
				<definiens id="0">updates the tags of named entities with semantic information</definiens>
			</definition>
			<definition id="3">
				<sentence>The Partial Parser Module then takes this updated text and breaks it into phrases while attempting to \ ] exically disambiguate the text .</sentence>
				<definiendum id="0">Partial Parser Module</definiendum>
				<definiens id="0">takes this updated text and breaks it into phrases</definiens>
			</definition>
			<definition id="4">
				<sentence>The Comparison Module determines how strongly the phrases of a sentence are related to those of a question , and this information is passed to several 28 modules which attempt to learn which features of the comparison are the most important for identifying whether a sentence is a strong answer candidate .</sentence>
				<definiendum id="0">Comparison Module</definiendum>
				<definiens id="0">determines how strongly the phrases of a sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>Heuristics ( e.g. , looking at titles like Mr. or word endings like rifle ) are then applied to decide the semantic type of the propernoun , and if the type can not be determined , the module returns both person and location as its type .</sentence>
				<definiendum id="0">Heuristics</definiendum>
				<definiens id="0">e.g. , looking at titles like Mr. or word endings like rifle ) are then applied to decide the semantic type of the propernoun</definiens>
			</definition>
			<definition id="6">
				<sentence>The Partial Parser Module follows sequentially after the Name Identification Module .</sentence>
				<definiendum id="0">Partial Parser Module</definiendum>
				<definiens id="0">follows sequentially after the Name Identification Module</definiens>
			</definition>
			<definition id="7">
				<sentence>There were two methods we used to construct the lexicon : open lexicon , which includes all words from the development set along with all determiners , pronouns , prepositions , particles , and conjunctions ( these words are essential to achieving good sentence segmentation ) , and closed lexicon , which includes all of the development and testing words 2 .</sentence>
				<definiendum id="0">open lexicon</definiendum>
				<definiendum id="1">closed lexicon</definiendum>
				<definiens id="0">includes all words from the development set along with all determiners , pronouns , prepositions , particles , and conjunctions</definiens>
				<definiens id="1">includes all of the development and testing words 2</definiens>
			</definition>
			<definition id="8">
				<sentence>Feature types used in the lexicon include subcat , gender , agr , case , vtype ( e.g. , progressive ) , mood , gap , inverted , voice , behavior ( e.g. , mass ) , type ( e.g. , interrogative , relative ) , semtype , and conjtype ( e.g. , noun-type , verb-type , etc. ) .</sentence>
				<definiendum id="0">Feature types</definiendum>
				<definiens id="0">used in the lexicon include subcat , gender , agr , case , vtype ( e.g. , progressive ) , mood , gap , inverted , voice , behavior ( e.g. , mass )</definiens>
			</definition>
			<definition id="9">
				<sentence>NPs have the feature types : Base ( the root word of the head word of the NP ) , AGR ( number/person information ) , SemType ( the semtype of the root form in the lexicon , e.g. , person , object , event , artifact , organization ) , Label ( the role type of the word in the sentence , e.g. , subject ) , and Gender .</sentence>
				<definiendum id="0">Base</definiendum>
				<definiendum id="1">SemType</definiendum>
				<definiens id="0">the root word of the head word of the NP</definiens>
				<definiens id="1">the semtype of the root form in the lexicon , e.g. , person , object , event , artifact , organization</definiens>
				<definiens id="2">the role type of the word in the sentence</definiens>
			</definition>
			<definition id="10">
				<sentence>Verb phrases ( VPs ) have the feature types : Base , AGR , SemType ( the semtype of the root form in the lexicon , e.g. , contact , act , possession ) , Tense ( e.g. , present , past ) , and Voice .</sentence>
				<definiendum id="0">Verb phrases</definiendum>
				<definiendum id="1">VPs</definiendum>
				<definiendum id="2">SemType</definiendum>
				<definiens id="0">the semtype of the root form in the lexicon , e.g. , contact , act , possession )</definiens>
			</definition>
			<definition id="11">
				<sentence>Prepositional phrases ( PPs ) have the feature types : Prep ( the root form of the preposition word ) , SemType ( the semtype of the root form in the lexicon , e.g. , at-loc , at-time ) , Need ( the object of the preposition ) , and NeedSemType ( the semtype of the object of the preposition ) .</sentence>
				<definiendum id="0">Prepositional phrases</definiendum>
				<definiendum id="1">PPs</definiendum>
				<definiendum id="2">Prep</definiendum>
				<definiendum id="3">SemType</definiendum>
				<definiendum id="4">NeedSemType</definiendum>
				<definiens id="0">the root form of the preposition word )</definiens>
			</definition>
			<definition id="12">
				<sentence>In the case of an NP conjunction , the Base is the union of the Base of each NP , AGR is set to 3p , and SemType is assigned as that of the head word of the merged NP .</sentence>
				<definiendum id="0">Base</definiendum>
				<definiendum id="1">AGR</definiendum>
				<definiendum id="2">SemType</definiendum>
				<definiens id="0">the union of the Base of each NP</definiens>
			</definition>
			<definition id="13">
				<sentence>The rule for finding the head word of an NP is : find the FIRST consecutive noun ( propernoun ) group in the NP , then the LAST noun ( propernoun ) in this group is defined as the head word of the NP .</sentence>
				<definiendum id="0">LAST noun</definiendum>
				<definiens id="0">find the FIRST consecutive noun ( propernoun ) group in the NP</definiens>
				<definiens id="1">the head word of the NP</definiens>
			</definition>
			<definition id="14">
				<sentence>• PP rules for word-sense disambiguation : For some nouns ( propernouns ) which are the object of a preposition , the intersection of the semtype value sets of the preposition word and its object determines their semtype .</sentence>
				<definiendum id="0">PP rules for word-sense disambiguation</definiendum>
				<definiens id="0">For some nouns ( propernouns ) which are the object of a preposition , the intersection of the semtype value sets of the preposition word and its object determines their semtype</definiens>
			</definition>
			<definition id="15">
				<sentence>GAS ( Jelasity and Dombi , 1998 ) is a steady genetic algorithm with subpopulation support .</sentence>
				<definiendum id="0">GAS</definiendum>
				<definiens id="0">a steady genetic algorithm with subpopulation support</definiens>
			</definition>
</paper>

		<paper id="0704">
			<definition id="0">
				<sentence>Morphosyntactic Disambiguation ( Part of Speech tagging ) is a useful benchmark problem for system comparison because it is typical for a large class of Natural Language Processing ( NLP ) problems that can be defined as disambiguation in local context .</sentence>
				<definiendum id="0">Morphosyntactic Disambiguation</definiendum>
				<definiendum id="1">Part of Speech tagging )</definiendum>
				<definiens id="0">a useful benchmark problem for system comparison because it is typical for a large class of Natural Language Processing ( NLP ) problems that can be defined as disambiguation in local context</definiens>
			</definition>
			<definition id="1">
				<sentence>POS tagging is a useful first step in text analysis , but also a prototypical benchmark task for the type of disambiguation problems which is paramount in natural language processing : assigning one of a set of possible labels to a linguistic object given different information sources derived from the linguistic context .</sentence>
				<definiendum id="0">POS tagging</definiendum>
				<definiens id="0">a useful first step in text analysis , but also a prototypical benchmark task for the type of disambiguation problems which is paramount in natural language processing : assigning one of a set of possible labels to a linguistic object given different information sources derived from the linguistic context</definiens>
			</definition>
			<definition id="2">
				<sentence>TIMBL includes a number of algorithmic variants and parameters .</sentence>
				<definiendum id="0">TIMBL</definiendum>
			</definition>
			<definition id="3">
				<sentence>The base model ( ISl ) defines the distance between a test item and each memory item as the number of features for which they have a different value .</sentence>
				<definiendum id="0">base model ( ISl</definiendum>
				<definiens id="0">the distance between a test item and each memory item as the number of features for which they have a different value</definiens>
			</definition>
			<definition id="4">
				<sentence>The heuristic approximation of computationally expensive pure MBL variants , ( IGTREE ) , creates an oblivious decision tree with features as tests , ordered according to information gain of features .</sentence>
				<definiendum id="0">IGTREE</definiendum>
				<definiens id="0">The heuristic approximation of computationally expensive pure MBL variants</definiens>
			</definition>
			<definition id="5">
				<sentence>Prefix-letters ( p ) , suffix-letters ( s ) , the occurrence of a hyphen ( h ) or a capital ( c ) are all considered to be relevant features for the disambiguation of unknown words .</sentence>
				<definiendum id="0">Prefix-letters</definiendum>
				<definiens id="0">( p ) , suffix-letters ( s ) , the occurrence of a hyphen ( h ) or a capital</definiens>
			</definition>
</paper>

		<paper id="0503">
			<definition id="0">
				<sentence>MT has been used to facilitate cross-language information retrieval ( IR ) , topic detection and other , wide-scoped scenarios .</sentence>
				<definiendum id="0">retrieval</definiendum>
				<definiendum id="1">IR</definiendum>
				<definiens id="0">information</definiens>
			</definition>
			<definition id="1">
				<sentence>One such system , the Army Research Lab ( ARL ) FALCON system , combines scanning , optical character recognition ( OCR ) , translation and filtering into a single process .</sentence>
				<definiendum id="0">Army Research Lab</definiendum>
				<definiens id="0">combines scanning , optical character recognition ( OCR ) , translation and filtering into a single process</definiens>
			</definition>
			<definition id="2">
				<sentence>Language processing services include language/code set identification ; code set conversion ; data normalisation , including diacritic reinsertion and generalised spell checking ; format preservation for Hyper-Text Mark-up Language ( HTML ) documents ; nottranslated word preservation and others .</sentence>
				<definiendum id="0">Language processing services</definiendum>
			</definition>
			<definition id="3">
				<sentence>Operational data can have one or more of these error types : misspellings and grammar mistakes ; missing diacritics ; mixed language documents ; improper capitalisation ; transliteration / transcription / code set mismatch ; scanning ( OCR ) errors ; web page or e-mail specific standards ; conversion errors ; network transmission errors ; segmentation problems ; character omissions .</sentence>
				<definiendum id="0">segmentation</definiendum>
				<definiens id="0">misspellings and grammar mistakes ; missing diacritics ; mixed language documents</definiens>
			</definition>
			<definition id="4">
				<sentence>Documents arrive in many formats that have meaning in their structure .</sentence>
				<definiendum id="0">Documents</definiendum>
				<definiens id="0">arrive in many formats that have meaning in their structure</definiens>
			</definition>
</paper>

		<paper id="0305">
			<definition id="0">
				<sentence>As an example , when depArpVal is a simple constraint it is deemed significant if it is not the only airport serving the departure location the user requested .</sentence>
				<definiendum id="0">depArpVal</definiendum>
				<definiens id="0">a simple constraint</definiens>
			</definition>
</paper>

		<paper id="0207">
			<definition id="0">
				<sentence>Lexical Conceptual Structure is a compositional abstraction with language-independent properties that transcend structural idiosyncrasies ( Jackendoff , 1983 ; Jackendoff , 1990 ; Jackendoff , 1996 ) .</sentence>
				<definiendum id="0">Lexical Conceptual Structure</definiendum>
				<definiens id="0">a compositional abstraction with language-independent properties that transcend structural idiosyncrasies</definiens>
			</definition>
			<definition id="1">
				<sentence>The type of an LCS node is one of Event , State , Path , Manner , Property or Thing , loosely correlated with verbs prepositions , adverbs , adjectives and nouns .</sentence>
				<definiendum id="0">type of an LCS node</definiendum>
				<definiens id="0">one of Event , State , Path , Manner , Property or Thing</definiens>
			</definition>
			<definition id="2">
				<sentence>Within each of these types , there are a number of conceptual primitives of that type , which are the basic building blocks of LCS structures .</sentence>
				<definiendum id="0">conceptual primitives</definiendum>
				<definiens id="0">the basic building blocks of LCS structures</definiens>
			</definition>
			<definition id="3">
				<sentence>An LCS captures the semantics of a lexical item through a combination of semantic structure ( specified by the shape of the graph and its structural primitives and fields ) and semantic content ( specified through constants ) .</sentence>
				<definiendum id="0">LCS</definiendum>
				<definiendum id="1">semantic content</definiendum>
				<definiens id="0">captures the semantics of a lexical item through a combination of semantic structure ( specified by the shape of the graph and its structural primitives and fields</definiens>
			</definition>
			<definition id="4">
				<sentence>a '' : THETA_ROLES ( ( I `` _ag_th , instr ( with ) '' ) ) : LCS ( cause ( * thing I ) ( go ident ( * Zhing 2 ) ( toward ident ( thing 2 ) ( at ident ( thing 2 ) ( reduce+ed 9 ) ) ) ) ( ( * with 19 ) instr ( *head* ) ( thin E 20 ) ) ) : VAR_SPEC ( ( 1 ( animate + ) ) ) ) ( : DEF_WORD .</sentence>
				<definiendum id="0">LCS</definiendum>
				<definiens id="0">* with 19 ) instr ( *head* ) ( thin E 20 ) ) ) : VAR_SPEC ( ( 1 ( animate +</definiens>
			</definition>
			<definition id="5">
				<sentence>A CLCS node matches an RLCS node , if the following conditions hold : ( 7 ) a. b. C. d. e. the primitives are the same ( or primitive for one is a wild-card , represented as nil ) the types ( e.g. , thing , event , state , etc. ) are the same the fields ( e.g. , identificational , possessive , locational , etc ) are the same the positions ( e.g. , subject , argument , or modifier ) are the same all obligatory children of the RLCS node have corresponding matches to children of the CLCS Subject and argument children of an RLCS node are obligatory unless specified as optional , whereas modifiers are optional unless specified as obligatory .</sentence>
				<definiendum id="0">CLCS node</definiendum>
				<definiens id="0">the same the fields ( e.g. , identificational , possessive , locational , etc ) are the same the positions ( e.g. , subject , argument , or modifier</definiens>
			</definition>
			<definition id="6">
				<sentence>Nitrogen 's input , Abstract Meaning Representation ( AMR ) , is a labeled directed graph written using the syntax for the PENMAN Sentence Plan Language ( Penman 1989 ) .</sentence>
				<definiendum id="0">Abstract Meaning Representation</definiendum>
				<definiendum id="1">AMR</definiendum>
				<definiens id="0">a labeled directed graph written using the syntax for the PENMAN Sentence Plan Language</definiens>
			</definition>
			<definition id="7">
				<sentence>( 8 ) AMR = &lt; concept &gt; I ( &lt; label &gt; { &lt; role &gt; &lt; AMR &gt; } + ) Since the roles expected by Nitrogen 's English generation grammar do not match well with the thematic roles and features of a CLCS , we have extended the AMR language with LCS-specific relations , calling the result , an LCS-AMR .</sentence>
				<definiendum id="0">LCS-AMR</definiendum>
				<definiens id="0">extended the AMR language with LCS-specific relations</definiens>
			</definition>
			<definition id="8">
				<sentence>The result of the linearization phase is a word lattice specifying the sequence of words that make up the resulting sentence and the points of ambiguity where different generation paths are taken .</sentence>
				<definiendum id="0">linearization phase</definiendum>
				<definiens id="0">a word lattice specifying the sequence of words that make up the resulting sentence and the points of ambiguity where different generation paths are taken</definiens>
			</definition>
			<definition id="9">
				<sentence>PUNC ) ( WRD `` *end-sentence* '' EOS ) ) The keyword SEQ specifies that what follows it is a list of words in their correct linear order .</sentence>
				<definiendum id="0">PUNC )</definiendum>
				<definiens id="0">The keyword SEQ specifies that what follows it is a list of words in their correct linear order</definiens>
			</definition>
			<definition id="10">
				<sentence>For the LCS-AMR in Figure 3 , the thematic hierarchy is what determined that the lunited statesl is the subject and Iquotal is the object of the verb Ireducel .</sentence>
				<definiendum id="0">thematic hierarchy</definiendum>
				<definiens id="0">what determined that the lunited statesl is the subject and Iquotal is the object of the verb Ireducel</definiens>
			</definition>
			<definition id="11">
				<sentence>This can include ambiguity between multiple concepts , such as the example in ( 5 ) , LCS type/structure ( e.g. , thing or event , which field ) , or structural ambiguity ( subject , argument or modifier ) .</sentence>
				<definiendum id="0">LCS type/structure</definiendum>
				<definiens id="0">field ) , or structural ambiguity ( subject , argument or modifier )</definiens>
			</definition>
</paper>

		<paper id="0302">
			<definition id="0">
				<sentence>GoDiS is implemented using the TRINDIKIT software package , which enables implementation of these behaviours in a compact and natural way .</sentence>
				<definiendum id="0">GoDiS</definiendum>
				<definiendum id="1">TRINDIKIT software package</definiendum>
				<definiens id="0">enables implementation of these behaviours in a compact and natural way</definiens>
			</definition>
			<definition id="1">
				<sentence>The TRINDIKIT is a toolkit for building and experimenting with dialogue move engines and information states ( IS ) , We use the term information state to mean , roughly , the information stored internally by an agent , in this case a dialogue system .</sentence>
				<definiendum id="0">TRINDIKIT</definiendum>
				<definiens id="0">a toolkit for building and experimenting with dialogue move engines and information states</definiens>
			</definition>
			<definition id="2">
				<sentence>A dialogue move engine ( DME ) updates the information state on the basis of observed dialogue moves and selects appropriate moves to be performed .</sentence>
				<definiendum id="0">dialogue move engine</definiendum>
				<definiendum id="1">DME</definiendum>
				<definiens id="0">updates the information state on the basis of observed dialogue moves and selects appropriate moves to be performed</definiens>
			</definition>
			<definition id="3">
				<sentence>se/research/proJ ects/trlndi/ Like any dialogue system built using the TRINDIKIT , GoDiS consists of a number of modules , an information state , and a number of resources hooked up to the information state .</sentence>
				<definiendum id="0">GoDiS</definiendum>
				<definiens id="0">consists of a number of modules , an information state , and a number of resources hooked up to the information state</definiens>
			</definition>
			<definition id="4">
				<sentence>In addition to the control module , which wires together the other modules , there are six modules in • GoDiS : input , which receives input3from the user ; interpret , which interprets utterances as dialogue moves with some content ; generate , which generates natural language from dialogue moves ; output , which produces output to the user ; update , which updates the information state based on interpreted moves ; and select , which selects the next move ( s ) to perform 4 .</sentence>
				<definiendum id="0">input</definiendum>
				<definiendum id="1">generate</definiendum>
				<definiendum id="2">output</definiendum>
				<definiendum id="3">update</definiendum>
				<definiendum id="4">select</definiendum>
				<definiens id="0">receives input3from the user</definiens>
				<definiens id="1">interprets utterances as dialogue moves with some content</definiens>
				<definiens id="2">generates natural language from dialogue moves ;</definiens>
				<definiens id="3">produces output to the user</definiens>
				<definiens id="4">updates the information state based on interpreted moves</definiens>
				<definiens id="5">selects the next move ( s ) to perform 4</definiens>
			</definition>
			<definition id="5">
				<sentence>DME modules consist of a set of update rules and ( optionally ) an update algorithm governing the order in which rules are applied .</sentence>
				<definiendum id="0">DME modules</definiendum>
				<definiens id="0">consist of a set of update rules and ( optionally ) an update algorithm governing the order in which rules are applied</definiens>
			</definition>
			<definition id="6">
				<sentence>In contrast , the second dialogue ( below ) shows how GoDiS is able to accommodate the task and integrate information in the order that the user gives it .</sentence>
				<definiendum id="0">GoDiS</definiendum>
			</definition>
			<definition id="7">
				<sentence>GoDiS is a small-scale prototype and as such it suffers from the familiar drawbacks of many experimental systems : its lexicons and databases are very small , and the domain knowledge is limited .</sentence>
				<definiendum id="0">GoDiS</definiendum>
				<definiens id="0">a small-scale prototype</definiens>
			</definition>
</paper>

		<paper id="0303">
			<definition id="0">
				<sentence>U : the same day I : Okay .</sentence>
				<definiendum id="0">U</definiendum>
			</definition>
			<definition id="1">
				<sentence>U : no thank you S : Thank you for calling !</sentence>
				<definiendum id="0">U</definiendum>
				<definiens id="0">no thank you S</definiens>
			</definition>
			<definition id="2">
				<sentence>`` U '' denotes a user utterance , `` S '' a system utterance , and 'T ' an intermediate system response spoken prior to database retrieval .</sentence>
				<definiendum id="0">U</definiendum>
				<definiens id="0">a user utterance , `` S '' a system utterance , and 'T ' an intermediate system response spoken prior to database retrieval</definiens>
			</definition>
			<definition id="3">
				<sentence>A similar process takes place when the system prompts for information such as a date or a departure city .</sentence>
				<definiendum id="0">similar process</definiendum>
				<definiens id="0">takes place when the system prompts for information such as a date or a departure city</definiens>
			</definition>
			<definition id="4">
				<sentence>on the `` core dialogue , '' defined as the interval subsequent to logging on and up until the itinerary is fully specified , but has not yet been priced .</sentence>
				<definiendum id="0">core dialogue</definiendum>
				<definiens id="0">the interval subsequent to logging on and up until the itinerary is fully specified , but has not yet been priced</definiens>
			</definition>
			<definition id="5">
				<sentence>In \ [ Polifroni et al. ( 1998 ) \ ] we proposed an E-form evaluation metric , which compares an E-form obtained by parsing the original orthography against that obtained by parsing the selected recognizer hypothesis .</sentence>
				<definiendum id="0">E-form evaluation metric</definiendum>
				<definiens id="0">compares an E-form obtained by parsing the original orthography against that obtained by parsing the selected recognizer hypothesis</definiens>
			</definition>
			<definition id="6">
				<sentence>IBR measures the average number of new attributes introduced per user query .</sentence>
				<definiendum id="0">IBR</definiendum>
				<definiens id="0">measures the average number of new attributes introduced per user query</definiens>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>The computerized spoken information systems ( or Spoken Dialogue System -- SDS ) that we will consider in this paper are systems where a computer acts as the operator of some service and interacts with a user in natural language , e.g. , switch board , directory assistance , or ticket service .</sentence>
				<definiendum id="0">computerized spoken information systems</definiendum>
				<definiens id="0">the operator of some service and interacts with a user in natural language , e.g. , switch board , directory assistance , or ticket service</definiens>
			</definition>
			<definition id="1">
				<sentence>A dialogue manager facilitates the negotiation of parameter values between a user and an SDS .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">facilitates the negotiation of parameter values between a user and an SDS</definiens>
			</definition>
			<definition id="2">
				<sentence>A dialogue engine calculates predictions for how to continue a dialogue from dependent knowledge sources ( e.g. , dialogue grammar and history , application description ) .</sentence>
				<definiendum id="0">dialogue engine</definiendum>
				<definiens id="0">calculates predictions for how to continue a dialogue from dependent knowledge sources ( e.g. , dialogue grammar and history , application description )</definiens>
			</definition>
			<definition id="3">
				<sentence>A pragmatic interpreter maps syntactic/semantic interpretation results onto predictions .</sentence>
				<definiendum id="0">pragmatic interpreter</definiendum>
				<definiens id="0">maps syntactic/semantic interpretation results onto predictions</definiens>
			</definition>
			<definition id="4">
				<sentence>Third , we present some of our current primitives , and finaUy , we describe the dialogue engine and how it uses the application description and other sources to calculate dialogue primitives .</sentence>
				<definiendum id="0">dialogue engine</definiendum>
				<definiens id="0">uses the application description and other sources to calculate dialogue primitives</definiens>
			</definition>
			<definition id="5">
				<sentence>The dialogue manager takes an application description ( Section 2.2 ) and a set of dialogue strategies ( Sections 3 and 4 ) as input -- both provided by the service designer .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">takes an application description</definiens>
			</definition>
			<definition id="6">
				<sentence>Notation : A primitive is written primName ( p=v , n ) , where primName is its name ; p E params ( AD ) U { aTask } ; aTask is a special parameter whose values E tasks ( AD ) ; v is the value of p ; and n is an integer denoting the number of times a primitive has been uttered .</sentence>
				<definiendum id="0">Notation</definiendum>
				<definiendum id="1">primitive</definiendum>
				<definiendum id="2">primName</definiendum>
				<definiendum id="3">aTask</definiendum>
				<definiendum id="4">; v</definiendum>
				<definiendum id="5">n</definiendum>
				<definiens id="0">a special parameter whose values E tasks ( AD )</definiens>
				<definiens id="1">an integer denoting the number of times a primitive has been uttered</definiens>
			</definition>
			<definition id="7">
				<sentence>requestValue ( p=v ) : system asks whether the value v of parameter p is correct .</sentence>
				<definiendum id="0">requestValue</definiendum>
				<definiens id="0">system asks whether the value v of parameter p is correct</definiens>
			</definition>
			<definition id="8">
				<sentence>requestConfirm ( p=v ) : system asks whether the value v of parameter p is correct , v is a recognition result , p E params ( AD ) U { aTask } .</sentence>
				<definiendum id="0">requestConfirm ( p=v )</definiendum>
				<definiendum id="1">v</definiendum>
				<definiens id="0">system asks whether the value v of parameter p is correct ,</definiens>
			</definition>
			<definition id="9">
				<sentence>requestValueABC ( p ) : system requests the spelling of the value of parameter p. requestParam ( p=v ) : system asks whether the value v is a value for parameter p. evaluate ( p=v ) : system acknowledges value v of parameter p. promise ( p=v ) : system promises to attempt to answer the user 's request , p E params ( AD ) U { aTask } .</sentence>
				<definiendum id="0">AD</definiendum>
				<definiens id="0">p ) : system requests the spelling of the value of parameter p. requestParam ( p=v ) : system asks whether the value v is a value for parameter p. evaluate ( p=v ) : system acknowledges value v of parameter p. promise ( p=v ) : system promises to attempt to answer the user 's request , p E params (</definiens>
			</definition>
			<definition id="10">
				<sentence>inform ( aTask=v ) : system informs about the acquired database results , v E aetiveTask ( AD ) U { tooMany , zero } .</sentence>
				<definiendum id="0">inform ( aTask=v )</definiendum>
				<definiens id="0">system informs about the acquired database results</definiens>
			</definition>
			<definition id="11">
				<sentence>inform ( aTask=n ) : system presents the n'th answer to the query t. n &gt; 0 inforrnAIternative ( p ) : system informs that there are several possible values for p. p E params ( AD ) U { aTask } .</sentence>
				<definiendum id="0">inform ( aTask=n )</definiendum>
				<definiens id="0">system presents the n'th answer to the query t. n &gt; 0 inforrnAIternative ( p ) : system informs that there are several possible values for p. p E params ( AD ) U { aTask }</definiens>
			</definition>
			<definition id="12">
				<sentence>inforrnAIternative ( p=v ) : system informs that a possible value of p is v. p E params ( AD ) U { aTask } .</sentence>
				<definiendum id="0">inforrnAIternative ( p=v )</definiendum>
				<definiens id="0">system informs that a possible value of p is v. p E params</definiens>
			</definition>
			<definition id="13">
				<sentence>informPositive ( p ) : system informs that the user recognized something correctly , p E params ( AD ) U { aTask } .</sentence>
				<definiendum id="0">informPositive</definiendum>
				<definiens id="0">system informs that the user recognized something correctly , p E params</definiens>
			</definition>
			<definition id="14">
				<sentence>requestAIternatives ( p ) : user requests possible values for parameter p. requestConffirm ( aTask=n ) : user asks system to confirm an answer that it has given , e.g. , `` Was the first answer $ 30 ? ''</sentence>
				<definiendum id="0">requestAIternatives</definiendum>
				<definiens id="0">( p ) : user requests possible values for parameter p. requestConffirm ( aTask=n ) : user asks system to confirm an answer that it has given</definiens>
			</definition>
			<definition id="15">
				<sentence>informValue ( p=v ) : user provides value v for parameter p. p was requested .</sentence>
				<definiendum id="0">informValue ( p=v )</definiendum>
				<definiens id="0">user provides value v for parameter p. p was requested</definiens>
			</definition>
			<definition id="16">
				<sentence>2 informExtraValue ( p=v ) : user provides value v for parameter p. p was not requested in the preceeding system utterance .</sentence>
				<definiendum id="0">informExtraValue ( p=v )</definiendum>
				<definiens id="0">user provides value v for parameter p. p was not requested in the preceeding system utterance</definiens>
			</definition>
			<definition id="17">
				<sentence>2 inforrnPositive ( p=v ) : user confirms that the value of parameter p is v. p E params ( AD ) U { aTask } .</sentence>
				<definiendum id="0">inforrnPositive ( p=v )</definiendum>
				<definiens id="0">user confirms that the value of parameter p is v. p E params</definiens>
			</definition>
			<definition id="18">
				<sentence>changeValue ( p=v ) : user changes the value of parameter p to v instead of v ' .</sentence>
				<definiendum id="0">changeValue ( p=v )</definiendum>
				<definiens id="0">user changes the value of parameter p to v instead of v '</definiens>
			</definition>
			<definition id="19">
				<sentence>2 repeatValue ( p=v ) : user repeats the value v of parameter p.2 correctPararn ( p=v ) : user corrects that v is the value of p , not p ' .</sentence>
				<definiendum id="0">repeatValue ( p=v )</definiendum>
				<definiens id="0">user repeats the value v of parameter p.2 correctPararn ( p=v ) : user corrects that v is the value of p , not p '</definiens>
			</definition>
			<definition id="20">
				<sentence>2The pragmatic interpreter instantiates v. 133 rejectValue ( p=v ) : the user has been given a series of alternatives and chooses p= : v ' .</sentence>
				<definiendum id="0">rejectValue ( p=v )</definiendum>
				<definiens id="0">the user has been given a series of alternatives</definiens>
			</definition>
			<definition id="21">
				<sentence>navigate ( aTask=v ) : user navigates in the query results , v E { forward , backward , repeat , n } where 0 n &lt; no of query results .</sentence>
				<definiendum id="0">navigate ( aTask=v )</definiendum>
				<definiens id="0">user navigates in the query results , v E { forward , backward , repeat , n } where 0 n &lt; no of query results</definiens>
			</definition>
			<definition id="22">
				<sentence>2 rejectRequest ( p=v ) : user ignores or does not hear the system request , v E { null , didNotHear } .</sentence>
				<definiendum id="0">rejectRequest ( p=v )</definiendum>
				<definiens id="0">user ignores or does not hear the system request , v E { null</definiens>
			</definition>
			<definition id="23">
				<sentence>evaluate ( t=v ) : user evaluates an answer she has received , v E { positive , neutral , negative , cancel } .</sentence>
				<definiendum id="0">evaluate ( t=v )</definiendum>
				<definiens id="0">user evaluates an answer she has received , v E { positive , neutral , negative , cancel }</definiens>
			</definition>
			<definition id="24">
				<sentence>The dialogue engine calculates the next turn by consulting and combining information from the knowledge sources .</sentence>
				<definiendum id="0">dialogue engine</definiendum>
			</definition>
			<definition id="25">
				<sentence>It has been argued that speech act grammars can not be used to describe dialogue since utterances can be multi-functional or encode more than one speech act ; Speech act grammars can typically be in only one state at a time , thus they can not capture this phenomenon ( Levinson , 1981 ) .</sentence>
				<definiendum id="0">Speech act</definiendum>
				<definiens id="0">used to describe dialogue since utterances can be multi-functional or encode more than one speech act</definiens>
			</definition>
			<definition id="26">
				<sentence>GEN-Primitive requestValue ( film ) requestConfirm ( theatre=Ridge ) REC-Primitives informValue ( film ) informValueABC ( film ) requestAIternatives ( film ) promise ( film ) rejectRequest ( film=v ) = informGarbage ( film ) requestParam ( p ) b informExtraValue ( p ) b informValueABC ( p ) b repeatValue ( p ) ~ changeValue ( p ) c withdrawAccept ( aTask=v ) d inform Positive ( theatre -- -Ridge ) repeatValue ( theatre=Ridge ) informNegative ( theatre -- -- Ridge ) correctValue ( theatre ) informValueABC ( theatre ) rejectRequest ( theatre=v ) a inform Garbage ( theatre ) informExtraValue ( p ) b informValueABC ( p ) b repeatValue ( p ) ¢ changeValue ( p ) c withd rawAccept ( aTask=v ) 'd =Vv E { null , didNotHear } ~VpE openParams ( AD ) VpE closedParams ( AD ) ~Vv E { cancel , hangup } Table 3 : REC-primitives calculated in response to two GEN-primitives in Dialogue 3 .</sentence>
				<definiendum id="0">GEN-Primitive requestValue</definiendum>
			</definition>
			<definition id="27">
				<sentence>( pj =vj ) Vl _ &lt; j &lt; maxj rejectRequest ( pi ) Vi k &lt; i &lt; maxi Table 4 : Mapping of user primitives , p=v means that value v for param p. input onto RECthe user provided the second sys/usr pair in Dialogue 5 .</sentence>
				<definiendum id="0">p=v</definiendum>
				<definiens id="0">Mapping of user primitives</definiens>
			</definition>
			<definition id="28">
				<sentence>We give the service designer the freedom to decide which kind of dialogue she wants -- -on a high level -- and the dialogue manager combines the basic primitives accordingly .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
				<definiens id="0">combines the basic primitives accordingly</definiens>
			</definition>
</paper>

		<paper id="0712">
			<definition id="0">
				<sentence>Morphology induction is a subproblem of important tasks like automatic learning of machine-readable dictionaries and grammar induction .</sentence>
				<definiendum id="0">Morphology induction</definiendum>
				<definiens id="0">a subproblem of important tasks like automatic learning of machine-readable dictionaries and grammar induction</definiens>
			</definition>
			<definition id="1">
				<sentence>Gaussier splits words based on p-similarity words that agree in exactly the first p characters .</sentence>
				<definiendum id="0">Gaussier</definiendum>
				<definiens id="0">splits words based on p-similarity words that agree in exactly the first p characters</definiens>
			</definition>
			<definition id="2">
				<sentence>CELEX is a hand-tagged , morphologicallyanalyzed database of English words .</sentence>
				<definiendum id="0">CELEX</definiendum>
			</definition>
			<definition id="3">
				<sentence>CELEX has limited coverage of the words from our data set ( where our data consists of over eight million words from random subcollections of TREC data ( Voorhees , et a1,1997/8 ) ) , so we only considered words with frequencies of 10 or more .</sentence>
				<definiendum id="0">CELEX</definiendum>
				<definiens id="0">has limited coverage of the words from our data set ( where our data consists of over eight million words from random subcollections of TREC data ( Voorhees , et a1,1997/8 ) ) , so we only considered words with frequencies of 10 or more</definiens>
			</definition>
			<definition id="4">
				<sentence>Precision is defined to be C/ ( C+Z ) , recall is C/ ( C+D ) , and F-Score is the product of precision and recall divided by the average of the two .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">F-Score</definiendum>
				<definiens id="0">the product of precision and recall divided by the average of the two</definiens>
			</definition>
</paper>

		<paper id="1207">
			<definition id="0">
				<sentence>The segmentation component provides a word lattice of the sentence that contains all the possible words , and the final disambiguation is achieved in the parsing process .</sentence>
				<definiendum id="0">segmentation component</definiendum>
				<definiens id="0">provides a word lattice of the sentence that contains all the possible words</definiens>
			</definition>
			<definition id="1">
				<sentence>The IWP of a single character is the likelihood for this character to appear as an independent word in texts : N ( Word ( c ) ) IWP ( c ) = N ( c ) where N ( Word ( c ) ) is the number of occurrences of a character as an independent word in the sentences of a given text corpus and N ( c ) is the total number of occurrence of this character in the same corpus .</sentence>
				<definiendum id="0">IWP of a single character</definiendum>
				<definiendum id="1">N ( Word ( c ) )</definiendum>
				<definiendum id="2">N ( c )</definiendum>
				<definiens id="0">the likelihood for this character to appear as an independent word in texts</definiens>
				<definiens id="1">the number of occurrences of a character as an independent word in the sentences of a given text corpus</definiens>
				<definiens id="2">the total number of occurrence of this character in the same corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>IWP ( s ) is the probability of a sequence of two or more characters being a sequence of independent words .</sentence>
				<definiendum id="0">IWP</definiendum>
				<definiens id="0">the probability of a sequence of two or more characters being a sequence of independent words</definiens>
			</definition>
			<definition id="3">
				<sentence>To represent the likelihood for a character to appear in a given position of a word with a given POS and a given length , we assign probabilities of the following form to each character : P ( Cat , Pos , Len ) where Cat is the category/POS of a word , Pos is the position of the character in the word , and Len is the length ( number of characters ) of the word .</sentence>
				<definiendum id="0">Cat</definiendum>
				<definiendum id="1">Pos</definiendum>
				<definiendum id="2">Len</definiendum>
				<definiens id="0">the category/POS of a word ,</definiens>
				<definiens id="1">the position of the character in the word , and</definiens>
				<definiens id="2">the length ( number of characters ) of the word</definiens>
			</definition>
			<definition id="4">
				<sentence>Here are some examples : Pnl2 ( the probability of appearing as the first character of a two-character noun ) Pv22 ( the probability of appearing as the second character of a two-character verb ) Pa34 ( the probability of appearing as the third character of a four-character adjective ) The values of those 27 kinds of probabilities are obtained by processing the 85,135 headwords in our dictionary .</sentence>
				<definiendum id="0">Pnl2</definiendum>
				<definiens id="0">the probability of appearing as the first character of a two-character noun</definiens>
				<definiens id="1">the probability of appearing as the second character of a two-character verb</definiens>
				<definiens id="2">the probability of appearing as the third character of a four-character adjective</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , N ( vl2 ( c ) ) Pv12 ( c ) = N ( c ) where N ( v12 ( c ) ) is the number of occurrences of a character in the first position of a two-character verb while N ( c ) is the total number of occurrences of this character in the dictionary headwords .</sentence>
				<definiendum id="0">N ( v12 ( c ) )</definiendum>
				<definiendum id="1">N ( c )</definiendum>
				<definiens id="0">the number of occurrences of a character in the first position of a two-character verb</definiens>
				<definiens id="1">the total number of occurrences of this character in the dictionary headwords</definiens>
			</definition>
			<definition id="6">
				<sentence>~-~D passed tlhe IWP test , but failed each of the P ( Cat ) tests .</sentence>
				<definiendum id="0">~-~D</definiendum>
			</definition>
</paper>

		<paper id="1428">
			<definition id="0">
				<sentence>We present the process of integrating the lexicon with FUF/SUR ( ; E. including how to represenl the lexicon in FUF format , how to unify input with the lexicon incrementally to generate more sophisticated and informative representations , and how to design an appropriate semantic input format so that the integration of the lexicon and FUF/SURGE can be done easily .</sentence>
				<definiendum id="0">FUF/SUR</definiendum>
				<definiens id="0">including how to represenl the lexicon in FUF format , how to unify input with the lexicon incrementally to generate more sophisticated and informative representations</definiens>
			</definition>
			<definition id="1">
				<sentence>Conceptual elements are by definition domain and application dependent ( they are the primitive concepts used in an application knowledge base ) .</sentence>
				<definiendum id="0">Conceptual elements</definiendum>
				<definiens id="0">the primitive concepts used in an application knowledge base</definiens>
			</definition>
			<definition id="2">
				<sentence>WordNet is the largest lexical database to date , consisting of over 120,000 unique words ( version 1.6 ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">the largest lexical database to date , consisting of over 120,000 unique words ( version 1.6 )</definiens>
			</definition>
			<definition id="3">
				<sentence>COMLEX contains syntactic information for over 38,000 English words .</sentence>
				<definiendum id="0">COMLEX</definiendum>
			</definition>
			<definition id="4">
				<sentence>The lexicon has wide coverage : the final lexicon consists of 5,676 verbs in total , over 14,100 senses ( on average ( synsets ) .</sentence>
				<definiendum id="0">wide coverage</definiendum>
			</definition>
			<definition id="5">
				<sentence>SURGE ( Elhadad and Robin , 1996 ) is a comprehensive English Grammar written in FUF .</sentence>
				<definiendum id="0">SURGE</definiendum>
				<definiens id="0">a comprehensive English Grammar written in FUF</definiens>
			</definition>
			<definition id="6">
				<sentence>For example , revision ( Robin , 1994 ) is a technique for building semantic inputs incrementally .</sentence>
				<definiendum id="0">revision</definiendum>
				<definiens id="0">a technique for building semantic inputs incrementally</definiens>
			</definition>
			<definition id="7">
				<sentence>Nitrogen ( Langkilde and Knight , 1998 ) , a natural language generation system developed at ISI , also includes a large-scale lexicon to support the generation process .</sentence>
				<definiendum id="0">Nitrogen</definiendum>
				<definiens id="0">a natural language generation system developed at ISI</definiens>
			</definition>
			<definition id="8">
				<sentence>Nitrogen combines symbolic rules with statistics learned from text corpora , while FUF/SURGE is based on Functional Unification Grammar .</sentence>
				<definiendum id="0">Nitrogen</definiendum>
				<definiens id="0">combines symbolic rules with statistics learned from text corpora</definiens>
			</definition>
</paper>

		<paper id="0107">
			<definition id="0">
				<sentence>This example will be used to show how to define a domain using the following terms : Objects are the types of salient things in the domain .</sentence>
				<definiendum id="0">Objects</definiendum>
				<definiens id="0">the types of salient things in the domain</definiens>
			</definition>
			<definition id="1">
				<sentence>Define B ( X ) to be the number of bits conveyed by an instance of random variable X , and IX\ ] to be the number of possible values of X. ( Possible ways of computing B ( X ) will be given in the next sections . )</sentence>
				<definiendum id="0">Define B ( X )</definiendum>
				<definiens id="0">the number of bits conveyed by an instance of random variable X</definiens>
			</definition>
			<definition id="2">
				<sentence>Since objects can be grouped together into classes , a class complexity is the number of bits conveyed by distinguishing one type of object from that class , plus the maximum object complexity that occurs in that class : CC. , ... = B ( O ) + max ( OCob # ) obj~class where O is the specification of an object in class .</sentence>
				<definiendum id="0">class complexity</definiendum>
				<definiens id="0">the number of bits conveyed by distinguishing one type of object from that class , plus the maximum object complexity that occurs in that class : CC. , ... = B ( O ) + max ( OCob # ) obj~class where O is the specification of an object in class</definiens>
			</definition>
			<definition id="3">
				<sentence>For this more general case , define B ( X ) to be B ( X1 , X2 , ... X , ) where each Xi is a possible value of X. Also define pl , p2 , ... Pn to be their associated probabilities .</sentence>
				<definiendum id="0">B ( X )</definiendum>
				<definiens id="0">a possible value of X. Also define pl</definiens>
			</definition>
</paper>

		<paper id="1410">
			<definition id="0">
				<sentence>The RAGS project aims to define a reference architecture for Natural Language Generation ( NLG ) systems .</sentence>
				<definiendum id="0">RAGS project</definiendum>
			</definition>
			<definition id="1">
				<sentence>The RAGS levels of representation are as follows4 : Conceptual The conceptual level of representation is defined only indirectly through an API via which a knowledge base ( providing the content from which generation takes place ) can be viewed as if it were defined in a simple KL-ONE ( Brachman and Schmolze , 1985 ) like system .</sentence>
				<definiendum id="0">simple KL-ONE</definiendum>
				<definiens id="0">a knowledge base ( providing the content from which generation takes place</definiens>
			</definition>
			<definition id="2">
				<sentence>Abstract Document Document structure defines the linear ordering of the constituents of the Rhetorical Representation with a POSITION feature , as well as two other features , TEXT-LEVEL , which takes values such as paragraph or sentence ; and LAYOUT , which takes values such as wrapped-text and vertical list .</sentence>
				<definiendum id="0">TEXT-LEVEL</definiendum>
				<definiendum id="1">LAYOUT</definiendum>
				<definiens id="0">takes values such as paragraph or sentence</definiens>
				<definiens id="1">takes values such as wrapped-text and vertical list</definiens>
			</definition>
			<definition id="3">
				<sentence>The Caption Generation System ( CGS ) generates explanatory captions of graphical presentations ( 2D charts and graphs ) .</sentence>
				<definiendum id="0">Caption Generation System</definiendum>
				<definiens id="0">generates explanatory captions of graphical presentations ( 2D charts and graphs )</definiens>
			</definition>
			<definition id="4">
				<sentence>Text Planner The input to the Longbow text planner discussed in section 4 above is a representation of a picture in SAGE format ( which has been annotated to indicate the types of complexity of each grapheme ) together with a goal , which can typically be interpreted as `` describe '' .</sentence>
				<definiendum id="0">SAGE format</definiendum>
				<definiens id="0">annotated to indicate the types of complexity of each grapheme</definiens>
			</definition>
</paper>

		<paper id="1313">
			<definition id="0">
				<sentence>Introduction With the rapid growth of electronic documents and the great development of network in China , there are more and more people touching the Intemet , on which , however , English is the most popular language being used .</sentence>
				<definiendum id="0">English</definiendum>
				<definiens id="0">the most popular language being used</definiens>
			</definition>
			<definition id="1">
				<sentence>MI ( q , t2 ) =log z P ( t~'t2 ) ( 1 ) P ( t~ ) P ( t2 ) Where P ( tl , t z ) is the co-occurrence probability of t~ and t~ in a Chinese sentence .</sentence>
				<definiendum id="0">MI</definiendum>
				<definiens id="0">the co-occurrence probability of t~ and t~ in a Chinese sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>P ( t l ) and P ( t 2 ) are the occurrence probabilities of term t I and t 2 in a sentence .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">the occurrence probabilities of term t I and t 2 in a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>P ( tl ) = n , __~_ ( 2 ) N P ( t2 ) = n,2 ( 3 ) N P ( tl , t2 ) = n , , , ,~ ( 4 ) N Where nt~ , nt2 is the individual term frequency of term t I and t 2 respectively if either of them occur in a sentence of the collection , ntt , t ~ is the co-occurrence frequency of term t I and t 2 if they are all in a sentence of the collection .</sentence>
				<definiendum id="0">nt~</definiendum>
				<definiendum id="1">nt2</definiendum>
				<definiens id="0">the individual term frequency of term t I and t 2 respectively if either of them occur in a sentence of the collection</definiens>
				<definiens id="1">the co-occurrence frequency of term t I and t 2 if they are all in a sentence of the collection</definiens>
			</definition>
			<definition id="4">
				<sentence>N is the number of sentences of the collection .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of sentences of the collection</definiens>
			</definition>
			<definition id="5">
				<sentence>el , e2 , ... , e , are the segmented Chinese words of the query after removing the stop words .</sentence>
				<definiendum id="0">e2 , ... , e</definiendum>
				<definiens id="0">the segmented Chinese words of the query after removing the stop words</definiens>
			</definition>
			<definition id="6">
				<sentence>W ( fm t ) = lOglO ( Ot'i_Ml ( f ~ ) + fl `` o_Ml ( fm t ) ) ( 6 ) l~'llgmkl '' t `` `` z z i_Mi ( fm l ) = k=l j=l / I~llrmkl ( 7 ) k=l r \ ] ~1 l Z ZMI ( f , ~ , J~ k ) o_ MI ( fm l ) = i=l , i¢m k=l ( 8 ) r lYd • i=l , i~m Where f~ is one sense of the English translation set F m of the word e , ~ ( l = 1 , ... , IF .</sentence>
				<definiendum id="0">f~</definiendum>
				<definiens id="0">one sense of the English translation set F m of the word e</definiens>
			</definition>
			<definition id="7">
				<sentence>The first part of the formula ( 6 ) i_MI ( f~ ) reflects the probability of English translation f , ~ and f , ~ to be a phrase .</sentence>
				<definiendum id="0">i_MI</definiendum>
				<definiens id="0">the probability of English translation f</definiens>
			</definition>
</paper>

		<paper id="1417">
			<definition id="0">
				<sentence>HYSSOP is itself part of the Intelligent Decision-Support System ( IDSS ) MATRIKS ( Multidimensional Analysis and Textual Reporting for Insight Knowledge Search ) , which aims to provide a comprehensive knowledge discovery environment through seamless integration of data warehousing , OLAP , data mining , expert system and NLG technologies .</sentence>
				<definiendum id="0">HYSSOP</definiendum>
			</definition>
			<definition id="1">
				<sentence>A fragment of the sentence factor ( Matrix , FactoringStrategy ) variables : Matrix = a factorization matrix FactoringStrategy = a list of pairs ( Dimension , Order ) where Dimension ~ dimensions ( Matrix ) and Order E { increasing , decreasing } RowGroups = list of sub-rnatrices of Matnx begin ff FactoringStrategy = ernptyList then FactoringStrategy &lt; buildFactodngStrategy ( Matrix ) ; ( Dim l , 0rderl ) &lt; first ( FactoringStrategy ) ; RernainingFactoringStrategy &lt; rest ( FactoringStrategy ) ; Matrix &lt; leftShiftColumn ( Matrix , Diml ) ; Matrix &lt; sortRows ( Matnx , Dim 1 , Order1 ) ; RowGroups &lt; horizSlice ( Matrix , Dim 1 ) ; for each RowGroup in RowGroups do : RowGroup &lt; mergeCells ( RowGroup , Dim 1 ) ; ( LeftSubMatrix , RighSubMatrix ) &lt; cut ( RowGroup , Diml ) ; FactoredRightSubMatnx &lt; factor ( RightSubMatrix , RernainingFactoringStrategy ) ; RowGreup &lt; paste ( LeftSubMatrix , FactoredRightSubMatrix , Dim 1 ) ; Matrix &lt; update ( Matrix , RowGroup ) ; endfor ; return Matrix ; end .</sentence>
				<definiendum id="0">fragment of the sentence factor ( Matrix , FactoringStrategy )</definiendum>
				<definiendum id="1">Matrix</definiendum>
				<definiens id="0">variables : Matrix = a factorization matrix FactoringStrategy = a list of pairs</definiens>
			</definition>
			<definition id="2">
				<sentence>buildFactoringStrategy ( Matrix ) : returns inside a list a pair ( Dim , increasing ) where Dim is the matrix 's dimension ( i.e. , column ) with the lowest number of distinct values .</sentence>
				<definiendum id="0">buildFactoringStrategy ( Matrix )</definiendum>
				<definiens id="0">returns inside a list a pair ( Dim , increasing ) where Dim is the matrix 's dimension ( i.e. , column ) with the lowest number of distinct values</definiens>
			</definition>
			<definition id="3">
				<sentence>sortRows ( Matrix , Diml,0rder ) : sorts the Matrix 's rows in order of their Dim1 cell value ; Order specifies whether the order should be increasing or decreasing .</sentence>
				<definiendum id="0">sortRows</definiendum>
				<definiens id="0">sorts the Matrix 's rows in order of their Dim1 cell value</definiens>
			</definition>
			<definition id="4">
				<sentence>horizSlice ( Matrix , Dim 1 ) : horizontally slices the Matrix into row groups with equal value along Dim I. rnergeCetls ( RowGroup , Diml ) : merges ( by definition equal valued ) cells of Dim1 in RowGroup .</sentence>
				<definiendum id="0">horizSlice</definiendum>
				<definiens id="0">merges ( by definition equal valued ) cells of Dim1 in RowGroup</definiens>
			</definition>
			<definition id="5">
				<sentence>update ( Matrix , RowGroup ) : identifies the rows R~ of Matrix whose cell ids match those of RowGroup RG and substitute those RM by RG inside Matrix Fig .</sentence>
				<definiendum id="0">RowGroup )</definiendum>
				<definiens id="0">identifies the rows R~ of Matrix whose cell ids match those of RowGroup RG and substitute those RM by RG inside Matrix Fig</definiens>
			</definition>
			<definition id="6">
				<sentence>The definition of aggregation that we gave at the beginning of previous section is similar to those provided by Dalianis and Huang , although it focuses on common feature factorization to insure aggregation remains a proper subset of sentence planning .</sentence>
				<definiendum id="0">aggregation</definiendum>
				<definiens id="0">similar to those provided by Dalianis and Huang , although it focuses on common feature factorization to insure aggregation remains a proper subset of sentence planning</definiens>
			</definition>
</paper>

		<paper id="1102">
			<definition id="0">
				<sentence>In particular we experimented the `` Boolean phraase '' modality , which allows the user to submit queries with keywords composed by means of logical operators .</sentence>
				<definiendum id="0">Boolean phraase '' modality</definiendum>
				<definiens id="0">allows the user to submit queries with keywords composed by means of logical operators</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 4 : Example of expansion insertion composition search ( KCS ) In this composition modality a disjunctive expression is constructed where each disjoint element is an AND clause formed by one of the possible tuple derived by the expansion set of each base keyword .</sentence>
				<definiendum id="0">KCS</definiendum>
				<definiens id="0">Example of expansion insertion composition search</definiens>
				<definiens id="1">an AND clause formed by one of the possible tuple derived by the expansion set of each base keyword</definiens>
			</definition>
			<definition id="2">
				<sentence>k , VKXS , k and VKCS , k of ( pos , assessment ) pairs corresponding to the three search methods , where pos is the position • of the document in the ordered list returned by the search method , and assessment is the assessment of one participant .</sentence>
				<definiendum id="0">pos</definiendum>
				<definiendum id="1">assessment</definiendum>
				<definiens id="0">the position • of the document in the ordered list returned by the search method</definiens>
			</definition>
			<definition id="3">
				<sentence>X v ( i ) X v ( i ) / p ( i ) f ( k ) = i~v~ f. ( k ) = i~v , ra m ~l/j j=l where p ( i ) is the position of the web document in the ordered list .</sentence>
				<definiendum id="0">X v</definiendum>
				<definiens id="0">the position of the web document in the ordered list</definiens>
			</definition>
			<definition id="4">
				<sentence>QS1 is the subset of questions whose number of morphological derivations and synonyms is higher than three ; QS2 is the subset whose number of lexical expansions is equal to two or three ; QS3 is the subset whose number of lexical expansions is lower than two .</sentence>
				<definiendum id="0">QS1</definiendum>
				<definiendum id="1">QS2</definiendum>
				<definiendum id="2">QS3</definiendum>
				<definiens id="0">the subset of questions whose number of morphological derivations and synonyms is higher than three</definiens>
				<definiens id="1">the subset whose number of lexical expansions is equal to two or three</definiens>
				<definiens id="2">the subset whose number of lexical expansions is lower than two</definiens>
			</definition>
</paper>

		<paper id="1104">
			<definition id="0">
				<sentence>With this idea in mind , we designed an IR system which performs a combined wordbased and sense-based indexing and retrieval .</sentence>
				<definiendum id="0">IR system</definiendum>
				<definiens id="0">performs a combined wordbased and sense-based indexing and retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>Concept matching is a technique that has been used in limited domains , like the legal field were conceptual indexing has been applied by ( Stein , 1997 ) .</sentence>
				<definiendum id="0">Concept matching</definiendum>
				<definiens id="0">a technique that has been used in limited domains</definiens>
			</definition>
			<definition id="2">
				<sentence>He defines also a new measure , called success rate which indicates if a question has an answer in the top ten documents returned by a retrieval system .</sentence>
				<definiendum id="0">success rate</definiendum>
				<definiens id="0">indicates if a question has an answer in the top ten documents returned by a retrieval system</definiens>
			</definition>
			<definition id="3">
				<sentence>A pseudo-word is an artificially created ambiguous word , like for example `` banana-door '' ( pseudo-words have been introduced for the first time in ( Yarowsky , 1993 ) , as means of testing WSD accuracy without the costs associated with the acquisition of sense tagged corpora ) .</sentence>
				<definiendum id="0">pseudo-word</definiendum>
				<definiens id="0">an artificially created ambiguous word</definiens>
			</definition>
			<definition id="4">
				<sentence>There are three main modules used by this system : module , which performs a semi-complete but precise disambiguation of the words in the documents .</sentence>
				<definiendum id="0">module</definiendum>
				<definiens id="0">performs a semi-complete but precise disambiguation of the words in the documents</definiens>
			</definition>
			<definition id="5">
				<sentence>f.f set where : Pos is the position of the word in the text ; Stem is the stemmed form of the word ; POS is the part of speech and Offset is the offset of the WordNet synset in which this word occurs .</sentence>
				<definiendum id="0">Pos</definiendum>
				<definiendum id="1">Stem</definiendum>
				<definiendum id="2">POS</definiendum>
				<definiendum id="3">Offset</definiendum>
				<definiens id="0">the position of the word in the text</definiens>
				<definiens id="1">the stemmed form of the word ;</definiens>
				<definiens id="2">the part of speech and</definiens>
			</definition>
			<definition id="6">
				<sentence>The indexing process takes a group of document files and produces a new index .</sentence>
				<definiendum id="0">indexing process</definiendum>
				<definiens id="0">takes a group of document files and produces a new index</definiens>
			</definition>
			<definition id="7">
				<sentence>fined as the number of relevant documents retrieved over the total number of documents retrieved ; ( 2 ) real/ , defined as the number of relevant documents retrieved over the total number of relevant documents found in the collection and ( 3 ) F-measure , which combines both the precision and recall into a single formula : Fmeas~re = ( 32 + l'O ) * P * R • P ) + R where P is the precision , R is the recall and is the relative importance given to recall over precision .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the number of relevant documents retrieved over the total number of documents retrieved</definiens>
				<definiens id="1">the number of relevant documents retrieved over the total number of relevant documents found in the collection</definiens>
				<definiens id="2">combines both the precision and recall into a single formula : Fmeas~re = ( 32 + l'O ) * P * R • P ) + R where P is the precision</definiens>
				<definiens id="3">the recall and is the relative importance given to recall over precision</definiens>
			</definition>
			<definition id="8">
				<sentence>The continuously increasing amount of information available today requires more and more sophisticated IR techniques , and semantic indexing is one of the new trends when trying to improve IR effectiveness .</sentence>
				<definiendum id="0">semantic indexing</definiendum>
				<definiens id="0">one of the new trends when trying to improve IR effectiveness</definiens>
			</definition>
</paper>

		<paper id="0507">
			<definition id="0">
				<sentence>TRANSTYPE is a project set up to explore an appealing solution to the problem of using Interactive Machine Translation ( IMT ) as a tool for professional or other highly-skilled translators .</sentence>
				<definiendum id="0">TRANSTYPE</definiendum>
				<definiens id="0">a project set up to explore an appealing solution to the problem of using Interactive Machine Translation ( IMT ) as a tool for professional or other highly-skilled translators</definiens>
			</definition>
			<definition id="1">
				<sentence>IMT first appeared as part of Kay 's MIND system ( Kay , 1973 ) , where the user 's role was to help the computer analyze the source text by answering questions about word sense , ellipsis , phrasal attachments , etc .</sentence>
				<definiendum id="0">IMT</definiendum>
			</definition>
			<definition id="2">
				<sentence>So TRANSTYPE is a specialized text editor with an embedded Machine translation engine as one of its components .</sentence>
				<definiendum id="0">TRANSTYPE</definiendum>
				<definiens id="0">a specialized text editor with an embedded Machine translation engine as one of its components</definiens>
			</definition>
			<definition id="3">
				<sentence>The potential gain from multiple-word predictions ( Langlais et al. , 2000 ) can be appreciated in the one-sentence translation task reported in table 1 , where a hypothetical user saves over 60 % of the keystrokes needed to produce a translation in a word completion scenario , and about 75 % in a `` unit '' completion scenario The core of TRANSTYPE is a completion engine which comprises two main parts : an evaluator which assigns probabilistic scores to completion 47 This bill is very similar to its companion bill which we dealt with yesterday in the house of commons word-completion task .</sentence>
				<definiendum id="0">multiple-word predictions</definiendum>
				<definiendum id="1">TRANSTYPE</definiendum>
				<definiens id="0">a completion engine which comprises two main parts : an evaluator which assigns probabilistic scores</definiens>
			</definition>
			<definition id="4">
				<sentence>The evaluator is a function p ( t\ [ t ' , s ) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens t ' which precede t in the current translation of s. Our approach to modeling this distribution is based to a large extent on that of the IBM group ( Brown et al. , 1993 ) , but it diflhrs in one significant aspect : whereas the IBM model involves a `` noisy channel '' decomposition , we use a linear combination of separate predictions from a language model p ( t\ [ t ' ) and a translation model p ( t\ [ s ) .</sentence>
				<definiendum id="0">evaluator</definiendum>
				<definiendum id="1">IBM model</definiendum>
				<definiendum id="2">translation model p</definiendum>
				<definiens id="0">a function p ( t\ [ t ' , s ) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens t ' which precede t in the current translation of s. Our approach to modeling this distribution is based to a large extent on that of the IBM group ( Brown et al. , 1993 ) , but it diflhrs in one significant aspect : whereas the</definiens>
			</definition>
			<definition id="5">
				<sentence>O ( t~ , s ) stands for any function which maps t~ , s into a set of equivalence classes .</sentence>
				<definiendum id="0">O</definiendum>
				<definiens id="0">any function which maps t~ , s into a set of equivalence classes</definiens>
			</definition>
			<definition id="6">
				<sentence>The total probability of the ith target-text token ti is just the average of the probabilities with which it is generated by each source text token sj ; this is a weighted average that takes the distance from the generating token into account : is1 p ( tils ) = ~p ( tilsj ) a ( jli , Is\ [ ) j=O ( 3 ) where p ( ti Is j ) is a word-for-word translation probability , Isl is the length ( counted in tokens ) ofthe source segment s under translation , and a ( jli , Is\ ] ) is the a priori alignment probability that the target-text token at position i will be generated by the source text token at position j ; this is equal to a constant value of 1~ ( Is I + 1 ) for model 1 .</sentence>
				<definiendum id="0">total probability</definiendum>
				<definiendum id="1">p ( ti Is j )</definiendum>
				<definiendum id="2">Isl</definiendum>
				<definiens id="0">the average of the probabilities with which it is generated by each source text token sj</definiens>
				<definiens id="1">a word-for-word translation probability</definiens>
				<definiens id="2">the length ( counted in tokens ) ofthe source segment s under translation</definiens>
				<definiens id="3">the a priori alignment probability that the target-text token at position i will be generated by the source text token at position j</definiens>
			</definition>
			<definition id="7">
				<sentence>The passive vocabulary is a large dictionary containing over 380,000 word forms .</sentence>
				<definiendum id="0">passive vocabulary</definiendum>
			</definition>
			<definition id="8">
				<sentence>Acknowledgements TRANSTYPE is a project funded by the Natural Sciences and Engineering Research Council of Canada .</sentence>
				<definiendum id="0">Acknowledgements TRANSTYPE</definiendum>
				<definiens id="0">a project funded by the Natural Sciences and Engineering Research Council of Canada</definiens>
			</definition>
</paper>

		<paper id="0301">
			<definition id="0">
				<sentence>The email agent , however , incorporates a speech and natural language understanding system developed by IBM Research , allowing users to collaborate either entirely in speech or with a mixture of speech and interface actions , such as selecting a message .</sentence>
				<definiendum id="0">IBM Research</definiendum>
				<definiens id="0">incorporates a speech and natural language understanding system developed by</definiens>
			</definition>
			<definition id="1">
				<sentence>The Collagen email agent , called Daffy , performs actions requested by the user with speech and watches user interface actions .</sentence>
				<definiendum id="0">Collagen email agent</definiendum>
				<definiens id="0">performs actions requested by the user with speech and watches user interface actions</definiens>
			</definition>
</paper>

		<paper id="0900">
</paper>

		<paper id="1422">
			<definition id="0">
				<sentence>MASCULINE ) : ( definite NOART ) ) ) ( second ( ( template PRONOUN ) ) ) ) ) ( person SECOND ) ( number PLURAL ) ) ) ( phenomenon ( ( template NOUN-PHRASE ) ( head `` dog '' ) ( definite NOART ) ( possessor ( ( template NOUN-PHRASE ) ( head `` sister '' ) ( gender FEMININE ) ( definite NOART ) ( possessor ( ( template NOUN-PHRASE ) ( rear-circum ( ( template CLAUSE ) ( mood T0-INFINITIVE ) ( process-type MATERIAL ) ( process `` swim '' ) ) ) ) Figure 1 : A Feature Structure for ( head `` Jack '' ) ( np-type PROPER ) ( gender MASCULINE ) ( pronominal YES ) ( definite NOART ) ) ) ) ) ) ) the Sentence `` Jack and I want his sister 's dog to swim . ''</sentence>
				<definiendum id="0">MASCULINE ) :</definiendum>
				<definiens id="0">( definite NOART ) ) ) ( second ( ( template PRONOUN ) ) ) ) ) ( person SECOND ) ( number PLURAL ) ) ) ( phenomenon ( ( template NOUN-PHRASE ) ( head `` dog ''</definiens>
			</definition>
			<definition id="1">
				<sentence>YAG ( Yet Another Generator ) ( Channarukul , 1999 ; McRoy et al. , 1999 ) is a template-based textrealization system that generates text in real-time .</sentence>
				<definiendum id="0">YAG</definiendum>
				<definiendum id="1">Yet Another Generator )</definiendum>
				<definiens id="0">a template-based textrealization system that generates text in real-time</definiens>
			</definition>
			<definition id="2">
				<sentence>In Figure 3 , it was not necessary for the application to specify that the conjunction of two noun phrases is a phlral noun phrase , nor that component noun phrases ( proper nouns , pronouns , and possessives ) should not , contain an article .</sentence>
				<definiendum id="0">component noun phrases</definiendum>
				<definiens id="0">proper nouns , pronouns , and possessives</definiens>
			</definition>
			<definition id="3">
				<sentence>CAUSATIVE PRESENT , PAST YES , NO YES , N0 YES , N0 ACTIVE , PASSIVE POSITIVE , NEGATIVE COMMON , PROPER FIRST , SECOND , THIRD SINGULAR , PLURAL NEUTRAL , MASCULINE , FEMININE YES , N0 , NOART YES , NO YES , NO YES , NO YES , NO POSSESSOR pronominal YES YES , NO PRONOUN PERSONAL FIRST SINGULAR NEUTRAL person number gender PERSONAL , OBJECTIVE , REFLEXIVE , POSSESSIVE-PRONOUN , POSSESSIVE-DETERMINER , RELATIVE , DEMONSTRATIVE FIRST , SECOND , THIRD SINGULAR , PLURAL NEUTRAL , MASCULINE , FEMININE CONJUNCTION sentence NO YES , NO Figure 2 : Some Defaults from YAG 's Syntactic Templates .</sentence>
				<definiendum id="0">OBJECTIVE</definiendum>
				<definiendum id="1">PLURAL NEUTRAL</definiendum>
			</definition>
			<definition id="4">
				<sentence>( ( template CLAUSE ) ( process-type MENTAL ) ( process `` want '' ) ( processor ( ( template CONJUNCTION ) ( first ( ( template NOUN-PHRASE ) ( head `` Jack '' ) ( np-type PROPER ) ( gender MASCULINE ) ) ) ( second ( ( template PRONOUN ) ) ) ) ) ( phenomenon ( ( template NOUN-PHRASE ) ( head `` dog '' ) ( possessor ( ( template NOUN-PHRASE ) ( head `` sister '' ) ( gender FEMININE ) • ~ ( possessor &lt; ( template NOUN-PHRASE ) ( head `` Jack '' ) ( np-type PROPER ) ( gender MASCULINE ) ( pronominal YES ) ) ) ) ) ) ) ( rear-circum ( ( template CLAUSE ) ( mood T0-INFINITIVE ) ( process-type MATERIAL ) ( process `` swim '' ) ) ) ) Figure 3 : A ( shorter ) Feature Struclur ( ) of the Sentence `` Jack and I want his .</sentence>
				<definiendum id="0">template CLAUSE ) ( process-type MENTAL ) ( process</definiendum>
				<definiendum id="1">template NOUN-PHRASE</definiendum>
				<definiens id="0">A ( shorter ) Feature Struclur ( ) of the Sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>An attribute grammar consists of a context-free grammar , a finite set of attributes , and a set of semantic rules .</sentence>
				<definiendum id="0">attribute grammar</definiendum>
				<definiens id="0">consists of a context-free grammar , a finite set of attributes , and a set of semantic rules</definiens>
			</definition>
			<definition id="6">
				<sentence>Attribute Evaluation is the process of computing values for every attribute instance in the tree according to the semantic rules defined for each production .</sentence>
				<definiendum id="0">Attribute Evaluation</definiendum>
				<definiens id="0">the process of computing values for every attribute instance in the tree according to the semantic rules defined for each production</definiens>
			</definition>
			<definition id="7">
				<sentence>This attribute grammar consists of two nonterminals , two terminals , andthree production rules .</sentence>
				<definiendum id="0">attribute grammar</definiendum>
				<definiens id="0">consists of two nonterminals , two terminals , andthree production rules</definiens>
			</definition>
			<definition id="8">
				<sentence>( ( template CONJUNCTION ) ( : first ( ( template NOUN-PHRASE ) ( head `` Jack '' ) ( np-type PROPER ) ( gender MASCULINE ) ) ) ( second ( ( template PRONOUN ) ) ) ) This fragment is the subject of the sentence , therefore features such as person and number would be required to enforce tile subject-verb agreement of English .</sentence>
				<definiendum id="0">template CONJUNCTION )</definiendum>
				<definiens id="0">template NOUN-PHRASE ) ( head `` Jack '' ) ( np-type PROPER ) ( gender MASCULINE ) ) ) ( second ( ( template PRONOUN ) ) ) ) This fragment is the subject of the sentence</definiens>
			</definition>
			<definition id="9">
				<sentence>( ( first third ) second ) ( ( second third ) second ) ( third third ) ) ) ) ( ( this syn number ) PLURAL ) ( ( this syn gender ) NEUTRAL ) ( ( this syn definite ) NOART ) ( ( this syn sentence ) ( UNION ( first syn sentence ) ( second syn sentence ) ) ) ( ( this definite ) ( this inh definite ) ) ( ( this number ) ( this inh number ) ) ( ( this np-type ) ( this inh np-type ) ) ( ( determiner inh number ) ( this inh number ) ) ( ( this syn definite ) ( IF ( AND ( NULL ( this possessor ) ) ( NULL ( this determiner ) ) ) THEN ( UNION ( this definite ) ( CASE ( this np-type ) OF ( ( common NO ) ( proper NOART ) ) ) ) ELSE ( UNION ( this definite ) ( possessor syn definite ) ( determiner syn definite ) ) ) ) ( ( this syn number ) ( UNION ( determiner syn number ) ( this number ) ) ) ( ( this syn person ) ( this person ) ) ( ( this syn np-type ) ( CASE ( this definite ) OF ( ( NO COMMON ) ( NOART PROPER ) ) ) ) ( ( this syn person ) ( this person ) ) ( ( this syn number ) ( this number ) ) ( ( this syn gender ) ( this gender ) ) ( ( this syn sentence ) NO ) ( ( this syn definite ) NOART ) Figure 7 : Semantic Rules of the CONJUNCTION , NOUN-PHRASE , and PRONOUN template .</sentence>
				<definiendum id="0">UNION</definiendum>
				<definiendum id="1">NULL</definiendum>
				<definiendum id="2">NULL</definiendum>
				<definiendum id="3">UNION</definiendum>
				<definiendum id="4">CASE</definiendum>
				<definiendum id="5">UNION</definiendum>
				<definiendum id="6">determiner syn number )</definiendum>
				<definiendum id="7">CASE</definiendum>
				<definiens id="0">this determiner</definiens>
			</definition>
</paper>

		<paper id="1407">
			<definition id="0">
				<sentence>Introduction Arguing involves an intentional communicative act that attempts to create , change or reinforce the beliefs and attitudes of another person .</sentence>
				<definiendum id="0">Introduction Arguing</definiendum>
				<definiens id="0">involves an intentional communicative act that attempts to create</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , an AMVF predicts the value v ( e ) of an entity e as follows : v ( e ) = v ( xl ... .. x , ) = Y~w , v/x9 , where ( x/ ... .. x , , ) is the vector of attribute values for an entity e Vattribute i , v , is the component value function , which maps the least preferable x , to 0 , the most preferable to I , and the other x , to values in \ [ 0,1\ ] w , is the weight for attribute i , with 0_ &lt; w , _ &lt; 1 and Zw , =1 w , is equal to the product of all the weights from the root of the value tree to the attribute i A function vo ( e ) can also be defined for each objective .</sentence>
				<definiendum id="0">AMVF</definiendum>
				<definiendum id="1">function vo</definiendum>
				<definiens id="0">maps the least preferable x , to 0 , the most preferable to I</definiens>
			</definition>
			<definition id="2">
				<sentence>Guidelines ( b ) Since argumentative intent is a value judgment , we canreasonab\ [ y assume that instead of being simply positive or negative , it may be specified more precisely as a number in the interval \ [ 0,1\ ] ( or as a specification that can be normalized in this interval ) , Then , the term paper we do not discuss arguments with a neutral argumentative intent .</sentence>
				<definiendum id="0">Guidelines</definiendum>
				<definiens id="0">a specification that can be normalized in this interval</definiens>
			</definition>
			<definition id="3">
				<sentence>In these strategies , the compellingness of an objective measures the objective 's strength in determining the overall value difference between the two alternatives , other things being equal .</sentence>
				<definiendum id="0">compellingness of an objective</definiendum>
				<definiens id="0">measures the objective 's strength in determining the overall value difference between the two alternatives , other things being equal</definiens>
			</definition>
			<definition id="4">
				<sentence>The formal definitions are : compellingness ( o , al , a2 , refo ) = = w ( o , refo ) \ [ vo ( at ) Vo ( a2 ) \ ] , where o is an objective , a/and a2 are alternatives , refo is an ancestor of o in the value tree w ( o , refo ) is the product of the weights of all the links from o to refo vo is the component value function for leaf objectives ( i.e. , attributes ) , and it is the recursive evaluation over children ( o ) for nonleaf objectives notably-compelling ?</sentence>
				<definiendum id="0">refo vo</definiendum>
				<definiens id="0">the product of the weights of all the links from o to</definiens>
			</definition>
			<definition id="5">
				<sentence>al , a2 , refo ) \ [ compellingness ( o , al , a2 , refo ) \ [ &gt; px+ko'x , where o , al , a2 and refo are defined as in the previous Def ; opop is an objective population ( e.g. , siblings ( o ) ) , and I opopl &gt; 2 pe opop ; xeX = \ [ compellingness ( p , al , a_~ , refo ) l gx is the mean of X , ~x is the standard deviation and k is a user-defined constant We have defined similar measures for arguing the value of a single entity and we named them s-compellingness and s-notably-compelling ?</sentence>
				<definiendum id="0">opop</definiendum>
				<definiendum id="1">~x</definiendum>
				<definiens id="0">an objective population ( e.g. , siblings ( o ) )</definiens>
			</definition>
			<definition id="6">
				<sentence>~ArglnO ; guideline ( a ) SecondBestObjlnFavor~-second most compelling objective o lo E AlllnFavor RemainingObjectiveslnFavor ~AlllnFavor SecondBestObjlnFavor ContrastingObjectives ~AllEvidence AlllnFavor ; guideline ( a ) ; ; ordering the selected content AddOrdering ( Root -~AllEvidence ) ; ; we assume MD=0 , so claim is not objectionable ; guideline ( b ) If Aware ( User , ContrastingObjectives ) then ; guideline ( f ) AddOrdering ( ContrastingObjectives -~ AlllnFavor ) Else AddOrdering ( ContrastingObjectives ~A lllnFavor ) ; A ddOrdering ( RemainingObjectiveslnFavor -~ SecondBestObjlnFavor ) ; guideline ( d ) Sort ( RemainingObjectiveslnFavor , '' decreasing order according to Measure-of-strength ) ; guideline ( d ) Sort ( ContrastingObjectives , '' strong ones in the middle , weak ones upfront and at the end ) ; guideline ( e ) ; ; steps for expressing or further argue the content Express-Value ( subject , Root , Arglnt ) For all o ~ AlllnFavor , If ~leaffo ) then Argue ( subject , o , SVo , k ) Else Express-Value ( subject , o , SVo ) For all o E ContrastingObjectives , Express-Value ( subject , o , SVo ) ; guideline ( e ) Legend : ( a -~ b ) ~ a preceeds b ( v~ ~v 2 ) ~ vl and v 2 are both positive or negative values ( see Section O for what this means for d~erent subjects ) - , .</sentence>
				<definiendum id="0">ddOrdering</definiendum>
				<definiens id="0">a ) SecondBestObjlnFavor~-second most compelling objective o lo E AlllnFavor RemainingObjectiveslnFavor ~AlllnFavor SecondBestObjlnFavor ContrastingObjectives ~AllEvidence AlllnFavor ; guideline ( a ) ; ; ordering the selected content AddOrdering ( Root -~AllEvidence )</definiens>
				<definiens id="1">expressing or further argue the content Express-Value ( subject , Root</definiens>
				<definiens id="2">subject , o , SVo , k ) Else Express-Value ( subject , o , SVo ) For all o E ContrastingObjectives , Express-Value ( subject , o</definiens>
			</definition>
</paper>

		<paper id="1206">
			<definition id="0">
				<sentence>The SIFAS ( Syntactic Marker based Full-Text Abstraction System ) system has been implemented to use discourse markers in the automatic summarization of Chinese ( T'sou et al. 1999 ) .</sentence>
				<definiendum id="0">SIFAS</definiendum>
				<definiens id="0">Syntactic Marker based Full-Text Abstraction System</definiens>
			</definition>
			<definition id="1">
				<sentence>We describe the i th apparent discourse marker using a 3-Tuple ADM~ : ADMi = &lt; LIi , * , SNi &gt; , where LIi : the Lexical Item of the apparent discourse marker .</sentence>
				<definiendum id="0">LIi</definiendum>
				<definiens id="0">the Lexical Item of the apparent discourse marker</definiens>
			</definition>
			<definition id="2">
				<sentence>SNi : the Sequence Number of the apparent discourse marker .</sentence>
				<definiendum id="0">SNi</definiendum>
			</definition>
			<definition id="3">
				<sentence>The SIFAS tagging system works in two modes : automatic and interactive ( semiautomatic ) .</sentence>
				<definiendum id="0">SIFAS tagging system</definiendum>
			</definition>
			<definition id="4">
				<sentence>C4.5 is one such system that learns decision-tree classifiers .</sentence>
				<definiendum id="0">C4.5</definiendum>
				<definiens id="0">one such system that learns decision-tree classifiers</definiens>
			</definition>
			<definition id="5">
				<sentence>Di I. Info ( Di ) i=l I DI Gain ratio ( D , T ) = gain ( D , T ) / Split ( D , T ) where , p ( c~ , D ) denotes the proportion of cases in D that belong to the i th class .</sentence>
				<definiendum id="0">D )</definiendum>
				<definiens id="0">the proportion of cases in D that belong to the i th class</definiens>
			</definition>
			<definition id="6">
				<sentence>The order of these attributes is : CDM , F1 , F2 , B1 , B2 , Fcom , Boom Acorn for Null marker location , and CDM , F1 , F2 , B1 , B2 , Fcom , Bcom , IsRDM for CDM classification , where IsRDM is a Boolean value .</sentence>
				<definiendum id="0">IsRDM</definiendum>
				<definiens id="0">a Boolean value</definiens>
			</definition>
			<definition id="7">
				<sentence>The Feature Extractor extracts syntactic information about the current CDM and send it to the Rule Interpreter ( see below ) .</sentence>
				<definiendum id="0">Feature Extractor</definiendum>
				<definiens id="0">extracts syntactic information about the current CDM and send it to the Rule</definiens>
			</definition>
</paper>

		<paper id="1312">
			<definition id="0">
				<sentence>For those with limited knowledge of the other language ( s ) , CLIR offers a wide pool of documents , even though the user does not have the skill to prepare a high quality query in the other language ( s ) .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">offers a wide pool of documents</definiens>
			</definition>
			<definition id="1">
				<sentence>For the user who is fluent in two or more languages , even though he/she may be able to formulate good queries in each of the source languages , CLIR relieves the user from having to do so .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">relieves the user from having to do so</definiens>
			</definition>
			<definition id="2">
				<sentence>Most CLIR studies have been based on a variant of tf-idf ; our experiments instead use a hidden Markov model ( HMM ) to estimate the probability that a document is relevant given the query .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">relevant given the query</definiens>
			</definition>
			<definition id="3">
				<sentence>Following Miller et al. , 1999 , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .</sentence>
				<definiendum id="0">IR system</definiendum>
			</definition>
			<definition id="4">
				<sentence>number of occurrences of W in C x • e0e IGx ) = length of Cx which is the general language probability for word W in language x. number of occurrences of W in D • e ( WlD ) = length of D In principle , any large corpus Cx that is representative of language x can be used in computing the general language probabilities .</sentence>
				<definiendum id="0">length of Cx</definiendum>
				<definiens id="0">the general language probability for word W in language x. number of occurrences</definiens>
			</definition>
			<definition id="5">
				<sentence>Transliteration , a technique that guesses the likely translations of a word based on pronunciation , can be readily used in translating proper nouns .</sentence>
				<definiendum id="0">Transliteration</definiendum>
				<definiens id="0">a technique that guesses the likely translations of a word based on pronunciation</definiens>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>Conversational grunts , such as uhhuh , un-hn , rnrn , and oh are ubiquitous in spoken English , but no satisfactory scheme for transcribing these items exists .</sentence>
				<definiendum id="0">Conversational grunts</definiendum>
				<definiens id="0">such as uhhuh , un-hn , rnrn , and oh are ubiquitous in spoken English , but no satisfactory scheme for transcribing these items exists</definiens>
			</definition>
			<definition id="1">
				<sentence>The central inspiration here is the fact that grunts are unlike words , in that they contain sounds which are never seen in the lexical items of the language .</sentence>
				<definiendum id="0">grunts</definiendum>
				<definiens id="0">contain sounds which are never seen in the lexical items of the language</definiens>
			</definition>
</paper>

		<paper id="0732">
</paper>

		<paper id="0738">
			<definition id="0">
				<sentence>XML is used as a serial syntax definition language , describing knowledge in terms of concepts and role restrictions ( i.e. alland cardinality-restrictions as in the DL , A£ .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">a serial syntax definition language , describing knowledge in terms of concepts</definiens>
			</definition>
			<definition id="1">
				<sentence>GermaNet is the German counterpart to the well known WordNet .</sentence>
				<definiendum id="0">GermaNet</definiendum>
				<definiens id="0">the German counterpart to the well known WordNet</definiens>
			</definition>
			<definition id="2">
				<sentence>First , the algorithm checks whether the conflicting dictionary head word denotes an acronym ( e.g. ALE is an acronym for unemployment benefits in German .</sentence>
				<definiendum id="0">e.g. ALE</definiendum>
				<definiens id="0">an acronym for unemployment benefits in German</definiens>
			</definition>
			<definition id="3">
				<sentence>Confidence denotes the part of all couplings supporting both domain and range concepts within the number of couplings that support the same domain concept .</sentence>
				<definiendum id="0">Confidence</definiendum>
				<definiens id="0">the part of all couplings supporting both domain and range concepts within the number of couplings that support the same domain concept</definiens>
			</definition>
</paper>

	</volume>
