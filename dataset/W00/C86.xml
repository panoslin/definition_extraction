<?xml version="1.0" encoding="UTF-8"?>
	<volume id="C86">

		<paper id="1097">
			<definition id="0">
				<sentence>SQL/DS ( Structured Query Language/Data System \ [ IBM8308\ ] ) is a relational \ [ CODD7006\ ] database management system .</sentence>
				<definiendum id="0">SQL/DS</definiendum>
				<definiens id="0">a relational \ [ CODD7006\ ] database management system</definiens>
			</definition>
			<definition id="1">
				<sentence>tail ( I , J , K , V , H ) pune ( I , J , K , D ) sent ( I , J , S ) para ( l , P ) text ( T ) V is a list of function words in the segment X and the part-of-speech of the last function word is H. D is either a period or a comma of the segment X if any .</sentence>
				<definiendum id="0">J , S ) para</definiendum>
				<definiendum id="1">V</definiendum>
				<definiendum id="2">H. D</definiendum>
				<definiens id="0">I , J , K , V , H ) pune ( I , J , K , D ) sent ( I ,</definiens>
			</definition>
			<definition id="2">
				<sentence>S is a sequence of segments seg ( I , J , K , X ) .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">a sequence of segments seg ( I , J , K , X )</definiens>
			</definition>
			<definition id="3">
				<sentence>Segij is a shorthand notation for a segment X appeared in the i-th row of the KWIC view satisfying seg ( pi , s , j , X ) for some p~ and s~ .</sentence>
				<definiendum id="0">Segij</definiendum>
				<definiens id="0">a shorthand notation for a segment X appeared in the i-th row of the KWIC view satisfying seg ( pi , s , j</definiens>
			</definition>
			<definition id="4">
				<sentence>Keyx equals the content word of Seg .</sentence>
				<definiendum id="0">Keyx</definiendum>
			</definition>
			<definition id="5">
				<sentence>Some sample proofreading rules are A rule for detecting incorrect ending of sentences rule ( 'terminatiw ; ' ) &lt; tail ( I , J , K , T , H ) &amp; end ofsentence ( E ) &amp; category ( 'terminative ' , H ) &amp; NOT punc ( I , J , K , E ) &amp; warning 1 ( 'missing punctuation ' , I , J , K ) . This rule scans the function words of text. If a segment ends with a flmction word ( the last : element of the list T in `` tail '' ) , which usually implies the `` end-of -- sentence ' , but is not followed by a punctuation mark ( period ) E , then give a warning to the author. A rule for detecting an inconsistent use of numeric prefixes One is Alphabetical prefix and another is Chinese numeric prefix rule ( 'numbers ' ) &lt; head ( ll , J I , K I , U1 , YI , G I , L1 ) &amp; number -prefix ( K I , L 1 , P l , W 1 ) &amp; head ( I2 , J2 , K2 , U2 , Y2 , G2 , L2 ) &amp; number -prefix ( K2 , L2 , P2 , Wl ) &amp; char-type ( P1 , T1 ) &amp; chartype ( P2 , T2 ) &amp; ne ( Tl , T2 ) &amp; warning2 ( 'numbers ' , II , Jl , Kl , I2 , J2 , K2 ) . This rule detects the inconsistent usage of Kanji and Roman numeric prefixes for some content word. if some primitive word Wl is preceded by numeric prefixes P1 and P2 denoting the same numbers but not of the same character type , then give a warning to the author. `` Number-prefix ( K , L , P , W ) ' succeeds if there is a number prefix P preceding a primitive word W in the compound word K , where the constituent types are listed in L. `` Chartype ( P , T ) '' succeeds if a 2-byte character string P consists of only one character type ( `` Kanji '' , `` Hiragana '' , `` Kanakana '' , or `` Roman '' ) or if P is `` mixed '' . KWIC Rules KWIC rules , in contrast with the source rules , refer to keywords of the KWIC view rather than the `` segment '' or `` head '' above. In the KWIC view , as explained in the previous subsection , if Keyj ... .. Keyk is the phonetic ordering , homonyms are arranged adjacently. This greatly reduces the time to detect homonym errors ( conversion errors ) because the system only has to scan the keywords Keyi once to examine the pronunciation of Key~ and Key~ , and possibly some other local conditions. For example , we can express possible conversion errors as follows. 415 ruleKWIC ( 'misconversion ' ) &lt; isordered ( 'pronunciation ' ) &amp; key ( I1 , U1 , YI , G1 ) &amp; nextkey ( I1 , U2 , YI , G2 ) &amp; ne ( UI , U2 ) &amp; pred ( I1 , P ) &amp; pred ( I2 , P ) &amp; succ ( I1 , S ) &amp; succ ( I2 , S ) &amp; wamingKWIC ( 'misconversion ' , I 1 ) . If there are distinct keywords U1 and U2 with the same pronunciation Y1 in the same context P ( preceding primitive word ) and S ( succeeding primitive word ) , then one of them is possibly a misconversion. `` Key ( I , U , Y , G ) '' is Key~ = U with pronunciation Y and lexical category G. `` Next-key ( I , U , Y , G ) '' unifies with key ( I1 , U , G , Y ) such that II=I+l. If Key~ , ... , Keyk are ordered either by their preceding or succeeding word , we can detect some lack of conformity in word usage. For example , if keywords are ordered by their succeeding words , the following case will be detected. ... be a spelling error in such cases . , . ... can find style errors as well as , .. ... to detect stylistic errors in the text ... ruleKWIC ( 'inconsistency ' ) &lt; ordered ( 'successor ' ) &amp; key ( II , U1 , Yl , Gl ) &amp; nextkey ( II , U2 , YI , G2 ) &amp; ne ( Ul , U2 ) &amp; stem ( U1 , S ) &amp; stem ( U2 , S ) &amp; warningKWIC ( 'inconsistency ' , II ) . Here we assume both stem ( 'style ' , 'style ' ) and stem ( 'stylistic ' , 'style ' ) are successful. This section illustrates a typical CR1TAC session consisting of four actions. That is , tionary server ( Figure 10 ) . These actions are implemented as basic functions of the system. Locating a word of interes~ in different views will efficiently help users judge the system-detected errors to be real errors or not. 416 `` CRITAC S0tlRCE At F 72 TRUItO= ? 2 $ IZg=lSiLINg=102 C0£=i ^LT=O 97 98 ? ~I~N~t~t~ '' : ; K : W~o~W~ ( 1 ) 3~Jb ( E ) N~k { ~lll { gllo~3d 99 ~ ( 3 ) N~N~No ) N~tI~_~OJ ( 4 ) { ~JllNo ) i~N~¢a-~c \ [ 5\ ] ~I~ 101 I~T~o~/tI~PA~CR I TAC~'r~¢~ tg~kl : ? k~O ) ~O ) ~ktNt 102 5Z~Ztl£ , ~¢ : .ltl~'~©ll~-~b-Cttt~ • ~lgY~'~'e 103 ~:5~ -- c~ , WOo F-o ) g0 , ~'~CR 1TAC'P~'~t~o ) 3~ ) ~o3 ... ... 311 ... ... .. 104 l~G~'zt ) l~09~lJw , is~J : ~ , o tzt-b , ~o ? 3~tzt~t~ &lt; N5~,0 '' 3~ , ! ~ 15======== 24==== 105 ~ { , % Ig~.o~l~dt.~g~.o~h¢~=~ '' ct , ~o 106 • *CRITAC**I 1 \ ] 2 \ [ U I 4 I**\ ] 5 \ [ 6 I 7 \ [ 8 \ [ *.1 9 \ ] 10 \ ] ll \ [ 12 \ [ PROOF ISreelttextl0uitlF , xpll**lSCH01 ? IBacklForwl**l = l } lomell/ordlKVIC\ [ : == % &gt; .</sentence>
				<definiendum id="0">Keyk</definiendum>
				<definiens id="0">A rule for detecting incorrect ending of sentences rule ( 'terminatiw ; ' ) &lt; tail ( I , J , K , T , H ) &amp; end ofsentence ( E ) &amp; category ( 'terminative ' , H ) &amp; NOT punc ( I , J , K , E ) &amp; warning 1 ( 'missing punctuation ' , I , J , K ) . This rule scans the function words of text. If a segment ends with a flmction word</definiens>
				<definiens id="1">the last : element of the list T in `` tail '' ) , which usually implies the `` end-of -- sentence ' , but is not followed by a punctuation mark ( period ) E , then give a warning to the author. A rule for detecting an inconsistent use of numeric prefixes One is Alphabetical prefix and another is Chinese numeric prefix rule ( 'numbers ' ) &lt; head ( ll , J I , K I , U1 , YI , G I , L1 ) &amp; number -prefix ( K I , L 1 , P l , W 1 ) &amp; head ( I2 , J2 , K2 , U2 , Y2 , G2 , L2 ) &amp; number -prefix ( K2 , L2 , P2 , Wl ) &amp; char-type ( P1 , T1 ) &amp; chartype ( P2 , T2 ) &amp; ne ( Tl , T2 ) &amp; warning2 ( 'numbers ' , II , Jl , Kl , I2 , J2 , K2 ) . This rule detects the inconsistent usage of Kanji and Roman numeric prefixes for some content word. if some primitive word Wl is preceded by numeric prefixes P1 and P2 denoting the same numbers but not of the same character type , then give a warning to the author. `` Number-prefix ( K , L , P , W ) ' succeeds if there is a number prefix P preceding a primitive word W in the compound word K , where the constituent types are listed in L. `` Chartype ( P , T ) '' succeeds if a 2-byte character string P consists of only one character type ( `` Kanji '' , `` Hiragana '' , `` Kanakana '' , or `` Roman '' ) or if P is `` mixed '' . KWIC Rules KWIC rules , in contrast with the source rules</definiens>
				<definiens id="2">explained in the previous subsection , if Keyj ... ..</definiens>
				<definiens id="3">the phonetic ordering , homonyms are arranged adjacently. This greatly reduces the time to detect homonym errors ( conversion errors ) because the system only has to scan the keywords Keyi once to examine the pronunciation of Key~ and Key~ , and possibly some other local conditions. For example , we can express possible conversion errors as follows. 415 ruleKWIC ( 'misconversion ' ) &lt; isordered ( 'pronunciation ' ) &amp; key ( I1 , U1 , YI , G1 ) &amp; nextkey ( I1 , U2 , YI , G2 ) &amp; ne ( UI , U2 ) &amp; pred ( I1 , P ) &amp; pred ( I2 , P ) &amp; succ ( I1 , S ) &amp; succ ( I2 , S ) &amp; wamingKWIC ( 'misconversion ' , I 1 ) . If there are distinct keywords U1 and U2 with the same pronunciation Y1 in the same context P ( preceding primitive word ) and S ( succeeding primitive word ) , then one of them is possibly a misconversion. `` Key ( I , U , Y , G ) '' is Key~ = U with pronunciation Y and lexical category G. `` Next-key ( I , U , Y , G ) '' unifies with key ( I1 , U , G , Y ) such that II=I+l. If Key~ , ... , Keyk are ordered either by their preceding or succeeding word , we can detect some lack of conformity in word usage. For example , if keywords are ordered by their succeeding words</definiens>
				<definiens id="4">a spelling error in such cases . , . ... can find style errors as well as , .. ... to detect stylistic errors in the text ... ruleKWIC ( 'inconsistency ' ) &lt; ordered ( 'successor ' ) &amp; key ( II , U1 , Yl , Gl ) &amp; nextkey ( II , U2 , YI , G2 ) &amp; ne ( Ul , U2 ) &amp; stem ( U1 , S ) &amp; stem ( U2 , S ) &amp; warningKWIC ( 'inconsistency '</definiens>
				<definiens id="5">'stylistic ' , 'style ' ) are successful. This section illustrates a typical CR1TAC session consisting of four actions. That is , tionary server ( Figure 10 ) . These actions are implemented as basic functions of the system. Locating a word of interes~ in different views will efficiently help users judge the system-detected errors to be real errors</definiens>
			</definition>
</paper>

		<paper id="1053">
			<definition id="0">
				<sentence>CTALK is such an object-oriented language and can dynamically handle the network using the concept of a world a group of objects -and an object .</sentence>
				<definiendum id="0">CTALK</definiendum>
				<definiens id="0">such an object-oriented language and can dynamically handle the network using the concept of a world a group of objects -and an object</definiens>
			</definition>
			<definition id="1">
				<sentence>A world is a set of objects , and some active worlds stay in the main memory .</sentence>
				<definiendum id="0">world</definiendum>
				<definiens id="0">a set of objects , and some active worlds stay in the main memory</definiens>
			</definition>
			<definition id="2">
				<sentence>SLOTS is a static property of an object .</sentence>
				<definiendum id="0">SLOTS</definiendum>
			</definition>
			<definition id="3">
				<sentence>METHODS is the message part of the object .</sentence>
				<definiendum id="0">METHODS</definiendum>
			</definition>
			<definition id="4">
				<sentence>`` Koto ° is one of the superconeepts of ~mokuteki ° and by itself a subconcept of `` TOP ~ and `` koto .</sentence>
				<definiendum id="0">Koto °</definiendum>
				<definiens id="0">one of the superconeepts of ~mokuteki ° and by itself a subconcept of</definiens>
			</definition>
</paper>

		<paper id="1120">
			<definition id="0">
				<sentence>Situation Semantics ( SS ) IBarwise 1982,1984a,1984b,1985a , 1985b,1985c,1985d,1985ell Barwise &amp; Perry 1983\ ] \ [ l , experaneeJ\ [ Pollard 1985HCreary &amp; Pollard\ ] is a ttmory of context used here to construct a nmdel of honorific sentences to analyze the relationship tmtween sentence and context .</sentence>
				<definiendum id="0">Situation Semantics</definiendum>
				<definiens id="0">a ttmory of context used here to construct a nmdel of honorific sentences to analyze the relationship tmtween sentence and context</definiens>
			</definition>
			<definition id="1">
				<sentence>DU : = speaking A ; yes addressing , A , B ; yes saying , A , alpha ; yes ( 11 ) Speaker 's Connection ( CS ) The speaker 's connection is a series of the following types .</sentence>
				<definiendum id="0">B ; yes saying</definiendum>
				<definiens id="0">a series of the following types</definiens>
			</definition>
			<definition id="2">
				<sentence>A is the actual object and \ [ AI is the word that represents A. CS : = speaking A ; yes refers A \ [ A\ ] ; yes ( 111 ) Resource Situation ( RS ) A resource situation is defined for each individual in a discourse ; it contains many events and constraints .</sentence>
				<definiendum id="0">AI</definiendum>
				<definiens id="0">the word that represents A. CS : = speaking A ; yes refers A \ [ A\ ] ; yes ( 111 ) Resource Situation ( RS ) A resource situation is defined for each individual in a discourse ; it contains many events and constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>A denotes the individual and `` Itr '' indicates that in the nfind of the individual A , the honorific event type Eh is `` represented . ''</sentence>
				<definiendum id="0">`` Itr</definiendum>
				<definiens id="0">the individual and</definiens>
			</definition>
			<definition id="4">
				<sentence>In formula 6 ) , `` Cwl ( Eh , ~q '' denotes the conditional constraint of word selection Cw which has Eh and anchor `` f '' as its conditional schema .</sentence>
				<definiendum id="0">Cwl</definiendum>
				<definiens id="0">the conditional constraint of word selection Cw which has Eh and anchor `` f '' as its conditional schema</definiens>
			</definition>
			<definition id="5">
				<sentence>Anchor `` f '' determines the relation between indeterminates in Eh and objects like taro and hanako .</sentence>
				<definiendum id="0">Anchor `` f ''</definiendum>
				<definiens id="0">determines the relation between indeterminates in Eh and objects like taro and hanako</definiens>
			</definition>
			<definition id="6">
				<sentence>ps ( \ [ talX\ ] , X , Context ) &lt; dsolve ( hono ! ( ( agent ! ( ds ! Context ) ) ! ( rs ! Context ) , eq ( speaker\ ] ( ds ! Context ) , object ! ( lex ! Context ) ) ) . , , &lt; 2 , denotes the operator `` : - '' in Prolog \ [ Bowen 1982\ ] . `` \ [ ta\ ] X\ ] , X '' is the DCG parsing mechanism. `` Context '' is a complex indeterminate variable for the context for this parsing part. `` dsolve '' is a Prolog predicate with the following mechanism. dsolve ( X , Y ) . X is a list like \ [ a , b , c , dl which contains Prolog atmns or terms. Y is a Prolog atom or term. 1 ) Search list X for Y. 2 ) If there is a term in X with the same arguments but different term name , fail and return. 3 ) if Y is not in X , then add Y to list X , succeed and return. 4 ) lfY is in X , succeed and return. `` hono ! ( ( agent ! ( ds ! Context ) ) ! ( rs ! Cantext ) ) '' represents a list of honorific event types in the resom'ce situation of the agent of discourse. `` object ! ( lex ! Context ) ) '' represents the lexical object in this parsing stage. This 508 notation for lexical items has its origin in Lexical Functional Gramrnar tKaplan &amp; Bresnaul , so this expression can be represented like ( ~object ) in the LFG manner. This example states that if '' ps '' = |taL then there should he honorific information in the resource situation of the individual who is the speaker. If the speaker 's RS contains two or nmre different terms expressing the honorific relationship between the same agents , fail. Thus , the mechanism of 2 ) in dsolve is very important because it shows that in the honorific information of one individual there should not be different information about the binary honorific relation between two individuals. ( 11 ) Second order honorifics Lexieal rules for second order lmnorifies can be represented as in following example program. Ex.4 This corresponds to Eh in 7 ) and 8 ) in Section 3.1.2. np ( X0 , X2 , Context ) &lt; n ( X0 , XI , Context ) , sub3 ( X 1 , X2 , Context ) , dsolve ( honn ! ( ( agent ! ( ds ! Context ) ) ! ( rs ! Context ) , up ( agenl , ! ( ds ! X ) , obj ! ( lex ! X ) ) ) . ( Ill ) Third order honorifics Lexical rules for third order honorifics can be represenl ; ed as in the following example program. Ex.5 This corresponds to Eh in 10 ) in section 3.1.2. vp ( X0 , X2 , Context ) &lt; v ( X0 , Xl , Context ) , suM ( X , , X2 , Context ) , dsolve ( hono ! ( ( agent ! ( ds ! Context ) ) ! ( rs ! Context ) , up ( agenti ( lex ! X ) , obj ! ( lex ! X ) ) ) . When we utilize the contextual elements like I ) S and RS in discourse it is very difficult to decide the context for each sentence. A sentence in discourse can be represented by the expression `` I ) S , CS , I\ [ alptm\ ] \ ] S , E '' , but then how do we nmp contexts like DS and CS to complex sentences ? Mizutani 's theory of honorific forms does not go into context switching in a complex sentence. So we have expanded his grammar and propose a basic mechanism for contcx~ switching. Consider sentence l ) below uttered by individual S to R which means `` individual T said that individual U said that Taro met llanako. '' In this example , we establish relations a ) through j ) among S , T , U , Taro and ltanako. The operater &gt; denotes the situation in which tim left hand side honm 's the right hand side , &lt; denotes the situation in which the right had side hmmrs the left hand side , and = denotes the situation in which there is no need to use honerifics between left hand side and right hand side .</sentence>
				<definiendum id="0">ps</definiendum>
				<definiendum id="1">X ''</definiendum>
				<definiendum id="2">X</definiendum>
				<definiendum id="3">Y</definiendum>
				<definiendum id="4">lfY</definiendum>
				<definiens id="0">the operator `` : - '' in Prolog \ [ Bowen 1982\ ] . `` \ [ ta\ ] X\ ] ,</definiens>
				<definiens id="1">a list like \ [ a , b , c , dl which contains Prolog atmns or terms.</definiens>
				<definiens id="2">a term in X with the same arguments but different term name , fail</definiens>
				<definiens id="3">a list of honorific event types in the resom'ce situation of the agent of discourse. `` object ! ( lex ! Context ) ) '' represents the lexical object in this parsing stage. This 508 notation for lexical items has its origin in Lexical Functional Gramrnar tKaplan &amp; Bresnaul , so this expression can be represented like ( ~object ) in the LFG manner. This example states that if '' ps '' = |taL then there should he honorific information in the resource situation of the individual who is the speaker. If the speaker 's RS contains two or nmre different terms expressing the honorific relationship between the same agents</definiens>
				<definiens id="4">to Eh in 7 ) and 8 ) in Section 3.1.2. np ( X0 , X2 , Context ) &lt; n ( X0 , XI</definiens>
				<definiens id="5">the contextual elements like I ) S and RS in discourse it is very difficult to decide the context for each sentence. A sentence in discourse can be represented by the expression `` I ) S , CS , I\ [ alptm\ ] \ ] S , E '' , but then how do we nmp contexts like DS and CS to complex sentences ? Mizutani 's theory of honorific forms does not go into context switching in a complex sentence. So we have expanded his grammar and propose a basic mechanism for contcx~ switching. Consider sentence l ) below uttered by individual S to R which means `` individual T said that individual U said that Taro met llanako.</definiens>
				<definiens id="6">relations a ) through j ) among S , T , U , Taro and ltanako. The operater &gt; denotes the situation in which tim left hand side honm 's the right hand side , &lt; denotes the situation in which the right had side hmmrs the left hand side , and = denotes the situation in which there is no need to use honerifics between left hand side and right hand side</definiens>
			</definition>
			<definition id="7">
				<sentence>107-164 \ [ Matsumoto 19831 Matsunmto , Y. , et al. , `` BUP : A Bottom-Up Parser Embedded in Protog , '' New Generation Computing , vol .</sentence>
				<definiendum id="0">BUP</definiendum>
				<definiens id="0">A Bottom-Up Parser Embedded in Protog</definiens>
			</definition>
</paper>

		<paper id="1036">
</paper>

		<paper id="1047">
			<definition id="0">
				<sentence>Abstract : We study the weak generative capacity of a class of parenthesis-free categorial grammars derived /torn those of Aries and Steedman by varying the set of reduction rules .</sentence>
				<definiendum id="0">Abstract</definiendum>
				<definiens id="0">the weak generative capacity of a class of parenthesis-free categorial grammars derived /torn those of Aries and Steedman by varying the set of reduction rules</definiens>
			</definition>
			<definition id="1">
				<sentence>Classically , a categorial grammar is a quadruple G ( VT , VA , J ; , F ) , where VT is a finite set of morl ) hemes , and VA is a tinite set of atomic categories , one of which is the distinguished category S. The set CA of categories is formed from VA as follows : ( 1 ) VAisasubset of CA , ( 2 ) if X and Y are in CA , t.hcJ , ( X , '' Y ) is I CA The grammar also ( : md.ain , ~ a lexicon F , which is a function from words to finite subsets of CA .</sentence>
				<definiendum id="0">categorial grammar</definiendum>
				<definiendum id="1">VT</definiendum>
				<definiendum id="2">VA</definiendum>
				<definiens id="0">a finite set of morl ) hemes , and</definiens>
				<definiens id="1">a tinite set of atomic categories , one of which is the distinguished category S. The set CA of categories is formed from VA as follows : ( 1 ) VAisasubset of CA</definiens>
			</definition>
			<definition id="2">
				<sentence>The number of occurrences of atomic category symbols in X is I X I ' Strings of category symbols are denoted by x , y. Mor pheme , s are denoted by a , b ; *norpheme strings by u , v , w. A categorial grammar under certain reduction rides is a qua druple G1¢ : ( VT , VA , S , F ) , where : VT is a finite set of morphelnes , VA a tinite set of attolnic categories , S E VA a dis tinguished elelnent , F a function from VT to 2 cA such that for every a E VT , F ( a ) is finite , where CA is the category set and is defined as : i ) if A EVA , then A E CA , ii ) if X E CA and A C VA , then X/A E CA , iii ) nothing else is in CA .</sentence>
				<definiendum id="0">VT</definiendum>
				<definiendum id="1">CA</definiendum>
				<definiens id="0">*norpheme strings by u , v , w. A categorial grammar under certain reduction rides is a qua druple G1¢ : ( VT , VA , S , F ) , where :</definiens>
				<definiens id="1">a finite set of morphelnes</definiens>
				<definiens id="2">the category set and is defined as : i ) if A EVA , then A E CA , ii ) if X E CA and A C VA , then X/A E CA , iii ) nothing else is in CA</definiens>
			</definition>
			<definition id="3">
				<sentence>We write. : U/A A/~ ~ U/IJ ; ( 4 ) ( FP s Ru e ) Same as ( 2 ) except that U/A must he headed by S ; ( 5 ) ( B Rule ) If U/A E CA , A EVA , the string A U/A can be replaced by U. We write : A U/A ~ U ; ( 6 ) ( B s Rule ) Same as ( 5 ) except that U/A must be headed by S. When it WOIl~t cause confusion , we write Gf¢ to denote a categori al grammar with rule set R , and specify a categorial grammar by just spe , cifying its lexicon F. The reduce relation &gt; on CA* x CA* is defined as : for all oq fl E CA* and all X , Y , Z E CA , o~XYfl - &gt; o~Z\ [ 3 if XY -- , Z. Let : &gt; * denote the reflexive and transitive closure of relation A rnorpheme string W=WlW= '' 'wn , where wi E VT , i=1,2 , .</sentence>
				<definiendum id="0">EVA</definiendum>
				<definiens id="0">B Rule ) If U/A E CA , A</definiens>
				<definiens id="1">for all oq fl E CA* and all X , Y , Z E CA , o~XYfl - &gt; o~Z\ [ 3 if XY -- , Z. Let : &gt; * denote the reflexive and transitive closure of relation A rnorpheme string W=WlW= '' 'wn</definiens>
			</definition>
			<definition id="4">
				<sentence>If L ( G~ ) contains any sentence of length greater than one , then it contains at least one sentence w uv such that vu is also in L ( GR ) .</sentence>
				<definiendum id="0">G~ )</definiendum>
				<definiens id="0">contains any sentence of length greater than one</definiens>
			</definition>
			<definition id="5">
				<sentence>tlowever , by the parenthesis convention , B/C/D is the abbreviation of ( ( B/C ) /D ) .</sentence>
				<definiendum id="0">B/C/D</definiendum>
			</definition>
			<definition id="6">
				<sentence>Input : A categorial grammar G R ( V T , VA , S , f ' ) R = { F , FP2 } .</sentence>
				<definiendum id="0">Input</definiendum>
				<definiens id="0">A categorial grammar G R ( V T , VA , S , f '</definiens>
			</definition>
			<definition id="7">
				<sentence>Method : LetDA = U l '' ( a ) ; aEVT Repeat For all non atomic categories U/A C DA ( 1 ) IfA ~ DA Then DA = DA U { U } ; ( 2 ) For all non atomic categories A/B E DA w it h DA = DA tO { U/B } ; Until DA was not updated dm'ing the last iteration .</sentence>
				<definiendum id="0">Method</definiendum>
				<definiens id="0">LetDA = U l '' ( a ) ; aEVT Repeat For all non atomic categories U/A C DA ( 1 ) IfA ~ DA Then DA = DA U { U } ; ( 2 ) For all non atomic categories A/B E DA w it h DA = DA tO { U/B } ; Until DA was not updated dm'ing the last iteration</definiens>
			</definition>
			<definition id="8">
				<sentence>Second , each morpheme b would introduce one A and one C within a complex category symbol which must be cancelh~l out sooner or later in order to reduce the whole string to S. In gen eral , there are two ways for such A and C being cancelled : ( 1 ) with an A headed or C headed complex category by the FP rule , which is impossible in this example ; ( 2 ) with a single atomic category A or C by either the F or P , s rule .</sentence>
				<definiendum id="0">FP rule</definiendum>
				<definiens id="0">such A and C being cancelled : ( 1 ) with an A headed or C headed complex category by the</definiens>
			</definition>
</paper>

		<paper id="1154">
			<definition id="0">
				<sentence>t From Japanese to German via flTLflS/II and SEflSYN The project SEMSYN-83 SEMSYN is an acronym for SEM antic SYNthesis has produced a system for the generation of German from semantic representations .</sentence>
				<definiendum id="0">project SEMSYN-83 SEMSYN</definiendum>
				<definiens id="0">an acronym for SEM antic SYNthesis has produced a system for the generation of German from semantic representations</definiens>
			</definition>
			<definition id="1">
				<sentence>IKBS stands for I ' ( ( DEVELOP -- INST- &gt; COflPUTER ) ( SUPPORT -- OBJ- &gt; DEVELOP ) ( SUPPORT -- INST - &gt; SVSTEfl ) ( GIVE -- INST ~ &gt; SYSTEM ) ( QUALITY -- POSSESSOR- &gt; SOFTWARE ) ( RELIflBILITV -- ENUfl- &gt; QUALITY ) ( GIVE -- GOAL- &gt; RELIABILITV ) ( GIVE -- OBJ- &gt; FlFFECT ) ( *NIL -- ST - &gt; RFFECT ) ) Ill. : SEMSVN 's interface with OTLflS/II ( TIT-gi ) Instantiated Knowledge Base Schemata .</sentence>
				<definiendum id="0">IKBS</definiendum>
				<definiens id="0">I ' ( ( DEVELOP -- INST- &gt; COflPUTER ) ( SUPPORT -- OBJ- &gt; DEVELOP ) ( SUPPORT -- INST - &gt; SVSTEfl ) ( GIVE -- INST ~ &gt; SYSTEM ) ( QUALITY -- POSSESSOR- &gt; SOFTWARE ) ( RELIflBILITV -- ENUfl- &gt; QUALITY ) ( GIVE -- GOAL- &gt; RELIABILITV ) ( GIVE -- OBJ- &gt; FlFFECT ) ( *NIL -- ST - &gt; RFFECT ) ) Ill. : SEMSVN 's interface with OTLflS/II ( TIT-gi ) Instantiated Knowledge Base Schemata</definiens>
			</definition>
			<definition id="2">
				<sentence>: NG ( : HERO `` Beoinflussunq '' ) ( : FERTURE $ ( : gET DEF ) ( : NUO SG ) ) ( : POBSflTTR ( : NG ( : HERO ( : NO-CONJUNCT ( : NGS ( : NG ( : HERD `` Zuverl~ssi~keit '' ) ( tFERTUREB ( sNUff SG ) ( =DET DEF ) ) ) ( =NO ( : HERD `` Quell=l= ' ) ( : FEATURES ( : NUM 86 ) ( IOET DEF ) ) ) ) ( : COBB `` und '' ) ) ) ( : FERrURES ( : gET DEF ) ( : NUfl PL ) ) ( : POSSRTTR ( : PG ( : PREP `` yon '' ) ( : POBJ ( : N6 ( : HERO `` Software '' ) ( : FERTURES ( : NUM SG ) ( : BET ZERO ) ) ) ) ) ) ) ) ( : QUBLIFIERS ( : PG ( : PREP `` mit '' ) ( =POBJ ( : NG ( : HERO `` Sqstem '' ) ( : FEBTUREB ( : BET INDEF ) ( : COS DnT ) ) ( : POSSRTTR ( =PG ( : PREP `` zu '' ) ( : POBJ ( =NG ( ~HERD `` UnterstOtzunq '' ) ( : FEflTUREB ( INUM SG ) ( ~DET DEF ) ) ( =POSSBTTR ( : NG ( : HERD `` EnLgicklunq '' ) ( =FEBTUBEO ( : BET DEF ) ( : BUff SG ) ) ( : QUBLIFIERS ( =PG ( =PREP `` =it '' ) ( : POBJ ( : NG ( : HERD `` Computer '' ) ( : FEATURES ( : DET INDEF ) ( =CRS DRT ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) I. : IRS-Deocription For TIT-B1 The third step the generator-front-end SUTRA-S -takes the IRS description and produces a corresponding syntactically and morphologically correct German surface structure ( Emele &amp; Momma , 1985 ) .</sentence>
				<definiendum id="0">gET DEF )</definiendum>
				<definiendum id="1">=NG</definiendum>
				<definiendum id="2">QUBLIFIERS</definiendum>
				<definiendum id="3">=PG</definiendum>
				<definiens id="0">NUfl PL ) ) ( : POSSRTTR ( : PG ( : PREP `` yon '' ) ( : POBJ ( : N6 ( : HERO `` Software '' ) ( : FERTURES ( : NUM SG ) ( : BET ZERO ) ) ) ) ) ) ) ) ( : QUBLIFIERS ( : PG ( : PREP `` mit '' ) ( =POBJ ( : NG ( : HERO `` Sqstem '' ) ( : FEBTUREB ( : BET INDEF ) ( : COS DnT ) ) ( : POSSRTTR</definiens>
			</definition>
			<definition id="3">
				<sentence>SUTRA-S is an extended reimplementation of the program SUTRA that has been developped by Busemann in the HAM-ANS project ( Busemann , 1982 ) .</sentence>
				<definiendum id="0">SUTRA-S</definiendum>
				<definiendum id="1">HAM-ANS project</definiendum>
				<definiens id="0">an extended reimplementation of the program SUTRA that has been developped by Busemann in the</definiens>
			</definition>
</paper>

		<paper id="1100">
			<definition id="0">
				<sentence>The theory mlght ignore some aspects , such as phonology , or etymology , wi ) lle it would use `` semantic '' categories ( such as COUNTABLE , TOOL , HUMAN , PERSONNIFIABLE , CONCRETE , ABSTRACT ... ) far more detailed than the `` natural '' ones ( SOMEBODY , SOMETHING ... ) .</sentence>
				<definiendum id="0">semantic '' categories</definiendum>
				<definiens id="0">such as COUNTABLE , TOOL , HUMAN , PERSONNIFIABLE , CONCRETE , ABSTRACT ... ) far more detailed than the `` natural '' ones ( SOMEBODY , SOMETHING ... )</definiens>
			</definition>
</paper>

		<paper id="1011">
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>I. Modularity : a Basic Principle of G2 S~stems Modularity is a defining characteristic of second genera ti .</sentence>
				<definiendum id="0">S~stems Modularity</definiendum>
				<definiens id="0">a Basic Principle of G2</definiens>
			</definition>
			<definition id="1">
				<sentence>Lexieal units ( LUs ) are not translated in isolation ; rather , transfer rules typically test the structural environment of each SL LU and , after inserting the appropriate TL equivalent , may rearrange that structure to accord with contextual\ [ constraints imposed by the TL LU .</sentence>
				<definiendum id="0">Lexieal units</definiendum>
				<definiendum id="1">LUs</definiendum>
				<definiens id="0">transfer rules typically test the structural environment of each SL LU and , after inserting the appropriate TL equivalent</definiens>
			</definition>
</paper>

		<paper id="1094">
			<definition id="0">
				<sentence>ATN Environment Active Chart parsing ( \ [ KAP 73\ ] ) is a highly general framework to implement parsers .</sentence>
				<definiendum id="0">ATN Environment Active Chart parsing</definiendum>
				<definiens id="0">a highly general framework to implement parsers</definiens>
			</definition>
</paper>

		<paper id="1063">
			<definition id="0">
				<sentence>The software module GRAPHON ( GRAPHemo-PHONome-conversion ) has boon developed to convert any given German text into its phonetic transcription ( I.P.A. ) ~ enriched by some prosodic markers .</sentence>
				<definiendum id="0">software module GRAPHON</definiendum>
				<definiens id="0">boon developed to convert any given German text into its phonetic transcription ( I.P.A. ) ~ enriched by some prosodic markers</definiens>
			</definition>
			<definition id="1">
				<sentence>A dictionary entry consists of the lemma , i.e. graphemic representation of the morph , on the one hand and an information-tree , serving to characterize its phonological , morphological and syntactic value on the other .</sentence>
				<definiendum id="0">dictionary entry</definiendum>
			</definition>
</paper>

		<paper id="1146">
			<definition id="0">
				<sentence>The VESPRA system consists of five components : I ) the noise reduction unit ; 2 ) the phonetic feature extraction and pattern recognition unit ; 3 ) an ATN grammar , a dialog model and a model of the controlled machlne ; 4 ) a machine control and dialog generation unit ; 5 ) a user friendly software development environment .</sentence>
				<definiendum id="0">VESPRA system</definiendum>
				<definiens id="0">consists of five components : I ) the noise reduction unit ; 2 ) the phonetic feature extraction and pattern recognition unit ; 3 ) an ATN grammar , a dialog model and a model of the controlled machlne ; 4 ) a machine control and dialog generation unit ; 5 ) a user friendly software development environment</definiens>
			</definition>
			<definition id="1">
				<sentence>An ATN grammar processes all meaningful sentences on the basis of these wordforms ( including reduced forms of 618 sentences ) .</sentence>
				<definiendum id="0">ATN grammar</definiendum>
			</definition>
</paper>

		<paper id="1066">
			<definition id="0">
				<sentence>It is one of three closely related projects funded under the Alvey IKBS Programme ( Natural Language Tlleme ) ; a parser is under development at Edinburgh by Henry Thompson and John Phillips , and a sentence grammar is being devised by Ted Briscoe and Clare Grover at Lancaster and Bran Boguraev and John Carroll at Cambridge .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">one of three closely related projects funded under the Alvey IKBS Programme ( Natural Language Tlleme ) ; a</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , a Noun Phrase is of the category : ( ( V - ) ( N + ) ( BAR 2 ) ) In our analysis , 'bound morphemes ' , that is to say prefxes and suffixes , are distinguished from others by their BAR specification ; tile suffix ing is the sole member of the category : ( ( V 4- ) ( N - ) ( VFORM ING ) ( BAR -1 ) ) As in other GPSG-based work , our analysis encodes the subcategorlzational prbpertles of lexlcal Items in the value of a feature SUBCAT .</sentence>
				<definiendum id="0">Noun Phrase</definiendum>
				<definiendum id="1">tile suffix ing</definiendum>
				<definiens id="0">of the category : ( ( V - ) ( N + )</definiens>
			</definition>
			<definition id="2">
				<sentence>The syntax field consists of a syntactic category , as defined by Gazdar et al. ( 1985 ) , i.e. a set of featurevalue pairs .</sentence>
				<definiendum id="0">syntax field</definiendum>
			</definition>
			<definition id="3">
				<sentence>In our grammar , the category and inflectabllity of a suffixed word are determined by the category and lnflectablllty of the suffix ; in the rule below , ALPHA , BETA , and GAMMA are variables ranging over the set of values { + , - } : ( ( V ALPHA ) ( N BETA ) ( INFL GAMMA ) ( BAR 0 ) ) = &gt; ( ( BAR 0 ) ) ( ( V ALPHA ) ( N BETA ) ( INFL GAMMA ) ( BAR -1 ) ) Since variables are interpreted consistently throughout a rule , the mother category and suffix will be identical In their specifications for N , V and INFL .</sentence>
				<definiendum id="0">GAMMA</definiendum>
				<definiendum id="1">V ALPHA ) ( N BETA ) ( INFL GAMMA )</definiendum>
				<definiens id="0">variables ranging over the set of values { +</definiens>
			</definition>
			<definition id="4">
				<sentence>When the feature set WDaughter is defined as including the subcategorlzation feature SUBCAT , the convention results in configuratkms such as : ( ( SUBCAT NP ) ) ( ( SUBCAT NP ) ) ( ( V + ) ( N +\ ] ) ( ( SUBCAT NP ) ) ( ( SUBCAT NP ) ) ( ( VFORM ING ) ) which show the relevant feature specifications in local trees arising from suffixatton of an adjective with +ize to produce a transitive verb and suffixatlon of a transitive verb with +ing to produce a present participle .</sentence>
				<definiendum id="0">WDaughter</definiendum>
				<definiens id="0">SUBCAT NP ) ) ( ( SUBCAT NP ) ) ( ( V + ) ( N +\ ] ) ( ( SUBCAT NP ) ) ( ( SUBCAT NP ) ) ( ( VFORM ING ) ) which show the relevant feature specifications in local trees arising from suffixatton of an adjective with +ize to produce a transitive verb and suffixatlon of a transitive verb with +ing to produce a present participle</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>For example , ~le following is an opening n~veby a teacher in a classroom dialogue consisting of two acts ( in brackets ) : T : those letters have a special name ( Starter ) do you know what it is ( Elicitation ) Most acts are realisedby a wide range of utterance types° For example , the act called 'starter ' can be realised by either a statement , question , conraand , or a moodless item .</sentence>
				<definiendum id="0">question</definiendum>
				<definiens id="0">consisting of two acts ( in brackets ) : T : those letters have a special name</definiens>
			</definition>
			<definition id="1">
				<sentence>Moves are the basic units of a dyadic exchange and can consist of a ntnnber of acts .</sentence>
				<definiendum id="0">Moves</definiendum>
				<definiens id="0">the basic units of a dyadic exchange and can consist of a ntnnber of acts</definiens>
			</definition>
			<definition id="2">
				<sentence>Conversational exchanges consist of chains of opening , challenging and/or supporting moves .</sentence>
				<definiendum id="0">Conversational exchanges</definiendum>
				<definiens id="0">consist of chains of opening , challenging and/or supporting moves</definiens>
			</definition>
			<definition id="3">
				<sentence>Transactions consist of patterns of exchanges , and interactions consist of unordered strings of transactions .</sentence>
				<definiendum id="0">Transactions</definiendum>
				<definiens id="0">consist of patterns of exchanges , and interactions consist of unordered strings of transactions</definiens>
			</definition>
			<definition id="4">
				<sentence>ARGOT : a s~ , stem overview .</sentence>
				<definiendum id="0">ARGOT</definiendum>
			</definition>
</paper>

		<paper id="1152">
			<definition id="0">
				<sentence>Introduction of separate English transformation in the E-J transfer makes the transfer component easy to maintain .</sentence>
				<definiendum id="0">E-J transfer</definiendum>
				<definiens id="0">makes the transfer component easy to maintain</definiens>
			</definition>
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>The translation process consists of subprocesses of analysis , transfer and generation .</sentence>
				<definiendum id="0">translation process</definiendum>
				<definiens id="0">consists of subprocesses of analysis , transfer and generation</definiens>
			</definition>
			<definition id="1">
				<sentence>The designator is a medium to instantiate the schemata in the condition side .</sentence>
				<definiendum id="0">designator</definiendum>
				<definiens id="0">a medium to instantiate the schemata in the condition side</definiens>
			</definition>
			<definition id="2">
				<sentence>b ) ( ~ ACOMP SUBJ ) = ( t SUBJ ) \ [ ( t ACOMP 8COMP 8UUJ ) V t XCOMP SUB J ) = ( t ACOMPSUSJ ) \ [ = ( ~SUBJ ) E ( ~ ACOMPSCOMP to ) = + &lt; ... .. &gt; J J ( t PRED ) ='tagaru ( T ACOMP SCOMP INF ) = + J &lt; ( t SUBJ } ( ~ XCOMP ) &gt; ' { T ACOMP PRED ) ='EAGER &lt; ( t sunJ ) ( t SCOMP ) &gt; ' ( ~ '' PRED ) ='BE L &lt; ( ?</sentence>
				<definiendum id="0">PRED</definiendum>
				<definiens id="0">( t SUBJ ) \ [ ( t ACOMP 8COMP 8UUJ ) V t XCOMP SUB J ) = ( t ACOMPSUSJ ) \ [ = ( ~SUBJ ) E ( ~ ACOMPSCOMP to ) = + &lt; ... .. &gt; J J ( t PRED ) ='tagaru ( T ACOMP SCOMP INF ) = + J &lt; ( t SUBJ } ( ~ XCOMP ) &gt; ' { T ACOMP PRED ) ='EAGER &lt; ( t sunJ ) ( t SCOMP ) &gt; ' ( ~ ''</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>Exploiting the modular nature of GB ( see Wehrli 1983 ) , the UG consists of a phrase structure cc~nent based on X-bar syntax ( Jackendoff 1977 ) , a transformational component that includes the rule Move Affix ( =affix-hopping ) and the general rule of Move Alpha ( including the subjacency constraint ) , and a well-formedness component containing constraints on surface representations .</sentence>
				<definiendum id="0">Exploiting the modular nature of GB</definiendum>
				<definiendum id="1">UG</definiendum>
				<definiens id="0">consists of a phrase structure cc~nent based on X-bar syntax ( Jackendoff 1977 ) , a transformational component that includes the rule Move Affix ( =affix-hopping ) and the general rule of Move Alpha ( including the subjacency constraint ) , and a well-formedness component containing constraints on surface representations</definiens>
			</definition>
			<definition id="1">
				<sentence>The UG , then , is an expression of the theories of X-bar , Case , Theta , Government , Binding , and Bounding ( Choms\ ] oy 1981 ) ( see Fig .</sentence>
				<definiendum id="0">UG</definiendum>
				<definiendum id="1">Bounding</definiendum>
				<definiens id="0">is an expression of the theories of X-bar , Case , Theta , Government , Binding , and</definiens>
			</definition>
			<definition id="2">
				<sentence>dict ( e , believe , v , \ [ ~0cat ( n ) , sub cat ( c ) , sdel ( + ) , ~nish ( o~r ) \ ] ) ° dict ( e , seem , v , \ [ subcat ( c ) , sdel ( + ) , theta ( ~ ) , spanish ( ~ ) \ ] ) .</sentence>
				<definiendum id="0">dict ( e</definiendum>
				<definiens id="0">believe , v , \ [ ~0cat ( n ) , sub cat ( c ) , sdel ( + ) , ~nish ( o~r ) \ ] ) ° dict ( e , seem , v , \ [ subcat ( c ) , sdel ( + )</definiens>
			</definition>
			<definition id="3">
				<sentence>As an ex-~r~ole , the following structure is created : for the sente/ % ce The man had seen many_~i\ [ ~LS_ from his window , where the symbol $ e denotes an empty value , and `` `` denotes a place-holder for features : ( 6 ) \ [ \ [ c , _\ ] , Se , \ [ Se , Se , \ [ \ [ i , _\ ] , \ [ \ [ n , _\ ] , the , \ [ Se , man \ ] \ ] , E Se , Se , \ [ \ [ v , _\ ] , had , \ [ $ e , seen , \ [ \ [ n , _\ ] , ~ny , \ [ $ e , things \ ] \ ] \ ] , \ [ \ [ p , _\ ] , Se , \ [ $ e , fz~m , \ [ \ [ n , _\ ] , his , \ [ Se , window \ ] \ ] \ ] \ ] \ ] \ ] \ ] , \ [ mode , decl\ ] \ ] \ ] Following the strategy : in ( i ) , the GH9 reads in a sentence ( assumed to be grammatically correct ) , analyzes the ~orphology of each word , and applies the phrase structure rule ( 5 ) recursively to build the S-str~Icture .</sentence>
				<definiendum id="0">`` ``</definiendum>
				<definiens id="0">an empty value , and</definiens>
				<definiens id="1">analyzes the ~orphology of each word , and applies the phrase structure rule ( 5 ) recursively to build the S-str~Icture</definiens>
			</definition>
			<definition id="4">
				<sentence>To show that S-bar is a bounding node in Spanish , Torrego ( 1984 ) notes that Verb Preposing ~mlst occur in every clause that contains a wh-phrase or its trace in OCMP .</sentence>
				<definiendum id="0">S-bar</definiendum>
			</definition>
</paper>

		<paper id="1138">
			<definition id="0">
				<sentence>The MsgObj case must be filled ( hlstanceOf ) by a MsgObjDesc ( defined by another caseframe , see below ) , and the other cases must be filled by a MailAchDesc ( the caseframe representing a peison or `` mail address '' ) .</sentence>
				<definiendum id="0">MsgObj case</definiendum>
				<definiendum id="1">MsgObjDesc</definiendum>
				<definiendum id="2">MailAchDesc</definiendum>
				<definiens id="0">the caseframe representing a peison or `` mail address '' )</definiens>
			</definition>
			<definition id="1">
				<sentence>; yntactic subject ; MsgObj as the direct object ; MsgRecipientObj as either the indirect object or as the object ( PrepO ) of a prepositional phrase , whose preposition ( CaseMarker ) is `` to '' ; CCRecipientObj as a prepositional 588 phrase with `` prepositions '' either ccing or copying .</sentence>
				<definiendum id="0">MsgObj</definiendum>
				<definiendum id="1">CaseMarker</definiendum>
				<definiens id="0">the direct object ; MsgRecipientObj as either the indirect object or as the object ( PrepO ) of a prepositional phrase</definiens>
			</definition>
			<definition id="2">
				<sentence>Caseframe headers are verbs ( for clausal caseframes } and nouns ( for nominal caseframes ) .</sentence>
				<definiendum id="0">Caseframe headers</definiendum>
				<definiens id="0">verbs ( for clausal caseframes } and nouns ( for nominal caseframes )</definiens>
			</definition>
</paper>

		<paper id="1089">
			<definition id="0">
				<sentence>Semantic space is an Euelidean space where words and entities are put .</sentence>
				<definiendum id="0">Semantic space</definiendum>
				<definiens id="0">an Euelidean space where words and entities are put</definiens>
			</definition>
			<definition id="1">
				<sentence>The semantic space is an Euclidean space where entities and words are scattered .</sentence>
				<definiendum id="0">semantic space</definiendum>
				<definiens id="0">an Euclidean space where entities and words are scattered</definiens>
			</definition>
			<definition id="2">
				<sentence>, ,o A B D ° o F o H ( b ) Go Co oE o B oA Ho OD °F ( c ) Fig.5 An example of space reconstruction process Fig,4 An example of initial semantic space ( a horizontal section ) trial loops to decrease inconsistency , the space settles in the configuration shown in Fig.3 ( c ) , which includes no inconsistency .</sentence>
				<definiendum id="0">c )</definiendum>
				<definiens id="0">a horizontal section</definiens>
			</definition>
</paper>

		<paper id="1099">
			<definition id="0">
				<sentence>BetaText is an attempt to provide tools for both those needs .</sentence>
				<definiendum id="0">BetaText</definiendum>
				<definiens id="0">an attempt to provide tools for both those needs</definiens>
			</definition>
			<definition id="1">
				<sentence>i~i elementary ( text ) event consists of the observation of one specified , concrete string in the text .</sentence>
				<definiendum id="0">i~i elementary ( text ) event</definiendum>
				<definiens id="0">consists of the observation of one specified , concrete string in the text</definiens>
			</definition>
			<definition id="2">
				<sentence>&lt; new string &gt; is a string that is substituted for the observed string ( the default is that the original string is retained ) , &lt; move &gt; is a directive to Che system w'here ( in the text ) it shall continue the analysis ; the default is immediately to 421 the right of the observed string .</sentence>
				<definiendum id="0">new string &gt;</definiendum>
				<definiens id="0">a string that is substituted for the observed string ( the default is that the original string is retained ) , &lt; move &gt; is a directive to Che system w'here ( in the text ) it shall continue the analysis ; the default is immediately to 421 the right of the observed string</definiens>
			</definition>
</paper>

		<paper id="1091">
			<definition id="0">
				<sentence>For all those schemeR Jt takes an expert to classify new words correctly .</sentence>
				<definiendum id="0">schemeR Jt</definiendum>
				<definiens id="0">takes an expert to classify new words correctly</definiens>
			</definition>
			<definition id="1">
				<sentence>Mnrphologic information consists of the Following features : KL : The morpho\ ] ogJc class as above \ ] JM : I n format ion about ' um\ ] aut ' PV : Information about : \ [ ermakJon o17 Pnp ( verhs only ) FM : In\ [ o : mation about other forms ( supple\ ] ion ) 'Phe syntactic inIYormation is stored in the feature SY .</sentence>
				<definiendum id="0">Mnrphologic information</definiendum>
				<definiendum id="1">KL</definiendum>
				<definiens id="0">The morpho\ ] ogJc class as above \ ] JM : I n format ion about ' um\ ] aut ' PV : Information about : \ [ ermakJon o17 Pnp ( verhs only ) FM : In\ [ o : mation about other forms ( supple\ ] ion ) 'Phe syntactic inIYormation is stored in the feature SY</definiens>
			</definition>
			<definition id="2">
				<sentence>, Machine Learning : An Artificial \ ] intelligence Approach , Tioga , Calif. ; 1982 Knopik T. : MORPHY Die morpho\ ] ogische Komponente zu einem Gener\ ] erungssystem fHr das Deutsche , Dip\ ] omarbeit , Inst .</sentence>
				<definiendum id="0">Machine Learning</definiendum>
				<definiens id="0">An Artificial \ ] intelligence Approach</definiens>
			</definition>
</paper>

		<paper id="1057">
			<definition id="0">
				<sentence>S O describes ; the content of a term `` ordered triplg '' in S\ ] , and S~ has tile topic term `` SGS '' in S Heine S is the ~e-a\ [ l of S , and S is the i : .</sentence>
				<definiendum id="0">tile topic term `` SGS</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">the ~e-a\ [ l of S , and</definiens>
			</definition>
			<definition id="1">
				<sentence>Hence , S is tile principal sentence and tile sentence 2 ... . level of S_ is the same as that of S^ z `` `` As a sl ) ecial case of detail relations , there are a rephrase relation and an example relation .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">S_</definiendum>
				<definiens id="0">tile principal sentence and tile sentence 2 ... . level of</definiens>
			</definition>
			<definition id="2">
				<sentence>A concurrent relation has the same t : i.me instant of the event occurrences or the same stages of logical inference while Jt has a distance or a spatial positional shift hetween the physical or tile logical objects described in the adjacent sentential groul ) s. The level number of a sentence to the adjacent sentential groups in these relations is assigned ill a similar way to that of the detail or the additional relation by referring to the intersentential relations and the global topics .</sentence>
				<definiendum id="0">concurrent relation</definiendum>
				<definiens id="0">a distance or a spatial positional shift hetween the physical or tile logical objects described in the adjacent sentential groul</definiens>
			</definition>
			<definition id="3">
				<sentence>n 1 n 2 n 1 n 2 ... ... .. n m ( a ) ( b ) Fig.11ntersentential relations In these diagrams a leaf node represents a sentence of a text and an intermediate node denotes a representative sentence of the direcL descendents or the principal parts of them .</sentence>
				<definiendum id="0">leaf node</definiendum>
			</definition>
			<definition id="4">
				<sentence>\ [ Example 2\ ] Titie : A natural language understanding system for data management Heading of Section : Generating English sentences Heading of Subsection : The selector ( l ) The selector 's inaia job is to construct a graph relevant to the input statement .</sentence>
				<definiendum id="0">Titie</definiendum>
				<definiens id="0">A natural language understanding system for data management Heading of Section : Generating English sentences Heading of Subsection : The selector</definiens>
			</definition>
			<definition id="5">
				<sentence>FJg.2 ( b ) '\ ] 'he conlpositJon of the text A symbo : l `` '' ' '' denotes a term prefixed te tile_ ' subfranle conta\ [ n : ing the marl ( , ,¢c- '' and modif led by the sub\ ] rame .</sentence>
				<definiendum id="0">l `` '' ' ''</definiendum>
				<definiens id="0">ing the marl ( , ,¢c- '' and modif led by the sub\ ] rame</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>By `` pragmatically sensitive '' , we mean that the system should not only produce well-formed coherent and cohesive language ( a minimum requirement of any NL system designed to handle discourse ) , but should also be sensitive to those aspects o~ user behaviour that humans are sensitive % o over and above simply providing a good response , including producing output that is appropriately decorated with those minor and semantically inconsequential elements of language that make the difference between natural language and natural natural language .</sentence>
				<definiendum id="0">cohesive language</definiendum>
				<definiens id="0">a minimum requirement of any NL system designed to handle discourse ) , but should also be sensitive to those aspects o~ user behaviour that humans are sensitive % o over and above simply providing a good response , including producing output that is appropriately decorated with those minor and semantically inconsequential elements of language that make the difference between natural language and natural natural language</definiens>
			</definition>
			<definition id="1">
				<sentence>The USER slot identifies the oucrent user of the system .</sentence>
				<definiendum id="0">USER slot</definiendum>
			</definition>
			<definition id="2">
				<sentence>The TURN slot has the value OPEN n or CLOSE n , where n is a number that refers to a particular exchange .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a number that refers to a particular exchange</definiens>
			</definition>
			<definition id="3">
				<sentence>The CONT slot specifies the semantic representation of the utterance , and we envisage using the same representation for semantics and for actions , so that all possible ACT types can be represented uniformly in the CONT slot .</sentence>
				<definiendum id="0">CONT slot</definiendum>
				<definiens id="0">specifies the semantic representation of the utterance</definiens>
			</definition>
			<definition id="4">
				<sentence>The symbols used serve as mnemonics for their approximate counterparts in English , but they should not be strictly equated with them : CONV ( conversation ) , DIAL ( dialogue ) , EXCH ( exchange ) and MOVE ( as discussed above ) .</sentence>
				<definiendum id="0">MOVE</definiendum>
				<definiens id="0">mnemonics for their approximate counterparts in English , but they should not</definiens>
			</definition>
			<definition id="5">
				<sentence>Who the user is can be defined at the CONV level ( i.e. we define a CONV as a conversation with one user ) .</sentence>
				<definiendum id="0">user</definiendum>
				<definiendum id="1">CONV level</definiendum>
				<definiens id="0">a conversation with one user )</definiens>
			</definition>
			<definition id="6">
				<sentence>Greek letters are variables ranging over possible feature values , and are to be interpreted consistently within a rule~ but not necessarily between rules .</sentence>
				<definiendum id="0">Greek letters</definiendum>
				<definiens id="0">variables ranging over possible feature values</definiens>
			</definition>
			<definition id="7">
				<sentence>MOVE i : U , OPEN I , REQAFFIREQACT MOVE 2 : S , CLOSE I , SUPPAFF ( REQAFF ) HOVE 3 : S , OPEN 2 , REQAFF ( RE~ACT ) MOVE 4 : U , CLOSE 2 , SUPPAFF ( REQAFF ( REQACT ) ) MOVE 5 : U , OPEN 3 , RE~ACT , hypothetical HOVE &amp; : S , CLOSE 3 , ACTION Another type of ir=ealis move is an anticipatory move , where on the basis of specific clues the system anticipates what the user 's next move will be .</sentence>
				<definiendum id="0">SUPPAFF ( REQAFF</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">an anticipatory move , where on the basis of specific clues the system anticipates what the user 's next move will be</definiens>
			</definition>
</paper>

		<paper id="1144">
			<definition id="0">
				<sentence>612 ( \ ] ) grapheme level : a b c d e f g phonemelovel : f Notice that the assumption of two levels , one for graphemes and one for phonemes , makes it possible to obtain information about the relation between graphemes and phonemes .</sentence>
				<definiendum id="0">grapheme level</definiendum>
			</definition>
</paper>

		<paper id="1093">
			<definition id="0">
				<sentence>LINGUISTIC SPECIFICATION Before presenting the specification language itself , atrial1 consider wllat properties that such a language we should have .</sentence>
				<definiendum id="0">LINGUISTIC SPECIFICATION Before</definiendum>
				<definiens id="0">presenting the specification language itself</definiens>
			</definition>
			<definition id="1">
				<sentence>Charts consist of a tree part and a forest part describing respectively a tree pattern and a forest pattern .</sentence>
				<definiendum id="0">Charts</definiendum>
				<definiens id="0">consist of a tree part and a forest part describing respectively a tree pattern and a forest pattern</definiens>
			</definition>
			<definition id="2">
				<sentence>gl g2 a ( b , c ( e , a I I b c I e f g gl g2 f , g ( gl , g2 ) ) ) =* a ( c ( e , g ( gl , g2 ) , f ) , b ) Is true : a i I I b c e g f \ [ gl g2 FqY~AE~of decoration for noun phrases : DECORATION deco : SET ( semantic relation : SCALAR ( instrument , quant|fter , qualifier ) , syntactic_function : SCALAR ( coordination , governor , subject ) , category : SCALAR ( noun : SCALAR ( semantic : SET ( animate , measure ) ) , adjective : SCALAR ( ordinal , cardinal , noun phrasequantifier ) determiner : SCALAR ( quantifier ) , subordlnator : SCALAR ( preposition ) ) The basic notion of the language is a labeled and decorated tree .</sentence>
				<definiendum id="0">SCALAR</definiendum>
				<definiens id="0">SCALAR ( ordinal , cardinal , noun phrasequantifier ) determiner : SCALAR ( quantifier ) , subordlnator : SCALAR ( preposition</definiens>
			</definition>
			<definition id="3">
				<sentence>The tree part describes a set of trees with the following syntax : TREE &lt; treepattern &gt; The forest part describes a set of sub-strings with the following syntax : FOREST &lt; forest_pattern &gt; The element of the forest pattern may be : a string element described direct } y ; a sub-string described indirectly using the corresponding structure ( tree ) , defined by some chart .</sentence>
				<definiendum id="0">tree part</definiendum>
				<definiens id="0">describes a set of trees with the following syntax : TREE &lt; treepattern &gt; The forest part describes a set of sub-strings with the following syntax : FOREST &lt; forest_pattern &gt; The element of the forest pattern may be : a string element described direct } y</definiens>
			</definition>
			<definition id="4">
				<sentence>A context pattern is a forest pattern where each tree pattern may be prefixed by the `` not '' boolean operator ( `` ^ '' ) , indicating the mandatory absence of the tree pattern .</sentence>
				<definiendum id="0">context pattern</definiendum>
				<definiens id="0">a forest pattern where each tree pattern may be prefixed by the `` not '' boolean operator ( `` ^ ''</definiens>
			</definition>
			<definition id="5">
				<sentence>A context elememt is a sub-string which is described with a corresponding tree pattern .</sentence>
				<definiendum id="0">context elememt</definiendum>
				<definiens id="0">a sub-string which is described with a corresponding tree pattern</definiens>
			</definition>
			<definition id="6">
				<sentence>THE DERIVATION MECHANISM An element of the mapping defined by a SCSG is a couple ( string , tree ) where the correapondance is defined for , each sub tree , The string is displayed as a linear graph labeled wtth string elements ( terminals of the grammar ) .</sentence>
				<definiendum id="0">DERIVATION MECHANISM An element</definiendum>
				<definiendum id="1">SCSG</definiendum>
				<definiens id="0">a couple ( string</definiens>
				<definiens id="1">terminals of the grammar )</definiens>
			</definition>
			<definition id="7">
				<sentence>ARC ( tree , string , context ) ; \ [ \ [ , \ [ I ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. + ClIART ts the chart identifier , ~\ [ 'ee z s trln9~ is the computed couple , TERMINAL is a string element definition , *chart , ~ vartable that will be tnstantlated with a chart tdenttf let , EVAL ts a predicate that evaluate the constra|nts part , ARC make the reduction and memorize the ( : ontexts for future evaluation .</sentence>
				<definiendum id="0">TERMINAL</definiendum>
				<definiendum id="1">EVAL</definiendum>
				<definiendum id="2">ARC</definiendum>
				<definiens id="0">the chart identifier , ~\ [ 'ee z s trln9~ is the computed couple ,</definiens>
				<definiens id="1">a string element definition</definiens>
				<definiens id="2">ts a predicate that evaluate the constra|nts part ,</definiens>
			</definition>
</paper>

		<paper id="1108">
			<definition id="0">
				<sentence>Following Ballard and Tinkham ( 1984 ) , TELI seeks to enable domain-independent English processing by maintaining detailed case frame information about the phrase types provided for by the system .</sentence>
				<definiendum id="0">TELI</definiendum>
				<definiens id="0">seeks to enable domain-independent English processing by maintaining detailed case frame information about the phrase types provided for by the system</definiens>
			</definition>
			<definition id="1">
				<sentence>For adjective phrases this might be given as 456 ( adjinfo ( head entity `` Subject '' ) ( adj adjective `` Adjective '' ) ( prep prep `` Preposition '' ) ( obj entity `` Object '' ) ) where `` adjinfo '' is an arbitrary symbol used internally to reference adjective phrase case frames .</sentence>
				<definiendum id="0">obj entity</definiendum>
				<definiens id="0">an arbitrary symbol used internally to reference adjective phrase case frames</definiens>
			</definition>
			<definition id="2">
				<sentence>Slot names ( head , adj , prep , obj ) are arbitrary ; filler types ( entity , adj , prep ) generally correspond to parts of speech , although `` entity '' denotes the subset of nouns that comprise the primitive object types of the domain at hand .</sentence>
				<definiendum id="0">Slot names</definiendum>
				<definiens id="0">head , adj , prep , obj ) are arbitrary ; filler types ( entity , adj , prep ) generally correspond to parts of speech , although `` entity '' denotes the subset of nouns that comprise the primitive object types of the domain at hand</definiens>
			</definition>
			<definition id="3">
				<sentence>Next , the interface designer specifies an arbitrary number of templates which the system will seek to match against a user 's English-like case frame specification .</sentence>
				<definiendum id="0">interface designer</definiendum>
				<definiens id="0">specifies an arbitrary number of templates which the system will seek to match against a user 's English-like case frame specification</definiens>
			</definition>
			<definition id="4">
				<sentence>matches any `` open '' category case slot x matches x ( x y ... ) matches any of x , y ... . In particular , the single match found for the structure shown above is a entity can be adj prep a entity which is known to be associated with adjective phrases ( since it was defined for that purpose ) .</sentence>
				<definiendum id="0">open '' category case slot x matches x</definiendum>
				<definiens id="0">a entity can be adj prep a entity which is known to be associated with adjective phrases</definiens>
			</definition>
			<definition id="5">
				<sentence>As noted previously , the question is one of generality versus naturalness in specific situations ; simple modifications to the algorithm given in the preceding section would enable alternate forms .</sentence>
				<definiendum id="0">question</definiendum>
				<definiens id="0">one of generality versus naturalness in specific situations</definiens>
			</definition>
			<definition id="6">
				<sentence>Appelt , D. , Martin , P. and Pereira , F. TEAM : An Experiment in the Design of Transpartable Natural-Language Intrfaces .</sentence>
				<definiendum id="0">TEAM</definiendum>
				<definiens id="0">An Experiment in the Design of Transpartable Natural-Language Intrfaces</definiens>
			</definition>
</paper>

		<paper id="1155">
			<definition id="0">
				<sentence>This figure shows that there is an abstraction hierarchy of descriptions such as surface word sequences , surface syntactic structures , deep syntactic structures , semantic structures , conceptual structures , etc. where , at the deeper levels , the descriptions of sentences of different individual \ ] anguages become closer and finally , at the deepest level ( the level of understanding ) , converge .</sentence>
				<definiendum id="0">deepest level</definiendum>
				<definiens id="0">surface word sequences , surface syntactic structures , deep syntactic structures , semantic structures , conceptual structures , etc. where , at the deeper levels , the descriptions of sentences of different individual \ ] anguages become closer and finally , at the</definiens>
			</definition>
			<definition id="1">
				<sentence>MT is one of the most promising application fields where the research results in text linguistics could be utilized .</sentence>
				<definiendum id="0">MT</definiendum>
			</definition>
			<definition id="2">
				<sentence>Unification Grammar : A Formalism for Machine Translation , COLING 84 , 1984 \ [ King 1981\ ] : King , M. : Design Characteristics of a Machine Translation System , in Proc .</sentence>
				<definiendum id="0">Unification Grammar</definiendum>
				<definiens id="0">A Formalism for Machine Translation</definiens>
				<definiens id="1">Design Characteristics of a Machine Translation System</definiens>
			</definition>
			<definition id="3">
				<sentence>ii , NO. i , 1985 \ [ Wilks 1972\ ] : Wilks , Y. : An Artificial Intelligence Approach to Machine Translation Grammar , in Computer Models of Thought and Language ( eds ; Schank and Colby ) , W.H. Freeman , 1972 \ [ Wilks 1975\ ] : Wilks , Y. : A Preferential Pattern Matching Semantics for Natural Language , Jour .</sentence>
				<definiendum id="0">Y.</definiendum>
				<definiendum id="1">Schank</definiendum>
				<definiendum id="2">Y.</definiendum>
				<definiens id="0">An Artificial Intelligence Approach to Machine Translation Grammar , in Computer Models of Thought and Language ( eds ;</definiens>
				<definiens id="1">A Preferential Pattern Matching Semantics for Natural Language , Jour</definiens>
			</definition>
</paper>

		<paper id="1062">
			<definition id="0">
				<sentence>The corresponding representation is : obj _def ( e , ret~r , single_obj ( calorimeter ) ) obj_def ( W , introd , stuff_obj ( water ) ) proposition ( 1 , obj attr_val , &lt; object ( W ) , attr ( temperature ) , value lee ( at , equal,50 C ) &gt; ) proposition ( 2 , contain , &lt; objeet ( C ) , referent ( W ) &gt; ) Ilere the calorimeter and the water are defined as physical objects and denoted by the identifiers C and W respectively .</sentence>
				<definiendum id="0">corresponding representation</definiendum>
				<definiens id="0">water ) ) proposition ( 1 , obj attr_val , &lt; object ( W ) , attr ( temperature ) , value lee ( at , equal,50 C ) &gt; ) proposition ( 2 , contain , &lt; objeet ( C ) , referent ( W ) &gt;</definiens>
				<definiens id="1">physical objects and denoted by the identifiers C and W respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>A case frame consists of the following parts : cases , selection , constraints , extract and presence .</sentence>
				<definiendum id="0">case frame</definiendum>
				<definiens id="0">consists of the following parts : cases , selection , constraints , extract and presence</definiens>
			</definition>
			<definition id="2">
				<sentence>in : proposition contain cases : object ( O ) , referent0~ ) selection head ( R ) , prep ( in , O ) constraints : is a ( O , container ) , is_ .</sentence>
				<definiendum id="0">R</definiendum>
			</definition>
			<definition id="3">
				<sentence>obj_attr_val ( sp_loc ( at , in , C ) , attr ( temperature ) , quant ( 22 , C ) ) Some points worth of noticing are the resolution of the ellipsed object ( location ) in the second sentence of the exercise ( proposition 12 ) and the resolution of the identic reference ( the calorimeter ) as well as of the pronoun ( it ) in the third sentence ( proposition 14 ) .</sentence>
				<definiendum id="0">obj_attr_val</definiendum>
			</definition>
</paper>

		<paper id="1072">
			<definition id="0">
				<sentence>A list of EUROTRA SRs as given in ELS-3 is reproduced beiow : SR -- -- '' -- -AGENT -EXPERIENCER -PAIIENT PLACE -- -I -- SPACE L TIME POSSESSION -- ORIGIN -~ STUFFTIRESPACE POSGESSION -GOAL ~'~'SPACE TIRE BLUFF PGSSEBSIGN -PATH ~ SPACE I -- '' TIRE AI~ CONDITION CONCESSIVE CONSEQUENCE CAUSE CONCERN QUALITY ~TOTUN ACCORD ACCOMPANIMENT INSTRUMENT MEASURE According to current EUROTRA legislation , these gRs are assigned to dictionary entries of verbs ( and other word classes , which will be disregarded in this paper ) by coders , and through these entries to clauses in a pattern matching process .</sentence>
				<definiendum id="0">list of EUROTRA SRs</definiendum>
				<definiens id="0">given in ELS-3 is reproduced beiow : SR -- -- ''</definiens>
			</definition>
			<definition id="1">
				<sentence>Circumstantial Role : A circumstantial role is a semantic constituent which is , on clause level , realized as a modifier rather than as a complement ~oq~ Participant Role : A semantic constituent which is , on clause level , realized as obligatory complement O~ional Participant Role : A semantic constituent which is , on clause level , realized as an optional complement Inherent Role : Inherent roles are obligatory participant roles and those participant roles which , Jf they are not realized in a clause , lead to look up in the preceding text or situation for a referent , Cf , : ( 20 ) David wax watching .</sentence>
				<definiendum id="0">Circumstantial Role</definiendum>
				<definiens id="0">A semantic constituent which is , on clause level , realized as obligatory complement O~ional Participant Role : A semantic constituent which is , on clause level , realized as an optional complement Inherent Role : Inherent roles are obligatory participant roles and those participant roles which , Jf they are not realized in a clause</definiens>
			</definition>
</paper>

		<paper id="1124">
			<definition id="0">
				<sentence>A two-level grammar consists of two sel ) aratc grammars , the mstaproductlon rule~ ( metarules ) and the hyperrules .</sentence>
				<definiendum id="0">two-level grammar</definiendum>
			</definition>
			<definition id="1">
				<sentence>where METANOTION is tile left-hand side `` nonterminal '' symbol of the production and hypernotion-1 , hypernotlon-2 , ... hypcrnotion-n are the n alternatives of the production right-hand side .</sentence>
				<definiendum id="0">METANOTION</definiendum>
				<definiens id="0">tile left-hand side `` nonterminal '' symbol of the production and hypernotion-1 , hypernotlon-2 , ... hypcrnotion-n are the n alternatives of the production right-hand side</definiens>
			</definition>
			<definition id="2">
				<sentence>Each hypcrnotion consists of protonotions ( terminal symbols ) and other metanotions .</sentence>
				<definiendum id="0">hypcrnotion</definiendum>
				<definiens id="0">consists of protonotions ( terminal symbols</definiens>
			</definition>
			<definition id="3">
				<sentence>A scntence consists of a noun phrase and a verb phrase .</sentence>
				<definiendum id="0">scntence</definiendum>
				<definiens id="0">consists of a noun phrase and a verb phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>The noun phrase consists of an optional sentence modifier such as a `` viewpoint '' adverbial and a subject sequence .</sentence>
				<definiendum id="0">noun phrase</definiendum>
				<definiens id="0">consists of an optional sentence modifier such as a `` viewpoint '' adverbial and a subject sequence</definiens>
			</definition>
			<definition id="5">
				<sentence>The subject sequence consists of two main subjects , separated by the coordinator and .</sentence>
				<definiendum id="0">subject sequence</definiendum>
			</definition>
			<definition id="6">
				<sentence>The verb phrase consists of a predicate sequence and an object sequence .</sentence>
				<definiendum id="0">verb phrase</definiendum>
				<definiens id="0">consists of a predicate sequence and an object sequence</definiens>
			</definition>
			<definition id="7">
				<sentence>Tlm predicate sequence consists of an auxiliary seqnence ( an optional auxiliary adverb such as a focusing or maximizing adverb followed by an active or passive auxiliary verb ) and the main verb of the sentencc , 12 .</sentence>
				<definiendum id="0">auxiliary seqnence</definiendum>
				<definiens id="0">an optional auxiliary adverb such as a focusing or maximizing adverb followed by an active or passive auxiliary verb</definiens>
			</definition>
			<definition id="8">
				<sentence>For exalnplc , the hypernotions where NOUN is singular , where VERB is past partlelple , and where NOUN and VERB agree in person and number call not bc precisely defined except by a very large number of formal rules such ms those given below : where aardvark is singular : EMPTY .</sentence>
				<definiendum id="0">NOUN</definiendum>
				<definiens id="0">singular , where VERB is past partlelple , and where NOUN and VERB agree in person</definiens>
			</definition>
			<definition id="9">
				<sentence>In the subseqnent discussion of hyperrules we will use the not , ation Itu to denote hyperrule number n. The start hypcrrule ( Ill ) of the two-level granunar is : 1 , SENTENOE : condition SENTENOE is a well-formed sentence .</sentence>
				<definiendum id="0">SENTENOE</definiendum>
				<definiendum id="1">SENTENOE</definiendum>
				<definiens id="0">a well-formed sentence</definiens>
			</definition>
			<definition id="10">
				<sentence>AUXILIARY_SEQUENCE VERB OBJECT_SEQUENCE PERIOD is a well-formed sentence : condition SUI1JEC'I~SEQUENCE shows subject-predicate agreelnent witb AUXILIARY_SEQUENOE VERB , condition SUBJEOT_SEQUENOE i.~ a well-formed subject , condition OBJEOT_SEQUEN ( JE shows objeet~prcdicate agreement with VERB , condition AUXILIARY_SEQU\ ] ' ; NOE VERB is ~ well-formed predieate~ condition OBJEGT_SEQUEN ( JE is a wclbhwmed object .</sentence>
				<definiendum id="0">AUXILIARY_SEQUENCE VERB OBJECT_SEQUENCE PERIOD</definiendum>
				<definiendum id="1">OBJEOT_SEQUEN</definiendum>
				<definiendum id="2">JE</definiendum>
				<definiens id="0">a well-formed sentence</definiens>
				<definiens id="1">a wclbhwmed object</definiens>
			</definition>
			<definition id="11">
				<sentence>condition IMAIN__SUBJEOT1 trod MAIN_SIJBJECT2 is a well-formed subject : condition MAIN_SUBJECTI is a well-formed subjcct , condition MAIN_SUBJE ( JT2 is a well-remind subjcct .</sentence>
				<definiendum id="0">MAIN_SUBJECTI</definiendum>
				<definiens id="0">a well-formed subject : condition</definiens>
			</definition>
			<definition id="12">
				<sentence>Premodifieatiml ( H13 ) requires 1 ) correct determiner usage ( i.e. with respect to singular and plural nouns ) and 2 ) any prcmodifying nouns must be singular or `` mass '' nouns ( i.e. nouns which denote item composition such as aluminum , bra~ss , etc. ) .</sentence>
				<definiendum id="0">Premodifieatiml</definiendum>
			</definition>
			<definition id="13">
				<sentence>qs nouns : where NOUN is Mngula¢ ; wlmre NOUN is a mass noun .</sentence>
				<definiendum id="0">NOUN</definiendum>
				<definiendum id="1">wlmre NOUN</definiendum>
				<definiens id="0">a mass noun</definiens>
			</definition>
			<definition id="14">
				<sentence>condition NOONI and NOUN2 arc singular or mass nouns : where NOUN1 is a mass noun~ where NOUN2 is a mass noun .</sentence>
				<definiendum id="0">NOUN1</definiendum>
				<definiens id="0">a mass noun~ where NOUN2 is a mass noun</definiens>
			</definition>
			<definition id="15">
				<sentence>MODIFICATION IS correct ill postlnodil|l : atlol| l condition POST_NOUN MODIFIOATION correctly post , modlfies DETERMINEI { NOUN_\ [ lEAD .</sentence>
				<definiendum id="0">MODIFICATION</definiendum>
			</definition>
			<definition id="16">
				<sentence>IIEAD : condition NOUN_IlEAl ) is a human noun , eondithm the verb of RELATIVI , ; _C , LAUSE agree~ wltll I ) ETERMINEll NOUN_IIEAD .</sentence>
				<definiendum id="0">condition NOUN_IlEAl</definiendum>
				<definiens id="0">a human noun , eondithm the verb of RELATIVI</definiens>
			</definition>
			<definition id="17">
				<sentence>conditlou NOUN is a human norm t where NOUN is a human noun .</sentence>
				<definiendum id="0">NOUN</definiendum>
				<definiendum id="1">NOUN</definiendum>
				<definiens id="0">a human norm t where</definiens>
			</definition>
			<definition id="18">
				<sentence>condition NOUNI and NOUN2 is a human noun t wlmre NOUN1 is a human noun 9 where NOUN2 is a human noun .</sentence>
				<definiendum id="0">NOUN2</definiendum>
				<definiendum id="1">NOUN2</definiendum>
				<definiens id="0">a human noun</definiens>
			</definition>
			<definition id="19">
				<sentence>condition NOUN_LIST COMMA_OPTION and NOIJN iS a hLIman nonu 1 condition NOUN_LIST in a human noun~ where NOUN is a human noun .</sentence>
				<definiendum id="0">NOUN</definiendum>
				<definiens id="0">a human noun</definiens>
			</definition>
			<definition id="20">
				<sentence>condition NOUN_LIST COMMA NOUN is a human noun : condition NOUN_LIST is a human noun , wikere NOUN is a human noun .</sentence>
				<definiendum id="0">condition NOUN_LIST COMMA NOUN</definiendum>
				<definiendum id="1">NOUN_LIST</definiendum>
				<definiendum id="2">NOUN</definiendum>
				<definiens id="0">a human noun</definiens>
			</definition>
			<definition id="21">
				<sentence>condition the verb of who PREDICATE_SEQUENGE OBJECT_SEQUENCE agrees with DETERMINER NOUN~HEAD : condition DETERMINER NOUN_IlEAl ) PREDICATE_SEQUENCE OBJECT_SEQUENCE PERIOD is a well-formed sentence , Tile third condition that the English sentences defined by our grammar must satisfy is that the predicate ( verb ) and objects should agrcc .</sentence>
				<definiendum id="0">DETERMINER NOUN_IlEAl ) PREDICATE_SEQUENCE OBJECT_SEQUENCE PERIOD</definiendum>
				<definiens id="0">a well-formed sentence</definiens>
				<definiens id="1">that the predicate ( verb ) and objects should agrcc</definiens>
			</definition>
			<definition id="22">
				<sentence>condition AUXILIARY_ADVERB_OPTION VERB is a well-formed predicate : EMPTY .</sentence>
				<definiendum id="0">AUXILIARY_ADVERB_OPTION VERB</definiendum>
				<definiens id="0">a well-formed predicate</definiens>
			</definition>
			<definition id="23">
				<sentence>condition ALrXILIAI~Y_ADVEI~ , B_OPTION AC TIVE_OR_PA S SIVE_ , AUX/LIARY VERB is a well-formed predicate : where VERB is a past participle .</sentence>
				<definiendum id="0">VERB</definiendum>
				<definiendum id="1">VERB</definiendum>
				<definiens id="0">a well-formed predicate : where</definiens>
				<definiens id="1">a past participle</definiens>
			</definition>
			<definition id="24">
				<sentence>A simple object ( H33 ) must satisfy the same conditions as a subject and hyperrules H10-H12 will apply recursively .</sentence>
				<definiendum id="0">simple object</definiendum>
				<definiens id="0">a subject and hyperrules H10-H12 will apply recursively</definiens>
			</definition>
			<definition id="25">
				<sentence>33 , condition OBJE ( 3T OBJECT_SEQUENCE_ADVERB is a well-formed object : condition OBJECT is a well-formed subject .</sentence>
				<definiendum id="0">OBJECT_SEQUENCE_ADVERB</definiendum>
				<definiendum id="1">condition OBJECT</definiendum>
				<definiens id="0">a well-formed object</definiens>
			</definition>
			<definition id="26">
				<sentence>_ADVERB is a well-formed object : condition INDIRECVr OBJE ( 3T is a well-formed nbject~ condition DIRECT_OBJECT is a well-formed object .</sentence>
				<definiendum id="0">_ADVERB</definiendum>
				<definiendum id="1">DIRECT_OBJECT</definiendum>
				<definiens id="0">a well-formed object</definiens>
				<definiens id="1">a well-formed object</definiens>
			</definition>
			<definition id="27">
				<sentence>2b * condition Professor White and the students who attend the university is a well-formed subject 3b * condition Professor White is a well-formed subject 4b * 3c * condition the students who attend the university is a well-formed subject 4e * condition the students is correct in premodification 4d .</sentence>
				<definiendum id="0">university</definiendum>
				<definiens id="0">a well-formed subject 3b * condition Professor White is a well-formed subject 4b * 3c * condition the students who attend the</definiens>
			</definition>
</paper>

		<paper id="1058">
</paper>

		<paper id="1133">
</paper>

		<paper id="1038">
</paper>

		<paper id="1033">
</paper>

		<paper id="1110">
			<definition id="0">
				<sentence>Survey of some ideas behind CAP The data structure used in CAP is a type of chart called S-graph ( see Maas 1985 ) .</sentence>
				<definiendum id="0">CAP</definiendum>
			</definition>
			<definition id="1">
				<sentence>The S-graph is an acyclic directed graph with exactly one start node and one end node .</sentence>
				<definiendum id="0">S-graph</definiendum>
				<definiens id="0">an acyclic directed graph with exactly one start node</definiens>
			</definition>
			<definition id="2">
				<sentence>The non-structural information is a set of property/value-pairs called 'decoration ' .</sentence>
				<definiendum id="0">non-structural information</definiendum>
				<definiens id="0">a set of property/value-pairs called 'decoration '</definiens>
			</definition>
			<definition id="3">
				<sentence>Where GPSG employs meta-rules , derived categories , and the ID/LP-formalism , LFG uses different structural concepts ( Cand F-structures ) and above all lexical knowledge .</sentence>
				<definiendum id="0">GPSG</definiendum>
				<definiendum id="1">LFG</definiendum>
			</definition>
			<definition id="4">
				<sentence>There are five types of rules according to the effect they have : blending rule : A + B = &gt; C start rule : A = &gt; X ( A ) right ex~insion : A ( X ) + B = &gt; A ( X + B ) left expansion : A + B ( X ) = &gt; B ( A + X ) concatenati~\ ] : A + B = &gt; X ( A + B ) A blending rule may be employed where a constituent structure does not have to be preserved , as in : AUX+PTC = &gt; FIV for : 'was ' + 'treated ' = &gt; treat ( TENSE=PAS~ ; MS=FINITE VERB , VOICE=PASS ) AUX 4INP = &gt; FIV for : 'will ' + 'treat ' = &gt; treat ( ~NSE=FUT etc. ) C !</sentence>
				<definiendum id="0">TENSE=PAS~ ; MS=FINITE VERB</definiendum>
				<definiens id="0">A + B = &gt; C start rule : A = &gt; X ( A ) right ex~insion : A ( X ) + B = &gt; A ( X + B ) left expansion : A + B ( X ) = &gt; B ( A + X</definiens>
				<definiens id="1">A + B = &gt; X ( A + B</definiens>
			</definition>
			<definition id="5">
				<sentence>end A mission consists of a list of submissions or scouts that are applied in the mode &lt; mode &gt; , if certain 'expectations ' ( =preconditions ) are fulfilled .</sentence>
				<definiendum id="0">mission</definiendum>
				<definiens id="0">consists of a list of submissions or scouts that are applied in the mode &lt; mode &gt; , if certain 'expectations ' ( =preconditions ) are fulfilled</definiens>
			</definition>
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>The point of view which we will adopt here is a very simple one : sentences are hierarchically structured strings of words , and grammar is a statement about the internal composition and external distributions of words .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiens id="0">sentences are hierarchically structured strings of words</definiens>
				<definiens id="1">a statement about the internal composition and external distributions of words</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , there is a non-inflectional Subcategorization Rule which states that English non-pronouns are either proper or common .</sentence>
				<definiendum id="0">non-inflectional Subcategorization Rule</definiendum>
				<definiens id="0">states that English non-pronouns are either proper or common</definiens>
			</definition>
			<definition id="2">
				<sentence>Patient ( PAT ) : the perceived central participant in a state or event Agent ( AGT ) : the perceived external instigator , initiator , controller , or experienccr of the action , event , or state Locus ( LOC ) : inner : the perceived concrete or abstract source , goal , or location of the Patient outer : the perceived concrete or abstract source , goal , or location of the action , event , or state Correspondent ( CAR ) : inner : the entity perceived as being in correspondence with the Patient outer : the perceived external frame or point of reference for the action , event , or state as a whole Means ( MNS ) : inner : the perceived immediate affeetor or effeetor of the Patient outer : the means by which the action , state , or event as a whole is perceived as being realize Fig .</sentence>
				<definiendum id="0">Patient</definiendum>
				<definiens id="0">the perceived central participant in a state or event Agent ( AGT ) : the perceived external instigator , initiator , controller , or experienccr of the action , event , or state Locus ( LOC ) : inner : the perceived concrete or abstract source , goal , or location of the Patient outer : the perceived concrete or abstract source , goal , or location of the action , event , or</definiens>
				<definiens id="1">the perceived immediate affeetor</definiens>
			</definition>
			<definition id="3">
				<sentence>Kaplan , It. , and Bresnan , J. , Lexical-Functional Grammar : A Formal System for Grammatical Representation .</sentence>
				<definiendum id="0">Lexical-Functional Grammar</definiendum>
				<definiens id="0">A Formal System for Grammatical Representation</definiens>
			</definition>
</paper>

		<paper id="1125">
			<definition id="0">
				<sentence>Marcus indicates this by use of `` attach a new node of 'type ' to active node '' in the grammar rules .</sentence>
				<definiendum id="0">Marcus</definiendum>
				<definiens id="0">attach a new node of 'type ' to active node '' in the grammar rules</definiens>
			</definition>
			<definition id="1">
				<sentence>( 3 ) Drop ( pop ) : pops the top node of the stack ( CAN ) .</sentence>
				<definiendum id="0">Drop ( pop )</definiendum>
				<definiens id="0">pops the top node of the stack ( CAN )</definiens>
			</definition>
			<definition id="2">
				<sentence>Marcus uses different notations , namely `` drop '' and `` drop into buffer '' , in the grammar to indicate the etTect of drop operations .</sentence>
				<definiendum id="0">Marcus</definiendum>
				<definiens id="0">uses different notations</definiens>
			</definition>
			<definition id="3">
				<sentence>Therefore an LR ( k.t ) parser will need to delay reduction of more than t possible phrases in parsing of '' a sentence with a prefix a '~ , n &gt; k+t , and thus G , is not LR ( k , t ) for any given k and t. In fact , LR ( k , t ) parsers put a limit t on the number of delayed decisions at any time during the parsing .</sentence>
				<definiendum id="0">Therefore an LR</definiendum>
				<definiens id="0">need to delay reduction of more than t possible phrases in parsing of '' a sentence with a prefix a '~</definiens>
			</definition>
			<definition id="4">
				<sentence>Consider the LR ( 0 ) = LR ( 0,1 ) grammar G ~ : S-~ , A A~cA A-~a S~B B-~cB B~b With any finite buffer , Marcus ' parser will be flooded with c 's , before it can decide to put an A node or a B node on the stack .</sentence>
				<definiendum id="0">A~cA A-~a S~B B-~cB B~b With</definiendum>
				<definiens id="0">any finite buffer</definiens>
			</definition>
			<definition id="5">
				<sentence>We have shown that the class of context-free grammars parsablc by a Marcus-type parser is neither a subcla , ; s of l , R ( k , t ) nor a subclass of BCP ( m , n ) grammars .</sentence>
				<definiendum id="0">Marcus-type parser</definiendum>
				<definiens id="0">the class of context-free grammars parsablc by a</definiens>
			</definition>
</paper>

		<paper id="1071">
			<definition id="0">
				<sentence>i is a problem or not , however~ an appruach which is censistent mith the general spirit o~ the model might he to define a cumber of 'choice ' levels , at which ~ : bmices between alternatives would be made ( tS is the obvious candidate ) , fie would require G and T rules tu be set up se that all alternative representations at these levels would he translatimn~lly equivalent~ uo that choice could be arbitrary .</sentence>
				<definiendum id="0">however~ an appruach</definiendum>
				<definiendum id="1">tS</definiendum>
				<definiens id="0">the obvious candidate )</definiens>
			</definition>
</paper>

		<paper id="1132">
			<definition id="0">
				<sentence>The RAREAS system is the natural language component of the MARWORDS project , which envisages automating the process of creating bulletins from meteorological information .</sentence>
				<definiendum id="0">RAREAS system</definiendum>
				<definiens id="0">the natural language component of the MARWORDS project , which envisages automating the process of creating bulletins from meteorological information</definiens>
			</definition>
			<definition id="1">
				<sentence>A major task in designing RAREAS was the definition of an input data format which properly divides the work between the MARWORDS expert system , which computes predicted values of weather parameters based on large-scale observations , and RAREAS itself , which interprets that data under local conditions for the purpose of marine forecasts .</sentence>
				<definiendum id="0">RAREAS itself</definiendum>
				<definiens id="0">computes predicted values of weather parameters based on large-scale observations , and</definiens>
			</definition>
			<definition id="2">
				<sentence>In its current implementation RAREAS reads the formatted forecast data and carries out ( sequentially ) the following major operations : reading and parsing of formatted input data , with the interpretation of certain coded values ; checking of data for consistency and plausibility , using databases of geographical and meteorological information ; insertion of default values when needed ; detection of conditions which are hazardous for marine operalions ( e.g. , freezing spray , calculated as a function of forecast wind speed and air temperature , and of a seasonally and regionally adjusted water temperature taken from the database ) ; `` merging of areas '' , namely , a check for similarity in the data for contiguous forecast areas ; when similarity threshold conditions are satisfied a single report formula is created for the merged areas under a header which lists those areas ; 563 suppression of data not sufficiently salient for explicit inclusion in the report ( e.g. , temperature is generally dropped after its use to check if freezing spray conditions are present ) ; synthesis of pre-linguistie ( `` logical '' ) representation for each sequence of weather events ; interpretation of transitions between weather events into same pre-linguistic form ; segmentation of logical structures into more .</sentence>
				<definiendum id="0">RAREAS</definiendum>
				<definiens id="0">reads the formatted forecast data and carries out ( sequentially ) the following major operations : reading and parsing of formatted input data , with the interpretation of certain coded values ; checking of data for consistency</definiens>
				<definiens id="1">the merged areas under a header which lists those areas ; 563 suppression of data not sufficiently salient for explicit inclusion in the report</definiens>
			</definition>
			<definition id="3">
				<sentence>The RAREAS architecture isolates different types of linguistic and non-linguistic knowledge within appropriate modules .</sentence>
				<definiendum id="0">RAREAS architecture</definiendum>
				<definiens id="0">isolates different types of linguistic and non-linguistic knowledge within appropriate modules</definiens>
			</definition>
</paper>

		<paper id="1042">
			<definition id="0">
				<sentence>The ANS ( p.468 ) provides no rule for choosing between using the simple ( or perfect ) past and using the modal auxiliary zullen .</sentence>
				<definiendum id="0">ANS ( p.468 )</definiendum>
				<definiens id="0">provides no rule for choosing between using the simple ( or perfect ) past and using the modal auxiliary zullen</definiens>
			</definition>
			<definition id="1">
				<sentence>In Groenendijk , J.A.G. , T.M.V. Janssen , &amp; M.B.J. Stokhof , eds , Formal methods in the study of language , vol .</sentence>
				<definiendum id="0">M.B.J. Stokhof</definiendum>
				<definiens id="0">eds , Formal methods in the study of language , vol</definiens>
			</definition>
</paper>

		<paper id="1118">
			<definition id="0">
				<sentence>TOPIC supplies text condensates ( summaries ) on variable degrees of generality and makes available facts acquired from the texts .</sentence>
				<definiendum id="0">TOPIC</definiendum>
				<definiens id="0">supplies text condensates ( summaries ) on variable degrees of generality and makes available facts acquired from the texts</definiens>
			</definition>
			<definition id="1">
				<sentence>Consequently , TOPIC 's text parser consists of two main components : the world knowledge which provides the means of correctly associating concepts with each other ( see sec.4.1 ) and the decision procedures ( word experts ) which utilize this foreknowledge to relate the concepts that are actually referred to by lexical items in a text , thus determining the patterns of thematic progression ( see see.4.2 ) .</sentence>
				<definiendum id="0">TOPIC 's text parser</definiendum>
				<definiens id="0">consists of two main components : the world knowledge which provides the means of correctly associating concepts with each other ( see sec.4.1 ) and the decision procedures ( word experts ) which utilize this foreknowledge to relate the concepts that are actually referred to by lexical items in a text , thus determining the patterns of thematic progression</definiens>
			</definition>
			<definition id="2">
				<sentence>Prototype frame ( concept class ) : micropr~es ~r &lt; wor~ leng~ &gt; I 4 bit , S bit , 16 bit , 32 bit \ ] ( \ ] ~nu~churer &gt; Associated instance frames ( individual concepts ) : zs @ ~szo0 S bit 16 bit &lt; reanufact~er &gt; &lt; \ ] ~nu~urer &gt; zil~j 5bto~la Fig 5 : A Prototype and Associated Instance Frames Frames are connected with each other by semantic relations ( cf. Fig 6 ) .</sentence>
				<definiendum id="0">Prototype</definiendum>
				<definiens id="0">micropr~es ~r &lt; wor~ leng~ &gt; I 4 bit</definiens>
			</definition>
			<definition id="3">
				<sentence>The semantic relation part-of is aggregation which expresses a semantic closeness .</sentence>
				<definiendum id="0">semantic relation part-of</definiendum>
				<definiens id="0">expresses a semantic closeness</definiens>
			</definition>
			<definition id="4">
				<sentence>lahn , U. ; U. Reimer : Computing Text Constituency : An Algorithmic Approach to the Generation of Text Graphs .</sentence>
				<definiendum id="0">Text Constituency</definiendum>
				<definiens id="0">An Algorithmic Approach to the Generation of Text Graphs</definiens>
			</definition>
			<definition id="5">
				<sentence>Hahn : On Formal Semantic Properties of a Frame Data Model .</sentence>
				<definiendum id="0">Hahn</definiendum>
			</definition>
			<definition id="6">
				<sentence>Strong , S : An Algorithm for Generating Structural Surrogates of English Text .</sentence>
				<definiendum id="0">S</definiendum>
			</definition>
</paper>

		<paper id="1134">
			<definition id="0">
				<sentence>Pleh ) w is a section of the database after event recognition has taken place ( the original entries are ill German ) .</sentence>
				<definiendum id="0">Pleh ) w</definiendum>
				<definiens id="0">a section of the database after event recognition has taken place ( the original entries are ill German )</definiens>
			</definition>
			<definition id="1">
				<sentence>The deep &lt; asus slot 571 contains first the verb stem of iiberholen as needed by the generation component and second the formal notation for an instantiation. The obligatory cases must be generated but may be omitted in the surface string in case of elliptic utterances whereas optional deep cases need not be generated at all. In the combinations slot it is represented which deep cases may be generated together ( e.g. for the verb fahren ( drive ) it is not allowed to generate a single SOURCE but instead SOURCE and GOAL must be generated ) . The Lot-preps slot specifies the prepositions which may be used with the verb iiberholen to generate locative expressions. The case descriptions in the obligatory and optional slots consist of two parts : a declaration of an identifier for the case expression on the language side , and a predicate ( in general a list of predicates ) relating the case expression to the scene data. The most important predicates are REF , TIME-REF , and LOC-REF. REF generates referring phrases for internal object descriptors like BMW1. TIME-REF generates the tense of the verb. As descriptions are usually given in present tense , presently TIME-REF only generates this tensc. LOC-REF relates the abstract location of the object as given by its coordinates to a natural language expression for a reference object. Note , that REF has to be used to generate a referring phrase for the reference object. Consider the sixth entry of the database in section 2. The instantiation only contains internal identifiers for objects , like traflic-lightl , for which referring phrases have to be generated ( see section 4 for further details on REF ) . In NAOS we use a specialization hierarchy for motion verbs. This hierarchy is pragmatically motivated and is rooted in situational semantics. It is no hierarchy of motion concepts as the one proposed in \ [ 23\ ] . It connects general verbs witb more special ones. A situation which may be described using a special verb implies the application of all more general verbs Take for instance the verb iiberholen ( overtake ) . \ [ t implies the use of the more general verbs vorueberfahren~ vorl ) nifahren ( drive past ) , passieren ( pass ) , naehern-r ( approach ) , entfernen-r ( recede ) , fahren ( drive , move ) , and bewegen-r ( move ) . It shonld be intuitively plausible that such a hierarchy is also used for event recognition. If , for instance , no naehern-r ( approach ) can be instantiated the more special events need not be tested. In NAOS the overall strategy for generating a descriptive text is as follows : * Group all moving objects according to their classmembership ; • For each object in each group describe the motions of the object for the time interval during which it was visible in the scene , Event selection for an object is done according to the following algorithm : and where the object was the agent ; most special event of the above collected ones ; one which started earlier and has the same or longer duration as the other one or take the one with longer duration ; in temporally consecutive order. Consider the following example. All events which were found for PERSON1 are : 572 ( RECEDE PERSON1 FBI 20 40 ) ( ENTFERNEN-R PERSDI\ ] I FDI 20 40 ) ( } /ALK PERSONI 0 40 ) ( OEHEI~ PERSONI 0 40 ) ( MOVE PERSONI O 40 ) ( BE~//EGEN-R PERSOIll 0 40 ) The above algorithm leads by use of the specialization hierarchy to the following verbalization list for PERSON1 : ( ( ( ~IALK PERSOI~I 0 40 ) ( 0 20 ) ) ( ( RECEDE PERSON1 FBI 20 40 ) ( 20 40 ) ) ) ( The last entry in parenthesis of each selected event denotes the interval in which the event was the most special one. ) This selection process is our first implementation of the strategy of anticipated visualization. The underlying question is : Which optional deep cases should be selected to restrict the hearer 's possibilities of placing the trajectory of an object in his internal model of the static background of the scene ? In NAOS the selection algorithm answering the above question is rather straightforward. It is based on the manner of action of the verb , the verbtype , and the heater 's knowledge. The algorithm is graphically represented in figure 2. EVENTTYPE NON-DURATIVE , INCHOATIVE DURATIVE Tl , ,o = EB A T , , , a = SE Tb , ~ = SB ^ T , , , d ¢~ SE T~ , ~ ~S B A T , ,d = S E VERBTYPE DIR LOC RED DIR , LOC RED RED DIR , STAT LOC STAT DIR , REO LOC STAT DIR LOC RED DEEP CASES LOCATIVE ? DIRECTION ? , LOCATIVE ? DIRECTION ? LOCATIVE ? NIL NIL LOCATIVE ? DIRECTION ? , LOCATIVE ? LOCATIVE ? NIL DIRECTION ? LOCATIVE ? LOCATIVE ? SOURCE ? , DIRECTION ? NIL RED NIL T~ , ~ ~ 8B ^ T , ,a ~ SE DIR , STAT LOCATIVE ? LOC SOURCE ? , GOAL7 Figure 2 : Selection of Deep Cases The abbreviations denote : Tb~ , Ten , t : start , end time of the event ; SB , SE : scene begin and scene end ; I ) IR , LOC , STAT , RED : directional ( turn off , return ) , locomotion ( walk , overtake ) , and static ( stand , wait ) verbs , finally verbs whose recognition implies reference objects ( reach s. th. , arrive at ) . The figure has to be read as follows. If an inchoative event like losfahren ( start moving ) has to be verbalized which has the verbtype locomotion , then choose direction ? and locative ? as deep cases. The question mark generally means , look into the partnermodel Lo see whether this deep case has already been generated fi ) r another event. If so , determine by use of the object 's actual location ( represnnted in the scene representation ) whether it is still valid. If this is the case do n't generate a uatural language expression for this deep case , otherwise do. Presently the partnermodel contains information about the static background of the scene and about what has been said so far in the same relational notation as was shown for instantiations in section 2. It is being updated when an event is verbalized. Note , that for durative events the decision is based on whether the start and end time of the event coincide with the beginning or ending of the image sequence. Consider the first case for durative events as given in figure 2. Right from the beginning of the sequence there is a car moving along a street until the sequence ends. In such a case it is not possible to verbalize a source as the object may have started its motion anywhere. To restrict the hearer 's visualization , direction and locative cases are verbalized , leading to a sentence like : The car moves on Schliiterstreet in direction of HaHerplace. Verbalizing a direction when the static background is known restricts the trajectory to being on one side of the road. Basically , our direction case is a goal or source ease where only two prepositional phrases are allowed , the German phrases in Richtung and aus Richtung ( in direction~ from direction ) . These phrases do not imply that the motion ends at the goal location as do most prepositional phrases in German which have to be in accusative surface case to denote a goal. The English language is in this respect inherently ambiguous. In the sentence The car moves behind the truck , the phrase behind the truck may denote a locative or goal deep case. In German these eases arc distinguished at the surface. \ [ `` or locative the above sentence translates to Des Aitto f~hrt hinter dem LKW , for the goal case , it translates to Des Auto f~hrt hinter den LKW. We have to distinguish different verbtypes as e.g. the meaning of a directional phrase changes with the verl ) type. Consider the sentences The car moves in direction of Hallerplace versus The car stands in direction of l\ [ allerplace ( in German both sentences arc well formed ) . The first sentence denotes the direction of the motion whereas the second one denotes the orientation of I , hc car. We thns distinguish between static ( STAT ) and h ) eomotion ( LOC ) verbs. The third verbtype , directional ( I ) IR ) , is used for verbs with a strong directional component like umkehren ( return ) , abbiegen ( turn off ) , etc. As they already imply a certain direction the additional verbalization of a direction using a prepositional phrase does usually not lead to acceptable sentences. The fourth type ( REO ) is used tbr verbs like erreichen ( reach s. th. ) having an obligatory locative case. The main result to note here is that the selection processes are low-level and verboriented. The only higher level goal is to inform the hearer and to convey as ranch information about an event as possible. In the next section we show by differem ; verbalizations of the same scene how rather complex syntactic structures arise. The general scheme for the generation process is as follows : first , then persons ; time of occurrence in the scene , earliest first ; ( a ) if the current event has a precedent and its event time is included in the precedent 's , begin the sentence with dabei ( in the meantime ) ; go to ( c ) ; ( b ) if the current event has a precedent and its event time overlaps the precedent 's , begin the sentence with unterdessen ( approx , in the meantime ) ; go to ( c ) ; ( c ) determine the optional deep cases and build a simple declarative sentence by using all chosen deep cases and applying the deep case semantics. Two temporally consecutive events are not verbalized using a temporal adverb as in the cases of inclusion and overlapping. This is due to the fact that from the linear order of the sentences the hearer usually infers consecutivity. The result of the above algorithm is a formal representation of the surface sentence which , rougidy , contains the w~rb 's stem , gemls verbi , modality , and person , all deep cases in random order , and all stems of the \ [ exical entries which appear in the surface sentence. This representation is taken as input by the system SUTRA ( for further details on the formal represeutation and the SUTRA system see \ [ 41 ) which then generates a correctly inflected German sentence. Below is an example of the output of NAOS. 18. , ausgabe text DIE SZENE EN'rHAELT VIER BEWEGTE OBJEKTE : DREI PKWS UND EINEN FUSSGAENGER. The scene consists of four moving objects : three vehicles and a pedestrian. EIN GRUENER VW NAEHERT SICtt DEM GROSSEN FUSSGAENGER AUS RICHTUNG tIALLERPLATZ. ER FAEIIRT AUF DER SCHLUETERSTRASSE. A green VW approaches the tall pedestrian from the direction of flalterplaee. It drives on Schlseterstreet. EIN GELBER VW FAEHRT VON DER ALTEN POST VOR DIE AMPEL. WAEHREN1 ) I ) ESSEN ENTFERNT ER SICH VON DEM GRUENEN VW. A yellow VW drives from the old postoftice to the tra~c light , h~ the meantime it recedes from the green VW. EIN SCHWARZER BMW FAEHRT IN RICHTUNG ttALLERPLATZ. DABEI UEBERIIOLT ER DEN GELBEN VW VOR DEM I '' ACIIBERI , \ ] ICI\ [ I INFORMATIK , DER SCltWARZE BMW ENTFERNT S1CI1 VON I ) EM GRUENEN VW. A black BMWdrives in the direction of Hallerpiace , During this time it overtakes the yellow VW in front of the department of computer science. The black BMW recedes from the green VW. DER GROSSE FUSSGAENGER GEHT IN RICHTUNG DAMMTOR AUF I ) EM SUEDLICIIEN FUSSWEG WESTLICH DER SCHLUETERSTRASSE. WAEHRFNDDESSEN ENTFERNT ER SICH VON DEM FACIIBEREICH INFORMATIK. The tall pedestrian walks hJ the direction of Dammtnr on the southern sidewalk west of Sehlseterstreet. h~ the meantime he recedes from the department of compnter science. 19. , logout The first sentence above is a standard one having the same structure for all different scenes. The remaining four paragraphs are motion descriptions for the tbur moving objects. We now discuss step ( c ) of the above algorithm in more detail as it covers some interesting phenomena. Consider the third paragraph describing the motions of the yellow VW. The verbalization list for this object is : ( ( ( DRIVE VW1 10 20 ) ( 10 25 ) ) ( ( RECEDE VW1 ~2 25 32 ) ( 25 32 ) ) ) The beginning ( SB ) and ending of the sequence ( SE ) lie at points 0 and 40 , respectively. According to the selection algorithm ( figure 3 ) a SOURCE should be verbalized for a durative event with the above event time if the verbtype is LOC. The generation algorithm checks whether the chosen optional cases are allowed for the verb , if so , it is further checked whether the combinations are allowed. As a SOURCE may not be generated alone for a fahren ( drive , move ) event , SOURCE and GOAL are generated. The fourth paragraph shows the outcome of a deep case selection in which the chosen case is not allowed for the verb. The verbalization llst for the black BMW contains only ilberholen ( overtake ) and entfernen-r ( recede ) . ( ( ( OVERTAKE BMWI VWI ( 10 12 ) ( 12 32 ) ( 10 32 ) ) ( ( RECEDE Bl~qt ~/2 20 40 ) ( 32 40 ) ) ) According to eventand verhtype DIRECTION is chosen as the appropriate deep case. As this case may not be used with the verb overtake two sentences are generated , one describing the direction 573 of the motion and the other one describing tbe specific event. The second sentence begins with a temporal advert ) specifying that both motions occur at the same time. In order to generate the two sentences first the classmembership of the agent of the verb which may not take the chosen deep case is determined. Then the speeializationhierarehy is used to go up to either fahren ( driv % move ) or gnhen ( walk ) as those verbs may take any deep case. Then the sentences are generated. Consider the following verbalization list : ( ( ( OVERTAKE BI~WI VW1 ( 0 8 ) ( 12 18 ) ( 0 18 ) ) ( ( DRIVE BI'~I 0 40 ) ( 18 40 ) ) ) Assuming the direction and location of the motion to be the same as before the algorithm presented so fat '' would generate A black BMW drives in the direction of Hallerplace. During this time it overtakes the yellow VW in front of the department of computer science. The black BMW drives. According to the deep ease selection algorithm a DIRECTION and LOCATIVE should be generated for the second event above. As both cases have already been generated with the first event and are still valid the sentence The black BMW drives is not generated because before generating a sentence it is checked whether the intbrmation is already known to the partner. In this section some aspects of the referring phrase generator are discussed. As can be seen from the example text objects are characterized by their properties , introdueed with indefinite noun phrases when they are not single representatives of a class and they may also be pronominalized to add to the coherence of the text. Therefore we use standard techniques as e.g. described in \ [ 8\ ] , \ [ 9\ ] . We want to stress one aspect of our referring phrase generator , namely its capability to generate restrictive relative clauses with motion verbs. As it may be easily the ease that a scene contains two objects with similar properties the task arises to distinguish them and generate unequivocal referring expressions. It is an interesting fact , that , we have several options to cope with this problem which each have their consequences. One option is to adopt McDonald 's scheme of generation without precisely knowing what to say next \ [ 13\ ] . According to this scheme two similar objects are characterized in the following way in NAOS. When the first one is introduced it is characterized by it 's properties e.g. a yellow VW. When the second one has to be introduced , REF notices that a yellow VW is already known to the partner and generates the phrase another yellow VW. It starts getting interesting in subsequent reference. The objects are then characterized by the events in which they were involved earlier whether as agent or in another role. This leads to referring phrases like the yellow VW , which receded from the pedestrian or the yellow VW , which has been overtaken. Note , how passive relative clauses arise naturally from the task of generating referring phrases in this paradigm. The same is also true for negation. Consider the case where the first yellow VW , say VWI , has passed an object and the second yellow VW , say VW2 , has overtaken an object and both event , s are already known to the partner. If REF has to generate again a referring phrase for VWI it notices that pass is a more general verb than overtake and may thus also be applied for the overtake event. It therefore generates the phrase the yellow VW , which has not overtaken the other object to distinguish it unequivocally from VW2 , Below is an example of this strategy in a texL for the same scene as above. The difference to the th'st scene is that we replaced the green VW by a yellow one. 10. , ausgabe text ; 574 DIE SZENE ENTItAI'~LT VIER BEWIdGTE OBJEKTE : I ) RE1 PKWS UND EINEN FUSS ( ~AENGER. The scene consists of four moving objects : three vehicles and a pede.. s~rian. EIN GELBER VW NAEIIERT SICIt DEM GROSSEN FUSSGAENGER AUS RICIITUNG tIALI , ERPI~ATZ. ER FAEHRT AUF I ) ER SCHLUETERSTRASSE. A yellow VW approaches the tall pedestrian from the direction of flallerplace. It drives on 3chlueterstreet. EIN ANI ) ERER GELBER VW FAEHRT VON DER AUPEN POST VOR DIE AMPEL. WAEtIRENDDESSEN ENTFFRNT ER S1Ctl VON DEM GIdLBEN VW , DER SICIt I ) EM GROSSEN FUSSGAENGER GENAEHERT HAT. Another yellow VW drives fi'om the old post office to the tralllc light. \ [ n the meantime it recedes from the yellow VW which approached the tall pedestrian. \ [ ! ; IN SCHWARZER BMW FAEllRT IN R1CHTUNG IIALLERPI , ATZ. I ) ABEI UEBEtHIOLT ER DEN ANDEREN CELBEN VW , DF , R SICII VON 1 ) EM CELP , I~N VW ENTFERNT flAT , VOR DFM FACIIBFI-H~ , ICtt INI , 'OllMA'I'IK. DER SCHWARZE BMW ENTI , 'ERNT SICIt VON DEM GI ! H , BI~ ; N VW , DEI { NICIIT UEBERIIOILT WORI ) F , N IST. A black BMW drives in direction of Ifallerphtce. Dewing this time it overtakes the other VW which receded fronl the yellow VW , is ti'oet of the department of computer science. Tile black BMW recedes fl'om the yellow VW which was not ow~rtaken. I ) EI { GROSSE FUSS ( .~AEN ( \ ] Ie , R ( IEIIT IN R1.CIITUNG I ) AMMTOR AUF I ) I , ,M SUEI ) LICHI,2N I , 'USSWEG WESTLICH DER SCIILUI'~TIt ' , I { STRASSE. WAIi ; III { ENDI ) FSSI , ; N ENTFERNT El1. SICH VON I ) FM FACIIBh'J~.E\ [ Clt INFORMATIK. `` /'lie tall pedestrian walks in direction of Dammtor on the southern sidewalk west of Schlueterstreet. \ [ n the meantime he recedes from the department of computer science. 11. , logout The consequences of this first option are rather complex syntactic structures whieh are not inotivated by higher level stylisl.ic choices. 1 , el us now look at a second opt , ion which has also been implemented. Experience with the above algorithm for dill % rent scenes showed , that if more than two similar objects are in a scene the restrictive relative clauses become hardly mlderstandable. We ~ , hus determine how many similar objects there are in the scene before we start the generation process. If there are more than two , REF generates names for them and introduces them as e.g. the first yellow VW , the second yellow VW and so on and uses these phrases in subsequent references. An example of this strategy would look like the first example text where the different vehicles are nanmd l , he first ... , the second ... . Tbe rest of the text would remain the same. Taking this option implies leaving McDonald 's scheme and approaching to a planning paradigm. It should be noted here that there is a third optimt which has hardly been investigated , namely to switch frmn contextual to cotextual reference as in phrases like the VW I mentioned last. We need filrther research hefore we can use such techniques effectively. We have proposed the scheme of anticipated visualization to generate coherent texts describing reaL-wnrld events ( visual data ) . The selection algorithms are based on low-level , verbinherent pro.perties , and on a pragmatically motivated verb hierarchy. 'lk~gether with t , he verbalization component the NAOS system is now fully operational from event , recognition to text generation in the domain of trafl'ie scenes. As this domain is rich enough to still pose a 1ol ; of problems I , his opens up l , he ol ) portunity t , o inl ; egral ; e higher level sl , rabelJies for e.g. combining sentences , selecting evengs , generating deie~ie expressions , el ; e. The main difference between NAOS and other systems for language generation is that , we approach the verbalization problem from the visual side. and thus are led to use basic selection algoril ; hms. Other systems like TAI , ESI'iN \ [ 151 , KI ) S \ [ 12J , TEXT \ [ 1 , t , KAMI ' \ [ l\ ] , and I1AM-ANS \ [ 1 ( ) } start their proeessi , g wibh language whereas NAOS starts with images. In close emmection to our resea , &lt; , is U , e wo , 'k , ,f \ [ 21 , 1~,4 } , 1231 , \ [ ? ? , \ ] , ~ , . , ,d \ [ , % 'rhe fi , .st iV ) u , . authors deal wilJl questions of moqon recognition and with a re-. ferellcc senlant , ic for irlOt ; iOrl verbs } ) Lit ~Ll'e IIot. CoLleerlled wit } l i , exL general~ion. They showed that case frames can Iw used to generate single utl , erancem Conklin and Ivh : l ) onald use the notion of salience to deal wil , h ghe seleel , ion problem in the task of describing a single image of a nal ) ural oul , door scene. TALESPIN exemplifies ~ha~ ; plans and goals of an actor may form the underlying sl , rueture of narratives and may I ; hus be motivation for l ; ext generation , hi KI ) S a represental , ion of wha~ to do in ea~ ( . , of fire alarm is transformed into a natural language. text. As the initial representa1 , ion already contains lexieal eni , ries and primitive l ) roposilfions the task is to organize tJds information anew so that i~ may be expressed ill an English text. Matll/ and Moore prol ) ose rules for ( : oml ) ining l ) ropositiolm and re , .ediL the text eonl , inuously to produce l , he final version. TEXT gem.'rate~ ; pars. gr~tplls as aiiswel 's ~o qtlestiolls a\ [ ) ollt da\ [ , abase Stl'llCtl/Fe. \ [ ~e/cl ( ef ) wI1 } las idenl ; ified discourse stra ( .e , gie , ~ for fulfilling three ( ; ( mmmlaie~fl.ive goals : detine , compare , aud describe. These sl , rategi ( ~s g , dde , the t , ; eaeration l ) ro ( : e. &lt; ls ill deciding what ; to say \ ] lext. Me } ( , eowlI Ilses 1 , he qucsl ; ion to deteemine tile eommunh : al.ive goal that the text should fldfil. Research of IJfis kind is very important to clarify ~he relation between l , he \ [ orln of ( -z text and il ; s underlying goals. ( ) ue of I ; he domains of IIAM..ANS is the Mad of I ; raflic scene which is also used in NAOS. /n this domain I|AM-ANS deals with primarily with answering questions about ~he tool , iota ; o\ [ ol @ ~cts and wi~h overanswering yes/no que , % ions \ [ 25 I. The dialogue ( : orei ) onent , of IIAM-ANS may be commcted to NA ( ) ~g I ; o also allow quest , ions of the user if ' t } m generated text was not sM\ [ ieienl fi ) r his underst ; anding. An evalual ; ion of the kind of question being asked by a user may help in devising bel , ter generation strategies. | ( AMP is a , system tbr plamfing natural languago ubteranees ia the domain of task oriented dialogues. The 1 ) lantfinlg altorithm i ; akes 1 ; he knowledge and I ) elief'a of the hearer into account , . '\ [ 'his sy.stem shows |low a priori beliefs of 1 ; he hearer may a\ ] L ; o be integrated in NAOS to generat ; e appropria/ ; e referring phrases. It would be interesting to use a phrasing componen~ for NAOS which would firs/ , determine all deep eases uecessary ~o maximally restrict \ [ , he visualized t , ra.jeet ; ory of an objeet 's mot , ion sequence and then try to distribute I ; he cases to the di\ [ ferent verbs u.sed in the descripl ; ion in order to general ; e smooth text. \ [ 1\ ] Appelt , \ ] ) .E. , iPlamfi*Jtg Nat m'al-Lal : G'tmge Utt ; era : nee~ : to ~hd ; i.~ ; fy M'ulLiple Goah~. SRI lntecn , xtlonal , Technical Note 259 , Menlo Park , CA. , 1982 { 2 } Bad\ ] or , N.I. , '.l_~m~po : ral .~.Ice , te Analysis : ( \ ] oxtceptnal \ ] i ) e. , : ( : ril ) tioL~ of Object Movemenl : m l { eport TR-.80 , l ) ept , of CS , University of Toronto , 1975 13\ ] Barwise , .I. , Perry , J. , ~il ; L~atio~s and Attibnde. &lt; ; . Bradford Books , MIT Press , 1983 14\ ] Busemann , S. , ~qurlhc.e Transli ) rmations dm'ing the Generation of Written German Senteneea. hc llolc , L. ted. ) , Natural l , anguage Generation Systems. Springer , Berlin , 1984 \ [ 51 Conldin , E.J. , McDomdd~ \ ] ) .D. , , qallenee : The. Key t ; o the Seleeti ( m Prol ) lem in Nat : m'al Lanl , mage Generation. COI , ING-82 , 129-135 16\ ] Davey , A. , l ) iaeour~e Produel ; i , m. A Computer Model of gome Aspeel : ~ of a Spealter. Edinburt ; h Uniwn'siW Press , 1978 \ [ 71 Filhnm'e , C. , \ ] . , , qeenes-and.-fl'ames gemantle , . , ILL : Zampolli , A. ( ed. ) , fAngui.stie Structures Processing. NoLth-llolland , Amsterdam , 1977 , 55-81 \ [ 8\ ] Goldman , N.M. , Coneeplaml ( -'eneration. In : Scha.lq It.C , ( ed. ) , Concept.al hffolmation Processhlg , Noi~h.I\ ] olland , 1973 , 289~371 191 yon llahn , W. , Hoeppner , W. , , lame.son , A. , Wahlster , % i. , '.Fhe AnaLomy of the Natural Langm~ge rtlialogue b ; ysl : em J ( \ ] AM~LPIVi. In : Bole , i , ( eLl. ) , Natm'al \ ] , anig , .age \ ] lased ( 1omimter .Systems. Ilanser/McMillan , Miinchen , 1980 , 11 ! ) .253 \ [ 101 l\ [ oeppner , W. , ( 'hristalhw , T. , Marburger , II. , Morik , K. , Nobel , \ [ I , O'Leary , M. , WahMmr , W. , lhWmld } .k , nah ; o.~ndependcnee : Experlenee with the Develolmuml ; of a ( -\ ] eriL|a\ ] l ) # ~lglla~2 A¢ : ee ! i\ [ i , ~iysl ; em to t { } ( ighly Diverse } gaekgrmmd gy.'nh.'r , .q , lJCAI..83,588..594 Ill\ ] Jamesoa , A. , WMdster , W. , /lser Modelli~lg in/~nlflmra General ; itnl : lglliptdtl a~td l ) ei~nlte ) ) oserip ( .ia~. ECAI-82:222-227 \ [ 12\ ] Mami , W.C. , Moore , J. , ConLlmter GeneratiwL of Mnli ; iparngraph ~'exl ; . AJC } , 711 ) , 1981 , 1 % 29 ( J3 / McDonald , I ) .l ) . , Nat ; m'al L.'nLgnage ( ~eneraLJon as a Comprd.a| : ional ) ~rol ) ! enl : a~l ~'n| ; lod'netion. in : lh'ady , M. , Bmwick , H.C. ( eds. ) , ComputaiAonal Models of Discourse. M\ ] T Press , Cambridl ; e , Ms : Is. , 1983 , ? ,09-.265 114\ ] McI ( eown , \ [ CII. , } ) iL ; eom'~m ~. ; I ; ratxwje~ for ( -~eneral ; i , .~ ; N : qmraliLaxiff , mlge Text. Artificial hd.elligenee 27 , 1985 , 1- , tl 115\ ] Meehan , J. , 'YA.LIn ... qPIN. h &lt; Schank , I { .C. , lli , ,d : ,eck , C.K. ( e &amp; ; . ) , hmicte Conllmter l.Indel-st~Lnding : Vive PioF , rarlu~ plus Miniat.ures. I , EA , llillsdMe , New Jersey , 198i , i97-258 \ [ 161 Nemmmn , ll. , Natural l , angm~ge Descrii ) l ; im~ of 'Yi : ~bm.SVaryi : ,~g ~3ee : nea. ln : Walt , z , l ) . ted. ) , Advances in Natm 'M I , :mge.age l'rocesses. Vohlme 1 ( in press ) ; also as I , 'II\ [ -\ [ Ilt..\ ] L.105/8 , t , l/'achbereich hlformat , ik , Unlversitlit tlamburg , 1984 117 } Neumann , ll. , On Natm'al Language Aecem ; to \ ] ( mage 5h &gt; quencet ; : Ewml ; \ ] Reeognition a~d Verbalization .</sentence>
				<definiendum id="0">Nat ; m'al L.'nLgnage</definiendum>
				<definiens id="0">the verb stem of iiberholen as needed by the generation component and second the formal notation for an instantiation. The obligatory cases must be generated but may be omitted in the surface string in case of elliptic utterances whereas optional deep cases need not be generated at all. In the combinations slot it is represented which deep cases may be generated together ( e.g. for the verb fahren ( drive ) it is not allowed to generate a single SOURCE but instead SOURCE and GOAL must be generated ) . The Lot-preps slot specifies the prepositions which may be used with the verb iiberholen to generate locative expressions. The case descriptions in the obligatory and optional slots consist of two parts : a declaration of an identifier for the case expression on the language side , and a predicate ( in general a list of predicates ) relating the case expression to the scene data. The most important predicates are REF , TIME-REF , and LOC-REF. REF generates referring phrases for internal object descriptors like BMW1. TIME-REF generates the tense of the verb. As descriptions are usually given in present tense , presently TIME-REF only generates this tensc. LOC-REF relates the abstract location of the object as given by its coordinates to a natural language expression for a reference object. Note , that REF has to be used to generate a referring phrase for the reference object. Consider the sixth entry of the database in section 2. The instantiation only contains internal identifiers for objects , like traflic-lightl , for which referring phrases have to be generated ( see section 4 for further details on REF ) . In NAOS we use a specialization hierarchy for motion verbs. This hierarchy is pragmatically motivated and is rooted in situational semantics. It is no hierarchy of motion concepts as the one proposed in \ [ 23\ ] . It connects general verbs witb more special ones. A situation which may be described using a special verb implies the application of all more general verbs Take for instance the verb iiberholen ( overtake ) . \ [ t implies the use of the more general verbs vorueberfahren~ vorl ) nifahren ( drive past ) , passieren ( pass ) , naehern-r ( approach ) , entfernen-r ( recede ) , fahren ( drive , move ) , and bewegen-r ( move ) . It shonld be intuitively plausible that such a hierarchy is also used for event recognition. If , for instance , no naehern-r ( approach ) can be instantiated the more special events need not be tested. In NAOS the overall strategy for generating a descriptive text is as follows : * Group all moving objects according to their classmembership ; • For each object in each group describe the motions of the object for the time interval during which it was visible in the scene , Event selection for an object is done according to the following algorithm : and where the object was the agent ; most special event of the above collected ones ; one which started earlier and has the same or longer duration as the other one or take the one with longer duration ; in temporally consecutive order. Consider the following example. All events which were found for PERSON1 are : 572 ( RECEDE PERSON1 FBI 20 40 ) ( ENTFERNEN-R PERSDI\ ] I FDI 20 40 ) ( } /ALK PERSONI 0 40 ) ( OEHEI~ PERSONI 0 40 ) ( MOVE PERSONI O 40 ) ( BE~//EGEN-R PERSOIll 0 40 ) The above algorithm leads by use of the specialization hierarchy to the following verbalization list for PERSON1 : ( ( ( ~IALK PERSOI~I 0 40 ) ( 0 20 ) ) ( ( RECEDE PERSON1 FBI 20 40 ) ( 20 40 ) ) ) ( The last entry in parenthesis of each selected event denotes the interval in which the event was the most special one. ) This selection process is our first implementation of the strategy of anticipated visualization. The underlying question is : Which optional deep cases should be selected to restrict the hearer 's possibilities of placing the trajectory of an object in his internal model of the static background of the scene ? In NAOS the selection algorithm answering the above question is rather straightforward. It is based on the manner of action of the verb , the verbtype , and the heater 's knowledge. The algorithm is graphically represented in figure 2. EVENTTYPE NON-DURATIVE , INCHOATIVE DURATIVE Tl , ,o = EB A T , , , a = SE Tb , ~ = SB ^ T , , , d ¢~ SE T~ , ~ ~S B A T , ,d = S E VERBTYPE DIR LOC RED DIR , LOC RED RED DIR , STAT LOC STAT DIR , REO LOC STAT DIR LOC RED DEEP CASES LOCATIVE ? DIRECTION ? , LOCATIVE ? DIRECTION ? LOCATIVE ? NIL NIL LOCATIVE ? DIRECTION ? , LOCATIVE ? LOCATIVE ? NIL DIRECTION ? LOCATIVE ? LOCATIVE ? SOURCE ? , DIRECTION ? NIL RED NIL T~ , ~ ~ 8B ^ T , ,a ~ SE DIR , STAT LOCATIVE ? LOC SOURCE ? , GOAL7 Figure 2 : Selection of Deep Cases The abbreviations denote : Tb~ , Ten , t : start , end time of the event ; SB , SE : scene begin and scene end ; I ) IR , LOC , STAT , RED : directional ( turn off , return ) , locomotion ( walk , overtake ) , and static ( stand , wait ) verbs , finally verbs whose recognition implies reference objects ( reach s. th. , arrive at ) . The figure has to be read as follows. If an inchoative event like losfahren ( start moving ) has to be verbalized which has the verbtype locomotion , then choose direction ? and locative ? as deep cases. The question mark generally means , look into the partnermodel Lo see whether this deep case has already been generated fi ) r another event. If so , determine by use of the object 's actual location ( represnnted in the scene representation ) whether it is still valid. If this is the case do n't generate a uatural language expression for this deep case , otherwise do. Presently the partnermodel contains information about the static background of the scene and about what has been said so far in the same relational notation as was shown for instantiations in section 2. It is being updated when an event is verbalized. Note , that for durative events the decision is based on whether the start and end time of the event coincide with the beginning or ending of the image sequence. Consider the first case for durative events as given in figure 2. Right from the beginning of the sequence there is a car moving along a street until the sequence ends. In such a case it is not possible to verbalize a source as the object may have started its motion anywhere. To restrict the hearer 's visualization , direction and locative cases are verbalized , leading to a sentence like : The car moves on Schliiterstreet in direction of HaHerplace. Verbalizing a direction when the static background is known restricts the trajectory to being on one side of the road. Basically , our direction case is a goal or source ease where only two prepositional phrases are allowed , the German phrases in Richtung and aus Richtung ( in direction~ from direction ) . These phrases do not imply that the motion ends at the goal location as do most prepositional phrases in German which have to be in accusative surface case to denote a goal. The English language is in this respect inherently ambiguous. In the sentence The car moves behind the truck , the phrase behind the truck may denote a locative or goal deep case. In German these eases arc distinguished at the surface. \ [ `` or locative the above sentence translates to Des Aitto f~hrt hinter dem LKW , for the goal case , it translates to Des Auto f~hrt hinter den LKW. We have to distinguish different verbtypes as e.g. the meaning of a directional phrase changes with the verl ) type. Consider the sentences The car moves in direction of Hallerplace versus The car stands in direction of l\ [ allerplace ( in German both sentences arc well formed ) . The first sentence denotes the direction of the motion whereas the second one denotes the orientation of I , hc car. We thns distinguish between static ( STAT ) and h ) eomotion ( LOC ) verbs. The third verbtype , directional ( I ) IR ) , is used for verbs with a strong directional component like umkehren ( return ) , abbiegen ( turn off ) , etc. As they already imply a certain direction the additional verbalization of a direction using a prepositional phrase does usually not lead to acceptable sentences. The fourth type ( REO ) is used tbr verbs like erreichen ( reach s. th. ) having an obligatory locative case. The main result to note here is that the selection processes are low-level and verboriented. The only higher level goal is to inform the hearer and to convey as ranch information about an event as possible. In the next section we show by differem ; verbalizations of the same scene how rather complex syntactic structures arise. The general scheme for the generation process is as follows : first , then persons ; time of occurrence in the scene , earliest first ; ( a ) if the current event has a precedent and its event time is included in the precedent 's , begin the sentence with dabei ( in the meantime ) ; go to ( c ) ; ( b ) if the current event has a precedent and its event time overlaps the precedent 's , begin the sentence with unterdessen ( approx , in the meantime ) ; go to ( c ) ; ( c ) determine the optional deep cases and build a simple declarative sentence by using all chosen deep cases and applying the deep case semantics. Two temporally consecutive events are not verbalized using a temporal adverb as in the cases of inclusion and overlapping. This is due to the fact that from the linear order of the sentences the hearer usually infers consecutivity. The result of the above algorithm is a formal representation of the surface sentence which , rougidy , contains the w~rb 's stem , gemls verbi , modality , and person , all deep cases in random order , and all stems of the \ [ exical entries which appear in the surface sentence. This representation is taken as input by the system SUTRA ( for further details on the formal represeutation and the SUTRA system see \ [ 41 ) which then generates a correctly inflected German sentence. Below is an example of the output of NAOS. 18. , ausgabe text DIE SZENE EN'rHAELT VIER BEWEGTE OBJEKTE : DREI PKWS UND EINEN FUSSGAENGER. The scene consists of four moving objects : three vehicles and a pedestrian. EIN GRUENER VW NAEHERT SICtt DEM GROSSEN FUSSGAENGER AUS RICHTUNG tIALLERPLATZ. ER FAEIIRT AUF DER SCHLUETERSTRASSE. A green VW approaches the tall pedestrian from the direction of flalterplaee. It drives on Schlseterstreet. EIN GELBER VW FAEHRT VON DER ALTEN POST VOR DIE AMPEL. WAEHREN1 ) I ) ESSEN ENTFERNT ER SICH VON DEM GRUENEN VW. A yellow VW drives from the old postoftice to the tra~c light , h~ the meantime it recedes from the green VW. EIN SCHWARZER BMW FAEHRT IN RICHTUNG ttALLERPLATZ. DABEI UEBERIIOLT ER DEN GELBEN VW VOR DEM I '' ACIIBERI , \ ] ICI\ [ I INFORMATIK , DER SCltWARZE BMW ENTFERNT S1CI1 VON I ) EM GRUENEN VW. A black BMWdrives in the direction of Hallerpiace , During this time it overtakes the yellow VW in front of the department of computer science. The black BMW recedes from the green VW. DER GROSSE FUSSGAENGER GEHT IN RICHTUNG DAMMTOR AUF I ) EM SUEDLICIIEN FUSSWEG WESTLICH DER SCHLUETERSTRASSE. WAEHRFNDDESSEN ENTFERNT ER SICH VON DEM FACIIBEREICH INFORMATIK. The tall pedestrian walks hJ the direction of Dammtnr on the southern sidewalk west of Sehlseterstreet. h~ the meantime he recedes from the department of compnter science. 19. , logout The first sentence above is a standard one having the same structure for all different scenes. The remaining four paragraphs are motion descriptions for the tbur moving objects. We now discuss step ( c ) of the above algorithm in more detail as it covers some interesting phenomena. Consider the third paragraph describing the motions of the yellow VW. The verbalization list for this object is : ( ( ( DRIVE VW1 10 20 ) ( 10 25 ) ) ( ( RECEDE VW1 ~2 25 32 ) ( 25 32 ) ) ) The beginning ( SB ) and ending of the sequence ( SE ) lie at points 0 and 40 , respectively. According to the selection algorithm ( figure 3 ) a SOURCE should be verbalized for a durative event with the above event time if the verbtype is LOC. The generation algorithm checks whether the chosen optional cases are allowed for the verb , if so , it is further checked whether the combinations are allowed. As a SOURCE may not be generated alone for a fahren ( drive , move ) event , SOURCE and GOAL are generated. The fourth paragraph shows the outcome of a deep case selection in which the chosen case is not allowed for the verb. The verbalization llst for the black BMW contains only ilberholen ( overtake ) and entfernen-r ( recede ) . ( ( ( OVERTAKE BMWI VWI ( 10 12 ) ( 12 32 ) ( 10 32 ) ) ( ( RECEDE Bl~qt ~/2 20 40 ) ( 32 40 ) ) ) According to eventand verhtype DIRECTION is chosen as the appropriate deep case. As this case may not be used with the verb overtake two sentences are generated , one describing the direction 573 of the motion and the other one describing tbe specific event. The second sentence begins with a temporal advert ) specifying that both motions occur at the same time. In order to generate the two sentences first the classmembership of the agent of the verb which may not take the chosen deep case is determined. Then the speeializationhierarehy is used to go up to either fahren ( driv % move ) or gnhen ( walk ) as those verbs may take any deep case. Then the sentences are generated. Consider the following verbalization list : ( ( ( OVERTAKE BI~WI VW1 ( 0 8 ) ( 12 18 ) ( 0 18 ) ) ( ( DRIVE BI'~I 0 40 ) ( 18 40 ) ) ) Assuming the direction and location of the motion to be the same as before the algorithm presented so fat '' would generate A black BMW drives in the direction of Hallerplace. During this time it overtakes the yellow VW in front of the department of computer science. The black BMW drives. According to the deep ease selection algorithm a DIRECTION and LOCATIVE should be generated for the second event above. As both cases have already been generated with the first event and are still valid the sentence The black BMW drives is not generated because before generating a sentence it is checked whether the intbrmation is already known to the partner. In this section some aspects of the referring phrase generator are discussed. As can be seen from the example text objects are characterized by their properties , introdueed with indefinite noun phrases when they are not single representatives of a class and they may also be pronominalized to add to the coherence of the text. Therefore we use standard techniques as e.g. described in \ [ 8\ ] , \ [ 9\ ] . We want to stress one aspect of our referring phrase generator , namely its capability to generate restrictive relative clauses with motion verbs. As it may be easily the ease that a scene contains two objects with similar properties the task arises to distinguish them and generate unequivocal referring expressions. It is an interesting fact , that , we have several options to cope with this problem which each have their consequences. One option is to adopt McDonald 's scheme of generation without precisely knowing what to say next \ [ 13\ ] . According to this scheme two similar objects are characterized in the following way in NAOS. When the first one is introduced it is characterized by it 's properties e.g. a yellow VW. When the second one has to be introduced , REF notices that a yellow VW is already known to the partner and generates the phrase another yellow VW. It starts getting interesting in subsequent reference. The objects are then characterized by the events in which they were involved earlier whether as agent or in another role. This leads to referring phrases like the yellow VW , which receded from the pedestrian or the yellow VW , which has been overtaken. Note , how passive relative clauses arise naturally from the task of generating referring phrases in this paradigm. The same is also true for negation. Consider the case where the first yellow VW , say VWI , has passed an object and the second yellow VW , say VW2 , has overtaken an object and both event , s are already known to the partner. If REF has to generate again a referring phrase for VWI it notices that pass is a more general verb than overtake and may thus also be applied for the overtake event. It therefore generates the phrase the yellow VW , which has not overtaken the other object to distinguish it unequivocally from VW2 , Below is an example of this strategy in a texL for the same scene as above. The difference to the th'st scene is that we replaced the green VW by a yellow one. 10. , ausgabe text ; 574 DIE SZENE ENTItAI'~LT VIER BEWIdGTE OBJEKTE : I ) RE1 PKWS UND EINEN FUSS ( ~AENGER. The scene consists of four moving objects : three vehicles and a pede.. s~rian. EIN GELBER VW NAEIIERT SICIt DEM GROSSEN FUSSGAENGER AUS RICIITUNG tIALI , ERPI~ATZ. ER FAEHRT AUF I ) ER SCHLUETERSTRASSE. A yellow VW approaches the tall pedestrian from the direction of flallerplace. It drives on 3chlueterstreet. EIN ANI ) ERER GELBER VW FAEHRT VON DER AUPEN POST VOR DIE AMPEL. WAEtIRENDDESSEN ENTFFRNT ER S1Ctl VON DEM GIdLBEN VW , DER SICIt I ) EM GROSSEN FUSSGAENGER GENAEHERT HAT. Another yellow VW drives fi'om the old post office to the tralllc light. \ [ n the meantime it recedes from the yellow VW which approached the tall pedestrian. \ [ ! ; IN SCHWARZER BMW FAEllRT IN R1CHTUNG IIALLERPI , ATZ. I ) ABEI UEBEtHIOLT ER DEN ANDEREN CELBEN VW , DF , R SICII VON 1 ) EM CELP , I~N VW ENTFERNT flAT , VOR DFM FACIIBFI-H~ , ICtt INI , 'OllMA'I'IK. DER SCHWARZE BMW ENTI , 'ERNT SICIt VON DEM GI ! H , BI~ ; N VW , DEI { NICIIT UEBERIIOILT WORI ) F , N IST. A black BMW drives in direction of Ifallerphtce. Dewing this time it overtakes the other VW which receded fronl the yellow VW , is ti'oet of the department of computer science. Tile black BMW recedes fl'om the yellow VW which was not ow~rtaken. I ) EI { GROSSE FUSS ( .~AEN ( \ ] Ie , R ( IEIIT IN R1.CIITUNG I ) AMMTOR AUF I ) I , ,M SUEI ) LICHI,2N I , 'USSWEG WESTLICH DER SCIILUI'~TIt ' , I { STRASSE. WAIi ; III { ENDI ) FSSI , ; N ENTFERNT El1. SICH VON I ) FM FACIIBh'J~.E\ [ Clt INFORMATIK. `` /'lie tall pedestrian walks in direction of Dammtor on the southern sidewalk west of Schlueterstreet. \ [ n the meantime he recedes from the department of computer science. 11. , logout The consequences of this first option are rather complex syntactic structures whieh are not inotivated by higher level stylisl.ic choices. 1 , el us now look at a second opt , ion which has also been implemented. Experience with the above algorithm for dill % rent scenes showed , that if more than two similar objects are in a scene the restrictive relative clauses become hardly mlderstandable. We ~ , hus determine how many similar objects there are in the scene before we start the generation process. If there are more than two , REF generates names for them and introduces them as e.g. the first yellow VW , the second yellow VW and so on and uses these phrases in subsequent references. An example of this strategy would look like the first example text where the different vehicles are nanmd l , he first ... , the second ... . Tbe rest of the text would remain the same. Taking this option implies leaving McDonald 's scheme and approaching to a planning paradigm. It should be noted here that there is a third optimt which has hardly been investigated , namely to switch frmn contextual to cotextual reference as in phrases like the VW I mentioned last. We need filrther research hefore we can use such techniques effectively. We have proposed the scheme of anticipated visualization to generate coherent texts describing reaL-wnrld events ( visual data ) . The selection algorithms are based on low-level , verbinherent pro.perties , and on a pragmatically motivated verb hierarchy. 'lk~gether with t , he verbalization component the NAOS system is now fully operational from event , recognition to text generation in the domain of trafl'ie scenes. As this domain is rich enough to still pose a 1ol ; of problems I , his opens up l , he ol ) portunity t , o inl ; egral ; e higher level sl , rabelJies for e.g. combining sentences , selecting evengs , generating deie~ie expressions , el ; e. The main difference between NAOS and other systems for language generation is that , we approach the verbalization problem from the visual side. and thus are led to use basic selection algoril ; hms. Other systems like TAI , ESI'iN \ [ 151 , KI ) S \ [ 12J , TEXT \ [ 1 , t , KAMI ' \ [ l\ ] , and I1AM-ANS \ [ 1 ( ) } start their proeessi , g wibh language whereas NAOS starts with images. In close emmection to our resea , &lt; , is U , e wo , 'k , ,f \ [ 21 , 1~,4 } , 1231 , \ [ ? ? , \ ] , ~ , . , ,d \ [ , % 'rhe fi , .st iV ) u , . authors deal wilJl questions of moqon recognition and with a re-. ferellcc senlant , ic for irlOt ; iOrl verbs } ) Lit ~Ll'e IIot. CoLleerlled wit } l i , exL general~ion. They showed that case frames can Iw used to generate single utl , erancem Conklin and Ivh : l ) onald use the notion of salience to deal wil , h ghe seleel , ion problem in the task of describing a single image of a nal ) ural oul , door scene. TALESPIN exemplifies ~ha~ ; plans and goals of an actor may form the underlying sl , rueture of narratives and may I ; hus be motivation for l ; ext generation , hi KI ) S a represental , ion of wha~ to do in ea~ ( . , of fire alarm is transformed into a natural language. text. As the initial representa1 , ion already contains lexieal eni , ries and primitive l ) roposilfions the task is to organize tJds information anew so that i~ may be expressed ill an English text. Matll/ and Moore prol ) ose rules for ( : oml ) ining l ) ropositiolm and re , .ediL the text eonl , inuously to produce l , he final version. TEXT gem.'rate~ ; pars. gr~tplls as aiiswel 's ~o qtlestiolls a\ [ ) ollt da\ [ , abase Stl'llCtl/Fe. \ [ ~e/cl ( ef ) wI1 } las idenl ; ified discourse stra ( .e , gie , ~ for fulfilling three ( ; ( mmmlaie~fl.ive goals : detine , compare , aud describe. These sl , rategi ( ~s g , dde , the t , ; eaeration l ) ro ( : e. &lt; ls ill deciding what ; to say \ ] lext. Me } ( , eowlI Ilses 1 , he qucsl ; ion to deteemine tile eommunh : al.ive goal that the text should fldfil. Research of IJfis kind is very important to clarify ~he relation between l , he \ [ orln of ( -z text and il ; s underlying goals. ( ) ue of I ; he domains of IIAM..ANS is the Mad of I ; raflic scene which is also used in NAOS. /n this domain I|AM-ANS deals with primarily with answering questions about ~he tool , iota ; o\ [ ol @ ~cts and wi~h overanswering yes/no que , % ions \ [ 25 I. The dialogue ( : orei ) onent , of IIAM-ANS may be commcted to NA ( ) ~g I ; o also allow quest , ions of the user if ' t } m generated text was not sM\ [ ieienl fi ) r his underst ; anding. An evalual ; ion of the kind of question being asked by a user may help in devising bel , ter generation strategies. | ( AMP is a , system tbr plamfing natural languago ubteranees ia the domain of task oriented dialogues. The 1 ) lantfinlg altorithm i ; akes 1 ; he knowledge and I ) elief'a of the hearer into account , . '\ [ 'his sy.stem shows |low a priori beliefs of 1 ; he hearer may a\ ] L ; o be integrated in NAOS to generat ; e appropria/ ; e referring phrases. It would be interesting to use a phrasing componen~ for NAOS which would firs/ , determine all deep eases uecessary ~o maximally restrict \ [ , he visualized t , ra.jeet ; ory of an objeet 's mot , ion sequence and then try to distribute I ; he cases to the di\ [ ferent verbs u.sed in the descripl ; ion in order to general ; e smooth text. \ [ 1\ ] Appelt , \ ] ) .E. , iPlamfi*Jtg Nat m'al-Lal : G'tmge Utt ; era : nee~ : to ~hd ; i.~ ; fy M'ulLiple Goah~. SRI lntecn , xtlonal , Technical Note 259 , Menlo Park , CA. , 1982 { 2 } Bad\ ] or , N.I. , '.l_~m~po : ral .~.Ice , te Analysis : ( \ ] oxtceptnal \ ] i ) e. , : ( : ril ) tioL~ of Object Movemenl : m l { eport TR-.80 , l ) ept , of CS , University of Toronto , 1975 13\ ] Barwise , .I. , Perry , J. , ~il ; L~atio~s and Attibnde. &lt; ; . Bradford Books , MIT Press , 1983 14\ ] Busemann , S. , ~qurlhc.e Transli ) rmations dm'ing the Generation of Written German Senteneea. hc llolc , L. ted. ) , Natural l , anguage Generation Systems. Springer , Berlin , 1984 \ [ 51 Conldin , E.J. , McDomdd~ \ ] ) .D. , , qallenee : The. Key t ; o the Seleeti ( m Prol ) lem in Nat : m'al Lanl , mage Generation. COI , ING-82 , 129-135 16\ ] Davey , A. , l ) iaeour~e Produel ; i , m. A Computer Model of gome Aspeel : ~ of a Spealter. Edinburt ; h Uniwn'siW Press , 1978 \ [ 71 Filhnm'e , C. , \ ] . , , qeenes-and.-fl'ames gemantle , . , ILL : Zampolli , A. ( ed. ) , fAngui.stie Structures Processing. NoLth-llolland , Amsterdam , 1977 , 55-81 \ [ 8\ ] Goldman , N.M. , Coneeplaml ( -'eneration. In : Scha.lq It.C , ( ed. ) , Concept.al hffolmation Processhlg , Noi~h.I\ ] olland , 1973 , 289~371 191 yon llahn , W. , Hoeppner , W. , , lame.son , A. , Wahlster , % i. , '.Fhe AnaLomy of the Natural Langm~ge rtlialogue b ; ysl : em J ( \ ] AM~LPIVi. In : Bole , i , ( eLl. ) , Natm'al \ ] , anig , .age \ ] lased ( 1omimter .Systems. Ilanser/McMillan , Miinchen , 1980 , 11 ! ) .253 \ [ 101 l\ [ oeppner , W. , ( 'hristalhw , T. , Marburger , II. , Morik , K. , Nobel , \ [ I , O'Leary , M. , WahMmr , W. , lhWmld } .k , nah ; o.~ndependcnee : Experlenee with the Develolmuml ; of a ( -\ ] eriL|a\ ] l ) # ~lglla~2 A¢ : ee ! i\ [ i , ~iysl ; em to t { } ( ighly Diverse } gaekgrmmd gy.'nh.'r , .q , lJCAI..83,588..594 Ill\ ] Jamesoa , A. , WMdster , W. , /lser Modelli~lg in/~nlflmra General ; itnl : lglliptdtl a~td l ) ei~nlte ) ) oserip ( .ia~. ECAI-82:222-227 \ [ 12\ ] Mami , W.C. , Moore , J. , ConLlmter GeneratiwL of Mnli ; iparngraph ~'exl ; . AJC } , 711 ) , 1981 , 1 % 29 ( J3 / McDonald , I ) .l ) . ,</definiens>
			</definition>
</paper>

		<paper id="1106">
			<definition id="0">
				<sentence>In other words , w i + /T ( ~i ) where ~i is a word and /T is a conversion system .</sentence>
				<definiendum id="0">~i</definiendum>
				<definiendum id="1">/T</definiendum>
				<definiens id="0">a conversion system</definiens>
			</definition>
			<definition id="1">
				<sentence>This may be expressed as follows : ~i I Pi I ' Pi2 'Pi~ ' ... .. ' Pin ÷ /T ( ~i I Pil 'Pi2 ... ... .. Pin ) =yj where ~i is a word ; and Pil ' Pi2 ' ... .. ' Pin are the limitations of ~i '' The set of Pil ' Pi2 ~ ... .. ' Pin should be low in number and simple .</sentence>
				<definiendum id="0">~i</definiendum>
				<definiendum id="1">Pil</definiendum>
				<definiens id="0">a word ; and</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>~AL , JAPAN , SYSTRAN , SUSY ) l~ns resulted in the necessity of an elaboration of the proposal for semantic features made in EIB-3 ( EUROTRA LINGUI~YfC SPECIFICATIONS ) .</sentence>
				<definiendum id="0">SUSY ) l~ns</definiendum>
			</definition>
			<definition id="1">
				<sentence>Now , both `` PERFECIXV~ ; '' and `` ~ '' can take the subcategory `` CAUSATIVE '' whereas the other subcatogoties of both aspects branch into disjunct feature sets , the refinement being defined by the `` is '' relationship and by the iltheritance of attributes .</sentence>
				<definiendum id="0">CAUSATIVE</definiendum>
			</definition>
</paper>

		<paper id="1095">
</paper>

		<paper id="1131">
			<definition id="0">
				<sentence>The IKBS is an instantiation of case or concept schemata denoted by semantic symbols as nodes in the semantic network .</sentence>
				<definiendum id="0">IKBS</definiendum>
				<definiens id="0">an instantiation of case or concept schemata denoted by semantic symbols as nodes in the semantic network</definiens>
			</definition>
</paper>

		<paper id="1107">
			<definition id="0">
				<sentence>An LKB is a knowledge base management system ( KBMS ) which stores various kinds of dictionary knowledge in a uniform framework and provides multiple viewpoints to the stored knowledge .</sentence>
				<definiendum id="0">LKB</definiendum>
				<definiens id="0">a knowledge base management system ( KBMS ) which stores various kinds of dictionary knowledge in a uniform framework and provides multiple viewpoints to the stored knowledge</definiens>
			</definition>
			<definition id="1">
				<sentence>In addition to conventional direct retrieval , the LKB has a more intelligent access capability to retrieve related knowledge through relationships among knowledge units .</sentence>
				<definiendum id="0">LKB</definiendum>
				<definiens id="0">a more intelligent access capability to retrieve related knowledge through relationships among knowledge units</definiens>
			</definition>
			<definition id="2">
				<sentence>In contrast to conventional database models where relationships between data items are statically defined at data generation time , the LKB extracts relationships dynamically by interpreting the contents of stored knowledge at run time .</sentence>
				<definiendum id="0">LKB</definiendum>
				<definiens id="0">extracts relationships dynamically by interpreting the contents of stored knowledge at run time</definiens>
			</definition>
			<definition id="3">
				<sentence>The methodologies include basic models , architectures , knowledge representation schemes , and implementation techniques .</sentence>
				<definiendum id="0">knowledge representation</definiendum>
				<definiens id="0">schemes , and implementation techniques</definiens>
			</definition>
			<definition id="4">
				<sentence>LKBs provide intelligent access as well as conventional keyword access to stored knowledge .</sentence>
				<definiendum id="0">LKBs</definiendum>
				<definiens id="0">provide intelligent access as well as conventional keyword access to stored knowledge</definiens>
			</definition>
			<definition id="5">
				<sentence>The most basic capability of the LKB is the conventional keyword search .</sentence>
				<definiendum id="0">LKB</definiendum>
				<definiens id="0">the conventional keyword search</definiens>
			</definition>
			<definition id="6">
				<sentence>Given a keyword from a user , the LKB retrieves a piece of stored knowledge whose headword matches the keyword .</sentence>
				<definiendum id="0">LKB</definiendum>
				<definiens id="0">retrieves a piece of stored knowledge whose headword matches the keyword</definiens>
			</definition>
			<definition id="7">
				<sentence>A dictionary is defined as a set of LKUs of the same type .</sentence>
				<definiendum id="0">dictionary</definiendum>
				<definiens id="0">a set of LKUs of the same type</definiens>
			</definition>
</paper>

		<paper id="1135">
			<definition id="0">
				<sentence>The dialog system consists of the following modules : Linguistic Processor , Turns '' Interpreter , Turns '' Generator , Planner , Dialog Monitor , 5oluar~ In addition to this the dialog system includes several knowledge bases for long-term knowledge : goals '' knowledge base , problem domain knowledge base , linguistic knowledge base , dialog knowledge base , partner 's knowledge base and selfknowledge base .</sentence>
				<definiendum id="0">dialog system</definiendum>
				<definiens id="0">consists of the following modules : Linguistic Processor , Turns '' Interpreter , Turns '' Generator , Planner , Dialog Monitor , 5oluar~ In addition to this the dialog system includes several knowledge bases for long-term knowledge : goals '' knowledge base , problem domain knowledge base , linguistic knowledge base , dialog knowledge base , partner 's knowledge base and selfknowledge base</definiens>
			</definition>
			<definition id="1">
				<sentence>The Linguistic Processor carries out morphological and syntactic analysis of the input turn with the help of linguistic knowledge base .</sentence>
				<definiendum id="0">Linguistic Processor</definiendum>
				<definiens id="0">carries out morphological and syntactic analysis of the input turn with the help of linguistic knowledge base</definiens>
			</definition>
			<definition id="2">
				<sentence>A later task of the Linguistic Processor is the generation of the surface answer from its semantic representation .</sentence>
				<definiendum id="0">Linguistic Processor</definiendum>
				<definiens id="0">the generation of the surface answer from its semantic representation</definiens>
			</definition>
			<definition id="3">
				<sentence>Secondly , the Turns Generator constructs the semantic representation of the future turn end adds it to the model of text of preceding dialog turns .</sentence>
				<definiendum id="0">Turns Generator</definiendum>
				<definiens id="0">constructs the semantic representation of the future turn end adds it to the model of text of preceding dialog turns</definiens>
			</definition>
			<definition id="4">
				<sentence>During parsing the input to the Linguistic Processor is the user 's utterance in natural language , the output is the syntactic representation of the turn in the form of dependency trees .</sentence>
				<definiendum id="0">Linguistic Processor</definiendum>
			</definition>
			<definition id="5">
				<sentence>ii ) Use of pronouns A pronoun may be substituted for a lexeme corresponding to a node of a dependency tree according to special rules .</sentence>
				<definiendum id="0">pronoun</definiendum>
				<definiens id="0">a lexeme corresponding to a node of a dependency tree according to special rules</definiens>
			</definition>
			<definition id="6">
				<sentence>Secondly , Turns'Generator constructs the semantic representation of the answer turn , i.e~ chooses the necessary communicative steps for carrying out the goals laid down by the Planner .</sentence>
				<definiendum id="0">Turns'Generator</definiendum>
				<definiens id="0">constructs the semantic representation of the answer turn , i.e~ chooses the necessary communicative steps for carrying out the goals laid down by the Planner</definiens>
			</definition>
</paper>

		<paper id="1114">
			<definition id="0">
				<sentence>VP -~ ( NP ) S ' S ' -- ~ whether S ( 3 ) *What does he\ [ vp wonder Is ' whether \ [ s she wants \ [ NP e\ ] \ ] s ' \ ] S\ ] VP The blocking of structures like these is achieved by permitting no bounding node to lie on the path between the empty constituent and the root node of the control domain , which is specified as annotation of the ~ g-meatvariable ( $ St ) , shown in the following 482 rule .</sentence>
				<definiendum id="0">VP -~</definiendum>
				<definiens id="0">he\ [ vp wonder Is ' whether \ [ s she wants \ [ NP e\ ] \ ] s ' \ ] S\ ] VP The blocking of structures like these is achieved by permitting no bounding node to lie on the path between the empty constituent and the root node of the control domain</definiens>
			</definition>
			<definition id="1">
				<sentence>A treenode is a complex data structure that contains the node 's label ( i.e. its syntactic category ) , a list of its daughters and a pointer to the f-structure attached to it .</sentence>
				<definiendum id="0">treenode</definiendum>
				<definiens id="0">a complex data structure that contains the node 's label ( i.e. its syntactic category ) , a list of its daughters and a pointer to the f-structure attached to it</definiens>
			</definition>
			<definition id="2">
				<sentence>&lt; pending &gt; is a pushdown stack of the nodes that are moved .</sentence>
				<definiendum id="0">&lt; pending &gt;</definiendum>
				<definiens id="0">a pushdown stack of the nodes that are moved</definiens>
			</definition>
			<definition id="3">
				<sentence>( 15 ) *What does he\ [ vp wonder \ [ s ' whether \ [ s she wants \ [ NP e\ ] \ ] S\ ] S ' \ ] vP ( 16 ) ... ...</sentence>
				<definiendum id="0">vP</definiendum>
				<definiens id="0">he\ [ vp wonder \ [ s ' whether \ [ s she wants \ [ NP e\ ] \ ] S\ ] S ' \ ]</definiens>
			</definition>
</paper>

		<paper id="1065">
			<definition id="0">
				<sentence>'rhe corresponding rule in the formalism being proposed here would look approximately like this : R10 ) a/sS disallowed in context e/d c/fg/h i/j , where sS is some set of characters to which \ [ a\ ] can correspond that does not include \ [ b\ ] .</sentence>
				<definiendum id="0">sS</definiendum>
			</definition>
			<definition id="1">
				<sentence>Zero is ttle name for the null character used ill this system .</sentence>
				<definiendum id="0">Zero</definiendum>
				<definiens id="0">ttle name for the null character used ill this system</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>This comparison will be made by a somewhat new method which we call `` Cross Translation Test ( CTT , in short ) '' , which will cventual\ ] y reveal the various IGs that have origins in the differences of culture , i.e. , the way of thinking or the way of representing concepts .</sentence>
				<definiendum id="0">CTT</definiendum>
				<definiens id="0">the way of thinking or the way of representing concepts</definiens>
			</definition>
			<definition id="1">
				<sentence>\ ] 1ere , the VMTS is a certain hypothetical system 109 which never models itself upon any actually existing machine translation systems , but which models the general properties of today 's practical structurebound machine translation systems .</sentence>
				<definiendum id="0">VMTS</definiendum>
				<definiens id="0">a certain hypothetical system 109 which never models itself upon any actually existing machine translation systems , but which models the general properties of today 's practical structurebound machine translation systems</definiens>
			</definition>
			<definition id="2">
				<sentence>Note that as a result of this large gap , the literal translation from ( J3 ) into ( E'3 ) , LT : ( J3 ) ÷ ( E'3 ) where , J ( J3 ) ( E'3 ) J~J ( E'3 ) ( E'3 ) I = 0 has failed to preserve the original meaning , i.e. , ( E'3 ) is an unacceptable translation which is misleading .</sentence>
				<definiendum id="0">LT</definiendum>
				<definiens id="0">an unacceptable translation which is misleading</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>~ ) ~e~t consists of verb , K~i~N shi ( adjective ) and \ ] ( ei~ouc~QR-Sl~_ ( adjectival noun ) .</sentence>
				<definiendum id="0">~ ) ~e~t</definiendum>
				<definiens id="0">consists of verb , K~i~N shi ( adjective )</definiens>
			</definition>
			<definition id="1">
				<sentence>~ of `` col~taia '' Corre lai ioa o.f Japanese m~l \ [ E~tglish case frames ~ i \ [ ( B cas \ ] P E ) ( E LEX c o n t a i n 1 ) ) ( E LEX C 0 n t a i n ) ( E CAT V ) ( E SURFACE CASE ( E SURFACE CASEI S U ~ J ) ( E SURFACE CASE2 0 B J i ) ) ( CASE-PATTERN V1 ) ... . ( E DEEP CASE ( E DEEP CASEi C P O ) ( E DEEP CASE2 0 B J ) ) ( CORRESPONDENCE- ( CORRESPONDENCEI -ji~3 ( CORRESPONDENCE2 ~ $ j~ ) ) ) ( E LEX i n c 1 u d e ) ( E CAT V ) ( E SURFACE CASE ( E SURFACE CASEi S U B J ) ( E SURFACE CASE2 © B J l ) ) ( CASE-PATTERN VI ) - ( E DEEP CASE ( E DEEP CASEI C P O ) ( E DEEP CASE2 0 ~ , I ) ) ( CORRESPONDENCE ( CORRESPONDENCEI J~'I~ ) ( CORRESPONDENCE2 ~ } ~ ) ) ) ) ) ) Figure 8,1 C ont , ~nta~f_ th~Japaneae _to Eng !</sentence>
				<definiendum id="0">E LEX c o n</definiendum>
				<definiendum id="1">E DEEP CASE ( E DEEP CASEi C P O ) ( E DEEP CASE2 0 B J ) ) ( CORRESPONDENCE-</definiendum>
				<definiendum id="2">- ( E DEEP CASE</definiendum>
				<definiens id="0">t a i n 1 ) ) ( E LEX C 0 n t a i n ) ( E CAT V ) ( E SURFACE CASE ( E SURFACE CASEI S U ~ J ) ( E SURFACE CASE2 0 B J i</definiens>
				<definiens id="1">n c 1 u d e ) ( E CAT V ) ( E SURFACE CASE ( E SURFACE CASEi S U B J ) ( E SURFACE CASE2 © B J l ) ) ( CASE-PATTERN VI )</definiens>
			</definition>
</paper>

		<paper id="1052">
			<definition id="0">
				<sentence>\ [ n I ) CKI1 , all Object consists of a set of slots each of which is represented by a Horn clallse headed by the sere predicate .</sentence>
				<definiendum id="0">Object</definiendum>
				<definiens id="0">consists of a set of slots each of which is represented by a Horn clallse headed by the sere predicate</definiens>
			</definition>
			<definition id="1">
				<sentence>Therefore , relatively complex semantic constraints , e.g. , person of blood type A or AB , can be easily described as shown below : sem ( Filler , isa : human , _ ) , ( sem ( Filler , boodType : a , ) ; sem ( Filler , boodType : ab , _ ) ) The meaning of the second , third and forth SA pair in 13 ) is obvious now .</sentence>
				<definiendum id="0">boodType</definiendum>
				<definiens id="0">a</definiens>
			</definition>
			<definition id="2">
				<sentence>The predicate concord is to check concord between subject and verb .</sentence>
				<definiendum id="0">predicate concord</definiendum>
				<definiens id="0">to check concord between subject and verb</definiens>
			</definition>
			<definition id="3">
				<sentence>al. : An Overview of KRL-O , Cognitive Science , i , i , 3-46 ( 1977 ) .</sentence>
				<definiendum id="0">al.</definiendum>
				<definiens id="0">An Overview of KRL-O</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>In that ( asc , Lho iifforn/at , ion that X may bc t ) is redundant bctwccn Lhc I.wo proccdures , and Litc other part or irlfornmLion those Droecdtlres contain is Ill ( Of\ ] '' sistcitL What one might hope here is \ [ o Jrlstitntiatc ) ( ( and Y ) to be b If we had cxectitcd freeze ( Y , member ( Y , It , cL ) iristcad of freeze ( Y , rn .</sentence>
				<definiendum id="0">cL</definiendum>
				<definiens id="0">redundant bctwccn Lhc I.wo proccdures , and Litc other part</definiens>
			</definition>
			<definition id="1">
				<sentence>cgraLo ( I member ( X , Y ) , cO ( X ) \ ] ) , el ( X , Y ) ( a ) modularize ( \ [ cO ( A ) \ ] ) X = A , V - .</sentence>
				<definiendum id="0">cgraLo</definiendum>
				<definiens id="0">A ) \ ] ) X = A</definiens>
			</definition>
</paper>

		<paper id="1151">
			<definition id="0">
				<sentence>The various constituent elements of the clau644 se are rewritten so as to conform to the following seauence : ( Passive ) + ( Negative ) + Role + NPl + Auxiliaries + Verb + ( NP2 ) + ( NP3 ) + PP NPI is the deep subject of the clause , NP2 is the direct'object ( the attribute or even nothin~ at all if the main verb is of the 'be ' type ) and NP3 is the indirect object .</sentence>
				<definiendum id="0">PP NPI</definiendum>
				<definiendum id="1">NP2</definiendum>
				<definiendum id="2">NP3</definiendum>
				<definiens id="0">Passive ) + ( Negative ) + Role + NPl + Auxiliaries + Verb + ( NP2 ) + ( NP3 ) +</definiens>
				<definiens id="1">the deep subject of the clause</definiens>
			</definition>
			<definition id="1">
				<sentence>The verb phrase rewrites itself extensively in the following manner : ( Infinitive ) + Present/Imperfect + 3rd .</sentence>
				<definiendum id="0">verb phrase</definiendum>
			</definition>
</paper>

		<paper id="1054">
			<definition id="0">
				<sentence>In order to describe agents ' positions with respect to a potential goal g we introduce three indices being individual for each agent : -INT ( X , g ) is a degree of X 's interest ( necessity , desirability ) in achieving tile goal g ; this index may be either positive or negative ; -CST ( X , g ) is a cost of achieving tile goal g , i.e. the efforts to be made by X for achieving g ; this index is always positive ; -BEN ( X , g ) is a benefit which may be derived by X from achieving g ; BEN ( X , g ) =INT ( X , g ) -CST ( X , g ) .</sentence>
				<definiendum id="0">g )</definiendum>
				<definiendum id="1">g )</definiendum>
				<definiendum id="2">BEN</definiendum>
				<definiens id="0">a degree of X 's interest ( necessity , desirability ) in achieving tile goal g</definiens>
				<definiens id="1">a cost of achieving tile goal g</definiens>
			</definition>
			<definition id="1">
				<sentence>achievement of tile metagoal k2 are based on the dependency relation : ( X &lt; Y , G ' , t3 ) . If X depends on Y , it is necessary for him to get Y 's permission for inclusion of a goal g~S ' into the X 's system of goals , or the proposition BEN ( Y , g~G.X ) &gt; t3 should belong to the set M , where t3 is the necessary value of index BEN for V to include a goal into his system of goals .</sentence>
				<definiendum id="0">t3</definiendum>
				<definiens id="0">the necessary value of index BEN for V to include a goal into his system of goals</definiens>
			</definition>
</paper>

		<paper id="1001">
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>position calls for one '' Incorporating non-monotonic reasonings , From such considerations we choose Situation Semantics ( henceforth SS ) developed by Barwise and Perry ( 1983 ) as a basis of our theory .</sentence>
				<definiendum id="0">position</definiendum>
				<definiens id="0">calls for one '' Incorporating non-monotonic reasonings , From such considerations we choose Situation Semantics ( henceforth SS ) developed by Barwise</definiens>
			</definition>
			<definition id="1">
				<sentence>A Constraint is a relation holding between types of situation , S - &gt; ~r , we read it as S involves S ' .</sentence>
				<definiendum id="0">Constraint</definiendum>
				<definiens id="0">a relation holding between types of situation</definiens>
			</definition>
			<definition id="2">
				<sentence>nccA~e assumed in the original version of Barwise and Perry ( 1983 ) , we shah introduce the plausibility ordering , - ( , satisfying the following conditions : ( 1 ) A - { B implies Ac_B ( =_ is an ordinary monotonic relation ) , ( Z ) A ~ A ( reflexivity ) , ( 3 ) A - ( B and B - ( C impllies A -C C ( transitivitv ) , Although the exact nature of ' the plausibility ordering is rather vague , its intuitive meaning is that any information , whether correct or incorrect in the actual , is of use in the model for SS .</sentence>
				<definiendum id="0">nccA~e</definiendum>
				<definiens id="0">an ordinary monotonic relation</definiens>
				<definiens id="1">impllies A -C C ( transitivitv ) , Although the exact nature of ' the plausibility ordering is rather vague , its intuitive meaning is that any information , whether correct or incorrect in the actual , is of use in the model for SS</definiens>
			</definition>
</paper>

		<paper id="1129">
			<definition id="0">
				<sentence>Uuification LFG is a unification-based grammar formalism .</sentence>
				<definiendum id="0">Uuification LFG</definiendum>
				<definiens id="0">a unification-based grammar formalism</definiens>
			</definition>
			<definition id="1">
				<sentence>Constraining equations can be handled as follows* : We introduce a special term 'C ' ( Value , Mark ) , where Value is the value demanded by the constraining equation and Mark is uninstantiated .</sentence>
				<definiendum id="0">Value</definiendum>
				<definiens id="0">the value demanded by the constraining equation and Mark is uninstantiated</definiens>
			</definition>
			<definition id="2">
				<sentence>Kaplan , R.M. and Bresnan , J. , `` Lexical-Functioual Grammar : A Formal System for Grammatical Representation '' in `` Mental Representation of Grammatical Relations '' , Bresnan eds. , MIT Press , 1982 Netter , K. , `` Getting Things Out Of Order '' , this volume .</sentence>
				<definiendum id="0">Lexical-Functioual Grammar</definiendum>
				<definiens id="0">A Formal System for Grammatical Representation '' in `` Mental Representation of Grammatical Relations ''</definiens>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>The XTRA is a prototype system now running nnd &amp; '' a C-prolog interpreter and fias a wide coverage of English phenomena , even though its vocabulary is rather small ( 1000 entries ) .</sentence>
				<definiendum id="0">XTRA</definiendum>
				<definiens id="0">a prototype system now running nnd &amp; '' a C-prolog interpreter and fias a wide coverage of English phenomena</definiens>
			</definition>
			<definition id="1">
				<sentence>The SDCG uses the semantics of words and phrases to restrict the number of syntactic pm~es of a sentence to those which arc semantically compatible .</sentence>
				<definiendum id="0">SDCG</definiendum>
				<definiens id="0">uses the semantics of words and phrases to restrict the number of syntactic pm~es of a sentence to those which arc semantically compatible</definiens>
			</definition>
			<definition id="2">
				<sentence>The sentence master contains the s , vutaetic dictionary and tlegins a topdown parse of tim sentence guided by the definite clause grammar .</sentence>
				<definiendum id="0">sentence master</definiendum>
				<definiens id="0">contains the s , vutaetic dictionary and tlegins a topdown parse of tim sentence guided by the definite clause grammar</definiens>
			</definition>
			<definition id="3">
				<sentence>Tile NP-master , which is also a syntactic process , finds all possible initial noun phrases which are meaningful by using its own syntactic information ( in a top down manner ) and by communicating with tile ANmaster for semantic information .</sentence>
				<definiendum id="0">Tile NP-master</definiendum>
				<definiens id="0">a syntactic process , finds all possible initial noun phrases which are meaningful by using its own syntactic information</definiens>
			</definition>
			<definition id="4">
				<sentence>The sentence master , as illustrated below , can be thought of as the root of a tree which h~s two children whieh we will refer to as the sentence monitors : the sentence head monitor ( SH-monitor ) and the sentence body monitor ( SB.-monitor ) .</sentence>
				<definiendum id="0">sentence master</definiendum>
				<definiens id="0">the sentence head monitor ( SH-monitor ) and the sentence body monitor ( SB.-monitor )</definiens>
			</definition>
			<definition id="5">
				<sentence>1 The sentence minster is the process which determines whether or \ ] lot a st , 'ing is a sentence .</sentence>
				<definiendum id="0">sentence minster</definiendum>
				<definiendum id="1">'ing</definiendum>
				<definiens id="0">the process which determines whether or \ ] lot a st</definiens>
				<definiens id="1">a sentence</definiens>
			</definition>
			<definition id="6">
				<sentence>The sentence master gives the sentence to both the SII-handler and tile SB-monitor which in turn give it to one of their children , say SII-handlerl and SB-handlerl .</sentence>
				<definiendum id="0">sentence master</definiendum>
				<definiens id="0">gives the sentence to both the SII-handler and tile SB-monitor which in turn give it to one of their children , say SII-handlerl and SB-handlerl</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , if one of the paths of , say , SB-handlerl does a reeursivc call to check whether or not the next phrase is a sentence ( as in a parenthetical expression or a conjunctive sentence ) , a message is sent to the sentence master to take care of this request .</sentence>
				<definiendum id="0">SB-handlerl</definiendum>
				<definiens id="0">does a reeursivc call to check whether or not the next phrase is a sentence</definiens>
			</definition>
			<definition id="8">
				<sentence>The noun-phrase master contains a queue of noun-phrase requests and allocates them to available noun-phrase handlers .</sentence>
				<definiendum id="0">noun-phrase master</definiendum>
				<definiens id="0">contains a queue of noun-phrase requests and allocates them to available noun-phrase handlers</definiens>
			</definition>
			<definition id="9">
				<sentence>The Computing Research Laboratory ( CRL ) has the use of Longman 's LDOCE English dictionary , which is realistic in size , prov\ ] des comprehensive syntactic information and also has its semantic entries both syntactically and semantically restricted , and limited to a 2000 word vocabulary .</sentence>
				<definiendum id="0">Computing Research Laboratory</definiendum>
				<definiens id="0">the use of Longman 's LDOCE English dictionary , which is realistic in size , prov\ ] des comprehensive syntactic information and also has its semantic entries both syntactically and semantically restricted</definiens>
			</definition>
</paper>

		<paper id="1040">
			<definition id="0">
				<sentence>Ilowevcr , since the opening of the article is more a personal recollection rather than expository , tile information that needs to be organized is not information about particular objects , i.e. amusement parks , but rather episodes in the author 's life .</sentence>
				<definiendum id="0">Ilowevcr</definiendum>
				<definiens id="0">more a personal recollection rather than expository , tile information that needs to be organized is not information about particular objects , i.e. amusement parks , but rather episodes in the author 's life</definiens>
			</definition>
</paper>

		<paper id="1150">
</paper>

		<paper id="1153">
			<definition id="0">
				<sentence>For example , the predicate part : of the Hornby 's verb llattern VP\ ] 3A of Eagl : ish is written as follows : PREDP ( PRED-co : to , MOI ) : m , kl-C \ ] : t\ ] , k2-c2 : t2 ) -- &gt; VP ( PRED-co : to , MOD : m ) NP ( k\ ] -Cl : t\ ] ) PP ( k2-c2 : TO-t 2 ) where PREDP , VP , NP and PP denote a PR\ ] '\ ] DJcage Phrase , a Verb Phrase , a Noun Phrase and a Prepositional Phrase respecively , k-c : t denotes a triple of a case label , a semantic category and a term and in denotes var : ious modal values such as tense an ( \ ] aspect .</sentence>
				<definiendum id="0">MOD</definiendum>
				<definiendum id="1">t\ ] ) PP</definiendum>
				<definiens id="0">TO-t 2 ) where PREDP , VP , NP and PP denote a PR\ ] '\ ] DJcage Phrase , a Verb Phrase , a Noun Phrase and a Prepositional Phrase respecively , k-c : t denotes a triple of a case label , a semantic category and a term and in denotes var : ious modal values such as tense an ( \ ] aspect</definiens>
			</definition>
			<definition id="1">
				<sentence>The IO expression consists of a pair of an input and an output predicate and asserts that the output predicate holds under the given input predicate .</sentence>
				<definiendum id="0">IO expression</definiendum>
				<definiens id="0">consists of a pair of an input and an output predicate and asserts that the output predicate holds under the given input predicate</definiens>
			</definition>
			<definition id="2">
				<sentence>Table 2 Conversion rules to objective lauguages IF TIIEN ( CONI ) : p. OP : s ... ... ... ... ... ... .. ( GCE ) ( CORD ( p s ) ) ... ... ... ... ... ... ... ... ( Lisp ) IF ( p ) s ; ... ... ... ... ... ... ... ... ..</sentence>
				<definiendum id="0">Conversion</definiendum>
				<definiens id="0">rules to objective lauguages IF TIIEN ( CONI ) : p. OP : s ... ... ... ... ... ... .. ( GCE ) ( CORD ( p s</definiens>
			</definition>
			<definition id="3">
				<sentence>K ) ) ) BRANCNI ( COND : &gt; ( K , O ) OP : FOR ( COUNT : N , FROM : I , TO : K , OP : HANDLE REDUCE ( SO : REDUCEDSEQUENCES ( I ) , OBJ : HANDLE ( N ) , INSTR : RULE ( N ) , GOAL : NEW_REDUCED _SEQUENCES ( J ) ) ) ) Fig.3 A part of formal specifications \ [ , -MAPS refines the formal specification by referrdng to library modules such as shown in Table \ ] and generates a ref : ined specification and the comment : shown in Fig.4 .</sentence>
				<definiendum id="0">K ) ) ) BRANCNI</definiendum>
				<definiendum id="1">OP</definiendum>
				<definiendum id="2">REDUCEDSEQUENCES</definiendum>
				<definiendum id="3">INSTR</definiendum>
				<definiendum id="4">GOAL</definiendum>
				<definiens id="0">NEW_REDUCED _SEQUENCES ( J ) ) ) ) Fig.3 A part of formal specifications \ [</definiens>
			</definition>
			<definition id="4">
				<sentence>RULE APPI , Y ( OBJ : REDUCTION_RULE , PARTIC : HANDLE , GOAL : REDUCED SYMBOL ) BRANCH1 ( COND : EQUAL ( REDUCED_SYMBOL , NULL ) , OP : RETURN ( FAIL ) ) FOR ( COUNT : N , FROM : 1 , TO : ( STACK_POINTER , SYMBOL NUMBER OF HANDI , E ) , OP : COPY ( OBJ : REDUCED_SEQUENCE ( N ) , GOAL : NEW_REDUCED _SEQUENCE ( N ) ) , ... ... ..~ ... ..o ... ... ... ... .. Fig.4 ( a ) A part of tile refined specification apply t : he rnl .</sentence>
				<definiendum id="0">GOAL</definiendum>
				<definiendum id="1">GOAL</definiendum>
				<definiens id="0">a ) A part of tile refined specification apply t : he rnl</definiens>
			</definition>
</paper>

		<paper id="1070">
			<definition id="0">
				<sentence>Tins geometry of dependency representations , on the ether hand , are normally unordered , Tile way out was a refashioning of DT as a compromise between DT and X-theory with a single bar : a subset of the information about the governing node was lowered into the mdbtree representing its dependents and to require that the subtree he ordered conforming to the position o~ elements in the input text , lbi~ worked badly with all sorts of difficult linguistic phenomena : exocentri ( : constructions ( e.g. ~onjuection ) , gapoing , discontinuity , long-distance dependencies , etc .</sentence>
				<definiendum id="0">Tins geometry of dependency representations</definiendum>
				<definiens id="0">a subset of the information about the governing node was lowered into the mdbtree representing its dependents and to require that the subtree he ordered conforming to the position o~ elements in the input text</definiens>
			</definition>
			<definition id="1">
				<sentence>Gt/r~ G~/=~m GEN Each stratum corresponds to an autonomous generating device for a representation language , Each generator consists of a set of atoms and a set of constructors that together allow for the generation of L ( 8 ) , a set of formally well-formed derivation trees .</sentence>
				<definiendum id="0">Gt/r~ G~/=~m GEN Each stratum</definiendum>
			</definition>
			<definition id="2">
				<sentence>The justification for compositionality is the intuition that the translation of some expression E 296 is a straightforward function of the translation of E 's parts and of the way these parts ere put together , The latter is required to restrain the complexity of this function : the codomain of a primitive translation must always be well-formed in terms of the target generator , This forbids internal strategy inside translators .</sentence>
				<definiendum id="0">justification for compositionality</definiendum>
				<definiens id="0">a straightforward function of the translation of E 's parts and of the way these parts ere put together</definiens>
			</definition>
</paper>

		<paper id="1020">
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>an evaluator consults the knowledge base and produces answers to questions given their semantic representation .</sentence>
				<definiendum id="0">evaluator</definiendum>
				<definiens id="0">consults the knowledge base and produces answers to questions given their semantic representation</definiens>
			</definition>
			<definition id="1">
				<sentence>Ollvelra E. , Perelra L. , Sabatier P. , `` ORBI : An expert system for environmental resources evaluation through natural language , Proc .</sentence>
				<definiendum id="0">ORBI</definiendum>
				<definiens id="0">An expert system for environmental resources evaluation through natural language , Proc</definiens>
			</definition>
</paper>

		<paper id="1084">
			<definition id="0">
				<sentence>Johnson R. et al. ( 1985 ) , 'EUROTRA : A Multilingual System under Development ' , Computational Linguistics , ll , pp.155-169 .</sentence>
				<definiendum id="0">'EUROTRA</definiendum>
				<definiens id="0">A Multilingual System under Development '</definiens>
			</definition>
			<definition id="1">
				<sentence>Karttunen , L. ( 1985 ) , HUG : a Development Environment for UGa , MS. , Stanford Kay , M. ( 1984 ) , Functional Unification Grammar : A Formalism for Machine Translation ' , Coling 84 , pp.75-78 .</sentence>
				<definiendum id="0">HUG</definiendum>
				<definiens id="0">a Development Environment for UGa , MS. , Stanford Kay , M. ( 1984 ) , Functional Unification Grammar : A Formalism for Machine Translation '</definiens>
			</definition>
</paper>

		<paper id="1156">
			<definition id="0">
				<sentence>Currently our inference engine uses a simple top-down proof technique ( inherited from Prolog , in which The research reported in this paper was conducted at the The ( ; enter for the Study of Language and Information , and was made possible in part by a gift from the System Development foundation , we gratefully acknowledge financial support from the National Science Foundation ( grant BNS8309780 ) ; and Klein also acknowledges financial support from the U.K. Science and Engineering Research Council ( Advanced FeUowship ) .</sentence>
				<definiendum id="0">inference engine</definiendum>
				<definiens id="0">uses a simple top-down proof technique</definiens>
			</definition>
			<definition id="1">
				<sentence>( 18 ) v ( V ) -- &gt; \ [ saw\ ] , { V : sem : in = \ [ Current I Super \ ] , V : sem : out = \ [ \ [ saw ( V : syn : argl , V : syn : arg2 ) I Current \ ] I Super \ ] } .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">sem : in = \ [ Current I Super \ ] , V : sem : out = \ [ \ [ saw ( V : syn : argl , V : syn : arg2 ) I Current \ ] I Super \ ] }</definiens>
			</definition>
			<definition id="2">
				<sentence>( 20 ) det ( Det ) -- &gt; \ [ every\ ] , { Det : sem : res : in = \ [ \ [ \ ] \ ] Det : sem : in \ ] , Det : sem : scope : in = \ [ \ [ \ ] I Det : sem : res : out \ ] , Det : sem : seope : out = \ [ Scope , Res I \ [ Current \ [ Super \ ] \ ] , Det : sem : out = \ [ \ [ ( Res == &gt; Scope ) ICurrent \ ] \ ] Super \ ] } .</sentence>
				<definiendum id="0">sem</definiendum>
				<definiens id="0">Res == &gt; Scope ) ICurrent \ ] \ ] Super \ ] }</definiens>
			</definition>
			<definition id="3">
				<sentence>Amsterdam : Mathematical Centre Tracts .</sentence>
				<definiendum id="0">Amsterdam</definiendum>
				<definiens id="0">Mathematical Centre Tracts</definiens>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>oss arbitrarily , and an ARG-for-ARG mapp : ing defined for tile particular verb pair ; or the AIIG \ ] at ) el s correspond to SOIlle aspect of the alla\ ] ysis ( typically deep syntactic function ) .</sentence>
				<definiendum id="0">ARG-for-ARG mapp</definiendum>
				<definiens id="0">tile particular verb pair ; or the AIIG \ ] at ) el s correspond to SOIlle aspect of the alla\ ] ysis ( typically deep syntactic function )</definiens>
			</definition>
			<definition id="1">
				<sentence>Nominal predicates in a PunctionaI Grammar of F , ngldah .</sentence>
				<definiendum id="0">Nominal</definiendum>
				<definiens id="0">predicates in a PunctionaI Grammar of F , ngldah</definiens>
			</definition>
</paper>

		<paper id="1090">
			<definition id="0">
				<sentence>A ) Thesaurus Operations A thesaurus is a word grouping device which provides a hierarchical and/or a clustered arrangement of the vocabulary for certain subject areas .</sentence>
				<definiendum id="0">thesaurus</definiendum>
				<definiens id="0">a word grouping device which provides a hierarchical and/or a clustered arrangement of the vocabulary for certain subject areas</definiens>
			</definition>
			<definition id="1">
				<sentence>Such a thesaurus operation normalizes the vocabulary and provides additional opportunities for matches between query and document vocabularies .</sentence>
				<definiendum id="0">thesaurus operation</definiendum>
			</definition>
</paper>

		<paper id="1012">
</paper>

		<paper id="1086">
			<definition id="0">
				<sentence>We introduce a layered model of the language denotational base ( the universe ) in which every world object Js assagned a layer ( level ) reflecting its relative singularity with respect tn other objects in the universe , We define the notion of relative singularity of world objects as an abstraction class of the layermembership relation Linguistic ( and related ) literature describes numerous forms of non-singular concept~ that can be found in discourse including intensional ( or functional ) concepts , mass concepts , generic ( or general ) concepts attributive concepts , abstract concepts , etc. \ [ I\ ] , \ [ 2\ ] .</sentence>
				<definiendum id="0">etc. \</definiendum>
				<definiens id="0">the universe ) in which every world object Js assagned a layer ( level ) reflecting its relative singularity with respect tn other objects in the universe</definiens>
				<definiens id="1">the notion of relative singularity of world objects as an abstraction class of the layermembership relation Linguistic ( and related ) literature describes numerous forms of non-singular concept~ that can be found in discourse including intensional ( or functional ) concepts , mass concepts , generic ( or general ) concepts attributive concepts , abstract concepts</definiens>
			</definition>
			<definition id="1">
				<sentence>( lc ) Gold is a yellow metal ( ld ) The temperature is a measure of molecular motion .</sentence>
				<definiendum id="0">Gold</definiendum>
				<definiens id="0">a yellow metal</definiens>
			</definition>
			<definition id="2">
				<sentence>y.z ¢ T. where T is a time coordinate .</sentence>
				<definiendum id="0">T</definiendum>
			</definition>
</paper>

		<paper id="1130">
			<definition id="0">
				<sentence>Ace is a uniform , hierarchical representation system , which facilitates the use of abstractions in the encoding of specialized knowledge as well as the representation of referential and metaphorical relationships among concepts .</sentence>
				<definiendum id="0">Ace</definiendum>
				<definiens id="0">facilitates the use of abstractions in the encoding of specialized knowledge as well as the representation of referential and metaphorical relationships among concepts</definiens>
			</definition>
			<definition id="1">
				<sentence>Many knowledge representation systems , however different they appear superficially , may be shown to have the same SUNIX is a trademark of AT &amp; T Bell Laboratories 554 formal expressive or inferential power .</sentence>
				<definiendum id="0">SUNIX</definiendum>
				<definiens id="0">a trademark of AT &amp; T Bell Laboratories 554 formal expressive or inferential power</definiens>
			</definition>
			<definition id="2">
				<sentence>The most common structured associations in Ace , taken from the KODIAK representation , 4 are the DOMINATE , or `` D '' , relation , which associates a subcategory with its parent category , and the MANIFEST or `` m '' relation , which associates a category with an aspectual or role .</sentence>
				<definiendum id="0">relation</definiendum>
				<definiens id="0">associates a category with an aspectual or role</definiens>
			</definition>
			<definition id="3">
				<sentence>View3 indicates the correspondence between the object of an action or event and the recipient of the transfer , and between the event and the object of the transfer .</sentence>
				<definiendum id="0">View3</definiendum>
				<definiens id="0">indicates the correspondence between the object of an action or event and the recipient of the transfer , and between the event and the object of the transfer</definiens>
			</definition>
			<definition id="4">
				<sentence>View2 represents the relationship between source and actor .</sentence>
				<definiendum id="0">View2</definiendum>
				<definiens id="0">represents the relationship between source and actor</definiens>
			</definition>
			<definition id="5">
				<sentence>PHRED : a generator for natural language interfaces .</sentence>
				<definiendum id="0">PHRED</definiendum>
			</definition>
			<definition id="6">
				<sentence>Ace : associating language with meaning .</sentence>
				<definiendum id="0">Ace</definiendum>
			</definition>
</paper>

		<paper id="1117">
			<definition id="0">
				<sentence>( Sl ) S fl ( fl SUgJ ) = f2 NP f2 der Mann fl = f3 VP f3 /\ ( f3 XO~MP ) = f5 f3 : f6 VP f5 V f6 f5 : : f8 V f8 I versucht hat ( fl XCOMp XCONP ) = f4 VP ' f4 L f4 = f7 VP f7 ( f7 OBJ ) = f9 f7 = flO NP f9 V flO I I das Buch zu Lesen ( F1 ) -- , .</sentence>
				<definiendum id="0">Sl ) S fl</definiendum>
				<definiens id="0">f6 VP f5 V f6 f5 : : f8 V f8 I versucht hat ( fl XCOMp XCONP</definiens>
			</definition>
			<definition id="1">
				<sentence>We define a variable ranging over the set of grammatical functions that may be fulfilled by NPs ( let 's call it Gs ) and modify our rules in the following way : Range of Variebtes : G = : { SUBJ , OgJ , OBJ2 , XCOMP ) GS { SUBJ , ogJ , OBJ2 \ ] ' Go = : C ogJ , OgJ2 } ( NO ) , ( RI ) , ( RS ) , ( R6 ) ( R2.4 ) S - &gt; ( R3.2 ) VP `` &gt; ( R7.1 ) V ' `` &gt; UP* ( 1 XCOMP* Gs ) = ~,1 iv t : t It XCOMP INF =c en\ ] iV ~ xcoNP ) = ~ , \ ] tv t = t\ ] \ [ VP ( 1 XCORP* XCOMP ) = iV ( EXTRAPOSITION ) =c +\ ] .</sentence>
				<definiendum id="0">R6 )</definiendum>
			</definition>
</paper>

		<paper id="1044">
			<definition id="0">
				<sentence>Logic 4 , 475-484 Joshi A. , B.Webber and R.M.Weischedel \ [ 1984 ) , Preventing False Inferences , in Proceeddings of Coling 84 , Stanford , 134-138 Kirschner Z. ( 1982 ) , A Dependency-Based Analysis of English for the Purpose of Machine Translation , Explizite Beschreibung der Sprache und automatische Textbearbeitung IX , Prague Schnelle H. ( 1984 ) , Programming of Net Linguistic Processes , GENET 17a , Bochum Sgall P. , Haji~ov~ E. and J.Panevov~ ( in press\ ] , The Meaning of the Sentence in Its Semantic and Pragmatic Aspects , Reidel ( Dordrecht\ ] and Academia ( Prague\ ] Slocum J. ( 1985 ) , A Survey of Machine Translation , Computational Linguistics Ii , 1-17 Vauquois B. and C.Boitet ( 1985\ ] , Automated Translation at Grenoble Universitv , Computational Linguistics ii , 28-36 Winograd T. ( 1976\ ] , Towards a Procedural Understanding of Semantics , Revue internationale de philosophie , 260-303</sentence>
				<definiendum id="0">1985 )</definiendum>
				<definiens id="0">A Dependency-Based Analysis of English for the Purpose of Machine Translation</definiens>
			</definition>
</paper>

		<paper id="1035">
</paper>

		<paper id="1037">
			<definition id="0">
				<sentence>Even such common grammatical structures as subordinate clauses and clause-level coordination occur with relatively low frequency in taskoriented interfaces , • Ellipsis Resolution Brevity is the key to successful communication .</sentence>
				<definiendum id="0">Ellipsis Resolution Brevity</definiendum>
				<definiens id="0">the key to successful communication</definiens>
			</definition>
			<definition id="1">
				<sentence>The Grammar Writers Workbench provides the LanguageCraft development environment , consisting of a structured grammar editor , a consistency checker , debugging and tracing facilities , and support for a rule-based language to connect to different applications .</sentence>
				<definiendum id="0">Grammar Writers Workbench</definiendum>
				<definiens id="0">provides the LanguageCraft development environment , consisting of a structured grammar editor</definiens>
				<definiens id="1">a rule-based language to connect to different applications</definiens>
			</definition>
			<definition id="2">
				<sentence>Knowledge-Based MachiNe Translation : An Entity Oriented Approach , '' Proceedings of COLING-86 , 1986 .</sentence>
				<definiendum id="0">Knowledge-Based MachiNe Translation</definiendum>
				<definiens id="0">An Entity Oriented Approach</definiens>
			</definition>
</paper>

		<paper id="1116">
			<definition id="0">
				<sentence>They refer to syntactical features of a constituent such as number ( NUM ) , gender ( GEN ) etc. and to grammatical functions of a constituent such a subject ( SUB J ) , object ( OBJ ) etc. , establishing relations between a node on the right side of a production and its predecessor .</sentence>
				<definiendum id="0">NUM</definiendum>
				<definiens id="0">SUB J ) , object ( OBJ ) etc. , establishing relations between a node on the right side of a production and its predecessor</definiens>
			</definition>
			<definition id="1">
				<sentence>A state is a tupef ( &lt; tree &gt; &lt; left &gt; &lt; right &gt; &lt; dot &gt; &lt; pred.-list &gt; ) &lt; tree &gt; is the current parsetree of that path &lt; left &gt; is a pointer to the input string the constituent begins with &lt; right &gt; is a pointer to the input string that immedeatty followsthe constituent &lt; dot &gt; marks the current position in the right side of the cfgrammar rule &lt; pred.-list &gt; is a set of pointers to all preceeding states who 's tree nodes might become the mother of the current states ' tree .</sentence>
				<definiendum id="0">state</definiendum>
				<definiens id="0">the current parsetree of that path &lt; left &gt; is a pointer to the input string the constituent begins with &lt; right &gt; is a pointer to the input string that immedeatty followsthe constituent &lt; dot &gt; marks the current position in the right side of the cfgrammar rule</definiens>
			</definition>
			<definition id="2">
				<sentence>A tree node is a complex data structure that contains the node 's label ( i.e. his syntactic category ) , a list of its daughters and a pointer to the f-structure attached to it .</sentence>
				<definiendum id="0">tree node</definiendum>
				<definiens id="0">a complex data structure that contains the node 's label ( i.e. his syntactic category ) , a list of its daughters and a pointer to the f-structure attached to it</definiens>
			</definition>
			<definition id="3">
				<sentence>state of analysis f-structu re predicting S \ [ \ ] s predicting NP \ [ \ ] NP 490 scanning this \ [ DET = DPRON NUM = SG \ ] NP scanning man \ [ DET = DPRON NUM = SG PRED = MAN \ ] NP completingNP \ [ SUBJ = \ [ DET = DPRON NUM = SG PRED = MAN \ ] \ ] S predicting VP \ [ \ ] vP scanningloved \ [ TENSE = PAST PRED = love ( 1 ' SUB J ) ( 1 ' ORJ ) \ ] vp predicting NP \ [ \ ] NP scanning Mary \ [ PRED = MARY NUM = SG \ ] NP completing NP \ [ TENSE =PAST PRED = love ( I ' SUB J ) ( 1` OBJ ) \ ] vp OBJ = \ [ PRED = MARY NUM = SG \ ] \ ] vP comptetingVP \ [ SUBJ = \ [ DET = DPRON NUM = SG PRED = MAN\ ] TENSE = PAST PRED =love ( 1 ' SUB J ) ( I ' OBJ ) OBJ = \ [ PRED = MARY NUM = SG \ ] \ ] s Building f-structures in this incremental way allows ruling out paths that would lead to inappropriate fo structures earlier than in a sequential process that builds c-structure and f-structure .</sentence>
				<definiendum id="0">] vP</definiendum>
				<definiens id="0">s predicting NP \ [ \ ] NP 490 scanning this \ [ DET = DPRON NUM = SG \ ] NP scanning man \ [ DET = DPRON NUM = SG PRED = MAN \ ] NP completingNP \ [ SUBJ = \ [ DET = DPRON NUM = SG PRED = MAN \ ] \ ] S predicting VP \ [ \</definiens>
				<definiens id="1">] vp predicting NP \ [ \ ] NP scanning Mary \ [ PRED = MARY NUM = SG \ ] NP completing NP \ [ TENSE =PAST PRED = love ( I ' SUB J ) ( 1` OBJ ) \ ] vp OBJ = \ [ PRED = MARY NUM = SG \ ] \ ] vP comptetingVP \ [ SUBJ = \ [ DET = DPRON NUM = SG PRED = MAN\ ] TENSE = PAST PRED =love ( 1 ' SUB J ) ( I ' OBJ ) OBJ = \ [ PRED = MARY NUM = SG \ ] \ ] s Building f-structures in this incremental way allows ruling out paths that would lead to inappropriate fo structures earlier than in a sequential process that builds c-structure and f-structure</definiens>
			</definition>
			<definition id="4">
				<sentence>Let ARG ( DOWN ) be the ARG ( Semform ) of the PRED of F ( DOWN ) .</sentence>
				<definiendum id="0">ARG ( DOWN</definiendum>
			</definition>
</paper>

		<paper id="1081">
			<definition id="0">
				<sentence>INTRODUCTION Ambiguity of determiners is one of the most striking phenomena of natural language ; what is strange is the case with ~hich humans use them : it seems that the molteplicity of interpretations of a ncun phrase including a determiner is not explicitly perceived by human users of rmtural language \ [ Hobbs 1983\ ] .</sentence>
				<definiendum id="0">INTRODUCTION Ambiguity of determiners</definiendum>
			</definition>
			<definition id="1">
				<sentence>ARBITRARY ( x , z ) : Any member of the class x identified by be expression z necessarily satisfies the property expressed by the pro ~ position in which z occurs .</sentence>
				<definiendum id="0">ARBITRARY</definiendum>
				<definiendum id="1">z )</definiendum>
				<definiens id="0">Any member of the class x identified by be expression z necessarily satisfies the property expressed by the pro ~ position in which z occurs</definiens>
			</definition>
			<definition id="2">
				<sentence>REF ( SjI , BOY ) &amp; IDEN£IFIABLE ( S , S , x ) &amp; R~ ( S , y , TO RAT ) &amp; AGENT ( y , x ) &amp; SEIT ( X ) The enly difference is the presence of the predicate SET2 ( x ) , ~hich states that the entity x is a set .</sentence>
				<definiendum id="0">REF</definiendum>
				<definiens id="0">the presence of the predicate SET2 ( x ) , ~hich states that the entity x is a set</definiens>
			</definition>
			<definition id="3">
				<sentence>In the first ease ( specific interpretation ) , the speaker is referring to a particular individt~al , ~hereas in the second one he is not .</sentence>
				<definiendum id="0">speaker</definiendum>
				<definiens id="0">specific interpretation</definiens>
			</definition>
			<definition id="4">
				<sentence>The first well known example is provided by a 'desire ' verb , that is 'to want ' : 7 ) John wants to nmrry a Norwegian Some different meanings can be characterized by the hearer 's different replies : 7a ) No , Ingrid is n't a Norwegian .</sentence>
				<definiendum id="0">John</definiendum>
				<definiens id="0">wants to nmrry a Norwegian Some different meanings can be characterized by the hearer 's different replies</definiens>
			</definition>
</paper>

		<paper id="1102">
			<definition id="0">
				<sentence>This paper outlines the experimental development of the SWESIL system : a structured lexicon-based word expert system designed to play a pivotal role in the process of Distributed ~an_~ay ~ Translation ( DLT ) which is being developed in the Netherlands .</sentence>
				<definiendum id="0">SWESIL system</definiendum>
				<definiens id="0">a structured lexicon-based word expert system designed to play a pivotal role in the process of Distributed ~an_~ay ~ Translation ( DLT ) which is being developed in the Netherlands</definiens>
			</definition>
			<definition id="1">
				<sentence>konduk'i &lt; tra'ir'ig'i &gt; &lt; &lt; tra'mov'i~'ig'i &gt; &gt; ( to conduct ) ( cause to go through ) { cause to be moved through ) FIRST ARGUMENT RELATOR SECOND ARGUMENT konduk'i &lt; tra'ir'ig'i &gt; io-n kurent'o , likv'a\ ] 'o , gas'o { inanimaCe £ATIENT\ ] ( current , liquid , gass } konduk'i &lt; tra'ir'ig'i &gt; per drat'o , kanal'o , tub'o~il'o { with INSTRUMENT1 Iwi~o , channel , tuhe , instrumant } konduk'i &lt; tra'ir'ig'i &gt; ien-al , de lok'~ , dom , o , ma~in , o , ejro ( to/from PLACE } \ [ position , house , i~achine , placel konduk'i &lt; tra'ir'ig'i &gt; por proviz'i , for'ig~i , el'ig'i { to PURPOSE ) { supply , remove , cause output { konduk'i &lt; tra'ir'ig'i &gt; ie-en , tra kabl'o , siste~'o , kloak'o ( within , trough } { cable , system , sewer } in~enier'o , instal~ist'o as konduk'i &lt; tra'ir'igri &gt; ( engineer , installator\ ] { AGENT off ) rekt'a e konduk'i &lt; tra'ir~ig'i &gt; ( straight , dlrectiy } { MANNER\ ] konduk'i &lt; tra'ir'ig'i &gt; ie-en mar'o , lag'o , lok'o , eJ'o ( intol ( sea , lake , position~place ) for'ig'i , el'ig'i io-n likv'a~'o~gas'o proviz ' i io-n lok ' o , dora ' o , ma~in ' o , ej ' o To ensure that the word ls properly linked into the tree ( and to reduce the number of possible search paths when disambiguatin£ ) the keyterm itself is labeled with a super-keyterm , related to the keyterm through the same ISA link that relates the keyterm to the lexeme .</sentence>
				<definiendum id="0">house</definiendum>
				<definiens id="0">to/from PLACE } \ [ position ,</definiens>
				<definiens id="1">engineer , installator\ ] { AGENT off ) rekt'a e konduk'i &lt; tra'ir~ig'i &gt; ( straight , dlrectiy } { MANNER\ ] konduk'i &lt; tra'ir'ig'i &gt; ie-en mar'o</definiens>
				<definiens id="2">the word ls properly linked into the tree ( and to reduce the number of possible search paths when disambiguatin£ ) the keyterm itself is labeled with a super-keyterm</definiens>
			</definition>
			<definition id="2">
				<sentence>To provide inferential power , the IL iatra-word g &lt; ammar is used , by means of which SWESIL can decompose complex keyterms into their logical constituents and reason about them. Each lexeme is described in detail in its entr\ [ : used both to differentiate the concept being defined from its `` genus '' ( Cf. \ [ CALZOLARI 1984 , AMSLER 1980\ ] ) , and to describe the coatextual~ectations of the lexeme in question. A definition is built up from ~airs : each pair consisting of two lexemes tied to each other with a relator. A relator is an IL word ( usually a function morpheme or preposition ) which denotes the roles the two lexemes play in relation to each other ( see table i ) . Most of the relators are used to represent the contextual 432 expectation , pattern of the lexeme : they specify the relations with the context typically expected for this entry , and the kind of lexemes most likely to partake in them. The complete information eventually to be contained in a definition can be said to represent what Mel'~uk calls the `` Lexical Universe '' of the entry \ [ MEL'~UK 1984\ ] . The Disambiguation Cycle The DLT syntactic parser generates dependency. trees : structural descriptions of the syntactically possible representations of a given sentence \ [ SCHUBERT 1986\ ] , from which a special diathesis module extracts relevant semantic information which it passes on to the SWESIL system in the form of dependency pairs similar to those found in the SWESIL entries. For each source language lexical unit , the diathesis module will search the SL to IL lexicon and will generate as many dependency pairs as necessary to capture all possible interpretations of a given \ ] ) art of the source string , using the process of paradigmatic extension ( i.e. filling in , for each lexeme , all possible word senses found in the dictionary ) . SWESIL receives those paradigms of dependency pairs ( ca|led IS| ' pairs ) and ca\ ] culates which interpretation best fits its expectations by comparing them with the information in its know|edge bank ( the SOLL pairs ) . The actual process of selecting the best fit from a set of possible ones is one of rankin &amp; : the conflicting pairs will be ordered according to the height of their match score. Those pairs that best fit the knowledge bank information come out highest , those that fit less come out lower. It is important to note here that the DLT system is designed to become an integral part of modern text-processing apparatus , and will parse texts 'on-line ' , starting the generation of 'parse trails ' as soon as the first word arrives. The re\ ] .ativeJ.y slow speed of the typed input gives SWESIL the opportunity to 'interleave ' wJ.th the parser and do a large amount of step by step pre.-orderinK , # @ dueing the time needed for the final ordering ( w~en all syntactical\ ] y impossible interpretations have been weeded out ) to a minimum. The criterium for choosing one interpretation amongst various others is always relative : only when one interpretation scores substantially higher than any of the others can it be said to be preferred over those others and accepted as the one to be passed on to the final representation. Unless a definitive choice can be made , the conflicting pairs have to be handed on to the disambiguation dialo ugh , by means of which the.human user of the system can assist in making the correct choice. Since SWESIL has already calculated the relative probabilities of the pairs , the dialogue module can use this to make the dialogue more intelligent and user-friendly , by presenting only the highest-scoring pair ( s ) to the user , not showing the full range of possibilities unless the proposed solution is rejected. The Matching Procedure To calculate the extent to which an IST pair conforms to the SOLL pair information in the knowledge bank , SWESIL uses a match score module. This match score module accepts as input one dependency \ ] ) air , and returns a score which reflects how well that dependency pair fits the expectat : ions found in the knowledge bank. What the match score module basically does is to take the input IST pair , locate the entries of both its constituent \ ] exemes , and then search both entries for the occurrence of SOLL pairs that are similar ( the notion 'similar ' being defined by a number of matching rules ) to the IST pair and calculate their measure of similarity. When both entries have been completely searched and certain boundary conditions have not been met ( see below ) , both lexemes are replaced by their keyterms , and the resulting 'super ' IST pair becomes the input to the same matching procedure ( Fig. i ) . Because of the way each lexeme can be recursively replaced with its own keyterm , the match score module in effect : searches through the relevant part of the lexioa\ ] taxonomy and records the match scores for the various levels of abstraction it reaches. A number of boundary conditions prevent the system from falling into endless loops. The most important of these conditions is determined by the main purpose of SWESIL : to find among competing IST pairs the one best fitting the information Jn the knowledge bank. Because of this , SWESIL carries out the matching procedures for the IST paJ rs in parallel , and monitors the accumulated scores of each pair , testing oa each level of matching to see whether one of the competing pairs has managed to score significantly higher than the rest. If this is so , SWESIL can 'freeze ' the matching of the lower pairs and take the high-scorii~g pair as a 'working hypothesis ' , only 'unfreezing ' the others if and when later evidence ( after other sentence elements have been parsed ) seems to invalidate the current one. Fig. l ; By tem~rsiveIy \ [ \ ] lOVJl~ lll~ \ [ l~e , tepund\ [ mcy hielarciw , wo , d~ c , m lie ma\ [ ched zl { ~\ ] t~ \ [ l~crea~ { i~lg ~evel of generaltza\ [ Lm~. Wt¢l , ~r con/ux\ [ matching can a\ ] sa ( reeH : { Lvely ) be apgl h 'd h &gt; stlenRthen the first ardor matche~ { .</sentence>
				<definiendum id="0">SWESIL</definiendum>
				<definiens id="0">the IL iatra-word g &lt; ammar is used , by means of which SWESIL can decompose complex keyterms into their logical constituents and reason about them. Each lexeme is described in detail in its entr\ [ : used both to differentiate the concept being defined from its `` genus '' ( Cf. \ [ CALZOLARI 1984 , AMSLER 1980\ ] ) , and to describe the coatextual~ectations of the lexeme in question. A definition is built up from ~airs : each pair consisting of two lexemes tied to each other with a relator. A relator is an IL word ( usually a function morpheme or preposition ) which denotes the roles the two lexemes play in relation to each other ( see table i ) . Most of the relators are used to represent the contextual 432 expectation , pattern of the lexeme : they specify the relations with the context typically expected for this entry , and the kind of lexemes most likely to partake in them. The complete information eventually to be contained in a definition can be said to represent what Mel'~uk calls the `` Lexical Universe '' of the entry \ [ MEL'~UK 1984\ ] . The Disambiguation Cycle The DLT syntactic parser generates dependency. trees : structural descriptions of the syntactically possible representations of a given sentence \ [ SCHUBERT 1986\ ] , from which a special diathesis module extracts relevant semantic information which it passes on to the SWESIL system in the form of dependency pairs similar to those found in the SWESIL entries. For each source language lexical unit , the diathesis module will search the SL to IL lexicon and will generate as many dependency pairs as necessary to capture all possible interpretations of a given \ ] ) art of the source string , using the process of paradigmatic extension ( i.e. filling in , for each lexeme , all possible word senses found in the dictionary ) . SWESIL receives those paradigms of dependency pairs ( ca|led IS| ' pairs ) and ca\ ] culates which interpretation best fits its expectations by comparing them with the information in its know|edge bank ( the SOLL pairs ) . The actual process of selecting the best fit from a set of possible ones is one of rankin &amp; : the conflicting pairs will be ordered according to the height of their match score. Those pairs that best fit the knowledge bank information come out highest , those that fit less come out lower. It is important to note here that the DLT system is designed to become an integral part of modern text-processing apparatus , and will parse texts 'on-line ' , starting the generation of 'parse trails ' as soon as the first word arrives. The re\ ] .ativeJ.y slow speed of the typed input gives SWESIL the opportunity to 'interleave ' wJ.th the parser and do a large amount of step by step pre.-orderinK , # @ dueing the time needed for the final ordering ( w~en all syntactical\ ] y impossible interpretations have been weeded out ) to a minimum. The criterium for choosing one interpretation amongst various others is always relative : only when one interpretation scores substantially higher than any of the others can it be said to be preferred over those others and accepted as the one to be passed on to the final representation. Unless a definitive choice can be made , the conflicting pairs have to be handed on to the disambiguation dialo ugh , by means of which the.human user of the system can assist in making the correct choice. Since SWESIL has already calculated the relative probabilities of the pairs , the dialogue module can use this to make the dialogue more intelligent and user-friendly , by presenting only the highest-scoring pair ( s ) to the user , not showing the full range of possibilities unless the proposed solution is rejected. The Matching Procedure To calculate the extent to which an IST pair conforms to the SOLL pair information in the knowledge bank</definiens>
				<definiens id="1">uses a match score module. This match score module accepts as input one dependency \ ] ) air , and returns a score which reflects how well that dependency pair fits the expectat : ions found in the knowledge bank. What the match score module basically does is to take the input IST pair , locate the entries of both its constituent \ ] exemes , and then search both entries for the occurrence of SOLL pairs that are similar ( the notion 'similar ' being defined by a number of matching rules ) to the IST pair and calculate their measure of similarity. When both entries have been completely searched and certain boundary conditions have not been met ( see below ) , both lexemes are replaced by their keyterms , and the resulting 'super ' IST pair becomes the input to the same matching procedure ( Fig. i ) . Because of the way each lexeme can be recursively replaced with its own keyterm , the match score module in effect : searches through the relevant part of the lexioa\ ] taxonomy and records the match scores for the various levels of abstraction it reaches. A number of boundary conditions prevent the system from falling into endless loops. The most important of these conditions is determined by the main purpose of SWESIL : to find among competing IST pairs the one best fitting the information Jn the knowledge bank. Because of this , SWESIL carries out the matching procedures for the IST paJ rs in parallel , and monitors the accumulated scores of each pair , testing oa each level of matching to see whether one of the competing pairs has managed to score significantly higher than the rest. If this is so , SWESIL can 'freeze ' the matching of the lower pairs and take the high-scorii~g pair as a 'working hypothesis ' , only 'unfreezing ' the others if and when later evidence ( after other sentence elements have been parsed ) seems to invalidate the current one. Fig. l ; By tem~rsiveIy \ [ \ ] lOVJl~ lll~ \ [ l~e , tepund\ [ mcy hielarciw , wo , d~ c , m lie ma\ [ ched zl { ~\ ] t~ \ [ l~crea~ { i~lg ~evel of generaltza\ [ Lm~. Wt¢l , ~r con/ux\ [ matching can a\ ] sa ( reeH : { Lvely ) be apgl h 'd h &gt; stlenRthen the first ardor matche~ {</definiens>
			</definition>
			<definition id="3">
				<sentence>The full output ( not shown here ) shows : the IST pair that is being matched , the lexeme ( with keyterm ) that is taken as starting point , the SOLL pairs that were found to match , together with their match scores and the hierarchic level at which they were found .</sentence>
				<definiendum id="0">IST pair</definiendum>
				<definiendum id="1">SOLL</definiendum>
				<definiens id="0">pairs that were found to match , together with their match scores and the hierarchic level at which they were found</definiens>
			</definition>
			<definition id="4">
				<sentence>\ [ the economy is growing } scored 1.905 2.2 ekonomik'o as kresk'i leconomics is growing I scored O.160 2.3 dllat'i -n ekonomi'o Iphysically expand tile economyl scored 0.105 2.4 dilatti -n ekonomlk~o { physically e×pand economicsl scored 0.084 Amsler , R.A. ( 1980 ) : The Structure of The Merriam-Webster Pocket Dictionarl , Austin ; University of Texas Calzolari , N. ( 1984 ) : Detecting Patterns in a Lexical Database , In : ProceedinRs of ColinR '84 , California ; Stanford University , Association for Computational Linguistics Mel'Euk , l.A. / A.K. Zolkovskij \ [ Zholkovsky\ ] ( 1984 ) : T @ .</sentence>
				<definiendum id="0">In</definiendum>
				<definiendum id="1">l.A. / A.K. Zolkovskij</definiendum>
				<definiens id="0">Detecting Patterns in a Lexical Database ,</definiens>
			</definition>
</paper>

		<paper id="1048">
			<definition id="0">
				<sentence>Vijay-Shanker and Joshi \ [ 9\ ] provided a brief description of the intuition behind the inclusion of Tree Adjoining Langages ( TAL ) in the class of languages generated by a variant of HG 's called Modified Head Grammars ( MHG 's ) .</sentence>
				<definiendum id="0">Vijay-Shanker</definiendum>
			</definition>
			<definition id="1">
				<sentence>A TAG is a 54uple G -= ( VN , V.r , S , I , A ) where Vlv and V T are finite sets of nonterminals and terminals respectively , S is a distinguished nonterminal , I is a finite set of initial trees and A is a finite set of auxiliary trees .</sentence>
				<definiendum id="0">TAG</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">a 54uple G -= ( VN , V.r , S , I , A ) where Vlv and V T are finite sets of nonterminals and terminals respectively ,</definiens>
				<definiens id="1">a distinguished nonterminal</definiens>
			</definition>
			<definition id="2">
				<sentence>Each node in an elementary tree is given a unique name in the following manner : the pMr ( % e } denotes the root of ~ , ; if ( % i } is a node in % then ( 3 , i. j ) represents the jth daughter of this node .</sentence>
				<definiendum id="0">pMr</definiendum>
				<definiens id="0">the root of ~</definiens>
			</definition>
			<definition id="3">
				<sentence>However , obviously not every MHG ( : an be given a linguistic interpretation in this way .</sentence>
				<definiendum id="0">MHG</definiendum>
				<definiens id="0">an be given a linguistic interpretation in this way</definiens>
			</definition>
			<definition id="4">
				<sentence>Let ( fl , i ) be the address of a node in an auxiliary tree fl , and '7 belongs to P ( ( fl , i ) ) with a frontier WlXtO 2 , We have a nonterminal corresponding to this node ( denoted by \ [ fl , i\ ] ) which derives the split string watw~ .</sentence>
				<definiendum id="0">] )</definiendum>
				<definiens id="0">derives the split string watw~</definiens>
			</definition>
			<definition id="5">
				<sentence>The OA constraints are used to ensure that every nonterminal introduced is rewritten .</sentence>
				<definiendum id="0">OA constraints</definiendum>
				<definiens id="0">used to ensure that every nonterminal introduced is rewritten</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>ies ( ~qual\ ] y well to closed sentences ( i°e yes-no questions ) as well as to open sentences ( i.e W\ [ I-questions ) ° \ ] , 'or an application of this im~thod as wo\ ] .</sentence>
				<definiendum id="0">ies</definiendum>
				<definiens id="0">] y well to closed sentences ( i°e yes-no questions ) as well as to open sentences ( i.e W\ [ I-questions ) ° \ ]</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus each unresloved DRS is a pair of the form K = \ [ K , L ( K ) \ ] where L ( K ) is the antecedent list of the DRS K. To resolve an unresolved DRS , each unresolved predicate ( UP ) must be resolved according to the following mule : for an unresolved DRS K = \ [ K , L ( K ) \ ] with K=\ [ U , CON\ ] a UP P of CON is transformed into the logical predicate P '' which is obtained by unifying pronoun arguments of P ih L ( K ) .</sentence>
				<definiendum id="0">DRS</definiendum>
				<definiens id="0">a pair of the form K = \ [ K , L ( K ) \ ] where L ( K ) is the antecedent list of the DRS</definiens>
			</definition>
			<definition id="2">
				<sentence>Let t be a formula and K ( t ) : \ [ U , CON\ ] its translation into a DRS. The DRS of situation is the ORS K§ ( n ) = \ [ U§ , CON§\ ] with U§ containing the instantiation of referents of U , CON§ ( ~pty , and n denoting the current state of the dialogue ( i.e. the occurrence of the question during the dialogue ) .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the ORS K§ ( n ) = \ [ U§ , CON§\ ] with U§ containing the instantiation of referents of U</definiens>
			</definition>
			<definition id="3">
				<sentence>Each sentence will be translated into two partiallogical formulas ( noted PLF ) of the form &lt; x , f &gt; , where x is a variable or an individual and f a logical formula .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">a variable or an individual and f a logical formula</definiens>
			</definition>
</paper>

		<paper id="1104">
			<definition id="0">
				<sentence>The PRIME DBMS software , which we use , is actually one of the first commercial products which closely adhered to the CODASYL network data model .</sentence>
				<definiendum id="0">PRIME DBMS software</definiendum>
				<definiens id="0">actually one of the first commercial products which closely adhered to the CODASYL network data model</definiens>
			</definition>
			<definition id="1">
				<sentence>The basic misunderstanding is the false identification of a mere presentation in a printed dictionary with an underlying lexical information structure .</sentence>
				<definiendum id="0">basic misunderstanding</definiendum>
				<definiens id="0">the false identification of a mere presentation in a printed dictionary with an underlying lexical information structure</definiens>
			</definition>
</paper>

		<paper id="1074">
			<definition id="0">
				<sentence>M-grammars can be seen as a computationally viable and syntactically powerful variant of Montague Grammar .</sentence>
				<definiendum id="0">M-grammars</definiendum>
			</definition>
			<definition id="1">
				<sentence>An M-grammar consists of three components : I ) a syntactic component , 2 ) a morphological component and 3 ) a semantic component .</sentence>
				<definiendum id="0">M-grammar</definiendum>
				<definiens id="0">consists of three components : I ) a syntactic component , 2 ) a morphological component and 3 ) a semantic component</definiens>
			</definition>
			<definition id="2">
				<sentence>In the rest of this paper I will abbreviate them by specifying the top node and a characterization of the rest of the tree , as : CAT { attribute : value , ... } ( string ) The syntactic component : defines S-trees by specifying : ( i ) a set of basic S-trees ( also called basic expressions ) ( ii ) a set of syntactic rules .</sentence>
				<definiendum id="0">} ( string</definiendum>
				<definiendum id="1">syntactic component</definiendum>
				<definiens id="0">a set of basic S-trees ( also called basic expressions</definiens>
			</definition>
			<definition id="3">
				<sentence>3 ) The semantic component M-grammars obey the Compositionality Principle , which states that the meaning of an expression is a function of the meaning of the parts of that expression .</sentence>
				<definiendum id="0">semantic component M-grammars obey the Compositionality Principle</definiendum>
				<definiens id="0">states that the meaning of an expression is a function of the meaning of the parts of that expression</definiens>
			</definition>
			<definition id="4">
				<sentence>The translation relation between two ( or more ) languages is defined by attuning their grammars as follows : ( i ) For each basic expression of a grammar there is at least one corresponding basic expression of the other grammar with the same meaning .</sentence>
				<definiendum id="0">translation relation between two</definiendum>
				<definiens id="0">attuning their grammars as follows : ( i ) For each basic expression of a grammar there is at least one corresponding basic expression of the other grammar with the same meaning</definiens>
			</definition>
			<definition id="5">
				<sentence>Temporal expressions consist of : tense , a linguistic category which consists of morphological forms of the verb ( e.g. worked , works ) or of auxiliary verb forms in combination with certain morphological fomns of the verb which I call `` periphrastic tenses '' ( e.g. has worked , is working ; Spanish : e_st~ trabajando ) .</sentence>
				<definiendum id="0">Temporal expressions</definiendum>
				<definiendum id="1">linguistic category</definiendum>
			</definition>
			<definition id="6">
				<sentence>Intervals are subsets of T without any gaps or branches .</sentence>
				<definiendum id="0">Intervals</definiendum>
				<definiens id="0">subsets of T without any gaps or branches</definiens>
			</definition>
			<definition id="7">
				<sentence>I propose therefore that in the Rosetta framework I ) a time meaning representation obligatorily will contain an aspeetual relation , i.e. a relation between E and a reference interval R~ , which will be called perfective if E is a subset ~ R E and imperfee -- t~ve~f~R~ is a subset of E , and ~ ) t~at .</sentence>
				<definiendum id="0">-- t~ve~f~R~</definiendum>
				<definiens id="0">a subset ~ R E and imperfee</definiens>
				<definiens id="1">a subset of E</definiens>
			</definition>
			<definition id="8">
				<sentence>aspect rules ( OB ) : These rules insert a reference adverbial and specify the aspectual tense forms ( perfective or imperfectlve ) of the verbs .</sentence>
				<definiendum id="0">aspect rules</definiendum>
				<definiendum id="1">OB )</definiendum>
			</definition>
			<definition id="9">
				<sentence>V. deictic rules ( OB ) : These rules determine the deictic tense form of the verbs in the clause .</sentence>
				<definiendum id="0">V. deictic rules</definiendum>
				<definiendum id="1">OB )</definiendum>
				<definiens id="0">These rules determine the deictic tense form of the verbs in the clause</definiens>
			</definition>
</paper>

		<paper id="1021">
</paper>

		<paper id="1064">
			<definition id="0">
				<sentence>~ # , ttern of a snD is a horizontal Dro !</sentence>
				<definiendum id="0">snD</definiendum>
			</definition>
			<definition id="1">
				<sentence>A bracketed phrase gives the history of the analysis .</sentence>
				<definiendum id="0">bracketed phrase</definiendum>
				<definiens id="0">gives the history of the analysis</definiens>
			</definition>
</paper>

		<paper id="1077">
			<definition id="0">
				<sentence>`` LexicalFunctional Grammar : A formal system for grammatical representation '' .</sentence>
				<definiendum id="0">LexicalFunctional Grammar</definiendum>
				<definiens id="0">A formal system for grammatical representation ''</definiens>
			</definition>
</paper>

		<paper id="1140">
			<definition id="0">
				<sentence>Semantic knowledge consists of lexical meanings of words and selectional restrictions between them .</sentence>
				<definiendum id="0">Semantic knowledge</definiendum>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>The Structural Correspondence Specification Gran~ar ( SCSG ) is a powerful linguist ic specification Formalism .</sentence>
				<definiendum id="0">Structural Correspondence Specification Gran~ar ( SCSG )</definiendum>
			</definition>
			<definition id="1">
				<sentence>A SCSG can be used for the synthesis of ' dynamic gralr~ } lars ( analyser and generator ) and as a reference for large linguistic systems .</sentence>
				<definiendum id="0">SCSG</definiendum>
				<definiens id="0">the synthesis of ' dynamic gralr~ } lars ( analyser and generator</definiens>
			</definition>
			<definition id="2">
				<sentence>procedures The SCSG base consists of a set of files Contalnlng tile grarrlnars , lhe base has a hlerarchtca\ ] structure .</sentence>
				<definiendum id="0">SCSG base</definiendum>
				<definiens id="0">consists of a set of files Contalnlng tile grarrlnars</definiens>
			</definition>
			<definition id="3">
				<sentence>The `` operand '' is a pattern giving the range OF the operation .</sentence>
				<definiendum id="0">operand</definiendum>
				<definiens id="0">a pattern giving the range OF the operation</definiens>
			</definition>
			<definition id="4">
				<sentence>Here V is the operator , GRAMMAR ( LANGUAGE=ENGLISti ) ls tile operand pattern and no option Is given .</sentence>
				<definiendum id="0">V</definiendum>
			</definition>
			<definition id="5">
				<sentence>The trace option is a switch that turns on or off the trace of the session .</sentence>
				<definiendum id="0">trace option</definiendum>
				<definiens id="0">a switch that turns on or off the trace of the session</definiens>
			</definition>
			<definition id="6">
				<sentence>The list of cross-references reveals the objects which are used but never defined or those defined but never used .</sentence>
				<definiendum id="0">list of cross-references</definiendum>
				<definiens id="0">reveals the objects which are used but never defined or those defined but never used</definiens>
			</definition>
</paper>

		<paper id="1079">
			<definition id="0">
				<sentence>AL6TAxLP is a part of an applied ~ theory for natural ~ngnage pmoeessing ( ALT/NLP ) .</sentence>
				<definiendum id="0">AL6TAxLP</definiendum>
				<definiens id="0">a part of an applied ~ theory for natural ~ngnage pmoeessing ( ALT/NLP )</definiens>
			</definition>
			<definition id="1">
				<sentence>340 ( I0 ) mmmarizes all the main options for semantic malysis in ~2 ~=level ) .</sentence>
				<definiendum id="0">I0 )</definiendum>
				<definiens id="0">mmmarizes all the main options for semantic malysis in ~2 ~=level )</definiens>
			</definition>
</paper>

		<paper id="1055">
			<definition id="0">
				<sentence>( 1 ) An initiating SA is a primary initiation of the goal ( see the designation in fig .</sentence>
				<definiendum id="0">SA</definiendum>
				<definiens id="0">a primary initiation of the goal ( see the designation in fig</definiens>
			</definition>
			<definition id="1">
				<sentence>Y is a positive ( a ) and negative ( b ) reaction of Y to g.X. SA2 .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">a positive ( a</definiens>
			</definition>
			<definition id="2">
				<sentence>Y is a negative reaction to g.X with the initiation of a reason aimed at the component C of the SAI .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">a negative reaction to g.X with the initiation of a reason aimed at the component C of the SAI</definiens>
			</definition>
			<definition id="3">
				<sentence>Y is an acceptance of X 's reaction to the reason by Y ( possibly by default ) .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">an acceptance of X 's reaction to the reason by Y ( possibly by default )</definiens>
			</definition>
			<definition id="4">
				<sentence>X is a completing SA .</sentence>
				<definiendum id="0">X</definiendum>
			</definition>
</paper>

		<paper id="1056">
			<definition id="0">
				<sentence>A PC-suited TBM-system , ARRAS ( SMITH 1984 ) , supports comfortable text inquiry by concordance and index functions , but has no textbase component .</sentence>
				<definiendum id="0">PC-suited TBM-system</definiendum>
				<definiens id="0">supports comfortable text inquiry by concordance and index functions , but has no textbase component</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus the TBMS is an integrated overall system consisting of file management system FMS data base management system DBMS text management system TMS method base management system MBMS user rA ... ... ... ..</sentence>
				<definiendum id="0">TBMS</definiendum>
			</definition>
			<definition id="2">
				<sentence>The following definition of the entire system is made , in analogy to the definitions of the individual components , in order to ensure that our terminology adequately reflects this state of affairs : ¥extbase management system = TBMS Branch : Linguistic data processing The TBMS is an information system that can administer texts and information on texts , and that makes texts accessible by integrating techniques from linguistic data processing and text processing .</sentence>
				<definiendum id="0">TBMS</definiendum>
				<definiens id="0">an information system that can administer texts and information on texts</definiens>
			</definition>
			<definition id="3">
				<sentence>A System Architecture I ( top level ) , which represents one way of realizing a TBMS is shown in Fig .</sentence>
				<definiendum id="0">System Architecture I</definiendum>
				<definiens id="0">top level ) , which represents one way of realizing a TBMS is shown in Fig</definiens>
			</definition>
			<definition id="4">
				<sentence>A word data base ( WDB ) is , formally spoken , a relation ranging over lexicographical features .</sentence>
				<definiendum id="0">word data base</definiendum>
				<definiendum id="1">WDB</definiendum>
				<definiens id="0">a relation ranging over lexicographical features</definiens>
			</definition>
</paper>

		<paper id="1092">
			<definition id="0">
				<sentence>PeriPhrase is a high-level computer language developed by A.L.P. Systems to facilitate parsing and structural transfer .</sentence>
				<definiendum id="0">PeriPhrase</definiendum>
				<definiens id="0">a high-level computer language developed by A.L.P. Systems to facilitate parsing and structural transfer</definiens>
			</definition>
			<definition id="1">
				<sentence>IL Per~ Syntax A PeriPhrase program consists of a declarations section followed by one or more rule packets .</sentence>
				<definiendum id="0">PeriPhrase program</definiendum>
				<definiens id="0">consists of a declarations section followed by one or more rule packets</definiens>
			</definition>
			<definition id="2">
				<sentence>PeriPhrase tries to match the pattern on the data being parsed .</sentence>
				<definiendum id="0">PeriPhrase</definiendum>
				<definiens id="0">tries to match the pattern on the data being parsed</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>\ [ 2\ ] CCRs have the form Vt : ~ , where 1T : is a schema and the notion of a possible schema is defined as follows : ( i ) ( R ( a , t ) ) and ( D ( ~ , t ) ) are of form g ; ( it ) if ~ is of form g , then ( ~ ) is of form n ; ( iiJ ) if Ip and x are both of form I~ , then ( ~0Kr ) is of form ~ , where K C ( A , V , D , e } ; ( iv ) constants designating categories occur as first arguments within all coastituent predicate expressions ; ( v ) the same variable t bound by the quantifier Vt occurs as second argument within all constituent predicate expressions ; ( vi ) these are all expressions of form ~ .</sentence>
				<definiendum id="0">] CCRs</definiendum>
				<definiendum id="1">1T</definiendum>
				<definiendum id="2">; ( iiJ</definiendum>
				<definiens id="0">a schema and the notion of a possible schema is defined as follows : ( i ) ( R ( a , t ) ) and ( D ( ~ , t ) ) are of form g ; ( it ) if ~ is of form g , then ( ~ ) is of form n</definiens>
			</definition>
			<definition id="1">
				<sentence>A CCR Vt : u may be rewritten in conjunctive normal form as Vt : ~ ^ ... A ~ , where each clause ot posltlve and predicate &lt; Pi is a disjunction . . n negated expressions , which is equivalent to V t : \ [ p\ ] ^ ... AVt : ~ , i.e. a conjunction of simple CCRs. -Let 0 } , be an e~pression of form n containing \ [ I\ ] I wish to thank Gerald Gazdar , Christa Hauenschild , William Keller , Daniel Maxwell , Manfred Pinkal , and Hans Uszkoreit for their comments on earlier versions of this paper. This work was carried out under the financial support of the BMFT of the German Federal Government. \ [ 2\ ] Interpretations of R ( ~ , t ) and D ( a , t ) in terms of the theory of feature instantiation in GKPS would be 'the root of local tree t is an extension of ~ ' and 'some daughter in local tree t is an extension of ~'. 50 only the predicate D ; then simple CCRs \ [ 3\ ] have the following forms : ( 4 ) Vt : R ( ~ , t ) \ ] ( 0 ' iff a I\ [ c0\ ] l Vt : 00 ' : \ ] R ( ~ , t ) iff Iko\ ] l Vt : ¢0 ' iff I\ [ 0 ) \ ] 1 iff ~ I\ [ . -- ~W\ ] l Quantification is ignored in the notation on the right ; ~ replaces P ( a , t ) and ~P ( ~ , t ) and ~-~ replaces ~P ( a , t ) giving 0o from ( 0 ' , where P = R or D. The special brackets ' I\ [ \ ] 1 ' enclose daughters and render the indication of material implication superfluous. Using this notation , ( 2 ) and ( 3 ) may be restated as ( 5 ) mid ( 6 ) , respectively : ( 5 ) S } \ [ A \ ] l ( 6 ) I\ [ C~D \ ] l To reformulate a set of ID rules we thus need ( a ) the definition of a set of branches constituting mother-daughter pairs and ( b ) an appropriate set of CURs. The definition of branches is permissive in the sense in which ID rules are permissive ( cf GKPS , p. 76 ) : branches with a conmmn mother can be adjoined to form a local tree. CCRs , like the LP rules , which also apply to local trees , are restrictive and limit the class of local trees admitted by the grammar. \ [ 4\ ] How sets of ID rules may be reformulated in this manner will be illustrated in the following section. GKPS ( pp. 47-49 ) exm , ines sets of simple context free rules and then proposes strongly equivalent descriptions in ID/LP format. One set of ID rules resulting from this reformulation is given in ( 7 ) : ( 7 ) S - &gt; NP , VP VP -~ V , VP S - &gt; AUX , NP , VP VP ~ &gt; V , NP VP - &gt; AUE , VP VP - &gt; V , NP , VP The ID rules of ( 7 ) admit local trees whose brancbes are among the following : ( 8 ) &lt; S , NP &gt; , &lt; S , VP &gt; , &lt; S , AUX &gt; , &lt; VP , V &gt; , &lt; VP , VP &gt; , &lt; VP , AUR &gt; , &lt; VP , NP &gt; Since none of the local trees admitted by ( 7 ) has more than one occurrence of a given category as daughter , we may say that the gran~ar first admits any strictly linearly ordered set \ [ 5\ ] of branches \ [ 3\ ] If categories are assumed to be atomic ( e.g. S , NP , V ) rather than complex for the moment , then it is unnecessary to mention more than one root category in a given CCR , \ [ 4\ ] Note that the distinction of permissive vs. restrictive statements is closely related to that of inherited vs. instontioted feature specifications in the feature instantiation principles of GPSG .</sentence>
				<definiendum id="0">CCR Vt</definiendum>
				<definiendum id="1">n negated expressions</definiendum>
				<definiendum id="2">LP rules</definiendum>
				<definiens id="0">a disjunction</definiens>
				<definiens id="1">the distinction of permissive vs. restrictive statements is closely related to that of inherited vs. instontioted feature specifications in the feature instantiation principles of GPSG</definiens>
			</definition>
			<definition id="2">
				<sentence>A single CCR covers the trees with S as root : ( 9 ) CCR 1 : S \ ] \ [ NP ^ VP \ ] l CUR 1 states that NP and VP are obligatory in any local tree with S as its root .</sentence>
				<definiendum id="0">CCR</definiendum>
				<definiens id="0">covers the trees with S as root : ( 9 ) CCR 1 : S \ ] \ [ NP ^ VP \ ] l CUR 1 states that NP and VP are obligatory in any local tree with S as its root</definiens>
			</definition>
			<definition id="3">
				<sentence>A corresponding CCR of the form VP I\ [ ( '~\ ] \ ] can now be formulated , where ( 0 is a Boolean expression in conjunctive normal form .</sentence>
				<definiendum id="0">corresponding CCR</definiendum>
				<definiens id="0">a Boolean expression in conjunctive normal form</definiens>
			</definition>
			<definition id="4">
				<sentence>Furthermore , the replacement of ID rules with CCRs is the essential prerequisite for the elimination of metarules described in section 2 .</sentence>
				<definiendum id="0">CCRs</definiendum>
			</definition>
			<definition id="5">
				<sentence>GKPS introduces not only metarules , e.g. the Passive Metarule ( p. 59 ) and the Extraposition Metarule ( p. 118 ) , but also related lexical rules involving the same phenomena , e.g. the Lexieal Rule for Passive Forms ( p. 219 ) and the Lexical Rule for Extraposition Verbs ( p. 222 ) .</sentence>
				<definiendum id="0">Passive Metarule</definiendum>
				<definiendum id="1">Extraposition Metarule</definiendum>
				<definiens id="0">the Lexieal Rule for Passive Forms ( p. 219 ) and the Lexical Rule for Extraposition Verbs ( p. 222 )</definiens>
			</definition>
			<definition id="6">
				<sentence>A feature specification is an ordered pair &lt; f , v &gt; containing a feature nmne f and value v , where the latter is restricted by the feature-value rmlge of the former , h category is a set of feature specifications such that no feature name is assigned more than one value ; it is legal iff it fulfills all Feature Cooccurrence Restrictions .</sentence>
				<definiendum id="0">feature specification</definiendum>
				<definiens id="0">an ordered pair &lt; f , v &gt; containing a feature nmne f and value v</definiens>
			</definition>
			<definition id="7">
				<sentence>\ [ 8\ ] A tree is an ordered pair consisting of a legal root category and a list of daughters , where each dau~ , ter is either a tree or a word form .</sentence>
				<definiendum id="0">A tree</definiendum>
				<definiens id="0">an ordered pair consisting of a legal root category and a list of daughters</definiens>
			</definition>
			<definition id="8">
				<sentence>As in GKPS , an FCR requires that a category specified &lt; NUI , L , + &gt; also be specified for SLASH : ( 41 ) \ [ +NULL\ ] ~ \ [ SLASH\ ] ( FCR 19 ) The distribution of SI , AStI is in turn governed by the CAP , HFC , and FFP .</sentence>
				<definiendum id="0">AStI</definiendum>
				<definiens id="0">in turn governed by the CAP , HFC , and FFP</definiens>
			</definition>
</paper>

		<paper id="1051">
			<definition id="0">
				<sentence>Another deficiency of tile database in ( l ) is that it knows nothing about John , Mary and their relationship , even though English speakers share descriptions of the typical objects in the sets defined by the predicates Human , Teacher and Student .</sentence>
				<definiendum id="0">tile database</definiendum>
				<definiens id="0">that it knows nothing about John , Mary and their relationship , even though English speakers share descriptions of the typical objects in the sets defined by the predicates Human , Teacher and Student</definiens>
			</definition>
			<definition id="1">
				<sentence>5 ) ~ lntelllgent ( mary ) A Teacher ( mary ) 6 ) ( Remainder ( X/2 ) = 0 ) A Oddnumber ( X ) A system needs the capacity to reason with prototype information assnelated with concepts .</sentence>
				<definiendum id="0">mary ) A Teacher</definiendum>
				<definiendum id="1">Remainder</definiendum>
				<definiendum id="2">Oddnumber ( X</definiendum>
				<definiendum id="3">system</definiendum>
				<definiens id="0">needs the capacity to reason with prototype information assnelated with concepts</definiens>
			</definition>
			<definition id="2">
				<sentence>Though other formalisms could be used to represent empirically-derived models of human commonsense knowledge , KT lends itself to representins the diversity of information found in the data because it allows a vlrtually unlimited number of features , while organizing them with the kind types .</sentence>
				<definiendum id="0">KT</definiendum>
				<definiens id="0">lends itself to representins the diversity of information found in the data because it allows a vlrtually unlimited number of features</definiens>
			</definition>
			<definition id="3">
				<sentence>The Kind~~ KT reads geography text , and shows its understanding of the textby answering questions .</sentence>
				<definiendum id="0">Kind~~ KT</definiendum>
				<definiens id="0">reads geography text , and shows its understanding of the textby answering questions</definiens>
			</definition>
			<definition id="4">
				<sentence>A herd consists of animals .</sentence>
				<definiendum id="0">herd</definiendum>
			</definition>
			<definition id="5">
				<sentence>Entities ( or events ) which come into being ( or take place ) naturally must be distinguished from those which arise through some sort of social intervention .</sentence>
				<definiendum id="0">Entities</definiendum>
				<definiens id="0">or events ) which come into being ( or take place ) naturally must be distinguished from those which arise through some sort of social intervention</definiens>
			</definition>
			<definition id="6">
				<sentence>ARTIFACT is one of the SOCIAL nodes .</sentence>
				<definiendum id="0">ARTIFACT</definiendum>
			</definition>
			<definition id="7">
				<sentence>KT limits these combinations by taking advantage of several important ontological constraints affecting the possible real-world objects and therefore possible combinations of features in commonsense knowledge .</sentence>
				<definiendum id="0">KT</definiendum>
				<definiens id="0">limits these combinations by taking advantage of several important ontological constraints affecting the possible real-world objects and therefore possible combinations of features in commonsense knowledge</definiens>
			</definition>
			<definition id="8">
				<sentence>The Inference Mecharfism Built into the natural language component by Stabler and Tarnawsky is a mctainterpreter which solves queries of all axioms active in the system .</sentence>
				<definiendum id="0">Tarnawsky</definiendum>
				<definiens id="0">Inference Mecharfism Built into the natural language component by Stabler and</definiens>
				<definiens id="1">a mctainterpreter which solves queries of all axioms active in the system</definiens>
			</definition>
			<definition id="9">
				<sentence>and that `` A clinic is a social place , place , inaninmte , physical , stationary , social , real , individual . ''</sentence>
				<definiendum id="0">clinic</definiendum>
			</definition>
			<definition id="10">
				<sentence>Thus KT makes the open world assumption except with regard to ontological classifica .</sentence>
				<definiendum id="0">KT</definiendum>
				<definiens id="0">makes the open world assumption except with regard to ontological classifica</definiens>
			</definition>
			<definition id="11">
				<sentence>When KT looks first at the translation of the text to see whether it contains an assertion which states a color for tile eggs , it must distinguish tile facts in the text which arc relevant to the feature type queried .</sentence>
				<definiendum id="0">KT</definiendum>
				<definiens id="0">looks first at the translation of the text to see whether it contains an assertion which states a color for tile eggs , it must distinguish tile facts in the text which arc relevant to the feature type queried</definiens>
			</definition>
			<definition id="12">
				<sentence>Using kind types for selection restrictions , KT infers that the entity named ABC is a SENTIENT .</sentence>
				<definiendum id="0">KT</definiendum>
				<definiendum id="1">ABC</definiendum>
				<definiens id="0">a SENTIENT</definiens>
			</definition>
			<definition id="13">
				<sentence>Q : Does John eat eggs .</sentence>
				<definiendum id="0">Q</definiendum>
				<definiens id="0">Does John eat eggs</definiens>
			</definition>
			<definition id="14">
				<sentence>Q : Does John look like a clinic7 A : No. -- -By ontology database .</sentence>
				<definiendum id="0">Q</definiendum>
				<definiens id="0">Does John look like a clinic7 A : No. -- -By ontology database</definiens>
			</definition>
			<definition id="15">
				<sentence>Similarly , STUFF is the collective nf MINERAl_ , INSTH'UTION is the collective of ROLl ?</sentence>
				<definiendum id="0">STUFF</definiendum>
				<definiendum id="1">INSTH'UTION</definiendum>
				<definiens id="0">the collective nf MINERAl_</definiens>
			</definition>
			<definition id="16">
				<sentence>, and BODY is the collective of PERSON , etc .</sentence>
				<definiendum id="0">BODY</definiendum>
			</definition>
			<definition id="17">
				<sentence>Co eclusjot~ hi conclusion , KT encodes an ontology which omdels the top level of typical t~'nglish speaker 's cognitive model ef the actual wolld .</sentence>
				<definiendum id="0">KT</definiendum>
				<definiens id="0">encodes an ontology which omdels the top level of typical t~'nglish speaker 's cognitive model ef the actual wolld</definiens>
			</definition>
			<definition id="18">
				<sentence>Because of this empirical basis , and the breadth of the ontology , KT is a transportable syslcm which is potentially useful for understanding any text of a general , literal nat'tn'e , Ashcralt , M.II .</sentence>
				<definiendum id="0">KT</definiendum>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>FGD can be characterized as follows : ( i ) FGD is a multilevel ( stratificational ) system of explicit description of language , consisting of a generative component and of several levels of description , which are ordered from meaning to sound and related by a complex interplay of cases of homonymy ( ambiguity } and synonymy on the basis of the asyrm~etrie dualism between form and function .</sentence>
				<definiendum id="0">FGD</definiendum>
				<definiens id="0">a multilevel ( stratificational ) system of explicit description of language , consisting of a generative component and of several levels of description</definiens>
			</definition>
			<definition id="1">
				<sentence>Most important of them is the topic-focus ariculation ( TFA ) of a sentence , which includes the partitioning of a sentence into topic ( conveying the old/given/salient/pres.upposed/contextually bound information ) and focus ( conveying the new/contextually non-bound information ) , and the deep word-order of a sentence , which is formal ly accountable for by the left-to right ordering of the nodes of the underlying dependency tree .</sentence>
				<definiendum id="0">TFA</definiendum>
				<definiendum id="1">focus</definiendum>
				<definiendum id="2">a sentence</definiendum>
				<definiens id="0">includes the partitioning of a sentence into topic ( conveying the old/given/salient/pres.upposed/contextually bound information</definiens>
			</definition>
			<definition id="2">
				<sentence>We argue that in the unmarked case , CA expressions ( which can be viewed as specifying , in a broad sense of the word , how the information conveyed by the focus holds e.g. it surprisingly holds , it probably holds , it does not hold , it for exampLLel e holds ) occupy the focus-initial position , extending their scope over the rest of the focus of the sentence ( this `` rest of the focus '' may consist of syntactically different elements , e.g. it may but need not contain the verb , it may contain one or more complementations , etc. ; for example , if there are four elements in a sentence ( the verb and three complementations ) , they can be arranged into 15 different distributions of elements in the topic and the focus of the sentence ) .</sentence>
				<definiendum id="0">CA expressions</definiendum>
				<definiens id="0">specifying , in a broad sense of the word , how the information conveyed by the focus holds e.g. it surprisingly holds</definiens>
				<definiens id="1">the verb and three complementations ) , they can be arranged into 15 different distributions of elements in the topic and the focus of the sentence )</definiens>
			</definition>
			<definition id="3">
				<sentence>( i ) In the tol ) ic of a sentence , CA expressions occur very rarely and exhibit idiosyncratic scoping properties ; for exainple , not has in is scope usually the verb ( belonging to the topic ) , while the other focussing adverbials ( such as only_ have in their scope the iranedi a te ly fol lowing ( noun ) phrase ( belonging to the topic ) .</sentence>
				<definiendum id="0">CA expressions</definiendum>
				<definiens id="0">occur very rarely and exhibit idiosyncratic scoping properties</definiens>
			</definition>
</paper>

		<paper id="1101">
			<definition id="0">
				<sentence>~lapp &lt; ird~'t d ( i/is XQ dictlOllrlJlre Tt. qua } SOtlS forille d~ 50fl equi valellt ell larlgue ciDl ( ; o ~e p ) U~I ~a P~ # : II~FFII lJerlTlet d~ ¢le pas I ( - ' rL'ploduir~ ( Idrls I~eqlJivaloflt Lorlte~tunl R£10~I ) EtJSE Obtenu jr~co h i a PAl `` A2 '' . Pour \ ] 'ORr ) RE I eS I ) ~I ~'VF '' ( ! t i'i { l '' cur r ( ~spofldeat f r e sp { aE L \ [ VOlllellt t d I ' ex i~ ; tence ( ILl SUDSi ; antlf verbal fOnlirlill IDRS\ [ IJN derive dn \ ] tiflflnltlfl eL Jtl pnolloMOIIn contrastil un reflexivitY , i ) o~sible poul le velbe russo et pour le verbe £r &lt; lnCai~o i ) t ) ur VRILL ( { R~ t 4J ~IVI~'~ deflote I e subs ( anti f verbal I iil.I scul 1 n V ( { \ [ LLAGE~ ot la IIX \ [ 11 le I &lt; llt ttul # los aQu× vQrD~s t rdfl ( , di S 5urlt s yn o fl y ( R { # S lout ( ~ I ( ! s UL frdncalses doiv ( } llt rl , ltwrel\ ] em { ! llt I } l ; l-e Lrldexee % doris ! e Oic. t ! ~E~dir_£_.~ &lt; ~Jo Pour I '' ORI ) ~ { - , i l . y par e×eaIple : la base TORuANTI &lt; lvec l &lt; } Pill '~Ai ) I~ ( I ) OUF I'odjectlf ) el ; ie FM `` NU\ [ R 'l ( pour les tormes \ [ ORDANT ( O~ S , i-~ kS ) ) ~ la b ( \ ] se ToRgEu~ avec la PRE `` NIl ) '° ( pour In suosta~ltif ( l~riv ( ; du verbe ) et le FM `` EUSE '' ( pour los formes I ' ( \ ] ROEd ( 1 { ~ RSI S£1 SES ) , la base YL\ ] RUAGE0 avec la PRL I'NVL4MAS~I ( pour le hem rrlascu\ ] ill d ( ~ri v ( ~ du verbe ) avec le F ~4 `` ~IOT '' ( pour los foriFleS TORDA~qE ( 0~ S ) i \ ] a base \ [ O~SI\ [ C\ ] ~ avec la PRC `` NVbFEM '' ( pour \ ] e nora Ferninin d~ ; rlve uu ver ! ) e ) , } vet le I : M ..t4nr. , ( pour los formes \ [ OKSIQN lot S ) et entinl unc • deroiere 119r/e de ce dictJoenairet obl i..jatoirellieat SilllS Pf { \ [ ~9 donrio la base t-\ [ JR\ [ ) t 0 partir dn laqua\ ] le on peut , j~nerer tout le 3ar { ldigme du v { ~rl ) ~ IOftDRf } ~ Cteci donnet los articles suivants : , ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... + ! ( l. O , ITL ×l-E &gt; -= /R\ [ KN i '' !</sentence>
				<definiendum id="0">ie FM</definiendum>
				<definiens id="0">V ( { \ [ LLAGE~ ot la IIX \ [ 11 le I &lt; llt ttul # los aQu× vQrD~s t rdfl ( , di S 5urlt s yn o fl y</definiens>
			</definition>
</paper>

		<paper id="1059">
			<definition id="0">
				<sentence>RINA : The Judge threw the book at him .</sentence>
				<definiendum id="0">RINA</definiendum>
				<definiens id="0">The Judge threw the book at him</definiens>
			</definition>
			<definition id="1">
				<sentence>Initially , RINA attempts to interpret the text using the literal phrase to throw an object at a person .</sentence>
				<definiendum id="0">RINA</definiendum>
				<definiens id="0">attempts to interpret the text using the literal phrase to throw an object at a person</definiens>
			</definition>
			<definition id="2">
				<sentence>When this interpretation fails , RINA forms a hypothesis about the new phrase .</sentence>
				<definiendum id="0">RINA</definiendum>
				<definiens id="0">forms a hypothesis about the new phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>The program consists of four components : ( 1 ) Phrasal lexicon : This is a list of phrases where each phrase is a declarative pattern-concept-situation triple .</sentence>
				<definiendum id="0">Phrasal lexicon</definiendum>
				<definiens id="0">a list of phrases where each phrase is a declarative pattern-concept-situation triple</definiens>
			</definition>
			<definition id="4">
				<sentence>y : thing Due to the type of the reference ( i.e. , a yellow Mercedes is a vehicle ) , the phrase P5 ( vehicle collision ) is selected , iIowever , the type of the reference might lead to an incorrect selection .</sentence>
				<definiendum id="0">yellow Mercedes</definiendum>
				<definiens id="0">a vehicle ) , the phrase P5 ( vehicle collision</definiens>
			</definition>
			<definition id="5">
				<sentence>The context in both $ 14 and S15 is the asymmetrical authority relationship .</sentence>
				<definiendum id="0">S15</definiendum>
				<definiens id="0">the asymmetrical authority relationship</definiens>
			</definition>
			<definition id="6">
				<sentence>Literal Interpretation In the absence of the appropriate phrase in the lexicon , RINA utilizes other available knowledge sources , namely ( a ) the literal interpretation and ( b ) the context .</sentence>
				<definiendum id="0">RINA</definiendum>
				<definiens id="0">utilizes other available knowledge sources , namely ( a ) the literal interpretation and ( b ) the context</definiens>
			</definition>
</paper>

		<paper id="1119">
			<definition id="0">
				<sentence>Reughly speaking , DRS is a sequence of D ( iscourse ) R ( epresentations ) ~ DR is nothing else than a partial modeI~ describing discourse objects and their tel\ [ aliens .</sentence>
				<definiendum id="0">DRS</definiendum>
				<definiens id="0">a sequence of D ( iscourse ) R ( epresentations ) ~ DR is nothing else than a partial modeI~ describing discourse objects and their tel\ [ aliens</definiens>
			</definition>
			<definition id="1">
				<sentence>V~'e start with the empby DR. Each discourse utterance extends the actual DR by adding appropriate information contained in the utterance , qFo construct any DR , some kind of reasoning mechanism is needed .</sentence>
				<definiendum id="0">discourse utterance</definiendum>
				<definiens id="0">extends the actual DR by adding appropriate information contained in the utterance</definiens>
			</definition>
			<definition id="2">
				<sentence>V~'e postulate the application of the nonmonotonic inference system for that purpose .</sentence>
				<definiendum id="0">V~'e</definiendum>
				<definiens id="0">postulate the application of the nonmonotonic inference system for that purpose</definiens>
			</definition>
			<definition id="3">
				<sentence>But we are prepared to reject this conclusion , if we learn theft ( Dweety is a pinguiru In default logic the rule about birds is represen\ [ ed by the following default : bird ( x ) : M flies ( x ) / flies ( x ) with the intended interpretation : `` for each individual x , if x is a bird and i { is consistent to assume that x flies , then it may be assumed that x flies '' .</sentence>
				<definiendum id="0">Dweety</definiendum>
				<definiens id="0">a bird and i { is consistent to assume that x flies</definiens>
			</definition>
			<definition id="4">
				<sentence>Defaults extend the information contained in axioms by sanctioning plausible , but not necessarily true , conclusions .</sentence>
				<definiendum id="0">Defaults</definiendum>
				<definiens id="0">extend the information contained in axioms by sanctioning plausible , but not necessarily true , conclusions</definiens>
			</definition>
</paper>

		<paper id="1067">
			<definition id="0">
				<sentence>A Bunsetsu is a Japanese syntactic unit which usually consists of an independent word followed by a sequence of dependent words .</sentence>
				<definiendum id="0">Bunsetsu</definiendum>
				<definiens id="0">a Japanese syntactic unit which usually consists of an independent word followed by a sequence of dependent words</definiens>
			</definition>
			<definition id="1">
				<sentence>language A Japanese sentence is composed of a string of Bunsetsu , and each Bunsetsu is a string of morphemes .</sentence>
				<definiendum id="0">Bunsetsu</definiendum>
				<definiens id="0">a string of morphemes</definiens>
			</definition>
			<definition id="2">
				<sentence>The VTX represents the position of morpheme in a sentence .</sentence>
				<definiendum id="0">VTX</definiendum>
				<definiens id="0">the position of morpheme in a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>The EDG represents the common attributes of the ambiguous morphemes .</sentence>
				<definiendum id="0">EDG</definiendum>
				<definiens id="0">the common attributes of the ambiguous morphemes</definiens>
			</definition>
			<definition id="4">
				<sentence>The ABL represents individual attributes of the morphemes .</sentence>
				<definiendum id="0">ABL</definiendum>
			</definition>
			<definition id="5">
				<sentence>A VTX is considered to be shared if the grammatical relationship between the preceeding EDG and its succeeding EDG is the same .</sentence>
				<definiendum id="0">VTX</definiendum>
				<definiendum id="1">EDG</definiendum>
				<definiens id="0">the same</definiens>
			</definition>
			<definition id="6">
				<sentence>The leasL Bunsetsu number \ [ 5\ ] is known as an effective heuristic approach for determining the segmentation of non-segmented input Kana sentences .</sentence>
				<definiendum id="0">leasL Bunsetsu</definiendum>
			</definition>
			<definition id="7">
				<sentence>In Figure 3 , VTX ( O ) and VTX ( n ) correspond to the beginning and the end of a sentence , respectively .</sentence>
				<definiendum id="0">VTX</definiendum>
				<definiens id="0">n ) correspond to the beginning and the end of a sentence</definiens>
			</definition>
			<definition id="8">
				<sentence>X ( ij ) is the weight of the EDG ( ij ) .</sentence>
				<definiendum id="0">X</definiendum>
			</definition>
			<definition id="9">
				<sentence>For the VTX ( n ) W ( n ) =0 ( 1 ) Generally , for EDG ( ij ) W ( ij ) -= W ( j ) -F X ( ij ) ( 2 ) And for VTX ( i ) W ( i ) -rain { W ( ij ) ~ ( 3 ) J This means that the minimun W ( ij ) is selected among the EDGs which share VTX ( i ) on their left side .</sentence>
				<definiendum id="0">VTX ( n ) W</definiendum>
				<definiens id="0">the minimun W ( ij ) is selected among the EDGs which share VTX ( i ) on their left side</definiens>
			</definition>
			<definition id="10">
				<sentence>The system consists of three subsystems : a translation control program , a morphological analysis program and a syntactic and semantic analysis program .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of three subsystems : a translation control program , a morphological analysis program and a syntactic and semantic analysis program</definiens>
			</definition>
</paper>

		<paper id="1068">
			<definition id="0">
				<sentence>If_ D ( W ) = ( R l ' Pl ifl ' SI ) 'RI G V+and PI , II , SICV~ anji ( W ) = ( R2 , P2 , I2 , S2 ) , R2£V + and P2,12 , $ 2 e V x So R 1 is the selected root ( R 2 is rejected ) F , X : ~a£a2ta .</sentence>
				<definiendum id="0">SICV~ anji</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">the selected root ( R 2 is rejected</definiens>
			</definition>
</paper>

		<paper id="1096">
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>Pullum 's theory is known as ID/LP analysis 2 According to this theory grammar ( 2.1 ) `` would be specified by means of the metagrammar '' given in ( 2.3 ) .</sentence>
				<definiendum id="0">Pullum 's theory</definiendum>
			</definition>
			<definition id="1">
				<sentence>( parse ( mohan anDaa khaataa hat ) ) Mohan egg eats is `` Mohan eats an egg '' ( S ( NP-subj ( NP ( DET nil ) ( ADJ ) ( N mohan ) ) ( K-ag nil ) ) ( NP-Ind nil ( K-dat nil ) ) ( NP-obj ( NP ( DET nil ) ( ADJ ) ( i anDaa ) ) ) ( VX : ( ADV ) ( V khaataa ( AUX hal ) ) ) ) t ( 3.22 ) ( p ... . ( anDaa mohan khaataa hal ) ) `` Mohan eats an egg '' ( S ( NP-subj ( NP ( DET nil ) ( ADJ ) ( N mohan ) ) ( K-ag nil ) ) ( NP-ind nll ( K-dat nil ) ) ( NP-obj ( NP ( DET nil ) ( ADJ ) ( N anDaa ) ) ) ( VX ( ADV ) ( V khaataa ( AUX hai ) ) ) ) t Processing word order variation with new techniques within the modified ID/LP framework seems to be revealing .</sentence>
				<definiendum id="0">NP-Ind nil</definiendum>
				<definiens id="0">DET nil ) ( ADJ ) ( i anDaa ) ) ) ( VX : ( ADV ) ( V khaataa ( AUX hal ) )</definiens>
				<definiens id="1">DET nil ) ( ADJ ) ( N mohan ) ) ( K-ag nil ) ) ( NP-ind nll ( K-dat nil ) ) ( NP-obj ( NP ( DET nil ) ( ADJ )</definiens>
				<definiens id="2">V khaataa ( AUX hai ) ) ) ) t Processing word order variation with new techniques within the modified ID/LP framework seems to be revealing</definiens>
			</definition>
			<definition id="2">
				<sentence>`` Word Order Variation : A Typological Study , '' in J. Greenberg ( ed . )</sentence>
				<definiendum id="0">Word Order Variation</definiendum>
				<definiens id="0">A Typological Study , '' in J. Greenberg ( ed .</definiens>
			</definition>
</paper>

		<paper id="1143">
			<definition id="0">
				<sentence>A number ol units have been used and discussed as the elementary recognition or synthesis units , e.g. , the phone , the diphone , the phoneme , the demi-syllable , and the syllable .</sentence>
				<definiendum id="0">number ol units</definiendum>
				<definiens id="0">the elementary recognition or synthesis units</definiens>
			</definition>
			<definition id="1">
				<sentence>It consists only of the elements C and V , where V denotes the syllabic nucleus of the syllable and C a consonantal position in the syllable .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the syllabic nucleus of the syllable and C a consonantal position in the syllable</definiens>
			</definition>
</paper>

		<paper id="1145">
			<definition id="0">
				<sentence>If you need a spare part ( a word ) , but you know only what type of a screw ( CV syllable ) you have in it and what type of machine ( context and sentence information ) it might be used in , the warehouse administration ( the parser ) will provide you with the spare part you have been looking for .</sentence>
				<definiendum id="0">warehouse administration</definiendum>
				<definiens id="0">a word ) , but you know only what type of a screw ( CV syllable ) you have in it and what type of machine ( context and sentence information</definiens>
				<definiens id="1">the parser ) will provide you with the spare</definiens>
			</definition>
			<definition id="1">
				<sentence>A parser which takes no account of the vowel in the syllable can not be expected to realize that a rising and a falling transition are cues for the same phoneme .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">takes no account of the vowel in the syllable can not be expected</definiens>
			</definition>
</paper>

		<paper id="1136">
			<definition id="0">
				<sentence>The focus of a RC query is a relation in the current DB .</sentence>
				<definiendum id="0">RC query</definiendum>
			</definition>
			<definition id="1">
				<sentence>cust~name= '' Maehines-Ltd '' ) ) ) ) ) ) ) } Selected focus : PRODUCT Paraphrase : For products which are ordered and which are contained in orders whose number is smaller than 458879 and which are placed by customers whose name is Vegetable Assoc or whose name is Machines LTD ( I ) give details of each order involved ( 2 ) show the customer names .</sentence>
				<definiendum id="0">PRODUCT Paraphrase</definiendum>
				<definiens id="0">For products which are ordered and which are contained in orders whose number is smaller than 458879 and which are placed by customers whose name is Vegetable Assoc or whose name is Machines LTD</definiens>
			</definition>
			<definition id="2">
				<sentence>\ [ 14\ ] M. WALLACE and V. WEST , `` QPROC : A Natural Language Database Enquiry System Inplemented in Prolog '' , in ICL Technical Journal , November 1983 .</sentence>
				<definiendum id="0">QPROC</definiendum>
				<definiens id="0">A Natural Language Database Enquiry System Inplemented in Prolog ''</definiens>
			</definition>
</paper>

		<paper id="1121">
			<definition id="0">
				<sentence>Abstract : The dominant philosophy regarding the formalization of Commonsense Inferencing in the physical domain consists in the exploitation of the `` tarskian '' scheme axiomatization &lt; - &gt; interpretation borrowed from mathematical logic .</sentence>
				<definiendum id="0">Abstract</definiendum>
				<definiens id="0">The dominant philosophy regarding the formalization of Commonsense Inferencing in the physical domain consists in the exploitation of the `` tarskian '' scheme axiomatization &lt; - &gt; interpretation borrowed from mathematical logic</definiens>
			</definition>
			<definition id="1">
				<sentence>conmaonsense in the psychological domain : a murder consists in an intentional killing , i.e. with a plan the goal of which is the death of somebody .</sentence>
				<definiendum id="0">murder</definiendum>
				<definiens id="0">consists in an intentional killing</definiens>
			</definition>
</paper>

		<paper id="1122">
			<definition id="0">
				<sentence>A cognitive component X : Z is distinguished in X which is a reflection of in X ( X 's beliefs about Z 's knowledge including Z 's beliefs about his partner X 's state of knowledge ) , i.e. a set of utterances of the form P=Z : P ' .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a reflection of in X ( X 's beliefs about Z 's knowledge including Z 's beliefs about his partner X 's state of knowledge )</definiens>
			</definition>
			<definition id="1">
				<sentence>Tile nucleous of integral content of tile SAA is a propositional structure , in the simplest case , a proposition P which represents S in a generalized and semantically structured form .</sentence>
				<definiendum id="0">tile SAA</definiendum>
				<definiens id="0">a propositional structure , in the simplest case , a proposition P which represents S in a generalized and semantically structured form</definiens>
			</definition>
			<definition id="2">
				<sentence>so , the P.-SAA IP is a combination of two E-SAA IPs , one of them introducing the positive evaluation of Q and the other negatively evaluating P ; a constituent ( b ) is added to the P-SAA IP and w-values are specified .</sentence>
				<definiendum id="0">P.-SAA IP</definiendum>
				<definiens id="0">a combination of two E-SAA IPs</definiens>
			</definition>
</paper>

		<paper id="1142">
			<definition id="0">
				<sentence>The word predictor receives a node and its parsing history from the controller and predicts the syntactic cate~ gories following the node .</sentence>
				<definiendum id="0">word predictor</definiendum>
				<definiens id="0">receives a node and its parsing history from the controller and predicts the syntactic cate~ gories following the node</definiens>
			</definition>
			<definition id="1">
				<sentence>'link ( C , G ) is a predicate to express that a string of which the left most symbol is a nonterminal C can be reduced to a nonterminal G. G is called a goal argument in this sense .</sentence>
				<definiendum id="0">most symbol</definiendum>
				<definiens id="0">a predicate to express that a string of which the left</definiens>
			</definition>
			<definition id="2">
				<sentence>'link ' is defined as follows : if the rule I ) is included in the grammar , then 'link ( cl , c ) ' holds , and if 'link ( a , b ) ' and 'link ( b , c ) ' &amp; old , then 'link ( a , c ) ' holds ( transitive law ) , and 'link ( c , c ) ' holds for every nonterminal c ( reflective law ) .</sentence>
				<definiendum id="0">c ) ' holds</definiendum>
				<definiens id="0">if the rule I ) is included in the grammar , then 'link ( cl , c ) ' holds , and if 'link ( a , b ) ' and 'link ( b , c ) ' &amp; old</definiens>
				<definiens id="1">transitive law ) , and 'link ( c , c ) ' holds for every nonterminal c ( reflective law )</definiens>
			</definition>
			<definition id="3">
				<sentence>In this case a rule can be expressed as follows : C ( So ) - &gt; \ [ Po ( So , SI ) } CI ( SI ) { PI ( SI , S2 ) } C2 ( S2 ) ... { Pn_l ( Sn_l , Sn ) ) Cn ( Sn ) , where S~ ( i=O , l ... . n ) is a list of semantic markers , Pi ( i=l,2 ... . n ) is a predicate to denote a constraint among semantic markers .</sentence>
				<definiendum id="0">S~</definiendum>
				<definiendum id="1">n )</definiendum>
				<definiendum id="2">Pi</definiendum>
				<definiendum id="3">n )</definiendum>
				<definiens id="0">a list of semantic markers</definiens>
				<definiens id="1">a predicate to denote a constraint among semantic markers</definiens>
			</definition>
</paper>

		<paper id="1069">
			<definition id="0">
				<sentence>Woif~ E. ( \ ] 977 ) : Vom BuchsLaben zum Laut .</sentence>
				<definiendum id="0">Woif~ E.</definiendum>
				<definiens id="0">Vom BuchsLaben zum Laut</definiens>
			</definition>
</paper>

		<paper id="1098">
</paper>

		<paper id="1112">
			<definition id="0">
				<sentence>= `` l &lt; form &gt; b. &lt; list manipulation , : : : PUSH t POP t INSERT data item &lt; data &gt; : := any data dtem &gt; : = &lt; form &gt; FIND path test level dtype FINDVAL path test level dtype f LOCATE path test level dtype &lt; path , :~= &lt; label , &gt; &lt; test &gt; : : = Tinny test &lt; level &gt; : :TICL &lt; dtype &gt; : = TINDJL The basic storing action is ADD which is used to store any incoming piece of structure .</sentence>
				<definiendum id="0">ADD</definiendum>
				<definiens id="0">PUSH t POP t INSERT data item &lt; data &gt; : := any data dtem &gt; : = &lt; form &gt; FIND path test level dtype FINDVAL path test level dtype f LOCATE path test level dtype &lt; path , :~= &lt; label , &gt; &lt;</definiens>
			</definition>
			<definition id="1">
				<sentence>Extraction of information is done by the forms FIND , which returns a pair , and FINDVAL , which returns only the vMue of a pair .</sentence>
				<definiendum id="0">FINDVAL</definiendum>
				<definiens id="0">returns a pair</definiens>
			</definition>
			<definition id="2">
				<sentence>LOCATE works exactly in the same way , ,but returns a pointer to a given radix .</sentence>
				<definiendum id="0">LOCATE</definiendum>
				<definiens id="0">works exactly in the same way , ,but returns a pointer to a given radix</definiens>
			</definition>
			<definition id="3">
				<sentence>PUSH , POP , and INSERT , manipulate the items in the list .</sentence>
				<definiendum id="0">INSERT</definiendum>
				<definiens id="0">manipulate the items in the list</definiens>
			</definition>
			<definition id="4">
				<sentence>PUSlt adds anew ( empty ) item in front of the list .</sentence>
				<definiendum id="0">PUSlt</definiendum>
				<definiens id="0">adds anew ( empty ) item in front of the list</definiens>
			</definition>
			<definition id="5">
				<sentence>POP removes the current top-item and embeds it into the new top-item , possibly assigning a label to the corresponding component .</sentence>
				<definiendum id="0">POP</definiendum>
				<definiens id="0">removes the current top-item</definiens>
			</definition>
</paper>

		<paper id="1113">
			<definition id="0">
				<sentence>The concatenation operator creates a composite memory vector encoding individual items or vectors ( &lt; A &gt; + &lt; B &gt; ) .</sentence>
				<definiendum id="0">concatenation operator</definiendum>
				<definiens id="0">creates a composite memory vector encoding individual items or vectors ( &lt; A &gt; + &lt; B &gt; )</definiens>
			</definition>
			<definition id="1">
				<sentence>The parsing mechanism consists of three distributed memory units , one permanent unit which stores context-free rule patterns , and two working memory units which encode temporary constituent structures .</sentence>
				<definiendum id="0">parsing mechanism</definiendum>
				<definiens id="0">consists of three distributed memory units , one permanent unit which stores context-free rule patterns , and two working memory units which encode temporary constituent structures</definiens>
			</definition>
			<definition id="2">
				<sentence>Thompson , H.S. ( 1983 ) MCHART : A flexible , modular chart parsing system .</sentence>
				<definiendum id="0">MCHART</definiendum>
				<definiens id="0">A flexible , modular chart parsing system</definiens>
			</definition>
</paper>

		<paper id="1073">
			<definition id="0">
				<sentence>Constituentgrammars ( C-~ ) are based on the part/whole relation and define a hierarchical structure with the respective higher ranking category defined as being composed of the lower ranking ones .</sentence>
				<definiendum id="0">Constituentgrammars</definiendum>
				<definiens id="0">C-~ ) are based on the part/whole relation and define a hierarchical structure with the respective higher ranking category defined as being composed of the lower ranking ones</definiens>
			</definition>
			<definition id="1">
				<sentence>A sentence S with a featrLre description FD consists of the pattern with a governing verb with a feature de~ciption FD and a compl~ent eonfiguration each cc~lement with a featuz~ description FO plus an arbitrary number of adjtmct~s each adjunct wit/~ a feature description FD~ ~he above proposed subclassification by syntactic realization can be .</sentence>
				<definiendum id="0">sentence S</definiendum>
				<definiens id="0">consists of the pattern with a governing verb with a feature de~ciption FD and a compl~ent eonfiguration each cc~lement with a featuz~ description FO plus an arbitrary number of adjtmct~s each adjunct wit/~ a feature description FD~ ~he above proposed subclassification by syntactic realization can be</definiens>
			</definition>
</paper>

		<paper id="1030">
</paper>

		<paper id="1082">
			<definition id="0">
				<sentence>Case based approaches to the semantics of directional modifiers can be characterized as weakly compositional in the following sense : In a verb phrase such as fly to Chicago the prepositional phrase contributes semantically the meaning of the NP Chicago ' as the directional or locative goal of the action associated with ~ .</sentence>
				<definiendum id="0">directional modifiers</definiendum>
				<definiens id="0">the prepositional phrase contributes semantically the meaning of the NP</definiens>
			</definition>
			<definition id="1">
				<sentence>Fallo~ing Davidson ( 1977 ) , the rightmcst argument position r ~n~ , es over events , or more specifically over evenl 347 stages which realize the event that the referents of the subject and object NPs are engaged in .</sentence>
				<definiendum id="0">Fallo~ing Davidson</definiendum>
				<definiens id="0">es over events , or more specifically over evenl 347 stages which realize the event that the referents of the subject</definiens>
			</definition>
</paper>

		<paper id="1045">
			<definition id="0">
				<sentence>( 14 ) Peter called him very angrily N ( S\N ) /N N ( ( S\N ) \ ( SLN ) ) / ( S\N ) / ( S~X\ [ ) ( ( S\N ) \ ( S~N ' ) ) ( 15 ) *Peter called him very N ( S\N ) /N N ( ( S\N ) \ ( S~ ) ) / ( ( S\N ) \ ( S\N ) ) at work ( S\N ) / ( S~ ) If functor categories are permitted to carry features of their own that are not necessarily bound to to any features of their argument and value categories , this problem disappears .</sentence>
				<definiendum id="0">S\N ) /N N</definiendum>
				<definiens id="0">S~ ) If functor categories are permitted to carry features of their own that are not necessarily bound to to any features of their argument and value categories</definiens>
			</definition>
			<definition id="1">
				<sentence>Conjunction is a good case for demonstrating the versatility .</sentence>
				<definiendum id="0">Conjunction</definiendum>
				<definiens id="0">a good case for demonstrating the versatility</definiens>
			</definition>
			<definition id="2">
				<sentence>: IRight-Node-Raising ( RNR ) which leads to sentences as : Peter likes and Paul buys bananas will be neglected here ( although RNR is an attractive lopic for catcgorial grammarians and one of my grammars ~ctnally handles many cases of RNR . )</sentence>
				<definiendum id="0">IRight-Node-Raising ( RNR</definiendum>
				<definiens id="0">leads to sentences as : Peter likes and Paul buys bananas will be neglected here ( although RNR is an attractive lopic for catcgorial grammarians and one of my grammars ~ctnally handles many cases of RNR</definiens>
			</definition>
</paper>

		<paper id="1078">
			<definition id="0">
				<sentence>\ ] A : ( l , T , R ) Automatic procedures for tile processing of speech act basically have to do with the selection and representation of contextual factors° They determine the assignment oF illocutions to linguistic utterances ( Gazdar 1981 ) .</sentence>
				<definiendum id="0">R ) Automatic</definiendum>
				<definiens id="0">procedures for tile processing of speech act basically have to do with the selection and representation of contextual factors° They determine the assignment oF illocutions to linguistic utterances</definiens>
			</definition>
			<definition id="1">
				<sentence>TEXAN is a system which builds on other programs already completed within our project .</sentence>
				<definiendum id="0">TEXAN</definiendum>
				<definiens id="0">a system which builds on other programs already completed within our project</definiens>
			</definition>
			<definition id="2">
				<sentence>INT represents the structure in which knowledge of states of affairs is embedded into knowledge of linguistic action .</sentence>
				<definiendum id="0">INT</definiendum>
				<definiens id="0">the structure in which knowledge of states of affairs is embedded into knowledge of linguistic action</definiens>
			</definition>
			<definition id="3">
				<sentence>4 TEL represents the text lexicon .</sentence>
				<definiendum id="0">TEL</definiendum>
				<definiens id="0">the text lexicon</definiens>
			</definition>
			<definition id="4">
				<sentence>As a third par\ [ a key ( K ) is established which provides the connection of input data and the TA-information .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">established which provides the connection of input data and the TA-information</definiens>
			</definition>
			<definition id="5">
				<sentence>On the level of simple illocutions the key represented by the lemma of the head of the respective phrase ; on the level of complex illocutions the key is the illocuhion of a lower level .</sentence>
				<definiendum id="0">key</definiendum>
				<definiens id="0">the illocuhion of a lower level</definiens>
			</definition>
			<definition id="6">
				<sentence>GRILL provides rules which represent the structure of INT and HAS and which transform them into procedures .</sentence>
				<definiendum id="0">GRILL</definiendum>
				<definiens id="0">provides rules which represent the structure of INT and HAS and which transform them into procedures</definiens>
			</definition>
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>in some cases , TRANSLEGS 's answer needs deduction rules , if properties or classes exist in one language and not in the other one for example , fhen , the system will propose `` substitution '' classes according to their formal proximity degree , lh # same type of answer will be done if one element has some properties in one language that its correspondent does n't have .</sentence>
				<definiendum id="0">TRANSLEGS 's answer</definiendum>
				<definiens id="0">needs deduction rules , if properties or classes exist in one language</definiens>
			</definition>
</paper>

		<paper id="1128">
			<definition id="0">
				<sentence>Theta-theory is the module which determines a sentence 's argument structure and theta or thematic-role ( e.g. , agency , theme , locative ) assignments .</sentence>
				<definiendum id="0">Theta-theory</definiendum>
			</definition>
			<definition id="1">
				<sentence>In short , a trace remains at an extraction site of Move ~ , PRO is a pronominal which may be present in ungoverned positions , and variables are Case-marked traces .</sentence>
				<definiendum id="0">PRO</definiendum>
				<definiens id="0">a pronominal which may be present in ungoverned positions , and variables are Case-marked traces</definiens>
			</definition>
			<definition id="2">
				<sentence>In both ( 3 ) a. and b. , i=j , but in ( 3 ) a. John is the subject , and in b. , Bill is the object .</sentence>
				<definiendum id="0">Bill</definiendum>
				<definiens id="0">the subject , and in b. ,</definiens>
			</definition>
			<definition id="3">
				<sentence>A governing category is the minimal S or NP which contains an anaphor or pronominal and a governor of that anaphor or pronominal .</sentence>
				<definiendum id="0">governing category</definiendum>
				<definiens id="0">the minimal S or NP which contains an anaphor or pronominal and a governor of that anaphor or pronominal</definiens>
			</definition>
			<definition id="4">
				<sentence>And X is a governor of Y iff X = A , N , V , or P and Y is contained in the smallest maximal projection of X ( i.e. , the smallest XP ) and X c-commands Y. C-command is defined in the usual way , that is , X c-commands Y iff the first branching node dominating X also dominates Y , and X does not dominate Y. Princ\ [ Lle Intuitively , a chain encodes the history of movement of a constituent .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a governor of Y iff X = A , N , V , or P and Y is contained in the smallest maximal projection of X</definiens>
			</definition>
			<definition id="5">
				<sentence>y , D-structure , S-structure , and LF ( logical form ) .</sentence>
				<definiendum id="0">LF</definiendum>
				<definiens id="0">logical form )</definiens>
			</definition>
			<definition id="6">
				<sentence>The parser processes a sentence and outputs a triple whose parts are simultaneously determined and consists of a constituent analysis , intended coreference relations ( binding and control ) , and argument structures ( theta-relations ) .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">processes a sentence and outputs a triple whose parts are simultaneously determined and consists of a constituent analysis , intended coreference relations ( binding and control ) , and argument structures ( theta-relations )</definiens>
			</definition>
			<definition id="7">
				<sentence>BOUND , FREE , and ABSOLUTE-FREE are the predicates which have access to PROCESSED-NODES and they specify as to whether or not two indices are to be unified .</sentence>
				<definiendum id="0">ABSOLUTE-FREE</definiendum>
				<definiens id="0">the predicates which have access to PROCESSED-NODES and they specify as to whether or not two indices are to be unified</definiens>
			</definition>
			<definition id="8">
				<sentence>In order to see the interactions of thetarelations , Binding conditions , and Control theory consider the sentence .</sentence>
				<definiendum id="0">Binding</definiendum>
				<definiens id="0">conditions , and Control theory consider the sentence</definiens>
			</definition>
</paper>

		<paper id="1141">
			<definition id="0">
				<sentence>Introduction A spoken message can be produced either to utter a written text ( text-to-speech system ) , or to communicate orally the information given in a semantic representation ( semantic-representation-to-speech system ) .</sentence>
				<definiendum id="0">spoken message</definiendum>
				<definiens id="0">text-to-speech system ) , or to communicate orally the information given in a semantic representation ( semantic-representation-to-speech system )</definiens>
			</definition>
			<definition id="1">
				<sentence>A diphone is defined as a segment ( about 1,200 for French ) that goes from the steady state of a phonetic segment to the steady state of the following segment and that contains In its heart all the transitional part between two consecutive sounds .</sentence>
				<definiendum id="0">diphone</definiendum>
				<definiens id="0">heart all the transitional part between two consecutive sounds</definiens>
			</definition>
			<definition id="2">
				<sentence>The prosodic processing ( Emerard 1977 ) is based on the allocation of prosodic markers ( e.g. \ [ =\ ] , \ [ # \ ] ) at different points in a sentence .</sentence>
				<definiendum id="0">prosodic processing</definiendum>
				<definiens id="0">based on the allocation of prosodic markers ( e.g. \ [ =\ ] , \ [ # \ ] ) at different points in a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>For these operations to be carried out , a text template includes , for each sentence , syntactic Information that Is represented in a tree whose nodes are syntacti~ categories such as S ( sentence ) , CL ( clause ) , SUBJECT or VERB .</sentence>
				<definiendum id="0">syntactic Information</definiendum>
				<definiens id="0">S ( sentence ) , CL ( clause ) , SUBJECT or VERB</definiens>
			</definition>
			<definition id="4">
				<sentence>A French morpho-phonetlc system has been built to compute an Inflected phonetic form given an orthographic basic word and Inflexlonal features ( Laporte 1986 ) .</sentence>
				<definiendum id="0">Inflexlonal features</definiendum>
				<definiens id="0">built to compute an Inflected phonetic form given an orthographic basic word</definiens>
			</definition>
			<definition id="5">
				<sentence>1 , ( 3 ) ( ( 5 ( CL ( SUBJECT ( NP ( N 2~ ) ) ) ( VERB a Of£R ) ( OBJECT ( NP ( DET de ) ( N zanem3n ) ) ) ( A-OBJECT ( NP ( PREP a ) ( N maRi ) ) ) ( SUB ( S ( CL ( CONJ pUR ) ( PPV la ) ( VERB R~idR ) ( ATTRIBUTE e~z ) ) ) ) ) , ) All the segmental phenomena have been taken into account and the next operation consists In entering prosodic markers in such a tree .</sentence>
				<definiendum id="0">CL</definiendum>
				<definiendum id="1">OBJECT</definiendum>
				<definiendum id="2">SUB ( S ( CL</definiendum>
				<definiens id="0">PPV la ) ( VERB R~idR ) ( ATTRIBUTE e~z ) ) )</definiens>
			</definition>
			<definition id="6">
				<sentence>Bibliography COURBON , J. L. , &amp; EMERARD , F. , t982 , `` SPARTE : A Textto-Speech Machine Using Synthesis by Dtphones '' , /EEE Int .</sentence>
				<definiendum id="0">SPARTE</definiendum>
			</definition>
</paper>

		<paper id="1085">
			<definition id="0">
				<sentence>In face-to-face conversation , however , participants also frequently use extralinguistic means for referent identification , in particular , various sorts of deictic gestures ( such as pointing at something by ones hand , finger , pencil , head or eyes ) .</sentence>
				<definiendum id="0">deictic gestures</definiendum>
				<definiens id="0">such as pointing at something by ones hand , finger , pencil , head or eyes )</definiens>
			</definition>
			<definition id="1">
				<sentence>Moreover , we discern two types of bottom regions : Labd regions contain the ofticial inscriptions on the form ( e.g. LR9 tbr 'Professional Expenses ' ) , value regions contain tile space for the user 's data ( e.g. VR28 for educational expenses ) .</sentence>
				<definiendum id="0">Labd regions</definiendum>
			</definition>
			<definition id="2">
				<sentence>General concepts can be ordered in a concept hierarchy , allowing the attribute descriptions of concepts to be inherited fl'om the superordinated concepts .</sentence>
				<definiendum id="0">General concepts</definiendum>
				<definiens id="0">allowing the attribute descriptions of concepts to be inherited fl'om the superordinated concepts</definiens>
			</definition>
			<definition id="3">
				<sentence>Individualized concepts ( depicted by ovals with lateral strokes in Fig .</sentence>
				<definiendum id="0">Individualized concepts</definiendum>
				<definiens id="0">depicted by ovals with lateral strokes in Fig</definiens>
			</definition>
			<definition id="4">
				<sentence>The task of the FSS ( cf. Allgaycr &amp; Rcddig 1986 ) is to express the syntactic and semantic relationships bclween the constituents of the input sentence .</sentence>
				<definiendum id="0">FSS</definiendum>
				<definiens id="0">to express the syntactic and semantic relationships bclween the constituents of the input sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>From a syntactic point of view , a deictic can serve two functions : it supplements a syntactically saturated description , i.e. takes the form of an additional attribute .</sentence>
				<definiendum id="0">i.e.</definiendum>
				<definiens id="0">takes the form of an additional attribute</definiens>
			</definition>
			<definition id="6">
				<sentence>Reichman , R. ( 1981 ) : Plain Speaking : A Theory and Grammar of Spontaneous Discourse .</sentence>
				<definiendum id="0">Plain Speaking</definiendum>
				<definiens id="0">A Theory and Grammar of Spontaneous Discourse</definiens>
			</definition>
</paper>

		<paper id="1075">
			<definition id="0">
				<sentence>ldioms occur in sentences as a number of words , possibly scattered over the sentence and possibly with sonde inflected el~nents ; this ntnfl~er of words has to be interpreted as havip4~ , one primitive meaning .</sentence>
				<definiendum id="0">ldioms</definiendum>
				<definiens id="0">occur in sentences as a number of words , possibly scattered over the sentence and possibly with sonde inflected el~nents</definiens>
			</definition>
			<definition id="1">
				<sentence>The grammars used in the system , called M-grammars , can be seen as a computationally viable variant of Montague Grammar which is in accordance with the transformational extensions proposed by Partee ( 1973 ) .</sentence>
				<definiendum id="0">M-grammars</definiendum>
			</definition>
			<definition id="2">
				<sentence>An `` S-tree '' is a labelled ordered tree .</sentence>
				<definiendum id="0">S-tree ''</definiendum>
				<definiens id="0">a labelled ordered tree</definiens>
			</definition>
			<definition id="3">
				<sentence>The labels of the nodes consist of a syntactic category and a list of attribute-value pairs .</sentence>
				<definiendum id="0">The labels of the nodes</definiendum>
				<definiens id="0">consist of a syntactic category and a list of attribute-value pairs</definiens>
			</definition>
			<definition id="4">
				<sentence>In this section an example will be given of an M-grammar that generates sentence ( 28 ) i ( 28 ) Pete lends the glrl a book Only those M-Rules that are relevant to the discussion in the following sections will be dealt with .</sentence>
				<definiendum id="0">Pete</definiendum>
				<definiens id="0">lends the glrl a book Only those M-Rules that are relevant to the discussion in the following sections will be dealt with</definiens>
			</definition>
			<definition id="5">
				<sentence>to lend '' and NP ( the girl ) renders CL ( Pete lend the gi~IJx~ ) , ~ application of ~ k fro `` lend '' and NP ( a book ) resLtlts in i CL ( Pete lend the gir~ a book ) , application of R 8 gives £EhTI~NCE ( Pete lends the girl a book ) .</sentence>
				<definiendum id="0">Pete</definiendum>
				<definiens id="0">lends the girl a book )</definiens>
			</definition>
			<definition id="6">
				<sentence>`` Normal '' argument 323 substitution rules substitute for the variables in their canonical positions , i.e. as a subject or ( indirect ) object directly under the clause node or as an object to a preposition in a prepositional object .</sentence>
				<definiendum id="0">substitution rules</definiendum>
				<definiens id="0">substitute for the variables in their canonical positions</definiens>
			</definition>
			<definition id="7">
				<sentence>( 45 ) the boy lost his te~nper ( 46 ) VERB I VAR VERB NP V 1 `` lose '' /N det head / \ POSSPRO NOUN V I `` t~nper '' The M-Rule that inserts the CBE makes all possible forms of the possessive pronoun ( his , her , their , etc. ) .</sentence>
				<definiendum id="0">CBE</definiendum>
				<definiens id="0">makes all possible forms of the possessive pronoun ( his , her , their , etc. )</definiens>
			</definition>
</paper>

		<paper id="1126">
			<definition id="0">
				<sentence>sJmple_gn = \ [ pattern = meaning = det = subst = adj = ( det subst adj ) \ [ obj = shoe definitude = defined qualif = green number = plural \ ] \ [ cat = det type = defined number =plurai lex ~ le \ ] \ [ cat = subst gender = fem number = plural lex = chaussure meaning = shoe \ ] \ [ cat = adj gender = fem number = plural lex = vert meaning = green \ ] This structure is built if the constraints are met : for this rule it implies agreement of gender and number , which is the case for `` les chaussures vertes '' .</sentence>
				<definiendum id="0">number</definiendum>
				<definiens id="0">sJmple_gn = \ [ pattern = meaning = det = subst = adj = ( det subst adj ) \ [ obj = shoe definitude = defined qualif = green number = plural \ ] \ [ cat = det type = defined number =plurai lex ~ le \ ] \ [ cat = subst gender = fem number = plural lex = chaussure meaning = shoe \ ] \ [ cat = adj gender = fem number = plural lex = vert meaning = green \</definiens>
			</definition>
			<definition id="1">
				<sentence>FD : for SUBST becomes : subst = \ [ cat = subst meaning ~ box number = plural \ ] where `` meaning '' and `` number '' have been added .</sentence>
				<definiendum id="0">FD</definiendum>
				<definiens id="0">subst = \ [ cat = subst meaning ~ box number = plural \ ] where `` meaning '' and</definiens>
			</definition>
			<definition id="2">
				<sentence>Example : Semantic structure associated to the advice `` Do not expose to rain '' in a user 's manual : \ [ advice advice-type = directive advice-giver = constructor content = \ [ link = negation argl = \ [ action action-type = expose subjsem = user objsem = machine obj2 = rain \ ] \ ] \ ] Among the `` generation models '' of the system , the following is Functionnaly Unifiable to the above structure : \ [ advice advice-type = directive gen-model = \ [ \ [ cat = prop-infinitive pattern = ( gvinf *comp ) meaning = &lt; content &gt; \ ] \ [ cat = prop-must pattern = ( gvdir *comp ) meaning = &lt; content &gt; \ ] \ ] \ ] Remark : the symbol * means that the rule may be repeated .</sentence>
				<definiendum id="0">generation models</definiendum>
				<definiens id="0">directive gen-model = \ [ \ [ cat = prop-infinitive pattern = ( gvinf *comp ) meaning = &lt; content &gt; \ ] \ [ cat = prop-must pattern = ( gvdir *comp ) meaning = &lt; content &gt; \ ] \ ] \ ] Remark : the symbol</definiens>
			</definition>
</paper>

		<paper id="1105">
			<definition id="0">
				<sentence>In this case , the FW denotes a usage of the EW .</sentence>
				<definiendum id="0">FW</definiendum>
				<definiens id="0">a usage of the EW</definiens>
			</definition>
			<definition id="1">
				<sentence>In ( 5 ) , two DW &lt; EWs hal ( t , that is , the DW `` NZ'~/~/ '' &lt; the EW `` $ ~ '' and the DW `` ~ '' &lt; the Ew `` $ ~ '' . In this case , the number of DNs are more than one , DW is n't modified and the FE is the word `` ~* '' . The FW is identical with the FE. ( Notes : `` ~ ' '' is a sub-postpositive signifying exemplification. ) The features of DSs in the dictionary are as follows : ( a ) Honorary , the final ~mrd in DS is DW. ( b ) In some cases , the final expression in DS is YE assigning semantic relation between DW and EW , and DW is just before the PE. ( c ) Genraly , DW is modified by another phrase ( modifier ) . ( d ) In some cases , DS contains more than one DW. The following general structure is obtained according to these features. ' '' ( \ [ MODIFIER\ ] , DW ) *. \ [ F~\ ] o Notes ) \ [ ... \ ] : optional constituent ( ... ) : required constituent * : sequence of coordinate constituent ( e.g.. , ~ ) • : concatination symbol which is diferent from coordinate constituent ( . ) ~or convenience of explanation , the general structure is divided into the following two types. ( I ) TYPEI : ... ( \ [ MODIFIER\ ] .DN ) *o ( I1 ) TYPEII : . , . ( \ [ MODI~\ ] : ER\ ] .DW ) *. PEa 445 In TYPE I , the final word is DW. In TYPEII , the final expression is FE , and BW is just before the FE. We will propose the following assumptions according to above-mentioned features in order to extruct the DW-EW relations from DOs of the general structure. ( ~ ) When DS is in TYPE I , DS~EW. Because DS is a phrase ( or a compound word ) as wide senoe. ( ~ ) When DS is in TYPEll , SS pFE EW. Where pFE is binary relation assigned by FE , and SS is the shortened DS corresponding to ( \ [ MODIFIER\ ] , DW ) *. ® \ [ MODIFIER\ ] • W ~ W ( ~ ) ( \ [ MODIFIERi\ ] .We ) * ~ \ [ MODIFIERa\ ] .Wa Where i , j : l~n , W is arbitrary word. The following general algorithm for deciding the DN-EW relations is obtained by means of these assumptions. ( I ) DS is in TYPE I ( DS dos n't include FE ) , ( A ) DW is modified , ( ~ ) The number of DW is only one , then DW &gt; EW ( B ) The number of DW are more than one , then CD ( B ) DW is n't modified , ( ~ ) The number of DW is only one , then DW -- EW ( ~ ) The number of DN are more than one , then DN &lt; EW ( II ) DS is in TYPEII ( DS includes FE ) , ( A ) DW is modified , ( a ) The number of DW is only one , PFE is ' &gt; ' or ' -- - ' , then BW &gt; EW otherwise CO. ( B ) The number of DW are more than one , then CD ( B ) DW is n't modified , ( a ) The number of DW is only one , then DW pFE EW ( B ) The number of DW are more than one , pFE is ' &lt; ' , then DW &lt; EW otherwise CD. CD denotes that ON-EW relation is n't extracted mechanically from DS. In this case , the extraction of DW-BW relation needs human support at this stage. 2,3 FEATURES OF FE FE prescribes hierarchical relations ( e.g. DW &gt; EW , DW &lt; EN , DW=EW , or DWmEW ) or whole-part relation ( DW~ EW ) . ( e.g. On `` \ [ ~ ( interbrain ) \ ] : ... . ~ ( brain ) OD -- ~9 ( a part Of ) o `` , the FE `` 6D -- ~ '' prescribes DW~ EW explicitly. ) Besides these relations , another relation between DW and BW are prescribed by special FEe ( e.g. `` ~T ( under ) '' ) , which is called associative relation ( R ) . There are so many FEs that they are mainly divided into four patterns called functional patterns { FP : a brief notation } . FP is expressed by means of regular expression. FP is necessary for extracting FE and DW-EW relation informat_j~_n_ ( i.e , information neccessary for deciding the DW-EW relations ) assigned by the FE. FP also designates a place of DW in DS , Main features of FP are as follows : ( 1 ) Type100 : \ [ , ..DWj • ~ • FW ( 2 ) Type200 : ... DW • ( ~9 . FN ) * ( 3 ) Type3OO : ... DW • P FW ( 4 ) Type400 : . , .DW • e~ '' 446 Motes ) ~* is arbitrary character string , ( ... ) * is repitation of ( , .. ) , P is special phrase ( e.g. Ic~'~ ) , is concatination symbol. We got about one hundred seventy FWs. These are classified into two groups. In one group ( contained 64 FWs ) , the FNs contain explicitly DW-EN relation information. In the other group ( contained 105 FWs ) , some of the FWs contain usages of the EWe , which are also important to thesaurus. We have constructed a FN dictionary which includes FP and DW-EW relation information corresponding to the FP. The system consists of the following four steps. RE~tion of EW and DS ( a ) Extraction of EW , its DS , the part of speech of the EW , the definition number of the DS from the dictionary. ( b ) Transformation of the extracted DS to the ordinary Japanese sentence 's form ( called the normalized DS ) . Because several contents ( meanings ) are thrown into one DS by means of parentheses or dot ' ' in the dictionary. ~D Extraction of FE and DW-EW rel~ information The FW Dictionary is used. ( a ) When DS dose n't include FW , DS is in TYPEI. ( b ) When DS includes FW and conforms FP , DS is in TYPEII. ( c ) When DS includes FW but does n't conform FP or when DS includes more than one FW , the DS is picked out as check data.Because it is difficult to distinguish between DW and FW or to extract DW-EW relation information mechanically. ( 3 ) Extraction of DW and DW-HW relation informatio~ A general word dictionary ( containing about 75,000 noun words ) ( S ) is used , in which the character strings of entry words were arranged in inverse order ( from right to left ) . DWs are basically extracted by means of longest matching method , because there is ordinarily no space between two adjacent words in the Japanese sentence. In addition to this. there are the following problems. ( a ) The 'hiragana ' notation is often used ( e.g. ~O ) ~b \ [ ~b\ ] ) . ( b ) The names of animals and plants are described by 'katakana ' ( e.g. ~ ) P \ [ ~\ ] ) . ( c ) The unknown ( compound ) words are often used. ( d ) In some cases , the DS containes more than one ON. The oxtructing procedure has to be constructed with regard to these ploblems. The relation information are also extracted , that is , 'DW is n't modified ' and 'The number of DN are more than one ' . When DN is n't extracted ( that is , DR is neither 'katakana ' string nor 'kanji ' string nor any entry word in the word dictionary ) from DS , the DS is picked out as check data. ( 4 ) Decision of DW-EW relation According to the conditions above-mentioned , DW-EW relations are decided. When extracted relation information is ambiguous , DS is picked out as check data. PE T R SU T A pilot system has been implemented on FACOM M-360 ( Nagasaki University Computer Center ) and FACON N-382 ( Kyushu University Computer Center ) mostly by PL/I. The experimental input data ( 2,824 DSs ) in the first step , arc the normalized DSs. Table 1 shows the number of input , output and check data in each step and the number of correct and incorrect data in output data. Table 2 shows the extracted DW-EW relations and the number of output data corresponding to the relations. The experimental results are as follows : ( 1 ) The ratio of TYPEI ( 2,374 ) to output data ( 2 , ? ll ) is about 87.6 % . ( 2 ) The ratio of TYPEI1 ( 337 ) to output data ( 2,711 ) is about 12.4 % . ( 3 ) The ratio of output data ( 2,434 ) to input data ( 2,824 ) is about 85 % . ( a ) The ratio ( called system precision ) of correct output data ( 2,311 ) to output data ( 2,434 ) is about 95 % . ( b ) The ratio ( called error ratio ) of incorrect output data ( 123 ) to output data ( 2,434 ) is about 5 % . ( 4 ) The ratio of check data ( 390 ) to input data ( 2,824 ) is about 14 % . Table 1 ( 1 ) Extraction of FE ( 2 ) Extraction of DW ( 3 ) Decision of Relation Result of Experiment The Number of Input Data , Output Data and Check Data in Each Step INPUT OUTPUT DATA DATA ( correct : incorrect 2,824 2,374 ( TYPE I ) 337 ( TYPE \ [ I ) 2,711 2,502 ( 2,386 : 116 ) 2,386 2,318 ( 2,311 : 7 ) 2,824 2,434 ( 2,311 : 123 ) CHECK DATA 113 209 68 390 Table 2 DW-EW Relations and the Number of Output Data corresponding to Each Relation Relatio\ [ DW : EW Subtota Total J orrect Dubious Incorrect Type Type Type i II I i II I i II 1963 I 71 31 0 o i io3 o i o 4i II Oi I oi 9 oi i oi io oi o 210~ ! 3. I ? oi o 0 i 0 O~ 0 Oi 1 o i 1 'i ' o ! 2 2 i Subtotal Type I i i1 1966i 71 12oi 1o~ 24i 12 oi 11 oi 11 2110 i 208 2318 Most of incorrect output data occur in the step of extraction of DWs which are described by 'hiragana ' notation , because of limitaions of the longest matching method. The improvement of the results necessitates ( a ) analysis of the DSs , ( b ) reinforcement of the general word dictionary used for extracting the DWs. 5~CONCLUDINO~RKK~_ ( 1 ) The similer researches have been carried out about several English dictionarys ( e.g. LONONAN ) ( 2 ) ( ~ ) , however there is scaresly any about Japanese dictionary. ( 2 ) We have extracted automaticlly , DW &lt; EW , DW~EW , DW~ EW in addition to DW &gt; EW as the DW-EW relations .</sentence>
				<definiendum id="0">EWs hal</definiendum>
				<definiendum id="1">DW</definiendum>
				<definiendum id="2">EW</definiendum>
				<definiendum id="3">FW</definiendum>
				<definiendum id="4">SS</definiendum>
				<definiens id="0">the number of DNs are more than one , DW is n't modified and the FE is the word `` ~* ''</definiens>
				<definiens id="1">identical with the FE. ( Notes : `` ~ ' '' is a sub-postpositive signifying exemplification. ) The features of DSs in the dictionary are as follows : ( a ) Honorary , the final ~mrd in DS is DW. ( b ) In some cases , the final expression in DS is YE assigning semantic relation between DW and EW , and DW is just before the PE. ( c ) Genraly , DW is modified by another phrase ( modifier ) . ( d ) In some cases , DS contains more than one DW. The following general structure is obtained according to these features. ' '' ( \ [ MODIFIER\ ] , DW ) *. \ [ F~\ ] o Notes ) \ [ ... \ ] : optional constituent ( ... ) : required constituent * : sequence of coordinate constituent ( e.g.. , ~ ) • : concatination symbol which is diferent from coordinate constituent ( . ) ~or convenience of explanation , the general structure is divided into the following two types. ( I ) TYPEI : ... ( \ [ MODIFIER\ ] .DN ) *o ( I1 ) TYPEII : . , . ( \ [ MODI~\ ] : ER\ ] .DW ) *. PEa 445 In TYPE I , the final word is DW. In TYPEII , the final expression is FE , and BW is just before the FE. We will propose the following assumptions according to above-mentioned features in order to extruct the DW-EW relations from DOs of the general structure. ( ~ ) When DS is in TYPE I , DS~EW. Because DS is a phrase ( or a compound word ) as wide senoe. ( ~ ) When DS is in TYPEll , SS pFE EW. Where pFE is binary relation assigned by FE , and</definiens>
			</definition>
			<definition id="2">
				<sentence>i0 ) ( 3 ) A.Miohiels , J.Noel : APPROACH TO THESAURUS PRODUCTION , Prec .</sentence>
				<definiendum id="0">J.Noel</definiendum>
				<definiens id="0">APPROACH TO THESAURUS PRODUCTION</definiens>
			</definition>
</paper>

		<paper id="1049">
			<definition id="0">
				<sentence>Tile principal difference between the `` classical '' eategorial granmlar and the ~eneralizcd cate_gorial 6-rams at ( GCG ) is 208 that inste~d of finite sets of categories corresponding to terminal syunbols , GCG allows fox , infinite sets of categories .</sentence>
				<definiendum id="0">GCG</definiendum>
				<definiens id="0">allows fox , infinite sets of categories</definiens>
			</definition>
			<definition id="1">
				<sentence>G , denoted G ( w ) ~ is defined as 'the lengt\ [ h of the longest category ' used in the aualy'sis wrt .</sentence>
				<definiendum id="0">G</definiendum>
				<definiendum id="1">G ( w ) ~</definiendum>
				<definiens id="0">'the lengt\ [ h of the longest category ' used in the aualy'sis wrt</definiens>
			</definition>
			<definition id="2">
				<sentence>~ denoted M ( w ) , is defined as the maximal number of visits paid to a sing'le square during the accepting computation ( ambiguity being treated as before ) .</sentence>
				<definiendum id="0">M ( w )</definiendum>
				<definiens id="0">the maximal number of visits paid to a sing'le square during the accepting computation ( ambiguity being treated as before )</definiens>
			</definition>
</paper>

		<paper id="1103">
			<definition id="0">
				<sentence>Abstract : The paper describes the design of a fair sized lexical database that is to be used with a natural language based expert system with German as the language of interaction .</sentence>
				<definiendum id="0">Abstract</definiendum>
				<definiens id="0">the design of a fair sized lexical database that is to be used with a natural language based expert system with German as the language of interaction</definiens>
			</definition>
			<definition id="1">
				<sentence>USL is a natural language front end to SQL/DS ( IBM 1983 ) operational in six languages .</sentence>
				<definiendum id="0">USL</definiendum>
				<definiens id="0">a natural language front end to SQL/DS</definiens>
			</definition>
			<definition id="2">
				<sentence>The Natural Language Analyzer consists of the following parts : a sentence separator splitting texts into sentences , • a pre-parser for dictionary look-up , .</sentence>
				<definiendum id="0">Natural Language Analyzer</definiendum>
				<definiens id="0">consists of the following parts : a sentence separator splitting texts into sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>Queries , Reports , and Files : Independently of the Dictionary Editor , the lexicographers work with the standard database interfaces ISQL ( IBM 1983 ) and QMF ( IBM 1983 , 1984 ) to query , extract , recover , and to view the contents of the word database .</sentence>
				<definiendum id="0">QMF</definiendum>
				<definiens id="0">IBM 1983 , 1984 ) to query , extract , recover , and to view the contents of the word database</definiens>
			</definition>
			<definition id="4">
				<sentence>o x SIJItJECT x x SOURCE x x FREQ x x FREQS x x STYLE x x XREF Nominative Singular lmqnitive without ~- ( e ) n '' , without separat } lc prefix XREF ( cont 'd ) Plural Furm lml } erfect , Past Participle 'I'RI { NN x x I ) ATUM x x 141 , F2 , F3 , F4,1 ; 5 ... . Positive # ADJ Scope of stem form Declension class Valency Preposition place/temporal/modal case/preposition case/preposition case/preposition case/preposition not used attributively not used adverbially not used predicatively x x x x x x Positive ( kadation x x Fig .</sentence>
				<definiendum id="0">o x SIJItJECT x x SOURCE x x FREQ x x FREQS x x STYLE x x XREF Nominative Singular lmqnitive</definiendum>
				<definiens id="0">ADJ Scope of stem form Declension class Valency Preposition place/temporal/modal case/preposition case/preposition case/preposition case/preposition not used attributively not used adverbially not used predicatively x x x x x x Positive ( kadation x x Fig</definiens>
			</definition>
			<definition id="5">
				<sentence>legt fiber -hat fibergelegt -fiberzulegen Full government : Paul legt Maria eine Jacke fiber Dative can be left out : Paul will eine Jacke fiberlegen Accusative can not be left out : *Paul legt der Maria fiber *Paul legt fiber Coding for ftberlegen 'to cover ' Stem : leg Prefix i~ber Word class : VERB Government : nominative dative accusative Obligatory : nominative accusative Testing for iiberlegen 'to reflect ' : Prefix : separable or not ?</sentence>
				<definiendum id="0">Prefix</definiendum>
				<definiens id="0">nominative dative accusative Obligatory : nominative accusative Testing for iiberlegen 'to reflect ' :</definiens>
			</definition>
</paper>

		<paper id="1039">
</paper>

		<paper id="1050">
</paper>

		<paper id="1109">
			<definition id="0">
				<sentence>FUNDPL uses syntactic functions ( and semantic relations ) as binary con , ~ ; tralnts in a grammar in the following sense .</sentence>
				<definiendum id="0">FUNDPL</definiendum>
				<definiens id="0">uses syntactic functions ( and semantic relations</definiens>
			</definition>
			<definition id="1">
				<sentence>In a concatenation description `` R '' stands for the regent itself .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the regent itself</definiens>
			</definition>
</paper>

		<paper id="1127">
			<definition id="0">
				<sentence>Then fi ) ( Xl , ... . Xn ) is an atomic condition .</sentence>
				<definiendum id="0">Xn )</definiendum>
			</definition>
			<definition id="1">
				<sentence>Initially , we begin with the unanalyzed sentence within a DRS K. The subject N ( oun ) P ( hrase ) node in the parse tree introduces a condition into the DRS , the condition man ( x ) ' , into Con K and a reference marker x into U K , \ ] -hat exhausts the content of the indefinite noun phrase .</sentence>
				<definiendum id="0">] -hat</definiendum>
				<definiens id="0">exhausts the content of the indefinite noun phrase</definiens>
			</definition>
			<definition id="2">
				<sentence>Because the pronoun is an NP , the algorithm requires that it introduce a new reference marker into the DRS. Because the pronoun is anaphoric , the reference marker it introduces must be linked to some already introduced reference marker in U K. Thus , U K provides a set of contextually `` discourse individuals '' ( objects that have been talked about in the discourse ) that can be referred to by NPs in subsequent discourse .</sentence>
				<definiendum id="0">U K</definiendum>
				<definiens id="0">provides a set of contextually `` discourse individuals '' ( objects that have been talked about in the discourse ) that can be referred to by NPs in subsequent discourse</definiens>
			</definition>
			<definition id="3">
				<sentence>loves ( x1 , x2 ) As we shall see shorlly , the truth conditions of such a DRS are essentially this : pick any man ; then there 's a woman that loves him .</sentence>
				<definiendum id="0">loves</definiendum>
			</definition>
			<definition id="4">
				<sentence>We define a model for the DRS `` language '' to be an ordered pair &lt; D , \ [ \ ] &gt; , where D is a set of entities ( the `` domain '' of tile model ) , and \ [ \ ] an interpretation function thai takes n-ary predicates into sets el ntuples in ~ ( w ( Dn ) ) .</sentence>
				<definiendum id="0">D</definiendum>
				<definiens id="0">a set of entities ( the `` domain '' of tile model ) , and \ [ \ ] an interpretation function thai takes n-ary predicates into sets el ntuples in ~ ( w ( Dn ) )</definiens>
			</definition>
			<definition id="5">
				<sentence>f. A ORS K is true in a model M just in case there is a proper embedding of K in M From the standpoint of the theory of information processing , a DRS represents the resuff of a recipient 's processing of a verbal input .</sentence>
				<definiendum id="0">ORS K</definiendum>
				<definiendum id="1">DRS</definiendum>
				<definiens id="0">the resuff of a recipient 's processing of a verbal input</definiens>
			</definition>
			<definition id="6">
				<sentence>The common noun phrase in SUBJ ( the head noun + any modifiers ) yields a predicative DRS , which will contain a complex property if the common noun phrase is itself complex-i.e. contains modifiers like possessives or relative clauses .</sentence>
				<definiendum id="0">SUBJ</definiendum>
				<definiendum id="1">DRS</definiendum>
				<definiens id="0">itself complex-i.e. contains modifiers like possessives or relative clauses</definiens>
			</definition>
			<definition id="7">
				<sentence>So in general it will be of the form ( ii ) &lt; Xx , 0 , ( UCN , CONcN\ [ x\ ] ) &gt; , where UCN is the set of reference markers and CONcN\ [ x \ ] is the set of conditions derived from the common noun phrase and where 'CONcN\ [ x \ ] ' denotes the fact that at least one condition in CONcN contains 'x ' as an argument .</sentence>
				<definiendum id="0">UCN</definiendum>
				<definiendum id="1">UCN</definiendum>
				<definiens id="0">the set of reference markers and CONcN\ [ x \ ] is the set of conditions derived from the common noun phrase and where 'CONcN\ [ x \ ] ' denotes the fact that at least one condition in CONcN contains 'x ' as an argument</definiens>
			</definition>
			<definition id="8">
				<sentence>The result is a quasi-complete DRS o1 the form ( iv ) &lt; 0 , 0 , ( URADJ , COnRAD j ) &gt; , where URADJ is the set of reference markers and COnRADJ is the set of conditions derived from the processing of RADJ .</sentence>
				<definiendum id="0">URADJ</definiendum>
				<definiendum id="1">URADJ</definiendum>
				<definiendum id="2">COnRADJ</definiendum>
				<definiens id="0">the set of conditions derived from the processing of RADJ</definiens>
			</definition>
			<definition id="9">
				<sentence>J I I IOBJ -Pro ' | low / LPRED `= : e~ ; ct ~ ; B'3 ) ~'XE ; M~ : ( OBJ : LPRED 'persuade &lt; ( SUBJ ) ( OBJ ) ( XCOMP ) &gt; ' iPRED='s~eeps &lt; ( SUBJ ) &gt; ' The DRS constructor begins with the specifier of the subj structure in the usual fashion and then begins to construct the common noun phrase from the inside out .</sentence>
				<definiendum id="0">DRS constructor</definiendum>
				<definiens id="0">begins with the specifier of the subj structure in the usual fashion and then begins to construct the common noun phrase from the inside out</definiens>
			</definition>
</paper>

		<paper id="1046">
			<definition id="0">
				<sentence>DRL consists of bracketed expressions which are lists in the sense of list processing .</sentence>
				<definiendum id="0">DRL</definiendum>
				<definiens id="0">consists of bracketed expressions which are lists in the sense of list processing</definiens>
			</definition>
			<definition id="1">
				<sentence>Suppose , for example , that D is a string corresponding to a subtree and H is the string that corresponds to the term superordinated to that subtree .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">a string corresponding to a subtree and</definiens>
			</definition>
			<definition id="2">
				<sentence>Let us define the attribute `` sequence '' ( seq ) as having the values i : C precedes H , and 2 : C follows H. Let us establish `` adjacency '' ( adj ) with the values i : C immediately precedes 1 { , and 2 : C immediately follows H , Finally , let us introduce `` delimitation '' ( lim ) with the values i : C is the leftmost of all of the strings corresponding to dependents of H , and 2 : C is the rightmost of of all of the dependents of H. For the sake of comparison , let us consider the following example which Pereira 1981 uses in order to illustrate Extraposition Grammar : ( 3 ) The mouse that the cat that likes fish chased squeaks , The following DRL-tree depicts the dependencies and the word order of this sentence by means of the attributes just defined : ( 4 ) ( ILLOCUTION : assertion : adj &lt; l &gt; ( PREDICATE : squeak : adj &lt; l &gt; ( SUBJECT : mouse : adj &lt; l &gt; ( DETERMINER : the : seq &lt; l &gt; ) ( ATTRIBUTE : chase : adj &lt; 2 &gt; ( OBJECT : that : lim &lt; l &gt; ) ( SUBJECT : cat : adj &lt; l &gt; ( DETERMINER : the : adj &lt; l &gt; ) ( ATTRIBUTE : like : adj &lt; 2 &gt; ( SUBJECT : that : lim &lt; l &gt; ) ( OBJECT : fish : adj &lt; 2 &gt; ) ) ) ) ) ) ) ; The projection of subtrees and their attributes yields the following constituent analysis of the input string : ( 5 ) the mouse that the cat that \ [ e squeaks likes fish chased \ [ adj &lt; l &gt; the \ [ , mouse -- ~ \ [ that the cat I seq &lt; l &gt; adj &lt; 2 &gt; \ ] that likes \ [ \ ] fish chased that \ [ + -- -chased \ [ lim &lt; l &gt; tile cat that likes fish \ [ &lt; I adj &lt; l &gt; the I *cat -- ~ \ [ that likes fish I adj &lt; l &gt; adj &lt; 2 &gt; I that \ ] ~ -- -likes -- ~ \ ] fish I lim &lt; l &gt; adj &lt; 2 &gt; I There is exactly one sequence of words that is in agreement with all of the attribute-values in the tree .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">OBJECT</definiendum>
				<definiendum id="3">SUBJECT</definiendum>
				<definiens id="0">having the values i : C precedes H , and 2 : C follows H. Let us establish `` adjacency ''</definiens>
				<definiens id="1">the leftmost of all of the strings corresponding to dependents of H</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , a role variable covers any role , a morphosyntactic subcategory covers any element of the defined set of features .</sentence>
				<definiendum id="0">morphosyntactic subcategory</definiendum>
				<definiens id="0">covers any element of the defined set of features</definiens>
			</definition>
</paper>

		<paper id="1111">
			<definition id="0">
				<sentence>ABSTRACT Aspects of syntactic predictions made during the recognition of English sentences are investigated .</sentence>
				<definiendum id="0">ABSTRACT Aspects</definiendum>
				<definiens id="0">of syntactic predictions made during the recognition of English sentences are investigated</definiens>
			</definition>
			<definition id="1">
				<sentence>The analyzer makes use of the simple stack mechanism whose behavior is specified by rules described in Greibach normal form .</sentence>
				<definiendum id="0">analyzer</definiendum>
				<definiens id="0">makes use of the simple stack mechanism whose behavior is specified by rules described in Greibach normal form</definiens>
			</definition>
			<definition id="2">
				<sentence>The simplest type of prediction , which forms the basis of the following discussions , is presented in this subsection .</sentence>
				<definiendum id="0">prediction</definiendum>
				<definiens id="0">forms the basis of the following discussions</definiens>
			</definition>
			<definition id="3">
				<sentence>CW CP SF NPr ( 1 ) art NP ~ t NP-ART ( 2 ) noun NP-ART ~ t *NP-N ( 3 ) rel_pro NP-N ~ nil ADJ_CLAUSE The first rule , for example , can he interpreted as follows : IF the current word ( CW ) is an article and the current prediction ( CP : the top element of the stack ) is NP , THEN shift the current word pointer ( since the shifting flag ( SF ) is t ) and replace the current prediction by the new prediction ( NPr ) .</sentence>
				<definiendum id="0">CW CP SF NPr</definiendum>
				<definiendum id="1">CP</definiendum>
				<definiens id="0">the top element of the stack ) is NP , THEN shift the current word pointer</definiens>
			</definition>
</paper>

		<paper id="1123">
			<definition id="0">
				<sentence>Ellman ( 8 ) even claims that `` the classification of indirect speech acts is primarily for analytic purposes and it is not stated anywhere that this classification is essential to the understanding process '' To oversimplify : The basic intuition of a naive user refers to a SELF and a SYSTEM , which works by telepathy , superficially guided by the linguistic utterance of the user .</sentence>
				<definiendum id="0">SYSTEM</definiendum>
				<definiens id="0">works by telepathy , superficially guided by the linguistic utterance of the user</definiens>
			</definition>
			<definition id="1">
				<sentence>Figures as the following corrupt clear communication : I sPoakerl -- -- IE \ ] -- -- I 'hearor t t I. po o , oo I 522 In opposition to these simplistic views of language , neurolinguistics has shown that understanding is a sort of pattern ( re ) construction working freely through different levels of abstraction between the level of physical perception and understanding or the reaction respectively .</sentence>
				<definiendum id="0">understanding</definiendum>
				<definiens id="0">the following corrupt clear communication : I sPoakerl -- -- IE \ ] -- -- I 'hearor t t I. po o , oo I 522 In opposition to these simplistic views of language</definiens>
				<definiens id="1">a sort of pattern ( re ) construction working freely through different levels of abstraction between the level of physical perception and</definiens>
			</definition>
</paper>

		<paper id="1004">
</paper>

		<paper id="1147">
			<definition id="0">
				<sentence>Long-term memory stores knowledge such as dictionaries , grammars , experiences , cmnmon-sense knowledge , expert knowledge , and procedural knowledge such as how to infm '' a fact from a collection of facts .</sentence>
				<definiendum id="0">Long-term memory</definiendum>
			</definition>
			<definition id="1">
				<sentence>Structure is a packet of memory organization .</sentence>
				<definiendum id="0">Structure</definiendum>
				<definiens id="0">a packet of memory organization</definiens>
			</definition>
			<definition id="2">
				<sentence>Discourse memory ( long-term memory ) is not simply an accumulation of the contents of episodic memory ( discourse memory ) , but is a structured memory coherently organized from the episodic memory ( discourse memory ) .</sentence>
				<definiendum id="0">Discourse memory</definiendum>
				<definiens id="0">an accumulation of the contents of episodic memory ( discourse memory ) , but is a structured memory coherently organized from the episodic memory ( discourse memory )</definiens>
			</definition>
			<definition id="3">
				<sentence>As a prelimlnary model of discourse memory , we define a Local Scene Frame ( LSF ) , which is a collection of cases and predicates in preceding sentences already analysed .</sentence>
				<definiendum id="0">Local Scene Frame</definiendum>
				<definiendum id="1">LSF )</definiendum>
				<definiens id="0">a collection of cases and predicates in preceding sentences already analysed</definiens>
			</definition>
			<definition id="4">
				<sentence>__t , _No_ &lt; kqa_~__ J t ... .. ... ... , ,.uot ... . ¼ i Fig. 1 Extended Case Structure Model situation in which the utterance is carried out. Information in the LSF is used for filling in missing cases , and resolving anaphora. A discussion of the detailed procedure for the assimilation would be beyond the scope of this paper. The Extended Case Structure Model ( ECS ) is a linguistic model for representing the meaning structures of the text. Thus the ECS presents a representation scheme for the episodic memory. Figure 1 shows its fundamental construction. The traditional case structure ( Fillmorean type ) is a structure for a unit sentence which consists mainly of relations between nouns and a verb. This is not sufficient to represent structures of real sentences which sometimes have complex noun phrases , compound sentences , etc. Also , the ECS has to have facilities for representing other structures involving relations between a noun and a noun , a verb and a verb , etc. The ECS has been designed to integrate those structures into one linguistic model. Its nature is hierarchical as to the compoundness of constituents , iterative as to conjunction , and recursive as to embedding. Using these formalisms , the syntactic and semantic structures of sentences can be represented uniformly and correctly. There are two types of semantic structurcs , composite and primitive structures. A cmnposite structure is made by integrating semantic structures using semantic relations. A primitive structure , by definition , can not be divided into further substructures. In general , a single word corresponds to a primitive structure , and a phrase corresponds to a composite structure. Since syntactic information can also contribute to define meaning structures , each semantic structure simultaneously incorporates not only meaning information but also syntactic information. We do not assume a language-independent universal semantic representation. Thus , it is necessary to define a proper ECS for each language : Japanese ECS ( J-ECS ) \ [ 6\ ] for Japanese language and English ECS ( E-ECS ) \ [ 7\ ] for English language. In the translation process from Japanese into English , the analysis procedure generates a J-ECS for a Japanese sentence , and the transfer procedure generates an E-ECS corresponding to the J-ECS. Senmntic relation connects semantic structures and builds a larger semantic structure , ranging from a word structure to a sentence structure. Figure 2 shows types of semantic relations , and each of them can be explained briefly as fellows : 1 ) Noun relation : Relationship between nouns ; Examples are whole-part , upper-lower , possession , material , etc. 2 ) Case relation : Relationship between a case element and a predicate ; Examples are object , agent , instrument , place , etc. 622 3 ) Embedded relation : Relationship between an embedded sentence and a noun phrase , which can be categorized into three types ; a ) case re'lation between a modified noun phrase and the predicate iu a modifier embedded sentence , b ) noun relation between a modified noun phrase and a noun phrase in a modifier embedded sentence , and c ) an appositive or subsidiary relation between a modified noun phrase and a modifier embedded sentence. 4 ) Conjunctive relation : Relationship between sentences ; Examples are cause-result , time-advance , assumption , etc. Concepts are associated with structures mentioned above. Among them , concepts associated with word structures represent word meanings which appear when the words are used in a sentence. A word meaning is represented by principal concepts , supplenmntary concepts , and their semantic dependencies. Principal and supplementary concepts are dcfined by using semantic categories , and prepared for nouns , adverbs , verbs , adjective-verbs and modalities as shown in Figure 3. Semantic dependencies are defined by using semantic relation fi'ames and semantic structure frames. Semantic categories , semantic relation fi'amcs and semantic structure frames have the following characteristics : 1 ) There are two types of concepts : prototype and instance. Prototypes play a part of selectional constraint to define semantic dependency structures. Instances show an assimilated structure which satisfies the selectienal constraints. 2 ) They shows semantic commonness and analogy between two structures. This allows the system to share information and to provide facilities for paraphrase. 3 ) Semantic categories make tip a hierarchical structure. This provides the system with inheritance ability and information sharing. There are two typos of dictionaries in LUTE. Mono-liugual dictionaries are used in analysis and generation , while bMingual dictionaries are used in transfer. Mono-lingual dictionaries have the following information about words and concepts : 1 ) tIow the word is expressed , 2 ) how the word is used in the syntax of a sentence , and 3 ) what concept the word corresponds to. Bi-lingual dictionaries has information on the correspondence of concepts in two different languages , and will be explained in section 6. ( Note that concepts are defined here by associating structures which are generally language dependent. ) Figure 4 shows the contents of a word dictionary. A word meaning can be regarded as an entry to the conceptual knowledge description. The LUTE dictionaries contain the following semantic information : 1 ) Semantic category ( for word meanings ) : Principal concepts associated with the word meaning. Those for nouns and adverbs are used as selectional constraints in semantic relation analysis. Those for predicate s are used to analyse modality. 2 ) Case fi'ame ( for predicate word meanings ) : Constraints and case relations which are applied to construct unit sentence semantic structures. There are three types of ease frames : intrinsic for each predicate word nmaning , common for several predicate word meanings , optional for outer ease relations. 3 ) Noun relation frame ( for noun word meanings ) : Constraints and semantic relationships which ace applied to construct semantic structures made up of two nouns. Case frames are also used as a ldnd of object relation frames for predicate-type nouns. 4 ) Event relation frame ( for predicate word meanings ) : Constraints and semantic relationships to be applied to construct complex sentence semantic structures. An example is the relation between the verb in a main clause and the verb in a subordinate clause. 5 ) Heuristics ( for semantic categories and relation fi'ames ) : This is used for resolving ambiguity of semantic categories , semantic relations , and semantic structures by linguistic information such N~oun-ielalot~ ... . tri~ci ; on ca~se~rel -- ati~on ; gent : a-ctio~n~objec~t -- actio~i-nst -- ru -- n , e , ; t~ ; ctio~n ' -Catego-ries for-~ouns-a~ld adverbs : : = , -~a-ture~m-a-teriT ; i lnstri , , , ~ ; ~ , i i ... . time-action location-action destination-action source-aetim~ co-object-action mannerI society organization \ [ cultllre i buman l action l state \ [ number l degree l enmtion l action freque cy-action object-state action-location action-time action-result actiontime l location| a bstract l concrete animate J plant I others degree I state'object property-object possessor-object number-object material-object Categories for verbs : : = voice active statlve movemental I transitional\ ] Iota , on-object object.property object-element object-number object-location speciesemotional I thinking perceptual existential judgenlental non-willing object l re ative-location Iocat on-specificatio ~ time-specification human-relation nounv oi c e : : = passive l affected-passive possible l sponraneous causa tive \ ] pet fective I cative : : =momentallcontinual suffix prefix-noun \ [ parallel l others Case relation : : = OBJECT-TYPE METHOD-TYPE DfRECTION-TYPEJ TIME-SPACE-TYPE 1 stative : : = ~ teiru\ [ -teiru Categories for adlectives and adjective-verbs : : = SUPPLEMENT-TYPE I MODIFICATION-TYPE 0 gJ E CT-TY PE : : = object I co-object \ [ statem ent-object J compared-object I seconds ry-obje ct I theme J agent \ [ experiencer METHOD-TYPE : : = method I instrument I material\ [ element I ca use DIRECTION-TYPE : : = source I destination I purpose I result \ ] giver I recipient TIME-SPACE-TYPE : : = location J time SUPPLEMENT-TYPE : :=Ocasion content role contrast region MODIFICATION-TYPE : : = manner \ [ frequency degree tbing rate I number emphasis I true tf Embedded relation : : = case relation\ ] relation that modified noun phrase modify case instance in tJm enlbedded sentencel apposition.Event-result Con unctive relation : : = condition right-affirmative cause lpurposelright assumption\ [ contrary-assumption contrary-affirmativeljuxtaposition introducr on pallare t merelation before simultaneous after continuation limitecl-continuationlduring I examplilTcation selection interrogative-contentslcitationlexplanationlspecificlnlinimal. limit proportion degree I limit stative I charactedstk \ ] relational I emotional Categories for modalities : : = as pect : : = beghlning just-before-beginning Ijust-after.beginning I continuous I repetitive I perfective \ ] just-before.perfective Ijust-after-perfective I perfecrivestate I others tense : : =past present future modal : : = negation possibility necessarity obligation I necessity I inevitability I favorability \ [ sufficiency I guess I affirmative \ ] confidential-guess I uncertahla ffirnlative estimation guess uncertain-guess l hearsay l intention willingness I plan hope try causative secood-pelson command interrogative request I pernlission invitation third-person l causa tive \ ] request I passive I spon tanity \ [ bene factive \ [ polite I respect I o , hers manner : : =limited degree \ [ extr eme-e xample l stress l exan\ ] plification \ ] parallel ladditionlselection uncertainty distinction others Fig. 2 Semantic Relations Fig. 3 Semantic Categories as preference over several semantic relations , semantic relation fillers , and remaining semantic relation fi'ames not yet filled. Both comnmn.-sense knowledge and expertdmowledge are constructed using basic elements such as concepts , , 'elations and structures as well as linguistic structures. Thus the non-lingulstlc knowledge manipulated in LUTI , ; is not represented in a simple database fl'amework but rather incorporated into the memory structure. Although re.troy language processing systems use the term `` knowledge '' rather vaguely , LU\ [ \ [ 'Itl gives a concrete form to knowledge in the sense of franmmetworks corresponding to word meanings. The current version of I , UTE defines the following types of knowledge in terms of semantic relations : 1 ) Concept Relation : Relations such as hyponymy , synonymy , antonymy , whole-part , and possession. One example is `` wholepart '' rehttion between `` densha ( ; ~ ii'- ' ) ( train ) '' and `` made ( ~ ) ( window ) '' . ( A window can be a part era train. ) 2 ) Event State Relation : Relations between two events or between an event and a state. One example is `` subsidiary situation '' relation that `` nioi ( ~ ~ ) ( smell ) '' results from `` yaku ( 'l ' ) '~ &lt; ) ( grill ) '' . 3 ) Mete knowledge : This is used for reasoning , such as in traversing the concept networks , and checMng semantic consistency according to concept networks. All information manipulated in LUTE is represented in a uniform frameworlt , called a Frame-Network. F , ach type of { lictiouary infermarion such as semantic category , case frame , noun relation frame , Entry Information ( Kanji-Code , Root-Form ) I tactic I~forma~ion ( Part-of-~peeeh. Co~jugat~omtype ) \ ] onin _3 • • • • . . -- I Obi~ct a~ , at , o , ,~ ... . 1~ ... I Object Relation F ... . S \ ] -- 1 E~entaelationFramel\ ] `` °° \ [ Eventaelatio~F ... . t\ ] Fig'. 4 Contents of dictionary ( nlono-lingual ) and event relation fi'ame is represented by frames with correspondlng frame names. These fi'amcs consist of subframes representing semantic relation information. Slots of a frame which represents semantic relation infermation contain information such as semantic category and cast particles stipulating the semantic relation. An idiomatic expression between a noun and a verb is represented by a co-relation fi'ame. This is the convention for sharing case slots in case Dames to yield an effective processing for case analysis and selection of word meaning. These frames are also provided for each noun. IIcuristies are defined as methods ( daemons ) in fl'ames. The concept relation of knowledge can be represented by inheritance and semantic relation slots of noun relation fl'ames. Event state relation is represented by event-object relation fl'ames , and expressed in a word meaning of the eorresponding noun. Using this relation fFame , semantic relations in a phrase , `` Sakana we yaku nioi ( , ( rE { `` ; t } '~ { ~ ~ , ) ( Smell of fish grilling ) '' can be analysed. Me , a-knowledge is represented as a procedure for unifying frames to select a word meaning , inheritance mechanism , and methods in frames as well as heuristics. l , ' , xtended Case Analysis ( F , CA ) builds the meaning structure of a sentence which is expressed by tim fi'amework based on ECS. The ECA integrates both syntactic and semantic analysis using Structure Patterns. Analysis proceeds in , ~t manner ill which , top down structure prediction and bottom-up structure integration are intertwined. Viewing the analysis from the standpoint of the activation of lcnowledge , an expression activates a word , a word activates a word meaning , a word meaning activates concepts , and coneel ) ts activate concept relations. We will describe the prccedure for analyzing Japanese sentences in the following sections. It is assumed here that the morphological analysis process has already segmented a sentence into a sequence of words. The ECA procedure can be explained roughly as follows. First , the ECA predicts a sentence structure in a top-down manner using Structure Patterns. Second , it analyzes semantic structures for the predicted sentence structure using Semantic Structure Frames , which describe constraints for integrating the substructures. Finally , those substructures are integrated into a bigger structure. These procedures are performed recursively for each level of constituent construction until an integrated meaning structure is obtained for the entire sentence. When information concerning semantic structure frames or knowledge is missing , the ECA does not attempt to nmke a unique integrated meaning structure. Rather it utilizes a variety of heuristics , thus making it possible to order multiple possible meaning structures in terms of likelihood or plausibility based on a score given to each meaning strueture. A rough outline of this analysis is presented in Figure 5. 623 syntactic prediction meaning integration \ [ unit structure \ ] ~ ... ... ... ... ... ... . \ [ unit structure~ \ [ phrase_. __~structure ~ ... ... ... .. ~~phrase structure \ [ ~ord structure l -- -~ word , tru~t~ , ~l Fig. g Rough sketch of analysis flow tIistorieal information , including both the success and failure of the processing , is stored so that the ECA can avoid analyzing the same sequence of substructures in the backtracking process. A structure pattern is a package of knowledge for predleting syntactic constructions between pairs of modifiers and modifieants among the constituent structures of a sentence. Based on this prediction , an analysis procedure is invoked to analyze their semantic structures. If this analysis succeeds , the modifier/modificant pair is integrated into a new unified structure. Structure patterns are assigned to each structure type in the ECS. An example of structure patterns for a unit sentence is shown in Figure 6. A structure pattern eenslsts of three parts : 1 ) the condition for applying the pattern , 2 ) the procedure for semantic structure analysis , and 3 ) newly integrated structure type. The first part describes whether this structure pattern can be applied to the structure sequence. The second part performs a semantic relation analysis of the structure sequence which satisfy the above condition. The third part describes the structure type to be produced by the above procedure. A structure pattern might be viewed as a context fi'ee gramnmr ( CFG ) rule augmented with a semantic relation analysis. In this case , the condition part corresponds to the right hand side of the CFG rule , the integrated structure type part corresponds to the left hand side of it , and the procedure part can be seen as a procedure to derive the left hand side from the right hand side. For each constituent construction predicted , the semantic relation between modifier and modifieant in the construction is analyzed using semantic relation frames. Depending on the differences in structure types of the modifierhnodifieant pair , different types of semantic relations can be analyzed. In addition , the word meanings of the word structure and the categories for the integrated structure can also be analyzed. Semantic relation analysis can be explained by the analogy of a key and key-hole. A modifieant has a number of possible key-holes , and a modifier can be regarded as the key which can match it. The procedure is to search for the best matching key hole for the key. The shapes of keys and key-holes are determined by syntactic ( case particles ) and semantic ( semantic category ) information. The score given to the integrated structure represents the degree of syntactic and semantic mismatch recognized in the integration process. It is represented by a two-dimensional vectm ' , whose first argument is for syntantic mismatch , and second is for semantic mismatch. At each stage of analysis , if syntactic constraint is not pattern-name : usent-pattern-1 variables : ( case-instance case-particle sequence usent ) structure : structure-class= usent substructures : substructure : substructure-label1 = sub1 structure-class = case patterns = ( .case-instance ( restrict &gt; case-particle case-particlep ) ) substructure : substructure-label2 = sub2 structure-class = usent patterns = ( .</sentence>
				<definiendum id="0">__t</definiendum>
				<definiendum id="1">_No_</definiendum>
				<definiendum id="2">ECS )</definiendum>
				<definiens id="0">&lt; kqa_~__ J t ... .. ... ... , ,.uot ... . ¼ i Fig. 1 Extended Case Structure Model situation in which the utterance is carried out. Information in the LSF is used for filling in missing cases , and resolving anaphora. A discussion of the detailed procedure for the assimilation would be beyond the scope of this paper. The Extended Case Structure Model (</definiens>
				<definiens id="1">a linguistic model for representing the meaning structures of the text. Thus the ECS presents a representation scheme for the episodic memory. Figure 1 shows its fundamental construction. The traditional case structure ( Fillmorean type ) is a structure for a unit sentence which consists mainly of relations between nouns and a verb. This is not sufficient to represent structures of real sentences which sometimes have complex noun phrases , compound sentences , etc. Also , the ECS has to have facilities for representing other structures involving relations between a noun and a noun , a verb and a verb , etc. The ECS has been designed to integrate those structures into one linguistic model. Its nature is hierarchical as to the compoundness of constituents , iterative as to conjunction , and recursive as to embedding. Using these formalisms , the syntactic and semantic structures of sentences can be represented uniformly and correctly. There are two types of semantic structurcs , composite and primitive structures. A cmnposite structure is made by integrating semantic structures using semantic relations. A primitive structure , by definition , can not be divided into further substructures. In general , a single word corresponds to a primitive structure , and a phrase corresponds to a composite structure. Since syntactic information can also contribute to define meaning structures , each semantic structure simultaneously incorporates not only meaning information but also syntactic information. We do not assume a language-independent universal semantic representation. Thus , it is necessary to define a proper ECS for each language : Japanese ECS ( J-ECS ) \ [ 6\ ] for Japanese language and English ECS ( E-ECS ) \ [ 7\ ] for English language. In the translation process from Japanese into English , the analysis procedure generates a J-ECS for a Japanese sentence , and the transfer procedure generates an E-ECS corresponding to the J-ECS. Senmntic relation connects semantic structures and builds a larger semantic structure , ranging from a word structure to a sentence structure. Figure 2 shows types of semantic relations , and each of them can be explained briefly as fellows : 1 ) Noun relation : Relationship between nouns ; Examples are whole-part , upper-lower , possession , material , etc. 2 ) Case relation : Relationship between a case element and a predicate ; Examples are object , agent , instrument , place , etc. 622 3 ) Embedded relation : Relationship between an embedded sentence and a noun phrase , which can be categorized into three types ; a ) case re'lation between a modified noun phrase and the predicate iu a modifier embedded sentence , b ) noun relation between a modified noun phrase and a noun phrase in a modifier embedded sentence , and c ) an appositive or subsidiary relation between a modified noun phrase and a modifier embedded sentence. 4 ) Conjunctive relation : Relationship between sentences ; Examples are cause-result , time-advance , assumption , etc. Concepts are associated with structures mentioned above. Among them , concepts associated with word structures represent word meanings which appear when the words are used in a sentence. A word meaning is represented by principal concepts , supplenmntary concepts , and their semantic dependencies. Principal and supplementary concepts are dcfined by using semantic categories , and prepared for nouns , adverbs , verbs , adjective-verbs and modalities as shown in Figure 3. Semantic dependencies are defined by using semantic relation fi'ames and semantic structure frames. Semantic categories , semantic relation fi'amcs and semantic structure frames have the following characteristics : 1 ) There are two types of concepts : prototype and instance. Prototypes play a part of selectional constraint to define semantic dependency structures. Instances show an assimilated structure which satisfies the selectienal constraints. 2 ) They shows semantic commonness and analogy between two structures. This allows the system to share information and to provide facilities for paraphrase. 3 ) Semantic categories make tip a hierarchical structure. This provides the system with inheritance ability and information sharing. There are two typos of dictionaries in LUTE. Mono-liugual dictionaries are used in analysis and generation , while bMingual dictionaries are used in transfer. Mono-lingual dictionaries have the following information about words and concepts : 1 ) tIow the word is expressed , 2 ) how the word is used in the syntax of a sentence , and 3 ) what concept the word corresponds to. Bi-lingual dictionaries has information on the correspondence of concepts in two different languages , and will be explained in section 6. ( Note that concepts are defined here by associating structures which are generally language dependent. ) Figure 4 shows the contents of a word dictionary. A word meaning can be regarded as an entry to the conceptual knowledge description. The LUTE dictionaries contain the following semantic information : 1 ) Semantic category ( for word meanings ) : Principal concepts associated with the word meaning. Those for nouns and adverbs are used as selectional constraints in semantic relation analysis. Those for predicate s are used to analyse modality. 2 ) Case fi'ame ( for predicate word meanings ) : Constraints and case relations which are applied to construct unit sentence semantic structures. There are three types of ease frames : intrinsic for each predicate word nmaning , common for several predicate word meanings , optional for outer ease relations. 3 ) Noun relation frame ( for noun word meanings ) : Constraints and semantic relationships which ace applied to construct semantic structures made up of two nouns. Case frames are also used as a ldnd of object relation frames for predicate-type nouns. 4 ) Event relation frame ( for predicate word meanings ) : Constraints and semantic relationships to be applied to construct complex sentence semantic structures. An example is the relation between the verb in a main clause and the verb in a subordinate clause. 5 ) Heuristics ( for semantic categories and relation fi'ames ) : This is used for resolving ambiguity of semantic categories , semantic relations , and semantic structures by linguistic information such N~oun-ielalot~ ... . tri~ci ; on ca~se~rel -- ati~on ; gent : a-ctio~n~objec~t -- actio~i-nst -- ru -- n , e , ; t~ ; ctio~n ' -Catego-ries for-~ouns-a~ld adverbs : : = , -~a-ture~m-a-teriT ; i lnstri , , , ~ ; ~ , i i ... . time-action location-action destination-action source-aetim~ co-object-action mannerI society organization \ [ cultllre i buman l action l state \ [ number l degree l enmtion l action freque cy-action object-state action-location action-time action-result actiontime l location| a bstract l concrete animate J plant I others degree I state'object property-object possessor-object number-object material-object Categories for verbs : : = voice active statlve movemental I transitional\ ] Iota , on-object object.property object-element object-number object-location speciesemotional I thinking perceptual existential judgenlental non-willing object l re ative-location Iocat on-specificatio ~ time-specification human-relation nounv oi c e : : = passive l affected-passive possible l sponraneous causa tive \ ] pet fective I cative : : =momentallcontinual suffix prefix-noun \ [ parallel l others Case relation : : = OBJECT-TYPE METHOD-TYPE DfRECTION-TYPEJ TIME-SPACE-TYPE 1 stative : : = ~ teiru\ [ -teiru Categories for adlectives and adjective-verbs : : = SUPPLEMENT-TYPE I MODIFICATION-TYPE 0 gJ E CT-TY PE : : = object I co-object \ [ statem ent-object J compared-object I seconds ry-obje ct I theme J agent \ [ experiencer METHOD-TYPE : : = method I instrument I material\ [ element I ca use DIRECTION-TYPE : : = source I destination I purpose I result \ ] giver I recipient TIME-SPACE-TYPE : : = location J time SUPPLEMENT-TYPE : :=Ocasion content role contrast region MODIFICATION-TYPE : : = manner \ [ frequency degree tbing rate I number emphasis I true tf Embedded relation : : = case relation\ ] relation that modified noun phrase modify case instance in tJm enlbedded sentencel apposition.Event-result Con unctive relation : : = condition right-affirmative cause lpurposelright assumption\ [ contrary-assumption contrary-affirmativeljuxtaposition introducr on pallare t merelation before simultaneous after continuation limitecl-continuationlduring I examplilTcation selection interrogative-contentslcitationlexplanationlspecificlnlinimal. limit proportion degree I limit stative I charactedstk \ ] relational I emotional Categories for modalities : : = as pect : : = beghlning just-before-beginning Ijust-after.beginning I continuous I repetitive I perfective \ ] just-before.perfective Ijust-after-perfective I perfecrivestate I others tense : : =past present future modal : : = negation possibility necessarity obligation I necessity I inevitability I favorability \ [ sufficiency I guess I affirmative \ ] confidential-guess I uncertahla ffirnlative estimation guess uncertain-guess l hearsay l intention willingness I plan hope try causative secood-pelson command interrogative request I pernlission invitation third-person l causa tive \ ] request I passive I spon tanity \ [ bene factive \ [ polite I respect I o , hers manner : : =limited degree \ [ extr eme-e xample l stress l exan\ ] plification \ ] parallel ladditionlselection uncertainty distinction others Fig. 2 Semantic Relations Fig. 3 Semantic Categories as preference over several semantic relations , semantic relation fillers , and remaining semantic relation fi'ames not yet filled. Both comnmn.-sense knowledge and expertdmowledge are constructed using basic elements such as concepts , , 'elations and structures as well as linguistic structures. Thus the non-lingulstlc knowledge manipulated in LUTI , ; is not represented in a simple database fl'amework but rather incorporated into the memory structure. Although re.troy language processing systems use the term `` knowledge '' rather vaguely , LU\ [ \ [ 'Itl gives a concrete form to knowledge in the sense of franmmetworks corresponding to word meanings. The current version of I , UTE defines the following types of knowledge in terms of semantic relations : 1 ) Concept Relation : Relations such as hyponymy , synonymy , antonymy , whole-part , and possession. One example is `` wholepart '' rehttion between `` densha ( ; ~ ii'- ' ) ( train ) '' and `` made ( ~ ) ( window ) '' . ( A window can be a part era train. ) 2 ) Event State Relation : Relations between two events or between an event and a state. One example is `` subsidiary situation '' relation that `` nioi ( ~ ~ ) ( smell ) '' results from `` yaku ( 'l ' ) '~ &lt; ) ( grill ) '' . 3 ) Mete knowledge : This is used for reasoning , such as in traversing the concept networks , and checMng semantic consistency according to concept networks. All information manipulated in LUTE is represented in a uniform frameworlt , called a Frame-Network. F , ach type of { lictiouary infermarion such as semantic category , case frame , noun relation frame , Entry Information ( Kanji-Code , Root-Form ) I tactic I~forma~ion ( Part-of-~peeeh. Co~jugat~omtype ) \ ] onin _3 • • • • . . -- I Obi~ct a~ , at , o , ,~ ... . 1~ ... I Object Relation F ... . S \ ] -- 1 E~entaelationFramel\ ] `` °° \ [ Eventaelatio~F ... . t\ ] Fig'. 4 Contents of dictionary ( nlono-lingual ) and event relation fi'ame is represented by frames with correspondlng frame names. These fi'amcs consist of subframes representing semantic relation information. Slots of a frame which represents semantic relation infermation contain information such as semantic category and cast particles stipulating the semantic relation. An idiomatic expression between a noun and a verb is represented by a co-relation fi'ame. This is the convention for sharing case slots in case Dames to yield an effective processing for case analysis and selection of word meaning. These frames are also provided for each noun. IIcuristies are defined as methods ( daemons ) in fl'ames. The concept relation of knowledge can be represented by inheritance and semantic relation slots of noun relation fl'ames. Event state relation is represented by event-object relation fl'ames , and expressed in a word meaning of the eorresponding noun. Using this relation fFame , semantic relations in a phrase , `` Sakana we yaku nioi ( , ( rE { `` ; t } '~ { ~ ~ , ) ( Smell of fish grilling ) '' can be analysed. Me , a-knowledge is represented as a procedure for unifying frames to select a word meaning , inheritance mechanism , and methods in frames as well as heuristics. l , ' , xtended Case Analysis ( F , CA ) builds the meaning structure of a sentence which is expressed by tim fi'amework based on ECS. The ECA integrates both syntactic and semantic analysis using Structure Patterns. Analysis proceeds in , ~t manner ill which , top down structure prediction and bottom-up structure integration are intertwined. Viewing the analysis from the standpoint of the activation of lcnowledge , an expression activates a word , a word activates a word meaning , a word meaning activates concepts , and coneel ) ts activate concept relations. We will describe the prccedure for analyzing Japanese sentences in the following sections. It is assumed here that the morphological analysis process has already segmented a sentence into a sequence of words. The ECA procedure can be explained roughly as follows. First , the ECA predicts a sentence structure in a top-down manner using Structure Patterns. Second , it analyzes semantic structures for the predicted sentence structure using Semantic Structure Frames , which describe constraints for integrating the substructures. Finally , those substructures are integrated into a bigger structure. These procedures are performed recursively for each level of constituent construction until an integrated meaning structure is obtained for the entire sentence. When information concerning semantic structure frames or knowledge is missing , the ECA does not attempt to nmke a unique integrated meaning structure. Rather it utilizes a variety of heuristics , thus making it possible to order multiple possible meaning structures in terms of likelihood or plausibility based on a score given to each meaning strueture. A rough outline of this analysis is presented in Figure 5. 623 syntactic prediction meaning integration \ [ unit structure \ ] ~ ... ... ... ... ... ... . \ [ unit structure~ \ [ phrase_. __~structure ~ ... ... ... .. ~~phrase structure \ [ ~ord structure l -- -~ word , tru~t~ , ~l Fig. g Rough sketch of analysis flow tIistorieal information , including both the success and failure of the processing , is stored so that the ECA can avoid analyzing the same sequence of substructures in the backtracking process. A structure pattern is a package of knowledge for predleting syntactic constructions between pairs of modifiers and modifieants among the constituent structures of a sentence. Based on this prediction , an analysis procedure is invoked to analyze their semantic structures. If this analysis succeeds , the modifier/modificant pair is integrated into a new unified structure. Structure patterns are assigned to each structure type in the ECS. An example of structure patterns for a unit sentence is shown in Figure 6. A structure pattern eenslsts of three parts : 1 ) the condition for applying the pattern , 2 ) the procedure for semantic structure analysis , and 3 ) newly integrated structure type. The first part describes whether this structure pattern can be applied to the structure sequence. The second part performs a semantic relation analysis of the structure sequence which satisfy the above condition. The third part describes the structure type to be produced by the above procedure. A structure pattern might be viewed as a context fi'ee gramnmr ( CFG ) rule augmented with a semantic relation analysis. In this case , the condition part corresponds to the right hand side of the CFG rule , the integrated structure type part corresponds to the left hand side of it , and the procedure part can be seen as a procedure to derive the left hand side from the right hand side. For each constituent construction predicted , the semantic relation between modifier and modifieant in the construction is analyzed using semantic relation frames. Depending on the differences in structure types of the modifierhnodifieant pair , different types of semantic relations can be analyzed. In addition , the word meanings of the word structure and the categories for the integrated structure can also be analyzed. Semantic relation analysis can be explained by the analogy of a key and key-hole. A modifieant has a number of possible key-holes , and a modifier can be regarded as the key which can match it. The procedure is to search for the best matching key hole for the key. The shapes of keys and key-holes are determined by syntactic ( case particles ) and semantic ( semantic category ) information. The score given to the integrated structure represents the degree of syntactic and semantic mismatch recognized in the integration process. It is represented by a two-dimensional vectm ' , whose first argument is for syntantic mismatch , and second is for semantic mismatch. At each stage of analysis , if syntactic constraint is not pattern-name : usent-pattern-1 variables : ( case-instance case-particle sequence usent ) structure : structure-class= usent substructures : substructure : substructure-label1 = sub1 structure-class = case patterns = ( .case-instance ( restrict &gt; case-particle case-particlep ) ) substructure : substructure-label2 = sub2 structure-class = usent patterns = (</definiens>
			</definition>
			<definition id="5">
				<sentence>Modality analysis consists of the following three modules combined with case analysis and conjunctive analysis : ( l ) Pro-ease-analysis : A modality which causes a change in the case structure is analyzed at this stage .</sentence>
				<definiendum id="0">Modality analysis</definiendum>
				<definiens id="0">A modality which causes a change in the</definiens>
			</definition>
			<definition id="6">
				<sentence>Word meaning is an entry fl'mn a word to the conceptual network consisting of dictionary information and knowledge .</sentence>
				<definiendum id="0">Word meaning</definiendum>
				<definiens id="0">an entry fl'mn a word to the conceptual network consisting of dictionary information and knowledge</definiens>
			</definition>
			<definition id="7">
				<sentence>The information available for the determination of word meaning is the accumulated situation ( discourse information ) and the accumulated word meanings ( accumulated concepts ) .</sentence>
				<definiendum id="0">word meaning</definiendum>
			</definition>
			<definition id="8">
				<sentence>2 ) If `` tame'is succeeded lay an embedded sentence and the predicate shows a perfective aspect ( that is , the end part of tile embedded sentence contains the auxiliary verb `` ta ( t : ) '' or `` teiru ( -C ~ ' 7o ) '' ) , or the semantic category of the predicate is `` state '' , the category is determined to be `` cause '' .</sentence>
				<definiendum id="0">`` teiru</definiendum>
				<definiens id="0">the end part of tile embedded sentence contains the auxiliary verb `` ta ( t : ) '' or</definiens>
			</definition>
			<definition id="9">
				<sentence>So , the transfer process consists of transfering components of the ECS 's , i.e. , concepts that make up the ECS and relations which hold among them .</sentence>
				<definiendum id="0">transfer process</definiendum>
				<definiens id="0">consists of transfering components of the ECS 's , i.e. , concepts that make up the ECS and relations which hold among them</definiens>
			</definition>
			<definition id="10">
				<sentence>The transfer ef concepts consists of 1 ) transfer of semantic categories , and 2 ) transfer of word meanings .</sentence>
				<definiendum id="0">transfer ef concepts</definiendum>
				<definiens id="0">consists of 1 ) transfer of semantic categories , and 2 ) transfer of word meanings</definiens>
			</definition>
			<definition id="11">
				<sentence>The LUTE is an experimental machine translation system between Japanese and English developed by applying ~he investigations mentioned above .</sentence>
				<definiendum id="0">LUTE</definiendum>
				<definiens id="0">an experimental machine translation system between Japanese and English developed by applying ~he investigations mentioned above</definiens>
			</definition>
</paper>

		<paper id="1115">
			<definition id="0">
				<sentence>There is an f-structure d and a mapping f from the set of nodes of c to the set of subDAGs of d such that d is a unique minimal f-structure that satisfies the annotations associated with the c-structure nodes ( f and d are constructed by the fdescription solution algorithm , for short KB-algorithm ) .</sentence>
				<definiendum id="0">c-structure nodes</definiendum>
				<definiens id="0">a unique minimal f-structure that satisfies the annotations associated with the</definiens>
			</definition>
			<definition id="1">
				<sentence>DEF A derivation is a sequence s0 ... s n where s i = : &lt; c , d , f &gt; ; 0~i~ &lt; n ; c = : c-structure ; d = : partial f-structure f~ IN ( c ) - &gt; T ( d ) \ ] ( mapping from the c-struoture nodes ( N ( c ) ) to the subDAGs of '' d ( T ( d ) ) ) So= : start triple s= : derived triple ; with a c-structure of a terminal string si .</sentence>
				<definiendum id="0">DEF A derivation</definiendum>
				<definiens id="0">start triple s= : derived triple ; with a c-structure of a terminal string si</definiens>
			</definition>
			<definition id="2">
				<sentence>5 ) The new DAG d ' is then the minimal extension of d which results from unifying the DAG which is introduced by the rule with that subDAG of d to which the expanded node was mapped qua f. d &amp; , 'A '' ~ @ t .</sentence>
				<definiendum id="0">'A</definiendum>
				<definiens id="0">the minimal extension of d which results from unifying the DAG which is introduced by the</definiens>
			</definition>
			<definition id="3">
				<sentence>l~- &gt; s i = &lt; w ' , d ' , g ' &gt; &lt; - &gt; w-F &gt; w ' and if &lt; i , wi &gt; is the replaced occurrence d , =r\ ] { d.gDAG\ [ dt_-_-d '' , , , ¥~PATH ( g ( &lt; i , v~ &gt; ) =dp - &gt; d '' p=dpudr ) } g'~\ [ w ' - &gt; T ( d ' ) l Vj~Dom ( w ' ) ( j &lt; i- &gt; Vly , PATH ( g ( &lt; j , ~ &gt; ) =dp - &gt; g ' ( &lt; j , w ; &gt; ) =d'P ) ) VjsDom ( w ' ) ( j &gt; ~i+ ( lP e ( r ) l ) - &gt; VpePATH ( g ( &lt; J- ( IP2 ( r ) I-I ) ~ ' &gt; ) =dP - &gt; g ' ( j , w ' &gt; ) =d'p ) ) Vj~Dom ( w ' ) ( i~j &lt; i+lP2 ( r ) l - &gt; Vp , p'ePATH ( g ( &lt; i , ~ &gt; ) =dp ^ g r ( &lt; j- ( i-1 ) , w~ &gt; =drP ' - &gt; g ' ( &lt; j , w~ &gt; ) =d'pp ' ) ) One obtains the monostratal version quite naturally if for all triples &lt; w , d , g &gt; of a derivation and a rule 's right side in the string version the arguments of g are attached as additional labelled edges to the start nodes of the subDAGs of d to which they are assigned qua g. Thus one obtains for the start triple , the derived triple s i.1 and the rule r the following structures : 6 ) So 11 si\ [ , ~/CI~ -- ~Z~ vp 11 ~ Np , ~ v0 ~\v NP VP V If &lt; w , d , g &gt; is a triple of the string version then a DAG s= N { d'eDAGId-C ; d'^ V &lt; i , w i &gt; ~w VpePATH ( g ( &lt; i , w i &gt; ) =dp- &gt; d'p ( i ) =~ ) } is the corresponding entity in the monostratal version .</sentence>
				<definiendum id="0">=d'p ) ) Vj~Dom ( w</definiendum>
				<definiens id="0">a triple of the string version then a DAG s= N { d'eDAGId-C</definiens>
			</definition>
			<definition id="4">
				<sentence>DEF Vs eFSe ( S ( s ) = { &lt; i , x &gt; e//VxVl~ P ~PATH ( sp ( i ) =x ) } The derivation concept is defined as follows : DEF A derivation is a sequence s 0 ... s n where si~FSe ; 0~ &lt; i~n ; So -- : .-1 , S S ( Sn ) eVT* ; si.-y-v &gt; si ; 0 &lt; i &lt; , n As in this version the occurrences are attached as edges to the start nodes of those subDAGs , to which they are assigned in the string version , an adequate concept of direct derivability can be inferred from the definition of the preceding section. One properly re-indexes the DAG s i . 1 and the DAG , which is introduced by the rule ( d , dr ) , according to the definition of g'. The derived DAG is constructed by the elimination of the edge to be replaced , and the unification of d r with that subDAG of d , to which the replaced edge was attached. A successful unification in the string version ca n't fail here because the labels of the additional edges of d ( after elimination of the edge to be replaced ) and d r are pairwise different. In the example the result of the application of T on &lt; 3 , VP &gt; of s i .</sentence>
				<definiendum id="0">DEF Vs eFSe ( S</definiendum>
				<definiendum id="1">DEF A derivation</definiendum>
			</definition>
			<definition id="5">
				<sentence>1 is defined as follows : IA o~ v6/\b~ &lt; ~ , A t ~ 1 '' 2 ~ , ~\~°o_~-\~ NP NP \~ ~ NP VP NP ~ ~p V ' V ' NP The concept of direct derivability is defined in the following way : DEF s=s i.T -- -~- &gt; si=s ' &lt; - &gt; ~pePATH3i~N ( sp ( i ) =p I ( ~ ) ^ s'=\ [ -\ ] { d'e DAGId~-d ' ^ d'p=dp u d r ) ) with C as the set of atomic values and s r as righthand side of i : VI ) ~PATH ( s rp~C- &gt; d'p=SrP ) A , ) d r =lT { d'eDAG VpePATH ( s r p\S ( Sr ) =¢- &gt; d'p\S ( d ) =¢ ) ^ VI ) ePATHVj~-~/ ( s p ( j ) =d'p ( j+ ( i1 ) ) ) J Vp~PATH ( speC- &gt; d'p=sp ) ^ \ [ Vpel~ATII ( sp\S ( s ) =~- &gt; d'p\S ( d ' ) =¢ ) ~ ' , d=\ [ ~ ( d'e DAG I VpePATIIVj¢~/ ( j &lt; i- &gt; d , p ( j ) =sp ( j ) ) / ' , 1VpePATHVj~gC ( j &gt; i- &gt; d p ( j+IS ( §. )</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the following way : DEF s=s i.T -- -~- &gt; si=s ' &lt; - &gt; ~pePATH3i~N ( sp ( i ) =p I ( ~ ) ^ s'=\ [ -\ ] { d'e DAGId~-d ' ^ d'p=dp u d r ) ) with C as the set of atomic values and s r as righthand side of i : VI ) ~PATH ( s rp~C- &gt; d'p=SrP ) A , ) d r =lT { d'eDAG VpePATH ( s r p\S ( Sr ) =¢- &gt; d'p\S ( d ) =¢ ) ^ VI ) ePATHVj~-~/ ( s p ( j ) =d'p ( j+ ( i1 ) )</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>This context consists of more than mere knowledge of the previous questions and answers .</sentence>
				<definiendum id="0">context</definiendum>
			</definition>
			<definition id="1">
				<sentence>A context model is one component of a user model .</sentence>
				<definiendum id="0">context model</definiendum>
				<definiens id="0">one component of a user model</definiens>
			</definition>
			<definition id="2">
				<sentence>Having thus hypothesized that perhaps Sells ( UDEL-BOOKSTORE , &lt; z &gt; : DISK ) from Sells ( UDEL-BOOKSTORE , &lt; v &gt; : TECHBOOK ) Sells ( UDEL-BOOKSTORE , &lt; w &gt; : NONTECHBOOK ) Sells ( UDEL-BOOKSTORE , &lt; x &gt; : TEXTBOOK ) IP can hypothesize the higher-level goaLs Purchase ( IS , &lt; z &gt; : DISK ) Have ( IS , &lt; z &gt; : DISK ) the last of which is a component of IP 's model of IS .</sentence>
				<definiendum id="0">TECHBOOK ) Sells</definiendum>
				<definiens id="0">a component of IP 's model of IS</definiens>
			</definition>
			<definition id="3">
				<sentence>Dissertation , Department of Computer Science , University of Delaware , 1985 Carberry , Sandra , `` Tracking User Goals in an InformationSeeking Environment '' , Proceedings of the National Conference on Artificial Intelligence , 1983 Carberry , Sandra , `` Using Inferred Knowledge to Understand Pragmatically Ill-Formed Queries '' , to appear in Communication Failure in Dialogue , Ronan Reilly editor , North Holland , 1986 Doyle , Jon , `` A Truth Maintenance System '' , Artificial Intelligence 12 ( 3 ) , 1979 Grice , H. P. , `` Logic and Conversation '' , In Syntax and Semantics , Cole and Morgan , editors , Academic Press , 1975 Grice , H. P. , `` Utterer 's Meaning and Intentions '' , Philosophical Review 68 , 1969 Grice , H. P. , `` Meaning '' , Philosophical Review 56 , 1957 Grosz , Barbara , `` Focusing and Description in Natural Language Dialogues '' , in Elements of Discourse Understanding , Joshi , A. , Webber , B. , and Sag , I. , editors , Cambridge University Press , 1981 Grosz , Barbara , `` The Representation and Use of Focus in a Sys= tem for Understanding Dialogs '' , Proceedings of the International Joint Conference on Artificial Intelligence , 1977 Joshi , Aravind K. , `` Mutual Beliefs in Question-Answer Systems '' , Mutual Knowledge , Academic Press , 1983 Kaplan , S. Jerroid , `` Cooperative Responses from a Portable Natural Language Query System '' , Artificial Intelligence 19j 1982 Litmus , Diane J. and Alien , James F. , `` A Plan Recognition Model for Clarification Subdialogues '' , Proceedings of the International Conference on Computational Linguistics , 1984 McCoy , Kathleen F. , `` Generating Responses to Property Misconceptions Using Perspective '' ~ to appear in Communication Failure in Dialogue , Ronan Reilly , Editor , 1986 McKeown , Kathleen R. , Te~t Generation , Cambridge University Press , 1985 Perrault , C. 1L and Allen , J. F. , `` A Plan-Based Analysis of Indirect Speech Acts '' , American Journal of Computational Linguistics , 1980 Pollack , Martha , `` Inferring Domain Plans in QuestionAnswering '' , forthcoming Ph.D .</sentence>
				<definiendum id="0">Utterer 's Meaning</definiendum>
				<definiendum id="1">Meaning</definiendum>
				<definiens id="0">'' , Philosophical Review 56 , 1957 Grosz , Barbara , `` Focusing and Description in Natural Language Dialogues '' , in Elements of Discourse Understanding , Joshi , A. , Webber , B. , and Sag , I. , editors , Cambridge University Press , 1981 Grosz , Barbara</definiens>
			</definition>
</paper>

		<paper id="1087">
			<definition id="0">
				<sentence>The surface scheme of a Hungarian sentence Js the following : ( &lt; A~ &lt; S NT &lt; V NF ) ' ) ~ &lt; V F &gt; ( ~A &gt; ' &lt; S N~ &lt; V NE &gt; * ) ~ where A stands for adverbials , S for nominal and V for verbal stems , N for nominal case endings , F for finite and NE for non-finite verbal suffixes .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">A~ &lt; S NT &lt; V NF ) ' ) ~ &lt; V F &gt; ( ~A &gt; ' &lt; S N~ &lt; V NE &gt; * ) ~ where A stands for adverbials</definiens>
				<definiens id="1">verbal stems</definiens>
			</definition>
			<definition id="1">
				<sentence>Such modulcs consist o£ rules \ ] : he \ ] eft sides of which are sJmJ .</sentence>
				<definiendum id="0">Such modulcs</definiendum>
			</definition>
</paper>

		<paper id="1061">
			<definition id="0">
				<sentence>256 repl~sentation called HPN ( IIierarchical Propositional Network ) , where integer importance values are assigned to tile basic conceptual units of the ELR ( concepts and propositions ) , in snch a way as to account for tile different importance of the constituents of the text .</sentence>
				<definiendum id="0">integer importance values</definiendum>
				<definiens id="0">assigned to tile basic conceptual units of the ELR ( concepts and propositions</definiens>
			</definition>
			<definition id="1">
				<sentence>om rhetoric predicates of the ELR , structural-semantic ( SS ) rules rely on the analysis of specific structural features of tile text that have a definite semantic role , such as ISA relations and macro-predicates of tile ELR , semantic-encyclopedic ( SE ) rules refer to world knowledge contained in the encyclopedia , explicit evahtation ( EEl rules take into account explicit statements concerning importance sometimes purposedly inserted in tile text by file author , and , finally , metarules ( MT ) embody strategic knowledge that concerns reasoning about importance rules aud their use .</sentence>
				<definiendum id="0">EEl rules</definiendum>
				<definiens id="0">take into account explicit statements concerning importance sometimes purposedly inserted in tile text by file author , and , finally , metarules ( MT ) embody strategic knowledge that concerns reasoning about importance rules aud their use</definiens>
			</definition>
			<definition id="2">
				<sentence>The operation of tile evaluator obeys the basic recognize-act cycle of a rule-based system .</sentence>
				<definiendum id="0">operation of tile evaluator</definiendum>
				<definiens id="0">obeys the basic recognize-act cycle of a rule-based system</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>I. Introduction A parser is a key component of a machine translation ( MT ) system .</sentence>
				<definiendum id="0">parser</definiendum>
			</definition>
			<definition id="1">
				<sentence>A subgrammar is a set of rewriting rules and the whole grammar is expressed as a network of such subgrammars ( subgrammar-netw ork ) .</sentence>
				<definiendum id="0">subgrammar</definiendum>
				<definiens id="0">a network of such subgrammars ( subgrammar-netw ork )</definiens>
			</definition>
			<definition id="2">
				<sentence>-- ( i ) This type of construction can be handled by the rules of the context free grammar ( CFG ) shown in figure i. S - '' S ' ' : ' IF ' ' IF - '' IFL 'and ' IFE IFL -~ IFE IFL ~ IFE ' , ' IFL IFE ~ IN NP IN -~ NUMBER ' ) ' NP -~ DET N : rules for itemized forms S -~ S ' ' ' : rules for S ' -NP VP structural analysis S : Sentence , IF : Itemized Form , IFL : List of Itemized Element , IFE : Element of Itemized Form , IN : Item Number , NP : Noun Phrase Figure 1 Context Free Rules for processing Itemized Forms However , if rewriting rules to handle such sentence constructions are added to the analysis grammar , the following problems would arise : a ) Deterioration of analysis efficiency : Rewriting rules which need not be referred to in a structural analysis will increase .</sentence>
				<definiendum id="0">IFE</definiendum>
				<definiendum id="1">IN</definiendum>
				<definiens id="0">rules for itemized forms S -~ S ' ' ' : rules for S ' -NP VP structural analysis</definiens>
			</definition>
</paper>

		<paper id="1137">
			<definition id="0">
				<sentence>Functional unification ( FU ) grammar is a general linguistic formalism based on the merging of feature-sets .</sentence>
				<definiendum id="0">Functional unification</definiendum>
				<definiendum id="1">FU ) grammar</definiendum>
				<definiens id="0">a general linguistic formalism based on the merging of feature-sets</definiens>
			</definition>
			<definition id="1">
				<sentence>Functional unification ( FU ) grammar is a grammatical formalism which allows descriptions of linguistic structures to be expressed as functional descriptions ( FDs ) , which are sets of `` features '' \ [ attribute-value pairs ) , and grammatical derivation is expressed in terms of these structures .</sentence>
				<definiendum id="0">Functional unification</definiendum>
				<definiendum id="1">FU ) grammar</definiendum>
				<definiens id="0">a grammatical formalism which allows descriptions of linguistic structures to be expressed as functional descriptions ( FDs ) , which are sets of `` features '' \ [ attribute-value pairs ) , and grammatical derivation is expressed in terms of these structures</definiens>
			</definition>
			<definition id="2">
				<sentence>In an FD E , any feature F whose feature-name is listed in the value of the PATTERN feature at the same level of nesting within E is a constituent .</sentence>
				<definiendum id="0">FD E</definiendum>
				<definiens id="0">a constituent</definiens>
			</definition>
			<definition id="3">
				<sentence>A FD F is well-formed with respect to the grammar G if there is an FD E in G such that F is an extension of E , and every constituent of F ( see above ) is well-formed with respect to G. An arbitrary FD can be used as the initial structure in deriving a fuller FD .</sentence>
				<definiendum id="0">FD F</definiendum>
				<definiens id="0">an FD E in G such that F is an extension of E</definiens>
			</definition>
			<definition id="4">
				<sentence>Then FI derives F2 using grammar G if F2 is well-formed with respect to G , and F2 is an extension of FI .</sentence>
				<definiendum id="0">F2</definiendum>
				<definiens id="0">an extension of FI</definiens>
			</definition>
			<definition id="5">
				<sentence>F 's constituents are exactly the values of the features Ci ( as in ( I ) ) , so for each of these FDs there must be an FD in the grammar of which the constituent FD is an extension .</sentence>
				<definiendum id="0">FD</definiendum>
				<definiens id="0">an extension</definiens>
			</definition>
			<definition id="6">
				<sentence>Berwick gives an explanation of why computational complexity is relevant to linguistic theory , and why NP-hardness is an undesirable property for a linguistic computation .</sentence>
				<definiendum id="0">Berwick</definiendum>
				<definiendum id="1">NP-hardness</definiendum>
				<definiens id="0">gives an explanation of why computational complexity is relevant to linguistic theory</definiens>
			</definition>
</paper>

		<paper id="1139">
			<definition id="0">
				<sentence>This again is a chart parser , which for one go is initialized with the NP 's , PP 's , and AP 's as terminal categories and the parts constituting the first verb-group hypothesis .</sentence>
				<definiendum id="0">AP</definiendum>
				<definiens id="0">a chart parser , which for one go is initialized with the NP 's , PP 's , and</definiens>
			</definition>
</paper>

		<paper id="1088">
			<definition id="0">
				<sentence>The corn of DRT ( and File Change Semantics ) is the treatment of indefinite noun phrases as reference establishing terms ( as opposed to their standard truth-conditional quantifier analysis , but in accordance with the treatmant of indefinites in NLP research ) and definite noun phrases ( pronouns as well as full NPs ) as anaphoric expressions .</sentence>
				<definiendum id="0">corn of DRT</definiendum>
				<definiens id="0">the treatment of indefinite noun phrases as reference establishing terms</definiens>
			</definition>
			<definition id="1">
				<sentence>368 ( 4 ) K2 : xyzu John ( x ) x owns y book ( y ) X=Z x reads u u=y The step-by-step construction of a DRS for a given text is the first part of its semantic analysis .</sentence>
				<definiendum id="0">x ) x owns y book</definiendum>
				<definiens id="0">the first part of its semantic analysis</definiens>
			</definition>
			<definition id="2">
				<sentence>For each of these classes , Kamp states a distinction between a deictic and an anaphoric use , and thus ends up with eight different types of definite noun phrases .</sentence>
				<definiendum id="0">Kamp</definiendum>
				<definiens id="0">states a distinction between a deictic and an anaphoric use</definiens>
			</definition>
			<definition id="3">
				<sentence>The discourse referent for the demonstrative NP this ot or that oL is , roughly speaking , linked to the most salient referent already contained in the DRS which satisfies the common-noun phrase ~ , Satisfaction of oL by x roughly means that the predication ~ ( x ) follows from the data available in K about x , possibly using additional background knowledge .</sentence>
				<definiendum id="0">discourse referent</definiendum>
				<definiens id="0">satisfies the common-noun phrase ~</definiens>
			</definition>
			<definition id="4">
				<sentence>A concept of current universe CUamust be employed , CU~ , being a distinguished subpart of the universe of discourse and consisting of a current-sentence position ( CUo , ~¢ ) and a lastsentence position ( CU s , ,¢ ) .</sentence>
				<definiendum id="0">CU</definiendum>
				<definiens id="0">s , ,¢ )</definiens>
			</definition>
			<definition id="5">
				<sentence>Finally , the consU'uction rule for anaphoric pronouns needs a slight reformulation ; ( 3 ) ( iii ) has to be replaced by : ( 13 ) Add x = y to K for some y ~ CU K This is only a first attempt to fix the local range of pronominal anaphora .</sentence>
				<definiendum id="0">consU'uction rule</definiendum>
				<definiens id="0">iii ) has to be replaced by : ( 13 ) Add x = y to K for some y ~ CU K</definiens>
			</definition>
			<definition id="6">
				<sentence>The uniqueness condition , which Kamp models with selection sets , should better be viewed as a very general conversational requirement , i.e. that the intended object of reference must be unambiguously more salient than each other possible candidate .</sentence>
				<definiendum id="0">uniqueness condition</definiendum>
				<definiens id="0">a very general conversational requirement</definiens>
			</definition>
			<definition id="7">
				<sentence>Kamp suggests that background information be stored in some DRS-like format ( Kmnp 1985 ) .</sentence>
				<definiendum id="0">Kamp</definiendum>
			</definition>
			<definition id="8">
				<sentence>371 Kamp gives as evidence for his non-uniqueness assumption examples like thatpope , which is odd or at least highly marked .</sentence>
				<definiendum id="0">Kamp</definiendum>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>( constant ) - : &gt; ( QUOTE ~ ( ) m ( a variable of type &lt; s , b &gt; for any b ) == &gt; ( \ [ IUOTE~ ( ) `` W `` &gt; ( LIST ( QUOTE QUOTE , S ) ( i-\ [ i ) `` ~ , - &gt; EVAL o ( The sentence ( l ) in ( I-7 ) is translated in ninety == &gt; ( L , ~BDA ( Q ) ( ( g~ ) ( INT* 90 ) ) be == &gt; ( L,1NBDA ( P ) ( LA , ~BDA ix ) ( ( P* ) ( INT~ ( LA~BDA ( y ) ( EOU~L ( X* ) ( YD ) ) ) ) ) ) ) the temperature == &gt; ( LAHBDA ( P ) ( FOR SO , 'IE ENTITY-COYCEPTS ( LAY , BDA ( Y ) ( FOR ALL E , ~IT ITY-CONCEPTS ( LA , 'iBDA ( X ) ( At~D ( IFF ( TEHP X ) ( EQUAL X Y ) ) ( ( P~ ) Y ) ) ) ) ) ) ) the temperature is ninety == &gt; ( ( TIIE ( FUNCTIO~I TEHP ) ) ( INT~ ( BE ( INT~ ( FUNCTION NUIETT ) ) ) ) INT ~ ( L , ~HBDA ( G ) ( LAHBDA ( * ) G ) ) ( i-12 ) Here we may assume there is a variabIe named * to the value of which are applied to produce the corresponding extensions .</sentence>
				<definiendum id="0">Q ) (</definiendum>
				<definiendum id="1">'IE ENTITY-COYCEPTS</definiendum>
				<definiendum id="2">~IT ITY-CONCEPTS ( LA , 'iBDA ( X ) ( At~D ( IFF ( TEHP X ) ( EQUAL X Y ) )</definiendum>
				<definiens id="0">( g~ ) ( INT* 90 ) ) be == &gt; ( L,1NBDA ( P ) ( LA , ~BDA ix ) ( ( P* ) ( INT~ ( LA~BDA ( y ) ( EOU~L ( X* ) ( YD ) ) ) ) ) ) ) the temperature == &gt;</definiens>
				<definiens id="1">INT~ ( BE ( INT~ ( FUNCTION NUIETT ) ) ) ) INT ~ ( L , ~HBDA ( G ) ( LAHBDA ( * ) G ) ) ( i-12</definiens>
			</definition>
			<definition id="1">
				<sentence>Lingulstic~ is a part of philosophy rathe : '' than psychology .</sentence>
				<definiendum id="0">Lingulstic~</definiendum>
				<definiens id="0">a part of philosophy rathe : '' than psychology</definiens>
			</definition>
</paper>

		<paper id="1034">
</paper>

		<paper id="1148">
			<definition id="0">
				<sentence>DIL stands for 'dictionary of interlingua ' and descibes tile semantics of a subworld .</sentence>
				<definiendum id="0">DIL</definiendum>
				<definiens id="0">'dictionary of interlingua ' and descibes tile semantics of a subworld</definiens>
			</definition>
			<definition id="1">
				<sentence>TIL stands for 'text of interlingua ' and is responsible for producing an interlingua text , which represents tile meaning of an input text in tile terms of trte interlingua .</sentence>
				<definiendum id="0">TIL</definiendum>
				<definiens id="0">'text of interlingua ' and is responsible for producing an interlingua text , which represents tile meaning of an input text in tile terms of trte interlingua</definiens>
			</definition>
			<definition id="2">
				<sentence>TRANS/ , AfOR explores the knowledge based apln'oach to machine translation .</sentence>
				<definiendum id="0">AfOR</definiendum>
				<definiens id="0">explores the knowledge based apln'oach to machine translation</definiens>
			</definition>
			<definition id="3">
				<sentence>The IL dictionary is a source of information for representing the meanings of SL texts .</sentence>
				<definiendum id="0">IL dictionary</definiendum>
			</definition>
			<definition id="4">
				<sentence>The three slots present here mean that every node in the tree has an id ; every node features some properties ( which exactly , will be shown in lower-level nodes ) ; and every node represents a concept that belongs to one or more subworlds .</sentence>
				<definiendum id="0">every node</definiendum>
				<definiens id="0">a concept that belongs to one or more subworlds</definiens>
			</definition>
			<definition id="5">
				<sentence>size-set : : = nil I infinitesimal \ [ ... I huge color-set : : = nil t black \ ] ... \ [ white shape-set : : : nil \ ] flat I square \ ] spherical ... material-set : : = nil I ( gold ( specific-gravity 81 ) ( unit-value 228 ) ) 1 ... subworld-set : : = nil I computer-world \ [ business-world \ [ everyday world boolean-set : : = nil I yes \ ] no texture-set : : = nil I smooth \ ] ... \ [ rough properties : : = ( 'properties ' donne ' ( 'size ' size set ) ( 'color ' color-set ) ( 'shape ' shape-set ) ( 'texture ' texture-set ) ( 'belongs-to ' creature \ [ organization ) ( 'part-of ' object I event ) ( 'consists-of ' object \ [ event ) ( 'power ' real ) ( 'speed ' real ) ( 'mass ' real ) ( 'edibility ' boolean-set ) ( 'made-of ' material-set ) ... ) A path of concept representations fi'om the root to a leaf node is presented below .</sentence>
				<definiendum id="0">color-set )</definiendum>
				<definiendum id="1">shape-set )</definiendum>
				<definiendum id="2">texture-set )</definiendum>
				<definiendum id="3">boolean-set )</definiendum>
				<definiens id="0">'consists-of ' object \ [ event ) ( 'power ' real ) ( 'speed ' real ) ( 'mass ' real ) ( 'edibility '</definiens>
			</definition>
			<definition id="6">
				<sentence>An IL sentence consists of a main clause and a number of subordinate clauses , possibly interconnected through discourse markers , with the speech act and focus information added .</sentence>
				<definiendum id="0">IL sentence</definiendum>
				<definiens id="0">consists of a main clause and a number of subordinate clauses , possibly interconnected through discourse markers , with the speech act and focus information added</definiens>
			</definition>
			<definition id="7">
				<sentence>This underscores the difference in the semantics of similarly named slots in DIL and TIE text : : ~ nil \ ] sentence I ( discourse-structure-type text text + ) The above means that an IL text is either an empty string , a single sentence , or a number of sentences interconnected through discourse structure markers .</sentence>
				<definiendum id="0">empty string</definiendum>
				<definiens id="0">the difference in the semantics of similarly named slots in DIL and TIE text : : ~ nil \ ] sentence I ( discourse-structure-type text text +</definiens>
			</definition>
			<definition id="8">
				<sentence>The subworld slot is a marker that shows that the sentence belongs to a 'semantic field ' related to computers .</sentence>
				<definiendum id="0">subworld slot</definiendum>
				<definiens id="0">a marker that shows that the sentence belongs to a 'semantic field ' related to computers</definiens>
			</definition>
			<definition id="9">
				<sentence>space : : = nil I absolute-space I relative-space absolute-space : : = ( 'space ( 'quantifier ' quantifier2 ) ( 'coordinatel ' real ) ( 'coordinate2 ' real ) ( 'coordiuateY real ) ) relative-space : : = ( 'space ' ( spatial-operatm '' object ) ( 'quantifier ' quantifier2 ) ) spatial-operator : : = left-of I equal I between I in I above \ ] near I nolle AS in the case of'time , relative ( topological ) space specifications will predominate in texts .</sentence>
				<definiendum id="0">relative</definiendum>
				<definiens id="0">'coordinatel ' real ) ( 'coordinate2 ' real ) ( 'coordiuateY real )</definiens>
			</definition>
			<definition id="10">
				<sentence>quantifierl : := nil\ ] all\ [ any I most I many t some \ ] few \ [ 1 I 2 \ [ ... quantifier2 : : = nil I hardly I half I almost I completely modality : : = ( 'modality ' modality-set ) modality-set : : = real I desirable \ ] undesirable I conditional I possible I impossible I necessary \ ] nil focus : : = ( 'given ' ( 'object ' obj ) l ( 'event ' event ) I ( 'clause ' clause ) I ( 'quantifier ' event-quantifier I quantifier ) ) 631 ( ' new ' ( 'object ' obj ) I ( 'event ' even0 \ [ ( 'clause ' clause ) \ [ ( 'quantifier ' event-quantifier I quantifier ) ) The thematic information , together with the discourse structure and speech act information , explicitly represents the rhetorical force of SL texts .</sentence>
				<definiendum id="0">obj ) I</definiendum>
				<definiens id="0">'quantifier ' event-quantifier I quantifier ) ) The thematic information , together with the discourse structure and speech act information</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>Unification is the key operation for building these structures .</sentence>
				<definiendum id="0">Unification</definiendum>
				<definiens id="0">the key operation for building these structures</definiens>
			</definition>
			<definition id="1">
				<sentence>D-PATR consists of four basic parts : • A unification package • Interpreter for rules and lexical items • Input output routines for directed graphs • An Earley style chart parser .</sentence>
				<definiendum id="0">D-PATR</definiendum>
				<definiens id="0">consists of four basic parts : • A unification package • Interpreter for rules and lexical items • Input output routines for directed graphs • An Earley style chart parser</definiens>
			</definition>
			<definition id="2">
				<sentence>A template is an abbreviation fora listofspecifications .</sentence>
				<definiendum id="0">template</definiendum>
				<definiens id="0">an abbreviation fora listofspecifications</definiens>
			</definition>
			<definition id="3">
				<sentence>A lexical rule is a special kind of template with two attributes : m and out .</sentence>
				<definiendum id="0">lexical rule</definiendum>
				<definiens id="0">a special kind of template with two attributes : m and out</definiens>
			</definition>
			<definition id="4">
				<sentence>D PATR uses an active chart parser that proceeds in a top-down , breadth-first manner .</sentence>
				<definiendum id="0">D PATR</definiendum>
				<definiens id="0">uses an active chart parser that proceeds in a top-down , breadth-first manner</definiens>
			</definition>
			<definition id="5">
				<sentence>79 Acknowledgments I ) -PATR is a close relative of Z-PATR , the first I'ATR implementation , whose main architect is Stuart Shieber .</sentence>
				<definiendum id="0">-PATR</definiendum>
				<definiens id="0">a close relative of Z-PATR , the first I'ATR implementation , whose main architect is Stuart Shieber</definiens>
			</definition>
			<definition id="6">
				<sentence>Kaplan , R. and J. Bresnan , `` I , exical-functional grammar : A Formal System for Grammatical Representation , '' The Mental Representation of Grammatical Relations , J. Bresnan , ed. , MIT Press , Cambdridge , Massachusetts , 1983 .</sentence>
				<definiendum id="0">exical-functional grammar</definiendum>
				<definiens id="0">A Formal System for Grammatical Representation , '' The Mental Representation of Grammatical Relations</definiens>
			</definition>
			<definition id="7">
				<sentence>Karttunen , L. D-PATR : A Development Environment for Unification-Based Grammars , CSLI Report , Center for the Study of Language and Information , Stanford , California ( forthcoming in 1986 ) .</sentence>
				<definiendum id="0">Karttunen , L. D-PATR</definiendum>
				<definiens id="0">A Development Environment for Unification-Based Grammars</definiens>
			</definition>
</paper>

		<paper id="1060">
			<definition id="0">
				<sentence>But the clustering process allows the system to cover more relations than appeared in the text data .</sentence>
				<definiendum id="0">clustering process</definiendum>
				<definiens id="0">allows the system to cover more relations than appeared in the text data</definiens>
			</definition>
</paper>

		<paper id="1083">
			<definition id="0">
				<sentence>A phase is an interval ( span or moment ) p on the time axis , which a truth value ( denoted by q ( p ) ) is assigned to : q ( p ) = T : p is an affirmative ( main- ) phase .</sentence>
				<definiendum id="0">phase</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">an interval ( span or moment ) p on the time axis , which a truth value</definiens>
			</definition>
			<definition id="1">
				<sentence>Is R = `` Mary believes in John 's promise of marriage '' and &lt; R &gt; = P , so 351 ( 14 ) alt ( PER ( alt ( &lt; tuesday &gt; OCC ( &lt; day &gt; , P ) ) , P ) ) = U ° is the corresponding expression for ( 12 ) .</sentence>
				<definiendum id="0">Mary</definiendum>
			</definition>
</paper>

		<paper id="1149">
			<definition id="0">
				<sentence>Functional grammar formalisms , such as lexical functional grammar ( LFG ) and functional unification grammar ( UG ) , on the other hand , can represent general syntactic knowledge , but are severely limited in their ability to represent general semantic information .</sentence>
				<definiendum id="0">UG</definiendum>
				<definiens id="0">syntactic knowledge , but are severely limited in their ability to represent general semantic information</definiens>
			</definition>
			<definition id="1">
				<sentence>Kay , M. , `` Functional Unification Grammar : A Formalism for Machine Translation , '' lOth International Conference on Computational Linguistics , Stanford , July 1984 , pp .</sentence>
				<definiendum id="0">Functional Unification Grammar</definiendum>
			</definition>
</paper>

		<paper id="1076">
			<definition id="0">
				<sentence>Our computational approach consists of two parts° First , build an explicit computational model , then sh ( m the practical applicabiIity and theoretical validity of the model° The most significant advantage of using a formal descrip- .</sentence>
				<definiendum id="0">computational approach</definiendum>
				<definiens id="0">consists of two parts° First , build an explicit computational model</definiens>
			</definition>
			<definition id="1">
				<sentence>If ' L is a regular language and h is a hom~rJorphia~l , then the range of tile inverse homomorphism ff~ ( L ) is also regular language .</sentence>
				<definiendum id="0">h</definiendum>
				<definiens id="0">a regular language</definiens>
			</definition>
			<definition id="2">
				<sentence>Here we suppose { I &lt; I , k2 , ..kn } eDk , { jl , j2 , ..jm } eDj : ( I ) one-to-one ( ki , ji ) e DkxDj. ( 2 ) one-to-many ( ki. lJn.Ji2 , ... Ji , ( il\ ] ) e DkX2 '' i ( 3 ) many-to-nlany ( Ikihki2 , -..ki , ( i ) l , lJil , Ji2. ' '' Ji , , , ( i ) } ) e 21 ) kx2 l ) j where , A xB is the Cartesian product of the two sets A and B~ and 2 A is the a power set of a set A. Obviously , one-to-one correspondence is isomorphic. Naturally , our attention will be focused on the oneto-many and many-to-many relations. Interpretation of these relations depends on various factors : allomorph , synonym and homonym. Thus , as for the interpretation which is dependent on synonymy or polysemy , we charac-terize the interpretation by specifying the canonical form , or the semantic feature instantiation , respectively. We examine the syntactic structure of the two languages. Frcn~ the correspondence in a segTaented word and word order , it is seen intuitively that they are strongly equivalent. And there is a sufficient linguistic evidence for it based on the study of experimental comparative linguistics\ [ 2\ ] . ~ phrase structure preserves each lexical semantic feature of a constituent structure , and a parse tree describes the construction of syntactic representation of a sentence. Horeover~ a partial tree in the whole parse tree plays a role of adjusting semantic and syntactic interpretation. Let us compare the examples of two parse tree constructions ( Fig I ) : VP VP ./ \ , / \ NP VP &lt; I &gt; PP VP /\ /\ / \ / k VP I ' : V AUX VP P V AUX I I l I I I I { Fig 1 : Syntactic trees of `` ( I ) thought ( somebody ) went ( to somewhere ) ' It is obvious that parse trees coincide with each other in one-to-one fashion , but syntactic categories do not .</sentence>
				<definiendum id="0">xB</definiendum>
				<definiens id="0">the interpretation by specifying the canonical form , or the semantic feature instantiation</definiens>
			</definition>
			<definition id="3">
				<sentence>Input : a 5-tuple phrase structure grammar G : ( N , Tk , Tj , P , S ) .</sentence>
				<definiendum id="0">Input</definiendum>
			</definition>
			<definition id="4">
				<sentence>s , Tk , Tj , Tk ' ancl T o ' are terminals , sem~ is semantic features , P and P ' are production rules , ~nd S and S ' are the start symbols° The J-K granmmr is designed analogously .</sentence>
				<definiendum id="0">sem~</definiendum>
				<definiens id="0">semantic features</definiens>
			</definition>
			<definition id="5">
				<sentence>We can define the K-J ( J-K ) syster , ; as a 3-tuple grammar G : ( wj , k ( or j ) , wk ) , wherewk and w i are Korean words and Japanese words , respectively , and k ( j ) : Wi-~Wk ( Wk -- ~Wj ) is a homomorphism .</sentence>
				<definiendum id="0">K-J</definiendum>
				<definiens id="0">a 3-tuple grammar G : ( wj , k ( or j ) , wk ) , wherewk and w i are Korean words and Japanese words</definiens>
			</definition>
			<definition id="6">
				<sentence>As mentioned above , the K-J ( J-K ) systel ; L constitutes a simple device for interpretation .</sentence>
				<definiendum id="0">K-J ( J-K</definiendum>
				<definiendum id="1">L</definiendum>
				<definiens id="0">constitutes a simple device for interpretation</definiens>
			</definition>
</paper>

		<paper id="1080">
			<definition id="0">
				<sentence>Collative Semantics is a new domain-independent sem , ~ntics for NI , P. This paper foeusses on CS , describing tile main issues it addresses ( lexical ambiguity , mctonymy , semantic relations , introduction of new information ) and general details of its knowledge representation , knowledge structures , techniques for matching together knowledge structures , and the way it records the results of matching in semantic vectors .</sentence>
				<definiendum id="0">Collative Semantics</definiendum>
				<definiens id="0">lexical ambiguity , mctonymy , semantic relations , introduction of new information ) and general details of its knowledge representation , knowledge structures</definiens>
			</definition>
			<definition id="1">
				<sentence>CS has l ) een implemented in a natural language program eaiicd recta5 which has been described in detail clsewherc ( Fass , 1986 ) .</sentence>
				<definiendum id="0">CS</definiendum>
				<definiens id="0">has l ) een implemented in a natural language program eaiicd recta5 which has been described in detail clsewherc</definiens>
			</definition>
			<definition id="2">
				<sentence>of Collative Semantics is a hierarchically structured semantic network with wordsenses as the nodes .</sentence>
				<definiendum id="0">Collative Semantics</definiendum>
			</definition>
			<definition id="3">
				<sentence>Computing a graph relation is a path search algorithm which operates over CS 's hierarchically structured semantic network .</sentence>
				<definiendum id="0">graph relation</definiendum>
				<definiens id="0">a path search algorithm which operates over CS 's hierarchically structured semantic network</definiens>
			</definition>
			<definition id="4">
				<sentence>Collativc Semantics has at least ~he disambiguation power of Preference Semantics because computing a graph relation produces paths describing set inclusion and exclusion over directed graphs with practically the same hierarchical organisation , but whereas the nodes in Wilks ' digraph are a restricted set of semantic primitives , the nodes in CS 's digraph are an unrestricted set of word-senses .</sentence>
				<definiendum id="0">digraph</definiendum>
				<definiens id="0">at least ~he disambiguation power of Preference Semantics because computing a graph relation produces paths describing set inclusion and exclusion over directed graphs with practically the same hierarchical organisation , but whereas the nodes in Wilks '</definiens>
			</definition>
			<definition id="5">
				<sentence>A multiple comparison algorit\ ] am is a technique used to match together the elements from two sets ( often within two KSs ) by isolating a pair of elements from the two sets and matching those elements together in some way .</sentence>
				<definiendum id="0">am</definiendum>
				<definiens id="0">a technique used to match together the elements from two sets</definiens>
			</definition>
			<definition id="6">
				<sentence>Fass , D.C. ( 1986 ) `` Collative Semantics : A Description of the Meta5 Program . ''</sentence>
				<definiendum id="0">Collative Semantics</definiendum>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>The BSO Company is a systems house in Utrecht , The Netherlands .</sentence>
				<definiendum id="0">BSO Company</definiendum>
				<definiens id="0">a systems house in Utrecht</definiens>
			</definition>
			<definition id="1">
				<sentence>The BYU-HRC is a center which promotes research in the College of Humanities at Brigham Young University ( BYU ) , in particular providing support for research involving language and computers .</sentence>
				<definiendum id="0">BYU-HRC</definiendum>
				<definiens id="0">a center which promotes research in the College of Humanities at Brigham Young University ( BYU ) , in particular providing support for research involving language and computers</definiens>
			</definition>
			<definition id="2">
				<sentence>BSO supplied the source documents , which were mostly public reports on agriculture , social conditions , etc. , published by the European Economic Community ( EEC ) or the United Nations ( UN ) .</sentence>
				<definiendum id="0">BSO</definiendum>
			</definition>
			<definition id="3">
				<sentence>BSO is now building an English to intermediate language ( IL ) lexicon and an IL to French lexicon .</sentence>
				<definiendum id="0">BSO</definiendum>
				<definiens id="0">now building an English to intermediate language ( IL ) lexicon and an IL to French lexicon</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>The heart of any knowledge-based system ( KB $ ) man or machine is his/ her/Its knowledge base ( KB ) , containing different types af knowledge ( cp .</sentence>
				<definiendum id="0">KB</definiendum>
				<definiens id="0">his/ her/Its knowledge base</definiens>
			</definition>
			<definition id="1">
				<sentence>A more adequate analysis of ( I ) should lead to a representation , which represents the plural explicitly ( and not only implicitly via `` ALL '' ) : ( 1 '' ) card~2-r.2-ALLx : child_of ( r.l , x ) human -J using a cardlnality attr/Dute to the RefO r.2 which represents the essential property that r.2 's real-world counterpart is assumed to consist of more than one human being ; the sertal attribute `` human '' , which will be , used here only , exemplifies another type of attribute , namely ~rtalattribut~ By this attribute mechanism I represent the meaning of numerals , e.g. `` dahn 's two cars '' leads to card= 2-r.9 ~ ALL x : cor ( x ) &amp; ewn ( r.l , x ) In text generation the communicative goals determine which designation ( s ) and R-ATTs are used to form the content of the message .</sentence>
				<definiendum id="0">RefO r.2 which</definiendum>
				<definiendum id="1">ewn</definiendum>
				<definiens id="0">represents the essential property that r.2 's real-world counterpart is assumed to consist of more than one human being</definiens>
				<definiens id="1">the communicative goals determine which designation ( s ) and R-ATTs are used to form the content of the message</definiens>
			</definition>
			<definition id="2">
				<sentence>D-COrd is the set of singletons over the set N of natural numbers ( including zero ) ; UD-CARD consists of the not-singleton elements of the power-sat of N with the partial ordering induced by the set inclusion .</sentence>
				<definiendum id="0">D-COrd</definiendum>
				<definiens id="0">the set of singletons over the set N of natural numbers ( including zero ) ; UD-CARD consists of the not-singleton elements of the power-sat of N with the partial ordering induced by the set inclusion</definiens>
			</definition>
			<definition id="3">
				<sentence>In e ( half ) formal way , a structure of determination is built up from e Scottien approximation \ ] etttco ( AL ) by the following method : by the direct neighbors of the ( now deleted ) NIL end the undardatermined part of the lattice ( UD-AL ) which is given by those elements of AL which ere neither NIL nor in LaD .</sentence>
				<definiendum id="0">AL</definiendum>
				<definiens id="0">end the undardatermined part of the lattice ( UD-AL ) which is given by those elements of AL which ere neither NIL nor in LaD</definiens>
			</definition>
</paper>

		<paper id="1043">
			<definition id="0">
				<sentence>GENERALIZATION : -expan ( cl , c2 ) is true if c2 serves as a generalization of cl , such as in a definition .</sentence>
				<definiendum id="0">GENERALIZATION</definiendum>
				<definiens id="0">true if c2 serves as a generalization of cl</definiens>
			</definition>
			<definition id="1">
				<sentence>CONTRASTIVE : -simil ( cl , c2 ) is true if c2 is either dissimilar or opposite from cl .</sentence>
				<definiendum id="0">CONTRASTIVE</definiendum>
				<definiens id="0">true if c2 is either dissimilar or opposite from cl</definiens>
			</definition>
			<definition id="2">
				<sentence>DIGRESSION : none ( cl , c2 ) is true if none of the other relations listed above exist between cl and c2 .</sentence>
				<definiendum id="0">DIGRESSION</definiendum>
				<definiens id="0">true if none of the other relations listed above exist between cl and c2</definiens>
			</definition>
</paper>

	</volume>
