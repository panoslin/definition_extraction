<?xml version="1.0" encoding="UTF-8"?>
	<volume id="W02">

		<paper id="2013">
			<definition id="0">
				<sentence>The problem we are trying to solve is this : we want to find a sequence of phrase tags t given a sequence of words w. We find the optimal ta0 as ta0a2a1 arg maxt Pa3 ta4 wa5 a1 argmaxt G a3 w a6 ta5 W a3 wa5 a6 where the conditional model P is expressed in terms of a joint generative model G of tags and words , and a language model W. Since t and w have the same length n , we regard the training data as a sequence of pairs , rather than a pair of sequences ( the two representations are isomorphic via a zip operation familiar to Python or Haskell programmers ) , and decompose the generative model G using a first order Markov assumption : Ga3 wa6 ta5 a1 Sa3 w1a6 t1a5 n∏ ia7 2 G1a3 wia6 ti a4 wi a8 1 a6 ti a8 1 a5a10a9 Doing the same for W and using a designated start event a3 w0a6 t0a5 instead of the start distribution S we obtain : Pa3 ta4 wa5 a1 n∏ ia7 1 G1a3 wia6 ti a4 wi a8 1 a6 ti a8 1 a5 W1a3 wi a4 wi a8 1a5 a9 We further decompose the conditional distribution G1 as follows : G1a3 wia6 ti a4 wi a8 1a6 tia8 1a5 a1 T a3 t i a4wia6 wia8 1a6 tia8 1a5 U a3 w i a4wia8 1a6 tia8 1a5a10a9 In addition to the first order assumption above , the only other assumption we make is that Ua3 wi a4wi a8 1 a6 ti a8 1 a5 a1 Ua3 w i a4 wia8 1a5 , which allows us toconclude that U a1 W 1 , and so our conditional se-quence model simplifies to Pa3 ta4 wa5 a1 n∏ ia7 1 Ta3 ti a4wia6 wi a8 1 a6 ti a8 1 a5a10a9 This is starting to look familiar : T is a conditional distribution over a finite set of phrase tags , so in principle any probabilistic classifier that uses ( features derived from ) the variables that T is conditioned on could be substituted in its place .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">a conditional distribution over a finite set of phrase tags , so in principle any probabilistic classifier that uses</definiens>
			</definition>
</paper>

		<paper id="2022">
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>Bow : A toolkit for statistical language modeling , text retrieval , classification , and clustering .</sentence>
				<definiendum id="0">Bow</definiendum>
				<definiens id="0">A toolkit for statistical language modeling</definiens>
			</definition>
			<definition id="2">
				<sentence>11 Gerard Salton , Christopher Buckley , Term-weighting approaches in automatic text retrieval , Information Processing and Management : an International Journal , v.24 n.5 , p.513-523 , 1988 12 Gerard Salton , Automatic text processing : the transformation , analysis , and retrieval of information by computer , Addison-Wesley Longman Publishing Co. , Inc. , Boston , MA , 1989 13 Frank Smadja , Kathleen R. McKeown , Vasileios Hatzivassiloglou , Translating collocations for bilingual lexicons : a statistical approach , Computational Linguistics , v.22 n.1 , p.1-38 , March 1996 14 Alan F. Smeaton , Ian Quigley , Experiments on using semantic distances between words in image caption retrieval , Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval , p.174-180 , August 18-22 , 1996 , Zurich , Switzerland 15 A. F. Smeaton .</sentence>
				<definiendum id="0">Management</definiendum>
				<definiens id="0">a statistical approach</definiens>
				<definiens id="1">the 19th annual international ACM SIGIR conference on Research and development in information retrieval</definiens>
			</definition>
			<definition id="3">
				<sentence>17 Tomek Strzalkowski , Natural Language Information Retrieval , Kluwer Academic Publishers , Norwell , MA , 1999 18 Michael Sussna , Word sense disambiguation for free-text indexing using a massive semantic network , Proceedings of the second international conference on Information and knowledge management , p.67-74 , November 01-05 , 1993 , Washington , D.C. , United States 19 C. J. Van Rijsbergen , Information Retrieval , Butterworth-Heinemann , Newton , MA , 1979 20 Ellen M. Voorhees , Using WordNet to disambiguate word senses for text retrieval , Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval , p.171-180 , June 27-July 01 , 1993 , Pittsburgh , Pennsylvania , United States</sentence>
				<definiendum id="0">Butterworth-Heinemann</definiendum>
				<definiens id="0">the 16th annual international ACM SIGIR conference on Research and development in information retrieval</definiens>
			</definition>
</paper>

		<paper id="1301">
			<definition id="0">
				<sentence>Spontaneous speech is an extremely powerful input/output modality for interacting with computer systems , a modality which , furthermore , is available and natural to the large majority of users without any need for training in using it for interactive purposes .</sentence>
				<definiendum id="0">Spontaneous speech</definiendum>
				<definiens id="0">available and natural to the large majority of users without any need for training in using it for interactive purposes</definiens>
			</definition>
			<definition id="1">
				<sentence>Multimodal systems are systems which offer the user combinations of input/output modalities for ( or ways of ) exchanging information with computer systems .</sentence>
				<definiendum id="0">Multimodal systems</definiendum>
				<definiens id="0">systems which offer the user combinations of input/output modalities for ( or ways of ) exchanging information with computer systems</definiens>
			</definition>
			<definition id="2">
				<sentence>semantic items and their allowed combinations ) task-oriented spoken dialogue systems 2005 Multiple-purpose personal assistants ( spoken dialogue , animated characters ) 2006 Task-oriented spoken translation systems for the web 2006 Useful speech summarisation systems in top languages 2006 Useful meeting summarisation systems 2008 Usable medium-vocabulary speech/text translation systems for all non-critical situations 2010 Medium-size vocabulary conversational systems 2010 Tools , platforms , infrastructure Standard tool for cross-level , cross-modality coding of natural interactivity data 2002 Infrastructure for rapid porting of spoken dialogue systems to new domains 2003 Platform for generating intelligent multimedia presentation systems with spoken interaction 2005 Science-based general portability of spoken dialogue systems across domains and tasks 2006 Other problems which were strongly felt when producing the list above include : ( i ) the fact that there is plenty of continuity in technology development .</sentence>
				<definiendum id="0">Infrastructure</definiendum>
				<definiens id="0">their allowed combinations ) task-oriented spoken dialogue systems 2005 Multiple-purpose personal assistants ( spoken dialogue , animated characters ) 2006 Task-oriented spoken translation systems for the web</definiens>
				<definiens id="1">speech/text translation systems for all non-critical situations 2010 Medium-size vocabulary conversational systems 2010 Tools , platforms , infrastructure Standard tool for cross-level , cross-modality coding of natural interactivity data 2002</definiens>
			</definition>
			<definition id="3">
				<sentence>Speech translation Despite the embattled 40-year history of language ( text ) translation systems , speech translation is now being researched across the world because of the realisation that far-lessthan-perfect paragraph-by-paragraph translation could yield useful applications in the shorter term .</sentence>
				<definiendum id="0">Speech translation Despite</definiendum>
				<definiens id="0">the embattled 40-year history of language ( text ) translation systems</definiens>
			</definition>
			<definition id="4">
				<sentence>Obviously , however , spoken conversation systems hold an enormous application potential because they represent the ultimate generalisation of the qualities which everybody seem to appreciate in task-oriented mixed initiative spoken language dialogue systems .</sentence>
				<definiendum id="0">spoken conversation systems</definiendum>
				<definiens id="0">the ultimate generalisation of the qualities which everybody seem to appreciate in task-oriented mixed initiative spoken language dialogue systems</definiens>
			</definition>
			<definition id="5">
				<sentence>Recently , the ISLE ( International Standards for Language Engineering ) Working Group on Natural Interactivity and Multimodality ( http : //www.isle.nis.sdu.dk ) has launched cross-Atlantic collaboration in the field of resources for natural interactivity and multimodality .</sentence>
				<definiendum id="0">ISLE</definiendum>
				<definiendum id="1">Multimodality ( http</definiendum>
				<definiens id="0">cross-Atlantic collaboration in the field of resources for natural interactivity and multimodality</definiens>
			</definition>
			<definition id="6">
				<sentence>Finally , the current covering title for FP6 IST research is “ambient intelligence” which is one of the terms of fashion quoted in the present paper .</sentence>
				<definiendum id="0">“ambient intelligence”</definiendum>
				<definiens id="0">one of the terms of fashion quoted in the present paper</definiens>
			</definition>
			<definition id="7">
				<sentence>DARPA Communicator : http : //fofoca.mitre.org/ DISC www.disc2.dk EAGLES : http : //www.ilc.pi.cnr.it/EAGLES96/home.html ELRA : http : //www.icp.inpg.fr/ELRA/home.html ELSNET http : //www.elsnet.org/ i3 : http : //www.i3net.org/ ISLE : http : //www.ilc.pi.cnr.it/EAGLES96/isle/ISLE_Home_Page.htm ISLE Working Group on Natural Interactivity and Multimodality : http : //www.isle.nis.sdu.dk HLT portal : http : //www.HLTCentral.org LDC http : //www.ldc.upenn.edu/ SmartKom : http : //smartkom.dfki.de/start.html Verbmobil : http : //verbmobil.dfki.de/</sentence>
				<definiendum id="0">http</definiendum>
				<definiens id="0">//fofoca.mitre.org/ DISC www.disc2.dk EAGLES : http : //www.ilc.pi.cnr.it/EAGLES96/home.html ELRA : http : //www.icp.inpg.fr/ELRA/home.html ELSNET http : //www.elsnet.org/ i3 : http : //www.i3net.org/ ISLE : http : //www.ilc.pi.cnr.it/EAGLES96/isle/ISLE_Home_Page.htm ISLE Working Group on Natural Interactivity and Multimodality : http : //www.isle.nis.sdu.dk HLT portal : http : //www.HLTCentral.org LDC http : //www.ldc.upenn.edu/ SmartKom :</definiens>
			</definition>
</paper>

		<paper id="2002">
</paper>

		<paper id="1819">
			<definition id="0">
				<sentence>Linguistic research has suggested that Chinese utterance is also structured in a prosodic hierarchy , in which there are mainly three levels of prosodic units : prosodic word , prosodic phrase and intonation phrase ( Li and Lin , 2000 ) .</sentence>
				<definiendum id="0">intonation phrase</definiendum>
				<definiens id="0">levels of prosodic units : prosodic word , prosodic phrase and</definiens>
			</definition>
			<definition id="1">
				<sentence>1 Acc is the overall accuracy of all the labels .</sentence>
				<definiendum id="0">Acc</definiendum>
			</definition>
			<definition id="2">
				<sentence>POS , which denotes part-of-speech of words , is a basic syntactic feature much easier to obtain with automatic POS taggers .</sentence>
				<definiendum id="0">POS</definiendum>
			</definition>
			<definition id="3">
				<sentence>The length of syntactic word ( WLEN ) , the length of the sentence in character ( SLENC ) and word ( SLENW ) are considered as length features .</sentence>
				<definiendum id="0">WLEN</definiendum>
				<definiens id="0">the length of the sentence in character ( SLENC</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , POS_0 denotes part-of-speech of the word just before the word boundary , POS_-1 denotes that of the second word previous to the boundary and POS_1 denotes that of the word just after the boundary .</sentence>
				<definiendum id="0">POS_0</definiendum>
				<definiendum id="1">POS_1</definiendum>
				<definiens id="0">part-of-speech of the word just before the word boundary</definiens>
			</definition>
			<definition id="5">
				<sentence>BTYPE_0 is the label of current boundary and also the target to be predicted .</sentence>
				<definiendum id="0">BTYPE_0</definiendum>
			</definition>
			<definition id="6">
				<sentence>Suppose the window size is L+R , which means the features of L words left to the boundary and R words right to it are used .</sentence>
				<definiendum id="0">L+R</definiendum>
				<definiens id="0">means the features of L words left to the boundary and R words right to it are used</definiens>
			</definition>
			<definition id="7">
				<sentence>LSET is an enlarged version of BSET , which includes the most frequent 100 words as independent tags .</sentence>
				<definiendum id="0">LSET</definiendum>
			</definition>
			<definition id="8">
				<sentence>Table 4 : Rule templates for TBL The left part of a rule template is a list of features , and the right is the target , BTYPE_0 .</sentence>
				<definiendum id="0">Rule</definiendum>
				<definiens id="0">templates for TBL The left part of a rule template is a list of features</definiens>
			</definition>
			<definition id="9">
				<sentence>TBL achieves comparable accuracy with C4.5 induction , which demonstrates that the design of transformation rule templates is successful .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">achieves comparable accuracy with C4.5 induction , which demonstrates that the design of transformation rule templates is successful</definiens>
			</definition>
			<definition id="10">
				<sentence>Prosodic phrase is a larger prosodic unit less related to word level features , thus it can not be predicted accurately using these features .</sentence>
				<definiendum id="0">Prosodic phrase</definiendum>
				<definiens id="0">a larger prosodic unit less related to word level features</definiens>
			</definition>
</paper>

		<paper id="0218">
			<definition id="0">
				<sentence>Dialogue Macrogame Theory ( DMT ) is a successor to a theory sometimes called Dialogue Game Theory , developed in the 1970s and 1980s at USCInformation Sciences Institute ( ISI ) .</sentence>
				<definiendum id="0">DMT )</definiendum>
			</definition>
			<definition id="1">
				<sentence>DMT is a step toward accounting for the coherence of entire dialogues .</sentence>
				<definiendum id="0">DMT</definiendum>
				<definiens id="0">a step toward accounting for the coherence of entire dialogues</definiens>
			</definition>
			<definition id="2">
				<sentence>DMT is an exercised framework , meaning that it has been applied to dialogues from a diversity of situations .</sentence>
				<definiendum id="0">DMT</definiendum>
				<definiens id="0">an exercised framework , meaning that it has been applied to dialogues from a diversity of situations</definiens>
			</definition>
			<definition id="3">
				<sentence>( Hopper attributes this orientation to interpreters of language , but not producers ( Hopper 1983 ) . )</sentence>
				<definiendum id="0">Hopper</definiendum>
				<definiens id="0">attributes this orientation to interpreters of language , but not producers</definiens>
			</definition>
			<definition id="4">
				<sentence>A ( dialogue macro ) game is defined as a set of three goals : A dialogue macrogame is a convention , loosely comparable to a lexical item or a grammatical pattern .</sentence>
				<definiendum id="0">( dialogue macro ) game</definiendum>
				<definiendum id="1">dialogue macrogame</definiendum>
			</definition>
			<definition id="5">
				<sentence>In turn 5 , CC is offering information to CMP .</sentence>
				<definiendum id="0">CC</definiendum>
				<definiens id="0">offering information to CMP</definiens>
			</definition>
			<definition id="6">
				<sentence>Within this scope , in turn 13 , CMP bids the Clarification Seeking game .</sentence>
				<definiendum id="0">CMP</definiendum>
				<definiens id="0">bids the Clarification Seeking game</definiens>
			</definition>
			<definition id="7">
				<sentence>DMT attempts broad coverage ; as indicated above , substantial coverage beyond map following dialogue has been demonstrated at the exercise level .</sentence>
				<definiendum id="0">DMT</definiendum>
				<definiens id="0">attempts broad coverage ; as indicated above , substantial coverage beyond map following dialogue has been demonstrated at the exercise level</definiens>
			</definition>
			<definition id="8">
				<sentence>In contrast , MAP represents additional detail about how map following is done .</sentence>
				<definiendum id="0">MAP</definiendum>
				<definiens id="0">additional detail about how map following is done</definiens>
			</definition>
</paper>

		<paper id="0901">
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>An extension to this classical estimation method is to use distance-weighted counts instead of raw counts for the relative frequencies : a75 a53 a4a40a76 a90 a56 a1a101a100a99a102 a39a52a103a31a104 a53a55a90 a8a106a105a48a107a57a108 a47 a56 a100a99a102 a39a52a103a11a104 a53a55a90 a8a106a105 a107 a56 a1 a91 a86a110a109a64a49a11a111a5a112a114a113a109 a100 a53a55a90 a8 a34 a47 a56 a91 a86a50a49a11a111 a112 a100 a53a55a90 a8 a34 a56 ( 5 ) a75 a53a55a90 a76a4a57a56 a1 a100a99a102 a39a52a103a31a104 a53a55a90 a8a106a105a115a107a57a108 a47 a56 a91a116a81 a92 a49a12a83a85a84a87a86a117a88 a100a99a102 a39a52a103a31a104 a53a55a90 a95a118a8a106a105a115a107a57a108 a47 a56 ( 6 ) a105 a107 denotes the training contexts of word a45 and a105a115a107a57a108 a47 the subset of a105 a107 corresponding to sense a4 .</sentence>
				<definiendum id="0">a107</definiendum>
			</definition>
			<definition id="1">
				<sentence>When a90 is a syntactic headword , a100 a53a55a90 a8 a34 a56 is computed by raw count .</sentence>
				<definiendum id="0">a90</definiendum>
				<definiens id="0">a syntactic headword</definiens>
			</definition>
			<definition id="2">
				<sentence>When a90 is a context word , a100 a53a55a90 a8 a34 a56 is computed as a function of the position a119 of the target word a45 in a34 and the positions a120 a6a11a8a14a13a15a13a15a13a15a8 a120 a16 where a90 occurs in a34 : a100 a53a55a90 a8 a34 a56 a1 a91 a16a121a87a122 a6a48a123 a53a55a119 a8 a120 a121 a56 .</sentence>
				<definiendum id="0">a90</definiendum>
				<definiens id="0">a context word , a100 a53a55a90 a8 a34 a56 is computed as a function of the position a119 of the target word a45 in a34 and the positions a120 a6a11a8a14a13a15a13a15a13a15a8 a120 a16 where a90 occurs in a34</definiens>
			</definition>
			<definition id="3">
				<sentence>Experimental results indicate that it is more effective to level out the local positional differences given by a continuous weighting , by instead using weight-equivalent regions which can be described with a simple stepfunction a123 a53a132a120 a8a50a133a134a56 a1 a6 a6a106a127a136a135a114a137 a113a138a64a139a7a140a66a113 a141a143a142 , ( a144 is a constant3 ) .</sentence>
				<definiendum id="0">a144</definiendum>
			</definition>
			<definition id="4">
				<sentence>When a90 is a word , 2Golding and Schabes ( 1996 ) show that the most important words for CSSC are contained within a window of a160a147a161 .</sentence>
				<definiendum id="0">a90</definiendum>
				<definiens id="0">a word</definiens>
			</definition>
			<definition id="5">
				<sentence>When a90 is a syntactic headword , a75 a53a55a90 a76a34 a56 is chosen as the average value of two ratios expressing the usefulness of the headword type for the given target word and respectively for the POS-class of the target word ( adjective , noun , verb ) .</sentence>
				<definiendum id="0">a90</definiendum>
				<definiens id="0">a syntactic headword</definiens>
			</definition>
			<definition id="6">
				<sentence>Feature Type Value DMM Naïve Bayes ( position ) Lemma/POS a166a168a167a94a169a31a170a171a147a172 a166a168a167a15a171a173a170a169a9a172 a174 Syntactic Features SubjectTo move/V 0 0 3 Modifier other/J 0 0 8 Bigrams -1 Bigram other/J 0 0 2 +1 Bigram with/I 0.4444 0.0007 1 Contextual Features Context ( -17 ) pub/N 0.3677 0.0007 .3 Context ( -13 ) sit/V 0.5708 0.0028 .5 Context ( -9 ) table/N 0.7173 0.0008 .5 Context ( -4 ) move/V 0.2990 0.0007 1 Context ( -3 ) into/I Context ( -2 ) the/D Context ( -1 ) other/J Target bar/N 0.4296 [ 0.0530 ] 2 Context ( +1 ) with/I Context ( +2 ) my/P Context ( +3 ) pint/N 0.3333 0.0001 2 ... ... ... ... Posterior probability a166a168a167a94a169a14a170a175a50a172 : a176 a177a179a178 =.46 a180a182a181 a109a71a183 a184a186a185 =.29 Figure 3 : A WSD example that shows the influence of syntactic , collocational and long-distance context features , the probability estimates used by Naïve Bayes and MM and their associated weights ( a174 ) , and the posterior probabilities of the true sense as computed by the two models .</sentence>
				<definiendum id="0">Feature Type Value DMM Naïve Bayes ( position</definiendum>
				<definiens id="0">A WSD example that shows the influence of syntactic , collocational and long-distance context features , the probability estimates used by Naïve Bayes and MM and their associated weights</definiens>
			</definition>
			<definition id="7">
				<sentence>AdaBoost is an iterative boosting algorithm introduced by Freund and Schapire ( 1997 ) shown to be successful for several natural language classification tasks .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">an iterative boosting algorithm introduced by Freund and Schapire ( 1997 ) shown to be successful for several natural language classification tasks</definiens>
			</definition>
			<definition id="8">
				<sentence>AdaBoost successively builds classifiers based on a weak learner ( base learning algorithm ) by weighting differently the examples in the training space , and outputs the final classification by mixing the predictions of the iteratively built classifiers .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">builds classifiers based on a weak learner ( base learning algorithm ) by weighting differently the examples in the training space , and outputs the final classification by mixing the predictions of the iteratively built classifiers</definiens>
			</definition>
</paper>

		<paper id="0310">
			<definition id="0">
				<sentence>( Zeng and Cimino , 1998 ) MEDLINE is the National Library of Medicine ( NLM ) premier bibliographic database covering the fields of medicine , nursing , dentistry , veterinarian medicine , the health care system , and the preclinial sciences .</sentence>
				<definiendum id="0">MEDLINE</definiendum>
				<definiens id="0">the National Library of Medicine ( NLM ) premier bibliographic database covering the fields of medicine , nursing , dentistry , veterinarian medicine , the health care system</definiens>
			</definition>
			<definition id="1">
				<sentence>MEDLINE contains bibliographic citations and author abstracts from more than 4,600 biomedical journals published in the United States and 70 other countries .</sentence>
				<definiendum id="0">MEDLINE</definiendum>
				<definiens id="0">contains bibliographic citations and author abstracts from more than 4,600 biomedical journals published in the United States and 70 other countries</definiens>
			</definition>
			<definition id="2">
				<sentence>The MED uses a frame-based semantic network that includes a classification hierarchy to represent medical concepts and the relationship among them .</sentence>
				<definiendum id="0">MED</definiendum>
			</definition>
</paper>

		<paper id="1015">
</paper>

		<paper id="0302">
			<definition id="0">
				<sentence>PMC is a digital archive of full text peerreviewed biomedical articles launched in February 2000 by the National Center for Biotechnology Information ( NCBI ) and the U.S. National Library of Medicine ( NLM ) ( Roberts et al. , 2001 ) .</sentence>
				<definiendum id="0">PMC</definiendum>
			</definition>
			<definition id="1">
				<sentence>Non-biological terms were obtained by comparing word frequencies in MEDLINE versus the Wall Street Journal ( WSJ ) using the following expression , where p is the probability of occurrence : log ( p ( word occurs in MEDLINE ) / p ( word occurs in WSJ ) ) &lt; 1 Additional false positives are found by regular expressions including numbers followed by measurements ( 25 mg/ml ) and common drug suffixes ( -ole , -ane , -ate , -ide , -ine , -ite , -ol , -ose , cooh ) .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">the probability of occurrence : log ( p ( word occurs in MEDLINE ) / p ( word occurs in WSJ</definiens>
			</definition>
			<definition id="2">
				<sentence>The false negative filter recovers a single word name if it : 1 ) matches a list of 34,555 single word names and 7611 compound word names compiled from LocusLink ( Pruitt &amp; Maglott 2001 ) and the Gene Ontology Consortium ( 2000 ) ( Wain et al. , 2002 ) and contains a good context word before or after the name , or 2 ) contains a low frequency trigram and a good context word before or after the name .</sentence>
				<definiendum id="0">Gene Ontology Consortium</definiendum>
				<definiens id="0">Wain et al. , 2002 ) and contains a good context word before or after the name</definiens>
			</definition>
			<definition id="3">
				<sentence>Wain , H. M. , Lush , M. , Ducluzeau , F. , and Povey , S. ( 2002 ) Genew : the human gene nomenclature database .</sentence>
				<definiendum id="0">Genew</definiendum>
				<definiens id="0">the human gene nomenclature database</definiens>
			</definition>
			<definition id="4">
				<sentence>Yu , H. , Hripcsak , G. , and Friedman , C. ( 2002 ) Mapping abbreviations to full forms in biomedical articles .</sentence>
				<definiendum id="0">Mapping</definiendum>
				<definiens id="0">abbreviations to full forms in biomedical articles</definiens>
			</definition>
</paper>

		<paper id="1808">
			<definition id="0">
				<sentence>12 Kok-Wee Gan , Kim-Teng Lua , Martha Palmer , A statistically emergent approach for language processing : application to modeling context effects in ambiguous Chinese word boundary perception , Computational Linguistics , v.22 n.4 , p.531-553 , December 1996 13 Xianping Ge , Wanda Pratt , Padhraic Smyth , Discovering Chinese words from unsegmented text ( poster abstract ) , Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval , p.271-272 , August 15-19 , 1999 , Berkeley , California , United States 14 Gregory Grefenstette and P. Tapanainen .</sentence>
				<definiendum id="0">Martha Palmer</definiendum>
				<definiens id="0">words from unsegmented text ( poster abstract ) , Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval</definiens>
			</definition>
</paper>

		<paper id="1604">
			<definition id="0">
				<sentence>Abstraction permits structural neutralizations that facilitate learning of translation examples across languages with radically different surface structure characteristics , and allows MT development to proceed within a largely languageindependent NLP architecture .</sentence>
				<definiendum id="0">Abstraction</definiendum>
			</definition>
			<definition id="1">
				<sentence>In this presentation we describe the MSR-MT English-Japanese system , an example-based MT system that learns structured phrase-sized translation units .</sentence>
				<definiendum id="0">MSR-MT English-Japanese</definiendum>
				<definiens id="0">learns structured phrase-sized translation units</definiens>
			</definition>
			<definition id="2">
				<sentence>The MSR-MT English-Japanese system is a hybrid example-based machine translation system that employs handcrafted broadcoverage augmented phrase structure grammars for parsing , and statistical and heuristic techniques to capture translation knowlege and for transfer between languages .</sentence>
				<definiendum id="0">MSR-MT English-Japanese system</definiendum>
				<definiens id="0">a hybrid example-based machine translation system that employs handcrafted broadcoverage augmented phrase structure grammars for parsing , and statistical and heuristic techniques to capture translation knowlege and for transfer between languages</definiens>
			</definition>
			<definition id="3">
				<sentence>The Spanish-English version of MSR-MT has been described in Richardson et al. 2001a , Richardson et al 2001b , and the reader is referred to these papers for more information concerning algorithms employed during phrase alignment .</sentence>
				<definiendum id="0">MSR-MT</definiendum>
				<definiens id="0">information concerning algorithms employed during phrase alignment</definiens>
			</definition>
			<definition id="4">
				<sentence>1 MSR-MT employs a post-parsing layer of semantic representation called LOGICAL FORM ( LF ) to handle core components of the translation process , namely acquisition and storage of translation knowledge , transfer between languages , and generation of target output .</sentence>
				<definiendum id="0">MSR-MT</definiendum>
				<definiens id="0">employs a post-parsing layer of semantic representation called LOGICAL FORM ( LF ) to handle core components of the translation process , namely acquisition and storage of translation knowledge , transfer between languages , and generation of target output</definiens>
			</definition>
			<definition id="5">
				<sentence>The LF alignment algorithm first establishes tentative lexical correspondences between nodes in the source and target LFs on the basis of lexical matching over dictionary information and approximately 31,000 “word associations , ” that is , lexical mappings extracted from the training corpora using statistical techniques based on mutual information ( Moore 2001 ) .</sentence>
				<definiendum id="0">LF alignment algorithm</definiendum>
			</definition>
			<definition id="6">
				<sentence>The Mindnet is a general-purpose database of semantic information ( Richardson et al. 1998 ) that has been repurposed as the primary repository of translation information for MT applications .</sentence>
				<definiendum id="0">Mindnet</definiendum>
			</definition>
			<definition id="7">
				<sentence>The Honyaku is a trademark of the Toshiba Corporation .</sentence>
				<definiendum id="0">Honyaku</definiendum>
			</definition>
</paper>

		<paper id="2011">
			<definition id="0">
				<sentence>Fisher kernels : P ( xj ) using combined unlabelled and labelled data ; ; pressing the similarityinX-space ; ; Fisher kernel and inductive inference .</sentence>
				<definiendum id="0">Fisher kernels</definiendum>
				<definiens id="0">P ( xj ) using combined unlabelled and labelled data ; ; pressing the similarityinX-space ; ; Fisher kernel and inductive inference</definiens>
			</definition>
			<definition id="1">
				<sentence>Let us consider our collection of documents fx k g k=1 : : : N , and denote by ` ( x ) = logP ( xj ) the log-likelihood of the model for data x. The expression of the Fisher kernel ( Jaakkola and Haussler , 1999 ) is then : K ( x 1 ; ; x 2 ) =r` ( x 1 ) &gt; I F ; 1 r` ( x 2 ) ( 3 ) The Fisher information matrix I F can be seen as a waytokeep the kernel expression independent of parameterisation and is de ned as I F = E r` ( x ) r` ( x ) &gt; , where the gradient is w.r.t.  and the expectation is taken over P ( xj ) .</sentence>
				<definiendum id="0">Fisher kernel</definiendum>
				<definiendum id="1">K</definiendum>
				<definiens id="0">a waytokeep the kernel expression independent of parameterisation and is de ned as I F = E r` ( x ) r` ( x ) &gt; , where the gradient is w.r.t.  and the expectation is taken over P ( xj )</definiens>
			</definition>
			<definition id="2">
				<sentence>The inference consists in a trade-o between the size of the margin ( linked to generalisation abilities ) and the number of training errors .</sentence>
				<definiendum id="0">inference</definiendum>
				<definiens id="0">consists in a trade-o between the size of the margin ( linked to generalisation abilities ) and the number of training errors</definiens>
			</definition>
			<definition id="3">
				<sentence>SVM trained with inductive inference using Fisher kernels estimated fromthe whole training data ( without using labels ) , with di erentnumber of classes c in the PLSA model ( 4 ) .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">kernels estimated fromthe whole training data ( without using labels</definiens>
			</definition>
</paper>

		<paper id="2007">
			<definition id="0">
				<sentence>In our implementation , each terminal or branching node contains a probability distribution which encodes the conditional probability of entity classes given the sistring corresponding to the path from the root to that node .</sentence>
				<definiendum id="0">probability distribution</definiendum>
				<definiens id="0">encodes the conditional probability of entity classes given the sistring corresponding to the path from the root to that node</definiens>
			</definition>
			<definition id="1">
				<sentence>For a sistring a26a16a27a25a26a29a28a18a30a31a30a31a30a32a26 a5 ( i.e. the path in the trie is a33a18a34a18a34 a22a18a1 a26 a27 a1 a26 a28 a1 a30a31a30a31a30 a1 a26 a5 ) the general smoothing model for the conditional class probabilities is given by the recursive formula : a35 a3a36a13a16a37a39a38a41a40 a26a16a27a25a26a29a28a8a30a31a30a31a30a32a26a43a42 a24a45a44 a27 a46 a13a16a3a6a5a14a7a47a9a48a11a8a13a16a37a39a38a49a40 a26a16a27a48a26a50a28a18a30a31a30a31a30a32a26a43a42 a24a45a51 a52 a3a6a5a14a7a47a9a48a11a8a13a16a15a18a17a20a19a53a21a53a22a53a40 a26 a27 a26 a28 a30a31a30a31a30a32a26 a42 a24a55a54 a35 a3a36a13a16a37 a38 a40 a26 a27 a26 a28 a30a31a30a31a30a32a26 a42a57a56a58a27 a24a60a59 ( 1 ) where a61 is a normalization factor and a52 a62 a63 a64a49a65 a0a67a66 a65a6a68a70a69 a0 are model parameters .</sentence>
				<definiendum id="0">a61</definiendum>
				<definiens id="0">a normalization factor</definiens>
			</definition>
			<definition id="2">
				<sentence>The probability of an entity class a79a39a80 given an entity candidate a81 at position a82a20a83a85a84a23a86 is re-computed using the formula : a87a88a90a89a16a91 a79a39a80a93a92 a81a95a94a96a82a20a83a85a84a23a86a10a97a99a98a101a100 a102a104a103a106a105a107a109a108 a100a111a110 a88a36a91 a79a39a80a93a92 a81a112a94a96a82a113a83a18a84 a107 a97a48a114 a84a14a115a55a116 a91 a82a20a83a85a84a23a86a10a94a96a82a20a83a85a84 a107 a97a117a114a23a79a118a83a18a119a121a120 a91 a81a112a94a96a82a20a83a85a84 a107 a97 ( 2 ) where a82a20a83a85a84 a100 a94a109a122a31a122a31a122a31a94a96a82a20a83a85a84 a105 are the positions of all instances of a81 in the corpus , a84a53a115a60a116 is the positional similarity , encoding the physical distance and topic ( if topic or document boundary information exists ) , conf is the classification confidence of each instance ( inverse proportional to the the a110 a88a36a91a16a123a18a124a20a125 a84a23a126a23a92 a81a112a94a96a82a20a83a85a84 a107 a97 , a127 is a normalization factor .</sentence>
				<definiendum id="0">probability of an entity</definiendum>
				<definiendum id="1">a84a53a115a60a116</definiendum>
				<definiendum id="2">a127</definiendum>
				<definiens id="0">re-computed using the formula : a87a88a90a89a16a91 a79a39a80a93a92 a81a95a94a96a82a20a83a85a84a23a86a10a97a99a98a101a100 a102a104a103a106a105a107a109a108 a100a111a110 a88a36a91 a79a39a80a93a92 a81a112a94a96a82a113a83a18a84 a107 a97a48a114 a84a14a115a55a116 a91 a82a20a83a85a84a23a86a10a94a96a82a20a83a85a84 a107 a97a117a114a23a79a118a83a18a119a121a120 a91 a81a112a94a96a82a20a83a85a84 a107 a97 ( 2 ) where a82a20a83a85a84 a100 a94a109a122a31a122a31a122a31a94a96a82a20a83a85a84 a105 are the positions of all instances of a81 in the corpus</definiens>
				<definiens id="1">the positional similarity , encoding the physical distance and topic ( if topic or document boundary information exists ) , conf is the classification confidence of each instance ( inverse proportional to the the a110 a88a36a91a16a123a18a124a20a125 a84a23a126a23a92 a81a112a94a96a82a20a83a85a84 a107 a97</definiens>
				<definiens id="2">a normalization factor</definiens>
			</definition>
			<definition id="3">
				<sentence>a128a111a129 represents the number of entities with correctly identified boundaries , but wrong classifications .</sentence>
				<definiendum id="0">a128a111a129</definiendum>
				<definiens id="0">the number of entities with correctly identified boundaries , but wrong classifications</definiens>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>SVMs , on the other hand , have the potential to handle large feature spaces , since SVMs use overfitting protection which does not necessarily depend on the number of features , and thus makes it possible to produce better performance .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">does not necessarily depend on the number of features</definiens>
			</definition>
			<definition id="1">
				<sentence>a20a22a21a24a23a26a25a28a27a2a29a31a30a33a32a26a34a35a37a36a39a38 a20a22a21a40a23 a25 a27a41a34a35a42a36a24a43a45a44a46a48a47a12a44 a49a2a50a52a51 a20a22a21a40a53 a46 a47a24a54 a27a55a23 a25 a32a26a34a35a42a36 a44a56a57a44 a58 a50a52a51 a20a22a21a40a23 a58 a27a41a34a35a42a36a24a43 a44a46a59a47a60a44 a49a2a50a18a51 a20a22a21a40a53 a46 a47a40a54 a27a55a23 a58 a32a26a34a35a37a36 a61a63a62a64a0a2a65a57a0 a20a22a21a40a53a4a66a57a27a67a23a11a25a2a32a26a34a35a42a36a68a38 a69a28a70 a44a71a72a44 a30 a50a52a51a26a73 a21a40a53 a66 a32a74a29 a30 a36 a20a22a21a40a23 a25 a27a67a29 a30 a36 a27a76a75a77a27 a70 a44a78a64a44 a79 a50a18a51 a44a71a72a44 a30 a50a52a51 a73 a21a40a53 a79 a32a74a29a31a30 a36 a20a80a21a40a23a26a25a81a27a2a29a82a30 a36 a20a80a21a40a23 a25 a27a83a34a35a42a36a68a38 a44a71a72a44 a30 a50a52a51 a20a22a21a40a23 a25 a27a2a29 a30 a36a48a84 a27a2a85a86a27 ( 1 ) a87a88a89a87 refers to the number of vocabularies , a87a90a91a87 denotes the number of labeled training documents , and a87a92a93a87 shows the number of categories .</sentence>
				<definiendum id="0">a87a90a91a87</definiendum>
				<definiens id="0">the number of vocabularies ,</definiens>
				<definiens id="1">the number of labeled training documents , and a87a92a93a87 shows the number of categories</definiens>
			</definition>
			<definition id="2">
				<sentence>The decision surface produced by SVMs for linearly separable space is a hyperplane which can be written as a117a119a118a17a120 + a8 = 0 ( a120 , a117 a112a122a121a104a123 , a8 a112a124a121 ) , where a120 is an arbitrary data point , and a117 = ( a61a126a125 , a118a76a118a17a118 , a61 a123 ) and a8 are learned from a training set of linearly separable data .</sentence>
				<definiendum id="0">a120</definiendum>
				<definiens id="0">an arbitrary data point , and a117 = ( a61a126a125 , a118a76a118a17a118 , a61 a123 ) and a8 are learned from a training set of linearly separable data</definiens>
			</definition>
			<definition id="3">
				<sentence>A time complexity of SVMs is known as a165a169a102 a10a130a170 a106a132a171 a165a98a102 a10a173a172 a106 , where a10 is the number of training data .</sentence>
				<definiendum id="0">time complexity of SVMs</definiendum>
				<definiendum id="1">a10</definiendum>
			</definition>
			<definition id="4">
				<sentence>The time for learning one binary classifier , a176a169a102 a10 a174 a106 is represented as a176a169a102 a10 a174 a106a178a162 a92 a118 a10 a174 a172 , where a92 is a constant .</sentence>
				<definiendum id="0">a92</definiendum>
				<definiens id="0">a constant</definiens>
			</definition>
			<definition id="5">
				<sentence>Recall denotes the ratio of correct assignments by the system divided by the total number of correct assignments .</sentence>
				<definiendum id="0">Recall</definiendum>
			</definition>
			<definition id="6">
				<sentence>Precision is the ratio of correct assignments by the system divided by the total number of the system’s assignments .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio of correct assignments by the system divided by the total number of the system’s assignments</definiens>
			</definition>
			<definition id="7">
				<sentence>One is a classifier that separates documents assigned the ‘Economics’ category ( positive examples ) from documents assigned a set of the other 24 top level categories , i.e. ‘hierarchy’ .</sentence>
				<definiendum id="0">‘Economics’ category</definiendum>
				<definiens id="0">a classifier that separates documents assigned the</definiens>
			</definition>
</paper>

		<paper id="1715">
			<definition id="0">
				<sentence>GUI is an immensely successful concept , notably demonstrated by the World Wide Web .</sentence>
				<definiendum id="0">GUI</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Speech Application Language Tags ( SALT 2002 ) is a proposed standard for implementing spoken language interfaces .</sentence>
				<definiendum id="0">Speech Application Language Tags</definiendum>
			</definition>
			<definition id="2">
				<sentence>SALT preserves the tremendous amount of flexibility of a page-based dialog system in dynamically adapting the style and presentation of a dialog ( Wang 2000 ) .</sentence>
				<definiendum id="0">SALT</definiendum>
				<definiens id="0">preserves the tremendous amount of flexibility of a page-based dialog system in dynamically adapting the style</definiens>
			</definition>
			<definition id="3">
				<sentence>SALT extends the mechanism for speech input , in which the notion of semantic objects ( Wang 2000 , Wang 1998 ) is introduced to capture the meaning of spoken language .</sentence>
				<definiendum id="0">SALT</definiendum>
				<definiendum id="1">semantic objects</definiendum>
				<definiens id="0">extends the mechanism for speech input</definiens>
				<definiens id="1">introduced to capture the meaning of spoken language</definiens>
			</definition>
			<definition id="4">
				<sentence>If the language model is a probabilistic context free grammar ( PCFG ) , the object can return the parse tree of the recognized outcome .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">a probabilistic context free grammar (</definiens>
			</definition>
			<definition id="5">
				<sentence>The prompt object raises a barge-in event when the computer detects user utterance during a prompt playback .</sentence>
				<definiendum id="0">prompt object</definiendum>
				<definiens id="0">raises a barge-in event when the computer detects user utterance during a prompt playback</definiens>
			</definition>
			<definition id="6">
				<sentence>Implicit confirmation is a good example , where the absence of an explicit correction from the user is considered as a confirmation .</sentence>
				<definiendum id="0">Implicit confirmation</definiendum>
				<definiens id="0">a good example , where the absence of an explicit correction from the user is considered as a confirmation</definiens>
			</definition>
			<definition id="7">
				<sentence>As shown above , SALT reuses the W3C XPATH language for extracting partial semantic objects from the parsed outcome .</sentence>
				<definiendum id="0">SALT</definiendum>
				<definiens id="0">reuses the W3C XPATH language for extracting partial semantic objects from the parsed outcome</definiens>
			</definition>
			<definition id="8">
				<sentence>SALT follows the XML standards that allow extensions being introduced on demand without sacrificing document portability .</sentence>
				<definiendum id="0">SALT</definiendum>
			</definition>
			<definition id="9">
				<sentence>SALT allows flexible and powerful dialog management by fully taking advantage of the well publicized benefits of XML , such as separation of data from presentation .</sentence>
				<definiendum id="0">SALT</definiendum>
				<definiens id="0">allows flexible and powerful dialog management by fully taking advantage of the well publicized benefits of XML , such as separation of data from presentation</definiens>
			</definition>
</paper>

		<paper id="0508">
			<definition id="0">
				<sentence>When such an adverb appears in an input sentence ( it may appear as an unidentified element in a sentence for analysis ) we give it the symbol of a noun phrase ( NP ) , with a special index number : NP8 or NP9 .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">an unidentified element in a sentence for analysis ) we give it the symbol of a noun phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>A diagonal stroke “/” indicates another possibility , shown in the expression which follows it .</sentence>
				<definiendum id="0">diagonal stroke “/”</definiendum>
			</definition>
			<definition id="2">
				<sentence>Responsa : An Operational Full-Text Retrieval System .</sentence>
				<definiendum id="0">Responsa</definiendum>
				<definiens id="0">An Operational Full-Text Retrieval System</definiens>
			</definition>
</paper>

		<paper id="0404">
			<definition id="0">
				<sentence>RST describes the coherence nature of a text and is based on the assumption that the elementary textual units are non-overlapping text spans .</sentence>
				<definiendum id="0">RST</definiendum>
				<definiens id="0">describes the coherence nature of a text and is based on the assumption that the elementary textual units are non-overlapping text spans</definiens>
			</definition>
			<definition id="1">
				<sentence>Next , sentence extraction takes place , in which important sentences in the articles are identified .</sentence>
				<definiendum id="0">sentence extraction</definiendum>
				<definiens id="0">takes place , in which important sentences in the articles are identified</definiens>
			</definition>
			<definition id="2">
				<sentence>The first of the three features is the centroid score , which quantifies the centrality of a sentence to the overall cluster of documents .</sentence>
				<definiendum id="0">centroid score</definiendum>
				<definiens id="0">quantifies the centrality of a sentence to the overall cluster of documents</definiens>
			</definition>
			<definition id="3">
				<sentence>The second is the position score , which assigns higher scores to sentences that are closer to the beginning of the document .</sentence>
				<definiendum id="0">position score</definiendum>
				<definiens id="0">assigns higher scores to sentences that are closer to the beginning of the document</definiens>
			</definition>
			<definition id="4">
				<sentence>&lt; Add &gt; adverb Multi-Document Extract CST Enhanced Summary CST Enhanced Revised Summary Source Documents A B C D C:1 B:13 D:5 Figure 1 : Revision-based MDS architecture : Letters denote documents ; numbers denote sentence numbers ( within documents ) We generated a corpus of summaries using the MEAD summarizer .</sentence>
				<definiendum id="0">Revision-based MDS</definiendum>
				<definiens id="0">architecture : Letters denote documents ; numbers denote sentence numbers ( within documents</definiens>
			</definition>
			<definition id="5">
				<sentence>Egypt , which lacks the oil wealth of the Gulf and has an economy struggling to revive from decades of socialist stagnation , has a long tradition of sending workers to the Gulf to fill everything from skilled to menial jobs .</sentence>
				<definiendum id="0">Egypt</definiendum>
				<definiens id="0">lacks the oil wealth of the Gulf and has an economy struggling to revive from decades of socialist stagnation</definiens>
			</definition>
</paper>

		<paper id="1806">
			<definition id="0">
				<sentence>CFG : A context-free grammar ( CFG ) is a quadruple ) , , , ( RSVV TN where T V is a set of terminals ( POS tags ) , N V is a set of non-terminals ( syntactic tags ) , N VS ∈ is the start non-terminal , and R is the finite set of rules , which are pairs from + ×VV N , where V denotes TN VV G1B .</sentence>
				<definiendum id="0">CFG</definiendum>
				<definiendum id="1">CFG</definiendum>
				<definiendum id="2">N V</definiendum>
				<definiendum id="3">, N VS ∈</definiendum>
				<definiendum id="4">R</definiendum>
				<definiens id="0">A context-free grammar (</definiens>
				<definiens id="1">a quadruple ) , , , ( RSVV TN where T V is a set of terminals ( POS tags ) ,</definiens>
				<definiens id="2">a set of non-terminals ( syntactic tags )</definiens>
				<definiens id="3">the start non-terminal , and</definiens>
				<definiens id="4">the finite set of rules , which are pairs from + ×VV N , where V denotes TN VV G1B</definiens>
			</definition>
			<definition id="1">
				<sentence>PCFG : A probabilistic context-free grammar ( PCFG ) is a quintuple ) , , , , ( PRSVV TN , where ) , , , ( RSVV TN is a CFG and ] 1,0 ( : G1DRP is a probability function such that N VN ∈∀ : ∑ ∈→ =→ RN NP αα α : 1 ) ( Rule Restriction : We restrict the CFG rules to be binary or unary rules , but NOT as strict as the Chomsky Normal Form ( CNF ) .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiendum id="1">PCFG</definiendum>
				<definiens id="0">A probabilistic context-free grammar (</definiens>
			</definition>
</paper>

		<paper id="2023">
			<definition id="0">
				<sentence>Similar rules hold for diffe r ent kinds of named entities consisting of more than one word .</sentence>
				<definiendum id="0">Similar rules</definiendum>
				<definiens id="0">hold for diffe r ent kinds of named entities consisting of more than one word</definiens>
			</definition>
			<definition id="1">
				<sentence>Theologe ( TI ) Theodor ( FN ) Theobald ( FN ) Theo [ d e fault ] ( FN ) ... ... T A Z ( root ) Figure 2 : Prefix Decision Tree for Proper Names As mentioned above , algorithm B works the same way as algorithm A , using suffixes instead of pr e fixes for the decision tree .</sentence>
				<definiendum id="0">Theologe</definiendum>
				<definiens id="0">e fault ] ( FN ) ... ... T A Z ( root ) Figure 2 : Prefix Decision Tree for Proper Names As mentioned above , algorithm B works the same way as algorithm A , using suffixes instead of pr e fixes for the decision tree</definiens>
			</definition>
</paper>

		<paper id="1613">
			<definition id="0">
				<sentence>The knowledge base is a bilingual corpus of source slices S’ and their translations T’ Given a source slice of input S , match S with the source slices and choose the most similar as the translation or get the translation from it .</sentence>
				<definiendum id="0">knowledge base</definiendum>
			</definition>
			<definition id="1">
				<sentence>From the Naïve Bayes formula： P ( C|CWk ) = P ( { vj | vj in C } |CWk ) = ∏ Vj in C P ( vj|sk ) ( 2 ) So formula ( 1 ) can be rewritten as : CW = argmax [ P ( CWk|C ) ] Input Sentence Statistics Knowledge = argmax [ logP ( CWk ) +∑ Vj in C logP ( vj|CWk ) ] ( 3 ) Where P ( CWk ) denotes the probability that CWk occurs in the corpus ; P ( vj| CWk ) denotes the probability that the context feature vj co-occurs with translation CWk。 A general algorithm of supervised word sense disambiguation is as follows : POS Tagger Manual Rule Base PPA Resolution Layered Parsing n comparative usable hip am also with s words , wor odification .</sentence>
				<definiendum id="0">CWk )</definiendum>
				<definiendum id="1">P ( vj| CWk )</definiendum>
				<definiens id="0">P ( { vj | vj in C } |CWk ) = ∏ Vj in C P ( vj|sk ) ( 2 ) So formula ( 1 ) can be rewritten as : CW = argmax [ P ( CWk|C ) ] Input Sentence Statistics Knowledge = argmax [ logP</definiens>
				<definiens id="1">the probability that CWk occurs in the corpus</definiens>
				<definiens id="2">the probability that the context feature vj co-occurs with translation CWk。 A general algorithm of supervised word sense disambiguation is as follows : POS Tagger Manual Rule Base PPA Resolution Layered Parsing n comparative usable hip am also with s words , wor odification</definiens>
			</definition>
			<definition id="2">
				<sentence>The conditional part is a scan window of variable length , which uses the context constraint conditions such as phrases or some linguistic features .</sentence>
				<definiendum id="0">conditional part</definiendum>
				<definiens id="0">uses the context constraint conditions such as phrases or some linguistic features</definiens>
			</definition>
			<definition id="3">
				<sentence>The operation part consists of corresponding conditional parts and translations and also , if necessary , some action functions .</sentence>
				<definiendum id="0">operation part</definiendum>
			</definition>
			<definition id="4">
				<sentence>For example , the rule to combine an adjective and a noun to generate a noun phrase is as follows : 0 : Cate=A + 1 : Cate=N - &gt; 0 : * + 1 : * + _NodeUf ( N， 0， 1 ) in which , “*” stands for corresponding translation of the nodes , _NodeUf ( ) is a function that combines the nodes to generate a new node .</sentence>
				<definiendum id="0">_NodeUf ( )</definiendum>
			</definition>
</paper>

		<paper id="0403">
</paper>

		<paper id="1801">
			<definition id="0">
				<sentence>The first phase could be called a generative phase , which lists all possible translation equivalent pairs from the aligned corpus .</sentence>
				<definiendum id="0">generative phase</definiendum>
				<definiens id="0">lists all possible translation equivalent pairs from the aligned corpus</definiens>
			</definition>
</paper>

		<paper id="1115">
			<definition id="0">
				<sentence>In practice , the method requires a0a2a1a4a3a6a5a8a7a10a9a12a11a13a1a4a3a15a14a16a14 computation time , and a0a2a1a4a3a17a14 memory space , where a3 is the number of documents or records .</sentence>
				<definiendum id="0">a3</definiendum>
			</definition>
			<definition id="1">
				<sentence>In order to find relationships between words in a large corpus or between labels in a large database , we may use a distance measure between the binary vectors of a3 dimensions , where a3 is the number of documents or records , and the a18 th element is 1 if the a18 th document/record contains the word or the label , or 0 otherwise .</sentence>
				<definiendum id="0">a3</definiendum>
				<definiens id="0">the number of documents or records</definiens>
			</definition>
			<definition id="2">
				<sentence>The sorted list is obtained in a0a2a1 a18 a35 a5 a3 a5 a7 a9a12a11 a1 a18 a35 a5 a3a15a14a16a14 computation time , where a18 is the maximum number of different words/labels in one document .</sentence>
				<definiendum id="0">a18</definiendum>
				<definiens id="0">the maximum number of different words/labels in one document</definiens>
			</definition>
			<definition id="3">
				<sentence>The computation time of the baseline system is a34 a35 a5 a3 where a34 is the distinct number of labels in the a3 time ( sec . )</sentence>
				<definiendum id="0">a34</definiendum>
				<definiens id="0">the distinct number of labels in the a3 time ( sec</definiens>
			</definition>
			<definition id="4">
				<sentence>The Yamamoto-Church method ( Yamamoto and Church , 2001 ) allows for the creation of a a21a29a22 a1 a19 a14 table using a0a8a1a4a3a15a14 memory space and a0a2a1a4a3 a5 a7 a9a12a11 a1a4a3a15a14a16a14 computation time , where a19 represents all substrings in a given corpus .</sentence>
				<definiendum id="0">Yamamoto-Church method</definiendum>
				<definiendum id="1">a19</definiendum>
				<definiens id="0">all substrings in a given corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>13 Conclusion This paper describes a method for selecting correlated pairs in a0a8a1a4a3a15a14 memory space and a0a2a1a4a3 a5 a7a10a9a12a11 a1a4a3a17a14a16a14 computation time , where a3 is the number of documents in a corpus , provided that there is an upper boundary in the number of different words/labels in one document/record .</sentence>
				<definiendum id="0">a3</definiendum>
				<definiens id="0">the number of documents in a corpus</definiens>
			</definition>
</paper>

		<paper id="2028">
</paper>

		<paper id="1406">
			<definition id="0">
				<sentence>Named entity ( NE ) recognition is an important task for many natural language applications , such as Internet search engines , document indexing , information extraction and machine translation .</sentence>
				<definiendum id="0">recognition</definiendum>
				<definiens id="0">Named entity ( NE )</definiens>
			</definition>
			<definition id="1">
				<sentence>According to Neyman-Pearson Lemma , an optimal hypothesis test involves the evaluation of the following log likelihood ratio : , , , ,1 ,1 ,1 , , , ,1 ,1 ,1 0 , , , ,1 ,1 ,1 1 , , , ,1 ,1 ,1 0 , , , ,1,1,11 ( , , ) ( , , | ) log ( , , | ) log ( , , | ) log ( , , | ) Lx Cy Rz LC R Lx Cy Rz LC R Lx Cy Rz LC R Lx Cy Rz LC R Lx Cy Rz LC R LLR o o o Po o o H Po o o H Po o o H P ooo H = = − ( 1 ) where , , , ,1,1,1 0 ( , , | ) Lx Cy Rz LC R P ooo His the likelihood of the candidate and its left and right contexts given the hypothesis that the candidate is a name and , , , ,1,1,11 ( , , | ) Lx Cy Rz LC R P ooo H is the likelihood of the candidate and its left and right contexts given the hypothesis that the candidate is not a name .</sentence>
				<definiendum id="0">| ) Lx Cy Rz LC R Lx Cy Rz LC R Lx Cy Rz LC R Lx Cy Rz LC R Lx Cy Rz LC</definiendum>
				<definiens id="0">an optimal hypothesis test involves the evaluation of the following log likelihood ratio : , , , ,1 ,1 ,1 , , , ,1 ,1 ,1 0 , , , ,1 ,1 ,1 1 , , , ,1 ,1 ,1 0 , , , ,1,1,11 ( , , ) ( , , | ) log ( , , | ) log ( , , | ) log ( , ,</definiens>
				<definiens id="1">P ooo H = = − ( 1 ) where , , , ,1,1,1 0 ( , , | ) Lx Cy Rz LC R P ooo His the likelihood of the candidate and its left and right contexts given the hypothesis that the candidate is a name and , , , ,1,1,11 ( , , | ) Lx Cy Rz LC R P ooo H is the likelihood of the candidate and its left and right contexts given the hypothesis that the candidate is not a name</definiens>
			</definition>
			<definition id="2">
				<sentence>chastic Context-free Grammar ) model ( Fujisaki , 1989 ) as follows : , 0,1 0 00 ( ) ( ) max ( ) max ( | ) Cy C T TT AT Po PT P TPA α α →∈ = ≈= ∑ ∏ ( 5 ) where T stands for one possible parse tree that derive the candidate , A α→ indicates a rule in the parse tree T , A stands for the left-handside symbol of the rule and α stands for the sequence of right-hand-side symbols of the rule .</sentence>
				<definiendum id="0">chastic Context-free Grammar ) model</definiendum>
				<definiens id="0">max ( ) max ( | ) Cy C T TT AT Po PT P TPA α α →∈ = ≈= ∑ ∏ ( 5 ) where T stands for one possible parse tree</definiens>
			</definition>
			<definition id="3">
				<sentence>In this figure , the symbol “S” denotes the start symbol , the symbol “SNG” denotes the nonterminal deriving surname characters and the symbol “GNC” denotes the nonterminal deriving given name characters .</sentence>
				<definiendum id="0">symbol “S”</definiendum>
				<definiendum id="1">symbol “SNG”</definiendum>
				<definiendum id="2">symbol “GNC”</definiendum>
				<definiens id="0">the start symbol , the</definiens>
				<definiens id="1">the nonterminal deriving given name characters</definiens>
			</definition>
			<definition id="4">
				<sentence>As a result , according to equations ( 2 ) - ( 5 ) , the scoring function in the NE model is defined as equation ( 6 ) to assess the log likelihood of the text segment “ , , , ,1,1,1 , , L xCyRz L CR o oo”given the null hypothesis that “ , ,1 Cy C o ”isaname .</sentence>
				<definiendum id="0">scoring function</definiendum>
				<definiens id="0">equation ( 6 ) to assess the log likelihood of the text segment “ , , , ,1,1,1 , , L xCyRz L CR o oo”given the null hypothesis that “ , ,1 Cy C o ”isaname</definiens>
			</definition>
			<definition id="5">
				<sentence>, , , NE ,1 ,1 ,1 0 , ,1 0 , ,1 11 0 ( , , ) log ( | ) log ( | ) max log ( | ) Lx Cy Rz LC R xz Li Li Ri Ri ii T AT Sooo Po o Po o PA α α −− == →∈ =+ + ∑∑ ∑ ( 6 ) where T is one possible parse tree that derive the candidate “ , ,1 Cy C o ” .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">one possible parse tree that derive the candidate “ , ,1 Cy C o ”</definiens>
			</definition>
			<definition id="6">
				<sentence>The purpose of the anti-NE model is to evaluate the value of , , , ,1,1,11 log ( , , | ) Lx Cy Rz LC R P ooo H , thelog likelihood of the candidate and its left and right contexts given the hypothesis that the candidate is not a name .</sentence>
				<definiendum id="0">anti-NE model</definiendum>
				<definiens id="0">to evaluate the value of , , , ,1,1,11 log ( , , | ) Lx Cy Rz LC R P ooo H , thelog likelihood of the candidate and its left and right contexts given the</definiens>
			</definition>
			<definition id="7">
				<sentence>The Expectation-Maximization ( EM ) algorithm ( Moon , 1996 ) has been widely used to estimate model parameters from incomplete data in many different applications .</sentence>
				<definiendum id="0">Expectation-Maximization</definiendum>
				<definiens id="0">used to estimate model parameters from incomplete data in many different applications</definiens>
			</definition>
			<definition id="8">
				<sentence>Conclusion Named entity ( NE ) recognition is an important task for many natural language applications , such as Internet search engines , document indexing , information extraction and machine translation .</sentence>
				<definiendum id="0">Conclusion Named entity ( NE ) recognition</definiendum>
			</definition>
</paper>

		<paper id="0906">
			<definition id="0">
				<sentence>The system obtains the data from raw corpora after the application of a partial parser and statistical filters .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">obtains the data from raw corpora after the application of a partial parser and statistical filters</definiens>
			</definition>
			<definition id="1">
				<sentence>The Kennedy Center is a part of Washington , therefore to see somebody in the Kennedy Center and see him in Washington are not semantically incompatible , so it is plausible to say it .</sentence>
				<definiendum id="0">Kennedy Center</definiendum>
			</definition>
			<definition id="2">
				<sentence>MI is a measure coming from Information Theory , defined as the logarithm of the ratio between the probability of the cooccurrence of the verb and the case , and the probability of the verb and the case appearing together calculated from their independent probability .</sentence>
				<definiendum id="0">MI</definiendum>
			</definition>
			<definition id="3">
				<sentence>Precision and recall would improve considerably if they were included because they are the most frequent cases ( as statistics perform well over frequent data ) , and also because the shallow parser links them correctly using the information carried by the auxiliary .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">statistics perform well over frequent data ) , and also because the shallow parser links them correctly using the information carried by the auxiliary</definiens>
			</definition>
</paper>

		<paper id="2026">
</paper>

		<paper id="0107">
			<definition id="0">
				<sentence>The university is one of the largest private universities in the U.S. with an enrollment of about 30,000 ( with 2,000 graduate students ) .</sentence>
				<definiendum id="0">university</definiendum>
				<definiens id="0">one of the largest private universities in the U.S. with an enrollment of about 30,000 ( with 2,000 graduate students</definiens>
			</definition>
			<definition id="1">
				<sentence>The Linguistics Department offers undergraduate and master degrees ( but no Ph.D. ) ; over 150 undergraduate majors are currently enrolled .</sentence>
				<definiendum id="0">Linguistics Department</definiendum>
			</definition>
			<definition id="2">
				<sentence>Evaluations : A three-hour ( non-programming ) final exam is given which tests a knowledge of concepts , algorithms , tools , procedures , and approaches learned throught the semester .</sentence>
				<definiendum id="0">three-hour</definiendum>
				<definiens id="0">tests a knowledge of concepts , algorithms , tools , procedures , and approaches learned throught the semester</definiens>
			</definition>
			<definition id="3">
				<sentence>With the NLP infrastructure recently developed , more technological exercises have been added to the curriculum involving WordNet , bitext alignment , corpus and lexicography tools , software localization ( l10n ) and internationalization ( i18n ) , machine-assisted translation , and machine translation systems ( standalone and web-based ) .</sentence>
				<definiendum id="0">internationalization</definiendum>
				<definiens id="0">added to the curriculum involving WordNet , bitext alignment , corpus and lexicography tools , software localization</definiens>
			</definition>
			<definition id="4">
				<sentence>works with a speech toolkit , a grad morphology class uses a morphology engine , and a language modeling seminar uses machine learning and other exemplarbased methods .</sentence>
				<definiendum id="0">grad morphology class</definiendum>
				<definiens id="0">uses a morphology engine , and a language modeling seminar uses machine learning and other exemplarbased methods</definiens>
			</definition>
</paper>

		<paper id="2031">
			<definition id="0">
				<sentence>Uppercase EFE Capitalized Australia Lowercase ( word length a10a12a11 characters ) necesidad Lowercase ( word length a13a12a11 characters ) del Other hoy , Table 1 : Word features and examples a8 One of the eight word features in Table 1 .</sentence>
				<definiendum id="0">Uppercase EFE Capitalized Australia Lowercase</definiendum>
				<definiens id="0">word length a10a12a11 characters ) necesidad Lowercase ( word length a13a12a11 characters ) del Other hoy</definiens>
			</definition>
</paper>

		<paper id="2001">
			<definition id="0">
				<sentence>MWEs pose a challenge to NLP due to their syntactic and semantic idiosyncrasies , which are often unpredictable from their component parts .</sentence>
				<definiendum id="0">MWEs</definiendum>
				<definiens id="0">pose a challenge to NLP due to their syntactic and semantic idiosyncrasies , which are often unpredictable from their component parts</definiens>
			</definition>
			<definition id="1">
				<sentence>Verb-particle constructions ( \VPCs '' ) consist of a 1http : //lingo.stanford.edu/mwe head verb and one or more obligatory particles , in the form of intransitive prepositions ( e.g. hand in ) , adjectives ( e.g. cut short ) or verbs ( e.g. let go ) ( Villavicencio and Copestake , 2002a ; Villavicencio and Copestake , 2002b ; Huddleston and Pullum , 2002 ) ; for the purposes of this paper , we will focus exclusively on prepositional particles|by far the most common and productive of the three types| and further restrict our attention to single-particle VPCs ( i.e. we ignore VPCs such as get along together ) .</sentence>
				<definiendum id="0">Verb-particle constructions</definiendum>
				<definiendum id="1">single-particle VPCs</definiendum>
				<definiens id="0">//lingo.stanford.edu/mwe head verb and one or more obligatory particles , in the form of intransitive prepositions ( e.g. hand in ) , adjectives ( e.g. cut short ) or verbs</definiens>
			</definition>
			<definition id="2">
				<sentence>The flrst diagnostic is the canonical test for particlehood , and states that transitive VPCs take two word orders : the joined conflguration whereby the verb and particle are adjacent and the NP complement follows the particle ( e.g. hand in the paper ) , and the split conflguration whereby the NP complement occurs between the verb and particle ( e.g. hand the paper in ) .</sentence>
				<definiendum id="0">flrst diagnostic</definiendum>
			</definition>
			<definition id="3">
				<sentence>That is , recall is an indication of the proportion of the 62 VPCs contained within the set of extracted VPCs .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">an indication of the proportion of the 62 VPCs contained within the set of extracted VPCs</definiens>
			</definition>
			<definition id="4">
				<sentence>Extraction One obvious method for extracting VPCs is to run a simple regular expression over the output of a partof-speech ( POS ) tagger , based on the observation that the Penn Treebank POS tagset , e.g. , contains a dedicated particle tag ( RP ) .</sentence>
				<definiendum id="0">VPCs</definiendum>
				<definiens id="0">to run a simple regular expression over the output of a partof-speech ( POS ) tagger , based on the observation that the Penn Treebank POS tagset , e.g. , contains a dedicated particle tag</definiens>
			</definition>
			<definition id="5">
				<sentence>TiMBL is a memory-based classiflcation system based on the k-nearest neighbour algorithm , which takes as training data a set of flxed-length feature vectors pre-classifled according to an information fleld .</sentence>
				<definiendum id="0">TiMBL</definiendum>
				<definiens id="0">a memory-based classiflcation system based on the k-nearest neighbour algorithm , which takes as training data a set of flxed-length feature vectors pre-classifled according to an information fleld</definiens>
			</definition>
			<definition id="6">
				<sentence>TiMBL provides powerful functionality for determining the relative distance between difierent values of a given feature in the form of MVDM , and also supports weighted voting between neighbours in classifying inputs , e.g. in the form of inverse distance weighting .</sentence>
				<definiendum id="0">TiMBL</definiendum>
				<definiens id="0">provides powerful functionality for determining the relative distance between difierent values of a given feature in the form of MVDM</definiens>
			</definition>
			<definition id="7">
				<sentence>We ran TiMBL based on the feature set described in Veenstra and van den Bosch ( 2000 ) , that is using the 5 word lemmata and POS tags to the left and 3 word lemmata and POS tags to the right of each focus word , along with the POS tag and lemma for the focus word .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiendum id="1">POS</definiendum>
				<definiens id="0">tags to the right of each focus word , along with the POS tag and lemma for the focus word</definiens>
			</definition>
			<definition id="8">
				<sentence>The reason for the dropofi in performance between the CoNLL data and the full WSJ is due to the CoNLL training and test data coming from a homogeneous data source , namely a subsection of the WSJ , but the Brown corpus being used as the training data in chunking the full extent of the WSJ .</sentence>
				<definiendum id="0">WSJ</definiendum>
				<definiens id="0">due to the CoNLL training and test data coming from a homogeneous data source , namely a subsection of the WSJ , but the Brown corpus being used as the training data in chunking the full extent of the WSJ</definiens>
			</definition>
			<definition id="9">
				<sentence>Smadja based his method on bigrams , but unlike conventional collocation work , described bigrams by way of the triple of hword1 , word2 , posni , where posn is the number of words occurring between word1 and word2 ( up to 4 ) .</sentence>
				<definiendum id="0">posn</definiendum>
				<definiens id="0">the number of words occurring between word1 and word2 ( up to 4 )</definiens>
			</definition>
			<definition id="10">
				<sentence>Multiword expressions : A pain in the neck for NLP .</sentence>
				<definiendum id="0">Multiword expressions</definiendum>
				<definiens id="0">A pain in the neck for NLP</definiens>
			</definition>
</paper>

		<paper id="1209">
			<definition id="0">
				<sentence>In order to describe the position relationship amongst components in a character , we have used the 12 Ideographic Description Characters ( IDC ) in ISO/IEC 10646 Part1:2000 in the range from 2FF0 to 2FFB , and defined an extra IDC “M” ( which indicates that a particular component is a basic component and will not be further decomposed ) , as shown in Table 1 .</sentence>
				<definiendum id="0">Ideographic Description Characters</definiendum>
				<definiens id="0">indicates that a particular component is a basic component and will not be further decomposed )</definiens>
			</definition>
			<definition id="1">
				<sentence>Each Character is decomposed according to the following definition : Character = IDC2 CC ( 1 ) CC ( 2 ) | IDC3 CC ( 1 ) CC ( 2 ) CC ( 3 ) | M where IDC2 ∈ ( 2FF0 – 2FFB ) CC ( i ) is a set of character components and i indicates its position in the sequence M is a special symbol indicating Character will not be further decomposed By our definition , a CC can be formed by three subsets : ( 1 ) coded radicals , ( 2 ) coded components and ideographs proper , and ( 3 ) intermediate components that are not coded in ISO 10646 .</sentence>
				<definiendum id="0">IDC2 ∈</definiendum>
				<definiendum id="1">M</definiendum>
				<definiens id="0">a special symbol indicating</definiens>
			</definition>
</paper>

		<paper id="0717">
			<definition id="0">
				<sentence>The connection between Client/Agent PCs and the Mediator is a standard video-conferencing connection that uses H323 and UDP protocols .</sentence>
				<definiendum id="0">Mediator</definiendum>
			</definition>
			<definition id="1">
				<sentence>The user interface display is designed for Windows r©and consists of four windows : ( 1 ) aMicrosoftr©Internet Explorer web browser ; ( 2 ) a Microsoft r©Windows NetMeeting videoconferencing application ; ( 3 ) the AeWhiteboard ; and ( 4 ) the Nespole Monitor .</sentence>
				<definiendum id="0">Windows r©and</definiendum>
				<definiens id="0">consists of four windows : ( 1 ) aMicrosoftr©Internet Explorer web browser ; ( 2 ) a Microsoft r©Windows NetMeeting videoconferencing application ; ( 3 ) the AeWhiteboard</definiens>
			</definition>
			<definition id="2">
				<sentence>The data used in the evaluations is part of a database collected during the project ( Burger et al. , 2001 ) .</sentence>
				<definiendum id="0">data</definiendum>
			</definition>
			<definition id="3">
				<sentence>The goals of the experiment were to test : ( 1 ) whether multi-modality increases the probability of successful interaction , especially when spatial information is the focus of the communicative exchange ; ( 2 ) whether multimodality helps reduce mis-communications and disfluencies ; and ( 3 ) whether multi-modality supports a faster recovery from recognition and translation errors .</sentence>
				<definiendum id="0">multi-modality</definiendum>
				<definiens id="0">increases the probability of successful interaction , especially when spatial information is the focus of the communicative exchange ; ( 2 ) whether multimodality helps reduce mis-communications and disfluencies</definiens>
			</definition>
</paper>

		<paper id="2003">
</paper>

		<paper id="1713">
			<definition id="0">
				<sentence>Here the upper template is intended to be used during the generation of text targeted at experts and the lower one in case text is to be produced for novices ( level is expert in one template and novice in the other ) .</sentence>
				<definiendum id="0">level</definiendum>
				<definiens id="0">to be produced for novices</definiens>
			</definition>
			<definition id="1">
				<sentence>XML was chosen because it has become the defacto standard language in many ( if not most ) scenarios where information transfer takes place .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">if not most ) scenarios where information transfer takes place</definiens>
			</definition>
			<definition id="2">
				<sentence>setGrammar ( Grammar grammar ) ; In the first case a Document object ( World Wide Web Consortium , 2000 ) that contains the grammar in parsed XML-format is passed , in the second case a pre-compiled Grammar object is passed .</sentence>
				<definiendum id="0">setGrammar</definiendum>
			</definition>
			<definition id="3">
				<sentence>setInputDocument ( Document input ) ; Again , the parameter passed is a Document object that contains the input in parsed XML format .</sentence>
				<definiendum id="0">setInputDocument</definiendum>
			</definition>
</paper>

		<paper id="0900">
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>Third , it has been shown by Perrone and Cooper ( 1993 ) that it is possible to reduce the classification error by a factor of BD C6 ( C6 is the number of classifiers ) by combination , if the classifiers’ errors are uncorrelated and unbiased .</sentence>
				<definiendum id="0">BD C6 ( C6</definiendum>
				<definiens id="0">the number of classifiers</definiens>
			</definition>
			<definition id="1">
				<sentence>Pedersen ( 2000 ) presents experiments with an ensemble of Naïve Bayes classifiers , which outperform all previous published results on two ambiguous words ( line and interest ) .</sentence>
				<definiendum id="0">Naïve Bayes classifiers</definiendum>
				<definiens id="0">outperform all previous published results on two ambiguous words</definiens>
			</definition>
			<definition id="2">
				<sentence>The feature space is a critical factor in classifier design , given the need to fuel the diverse strengths of the component classifiers .</sentence>
				<definiendum id="0">feature space</definiendum>
				<definiens id="0">a critical factor in classifier design , given the need to fuel the diverse strengths of the component classifiers</definiens>
			</definition>
			<definition id="3">
				<sentence>The syntactic features extracted for a target word depend on the word’s part of speech : AF verbs : the head noun of the verb’s object , particle/preposition and prepositional object ; AF nouns : the headword of any verb-object , subject-verb or noun-noun relationships identified for the target word ; AF adjectives : the head noun modified by the adjective .</sentence>
				<definiendum id="0">AF verbs</definiendum>
				<definiendum id="1">AF nouns</definiendum>
				<definiendum id="2">AF adjectives</definiendum>
				<definiens id="0">: the headword of any verb-object , subject-verb or noun-noun relationships identified for the target word ;</definiens>
			</definition>
			<definition id="4">
				<sentence>In these models , a vector is created for each document in the collection : CS BP B4CS CY B5 CYBYCY CYBPBD BNCS CY BP CR CY C6 CF CY , where CR CY is the number of times the feature CU CY appears in document CS , C6 is the number of words in CS and CF CY is a weight associated with the feature CU CY 2 .</sentence>
				<definiendum id="0">CR CY</definiendum>
				<definiendum id="1">C6</definiendum>
				<definiendum id="2">CF CY</definiendum>
				<definiens id="0">the number of times the feature CU CY appears in document CS ,</definiens>
				<definiens id="1">the number of words in CS and</definiens>
			</definition>
			<definition id="5">
				<sentence>2 The weight CF CY depends on the type of the feature CU CY : for the bag-of-word features , this weight is inversely proportional to the distance between the target word and the feature , while for predicate-argument and extended ngram features it is a empirically estimated weight ( on a per language basis ) .</sentence>
				<definiendum id="0">weight CF CY</definiendum>
				<definiendum id="1">CU CY</definiendum>
				<definiens id="0">a empirically estimated weight ( on a per language basis )</definiens>
			</definition>
			<definition id="6">
				<sentence>CMD7 BP CPD6CVD1CPDC D7 C8 B4D7CYCSB5 C8 B4BMD7CYCSB5 BP CPD6CVD1CPDC D7 C8 B4D7B5 C8 B4BMD7B5 CH CUBECS C8 B4CUCYD7B5 C8 B4CUCYBMD7B5 where CMD7 is the selected sense , CS denotes documents and CU denotes features .</sentence>
				<definiendum id="0">CMD7</definiendum>
				<definiendum id="1">CS</definiendum>
				<definiendum id="2">CU</definiendum>
				<definiens id="0">the selected sense</definiens>
				<definiens id="1">documents and</definiens>
			</definition>
			<definition id="7">
				<sentence>00 00 11 11 000000000000000000000000000000000000000000011111111111111111111111111111111111111111110 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 00 00 11 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 00 00 00 00 00 00 00 00 00 00 00 00 00 00 11 11 11 11 11 11 11 11 11 11 11 11 11 11 00 00 11 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 00 00 11 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 00 00 11 11 Cosine Bayes TBL DL BayesRatio Classifier Aggreement ( % of data ) Bayes Cosine BayesRatio DL TBL MMVC MMVC ( a ) Classifier inter-agreement on SENSEVAL2 English data System SENSEVAL1 SENSEVAL2 EN EN ES EU SV Baseline 63.2 48.3 45.9 62.7 46.2 NB 80.4 65.7 67.9 71.2 66.7 BR 79.8 65.3 69.0 69.6 68.0 Cosine 74.0 62.2 65.9 66.0 66.4 DL 79.9 63.2 65.1 70.7 61.5 TBL 80.7 64.4 64.7 69.4 62.7 MMVC 81.1 66.7 66.7 69.7 61.9 ( b ) Individual classifier performance ; best performers are shown in bold Figure 3 : Individual Classifier Properties ( cross-validation on SENSEVAL training data ) Distributions One of the simplest ways to combine the posterior probability distributions is via direct averaging ( Equation ( 1 ) ) .</sentence>
				<definiendum id="0">Cosine Bayes TBL DL BayesRatio Classifier Aggreement</definiendum>
				<definiens id="0">Individual Classifier Properties ( cross-validation on SENSEVAL training data</definiens>
			</definition>
			<definition id="8">
				<sentence>The averaging method is a particular case of weighted mixture : 4 C8 B4D7CYDCBNCSB5 BP C6 CG CZBPBD C8 B4CZCYDCBNCSB5 A1 C8 CZ B4D7CYDCBNCSB5BP C6 CG CZBPBD AL CZ B4DCBNCSB5 A1C8 CZ B4D7CYDCBNCSB5 ( 2 ) where AL CZ B4CSBNCSB5 is the weight assigned to the classifier CZ in the mixture and D4 CZ B4D7CYDCBNCSB5 is the posterior probability distribution output by classifier CZ ; for AL CZ B4DCBNCSB5BP BD C6 we obtain Equation ( 1 ) .</sentence>
				<definiendum id="0">averaging method</definiendum>
				<definiendum id="1">AL CZ B4CSBNCSB5</definiendum>
				<definiendum id="2">D4 CZ B4D7CYDCBNCSB5</definiendum>
				<definiens id="0">the weight assigned to the classifier CZ in the mixture</definiens>
			</definition>
			<definition id="9">
				<sentence>One way to estimate these parameters is by linear regression ( Fuhr , 1989 ) : estimate the coefficients that minimize the mean square error ( MSE ) D1CXD2 CG DC CG CS AD AD AD AD AD BV B4DCBNCSB5 A0 C6 CG CZBPBD AL CZ B4DCBNCSB5 A1 D4B4A1CYDCBNCSB5 AD AD AD AD AD BE ( 3 ) where BV B4DCBNCSB5 is the target vector of the correct classification of word DC in document d : 4 Note that we are computing a probability conditioned both on the target word DC and the document CS , because the documents are associated with a particular target word DC ; this formalization works mainly for the lexical choice task .</sentence>
				<definiendum id="0">CG DC CG CS AD AD AD AD AD BV</definiendum>
				<definiendum id="1">BV B4DCBNCSB5</definiendum>
				<definiens id="0">estimate the coefficients that minimize the mean square error ( MSE ) D1CXD2</definiens>
				<definiens id="1">the target vector of the correct classification of word DC in document d : 4 Note that we are computing a probability conditioned both on the target word DC and the document CS , because the documents</definiens>
			</definition>
			<definition id="10">
				<sentence>The behavior is identical to selecting the sense with the highest posterior probability , computed as C8 B4D7CYDCBNCSB5BP C8 CZ AL CZ B4DCBNCSB5 A1 ÆB4D7BNCMD7 CZ B4DCBNCSB5B5 C8 D8 C8 CZ AL CZ B4DCBNCSB5 A1 ÆB4D8BNCMD7 CZ B4DCBNCSB5B5 ( 6 ) where Æ is the Kronecker function and CMD7 CZ B4DCBNCSB5 is the classification of the CZ th classifier .</sentence>
				<definiendum id="0">Æ</definiendum>
				<definiendum id="1">CMD7 CZ B4DCBNCSB5</definiendum>
				<definiens id="0">the classification of the CZ th classifier</definiens>
			</definition>
			<definition id="11">
				<sentence>The data consists of contexts associated with a specific word to be sense tagged ( target word ) ; the context size varies from 1 sentence ( Spanish ) to 5 sentences ( English , Swedish ) .</sentence>
				<definiendum id="0">data</definiendum>
			</definition>
</paper>

		<paper id="1816">
			<definition id="0">
				<sentence>Obviously , T is a group with the operation of composition .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">a group with the operation of composition</definiens>
			</definition>
			<definition id="1">
				<sentence>Corollary 2.1 Ω ( Sprime ) ≤ Ω ( S ) +Ω ( SsquigglerightSprime ) Definition 2.5 The degree of structural destruction from S to Sprime , is defined by ρ ( SsquigglerightSprime ) = 1− Ω ( S prime ) Ω ( S ) +Ω ( SsquigglerightSprime ) ( 1 ) Property 2.1 0 ≤ ρ ( SsquigglerightSprime ) ≤ 1 Definition 2.6 Let S squiggleright S1 squiggleright ··· squiggleright Sn squiggleright ··· be a sequence of evolution , the sequence is called convergent if there exists a constant A s.t. 0 ≤ A ≤ 1 and limn→∞ρ ( SsquigglerightSn ) = A. It’s easy to see that a local evolution of the lexicon may not be an optimization even for a specific application .</sentence>
				<definiendum id="0">Sprime ) ≤ Ω ( S ) +Ω</definiendum>
				<definiens id="0">S prime ) Ω ( S ) +Ω ( SsquigglerightSprime ) ( 1 ) Property 2.1 0 ≤ ρ ( SsquigglerightSprime ) ≤ 1 Definition 2.6 Let S squiggleright S1 squiggleright ··· squiggleright Sn squiggleright ··· be a sequence of evolution , the sequence is called convergent if there exists a constant A s.t. 0 ≤ A ≤ 1 and limn→∞ρ ( SsquigglerightSn ) = A. It’s easy to see that a local evolution of the lexicon may not be an optimization even for a specific application</definiens>
			</definition>
			<definition id="2">
				<sentence>A more important work in WordNet is the construction of a well-structured concept network based on the hypernymy relation ( the main framework ) and other accessorial relations , such as , the opposite relation , the holonymy relation , entailment , cause , etc .</sentence>
				<definiendum id="0">relation</definiendum>
				<definiens id="0">the construction of a well-structured concept network based on the hypernymy</definiens>
			</definition>
			<definition id="3">
				<sentence>Definition 3.2 Let Σ be the set of all words , then Γ , the set of all concepts ( or SynSets ) in a WordNet-like lexicon , is a subset of 2Σ .</sentence>
				<definiendum id="0">set of all concepts</definiendum>
			</definition>
			<definition id="4">
				<sentence>The set of all SynSets containing w is denoted by ∆ ( w ) , in which each element is called a sense of w. Definition 3.3 Given a well-defined sentence S = w1w2 ···wn , WSD is the computable processing which tags wi a unique sense si = { wi , wi1 , ··· , wik } such that each derived combinatorial path is a well-defined sentence with the semantics of S. The Principle of Substitution provides a corpus-based empirical approach to test a SynSet well-defined or not .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">the computable processing which tags wi a unique sense si = { wi</definiens>
				<definiens id="1">a well-defined sentence with the semantics of S. The Principle of Substitution provides a corpus-based empirical approach to test a SynSet well-defined or not</definiens>
			</definition>
			<definition id="5">
				<sentence>The SynSet is the smallest unit in a WordNet-like lexicon , which is the underlying of the structural descriptions between the concepts .</sentence>
				<definiendum id="0">SynSet</definiendum>
				<definiendum id="1">WordNet-like lexicon</definiendum>
				<definiens id="0">the smallest unit in a</definiens>
			</definition>
			<definition id="6">
				<sentence>A Hidden Markov Model with two parameters will be adopted as the main statistical model for WSD , and the Statistical Decision Theory and Bayesian Analysis , which are good at analyzing the small samples , conducted as a comparison .</sentence>
				<definiendum id="0">Hidden Markov Model</definiendum>
				<definiens id="0">the main statistical model for WSD , and the Statistical Decision Theory and Bayesian Analysis , which are good at analyzing the small samples , conducted as a comparison</definiens>
			</definition>
			<definition id="7">
				<sentence>Definition 4.1 A labeled tree is a 5-tuple T = 〈N , Q , D , P , L〉 satisfying that : nance relation precedence relation [ ( x , y ) /∈ D ∧ ( y , x ) /∈ D ] ] ( x , z ) ∈ D ] → ( y , z ) ∈ P ] Definition 4.2 A hypernymy tree is a labeled tree , in which the label map is one-to-one .</sentence>
				<definiendum id="0">hypernymy tree</definiendum>
				<definiens id="0">a 5-tuple T = 〈N , Q , D , P , L〉 satisfying that : nance relation precedence relation [ ( x , y ) /∈ D ∧ ( y , x ) /∈ D ] ] ( x , z ) ∈ D ] → ( y</definiens>
			</definition>
			<definition id="8">
				<sentence>Let the offset of y is l , the similarity between x and y is : • If mn = 1 , S ( x , y ) def= 〈0 , |k −l|〉 • If mn negationslash= 1 , S ( x , y ) def= 〈m+n,0〉 Definition 4.5 Suppose that S ( x1 , y1 ) = 〈a1 , b1〉 and S ( x2 , y2 ) = 〈a2 , b2〉 , the comparison of similarities is defined as follows : • S ( x1 , y1 ) precedesequal S ( x2 , y2 ) ↔ b1 ≤ b2 • If a1 &lt; a2 , then S ( x1 , y1 ) ≺ S ( x2 , y2 ) • If a1 &gt; a2 , then S ( x2 , y2 ) ≺ S ( x1 , y1 ) Theorem 4.1 〈 { S ( x , y ) |x , y ∈ N } , precedesequal〉 is a totally ordered set .</sentence>
				<definiendum id="0">y</definiendum>
				<definiendum id="1">y1 ) precedesequal S</definiendum>
				<definiendum id="2">y1 ) ≺ S ( x2 , y2</definiendum>
				<definiendum id="3">x2 , y2 ) ≺ S</definiendum>
				<definiens id="0">x , y ) |x , y ∈ N } , precedesequal〉 is a totally ordered set</definiens>
			</definition>
			<definition id="9">
				<sentence>Otherwise , the disjointed union Cprime⊕Cprimeprime is the closed semantic constraint .</sentence>
				<definiendum id="0">disjointed union Cprime⊕Cprimeprime</definiendum>
				<definiens id="0">the closed semantic constraint</definiens>
			</definition>
			<definition id="10">
				<sentence>Definition 4.6 The induction of the closed semantic constraints of C , D ∈ Γ is defined by CintersectionsqD =    inf ( C , D ) if ∀x [ inf ( C , D ) precedesequal x ] succeeds in the substitution C ⊕D otherwise Definition 4.7 By Theorem 4.1 , the induction between C ⊕D and E ∈ Γ is defined by ( C ⊕D ) intersectionsqE = braceleftbigg ( C intersectionsqE ) ⊕D if S ( C , E ) precedesequal S ( D , E ) C ⊕ ( D intersectionsqE ) otherwise Theoretically , if C1⊕C2⊕···⊕Cn is the closed semantic constraint of the argument of C ∈ ΓV , then ∀i , ∀x [ Ci precedesequal x ] succeeds in the substitution .</sentence>
				<definiendum id="0">C1⊕C2⊕···⊕Cn</definiendum>
				<definiens id="0">The induction of the closed semantic constraints of C , D ∈ Γ is defined by CintersectionsqD =    inf ( C , D ) if ∀x [ inf ( C , D ) precedesequal x ] succeeds in the substitution C ⊕D otherwise Definition 4.7 By Theorem 4.1 , the induction between C ⊕D and E ∈ Γ is defined by ( C ⊕D ) intersectionsqE = braceleftbigg ( C intersectionsqE ) ⊕D if S ( C , E ) precedesequal S</definiens>
				<definiens id="1">the closed semantic constraint of the argument of C ∈ ΓV , then ∀i , ∀x [ Ci precedesequal x ] succeeds in the substitution</definiens>
			</definition>
			<definition id="11">
				<sentence>ΓN is structured by not only the hypernymy relation but also the closed semantic constraints .</sentence>
				<definiendum id="0">ΓN</definiendum>
				<definiens id="0">structured by not only the hypernymy relation but also the closed semantic constraints</definiens>
			</definition>
			<definition id="12">
				<sentence>1998 EuroWordNet : A Multilinugual Database with Lexical Semantic Networks .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
			</definition>
</paper>

		<paper id="1601">
			<definition id="0">
				<sentence>S-SSTC consists of two SSTCs that are related by a synchronization relation .</sentence>
				<definiendum id="0">S-SSTC</definiendum>
			</definition>
			<definition id="1">
				<sentence>G30G52G55G48 G53G55G48G56G48G51G57G44G57G4CG52G51G56 G52G49 G30G37G37 G46G44G51 G45G48 G49G52G58G51G47 G4CG51 G0BG30G48G4FGB6GFEG58G4EG0F G14G1CG1CG1AG0C G44G51G47 G0BG30G4CG4FG4CGFCG48G59G4CGFCG0F G15G13G13G14G0CG11 The SSTC is a general structure that can associate an arbitrary tree structure to string in a language as desired by the annotator to be the interpretation structure of the string , and more importantly is the facility to specify the correspondence between the string and the associated tree which can be nonprojective ( Boitet &amp; Zaharin , 1988 ) .</sentence>
				<definiendum id="0">SSTC</definiendum>
			</definition>
			<definition id="2">
				<sentence>Definitions 2 : An SSTC is a general structure , which is a string in a language associated with an arbitrary tree structure ; i.e. its interpretation structure , and the correspondence between the string and its associated tree , which can be non-projective ; i.e. SSTC is a triple ( st , tr , co ) , where st is a string in one language , tr is its associated representation tree structure and co is the correspondence between st and tr .</sentence>
				<definiendum id="0">SSTC</definiendum>
				<definiendum id="1">SSTC</definiendum>
				<definiendum id="2">st</definiendum>
				<definiens id="0">a string in a language associated with an arbitrary tree structure</definiens>
				<definiens id="1">a triple ( st , tr , co )</definiens>
				<definiens id="2">a string in one language</definiens>
			</definition>
			<definition id="3">
				<sentence>SNODE ( N ) : An interval of the substring in the string that corresponds to the node N in the tree .</sentence>
				<definiendum id="0">SNODE ( N )</definiendum>
				<definiens id="0">An interval of the substring in the string that corresponds to the node N in the tree</definiens>
			</definition>
			<definition id="4">
				<sentence>STREE ( N ) : An interval of the substring in the string that corresponds to the subtree having the node N as root .</sentence>
				<definiendum id="0">STREE</definiendum>
				<definiens id="0">An interval of the substring in the string that corresponds to the subtree having the node N as root</definiens>
			</definition>
			<definition id="5">
				<sentence>S-TAG is a variant of Tree Adjoining Grammar ( TAG ) introduced by ( Shieber &amp; Schabes,1990 ) to characterize correspondences between tree adjoining languages .</sentence>
				<definiendum id="0">S-TAG</definiendum>
				<definiens id="0">a variant of Tree Adjoining Grammar ( TAG ) introduced by ( Shieber &amp; Schabes,1990 ) to characterize correspondences between tree adjoining languages</definiens>
			</definition>
			<definition id="6">
				<sentence>A S-SSTC consists of a pair of SSTCs with an additional synchronization relation between them .</sentence>
				<definiendum id="0">S-SSTC</definiendum>
			</definition>
			<definition id="7">
				<sentence>The use of S-SSTC is motivated by the desire to describe not only the correspondence between the text and its representation structure in one language ( i.e. SSTC ) but also the correspondence between two languages ( synchronous correspondence ) .</sentence>
				<definiendum id="0">S-SSTC</definiendum>
				<definiens id="0">motivated by the desire to describe not only the correspondence between the text and its representation structure in one language ( i.e. SSTC ) but also the correspondence between two languages ( synchronous correspondence )</definiens>
			</definition>
			<definition id="8">
				<sentence>Definitions : Let each of S and T be SSTC which consists of a triple ( st , tr , co ) , where st is a string in one language , tr is its associated representation tree structure and co is the correspondence between st and tr , as defined in Section 2.1 .</sentence>
				<definiendum id="0">SSTC</definiendum>
				<definiendum id="1">st</definiendum>
				<definiens id="0">a string in one language</definiens>
			</definition>
			<definition id="9">
				<sentence>A synchronous SSTC Ssyn is defined as a triple ( S , T , ( , ) ϕ S T ) , where ( , ) ϕ S T is a set of links defining the synchronization correspondence between S and T at different internal levels of the two SSTC structures .</sentence>
				<definiendum id="0">synchronous SSTC Ssyn</definiendum>
				<definiens id="0">a triple ( S , T , ( , ) ϕ S T ) , where ( , ) ϕ S T is a set of links defining the synchronization correspondence between S and T at different internal levels of the two SSTC structures</definiens>
			</definition>
			<definition id="10">
				<sentence>A link G41∈ ( , ) ϕ S T can be either of type sn G41 or st G41 which defines the synchronous correspondences between nodes of tr in S , and nodes of tr in T. G83 sn G41 records the synchronous correspondences at level of nodes in S and T ( i.e. lexical correspondences between specified nodes ) , and 3 for a comprehensive overview about EBMT , see Somers ( 1999 ) Many-to-one mapping Elimination of dominance Inversion of dominance Figure 3 : Kinds of relations between different languages , which are not isomorphic .</sentence>
				<definiendum id="0">link G41∈</definiendum>
				<definiens id="0">defines the synchronous correspondences between nodes of tr in S , and nodes of tr in T. G83 sn G41 records the synchronous correspondences at level of nodes in S and T ( i.e. lexical correspondences between specified nodes )</definiens>
			</definition>
			<definition id="11">
				<sentence>G83 st G41 records the synchronous correspondences at level of subtrees in S and T ( i.e. structural correspondences between subtrees ) , and normally st G41 = ( Y 1 , Y 2 ) , where Y 1 and Y 2 are sequences of STREE correspondences in co , which may be empty .</sentence>
				<definiendum id="0">G41</definiendum>
				<definiens id="0">records the synchronous correspondences at level of subtrees in S and T ( i.e. structural correspondences between subtrees</definiens>
				<definiens id="1">sequences of STREE correspondences in co</definiens>
			</definition>
			<definition id="12">
				<sentence>sn G41 is a pair ( s sn G41 , t sn G41 ) , where s sn G41 is from the first SSTC and t sn G41 is from the second SSTC .</sentence>
				<definiendum id="0">sn G41</definiendum>
				<definiens id="0">a pair ( s sn G41 , t sn G41</definiens>
			</definition>
			<definition id="13">
				<sentence>st G41 is a pair ( s st G41 , t st G41 ) , where s st G41 from the first SSTC and t st G41 from the second SSTC as defined below : G83 s st G41 = { i 1 _j 1 +…+ i k _j k +…+ i p _j p } | i k _j k ∈Y : STREE correspondence in co of the first SSTC or ( i k _j k ) = ( i k _j k ) ( i u _j v ) | i u ≥i k ∧ j v≤ j h : i.e. ( i u _j v ) ⊆ ( i k _j k ) which corresponds to an incomplete subtree .</sentence>
				<definiendum id="0">G41</definiendum>
				<definiens id="0">a pair ( s st G41 , t st G41</definiens>
				<definiens id="1">i k _j k +…+ i p _j p } | i k _j k ∈Y : STREE correspondence in co of the first SSTC or ( i k _j k ) = ( i k _j k ) ( i u _j v ) | i u ≥i k ∧ j v≤ j h : i.e. ( i u _j v ) ⊆ ( i k _j k ) which corresponds to an incomplete subtree</definiens>
			</definition>
			<definition id="14">
				<sentence>Figure 7 exemplifies a case where the number of nodes in the synchronized SSTCs or subSSTCs is the same , but they exhibit different structures .</sentence>
				<definiendum id="0">subSSTCs</definiendum>
				<definiens id="0">the same , but they exhibit different structures</definiens>
			</definition>
			<definition id="15">
				<sentence>Synchronous correspondence ( 2-3+4-6,3-5 ) a vu [ v ] ( 3-4+5-6/0-1+2-4+5-6 ) Pierre [ n ] ( 0-1/0-1 ) l’ [ n ] ( 2-3/2-3 ) 0 Pierre 1 ne 2 l’ 3 a 4 pas 5 vu 6 Tree String has seen [ v ] ( 1-2+3-4/0-2+3-5 ) Peter [ n ] ( 0-1/0-1 ) it [ n ] ( 4-5/4-5 ) 0 Peter 1 has 2 not 3 seen 4 it 5 Tree String ne pas [ neg ] ( 1-2+4-5/0-6 ) not [ neg ] ( 2-3/0-5 ) Figure 6 : Cliticized sentence : the French sentence “Pierre ne l ‘a pas vu” and its corresponding English sentence “Peter has not seen it” .</sentence>
				<definiendum id="0">Cliticized sentence</definiendum>
				<definiens id="0">the French sentence “Pierre ne l ‘a pas vu” and its corresponding English sentence “Peter has not seen it”</definiens>
			</definition>
			<definition id="16">
				<sentence>For instance , when building translation units in EBMT approaches ( Richardson et al. , 2001 ) , ( Aramaki , 2001 ) , ( AlAdhaileh &amp; Tang , 1999 ) , ( Sato &amp; Nagao , 1990 ) , ( Sato , 1991 ) , ( Sadler &amp; Vendelmans , 1990 ) , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences ( lexical and structural correspondences ) for transferrules’ extraction from parallel parsed corpus ( Menezes &amp; Richardson , 2001 ) , ( Watanabe et al. , Tree String Tree String Figure 9 : Partial subtree/s correspondence : the German sentence “Er beschenkte Hans reichlich” and its corresponding English sentence “He gave John an expensive present” ; i.e. the use of ( - ) operation to calculate the Y : STREE interval .</sentence>
				<definiendum id="0">S-SSTC</definiendum>
				<definiens id="0">Watanabe et al. , Tree String Tree String Figure 9 : Partial subtree/s correspondence : the German sentence “Er beschenkte Hans reichlich” and its corresponding English sentence “He gave John an expensive present”</definiens>
			</definition>
</paper>

		<paper id="1108">
			<definition id="0">
				<sentence>WordNet : An on-line lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An on-line lexical database</definiens>
			</definition>
			<definition id="1">
				<sentence>Learnability and Cognition : The Acquisition of Argument Structure .</sentence>
				<definiendum id="0">Learnability</definiendum>
				<definiendum id="1">Cognition</definiendum>
			</definition>
</paper>

		<paper id="1409">
</paper>

		<paper id="0814">
			<definition id="0">
				<sentence>The word-experts consist of different trained subcomponents which make use of different knowledge : ( i ) a classifier trained on the local context of the ambiguous focus word , ( ii ) a learner trained on keywords , ( iii ) a classifier trained on both of the previous information sources , ( iv ) a baseline classifier always providing the most frequent sense in the sense lexicon and ( v ) four voting strategies which vote on the outputs of the previously mentioned classifiers .</sentence>
				<definiendum id="0">word-experts</definiendum>
				<definiens id="0">consist of different trained subcomponents which make use of different knowledge : ( i ) a classifier trained on the local context of the ambiguous focus word , ( ii ) a learner trained on keywords , ( iii ) a classifier trained on both of the previous information sources , ( iv ) a baseline classifier always providing the most frequent sense in the sense lexicon</definiens>
			</definition>
			<definition id="1">
				<sentence>ysemy can be described as the number of senses of a word-POS combination ; entropy is an estimation of the information chaos in the frequency distribution of the senses .</sentence>
				<definiendum id="0">entropy</definiendum>
				<definiens id="0">the number of senses of a word-POS combination ;</definiens>
			</definition>
			<definition id="2">
				<sentence>The psycho-biology of language : an introduction to dynamic philology .</sentence>
				<definiendum id="0">psycho-biology of language</definiendum>
				<definiens id="0">an introduction to dynamic philology</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>The most obvious is as a means to build a parallel corpus from a set of multilingual documents that contains some translation pairs .</sentence>
				<definiendum id="0">most obvious</definiendum>
				<definiens id="0">a means to build a parallel corpus from a set of multilingual documents that contains some translation pairs</definiens>
			</definition>
			<definition id="1">
				<sentence>Speci cally , the score I use is : tsim = log Pr ( two-word links in best matching ) log Pr ( all links in best matching ) ( 1 ) This score is an example of Lin’s ( 1998 ) mathematical de nition of similarity , which is motivated by information theory : sim ( X ; Y ) = log Pr ( common ( X ; Y ) ) log Pr ( description ( X ; Y ) ) ( 2 ) where X and Y are any objects generated by a probabilistic model.2 In this research , I seek to show how multiple linguistic resources can be exploited together to recognize translation .</sentence>
				<definiendum id="0">similarity</definiendum>
				<definiens id="0">motivated by information theory : sim ( X ; Y ) = log Pr ( common ( X ; Y ) ) log Pr ( description</definiens>
			</definition>
			<definition id="2">
				<sentence>If Equation ( 3 ) is applied to pairs of documents in the same language , with a \translation lexicon '' de ned by the identity relation , then tsim is a variant of resemblance ( r ) , as dened by Broder et al. ( 1997 ) for the problem of monolingual duplicate detection : r ( X ; Y ) = jS ( X ) \S ( Y ) jjS ( X ) [ S ( Y ) j ( 4 ) where S ( Z ) is a shingling of the words in Z ; a shingling is the set of uniquen-gram types in the text for some xed n ( Damashek , 1995 ) .</sentence>
				<definiendum id="0">tsim</definiendum>
				<definiendum id="1">shingling</definiendum>
				<definiens id="0">a shingling of the words in Z</definiens>
			</definition>
			<definition id="3">
				<sentence>The STRAND system ( Resnik , 1999 ) , for example , uses structural markup information from the pages , without looking at their content , to attempt to align them .</sentence>
				<definiendum id="0">STRAND system</definiendum>
			</definition>
			<definition id="4">
				<sentence>An English-French dictionary ( a total of 34,808 entries , 4,021 of which are not one-toone ) .9 It contains morphological variants but does not include character accents .</sentence>
				<definiendum id="0">English-French dictionary</definiendum>
			</definition>
			<definition id="5">
				<sentence>A word-to-word translation model ( Melamed , 2000 ) trained on a verse-aligned Bible using MWBM ( 15,548 verses , averaging 25.5 English words , 23.4 French words after tokenization ) .</sentence>
				<definiendum id="0">word-to-word translation model</definiendum>
				<definiens id="0">French words after tokenization )</definiens>
			</definition>
			<definition id="6">
				<sentence>N is the number of examples for which judgement-comparison was possible in each case ( human judges were sometimes undecided ; those cases are ignored in computing ) .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
</paper>

		<paper id="1818">
			<definition id="0">
				<sentence>Recognizing simple and non-recursive base phrases is an important subtask for many natural language processing applications , such as information retrieval .</sentence>
				<definiendum id="0">non-recursive base phrases</definiendum>
				<definiens id="0">an important subtask for many natural language processing applications , such as information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>A major head is the ‘semantic’ head ( s-head ) for the root of the chunk headed by it .</sentence>
				<definiendum id="0">major head</definiendum>
				<definiens id="0">the ‘semantic’ head ( s-head ) for the root of the chunk headed by it</definiens>
			</definition>
			<definition id="2">
				<sentence>In this paper , a Chinese base phrase consists of a single content word surrounded by a cluster of function words .</sentence>
				<definiendum id="0">Chinese base phrase</definiendum>
				<definiens id="0">consists of a single content word surrounded by a cluster of function words</definiens>
			</definition>
			<definition id="3">
				<sentence>In most cases , the type accords with the head’s syntactical information , for example , when the head is a noun , the phrase is a noun phrase .</sentence>
				<definiendum id="0">syntactical information</definiendum>
				<definiendum id="1">phrase</definiendum>
				<definiens id="0">a noun phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>∈ The indicates the position of the word in a base phrase as shown below : i r ‘L’ : the left boundary , ‘R’ : the right boundary , ‘I’ : the middle position , ‘O’ : outside any base phrases , ‘LR’ : the left and right boundary .</sentence>
				<definiendum id="0">‘I’</definiendum>
				<definiens id="0">the right boundary ,</definiens>
				<definiens id="1">the middle position</definiens>
				<definiens id="2">the left and right boundary</definiens>
			</definition>
			<definition id="5">
				<sentence>Precision for &lt; &gt; mn cr Recall For &gt; &lt; mn cr np vp sp tp ap bp dp mp mbar 92.27 % 90.40 % 75.15 % 82.87 % 93.52 % 92.60 % 97.56 % 93.90 % 74.15 % 93.61 % 89.65 % 48.41 % 71.62 % 91.89 % 76.38 % 97.63 % 92.38 % 72.26 % Total1 91.90 % 91.65 % 97.85 % 98.41 % Total2 93.83 % 93.83 % ( 3 ) Boundaries absence : For example , in the sentence of “ { vp 包括 /v } { np 内服 /n } 、 /、 { np 外用 /n 药 物 /n } 以及 /c { vp 放血 /v } ” , “ { np 外 用 /n 药物 /n } ” should be “ { np 外用 /n } { np 药物 /n } ” .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">/n 药 物 /n } 以及 /c { vp 放血 /v } ” , “ { np 外 用 /n 药物 /n } ” should be “ { np 外用 /n } { np 药物 /n } ”</definiens>
			</definition>
</paper>

		<paper id="1040">
</paper>

		<paper id="0311">
			<definition id="0">
				<sentence>Information Extraction ( IE ) , defined as the activity to extract structured knowledge from unstructured text sources , offers new opportunities for the exploitation of biological information contained in the vast amounts of scientific literature .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
			</definition>
			<definition id="1">
				<sentence>TheSITE/FUNCTIONslot is filled with widely recognizable descriptions that indicate that this residue is important for the structure’s activation ( e.g. active-site ) or functional characteristics ( e.g. catalytic ) .</sentence>
				<definiendum id="0">TheSITE/FUNCTIONslot</definiendum>
				<definiens id="0">important for the structure’s activation ( e.g. active-site ) or functional characteristics ( e.g. catalytic )</definiens>
			</definition>
			<definition id="2">
				<sentence>The PASTA system is a pipeline of processing components that perform the following major tasks : text preprocessing , terminological processing , syntactic and semantic analysis , discourse interpretation , and template extraction .</sentence>
				<definiendum id="0">PASTA system</definiendum>
				<definiens id="0">text preprocessing , terminological processing , syntactic and semantic analysis , discourse interpretation</definiens>
			</definition>
			<definition id="3">
				<sentence>The domain model consists of a concept hierarchy ( ontology ) together with inheritable properties and inference rules for the concepts .</sentence>
				<definiendum id="0">domain model</definiendum>
			</definition>
			<definition id="4">
				<sentence>source=start or via the PASTA project home page at http : //www.dcs.shef.ac.uk/nlp/pasta/ 6TRESTLE : Text Retrieval Extraction and Summarisation Technologies for large Enterprises PASTA IE NE Tagged Texts Templates Indexer Entity/Template Indices Dynamic Page Generation Web Server Medline Information Seeking User Figure 2 : The PASTAWeb Architecture Access Frame Header Frame Document Index Frame Template Flags Template Flag ( multiple templates ) ( single template ) Colur Index to Tagged Entities Template in Tabular Format Tagged Text Frame Figure 3 : The PASTAWeb Interface Initially , MEDLINE abstracts are fed through the PASTA IE system which produces two kinds of output : ( i ) texts annotated with SGML tags describing term class information for protein , residues , species , regions , and ( ii ) templates which are used as the main stores of information about residues including relational information between proteins and residues and between proteins and species .</sentence>
				<definiendum id="0">Summarisation Technologies</definiendum>
				<definiens id="0">The PASTAWeb Interface Initially , MEDLINE abstracts are fed through the PASTA IE system which produces two kinds of output : ( i ) texts annotated with SGML tags describing term class information for protein , residues , species , regions</definiens>
			</definition>
			<definition id="5">
				<sentence>Just below the “Header Frame” is the “Document Index Frame” which initially serves to display the automatically generated indices together with document information .</sentence>
				<definiendum id="0">“Header Frame”</definiendum>
				<definiens id="0">the “Document Index Frame” which initially serves to display the automatically generated indices together with document information</definiens>
			</definition>
			<definition id="6">
				<sentence>Unfortunately , although the type of object-oriented template produced by PASTA ( Fig 1 ) is an efficient data structure for storing complex information , it is not suitable for displaying to end-users .</sentence>
				<definiendum id="0">PASTA</definiendum>
				<definiens id="0">an efficient data structure for storing complex information</definiens>
			</definition>
			<definition id="7">
				<sentence>Nevertheless , PASTAWeb offers the core technology for the development of a fully automated IE system whose input can be based on automated updates ( “autoalerts” ) from MEDLINE without human intervention .</sentence>
				<definiendum id="0">PASTAWeb</definiendum>
				<definiens id="0">offers the core technology for the development of a fully automated IE system whose input can be based on automated updates ( “autoalerts” ) from MEDLINE without human intervention</definiens>
			</definition>
</paper>

		<paper id="0700">
</paper>

		<paper id="0500">
</paper>

		<paper id="0713">
			<definition id="0">
				<sentence>TrIM is an instant messaging environment in which participants are able to interact by reading and typing in their own preferred languages .</sentence>
				<definiendum id="0">TrIM</definiendum>
				<definiens id="0">an instant messaging environment in which participants are able to interact by reading and typing in their own preferred languages</definiens>
			</definition>
</paper>

		<paper id="2021">
</paper>

		<paper id="2020">
</paper>

		<paper id="0507">
			<definition id="0">
				<sentence>QARAB : A Question Answering System to Support the Arabic Language Bassam Hammo Hani Abu-Salem Steven Lytinen DePaul University School of Computer Science , Telecommunications and Information Systems 243 S. Wabash Avenue , Chicago IL 60604 bhammo @ condor.depaul.edu habusalem @ cti.depaul.edu lytinen @ cs.depaul.edu Martha Evens Illinois Institute of Technology Computer Science Department 10 West 31 st Street , Chicago , IL 60616 evens @ iit.edu We describe the design and implementation of a question answering ( QA ) system called QARAB .</sentence>
				<definiendum id="0">QARAB</definiendum>
				<definiens id="0">A Question Answering System to Support the Arabic Language Bassam Hammo Hani Abu-Salem Steven Lytinen DePaul University School of Computer Science , Telecommunications and Information Systems 243 S. Wabash Avenue , Chicago IL 60604 bhammo @ condor.depaul.edu habusalem @ cti.depaul.edu lytinen @ cs.depaul.edu Martha Evens Illinois Institute of Technology Computer Science Department 10 West 31 st Street , Chicago , IL 60616 evens @ iit.edu We describe the design and implementation of a question answering</definiens>
			</definition>
			<definition id="1">
				<sentence>We are tackling this problem for Arabic using traditional Information Retrieval ( IR ) techniques coupled with a sophisticated Natural Language Processing ( NLP ) approach .</sentence>
				<definiendum id="0">IR</definiendum>
				<definiens id="0">techniques coupled with a sophisticated Natural Language Processing ( NLP ) approach</definiens>
			</definition>
			<definition id="2">
				<sentence>QARAB is the result of coupling traditional Information Retrieval ( IR ) techniques with a sophisticated Natural Language Processing ( NLP ) approach .</sentence>
				<definiendum id="0">QARAB</definiendum>
				<definiens id="0">the result of coupling traditional Information Retrieval ( IR ) techniques with a sophisticated Natural Language Processing ( NLP ) approach</definiens>
			</definition>
			<definition id="3">
				<sentence>The MURAX system [ Kupiec , 1993 ] used robust linguistic methods to answer closed-class natural language questions .</sentence>
				<definiendum id="0">MURAX system</definiendum>
			</definition>
			<definition id="4">
				<sentence>Another system , with a different approach , is the FAQFinder system [ Burke et al. , 1997 ] , which attempted to solve the question-answering problem using a database of question-answer pairs built from existing frequently asked question ( FAQ ) files .</sentence>
				<definiendum id="0">FAQ</definiendum>
				<definiens id="0">the FAQFinder system [ Burke et al. , 1997 ] , which attempted to solve the question-answering problem using a database of question-answer pairs built from existing frequently asked question</definiens>
			</definition>
			<definition id="5">
				<sentence>The recognition process occurs in multiple stages in which a list of patterns and heuristics may be applied to mark the proper noun .</sentence>
				<definiendum id="0">recognition process</definiendum>
				<definiens id="0">occurs in multiple stages in which a list of patterns and heuristics may be applied to mark the proper noun</definiens>
			</definition>
			<definition id="6">
				<sentence>Question Types Processed by the QARAB System Query Starting with Query Type ﻦﻣ Who , Whose Person ﻰﺘﻣ When Date , Time ﺎﻣ ،ﻣاذﺎ What , Which Organization , Product , Event ﻦﻳا Where Location ( natural , political ) ﻢآ How Much , How Many Number , Quantity There are two other types of question particles , namely ﻒﻴآ and اذﺎﻤﻟ ( How and Why ) .</sentence>
				<definiendum id="0">Question Types</definiendum>
				<definiens id="0">Processed by the QARAB System Query Starting with Query Type ﻦﻣ Who , Whose Person ﻰﺘﻣ When Date , Time ﺎﻣ ،ﻣاذﺎ What , Which Organization , Product , Event ﻦﻳا Where Location ( natural , political ) ﻢآ How Much</definiens>
			</definition>
			<definition id="7">
				<sentence>The input to the Answer Generator is the “bag of words” and the paragraphs extracted from the top ranked relevant documents .</sentence>
				<definiendum id="0">Answer Generator</definiendum>
				<definiens id="0">the “bag of words” and the paragraphs extracted from the top ranked relevant documents</definiens>
			</definition>
</paper>

		<paper id="0312">
</paper>

		<paper id="1704">
			<definition id="0">
				<sentence>Discourse markers are words ( predominantly conjunctions ) that signal the kind of semantic or rhetorical relationship between adjacent spans of text .</sentence>
				<definiendum id="0">Discourse markers</definiendum>
				<definiens id="0">words ( predominantly conjunctions ) that signal the kind of semantic or rhetorical relationship between adjacent spans of text</definiens>
			</definition>
			<definition id="1">
				<sentence>Thus , DiMLex contributes to initial discourse marker disambiguation .</sentence>
				<definiendum id="0">DiMLex</definiendum>
				<definiens id="0">contributes to initial discourse marker disambiguation</definiens>
			</definition>
</paper>

		<paper id="0816">
</paper>

		<paper id="0112">
			<definition id="0">
				<sentence>R &amp; D work in computational linguistics and language technology in Estonia is being carried out , in addition to UT , in the Institute of the Estonian Language ( IEL is a research institution ) and the Institute of Cybernetics of Tallinn Technical University .</sentence>
				<definiendum id="0">Estonian Language ( IEL</definiendum>
				<definiens id="0">a research institution</definiens>
			</definition>
			<definition id="1">
				<sentence>UT computational linguists have participated in a number of international projects , e.g. GLOSSER , MULTEXT-EAST , TELRI-I , TELRI-II , CONCEDE , EuroWordNet , BABEL , to name some , and carried out numerous projects commissioned by the Estonian Science Foundation and the Estonian Informatics Centre .</sentence>
				<definiendum id="0">e.g. GLOSSER</definiendum>
			</definition>
			<definition id="2">
				<sentence>As demonstrated by a questionnaire carried out in March 1999 in 60 European universities where CL is being taught ( de Smedt et al. , 1999 ) , three options are basically used in teaching CL and language technology : a1 A minor in philology ( dominating ) a1 A minor in Computer Science a1 An independent subject .</sentence>
				<definiendum id="0">CL</definiendum>
			</definition>
</paper>

		<paper id="2005">
</paper>

		<paper id="1201">
			<definition id="0">
				<sentence>The language data inside the &lt; cesDoc &gt; tags can be marked up simply with a paragraph tag &lt; p &gt; ( Figure 2 ) or they can be more elaborately marked up with tags of semantic value ( e.g. , date , number , measure , name , term , time , foreign word ) and formatting value ( e.g. , figure , table , p , sp , div , caption ) ( Figure 3 ) .</sentence>
				<definiendum id="0">language data</definiendum>
				<definiens id="0">tags of semantic value ( e.g. , date , number , measure , name , term , time , foreign word ) and formatting value ( e.g. , figure , table , p , sp , div</definiens>
			</definition>
</paper>

		<paper id="1010">
</paper>

		<paper id="1904">
			<definition id="0">
				<sentence>A European alternative to SGML is the ODA ( Office Document Architecture ) that is also a standard [ ISO 8613 ] .</sentence>
				<definiendum id="0">European alternative to SGML</definiendum>
				<definiens id="0">the ODA ( Office Document Architecture ) that is also a standard</definiens>
			</definition>
			<definition id="1">
				<sentence>The regular language R L , which generates a set of RTCSs , can be described by regular expressions as follows : * { | ( ) , , , } R R L xxaya aa yLε==+∈Σ∈ % % ( 1 ) where Σ denotes a finite set of symbols , i.e. TC-pairs in this paper , and a are symbols in a % Σ , in which denotes a TC-pair consisting of a start or empty tag and a content , notated as a ( , ) ii cat= , and denotes a TC-pair consisting of an end tag corresponding to a ’s and a content , notated as a % ( , at ) ij c= % % , and ε denotes a null and stands for that is a TC-pair with an empty tag or is omitted .</sentence>
				<definiendum id="0">regular language R L</definiendum>
				<definiendum id="1">ε</definiendum>
				<definiens id="0">generates a set of RTCSs , can be described by regular expressions as follows : * { | ( ) , , , } R R L xxaya</definiens>
				<definiens id="1">a finite set of symbols</definiens>
				<definiens id="2">a TC-pair consisting of a start or empty tag and a content , notated as a ( , ) ii cat= , and denotes a TC-pair consisting of an end tag corresponding to a ’s and a content</definiens>
			</definition>
			<definition id="2">
				<sentence>A single empty tag can be regarded as an elementary RTCS .</sentence>
				<definiendum id="0">single empty tag</definiendum>
			</definition>
			<definition id="3">
				<sentence>For each two MPTs and T , we measure their similarity as follows : 1 T 2 ( 2 ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) 12 12 12 12 12 0 , if 1 , if , and , both and are single-vertex trees 1 , , elsewise MPT nnsubMPT root T root T root T root T Sim T T TT Sim T Tδδ − ≠  =  =    +− ⋅  where returns the root tag of an MPT , ( ) root n δ denotes a relational weight of a parent to its children at level , and is a function of estimating the similarity between the two MPTs based on their sub-trees’ similarities , which is defined as follows : n ( ) sub MPT Sim − 12 , , 1 ( , ) max ( , ( ) A T A sub MPT MPT A k A k g kB T Sim T T Sim T g T T − = = ∑ ( 3 ) where is one of the two MPTs and T such that it subsums fewer sub-trees , A T 1 T 2 B T is another one , and g denotes a one-to-one function from to A T B T .</sentence>
				<definiendum id="0">) ( ) ( ) ( ) ( ) ( )</definiendum>
			</definition>
			<definition id="4">
				<sentence>Conclusion List is an efficient way to represent information .</sentence>
				<definiendum id="0">Conclusion List</definiendum>
				<definiens id="0">an efficient way to represent information</definiens>
			</definition>
</paper>

		<paper id="0804">
			<definition id="0">
				<sentence>Predicative forms include verbs , but also prepositions which have a heavy semantic weight by themselves .</sentence>
				<definiendum id="0">Predicative forms</definiendum>
				<definiens id="0">include verbs , but also prepositions which have a heavy semantic weight by themselves</definiens>
			</definition>
			<definition id="1">
				<sentence>Adjunction : flat with terrace / steak with French fries / tea with milk , Exclusion : they all came except Paul .</sentence>
				<definiendum id="0">Adjunction</definiendum>
				<definiens id="0">they all came except Paul</definiens>
			</definition>
			<definition id="2">
				<sentence>Senses are described at two levels : ( 1 ) by means of a thematic grid characterizing the ‘standard’ function of each argument using the 21 thematic role system we have defined and , mainly ( 2 ) by means of the Lexical Conceptual Structure ( LCS ) ( Jackendoff 90 , 97 ) , which seems to be sufficiently expressive for that purpose .</sentence>
				<definiendum id="0">Lexical Conceptual Structure</definiendum>
				<definiens id="0">seems to be sufficiently expressive for that purpose</definiens>
			</definition>
			<definition id="3">
				<sentence>Same for La guerre avec l’Allemagne ( the war with Germany ) , where avec characterizes an opposition ( contre ( against ) is more usual ) , due to the semantics of war , a use that needs some interpretation ( there are a few such situations with aggression verbs , where semantic composition is necessary to get the meaning of the expression ) .</sentence>
				<definiendum id="0">guerre avec l’Allemagne</definiendum>
				<definiendum id="1">avec</definiendum>
			</definition>
</paper>

		<paper id="0226">
			<definition id="0">
				<sentence>Due to the rapid progress of speech and language processing technologies ( Cole et al. , 1998 ; Juang and Furui , 2000 ) , ever-increasing computing power , and vast quantity of social requirements , spoken dialogue systems ( SDSs ) , which promise to provide natural and ubiquitous access to online information and service , have become the focus of many research groups ( both academic and industrial ) with many projects sponsored by EU , US ( D ) ARPA and others in the past few years ( Zue and Glass , 2000 ; McTear , 2002 ; Xu , 2001 ) .</sentence>
				<definiendum id="0">spoken dialogue systems</definiendum>
				<definiens id="0">both academic and industrial ) with many projects sponsored by EU</definiens>
			</definition>
			<definition id="1">
				<sentence>Plan-based dialogue model explains why agents act in dialogues , but at the expense of complex representation and reasoning .</sentence>
				<definiendum id="0">Plan-based dialogue model</definiendum>
				<definiens id="0">explains why agents act in dialogues , but at the expense of complex representation and reasoning</definiens>
			</definition>
			<definition id="2">
				<sentence>4 To link dialogue acts to utterances , three problems 5 must be addressed at the same time : AF Dialogue act classification scheme and its reliability in coding corpus , ( Carletta et al. , 1997 ; Allen and Core , 1997 ; Traum , 1999 ) ; AF Choice of features/cues that can support automatic dialogue act identification , including lexical , syntactic , prosodic , collocational , and discourse cues ; AF A model that correlates dialogue acts with those features .</sentence>
				<definiendum id="0">AF Choice</definiendum>
				<definiendum id="1">AF A model</definiendum>
				<definiens id="0">of features/cues that can support automatic dialogue act identification , including lexical , syntactic , prosodic , collocational , and discourse cues ;</definiens>
			</definition>
			<definition id="3">
				<sentence>So we choose a higher level 4 Following Jurafsky ( 2002 ) , we will adopt the term dialogue act , which captures the illocutionary force or commucative function of speech act .</sentence>
				<definiendum id="0">dialogue act</definiendum>
				<definiens id="0">captures the illocutionary force or commucative function of speech act</definiens>
			</definition>
			<definition id="4">
				<sentence>Against the above gap and its causes we propose a generic dialogue model ( GDM ) for task-oriented dialogues , which consists of five ranks of discourse units and three levels of dialogue dynamics .</sentence>
				<definiendum id="0">GDM</definiendum>
			</definition>
			<definition id="5">
				<sentence>Meso-dynamics explains utterance-to-utterance moves within one group which present recurrent interaction patterns .</sentence>
				<definiendum id="0">Meso-dynamics</definiendum>
				<definiens id="0">explains utterance-to-utterance moves within one group which present recurrent interaction patterns</definiens>
			</definition>
			<definition id="6">
				<sentence>Macro-dynamics describes inter-group moves , which may take place intra-transactionally within one subtask or inter-transactionally between subtasks .</sentence>
				<definiendum id="0">Macro-dynamics</definiendum>
				<definiens id="0">describes inter-group moves , which may take place intra-transactionally within one subtask or inter-transactionally between subtasks</definiens>
			</definition>
			<definition id="7">
				<sentence>Turn is a natural unit that appears in dialogues , but is it an basic unit ?</sentence>
				<definiendum id="0">Turn</definiendum>
			</definition>
			<definition id="8">
				<sentence>From the view of GDM , the strategies a dialogue agent may choose can also be classified into three levels , i.e. , Micro-level strategies how to realize information structure , anaphora , ellipsis , and others , in utterances , Meso-level strategies what to say regarding current group status , so as to complete ongoing group more friendly , Macro-level strategies how to choose discourse topic regarding current task status , so as to complete the underlying task more efficiently .</sentence>
				<definiendum id="0">Micro-level</definiendum>
				<definiens id="0">strategies how to realize information structure , anaphora , ellipsis , and others , in utterances , Meso-level strategies what to say regarding current group status , so as to complete ongoing group more friendly , Macro-level strategies how to choose discourse topic regarding current task status</definiens>
			</definition>
			<definition id="9">
				<sentence>To segment a dialogue into groups is first to determine the beginning of a group , i.e. , to determine if an utterance is an initiative or not .</sentence>
				<definiendum id="0">utterance</definiendum>
				<definiens id="0">determine the beginning of a group</definiens>
			</definition>
			<definition id="10">
				<sentence>8 C3 BPB4C8B4BTB5 A0C8B4BXB5B5BPB4BD A0C8B4BXB5B5 , where C8B4BTB5 is the proportion of times that the coders agree and C8B4BXB5 is the proportion of times that one would expect them to agree by chance .</sentence>
				<definiendum id="0">C8B4BTB5</definiendum>
				<definiendum id="1">C8B4BXB5</definiendum>
				<definiens id="0">the proportion of times that the coders agree and</definiens>
				<definiens id="1">the proportion of times that one would expect them to agree by chance</definiens>
			</definition>
			<definition id="11">
				<sentence>Collagen : A collaboration manager for software interface agents .</sentence>
				<definiendum id="0">Collagen</definiendum>
			</definition>
</paper>

		<paper id="1407">
			<definition id="0">
				<sentence>For instance , in an example shown in Figure 2 , # LDN ( trigram ) =3 , # RDN ( trigram ) =2 LN ( N , k ) and RN ( N , k ) : The general functions that take into account the number of occurrences of each noun bigram like [ LNi N ] and [ N RNj ] are defined as follows .</sentence>
				<definiendum id="0">RN</definiendum>
				<definiendum id="1">bigram</definiendum>
				<definiens id="0">The general functions that take into account the number of occurrences of each noun</definiens>
			</definition>
			<definition id="1">
				<sentence>However the original definition of C-value can not score a single-noun because the important part of the definition C-value is : ) c ( a ) t ( a ) -1 ) ( n ( a ) -length ( a ) ( value ( a ) -C = -- ( 5 ) where a is compound noun , length ( a ) is the number of single-nouns which make up a , n ( a ) is the total frequency of occurrence of a on the corpus , t ( a ) is the frequency of occurrence of a in longer candidate terms , and c ( a ) is the number of those candidate terms .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">the number of single-nouns which make up a</definiens>
				<definiens id="1">the frequency of occurrence of a in longer candidate terms</definiens>
				<definiens id="2">the number of those candidate terms</definiens>
			</definition>
			<definition id="2">
				<sentence>Clearly , GM prefers longer terms .</sentence>
				<definiendum id="0">GM</definiendum>
				<definiens id="0">prefers longer terms</definiens>
			</definition>
</paper>

		<paper id="0801">
			<definition id="0">
				<sentence>Basque is an agglutinative language , and its case suffixes are more or less equivalent to prepositions , but are also used to mark the subject and objects of verbs .</sentence>
				<definiendum id="0">Basque</definiendum>
				<definiens id="0">an agglutinative language , and its case suffixes are more or less equivalent to prepositions , but are also used to mark the subject and objects of verbs</definiens>
			</definition>
			<definition id="1">
				<sentence>process ( XLEM ) , due to lexicalized items , e.g. gizonezko ( meaning male person ) .</sentence>
				<definiendum id="0">XLEM</definiendum>
			</definition>
</paper>

		<paper id="1033">
			<definition id="0">
				<sentence>Finally , we applied an answer tiling algorithm , which both merges similar answers and assembles longer answers from overlapping smaller answer fragments .</sentence>
				<definiendum id="0">answer tiling algorithm</definiendum>
				<definiens id="0">answers and assembles longer answers from overlapping smaller answer fragments</definiens>
			</definition>
			<definition id="1">
				<sentence>As we can see , the decision tree overfits the training data and does not generalize sufficiently to give useful results on the Trec 10 ( test ) data .</sentence>
				<definiendum id="0">decision tree</definiendum>
				<definiens id="0">overfits the training data and does not generalize sufficiently to give useful results on the Trec 10 ( test ) data</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>, Speech Communication , v.23 n.1-2 , p.113-127 , Oct. 1997 7 Peter Anthony Heeman , Speech repairs , intonational boundaries and discourse markers : modeling speakers ' utterances in spoken dialog , University of Rochester , Rochester , NY , 1998 8 M. Meteer et al. 1995 .</sentence>
				<definiendum id="0">Speech repairs</definiendum>
				<definiens id="0">modeling speakers ' utterances in spoken dialog</definiens>
			</definition>
</paper>

		<paper id="1900">
</paper>

		<paper id="0800">
</paper>

		<paper id="1107">
			<definition id="0">
				<sentence>For examples , there are the following Japanese examples : yuushuu_na seiseki ( excellent ) ( an academic record ) an excellent academic record sugure_ta seiseki ( excel and suffix of “adnominal” ) ( an academic record ) an excellent academic record “Yuushuu_na ( excellent ) ” is an adjective and “sugure_ta ( excel ) ” is a verb , but they represent the same meaning and same semantic function , that is , an evaluation of an academic record .</sentence>
				<definiendum id="0">”</definiendum>
				<definiens id="0">an academic record ) an excellent academic record “Yuushuu_na ( excellent )</definiens>
				<definiens id="1">a verb , but they represent the same meaning and same semantic function</definiens>
			</definition>
			<definition id="1">
				<sentence>For examples , kandai_na kihuu no hito ( gentle ) ( disposition ) ( of ) ( person ) a gentle person shinshu no kihuu no hito ( initiative ) ( of ) ( disposition ) ( of ) ( person ) a person of initiative In Japanese “kandai_na ( gentle ) ” is an adjective and “shinshu ( initiative ) ” is a noun .</sentence>
				<definiendum id="0">) ”</definiendum>
				<definiens id="0">kandai_na kihuu no hito ( gentle ) ( disposition ) ( of ) ( person ) a gentle person shinshu no kihuu no hito ( initiative ) ( of ) ( disposition ) ( of ) ( person ) a person of initiative In Japanese “kandai_na ( gentle ) ” is an adjective and “shinshu ( initiative</definiens>
				<definiens id="1">a noun</definiens>
			</definition>
			<definition id="2">
				<sentence>Let us consider the Japanese phrases , “kanashii kimochi ( sad feeling ) ” and “yorokobi no kimochi ( feeling of delight ) ” as examples .</sentence>
				<definiendum id="0">“kanashii kimochi</definiendum>
				<definiens id="0">feeling of delight ) ” as examples</definiens>
			</definition>
			<definition id="3">
				<sentence>This means that we co-classified both head nouns , i.e. abstract nouns , and adnominal constituents at the same time .</sentence>
				<definiendum id="0">i.e. abstract</definiendum>
				<definiens id="0">nouns , and adnominal constituents at the same time</definiens>
			</definition>
</paper>

		<paper id="0103">
			<definition id="0">
				<sentence>Scardamalia and Bereiter ( 1993 ) identify seven global characteristics that technologies must have to support this kind of participation : Balance : a distinction between public and private and between individual and group knowledge processes .</sentence>
				<definiendum id="0">Balance</definiendum>
				<definiens id="0">a distinction between public and private and between individual and group knowledge processes</definiens>
			</definition>
			<definition id="1">
				<sentence>We intend to distinguish the following kinds of links : Conceptual/taxonomical : connecting instances of key concepts and terms used throughout the course material with their definitions and provenience ; Empirical context : connecting instances of design decisions , algorithms and formal definitions to encyclopedic discussions of their linguistic motivation and empirical significance ; Denotational : connecting instances of constructional terms and issues within linguistics as well as correctness conditions of algorithms to the mathematical definitions that formalize them within the foundations of constraint-based linguistics ; Operational : connecting mathematical definitions and instances of related linguistic discussions to computational instructional material describing the algorithms used to construct , refute or transform the formal objects representing them in a practical system ; Implementational : connecting discussions of algorithms to the actual annotated system source code in the TRALE system used to implement them , and mathematical definitions and discussions of linguistic constructions to the actual annotated grammar source code used to represent them in a typical implementation .</sentence>
				<definiendum id="0">Implementational</definiendum>
				<definiens id="0">refute or transform the formal objects representing them in a practical system ;</definiens>
				<definiens id="1">the actual annotated grammar source code used to represent them in a typical implementation</definiens>
			</definition>
</paper>

		<paper id="2030">
			<definition id="0">
				<sentence>HPSG ( Head-driven Phrase Structure Grammar ) is a modern constraintbased lexicalist ( unification ) grammar , described in Pollard and Sag ( 1994 ) .</sentence>
				<definiendum id="0">HPSG</definiendum>
			</definition>
			<definition id="1">
				<sentence>Features Used The Redwoods treebank ( Oepen et al. , 2002 ) is an under-construction treebank of sentences corresponding to a particular HPSG grammar , the LinGO ERG ( Flickinger , 2000 ) .</sentence>
				<definiendum id="0">Redwoods treebank</definiendum>
				<definiendum id="1">LinGO ERG</definiendum>
				<definiens id="0">an under-construction treebank of sentences corresponding to a particular HPSG grammar , the</definiens>
			</definition>
			<definition id="2">
				<sentence>PCFG-S is a simple PCFG model where we only have the node label ( feature 0 ) in the history , and PCFG-GP has only the node and its parent’s labels ( features 0 and 1 ) as in PCFG grammars with grandparent annotation .</sentence>
				<definiendum id="0">PCFG-S</definiendum>
				<definiens id="0">features 0 and 1 ) as in PCFG grammars with grandparent annotation</definiens>
			</definition>
</paper>

		<paper id="1902">
			<definition id="0">
				<sentence>Linguistic entries consist of words , phrases and part-of-speech tags , such as “television , ” “3D Surround , ” and “NP 2 .”</sentence>
				<definiendum id="0">Linguistic entries</definiendum>
			</definition>
			<definition id="1">
				<sentence>Semantic types consist of attribute names , semantic tags ( categories ) 3 and user-defined semantic classes 4 , such as “ @ model , ” “ @ person , ” and “ % each.”</sentence>
				<definiendum id="0">Semantic types</definiendum>
			</definition>
			<definition id="2">
				<sentence>LSP-based language processing simplifies the natural language interface due to the following characteristics : First , linguistic elements from lexicons to semantic categories offer flexibility in representing natural language .</sentence>
				<definiendum id="0">LSP-based language processing</definiendum>
				<definiens id="0">simplifies the natural language interface due to the following characteristics : First , linguistic elements from lexicons to semantic categories offer flexibility in representing natural language</definiens>
			</definition>
			<definition id="3">
				<sentence>The AV-tree construction phase finds the relation between the nodes obtained from the previous phase , and produces an attribute-value tree that is independent of DBMSs .</sentence>
				<definiendum id="0">AV-tree construction phase</definiendum>
				<definiens id="0">finds the relation between the nodes obtained from the previous phase , and produces an attribute-value tree that is independent of DBMSs</definiens>
			</definition>
			<definition id="4">
				<sentence>The category dictionary consists of four components : semantic tags , user-defined semantic classes , part-of-speech ( POS ) tags , and lexical forms .</sentence>
				<definiendum id="0">category dictionary</definiendum>
			</definition>
			<definition id="5">
				<sentence>The action consists of an attribute and a value operator .</sentence>
				<definiendum id="0">action</definiendum>
			</definition>
			<definition id="6">
				<sentence>The condition part of the grammar consists of attributes and conjunctions ( see examples below ) , whereas the action part consists of binary operators and the attributes’ index in postfix notation .</sentence>
				<definiendum id="0">condition part of the grammar</definiendum>
				<definiens id="0">consists of attributes and conjunctions ( see examples below ) , whereas the action part consists of binary operators and the attributes’ index in postfix notation</definiens>
			</definition>
			<definition id="7">
				<sentence>Next , CGI ( Common Gateway Interface ) sends the query to DBMSs .</sentence>
				<definiendum id="0">CGI</definiendum>
				<definiens id="0">the query to DBMSs</definiens>
			</definition>
			<definition id="8">
				<sentence>[ 3 ] J. Binot , L. Debille , D. Sedlock , and B. Vandecapelle , “Natural Language Interfaces : A New Philosophy , ” SunExpert Magazine , January , 1991 .</sentence>
				<definiendum id="0">“Natural Language Interfaces</definiendum>
			</definition>
			<definition id="9">
				<sentence>[ 17 ] A. Shankar and W. Yung , gNarLI : A practical Approach to Natural Language Interfaces to Databases , Term Report , Harvard University , 2000 .</sentence>
				<definiendum id="0">gNarLI</definiendum>
				<definiens id="0">A practical Approach to Natural Language Interfaces to Databases</definiens>
			</definition>
</paper>

		<paper id="0707">
			<definition id="0">
				<sentence>The content of the data sets consists of conversations between a client and the front desk at a hotel and conversations between a client and train station staff .</sentence>
				<definiendum id="0">content of the data sets</definiendum>
				<definiens id="0">consists of conversations between a client and the front desk at a hotel and conversations between a client and train station staff</definiens>
			</definition>
</paper>

		<paper id="0506">
			<definition id="0">
				<sentence>For the purposes of this paper , a word is any Arabic surface form , a stem is a word without any prefixes or suffixes , and a root is a linguistic unit of meaning , which has no prefix , suffix , or infix .</sentence>
				<definiendum id="0">word</definiendum>
				<definiendum id="1">stem</definiendum>
				<definiens id="0">a word without any prefixes or suffixes</definiens>
				<definiens id="1">a linguistic unit of meaning , which has no prefix , suffix , or infix</definiens>
			</definition>
			<definition id="1">
				<sentence>Currently , ALPNET is owned by Xerox and uses Xerox Finite-State Morphology tools [ 11 ] .</sentence>
				<definiendum id="0">ALPNET</definiendum>
			</definition>
			<definition id="2">
				<sentence>morphological analyzer : This process is simple , but requires the availability of an analyzer .</sentence>
				<definiendum id="0">morphological analyzer</definiendum>
				<definiens id="0">simple , but requires the availability of an analyzer</definiens>
			</definition>
			<definition id="3">
				<sentence>The probabilities being calculated are given for character strings S1 and S2 and template T as : P ( S1 begins a word , S1 is a prefix ) P ( S2 ends a word , S2 is a suffix ) P ( T is a template ) Another potential way of calculating the probabilities of prefixes and suffixes is to use the conditional probabilities that the item appears in the word and is actually a prefix or suffix .</sentence>
				<definiendum id="0">S1</definiendum>
				<definiendum id="1">S2</definiendum>
				<definiens id="0">a prefix ) P ( S2 ends a word ,</definiens>
				<definiens id="1">a suffix ) P ( T is a template ) Another potential way of calculating the probabilities of prefixes and suffixes is to use the conditional probabilities that the item appears in the word and is actually a prefix or suffix</definiens>
			</definition>
			<definition id="4">
				<sentence>In other words , the probabilities being calculated are given for character strings S1 and S2 as : P ( S1 is a prefix | S1 begins a word ) P ( S2 is a suffix | S2 ends a word ) Notice that Sebawai’s stems are slightly different from standard stems .</sentence>
				<definiendum id="0">S1</definiendum>
				<definiendum id="1">S2</definiendum>
				<definiens id="0">a prefix | S1 begins a word</definiens>
				<definiens id="1">a suffix | S2 ends a word</definiens>
			</definition>
			<definition id="5">
				<sentence>P ( root ) = P ( S1 begins a word , S1 is a prefix ) * P ( S2 ends a word , S2 is a suffix ) * P ( T is a template ) The probabilities of stems , suffixes , and templates are assumed to be independent .</sentence>
				<definiendum id="0">S1</definiendum>
				<definiendum id="1">S2</definiendum>
				<definiens id="0">a prefix ) * P ( S2 ends a word</definiens>
				<definiens id="1">a suffix</definiens>
				<definiens id="2">a template</definiens>
			</definition>
			<definition id="6">
				<sentence>The new probability of the root becomes : P ( root ) = P ( S1 begins a word , S1 is a prefix ) * P ( S2 ends a word , S2 is a suffix ) * P ( T is a template ) * P ( letter substitution or letter addition ) As for smoothing the prefix and suffix probabilities , Witten-Bell discounting was used [ 17 ] .</sentence>
				<definiendum id="0">S1</definiendum>
				<definiendum id="1">S2</definiendum>
				<definiendum id="2">S2</definiendum>
				<definiens id="0">new probability of the root becomes : P ( root ) = P ( S1 begins a word</definiens>
				<definiens id="1">a prefix</definiens>
				<definiens id="2">ends a word ,</definiens>
				<definiens id="3">a suffix ) * P ( T is a template ) * P ( letter substitution or letter addition</definiens>
			</definition>
			<definition id="7">
				<sentence>Results summary : Using Sebawai’s guess of the most likely root resulted in a higher mean average precision than when using one root produced by ALPNET ( Note that ALPNET randomly ordered the possible roots ) .</sentence>
				<definiendum id="0">Results summary</definiendum>
				<definiens id="0">Using Sebawai’s guess of the most likely root resulted in a higher mean average precision than when using one root produced by ALPNET ( Note that ALPNET randomly ordered the possible roots )</definiens>
			</definition>
			<definition id="8">
				<sentence>Morphology : A General Computational Model for Word-form Recognition and Production.”</sentence>
				<definiendum id="0">Morphology</definiendum>
			</definition>
</paper>

		<paper id="1500">
			<definition id="0">
				<sentence>Grammar Engineering and Evaluation null Roberto Bartolini , Alessandro Lenci , Simonetta Montemagni , Vito Pirrelli : Grammar and Lexicon in the Robust Parsing of Italian towards a Non-Naïve Interplay null Emily M. Bender , Dan Flickinger , Stephan Oepen : The Grammar Matrix : An Open-Source Starter-Kit for the Rapid Development of Cross-linguistically Consistent Broad-Coverage Precision Grammars null Miriam Butt , Helge Dyvik , Tracy Holloway King , Hiroshi Masuichi , Christian Rohrer : The Parallel Grammar Project null Richard Campbell , Carmen Lozano , Jessie Pinkham , Martine Smets : Machine Translation as a Testbed for Multilingual Analysis null Caroline Hagège , Gabriel G. Bès : Encoding and Reusing Linguistic Information Expressed by Linguistic Properties null Ronald M. Kaplan , Tracy Holloway King , John T. Maxwell III : Adapting Existing Grammars : The XLE Experience null Alexandra Kinyon , Carlos A. Prolo : A Classification of Grammar Development Strategies null Stephan Oepen , Emily M. Bender , Uli Callmeier , Dan Flickinger , Melanie Siegel : Parallel Distributed Grammar Engineering for Practical Applications null Carlos A. Prolo : Coping with Problems in Grammars Automatically Extracted from Treebanks null Hisami Suzuki : A Development Environment for Large-scale Multi-lingual Parsing Systems</sentence>
				<definiendum id="0">Development Environment</definiendum>
				<definiens id="0">The Grammar Matrix : An Open-Source Starter-Kit for the Rapid Development of Cross-linguistically Consistent Broad-Coverage Precision Grammars null Miriam Butt</definiens>
				<definiens id="1">The Parallel Grammar Project null Richard Campbell</definiens>
				<definiens id="2">The XLE Experience null Alexandra Kinyon , Carlos A. Prolo : A Classification of Grammar Development Strategies null Stephan Oepen</definiens>
				<definiens id="3">Parallel Distributed Grammar Engineering for Practical Applications null Carlos A. Prolo : Coping with Problems in Grammars Automatically Extracted from Treebanks null Hisami Suzuki : A</definiens>
			</definition>
</paper>

		<paper id="1116">
			<definition id="0">
				<sentence>HowNet is a bilingual general knowledge base that encodes inter-concept semantic relations and the inter-attribute semantic relations .</sentence>
				<definiendum id="0">HowNet</definiendum>
				<definiens id="0">a bilingual general knowledge base that encodes inter-concept semantic relations and the inter-attribute semantic relations</definiens>
			</definition>
			<definition id="1">
				<sentence>In contrast to WordNet ( Miller , 1990 ) , HowNet adopts a constructive approach of meaning representation ( Miller , 1993 ) .</sentence>
				<definiendum id="0">HowNet</definiendum>
			</definition>
			<definition id="2">
				<sentence>“X” represents some 2 http : //godel.iis.sinica.edu.tw/CKIP/hk/index.html language and each language has three specific items : W_X , E_X and G_X .</sentence>
				<definiendum id="0">“X”</definiendum>
				<definiens id="0">//godel.iis.sinica.edu.tw/CKIP/hk/index.html language and each language has three specific items : W_X , E_X and G_X</definiens>
			</definition>
			<definition id="3">
				<sentence>It names the hypernym or the superordinate term , which gives a general classification of the concept .</sentence>
				<definiendum id="0">superordinate term</definiendum>
				<definiens id="0">gives a general classification of the concept</definiens>
			</definition>
			<definition id="4">
				<sentence>The HowNet corpus is written in XML format , and contains the part-of-speech , sense and semantic dependency relation information for each word .</sentence>
				<definiendum id="0">HowNet corpus</definiendum>
				<definiens id="0">XML format , and contains the part-of-speech , sense and semantic dependency relation information for each word</definiens>
			</definition>
			<definition id="5">
				<sentence>There are 30,976 word tokens and 3,178 sentences 9 in the HowNet corpus , which is divided into two sets in the experiment : 2,400 sentences ( 23,191 word tokens ) are reserved for training , and 778 sentences ( 7,785 word tokens ) for testing .</sentence>
				<definiendum id="0">HowNet corpus</definiendum>
				<definiens id="0">is divided into two sets in the experiment : 2,400 sentences ( 23,191 word tokens ) are reserved for training , and 778 sentences ( 7,785 word tokens ) for testing</definiens>
			</definition>
</paper>

		<paper id="0811">
			<definition id="0">
				<sentence>Lower bound ( LB ) : ALL is how often all of the first-orders chose correctly .</sentence>
				<definiendum id="0">LB</definiendum>
				<definiens id="0">ALL is how often all of the first-orders chose correctly</definiens>
			</definition>
			<definition id="1">
				<sentence>Baselines ( BL ) : MFS is the most-frequent-sense baseline , SNG is the best single first-order classifier as chosen on held-out data for that word .</sentence>
				<definiendum id="0">Baselines</definiendum>
				<definiendum id="1">MFS</definiendum>
				<definiendum id="2">SNG</definiendum>
				<definiens id="0">the most-frequent-sense baseline</definiens>
				<definiens id="1">the best single first-order classifier as chosen on held-out data for that word</definiens>
			</definition>
			<definition id="2">
				<sentence>System choices : ACC is the accuracy of the selection the system makes based on held-out data .</sentence>
				<definiendum id="0">ACC</definiendum>
				<definiens id="0">the accuracy of the selection the system makes based on held-out data</definiens>
			</definition>
			<definition id="3">
				<sentence>CL is the 2nd-order classifier selected .</sentence>
				<definiendum id="0">CL</definiendum>
				<definiens id="0">the 2nd-order classifier selected</definiens>
			</definition>
</paper>

		<paper id="0501">
			<definition id="0">
				<sentence>The Definite Clause Grammar ( DCG ) rules that are used are an expansion of regular context-free grammars ; they define a set of one or more expansions from a set of variables to a complete form .</sentence>
				<definiendum id="0">Definite Clause Grammar</definiendum>
				<definiens id="0">an expansion of regular context-free grammars ; they define a set of one or more expansions from a set of variables to a complete form</definiens>
			</definition>
			<definition id="1">
				<sentence>The user interface is a HTML form which then passes its input to a cgi-bin script which formats them properly for a Java wrapper to the Prolog interpreter .</sentence>
				<definiendum id="0">user interface</definiendum>
				<definiens id="0">a HTML form which then passes its input to a cgi-bin script which formats them properly for a Java wrapper to the Prolog interpreter</definiens>
			</definition>
			<definition id="2">
				<sentence>The user interface consists of two HTML forms , one for parsing and one for generation , which are on the same page 4 .</sentence>
				<definiendum id="0">user interface</definiendum>
				<definiens id="0">consists of two HTML forms , one for parsing and one for generation , which are on the same page 4</definiens>
			</definition>
			<definition id="3">
				<sentence>Due to the fact that parsing , especially with wildcard expansion , is computationally intensive , and Prolog is an interpreted language and therefore somewhat slow , the web-server , a PII-266 system , passes the actual work off to a backend , a dual Athlon 1900+ system .</sentence>
				<definiendum id="0">Prolog</definiendum>
			</definition>
</paper>

		<paper id="0503">
			<definition id="0">
				<sentence>A morphology system is the backbone of a natural language processing system .</sentence>
				<definiendum id="0">morphology system</definiendum>
			</definition>
			<definition id="1">
				<sentence>Al-Fedaghi and Al-Anzi ( 1989 ) present an algorithm to generate the root and the pattern of a given Arabic word .</sentence>
				<definiendum id="0">Al-Fedaghi</definiendum>
				<definiens id="0">present an algorithm to generate the root and the pattern of a given Arabic word</definiens>
			</definition>
			<definition id="2">
				<sentence>Example : سورﺪﻣ the thing that has been studied An instrument noun is a noun indicating the tool of an action .</sentence>
				<definiendum id="0">instrument noun</definiendum>
				<definiens id="0">a noun indicating the tool of an action</definiens>
			</definition>
			<definition id="3">
				<sentence>Answer : No // the system drops group # 1 Result : Group # 2 : The noun ( ﺐﻋﻼﻣ playground ) is a plural Feminine .</sentence>
				<definiendum id="0">Answer</definiendum>
			</definition>
			<definition id="4">
				<sentence>The User-Feedback Module found most of the nouns that the Database Checker Module failed to identify .</sentence>
				<definiendum id="0">User-Feedback Module</definiendum>
				<definiens id="0">found most of the nouns that the Database Checker Module failed to identify</definiens>
			</definition>
</paper>

		<paper id="1114">
</paper>

		<paper id="1403">
			<definition id="0">
				<sentence>Experiments are done on a ‘flat’ list of terms obtained from an originally hierarchically-structured terminology : the French version of the US National Library of Medicine MeSH thesaurus .</sentence>
				<definiendum id="0">hierarchically-structured terminology</definiendum>
			</definition>
			<definition id="1">
				<sentence>Internal methods look at the constituency of terms , and compare terms based on the words they contain .</sentence>
				<definiendum id="0">Internal methods</definiendum>
				<definiens id="0">look at the constituency of terms , and compare terms based on the words they contain</definiens>
			</definition>
			<definition id="2">
				<sentence>External methods take advantage of the context in which terms occur : they examine the behavior of terms in corpora .</sentence>
				<definiendum id="0">External methods</definiendum>
				<definiens id="0">take advantage of the context in which terms occur : they examine the behavior of terms in corpora</definiens>
			</definition>
			<definition id="3">
				<sentence>The French version of the MeSH ( INSERM , 2000 ) contains a translation of these terms ( 19,638 terms ) plus synonyms .</sentence>
				<definiendum id="0">MeSH</definiendum>
				<definiens id="0">contains a translation of these terms ( 19,638 terms</definiens>
			</definition>
</paper>

		<paper id="0222">
</paper>

		<paper id="0309">
			<definition id="0">
				<sentence>Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system ( Choueka , 1990 ; J¨appinen and Niemist¨o , 1988 ; Kraaij and Pohlmann , 1996 ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .</sentence>
				<definiendum id="0">information retrieval</definiendum>
			</definition>
			<definition id="1">
				<sentence>A random sample ( a8 =400 ) was classified by a medical expert whether they contained medical jargon or the wording of laymen .</sentence>
				<definiendum id="0">random sample</definiendum>
				<definiens id="0">classified by a medical expert whether they contained medical jargon or the wording of laymen</definiens>
			</definition>
			<definition id="2">
				<sentence>This is not at all surprising given all the tuning Precision ( % ) AltaVista Experimental Recall WSA SU SY WSA SU SY ( % ) 0 53.6 69.4 66.9 56.8 67.3 64.2 10 51.7 65.5 60.5 53.2 60.3 58.8 20 45.4 61.4 54.9 44.7 50.7 48.3 30 34.9 55.4 51.6 34.8 45.7 39.4 40 29.5 51.4 46.7 29.3 34.6 32.9 50 27.8 49.7 44.1 26.5 31.2 29.4 60 26.2 40.7 39.2 22.0 22.2 20.1 70 18.1 32.6 31.7 13.5 18.9 16.5 80 15.2 26.3 22.4 11.6 13.4 12.1 90 5.6 20.1 11.4 4.4 7.9 8.3 100 5.4 16.3 11.0 4.0 7.0 7.5 3pt 29.5 45.8 40.5 27.6 32.8 29.9 avrg 11pt 28.5 44.4 40.0 27.3 32.6 30.7 avrg Table 6 : Precision/Recall Table for Expert Queries comparing the AltaVistaTM with our Experimental Search Engine efforts that went into AltaVistaTM .</sentence>
				<definiendum id="0">AltaVista Experimental Recall WSA SU SY WSA SU SY</definiendum>
				<definiens id="0">Precision/Recall Table for Expert Queries comparing the AltaVistaTM with our Experimental Search Engine efforts that went into AltaVistaTM</definiens>
			</definition>
</paper>

		<paper id="0204">
</paper>

		<paper id="2012">
			<definition id="0">
				<sentence>Complex categories are built from basic categories using / , \ , and * : Basic categories c1 , c2 , c3 , ... , c12345 , ... Complex categories c1\c12345 , c2/c3 , c4*c5 , c2/ ( c3\ ( c4*c5 ) ) B ) A lexicon is a mapping of lexemes [ word types represented in phonetic or enrichedorthographic encoding ] onto categories .</sentence>
				<definiendum id="0">lexicon</definiendum>
				<definiens id="0">Basic categories c1 , c2 , c3 , ... , c12345 , ... Complex categories c1\c12345 , c2/c3 , c4*c5</definiens>
				<definiens id="1">a mapping of lexemes [ word types represented in phonetic or enrichedorthographic encoding ] onto categories</definiens>
			</definition>
			<definition id="1">
				<sentence>A solo is a string of segments [ an utterance delimited by e.g. turntakes and pauses ] .</sentence>
				<definiendum id="0">solo</definiendum>
			</definition>
			<definition id="2">
				<sentence>A corpus is a bag of soli [ a transcript of a conversation ] .</sentence>
				<definiendum id="0">corpus</definiendum>
				<definiens id="0">a bag of soli [ a transcript of a conversation ]</definiens>
			</definition>
			<definition id="3">
				<sentence>The disorder function Dis takes a sequent Σ [ the lexical mapping of an utterance ] returning the number of uninterpretable atoms in Σ , i.e. σ+s and σ–s in a ( maximally linked ) proof .</sentence>
				<definiendum id="0">disorder function Dis</definiendum>
				<definiens id="0">takes a sequent Σ [ the lexical mapping of an utterance ] returning the number of uninterpretable atoms in Σ</definiens>
			</definition>
			<definition id="4">
				<sentence>Examples : Dis ( ca/cb cb ⇒ ca ) = 0 Dis ( ca/cb cb ⇒ cc ) = 2 Dis ( cb ca/cb ⇒ cc ) = 4 Dis ( ca/cb cc cb ⇒ ca ) = 1 Dis ( ca/cc cb ca\cc ⇒ ca ) = 2 DIS ( Lex , K ) is the total amount of disorder in training corpus K wrt .</sentence>
				<definiendum id="0">Dis</definiendum>
				<definiendum id="1">Lex , K )</definiendum>
				<definiens id="0">the total amount of disorder in training corpus K wrt</definiens>
			</definition>
</paper>

		<paper id="0803">
			<definition id="0">
				<sentence>More fundamentally , the notion of polysemy poses the major question of the relation between language and thought .</sentence>
				<definiendum id="0">polysemy</definiendum>
				<definiens id="0">poses the major question of the relation between language and thought</definiens>
			</definition>
			<definition id="1">
				<sentence>Under her account , language is grounded in thought and polysemy is a consequence of the instantiation of thought into language , the cognitive dictionary being the glue of all the meanings of a polysemous word .</sentence>
				<definiendum id="0">polysemy</definiendum>
				<definiens id="0">a consequence of the instantiation of thought into language , the cognitive dictionary being the glue of all the meanings of a polysemous word</definiens>
			</definition>
			<definition id="2">
				<sentence>Guillaume ( ibid. : 279 ) defines the comitativity as follows1 : “ the preposition avec is an abstract image of parallelism : it expresses the relation holding between two entities that exist or act together , accomplish the same movements and follow the same directions .</sentence>
				<definiendum id="0">Guillaume</definiendum>
				<definiendum id="1">preposition avec</definiendum>
				<definiens id="0">an abstract image of parallelism : it expresses the relation holding between two entities that exist or act together , accomplish the same movements and follow the same directions</definiens>
			</definition>
			<definition id="3">
				<sentence>A classification is a triple ( Objets , Types , � ) , where Objets is a set of objects , Types a set of categories or types , and � a relation between Objets and Types .</sentence>
				<definiendum id="0">classification</definiendum>
				<definiendum id="1">Objets</definiendum>
				<definiens id="0">a set of objects , Types a set of categories or types , and � a relation between Objets and Types</definiens>
			</definition>
			<definition id="4">
				<sentence>GN1GN1GN2GN2 ( ) ( 123 ; ) , , , , f’g’f’g’ fg αββα→← ←→φφφφ MMM MMM � ��� The following set of constraints further specify this representation ( the operators F , P aggregation ( Kratzer , 1989 ) : the association has to be possible within the system itself and not by the intervention of external events .</sentence>
				<definiendum id="0">P aggregation</definiendum>
				<definiens id="0">the association has to be possible within the system itself and not by the intervention of external events</definiens>
			</definition>
			<definition id="5">
				<sentence>Avec forces an interpretation where the sadness ( or another property ) of Mary influences the sadness of John : avec signals a coordination of the properties of the entities it links .</sentence>
				<definiendum id="0">Avec</definiendum>
				<definiens id="0">forces an interpretation where the sadness ( or another property ) of Mary influences the sadness of John : avec signals a coordination of the properties of the entities it links</definiens>
			</definition>
</paper>

		<paper id="1103">
			<definition id="0">
				<sentence>WN is a wide-coverage lexico-conceptual taxonomy of English .</sentence>
				<definiendum id="0">WN</definiendum>
			</definition>
			<definition id="1">
				<sentence>Based on the supposition that , if a connection is a joint solution of two methods , its probability to be correct would be higher , and then the joint evaluation of both methods will be higher than that of each Table 1 : First and second method evaluations method set volume accuracy reevaluation 1 3704 92 % 91.25 % 2 935 89 % 86.40 % 3 1888 89 % 74.85 % 4 2690 85 % 69.27 % 5 5123 80 % 91.62 % 6 1450 75 % 85.28 % 7 11687 58 % 92.50 % 8 40299 61 % 85.06 % 9 1256 79 % 82.26 % 10 1432 51 % 76.05 % 11 2202 57 % 77.40 % 12 1846 60 % 76.43 % 13 23829 56 % 87.44 % 14 24740 61 % 87.98 % 15 4567 75 % 76.61 % 16 3164 85 % 86.28 % 17 510 78 % 89.76 % method separately , and having checked the high degree of intersection between solutions of the different methods , we decided to add to the previous set of connections ( Subset1 ) those connections occurring as simultaneous solution of two of the methods not considered in the previous phase , increasing coverage without loosing precision .</sentence>
				<definiendum id="0">Subset1</definiendum>
				<definiens id="0">those connections occurring as simultaneous solution of two of the methods not considered in the previous phase , increasing coverage without loosing precision</definiens>
			</definition>
			<definition id="2">
				<sentence>To do this , all the data has been condensed in a matrix of 66,609 vectors , one vector for each link , of the kind link ma1 ma3 ... ma1a4a3 ma1a5a4 eval where mi are booleans indicating membership of the link to the set of solutions of method i , eval is the manual evaluation accepting one of two values ( OK being correct , KO being incorrect ) , and link is the pair ( WN1.5 synset , Spanish word ) .</sentence>
				<definiendum id="0">eval</definiendum>
				<definiendum id="1">link</definiendum>
				<definiens id="0">the pair ( WN1.5 synset , Spanish word )</definiens>
			</definition>
			<definition id="3">
				<sentence>The logistic regression is a technique which allows finding a model ( in the mathematical sense ) for approximating a0a20a1a4a3a6a5a8a7 on the basis of a set of explicative variables ( in our case ma1 , ma3 , ... ma1a5a4 ) .</sentence>
				<definiendum id="0">logistic regression</definiendum>
				<definiens id="0">a technique which allows finding a model ( in the mathematical sense ) for approximating a0a20a1a4a3a6a5a8a7 on the basis of a set of explicative variables ( in our case ma1 , ma3 , ... ma1a5a4 )</definiens>
			</definition>
</paper>

		<paper id="0225">
</paper>

		<paper id="1603">
			<definition id="0">
				<sentence>For this paper , the term semi-automatic translation means the sentence translation with user interaction to manually resolve structural and semantic ambiguities during translation period .</sentence>
				<definiendum id="0">semi-automatic translation</definiendum>
				<definiens id="0">means the sentence translation with user interaction to manually resolve structural and semantic ambiguities during translation period</definiens>
			</definition>
			<definition id="1">
				<sentence>We apply the Maximum-Entropy-Inspired Parser ( Charniak , 1999 ) ( so-called Charniak Parser ) to analyze and determine the appropriate grammatical structure of an English sentence .</sentence>
				<definiendum id="0">Maximum-Entropy-Inspired Parser</definiendum>
				<definiens id="0">so-called Charniak Parser ) to analyze and determine the appropriate grammatical structure of an English sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Phrase is a word-ordering pattern that can not be separately translated .</sentence>
				<definiendum id="0">Phrase</definiendum>
			</definition>
			<definition id="3">
				<sentence>In English , we can normally modify a certain core noun with modifiers in two ways— Table 1 : Rules for the parse tree modification process Original PTB Modified ( VP ( AUX ( be ) ) ( NP ) ) ( VP ( be ) ( NP ) ) ( VP ( AUX ( be ) ) ( PP ) ) ( VP ( be ) ( PP ) ) ( VP ( AUX ( be ) ) ( VP ( VBG ) * ) ) ( VP ( be ) ( VBG ) * ) ( VP ( AUX ( be ) ) ( VP ( VBN ) * ) ) ( VP ( be ) ( VBN ) * ) ( VP ( AUX ( be ) ) ( ADJP ) ) ( VP ( be ) ( ADJP ) ) ( VP ( VBP ( look ) ) ( PP ( IN ( for ) ) ( NP ) ) ) ( VP ( look ) ( for ) ( NP ) ) Table 2 : Rules to translate the verb to be and the verbal phrase look for something English Rules Thai Rules VP !</sentence>
				<definiendum id="0">AUX</definiendum>
				<definiendum id="1">AUX</definiendum>
				<definiendum id="2">AUX</definiendum>
				<definiendum id="3">VP</definiendum>
				<definiendum id="4">AUX</definiendum>
				<definiendum id="5">AUX</definiendum>
			</definition>
			<definition id="4">
				<sentence>The probability of a parse tree … is given by the equation P ( … ) = – ( c… ; c…1 ; c…2 ; c…3 ; : : : ; c…n ) nY k=1 P ( …k ) where …k is the k-th subtree of the parse tree … whose number of member subtrees is n , c… represents the constituent of the tree … , and – is a probability relation that maps the constituents of the root and its single-depth children to the probability value .</sentence>
				<definiendum id="0">…k</definiendum>
				<definiendum id="1">–</definiendum>
				<definiens id="0">the k-th subtree of the parse tree … whose number of member subtrees is n , c… represents the constituent of the tree … , and</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>3 Michael Collins , Nigel Duffy , New ranking algorithms for parsing and tagging : kernels over discrete structures , and the voted perceptron , Proceedings of the 40th Annual Meeting on Association for Computational Linguistics , July 07-12 , 2002 , Philadelphia , Pennsylvania 4 Michael Collins , Ranking algorithms for named-entity extraction : boosting and the voted perceptron , Proceedings of the 40th Annual Meeting on Association for Computational Linguistics , July 07-12 , 2002 , Philadelphia , Pennsylvania 5 Yoav Freund , Robert E. Schapire , Large Margin Classification Using the Perceptron Algorithm , Machine Learning , v.37 n.3 , p.277-296 , Dec. 1999 6 David P. Helmbold , Manfred K. Warmuth , On weak learning , Journal of Computer and System Sciences , v.50 n.3 , p.551-573 , June 1995 7 John D. Lafferty , Andrew McCallum , Fernando C. N. Pereira , Conditional Random Fields : Probabilistic Models for Segmenting and Labeling Sequence Data , Proceedings of the Eighteenth International Conference on Machine Learning , p.282-289 , June 28-July 01 , 2001 8 Andrew McCallum , Dayne Freitag , Fernando C. N. Pereira , Maximum Entropy Markov Models for Information Extraction and Segmentation , Proceedings of the Seventeenth International Conference on Machine Learning , p.591-598 , June 29-July 02 , 2000 9 Mitchell P. Marcus , Mary Ann Marcinkiewicz , Beatrice Santorini , Building a large annotated corpus of English : the penn treebank , Computational Linguistics , v.19 n.2 , June 1993 10 Ramshaw , L. , and Marcus , M. P. ( 1995 ) .</sentence>
				<definiendum id="0">Perceptron Algorithm , Machine Learning</definiendum>
				<definiens id="0">Probabilistic Models for Segmenting and Labeling Sequence Data , Proceedings of the Eighteenth International Conference on Machine Learning , p.282-289 , June 28-July 01 , 2001 8 Andrew McCallum , Dayne Freitag , Fernando C. N. Pereira , Maximum Entropy Markov Models for Information Extraction and Segmentation , Proceedings of the Seventeenth International Conference on Machine Learning , p.591-598</definiens>
				<definiens id="1">the penn treebank</definiens>
			</definition>
			<definition id="1">
				<sentence>The Perceptron : A Probabilistic Model for Information Storage and Organization in the Brain .</sentence>
				<definiendum id="0">Perceptron</definiendum>
				<definiens id="0">A Probabilistic Model for Information Storage and Organization in the Brain</definiens>
			</definition>
</paper>

		<paper id="0602">
			<definition id="0">
				<sentence>ACL Special Interest Group in Computational Phonology ( SIGPHON ) , Philadelphia , Morphological and Phonological Learning : Proceedings of the 6th Workshop of the which uses a generative probability model and a hill climbing search .</sentence>
				<definiendum id="0">Phonological Learning</definiendum>
				<definiens id="0">Proceedings of the 6th Workshop of the which uses a generative probability model and a hill climbing search</definiens>
			</definition>
			<definition id="1">
				<sentence>The probability of choosing a paradigm a21 , for a stem is calculated using a maximum likelihood estimate : a28PARAa23a25 a28 a0 where PARAa23a25 is the set of stems in paradigm a21 .</sentence>
				<definiendum id="0">PARAa23a25</definiendum>
			</definition>
			<definition id="2">
				<sentence>STEMa2 is the maximal sized set of stems that meets this requirement .</sentence>
				<definiendum id="0">STEMa2</definiendum>
				<definiens id="0">the maximal sized set of stems that meets this requirement</definiens>
			</definition>
			<definition id="3">
				<sentence>For English we used set A of the Hansard corpus , which is a parallel English and French corpus of proceedings of the Canadian Parliament .</sentence>
				<definiendum id="0">Hansard corpus</definiendum>
				<definiens id="0">a parallel English and French corpus of proceedings of the Canadian Parliament</definiens>
			</definition>
			<definition id="4">
				<sentence>The stem relation precision measures how many of the relations predicted by the system were correct , while the recall measures how many of the relations present in the data were found .</sentence>
				<definiendum id="0">stem relation precision</definiendum>
				<definiens id="0">measures how many of the relations predicted by the system were correct , while the recall measures how many of the relations present in the data were found</definiens>
			</definition>
			<definition id="5">
				<sentence>Stem relation fscore is an unbiased combination of precision and recall that favors equal scores .</sentence>
				<definiendum id="0">Stem relation fscore</definiendum>
				<definiens id="0">an unbiased combination of precision and recall that favors equal scores</definiens>
			</definition>
</paper>

		<paper id="0708">
			<definition id="0">
				<sentence>The C-star II database has been partially re-tagged with the Nespole interlingua , which enables us to make comparisons on the same data with two types of interlinguas and on two types of data ( Cstar II and Nespole ) with the same interlingua .</sentence>
				<definiendum id="0">Nespole interlingua</definiendum>
				<definiens id="0">enables us to make comparisons on the same data with two types of interlinguas and on two types of data ( Cstar II and Nespole ) with the same interlingua</definiens>
			</definition>
			<definition id="1">
				<sentence>The C-star II interlingua speci cation document contains de nitions for 44 speech acts , 93 concepts , and 117 argument names .</sentence>
				<definiendum id="0">C-star II interlingua speci cation document</definiendum>
				<definiens id="0">contains de nitions for 44 speech acts</definiens>
			</definition>
			<definition id="2">
				<sentence>The domain action is the part of the interlingua consisting of the speech act and concepts , in this case request-action+reservation+temporal+hotel .</sentence>
				<definiendum id="0">domain action</definiendum>
				<definiens id="0">the part of the interlingua consisting of the speech act and concepts</definiens>
			</definition>
			<definition id="3">
				<sentence>A domain action consists of a speech act followed by zero or more concepts .</sentence>
				<definiendum id="0">domain action</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Nespole interlingua includes 65 speech acts and 110 concepts .</sentence>
				<definiendum id="0">Nespole interlingua</definiendum>
			</definition>
			<definition id="5">
				<sentence>A lexical-semantic interlingua includes a representation of predicates and their arguments .</sentence>
				<definiendum id="0">lexical-semantic interlingua</definiendum>
			</definition>
			<definition id="6">
				<sentence>The no-tag rate is the percentage of sentences that can not be assigned an interlingua representation by a human expert .</sentence>
				<definiendum id="0">no-tag rate</definiendum>
				<definiens id="0">the percentage of sentences that can not be assigned an interlingua representation by a human expert</definiens>
			</definition>
			<definition id="7">
				<sentence>We have presented a comparison of a purely domain-action-based interlingua ( the C-star II interlingua ) and a more expressive , but still domain-action-based interlingua ( the Nespole interlingua ) .</sentence>
				<definiendum id="0">domain-action-based interlingua</definiendum>
				<definiens id="0">the C-star II interlingua ) and a more expressive , but still domain-action-based interlingua ( the Nespole interlingua )</definiens>
			</definition>
</paper>

		<paper id="0817">
			<definition id="0">
				<sentence>Open Mind Word Expert is an implemented active learning system for collecting word sense tagging from the general public over the Web .</sentence>
				<definiendum id="0">Mind Word Expert</definiendum>
				<definiens id="0">an implemented active learning system for collecting word sense tagging from the general public over the Web</definiens>
			</definition>
			<definition id="1">
				<sentence>Open Mind Word Expert is a newly born project that follows the Open Mind initiative ( Stork , 1999 ) .</sentence>
				<definiendum id="0">Mind Word Expert</definiendum>
			</definition>
			<definition id="2">
				<sentence>Additionally , ( Kilgarriff , 1998 ) mentions the Hector corpus , which comprises about 300 word types with 300-1000 tagged instances for each word , selected from a 17 million word corpus .</sentence>
				<definiendum id="0">Hector corpus</definiendum>
				<definiens id="0">comprises about 300 word types with 300-1000 tagged instances for each word , selected from a 17 million word corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>Open Mind Word Expert is a Web-based interface where users can tag words with their WordNet senses .</sentence>
				<definiendum id="0">Mind Word Expert</definiendum>
			</definition>
			<definition id="4">
				<sentence>For example , WordZap ( http : //wordzap.com ) , a game that pits players against each other or against a computer to be the first to make seven words from several presented letters ( with some additional rules ) , has been downloaded by well over a million users , and the reviewers describe the game as “addictive” .</sentence>
				<definiendum id="0">WordZap ( http</definiendum>
				<definiens id="0">has been downloaded by well over a million users</definiens>
			</definition>
			<definition id="5">
				<sentence>We will initially select a set of 100 nouns , and collect for each of them a0a2a1a4a3a6a5a8a7a4a9a10a1 tagged samples ( Edmonds , 2000 ) , where a5 is the number of senses of the noun .</sentence>
				<definiendum id="0">a5</definiendum>
				<definiens id="0">the number of senses of the noun</definiens>
			</definition>
</paper>

		<paper id="1807">
			<definition id="0">
				<sentence>He also includes the case where an additional verb and a main verb are used , such as V+ 着 expression in V1 position , which indicates that V1 is additional and V2 is main .</sentence>
				<definiendum id="0">V2</definiendum>
				<definiens id="0">additional and</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 1 : TOTAL-CK system architecture Construction In the previous chapter , we mentioned the syntactic format of SVCs which is NP V1 ( NP ) V2 ( NP ) and the different scope of definition of SVCs by the Chinese language researches .</sentence>
				<definiendum id="0">Construction</definiendum>
				<definiens id="0">TOTAL-CK system architecture</definiens>
			</definition>
			<definition id="2">
				<sentence>To outline the scope of SVCs , we define SVCs in terms of dependency relation such that V1 is the head of V2 , or V2 is the head of V1 .</sentence>
				<definiendum id="0">V1</definiendum>
				<definiendum id="1">V2</definiendum>
				<definiens id="0">the head of V2</definiens>
				<definiens id="1">the head of V1</definiens>
			</definition>
			<definition id="3">
				<sentence>Then the functions : head , nw , and npos , are defined as below : head ( n ) =hn where n∈N and hn is the head of n nw ( n ) = w where n ∈N and w ∈ W npos ( n ) = np where n ∈N and np ∈P A definition of SVC is : Given a node n such that npos ( n ) ∈ V and Head ( n ) = hn , If and only if npos ( hn ) ∈ V and hn is the head of a given sentence then the sentence is a SVC .</sentence>
				<definiendum id="0">hn</definiendum>
				<definiendum id="1">hn</definiendum>
				<definiens id="0">the head of n nw ( n ) = w where n ∈N and w ∈ W npos ( n ) = np where n ∈N and np ∈P A definition of SVC is : Given a node n such that npos ( n ) ∈ V and Head ( n ) = hn , If and only if npos ( hn ) ∈ V and</definiens>
				<definiens id="1">the head of a given sentence then the sentence is a SVC</definiens>
			</definition>
			<definition id="4">
				<sentence>Sentence nw nwh SH SVC 他开门进去。 进 开 Yes Yes 我没想到你住在北京。 住 想 Yes Yes 在这里停车犯法。 停 犯 Yes Yes 各接入网络的总数已 经超过1000个。 接入 总数 No No Table 1 : Example of Testing SVC Where nw : nw ( n ) ; nwh : nw ( head ( n ) ) ; SH : testing if head ( n ) is the sentence head ; n is a given node .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a given node</definiens>
			</definition>
			<definition id="5">
				<sentence>If the noun phrase between V1 and V2 is the object of V1 and the subject of V2 , then it is a pivot construction .</sentence>
				<definiendum id="0">V2</definiendum>
				<definiens id="0">the object of V1 and the subject of V2</definiens>
			</definition>
			<definition id="6">
				<sentence>When V2 occurs on the condition of the action of V1 , then it is classified as a circumstantial case .</sentence>
				<definiendum id="0">V2</definiendum>
				<definiens id="0">occurs on the condition of the action of V1 , then it is classified as a circumstantial case</definiens>
			</definition>
			<definition id="7">
				<sentence>N Separate Event SVC Ex ) 我去问刘厂长。 Figure 2 : Algorithm of Detecting SVC for Case 1 Subject SVC Ex ) 厂长 偷听 私 人电话 违反 了国家法律。 SVC sentence Figure 3 : Algorithm of Detecting SVC for Case 2 Object SVC Ex ) 厂长偷听属下打电话 。 Y V1 takes NP &amp; VP N N Y V2 takes VP as Sub .</sentence>
				<definiendum id="0">Y V2</definiendum>
				<definiens id="0">takes VP as Sub</definiens>
			</definition>
			<definition id="8">
				<sentence>To complete the solution , we first define the relations : RSTV , RSTL and RSTM as follows : Definition 2 We define the relations : RSTV , RSTL , and RSTM , as follows : RSTV= { ( V1 , V2 ) where V1 and V2 are the first verb and second verb in a given SVC sentence and V2 is semantically restricted by V1 : ( V1 , V2 ) ( V2 , V1 ) } ≠ RSTL= { ( CL1 , CL2 ) where CL1 and CL2 are the low level concept of the first verb and the low level concept 3 of second verb in the Chinese thesaurus , respectively , and CL2 is semantically restricted by CL1 : ( CL1 , CL2 ) ≠ ( CL2 , CL1 ) } RSTM= { ( CM1 , CM2 ) where CM1 and CM2 are the middle level concept of the first verb and the middle level concept of second verb in the Chinese thesaurus , respectively , and ML2 is semantically restricted by ML1 : ( ML1 , ML2 ) ≠ ( ML2 , ML1 ) } The relations RSTV , RSTL , and RSTM are not symmetric and not reflexive .</sentence>
				<definiendum id="0">RSTM</definiendum>
				<definiendum id="1">RSTV= {</definiendum>
				<definiendum id="2">V2</definiendum>
				<definiendum id="3">V2</definiendum>
				<definiendum id="4">≠ RSTL= {</definiendum>
				<definiendum id="5">CL2</definiendum>
				<definiendum id="6">CL2</definiendum>
				<definiendum id="7">CM2</definiendum>
				<definiens id="0">the relations : RSTV , RSTL and RSTM as follows : Definition 2 We define the relations : RSTV , RSTL , and</definiens>
				<definiens id="1">the first verb and second verb in a given SVC sentence</definiens>
			</definition>
			<definition id="9">
				<sentence>Also , the data structure of RSTM is easily represented with an adjacent matrix with the size of 21*21 4 ( Sahni , 1998 ) where the matrix M is a square matrix , whose column and row are the middle-level concept , and if M ( i , j ) = 1 then concept j is semantically restricted by concept i , otherwise ( i , j ) ∉RSTM .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">row</definiendum>
				<definiens id="0">a square matrix , whose column and</definiens>
			</definition>
</paper>

		<paper id="1706">
			<definition id="0">
				<sentence>A finite-state cascade is a sequence of non-recursive levels : phrases at one level are built on phrases at the previous level without containing same level or higher-level phrases .</sentence>
				<definiendum id="0">finite-state cascade</definiendum>
				<definiens id="0">a sequence of non-recursive levels : phrases at one level are built on phrases at the previous level without containing same level or higher-level phrases</definiens>
			</definition>
</paper>

		<paper id="1709">
</paper>

		<paper id="1210">
			<definition id="0">
				<sentence>MRS is a flat semantic formalism that works well with typed feature structures and is flexible in that it provides structures that are under-specified for scopal information .</sentence>
				<definiendum id="0">MRS</definiendum>
				<definiens id="0">a flat semantic formalism that works well with typed feature structures</definiens>
			</definition>
			<definition id="1">
				<sentence>A sign is a complex feature structure representing information of different linguistic levels of a phrase or lexical item .</sentence>
				<definiendum id="0">sign</definiendum>
				<definiens id="0">a complex feature structure representing information of different linguistic levels of a phrase or lexical item</definiens>
			</definition>
			<definition id="2">
				<sentence>Using this mechanism , it is possible to control the sequence of verbal endings : Verb stems select verbal endings via SPEC and take no SPR , derivational morphemes ( like causative or potential ) select tense endings or other derivational morphemes via MARK and subcategorize for verb stems and/or verb endings via SPR ( sase takes only verb stems ) , and tense endings take verb stems or endings as SPR and take no MARK or SPEC ( as they occur at the end of the sequence ) .</sentence>
				<definiendum id="0">SPEC</definiendum>
				<definiens id="0">stems select verbal endings via SPEC and take no SPR , derivational morphemes</definiens>
			</definition>
			<definition id="3">
				<sentence>Japanese auxiliaries combine with verbs and provide either aspectual or perspective information or information about honorification .</sentence>
				<definiendum id="0">Japanese auxiliaries</definiendum>
				<definiens id="0">combine with verbs and provide either aspectual or perspective information or information about honorification</definiens>
			</definition>
			<definition id="4">
				<sentence>We integrated ChaSen ( Asahara &amp; Matsumoto 2000 ) , a tool that provides word segmentation as well as POS tags and morphological information such as verbal inflection .</sentence>
				<definiendum id="0">ChaSen</definiendum>
			</definition>
</paper>

		<paper id="1815">
			<definition id="0">
				<sentence>ItistaggedRRifit occurs on the right boundary of a word , and formsawordwiththecharacter ( s ) onitsleft .</sentence>
				<definiendum id="0">ItistaggedRRifit</definiendum>
				<definiens id="0">occurs on the right boundary of a word , and formsawordwiththecharacter ( s ) onitsleft</definiens>
			</definition>
			<definition id="1">
				<sentence>Inthetrainingprocess , givenasequence n of characters { c 1 , … , c n } and their POC tags { t 1 , ... , t n } as training data , the purpose is to determine the parameters { a42 , a43 1 , ... , a43 k } that maximizethelikelihood Lofthetrainingdata using p : ∏∏∏ === == k j f j n i i n i i i t i h j thppL 111 ) , ( ) , ( ) ( αpiµ ( ii ) Thesuccessofthemodelintaggingdependstoa largeextentontheselectionofsuitablefeatures .</sentence>
				<definiendum id="0">Inthetrainingprocess</definiendum>
				<definiens id="0">givenasequence n of characters { c 1 , … , c n } and their POC tags { t 1 , ... , t n } as training data , the purpose is to determine the parameters { a42</definiens>
			</definition>
			<definition id="2">
				<sentence>The error-driven transformation-basedmodellearnsarankedset ofrulesbycomparingtheperfectlyPOC-tagged corpus ( the reference corpus ) with the same corpustaggedbythemaximumentropymodel ( the maxent-tagged corpus ) .</sentence>
				<definiendum id="0">error-driven transformation-basedmodellearnsarankedset ofrulesbycomparingtheperfectlyPOC-tagged corpus</definiendum>
				<definiens id="0">the maxent-tagged corpus )</definiens>
			</definition>
			<definition id="3">
				<sentence>Precision ( p ) is defined as the number of correctly segmentedwordsdividedbythetotalnumberof words in the automatically segmented corpus .</sentence>
				<definiendum id="0">Precision ( p )</definiendum>
				<definiens id="0">the number of correctly segmentedwordsdividedbythetotalnumberof words in the automatically segmented corpus</definiens>
			</definition>
</paper>

		<paper id="0207">
			<definition id="0">
				<sentence>The SmartKom research project ( a consortium of twelve academic and industrial partners ) aims at developing a multi-modal and multidomain information system .</sentence>
				<definiendum id="0">SmartKom research project</definiendum>
				<definiens id="0">a consortium of twelve academic and industrial partners ) aims at developing a multi-modal and multidomain information system</definiens>
			</definition>
</paper>

		<paper id="1803">
</paper>

		<paper id="1612">
			<definition id="0">
				<sentence>Machine Translation ( MT ) is an automatic system that provides an ability to convert a message written in one language ( source language : SL ) to another ( target language : TL ) [ 1 ] .</sentence>
				<definiendum id="0">Machine Translation</definiendum>
			</definition>
			<definition id="1">
				<sentence>The European Multilingual Information Retrieval ( EMIR ) project [ 6 ] , the MULINEX project [ 7 ] , the TwentyOne project [ 8 ] , and the cross-language retrieval track in TREC [ 9 ] conference all reflect people’s interest in A Cross System Machine Translation Thepchai Supnithi , Virach Sornlertlamvanich , Thatsanee Charoenporn Information Research and Development Division National Electronics and Computer Technology Center 112 Thailand Science Park , Paholyothin Rd. , Klong 1 , Klong Luang , Pathumthani 12120 THAILAND { thepchai , virach , thatsanee } @ nectec.or.th providing interoperability among different language processing environments and multilingual information retrieval .</sentence>
				<definiendum id="0">Multilingual Information Retrieval</definiendum>
				<definiens id="0">conference all reflect people’s interest in A Cross System Machine Translation Thepchai Supnithi</definiens>
			</definition>
			<definition id="2">
				<sentence>“Internet security” which is defined as a private standard causes the misunderstanding .</sentence>
				<definiendum id="0">“Internet security”</definiendum>
				<definiens id="0">a private standard causes the misunderstanding</definiens>
			</definition>
</paper>

		<paper id="2034">
</paper>

		<paper id="0807">
			<definition id="0">
				<sentence>CL Research’s DIMAP ( Dictionary Maintenance Programs ) disambiguates open text against WordNet or any other dictionary converted to DIMAP .</sentence>
				<definiendum id="0">CL Research’s DIMAP ( Dictionary Maintenance Programs )</definiendum>
			</definition>
			<definition id="1">
				<sentence>Details of this conversion ( which captures all WordNet information ) and the creation of a separate “phrase” dictionary for all noun and verb multiword units ( MWUs ) are described in Litkowski ( 2001 ) .</sentence>
				<definiendum id="0">MWUs</definiendum>
				<definiens id="0">captures all WordNet information ) and the creation of a separate “phrase” dictionary for all noun</definiens>
			</definition>
			<definition id="2">
				<sentence>In particular , we identified the following features : ( 1 ) whether the sense selected was the default ( first ) sense ( i.e. , no other features were identified in examining any of the senses ) , ( 2 ) whether the identified sense was based on the occurrence of the target word in an idiom , ( 3 ) whether a type ( specifically , transitivity ) factored into the sense selection , ( 4 ) whether the selected sense had any syntactic or semantic clues , ( 5 ) whether a subcategorization pattern figured into the sense selection , ( 6 ) whether the sense had a specified word form ( e.g. , capitalization , tense , or number ) , ( 7 ) whether a syntactic usage was relevant ( e.g. , nouns as modifiers or an adjective being used as a noun , such as “the blind” ) , ( 8 ) whether a selectional preference was satisfied ( for verb subjects and objects and adjective modificands ) , ( 9 ) whether we were able to use a Lesk-style context clue from the definitions or an example , and ( 10 ) topic area ( e.g. , subject fields , usage labels , or register labels associated with definitions ) .</sentence>
				<definiendum id="0">transitivity</definiendum>
				<definiens id="0">whether the sense had a specified word form ( e.g. , capitalization , tense , or number ) , ( 7 ) whether a syntactic usage was relevant ( e.g. , nouns as modifiers</definiens>
				<definiens id="1">subject fields , usage labels , or register labels associated with definitions )</definiens>
			</definition>
			<definition id="3">
				<sentence>Comparative Analysis of Features Used in WordNet and NODE Disambiguation Instance Default Idiom Kind Clue Context Topics Form With As Prefs POS WordNet 768 556 79 0 0 190 0 0 15 0 1 Adjectives 1754 1140 293 0 0 536 0 0 29 0 0 Nouns 1804 436 161 0 2 576 0 0 984 0 0 Verbs 4326 2132 533 0 2 1302 0 0 1028 0 1 Total NODE 768 324 81 0 2 249 168 14 11 11 33 Adjectives 1754 456 269 14 94 546 364 317 28 136 3 Nouns 1804 175 105 61 124 564 285 353 573 187 108 Verbs 4326 955 455 75 220 1359 817 684 612 334 144 Total The significant difference in the number of default selections between WordNet and NODE is a broad indicator that there is more information available in NODE than in WordNet .</sentence>
				<definiendum id="0">NODE</definiendum>
				<definiens id="0">a broad indicator that there is more information available in NODE than in WordNet</definiens>
			</definition>
			<definition id="4">
				<sentence>Clues ( i.e. , strong collocations ) were important for art , bar , chair , grip , post , and sense .</sentence>
				<definiendum id="0">Clues</definiendum>
				<definiens id="0">strong collocations ) were important for art , bar , chair , grip , post , and sense</definiens>
			</definition>
</paper>

		<paper id="2029">
</paper>

		<paper id="0212">
			<definition id="0">
				<sentence>The goal of this paper is to provide a basic account of conditional yes/no responses ( CRs ) : We describe the conditions under which CRs are appropriate , and how these conditions translate into a uniform approach to understanding and producing CRs.1 We focus on information-seeking dialogues between a human user and a dialogue system in the travel domain .</sentence>
				<definiendum id="0">CRs )</definiendum>
				<definiens id="0">We describe the conditions under which CRs are appropriate , and how these conditions translate into a uniform approach to understanding and producing CRs.1 We focus on information-seeking dialogues between a human user and a dialogue system in the travel domain</definiens>
			</definition>
			<definition id="1">
				<sentence>GoDis is an experimental system in the travel domain , using the information-state approach to dialogue developed the TRINDI and SIRIDUS projects ( Cooper et al. , 1999 ; Lewin et al. , 2000 ) .</sentence>
				<definiendum id="0">GoDis</definiendum>
			</definition>
</paper>

		<paper id="1303">
			<definition id="0">
				<sentence>Information assurance guarantees the authenticity of transmitted and stored information .</sentence>
				<definiendum id="0">Information assurance</definiendum>
				<definiens id="0">guarantees the authenticity of transmitted and stored information</definiens>
			</definition>
			<definition id="1">
				<sentence>Let T be a NL text , and let W be a string that is much shorter than T. We wish to generate NL text T’ such that : T’ has essentially the same meaning as T ; T ' contains W as a secret watermark , and the presence of W would hold up in court if revealed ( e.g. , W could say , “This is the Property of X , and was licensed to Y on date Z” ) ; the watermark W is not readable from T ' without knowledge of the secret key that was used to introduce W ; for someone who knows the secret key , W can be obtained from T ' without knowledge of T ( so there is no need to permanently store the original , non-watermarked copy of copyrighted material ) ; unless someone knows the secret key , W is difficult to remove from T ' without drastically changing the meaning of T ' ; the process by which W is introduced into T to obtain T ' is not secret , rather , it is the secret key that gives the scheme its security .</sentence>
				<definiendum id="0">“This</definiendum>
				<definiendum id="1">W</definiendum>
				<definiens id="0">T’ has essentially the same meaning as T ; T ' contains W as a secret watermark</definiens>
				<definiens id="1">not readable from T ' without knowledge of the secret key that was used to introduce W ; for someone who knows the secret key , W can be obtained from T ' without knowledge of T ( so there is no need to permanently store the original , non-watermarked copy of copyrighted material ) ; unless someone knows the secret key ,</definiens>
				<definiens id="2">difficult to remove from T ' without drastically changing the meaning of T ' ; the process by which W is introduced into T to obtain T ' is not secret</definiens>
			</definition>
			<definition id="2">
				<sentence>Similarly , to use another example , if an InfoSec task involves human alongside software agents , NLP is the most efficient way of handling interagent communication ( see Nirenburg and Raskin 2002 , Ch .</sentence>
				<definiendum id="0">NLP</definiendum>
			</definition>
			<definition id="3">
				<sentence>The language-independent single ontology defines the content of most lexical entries in the lexicon and in the onomasticon ( proper noun lexicon ) of each NL .</sentence>
				<definiendum id="0">language-independent single ontology</definiendum>
				<definiens id="0">defines the content of most lexical entries in the lexicon and in the onomasticon</definiens>
			</definition>
			<definition id="4">
				<sentence>The fact database contains all the remembered event instances , and text meaning representations ( TMR ) are automatically generated for each text by the analyzer part of the processing system .</sentence>
				<definiendum id="0">fact database</definiendum>
				<definiens id="0">contains all the remembered event instances , and text meaning representations ( TMR ) are automatically generated for each text by the analyzer part of the processing system</definiens>
			</definition>
</paper>

		<paper id="0606">
			<definition id="0">
				<sentence>ACL Special Interest Group in Computational Phonology ( SIGPHON ) , Philadelphia , Morphological and Phonological Learning : Proceedings of the 6th Workshop of the process corpus data for an analysis to be performed by a human morphologist , or as the first step of a fully automated morphological learning program , to be followed , for example , by a rule induction procedure that extracts correspondence patterns from paired forms .</sentence>
				<definiendum id="0">Phonological Learning</definiendum>
				<definiens id="0">Proceedings of the 6th Workshop of the process corpus data for an analysis to be performed by a human morphologist , or as the first step of a fully automated morphological learning program , to be followed</definiens>
			</definition>
			<definition id="1">
				<sentence>Mutual information ( first introduced to computational linguistics by Church and Hanks ( 1989 ) ) is one of many measures that seems to be roughly correlated to the degree of semantic relatedness between words .</sentence>
				<definiendum id="0">Mutual information</definiendum>
				<definiens id="0">one of many measures that seems to be roughly correlated to the degree of semantic relatedness between words</definiens>
			</definition>
			<definition id="2">
				<sentence>We tested our procedure on the German APA corpus , a corpus of newswire containing over twenty-eight million word tokens , and on the English Brown corpus ( Kuˇcera and Francis , 1967 ) , a balanced corpus containing less than one million two hundred thousand word tokens .</sentence>
				<definiendum id="0">German APA corpus</definiendum>
				<definiens id="0">a balanced corpus containing less than one million two hundred thousand word tokens</definiens>
			</definition>
			<definition id="3">
				<sentence>Moreover , after some preliminary experimentation , we also decided to remove words longer than 9 characters from the German list ( this corresponds to trimming words whose length is one standard deviation or more above the average token length ) .</sentence>
				<definiendum id="0">list</definiendum>
				<definiens id="0">one standard deviation or more above the average token length )</definiens>
			</definition>
			<definition id="4">
				<sentence>However , Yarowksy and Wicentowski restricted the possible matchings to pairs in which one member is an inflected verb form , and the other member is a potential verbal root , whereas in our experiments any word in the corpus ( as long as it was below a certain frequency threshold , and it was recognized by the XEROX analyzer ) could be matched with any other word in the corpus .</sentence>
				<definiendum id="0">XEROX analyzer )</definiendum>
				<definiens id="0">an inflected verb form</definiens>
			</definition>
</paper>

		<paper id="0215">
			<definition id="0">
				<sentence>A Request for action is modelled as a proposal whose content is of the form ( Should-Do Agt Action ) .</sentence>
				<definiendum id="0">Request for action</definiendum>
			</definition>
			<definition id="1">
				<sentence>A question is a proposal for the action to provide certain information .</sentence>
				<definiendum id="0">question</definiendum>
				<definiens id="0">a proposal for the action to provide certain information</definiens>
			</definition>
			<definition id="2">
				<sentence>Clearly , negotiation is a type of problemsolving ( Di Eugenio et al. , 1998 ) .</sentence>
				<definiendum id="0">negotiation</definiendum>
			</definition>
			<definition id="3">
				<sentence>For example , it is usually not the case that the name of a DP is a negotiable issue ; this is why it would perhaps seem counterintuitive to view an introduction ( \Hi , my name is NN '' ) as a proposal .</sentence>
				<definiendum id="0">DP</definiendum>
				<definiens id="0">a negotiable issue</definiens>
			</definition>
			<definition id="4">
				<sentence>The lu fleld contains information about the speaker of , and the moves performed in , latest utterance .</sentence>
				<definiendum id="0">lu fleld</definiendum>
				<definiens id="0">contains information about the speaker of , and the moves performed in , latest utterance</definiens>
			</definition>
			<definition id="5">
				<sentence>An open stack is a stack where non-topmost elements are accessible for inspection and deletion .</sentence>
				<definiendum id="0">open stack</definiendum>
				<definiens id="0">a stack where non-topmost elements are accessible for inspection and deletion</definiens>
			</definition>
</paper>

		<paper id="1036">
			<definition id="0">
				<sentence>In the maximum entropy model ( Della Pietra et al. , 1997 ) , the conditional probability of the output y given the context x can be estimated as the following p λ ( y | x ) of the form of the exponential family , where binary-valued indicator functions called feature functions f i ( x , y ) are introduced for expressing a set of “features” , or “attributes” of the context x and the output y.Aparameter λ i is introduced for each feature f i , and is estimated from a training data .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
			</definition>
			<definition id="1">
				<sentence>In those event expressions , systems indicates the list of the indices of the systems which output the named entity , mlength gives the number of the constituent morphemes , NEtag gives one of the nine named entity types , POS gives the list of parts-of-speech of the constituent morphemes , and class NE indicates whether the named entity is a correct one compared against the gold standard ( “+” ) , or the one over-generated by the systems ( “−” ) .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">the list of the indices of the systems which output the named entity , mlength gives the number of the constituent morphemes , NEtag gives one of the nine named entity types</definiens>
				<definiens id="1">gives the list of parts-of-speech of the constituent morphemes , and class NE indicates whether the named entity is a correct one compared against the gold standard</definiens>
			</definition>
			<definition id="2">
				<sentence>A decision list ( Yarowsky , 1994 ) is a sorted list of decision rules , each of which decides the value of class given some features f of an event .</sentence>
				<definiendum id="0">decision list</definiendum>
				<definiens id="0">a sorted list of decision rules , each of which decides the value of class given some features f of an event</definiens>
			</definition>
			<definition id="3">
				<sentence>As the training data sets TrI and TrC , we evaluate the following two assignments ( a ) and ( b ) , where D CRL denotes the IREX workshop’s training data : ( a ) TrI : D CRL − D 200 CRL ( 200 articles from D CRL ) TrC : D 200 CRL ( b ) TrI = TrC = D CRL We use the IREX workshop’s test data for Ts .</sentence>
				<definiendum id="0">D CRL</definiendum>
				<definiendum id="1">TrI</definiendum>
				<definiens id="0">the IREX workshop’s training data : ( a )</definiens>
				<definiens id="1">b ) TrI = TrC = D CRL We use the IREX workshop’s test data for Ts</definiens>
			</definition>
</paper>

		<paper id="0221">
			<definition id="0">
				<sentence>We train and test the DATE tagger on various combinations of the DARPA Communicator June-2000 and October-2001 human-computer corpora , and the CMU human-human corpus in the travel planning domain .</sentence>
				<definiendum id="0">CMU human-human</definiendum>
				<definiens id="0">corpus in the travel planning domain</definiens>
			</definition>
			<definition id="1">
				<sentence>U : ANY TIME S : From Seoul .</sentence>
				<definiendum id="0">U</definiendum>
			</definition>
			<definition id="2">
				<sentence>We report the results of applying a rule-induction method to train and test DATE taggers on various combinations of the DARPA Communicator June2000 and October-2001 HC corpora , and the CMU HH corpus in the travel planning domain .</sentence>
				<definiendum id="0">CMU HH</definiendum>
				<definiens id="0">corpus in the travel planning domain</definiens>
			</definition>
			<definition id="3">
				<sentence>The DARPA Communicator HC dialogue corpus consists of the June2000 corpus and the October-2001 corpus .</sentence>
				<definiendum id="0">DARPA Communicator HC dialogue corpus</definiendum>
			</definition>
			<definition id="4">
				<sentence>The HH dialogue corpus consists of the CMUcorpus ( Eskenazi et al. , 1999 ) .</sentence>
				<definiendum id="0">HH dialogue corpus</definiendum>
			</definition>
			<definition id="5">
				<sentence>The CMU-corpus consists of 38 dialogues with a total of 1062 travel agent utterances .</sentence>
				<definiendum id="0">CMU-corpus</definiendum>
				<definiens id="0">consists of 38 dialogues with a total of 1062 travel agent utterances</definiens>
			</definition>
			<definition id="6">
				<sentence>DATE classi es each utterance along three cross-cutting orthogonal dimensions of utterance classi cation : ( 1 ) a SPEECH ACT dimension ; ( 2 ) a CONVERSATIONAL-DOMAIN dimension ; and ( 3 ) a TASK-SUBTASK dimension .</sentence>
				<definiendum id="0">DATE classi</definiendum>
				<definiens id="0">es each utterance along three cross-cutting orthogonal dimensions of utterance classi cation : ( 1 ) a SPEECH ACT dimension ; ( 2 ) a CONVERSATIONAL-DOMAIN dimension ; and ( 3 ) a TASK-SUBTASK dimension</definiens>
			</definition>
			<definition id="7">
				<sentence>The SPEECH ACT dimension captures distinctions between distinct communicative goals such as requesting information ( REQUEST-INFO ) , presenting information ( PRESENT-INFO ) and making offers ( OFFER ) to act on behalf of the caller .</sentence>
				<definiendum id="0">SPEECH ACT dimension</definiendum>
				<definiens id="0">requesting information ( REQUEST-INFO ) , presenting information ( PRESENT-INFO ) and making offers ( OFFER ) to act on behalf of the caller</definiens>
			</definition>
			<definition id="8">
				<sentence>DATE adds a third domain called about-situation-frame , to distinguish utterances that provide information about the interactional context , e.g. Try saying a short sentence , or I know about 500 international destinations .</sentence>
				<definiendum id="0">DATE</definiendum>
				<definiens id="0">adds a third domain called about-situation-frame , to distinguish utterances that provide information about the interactional context</definiens>
			</definition>
			<definition id="9">
				<sentence>The usr-rec-string-identity feature is a Training Data Test Data Dim Maj. Cl .</sentence>
				<definiendum id="0">usr-rec-string-identity feature</definiendum>
			</definition>
</paper>

		<paper id="1302">
			<definition id="0">
				<sentence>Information retrieval engines , text summarizers , question answering and other dialog systems , and language translators provide complementary functionalities which can be combined to serve a variety of users , ranging from the casual user asking questions of the web to a sophisticated , professional knowledge worker .</sentence>
				<definiendum id="0">Information retrieval engines</definiendum>
				<definiens id="0">systems , and language translators provide complementary functionalities which can be combined to serve a variety of users , ranging from the casual user asking questions of the web to a sophisticated , professional knowledge worker</definiens>
			</definition>
			<definition id="1">
				<sentence>Chances are that hybrid combinations of symbolic and stochastic translation engines , able to learn relevant terminology from translation memories will eventually achieve a level of performance that will make them useful for the professional translator .</sentence>
				<definiendum id="0">Chances</definiendum>
				<definiens id="0">hybrid combinations of symbolic and stochastic translation engines</definiens>
			</definition>
			<definition id="2">
				<sentence>The grammar consists of a lexicon , and rules that syntactically and semantically combine words and phrases into larger phrases and sentences .</sentence>
				<definiendum id="0">grammar</definiendum>
				<definiens id="0">consists of a lexicon , and rules that syntactically and semantically combine words and phrases into larger phrases and sentences</definiens>
			</definition>
			<definition id="3">
				<sentence>The generator user has to specify not only the semantic content of the desired text , but also its pragmatic – interpersonal and situational – effects .</sentence>
				<definiendum id="0">generator user</definiendum>
				<definiens id="0">has to specify not only the semantic content of the desired text , but also its pragmatic – interpersonal and situational – effects</definiens>
			</definition>
			<definition id="4">
				<sentence>A grand challenge is the automated generation of coordinated speech , natural language , gesture , animation , non-speech audio , generation , possibly delivered via interactive , animated lifelike agents .</sentence>
				<definiendum id="0">grand challenge</definiendum>
			</definition>
			<definition id="5">
				<sentence>Developers of machine translation systems , which from the beginning have involved large vocabularies , have long recognized the lexicon as a critical ( and perhaps the critical ) system resource .</sentence>
				<definiendum id="0">machine translation systems</definiendum>
				<definiens id="0">a critical ( and perhaps the critical ) system resource</definiens>
			</definition>
</paper>

		<paper id="1000">
</paper>

		<paper id="1505">
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>We will study the problem of aligning an English sentence to a French sentence and we will use the word alignment of the IBM statistical translation models ( Brown et al. , 1993 ) .</sentence>
				<definiendum id="0">IBM statistical translation models</definiendum>
				<definiens id="0">study the problem of aligning an English sentence to a French sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The Sentence Alignment Error refers to the loss function that gives a penalty of 1 for any errorful alignment : , where is the indicator function of the set .</sentence>
				<definiendum id="0">Sentence Alignment Error</definiendum>
				<definiens id="0">any errorful alignment : , where is the indicator function of the set</definiens>
			</definition>
			<definition id="2">
				<sentence>The AER makes an explicit distinction between ambiguous and unambiguous word alignments .</sentence>
				<definiendum id="0">AER</definiendum>
				<definiens id="0">makes an explicit distinction between ambiguous and unambiguous word alignments</definiens>
			</definition>
			<definition id="3">
				<sentence>A complete path through the WFST is a sequence of transitions given by such that and .</sentence>
				<definiendum id="0">WFST</definiendum>
				<definiens id="0">a sequence of transitions given by such that and</definiens>
			</definition>
			<definition id="4">
				<sentence>The lattice transition posterior probability is the sum of the posterior probabilities of all lattice paths passing through the transition .</sentence>
				<definiendum id="0">lattice transition posterior probability</definiendum>
				<definiens id="0">the sum of the posterior probabilities of all lattice paths passing through the transition</definiens>
			</definition>
			<definition id="5">
				<sentence>Therefore , the MBR alignment ( Equation 9 ) can be found in terms of the modified link weight for each alignment link ( 10 ) We can rewrite the above equation as ( 11 ) We now derive MBR alignment under the Generalized Alignment Error loss function ( Equation 3 ) .</sentence>
				<definiendum id="0">MBR alignment</definiendum>
				<definiens id="0">be found in terms of the modified link weight for each alignment link ( 10 ) We can rewrite the above equation as ( 11 ) We now derive MBR alignment under the Generalized Alignment Error loss function</definiens>
			</definition>
			<definition id="6">
				<sentence>The MBR alignment ( Equation 12 ) can be found in terms of the modified link weight for each alignment link ( 13 ) The MBR alignment procedures under the and loss functions begin with a WFST that contains the alignment probabilities as described in Section 4.1 .</sentence>
				<definiendum id="0">MBR alignment</definiendum>
				<definiendum id="1">MBR alignment</definiendum>
				<definiens id="0">procedures under the and loss functions begin with a WFST that contains the alignment probabilities as described in Section 4.1</definiens>
			</definition>
			<definition id="7">
				<sentence>With defined as in Equation 14 , the Generalized Alignment Error loss function ( Equation 3 ) is called the Parse-Tree Syntactic Distance ( ) .</sentence>
				<definiendum id="0">Generalized Alignment Error loss function</definiendum>
			</definition>
			<definition id="8">
				<sentence>The WFST framework involves building a transducer for each constituent of the IBM-3 Alignment Models : the word fertility model ; the NULL fertility model ; and the word translation model ( Section 5.4 ) .</sentence>
				<definiendum id="0">WFST framework</definiendum>
				<definiendum id="1">NULL fertility</definiendum>
				<definiens id="0">involves building a transducer for each constituent of the IBM-3 Alignment Models : the word fertility model</definiens>
			</definition>
			<definition id="9">
				<sentence>Generalized Alignment Error Rates Decoder AER PTSD-S POSD-S AWCD-S PTSD-A POSD-A AWCD-A ML 18.13 3.13 4.35 4.69 29.39 51.36 54.58 MBR-AE 14.87 1.34 1.89 1.94 19.81 36.42 38.58 MBR-PTSD 23.26 0.62 0.69 0.82 14.45 26.76 28.42 MBR-POSD 28.60 2.43 0.69 3.23 15.70 26.28 29.48 MBR-AWCD 24.71 1.00 0.95 0.86 14.92 26.83 28.39 Table 1 : Performance ( % ) of the MBR decoders under the Alignment Error and Generalized Alignment Error Rates .</sentence>
				<definiendum id="0">Generalized Alignment Error Rates Decoder AER PTSD-S POSD-S AWCD-S PTSD-A POSD-A AWCD-A</definiendum>
			</definition>
			<definition id="10">
				<sentence>MBR alignment is a promising modeling framework for the detailed linguistic annotation of bilingual texts .</sentence>
				<definiendum id="0">MBR alignment</definiendum>
				<definiens id="0">a promising modeling framework for the detailed linguistic annotation of bilingual texts</definiens>
			</definition>
</paper>

		<paper id="1410">
			<definition id="0">
				<sentence>FAQFinder is a web-based , natural language Q &amp; A system which uses Usenet Frequently Asked Questions ( FAQ ) les to answer users ' questions .</sentence>
				<definiendum id="0">FAQFinder</definiendum>
			</definition>
			<definition id="1">
				<sentence>DCV is a variation of the standard cross-validation ( CV ) where the data is partitioned according to domains instead of random 2 We used k = 3 and majorityvoting scheme for all experiments in our currentwork .</sentence>
				<definiendum id="0">DCV</definiendum>
				<definiens id="0">a variation of the standard cross-validation ( CV ) where the data is partitioned according to domains instead of random 2 We used k = 3 and majorityvoting scheme for all experiments in our currentwork</definiens>
			</definition>
			<definition id="2">
				<sentence>Gain Ratio ( GR ) is a metric often used in classi cation systems ( notably in C4.5 ) for measuring howwell a feature predicts the categories of the examples .</sentence>
				<definiendum id="0">Gain Ratio ( GR )</definiendum>
				<definiens id="0">a metric often used in classi cation systems</definiens>
			</definition>
			<definition id="3">
				<sentence>GR is a normalized version of another metric called Information Gain ( IG ) , which measures the informativeness of a feature by the number of bits required to encode the examples if they are partitioned into two sets , based on the presence or absence of the feature .</sentence>
				<definiendum id="0">GR</definiendum>
				<definiens id="0">a normalized version of another metric called Information Gain ( IG ) , which measures the informativeness of a feature by the number of bits required to encode the examples if they are partitioned into two sets , based on the presence or absence of the feature</definiens>
			</definition>
			<definition id="4">
				<sentence>Given a collection of examples S , the Gain Ratio of a feature A , GR ( S ; ; A ) , is de ned as : GR ( S ; ; A ) = IG ( S ; ; A ) SI ( S ; ; A ) where IG ( S ; ; A ) isthe InformationGainde ned to be : IG ( S ; ; A ) = ; P m i=1 Pr ( c i ) log 2 Pr ( c i ) +Pr ( A ) P m i=1 Pr ( c i jA ) log 2 Pr ( c i jA ) +Pr ( A ) P m i=1 Pr ( c i jA ) log 2 Pr ( c i jA ) and SI ( S ; ; A ) is the Splitting Information dened to be : SI ( S ; ; A ) = ; Pr ( A ) log 2 Pr ( A ) ; Pr ( A ) log 2 Pr ( A ) 3 The description of Information Gain here is for binary partitioning .</sentence>
				<definiendum id="0">Gain Ratio of a feature A , GR</definiendum>
				<definiendum id="1">SI ( S ; ; A )</definiendum>
				<definiendum id="2">Pr</definiendum>
				<definiendum id="3">Pr</definiendum>
				<definiens id="0">de ned as : GR ( S ; ; A ) = IG ( S ; ; A ) SI ( S ; ; A ) where IG ( S ; ; A ) isthe InformationGainde ned to be : IG ( S ; ; A ) = ; P m</definiens>
				<definiens id="1">the Splitting Information dened to be : SI ( S ; ; A ) = ;</definiens>
			</definition>
</paper>

		<paper id="1703">
			<definition id="0">
				<sentence>In our case , the “stuﬀ” consists of raw paged-based information presentations , such as illustrated books , newspapers ( print and online versions ) , instructional texts , manuals , and so on ; the “data” is then highly structured re-representations of these documents that bring out parallel but interrelated dimensions of organization crucial for the total eﬀect , or meaning , of the ‘page’ .</sentence>
				<definiendum id="0">“stuﬀ”</definiendum>
				<definiens id="0">consists of raw paged-based information presentations , such as illustrated books , newspapers ( print and online versions ) , instructional texts , manuals , and so on ; the “data” is then highly structured re-representations of these documents that bring out parallel but interrelated dimensions of organization crucial for the total eﬀect , or meaning , of the ‘page’</definiens>
			</definition>
			<definition id="1">
				<sentence>Further constraints that are known to determine document design include : canvasconstraints , arising out of the physical nature of the object being produced ( e.g. , page or screen , fold-geometry in leaﬂets , and so on ) , productionconstraints , arising out of the production technology , and consumption constraints , arising out of the time , place , and manner of acquiring and consuming the document .</sentence>
				<definiendum id="0">consumption constraints</definiendum>
				<definiens id="0">the physical nature of the object being produced ( e.g. , page or screen , fold-geometry in leaﬂets</definiens>
			</definition>
			<definition id="2">
				<sentence>These base level units range over textual , graphical and layout elements and give a comprehensive account of the material on the page , i.e. they comprise everything which can be seen on the page/pages of the document , including : orthographic sentences , sentence fragments initiating a list , headings , titles , headlines , photos , drawings , diagrams , ﬁgures ( without caption ) , captions of photos , drawings , diagrams , tables , text in photos , drawings , diagrams , icons , tables cells , list headers , list items , list labels ( itemizers ) , items in a menu , page numbers , footnotes ( without footnote label ) , footnote labels , running heads , emphasized text , horizontal or vertical lines which function as delimiters between columns or rows , lines , arrows , and polylines which connect other base units .</sentence>
				<definiendum id="0">base level units</definiendum>
				<definiens id="0">range over textual , graphical and layout elements and give a comprehensive account of the material on the page</definiens>
				<definiens id="1">orthographic sentences , sentence fragments initiating a list , headings , titles , headlines , photos , drawings , diagrams , ﬁgures ( without caption ) , captions of photos , drawings , diagrams , tables , text in photos , drawings , diagrams , icons , tables cells , list headers , list items , list labels ( itemizers ) , items in a menu , page numbers , footnotes ( without footnote label</definiens>
			</definition>
			<definition id="3">
				<sentence>Each of the more abstract layers is represented formally as a further structured XML speciﬁcation whose precise informational content and form is in turn deﬁned by an appropriate Document Type Deﬁnition ( DTD ) .</sentence>
				<definiendum id="0">form</definiendum>
				<definiendum id="1">DTD</definiendum>
				<definiens id="0">a further structured XML speciﬁcation whose precise informational content and</definiens>
			</definition>
			<definition id="4">
				<sentence>Space precludes a detailed account of the organization of all the levels of the annotation scheme .</sentence>
				<definiendum id="0">Space</definiendum>
				<definiens id="0">precludes a detailed account of the organization of all the levels of the annotation scheme</definiens>
			</definition>
			<definition id="5">
				<sentence>For this , we introduce an area model , which serves to determine the position of each layout-chunk/layoutleaf in an abstract , but fully explicit , way .</sentence>
				<definiendum id="0">area model</definiendum>
				<definiens id="0">serves to determine the position of each layout-chunk/layoutleaf in an abstract , but fully explicit , way</definiens>
			</definition>
			<definition id="6">
				<sentence>Perhaps , to oﬀer an NLP analogy : whereas the XML modelling decisions correspond to a ﬁne-scaled phonetic description of a language event , we are in the GeM project searching for the higher levels of abstraction corresponding to the grammar , semantics and pragmatics of the language events .</sentence>
				<definiendum id="0">NLP analogy</definiendum>
				<definiens id="0">whereas the XML modelling decisions correspond to a ﬁne-scaled phonetic description of a language event</definiens>
			</definition>
</paper>

		<paper id="0605">
			<definition id="0">
				<sentence>In a natural sense , under that assumption , an explicit description of the behavior of a word w in a corpus is a sparse vector L = [ l 1 , l 2 , … , l V ] , of length V ( where “V” is the number of words in the vocabulary of the corpus ) , indicating by l i how often each word v i occurs immediately to the left of w , and also an similar vector R , also of length V , indicating how often each word occurs immediately to the right of w. Paraphrasing this , we may view the syntactic behavior of a word in a corpus as being expressed by its location in a space of 2V dimensions , or a vector from the origin to this location ; this space has a natural decomposition into two spaces , called Left and Right , each of dimension V. Needless to say , such a representation is not directly illuminating -nor does it provide a way to cogently present similarities or clusterings among words .</sentence>
				<definiendum id="0">“V”</definiendum>
			</definition>
			<definition id="1">
				<sentence>The degree of a vertex of a graph is the number of edges adjacent to it ; the degree of the m th vertex , d ( v m ) is thus the sum of the values in the m th row of M. If we define D as the diagonal matrix whose entry D ( m , m ) is d ( v m ) , the degree of v m , then the laplacian of the graph is defined as D – M. The normalized laplacian L is defined as D ½ ( D – M ) D ½ .</sentence>
				<definiendum id="0">degree of a vertex of a graph</definiendum>
				<definiendum id="1">laplacian L</definiendum>
				<definiens id="0">the number of edges adjacent to it ; the degree of the m th vertex , d ( v m ) is thus the sum of the values in the m th row of M. If we define D as the diagonal matrix whose entry D ( m , m ) is d ( v m ) , the degree of v m</definiens>
			</definition>
			<definition id="2">
				<sentence>In Figure 1 ( LeftGraph ) , the bottom corner consists primarily of non-finite verbs ( be , do , make ) ; the left corner of finite verbs ( was , had , has ) ; the right corner primarily of nouns ( world , way , system ) ; while the top shows little homogeneity , though it includes the prepositions .</sentence>
				<definiendum id="0">LeftGraph</definiendum>
				<definiendum id="1">non-finite verbs</definiendum>
				<definiens id="0">has ) ; the right corner primarily of nouns ( world , way , system</definiens>
			</definition>
			<definition id="3">
				<sentence>Bottom : social national white local political personal private strong medical final black French technical nuclear british health husband blue Left : most number kind full type secretary amount front instead member sort series rest types piece image lack Right : of in for on by at from into after through under since during against among within along across including near Top : going want seems seemed able wanted likely difficult according due tried decided trying related try</sentence>
				<definiendum id="0">Bottom</definiendum>
				<definiens id="0">social national white local political personal private strong medical final black French technical nuclear british health husband</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>The actual ( joint ) distribution is not in the family of NB models , and so it can not be learned perfectly .</sentence>
				<definiendum id="0">NB</definiendum>
				<definiens id="0">models , and so it can not be learned perfectly</definiens>
			</definition>
			<definition id="1">
				<sentence>In the SENSEVAL competition ( Kilgarriff , 1998 ) , we guess sense distributions , and our score is the sum of the masses assigned to the correct senses .</sentence>
				<definiendum id="0">SENSEVAL competition</definiendum>
				<definiens id="0">the sum of the masses assigned to the correct senses</definiens>
			</definition>
			<definition id="2">
				<sentence>We optimized JL ( using the RFEs ) .3 We also optimized SCL and ( the log of ) CL , using a conjugate gradient ( CG ) method ( Press et al. , 1988 ) .4 For CL and SCL , we optimized each objective both over the space of all distributions and over the subspace of non-deficient models ( giving CL and SCL ) .</sentence>
				<definiendum id="0">JL</definiendum>
			</definition>
			<definition id="3">
				<sentence>The x-axis is the average number of training instances per sense , weighted by the frequency of that sense in the test data .</sentence>
				<definiendum id="0">x-axis</definiendum>
			</definition>
			<definition id="4">
				<sentence>JL is the standard HMM .</sentence>
				<definiendum id="0">JL</definiendum>
				<definiens id="0">the standard HMM</definiens>
			</definition>
			<definition id="5">
				<sentence>CL duplicates the simple CRFs in ( Lafferty et al. , 2001 ) .</sentence>
				<definiendum id="0">CL</definiendum>
			</definition>
			<definition id="6">
				<sentence>o1 o2 o3 : : : : on s1 s2 s3 sn ( a ) o1 o2 o3 : : : : on s1 s2 s3 sn ( b ) Figure 6 : Graphical models : ( a ) the downward HMM , and ( b ) the upward conditional Markov model ( CMM ) .</sentence>
				<definiendum id="0">CMM</definiendum>
				<definiens id="0">Graphical models : ( a ) the downward HMM , and ( b ) the upward conditional Markov model</definiens>
			</definition>
			<definition id="7">
				<sentence>Label bias is a type of explaining-away phenomenon ( Pearl , 1988 ) which can be attributed to the local conditional modeling of each state .</sentence>
				<definiendum id="0">Label bias</definiendum>
				<definiens id="0">a type of explaining-away phenomenon ( Pearl , 1988 ) which can be attributed to the local conditional modeling of each state</definiens>
			</definition>
</paper>

		<paper id="1606">
			<definition id="0">
				<sentence>To eliminate noise and to reduce the number of CCI , refinement proceesing is applied Japanese Corpus COBALT-J/K ( Japanese-to-Korean MT system ) Sense Tagged Korean Corpus Partial Parsing &amp; Pattern Scanning Raw CCI CCI Refinement Processing Refined CCI Feature Set Construction Neural Net Construction Feature Set Network Construction Neural Network Network Learning Stored in MT Dictionary Network Parameters Figure 1 .</sentence>
				<definiendum id="0">refinement proceesing</definiendum>
				<definiendum id="1">Corpus COBALT-J/K</definiendum>
				<definiens id="0">Japanese-to-Korean MT system ) Sense Tagged Korean Corpus Partial Parsing &amp; Pattern Scanning Raw CCI CCI Refinement Processing Refined CCI Feature Set Construction Neural Net Construction Feature Set Network Construction Neural Network Network Learning Stored in MT Dictionary Network Parameters Figure 1</definiens>
			</definition>
			<definition id="1">
				<sentence>COBALT-J/K ( Collocation-Based Language r from Japanese to Korean ) is a high-quality ical MT system developed by POSTECH .</sentence>
				<definiendum id="0">COBALT-J/K</definiendum>
				<definiens id="0">a high-quality ical MT system developed by POSTECH</definiens>
			</definition>
			<definition id="2">
				<sentence>3 Because of it the used in our sense clas shown in Figure 3 , each n represents a C 1 , C 2 , C 3 , ... } , i , W ( S i ) ) as a knowledge source for WSD of The more cription of the CCI extraction is Construction of Neural Network Neural Network Architecture s strong capability for classification , multilayer feedforward neural network is sification system .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">Construction of Neural Network Neural Network Architecture s strong capability for classification</definiens>
			</definition>
			<definition id="3">
				<sentence>COBALT-K/ naptic weights ) and 54 integers ( for input each homograph , which is a Word Sense Disambiguation ybrid method , which mbines the advantage of corpus-based and methods .</sentence>
				<definiendum id="0">COBALT-K/ naptic weights</definiendum>
				<definiendum id="1">Word Sense Disambiguation ybrid method</definiendum>
				<definiens id="0">mbines the advantage of corpus-based and methods</definiens>
			</definition>
</paper>

		<paper id="2024">
			<definition id="0">
				<sentence>This sentence contains four named entities : Wol and Del Bosque are persons , Argentina is a location and Real Madrid is a organization .</sentence>
				<definiendum id="0">Argentina</definiendum>
				<definiens id="0">a location</definiens>
				<definiens id="1">a organization</definiens>
			</definition>
			<definition id="1">
				<sentence>Theyhave usedthe data for developing a named-entity recognition system that includes a machine learning component .</sentence>
				<definiendum id="0">Theyhave usedthe data for</definiendum>
				<definiens id="0">developing a named-entity recognition system that includes a machine learning component</definiens>
			</definition>
			<definition id="2">
				<sentence>The data consists of words , entity tags and partof-speech tags which have been derived by a Dutch part-of-speech tagger ( Daelemans et al. , 1996 ) .</sentence>
				<definiendum id="0">data</definiendum>
			</definition>
			<definition id="3">
				<sentence>Precision is the percentage of named entities found by the learning system that are correct .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the percentage of named entities found by the learning system that are correct</definiens>
			</definition>
			<definition id="4">
				<sentence>Recall is the percentage of named entities present in the corpus that are found by the system .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the percentage of named entities present in the corpus that are found by the system</definiens>
			</definition>
</paper>

		<paper id="2015">
</paper>

		<paper id="1110">
			<definition id="0">
				<sentence>The Papillon project applies some tools and methods to develop multipurpose , multilingual lexical data collaboratively on Internet .</sentence>
				<definiendum id="0">Papillon project</definiendum>
				<definiens id="0">applies some tools and methods to develop multipurpose , multilingual lexical data collaboratively on Internet</definiens>
			</definition>
			<definition id="1">
				<sentence>The framework consists in the definition of an XML namespace 1 called DML ( Dictionary Markup Language ) .</sentence>
				<definiendum id="0">framework</definiendum>
			</definition>
			<definition id="2">
				<sentence>A lexie is a complete monolingual entry .</sentence>
				<definiendum id="0">lexie</definiendum>
				<definiens id="0">a complete monolingual entry</definiens>
			</definition>
</paper>

		<paper id="1102">
			<definition id="0">
				<sentence>WordNet is a lexicon comprising of nouns , verbs , adjectives and adverbs .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a lexicon comprising of nouns , verbs , adjectives and adverbs</definiens>
			</definition>
</paper>

		<paper id="1034">
</paper>

		<paper id="0105">
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>Adopting a similar approach as FAQFinder ( Hammond et al. , 1995 ) , AskJeeves maintains a database of questions and webpages that provide answers to them .</sentence>
				<definiendum id="0">AskJeeves</definiendum>
				<definiens id="0">maintains a database of questions and webpages that provide answers to them</definiens>
			</definition>
			<definition id="1">
				<sentence>To learn an optimal control strategy that maximizes the cumulative reward over time , an evaluation function Q ( s ; a ) is defined as follows : Q ( s ; a ) · r ( s ; a ) + maxa0Q ( – ( s ; a ) ; a0 ) ( 1 ) In other words , Q ( s ; a ) is the immediate reward , r ( s ; a ) , plus the discounted maximum future reward starting from the new state – ( s ; a ) .</sentence>
				<definiendum id="0">Q ( s</definiendum>
				<definiens id="0">maximizes the cumulative reward over time , an evaluation function Q ( s ; a ) is defined as follows : Q ( s ; a ) · r ( s ; a ) + maxa0Q ( – ( s ; a ) ; a0 ) ( 1 ) In other words</definiens>
				<definiens id="1">the immediate reward , r ( s ; a ) , plus the discounted maximum future reward starting from the new state – ( s ; a )</definiens>
			</definition>
			<definition id="2">
				<sentence>As shown in Figure 1 , RISQUE adopts a hybrid architecture 5Morphological and synonym expansions are applied at the outset , which was shown to result in better performance than optional application of those rules .</sentence>
				<definiendum id="0">RISQUE</definiendum>
				<definiens id="0">adopts a hybrid architecture 5Morphological and synonym expansions</definiens>
			</definition>
			<definition id="3">
				<sentence>Hit List Accumulation Ontology Hub-Page Identifier Natural Language Question Question Pre-Processing Top n Hits for Question Question Understanding NP Sequencing and Retrieval Query Formulation Figure 1 : RISQUE Architecture that combines the utility of traditional knowledgebased methods and statistical approaches .</sentence>
				<definiendum id="0">RISQUE Architecture</definiendum>
				<definiens id="0">combines the utility of traditional knowledgebased methods and statistical approaches</definiens>
			</definition>
			<definition id="4">
				<sentence>The hub-page identifier consists of a mapping from a subset of the named entities in the ontology to their corresponding hub-pages.8 For each question , the hub-page identifier retrieves the hub-page for the most salient NP , if possible , which is presented as the first entry in the hit list .</sentence>
				<definiendum id="0">hub-page identifier</definiendum>
				<definiens id="0">consists of a mapping from a subset of the named entities in the ontology to their corresponding hub-pages.8 For each question , the hub-page identifier retrieves the hub-page for the most salient NP , if possible</definiens>
			</definition>
			<definition id="5">
				<sentence>RISQUE utilizes a two-pronged approach to generate hit lists for answering natural language questions .</sentence>
				<definiendum id="0">RISQUE</definiendum>
			</definition>
			<definition id="6">
				<sentence>On the other hand , RISQUE adopts a statistical iterative query formulation and retrieval mechanism that generates new queries by applying transformation rules to previously-issued queries .</sentence>
				<definiendum id="0">RISQUE</definiendum>
				<definiens id="0">adopts a statistical iterative query formulation and retrieval mechanism that generates new queries by applying transformation rules to previously-issued queries</definiens>
			</definition>
</paper>

		<paper id="1510">
			<definition id="0">
				<sentence>y Tools for grammar testing : these tools allow linguists to compare results of two versions of 1 This component is further divided into the Sketch component , which produces trees with default attachment of constituents , and the Portrait component , which finds the best attachment sites ( Heidorn , 2000 ) .</sentence>
				<definiendum id="0">y Tools for grammar testing</definiendum>
				<definiendum id="1">component</definiendum>
				<definiens id="0">finds the best attachment sites</definiens>
			</definition>
			<definition id="1">
				<sentence>For regression testing , we also have a means to distribute the processing onto multiple CPUs : the processing cluster currently consists of 19 machines with 2 CPUs each ( 500MHz , 128~512MB RAM ) , which parses the entire WSJ section of Penn Treebank ( 49,208 sentences ) in 3 minutes and 10 seconds ( or 259 sentences/sec ) , and a one million-sentence Nikkei newspaper corpus of Japanese in about 30 minutes ( 550+ sentences/sec ) .</sentence>
				<definiendum id="0">processing cluster</definiendum>
				<definiens id="0">parses the entire WSJ section of Penn Treebank ( 49,208 sentences ) in 3 minutes and 10 seconds</definiens>
			</definition>
</paper>

		<paper id="0907">
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>Although , in principle , any clustering algorithm can be used , most previous work uses a singlelink clustering algorithm to impose coreference partitions.2 An implicit assumption in the choice of the single-link clustering algorithm is that coreference resolution is viewed as anaphora resolution , i.e. the goal during clustering is to find an antecedent for each anaphoric NP in a document.3 Three intrinsic properties of coreference4 , however , make the formulation of the problem as a classification-based single-link clustering task potentially undesirable : Coreference is a rare relation .</sentence>
				<definiendum id="0">Coreference</definiendum>
				<definiens id="0">a rare relation</definiens>
			</definition>
			<definition id="1">
				<sentence>Coreference is a discourse-level problem with different solutions for different types of NPs .</sentence>
				<definiendum id="0">Coreference</definiendum>
				<definiens id="0">a discourse-level problem with different solutions for different types of NPs</definiens>
			</definition>
			<definition id="2">
				<sentence>Coreference is an equivalence relation .</sentence>
				<definiendum id="0">Coreference</definiendum>
				<definiens id="0">an equivalence relation</definiens>
			</definition>
			<definition id="3">
				<sentence>Algorithm NEG-SELECT ( NEG : set of all possible negative instances ) for a9a33a10a34a12a22a14a35a16a36a18a21a20a12a22a14a37a23a25a18a4a26a39a38 NEG do if NPa8 a3 is anaphoric then if NPa7 a3 precedes a40 ( NPa8 a3 ) then NEG : = NEG a41a35a42a11a9a33a10a34a12a22a14a37a16a19a18a11a20a12a22a14a37a23a25a18a4a26a44a43 else NEG : = NEG a41a35a42a33a9a11a10a13a12a15a14a32a16a36a18a21a20a12a22a14a37a23a25a18a4a26a25a43 return NEG Figure 1 : The NEG-SELECT algorithm ing algorithm to incorporate a loss function with a much larger penalty for minority class errors than for instances from the majority classes ( e.g. Gordon and Perlis ( 1989 ) , Pazzani et al. ( 1994 ) ) .</sentence>
				<definiendum id="0">Algorithm NEG-SELECT</definiendum>
				<definiens id="0">anaphoric then if NPa7 a3 precedes a40 ( NPa8 a3 ) then NEG : = NEG a41a35a42a11a9a33a10a34a12a22a14a37a16a19a18a11a20a12a22a14a37a23a25a18a4a26a44a43 else NEG : = NEG a41a35a42a33a9a11a10a13a12a15a14a32a16a36a18a21a20a12a22a14a37a23a25a18a4a26a25a43 return NEG</definiens>
			</definition>
			<definition id="4">
				<sentence>Feature Type Feature Description Lexical PRO STR C if both NPs are pronominal and are the same string ; else I. PN STR C if both NPs are proper names and are the same string ; else I. SOON STR NONPRO C if both NPs are non-pronominal and the string of NPa16a19a18 matches that of NPa23a25a18 ; else I. Grammatical PRONOUN 1 Y if NPa16a19a18 is a pronoun ; else N. PRONOUN 2 Y if NPa23a25a18 is a pronoun ; else N. DEMONSTRATIVE 2 Y if NPa23a25a18 starts with a demonstrative such as “this , ” “that , ” “these , ” or “those ; ” else N. BOTH PROPER NOUNS C if both NPs are proper names ; NA if exactly one NP is a proper name ; else I. NUMBER C if the NP pair agree in number ; I if they disagree ; NA if number information for one or both NPs can not be determined .</sentence>
				<definiendum id="0">NA if exactly one NP</definiendum>
				<definiens id="0">non-pronominal and the string of NPa16a19a18 matches that of NPa23a25a18</definiens>
				<definiens id="1">a pronoun</definiens>
				<definiens id="2">a pronoun</definiens>
				<definiens id="3">a demonstrative such as “this , ” “that , ” “these , ” or “those ; ” else N. BOTH PROPER NOUNS C if both NPs are proper names</definiens>
				<definiens id="4">a proper name ; else I. NUMBER C if the NP pair agree in number ; I if they disagree</definiens>
			</definition>
			<definition id="5">
				<sentence>SPAN I if one NP spans the other ; else C. MAXIMALNP I if both NPs have the same maximal NP projection ; else C. SYNTAX I if the NPs have incompatible values for the BINDING , CONTRAINDICES , SPAN or MAXIMALNP constraints ; else C. INDEFINITE I if NPa23a25a18 is an indefinite and not appositive ; else C. PRONOUN I if NPa16a19a18 is a pronoun and NPa23a25a18 is not ; else C. EMBEDDED 1 Y if NPa16a19a18 is an embedded noun ; else N. TITLE I if one or both of the NPs is a title ; else C. Semantic WNCLASS C if the NPs have the same WordNet semantic class ; I if they don’t ; NA if the semantic class information for one or both NPs can not be determined .</sentence>
				<definiendum id="0">else N. TITLE I</definiendum>
				<definiens id="0">an indefinite and not appositive ; else C. PRONOUN I if NPa16a19a18 is a pronoun</definiens>
				<definiens id="1">an embedded noun ;</definiens>
				<definiens id="2">a title ; else C. Semantic WNCLASS C if the NPs have the same WordNet semantic class</definiens>
			</definition>
			<definition id="6">
				<sentence>ALIAS C if one NP is an alias of the other ; else I. Positional SENTNUM Distance between the NPs in terms of the number of sentences .</sentence>
				<definiendum id="0">ALIAS C</definiendum>
				<definiens id="0">an alias of the other ; else I. Positional SENTNUM Distance between the NPs in terms of the number of sentences</definiens>
			</definition>
			<definition id="7">
				<sentence>Algorithm POS-SELECT ( L : positive rule learner , T : set of training instances ) FinalRuleSet : = a57 ; AnaphorSet : = a57 ; BestRule : = NIL ; repeat BestRule : = best rule among the ranked set of positive rules induced on T using L FinalRuleSet : = FinalRuleSet a58 BestRule // collect anaphors from instances that // are correctly covered by BestRule for a9a11a10a13a12a22a14a32a16a19a18a11a20a12a22a14a37a23a25a18a4a26a59a38 T do if a9a33a10a34a12a22a14a32a16a19a18a60a20a12a15a14a24a23a25a18a21a26 is covered by BestRule and class ( a9a33a10a34a12a22a14a35a16a36a18a21a20a12a22a14a32a23a28a18a27a26 ) a61 COREFERENT then AnaphorSet : = AnaphorSet a58a62a42 NPa8 a3 a43 // remove instances associated with the // anaphors covered by BestRule for a9 a10a13a12a22a14 a16a19a18 a20a12a22a14 a23a25a18 a26 a38 T do if NPa8 a3a63a38 AnaphorSet then T a64a65a61 T a41a66a42a67a9 a10a34a12a22a14a17a16a19a18a21a20a12a22a14a37a23a28a18a60a26 a43 until L can not induce any rule for the positives .</sentence>
				<definiendum id="0">Algorithm POS-SELECT</definiendum>
			</definition>
			<definition id="8">
				<sentence>The output of POS-SELECT is a set of positive rules selected during each iteration of the algorithm .</sentence>
				<definiendum id="0">POS-SELECT</definiendum>
				<definiens id="0">a set of positive rules selected during each iteration of the algorithm</definiens>
			</definition>
</paper>

		<paper id="0216">
			<definition id="0">
				<sentence>Report ( Current activity ) facilitator OAA2 Synthesizer Generator Gemini Parser and Recognizer Speech Festival Display Interactive Map NL SR TTS DM GUI Activities Model Interface Dialogue Move Tree ( DMT ) Activity Tree ( AT ) System Agenda ( SA ) Pending List ( PL ) Modality Buffer ( MB ) ROBOT Salience List ( SL ) Speech Nuance DIALOGUE MANAGER Figure 1 : The WITAS dialogue system architecture defined activities ( e.g. switch lights on , record on channel a0 , send email a1 to a2 , search for vehicle a3 ) , and that an important part of the dialogue context to be modelled in such a system is the device’s planned activities , current activities , and their execution status5 .</sentence>
				<definiendum id="0">Report</definiendum>
			</definition>
			<definition id="1">
				<sentence>As a representation of conversational context , the dialogue manager uses the following data structures which make up the dialogue Information State ( IS ) ; a0 Dialogue Move Tree ( DMT ) a0 Activity Tree ( AT ) a0 System Agenda ( SA ) a0 Pending List ( PL ) a0 Salience List ( SL ) a0 Modality Buffer ( MB ) Figure 4 shows how the Dialogue Move Tree relates to other parts of the dialogue manager as a whole .</sentence>
				<definiendum id="0">dialogue manager</definiendum>
			</definition>
			<definition id="2">
				<sentence>Incoming logical forms ( LFs ) from the parsing process are always tagged with a dialogue move ( see e.g. ( Ginzburg et al. , 2001 ) ) , which precedes more detailed information about an utterance .</sentence>
				<definiendum id="0">LFs</definiendum>
				<definiens id="0">precedes more detailed information about an utterance</definiens>
			</definition>
			<definition id="3">
				<sentence>Note that this notion of “Dialogue Move Tree” is quite different from previous work on dialogue trees , in that the DMT does not represent a “parse” of the dialogue using a dialogue grammar ( e.g. ( Ahrenberg et al. , 1990 ) ) , but instead represents all the threads in the dialogue , where a thread is the set of utterances which serve a particular dialogue goal .</sentence>
				<definiendum id="0">thread</definiendum>
				<definiens id="0">the set of utterances which serve a particular dialogue goal</definiens>
			</definition>
			<definition id="4">
				<sentence>Communicative goals may also exist on the “Pending List” ( PL ) which is the part of the information state which stores questions that the system has asked , but which the user has not answered , so that they may be re-raised by the system .</sentence>
				<definiendum id="0">“Pending List” ( PL</definiendum>
				<definiens id="0">the part of the information state which stores questions that the system has asked , but which the user has not answered , so that they may be re-raised by the system</definiens>
			</definition>
			<definition id="5">
				<sentence>The end result of our selection and aggregation module ( see section 6.2 ) is a fully specified logical form which is to be sent to the Semantic-HeadDriven Generation component of Gemini ( Shieber et al. , 1990 ) .</sentence>
				<definiendum id="0">aggregation module</definiendum>
			</definition>
</paper>

		<paper id="1405">
			<definition id="0">
				<sentence>This is done by ranking for each source word the target words according to their non normalized posterior likelihood ( that is argmaxe p ( fje ) p ( e ) , where p ( e ) is given by a unigram target language model , and p ( fje ) is given by the transfer Hansard sentences , we observed a reduction in word error rate of more than 3 % with the reduced model .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">given by a unigram target language model , and p ( fje ) is given by the transfer Hansard sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>FreeSrcPositions returns the source positions not already associated to words of h ; NBestTgtWords returns the list of words that are likely to follow the last bigram uv preceeding e according to the language model ; and setIfBetter ( i ; j ; c ; e ; p ; f ; bj ; bw ) is an operator that memorizes an hypothesis if its score ( p ) is greater than the hypothesis already stored in Space ( i ; j ; c ; e ) .</sentence>
				<definiendum id="0">setIfBetter</definiendum>
				<definiendum id="1">bw )</definiendum>
				<definiens id="0">an operator</definiens>
			</definition>
			<definition id="2">
				<sentence>The flrst rate is the percentage of sentences for which the decoder found the exact translation ( that is , the one of our oracle ) , and the word error rate is computed by a Levenstein distance ( counting the same penalty for both insertion , deletion and substitution edition operations ) .</sentence>
				<definiendum id="0">flrst rate</definiendum>
				<definiens id="0">the percentage of sentences for which the decoder found the exact translation</definiens>
			</definition>
			<definition id="3">
				<sentence>jlengthj reports the average length ( counted in words ) of the source sentences and the standard deviation ; nbs is the number of sentences in the corpus .</sentence>
				<definiendum id="0">jlengthj</definiendum>
				<definiens id="0">reports the average length ( counted in words ) of the source sentences and the standard deviation</definiens>
				<definiens id="1">the number of sentences in the corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>nb is the number of entries in the lexicon and coverage reports the number of difierent source entries from the lexicon belonging to the text to translate and the total number of their occurrences .</sentence>
				<definiendum id="0">nb</definiendum>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>Heeman’s ( 1998 ) POS LM achieves a perplexity reduction compared to a trigram LM by instead rede ning the speech recognition problem as determining : W ; T = arg max W ; T P ( W ; TjA ) = arg max W ; T P ( W ; T ) P ( AjW ; T ) arg max W ; T P ( W ; T ) P ( AjW ) where T is the POS sequence t N 1 associated with the word sequence W = w N 1 given the speech utterance A.TheLMP ( W ; T ) isajoint probabilistic model that accounts for both the sequence of words w N 1 and their tag assignments t N 1 by estimating the joint probabilities of words and tags : P ( w N 1 ; t N 1 ) = N Y i=1 P ( w i ; t i jw i−1 1 ; t i−1 1 ) ( 2 ) Johnson ( 2001 ) and La erty et al. ( 2001 ) provide insight into why a joint model is superior to a conditional model .</sentence>
				<definiendum id="0">POS LM</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">achieves a perplexity reduction compared to a trigram LM by instead rede ning the speech recognition problem as determining : W ; T = arg max W ; T P ( W ; TjA ) = arg max W</definiens>
			</definition>
			<definition id="1">
				<sentence>In an attempt to incorporate even more knowledge into a structured LM , Goodman ( 1997 ) has developed a probabilistic feature grammar ( PFG ) that conditions not only on structure but also on a small set of grammatical features ( e.g. , number ) and has achieved parse accuracy improvement .</sentence>
				<definiendum id="0">PFG</definiendum>
				<definiens id="0">1997 ) has developed a probabilistic feature grammar (</definiens>
			</definition>
			<definition id="2">
				<sentence>Hence , we develop a new dependencygrammar almost-parsing LM , SuperARV LM , which uses enriched tags called SuperARVs .</sentence>
				<definiendum id="0">SuperARV LM</definiendum>
				<definiens id="0">uses enriched tags called SuperARVs</definiens>
			</definition>
			<definition id="3">
				<sentence>The SuperARV LM is a highly lexicalized probabilistic LM based on the Constraint Dependency Grammar ( CDG ) ( Harper and Helzerman , 1995 ) .</sentence>
				<definiendum id="0">SuperARV LM</definiendum>
			</definition>
			<definition id="4">
				<sentence>CDG represents a parse as assignments of dependency relations to functional variables ( denoted roles ) associated with each word in a sentence .</sentence>
				<definiendum id="0">CDG</definiendum>
				<definiens id="0">a parse as assignments of dependency relations to functional variables ( denoted roles ) associated with each word in a sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>The need roles ( denoted N1 , N2 , and N3 ) are used to ensure the grammatical requirements ( e.g. , subcategorization ) of a word are met , as in the case of the verb did , which needs a subject and a base form verb ( but since the word takes no other complements , the modpronoun case=common behavior=nominal type=interrogative semtype=inanimate agr=3s G=np-4 verb subcat=base verbtype=past voice=active inverted=yes type=none gapp=yes mood=whquestion semtype=auxiliary agr=all G=vp-1 Need1=S-3 Need2=S-4 Need3=S-2 pronoun case=common behavior=nominal type=personal semtype=human agr=2s G=subj-2 1 what 2 did 3 you The SuperARV of the word `` did '' : Category : Verb 4 learn verb subcat=obj vtype=infinitive voice=active inverted=no type=none gapp=yes mood=whquestion semtype=behavior agr=none G=vp-2 Need1=S-4 Need2=S-1 Need3=S-4 Features : { verbtype=past , voice=active , inverted=yes , type=none , gapp=yes , mood=whquestion , agr=all } Role=G , Label=vp , PX &gt; MX , ( ModifieeCategory=pronoun ) Role=Need1 , Label=S , PX &lt; MX , ( ModifieeCategory=pronoun ) Role=Need2 , Label=S , PX &lt; MX , ( ModifieeCategory=verb ) Role=Need3 , Label=S , PX=MX , ( ModifieeCategory=verb ) Dependent Positional Constraints : MX [ G ] &lt; PX = MX [ Need3 ] &lt; MX [ Need1 ] &lt; MX [ Need2 ] MC } need role constraints } } } C F } } ( R , L , UC , MC ) + DC ARV for vp-1 assigned to G for did : cat1=verb , subcat=base , verbtype=past , voice=active , inverted=yes , type=none , gapp=yes , mood=whquestion , semtype=auxiliary , agr=all , role1=G , label1=vp , ( PX1 &gt; MX1 ) ARVP for vp-1 assigned to G for did and subj-2 assigned to G for you : cat1=verb , subcat=base , verbtype=past , voice=active , inverted=yes , type=none , gapp=yes , mood=whquestion , semtype=auxiliary , agr=all , role1=G , label1=vp , ( PX1 &gt; MX1 ) cat2=pronoun , case=common , behavior=nominal , type=personal , semtype=human , agr=2s , role2=G , label2=subj , ( PX2 &gt; MX2 ) ( PX1 &lt; PX2 ) , ( MX1 &lt; MX2 ) , ( PX1=MX2 ) , ( MX1 &lt; PX2 ) Figure 1 : An example of a CDG parse , an ARV and ARVP , and the SuperARV of the word did in the sentence what did you learn.Note : G represents the governor role ; the need roles , Need1 , Need2 , andNeed3 , areused to ensure that the grammatical requirements of the word are met. PX and MX ( [ R ] ) represent the position of a word and its modi ee ( for role R ) , respectively. i ee of the role value assigned to N3 is set equal to its own position ) . Including need roles also provides a mechanism for using non-headword dependencies to constrain parse structures , which Bod ( 2001 ) has shown contributes to improved parsing accuracy. During parsing , the grammaticality of a sentence in a language de ned by a CDG is determined by applying a set of constraints to the possible role value assignments ( Harper and Helzerman , 1995 ; Maruyama , 1990 ) . Originally , the constraints were comprised of a set of hand-written rules specifying which role values ( unary constraints ) and pairs of role values ( binary constraints ) were grammatical ( Maruyama , 1990 ) . In order to derive the constraints directly from CDG annotated sentences , we have developed an algorithm to extract grammar relations using information derived directly from annotated sentences ( Harper et al. , 2000 ; Harper and Wang , 2001 ) . Using the relationship between a role value’s position and its modi ee’s position , unary and binary constraints can be represented as a nite set of abstract role values ( ARVs ) and abstract role value pairs ( ARVPs ) , respectively. The light gray box of Figure 1 shows an example of an ARV and an ARVP. The ARV for the governor role value of did indicates its lexical category , lexical features , role , label , and positional relation information. ( PX1 &gt; MX1 ) indicates that did is governed by a word that precedes it .</sentence>
				<definiendum id="0">G</definiendum>
				<definiendum id="1">MX</definiendum>
				<definiens id="0">ModifieeCategory=verb ) Role=Need3 , Label=S , PX=MX , ( ModifieeCategory=verb ) Dependent Positional Constraints : MX [ G ] &lt; PX = MX [ Need3 ] &lt;</definiens>
			</definition>
			<definition id="6">
				<sentence>The SuperARV structure provides an explicit way to organize information concerning one consistent set of dependency links for a word that can be directly derived from its parse assignments .</sentence>
				<definiendum id="0">SuperARV structure</definiendum>
				<definiens id="0">provides an explicit way to organize information concerning one consistent set of dependency links for a word that can be directly derived from its parse assignments</definiens>
			</definition>
			<definition id="7">
				<sentence>A SuperARV is formally de ned as a four-tuple for a word , hC ; F , ( R ; L ; UC ; MC ) + ; DCi , whereC is the lexical category of the word , F = fFname 1 = Fvalue 1 , : : : ; FName f = FValue f g is a feature vector ( where Fname i is the name of a feature and Fvalue i is its corresponding value ) , ( R , L , UC , MC ) + is a list of one or more four-tuples , each representing an abstraction of a role value assignment , where R is a role variable , L is a functionality label , UC represents the relative position relation of a word and its dependent , MC is the lexical category of the modi ee for this dependency relation , and DC represents the relative ordering of the positions of a word and all of its modi ees .</sentence>
				<definiendum id="0">SuperARV</definiendum>
				<definiendum id="1">whereC</definiendum>
				<definiendum id="2">MC ) +</definiendum>
				<definiendum id="3">R</definiendum>
				<definiendum id="4">L</definiendum>
				<definiendum id="5">UC</definiendum>
				<definiendum id="6">MC</definiendum>
				<definiendum id="7">DC</definiendum>
				<definiens id="0">the lexical category of the word</definiens>
				<definiens id="1">a role variable ,</definiens>
				<definiens id="2">a functionality label ,</definiens>
				<definiens id="3">the relative position relation of a word and its dependent ,</definiens>
				<definiens id="4">the relative ordering of the positions of a word and all of its modi ees</definiens>
			</definition>
			<definition id="8">
				<sentence>Our SuperARV LM estimates the joint probability of words w N 1 and their SuperARV tags t N 1 : Pr ( w N 1 t N 1 ) = N Y i=1 Pr ( w i t i jw i−1 1 t i−1 1 ) = N Y i=1 Pr ( t i jw i−1 1 t i−1 1 ) Pr ( w i jw i−1 1 t i 1 ) N Y i=1 Pr ( t i jw i−1 i−2 t i−1 i−2 ) Pr ( w i jw i−1 i−2 t i i−2 ) ( 3 ) Notice we use a joint probabilistic model to enable the joint prediction of words and their SuperARVs so that word form information is tightly integrated at the model level .</sentence>
				<definiendum id="0">SuperARV LM</definiendum>
				<definiens id="0">estimates the joint probability of words</definiens>
			</definition>
			<definition id="9">
				<sentence>^ P n ( xjy 1 ; y 2 ; : : : ; y n ) = ( x ; y 1 ; y 2 ; : : : ; y n ) P n ( xjy 1 ; y 2 ; : : : ; y n ) + ( 1− ( x ; y 1 ; y 2 ; : : : ; y n ) ) ^ P n−1 ( xjy 1 ; y 2 ; : : : ; y n−1 ) where : y 1 ; y 2 ; : : : ; y n is the context of order n-gram to predict x ; P n ( xjy 1 ; y 2 ; : : : ; y n ) is the order n-gram maximum likelihood estimation .</sentence>
				<definiendum id="0">y n</definiendum>
				<definiendum id="1">P n</definiendum>
				<definiens id="0">the order n-gram maximum likelihood estimation</definiens>
			</definition>
			<definition id="10">
				<sentence>Parser-based LMs use a similar procedure that sums over parses .</sentence>
				<definiendum id="0">Parser-based LMs</definiendum>
				<definiens id="0">a similar procedure that sums over parses</definiens>
			</definition>
			<definition id="11">
				<sentence>the word-level tokenization of treebank texts di ers from that used in the speech recognition task with the major di erences being : numbers ( e.g. , \1.2 % '' versus \one point two percent '' ) , dates ( e.g. , \Dec. 20 , 2001 '' versus \December twentieth , two thousand one '' ) , currencies ( e.g. , \ $ 10.25 '' versus \ten dollars and twenty ve cents '' ) , common abbreviations ( e.g. , \Inc. '' versus \Incorporated '' ) , acronyms ( e.g. , \I.B.M. '' versus \I. B. M. '' ) , hyphenated and period-delimited phrases ( e.g. , \red-carpet '' versus \red carpet '' ) , and contractions and possessives ( e.g. , \do n’t '' versus \don’t '' ) .</sentence>
				<definiendum id="0">acronyms ( e.g. , \I.B.M.</definiendum>
				<definiens id="0">period-delimited phrases ( e.g. , \red-carpet '' versus \red carpet '' ) , and contractions and possessives ( e.g. , \do n’t '' versus \don’t '' )</definiens>
			</definition>
			<definition id="12">
				<sentence>The knowledge sources the SuperARV LM uses , represented as components of the structure shown in Figure 1 , include : lexical category ( denoted c ) , lexical features ( denoted f ) , role label or link type information ( denoted L ) , a governor role dependency relation constraint ( R , L , UC ) ( denoted g ) , a set of need role dependency relation constraints ( R ; L ; UC ) + ( denoted n ) , and modi ee constraints represented as the lexical category of the modi ee for each role ( denoted m ) .</sentence>
				<definiendum id="0">SuperARV LM</definiendum>
				<definiens id="0">a governor role dependency relation constraint ( R , L , UC ) ( denoted g ) , a set of need role dependency relation constraints ( R ; L ; UC ) + ( denoted n ) , and modi</definiens>
			</definition>
			<definition id="13">
				<sentence>We have constructed nine different LMs based on reduced SuperARV structures denoted SARV-k ( i.e. , a SuperARV structure after removing k with k K ) , where −k represents the deletion of a subset of knowledge types ( e.g. , f , mn , cgmn ) .</sentence>
				<definiendum id="0">−k</definiendum>
				<definiens id="0">the deletion of a subset of knowledge types</definiens>
			</definition>
			<definition id="14">
				<sentence>Zeman’s PDG ( Hajic et al. , 1998 ) differs signi cantly from our original SuperARV LM in that it ignores label information L and some lexical feature information ( the morphological tags do not include some lexical features having influence on syntax , denoted syntactic lexical features , i.e. , gapp , inverted , mood , type , case , voice ) , and does not enforce valency constraints ( instead , the model only counts the number of links associated with a word without discriminating whether the links represent governing or linguistic structural requirements ) .</sentence>
				<definiendum id="0">Zeman’s PDG</definiendum>
				<definiens id="0">the number of links associated with a word without discriminating whether the links represent governing or linguistic structural requirements )</definiens>
			</definition>
			<definition id="15">
				<sentence>The full SuperARV LM yields the lowest perplexity .</sentence>
				<definiendum id="0">SuperARV LM</definiendum>
				<definiens id="0">yields the lowest perplexity</definiens>
			</definition>
</paper>

		<paper id="2025">
</paper>

		<paper id="0603">
			<definition id="0">
				<sentence>The compression effect is measured in what the authors call Description Length Gain , defined as the relative reduction in entropy .</sentence>
				<definiendum id="0">compression effect</definiendum>
				<definiens id="0">the relative reduction in entropy</definiens>
			</definition>
			<definition id="1">
				<sentence>Brent presents a general , modular probabilistic model structure for word discovery ( Brent , 1999 ) .</sentence>
				<definiendum id="0">Brent</definiendum>
				<definiens id="0">presents a general , modular probabilistic model structure for word discovery</definiens>
			</definition>
			<definition id="2">
				<sentence>The practical purpose of the segmentation is to provide a vocabulary of language units that is smaller and generalizes better than a vocabulary consisting of words as they appear in text .</sentence>
				<definiendum id="0">segmentation</definiendum>
				<definiens id="0">to provide a vocabulary of language units that is smaller and generalizes better than a vocabulary consisting of words as they appear in text</definiens>
			</definition>
			<definition id="3">
				<sentence>The total cost consists of two parts : the cost of the source text in this model and the cost of the codebook .</sentence>
				<definiendum id="0">total cost</definiendum>
				<definiens id="0">consists of two parts : the cost of the source text in this model and the cost of the codebook</definiens>
			</definition>
			<definition id="4">
				<sentence>A zero split location denotes a leaf node , i.e. , a morph .</sentence>
				<definiendum id="0">zero split location</definiendum>
				<definiens id="0">a leaf node</definiens>
			</definition>
			<definition id="5">
				<sentence>The analyzer is a finite-state transducer that reads a word form as input and outputs the base form of the word together with grammatical tags .</sentence>
				<definiendum id="0">analyzer</definiendum>
			</definition>
			<definition id="6">
				<sentence>The tag set consists of tags corresponding to morphological affixes and other tags , for example , part-of-speech tags .</sentence>
				<definiendum id="0">tag set</definiendum>
			</definition>
			<definition id="7">
				<sentence>The tags are A ( adjective ) , ACT ( active voice ) , ADV ( adverb ) , CMP ( comparative ) , GEN ( genitive ) , N ( noun ) , PCP2 ( 2nd participle ) , PL ( plural ) , PTV ( partitive ) , SG ( singular ) , V ( verb ) , and &lt; DER : ly &gt; ( -ly derivative ) .</sentence>
				<definiendum id="0">ADV ( adverb</definiendum>
				<definiendum id="1">CMP</definiendum>
				<definiendum id="2">GEN ( genitive</definiendum>
				<definiens id="0">active voice )</definiens>
			</definition>
			<definition id="8">
				<sentence>The distance d ( M , L ) for a pair of morph M and label L is given by : d ( M , L ) = −log cM , Lc M , ( 2 ) where cM , L is the number of word tokens in which the morph M has been aligned with the label L ; and cM is the number of word tokens that contain the morph M in their segmentation .</sentence>
				<definiendum id="0">cM , L</definiendum>
				<definiendum id="1">cM</definiendum>
				<definiens id="0">the number of word tokens in which the morph M has been aligned with the label L</definiens>
			</definition>
			<definition id="9">
				<sentence>However , suffixes , in particular , can have several meanings , e.g. , the English suffix s can mean either the plural of nouns or the third person singular of the present tense of verbs .</sentence>
				<definiendum id="0">suffix</definiendum>
			</definition>
			<definition id="10">
				<sentence>Linguistica , on the other hand , employs a more restricted segmentation , which leads to a larger codebook and to the fact that the codebook occupies a large part of the total MDL cost .</sentence>
				<definiendum id="0">Linguistica</definiendum>
				<definiens id="0">leads to a larger codebook and to the fact that the codebook occupies a large part of the total MDL cost</definiens>
			</definition>
			<definition id="11">
				<sentence>Method names are abbreviated : Recursive segmentation and MDL cost ( Rec .</sentence>
				<definiendum id="0">MDL</definiendum>
				<definiens id="0">Recursive segmentation</definiens>
			</definition>
			<definition id="12">
				<sentence>The alignment distance is the total distance computed over the sequence of morph/morphemic label pairs in the test data .</sentence>
				<definiendum id="0">alignment distance</definiendum>
				<definiens id="0">the total distance computed over the sequence of morph/morphemic label pairs in the test data</definiens>
			</definition>
</paper>

		<paper id="0209">
			<definition id="0">
				<sentence>In IBM’s form-based dialog manager , or FDM ( Papineni et al. 1998 ) , a developer defines a set of forms that correspond to separate tasks in the application , such as finding a flight leg .</sentence>
				<definiendum id="0">FDM</definiendum>
				<definiens id="0">a set of forms that correspond to separate tasks in the application , such as finding a flight leg</definiens>
			</definition>
</paper>

		<paper id="1208">
</paper>

		<paper id="1203">
			<definition id="0">
				<sentence>We report on the role of the Urdu grammar in the Parallel Grammar ( ParGram ) project ( Butt et al. , 1999 ; Butt et al. , 2002 ) .1 The ParGram project was designed to use a single grammar development platform and a unified methodology of grammar writing to develop large-scale grammars for typologically different languages .</sentence>
				<definiendum id="0">ParGram ) project</definiendum>
				<definiens id="0">grammar writing to develop large-scale grammars for typologically different languages</definiens>
			</definition>
			<definition id="1">
				<sentence>LFG assumes a version of Chomsky’s Universal Grammar hypothesis , namely that all languages are governed by similar underlying structures .</sentence>
				<definiendum id="0">LFG</definiendum>
				<definiens id="0">assumes a version of Chomsky’s Universal Grammar hypothesis</definiens>
			</definition>
			<definition id="2">
				<sentence>The ParGram project aims to test the LFG formalism for its universality and coverage limitations and to see how far parallelism can be maintained across languages .</sentence>
				<definiendum id="0">ParGram project</definiendum>
				<definiens id="0">aims to test the LFG formalism for its universality and coverage limitations and to see how far parallelism can be maintained across languages</definiens>
			</definition>
			<definition id="3">
				<sentence>It has also helped control ambiguity because in the case of Japanese , the morphology determines the part of speech of each word in the string with very little ambiguity .</sentence>
				<definiendum id="0">morphology</definiendum>
				<definiens id="0">determines the part of speech of each word in the string with very little ambiguity</definiens>
			</definition>
			<definition id="4">
				<sentence>While some morphological analyzers already exist for Hindi,3 e.g. , as part of the tools developed at the Language Technologies Research Centre ( LTRC ) , IIT Hyderabad ( http : //www.iiit.net/ltrc/index.html ) , they are not immediately compatible with the XLE grammar development platform , nor is it clear that the morphological analyses they produce conform to the standards and methods developed within the ParGram project .</sentence>
				<definiendum id="0">IIT Hyderabad ( http</definiendum>
				<definiens id="0">part of the tools developed at the Language Technologies Research Centre ( LTRC )</definiens>
			</definition>
			<definition id="5">
				<sentence>The finite-state morphologies used in the ParGram project associate surface forms of words with a canonical form ( a lemma ) and a series of morphological tags that provide grammatical information 3An on-line morphological analyzer is available at : http : //ccat.sas.upenn.edu/plc/tamilweb/hindi.html about that form .</sentence>
				<definiendum id="0">canonical form</definiendum>
				<definiens id="0">a lemma ) and a series of morphological tags that provide grammatical information 3An on-line morphological analyzer is available at : http : //ccat.sas.upenn.edu/plc/tamilweb/hindi.html about that form</definiens>
			</definition>
</paper>

		<paper id="0210">
			<definition id="0">
				<sentence>This blackboard-type information storage can be accessed by each system component via the Information Manager , which allows them to utilize all the information that the system contains , such as dialogue history and user profiles , directly .</sentence>
				<definiendum id="0">Information Manager</definiendum>
				<definiens id="0">allows them to utilize all the information that the system contains , such as dialogue history and user profiles</definiens>
			</definition>
			<definition id="1">
				<sentence>The utterance Topic and New Information ( Topic , NewInfo ) of the relevant user utterances are given by the parsing unit , and supplemented with discourse knowledge by ellipsis and anaphora resolution agents ( which are Input Agents ) .</sentence>
				<definiendum id="0">NewInfo )</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Dialogue Manager ( DM ) consists of agents corresponding to possible system actions ( Figure 3 ) .</sentence>
				<definiendum id="0">Dialogue Manager ( DM )</definiendum>
			</definition>
</paper>

		<paper id="1701">
			<definition id="0">
				<sentence>Many systems and projects have been developed towards this aim hitherto : SHOE ( Luke et al. , 2000 ) proposes HTML page semantic annotation with a Horn clause-based language also called SHOE ; the ( KA ) 2 initiative ( Benjamins et al. , 1999 ) seeks to annotate HTML documents with ontological information , taking Knowledge Acquisition Community ontologies as a basis ; PlanetOnto ( Motta et al. , 1999 ) aims at automatically annotating the HTML news pages of an organisation by means of the information obtained from an event-ontology based knowledge base ; finally , within the Semantic Community Web Portals project ( Staab et al. , 2000 ) an ontologybased architecture for editing and maintaining web portals in an easier way is being developed .</sentence>
				<definiendum id="0">PlanetOnto</definiendum>
				<definiens id="0">aims at automatically annotating the HTML news pages of an organisation by means of the information obtained from an event-ontology based knowledge base ; finally , within the Semantic Community Web Portals project ( Staab et al. , 2000 ) an ontologybased architecture for editing and maintaining web portals in an easier way is being developed</definiens>
			</definition>
			<definition id="1">
				<sentence>5 A semantic field ( sometimes also called a conceptual field , a semantic domain or a lexical domain ) is a theoretical construct which groups together words that are related by virtue of their being connected – at some level of generality – with the same mental concept ( Wilson &amp; Thomas , 1997 ) .</sentence>
				<definiendum id="0">semantic field</definiendum>
				<definiendum id="1">conceptual field</definiendum>
				<definiens id="0">a theoretical construct which groups together words that are related by virtue of their being connected – at some level of generality – with the same mental concept</definiens>
			</definition>
			<definition id="2">
				<sentence>Each tagset has been assigned a different class in the morphAnnot namespace : TradAnnot ( CRATER tagset ) , MBTAnnot ( MBT tagset ) and ConstrAnnot ( Constraint Grammar – CONEXOR FDG tagset ) .</sentence>
				<definiendum id="0">ConstrAnnot</definiendum>
				<definiens id="0">Constraint Grammar – CONEXOR FDG tagset )</definiens>
			</definition>
			<definition id="3">
				<sentence>Further elements susceptible of semantic annotation are being sought and research is being done towards their determination by the linguist team OntoTag has not y the project the exam In our raw text is labelled URI specified by after , nested , a inserted , introducing the token as the source syntactic and sem The tagset associated XML data model union of those three others defined for CRATER ( a Spanish POS tagset , TEI and EAGLES conform developed in our laboratory tagger , also EAGLES conform based version of CONEXOR FDG parser m syntactic part .</sentence>
				<definiendum id="0">CRATER</definiendum>
				<definiendum id="1">TEI</definiendum>
				<definiens id="0">a Spanish POS tagset ,</definiens>
			</definition>
			<definition id="4">
				<sentence>12 A chunker is a natural language ( pre ) processing tool that separates and segments sentences into its subconstituents , i.e. noun , verb and prepositional phrases , etc. former .</sentence>
				<definiendum id="0">chunker</definiendum>
				<definiens id="0">a natural language ( pre ) processing tool that separates and segments sentences into its subconstituents , i.e. noun , verb and prepositional phrases</definiens>
			</definition>
			<definition id="5">
				<sentence>The integration of these two approaches ( Corpus Linguistics and AI ) entails many advantages for language engineering and AI applications .</sentence>
				<definiendum id="0">Corpus Linguistics</definiendum>
			</definition>
			<definition id="6">
				<sentence>In “Corpus Annotation : Linguistic Information from Computer Text Corpora” , R. Garside , G. Leech &amp; A. M. McEnery , ed. , Longman , London .</sentence>
				<definiendum id="0">“Corpus Annotation</definiendum>
				<definiens id="0">Linguistic Information from Computer Text Corpora”</definiens>
			</definition>
</paper>

		<paper id="0100">
</paper>

		<paper id="1714">
			<definition id="0">
				<sentence>The Time Map model employs a phonotactic automaton ( finitestate representation of the permissible combinations of sounds in a language ) , and axioms of event logic , to interpret multilinear feature representations .</sentence>
				<definiendum id="0">Time Map model</definiendum>
				<definiens id="0">employs a phonotactic automaton ( finitestate representation of the permissible combinations of sounds in a language ) , and axioms of event logic , to interpret multilinear feature representations</definiens>
			</definition>
			<definition id="1">
				<sentence>REFLEX is a gene ric , language independent application , which allows for the rapid design and construction of syllable lexicons , for any language .</sentence>
				<definiendum id="0">REFLEX</definiendum>
				<definiens id="0">a gene ric , language independent application , which allows for the rapid design and construction of syllable lexicons</definiens>
			</definition>
			<definition id="2">
				<sentence>The REFLEX system outputs a featurebased syllable lexicon .</sentence>
				<definiendum id="0">REFLEX system</definiendum>
				<definiens id="0">outputs a featurebased syllable lexicon</definiens>
			</definition>
			<definition id="3">
				<sentence>2 In the http : //www.w3c.org/TR/xpath example given , REFLEX searches the document , checking the value of the text child of each syllable element , against each candidate syllable output by LIPS .</sentence>
				<definiendum id="0">REFLEX</definiendum>
				<definiens id="0">searches the document , checking the value of the text child of each syllable element , against each candidate syllable output by LIPS</definiens>
			</definition>
</paper>

		<paper id="0101">
			<definition id="0">
				<sentence>Together , these examples form an introduction to parsing and parsers , showing what kind of grammatical units are used ( card game ) , how sentences can be broken down into these units by following a recursive transition network ( RTN ; board game ) and how a parser can decide which route to take within the RTN ( roleplaying game ) .</sentence>
				<definiendum id="0">roleplaying game</definiendum>
				<definiens id="0">an introduction to parsing and parsers , showing what kind of grammatical units are used ( card game )</definiens>
			</definition>
			<definition id="1">
				<sentence>The Ling Rummy deck consists of 54 cards , 2 each of which ( see Figure 1 ) depicts a syntactic function ( e.g. CO = object complement ) , a terminal syntactic category ( e.g. ART = article ) , a non-terminal syntactic category ( e.g. NP = noun phrase ) , and an utterance .</sentence>
				<definiendum id="0">Ling Rummy deck</definiendum>
				<definiens id="0">consists of 54 cards , 2 each of which ( see Figure 1 ) depicts a syntactic function ( e.g. CO = object complement ) , a terminal syntactic category ( e.g. ART = article ) , a non-terminal syntactic category ( e.g. NP = noun phrase ) , and an utterance</definiens>
			</definition>
			<definition id="2">
				<sentence>The goal of the game is to form combinations of three cards , a constituent in the utterance shown on the first card having a category shown on the second and the function shown on the third card ( e.g. in Figure 1 “absolutely quiet” is an adjective phrase ( AJP ) functioning as an object complement ( CO ) ) .</sentence>
				<definiendum id="0">goal of the game</definiendum>
				<definiens id="0">an adjective phrase ( AJP ) functioning as an object complement ( CO ) )</definiens>
			</definition>
			<definition id="3">
				<sentence>The details of the resulting game , called the RTN Game , are inspired on the railroad game Box Cars ( Erickson and Erickson , 1974 , later republished as Rail Baron , Erickson et al. , 1977 ) , in which players move their train markers between cities in the United States and can buy historical railroads like the Southern Pacific .</sentence>
				<definiendum id="0">RTN Game</definiendum>
				<definiens id="0">in which players move their train markers between cities in the United States and can buy historical railroads like the Southern Pacific</definiens>
			</definition>
</paper>

		<paper id="0110">
</paper>

		<paper id="0401">
</paper>

		<paper id="0213">
			<definition id="0">
				<sentence>A Bayesian network is a directed acyclic graph in which the nodes represent the stochastic variables considered , while the structure ( given by the arcs between the nodes ) constitutes a set of conditional independencies among these variables : a variable is conditionally independent of its non-descendants in the network , given its parents in the network .</sentence>
				<definiendum id="0">Bayesian network</definiendum>
				<definiens id="0">a directed acyclic graph in which the nodes represent the stochastic variables considered , while the structure ( given by the arcs between the nodes ) constitutes a set of conditional independencies among these variables : a variable is conditionally independent of its non-descendants in the network</definiens>
			</definition>
			<definition id="1">
				<sentence>Notice that the machine learning technique known as Naive Bayes Classifier ( see for instance ( Mitchell , 1997 ) ) assumes that all variables are conditionally independent of each other given the variable that has to be classified .</sentence>
				<definiendum id="0">Naive Bayes Classifier</definiendum>
			</definition>
			<definition id="2">
				<sentence>A Naive Bayes classifier can be seen as a special case of a Bayesian network classifier , where the network structure consists of arcs from the class variable to all variables representing the features : see Figure 3 .</sentence>
				<definiendum id="0">Naive Bayes classifier</definiendum>
			</definition>
			<definition id="3">
				<sentence>The dialogue acts in Table 1 can be found at the deeper levels of the DAMSL hierarchy , e.g. a request is a special case of a infl addr fut act and an acknowledge is a special case of an understanding .</sentence>
				<definiendum id="0">acknowledge</definiendum>
				<definiens id="0">a special case of a infl addr fut act and an</definiens>
			</definition>
</paper>

		<paper id="1804">
</paper>

		<paper id="0714">
			<definition id="0">
				<sentence>Currently , approaches based on Gaussian Mixture Models ( GMMs ) [ 1 ] are the most widely and successfully used methods for speaker identification .</sentence>
				<definiendum id="0">GMMs</definiendum>
				<definiens id="0">the most widely and successfully used methods for speaker identification</definiens>
			</definition>
			<definition id="1">
				<sentence>Under mismatched conditions , we do not know the test segment distance ; we make use of all a73a75a74a77a76 sets of a33a35a34a78a36a39a38a29 phonotactic models , where a73 is the number of distances , and modify our decision rule to estimate a28a79a70 a29 a74a81a80a83a82a85a84 a29 a65a39a80a83a82a85a84a16a86 a72 a36 a33a35a34a78a36a53a38a29a38a86a21a68 , where a43 is the index over phone recognizers , a48 is the index over speaker phonotactic models , and a40a87a41a89a88a90a41a6a73 .</sentence>
				<definiendum id="0">a73</definiendum>
				<definiendum id="1">a43</definiendum>
				<definiendum id="2">a48</definiendum>
				<definiens id="0">the number of distances</definiens>
				<definiens id="1">the index over phone recognizers</definiens>
				<definiens id="2">the index over speaker phonotactic models , and a40a87a41a89a88a90a41a6a73</definiens>
			</definition>
</paper>

		<paper id="1903">
			<definition id="0">
				<sentence>MURAX ( Kupiec ( 1993 ) ) is one of the noun-phrase extraction systems .</sentence>
				<definiendum id="0">MURAX</definiendum>
				<definiendum id="1">Kupiec</definiendum>
				<definiens id="0">one of the noun-phrase extraction systems</definiens>
			</definition>
			<definition id="1">
				<sentence>MAYA has been designed as a separate component that interfaces with a traditional IR system .</sentence>
				<definiendum id="0">MAYA</definiendum>
				<definiens id="0">a separate component that interfaces with a traditional IR system</definiens>
			</definition>
			<definition id="2">
				<sentence>The NE recognizer consists of a named entity dictionary ( so-called PLO dictionary ) and a pattern matcher .</sentence>
				<definiendum id="0">NE recognizer</definiendum>
			</definition>
			<definition id="3">
				<sentence>If the next sentence has anaphors or lexical chains of the current sentence and the current sentence does not have anaphors or lexical chains of the previous sentence , the indexing engine sets the window size as 2 .</sentence>
				<definiendum id="0">indexing engine</definiendum>
				<definiens id="0">sets the window size as 2</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , when www.yahoo.co.kr is an answer candidate in the sentence , “Yahoo Korea ( www.yahoo.co.kr ) starts a new service.”</sentence>
				<definiendum id="0">www.yahoo.co.kr</definiendum>
				<definiens id="0">an answer candidate in the sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>a36 Term frequency : the frequency of each content word in a context window .</sentence>
				<definiendum id="0">Term frequency</definiendum>
				<definiens id="0">the frequency of each content word in a context window</definiens>
			</definition>
			<definition id="6">
				<sentence>The indexing engine gives high scores to content words that are near to answer candidates .</sentence>
				<definiendum id="0">indexing engine</definiendum>
			</definition>
			<definition id="7">
				<sentence>Therefore , the indexing engine uses law-level information like the term frequencies and the distances after considering the cost for the additional analysis and indexing time .</sentence>
				<definiendum id="0">indexing engine</definiendum>
				<definiens id="0">uses law-level information like the term frequencies and the distances after considering the cost for the additional analysis and indexing time</definiens>
			</definition>
			<definition id="8">
				<sentence>The indexing engine calculates local scores by two steps .</sentence>
				<definiendum id="0">indexing engine</definiendum>
				<definiens id="0">calculates local scores by two steps</definiens>
			</definition>
			<definition id="9">
				<sentence>cjidist cwadistw jikd += ) ) , ( log ( ) , ( , ( 1 ) In Equation 1 , ) , ( , jikd wadistw is the distance weight of the content word w that is located at the jth position in the kth context window of a document d. ) , ( jidist is the distance between the answer candidate ia , which is located at the ith position , and the content word jw , which is located at the jth position .</sentence>
				<definiendum id="0">wadistw</definiendum>
				<definiendum id="1">jidist</definiendum>
				<definiens id="0">the distance weight of the content word w that is located at the jth position in the kth context window of a document d. )</definiens>
				<definiens id="1">the distance between the answer candidate ia , which is located at the ith position</definiens>
			</definition>
			<definition id="10">
				<sentence>In Equation 2 , ) , ( ) ( , nposin kd waLS is the local score of the nth content word w when n identical content words exist in the kth context window of a document d , and pos ( n ) is the position of the nth content word .</sentence>
				<definiendum id="0">nposin kd waLS</definiendum>
				<definiens id="0">the local score of the nth content word w when n identical content words exist in the kth context window of a document d , and pos</definiens>
				<definiens id="1">the position of the nth content word</definiens>
			</definition>
			<definition id="11">
				<sentence>After calculating the local scores , the indexing engine saves the local scores with the position information of the relevant answer candidate in the answer DB .</sentence>
				<definiendum id="0">indexing engine</definiendum>
				<definiens id="0">saves the local scores with the position information of the relevant answer candidate in the answer DB</definiens>
			</definition>
			<definition id="12">
				<sentence>A pseudo-document is a virtual document that consists of content words occurring with an answer candidate in some documents .</sentence>
				<definiendum id="0">pseudo-document</definiendum>
				<definiens id="0">a virtual document that consists of content words occurring with an answer candidate in some documents</definiens>
			</definition>
			<definition id="13">
				<sentence>An example of the pseudo-documents In the next step , the indexing engine calculates global scores of each answer candidate , as shown in Equation ( 3 ) .</sentence>
				<definiendum id="0">indexing engine</definiendum>
				<definiens id="0">calculates global scores of each answer candidate</definiens>
			</definition>
			<definition id="14">
				<sentence>Therefore , the TF component , ) ) _/ ( 5.05.0 ( tfMaxtfw⋅+ in Equation 3 , means the normalized frequency of the content word w in the pseudo-document adpseudo _ that is named after the answer candidate a. The IDF component , ) log ( / ) /log ( NnN , means the normalized reciprocal frequency of the pseudo-documents including the content word w. The value of TF⋅IDF , ) , _ ( wdpseudoGS a , means the global score between the answer candidate a and the content word w. In detail , tfw is the term frequency of the content word w in adpseudo _ .</sentence>
				<definiendum id="0">tfw</definiendum>
				<definiens id="0">means the normalized frequency of the content word w in the pseudo-document adpseudo _ that is named after the answer candidate a. The IDF component</definiens>
			</definition>
			<definition id="15">
				<sentence>Max_tf is the maximum value among the frequencies of content words in adpseudo _ .</sentence>
				<definiendum id="0">Max_tf</definiendum>
				<definiens id="0">the maximum value among the frequencies of content words in adpseudo _</definiens>
			</definition>
			<definition id="16">
				<sentence>n is the number of the pseudo-documents that include the content word w. N is the total number of the pseudo-documents .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="17">
				<sentence>p p i pp p i p i pppp and qqq atqatqatq QASim +++ −++−+−− = a253 a253 21 2211 ) 1 ( ) 1 ( ) 1 ( 1 ) , ( ( 5 ) In Equation 5 , A is an answer candidate , and ati is the ith term score in the context window of the answer candidate .</sentence>
				<definiendum id="0">ati</definiendum>
				<definiens id="0">the ith term score in the context window of the answer candidate</definiens>
			</definition>
			<definition id="18">
				<sentence>WEBTEC consists of 22,448 documents ( 110,004 kilobytes ) , and KorQATeC 1.0 consists of 207,067 balanced documents ( 368,768 kilobytes ) .</sentence>
				<definiendum id="0">WEBTEC</definiendum>
			</definition>
			<definition id="19">
				<sentence>n is the number of questions .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="20">
				<sentence>For ranking answer candidates , MAYA uses the weighted sums of global scores and local scores , as shown in Equation 4 .</sentence>
				<definiendum id="0">MAYA</definiendum>
				<definiens id="0">uses the weighted sums of global scores and local scores</definiens>
			</definition>
</paper>

		<paper id="0217">
			<definition id="0">
				<sentence>How recently a potential referent was referred to is one important factor , another is the embedding activity within which the anaphoric reference was made ( e.g. the type of verb phrase in which the referent appears ) , a third is the intra-sentential location of the relevant noun phrases in the preceding dialogue , a fourth is the relative prominence of a potential referent in the dialogue situation , and so on .</sentence>
				<definiendum id="0">dialogue</definiendum>
				<definiendum id="1">fourth</definiendum>
				<definiens id="0">the type of verb phrase in which the referent appears ) , a third is the intra-sentential location of the relevant noun phrases in the preceding</definiens>
				<definiens id="1">the relative prominence of a potential referent in the dialogue situation , and so on</definiens>
			</definition>
</paper>

		<paper id="1813">
			<definition id="0">
				<sentence>The Segmentation Corpus is an electronic database of around 33,000 Cantonese word types extracted from a 1.7 million character corpus of Hong Kong newspapers , along with a tokenized record of the text .</sentence>
				<definiendum id="0">Segmentation Corpus</definiendum>
				<definiens id="0">an electronic database of around 33,000 Cantonese word types extracted from a 1.7 million character corpus of Hong Kong newspapers , along with a tokenized record of the text</definiens>
			</definition>
			<definition id="1">
				<sentence>For our current purpose , the most useful part of the Segmentation Corpus is the wordlist proper , a file containing a separate entry for each word type identified by the segmentation criteria .</sentence>
				<definiendum id="0">Segmentation Corpus</definiendum>
				<definiens id="0">the wordlist proper , a file containing a separate entry for each word type identified by the segmentation criteria</definiens>
			</definition>
</paper>

		<paper id="0106">
</paper>

		<paper id="0908">
			<definition id="0">
				<sentence>We de ne a context relation instance as a tuple ( w ; r ; w0 ) where w is the thesaurus term , which occurs in some grammatical relation r with another word w0 in the sentence .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">the thesaurus term , which occurs in some grammatical relation r with another word w0 in the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Figure 2 presents both the performance of the system using direct match evaluation ( left axis ) and execution times ( right axis ) for increasing cutoffs .</sentence>
				<definiendum id="0">execution times</definiendum>
				<definiens id="0">right axis ) for increasing cutoffs</definiens>
			</definition>
			<definition id="2">
				<sentence>The BIG columns show the previous measure results if we returned 10,000 synonyms , and MAX gives the results for a comparison of the gold standard against itself .</sentence>
				<definiendum id="0">MAX</definiendum>
				<definiens id="0">gives the results for a comparison of the gold standard against itself</definiens>
			</definition>
</paper>

		<paper id="0808">
			<definition id="0">
				<sentence>2 In order to compare the algorithm results with the annotators’ sense assignments , we normalized the data as follows : for each annotator and the algorithm , each of the 33 words was represented as a vector of length n ( n-1 ) /2 , where n is the number of occurrences of the word in the corpus .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of occurrences of the word in the corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>We chose nouns that occur a minimum of 10 times in the corpus , have no undetermined translations and at least five different translations in the six nonEnglish languages , and have the log likelihood score of at least 18 ; that is : LL ( T T , T S ) = Â = 2 1 ij n* j * j*i ij n log ≥ 18 where n ij stands for the number of times T T and T S have been seen together in aligned sentences , n i* and n *j stand for the number occurrences of T T and T S , respectively , and n ** represents the total 4 We computed raw percentages only ; common measures of annotator agreement such as the Kappa statistic ( Carletta , 1996 ) proved to be inappropriate for our two-category ( “yesno” ) classification scheme .</sentence>
				<definiendum id="0">n ij</definiendum>
				<definiendum id="1">T S</definiendum>
				<definiendum id="2">n **</definiendum>
				<definiendum id="3">Kappa statistic</definiendum>
				<definiens id="0">the number of times T T and T S have been seen together in aligned sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>The LL score is set at a maximum value to ensure high precision for the extracted translation equivalents , which minimizes sense clustering errors due to incorrect word alignment .</sentence>
				<definiendum id="0">LL score</definiendum>
				<definiens id="0">minimizes sense clustering errors due to incorrect word alignment</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0711">
</paper>

		<paper id="0203">
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>In its first appearance , it acknowledges that some material will be adjoined to a VP that dominates the element at the top of the stack ( in fact it dominates the a0 topmost elements , where a0 is the second parameter of bpack ) .</sentence>
				<definiendum id="0">a0</definiendum>
			</definition>
			<definition id="1">
				<sentence>An instantaneous description ( or “configuration” ) can be characterized by two components : cludes the current ( automaton ) state ; stack .</sentence>
				<definiendum id="0">instantaneous description</definiendum>
				<definiens id="0">cludes the current ( automaton</definiens>
			</definition>
			<definition id="2">
				<sentence>A striking solution arises from a notable fact from LR parsing theory for CFGs : If state a5 a16 contains an action reduce p , where a39 is a production with a23 symbols on its right side , then , the pair ( a5 a16a21a17a20a64 a8a10a5a13a16 ) , from the instantaneous description , uniquely identifies the entire sequence a5 a16a21a17a20a64 a8a10a5 a16a18a17a20a64a72a71a65a11 a8a13a14a73a14a73a14a73a8a10a5a13a16a21a17a22a11a7a8a10a5a13a16 .</sentence>
				<definiendum id="0">a39</definiendum>
				<definiens id="0">If state a5 a16 contains an action reduce p</definiens>
				<definiens id="1">a production with a23 symbols on its right side</definiens>
			</definition>
			<definition id="3">
				<sentence>Keeping all nodes in the tree alive is a direct consequence of the fact that we do not intend to do exhaustive backtracking .</sentence>
				<definiendum id="0">Keeping all nodes in the tree alive</definiendum>
				<definiens id="0">a direct consequence of the fact that we do not intend to do exhaustive backtracking</definiens>
			</definition>
			<definition id="4">
				<sentence>In table 1 we report the following figures for the development set ( Section 0 ) and test set ( Section 23 ) : a10 % failed is the percentage of sentences for which the parser failed ( in the two attempts ) .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">the percentage of sentences for which the parser failed ( in the two attempts )</definiens>
			</definition>
</paper>

		<paper id="0400">
</paper>

		<paper id="0806">
</paper>

		<paper id="0303">
			<definition id="0">
				<sentence>Hatzivassiloglou et al. ( 2001 ) points out the benefits and the difficulties inherent in distinguishing between genes , proteins , and RNA ; we found that it was also important to differentiate between genes , proteins , RNA , and receptors , promoters , antagonists , domains , and binding sites , as well as diseases , syndromes , conditions , phenotypes , and mutants , as all of these were noted by our subject-matter expert as sources of false positives .</sentence>
				<definiendum id="0">RNA</definiendum>
				<definiens id="0">2001 ) points out the benefits and the difficulties inherent in distinguishing between genes , proteins , and</definiens>
				<definiens id="1">important to differentiate between genes , proteins , RNA , and receptors , promoters , antagonists , domains , and binding sites , as well as diseases , syndromes , conditions , phenotypes , and mutants , as all of these were noted by our subject-matter expert as sources of false positives</definiens>
			</definition>
</paper>

		<paper id="0406">
			<definition id="0">
				<sentence>DUC aims to compile standard training and test collections that can be shared among researchers and to provide common and large scale evaluations in single and multiple document summarization for their participants .</sentence>
				<definiendum id="0">DUC</definiendum>
			</definition>
			<definition id="1">
				<sentence>Proceedings of the Workshop on Automatic Summarization ( including DUC 2002 ) , • Exploratory summarization : participants were encouraged to investigate alternative approaches to evaluating summarization and report their results .</sentence>
				<definiendum id="0">Exploratory summarization</definiendum>
			</definition>
			<definition id="2">
				<sentence>Weighted Retention Recall at different compression ratios has been used in summarization research to measure how well an automatic system retains important content of original documents ( Mani and Maybury 1999 ) .</sentence>
				<definiendum id="0">Weighted Retention Recall</definiendum>
				<definiens id="0">used in summarization research to measure how well an automatic system retains important content of original documents</definiens>
			</definition>
			<definition id="3">
				<sentence>The Compression Ratio is defined as the length of a summary ( by words or sentences ) divided by the length of its original document .</sentence>
				<definiendum id="0">Compression Ratio</definiendum>
			</definition>
			<definition id="4">
				<sentence>NAMS is defined as follows : a 1 ·NAM 1 + a 2 ·NAM 2 + a 3 ·NAM 3 + a 4 ·NAM 4 NAM n is n-gram hit ratio defined as : MUin grams-n of # total S and MUbetween grams-n matched of # We tested three different configurations of a i : 4 The whole system summary was used to compute NAMS against a model unit .</sentence>
				<definiendum id="0">NAMS</definiendum>
			</definition>
</paper>

		<paper id="1506">
			<definition id="0">
				<sentence>In this paper , we report on the the XLE system ( Maxwell and Kaplan , 1993 ) , a parser and grammar development platform for Lexical Functional Grammars .</sentence>
				<definiendum id="0">XLE system</definiendum>
				<definiens id="0">a parser and grammar development platform for Lexical Functional Grammars</definiens>
			</definition>
			<definition id="1">
				<sentence>The WSJ grammar covers the UPenn Wall Street Journal ( WSJ ) treebank sentences ( Marcus et al. , 1994 ) .</sentence>
				<definiendum id="0">WSJ grammar</definiendum>
			</definition>
			<definition id="2">
				<sentence>It specifies all of the STANDARD grammar files as well as its own rule , template , lexicon , and morphology files .</sentence>
				<definiendum id="0">STANDARD grammar</definiendum>
				<definiens id="0">files as well as its own rule , template , lexicon , and morphology files</definiens>
			</definition>
			<definition id="3">
				<sentence>The top-level category is one of the parameters of a configuration , and the EUREKA CONFIGURATION specifies that FIELD instead of the STANDARD ROOT is the start-symbol of the grammar .</sentence>
				<definiendum id="0">STANDARD ROOT</definiendum>
				<definiens id="0">one of the parameters of a configuration , and the EUREKA CONFIGURATION specifies that FIELD instead of the</definiens>
			</definition>
			<definition id="4">
				<sentence>( 13 ) METARULEMACRO ( CAT BASECAT RHS ) = LSB LABEL [ BASECAT ] CAT RSB copy of STANDARD coordination copy of STANDARD surrounding quote .</sentence>
				<definiendum id="0">METARULEMACRO</definiendum>
				<definiens id="0">CAT BASECAT RHS ) = LSB LABEL [ BASECAT ] CAT RSB copy of STANDARD coordination copy of STANDARD surrounding quote</definiens>
			</definition>
			<definition id="5">
				<sentence>The part-name UDH is singular when it appears without the ’s and thus the morphological tag +Sg is appended to it .</sentence>
				<definiendum id="0">morphological tag +Sg</definiendum>
				<definiens id="0">singular when it appears without the ’s and thus the</definiens>
			</definition>
			<definition id="6">
				<sentence>Part-of-speech tags appear in a distinctive format , beginning with a / and ending with a , with the intervening material indicating the content of the tag ( VBZ for finite 3rd singular verb , VBG for a progressive , VBN for a passive , etc. ) .</sentence>
				<definiendum id="0">Part-of-speech tags</definiendum>
				<definiens id="0">appear in a distinctive format , beginning with a / and ending with a , with the intervening material indicating the content of the tag</definiens>
			</definition>
			<definition id="7">
				<sentence>The Xerox calculus includes the composition , ignore , and substitution operator discussed by Kaplan and Kay ( 1994 ) and the priority-union operator of Kaplan and Newman ( 1997 ) .</sentence>
				<definiendum id="0">Xerox calculus</definiendum>
			</definition>
			<definition id="8">
				<sentence>XLE supports a version of Optimality Theory ( OT ) ( Prince and Smolensky , 1993 ) which is used to rank an analysis relative to other possible analyses ( Frank et al. , 2001 ) .</sentence>
				<definiendum id="0">XLE</definiendum>
			</definition>
			<definition id="9">
				<sentence>Maintenance is a serious issue for any large-scale grammar development activity , and the maintenance problems are compounded when multiple versions are being created perhaps by several different grammar writers .</sentence>
				<definiendum id="0">Maintenance</definiendum>
				<definiens id="0">a serious issue for any large-scale grammar development activity , and the maintenance problems are compounded when multiple versions are being created perhaps by several different grammar writers</definiens>
			</definition>
			<definition id="10">
				<sentence>The WSJ lexicons include many titles and proper nouns that may ultimately be moved to the STANDARD files .</sentence>
				<definiendum id="0">WSJ lexicons</definiendum>
			</definition>
</paper>

		<paper id="1038">
</paper>

		<paper id="0805">
			<definition id="0">
				<sentence>ANSWER ( Spanish ) : *no cortarse* notice , they are a pain in the a83 taga84 buma83 /taga84 ANSWER ( Spanish ) : *pesado* a0 Quality of Senseval-2 annotations Finally , some erroneous manual annotations of the Senseval-2 corpus were highlighted by unexpected proximity or stability values .</sentence>
				<definiendum id="0">ANSWER ( Spanish )</definiendum>
				<definiens id="0">*no cortarse* notice , they are a pain in the a83 taga84 buma83 /taga84 ANSWER ( Spanish ) : *pesado* a0 Quality of Senseval-2 annotations Finally , some erroneous manual annotations of the Senseval-2 corpus were highlighted by unexpected proximity or stability values</definiens>
			</definition>
</paper>

		<paper id="0802">
			<definition id="0">
				<sentence>A digraph consists of nodes and directed arcs between the nodes .</sentence>
				<definiendum id="0">digraph</definiendum>
			</definition>
			<definition id="1">
				<sentence>A preposition definition is either ( 1 ) a preposition ; ( 2 ) a prepositional phrase + a preposition ; ( 3 ) ( an optional leading string ) + a transitive present participle ; or ( 4 ) a leading string + an infinitive of a transitive verb .</sentence>
				<definiendum id="0">preposition definition</definiendum>
				<definiens id="0">an optional leading string ) + a transitive present participle ; or ( 4 ) a leading string + an infinitive of a transitive verb</definiens>
			</definition>
			<definition id="2">
				<sentence>One sense of “after” is “in imitation of” ( e.g. , “a mystery story after Poe” ) ; examining the table suggests that this is a deverbal use of “of” , where the object of “after” would be the object of the underlying verb of “imitation” , so that when “after” is used in this sense , its arg1 is the object of the verb “imitate” .</sentence>
				<definiendum id="0">“in imitation of”</definiendum>
				<definiens id="0">the object of the verb “imitate”</definiens>
			</definition>
			<definition id="3">
				<sentence>Definitions of “of” Type Definition ( Subsense ( s ) ) partitive noun , with the word denoting the whole functioning as the head of the phrase ) composer and their works collectively ) category ( governed by a noun expressing the fact that a category is vague ) of the underlying verb ; the second noun denotes the object of the underlying verb ; head of the phrase is a predicative adjective ) cause ) analysis includes identification of the syntactic role and semantic type of the noun phrases , along with attributes such as number and gender .</sentence>
				<definiendum id="0">head of the phrase</definiendum>
				<definiens id="0">the head of the phrase</definiens>
				<definiens id="1">a predicative adjective ) cause ) analysis includes identification of the syntactic role and semantic type of the noun phrases</definiens>
			</definition>
</paper>

		<paper id="2010">
			<definition id="0">
				<sentence>Transformation-based learning ( TBL henceforth ) is an error-driven machine learning technique which works by first assigning an initial classification to the data , and then automatically proposing , evaluating and selecting the transformations that maximally decrease the number of errors .</sentence>
				<definiendum id="0">Transformation-based learning ( TBL henceforth )</definiendum>
				<definiens id="0">an error-driven machine learning technique which works by first assigning an initial classification to the data</definiens>
			</definition>
			<definition id="1">
				<sentence>The input to the FB algorithm consists of a series of chunks BV BD BNBMBMBMBNBV D2 , each spanning a sequence of words DB BD BMBMBMDB CQ BD A0BD DB CQ BD BMBMBMDB CT BD DG DFDE DH BV BD BMBMBMDB CQ D2 BMBMBMDB CT D2 DG DFDE DH BV D2 BMBMBMDB D1 3 For this task , Snow does not bring any improvement to the fnTBL’s output .</sentence>
				<definiendum id="0">FB algorithm</definiendum>
				<definiendum id="1">BD BMBMBMDB CQ BD A0BD DB CQ BD BMBMBMDB CT BD DG DFDE DH BV BD BMBMBMDB CQ D2 BMBMBMDB CT D2 DG DFDE DH BV D2</definiendum>
				<definiens id="0">consists of a series of chunks BV BD BNBMBMBMBNBV D2 , each spanning a sequence of words DB</definiens>
			</definition>
			<definition id="2">
				<sentence>Method Spanish Dutch FB performance 76.49 73.30 FB on perfect chunk breaks 83.52 81.30 Table 4 : Forward-Backward results ( F-measure ) on the development sets For each marked entity BV CY , the goal is to determine its most likely type : 4 CM BX CY BP CPD6CVD1CPDC BX CY C8 BX CYA0BD BD BNBX D2 CYB7BD C8 B4BX D2 BD CYDB D1 BD B5BP CPD6CVD1CPDC BX CY C8 BX CYA0BD BD BNBX D2 CYB7BD C8 A0 DB CQ BD A0BD BD BX BD BMBMBMBX D2 DB D1 CT D2 B7BD A1 A1 C8 AG D0CTD2 AG DB CT CY CQ CY AH CYBX CY AH A1 C8 AG DB CT CY CQ CY CYBX CY AH ( 1 ) where C8 A0 DB CQ BD A0BD BD BX BD BMBMBMBX D2 DB D1 CT D2 B7BD A1 represents the entity-external/contextual probability , and C8 AG D0CTD2 AG DB CT CY CQ CY AH CYBX CY AH C8 AG DB CT CY CQ CY CYBX CY AH is the entity-internal probability .</sentence>
				<definiendum id="0">C8 AG D0CTD2 AG DB CT CY CQ CY AH CYBX</definiendum>
				<definiens id="0">BX CYA0BD BD BNBX D2 CYB7BD C8 B4BX D2 BD CYDB D1 BD B5BP CPD6CVD1CPDC BX CY C8 BX CYA0BD BD BNBX D2 CYB7BD C8 A0 DB CQ BD A0BD BD BX BD BMBMBMBX D2 DB D1 CT D2 B7BD A1 A1 C8 AG D0CTD2 AG DB CT CY CQ CY AH CYBX CY AH A1 C8 AG DB CT CY CQ CY CYBX CY AH ( 1 ) where C8 A0 DB CQ BD A0BD BD BX BD BMBMBMBX D2 DB D1 CT D2 B7BD A1 represents the entity-external/contextual probability , and</definiens>
			</definition>
</paper>

		<paper id="0307">
			<definition id="0">
				<sentence>The Mouse Atlas , developed by researchers at the Medical Research Council’s Human Genetics Unit ( MRC HGU ) in Edinburgh , is a 3D atlas of mouse embryo development ( http : //genex.hgu.mrc.ac.uk ) .</sentence>
				<definiendum id="0">Mouse Atlas</definiendum>
				<definiens id="0">developed by researchers at the Medical Research Council’s Human Genetics Unit ( MRC HGU ) in Edinburgh , is a 3D atlas of mouse embryo development ( http : //genex.hgu.mrc.ac.uk )</definiens>
			</definition>
			<definition id="1">
				<sentence>A user may enter a string that matches nothing ( 0 % recall ) : ( 1 ) it may be neither a component term nor a substring within a component term – e.g. , while HEART is a common synonym for the modifier “cardiac” ( and a component term in its own right ) and CARDIAC MUSCLE is a component term , the string “heart muscle” yields no match ; or ( 2 ) it may span multiple component terms in the nomenclature – e.g. , while GLAND is a component term , and PITUITARY is the component term of one of its children ( i.e. , a member of the set of glands ) , the string “pituitary gland” yields no match .</sentence>
				<definiendum id="0">HEART</definiendum>
				<definiendum id="1">CARDIAC MUSCLE</definiendum>
				<definiendum id="2">GLAND</definiendum>
				<definiendum id="3">PITUITARY</definiendum>
				<definiens id="0">enter a string that matches nothing ( 0 % recall ) : ( 1 ) it may be neither a component term nor a substring within a component term – e.g.</definiens>
				<definiens id="1">a common synonym for the modifier “cardiac” ( and a component term in its own right</definiens>
				<definiens id="2">a component term , the string “heart muscle” yields no match ; or</definiens>
				<definiens id="3">a component term , and</definiens>
				<definiens id="4">the component term of one of its children</definiens>
				<definiens id="5">a member of the set of glands ) , the string “pituitary gland” yields no match</definiens>
			</definition>
			<definition id="2">
				<sentence>In the Mouse Anatomical Nomenclature , this situation corresponds , first off , to path specifications that differ only in their root note ( which designates the embryo 4The size of Theiler Stage trees ranges from 3 nodes in stage 2 ( early development ) to 1739 nodes in stage 26 ( pre-birth ) , with the average size being 528 nodes .</sentence>
				<definiendum id="0">Mouse Anatomical Nomenclature</definiendum>
				<definiens id="0">to path specifications that differ only in their root note ( which designates the embryo 4The size of Theiler Stage trees ranges from 3 nodes in stage 2</definiens>
			</definition>
			<definition id="3">
				<sentence>The difference may simply be in the particular component term associated with a non-terminal node – e.g. FUTURE FOREBRAIN is a child of FUTURE BRAIN in stages 15-16 , while FOREBRAIN descends from BRAIN in stages 17-26 .</sentence>
				<definiendum id="0">FUTURE FOREBRAIN</definiendum>
				<definiendum id="1">FUTURE BRAIN</definiendum>
				<definiens id="0">a child of</definiens>
			</definition>
			<definition id="4">
				<sentence>FIBULA is a unique designator in Stage23 , becoming EMBRYO .</sentence>
				<definiendum id="0">FIBULA</definiendum>
				<definiens id="0">a unique designator in Stage23 , becoming EMBRYO</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , a sub-string match on the phrase “lumen” results in future spinal cord ; neural tube ; neural lumen foregut diverticulum ; lumen hindgut diverticulum ; lumen midgut ; lumen future spinal cord ; neural tube ; neural lumen foregut diverticulum ; lumen hindgut diverticulum ; lumen midgut ; lumen foregut-midgut junction ; lumen future spinal cord ; neural tube ; neural lumen ( future spinal canal , spinal canal ) hindgut diverticulum ; lumen midgut ; lumen foregut-midgut junction ; lumen rest of foregut ; lumen foregut ; pharyngeal region ; lumen otic pit ; lumen 10 TS15 term ( s ) matching query “lumen” : optic recess ( lumen of optic stalk ) future spinal cord ; neural tube ; neural lumen ( future spinal canal , spinal canal ) hindgut diverticulum ; lumen midgut ; lumen pharynx ; lumen foregut-midgut junction ; lumen hindgut ; lumen rest of foregut ; lumen foregut ; oesophageal region ; lumen otic pit ; lumen Locating an entity of interest amongst all these tree paths can be an arduous task .</sentence>
				<definiendum id="0">neural lumen</definiendum>
				<definiendum id="1">lumen foregut ; pharyngeal region</definiendum>
				<definiens id="0">a sub-string match on the phrase “lumen” results in future spinal cord ; neural tube ; neural lumen foregut diverticulum ; lumen hindgut diverticulum ; lumen midgut ; lumen future spinal cord ; neural tube ; neural lumen foregut diverticulum</definiens>
				<definiens id="1">lumen of optic stalk ) future spinal cord ; neural tube ; neural lumen ( future spinal canal , spinal canal ) hindgut diverticulum</definiens>
			</definition>
			<definition id="6">
				<sentence>The introduction of phrases based on more than one component term within the Mouse Anatomy Nomenclature significantly reduces the number of irrelevant matches compared to searches based on a single comonent term .</sentence>
				<definiendum id="0">introduction of phrases</definiendum>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>Many alignment models assume a one to many mapping from source language words to target language words , such as the IBM models 1-5 of Brown et al. ( 1993 ) and the HMM alignment model of ( Vogel et al. , 1996 ) .</sentence>
				<definiendum id="0">Many alignment models</definiendum>
				<definiens id="0">assume a one to many mapping from source language words to target language words</definiens>
			</definition>
			<definition id="1">
				<sentence>In addition , the IBM Models 3 , 4 and 5 include a fertility model a17 a1a19a18a20a8a3a21a13 where a18 is the number of words aligned to a source word a3 .</sentence>
				<definiendum id="0">a18</definiendum>
				<definiens id="0">the number of words aligned to a source word a3</definiens>
			</definition>
			<definition id="2">
				<sentence>We use the following linear interpolation to smooth tag translation probabilities : a29a2a1a4a10a41a81 a22 a8a3a122a81 a102a44a103 a13a52a33a77a148a85a149a29a2a1a4a10a41a81 a22 a8a3a122a81 a102a44a103 a13a31a150a151a1a108a144a152a114a153a148a12a13 a7 a154 ( 4 ) T is the size of the French tag set and a148 is set to be so heavily smoothed with a uniform distribution because in EM the tag translation probabilities quickly become very sharp and can easily overrule the alignment and word translation probabilities .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the size of the French tag set</definiens>
			</definition>
			<definition id="3">
				<sentence>A major advantage of the IBM models 3–5 over the HMM alignment model is the presence of a model of source word fertility .</sentence>
				<definiendum id="0">HMM alignment model</definiendum>
				<definiens id="0">the presence of a model of source word fertility</definiens>
			</definition>
			<definition id="4">
				<sentence>We extended the HMM model to decide whether to generate more words from the previous English word a3a16a102a44a103a42a131 a110 or to move on to a different word depending on the identity of the English word a3a6a102a44a103a42a131 a110 .</sentence>
				<definiendum id="0">HMM model</definiendum>
			</definition>
			<definition id="5">
				<sentence>Sparsity is a problem in estimating stay probabilities P ( staya8a3a16a102a46a103a107a131 a110 ) .</sentence>
				<definiendum id="0">Sparsity</definiendum>
			</definition>
			<definition id="6">
				<sentence>We use the probability of a jump of size zero from the baseline model as our prior to do smoothing as follows : a29a2a1 staya8a3 a125 a103a42a131 a110 a13a87a33a116a148a73a29a145a168a6a169a56a150a45a1a108a144a108a114a60a148a12a13a46a29a2a1 staya8a3 a125 a103a42a131 a110 a13 ( 6 ) 5E [ X ] = a110 a170 =a171 + a172a124a171a74a173a19a135a31a174a85a171a47a175 a110 + a176a113a171a74a173a19a135a157a174a85a171a6a175 a133 + . . . where X is the number of Bernoulli trials until the first success .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">the probability of a jump of size zero from the baseline model as our prior to do smoothing as follows : a29a2a1 staya8a3 a125 a103a42a131 a110 a13a87a33a116a148a73a29a145a168a6a169a56a150a45a1a108a144a108a114a60a148a12a13a46a29a2a1 staya8a3 a125 a103a42a131 a110 a13 ( 6 ) 5E [ X ] = a110 a170 =a171 + a172a124a171a74a173a19a135a31a174a85a171a47a175 a110 + a176a113a171a74a173a19a135a157a174a85a171a6a175 a133 +</definiens>
				<definiens id="1">the number of Bernoulli trials until the first success</definiens>
			</definition>
			<definition id="7">
				<sentence>Null appears in every English sentence and often serves to generate syntactic elements in the target language that are missing in the source .</sentence>
				<definiendum id="0">Null</definiendum>
				<definiens id="0">appears in every English sentence and often serves to generate syntactic elements in the target language that are missing in the source</definiens>
			</definition>
			<definition id="8">
				<sentence>Our test data consists of a191 a179a6a179 manually aligned sentences which are the same data set used by ( Och and Ney , 2000b ) .6 In the annotated sentences every alignment between two words is labeled as either a sure ( S ) or possible ( P ) alignment .</sentence>
				<definiendum id="0">test data</definiendum>
				<definiens id="0">consists of a191 a179a6a179 manually aligned sentences which are the same data set used by ( Och and Ney , 2000b ) .6 In the annotated sentences every alignment between two words is labeled as either a sure ( S</definiens>
			</definition>
			<definition id="9">
				<sentence>The models we implemented and compare in this section are the following : a211 Baseline is the baseline HMM model described in section 2 a211 Tags is an HMM model that includes tags for translation probabilities ( section 5.1 ) 6We want to thank Franz Och for sharing the annotated data with us .</sentence>
				<definiendum id="0">Baseline</definiendum>
				<definiens id="0">the baseline HMM model described in section 2 a211 Tags is an HMM model that includes tags for translation probabilities ( section 5.1 ) 6We want to thank Franz Och for sharing the annotated data with us</definiens>
			</definition>
			<definition id="10">
				<sentence>a211 SG is an HMM model that includes stay probabilities ( section 5.3 ) a211 Null is an HMM model that includes the new generation model for words by Null ( section 5.4 ) a211 Tags+Null , Tags+SG , and Tags+Null+SG are combinations of the above models Table 2 shows AER results for our improved models on training corpora of increasing size .</sentence>
				<definiendum id="0">a211 SG</definiendum>
				<definiens id="0">an HMM model that includes stay probabilities ( section 5.3 ) a211 Null is an HMM model that includes the new generation model for words by Null ( section 5.4 ) a211 Tags+Null , Tags+SG</definiens>
			</definition>
			<definition id="11">
				<sentence>The model Null outperforms the baseline at every data set size , with the error reduction being larger for bigger training sets ( up to 9.2 % error reduction ) .</sentence>
				<definiendum id="0">model Null</definiendum>
				<definiens id="0">outperforms the baseline at every data set size , with the error reduction being larger for bigger training sets</definiens>
			</definition>
			<definition id="12">
				<sentence>The combination of Tags and the SG or Null models outperforms the individual models in the combination since they address different problems and make orthogonal mistakes .</sentence>
				<definiendum id="0">Null models</definiendum>
				<definiens id="0">outperforms the individual models in the combination since they address different problems and make orthogonal mistakes</definiens>
			</definition>
			<definition id="13">
				<sentence>The signed rank test uses the normalized test statistic a215 a161 a24a73a216 a59 a215 a161 a63 a217 a218 a102a42a219 a59 a215 a161 a63 .</sentence>
				<definiendum id="0">signed rank test</definiendum>
				<definiens id="0">uses the normalized test statistic a215 a161 a24a73a216 a59 a215 a161 a63 a217 a218 a102a42a219 a59 a215 a161 a63</definiens>
			</definition>
</paper>

		<paper id="0305">
			<definition id="0">
				<sentence>Word level BNs have input nodes named `` head '' , `` mod1 '' and `` mod2 '' , corresponding to the syntactic head and modifiers of a phrase .</sentence>
				<definiendum id="0">Word level</definiendum>
				<definiens id="0">mod1 '' and `` mod2 '' , corresponding to the syntactic head and modifiers of a phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>M+ uses a bottom-up chart parser , with a context free grammar ( CFG ) .</sentence>
				<definiendum id="0">M+</definiendum>
				<definiens id="0">uses a bottom-up chart parser , with a context free grammar ( CFG )</definiens>
			</definition>
			<definition id="2">
				<sentence>For instance , the interpretation of `` hazy right lower lobe opacity '' could be the expression ( and ( head-of # phrase1 # find1 ) ( located-at # find1 # loc1 ) ) where # phrase1 identifies a syntactic phrase object , and # find1 and # loc1 are tokens representing instances of the findings BN ( instanced with the words `` hazy '' and `` opacity '' ) and the anatomic BN ( instanced with `` right '' , `` lower '' and `` lobe '' ) , respectively .</sentence>
				<definiendum id="0">BN</definiendum>
				<definiens id="0">a syntactic phrase object , and # find1 and # loc1 are tokens representing instances of the findings BN ( instanced with the words `` hazy '' and `` opacity ''</definiens>
			</definition>
			<definition id="3">
				<sentence>The relation 'head-of ' denotes that the findings BN is the main or `` head '' BN for that phrase .</sentence>
				<definiendum id="0">relation 'head-of</definiendum>
				<definiendum id="1">BN</definiendum>
				<definiens id="0">the main or `` head '' BN for that phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>The ASG recognizes patterns of semantic relations among the BNs , and supports analysis and inference based on those patterns .</sentence>
				<definiendum id="0">ASG</definiendum>
				<definiens id="0">recognizes patterns of semantic relations among the BNs , and supports analysis and inference based on those patterns</definiens>
			</definition>
			<definition id="5">
				<sentence>For convenience , several shorthand functional notations are used : If P represents a phrase on the parse chart , rootbn ( P ) represents the root or head BN instance in P 's interpretation graph , and type-of ( root-bn ( P ) ) is the BN type of root-bn ( P ) .</sentence>
				<definiendum id="0">type-of</definiendum>
				<definiens id="0">the root or head BN instance in P 's interpretation graph</definiens>
			</definition>
			<definition id="6">
				<sentence>M+ uses the ASG to identify that relation and to add it to the interpretation graph in the form of a path of named arcs connecting root-bn ( A ) and root-bn ( B ) .</sentence>
				<definiendum id="0">M+</definiendum>
			</definition>
			<definition id="7">
				<sentence>The M+ architecture consists of six basic components : The parser , concept space , rule base , lexicon , ASL inference engine , and Bayesian network component .</sentence>
				<definiendum id="0">M+ architecture</definiendum>
				<definiens id="0">consists of six basic components : The parser , concept space , rule base , lexicon , ASL inference engine , and Bayesian network component</definiens>
			</definition>
			<definition id="8">
				<sentence>As mentioned , the parser is an implementation of a bottom up chart parser with context free grammar .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">an implementation of a bottom up chart parser with context free grammar</definiens>
			</definition>
			<definition id="9">
				<sentence>The Bayesian network component utilizes the Norsys Netica ( TM ) API , and includes a set of Lisp and C language routines for instantiating and retrieving probabilities from BNs .</sentence>
				<definiendum id="0">Bayesian network component</definiendum>
				<definiens id="0">utilizes the Norsys Netica ( TM ) API , and includes a set of Lisp and C language routines for instantiating and retrieving probabilities from BNs</definiens>
			</definition>
			<definition id="10">
				<sentence>To parse phrases containing unknown words , M+ uses a technique based on a variation of the vector space model of lexical semantic similarity ( Manning and Schutze , 1999 ) .</sentence>
				<definiendum id="0">M+</definiendum>
				<definiens id="0">uses a technique based on a variation of the vector space model of lexical semantic similarity</definiens>
			</definition>
</paper>

		<paper id="1820">
			<definition id="0">
				<sentence>p ( ft j ) is the weight of the feature term ft j .</sentence>
				<definiendum id="0">p ( ft j )</definiendum>
				<definiens id="0">the weight of the feature term ft j</definiens>
			</definition>
			<definition id="1">
				<sentence>p ( f j ) is the weight of the topic feature f j .</sentence>
				<definiendum id="0">p ( f j )</definiendum>
				<definiens id="0">the weight of the topic feature f j</definiens>
			</definition>
			<definition id="2">
				<sentence>GAD ( f j ) is the coefficient of the topic feature f j .</sentence>
				<definiendum id="0">GAD</definiendum>
				<definiens id="0">the coefficient of the topic feature f j</definiens>
			</definition>
			<definition id="3">
				<sentence>2 ) Topic Feature Aggregation ( FA ) : According to distribution of topic features , in this phase we use topic feature aggregation formulas to compute the weights of topics of a text , then the topic of a text could be determined by the weights computed .</sentence>
				<definiendum id="0">Topic Feature Aggregation ( FA )</definiendum>
				<definiens id="0">determined by the weights computed</definiens>
			</definition>
			<definition id="4">
				<sentence>Output : a text with formats , segmentation and POS tagging Step2 : Topic feature identification Input : a text with formats , segmentation and POS tagging identification and tagging The core of the method is to use feature dictionary to realize the feature terms identification and tagging .</sentence>
				<definiendum id="0">Output</definiendum>
				<definiens id="0">a text with formats , segmentation and POS tagging Step2 : Topic feature identification Input : a text with formats , segmentation</definiens>
			</definition>
</paper>

		<paper id="1702">
			<definition id="0">
				<sentence>Content selection is a key factor of any successful document generation system .</sentence>
				<definiendum id="0">Content selection</definiendum>
				<definiens id="0">a key factor of any successful document generation system</definiens>
			</definition>
			<definition id="1">
				<sentence>Course material ( multilingual parallel corpus ) User aspects xml-dtd Document generation Document view COURSE GENERATOR Generation engine html-xml-dtdxsl-javascript Select content and format in an “intelligent” way .</sentence>
				<definiendum id="0">Course material</definiendum>
				<definiens id="0">multilingual parallel corpus ) User aspects xml-dtd Document generation Document view COURSE GENERATOR Generation engine html-xml-dtdxsl-javascript Select content and format in an “intelligent” way</definiens>
			</definition>
			<definition id="2">
				<sentence>This master document consists in a full-fledged text with references to all necessary multimedia elements ( figures , tables , pictures , links , etc. ) .</sentence>
				<definiendum id="0">master document</definiendum>
			</definition>
			<definition id="3">
				<sentence>Tags carry information of the logical composition of the text as well as metadata information about its discourse structure .</sentence>
				<definiendum id="0">Tags</definiendum>
				<definiens id="0">carry information of the logical composition of the text as well as metadata information about its discourse structure</definiens>
			</definition>
			<definition id="4">
				<sentence>The CSA determines which segments of the discourse are going to be used in order to make explicit the set of parameters that conform with the user’s profile .</sentence>
				<definiendum id="0">CSA</definiendum>
				<definiens id="0">determines which segments of the discourse are going to be used in order to make explicit the set of parameters that conform with the user’s profile</definiens>
			</definition>
			<definition id="5">
				<sentence>The selection algorithm works in three consecutive phases : parallel selection , horizontal filtering and vertical filtering .</sentence>
				<definiendum id="0">selection algorithm</definiendum>
				<definiens id="0">works in three consecutive phases : parallel selection , horizontal filtering and vertical filtering</definiens>
			</definition>
			<definition id="6">
				<sentence>Vertical filtering is the most important phase of the three as it is here that the parts of the discourse tree are selected or discarded .</sentence>
				<definiendum id="0">Vertical filtering</definiendum>
			</definition>
			<definition id="7">
				<sentence>The javascript code manages the user aspects ( one of the inputs of the algorithm ) and the application of the casdading filters ( the CSA ) .</sentence>
				<definiendum id="0">javascript code</definiendum>
			</definition>
</paper>

		<paper id="1906">
			<definition id="0">
				<sentence>Consequently , when working on large document collections , QA systems apply Information Retrieval ( IR ) techniques to reduce drastically text collections to a tractable quantity of relevant text .</sentence>
				<definiendum id="0">QA</definiendum>
				<definiendum id="1">IR )</definiendum>
			</definition>
			<definition id="1">
				<sentence>Open domain QA systems are defined as tools capable of extracting the answer to user queries directly from unrestricted domain documents .</sentence>
				<definiendum id="0">Open domain QA systems</definiendum>
				<definiens id="0">tools capable of extracting the answer to user queries directly from unrestricted domain documents</definiens>
			</definition>
			<definition id="2">
				<sentence>W q , t = log e ( f q , t + 1 ) · idf idf = log e ( N / f t + 1 ) Where f p , t is the number of times that the term t appears in the passage p. f q , t represents the number of times that the term t appears in the query q. N is the number of documents in the collection and f t is refers to the number of documents that contain the term t. document is selected for retrieval .</sentence>
				<definiendum id="0">f p</definiendum>
				<definiens id="0">the number of times that the term t appears in the passage p. f q</definiens>
				<definiens id="1">the number of times that the term t appears in the query q. N is the number of documents in the collection</definiens>
				<definiens id="2">the number of documents that contain the term t. document is selected for retrieval</definiens>
			</definition>
			<definition id="3">
				<sentence>The document set consists of 978,952 documents from the TIPSTER and TREC following collections : AP Newswire , Wall Street Journal , San Jose Mercury News , Financial Times , Los Angeles Times , Foreign Broadcast Information Service .</sentence>
				<definiendum id="0">document set</definiendum>
				<definiens id="0">consists of 978,952 documents from the TIPSTER and TREC following collections : AP Newswire , Wall Street Journal</definiens>
			</definition>
			<definition id="4">
				<sentence>ATTIR-system Documents Questions IR-n system QA system 1000 more relevant documents 200 more relevant passages Documents IR-n system 200 more relevant passages Answers Figure 1 .</sentence>
				<definiendum id="0">ATTIR-system Documents</definiendum>
				<definiens id="0">Questions IR-n system QA system 1000 more relevant documents 200 more relevant passages Documents IR-n system 200 more relevant passages Answers Figure 1</definiens>
			</definition>
</paper>

		<paper id="0904">
			<definition id="0">
				<sentence>Hand-built general-purpose lexicons , such as the WordNet ( Fellbaum , 1998 ) , have often been used to bring semantic knowledge into NLP-systems .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">used to bring semantic knowledge into NLP-systems</definiens>
			</definition>
			<definition id="1">
				<sentence>A baseNP includes optional determiners and/or premodifiers , followed by nominal heads .</sentence>
				<definiendum id="0">baseNP</definiendum>
			</definition>
			<definition id="2">
				<sentence>Each class X N has a class feature X which is the hypernym’s lemma , where N is a unique number designating the unique class and where the class members are the hyponym lemmas .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">members</definiendum>
				<definiens id="0">a unique number designating the unique class and where the class</definiens>
			</definition>
			<definition id="3">
				<sentence>That is , if X is a kind of Y , and Y is a kind of Z , then the two classes containing these pairs can only be composed if the hyponymy relation also holds between X and Z. In practice , the three hypernym-hyponym pairs X-Y , Y-Z and X-Z all have to be found in our corpus.3 Next , we will turn to the outline of the implementation for building the hierarchical structures from the classes created through the method described in the previous section : a. find all sets of classes that can be used in building hierarchies with class k. b. choose one set of classes that should be used .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">a kind of Z</definiens>
			</definition>
			<definition id="4">
				<sentence>kind : a0a7a1a4a3 ( funcword ) + a0a2a1a4a8 ( a0a7a1a34a16 , ) * anda23or a0a7a1a30a29 where a0a7a1a4a3 is a baseNP , where ( funcword ) + is one or more function words 5 and where the sequence ‘ ( a0a2a1a9a16 , ( anda23or ) ) + a0a7a1a30a29 ’ is a conjoined noun phrase .</sentence>
				<definiendum id="0">a0a7a1a4a3</definiendum>
				<definiens id="0">a baseNP , where ( funcword ) + is one or more function words 5 and where the sequence ‘ ( a0a2a1a9a16 , ( anda23or ) ) + a0a7a1a30a29 ’ is a conjoined noun phrase</definiens>
			</definition>
			<definition id="5">
				<sentence>A d-pair is defined as an ordered pair of terms a119 a80a101a120a11a10a6a80a6a121a123a122 in the hierarchy where t1 dominates t2 , and where t1 a117a118 t2 .</sentence>
				<definiendum id="0">d-pair</definiendum>
			</definition>
</paper>

		<paper id="0601">
</paper>

		<paper id="1205">
			<definition id="0">
				<sentence>OLACMS ( stands for Open Language Archives Community Metadata Set ) is a standard for describe language resources .</sentence>
				<definiendum id="0">OLACMS</definiendum>
			</definition>
			<definition id="1">
				<sentence>Three primary standards are the foundational basis of the OLAC infrastructure that serve to bridge the multiple gaps which now lie in between language resources and users : ( 1 ) OLACMS : the OLAC Metadata Set ( Qualified DC , Dublin Core ) , ( 2 ) OLAC MHP : refinements to the OAI ( Open Archives Initiative , http : //www.openarchives.org ) protocol , and ( 3 ) OLAC Process : a procedure for identifying Best Common Practice Recommendations .</sentence>
				<definiendum id="0">OAI ( Open Archives Initiative , http</definiendum>
				<definiendum id="1">OLAC Process</definiendum>
				<definiens id="0">the foundational basis of the OLAC infrastructure that serve to bridge the multiple gaps which now lie in between language resources and users : ( 1 ) OLACMS : the OLAC Metadata Set ( Qualified DC</definiens>
			</definition>
			<definition id="2">
				<sentence>First , the Dublin Core Metadata Initiative ( DCMI ) is an open forum engaged in the development of interoperable online metadata standards that support a broad range of purposes and business models .</sentence>
				<definiendum id="0">Dublin Core Metadata Initiative</definiendum>
				<definiens id="0">an open forum engaged in the development of interoperable online metadata standards that support a broad range of purposes</definiens>
			</definition>
			<definition id="3">
				<sentence>standards ISLE Meta Data Initiative ( IMDI ) is a cousin of OLACMS .</sentence>
				<definiendum id="0">IMDI</definiendum>
				<definiens id="0">a cousin of OLACMS</definiens>
			</definition>
			<definition id="4">
				<sentence>IMDI proposes a metadata set for natural language processing under the broader International Standards for Language Engineering ( ISLE ) project .</sentence>
				<definiendum id="0">IMDI</definiendum>
				<definiens id="0">proposes a metadata set for natural language processing under the broader International Standards for Language Engineering ( ISLE ) project</definiens>
			</definition>
			<definition id="5">
				<sentence>ISLE is co-sponsored by the European Commission of the EU and National Science Foundation of the USA .</sentence>
				<definiendum id="0">ISLE</definiendum>
				<definiens id="0">co-sponsored by the European Commission of the EU and National Science Foundation of the USA</definiens>
			</definition>
			<definition id="6">
				<sentence>On one hand , IMDI is an elaboration of OLACMS since it deals specifically with recording sessions .</sentence>
				<definiendum id="0">IMDI</definiendum>
				<definiens id="0">an elaboration of OLACMS since it deals specifically with recording sessions</definiens>
			</definition>
			<definition id="7">
				<sentence>By his definition , an ( linguistic ) event that called a session is the top element and there results a number of related linguistic resources : Video tape , Photographs , Digitised video file , Digitised photographs , Digitisations of the images used as stimuli , One electronic transcription file , One or more electronic analysis files , Field notes and experiment descriptions ( in electronic form ) .</sentence>
				<definiendum id="0">session</definiendum>
				<definiendum id="1">Digitised</definiendum>
			</definition>
			<definition id="8">
				<sentence>IMDI Team ( August 2001 ) mapped IMDI Session Descriptions with OLAC description formalisms used by institutions that deal with “published corpora” such as [ ELRA ] and [ LDC ] .</sentence>
				<definiendum id="0">IMDI Team</definiendum>
			</definition>
			<definition id="9">
				<sentence>The IMDI Team ( Gibbon , et al. 2001 ) launched IMDI Metadata Elements for Catalogue Descriptions , Version Lexicon Descriptions .</sentence>
				<definiendum id="0">IMDI Team</definiendum>
				<definiens id="0">et al. 2001 ) launched IMDI Metadata Elements for Catalogue Descriptions , Version Lexicon Descriptions</definiens>
			</definition>
			<definition id="10">
				<sentence>For instance , the Sinica Corpus covers the language of the Republica of China in Taiwan .</sentence>
				<definiendum id="0">Sinica Corpus</definiendum>
				<definiens id="0">covers the language of the Republica of China in Taiwan</definiens>
			</definition>
			<definition id="11">
				<sentence>Sinica Corpus specifies the media of the language reources as : Newspaper , General Magazine , Academic Journal , Textbook , The Topic parameter of Sinica Corpus has the same content as the element Subject .</sentence>
				<definiendum id="0">Sinica Corpus</definiendum>
				<definiens id="0">Topic parameter of Sinica Corpus has the same content as the element Subject</definiens>
			</definition>
			<definition id="12">
				<sentence>Table 2 Topic of Sinica Corpus ( Ckip Technology Report 93-05 ) Primary Sub Philosophy Thoughts | Psychology | Religion | Natural Science Mathematics | Astronomy | Physics | Chemical | Mineral | Creature | Agriculture | Archeology | Geography | Environmental Protection | Earch Science | Engineering | Social Sciences Economy | Finance | Business &amp; Management | Marketing | Politics | Political Party | Political Activities | National Policy | International Relations | Domestic Affairs | Military |Judicature | Education | Transportation | Culture | History | Race | Language | MassMedia | Public Welfare | Welfare | Personnel Matters | Statistical Survey | Crime | Calamity | Sociological Facts | Arts Music | Dance | Sculp | Painting | Photography | Drama | Artistry | Historical Relics | Architecture | General Arts | General /Leisure Travels | Sport | Foods | Medical Treatment | Hygine | Clothes | Movie and popular arts | People | Information | Cunsume | Family | Literature Literary Theory | Criticism | Other literary work | Indigenous Literature | Childern’s Literature | Martial Arts Literature | Romance | An example for the adoptation follows : for a Sinica Corpus text with a Topic of Arts and a sub-topic of Music , it will be catalgued as follows : &lt; Subject &gt; Arts/Music &lt; /Subject &gt; .</sentence>
				<definiendum id="0">Sinica Corpus</definiendum>
			</definition>
			<definition id="13">
				<sentence>SIL has produced an online searchable database : Ethnologue that provides a comprehensive system of language identification covering more than 6,800 languages .</sentence>
				<definiendum id="0">SIL</definiendum>
			</definition>
</paper>

		<paper id="0716">
			<definition id="0">
				<sentence>In Model 1 ( Figure 1 ) we treat the entire software system as a “black box , ” just recognizing that the input is a source language utterance ( SLU ) and the output is a target language utterance ( TLU ) .</sentence>
				<definiendum id="0">SLU</definiendum>
				<definiens id="0">a source language utterance</definiens>
				<definiens id="1">a target language utterance</definiens>
			</definition>
			<definition id="1">
				<sentence>First , a U2U metric for production use should consist of approximately seven categories of errors , plus or minus two .</sentence>
				<definiendum id="0">U2U metric</definiendum>
				<definiens id="0">consist of approximately seven categories of errors , plus or minus two</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , one category may refer to the appropriate mapping of source language words to target language words , where appropriate is defined by the category description .</sentence>
				<definiendum id="0">appropriate</definiendum>
				<definiens id="0">the appropriate mapping of source language words to target language words</definiens>
			</definition>
</paper>

		<paper id="0701">
			<definition id="0">
				<sentence>For this , we use DP-matching , which tells us the distance between word sequences , dist while giving us the matched portions between the input and the example .</sentence>
				<definiendum id="0">DP-matching</definiendum>
				<definiens id="0">tells us the distance between word sequences</definiens>
			</definition>
			<definition id="1">
				<sentence>K is the level of the most specific common abstraction of two words , and N is the height of the thesaurus .</sentence>
				<definiendum id="0">K</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the level of the most specific common abstraction of two words , and</definiens>
				<definiens id="1">the height of the thesaurus</definiens>
			</definition>
			<definition id="2">
				<sentence>3 The TOEIC ( Test of English for International Communcation ) test is an English language proficiency test for people whose native language is not English ( http : //www.chauncey.com/ ) .</sentence>
				<definiendum id="0">TOEIC</definiendum>
				<definiens id="0">an English language proficiency test for people whose native language is not English ( http : //www.chauncey.com/ )</definiens>
			</definition>
			<definition id="3">
				<sentence>Statistical machine translation ( SMT ) represents a translation process as a noisy channel model that consists of a source-channel model and a language model of the target language .</sentence>
				<definiendum id="0">SMT )</definiendum>
				<definiens id="0">represents a translation process as a noisy channel model that consists of a source-channel model and a language model of the target language</definiens>
			</definition>
			<definition id="4">
				<sentence>Synonymous expressions are defined as a sequence of variant words with surrounding common words .</sentence>
				<definiendum id="0">Synonymous expressions</definiendum>
				<definiens id="0">a sequence of variant words with surrounding common words</definiens>
			</definition>
</paper>

		<paper id="1404">
</paper>

		<paper id="0202">
			<definition id="0">
				<sentence>Spoken discourses between native speakers of English and Hong Kong Chinese have been recorded as a first step to build up the Hong Kong Corpus of Spoken English ( HKCSE ) .</sentence>
				<definiendum id="0">Spoken discourses</definiendum>
			</definition>
			<definition id="1">
				<sentence>Each sub-corpora consists of 50 hours of naturally-occurring discourses .</sentence>
				<definiendum id="0">sub-corpora</definiendum>
			</definition>
			<definition id="2">
				<sentence>Tone is the tonic or nucleus in a tone unit ( i.e. the last prominent syllable of a tone unit ) , and either the letters are capitalised or underlined , the latter is for cases in which more stressed syllables follow the tonic .</sentence>
				<definiendum id="0">Tone</definiendum>
				<definiens id="0">the tonic or nucleus in a tone unit</definiens>
			</definition>
</paper>

		<paper id="1109">
			<definition id="0">
				<sentence>WordNet , An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>8 David D. McDonald , Internal and external evidence in the identification and semantic categorization of proper names , Corpus processing for lexical acquisition , MIT Press , Cambridge , MA , 1996 9 Andrei Mikheev , Marc Moens , Claire Grover , Named Entity recognition without gazetteers , Proceedings of the ninth conference on European chapter of the Association for Computational Linguistics , June 08-12 , 1999 , Bergen , Norway 10 Pianta , E. , Bentivogli , L. , and Girardi , C. ( 2002 ) .</sentence>
				<definiendum id="0">Corpus processing</definiendum>
				<definiens id="0">external evidence in the identification and semantic categorization of proper names</definiens>
			</definition>
			<definition id="2">
				<sentence>MultiWordNet : Developing an Aligned Multilingual Database .</sentence>
				<definiendum id="0">MultiWordNet</definiendum>
			</definition>
</paper>

		<paper id="2014">
</paper>

		<paper id="2035">
</paper>

		<paper id="0200">
			<definition id="0">
				<sentence>The workshop is organized by SIGdial ( http : //www.sigdial.org ) which is sponsored jointly by ACL ( http : //www.aclweb.org ) and ISCA ( http : //www.isca-speech.org ) .</sentence>
				<definiendum id="0">SIGdial ( http</definiendum>
				<definiendum id="1">ISCA ( http</definiendum>
				<definiens id="0">//www.sigdial.org ) which is sponsored jointly by ACL ( http : //www.aclweb.org )</definiens>
			</definition>
</paper>

		<paper id="0709">
			<definition id="0">
				<sentence>n is an integer , and n ≥ 1 .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">an integer , and n ≥ 1</definiens>
			</definition>
			<definition id="1">
				<sentence>Fourth , DMM works to supervise the interaction for disambiguation of the input .</sentence>
				<definiendum id="0">DMM</definiendum>
				<definiens id="0">works to supervise the interaction for disambiguation of the input</definiens>
			</definition>
			<definition id="2">
				<sentence>The inter-lingua uses the interchangeable format ( IF ) developed by C-STAR ( Consortium for Speech Translation Advanced Research ) .</sentence>
				<definiendum id="0">inter-lingua</definiendum>
			</definition>
			<definition id="3">
				<sentence>A split unit is one of the following expressions : null A single word .</sentence>
				<definiendum id="0">split unit</definiendum>
				<definiens id="0">one of the following expressions : null A single word</definiens>
			</definition>
			<definition id="4">
				<sentence>The DMM asks the user ques features of a specific verb , In the DMM module , a fram express the user’s intentions , which consists of a series of slots as follows .</sentence>
				<definiendum id="0">DMM</definiendum>
				<definiens id="0">asks the user ques features of a specific verb</definiens>
				<definiens id="1">consists of a series of slots as follows</definiens>
			</definition>
			<definition id="5">
				<sentence>TYPE : { Interrogative/… } AGENT : noun ; OBJECT1 : noun ; OBJECT2 : noun ; QUANTITY1 : numeral ; UNIT1 : classifier ; QUANTITY2 : numeral ; UNIT2 : classifier ; TIME : numeral &amp; classifier ; HOW : adjective ; Figure 3 .</sentence>
				<definiendum id="0">TIME</definiendum>
				<definiens id="0">numeral &amp; classifier</definiens>
			</definition>
			<definition id="6">
				<sentence>Because the keywords have been spotted out and their dependence relations have been analyzed , the DMM asks the user according to the analysis results and the concrete context .</sentence>
				<definiendum id="0">DMM</definiendum>
				<definiens id="0">asks the user according to the analysis results and the concrete context</definiens>
			</definition>
			<definition id="7">
				<sentence>Because the SR module still does not recognize the speech of the word ‘香格里拉 ( Shangri-la ) ’ , the DMM is unable to parse the user’s answer .</sentence>
				<definiendum id="0">DMM</definiendum>
				<definiens id="0">the speech of the word ‘香格里拉 ( Shangri-la ) ’ , the</definiens>
			</definition>
			<definition id="8">
				<sentence>ACTION is the English word corresponding to the Chinese word in the ACTION slot .</sentence>
				<definiendum id="0">ACTION</definiendum>
			</definition>
			<definition id="9">
				<sentence>However , we are facing much hard work that involve the following aspects at least : null Develop the reasonable strategies and standards to evaluate the parsing results ; null Design the effective templates to ask the user questions according the keywords and the concrete context ; null Define the practical templates to generate the translation results ; null Build the machine learning mechanism to enrich the knowledge base of the system .</sentence>
				<definiendum id="0">null Build</definiendum>
				<definiens id="0">the machine learning mechanism to enrich the knowledge base of the system</definiens>
			</definition>
</paper>

		<paper id="1202">
</paper>

		<paper id="1408">
			<definition id="0">
				<sentence>ATR is based on the C/NC-value method ( Frantzi et al. 1 BioPath is a Eureka funded project , coordinated by LION BioScience ( http : //www.lionbioscience.com ) and funded by the German Ministry of Research .</sentence>
				<definiendum id="0">ATR</definiendum>
				<definiendum id="1">BioPath</definiendum>
			</definition>
			<definition id="1">
				<sentence>Context pattern ( CP ) is a generalised regular expression that corresponds to either left or right context of a term .</sentence>
				<definiendum id="0">CP</definiendum>
			</definition>
			<definition id="2">
				<sentence>It assesses a CP ( p ) according to its total frequency ( f ( p ) ) , its length ( |p| , as the number of constituents ) and the frequency of its occurrence within other CPs ( |T p | , where T p is a set of all CPs that contain p ) : The CPs whose CP-value is above a chosen threshold are deemed important .</sentence>
				<definiendum id="0">total frequency</definiendum>
				<definiendum id="1">CPs whose CP-value</definiendum>
				<definiens id="0">the number of constituents ) and the frequency of its occurrence within other CPs ( |T p | , where T p is a set of all CPs that contain p</definiens>
			</definition>
			<definition id="3">
				<sentence>Non-terminal &lt; &amp; &gt; denotes a conjunctive word sequence , i.e. the following regular expression : ( as well as ) | ( and [ /or ] ) | ( or [ /and ] ) .</sentence>
				<definiendum id="0">&gt;</definiendum>
				<definiens id="0">a conjunctive word sequence</definiens>
			</definition>
			<definition id="4">
				<sentence>Term glucocotricoid receptor estrogen receptor steroid receptor 0.66 0.64 progesterone receptor 0.55 0.59 human estrogen t retinoid x receptor 0.27 0.36 nuclear receptor 0.30 0.33 receptor complex 0.31 0.33 retinoic acid receptor 0.27 0.28 retinoid nuclear t Table 7 : Similarity values for glucocorticoid receptor and estrogen receptor The supervised learning of parameters resulted in the values 0.13 , 0.81 and 0.06 for α , β , and γ respectively ( see Spasić et al. ( 2002 ) ) .</sentence>
				<definiendum id="0">γ respectively</definiendum>
				<definiens id="0">Similarity values for glucocorticoid receptor and estrogen receptor The supervised learning of parameters resulted in the values 0.13 , 0.81 and 0.06 for α , β , and</definiens>
			</definition>
</paper>

		<paper id="0306">
			<definition id="0">
				<sentence>Natural Language is a vital medium in medicine .</sentence>
				<definiendum id="0">Natural Language</definiendum>
				<definiens id="0">a vital medium in medicine</definiens>
			</definition>
			<definition id="1">
				<sentence>Natural Language Processing ( NLP ) tools have been applied to medical narrative for a variety of applications , such as triggering clinical alerts ( Friedman , 1997 ) and document classification ( Wilcox , 2000 ) .</sentence>
				<definiendum id="0">Natural Language Processing</definiendum>
				<definiens id="0">applied to medical narrative for a variety of applications , such as triggering clinical alerts</definiens>
			</definition>
			<definition id="2">
				<sentence>Dependency grammars ( Hudson , 1991 ) generate parses where words in a sentence are related directly to the word which is its syntactic head .</sentence>
				<definiendum id="0">Dependency grammars</definiendum>
				<definiens id="0">generate parses where words in a sentence are related directly to the word which is its syntactic head</definiens>
			</definition>
			<definition id="3">
				<sentence>TBL is a good choice for learning a dependency grammar of medical language .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">a good choice for learning a dependency grammar of medical language</definiens>
			</definition>
</paper>

		<paper id="0109">
			<definition id="0">
				<sentence>NLTK , the Natural Language Toolkit , is a suite of open source program modules , tutorials and problem sets , providing ready-to-use computational linguistics courseware .</sentence>
				<definiendum id="0">NLTK</definiendum>
				<definiendum id="1">Natural Language Toolkit</definiendum>
				<definiens id="0">a suite of open source program modules , tutorials and problem sets , providing ready-to-use computational linguistics courseware</definiens>
			</definition>
			<definition id="1">
				<sentence>Python is an object-oriented scripting language developed by Guido van Rossum and available on all platforms ( www.python.org ) .</sentence>
				<definiendum id="0">Python</definiendum>
				<definiens id="0">an object-oriented scripting language developed by Guido van Rossum and available on all platforms ( www.python.org )</definiens>
			</definition>
			<definition id="2">
				<sentence>Python is an object-oriented language , but not punitively so , and it is easy to encapsulate data and methods inside Python classes .</sentence>
				<definiendum id="0">Python</definiendum>
			</definition>
			<definition id="3">
				<sentence>The pcfgparser module provides a variety of difierent parsers for probabilistic grammars .</sentence>
				<definiendum id="0">pcfgparser module</definiendum>
			</definition>
			<definition id="4">
				<sentence>maxent module deflnes the maximum entropy model for text classiflcation , and implements two algorithms for training the model : Generalized Iterative Scaling and Improved Iterative Scaling .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
				<definiens id="0">Generalized Iterative Scaling and Improved Iterative Scaling</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , ChunkRule ( ’ &lt; NN.* &gt; ’ ) builds chunks from sequences of consecutive nouns ; ChinkRule ( ’ &lt; VB. &gt; ’ ) excises verbs from existing chunks ; SplitRule ( ’ &lt; NN &gt; ’ , ’ &lt; DT &gt; ’ ) splits any existing chunk that contains a singular noun followed by determiner into two pieces ; and MergeRule ( ’ &lt; JJ &gt; ’ , ’ &lt; JJ &gt; ’ ) combines two adjacent chunks where the flrst chunk ends and the second chunk starts with adjectives .</sentence>
				<definiendum id="0">MergeRule</definiendum>
				<definiens id="0">consecutive nouns ; ChinkRule ( ’ &lt; VB. &gt; ’ ) excises verbs from existing chunks ; SplitRule ( ’ &lt; NN &gt; ’</definiens>
				<definiens id="1">two adjacent chunks where the flrst chunk ends</definiens>
			</definition>
			<definition id="6">
				<sentence>* &gt; +’ ) ChinkRule ( ’ &lt; VB.*|IN|CC|R.*|MD|WRB|TO|.| , &gt; +’ ) ] NLTK provides graphical tools that can be used in class demonstrations to help explain basic NLP concepts and algorithms .</sentence>
				<definiendum id="0">NLTK</definiendum>
				<definiens id="0">provides graphical tools that can be used in class demonstrations to help explain basic NLP concepts and algorithms</definiens>
			</definition>
			<definition id="7">
				<sentence>Example : The Chart Parsing Tool The chart parsing tool is an example of a graphical tool provided by NLTK .</sentence>
				<definiendum id="0">chart parsing tool</definiendum>
				<definiens id="0">an example of a graphical tool provided by NLTK</definiens>
			</definition>
			<definition id="8">
				<sentence>Chart parsing is a exible parsing algorithm that uses a data structure called a chart to record hypotheses about syntactic constituents .</sentence>
				<definiendum id="0">Chart parsing</definiendum>
				<definiens id="0">a exible parsing algorithm that uses a data structure called a chart to record hypotheses about syntactic constituents</definiens>
			</definition>
			<definition id="9">
				<sentence>We used NLTK as a basis for the assignments and student projects in CIS-530 , an introductory computational linguistics class taught at the University of Pennsylvania .</sentence>
				<definiendum id="0">NLTK</definiendum>
				<definiens id="0">a basis for the assignments and student projects in CIS-530 , an introductory computational linguistics class taught at the University of Pennsylvania</definiens>
			</definition>
			<definition id="10">
				<sentence>NLTK provides a simple , extensible , uniform framework for assignments , projects , and class demonstrations .</sentence>
				<definiendum id="0">NLTK</definiendum>
				<definiens id="0">provides a simple , extensible , uniform framework for assignments , projects , and class demonstrations</definiens>
			</definition>
			<definition id="11">
				<sentence>Second , its target audience consists of both linguists and computer scientists , and it is accessible and challenging at many levels of prior computational skill .</sentence>
				<definiendum id="0">target audience</definiendum>
				<definiens id="0">consists of both linguists and computer scientists , and it is accessible and challenging at many levels of prior computational skill</definiens>
			</definition>
			<definition id="12">
				<sentence>NLTK is an open source project , and we welcome any contributions .</sentence>
				<definiendum id="0">NLTK</definiendum>
				<definiens id="0">an open source project</definiens>
			</definition>
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>Evidence from Extraction Patterns Basilisk ( Bootstrapping Approach to SemantIc Lexicon Induction using Semantic Knowledge ) is a weakly supervised bootstrapping algorithm that automatically generates semantic lexicons .</sentence>
				<definiendum id="0">Extraction Patterns Basilisk</definiendum>
				<definiens id="0">a weakly supervised bootstrapping algorithm that automatically generates semantic lexicons</definiens>
			</definition>
			<definition id="1">
				<sentence>Basilisk scores each candidate word by gathering all patterns that extract it and measuring how strongly those contexts are associated with words that belong to the semantic category .</sentence>
				<definiendum id="0">Basilisk</definiendum>
				<definiens id="0">scores each candidate word by gathering all patterns that extract it and measuring how strongly those contexts</definiens>
			</definition>
			<definition id="2">
				<sentence>AutoSlog’s extraction patterns represent linguistic expressions that extract a noun phrase in one of three syntactic roles : subject , direct object , or prepositional phrase object .</sentence>
				<definiendum id="0">AutoSlog’s extraction patterns</definiendum>
			</definition>
			<definition id="3">
				<sentence>Intuitively , the RlogF metric is a weighted conditional probability ; a pattern receives a high score if a high percentage of its extractions are category members , or if a moderate percentage of its extractions are category members anditextractsalotofthem .</sentence>
				<definiendum id="0">RlogF metric</definiendum>
			</definition>
			<definition id="4">
				<sentence>Basilisk uses a value of N=20 for the rst iteration , which allows a variety of patterns to be considered , yet is small enough that all of the patterns are strongly associated with the category .</sentence>
				<definiendum id="0">Basilisk</definiendum>
				<definiens id="0">uses a value of N=20 for the rst iteration , which allows a variety of patterns to be considered</definiens>
			</definition>
			<definition id="5">
				<sentence>Basilisk collects all noun phrases ( NPs ) extracted by patterns in the pattern pool and puts the head noun of each NP into the candidate word pool .</sentence>
				<definiendum id="0">Basilisk</definiendum>
				<definiens id="0">collects all noun phrases ( NPs ) extracted by patterns in the pattern pool and puts the head noun of each NP into the candidate word pool</definiens>
			</definition>
			<definition id="6">
				<sentence>The formula is : score ( word i ) = P i X j=1 F j P i ( 2 ) where P i is the number of patterns that extract word i , andF j is the number of distinct category members extracted by pattern j. A word receives a high score if it is extracted by patterns that also have a tendency to extract known category members .</sentence>
				<definiendum id="0">word</definiendum>
				<definiens id="0">the number of patterns that extract word i</definiens>
			</definition>
			<definition id="7">
				<sentence>Basilisk nds all patterns that extract \Peru '' and computes the average number of known locations extracted by those patterns .</sentence>
				<definiendum id="0">Basilisk</definiendum>
				<definiens id="0">nds all patterns that extract \Peru '' and computes the average number of known locations extracted by those patterns</definiens>
			</definition>
			<definition id="8">
				<sentence>Rilo and Shepherd ( Rilo and Shepherd , 1997 ) developed a bootstrapping algorithm that exploits lexical co-occurrence statistics , and Roark and Charniak ( Roark and Charniak , 1998 ) re ned this algorithm to focus more explicitly on certain syntactic structures .</sentence>
				<definiendum id="0">bootstrapping algorithm</definiendum>
				<definiens id="0">exploits lexical co-occurrence statistics</definiens>
			</definition>
			<definition id="9">
				<sentence>Hale , Ge , and Charniak ( Ge et al. , 1998 ) devised a technique to learn the gender of words .</sentence>
				<definiendum id="0">Charniak</definiendum>
				<definiens id="0">Ge et al. , 1998 ) devised a technique to learn the gender of words</definiens>
			</definition>
			<definition id="10">
				<sentence>Each word w i in the candidate word pool receives a score for category c a based on the following formula : di ( w i , c a ) = AvgLog ( w i , c a ) -max b6=a ( AvgLog ( w i , c b ) ) where AvgLog is the candidate scoring function used previously by Basilisk ( see Equation 3 ) and the max function returns the maximum AvgLog value over all competing categories .</sentence>
				<definiendum id="0">AvgLog</definiendum>
				<definiens id="0">the candidate scoring function used previously by Basilisk ( see Equation 3 ) and the max function returns the maximum AvgLog value over all competing categories</definiens>
			</definition>
			<definition id="11">
				<sentence>A word is ranked highly only if it has a high score for the 0 10 20 30 40 50 60 70 80 90 100 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Building mb-M mb-1 0 50 100 150 200 250 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Event mb-M mb-1 0 100 200 300 400 500 600 700 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Human mb-M mb-1 0 100 200 300 400 500 600 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Location mb-M mb-1 0 5 10 15 20 25 30 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Time mb-M mb-1 0 10 20 30 40 50 60 70 80 90 100 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Weapon mb-M mb-1 Figure 7 : Meta-Bootstrapping , MCAT vs. 1CAT targeted category and there is little evidence that it belongs to a di erent category .</sentence>
				<definiendum id="0">mb-M</definiendum>
				<definiens id="0">the 0 10 20 30 40 50 60 70 80 90 100 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Building mb-M mb-1 0 50 100 150 200 250 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Event mb-M mb-1 0 100 200 300 400 500 600 700 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Human mb-M mb-1 0 100 200 300 400 500 600 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Location mb-M mb-1 0 5 10 15 20 25 30 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Time mb-M mb-1 0 10 20 30 40 50 60 70 80 90 100 0 200 400 600 800 1000 Correct Lexicon Entries Total Lexicon Entries Weapon</definiens>
			</definition>
</paper>

		<paper id="1605">
			<definition id="0">
				<sentence>ParSit consists of four modules that are a syntax analysis module , a semantic analysis module , a semantic generation module , and a syntax generation module .</sentence>
				<definiendum id="0">ParSit</definiendum>
				<definiens id="0">consists of four modules that are a syntax analysis module , a semantic analysis module , a semantic generation module</definiens>
			</definition>
			<definition id="1">
				<sentence>RIPPER is a propositional rule learning algorithm that constructs a ruleset which classifies the training data [ 11 ] .</sentence>
				<definiendum id="0">RIPPER</definiendum>
			</definition>
			<definition id="2">
				<sentence>∈ A s , where A n is a nominal attribute and v is a legal value for A n ; or A c is a continuous variable and θ is some value for A c that occurs in the training data ; or A s is a set-value attribute and v is a value that is an element of A s .</sentence>
				<definiendum id="0">A n</definiendum>
				<definiendum id="1">v</definiendum>
				<definiendum id="2">A c</definiendum>
				<definiendum id="3">θ</definiendum>
				<definiendum id="4">A s</definiendum>
				<definiendum id="5">v</definiendum>
				<definiens id="0">a nominal attribute and</definiens>
				<definiens id="1">a legal value for A n ; or</definiens>
				<definiens id="2">a continuous variable and</definiens>
				<definiens id="3">some value for A c that occurs in the training data ; or</definiens>
				<definiens id="4">a set-value attribute and</definiens>
			</definition>
			<definition id="3">
				<sentence>A set-valued attribute is an attribute whose value is a set of strings .</sentence>
				<definiendum id="0">set-valued attribute</definiendum>
				<definiens id="0">a set of strings</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>Ensemble learning is a machine learning technique that combines the output of several different classiers with the goal of improving classi cation performance .</sentence>
				<definiendum id="0">Ensemble learning</definiendum>
				<definiens id="0">a machine learning technique that combines the output of several different classiers with the goal of improving classi cation performance</definiens>
			</definition>
			<definition id="1">
				<sentence>We de ne a context relation instance as a tuple ( w ; r ; w0 ) where w is a thesaurus term , occurring in a relation of type r , with another word w0 in the sentence .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">a thesaurus term , occurring in a relation of type r</definiens>
			</definition>
			<definition id="2">
				<sentence>C ( A ; B ) = ( 1 jerrors ( A ) \errors ( B ) jjerrors ( A ) j ) 100 % ( 1 ) Rs ( A ; B ) = P i ( r ( Ai ) r ( A ) ) ( r ( Bi ) r ( B ) ) q P i ( r ( Ai ) r ( A ) ) 2 qP i ( r ( Bi ) r ( B ) ) 2 ( 2 ) where r ( x ) is the rank of synonym x. The Spearman rank-order correlation coef cient is the linear correlation coef cient between the rankings of elements of A and B. Rs is a useful non-parametric comparison for when the rank order is more relevant than the actual values in the distribution .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">B ) jjerrors</definiendum>
				<definiendum id="2">r</definiendum>
				<definiendum id="3">r</definiendum>
				<definiendum id="4">B. Rs</definiendum>
			</definition>
			<definition id="3">
				<sentence>INVR is the sum of the inverse rank of each matching synonym , e.g. gold standard matches at ranks 3 , 5 and 28 give an inverse rank score of 1 3 + 1 5 + 1 28 0:569 .</sentence>
				<definiendum id="0">INVR</definiendum>
				<definiens id="0">the sum of the inverse rank of each matching synonym</definiens>
			</definition>
			<definition id="4">
				<sentence>Top n precision is the percentage of matching synonyms in the top n extracted synonyms .</sentence>
				<definiendum id="0">Top n precision</definiendum>
				<definiens id="0">the percentage of matching synonyms in the top n extracted synonyms</definiens>
			</definition>
</paper>

		<paper id="0809">
			<definition id="0">
				<sentence>Solving lexical ambiguity , or word sense disambiguation ( WSD ) , is an important task in Natural Language Processing systems ( Kilgarriff and Palmer , 2000 ) .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">an important task in Natural Language Processing systems</definiens>
			</definition>
			<definition id="1">
				<sentence>The distinguishing feature of memory-based learning ( MBL ) in contrast with minimal-descriptionlength-driven or “eager” ML algorithms is that MBL keeps all training data in memory , and only abstracts at classification time by extrapolating a class from the most similar item ( s ) in memory to the new test item .</sentence>
				<definiendum id="0">memory-based learning</definiendum>
				<definiendum id="1">MBL</definiendum>
				<definiendum id="2">MBL</definiendum>
			</definition>
			<definition id="2">
				<sentence>Sense tags consist of the word’s lemma and a sense description of one or two words ( berg stapel ) or a reference of the grammatical category ( fiets N , fietsen V ) .</sentence>
				<definiendum id="0">Sense tags</definiendum>
			</definition>
</paper>

		<paper id="0214">
			<definition id="0">
				<sentence>ordered semantic space The Self-Organizing Map ( Kohonen , 1982 ; Kohonen , 1995 ) is an unsupervised neural network method suitable for ordering and visualization of complex data sets .</sentence>
				<definiendum id="0">Self-Organizing Map</definiendum>
			</definition>
			<definition id="1">
				<sentence>dialogue topic of a dialogue turn The ordered document map can be utilized in the analysis of dialogue topics as follows : encode a dialogue turn , i.e. , an utterance u ( or an utterance combined with its recent history ) as a document vector .</sentence>
				<definiendum id="0">utterance u</definiendum>
				<definiens id="0">encode a dialogue turn</definiens>
			</definition>
			<definition id="2">
				<sentence>The probability model used for topic estimation is P ( Ai|S ) = P ( XN|S ) P ( Ai|XN ) , ( 1 ) where Ai is the topic category , S denotes the text transcription of the spoken sentence and XN is the set of N best map vectors used for the classification .</sentence>
				<definiendum id="0">Ai</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">XN</definiendum>
				<definiens id="0">the topic category ,</definiens>
				<definiens id="1">the text transcription of the spoken sentence and</definiens>
				<definiens id="2">the set of N best map vectors used for the classification</definiens>
			</definition>
			<definition id="3">
				<sentence>Stopwords ( function words etc. ) and words that appeared fewer than 2 times in the training data were removed .</sentence>
				<definiendum id="0">Stopwords</definiendum>
				<definiens id="0">words etc. ) and words that appeared fewer than 2 times in the training data were removed</definiens>
			</definition>
			<definition id="4">
				<sentence>The probability of a word belonging to the class topic , focus or other is modeled as P ( Ti|W , S ) = P ( Ti|W ) P ( Ti|S ) P ( T i ) , ( 2 ) where W denotes the word , S its position in an utterance , and Ti ∈ { topic , focus , other } stands for the class .</sentence>
				<definiendum id="0">W</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">the word ,</definiens>
				<definiens id="1">its position in an utterance , and Ti ∈ { topic , focus , other } stands for the class</definiens>
			</definition>
			<definition id="5">
				<sentence>For the term P ( Ti|S ) that describes the effect of the position of a word we use a softmax model , namely P ( Ti|Sj ) = e qi ( xj ) summationtext i eqi ( xj ) , ( 3 ) where the index j identifies the word and xj is the position of the word j. The functions qi are defined as simple linear functions qi ( xj ) = aixj +bi ( 4 ) The parameters ai and bi are estimated from the training data .</sentence>
				<definiendum id="0">P ( Ti|S )</definiendum>
				<definiendum id="1">xj</definiendum>
				<definiens id="0">describes the effect of the position of a word we use a softmax model , namely P ( Ti|Sj ) = e qi ( xj ) summationtext i eqi ( xj ) , ( 3 ) where the index j identifies the word and</definiens>
			</definition>
</paper>

		<paper id="1817">
			<definition id="0">
				<sentence>That is : T= ( t 1 , t 2 , … , t m ) , R= ( r 1 , r 2 , … , r m ) , m &gt; 0 , R # = arg P ( R|T ) ... ... ... ... ... ... .… ... ... ..E1 R max According to the Bayes equation , we can get : P ( R|T ) = P ( R ) P ( T|R ) /P ( T ) ... ... ... ... ... ... .E2 For a particular token sequence , P ( T ) is a constant .</sentence>
				<definiendum id="0">P ( T )</definiendum>
				<definiens id="0">a constant</definiens>
			</definition>
			<definition id="1">
				<sentence>Input : Corpus which is segmented and POS tagged T : the type of unknown words ; R : Roles set of T Output : C ( t i , r i ) , C ( r i ) and C ( r i-1 , r i ) Algorithm : ( 1 ) Get one sentence S from corpus C ; ( 2 ) Extract all tokens and POS tags from S ; ( 3 ) Convert all POS tags to roles in T after role analysis .</sentence>
				<definiendum id="0">POS tagged T</definiendum>
				<definiens id="0">the type of unknown words ; R : Roles set of T Output : C ( t i</definiens>
			</definition>
			<definition id="2">
				<sentence>In addition , F-measurement is a uniformly weighted harmonic mean of precision rate and recalling rate as shown in E8 .</sentence>
				<definiendum id="0">F-measurement</definiendum>
				<definiens id="0">a uniformly weighted harmonic mean of precision rate</definiens>
			</definition>
</paper>

		<paper id="1104">
</paper>

		<paper id="2016">
			<definition id="0">
				<sentence>Such a probabilistic model is not always efficient since it needs to calculate the probabilities for all possible dependencies and creates n˙ ( n¡1 ) =2 ( where n is the number of segments in a sentence ) training examples per sentence .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of segments in a sentence ) training examples per sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Statistical dependency analysis is defined as a searching problem for the dependency pattern D that maximizes the conditional probability P ( DjB ) of the input sequence under the above-mentioned constraints .</sentence>
				<definiendum id="0">Statistical dependency analysis</definiendum>
				<definiens id="0">a searching problem for the dependency pattern D that maximizes the conditional probability P ( DjB ) of the input sequence under the above-mentioned constraints</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus , a total of n˙ ( n¡1 ) =2 training examples ( where n is the number of segments in a sentence ) must be produced per sentence .</sentence>
				<definiendum id="0">n</definiendum>
			</definition>
			<definition id="3">
				<sentence>† Simple and Efficient If we use the CYK algorithm , the probabilistic model requires O ( n3 ) parsing time , ( where n is the number of segments in a sentence . )</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of segments in a sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>SVM is a binary linear classifier trained from the samples , each of which belongs either to positive or negative class as follows : ( x1 ; y1 ) ; : : : ; ( xl ; yl ) ( xi 2 Rn ; yi 2 f+1 ; ¡1g ) ; where xi is a feature vector of the i-th sample represented by an n dimensional vector , and yi is the class ( positive ( +1 ) or negative ( ¡1 ) class ) label of the i-th sample .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiendum id="1">xi</definiendum>
				<definiendum id="2">yi</definiendum>
				<definiens id="0">a feature vector of the i-th sample represented by an n dimensional vector , and</definiens>
			</definition>
			<definition id="5">
				<sentence>SVMs find the optimal separating hyperplane ( w¢x + b ) based on the maximal margin strategy .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">find the optimal separating hyperplane ( w¢x + b ) based on the maximal margin strategy</definiens>
			</definition>
			<definition id="6">
				<sentence>Head Word ( HW ) is the rightmost content word in the segment .</sentence>
				<definiendum id="0">HW )</definiendum>
				<definiens id="0">the rightmost content word in the segment</definiens>
			</definition>
			<definition id="7">
				<sentence>Sentence accuracy is the percentage of sentences in which all dependencies are determined correctly .</sentence>
				<definiendum id="0">Sentence accuracy</definiendum>
				<definiens id="0">the percentage of sentences in which all dependencies are determined correctly</definiens>
			</definition>
			<definition id="8">
				<sentence>It is difficult to apply the probabilistic model to the large data set , since it takes no less than 336 hours ( 2 weeks ) to carry out the experiments even with the standard data set , and SVMs require quadratic or more computational cost on the number of training examples .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiens id="0">require quadratic or more computational cost on the number of training examples</definiens>
			</definition>
</paper>

		<paper id="0903">
			<definition id="0">
				<sentence>We frame the task of inserting new words into the dictionary as a classification problem : a19 is the set of classes defined by the dictionary .</sentence>
				<definiendum id="0">a19</definiendum>
			</definition>
			<definition id="1">
				<sentence>Collocations have been widely used for tasks such as word sense disambiguation ( WSD ) ( Yarowsky , 1995 ) , information extraction ( IE ) ( Riloff , 1996 ) , and named-entity recognition ( Collins and Singer , 1999 ) .</sentence>
				<definiendum id="0">named-entity recognition</definiendum>
				<definiens id="0">word sense disambiguation ( WSD ) ( Yarowsky , 1995 ) , information extraction ( IE )</definiens>
			</definition>
			<definition id="2">
				<sentence>AdaBoost minimizes the exponential loss on the training set so that incorrect classification and disagreement between members of the ensemble are penalized .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">minimizes the exponential loss on the training set so that incorrect classification and disagreement between members of the ensemble are penalized</definiens>
			</definition>
			<definition id="3">
				<sentence>A weak learner is defined as follows : a117 a134 a115 a29 a21 a45 a30 a129 a34a147a48a190a189 a186a187a115a94a29a140a39 a30 a129 a34 if a39 a22a75a21 a45 a100 if a39a192a191 a22a75a21 a45 ( 7 ) The prediction a186a193a115a94a29a140a39 a30 a129 a34 is computed as follows : a186a36a115a94a29a140a39 a30 a129 a34a116a48 a95 a194a42a195a122a196a75a197a116a198 a138 a163a75a199a201a200 a198 a138 a175 a199a201a200a154a202 ( 8 ) a198 a138 a163 ( a198 a138 a175 ) is the sum of the weights of noun-label pairs , from the distribution a139 a115 , where the feature appears and the label is correct ( wrong ) ; a200 a48 a123 a135 a137 is a smoothing factor .</sentence>
				<definiendum id="0">weak learner</definiendum>
				<definiendum id="1">a200 a48 a123 a135 a137</definiendum>
				<definiens id="0">follows : a117 a134 a115 a29 a21 a45 a30 a129 a34a147a48a190a189 a186a187a115a94a29a140a39 a30 a129 a34 if a39 a22a75a21 a45 a100 if a39a192a191 a22a75a21 a45 ( 7 ) The prediction a186a193a115a94a29a140a39 a30 a129 a34 is computed as follows : a186a36a115a94a29a140a39 a30 a129 a34a116a48 a95 a194a42a195a122a196a75a197a116a198 a138 a163a75a199a201a200 a198 a138 a175 a199a201a200a154a202 ( 8 ) a198 a138 a163 ( a198 a138 a175 ) is the sum of the weights of noun-label pairs , from the distribution a139 a115 , where the feature appears and the label is correct ( wrong ) ;</definiens>
				<definiens id="1">a smoothing factor</definiens>
			</definition>
			<definition id="4">
				<sentence>To specify the morphological properties of the nouns being classified , we used the following set of features : a213 plural ( PL ) : if the token occurs in the plural form , PL=1 ; otherwise PL=0 a213 upper case ( MU ) : if the token’s first character is upper-cased MU=1 ; otherwise MU=0 a213 suffixes ( MS ) : each token can have 0 , 1 , or more of a given set of suffixes , e.g. , -er , ishment , -ity , -ism , -esse , ... a213 prefixes ( MP ) : each token can have 0 , 1 or more prefixes , e.g. , pro- , re- , di- , tri- , ... a213 Words that have complex morphology share the morphological head word if this is a noun in Wordnet .</sentence>
				<definiendum id="0">MS )</definiendum>
				<definiendum id="1">MP )</definiendum>
				<definiens id="0">if the token occurs in the plural form</definiens>
				<definiens id="1">1 , or more of a given set of suffixes , e.g. , -er , ishment , -ity</definiens>
			</definition>
			<definition id="5">
				<sentence>There are two cases , depending on whether the word is hyphenated ( MSHH ) or the head word is a suffix ( MSSH ) – hyphenated ( MSHH ) : drinking age and age share the same head-word age – non-hyphenated ( MSSH ) : chairman and man share the same suffix head word , man .</sentence>
				<definiendum id="0">MSHH</definiendum>
			</definition>
			<definition id="6">
				<sentence>Boostexter : A boostingbased system for text categorization .</sentence>
				<definiendum id="0">Boostexter</definiendum>
				<definiens id="0">A boostingbased system for text categorization</definiens>
			</definition>
</paper>

		<paper id="0300">
</paper>

		<paper id="1705">
</paper>

		<paper id="0208">
			<definition id="0">
				<sentence>DAT : Dialogue annotation tool .</sentence>
				<definiendum id="0">DAT</definiendum>
				<definiens id="0">Dialogue annotation tool</definiens>
			</definition>
			<definition id="1">
				<sentence>N.b. : A graphical user interface for annotating spoken dialogue .</sentence>
				<definiendum id="0">N.b.</definiendum>
			</definition>
</paper>

		<paper id="1712">
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>Text prediction is a form of interactive machine translation that is well suited to skilled translators .</sentence>
				<definiendum id="0">Text prediction</definiendum>
				<definiens id="0">a form of interactive machine translation that is well suited to skilled translators</definiens>
			</definition>
			<definition id="1">
				<sentence>Unlike the TransType prototype , which proposes a set of single-word ( or single-unit ) suggestions , we assume that each prediction consists of only a single proposal , but one that may span an arbitrary number of words .</sentence>
				<definiendum id="0">TransType prototype</definiendum>
				<definiens id="0">proposes a set of single-word ( or single-unit ) suggestions , we assume that each prediction consists of only a single proposal , but one that may span an arbitrary number of words</definiens>
			</definition>
			<definition id="2">
				<sentence>s is the source sentence , h is the part of its translation that has already been typed , x is what the translator wants to type , and x is the prediction .</sentence>
				<definiendum id="0">s</definiendum>
				<definiendum id="1">x</definiendum>
				<definiens id="0">the source sentence , h is the part of its translation that has already been typed , x is what the translator wants to type</definiens>
			</definition>
			<definition id="3">
				<sentence>With this assumption , the key determinant of edit cost is the length of the correct prefix of x , so the expected benefit can be written as : B ( x ; h ; s ) = lX k=0 p ( kjx ; h ; s ) B ( x ; h ; s ; k ) ; ( 2 ) where p ( kjx ; h ; s ) is the probability that exactly k characters from the beginning of x will be correct , l is the length of x , and B ( x ; h ; s ; k ) is the benefit to the user given that the first k characters of x are correct .</sentence>
				<definiendum id="0">h ; s )</definiendum>
				<definiendum id="1">l</definiendum>
				<definiendum id="2">B ( x</definiendum>
				<definiendum id="3">k )</definiendum>
				<definiens id="0">p ( kjx ;</definiens>
			</definition>
			<definition id="4">
				<sentence>For k &lt; l : p ( kjx ; h ; s ) = p ( xk1jh ; s ) p ( xk+11 jh ; s ) where xk1 = x1 : : : xk. If k = l , p ( kjx ; h ; s ) = p ( xjh ; s ) . Also , p ( x01 ) 1. The next step is to convert string probabilities into word probabilities. To do this , we assume that strings map one-to-one into token sequences , so that : p ( xk1jh ; s ) p ( v1 ; w2 ; : : : ; wm 1 ; umjh ; s ) ; where v1 is a possibly-empty word suffix , each wi is a complete word , and um is a possibly empty word prefix. For example , if x in figure 1 were evenir aux choses , then x141 would map to v1 = evenir , w2 = aux , and u3 = cho. The one-to-one assumption is reasonable given that entries in our lexicon contain neither whitespace nor internal punctuation. To model word-sequence probabilities , we apply the chain rule : p ( v1 ; w2 ; : : : ; wm 1 ; umjh ; s ) = p ( v1jh ; s ) m 1Y i=2 p ( wijh ; v1 ; wi 12 ; s ) p ( umjh ; v1 ; wm 12 ; s ) : ( 3 ) The probabilities of v1 and um can be expressed in terms of word probabilities as follows. Letting u1 be the prefix of the word that ends in v1 ( eg , r in figure 1 ) , w1 = u1v1 , and h = h0u1 : p ( v1jh ; s ) = p ( w1jh0 ; s ) = X w : w=u1v p ( wjh0 ; s ) ; where the sum is over all words that start with u1. Similarly : p ( umjh0 ; wm 11 ; s ) = X w : w=umv p ( wjh0 ; wm 11 ; s ) : ( 4 ) Thus all factors in ( 3 ) can be calculated from probabilities of the form p ( wjh ; s ) which give the likelihood that a word w will follow a previous sequence of words h in the translation of s.1 This is the family of distributions we have concentrated on modeling. Our model for p ( wjh ; s ) is a log-linear combination of a trigram language model for p ( wjh ) and a maximum-entropy translation model for p ( wjs ) , described in ( Foster , 2000a ; Foster , 2000b ) . The translation component is an analog of the IBM model 2 ( Brown et al. , 1993 ) , with parameters that are optimized for use with the trigram. The combined model is shown in ( Foster , 2000a ) to have significantly lower test corpus perplexity than the linear combination of a trigram and IBM 2 used in the TransType experiments ( Langlais et al. , 2002 ) . Both models supportO ( mJV 3 ) Viterbi-style searches for the most likely sequence of m words that follows h , where J is the number of tokens in s and V is the size of the target-language vocabulary. Compared to an equivalent noisy-channel combination of the form p ( t ) p ( sjt ) , where t is the target sentence , our model is faster but less accurate. It is faster because the search problem for noisychannel models is NP-complete ( Knight , 1999 ) , and even the fastest dynamic-programming heuristics used in statistical MT ( Niessen et al. , 1998 ; Tillmann and Ney , 2000 ) , are polynomial in J—for instance O ( mJ4V 3 ) in ( Tillmann and Ney , 2000 ) . It is less accurate because it ignores the alignment relation between s and h , which is captured by even the simplest noisy-channel models. Our model is therefore suitable for making predictions in real time , but not for establishing complete translations unassisted by a human. The most expensive part of the calculation in equation ( 3 ) is the sum in ( 4 ) over all words in the vocabulary , which according to ( 2 ) must be carried out for every character position k in a given prediction x. We reduce the cost of this by performing sums only at the end of each sequence of complete tokens in x ( eg , after revenir and revenir aux in the above example ) . At these points , probabilities for all possible prefixes of the next word are calculated in a 1Here we ignore the distinction between previous words that have been sanctioned by the translator and those that are hypothesized as part of the current prediction. single recursive pass over the vocabulary and stored in a trie for later access. In addition to the exact calculation , we also experimented with establishing exact probabilities via p ( wjh ; s ) only at the end of each token in x , and assuming that the probabilities of the intervening characters vary linearly between these points. As a result of this assumption , p ( kjx ; h ; s ) = p ( xk1jh ; s ) p ( xk+11 jh ; s ) is constant for all k between the end of one word and the next , and therefore can be factored out of the sum in equation ( 2 ) between these points. The purpose of the user model is to determine the expected benefit B ( x ; h ; s ; k ) to the translator of a prediction x whose first k characters match the text that the translator wishes to type. This will depend on whether the translator decides to accept or reject the prediction , so the first step in our model is the following expansion : B ( x ; h ; s ; k ) = X a2f0 ; 1g p ( ajx ; h ; s ; k ) B ( x ; h ; s ; k ; a ) ; wherep ( ajx ; h ; s ; k ) is the probability that the translator accepts or rejects x , B ( x ; h ; s ; k ; a ) is the benefit they derive from doing so , and a is a random variable that takes on the values 1 for acceptance and 0 for rejection. The first two quantities are the main elements in the user model , and are described in following sections. The parameters of both were estimated from data collected during the TransType trial described in ( Langlais et al. , 2002 ) , which involved nine accomplished translators using a prototype prediction tool for approximately half an hour each. In all cases , estimates were made by pooling the data for all nine translators. Ideally , a model for p ( ajx ; h ; s ; k ) would take into account whether the user actually reads the proposal before accepting or rejecting it , eg : p ( ajx ; h ; s ; k ) = X r2f0 ; 1g p ( ajr ; x ; h ; s ; k ) p ( rjx ; h ; s ; k ) where r is a boolean “read” variable. However , this information is hard to extract reliably from the available data ; and even if were obtainable , many of the −60−50−40−30−20−10 0 10 20 30 40 50 600 1 probability of accepting gain ( length of correct prefix − length of incorrect suffix ) rawsmoothed model Figure 2 : Probability that a prediction will be accepted versus its gain. factors which influence whether a user is likely to read a proposal—such as a record of how many previous predictions have been accepted—are not available to the predictor in our formulation. We thus model p ( ajx ; h ; s ; k ) directly. Our model is based on the assumption that the probability of accepting x depends only on what the user stands to gain from it , defined according to the editing scenario given in section 2 as the amount by which the length of the correct prefix of x exceeds the length of the incorrect suffix : p ( ajx ; h ; s ; k ) p ( aj2k l ) ; wherek ( l k ) = 2k l is called the gain. For instance , the gain for the prediction in figure 1 would be 2 7 8 = 6. The strongest part of this assumption is dropping the dependence on h , because there is some evidence from the data that users are more likely to accept at the beginnings of words. However , this does not appear to have a severe effect on the quality of the model. Figure 2 shows empirical estimates of p ( a = 1j2k l ) from the TransType data. There is a certain amount of noise intrinsic to the estimation procedure , since it is difficult to determine x , and therefore k , reliably from the data in some cases ( when the user is editing the text heavily ) . Nonetheless , it is apparent from the plot that gain is a useful abstrac0 10 20 30 40 50 600 500 1000 1500 2000 2500 3000 3500 4000 average time to accept ( msecs ) length of proposal ( chars ) rawleast−squares fit 0 10 20 30 40 50 600 500 1000 1500 2000 2500 3000 3500 4000 average time to reject ( msecs ) length of proposal ( chars ) rawleast−squares fit Figure 3 : Time to read and accept or reject proposals versus their length tion , because the empirical probability of acceptance is very low when it is less than zero and rises rapidly as it increases. This relatively clean separation supports the basic assumption in section 2 that benefit depends on k. The points labelled smoothed in figure 2 were obtained using a sliding-average smoother , and the model curve was obtained using two-component Gaussian mixtures to fit the smoothed empirical likelihoods p ( gainja = 0 ) and p ( gainja = 1 ) . The model probabilities are taken from the curve at integral values. As an example , the probability of accepting the prediction in figure 1 is about .25. The benefit B ( x ; h ; s ; k ; a ) is defined as the typing time the translator saves by accepting or rejecting a prediction x whose first k characters are correct. To determine this , we assume that the translator first reads x , then , if he or she decides to accept , uses a special command to place the cursor at the end of x and erases its last l k characters. Assuming independence from h ; s as before , our model is : B ( x ; k ; a ) = R 1 ( x ) +T ( x ; k ) E ( x ; k ) ; a = 1 R0 ( x ) ; a = 0 where Ra ( x ) is the cost of reading x when it ultimately gets accepted ( a= 1 ) or rejected ( a= 0 ) , T ( x ; k ) is the cost of manually typing xk1 , and E ( x ; k ) is the edit cost of accepting x and erasing to the end of its first k characters. A natural unit for B ( x ; k ; a ) is the number of keystrokes saved , so all elements of the above equation are converted to this measure. This is straightforward in the case of T ( x ; k ) and E ( x ; k ) , which are estimated as k and l k + 1 respectively—for E ( x ; k ) , this corresponds to one keystroke for the command to accept a prediction , and one to erase each wrong character. This is likely to slightly underestimate the true benefit , because it is usually harder to type n characters than to erase them. As in the previous section , read costs are interpreted as expected values with respect to the probability that the user actually does read x , eg , assuming 0 cost for not reading , R0 ( x ) = p ( r=1jx ) R00 ( x ) , where R00 ( x ) is the unknown true cost of reading and rejecting x. To determine Ra ( x ) , we measured the average elapsed time in the TransType data from the point at which a proposal was displayed to the point at which the next user action occurred—either an acceptance or some other command signalling a rejection. Times greater than 5 seconds were treated as indicating that the translator was distracted and were filtered out. As shown in figure 3 , read times are much higher for predictions that get accepted , reflecting both a more careful perusal by the translator and the fact the rejected predictions are often simply ignored.2 In both cases there is a weak linear rela2Here the number of characters read was assumed to include the whole contents of the TransType menu in the case of rejections , and only the proposal that was ultimately accepted in the case of acceptances. tionship between the number of characters read and the time taken to read them , so we used the leastsquares lines shown as our models. Both plots are noisy and would benefit from a more sophisticated psycholinguistic analysis , but they are plausible and empirically-grounded first approximations. To convert reading times to keystrokes for the benefit function we calculated an average time per keystroke ( 304 milliseconds ) based on sections of the trial where translators were rapidly typing and when predictions were not displayed. This gives an upper bound for the per-keystroke cost of reading— compare to , for instance , simply dividing the total time required to produce a text by the number of characters in it—and therefore results in a conservative estimate of benefit. To illustrate the complete user model , in the figure 1 example the benefit of accepting would be 7 2 4:2 = :8 keystrokes and the benefit of rejecting would be :2 keystrokes. Combining these with the acceptance probability of .25 gives an overall expected benefit B ( x ; h ; s ; k = 7 ) for this proposal of Searching directly through all character strings x in order to find ^x according to equation ( 1 ) would be very expensive. The fact that B ( x ; h ; s ) is nonmonotonic in the length of x makes it difficult to organize efficient dynamic-programming search techniques or use heuristics to prune partial hypotheses. Because of this , we adopted a fairly radical search strategy that involves first finding the most likely sequence of words of each length , then calculating the benefit of each of these sequences to determine the best proposal. The algorithm is : word sequence : ^wm = argmax w1 : ( w1=u1v ) ; wm2 p ( wm1 jh0 ; s ) ; where u1 and h0 are as defined in section 3. string ^xm. empty string if all B ( ^xm ; h ; s ) are nonpositive. M average time maximum time 1 0.0012 0.01 2 0.0038 0.23 3 0.0097 0.51 4 0.0184 0.55 5 0.0285 0.57 Table 1 : Approximate times in seconds to generate predictions of maximum word sequence length M , on a 1.2GHz processor , for the MEMD model. In all experiments reported below , M was set to a maximum of 5 to allow for convenient testing. Step 1 is carried out using a Viterbi beam search. To speed this up , the search is limited to an active vocabulary of target words likely to appear in translations of s , defined as the set of all words connected by some word-pair feature in our translation model to some word in s. Step 2 is a trivial deterministic procedure that mainly involves deciding whether or not to introduce blanks between adjacent words ( eg yes in the case of la + vie , no in the case of l’ + an ) . This also removes the prefix u1 from the proposal. Step 3 involves a straightforward evaluation of m strings according to equation ( 2 ) . Table 1 shows empirical search timings for various values of M , for the MEMD model described in the next section. Times for the linear model are similar. Although the maximum times shown would cause perceptible delays for M &gt; 1 , these occur very rarely , and in practice typing is usually not noticeably impeded when using the TransType interface , even at M = 5 .</sentence>
				<definiendum id="0">v1</definiendum>
				<definiendum id="1">um</definiendum>
				<definiendum id="2">translation component</definiendum>
				<definiendum id="3">V</definiendum>
				<definiendum id="4">t</definiendum>
				<definiendum id="5">k )</definiendum>
				<definiendum id="6">r</definiendum>
				<definiendum id="7">Ra ( x )</definiendum>
				<definiendum id="8">T ( x ; k )</definiendum>
				<definiendum id="9">k )</definiendum>
				<definiendum id="10">)</definiendum>
				<definiendum id="11">R00 ( x )</definiendum>
				<definiens id="0">p ( kjx ; h ; s ) = p ( xk1jh ; s ) p ( xk+11 jh ; s ) where xk1 = x1 : : : xk. If k = l , p ( kjx ; h ; s ) = p ( xjh ; s ) . Also , p ( x01 ) 1. The next step is to convert string probabilities into word probabilities. To do this , we assume that strings map one-to-one into token sequences , so that : p ( xk1jh ; s ) p ( v1 ; w2 ; : : : ; wm 1 ; umjh ; s ) ; where</definiens>
				<definiens id="1">a possibly-empty word suffix , each wi is a complete word , and</definiens>
				<definiens id="2">one-to-one assumption is reasonable given that entries in our lexicon contain neither whitespace nor internal punctuation. To model word-sequence probabilities , we apply the chain rule : p ( v1 ; w2 ; : : : ; wm 1 ; umjh ; s ) = p ( v1jh ; s ) m 1Y i=2 p ( wijh ; v1 ; wi 12 ; s ) p ( umjh ; v1 ; wm 12 ; s ) : ( 3 ) The probabilities of v1 and um can be expressed in terms of word probabilities as follows. Letting u1 be the prefix of the word that ends in v1 ( eg , r in figure 1 ) , w1 = u1v1 , and h = h0u1 : p ( v1jh ; s ) = p ( w1jh0 ; s ) = X w : w=u1v p ( wjh0 ; s ) ; where the sum is over all words that start with u1. Similarly : p ( umjh0 ; wm 11 ; s ) = X w : w=umv p ( wjh0 ; wm 11 ; s ) : ( 4 ) Thus all factors in ( 3 ) can be calculated from probabilities of the form p ( wjh ; s ) which give the likelihood that a word w will follow a previous sequence of words h in the translation of s.1 This is the family of distributions we have concentrated on modeling. Our model for p ( wjh ; s ) is a log-linear combination of a trigram language model for p ( wjh ) and a maximum-entropy translation model for p ( wjs ) , described in ( Foster , 2000a</definiens>
				<definiens id="3">an analog of the IBM model 2 ( Brown et al. , 1993 ) , with parameters that are optimized for use with the trigram. The combined model is shown in ( Foster , 2000a ) to have significantly lower test corpus perplexity than the linear combination of a trigram and IBM 2 used in the TransType experiments ( Langlais et al. , 2002 ) . Both models supportO ( mJV 3 ) Viterbi-style searches for the most likely sequence of m words that follows h , where J is the number of tokens in s</definiens>
				<definiens id="4">the size of the target-language vocabulary. Compared to an equivalent noisy-channel combination of the form p ( t ) p ( sjt )</definiens>
				<definiens id="5">the target sentence , our model is faster but less accurate. It is faster because the search problem for noisychannel models is NP-complete ( Knight , 1999 ) , and even the fastest dynamic-programming heuristics used in statistical MT ( Niessen et al. , 1998 ; Tillmann and Ney , 2000 ) , are polynomial in J—for instance O ( mJ4V 3 ) in ( Tillmann and Ney , 2000 ) . It is less accurate because it ignores the alignment relation between s and h , which is captured by even the simplest noisy-channel models. Our model is therefore suitable for making predictions in real time , but not for establishing complete translations unassisted by a human. The most expensive part of the calculation in equation ( 3 ) is the sum in ( 4 ) over all words in the vocabulary , which according to ( 2 ) must be carried out for every character position k in a given prediction x. We reduce the cost of this by performing sums only at the end of each sequence of complete tokens in x ( eg , after revenir and revenir aux in the above example ) . At these points , probabilities for all possible prefixes of the next word are calculated in a 1Here we ignore the distinction between previous words that have been sanctioned by the translator and those that are hypothesized as part of the current prediction. single recursive pass over the vocabulary and stored in a trie for later access. In addition to the exact calculation , we also experimented with establishing exact probabilities via p ( wjh ; s ) only at the end of each token in x , and assuming that the probabilities of the intervening characters vary linearly between these points. As a result of this assumption , p ( kjx ; h ; s ) = p ( xk1jh ; s ) p ( xk+11 jh ; s ) is constant for all k between the end of one word and the next , and therefore can be factored out of the sum in equation ( 2 ) between these points. The purpose of the user model is to determine the expected benefit B ( x ; h ; s ; k ) to the translator of a prediction x whose first k characters match the text that the translator wishes to type. This will depend on whether the translator decides to accept or reject the prediction , so the first step in our model is the following expansion : B ( x ; h ; s ; k ) = X a2f0 ; 1g p ( ajx ; h ; s ; k ) B ( x ; h ; s ; k ; a )</definiens>
				<definiens id="6">the probability that the translator accepts or rejects x , B ( x ; h ; s ; k ; a ) is the benefit they derive from doing so , and a is a random variable that takes on the values 1 for acceptance and 0 for rejection. The first two quantities are the main elements in the user model , and are described in following sections. The parameters of both were estimated from data collected during the TransType trial described in ( Langlais et al. , 2002 ) , which involved nine accomplished translators using a prototype prediction tool for approximately half an hour each. In all cases , estimates were made by pooling the data for all nine translators. Ideally , a model for p ( ajx ; h ; s ; k ) would take into account whether the user actually reads the proposal before accepting or rejecting it , eg : p ( ajx ; h ; s ; k ) = X r2f0 ; 1g p ( ajr ; x ; h ; s ; k ) p ( rjx ; h ; s ; k ) where</definiens>
				<definiens id="7">a boolean “read” variable. However , this information is hard to extract reliably from the available data ; and even if were obtainable , many of the −60−50−40−30−20−10 0 10 20 30 40 50 600 1 probability of accepting gain ( length of correct prefix − length of incorrect suffix ) rawsmoothed model Figure 2 : Probability that a prediction will be accepted versus its gain. factors which influence whether a user is likely to read a proposal—such as a record of how many previous predictions have been accepted—are not available to the predictor in our formulation. We thus model p ( ajx ; h ; s ; k ) directly. Our model is based on the assumption that the probability of accepting x depends only on what the user stands to gain from it , defined according to the editing scenario given in section 2 as the amount by which the length of the correct prefix of x exceeds the length of the incorrect suffix : p ( ajx ; h ; s ; k ) p ( aj2k l ) ; wherek ( l k ) = 2k l is called the gain. For instance , the gain for the prediction in figure 1 would be 2 7 8 = 6. The strongest part of this assumption is dropping the dependence on h , because there is some evidence from the data that users are more likely to accept at the beginnings of words. However , this does not appear to have a severe effect on the quality of the model. Figure 2 shows empirical estimates of p ( a = 1j2k l ) from the TransType data. There is a certain amount of noise intrinsic to the estimation procedure , since it is difficult to determine x , and therefore k , reliably from the data in some cases ( when the user is editing the text heavily</definiens>
				<definiens id="8">a useful abstrac0 10 20 30 40 50 600 500 1000 1500 2000 2500 3000 3500 4000 average time to accept ( msecs ) length of proposal ( chars ) rawleast−squares fit 0 10 20 30 40 50 600 500 1000 1500 2000 2500 3000 3500 4000 average time to reject ( msecs ) length of proposal ( chars ) rawleast−squares fit Figure 3 : Time to read and accept or reject proposals versus their length tion , because the empirical probability of acceptance is very low when it is less than zero and rises rapidly as it increases. This relatively clean separation supports the basic assumption in section 2 that benefit depends on k. The points labelled smoothed in figure 2 were obtained using a sliding-average smoother , and the model curve was obtained using two-component Gaussian mixtures to fit the smoothed empirical likelihoods p ( gainja = 0 ) and p ( gainja = 1 ) . The model probabilities are taken from the curve at integral values. As an example , the probability of accepting the prediction in figure 1 is about .25. The benefit B ( x ; h ; s</definiens>
				<definiens id="9">the typing time the translator saves by accepting or rejecting a prediction x whose first k characters are correct. To determine this , we assume that the translator first reads x , then , if he or she decides to accept , uses a special command to place the cursor at the end of x and erases its last l k characters. Assuming independence from h ; s as before , our model is : B ( x ; k ; a ) = R 1 ( x ) +T ( x ; k ) E ( x ; k ) ; a = 1 R0 ( x ) ; a = 0 where</definiens>
				<definiens id="10">the cost of reading x when it ultimately gets accepted ( a= 1 ) or rejected ( a= 0 )</definiens>
				<definiens id="11">the cost of manually typing xk1 , and E ( x ;</definiens>
				<definiens id="12">the edit cost of accepting x and erasing to the end of its first k characters. A natural unit for B ( x ; k ; a</definiens>
				<definiens id="13">the number of keystrokes saved , so all elements of the above equation are converted to this measure. This is straightforward in the case of T ( x ; k ) and E ( x ; k ) , which are estimated as k and l k + 1 respectively—for E ( x ; k ) , this corresponds to one keystroke for the command to accept a prediction , and one to erase each wrong character. This is likely to slightly underestimate the true benefit , because it is usually harder to type n characters than to erase them. As in the previous section , read costs are interpreted as expected values with respect to the probability that the user actually does read x , eg , assuming 0 cost for not reading , R0 ( x ) = p ( r=1jx ) R00 ( x )</definiens>
				<definiens id="14">the unknown true cost of reading and rejecting x. To determine Ra ( x ) , we measured the average elapsed time in the TransType data from the point at which a proposal was displayed to the point at which the next user action occurred—either an acceptance or some other command signalling a rejection. Times greater than 5 seconds were treated as indicating that the translator was distracted and were filtered out. As shown in figure 3 , read times are much higher for predictions that get accepted , reflecting both a more careful perusal by the translator and the fact the rejected predictions are often simply ignored.2 In both cases there is a weak linear rela2Here the number of characters read was assumed to include the whole contents of the TransType menu in the case of rejections , and only the proposal that was ultimately accepted in the case of acceptances. tionship between the number of characters read and the time taken to read them , so we used the leastsquares lines shown as our models. Both plots are noisy and would benefit from a more sophisticated psycholinguistic analysis , but they are plausible and empirically-grounded first approximations. To convert reading times to keystrokes for the benefit function we calculated an average time per keystroke ( 304 milliseconds ) based on sections of the trial where translators were rapidly typing and when predictions were not displayed. This gives an upper bound for the per-keystroke cost of reading— compare to , for instance , simply dividing the total time required to produce a text by the number of characters in it—and therefore results in a conservative estimate of benefit. To illustrate the complete user model , in the figure 1 example the benefit of accepting would be 7 2 4:2 = :8 keystrokes and the benefit of rejecting would be :2 keystrokes. Combining these with the acceptance probability of .25 gives an overall expected benefit B ( x ; h ; s ; k = 7 ) for this proposal of Searching directly through all character strings x in order to find ^x according to equation ( 1 ) would be very expensive. The fact that B ( x ; h ; s ) is nonmonotonic in the length of x makes it difficult to organize efficient dynamic-programming search techniques or use heuristics to prune partial hypotheses. Because of this , we adopted a fairly radical search strategy that involves first finding the most likely sequence of words of each length , then calculating the benefit of each of these sequences to determine the best proposal. The algorithm is : word sequence : ^wm = argmax w1 : ( w1=u1v ) ; wm2 p ( wm1 jh0 ; s ) ; where u1 and h0 are as defined in section 3. string ^xm. empty string if all B ( ^xm ; h ; s ) are nonpositive. M average time maximum time 1 0.0012 0.01 2 0.0038 0.23 3 0.0097 0.51 4 0.0184 0.55 5 0.0285 0.57 Table 1 : Approximate times in seconds to generate predictions of maximum word sequence length M , on a 1.2GHz processor , for the MEMD model. In all experiments reported below , M was set to a maximum of 5 to allow for convenient testing. Step 1 is carried out using a Viterbi beam search. To speed this up , the search is limited to an active vocabulary of target words likely to appear in translations of s , defined as the set of all words connected by some word-pair feature in our translation model to some word in s. Step 2 is a trivial deterministic procedure that mainly involves deciding whether or not to introduce blanks between adjacent words ( eg yes in the case of la + vie , no in the case of l’ + an ) . This also removes the prefix u1 from the proposal. Step 3 involves a straightforward evaluation of m strings according to equation ( 2 ) . Table 1 shows empirical search timings for various values of M , for the MEMD model described in the next section. Times for the linear model are similar. Although the maximum times shown would cause perceptible delays for M &gt; 1 , these occur very rarely , and in practice typing is usually not noticeably impeded when using the TransType interface</definiens>
			</definition>
			<definition id="5">
				<sentence>To correct for this , we used modified probabilities of the form m p ( ^wmjh ; s ) , where m is a length-specific correction factor , tuned so as to optimize benefit on a cross-validation corpus .</sentence>
				<definiendum id="0">m</definiendum>
				<definiens id="0">a length-specific correction factor , tuned so as to optimize benefit on a cross-validation corpus</definiens>
			</definition>
</paper>

		<paper id="1811">
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>Maximum entropy classiflcation ( MaxEnt , or ME , for short ) is an alternative technique which has proven efiective in a number of natural language processing applications ( Berger et al. , 1996 ) .</sentence>
				<definiendum id="0">Maximum entropy classiflcation</definiendum>
				<definiendum id="1">MaxEnt</definiendum>
			</definition>
			<definition id="1">
				<sentence>; where Z ( d ) is a normalization function .</sentence>
				<definiendum id="0">Z ( d )</definiendum>
			</definition>
			<definition id="2">
				<sentence>Fi ; c is a feature/class function for feature fi and class c , deflned as follows:6 Fi ; c ( d ; c0 ) : = n1 ; n i ( d ) &gt; 0 and c0 = c 0 otherwise : For instance , a particular feature/class function might flre if and only if the bigram \still hate '' appears and the document’s sentiment is hypothesized to be negative.7 Importantly , unlike Naive Bayes , MaxEnt makes no assumptions about the relationships between features , and so might potentially perform better when conditional independence assumptions are not met .</sentence>
				<definiendum id="0">c</definiendum>
				<definiendum id="1">MaxEnt</definiendum>
				<definiens id="0">a feature/class function for feature fi and class c , deflned as follows:6 Fi ; c ( d ; c0 ) : = n1 ; n i ( d ) &gt; 0</definiens>
			</definition>
			<definition id="3">
				<sentence>In terms of relative performance , Naive Bayes tends to do the worst and SVMs tend to do the best , although the 12http : //www.english.bham.ac.uk/stafi/oliver/software/tagger/index.htm 13Turney’s ( 2002 ) unsupervised algorithm uses bigrams containing an adjective or an adverb .</sentence>
				<definiendum id="0">Naive Bayes</definiendum>
				<definiens id="0">tends to do the worst and SVMs tend to do the best</definiens>
			</definition>
			<definition id="4">
				<sentence>The grammar of sense : Using part-of-speech tags as a flrst step in semantic disambiguation .</sentence>
				<definiendum id="0">grammar of sense</definiendum>
				<definiens id="0">a flrst step in semantic disambiguation</definiens>
			</definition>
</paper>

		<paper id="1037">
</paper>

		<paper id="0211">
			<definition id="0">
				<sentence>The PACT Geometry Tutor is an operational prototype that does a finer-grained symbolic classification ( Aleven et al. , 2001 ) .</sentence>
				<definiendum id="0">PACT Geometry Tutor</definiendum>
			</definition>
			<definition id="1">
				<sentence>As the student enters an answer and explanation for a qualitative physics question the sentence-level understanding module builds sets of propositions and passes ( APE ) Dialogue Engine Interface Tutorial Strategist propositions Discourse−level Understanding Inference Engine ( Tacitus−lite+ ) proofs proofs ordered Sentence−level Realization ( RealPro ) Discourse Manager ordered searchqueue studentstrings Sentence−level Understanding ( Carmel/Rainbow ) History Language and goals goal or class Domain axioms andaxiomsqueue search response KCD propositions orresponse classes directive goal and propositions tutorstrings tutor string tutor string Figure 1 : Why-Atlas Tutoring System Architecture them , via the discourse manager , to the discourselevel understanding module .</sentence>
				<definiendum id="0">APE</definiendum>
				<definiens id="0">Why-Atlas Tutoring System Architecture them , via the discourse manager , to the discourselevel understanding module</definiens>
			</definition>
			<definition id="2">
				<sentence>The discourse-level understanding module uses language and domain reasoning axioms and the Tacitus-lite+ abductive inference engine to create a set of proofs that offer an explanation for the student’s essay and give some insight into what the student may believe about physics and how to apply that knowledge .</sentence>
				<definiendum id="0">discourse-level understanding module</definiendum>
				<definiens id="0">uses language and domain reasoning axioms and the Tacitus-lite+ abductive inference engine to create a set of proofs that offer an explanation for the student’s essay and give some insight into what the student may believe about physics and how to apply that knowledge</definiens>
			</definition>
			<definition id="3">
				<sentence>Tacitus-lite+ Abduction is a process of reasoning from an observation to possible explanations for that observation .</sentence>
				<definiendum id="0">Tacitus-lite+ Abduction</definiendum>
				<definiens id="0">a process of reasoning from an observation to possible explanations for that observation</definiens>
			</definition>
			<definition id="4">
				<sentence>Following the weighted abductive inference algorithm described in ( Stickel , 1988 ) , Tacitus-lite is a collection of axioms where each axiom is expressed as a Horn clause .</sentence>
				<definiendum id="0">Tacitus-lite</definiendum>
				<definiens id="0">a collection of axioms where each axiom is expressed as a Horn clause</definiens>
			</definition>
			<definition id="5">
				<sentence>( 2 ) p1w1 ^ ^ pnwn ) r Given a goal or observation to be proven , Tacituslite takes one of four actions ; 1 ) assumes the observation at the cost associated with it 2 ) unifies with a fact for zero cost 3 ) unifies with a literal that has already been assumed or proven at no additional cost 4 ) attempts to prove it with an axiom .</sentence>
				<definiendum id="0">Tacituslite</definiendum>
			</definition>
			<definition id="6">
				<sentence>However , Tacitus-lite allows the applications builder to set depth bounds on the number of axioms applied in proving an observation and on the global number of proofs generated during search .</sentence>
				<definiendum id="0">Tacitus-lite</definiendum>
				<definiens id="0">allows the applications builder to set depth bounds on the number of axioms applied in proving an observation and on the global number of proofs generated during search</definiens>
			</definition>
			<definition id="7">
				<sentence>One way to prove that the velocity of the pumpkin is decreasing is to prove that just the horizontal component of the velocity vector is the one that is decreasing since the context of the question ( see ( 1 ) ) makes this a likely interpretation .</sentence>
				<definiendum id="0">velocity vector</definiendum>
				<definiens id="0">the velocity of the pumpkin is decreasing is to prove that just the horizontal component of the</definiens>
			</definition>
</paper>

		<paper id="1118">
			<definition id="0">
				<sentence>Johnson , R , C. Fillmore , E. Wood , J. Ruppenhofer , M. Urban , M. Petruck , C. Baker ( 2001 ) The FrameNet Project : Tools for Lexicon Building , http : //www.icsi.berkeley.edu/~framenet/ Jung , C.G. , Riklin , F. ( 1906 ) .</sentence>
				<definiendum id="0">FrameNet Project</definiendum>
				<definiens id="0">Tools for Lexicon Building</definiens>
			</definition>
			<definition id="1">
				<sentence>WordNet : An On-Line Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="1400">
			<definition id="0">
				<sentence>COMPUTERM 2002 : Second International Workshop on Computational Terminology null Alan M. Buckeridge , Richard F. E. Sutcliffe : Disambiguating Noun Compounds with Latent Semantic Indexing null Michael Carl , Philippe Langlais : An Intelligent Terminology Database as a Pre-processor for Statistical Machine Translation null Natalia Grabar , Pierre Zweigenbaum : Lexically-Based Terminology Structuring : Some Inherent Limits null Oi Yee Kwong , Benjamin K. Tsou , Tom B.Y. Lai , Robert W. P. Luk , Lawrence Y. L. Cheung , Francis C. Y. Chik : Alignment and Extraction of Bilingual Legal Terminology from Context Profiles null Philippe Langlais : Improving a general-purpose Statistical Translation Engine by Terminological lexicons null Yi-Chung Lin , Peng-Hsiang Hung : Probabilistic Named Entity Verification null Hiroshi Nakagawa , Tatsunori Mori : A Simple but Powerful Automatic Term Extraction Method null Goran Nenadić , Irena Spasić , Sophia Ananiadou : Automatic Discovery of Term Similarities Using Pattern Mining null Koichi Takeuchi , Kyo Kageura , Teruo Koyama : An LCS-Based Approach for Analyzing Japanese Compound Nouns with Deverbal Heads null Noriko Tomuro : Question Terminology and Representation for Question Type Classification null Kazuhide Yamamoto : Acquisition of Lexical Paraphrases from Texts</sentence>
				<definiendum id="0">Lexically-Based Terminology Structuring</definiendum>
				<definiens id="0">An Intelligent Terminology Database as a Pre-processor for Statistical Machine Translation null Natalia Grabar</definiens>
				<definiens id="1">Probabilistic Named Entity Verification null Hiroshi Nakagawa , Tatsunori Mori : A Simple but Powerful Automatic Term Extraction Method null Goran Nenadić</definiens>
			</definition>
</paper>

		<paper id="1901">
			<definition id="0">
				<sentence>Where the user identifies a knowledge gap ( a question ) , the system will feed in the respective summary items if possible .</sentence>
				<definiendum id="0">knowledge gap</definiendum>
				<definiens id="0">a question ) , the system will feed in the respective summary items if possible</definiens>
			</definition>
			<definition id="1">
				<sentence>The claim of user-centered information seeking is to enable users to remain integrated in their own domain and think about their own issues when stating their information needs .</sentence>
				<definiendum id="0">user-centered information seeking</definiendum>
				<definiens id="0">to enable users to remain integrated in their own domain and think about their own issues when stating their information needs</definiens>
			</definition>
			<definition id="2">
				<sentence>Retrieval queries need fewer items than summarization target specifications , but they are derived likewise by replacing variables with their current content .</sentence>
				<definiendum id="0">Retrieval queries</definiendum>
				<definiens id="0">need fewer items than summarization target specifications , but they are derived likewise by replacing variables with their current content</definiens>
			</definition>
			<definition id="3">
				<sentence>Implementation of SummIt-BMT is supported by the German Science Foundation ( DFG ) under grant EN 186/6-1 and HE 2927/2-1 , by the German Federal Ministery of Education and Research ( bmbf ) under grant 1701200 , and by the Ministery of Science and Culture of Lower Saxony under grant 1999.384 .</sentence>
				<definiendum id="0">SummIt-BMT</definiendum>
				<definiens id="0">supported by the German Science Foundation ( DFG ) under grant EN 186/6-1 and HE 2927/2-1 , by the German Federal Ministery of Education</definiens>
			</definition>
</paper>

		<paper id="2027">
			<definition id="0">
				<sentence>9 Daniel Boley , Maria Gini , Robert Gross , Eui-Hong Han , George Karypis , Vipin Kumar , Bamshad Mobasher , Jerome Moore , Kyle Hastings , Partitioning-based clustering for Web document categorization , Decision Support Systems , v.27 n.3 , p.329-341 , Dec.1999 10 Gerard Salton , Automatic text processing : the transformation , analysis , and retrieval of information by computer , Addison-Wesley Longman Publishing Co. , Inc. , Boston , MA , 1989 11 Fabrizio Sebastiani , Machine learning in automated text categorization , ACM Computing Surveys ( CSUR ) , v.34 n.1 , p.1-47 , March 2002 12 Jianbo Shi , Jitendra Malik , Normalized Cuts and Image Segmentation , Proceedings of the 1997 Conference on Computer Vision and Pattern Recognition ( CVPR '97 ) , p.731 , June 17-19 , 1997 13 Gilbert Strang .</sentence>
				<definiendum id="0">ACM Computing Surveys</definiendum>
				<definiens id="0">Fabrizio Sebastiani , Machine learning in automated text categorization ,</definiens>
			</definition>
</paper>

		<paper id="1610">
			<definition id="0">
				<sentence>A DSyntS is an unordered tree where all nodes are meaning-bearing and lexicalized .</sentence>
				<definiendum id="0">DSyntS</definiendum>
				<definiens id="0">an unordered tree where all nodes are meaning-bearing and lexicalized</definiens>
			</definition>
			<definition id="1">
				<sentence>The simplest transfer rules consist of direct lexical mappings , while the most complex may contain source and target syntactic patterns composed of multiple nodes defined with lexical and/or syntactic features .</sentence>
				<definiendum id="0">simplest transfer rules</definiendum>
				<definiens id="0">consist of direct lexical mappings , while the most complex may contain source and target syntactic patterns composed of multiple nodes defined with lexical and/or syntactic features</definiens>
			</definition>
			<definition id="2">
				<sentence>Attribute constraints can be divided into two types : AF independent attribute constraints , whose scope covers only one part of a candidate transfer rule and which are the same for the source and target parts ; AF concurrent attribute constraints , whose scope extends to both the source and target parts of a candidate transfer rule .</sentence>
				<definiendum id="0">Attribute constraints</definiendum>
				<definiendum id="1">AF concurrent attribute constraints</definiendum>
				<definiens id="0">AF independent attribute constraints , whose scope covers only one part of a candidate transfer rule</definiens>
				<definiens id="1">both the source and target parts of a candidate transfer rule</definiens>
			</definition>
</paper>

		<paper id="1111">
			<definition id="0">
				<sentence>Sometimes these preferences occur within the WH phrase ( “what color” ) , and sometimes they are embedded elsewhere within the question ( “what is the color ... ” ) .</sentence>
				<definiendum id="0">WH phrase</definiendum>
				<definiens id="0">“what color” ) , and sometimes they are embedded elsewhere within the question ( “what is the color ... ” )</definiens>
			</definition>
</paper>

		<paper id="0402">
			<definition id="0">
				<sentence>The hypertext summaries include a high-level textual overview ; tables of all comparable numeric estimates , organized to highlight discrepancies ; and targeted access to supporting information from the original articles .</sentence>
				<definiendum id="0">hypertext summaries</definiendum>
				<definiens id="0">a high-level textual overview ; tables of all comparable numeric estimates , organized to highlight discrepancies</definiens>
			</definition>
			<definition id="1">
				<sentence>The average sentence overlap is the average of all pairwise sentence similarity measures ; we have found this measure to be a useful counterpart to sentence position in reliably identifying salient sentences , with the other factors playing a lesser role .</sentence>
				<definiendum id="0">average sentence overlap</definiendum>
				<definiens id="0">the average of all pairwise sentence similarity measures ; we have found this measure to be a useful counterpart to sentence position in reliably identifying salient sentences , with the other factors playing a lesser role</definiens>
			</definition>
			<definition id="2">
				<sentence>For the evaluation below , the IE system was trained on 12 of 25 texts from topic 89 of the TDT2 corpus , a set of newswires that describe the May 1998 earthquake in Afganistan .</sentence>
				<definiendum id="0">TDT2 corpus</definiendum>
				<definiens id="0">a set of newswires that describe the May 1998 earthquake in Afganistan</definiens>
			</definition>
			<definition id="3">
				<sentence>The marginal relevance systems ( MR and MR+IE ) used a simple selection mechanism which does not involve search , inspired by the maximal marginal relevance ( MMR ) approach ( Goldstein et al. , 2000 ) .</sentence>
				<definiendum id="0">marginal relevance systems</definiendum>
			</definition>
</paper>

		<paper id="0810">
</paper>

		<paper id="0812">
			<definition id="0">
				<sentence>Duluth38 is an ensemble approach that assigns a sense to an instance of an ambiguous word by taking a vote among three bagged decision trees .</sentence>
				<definiendum id="0">Duluth38</definiendum>
			</definition>
			<definition id="1">
				<sentence>The English lexical sample for SENSEVAL-2 consists of 73 word types , each of which is associated with a single part of speech .</sentence>
				<definiendum id="0">English lexical sample for SENSEVAL-2</definiendum>
				<definiens id="0">consists of 73 word types , each of which is associated with a single part of speech</definiens>
			</definition>
			<definition id="2">
				<sentence>The evaluation data for the English lexical sample consists of 4,328 held out test instances .</sentence>
				<definiendum id="0">lexical sample</definiendum>
			</definition>
			<definition id="3">
				<sentence>The Spanish lexical sample for SENSEVAL-2 consists of 39 word types .</sentence>
				<definiendum id="0">Spanish lexical sample for SENSEVAL-2</definiendum>
				<definiens id="0">consists of 39 word types</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , UBC refers to a three member ensemble consisting of unigram ( U ) , bigram ( B ) , and co–occurrence ( C ) decision trees , while BC refers to a two member ensemble of bigram ( B ) and co-occurrence ( C ) decision trees .</sentence>
				<definiendum id="0">UBC</definiendum>
			</definition>
			<definition id="5">
				<sentence>Unigram features consist of all words not in the stop–list that occur five or more times in the training examples for a word .</sentence>
				<definiendum id="0">Unigram features</definiendum>
				<definiens id="0">consist of all words not in the stop–list that occur five or more times in the training examples for a word</definiens>
			</definition>
			<definition id="6">
				<sentence>However , each ensemble consists of 81 Naive Bayesian classifiers , making it difficult to determine which features and classifiers were contributing most significantly to disambiguation .</sentence>
				<definiendum id="0">ensemble</definiendum>
			</definition>
			<definition id="7">
				<sentence>Co–occurrence features , generically defined as bigrams where one of the words is the target word and the other occurs within a few positions , have been widely used in computational approaches to word sense disambiguation .</sentence>
				<definiendum id="0">Co–occurrence features</definiendum>
				<definiens id="0">bigrams where one of the words is the target word and the other occurs within a few positions , have been widely used in computational approaches to word sense disambiguation</definiens>
			</definition>
</paper>

		<paper id="1030">
			<definition id="0">
				<sentence>Gsearch ( Corley et al. , 2001 ) , a chart parser which detects syntactic patterns in a tagged corpus by exploiting a user-specified context free grammar and a syntactic query , was used to extract all nouns occurring in a head-modifier relationship with one of the 30 adjectives .</sentence>
				<definiendum id="0">Gsearch</definiendum>
				<definiens id="0">a chart parser which detects syntactic patterns in a tagged corpus by exploiting a user-specified context free grammar and a syntactic query , was used to extract all nouns occurring in a head-modifier relationship with one of the 30 adjectives</definiens>
			</definition>
			<definition id="1">
				<sentence>The following search terms were used for adjective-noun , noun-noun , and verb-object bigrams , respectively : ( 1 ) `` A N '' , whereA is the adjective and N is the singular or plural form of the noun .</sentence>
				<definiendum id="0">whereA</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the singular or plural form of the noun</definiens>
			</definition>
			<definition id="2">
				<sentence>( 2 ) `` N1 N2 '' where N1 is the singular form of the first noun and N2 is the singular or plural form of the second noun .</sentence>
				<definiendum id="0">N1</definiendum>
				<definiendum id="1">N2</definiendum>
				<definiens id="0">the singular form of the first noun</definiens>
				<definiens id="1">the singular or plural form of the second noun</definiens>
			</definition>
			<definition id="3">
				<sentence>( 3 ) `` V Det N '' where V is the infinitive , singular present , plural present , past , perfect , or gerund foroftheverb , Det is the determiner the , a or the empty string , and N is the singular or plural form of the noun .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">Det</definiendum>
				<definiendum id="2">N</definiendum>
				<definiens id="0">the infinitive , singular present , plural present , past , perfect , or gerund foroftheverb ,</definiens>
				<definiens id="1">the determiner the , a or the empty string</definiens>
			</definition>
			<definition id="4">
				<sentence>noun-noun bigrams high medium low unseen predicate process 1:14 user :95 gala 0 collection , clause , coat directory television 1:53 satellite :95 edition 0 chain , care , vote broadcast plasma 1:78 nylon 1:20 unit :60 fund , theology , minute membrane verb-object bigrams predicate high medium low unseen fulfill obligation 3:87 goal 2:20 scripture :69 participant , muscle , grade intensify problem 1:79 effect 1:10 alarm 0 score , quota , chest choose name 3:74 law 1:61 series 1:10 lift , bride , listener Table 1 : Example stimuli for seen and unseen noun-noun and verb-object bigrams ( with log-transformed BNC counts ) seen bigrams adj-noun noun-noun verb-object Min Max Mean SD Min Max Mean SD Min Max Mean SD Altavista 0 5:67 3:55 1:06 :67 6:28 3:41 1:21 0 5:46 3:20 1:14 Google 1:26 5:98 3:89 1:00 :90 6:11 3:66 1:20 0 5:85 3:56 1:16 BNC 0 2:19 :90 :69 0 2:14 :74 :64 0 2:55 :68 :58 unseen bigrams adj-noun noun-noun verb-object Min Max Mean SD Min Max Mean SD Min Max Mean SD Altavista 0 4:04 1:29 :94 0 3:80 1:08 1:12 0 3:72 1:38 1:06 Google 0 3:99 1:68 :96 0 4:00 1:42 1:09 0 4:07 1:76 1:04 Table 3 : Descriptive statistics for web counts and BNC counts ( log-transformed ) adj-noun noun-noun verb-object Altavista 447 467 331 Google 977 831 759 Table 4 : Average factor by which the web counts are larger than the BNC counts ( seen bigrams ) While the procedure for obtaining web counts described in Section 2.2 is very straightforward , it also has obvious limitations .</sentence>
				<definiendum id="0">SD Min Max Mean SD Min Max Mean SD Altavista</definiendum>
				<definiens id="0">Example stimuli for seen and unseen noun-noun and verb-object bigrams ( with log-transformed BNC counts ) seen bigrams adj-noun noun-noun verb-object Min Max Mean</definiens>
				<definiens id="1">BNC 0 2:19 :90 :69 0 2:14 :74 :64 0 2:55 :68 :58 unseen bigrams adj-noun noun-noun verb-object Min Max Mean SD Min Max Mean SD Min Max Mean SD Altavista 0 4:04 1:29 :94 0</definiens>
				<definiens id="2">Descriptive statistics for web counts and BNC counts ( log-transformed ) adj-noun noun-noun verb-object Altavista 447 467 331 Google 977 831 759 Table 4 : Average factor by which the web counts are larger than the BNC counts ( seen bigrams</definiens>
			</definition>
			<definition id="5">
				<sentence>Table 7 ( top half ) lists the correlation coefficients that were obtained when correlatadj-noun bigrams noun-noun bigrams verb-object bigrams N Min Max Mean SD N Min Max Mean SD N Min Max Mean SD Seen 30 −:85 :11 −:13 :22 25 −:15 :69 :40 :21 27 −:52 :45 :12 :24 Unseen 41 −:56 :37 −:07 :20 25 −:49 :52 −:01 :23 21 −:51 :28 −:16 :22 Table 6 : Descriptive statistics for plausibility judgments ( log-transformed ) ; N is the number of subjects used in each experiment ing log-transformed web and BNC counts with log-transformed plausibility judgments .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">Descriptive statistics for plausibility judgments ( log-transformed )</definiens>
			</definition>
			<definition id="6">
				<sentence>Introduction to WordNet : An on-line lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="7">
				<sentence>Selection and Information : A Class-Based Approach to Lexical Relationships .</sentence>
				<definiendum id="0">Selection</definiendum>
				<definiendum id="1">Information</definiendum>
			</definition>
</paper>

		<paper id="1711">
			<definition id="0">
				<sentence>In recent years , the semantic web ( Berners-Lee et al. , 2001 ) has been evolving as the nextgeneration web technology and has attracted the attention of many researchers in database and knowledge engineering communities .</sentence>
				<definiendum id="0">semantic web</definiendum>
				<definiens id="0">the nextgeneration web technology and has attracted the attention of many researchers in database and knowledge engineering communities</definiens>
			</definition>
			<definition id="1">
				<sentence>Given that D is a local model for the ontology integration system and I a global interpretation for the system , the correspondence between C and V is specified as follows by referring to ( Calvanese et al. , 2001 ) : •〈C , V , sound〉 if all tuples satisfying V in D satisfy C in I •〈C , V , complete〉 if no tuple other than those satisfying V in D satisfies C in I •〈C , V , exact〉 if the set of tuples that satisfy C in I is exactly the set of tuples satisfying V in D. In the above notation , “I satisfies” means that I satisfies every correspondence in the mapping between the global ontology and the local ontologies wrt D. These correspondences are valid if the global ontology is assumed to be consistent ; however , inconsistencies might occur when the term in the global ontology has more than one definition .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">“I satisfies”</definiendum>
				<definiens id="0">a local model for the ontology integration system</definiens>
				<definiens id="1">the term in the global ontology has more than one definition</definiens>
			</definition>
			<definition id="2">
				<sentence>If such a new subclass were named “sub-bass , ” it would be represented in this manner : &lt; daml : Class rdf : ID= '' sub-bass '' &gt; &lt; subClassOf rdf : resource= '' # bass '' / &gt; &lt; /daml : Class &gt; &lt; daml : Class rdf : about= '' # sub-bass '' &gt; &lt; isMemberOf rdf : resource= '' # orchestra '' / &gt; &lt; /daml : Class &gt; Let O be an ontology screening system .</sentence>
				<definiendum id="0">Class rdf</definiendum>
				<definiens id="0">an ontology screening system</definiens>
			</definition>
			<definition id="3">
				<sentence>Word sense disambiguation , called WSD , can provide one clue for solving these problems because it draws certain close relationships among words appearing as property values or concept definitions .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">draws certain close relationships among words appearing as property values or concept definitions</definiens>
			</definition>
</paper>

		<paper id="0705">
			<definition id="0">
				<sentence>A hierarchical alignment consists of four functions .</sentence>
				<definiendum id="0">hierarchical alignment</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the experiments described in this paper , the cost function a17 relating a source word ( or compound ) a5 in a bitext with a target word ( or compound ) a12 is a17a14a6a8a5a34a19a21a12a35a19a24a23a25a9a37a36 a26 a6a8a5a34a19a21a12a29a9a39a38a41a40a22a6a8a5a34a19a21a12a35a19a24a23a25a9 where a40a42a6a8a5a20a19a21a12a22a19a24a23a43a9 is a length-normalized measure of the apparent distortion in the positions of a5 and a12 in the source and target strings of a23 .</sentence>
				<definiendum id="0">a40a42a6a8a5a20a19a21a12a22a19a24a23a43a9</definiendum>
				<definiens id="0">a length-normalized measure of the apparent distortion in the positions of a5 and a12 in the source and target strings of a23</definiens>
			</definition>
			<definition id="2">
				<sentence>A transition from state a50 to state a50 a13 has the form a63 a50a64a19a56a50 a13 a19a21a5a20a19a21a12a22a19a24a65a66a19a21a67a37a19a56a68a25a69 where a5 is a member of a47 or is the empty string a11 ; a12 is a member of a48 or a11 ; the integer a65 is the input position ; the integer a67 is the output position ; and the real number a68 is the weight of the transition .</sentence>
				<definiendum id="0">a5</definiendum>
				<definiendum id="1">a12</definiendum>
				<definiendum id="2">integer a67</definiendum>
				<definiens id="0">a member of a47 or is the empty string a11</definiens>
				<definiens id="1">a member of a48 or a11 ; the integer a65 is the input position ; the</definiens>
			</definition>
			<definition id="3">
				<sentence>Dependency transduction models are generative statistical models which derive synchronized pairs of dependency trees , a source language dependency tree and a target dependency tree .</sentence>
				<definiendum id="0">Dependency transduction models</definiendum>
				<definiens id="0">generative statistical models which derive synchronized pairs of dependency trees , a source language dependency tree and a target dependency tree</definiens>
			</definition>
			<definition id="4">
				<sentence>A dependency tree , in the sense of dependency grammar ( for example Hays ( 1964 ) , Hudson ( 1984 ) ) , is a tree in which the words of a sentence appear as nodes ; the parent of a node is its head and the child of a node is the node’s dependent .</sentence>
				<definiendum id="0">dependency tree</definiendum>
				<definiendum id="1">dependency grammar</definiendum>
				<definiens id="0">a tree in which the words of a sentence appear as nodes</definiens>
			</definition>
			<definition id="5">
				<sentence>The probability of such a derivation can be expressed as : a87 a6a88a94a95a6a8a5a45a51a53a19a21a12a71a51a55a9a21a9 a87 a6a88a97a99a98a35a100a33a101a102a21a100a25a9 where a87 a6a88a97a103a98a39a101a102a104a9 is the probability of a subderivation headed by a5 and a12 , that is a87 a6a88a97a99a98a16a101a102a104a9a37a36 a87 a6a88a50a31a51a93a89a5a20a19a21a12a14a9 a105 a51a33a106a18a107a8a106a18a108 a87 a6a88a50 a107a110a109a39a111 a19a21a5 a107 a19a21a12 a107 a19a24a65 a107 a19a21a67 a107 a89a5a20a19a21a12a22a19a56a50 a107 a9 a87 a6a88a97 a98a35a112a88a101a102a21a112 a9 for a derivation in which the dependents of a5 and a12 are generated by a113 transitions .</sentence>
				<definiendum id="0">a87 a6a88a97a103a98a39a101a102a104a9</definiendum>
			</definition>
			<definition id="6">
				<sentence>Using the resulting trees , the probabilities of a bilingual lexicon , i.e. a87 a6a8a12a115a89a5a10a9 where a5 is a source language word , and a12 is a target language word , are estimated from the counts of synchronized lexical nodes .</sentence>
				<definiendum id="0">a5</definiendum>
				<definiendum id="1">a12</definiendum>
				<definiens id="0">a source language word , and</definiens>
			</definition>
			<definition id="7">
				<sentence>Basically , the transduction procedure ( i ) finds an instance a6a118a86a93a19a21a84a56a9 of the translation training pairs for which the example source string a86 provides the “best” match to the input source string a132 , and ( ii ) produces , as the translation output , a modified version of the example target string a84 , where the modifications reflect mismatches between a86 and the input .</sentence>
				<definiendum id="0">transduction procedure ( i )</definiendum>
				<definiens id="0">finds an instance a6a118a86a93a19a21a84a56a9 of the translation training pairs for which the example source string a86 provides the “best” match to the input source string a132</definiens>
			</definition>
			<definition id="8">
				<sentence>Translation accuracy includes transpositions ( i.e. movement ) of words as well as insertions , deletions , and substitutions .</sentence>
				<definiendum id="0">Translation accuracy</definiendum>
				<definiens id="0">includes transpositions ( i.e. movement ) of words as well as insertions , deletions , and substitutions</definiens>
			</definition>
</paper>

		<paper id="1206">
			<definition id="0">
				<sentence>lexeme-based retrieval ( e.g. 'take off ' + 'jacket ' from 'took off his jacket ' ) , identifying syntactic phrases ( such asZ�b�fromZ ��`h ) , synonym expansion , and crosslanguage information retrieval ( CLIR ) ( Goto et al. 2001 ) .</sentence>
				<definiendum id="0">lexeme-based retrieval</definiendum>
			</definition>
			<definition id="1">
				<sentence>Thispaper summarizes the typology of CJK orthographic variation , briefly analyzes the linguistic issues , and discusses why lexical databases should play a central role in the disambiguation process .</sentence>
				<definiendum id="0">Thispaper</definiendum>
				<definiens id="0">summarizes the typology of CJK orthographic variation</definiens>
			</definition>
			<definition id="2">
				<sentence>sophisticated , and far more challenging , approach to C2C conversion is called lexemic conversion , which maps SC and TC lexemes that are semantically , not orthographically , equivalent .</sentence>
				<definiendum id="0">lexemic conversion</definiendum>
			</definition>
			<definition id="3">
				<sentence>Lexemic conversion is the most difficult aspect of C2C conversion and can only be done with the help of mapping tables .</sentence>
				<definiendum id="0">Lexemic conversion</definiendum>
				<definiens id="0">the most difficult aspect of C2C conversion and can only be done with the help of mapping tables</definiens>
			</definition>
			<definition id="4">
				<sentence>that contributes to the complexity of the Japanese writing system is the existence of a large number of homophones ( words pronounced the same but written differently ) and their variable orthography ( Halpern 2000 ) .</sentence>
				<definiendum id="0">homophones</definiendum>
				<definiendum id="1">variable orthography</definiendum>
				<definiens id="0">words pronounced the same but written differently</definiens>
			</definition>
			<definition id="5">
				<sentence>2 Var.3 Hanja vs. hangul many people G1fadG1968 ( daese ) G9cbbGaaf3 ( daese ) Hangul vs. hybrid shirt GaffbGb12fGab0fGb7db ( waisyeacheu ) G3cGab0fGb7dbG3 ( waisyeacheu ) Hangul vs. numeral vs. hanja one o'clock Gbf17Gac97 ( hansi ) G14Gac97 ( hansi ) G1486G2cc8 ( hansi ) English vs. hangul sex sex Gaaf4Gac5f ( sekseu ) contributing to the irregularity of hangul orthography is the differences in spelling between South Korea ( S.K. ) and North Korea ( N.K. ) .</sentence>
				<definiendum id="0">hangul orthography</definiendum>
			</definition>
			<definition id="6">
				<sentence>The CJK Dictionary Institute ( CJKI ) , which specializes in CJK computational lexicography , is engaged in an ongoing research and development effort to compile comprehensive CJK lexical databases ( currently about 5.5 million entries ) , with special emphasis on orthographic disambiguation and proper nouns .</sentence>
				<definiendum id="0">CJK Dictionary Institute</definiendum>
			</definition>
</paper>

		<paper id="0304">
			<definition id="0">
				<sentence>The ‘tag’ of a letter is the expected accented form of this letter ( or the same letter if it is not accented ) .</sentence>
				<definiendum id="0">‘tag’ of a letter</definiendum>
				<definiens id="0">the expected accented form of this letter</definiens>
			</definition>
			<definition id="1">
				<sentence>Let CU CR the number of correct accentuations in CU .</sentence>
				<definiendum id="0">CU CR</definiendum>
				<definiens id="0">the number of correct accentuations in CU</definiens>
			</definition>
			<definition id="2">
				<sentence>Set denotes the subset of words as explained in section 3.5 .</sentence>
				<definiendum id="0">Set</definiendum>
			</definition>
			<definition id="3">
				<sentence>recall precisionA6ci right D2 1906 0.470 0.747A60.017 D4 943 0.233 0.804A60.023 CU 324 0.080 1.000A60.000 D8D3D8 3173 0.783 0.784A60.013 left D2 743 0.183 0.649A60.028 D4 500 0.123 0.428A60.028 CU 1734 0.428 1.000A60.000 D8D3D8 2977 0.734 0.736A60.014 mixed D2 7 0.002 1.000A60.000 D4 0 0.000 0.000A60.000 CU 4040 0.997 1.000A60.000 D8D3D8 4047 0.998 1.000A60.000 majority decision ( 0.9 ) mixed D2 2 0.000 1.000A60.000 D4 0 0.000 0.000A60.000 CU 4045 0.998 1.000A60.000 D8D3D8 4047 0.998 1.000A60.000 Table 6 : Validation : different context methods , MeSH training , 4054 words of accented MeSH .</sentence>
				<definiendum id="0">Validation</definiendum>
				<definiens id="0">different context methods</definiens>
			</definition>
			<definition id="4">
				<sentence>A precision/recall of 0.920A60.037/0.750 is ABU training ( strict ) set cor .</sentence>
				<definiendum id="0">precision/recall of 0.920A60.037/0.750</definiendum>
				<definiens id="0">ABU training ( strict ) set cor</definiens>
			</definition>
</paper>

		<paper id="0504">
			<definition id="0">
				<sentence>The probability of any possible path in our model that generates this phrase can be computed as follows : ) | ( ) ( 1,1 −∏= iin wwpiWp This equation decomposes into the following maximum likelihood probability estimations , denoted by pˆ , in which c ( word ) denotes the number of instances that word had occurred in the training set and c ( word1 , word2 ) denotes the number of joint occurrences of word1 and word2 in the training set. )</sentence>
				<definiendum id="0">word2 )</definiendum>
				<definiens id="0">generates this phrase can be computed as follows : ) | ( ) ( 1,1 −∏= iin wwpiWp This equation decomposes into the following maximum likelihood probability estimations , denoted by pˆ , in which c ( word ) denotes the number of instances that word had occurred in the training set and c</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , we define ) 1|2 ( ) 1 ( ) 1|2 ( ) 1|2 ( ) 1|2 ( wwpwwwp wwPwwp d α= = Here , dP is the discounted estimate using the Good-Turing method , p is a probability estimated by the number of occurrences and ) 1 ( wα is a normalizing factor that divides the unknown if c ( w2 , w1 ) &gt; 0 if c ( w2 , w1 ) =0 probability mass of unseen bigrams beginning with w1 .</sentence>
				<definiendum id="0">dP</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">the discounted estimate using the Good-Turing method ,</definiens>
				<definiens id="1">a probability estimated by the number of occurrences</definiens>
			</definition>
			<definition id="2">
				<sentence>Because we wish to estimate ) 1|2 ( wwPd , we define the discounted frequency counts as follows : ) 2,1 ( 1 ) 2,1 ( ) 2,1 ( ) 2,1 ( * wwc wwc n nwwcwwc ++= where cn is the number of different bigrams in the corpus that have frequency c. Following Katz , we estimate the probability of unseen bigrams to be p ( w2|w1 ) ≅ If the missing bigram is composed of two individually observed words , this technique allows us to estimate the probability mass of the unseen bigram .</sentence>
				<definiendum id="0">discounted frequency</definiendum>
				<definiendum id="1">cn</definiendum>
				<definiens id="0">counts as follows : ) 2,1 ( 1 ) 2,1 ( ) 2,1 ( ) 2,1 ( * wwc wwc n nwwcwwc ++= where</definiens>
				<definiens id="1">the number of different bigrams in the corpus that have frequency c. Following Katz , we estimate the probability of unseen bigrams to be p ( w2|w1 ) ≅ If the missing bigram is composed of two individually observed words , this technique allows us to estimate the probability mass of the unseen bigram</definiens>
			</definition>
			<definition id="3">
				<sentence>In some cases , the unseen bigram consists of individual words that have never been seen .</sentence>
				<definiendum id="0">unseen bigram</definiendum>
				<definiens id="0">consists of individual words that have never been seen</definiens>
			</definition>
			<definition id="4">
				<sentence>Results of Bigram Model 60 65 70 75 80 85 90 40 60 90 Percentage of Training Data W o r d A c c u r a c y P e r c e n t a g e Hebrew 1 Hebrew2 Arabic Figure 3 presents our results using the bigram HMM model , where “Hebrew 1” measures word accuracy be in Hebrew , “Hebrew 2” measures phonetic group accuracy , and “Arabic” measures word accuracy in Arabic .</sentence>
				<definiendum id="0">“Hebrew</definiendum>
				<definiendum id="1">“Arabic”</definiendum>
				<definiens id="0">measures word accuracy in Arabic</definiens>
			</definition>
			<definition id="5">
				<sentence>For Hebrew , a morphological analyzer called Nakdan Text exists , as part of the Rav Milim project for the processing of modern Hebrew ( Choueka and Neeman 1995 ) .</sentence>
				<definiendum id="0">Hebrew</definiendum>
				<definiens id="0">a morphological analyzer called Nakdan Text exists , as part of the Rav Milim project for the processing of modern</definiens>
			</definition>
			<definition id="6">
				<sentence>We wish to demonstrate that HMMs are a useful tool for computational processing of Semitic languages , and that these models generalize to other languages .</sentence>
				<definiendum id="0">HMMs</definiendum>
				<definiens id="0">a useful tool for computational processing of Semitic languages</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>A simple appositive structure consists of a noun phrase ( NP ) , followed by a comma , followed by another NP , where the two NPs are coreferent .</sentence>
				<definiendum id="0">simple appositive structure</definiendum>
			</definition>
			<definition id="1">
				<sentence>As a motivating example , assume that ( 1 ) appositives are the targeted syntactic structure ( 2 ) bootstrapping begins by using the PNP lexicon , and ( 3 ) PEOPLE is the semantic category of Proper NP Lexicon Syntactic Heuristics Text Corpus Prospective Proper NPs Seed Words Exclusive Non−Exclusive Non−Exclusive Exclusive Lexicon General Noun Prospective General Nouns Figure 1 : Bootstrapping Model interest .</sentence>
				<definiendum id="0">PEOPLE</definiendum>
				<definiens id="0">the semantic category of Proper NP Lexicon Syntactic Heuristics Text Corpus Prospective Proper NPs Seed Words Exclusive Non−Exclusive Non−Exclusive Exclusive Lexicon General Noun Prospective General Nouns Figure 1 : Bootstrapping Model interest</definiens>
			</definition>
			<definition id="2">
				<sentence>Exclusivity filtering is the only step that uses statistics .</sentence>
				<definiendum id="0">Exclusivity filtering</definiendum>
			</definition>
			<definition id="3">
				<sentence>First , we use an evidence measure : Evidence ( w ; c ) = S w ; c S w where S w is the number of times word w was found in the syntactic structure , and S w ; c is the number of times word w was found in the syntactic structure collocated with a member of category c.Theevidence measure is the maximum likelihood estimate that a word belongs to a semantic category given that it appears in the targeted syntactic structure ( a word is assumed to belong to the category if it is collocated with another category member ) .</sentence>
				<definiendum id="0">S w</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">the number of times word w was found in the syntactic structure</definiens>
			</definition>
			<definition id="4">
				<sentence>Exclusivity ( w ; c ) = S w ; c S w ; : c where S w ; c is the number of times word w was found in the syntactic structure collocated with a member of category c , andS w ; : c is the number of times word w was found in the syntactic structure collocated with a member of a different semantic class .</sentence>
				<definiendum id="0">Exclusivity</definiendum>
				<definiendum id="1">c</definiendum>
				<definiendum id="2">c</definiendum>
				<definiens id="0">the number of times word w was found in the syntactic structure collocated with a member of category c</definiens>
			</definition>
			<definition id="5">
				<sentence>People ( WSJ ) : adman , co-chairman , head , economist , shareholder , AMR Chairman Robert Crandall , Assistant Secretary David Mullins , Deng Xiaoping , Abby Joseph Cohen , C. Everett Koop Organization ( WSJ ) : parent , subsidiary , distiller , arm , suitor , AMR Corp. , ABB ASEA Brown Boveri , J.P. Morgan , James River , Federal Reserve Board People ( Pharm ) : surgeon , executive , recipient , co-author , pioneer , Amgen Chief Executive Officer , Barbara Ryan , Chief Scientific Officer Norbert Riedel , Dr. Cole , Analyst Mark Augustine Organization ( Pharm ) : device-maker , drugmaker , licensee , organization , venture , ALR Technologies , Aventis Pharmaceuticals , Bayer AG , FDA Advisory Panel , Hadassah University Hospital Product ( Pharm ) : compound , stent , platform , blocker , antibiotic , Bexxar , Viratrol , MBX-102 , Apothesys Decision Support System , AERx Pain Management System Table 1 : Examples of Learned Words of a word in general .</sentence>
				<definiendum id="0">People</definiendum>
				<definiendum id="1">Aventis Pharmaceuticals , Bayer AG</definiendum>
				<definiens id="0">surgeon , executive , recipient , co-author , pioneer</definiens>
				<definiens id="1">device-maker , drugmaker , licensee , organization , venture</definiens>
				<definiens id="2">compound , stent , platform , blocker , antibiotic , Bexxar , Viratrol , MBX-102 , Apothesys Decision Support System</definiens>
				<definiens id="3">Examples of Learned Words of a word in general</definiens>
			</definition>
			<definition id="6">
				<sentence>The first value ( X ) is the percentage of entries that were judged to be correct , and the second value ( Y ) is the accuracy after removing entries resulting from parser errors .</sentence>
				<definiendum id="0">X )</definiendum>
				<definiens id="0">the percentage of entries that were judged</definiens>
			</definition>
			<definition id="7">
				<sentence>Seed Words Syntactic Structures Lexicons for All 3 Appositive Bootstrapping Process Compound Noun Bootstrapping Process ISA Clause Bootstrapping Process Figure 2 : Co-Training Model Co-training ( Blum and Mitchell , 1998 ) is a learning technique which combines classifiers that support different views of the data in a single learning mechanism .</sentence>
				<definiendum id="0">Co-Training Model Co-training</definiendum>
				<definiens id="0">a learning technique which combines classifiers that support different views of the data in a single learning mechanism</definiens>
			</definition>
</paper>

		<paper id="1508">
			<definition id="0">
				<sentence>The toolkit implements an approach to grammar development and system optimization that builds on precise empirical data and systematic experimentation , as it has been advocated by , among others , Erbach &amp; Uszkoreit ( 1990 ) , Erbach ( 1991 ) , and Carroll ( 1994 ) .</sentence>
				<definiendum id="0">toolkit</definiendum>
				<definiens id="0">implements an approach to grammar development and system optimization that builds on precise empirical data and systematic experimentation , as it has been advocated by , among others</definiens>
			</definition>
			<definition id="1">
				<sentence>Parallelization of Test Runs The [ incr tsdb ( ) ] architecture ( see Figure 1 ) separates the batch control and statistics kernel from what is referred to as client processors ( i.e. parsing systems like the LKB or PET ) through an application program interface ( API ) and the Parallel Virtual Machine ( PVM ; Geist , Bequelin , Dongarra , Manchek , &amp; Sunderam , 1994 ) message-passing protocol layer .</sentence>
				<definiendum id="0">client processors</definiendum>
				<definiendum id="1">Virtual Machine</definiendum>
				<definiens id="0">i.e. parsing systems like the LKB or PET ) through an application program interface ( API ) and the Parallel</definiens>
			</definition>
			<definition id="2">
				<sentence>computational grammars is a difficult challenge , for the HPSG framework two metrics suggest themselves : the number of types ( i.e. the size of the grammatical ontology ) and the number of grammar rules ( i.e. the inventory of construction types ) .</sentence>
				<definiendum id="0">computational grammars</definiendum>
				<definiendum id="1">grammar rules</definiendum>
				<definiens id="0">a difficult challenge , for the HPSG framework two metrics suggest themselves : the number of types ( i.e. the size of the grammatical ontology</definiens>
			</definition>
</paper>

		<paper id="1504">
			<definition id="0">
				<sentence>Note that the surface subject of the passive is rendered as the Dobj ( deep object ) in LF , and the par-phrase as the Dsub ( deep subject ) .</sentence>
				<definiendum id="0">Dobj</definiendum>
				<definiens id="0">deep object ) in LF</definiens>
			</definition>
			<definition id="1">
				<sentence>The transfer component consists of transfer patterns automatically acquired from sentencealigned bilingual corpora ( described below ) using an alignment algorithm described in detail in Menezes and Richardson ( 2001 ) .</sentence>
				<definiendum id="0">transfer component</definiendum>
			</definition>
</paper>

		<paper id="1607">
			<definition id="0">
				<sentence>According to a report of EAGLES ( 1998 ) , LLOCE is a small size learner style dictionary largely derived from LDOCE and organized along semantic principles .</sentence>
				<definiendum id="0">LLOCE</definiendum>
			</definition>
			<definition id="1">
				<sentence>DTs is the set of dictionary meanings for s entry , each meaning is represented by d. W S = { s } , set of English real words and idioms presented in S. W T = { t | t ∈T ∧ t ∈ VD } , set of Vietnamese possible words presented in T. where : VD is the Vietnamese Dictionary containing Vietnamese possible words and phrases .</sentence>
				<definiendum id="0">DTs</definiendum>
				<definiendum id="1">VD</definiendum>
				<definiens id="0">the set of dictionary meanings for s entry , each meaning is represented by d. W S = { s } , set of English real words and idioms presented in S. W T = { t | t ∈T ∧ t ∈ VD } , set of Vietnamese possible words presented in T. where :</definiens>
			</definition>
			<definition id="2">
				<sentence>DTSim ( s , t ) = max Sim ( d , t ) |||| ) , ( ) , ( ) , ( YX bXToYaFrom YXClassSim XaYb + + = ∑∑ ∈∈ Pr ( s , t ) = t ( s , t ) x d ( i , j ) ConceptSim ( s , t ) = maxClassSim ( X , Y ) s∈X , t∈Y ( 2 ) ( 4 ) ( 5 ) ( 3 ) 2 x | d ∩ t | Sim ( d , t ) = | d | + | t | ( 1 ) Table 3 .</sentence>
				<definiendum id="0">DTSim</definiendum>
				<definiens id="0">s , t ) = max Sim ( d , t ) |||| ) , ( ) , ( ) , ( YX bXToYaFrom YXClassSim XaYb + + = ∑∑ ∈∈ Pr ( s , t ) = t</definiens>
			</definition>
			<definition id="3">
				<sentence>WordNet and Class-based Probabilities , WORDNET : An Electronic Lexical Database ( edited by Christiane Fellbaum ) , MIT Press , pp .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiendum id="1">WORDNET</definiendum>
				<definiens id="0">An Electronic Lexical Database ( edited by Christiane Fellbaum )</definiens>
			</definition>
			<definition id="4">
				<sentence>WordNet : an electronic lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">an electronic lexical database</definiens>
			</definition>
</paper>

		<paper id="1503">
			<definition id="0">
				<sentence>LFG assumes a version of Chomsky’s Universal Grammar hypothesis , namely that all languages are structured by similar underlying principles .</sentence>
				<definiendum id="0">LFG</definiendum>
				<definiens id="0">assumes a version of Chomsky’s Universal Grammar hypothesis</definiens>
			</definition>
			<definition id="1">
				<sentence>The ParGram project aims to test the LFG formalism for its universality and coverage limitations and to see how far parallelism can be maintained across languages .</sentence>
				<definiendum id="0">ParGram project</definiendum>
				<definiens id="0">aims to test the LFG formalism for its universality and coverage limitations and to see how far parallelism can be maintained across languages</definiens>
			</definition>
			<definition id="2">
				<sentence>The LS-GRAM project ( Schmidt et al. , 1996 ) , funded by the EU-Commission under LRE ( Linguistic Research and Engineering ) , was concerned with the development of grammatical resources for nine European languages : Danish , Dutch , English , French , German , Greek , Italian , Portuguese , and Spanish .</sentence>
				<definiendum id="0">LS-GRAM project</definiendum>
				<definiens id="0">Danish , Dutch , English , French , German , Greek , Italian , Portuguese , and Spanish</definiens>
			</definition>
			<definition id="3">
				<sentence>An effort which is closer in spirit to ParGram is the implemention of grammar development platforms for HPSG .</sentence>
				<definiendum id="0">ParGram</definiendum>
				<definiens id="0">the implemention of grammar development platforms for HPSG</definiens>
			</definition>
			<definition id="4">
				<sentence>The Norwegian grammar includes a semantic projection ; their analyses produce not only cand f-structures , but also semantic structures .</sentence>
				<definiendum id="0">Norwegian grammar</definiendum>
				<definiens id="0">includes a semantic projection ; their analyses produce not only cand f-structures , but also semantic structures</definiens>
			</definition>
			<definition id="5">
				<sentence>Parallelism leads to the situation where the feature GEND occurs in German , French , Urdu , and Norwegian , but not in English and Japanese .</sentence>
				<definiendum id="0">Parallelism</definiendum>
				<definiens id="0">the situation where the feature GEND occurs in German , French , Urdu</definiens>
			</definition>
</paper>

		<paper id="0604">
			<definition id="0">
				<sentence>The central mechanism of the theory , the Word Formation Strategy ( WFS ) , is a sort of non-decomposable morphological transformation that relates full words with full words ( or helps one fashion a full word from another full word ) and parses any complex word into a variable and a non-variable component .</sentence>
				<definiendum id="0">Word Formation Strategy</definiendum>
			</definition>
			<definition id="1">
				<sentence>Two-level morphology : a general computational model for word-form recognition and production .</sentence>
				<definiendum id="0">Two-level morphology</definiendum>
				<definiens id="0">a general computational model for word-form recognition and production</definiens>
			</definition>
</paper>

		<paper id="0509">
			<definition id="0">
				<sentence>glottal stop , � � voiced pharyngeal fricative ( �Ayn ) , đ � velarized d , ś � velarized s. Orthographic transliterations appear in curly brackets .</sentence>
				<definiendum id="0">fricative</definiendum>
				<definiens id="0">�Ayn ) , đ � velarized d , ś � velarized s. Orthographic transliterations appear in curly brackets</definiens>
			</definition>
			<definition id="1">
				<sentence>A lemma can be said to be the equivalent to a lexical entry : the basic grammatical unit of natural language that is semantically closed .</sentence>
				<definiendum id="0">lemma</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Hamza sign , which represents the glottal stop phoneme , can be written in 5 different ways , depending on its phonological environment .</sentence>
				<definiendum id="0">Hamza sign</definiendum>
				<definiens id="0">represents the glottal stop phoneme</definiens>
			</definition>
			<definition id="3">
				<sentence>MSA has incomplete agreement in verb-subject sentences , which are the vast majority .</sentence>
				<definiendum id="0">MSA</definiendum>
				<definiens id="0">has incomplete agreement in verb-subject sentences , which are the vast majority</definiens>
			</definition>
			<definition id="4">
				<sentence>Perhaps the major challenge for NLP analysis in MSA and MH is overcoming the ambiguity of forms .</sentence>
				<definiendum id="0">MH</definiendum>
				<definiens id="0">overcoming the ambiguity of forms</definiens>
			</definition>
			<definition id="5">
				<sentence>The lemma database contains all crucial information about each lemma , including lexical features such as part of speech , gender , number , meaning , root , verb pattern ( Wazn / Binyan ) etc .</sentence>
				<definiendum id="0">lemma database</definiendum>
				<definiens id="0">part of speech , gender , number , meaning , root , verb pattern</definiens>
			</definition>
			<definition id="6">
				<sentence>The idiom/collocation database stores information about co-occurrence of words .</sentence>
				<definiendum id="0">idiom/collocation database</definiendum>
				<definiens id="0">stores information about co-occurrence of words</definiens>
			</definition>
			<definition id="7">
				<sentence>In the records there is one extra field as compared to the basic morphological analyzer : the score field , which reflects the effect of the context analysis .</sentence>
				<definiendum id="0">score field</definiendum>
				<definiens id="0">reflects the effect of the context analysis</definiens>
			</definition>
</paper>

		<paper id="1905">
			<definition id="0">
				<sentence>QA is different than search engines in two aspects : ( i ) instead of a string of keyword search terms , the query is a natural language question , necessitating question parsing , ( ii ) instead of a list of documents or URLs , a list of candidate answers at phrase level or sentence level are expected to be returned in response to a query , hence the need for text processing beyond keyword indexing , typically supported by Natural Language Processing ( NLP ) and Information Extraction ( IE ) ( Chinchor and Marsh 1998 , Hovy , Hermjakob and Lin 2001 , Li and Srihari 2000 ) .</sentence>
				<definiendum id="0">query</definiendum>
			</definition>
			<definition id="1">
				<sentence>• Part-of-Speech Tagging : tagging syntactic categories such as noun , verb , adjective , etc. • Shallow Parsing : grouping basic linguistic units as building blocks for structural links , such as Basic Noun Phrase , Verb Group , etc. • Asking-point Identification : analysis of question sentences to determine what is being asked • Semantic Parsing : decoding grammatical dependency relationships at the logical level between linguistic units , such as Verb-Subject ( V-S ) , Verb-Object ( V-O ) , Head-Modifier ( H-M ) relationships ; both active patterns and passive patterns will be parsed into the same underlying logical S-V-O relationships • Named Entity Tagger : classifying proper names and other phrases to different categories such as Person , Organization , Location , Money , etc. • Entity Association Extractor : relating named entities with predefined associations such as Affiliation , Position , Age , Spouse , Address , etc .</sentence>
				<definiendum id="0">Part-of-Speech Tagging</definiendum>
				<definiendum id="1">Head-Modifier</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Asking-point ( Link ) Identification Module is charged with the task of parsing wh-phrases in their context into three categories : NE Askingpoint , Asking-point Association Link and Asking-point Grammar Link .</sentence>
				<definiendum id="0">Asking-point</definiendum>
				<definiens id="0">NE Askingpoint , Asking-point Association Link and Asking-point Grammar Link</definiens>
			</definition>
			<definition id="3">
				<sentence>If the incoming question is Who won the Nobel Prize in 1991 , and the candidate answer string is John Smith won the Nobel Prize in 1991 , the question template and answer template are shown below : win V-S : NePerson [ Who ] V-O : NP [ the Nobel Prize ] H-M : NeYear [ 1991 ] win V-S : NePerson [ John Smith ] V-O : NP [ the Nobel Prize ] H-M : NeYear [ 1991 ] The template matching will match the asking point Who with the answer point John Smith because for all the dependency links in the trees , the information is all compatible ( in this case , exact match ) .</sentence>
				<definiendum id="0">information</definiendum>
				<definiens id="0">Who won the Nobel Prize in 1991 , and the candidate answer string is John Smith won the Nobel Prize in 1991</definiens>
			</definition>
</paper>

		<paper id="0608">
			<definition id="0">
				<sentence>As evaluation measure , we used “word accuracy” which computes the rate of words with all predicted syllable brackets exactly matching the annotated syllable brackets .</sentence>
				<definiendum id="0">“word accuracy”</definiendum>
				<definiens id="0">computes the rate of words with all predicted syllable brackets exactly matching the annotated syllable brackets</definiens>
			</definition>
</paper>

		<paper id="1402">
</paper>

		<paper id="0405">
			<definition id="0">
				<sentence>For the Dallas Cowboys-Cincinnati Bengals football game topic , for example , in addition to the test query BENGALS AND COWBOYS , other queries used to search the date range of documents in order to identify potential recall errors included the following : • CINCINNATI AND ( COWBOYS OR FOOTBALL ) AND NOT ( BENGALS AND COWBOYS ) • DALLAS AND ( BENGALS OR FOOTBALL OR OHIO ) AND NOT ( BENGALS AND COWBOYS ) • CINERGY AND NOT ( BENGALS AND COWBOYS ) ( Cinergy Field is the name of the football field where the game was played ) All documents retrieved by such queries were examined for their degree of relevance in order to produce more accurate recall results in this test .</sentence>
				<definiendum id="0">Dallas Cowboys-Cincinnati Bengals football game topic</definiendum>
				<definiendum id="1">BENGALS AND COWBOYS ) ( Cinergy Field</definiendum>
				<definiens id="0">the name of the football field where the game was played ) All documents retrieved by such queries were examined for their degree of relevance in order to produce more accurate recall results in this test</definiens>
			</definition>
</paper>

		<paper id="0902">
			<definition id="0">
				<sentence>Roughly speaking , SMT divides the task of translation into two steps : a word-level translation model and a model for word reordering during the translation process .</sentence>
				<definiendum id="0">SMT</definiendum>
				<definiens id="0">the task of translation into two steps : a word-level translation model and a model for word reordering during the translation process</definiens>
			</definition>
</paper>

		<paper id="1101">
			<definition id="0">
				<sentence>Event matching is the process of selecting the relevant facts in a news article in terms of their general type ( e.g. selling or buying companies , winning a football match ) , their participants and their related roles ( e.g. the company sold or the winning football team ) Authoring is the activity of generating links between news articles according to relationships established among facts detected in the previous phase .</sentence>
				<definiendum id="0">Event matching</definiendum>
				<definiendum id="1">Authoring</definiendum>
				<definiens id="0">the process of selecting the relevant facts in a news article in terms of their general type ( e.g. selling or buying companies , winning a football match ) , their participants and their related roles ( e.g. the company sold or the winning football team</definiens>
			</definition>
			<definition id="1">
				<sentence>The NAMIC system uses a modularised IE architecture whose principal components , used to create the IE repository , are morpho-syntactic analysis , categorisation and semantic analysis .</sentence>
				<definiendum id="0">NAMIC system</definiendum>
				<definiens id="0">uses a modularised IE architecture whose principal components</definiens>
			</definition>
			<definition id="2">
				<sentence>Ambiguity is controlled by partof-speech tagging and domain verb-subcategorisation frames that guide the dependency recognition phase .</sentence>
				<definiendum id="0">Ambiguity</definiendum>
				<definiens id="0">guide the dependency recognition phase</definiens>
			</definition>
			<definition id="3">
				<sentence>The NE Matcher returns the text with the Named Entities marked .</sentence>
				<definiendum id="0">NE Matcher</definiendum>
			</definition>
			<definition id="4">
				<sentence>The NE grammar contains rules for coreferring abbreviations as well as different ways of expressing the same named entity such as Dr. Smith , John Smith and Mr. Smith occurring in the same article .</sentence>
				<definiendum id="0">NE grammar</definiendum>
				<definiens id="0">contains rules for coreferring abbreviations as well as different ways of expressing the same named entity such as Dr. Smith , John Smith and Mr. Smith occurring in the same article</definiens>
			</definition>
			<definition id="5">
				<sentence>The Discourse Processor module translates the semantic representation produced by the parser into a representation of instances , their ontological classes and their attributes , in the XI knowledge representation language ( Gaizauskas and Humphreys , 1996 ) .</sentence>
				<definiendum id="0">Discourse Processor module</definiendum>
				<definiens id="0">translates the semantic representation produced by the parser into a representation of instances , their ontological classes and their attributes , in the XI knowledge representation language</definiens>
			</definition>
			<definition id="6">
				<sentence>As one context can enter in more than one cluster ( as it can share all ( or part ) of its relations with the others ) , the inclusion property establishes a natural partial order among clusters .</sentence>
				<definiendum id="0">inclusion property</definiendum>
			</definition>
			<definition id="7">
				<sentence>The clustering step has been approached with a technique similar to the Galois lattices , where feature vectors represent syntactic-semantic properties of the different verbs ( i.e. pattern a38 a12 a29a8a30a31a30a31a30a31a29a50a38a39a33 derived in the previous phase ) .</sentence>
				<definiendum id="0">feature vectors</definiendum>
				<definiens id="0">represent syntactic-semantic properties of the different verbs ( i.e. pattern a38 a12 a29a8a30a31a30a31a30a31a29a50a38a39a33 derived in the previous phase )</definiens>
			</definition>
			<definition id="8">
				<sentence>EuroWordNet ( Vossen , 1998 ) is a multilingual lexical knowledge ( KB ) base comprised of hierarchical representations of lexical items for several European languages ( Dutch , Italian , Spanish , German , French , Czech and Estonian ) .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
			</definition>
			<definition id="9">
				<sentence>Information Retrieval ( Spark Jones and Willett , 1997 ; Rijsbergen , 1979 ) , or document retrieval as it is in practice , is a well used , robust technology which allows users to access some subset of documents by means of a set of keywords .</sentence>
				<definiendum id="0">Information Retrieval</definiendum>
				<definiendum id="1">document retrieval</definiendum>
				<definiens id="0">a well used , robust technology which allows users to access some subset of documents by means of a set of keywords</definiens>
			</definition>
</paper>

		<paper id="1204">
			<definition id="0">
				<sentence>Nicoletta CALZOLARI Istituto di Linguistica Computazionale , CNR Area della Ricerca , Via Moruzzi 1 Pisa , Italy , 56100 glottolo @ ilc.cnr.it Alessandro LENCI Dipartimento di Linguistica , Università di Pisa Via S. Maria 36 Pisa , Italy , 56100 alessandro.lenci @ ilc.cnr.it Francesca BERTAGNA Dipartimento di Linguistica , Università di Pisa Via S. Maria 36 Pisa , Italy , 56100 francesca.bertagna @ ilc.cnr.it Antonio ZAMPOLLI Istituto di Linguistica Computazionale , CNR Area della Ricerca , Via Moruzzi 1 Pisa , Italy , 56100 pisa @ ilc.cnr.it ISLE is a continuation of the long standing EAGLES initiative and it is supported by EC and NSF under the Human Language Technology ( HLT ) programme .</sentence>
				<definiendum id="0">ISLE</definiendum>
			</definition>
			<definition id="1">
				<sentence>ISLE ( International Standards for Language Engineering ) is a continuation of the long standing European EAGLES ( Expert Advisory Group for Language Engineering Standards ) initiative ( Calzolari et al. , 1996 ) , carried out through a number of subsequent projects funded by the European Commission ( EC ) since 1993 .</sentence>
				<definiendum id="0">ISLE</definiendum>
				<definiens id="0">a continuation of the long standing European EAGLES ( Expert Advisory Group for Language Engineering Standards ) initiative ( Calzolari et al. , 1996 ) , carried out through a number of subsequent projects funded by the European Commission ( EC ) since 1993</definiens>
			</definition>
			<definition id="2">
				<sentence>ISLE is an initiative under the Human Language Technology ( HLT ) programme within the EU-US International Research Co-operation with the aim to develop and promote widely agreed and urgently demanded HLT standards , common guidelines and best practice recommendations for infrastructural language resources ( Zampolli , 1998 ) , ( Calzolari , 1998 ) , tools that exploit them , and language engineering products .</sentence>
				<definiendum id="0">ISLE</definiendum>
				<definiens id="0">an initiative under the Human Language Technology ( HLT ) programme within the EU-US International Research Co-operation with the aim to develop</definiens>
			</definition>
			<definition id="3">
				<sentence>For evaluation , ISLE is working on : i ) quality models for machine translation systems ; ii ) maintenance of previous guidelines in an ISO based framework ( ISO 9126 , ISO 14598 ) .</sentence>
				<definiendum id="0">ISLE</definiendum>
				<definiens id="0">working on : i ) quality models for machine translation systems ; ii ) maintenance of previous guidelines in an ISO based framework ( ISO 9126</definiens>
			</definition>
			<definition id="4">
				<sentence>The CLWG pursues this goal by proposing a general schema for the encoding of multilingual lexical information , the MILE ( Multilingual ISLE Lexical Entry ) .</sentence>
				<definiendum id="0">CLWG</definiendum>
			</definition>
			<definition id="5">
				<sentence>The “conceptual core” of the lexicons consists of the basic structured set of “semantic types” ( the SIMPLE ontology ) and the basic set of notions to be encoded for each Semantic Unit ( SemU ) : domain information , lexicographic gloss , argument structure , selectional restrictions/preferences on the arguments , event type , links of the arguments to the syntactic subcategorization frames as represented in the PAROLE lexicons , ‘qualia’ structure , following the Generative Lexicon ( Pustejovsky , 1995 ) , semantic relations , etc..</sentence>
				<definiendum id="0">“conceptual core” of the lexicons</definiendum>
				<definiens id="0">consists of the basic structured set of “semantic types” ( the SIMPLE ontology ) and the basic set of notions to be encoded for each Semantic Unit ( SemU ) : domain information , lexicographic gloss , argument structure , selectional restrictions/preferences on the arguments , event type , links of the arguments to the syntactic subcategorization frames as represented in the PAROLE lexicons , ‘qualia’ structure , following the Generative Lexicon</definiens>
			</definition>
			<definition id="6">
				<sentence>Multi-MILE specifies a formal environment for the characterization of multilingual correspondences between lexical items .</sentence>
				<definiendum id="0">Multi-MILE</definiendum>
				<definiens id="0">specifies a formal environment for the characterization of multilingual correspondences between lexical items</definiens>
			</definition>
			<definition id="7">
				<sentence>The MILE Shared Lexical Objects will instantiate the MILE Lexical Data Categories , to be used to build in an easy and straightforward way lexical entries .</sentence>
				<definiendum id="0">MILE Shared Lexical Objects</definiendum>
			</definition>
			<definition id="8">
				<sentence>The ISLE Lexicographic Station is a development platform used to automatically generate a prototype tool starting from the MILE DTD .</sentence>
				<definiendum id="0">ISLE Lexicographic Station</definiendum>
			</definition>
</paper>

		<paper id="1007">
</paper>

		<paper id="1814">
			<definition id="0">
				<sentence>A P-Name sometimes forms part of but not a complete named entity .</sentence>
				<definiendum id="0">P-Name</definiendum>
				<definiens id="0">forms part of but not a complete named entity</definiens>
			</definition>
			<definition id="1">
				<sentence>We then remove all 2 http : //www.google.com/intl/zh-CN/ Seed P-Name characters Seed context cue words Webpages P-Names Generate new P-Name characters And new context cue words Search Engine Search Engine Evaluate StringMatch non-Chinese letters and common words containing more than one character .</sentence>
				<definiendum id="0">//www.google.com/intl/zh-CN/ Seed P-Name</definiendum>
				<definiens id="0">Generate new P-Name characters And new context cue words Search Engine Search Engine Evaluate StringMatch non-Chinese letters and common words containing more than one character</definiens>
			</definition>
			<definition id="2">
				<sentence>c -x ( or c +x ) gives the probability that the P-Name is of type x , if this cue-word is at the left ( or right ) boundary of the P-Name .</sentence>
				<definiendum id="0">c -x</definiendum>
				<definiendum id="1">c +x )</definiendum>
				<definiendum id="2">P-Name</definiendum>
				<definiens id="0">gives the probability that the</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus for each P-Name candidate p k ( m ) ( p k ( m ) =c 1 c 2 …c n ) in P ( m ) , we compute : ) ( / ) ( ) ( ) ( 2 ) ( 1 ) ( m k m k m k psMpsps ∗+= β ( 3 ) 12 ( ) 2 3 1 112 11 11 1 1 ( ) ( ) ( ) ( ) nN n N n N m kjiji ji ij ij i j sp nc ncc ncccωω ω −− +++ == = = = = =+ +∑∑ ∑∑ ∑∑ ( ) 2 ( ) max ( , , ) m k plo s pcc= ( 3.2 ) where n is the number of characters in p k ( m ) , and N equals |P ( m ) | .</sentence>
				<definiendum id="0">P-Name candidate p k</definiendum>
				<definiendum id="1">p k</definiendum>
				<definiendum id="2">1 ( ) ( ) ( )</definiendum>
				<definiendum id="3">n</definiendum>
				<definiendum id="4">N equals |P</definiendum>
				<definiens id="0">the number of characters in p k</definiens>
			</definition>
			<definition id="4">
				<sentence>n j ( c i ) , n j ( c i c i+1 ) and n j ( c i c i+1 c i+2 ) are respectively number of times the character strings c i , c i c i+1 and c i c i+1 c i+2 in p k ( m ) also appear in other P-Name candidates in P ( m ) .</sentence>
				<definiendum id="0">n j ( c i</definiendum>
				<definiens id="0">respectively number of times the character strings c i , c i c i+1 and c i c i+1 c i+2 in p k</definiens>
			</definition>
			<definition id="5">
				<sentence>Thus , intuitively we estimate Conf ( c i ( m ) ) by its occurrences in both PKUC and P ( m ) as : ( ) ( ) ( ) 1 1 ( ) 1 ( ) ( ) ln ( ) ( ) c c c N m k N m mk i k N km kneg k sp Conf c s p sp N = = = ∑ =∗∑ +∑ Here we assume that there are N c P-Name candidates in P ( m ) that contain c i ( m ) ; and N neg is the number of times that c i ( m ) is used as single-character word in PKUC .</sentence>
				<definiendum id="0">Conf ( c i</definiendum>
				<definiendum id="1">N neg</definiendum>
				<definiens id="0">the number of times that c i ( m ) is used as single-character word in PKUC</definiens>
			</definition>
			<definition id="6">
				<sentence>( ) , ( max { ) ( ) ( 1 ) ( 1 ) ( +− ∗∗∗ += +− i cB i cB ii cConfecConfe cConfcSConf ii α where α is a predefined constant ( we use α = 1 ) , and ) ( ) ( ) ( ; ) ( ) ( ) ( 11 i ii i i ii i cC ccC cB cC ccC cB −−++ == .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">a predefined constant ( we use α = 1 )</definiens>
			</definition>
			<definition id="7">
				<sentence>Recall ( Rc ) = N c / ( N c + N p + N m ) ; Precision ( Pr ) = N c / ( N c + N p + N s ) .</sentence>
				<definiendum id="0">Recall</definiendum>
			</definition>
</paper>

		<paper id="2019">
			<definition id="0">
				<sentence>We approach the problem of identifying named entities as a kind of probabilistic tagging : given a sequence of words w1 a24a25a24a25a24 wn , we want to find the corresponding sequence of tags t1 a24a25a24a25a24 tn , drawn from a vocabulary of possible tags T , which satisfies : S a26 argmax t1 a27a27a27 tn Pa28 t1 a24a25a24a25a24 tn a29 w1 a24a25a24a25a24 wn a30 ( 1 ) The possible tags are a31a6a32a34a33a36a35a36a37 and a38a34a32a39a33a40a35a8a37 , which mark the beginning and continuation of personal names ; a31a41a32a40a42a39a37a14a43 and a38a34a32a36a42a39a37a14a43 , which mark names of organizations ; a31a41a32a34a44a41a42a36a45 and a38a34a32a34a44a41a42a36a45 , which mark names of locations ; a31a6a32a39a46a12a38a34a47a8a45 and a38a34a32a39a46a12a38a34a47a8a45 , which mark miscellaneous names ; and a42 , which marks non-name tokens .</sentence>
				<definiendum id="0">a42</definiendum>
				<definiens id="0">the problem of identifying named entities as a kind of probabilistic tagging : given a sequence of words w1 a24a25a24a25a24 wn</definiens>
				<definiens id="1">a vocabulary of possible tags T , which satisfies : S a26 argmax t1 a27a27a27 tn Pa28 t1 a24a25a24a25a24 tn a29 w1 a24a25a24a25a24 wn a30 ( 1 ) The possible tags are a31a6a32a34a33a36a35a36a37 and a38a34a32a39a33a40a35a8a37 , which mark the beginning and continuation of personal names ; a31a41a32a40a42a39a37a14a43 and a38a34a32a36a42a39a37a14a43 , which mark names of organizations ; a31a41a32a34a44a41a42a36a45 and a38a34a32a34a44a41a42a36a45 , which mark names of locations</definiens>
			</definition>
			<definition id="1">
				<sentence>Maximum entropy models ( Jaynes , 1957 ; Berger et al. , 1996 ; Della Pietra et al. , 1997 ) are a class of exponential models which require no unwarranted independence assumptions and have proven to be very successful in general for integrating information from disparate and possibly overlapping sources .</sentence>
				<definiendum id="0">Maximum entropy models</definiendum>
			</definition>
			<definition id="2">
				<sentence>To allow the use in the first sentence to provide information about the second , a73a77a76a41a86a89a87 uses a feature which is true just in case the current word occurred as part of a personal name previously in the text being tagged .</sentence>
				<definiendum id="0">a73a77a76a41a86a89a87</definiendum>
				<definiens id="0">uses a feature which is true just in case the current word occurred as part of a personal name previously in the text being tagged</definiens>
			</definition>
</paper>

		<paper id="2032">
</paper>

		<paper id="2006">
			<definition id="0">
				<sentence>The Mean Probability of Truth , as shown in Table 1 , is another measure of the quality of the POS predictions made by the algorithm , representing the probability mass associated with the true POS tag averaged over all words .</sentence>
				<definiendum id="0">Mean Probability of Truth</definiendum>
				<definiens id="0">predictions made by the algorithm , representing the probability mass associated with the true POS tag averaged over all words</definiens>
			</definition>
			<definition id="1">
				<sentence>1000 words of test data were annotated with a standardized , finely detailed part-of-speech tag inventory including the full complex distinctions for gender , person , number , case , detailed tense and nominal definiteness ( an inventory of 259 and 230 fine-grained tags were used for Spanish and Romanian respectively ) .</sentence>
				<definiendum id="0">nominal definiteness</definiendum>
				<definiens id="0">an inventory of 259 and 230 fine-grained tags were used for Spanish and Romanian respectively )</definiens>
			</definition>
</paper>

		<paper id="0308">
			<definition id="0">
				<sentence>The 13th edition ( 2002 ) of the UMLS Metathesaurus contains over than sixty families of medical vocabularies , and organized in some 775,000 concepts .</sentence>
				<definiendum id="0">UMLS Metathesaurus</definiendum>
			</definition>
			<definition id="1">
				<sentence>A phrase from MEDLINE becomes a candidate term in the Metathesaurus if the following two requirements are met : 1 ) a demodified term created from this phrase is found in the terminology and 2 ) similarly modified terms exist in the terminology , for a given semantic category .</sentence>
				<definiendum id="0">MEDLINE</definiendum>
				<definiens id="0">becomes a candidate term in the Metathesaurus if the following two requirements are met : 1 ) a demodified term created from this phrase is found in the terminology and 2 ) similarly modified terms exist in the terminology</definiens>
			</definition>
</paper>

		<paper id="1106">
			<definition id="0">
				<sentence>In particular , we define a translation equivalence relation as a bilingual lexical semantic relation .</sentence>
				<definiendum id="0">translation equivalence relation</definiendum>
				<definiens id="0">a bilingual lexical semantic relation</definiens>
			</definition>
			<definition id="1">
				<sentence>The rich and structured semantic information described in WN and EWN can be transported through accurate translation if the conceptual relations defined by LSRs remain constant in both languages .</sentence>
				<definiendum id="0">EWN</definiendum>
				<definiens id="0">The rich and structured semantic information described in WN and</definiens>
			</definition>
			<definition id="2">
				<sentence>In this model , the relation y , between CW1 and CW2 is a functional combination of the three LSR’s i , x , and ii .</sentence>
				<definiendum id="0">relation y</definiendum>
				<definiendum id="1">CW2</definiendum>
				<definiens id="0">a functional combination of the three LSR’s i , x , and ii</definiens>
			</definition>
			<definition id="3">
				<sentence>Translation-mediated LSR Prediction ( Reduced Model , currently adopted ) With the semantic contribution of the translation equivalency defined as a ( bilingual ) LSR , the inference of LSR in the target language wordnet is a simple combination of semantic relations .</sentence>
				<definiendum id="0">Translation-mediated LSR Prediction ( Reduced Model</definiendum>
				<definiens id="0">currently adopted ) With the semantic contribution of the translation equivalency defined as a ( bilingual ) LSR , the inference of LSR in the target language wordnet is a simple combination of semantic relations</definiens>
			</definition>
			<definition id="4">
				<sentence>Translation-mediated LSR Prediction ( when TE’s are synonymous ) In this case , the translation LSR is an identical relation ; the LSR of the source language wordnet can be directly inherited .</sentence>
				<definiendum id="0">Translation-mediated LSR Prediction</definiendum>
				<definiendum id="1">LSR</definiendum>
				<definiens id="0">an identical relation</definiens>
			</definition>
</paper>

		<paper id="1112">
			<definition id="0">
				<sentence>Suppose the stingray is one of a number of candidate antecedent NPs in the context .</sentence>
				<definiendum id="0">Suppose the stingray</definiendum>
				<definiens id="0">one of a number of candidate antecedent NPs in the context</definiens>
			</definition>
			<definition id="1">
				<sentence>The single-case recall is the ratio of the size of the overlap set to the size of the target set ( i.e , how many real antecedents remain after filtering ) , while the singlecase precision is the ratio of the size of the overlap set to the size of the selected set ( i.e. , what proportion of the selected set are real antecedents ) .</sentence>
				<definiendum id="0">single-case recall</definiendum>
				<definiens id="0">the ratio of the size of the overlap set to the size of the target set ( i.e , how many real antecedents remain after filtering</definiens>
			</definition>
			<definition id="2">
				<sentence>Another direction we have not explored is the complementary information about anaphora resolution that derives from explicit statements of association : in line with the Gricean maxims , the author’s decision to use an expression such as the leg of the okapi may constitute evidence that there is more than one previously mentioned entity in the context that may have legs .</sentence>
				<definiendum id="0">Gricean maxims</definiendum>
				<definiens id="0">the complementary information about anaphora resolution that derives from explicit statements of association : in line with the</definiens>
			</definition>
</paper>

		<paper id="1608">
			<definition id="0">
				<sentence>Each combination consists of JU , an Unknown word for which we have no valency information ; E , its English translation ( or translations ) ; which is linked to one or more valency patterns JV in the valency dictionary .</sentence>
				<definiendum id="0">combination</definiendum>
				<definiens id="0">consists of JU , an Unknown word for which we have no valency information ; E , its English translation ( or translations ) ; which is linked to one or more valency patterns JV in the valency dictionary</definiens>
			</definition>
</paper>

		<paper id="0224">
			<definition id="0">
				<sentence>Repair ( repair ) Changes the content of the current DU .</sentence>
				<definiendum id="0">Repair</definiendum>
			</definition>
			<definition id="1">
				<sentence>An example is found in dialogue excerpt ( 1 ) from an older dyad , where one of B’s utterances , “a-hon-na-ikatta ( that’s good ) , ” acknowledges the previous utterance of speaker A while initiating B’s presentation of her own information .</sentence>
				<definiendum id="0">”</definiendum>
				<definiens id="0">acknowledges the previous utterance of speaker A while initiating B’s presentation of her own information</definiens>
			</definition>
			<definition id="2">
				<sentence>The difference was significant ( t ( 5 ) =2.87 , .01 &lt; p &lt; .05 , two-tailed ) . 233 225 203 110 138 51 0 % 20 % 40 % 60 % 80 % 100 % older dyads younger dyads ( 10.3 % ) ( 42.8 % ) ( 46.9 % ) ( 26.7 % ) ( 22.4 % ) ( 50.9 % ) initiation-ack generalpurpose ack non-generalpurpose ack Figure 2. Ratios of the three types of acknowledgements in older dyads and younger dyads General-purpose acknowledgements Beside these dual-functional acknowledgments , there were a significant number of “dedicated” acknowledgements , namely , utterances annotated as “acknowledgements” but not as anything else. Inside these dedicated acknowledgements , however , we can distinguish two types. One type consists of general-purpose acknowledgements , such as “uh-huh” and “m” , that could be used irrespective of the contents of the preceding presentations. The other type comprises special-purpose acknowledgements , such as repeating or paraphrasing responses , whose contents must vary depending on the contents of the preceding presentations. An example of general-purpose acknowledgement is speaker A’s short utterance “n ( m ) ” in excerpt ( 2 ) . In contrast , speaker B’s utterance “n-n-mite ( m , you saw it ) ” in excerpt ( 3 ) is a case of special-purpose acknowledgment since it paraphrases the preceding utterance by speaker A and thus depends on its specific content. 1 ( 2 ) act UU Utterance init 26 50.1 B : nanka-sono ( well ) cont 26 ( 50.1 ) 50.2 shinseki-no-hito-kaeru ( the relative left ) cont 26 ( 50.2 ) 50.3 koro-ni-natte ( at time ) ack 26 51.1 A : n ( m ) init 27 B : obaasan-ga-kite ( her grand mother came and ) cont 27 ( 52.1 ) anta-aisatu-senkaine-tte ( said “`you must greet them” ) ( 3 ) act UU Utterance init 1 -tte ( then I had to get in the third car ) ack 1 init 2 o-he ( I tried hard to get to the car ) cont 2 ( 4.1 ) 4.2 : hata-sanbon-mitoite ( seeing the flag ) ack 2 ( m , you saw it ) init 3 ( When I got to the car , it had no seats ) ack 3 ( ah ) acknowledgements into general-purpose and special purpose acknowledgements are subtler than suggested here. For example , an utterance that sounds “n ( m ) ” could be classified as special-purpose if it has a marked prosodic feature that signals the speaker’s emotion or feeling. Interestingly , older dyads produced more general-purpose acknowledgements ( 43 % ) than younger adults did ( 23 % ) . The difference is highly significant ( χ 2 ( 2 ) =67.2 , p &lt; .01 ) , as we can also see by comparing the middle sections of the two column in Figure 2. Post-grounding acknowledgements Dialogues conducted by older dyads contained several instances of requests for acknowledgement issued after acknowledgements , while those by younger dyads contained no such instances ( older dyads , 9 ; younger dyads , 0 ) . For example , the second request for acknowledgement “ne ( see ? ) ” towards the end of excerpt ( 4 ) was issued after the acknowledgment “n ( m ) ” by speaker A , requesting further acknowledgement of the presentation “watashi-no-shita-wo ( and my younger sister ) ” that had been already grounded. This phenomenon is particularly interesting since a request for acknowledgement after acknowledgement is not in the scope of Traum’s finite-state transition model of grounding sequences. ( 4 ) act UU Utterance init 92 178.1 B : hoide-shita-ga ( and my younger brother ) reqAck 92 178.2 : ne ( see ? ) ack 92 179.1 A : n ( m ) init 93 180.1 B : ano ( what was that ? ) cont 93 ( 180.1 ) 180.2 : nakanogou-he-yattee ( they left him in relative hand ) ack 93 181.1 A : n ( m ) init 94 182.1 B : watashi-no-shita-wo ( and my younger sister ) ack 94 183.1 A : n ( m ) reqAck 94 184.1 B : ne ( see ? ) ack 94 185.1 A : n ( m ) Furthermore , older dyads produced “acknowledgements after acknowledgements” slightly more frequently than younger did ( older adults , 35 ; younger adults , 25 ) . The second utterance “nn ( m ) ” by speaker B is an instance of that type of acknowledgements. ( 5 ) act UU Utterance cont 34 ( 64.3 ) 64.4 B : hachiju-kara-ue-ni-naryanani-wo-nn-na-aryan-na ( as we get over 80’s ) cont 34 ( 64.4 ) 64.5 : otoroeru-bakkari-ya ( we are languishing ) ack 34 65.1 A : hou-ya ( right ) ack 34 66.1 B : nn ( m ) response Collaborative completions were slightly more frequent in older dyads than in younger dyads ( older adults , 13 ; younger adults , 7 ) . Likewise , echoic responses were more frequent in older dyads than in younger dyads ( older adults , 23 ; younger adults , 10 ) . Speaker A’s second utterance in excerpt ( 6 ) is an example of collaborative completion done by an older dyad , and speaker B’s second utterance in excerpt ( 7 ) is an example of echoic response done by an older speaker. ( 6 ) act UU Utterance init 37 74.1 B : hitori-oru-ga-to ( whether being alone or ) ack 37 75.1 A : n ( m ) init 38 76.1 B : nina-tooru-ga-to ( being with someone ) cont 38 ( 76.1 ) 76.2 : debu-kibun-ga ( feels ) ack 38 init 39 77.1 A : chigau-ga ( a big difference ) ack 39 78.1 B : chigota-tte-ne ( yes , it’s different ) ( 7 ) act UU Utterance ack 1 ( you’re right ) init 2 ( that’s how rice can grow ) ack 2 ( can grow ) Thus , our exploratory comparison suggests several points of difference between dialogues by older dyads and dialogues by younger dyads. What would these individual differences reveal about common stereotypes about conversations with aged people ? Do these individual differences combine themselves to define two different grounding styles attributable to older and younger dyads ? utterances were less frequent in older dyads. Initiation-acknowledgements are dual-functional utterances , performing two grounding acts by single utterance units. Dedicated acknowledgments are mono-functional , performing single grounding functions per single utterance units. Thus , if we define the grounding tempo of a given part of dialogue as the ratio of the number of utterance units to the number of different grounding acts performed by them , then an occurrence of initiation-acknowledgement certainly increases the grounding tempo of the local context. In contrast , a dedicated acknowledgement has no such accelerative effect on grounding tempo , and a frequent use of dedicated acknowledgements may even cause impressions of relative slowness of the grounding tempo in the local context. Now our exploratory comparison indicated that older dyads used dedicated acknowledgements more frequently than younger dyads , who used initiation-acknowledgements more frequently. It is then plausible that this contrast in the kinds of frequently used acknowledgements underlies the common impression that conversations with older people are slow-paced and , since the grounding tempo is related to how efficiently information is shared , this contrast might partially account for the common impression that older people understand things slowly. after acknowledgements. In this regard , an occurrence of post-grounding acknowledgment must have a deceleration effect on the grounding tempo in the local context. For the grounding function it performs , namely , the acknowledgement of the presented information , is one that has been done by the preceding acknowledgement , and thus the ratio of the number of utterance units to the number of grounding functions performed by them is even worse than the case of dedicated acknowledgments. Now again , our exploratory comparison indicated that older dyads used post-grounding acknowledgements more frequently than younger dyads. This contrast therefore might be an added cause to the stereotypes mentioned above , slow-pacedness and slow-understanding. general-purpose acknowledgements more frequently. Precisely because the form of a general-purpose acknowledgement , such as “uh-huh” and “m , ” does not depend on the content of the utterance being acknowledged , a general-purpose acknowledgement gives only weak evidence of reception or understanding of the content. In contrast , a special-purpose acknowledgement , such as repeating or paraphrasing responses , has stronger evidentiality , since its form is the result of an appropriate choice relative to the content of the acknowledged utterance. Now , our preliminary comparison indicated that older dyads used general-purpose acknowledgements more frequently than younger dyads , and this contrast may well be still another cause to the negative stereotype on older people’s capacities for understanding during conversation. Overall , our exploratory comparison suggests a particular style of grounding as characteristic to older dyads. That is , older dyads use more dedicated acknowledgments than dual-functional acknowledgements involving initiations , and among dedicated acknowledgements , older dyads use more general-purpose acknowledgements than special-purpose acknowledgements ; they also use post-grounding acknowledgements relatively often , either spontaneously or solicited by requests for acknowledgements. Let us call this grounding style style A , and call the grounding style characterized by the opposite tendencies style B. Now we have obtained this hypothetical contrast in grounding styles through an overall comparison of the entire group of older dyads and the entire group of younger dyads. So the question remains how much this contrast applies to individual dyads of older and younger people. Aren’t there any exceptional older dyads with grounding style B ? Any younger dyads with grounding style A ? To address these questions , we re-evaluated our data and ranked all ten dialogues in our data according to the ratios of dedicated acknowledgements , the ratios of general-purpose acknowledgements , and the counts of post-grounding acknowledgements ( solicited acknowledgements and spontaneous acknowledgements ) . Table 2 shows the result of ranking , where the hatched cells indicate dialogues by older dyads. Here we see that the contrast of style A and style B divides older dyads and younger dyads fairly clearly. In fact , the separation of older and younger dyads is statistically significant in the ratio of dedicated acknowledgements ( W 0 &gt; =w 5,5 ( 0.01 ) =39 , two-tailed ) , the ratio of general-purpose acknowledgements ( W 0 &gt; =w 5,5 ( 0.025 ) =38 , two-tailed ) and the counts of solicited post-grounding acknowledgements ( E ( R ) =27.5 , V ( R ) =36 , Z 0 =3.75 , Z ( a ) =3.09 , p &lt; 0.002 , two-tailed ) .</sentence>
				<definiendum id="0">exploratory comparison</definiendum>
				<definiendum id="1">exploratory comparison</definiendum>
				<definiens id="0">26.7 % ) ( 22.4 % ) ( 50.9 % ) initiation-ack generalpurpose ack non-generalpurpose ack Figure 2. Ratios of the three types of acknowledgements in older dyads and younger dyads General-purpose acknowledgements Beside these dual-functional acknowledgments , there were a significant number of “dedicated” acknowledgements , namely , utterances annotated as “acknowledgements” but not as anything else. Inside these dedicated acknowledgements</definiens>
				<definiens id="1">irrespective of the contents of the preceding presentations. The other type comprises special-purpose acknowledgements , such as repeating or paraphrasing responses , whose contents must vary depending on the contents of the preceding presentations. An example of general-purpose acknowledgement is speaker A’s short utterance “n ( m ) ” in excerpt ( 2 ) . In contrast , speaker B’s utterance “n-n-mite ( m , you saw it ) ” in excerpt ( 3 ) is a case of special-purpose acknowledgment since it paraphrases the preceding utterance by speaker A and thus depends on its specific content. 1 ( 2 ) act UU Utterance init 26 50.1 B : nanka-sono ( well ) cont 26 ( 50.1 ) 50.2 shinseki-no-hito-kaeru ( the relative left ) cont 26 ( 50.2 ) 50.3 koro-ni-natte ( at time ) ack 26 51.1 A : n ( m ) init 27 B : obaasan-ga-kite ( her grand mother came and ) cont 27 ( 52.1 ) anta-aisatu-senkaine-tte ( said “`you must greet them” ) ( 3 ) act UU Utterance init 1 -tte ( then I had to get in the third car ) ack 1 init 2 o-he ( I tried hard to get to the car ) cont 2 ( 4.1 ) 4.2 : hata-sanbon-mitoite ( seeing the flag ) ack 2 ( m , you saw it ) init 3 ( When I got to the car , it had no seats ) ack 3 ( ah ) acknowledgements into general-purpose and special purpose acknowledgements are subtler than suggested here. For example , an utterance that sounds “n ( m ) ” could be classified as special-purpose if it has a marked prosodic feature that signals the speaker’s emotion or feeling. Interestingly , older dyads produced more general-purpose acknowledgements ( 43 % ) than younger adults did ( 23 % ) . The difference is highly significant ( χ 2 ( 2 ) =67.2 , p &lt; .01 ) , as we can also see by comparing the middle sections of the two column in Figure 2. Post-grounding acknowledgements Dialogues conducted by older dyads contained several instances of requests for acknowledgement issued after acknowledgements , while those by younger dyads contained no such instances ( older dyads , 9 ; younger dyads , 0 ) . For example , the second request for acknowledgement “ne ( see ? ) ” towards the end of excerpt ( 4 ) was issued after the acknowledgment “n ( m ) ” by speaker A , requesting further acknowledgement of the presentation “watashi-no-shita-wo ( and my younger sister ) ” that had been already grounded. This phenomenon is particularly interesting since a request for acknowledgement after acknowledgement is not in the scope of Traum’s finite-state transition model of grounding sequences. ( 4 ) act UU Utterance init 92 178.1 B : hoide-shita-ga ( and my younger brother ) reqAck 92 178.2 : ne ( see ? ) ack 92 179.1 A : n ( m ) init 93 180.1 B : ano ( what was that ? ) cont 93 ( 180.1 ) 180.2 : nakanogou-he-yattee ( they left him in relative hand ) ack 93 181.1 A : n ( m ) init 94 182.1 B : watashi-no-shita-wo ( and my younger sister ) ack 94 183.1 A : n ( m ) reqAck 94 184.1 B : ne ( see ? ) ack 94 185.1 A : n ( m ) Furthermore , older dyads produced “acknowledgements after acknowledgements” slightly more frequently than younger did ( older adults , 35 ; younger adults , 25 ) . The second utterance “nn ( m ) ” by speaker B is an instance of that type of acknowledgements. ( 5 ) act UU Utterance cont 34 ( 64.3 ) 64.4 B : hachiju-kara-ue-ni-naryanani-wo-nn-na-aryan-na ( as we get over 80’s ) cont 34 ( 64.4 ) 64.5 : otoroeru-bakkari-ya ( we are languishing ) ack 34 65.1 A : hou-ya ( right ) ack 34 66.1 B : nn ( m ) response Collaborative completions were slightly more frequent in older dyads than in younger dyads ( older adults , 13 ; younger adults , 7 ) . Likewise , echoic responses were more frequent in older dyads than in younger dyads ( older adults , 23 ; younger adults , 10 ) . Speaker A’s second utterance in excerpt ( 6 ) is an example of collaborative completion done by an older dyad , and speaker B’s second utterance in excerpt ( 7 ) is an example of echoic response done by an older speaker. ( 6 ) act UU Utterance init 37 74.1 B : hitori-oru-ga-to ( whether being alone or ) ack 37 75.1 A : n ( m ) init 38 76.1 B : nina-tooru-ga-to ( being with someone ) cont 38 ( 76.1 ) 76.2 : debu-kibun-ga ( feels ) ack 38 init 39 77.1 A : chigau-ga ( a big difference ) ack 39 78.1 B : chigota-tte-ne ( yes , it’s different ) ( 7 ) act UU Utterance ack 1 ( you’re right ) init 2 ( that’s how rice can grow</definiens>
				<definiens id="2">suggests several points of difference between dialogues by older dyads and dialogues by younger dyads. What would these individual differences reveal about common stereotypes about conversations with aged people ? Do these individual differences combine themselves to define two different grounding styles attributable to older and younger dyads ? utterances were less frequent in older dyads. Initiation-acknowledgements are dual-functional utterances</definiens>
				<definiens id="3">the grounding tempo of a given part of dialogue as the ratio of the number of utterance units to the number of different grounding acts performed by them , then an occurrence of initiation-acknowledgement certainly increases the grounding tempo of the local context. In contrast , a dedicated acknowledgement has no such accelerative effect on grounding tempo , and a frequent use of dedicated acknowledgements may even cause impressions of relative slowness of the grounding tempo in the local context. Now our exploratory comparison indicated that older dyads used dedicated acknowledgements more frequently than younger dyads , who used initiation-acknowledgements more frequently. It is then plausible that this contrast in the kinds of frequently used acknowledgements underlies the common impression that conversations with older people are slow-paced and , since the grounding tempo is related to how efficiently information is shared , this contrast might partially account for the common impression that older people understand things slowly. after acknowledgements. In this regard , an occurrence of post-grounding acknowledgment must have a deceleration effect on the grounding tempo in the local context. For the grounding function it performs , namely , the acknowledgement of the presented information , is one that has been done by the preceding acknowledgement , and thus the ratio of the number of utterance units to the number of grounding functions performed by them is even worse than the case of dedicated acknowledgments. Now again , our exploratory comparison indicated that older dyads used post-grounding acknowledgements more frequently than younger dyads. This contrast therefore might be an added cause to the stereotypes mentioned above , slow-pacedness and slow-understanding. general-purpose acknowledgements more frequently. Precisely because the form of a general-purpose acknowledgement , such as “uh-huh” and “m , ” does not depend on the content of the utterance being acknowledged , a general-purpose acknowledgement gives only weak evidence of reception or understanding of the content. In contrast , a special-purpose acknowledgement , such as repeating or paraphrasing responses , has stronger evidentiality , since its form is the result of an appropriate choice relative to the content of the acknowledged utterance. Now , our preliminary comparison indicated that older dyads used general-purpose acknowledgements more frequently than younger dyads</definiens>
				<definiens id="4">suggests a particular style of grounding as characteristic to older dyads. That is , older dyads use more dedicated acknowledgments than dual-functional acknowledgements involving initiations , and among dedicated acknowledgements , older dyads use more general-purpose acknowledgements than special-purpose acknowledgements ; they also use post-grounding acknowledgements relatively often , either spontaneously or solicited by requests for acknowledgements. Let us call this grounding style style A , and call the grounding style characterized by the opposite tendencies style B. Now we have obtained this hypothetical contrast in grounding styles through an overall comparison of the entire group of older dyads and the entire group of younger dyads. So the question remains how much this contrast applies to individual dyads of older and younger people. Aren’t there any exceptional older dyads with grounding style B ? Any younger dyads with grounding style A ? To address these questions , we re-evaluated our data and ranked all ten dialogues in our data according to the ratios of dedicated acknowledgements , the ratios of general-purpose acknowledgements , and the counts of post-grounding acknowledgements ( solicited acknowledgements and spontaneous acknowledgements</definiens>
			</definition>
</paper>

		<paper id="1707">
			<definition id="0">
				<sentence>Introduction The website Slate is an information centre on language technology ( LT ) developed in Sweden and/or for the Swedish language .</sentence>
				<definiendum id="0">website Slate</definiendum>
				<definiens id="0">an information centre on language technology</definiens>
			</definition>
			<definition id="1">
				<sentence>SlateBot is an application being developed in Perl , in order to acommodate for entry modes a ) and b ) above .</sentence>
				<definiendum id="0">SlateBot</definiendum>
				<definiens id="0">an application being developed in Perl</definiens>
			</definition>
			<definition id="2">
				<sentence>The HTML parser looks for SPAN tags , and returns those that correspond to our categories .</sentence>
				<definiendum id="0">HTML parser</definiendum>
			</definition>
			<definition id="3">
				<sentence>The Semantic Web is an attempt to give information on the web meaning , in order to facilitate searching , automation , etc ( W3C , 2001 ) .</sentence>
				<definiendum id="0">Semantic Web</definiendum>
				<definiens id="0">an attempt to give information on the web meaning</definiens>
			</definition>
			<definition id="4">
				<sentence>The Resource Description Framework , RDF is a language for providing metadata to support the Semantic Web .</sentence>
				<definiendum id="0">RDF</definiendum>
			</definition>
			<definition id="5">
				<sentence>The elements’ main uses are for information or service resources , e.g. bibliographies and card catalogs .</sentence>
				<definiendum id="0">elements’ main uses</definiendum>
				<definiens id="0">information or service resources</definiens>
			</definition>
			<definition id="6">
				<sentence>DocBook is an SGML or XML format for technical documentation .</sentence>
				<definiendum id="0">DocBook</definiendum>
			</definition>
			<definition id="7">
				<sentence>The Open Archives Initiative , OAI is an experimental initiative for efficient dissemination of content .</sentence>
				<definiendum id="0">OAI</definiendum>
				<definiens id="0">an experimental initiative for efficient dissemination of content</definiens>
			</definition>
			<definition id="8">
				<sentence>OLAC , the Open Language Archives Community is a community who develop methods for digital archiving of language resources and a network for housing and accessing such services ( OLAC , 2001 ) .</sentence>
				<definiendum id="0">OLAC</definiendum>
				<definiendum id="1">Open Language Archives Community</definiendum>
				<definiens id="0">a community who develop methods for digital archiving of language resources and a network for housing and accessing such services</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>In particular , using all of these knowledge sources and SVM ( i.e. , a single learning algorithm ) achieves accuracy higher than the best official scores on both SENSEVAL-2 and SENSEVAL-1 test data .</sentence>
				<definiendum id="0">SVM</definiendum>
			</definition>
			<definition id="1">
				<sentence>Given an occurrence of a word a2 in a natural language text , the task of word sense disambiguation ( WSD ) is to determine the correct sense of a2 in that context .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">a natural language text , the task of word sense disambiguation</definiens>
				<definiens id="1">to determine the correct sense of a2 in that context</definiens>
			</definition>
			<definition id="2">
				<sentence>WSD is a fundamental problem of natural language processing .</sentence>
				<definiendum id="0">WSD</definiendum>
			</definition>
			<definition id="3">
				<sentence>, the POS feature vector is a24a26a25a28a27 a8a10a29a31a30a32a8 a27a33a27 a8 a27a33a27a35a34 a8a37a36a38a8a40a39a37a8a40a39a42a41 where a39 denotes the POS tag of a null token .</sentence>
				<definiendum id="0">POS feature vector</definiendum>
				<definiendum id="1">a39</definiendum>
			</definition>
			<definition id="4">
				<sentence>a39 , where a39 denotes a null token .</sentence>
				<definiendum id="0">a39</definiendum>
			</definition>
			<definition id="5">
				<sentence>If a training ( or test ) context of a2 has collocation a60 , and a60 is a selected feature value , then the a52 a20a61a53a55 feature of a2 has value a60 .</sentence>
				<definiendum id="0">a60</definiendum>
			</definition>
			<definition id="6">
				<sentence>The SVM ( Vapnik , 1995 ) performs optimization to find a hyperplane with the largest margin that separates training examples into two classes .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiens id="0">performs optimization to find a hyperplane with the largest margin that separates training examples into two classes</definiens>
			</definition>
			<definition id="7">
				<sentence>SVM performs best without feature selection , whereas NB performs best with some feature selection ( a44 a12a104a45a74a46 ) .</sentence>
				<definiendum id="0">SVM</definiendum>
			</definition>
</paper>

		<paper id="1907">
			<definition id="0">
				<sentence>Green : An experimental system generating summary of japanese editorials by combining multiple discourse characteristics .</sentence>
				<definiendum id="0">Green</definiendum>
			</definition>
</paper>

		<paper id="1602">
			<definition id="0">
				<sentence>In the current practice , a multilingual document consists in many parallel monolingual files , which may be technical documentation as well as help files , message files , or simply thematic information put on the web and intended for a multilingual audience ( medicine , cooking , travel… ) .</sentence>
				<definiendum id="0">multilingual document</definiendum>
			</definition>
			<definition id="1">
				<sentence>The UNL representation of a text is a list of `` semantic graphs '' , each expressing the meaning of a natural language utterance .</sentence>
				<definiendum id="0">UNL representation of a text</definiendum>
				<definiens id="0">a list of `` semantic graphs '' , each expressing the meaning of a natural language utterance</definiens>
			</definition>
			<definition id="2">
				<sentence>The lexical units , called Universal Words ( UW ) , represent ( sets of ) word meanings , something less ambitious than concepts .</sentence>
				<definiendum id="0">Universal Words</definiendum>
				<definiens id="0">sets of ) word meanings , something less ambitious than concepts</definiens>
			</definition>
			<definition id="3">
				<sentence>AUW is an English term or special symbol ( number… ) possibly completed by semantic restrictions : the UW `` process '' represents all word meanings of that lemma , seen as citation form ( verb or noun here ) , and `` process ( icl &gt; do , agt &gt; person ) '' covers only the meanings of processing , working on , etc .</sentence>
				<definiendum id="0">AUW</definiendum>
			</definition>
			<definition id="4">
				<sentence>The UNL-html format predates XML , hence the special tags like [ S ] and { unl } , but we may transform it into an equivalent `` UNL-xml '' format .</sentence>
				<definiendum id="0">UNL-html format</definiendum>
				<definiens id="0">predates XML , hence the special tags like [ S ] and { unl }</definiens>
			</definition>
			<definition id="5">
				<sentence>It currently allows to : • get dynamic information on UNL sites , • access a collection of documents ( specs , articles ) on UNL , • browse a collection of aligned sentences and UNL graphs in many languages • experiment multilingual deconversion , • try the first version of a Web and XMLoriented UNL graph editor , limited to simple graphs ( trees ) , and programmed using more tags ( UNL-xml-ed ) , DOM , and javaScript [ 9 ] .</sentence>
				<definiendum id="0">UNL</definiendum>
			</definition>
</paper>

		<paper id="2009">
			<definition id="0">
				<sentence>The CD clustering algorithm , presented in Section 2.2 below , extends the information bottleneck ( IB ) soft clustering method .</sentence>
				<definiendum id="0">CD clustering algorithm</definiendum>
				<definiens id="0">presented in Section 2.2 below , extends the information bottleneck ( IB ) soft clustering method</definiens>
			</definition>
			<definition id="1">
				<sentence>It computes , through an iterative EM-like process , probabilistic assignments p ( c|x ) for each element x into each cluster c. Starting with random ( or heuristically chosen ) p ( c|x ) values at time t = 0 , the IB algorithm iterates the following steps until convergence : IB1 : Calculate for each cluster c its marginal probability : ∑ ∈ − = Xx tt xcpxpcp ) | ( ) ( ) ( 1 .</sentence>
				<definiendum id="0">IB algorithm</definiendum>
				<definiens id="0">through an iterative EM-like process , probabilistic assignments p ( c|x ) for each element x into each cluster c. Starting with random ( or heuristically chosen ) p ( c|x ) values at time t = 0 , the</definiens>
			</definition>
			<definition id="2">
				<sentence>IB2 : Calculate for each feature y and cluster c a conditional probability p ( y|c ) : ∑ ∈ − = Xx tt cxpxypcyp ) | ( ) | ( ) | ( 1 .</sentence>
				<definiendum id="0">IB2</definiendum>
				<definiens id="0">each feature y and cluster c a conditional probability p ( y|c ) : ∑ ∈ − = Xx tt cxpxypcyp</definiens>
			</definition>
</paper>

		<paper id="1117">
			<definition id="0">
				<sentence>The connection is defined as follows : typedef struct CharConn { int id ; char char1 [ 5 ] ; char char2 [ 5 ] ; int weight ; int wlen ; char wpos [ 20 ] ; char bchar [ 5 ] ; int route ; CharConn *next ; } CharConn ; In the structure , id is the sequence number of a connection edge , char1 is the first character node , char2 is the second character node ; weight is the weight of a edge , if char1 and char2 is in a Chinese word and char2 isn’t the final character of a word , weight equal to 0 ; if char2 is the final character of a word ( char2 is a control node ) , weight equal to 1 .</sentence>
				<definiendum id="0">char1</definiendum>
				<definiendum id="1">char2</definiendum>
				<definiendum id="2">weight</definiendum>
				<definiens id="0">follows : typedef struct CharConn { int id ; char char1 [ 5 ] ; char char2 [ 5 ] ; int weight ; int wlen ; char wpos [ 20 ] ; char bchar [ 5 ] ; int route ; CharConn *next ; } CharConn</definiens>
				<definiens id="1">the sequence number of a connection edge ,</definiens>
				<definiens id="2">the first character node ,</definiens>
				<definiens id="3">the second character node ;</definiens>
				<definiens id="4">the weight of a edge , if char1 and char2 is in a Chinese word and char2 isn’t the final character of a word , weight equal to 0 ; if char2 is the final character of a word ( char2 is a control node ) , weight equal to 1</definiens>
			</definition>
			<definition id="1">
				<sentence>wlen is the length of a word , if char2 isn’t a control node , wlen is zero ; wpos is the part-of-speech of a word , if char2 isn’t a control node , wpos is null ; bchar is the first character of a word , if char2 isn’t a control node , bchar is null ; route is the former connection id , if the length of a word is greater to two characters .</sentence>
				<definiendum id="0">wlen</definiendum>
				<definiendum id="1">wpos</definiendum>
				<definiendum id="2">bchar</definiendum>
				<definiendum id="3">route</definiendum>
				<definiens id="0">the first character of a word</definiens>
			</definition>
			<definition id="2">
				<sentence>The algorithm has some characteristics as follows : ( 1 ) the character net is a basic data structure , makes the use of all information in segmentation consistently and easy .</sentence>
				<definiendum id="0">character net</definiendum>
				<definiens id="0">a basic data structure , makes the use of all information in segmentation consistently and easy</definiens>
			</definition>
</paper>

		<paper id="0712">
			<definition id="0">
				<sentence>Free-style sentence translation accepts natural language sentences and translates them by machine translation .</sentence>
				<definiendum id="0">Free-style sentence translation</definiendum>
			</definition>
			<definition id="1">
				<sentence>A scene represents a place or a situation where the user wishes to accomplish the task and the subtask .</sentence>
				<definiendum id="0">scene</definiendum>
				<definiens id="0">a place or a situation where the user wishes to accomplish the task and the subtask</definiens>
			</definition>
			<definition id="2">
				<sentence>The prototype system consists of six components — speech recognition , machine translation , registered sentence retrieval , parallel text based translation , registered sentence database , speech synthesis ( Figure 1 ) .</sentence>
				<definiendum id="0">prototype system</definiendum>
			</definition>
			<definition id="3">
				<sentence>When the user clicks the “honyaku ( translate ) ” button after selecting the input sentence , the system translates it into English through the machine translation , displays it ( Figure Figure 8 : English translation of the registered sentence “Kore wa ch ¯umon to chigaimasu .</sentence>
				<definiendum id="0">“honyaku</definiendum>
				<definiens id="0">( translate ) ” button after selecting the input sentence , the system translates it into English through the machine translation , displays it ( Figure Figure 8 : English translation of the registered sentence “Kore wa ch ¯umon to chigaimasu</definiens>
			</definition>
</paper>

		<paper id="0710">
</paper>

		<paper id="1018">
</paper>

		<paper id="1611">
</paper>

		<paper id="1509">
			<definition id="0">
				<sentence>A TAG is a set of lexicalized elementary trees that can be combined , through the operations of tree adjunction and tree substitution , to derive syntactic structures for sentences .</sentence>
				<definiendum id="0">TAG</definiendum>
				<definiens id="0">a set of lexicalized elementary trees that can be combined , through the operations of tree adjunction and tree substitution , to derive syntactic structures for sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>Finally , and more crucially , we have omitted one case in our discussion : the case in which the UCP ( NP ( UCP ( JJ electronic ) ( , , ) ( NN computer ) ( CC and ) ( NN building ) ) ( NNS products ) ) Figure 8 : UCP with multiple conjuncts ( S ( NP-SBJ-1 The Series 1989 B bonds ) ( VP ( VBP are ) ( VP ( VBN rated ) ( S *-1 double-A ) ) ) ) ( S ( NP-SBJ-1 The Series 1989 B bonds ) ( VP ( VBP are ) ( UCP-PRD ( ADJP-PRD ( JJ uninsured ) ) ( CC and ) ( VP ( VBN rated ) ( S *-1 double-A ) ) ) ) ) Figure 9 : UCP involving VP argument of the copula is the natural head-child of some node .</sentence>
				<definiendum id="0">UCP-PRD ( ADJP-PRD</definiendum>
				<definiens id="0">the case in which the UCP ( NP ( UCP ( JJ electronic ) ( , , ) ( NN computer )</definiens>
			</definition>
			<definition id="2">
				<sentence>( NP ( NP the 3 billion New Zealand dollars ) ( PRN ( -LRB-LRB- ) ( NP US $ 1.76 billion *U* ) ( -RRB-RRB- ) ) ) a ) A parenthetical NP attached to another NP ( S ( NP-SBJ The total relationship ) ( PRN ( , , ) ( SBAR-ADV as Mr. Lee sees it ) ( , , ) ) ( VP ( VBZ is ) ... ) ) b ) A parenthetical S between subject and verb Figure 12 : Parentheticals intransitive tree for the VB “pass” , onto which the ADVP modifier tree would adjoin .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiens id="0">total relationship ) ( PRN ( , , ) ( SBAR-ADV as Mr. Lee sees it ) ( , , ) ) ( VP ( VBZ is ) ... ) ) b ) A parenthetical S between subject and verb Figure 12 : Parentheticals intransitive tree for the VB “pass”</definiens>
			</definition>
			<definition id="3">
				<sentence>LexTract extracts trees with no concern for the appropriate projective structure of constituents when not explicitly marked in the PTB .</sentence>
				<definiendum id="0">LexTract</definiendum>
				<definiens id="0">extracts trees with no concern for the appropriate projective structure of constituents when not explicitly marked in the PTB</definiens>
			</definition>
			<definition id="4">
				<sentence>Since LexTract do not allow us to spec ( NP ( DT an ) ( ADJP ( RB even ) ( JJR stronger ) ) ( NN argument ) ) ( NP-SBJ-1 ( NP ( JJ late ) ( NNP October ) ) ( NN weather ) ) a0a12a1 a3 a3a3 a4 a4a4 a32a19a37 a20a34a1 a20a22a20a38a30a19a18 a0a12a1a14a13 a0a2a1 a3 a3a3 a4 a4a4 a0a2a1 a0a12a0a2a1a36a18 a0a12a1a14a13 Figure 15 : Complex modification annotation and extracted trees ify for the insertion of “obligatory” projections we had to accomplish this through a somewhat complicated post-processing step using a projection table .</sentence>
				<definiendum id="0">ADJP</definiendum>
				<definiens id="0">NN weather ) ) a0a12a1 a3 a3a3 a4 a4a4 a32a19a37 a20a34a1 a20a22a20a38a30a19a18 a0a12a1a14a13 a0a2a1 a3 a3a3 a4 a4a4 a0a2a1 a0a12a0a2a1a36a18 a0a12a1a14a13 Figure 15 : Complex modification annotation and extracted trees ify for the insertion of “obligatory” projections we had to accomplish this through a somewhat complicated post-processing step using a projection table</definiens>
			</definition>
</paper>

		<paper id="1805">
			<definition id="0">
				<sentence>And ambiguity resolution is one of the most challenging NLP tasks that is currently still beyond the power of machines .</sentence>
				<definiendum id="0">ambiguity resolution</definiendum>
				<definiens id="0">one of the most challenging NLP tasks that is currently still beyond the power of machines</definiens>
			</definition>
</paper>

		<paper id="1810">
			<definition id="0">
				<sentence>The indexing method presented in this paper deals with the following five kinds of files : ( 1 ) Corpus File : a large-scale text file .</sentence>
				<definiendum id="0">Corpus File</definiendum>
				<definiens id="0">a large-scale text file</definiens>
			</definition>
			<definition id="1">
				<sentence>So the Separation File needs to be updated if the Corpus File is changed .</sentence>
				<definiendum id="0">Separation File</definiendum>
				<definiens id="0">needs to be updated if the Corpus File is changed</definiens>
			</definition>
			<definition id="2">
				<sentence>The Separation File is composed of a series of records ; each record consists of two parts : ( 1 ) The code of the delimiters , which distinguishes the different kinds of the delimiters ; ( 2 ) The physical position of each delimiter found in the corpus .</sentence>
				<definiendum id="0">Separation File</definiendum>
				<definiens id="0">composed of a series of records ; each record consists of two parts : ( 1 ) The code of the delimiters , which distinguishes the different kinds of the delimiters</definiens>
				<definiens id="1">physical position of each delimiter found in the corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>Each record of the Frequency File consists of two parts : ( 1 ) The frequency of the word occurring in the Corpus , which is equal to the number of the blocks the word associates in the Index File .</sentence>
				<definiendum id="0">record of the Frequency File</definiendum>
				<definiens id="0">consists of two parts : ( 1 ) The frequency of the word occurring in the Corpus , which is equal to the number of the blocks the word associates in the Index File</definiens>
			</definition>
			<definition id="4">
				<sentence>The following equation is used to compute the mutual information of the adjective-noun pair : ) ( ) ( ) , ( log ) , ( 2 G1DG73G62G11 G1DG73G62G11 G1DG73G62G11 pp p MI = c p N ) ( N ) ( G62G11 G62G11 ≈ , c p N ) ( N ) ( G1DG73 G1DG73 ≈ c p N ) , ( N ) , ( G1DG73G62G11 G1DG73G62G11 ≈ c N is the total number of sentences in the corpus , so 5,816,952= c N .</sentence>
				<definiendum id="0">N</definiendum>
			</definition>
</paper>

		<paper id="1809">
			<definition id="0">
				<sentence>Pinyin is an official coding used in China and getting popular elsewhere .</sentence>
				<definiendum id="0">Pinyin</definiendum>
			</definition>
</paper>

		<paper id="0505">
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>NP Adv PP put PP PP PP NP AdjP S A PCFG is a conditional probability function p ( RHS j LHS ) .1 For example , p ( V NP PPjVP ) gives the probability of the rule VP !</sentence>
				<definiendum id="0">PP PP PP NP AdjP S A PCFG</definiendum>
			</definition>
			<definition id="1">
				<sentence>A simple compromise ( novel to this paper ) is a hybrid Treebank/Markov model , which backs off from a Treebank model to a Markov .</sentence>
				<definiendum id="0">simple compromise</definiendum>
				<definiens id="0">a hybrid Treebank/Markov model , which backs off from a Treebank model to a Markov</definiens>
			</definition>
			<definition id="2">
				<sentence>In the Penn Treebank , put is the head of three constituents ( V , VP , and S , where underlining denotes a head child ) and joins with different dependents at different levels : [ S [ NP Jim ] [ VP [ V put ] [ NP pizza ] [ PP in the oven ] ] ] In the flattened or dependency version that we prefer , each word joins with all of its dependents at once : [ S [ NP Jim ] put [ NP pizza ] [ PP in the oven ] ] A PCFG generating the flat structure must estimate p ( NP put NP PP j Sput ) .</sentence>
				<definiendum id="0">PCFG generating</definiendum>
				<definiens id="0">the head of three constituents ( V , VP , and S , where underlining denotes a head child ) and joins with different dependents at different levels : [ S [ NP Jim ] [ VP [ V put ] [ NP pizza ] [ PP in the oven ] ] ] In the flattened or dependency version</definiens>
			</definition>
			<definition id="3">
				<sentence>A non-flat PCFG adds the dependents of put in 3 independent steps , so in effect it factors the flat rule’s probability into 3 supposedly independent “subrule probabilities , ” p ( NP VPput j Sput ) p ( Vput NP PPjVPput ) p ( putjVput ) .</sentence>
				<definiendum id="0">non-flat PCFG</definiendum>
				<definiens id="0">adds the dependents of put in 3 independent steps , so in effect it factors the flat rule’s probability into 3 supposedly independent “subrule probabilities</definiens>
			</definition>
			<definition id="4">
				<sentence>A learner should seek that maximizes p ( ) p ( D j ) , where D is the set of strings , rules , or trees observed by the learner .</sentence>
				<definiendum id="0">D</definiendum>
			</definition>
			<definition id="5">
				<sentence>MI measures the mutual information of these two events , computed over all words .</sentence>
				<definiendum id="0">MI</definiendum>
			</definition>
			<definition id="6">
				<sentence>To fund NP PP ) denotes the probability that the random walk somehow reaches Sfund !</sentence>
				<definiendum id="0">NP PP )</definiendum>
			</definition>
			<definition id="7">
				<sentence>Narrower generalization weights such as 4 and 5 control where PP is likely to be inserted .</sentence>
				<definiendum id="0">Narrower generalization</definiendum>
				<definiendum id="1">PP</definiendum>
				<definiens id="0">likely to be inserted</definiens>
			</definition>
			<definition id="8">
				<sentence>Beyond the initial weights and generalization weights , in practice we allow one exception weight ( e.g. , 8 ; 9 ) for each rule that appeared in training data .</sentence>
				<definiendum id="0">Beyond</definiendum>
				<definiens id="0">the initial weights and generalization weights</definiens>
			</definition>
			<definition id="9">
				<sentence>We eliminate e and introduce a different parameter e , called a perturbation , which is used in the following replacements for equations ( 1 ) and ( 2 ) : I ( e ) = e ; START + X e0 I ( e0 ) exp e p ( e0 !</sentence>
				<definiendum id="0">perturbation</definiendum>
			</definition>
			<definition id="10">
				<sentence>It is worthwhile to compare the statistical approach here with some other approaches : Transformation models are similar to graphical models : they allow similar patterns of deductive and abductive inference from observations .</sentence>
				<definiendum id="0">Transformation models</definiendum>
				<definiens id="0">similar to graphical models : they allow similar patterns of deductive and abductive inference from observations</definiens>
			</definition>
			<definition id="11">
				<sentence>A transformation model can be regarded as a probabilistic FSA that consists mostly of -transitions .</sentence>
				<definiendum id="0">transformation model</definiendum>
				<definiens id="0">a probabilistic FSA that consists mostly of -transitions</definiens>
			</definition>
</paper>

		<paper id="0206">
			<definition id="0">
				<sentence>Intuitively , these cross-media cues ( CMCs ) help the print reader to integrate information presented in different media , i.e. , printed text and printed graphics .</sentence>
				<definiendum id="0">cross-media</definiendum>
				<definiens id="0">cues ( CMCs ) help the print reader to integrate information presented in different media</definiens>
			</definition>
			<definition id="1">
				<sentence>The dependent variables are the time to complete the tests ( Time ) and score on the tests ( Score ) .</sentence>
				<definiendum id="0">dependent variables</definiendum>
			</definition>
			<definition id="2">
				<sentence>Design : A Practical Introduction .</sentence>
				<definiendum id="0">Design</definiendum>
				<definiens id="0">A Practical Introduction</definiens>
			</definition>
</paper>

		<paper id="0223">
</paper>

		<paper id="0102">
			<definition id="0">
				<sentence>The algorithm estimates the parameters of a Hidden Markov Model ( HMM ) by ExpectationMaximization ( EM ) , using dynamic programming to carry out the expectation steps efficiently .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiens id="0">estimates the parameters of a Hidden Markov Model ( HMM ) by ExpectationMaximization ( EM ) , using dynamic programming to carry out the expectation steps efficiently</definiens>
			</definition>
			<definition id="1">
				<sentence>30 ) That behavior is actually guaranteed : repeated 30It is the total probability of paths that explain the data , i.e. , all paths in Figure 4 , as given by column I of Figure 1 ; see footnote 10 .</sentence>
				<definiendum id="0">30It</definiendum>
				<definiens id="0">the total probability of paths that explain the data , i.e. , all paths in Figure 4</definiens>
			</definition>
</paper>

		<paper id="1411">
</paper>

		<paper id="2033">
			<definition id="0">
				<sentence>The subcategorisation frame includes all the complements of a given word .</sentence>
				<definiendum id="0">subcategorisation frame</definiendum>
				<definiens id="0">includes all the complements of a given word</definiens>
			</definition>
			<definition id="1">
				<sentence>According to Chomsky’s Principles and Parameters Theory ( Chomsky 1981 ) , the UG is composed of principles and parameters , and the processoflearningalanguageisregardedasthesetting of values of a number of parameters , given exposure to this particular language .</sentence>
				<definiendum id="0">UG</definiendum>
				<definiens id="0">composed of principles and parameters , and the processoflearningalanguageisregardedasthesetting of values of a number of parameters , given exposure to this particular language</definiens>
			</definition>
			<definition id="2">
				<sentence>Then , for instance , in the sentence : † ( 3 ) John talks to Mary with logical form † ( 4 ) talk-communicative-act ( e , x , y ) , john ( x ) , comm-to ( y ) , mary ( y ) the verb talks has two arguments , the NP subject John , and the PP to Mary , as represented in the logical form associated with the verb , where the PP is the second argument and as suchshouldbeincludedinthesubcategorisation frame of the verb : ( SnNP ) /PP .</sentence>
				<definiendum id="0">PP</definiendum>
			</definition>
			<definition id="3">
				<sentence>On the other hand , the sentence : † ( 9 ) Bill swims across the river with logical form : † ( 10 ) swim-motion-act ( e , x ) , bill ( x ) , motionacross ( e , y ) , the ( y ) , river ( y ) shows a case where the PP is an ( optional ) argument of the verb swim , and where the appropriate subcategorisation frame for the verb should include it ( ( SnNP ) /PP ) , even though the PP is not included in the logical form of the verb .</sentence>
				<definiendum id="0">bill</definiendum>
				<definiendum id="1">PP</definiendum>
				<definiens id="0">an ( optional ) argument of the verb swim</definiens>
			</definition>
			<definition id="4">
				<sentence>For certain verbs the PP is an obligatory argument of the verb and should be included in its subcategorisation frame .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">an obligatory argument of the verb</definiens>
			</definition>
			<definition id="5">
				<sentence>This is a case of a verb that can occur in both constructions with the PP being a semantic argument , which , when occurring , must be included in the subcategorisation frame of the verb .</sentence>
				<definiendum id="0">semantic argument</definiendum>
				<definiens id="0">a case of a verb that can occur in both constructions with the PP being a</definiens>
			</definition>
			<definition id="6">
				<sentence>The frequency with which put occurs with a locative PP correctly indicates that the PP is an argument of the verb , and it needs to be included in the subcategorisation frame of the verb .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">an argument of the verb , and it needs to be included in the subcategorisation frame of the verb</definiens>
			</definition>
			<definition id="7">
				<sentence>In this case , the PP is an adjunct to the verb .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">an adjunct to the verb</definiens>
			</definition>
			<definition id="8">
				<sentence>To test this approach we conducted an experiment where the learner is evaluated in terms of three different verbs : put where the PP is an obligatory argument , come , where the locative PP is an optional argument , and draw ( in the sense of drawing a picture ) where the PP is an adjunct .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiendum id="1">PP</definiendum>
				<definiens id="0">an obligatory argument , come , where the locative PP is an optional argument</definiens>
				<definiens id="1">an adjunct</definiens>
			</definition>
			<definition id="9">
				<sentence>If so , the PP is an optional complement of the verb .</sentence>
				<definiendum id="0">PP</definiendum>
			</definition>
			<definition id="10">
				<sentence>In terms of frequency of occurrence of the verbs with the locative PPs , other verbs in the mother’s sentences from the entire Sachs corpus also have a similar pattern , with the locative PP being frequent for obligatory arguments of the verb , and less frequent for the other cases : † stay , which according to the “do-so” test has an obligatory locative PP argument , occurs in 100 % of the cases with locative PPs , † come , which has optional locative PP arguments , occurs in 69.6 % of the cases with locative PPs , and all of these can be semantically selected by the verb , † eat , as a transitive verb which does not have a locative PP argument , occurs in only 1.23 % of the cases with locative PPs , and † play , as an intransitive verb also does not have a PP argument , is in 40 % of the cases with a locative PP .</sentence>
				<definiendum id="0">come</definiendum>
				<definiens id="0">has optional locative PP arguments , occurs in 69.6 % of the cases with locative PPs , and all of these can be semantically selected by the verb</definiens>
			</definition>
</paper>

		<paper id="0702">
			<definition id="0">
				<sentence>TF-IDF Clustering Method ( 1 ) Find the word that has the highest TF-IDF value among the words in the sentence set ; ( 2 ) Divide the sentence set into two subsets ; one that contains the word obtained in step ( 1 ) and one that does not ; ( 3 ) Repeat steps ( 1 ) and ( 2 ) recursively until TF-IDF value reaches the threshold .</sentence>
				<definiendum id="0">TF-IDF Clustering Method</definiendum>
				<definiens id="0">Find the word that has the highest TF-IDF value among the words in the sentence set ; ( 2 ) Divide the sentence set into two subsets ; one that contains the word obtained in step ( 1 ) and one that does not ; ( 3 ) Repeat steps ( 1 ) and ( 2 ) recursively until TF-IDF value reaches the threshold</definiens>
			</definition>
			<definition id="1">
				<sentence>The other set consists of 45 dialogues comprising 498 sentences , which may include irregular expressions but closely representing daily spoken language ( hereafter called “real situation dialogue data” ) .</sentence>
				<definiendum id="0">other set</definiendum>
			</definition>
</paper>

		<paper id="0909">
			<definition id="0">
				<sentence>The BNC is a good choice of corpus for us because it has been tagged ( automatically by the CLAWS tagger ) .</sentence>
				<definiendum id="0">BNC</definiendum>
				<definiens id="0">a good choice of corpus for us because it has been tagged</definiens>
			</definition>
			<definition id="1">
				<sentence>BSP is a suite of programs to aid in analyzing bigrams in a corpus ( newer versions allow Ngrams ) .</sentence>
				<definiendum id="0">BSP</definiendum>
			</definition>
			<definition id="2">
				<sentence>The BSP tools count for each bigram in a corpus how many times it occurs , and how many times the first word occurs .</sentence>
				<definiendum id="0">BSP tools</definiendum>
				<definiens id="0">count for each bigram in a corpus how many times it occurs , and how many times the first word occurs</definiens>
			</definition>
			<definition id="3">
				<sentence>n11 is the number of times the bigram xy occurs ; n12 is the number of times x occurs in bigrams at the left of words other than y ; n21 is the number of times y occurs in bigrams after words other that x ; and n22 is the number of bigrams containing neither x nor y. In Table 1 the variable X denotes the presence or absence of daunting in the first position of a bigram , and Y denotes the presence or absence of task in the second position of a bigram .</sentence>
				<definiendum id="0">n11</definiendum>
				<definiendum id="1">n12</definiendum>
				<definiendum id="2">n21</definiendum>
				<definiendum id="3">n22</definiendum>
				<definiendum id="4">variable X</definiendum>
				<definiendum id="5">Y</definiendum>
				<definiens id="0">the number of times the bigram xy occurs ;</definiens>
				<definiens id="1">the number of times x occurs in bigrams at the left of words other than y ;</definiens>
				<definiens id="2">the number of times y occurs in bigrams after words other that x ; and</definiens>
				<definiens id="3">the number of bigrams containing neither x</definiens>
				<definiens id="4">the presence or absence of daunting in the first position of a bigram</definiens>
			</definition>
			<definition id="4">
				<sentence>The marginal distributions of X and Y are the row and column totals obtained by summing the joint frequencies : n+1 = n11 + n21 , n1+ = n11 + n12 , and n++ is the total number of bigrams .</sentence>
				<definiendum id="0">n++</definiendum>
			</definition>
			<definition id="5">
				<sentence>The BSP tool counts for each bigram in a corpus how many times it occurs , how many times the first word occurs at the left of any bigram ( n+1 ) , and how many times the second words occurs at the right of 4http : //www.d.umn.edu/ tpederse/code .</sentence>
				<definiendum id="0">BSP tool</definiendum>
				<definiens id="0">counts for each bigram in a corpus how many times it occurs , how many times the first word occurs at the left of any bigram ( n+1 ) , and how many times the second words occurs at the right of</definiens>
			</definition>
			<definition id="6">
				<sentence>Mutual information , I ( x ; y ) , compares the probability of observing words x and word y together ( the joint probability ) with the probabilities of observing x and y independently ( the probability of occurring together by chance ) ( Church and Hanks , 1991 ) .</sentence>
				<definiendum id="0">y )</definiendum>
			</definition>
			<definition id="7">
				<sentence>Fisher’s exact test is a significance test that is considered to be more appropriate for sparse and skewed samples of data than statistics such as the log-likelihood ratio or Pearson’s Chi-Square test ( Pedersen , 1996 ) .</sentence>
				<definiendum id="0">Fisher’s exact test</definiendum>
			</definition>
			<definition id="8">
				<sentence>If the collocations of interest are xw and yw ( or similarly wx and wy ) , then we have the approximations ¯x1 = s21 = P ( x ; w ) and ¯x2 = s22 = P ( y ; w ) ; therefore : t = P ( x ; w ) P ( y ; w ) qP ( x ; w ) +P ( y ; w ) n++ = nxw nywpn xw + nyw If w is a word that collocates with one of the nearsynonyms in a cluster , and x is each of the near5The search was done on 13 March 2002 .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">a word that collocates with one of the nearsynonyms in a cluster</definiens>
			</definition>
			<definition id="9">
				<sentence>synonyms , we can approximate the mutual information relative to w : P ( w ; x ) P ( x ) = nwx nx where P ( w ) was dropped because it is the same for various x ( we can not compute if we keep it , because we don’t know the total number of bigrams on the Web ) .</sentence>
				<definiendum id="0">P ( w</definiendum>
			</definition>
</paper>

		<paper id="1609">
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>When you’re away from the phone and someone takes a message for you , at the very least you’d expect to be told who called and whether they left a number for you to call back .</sentence>
				<definiendum id="0">someone</definiendum>
				<definiens id="0">takes a message for you , at the very least you’d expect to be told who called and whether they left a number for you to call back</definiens>
			</definition>
			<definition id="1">
				<sentence>In practice , e.g. in the context of a sophisticated voicemail front-end ( Hirschberg et al. , 2001 ) that is tightly integrated with an organization-wide voicemail system and private branch exchange ( PBX ) , additional sources of information may be available : the voicemail system or the PBX might provide information about the originating station of a call , and speaker identification can be used to match a caller’s voice against models of known callers ( Rosenberg et al. , 2001 ) .</sentence>
				<definiendum id="0">speaker identification</definiendum>
				<definiens id="0">Hirschberg et al. , 2001 ) that is tightly integrated with an organization-wide voicemail system and private branch exchange ( PBX ) , additional sources of information</definiens>
			</definition>
</paper>

		<paper id="0905">
			<definition id="0">
				<sentence>Recent lexicalist Grammars project the subcategorisation information encoding in the lexicon onto syntactic structures .</sentence>
				<definiendum id="0">Recent lexicalist Grammars</definiendum>
				<definiens id="0">project the subcategorisation information encoding in the lexicon onto syntactic structures</definiens>
			</definition>
			<definition id="1">
				<sentence>This is why these coTable 2 : Dictionary entries a8 abono ( loan ) a131 a9a12a11a14a13 a37 a17a19a110a5a26a44a22a25a13 a37 a39a74a113a101a30a38a18a42a126a132a18 a15 a41a36a43a103a133 a134 aplicac¸˜ao caso fixac¸˜ao montante pagamento t´ıtulo a135 ( diligence case fixing amount payment bond ) a131 a9a12a11a14a13a16a15a7a17a19a110a5a26a44a22a74a113a101a30a32a18a42a126a132a18a65a37a5a39a25a13a40a15a42a41a36a43a103a133 a134 ajuda despesa pens˜ao quantia remunerac¸˜ao subs´ıdio suplemento valor vencimentoa135 ( assistance expense pension amount remuneration subsidy additional tax value salary ) a131 a9a12a11a14a13a16a37a7a17a34a33a36a18a44a30a81a111 a110a5a26a44a22a25a13a16a37a7a39a74a113a101a30a38a18a42a126a132a18a98a15a98a41a36a43a103a133 a134 conceder conter definir determinar fixar manter prever a135 ( concede comprise define determine fix maintain foresee ) a8 emanar ( emanate ) a131 a9a12a11a14a13 a15 a17a34a33a36a18a44a30a81a111 a110a5a26a44a22a82a26a52a129a122a113a7a126a132a113a5a24 a37 a39a25a13 a15 a41a36a43a103a133 a134 al´ınea artigo c´odigo decreto diploma disposic¸˜ao estatuto legislac¸˜ao lei norma regulamentoa135 ( paragraph article code decree diploma disposition statute legislation law norm regulation ) a131 a9a12a11a14a13 a15 a17a34a33a36a18a44a30a81a111 a110a5a26a44a22a82a26a52a129a122a113a7a126a132a113a5a24 a37 a39a25a13 a15 a41a36a43a103a133 a134 administrac¸˜ao autoridade comiss˜ao conselho direcc¸˜ao estado governo ministro tribunal ´org˜aoa135 ( administration authority commission council direction state government minister tribunal organ ) a8 presidente ( president ) a131 a9a12a11a14a13a16a15a7a17a19a110a5a26a44a22a19a28a4a24a44a26a98a115a52a33a95a110a5a26a50a126a136a116a25a26a59a37a5a39a25a13a40a15a42a41a36a43a103a133 a134 assembleia cˆamara comis˜ao conselho direcc¸˜ao estado empresa gest˜ao instituto regi˜ao rep´ublica secc¸˜ao tribunal a135 ( assembly chamber council direction state enterprise management institute region republic section tribunal ) a131 a9a12a11a14a13a16a37a7a17a19a110a5a26a44a22a25a13a16a37a7a39a19a28a16a24a27a26a65a115a65a33a36a110a114a26a50a126a136a116a25a26a59a15a42a41a36a43a103a133 a134 cargo categoria func¸˜ao lugar remunerac¸ ˜ao vencimento a135 ( post rank function place/post remuneration salary ) hyponyms can appear in subcategorisation contexts such as : a9a12a11a40a13 a37 a17a19a110a5a26a27a22a25a33a93a126a127a115a25a28a46a26a52a35a32a116a81a18a42a24 a37 a41a36a43 , ( of the inspector ) , a9a12a11a40a13a40a37a5a17a19a110a7a18a44a30a45a111a14a22a74a110a114a26a65a115a42a26a50a129a137a28a6a26a52a126a127a138a40a113a5a24a42a37a7a39a25a13a40a15a42a41a36a43 ( to accomplish ) .</sentence>
				<definiendum id="0">assistance expense pension amount remuneration</definiendum>
				<definiendum id="1">administration authority commission council direction state government minister tribunal organ ) a8 presidente</definiendum>
				<definiendum id="2">a135 ( assembly chamber council direction state enterprise management institute region republic</definiendum>
				<definiens id="0">paragraph article code decree diploma disposition statute legislation law norm regulation</definiens>
			</definition>
			<definition id="2">
				<sentence>Coverage indicates the proportion of candidate dependencies that were actually corrected .</sentence>
				<definiendum id="0">Coverage</definiendum>
			</definition>
</paper>

		<paper id="1401">
			<definition id="0">
				<sentence>There remains the question of how “acceptability” is to be determined computationally .</sentence>
				<definiendum id="0">“acceptability”</definiendum>
				<definiens id="0">to be determined computationally</definiens>
			</definition>
			<definition id="1">
				<sentence>Similar to the approaches discussed above , Lauer extracts a training set of approximately 35,000 unambiguous noun-noun modifier-head compounds to estimate the degree of association between Roget categories .</sentence>
				<definiendum id="0">Lauer</definiendum>
			</definition>
			<definition id="2">
				<sentence>Latent Semantic Indexing ( LSI ) is a variant of the vector-space approach to information retrieval .</sentence>
				<definiendum id="0">Latent Semantic Indexing ( LSI )</definiendum>
				<definiens id="0">a variant of the vector-space approach to information retrieval</definiens>
			</definition>
			<definition id="3">
				<sentence>Selection and Information : A Class-Based Approach to Lexical Relationships .</sentence>
				<definiendum id="0">Selection</definiendum>
				<definiendum id="1">Information</definiendum>
			</definition>
</paper>

		<paper id="2008">
			<definition id="0">
				<sentence>The legends list the selected words with the relative frequency ( as a percentage ) of each word in the full corpus .</sentence>
				<definiendum id="0">relative frequency</definiendum>
				<definiens id="0">a percentage ) of each word in the full corpus</definiens>
			</definition>
</paper>

		<paper id="1304">
			<definition id="0">
				<sentence>1 A wordnet is a conceptually structured knowledge base of word senses .</sentence>
				<definiendum id="0">wordnet</definiendum>
				<definiens id="0">a conceptually structured knowledge base of word senses</definiens>
			</definition>
			<definition id="1">
				<sentence>EuroWordNet ( Vossen 1998 ) is a multilingual database with wordnets for several European languages ( Dutch , Italian , Spanish , German , French , Czech and Estonian ) .</sentence>
				<definiendum id="0">EuroWordNet</definiendum>
				<definiens id="0">a multilingual database with wordnets for several European languages ( Dutch , Italian , Spanish , German , French , Czech and Estonian )</definiens>
			</definition>
			<definition id="2">
				<sentence>Furthermore , linguistic information keyed to word senses that are linked to interlingual concepts ( as proposed in the EuroWordNet model ) , can be easily integrated in a multilingual Lexical Knowledge Base ( cf. section 2.3 ) Word Sense Disambiguation ( WSD ) is the task of assigning the appropriate meaning ( sense ) to a given word in a text or discourse .</sentence>
				<definiendum id="0">Word Sense Disambiguation</definiendum>
				<definiendum id="1">WSD )</definiendum>
				<definiens id="0">the task of assigning the appropriate meaning ( sense ) to a given word in a text or discourse</definiens>
			</definition>
			<definition id="3">
				<sentence>With current state-of-the-art accuracy in the range 60-70 % , WSD is one of the most important open problems in Natural Language Processing .</sentence>
				<definiendum id="0">WSD</definiendum>
			</definition>
			<definition id="4">
				<sentence>MEANING proposes an innovative bootstrapping process to deal with the interdependency between WSD and knowledge acquisition : them to very large corpora by coupling knowledge-based techniques on the existing EuroWordNet ( e.g. to populate it with domain labels , to induce automatically 3 Started in March 2002 , MEANING IST-200134460 `` Developing Multilingual Web-scale Language Technologies '' is a three years research project funded by the EC .</sentence>
				<definiendum id="0">MEANING</definiendum>
				<definiens id="0">proposes an innovative bootstrapping process to deal with the interdependency between WSD and knowledge acquisition</definiens>
			</definition>
</paper>

		<paper id="0704">
</paper>

		<paper id="1800">
			<definition id="0">
				<sentence>The First SIGHAN Workshop on Chinese Language Processing null Baobao Chang , Pernilla Danielsson , Wolfgang Teubert : Extraction of Translation Unit from Chinese-English Parallel Corpora null Lawrence Cheung , Tom Lai , Robert Luk , Oi Yee Kwong , King Kui Sin , Benjamin K. Tsou : Some Considerations on Guidelines for Bilingual Alignment and Terminology Extraction null Susan Converse : Developing Guidelines for the Annotation of Anaphors in the Chinese Treebank null Hongzhao He , Jianfeng Gao , Pilian He , Changning Huang : Finding the Better Indexing units for Chinese Information Retrieval null Chu-Ren Huang , Ru-Yng Chang : Categorical Ambiguity and Information Content : A Corpus-based Study of Chinese null Liang Huang , Yinan Peng , Huan Wang , Zhenyu Wu : PCFG Parsing for Restricted Classical Chinese Texts null Dong-il Kim , Zheng Cui , Jinji Li , Jong-Hyeok Lee : A Knowledge Based Approach to Identification of Serial Verb Construction in Chinese-to-Korean Machine Translation System null Chunyu Kit , Haihua Pan , Hongbiao Chen : Learning Case-based Knowledge for Disambiguating Chinese Word Segmentation : A Preliminary Study null Kui-Lam Kwok , Peter Deng : Corpus-Based Pinyin Name Resolution null Li Li , Chunfa Yuan , K.F. Wong , Wenjie Li : An Indexing Method Based on Sentences null Huihsin Tseng , Keh-Jiann Chen : Design of Chinese Morphological Analyzer null Zhongjian Wang , Kenji Araki , Koji Tochinai : A Word Segmentation Method with Dynamic Adapting to Text Using Inductive Learning null Wai Yi Peggy Wong , Chris Brew , Mary E. Beckman , Shui-duen Chan : Using the Segmentation Corpus to Define an Inventory of Concatenative Units for Cantonese Speech Synthesis null Jing Xiao , Jimin Liu , Tat-Seng Chua : Extracting Pronunciation-translated Names from Chinese Texts using Bootstrapping Approach null Nianwen Xue , Susan P. Converse : Combining Classifiers for Chinese Word Segmentation null Jiangsheng Yu : WSD and Closed Semantic Constraint null Kevin Zhang , Qun Liu , Hao Zhang , Xue-Qi Cheng : Automatic Recognition of Chinese Unknown Words Based on Roles Tagging null Yuqi Zhang , Qiang Zhou : Chinese Base-Phrases Chunking null Sheng Zhao , Jianhua Tao , Lianhong Cai : Learning Rules for Chinese Prosodic Phrase Prediction null Jingbo Zhu , Tianshun Yao : A Knowledge-based Approach to Text Classification</sentence>
				<definiendum id="0">Converse</definiendum>
				<definiendum id="1">Information Content</definiendum>
				<definiens id="0">Some Considerations on Guidelines for Bilingual Alignment and Terminology Extraction null Susan</definiens>
				<definiens id="1">PCFG Parsing for Restricted Classical Chinese Texts null Dong-il Kim</definiens>
				<definiens id="2">A Knowledge Based Approach to Identification of Serial Verb Construction in Chinese-to-Korean Machine Translation System null Chunyu Kit , Haihua Pan , Hongbiao Chen : Learning Case-based Knowledge for Disambiguating Chinese Word Segmentation : A Preliminary Study null Kui-Lam Kwok , Peter Deng : Corpus-Based Pinyin Name Resolution null Li Li</definiens>
				<definiens id="3">A Word Segmentation Method with Dynamic Adapting to Text Using Inductive Learning null Wai Yi Peggy Wong</definiens>
			</definition>
</paper>

		<paper id="0111">
			<definition id="0">
				<sentence>In brief , TAGLET is a context-free tree-rewriting formalism , defined by the usual complementation operation and the simplest imaginable modification operation .</sentence>
				<definiendum id="0">TAGLET</definiendum>
				<definiens id="0">a context-free tree-rewriting formalism , defined by the usual complementation operation and the simplest imaginable modification operation</definiens>
			</definition>
			<definition id="1">
				<sentence>From the outside , abstractly , a lexicalized grammar analyzes each sentence as a simple combination of atomic elements from a lexicon of options .</sentence>
				<definiendum id="0">lexicalized grammar</definiendum>
				<definiens id="0">a simple combination of atomic elements from a lexicon of options</definiens>
			</definition>
			<definition id="2">
				<sentence>For complementation , TAGLET adopts TAG’s substitution operation ; substitution replaces a leaf node in the head tree with the phrase structure tree associated with the complement .</sentence>
				<definiendum id="0">TAGLET</definiendum>
				<definiens id="0">adopts TAG’s substitution operation ; substitution replaces a leaf node in the head tree with the phrase structure tree associated with the complement</definiens>
			</definition>
			<definition id="3">
				<sentence>TAGLET requires the use of one of the familiar context-free filler-gap analyses , as perhaps that suggested by the trees in Figure 4 , and their composition : Q H H NP who S/NP NP Chris S/NP H H H NP VP/NP H H V thinks S/NP NP Sandy S/NP H H NP VP/NP V likes Figure 4 : TAGLET requires a gap-threading analysis of extraction ( or another context-free analysis ) .</sentence>
				<definiendum id="0">TAGLET</definiendum>
				<definiendum id="1">TAGLET</definiendum>
				<definiens id="0">requires the use of one of the familiar context-free filler-gap analyses , as perhaps that suggested by the trees in Figure 4 , and their composition : Q H H NP who S/NP NP Chris S/NP H H H NP VP/NP H H V thinks S/NP NP Sandy S/NP H H NP VP/NP V likes Figure 4</definiens>
			</definition>
			<definition id="4">
				<sentence>Treeinsertion grammar : A cubic-time parsable formalism that lexicalizes context-free grammar without changing the trees produced .</sentence>
				<definiendum id="0">Treeinsertion grammar</definiendum>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>The test data consists of a series of inputs x 1 , ... , x n , and we are trying to predict the corresponding results y 1 , ... , y n .</sentence>
				<definiendum id="0">test data</definiendum>
				<definiens id="0">consists of a series of inputs x 1 , ... , x n , and we are trying to predict the corresponding results y 1 , ... , y n</definiens>
			</definition>
</paper>

		<paper id="1211">
			<definition id="0">
				<sentence>The XML Corpus Encoding Standard ( XCES ) is a part of the Guideline developed by the Expert Advisory Group on Language Engineering Standards ( Ide , N. , Bonhomme , P. , Romary , L. 2000 ) .</sentence>
				<definiendum id="0">XML Corpus Encoding Standard ( XCES )</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Chinese texts used in this corpus are selected carefully under the condition of times , genre , and field .</sentence>
				<definiendum id="0">Chinese texts</definiendum>
				<definiens id="0">used in this corpus are selected carefully under the condition of times , genre , and field</definiens>
			</definition>
			<definition id="2">
				<sentence>The Hua Yu corpus ( 2 million Chinese characters ) is a POS tagged field-balance corpus .</sentence>
				<definiendum id="0">Hua Yu</definiendum>
				<definiens id="0">a POS tagged field-balance corpus</definiens>
			</definition>
</paper>

		<paper id="0715">
			<definition id="0">
				<sentence>In Figure 3 , the horizontal axis represents the TOEIC score and the vertical axis the system winning rate ( SWR ) given by following equation : Translation Result by Human Evaluation Sheet Japanese Test Text Typing Paired Comparison Accurate Text where N TOTAL denotes the total number of utterances in the test set , N TDMT represents the number of `` TDMT won '' utterances , and N EVEN , indicates the number of even ( non-winner ) utterances , i.e. , no difference between the results of the TDMT and humans .</sentence>
				<definiendum id="0">N TOTAL</definiendum>
				<definiendum id="1">N TDMT</definiendum>
				<definiendum id="2">i.e.</definiendum>
				<definiens id="0">the TOEIC score and the vertical axis the system winning rate ( SWR ) given by following equation : Translation Result by Human Evaluation Sheet Japanese Test Text Typing Paired Comparison Accurate Text where</definiens>
				<definiens id="1">the total number of utterances in the test set</definiens>
				<definiens id="2">the number of `` TDMT won '' utterances</definiens>
				<definiens id="3">indicates the number of even ( non-winner ) utterances ,</definiens>
			</definition>
			<definition id="1">
				<sentence>The SWR ranges from 0 to 1.0 , signifying the degree of capability of the MT system relative to that of the examinee .</sentence>
				<definiendum id="0">SWR</definiendum>
				<definiens id="0">ranges from 0 to 1.0 , signifying the degree of capability of the MT system relative to that of the examinee</definiens>
			</definition>
</paper>

		<paper id="0607">
			<definition id="0">
				<sentence>The hits of the rule is the number of forms that it actually derives correctly .</sentence>
				<definiendum id="0">hits of the rule</definiendum>
				<definiens id="0">the number of forms that it actually derives correctly</definiens>
			</definition>
</paper>

		<paper id="2018">
			<definition id="0">
				<sentence>Maximum entropy ( ME ) models , variously known as log-linear , Gibbs , exponential , and multinomial logit models , provide a general purpose machine learning technique for classification and prediction which has been successfully applied to fields as diverse as computer vision and econometrics .</sentence>
				<definiendum id="0">Maximum entropy ( ME ) models</definiendum>
				<definiens id="0">log-linear , Gibbs , exponential , and multinomial logit models , provide a general purpose machine learning technique for classification and prediction which has been successfully applied to fields as diverse as computer vision and econometrics</definiens>
			</definition>
			<definition id="1">
				<sentence>An extension of Iterative Proportional Fitting ( Deming and Stephan , 1940 ) , GIS scales the probability distribution q ( k ) by a factor proportional to the ratio of Ep [ f ] to Eq ( k ) [ f ] , with the restriction that ∑ j f j ( x ) = C for each event x in the training data ( a condition which can be easily satisfied by the addition of a correction feature ) .</sentence>
				<definiendum id="0">GIS</definiendum>
				<definiens id="0">a condition which can be easily satisfied by the addition of a correction feature )</definiens>
			</definition>
			<definition id="2">
				<sentence>To avoid this slowed convergence and the need for a correction feature , Della Pietra et al. ( 1997 ) propose an Improved Iterative Scaling ( IIS ) algorithm , whose update rule is the solution to the equation : Ep [ f ] = ∑ w ; x p ( w ) q ( k ) ( xjw ) f ( x ) exp ( M ( x ) δ ( k ) ) where M ( x ) is the sum of the feature values for an event x in the training data .</sentence>
				<definiendum id="0">M ( x )</definiendum>
			</definition>
			<definition id="3">
				<sentence>The gradient of a function is a vector which points in the direction in which the function’s value increases most rapidly .</sentence>
				<definiendum id="0">gradient of a function</definiendum>
				<definiens id="0">a vector which points in the direction in which the function’s value increases most rapidly</definiens>
			</definition>
			<definition id="4">
				<sentence>The usefulness of the curvature is made clear if we consider a second-order Taylor series approximation of L ( θ + δ ) : L ( θ + δ ) L ( θ ) + δT G ( θ ) + 12δT H ( θ ) δ ( 4 ) where H is Hessian matrix of the log-likelihood function , the d d matrix of its second partial derivatives with respect to θ .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">Hessian matrix of the log-likelihood function , the d d matrix of its second partial derivatives with respect to θ</definiens>
			</definition>
			<definition id="5">
				<sentence>PETSc offers data structures and routines for parallel and sequential storage , manipulation , and visualization of very large sparse matrices .</sentence>
				<definiendum id="0">PETSc</definiendum>
				<definiens id="0">offers data structures and routines for parallel and sequential storage , manipulation , and visualization of very large sparse matrices</definiens>
			</definition>
</paper>

		<paper id="1812">
			<definition id="0">
				<sentence>Here Inductive Learning is the procedure to extract recursively WS by multi steps ( Araki et al. , 1995 ) .</sentence>
				<definiendum id="0">Inductive Learning</definiendum>
			</definition>
			<definition id="1">
				<sentence>We deﬁne LEF as follows : LEF = FR+αCS − βES+ γLE FR+CS − ES+LE ( 1 ) Where : FR , CS , ES and LE are the frequency of CW or WS appearing in the text , the frequency of the correct segmentation , the frequency of the erroneous segmentation and the lengthofCWorWSrespectively .</sentence>
				<definiendum id="0">LEF</definiendum>
				<definiens id="0">LEF = FR+αCS − βES+ γLE FR+CS − ES+LE ( 1 ) Where : FR , CS , ES and LE are the frequency of CW or WS appearing in the text , the frequency of the correct segmentation , the frequency of the erroneous segmentation and the lengthofCWorWSrespectively</definiens>
			</definition>
			<definition id="2">
				<sentence>( 3 ) When LEF value of the set of possible segmentations is equal to each other , the correct segmentation candidate is decided by the word candidate that the value of ES is minimum , the value of CS is maximum , the value of FR is maximum , the value of LE is the longest or the location of segmentation is the leftmost in a sentence in turn .</sentence>
				<definiendum id="0">segmentation</definiendum>
				<definiens id="0">the leftmost in a sentence in turn</definiens>
			</definition>
			<definition id="3">
				<sentence>If the common character string consists of more thantwocharacters , weextractitasawordcandidate and call it common part and represent it by S1 ( Segment one ) .</sentence>
				<definiendum id="0">character string</definiendum>
				<definiens id="0">consists of more thantwocharacters , weextractitasawordcandidate and call it common part and represent it by S1 ( Segment one )</definiens>
			</definition>
			<definition id="4">
				<sentence>The economics consists of the text of economic system , economic policy and economic theory .</sentence>
				<definiendum id="0">economics</definiendum>
				<definiens id="0">consists of the text of economic system , economic policy and economic theory</definiens>
			</definition>
			<definition id="5">
				<sentence>The engineering consists of the text of electronics , communication engineering , machineengineeringandnuclearindustry .</sentence>
				<definiendum id="0">engineering</definiendum>
			</definition>
			<definition id="6">
				<sentence>The unsegmentation number is the number when all unsegmented strings are segmented correctly .</sentence>
				<definiendum id="0">unsegmentation number</definiendum>
				<definiens id="0">the number when all unsegmented strings are segmented correctly</definiens>
			</definition>
			<definition id="7">
				<sentence>Sometimes the correct segmentation rate is a little lower because the domain of text is a little diﬀerence , for example : the economics consists of the text of economic system , economic policy and economic theory and so on .</sentence>
				<definiendum id="0">segmentation rate</definiendum>
				<definiens id="0">consists of the text of economic system , economic policy and economic theory and so on</definiens>
			</definition>
			<definition id="8">
				<sentence>Precision [ % ] = CWN TWN ×100 ( 5 ) Recall [ % ] = CWN TUN ×100 ( 6 ) Where , CWNis thenumberofwords thatare predicted correctly .</sentence>
				<definiendum id="0">CWNis</definiendum>
				<definiens id="0">thenumberofwords thatare predicted correctly</definiens>
			</definition>
			<definition id="9">
				<sentence>TWN is the total number of words that are predicted .</sentence>
				<definiendum id="0">TWN</definiendum>
				<definiens id="0">the total number of words that are predicted</definiens>
			</definition>
			<definition id="10">
				<sentence>TUN is the total number of unknown words .</sentence>
				<definiendum id="0">TUN</definiendum>
			</definition>
</paper>

		<paper id="0703">
			<definition id="0">
				<sentence>The job of the analyzer is to produce a shallow semantic interlingua representation for spoken task-oriented utterances .</sentence>
				<definiendum id="0">job of the analyzer</definiendum>
				<definiens id="0">to produce a shallow semantic interlingua representation for spoken task-oriented utterances</definiens>
			</definition>
			<definition id="1">
				<sentence>An IF representation consists of four parts : a speaker tag , a speech act , an optional sequence of concepts , and an optional set of arguments .</sentence>
				<definiendum id="0">IF representation</definiendum>
			</definition>
			<definition id="2">
				<sentence>The SOUP parser is a stochastic , chart-based , topdown parser that is designed to provide real-time analysis of spoken language using context-free semantic grammars .</sentence>
				<definiendum id="0">SOUP parser</definiendum>
				<definiens id="0">a stochastic , chart-based , topdown parser that is designed to provide real-time analysis of spoken language using context-free semantic grammars</definiens>
			</definition>
			<definition id="3">
				<sentence>The pseudo-argument grammar contains toplevel nonterminals that do not correspond to interlingua concepts .</sentence>
				<definiendum id="0">pseudo-argument grammar</definiendum>
				<definiens id="0">contains toplevel nonterminals that do not correspond to interlingua concepts</definiens>
			</definition>
			<definition id="4">
				<sentence>Each training example for the speech act classifier consists of the speech act from the annotated IF and a vector of binary features with a positive value set for each argument or pseudo-argument label that occurs in the argument parse .</sentence>
				<definiendum id="0">speech act classifier</definiendum>
			</definition>
			<definition id="5">
				<sentence>Furthermore , the phrase-level argument grammars used in the analyzer contain fewer rules than a full semantic grammar .</sentence>
				<definiendum id="0">phrase-level argument grammars</definiendum>
				<definiens id="0">used in the analyzer contain fewer rules than a full semantic grammar</definiens>
			</definition>
</paper>

		<paper id="1100">
			<definition id="0">
				<sentence>Workshops SEMANET : Building and Using Semantic Networks null R. Basili , R. Catizone , L. Padro , M.T. Pazienza , G. Rigau , A. Setzer , N. Webb , F. Zanzotto : Knowledge-Based Multilingual Document Analysis null Echa Chang , Chu-Ren Huang , Sue-Jin Ker , Chang-Hua Yang : Induction of Classification from Lexicon Expansion : Assigning Domain Tags to WordNet Entries null Javier Farreres , Horacio Rodríguez , Karina Gibert : Semiautomatic Creation of Taxonomies null Pascale Fung : Semantic Networks : the Path to Profitability null Eduard Hovy : Building Semanticntological Knowledge by Text Mining null Chu-Ren Huang , I-Ju E. Tseng , Dylan B.S. Tsai : Translating Lexical Semantic Relations : The First Step towards Multilingual Wordnets null Kyoko Kanzaki , Qing Ma , Masaki Murata , Hitoshi Isahara : Classification of Adjectival and Non-adjectival Nouns Based on their Semantic Behavior by Using a Self-Organizing Semantic Map null Anna Korhonen : Assigning Verbs to Semantic Classes via WordNet null Bernardo Magnini , Matteo Negri , Roberto Prevete , Hristo Tanev : A WordNet-Based Approach to Named Entites Recognition null Mathieu Mangeot-Lerebours , Gilles Sérasset , Frédéric Andrès : Frameworks , Implementation and Open Problems for the Collaborative Building of a Multilingual Lexical Database null Gideon S. Mann : Fine-Grained Proper Noun Ontologies for Question Answering null Josef Meyer , Robert Dale : Using the WordNet Hierarchy for Associative Anaphora Resolution null Thierry Poibeau , Dominique Dutoit : Generating Extraction Patterns from a Large Semantic Network and an Untagged Corpus null Takuya Sakaguchi , Shun Ishizaki : A Japanese Semantic Network Built on a Pulsed Neural Network with Encoding Associative Concept Dictionaries null Kyoji Umemura : Selecting the Most Highly Correlated Pairs within a Large Vocabulary null Ping Wai Wong , Yongsheng Yang : A Maximum Entropy Approach to HowNet-Based Chinese Word Sense Disambiguation null Lixin Zhou , Qun Liu : A Character-net Based Chinese Text Segmentation Method null Michael Zock : Sorry , What Was Your Name Again , or How to Overcome the tip-of-the tongue Problem with the Help of a Computer ?</sentence>
				<definiendum id="0">Workshops SEMANET</definiendum>
				<definiendum id="1">Maximum Entropy</definiendum>
				<definiens id="0">The First Step towards Multilingual Wordnets null Kyoko Kanzaki</definiens>
				<definiens id="1">A WordNet-Based Approach to Named Entites Recognition null Mathieu Mangeot-Lerebours , Gilles Sérasset , Frédéric Andrès : Frameworks , Implementation and Open Problems for the Collaborative Building of a Multilingual Lexical Database null Gideon S. Mann : Fine-Grained Proper Noun Ontologies for Question Answering null Josef Meyer</definiens>
				<definiens id="2">A Japanese Semantic Network Built on a Pulsed Neural Network with Encoding Associative Concept Dictionaries null Kyoji Umemura</definiens>
			</definition>
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>The PHTM is a simple extension of the trigram model that incorporates the dependencies between headwords .</sentence>
				<definiendum id="0">PHTM</definiendum>
				<definiens id="0">a simple extension of the trigram model that incorporates the dependencies between headwords</definiens>
			</definition>
			<definition id="1">
				<sentence>The PHTM can then be formulated as : =Φ − ) ) ... ( | ( 11 ii wwwP ( 1 ) ) ) ... ( | ( ) ) ... ( | ( 1111 iiiii HwwwPwwHP −− Φ×Φ ) ) ... ( | ( ) ) ... ( | ( 1111 iiiii FwwwPwwFP −− Φ×Φ+ where Φ is a function that maps the word history ( w 1 …w i-1 ) onto equivalence classes .</sentence>
				<definiendum id="0">Φ</definiendum>
				<definiens id="0">a function that maps the word history ( w 1 …w i-1 ) onto equivalence classes</definiens>
			</definition>
			<definition id="2">
				<sentence>This estimate is an interpolated probability of three probabilities : P ( w i |h i-2 h i-1 H i ) and P ( w i |h i-1 h i-2 H i ) , which are the headword trigram probability with or without permutation , and P ( w i |w i-2 w i-1 H i ) , which is the probability of w i given that it is a headword , where h i-1 and h i-2 denote the two preceding headwords , and λ 1 , λ 2 ∈ [ 0,1 ] are the interpolation weights optimized on held-out data .</sentence>
				<definiendum id="0">h i-1</definiendum>
				<definiens id="0">the headword trigram probability with or without permutation</definiens>
				<definiens id="1">the interpolation weights optimized on held-out data</definiens>
			</definition>
			<definition id="3">
				<sentence>( 5 ) Now , by separating the estimates of probabilities of headwords and function words , Equation ( 1 ) can be rewritten as : P ( w i |Φ ( w 1 …w i-1 ) ) = ( 6 ) ) | ( ) ( | ( ( 122121 −−−− iiiiii hhwPwwHP λλ ) ) | ( ) 1 ( 212 −− −+ iii hhwPλ ) | ( ) 1 ( 121 −− −+ iii wwwPλ w i : headword ) | ( 12 −− iii wwwP          w i : function word There are three probabilities to be estimated in Equation ( 6 ) : word trigram probability P ( w i |w i-2 w i-1 ) , headword trigram probability P ( w i |h i-2 h i-1 ) and P ( w i |h i-1 h i-2 ) ( where w i is a headword ) , and category probability P ( H i |w i-2 w i-1 ) .</sentence>
				<definiendum id="0">headword trigram probability P ( w</definiendum>
				<definiens id="0">by separating the estimates of probabilities of headwords and function words</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , maximum entropy ( ME ) models ( Rosenfeld , 1994 ) provide a nice framework for incorporating arbitrary knowledge sources , but training and using ME models is computationally extremely expensive .</sentence>
				<definiendum id="0">maximum entropy ( ME ) models</definiendum>
				<definiens id="0">provide a nice framework for incorporating arbitrary knowledge sources , but training and using ME models is computationally extremely expensive</definiens>
			</definition>
			<definition id="5">
				<sentence>Performance on this task is generally measured in terms of the character error rate ( CER ) , which is the number of characters wrongly converted from the phonetic string divided by the number of characters in the correct transcript .</sentence>
				<definiendum id="0">CER</definiendum>
				<definiens id="0">the number of characters wrongly converted from the phonetic string divided by the number of characters in the correct transcript</definiens>
			</definition>
			<definition id="6">
				<sentence>The role of the language model is to select the word string ( in a combination of Kanji and Kana ) with the highest probability among the candidate strings that match the typed phonetic ( Kana ) string .</sentence>
				<definiendum id="0">role of the language model</definiendum>
				<definiens id="0">to select the word string ( in a combination of Kanji and Kana ) with the highest probability among the candidate strings that match the typed phonetic ( Kana ) string</definiens>
			</definition>
</paper>

		<paper id="1700">
			<definition id="0">
				<sentence>The 2nd Workshop on NLP and XML ( NLPXML-2002 ) null Guadalupe Aguado de Cea , Inmaculada Álvarez-de-Mon , Antonio Pareja-Lora Rosario Plaza-Arteche : RDF ( S ) /XML Linguistic Annotation of Semantic Web Pages null Guillermo Barrutieta , Joseba Abaitua , JosuKa Díaz : Cascading XSL Filters for Content Selection in Multilingual Document Generation null John Bateman , Renate Henschel , Judy Delin : A Brief Introduction to the GeM Annotation Schema for Complex Document Layout null Daniela Berger , David Reitter , Manfred Stede : XML/XSL in the Dictionary : The Case of Discourse Markers null Christian Boitet , Mathieu Mangeot , Gilles Sérasset : The PAPILLON Project : Cooperatively Building a Multilingual Lexical Data-base to Derive Open Source Dictionaries &amp; Lexicons null Claire Grover , Ewan Klein , Mirella Lapata , Alex Lascarides : XML-based NLP Tools for Analysing and Annotating Medical Language null Petter Karlström , Robin Cooper : Towards a Web-based Centre on Swedish Language Technology null Boris Katz , Jimmy Lin : Annotating the Semantic Web Using Natural Language null Eugene Koontz : XML in a Web-based Grammar Development Environment null Jan-Torsten Milde : The TASX-environment : An XML-based Toolset for the Creation of Multimodal Corpora null Chieko Nakabasami , Naoyuki Nomura : A Proposal for Screening Inconsistencies in Ontologies based on Query Languages using WSD null Kiril Simov , Milen Kouylekov , Alexander Simov : Cascaded Regular Grammars over XML Documents null Holger Stenzhorn : XtraGen A Natural Language Generation System Using XMLand Java-Technologies null Michael Walsh , Stephen Wilson , Julie Carson-Berndsen : XiSTS XML in Speech Technology Systems null Kuansan Wang : SALT : An XML Application for Web-based Multimodal Dialog Management</sentence>
				<definiendum id="0">PAPILLON Project</definiendum>
				<definiendum id="1">Milde</definiendum>
				<definiens id="0">A Brief Introduction to the GeM Annotation Schema for Complex Document Layout null Daniela Berger</definiens>
				<definiens id="1">XML-based NLP Tools for Analysing and Annotating Medical Language null Petter Karlström , Robin Cooper : Towards a Web-based Centre on Swedish Language Technology null Boris Katz , Jimmy Lin : Annotating the Semantic Web Using Natural Language null Eugene Koontz : XML in a Web-based Grammar Development Environment null Jan-Torsten</definiens>
				<definiens id="2">A Proposal for Screening Inconsistencies in Ontologies based on Query Languages using WSD null Kiril Simov , Milen Kouylekov , Alexander Simov : Cascaded Regular Grammars over XML Documents null Holger Stenzhorn : XtraGen A Natural Language Generation System</definiens>
			</definition>
</paper>

		<paper id="0718">
			<definition id="0">
				<sentence>Dictation machines in limited domain , simple automatic services over telephone , command and control in car , spoken document retrieval from broadcast news .</sentence>
				<definiendum id="0">Dictation machines</definiendum>
				<definiens id="0">simple automatic services over telephone , command and control in car , spoken document retrieval from broadcast news</definiens>
			</definition>
			<definition id="1">
				<sentence>Speech synthesis is an important component in a speech to speech translation system .</sentence>
				<definiendum id="0">Speech synthesis</definiendum>
				<definiens id="0">an important component in a speech to speech translation system</definiens>
			</definition>
</paper>

		<paper id="1502">
			<definition id="0">
				<sentence>h8 is equal modulo quantifiers ( QEQ ) to the handle of the study-rel ( h9 ) , and h7 is equal modulo quantifiers to the argument of the prpstn-rel ( h2 ) .</sentence>
				<definiendum id="0">h7</definiendum>
				<definiens id="0">equal modulo quantifiers</definiens>
			</definition>
</paper>

		<paper id="0201">
			<definition id="0">
				<sentence>Information is shared by passing KQML ( Finin et al. , 1997 ) messages through a central hub , the Facilitator , which supportsmessageloggingandsyntaxchecking as well as broadcast and selective broadcast between components .</sentence>
				<definiendum id="0">Information</definiendum>
				<definiens id="0">Finin et al. , 1997 ) messages through a central hub , the Facilitator , which supportsmessageloggingandsyntaxchecking as well as broadcast and selective broadcast between components</definiens>
			</definition>
</paper>

		<paper id="0220">
			<definition id="0">
				<sentence>SOUP : A parser for real-world spontaneous speechgrowing semantic grammars .</sentence>
				<definiendum id="0">SOUP</definiendum>
				<definiens id="0">A parser for real-world spontaneous speechgrowing semantic grammars</definiens>
			</definition>
</paper>

		<paper id="0502">
			<definition id="0">
				<sentence>In recent work , we have extended DATR , creating KATR , which is both a formal language and a computer program that generates desired forms by interpreting that language .</sentence>
				<definiendum id="0">KATR</definiendum>
				<definiens id="0">both a formal language and a computer program that generates desired forms by interpreting that language</definiens>
			</definition>
			<definition id="1">
				<sentence>A theory in KATR is a network of nodes ; the network of nodes constituting our verb morphology theory is represented in Figure 1 .</sentence>
				<definiendum id="0">theory in KATR</definiendum>
				<definiens id="0">a network of nodes</definiens>
			</definition>
			<definition id="2">
				<sentence>A query is a list of atoms , such as &lt; root &gt; or &lt; vowel2 perfect 3 sg masc &gt; ; in our theory , the atoms generally represent form categories ( such as root , binyanprefix , vowel1 , cons2 ) , morphosyntactic properties ( such as perfect , sg , fem ) or specific Hebrew characters .</sentence>
				<definiendum id="0">query</definiendum>
			</definition>
			<definition id="3">
				<sentence>The rule for Speak illustrates one of the strategies upon which we build KATR theories : A node representing a category ( here , a particular verb ) may provide information ( here , the letters of the verb’s root ) needed by more general nodes ( here , PIELand the nodes to which it , in turn , refers ) .</sentence>
				<definiendum id="0">PIELand the nodes</definiendum>
				<definiens id="0">one of the strategies upon which we build KATR theories : A node representing a category ( here , a particular verb ) may provide information ( here , the letters of the verb’s root ) needed by more general nodes</definiens>
			</definition>
			<definition id="4">
				<sentence>This rule exemplifies a second strategy of KATR theories : A node representing a specific category ( here , pi‘el verbs ) may override information ( here , the nature of the second consonant ) that is assumed by more general nodes ( here , VERB and the nodes to which it , in turn , refers ) .</sentence>
				<definiendum id="0">VERB</definiendum>
			</definition>
			<definition id="5">
				<sentence>An empty right-hand side in a rule means that the result of a matching query is the empty string .</sentence>
				<definiendum id="0">empty right-hand side</definiendum>
				<definiens id="0">the empty string</definiens>
			</definition>
			<definition id="6">
				<sentence>ROOT2 is one of a family of three nodes each of which isolates a particular consonant in a verb’s triliteral root .</sentence>
				<definiendum id="0">ROOT2</definiendum>
				<definiens id="0">one of a family of three nodes each of which isolates a particular consonant in a verb’s triliteral root</definiens>
			</definition>
			<definition id="7">
				<sentence>Lookup nodes ( such as the boxed nodes in Figure 1 ) do not participate in the hierarchical relationships defined by the network’s default rules .</sentence>
				<definiendum id="0">Lookup nodes</definiendum>
				<definiens id="0">such as the boxed nodes in Figure 1 ) do not participate in the hierarchical relationships defined by the network’s default rules</definiens>
			</definition>
			<definition id="8">
				<sentence>It exemplifies two more strategies of programming KATR theories : ( 1 ) Combining : It combines various pieces of morphology , namely those represented by the nodes VERBPREFIX , STEM , and VERBSUFFIX , each of which is referred to by VERB , and ( 2 ) Postprocessing : It presents the entire result of that combination to a postprocessing step represented by the node ACCENT .</sentence>
				<definiendum id="0">VERBSUFFIX</definiendum>
				<definiens id="0">combines various pieces of morphology , namely those represented by the nodes VERBPREFIX , STEM , and</definiens>
			</definition>
			<definition id="9">
				<sentence>KATR allows set notation as well , which allows us to deal with morphosyntactic properties in any order .</sentence>
				<definiendum id="0">KATR</definiendum>
				<definiens id="0">allows set notation as well , which allows us to deal with morphosyntactic properties in any order</definiens>
			</definition>
			<definition id="10">
				<sentence>KATR includes the ++syntax for explicitly enhancing the effective length of the preferred left-hand side ; we use this facility in the VERBSUFFIX node .</sentence>
				<definiendum id="0">KATR</definiendum>
				<definiens id="0">includes the ++syntax for explicitly enhancing the effective length of the preferred left-hand side</definiens>
			</definition>
			<definition id="11">
				<sentence>KATR allows greater control over which nodes are to be displayed under default queries .</sentence>
				<definiendum id="0">KATR</definiendum>
				<definiens id="0">allows greater control over which nodes are to be displayed under default queries</definiens>
			</definition>
			<definition id="12">
				<sentence>First , KATR identifies the rule within the node with the best matching left-hand side .</sentence>
				<definiendum id="0">KATR</definiendum>
				<definiens id="0">identifies the rule within the node with the best matching left-hand side</definiens>
			</definition>
</paper>

		<paper id="1708">
			<definition id="0">
				<sentence>7 Gregory Karvounarakis , Sofia Alexaki , Vassilis Christophides , Dimitris Plexousakis , Michel Scholl , RQL : a declarative query language for RDF , Proceedings of the 11th international conference on World Wide Web , May 07-11 , 2002 , Honolulu , Hawaii , USA 8 Boris Katz , Beth Levin , Exploiting lexical regularities in designing natural language systems , Proceedings of the 12th conference on Computational linguistics , p.316-323 , August 22-27 , 1988 , Budapest , Hungry 9 Boris Katz and Patrick H. Winston .</sentence>
				<definiendum id="0">RQL</definiendum>
				<definiens id="0">a declarative query language for RDF</definiens>
			</definition>
</paper>

		<paper id="0813">
			<definition id="0">
				<sentence>The automatic tagger estimates the conditional probability that a word has sense x given that it occurs in context y , where y is a conjunction of features .</sentence>
				<definiendum id="0">conditional probability</definiendum>
				<definiendum id="1">y</definiendum>
				<definiens id="0">a conjunction of features</definiens>
			</definition>
			<definition id="1">
				<sentence>In addition to the SENSEVAL-1 verbs , we ran the system on the SENSEVAL-1 data for shake , which contains both nouns and verbs .</sentence>
				<definiendum id="0">shake</definiendum>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>Spectral clustering performs a dimensionality reduction on the verb frame patterns , and provides a robustness and e ciency that standard clustering methods do not display in direct use .</sentence>
				<definiendum id="0">Spectral clustering</definiendum>
				<definiens id="0">performs a dimensionality reduction on the verb frame patterns</definiens>
			</definition>
			<definition id="1">
				<sentence>Frame Prob Frame Prob ns-dass 0.27945 npr 0.00261 ns-2 0.27358 nds-dass 0.00253 np 0.09951 ndi 0.00161 n 0.08811 nrs-dass 0.00029 na 0.08046 ndr 0.00029 ni 0.05015 nrs-w 0.00029 nd 0.03392 nir 0.00027 nad 0.02325 nds-w 0.00024 nds-2 0.01011 xd 0.00017 nai 0.00894 ns-ob 0.00014 ns-w 0.00859 nas-ob 0.00014 nas-w 0.00681 nds-ob 0.00000 nap 0.00594 nrs-ob 0.00000 nr 0.00455 x 0.00000 nar 0.00436 xa 0.00000 nrs-2 0.00391 xp 0.00000 ndp 0.00356 xr 0.00000 nas-dass 0.00342 xs-dass 0.00000 nas-2 0.00281 k 0.00000 Table 1 : Probability distribution for glauben Our previous work on the valency data applied k-Means ( a standard technique ) to the task of inducing semantic classes for German verbs ( Schulte im Walde and Brew , 2002 ) .</sentence>
				<definiendum id="0">Probability distribution</definiendum>
			</definition>
			<definition id="2">
				<sentence>Many of evidence performance Algorithm k Support Con dence Quality Precision Recall F-Measure Cos ( Ng ) 14 0.80 0.83 0.81 0.30 0.43 0.35 Cos ( Direct ) 14 0.78 0.74 0.21 0.44 0.28 Cos ( Ng ) ( 12 ) 0.79 0.81 0.26 0.40 0.32 Cos ( Direct ) 12 0.72 0.79 0.20 0.45 0.28 BCos ( Ng ) 14 0.86 0.86 0.86 0.21 0.23 0.22 BCos ( Direct ) 14 0.81 0.78 0.16 0.21 0.18 BCos ( Ng ) ( 17 ) 0.86 0.83 0.28 0.23 0.25 BCos ( Direct ) 17 0.87 0.80 0.13 0.11 0.12 Skew ( Ng ) 14 0.84 0.85 0.85 0.37 0.47 0.41 Skew ( Direct ) 14 0.84 0.78 0.22 0.34 0.27 Skew ( Ng ) ( 16 ) 0.86 0.88 0.49 0.47 0.48 Skew ( Direct ) 16 0.84 0.84 0.35 0.41 0.37 Table 3 : Performance of the clustering algorithms the eigenvectors appear to correspond to a partition of the data into a small number of tight clusters .</sentence>
				<definiendum id="0">BCos</definiendum>
				<definiens id="0">Performance of the clustering algorithms the eigenvectors appear to correspond to a partition of the data into a small number of tight clusters</definiens>
			</definition>
			<definition id="3">
				<sentence>Selection and Information : A Class-Based Approach to Lexical Relationships .</sentence>
				<definiendum id="0">Selection</definiendum>
				<definiendum id="1">Information</definiendum>
			</definition>
</paper>

		<paper id="0301">
			<definition id="0">
				<sentence>The process called named entity recognition , which finds entities that fill the information slots , e.g. , proteins , DNAs , RNAs , cells etc. , in the biomedical context , is an important building block in such biomedical IE systems .</sentence>
				<definiendum id="0">entity recognition</definiendum>
				<definiens id="0">finds entities that fill the information slots , e.g. , proteins , DNAs , RNAs , cells etc. , in the biomedical context</definiens>
			</definition>
			<definition id="1">
				<sentence>Conceptually , named entity recognition consists of two tasks : identification , which finds the region of a named entity in a text , and classification , which determines the semantic class of that named entity .</sentence>
				<definiendum id="0">identification</definiendum>
				<definiendum id="1">classification</definiendum>
				<definiens id="0">finds the region of a named entity in a text , and</definiens>
				<definiens id="1">determines the semantic class of that named entity</definiens>
			</definition>
			<definition id="2">
				<sentence>To overcome such a situation , the GENIA corpus ( Ohta et al. , 2002 ) has been developed , and at this time it is the largest biomedical annotated corpus available to public , containing 670 annotated abstracts of the MEDLINE database .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">the largest biomedical annotated corpus available to public , containing 670 annotated abstracts of the MEDLINE database</definiens>
			</definition>
			<definition id="3">
				<sentence>Support Vector Machines ( SVMs ) ( Vapnik , 1995 ) and Maximum Entropy ( ME ) method ( Berger et al. , 1996 ) are powerful learning methods that satisfy such requirements , and are applied successfully to other NLP tasks ( Kudo and Matsumoto , 2000 ; Nakagawa et al. , 2001 ; Ratnaparkhi , 1996 ) .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs )</definiendum>
				<definiens id="0">powerful learning methods that satisfy such requirements</definiens>
			</definition>
			<definition id="4">
				<sentence>The GENIA corpus is an annotated corpus of paper abstracts taken from the MEDLINE database .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">an annotated corpus of paper abstracts taken from the MEDLINE database</definiens>
			</definition>
			<definition id="5">
				<sentence>Margin is defined as the distance between the hyperplane and the training samples nearest to the hyperplane .</sentence>
				<definiendum id="0">Margin</definiendum>
				<definiens id="0">the distance between the hyperplane and the training samples nearest to the hyperplane</definiens>
			</definition>
			<definition id="6">
				<sentence>In the following explanation , K denotes the number of the target classes .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the number of the target classes</definiens>
			</definition>
			<definition id="7">
				<sentence>The BIO formulation produces one training sample per word , and the training with the GENIA corpus involves over 100,000 training samples as can be seen from Table 1 .</sentence>
				<definiendum id="0">BIO formulation</definiendum>
				<definiens id="0">produces one training sample per word , and the training with the GENIA corpus involves over 100,000 training samples</definiens>
			</definition>
			<definition id="8">
				<sentence>wk ; i = 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; : 1 if a word at k , Wk , is the ith word in the vocabularyV 0 otherwise ( word feature ) posk ; i = 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; : 1 if Wk is assigned the ith POS tag in the POS tag listPOS 0 otherwise ( part-of-speech feature ) prek ; i = 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; : 1 if Wk starts with the ith prefix in the prefix listP 0 otherwise ( prefix feature ) suf k ; i = 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; : 1 if Wk starts with the ith su x in the su x listS 0 otherwise ( su x feature ) subk ; i = 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; : 1 if Wk contains the ith substring in the substring listSB 0 otherwise ( substring feature ) pck ; i = 8 &gt; &lt; &gt; :1 if Wk ( k &lt; 0 ) was assigned ith class0 otherwise ( preceding class feature ) In the above definitions , k is a relative word position from the word to be classified .</sentence>
				<definiendum id="0">k</definiendum>
				<definiens id="0">a relative word position from the word to be classified</definiens>
			</definition>
			<definition id="9">
				<sentence>P ( cjx ) = 1Z ( x ) Y i fi ( c ; x ) i ; where Z ( x ) is a normalization constant , and fi ( c ; x ) is a feature function .</sentence>
				<definiendum id="0">Z ( x )</definiendum>
				<definiendum id="1">fi ( c ; x )</definiendum>
				<definiens id="0">a normalization constant , and</definiens>
			</definition>
			<definition id="10">
				<sentence>This leads to the same situation with the one-vsrest method , i.e. , if LO is the number of the samples belonging to the class “O” , then the most dominant part of the training takes time in K OS V M ( LO ) .</sentence>
				<definiendum id="0">LO</definiendum>
				<definiens id="0">the number of the samples belonging to the class “O” , then the most dominant part of the training takes time in K OS V M ( LO )</definiens>
			</definition>
			<definition id="11">
				<sentence>The word cache feature is defined as the disjunction of several word features as : wckfk1 ; ; kng ; i _k2kwk ; i We intend that the word cache feature captures the similarities of the patterns with a common key word such as follows .</sentence>
				<definiendum id="0">word cache feature</definiendum>
				<definiens id="0">the disjunction of several word features as : wckfk1 ; ; kng ; i _k2kwk ; i We intend that the word cache feature captures the similarities of the patterns with a common key word such as follows</definiens>
			</definition>
			<definition id="12">
				<sentence>hmmk ; i = 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; : 1 if the Viterbi state for Wk is the ith state in the HMM’s statesH 0 otherwise ( HMM feature ) In the experiments , we train an HMM using raw MEDLINE abstracts in the GENIA corpus , and show that the HMM state feature can improve the accuracy .</sentence>
				<definiendum id="0">show</definiendum>
				<definiens id="0">an HMM using raw MEDLINE abstracts in the GENIA corpus , and</definiens>
			</definition>
			<definition id="13">
				<sentence>0 5000 10000 15000 20000 25000 30000 35000 40000 45000 0 20000 40000 60000 80000 100000 120000 140000 Training Time ( seconds ) Number of training samples No splitSplit ( a ) Training size vs. time 0 5000 10000 15000 20000 25000 30000 35000 40000 45000 Term Accuracy ( F-Score ) Training Time ( seconds ) No splitSplit ( b ) Training time vs. accuracy Figure 1 : E ect of the class splitting technique .</sentence>
				<definiendum id="0">splitSplit</definiendum>
				<definiens id="0">E ect of the class splitting technique</definiens>
			</definition>
</paper>

		<paper id="0108">
			<definition id="0">
				<sentence>Unlike other NLP teaching tools which were designed specifically and only for this purpose , GATE is a system developed for and used actively in language engineering research .</sentence>
				<definiendum id="0">GATE</definiendum>
				<definiens id="0">a system developed for and used actively in language engineering research</definiens>
			</definition>
			<definition id="1">
				<sentence>Inter-module consistency is achieved by using the annotations model to hold language data , while extensibility and modularity are the very reason why GATE has been successfully used in many research projects ( Maynard et al. , 2000 ) .</sentence>
				<definiendum id="0">GATE</definiendum>
				<definiens id="0">the annotations model to hold language data</definiens>
			</definition>
			<definition id="2">
				<sentence>GATE uses a single unified model of annotation a modified form of the TIPSTER format ( Grishman , 1997 ) which has been made largely compatible with the Atlas format ( Bird and Liberman , 1999 ) .</sentence>
				<definiendum id="0">GATE</definiendum>
				<definiens id="0">uses a single unified model of annotation a modified form of the TIPSTER format</definiens>
			</definition>
			<definition id="3">
				<sentence>JAPE is a version of CPSL ( Common Pattern Specification Language ) ( Appelt , 1996 ) and is used to describe patterns to match and annotations to be created as a result ( for further details see ( Cunningham et al. , 2002b ) ) .</sentence>
				<definiendum id="0">JAPE</definiendum>
				<definiens id="0">a version of CPSL ( Common Pattern Specification Language ) ( Appelt , 1996 ) and is used to describe patterns to match and annotations to be created as a result</definiens>
			</definition>
			<definition id="4">
				<sentence>NamedEntity = { kind = `` company '' , rule = `` Company1 '' } The rule matches a pattern consisting of any kind of word , which starts with an upper-cased letter ( recognised by the tokeniser ) , followed by one of the entries in the gazetteer list for company designators ( words which typically indicate companies , such as ‘Ltd.’ and ‘GmBH’ ) .</sentence>
				<definiendum id="0">word</definiendum>
				<definiens id="0">starts with an upper-cased letter ( recognised by the tokeniser</definiens>
			</definition>
			<definition id="5">
				<sentence>The grammars ( which are sets of rules ) do not need to be compiled by the students , because they are automatically analysed and executed by the JAPE Transducer module , which is a finiteFigure 4 : The visual evaluation tool state transducer over the annotations in the document .</sentence>
				<definiendum id="0">JAPE Transducer module</definiendum>
				<definiens id="0">sets of rules ) do not need to be compiled by the students</definiens>
			</definition>
			<definition id="6">
				<sentence>The sentence splitter is a cascade of finitestate transducers which segments the text into sentences .</sentence>
				<definiendum id="0">sentence splitter</definiendum>
				<definiens id="0">a cascade of finitestate transducers which segments the text into sentences</definiens>
			</definition>
			<definition id="7">
				<sentence>The gazetteer consists of lists such as cities , organisations , days of the week , etc .</sentence>
				<definiendum id="0">gazetteer</definiendum>
			</definition>
			<definition id="8">
				<sentence>By default , GATE is supplied with an NE transducer which performs named entity recognition for English and a VP Chunker which shows how chunking can be done using JAPE .</sentence>
				<definiendum id="0">GATE</definiendum>
				<definiendum id="1">VP Chunker</definiendum>
				<definiens id="0">supplied with an NE transducer which performs named entity recognition for English and a</definiens>
			</definition>
</paper>

		<paper id="0104">
			<definition id="0">
				<sentence>Students build a quite sophisticated text-based natural language query system .</sentence>
				<definiendum id="0">Students</definiendum>
				<definiens id="0">build a quite sophisticated text-based natural language query system</definiens>
			</definition>
</paper>

		<paper id="1113">
			<definition id="0">
				<sentence>Information Extraction ( IE ) is a technology dedicated to the extraction of structured information from texts .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
				<definiens id="0">a technology dedicated to the extraction of structured information from texts</definiens>
			</definition>
			<definition id="1">
				<sentence>More recently , the SrV system ( Freitag , 1998 ) and the Pinocchio system ( Ciravegna , 2001 ) use a combination of relational and basic statistical methods inspired from Naïve Bayes for IE tasks .</sentence>
				<definiendum id="0">SrV system</definiendum>
				<definiendum id="1">Pinocchio system</definiendum>
			</definition>
			<definition id="2">
				<sentence>An overview of the results is given below ( P is for precision , R for recall ; P &amp; R is the combined ratio of P and R ) : Slot 1 Slot 2 P : 100 R : 90 P : 100 R : 91.6 Human annotators P &amp; R : 94.7 P &amp; R : 95.6 P : 79.6 R : 62.6 P : 93.4 R : 73 INTEX + manual resources P &amp; R : 70 P &amp; R : 81.9 P : 65.8 R : 58.7 P : 77 R : 65.3 INTEX + SemTex P &amp; R : 62 P &amp; R : 70.7 The system running with automatically defined resources is about 10 % less efficient than the one with manually defined resources .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the combined ratio of P and R )</definiens>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>Automatic speech recognition , which decodes human voice to generate transcriptions , has of late become a practical technology .</sentence>
				<definiendum id="0">Automatic speech recognition</definiendum>
				<definiens id="0">decodes human voice to generate transcriptions , has of late become a practical technology</definiens>
			</definition>
			<definition id="1">
				<sentence>Initiated partially by TREC-6 , various methods have been proposed for “spoken document retrieval ( SDR ) , ” in which written queries are used to search speech archives for relevant information ( Garofolo et al. , 1997 ) .</sentence>
				<definiendum id="0">SDR</definiendum>
			</definition>
			<definition id="2">
				<sentence>The speech recognition module generates word sequence a2 , given phone sequence a3 .</sentence>
				<definiendum id="0">speech recognition module</definiendum>
			</definition>
			<definition id="3">
				<sentence>In other words , OOV words were modeled as sequences of syllables .</sentence>
				<definiendum id="0">OOV</definiendum>
				<definiens id="0">words were modeled as sequences of syllables</definiens>
			</definition>
</paper>

		<paper id="0706">
			<definition id="0">
				<sentence>( 1 ) Conceptually , the translation can be viewed as a two-step process ( Ney , 1999 ; Ney et al. , 2000 ) : x → s → t , where s is a sequence of source-language words which would match the observed acoustic sequence x and t is a target-language word sequence associated with s. Consequently , Pr ( t|x ) = summationdisplay s Pr ( t , s|x ) , ( 2 ) and , with the natural assumption that Pr ( x|s , t ) does not depend on the target sentence t , ˆt = argmax t parenleftBiggsummationdisplay s Pr ( s , t ) · Pr ( x|s ) parenrightBigg .</sentence>
				<definiendum id="0">Conceptually</definiendum>
				<definiendum id="1">s</definiendum>
				<definiendum id="2">t</definiendum>
				<definiens id="0">a two-step process ( Ney , 1999 ; Ney et al. , 2000 ) : x → s → t</definiens>
				<definiens id="1">a sequence of source-language words which would match the observed acoustic sequence x and</definiens>
			</definition>
			<definition id="1">
				<sentence>3 is transformed in the optimization problem : ˆt = argmax t parenleftBiggsummationdisplay s PrT ( s , t ) · PrM ( x|s ) parenrightBigg , ( 4 ) where PrT ( s , t ) is the probability supplied by the SFST and PrM ( x|s ) is the density value supplied by the corresponding HMMs associated to s for the acoustic sequence x. A SFST , T , is a tuple 〈Q , Σ , ∆ , R , q0 , F , P〉 , where Q is a finite set of states ; q0 is the initial state ; Σ and ∆ are finite sets of input symbols ( source words ) and output symbols ( target words ) , respectively ( Σ∩∆ = ∅ ) ; R is a set of transitions of the form ( q , a , ω , qprime ) for q , qprime ∈ Q , a ∈ Σ , ω ∈ ∆star and1 P : R → IR+ ( transition probabilities ) and F : Q → IR+ ( finalstate probabilities ) are functions such that ∀q ∈ Q : F ( q ) + summationdisplay ∀ ( a , ω , qprime ) ∈ Σ×∆star ×Q : ( q , a , ω , qprime ) ∈ R P ( q , a , ω , qprime ) = 1 .</sentence>
				<definiendum id="0">SFST , T ,</definiendum>
				<definiendum id="1">R</definiendum>
				<definiendum id="2">Q</definiendum>
				<definiendum id="3">q0</definiendum>
				<definiendum id="4">R</definiendum>
				<definiens id="0">ˆt = argmax t parenleftBiggsummationdisplay s PrT ( s , t ) · PrM ( x|s ) parenrightBigg , ( 4 ) where PrT ( s , t ) is the probability supplied by the SFST and PrM ( x|s ) is the density value supplied by the corresponding HMMs associated to s for the acoustic sequence x. A</definiens>
				<definiens id="1">a tuple 〈Q , Σ , ∆ ,</definiens>
				<definiens id="2">a finite set of states</definiens>
				<definiens id="3">the initial state ; Σ and ∆ are finite sets of input symbols ( source words ) and output symbols ( target words ) , respectively ( Σ∩∆ = ∅ ) ;</definiens>
				<definiens id="4">a set of transitions of the form ( q , a , ω , qprime ) for q , qprime ∈ Q , a ∈ Σ , ω ∈ ∆star and1 P : R → IR+ ( transition probabilities</definiens>
			</definition>
			<definition id="2">
				<sentence>For a pair ( s , t ) ∈ Σstar × ∆star , a translation form , φ , is a sequence of transitions in a SFST T : φ : ( q0 , s1 , ˜t1 , q1 ) , ( q1 , s2 , ˜t2 , q2 ) , ... , ( qI−1 , sI , ˜tI , qI ) , where ˜tj denotes a substring of target words ( the empty string for ˜tj is also possible ) , such that ˜t1 ˜t2 ... ˜tI = t and I is the length of the source sentence s. The probability of φ is PrT ( φ ) = F ( qI ) · Iproductdisplay i=0 P ( qi−1 , si , ˜ti , qi ) .</sentence>
				<definiendum id="0">˜tj</definiendum>
				<definiens id="0">a sequence of transitions in a SFST T : φ : ( q0 , s1 , ˜t1</definiens>
				<definiens id="1">a substring of target words ( the empty string for ˜tj is also possible</definiens>
				<definiens id="2">the length of the source sentence s. The probability of φ is PrT ( φ ) = F ( qI ) · Iproductdisplay i=0 P ( qi−1 , si , ˜ti , qi )</definiens>
			</definition>
			<definition id="3">
				<sentence>( 5 ) Finally , the probability of the pair ( s , t ) is PrT ( s , t ) = summationdisplay φ∈d ( s , t ) PrT ( φ ) ( 6 ) ≈ max φ∈d ( s , t ) PrT ( φ ) , ( 7 ) where d ( s , t ) is the set of all translation forms for the pair ( s , t ) .</sentence>
				<definiendum id="0">PrT</definiendum>
				<definiens id="0">the set of all translation forms for the pair ( s , t )</definiens>
			</definition>
			<definition id="4">
				<sentence>λ denotes the empty string .</sentence>
				<definiendum id="0">λ</definiendum>
				<definiens id="0">the empty string</definiens>
			</definition>
</paper>

		<paper id="0815">
</paper>

		<paper id="1501">
			<definition id="0">
				<sentence>The system consists of i. ) CHUNK-IT ( Federici et al. 1998a ) , a battery of finite state automata for non-recursive text segmentation ( chunking ) , and ii . )</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">consists of i. ) CHUNK-IT ( Federici et al. 1998a ) , a battery of finite state automata for non-recursive text segmentation ( chunking ) , and ii</definiens>
			</definition>
			<definition id="1">
				<sentence>IDEAL ( Lenci et al. 2001 ) , a dependency-based analyser of the full range of intra-sentential functional relations ( e.g. subject , object , modifier , complement , etc. ) .</sentence>
				<definiendum id="0">IDEAL</definiendum>
				<definiens id="0">a dependency-based analyser of the full range of intra-sentential functional relations ( e.g. subject , object , modifier , complement , etc. )</definiens>
			</definition>
			<definition id="2">
				<sentence>IDEAL includes in turn two main components : ( i. ) a Core Dependency Grammar of Italian ; ( ii . )</sentence>
				<definiendum id="0">IDEAL</definiendum>
				<definiens id="0">includes in turn two main components : ( i. ) a Core Dependency Grammar of Italian</definiens>
			</definition>
			<definition id="3">
				<sentence>IDEAL adopts a slightly simplified version of the FAME annotation scheme ( Lenci et al. 2000 ) , where functional relations are headbased and hierarchically organised to make provision for underspecified representations of highly ambiguous functional analyses .</sentence>
				<definiendum id="0">IDEAL</definiendum>
				<definiens id="0">adopts a slightly simplified version of the FAME annotation scheme ( Lenci et al. 2000 ) , where functional relations are headbased and hierarchically organised to make provision for underspecified representations of highly ambiguous functional analyses</definiens>
			</definition>
			<definition id="4">
				<sentence>The test corpus contains a selection of sentences extracted from the balanced partition of the Italian Syntactic Semantic Treebank ( ISST , Montemagni et al. 2000 ) , including articles from 1 Adjectival and adverbial modification ; negation ; ( nonextraposed ) sentence arguments ( subject , object , indirect object ) ; causative and modal constructions ; predicative constructions ; PP complementation and modification ; embedded finite and non-finite clauses ; control of infinitival subjects ; relative clauses ( main cases ) ; participial constructions ; adjectival coordination ; noun-noun coordination ( main cases ) ; PP-PP coordination ( main cases ) ; cliticization .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiendum id="1">PP complementation</definiendum>
				<definiendum id="2">noun-noun coordination</definiendum>
				<definiendum id="3">PP-PP coordination</definiendum>
				<definiens id="0">contains a selection of sentences extracted from the balanced partition of the Italian Syntactic Semantic Treebank ( ISST</definiens>
				<definiens id="1">nonextraposed ) sentence arguments ( subject , object , indirect object ) ; causative and modal constructions</definiens>
			</definition>
			<definition id="5">
				<sentence>TC consists of 23,919 word tokens , corresponding to 721 sentences ( with a mean sentence length of 33.18 words , including punctuation tokens ) .</sentence>
				<definiendum id="0">TC</definiendum>
			</definition>
			<definition id="6">
				<sentence>PC_V is the subset with a V ( erbal ) head and PC_N the subset with a N ( ominal ) head .</sentence>
				<definiendum id="0">PC_V</definiendum>
			</definition>
			<definition id="7">
				<sentence>Precision is defined as the ratio of correctly identified dependency relations over all relations found by the parser ( prec = correctly identified relations / total number of identified relations ) ; recall refers to the ratio of correctly identified dependency relations over all relations in ISST ( recall = correctly identified relations / ISST relations ) .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">the ratio of correctly identified dependency relations over all relations found by the parser ( prec = correctly identified relations / total number of identified relations ) ;</definiens>
			</definition>
</paper>

		<paper id="1207">
			<definition id="0">
				<sentence>In section 4 , then , provides Thai Language Computational Modeling as a basis for creating cost-effective solutions to those practical problems .</sentence>
				<definiendum id="0">Modeling</definiendum>
				<definiens id="0">provides Thai Language Computational</definiens>
			</definition>
			<definition id="1">
				<sentence>Since Thai has no inflection and no word delimiters , Thai morphological processing is mainly to recognize word boundaries instead of recognizing a lexical form from a surface form as in English .</sentence>
				<definiendum id="0">Thai morphological</definiendum>
				<definiens id="0">no inflection and no word delimiters</definiens>
			</definition>
			<definition id="2">
				<sentence>“การ ( ka : n ) ” state or “ผู ( p h u : ) ” signal ) ” are used in verb or verb phrase and sometimes from noun ( Nominalization ) .</sentence>
				<definiendum id="0">“การ ( ka</definiendum>
				<definiens id="0">p h u : ) ” signal ) ” are used in verb or verb phrase and sometimes from noun</definiens>
			</definition>
</paper>

		<paper id="1600">
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>A multiple-sequence alignment algorithm takes as input n stringsandoutputsan n-rowcorrespondence table , or multiple-sequence alignment ( MSA ) .</sentence>
				<definiendum id="0">multiple-sequence alignment</definiendum>
				<definiendum id="1">MSA</definiendum>
				<definiens id="0">input n stringsandoutputsan n-rowcorrespondence table , or multiple-sequence alignment</definiens>
			</definition>
			<definition id="1">
				<sentence>† In the template induction phase ( Section 3.3 ) , we convert the aligned slotted lattices into templates | sequences of words and argument positions | by tracing slotted lattice paths .</sentence>
				<definiendum id="0">template induction phase</definiendum>
				<definiens id="0">the aligned slotted lattices into templates | sequences of words and argument positions | by tracing slotted lattice paths</definiens>
			</definition>
			<definition id="2">
				<sentence>We then set sim ( x ; y ) = 8 &gt; &lt; &gt; : 1 x = y , x 2§ ; 0:5 x … y ; ¡0:01 exactly one of x ; y is ; ¡0:5 otherwise ( mismatch ) where § is the vocabulary and x … y denotes that T lists x and y asparaphrases.2 Figure2showsthelattice computed for the verbalizations of the instance 2These values were hand-tuned on a held-out development corpus , described later .</sentence>
				<definiendum id="0">y</definiendum>
				<definiendum id="1">§</definiendum>
				<definiens id="0">the vocabulary and x … y denotes that T lists x and y asparaphrases.2 Figure2showsthelattice computed for the verbalizations of the instance 2These values were hand-tuned on a held-out development corpus , described later</definiens>
			</definition>
</paper>

		<paper id="2000">
			<definition id="0">
				<sentence>The 6th Conference on Natural Language Learning 2002 ( CoNLL-2002 ) null Timothy Baldwin , Aline : Extracting the Unextractable : A Case Study on Verb-particles null William J. Black , Argyrios Vasilakopoulos : Language Independent Named Entity Classification by modified Transformation-based Learning and by Decision Tree Induction null John D. Burger , John C. Henderson , William T. Morgan : Statistical Named Entity Recognizer Adaptation null Xavier Carreras , Lluís Màrquez , Lluís Padró : Named Entity Extraction using AdaBoost null Liviu Ciortuz : Learning Attribute Values in Typed-unification Grammars : On Generalised Rule Reduction null Silviu Cucerzan , David Yarowsky : Bootstrapping a Multilingual Part-of-speech Tagger in One Person-day null Silviu Cucerzan , David Yarowsky : Language Independent NER using a Unified Model of Internal and Contextual Evidence null James R. Curran , Miles Osborne : A Very Very Large Corpus Does n't Always Yield Reliable Estimates null Ido Dagan , Zvika Marx , Eli Shamir : Cross-dataset Clustering : Revealing Corresponding Themes across Multiple Corpora null Radu Florian : Named Entity Recognition as a House of Cards : Classifier Stacking null Cyril Goutte , Hervé Déjean , Eric Gaussier , Nicola Cancedda , Jean-Michel Renders : Combining Labelled and Unlabelled Data : A Case Study on Fisher Kernels and Transductive Inference for Biological Entity Recognition null Peter Juel Henrichsen : GraSp : Grammar Learning from Unlabelled Speech Corpora null Martin Jansche : Named Entity Extraction with Conditional Markov Models and Classifiers null Anna Korhonen , Yuval Krymolowski : On the Robustness of Entropy-Based Similarity Measures in Evaluation of Subcategorization Acquisition Systems null Yuval Krymolowski : Distinguishing Easy and Hard Instances null Taku Kudo , Yuji Matsumoto : Japanese Dependency Analysis using Cascaded Chunking null Wei-Hao Lin , Hsin-Hsi Chen : Backward Machine Transliteration by Learning Phonetic Similarity null Robert Malouf : A Comparison of Algorithms for Maximum Entropy Parameter Estimation null Robert Malouf : Markov Models for Language-independent Named Entity Recognition null Paul McNamee , James Mayfield : Entity Extraction without Language-specific Resources null Rada Mihalcea , Vivi Nastase : Letter Level Learning for Language Independent Diacritics Restoration null Jon Patrick , Casey Whitelaw , Robert Munro : SLINERC : The Sydney Language-independent Named Entity Recogniser and Classifier null Uwe Quasthoff , Christian Biemann , Christian Wolff : Named Entity Learning and Verification : Expectation Maximization in Large Corpora null Erik F. Tjong Kim Sang : Introduction to the CoNLL-2002 Shared Task : LanguageIndependent Named Entity Recognition null Erik F. Tjong Kim Sang : Memory-Based Named Entity Recognition null Charles Schafer , David Yarowsky : Inducing Translation Lexicons via Diverse Similarity Measures and Bridge Languages null S. H. Srinivasan : Features for Unsupervised Document Classification null Hiroya Takamura , Yuji Matsumoto : Two-dimensional Clustering for Text Categorization null Koichi Takeuchi , Nigel Collier : Use of Support Vector Machines in Extended Named Entity Recognition null Kristina Toutanova , Christopher D. Manning : Feature Selection for a Rich HPSG Grammar Using Decision Trees null Koji Tsukamoto , Yutaka Mitsuishi , Manabu Sassano : Learning with Multiple Stacking for Named Entity Recognition null Jorn Veenstra , Frank Henrik Müller , Tylman Ule : Topological Field Chunking for German null Aline Villavicencio : Learning to Distinguish PP Arguments from Adjuncts null Janyce Wiebe , Theresa Wilson : Learning to Disambiguate Potentially Subjective Expressions null Dekai Wu , Grace Ngai , Marine Carpuat , Jeppe Larsen , Yongsheng Yang : Boosting for Named Entity Recognition</sentence>
				<definiendum id="0">Osborne</definiendum>
				<definiendum id="1">Very Very Large Corpus Does</definiendum>
				<definiens id="0">Extracting the Unextractable : A Case Study on Verb-particles null William J. Black , Argyrios Vasilakopoulos : Language Independent Named Entity Classification by modified Transformation-based Learning and by Decision Tree Induction null John D. Burger</definiens>
				<definiens id="1">Named Entity Extraction using AdaBoost null Liviu Ciortuz : Learning Attribute Values in Typed-unification Grammars : On Generalised Rule Reduction null Silviu Cucerzan</definiens>
				<definiens id="2">Language Independent NER using a Unified Model of Internal and Contextual Evidence null James R. Curran , Miles</definiens>
				<definiens id="3">Cross-dataset Clustering : Revealing Corresponding Themes across Multiple Corpora null Radu Florian : Named Entity Recognition as a House of Cards : Classifier Stacking null Cyril Goutte , Hervé Déjean , Eric Gaussier , Nicola Cancedda , Jean-Michel Renders : Combining Labelled and Unlabelled Data : A Case Study on Fisher Kernels and Transductive Inference for Biological Entity Recognition null Peter Juel Henrichsen : GraSp : Grammar Learning from Unlabelled Speech Corpora null Martin Jansche : Named Entity Extraction with Conditional Markov Models and Classifiers null Anna Korhonen , Yuval Krymolowski : On the Robustness of Entropy-Based Similarity Measures in Evaluation of Subcategorization Acquisition Systems null Yuval Krymolowski : Distinguishing Easy and Hard Instances null Taku Kudo , Yuji Matsumoto : Japanese Dependency Analysis using Cascaded Chunking null Wei-Hao Lin , Hsin-Hsi Chen : Backward Machine Transliteration by Learning Phonetic Similarity null Robert Malouf : A Comparison of Algorithms for Maximum Entropy Parameter Estimation null Robert Malouf : Markov Models for Language-independent Named Entity Recognition null Paul McNamee , James Mayfield : Entity Extraction without Language-specific Resources null Rada Mihalcea , Vivi Nastase : Letter Level Learning for Language Independent Diacritics Restoration null Jon Patrick</definiens>
				<definiens id="4">The Sydney Language-independent Named Entity Recogniser and Classifier null Uwe Quasthoff , Christian Biemann , Christian Wolff : Named Entity Learning and Verification : Expectation Maximization in Large Corpora null Erik F. Tjong Kim Sang : Introduction to the CoNLL-2002 Shared Task : LanguageIndependent Named Entity Recognition null Erik F. Tjong Kim Sang : Memory-Based Named Entity Recognition null Charles Schafer , David Yarowsky : Inducing Translation Lexicons via Diverse Similarity Measures and Bridge Languages null S. H. Srinivasan : Features for Unsupervised Document Classification null Hiroya Takamura , Yuji Matsumoto : Two-dimensional Clustering for Text Categorization null Koichi Takeuchi , Nigel Collier : Use of Support Vector Machines in Extended Named Entity Recognition null Kristina Toutanova , Christopher D. Manning : Feature Selection for a Rich HPSG Grammar Using Decision Trees null Koji Tsukamoto</definiens>
				<definiens id="5">Topological Field Chunking for German null Aline Villavicencio : Learning to Distinguish PP Arguments from Adjuncts null Janyce Wiebe , Theresa Wilson : Learning to Disambiguate Potentially Subjective Expressions null Dekai Wu</definiens>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>Word graphs : An efficient interface between continous speech recognition and language u</sentence>
				<definiendum id="0">Word graphs</definiendum>
			</definition>
</paper>

		<paper id="0227">
			<definition id="0">
				<sentence>The MML principle is a model-selection technique which applies information-theoretic criteria to trade data fit against model complexity ( a glossary of model-selection techniques appears in http : //www-white.media.mit.edu/ a0 tpminka/statlearn/glossary ) .</sentence>
				<definiendum id="0">MML principle</definiendum>
			</definition>
			<definition id="1">
				<sentence>MML has been used in a variety of applications , e.g. , in NL it was used for lexical selection in speech understanding ( Thomas et al. , 1997 ) .</sentence>
				<definiendum id="0">MML</definiendum>
				<definiens id="0">used in a variety of applications</definiens>
			</definition>
			<definition id="2">
				<sentence>The MML criterion is derived from Bayes Theorem : Pra1a3a2a5a4a7a6a9a8a11a10 Pra1a3a6a9a8a13a12 Pra1a3a2a9a14a6a15a8 , wherea2 is the data and a6 is a hypothesis which explains the data .</sentence>
				<definiendum id="0">wherea2</definiendum>
				<definiendum id="1">a6</definiendum>
			</definition>
			<definition id="3">
				<sentence>An Implication Graph is a graphical representation of an argument , which represents a basic “understanding” of the argument .</sentence>
				<definiendum id="0">Implication Graph</definiendum>
			</definition>
			<definition id="4">
				<sentence>a38a40a39 Usr represents an understanding of the user’s argument .</sentence>
				<definiendum id="0">a38a40a39 Usr</definiendum>
			</definition>
			<definition id="5">
				<sentence>a38a40a39 SysInt represents an understanding of a candidate interpretation .</sentence>
				<definiendum id="0">a38a40a39 SysInt</definiendum>
				<definiens id="0">an understanding of a candidate interpretation</definiens>
			</definition>
			<definition id="6">
				<sentence>It is directly obtained from SysInt , but it differs from SysInt in that all its arcs point towards a goal node and head-to-head evidence nodes are represented as antecedents of an implication , while SysInt is a general Bayesian subnet .</sentence>
				<definiendum id="0">SysInt</definiendum>
				<definiens id="0">a general Bayesian subnet</definiens>
			</definition>
			<definition id="7">
				<sentence>The interpretation process obtains a38a40a39 Usr from the user’s input , and SysInt from a38a27a39 Usr ( left-hand side of Figure 1 ) .</sentence>
				<definiendum id="0">interpretation process</definiendum>
				<definiens id="0">obtains a38a40a39 Usr from the user’s input</definiens>
			</definition>
			<definition id="8">
				<sentence>UArg : a5a7a6 Usr : Mr Body and Mr Green argued a8 Mr Green had a motive to kill Mr Body G argued with B G had motive a5a7a6 SysInt : SysInt : G argued with B G had motive G and B were enemies G argued with B G had motive G and B were enemies Figure 2 : Simple Argument and Interpretation In order to transmit SysInt , we simply send its propositions and the relations between them .</sentence>
				<definiendum id="0">UArg</definiendum>
				<definiens id="0">a5a7a6 Usr : Mr Body and Mr Green argued a8 Mr Green had a motive to kill Mr Body G argued with B G had motive a5a7a6 SysInt : SysInt : G argued with B G had motive G and B were enemies G argued with B G had motive G and B</definiens>
			</definition>
			<definition id="9">
				<sentence>In the absence of statistical information about discrepancies between user beliefs and system beliefs , we have devised a probability function as follows : Pra1a11a10a22a14a24a23a26a25a34a1a0 a0 a38a27a39 Usr a8a34a14a10a22a14a24a23a26a25a34a1a0 a0 a38a27a39 SysInt a8a8a17a10 a28 a12 a11 a2a30a29a15a31a33a32a35a34a11a36 a33 a36a38a37a39a41a40a42a32a35a34a11a43a44a2a30a45a5a8a7 Usra46 a36a47a39a41a40a42a32a35a34a11a43a44a2a30a45a5a8a7 SysInta46 a37 ( 5 ) where a28 is a normalizing constant , and NumCt is the number of belief categories ( =7 ) .</sentence>
				<definiendum id="0">a28</definiendum>
				<definiendum id="1">NumCt</definiendum>
			</definition>
			<definition id="10">
				<sentence>The length of the message which conveys this information is a1 a2a4a3a6a5a8a7 Usr MLa1 Sentencea2 in UArga14a0 a8 Table 1 : Summary of Message Length Calculation MLa1 UArga4 SysInta8 Equation 1 MLa1 SysInta8 Equation 2 MLa1a38a40a39 Usra14SysInta8 belief operations Equations 4 , 5 structural operations Equations 6 , 7 , 8 , 9 , 10 MLa1 UArga14a38a40a39 Usra8 Equation 11 Table 2 : Summary of Message Length Calculation for the Simple Argument MLa1 SysInta8 20.6 bits MLa1a38a40a39 Usra14SysInta8 belief operations ( no beliefs stated ) 0.0 bits structural operations 1.6 bits MLa1 UArga14a38a40a39 Usra8 65.6 bits MLa1 UArga4 SysInta8 87.8 bits where Sentencea2 in UArg is the user’s sentence which matches the proposition for node a0 ina38a40a39 Usr .</sentence>
				<definiendum id="0">length of the message</definiendum>
			</definition>
</paper>

		<paper id="0205">
			<definition id="0">
				<sentence>Thus MUP lacks features that spoken-language phenomena require of annotation tools , e.g. layers of annotation to repair disfluencies , the representation of simultaneous speakers , and interfaces to speech tools .</sentence>
				<definiendum id="0">MUP</definiendum>
				<definiens id="0">lacks features that spoken-language phenomena require of annotation tools , e.g. layers of annotation to repair disfluencies , the representation of simultaneous speakers , and interfaces to speech tools</definiens>
			</definition>
			<definition id="1">
				<sentence>We specified XML for an annotation language because it is a lingua franca : the vocabulary is quite commonly known , there is a host of XML processing software , people can inspect it , and XML provides a rich ability to add attributes to elements .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiendum id="1">XML</definiendum>
			</definition>
			<definition id="2">
				<sentence>These elements must be labeled with XML ID atributes to be the target of annotations .</sentence>
				<definiendum id="0">XML ID</definiendum>
				<definiens id="0">atributes to be the target of annotations</definiens>
			</definition>
			<definition id="3">
				<sentence>The MATE workbench ( McKelvie et al. , 2001 ) is a full-featured dialogue markup tool , however we found it to be complex and difficult to use .</sentence>
				<definiendum id="0">MATE workbench</definiendum>
				<definiens id="0">a full-featured dialogue markup tool</definiens>
			</definition>
</paper>

		<paper id="2004">
</paper>

		<paper id="0219">
			<definition id="0">
				<sentence>Communication efficiency relates to the efficiency of the dialogic interaction , and includes — besides the aspects speed and conciseness — also the smoothness of the dialogue ( which is sometimes called “dialogue quality” ) .</sentence>
				<definiendum id="0">Communication efficiency</definiendum>
				<definiens id="0">relates to the efficiency of the dialogic interaction , and includes — besides the aspects speed and conciseness — also the smoothness of the dialogue ( which is sometimes called “dialogue quality” )</definiens>
			</definition>
			<definition id="1">
				<sentence>Service efficiency is the adequacy of the service as a whole for the purpose defined by the user .</sentence>
				<definiendum id="0">Service efficiency</definiendum>
			</definition>
			<definition id="2">
				<sentence>Additional features of the questionnaires directly address user satisfaction ( e.g. perceived satisfaction , degree of enjoyment , user happiness , system likability , degree of frustration or irritation ) and acceptability ( perceived acceptability , willingness to use the system in the future ) .</sentence>
				<definiendum id="0">acceptability</definiendum>
				<definiens id="0">user satisfaction ( e.g. perceived satisfaction , degree of enjoyment , user happiness , system likability , degree of frustration or irritation</definiens>
			</definition>
			<definition id="3">
				<sentence>Dialogue cooperativity is a category which is based on a relatively sophisticated theoretical as well as empirical background .</sentence>
				<definiendum id="0">Dialogue cooperativity</definiendum>
				<definiens id="0">a category which is based on a relatively sophisticated theoretical as well as empirical background</definiens>
			</definition>
			<definition id="4">
				<sentence>The dialogue symmetry category captures the remaining partner asymmetry aspect , and has been designed separately to additionally cover initiative and interaction control aspects .</sentence>
				<definiendum id="0">dialogue symmetry category</definiendum>
				<definiens id="0">captures the remaining partner asymmetry aspect , and has been designed separately to additionally cover initiative and interaction control aspects</definiens>
			</definition>
</paper>

		<paper id="1507">
			<definition id="0">
				<sentence>7This subdivision avoids an combinatoric explosion in the number of rules if the grammar was fully lexicalized 8For other MetaRule based approaches based on the DATR formalism , see ( Carroll et al. , 2000 ) or ( Evans et al. , 2000 ) A MetaRule works as a pattern-matching tool on trees .</sentence>
				<definiendum id="0">MetaRule</definiendum>
			</definition>
			<definition id="1">
				<sentence>A TAG elementary tree is generated by inheriting from exactly one terminal class from dimension 1 , one terminal class from dimension 2 , and n terminal classes from dimension 3 ( where n is the number of arguments of the elementary tree being generated ) .</sentence>
				<definiendum id="0">TAG elementary tree</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of arguments of the elementary tree being generated )</definiens>
			</definition>
			<definition id="2">
				<sentence>Lexik : a maintenance tool for FTAG .</sentence>
				<definiendum id="0">Lexik</definiendum>
				<definiens id="0">a maintenance tool for FTAG</definiens>
			</definition>
</paper>

		<paper id="1802">
			<definition id="0">
				<sentence>Keyword : legal terminology , bilingual terminology , bilingual alignment , corpus-based linguistics Multilingual terminology is an important language resource for a range of natural language processing tasks such as machine translation and cross-lingual information retrieval .</sentence>
				<definiendum id="0">Keyword</definiendum>
				<definiens id="0">legal terminology , bilingual terminology , bilingual alignment , corpus-based linguistics Multilingual terminology is an important language resource for a range of natural language processing tasks such as machine translation and cross-lingual information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>The Bilingual Legal Information System ( BLIS ) developed by the Department of Justice , HKSAR provides simple keyword search for the glossaries and laws that are available in both Chinese and English .</sentence>
				<definiendum id="0">Bilingual Legal Information System</definiendum>
				<definiens id="0">BLIS ) developed by the Department of Justice , HKSAR provides simple keyword search for the glossaries and laws that are available in both Chinese and English</definiens>
			</definition>
</paper>

		<paper id="1039">
			<definition id="0">
				<sentence>The translation model captures the translation of source language words into the target language and the reordering of those words .</sentence>
				<definiendum id="0">translation model</definiendum>
			</definition>
			<definition id="1">
				<sentence>Each a24a30a29 is a set of indices into a0 where a31a33a32 a24a25a29a35a34a12a36a38a37 a31 a37a9a39a40a34a42a41a43a37 a44 a37a46a45 indicates that word a31 in the French sentence is aligned with word a44 in the English sentence .</sentence>
				<definiendum id="0">a24a30a29</definiendum>
				<definiens id="0">a set of indices into a0 where a31a33a32 a24a25a29a35a34a12a36a38a37 a31 a37a9a39a40a34a42a41a43a37 a44 a37a46a45 indicates that word a31 in the French sentence is aligned with word a44 in the English sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>The flattening operation consists of identifying all nested verb phrases and splicing the children of the nested phrase into the parent phrase in its place .</sentence>
				<definiendum id="0">flattening operation</definiendum>
				<definiens id="0">consists of identifying all nested verb phrases and splicing the children of the nested phrase into the parent phrase in its place</definiens>
			</definition>
</paper>

		<paper id="2017">
</paper>

		<paper id="1200">
</paper>

		<paper id="1300">
</paper>

		<paper id="0600">
</paper>

		<paper id="1105">
</paper>

		<paper id="1710">
			<definition id="0">
				<sentence>Agtk : the annotation graph toolkit .</sentence>
				<definiendum id="0">Agtk</definiendum>
				<definiens id="0">the annotation graph toolkit</definiens>
			</definition>
			<definition id="1">
				<sentence>Praat , a system for doing phonetics by computer .</sentence>
				<definiendum id="0">Praat</definiendum>
				<definiens id="0">a system for doing phonetics by computer</definiens>
			</definition>
			<definition id="2">
				<sentence>R : A language for data analysis and graphics .</sentence>
				<definiendum id="0">R</definiendum>
			</definition>
</paper>

	</volume>
