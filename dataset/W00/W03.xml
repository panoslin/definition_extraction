<?xml version="1.0" encoding="UTF-8"?>
	<volume id="W03">

		<paper id="0417">
			<definition id="0">
				<sentence>The naive Bayes classifier is a simple but effective classifier which has been used in numerous applications of information processing such as image recognition , natural language processing , information retrieval , etc. ( Escudero et al. , 2000 ; Lewis , 1998 ; Nigam and Ghani , 2000 ; Pedersen , 2000 ) .</sentence>
				<definiendum id="0">naive Bayes classifier</definiendum>
				<definiens id="0">a simple but effective classifier which has been used in numerous applications of information processing such as image recognition , natural language processing , information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>By assuming the conditional independence of the elements of a vector , P ( vectorx|c k ) is decomposed as follows , P ( vectorx|c k ) = d productdisplay j=1 P ( x j |c k ) , ( 2 ) where x j is the jth element of vector vectorx .</sentence>
				<definiendum id="0">x j</definiendum>
				<definiens id="0">vectorx|c k ) is decomposed as follows , P ( vectorx|c k ) = d productdisplay j=1 P ( x j |c k</definiens>
			</definition>
			<definition id="2">
				<sentence>The Expectation Maximization ( EM ) algorithm ( Dempster et al. , 1977 ) is a general framework for estimating the parameters of a probability model when the data has missing values .</sentence>
				<definiendum id="0">Expectation Maximization</definiendum>
				<definiens id="0">a general framework for estimating the parameters of a probability model when the data has missing values</definiens>
			</definition>
			<definition id="3">
				<sentence>The EM algorithm consists of the E-step in which the expected values of the missing sufficient statistics given the observed data and the current parameter estimates are computed , and the M-step in which the expected values of the sufficient statistics computed in the E-step are used to compute complete data maximum likelihood estimates of the parameters ( Dempster et al. , 1977 ) .</sentence>
				<definiendum id="0">EM algorithm</definiendum>
			</definition>
</paper>

		<paper id="0110">
			<definition id="0">
				<sentence>The Alexandria Digital Library Project ( Hill , 2000 ) , however , defines a gazetteer entry as also requiring a type designation to describe the entity referred to by the name and location .</sentence>
				<definiendum id="0">Alexandria Digital Library Project</definiendum>
				<definiens id="0">defines a gazetteer entry as also requiring a type designation to describe the entity referred to by the name and location</definiens>
			</definition>
			<definition id="1">
				<sentence>The GazDB uses the well-known relational approach ( Codd , 1970 ) to store the geographic data for the gazetteer .</sentence>
				<definiendum id="0">GazDB</definiendum>
				<definiens id="0">uses the well-known relational approach ( Codd , 1970 ) to store the geographic data for the gazetteer</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus while Macao is a spelling variant of Macau , and Macau is the name of a city in Southern China , nonetheless Macao is not considered to be a GazDB name proper for the city .</sentence>
				<definiendum id="0">Macau</definiendum>
				<definiens id="0">a spelling variant of Macau , and</definiens>
				<definiens id="1">the name of a city in Southern China</definiens>
			</definition>
			<definition id="3">
				<sentence>The GazDB maintains a taxonomy of geographic features , consisting of an administrative hierarchy of the world .</sentence>
				<definiendum id="0">GazDB</definiendum>
				<definiens id="0">maintains a taxonomy of geographic features , consisting of an administrative hierarchy of the world</definiens>
			</definition>
			<definition id="4">
				<sentence>The authoritative title is the ordered sequence of the authoritative names for the list of hierarchical regions that contain the feature , so it is easy to compute from a hierarchical region tree in the GazDB .</sentence>
				<definiendum id="0">authoritative title</definiendum>
				<definiens id="0">the ordered sequence of the authoritative names for the list of hierarchical regions that contain the feature , so it is easy to compute from a hierarchical region tree in the GazDB</definiens>
			</definition>
			<definition id="5">
				<sentence>The GazDB classifies geographic entities along 3 orthogonal scales : spatial representation , functional class , and administrative type .</sentence>
				<definiendum id="0">GazDB</definiendum>
				<definiens id="0">classifies geographic entities along 3 orthogonal scales : spatial representation , functional class</definiens>
			</definition>
			<definition id="6">
				<sentence>The GazDB classifies features by their footprint into 6 major types ( each with numerous subtypes ) : 1 point – 0-dimensional ( approximated to a point , e.g. a factory gate or a well ) 2 line – 1-dimensional ( e.g. a road or power line ) 3 area – 2-dimensional without clearly defined boundaries ( e.g. wetlands ) 4 point-area – a 2-D region with clearly defined boundaries ( e.g. county or lake ) 5 cluster of point-areas – e.g. an archipelago 6 probability density distribution – a feature that shifts over time , e.g. ice packs 0 unknown/unclassified Many features , particularly structures , can also be described by their functional class : 1 building – a man-made structure 2 campus – a feature that contains a number of buildings on open space , such as a military base .</sentence>
				<definiendum id="0">GazDB</definiendum>
				<definiens id="0">classifies features by their footprint into 6 major types ( each with numerous subtypes</definiens>
				<definiens id="1">a 2-D region with clearly defined boundaries ( e.g. county or lake ) 5 cluster of point-areas – e.g. an archipelago 6 probability density distribution – a feature that shifts over time , e.g. ice packs 0 unknown/unclassified Many features , particularly structures , can also be described by their functional class : 1 building – a man-made structure 2 campus – a feature that contains a number of buildings on open space , such as a military base</definiens>
			</definition>
			<definition id="7">
				<sentence>The GazDB maintains a complete hierarchical tree of all the administrative subdivisions within a country and the geographic entities contained therein , without any depth limitations .</sentence>
				<definiendum id="0">GazDB</definiendum>
				<definiens id="0">maintains a complete hierarchical tree of all the administrative subdivisions within a country and the geographic entities contained therein , without any depth limitations</definiens>
			</definition>
</paper>

		<paper id="1704">
			<definition id="0">
				<sentence>Word extraction is one of the important tasks in text information processing .</sentence>
				<definiendum id="0">Word extraction</definiendum>
				<definiens id="0">one of the important tasks in text information processing</definiens>
			</definition>
			<definition id="1">
				<sentence>In the table : xy represents any two-character item , x stands for all characters except x , is the size of training corpus , and are frequency and probability of x respectively , and are frequency and probability of N xy x f x p f xy p xy respectively , and xy ξ is the frequency expectation of xy suppose x and y are independent .</sentence>
				<definiendum id="0">xy</definiendum>
				<definiendum id="1">xy ξ</definiendum>
				<definiens id="0">represents any two-character item , x stands for all characters except x , is the size of training corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>TS1 contains 196,977 distinct bigrams , among which 17,333 are two-character words according to PDA98J .</sentence>
				<definiendum id="0">TS1</definiendum>
				<definiens id="0">contains 196,977 distinct bigrams , among which 17,333 are two-character words according to PDA98J</definiens>
			</definition>
			<definition id="3">
				<sentence>Suppose is the internal associative strength of any item ) ( xyscore i xy with respect to the i-th measure , is its corresponding interval determined by the value of score , is the interval probability of v , then the soundness of ) ( xyv i ) ( xy i ) ( xy i ) ( xypv i xy being word , , will be given by : ) ( xypv ∑ = ×= 9 1 ) ) ( ( ) ( i ii xypvwtxypv where is the weight for the i-th measure .</sentence>
				<definiendum id="0">Suppose</definiendum>
				<definiendum id="1">) ( ( )</definiendum>
				<definiens id="0">the internal associative strength of any item</definiens>
			</definition>
			<definition id="4">
				<sentence>Given a set of examples S , the information gain caused by a cut point t will be : ) ( || || ) ( || || ) ( ) , ( 2 2 1 1 SEnt S S SEnt S S SEntStIG −−= 1 S where Ent ( S ) is the entropy of S , and S and are two subsets of S partitioned by the cut point t .</sentence>
				<definiendum id="0">Ent ( S )</definiendum>
				<definiendum id="1">S</definiendum>
				<definiens id="0">the entropy of S , and</definiens>
			</definition>
			<definition id="5">
				<sentence>//Φ is an empty set Step5 .</sentence>
				<definiendum id="0">//Φ</definiendum>
				<definiens id="0">an empty set Step5</definiens>
			</definition>
			<definition id="6">
				<sentence>Open Test for Effect of Internal Measures , the Contextual Measures and the Hybrid ( on TS2 ) Precision ( % ) Recall ( % ) F-measure ( % ) Setting t 1 and t 2 for Left/Right Entropy MI 56.72 58.97 57.82 N.A. Comb 60.41 59.35 59.87 N.A. MI+Le/Re 83.53 54.88 66.24 MI-tuned threshold Comb+Le/Re* 85.69 55.76 67.56 MI-tuned threshold Comb+Le/Re 85.71 57.02 68.48 Comb-tuned threshold This section turns to discuss how to make use of contextual measures .</sentence>
				<definiendum id="0">Open Test</definiendum>
				<definiendum id="1">Hybrid</definiendum>
				<definiens id="0">to discuss how to make use of contextual measures</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>E ˜p [ f i ] = summationtext x ˜p ( x ) summationtext y ˜p ( y|x ) f i ( x , y ) , ( 4 ) E p [ f i ] = summationtext x ˜p ( x ) summationtext y p ( y|x ) f i ( x , y ) , ( 5 ) ˜p ( x ) =c ( x ) /L , ˜p ( y|x ) =c ( x , y ) /c ( x ) , ( 6 ) where c ( · ) indicates the number of times · occurred in the training data , and L is the number of training examples .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">/L , ˜p ( y|x ) =c ( x , y ) /c ( x ) , ( 6 ) where c ( · ) indicates the number of times · occurred in the training data , and</definiens>
				<definiens id="1">the number of training examples</definiens>
			</definition>
			<definition id="1">
				<sentence>In the Gaussian MAP ME estimation ( Chen and Rosenfeld , 2000 ) , the objective function is : LL ( λ ) − summationtext i ( 1 2σ 2 i ) λ 2 i , ( 16 ) which is derived as a consequence of maximizing the log-likelihood of the posterior probability , using a Gaussian distribution centered around zero with the variance σ 2 i as a prior on parameters .</sentence>
				<definiendum id="0">Gaussian MAP ME estimation</definiendum>
				<definiendum id="1">objective function</definiendum>
				<definiens id="0">a prior on parameters</definiens>
			</definition>
			<definition id="2">
				<sentence>With the uniform distribution as the prior , k times out of n trials give the posterior distribution : p ( θ ) =Be ( 1+k,1+n−k ) , where Be ( α , β ) is the beta distribution .</sentence>
				<definiendum id="0">Be</definiendum>
				<definiens id="0">the beta distribution</definiens>
			</definition>
			<definition id="3">
				<sentence>The OHSUMED dataset ( Hersh et al. , 1994 ) is a collection of clinical paper abstracts from the MEDLINE database .</sentence>
				<definiendum id="0">OHSUMED dataset</definiendum>
				<definiens id="0">a collection of clinical paper abstracts from the MEDLINE database</definiens>
			</definition>
			<definition id="4">
				<sentence>The average cross entropy was calculated as − 1 C summationtext c 1 L summationtext i log p c ( y i |d i ) , where C is the number of categories .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the number of categories</definiens>
			</definition>
</paper>

		<paper id="0804">
			<definition id="0">
				<sentence>A data model is a formalized description of the data objects ( in terms of composition , attributes , class membership , applicable procedures , etc. ) and relations among them , independent of their instantiation in any particular form .</sentence>
				<definiendum id="0">data model</definiendum>
				<definiens id="0">a formalized description of the data objects ( in terms of composition , attributes , class membership , applicable procedures , etc. ) and relations among them , independent of their instantiation in any particular form</definiens>
			</definition>
			<definition id="1">
				<sentence>Including o continuous segments ( appear contiguously in the primary data ) o superand sub-segments , where groups of segments will comprise the parts of a larger segment ( e.g. , a contiguous word segments typically comprise a sentence segment ) o discontinuous segments ( linking continuous segments ) o landmarks ( e.g time stamps ) that note a point in the primary data In current practice , segmental information may or may not appear in the document containing the primary data itself .</sentence>
				<definiendum id="0">continuous segments</definiendum>
				<definiendum id="1">o landmarks ( e.g time stamps</definiendum>
			</definition>
			<definition id="2">
				<sentence>Stand-off annotation : Annotations layered over a given primary document and instantiated in a document separate from that containing the primary data .</sentence>
				<definiendum id="0">Stand-off annotation</definiendum>
				<definiens id="0">Annotations layered over a given primary document and instantiated in a document separate from that containing the primary data</definiens>
			</definition>
			<definition id="3">
				<sentence>The following general principles will guide the LAF development : o The data model and document form are distinct but mappable to one another o The data model is parsimonious , general , and formally precise o The data model is built around a clear separation of structure and content o There is an inventory of logical operations supported by the data model , which define its abstract semantics o The document form is largely under user control o The mapping between the flexible document form and data model is via a rigid dump-format o The mapping from document form to the dump format is documented in an XML Schema ( or the functional equivalent thereof ) associated with the document o Mapping is operationalized either via schema-based data-binding process or via schema-derived stylesheet mapping between the user document and the dump-format document .</sentence>
				<definiendum id="0">Schema</definiendum>
				<definiens id="0">an inventory of logical operations supported by the data model , which define its abstract semantics o The document form is largely under user control o The mapping between the flexible document form and data model is via a rigid dump-format o The mapping from document form to the dump format is documented in an XML</definiens>
			</definition>
			<definition id="4">
				<sentence>o Resources will be available to support the design and specification of document forms , for example : -XML Schemas in several normal forms based on type definitions and abstract elements that can be exploited via type derivation and/or substitution group ; -XPointer design-patterns with standoff semantics ; -Schema annotations specifying mapping between document form and data model ; -Meta-stylesheet for mapping from annotated XML Schema to mapping stylesheets ; -Data-binding stylesheets with language-specific bindings ( e.g. Java ) .</sentence>
				<definiendum id="0">-Schema annotations</definiendum>
				<definiendum id="1">language-specific bindings</definiendum>
				<definiens id="0">several normal forms based on type definitions and abstract elements that can be exploited via type derivation and/or substitution group</definiens>
			</definition>
</paper>

		<paper id="0905">
			<definition id="0">
				<sentence>It can be said that ontological semantics is a descendant of the script-oriented approach to natural language processing , especially in the strategic sense of accentuating semantic content , that is , the quantity and quality of stored knowledge required for descriptions and applications .</sentence>
				<definiendum id="0">ontological semantics</definiendum>
				<definiens id="0">a descendant of the script-oriented approach to natural language processing , especially in the strategic sense of accentuating semantic content , that is , the quantity and quality of stored knowledge required for descriptions and applications</definiens>
			</definition>
			<definition id="1">
				<sentence>Plans are special kinds of scripts that describe the process of attaining a goal by an agent or its proxies .</sentence>
				<definiendum id="0">Plans</definiendum>
			</definition>
			<definition id="2">
				<sentence>Manipulating plans and goals is especially important in some applications of ontological semantics , for instance , in advice giving applications where the system is entrusted with recognizing the intentions ( goals ) of an agent or a group of agents based on processing texts about their behavior .</sentence>
				<definiendum id="0">ontological semantics</definiendum>
				<definiens id="0">advice giving applications where the system is entrusted with recognizing the intentions ( goals ) of an agent or a group of agents based on processing texts about their behavior</definiens>
			</definition>
			<definition id="3">
				<sentence>Computational humor aims to increase the acceptability of natural language interaction between human and machine by injecting relevant humor into natural language interfaces .</sentence>
				<definiendum id="0">Computational humor</definiendum>
			</definition>
			<definition id="4">
				<sentence>In general , any event is , in fact , complex , that is , one can almost always find subevents of an event ; whether and to what extent it is necessary to represent it as a script is a matter of grain size dictated by whether an application needs this information for reasoning , and that , in turn , is largely determined by the nature of the corpora in the domain served by the application .</sentence>
				<definiendum id="0">a script</definiendum>
				<definiens id="0">a matter of grain size dictated by whether an application needs this information for reasoning , and that , in turn , is largely determined by the nature of the corpora in the domain served by the application</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , if we want to state that somebody is a driver of trucks , we would have to say that there is an instance of DRIVE in which the THEME is TRUCK and the AGENT is the person in question .</sentence>
				<definiendum id="0">AGENT</definiendum>
				<definiens id="0">the person in question</definiens>
			</definition>
</paper>

		<paper id="1607">
			<definition id="0">
				<sentence>In Japanese language syntax , modality is defined as the intention of the writer that is represented by grammatical expressions expressed grammatically ( Nitta and Masuoka ed. , 1989 ) and typically appears in the form of particles and auxiliary verbs in the sentence structure .</sentence>
				<definiendum id="0">modality</definiendum>
				<definiens id="0">the intention of the writer that is represented by grammatical expressions expressed grammatically</definiens>
				<definiens id="1">appears in the form of particles and auxiliary verbs in the sentence structure</definiens>
			</definition>
			<definition id="1">
				<sentence>Especially , te-hoshii is a typical request expression .</sentence>
				<definiendum id="0">te-hoshii</definiendum>
				<definiens id="0">a typical request expression</definiens>
			</definition>
			<definition id="2">
				<sentence>Line ② includes direct request expressions that could not be paraphrased because they were used in quotations .</sentence>
				<definiendum id="0">Line ②</definiendum>
				<definiens id="0">includes direct request expressions that could not be paraphrased because they were used in quotations</definiens>
			</definition>
			<definition id="3">
				<sentence>Of the x i = number of correctly tagged answers total number of answers in the test data 1 if X has feature i 0 otherwise 24,000 sentences , the three subjects A , B and C were each given 8,000 of them .</sentence>
				<definiendum id="0">three</definiendum>
			</definition>
			<definition id="4">
				<sentence>KC is the kappa coefficient between subjects ( Cohen 1960 ) .</sentence>
				<definiendum id="0">KC</definiendum>
				<definiens id="0">the kappa coefficient between subjects</definiens>
			</definition>
</paper>

		<paper id="0409">
			<definition id="0">
				<sentence>TiMBL is a collection of memory-based learners that sit on top of the classic k-NN classification kernel with added metrics , algorithms , and extra functions .</sentence>
				<definiendum id="0">TiMBL</definiendum>
				<definiens id="0">a collection of memory-based learners that sit on top of the classic k-NN classification kernel with added metrics , algorithms , and extra functions</definiens>
			</definition>
			<definition id="1">
				<sentence>IB1-IG is a k-NN classifier that uses a weighted overlap metric , where a feature weight is automatically computed as the Information Gain ( IG ) of that feature .</sentence>
				<definiendum id="0">IB1-IG</definiendum>
			</definition>
			<definition id="2">
				<sentence>The weighted overlap metric for two instances X and Y is defined as : ∑ = =∆ n i iii yxwYX 1 ) , ( ) , ( δ ( 1 ) where : ii ii ii ii ii yx yx minmax yx abs yx ≠ =        − − = if if else numeric , if 1 0 ) ( ) , ( δ Information gain is computed for every feature in isolation by computing the difference in uncertainty between situations with or without knowledge of the feature value ( for more information , see Daelemans et al. , 2001 ) .</sentence>
				<definiendum id="0">weighted overlap metric</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiendum id="2">δ Information gain</definiendum>
				<definiens id="0">every feature in isolation by computing the difference in uncertainty between situations with or without knowledge of the feature value</definiens>
			</definition>
			<definition id="3">
				<sentence>3 Ripper Ripper is a fast and effective rule-based learner developed by William Cohen ( Cohen , 1995 ) .</sentence>
				<definiendum id="0">Ripper Ripper</definiendum>
			</definition>
			<definition id="4">
				<sentence>Ripper produces a model consisting of an ordered set of if-then rules .</sentence>
				<definiendum id="0">Ripper</definiendum>
				<definiens id="0">produces a model consisting of an ordered set of if-then rules</definiens>
			</definition>
			<definition id="5">
				<sentence>Thus the CPS function is defined as the ratio of the number of times our instance is the closest neighbor for an instance of the same class and the number of times our instance is the closest neighbor for another instance regardless of its class .</sentence>
				<definiendum id="0">CPS function</definiendum>
				<definiens id="0">the ratio of the number of times our instance is the closest neighbor for an instance of the same class</definiens>
			</definition>
			<definition id="6">
				<sentence>Local typicality While CPS captures information very close to an instance , typicality as defined by Zhang captures information from the entire dataset .</sentence>
				<definiendum id="0">Local typicality While CPS</definiendum>
				<definiens id="0">captures information very close to an instance , typicality as defined by Zhang captures information from the entire dataset</definiens>
			</definition>
			<definition id="7">
				<sentence>CABIN measures a binary version of the Concept Accuracy ( percent of semantic concepts recognized correctly ) while WERBIN measures a binary version of the Word Error Rate ( percent of words recognized incorrectly ) .</sentence>
				<definiendum id="0">CABIN</definiendum>
				<definiens id="0">measures a binary version of the Concept Accuracy ( percent of semantic concepts recognized correctly ) while WERBIN measures a binary version of the Word Error Rate ( percent of words recognized incorrectly )</definiens>
			</definition>
</paper>

		<paper id="0800">
</paper>

		<paper id="0502">
			<definition id="0">
				<sentence>MEAD produces a centroid ( vector ) for all of the sentences and then selects those sentences which are closest to the centroid .</sentence>
				<definiendum id="0">MEAD</definiendum>
				<definiens id="0">produces a centroid ( vector ) for all of the sentences and then selects those sentences which are closest to the centroid</definiens>
			</definition>
			<definition id="1">
				<sentence>Relative utility is a metric which measures sentence relevance .</sentence>
				<definiendum id="0">Relative utility</definiendum>
			</definition>
			<definition id="2">
				<sentence>Algorithm 2 ( SAS ) , the best performer among the manual summaries , used the sum of all scores across events and judges ; thus , it tapped into which sentences were most popular overall .</sentence>
				<definiendum id="0">SAS</definiendum>
				<definiens id="0">the best performer among the manual summaries , used the sum of all scores across events and judges</definiens>
				<definiens id="1">sentences were most popular overall</definiens>
			</definition>
</paper>

		<paper id="0908">
			<definition id="0">
				<sentence>The JAVELIN system consists of four basic components : a question analysis module , a retrieval engine , a passage analysis module ( supporting both statistical and NLP techniques ) , and an answer selection module .</sentence>
				<definiendum id="0">JAVELIN system</definiendum>
				<definiens id="0">consists of four basic components : a question analysis module , a retrieval engine , a passage analysis module ( supporting both statistical and NLP techniques ) , and an answer selection module</definiens>
			</definition>
			<definition id="1">
				<sentence>For the lexical processing step , we have integrated several external resources : the Brill part-of-speech tagger ( Brill , 1995 ) , BBN IdentiFinder ( BBN , 2000 ) ( to tag named entities such as proper names , time expressions , numbers , etc. ) , WordNet ( Fellbaum , 1998 ) ( for semantic categorization ) , and the KANTOO Lexifier ( Nyberg and Mitamura , 2000 ) ( to access a syntactic lexicon for verb valence information ) .</sentence>
				<definiendum id="0">BBN IdentiFinder</definiendum>
				<definiens id="0">semantic categorization</definiens>
			</definition>
			<definition id="2">
				<sentence>Passages selected by the retrieval engine are processed by the Link Grammar parser ( Grinberg et al. , 1995 ) .</sentence>
				<definiendum id="0">Passages</definiendum>
			</definition>
			<definition id="3">
				<sentence>The parser uses a lexicalized grammar which specifies links , i.e. , grammatical functions , and provides a constituent structure as output .</sentence>
				<definiendum id="0">parser</definiendum>
				<definiens id="0">uses a lexicalized grammar which specifies links , i.e. , grammatical functions , and provides a constituent structure as output</definiens>
			</definition>
			<definition id="4">
				<sentence>2 indicates that Wendy’s is an object of the verb founded .</sentence>
				<definiendum id="0">Wendy’s</definiendum>
				<definiens id="0">an object of the verb founded</definiens>
			</definition>
			<definition id="5">
				<sentence>The representation uses the following main constructs:2 formula is a conjunction of literals and represents the meaning of the entire sentence ( or question ) ; literal is a predicate relation over two terms ; in particular , we distinguish two types of literals : extrinsic literal , a literal which relates a label to a label , and intrinsic literal , a literal which relates a label to a word ; 2The use of terminology common in the field of formal logic is aimed at providing an intuitive understanding to the reader , but is not meant to give the impression that our work is built on a firm logic-theoretic framework .</sentence>
				<definiendum id="0">literal</definiendum>
				<definiens id="0">a conjunction of literals and represents the meaning of the entire sentence</definiens>
				<definiens id="1">a predicate relation over two terms</definiens>
				<definiens id="2">extrinsic literal , a literal which relates a label to a label , and intrinsic literal , a literal which relates a label to a word</definiens>
			</definition>
			<definition id="6">
				<sentence>Figure 2 : R. David Thomas founded Wendy’s in 1969. : Link Grammar parser output predicate is used to capture relations between terms ; term is either a label , a variable which refers to a specific entity or an event , or a word , which is either a single word ( e.g. , John ) or a sequence of words separated by whitespace ( e.g. , for proper names such as John Smith ) .</sentence>
				<definiendum id="0">term</definiendum>
				<definiens id="0">R. David Thomas founded Wendy’s in 1969. : Link Grammar parser output predicate is used to capture relations between terms</definiens>
			</definition>
			<definition id="7">
				<sentence>Using a precursor predicate example comments ROOT ROOT ( x13 , jJohnj ) the root form of entity/event x13 OBJECT OBJECT ( x2 , x3 ) x3 is the object of verb or preposition x2 SUBJECT SUBJECT ( x2 , x3 ) x3 is the subject of verb x2 DET DET ( x2 , x1 ) x1 is a determiner/quantifier of x2 TYPE TYPE ( x3 , jeventj ) x3 is of the type event TENSE TENSE ( x1 , jpresentj ) x1 is a verb in present tense EQUIV EQUIV ( x1 , x3 ) semantic equivalence : apposition : ”John , a student of CMU” equality operator in copular sentences : ”John is a student of CMU” ATTRIBUTE ATTRIBUTE ( x1 , x3 ) x3 is an adjective modifier of x1 : adjective-noun : ”stupid John” copular constructions : ”John is stupid” PREDICATE PREDICATE ( x2 , x3 ) copular constructions : ”Y is x3” ROOT ( x2 , jbej ) SUBJECT ( x2 , Y ) PREDICATE ( x2 , x3 ) POSSESSOR POSSESSOR ( x2 , x4 ) x4 is the possessor of x2 ”x4’s x2” or ”x2 of x4” AND AND ( x3 , x1 ) ”John and Mary laughed.”</sentence>
				<definiendum id="0">ROOT ROOT</definiendum>
				<definiendum id="1">”John</definiendum>
				<definiens id="0">the subject of verb x2 DET DET ( x2 , x1 ) x1 is a determiner/quantifier of x2 TYPE TYPE</definiens>
			</definition>
			<definition id="8">
				<sentence>Let O be the set of all possible orderings of PE , O an element of O , QEj literal j of QE , and Oj literal j of ordering O. Then : ( 3 ) sim ( Q ; P ) = sim ( QE ; PE ) = maxO2O ( Qnj=0 sim ( QEj ; Oj ) ) 1n The similarity of two extrinsic literals , lE and lE0 , is computed by the square root of the similarity scores of each pair of labels , multiplied by the weight of the given literal , dependent on the equivilance of the predicates p ; p0 of the respective literals lE ; lE0 .</sentence>
				<definiendum id="0">lE</definiendum>
				<definiens id="0">the set of all possible orderings of PE , O an element of O , QEj literal j of QE , and Oj literal j of ordering O. Then : ( 3 ) sim ( Q ; P ) = sim</definiens>
				<definiens id="1">computed by the square root of the similarity scores of each pair of labels , multiplied by the weight of the given literal , dependent on the equivilance of the predicates p</definiens>
			</definition>
			<definition id="9">
				<sentence>ROOT ( y1 , jBenjaminj ) , ROOT ( y2 , jmurderj ) , ROOT ( y3 , jJeffersonj ) , TYPE ( y2 , jeventj ) , TYPE ( y1 , jpersonj ) , TYPE ( y3 , jpersonj ) , SUBJECT ( y2 , y1 ) , OBJECT ( y2 , y3 ) Computing the similarity between two formulae , ( loosely referred to here by their original text ) , gives the following : ( 9 ) sim [ jWho killed Jefferson ?</sentence>
				<definiendum id="0">ROOT</definiendum>
			</definition>
</paper>

		<paper id="1713">
			<definition id="0">
				<sentence>In addition , named entities , such as person names , place names , organizations , translation terms , titles of person and so on , are usually very important for the document without reference to their frequency .</sentence>
				<definiendum id="0">place</definiendum>
				<definiens id="0">names , organizations , translation terms</definiens>
			</definition>
			<definition id="1">
				<sentence>Suppose the character string c i …c j in the original text with the sentence c 1 c 2 …c i-1 c i …c j c j+1 …c n as its context , if the segmentation tool segments c i-1 c i or c j c j+1 into one word , then c i …c j will not be regarded as an integrated unit .</sentence>
				<definiendum id="0">Suppose the character string c</definiendum>
				<definiens id="0">the segmentation tool segments c i-1 c i or c j c j+1 into one word</definiens>
			</definition>
			<definition id="2">
				<sentence>Only conducting frequency statistics of character strings can’t refine the candidate set well , and we utilize the relatively mature linguistic segmentation and POS tagging techniques so that we can further improve the quality of the candidate keywords .</sentence>
				<definiendum id="0">Only conducting frequency</definiendum>
				<definiens id="0">statistics of character strings can’t refine the candidate set well</definiens>
			</definition>
			<definition id="3">
				<sentence>As in figure 2 , Length represents the length of keywords and percentage denotes the corresponding percentage that keywords of this length are in the set .</sentence>
				<definiendum id="0">Length</definiendum>
				<definiens id="0">the length of keywords</definiens>
			</definition>
			<definition id="4">
				<sentence>Here , we automatically extracted keywords from them and evaluated the results with the standard measures of precision and recall , which are defined as follows : Where P represents precision , and R represents recall .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">keywords from them and evaluated the results with the standard measures of precision and recall , which are defined as follows : Where P represents precision , and</definiens>
			</definition>
</paper>

		<paper id="1711">
</paper>

		<paper id="0205">
			<definition id="0">
				<sentence>Tutorial dialogue is a natural way to provide students with a learning environment that exhibits characteristics that have been shown to correlate with student learning gains , such as student activity .</sentence>
				<definiendum id="0">Tutorial dialogue</definiendum>
				<definiens id="0">a natural way to provide students with a learning environment that exhibits characteristics that have been shown to correlate with student learning gains , such as student activity</definiens>
			</definition>
			<definition id="1">
				<sentence>Systems Why2-Atlas is a text based intelligent tutoring dialogue system ( Ros·e et al. , 2002a ; VanLehn et al. , 2002 ) .</sentence>
				<definiendum id="0">Systems Why2-Atlas</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Why2-Atlas Human-Human Typed Tutoring Corpus is a collection of typed tutoring dialogues between ( human ) tutor and student collected via typed interface , which the tutor plays the same role that Why2-Atlas is designed to perform .</sentence>
				<definiendum id="0">Why2-Atlas Human-Human Typed Tutoring Corpus</definiendum>
				<definiens id="0">a collection of typed tutoring dialogues between ( human ) tutor and student collected via typed interface , which the tutor plays the same role that Why2-Atlas is designed to perform</definiens>
			</definition>
			<definition id="3">
				<sentence>Corpus The ITSPOKE Human-Human Spoken Tutoring Corpus is a parallel collection of spoken tutoring dialogues collected via a web interface supplemented with a high quality audio link , where a human tutor performs the same task that our ITSPOKE system is being designed to perform .</sentence>
				<definiendum id="0">ITSPOKE Human-Human Spoken Tutoring Corpus</definiendum>
				<definiens id="0">being designed to perform</definiens>
			</definition>
			<definition id="4">
				<sentence>The experimental procedure used to collect the corpus is exactly the same as the procedure used to gather the Why2-Atlas Human-Human Corpus : the same tutor is used , the same subject pool1 is used , the same pre-test and post-test are used , and the same set of physics prob1We assigned a greater percentage of students to the text based condition as part of a separate experiment .</sentence>
				<definiendum id="0">Human-Human Corpus</definiendum>
				<definiens id="0">the text based condition as part of a separate experiment</definiens>
			</definition>
</paper>

		<paper id="1502">
			<definition id="0">
				<sentence>Fastus : A finite-state processor for information extraction from real world texts .</sentence>
				<definiendum id="0">Fastus</definiendum>
				<definiens id="0">A finite-state processor for information extraction from real world texts</definiens>
			</definition>
</paper>

		<paper id="1115">
			<definition id="0">
				<sentence>Temporal information retrieval is the process of extracting time-varying information .</sentence>
				<definiendum id="0">Temporal information retrieval</definiendum>
				<definiens id="0">the process of extracting time-varying information</definiens>
			</definition>
			<definition id="1">
				<sentence>A document may be modified any time after it is created , and hence a document consists of time-varying information .</sentence>
				<definiendum id="0">document</definiendum>
				<definiens id="0">may be modified any time after it is created , and hence a document consists of time-varying information</definiens>
			</definition>
			<definition id="2">
				<sentence>Assume that there are time points t 1 , t 2 , t 2 ’ , t 3 , t 3 ’ , t 4 ( t i &lt; t i+1 , t i =t i ’ ) . Also assume that [ t i , t j ] ( i &lt; j ) is a time interval , where start ( [ t i , t j ] ) =t i , and end ( [ t i , t j ] ) =t j . The following relations exist among time points X and Y , and time intervals A and B. X before Y : X &lt; Y , e.g. t 1 before t 2 X after Y : X &gt; Y , e.g. t 2 after t 1 X simultaneous-with Y : X = Y , e.g. t 2 simultaneous-with t 2 ’ X in A : start ( A ) ≤X≤end ( Y ) , e.g. t 2 in [ t 1 , t 3 ] A before B : end ( A ) &lt; start ( B ) , e.g. [ t 1 , t 2 ] before [ t 3 , t 4 ] A meets B : end ( A ) =start ( B ) , e.g. [ t 1 , t 2 ] meets [ t 2 ’ , t 3 ] A overlaps B : start ( B ) &lt; end ( A ) &lt; end ( B ) ∩ start ( A ) &lt; start ( B ) , e.g. [ t 1 , t 3 ] overlaps [ t 2 , t 4 ] A starts B : start ( A ) =start ( B ) , e.g. [ t 2 , t 3 ] starts [ t 2 ’ , t 4 ] A during B : start ( A ) &gt; start ( B ) ∩ end ( A ) &lt; end ( B ) , e.g. [ t 2 , t 3 ] during [ t 1 , t 4 ] A finished B : end ( A ) =end ( B ) ∩ start ( A ) &gt; start ( B ) , e.g. [ t 2 , t 3 ] finishes [ t 1 , t 3 ’ ] A after B : start ( A ) &gt; end ( B ) , e.g. [ t 3 , t 4 ] after [ t 1 , t 2 ] A met-by B : start ( A ) =end ( B ) , e.g. [ t 2 , t 3 ] met-by [ t 1 , t 2 ’ ] A overlapped-by B : start ( B ) &lt; start ( A ) &lt; end ( B ) ∩ end ( B ) &lt; end ( A ) , e.g. [ t 2 , t 4 ] overlapped-by [ t 1 , t 3 ] A started-by B : start ( A ) =start ( B ) ∩ end ( A ) &gt; end ( B ) , e.g. [ t 2 , t 4 ] started-by [ t 2 ’ , t 3 ] A contains B : start ( A ) &lt; start ( B ) ∩ end ( A ) &gt; end ( B ) , e.g. [ t 1 , t 4 ] contains [ t 2 , t 3 ] A finished-by B : end ( A ) =end ( B ) ∩ start ( A ) &lt; start ( B ) , e.g. [ t 1 , t 3 ] finished-by [ t 2 , t 3 ’ ] A cotemporal B : start ( A ) =start ( B ) ∩ end ( A ) =end ( B ) , e.g. [ t 2 , t 3 ] cotemporal [ t 2 ’ , t 3 ’ ] In a temporal database , there are 2 kinds of times : valid times and transaction times. Valid times concern facts that are true in modeled reality. Transaction times concern facts that are current in the database. In general , a valid time DB stores only fresh data , whereas a transaction time DB stores the complete history of the data. A bitemporal DB supports both kinds of data. Retrieval In this paper , temporal information retrieval is defined as determining whether or not a document exists at a time point or in a time interval. This is in contrast to whether or not the content of a document includes the specified time. For example , assume that a document containing the text In 2002 , the FIFA World Cup will be held in Korea and Japan was written in 1998. In the former case , this document would be retrieved with the query , 1998 and ( Korea or Japan ) . In the latter case , this document would be retrieved with the query , 2002 and ( Korea or Japan ) . The number 1998 in the former case is the modified time of the document. The number 2002 in the latter case is a keyword in the text of the document. This latter type of retrieval is classified as a query expansion or a numerical query. We discuss temporal information retrieval in the former sense. Assume that a document always contains facts. In this case , a fact in temporal information retrieval means the existence of the document. Valid time is the time when the document exists in the real world , and transaction time denotes the time when the document is indexed. The lifetime of a document depends on the document model , and there are two kinds of models. The first is the immutable model , in which the lifetime of a document is equivalent to the lifetime of the information. The information is the content of the document , and when a document is modified , the information is also changed. Therefore , an old document is deleted and a new document is created at every modification time. The second type of model is the mutable model , in which the modification of a document is allowed. In this model , when a document is modified , the content of the document is changed but the document itself is not changed. So , in the mutable model , a document exists from the time it is created to the time it is deleted , although its content may change multiple times. In the immutable model , a document exists only from one modification time to another. From the viewpoint of the users the retrieval result , with the exception of time , is not dependent on the document model. However , in the immutable model , the retrieval result is based on the modification time , whereas in the mutable model , it is based on the creation time. There are several possible interpretations of created time , modified time and deleted time. Assume that someone had information at time t 1 , he wrote it into a document at t 2 , he published the document at t 3 , and the document was indexed by a search engine at t 4 . It is important to determine what time corresponds to the origin of the information. In principle , the information is created at t 1 . However , it is hard to prove this fact and it is impossible to retrieve it. The time t 2 is determined by outside factors. In addition , it may not be possible for everyone to publish a web document without changing the timestamp , so , t 2 is not a good measure. The time t 3 is the published time when the document is available on the web. However , it is difficult to retrieve the document at precisely t 3 . In fact , we can retrieve the document after t 4 . Ideally , t 4 should be nearly equal to t 3 . In centralized search engines , because t 4 − t 3 is greater than t 3 − t 2 , t 2 is used instead of t 4 . However , in distributed search engines , because t 4 − t 3 is very small , t 4 is used for the purpose of temporal information retrieval. In such a case , the valid time is equivalent to the transaction time. There are two kinds of temporal queries in temporal information retrieval. One is an interval query which retrieves documents existing in an interval of time. The other is a point query which retrieves documents existing at a certain time point. An interval query is also called a time slice query. A temporal query is used in conjunction with a keyword query. The retrieval results include not only the content of the documents , but also the created time and the modified time. The targets of a temporal query are the lifetime interval and the modified time point of the document. In a temporal query , temporal relations mentioned in section 2.1 may be specified. In order to realize fully temporal information retrieval , it is necessary to store the complete history of every document’s modification , however this has huge storage requirements. So instead , we introduce fresh information retrieval as a practical substitute , which retrieves the last modified versions of current documents. Temporal information retrieval is the retrieval of documents that exist during a time interval. Fresh information retrieval is not the retrieval of documents that have current content , but to retrieve current documents which exist with content during a time interval. With fresh information retrieval , huge storage is unnecessary because only the last modified version of a document is stored. Also , fresh information retrieval supports all the functions of temporal information retrieval except that the retrieved document is the current version. In section 2.1 , we described that a valid time DB stores only current versions of documents. In this sense , fresh information retrieval is valid time information retrieval. We illustrate 3 kinds of information retrieval in Fig. 1. In this figure , there are 3 documents D 0 , D 1 and D 2 , and the black dots represent modification events. In non-temporal information retrieval , documents which exist at the current point in time are retrieved. In Fig. 1 , D 0 and D 1 are retrieved by non-temporal information retrieval. D 2 is not retrieved because it is deleted. In fresh information retrieval , D 0 and D 1 are retrieved in the same way as in non-temporal information retrieval. However , D 0 is retrieved with the temporal query shown as the dashed rectangle in Fig. 1. Non-temporal information retrieval does not support such a query. Finally , in fully temporal information retrieval , all documents D 0 , D 1 , and D 2 may be retrieved with any temporal query. For example , D 0 exists as 3 versions separated by two modifications. First , we explain a basic idea of CSE. In order to minimize the update interval , every web site basically makes indices via a local indexer. However , these sites are not cooperative yet. Each site sends the information about what ( i.e. which words ) it knows to the manager. This information is called Forward Knowledge ( FK ) , and is Meta knowledge indicating what each site knows. FK is the same as FI of Ingrid. When searching , the manager tells which site has documents including any word in the query to the client , and then the client sends the query to all of those sites. In this way , since CSE needs two-pass communication at searching , the retrieval time of CSE becomes longer than that of a centralized search engine. CSE consists of the following components ( see Figure 1 ) . null Location Server ( LS ) : It manages FK exclusively. Using FK , LS performs Query based Site Selection described later. LS also has Site selection Cache ( SC ) which caches results of site selection. null Cache Server ( CS ) : It caches FK and retrieval results. LS can be thought of as the top-level CS. It realizes Next 10 searches by caching retrieval results. Furthermore , it realizes a parallel search by calling LMSE mentioned later in parallel. null Local Meta Search Engine ( LMSE ) : It receives queries from a user , sends it to CS ( User I/F in Figure 2 ) , and does local search process by calling LSE mentioned later ( Engine I/F in Figure 2 ) . It works as the Meta search engine that abstracts the difference between LSEs. null Local Search Engine ( LSE ) : It gathers documents locally ( Gatherer in Figure 2 ) , makes a local index ( Indexer in Fig. 2 ) , and retrieves documents by using the index ( Engine in Figure 2 ) . In CSE , Namazu [ 1 ] can be used as a LSE. Furthermore we are developing an original indexer designed to realize high-level search functions such as parallel search and phrase search. Namazu has widely used as the search services on various Japanese sites. Next , we explain how the update process is done. In CSE , Update I/F of LSE carries out the update process periodically. The algorithm for the update process in CSE is as follows. Figure 1. Temporal Information Retrieval D 0 D 1 D 2 tnow Figure 2. The overview of CSE pages ) in the target Web sites using direct access ( i.e. via NFS ) if available , using archived access ( i.e. via CGI ) if it is available but direct access is not available , and using HTTP access otherwise. Here , we explain archived access in detail. In archived access , a special CGI that provides mobile agent place functions is used. A mobile agent is sent to that place. The agent archives local files , compresses them and sends back to the gatherer. documents by parallel processing based on Boss-Worker model. i updates as follows. i obtains from the corresponding LSE the total number N i of all the documents , the set K i of all the words appearing in some documents , and the number n k , i of all the documents including word k , and sends to CS all of them together with its own URL. i to the upper-level CS. The transmission of the contents is terminated when they reach the top-level CS ( namely , LS ) . i /∑n k , i ) from N k , i and N i for each word k. i updates as follows has been searched and the set of idf values from LS. i obtains from the corresponding LSE the highest score max d∈D S i ( d , q ) for each q∈ { Q , K i } , S i ( d , k ) is a score of document d containing k , D is the set of all the documents in the site , and sends to CS all of them together with its own URL. i to the upper-level CS. The transmission of the contents is terminated when they reach the top-level CS ( namely , LS ) . Note that the data transferred between each module are mainly used for distributed calculation to obtain the score based on the tf*idf method. We call this method the distributed tf*idf method. The score based on the distributed tf*idf method is calculated at the search process. So we will give the detail about the score when we explain the search process in CSE. For the good performance of the update process , the performance of the search process is sacrificed in CSE. Here we explain how the search process in CSE is done. 0 receives a query from a user , it sends the query to CS. documents satisfying the query. query by using LSE , and returns the result to CS. LMSEs , and returns it to LMSE 0 . 0 displays the search result to the user. .Here , we describe the design of scalable architecture for the distributed search engine , CSE. In CSE , at searching time , there is the problem that communication delay occurs. Such a problem is solved by using following techniques. null Look Ahead Cache in Next 10 Search [ 3 ] To shorten the delay on search process , CS prepares the next result for the Next 10 search. That is , the search result is divided into page units , and each page unit is cached in advance by background process without increasing the response time. null Score based Site Selection ( SbSS ) [ 4 ] In the Next 10 search , the score of the next ranked document in each site is gathered in advance , and the requests to the sites with low-ranked documents are suppressed. By this suppression , the network traffic does not increase unnecessarily. For example , there are more than 100,000 domain sites in Japan. However , by using this technique , about ten sites are sufficient to requests on each continuous search. null Global Shared Cache ( GSC ) [ 5 ] A LMSE sends a query to the nearest CS. Many CS may send same requests to LMSEs. So , in order to globally share cached retrieval results among CSs , we proposed Global Shared Cache ( GSC ) . In this method , LS memories the authority CS a of each query and tells CSs CS a instead of LMSEs. CS caches the cached contents of CS a . null Persistent Cache ( PC ) [ 6 ] There is at least one CS in CSE in order to improve the response time of retrieval. However , the cache becomes invalid soon because the update interval is very short in CSE. Valuable first page is also lost. Therefore , we need persistent cache , which holds valid cache data before and after updating. In this method , there are two update phases. At first update phase , each LMSE sends the number of documents including each word to LS , and LS detects idf of each word. At second update phase , preliminary search is performed using new idfs in order to update caches. null Query based Site Selection ( QbSS ) [ 7 ] [ 8 ] CSE supports Boolean search based on Boolean formula. In Boolean search of CSE , the operations and , or , and and-not are available. Let S A and S B be the set of target sites for search queries A and B , respectively. Then , the set of target sites for queries A and B , A or B , and A and-not B are S A ∩ S B , S A ∪ S B , and S A , respectively. By this selection of the target sites , the number of messages in search process is saved. These techniques are used as follows : if the previous page of Next 10 search has been already searched LAC else if query does not contain and or and-not SbSS else if it has been searched since index was updated GSC else if it has been searched once PC else // query is new QbSS fi Here , we describe the temporal queries used to support the retrieval of temporal information. CSE currently supports Boolean queries for keywords , and temporal queries in addition to keyword queries. Temporal queries are used to select documents existing at certain times or within certain time intervals. A temporal query is an expression of a time point or a time interval. First , we define a time point expression. Several conventional search engines can retrieve documents modified in some days or some months. However , this level of granularity is not sufficient for retrieving fresh information. A fresh information retrieval system has to retrieve documents modified within a matter of minutes at least. CSE updates the index within a few minutes independent of the scale of the system. In the near future , we expect to allow retrieval in real time , which is ideal for the purpose of fresh information retrieval. Therefore , we employ the second as the granularity of a chronon. A computer stores time as an integer which is represented as the number of seconds after 1970-01-01 00:00:00 GMT. However , it is not natural for a human to count time using only seconds , so in this paper we represent time as the following expression. Y/M/D/h/m/s Here , Y is the year in A.D. , M is the numerical month ( 1-12 ) , D is the day in a month ( 1-31 ) , h is the hour ( 0-23 ) , m is the minute ( 0-59 ) , s is the second ( 0-59 ) . If each granularity is omitted , it denotes an initial value. For an example , Y is Y/1/1/0/0/0. Furthermore , a time which is prefixed with a minus sign denotes the difference from the current time. -Y/M/D/h/m/s For example , -1/6 is a year and 6 months ago. If the accepted temporal query is negative , it is added to the current time. A negative temporal query is provided for the user’s convenience. Next , we define the attributes of a document and their symbols as time point variables. /c the created time of the document /e the effective modified time of the document /m the last modified time of the document /now the current time Here , the effective modified time of the document denotes the last modified time where the content of the version is nearly equal to that of the current version. We will describe how to calculate /e in section 4.2. In the immutable document model , /m is used , and in the mutable document model , /c is used. The relationship of /c≤ /e≤ /m≤ /now is always true. The following queries exist concerning time points t 1 and t 2 . t 1 &lt; t 2 : t 1 before t 2 t 1 &gt; t 2 : t 1 after t 2 t 1 = t 2 : t 1 simultaneous-with t 2 Here , time point queries are compared with each other in the smallest granularity even if they form an elliptical representation .</sentence>
				<definiendum id="0">transaction time</definiendum>
				<definiendum id="1">retrieval</definiendum>
				<definiendum id="2">retrieved document</definiendum>
				<definiendum id="3">S i</definiendum>
				<definiendum id="4">k )</definiendum>
				<definiendum id="5">D</definiendum>
				<definiendum id="6">LS</definiendum>
				<definiendum id="7">S A , respectively. By</definiendum>
				<definiendum id="8">intervals. A temporal query</definiendum>
				<definiendum id="9">Y</definiendum>
				<definiendum id="10">M</definiendum>
				<definiendum id="11">Y</definiendum>
				<definiens id="0">t 3 , t 3 ’ , t 4 ( t i &lt; t i+1 , t i =t i ’ ) . Also assume that [ t i , t j ] ( i &lt; j ) is a time interval , where start ( [ t i , t j ] ) =t i , and end ( [ t i , t j ] ) =t j . The following relations exist among time points X and Y , and time intervals A and B. X before Y : X &lt; Y , e.g. t 1 before t 2 X after Y : X &gt; Y , e.g. t 2 after t 1 X simultaneous-with Y : X = Y , e.g. t 2 simultaneous-with t 2 ’ X in A : start ( A ) ≤X≤end ( Y ) , e.g. t 2 in [ t 1 , t 3 ] A before B : end ( A ) &lt; start ( B ) , e.g. [ t 1 , t 2 ] before [ t 3 , t 4 ] A meets B : end ( A ) =start ( B ) , e.g. [ t 1 , t 2 ] meets [ t 2 ’ , t 3 ] A overlaps B : start ( B ) &lt; end ( A ) &lt; end ( B ) ∩ start ( A ) &lt; start ( B ) , e.g. [ t 1 , t 3 ] overlaps [ t 2 , t 4 ] A starts B : start ( A ) =start ( B ) , e.g. [ t 2 , t 3 ] starts [ t 2 ’ , t 4 ] A during B : start ( A ) &gt; start ( B ) ∩ end ( A ) &lt; end ( B ) , e.g. [ t 2 , t 3 ] during [ t 1 , t 4 ] A finished B : end ( A ) =end ( B ) ∩ start ( A ) &gt; start ( B ) , e.g. [ t 2 , t 3 ] finishes [ t 1 , t 3 ’ ] A after B : start ( A ) &gt; end ( B ) , e.g. [ t 3 , t 4 ] after [ t 1 , t 2 ] A met-by B : start ( A ) =end ( B ) , e.g. [ t 2 , t 3 ] met-by [ t 1 , t 2 ’ ] A overlapped-by B : start ( B ) &lt; start ( A ) &lt; end ( B ) ∩ end ( B ) &lt; end ( A ) , e.g. [ t 2 , t 4 ] overlapped-by [ t 1 , t 3 ] A started-by B : start ( A ) =start ( B ) ∩ end ( A ) &gt; end ( B ) , e.g. [ t 2 , t 4 ] started-by [ t 2 ’ , t 3 ] A contains B : start ( A ) &lt; start ( B ) ∩ end ( A ) &gt; end ( B ) , e.g. [ t 1 , t 4 ] contains [ t 2 , t 3 ] A finished-by B : end ( A ) =end ( B ) ∩ start ( A ) &lt; start ( B ) , e.g. [ t 1 , t 3 ] finished-by [ t 2 , t 3 ’ ] A cotemporal B : start ( A ) =start ( B ) ∩ end ( A ) =end ( B ) , e.g. [ t 2 , t 3 ] cotemporal [ t 2 ’ , t 3 ’ ] In a temporal database , there are 2 kinds of times : valid times and transaction times. Valid times concern facts that are true in modeled reality. Transaction times concern facts that are current in the database. In general , a valid time DB stores only fresh data , whereas a transaction time DB stores the complete history of the data. A bitemporal DB supports both kinds of data. Retrieval In this paper , temporal information retrieval is defined as determining whether or not a document exists at a time point or in a time interval. This is in contrast to whether or not the content of a document includes the specified time. For example , assume that a document containing the text In 2002 , the FIFA World Cup will be held in Korea and Japan was written in 1998. In the former case , this document would be retrieved with the query , 1998 and ( Korea or Japan ) . In the latter case , this document would be retrieved with the query , 2002 and ( Korea or Japan ) . The number 1998 in the former case is the modified time of the document. The number 2002 in the latter case is a keyword in the text of the document. This latter type of retrieval is classified as a query expansion or a numerical query. We discuss temporal information retrieval in the former sense. Assume that a document always contains facts. In this case , a fact in temporal information retrieval means the existence of the document. Valid time is the time when the document exists in the real world , and</definiens>
				<definiens id="1">the time when the document is indexed. The lifetime of a document depends on the document model , and there are two kinds of models. The first is the immutable model , in which the lifetime of a document is equivalent to the lifetime of the information. The information is the content of the document , and when a document is modified , the information is also changed. Therefore , an old document is deleted and a new document is created at every modification time. The second type of model is the mutable model , in which the modification of a document is allowed. In this model , when a document is modified , the content of the document is changed but the document itself is not changed. So , in the mutable model , a document exists from the time it is created to the time it is deleted , although its content may change multiple times. In the immutable model , a document exists only from one modification time to another. From the viewpoint of the users the retrieval result , with the exception of time , is not dependent on the document model. However , in the immutable model , the retrieval result is based on the modification time , whereas in the mutable model , it is based on the creation time. There are several possible interpretations of created time , modified time and deleted time. Assume that someone had information at time t 1 , he wrote it into a document at t 2 , he published the document at t 3 , and the document was indexed by a search engine at t 4 . It is important to determine what time corresponds to the origin of the information. In principle , the information is created at t 1 . However , it is hard to prove this fact and it is impossible to retrieve it. The time t 2 is determined by outside factors. In addition , it may not be possible for everyone to publish a web document without changing the timestamp , so , t 2 is not a good measure. The time t 3 is the published time when the document is available on the web. However , it is difficult to retrieve the document at precisely t 3 . In fact , we can retrieve the document after t 4 . Ideally , t 4 should be nearly equal to t 3 . In centralized search engines , because t 4 − t 3 is greater than t 3 − t 2 , t 2 is used instead of t 4 . However , in distributed search engines , because t 4 − t 3 is very small , t 4 is used for the purpose of temporal information retrieval. In such a case , the valid time is equivalent to the transaction time. There are two kinds of temporal queries in temporal information retrieval. One is an interval query which retrieves documents existing in an interval of time. The other is a point query which retrieves documents existing at a certain time point. An interval query is also called a time slice query. A temporal query is used in conjunction with a keyword query. The retrieval results include not only the content of the documents , but also the created time and the modified time. The targets of a temporal query are the lifetime interval and the modified time point of the document. In a temporal query , temporal relations mentioned in section 2.1 may be specified. In order to realize fully temporal information retrieval , it is necessary to store the complete history of every document’s modification , however this has huge storage requirements. So instead , we introduce fresh information retrieval as a practical substitute , which retrieves the last modified versions of current documents. Temporal information</definiens>
				<definiens id="2">the retrieval of documents that exist during a time interval. Fresh information retrieval is not the retrieval of documents that have current content , but to retrieve current documents which exist with content during a time interval. With fresh information retrieval , huge storage is unnecessary because only the last modified version of a document is stored. Also , fresh information retrieval supports all the functions of temporal information retrieval except that the</definiens>
				<definiens id="3">the current version. In section 2.1 , we described that a valid time DB stores only current versions of documents. In this sense , fresh information retrieval is valid time information retrieval. We illustrate 3 kinds of information retrieval in</definiens>
				<definiens id="4">D 0 , D 1 and D 2 , and the black dots represent modification events. In non-temporal information retrieval , documents which exist at the current point in time are retrieved. In Fig. 1 , D 0 and D 1 are retrieved by non-temporal information retrieval. D 2 is not retrieved because it is deleted. In fresh information retrieval , D 0 and D 1 are retrieved in the same way as in non-temporal information retrieval. However , D 0 is retrieved with the temporal query shown as the dashed rectangle in Fig. 1. Non-temporal information retrieval does not support such a query. Finally , in fully temporal information retrieval , all documents D 0 , D 1 , and D 2 may be retrieved with any temporal query. For example , D 0 exists as 3 versions separated by two modifications. First , we explain a basic idea of CSE. In order to minimize the update interval , every web site basically makes indices via a local indexer. However , these sites are not cooperative yet. Each site sends the information about what ( i.e. which words ) it knows to the manager. This information is called Forward Knowledge ( FK ) , and is Meta knowledge indicating what each site knows. FK is the same as FI of Ingrid. When searching , the manager tells which site has documents including any word in the query to the client , and then the client sends the query to all of those sites. In this way , since CSE needs two-pass communication at searching , the retrieval time of CSE becomes longer than that of a centralized search engine. CSE consists of the following components ( see Figure 1 ) . null Location Server ( LS ) : It manages FK exclusively. Using FK , LS performs Query based Site Selection described later. LS also has Site selection Cache ( SC ) which caches results of site selection. null Cache Server ( CS ) : It caches FK and retrieval results. LS can be thought of as the top-level CS. It realizes Next 10 searches by caching retrieval results. Furthermore , it realizes a parallel search by calling LMSE mentioned later in parallel. null Local Meta Search Engine ( LMSE ) : It receives queries from a user , sends it to CS ( User I/F in Figure 2 ) , and does local search process by calling LSE mentioned later ( Engine I/F in Figure 2 ) . It works as the Meta search engine that abstracts the difference between LSEs. null Local Search Engine ( LSE ) : It gathers documents locally ( Gatherer in Figure 2 ) , makes a local index ( Indexer in Fig. 2 ) , and retrieves documents by using the index ( Engine in Figure 2 ) . In CSE , Namazu [ 1 ] can be used as a LSE. Furthermore we are developing an original indexer designed to realize high-level search functions such as parallel search and phrase search. Namazu has widely used as the search services on various Japanese sites. Next , we explain how the update process is done. In CSE , Update I/F of LSE carries out the update process periodically. The algorithm for the update process in CSE is as follows. Figure 1. Temporal Information Retrieval D 0 D 1 D 2 tnow Figure 2. The overview of CSE pages ) in the target Web sites using direct access ( i.e. via NFS ) if available , using archived access ( i.e. via CGI ) if it is available but direct access is not available , and using HTTP access otherwise. Here , we explain archived access in detail. In archived access , a special CGI that provides mobile agent place functions is used. A mobile agent is sent to that place. The agent archives local files , compresses them and sends back to the gatherer. documents by parallel processing based on Boss-Worker model. i updates as follows. i obtains from the corresponding LSE the total number N i of all the documents , the set K i of all the words appearing in some documents , and the number n k , i of all the documents including word k , and sends to CS all of them together with its own URL. i to the upper-level CS. The transmission of the contents is terminated when they reach the top-level CS ( namely , LS ) . i /∑n k , i ) from N k , i and N i for each word k. i updates as follows has been searched and the set of idf values from LS. i obtains from the corresponding LSE the highest score max d∈D S i ( d , q ) for each q∈ { Q , K i } ,</definiens>
				<definiens id="5">a score of document d containing k</definiens>
				<definiens id="6">the set of all the documents in the site , and sends to CS all of them together with its own URL. i to the upper-level CS. The transmission of the contents is terminated when they reach the top-level CS ( namely , LS ) . Note that the data transferred between each module are mainly used for distributed calculation to obtain the score based on the tf*idf method. We call this method the distributed tf*idf method. The score based on the distributed tf*idf method is calculated at the search process. So we will give the detail about the score when we explain the search process in CSE. For the good performance of the update process , the performance of the search process is sacrificed in CSE. Here we explain how the search process in CSE is done. 0 receives a query from a user , it sends the query to CS. documents satisfying the query. query by using LSE , and returns the result to CS. LMSEs , and returns it to LMSE 0 . 0 displays the search result to the user. .Here , we describe the design of scalable architecture for the distributed search engine , CSE. In CSE , at searching time , there is the problem that communication delay occurs. Such a problem is solved by using following techniques. null Look Ahead Cache in Next 10 Search [ 3 ] To shorten the delay on search process , CS prepares the next result for the Next 10 search. That is , the search result is divided into page units , and each page unit is cached in advance by background process without increasing the response time. null Score based Site Selection ( SbSS ) [ 4 ] In the Next 10 search , the score of the next ranked document in each site is gathered in advance , and the requests to the sites with low-ranked documents are suppressed. By this suppression , the network traffic does not increase unnecessarily. For example , there are more than 100,000 domain sites in Japan. However , by using this technique , about ten sites are sufficient to requests on each continuous search. null Global Shared Cache ( GSC ) [ 5 ] A LMSE sends a query to the nearest CS. Many CS may send same requests to LMSEs. So , in order to globally share cached retrieval results among CSs , we proposed Global Shared Cache ( GSC ) . In this method</definiens>
				<definiens id="7">memories the authority CS a of each query and tells CSs CS a instead of LMSEs. CS caches the cached contents of CS a . null Persistent Cache ( PC ) [ 6 ] There is at least one CS in CSE in order to improve the response time of retrieval. However , the cache becomes invalid soon because the update interval is very short in CSE. Valuable first page is also lost. Therefore , we need persistent cache , which holds valid cache data before and after updating. In this method , there are two update phases. At first update phase , each LMSE sends the number of documents including each word to LS , and LS detects idf of each word. At second update phase , preliminary search is performed using new idfs in order to update caches. null Query based Site Selection ( QbSS ) [ 7 ] [ 8 ] CSE supports Boolean search based on Boolean formula. In Boolean search of CSE , the operations and , or , and and-not are available. Let S A and S B be the set of target sites for search queries A and B , respectively. Then , the set of target sites for queries A and B , A or B , and A and-not B are S A ∩ S B , S A ∪ S B , and</definiens>
				<definiens id="8">this selection of the target sites , the number of messages in search process is saved. These techniques are used as follows : if the previous page of Next 10 search has been already searched LAC else if query does not contain and or and-not SbSS else if it has been searched since index was updated GSC else if it has been searched once PC else // query is new QbSS fi Here , we describe the temporal queries used to support the retrieval of temporal information. CSE currently supports Boolean queries for keywords , and temporal queries in addition to keyword queries. Temporal queries are used to select documents existing at certain times or within certain time</definiens>
				<definiens id="9">an expression of a time point or a time interval. First , we define a time point expression. Several conventional search engines can retrieve documents modified in some days or some months. However , this level of granularity is not sufficient for retrieving fresh information. A fresh information retrieval system has to retrieve documents modified within a matter of minutes at least. CSE updates the index within a few minutes independent of the scale of the system. In the near future , we expect to allow retrieval in real time , which is ideal for the purpose of fresh information retrieval. Therefore , we employ the second as the granularity of a chronon. A computer stores time as an integer which is represented as the number of seconds after 1970-01-01 00:00:00 GMT. However , it is not natural for a human to count time using only seconds , so in this paper we represent time as the following expression. Y/M/D/h/m/s Here</definiens>
				<definiens id="10">the year in A.D.</definiens>
				<definiens id="11">the numerical month ( 1-12 ) , D is the day in a month ( 1-31 ) , h is the hour ( 0-23 ) , m is the minute ( 0-59 ) , s is the second ( 0-59 ) . If each granularity is omitted , it denotes an initial value. For an example</definiens>
				<definiens id="12">Y/1/1/0/0/0. Furthermore , a time which is prefixed with a minus sign denotes the difference from the current time. -Y/M/D/h/m/s For example , -1/6 is a year and 6 months ago. If the accepted temporal query is negative , it is added to the current time. A negative temporal query is provided for the user’s convenience. Next , we define the attributes of a document and their symbols as time point variables. /c the created time of the document /e the effective modified time of the document /m the last modified time of the document /now the current time Here , the effective modified time of the document denotes the last modified time where the content of the version is nearly equal to that of the current version. We will describe how to calculate /e in section 4.2. In the immutable document model , /m is used , and in the mutable document model , /c is used. The relationship of /c≤ /e≤ /m≤ /now is always true. The following queries exist concerning time points t 1 and t 2 . t 1 &lt; t 2 : t 1 before t 2 t 1 &gt; t 2 : t 1 after t 2 t 1 = t 2 : t 1 simultaneous-with t 2 Here , time point queries are compared with each other in the smallest granularity even if they form an elliptical representation</definiens>
			</definition>
			<definition id="3">
				<sentence>If a time point T is included in [ t 1 , t 2 ] ( T ∈ [ t 1 , t 2 ] ) , t 1 ≤ T ∩ T &lt; t 2 . Although [ t 1 , t 2 ) is mathematically more accurate compared with [ t 1 , t 2 ] , [ t 1 , t 2 ] is easy for us to understand. In Allen’s temporal interval logic , which lacks the concept of a time point , it is not clear whether both edges of the time interval are included in the range of the time interval or not. In our system , we allow an elliptical representation of a time interval such as [ T ] = [ T , T+1 ] , where T+1 denotes the increment of the smallest explicit granularity , e.g. [ 2000 ] = [ 2000,2001 ] , [ 2002/1/31 ] = [ 2002/1/31,2002/2/1 ] . The lifetime of the document is represented as [ /c , /now ] . As mentioned in section 2.1 , there are a large number of relationships between Allen’s time intervals. However , they can all be reduced to relationships between time points and the functions giving the start point and the end point of the time interval. For this reason , CSE does not support interval queries but only point queries. Next , we discuss whether a temporal query is mixed with a keyword query or not. In the case of mixing , the semantics of a query is simple but its implementation is complex. Conversely , without mixing , the semantics of a query is complex but it can be implemented easily. For example , we can use the following query if mixing is allowed. FIFA World Cup and ( ( ( Korea or Japan ) and ( /c in [ 2002 ] ) ) or ( France and ( /c in [ 1998 ] ) ) ) This query searches for both documents that describe the World Cup held in Korea and Japan in 2002 and documents that describe the World Cup held in France in 1998. On the other hand , if mixing is not allowed , the following query could be used. FIFA World Cup and ( Korea or Japan or France ) /c in [ 2002 ] or /c in [ 1998 ] Here , the relationship between keyword query and temporal query is conjunctive. This query searches for documents that describe both the World Cup of France and the World Cup of Korea and Japan in 1998 or 2002. In the latter method , a document describing Korea and Japan in 1998 and another document describing France in 2002 may both be retrieved. Therefore , we employ the former method. Temporal query TQ is represented with BNF as follows : TQ : Q | TQ or TQ | TQ and TQ | TQ and TC | TC and TQ | TQ not TQ | TQ not TC Q : K | Q and Q | Q or Q | Q not Q TC : T v &gt; T c | T v &lt; T c | T v = T c | T v ≤ T c | T v ≥ T c | T v in [ T c ] | T v in [ T c , T c ] | TC or TC | TC and TC Here , K is a keyword , Q is a Boolean expression of keywords , T v is a time point variable , T c is a time point constant , and TC is a temporal query .</sentence>
				<definiendum id="0">K</definiendum>
				<definiendum id="1">Q</definiendum>
				<definiendum id="2">T v</definiendum>
				<definiendum id="3">T c</definiendum>
				<definiendum id="4">TC</definiendum>
				<definiens id="0">the increment of the smallest explicit granularity</definiens>
				<definiens id="1">both documents that describe the World Cup held in Korea and Japan in 2002 and documents that describe the World Cup held in France</definiens>
				<definiens id="2">follows : TQ : Q | TQ or TQ | TQ and TQ | TQ and TC | TC and TQ | TQ not TQ | TQ not TC Q : K | Q and Q | Q or Q | Q not Q TC : T v &gt; T c | T v &lt; T c | T v = T c | T v ≤ T c | T v ≥ T c | T v in [ T c ] | T v in [ T c , T c ] | TC or TC</definiens>
				<definiens id="3">a keyword</definiens>
				<definiens id="4">a Boolean expression of keywords</definiens>
				<definiens id="5">a temporal query</definiens>
			</definition>
			<definition id="4">
				<sentence>Namazu searches HTML documents with HTTP headers and e-mail like documents by using a regular expression involving time .</sentence>
				<definiendum id="0">Namazu</definiendum>
				<definiens id="0">searches HTML documents with HTTP headers and e-mail like documents by using a regular expression involving time</definiens>
			</definition>
			<definition id="5">
				<sentence>CSE realizes regular response time regardless of its scale .</sentence>
				<definiendum id="0">CSE</definiendum>
			</definition>
			<definition id="6">
				<sentence>html NAVER , http : //www.naver.com/ Christian S. Jensen : Temporal Database Management , Thesis , http : //www.cs.auc.dk/~csj/Thesis/ Fabio Grandi , Federica Mandreoli , The Valid Web : An XML/XSL Infrastructure for Temporal Management of Web Documents , ADVIS 2000 , pp .</sentence>
				<definiendum id="0">Valid Web</definiendum>
				<definiens id="0">//www.naver.com/ Christian S. Jensen : Temporal Database Management , Thesis , http : //www.cs.auc.dk/~csj/Thesis/ Fabio Grandi</definiens>
			</definition>
</paper>

		<paper id="0613">
			<definition id="0">
				<sentence>Training data consists of music reviews from the Internet correlated echnology and Entertainment Media : Rights and Responsibilities with acoustic recordings of the reviewed music .</sentence>
				<definiendum id="0">Entertainment Media</definiendum>
				<definiens id="0">music reviews from the Internet correlated echnology</definiens>
			</definition>
			<definition id="1">
				<sentence>Each pair { artist , term } retrieved is given an associated salience weight , which indicates the relative importance of term as associated to artist .</sentence>
				<definiendum id="0">associated salience weight</definiendum>
				<definiens id="0">indicates the relative importance of term as associated to artist</definiens>
			</definition>
			<definition id="2">
				<sentence>It is related to the Support Vector Machine ( Vapnik , 1998 ) in that they are both instances of Tikhonov regularization ( Evgeniou et al. , 2000 ) , but whereas training a Support Vector Machine requires the solution of a constrained quadratic programming problem , training RLSC only requires solving a single system of linear equations .</sentence>
				<definiendum id="0">Support Vector Machine</definiendum>
				<definiens id="0">Evgeniou et al. , 2000 ) , but whereas training a Support Vector Machine requires the solution of a constrained quadratic programming problem</definiens>
			</definition>
			<definition id="3">
				<sentence>Kf ( x1 , x2 ) is a generalized dot product ( in a Reproducing Kernel Hilbert Space ( Aronszajn , 1950 ) ) between xi and xj .</sentence>
				<definiendum id="0">Kf</definiendum>
				<definiens id="0">a generalized dot product</definiens>
			</definition>
			<definition id="4">
				<sentence>Then , training an RLSC system consists of solving the system of linear equations ( K + IC ) c = y , ( 2 ) where C is a user-supplied regularization constant .</sentence>
				<definiendum id="0">RLSC system</definiendum>
				<definiens id="0">consists of solving the system of linear equations ( K + IC ) c = y , ( 2 ) where C is a user-supplied regularization constant</definiens>
			</definition>
			<definition id="5">
				<sentence>P ( an ) indicates overall negative accuracy , P ( a ) is defined as P ( ap ) P ( an ) , which should remain significant even in the face of extreme negative output class bias .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">P ( a )</definiendum>
				<definiens id="0">P ( ap ) P ( an ) , which should remain significant even in the face of extreme negative output class bias</definiens>
			</definition>
			<definition id="6">
				<sentence>WordNet ( Miller , 1990 ) is a lexical database handdeveloped by lexicographers .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a lexical database handdeveloped by lexicographers</definiens>
			</definition>
			<definition id="7">
				<sentence>Schemes like PCA or MDS would simply use the euclidean distance to do this , where Isomap operates on prior knowledge of the structure within the data .</sentence>
				<definiendum id="0">Isomap</definiendum>
			</definition>
</paper>

		<paper id="1719">
			<definition id="0">
				<sentence>The suffixes “o” and “c” will be used to denote open and closed tracks , respectively : Thus “ASo , c” denotes the Academia Sinica corpus , both open and closed tracks ; and “PKc” denotes the Beijing University corpus , closed track .</sentence>
				<definiendum id="0">Academia Sinica corpus</definiendum>
				<definiendum id="1">“PKc”</definiendum>
				<definiens id="0">the Beijing University corpus , closed track</definiens>
			</definition>
			<definition id="1">
				<sentence>The script used for scoring can be downloaded from http : //www.sighan.org/ bakeoff2003/score ; it is a simple Perl script that depends upon a version of diff ( e.g. GNU diffutils 2.7.2 ) , that supports the -y flag for side-by-side output format .</sentence>
				<definiendum id="0">script used for scoring</definiendum>
				<definiens id="0">a simple Perl script that depends upon a version of diff ( e.g. GNU diffutils 2.7.2</definiens>
			</definition>
			<definition id="2">
				<sentence>However , The PKU corpus includes characters that are not part of GB 2312-80 , but are encoded in GBK .</sentence>
				<definiendum id="0">PKU corpus</definiendum>
				<definiens id="0">includes characters that are not part of GB 2312-80 , but are encoded in GBK</definiens>
			</definition>
			<definition id="3">
				<sentence>Per normal usage , OOV is defined as the set of words in the test corpus not occurring in the training corpus.2 We expect systems to do at least as well as this baseline .</sentence>
				<definiendum id="0">OOV</definiendum>
				<definiens id="0">the set of words in the test corpus not occurring in the training corpus.2 We expect systems to do at least as well as this baseline</definiens>
			</definition>
			<definition id="4">
				<sentence>However as we can see from the scores in Table 4 , such cases constitute at most about Corpus word count R P F OOV Ra0a1a0a3a2 Ra4a2 AS 11,985 0.917 0.912 0.915 0.022 0.000 0.938 CTB 39,922 0.800 0.663 0.725 0.181 0.062 0.962 HK 34,955 0.908 0.830 0.867 0.071 0.037 0.974 PK 17,194 0.909 0.829 0.867 0.069 0.050 0.972 Table 3 : Baseline scores : Results for maximum matching using only words from training data Corpus word count R P F OOV Ra0a1a0a3a2 Ra4a2 AS 11,985 0.990 0.993 0.992 0.022 0.988 0.990 CTB 39,922 0.982 0.988 0.985 0.181 0.990 0.980 HK 34,955 0.986 0.991 0.989 0.071 0.996 0.985 PK 17,194 0.995 0.996 0.995 0.069 1.000 0.994 Table 4 : Topline ( “cheating” ) scores : Results for maximum matching using only words from testing data data as a0a2a1 a3 a26a5a4a7a6a9a8 a26a11a10a13a12a15a14 , where a14 is the number of trials ( words ) .</sentence>
				<definiendum id="0">a14</definiendum>
				<definiens id="0">Baseline scores : Results for maximum matching using only words from training data Corpus word</definiens>
				<definiens id="1">the number of trials ( words )</definiens>
			</definition>
			<definition id="5">
				<sentence>We include as “BASE” , and “TOP” the baseline and topline scores discussed previously .</sentence>
				<definiendum id="0">“TOP”</definiendum>
				<definiens id="0">the baseline and topline scores discussed previously</definiens>
			</definition>
</paper>

		<paper id="1306">
			<definition id="0">
				<sentence>Dictionary-based protein name recognition is the first step for practical information extraction from biomedical documents because it provides ID information of recognized terms unlike machine learning based approaches .</sentence>
				<definiendum id="0">Dictionary-based protein name recognition</definiendum>
				<definiens id="0">the first step for practical information extraction from biomedical documents because it provides ID information of recognized terms unlike machine learning based approaches</definiens>
			</definition>
			<definition id="1">
				<sentence>2The Swiss-Prot is an annotated protein sequence database .</sentence>
				<definiendum id="0">Swiss-Prot</definiendum>
				<definiens id="0">an annotated protein sequence database</definiens>
			</definition>
			<definition id="2">
				<sentence>In this case , “NK” is an abbreviation of “natural killer” and is not a protein name .</sentence>
				<definiendum id="0">“NK”</definiendum>
				<definiens id="0">an abbreviation of “natural killer”</definiens>
			</definition>
			<definition id="3">
				<sentence>The naive Bayes classifier is a simple but effective classifier which has been used in numerous applications of information processing such as image recognition , natural language processing and information retrieval ( Lewis , 1998 ; Escudero et al. , 2000 ; Pedersen , 2000 ; Nigam and Ghani , 2000 ) .</sentence>
				<definiendum id="0">naive Bayes classifier</definiendum>
				<definiendum id="1">retrieval</definiendum>
				<definiens id="0">a simple but effective classifier which has been used in numerous applications of information processing such as image recognition , natural language processing and information</definiens>
			</definition>
			<definition id="4">
				<sentence>By assuming the conditional independence among the elements of a vector , P ( ~xjck ) is decomposed as follows , P ( ~xjck ) = dY j=1 P ( xjjck ) ; ( 6 ) where xj is the jth element of vector ~x. Then Equation 5 becomes P ( ckj~x ) = P ( ck ) Qd j=1 P ( xjjck ) P ( ~x ) ( 7 ) By this equation , we can calculate P ( ckj~x ) and classify ~x into the class with the highest P ( ckj~x ) .</sentence>
				<definiendum id="0">xj</definiendum>
				<definiendum id="1">P ( ~x )</definiendum>
				<definiens id="0">the jth element of vector ~x. Then Equation 5 becomes P ( ckj~x ) = P ( ck ) Qd j=1 P ( xjjck )</definiens>
			</definition>
			<definition id="5">
				<sentence>Wend : the last word of the term .</sentence>
				<definiendum id="0">Wend</definiendum>
			</definition>
			<definition id="6">
				<sentence>Wmiddle : the other words of the term without positional information ( bag-of-words ) .</sentence>
				<definiendum id="0">Wmiddle</definiendum>
				<definiens id="0">the other words of the term without positional information ( bag-of-words )</definiens>
			</definition>
			<definition id="7">
				<sentence>The GENIA corpus is an annotated corpus , which contains 2000 abstracts extracted from MEDLINE database .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiendum id="1">annotated corpus</definiendum>
				<definiens id="0">contains 2000 abstracts extracted from MEDLINE database</definiens>
			</definition>
			<definition id="8">
				<sentence>F-measure is defined as the harmonic mean for precision and recall as follows : F = 2 precision recallprecision + recall ( 8 ) Table 2 : Precision Improvement by Filtering Precision Recall F-measure w/o filtering 48.6 70.7 57.6 with filtering 74.3 65.3 69.5 Table 3 : Recall Improvement by Approximate String Search Threshold Precision Recall F-measure 10.0 72.6 67.7 70.0 The first row shows the performances achieved without filtering .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiens id="0">the harmonic mean for precision and recall as follows : F = 2 precision recallprecision + recall ( 8 ) Table 2 : Precision Improvement by Filtering Precision Recall F-measure w/o filtering 48.6 70.7 57.6 with filtering 74.3 65.3 69.5 Table 3 : Recall Improvement by Approximate String Search Threshold Precision Recall</definiens>
			</definition>
			<definition id="9">
				<sentence>False recognition , which is a common problem of dictionary-based approaches , is suppressed by a classifier trained on an annotated corpus .</sentence>
				<definiendum id="0">False recognition</definiendum>
				<definiens id="0">a common problem of dictionary-based approaches , is suppressed by a classifier trained on an annotated corpus</definiens>
			</definition>
</paper>

		<paper id="0812">
			<definition id="0">
				<sentence>Given a system description and modules that implement a minimal interface , the SDL compiler returns a running Java program which realizes exactly the desired behavior of the original speci£cation .</sentence>
				<definiendum id="0">SDL compiler</definiendum>
				<definiens id="0">realizes exactly the desired behavior of the original speci£cation</definiens>
			</definition>
			<definition id="1">
				<sentence>The SDL compiler is part of the SProUT shallow language platform , a system for the development and processing of multilingual resources .</sentence>
				<definiendum id="0">SDL compiler</definiendum>
			</definition>
			<definition id="2">
				<sentence>In this paper , we focus on a general system description language , called SDL , which allows the declarative speci£cation of NLP systems from a set of already existing base modules .</sentence>
				<definiendum id="0">SDL</definiendum>
				<definiens id="0">a general system description language , called</definiens>
			</definition>
			<definition id="3">
				<sentence>+ here is the analogue to functional composition – , and so we de£ne the meaning ( or abstract semantics ) [ [ ¢ ] ] of m1 + m2 as [ [ m1 + m2 ] ] ( ~s ) : = ( m2 –m1 ) ( ~s ) = m2 ( m1 ( ~s ) ) m1 + m2 then is well-de£ned if m1 # , m2 # , and T1 S2 is the case , due to the following biconditional : m1 # ; m2 # ; T1 S2 ( ) ( m1 –m2 : S1 ¡ !</sentence>
				<definiendum id="0">T1 S2</definiendum>
				<definiendum id="1">T1 S2 ( )</definiendum>
				<definiens id="0">the analogue to functional composition – , and so we de£ne the meaning ( or abstract semantics</definiens>
			</definition>
			<definition id="4">
				<sentence>„ is a functional and so , given a function f as its input , returns a new function „ ( f ) , the unbounded minimization of f. Originally employed to precisely de£ne ( partial ) recursive functions of natural numbers , we need a slight generalization , so that we can apply „ to functions , not necessarily operating on natural numbers .</sentence>
				<definiendum id="0">„</definiendum>
				<definiens id="0">a functional and so , given a function f as its input , returns a new function „ ( f ) , the unbounded minimization of f. Originally employed to precisely de£ne ( partial ) recursive functions of natural numbers</definiens>
			</definition>
			<definition id="5">
				<sentence>† getOutput ( ) returns the output originally given to setOutput ( ) .</sentence>
				<definiendum id="0">† getOutput ( )</definiendum>
			</definition>
			<definition id="6">
				<sentence>Local variables ( pre£xed by the low line character ) are also introduced for the individual run ( ) methods ( 15 , : : : , 23 below ) .</sentence>
				<definiendum id="0">Local variables</definiendum>
				<definiens id="0">pre£xed by the low line character ) are also introduced for the individual run</definiens>
			</definition>
</paper>

		<paper id="1506">
			<definition id="0">
				<sentence>The proposed lexical analyzer allows us to define arbitrary properties other than those defined by the Unicode standard .</sentence>
				<definiendum id="0">lexical analyzer</definiendum>
				<definiens id="0">allows us to define arbitrary properties other than those defined by the Unicode standard</definiens>
			</definition>
			<definition id="1">
				<sentence>System Overview NE recognized text ( local code ) Language X Plain text ( local code ) Lexical Analysis Rule Character Code Converter ( local code to Unicode ) Character Code Converter ( Unicode to local code ) Lexical Analyzer Word Candidates JP CN Statistical Language Model ( Dictionaries ) KR EN NE Recognizer Morph AnalyzerN-best Word Sequence Search Analytical Engine Table 1 shows the varieties of character types in each language .</sentence>
				<definiendum id="0">Dictionaries ) KR EN NE Recognizer Morph AnalyzerN-best Word Sequence Search Analytical</definiendum>
				<definiens id="0">local code ) Language X Plain text ( local code ) Lexical Analysis Rule Character Code Converter ( local code to Unicode ) Character Code Converter ( Unicode to local code ) Lexical Analyzer Word Candidates JP CN Statistical Language Model</definiens>
			</definition>
			<definition id="2">
				<sentence>The analytical engine consists of N-best word sequence search and a statistical language model .</sentence>
				<definiendum id="0">analytical engine</definiendum>
				<definiens id="0">consists of N-best word sequence search and a statistical language model</definiens>
			</definition>
			<definition id="3">
				<sentence>Here , NC represents the type of named entity such as organization , personal name , or location .</sentence>
				<definiendum id="0">NC</definiendum>
				<definiens id="0">the type of named entity such as organization , personal name , or location</definiens>
			</definition>
			<definition id="4">
				<sentence>| ( ij xyt is translation probability and is estimated by applying the EM algorithm to a large number of parallel texts .</sentence>
				<definiendum id="0">ij xyt</definiendum>
				<definiens id="0">translation probability and is estimated by applying the EM algorithm to a large number of parallel texts</definiens>
			</definition>
</paper>

		<paper id="1900">
</paper>

		<paper id="0801">
			<definition id="0">
				<sentence>The TEXTRACT Architecture : Overview TEXTRACT is a robust document analysis framework , whose design has been motivated by the requirements of an operational system capable of efficient processing of thousands of documents/gigabytes of data .</sentence>
				<definiendum id="0">TEXTRACT Architecture</definiendum>
				<definiens id="0">a robust document analysis framework , whose design has been motivated by the requirements of an operational system capable of efficient processing of thousands of documents/gigabytes of data</definiens>
			</definition>
			<definition id="1">
				<sentence>The common architecture features it shares with TAF include : • interchangeable document parsers allow the ‘ingestion’ of source documents in more than one format ( specifically , XML , HTML , ASCII , as well as a range of proprietary ones ) ; • a document model provides an abstraction layer between the character-based document stream and annotation-based document components , both structurally derived ( such as paragraphs and sections ) and linguistically discovered ( such as named entities , terms , or phrases ) ; • linguistic analysis functionalities are provided via tightly coupled individual plugin components ; these share the annotation repository , lexical cache , and vocabulary and communicate with each other by posting results to , and reading prior analyses from , them ; • plugins share a common interface , and are dispatched by a plugin manager according to declared dependencies among plugins ; a resource manager controls shared resources such as lexicons , glossaries , or gazetteers ; and at a higher level of abstraction , an engine maintains the document processing cycle ; • the system and individual plugins are softly configurable , completely from the outside ; • the architecture allows for processing of a stream of documents ; furthermore , by means of collection-level plugins and applications , crossdocument analysis and statistics can be derived for entire document collections .</sentence>
				<definiendum id="0">ASCII</definiendum>
				<definiendum id="1">reading</definiendum>
				<definiens id="0">such as paragraphs and sections ) and linguistically discovered ( such as named entities , terms , or phrases</definiens>
			</definition>
			<definition id="2">
				<sentence>TEXTRACT is industrial strength ( IBM , 1997 ) , Unicodeready , and language-independent ( currently , analysis functionalities are implemented primarily for English ) .</sentence>
				<definiendum id="0">TEXTRACT</definiendum>
				<definiens id="0">industrial strength ( IBM , 1997 ) , Unicodeready , and language-independent ( currently , analysis functionalities are implemented primarily for English )</definiens>
			</definition>
			<definition id="3">
				<sentence>TEXTRACT is ‘populated’ by a number of plugins , providing functionalities for : • tokenization ; • document structure analysis , from tags and white space ; • lexicon interface , complete with efficient lookup and full morphology ; • importation of lexical and vocabulary analyses from a non-TEXTRACT process via XML markup ; • analysis of out-of-vocabulary words ( Park , 2002 ) ; • abbreviation finding and expansion ( Park and Byrd , 2001 ) ; • named entity identification and classification ( person names , organizations , places , and so forth ) ( Ravin and Wacholder , 1997 ) ; • technical term identification , in technical prose ( Justeson and Katz , 1995 ) ; • vocabulary determination and glossary extraction , in specialized domains ( Park et al. , 2002 ) ; • vocabulary aggregation , with reduction to canonical form , within and across documents ; • part-of-speech tagging ( with different taggers ) for determining syntactic categories in context ; • shallow syntactic parsing , for identifying phrasal and clausal constructs and semantic relations ( Boguraev , 2000 ) ; • salience calculations , both of interand intradocument salience ; • analysis of topic shifts within a document ( Boguraev and Neff , 2000a ) ; • document clustering , cluster organization , and cluster labeling ; • single document summarization , configurable to deploy different algorithmic schemes ( sentence extraction , topical highlights , lexical cohesion ) ( Boguraev and Neff , 2000a , 2000b ) ; • multi-document summarization , using iterative residual rescaling ( Ando et al. , 2000 ) ; • pattern matching , deploying finite state technology specially designed to operate over document content abstractions ( as opposed to a character stream alone ) .</sentence>
				<definiendum id="0">TEXTRACT</definiendum>
				<definiens id="0">complete with efficient lookup and full morphology ; • importation of lexical and vocabulary analyses from a non-TEXTRACT process via XML markup ; • analysis of out-of-vocabulary words</definiens>
				<definiens id="1">organizations , places , and so forth ) ( Ravin and Wacholder , 1997 ) ; • technical term identification</definiens>
				<definiens id="2">designed to operate over document content abstractions ( as opposed to a character stream alone )</definiens>
			</definition>
			<definition id="4">
				<sentence>The annotation repository owns the type system and pre-populates it at startup time .</sentence>
				<definiendum id="0">annotation repository</definiendum>
				<definiens id="0">owns the type system and pre-populates it at startup time</definiens>
			</definition>
			<definition id="5">
				<sentence>The annotation repository has a container of annotations ordered on start location ( ascending ) , end location ( descending ) , priority of type family ( descending ) , priority within type family ( descending ) , and type name ( ascending ) .</sentence>
				<definiendum id="0">annotation repository</definiendum>
				<definiendum id="1">end location</definiendum>
				<definiendum id="2">type name</definiendum>
				<definiens id="0">has a container of annotations ordered on start location ( ascending )</definiens>
			</definition>
			<definition id="6">
				<sentence>Figure 2 is broadly indicative of some of the functional components exposed : in particular , it exemplifies a working context for a grammar writer , which includes an interface for setting operational parameters , a grammar editor/compiler , and multiple viewers for the results of the pattern match , mediated via the annotation repository , and making use of different presentation perspectives ( e.g. a parse tree for structural analysis , concordance for pattern matching , and so forth . )</sentence>
				<definiendum id="0">multiple</definiendum>
				<definiens id="0">viewers for the results of the pattern match , mediated via the annotation repository</definiens>
			</definition>
			<definition id="7">
				<sentence>The lexical lookup ( lexalyzer ) plugin populates the lexical cache with tokens , their lemma forms , and morpho-syntactic features .</sentence>
				<definiendum id="0">lexical lookup ( lexalyzer ) plugin</definiendum>
				<definiens id="0">populates the lexical cache with tokens , their lemma forms , and morpho-syntactic features</definiens>
			</definition>
			<definition id="8">
				<sentence>Morpho-syntactic features are encoded in an interchange format which mediates among notations of different granularities ( of syntactic feature distinctions or morphological ambiguity ) , used by dictionaries ( we use the IBM LanguageWare dictionaries , available for over 30 languages ) , tag sets , and finite state grammar symbols .</sentence>
				<definiendum id="0">IBM LanguageWare</definiendum>
				<definiens id="0">dictionaries , available for over 30 languages ) , tag sets</definiens>
			</definition>
			<definition id="9">
				<sentence>Plugin Example : TEXTRACT’s Finite State Transducer Numerous NLP applications today deploy finite state ( FS ) processing techniques—for , among other things , efficiency of processing , perspicuity of representation , rapid prototyping , and grammar reusability ( see , for instance , Karttunen et al. , 1996 ; Kornai , 1999 ) .</sentence>
				<definiendum id="0">grammar reusability</definiendum>
				<definiens id="0">TEXTRACT’s Finite State Transducer Numerous NLP applications today deploy finite state ( FS ) processing techniques—for , among other things , efficiency of processing , perspicuity of representation , rapid prototyping , and</definiens>
			</definition>
			<definition id="10">
				<sentence>The FST plugin therefore incorporates logic in its reInit ( ) method which scans an FST file ( itself generated by an FST compiler typically running in the background ) , and determines— by deferring to a symbol compiler—what new annotation types and attribute features need to be dynamically configured and incrementally added to the model .</sentence>
				<definiendum id="0">FST plugin</definiendum>
				<definiendum id="1">FST file</definiendum>
				<definiens id="0">itself generated by an FST compiler typically running in the background ) , and determines— by deferring to a symbol compiler—what new annotation types and attribute features need to be dynamically configured and incrementally added to the model</definiens>
			</definition>
			<definition id="11">
				<sentence>The Talent system , and TEXTRACT in particular , belongs to a family of language engineering systems which includes GATE ( University of Sheffield ) , Alembic ( MITRE Corporation ) , ATLAS ( University of Pennsylvania ) , among others .</sentence>
				<definiendum id="0">TEXTRACT</definiendum>
				<definiens id="0">a family of language engineering systems which includes GATE ( University of Sheffield</definiens>
			</definition>
			<definition id="12">
				<sentence>GDM , which corresponds to TEXTRACT’s driver , engine , and plugin manager , is responsible for managing the storage and transmission ( via APIs ) of the annotations created and manipulated by the NLP processing modules in CREOLE .</sentence>
				<definiendum id="0">GDM</definiendum>
				<definiens id="0">corresponds to TEXTRACT’s driver , engine , and plugin manager , is responsible for managing the storage and transmission ( via APIs ) of the annotations created and manipulated by the NLP processing modules in CREOLE</definiens>
			</definition>
			<definition id="13">
				<sentence>In TEXTRACT’s terms , the GDM is responsible for the data model kept in the document and collection objects .</sentence>
				<definiendum id="0">GDM</definiendum>
				<definiens id="0">responsible for the data model kept in the document and collection objects</definiens>
			</definition>
			<definition id="14">
				<sentence>Cunningham , et al. ( 1997 ) emphasize that CREOLE modules , which can encapsulate both algorithmic and data resources , are mainly created by wrapping preexisting code to meet the GDM APIs .</sentence>
				<definiendum id="0">Cunningham</definiendum>
			</definition>
			<definition id="15">
				<sentence>Alembic , built for participation in the MUC conferences and adhering to the TIPSTER API ( Grishman , 1996 ) , incorporates automated annotators ( “plugins” ) for word/sentence tokenization , part-of-speech tagging , person/ organization/ location/ date recognition , and coreference analysis .</sentence>
				<definiendum id="0">Alembic</definiendum>
				<definiendum id="1">TIPSTER API</definiendum>
				<definiens id="0">incorporates automated annotators ( “plugins” ) for word/sentence tokenization , part-of-speech tagging</definiens>
			</definition>
			<definition id="16">
				<sentence>Alembic incorporates ATLAS’s “annotation graphs” as its logical representation for annotations .</sentence>
				<definiendum id="0">Alembic</definiendum>
				<definiens id="0">incorporates ATLAS’s “annotation graphs” as its logical representation for annotations</definiens>
			</definition>
			<definition id="17">
				<sentence>Annotation graphs reside in “annotation sets , ” which are closest in spirit to TEXTRACT’s annotation repository , although they do n't apparently provide APIs for finegrained manipulation of , and filtered iterations over , the stored annotations .</sentence>
				<definiendum id="0">Annotation graphs</definiendum>
			</definition>
			<definition id="18">
				<sentence>Rather , ATLAS exports physical representations of annotation sets as XML files or relational data bases containing stand-off annotations , which may then be processed by external applications .</sentence>
				<definiendum id="0">ATLAS</definiendum>
				<definiens id="0">exports physical representations of annotation sets as XML files or relational data bases containing stand-off annotations</definiens>
			</definition>
			<definition id="19">
				<sentence>As a result , TEXTRACT uses a homogeneous implementation style for its annotation and application plugins , with a tight coupling to the underlying shared analysis data model .</sentence>
				<definiendum id="0">TEXTRACT</definiendum>
				<definiens id="0">uses a homogeneous implementation style for its annotation and application plugins</definiens>
			</definition>
</paper>

		<paper id="1703">
			<definition id="0">
				<sentence>Due to the improvement of speech recognition technology , spoken language user interfaces , spoken dialogue systems , and speech translation systems are no longer only laboratory dreams .</sentence>
				<definiendum id="0">speech translation systems</definiendum>
				<definiens id="0">spoken language user interfaces , spoken dialogue systems , and</definiens>
			</definition>
			<definition id="1">
				<sentence>Further , we simply integrate the two N-gram methods and propose a bi-directional N-gram method ( BN ) , which takes into account both the left and the right context of a candidate segmentation site .</sentence>
				<definiendum id="0">BN</definiendum>
				<definiens id="0">takes into account both the left and the right context of a candidate segmentation site</definiens>
			</definition>
			<definition id="2">
				<sentence>The value of ) ... ( 121 +ii SBWWWWP and ) ... ( 121 +ii WWWWP will determine whether a specific word ) 1 ( miW i ≤≤ is the final word of a sentence .</sentence>
				<definiendum id="0">miW i ≤≤</definiendum>
				<definiens id="0">the final word of a sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Since we consider information concerning the lexical context to be useful , we define the feature functions for our maximum method as follows :    == = else bScefixincludeif cbf j j 0 ) 0 &amp; &amp; ) ) , ( ( Pr ( 1 ) , ( 10    == = else bScefixincludeif cbf j j 0 ) 1 &amp; &amp; ) ) , ( ( Pr ( 1 ) , ( 11    == = else bScSuffixincludeif cbf j j 0 ) 0 &amp; &amp; ) ) , ( ( ( 1 ) , ( 20    == = else bScSuffixincludeif cbf j j 0 ) 1 &amp; &amp; ) ) , ( ( ( 1 ) , ( 21 S j denotes a sequence of one or more words which we can call the Matching String .</sentence>
				<definiendum id="0">S j</definiendum>
				<definiens id="0">a sequence of one or more words which we can call the Matching String</definiens>
			</definition>
			<definition id="4">
				<sentence>Prefix ( c ) denotes all the word sequences ending with c ( that is , c 's left context plus c ) and Suffix ( c ) denotes all the word sequences beginning with c ( in other words , c plus its right context ) .</sentence>
				<definiendum id="0">Prefix ( c )</definiendum>
				<definiendum id="1">Suffix ( c )</definiendum>
				<definiens id="0">denotes all the word sequences ending with c ( that is , c 's left context plus c</definiens>
				<definiens id="1">denotes all the word sequences beginning with c ( in other words , c plus its right context )</definiens>
			</definition>
			<definition id="5">
				<sentence>Thus the joint probability distribution of the candidate sites and their surrounding contexts is given by : ) ( ) , ( 1 ) , ( 21 ) , ( 20 ) , ( 11 ) , ( 10 21201110 ∏ = ×××= k j cbf j cbf j cbf j cbf j jjjj bcP ααααπ where k is the total number of the Matching Strings and π is a parameter set to make P ( c,1 ) and P ( c,0 ) sum to 1 .</sentence>
				<definiendum id="0">surrounding contexts</definiendum>
				<definiendum id="1">k</definiendum>
				<definiens id="0">the total number of the Matching Strings and π is a parameter set to make P ( c,1 ) and P ( c,0 ) sum to 1</definiens>
			</definition>
			<definition id="6">
				<sentence>Since the maximum entropy parameters for MEBN algorithm are used as modifying NN and RN , we just estimate the joint probability of the candidate and its surrounding contexts based upon the segments by NN and RN .</sentence>
				<definiendum id="0">maximum entropy parameters</definiendum>
				<definiens id="0">the joint probability of the candidate and its surrounding contexts based upon the segments by NN and RN</definiens>
			</definition>
			<definition id="7">
				<sentence>If we use “RightNum” to denote the number of right segmentations , “WrongNum” denote the number of wrong segmentations , and “TotalNum” to denote the number of segmentations in the original testing corpus , the precision ( P ) can be computed using the formula P=RightNum/ ( RightNum+WrongNum ) , the recall ( R ) is computed as R=RightNum/TotalNum , and the F-Score is computed as F-Score = RP RP + ××2 .</sentence>
				<definiendum id="0">“WrongNum” denote</definiendum>
				<definiendum id="1">formula P=RightNum/</definiendum>
				<definiendum id="2">R</definiendum>
				<definiendum id="3">F-Score</definiendum>
				<definiens id="0">the number of wrong segmentations</definiens>
			</definition>
			<definition id="8">
				<sentence>For RN , BN and MEBN , suppose TN denotes the number of total segmentations , CON denotes the number of correct segmentations overlapping with those found by NN ; SWN denotes the number of wrong NN segmentations which were skipped ; WNON denotes the number of wrong segmentations not overlapping with those of NN ; and CNON denotes the number of segmentations which were correct but did not overlap with those of NN .</sentence>
				<definiendum id="0">MEBN</definiendum>
				<definiendum id="1">TN</definiendum>
				<definiendum id="2">CON</definiendum>
				<definiendum id="3">SWN</definiendum>
				<definiendum id="4">WNON</definiendum>
				<definiendum id="5">CNON</definiendum>
				<definiens id="0">the number of total segmentations</definiens>
				<definiens id="1">the number of correct segmentations overlapping with those found by NN</definiens>
				<definiens id="2">the number of wrong NN segmentations which were skipped ;</definiens>
				<definiens id="3">the number of wrong segmentations not overlapping with those of NN</definiens>
				<definiens id="4">the number of segmentations which were correct but did not overlap with those of NN</definiens>
			</definition>
</paper>

		<paper id="1312">
			<definition id="0">
				<sentence>Perceptron is a simple iterative learning algorithm that represents in its simplest form a two-layer ( input/output ) neural network where each node in the input layer is connected to each node in the output layer .</sentence>
				<definiendum id="0">Perceptron</definiendum>
				<definiens id="0">a simple iterative learning algorithm that represents in its simplest form a two-layer ( input/output ) neural network where each node in the</definiens>
			</definition>
			<definition id="1">
				<sentence>The Bayes decision rule chooses the class that maximizes the conditional probability of the class given the context in which it occurs : ( 1 ) C` = argmax ) | ( ) ( 1 CVPCP n j j∏ = Here , C` is the chosen category , C is the set of all categories and V j is the context .</sentence>
				<definiendum id="0">Bayes decision rule</definiendum>
				<definiendum id="1">C`</definiendum>
				<definiendum id="2">C</definiendum>
				<definiens id="0">chooses the class that maximizes the conditional probability of the class given the context in which it occurs : ( 1 ) C` = argmax ) |</definiens>
				<definiens id="1">the set of all categories</definiens>
				<definiens id="2">the context</definiens>
			</definition>
			<definition id="2">
				<sentence>A particular implementation of the Naïve Bayes decision rule based on the independence assumption to text categorization and word sense disambiguation problems is also known as “bag of words” approach [ 13 ] .</sentence>
				<definiendum id="0">particular implementation of the Naïve Bayes decision rule</definiendum>
			</definition>
			<definition id="3">
				<sentence>The MeSH classification is available as part of the UMLS ( Unified Medical Language System ) compiled and distributed by the National Library of Medicine ( NLM ) [ 9 ] .</sentence>
				<definiendum id="0">NLM</definiendum>
				<definiens id="0">available as part of the UMLS ( Unified Medical Language System</definiens>
			</definition>
			<definition id="4">
				<sentence>HICDA is a hierarchical classification with 19 root nodes and 4,334 leaf nodes .</sentence>
				<definiendum id="0">HICDA</definiendum>
				<definiens id="0">a hierarchical classification with 19 root nodes and 4,334 leaf nodes</definiens>
			</definition>
			<definition id="5">
				<sentence>The second type ( Type II ) is the data annotated by Emeritus physicians ( experts ) .</sentence>
				<definiendum id="0">Type II</definiendum>
				<definiens id="0">the data annotated by Emeritus physicians ( experts )</definiens>
			</definition>
			<definition id="6">
				<sentence>( 2 ) FNFPTNTP TNTP Acc +++ + ∗= 100 Where TP represents the number of times the classifier guessed a correct positive value ( true positives ) , TN is the number of times the classifier correctly guessed a negative value ( true negatives ) , FP is the number of times the classifier predicted a positive value but the correct value was negative ( false positives ) and the FN ( false negatives ) is the inverse of FP .</sentence>
				<definiendum id="0">TP</definiendum>
				<definiendum id="1">TN</definiendum>
				<definiendum id="2">FP</definiendum>
				<definiens id="0">the number of times the classifier guessed a correct positive value ( true positives ) ,</definiens>
				<definiens id="1">the number of times the classifier correctly guessed a negative value ( true negatives ) ,</definiens>
				<definiens id="2">the number of times the classifier predicted a positive value but the correct value was negative ( false positives ) and the FN ( false negatives</definiens>
				<definiens id="3">the inverse of FP</definiens>
			</definition>
</paper>

		<paper id="0809">
			<definition id="0">
				<sentence>Interface specifications are an important part of the computational infrastructure in engineering language technology ( LT ) systems .</sentence>
				<definiendum id="0">Interface specifications</definiendum>
				<definiens id="0">an important part of the computational infrastructure in engineering language technology ( LT ) systems</definiens>
			</definition>
			<definition id="1">
				<sentence>The OIL language employs frame semantics and provides most of the modeling primitives commonly used in frame-based knowledge representation systems .</sentence>
				<definiendum id="0">OIL language</definiendum>
				<definiens id="0">employs frame semantics and provides most of the modeling primitives commonly used in frame-based knowledge representation systems</definiens>
			</definition>
			<definition id="2">
				<sentence>OIL-RDFS definition is a directed acyclic graph , while XMLS establish a tree structure .</sentence>
				<definiendum id="0">OIL-RDFS definition</definiendum>
				<definiens id="0">a directed acyclic graph</definiens>
			</definition>
			<definition id="3">
				<sentence>Step 1 Mapping of class definitions : According to this ontology , the class WatchPerceptualProcess is a subclass of PerceptualProcess , and its instances have an object to be watched , i.e. AvEntertainment .</sentence>
				<definiendum id="0">WatchPerceptualProcess</definiendum>
				<definiens id="0">a subclass of PerceptualProcess , and its instances have an object to be watched</definiens>
			</definition>
			<definition id="4">
				<sentence>We support the transformation of the following slot fillers : A non-final class definition : A non-final class in the ontology is a class having further subclasses in the generalization hierarchy .</sentence>
				<definiendum id="0">non-final class definition</definiendum>
				<definiens id="0">a class having further subclasses in the generalization hierarchy</definiens>
			</definition>
			<definition id="5">
				<sentence>The main objective of our approach is , however , to bring semantics to XML documents , i.e. , derive appropriate interface specifications from the given domain model , thereby enabling highquality reasoning immediately on the XMLS level .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">documents , i.e. , derive appropriate interface specifications from the given domain model</definiens>
			</definition>
</paper>

		<paper id="1301">
			<definition id="0">
				<sentence>1 FlyBase is a database that focuses on research in the genetics and molecular biology of the fruit fly ( Drosophila melangasIncreasingly , biological databases serve to collect and organize published experimental results .</sentence>
				<definiendum id="0">FlyBase</definiendum>
				<definiens id="0">a database that focuses on research in the genetics and molecular biology of the fruit fly ( Drosophila melangasIncreasingly , biological databases serve to collect and organize published experimental results</definiens>
			</definition>
			<definition id="1">
				<sentence>As a result , curation is a time-consuming and expensive process ; database curators are increasingly eager to adopt text mining and natural language processing techniques to make curation faster and more consistent .</sentence>
				<definiendum id="0">curation</definiendum>
			</definition>
			<definition id="2">
				<sentence>For FlyBase , Drosophila genes are the key biological entities ; each entity ( e.g. , gene ) is associated with a unique identifier for the underlying physical entity .</sentence>
				<definiendum id="0">Drosophila genes</definiendum>
				<definiens id="0">the key biological entities</definiens>
			</definition>
			<definition id="3">
				<sentence>A single entity ( as represented by a unique identifier ) may have a number of names like Toll or even ATPα , which has 38 synonyms listed in FlyBase .</sentence>
				<definiendum id="0">single entity</definiendum>
				<definiens id="0">has 38 synonyms listed in FlyBase</definiens>
			</definition>
			<definition id="4">
				<sentence>We found 35,971 genes with associated ‘gene symbols’ ( e.g. Tl is the gene symbol for Toll ) and 48,434 synonyms ; therefore , each gene has an average of 2.3 alternate naming forms , including the gene symbol .</sentence>
				<definiendum id="0">e.g. Tl</definiendum>
				<definiens id="0">the gene symbol for Toll</definiens>
			</definition>
			<definition id="5">
				<sentence>Our evaluation metric ard metric used in named entity Abstracts from PubMed Lexicon FlyBase Large Quantity of Noisy Training Data Plain Text Genes Tagged Gene1 Gene2 Other1 Other2 Start End Text automatically tagged using FlyBase references and a lexicon is used to train up a tagger capable of tagging gene names in new text , including gene names never observed before .</sentence>
				<definiendum id="0">metric ard metric</definiendum>
				<definiens id="0">used in named entity Abstracts from PubMed Lexicon FlyBase Large</definiens>
			</definition>
</paper>

		<paper id="1604">
			<definition id="0">
				<sentence>Technical documentation is characterised by vast amounts of domain-speci c terminology , which needs to be exploited for providing intelligent access to the information contained in the manuals ( Rinaldi et al. , 2002b ) .</sentence>
				<definiendum id="0">c terminology</definiendum>
				<definiens id="0">needs to be exploited for providing intelligent access to the information contained in the manuals</definiens>
			</definition>
			<definition id="1">
				<sentence>An on-line demo of ExtrAns can be found at the project web page.3 Knowledge Base Document Linguistic Analysis Term processing Figure 2 : O -line Processing of Documents More recently we tackled a di erent domain , the Airplane Maintenance Manuals ( AMM ) of the Airbus A320 ( Rinaldi et al. , 2002b ) , which o ered the additional challenges of an SGML-based format and a much larger size ( 120MB ) .4 Despite being developed initially for a speci c domain , ExtrAns has demonstrated a high level of domain independence .</sentence>
				<definiendum id="0">Airplane Maintenance Manuals</definiendum>
				<definiens id="0">o ered the additional challenges of an SGML-based format</definiens>
			</definition>
			<definition id="2">
				<sentence>The document sentences ( and user queries ) are syntactically processed with the Link Grammar ( LG ) parser ( Sleator and Temperley , 1993 ) which uses a 3http : //www.ifi.unizh.ch/cl/extrans/ 4Still considerably smaller than the size of the document collections used for TREC grammar with a wide coverage of English and has a robust treatment of ungrammatical sentences and unknown words .</sentence>
				<definiendum id="0">Link Grammar</definiendum>
			</definition>
			<definition id="3">
				<sentence>The main feature of the MLFs is the use of rei cation ( the expression of abstract concepts as concrete objects ) to achieve at expressions ( Moll a et al. , 2000b ) .</sentence>
				<definiendum id="0">MLFs</definiendum>
				<definiens id="0">the use of rei cation ( the expression of abstract concepts as concrete objects</definiens>
			</definition>
			<definition id="4">
				<sentence>Utilizing the synsets in the semantic representation means that when the query includes a term , ExtrAns returns sentences that logically answer the query , inFastr Term Extraction Hyponymy Thesaurus ExtrAns Document Figure 4 : Term Processing volving any known paraphrase of that term .</sentence>
				<definiendum id="0">ExtrAns</definiendum>
				<definiens id="0">returns sentences that logically answer the query</definiens>
				<definiens id="1">Term Processing volving any known paraphrase of that term</definiens>
			</definition>
			<definition id="5">
				<sentence>Phrasal rules represent the manner in which tokens combine to form multi-token terms , and feature-value pairs carry the token speci c information .</sentence>
				<definiendum id="0">Phrasal rules</definiendum>
				<definiens id="0">the manner in which tokens combine to form multi-token terms , and feature-value pairs carry the token speci c information</definiens>
			</definition>
			<definition id="6">
				<sentence>Metarules license the relation between two terms by constraining their phrase structures in conjunction with the morphological and semantic information on the individual tokens .</sentence>
				<definiendum id="0">Metarules</definiendum>
				<definiens id="0">license the relation between two terms by constraining their phrase structures in conjunction with the morphological and semantic information on the individual tokens</definiens>
			</definition>
			<definition id="7">
				<sentence>This query nds the answer in Figure 7 ( where stowage compartment is a hyperonym of overhead stowage compartment ) .</sentence>
				<definiendum id="0">stowage compartment</definiendum>
				<definiens id="0">a hyperonym of overhead stowage compartment )</definiens>
			</definition>
</paper>

		<paper id="1205">
			<definition id="0">
				<sentence>The score of a sentence is the sum of words’ scores from that sentence ( Zechner , 1996 ) Indicator phrase method : Paice ( 1981 ) noticed that in scientific papers it is possible to identify phrases such as in this paper , we present , in conclusion , which are usually meta-discourse markers .</sentence>
				<definiendum id="0">score of a sentence</definiendum>
				<definiens id="0">the sum of words’ scores from that sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Caution needs to be taken whenever a new chromosome is produced so the values of the genes are distinct ( i.e. the summary contains distinct sentences ) .</sentence>
				<definiendum id="0">Caution</definiendum>
				<definiens id="0">the summary contains distinct sentences</definiens>
			</definition>
			<definition id="2">
				<sentence>In our case the fitness function is the sum of the scores of the sentences indicated in the chromosome .</sentence>
				<definiendum id="0">fitness function</definiendum>
				<definiens id="0">the sum of the scores of the sentences indicated in the chromosome</definiens>
			</definition>
</paper>

		<paper id="0510">
</paper>

		<paper id="0501">
			<definition id="0">
				<sentence>Parse : [ S Illegal fireworks [ VP [ VP injured hundreds of people ] [ CC and ] [ VP started six fires ] ] ] Output of VP-over-VP : Illegal fireworks injured hundreds of people ( 11 ) Input : A company offering blood cholesterol tests in grocery stores says medical technology has outpaced state laws , but the state says the company doesn’t have the proper licenses .</sentence>
				<definiendum id="0">Parse</definiendum>
				<definiens id="0">A company offering blood cholesterol tests in grocery stores says medical technology has outpaced state laws</definiens>
			</definition>
			<definition id="1">
				<sentence>HMM Hedge treats the summarization problem as analogous to statistical machine translation .</sentence>
				<definiendum id="0">HMM Hedge</definiendum>
			</definition>
			<definition id="2">
				<sentence>BLEU uses a modified n-gram precision measure to compare machine translations to reference human translations .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">uses a modified n-gram precision measure to compare machine translations to reference human translations</definiens>
			</definition>
</paper>

		<paper id="1309">
			<definition id="0">
				<sentence>M is a mark and D is a delimiter .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">D</definiendum>
				<definiens id="0">a mark</definiens>
			</definition>
			<definition id="1">
				<sentence>A plain sentence undergoes morphological analysis and BaseNP recognition .</sentence>
				<definiendum id="0">plain sentence</definiendum>
			</definition>
			<definition id="2">
				<sentence>A common prefix search start position ( cps start ) is a position in a sentence at which a dictionary lookup can start .</sentence>
				<definiendum id="0">common prefix search start position ( cps start )</definiendum>
				<definiens id="0">a position in a sentence at which a dictionary lookup can start</definiens>
			</definition>
			<definition id="3">
				<sentence>A token is a substring in a sentence which matches with a lexeme in the dictionary , and is enclosed by a cps start and a cps end .</sentence>
				<definiendum id="0">token</definiendum>
				<definiens id="0">a substring in a sentence which matches with a lexeme in the dictionary</definiens>
			</definition>
			<definition id="4">
				<sentence>A mark is a special symbol or substring that by itself can form a token even when it appears within a graphic word .</sentence>
				<definiendum id="0">mark</definiendum>
				<definiens id="0">a special symbol or substring that by itself can form a token even when it appears within a graphic word</definiens>
			</definition>
			<definition id="5">
				<sentence>A delimiter is a special symbol or code that by itself can not form a token but can work to delimit tokens .</sentence>
				<definiendum id="0">delimiter</definiendum>
				<definiens id="0">a special symbol</definiens>
			</definition>
			<definition id="6">
				<sentence>A word is a substring in a sentence of which segmentation boundary is determined by the morpho2http : //bmkd .</sentence>
				<definiendum id="0">word</definiendum>
			</definition>
			<definition id="7">
				<sentence>Both “SLP76” and “SLP-76-associated†substrate” ( † denotes a space character ) are tokens since they are lexemes in the dictionary , but “SLP-76-” is not a token since it is not a lexeme in the dictionary .</sentence>
				<definiendum id="0">“SLP-76-associated†substrate” ( †</definiendum>
				<definiens id="0">denotes a space character</definiens>
			</definition>
			<definition id="8">
				<sentence>GENIA Corpus 3.0p3 is used to calculate a word probability p ( wjt ) , and a tag probability p ( tjt0 ; t00 ) which is modeled by a simple trigram .</sentence>
				<definiendum id="0">GENIA Corpus 3.0p3</definiendum>
				<definiens id="0">used to calculate a word probability p ( wjt ) , and a tag probability p ( tjt0 ; t00 ) which is modeled by a simple trigram</definiens>
			</definition>
			<definition id="9">
				<sentence>First , we collect human protein names ( including synonyms ) and their accession numbers from protein sequence repositories , SwissProt ( SP ) ( Boeckmann et al. , 2003 ) and Protein Information Resource ( PIR ) ( Wu et al. , 2002 ) .</sentence>
				<definiendum id="0">SwissProt ( SP )</definiendum>
				<definiens id="0">including synonyms</definiens>
			</definition>
			<definition id="10">
				<sentence>sloppy count Correct if any morpheme estimated by system overlaps with any morpheme defined by answer .</sentence>
				<definiendum id="0">sloppy count Correct</definiendum>
				<definiens id="0">if any morpheme estimated by system overlaps with any morpheme defined by answer</definiens>
			</definition>
</paper>

		<paper id="0318">
			<definition id="0">
				<sentence>Partialtranslation-count expresses the number of partialtranslations .</sentence>
				<definiendum id="0">Partialtranslation-count</definiendum>
				<definiens id="0">expresses the number of partialtranslations</definiens>
			</definition>
			<definition id="1">
				<sentence>[ 1 ] g91g93g40g41 g91 g93g40g41g91 g93g40 g41 g91g93g40g41g91g93g40g41 3221 3221 321 ~ wwCwwC wwCwwC wwwF g43 g183g43g183 g61g183 , where ~ F ( [ w 1 w 2 g183 w 3 ] ) is the plausibility that the position after a word sequence w 1 w 2 and before a word w 3 is a splitting position , [ w l w m ] is a bigram , [ w l w m w n ] is a trigram , g183 indicates a boundary of sentences , and C ( N-gram ) means the appearance count of the N-gram in a training set .</sentence>
				<definiendum id="0">] )</definiendum>
				<definiendum id="1">g183</definiendum>
				<definiens id="0">the plausibility that the position after a word sequence</definiens>
				<definiens id="1">a splitting position</definiens>
			</definition>
			<definition id="2">
				<sentence>[ 2 ] exampleinput LL SEMDISTDI dist g43 g43g43 g61 g229 2 The characteristics of D 3 , especially in comparison with most EBMT proposals , are a ) D 3 does not assume syntactic parsing and bilingual tree-banks ; b ) D 3 generates translation patterns on the fly according to the input and the retrieved translation examples as needed ; c ) D 3 uses examples sentence-by-sentence and does not combine examples .</sentence>
				<definiendum id="0">c</definiendum>
				<definiens id="0">generates translation patterns on the fly according to the input and the retrieved translation examples as needed ;</definiens>
			</definition>
			<definition id="3">
				<sentence>BTEC is a collection of Japanese sentences and their English translations usually found in phrase-books for foreign tourists .</sentence>
				<definiendum id="0">BTEC</definiendum>
				<definiens id="0">a collection of Japanese sentences and their English translations usually found in phrase-books for foreign tourists</definiens>
			</definition>
			<definition id="4">
				<sentence>dist-insplitting is defined by equation [ 4 ] , an extension of dist , and ranges from 0 to 1 .</sentence>
				<definiendum id="0">dist-insplitting</definiendum>
			</definition>
</paper>

		<paper id="0705">
			<definition id="0">
				<sentence>TRINDIKit ( TRINDI 2002 ) is an IS-based open source Prolog toolkit .</sentence>
				<definiendum id="0">TRINDIKit</definiendum>
			</definition>
</paper>

		<paper id="0602">
			<definition id="0">
				<sentence>Topics are separate distributions over V .</sentence>
				<definiendum id="0">Topics</definiendum>
			</definition>
			<definition id="1">
				<sentence>For a given number of topics , we have jKj£jVj parameters , where K is the set of topics .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the set of topics</definiens>
			</definition>
			<definition id="2">
				<sentence>Still , the remaining middle frequency words do a good job of separating captions into qualitatively good topics , Our contention is that this middle frequency is closely aligned with the true statistics of the entire corpus .</sentence>
				<definiendum id="0">Our contention</definiendum>
				<definiens id="0">closely aligned with the true statistics of the entire corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>We fit each of these models 10 different times each for K = 10 ; 20 ; : ::100 where K is the number of topics .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the number of topics</definiens>
			</definition>
			<definition id="4">
				<sentence>We define a symmetric KL divergence between two topics distributions ti and tj as KLsymmetric = 12 ( KL ( tijjtj ) +KL ( tjjjti ) ) ( 3 ) KL ( tijjtj ) = X w2V ( ( p ( wjti ) log ( p ( wjti ) p ( wjt j ) ) ) ( 4 ) where V is the corpus vocabulary .</sentence>
				<definiendum id="0">KL</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">the corpus vocabulary</definiens>
			</definition>
			<definition id="5">
				<sentence>Topics are defined as probability distributions across the corpus vocabulary .</sentence>
				<definiendum id="0">Topics</definiendum>
				<definiens id="0">probability distributions across the corpus vocabulary</definiens>
			</definition>
			<definition id="6">
				<sentence>News photo captions are an interesting dataset both for their unique textual properties , and for the opportunities they provide to exploit relationships between the text and image contents .</sentence>
				<definiendum id="0">News photo captions</definiendum>
				<definiens id="0">an interesting dataset both for their unique textual properties , and for the opportunities they provide to exploit relationships between the text and image contents</definiens>
			</definition>
</paper>

		<paper id="0422">
			<definition id="0">
				<sentence>A NE phrase , denoted as ( s , e ) k , is a phrase spanning from word xs to word xe , having s ≤ e , with category k ∈ K. Let NE be the set of all potential NE phrases , expressed as NE = { ( s , e ) k | 0 ≤ s ≤ e , k ∈ K } .</sentence>
				<definiendum id="0">NE phrase</definiendum>
				<definiens id="0">a phrase spanning from word xs to word xe , having s ≤ e , with category k ∈ K. Let NE be the set of all potential NE phrases , expressed as NE = { ( s , e ) k | 0 ≤ s ≤ e , k ∈ K }</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , it can be expressed as : Y = { y ⊆ NE |∀ne1 , ne2 ∈ y ne1negationslash∼ne2 } The goal of the NE extraction problem is to identify the correct solution y ∈ Y for a given sentence x. The NE-Chunker is a function which given a sentence x ∈ X identifies the set of NE phrases y ∈ Y : NEch : X → Y The NE-Chunker recognizes NE phrases in two layers of processing .</sentence>
				<definiendum id="0">NE-Chunker</definiendum>
				<definiens id="0">a function which given a sentence x ∈ X identifies the set of NE phrases y ∈ Y</definiens>
			</definition>
			<definition id="2">
				<sentence>Furthermore , we define the predicate BI∗ , which tests whether a certain phrase is formed by a starting begin word and subsequent inside words .</sentence>
				<definiendum id="0">predicate BI∗</definiendum>
				<definiens id="0">tests whether a certain phrase is formed by a starting begin word and subsequent inside words</definiens>
			</definition>
			<definition id="3">
				<sentence>Given this , the NE-Chunker is a function which searches a NE chunking for a sentence x according to the following optimality criterion : NEch ( x ) = arg max y∈YBI∗ summationdisplay ( s , e ) k∈y scorek ( s , e ) That is , among the considered chunkings of the sentence , the optimal one is defined to be the one whose NE phrases maximize the summation of phrase scores .</sentence>
				<definiendum id="0">NE-Chunker</definiendum>
				<definiens id="0">a function which searches a NE chunking for a sentence x according to the following optimality criterion : NEch ( x ) = arg max y∈YBI∗ summationdisplay</definiens>
			</definition>
			<definition id="4">
				<sentence>A perceptron is a linear discriminant function h¯w : Rn → R parametrized by a weight vector ¯w in Rn .</sentence>
				<definiendum id="0">perceptron</definiendum>
				<definiens id="0">a linear discriminant function h¯w : Rn → R parametrized by a weight vector ¯w in Rn</definiens>
			</definition>
			<definition id="5">
				<sentence>Given a kernel function K ( x , xprime ) , the final expression of a dual voted perceptron becomes : h¯w ( ¯x ) = Jsummationdisplay j=1 cj jsummationdisplay l=1 sxlK ( ¯xl , ¯x ) In this paper we work with polynomial kernels K ( x , xprime ) = ( x · xprime + 1 ) d , where d is the degree of the kernel .</sentence>
				<definiendum id="0">kernel function K</definiendum>
				<definiendum id="1">d</definiendum>
				<definiens id="0">the final expression of a dual voted perceptron becomes : h¯w ( ¯x )</definiens>
			</definition>
			<definition id="6">
				<sentence>Xavier Carreras holds a grant by the Catalan Government Research Department .</sentence>
				<definiendum id="0">Xavier Carreras</definiendum>
			</definition>
</paper>

		<paper id="1509">
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>Let a129a130a3a121a21a39a27a119a7a12a23a16a28 denote the document frequency , i.e. , the number of aligned article-pairs , in which a27 occurs in the English article and a23 in the Chinese .</sentence>
				<definiendum id="0">document frequency</definiendum>
				<definiens id="0">the number of aligned article-pairs , in which a27 occurs in the English article</definiens>
			</definition>
</paper>

		<paper id="0103">
</paper>

		<paper id="1102">
			<definition id="0">
				<sentence>Goldstein et al. ( 1999 ) presented an extraction technique that assigns weighted scores for both statistical and linguistic features in the sentence .</sentence>
				<definiendum id="0">extraction technique</definiendum>
				<definiens id="0">assigns weighted scores for both statistical and linguistic features in the sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>Therefore , the local clustering score for paragraph si can be calculated as follows : Lsi = argmaxβns ( β , si ) 2 n ( β , si ) , ( 2 ) where ns ( β , si ) is the number of bracketed significant words , and n ( β , si ) is the total number of bracketed words .</sentence>
				<definiendum id="0">si )</definiendum>
				<definiens id="0">the number of bracketed significant words , and n ( β , si</definiens>
			</definition>
			<definition id="2">
				<sentence>After obtaining both scores , for each paragraph si , we can compute the combination score by using the following ranking function : F ( si ) = λGprime + ( 1 −λ ) Lprime , ( 4 ) where Gprime is the normalized global connectivity score , and Lprime is the normalized local clustering score .</sentence>
				<definiendum id="0">Gprime</definiendum>
				<definiendum id="1">Lprime</definiendum>
				<definiens id="0">the normalized global connectivity score , and</definiens>
			</definition>
			<definition id="3">
				<sentence>The normalized global connectivity score Gprime can be calculated as follows : Gprime = dsid max , ( 5 ) where dmax is the degree of the node that has the maximum edges using for normalization , resulting the score in the range of [ 0,1 ] .</sentence>
				<definiendum id="0">dmax</definiendum>
			</definition>
			<definition id="4">
				<sentence>ค ําส ําค ัญ ( Keywords ) : เพนเท ียมเอ ็ม , โมบายล โปรเซสเซอร  , โปรเซสเซอร  , อ ินเทล , เคร ื่องโน ตบ ุค , เดสก ท ็อป , เทคโนโลย ี , ประส ิทธ ิภาพ , การใช พล ังงาน , บร ิษ ัทอ ินเทล , ร ุนป จจ ุบ ัน ท ําการย อเอกสารท ี่ 20 % ( Summarization result at 20 % ) : ท ี่น าส ังเกตก ็ค ือท ั้ง “เพรสคอตต ” และ “เพนเท ียมเอ ็ม ” น ั้น ได ร ับการพ ัฒนาข ึ้นมาบนพ ื้นฐาน สถาป ตยกรรมเด ียวก ัน น ั่นหมายความว า ตอนน ี้เดสก ท ็อปโปรเซสเซอร และโมบายล โปรเซสเซอร ของ อ ินเทลม ีประส ิทธ ิภาพและความสามารถท ัดเท ียมก ันแล ว หร ือถ าจะต างก ันก ็คงเล ็กน อย ในแง ของเทคโนโลย ี อ ินเทลโมบายล โปรเซสเซอร ในป จจ ุบ ันจะเป นการพ ัฒนาต อยอดจากเดสก ท ็อป โปรเซสเซอร  โดยม ีการปร ับปร ุงให ม ีการใช พล ังงานน อยลง ก ินไฟน อยลง ซ ึ่งเคร ื่องโน ตบ ุคท ี่ใช อ ินเทล โมบายล โปรเซสเซอร ร ุนป จจ ุบ ันจะสามารถร ันบนแบตเตอร ี่ได นาน 1-4 ช ั่วโมง ในแง ของการตลาด อ ินเทลจะท ําตลาดโปรเซสเซอร เพนเท ียมเอ ็ม ภายใต ช ื่อ “เซนทร ิโน ” ( Centrino ) โดยวางจ ําหน วยเป นช ุดแพ ็คเกจ ท ี่นอกจากจะม ีโปรเซสเซอร แล ว ย ังม ีช ิปเซ ็ตและโมด ูลระบบส ื่อสารไร  สาย ( WiFi ) รวมอย ูด วย Figure 4 : An example of keywords and extracted summaries in Thai .</sentence>
				<definiendum id="0">ค ําส ําค ัญ ( Keywords</definiendum>
				<definiens id="0">Centrino ) โดยวางจ ําหน วยเป นช ุดแพ ็คเกจ ท ี่นอกจากจะม ีโปรเซสเซอร แล ว ย ังม ีช ิปเซ ็ตและโมด ูลระบบส ื่อสารไร  สาย ( WiFi ) รวมอย ูด วย</definiens>
			</definition>
</paper>

		<paper id="1812">
			<definition id="0">
				<sentence>Decomposability is a description of the degree to which the semantics of an MWE can be ascribed to those of its parts ( Riehemann , 2001 ; Sag et al. , 2002 ) .</sentence>
				<definiendum id="0">Decomposability</definiendum>
			</definition>
			<definition id="1">
				<sentence>Finally , simple decomposable MWEs ( also known as “institutionalised” MWEs , e.g. kindle excitement , traffic light ) decompose into simplex senses and generally display high syntactic variability .</sentence>
				<definiendum id="0">simple decomposable MWEs</definiendum>
				<definiens id="0">“institutionalised” MWEs , e.g. kindle excitement , traffic light ) decompose into simplex senses and generally display high syntactic variability</definiens>
			</definition>
			<definition id="2">
				<sentence>LSA allows us to calculate the similarity between an arbitrary word pair , offering the advantage of being able to measure the similarity between the MWE and each of its constituent words .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">allows us to calculate the similarity between an arbitrary word pair</definiens>
			</definition>
			<definition id="3">
				<sentence>More importantly , LSA makes no assumptions about the lexical or syntactic composition of the inputs , and thus constitutes a fully constructionand language-inspecific method of modelling decomposability .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">makes no assumptions about the lexical or syntactic composition of the inputs</definiens>
			</definition>
			<definition id="4">
				<sentence>Significance here is defined as the absence of overlap between the 95 % confidence interval of the mutual information scores .</sentence>
				<definiendum id="0">Significance</definiendum>
				<definiens id="0">the absence of overlap between the 95 % confidence interval of the mutual information scores</definiens>
			</definition>
			<definition id="5">
				<sentence>Lin provides some examples that suggest he has identified a successful measure of “compositionality” .</sentence>
				<definiendum id="0">Lin</definiendum>
				<definiens id="0">provides some examples that suggest he has identified a successful measure of “compositionality”</definiens>
			</definition>
			<definition id="6">
				<sentence>Hyponymy provides the most immediate way of evaluating decomposability .</sentence>
				<definiendum id="0">Hyponymy</definiendum>
				<definiens id="0">provides the most immediate way of evaluating decomposability</definiens>
			</definition>
			<definition id="7">
				<sentence>Lin ( 1998c ) also employs the idea of corpusderived information content , and defines the similarity between two concepts in the following way : sim ( C1 ; C2 ) = 2 log P ( C0 ) log P ( C 1 ) + log P ( C2 ) ( 1 ) where C0 is the lowest class in the hierarchy that subsumes both classes .</sentence>
				<definiendum id="0">C0</definiendum>
				<definiens id="0">employs the idea of corpusderived information content , and defines the similarity between two concepts in the following way : sim ( C1 ; C2 ) = 2 log P ( C0 ) log P ( C 1 ) + log P ( C2 ) ( 1 ) where</definiens>
			</definition>
			<definition id="8">
				<sentence>In the case of the verb-particle data , WordNet has no classification of prepositions or particles , so we can only calculate the similarity between the head verb and verbparticle ( VPC ( head ) ) .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiendum id="1">VPC</definiendum>
				<definiens id="0">no classification of prepositions or particles</definiens>
			</definition>
			<definition id="9">
				<sentence>Multiword expressions : A pain in the neck for NLP .</sentence>
				<definiendum id="0">Multiword expressions</definiendum>
				<definiens id="0">A pain in the neck for NLP</definiens>
			</definition>
</paper>

		<paper id="0435">
</paper>

		<paper id="0429">
			<definition id="0">
				<sentence>Hidden Markov models break the probability calculations into two pieces : transition probabilities ( the probability of moving from one vertex to another independent of the word at the destination node ) , and emission probabilities ( the probability that a given word would be generated from a certain state independent of the path taken to get to that state ) .</sentence>
				<definiendum id="0">transition probabilities</definiendum>
				<definiens id="0">the probability of moving from one vertex to another independent of the word at the destination node )</definiens>
			</definition>
			<definition id="1">
				<sentence>A support vector machine is a binary classifier that uses supervised training to predict whether a given vector is in a target class .</sentence>
				<definiendum id="0">support vector machine</definiendum>
				<definiens id="0">a binary classifier that uses supervised training to predict whether a given vector is in a target class</definiens>
			</definition>
</paper>

		<paper id="1903">
			<definition id="0">
				<sentence>The annotation of word senses such as used by machine-learning based word sense disambiguation ( WSD ) tools corresponds to the task of selecting the correct semantic class or concept for a word from an underlying ontology such as WordNet ( Resnik , 1997 ) .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">used by machine-learning based word sense disambiguation (</definiens>
			</definition>
			<definition id="1">
				<sentence>Ontologies are formal specifications of a conceptualization ( Gruber , 1993 ) so that it seems straightforward to formalize annotation schemes as ontologies and make use of semantic annotation tools such as OntoMat ( Handschuh et al. , 2001 ) for the purpose of linguistic annotation .</sentence>
				<definiendum id="0">Ontologies</definiendum>
				<definiens id="0">formal specifications of a conceptualization ( Gruber , 1993 ) so that it seems straightforward to formalize annotation schemes as ontologies and make use of semantic annotation tools such as OntoMat ( Handschuh et al. , 2001 ) for the purpose of linguistic annotation</definiens>
			</definition>
			<definition id="2">
				<sentence>annotation framework An ontology is a formal specification of a conceptualization ( Gruber , 1993 ) .</sentence>
				<definiendum id="0">ontology</definiendum>
			</definition>
			<definition id="3">
				<sentence>According to this model , an ontology is defined as follows : Definition 1 ( Ontology ) An ontology is a structure a0a2a1a4a3 a5a7a6a9a8a11a10a13a12a14a8a16a15a17a8a11a10a19a18a21a20 consisting of ( i ) two disjoint sets a6 and a15 called concept identifiers and relation identifiers respectively , ( ii ) a partial order a10a9a12 on a6 called concept hierarchy or taxonomy , ( iii ) a function a22a23a1a24a15a26a25 a6a28a27a29a6 1 called signature and ( iv ) a partial order a10a30a18 on a15 called relation hierarchy .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiendum id="1">Ontology</definiendum>
				<definiendum id="2">ontology</definiendum>
				<definiens id="0">a structure a0a2a1a4a3 a5a7a6a9a8a11a10a13a12a14a8a16a15a17a8a11a10a19a18a21a20 consisting of ( i ) two disjoint sets a6 and a15 called concept identifiers and relation identifiers respectively , ( ii ) a partial order a10a9a12 on a6 called concept hierarchy or taxonomy , ( iii ) a function a22a23a1a24a15a26a25 a6a28a27a29a6 1 called signature and ( iv ) a partial order a10a30a18 on a15 called relation hierarchy</definiens>
			</definition>
			<definition id="4">
				<sentence>An a31 -axiom system for an ontology a0 as defined above is a pair ( AI , a32 ) where ( i ) AI is a set whose elements are called axiom identifiers and ( ii ) a32 : AI a25 a31 is a mapping .</sentence>
				<definiendum id="0">a31 -axiom system for an ontology a0</definiendum>
				<definiens id="0">a set whose elements are called axiom identifiers</definiens>
			</definition>
			<definition id="5">
				<sentence>If an annotator for example annotates the following coreferences : Coreference ( A , B ) and Coreference ( B , C ) a system’s answer such as Coreference ( A , C ) will actually be counted as correct due to the fact that Coreference is defined as a transitive relation within the ontology .</sentence>
				<definiendum id="0">Coreference ( A , B</definiendum>
				<definiendum id="1">Coreference ( B</definiendum>
				<definiens id="0">a transitive relation within the ontology</definiens>
			</definition>
			<definition id="6">
				<sentence>CREAM is an annotation and authoring framework and OntoMat-Annotizer ( OntoMat for short ) is its concrete implementation .</sentence>
				<definiendum id="0">CREAM</definiendum>
				<definiens id="0">an annotation and authoring</definiens>
			</definition>
			<definition id="7">
				<sentence>The F-Logic inference engine combines orderingindependent reasoning in a high-level logical language with a well-founded semantics .</sentence>
				<definiendum id="0">F-Logic inference engine</definiendum>
				<definiens id="0">combines orderingindependent reasoning in a high-level logical language with a well-founded semantics</definiens>
			</definition>
</paper>

		<paper id="1606">
			<definition id="0">
				<sentence>The PROPERTY predicate is the result of the normalization of strings expressing physical or chemical properties of the toxic product .</sentence>
				<definiendum id="0">PROPERTY predicate</definiendum>
				<definiens id="0">the result of the normalization of strings expressing physical or chemical properties of the toxic product</definiens>
			</definition>
			<definition id="1">
				<sentence>Paraphrase detection is a useful step in many NLP applications .</sentence>
				<definiendum id="0">Paraphrase detection</definiendum>
			</definition>
			<definition id="2">
				<sentence>For instance , we want to obtain the same normalized predicate for the two utterances ProductX is a colorless , nonflammable liquid and ProductX is a liquid that has no colour and that does not burn easily namely : DESCRIPTION COLOUR ( ProductX , colorless ) PHYS FORM ( ProductX , liquid ) PROPERTY NEG ( ProductX , burn , NONE , NONE , NONE ) .</sentence>
				<definiendum id="0">ProductX</definiendum>
				<definiendum id="1">DESCRIPTION COLOUR</definiendum>
				<definiendum id="2">PHYS FORM</definiendum>
				<definiens id="0">a colorless , nonflammable liquid</definiens>
				<definiens id="1">a liquid that has no colour</definiens>
			</definition>
			<definition id="3">
				<sentence>Deduction rules Deduction rules apply on a chunk tree and consist in three parts : Context Condition Extraction Context is a regular expression on chunk tree nodes that has to be matched with the rule to apply .</sentence>
				<definiendum id="0">Deduction rules Deduction rules</definiendum>
				<definiens id="0">a regular expression on chunk tree nodes that has to be matched with the rule to apply</definiens>
			</definition>
			<definition id="4">
				<sentence>The fourth line ( negative condition : ) verifies if a SUBJ dependency exists between the lexical nodes corresponding to the variable # 2 ( the verb ) and # 1 ( the head of the nominal chunk ) .</sentence>
				<definiendum id="0">fourth line</definiendum>
				<definiens id="0">the head of the nominal chunk )</definiens>
			</definition>
			<definition id="5">
				<sentence>if ( SUBJ ( # 1 , # 2 ) &amp; VDOMAIN [ passive ] ( # 1 , # 3 ) ) OBJ-N ( # 3 , # 2 ) Unlike Ros´e’s approach ( Ros´e , 2000 ) which also developed a deep syntactic analyzer , this is done exclusively by hand-made rules based on the previous calculated dependencies on the one hand and syntactic and morphological properties of the nodes involved in the dependencies on the other hand .</sentence>
				<definiendum id="0">SUBJ</definiendum>
			</definition>
			<definition id="6">
				<sentence>if ( SUBSTANCE ( # 1 ) &amp; ATTRIB ( # 1 , # 8 [ adj_property ] ) &amp; ISAJ ( # 9 , # 10 ) &amp; # 8 [ lem me ] : # 9 [ lem me ] ) PROPERTY ( # 1 , # 10 , # # Pron [ lem me =NONE ] , # # Pron [ lem me =NONE ] , # # Pron [ lem me =NONE ] ) The rule formalism is the one used for the general syntactic grammar and the deep syntax grammar .</sentence>
				<definiendum id="0">SUBSTANCE</definiendum>
			</definition>
			<definition id="7">
				<sentence>the system is able to extract the following list of predicates : SUBSTANCE ( acetone ) PHYS_FORM ( acetone , chemical ) PHYS_FORM ( acetone , liquid ) DESCRIPTION_COLOUR ( acetone , colorless ) DESCRIPTION_SMELL ( acetone , distinct ) PROPERTY ( acetone , burn , NONE , NONE , easily ) PROPERTY ( acetone , evaporate , NONE , NONE , easily ) PROPERTY ( acetone , dissolve , water , in , NONE ) ORIGIN ( acetone , natural , vehicle exhaust , in ) ORIGIN ( acetone , natural , tobacco smoke , in ) ORIGIN ( acetone , natural , landfill site , in ) ORIGIN ( acetone , natural , plant , in ) ORIGIN ( acetone , natural , the environment , in ) ORIGIN ( acetone , man-made , NONE , NONE ) ORIGIN ( acetone , natural , tree , in ) ORIGIN ( acetone , natural , volcanic gas , in ) ORIGIN ( acetone , natural , forest fire , in ) ORIGIN ( acetone , natural , a product , in ) SYNONYM ( acetone , dimethyl ketone ) SYNONYM ( acetone , beta-ketopropane ) SYNONYM ( acetone,2-propanone ) USE ( acetone , NONE , NONE , make , plastic , present ) USE ( acetone , NONE , NONE , make , fiber , present ) USE ( acetone , NONE , NONE , make , drug , present ) USE ( acetone , NONE , NONE , make , other chemical , present ) USE ( acetone , NONE , NONE , dissolve , other substance , present ) Most of the information present in the original text has been extracted and normalized : for example , flammable is normalized as PROPERTY ( acetone , burn , NONE , NONE , easily ) .</sentence>
				<definiendum id="0">NONE , NONE ) ORIGIN</definiendum>
				<definiendum id="1">dimethyl ketone ) SYNONYM</definiendum>
				<definiens id="0">plastic , present ) USE ( acetone , NONE , NONE , make , fiber , present ) USE ( acetone , NONE , NONE , make , drug , present ) USE ( acetone , NONE , NONE , make , other chemical , present</definiens>
			</definition>
			<definition id="8">
				<sentence>Information extraction consists here in normalization of syntactic processing using both deep syntactic and morphological information as well as corpus specific knowledge .</sentence>
				<definiendum id="0">Information extraction</definiendum>
				<definiens id="0">consists here in normalization of syntactic processing using both deep syntactic and morphological information as well as corpus specific knowledge</definiens>
			</definition>
</paper>

		<paper id="1804">
			<definition id="0">
				<sentence>Our solution shows O ( h ( F ) N log N ) time complexity where N is the corpus size and h ( F ) a function of the window context .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the corpus size and h ( F ) a function of the window context</definiens>
			</definition>
			<definition id="1">
				<sentence>However , in order to overcome its conceptual rigidity , T. Kuhn et al. ( 1994 ) have defined the polygram model that estimates the probability of an ngram by interpolating the relative frequencies of all its kgrams ( k ≤ n ) .</sentence>
				<definiendum id="0">polygram model</definiendum>
			</definition>
			<definition id="2">
				<sentence>F+1 ) word size window context ( F represents the context in terms of words on the right and on the left of any word in the corpus ) .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">represents the context in terms of words on the right and on the left of any word in the corpus )</definiens>
			</definition>
			<definition id="3">
				<sentence>Instead , we propose a 4 As specific , we intend a sequence that fits the definition of collocation given by Dias ( 2002 ) : “A collocation is a recurrent sequence of words that co-occur together more than expected by chance in a given domain” .</sentence>
				<definiendum id="0">“A collocation</definiendum>
				<definiens id="0">a recurrent sequence of words that co-occur together more than expected by chance in a given domain”</definiens>
			</definition>
			<definition id="4">
				<sentence>For each word in the corpus , there exists an algorithmic pattern that identifies all the possible positional ngrams in a 2 .</sentence>
				<definiendum id="0">algorithmic pattern</definiendum>
				<definiens id="0">identifies all the possible positional ngrams in a 2</definiens>
			</definition>
			<definition id="5">
				<sentence>The Mutual Expectation evaluates the degree of rigidity that links together all the words contained in a positional ngram ( ∀n , n ≥ 2 ) based on the concept of Normalized Expectation and relative frequency .</sentence>
				<definiendum id="0">Mutual Expectation</definiendum>
				<definiendum id="1">positional ngram</definiendum>
				<definiens id="0">evaluates the degree of rigidity that links together all the words contained in a</definiens>
			</definition>
			<definition id="6">
				<sentence>Indeed , a given positional ngram is a substring that can appear in different positions of the corpus being the count of these positions its frequency .</sentence>
				<definiendum id="0">positional ngram</definiendum>
				<definiens id="0">a substring that can appear in different positions of the corpus being the count of these positions its frequency</definiens>
			</definition>
			<definition id="7">
				<sentence>In fact , Alexandre Gil ( 2002 ) has proved that , mainly due to the implementation of the Multikey Quicksort algorithm , our implementation evidences a time complexity of O ( h ( F ) N log N ) where N is the size of the corpus and h ( F ) a function of the window context .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the size of the corpus and h ( F ) a function of the window context</definiens>
			</definition>
</paper>

		<paper id="1708">
			<definition id="0">
				<sentence>Chinese Named Entity Recognition System ( CHINERS ) is a component of Chinese information extraction system which is being developed .</sentence>
				<definiendum id="0">Chinese Named Entity Recognition System</definiendum>
				<definiens id="0">a component of Chinese information extraction system which is being developed</definiens>
			</definition>
			<definition id="1">
				<sentence>In order to improve the quality for word segmentation and POS tagging , there may be two ways to achieve such goal : Domain Verb Lexicon and HowNet Recognized Results Named Entity Recognition TN , CT and PI Recognition Knowledge Machine Learning for Error Repairing Error Repairing for Word Segmentation and POS Tagging Seg .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">goal : Domain Verb Lexicon and HowNet Recognized Results Named Entity Recognition TN , CT and PI Recognition Knowledge Machine Learning for Error Repairing Error Repairing for Word Segmentation and POS Tagging Seg</definiens>
			</definition>
			<definition id="2">
				<sentence>J is a POS tag for the abbreviated word .</sentence>
				<definiendum id="0">J</definiendum>
			</definition>
			<definition id="3">
				<sentence>The NE recognition rule is defined as follows : Recognition Category  POS Rule | Semantic Constraint1 | Semantic Constraint2 | … | Semantic Constraintn The NE recognition rule is composed of POS rule and its corresponding semantic constraints .</sentence>
				<definiendum id="0">NE recognition rule</definiendum>
				<definiens id="0">follows : Recognition Category  POS Rule | Semantic Constraint1 | Semantic Constraint2 | … | Semantic Constraintn The NE recognition rule is composed of POS rule and its corresponding semantic constraints</definiens>
			</definition>
			<definition id="4">
				<sentence>The POS index matrix provides the position of indexes related with POS tags between two states in the semantic index matrix .</sentence>
				<definiendum id="0">POS index matrix</definiendum>
				<definiens id="0">provides the position of indexes related with POS tags between two states in the semantic index matrix</definiens>
			</definition>
			<definition id="5">
				<sentence>For instance , the valence constituents for the verb “a40 ” in our domain are defined as follows : Basic Format : Essiv win Object ( Team1 win1 Team2 ; Person1 win2 Person2 ; Personal Identity1 win3 Personal Identity2 ; … ) Extended Format : Link + Basic Format ; Accompaniment + Basic Format ; … In the basic format , Essiv is a subject that represents a non-spontaneous action and state in an event .</sentence>
				<definiendum id="0">Essiv</definiendum>
				<definiens id="0">Basic Format : Essiv win Object ( Team1 win1 Team2 ; Person1 win2 Person2 ; Personal Identity1 win3 Personal Identity2 ; … ) Extended Format : Link + Basic Format ; Accompaniment + Basic Format ; … In the basic format ,</definiens>
				<definiens id="1">a subject that represents a non-spontaneous action and state in an event</definiens>
			</definition>
			<definition id="6">
				<sentence>Object is a direct object that deals with an non-spontaneous action .</sentence>
				<definiendum id="0">Object</definiendum>
				<definiens id="0">a direct object that deals with an non-spontaneous action</definiens>
			</definition>
			<definition id="7">
				<sentence>Accompaniment expresses an indirect object that is accompanied or excluded .</sentence>
				<definiendum id="0">Accompaniment</definiendum>
				<definiens id="0">expresses an indirect object that is accompanied or excluded</definiens>
			</definition>
			<definition id="8">
				<sentence>The training set consists of 94 texts including 3473 sentences ( roughly 37077 characters ) from Jiefang Daily in 2001 .</sentence>
				<definiendum id="0">training set</definiendum>
				<definiens id="0">consists of 94 texts including 3473 sentences ( roughly 37077 characters ) from Jiefang Daily in 2001</definiens>
			</definition>
			<definition id="9">
				<sentence>The testing set is a separate set , which contains 20 texts including 658 sentences ( roughly 8340 characters ) .</sentence>
				<definiendum id="0">testing set</definiendum>
				<definiens id="0">a separate set , which contains 20 texts including 658 sentences ( roughly 8340 characters )</definiens>
			</definition>
</paper>

		<paper id="0415">
			<definition id="0">
				<sentence>In this paper we demonstrate methods of improving both the recall and the precision of automatic methods for extraction of hyponymy ( IS A ) relations from free text .</sentence>
				<definiendum id="0">hyponymy (</definiendum>
			</definition>
			<definition id="1">
				<sentence>The fundamental relationship between objects in a taxonomy is called hyponymy , where y is a hyponym of x if every y is also an x. For example , every trout is also a fish , so we say that trout is a hyponym ( “below name” ) of fish and conversely , fish is a hypernym ( “above name” ) of trout .</sentence>
				<definiendum id="0">y</definiendum>
				<definiendum id="1">fish</definiendum>
				<definiens id="0">a hyponym ( “below name” ) of fish</definiens>
				<definiens id="1">a hypernym ( “above name” ) of trout</definiens>
			</definition>
			<definition id="2">
				<sentence>Another definition is given by Caraballo ( 1999 ) : “. . . a word A is said to be a hypernym of a word B if native speakers of English accept the sentence ‘B is a ( kind of ) A.’ ” linguistic tools such as lemmatization can be used to reliably put the extracted relationships into a normalized or “canonical” form for addition to a semantic resource .</sentence>
				<definiendum id="0">‘B</definiendum>
				<definiens id="0">native speakers of English accept the sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Similarity between two vectors ( points ) was measured using the cosine of the angle between them , in the same way as the similarity between a query and a document is often measured 5A “stoplist” is a list of frequent words which have little semantic content in themselves , such as prepositions and pronouns ( Baeza-Yates and Ribiero-Neto , 1999 , p. 167 ) .</sentence>
				<definiendum id="0">Similarity between two vectors ( points</definiendum>
				<definiens id="0">measured using the cosine of the angle between them , in the same way as the similarity between a query and a document is often measured 5A “stoplist” is a list of frequent words which have little semantic content in themselves , such as prepositions and pronouns ( Baeza-Yates and Ribiero-Neto , 1999 , p. 167 )</definiens>
			</definition>
			<definition id="4">
				<sentence>LSA provides broad-based semantic information learned statistically over many occurences of words ; lexicosyntactic hyponymy extraction learns semantic information from specific phrases within a corpus .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">provides broad-based semantic information learned statistically over many occurences of words ; lexicosyntactic hyponymy extraction learns semantic information from specific phrases within a corpus</definiens>
			</definition>
</paper>

		<paper id="1200">
</paper>

		<paper id="1310">
			<definition id="0">
				<sentence>The EPoCare server uses this database to provide answers to queries posed by clinicians .</sentence>
				<definiendum id="0">EPoCare server</definiendum>
				<definiens id="0">uses this database to provide answers to queries posed by clinicians</definiens>
			</definition>
			<definition id="1">
				<sentence>UMLS FTI ToX Engine keywords candidate answers EPoCare Server expanded retrieved documents Catalog clinical answers answers keywords Client Application Front Controller clinical query Query-Answer Matcher Query Processor ( relevant ) documents candidate CE Retriever EBOC expansion of keywords ToX query / answer Answer Extractor Figure 1 : EPoCare system architecture .</sentence>
				<definiendum id="0">UMLS FTI ToX Engine keywords candidate</definiendum>
				<definiens id="0">answers EPoCare Server expanded retrieved documents Catalog clinical answers answers keywords Client Application Front Controller clinical query Query-Answer Matcher Query Processor ( relevant ) documents candidate CE Retriever EBOC expansion of keywords ToX query / answer Answer Extractor Figure 1 : EPoCare system architecture</definiens>
			</definition>
			<definition id="2">
				<sentence>The XML database is manipulated by ToX , a repository manager for XML data ( Barbosa et al. , 2001 ) .</sentence>
				<definiendum id="0">XML database</definiendum>
			</definition>
			<definition id="3">
				<sentence>WordNet is the main knowledge base that most current GQA systems use in analyzing relationships among words when calculating the similarity of a question and a candidate answer .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">the main knowledge base that most current GQA systems use in analyzing relationships among words when calculating the similarity of a question and a candidate answer</definiens>
			</definition>
			<definition id="4">
				<sentence>A good complement to WordNet is the Unified Medical Language System ( UMLS ) ( Lindberg et al. , 1993 ) , developed by the National Library of Medicine .</sentence>
				<definiendum id="0">good complement to WordNet</definiendum>
				<definiens id="0">the Unified Medical Language System ( UMLS ) ( Lindberg et al. , 1993 ) , developed by the National Library of Medicine</definiens>
			</definition>
			<definition id="5">
				<sentence>UMLS contains three knowledge sources : the Metathesaurus , the Semantic Network , and the Specialist Lexicon .</sentence>
				<definiendum id="0">UMLS</definiendum>
				<definiens id="0">contains three knowledge sources : the Metathesaurus , the Semantic Network , and the Specialist Lexicon</definiens>
			</definition>
			<definition id="6">
				<sentence>The Metathesaurus represents biomedical knowledge by organizing concepts according to their relationships and meanings .</sentence>
				<definiendum id="0">Metathesaurus</definiendum>
				<definiens id="0">biomedical knowledge by organizing concepts according to their relationships and meanings</definiens>
			</definition>
			<definition id="7">
				<sentence>The Text Retrieval Conference uses the Mean Reciprocal Rank ( MRR ) as an evaluation metric .</sentence>
				<definiendum id="0">Text Retrieval Conference</definiendum>
				<definiens id="0">uses the Mean Reciprocal Rank ( MRR ) as an evaluation metric</definiens>
			</definition>
			<definition id="8">
				<sentence>In this method , a system may return an ordered list of up to five different candidate answers to a question , and the score received is 1=n , where n is the position in the list of the correct answer ( if it appears at all ) ; for example , if the correct answer is fourth in the list , the system receives a score of 0.25 for that test item .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">a score of 0.25 for that test item</definiens>
			</definition>
			<definition id="9">
				<sentence>For example : Thrombolysis reduces the risk of dependency , but increases the risk of death .</sentence>
				<definiendum id="0">Thrombolysis</definiendum>
				<definiens id="0">reduces the risk of dependency , but increases the risk of death</definiens>
			</definition>
</paper>

		<paper id="0314">
			<definition id="0">
				<sentence>The original PrefixSpan gives a predicate that always returns true .</sentence>
				<definiendum id="0">PrefixSpan</definiendum>
				<definiens id="0">gives a predicate that always returns true</definiens>
			</definition>
			<definition id="1">
				<sentence>For this present work , we use Dunning’s log-likelihood ratio statistics ( Dunning , 1993 ) defined as follows : sim = aloga+blogb+clogc+dlogd ¡ ( a+b ) log ( a+b ) ¡ ( a+c ) log ( a+c ) ¡ ( b+d ) log ( b+d ) ¡ ( c+d ) log ( c+d ) + ( a+b+c+d ) log ( a+b+c+d ) For each bilingual pattern EiJj , we compute its similarity score and qualify it as a bilingual sequence-to-sequence correspondence if no equally strong or stronger association for monolingual constituent is found .</sentence>
				<definiendum id="0">log-likelihood ratio statistics</definiendum>
				<definiens id="0">Dunning , 1993 ) defined as follows : sim = aloga+blogb+clogc+dlogd ¡ ( a+b ) log ( a+b ) ¡ ( a+c ) log ( a+c ) ¡ ( b+d ) log ( b+d ) ¡ ( c+d ) log ( c+d ) + ( a+b+c+d ) log ( a+b+c+d ) For each bilingual pattern EiJj</definiens>
			</definition>
			<definition id="2">
				<sentence>Sequential pattern mining takes care of translation candidate generation as well as efficient counting of the generated candidates .</sentence>
				<definiendum id="0">Sequential pattern mining</definiendum>
				<definiens id="0">takes care of translation candidate generation as well as efficient counting of the generated candidates</definiens>
			</definition>
</paper>

		<paper id="1805">
			<definition id="0">
				<sentence>Phraseness is a somewhat abstract notion which describes the degree to which a given word sequence is considered to be a phrase .</sentence>
				<definiendum id="0">Phraseness</definiendum>
				<definiens id="0">a somewhat abstract notion which describes the degree to which a given word sequence is considered to be a phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>Informativeness refers to how well a phrase captures or illustrates the key ideas in a set of documents .</sentence>
				<definiendum id="0">Informativeness</definiendum>
				<definiens id="0">how well a phrase captures or illustrates the key ideas in a set of documents</definiens>
			</definition>
			<definition id="2">
				<sentence>A word sequence can be informative for a particular domain but not a phrase ; “toyota , honda , ford” is an example of a non-phrase sequence of informative words in a hybrid car domain .</sentence>
				<definiendum id="0">ford”</definiendum>
				<definiens id="0">a particular domain but not a phrase ; “toyota , honda</definiens>
			</definition>
			<definition id="3">
				<sentence>Word collocation Various collocation metrics have been proposed , including mean and variance ( Smadja , 1994 ) , the t-test ( Church et al. , 1991 ) , the chi-square test , pointwise mutual information ( MI ) ( Church and Hanks , 1990 ) , and binomial loglikelihood ratio test ( BLRT ) ( Dunning , 1993 ) .</sentence>
				<definiendum id="0">Word collocation Various collocation metrics</definiendum>
			</definition>
			<definition id="4">
				<sentence>According to ( Manning and Sch¨utze , 1999 ) , BLRT is one of the most stable methods for collocation discovery .</sentence>
				<definiendum id="0">BLRT</definiendum>
				<definiens id="0">one of the most stable methods for collocation discovery</definiens>
			</definition>
			<definition id="5">
				<sentence>( Pantel and Lin , 2001 ) reports , however , that BLRT score can be also high for two frequent terms that are rarely adjacent , such as the word pair “the the , ” and uses a hybrid of MI and BLRT .</sentence>
				<definiendum id="0">BLRT score</definiendum>
				<definiens id="0">the word pair “the the , ” and uses a hybrid of MI and BLRT</definiens>
			</definition>
			<definition id="6">
				<sentence>Combining keyphrase and collocation Yamamoto and Church ( 2001 ) compare two metrics , MI and Residual IDF ( RIDF ) , and observed that MI is suitable for finding collocation and RIDF is suitable for finding informative phrases .</sentence>
				<definiendum id="0">MI</definiendum>
				<definiendum id="1">RIDF</definiendum>
				<definiens id="0">suitable for finding collocation and</definiens>
				<definiens id="1">suitable for finding informative phrases</definiens>
			</definition>
			<definition id="7">
				<sentence>The BLRT score is calculated with a0a2a1a4a3a6a5a8a7a10a9a12a11 a1a14a13 a0 a1a14a13 a3 a1a16a15 a7a10a9a12a11 a5a17a13 a0 a5a17a13 a3 a5a18a15 a7a10a9a12a11 a13 a0 a1 a13 a3a4a1 a15 a7a10a9a12a11 a13 a0 a5 a13 a3 a5 a15 ( 1 ) where a11a20a19a22a21 a0a6a19a24a23 a3a25a19 , a11a26a21a27a9 a0 a1a29a28 a0 a5 a15 a23a30a9 a3a4a1a29a28 a3 a5 a15 , and a7a10a9a12a11 a13 a0 a13 a3 a15 a21a31a11a33a32a34a9a36a35a38a37a26a11 a15a40a39a42a41 a32 ( 2 ) In the case of calculating the phraseness score of an adjacent word pair ( a43 a13a45a44 ) , the null hypothesis is that a43 and a44 are independent , which can be expressed as a11a2a9 a44a25a46a43 a15 a21a47a11a29a9 a44a22a46a49a48 a43 a15 .</sentence>
				<definiendum id="0">BLRT score</definiendum>
				<definiens id="0">the case of calculating the phraseness score of an adjacent word pair</definiens>
			</definition>
			<definition id="8">
				<sentence>The simplest language model is a unigram model , which assumes each word of a given word sequence is drawn independently .</sentence>
				<definiendum id="0">simplest language model</definiendum>
				<definiens id="0">a unigram model</definiens>
			</definition>
			<definition id="9">
				<sentence>The KL divergence ( also called relative entropy ) between two probability mass function a11a29a9a54a43 a15 and a14a59a9a54a43 a15 is defined as a15 a9a12a11a17a16a18a14 a15 a21a20a19a22a21 a11a29a9a54a43 a15 a1a93a3a6a5 a11a29a9a54a43 a15 a14a59a9a54a43 a15 ( 6 ) KL divergence is “a measure of the inefficiency of assuming that the distribution is a14 when the true distribution is a11 .”</sentence>
				<definiendum id="0">KL divergence</definiendum>
			</definition>
			<definition id="10">
				<sentence>Likelihood ratio ( or relative frequency ratio ) has a tendency to pick up rare words as informative .</sentence>
				<definiendum id="0">Likelihood ratio</definiendum>
				<definiens id="0">a tendency to pick up rare words as informative</definiens>
			</definition>
</paper>

		<paper id="0418">
			<definition id="0">
				<sentence>A script is a stereotypical sequence of events that occur as part of a larger situation and can be used to infer missing details from a partial description of the larger occurrence , in essence providing a means for extracting information that is not actually present in a text .</sentence>
				<definiendum id="0">script</definiendum>
				<definiens id="0">a stereotypical sequence of events that occur as part of a larger situation</definiens>
			</definition>
			<definition id="1">
				<sentence>Each is a physical object , yet there are a large number of other physical objects that would not reasonably participate in a crash in the same way ( books , hamburgers , and moons are a few examples ) .</sentence>
				<definiendum id="0">moons</definiendum>
				<definiens id="0">a physical object , yet there are a large number of other physical objects that would not reasonably participate in a crash in the same way ( books , hamburgers , and</definiens>
			</definition>
			<definition id="2">
				<sentence>SPANIEL uses a statistical model to identify correlations .</sentence>
				<definiendum id="0">SPANIEL</definiendum>
			</definition>
			<definition id="3">
				<sentence>Briefly , SPANIEL uses a modified Markov model to capture correlations .</sentence>
				<definiendum id="0">SPANIEL</definiendum>
				<definiens id="0">uses a modified Markov model to capture correlations</definiens>
			</definition>
			<definition id="4">
				<sentence>First , the cooccurrence of two nodes , C ( Ni ; Nj ) , is the number of narratives in which Ni occurs before Nj , and thus quantifies each arc .</sentence>
				<definiendum id="0">Nj )</definiendum>
				<definiens id="0">the number of narratives in which Ni occurs before Nj</definiens>
			</definition>
			<definition id="5">
				<sentence>Given this graph , SPANIEL uses a beam search to detect correlations of multiple events by incrementally expanding a sequence of events that occur frequently together .</sentence>
				<definiendum id="0">SPANIEL</definiendum>
				<definiens id="0">uses a beam search to detect correlations of multiple events by incrementally expanding a sequence of events that occur frequently together</definiens>
			</definition>
			<definition id="6">
				<sentence>DC : null AGENT : AIRCRAFT ACTION : CRASHED THEME : INTO_GROUND DC : AGENT : PILOT ACTION : REPORTED THEME : null DC : null AGENT : HE ACTION : WAS_RUNNING_OUT THEME : OF_FUEL The aircraft crashed into the ground .</sentence>
				<definiendum id="0">DC</definiendum>
				<definiendum id="1">ACTION</definiendum>
				<definiens id="0">null AGENT : AIRCRAFT ACTION : CRASHED THEME : INTO_GROUND DC : AGENT : PILOT ACTION : REPORTED THEME : null DC : null AGENT : HE</definiens>
			</definition>
			<definition id="7">
				<sentence>The second criteria for adding nodes to events , InSeq , ensures that all nodes in an event occur in similar contexts .</sentence>
				<definiendum id="0">InSeq</definiendum>
				<definiens id="0">ensures that all nodes in an event occur in similar contexts</definiens>
			</definition>
			<definition id="8">
				<sentence>REVISE removes such nodes from events .</sentence>
				<definiendum id="0">REVISE</definiendum>
				<definiens id="0">removes such nodes from events</definiens>
			</definition>
			<definition id="9">
				<sentence>Our event generation technique is an essential part of SPANIEL , our event correlation learning system .</sentence>
				<definiendum id="0">event generation technique</definiendum>
				<definiens id="0">an essential part of SPANIEL , our event correlation learning system</definiens>
			</definition>
</paper>

		<paper id="1726">
</paper>

		<paper id="0900">
</paper>

		<paper id="0316">
			<definition id="0">
				<sentence>Dinh Dien Information Technology Faculty of Vietnam National University of HCMC , 20/C2 Hoang Hoa Tham , Ward 12 , Tan Binh Dist. , HCM City , Vietnam ddien @ saigonnet.vn Hoang Kiem Center of Information Technology Development of Vietnam National University of HCMC , 227 Nguyen Van Cu , District 5 , HCM City , hkiem @ citd.edu.vn Corpus-based Natural Language Processing ( NLP ) tasks for such popular languages as English , French , etc. have been well studied with satisfactory achievements .</sentence>
				<definiendum id="0">Corpus-based Natural Language Processing ( NLP</definiendum>
				<definiens id="0">saigonnet.vn Hoang Kiem Center of Information Technology Development of Vietnam National University of HCMC , 227 Nguyen Van Cu</definiens>
			</definition>
			<definition id="1">
				<sentence>This POS-tagger made use of the Transformation-Based Learning ( or TBL ) method to bootstrap the POS-annotation results of the English POS-tagger by exploiting the POS-information of the corresponding Vietnamese words via their wordalignments in EVC .</sentence>
				<definiendum id="0">Transformation-Based Learning</definiendum>
				<definiens id="0">or TBL ) method to bootstrap the POS-annotation results of the English POS-tagger by exploiting the POS-information of the corresponding Vietnamese words via their wordalignments in EVC</definiens>
			</definition>
			<definition id="2">
				<sentence>null English-Vietnamese bilingual Corpus ( EVC ) : resources of EVC , word-alignment of EVC .</sentence>
				<definiendum id="0">null English-Vietnamese bilingual Corpus</definiendum>
				<definiens id="0">resources of EVC , word-alignment of EVC</definiens>
			</definition>
			<definition id="3">
				<sentence>null Bootstrapping English-POS-Tagger : bootstrapping English POS-Tagger by the POS-tag of corresponding Vietnamese words .</sentence>
				<definiendum id="0">null Bootstrapping English-POS-Tagger</definiendum>
			</definition>
			<definition id="4">
				<sentence>TBL is active in conformity with the transformational rules in order to change wrong tags into right ones .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">active in conformity with the transformational rules in order to change wrong tags into right ones</definiens>
			</definition>
			<definition id="5">
				<sentence>The TBL algorithm for POS-tagger can be briefly described under two periods as follows : * The training period : null Starting with the annotated training corpus ( or called golden corpus , which has been assigned with correct POS tag annotations ) , TBL copies this golden corpus into a new unannotated corpus ( called current corpus , which is removed POS tag annotations ) .</sentence>
				<definiendum id="0">TBL algorithm for POS-tagger</definiendum>
				<definiendum id="1">golden corpus</definiendum>
				<definiendum id="2">TBL</definiendum>
				<definiens id="0">has been assigned with correct POS tag annotations</definiens>
			</definition>
			<definition id="6">
				<sentence>null TBL applies each instance of each candidate rule ( following the format of templates designed by human beings ) in the current corpus .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">applies each instance of each candidate rule ( following the format of templates designed by human beings ) in the current corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>* The executing period : null Starting with the new unannotated text , TBL assigns an inital POS-tag to each word in text in a way similar to that of the training period .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">null Starting with the new unannotated text</definiens>
			</definition>
			<definition id="8">
				<sentence>Remarkably , this EVC includes the SUSANNE corpus ( Sampson , 1995 ) – a golden corpus has been manually annotated such necessary English linguistic annotations as lemma , POS tags , chunking tags , syntactic trees , etc .</sentence>
				<definiendum id="0">SUSANNE corpus</definiendum>
			</definition>
			<definition id="9">
				<sentence>Predicate π follows the specified templates of transformation rules .</sentence>
				<definiendum id="0">Predicate π</definiendum>
				<definiens id="0">follows the specified templates of transformation rules</definiens>
			</definition>
			<definition id="10">
				<sentence>* Complexity of the algorithm : O ( n*t*c ) where n : size of training set ( number of words ) ; t : size of possible transformation rule set ( number of candidate rules ) ; c : size of corpus satisfied rule applying condition ( number of order satisfied predicate π ) .</sentence>
				<definiendum id="0">candidate rules</definiendum>
				<definiens id="0">n*t*c ) where n : size of training set ( number of words</definiens>
			</definition>
			<definition id="11">
				<sentence>Through the statistical table 3 below , the information of Vietnamese POS-tags can be seen as follows : Case 1,2,3,4 : no need for any disambiguation of English POS-tags .</sentence>
				<definiendum id="0">Vietnamese POS-tags</definiendum>
				<definiens id="0">no need for any disambiguation of English POS-tags</definiens>
			</definition>
</paper>

		<paper id="1103">
			<definition id="0">
				<sentence>RAAP is a content-based collaborative information filtering for helping the user to classify domain specific information found in the WWW , and also recommends these URLs to other users with similar interests .</sentence>
				<definiendum id="0">RAAP</definiendum>
				<definiens id="0">a content-based collaborative information filtering for helping the user to classify domain specific information found in the WWW</definiens>
			</definition>
			<definition id="1">
				<sentence>Fab system , which uses contentbased techniques instead of user ratings to create profiles of users .</sentence>
				<definiendum id="0">Fab system</definiendum>
				<definiens id="0">uses contentbased techniques instead of user ratings to create profiles of users</definiens>
			</definition>
			<definition id="2">
				<sentence>( , ) Pr ( , ) 1 ( 1 ) ( , ) CS j k ojk MaxCS i k = where Pr ( , ) ojkmeans the probability of object j to be assigned to cluster k ; The ( , ) CS j k means the function to calculate the counter-similarity between object j and cluster k ; ( , ) Max CS i k means the maximum counter-similarity between an object and cluster k .</sentence>
				<definiendum id="0">Pr</definiendum>
			</definition>
			<definition id="3">
				<sentence>Input : the number of clusters k and item attributes Output : a set of k clusters that minimizes the squarederror criterion , and the probability of each item to be assigned to each cluster center , which are represented as a fuzzy set .</sentence>
				<definiendum id="0">Input</definiendum>
				<definiens id="0">the number of clusters k and item attributes Output : a set of k clusters that minimizes the squarederror criterion , and the probability of each item to be assigned to each cluster center</definiens>
			</definition>
			<definition id="4">
				<sentence>Pearson correlation measures the degree to which a linear relationship exists between two variables .</sentence>
				<definiendum id="0">Pearson correlation</definiendum>
				<definiens id="0">measures the degree to which a linear relationship exists between two variables</definiens>
			</definition>
			<definition id="5">
				<sentence>, , 1 22 11 ( ) ( ) ( , ) ( 3 ) ( ) ( ) m uk u ul u u mm uk u ul u uu RRRR sim k l RR RR = == −− = ∑ ∑∑ where ( , ) sim k l means the similarity between item k and l ; m means the total number of users , who rates on both item k and l ; u R are the average ratings of user u ; , uk R , , ul R mean the rating of user u on item k and l respectively .</sentence>
				<definiendum id="0">u R</definiendum>
				<definiens id="0">the average ratings of user u ; , uk R , , ul R mean the rating of user u on item k and l respectively</definiens>
			</definition>
			<definition id="6">
				<sentence>The general formula for a prediction on item k of user u ( Resnick et al. , 1994 ) is : , 1 , 1 ( ) ( , ) ( 5 ) ( , ) n ui i i uk k n i RRsimki PR sim k i = = −× =+ ∑ ∑ where , uk P represents the predication for the user u on item k ; n means the total neighbours of item k ; , ui R means the user u rating on item i ; k R is the average ratings on item k ; ( , ) sim k i means the similarity between item k and its’ neighbour i ; i R means the average ratings on item i .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">means the total neighbours of item k ; , ui R means the user u rating on item i ; k R is the average ratings on item k</definiens>
			</definition>
			<definition id="7">
				<sentence>In Equation 5 , k R is the average rating of all ratings on item k .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">the average rating of all ratings on item k</definiens>
			</definition>
			<definition id="8">
				<sentence>( ) / 8Amn= where , n is the number of items whose ranking value is lager than a given threshold , m is the number of items containing attribute A among n items and its ranking is larger than threshold .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of items whose ranking value is lager than a given threshold</definiens>
				<definiens id="1">the number of items containing attribute A among n items and its ranking is larger than threshold</definiens>
			</definition>
			<definition id="9">
				<sentence>MAE ( Mean Absolute Error ) has widely been used in evaluating the accuracy of a recommender system by comparing the numerical recommendation scores against the actual user ratings in the test data .</sentence>
				<definiendum id="0">MAE</definiendum>
			</definition>
			<definition id="10">
				<sentence>, , 1 ( 7 ) n ui ui u PR MAE n = − = ∑ where , ui P means the user u prediction on item i ; , ui R means the user u rating on item i in the test data ; n is the number of rating-prediction pairs between the test data and the prediction result .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">n ui ui u PR MAE n = − = ∑ where , ui P means the user u prediction on item i ; , ui R means the user u rating on item i in the test data</definiens>
				<definiens id="1">the number of rating-prediction pairs between the test data and the prediction result</definiens>
			</definition>
			<definition id="11">
				<sentence>Comparison From the Figure 7 , it can be observed that the performance of combination ICHM is the best , and the second is the enlarged ICHM , which is followed by the item-based collaborative method , the last is UCHM ( User-based Clustering Hybrid Method ) which applies the clustering technique described in Section 3 to user-based collaborative filtering , where user profiles are clustered instead of item contents .</sentence>
				<definiendum id="0">ICHM</definiendum>
				<definiens id="0">User-based Clustering Hybrid Method ) which applies the clustering technique described in Section 3 to user-based collaborative filtering , where user profiles are clustered instead of item contents</definiens>
			</definition>
</paper>

		<paper id="0505">
			<definition id="0">
				<sentence>Law reports form the most important part of a lawyer’s or law student’s reading matter .</sentence>
				<definiendum id="0">Law</definiendum>
				<definiens id="0">reports form the most important part of a lawyer’s or law student’s reading matter</definiens>
			</definition>
			<definition id="1">
				<sentence>Manual summarisation can be considered as a form of information selection using an unconstrained vocabulary with no artificial linguistic limitations .</sentence>
				<definiendum id="0">Manual summarisation</definiendum>
				<definiens id="0">a form of information selection using an unconstrained vocabulary with no artificial linguistic limitations</definiens>
			</definition>
			<definition id="2">
				<sentence>OWN : sentences which describe any aspect of the work presented in the current paper .</sentence>
				<definiendum id="0">OWN</definiendum>
				<definiens id="0">sentences which describe any aspect of the work presented in the current paper</definiens>
			</definition>
			<definition id="3">
				<sentence>The DTD defines a House of Lords Judgment as a J element whose BODY element is composed of a number of LORD elements .</sentence>
				<definiendum id="0">DTD</definiendum>
			</definition>
			<definition id="4">
				<sentence>CoNLL ( Conference on Natural Language Learning ) is a yearly meeting of researchers interested in using machine learning to solve problems in natural language processing .</sentence>
				<definiendum id="0">CoNLL</definiendum>
				<definiens id="0">a yearly meeting of researchers interested in using machine learning to solve problems in natural language processing</definiens>
			</definition>
			<definition id="5">
				<sentence>The maximum entropy algorithm produces a distribution pa0 a1a3a2xa4 ca5 based on a set of labelled training examples , where a2x is the vector of active features .</sentence>
				<definiendum id="0">maximum entropy algorithm</definiendum>
				<definiendum id="1">a2x</definiendum>
				<definiens id="0">produces a distribution pa0 a1a3a2xa4 ca5 based on a set of labelled training examples</definiens>
				<definiens id="1">the vector of active features</definiens>
			</definition>
			<definition id="6">
				<sentence>The correlation coefficient is a statistical measure of ‘related-ness’ .</sentence>
				<definiendum id="0">correlation coefficient</definiendum>
			</definition>
</paper>

		<paper id="1716">
			<definition id="0">
				<sentence>SKCC consists of one general database and six sub-databases .</sentence>
				<definiendum id="0">SKCC</definiendum>
			</definition>
			<definition id="1">
				<sentence>In sentence [ 1 ] , the word modified by �清淡� is the noun�茶� ( tea ) , which is a kind of �drink� ; while the word�清淡� in sentence [ 2 ] is a predicate of “business” .</sentence>
				<definiendum id="0">]</definiendum>
				<definiens id="0">a predicate of “business”</definiens>
			</definition>
			<definition id="2">
				<sentence>SKCC is a well-structured Chinese-English bilingual semantic resource , as described in the paper , it has more than 66,000 Chinese words and their English counterparts classified , and the accurate description of about 1.5 million attributes further enriched the abundance of lexical semantic knowledge .</sentence>
				<definiendum id="0">SKCC</definiendum>
				<definiens id="0">a well-structured Chinese-English bilingual semantic resource</definiens>
			</definition>
</paper>

		<paper id="1715">
			<definition id="0">
				<sentence>Explanation-based Learning ( EBL ) is a technique to speed-up parsing .</sentence>
				<definiendum id="0">Explanation-based Learning ( EBL )</definiendum>
				<definiens id="0">a technique to speed-up parsing</definiens>
			</definition>
			<definition id="1">
				<sentence>Explanation-based learning ( EBL ) is a method to speed-up rule-based parsing via the caching of examples .</sentence>
				<definiendum id="0">Explanation-based learning ( EBL</definiendum>
				<definiens id="0">a method to speed-up rule-based parsing via the caching of examples</definiens>
			</definition>
			<definition id="2">
				<sentence>The PS generates , besides the output , a documentation of the reasoning steps involved ( the explanation ) .</sentence>
				<definiendum id="0">PS generates</definiendum>
				<definiens id="0">besides the output , a documentation of the reasoning steps involved ( the explanation )</definiens>
			</definition>
			<definition id="3">
				<sentence>The utility problem questions the claim of speeding-up applications ( Minton , 1990 ) : Retrieving cached solutions in addition to regular processing requires extra time .</sentence>
				<definiendum id="0">utility problem</definiendum>
				<definiens id="0">questions the claim of speeding-up applications ( Minton , 1990 ) : Retrieving cached solutions in addition to regular processing requires extra time</definiens>
			</definition>
			<definition id="4">
				<sentence>Uppercase variables stand for collections and lowercase variables for elements .</sentence>
				<definiendum id="0">Uppercase variables</definiendum>
				<definiens id="0">stand for collections and lowercase variables for elements</definiens>
			</definition>
			<definition id="5">
				<sentence>a86 is the set of observable data with each a28a84a87a88a86 being a tuple a28 a8 a17 a61 a32a59a62 a21 .3 a89 is the set of data classified according to a52 , with a90a51a8 a17 a28a72a32 a61 a21 .</sentence>
				<definiendum id="0">a86</definiendum>
				<definiens id="0">the set of observable data with each a28a84a87a88a86 being a tuple a28 a8 a17 a61 a32a59a62 a21 .3 a89 is the set of data classified according to a52</definiens>
			</definition>
			<definition id="6">
				<sentence>Transferring this notation to the description of parsing , a52 is a syntactic formalism and a58 a grammar .</sentence>
				<definiendum id="0">a52</definiendum>
				<definiens id="0">a syntactic formalism</definiens>
			</definition>
			<definition id="7">
				<sentence>a53 is the union of syntax trees and morphosyntactic tags .</sentence>
				<definiendum id="0">a53</definiendum>
			</definition>
			<definition id="8">
				<sentence>a86 is a corpus tagged with a53 .</sentence>
				<definiendum id="0">a86</definiendum>
			</definition>
			<definition id="9">
				<sentence>a89 is a treebank , a cache of parse trees , or a history of explanations .</sentence>
				<definiendum id="0">a89</definiendum>
				<definiens id="0">a treebank , a cache of parse trees , or a history of explanations</definiens>
			</definition>
			<definition id="10">
				<sentence>Elements of a118 are caching ( no generalization ) , induction ( hypothesis after data inspection ) and abduction ( hypothesis during classification ) .</sentence>
				<definiendum id="0">caching</definiendum>
				<definiens id="0">no generalization ) , induction ( hypothesis after data inspection ) and abduction ( hypothesis during classification )</definiens>
			</definition>
			<definition id="11">
				<sentence>a107 is a deductive inference if a60 is obtained from an induction ( a reduction of a28 with the help of a132a106a71a29a81a56a71a47a133a59a71 ) .</sentence>
				<definiendum id="0">a107</definiendum>
			</definition>
			<definition id="12">
				<sentence>AEBL acquires empirical knowledge similarly to DEBL .</sentence>
				<definiendum id="0">AEBL</definiendum>
			</definition>
			<definition id="13">
				<sentence>Macro Learning is the common term for the combination of EBL with recursive deduction ( Tadepalli , 1991 ) .</sentence>
				<definiendum id="0">Macro Learning</definiendum>
			</definition>
			<definition id="14">
				<sentence>Explanation-based Learning has been used to speedup natural language parsing .</sentence>
				<definiendum id="0">Explanation-based Learning</definiendum>
			</definition>
</paper>

		<paper id="0806">
			<definition id="0">
				<sentence>NLP is experiencing an explosion in the quantity of electronic text available .</sentence>
				<definiendum id="0">NLP</definiendum>
				<definiens id="0">experiencing an explosion in the quantity of electronic text available</definiens>
			</definition>
			<definition id="1">
				<sentence>Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) ( Cunningham et al. , 1997 ) and the Alembic Workbench ( Day et al. , 1997 ) ) as well as NLP tools and resources that can be manipulated from the GUI .</sentence>
				<definiendum id="0">Many</definiendum>
				<definiendum id="1">Alembic Workbench</definiendum>
				<definiens id="0">provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) ( Cunningham et al. , 1997 ) and the</definiens>
			</definition>
			<definition id="2">
				<sentence>Machine learning methods should be interchangeable : Transformation-based learning ( TBL ) ( Brill , 1993 ) and Memory-based learning ( MBL ) ( Daelemans et al. , 2002 ) have been applied to many different problems , so a single interchangeable component should be used to represent each method .</sentence>
				<definiendum id="0">Machine learning methods</definiendum>
				<definiens id="0">Transformation-based learning ( TBL ) ( Brill , 1993 ) and Memory-based learning ( MBL ) ( Daelemans et al. , 2002 ) have been applied to many different problems</definiens>
			</definition>
			<definition id="3">
				<sentence>lexical processing tokenization , word segmentation and morphological analysis ; feature extraction extracting lexical and annotation features from the current context in sequences , bag of words from segments of text data-structures and algorithms efficient lexical representations , lexicons , tagsets and statistics ; Viterbi , beam-search and n-best sequence taggers , parsing algorithms ; machine learning methods statistical models : Na¨ıve Bayes , Maximum Entropy , Conditional Random Fields ; and other methods : Decision Trees and Lists , TBL and MBL ; resources APIs to WordNet ( Fellbaum , 1998 ) , Google and other lexical resources such as gazetteers , ontologies and machine readable dictionaries ; existing tools integrating existing open source components and providing interfaces to existing tools that are only distributed as executables .</sentence>
				<definiendum id="0">Maximum Entropy</definiendum>
				<definiendum id="1">TBL</definiendum>
				<definiens id="0">annotation features from the current context in sequences , bag of words from segments of text data-structures and algorithms efficient lexical representations , lexicons , tagsets and statistics</definiens>
				<definiens id="1">Decision Trees and Lists ,</definiens>
			</definition>
</paper>

		<paper id="1721">
			<definition id="0">
				<sentence>Given a dictionary and a sentence , our base segmentation algorithm finds all possible segmentations of the sentence with respect to the dictionary , computes the probability of each segmentation , and chooses the segmentation with the highest probability .</sentence>
				<definiendum id="0">base segmentation algorithm</definiendum>
				<definiens id="0">finds all possible segmentations of the sentence with respect to the dictionary , computes the probability of each segmentation</definiens>
			</definition>
			<definition id="1">
				<sentence>The probability of a word is estimated from the training corpus as a30a38a31 a22a2a36a37a42a8a47a2a48a50a49a52a51 a47 , where a53a54a31a22a2a36 is the number of times that the word a22 occurs in the training corpus , and a53 is the number of words in the training corpus .</sentence>
				<definiendum id="0">a53a54a31a22a2a36</definiendum>
				<definiendum id="1">a53</definiendum>
				<definiens id="0">the number of times that the word a22 occurs in the training corpus</definiens>
				<definiens id="1">the number of words in the training corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>The in-word probability of a character is the probability that the character occurs in a word of two or more characters .</sentence>
				<definiendum id="0">in-word probability of a character</definiendum>
				<definiens id="0">the probability that the character occurs in a word of two or more characters</definiens>
			</definition>
			<definition id="3">
				<sentence>Consider the text a109a68a110 again , in the testing data , a59a123a109a44a110a61a124a44a125 is segmented into a59 /a109a61a110 /a124a44a125 by our base algorithm .</sentence>
				<definiendum id="0">a59a123a109a44a110a61a124a44a125</definiendum>
				<definiens id="0">in the testing data ,</definiens>
			</definition>
			<definition id="4">
				<sentence>pus , pkd2 consists of the words in pkd1 and the words converted from pkd1 by changing the GB encoding to ASCII encoding for the numeric digits and the English letters , and pkd3 consists of the words in pkd2 and the words automatically extracted from the PK testing texts using the procedures described in section 3 .</sentence>
				<definiendum id="0">pkd2</definiendum>
			</definition>
</paper>

		<paper id="0404">
			<definition id="0">
				<sentence>Subjective remarks come in a variety of forms , including opinions , rants , allegations , accusations , suspicions , and speculation .</sentence>
				<definiendum id="0">Subjective remarks</definiendum>
				<definiens id="0">come in a variety of forms , including opinions , rants , allegations , accusations , suspicions , and speculation</definiens>
			</definition>
			<definition id="1">
				<sentence>Meta-Bootstrapping and Basilisk were designed to learn words that belong to a semantic category ( e.g. , “truck” is a VEHICLE and “seashore” is a LOCATION ) .</sentence>
				<definiendum id="0">“seashore”</definiendum>
			</definition>
			<definition id="2">
				<sentence>Next , MetaBoot computes a score for each pattern based upon the number of seed words among its extractions .</sentence>
				<definiendum id="0">MetaBoot</definiendum>
			</definition>
			<definition id="3">
				<sentence>A second level of bootstrapping ( the “meta-” bootstrapping part ) makes the algorithm more robust .</sentence>
				<definiendum id="0">second level of bootstrapping</definiendum>
				<definiens id="0">the “meta-” bootstrapping part ) makes the algorithm more robust</definiens>
			</definition>
			<definition id="4">
				<sentence>Similarly , Basilisk begins with an unannotated text corpus and a small set of 2Our implementation of Meta-Bootstrapping learns individual nouns ( vs. noun phrases ) and discards capitalized words .</sentence>
				<definiendum id="0">Basilisk</definiendum>
				<definiens id="0">begins with an unannotated text corpus and a small set of 2Our implementation of Meta-Bootstrapping learns individual nouns ( vs. noun phrases</definiens>
			</definition>
			<definition id="5">
				<sentence>cowardice embarrassment hatred outrage crap fool hell slander delight gloom hypocrisy sigh disdain grievance love twit dismay happiness nonsense virtue Table 3 : Subjective Seed Words Extraction Patterns Examples of Extracted Nouns expressed &lt; dobj &gt; condolences , hope , grief , views , worries , recognition indicative of &lt; np &gt; compromise , desire , thinking inject &lt; dobj &gt; vitality , hatred reaffirmed &lt; dobj &gt; resolve , position , commitment voiced &lt; dobj &gt; outrage , support , skepticism , disagreement , opposition , concerns , gratitude , indignation show of &lt; np &gt; support , strength , goodwill , solidarity , feeling &lt; subject &gt; was shared anxiety , view , niceties , feeling Table 4 : Extraction Pattern Examples terns that were discovered to be associated with subjective nouns .</sentence>
				<definiendum id="0">position</definiendum>
				<definiens id="0">Subjective Seed Words Extraction Patterns Examples of Extracted Nouns expressed &lt; dobj &gt; condolences , hope , grief , views , worries</definiens>
			</definition>
			<definition id="6">
				<sentence>WBO includes a set of stems positively correlated with the subjective training examples ( subjStems ) and a set of stems positively correlated with the objective training examples ( objStems ) .</sentence>
				<definiendum id="0">WBO</definiendum>
				<definiens id="0">includes a set of stems positively correlated with the subjective training examples ( subjStems ) and a set of stems positively correlated with the objective training examples ( objStems )</definiens>
			</definition>
			<definition id="7">
				<sentence>As our evaluation metrics , we computed accuracy ( Acc ) as the percentage of the system’s classifications that match the gold-standard , and precision ( Prec ) and recall ( Rec ) with respect to subjective sentences .</sentence>
				<definiendum id="0">accuracy ( Acc</definiendum>
				<definiendum id="1">precision</definiendum>
				<definiendum id="2">recall</definiendum>
				<definiens id="0">the percentage of the system’s classifications that match the gold-standard</definiens>
			</definition>
			<definition id="8">
				<sentence>Row ( 1 ) shows a Naive Bayes classifier that uses unigram bag-ofwords features , with one binary feature for the absence or presence in the sentence of each word that appeared during training .</sentence>
				<definiendum id="0">Naive Bayes classifier</definiendum>
				<definiens id="0">the absence or presence in the sentence of each word that appeared during training</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>We propose two basic approaches to feature representation : distribution-based representation , which simply looks at the distribution of features in the corpus data , and agreement-based representation which analyses the level of tokenwise agreement between multiple preprocessor systems .</sentence>
				<definiendum id="0">distribution-based representation</definiendum>
				<definiens id="0">simply looks at the distribution of features in the corpus data , and agreement-based representation which analyses the level of tokenwise agreement between multiple preprocessor systems</definiens>
			</definition>
			<definition id="1">
				<sentence>Countability is the syntactic property that determines whether a noun can take singular and plural forms , and affects the range of permissible modifiers .</sentence>
				<definiendum id="0">Countability</definiendum>
				<definiens id="0">the syntactic property that determines whether a noun can take singular and plural forms , and affects the range of permissible modifiers</definiens>
			</definition>
			<definition id="2">
				<sentence>Feature clusters are either one-dimensional ( describing a single multivariate feature ) or twodimensional ( describing the interaction between two multivariate features ) , with each dimension describing a lexical or syntactic property of the construction in question .</sentence>
				<definiendum id="0">Feature clusters</definiendum>
				<definiens id="0">describing a single multivariate feature ) or twodimensional ( describing the interaction between two multivariate features ) , with each dimension describing a lexical or syntactic property of the construction in question</definiens>
			</definition>
			<definition id="3">
				<sentence>The κ statistic ( Carletta , 1996 ) is recast as : κ ( fs , w ) ( sys , sys ) = agr ( fs , w ) ( sys , sys ) − P agr ( fs , ∗ ) ( sys , sys ) N − P agr ( fs , ∗ ) ( sys , sys ) N In this modified form , κ ( fs , w ) represents the divergence in relative agreement wrt f s for target noun w , relative to the mean relative agreement wrt f s over all words .</sentence>
				<definiendum id="0">κ statistic</definiendum>
				<definiendum id="1">w )</definiendum>
				<definiens id="0">target noun w , relative to the mean relative agreement wrt f s over all words</definiens>
			</definition>
			<definition id="4">
				<sentence>We additionally calculate the mean value of each metric across the system pairings and the overall correlated weight for each countability class C as : cw ( C , w ) ( sys , sys ) = P fs∈C|tok ( fs , w ) ( sys ) ∩tok ( fs , w ) ( sys ) |P i|tok ( fi , w ) ( sys ) ∩tok ( fi , w ) ( sys ) | Correlated weight describes the occurrence of correlated features in the given countability class relative to other correlated features .</sentence>
				<definiendum id="0">fi , w )</definiendum>
				<definiendum id="1">w )</definiendum>
				<definiens id="0">the mean value of each metric across the system pairings and the overall correlated weight for each countability class C as : cw ( C , w ) ( sys , sys ) = P fs∈C|tok</definiens>
			</definition>
			<definition id="5">
				<sentence>Classification accuracies are thus simply used for classifier comparison within a basic classifier architecture ( SINGLE or SUITE ) , and F-score is Classifier Accuracy F-score Majority class .746 .855 Unsupervised .798 .879 Dist ( POS , SUITE ) .928 .953 Dist ( POS , SINGLE ) ( .850 ) .940 Dist ( chunk , SUITE ) .933 .956 Dist ( chunk , SINGLE ) ( .853 ) .942 Dist ( RASP , SUITE ) .923 .950 Dist ( RASP , SINGLE ) ( .847 ) .940 Dist ( AllCON , SUITE ) .939 .960 Dist ( AllCON , SINGLE ) ( .857 ) .944 Dist ( AllMEAN , SUITE ) .937 .959 Agree ( Token , SUITE ) .902 .936 Agree ( Class , SUITE ) .911 .941 Table 1 : Basic results for countable nouns Classifier Accuracy F-score Majority class .783 ( .357 ) Unsupervised .342 .391 Dist ( POS , SUITE ) .945 .876 Dist ( POS , SINGLE ) ( .850 ) .861 Dist ( chunk , SUITE ) .945 .876 Dist ( chunk , SINGLE ) ( .853 ) .861 Dist ( RASP , SUITE ) .944 .872 Dist ( RASP , SINGLE ) ( .847 ) .851 Dist ( AllCON , SUITE ) .952 .892 Dist ( AllCON , SINGLE ) ( .857 ) .873 Dist ( AllMEAN , SUITE ) .954 .895 Agree ( Token , SUITE ) .923 .825 Agree ( Class , SUITE ) .923 .824 Table 2 : Basic results for uncountable nouns the evaluation metric of choice for overall evaluation .</sentence>
				<definiendum id="0">Classification accuracies</definiendum>
				<definiendum id="1">Dist</definiendum>
				<definiendum id="2">Dist</definiendum>
				<definiendum id="3">Dist</definiendum>
				<definiendum id="4">Dist</definiendum>
				<definiendum id="5">Dist ( AllCON , SINGLE )</definiendum>
				<definiendum id="6">Dist</definiendum>
				<definiendum id="7">Agree ( Class , SUITE</definiendum>
				<definiens id="0">Basic results for countable nouns Classifier Accuracy F-score Majority class</definiens>
			</definition>
</paper>

		<paper id="0104">
			<definition id="0">
				<sentence>P ( E ) can be ignored , and P ( E|C ) is reduced to a product of P ( e k |c k ) if independence of e k with e j , and e k with c j ( j k ) are assumed .</sentence>
				<definiendum id="0">P ( E|C</definiendum>
				<definiens id="0">reduced to a product of P ( e k |c k ) if independence of e k with e j , and e k with c j ( j k ) are assumed</definiens>
			</definition>
			<definition id="1">
				<sentence>The test set consists of 162 non-capital city names randomly selected from the map , six from each of the twenty-seven provinces excluding Taiwan ( where some names are in Wade-Giles convention ) .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of 162 non-capital city names randomly selected from the map , six from each of the twenty-seven provinces excluding Taiwan ( where some names are in Wade-Giles convention )</definiens>
			</definition>
</paper>

		<paper id="0302">
			<definition id="0">
				<sentence>Like competitive linking , ProAlign uses a constrained search to find high scoring alignments .</sentence>
				<definiendum id="0">ProAlign</definiendum>
				<definiens id="0">uses a constrained search to find high scoring alignments</definiens>
			</definition>
			<definition id="1">
				<sentence>An alignment A for two sentences E and F is a set of links such that every word in E and F participates in at least one link , and a word linked to e0 or f0 participates in no other links .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">a set of links such that every word in E and F participates in at least one link , and a word linked to e0 or f0 participates in no other links</definiens>
			</definition>
			<definition id="2">
				<sentence>The second constraint , known as the cohesion constraint ( Fox , 2002 ) , uses the dependency tree ( Mel’ˇcuk , 1987 ) of the English sentence to restrict possible link combinations .</sentence>
				<definiendum id="0">cohesion constraint</definiendum>
				<definiens id="0">uses the dependency tree ( Mel’ˇcuk , 1987 ) of the English sentence to restrict possible link combinations</definiens>
			</definition>
			<definition id="3">
				<sentence>We define spanH ( ei , TE , A ) = [ k1 , k2 ] , where k1 = min { j|l ( i , j ) ∈ A } k2 = max { j|l ( i , j ) ∈ A } In Figure 1 , for the node reboot , the phrase span is [ 4,4 ] and the head span is also [ 4,4 ] ; for the node discover ( with the link between to and `a in place ) , the phrase span is [ 2,11 ] and the head span is the empty set ∅ .</sentence>
				<definiendum id="0">phrase span</definiendum>
				<definiendum id="1">phrase span</definiendum>
				<definiens id="0">the empty set ∅</definiens>
			</definition>
			<definition id="4">
				<sentence>An alignment A consists of t links { l1 , l2 , ... , lt } , where each lk = l ( eik , fjk ) for some ik and jk .</sentence>
				<definiendum id="0">alignment A</definiendum>
				<definiens id="0">consists of t links { l1 , l2 , ... , lt }</definiens>
			</definition>
			<definition id="5">
				<sentence>Link probability is the number of time two words are linked , divided by the number of times they co-occur .</sentence>
				<definiendum id="0">Link probability</definiendum>
				<definiens id="0">the number of time two words are linked , divided by the number of times they co-occur</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>Combinatory Categorial Grammar ( CCG ) ( Steedman , 2000 ) , is a grammatical theory which provides a completely transparent interface between surface syntax and underlying semantics , such that each syntactic derivation corresponds directly to an interpretable semantic representation which includes long-range dependencies that arise through control , raising , coordination and extraction .</sentence>
				<definiendum id="0">Combinatory Categorial Grammar ( CCG )</definiendum>
				<definiens id="0">a grammatical theory which provides a completely transparent interface between surface syntax and underlying semantics , such that each syntactic derivation corresponds directly to an interpretable semantic representation which includes long-range dependencies that arise through control , raising , coordination and extraction</definiens>
			</definition>
			<definition id="1">
				<sentence>The CCG parser returns the local and long-range word-word dependencies that express the predicateargument structure corresponding to the derivation .</sentence>
				<definiendum id="0">CCG parser</definiendum>
				<definiens id="0">returns the local and long-range word-word dependencies that express the predicateargument structure corresponding to the derivation</definiens>
			</definition>
			<definition id="2">
				<sentence>Probabilities of a parse constituent belonging to a given semantic role are calculated from the following features : The phrase type feature indicates the syntactic type of the phrase expressing the semantic roles : examples include noun phrase ( NP ) , verb phrase ( VP ) , and clause ( S ) .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">the syntactic type of the phrase expressing the semantic roles : examples include noun phrase ( NP ) , verb phrase</definiens>
			</definition>
			<definition id="3">
				<sentence>The parse tree path feature , designed to capture grammatical relations between constituents , is replaced with a feature defined as follows : If there is a dependency in the predicate-argument structure of the CCG derivation between two words w and w 0 , the path feature from w to w 0 is defined as the lexical category of the functor , the argument slot i occupied by the argument , plus an arrow ( or ! )</sentence>
				<definiendum id="0">CCG derivation</definiendum>
				<definiens id="0">parse tree path feature , designed to capture grammatical relations between constituents</definiens>
			</definition>
			<definition id="4">
				<sentence>Further mismatches occur because the predicate-argument structure returned by the CCG parser only contains syntactic dependencies , whereas the PropBank data also contain some anaphoric dependencies , eg. : ( 9 ) [ ARG0 Realist ’s ] negotiations to acquire Ammann Laser Technik AG ... ( 10 ) When properly applied , [ ARG0 the adhesive ] is designed to ... Such dependencies also do not correspond to a relation in the predicate-argument structure of the CCG derivation , and cause the path feature to be used .</sentence>
				<definiendum id="0">CCG parser</definiendum>
				<definiens id="0">the adhesive ] is designed to ... Such dependencies also do not correspond to a relation in the predicate-argument structure of the CCG derivation , and cause the path feature to be used</definiens>
			</definition>
			<definition id="5">
				<sentence>S ARG0 NP NNP London VP VBD denied ARG1 NP NNS plans ARGM-TMP PP IN on NP NNP Monday S [ dcl ] ARG0 NP N London S [ dcl ] nNP S [ dcl ] nNP ( S [ dcl ] nNP ) =NP denied ARG1 NP N plans ARGM-TMP ( SnNP ) n ( SnNP ) ( ( SnNP ) n ( SnNP ) ) =NP on NP N Monday Figure 4 : A sample sentence as produced by the Treebank parser ( left ) and by the CCG parser ( right ) .</sentence>
				<definiendum id="0">S ARG0 NP NNP London VP VBD denied ARG1 NP NNS</definiendum>
				<definiens id="0">plans ARGM-TMP PP IN on NP NNP Monday S [ dcl ] ARG0 NP N London S [ dcl ] nNP S [ dcl ] nNP ( S [ dcl ] nNP ) =NP denied ARG1 NP N plans ARGM-TMP ( SnNP ) n ( SnNP ) ( ( SnNP ) n ( SnNP</definiens>
				<definiens id="1">A sample sentence as produced by the Treebank parser ( left ) and by the CCG parser ( right )</definiens>
			</definition>
			<definition id="6">
				<sentence>The importance of long-range dependencies for our task is indicated by the fact that the performance on the Penn Treebank gold standard without traces Treebank-based CCG-based Scoring Precision Recall F-score Precision Recall F-score Automatic parses Head word 72.6 61.2 66.4 71.0 63.1 66.8 Boundary 68.6 57.8 62.7 55.7 49.5 52.4 Gold-standard parses Head word 77.6 75.2 76.3 76.3 67.8 71.8 ( Treebank : w/o traces ) Boundary 74.4 66.5 70.2 67.5 60.0 63.5 Table 3 : Comparison of scoring regimes , using automatic parser output and gold standard parses .</sentence>
				<definiendum id="0">Treebank</definiendum>
				<definiens id="0">Treebank gold standard without traces Treebank-based CCG-based Scoring Precision Recall F-score Precision Recall F-score Automatic parses Head word</definiens>
			</definition>
</paper>

		<paper id="0101">
			<definition id="0">
				<sentence>GATE , a General Architecture for Text Engineering , is developed by the Sheffield NLP group and has been used in many language processing projects ; in particular for Information Extraction in a variety of languages ( Maynard and Cunningham , 2003 ) .</sentence>
				<definiendum id="0">GATE</definiendum>
				<definiens id="0">a General Architecture for Text Engineering , is developed by the Sheffield NLP group and has been used in many language processing projects ; in particular for Information Extraction in a variety of languages</definiens>
			</definition>
			<definition id="1">
				<sentence>A semantic query web user interface allows for queries such as ”Organization2Sesame ( http : //sesame.aidministrator.nl/ ) is an open source RDF ( S ) -based repository and querying facility .</sentence>
				<definiendum id="0">”Organization2Sesame ( http</definiendum>
				<definiens id="0">an open source RDF ( S ) -based repository and querying facility</definiens>
			</definition>
			<definition id="2">
				<sentence>Ontology Middleware Module is an enterprise back-end for formal knowledge management .</sentence>
				<definiendum id="0">Ontology Middleware Module</definiendum>
			</definition>
			<definition id="3">
				<sentence>Location sub-ontology Because the Geographic features ( Locations ) form a large part of the entities of general importance , we demance full text search engine 6Ontology Web Language ( OWL ) , http : //www.w3.org/TR/owl-semantics/ veloped a Location sub-ontology as part of the KIM ontology .</sentence>
				<definiendum id="0">Location sub-ontology</definiendum>
				<definiens id="0">//www.w3.org/TR/owl-semantics/ veloped a Location sub-ontology as part of the KIM ontology</definiens>
			</definition>
			<definition id="4">
				<sentence>The Location entity denotes an area in 3D space7 , which includes geographic entities with physical boundaries , such as geographical areas and landmasses , bodies of water , geological formations and also politically defined areas ( e.g. ”U.S. Administered areas” ) .</sentence>
				<definiendum id="0">Location entity</definiendum>
			</definition>
			<definition id="5">
				<sentence>The classification hierarchy ( consisting of 97 classes ) is based on the ADL Feature Type Thesaurus version 070203 .</sentence>
				<definiendum id="0">classification hierarchy</definiendum>
			</definition>
			<definition id="6">
				<sentence>In addition to the above predefined locations , KIM : • learns from the texts it analyses ; • has a comprehensive set of rules and patterns helping it to recognize unknown entities ; • has a Hidden Markov Model learner , capable of correcting symbolic patterns .</sentence>
				<definiendum id="0">KIM</definiendum>
				<definiens id="0">a Hidden Markov Model learner , capable of correcting symbolic patterns</definiens>
			</definition>
			<definition id="7">
				<sentence>GNS database is the official repository of foreign place-name decisions approved by the U.S. Board on Geographic Names ( US BGN ) and contains approximately 3.9 million features with 5.37 million names .</sentence>
				<definiendum id="0">GNS database</definiendum>
				<definiens id="0">the official repository of foreign place-name decisions approved by the U.S. Board on Geographic Names ( US BGN ) and contains approximately 3.9 million features with 5.37 million names</definiens>
			</definition>
			<definition id="8">
				<sentence>The data is available for download in standard formatted text files , which contain : unique feature index ( UFI ) , several names per Location ( the official name , short name , sometimes different transcriptions of the name ) , geographic coordinates ( one point ; no bounding rectangle ) .</sentence>
				<definiendum id="0">Location</definiendum>
				<definiens id="0">available for download in standard formatted text files , which contain : unique feature index</definiens>
			</definition>
			<definition id="9">
				<sentence>The locations KB is used for Information Extraction ( IE ) as part of the KIM system , combining symbolic and stochastic approaches , based on the ANNIE IE components from GATE .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiens id="0">IE ) as part of the KIM system , combining symbolic and stochastic approaches , based on the ANNIE IE components from GATE</definiens>
			</definition>
			<definition id="10">
				<sentence>Further , unknown or not precisely matching entities are recognized with patternbased grammars : • using location pre/post keys to identify locations , e.g. ”The River Thames” • using location pre/post keys + Location , e.g. ”north Egypt” , ”south Wales” • context-based recognition , such as : ”in” + Tokenwith-first-uppercase Number of disambiguation problems ( mostly in the case of Location names occurring in the composite name of other Entities ) are also detected and resolved : • ambiguity between Person and Organization , e.g. ”U.S. Navy” ( this would normally be recognized as a Person name from the pattern ”two initials + Family name” , but in this case the initials match a location alias ) • occurrence of locations in person names , e.g. ”Jack London” ( disambiguated because in the KB there is LexicalResource ”Jack” is a first name of Person ) • occurrence of locations in Organization names , e.g. ”Scotland Yard” ( disambiguated because in the KB there is such Organization ) Finally , some of the recognized Entities ( including Locations ) , which are not marked as noun by the part of speech tagger are discarded .</sentence>
				<definiendum id="0">”Jack London”</definiendum>
				<definiendum id="1">LexicalResource ”Jack”</definiendum>
				<definiens id="0">recognized with patternbased grammars : • using location pre/post keys to identify locations , e.g. ”The River Thames” • using location pre/post keys + Location , e.g. ”north Egypt” , ”south Wales” • context-based recognition , such as : ”in” + Tokenwith-first-uppercase Number of disambiguation problems ( mostly in the case of Location names occurring in the composite name of other Entities ) are also detected and resolved : • ambiguity between Person and Organization</definiens>
				<definiens id="1">a first name of Person ) • occurrence of locations in Organization names</definiens>
			</definition>
			<definition id="11">
				<sentence>The Corpus Benchmark Tool ( CBT ) is one of the components in GATE which enables automatic evaluation of an application in terms of Precision , Recall and F-measure , against a set of ground truths .</sentence>
				<definiendum id="0">Corpus Benchmark Tool ( CBT )</definiendum>
				<definiens id="0">one of the components in GATE which enables automatic evaluation of an application in terms of Precision</definiens>
			</definition>
			<definition id="12">
				<sentence>MUSE is an information extraction system developed within GATE which aims to perform named entity recognition on different types of text ( Maynard et al , 2002 ) .</sentence>
				<definiendum id="0">MUSE</definiendum>
				<definiens id="0">an information extraction system developed within GATE which aims to perform named entity recognition on different types of text</definiens>
			</definition>
			<definition id="13">
				<sentence>MUSE recognises the standard MUC entity types of Person , Location , Organisation , Date , Time , Percent , and some additional types such as Addresses and Identifiers .</sentence>
				<definiendum id="0">MUSE</definiendum>
				<definiens id="0">recognises the standard MUC entity types of Person , Location , Organisation , Date , Time , Percent</definiens>
			</definition>
			<definition id="14">
				<sentence>MUSE uses flat-list gazetteers which primarily contain contextual clues that help with the identification of named entities , e.g. , company designators ( such as Ltd , GmbH ) , job titles , person titles ( such as Mr , Mrs ) , common first names , typical organisation types ( e.g. , Ministry , University ) .</sentence>
				<definiendum id="0">MUSE</definiendum>
				<definiens id="0">uses flat-list gazetteers which primarily contain contextual clues that help with the identification of named entities</definiens>
			</definition>
</paper>

		<paper id="1714">
</paper>

		<paper id="1202">
			<definition id="0">
				<sentence>Ours is an age where many documents are archived electronically and are available whenever needed .</sentence>
				<definiendum id="0">Ours</definiendum>
				<definiens id="0">an age where many documents are archived electronically and are available whenever needed</definiens>
			</definition>
			<definition id="1">
				<sentence>The purpose of this paper is to present work which investigates the use of Singular Value Decomposition ( SVD ) as a means of determining if a word is a good candidate for inclusion in the headline .</sentence>
				<definiendum id="0">Singular Value Decomposition ( SVD )</definiendum>
				<definiens id="0">a good candidate for inclusion in the headline</definiens>
			</definition>
			<definition id="2">
				<sentence>Conceptually , SVD provides an analysis of the data which describes the relationship between the distribution of words and sentences .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">provides an analysis of the data which describes the relationship between the distribution of words</definiens>
			</definition>
			<definition id="3">
				<sentence>Jin and Hauptmann ( 2001 ) provide a comparison of a variety of learning approaches used by researchers for modelling the content of headlines including the Iterative ExpectationMaximisation approach , the K-Nearest neighbours approach , a term vector approach and the approach of Witbrock and Mittal ( 1999 ) .</sentence>
				<definiendum id="0">K-Nearest neighbours</definiendum>
				<definiens id="0">provide a comparison of a variety of learning approaches used by researchers for modelling the content of headlines including the Iterative ExpectationMaximisation approach , the</definiens>
			</definition>
			<definition id="4">
				<sentence>The preprocessing , which mirrors that used by Witbrock and Mittal ( 1999 ) , replaces XML markup tags and punctuation ( except apostrophes ) with whitespace .</sentence>
				<definiendum id="0">preprocessing</definiendum>
				<definiens id="0">mirrors that used by Witbrock and Mittal ( 1999 ) , replaces XML markup tags and punctuation ( except apostrophes ) with whitespace</definiens>
			</definition>
			<definition id="5">
				<sentence>For example , in the context of information retrieval , this provides one way to retrieve additional documents that contain synonyms of query terms , where synonymy is defined by similarity of word co-occurrences .</sentence>
				<definiendum id="0">synonymy</definiendum>
				<definiens id="0">in the context of information retrieval , this provides one way to retrieve additional documents that contain synonyms of query terms</definiens>
			</definition>
			<definition id="6">
				<sentence>The SVD analysis provides another matrix which scores how well each word relates to each theme .</sentence>
				<definiendum id="0">SVD analysis</definiendum>
				<definiens id="0">provides another matrix which scores how well each word relates to each theme</definiens>
			</definition>
			<definition id="7">
				<sentence>For such a matrix , the SVD of A is a process that provides the right hand side of the following equation : A = U.S. Vtranspose where U is a t * r matrix , S is an r * r matrix , and V is an s * r matrix .</sentence>
				<definiendum id="0">SVD of A</definiendum>
				<definiendum id="1">S</definiendum>
				<definiendum id="2">V</definiendum>
				<definiens id="0">a process that provides the right hand side of the following equation : A = U.S. Vtranspose where U is a t * r matrix ,</definiens>
				<definiens id="1">an s * r matrix</definiens>
			</definition>
			<definition id="8">
				<sentence>The dimension size r is the rank of A , and is less than or equal to the number of columns of A , in this case , s. The matrix S is a diagonal matrix with interesting properties , the most important of which is that the diagonal is sorted by size .</sentence>
				<definiendum id="0">dimension size r</definiendum>
				<definiens id="0">the rank of A , and is less than or equal to the number of columns of A , in this case , s. The matrix S is a diagonal matrix with interesting properties</definiens>
			</definition>
			<definition id="9">
				<sentence>Of the resulting matrices , V is an indication of how each sentence relates to each theme , indicated by a score .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">an indication of how each sentence relates to each theme , indicated by a score</definiens>
			</definition>
			<definition id="10">
				<sentence>Cambridge : The MIT Press .</sentence>
				<definiendum id="0">Cambridge</definiendum>
			</definition>
			<definition id="11">
				<sentence>Witbrock , M. , and Mittal , V. ( 1999 ) Ultrasummarization : A statistical approach to generating highly condensed non-extractive summaries .</sentence>
				<definiendum id="0">Ultrasummarization</definiendum>
				<definiens id="0">A statistical approach to generating highly condensed non-extractive summaries</definiens>
			</definition>
</paper>

		<paper id="1308">
			<definition id="0">
				<sentence>The MEDLINE database is an online collection of abstracts for published journal articles in biology and medicine and contains more than nine million articles .</sentence>
				<definiendum id="0">MEDLINE database</definiendum>
				<definiens id="0">an online collection of abstracts for published journal articles in biology and medicine and contains more than nine million articles</definiens>
			</definition>
			<definition id="1">
				<sentence>By substituting Φ ( xi ) for each training example in S we derive the final form of the optimal decision function f , f ( x ) = sgn ( mX i yifiik ( x ; xi ) +b ) ( 5 ) where b 2 R is the bias and the Lagrange parameters fii ( fii ‚ 0 ) are estimated using quadratic optimization to maximize the following function w ( fi ) = mX i=1 fii ¡ 12 mX i ; j fiifijyiyjk ( xi ; xj ) ( 6 ) under the constraints that mX i=1 fiiyi = 0 ( 7 ) and 0 • fii • C ( 8 ) for i = 1 ; : : : ; m. C is a constant that controls the ratio between the complexity of the function and the number of misclassified training examples .</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">Lagrange parameters fii</definiendum>
				<definiendum id="2">j fiifijyiyjk</definiendum>
				<definiendum id="3">m. C</definiendum>
				<definiens id="0">a constant that controls the ratio between the complexity of the function and the number of misclassified training examples</definiens>
			</definition>
			<definition id="2">
				<sentence>where P denotes Precision and R Recall .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
			<definition id="3">
				<sentence>P is the ratio of the number of correctly found NE chunks to the number of found NE chunks , and R is the ratio of the number of correctly found NE chunks to the number of true NE chunks .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">the ratio of the number of correctly found NE chunks to the number of found NE chunks , and</definiens>
			</definition>
</paper>

		<paper id="0311">
			<definition id="0">
				<sentence>Speech-to-speech translation ( S2ST ) technologies consist of speech recognition , machine translation ( MT ) , and speech synthesis ( Waibel , 1996 ; Wahlster , 2000 ; Yamamoto , 2000 ) .</sentence>
				<definiendum id="0">Speech-to-speech translation</definiendum>
				<definiendum id="1">S2ST ) technologies</definiendum>
				<definiens id="0">consist of speech recognition , machine translation ( MT ) , and speech synthesis</definiens>
			</definition>
			<definition id="1">
				<sentence>Example-based MT ( EBMT ) is one of the corpusbased machine translation methods .</sentence>
				<definiendum id="0">Example-based MT</definiendum>
				<definiendum id="1">EBMT )</definiendum>
				<definiens id="0">one of the corpusbased machine translation methods</definiens>
			</definition>
			<definition id="2">
				<sentence>A meaning-equivalent sentence means a sentence having the main meaning of an input sentence despite lacking some unimportant information .</sentence>
				<definiendum id="0">meaning-equivalent sentence</definiendum>
				<definiens id="0">means a sentence having the main meaning of an input sentence despite lacking some unimportant information</definiens>
			</definition>
			<definition id="3">
				<sentence>Perplexity is used as a metric for how well a language model derived from a training set matches a test set ( Jurafsky and Martin , 2000 ) .</sentence>
				<definiendum id="0">Perplexity</definiendum>
				<definiens id="0">a metric for how well a language model derived from a training set matches a test set</definiens>
			</definition>
			<definition id="4">
				<sentence>Meaning-equivalent sentences are defined as follows : meaning-equivalent sentence ( to an input sentence ) A sentence that shares the main meaning with the input sentence despite lacking some unimportant information .</sentence>
				<definiendum id="0">Meaning-equivalent sentences</definiendum>
				<definiens id="0">follows : meaning-equivalent sentence ( to an input sentence ) A sentence that shares the main meaning with the input sentence despite lacking some unimportant information</definiens>
			</definition>
			<definition id="5">
				<sentence>Modality Clues tekudasai ( auxiliary verb ) Request teitadakeru ( auxiliary verb ) shi-tai ( expression ) Desire te-hoshii ( expression ) negau ( verb ) ka ( final particle ) Question ne ( final particle ) nai ( auxiliary verb or adjective ) Negation masen ( auxiliary verb ) Tense Clues Past ta ( auxiliary verb ) Table 3 : Clues for Discriminating Modalities in Japanese are also included .</sentence>
				<definiendum id="0">Modality Clues</definiendum>
				<definiens id="0">auxiliary verb ) Request teitadakeru ( auxiliary verb</definiens>
				<definiens id="1">final particle ) Question ne ( final particle ) nai ( auxiliary verb or adjective ) Negation masen ( auxiliary verb ) Tense Clues Past ta ( auxiliary verb</definiens>
				<definiens id="2">Clues for Discriminating Modalities in Japanese are also included</definiens>
			</definition>
			<definition id="6">
				<sentence>A speech act is a concept similar to modality in which speakers’ intentions are represented .</sentence>
				<definiendum id="0">speech act</definiendum>
				<definiens id="0">a concept similar to modality in which speakers’ intentions are represented</definiens>
			</definition>
			<definition id="7">
				<sentence>N denotes the number of content words in meaning-equivalent sentences .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of content words in meaning-equivalent sentences</definiens>
			</definition>
			<definition id="8">
				<sentence>Accuracy is defined as the ratio of the number of correctly equivalent sentences to that of total inputs .</sentence>
				<definiendum id="0">Accuracy</definiendum>
				<definiens id="0">the ratio of the number of correctly equivalent sentences to that of total inputs</definiens>
			</definition>
</paper>

		<paper id="1209">
			<definition id="0">
				<sentence>Open-Domain factoid Question Answering ( QA ) is defined as the task of answering fact-based questions phrased in Natural Language .</sentence>
				<definiendum id="0">Open-Domain factoid Question Answering ( QA</definiendum>
				<definiens id="0">the task of answering fact-based questions phrased in Natural Language</definiens>
			</definition>
			<definition id="1">
				<sentence>, would be identified as a question asking about a time ( or a time period ) , “Where is the sea of tranquility ? ”</sentence>
				<definiendum id="0">“Where</definiendum>
				<definiens id="0">a question asking about a time ( or a time period</definiens>
			</definition>
			<definition id="2">
				<sentence>“ IR Loss” represents the average number of questions for which the IR failed completely ( i.e. , the IR did not return even a single sentence that contains the correct answer ) .</sentence>
				<definiendum id="0">“ IR Loss”</definiendum>
				<definiens id="0">the average number of questions for which the IR failed completely</definiens>
			</definition>
			<definition id="3">
				<sentence>The IR precision is the precision of the IR system for the number of sentences considered .</sentence>
				<definiendum id="0">IR precision</definiendum>
			</definition>
			<definition id="4">
				<sentence>Answer-Pinpointing Precision Number Correct Overall Precision IR Sentences Total questions IR Precision IR Loss Classifier Re-ranker Classifier Re-ranker Classifier Re-ranker 1 500 0.266 0.742 0.0027 0.3565 29 46 0.058 0.092 10 500 0.2018 0.48 0.0016 0.4269 7 111 0.014 0.222 50 500 0.1155 0.386 0.0015 0.4885 6 150 0.012 0.3 100 500 0.0878 0.362 0.0015 0.5015 5 160 0.01 0.32 150 500 0.0763 0.35 0.0015 0.5138 5 167 0.01 0.334 200 500 0.0703 0.344 0.0015 0.5182 3 170 0.01 0.34 Table 3 : Results for Classifier and Re-ranker under varying conditions of IR .</sentence>
				<definiendum id="0">Answer-Pinpointing Precision Number Correct Overall Precision IR Sentences Total questions IR Precision IR Loss Classifier Re-ranker Classifier Re-ranker</definiendum>
				<definiens id="0">Results for Classifier and Re-ranker under varying conditions of IR</definiens>
			</definition>
</paper>

		<paper id="0509">
			<definition id="0">
				<sentence>10 Acknowledgements This research is supported by the Defense Advanced Research Projects Agency as part of the Translingual Information Detection , Extraction and Summarization ( TIDES ) program , under Grant N66001-001-1-8917 from the Space and Naval Warfare Systems Center , San Diego , and by the National Science Foundation under Grant IIS-0081962 .</sentence>
				<definiendum id="0">Extraction</definiendum>
				<definiens id="0">the Defense Advanced Research Projects Agency as part of the Translingual Information Detection</definiens>
			</definition>
</paper>

		<paper id="0308">
			<definition id="0">
				<sentence>In this paper we describe the TREQ-AL system , which builds on TREQ and aims at generating a word-alignment map for a parallel text ( a bitext ) .</sentence>
				<definiendum id="0">TREQ-AL system</definiendum>
				<definiens id="0">builds on TREQ and aims at generating a word-alignment map for a parallel text ( a bitext )</definiens>
			</definition>
			<definition id="1">
				<sentence>The alignment chains ( found in the previous step ) are given the highest priority in alignment disambiguation .</sentence>
				<definiendum id="0">alignment chains (</definiendum>
			</definition>
			<definition id="2">
				<sentence>TREQ-AL uses no external bilingual-resources .</sentence>
				<definiendum id="0">TREQ-AL</definiendum>
				<definiens id="0">uses no external bilingual-resources</definiens>
			</definition>
</paper>

		<paper id="1407">
			<definition id="0">
				<sentence>Difference in the semantic features of the components in the readings of ‘grow_proto’ and ‘grow_appear’ is illustrated in the following table : LOCATION , which indicates place where AGENT takes action .</sentence>
				<definiendum id="0">LOCATION</definiendum>
				<definiens id="0">indicates place where AGENT takes action</definiens>
			</definition>
</paper>

		<paper id="1705">
			<definition id="0">
				<sentence>Afterward , a bottom-up merging process applies the general rules to extract unknown word candidates .</sentence>
				<definiendum id="0">bottom-up merging process</definiendum>
				<definiens id="0">applies the general rules to extract unknown word candidates</definiens>
			</definition>
			<definition id="1">
				<sentence>selectivity ( precision ) , the range of non-sentences it identifies as problematic and 3 .</sentence>
				<definiendum id="0">selectivity ( precision )</definiendum>
				<definiens id="0">problematic and 3</definiens>
			</definition>
			<definition id="2">
				<sentence>The rules in table 2 are classified into two kinds : one kind is the rules which both its right-hand side symbols consist of detected morphemes , i.e , ( 1 ) , ( 2 ) , ( 7 ) , and ( 10 ) , the others are the rules that just one of its right-hand side symbols consists of detected morphemes , i.e , ( 3 ) , ( 4 ) , ( 5 ) , ( 6 ) , ( 8 ) , ( 9 ) , ( 11 ) , and ( 12 ) .</sentence>
				<definiendum id="0">right-hand side symbols</definiendum>
				<definiens id="0">consist of detected morphemes , i.e , ( 1 )</definiens>
				<definiens id="1">the rules that just one of its right-hand side symbols consists of detected morphemes , i.e , ( 3 )</definiens>
			</definition>
			<definition id="3">
				<sentence>Freqdocu ( LR ) &gt; =Threshold ( 3 ) ( 4 ) ( 5 ) ( 6 ) ( 8 ) ( 9 ) ( 11 ) ( 12 ) Pdocu ( L|R ) =1 ( 1 ) ( 3 ) ( 7 ) ( 8 ) ( 9 ) ( 12 ) Pdocu ( R|L ) =1 ( 1 ) ( 5 ) ( 9 ) ( 10 ) ( 11 ) ( 12 ) Category ( L ) is bound , verb , noun or adjective ( 5 ) ( 6 ) ( 8 ) ( 9 ) Category ( R ) is bound , verb , noun or adjective ( 3 ) ( 4 ) ( 11 ) ( 12 ) Notes : L denotes left terminal of right-hand side R denotes right terminal of right-hand side Threshold is a function of Length ( LR ) and text size .</sentence>
				<definiendum id="0">Freqdocu</definiendum>
				<definiendum id="1">Threshold</definiendum>
				<definiens id="0">Category ( R ) is bound , verb , noun or adjective ( 3 ) ( 4 ) ( 11 ) ( 12 ) Notes : L denotes left terminal of right-hand side R denotes right terminal of right-hand side</definiens>
				<definiens id="1">a function of Length ( LR ) and text size</definiens>
			</definition>
			<definition id="4">
				<sentence>==================================== ) , ( ) , ( RLfRLoccurenceco =− -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- ) ( ) ( ) , ( log ) , ( RPLP RLPRLMI = -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- ) , ( ) , ( ) , ( RLMIRLfRLVMI = -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- ) , ( ) ( ) ( ) , ( ) , ( RLf N RfLfRLf RLscoret − =− Notes : f ( L , R ) denotes the number of occurrences of L , R in the text ; N denotes the number of occurrences of all the tokens in the text ; length ( * ) denotes the length of * .</sentence>
				<definiendum id="0">R )</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">RLfRLoccurenceco =− -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- ) ( ) ( ) , ( log ) , ( RPLP RLPRLMI = -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- ) , ( ) , ( ) , ( RLMIRLfRLVMI = -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- --</definiens>
				<definiens id="1">the number of occurrences of L , R in the text</definiens>
				<definiens id="2">the number of occurrences of all the tokens in the text ; length ( * ) denotes the length of *</definiens>
			</definition>
</paper>

		<paper id="1601">
			<definition id="0">
				<sentence>Paraphrases , which stem from the variety of lexical and grammatical means of expressing meaning available in a language , pose challenges for a sentence generation system .</sentence>
				<definiendum id="0">Paraphrases</definiendum>
				<definiens id="0">stem from the variety of lexical and grammatical means of expressing meaning available in a language , pose challenges for a sentence generation system</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>Assume that we are given the training data B4DC CX BNDD CX B5BNBMBMBMBNB4DC D0 BNDD D0 B5BNDC CX BE CA D2 BNDD CX BECUB7BDBNA0BDCVBM The decision function CV in SVM framework is defined as : CVB4DCB5 BP D7CVD2B4CUB4DCB5B5 ( 1 ) CUB4DCB5 BP D0 CG CXBPBD DD CX AB CX C3B4DC CX BNDCB5B7CQ ( 2 ) where C3 is a kernel function , CQ BE CA is a threshold , and AB CX are weights .</sentence>
				<definiendum id="0">C3</definiendum>
				<definiendum id="1">CQ BE CA</definiendum>
				<definiendum id="2">AB CX</definiendum>
				<definiens id="0">a kernel function</definiens>
				<definiens id="1">a threshold</definiens>
			</definition>
			<definition id="1">
				<sentence>Besides , the weights AB CX satisfy the following constraints : BKCX BMBCAK AB CX AK BV and D0 CG CXBPBD AB CX DD CX BPBCBN where BV is a misclassification cost .</sentence>
				<definiendum id="0">BV</definiendum>
				<definiens id="0">a misclassification cost</definiens>
			</definition>
			<definition id="2">
				<sentence>For linear SVMs , the kernel function C3 is defined as : C3B4DC CX BNDCB5BPDC CX A1DCBM In this case , Equation 2 can be written as : CUB4DCB5 BP DBA1DCB7 CQ ( 3 ) where DB BP C8 D0 CXBPBD DD CX AB CX DC CX .</sentence>
				<definiendum id="0">linear SVMs</definiendum>
			</definition>
			<definition id="3">
				<sentence>BC , if randB4B5 AK D8 then remove the feature CU , where randB4B5 is a function which generates a random number from BC to BD , and D8 is a parameter to decide how many features are deleted .</sentence>
				<definiendum id="0">BC</definiendum>
				<definiendum id="1">randB4B5</definiendum>
				<definiendum id="2">D8</definiendum>
				<definiens id="0">the feature CU , where</definiens>
				<definiens id="1">a function which generates a random number from BC to BD</definiens>
				<definiens id="2">a parameter to decide how many features are deleted</definiens>
			</definition>
			<definition id="4">
				<sentence>F-measure is defined as : F-measure BP B4BD B7 AC BE B5D4D5 AC BE D4 B7 D5 ( 4 ) where D4 is precision and D5 is recall and AC is a parameter which decides the relative weight of precision and recall .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiendum id="1">D5</definiendum>
				<definiendum id="2">AC</definiendum>
				<definiens id="0">F-measure BP B4BD B7 AC BE B5D4D5 AC BE D4 B7 D5 ( 4 ) where D4 is precision and</definiens>
				<definiens id="1">a parameter which decides the relative weight of precision and recall</definiens>
			</definition>
			<definition id="5">
				<sentence>We used linear SVMs and set a misclassification cost BV to BCBMBCBDBIBHBGBD which is BDBPB4the average of DCA1DCB5 where DC is a feature vector in the 9,603 size training set .</sentence>
				<definiendum id="0">DC</definiendum>
				<definiens id="0">a feature vector in the 9,603 size training set</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>yes , no Syntactic GRAM FUNC Grammatical role ( for all NPs ) subject , predicative NP , dative object , direct object , oblique , unknown Syntactic SYN PAR Anaphor-antecedent agreement with respect to grammatical function yes , no Positional SDIST Distance between antecedent and anaphor in sentences 1 , 2 , 3 , 4 , 5 Semantic SEMCLASS Semantic class ( for all NPs ) person , organization , location , date , money , number , thing , abstract , unknown Semantic SEMCLASS AGR Anaphor-antecedent agreement with respect to semantic class yes , no , unknown Semantic GENDER AGR Anaphor-antecedent agreement with respect to gender same , compatible , incompatible , unknown Semantic RELATION Type of relation between anaphor and antecedent same-predicate , hypernymy , meronymy , compatible , incompatible , unknown ( 5 ) These three countries aren’t completely off the hook , though .</sentence>
				<definiendum id="0">Syntactic GRAM FUNC Grammatical role</definiendum>
				<definiens id="0">predicative NP , dative object , direct object , oblique , unknown Syntactic SYN PAR Anaphor-antecedent agreement with respect to grammatical function yes , no Positional SDIST</definiens>
				<definiens id="1">compatible , incompatible , unknown Semantic RELATION Type of relation between anaphor and antecedent same-predicate , hypernymy , meronymy , compatible , incompatible</definiens>
			</definition>
			<definition id="1">
				<sentence>The feature SYN PAR captures syntactic parallelism between anaphor and antecedent .</sentence>
				<definiendum id="0">SYN PAR</definiendum>
				<definiens id="0">captures syntactic parallelism between anaphor and antecedent</definiens>
			</definition>
			<definition id="2">
				<sentence>Word sense ambiguity is one of the reasons for misclassifications .</sentence>
				<definiendum id="0">Word sense ambiguity</definiendum>
				<definiens id="0">one of the reasons for misclassifications</definiens>
			</definition>
			<definition id="3">
				<sentence>We classified LOCATIONS into COUNTRY , ( US ) STATE , CITY , RIVER , LAKE and OCEAN , using mainly 11 http : //info.ox.ac.uk/bnc Table 3 : Patterns and Instantiations for other-anaphora ANTECEDENT PATTERN INSTANTIATIONS common noun ( O1 ) : ( N BD CUsgCV OR N BD CUplCV ) and other N BE CUplCV I CR BD : “ ( university OR universities ) and other schools” proper name ( O1 ) : ( N BD CUsgCV OR N BD CUplCV ) and other N BE CUplCV I D4 BD : “ ( person OR persons ) and other children” I D4 BE : “ ( child OR children ) and other persons” ( O2 ) : N BD and other N BE CUplCV I D4 BF : “Will Quinlan and other children” gazetteers .</sentence>
				<definiendum id="0">N BD CUsgCV OR N BD CUplCV</definiendum>
				<definiens id="0">“ ( person OR persons ) and other children” I D4 BE : “ ( child OR children</definiens>
			</definition>
			<definition id="4">
				<sentence>We use the list-context pattern : 13 ( O1 ) ( N BD CUsgCV OR N BD CUplCV ) and other N BE CUplCV For common noun antecedents , we instantiate the pattern by substituting N BD with each possible antecedent from set BT , andN BE with ana , as normally N BD is a hyponym of N BE in ( O1 ) , and the antecedent is a hyponym of the anaphor .</sentence>
				<definiendum id="0">N BD</definiendum>
			</definition>
</paper>

		<paper id="2001">
			<definition id="0">
				<sentence>Information ( document ) retrieval systems resort to two classes of approaches ; the first makes use of the form-based or words-based approach addressing the exact syntactic properties of documents , while the second makes use of the content-based approach which exploits the semantic connection between documents and queries .</sentence>
				<definiendum id="0">Information ( document ) retrieval systems</definiendum>
				<definiens id="0">exploits the semantic connection between documents and queries</definiens>
			</definition>
			<definition id="1">
				<sentence>In image recognition field ( Turk and Pentland , 1991 ; Chen and Tokuda , 2003b ) , a so-called PCA ( principal component analysis ) principle has been used successfully in facial recognition problems as a most effective scheme of dimension reduction .</sentence>
				<definiendum id="0">image recognition field</definiendum>
				<definiens id="0">a most effective scheme of dimension reduction</definiens>
			</definition>
			<definition id="2">
				<sentence>The LSI ( latent semantic indexing ) technique ( Berry et al. , 1999 ; Littman et al. , 1998 ) is a counterpart of the PCA in text document processing .</sentence>
				<definiendum id="0">LSI ( latent semantic indexing</definiendum>
			</definition>
			<definition id="3">
				<sentence>For each patent document in collection , we preprocess it and assign it with a document vector as B4CP BD BNCP BE BNBMBMBMBNCP D1 B5 , where CP CX BP CU CX A1 CV CX ; here CU CX denotes the number of times the term D8 CX appears in an expression of the document , and CV CX denotes the global weight over all the documents ; the weight denotes a parameter indicating the relative importance of the term in representing the document abstracts .</sentence>
				<definiendum id="0">CV CX</definiendum>
				<definiens id="0">with a document vector as B4CP BD BNCP BE BNBMBMBMBNCP D1 B5 , where CP CX BP CU CX A1 CV CX ; here CU CX denotes the number of times the term D8 CX appears in an expression of the document , and</definiens>
				<definiens id="1">the global weight over all the documents</definiens>
			</definition>
			<definition id="4">
				<sentence>An Exterior Differential Document Vector in particular is defined as the Differential Document Vector C1 BP C1 BD A0 C1 BE , ifC1 BD and C1 BE constitute two normalized document vectors of any two different documents .</sentence>
				<definiendum id="0">Exterior Differential Document Vector in particular</definiendum>
				<definiens id="0">the Differential Document Vector C1 BP C1 BD A0 C1 BE</definiens>
			</definition>
			<definition id="5">
				<sentence>An Interior Differential Document Vector is defined by the Differential Document Vector C1 BP C1 BD A0 C1 BE , where C1 BD and C1 BE constitute two different normalized document vectors of the same document .</sentence>
				<definiendum id="0">Interior Differential Document Vector</definiendum>
				<definiens id="0">the Differential Document Vector C1 BP C1 BD A0 C1 BE , where C1 BD and C1 BE constitute two different normalized document vectors of the same document</definiens>
			</definition>
			<definition id="6">
				<sentence>The Exterior Differential Term-Document Matrix is defined as a matrix , each column of which is set to an Exterior Differential Document Vector .</sentence>
				<definiendum id="0">Exterior Differential Term-Document Matrix</definiendum>
				<definiens id="0">a matrix , each column of which is set to an Exterior Differential Document Vector</definiens>
			</definition>
			<definition id="7">
				<sentence>The Interior Differential Term-Document Matrix is defined as a matrix , each column of which comprises an interior Differential Document Vector .</sentence>
				<definiendum id="0">Interior Differential Term-Document Matrix</definiendum>
			</definition>
			<definition id="8">
				<sentence>Any differential term-document matrix , say , of mby-n matrix D of rank D6 AK D5 BP D1CXD2B4D1BND2B5 , can be decomposed into a product of three matrices , namely BW BP CDCBCE CC , such that CD and CE are an D1-by-D5 and D5-by-D2 unitary matrices respectively , where the first D6 columns of CD and CE are the eigenvectors of BWBW CC and BW CC BW respectively .</sentence>
				<definiendum id="0">CE</definiendum>
				<definiens id="0">an D1-by-D5 and D5-by-D2 unitary matrices respectively , where the first D6 columns of CD and CE are the eigenvectors of BWBW CC and BW CC BW respectively</definiens>
			</definition>
			<definition id="9">
				<sentence>Thus , C8 BP BD D2 BWBW CC , where C8 is the covariance of the distribution computed from the training set .</sentence>
				<definiendum id="0">C8 BP BD D2 BWBW CC</definiendum>
				<definiendum id="1">C8</definiendum>
				<definiens id="0">the covariance of the distribution computed from the training set</definiens>
			</definition>
			<definition id="10">
				<sentence>Thus , the likelihood function C8B4DCCYBWB5 could be estimated by CM C8B4DCCYBWB5BP D2 BDBPBE CTDCD4 AI A0 D2 BE C8 CZ CXBPBD DD BE CX Æ BE CX AJ A1 CTDCD4 AG A0 D2AF BE B4DCB5 BEAQ AH B4BEAPB5 D2BPBE C9 CZ CXBPBD Æ CX A1 AQ B4D6A0CZB5BPBE BN ( 1 ) where DD BP CD CC CZ DC , AF BE B4DCB5 BP CYCYDCCYCY BE A0 C8 CZ CXBPBD DD BE CX , AQ BP BD D6A0CZ C8 D6 CXBPCZB7BD Æ BE CX , D6 is the rank of matrix BW .</sentence>
				<definiendum id="0">D6</definiendum>
				<definiens id="0">CM C8B4DCCYBWB5BP D2 BDBPBE CTDCD4 AI A0 D2 BE C8 CZ CXBPBD DD BE CX Æ BE CX AJ A1 CTDCD4 AG A0 D2AF BE B4DCB5 BEAQ AH B4BEAPB5 D2BPBE C9 CZ CXBPBD Æ CX A1 AQ B4D6A0CZB5BPBE BN ( 1 ) where DD BP CD CC CZ DC , AF BE B4DCB5 BP CYCYDCCYCY BE A0 C8 CZ CXBPBD DD BE CX , AQ BP BD D6A0CZ C8 D6 CXBPCZB7BD Æ BE CX</definiens>
			</definition>
			<definition id="11">
				<sentence>C1 CYDCB5BP C8B4DCCYBW C1 B5C8B4BW C1 B5 C8B4DCCYBW C1 B5C8B4BW C1 B5B7C8B4DCCYBW BX B5C8B4BW BX B5 BN where C8B4BW C1 B5 is set to an average number of recalls divided by the number of documents in the data base and C8B4BW BX B5 is set to BD A0 C8B4BW C1 B5 .</sentence>
				<definiendum id="0">C8B4BW C1 B5</definiendum>
				<definiens id="0">set to an average number of recalls divided by the number of documents in the data base</definiens>
			</definition>
</paper>

		<paper id="1600">
</paper>

		<paper id="0424">
			<definition id="0">
				<sentence>Named Entity Recognition1 ( NER ) can be treated as a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type .</sentence>
				<definiendum id="0">NER</definiendum>
				<definiens id="0">a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type</definiens>
			</definition>
			<definition id="1">
				<sentence>Generalised Iterative Scaling ( GIS ) is used to estimate the values of the weights .</sentence>
				<definiendum id="0">Generalised Iterative Scaling</definiendum>
				<definiendum id="1">GIS</definiendum>
			</definition>
			<definition id="2">
				<sentence>Condition Contextual predicate freq ( wi ) &lt; 5 X is prefix of wi , |X| ≤ 4 X is suffix of wi , |X| ≤ 4 wi contains a digit wi contains uppercase character wi contains a hyphen ∀wi wi = X wi−1 = X , wi−2 = X wi+1 = X , wi+2 = X ∀wi POSi = X POSi−1 = X , POSi−2 = X POSi+1 = X , POSi+2 = X ∀wi NEi−1 = X NEi−2NEi−1 = XY Table 1 : Contextual predicates in baseline system We used three data sets : the English and German data for the CoNLL-2003 shared task ( Tjong Kim Sang and De Meulder , 2003 ) and the Dutch data for the CoNLL2002 shared task ( Tjong Kim Sang , 2002 ) .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">prefix of wi</definiens>
			</definition>
			<definition id="3">
				<sentence>Mixedcase applies to words with mixed lowerand uppercase ( e.g. CityBank ) .</sentence>
				<definiendum id="0">Mixedcase</definiendum>
			</definition>
			<definition id="4">
				<sentence>Maximum entropy models are an effective way of incorporating diverse and overlapping features .</sentence>
				<definiendum id="0">Maximum entropy models</definiendum>
				<definiens id="0">an effective way of incorporating diverse and overlapping features</definiens>
			</definition>
</paper>

		<paper id="1610">
			<definition id="0">
				<sentence>== = j j i i ww ji vv vv FFwwsim ji 2 2 2 1 21 21211 * ) * ( ) , cos ( ) , ( 21 ( 1 ) where ) , ( ... ) , , ( ) , , ( 2211 &gt; = &lt; imimiiiii vwvwvwF Fi is the feature vector of wi ; 1=ijv if word ijw is a hub or an authority of the word wi ; else , 0=ijv ; Corpus This section proposes a novel method to extract synonyms from a bilingual corpus .</sentence>
				<definiendum id="0">vwvwvwF Fi</definiendum>
				<definiens id="0">the feature vector of wi ; 1=ijv if word ijw is a hub or an authority of the word wi</definiens>
				<definiens id="1">a novel method to extract synonyms from a bilingual corpus</definiens>
			</definition>
			<definition id="1">
				<sentence>== = j j i i cc ji pp pp FFwwsim ji 2 2 2 1 21 21212 * ) * ( ) , cos ( ) , ( 21 ( 3 ) where ) , ( ... ) , , ( ) , , ( 2211 &gt; = &lt; imimiiiii pcpcpcF Fi is the feature vector of wi ; ijc is the j th Chinese translation of the word w i ; ijp is the translation probability of the word wi is translated into ijc For example , the feature vectors of two words “ abandon” and “ forsake” are : forsake : &lt; ( , 0.1333 ) , ( o , 0.1333 ) , ( , abandon : &lt; ( , 0.3018 ) , ( o , 0.1126 ) , ( F+ , gual Corpus The context method described in Section 1 is also used for synonym extraction from large monolingual corpora of documents .</sentence>
				<definiendum id="0">pcpcpcF Fi</definiendum>
				<definiendum id="1">ijc</definiendum>
				<definiens id="0">the feature vector of wi ;</definiens>
				<definiens id="1">the translation probability of the word wi is translated into ijc For example , the feature vectors of two words “ abandon” and “ forsake”</definiens>
			</definition>
			<definition id="2">
				<sentence>( iwA denotes the attribute set of the word iw .</sentence>
				<definiendum id="0">iwA</definiendum>
				<definiens id="0">the attribute set of the word iw</definiens>
			</definition>
			<definition id="3">
				<sentence>Originally , the ensemble method is a machine learning technique of combining the outputs of several classifiers to improve the classification performance ( Dietterich , 2000 ) .</sentence>
				<definiendum id="0">ensemble method</definiendum>
				<definiens id="0">a machine learning technique of combining the outputs of several classifiers to improve the classification performance</definiens>
			</definition>
			<definition id="4">
				<sentence>Token means the total number of triples in the triple set and type means a unique instance of triple in the corpus .</sentence>
				<definiendum id="0">Token</definiendum>
				<definiens id="0">means the total number of triples in the triple set and type means a unique instance of triple in the corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>Therefore , a polysemous word occurs in more than one synsets .</sentence>
				<definiendum id="0">polysemous word</definiendum>
				<definiens id="0">occurs in more than one synsets</definiens>
			</definition>
			<definition id="6">
				<sentence>|S| |SS| G˙=precision ( 7 ) |S| |SS| G G˙=recall ( 8 ) recallprecision recallprecision2measure-f + **= ( 9 ) In order to evaluate our methods , we build up a test set which includes three parts : ( a ) high-frequency words : occurring more than 100 times ; ( b ) middle-frequency words : occurring more than 10 times and not greater than 100 times ; ( c ) low-frequency words : occurring no greater than 10 times .</sentence>
				<definiendum id="0">|S| |SS| G˙=precision</definiendum>
				<definiendum id="1">( c ) low-frequency words</definiendum>
				<definiens id="0">a test set which includes three parts : ( a ) high-frequency words : occurring more than 100 times ; ( b ) middle-frequency words : occurring more than 10 times and not greater than 100 times ;</definiens>
			</definition>
</paper>

		<paper id="1802">
			<definition id="0">
				<sentence>Examples of such complex relationships are : FALLOUT is caused by NUCLEAR EXPLOSION COAL-MINE is a place for COAL-MINING Studying term formation , ( Kageura , 2002 ) introduces intra-term relationships dealing with complex terms and defining the role of the determinant with respect to the head noun .</sentence>
				<definiendum id="0">NUCLEAR EXPLOSION COAL-MINE</definiendum>
				<definiens id="0">a place for COAL-MINING Studying term formation</definiens>
			</definition>
			<definition id="1">
				<sentence>For French , the syntactic structures or patterns of base-terms are : Noun1 Adj emballage biod´egradable ( biodegradable package ) Noun1 ( Prep ( Det ) ) Noun2 ions calcium ( calcium ion ) prot´eine de poissons ( fish protein ) , chimioprophylaxie au rifampine ( rifampicin chemoprophylaxis ) Noun1 `a Vinf viandes `a griller ( grill meat ) These base structures are not frozen structures and accept variations .</sentence>
				<definiendum id="0">biod´egradable</definiendum>
				<definiens id="0">fish protein ) , chimioprophylaxie au rifampine ( rifampicin chemoprophylaxis ) Noun1 `a Vinf viandes `a griller</definiens>
			</definition>
			<definition id="2">
				<sentence>The lexical function that captures hyperonymic relationships is the function Spec introduced by ( Grimes , 1990 ) : Spec ( contraction isom´etrique “isometric contraction” ) = contraction musculaire isom´etrique “isometric muscular contraction” Spec ( agent bact´erien “bacterial agent” ) = agent infectieux bact´erien “bacterial infectious agent” a0 Antonymy : if it is an adverb of negation that modifies the base term of N1 Adj structure , an antonymic relationship occurs between the base term and the modified one .</sentence>
				<definiendum id="0">lexical function</definiendum>
			</definition>
			<definition id="3">
				<sentence>Stripping-recoding morphological rules adopt the following rule schemata : a0 a6a2a1 a3a5a4a7a6a9a8a11a10 where : S is the relational suffix to be deleted from the end of an adjective .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">the relational suffix to be deleted from the end of an adjective</definiens>
			</definition>
</paper>

		<paper id="0811">
			<definition id="0">
				<sentence>The term middleware ( Emmerich , 2000 ) denotes the specific software infrastructure that facilitates the interaction among distributed software modules , i.e. the software layer between the operating system—including the basic communication protocols—and the distributed components that interact via the network .</sentence>
				<definiendum id="0">term middleware</definiendum>
				<definiens id="0">the specific software infrastructure that facilitates the interaction among distributed software modules , i.e. the software layer between the operating system—including the basic communication protocols—and the distributed components that interact via the network</definiens>
			</definition>
			<definition id="1">
				<sentence>Modeller : Active knowledge sources that provide explicit models of relevant aspects of the dialog system , like for example discourse memory , lexicon , or a suitable model of the underlying application functionality .</sentence>
				<definiendum id="0">Modeller</definiendum>
				<definiens id="0">Active knowledge sources that provide explicit models of relevant aspects of the dialog system</definiens>
			</definition>
			<definition id="2">
				<sentence>XML-based languages define an external notation for the representation of structured data and simplify the interchange of complex data between separate applications .</sentence>
				<definiendum id="0">XML-based languages</definiendum>
				<definiens id="0">an external notation for the representation of structured data and simplify the interchange of complex data between separate applications</definiens>
			</definition>
			<definition id="3">
				<sentence>Conceptual taxonomies provide the foundation for the representation of domain knowledge as it is required within a dialog system to enable a natural conversation in the given application scenario .</sentence>
				<definiendum id="0">Conceptual taxonomies</definiendum>
				<definiens id="0">provide the foundation for the representation of domain knowledge as it is required within a dialog system to enable a natural conversation in the given application scenario</definiens>
			</definition>
			<definition id="4">
				<sentence>VERBMOBIL ( Wahlster , 2000 ) is a speaker-independent and bidirectional speech-to-speech translation system that aims to provide users in mobile situations with simultaneous dialog interpretation services for restricted topics .</sentence>
				<definiendum id="0">VERBMOBIL</definiendum>
			</definition>
			<definition id="5">
				<sentence>VERBMOBIL follows a hybrid approach that incorporates both deep and shallow processing schemes .</sentence>
				<definiendum id="0">VERBMOBIL</definiendum>
				<definiens id="0">follows a hybrid approach that incorporates both deep and shallow processing schemes</definiens>
			</definition>
			<definition id="6">
				<sentence>SMARTKOM is a multimodal dialog system that combines speech , gesture , and facial expressions for both , user input and system output ( Wahlster et al. , 2001 ) .</sentence>
				<definiendum id="0">SMARTKOM</definiendum>
			</definition>
			<definition id="7">
				<sentence>SMARTKOM PUBLIC realizes an advanced multimodal information and communication kiosk for airports , train stations , or other public places .</sentence>
				<definiendum id="0">SMARTKOM PUBLIC</definiendum>
				<definiens id="0">realizes an advanced multimodal information and communication kiosk for airports , train stations , or other public places</definiens>
			</definition>
			<definition id="8">
				<sentence>COMIC2 ( Conversational Multimodal Interaction with Computers ) is a recent research project that focuses on computer-based mechanisms of interaction in cooperative work .</sentence>
				<definiendum id="0">COMIC2 ( Conversational Multimodal Interaction with Computers )</definiendum>
				<definiens id="0">a recent research project that focuses on computer-based mechanisms of interaction in cooperative work</definiens>
			</definition>
			<definition id="9">
				<sentence>GCSI , the Galaxy Communicator software infrastructure ( Seneff et al. , 1999 ) , is an open source architecture for the realization of natural language dialog systems .</sentence>
				<definiendum id="0">GCSI</definiendum>
				<definiendum id="1">Galaxy Communicator software infrastructure</definiendum>
				<definiens id="0">an open source architecture for the realization of natural language dialog systems</definiens>
			</definition>
</paper>

		<paper id="1717">
			<definition id="0">
				<sentence>Therefore , the baseline probability for any pair+relation might be far below 50 % and more than 50 % is a good indicator that a given pair does typically occur in a given relation .</sentence>
				<definiendum id="0">baseline probability</definiendum>
				<definiens id="0">a good indicator that a given pair does typically occur in a given relation</definiens>
			</definition>
</paper>

		<paper id="1107">
			<definition id="0">
				<sentence>Then we examined Support Vector Machines ( SVMs ) and sequential pattern mining relative to the set of lists , and observed the obtained model to find useful features for extraction of answers to explain a relevant procedure .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs</definiendum>
				<definiens id="0">sequential pattern mining relative to the set of lists , and observed the obtained model to find useful features for extraction of answers to explain a relevant procedure</definiens>
			</definition>
			<definition id="1">
				<sentence>The PrefixSpan algorithm succeed in reducing the cost of calculation by performing an operation , called projection , which confines the range of the search to sets of frequent subsequences .</sentence>
				<definiendum id="0">projection</definiendum>
				<definiens id="0">confines the range of the search to sets of frequent subsequences</definiens>
			</definition>
			<definition id="2">
				<sentence>j48 , which is an implementation of the C4.5 algorithm by Weka3 , was chosen .</sentence>
				<definiendum id="0">j48</definiendum>
				<definiens id="0">an implementation of the C4.5 algorithm by Weka3 , was chosen</definiens>
			</definition>
</paper>

		<paper id="1701">
			<definition id="0">
				<sentence>Maximum Matching ( MM ) based segmentation ( Huang , 1997 ) can be regarded as the simplest rule-based approach , in which one starts from one end of the input sentence , greedily matches the longest word towards the other end , and repeats the process with the rest unmatched character sequences until the entire sentence is processed .</sentence>
				<definiendum id="0">Maximum Matching ( MM ) based segmentation</definiendum>
				<definiens id="0">the simplest rule-based approach , in which one starts from one end of the input sentence , greedily matches the longest word towards the other end , and repeats the process with the rest unmatched character sequences until the entire sentence is processed</definiens>
			</definition>
			<definition id="1">
				<sentence>An OAS is a Chinese character string O that satisfies the following two conditions : a ) There exist two segmentations Seg 1 and Seg 2 such that 2211 , SegwSegw ∈∈∀ , where Chinese words w 1 and w 2 are different from either literal strings or positions ; b ) 2211 , SegwSegw ∈∈∃ , where w 1 and w 2 overlap .</sentence>
				<definiendum id="0">OAS</definiendum>
				<definiens id="0">a Chinese character string</definiens>
			</definition>
</paper>

		<paper id="0600">
</paper>

		<paper id="0303">
			<definition id="0">
				<sentence>The bracket alignment includes a word alignment as a byproduct .</sentence>
				<definiendum id="0">bracket alignment</definiendum>
				<definiens id="0">includes a word alignment as a byproduct</definiens>
			</definition>
			<definition id="1">
				<sentence>The alignment is evaluated in terms of precision , recall , F-measure and alignment error rate ( AER ) defined in the shared task .</sentence>
				<definiendum id="0">AER</definiendum>
				<definiens id="0">evaluated in terms of precision , recall , F-measure and alignment error rate</definiens>
			</definition>
</paper>

		<paper id="1119">
			<definition id="0">
				<sentence>Our syntax parser locates the subject , object , and head word within a sentence .</sentence>
				<definiendum id="0">syntax parser</definiendum>
				<definiens id="0">locates the subject , object , and head word within a sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>For convince , we define SI is a set of semanticinformation and assume that the jth semanticinformation of the node nj is nj [ i ] .</sentence>
				<definiendum id="0">SI</definiendum>
				<definiendum id="1">node nj</definiendum>
				<definiens id="0">a set of semanticinformation and assume that the jth semanticinformation of the</definiens>
			</definition>
			<definition id="2">
				<sentence>FindRule ( N ) Require : Input : N is a node Ensure : A syntax control for a rule fInitialization step : g 1 : for i = 1 to k do 2 : for j = 1 to Ki do 3 : Set stack s [ i ] =all index rules in the set of condition rules satisfy ni : sem = ni [ j ] 4 : end for 5 : for i = 1 to K1 do 6 : Cost [ 0 ] [ i ] = 1 ; 7 : Back [ 0 ] [ i ] = 0 ; 8 : end for 9 : end for fInteraction step : g 10 : for i = 1 to k do 11 : for j=1 to Ki do 12 : Cost [ i ] [ j ] = maxCost [ i ¡ 1 ] [ l ] £ Value ( s [ i ] [ j ] ; s [ i¡1 ] [ l ] ) with l = 1 ; Ki Back [ i ] [ j ] = all the index gave max 13 : end for 14 : end for fIdentification step : g 15 : Set a list LS= all index rules gave max values Cost [ k ] [ j ] with j = 1 ; Kk .</sentence>
				<definiendum id="0">FindRule</definiendum>
				<definiens id="0">a node Ensure : A syntax control for a rule fInitialization step</definiens>
			</definition>
			<definition id="3">
				<sentence>Ensure : a syntax tree with rich semantic information fSemanticParsingTreeg 1 : if N is leaf then 2 : Update all symbol-meaning in word entry 3 : else 4 : FindRules ( N ) ; 5 : end iffmain procedureg 6 : SemanticParsingNode ( root ) ; The input of this process is a syntax tree which associated with rich information after applying the semantic parsing process .</sentence>
				<definiendum id="0">Ensure</definiendum>
				<definiens id="0">a syntax tree with rich semantic information</definiens>
				<definiens id="1">a syntax tree which associated with rich information after applying the semantic parsing process</definiens>
			</definition>
			<definition id="4">
				<sentence>WORDNET : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WORDNET</definiendum>
			</definition>
</paper>

		<paper id="0300">
</paper>

		<paper id="0504">
			<definition id="0">
				<sentence>The Million Book Project is one of the projects that uses OCR technology for digitizing books .</sentence>
				<definiendum id="0">Million Book Project</definiendum>
				<definiens id="0">one of the projects that uses OCR technology for digitizing books</definiens>
			</definition>
			<definition id="1">
				<sentence>Even when ESG produces a complete parse tree for a noisy sentence , the result is incorrect most of times .</sentence>
				<definiendum id="0">ESG</definiendum>
				<definiens id="0">produces a complete parse tree for a noisy sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>The performance of the system is affected by noise in multiple dimensions : lexical links are less reliable in a noisy condition ; cue phrases are likely to be missed due to noisy spelling ; and word frequency is less accurate due to different noisy occurrences of the same word .</sentence>
				<definiendum id="0">cue phrases</definiendum>
				<definiendum id="1">word frequency</definiendum>
				<definiens id="0">less accurate due to different noisy occurrences of the same word</definiens>
			</definition>
			<definition id="3">
				<sentence>The simple cosine is computed as the cosine of two document vectors , the weight of each element in the vector being 1=pN , where N is the total number of elements in the vector .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of elements in the vector</definiens>
			</definition>
</paper>

		<paper id="0106">
			<definition id="0">
				<sentence>The InfoXtract location normalization module consists of local pattern matching and discourse co-occurrence analysis as well as default senses .</sentence>
				<definiendum id="0">InfoXtract location normalization module</definiendum>
			</definition>
			<definition id="1">
				<sentence>Location normalization is a special application of word sense disambiguation ( WSD ) .</sentence>
				<definiendum id="0">Location normalization</definiendum>
				<definiens id="0">a special application of word sense disambiguation ( WSD )</definiens>
			</definition>
			<definition id="2">
				<sentence>This involves two issues : ( i ) determining default senses using heuristics and/or other methods , such as statistical processing for semi-automatic default sense extraction from the web [ Li et al. 2002 ] ; and ( ii ) setting the conditions/thresholds and the proper levels when assigning default senses , to coordinate with local and discourse evidence for enhanced performance .</sentence>
				<definiendum id="0">discourse evidence</definiendum>
				<definiens id="0">the proper levels when assigning default senses , to coordinate with local and</definiens>
			</definition>
</paper>

		<paper id="1403">
			<definition id="0">
				<sentence>They think that the most appropriate level for representing conceptual knowledge which underlies systematic metaphors is a level similar to the Inter-Lingual-Index ( ILI ) in EuroWordNet ( EWN ) .</sentence>
				<definiendum id="0">ILI</definiendum>
				<definiens id="0">the most appropriate level for representing conceptual knowledge which underlies systematic metaphors is a level similar to the Inter-Lingual-Index</definiens>
			</definition>
			<definition id="1">
				<sentence>The Hamburg Metaphor Database ( HMD ) contains corpus examples in French and German as well as synsets from EWN to which the metaphorically used lexemes belong , and labels for source and target domains of the metaphors in two different naming systems .</sentence>
				<definiendum id="0">Hamburg Metaphor Database ( HMD</definiendum>
				<definiens id="0">source and target domains of the metaphors in two different naming systems</definiens>
			</definition>
			<definition id="2">
				<sentence>Query parameters include the synsets and the annotated source and target domains of the metaphor as well as the language of the corpus example .</sentence>
				<definiendum id="0">Query parameters</definiendum>
				<definiens id="0">include the synsets and the annotated source and target domains of the metaphor as well as the language of the corpus example</definiens>
			</definition>
			<definition id="3">
				<sentence>If a MENTAL EVENT ( like THEORETICAL DEBATE ) is a specialisation of an EVENT ( like COMPETITION ) , then the first metaphor can be interpreted as a specialisation of the second one .</sentence>
				<definiendum id="0">MENTAL EVENT</definiendum>
				<definiens id="0">a specialisation of an EVENT ( like COMPETITION</definiens>
			</definition>
			<definition id="4">
				<sentence>It can be hoped that new tools like VisDic ( Pavelek and Pala , 2002 ; Horak et al. , 2003 ) and DEB ( Smrˇz and Povoln´y , 2003 ) for editing lexical databases will enable the integration of independent further developments of EWN ( for example GermaNet ) with EWN data and the creation of new relationships .</sentence>
				<definiendum id="0">DEB</definiendum>
				<definiendum id="1">EWN</definiendum>
				<definiens id="0">example GermaNet ) with EWN data and the creation of new relationships</definiens>
			</definition>
</paper>

		<paper id="0910">
</paper>

		<paper id="0102">
			<definition id="0">
				<sentence>The geospatial theory that SNARK uses for this application consists of a set of axioms , logical sentences that provide definitions and describe properties of important spatial constants , functions , and relations , including those in the logical form of the query .</sentence>
				<definiendum id="0">geospatial theory</definiendum>
				<definiens id="0">a set of axioms , logical sentences that provide definitions and describe properties of important spatial constants , functions , and relations , including those in the logical form of the query</definiens>
			</definition>
			<definition id="1">
				<sentence>( Manna and Waldinger , 1980 ) Using the appropriate axioms , SNARK transforms and decomposes the query to simpler and simpler subqueries .</sentence>
				<definiendum id="0">SNARK</definiendum>
				<definiens id="0">transforms and decomposes the query to simpler and simpler subqueries</definiens>
			</definition>
			<definition id="2">
				<sentence>Procedural attachment allows subqueries to be answered by external knowledge sources , which may be programs or data bases and may reside on any machine accessible through the Web .</sentence>
				<definiendum id="0">Procedural attachment</definiendum>
				<definiens id="0">allows subqueries to be answered by external knowledge sources , which may be programs or data bases and may reside on any machine accessible through the Web</definiens>
			</definition>
			<definition id="3">
				<sentence>the ASCS ( Pease et al. , 2002 ) search engine , which searches the Web for pages that are encoded in DAML ( the DARPA Agent Markup Language ) and extracts their content ; much of the Factbook has been encoded in DAML and is actually accessed through ASCS .</sentence>
				<definiendum id="0">ASCS</definiendum>
				<definiens id="0">searches the Web for pages that are encoded in DAML ( the DARPA Agent Markup Language ) and extracts their content ; much of the Factbook has been encoded in DAML and is actually accessed through ASCS</definiens>
			</definition>
			<definition id="4">
				<sentence>GeoLogica abbreviates countries by their names ; thus Canada is simply canada .</sentence>
				<definiendum id="0">GeoLogica</definiendum>
				<definiens id="0">abbreviates countries by their names</definiens>
			</definition>
			<definition id="5">
				<sentence>For instance , canada is a symbol that denotes the actual country Canada , a region on Earth .</sentence>
				<definiendum id="0">canada</definiendum>
				<definiens id="0">a symbol that denotes the actual country Canada , a region on Earth</definiens>
			</definition>
			<definition id="6">
				<sentence>real is a variable that has not yet been instantiated , or assigned a value , the agent can not operate .</sentence>
				<definiendum id="0">real</definiendum>
				<definiens id="0">a variable that has not yet been instantiated</definiens>
			</definition>
			<definition id="7">
				<sentence>The system CYC ( Lenat and Guha , 1998 ) includes a large theory of spatial reasoning and now also incorporates procedural attachment .</sentence>
				<definiendum id="0">CYC</definiendum>
				<definiens id="0">includes a large theory of spatial reasoning and now also incorporates procedural attachment</definiens>
			</definition>
			<definition id="8">
				<sentence>( A theory is an ontology in which the meaning of the symbols is pinned down by axioms . )</sentence>
				<definiendum id="0">theory</definiendum>
				<definiens id="0">an ontology in which the meaning of the symbols is pinned down by axioms</definiens>
			</definition>
</paper>

		<paper id="0433">
			<definition id="0">
				<sentence>We describe multiple stacking and voting methods that effectively combine strong classifiers such as boosting , SVM , and TBL , for the named-entity recognition ( NER ) task .</sentence>
				<definiendum id="0">TBL</definiendum>
				<definiens id="0">multiple stacking and voting methods that effectively combine strong classifiers such as boosting</definiens>
			</definition>
			<definition id="1">
				<sentence>Support Vector Machines ( SVMs ) have gained a considerable following in recent years ( Boser et al. , 1992 ) , particularly in dealing with high-dimensional spaces such as commonly found in natural language problems like text categorization ( Joachims , 1998 ) .</sentence>
				<definiendum id="0">Support Vector Machines ( SVMs</definiendum>
				<definiens id="0">commonly found in natural language problems like text categorization</definiens>
			</definition>
			<definition id="2">
				<sentence>Transformation-based learning ( Brill , 1995 ) ( TBL ) is a rule-based machine learning algorithm that was first introduced by Brill and used for part-of-speech tagging .</sentence>
				<definiendum id="0">Transformation-based learning</definiendum>
				<definiendum id="1">TBL</definiendum>
				<definiens id="0">a rule-based machine learning algorithm</definiens>
			</definition>
			<definition id="3">
				<sentence>The different ways that we dealt with the problem were : ( 1 ) Rank all the NE types by frequency in the training corpus .</sentence>
				<definiendum id="0">Rank</definiendum>
				<definiens id="0">all the NE types by frequency in the training corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>Precision Recall Fβ=1 ( Boost ) Base 88.64 % 87.68 % 88.16 ( Boost ) Base + Stacked 89.26 % 88.29 % 88.77 Table 1 : Improving classification of NE types via stacked AdaBoost .</sentence>
				<definiendum id="0">Precision Recall Fβ=1</definiendum>
				<definiens id="0">Improving classification of NE types via stacked AdaBoost</definiens>
			</definition>
</paper>

		<paper id="0700">
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>The PropBank superimposes an annotation of semantic predicate-argument structures on top of the Penn Treebank ( PTB ) ( Marcus et al. , 1993 ; Marcus et al. , 1994 ) .</sentence>
				<definiendum id="0">PropBank</definiendum>
			</definition>
			<definition id="1">
				<sentence>The PropBank contains all of the notation of the Penn Treebank as well as semantic notation .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">contains all of the notation of the Penn Treebank as well as semantic notation</definiens>
			</definition>
			<definition id="2">
				<sentence>Accuracy is measured for all words in the sentence including punctuation .</sentence>
				<definiendum id="0">Accuracy</definiendum>
				<definiens id="0">measured for all words in the sentence including punctuation</definiens>
			</definition>
			<definition id="3">
				<sentence>LDA is an acronym for Lightweight Dependency Analyzer ( Srinivas ( 1997 ) ) .</sentence>
				<definiendum id="0">LDA</definiendum>
			</definition>
</paper>

		<paper id="0320">
			<definition id="0">
				<sentence>Preprocessing : Preprocessing the Inuktitut and the English raised separate issues .</sentence>
				<definiendum id="0">Preprocessing</definiendum>
				<definiens id="0">Preprocessing the Inuktitut and the English raised separate issues</definiens>
			</definition>
</paper>

		<paper id="0611">
			<definition id="0">
				<sentence>Siskind ( 2001 ) , in contrast , used data which was explicitly created for his experiments ; Barzilay and Lee ( 2002 ) used texts which subjects had written for a previous experiment ; and Roy ( 2002 ) used both data and texts that were created for his experiments .</sentence>
				<definiendum id="0">Roy</definiendum>
				<definiens id="0">in contrast , used data which was explicitly created for his experiments</definiens>
			</definition>
			<definition id="1">
				<sentence>This tables also shows the statistical significance of differences between forecasters , calculated with a a chi-square test ( which treats time as a categorical variable ) .</sentence>
				<definiendum id="0">chi-square test</definiendum>
				<definiens id="0">which treats time as a categorical variable )</definiens>
			</definition>
			<definition id="2">
				<sentence>These patterns are replicated across the corpus : some phrases ( such as by midday and by morning ) are used in the same way by all forecasters ; some phrases ( such as by evening and by late morning ) are used in very different ways by the forecasters ; and some phrases ( such as by late evening and by midnight ) have the same core meaning ( eg , 0000 ) but different distributions around the core .</sentence>
				<definiendum id="0">phrases</definiendum>
				<definiendum id="1">phrases</definiendum>
				<definiens id="0">by midday and by morning ) are used in the same way by all forecasters ; some</definiens>
			</definition>
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>In the algorithm , we use I for the number of training instances , Y for the number of output classes , and F for the number of candidate features or the size of the candidate feature set .</sentence>
				<definiendum id="0">Y</definiendum>
				<definiens id="0">the number of candidate features or the size of the candidate feature set</definiens>
			</definition>
			<definition id="1">
				<sentence>Let g ( j , k ) represent the gain due to the addition of feature f j to the active model at stage k. In our experiments , it is found even if D ( i.e. , the additional number of stages after stage k ) is large , for most j , g ( j , k+D ) g ( j , k ) is a negative number or at most a very small positive number .</sentence>
				<definiendum id="0">k )</definiendum>
			</definition>
			<definition id="2">
				<sentence>Let † E d ( f ) =˜ p ( x ) max y { f ( x , y ) } x Â † R e ( f ) =E ˜ p ( f ) /E d ( f ) Yp/1 0 Then ) log ( ) , ( ( 1 ) ( 0 0 fR p p f e e j ⋅a † g ( j,0 ) =L ( p ∅»f a ( i,0 ) -L ( p ∅ ) =E d ( f ) [ R e ( f ) log R e ( f ) p 0 + ( 1-R e ( f ) ) log 1-R e ( f ) p 0 ] where ∅ denotes an empty set , p ∅ is the uniform distribution .</sentence>
				<definiendum id="0">∅</definiendum>
				<definiendum id="1">p ∅</definiendum>
				<definiens id="0">y ) } x Â † R e ( f ) =E ˜ p ( f ) /E d ( f ) Yp/1 0 Then ) log ( ) , ( ( 1 ) ( 0 0 fR p p f e e j ⋅a</definiens>
				<definiens id="1">the uniform distribution</definiens>
			</definition>
			<definition id="3">
				<sentence>The first sets of experiments use a dataset { ( x , y ) } , derived from the Penn Treebank , where x is a 10 dimension vector including word , POS tag and grammatical relation tag information from two adjacent regions , and y is the grammatical relation tag between the two regions .</sentence>
				<definiendum id="0">x</definiendum>
				<definiendum id="1">y</definiendum>
				<definiens id="0">a 10 dimension vector including word , POS tag and grammatical relation tag information from two adjacent regions</definiens>
				<definiens id="1">the grammatical relation tag between the two regions</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>For the parsing and antecedent recovery experiments , in the case of WH-traces ( WH–a1a2a1a2a1 ) and controlled NP-traces ( NP–NP ) , we follow the standard technique of marking nodes dominating the empty element up to but not including the parent of the antecedent as defective ( missing an argument ) with a gap feature ( Gazdar et al. , 1985 ; Collins , 1999 ) .</sentence>
				<definiendum id="0">controlled NP-traces</definiendum>
				<definiens id="0">the standard technique of marking nodes dominating the empty element up to but not including the parent of the antecedent as defective ( missing an argument</definiens>
			</definition>
			<definition id="1">
				<sentence>The unlexicalized CYK parser we use has a worst-case asymptotic runtime of Oa0 n3N3a1 where n is the number of words and N is the number of nonterminals .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the number of words</definiens>
			</definition>
			<definition id="2">
				<sentence>Three factors contribute to this larger nonterminal set : ( i ) nonterminals are augmented with EE types that contain the parent node of the EE ( i.e. S may become Sa2a4a3a6a5a8a7a4a9 , Sa2a4a3a6a5a10a9a4a9 , etc. ) ( ii ) we must include combinations of EEs as nonterminals may dominate more than one unbound EE ( i.e. Sa7a4a9a11a5a8a7a4a9a6a12a8a2a4a3a6a5a8a7a4a9 a1 and ( iii ) a single nonterminal may be repeated in the presence of co-ordination ( i.e. Sa7a4a9a11a5a8a7a4a9 a12 a7a4a9a11a5a8a7a4a9 ) .</sentence>
				<definiendum id="0">EE</definiendum>
				<definiens id="0">a single nonterminal may be repeated in the presence of co-ordination ( i.e. Sa7a4a9a11a5a8a7a4a9 a12 a7a4a9a11a5a8a7a4a9 )</definiens>
			</definition>
			<definition id="3">
				<sentence>In order to show the effects of increasing the size of nonterminal vocabulary , the first INSERT model only considers one EE type , WH–NP while the second ( henceforth PRO &amp; WH ) considers all WH traces as well as NP–NP and PRO–NP discontinuities .</sentence>
				<definiendum id="0">WH )</definiendum>
				<definiens id="0">considers all WH traces as well as NP–NP and PRO–NP discontinuities</definiens>
			</definition>
</paper>

		<paper id="1725">
			<definition id="0">
				<sentence>As our program needs to handle both Simplified and Traditional Chinese characters , Unicode is the only solution for dealing with more than one script at the same time .</sentence>
				<definiendum id="0">Unicode</definiendum>
				<definiens id="0">the only solution for dealing with more than one script at the same time</definiens>
			</definition>
			<definition id="1">
				<sentence>Data manager Segmentor PreProcessor Kernel Post Processor New Word Extractor Knowledgebase In order to keep the dictionary maintenance simple , our system uses a single dictionary which only keeps the so called canonical form of a word .</sentence>
				<definiendum id="0">system</definiendum>
				<definiens id="0">uses a single dictionary which only keeps the so called canonical form of a word</definiens>
			</definition>
			<definition id="2">
				<sentence>1 3 N N recall = ( 1 ) 2 3 N N presicion = ( 2 ) precisionrecall precisionrecall recallprecisionF + ×× = 2 ) , ( 1 ( 3 ) where N 1 denotes the number of words in the annotated corpus , N 2 denotes the number of words identified by the segmentation algorithm , and N 3 is the number of words correctly identified .</sentence>
				<definiendum id="0">N 1</definiendum>
				<definiens id="0">the number of words in the annotated corpus</definiens>
				<definiens id="1">the number of words identified by the segmentation algorithm</definiens>
				<definiens id="2">the number of words correctly identified</definiens>
			</definition>
</paper>

		<paper id="0201">
			<definition id="0">
				<sentence>AutoTutor is a domain-portable intelligent tutoring system ( ITS ) with current versions in the domains of physics and computer literacy ( Graesser et al. 1999 ; Olney et al. 2002 ) .</sentence>
				<definiendum id="0">AutoTutor</definiendum>
				<definiens id="0">a domain-portable intelligent tutoring system ( ITS ) with current versions in the domains of physics and computer literacy</definiens>
			</definition>
			<definition id="1">
				<sentence>On the practical side , AutoTutor is a web-based application that performs in real time ; thus utterance classification must also proceed in real time .</sentence>
				<definiendum id="0">AutoTutor</definiendum>
				<definiens id="0">a web-based application that performs in real time</definiens>
			</definition>
			<definition id="2">
				<sentence>AutoTutor simulates the dialog patterns and pedagogical strategies of human tutors in a conversational interface that supports mixed-initiative dialog .</sentence>
				<definiendum id="0">AutoTutor</definiendum>
				<definiens id="0">simulates the dialog patterns and pedagogical strategies of human tutors in a conversational interface that supports mixed-initiative dialog</definiens>
			</definition>
			<definition id="3">
				<sentence>The Dialog Advancer Network ( DAN ) is the intermediary of dialog move generation in all instances , using information from the speech act classifier and LSA to select the next dialog move type and appropriate discourse markers .</sentence>
				<definiendum id="0">Dialog Advancer Network ( DAN )</definiendum>
			</definition>
			<definition id="4">
				<sentence>The most notable system within this framework is QUALM ( Lehnert 1978 ) , which utilizes twelve of the question categories .</sentence>
				<definiendum id="0">QUALM</definiendum>
				<definiens id="0">utilizes twelve of the question categories</definiens>
			</definition>
			<definition id="5">
				<sentence>Jurafsky and Martin ( 2000 ) describe the problem of interpreting speech acts using pragmatic and semantic inference as AI-complete , i.e. impossible without creating a full artificial intelligence .</sentence>
				<definiendum id="0">AI-complete</definiendum>
				<definiens id="0">impossible without creating a full artificial intelligence</definiens>
			</definition>
			<definition id="6">
				<sentence>Frozen expressions consist of metacognitive and metacommunicative utterances .</sentence>
				<definiendum id="0">Frozen expressions</definiendum>
				<definiens id="0">consist of metacognitive and metacommunicative utterances</definiens>
			</definition>
			<definition id="7">
				<sentence>Recall , fallout , precision , and f-measure were calculated in the following way for each category : Recall = tp / ( tp + fn ) Fallout = fp / ( fp + tn ) Precision = tp / ( tp + fp ) F-measure = 2 * Recall * Precision Recall + Precision Recall and fallout are often used in signal detection analysis to calculate a measure called d’ ( Green and Swets 1966 ) .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">F-measure = 2 * Recall * Precision Recall + Precision Recall and fallout</definiens>
			</definition>
			<definition id="8">
				<sentence>Brainstormed questions are an unreliable source of testing data because they are not randomly sampled .</sentence>
				<definiendum id="0">Brainstormed questions</definiendum>
			</definition>
</paper>

		<paper id="2000">
</paper>

		<paper id="1505">
</paper>

		<paper id="0430">
			<definition id="0">
				<sentence>This paper describes WebListing , a method that obtains seeds for the lexicons from the labeled data , then uses the Web , HTML formatting regularities and a search engine service to significantly augment those lexicons .</sentence>
				<definiendum id="0">WebListing</definiendum>
				<definiens id="0">a method that obtains seeds for the lexicons from the labeled data , then uses the Web , HTML formatting regularities and a search engine service to significantly augment those lexicons</definiens>
			</definition>
			<definition id="1">
				<sentence>Conditional Random Fields ( CRFs ) ( Lafferty et al. , 2001 ) are undirected graphical models used to calculate the conditional probability of values on designated output nodes given values assigned to other designated input nodes .</sentence>
				<definiendum id="0">Conditional Random Fields ( CRFs )</definiendum>
				<definiens id="0">Lafferty et al. , 2001 ) are undirected graphical models used to calculate the conditional probability of values on designated output nodes given values assigned to other designated input nodes</definiens>
			</definition>
			<definition id="2">
				<sentence>By the Hammersley-Clifford theorem , CRFs define the conditional probability of a state sequence given an input sequence to be PΛ ( s|o ) = 1Z o exp parenleftBigg Tsummationdisplay t=1 summationdisplay k λkfk ( st−1 , st , o , t ) parenrightBigg , where Zo is a normalization factor over all state sequences , fk ( st−1 , st , o , t ) is an arbitrary feature function over its arguments , and λk is a learned weight for each feature function .</sentence>
				<definiendum id="0">Zo</definiendum>
				<definiendum id="1">λk</definiendum>
				<definiens id="0">a normalization factor over all state sequences</definiens>
				<definiens id="1">an arbitrary feature function over its arguments</definiens>
			</definition>
			<definition id="3">
				<sentence>Assuming that the training labels on instance j make its state path unambiguous , let s ( j ) denote that path , and then the first-derivative of the log-likelihood is δL δλk =   Nsummationdisplay j=1 Ck ( s ( j ) , o ( j ) )  −   Nsummationdisplay j=1 summationdisplay s PΛ ( s|o ( j ) ) Ck ( s , o ( j ) )  − λkσ2 where Ck ( s , o ) is the “count” for feature k given s and o , equal to summationtextTt=1 fk ( st−1 , st , o , t ) , the sum of fk ( st−1 , st , o , t ) values for all positions , t , in the sequence s. The first two terms correspond to the difference between the empirical expected value of feature fk and the model’s expected value : ( ˜E [ fk ] −EΛ [ fk ] ) N. The last term is the derivative of the Gaussian prior .</sentence>
				<definiendum id="0">Ck (</definiendum>
				<definiens id="0">δL δλk =   Nsummationdisplay j=1 Ck ( s ( j ) , o ( j ) )  −   Nsummationdisplay j=1 summationdisplay s PΛ ( s|o ( j )</definiens>
				<definiens id="1">s , o ) is the “count” for feature k given s and o , equal to summationtextTt=1 fk ( st−1 , st , o , t ) , the sum of fk ( st−1 , st , o , t ) values for all positions , t , in the sequence s. The first two terms correspond to the difference between the empirical expected value of feature fk and the model’s expected value : ( ˜E [ fk ] −EΛ [ fk ] ) N. The last term is the derivative of the Gaussian prior</definiens>
			</definition>
</paper>

		<paper id="1206">
			<definition id="0">
				<sentence>Sharon Small , Ting Liu , Nobuyuki Shimizu , and Tomek Strzalkowski ILS Institute The State University of New York at Albany 1400 Washington Avenue Albany , NY 12222 { small , tl7612 , ns3203 , tomek } @ albany.edu HITIQA is an interactive question answering technology designed to allow intelligence analysts and other users of information systems to pose questions in natural language and obtain relevant answers , or the assistance they require in order to perform their tasks .</sentence>
				<definiendum id="0">HITIQA</definiendum>
				<definiens id="0">an interactive question answering technology designed to allow intelligence analysts and other users of information systems to pose questions in natural language and obtain relevant answers</definiens>
			</definition>
			<definition id="1">
				<sentence>1 TREC QA is the annual Question Answering evaluation sponsored by the U.S. National Institute of Standards and Technology www.trec.nist.gov .</sentence>
				<definiendum id="0">TREC QA</definiendum>
			</definition>
			<definition id="2">
				<sentence>TOPIC : [ pollution , industry , sources ] LOCATION : [ Black Sea ] INDUSTRY : [ fishing ] Figure 3 : HITIQA generated Goal Frame TOPIC : pollution SUB-TOPIC : [ sources ] LOCATION : [ Black Sea ] INDUSTRY : [ fisheries , tourism ] TEXT : [ In a period of only three decades ( 1960's-1980 's ) , the Black Sea has suffered the catastrophic degradation of a major part of its natural resources .</sentence>
				<definiendum id="0">TOPIC</definiendum>
				<definiendum id="1">TEXT</definiendum>
				<definiens id="0">[ pollution , industry , sources ] LOCATION : [ Black Sea ] INDUSTRY : [ fishing ] Figure 3 : HITIQA generated Goal Frame TOPIC : pollution SUB-TOPIC : [ sources ] LOCATION : [ Black Sea ] INDUSTRY : [ fisheries , tourism ]</definiens>
			</definition>
			<definition id="3">
				<sentence>For 5 A notable exception is CU Communicator developed at University of Colorado ( Ward and Pellom , 1999 ) example , if the answer space appears too large or varied , e.g. consists of many different topics , the system may ask the user how to narrow it .</sentence>
				<definiendum id="0">CU Communicator</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Negative-Goal Frame includes information that HITIQA has identified as being of no interest to the user .</sentence>
				<definiendum id="0">Negative-Goal Frame</definiendum>
				<definiens id="0">includes information that HITIQA has identified as being of no interest to the user</definiens>
			</definition>
			<definition id="5">
				<sentence>PartsID : A Dialog-Based System for Identifying Parts for Medical Systems .</sentence>
				<definiendum id="0">PartsID</definiendum>
			</definition>
			<definition id="6">
				<sentence>`` TRIPS : An Intelligent Integrated Problem-Solving Assistant , '' in Proc .</sentence>
				<definiendum id="0">TRIPS</definiendum>
				<definiens id="0">An Intelligent Integrated Problem-Solving Assistant , '' in Proc</definiens>
			</definition>
			<definition id="7">
				<sentence>MATCH : An Architecture for Multimodal Dialogue Systems .</sentence>
				<definiendum id="0">MATCH</definiendum>
			</definition>
			<definition id="8">
				<sentence>WordNet : A Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="0807">
			<definition id="0">
				<sentence>The Edinburgh Language Technology Group’s SGMLaware NLP tools ( Mikheev et al. , 1999 ) comprise a set of programs that rely on the common LT XML API2 to annotate text using cascading ( deterministic ) Finite-State Transducers ( Table 1 ) .</sentence>
				<definiendum id="0">Edinburgh Language Technology Group’s SGMLaware NLP tools</definiendum>
				<definiendum id="1">LT XML API2</definiendum>
				<definiendum id="2">deterministic ) Finite-State Transducers</definiendum>
				<definiens id="0">Mikheev et al. , 1999 ) comprise a set of programs that rely on the common</definiens>
			</definition>
			<definition id="1">
				<sentence>A framework is a collection of pre-defined services that embody a certain , given organization , within which the user can extend the functionality provided ; frameworks impose certain organizational principles on the developer ( Griffel , 1998 ) .</sentence>
				<definiendum id="0">framework</definiendum>
			</definition>
			<definition id="2">
				<sentence>The General Architecture for Text Engineering ( GATE ) 3 is a theory-neutral framework for the management and integration of NLP components and documents on which they operate ( Cunningham et al. , 1996 ; Cunningham , 2000 ; Bontcheva et al. , 2002 ; Cunningham et al. , 2002 ; Maynard et al. , forthcoming ) .</sentence>
				<definiendum id="0">General Architecture for Text Engineering</definiendum>
				<definiens id="0">a theory-neutral framework for the management and integration of NLP components and documents on which they operate ( Cunningham et al. , 1996 ; Cunningham , 2000 ; Bontcheva et al. , 2002 ; Cunningham et al. , 2002 ; Maynard et al. , forthcoming )</definiens>
			</definition>
			<definition id="3">
				<sentence>The WHITEBOARD project ( Crysmann et al. , 2002 ) uses monotonic XML annotation to integrate deep and shallow processing ( Figure 2 , middle ) .</sentence>
				<definiendum id="0">WHITEBOARD project</definiendum>
				<definiens id="0">Crysmann et al. , 2002 ) uses monotonic XML annotation to integrate deep and shallow processing ( Figure 2</definiens>
			</definition>
			<definition id="4">
				<sentence>ALEP , the Advanced Language Engineering Platform ( Simpkins and Groenendijk , 1994 ; Bredenkamp et al. , 1997 ) is an early framework that focused on multilinguality .</sentence>
				<definiendum id="0">ALEP</definiendum>
				<definiens id="0">an early framework that focused on multilinguality</definiens>
			</definition>
			<definition id="5">
				<sentence>ALEP’s Text Handling component ( Declerck , 1997 ) uses a particular SGML-based annotation that can be enriched with user-defined tags .</sentence>
				<definiendum id="0">ALEP’s Text Handling component</definiendum>
				<definiens id="0">uses a particular SGML-based annotation that can be enriched with user-defined tags</definiens>
			</definition>
			<definition id="6">
				<sentence>Control is specified in a PROLOG-like Interagent Communication Language ( ICL ) , which contains , but separates , declarative and procedural knowledge ( how to do and what to do ) .</sentence>
				<definiendum id="0">Control</definiendum>
				<definiens id="0">contains , but separates , declarative and procedural knowledge ( how to do and what to do )</definiens>
			</definition>
			<definition id="7">
				<sentence>Finite-State Automata ( FSAs ) were historically the first devices that have received a software engineering treatment ( Watson , 1995 ) , as they are pervasive from compiler technology to software engineering itself .</sentence>
				<definiendum id="0">Finite-State Automata</definiendum>
				<definiendum id="1">FSAs</definiendum>
				<definiens id="0">they are pervasive from compiler technology to software engineering itself</definiens>
			</definition>
			<definition id="8">
				<sentence>( Manolescu , 2000 ) identifies the FeatureExtraction pattern as a useful abstraction for information retrieval and natural language processing : a FeatureExtractorManager is a Factory of FeatureExtractor objects , where each knows a MappingStrategy , a FilteringStrategy and a Database .</sentence>
				<definiendum id="0">FeatureExtractorManager</definiendum>
				<definiens id="0">identifies the FeatureExtraction pattern as a useful abstraction for information retrieval and natural language processing : a</definiens>
				<definiens id="1">a Factory of FeatureExtractor objects</definiens>
			</definition>
			<definition id="9">
				<sentence>Composition languages are a logical next step in the ongoing development of new abstraction layers for computing.6 Figure 3 depicts the trade-off researchers have to face when deciding between carrying out an experiment , building a prototype program , implementing a more fleshed-out self-contained system , building a complete , generic , redistributable toolkit or whether they invest long-term in providing the community with a new framework.7 On the one hand , experiments ensure high short-term productivity with hardly any reuse or crossfertilization to other projects .</sentence>
				<definiendum id="0">Composition languages</definiendum>
				<definiens id="0">implementing a more fleshed-out self-contained system , building a complete , generic , redistributable toolkit or whether they invest long-term in providing the community with a new framework.7 On the one hand , experiments ensure high short-term productivity with hardly any reuse or crossfertilization to other projects</definiens>
			</definition>
			<definition id="10">
				<sentence>Frameworks are a valuable asset on the way as they embody common assumptions , but ( unlike toolkits ) they are not normally inter-operable with other frameworks .</sentence>
				<definiendum id="0">Frameworks</definiendum>
				<definiens id="0">a valuable asset on the way as they embody common assumptions , but ( unlike toolkits ) they are not normally inter-operable with other frameworks</definiens>
			</definition>
</paper>

		<paper id="1315">
</paper>

		<paper id="1408">
			<definition id="0">
				<sentence>But utering a contradictory expresion is a deviation from our general understanding about language use .</sentence>
				<definiendum id="0">contradictory expresion</definiendum>
				<definiens id="0">a deviation from our general understanding about language use</definiens>
			</definition>
			<definition id="1">
				<sentence>The cordination problem game is a type of game which Lewis analyses as a part of this theory of convention ( Lewis , 1961 ) .</sentence>
				<definiendum id="0">cordination problem game</definiendum>
			</definition>
			<definition id="2">
				<sentence>‘Colorles gren ideas slep furiously’ is a famous meaningles sentence writen by Chomsky .</sentence>
				<definiendum id="0">‘Colorles gren ideas slep furiously’</definiendum>
				<definiens id="0">a famous meaningles sentence writen by Chomsky</definiens>
			</definition>
			<definition id="3">
				<sentence>Problem Game GTS ( Game Theoretic Semantics ) has ben developed as an alternative semantics where major semantics have ben based on Tarski’s definition of truth .</sentence>
				<definiendum id="0">Problem Game GTS ( Game Theoretic Semantics</definiendum>
				<definiens id="0">an alternative semantics where major semantics have ben based on Tarski’s definition of truth</definiens>
			</definition>
			<definition id="4">
				<sentence>As the name shows , GTS is a semantics that models the idea of game theory .</sentence>
				<definiendum id="0">GTS</definiendum>
				<definiens id="0">a semantics that models the idea of game theory</definiens>
			</definition>
			<definition id="5">
				<sentence>‘Dead metaphor’ is a type of metaphor of which metaphorical meaning is rigid and most of us understand it in same way so that often we find its metaphorical meaning in dictionary .</sentence>
				<definiendum id="0">‘Dead metaphor’</definiendum>
				<definiens id="0">a type of metaphor of which metaphorical meaning is rigid and most of us understand it in same way so that often we find its metaphorical meaning in dictionary</definiens>
			</definition>
			<definition id="6">
				<sentence>The meaning of a metaphorical expresion is a game that has two ‘meanings’ , which are two choices with the tension caused by the coexistence of the two meanings .</sentence>
				<definiendum id="0">meaning of a metaphorical expresion</definiendum>
				<definiens id="0">a game that has two ‘meanings’ , which are two choices with the tension caused by the coexistence of the two meanings</definiens>
			</definition>
			<definition id="7">
				<sentence>Metaphorical meaning is one of the meanings that a metaphorical expresion has .</sentence>
				<definiendum id="0">Metaphorical meaning</definiendum>
				<definiens id="0">one of the meanings that a metaphorical expresion has</definiens>
			</definition>
</paper>

		<paper id="0904">
			<definition id="0">
				<sentence>Operative Strategies in Ontological Semantics cat verb subject root $ var1 cat noun direct-object root $ var2 cat noun sem-struc CREATE-ARTIFACT AGENT ^ $ var1 THEME ^ $ var2 In the above entry , the variables are used for linking ; the caret means ‘the meaning of’ ; CREATEARTIFACT is an ontological concept ( ontological concepts are in SMALL-CAPS ) ; AGENT and THEME are among its case roles and are used in this lexicon entry to specify selectional restrictions on this sense of make .</sentence>
				<definiendum id="0">caret</definiendum>
				<definiendum id="1">CREATEARTIFACT</definiendum>
				<definiens id="0">an ontological concept ( ontological concepts are in SMALL-CAPS</definiens>
			</definition>
			<definition id="1">
				<sentence>Residual ambiguity is one of several possible initial outcomes of the analysis process .</sentence>
				<definiendum id="0">Residual ambiguity</definiendum>
				<definiens id="0">one of several possible initial outcomes of the analysis process</definiens>
			</definition>
</paper>

		<paper id="0607">
			<definition id="0">
				<sentence>This paper details a new software framework , Experience-Based Language Acquisition ( EBLA ) , that acquires a childlike language known as protolanguage in a bottom-up fashion based on visually perceived experiences .</sentence>
				<definiendum id="0">Experience-Based Language Acquisition ( EBLA</definiendum>
				<definiens id="0">acquires a childlike language known as protolanguage in a bottom-up fashion based on visually perceived experiences</definiens>
			</definition>
			<definition id="1">
				<sentence>EBLA processes the individual frames in the videos to identify and store information about significant objects .</sentence>
				<definiendum id="0">EBLA</definiendum>
				<definiens id="0">processes the individual frames in the videos to identify and store information about significant objects</definiens>
			</definition>
			<definition id="2">
				<sentence>Finally , in the lexical acquisition stage , EBLA attempts to acquire language for the entities extracted in the second stage using protolanguage descriptions of each event .</sentence>
				<definiendum id="0">EBLA</definiendum>
				<definiens id="0">attempts to acquire language for the entities</definiens>
			</definition>
			<definition id="3">
				<sentence>The MER becomes the cognitive building block for increasingly complex knowledge representation and , ultimately , natural language .</sentence>
				<definiendum id="0">MER</definiendum>
				<definiens id="0">becomes the cognitive building block for increasingly complex knowledge representation and , ultimately , natural language</definiens>
			</definition>
			<definition id="4">
				<sentence>In 1992 , he described ABIGAIL , a system that constructs semantic descriptions of events occurring in computer-generated stick-figure animations .</sentence>
				<definiendum id="0">ABIGAIL</definiendum>
				<definiens id="0">a system that constructs semantic descriptions of events occurring in computer-generated stick-figure animations</definiens>
			</definition>
			<definition id="5">
				<sentence>HOWARD produces hidden Markov models ( HMMs ) of the motion profiles of the objects involved in an event .</sentence>
				<definiendum id="0">HOWARD</definiendum>
				<definiens id="0">produces hidden Markov models ( HMMs ) of the motion profiles of the objects involved in an event</definiens>
			</definition>
			<definition id="6">
				<sentence>The f-struct is an intermediate set of features that allows a layer of abstraction between the individual motions of an action and the action verb that describes them .</sentence>
				<definiendum id="0">f-struct</definiendum>
			</definition>
			<definition id="7">
				<sentence>An f-struct is a list of feature-value pairs represented in a table with two rows .</sentence>
				<definiendum id="0">f-struct</definiendum>
				<definiens id="0">a list of feature-value pairs represented in a table with two rows</definiens>
			</definition>
			<definition id="8">
				<sentence>Method Used by EBLA to Process Experiences As part of each experience , EBLA receives a textual description of the event taking place .</sentence>
				<definiendum id="0">EBLA</definiendum>
				<definiens id="0">receives a textual description of the event taking place</definiens>
			</definition>
			<definition id="9">
				<sentence>It should be noted that EBLA is not explicitly coded to ignore articles , but since they are referentially ambiguous when considered as individual , unordered lexemes , EBLA is unable to map them to entities .</sentence>
				<definiendum id="0">EBLA</definiendum>
				<definiens id="0">unable to map them to entities</definiens>
			</definition>
			<definition id="10">
				<sentence>EBLA attempts to establish the correct mappings for these lists in three stages : ences .</sentence>
				<definiendum id="0">EBLA</definiendum>
			</definition>
</paper>

		<paper id="1723">
			<definition id="0">
				<sentence>Word bigram segmentation aims to find the most appropriate segmentation m wwwWL 21 ˆ = that maximizes the probability ∏ = − m i iir wwP 1 1 ) | ( , i.e. ∏ = − ≈= m i iir W r W wwPCWPW 1 1 ) | ( maxarg ) | ( maxarg ˆ ( 1 ) where ) | ( 1−iir wwP is the probability that word l w will occur given previous word 1−i w , which can be easily estimated from segmented corpus using maximum likelihood estimation ( MLE ) , i.e. ) ( ) ( ) | ( 1 1 1 − − − ≈ i ii iir wCount wwCount wwP ( 2 ) To avoid the problem of data sparseness in MLE , here we apply the linear interpolation technique ( Jelinek and Mercer , 1980 ) to smooth the estimated word bigram probabilities .</sentence>
				<definiendum id="0">Word bigram segmentation</definiendum>
				<definiendum id="1">wwP</definiendum>
				<definiendum id="2">w</definiendum>
				<definiens id="0">maximizes the probability ∏ = − m i iir wwP 1 1 ) | ( , i.e. ∏ = − ≈= m i iir W r W wwPCWPW 1 1 ) | ( maxarg ) |</definiens>
				<definiens id="1">the probability that word l w will occur given previous word 1−i</definiens>
				<definiens id="2">estimated from segmented corpus using maximum likelihood estimation ( MLE ) , i.e. ) ( ) ( ) | ( 1 1 1 − − − ≈ i ii iir wCount wwCount wwP ( 2 ) To avoid the problem of data sparseness in MLE</definiens>
			</definition>
			<definition id="1">
				<sentence>Let ) ( 1+ii wwt denote the type of a word juncture 1+ii ww , and ) ) ( ( 1+iir wwtP denote the relevant conditional probability , then ) ( ) ) ( ( ) ) ( ( 1 1 1 + + + = ii ii def iir wwCount wwtCount wwtP ( 3 ) Thus , the word juncture probability ) ( UCJM wP of a particular unknown word jiiU wwwwL 1+ = ) 1 ( nji ≤≤≤ can be calculated by ∏ − = ++− ××= 1 111 ) ) ( ( ) ) ( ( ) ) ( ( ) ( j il llNrjjBriiBrUCJM cctPwwtPwwtPwP ( 4 ) In a sense , word juncture model mirrors the affinity of known word pairs in forming an unknown word .</sentence>
				<definiendum id="0">word juncture model</definiendum>
				<definiens id="0">the type of a word juncture 1+ii ww , and ) ) ( ( 1+iir wwtP denote the relevant conditional probability , then ) ( ) ) ( ( ) ) ( ( 1 1 1 + + + = ii ii def iir wwCount wwtCount wwtP ( 3 ) Thus , the word juncture probability ) ( UCJM wP of a particular unknown word jiiU wwwwL 1+ = ) 1 ( nji ≤≤≤ can be calculated by ∏ − = ++− ××= 1 111 ) ) ( ( ) ) ( ( ) ) ( ( ) ( j il</definiens>
			</definition>
			<definition id="2">
				<sentence>Let ) ( wpttn denote a particular pattern of w in an unknown word and ) ) ( ( wpttnP r denote the relevant probability , then ) ( ) ) ( ( ) ) ( ( wCount wpttnCount wpttnP def r = ( 5 ) Obviously , 1 ) ) ( ( = ∑ pttn r wpttnP .</sentence>
				<definiendum id="0">Let ) ( wpttn denote</definiendum>
				<definiendum id="1">) )</definiendum>
				<definiens id="0">a particular pattern of w in an unknown word and</definiens>
			</definition>
			<definition id="3">
				<sentence>In the evaluation program of the First International Chinese Word Segmentation Bakeoff , six measures are employed to score the performance of a word segmentation system , namely test recall ( R ) , test precision ( denoted by P ) , the balanced F-measure ( F ) , the out-of-vocabulary ( OOV ) rate for the test corpus , the recall on OOV words ( R OOV ) , and the recall on in-vocabulary ( R iv ) words .</sentence>
				<definiendum id="0">test precision</definiendum>
				<definiendum id="1">balanced F-measure</definiendum>
				<definiens id="0">the out-of-vocabulary ( OOV ) rate for the test corpus , the recall on OOV words ( R OOV</definiens>
			</definition>
			<definition id="4">
				<sentence>OOV is defined as the set of words in the test corpus not occurring in the training corpus in the closed test , and the set of words in the test corpus not occurring in the lexicon used in the open test .</sentence>
				<definiendum id="0">OOV</definiendum>
				<definiens id="0">the set of words in the test corpus not occurring in the training corpus in the closed test , and the set of words in the test corpus not occurring in the lexicon used in the open test</definiens>
			</definition>
			<definition id="5">
				<sentence>However , the overall test F-measure drops by only 0.2 percent in the open test , compared with the closed test .</sentence>
				<definiendum id="0">overall test F-measure</definiendum>
				<definiens id="0">drops by only 0.2 percent in the open test , compared with the closed test</definiens>
			</definition>
			<definition id="6">
				<sentence>For example , there was a sentence 中行长葛支行注重健身in the test corpus , where , the string中行长葛 is a fragment mixed with ambiguity and unknown words .</sentence>
				<definiendum id="0">string中行长葛</definiendum>
				<definiens id="0">a fragment mixed with ambiguity and unknown words</definiens>
			</definition>
</paper>

		<paper id="0307">
			<definition id="0">
				<sentence>Types of Alignment The test set consists of 447 alignment samples from the Canadian Hansards which were pre-tokenized .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of 447 alignment samples from the Canadian Hansards which were pre-tokenized</definiens>
			</definition>
			<definition id="1">
				<sentence>In figure 1 , “null-alignment” plots the union of the submitted alignment data and the inserted null-alignments .</sentence>
				<definiendum id="0">“null-alignment”</definiendum>
				<definiens id="0">plots the union of the submitted alignment data and the inserted null-alignments</definiens>
			</definition>
</paper>

		<paper id="1121">
</paper>

		<paper id="1902">
			<definition id="0">
				<sentence>The structure of this language is defined by a skeleton that consists on &lt; struct &gt; ( a node/level in the annotation ) and &lt; feat &gt; elements ( feature attached to the enclosing &lt; struct &gt; node ) .</sentence>
				<definiendum id="0">&lt; feat &gt; elements</definiendum>
				<definiens id="0">a skeleton that consists on &lt; struct &gt; ( a node/level in the annotation ) and</definiens>
			</definition>
			<definition id="1">
				<sentence>CAML is the language used for annotation encoding in particular projects .</sentence>
				<definiendum id="0">CAML</definiendum>
				<definiens id="0">the language used for annotation encoding in particular projects</definiens>
			</definition>
			<definition id="2">
				<sentence>As previously presented in Figure 3 , on each line of the figure : a0 the first symbol represents the syntactic function ( ‘SUBJ’= subject , ‘N’=noun modifier , ‘H’=head , etc. ) ; a0 following ‘ : ’ , we have the syntactic form for groups of words ( ’np’=noun phrase , etc. ) and POS-tags for single words ( ’n’=noun , ’v’=verb , etc. ) ; a0 in brackets are the word canonical form and other inflectional tags ; a0 after the brackets comes the word as it occurs in the corpus .</sentence>
				<definiendum id="0">syntactic function</definiendum>
				<definiens id="0">the word as it occurs in the corpus</definiens>
			</definition>
</paper>

		<paper id="2004">
</paper>

		<paper id="1905">
			<definition id="0">
				<sentence>MILE consists of an incremental definition of object-oriented layers for lexical description that will enable open and distributed lexicons , with elements possibly residing in different sites of the web .</sentence>
				<definiendum id="0">MILE</definiendum>
				<definiens id="0">consists of an incremental definition of object-oriented layers for lexical description that will enable open and distributed lexicons , with elements possibly residing in different sites of the web</definiens>
			</definition>
			<definition id="1">
				<sentence>The Resource Definition Framework ( RDF ) and the Ontology Web Language ( OWL ) recently developed by the World Wide Web Consortium ( W3C ) build upon the XML web infrastructure to enable the creation of a Semantic Web , wherein web objects can be classified according to their properties , and the semantics of their relations ( links ) to other web objects can be precisely defined .</sentence>
				<definiendum id="0">Resource Definition Framework ( RDF</definiendum>
				<definiens id="0">the Ontology Web Language ( OWL ) recently developed by the World Wide Web Consortium ( W3C ) build upon the XML web infrastructure to enable the creation of a Semantic Web , wherein web objects can be classified according to their properties , and the semantics of their relations ( links ) to other web objects</definiens>
			</definition>
			<definition id="2">
				<sentence>The MILE lexical entry is an ideal structure for rendering via RDFWL .</sentence>
				<definiendum id="0">MILE lexical entry</definiendum>
				<definiens id="0">an ideal structure for rendering via RDF/OWL</definiens>
			</definition>
			<definition id="3">
				<sentence>An RDF schema defines classes of objects and their relations to other objects .</sentence>
				<definiendum id="0">RDF schema</definiendum>
				<definiens id="0">defines classes of objects and their relations to other objects</definiens>
			</definition>
			<definition id="4">
				<sentence>The ISLE RDF schema and entries have been validated using the ICS-FORTH Validating RDF Parser ( VRP v2.1 ) , which analyzes the syntax of a given RDF/ XML file according to the RDF Model and Syntax Specification 4 and checks whether the statements contained in both RDF schemas and resource descriptions satisfy the semantic constraints derived by the RDF Schema Specification .</sentence>
				<definiendum id="0">ISLE RDF schema</definiendum>
				<definiendum id="1">ICS-FORTH Validating RDF Parser</definiendum>
				<definiens id="0">analyzes the syntax of a given RDF/ XML file according to the RDF Model and Syntax Specification 4 and checks whether the statements contained in both RDF schemas and resource descriptions satisfy the semantic constraints derived by the RDF Schema Specification</definiens>
			</definition>
</paper>

		<paper id="1613">
</paper>

		<paper id="1803">
			<definition id="0">
				<sentence>Various shallow methods have been proposed to translate compound nouns , notable amongst which are memory-based machine translation and word-to-word compositional machine translation .</sentence>
				<definiendum id="0">Various shallow methods</definiendum>
				<definiens id="0">proposed to translate compound nouns , notable amongst which are memory-based machine translation and word-to-word compositional machine translation</definiens>
			</definition>
			<definition id="1">
				<sentence>Idiomaticity is the problem of compositional semantic unpredictability and/or syntactic markedness , as seen in expressions such as kick the bucket ( = diea0 ) and by and large , respectively .</sentence>
				<definiendum id="0">Idiomaticity</definiendum>
			</definition>
			<definition id="2">
				<sentence>Noun-noun ( NN ) compounds ( e.g. web server , car park ) characteristically occur with high frequency and high lexical and semantic variability .</sentence>
				<definiendum id="0">Noun-noun ( NN</definiendum>
				<definiens id="0">compounds ( e.g. web server , car park ) characteristically occur with high frequency and high lexical and semantic variability</definiens>
			</definition>
			<definition id="3">
				<sentence>Memory-based machine translation ( MBMT ) is a simple and commonly-used method for translating NN compounds , whereby translation pairs are stored in a static translation database indexed by their source language strings .</sentence>
				<definiendum id="0">MBMT</definiendum>
				<definiens id="0">a simple and commonly-used method for translating NN compounds , whereby translation pairs are stored in a static translation database indexed by their source language strings</definiens>
			</definition>
			<definition id="4">
				<sentence>MBMT has the ability to produce consistent , high-quality translations ( conditioned on the quality of the original bilingual dictionary ) and is therefore suited to translating compounds in closed domains .</sentence>
				<definiendum id="0">MBMT</definiendum>
				<definiens id="0">the ability to produce consistent , high-quality translations ( conditioned on the quality of the original bilingual dictionary ) and is therefore suited to translating compounds in closed domains</definiens>
			</definition>
			<definition id="5">
				<sentence>Interpretation-driven DMT ( or DMTINTERP ) offers the means to deal with NN compounds where strict word-to-word alignment does not hold .</sentence>
				<definiendum id="0">Interpretation-driven DMT</definiendum>
				<definiendum id="1">DMTINTERP</definiendum>
				<definiens id="0">offers the means to deal with NN compounds where strict word-to-word alignment does not hold</definiens>
			</definition>
			<definition id="6">
				<sentence>DMTCOMP relies on translation templates to map the source language NN compound onto different constructions in the target language and generate translation candidates .</sentence>
				<definiendum id="0">DMTCOMP</definiendum>
				<definiens id="0">relies on translation templates to map the source language NN compound onto different constructions in the target language and generate translation candidates</definiens>
			</definition>
			<definition id="7">
				<sentence>Explicit abbreviation expansion could unearth the full wordform and facilitate alignment .</sentence>
				<definiendum id="0">Explicit abbreviation expansion</definiendum>
				<definiens id="0">could unearth the full wordform and facilitate alignment</definiens>
			</definition>
			<definition id="8">
				<sentence>We test-run this extended method for the JE translation task , using the Nihongo Goi-taikei thesaurus ( Ikehara et al. , 1997 ) as the source of source language synonyms , and ALTDICa62 as our translation dictionary .</sentence>
				<definiendum id="0">Nihongo Goi-taikei</definiendum>
				<definiens id="0">thesaurus ( Ikehara et al. , 1997 ) as the source of source language synonyms</definiens>
			</definition>
			<definition id="9">
				<sentence>The Nihongo Goi-taikei thesaurus classifies the contents of ALTDIC into 2,700 semantic classes .</sentence>
				<definiendum id="0">Nihongo Goi-taikei thesaurus</definiendum>
				<definiens id="0">classifies the contents of ALTDIC into 2,700 semantic classes</definiens>
			</definition>
			<definition id="10">
				<sentence>If we analyse the complexity of simple word-based substitution to be a28a30a29a32a31 a16a34a33 where a31 is the average number of translations per word , the complexity of synonym based substitution becomes a28a35a29a36a29a38a37 a16 a62 a31 a33 a31 a16 a33 where a37 is the average number of synonyms per class .</sentence>
				<definiendum id="0">a31</definiendum>
				<definiens id="0">the average number of translations per word , the complexity of synonym based substitution becomes a28a35a29a36a29a38a37 a16 a62 a31 a33 a31 a16 a33 where a37 is the average number of synonyms per class</definiens>
			</definition>
			<definition id="11">
				<sentence>As baselines , we also present the results for MBMTDICT ( MBMTDICT ( orig ) ) and DMTCOMP ( DMTCOMP ( orig ) ) in their original configurations ( over the full 23 templates and without synonym-substitution for DMTCOMP ) .</sentence>
				<definiendum id="0">DMTCOMP ( DMTCOMP</definiendum>
				<definiens id="0">( orig ) ) in their original configurations ( over the full 23 templates and without synonym-substitution for DMTCOMP</definiens>
			</definition>
</paper>

		<paper id="0423">
			<definition id="0">
				<sentence>This task has its origin from the Message Understanding Conferences ( MUC ) in the 1990s , a series of conferences aimed at evaluating systems that extract information from natural language texts .</sentence>
				<definiendum id="0">MUC</definiendum>
				<definiens id="0">a series of conferences aimed at evaluating systems that extract information from natural language texts</definiens>
			</definition>
			<definition id="1">
				<sentence>It is unique , agrees with the maximum-likelihood distribution , and has the exponential form ( Della Pietra et al. , 1997 ) : p ( o|h ) = 1Z ( h ) kproductdisplay j=1 αfj ( h , o ) j , where o refers to the outcome , h the history ( or context ) , and Z ( h ) is a normalization function .</sentence>
				<definiendum id="0">Z ( h )</definiendum>
				<definiens id="0">agrees with the maximum-likelihood distribution , and has the exponential form ( Della Pietra et al. , 1997 ) : p ( o|h ) = 1Z ( h</definiens>
				<definiens id="1">a normalization function</definiens>
			</definition>
			<definition id="2">
				<sentence>The maximum entropy classifier is used to classify each word as one of the following : the beginning of a NE ( B tag ) , a word inside a NE ( C tag ) , the last word of a NE ( L tag ) , or the unique word in a NE ( U tag ) .</sentence>
				<definiendum id="0">maximum entropy classifier</definiendum>
				<definiens id="0">the beginning of a NE ( B tag ) , a word inside a NE ( C tag ) , the last word of a NE ( L tag</definiens>
			</definition>
			<definition id="3">
				<sentence>The probability of the classes c1 , ... , cn assigned to the words in a sentence s in a document D is defined as follows : P ( c1 , ... , cn|s , D ) = nproductdisplay i=1 P ( ci|s , D ) ∗ P ( ci|ci−1 ) , where P ( ci|s , D ) is determined by the maximum entropy classifier .</sentence>
				<definiendum id="0">P (</definiendum>
				<definiens id="0">The probability of the classes c1 , ... , cn assigned to the words in a sentence s in a document D is defined as follows : P ( c1 , ... , cn|s</definiens>
				<definiens id="1">determined by the maximum entropy classifier</definiens>
			</definition>
			<definition id="4">
				<sentence>Frequent Word List ( FWL ) This list consists of words that occur in more than 5 different documents .</sentence>
				<definiendum id="0">list</definiendum>
				<definiens id="0">consists of words that occur in more than 5 different documents</definiens>
			</definition>
			<definition id="5">
				<sentence>Useful Bigrams ( UBI ) This list consists of bigrams of words that precede a name class .</sentence>
				<definiendum id="0">Useful Bigrams ( UBI ) This list</definiendum>
				<definiens id="0">consists of bigrams of words that precede a name class</definiens>
			</definition>
			<definition id="6">
				<sentence>In this case , News has an additional feature of I begin set to 1 , Broadcasting has an additional feature of I continue set to 1 , and Corp. has an additional feature of I end set to 1 .</sentence>
				<definiendum id="0">News</definiendum>
				<definiens id="0">has an additional feature of I begin set to 1 , Broadcasting has an additional feature of I continue set to 1 , and Corp. has an additional feature of I end set to 1</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>Another improvement over Och et al. and Yamada and Knight is the use of the finite state machine ( FSM ) modelling framework ( e.g. Bangalore and Riccardi , 2000 ) , which offers the considerable advantage of a flexible framework for decoding , as well as a representation which is suitable for the fixed two-level phrasal modelling employed here .</sentence>
				<definiendum id="0">Knight</definiendum>
				<definiens id="0">offers the considerable advantage of a flexible framework for decoding , as well as a representation which is suitable for the fixed two-level phrasal modelling employed here</definiens>
			</definition>
			<definition id="1">
				<sentence>The next stage of backoff from the above , literal level is a model that generates aligned English POS tag sequences given foreign POS tag sequences : details and an example can be found in Table 4 ( 2 ) .</sentence>
				<definiendum id="0">literal level</definiendum>
				<definiens id="0">a model that generates aligned English POS tag sequences given foreign POS tag sequences : details</definiens>
			</definition>
			<definition id="2">
				<sentence>j ( 1 ) P ( foreign bracketing , foreign phrase sequence j foreign words ) twSy Alljnp AlsAdsp AljmEyp AlEAmp .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">( foreign bracketing , foreign phrase sequence j foreign words</definiens>
			</definition>
			<definition id="3">
				<sentence>P ( NP2 VP1 NP3 PPNP4 PUNC5 j ( 2 ) P ( english phrase sequence , phrase alignment matrix j VP1 NP2 NP3 PPNP4 PUNC5 ) foreign phrase sequence ) P ( [ the sixth committee ] NP2 [ recommends ] V P1 ( 3 ) P ( english words , english bracketing , english phrase sequence j [ the general assembly ] NP3 .</sentence>
				<definiendum id="0">P</definiendum>
			</definition>
			<definition id="4">
				<sentence>Lexical coercion is a phenomenon that sometimes occurs when we condition translation of a foreign word on the word and the English part-of-speech .</sentence>
				<definiendum id="0">Lexical coercion</definiendum>
				<definiens id="0">a phenomenon that sometimes occurs when we condition translation of a foreign word on the word and the English part-of-speech</definiens>
			</definition>
</paper>

		<paper id="0906">
			<definition id="0">
				<sentence>First , to show that the metric measures something real and useful : in this case , that entailment and contradiction detection ( ECD ) measures an important facet of language understanding , and that it correlates with the ability to develop useful applications ( section 2 ) .</sentence>
				<definiendum id="0">contradiction detection</definiendum>
				<definiendum id="1">ECD )</definiendum>
				<definiens id="0">measures an important facet of language understanding , and that it correlates with the ability to develop useful applications ( section 2 )</definiens>
			</definition>
			<definition id="1">
				<sentence>Third , to show that the metric is not impossibly difficult for current technologies to satisfy , so that it encourages technological progress rather than stunting it : section 4 discusses a prototype system ( described more fully in ( Crouch et al. , 2002 ) ) to argue that , with current technology , ECD is a realistic though challenging metric .</sentence>
				<definiendum id="0">ECD</definiendum>
				<definiens id="0">a realistic though challenging metric</definiens>
			</definition>
			<definition id="2">
				<sentence>The Eureka system includes a large textual database containing engineer-authored documents ( tips ) about the repair and maintenance of printers and photocopiers .</sentence>
				<definiendum id="0">Eureka system</definiendum>
				<definiens id="0">includes a large textual database containing engineer-authored documents ( tips ) about the repair and maintenance of printers and photocopiers</definiens>
			</definition>
			<definition id="3">
				<sentence>Contexted Clauses A contexted atomic clause comprises an atomic fact , plus the context in which the fact is supposed to hold .</sentence>
				<definiendum id="0">Contexted Clauses A contexted atomic clause</definiendum>
				<definiens id="0">comprises an atomic fact , plus the context in which the fact is supposed to hold</definiens>
			</definition>
			<definition id="4">
				<sentence>b. ( ist t ( instantiated corrosion1 ) ) ( ist t ( uninstantiated contact2 ) ) ( ist t ( prevent corrosion1 contact2 ) ) ( maxsim prevent-context3 t corrosion1 ) ( ist prevent-context3 ( uninstantiated contact2 ) ) ( ist prevent-context3 ( instantiated corrosion1 ) ) ( subconcept corrosion1 corrosion ) ( subconcept contact2 contact ) ( subconcept contact2 continuous ) Here we have a number of facts about what holds in the intitial context , t : that there is an instance of a sub-concept of corrosion but no instance of some sub-concept of ( continuous ) contact , and that the prevent relation holds between the corrosion and contact concepts .</sentence>
				<definiendum id="0">ist t</definiendum>
			</definition>
			<definition id="5">
				<sentence>Context Matching Having obtained contexted representations for two texts , ECD proceeds in two stages .</sentence>
				<definiendum id="0">ECD</definiendum>
				<definiens id="0">proceeds in two stages</definiens>
			</definition>
			<definition id="6">
				<sentence>The first stage of mapping uses a broad coverage , hand coded Lexical Functional Grammar of English ( Butt et al. , 1998 ) and the parser from the Xerox Linguistic Environment ( XLE ) ( Maxwell and Kaplan , 1993 ) to parse the documents .</sentence>
				<definiendum id="0">Linguistic Environment</definiendum>
				<definiens id="0">uses a broad coverage , hand coded Lexical Functional Grammar of English ( Butt et al. , 1998 ) and the parser from the Xerox</definiens>
			</definition>
			<definition id="7">
				<sentence>The Structure Mapping Engine ( SME ) ( Forbus et al. , 1989 ) is used to match contexts .</sentence>
				<definiendum id="0">Structure Mapping Engine ( SME )</definiendum>
				<definiens id="0">used to match contexts</definiens>
			</definition>
			<definition id="8">
				<sentence>The SME is a graph matching algorithm developed for the recognition of analogy .</sentence>
				<definiendum id="0">SME</definiendum>
				<definiens id="0">a graph matching algorithm developed for the recognition of analogy</definiens>
			</definition>
			<definition id="9">
				<sentence>Intensional ECD seems to presuppose deep and detailed syntactic and semantic analysis ( though we have no arguments to rule out the possibility of shallower analysis ) .</sentence>
				<definiendum id="0">Intensional ECD</definiendum>
				<definiens id="0">seems to presuppose deep and detailed syntactic and semantic analysis</definiens>
			</definition>
			<definition id="10">
				<sentence>The current state of deep language processing technology suggests that ECD is a viable though challenging metric for open text in restricted domains .</sentence>
				<definiendum id="0">ECD</definiendum>
				<definiens id="0">a viable though challenging metric for open text in restricted domains</definiens>
			</definition>
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>The FrameNet project seeks to annotate a large subset of the British National Corpus with semantic information .</sentence>
				<definiendum id="0">FrameNet project</definiendum>
				<definiens id="0">seeks to annotate a large subset of the British National Corpus with semantic information</definiens>
			</definition>
			<definition id="1">
				<sentence>Their best performance on held out test data is achieved using a linear interpolation model : where r is the class to be predicted , x is the vector of syntactic features , x i is a subset of those features , α i is the weight given to that subset conditional probability ( as determined using the EM algorithm ) , and m is the total number of subsets used .</sentence>
				<definiendum id="0">linear interpolation model</definiendum>
				<definiendum id="1">r</definiendum>
				<definiendum id="2">m</definiendum>
				<definiens id="0">a subset of those features , α i is the weight given to that subset conditional probability ( as determined using the EM algorithm ) , and</definiens>
				<definiens id="1">the total number of subsets used</definiens>
			</definition>
			<definition id="2">
				<sentence>The target predicate is the only feature that is not extracted from the sentence itself and must be given by the user .</sentence>
				<definiendum id="0">target predicate</definiendum>
				<definiens id="0">the only feature that is not extracted from the sentence itself and must be given by the user</definiens>
			</definition>
			<definition id="3">
				<sentence>For example , in the sentence : “Alexandra bent her head ; ” “Alexandra” is an external argument Noun Phrase , “bent” is a target predicate , and “her head” is an object argument Noun Phrase .</sentence>
				<definiendum id="0">“Alexandra”</definiendum>
				<definiendum id="1">“bent”</definiendum>
				<definiens id="0">a target predicate</definiens>
			</definition>
			<definition id="4">
				<sentence>∑ = = n i i x xrf Z xrp 0 i ) ] , ( exp [ 1 ) | ( λ Here Z x is a normalization constant , f i ( r , x ) is a feature function which maps each role and vector element ( or combination of elements ) to a binary value , n is the total number of feature functions , and λ i is the weight for a given feature function .</sentence>
				<definiendum id="0">x )</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">λ i</definiendum>
				<definiens id="0">a feature function which maps each role and vector element ( or combination of elements</definiens>
			</definition>
</paper>

		<paper id="1404">
			<definition id="0">
				<sentence>Aptness is an umbrella term that covers a multitude of issues in the interpretation and generation of creative metaphor .</sentence>
				<definiendum id="0">Aptness</definiendum>
				<definiens id="0">an umbrella term that covers a multitude of issues in the interpretation and generation of creative metaphor</definiens>
			</definition>
			<definition id="1">
				<sentence>To L &amp; J , systematicity is a measure of the generativity of a metaphoric schema , so that the same schema ( such as Life is a Journey ) can serve as the deep structure for a wide variety of different , but mutually systematic , surface metaphors ( such as “ my job has hit a rocky patch” and “ my career has stalled” ) .</sentence>
				<definiendum id="0">systematicity</definiendum>
				<definiens id="0">a measure of the generativity of a metaphoric schema</definiens>
			</definition>
			<definition id="2">
				<sentence>For instance , WordNet contains a variety of concepts that are formally similar to { diary , journal } and which also mention “travel” in their glosses , such as { travel_guidebook } and { passport } .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">contains a variety of concepts that are formally similar to { diary , journal } and which also mention “travel” in their glosses</definiens>
			</definition>
</paper>

		<paper id="0907">
			<definition id="0">
				<sentence>Story understanding is a fundamental unsolved problem in artificial intelligence and computational linguistics .</sentence>
				<definiendum id="0">Story understanding</definiendum>
				<definiens id="0">a fundamental unsolved problem in artificial intelligence and computational linguistics</definiens>
			</definition>
			<definition id="1">
				<sentence>Space , for example , may be represented at different levels of the spatial semantic hierarchy ( Kuipers , 2000 ) such as topological space and metric space as well as at different levels of granularity such as room-scale and object-scale space .</sentence>
				<definiendum id="0">Space</definiendum>
				<definiens id="0">topological space and metric space as well as at different levels of granularity such as room-scale and object-scale space</definiens>
			</definition>
			<definition id="2">
				<sentence>The event calculus predicates important for this paper are as follows : Happens ( e ; t ) represents that an event e happens at time t. HoldsAt ( f ; t ) represents that a fluent f holds at time t. Initiates ( e ; f ; t ) represents that if event e occurs at t then fluent f starts holding after t. Terminates ( e ; f ; t ) represents that if event e occurs at t then fluent f stops holding after t. Reasoning using the event calculus is carried out as follows : If 1 and 2 are conjunctions of Happens and temporal ordering formulas , is a conjunction of Initiates , Terminates , and Releases axioms , is the conjunction of the event calculus axioms ECF1 to ECF5 ( Shanahan , 1997 ) , is a conjunction of state constraints , is a conjunction of trajectory axioms , is a conjunction of uniqueness-of-names axioms , and is a conjunction of HoldsAt formulas , then we are interested in the following : CIRC [ 1^ 2 ; Happens ] ^ CIRC [ ; Initiates ; Terminates ; Releases ] ^ ^ ^ ^ j= Deduction and projection are performed by taking 1 , 2 , , , , , and as input , and producing as output .</sentence>
				<definiendum id="0">Releases axioms</definiendum>
				<definiens id="0">if event e occurs at t then fluent f starts holding after t. Terminates ( e</definiens>
			</definition>
			<definition id="3">
				<sentence>The main program consists of 6332 lines of Python and Java code .</sentence>
				<definiendum id="0">main program</definiendum>
			</definition>
			<definition id="4">
				<sentence>The satisfiability encoder consists of 3658 lines of C code .</sentence>
				<definiendum id="0">satisfiability encoder</definiendum>
			</definition>
			<definition id="5">
				<sentence>More specifically , the event calculus narrative provided as input consists of : annotation of the story sentences as Happens and HoldsAt formulas , the structure of room-scale topological space , and ( optionally , to reduce the number of models ) initial and intermediate events and fluents , represented by Happens and HoldsAt formulas .</sentence>
				<definiendum id="0">event calculus narrative</definiendum>
				<definiens id="0">consists of : annotation of the story sentences as Happens and HoldsAt formulas , the structure of room-scale topological space , and ( optionally , to reduce the number of models ) initial and intermediate events and fluents , represented by Happens and HoldsAt formulas</definiens>
			</definition>
			<definition id="6">
				<sentence>One rule is given by Proposition 2 of Lifschitz , which reduces circumscription to predicate completion : IfF ( x ) does not containP , then the circumscription CIRC [ 8xF ( x ) ) P ( x ) ; P ] is equivalent to 8xF ( x ) , P ( x ) Many cases of circumscription in the event calculus reduce directly to simple predicate completion using Proposition 2 , but some do not .</sentence>
				<definiendum id="0">P ( x</definiendum>
				<definiens id="0">reduces circumscription to predicate completion : IfF ( x ) does not containP</definiens>
			</definition>
			<definition id="7">
				<sentence>OMSpace : object-scale metric space , with falling and collisions .</sentence>
				<definiendum id="0">OMSpace</definiendum>
			</definition>
			<definition id="8">
				<sentence>OTSpace : object-scale topological space .</sentence>
				<definiendum id="0">OTSpace</definiendum>
				<definiens id="0">object-scale topological space</definiens>
			</definition>
			<definition id="9">
				<sentence>PlayNeed : the need to play , with a simple model of needs and intentions .</sentence>
				<definiendum id="0">PlayNeed</definiendum>
				<definiens id="0">the need to play , with a simple model of needs and intentions</definiens>
			</definition>
			<definition id="10">
				<sentence>RTSpace : room-scale topological space .</sentence>
				<definiendum id="0">RTSpace</definiendum>
				<definiens id="0">room-scale topological space</definiens>
			</definition>
			<definition id="11">
				<sentence>Vision : some simple aspects of vision .</sentence>
				<definiendum id="0">Vision</definiendum>
				<definiens id="0">some simple aspects of vision</definiens>
			</definition>
			<definition id="12">
				<sentence>Initiates ( DoorUnlock ( actor , door ) , DoorUnlocked ( door ) , time ) We have similar precondition and effect axioms for locking a door .</sentence>
				<definiendum id="0">Initiates</definiendum>
				<definiendum id="1">DoorUnlocked</definiendum>
				<definiens id="0">( door ) , time ) We have similar precondition and effect axioms for locking a door</definiens>
			</definition>
			<definition id="13">
				<sentence>Initiates ( DoorOpen ( actor , door ) , DoorIsOpen ( door ) , time ) We have similar precondition and effect axioms for closing a door .</sentence>
				<definiendum id="0">Initiates</definiendum>
				<definiendum id="1">DoorIsOpen</definiendum>
				<definiens id="0">( door ) , time ) We have similar precondition and effect axioms for closing a door</definiens>
			</definition>
			<definition id="14">
				<sentence>Happens ( WalkThroughDoor12 ( actor , door ) , time ) ) HoldsAt ( Awake ( actor ) , time ) ^ HoldsAt ( Standing ( actor ) , time ) ^ HoldsAt ( DoorIsOpen ( door ) , time ) ^ HoldsAt ( At ( actor , Side1 ( door ) ) , time ) Axiom 9 .</sentence>
				<definiendum id="0">Happens</definiendum>
				<definiendum id="1">WalkThroughDoor12</definiendum>
				<definiendum id="2">HoldsAt</definiendum>
				<definiens id="0">( actor , door ) , time ) ) HoldsAt ( Awake ( actor ) , time ) ^ HoldsAt ( Standing ( actor ) , time ) ^ HoldsAt ( DoorIsOpen ( door ) , time ) ^</definiens>
			</definition>
			<definition id="15">
				<sentence>Happens ( WalkThroughDoor21 ( actor , door ) , time ) ) HoldsAt ( Awake ( actor ) , time ) ^ HoldsAt ( Standing ( actor ) , time ) ^ HoldsAt ( DoorIsOpen ( door ) , time ) ^ HoldsAt ( At ( actor , Side2 ( door ) ) , time ) Effect axioms state that if an actor walks through one side of a door , the actor will be at the other side of the door : Axiom 10 .</sentence>
				<definiendum id="0">Happens</definiendum>
				<definiendum id="1">WalkThroughDoor21</definiendum>
				<definiendum id="2">HoldsAt</definiendum>
				<definiendum id="3">Effect axioms</definiendum>
				<definiens id="0">( actor , door ) , time ) ) HoldsAt ( Awake ( actor ) , time ) ^ HoldsAt ( Standing ( actor ) , time ) ^ HoldsAt ( DoorIsOpen ( door ) , time ) ^</definiens>
			</definition>
			<definition id="16">
				<sentence>SkyOf ( outside ) = sky ) HoldsAt ( At ( sky , outside ) , time ) The complete run of the Snowman story takes 45 minutes on a machine with a 700 MHz Pentium III processor and 512 megabytes of RAM .</sentence>
				<definiendum id="0">HoldsAt</definiendum>
				<definiendum id="1">Snowman story</definiendum>
				<definiens id="0">takes 45 minutes on a machine with a 700 MHz Pentium III processor and 512 megabytes of RAM</definiens>
			</definition>
			<definition id="17">
				<sentence>In-depth understanding : A computer model of integrated processing for narrative comprehension .</sentence>
				<definiendum id="0">In-depth understanding</definiendum>
				<definiens id="0">A computer model of integrated processing for narrative comprehension</definiens>
			</definition>
</paper>

		<paper id="1501">
			<definition id="0">
				<sentence>The symbol A ⇔ B denotes a foreign name A is translated and/or transliterated into a Chinese name B. ( s1 ) Victoria Fall ⇔ 維多利亞瀑布 ( wei duo li ya pu bu ) ( s2 ) Little Rocky Mountains ⇔ 小落磯山脈 ( xiao luo ji shan mo ) ( s3 ) Great Salt Lake ⇔ 大鹽湖 ( da yan hu ) ( s4 ) Kenmare ⇔ 康美爾 ( kang mei er ) ( s5 ) East Chicago ⇔ 東芝加哥 ( dong zhi jia ge ) Example ( s1 ) shows a name part ( i.e. , Victoria ) and a keyword part ( i.e. , Fall ) of a named location are transliterated and translated into “維多利亞 ” ( wei duo li ya ) and “瀑布 ” ( pu bu ) , respectively .</sentence>
				<definiendum id="0">⇔ B</definiendum>
				<definiens id="0">a foreign name A is translated and/or transliterated into a</definiens>
			</definition>
			<definition id="1">
				<sentence>Each entry consists of three parts , including foreign location name , Chinese transliteration/translation name , and country name , e.g. , ( Victoria Fall , “維 多利亞瀑布 ” ( wei duo li ya pu bu ) , South Africa ) , ( Little Rocky Mountains , “小落磯山脈 ” ( xiao luo ji shan mo ) , USA ) , etc .</sentence>
				<definiendum id="0">entry</definiendum>
			</definition>
			<definition id="2">
				<sentence>FL denotes the length of foreign names in words , CL denotes the length of Chinese names in characters , and Count denotes the number of foreign names of the specified length .</sentence>
				<definiendum id="0">FL</definiendum>
				<definiendum id="1">CL</definiendum>
				<definiendum id="2">Count</definiendum>
				<definiens id="0">the length of foreign names in words</definiens>
				<definiens id="1">the length of Chinese names in characters</definiens>
			</definition>
			<definition id="3">
				<sentence>( 1 ) Suffix Party ( 黨 , dang ) , Association ( 協會 , xie hui ) , University ( 大學 , da xue ) , Co. ( 公司 , gong si ) , Committee ( 委員會 , wei yuan hui ) , Company ( 公司 , gong si ) , Bank ( 銀行 , yia hang ) , etc. ( 2 ) Prefix International ( 國際 , guo ji ) , World ( 世界 , shi jie ) , American ( 美國 , mei guo ) , National ( 全國 , quan guo ) , Japan ( 日本 , ri ben ) , National ( 國家 , guo jia ) , Asian ( 亞洲 , ya zhou ) , etc .</sentence>
				<definiendum id="0">Suffix Party</definiendum>
			</definition>
			<definition id="4">
				<sentence>The j th pair , 1 ≤ j ≤ M , is denoted by { E j , C j } , where E j is a foreign named entity , and C j is a Chinese named entity .</sentence>
				<definiendum id="0">C j</definiendum>
				<definiens id="0">a foreign named entity , and</definiens>
			</definition>
			<definition id="5">
				<sentence>If a named entity E j comprises m words w 1· w 2 …w m , then a candidate segment e p , q is defined as w p … w q , where 1 ≤ p ≤ q ≤ m. If a Chinese named entity C j has n syllables s 1· s 2 …s n , then a candidate segment c x , y is defined as s x … s y , where 1 ≤ p ≤ q ≤ n. Theoretically , we can get 2 ) 1 ( 2 ) 1 ( + × + nnmm pairs of { e p , q , c x , y } from { E j , C j } .</sentence>
				<definiendum id="0">y</definiendum>
				<definiens id="0">w p … w q , where 1 ≤ p ≤ q ≤ m. If a Chinese named entity C j has n syllables s 1· s 2 …s n , then a candidate segment c x</definiens>
				<definiens id="1">s x … s y , where 1 ≤ p ≤ q ≤ n. Theoretically</definiens>
				<definiens id="2">+ × + nnmm pairs of { e p , q , c x , y } from { E j , C j }</definiens>
			</definition>
			<definition id="6">
				<sentence>Term frequency ( tf ) of a Chinese translation segment c i in e denotes the number of occurrences of c i in e. Document frequency ( df ) of c i is the number of foreign segments that c i is translated to .</sentence>
				<definiendum id="0">Term frequency</definiendum>
				<definiendum id="1">Document frequency</definiendum>
				<definiens id="0">the number of occurrences of c i in e.</definiens>
				<definiens id="1">the number of foreign segments that c i is translated to</definiens>
			</definition>
			<definition id="7">
				<sentence>A candidate segment c p , q is defined as a string that begins with s p and ends with s q .</sentence>
				<definiendum id="0">candidate segment c p</definiendum>
				<definiens id="0">a string that begins with s p and ends with s q</definiens>
			</definition>
			<definition id="8">
				<sentence>The complexity of the original algorithm is O ( m 2 n 2 ) , but the complexity of the algorithm here is O ( 2 m 2 n ) , where m is the word count for a foreign named entity and n is the character count for a Chinese named entity .</sentence>
				<definiendum id="0">m</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the word count for a foreign named entity</definiens>
				<definiens id="1">the character count for a Chinese named entity</definiens>
			</definition>
			<definition id="9">
				<sentence>Four transformation rules shown as follows are learned , where α and β denote keywords for foreign language and Chinese , respectively ; δ is a Chinese transliteration of a foreign fragment γ ; the number enclosed in parentheses denotes frequency the rule is applied .</sentence>
				<definiendum id="0">δ</definiendum>
				<definiens id="0">follows are learned , where α and β denote keywords for foreign language and Chinese , respectively ;</definiens>
			</definition>
</paper>

		<paper id="0434">
			<definition id="0">
				<sentence>In our system , this is achieved by estimating the conditional probability P ( ti = c|xi ) for every possible class-label value c , where xi is a feature vector associated with token i. It is essentially a sufficient statistic in our model : we assume that P ( ti = c|xi ) = P ( ti = c| { wi } , { tj } j≤i ) .</sentence>
				<definiendum id="0">xi</definiendum>
				<definiens id="0">ti = c|xi ) = P ( ti = c| { wi }</definiens>
			</definition>
			<definition id="1">
				<sentence>In our system , the conditional probability model has the following parametric form : P ( ti = c|xi , { ti−lscript , ... , ti−1 } ) = T ( wTc xi + bc ) , where T ( y ) = min ( 1 , max ( 0 , y ) ) is the truncation of y into the interval [ 0,1 ] .</sentence>
				<definiendum id="0">) )</definiendum>
				<definiens id="0">wTc xi + bc ) , where T ( y ) = min ( 1 , max ( 0 , y</definiens>
			</definition>
</paper>

		<paper id="1612">
			<definition id="0">
				<sentence>‘ ( verb-c ) ’ means a consonant verb such as ‘yomu’ .</sentence>
				<definiendum id="0">‘ ( verb-c ) ’</definiendum>
			</definition>
			<definition id="1">
				<sentence>These 6 translations were evaluated by five methods : B1 to B4 are Japanese versions of BLEU with the extension described in Section 3 and M1 is a manual evaluation .</sentence>
				<definiendum id="0">M1</definiendum>
				<definiens id="0">a manual evaluation</definiens>
			</definition>
			<definition id="2">
				<sentence>M1 : Average score of the manual evaluation of all translations in the corpus .</sentence>
				<definiendum id="0">M1</definiendum>
				<definiens id="0">Average score of the manual evaluation of all translations in the corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>‘ ( verb-v ) ’ denotes a vowel verb .</sentence>
				<definiendum id="0">‘ ( verb-v ) ’</definiendum>
			</definition>
</paper>

		<paper id="1503">
			<definition id="0">
				<sentence>tag specifications ( IREX Committee , 1999 ) ( an English description in ( Sekine and Isahara , 1999 ) ) as regards the markup form , NE classes , and NE recognition guidelines .</sentence>
				<definiendum id="0">tag specifications</definiendum>
				<definiens id="0">regards the markup form , NE classes , and NE recognition guidelines</definiens>
			</definition>
</paper>

		<paper id="2008">
			<definition id="0">
				<sentence>A patent claim shares technical terminology with the rest of a patent but differs greatly in its content and syntax .</sentence>
				<definiendum id="0">patent claim</definiendum>
				<definiens id="0">shares technical terminology with the rest of a patent but differs greatly in its content and syntax</definiens>
			</definition>
			<definition id="1">
				<sentence>Supertagging is a process of tagging lexemes with labels ( or supertags ) , which code richer information than standard POS tags .</sentence>
				<definiendum id="0">Supertagging</definiendum>
			</definition>
			<definition id="2">
				<sentence>The semantic status of every case-role is defined as “agent” , “place” , “mode” , etc .</sentence>
				<definiendum id="0">semantic status of every case-role</definiendum>
			</definition>
			<definition id="3">
				<sentence>Syntactic knowledge includes the knowledge about linearization patterns of predicates that codes both the knowledge about co-occurrences of predicates and case-roles and the knowledge about their liner order in the claim text .</sentence>
				<definiendum id="0">Syntactic knowledge</definiendum>
				<definiens id="0">includes the knowledge about linearization patterns of predicates that codes both the knowledge about co-occurrences of predicates and case-roles and the knowledge about their liner order in the claim text</definiens>
			</definition>
			<definition id="4">
				<sentence>Our Phrase Structure Grammar consists of a number of rewriting rules and is specified over a space of supertags .</sentence>
				<definiendum id="0">Phrase Structure Grammar</definiendum>
				<definiens id="0">consists of a number of rewriting rules and is specified over a space of supertags</definiens>
			</definition>
			<definition id="5">
				<sentence>This grammar assigns a final parse ( representation ) to a claim sentence in the form : text : := { template ) { template } * template : := { label predicate-class predicate ( ( caserole ) ( case-role ) * } case-role : := ( rank status value ) value : := phrase { ( phrase ( word supertag ) * ) } * where label is a unique identifier of the elementary predicate-argument structure ( by convention , marked by the number of its predicate as it appears in the claim sentence , predicate-class is a label of an ontological concept , predicate is a string corresponding to a predicate from the system lexicon , case-roles are ranked according to the frequency of their cooccurrence with each predicate in the training corpus , status is a semantic status of a case-role , such as agent , theme , place , instrument , etc. , and value is a string which fills a case-role .</sentence>
				<definiendum id="0">predicate-class</definiendum>
				<definiendum id="1">value</definiendum>
				<definiens id="0">a claim sentence in the form : text : := { template ) { template } * template : := { label predicate-class predicate ( ( caserole ) ( case-role ) * } case-role : := ( rank status value ) value : := phrase { ( phrase ( word supertag ) * ) } * where label is a unique identifier of the elementary predicate-argument structure ( by convention , marked by the number of its predicate as it appears in the claim sentence</definiens>
				<definiens id="1">a label of an ontological concept , predicate is a string corresponding to a predicate from the system lexicon , case-roles are ranked according to the frequency of their cooccurrence with each predicate in the training corpus , status is a semantic status of a case-role , such as agent , theme , place , instrument , etc. , and</definiens>
				<definiens id="2">a string which fills a case-role</definiens>
			</definition>
			<definition id="6">
				<sentence>Supertag is a tag , which conveys both morphological information and semantic knowledge as specified in the shallow lexicon ( see Section 2.1 ) .</sentence>
				<definiendum id="0">Supertag</definiendum>
				<definiens id="0">a tag , which conveys both morphological information and semantic knowledge as specified in the shallow lexicon</definiens>
			</definition>
			<definition id="7">
				<sentence>The basic analysis scenario for the patent claim consists of the following sequence of procedures : • Tokenization • Supertagging • Chunking • Determining dependencies Every procedure relies on a certain amount of static knowledge of the model and on the dynamic knowledge collected by the previous analyzing procedures .</sentence>
				<definiendum id="0">basic analysis scenario for the patent claim</definiendum>
				<definiens id="0">consists of the following sequence of procedures : • Tokenization • Supertagging • Chunking • Determining dependencies Every procedure relies on a certain amount of static knowledge of the model and on the dynamic knowledge collected by the previous analyzing procedures</definiens>
			</definition>
			<definition id="8">
				<sentence>Then the supertag disambiguation procedure attempts to disambiguate multiple supertags .</sentence>
				<definiendum id="0">supertag disambiguation procedure</definiendum>
				<definiens id="0">attempts to disambiguate multiple supertags</definiens>
			</definition>
			<definition id="9">
				<sentence>The chunking procedure is a succession of processing steps itself starting with the simplenoun-phrase procedure , followed the complexnoun-phrase procedure , which integrates simple noun phrases into more complex structures ( those including prepositions and conjunctions ) .</sentence>
				<definiendum id="0">chunking procedure</definiendum>
				<definiens id="0">a succession of processing steps itself starting with the simplenoun-phrase procedure , followed the complexnoun-phrase procedure , which integrates simple noun phrases into more complex structures</definiens>
			</definition>
</paper>

		<paper id="1718">
			<definition id="0">
				<sentence>However , due to the lack of in-depth research , SCNE is a major source of errors in named entity recognition ( NER ) .</sentence>
				<definiendum id="0">SCNE</definiendum>
				<definiens id="0">a major source of errors in named entity recognition ( NER )</definiens>
			</definition>
			<definition id="1">
				<sentence>However , due to the lack of research , SCNE is a major source of errors in NER .</sentence>
				<definiendum id="0">SCNE</definiendum>
				<definiens id="0">a major source of errors in NER</definiens>
			</definition>
			<definition id="2">
				<sentence>However , due to the lack of research , SCNE is a major source of errors in NER .</sentence>
				<definiendum id="0">SCNE</definiendum>
				<definiens id="0">a major source of errors in NER</definiens>
			</definition>
			<definition id="3">
				<sentence>We are given Chinese sentence S , which is a character string .</sentence>
				<definiendum id="0">Chinese sentence S</definiendum>
			</definition>
			<definition id="4">
				<sentence>| ( ) ( maxarg* WSPWPW W = ( 1 ) Following our Chinese word definition , we define word class C as follows : ( 1 ) each lexicon word is defined as a class ; ( 2 ) each morphologically derived word is defined as a class ; ( 3 ) each type of named entities is defined as a class , e.g. all person names belong to a class PN , and ( 4 ) each type of factoids is defined as a class , e.g. all time expressions belong to a class TIME .</sentence>
				<definiendum id="0">| ( )</definiendum>
				<definiendum id="1">word class C</definiendum>
				<definiens id="0">a class ; ( 2 ) each morphologically derived word</definiens>
				<definiens id="1">a class</definiens>
				<definiens id="2">a class</definiens>
			</definition>
			<definition id="5">
				<sentence>= = n i i j j SSCL SSCLSCLNE 1 | ) ( | | ) ( | ) _|P ( S ( 3 ) Here , Sj is a character in SCL list which is extracted from training corpus .</sentence>
				<definiendum id="0">Sj</definiendum>
				<definiens id="0">a character in SCL list which is extracted from training corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>|SCL ( Sj ) | is the number of tokens Sj , which are labeled as SCL in training corpus .</sentence>
				<definiendum id="0">|SCL ( Sj ) |</definiendum>
				<definiens id="0">the number of tokens Sj , which are labeled as SCL in training corpus</definiens>
			</definition>
			<definition id="7">
				<sentence>Local context characters ( i.e. left or right characters within a window ) are used as features .</sentence>
				<definiendum id="0">Local context characters</definiendum>
			</definition>
			<definition id="8">
				<sentence>, ( exp ( ) ( 1 ) | ( = i ii yxfxZxyP λ λ λ ( 5 ) where a0 i is a weight of the feature fi , and Z ( x ) is a normalization factor .</sentence>
				<definiendum id="0">Z ( x )</definiendum>
				<definiens id="0">a normalization factor</definiens>
			</definition>
			<definition id="9">
				<sentence>M1 is the original model described in Section 3.1 .</sentence>
				<definiendum id="0">M1</definiendum>
			</definition>
			<definition id="10">
				<sentence>6 Conclusion Although SCNE is very common in written Chinese text , due to the lack of in-depth research , SCNE is a major source of errors in NER .</sentence>
				<definiendum id="0">SCNE</definiendum>
				<definiens id="0">a major source of errors in NER</definiens>
			</definition>
</paper>

		<paper id="0603">
			<definition id="0">
				<sentence>Winograd’s SHRDLU is a well known system that could understand and generate natural language referring to objects and actions in a simple blocks world ( Winograd , 1970 ) .</sentence>
				<definiendum id="0">Winograd’s SHRDLU</definiendum>
			</definition>
			<definition id="1">
				<sentence>Partee provides an overview of the general formal semantics approach and the problems of context based meanings and meaning compositionality from this perspective ( Partee , 1995 ) .</sentence>
				<definiendum id="0">Partee</definiendum>
				<definiens id="0">provides an overview of the general formal semantics approach and the problems of context based meanings</definiens>
			</definition>
			<definition id="2">
				<sentence>The AVS is a measure of spatial relation meant to approximate human judgements corresponding to words like “above” and “to the left of” in 2D scenes of objects .</sentence>
				<definiendum id="0">AVS</definiendum>
				<definiens id="0">a measure of spatial relation meant to approximate human judgements corresponding to words like “above”</definiens>
			</definition>
			<definition id="3">
				<sentence>Given that the noun expects no arguments and that the grammar contains a rule of the form NP←N , an NP ( noun phrase ) is instantiated and the probabilistic composer is applied to the default set of objects yielded by N , which consists of all objects visible .</sentence>
				<definiendum id="0">NP ( noun phrase</definiendum>
			</definition>
			<definition id="4">
				<sentence>The “on” P ( prepoART : the CADJ : purple N : purple NP : P ( N ) NP : S ( NP ) N : one NP : one NP : P ( N ) NP : S ( NP ) P : on ART : the N : left ADJ : left N : left NP : left NP : left NP : S ( NP ) NP : S ( NP ) NP : O.x.min ( NP ) NP : O.x.min ( NP ) NP : O.x.min ( NP ) the purple one on the left Figure 7 : Sample parse of a referring noun phrase sition ) is left dangling for the moment as it needs a constituent that follows it .</sentence>
				<definiendum id="0">“on” P ( prepoART</definiendum>
				<definiens id="0">the CADJ : purple N : purple NP</definiens>
			</definition>
</paper>

		<paper id="0207">
			<definition id="0">
				<sentence>Many people contributed to the research including , but by no means limited to Susan Dumais , Peter Foltz , George Furnas , Walter Kintsch , Darrell Laham , Karen Lochbaum , Bob Rehder , and Lynn Streeter , 2 Introduction In my outsider’s opinion—I’m not a linguist and this is my first ACL meeting—this workshop marks an important turn in the study of language .</sentence>
				<definiendum id="0">workshop</definiendum>
				<definiens id="0">marks an important turn in the study of language</definiens>
			</definition>
			<definition id="1">
				<sentence>I’ll briefly describe where LSA came from , how it works , what it does and doesn’t do , some educational applications in which what it does is useful , some things that limit its usefulness and beg for better basic science , and some nitty-gritty on how and how not to apply it .</sentence>
				<definiendum id="0">LSA</definiendum>
			</definition>
			<definition id="2">
				<sentence>Incorrect measures of similarity occur especially for sentences to sentence comparisons in which syntax has strong effects , where broader contextual information or pragmatic intent is involved , and where word meanings have strong relations to perceptual sources to which LSA training has had no access .</sentence>
				<definiendum id="0">Incorrect</definiendum>
				<definiens id="0">measures of similarity occur especially for sentences to sentence comparisons in which syntax has strong effects , where broader contextual information or pragmatic intent is involved , and where word meanings have strong relations to perceptual sources to which LSA training has had no access</definiens>
			</definition>
</paper>

		<paper id="0803">
			<definition id="0">
				<sentence>OLLIE uses a browser client while data storage and ML training is performed on servers .</sentence>
				<definiendum id="0">OLLIE</definiendum>
				<definiens id="0">uses a browser client while data storage and ML training is performed on servers</definiens>
			</definition>
			<definition id="1">
				<sentence>OLLIE is an on-line application for corpus annotation that harnesses the power of Machine Learning ( ML ) and Information Extraction ( IE ) in order to make the annotator’s task easier and more efficient .</sentence>
				<definiendum id="0">OLLIE</definiendum>
				<definiens id="0">an on-line application for corpus annotation that harnesses the power of Machine Learning ( ML ) and Information Extraction ( IE ) in order to make the annotator’s task easier and more efficient</definiens>
			</definition>
			<definition id="2">
				<sentence>The OLLIE client consists of several web pages , each of them giving the user access to a particular service provided by the server .</sentence>
				<definiendum id="0">OLLIE client</definiendum>
				<definiens id="0">consists of several web pages , each of them giving the user access to a particular service provided by the server</definiens>
			</definition>
			<definition id="3">
				<sentence>The right-hand side shows the classes of annotations ( as specified in the user profile ) and the user selects the text to be annotated ( e.g. , “McCarthy” ) and clicks on the desired class ( e.g. , Person ) .</sentence>
				<definiendum id="0">right-hand side</definiendum>
				<definiens id="0">specified in the user profile ) and the user selects the text to be annotated</definiens>
			</definition>
			<definition id="4">
				<sentence>GATE is an infrastructure for developing and deploying software components that process human language ( Cunningham et al. , 2002 ) .</sentence>
				<definiendum id="0">GATE</definiendum>
			</definition>
			<definition id="5">
				<sentence>The annotation format is a modified form of the TIPSTER format ( Grishman , 1997 ) , is largely isomorphic with the Atlas format ( Bird and Liberman , 1999 ) and successfully supports I to/from XCES and TEI ( Ide et al. , 2000 ) .1 An annotation has a type , a pair of nodes pointing to positions inside the document content , and a set of attribute-values , encoding further linguistic information .</sentence>
				<definiendum id="0">annotation format</definiendum>
				<definiendum id="1">TIPSTER format</definiendum>
				<definiens id="0">a pair of nodes pointing to positions inside the document content , and a set of attribute-values , encoding further linguistic information</definiens>
			</definition>
			<definition id="6">
				<sentence>Linguistic data ( i.e. , annotated documents and corpora ) is stored in a database on the server ( see Figure 1 ) , in order to achieve optimal performance , concurrent data access , and persistence between working sessions .</sentence>
				<definiendum id="0">Linguistic data</definiendum>
				<definiens id="0">stored in a database on the server ( see Figure 1 ) , in order to achieve optimal performance , concurrent data access , and persistence between working sessions</definiens>
			</definition>
			<definition id="7">
				<sentence>Nominal attributes trigger the addition of the feature specified in the attribute definition on an annotation of the required type situated at the position of the classified instance .</sentence>
				<definiendum id="0">Nominal attributes</definiendum>
				<definiens id="0">trigger the addition of the feature specified in the attribute definition on an annotation of the required type situated at the position of the classified instance</definiens>
			</definition>
			<definition id="8">
				<sentence>OLLIE is an advanced collaborative annotation environment , which allows users to share and annotate distributed corpora , supported by adaptive information extraction that trains in the background and provides suggestions .</sentence>
				<definiendum id="0">OLLIE</definiendum>
			</definition>
			<definition id="9">
				<sentence>In addition , OLLIE is the only adaptive IE system that allows users to choose which ML approach they want to use and to comparatively evaluate different approaches .</sentence>
				<definiendum id="0">OLLIE</definiendum>
				<definiens id="0">the only adaptive IE system that allows users to choose which ML approach they want to use and to comparatively evaluate different approaches</definiens>
			</definition>
</paper>

		<paper id="0703">
</paper>

		<paper id="0402">
			<definition id="0">
				<sentence>Maximize : LD ( α ) ≡ lsummationdisplay i=1 αi − 12 lsummationdisplay i , j=1 yiyjαiαj ( xi •xj ) ( 2 ) subject to : 0 ≤ αi ≤ C andsummationtexti αiyi = 0 , where αi ( i = 1 ... l ) are the Lagrange multipliers , l is the total number of training samples , and C is a weighting parameter for mis-classification .</sentence>
				<definiendum id="0">αi</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">a weighting parameter for mis-classification</definiens>
			</definition>
			<definition id="1">
				<sentence>Vapnik-Chervonenkis ( VC ) dimension ( Vapnik , 1999 ) , as well as some other measures , is used to estimate the complexity of the hypothesis space , or the capacity of the learning machine .</sentence>
				<definiendum id="0">Vapnik-Chervonenkis</definiendum>
				<definiendum id="1">VC ) dimension</definiendum>
				<definiens id="0">used to estimate the complexity of the hypothesis space , or the capacity of the learning machine</definiens>
			</definition>
			<definition id="2">
				<sentence>In the boosting algorithm of ( Collins , 2000 ) , for each sample ( parse ) xij , its margin is defined as F ( xi1 , ¯α ) − F ( xij , ¯α ) , where F is a score function and ¯α is the parameter vector .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">a score function and ¯α is the parameter vector</definiens>
			</definition>
			<definition id="3">
				<sentence>Then the decision function is f ( ( xj , xk ) ) = Nssummationdisplay i=1 αiyiPK ( ( si1 , si2 ) , ( xj , xk ) ) + b = b + ( Nssummationdisplay i=1 αiyi ( K ( si1 , xj ) −K ( si2 , xj ) ) ) − ( Nssummationdisplay i=1 αiyi ( K ( si1 , xk ) −K ( si2 , xk ) ) ) , where xj and xk are two distinct parses of a sentence , ( si1 , si2 ) is the ith support vector , and Ns is the total number of support vectors .</sentence>
				<definiendum id="0">Nssummationdisplay i=1 αiyi ( K</definiendum>
				<definiendum id="1">Ns</definiendum>
				<definiens id="0">the ith support vector , and</definiens>
			</definition>
			<definition id="4">
				<sentence>Because Tr can be computed by dynamic programming , the computational complexity of Tr ( u , v ) is O ( |u|∗|v| ) , where |u| and |v| are the tree sizes of u and v respectively .</sentence>
				<definiendum id="0">O</definiendum>
				<definiens id="0">the tree sizes of u and v respectively</definiens>
			</definition>
			<definition id="5">
				<sentence>lvote ( x , f ) ≡ braceleftbigg 1 if f ( ¯x ) &lt; f ( x ) 0 otherwise ( 10 ) where f is a parse scoring function .</sentence>
				<definiendum id="0">f</definiendum>
			</definition>
			<definition id="6">
				<sentence>E is the space of event of the classification problem , and PrE ( ( x , ¯x ) ) = PrE ( ( ¯x , x ) ) = 12PrX ( x ) .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">the space of event of the classification problem , and PrE ( ( x , ¯x ) ) = PrE ( ( ¯x , x</definiens>
			</definition>
			<definition id="7">
				<sentence>Variants of the Perceptron algorithm , which are known as Approximate Maximal Margin classifier , such as PAM ( Krauth and Mezard , 1987 ) , ALMA ( Gentile , 2001 ) and PAUM ( Li et al. , 2002 ) , produce decision hyperplanes within ratio of the maximal margin .</sentence>
				<definiendum id="0">Variants of the Perceptron algorithm</definiendum>
				<definiendum id="1">Approximate Maximal Margin classifier</definiendum>
				<definiendum id="2">ALMA</definiendum>
				<definiendum id="3">PAUM</definiendum>
				<definiens id="0">Li et al. , 2002 ) , produce decision hyperplanes within ratio of the maximal margin</definiens>
			</definition>
			<definition id="8">
				<sentence>The training complexity for SVMlight is roughly O ( n2.1 ) ( Joachims , 1998 ) , where n is the number of the training samples .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of the training samples</definiens>
			</definition>
			<definition id="9">
				<sentence>Specifically , slice i contains positive samples ( ( ˜pk , pki ) , +1 ) and negative samples ( ( pki , ˜pk ) , −1 ) , where ˜pk is the best parse for sentence k , pki is the parse with the ith highest loglikelihood in all the parses for sentence k and it is not the best parse .</sentence>
				<definiendum id="0">˜pk</definiendum>
				<definiens id="0">the best parse for sentence k</definiens>
			</definition>
			<definition id="10">
				<sentence>≤40 Words ( 2245 sentences ) Model LR LP CBs 0 CBs 2 CBs CO99 88.5 % 88.7 % 0.92 66.7 % 87.1 % CH00 90.1 % 90.1 % 0.74 70.1 % 89.6 % CO00 90.1 % 90.4 % 0.73 70.7 % 89.6 % SVM 89.9 % 90.3 % 0.75 71.7 % 89.4 % ≤100 Words ( 2416 sentences ) Model LR LP CBs 0 CBs 2 CBs CO99 88.1 % 88.3 % 1.06 64.0 % 85.1 % CH00 89.6 % 89.5 % 0.88 67.6 % 87.7 % CO00 89.6 % 89.9 % 0.87 68.3 % 87.7 % SVM 89.4 % 89.8 % 0.89 69.2 % 87.6 % where fi is the result of the ith SVM .</sentence>
				<definiendum id="0">CBs</definiendum>
				<definiendum id="1">fi</definiendum>
				<definiens id="0">2245 sentences ) Model LR LP CBs</definiens>
				<definiens id="1">2416 sentences ) Model LR LP</definiens>
			</definition>
			<definition id="11">
				<sentence>X-axis stands for the number of slices to be combined .</sentence>
				<definiendum id="0">X-axis</definiendum>
				<definiens id="0">the number of slices to be combined</definiens>
			</definition>
</paper>

		<paper id="1603">
			<definition id="0">
				<sentence>† Denotation , which can be paraphrased to ‘nuance’ , is defined as “the thing that is actually described by a word rather than the feelings or ideas it suggests” in Longman web dictionary1 .</sentence>
				<definiendum id="0">† Denotation</definiendum>
				<definiens id="0">“the thing that is actually described by a word rather than the feelings or ideas it suggests” in Longman web dictionary1</definiens>
			</definition>
			<definition id="1">
				<sentence>Core meaning : Potate ( build ) Denotation : �bnaosu ( repair ) Lexical restriction : �jinja ( shrine ) ��bukkaku ( temple ) Figure 1 : Features in a definition statement In this paper , we assume that a definition statement of a word ( hereafter an entry ) in a dictionary consists of four types of materials as follows : † Core meaning is a word which exactly describes a particular semantic category which the entry belongs to .</sentence>
				<definiendum id="0">Core meaning</definiendum>
			</definition>
			<definition id="2">
				<sentence>For each fine-grained meaning f of e which belongs to a semantic category C , compute co-occurrence probabilities P ( f ; C ) = P i nsifP i Nsi ( 1 ) P ( f ; e ) = nefN e ( 2 ) where si is a near-synonym of e , nab is the co-occurrence frequency between a word a and a label b , and Na is the frequency of a. Step 5 .</sentence>
				<definiendum id="0">si</definiendum>
				<definiendum id="1">nab</definiendum>
				<definiendum id="2">Na</definiendum>
				<definiens id="0">the co-occurrence frequency between a word a and a label b , and</definiens>
			</definition>
			<definition id="3">
				<sentence>According to these cases , the total denotational score Sd of si is defined by Sd = X j pWj ( 3 ) where Wj is the weight of dij ( one of the denotations of si ) and p = 8 &gt; &lt; &gt; : 1 ( in Case 1 , 2 , 4a ) 0 ( in Case 3 ) ¡1 ( in Case 4b ) Note that Case 3 gives no weight , because the case does not consider any denotation of si but compares only between dw and its context .</sentence>
				<definiendum id="0">Wj</definiendum>
			</definition>
			<definition id="4">
				<sentence>Hence , our method defines the similarity between a lexical restriction vi and a semantic label qi of a word in an input context as follows : sim ( vi ; qi ) = log2 dep ( root ( v i ; qi ) ) £4 dep ( vi ) +dep ( qi ) ¶ ( 4 ) where root ( a ; b ) is the root node of the minimum subtree which includes both a and b , and dep ( a ) is the depth of a in the thesaurus .</sentence>
				<definiendum id="0">dep</definiendum>
				<definiens id="0">the root node of the minimum subtree which includes both a and b</definiens>
			</definition>
			<definition id="5">
				<sentence>Based on this process , we can compute the total score Sv of each near-synonym si of a target word w in an input sentence , with all extracted pairs of a lexical restriction vj and a semantic label qj in the input sentence by Sv = X j ( Wj ¢sim ( vj ; qj ) ) ( 5 ) where Wj is the weight of vj .</sentence>
				<definiendum id="0">Wj</definiendum>
				<definiens id="0">compute the total score Sv of each near-synonym si of a target word w in an input sentence , with all extracted pairs of a lexical restriction vj and a semantic label qj in the input sentence by Sv = X j</definiens>
				<definiens id="1">the weight of vj</definiens>
			</definition>
			<definition id="6">
				<sentence>( 6 ) where R is the number of near-synonyms which can be paraphrased , n is the number of presented nearsynonyms , and zi = 8 &lt; : 1 if a near synonym in rank i can be paraphrased 0 otherwize Table 3 shows the result .</sentence>
				<definiendum id="0">R</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the number of near-synonyms which can be paraphrased</definiens>
			</definition>
</paper>

		<paper id="1203">
			<definition id="0">
				<sentence>Clustering is done by modified K-means ( MKM ) -- a method that yields more optimal clusters than the conventional K-means method .</sentence>
				<definiendum id="0">Clustering</definiendum>
				<definiens id="0">done by modified K-means ( MKM ) -- a method that yields more optimal clusters than the conventional K-means method</definiens>
			</definition>
			<definition id="1">
				<sentence>We want to find ) | ( maxarg DCP C where D is a document consisting of linearly ordered sentence sequences ) ) ( , ) , ( , ) ,2 ( ) ,1 ( ( TstsssD  = , and C is a theme class sequence which consists of the class labels of all the sentences in D , ) ) ) ( ( , ) ) , ( ( , ) ) ,2 ( ( ) ) ,1 ( ( ( TsctscscscC  = .</sentence>
				<definiendum id="0">D</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">a document consisting of linearly ordered sentence sequences ) ) ( , ) , ( , ) ,2 ( ) ,1 ( ( TstsssD  = , and</definiens>
				<definiens id="1">a theme class sequence which consists of the class labels of all the sentences in D , ) ) ) ( ( , ) ) , ( ( , ) ) ,2 ( ( ) ) ,1 ( ( ( TsctscscscC  =</definiens>
			</definition>
			<definition id="2">
				<sentence>As we consider a document D to be a sequence of sentences , the sentences themselves are represented as feature vectors ) ( ts of length L , where t is the position of the sentence in the document and L is the size of the vocabulary .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">the position of the sentence in the document</definiens>
				<definiens id="1">the size of the vocabulary</definiens>
			</definition>
			<definition id="3">
				<sentence>Each element of the vector ) ( ts is an index term in the sentence , weighted by its text frequency ( tf ) and inverse document frequency ( idf ) where tf is defined as the frequency of the word in that particular sentence , and idf is the inverse frequency of the word in the larger document collection Ndflog− where df is the number of sentences this particular word appears in and N is the total number of sentences in the training corpus .</sentence>
				<definiendum id="0">element of the vector ) ( ts</definiendum>
				<definiendum id="1">inverse document frequency ( idf</definiendum>
				<definiendum id="2">tf</definiendum>
				<definiendum id="3">idf</definiendum>
				<definiendum id="4">df</definiendum>
				<definiendum id="5">N</definiendum>
				<definiens id="0">an index term in the sentence , weighted by its text frequency ( tf ) and</definiens>
				<definiens id="1">the frequency of the word in that particular sentence</definiens>
				<definiens id="2">the inverse frequency of the word in the larger document collection Ndflog− where</definiens>
				<definiens id="3">the number of sentences this particular word appears in and</definiens>
				<definiens id="4">the total number of sentences in the training corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>and Text Segmentation Text cohesion ( Halliday and Hasan ( 1996 ) ) is an important concept in summarization as it underlines the theme of a text segment based on connectivity patterns between sentences ( Mani ( 2002 ) ) .</sentence>
				<definiendum id="0">Text Segmentation Text cohesion</definiendum>
				<definiens id="0">an important concept in summarization as it underlines the theme of a text segment based on connectivity patterns between sentences</definiens>
			</definition>
			<definition id="5">
				<sentence>Our Hidden Markov Model provides a unified framework to incorporate text cohesion and term distribution information in the transition probabilities of theme classes .</sentence>
				<definiendum id="0">Hidden Markov Model</definiendum>
				<definiens id="0">provides a unified framework to incorporate text cohesion and term distribution information in the transition probabilities of theme classes</definiens>
			</definition>
			<definition id="6">
				<sentence>For a sentence vector of length L , where L is the total size of the vocabulary , its elements—the index terms—have certain probability density function ( pdf ) .</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">the total size of the vocabulary</definiens>
			</definition>
			<definition id="7">
				<sentence>We choose to evaluate our stochastic theme classification system ( STCS ) on a multi-document summarization task , among other possible tasks We choose a content-based method to evaluate the summaries extracted by our system , compared to those by another extraction-based system MEAD ( Radev 2002 ) , and against a baseline system that chooses the top N sentence in each document as salient sentences .</sentence>
				<definiendum id="0">STCS</definiendum>
				<definiens id="0">against a baseline system that chooses the top N sentence in each document as salient sentences</definiens>
			</definition>
</paper>

		<paper id="1720">
			<definition id="0">
				<sentence>Finally , the Support Vector Machine-based chunker brings character units together into words so as to determine the word boundaries .</sentence>
				<definiendum id="0">Support Vector Machine-based chunker</definiendum>
				<definiens id="0">brings character units together into words so as to determine the word boundaries</definiens>
			</definition>
</paper>

		<paper id="0203">
			<definition id="0">
				<sentence>By way of example , syntax is a prime candidate for a domain-specific term in the sentence `` Syntax is the branch of linguistics which studies the way words are put together into sentences '' .</sentence>
				<definiendum id="0">syntax</definiendum>
				<definiendum id="1">Syntax</definiendum>
				<definiens id="0">a prime candidate for a domain-specific term in the sentence</definiens>
				<definiens id="1">the branch of linguistics which studies the way words</definiens>
			</definition>
			<definition id="1">
				<sentence>It should be noted that , from a keyword , as in the case of the keyword `` phrase '' , a list of semantically close terms including noun phrase , verb phrase , adjective phrase and adverb phrase can be obtained .</sentence>
				<definiendum id="0">adverb phrase</definiendum>
				<definiens id="0">a list of semantically close terms including noun phrase , verb phrase , adjective phrase and</definiens>
			</definition>
			<definition id="2">
				<sentence>Example rules include the transformation of an SVO sentence in which the subject is a term , into the question `` Which HVO '' where H is a hypernym of the term .</sentence>
				<definiendum id="0">H</definiendum>
				<definiens id="0">the transformation of an SVO sentence in which the subject is a term</definiens>
			</definition>
			<definition id="3">
				<sentence>( i ) Item Difficulty We estimated the Item Difficulty ( ID ) by establishing the percentage of students from the two groups who answered the item correctly ( ID = C/T x 100 , where C is the number who answered the item correctly and T is the total number of students who attempted the item ) .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">Item Difficulty We estimated the Item Difficulty ( ID ) by establishing the percentage of students from the two groups who answered the item correctly ( ID = C/T x 100 , where</definiens>
				<definiens id="1">the number who answered the item correctly and</definiens>
			</definition>
</paper>

		<paper id="0421">
			<definition id="0">
				<sentence>Xavier Carreras holds a grant by the Catalan Government Research Department .</sentence>
				<definiendum id="0">Xavier Carreras</definiendum>
			</definition>
</paper>

		<paper id="1401">
			<definition id="0">
				<sentence>Viewed traditionally , metonymy is a nonliteral figure of speech in which the name of one thing is substituted for that of another related to it .</sentence>
				<definiendum id="0">metonymy</definiendum>
			</definition>
			<definition id="1">
				<sentence>The semantic relation that is captured by metonymy is one of semantic contiguity , in the sense that in many cases there are systematic relations between metonymically related concepts that can be regarded as slots in conceptual frames ( cf. Fillmore 1977 ) .</sentence>
				<definiendum id="0">semantic relation</definiendum>
			</definition>
			<definition id="2">
				<sentence>As the example above shows , polysemy is a common way in which metonymically related concepts manifest themselves in language .</sentence>
				<definiendum id="0">polysemy</definiendum>
				<definiens id="0">a common way in which metonymically related concepts manifest themselves in language</definiens>
			</definition>
			<definition id="3">
				<sentence>Regular polysemy is a subset of metonymy that covers the systematicity of the semantic relations involved .</sentence>
				<definiendum id="0">Regular polysemy</definiendum>
			</definition>
			<definition id="4">
				<sentence>EuroWordNet ( EWN ) ( Vossen 1997 ; Peters 1998 ) is a multilingual thesaurus incorporating wordnets from eight languages : English , Italian , Dutch , German , Spanish , French , Czech , Estonian .</sentence>
				<definiendum id="0">EuroWordNet ( EWN</definiendum>
			</definition>
			<definition id="5">
				<sentence>crocheting natural or synthetic fibers ) Covering ( a natural object that covers or envelops ) English Rp class ( 4 total ) : wool , hair , fleece , tapa Dutch RP class ( 1 total ) : wol Spanish RP class ( 1 total ) : lana Coverage of the intersection between all three languages : 25 % of set derived from WordNet Hypernymic Pair : Plant ( a living organism lacking the power of locomotion ) Edible fruit ( edible reproductive body of a seed plant especially one having sweet flesh ) English RP class ( 159 total ) : apple , boxberry , blackcurrant , banana , fig . . . Dutch RP clas s ( 9 total ) : banaan , vijg , persimoen , meloen… Spanish RP class ( 20 total ) : banana , plátano , melón , caqui , higo… Coverage of the intersection between all three languages : 2.5 % of set derived from WordNet Hypernymic Pair : Person ( a human being ) Quality ( an essential and distinguishing attribute of something or someone ) English RP class ( 11 total ) : attraction , authority , beauty , . . . Dutch RP class ( 1 total ) : schoonheid Spanish RP class ( 4 total ) : belleza , atracción , autoridad , imagen Word intersection between all three languages : 9 % of set derived from WordNet Hypernymic Pair : Substance ( that which has mass and occupies space ) Drug ( something that is used as a medicine or narcotic ) English RP class ( 25 total ) : alcohol , bromide , dragee , histamine , iodine , liquor… Dutch RP class ( 2 total ) : broom , cocktail Spanish RP class ( 10 total ) : bromuro , histamina , muscatel , yodo… Word intersection between all three languages : 4 % of set derived from WordNet Hypernymic Pair : Occupation ( the principal activity in your life ) – Discipline ( a branch of knowledge ) English RP class ( 6 total ) : architecture , literature , politics , law , theology , interior design Dutch RP class ( 1 total ) : architectuur Spanish RP class ( 2 total ) : arquitectura , teología Word intersection between all three languages : 16 % of set derived from WordNet It is possible to view these results as an indication of the cross-linguistic validity of the regular polysemic patterns and their level of universality relative to the language families represented by the wordnets .</sentence>
				<definiendum id="0">Covering</definiendum>
				<definiens id="0">a natural object that covers or envelops</definiens>
				<definiens id="1">a living organism lacking the power of locomotion ) Edible fruit ( edible reproductive body of a seed plant especially one having sweet flesh ) English RP class ( 159 total ) : apple , boxberry , blackcurrant , banana , fig</definiens>
				<definiens id="2">banana , plátano , melón , caqui</definiens>
				<definiens id="3">a human being ) Quality ( an essential and distinguishing attribute of something or someone ) English RP class ( 11 total ) : attraction , authority , beauty</definiens>
				<definiens id="4">a medicine or narcotic ) English RP class ( 25 total ) : alcohol , bromide , dragee , histamine , iodine</definiens>
				<definiens id="5">the principal activity in your life ) – Discipline ( a branch of knowledge ) English RP class ( 6 total ) : architecture , literature , politics , law</definiens>
			</definition>
			<definition id="6">
				<sentence>The Spanish política lacks a profession reading in the Spanish wordnet .</sentence>
				<definiendum id="0">Spanish política</definiendum>
				<definiens id="0">lacks a profession reading in the Spanish wordnet</definiens>
			</definition>
			<definition id="7">
				<sentence>( 1998 ) , WordNet : An Electronic Lexical Database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>The parse actionsa56 a48a50a49a53 are an ordered sequence , wherea68a43a69 is the number of actions associated with the parse a40 .</sentence>
				<definiendum id="0">wherea68a43a69</definiendum>
				<definiens id="0">the number of actions associated with the parse a40</definiens>
			</definition>
			<definition id="1">
				<sentence>Each component model takes the exponential form : a37a55a38a57a56 a51 a42a6a44a59a58a60a56 a61 a51a64a63a65a53a67a66 a53 a45a46a70 a71a16a72a21a73a75a74a77a76a79a78a81a80 a78a16a82a11a78 a38a83a44a59a58a60a56a84a61 a51a64a63a65a53a67a66 a53 a58a60a56 a51 a45a86a85 a87 a38a83a44a59a58a60a56a84a61 a51a64a63a65a53a67a66 a53 a45 a58 ( 2 ) where a87 a38a83a44a59a58a60a56 a61 a51a41a63a65a53a67a66 a53 a45 is a normalization term to ensure that a37a55a38a57a56 a51a42a6a44a88a58a60a56a62a61 a51a41a63a65a53a67a66 a53 a45 is a probability , a82a11a78 a38a83a44a59a58a60a56 a61 a51a64a63a65a53a67a66 a53 a58a60a56 a51 a45 is a feature function ( often binary ) and a80 a78 is the weight ofa82a21a78 .</sentence>
				<definiendum id="0">component model</definiendum>
				<definiendum id="1">a80 a78</definiendum>
				<definiens id="0">takes the exponential form : a37a55a38a57a56 a51 a42a6a44a59a58a60a56 a61 a51a64a63a65a53a67a66 a53 a45a46a70 a71a16a72a21a73a75a74a77a76a79a78a81a80 a78a16a82a11a78 a38a83a44a59a58a60a56a84a61 a51a64a63a65a53a67a66 a53 a58a60a56 a51 a45a86a85 a87 a38a83a44a59a58a60a56a84a61 a51a64a63a65a53a67a66 a53 a45 a58 ( 2 ) where a87 a38a83a44a59a58a60a56 a61 a51a41a63a65a53a67a66 a53 a45 is a normalization term to ensure that a37a55a38a57a56 a51a42a6a44a88a58a60a56a62a61 a51a41a63a65a53a67a66 a53 a45 is a probability</definiens>
				<definiens id="1">a feature function ( often binary )</definiens>
				<definiens id="2">the weight ofa82a21a78</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , when the template a101 a63a65a53a58a118a104a99a119 is applied to the rst character of the sample sentence , ( IP ( NP ( NP ( NRa22 /nrba23 /nrma25 /nre ) ) ( NP ( NN a27 /nnb a28 /nne ) ( NN a30 /nnb a31 /nne ) ) ) ( VP ( VV a33 /vvb a30 /vve ) ) ( PU a34 /pus ) ) , a feature a82 a38a64a101 a63a65a53 a70 *BOUNDARY*a58a118a104a118a119a120a70a121a106a65a122a21a123a124a45 is generated .</sentence>
				<definiendum id="0">IP</definiendum>
				<definiens id="0">the rst character of the sample sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Index Template ( context , future ) 1 a105a138a102a139a58a60a56a100a119a136a38a64a106a140a70a129a107 a1 a58a12 a58a1a45 2 a105a102 a105a102a11a131 a53a58a60a56 a119 a38a64a106a128a70a133a107 a1 a58a12 a45 Table 2 : Chunk feature templates : a105a102 a38a64a106a140a70a129a107 a1 a58a12 a58a1a45 is the chunk label plus the tag of its right most child if the a106a50a114a19a116 tree is a chunk ; Otherwise a105a20a102 is the constituent label of thea106 a114a19a116 tree .</sentence>
				<definiendum id="0">Index Template</definiendum>
				<definiendum id="1">tree</definiendum>
				<definiens id="0">Chunk feature templates : a105a102 a38a64a106a140a70a129a107 a1 a58a12 a58a1a45 is the chunk label plus the tag of its right most child if the a106a50a114a19a116</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , the interpretation of the template on line 4 of Table 3 is that a71 a63a65a53 is the root label of the previous subtree , a110 a61 a63a65a53 a111 a63a65a53a67a66 is the label of the right-most child of the previous tree , and a71a119 is the root label of the current subtree .</sentence>
				<definiendum id="0">a71a119</definiendum>
				<definiens id="0">the label of the right-most child of the previous tree</definiens>
				<definiens id="1">the root label of the current subtree</definiens>
			</definition>
			<definition id="5">
				<sentence>Index Template ( context , future ) 1 a71 a63a65a53a71a102a139a58a60a56a8a119a132a38a64a106a128a70 a12 a58a1 a58a130a108a21a45 2 a71 a63a65a53a110 a61 a63a65a53 a111 a63 a102 a66 a58a60a56a8a119a125a38a64a106a128a70 a1 a58a130a108a21a45 3 a71 a63a65a53a71a119a71 a53 4 a71 a63a65a53a110 a61 a63a65a53 a111 a63a65a53a67a66 a71 a119a4a58a60a56a8a119 5 a71 a63a65a53a110 a61 a63a65a53 a111 a63a65a53a67a66 a71 a119 a71 a53 a58a60a56a100a119 6 a71 a63a65a53a110 a61 a63a65a53 a111 a63a65a53a67a66 a110 a61 a63a65a53 a111 a63 a134 a66 a58a60a56a100a119 Table 3 : Extend feature templates : a71a102a65a38a64a106 a70 a107 a1 a58 a12 a58 a1 a58a130a108a21a45 is the root constituent label of the a106 a114a19a116 subtree ( relative to the current one ) ; a110 a61 a63a65a53 a111 a63 a102 a66 a38a64a106a147a70 a1 a58a130a108a21a45 is the label of the a106 a114a19a116 rightmost child of the previous subtree .</sentence>
				<definiendum id="0">Index Template</definiendum>
			</definition>
			<definition id="6">
				<sentence>Index Template ( context , future ) 1 a71a119a109a148a149a110a8a119a138a111a53a50a150a16a150a16a150a110a14a119a138a111a102a152a151a11a58a60a56a8a119 2 a71a119a138a111a63a65a53a58a60a56a8a119 3 a71a119a16a110a14a119a138a111a51a58a60a56a100a119a125a38a64a153a81a70 a1 a58a130a108a100a58a150a16a150a16a150 a58a118a106a50a154a18a45 4 a71 a63a65a53a58a60a56 a119 5 a71 a53a58a60a56a100a119 6 a71 a63 a134a71 a63a65a53a58a60a56 a119 7 a71 a53a71a134a152a58a60a56a100a119 Table 4 : Check feature templates : a71a102a135a38a64a106 a70 a107 a1 a58 a12 a58 a1 a58a130a108a21a45 is the constituent label of thea106a54a114a19a116 subtree ( relative to the current one ) .</sentence>
				<definiendum id="0">Index Template</definiendum>
				<definiendum id="1">a58a130a108a21a45</definiendum>
				<definiens id="0">Check feature templates : a71a102a135a38a64a106 a70 a107 a1 a58 a12 a58 a1</definiens>
			</definition>
			<definition id="7">
				<sentence>Similarly , a158a159a38a64a101a109a102a139a58a60a155a160a45 tests if the character a101a156a102 occurs in any position of any word on the list a155 , and a71 a38a64a101 a102 a58a60a155a160a45 tests if the character a101 a102 is the last position of any word on the lista155 .</sentence>
				<definiendum id="0">a158a159a38a64a101a109a102a139a58a60a155a160a45 tests</definiendum>
				<definiens id="0">if the character a101a156a102 occurs in any position of any word on the list a155</definiens>
				<definiens id="1">tests if the character a101 a102 is the last position of any word on the lista155</definiens>
			</definition>
			<definition id="8">
				<sentence>Formally , leta164a35a165a11a38a64a153a94a45a92a58a92a164a167a166a84a38a64a153a99a45 be the number of words of thea153a114a19a116 reference sentence and its parser output , respectively , and a168a169a38a64a153a94a45 be the number of common words in thea153a67a114a19a116 sentence of test set , then the word segmentation F-measure is a170a59a171a67a172a67a173 a70 a108 a76 a51 a168a169a38a64a153a94a45 a76 a51 a91 a164 a165 a38a64a153a94a45a146a174a175a164 a166 a38a64a153a94a45a93 a3 ( 4 ) The F-measure of constituent labels is computed similarly : a170 a112a177a176a130a178 a70 a108 a76 a51 a68a179a38a64a153a94a45 a76 a51 a91 a155a46a165a11a38a64a153a94a45a50a174a36a155a146a166a62a38a64a153a94a45a94a93 a58 ( 5 ) where a155 a165 a38a64a153a94a45 and a155 a166 a38a64a153a94a45 are the number of constituents in the a153a114a19a116 reference parse tree and parser output , respectively , and a68a180a38a64a153a99a45 is the number of common constituents .</sentence>
				<definiendum id="0">a68a180a38a64a153a99a45</definiendum>
				<definiens id="0">the number of words of thea153a114a19a116 reference sentence and its parser output , respectively , and a168a169a38a64a153a94a45 be the number of common words in thea153a67a114a19a116 sentence of test set , then the word segmentation F-measure is a170a59a171a67a172a67a173 a70 a108 a76 a51 a168a169a38a64a153a94a45 a76 a51 a91 a164 a165 a38a64a153a94a45a146a174a175a164 a166 a38a64a153a94a45a93 a3</definiens>
				<definiens id="1">the number of constituents in the a153a114a19a116 reference parse tree and parser output , respectively , and</definiens>
				<definiens id="2">the number of common constituents</definiens>
			</definition>
			<definition id="9">
				<sentence>Bikel and Chiang ( 2000 ) in fact contains two parsers : one is a lexicalized probabilistic contextfree grammar ( PCFG ) similar to ( Collins , 1997 ) ; the other is based on statistical TAG ( Chiang , 2000 ) .</sentence>
				<definiendum id="0">PCFG</definiendum>
				<definiens id="0">a lexicalized probabilistic contextfree grammar (</definiens>
			</definition>
</paper>

		<paper id="0420">
</paper>

		<paper id="1729">
			<definition id="0">
				<sentence>The Chinese word segmentation module uses a rule-based approach , based on a large dictionary and fine-grained linguistic rules .</sentence>
				<definiendum id="0">Chinese word segmentation module</definiendum>
				<definiens id="0">uses a rule-based approach , based on a large dictionary and fine-grained linguistic rules</definiens>
			</definition>
			<definition id="1">
				<sentence>Chinese word segmentation is one of the preprocessing steps of the SYSTRAN ChineseEnglish Machine Translation ( MT ) system .</sentence>
				<definiendum id="0">Chinese word segmentation</definiendum>
			</definition>
			<definition id="2">
				<sentence>The basic segmentation strategy is to list all possible matches for a translation unit ( typically , a sentence ) , then to solve overlapping matches via linguistic rules .</sentence>
				<definiendum id="0">basic segmentation strategy</definiendum>
				<definiens id="0">a sentence ) , then to solve overlapping matches via linguistic rules</definiens>
			</definition>
</paper>

		<paper id="1504">
			<definition id="0">
				<sentence>A gazetteer entry consists of a set of possible NE categories .</sentence>
				<definiendum id="0">gazetteer entry</definiendum>
			</definition>
			<definition id="1">
				<sentence>On the other hand , XLa50a36a51a53a52a55a54 achieves a higher peak ( increasing accuracy up to lan data , CA ) before decreasing below baseline .</sentence>
				<definiendum id="0">XLa50a36a51a53a52a55a54</definiendum>
				<definiens id="0">achieves a higher peak ( increasing accuracy up to lan data , CA ) before decreasing below baseline</definiens>
			</definition>
</paper>

		<paper id="1300">
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>WordNet : An electronic lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An electronic lexical database</definiens>
			</definition>
			<definition id="1">
				<sentence>Sankyha : The Indian Journal of Statistics .</sentence>
				<definiendum id="0">Sankyha</definiendum>
			</definition>
			<definition id="2">
				<sentence>Selection and Information : A class-based approach to lexical relationships .</sentence>
				<definiendum id="0">Selection</definiendum>
				<definiendum id="1">Information</definiendum>
			</definition>
</paper>

		<paper id="0416">
			<definition id="0">
				<sentence>Our probability model is a class-based model and it is an extension of the model proposed by Li and Abe ( 1998 ) .</sentence>
				<definiendum id="0">probability model</definiendum>
				<definiens id="0">a class-based model</definiens>
			</definition>
			<definition id="1">
				<sentence>A word class is a group of words which performs similarly in some linguistic phenomena .</sentence>
				<definiendum id="0">word class</definiendum>
				<definiens id="0">a group of words which performs similarly in some linguistic phenomena</definiens>
			</definition>
			<definition id="2">
				<sentence>BT CZ denotes a set of possible values for the CZ-th variable CG CZ .</sentence>
				<definiendum id="0">BT CZ</definiendum>
			</definition>
			<definition id="3">
				<sentence>Assume that we have C6 samples of co-occurrence data : CB BP CUDC CX BPB4DC BDCX BNDC BECX BNBMBMBMBNDC D2CX B5 CY CX BPBDBNBEBNBMBMBMBNC6CVBM The objective function in both clustering and parameter estimations in our method is the description length , D0B4C5BNCBB5 , which is defined as follows : D0B4C5BNCBB5BPA0D0D3CVC4 C5 B4CBB5B7D0B4C5B5BN ( 2 ) where C5 denotes the model and C4 C5 B4CBB5 is the likelihood of samples CB under model C5 : C4 C5 B4CBB5BP C6 CH CXBPBD C8B4DC BDCX BNDC BECX BNBMBMBMBNDC D2CX B5BM ( 3 ) The first term in Eq.2 , A0D0D3CVC4 C5 B4CBB5 , is called the data description length .</sentence>
				<definiendum id="0">C5</definiendum>
				<definiendum id="1">C4 C5 B4CBB5</definiendum>
				<definiens id="0">samples of co-occurrence data : CB BP CUDC CX BPB4DC BDCX BNDC BECX BNBMBMBMBNDC D2CX B5 CY CX BPBDBNBEBNBMBMBMBNC6CVBM The objective function in both clustering and parameter estimations in our method is the description length , D0B4C5BNCBB5 , which is defined as follows : D0B4C5BNCBB5BPA0D0D3CVC4 C5 B4CBB5B7D0B4C5B5BN ( 2 ) where</definiens>
				<definiens id="1">the model</definiens>
			</definition>
			<definition id="4">
				<sentence>The second term , D0B4C5B5 , is called the model description length , and when sample size C6 is large , it can be approximated as D0B4C5B5BP D6 BE D0D3CVC6BN where D6 is the number of free parameters in model C5 .</sentence>
				<definiendum id="0">D6</definiendum>
			</definition>
			<definition id="5">
				<sentence>Our clustering algorithm is a combination of three basic operations : CLASSIFY , SPLIT and MERGE .</sentence>
				<definiendum id="0">clustering algorithm</definiendum>
				<definiens id="0">a combination of three basic operations : CLASSIFY , SPLIT and MERGE</definiens>
			</definition>
			<definition id="6">
				<sentence>The CLASSIFY takes a partition CC in BT as input and improves the partition by moving the elements in BT from one class to another .</sentence>
				<definiendum id="0">CLASSIFY</definiendum>
				<definiens id="0">takes a partition CC in BT as input and improves the partition by moving the elements in BT from one class to another</definiens>
			</definition>
			<definition id="7">
				<sentence>The MERGE takes a partition CC as input and successively chooses two classes BV CX and BV CY from CC and replaces them with their union , BV CX CJBV CY .</sentence>
				<definiendum id="0">MERGE</definiendum>
				<definiens id="0">takes a partition CC as input and successively chooses two classes BV CX and BV CY from CC and replaces them with their union</definiens>
			</definition>
			<definition id="8">
				<sentence>The SPLIT takes a class , BV , and tries to find the best division of BV into two new classes , which will decrease the description length the most .</sentence>
				<definiendum id="0">SPLIT</definiendum>
				<definiens id="0">takes a class</definiens>
			</definition>
			<definition id="9">
				<sentence>The following is the precise algorithm for our main procedure : Algorithm 1 MAIN PROCEDURE ( C2 ) INPUT C2 : an integer specifying the number of trials in a SPLIT operation OUTPUT Partitions CC BD BNBMBMBNCC D2 and estimated parameters in the model PROCEDURE Step 0 CUCC BD BNBMBMBNCC D2 CVAWINITIALIZEB4CUBT BD BNBMBMBT D2 CVBNC2B5 Step 1 Do Step 2 through Step 3 until no change is made through one iteration Step 2 For D7 BPBDBNBMBMBND2 , do Step 2.1 through Step 2.2 Step 2.1 Do Step 2.1.1 until no change occurs through it Step 2.1.1 For CZ BPBDBNBMBMBND2 , CC CZ AW CLASSIFYB4CC CZ B5 Step 2.2 For each BV BE CC D7 , BV AW SPLITB4BVBNC2B5 Step 3 For CZ BPBDBNBMBMBND2 , CC CZ AW MERGEB4CC CZ B5 Step 4 Return the resulting partitions with the parameters in the model In the Step 0 of the algorithm , INITIALIZE creates the initial partitions of BT BD BNBMBMBMBNBT D2 .</sentence>
				<definiendum id="0">CC CZ AW MERGEB4CC CZ B5</definiendum>
				<definiens id="0">an integer specifying the number of trials in a SPLIT operation OUTPUT Partitions CC BD BNBMBMBNCC D2 and estimated parameters in the model PROCEDURE Step 0 CUCC BD BNBMBMBNCC D2 CVAWINITIALIZEB4CUBT BD BNBMBMBT D2</definiens>
			</definition>
			<definition id="10">
				<sentence>To explain the algorithm more fully , we define ‘counter functions’ CUB4BMBMB5 as follows : CUB4DC CZ B5BPAZCUDC BE CB CY DC CZ BP DC CZ CV CUB4BV CZ B5BPAZCUDC BE CB CY DC CZ BE BV CZ CV CUB4BV BD BNBMBMBNBV D2 B5BPAZCUDC BE CB CY DC BD BE BV BD BNBMBMBNDC D2 BE BV D2 CV CUB4BV BD BNBMBMBNBV CZA0BD BNDCBNBV CZB7BD BNBMBMBNBV D2 B5 BPAZCUDC BE CB CY DC CX BE BV CX B4CX BIBP CZB5BNDC CZ BP DCCV where the hatch ( AZ ) denotes the cardinality of a set and DC CZ is the CZ-th variable in sample DC .</sentence>
				<definiendum id="0">AZ</definiendum>
				<definiendum id="1">DC CZ</definiendum>
				<definiens id="0">follows : CUB4DC CZ B5BPAZCUDC BE CB CY DC CZ BP DC CZ CV CUB4BV CZ B5BPAZCUDC BE CB CY DC CZ BE BV CZ CV CUB4BV BD BNBMBMBNBV D2 B5BPAZCUDC BE CB CY DC BD BE BV BD BNBMBMBNDC D2 BE BV D2 CV CUB4BV BD BNBMBMBNBV CZA0BD BNDCBNBV CZB7BD BNBMBMBNBV D2 B5 BPAZCUDC BE CB CY DC CX BE BV CX B4CX BIBP CZB5BNDC CZ BP DCCV where the hatch (</definiens>
				<definiens id="1">the cardinality of a set</definiens>
			</definition>
			<definition id="11">
				<sentence>The precise algorithm is as follows : Algorithm 2 CLASSIFY ( CC CZ ) INPUT CC CZ : a partition in BT CZ OUTPUT An improved partition in BT CZ PROCEDURE Step 1 Do steps 2.1 through 2.3 until no elements in BT CZ can move from their current class to another one .</sentence>
				<definiendum id="0">CC CZ ) INPUT CC CZ</definiendum>
				<definiens id="0">a partition in BT CZ OUTPUT An improved partition in BT CZ PROCEDURE Step 1 Do steps 2.1 through 2.3 until no elements in BT CZ can move from their current class to another one</definiens>
			</definition>
			<definition id="12">
				<sentence>Step 2.1 For each element DC BE BT CZ , choose a class BV BC DC BE CC CZ which satisfies the following two conditions : BC DC is not empty B4BV BC DC BIBP AUB5 , and BC DC maximizes following quantity CVB4DCBNBV BC DC B5 : CVB4DCBNBV BC DC B5BP CG BV CX BECC CX CUB4BV BD BNBMBMBNBV CZA0BD BNDCBNBV CZB7BD BNBMBMBNBV D2 B5 A2D0D3CV CUB4BV BD BNBMBMBNBV CZA0BD BNBV BC DC BNBV CZB7BD BNBMBMBNBV D2 B5 CUB4BV BC DC B5 BM When the class containing DC now , BV DC , maximizes CV , select BV DC as BV BC DC even if some other classes also maximize CV .</sentence>
				<definiendum id="0">BT CZ</definiendum>
				<definiendum id="1">CC CZ</definiendum>
				<definiens id="0">satisfies the following two conditions : BC DC is not empty B4BV BC DC BIBP AUB5 , and BC DC maximizes following quantity CVB4DCBNBV BC DC B5 : CVB4DCBNBV BC DC B5BP CG BV CX BECC CX CUB4BV BD BNBMBMBNBV CZA0BD BNDCBNBV CZB7BD BNBMBMBNBV D2 B5 A2D0D3CV CUB4BV BD BNBMBMBNBV CZA0BD BNBV BC DC BNBV CZB7BD BNBMBMBNBV D2 B5 CUB4BV BC DC B5 BM When the class containing DC now , BV DC , maximizes CV , select BV DC as BV BC</definiens>
			</definition>
			<definition id="13">
				<sentence>Let BV DC BE CC BD and BW DC BE CD BD denote the classes where an element DC BE BT BD belongs , before and after Step 2 , respectively .</sentence>
				<definiendum id="0">BV DC</definiendum>
				<definiens id="0">BE CC BD and BW DC BE CD BD denote the classes where an element DC BE BT BD belongs , before and after Step 2 , respectively</definiens>
			</definition>
			<definition id="14">
				<sentence>We also use the suffixes in notations BV CX and BW CX as it holds that , if BV BC DC BP BV CX , then DC BE BW CX .</sentence>
				<definiendum id="0">BW CX</definiendum>
				<definiens id="0">it holds that , if BV BC DC BP BV CX , then DC BE BW CX</definiens>
			</definition>
			<definition id="15">
				<sentence>The MERGE takes partition CC as input and successively chooses two classes BV CX and BV CY from CC and replaces them with their union BV CX CJBV CY .</sentence>
				<definiendum id="0">MERGE</definiendum>
				<definiens id="0">takes partition CC as input and successively chooses two classes BV CX and BV CY from CC and replaces them with their union BV CX CJBV CY</definiens>
			</definition>
			<definition id="16">
				<sentence>In the pseudo code , Æ CXCY denotes the reduction in D0B4C5BNCBB5 which results in the merging of BV CX and BV CY .</sentence>
				<definiendum id="0">CXCY</definiendum>
			</definition>
			<definition id="17">
				<sentence>Step 3.4 Delete all Æ CXCY ’s which concern the merged classes BV CP or BV CQ from the table .</sentence>
				<definiendum id="0">Æ CXCY ’s</definiendum>
				<definiens id="0">concern the merged classes BV CP or BV CQ from the table</definiens>
			</definition>
			<definition id="18">
				<sentence>A bunsetsu consists of one or more content words and zero or more function words that follow these .</sentence>
				<definiendum id="0">bunsetsu</definiendum>
				<definiens id="0">consists of one or more content words and zero or more function words that follow these</definiens>
			</definition>
			<definition id="19">
				<sentence>That is the dependency of types : noun-pp AX pred , where noun is a noun , or the head of a compound noun , pp is one of 9 postpositions CUga , wo , ni , de , to , he , made , kara , yoriCV and pred is a bunsetsu which contains a verb or an adjective as its content word part .</sentence>
				<definiendum id="0">noun</definiendum>
				<definiendum id="1">kara , yoriCV</definiendum>
			</definition>
			<definition id="20">
				<sentence>Thus , our test data is in the form BO noun-ppBNCUpred BD BNBMBMBNpred D2 CV BQBN ( 8 ) where CUpred BD , ... , pred D2 CV is the set of all candidate dependee bunsetsus that are to the right of the input dependent bunsetsu noun-pp in a sentence .</sentence>
				<definiendum id="0">test data</definiendum>
				<definiens id="0">in the form BO noun-ppBNCUpred BD BNBMBMBNpred D2 CV BQBN ( 8 ) where CUpred BD , ... , pred D2 CV is the set of all candidate dependee bunsetsus that are to the right of the input dependent bunsetsu noun-pp in a sentence</definiens>
			</definition>
			<definition id="21">
				<sentence>From these types of samples , we want to estimate probabilityC8B4D6BNnounBNppBNpredB5 and use these to approximate probability D4 CX , where given the test data in Eq.8 , pred CX is the correct answer , expressed as D4 CX BB C8B4B7BNnounBNppBNpred CX B5 CH CYBIBPCX C8B4A0BNnounBNppBNpred CY B5BM We approximated the probability of occurrence for sample type D6 BP A0 expressed as C8B4A0BNnounBNppBNpredB5BPC8B4A0BNnounB5C8B4A0BNppBNpredB5BN and estimated these from the raw frequencies .</sentence>
				<definiendum id="0">CX</definiendum>
				<definiens id="0">estimate probabilityC8B4D6BNnounBNppBNpredB5 and use these to approximate probability D4 CX , where given the test data in Eq.8 , pred</definiens>
			</definition>
			<definition id="22">
				<sentence>Thus , our decision rule given test data ( Eq.8 ) is , to select pred CZ where CZ is the index which maximizes the value C8 B7 B4nounBNpp : pred CZ B5 C8B4A0BNppBNpred CZ B5 BM We extracted the training samples and the test data from the EDR Japanese corpus ( EDR , 1994 ) .</sentence>
				<definiendum id="0">CZ</definiendum>
			</definition>
			<definition id="23">
				<sentence>In the results , precision refers to the ratio CRBPB4CR B7 DBB5 and coverage refers to the ratio CRBPD8 , where CR and DB denote the numbers of correct and wrong predictions , and D8 denotes the number of all test data .</sentence>
				<definiendum id="0">D8</definiendum>
				<definiens id="0">the number of all test data</definiens>
			</definition>
			<definition id="24">
				<sentence>All the ‘ties cases’ were 1 10 100 1000 10000 100000 1000 10000 100000 computation time ( sec ) size of vocabulary our method Li’s method CLASSIFY Figure 1 : Computation time 10 100 1000 10000 100000 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 computation time ( sec ) coverage our method Li’s method Figure 2 : Coverage-Cost plot treated as wrong answers ( DB ) , where a ‘tie case’ means a situation where two or more predictions are made with the same maximum probabilities .</sentence>
				<definiendum id="0">‘tie case’</definiendum>
				<definiens id="0">Coverage-Cost plot treated as wrong answers ( DB ) , where a</definiens>
			</definition>
</paper>

		<paper id="1316">
			<definition id="0">
				<sentence>An SVM is a binary classification method that combines statistical learning and optimisation techniques with kernel mapping ( Vapnik , 1995 ) .</sentence>
				<definiendum id="0">SVM</definiendum>
			</definition>
			<definition id="1">
				<sentence>All abstracts ( from a larger collection , see Section 4 ) that contained at least one occurrence of a given gene or its aliases have been selected as documents relevant for that gene .</sentence>
				<definiendum id="0">All abstracts</definiendum>
				<definiens id="0">a larger collection , see Section 4 ) that contained at least one occurrence of a given gene or its aliases have been selected as documents relevant for that gene</definiens>
			</definition>
			<definition id="2">
				<sentence>An idf-like measure has been used for feature weights : the weight of a word w for gene g is given by ( 1 ) | ) |1 ( ) ( 1 log gw Rj j RN wf g + + ∑ ∈ where R g is a set of relevant documents for the gene g , f j ( w ) is the frequency of w in document j , and N w is the global frequency of w. Gene vectors , containing weights for all co-occurring words , have been used as input for the SVM .</sentence>
				<definiendum id="0">R g</definiendum>
				<definiendum id="1">N w</definiendum>
				<definiens id="0">a set of relevant documents for the gene g</definiens>
				<definiens id="1">the global frequency of w. Gene vectors , containing weights for all co-occurring words</definiens>
			</definition>
			<definition id="3">
				<sentence>As feature weights , binary values ( i.e. a gene is present/absent in a document ) were used .</sentence>
				<definiendum id="0">binary values</definiendum>
				<definiens id="0">present/absent in a document ) were used</definiens>
			</definition>
</paper>

		<paper id="0202">
			<definition id="0">
				<sentence>A term is any string of alpha-numeric characters ( typically a single word ) .</sentence>
				<definiendum id="0">term</definiendum>
				<definiens id="0">any string of alpha-numeric characters ( typically a single word )</definiens>
			</definition>
			<definition id="1">
				<sentence>a0 A term abstraction is defined as any regular expression that can be applied to and match a single word ( i.e. that contains no whitespace ) .</sentence>
				<definiendum id="0">a0 A term abstraction</definiendum>
				<definiens id="0">any regular expression that can be applied to and match a single word ( i.e. that contains no whitespace )</definiens>
			</definition>
			<definition id="2">
				<sentence>a0 An ordering constraint is a requirement that two terms ( or term abstractions ) occur in a particular order .</sentence>
				<definiendum id="0">An ordering constraint</definiendum>
				<definiens id="0">a requirement that two terms ( or term abstractions ) occur in a particular order</definiens>
			</definition>
			<definition id="3">
				<sentence>Recall is correct positives over all positives ( correct + incorrect . )</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">correct positives over all positives ( correct + incorrect</definiens>
			</definition>
			<definition id="4">
				<sentence>In particular , the Pinitial class consists of answers where the student claimed that Object A had a higher average speed , but not because they confused position and speed , as the automated diagnostic system had inferred .</sentence>
				<definiendum id="0">Pinitial class</definiendum>
				<definiens id="0">consists of answers where the student claimed that Object A had a higher average speed , but not because they confused position and speed , as the automated diagnostic system had inferred</definiens>
			</definition>
</paper>

		<paper id="1901">
			<definition id="0">
				<sentence>Including o continuous segments ( appear contiguously in the primary data ) o superand sub-segments , where groups of segments will comprise the parts of a larger segment ( e.g. , a contiguous word segments typically comprise a sentence segment ) o discontinuous segments ( linked continuous segments ) o landmarks ( e.g. time stamps ) that note a point in the primary data In current practice , segmental information may or may not appear in the document containing the primary data itself .</sentence>
				<definiendum id="0">continuous segments</definiendum>
				<definiens id="0">a sentence segment ) o discontinuous segments ( linked continuous segments ) o landmarks ( e.g. time stamps</definiens>
			</definition>
			<definition id="1">
				<sentence>Stand-off annotation : Annotations layered over a given primary document and instantiated in a document separate from that containing the primary data .</sentence>
				<definiendum id="0">Stand-off annotation</definiendum>
				<definiens id="0">Annotations layered over a given primary document and instantiated in a document separate from that containing the primary data</definiens>
			</definition>
</paper>

		<paper id="1116">
			<definition id="0">
				<sentence>An alternative is to use implicit feedback where document relevance is inferred from user’s behavior , which has received increased attention in recent years ( Nichols , 1997 ; Konstan et al. , 1997 ; Kim , 2000 ) This paper focuses upon the extraction of user preferences from a few documents that might interest a user .</sentence>
				<definiendum id="0">document relevance</definiendum>
				<definiens id="0">has received increased attention in recent years</definiens>
			</definition>
			<definition id="1">
				<sentence>The j th′ component of w is : c Ci ji c Ci ji joldj nn x n x ww − ∑ − ∑ += ∉∈ , , , γβα ( 1 ) where , , ij x means j th′ component of ith′ document vector i x and n is the number of training documents .</sentence>
				<definiendum id="0">, ij x</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">c Ci ji c Ci ji joldj nn x n x ww − ∑ − ∑ += ∉∈ , , , γβα ( 1 ) where ,</definiens>
				<definiens id="1">the number of training documents</definiens>
			</definition>
			<definition id="2">
				<sentence>C is the set of positive training documents , and c n is the number of positive training documents .</sentence>
				<definiendum id="0">C</definiendum>
				<definiendum id="1">c n</definiendum>
				<definiens id="0">the set of positive training documents , and</definiens>
				<definiens id="1">the number of positive training documents</definiens>
			</definition>
			<definition id="3">
				<sentence>1 , , , 2 ( ) ij ij i i iij ww wxyxη + = −•− ( 2 ) where , η is the learning rate which controls how quickly the weight vector w is allowed to change and ii xw • is the cosine value of the two vectors .</sentence>
				<definiendum id="0">η</definiendum>
				<definiens id="0">the learning rate which controls how quickly the weight vector</definiens>
				<definiens id="1">the cosine value of the two vectors</definiens>
			</definition>
			<definition id="4">
				<sentence>Three factors of a term ( term frequency , document frequency within positive examples , and IDF ) are used to calculate the importance of a specific term .</sentence>
				<definiendum id="0">document frequency</definiendum>
				<definiens id="0">used to calculate the importance of a specific term</definiens>
			</definition>
			<definition id="5">
				<sentence>The TF ( Term Frequency ) is the term frequency of a specific term not in a document but in a set of documents , which is calculated by dividing total occurrences of the term in a set of documents by the number of documents in the set containing the term .</sentence>
				<definiendum id="0">TF ( Term Frequency )</definiendum>
			</definition>
			<definition id="6">
				<sentence>max i i i j j j TF DF NTF TF DF =         ( 3 ) where , i TF is the frequency of term t i in the example documents , i DF is the number of documents having term t i in the example document , [ ] j j Max x means the maximum value of variable j x .</sentence>
				<definiendum id="0">TF</definiendum>
				<definiendum id="1">DF</definiendum>
				<definiens id="0">the frequency of term t i in the example documents</definiens>
				<definiens id="1">the number of documents having term t i in the example document</definiens>
			</definition>
			<definition id="7">
				<sentence>The DF ( Document Frequency ) represents the frequency of documents having a specific term within the example documents .</sentence>
				<definiendum id="0">DF ( Document Frequency )</definiendum>
				<definiens id="0">the frequency of documents having a specific term within the example documents</definiens>
			</definition>
			<definition id="8">
				<sentence>The normalized document frequency , NDF , is defined in equation ( 4 ) , where i DF is the number of documents having term t i in the example documents .</sentence>
				<definiendum id="0">normalized document frequency</definiendum>
				<definiendum id="1">i DF</definiendum>
				<definiens id="0">the number of documents having term t i in the example documents</definiens>
			</definition>
			<definition id="9">
				<sentence>max i i jj DF NDF DF = ( 4 ) The IDF ( Inverse Document Frequency ) represents the inverse document frequency of a specific term over an entire document collection not example documents .</sentence>
				<definiendum id="0">IDF ( Inverse Document Frequency )</definiendum>
				<definiens id="0">the inverse document frequency of a specific term over an entire document collection not example documents</definiens>
			</definition>
			<definition id="10">
				<sentence>The normalized inverse document frequency , NIDF , is defined as follows : , log max i ii jj i IDF N NIDF IDF IDF n == ( 5 ) where , N is the total number of documents and i n is the number of documents containing term t i .</sentence>
				<definiendum id="0">normalized inverse document frequency , NIDF</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">follows : , log max i ii jj i IDF N NIDF IDF IDF n == ( 5 ) where ,</definiens>
			</definition>
			<definition id="11">
				<sentence>The fuzzy output variable , TW ( Term Weight ) which represents the importance of a term , has six linguistic labels as shown in Figure 1 ( b ) .</sentence>
				<definiendum id="0">TW ( Term Weight )</definiendum>
				<definiens id="0">represents the importance of a term</definiens>
			</definition>
			<definition id="12">
				<sentence>1 ) ( log1 1 2 + ∑ − −= = n tfkf RD n j ikjk pik ( 6 ) where , RD ik is the relevance degree between IRKs and candidate term t i in document d k , kf jk is the frequency of initial representative keyword j in document d k , tf ik is the frequency of candidate term t i in document d k , n is the number of IRKs , p is a control parameter .</sentence>
				<definiendum id="0">RD ik</definiendum>
				<definiendum id="1">kf jk</definiendum>
				<definiendum id="2">tf ik</definiendum>
				<definiendum id="3">n</definiendum>
				<definiendum id="4">p</definiendum>
				<definiens id="0">the relevance degree between IRKs and candidate term t i in document d k</definiens>
				<definiens id="1">the frequency of initial representative keyword j in document d k ,</definiens>
				<definiens id="2">the frequency of candidate term t i in document d k</definiens>
				<definiens id="3">a control parameter</definiens>
			</definition>
			<definition id="13">
				<sentence>After calculating the relevance degree of a candidate term , the weight of the term in the set of example documents is determined by the following equation : iikik n k ikikri IDFTFw RDww ×= ∑ ×= =1 ) ( ( 7 ) where , w ri is the weight of term t i in the document set , w ik is the weight of term t i in document d k , TF ik is the frequency of term t i in document d k , IDF i is the inverse document frequency of term t i , and n is the number of example documents .</sentence>
				<definiendum id="0">ik</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the weight of term t i in the document set , w</definiens>
				<definiens id="1">the weight of term t i in document d k</definiens>
				<definiens id="2">the frequency of term t i in document d k</definiens>
			</definition>
			<definition id="14">
				<sentence>×         × += ijj i ki n N freq freq w log max where , freq i is the frequency of initial representative keyword t i , n i is the frequency of documents in which t i appear , and N is the total number of documents .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total number of documents</definiens>
			</definition>
			<definition id="15">
				<sentence>IF , IR , IW : mean that IRKs are selected based on the weight obtained by the method in Section 3.1 , the Rocchio algorithm , and the Widrow-Hoff algorithm , respectively .</sentence>
				<definiendum id="0">IW</definiendum>
				<definiens id="0">mean that IRKs are selected based on the weight obtained by the</definiens>
			</definition>
			<definition id="16">
				<sentence>EC , EF , ER , EW : mean that expanded terms are selected based on the weight obtained by applying the method in Section 3.3 , the method in Section algorithm , respectively .</sentence>
				<definiendum id="0">EW</definiendum>
				<definiens id="0">mean that expanded terms are selected based on the weight obtained by applying the method in Section 3.3 , the method in Section algorithm , respectively</definiens>
			</definition>
</paper>

		<paper id="0208">
			<definition id="0">
				<sentence>Latent semantic analysis ( LSA ) has been used in several intelligent tutoring systems ( ITS’s ) for assessing students’ learning by evaluating their answers to questions in the tutoring domain .</sentence>
				<definiendum id="0">Latent semantic analysis</definiendum>
				<definiendum id="1">LSA</definiendum>
				<definiens id="0">used in several intelligent tutoring systems ( ITS’s ) for assessing students’ learning by evaluating their answers to questions in the tutoring domain</definiens>
			</definition>
			<definition id="1">
				<sentence>We present here an approach called Syntactically Enhanced LSA ( SELSA ) which generalizes LSA by considering a word along with its syntactic neighborhood given by the part-of-speech tag of its preceding word , as a unit of knowledge representation .</sentence>
				<definiendum id="0">LSA ( SELSA )</definiendum>
				<definiens id="0">generalizes LSA by considering a word along with its syntactic neighborhood given by the part-of-speech tag of its preceding word , as a unit of knowledge representation</definiens>
			</definition>
			<definition id="2">
				<sentence>These limitations can be alleviated by using latent semantic analysis ( LSA ) , a recently developed technique for information retrieval ( Deerwester et al. , 1990 ) , knowledge representation ( Landauer et al. , 1998 ) , natural language understanding and cognitive modeling ( Graesser et al. , 1999 ; Graesser et al. , 2000 ) etc .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">a recently developed technique for information retrieval ( Deerwester et al. , 1990 ) , knowledge representation ( Landauer et al. , 1998 ) , natural language understanding and cognitive modeling</definiens>
			</definition>
			<definition id="3">
				<sentence>LSA is a statistical corpus-based natural language understanding technique that supports semantic similarity measurement between texts .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">a statistical corpus-based natural language understanding technique that supports semantic similarity measurement between texts</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus SELSA captures finer resolution of syntactic-semantic information compared to mere semantics of LSA .</sentence>
				<definiendum id="0">SELSA</definiendum>
				<definiens id="0">captures finer resolution of syntactic-semantic information compared to mere semantics of LSA</definiens>
			</definition>
			<definition id="5">
				<sentence>LSA is a statistical-algebraic technique for extracting and inferring contextual usage of words in documents ( Landauer et al. , 1998 ) .</sentence>
				<definiendum id="0">LSA</definiendum>
			</definition>
			<definition id="6">
				<sentence>AutoTutor is a fully automated computer tutor that assists students in learning about hardware , operating systems and the Internet in an introductory computer literacy course .</sentence>
				<definiendum id="0">AutoTutor</definiendum>
				<definiens id="0">a fully automated computer tutor that assists students in learning about hardware , operating systems and the Internet in an introductory computer literacy course</definiens>
			</definition>
			<definition id="7">
				<sentence>LSA is a major component of the mechanism that evaluates the quality of student contributions in the tutorial dialog .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">a major component of the mechanism that evaluates the quality of student contributions in the tutorial dialog</definiens>
			</definition>
			<definition id="8">
				<sentence>Apex ( Dessus et al. , 2000 ) is a web-based learning environment which manages student productions , assessments and courses .</sentence>
				<definiendum id="0">Apex</definiendum>
				<definiens id="0">a web-based learning environment which manages student productions , assessments and courses</definiens>
			</definition>
			<definition id="9">
				<sentence>Thus SELSA ( LSA ) would evaluate the answers in the following manner .</sentence>
				<definiendum id="0">SELSA</definiendum>
				<definiens id="0">evaluate the answers in the following manner</definiens>
			</definition>
			<definition id="10">
				<sentence>R minMAD maxCorrect minFalse 200 0.2449 125 31 250 0.2412 125 30 300 0.2422 126 30 350 0.2484 125 31 400 0.2504 124 32 Table 3 : SELSA MAD , correct and false evaluation R minMAD maxCorrect minFalse 200 0.2497 122 29 250 0.2523 120 31 300 0.2555 121 32 350 0.2525 122 32 400 0.2475 123 30 Table 4 : LSA MAD , correct and false evaluation We define an evaluationli by SELSA ( LSA ) to be correct or false as below : li CORRECT if jli hij &lt; CT li FALSE if jli hij &gt; FT where CT and FT are correctness and falsehood thresholds which were set to 0.05 and 0.95 respectively for strict measures .</sentence>
				<definiendum id="0">SELSA MAD</definiendum>
				<definiendum id="1">LSA MAD</definiendum>
				<definiendum id="2">CORRECT</definiendum>
				<definiens id="0">if jli hij &lt; CT li FALSE if jli hij &gt; FT where CT and FT are correctness and falsehood thresholds which were set to 0.05 and 0.95 respectively for strict measures</definiens>
			</definition>
			<definition id="11">
				<sentence>It is also found that SELSA uses the syntactic information to expand the document similarity measure i.e. , mere semantically similar documents are placed wider apart than syntactic-semantically similar documents in SELSA space .</sentence>
				<definiendum id="0">SELSA</definiendum>
				<definiens id="0">uses the syntactic information to expand the document similarity measure i.e. , mere semantically similar documents are placed wider apart than syntactic-semantically similar documents in SELSA space</definiens>
			</definition>
</paper>

		<paper id="0410">
			<definition id="0">
				<sentence>Thus , the problem of dimensionality reduction is a key issue to be addressed in verb class discovery .</sentence>
				<definiendum id="0">dimensionality reduction</definiendum>
				<definiens id="0">a key issue to be addressed in verb class discovery</definiens>
			</definition>
			<definition id="1">
				<sentence>The Animacy Features ( 76 features ) Semantic properties of the arguments that fill certain roles , such as animacy or motion , are more challenging to detect automatically .</sentence>
				<definiendum id="0">Animacy Features</definiendum>
				<definiens id="0">76 features ) Semantic properties of the arguments that fill certain roles</definiens>
			</definition>
			<definition id="2">
				<sentence>All features were estimated from counts over the British National Corpus ( BNC ) , a 100M word corpus of text samples of recent British English ranging over a wide spectrum of domains .</sentence>
				<definiendum id="0">National Corpus</definiendum>
				<definiens id="0">estimated from counts over the British</definiens>
			</definition>
			<definition id="3">
				<sentence>We chose hierarchical clustering because it may be possible to find coherent subclusters of verbs even when there are not exactly a0 good clusters , where a0 is the number of classes .</sentence>
				<definiendum id="0">a0</definiendum>
				<definiens id="0">the number of classes</definiens>
			</definition>
			<definition id="4">
				<sentence>Full is full feature set ; Ling is manually selected subset ; Seed is seed-verb-selected set .</sentence>
				<definiendum id="0">Full</definiendum>
				<definiendum id="1">Seed</definiendum>
				<definiens id="0">full feature set</definiens>
				<definiens id="1">seed-verb-selected set</definiens>
			</definition>
			<definition id="5">
				<sentence>More importantly , the Seed set shows a mean overall reduction in error rate ( over Base a22a26a23a13a23 ) of 28 % , compared to 17 % for the Ling set .</sentence>
				<definiendum id="0">Seed set</definiendum>
				<definiens id="0">shows a mean overall reduction in error rate ( over Base a22a26a23a13a23 ) of 28 % , compared to 17 % for the Ling set</definiens>
			</definition>
</paper>

		<paper id="0313">
			<definition id="0">
				<sentence>Translation spotting ( TS ) takes as input a couple , i.e. a pair of SL and TL text segments , which are known to be translations of one another , and a SL query , i.e. a subset of the tokens of the SL segment , on which the TS will focus its attention .</sentence>
				<definiendum id="0">Translation spotting</definiendum>
				<definiens id="0">a pair of SL and TL text segments</definiens>
			</definition>
			<definition id="1">
				<sentence>The result of the TS process consists of two sets of tokens , i.e. one for each language .</sentence>
				<definiendum id="0">TS process</definiendum>
				<definiens id="0">consists of two sets of tokens</definiens>
			</definition>
			<definition id="2">
				<sentence>This process ( translation spotting ) can be viewed as a by-product of wordalignment , i.e. the problem of establishing correspondences between the words of a text and those of its translation : obviously , given a complete alignment between the words of the SL and TL texts , we can extract only that part of the alignment that concerns the TS query ; conversely , TS may be seen as a sub-task of the wordalignment problem : a complete word-alignment can be obtained by combining the results of a series of TS operations , covering the entirety of the SL text .</sentence>
				<definiendum id="0">translation spotting</definiendum>
				<definiendum id="1">TL</definiendum>
				<definiens id="0">a by-product of wordalignment</definiens>
			</definition>
			<definition id="3">
				<sentence>Brown et al. also define the Viterbi alignment between source and target sentences S and T as the alignment ˆa whose probability is maximal under some translation model : ˆa = argmaxa∈APrM ( a|S , T ) where A is the set of all possible alignments between S and T , and PrM ( a|S , T ) is the estimate of a’s probability under model M , which we denote Pr ( a|S , T ) from hereon .</sentence>
				<definiendum id="0">Viterbi alignment</definiendum>
				<definiendum id="1">PrM ( a|S , T )</definiendum>
				<definiens id="0">between source and target sentences S and T as the alignment ˆa whose probability is maximal under some translation model : ˆa = argmaxa∈APrM ( a|S , T ) where A is the set of all possible alignments between S and T</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , we can formulate a variant of the Viterbi TS method above , which looks for the alignment that maximizes Pr ( a|S , T ) , under the constraint that the TL tokens aligned with the SL query must be contiguous .</sentence>
				<definiendum id="0">T )</definiendum>
				<definiens id="0">looks for the alignment that maximizes Pr ( a|S ,</definiens>
			</definition>
			<definition id="5">
				<sentence>Consider a procedure that seeks the ( possibly null ) sequence tj1 ... tj2 of T , that maximizes : Pr ( aq|si2i1 , tj2j1 ) Pr ( a¯q|si1−11 smi2+1 , tj1−11 tnj2+1 ) Such a procedure actually produces two distinct alignments over S and T : an alignment aq , which connects the query tokens ( the sequence si2i1 ) with a sequence of contiguous tokens in T ( the sequence tj2j1 ) , and an alignment a¯q , which connects the rest of sentence S ( i.e. all the tokens outside the query ) with the rest of T. Together , these two alignments constitute the alignment a = aq ∪ a¯q , whose probability is maximal , under a double constraint : within a contiguous region of T ( the sequences tj2j1 ) ; sequences si1−11 and smi2+1 ) can only get connected to tokens outside tj2j1 .</sentence>
				<definiendum id="0">query tokens</definiendum>
				<definiens id="0">a procedure actually produces two distinct alignments over S and T : an alignment aq</definiens>
			</definition>
			<definition id="6">
				<sentence>Consider a procedure that splits each the source and target sentences S and T into two independent parts , in such a way as to maximise the probability of the two resulting Viterbi alignments : argmax〈i , j , d〉    d = 1 : Pr ( a1|si1 , tj1 ) ×Pr ( a2|smi+1 , tnj+1 ) d = −1 : Pr ( a1|si1 , tnj+1 ) ×Pr ( a2|smi+1 , tj1 ) In the triple 〈i , j , d〉 above , i represents a “split point” in the SL sentence S , j is the analog for TL sentence T , and d is the “direction of correspondence” : d = 1 denotes a “parallel correspondence” , i.e. s1 ... si corresponds to t1 ... tj and si+1 ... sm corresponds to tj+1 ... tn ; d = −1 denotes a “crossing correspondence” , i.e. s1 ... si corresponds to tj+1 ... tn and si+1 ... sm corresponds to t1 ... tj .</sentence>
				<definiendum id="0">d</definiendum>
				<definiens id="0">splits each the source and target sentences S and T into two independent parts , in such a way as to maximise the probability of the two resulting Viterbi alignments : argmax〈i , j</definiens>
				<definiens id="1">a “split point” in the SL sentence S , j is the analog for TL sentence T , and</definiens>
				<definiens id="2">a “parallel correspondence”</definiens>
			</definition>
			<definition id="7">
				<sentence>We then submitted the same sentence-pairs and SL queries to each of the proposed TS methods , and measured how the TL answers produced automatically compared with those produced manually .</sentence>
				<definiendum id="0">SL queries</definiendum>
				<definiens id="0">to each of the proposed TS methods , and measured how the TL answers produced automatically compared with those produced manually</definiens>
			</definition>
			<definition id="8">
				<sentence>The Expansion post-processing , which finds the shortest possible sequence that covers all the tokens of the Viterbi TL answer , solves the problem in simple situations such as the one in the above example .</sentence>
				<definiendum id="0">Expansion post-processing</definiendum>
				<definiens id="0">finds the shortest possible sequence that covers all the tokens of the Viterbi TL answer</definiens>
			</definition>
</paper>

		<paper id="0209">
			<definition id="0">
				<sentence>The Intelligent Essay Assessor ( IEA ) uses latent semantic analysis in calculating its metrics ( Landauer et al. , 2003 ) .</sentence>
				<definiendum id="0">Intelligent Essay Assessor</definiendum>
			</definition>
			<definition id="1">
				<sentence>A link is a targeted relationship between two words and has two parts : a left side and a right side .</sentence>
				<definiendum id="0">link</definiendum>
				<definiens id="0">a targeted relationship between two words and has two parts : a left side and a right side</definiens>
			</definition>
			<definition id="2">
				<sentence>The LG parser as distributed was not completely suited to handle the grading of ESL students’ essays , so some modifications had to be made .</sentence>
				<definiendum id="0">LG parser</definiendum>
				<definiendum id="1">ESL students’</definiendum>
			</definition>
			<definition id="3">
				<sentence>We used ESL essays written by Intensive EnLinkage 1 , cost vector = ( UNUSED=4 DIS=0 AND=0 LEN=11 ) + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Xp -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -+ + -- -- -Wd -- -- -+ | | +-D*u-+ -- -- -- -- -- -- Ss -- -- -- -- -- -+ -- -Ost -- + | ||| | | LEFT-WALL the class .</sentence>
				<definiendum id="0">ESL</definiendum>
				<definiens id="0">essays written by Intensive EnLinkage 1 , cost vector = ( UNUSED=4 DIS=0 AND=0 LEN=11 ) + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Xp -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -+ + -- -- -Wd -- -- -+ | | +-D*u-+ -- -- -- -- -- -- Ss -- -- -- -- -- -+ -- -Ost -- + | ||| | | LEFT-WALL the class</definiens>
			</definition>
</paper>

		<paper id="0200">
</paper>

		<paper id="1104">
			<definition id="0">
				<sentence>To do this , we introduce , as the major vector space , the differential LSI ( or DLSI ) space which is formed from the differences between normalized intraand extradocument vectors and normalized centroid vectors of clusters where the intraand extra-document refers to the documents included within or outside of the given cluster respectively .</sentence>
				<definiendum id="0">LSI</definiendum>
				<definiens id="0">the documents included within or outside of the given cluster respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>An example will be given below : a29 a25 a17a35a27a37a36a16a38a24a33 a14a7a39a21a40a42a41a35a25 a17a43a23 and a33 a25 a27 a39a8a44 a39 a45a47a46a49a48a51a50 a52 a53 a17a2a54a55a1a57a56 a25 a17a10a36a16a38a24a33 a14 a56 a25 a17a24a23a58a3 where a56 a25 a17a35a27a60a59a62a61a63 a64 a61 , a65a19a25 is the total number of times that term a0a25 appears in the collection , a41a66a25a17 the number of times the term a0a25 appears in the document a13 , and a50 the number of documents in the collection .</sentence>
				<definiendum id="0">a65a19a25</definiendum>
				<definiens id="0">the total number of times that term a0a25 appears in the collection</definiens>
			</definition>
			<definition id="2">
				<sentence>The document vector a14a16a15 a1a18a17 a3a15 a6a20a17 a3a4a9a4a9a4a9a21a3a15 a11a22a17 a23 can be normalized as a14a68a67 a1a18a17a69a3a67a6a20a17a49a3a4a9a4a9a4a9a10a3a67a11a70a17a43a23 by the following formula : a67a71a25 a17a35a27 a15a69a25 a17a24a72a74a73a75 a75 a76 a11 a53 a77 a54a55a1 a15 a6 a77 a17a8a78 ( 1 ) The normalized centroid vector a79 a27 a14a16a80 a1 a3 a80 a6 a3a4a9a4a9a4a9a21a3 a80 a11 a23 of a cluster can be calculated in terms of the normalized vector as a80a2a25 a27 a81 a25 a72a83a82 a84 a11 a17a2a54a55a1 a81 a6 a25 , where a14a81a19a1a4a3a71a81a24a6a43a3a4a9a4a9a4a9a21a3a71a81a21a11a66a23a86a85 is a mean vector of the member documents in the cluster which are normalized as a0 a1a10a3a0 a6a8a3a4a9a4a9a4a9a10a3a0 a77 ; i.e. , a14 a81a19a1a57a3a71a81a24a6a8a3a4a9a4a9a4a9a10a3a71a81a21a11a66a23a85 a27 a1 a77 a84 a77 a17a2a54a55a1 a0 a17 .</sentence>
				<definiendum id="0">a14a81a19a1a4a3a71a81a24a6a43a3a4a9a4a9a4a9a21a3a71a81a21a11a66a23a86a85</definiendum>
				<definiens id="0">a mean vector of the member documents in the cluster which are normalized as a0 a1a10a3a0 a6a8a3a4a9a4a9a4a9a10a3a0 a77</definiens>
			</definition>
			<definition id="3">
				<sentence>A differential document vector is defined as a0a55a25 a44 a0 a17 where a0 a25 and a0 a17 are normalized document vectors satisfying some criteria as given above .</sentence>
				<definiendum id="0">differential document vector</definiendum>
				<definiens id="0">a0a55a25 a44 a0 a17 where a0 a25 and a0 a17 are normalized document vectors satisfying some criteria as given above</definiens>
			</definition>
			<definition id="4">
				<sentence>A differential intra-document vector a1a3a2 is the differential document vector defined as a0 a25 a44a4a0 a17 , where a0 a25 and a0 a17 are two normalized document vectors of same cluster .</sentence>
				<definiendum id="0">differential intra-document vector a1a3a2</definiendum>
				<definiens id="0">the differential document vector defined as a0 a25 a44a4a0 a17 , where a0 a25 and a0 a17 are two normalized document vectors of same cluster</definiens>
			</definition>
			<definition id="5">
				<sentence>A differential extra-document vector a1a6a5 is the differential document vector defined as a0 a25 a44a7a0 a17 , where a0 a25 and a0 a17 are two normalized document vectors of different clusters .</sentence>
				<definiendum id="0">differential extra-document vector a1a6a5</definiendum>
				<definiens id="0">the differential document vector defined as a0 a25 a44a7a0 a17 , where a0 a25 and a0 a17 are two normalized document vectors of different clusters</definiens>
			</definition>
			<definition id="6">
				<sentence>Noting that the mean a47 a48 of the differential intra ( extra- ) document vectors are approximately a33 , we may assume that the differential vectors formed follows a high-dimensional Gaussian distribution so that the likelihood of any differential vector a48 will be given by a49 a14 a48a51a50 a1 a23 a27a53a52a30a54a56a55 a57 a44 a1 a6 a65a62a14 a48 a23a59a58 a14a28a60a46a61 a23a63a62a46a64 a6 a50a66a65a67a50 a1 a64 a6 a3 where a65a62a14a48 a23 a27 a48 a85 a65a69a68 a1 a48 , and a65 is the covariance of the distribution computed from the training set expressed a65 a27 a1 a62 a1a3a1 a85 .</sentence>
				<definiendum id="0">a65</definiendum>
				<definiens id="0">a23 a27a53a52a30a54a56a55 a57 a44 a1 a6 a65a62a14 a48 a23a59a58 a14a28a60a46a61 a23a63a62a46a64 a6 a50a66a65a67a50 a1 a64 a6 a3 where a65a62a14a48 a23 a27 a48 a85 a65a69a68 a1 a48 , and</definiens>
			</definition>
			<definition id="7">
				<sentence>Thus , the likelihood function a49 a14 a48a86a50 a1 a23 could be estimated by a78 a49 a14 a48a86a50 a1 a23 a27 a50 a1 a64 a6 a52a30a54a87a55a89a88 a44 a62 a6 a84 a77 a25 a54a55a1a51a90a30a91a61 a92 a91a61a87a93 a9 a52a30a54a56a55a3a94 a44 a62a46a95 a91a97a96a99a98a101a100a6a103a102a105a104 a14a28a60a46a61 a23a62a43a64 a6a74a106 a77 a25 a54a55a1 a27a2a25 a9 a79 a96 a76 a68 a77 a100 a64 a6 a3 ( 2 ) where a72 a27a107a21 a85a77 a48 , a108 a6 a14 a48 a23 a27 a50a85a50a48a86a50a85a50 a6 a44 a84 a77 a25 a54a55a1 a72 a6 a25 , a79 a27a1 a76 a68 a77 a84a77a76 a25 a54 a77a42a80 a1 a27 a6 a25 , and a10 is the rank of matrix a1 .</sentence>
				<definiendum id="0">a10</definiendum>
				<definiens id="0">estimated by a78 a49 a14 a48a86a50 a1 a23 a27 a50 a1 a64 a6 a52a30a54a87a55a89a88 a44 a62 a6 a84 a77 a25 a54a55a1a51a90a30a91a61 a92 a91a61a87a93 a9 a52a30a54a56a55a3a94 a44 a62a46a95 a91a97a96a99a98a101a100a6a103a102a105a104 a14a28a60a46a61 a23a62a43a64 a6a74a106 a77 a25 a54a55a1 a27a2a25 a9 a79 a96 a76 a68 a77 a100 a64 a6 a3 ( 2 ) where a72 a27a107a21 a85a77 a48 , a108 a6 a14 a48 a23 a27 a50a85a50a48a86a50a85a50 a6 a44 a84 a77 a25 a54a55a1 a72 a6 a25 , a79 a27a1 a76 a68 a77 a84a77a76 a25 a54 a77a42a80 a1 a27 a6 a25 , and</definiens>
			</definition>
			<definition id="8">
				<sentence>When both a49 a14a48a51a50a1 a2 a23 and a49 a14a48a86a50a1a8a5 a23 are computed , the Baysian posteriori function can be computed as : a49 a14a71a1 a2 a50a48 a23a51a27 a49 a14 a48a86a50 a1 a2 a23a49 a14a71a1 a2 a23 a49 a14 a48a51a50 a1a8a2 a23a49 a14a71a1a8a2 a23 a40 a49 a14 a48a86a50 a1 a5 a23a49 a14a71a1 a5 a23 a3 where a49 a14a71a1 a2 a23 is set to a39 a72 a50a1a0 where a50a1a0 is the number of clusters in the database 1 while a49 a14a71a1 a5 a23 is set to a39 a44 a49 a14a71a1a8a2 a23 .</sentence>
				<definiendum id="0">Baysian posteriori function</definiendum>
				<definiendum id="1">a50a1a0</definiendum>
			</definition>
			<definition id="9">
				<sentence>differential document vector a48 a27 a27a28a44 a79 , where a79 is the normalized vector giving the center or centroid of the cluster .</sentence>
				<definiendum id="0">a79</definiendum>
				<definiens id="0">the normalized vector giving the center or centroid of the cluster</definiens>
			</definition>
			<definition id="10">
				<sentence>The document vector for the new document a27 is given by : a14a71a33 a3 a33 a3 a33 a3 a33 a3 a39 a3 a33 a3 a33 a3 a39 a3 a33 a3 a33 a3 a33 a3 a33 a3 a33 a3 a33 a3 a39 a3 a33 a3 a33 a3 a33 a23a85 , and in normalized form by a14a71a33 a3 a33 a3 a33 a3 a33 a3 a33 a78a14a13a16a15a17a15 a44 a13 a33 a60a16a18a17a19 a3 a33 a3 a33 a3 a33 a78a14a13a20a15a17a15 a44 a13 a33 a60a16a18a17a19 a3 a33 a3 a33 a3 a33 a3 a33 a3 a33 a3 a33 a3 a33 a78a14a13a16a15a17a15 a44 a13 a33 a60a17a18a17a19 a3 a33 a3 a33 a3 a33 a23a86a85 .</sentence>
				<definiendum id="0">document vector</definiendum>
			</definition>
</paper>

		<paper id="1112">
			<definition id="0">
				<sentence>Distribution of attributes for concepts in an equivalence class ( α-relation ) attributes concepts De finition Polic y Pa y C ons ul ta tio n case Pr oble m s K i nds Pur pos e Cu rren t situa tion R e gula tions Me rits Ca lc ula tion m e thods Ne gotia tion # a ttr ib u t es Incentives O O O O O O O O O O 10 Hourly wage O O O O O O 6 Basic salary O O O O 4 Service allowance O O O O O O O O 8 Ability allowance O O O O O O O 7 Bonus OOOO OO OO8 Our knowledge base consists of three parts : a concept network , attributes associated with each concept , and answer set belonging to each &lt; concept , attribute &gt; pair .</sentence>
				<definiendum id="0">Distribution of attributes</definiendum>
				<definiendum id="1">knowledge base</definiendum>
				<definiens id="0">for concepts in an equivalence class ( α-relation ) attributes concepts De finition Polic y Pa y C ons ul ta tio n case Pr oble m s K i nds Pur pos e Cu rren t situa tion R e gula tions Me rits Ca lc ula tion m e thods Ne gotia tion # a ttr ib</definiens>
				<definiens id="1">consists of three parts : a concept network , attributes associated with each concept , and answer set belonging to each &lt; concept , attribute &gt; pair</definiens>
			</definition>
			<definition id="1">
				<sentence>of the 25th annual international ACM SIGIR 2002 2nd workshop on Operational Text Classification , Tampere , Finland , 2002 Christiane Fellbaum , WordNet : An Electronic Lexical Database , The MIT press , 1998 Ricardo Baeza-Yates , Berthier Ribeiro-Neto , Modern Information Retrieval , Yiming Yang and Xin Liu , A Re-examination Of Text Categorization Methods , pp .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An Electronic Lexical Database</definiens>
			</definition>
</paper>

		<paper id="1122">
</paper>

		<paper id="1311">
			<definition id="0">
				<sentence>Healthcare-associated pneumonia is an infection that is acquired during hospitalization , or in emergency departments and outpatient clinics , and it is neither present nor incubated at the time of admission .</sentence>
				<definiendum id="0">Healthcare-associated pneumonia</definiendum>
			</definition>
			<definition id="1">
				<sentence>The National Electronic Disease Surveillance System ( NEDSS ) focuses on standards and the response to biothreats .</sentence>
				<definiendum id="0">National Electronic Disease Surveillance System</definiendum>
				<definiendum id="1">NEDSS )</definiendum>
				<definiens id="0">focuses on standards and the response to biothreats</definiens>
			</definition>
			<definition id="2">
				<sentence>The structured output consists of primary units of clinical information ( i.e. findings , procedures , and medications ) , along with corresponding modifiers ( e.g. body locations , degree , certainty ) .</sentence>
				<definiendum id="0">structured output</definiendum>
				<definiens id="0">consists of primary units of clinical information ( i.e. findings , procedures , and medications ) , along with corresponding modifiers ( e.g. body locations , degree , certainty )</definiens>
			</definition>
			<definition id="3">
				<sentence>Currently , MedLEE attempts to find a complete parse and only resorts to partial parsing when a full parse can not be obtained .</sentence>
				<definiendum id="0">MedLEE</definiendum>
				<definiens id="0">attempts to find a complete parse and only resorts to partial parsing when a full parse can not be obtained</definiens>
			</definition>
			<definition id="4">
				<sentence>In a study we used the UMLS ( Unified Medical Language System ) ( Lindberg , Humphreys , and McCray , 1993 ) , a controlled vocabulary developed and maintained by the National Library of Medicine , to automatically generate a lexicon .</sentence>
				<definiendum id="0">UMLS</definiendum>
				<definiens id="0">a controlled vocabulary developed and maintained by the National Library of Medicine , to automatically generate a lexicon</definiens>
			</definition>
			<definition id="5">
				<sentence>In chest radiographs of neonates , BPD generally denotes broncopulmonary dysplasia , a condition that predisposes the patient to respiratory infection .</sentence>
				<definiendum id="0">BPD</definiendum>
				<definiens id="0">broncopulmonary dysplasia , a condition that predisposes the patient to respiratory infection</definiens>
			</definition>
			<definition id="6">
				<sentence>The CDC NNIS definition for healthcare-associated pneumonia is a 2-page written protocol with two different criteria .</sentence>
				<definiendum id="0">CDC NNIS definition for healthcare-associated pneumonia</definiendum>
				<definiens id="0">a 2-page written protocol with two different criteria</definiens>
			</definition>
</paper>

		<paper id="0111">
			<definition id="0">
				<sentence>Additional attributes can be added to simplify processing : ‘key’ provides an alternative identifier for the object being named , such as a database record key , while ‘reg’ can provide a regularized form of the name used so part of the earlier excerpt from Fiennes becomes : Thence 6 miles to &lt; placeName reg=”Blandford Forum” &gt; Blandford &lt; /placeName &gt; , thence 18 to &lt; placeName reg=”Salisbury” &gt; Salsebury &lt; /placeName &gt; .</sentence>
				<definiendum id="0">Additional attributes</definiendum>
				<definiens id="0">‘key’ provides an alternative identifier for the object being named</definiens>
			</definition>
</paper>

		<paper id="1303">
			<definition id="0">
				<sentence>CPs consist of the syntactic categories and other grammatical and lexical information ( e.g. PREP NP V : stimulate ) .</sentence>
				<definiendum id="0">CPs</definiendum>
			</definition>
			<definition id="1">
				<sentence>each class c i , j from the set C i according to the following formula : ) , ( ) 1 ( ) , ( , , , jijiji ctExapactC ⋅−+⋅= ( 1 ) where a ( 0 ≤ a ≤ 1 ) is a parameter , which balances the impact of the class probabilities and the similarity measure .</sentence>
				<definiendum id="0">class c i</definiendum>
				<definiens id="0">a parameter , which balances the impact of the class probabilities and the similarity measure</definiens>
			</definition>
			<definition id="2">
				<sentence>We used an ontology , which is a part of the UMLS ( Unified Medical Language System ) knowledge sources ( UMLS , 2002 ) .</sentence>
				<definiendum id="0">ontology</definiendum>
				<definiens id="0">a part of the UMLS ( Unified Medical Language System ) knowledge sources</definiens>
			</definition>
</paper>

		<paper id="1813">
			<definition id="0">
				<sentence>As well as in the case of other multiword expressions ( MWEs ) , the question arises of how they should be analyzed to make them suitable for machine processing.1 In this paper , we will propose an HPSG-based linguistically motivated , formal treatment of CPs , applicable for computational platforms intended for developing typed feature structure grammars .</sentence>
				<definiendum id="0">MWEs</definiendum>
				<definiens id="0">HPSG-based linguistically motivated , formal treatment of CPs , applicable for computational platforms intended for developing typed feature structure grammars</definiens>
			</definition>
			<definition id="1">
				<sentence>6TRALE is a platform for implementing HPSG-style grammars that was created within the framework of the B8 project Ein HPSG-Syntaxfragment für das Deutsche : Sprachtheoretische Grundlagen und Computerlinguistische Implementierung and Domain Specific Processing of Constraint-Based Grammars of the SFB 340 Sprachtheoretische Grundlagen für die Computerlinguistik under direction of Gerald Penn and has been still developed within the framework of the MiLCAConsortium at the Seminar für Sprachwissenschaft in Tübingen .</sentence>
				<definiendum id="0">6TRALE</definiendum>
				<definiens id="0">a platform for implementing HPSG-style grammars that was created within the framework of the B8 project Ein HPSG-Syntaxfragment für das Deutsche : Sprachtheoretische Grundlagen und Computerlinguistische Implementierung and Domain Specific Processing of Constraint-Based Grammars of the SFB</definiens>
			</definition>
</paper>

		<paper id="0305">
			<definition id="0">
				<sentence>This iterative procedure updates the current estimate a4a9a31a33a32a35a34a36a38a37 of the EAF of source word a39 with target word a40 , using the following two-stage equations : a41a29a42a44a43a46a45 a47a7a48 a49 a50 a51 a52 a53 a45 a42 a49 a45 a50 a48a55a54 a53 a41a29a42a44a43a46a56a19a47a57a45a58a57a48 a49 a50 a59 a60 a49 a41 a42a44a43a46a56a61a47a57a45 a58a57a48 a49 ( 1 ) a41 a42a44a43a46a45 a58a57a48 a49 a50 a51 a52 a53 a45 a42 a49 a45 a50 a48a55a54 a53 a41 a42a44a43a46a45 a47a7a48 a49 a50 a59 a60 a50 a41a62a42a38a43a46a45 a47a7a48 a63 a50 ( 2 ) where a4 a36a20a64 and a4 a64a37 are the current estimates of the row and column marginals , a65 is a pair of aligned sentences containing words a39 and a40 , and a65 a36 and a65 a37 are the observed frequencies of words a39 and a40 in a65 .</sentence>
				<definiendum id="0">iterative procedure</definiendum>
				<definiendum id="1">a65</definiendum>
				<definiens id="0">updates the current estimate a4a9a31a33a32a35a34a36a38a37 of the EAF of source word a39 with target word a40 , using the following two-stage equations : a41a29a42a44a43a46a45 a47a7a48 a49 a50 a51 a52 a53 a45 a42 a49 a45 a50 a48a55a54 a53 a41a29a42a44a43a46a56a19a47a57a45a58a57a48 a49 a50 a59 a60 a49 a41 a42a44a43a46a56a61a47a57a45 a58a57a48 a49 ( 1 ) a41 a42a44a43a46a45 a58a57a48 a49 a50 a51 a52 a53 a45 a42 a49 a45 a50 a48a55a54 a53 a41 a42a44a43a46a45 a47a7a48 a49 a50 a59 a60 a50 a41a62a42a38a43a46a45 a47a7a48 a63 a50 ( 2 ) where a4 a36a20a64 and a4 a64a37 are the current estimates of the row and column marginals</definiens>
				<definiens id="1">a pair of aligned sentences containing words a39 and a40 , and a65 a36 and a65 a37 are the observed frequencies of words a39 and a40 in a65</definiens>
			</definition>
			<definition id="1">
				<sentence>Table 1 shows the results.1 1In the table , AER stands for Average Error Rate without null-aligned words , and AERn was calculated with null-aligned words .</sentence>
				<definiendum id="0">AER</definiendum>
				<definiens id="0">stands for Average Error Rate without null-aligned words</definiens>
			</definition>
</paper>

		<paper id="0601">
			<definition id="0">
				<sentence>To be consistent with the more general models referenced above , we index the nodes by “levels” , l. Given a region ( “blob” ) , b , and a word w , we have † P ( w | b ) = P ( w |l ) P ( b |l ) P ( l ) P ( b ) l Â ( 1 ) where P ( l ) is the level prior , P ( w|l ) is a frequency table , and P ( b|l ) is a Gaussian over features .</sentence>
				<definiendum id="0">P ( w|l )</definiendum>
				<definiendum id="1">P ( b|l )</definiendum>
				<definiens id="0">a frequency table</definiens>
				<definiens id="1">a Gaussian over features</definiens>
			</definition>
</paper>

		<paper id="0810">
			<definition id="0">
				<sentence>UIMA is a software architecture for developing applications which integrate search and analytics over a combination of structured and unstructured information .</sentence>
				<definiendum id="0">UIMA</definiendum>
				<definiens id="0">a software architecture for developing applications which integrate search and analytics over a combination of structured and unstructured information</definiens>
			</definition>
			<definition id="1">
				<sentence>In UIMA , a TAE is a recursive structure which may be composed of sub or component engines each performing a different stage of the application’s analysis .</sentence>
				<definiendum id="0">TAE</definiendum>
				<definiens id="0">a recursive structure which may be composed of sub or component engines each performing a different stage of the application’s analysis</definiens>
			</definition>
			<definition id="2">
				<sentence>Application Logic Semantic Search Engine Document , Collection &amp; Meta-data Store ( Text ) Analysis Engines ( TAEs ) Structured Knowledge Access Query key words and concepts Token and concept Indexing Knowledge Source Adapters ( KSAs ) integrate and deliver content from many structured knowledge sources according to central ontologies Collection Processing Manager ( CPM ) Structured Information Unstructured Information Analysis engines employing a variety of analytical techniques and strategies for detecting semantic content Relevant Knowledge Collection Analysis Engine ( s ) Figure 1 : UIMA High-Level Architecture Examples of Text Analysis Engines include language translators , document summarizers , document classifiers , and named-entity detectors .</sentence>
				<definiendum id="0">Application Logic</definiendum>
				<definiens id="0">TAEs ) Structured Knowledge Access Query key words and concepts Token and concept Indexing Knowledge Source Adapters ( KSAs ) integrate and deliver content from many structured knowledge sources according to central ontologies Collection Processing Manager ( CPM ) Structured Information Unstructured Information Analysis engines employing a variety of analytical techniques and strategies for detecting semantic content Relevant Knowledge Collection Analysis Engine ( s ) Figure 1 : UIMA High-Level Architecture Examples of Text Analysis Engines include language translators , document summarizers , document classifiers , and named-entity detectors</definiens>
			</definition>
			<definition id="3">
				<sentence>A TAE takes in a document and produces an analysis .</sentence>
				<definiendum id="0">TAE</definiendum>
				<definiens id="0">takes in a document and produces an analysis</definiens>
			</definition>
			<definition id="4">
				<sentence>UIMA implementations include a document , collection and meta-data store that implements the Collection Reader interface and manages multiple collections and their elements .</sentence>
				<definiendum id="0">UIMA implementations</definiendum>
			</definition>
			<definition id="5">
				<sentence>In support of Collection Analysis Engines , UIMA defines the Collection Processing Manager ( CPM ) component .</sentence>
				<definiendum id="0">UIMA</definiendum>
			</definition>
			<definition id="6">
				<sentence>The CPM applies the TAE and returns the analysis , represented by a CAS , for each element in the collection .</sentence>
				<definiendum id="0">CPM</definiendum>
				<definiens id="0">applies the TAE and returns the analysis</definiens>
			</definition>
			<definition id="7">
				<sentence>UIMA specifies an interface for an analysis engine ; roughly speaking it is “CAS in” and “CAS out” .</sentence>
				<definiendum id="0">UIMA</definiendum>
				<definiens id="0">specifies an interface for an analysis engine</definiens>
			</definition>
			<definition id="8">
				<sentence>The Analysis Sequencer is a pluggable range from provide simple iteration over a declaratively specified static flow to complex planning algorithms .</sentence>
				<definiendum id="0">Analysis Sequencer</definiendum>
				<definiens id="0">a pluggable range from provide simple iteration over a declaratively specified static flow to complex planning algorithms</definiens>
			</definition>
			<definition id="9">
				<sentence>The CAS contains the original document ( the subject of analysis ) plus the meta-data contributed by any analysis engines that have run previously .</sentence>
				<definiendum id="0">CAS</definiendum>
				<definiens id="0">the subject of analysis ) plus the meta-data contributed by any analysis engines that have run previously</definiens>
			</definition>
			<definition id="10">
				<sentence>The analysis engine deployer decides how analysis engines and the resources they require are deployed on particular hardware and system middleware .</sentence>
				<definiendum id="0">analysis engine deployer</definiendum>
				<definiens id="0">decides how analysis engines and the resources they require are deployed on particular hardware and system middleware</definiens>
			</definition>
			<definition id="11">
				<sentence>The Analysis Structure Broker is the component that transports the CAS between these components regardless of how they are deployed .</sentence>
				<definiendum id="0">Analysis Structure Broker</definiendum>
				<definiens id="0">the component that transports the CAS between these components regardless of how they are deployed</definiens>
			</definition>
			<definition id="12">
				<sentence>IBM develops a variety of information management , information integration , data mining , knowledge management and search-related products and services .</sentence>
				<definiendum id="0">IBM</definiendum>
				<definiens id="0">develops a variety of information management , information integration , data mining</definiens>
			</definition>
			<definition id="13">
				<sentence>The UIMA project at IBM has encouraged many groups in six of the Research division’s labs to understand and adopt the UIMA architecture as a common conceptual foundation for classifying , describing , developing and combining HLT components in aggregate applications that integrate search and analytical functions .</sentence>
				<definiendum id="0">UIMA architecture</definiendum>
				<definiens id="0">encouraged many groups in six of the Research division’s labs to understand</definiens>
			</definition>
</paper>

		<paper id="1730">
</paper>

		<paper id="1109">
			<definition id="0">
				<sentence>Thus , what deserves more attention is Cross-Language Information Access ( CLIA ) , which subsumes CLIR and provides useful information to the user in source language ( e.g. ( Frederking et al. , 1997 ) ) .</sentence>
				<definiendum id="0">Cross-Language Information Access</definiendum>
				<definiens id="0">subsumes CLIR and provides useful information to the user in source language ( e.g. ( Frederking et al. , 1997 ) )</definiens>
			</definition>
			<definition id="1">
				<sentence>This paper describes two new features of the BRIDJE ( Bi-directional Retriever/Information Distiller for Japanese and English ) system ( Sakai et al. , 2002a ; Sakai et al. , 2002b ; Sakai et al. , 2003 ) which integrates machine translation ( MT ) with information retrieval ( IR ) to support both English-Japanese ( E-J ) and Japanese-English ( J-E ) CLIA .</sentence>
				<definiendum id="0">Japanese-English ( J-E</definiendum>
				<definiens id="0">Japanese and English ) system ( Sakai et al. , 2002a ; Sakai et al. , 2002b ; Sakai et al. , 2003 ) which integrates machine translation ( MT ) with information retrieval</definiens>
			</definition>
			<definition id="2">
				<sentence>To our knowledge , BRIDJE is the first system that truly integrates MT with IR and performs well in terms of standard measures .</sentence>
				<definiendum id="0">BRIDJE</definiendum>
				<definiens id="0">the first system that truly integrates MT with IR and performs well in terms of standard measures</definiens>
			</definition>
			<definition id="3">
				<sentence>Based on Semantic Role Analysis ( SRA ) originally designed for enhancing retrieval performance ( Sakai et al. , 2002a ; Suzuki et al. , 2001 ) , the Information Distiller extracts important text fragments from a retrieved document on the fly .</sentence>
				<definiendum id="0">Information Distiller</definiendum>
				<definiens id="0">extracts important text fragments from a retrieved document on the fly</definiens>
			</definition>
			<definition id="4">
				<sentence>BRIDJE is an enhanced , fully bilingual version of the KIDS Japanese retrieval system that recently achieved the highest performances in the EnglishJapanese and Japanese monolingual IR tasks at NTCIR-3 ( Chen et al. , 2003 ; Sakai et al. , 2003 ) .</sentence>
				<definiendum id="0">BRIDJE</definiendum>
				<definiens id="0">an enhanced</definiens>
			</definition>
			<definition id="5">
				<sentence>In contrast , BRIDJE treats these candidates as a group of synonyms , which is now known to be effective in CLIR ( Pirkola , 1998 ) .</sentence>
				<definiendum id="0">BRIDJE</definiendum>
				<definiens id="0">treats these candidates as a group of synonyms</definiens>
			</definition>
			<definition id="6">
				<sentence>MULINEX ( Capstick et al. , 2000 ) , which is a dictionary-based CLIR system for French , English and German , uses the LOGOS MT system for document/summary presentation .</sentence>
				<definiendum id="0">MULINEX</definiendum>
				<definiens id="0">a dictionary-based CLIR system for French , English and German , uses the LOGOS MT system for document/summary presentation</definiens>
			</definition>
			<definition id="7">
				<sentence>Partial disambiguation takes all candidate translations that are left just after the semantic analysis stage ( “hiku” and “ens¯o-suru” in the above example ) , and treats them as a set of synonyms in retrieval .</sentence>
				<definiendum id="0">Partial disambiguation</definiendum>
				<definiens id="0">takes all candidate translations that are left just after the semantic analysis stage ( “hiku” and “ens¯o-suru” in the above example ) , and treats them as a set of synonyms in retrieval</definiens>
			</definition>
			<definition id="8">
				<sentence>BRIDJE employs word-based indexing , prior to which synonyms and phrases can be defined .</sentence>
				<definiendum id="0">BRIDJE</definiendum>
				<definiens id="0">employs word-based indexing , prior to which synonyms and phrases</definiens>
			</definition>
			<definition id="9">
				<sentence>In general , PRF preserves the positive effect of partial disambiguation .</sentence>
				<definiendum id="0">PRF</definiendum>
				<definiens id="0">preserves the positive effect of partial disambiguation</definiens>
			</definition>
			<definition id="10">
				<sentence>( a ) ( b ) FD PD NTCIR-3 E-J 8.6 26.9 3 NTCIR-2 E-J 6.5 18.1 4 BMIR-J2 E-J ( X ) 3.1 11.9 1 BMIR-J2 E-J ( Y ) 3.5 12.3 0 NTCIR-3 J-E 11.0 20.1 5 NTCIR-2 J-E 13.5 16.0 8 word ( with one exception ) , and it appears that out-ofvocabulary words did not directly affect our experiments : partial disambiguation managed to improve five of the eight NTCIR-2 J-E topics that contained an out-of-vocabulary word .</sentence>
				<definiendum id="0">E-J</definiendum>
				<definiens id="0">word ( with one exception ) , and it appears that out-ofvocabulary words did not directly affect our experiments : partial disambiguation managed to improve five of the eight NTCIR-2 J-E topics that contained an out-of-vocabulary word</definiens>
			</definition>
			<definition id="11">
				<sentence>( TITLE ) S1 : The [ Paris 22-day cooperation ] Director Takeshi Kitano who won Golden Lion ( Grand Prix ) at the Venice Film Festival in 1997 will send new work `` chrysanthemum Jiro 's summer '' into a world 's largest film festival and the competition section of the Cannes International Film Festival .</sentence>
				<definiendum id="0">TITLE ) S1</definiendum>
			</definition>
			<definition id="12">
				<sentence>Semantic Role # fragments Precision A. NTCIR-2 English documents TOPIC/AIM 72 ( 12 % ) 100 % RESULT/ 58 ( 10 % ) 98 % CONCLUSION ( 57/58 ) BACKGROUND 8 ( 1 % ) 100 % OPINION 0 ( 0 % ) SubTotal 138 ( 23 % ) 99 % ( 137/138 ) UNDETERMINED 454 ( 77 % ) Total 592 ( 100 % ) B. NTCIR-2 Japanese documents TOPIC/AIM 82 ( 15 % ) 96 % ( 79/82 ) RESULT/ 42 ( 8 % ) 100 % CONCLUSION BACKGROUND 27 ( 5 % ) 93 % ( 25/27 ) OPINION 7 ( 1 % ) 100 % SubTotal 158 ( 31 % ) 97 % ( 153/158 ) UNDETERMINED 355 ( 69 % ) Total 513 ( 100 % ) As the Information Distiller is an interactive subsystem , user-oriented , overall usefulness evaluations should be performed .</sentence>
				<definiendum id="0">Information Distiller</definiendum>
				<definiens id="0">an interactive subsystem , user-oriented , overall usefulness evaluations should be performed</definiens>
			</definition>
			<definition id="13">
				<sentence>We define SRA precision as the number of fragments with acceptable SRs divided by the total number of fragments .</sentence>
				<definiendum id="0">SRA precision</definiendum>
				<definiens id="0">the number of fragments with acceptable SRs divided by the total number of fragments</definiens>
			</definition>
			<definition id="14">
				<sentence>Topics of our future work include : Improving partial disambiguation by being more selective ; Extensive and user-oriented evaluations of the Information Distiller ; User-oriented query expansion using the Information Distiller ; Expanding our language scope , for example , to Chinese ; and Building a true cross-language question answering system .</sentence>
				<definiendum id="0">Building</definiendum>
				<definiens id="0">a true cross-language question answering system</definiens>
			</definition>
			<definition id="15">
				<sentence>Gachot , D. A. , Lange , E. and Yang , J. : The SYSTRAN NLP Browser : An Application of Machine Translation Technology in Cross-Language Information Retrieval , In ( Grefenstette , 1998 ) .</sentence>
				<definiendum id="0">SYSTRAN NLP Browser</definiendum>
				<definiens id="0">An Application of Machine Translation Technology in Cross-Language Information Retrieval</definiens>
			</definition>
</paper>

		<paper id="0802">
			<definition id="0">
				<sentence>A multilayer chart holds the linguistic processing results in the online system memory while XML annotations can be accessed online as well as offline .</sentence>
				<definiendum id="0">multilayer chart</definiendum>
			</definition>
			<definition id="1">
				<sentence>XSLT ( Clark 1999 ) is a W3C standard language for the transformation of XML documents .</sentence>
				<definiendum id="0">XSLT</definiendum>
			</definition>
			<definition id="2">
				<sentence>An XSL stylesheet consists of templates with XPath expressions that must match the input document in order to be executed .</sentence>
				<definiendum id="0">XSL stylesheet</definiendum>
			</definition>
			<definition id="3">
				<sentence>There are basically three kinds of results : • strings ( including non-XML output , e.g. RTF or even programming language source code ) • lists of unique identifiers denoting references to nodes in the XML input document • XML documents In other words , if we formulate queries as functions , we get the following query signatures : • getValue : C × D × P* → S* • getNodes : C × D × P* → N* • getDocument : C × D × P* → D where C is the component , D an XML document , P* a ( possibly empty ) sequence of parameters , S* a sequence of strings , and N* a sequence of node identifiers .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the component</definiens>
			</definition>
			<definition id="4">
				<sentence>The sample query returns the node identifiers of all named entities ( NE tags ) that are in the given range of tokens ( W tags ) .</sentence>
				<definiendum id="0">sample query</definiendum>
				<definiens id="0">returns the node identifiers of all named entities ( NE tags ) that are in the given range of tokens ( W tags )</definiens>
			</definition>
			<definition id="5">
				<sentence>E.g. , in SPPC XML output , named entity elements enclose token elements .</sentence>
				<definiendum id="0">E.g.</definiendum>
				<definiens id="0">in SPPC XML output , named entity elements enclose token elements</definiens>
			</definition>
			<definition id="6">
				<sentence>NiteQL ( Evert and Voormann 2002 ) can be seen as an extension to XPath within XSLT , has a more concise syntax especially for document structure-related expressions and a focus on timeline support with specialized queries ( for speech annotation ) .</sentence>
				<definiendum id="0">NiteQL</definiendum>
				<definiens id="0">an extension to XPath within XSLT , has a more concise syntax especially for document structure-related expressions and a focus on timeline support with specialized queries ( for speech annotation )</definiens>
			</definition>
			<definition id="7">
				<sentence>XQuery is a powerful , SQL-like query language on XML documents where XPath is a subset rather than asublanguageasinXSLT .</sentence>
				<definiendum id="0">XQuery</definiendum>
				<definiendum id="1">XPath</definiendum>
				<definiens id="0">a powerful , SQL-like query language on XML documents where</definiens>
				<definiens id="1">a subset rather than asublanguageasinXSLT</definiens>
			</definition>
</paper>

		<paper id="1706">
			<definition id="0">
				<sentence>sun , jurafsky } @ colorado.edu The length of a constituent ( number of syllables in a word or number of words in a phrase ) , or rhythm , plays an important role in Chinese syntax .</sentence>
				<definiendum id="0">rhythm</definiendum>
				<definiens id="0">a word or number of words in a phrase ) , or</definiens>
			</definition>
			<definition id="1">
				<sentence>The content chunk is a phrase containing only content words , akin to a generalization of a BaseNP .</sentence>
				<definiendum id="0">content chunk</definiendum>
				<definiens id="0">a phrase containing only content words , akin to a generalization of a BaseNP</definiens>
			</definition>
			<definition id="2">
				<sentence>Thus , a probability is assigned for expansion of each node n when a rule r is applied : ) | , ( ) ) ( ( AFSPnrP β= ( 3 ) where A - &gt; β is a CFG rule and FS is a feature set related to β .</sentence>
				<definiendum id="0">FS</definiendum>
				<definiens id="0">a CFG rule and</definiens>
				<definiens id="1">a feature set related to β</definiens>
			</definition>
			<definition id="3">
				<sentence>From Equation ( 3 ) we get : ) | ( * ) , | ( ) ) ( ( APAFSPnrP ββ= ( 4 ) where P ( FS| β , A ) is probabilistic feature ( PF ) model and P ( β | A ) is PCFG model .</sentence>
				<definiendum id="0">P ( FS| β</definiendum>
				<definiens id="0">probabilistic feature ( PF ) model and P ( β | A ) is PCFG model</definiens>
			</definition>
			<definition id="4">
				<sentence>Let F be a feature associated with a string β , where the possible values for F are f 1 , f 2 , … , f n , E is the set of observations of rule A → β in the training corpus , and thus E can be divided into n disjoint subsets : E 1 , E 2 , … , E n , corresponding to f 1 , f 2 , … , f n respectively .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">the set of observations of rule A → β in the training corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>Precision represents how many phrases are correct among the phrases recognized , recall represents how many phrases in the gold standard are correctly recognized , and F-measure is defined as follows : callecision callecision measureF RePr 2RePr + ×× =− Table 4 gives the experimental results in three different conditions : the first row gives the result of PCFG model ; the second row gives the result of PCFG model integrated with rhythm feature model ( RF ) where only the features of simple phrases are considered ; the last row gives the result of PCFG model plus RF where the rhythm features in all the phrases are considered .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">represents how many phrases are correct among the phrases recognized , recall represents how many phrases in the gold standard are correctly recognized</definiens>
				<definiens id="1">the experimental results in three different conditions : the first row gives the result of PCFG model ; the second row gives the result of PCFG model integrated with rhythm feature model ( RF ) where only the features of simple phrases are considered ; the last row gives the result of PCFG model plus RF where the rhythm features in all the phrases are considered</definiens>
			</definition>
</paper>

		<paper id="1305">
			<definition id="0">
				<sentence>Conceptually , named entity recognition consists of two tasks : identification , which finds the boundaries of a named entity in a text , and classification , which determines the semantic class of that named entity .</sentence>
				<definiendum id="0">identification</definiendum>
				<definiendum id="1">classification</definiendum>
				<definiens id="0">finds the boundaries of a named entity in a text , and</definiens>
				<definiens id="1">determines the semantic class of that named entity</definiens>
			</definition>
			<definition id="1">
				<sentence>The region information is encoded by using simple T representation : T means that current word is a part of a named entity , and O means that the word is not in a named entity .</sentence>
				<definiendum id="0">T</definiendum>
				<definiendum id="1">O</definiendum>
				<definiens id="0">a part of a named entity , and</definiens>
			</definition>
			<definition id="2">
				<sentence>The named entity identification is defined as the classification of each word to one of the classes that represent the region information .</sentence>
				<definiendum id="0">named entity identification</definiendum>
				<definiens id="0">the classification of each word to one of the classes that represent the region information</definiens>
			</definition>
			<definition id="3">
				<sentence>The region information is encoded by using simple T representation : T means that the current word is a part of a named entity , and O means that the current word is not in a named entity .</sentence>
				<definiendum id="0">T</definiendum>
				<definiendum id="1">O</definiendum>
				<definiens id="0">a part of a named entity , and</definiens>
			</definition>
			<definition id="4">
				<sentence>At the second Table 3 : Performance comparison with or w/o post-processing ( Ffl=1 ) : ( A ) 10-fold cross validation ( 1800 abstracts , test with 200 abstracts ) , ( B ) training with 590 abstracts , test with 80 abstracts A B ( Kazama , 2002 ) No. of W PostProc with PostProc No. of W PostProc with PostProc No. of Inst Inst Inst Identification 76.2/82.4/79.2 76.8/83.1/79.9 78.4/80.8/79.6 80.2/82.6/81.4 75.9/71.4/73.6 Classification 63.6/68.8/66.1 64.0/69.2/66.5 65.8/67.9/66.8 67.0/69.0/68.0 56.2/52.8/54.4 protein 25,276 60.9/79.8/69.1 61.7/78.8/69.2 1,056 61.3/81.3/69.9 62.8/80.7/70.6 709 49.2/66.4/56.5 DNA 8,858 65.1/63.9/64.5 65.0/63.8/64.4 474 71.4/61.0/65.8 72.1/61.6/66.4 460 49.6/37.0/42.3 RNA 683 72.2/71.7/72.0 73.8/72.5/73.1 36 74.4/88.9/81.0 75.6/86.1/80.5 cell line 3,783 71.6/54.2/61.7 72.3/72.3/72.3 201 73.2/44.8/55.6 73.2/44.8/55.6 121 60.2/46.3/52.3 cell type 6,423 67.2/77.5/72.0 67.5/67.5/67.5 252 64.9/82.1/72.5 65.4/81.7/72.7 199 70.0/75.4/72.6 phase , we tried to classify the identified entity into its semantic class by voting the SVMs .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">1800 abstracts , test with 200 abstracts ) , ( B ) training with 590 abstracts</definiens>
			</definition>
</paper>

		<paper id="1105">
			<definition id="0">
				<sentence>A naive Bayes classifier is a well-known and highly practical probabilistic classifier , and has been employed in many applications .</sentence>
				<definiendum id="0">naive Bayes classifier</definiendum>
			</definition>
			<definition id="1">
				<sentence>In other words , a document CS CY is a random vector which consists of the Poisson random variables CG CX , and CG CX has the value of withinterm-frequency CU CXCY for the CX-th term D8 CX .</sentence>
				<definiendum id="0">document CS CY</definiendum>
			</definition>
			<definition id="2">
				<sentence>Thus , if we assume the independence among the terms in CS CY , a probability of CS CY is represented by , D4B4CS CY B5BP CYCE CY CH CXBPBD C8B4CG CX BP CU CXCY B5 ( 4 ) where , CYCE CY is a vocabulary size , and each C8B4CG CX BP CU CXCY B5 is given by , C8B4CG CX BP CU CXCY B5BP CT A0AL AL CU CXCY CU CXCY AX ( 5 ) where , AL is the Poisson mean .</sentence>
				<definiendum id="0">D4B4CS CY B5BP CYCE CY CH CXBPBD C8B4CG CX BP CU CXCY B5</definiendum>
				<definiendum id="1">CYCE CY</definiendum>
				<definiendum id="2">AL</definiendum>
				<definiens id="0">a vocabulary size , and each C8B4CG CX BP CU CXCY B5 is given by , C8B4CG CX BP CU CXCY B5BP CT A0AL AL CU CXCY CU CXCY AX ( 5 ) where ,</definiens>
			</definition>
			<definition id="3">
				<sentence>Since CU CXCY is a frequency of a term CX in a document CS CY with a fixed length according to the definition of Poisson distribution , we should normalize the actual term frequencies in the documents with the different length .</sentence>
				<definiendum id="0">CU CXCY</definiendum>
				<definiens id="0">a frequency of a term CX in a document CS CY with a fixed length according to the definition of Poisson distribution</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus , we estimate CU CXCY as the normalized and smoothed frequency of actual term frequency DC CXCY , represented by , DI CU CXCY BP DC CXCY B7 AI CSD0 CY B7 AI A1CYCE CY A1 AS ( 7 ) where AI is a laplace smoothing parameter , AS is any huge value which makes all the DI CU CXCY in our model an integer value 1 , and CSD0 CY is the length of CS CY .</sentence>
				<definiendum id="0">CU CXCY</definiendum>
				<definiendum id="1">DI CU CXCY BP DC CXCY</definiendum>
				<definiendum id="2">AI</definiendum>
				<definiendum id="3">AS</definiendum>
				<definiendum id="4">CSD0 CY</definiendum>
				<definiens id="0">the normalized and smoothed frequency of actual term frequency DC CXCY , represented by</definiens>
				<definiens id="1">a laplace smoothing parameter</definiens>
				<definiens id="2">any huge value which makes all the DI CU CXCY in our model an integer value 1 , and</definiens>
			</definition>
			<definition id="5">
				<sentence>Then , Poisson mean AL CX , which represents an average number of occurrence of D8 CX in the documents belonging to class CR , is estimated using the normalized and smoothed DI CU CXCY values over the training documents as follows : DI AL CX BP CG CS CY BEBW CR CVB4CS CY CYCRB5 A1 DI CU CXCY ( 8 ) where BW CR is the set of training documents belonging to class CR , and CVB4CS CY CYCRB5 2 is the interpolation of the uniform probability and the probability proportional to the length of the document , and the interpolation is calculated as follows : CVB4CS CY CYCRB5 BP AB BD CYBW CR CY B7B4BDA0 ABB5 CSD0 CY C8 CS CY BEBW CR CSD0 CY ( 9 ) Simple averaging of DI CU CXCY , the case of AB=1 , seems to be correct to estimate AL CX .</sentence>
				<definiendum id="0">AL CX</definiendum>
				<definiens id="0">represents an average number of occurrence of D8 CX in the documents belonging to class CR , is estimated using the normalized and smoothed DI CU CXCY values over the training documents as follows : DI AL CX BP CG CS CY BEBW CR CVB4CS CY CYCRB5 A1 DI CU CXCY ( 8 ) where BW CR is the set of training documents belonging to class CR</definiens>
			</definition>
			<definition id="6">
				<sentence>However , the statistics 1 Since CU CXCY is a value of random variable CG CXCY representing the frequency in our Poisson distribution , we multiply the normalized frequency with some unnatural constant AS to make CU CXCY integer value .</sentence>
				<definiendum id="0">CU CXCY</definiendum>
				<definiens id="0">a value of random variable CG CXCY representing the</definiens>
			</definition>
			<definition id="7">
				<sentence>Consequently , AL CX is a weighted average over all training documents belonging to the class CR , and AM CX for the class AMCR can be estimated in the same manner .</sentence>
				<definiendum id="0">AL CX</definiendum>
				<definiens id="0">a weighted average over all training documents belonging to the class CR , and AM CX for the class AMCR can be estimated in the same manner</definiens>
			</definition>
			<definition id="8">
				<sentence>With the feature weighting method , our DE CYCR is redefined as follows : DE CYCR BP CYCE CY CG CXBPBD DB CXCR W CR A1 D0D3CV CT A0 DI AL CX DI AL CX DI CU CXCY CT A0 DIAM CX DIAM CX DI CU CXCY ( 10 ) where , DB CXCR is the weight of feature for the class CR , and W CR is the normalization factor , that is , C8 CE CXBPBD DB CXCR .</sentence>
				<definiendum id="0">DB CXCR</definiendum>
				<definiens id="0">redefined as follows : DE CYCR BP CYCE CY CG CXBPBD DB CXCR W CR A1 D0D3CV CT A0 DI AL CX DI AL CX DI CU CXCY CT A0 DIAM CX DIAM CX DI CU CXCY ( 10 ) where ,</definiens>
				<definiens id="1">the weight of feature for the class CR , and W CR is the normalization factor , that is , C8 CE CXBPBD DB CXCR</definiens>
			</definition>
			<definition id="9">
				<sentence>Information gain ( or average mutual information ) is an information-theoretic measure defined by the amount of reduced uncertainty given a piece of information .</sentence>
				<definiendum id="0">Information gain</definiendum>
				<definiendum id="1">mutual information )</definiendum>
				<definiens id="0">an information-theoretic measure defined by the amount of reduced uncertainty given a piece of information</definiens>
			</definition>
			<definition id="10">
				<sentence>We use the information gain value as the weight of each term for the class CR , and the value is calculated using a document event model as follows : DB CXCR BP C0B4BVB5 A0 C0B4BVCYCF CX B5 ( 11 ) BP CG CR D7 BECUCRBNAMCRCV CG DB D8 BECUDB CX BN AMDB CX CV D4B4CR D7 BNDB D7 B5D0D3CV D4B4CR D7 BNDB D8 B5 D4B4CR D7 B5D4B4DB D8 B5 where , for example , D4B4CRB5 is the number of documents belonging to the class CR divided by the total number of documents , and D4B4AMDBB5 is the number of documents without the term DB divided by the total number of documents , etc .</sentence>
				<definiendum id="0">document event model</definiendum>
				<definiendum id="1">D4B4CRB5</definiendum>
				<definiendum id="2">D4B4AMDBB5</definiendum>
				<definiens id="0">the information gain value as the weight of each term for the class CR</definiens>
				<definiens id="1">the number of documents belonging to the class CR divided by the total number of documents</definiens>
			</definition>
			<definition id="11">
				<sentence>By a couple of simple arithmetic operations , our final DE CYCR function can be rewritten as follows : DE CYCR BP AS W CR B4BT CR B7B4BU CR B7CMDE CYCR B5 BD CSD0 CY BC B5 ( 14 ) where , BT CR BP CYCE CY CG CXBPBD DB CXCR B4DIAM CX BC A0 DI AL CX BC B5 BU CR BP AI CYCE CY CG CXBPBD DB CXCR D0D3CV DI AL CX BC DIAM CX BC CMDE CYCR BP CG BKCXBND8 CX BECS CY DB CXCR DC CXCY D0D3CV DI AL CX BC DIAM CX BC DI AL CX BC BP BD AS DI AL CX BP CG CS CY BEBW CR CVB4CS CY CYCRB5 A1 DI CU CXCY AS CSD0 BC CY BP CSD0 CY B7 AICYCE CY In this equation , DI AL CX BC and DIAM CX BC are just weighted average of AS-dropped DI CU CXCY , that is , DC CXCY B7AI CSD0 CY B7AICYCE CY .</sentence>
				<definiendum id="0">BT CR BP CYCE CY CG CXBPBD DB CXCR B4DIAM CX BC A0 DI AL CX BC B5 BU CR BP AI CYCE CY CG CXBPBD DB CXCR D0D3CV DI AL CX BC DIAM CX BC CMDE CYCR</definiendum>
				<definiens id="0">BP CG BKCXBND8 CX BECS CY DB CXCR DC CXCY D0D3CV DI AL CX BC DIAM CX BC DI AL CX BC BP BD AS DI AL CX BP CG CS CY BEBW CR CVB4CS CY CYCRB5 A1 DI CU CXCY AS CSD0 BC CY BP CSD0 CY</definiens>
			</definition>
</paper>

		<paper id="0112">
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>Lisbon has a mild and equable climate , with a mean annual temperature of 63 degree F ( 17 degree C ) .</sentence>
				<definiendum id="0">Lisbon</definiendum>
			</definition>
			<definition id="1">
				<sentence>Jakarta is a tropical , humid city , with annual temperatures ranging between the extremes of 75 and 93 degree F ( 24 and 34 degree C ) and a relative humidity between 75 and 85 percent .</sentence>
				<definiendum id="0">Jakarta</definiendum>
				<definiens id="0">a tropical , humid city , with annual temperatures ranging between the extremes of 75 and 93 degree F ( 24 and 34 degree C</definiens>
			</definition>
			<definition id="2">
				<sentence>Each text pair in the training and testing sets was annotated by two annotators.8 In our guidelines to them , we defined two sentences as aligned if they contain at least one clause 7Britannica Elementary is a new feature of the encyclopedia , not all entries in the original Britannica have been fully updated .</sentence>
				<definiendum id="0">Elementary</definiendum>
				<definiens id="0">Each text pair in the training and testing sets was annotated by two annotators.8 In our guidelines to them</definiens>
				<definiens id="1">aligned if they contain at least one clause 7Britannica</definiens>
				<definiens id="2">a new feature of the encyclopedia , not all entries in the original Britannica have been fully updated</definiens>
			</definition>
			<definition id="3">
				<sentence>Alignment is a tedious task , and sentence pairs can easily be missed even by a careful human annotator .</sentence>
				<definiendum id="0">Alignment</definiendum>
				<definiens id="0">a tedious task , and sentence pairs can easily be missed even by a careful human annotator</definiens>
			</definition>
			<definition id="4">
				<sentence>We also compare our algorithm with two state-ofthe-art systems , SimFinder ( Hatzivassiloglou et al. , 1999 ) and Decomposition ( Jing , 2002 ) .10 Figure 6 shows Precision/Recall curves for the different systems .</sentence>
				<definiendum id="0">SimFinder</definiendum>
				<definiendum id="1">Decomposition</definiendum>
				<definiens id="0">shows Precision/Recall curves for the different systems</definiens>
			</definition>
			<definition id="5">
				<sentence>Prague is a centuries-old city with a wealth of historic landmarks .</sentence>
				<definiendum id="0">Prague</definiendum>
				<definiens id="0">a centuries-old city with a wealth of historic landmarks</definiens>
			</definition>
</paper>

		<paper id="0605">
			<definition id="0">
				<sentence>Structural alignment is a process in which corresponding elements in two structured representations are identified by matching .</sentence>
				<definiendum id="0">Structural alignment</definiendum>
				<definiens id="0">a process in which corresponding elements in two structured representations are identified by matching</definiens>
			</definition>
			<definition id="1">
				<sentence>LCS is a cognitive representation that focuses on trajectories and spatial relations .</sentence>
				<definiendum id="0">LCS</definiendum>
				<definiens id="0">a cognitive representation that focuses on trajectories and spatial relations</definiens>
			</definition>
			<definition id="2">
				<sentence>Unlike other representations such as Logical Form ( LF ) and Conceptual Dependency ( CD ) , LCS delineates notions of PATHs and PLACEs .</sentence>
				<definiendum id="0">Conceptual Dependency</definiendum>
				<definiendum id="1">LCS</definiendum>
				<definiens id="0">delineates notions of PATHs and PLACEs</definiens>
			</definition>
			<definition id="3">
				<sentence>• [ THING ] • [ PLACE ] ←− PLACE-FUNC ( [ THING ] ) where PLACE-FUNC ∈ { AT , ABOVE , BELOW , ON , IN , etc. } • [ PATH ] ←− PATH ( PATH-ELEMENT , PATHELEMENT , ··· ) • [ PATH-ELEMENT ] ←− PATH-FUNC ( [ PLACE ] ) where PATH-FUNC ∈ { TO , FROM , TOWARD , AWAY-FROM , VIA , etc. } • [ EVENT ] ←− GO ( [ THING ] , [ PATH ] ) • [ STATE ] ←− BE ( [ THING ] , [ PLACE ] ) • [ CAUSE ] ←− CAUSE ( [ THING ] , [ EVENT ] ) • [ CAUSE ] ←− CAUSE ( [ EVENT ] , [ EVENT ] ) Using LCS , the trajectory expressed in the sentence “The bird flew from the pole to Deborah , ” is represented as in Figure 3 Lexical-Conceptual Semantics focuses on spatial relations in the physical world .</sentence>
				<definiendum id="0">←− CAUSE</definiendum>
				<definiens id="0">PLACE-FUNC ∈ { AT , ABOVE , BELOW , ON</definiens>
			</definition>
			<definition id="4">
				<sentence>CCG has many advantages in a system like ours .</sentence>
				<definiendum id="0">CCG</definiendum>
				<definiens id="0">has many advantages in a system like ours</definiens>
			</definition>
			<definition id="5">
				<sentence>vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle x vextendsingle vextendsingle vextendsingle PATH GO fly                       S : vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle |THING Dove−Bird vextendsingle vextendsingle vextendsingle PATH GO            Figure 4 : The parsing and structural alignment system functions as a constraint on linguistic and visual interpretations , requiring that expressions follow grammatical rules and that they align with the semantic domain input .</sentence>
				<definiendum id="0">vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle x vextendsingle vextendsingle</definiendum>
				<definiens id="0">The parsing and structural alignment system functions as a constraint on linguistic and visual interpretations , requiring that expressions follow grammatical rules and that they align with the semantic domain input</definiens>
			</definition>
			<definition id="6">
				<sentence>Since our intent is to perform structural alignment with input from the non-linguistic domain , our goal in parsing is to find the semantic parse structure which 4 For a full description and analysis of CCG , see ( Steedman , 2000 ) CCG Constraint Backward Application ( &lt; ) Y : a X\Y : f ⇒ Y : fa “The boy” NP : |THING Boy “The boy went to the lake” S : vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle |THING Boy vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle |THING Lake PLACE At PATH−ELEMENT To PATH EVENT Go “went to the lake” S\NP : λx .</sentence>
				<definiendum id="0">S\NP</definiendum>
				<definiens id="0">vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle |THING Boy vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle vextendsingle |THING Lake PLACE At PATH−ELEMENT To PATH EVENT Go “went to the lake”</definiens>
			</definition>
			<definition id="7">
				<sentence>The vision system consists of two parts .</sentence>
				<definiendum id="0">vision system</definiendum>
			</definition>
			<definition id="8">
				<sentence>This matching procedure attempts to identify objects persisting between frames based on proximity in size , shape , color , and position using a 4-dimensional nearest-neighbors approach .</sentence>
				<definiendum id="0">matching procedure</definiendum>
				<definiens id="0">attempts to identify objects persisting between frames based on proximity in size , shape , color</definiens>
			</definition>
			<definition id="9">
				<sentence>If an object is found and moving , an LCS GO frame is instantiated and the object is compared to all others present so the appropriate path and place functions can be calculated .</sentence>
				<definiendum id="0">LCS GO frame</definiendum>
				<definiens id="0">the appropriate path and place functions can be calculated</definiens>
			</definition>
</paper>

		<paper id="0805">
			<definition id="0">
				<sentence>The Virtual Laboratory : a toolset to enable distributed molecular modeling for drug design on the World-Wide Grid .</sentence>
				<definiendum id="0">Virtual Laboratory</definiendum>
				<definiens id="0">a toolset to enable distributed molecular modeling for drug design on the World-Wide Grid</definiens>
			</definition>
			<definition id="1">
				<sentence>http : //www.language-archives.org/NOTE/third-party-extensions.html 6 Christopher Cieri , Steven Bird , Annotation graphs and servers and multi-modal resources : infrastructure for interdisciplinary education , research and development , Proceedings of the ACL 2001 Workshop on Human Language Technology and Knowledge Management , p.23-30 , July 07-07 , 2001 , France 7 Hamish Cunningham , Yorick Wilks , Robert J. Gaizauskas , GATE : a General Architecture for Text Engineering , Proceedings of the 16th conference on Computational linguistics , August 05-09 , 1996 , Copenhagen , Denmark 8 Hamish Cunningham , 2002 .</sentence>
				<definiendum id="0">GATE</definiendum>
				<definiens id="0">a General Architecture for Text Engineering</definiens>
			</definition>
			<definition id="2">
				<sentence>GATE , a General Architecture for Text Engineering .</sentence>
				<definiendum id="0">GATE</definiendum>
				<definiens id="0">a General Architecture for Text Engineering</definiens>
			</definition>
			<definition id="3">
				<sentence>The Physiology of the Grid : An Open Grid Services Architecture for Distributed Systems Integration .</sentence>
				<definiendum id="0">Physiology of the Grid</definiendum>
				<definiens id="0">An Open Grid Services Architecture for Distributed Systems Integration</definiens>
			</definition>
			<definition id="4">
				<sentence>Viser : a virtual service provider for displaying selected OLAC metadata .</sentence>
				<definiendum id="0">Viser</definiendum>
			</definition>
</paper>

		<paper id="0206">
			<definition id="0">
				<sentence>Granska is a grammar checker for Swedish developed at the Royal Institute of Technology in Sweden ( Domeij et al. , 2000 ) .</sentence>
				<definiendum id="0">Granska</definiendum>
			</definition>
			<definition id="1">
				<sentence>Granska combines probabilistic and rule-based methods to achieve high efficiency and robustness ( see also Carlberger and Kann ( 1999 ) ) .</sentence>
				<definiendum id="0">Granska</definiendum>
				<definiens id="0">combines probabilistic and rule-based methods to achieve high efficiency</definiens>
			</definition>
			<definition id="2">
				<sentence>Good – Granska is a quite good help for me .</sentence>
				<definiendum id="0">Good – Granska</definiendum>
			</definition>
			<definition id="3">
				<sentence>As Chapelle writes ”the question for computer aided second-language is not whether or not the computational grammar is a good theoretical account of the language within a particular domain , but instead is whether or not the program is able to interact with the learner in a way that is useful relative to its purpose” ( Chapelle ( 2001 ) , p. 36 ) .</sentence>
				<definiendum id="0">computational grammar</definiendum>
				<definiens id="0">a good theoretical account of the language within a particular domain , but instead is whether or not the program is able to interact with the learner in a way that is useful relative to its purpose” ( Chapelle ( 2001 ) , p. 36 )</definiens>
			</definition>
</paper>

		<paper id="1108">
			<definition id="0">
				<sentence>CLIR consists of retrieving documents written in one language using queries written in another language .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">consists of retrieving documents written in one language using queries written in another language</definiens>
			</definition>
			<definition id="1">
				<sentence>Transliteration is the phonetic or spelling representation of one language using the alphabet of another language ( Knight and Graehl , 1998 ) .</sentence>
				<definiendum id="0">Transliteration</definiendum>
				<definiens id="0">the phonetic or spelling representation of one language using the alphabet of another language</definiens>
			</definition>
			<definition id="2">
				<sentence>ATN applies augmented normalized term frequency , tf idf document frequency ( term frequency times inverse document frequency components ) to weigh terms in the collection of documents .</sentence>
				<definiendum id="0">ATN</definiendum>
				<definiendum id="1">tf idf document frequency</definiendum>
				<definiendum id="2">term frequency times inverse document frequency</definiendum>
				<definiens id="0">applies augmented normalized term frequency</definiens>
			</definition>
			<definition id="3">
				<sentence>In Table 2 , idfj = log NFj ; where , N represents the number of documents and Fj represents the document frequency of term Tj .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">Fj</definiendum>
				<definiens id="0">the number of documents</definiens>
				<definiens id="1">represents the document frequency of term Tj</definiens>
			</definition>
</paper>

		<paper id="0315">
			<definition id="0">
				<sentence>The alignment score is a combination ( by linear regression ) of two word translation lexicon scores and three sentence length scores and predicts the translation quality scores from a set of human annotators .</sentence>
				<definiendum id="0">alignment score</definiendum>
				<definiens id="0">a combination ( by linear regression ) of two word translation lexicon scores and three sentence length scores and predicts the translation quality scores from a set of human annotators</definiens>
			</definition>
			<definition id="1">
				<sentence>• A character encoding detector , which judges if the Chinese html document is GB2312 encoding or BIG5 encoding .</sentence>
				<definiendum id="0">character encoding detector</definiendum>
				<definiens id="0">GB2312 encoding or BIG5 encoding</definiens>
			</definition>
			<definition id="2">
				<sentence>• An encoding converter , which converts the BIG5 documents to GB2312 encoding .</sentence>
				<definiendum id="0">encoding converter</definiendum>
			</definition>
			<definition id="3">
				<sentence>• A document alignment program , which judges if the document pair is close translation candidates , and filters out those non-translation pairs .</sentence>
				<definiendum id="0">document alignment program</definiendum>
				<definiens id="0">judges if the document pair is close translation candidates</definiens>
			</definition>
			<definition id="4">
				<sentence>.1 ) , , { ( ) ( ) ( Sief ii = , our Model-1 training for t ( f|e ) is as follows : ∑ = − = S s ss e efefceft 1 ) ( ) ( 1 ) , ; | ( ) | ( λ Where 1− e λ is a normalization factor such that ∑ j j eft ) , ; | ( ) ( ) ( ss efefc denotes the expected number of times that word e connects to word f. ∑∑ ∑ == = = l i i m j jl k k ss eeff eft eft efefc 11 1 ) ( ) ( ) , ( ) , ( ) | ( ) | ( ) , ; | ( δδ With the conditional probability t ( f|e ) , the probability for an alignment of foreign string F given English string E is in ( 1 ) : ∏∑ = = + = m j n i ijm eft l EFP 1 0 ) | ( ) 1 ( 1 ) | ( ( 1 ) The probability of alignment F given E : ) | ( EFP is shown to achieve the global maximum under this EM framework as stated in ( Brown et al.,1993 ) .</sentence>
				<definiendum id="0">| ( ) ( ) ( ss efefc</definiendum>
				<definiens id="0">{ ( ) ( ) ( Sief ii = , our Model-1 training for t ( f|e ) is as follows : ∑ = − = S s ss e efefceft 1 ) ( ) ( 1 ) , ; | ( ) | ( λ Where 1− e λ is a normalization factor such that ∑ j j eft ) , ;</definiens>
				<definiens id="1">the expected number of times that word e connects to word f. ∑∑ ∑ == = = l i i m j jl k k ss eeff eft eft efefc 11 1 ) ( ) ( ) , ( ) , ( ) | ( ) | ( ) , ; | ( δδ With the conditional probability t ( f|e ) , the probability for an alignment of foreign string F given English string E is in ( 1 ) : ∏∑ = = + = m j n i ijm eft l EFP 1 0 ) | ( ) 1 ( 1 ) | ( ( 1 ) The probability of alignment F given E : ) | ( EFP is shown to achieve the</definiens>
			</definition>
			<definition id="5">
				<sentence>After W is calculated , the predicted score from the regression model is : * ' AWH = ( 7 ) where 'H is the final predicted alignment quality score of the regression model .</sentence>
				<definiendum id="0">'H</definiendum>
				<definiens id="0">the final predicted alignment quality score of the regression model</definiens>
			</definition>
</paper>

		<paper id="0407">
			<definition id="0">
				<sentence>S is a seed set of labelled sentences L T is labelled training data for TNT L C is labelled training data for C &amp; C U is a large set of unlabelled sentences C is a cache holding a small subset of U initialise : L T L C S Train TNTandC &amp; ConS loop : Partition U into the disjoint sets C and U 0 .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">a seed set of labelled sentences L T is labelled training data for TNT L C is labelled training data for C &amp; C U is a large set of unlabelled sentences C is a cache holding a small subset of U initialise : L T L C S Train TNTandC &amp; ConS loop : Partition U into the disjoint sets C and U 0</definiens>
			</definition>
			<definition id="1">
				<sentence>Until U is empty Figure 1 : The general co-training process C is a cache of sentences labelled by the other tagger U is a set of sentences , used for measuring agreement initialise : c max ; ; A max 0 Repeat n times : Randomly sample c C Retrain current tagger using c as additional data if new agreement rate , A , onU &gt; A max A max A ; c max c return c max Figure 2 : Agreement-based example selection The pseudo-code for the agreement-based selection method is given in Figure 2 .</sentence>
				<definiendum id="0">U</definiendum>
				<definiendum id="1">c max</definiendum>
				<definiens id="0">empty Figure 1 : The general co-training process C is a cache of sentences labelled by the other tagger</definiens>
				<definiens id="1">a set of sentences , used for measuring agreement initialise : c max ; ; A max 0 Repeat n times : Randomly sample c C Retrain current tagger using c as additional data if new agreement rate , A , onU &gt; A max A max A ;</definiens>
			</definition>
			<definition id="2">
				<sentence>5Conclusion We have shown that co-training is an effective technique for bootstrapping POS taggers trained on small amounts of labelled data .</sentence>
				<definiendum id="0">co-training</definiendum>
			</definition>
</paper>

		<paper id="0909">
			<definition id="0">
				<sentence>Dagmar Ziegler is the treasury secretary of the German state of Brandenburg .</sentence>
				<definiendum id="0">Dagmar Ziegler</definiendum>
				<definiens id="0">the treasury secretary of the German state of Brandenburg</definiens>
			</definition>
			<definition id="1">
				<sentence>“Understanding a text” for some cognitive agent means to fuse prior knowledge with information encountered in the text .</sentence>
				<definiendum id="0">cognitive agent</definiendum>
				<definiens id="0">means to fuse prior knowledge with information encountered in the text</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>The variable X denotes a head , identifying the head of the infinitival complement’s subject with the head of the object , thus capturing the object control relation .</sentence>
				<definiendum id="0">variable X</definiendum>
				<definiens id="0">a head , identifying the head of the infinitival complement’s subject with the head of the object , thus capturing the object control relation</definiens>
			</definition>
			<definition id="1">
				<sentence>Formally , a dependency is defined as a 5-tuple : hh f ; f ; s ; h a ; li , whereh f is the head word of the functor , f is the functor category ( extended with head and dependency information ) , s is the argument slot , and h a is the head word of the argument .</sentence>
				<definiendum id="0">whereh f</definiendum>
				<definiens id="0">a 5-tuple : hh f ; f ; s ; h a</definiens>
				<definiens id="1">the head word of the functor , f is the functor category ( extended with head and dependency information</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , the dependency encoding Lotus as the object of bought ( as in IBM bought Lotus ) is represented as follows : hbought ; ( S [ dcl ] bought nNP 1 ) =NP 2 ; 2 ; Lotus ; nulli ( 2 ) If the object has been extracted using a relative pronoun with the category ( NPnNP ) = ( S [ dcl ] =NP ) ( asin the company that IBM bought ) , the dependency is as follows : hbought ; ( S [ dcl ] bought nNP 1 ) =NP 2 ; 2 ; company ; i ( 3 ) where is the category ( NPnNP ) = ( S [ dcl ] =NP ) assigned to the relative pronoun .</sentence>
				<definiendum id="0">=NP )</definiendum>
				<definiens id="0">the object of bought ( as in IBM bought Lotus</definiens>
			</definition>
			<definition id="3">
				<sentence>The probability of a dependency structure , 2 , given a sentence , S , isdefinedasfollows : P ( jS ) = X d2 ( ; S ) P ( d ; jS ) ( 5 ) where ( ; S ) is the set of derivations for S which lead to and is the set of dependency structures .</sentence>
				<definiendum id="0">S )</definiendum>
				<definiens id="0">a sentence , S , isdefinedasfollows : P ( jS ) = X d2 ( ; S ) P ( d ; jS ) ( 5 ) where ( ;</definiens>
				<definiens id="1">the set of derivations for S which lead to and is the set of dependency structures</definiens>
			</definition>
			<definition id="4">
				<sentence>Note that ( ; S ) includes the non-standard derivations allowed by CCG .</sentence>
				<definiendum id="0">S )</definiendum>
				<definiens id="0">includes the non-standard derivations allowed by CCG</definiens>
			</definition>
			<definition id="5">
				<sentence>jS ) is a probability distribution : Z S = X !</sentence>
				<definiendum id="0">jS )</definiendum>
			</definition>
			<definition id="6">
				<sentence>A conjunctive node results from either the combination of two disjunctive nodes using a binary rule , e.g. forward composition ; or results from a single disjunctive node using a unary rule , e.g. type-raising ; or is a leaf node ( a word plus lexical category ) .</sentence>
				<definiendum id="0">conjunctive node</definiendum>
				<definiens id="0">a leaf node ( a word plus lexical category )</definiens>
			</definition>
			<definition id="7">
				<sentence>The packed structure we have described is an example of a feature forest ( Miyao and Tsujii , 2002 ) , defined as follows : A feature forest isatuplehC ; D ; R ; γ ; iwhere AF C is a set of conjunctive nodes ; AF D is a set of disjunctive nodes ; AF R D is a set of root disjunctive nodes ; 5 AF γ : D !</sentence>
				<definiendum id="0">AF D</definiendum>
				<definiendum id="1">AF R D</definiendum>
				<definiens id="0">an example of a feature forest ( Miyao and Tsujii , 2002 ) , defined as follows : A feature forest isatuplehC ; D ; R ; γ ; iwhere AF C is a set of conjunctive nodes</definiens>
				<definiens id="1">a set of disjunctive nodes ;</definiens>
			</definition>
			<definition id="8">
				<sentence>Nwhich counts the number of times f i appears on a particular conjunctive node .</sentence>
				<definiendum id="0">Nwhich</definiendum>
				<definiens id="0">counts the number of times f i appears on a particular conjunctive node</definiens>
			</definition>
			<definition id="9">
				<sentence>GIS is a very simple algorithm for estimating the parameters of a log-linear model .</sentence>
				<definiendum id="0">GIS</definiendum>
				<definiens id="0">a very simple algorithm for estimating the parameters of a log-linear model</definiens>
			</definition>
			<definition id="10">
				<sentence>inside outside c 1 d 2 c 6 c 4 c 3 c 7 c 5 c 2 d 1 d 3 d 6 c 8 c 10 d 4 d 5 c 9 Figure 1 : Example feature forest outside score denoted c , then the expected value of f i can be written as follows : 7 E p f i = X S ˜ P ( S ) 1 Z S X c2C s f i ( c ) c c ( 11 ) where C s is the set of conjunctive nodes for S .</sentence>
				<definiendum id="0">C s</definiendum>
				<definiens id="0">E p f i = X S ˜ P ( S ) 1 Z S X c2C s f i ( c ) c c ( 11 ) where</definiens>
				<definiens id="1">the set of conjunctive nodes for S</definiens>
			</definition>
			<definition id="11">
				<sentence>The outside score for a conjunctive node , c , is the outside score for its disjunctive node mother : c = d where c2γ ( d ) ( 14 ) The outside score for a disjunctive node is a sum over the mother nodes , of the product of the outside score of the mother , the inside score of the sister , and the feature weights on the mother .</sentence>
				<definiendum id="0">outside score</definiendum>
				<definiens id="0">a sum over the mother nodes , of the product of the outside score of the mother , the inside score of the sister , and the feature weights on the mother</definiens>
			</definition>
			<definition id="12">
				<sentence>The features used in our preliminary implementation are as follows : AF dependency features ; AF lexical category features ; AF root category features .</sentence>
				<definiendum id="0">AF lexical</definiendum>
				<definiens id="0">follows : AF dependency features</definiens>
			</definition>
			<definition id="13">
				<sentence>We have also described an MPI implementation of GIS which solves the computational challenges .</sentence>
				<definiendum id="0">GIS</definiendum>
				<definiens id="0">solves the computational challenges</definiens>
			</definition>
</paper>

		<paper id="0105">
			<definition id="0">
				<sentence>UN-LOCODE is the of cial gazetteer by the United Nations ; it is also freely available from the UNECE Web site1 and contains more than 36 000 locations in 234 countries ( UNECE , 1998 ) .</sentence>
				<definiendum id="0">UN-LOCODE</definiendum>
			</definition>
			<definition id="1">
				<sentence>A’ A’’ C D E F GHI J K B Places mentioned in discourse Potential Referents Places NOT mentioned in discourse Figure 3 : A Place-Name Resolution Method .</sentence>
				<definiendum id="0">GHI J K B Places</definiendum>
				<definiens id="0">mentioned in discourse Potential Referents Places NOT mentioned in discourse Figure 3 : A Place-Name Resolution Method</definiens>
			</definition>
			<definition id="2">
				<sentence>-120˚ -120˚ -105˚ -105˚ -90˚ -90˚ -75˚ -75˚ Figure 9 : Story C : The Final Paragraph Places the Event in Context ( Global View ; Complete Story ) .</sentence>
				<definiendum id="0">Story C</definiendum>
			</definition>
			<definition id="3">
				<sentence>Q : Is Andorra la Vella part of Spain ?</sentence>
				<definiendum id="0">Q</definiendum>
			</definition>
			<definition id="4">
				<sentence>These ( geo- ) graphical document surrogates give an overview about where a reported news event takes place .</sentence>
				<definiendum id="0">geo- ) graphical document surrogates</definiendum>
				<definiens id="0">give an overview about where a reported news event takes place</definiens>
			</definition>
</paper>

		<paper id="0609">
			<definition id="0">
				<sentence>A conditional probability field assigns to each a17 , which corresponds to a point in an a24 -dimensional sensor group , a conditional probability of the form a25 a20Ea26a17a23a22 , where E denotes the occurrence of some event .</sentence>
				<definiendum id="0">conditional probability field</definiendum>
				<definiendum id="1">E</definiendum>
				<definiens id="0">the occurrence of some event</definiens>
			</definition>
			<definition id="1">
				<sentence>Because hear-Wa20a0a28a27a17a23a22 is a linear transform of utter-Wa20a0a28a27a17a23a22 , any value of a17 that minimizes ( maximizes ) one minimizes ( maximizes ) the other .</sentence>
				<definiendum id="0">hear-Wa20a0a28a27a17a23a22</definiendum>
			</definition>
			<definition id="2">
				<sentence>Given all of the configurations for which a particular word was used , the semantic accuracy is the percentage of configurations that the meaning component of the word selects an aspect of the configuration that a native speaker of the language says is appropriate .</sentence>
				<definiendum id="0">semantic accuracy</definiendum>
				<definiens id="0">the percentage of configurations that the meaning component of the word selects an aspect of the configuration that a native speaker of the language says is appropriate</definiens>
			</definition>
</paper>

		<paper id="0704">
			<definition id="0">
				<sentence>ISD consists of the following components : ties ( accounts , spare parts , flights ) and their attributes ( account number , part size , destination city , etc. ) as well as methods for identifying references to these attributes in user statements .</sentence>
				<definiendum id="0">ISD</definiendum>
				<definiens id="0">consists of the following components : ties ( accounts , spare parts , flights ) and their attributes ( account number , part size , destination city , etc. ) as well as methods for identifying references to these attributes in user statements</definiens>
			</definition>
			<definition id="1">
				<sentence>Each frame consists of a keyword profile ( a list of salient terms derived from human-human dialogues ) and a prompt sequence , which is a list of attributes whose values must be collected in order to complete the transaction .</sentence>
				<definiendum id="0">prompt sequence</definiendum>
				<definiens id="0">a keyword profile ( a list of salient terms derived from human-human dialogues</definiens>
				<definiens id="1">a list of attributes whose values must be collected in order to complete the transaction</definiens>
			</definition>
			<definition id="2">
				<sentence>The User ID Frame Router operates analogously , with each frame representing a different user ( customer ) .</sentence>
				<definiendum id="0">User ID Frame Router</definiendum>
				<definiens id="0">operates analogously , with each frame representing a different user</definiens>
			</definition>
</paper>

		<paper id="2005">
			<definition id="0">
				<sentence>A phrasal term consists of two adjacentwords in the query string .</sentence>
				<definiendum id="0">phrasal term</definiendum>
			</definition>
			<definition id="1">
				<sentence>Value ) Each candidate in the pool is givenaTDV which represents \goodness '' of the term to retrieve documents in the target domain .</sentence>
				<definiendum id="0">Value</definiendum>
				<definiens id="0">givenaTDV which represents \goodness '' of the term to retrieve documents in the target domain</definiens>
			</definition>
			<definition id="2">
				<sentence>The candidates are ranked on the TDVand top-ranked n terms are selected as query terms , where n is an unknown constant and treated as a tuning parameter for fullautomatic retrieval .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">an unknown constant and treated as a tuning parameter for fullautomatic retrieval</definiens>
			</definition>
			<definition id="3">
				<sentence>We give some instances of TV using two probabilities p and q , where p is a probability that the term occurs in the target domain and q is a probability that the term occurs in the query domain .</sentence>
				<definiendum id="0">p</definiendum>
				<definiendum id="1">q</definiendum>
				<definiens id="0">a probability that the term occurs in the target domain and</definiens>
				<definiens id="1">a probability that the term occurs in the query domain</definiens>
			</definition>
			<definition id="4">
				<sentence>QV2 : Term frequency model QV = tf QV3 : Term weight model QV = weight where weight is the retrieval weight given by the retrieval system .</sentence>
				<definiendum id="0">weight</definiendum>
				<definiens id="0">the retrieval weight given by the retrieval system</definiens>
			</definition>
</paper>

		<paper id="1731">
</paper>

		<paper id="0321">
</paper>

		<paper id="1313">
			<definition id="0">
				<sentence>The GENIA ontology is a taxonomy of , currently , 47 biologically relevant nominal categories , such as body part , virus , or RNA domain or region ; the taxonomy has 35 terminal categories .</sentence>
				<definiendum id="0">GENIA ontology</definiendum>
				<definiens id="0">a taxonomy of , currently , 47 biologically relevant nominal categories , such as body part , virus , or RNA domain or region</definiens>
			</definition>
			<definition id="1">
				<sentence>The GENIA corpus is encoded in the Genia Project Markup Language .</sentence>
				<definiendum id="0">GENIA corpus</definiendum>
				<definiens id="0">encoded in the Genia Project Markup Language</definiens>
			</definition>
			<definition id="2">
				<sentence>The GPML is an XML DTD ( Kim et al. , 2001 ) where each article contains its MEDLINE ID , title and abstract .</sentence>
				<definiendum id="0">GPML</definiendum>
				<definiens id="0">an XML DTD ( Kim et al. , 2001 ) where each article contains its MEDLINE ID , title and abstract</definiens>
			</definition>
			<definition id="3">
				<sentence>The Text Encoding Initiative was established in 1987 as a systematised attempt to develop a fully general text encoding model and set of encoding conventions based upon it , suitable for processing and analysis of any type of text , in any language , and intended to serve the increasing range of existing ( and potential ) applications and uses .</sentence>
				<definiendum id="0">Text Encoding Initiative was</definiendum>
				<definiens id="0">established in 1987 as a systematised attempt to develop a fully general text encoding model and set of encoding conventions based upon it , suitable for processing</definiens>
			</definition>
			<definition id="4">
				<sentence>The XML prolog given in this Figure defines that hteiCorpus.2i is the root element of the corpus , that the external DTD resides at the given URL belonging to the TEI Consortium , and that a number of TEI modules , detailed below , are being used to parametrise the TEI to arrive at our particular DTD .</sentence>
				<definiendum id="0">XML prolog</definiendum>
				<definiens id="0">the root element of the corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>XML option indicates that the target DTD is to be expressed in XML .</sentence>
				<definiendum id="0">DTD</definiendum>
			</definition>
			<definition id="6">
				<sentence>The TEI header describes an encoded work so that the text ( corpus ) itself , its source , its encoding , and its revisions are all thoroughly documented .</sentence>
				<definiendum id="0">TEI header</definiendum>
			</definition>
			<definition id="7">
				<sentence>The transformation is written as a XSLT stylesheet , which makes reference to two documents : the GENIA ontology in TEI and the template for the corpus header .</sentence>
				<definiendum id="0">XSLT stylesheet</definiendum>
				<definiens id="0">makes reference to two documents : the GENIA ontology in TEI and the template for the corpus header</definiens>
			</definition>
			<definition id="8">
				<sentence>Tokenisation , i.e. , the identification of words and punctuation marks , is the lowest level of linguistic analysis , yet is , in spite ( or because ) of this of considerable importance .</sentence>
				<definiendum id="0">Tokenisation</definiendum>
				<definiens id="0">the identification of words and punctuation marks</definiens>
			</definition>
			<definition id="9">
				<sentence>In such cases by parsing the coordination all the terms can be identified and annotated ; the TEI encoding achieves this by specifyng the propositional formula involving the participating concepts in the function attribute ; for example , hcl function=” ( AND G.tissue G.tissue ) ” ana=”G.tissue”ihclinormalh=cli and hclihypopigmentedh=clihcliskin samplesh=clih=cli .</sentence>
				<definiendum id="0">TEI encoding</definiendum>
				<definiens id="0">achieves this by specifyng the propositional formula involving the participating concepts in the function attribute</definiens>
			</definition>
			<definition id="10">
				<sentence>In TEI they are XML ID attributes , &lt; daml : Class rdf : ID= '' source '' &gt; &lt; /daml : Class &gt; &lt; taxonomy id= '' G.taxonomy '' &gt; &lt; daml : Class rdf : ID= '' natural '' &gt; &lt; category id= '' G.source '' &gt; &lt; rdfs : subClassOf rdf : resource= '' # source '' / &gt; &lt; catDesc &gt; biological source &lt; /catDesc &gt; &lt; /daml : Class &gt; &lt; category id= '' G.natural '' &gt; &lt; daml : Class rdf : ID= '' organism '' &gt; &lt; catDesc &gt; natural &lt; /catDesc &gt; &lt; rdfs : subClassOf rdf : resource= '' # natural '' / &gt; &lt; category id= '' G.organism '' &gt; &lt; /daml : Class &gt; &lt; catDesc &gt; organism &lt; /catDesc &gt; &lt; daml : Class rdf : ID= '' multi_cell '' &gt; &lt; category id= '' G.multi_cell '' &gt; &lt; rdfs : subClassOf rdf : resource= '' # organism '' / &gt; &lt; catDesc &gt; multi-cellular &lt; /catDesc &gt; &lt; /daml : Class &gt; &lt; /category &gt; ... ... Figure 4 : The GENIA DAML+OIL and TEI ontology and can rely on the XML parser to resolve them .</sentence>
				<definiendum id="0">XML ID</definiendum>
				<definiendum id="1">Class rdf</definiendum>
				<definiens id="0">biological source &lt; /catDesc &gt; &lt; /daml : Class &gt; &lt; category id= '' G.natural '' &gt;</definiens>
			</definition>
			<definition id="11">
				<sentence>The GENIA Corpus : an Annotated Research Abstract Corpus in Molecular Biology Domain .</sentence>
				<definiendum id="0">GENIA Corpus</definiendum>
			</definition>
</paper>

		<paper id="0109">
			<definition id="0">
				<sentence>A linguistic analyser of spatial expressions ( nominal and prepositional phrases ) have been designed , which recognise them and produces a symbolic representation of their `` content '' .</sentence>
				<definiendum id="0">linguistic analyser of spatial expressions</definiendum>
				<definiens id="0">nominal and prepositional phrases ) have been designed , which recognise them and produces a symbolic representation of their `` content ''</definiens>
			</definition>
			<definition id="1">
				<sentence>It is defined by four possible sub-features : • “egn” ( named geographical entity ) with the name and type of this entity ; • the “coord” field gives the coordinates of the named place , when available .</sentence>
				<definiendum id="0">“coord” field</definiendum>
				<definiens id="0">four possible sub-features : • “egn” ( named geographical entity ) with the name and type of this entity ; • the</definiens>
				<definiens id="1">gives the coordinates of the named place , when available</definiens>
			</definition>
			<definition id="2">
				<sentence>• Geometrically defined zones : `` le triangle AvignonAix-Marseille '' ( the Avignon-Aix-Marseille triangle ) ; and areas defined by some kind of bounds : `` du Sud-Ouest à la Bourgogne '' ( from South-West to Burgundy ) .</sentence>
				<definiendum id="0">le triangle AvignonAix-Marseille ''</definiendum>
			</definition>
			<definition id="3">
				<sentence>For example , consider the query “find passages concening the city of Caen” , with respect to passages mentionning “Caen” itself , “the Calvados” ( department to which Caen belongs ) , “BasseNormandie” ( Caen’s administrative Region ) , and finally “the northern half of France” .</sentence>
				<definiendum id="0">“BasseNormandie”</definiendum>
				<definiens id="0">administrative Region ) , and finally “the northern half of France”</definiens>
			</definition>
</paper>

		<paper id="0606">
			<definition id="0">
				<sentence>Extraction of Meaning In this developmental context , Mandler ( 1999 ) suggested that the infant begins to construct meaning from the scene based on the extraction of perceptual primitives .</sentence>
				<definiendum id="0">Extraction of Meaning In</definiendum>
				<definiens id="0">the infant begins to construct meaning from the scene based on the extraction of perceptual primitives</definiens>
			</definition>
			<definition id="1">
				<sentence>A video camera above the surface provides a video image that is processed by a color-based recognition and tracking system ( Smart – Panlab , Barcelona Spain ) that generates a time ordered sequence of the contacts that occur between objects that is subsequently processed for event analysis ( below ) .</sentence>
				<definiendum id="0">video camera</definiendum>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>The function produces a probability distribution ( a vector ) over a26 a27 , the a31a20a32a34a33a36a35 element being the conditional probability of the a31a10a32a37a33a36a35 member of a26 a27 .</sentence>
				<definiendum id="0">probability distribution</definiendum>
			</definition>
			<definition id="1">
				<sentence>A softmax function ( Equation 4 ) is used at the output of the neural net to make sure probabilities sum to 1 .</sentence>
				<definiendum id="0">softmax function</definiendum>
				<definiens id="0">used at the output of the neural net to make sure probabilities sum to 1</definiens>
			</definition>
			<definition id="2">
				<sentence>Training is achieved by searching for parameters a38 of the neural network and the values of feature vectors that maximize the penalized log-likelihood of the training corpus : a39a41a40a43a42 a44a2a45a47a46a49a48 a27a51a50a53a52a29a54a56a55 a46a58a57a59a10a46 a42a36a60a62a61a62a61a62a61a62a60 a59a10a46a63a10a64 a42a58a65a66a68a67 a19a25a69 a54 a66a68a67 ( 1 ) where a0a2a1a4a3a71a70a53a5a7a25a70a8 a9a16a72a73a72a73a72a73a9a11a7a18a70a17a20a19a21a8 a22 is the probability of word a3 a70 ( network output at time a33 ) , a74 is the training data size and a75 a1a76a38a77a22 is a regularization term , sum of the parameters’ squares in our case .</sentence>
				<definiendum id="0">a74</definiendum>
				<definiens id="0">the training data size and a75 a1a76a38a77a22 is a regularization term</definiens>
			</definition>
			<definition id="3">
				<sentence>The neural network is a simple fully connected network with one hidden layer and sigmoid transfer functions .</sentence>
				<definiendum id="0">neural network</definiendum>
			</definition>
			<definition id="4">
				<sentence>More specifically , the output of the hidden layer is given by : a0a2a1 a40a4a3a6a5a8a7a10a9 a54 a45 a11 a63 a64 a42a13a12a15a14 a16a18a17 a42 a19 a16a21a20 a1 a16a23a22a25a24a27a26 a1 a67 a28 a40 a8 a60 a12 a60a62a61a62a61a62a61a60a29 ( 2 ) where a35 a28 is the a30 a32 a33a11a35 output of the hidden layer , a31a33a32 is the a34 a32 a33a11a35 input of the network , a35 a28 a32 and a36 a0 a28are weight and bias elements for the hidden layer respectively , and a37 is the number of hidden units .</sentence>
				<definiendum id="0">a35 a28</definiendum>
				<definiendum id="1">a31a33a32</definiendum>
				<definiendum id="2">a37</definiendum>
				<definiens id="0">the a30 a32 a33a11a35 output of the hidden layer</definiens>
				<definiens id="1">the a34 a32 a33a11a35 input of the network , a35 a28 a32 and a36 a0 a28are weight and bias elements for the hidden layer respectively</definiens>
				<definiens id="2">the number of hidden units</definiens>
			</definition>
			<definition id="5">
				<sentence>The language model probability assignment for the word at position a30a16a15 a1 in the input sentence is made using : a52a18a17a20a19 a14 a54a60a59 a1 a57 a42 a57 a20 a1 a67 a46 a45a22a21 a1a24a23 a17 a1 a52a29a54a60a59 a1 a57 a42 a57 a20 a1 a55 a1 a67a63a61a25 a54 a20 a1 a60a55 a1 a67 a60 a25 a54 a20 a1 a60a55 a1 a67 a46 a52a29a54 a20 a1 a55 a1 a67a27a26 a45a28a21 a1 a23 a17 a1 a52a29a54 a20 a1 a55 a1 a67 a60 ( 6 ) which ensures a proper probability normalization over strings a35a30a29 , where a31 a28 is the set of all parses present in our stacks at the current stage a30 .</sentence>
				<definiendum id="0">language model probability assignment</definiendum>
			</definition>
			<definition id="6">
				<sentence>According to the EM algorithm , the auxiliary function can be written as : a32 a54a34a33 a60a36a35 a33 a67 a40 a45a37a21 a52a29a54 a55 a57 a20 a65a36a35 a33 a67 a48 a27a51a50a53a52a29a54 a20 a60a55a6a65 a33 a67 a61 ( 7 ) The E step in the EM algorithm is to find a0a2a1a13a48 a5 a35a39a38a41a40 a42 a22 under the model parameters a40 a42 of the previous iteration , the M step is to find parameters a42 that maximize the auxiliary function a43 a1 a42 a9 a40a42 a22 above .</sentence>
				<definiendum id="0">M step</definiendum>
				<definiens id="0">to find a0a2a1a13a48 a5 a35a39a38a41a40 a42 a22 under the model parameters a40 a42 of the previous iteration , the</definiens>
			</definition>
			<definition id="7">
				<sentence>In the results of Table 2 , the trigram model is a Kneser-Ney smoothed model that gave PPL of 149.6 by itself .</sentence>
				<definiendum id="0">trigram model</definiendum>
			</definition>
</paper>

		<paper id="1120">
			<definition id="0">
				<sentence>Since the Web consists of documents in various domains or genres , the method for Cross-Language Information Retrieval ( CLIR ) of Web documents should be independent of a particular domain .</sentence>
				<definiendum id="0">Web</definiendum>
				<definiens id="0">consists of documents in various domains or genres , the method for Cross-Language Information Retrieval ( CLIR ) of Web documents should be independent of a particular domain</definiens>
			</definition>
			<definition id="1">
				<sentence>Feature term set is a set of terms that seem to distinguish the category .</sentence>
				<definiendum id="0">Feature term set</definiendum>
				<definiens id="0">a set of terms that seem to distinguish the category</definiens>
			</definition>
			<definition id="2">
				<sentence>TF¢ICF is calculated as follows : tf ¢icf ( ti ; c ) = f ( ti ) N c ¢log Nn i +1 where ti is the term appearing in the category c , f ( ti ) is the term frequency of term ti , Nc is the total number of terms in the category c , ni is number of the categories that contain the term ti|and N is the number of all categories in the directory .</sentence>
				<definiendum id="0">TF¢ICF</definiendum>
				<definiendum id="1">ti</definiendum>
				<definiendum id="2">Nc</definiendum>
				<definiendum id="3">N</definiendum>
				<definiens id="0">the term appearing in the category c , f ( ti ) is the term frequency of term ti</definiens>
				<definiens id="1">the total number of terms in the category c , ni is number of the categories that contain the term ti|and</definiens>
			</definition>
			<definition id="3">
				<sentence>The similarity between the source category a and the target category b is calculated as the total of multiplying the weights of each feature term in the category a by the weight of its translation in the category b. The similarity of the category a for the category b is calculated as follows : sim ( a ; b ) = X f2fa w ( f ; a ) ¢w ( t ; b ) where f is a feature term , fa is the feature term set of category a , t is the translation of f in the category feature term set of category a feature term set of category bfeature term f translation candidates t1 t2 t3 .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">fa</definiendum>
			</definition>
			<definition id="4">
				<sentence>We define the query vector ~q as follows : ~q = ( q1 ; q2 ; : : : ; qn ) where qk is the weight of the k-th keyword in the query .</sentence>
				<definiendum id="0">query vector ~q</definiendum>
				<definiendum id="1">qk</definiendum>
				<definiens id="0">the weight of the k-th keyword in the query</definiens>
			</definition>
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>Anaphora resolution is one of the most important research topics in Natural Language Processing .</sentence>
				<definiendum id="0">Anaphora resolution</definiendum>
			</definition>
			<definition id="1">
				<sentence>A Japanese sentence is a sequence of bunsetsus : a0a2a1a4a3a6a5a7a5a6a5a8a3a7a0a10a9 .</sentence>
				<definiendum id="0">Japanese sentence</definiendum>
			</definition>
			<definition id="2">
				<sentence>A bunsetsu is a sequence of content words ( e.g. , nouns , adjectives , and verbs ) followed by zero or more functional words ( e.g. , particles and auxiliary verbs ) : a0a12a11 a13 a1 a3a6a5a7a5a6a5a14a3 a13a16a15 a3a7a17 a1 a3a7a5a6a5a7a5a8a3a6a17a19a18 .</sentence>
				<definiendum id="0">bunsetsu</definiendum>
				<definiens id="0">a sequence of content words ( e.g. , nouns , adjectives , and verbs ) followed by zero or more functional words</definiens>
			</definition>
			<definition id="3">
				<sentence>A zero’s bunsetsu is a bunsetsu that contains the zero .</sentence>
				<definiendum id="0">zero’s bunsetsu</definiendum>
				<definiens id="0">a bunsetsu that contains the zero</definiens>
			</definition>
			<definition id="4">
				<sentence>a36 ’s particle is denoted ZP , and CP stands for a37 ’s next word that is a37 ’s particle or a punctuation symbol .</sentence>
				<definiendum id="0">CP</definiendum>
				<definiens id="0">a37 ’s particle or a punctuation symbol</definiens>
			</definition>
			<definition id="5">
				<sentence>If a37 is dou-sha ( the company ) , it is replaced by the latest organization name .</sentence>
				<definiendum id="0">dou-sha</definiendum>
				<definiens id="0">the company ) , it is replaced by the latest organization name</definiens>
			</definition>
			<definition id="6">
				<sentence>For instance , we can use a lexicographically increasing order defined by a21 Via3 Rea3 Aga3 Dia3 Saa26 , where a45 Vi ( for violation ) is 1 if the candidate violates the semantic constraint .</sentence>
				<definiendum id="0">a45 Vi</definiendum>
				<definiens id="0">1 if the candidate violates the semantic constraint</definiens>
			</definition>
			<definition id="7">
				<sentence>Siblings When CP is wa or mo , it is not clear whether a37 is a subject .</sentence>
				<definiendum id="0">CP</definiendum>
				<definiens id="0">a subject</definiens>
			</definition>
			<definition id="8">
				<sentence>Sahen meishi is a kind of noun that can be an object of the verb ‘suru’ ( do ) ( e.g. , ‘shopping’ in ‘do the shopping’ ) .</sentence>
				<definiendum id="0">Sahen meishi</definiendum>
				<definiens id="0">a kind of noun that can be an object of the verb ‘suru’ ( do )</definiens>
			</definition>
			<definition id="9">
				<sentence>By using the training data , SVM finds a decision function a58 a21 a54 a26a59a11 a53 a56 a53a8a60a27a53a62a61 a21 a54 a3a38a63 a53 a26a65a64a66a0 , where a54 is the feature vector of a candidate a37 and a63 a53 s are support vectors selected from the training data .</sentence>
				<definiendum id="0">SVM</definiendum>
				<definiendum id="1">a54</definiendum>
				<definiens id="0">the feature vector of a candidate a37 and a63 a53 s are support vectors selected from the training data</definiens>
			</definition>
			<definition id="10">
				<sentence>‘Svm1’ uses the ordinary SVM ( Vapnik , 1995 ) while ‘svm2’ uses a modified SVM for unbalanced data ( Morik et al. , 1999 ) , which gives a large penalty to misclassification of a minority ( = positive ) example.5 In general , svm2 accepts more cadidates than svm1 .</sentence>
				<definiendum id="0">ordinary SVM</definiendum>
				<definiens id="0">uses a modified SVM for unbalanced data ( Morik et al. , 1999 ) , which gives a large penalty to misclassification of a minority ( = positive ) example.5 In general , svm2 accepts more cadidates than svm1</definiens>
			</definition>
</paper>

		<paper id="0401">
			<definition id="0">
				<sentence>However , existing models of disambiguation with lexicalized grammars are a mere extension of lexicalized probabilistic context-free grammars ( LPCFG ) ( Collins , 1996 ; Collins , 1997 ; Charniak , 1997 ) , which are based on the decomposition of parsing results into the syntactic/semantic dependencies of two words in a sentence under the assumption of independence of the dependencies .</sentence>
				<definiendum id="0">lexicalized grammars</definiendum>
			</definition>
			<definition id="1">
				<sentence>Since the sequence of syntactic categories restricts the possible structure of parsing results , the semantics probability is a conditional probability without decomposition into the primitive dependencies of words .</sentence>
				<definiendum id="0">semantics probability</definiendum>
				<definiens id="0">a conditional probability without decomposition into the primitive dependencies of words</definiens>
			</definition>
			<definition id="2">
				<sentence>p ( T ) = productdisplay i p ( w h i , w n i , r i |η ) , where η is a condition of the probability , which is usually the nonterminal symbol of the mother node .</sentence>
				<definiendum id="0">η</definiendum>
				<definiens id="0">a condition of the probability , which is usually the nonterminal symbol of the mother node</definiens>
			</definition>
			<definition id="3">
				<sentence>A dependency structure is formally defined as a set of dependencies : S = { 〈w h i , w n i , η i 〉 } , where w h i and w n i are a head and argument word of the dependency , and η i is an argument position of the head word filled by the argument word .</sentence>
				<definiendum id="0">η i</definiendum>
				<definiens id="0">a set of dependencies : S = { 〈w h i , w n i , η i 〉 }</definiens>
			</definition>
			<definition id="4">
				<sentence>A lexicalized grammar is Lexicalized parse tree 〈write , what , S→ write S〉 , 〈write , does , S→ does S〉 , 〈write , student , S→ NP VP〉 , 〈student , your , NP→ your student〉 , 〈write , want , VP→ want VP〉 , 〈write , to , VP→ to write〉 Derivation tree 〈write , what , SUBST〉 , 〈write , does , ADJ〉 , 〈write , student , SUBST〉 , 〈student , your , ADJ〉 , 〈write , want , ADJ〉 , 〈write , to , ADJ〉 Dependency structure 〈write , what , ARG2〉 , 〈write , does , MODIFY〉 , 〈write , student , ARG1〉 , 〈student , your , MODIFY〉 , 〈write , want , MODIFY〉 , 〈want , student , ARG1〉 , 〈write , to , MODIFY〉 Figure 5 : Parsing results of lexicalized grammars then defined as a tuple G = 〈L , R〉 , where L = { l = 〈w , c〉|w ∈W , c ∈C } is a lexicon and R is a set of grammar rules .</sentence>
				<definiendum id="0">lexicalized grammar</definiendum>
				<definiendum id="1">R</definiendum>
				<definiens id="0">Lexicalized parse tree 〈write , what , S→ write S〉 , 〈write , does , S→ does S〉 , 〈write , student , S→ NP VP〉 , 〈student , your , NP→ your student〉 , 〈write , want , VP→ want VP〉 , 〈write , to , VP→ to write〉 Derivation tree 〈write , what , SUBST〉 , 〈write , does , ADJ〉 , 〈write , student , SUBST〉 , 〈student , your , ADJ〉 , 〈write , want , ADJ〉 , 〈write , to , ADJ〉 Dependency structure 〈write , what , ARG2〉 , 〈write , does , MODIFY〉 , 〈write , student , ARG1〉 , 〈student , your , MODIFY〉 , 〈write , want , MODIFY〉 , 〈want , student , ARG1〉 , 〈write , to , MODIFY〉 Figure 5 : Parsing results of lexicalized grammars then defined as a tuple G = 〈L , R〉 , where L = { l = 〈w , c〉|w ∈W</definiens>
				<definiens id="1">a lexicon and</definiens>
				<definiens id="2">a set of grammar rules</definiens>
			</definition>
			<definition id="5">
				<sentence>A parsing result of lexicalized grammars is defined as a labeled graph structure A = { a|a = 〈l h , l n , d〉 } , where a is an edge representing the dependency of head l h and argument l n labeled with d.For example , the lexicalized parse tree in Figure 2 is represented in this form as in Figure 5 , as well as the derivation tree and the dependency structure .</sentence>
				<definiendum id="0">lexicalized grammars</definiendum>
				<definiens id="0">a labeled graph structure A = { a|a = 〈l h , l n , d〉 } , where a is an edge representing the dependency of head l h and argument l n labeled with d.For example , the lexicalized parse tree</definiens>
			</definition>
			<definition id="6">
				<sentence>p ( c|w ) = productdisplay i p ( c i |w i ) The second describes the probability of semantics , which expresses the semantic preferences of relating the words in a sentence .</sentence>
				<definiendum id="0">p</definiendum>
				<definiens id="0">expresses the semantic preferences of relating the words in a sentence</definiens>
			</definition>
			<definition id="7">
				<sentence>Since semantics probability can not be decomposed into independent sub-events , we applied a maximum entropy model , which allowed probabilistic modeling without the independence assumption .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
				<definiens id="0">allowed probabilistic modeling without the independence assumption</definiens>
			</definition>
			<definition id="8">
				<sentence>Given parsing result A , semantics probability is defined as follows : p ( A|c ) = 1 Z c exp   summationdisplay s∈S ( A ) λ ( s )   Z c = summationdisplay A prime ∈A ( c ) exp   summationdisplay s prime ∈S ( A prime ) λ ( s prime )   , where S ( A ) is a set of connected subgraphs of A , λ ( s ) is a weight of subgraph s , and A ( c ) is a set of parsing results allowed by the sequence of syntactic categories c. Since we aim at separating syntactic and semantic preferences , feature functions for semantic probability distinguish only words , not syntactic categories .</sentence>
				<definiendum id="0">semantics probability</definiendum>
				<definiendum id="1">S ( A )</definiendum>
				<definiendum id="2">λ</definiendum>
				<definiendum id="3">A ( c )</definiendum>
				<definiens id="0">follows : p ( A|c ) = 1 Z c exp   summationdisplay s∈S ( A ) λ ( s )   Z c = summationdisplay A prime ∈A ( c ) exp   summationdisplay s prime ∈S ( A prime ) λ ( s prime )  </definiens>
				<definiens id="1">a set of connected subgraphs of A ,</definiens>
			</definition>
			<definition id="9">
				<sentence>It can be applied to any parsing results given by a lexicalized grammar , does not require the independence assumption , and is defined as a combination of syntax and semantics probabilities , where the semantics probability is a discriminative model that selects a parsing result from the set of candidates given by the syntax probability .</sentence>
				<definiendum id="0">lexicalized grammar</definiendum>
				<definiendum id="1">the semantics probability</definiendum>
				<definiens id="0">a discriminative model that selects a parsing result from the set of candidates given by the syntax probability</definiens>
			</definition>
</paper>

		<paper id="2003">
			<definition id="0">
				<sentence>IPC ( International Patent Classification ) is the most popular one .</sentence>
				<definiendum id="0">IPC</definiendum>
				<definiendum id="1">Patent Classification )</definiendum>
			</definition>
</paper>

		<paper id="0412">
			<definition id="0">
				<sentence>This paper introduces PhraseNet , a contextsensitive lexical semantic knowledge base system .</sentence>
				<definiendum id="0">PhraseNet</definiendum>
				<definiens id="0">a contextsensitive lexical semantic knowledge base system</definiens>
			</definition>
			<definition id="1">
				<sentence>PhraseNet makes use of WordNet as an important knowledge source .</sentence>
				<definiendum id="0">PhraseNet</definiendum>
				<definiens id="0">an important knowledge source</definiens>
			</definition>
			<definition id="2">
				<sentence>In its current design , PhraseNet defines “context” hierarchically with three abstraction levels : abstract syntactic skeletons , such as [ ( S ) ¡ ( V ) ¡ ( DO ) ¡ ( IO ) ¡ ( P ) ¡ ( N ) ] which stands for Subject , Verb , Direct Object , Indirect Object , Preposition and Noun ( Object ) of the Preposition , respectively ; syntactic skeletons whose components are enhanced by semantic abstraction , such as [ Peop ¡ send ¡ Peop ¡ gift ¡ on ¡ Day ] and finally concrete syntactic skeletons from real sentences as [ they ¡send¡mom¡gift¡on¡Christmas ] .</sentence>
				<definiendum id="0">PhraseNet</definiendum>
				<definiens id="0">defines “context” hierarchically with three abstraction levels : abstract syntactic skeletons</definiens>
			</definition>
			<definition id="3">
				<sentence>While still in preliminary stages of development and experimentation and with a lot of functionalities still missing , we believe that PhraseNet is an important effort towards building a contextually sensitive lexical semantic resource , that will be of much value to NLP researchers as well as linguists and language learners .</sentence>
				<definiendum id="0">PhraseNet</definiendum>
				<definiens id="0">an important effort towards building a contextually sensitive lexical semantic resource , that will be of much value to NLP researchers as well as linguists and language learners</definiens>
			</definition>
			<definition id="4">
				<sentence>The lowest level of contexts is the concrete instantiation of the stated syntactic skeleton , such as [ Mary ( S ) ¡give ( V ) ¡ John ( DO ) ¡ gift ( IO ) ¡ on ( P ) ¡ birthday ( N ) ] and 2See details in Sec .</sentence>
				<definiendum id="0">lowest level of contexts</definiendum>
				<definiens id="0">the concrete instantiation of the stated syntactic skeleton , such as [ Mary ( S ) ¡give ( V ) ¡ John ( DO ) ¡ gift ( IO ) ¡ on ( P ) ¡ birthday ( N ) ] and 2See details in Sec</definiens>
			</definition>
			<definition id="5">
				<sentence>PhraseNet organizes nouns and verbs into “consets” and a “conset” is defined as a context with all its corresponding pointers ( edges ) to other consets .</sentence>
				<definiendum id="0">PhraseNet</definiendum>
				<definiendum id="1">“conset”</definiendum>
				<definiens id="0">organizes nouns and verbs into “consets” and a</definiens>
				<definiens id="1">a context with all its corresponding pointers ( edges ) to other consets</definiens>
			</definition>
			<definition id="6">
				<sentence>Each node is a context and edges between nodes are relations defined by the context of each node .</sentence>
				<definiendum id="0">node</definiendum>
				<definiens id="0">a context and edges between nodes are relations defined by the context of each node</definiens>
			</definition>
			<definition id="7">
				<sentence>PN RL is a family of functions , modelled after WordNet relations .</sentence>
				<definiendum id="0">PN RL</definiendum>
			</definition>
			<definition id="8">
				<sentence>The functions are described below : PN WL takes the optional contextual skeleton and one specified word in that context as inputs and returns the corresponding wordlist occurring in that context or a higher level of context .</sentence>
				<definiendum id="0">PN WL</definiendum>
				<definiens id="0">takes the optional contextual skeleton</definiens>
			</definition>
			<definition id="9">
				<sentence>For example , for the partial context [ strategy ¡ involve¡⁄¡⁄¡⁄ ] , we have : [ strategy involve * * * , &lt; DO : advertisement 4 , abuse 1 , campaign 2 , compromise 1 , everything 1 , fumigation 1 , item 1 , membership 1 , option 3 , stockoption 1 &gt; ] In this case , “strategy” is the subject and “involve” is the predicate and all words in the list serve as the direct object .</sentence>
				<definiendum id="0">“strategy”</definiendum>
				<definiendum id="1">“involve”</definiendum>
				<definiens id="0">the subject and</definiens>
			</definition>
			<definition id="10">
				<sentence>Question classification ( QC ) is the task of determining the semantic class of the answer of a given question .</sentence>
				<definiendum id="0">QC</definiendum>
				<definiens id="0">the task of determining the semantic class of the answer of a given question</definiens>
			</definition>
			<definition id="11">
				<sentence>Performance is evaluated by the precision of classifying 1,000 test questions , defined as follows : Precison = # of correct predictions # of predictions ( 2 ) Table 2 presents the classification precision before and after incorporating WordNet and PhraseNet information into the classifier .</sentence>
				<definiendum id="0">Performance</definiendum>
				<definiens id="0">evaluated by the precision of classifying 1,000 test questions</definiens>
				<definiens id="1">PhraseNet information into the classifier</definiens>
			</definition>
			<definition id="12">
				<sentence>FrameNet ( Baker et al. , 1998 ) produces a semantic dictionary that documents combinatorial properties of English lexical items in semantic and syntactic terms based on attestations in a very large corpus .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">produces a semantic dictionary that documents combinatorial properties of English lexical items in semantic and syntactic terms based on attestations in a very large corpus</definiens>
			</definition>
			<definition id="13">
				<sentence>With hierarchical sentential local contexts embedded and used to categorize word classes automatically , we believe that PhraseNet provides the right direction for building useful lexical semantic database .</sentence>
				<definiendum id="0">PhraseNet</definiendum>
				<definiens id="0">provides the right direction for building useful lexical semantic database</definiens>
			</definition>
			<definition id="14">
				<sentence>PhraseNet is an ongoing project and is still in its preliminary stage .</sentence>
				<definiendum id="0">PhraseNet</definiendum>
			</definition>
</paper>

		<paper id="0419">
			<definition id="0">
				<sentence>This sentence contains three named entities : Ekeus is a person , U.N. is a organization and Baghdad is a location .</sentence>
				<definiendum id="0">Ekeus</definiendum>
				<definiendum id="1">U.N.</definiendum>
				<definiendum id="2">Baghdad</definiendum>
				<definiens id="0">a organization</definiens>
			</definition>
			<definition id="1">
				<sentence>Aff : affix information ( n-grams ) ; bag : bag of words ; cas : global case information ; chu : chunk tags ; doc : global document information ; gaz : gazetteers ; lex : lexical features ; ort : orthographic information ; pat : orthographic patterns ( like Aa0 ) ; pos : part-of-speech tags ; pre : previously predicted NE tags ; quo : flag signing that the word is between quotes ; tri : trigger words .</sentence>
				<definiendum id="0">Aff</definiendum>
				<definiens id="0">affix information ( n-grams ) ; bag : bag of words ; cas : global case information ; chu : chunk tags ; doc : global document information</definiens>
				<definiens id="1">orthographic information</definiens>
			</definition>
			<definition id="2">
				<sentence>Precision is the percentage of named entities found by the learning system that are correct .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the percentage of named entities found by the learning system that are correct</definiens>
			</definition>
			<definition id="3">
				<sentence>Recall is the percentage of named entities present in the corpus that are found by the system .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the percentage of named entities present in the corpus that are found by the system</definiens>
			</definition>
			<definition id="4">
				<sentence>A Robust Risk Minimization based Named Entity Recognition System .</sentence>
				<definiendum id="0">Robust Risk Minimization</definiendum>
				<definiens id="0">based Named Entity Recognition System</definiens>
			</definition>
</paper>

		<paper id="0310">
			<definition id="0">
				<sentence>For example , the Candide system ( Berger et al. , 1994 ) was trained on ten years’ worth of Canadian Parliament proceedings , which consists of 2.87 million parallel sentences in French and English .</sentence>
				<definiendum id="0">Candide system</definiendum>
				<definiens id="0">consists of 2.87 million parallel sentences in French and English</definiens>
			</definition>
			<definition id="1">
				<sentence>Co-training is a weakly supervised learning techniques which uses an initially small amount of human labeled data to automatically bootstrap larger sets of machine labeled training data .</sentence>
				<definiendum id="0">Co-training</definiendum>
				<definiens id="0">a weakly supervised learning techniques which uses an initially small amount of human labeled data to automatically bootstrap larger sets of machine labeled training data</definiens>
			</definition>
			<definition id="2">
				<sentence>Self-training is a weakly supervised method in which a single learner retrains on the labels that it applies to unlabeled data itself .</sentence>
				<definiendum id="0">Self-training</definiendum>
			</definition>
</paper>

		<paper id="1000">
</paper>

		<paper id="1806">
			<definition id="0">
				<sentence>Positional ngrams are nothing more than ordered vectors of textual units which principles are introduced in the next subsection .</sentence>
				<definiendum id="0">Positional ngrams</definiendum>
				<definiens id="0">are nothing more than ordered vectors of textual units which principles are introduced in the next subsection</definiens>
			</definition>
			<definition id="1">
				<sentence>Positional word 2grams Positional word 3grams [ Ngram Statistics ] [ Ngram Statistics from ] [ Ngram ___ from ] [ Ngram Statistics ___ Large ] [ Ngram ___ ___ Large ] [ Ngram ___ from Large ] [ to ___ Ngram ] [ to ___ Ngram ___ from ] Table 1 : Possible positional ngrams Generically , any positional word ngram may be defined as a vector of words [ p 11 u 1 p 12 u 2 … p 1n u n ] where u i stands for any word in the positional ngram and p 1i represents the distance that separates words u 1 and u i 2 .</sentence>
				<definiendum id="0">Positional word</definiendum>
				<definiens id="0">2grams Positional word 3grams [ Ngram Statistics ] [ Ngram Statistics from ] [ Ngram ___ from ] [ Ngram Statistics ___ Large ] [ Ngram ___ ___ Large ] [ Ngram ___ from Large ] [ to ___ Ngram ] [ to ___ Ngram ___ from ] Table 1 : Possible positional ngrams Generically , any positional word ngram may be defined as a vector of words [ p 11 u 1 p 12 u 2 … p 1n u n ] where u i stands for any word in the positional ngram and p 1i represents the distance that separates words u 1 and u i 2</definiens>
			</definition>
			<definition id="2">
				<sentence>A positional tag ngram is nothing more than an ordered vector of part-of-speech tags exactly in the same way a positional word ngram is an ordered vector of words .</sentence>
				<definiendum id="0">positional tag ngram</definiendum>
				<definiens id="0">an ordered vector of words</definiens>
			</definition>
			<definition id="3">
				<sentence>Generically , any positional tag ngram may be defined as a vector of part-of-speech tags [ p 11 t 1 p 12 t 2 … p 1n t n ] where t i stands for any part-of-speech tag in the positional tag ngram and p 1i represents the distance that separates the part-of-speech tags t 1 and t i .</sentence>
				<definiendum id="0">positional tag ngram</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Mutual Expectation ( ME ) has been introduced by Gaël Dias ( 2002 ) and evaluates the degree of cohesiveness that links together all the textual units contained in a positional ngram ( ∀n , n ≥ 2 ) based on the concept of Normalized Expectation and relative frequency .</sentence>
				<definiendum id="0">Mutual Expectation</definiendum>
				<definiendum id="1">positional ngram</definiendum>
				<definiens id="0">evaluates the degree of cohesiveness that links together all the textual units contained in a</definiens>
			</definition>
			<definition id="5">
				<sentence>As we said earlier , the ME is going to be used to calculate the degree cohesiveness of any positional word ngram and any positional tag ngram .</sentence>
				<definiendum id="0">ME</definiendum>
				<definiens id="0">going to be used to calculate the degree cohesiveness of any positional word ngram and any positional tag ngram</definiens>
			</definition>
			<definition id="6">
				<sentence>The GenLocalMaxs ( Gaël Dias , 2002 ) proposes a flexible and fine-tuned approach for the selection process as it concentrates on the identification of local maxima of association measure values .</sentence>
				<definiendum id="0">GenLocalMaxs</definiendum>
				<definiens id="0">proposes a flexible and fine-tuned approach for the selection process as it concentrates on the identification of local maxima of association measure values</definiens>
			</definition>
			<definition id="7">
				<sentence>Let cam be the combined association measure , W a positional word-tag ngram , Ω n-1 the set of all the positional word-tag ( n-1 ) grams contained in W , Ω n+1 the set of all the positional word-tag ( n+1 ) -grams containing W and sizeof ( . )</sentence>
				<definiendum id="0">positional word-tag</definiendum>
				<definiens id="0">a positional word-tag ngram , Ω n-1 the set of all the</definiens>
			</definition>
			<definition id="8">
				<sentence>The GenLocalMaxs is defined as : ∀x ∈Ω n-1 , ∀y ∈Ω n+1 , W is a MWU if ( sizeof ( W ) =2 ∧ cam ( W ) &gt; cam ( y ) ) ∨ ( sizeof ( W ) ≠2 ∧ cam ( W ) ≥ cam ( x ) ∧ cam ( W ) &gt; cam ( y ) ) Definition 1 : GenLocalMaxs Algorithm Among others , the GenLocalMaxs shows one important property : it does not depend on global thresholds .</sentence>
				<definiendum id="0">GenLocalMaxs</definiendum>
				<definiendum id="1">W</definiendum>
				<definiens id="0">∧ cam ( W ) ≥ cam ( x ) ∧ cam ( W ) &gt; cam ( y ) ) Definition 1 : GenLocalMaxs Algorithm Among others , the GenLocalMaxs shows one important property : it does not depend on global thresholds</definiens>
			</definition>
			<definition id="9">
				<sentence>The Mutual Expectation tends to give more importance to frequent sequences of textual units .</sentence>
				<definiendum id="0">Mutual Expectation</definiendum>
				<definiens id="0">tends to give more importance to frequent sequences of textual units</definiens>
			</definition>
</paper>

		<paper id="0426">
			<definition id="0">
				<sentence>In this paper , Long Short-Term Memory ( LSTM ) ( Hochreiter and Schmidhuber , 1997 ) is applied to named entity recognition , using data from the Reuters Corpus , English Language , Volume 1 , and the European Corpus Initiative Multilingual Corpus 1 .</sentence>
				<definiendum id="0">Long Short-Term Memory</definiendum>
				<definiens id="0">applied to named entity recognition , using data from the Reuters Corpus , English Language , Volume 1 , and the European Corpus Initiative Multilingual Corpus 1</definiens>
			</definition>
			<definition id="1">
				<sentence>LSTM is an architecture and training algorithm for recurrent neural networks ( RNNs ) , capable of remembering information over long time periods during the processing of a sequence .</sentence>
				<definiendum id="0">LSTM</definiendum>
				<definiens id="0">an architecture and training algorithm for recurrent neural networks ( RNNs ) , capable of remembering information over long time periods during the processing of a sequence</definiens>
			</definition>
			<definition id="2">
				<sentence>The units are updated according to the formula a0a2a1a4a3a6a5a8a7a10a9a12a11a13a15a14a16a0a17a1a18a3a20a19a22a21a23a5a25a24a27a26a28a1a4a3a6a5 , where a0a2a1a18a9a29a5a30a7a31a9 , a26a28a1a18a3a6a5 is the pattern representing the current POS tag , anda3a32a7a33a21a35a34a36a11a37a11a38a11a37a34a40a39 wherea39 is the length of the current sequence of inputs ( twice the length of the current sentence due to the 2 pass processing ) .</sentence>
				<definiendum id="0">a0a2a1a18a9a29a5a30a7a31a9 , a26a28a1a18a3a6a5</definiendum>
				<definiens id="0">the pattern representing the current POS tag , anda3a32a7a33a21a35a34a36a11a37a11a38a11a37a34a40a39 wherea39 is the length of the current sequence of inputs ( twice the length of the current sentence due to the 2 pass processing )</definiens>
			</definition>
			<definition id="3">
				<sentence>The “Wts” column gives the number of weights used .</sentence>
				<definiendum id="0">“Wts” column</definiendum>
			</definition>
			<definition id="4">
				<sentence>The Precision gives the percentage of named entities found that were correct , whilst the Recall is the percentage of named entities defined in the data that were found .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">gives the percentage of named entities found that were correct , whilst the Recall is the percentage of named entities defined in the data that were found</definiens>
			</definition>
</paper>

		<paper id="1500">
</paper>

		<paper id="0901">
			<definition id="0">
				<sentence>We envisage that , ultimately , the knowledge base ( KB ) will comprise a small number of abstract , core representations ( e.g. , movement , transportation , conversion , production , containment ) , along with a large number of detailed scenario representations .</sentence>
				<definiendum id="0">knowledge base ( KB</definiendum>
				<definiens id="0">e.g. , movement , transportation , conversion , production , containment</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , if we use “giver” and “donor” ( rather than “agent” and “agent” , say ) as roles in “give” and “donate” representations respectively , and “donate” is a kind of “give” , it is then up to the inference engine to recognize that 1In practice , this separation of events and states is not always so clean at the boundaries : whether something is an event or state is partly subjective , depending on the viewpoint adopted , e.g. , the level of temporal granularity chosen .</sentence>
				<definiendum id="0">“donate”</definiendum>
				<definiens id="0">rather than “agent” and “agent” , say ) as roles in “give” and “donate” representations respectively , and</definiens>
			</definition>
			<definition id="2">
				<sentence>In the graphical depiction , the dark node denotes a universally quantified object , other nodes denote implied , existentially quantified objects , and arcs denote binary relations .</sentence>
				<definiendum id="0">dark node</definiendum>
				<definiens id="0">a universally quantified object , other nodes denote implied , existentially quantified objects , and arcs denote binary relations</definiens>
			</definition>
			<definition id="3">
				<sentence>The semantics of this structure are that : for every launching a satellite event , there exists a rocket , a launch site , a countdown event , ... etc. , and the rocket is the vehicle of the launching a satellite , the launch site is the location of the launching a satellite , etc .</sentence>
				<definiendum id="0">launch site</definiendum>
				<definiens id="0">the location of the launching a satellite</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , launch a satellite v1 is a subclass of transport v1 , whose representation includes an axiom stating that during the move v1 subevent , the cargo is inside the vehicle .</sentence>
				<definiendum id="0">cargo</definiendum>
				<definiens id="0">a subclass of transport v1 , whose representation includes an axiom stating that during the move v1 subevent , the</definiens>
			</definition>
</paper>

		<paper id="0204">
			<definition id="0">
				<sentence>In the word exercises , PLASER computes a confidence-based score for each phoneme of the given word , and paints each vowel or consonant segment in the word using a novel 3-color scheme to indicate their pronunciation accuracy .</sentence>
				<definiendum id="0">PLASER</definiendum>
				<definiens id="0">computes a confidence-based score for each phoneme of the given word , and paints each vowel or consonant segment in the word using a novel 3-color scheme to indicate their pronunciation accuracy</definiens>
			</definition>
			<definition id="1">
				<sentence>PLASER consists of 20 lessons , and each lesson teaches two American English phonemes as shown in Table 1 .</sentence>
				<definiendum id="0">PLASER</definiendum>
				<definiens id="0">consists of 20 lessons , and each lesson teaches two American English phonemes as shown in Table 1</definiens>
			</definition>
			<definition id="2">
				<sentence>Word-List Speaking Exercise : A student may pick any word from a list to say , and PLASER has to decide how well each phoneme in the word is pronounced .</sentence>
				<definiendum id="0">Word-List Speaking Exercise</definiendum>
				<definiendum id="1">PLASER</definiendum>
				<definiens id="0">has to decide how well each phoneme in the word is pronounced</definiens>
			</definition>
			<definition id="3">
				<sentence>The feedback for Word-List Speaking Exercise consists of an overall score for the practising word ( “cheese” here ) as well as a confidence score for each individual phoneme in the word using a novel 3-color scheme .</sentence>
				<definiendum id="0">feedback for Word-List Speaking Exercise</definiendum>
			</definition>
			<definition id="4">
				<sentence>MP-DATA : A superset of words used in PLASER’s minimal-pair exercises recorded by eight highschool students , 4 males and 4 females , each speaking »300 words for a total of 2,431 words .</sentence>
				<definiendum id="0">MP-DATA</definiendum>
				<definiens id="0">A superset of words used in PLASER’s minimal-pair exercises recorded by eight highschool students</definiens>
			</definition>
			<definition id="5">
				<sentence>WL-DATA : A superset of words used in PLASER’s word exercises by the same eight students who recorded the MP-DATA for a total of 2,265 words .</sentence>
				<definiendum id="0">WL-DATA</definiendum>
				<definiens id="0">A superset of words used in PLASER’s word exercises by the same eight students who recorded the MP-DATA for a total of 2,265 words</definiens>
			</definition>
			<definition id="6">
				<sentence>STEP 3 : For each acoustic segment Xu of phoneme yu ( where u denotes the phoneme index ) , PLASER computes its GOP ( yu ) , su , as its posterior probability by the following log-likelihood ratio normalized by its duration Tu : su = logProb ( yujXu ) … 1T u ¢log `` p ( Xujyu ) p ( yu ) P N k=1 p ( Xujyk ) p ( yk ) # ( 1 ) … 1T u ¢log • p ( X ujyu ) p ( Xujyjmax ) ‚ ( 2 ) where N is the number of phonemes , and jmax is the phoneme model that gives the highest likelihood of the given segment .</sentence>
				<definiendum id="0">u</definiendum>
				<definiendum id="1">jmax</definiendum>
				<definiens id="0">the phoneme index ) , PLASER computes its GOP ( yu ) , su , as its posterior probability by the following log-likelihood ratio normalized by its duration Tu : su = logProb ( yujXu ) … 1T u ¢log `` p ( Xujyu ) p ( yu ) P N k=1 p ( Xujyk ) p ( yk ) # ( 1 ) … 1T u ¢log • p ( X ujyu ) p ( Xujyjmax ) ‚ ( 2 ) where N is the number of phonemes , and</definiens>
				<definiens id="1">the phoneme model that gives the highest likelihood of the given segment</definiens>
			</definition>
			<definition id="7">
				<sentence>Firstly , one has to decide how forgiving one wants to be and specifies the following two figures : † the false acceptance rate ( FA ) for an incorrectly pronounced phoneme ; and , † the false rejection rate ( FR ) for a correctly pronounced phoneme .</sentence>
				<definiendum id="0">FR</definiendum>
				<definiens id="0">† the false acceptance rate ( FA ) for an incorrectly pronounced phoneme ; and , † the false rejection rate (</definiens>
			</definition>
</paper>

		<paper id="1110">
			<definition id="0">
				<sentence>Information retrieval aims to match the information need expressed by the searcher in the query with concepts expressed in documents .</sentence>
				<definiendum id="0">Information retrieval</definiendum>
				<definiens id="0">aims to match the information need expressed by the searcher in the query with concepts expressed in documents</definiens>
			</definition>
			<definition id="1">
				<sentence>The expansion process aims to ( re ) introduce terminology that could have been used by the author to express the concepts in the documents .</sentence>
				<definiendum id="0">expansion process</definiendum>
				<definiens id="0">aims to ( re ) introduce terminology that could have been used by the author to express the concepts in the documents</definiens>
			</definition>
			<definition id="2">
				<sentence>MandarinEnglish Information ( MEI ) : Investigating translingual speech retrieval .</sentence>
				<definiendum id="0">MandarinEnglish Information</definiendum>
				<definiendum id="1">MEI )</definiendum>
			</definition>
</paper>

		<paper id="0507">
			<definition id="0">
				<sentence>In Table 6 and Table 7 , ‘ld’ means a baseline system using lead method , ‘free’ is free summaries produced by human ( abstract type 2 ) , and ‘part’ is human-produced ( abstract type1 ) summaries , and these three are baseline and reference scores for task A. Deletion Insertion Replacement System UIM RD IM RD C RD F0101 1.4 0.4 1.3 0.2 0.5 F0102 1.2 0.4 1.0 0.0 0.4 F0103 0.8 0.1 1.2 0.0 0.2 F0104 0.8 0.1 1.2 0.1 0.1 F0105 1.2 0.1 0.7 0.0 0.4 F0106 2.1 0.2 1.7 0.1 0.1 F0107 0.8 0.6 0.9 0.1 0.2 F0108 1.4 0.1 1.1 0.1 0.2 ld 1.9 0.1 1.3 0.0 0.0 free 0.6 0.4 1.1 0.1 0.2 part 0.7 0.3 1.1 0.1 0.1 edit 0.2 0.1 0.5 0.1 0.2 ALL 1.1 0.3 1.1 0.1 0.2 Table 7 Evaluation by revision ( task A 20 % ) Deletion Insertion Replacement System UIM RD IM RD C RD F0201 3.8 0.7 7.2 1.4 1.1 F0202 5.2 0.6 3.5 0.4 0.7 F0203 5.1 0.6 3.8 0.5 0.9 F0204 4.2 0.6 3.4 0.7 1.4 F0205 8.1 0.6 5.4 1.7 3.0 F0206 3.2 0.2 4.7 0.7 0.8 F0207 7.0 1.1 4.1 1.1 1.1 F0208 4.8 0.7 4.0 0.4 0.8 F0209 4.6 0.5 3.9 0.5 0.5 human 3.0 0.9 3.4 7.8 1.0 ld 5.7 0.9 2.9 0.4 0.7 stein 4.0 0.5 2.2 0.3 0.8 edit 3.0 1.2 2.9 0.7 0.7 ALL 4.9 0.7 4.0 1.3 1.1 Table 8 Evaluation by revision ( task B long ) In Table 8 and Table 9 , ‘human’ means humanproduced summaries which are different from the key data , and ‘ld’ means a baseline system using lead method , ‘stein’ means a benchmark system using Stein method , and these three are baseline , reference , and benchmark scores for task B. To determine the plausibility of the judges’ revision , the revised summaries were again evaluated with the evaluation methods in section 5 .</sentence>
				<definiendum id="0">‘part’</definiendum>
				<definiendum id="1">‘ld’</definiendum>
				<definiens id="0">free summaries produced by human</definiens>
				<definiens id="1">human-produced ( abstract type1</definiens>
				<definiens id="2">means a baseline system using lead method</definiens>
			</definition>
</paper>

		<paper id="1400">
</paper>

		<paper id="1402">
			<definition id="0">
				<sentence>Antonietta Alonge Sezione di Linguistica Facoltà di Lettere e Filosofia Università di Perugia Piazza Morlacchi , 11 Perugia 06100 ITALY antoalonge @ libero.it Margherita Castelli Sezione di Linguistica Facoltà di Lettere e Filosofia Università di Perugia Piazza Morlacchi , 11 Perugia 06100 ITALY castelli @ unipg.it In this paper we address the issue of the encoding of information on metaphors in a WordNet-like database , i.e. the Italian wordnet in EuroWordNet ( ItalWordNet ) .</sentence>
				<definiendum id="0">Italian wordnet</definiendum>
				<definiens id="0">the encoding of information on metaphors in a WordNet-like database</definiens>
			</definition>
</paper>

		<paper id="1602">
			<definition id="0">
				<sentence>Very timely , the acquisition of paraphrase patterns has been actively studied in recent years : AF Manual collection of paraphrases in the context of language generation , e.g. ( Robin and McKeown , 1996 ) , AF Derivation of paraphrases through existing lexical resources , e.g. ( Kurohashi et al. , 1999 ) , AF Corpus-based statistical methods inspired by the work on information extraction , e.g. ( Jacquemin , 1999 ; Lin and Pantel , 2001 ) , and AF Alignment-based acquisition of paraphrases from comparable corpora , e.g. ( Barzilay and McKeown , 2001 ; Shinyama et al. , 2002 ; Barzilay and Lee , 2003 ) .</sentence>
				<definiendum id="0">AF Derivation</definiendum>
				<definiens id="0">AF Manual collection of paraphrases in the context of language generation</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , in Figure 1 , the feature characterizing sentence ( A ) is a non-restrictive relative clause ( i.e. , sentence ( A ) was selected as an example of this feature ) .</sentence>
				<definiendum id="0">feature characterizing sentence</definiendum>
				<definiendum id="1">sentence</definiendum>
				<definiens id="0">a non-restrictive relative clause</definiens>
			</definition>
			<definition id="2">
				<sentence>BWB4D7 CX BND7 CY B5 represents the difference in readability between D7 CX and D7 CY ; it is computed in the following way .</sentence>
				<definiendum id="0">BWB4D7 CX BND7 CY B5</definiendum>
				<definiens id="0">represents the difference in readability between D7 CX and D7 CY ; it is computed in the following way</definiens>
			</definition>
			<definition id="3">
				<sentence>D7 CX D7 CY be the set of respondents who assessed B4D7 CX BND7 CY B5 .</sentence>
				<definiendum id="0">D7 CX D7 CY</definiendum>
				<definiens id="0">the set of respondents who assessed B4D7 CX BND7 CY B5</definiens>
			</definition>
			<definition id="4">
				<sentence>( someone does not V to nothing but N ) ( it is only to N that someone does V ) MDS transfer rule sp_rule ( 108 , negation , RefNode ) : match ( RefNode , X4= [ pos : postp , lex : shika ] ) , depend ( X3= [ pos : verb ] , empty , X4 ) , depend ( X1= [ pos : aux_verb , lex : nai ] , X2= [ pos : aux_verb* ] , X3 ) , depend ( X4 , empty , X5= [ pos : noun ] ) , replace ( X1 , X6= [ pos : aux_verb , lex : da ] ) , substitute ( X5 , X12= [ pos : noun ] ) , move_dtrs ( X5 , X12 ) , substitute ( X3 , X10= [ pos : verb ] ) , : pos : postp lex : shika ( except ) pos : aux_verb lex : da ( copula ) pos : postp lex : wa ( TOP ) X6 X11 X12 pos : noun lex : no ( thing ) pos : postp lex : dake ( only ) pos : noun pos : noun aux_verb* pos : aux_verb lex : nai ( not ) pos : verbX3 X4 X1 X5 X2 X7 X8 X10 pos : verb X9 vws MDS processing operators ( =X5 ) ( =X2 ) ( =X3 ) Figure 2 : Three-layered rule representation transformation patterns that is powerful enough to represent a sufficiently broad range of paraphrase patterns .</sentence>
				<definiendum id="0">V ) MDS transfer rule sp_rule</definiendum>
				<definiendum id="1">] ) , substitute</definiendum>
				<definiendum id="2">move_dtrs</definiendum>
				<definiens id="0">no ( thing ) pos : postp lex</definiens>
			</definition>
			<definition id="5">
				<sentence>AF Most types of errors tended to occur regardless of the types of transfer .</sentence>
				<definiendum id="0">AF Most</definiendum>
				<definiens id="0">types of errors tended to occur regardless of the types of transfer</definiens>
			</definition>
</paper>

		<paper id="1801">
</paper>

		<paper id="0319">
			<definition id="0">
				<sentence>LSA is an analytical methodology that uses mathematical procedures and vector space modeling 1 At present , the collection of texts used consists of 30 English and 30 French documents , all perfectly mated .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">an analytical methodology that uses mathematical procedures and vector space modeling 1 At present , the collection of texts used consists of 30 English and 30 French documents , all perfectly mated</definiens>
			</definition>
			<definition id="1">
				<sentence>Because of the way LSA represents word-usage associations and patterns among documents and terms , it may have much to offer in understanding the difficulty levels of these tasks .</sentence>
				<definiendum id="0">LSA</definiendum>
				<definiens id="0">word-usage associations and patterns among documents and terms</definiens>
			</definition>
			<definition id="2">
				<sentence>The LSA methodology begins with the term-bydocument matrix , an n x m matrix where each value in the matrix is the frequency of the nth word in the mth document .</sentence>
				<definiendum id="0">LSA methodology</definiendum>
				<definiens id="0">begins with the term-bydocument matrix , an n x m matrix where each value in the matrix is the frequency of the nth word in the mth document</definiens>
			</definition>
			<definition id="3">
				<sentence>SVD permits the reduction of any n x m matrix to a set of three matrices , such that M = UΣV T , where U = ( m x m matrix of left singular vectors ) Σ = ( n x m diagonal matrix containing the singular values of M ) V T = ( n x n transposed row matrix of the right singular vectors ) .</sentence>
				<definiendum id="0">SVD</definiendum>
				<definiens id="0">permits the reduction of any n x m matrix to a set of three matrices , such that M = UΣV T , where U = ( m x m matrix of left singular vectors ) Σ = ( n x m diagonal matrix containing the singular values of M ) V T = ( n x n transposed row matrix of the right singular vectors</definiens>
			</definition>
			<definition id="4">
				<sentence>In this section , an example of how the SVD procedure depicts the word and document relationships on the different dimensions is discussed .</sentence>
				<definiendum id="0">SVD procedure</definiendum>
				<definiens id="0">depicts the word and document relationships on the different dimensions is discussed</definiens>
			</definition>
</paper>

		<paper id="0414">
			<definition id="0">
				<sentence>We therefore define our similarity measure as a measure related to the inner product of two vectors a58 a8 a19a10a59a61a60 a29 a32 a14a62 a36a25a37 a8 a62 a59 a62 , where a38 is the number of dimensions .</sentence>
				<definiendum id="0">a38</definiendum>
				<definiens id="0">the number of dimensions</definiens>
			</definition>
			<definition id="1">
				<sentence>The cutoff value ( i.e. how far down the list to go ) is a tunable parameter .</sentence>
				<definiendum id="0">cutoff value</definiendum>
				<definiens id="0">a tunable parameter</definiens>
			</definition>
</paper>

		<paper id="1808">
			<definition id="0">
				<sentence>In this paper we discuss verb-particle constructions ( VPCs ) in English and analyse some of the available sources of information about them for use in NLP systems .</sentence>
				<definiendum id="0">verb-particle constructions</definiendum>
				<definiendum id="1">VPCs</definiendum>
			</definition>
			<definition id="1">
				<sentence>In Table 1 we can see the coverage of phrasal verbs ( PVs ) in several dictionaries and lexicons : Collins Cobuild Dictionary of Phrasal Verbs ( Collins-PV ) , Cambridge International Dictionary of Phrasal Verbs ( CIDE-PV ) , the electronic versions of the Alvey Natural Language Tools ( ANLT ) lexicon ( Carroll and Grover , 1989 ) ( which was derived from the Longman Dictionary of Contemporary English , LDOCE ) , the Comlex lexicon ( Macleod and Grishman , 1998 ) , and the LinGO English Resource Grammar ( ERG ) ( Copestake and Flickinger , 2000 ) version of November 2001 .</sentence>
				<definiendum id="0">PVs</definiendum>
				<definiens id="0">and the LinGO English Resource Grammar ( ERG ) ( Copestake and Flickinger</definiens>
			</definition>
			<definition id="2">
				<sentence>In relation to VPCs , ANLT uses the largest number of particles , and with one exception all the particles contained in the ERG and Comlex are already contained in ANLT .</sentence>
				<definiendum id="0">ANLT</definiendum>
				<definiens id="0">uses the largest number of particles , and with one exception all the particles contained in the ERG</definiens>
			</definition>
			<definition id="3">
				<sentence>The BNC is a 100 million word corpus containing samples of written text from a wide variety of sources , designed to represent as wide a range of modern British English as possible .</sentence>
				<definiendum id="0">BNC</definiendum>
				<definiens id="0">a 100 million word corpus containing samples of written text from a wide variety of sources , designed to represent as wide a range of modern British English as possible</definiens>
			</definition>
			<definition id="4">
				<sentence>From these classes , we can see two basic patterns : a3 verbs that can form aspectual combinations , with the particle giving a sense of completion and/or increase/improvement to the action denoted by the verb , e.g. verbs of Eating ( 39.1 ) and Splitting ( 23.2 ) , a3 verbs that imply some motion or take a location , e.g. verbs of Bring and Take ( 11.3 ) , Push and Pull ( 12 ) and Putting in spatial con guration ( 9.2 ) , and can form resultative combinations .</sentence>
				<definiendum id="0">Take ( 11.3</definiendum>
				<definiens id="0">a3 verbs that can form aspectual combinations , with the particle giving a sense of completion and/or increase/improvement to the action denoted by the verb</definiens>
			</definition>
</paper>

		<paper id="0701">
			<definition id="0">
				<sentence>An ARG consists of a set of nodes and a set of edges .</sentence>
				<definiendum id="0">ARG</definiendum>
				<definiens id="0">consists of a set of nodes and a set of edges</definiens>
			</definition>
			<definition id="1">
				<sentence>The match process is to maximize the following function : ( , ) ( , ) ( , ) ( , ) ( , ) ( , ) c s xm xm xm x mynxymn xymn QG G Pa a Pa Pa r αζ α ααψγ = ∑∑ ∑∑∑∑ + ( 1 ) with respect to P ( a x , α m ) , the matching probabilities between the referent node a x and the referring node α m .</sentence>
				<definiendum id="0">match process</definiendum>
				<definiens id="0">( , ) ( , ) ( , ) ( , ) ( , ) ( , ) c s xm xm xm x mynxymn xymn</definiens>
			</definition>
			<definition id="2">
				<sentence>For example , ζ ( a x , α m ) =Sem ( a x , α m ) Tem ( a x , α m ) , where Sem ( a x , α m ) measures the semantic compatibility by determining whether the semantic categories of a x and α m are the same , whether their attributes are compatible , and so on .</sentence>
				<definiendum id="0">Tem</definiendum>
				<definiendum id="1">Sem</definiendum>
				<definiens id="0">a x , α m ) measures the semantic compatibility by determining whether the semantic categories of a x</definiens>
			</definition>
			<definition id="3">
				<sentence>Tem ( a x , α m ) measures the temporal alignment and is empirically defined as follows :            − − = contextfromisa gesturefromisa timeatime aTem x x mx mx ,1.0 , 2000 | ) ( ) ( | exp ) , ( α α To maximize ( 1 ) , we modified the graduated assignment algorithm ( Gold and Rangarajan , 1996 ) .</sentence>
				<definiendum id="0">Tem</definiendum>
				<definiens id="0">a x , α m ) measures the temporal alignment and is empirically defined as follows :            − − = contextfromisa gesturefromisa timeatime aTem x x mx mx ,1.0 , 2000 | ) ( ) ( | exp )</definiens>
			</definition>
</paper>

		<paper id="1117">
			<definition id="0">
				<sentence>Keywords : Document Clustering , Weighting Scheme , Feature Selection Document clustering is an aggregation of documents by discriminating the relevant documents from the irrelevant documents .</sentence>
				<definiendum id="0">Document Clustering</definiendum>
				<definiens id="0">an aggregation of documents by discriminating the relevant documents from the irrelevant documents</definiens>
			</definition>
			<definition id="1">
				<sentence>The clustering method , which is focused on similarity calculation considers the whole words except stopwords as the representative of the document , and constitutes a document vector that is calculated by the weight value from the term frequency and document frequency .</sentence>
				<definiendum id="0">clustering method</definiendum>
				<definiens id="0">the representative of the document , and constitutes a document vector that is calculated by the weight value from the term frequency and document frequency</definiens>
			</definition>
			<definition id="2">
				<sentence>When we construct a document vector , term frequency and document frequency are the most important features to calculate the weight of a term .</sentence>
				<definiendum id="0">document frequency</definiendum>
			</definition>
</paper>

		<paper id="1700">
</paper>

		<paper id="1307">
			<definition id="0">
				<sentence>Our experiments on GENIA V3.0 and GENIA V1.1 achieve the 66.1 and 62.5 F-measure respectively , which outperform the previous best published results by 8.1 F-measure when using the same training and testing data .</sentence>
				<definiendum id="0">GENIA V1.1</definiendum>
				<definiens id="0">achieve the 66.1 and 62.5 F-measure respectively , which outperform the previous best published results by 8.1 F-measure when using the same training and testing data</definiens>
			</definition>
			<definition id="1">
				<sentence>n n ttt ⋅⋅⋅= 211 n gg ⋅= 211 ) 1 n G n g⋅⋅ | ( 1 n TP In token sequence G , the token g is defined as , where w is the word and is the feature set related with the word .</sentence>
				<definiendum id="0">w</definiendum>
				<definiens id="0">the word and is the feature set related with the word</definiens>
			</definition>
			<definition id="2">
				<sentence>LRB ( RRB ) LSB [ RSB ] RomanDigit II GreekLetter Beta StopWord in , at ATCGsequence AACAAAG OneDigit 5 AllDigits 60 DigitCommaDigit 1,25 DigitDotDigit 0.5 OneCap T AllCaps CSF CapLowAlpha All CapMixAlpha IgM LowMixAlpha kDa AlphaDigitAlpha H2A AlphaDigit T4 DigitAlphaDigit 6C2 DigitAlpha 19D Table 1 : Simple deterministic features From Table 1 , we can find that : are designed intuitively to provide information to detect the boundary of NE .</sentence>
				<definiendum id="0">LRB</definiendum>
				<definiens id="0">find that : are designed intuitively to provide information to detect the boundary of NE</definiens>
			</definition>
</paper>

		<paper id="1906">
</paper>

		<paper id="0610">
			<definition id="0">
				<sentence>Heavy specifies a property of objects which involves affordances that intertwine procedural representations with perceptual expectations ( Gibson , 1979 ) .</sentence>
				<definiendum id="0">Heavy</definiendum>
				<definiens id="0">specifies a property of objects which involves affordances that intertwine procedural representations with perceptual expectations</definiens>
			</definition>
			<definition id="1">
				<sentence>Ripley integrates real-time information from its visual and proprioceptive systems to construct an “internal replica” , or mental model of its environment that best explains the history of sensory data that Ripley has observed2 .</sentence>
				<definiendum id="0">Ripley</definiendum>
			</definition>
			<definition id="2">
				<sentence>ODE provides facilities for modeling the dynamics of three dimensional rigid objects based on Newtonian physics .</sentence>
				<definiendum id="0">ODE</definiendum>
				<definiens id="0">provides facilities for modeling the dynamics of three dimensional rigid objects based on Newtonian physics</definiens>
			</definition>
			<definition id="3">
				<sentence>The ODE simulator provides an interface for creating and destroying rigid objects with arbitrary polyhedron geometries placed within a 3D virtual world .</sentence>
				<definiendum id="0">ODE simulator</definiendum>
				<definiens id="0">provides an interface for creating and destroying rigid objects with arbitrary polyhedron geometries placed within a 3D virtual world</definiens>
			</definition>
			<definition id="4">
				<sentence>ODE computes basic Newtonian updates of object positions at discrete time steps based object masses and applied forces .</sentence>
				<definiendum id="0">ODE</definiendum>
				<definiens id="0">computes basic Newtonian updates of object positions at discrete time steps based object masses and applied forces</definiens>
			</definition>
			<definition id="5">
				<sentence>The Objecter consists of two interconnected components .</sentence>
				<definiendum id="0">Objecter</definiendum>
				<definiens id="0">consists of two interconnected components</definiens>
			</definition>
			<definition id="6">
				<sentence>To begin with a simple case , the word “blue” is a property that may be defined as : property Blue ( x ) { c←GetColorModel ( x ) return fblue ( c ) } The function returns a scalar value that indicates how strongly the color of object x matches the expected color model encoded in fblue .</sentence>
				<definiendum id="0">word “blue”</definiendum>
				<definiens id="0">a property that may be defined as : property Blue ( x ) { c←GetColorModel ( x ) return fblue ( c ) } The function returns a scalar value that indicates how strongly the color of object x matches the expected color model encoded in fblue</definiens>
			</definition>
			<definition id="7">
				<sentence>This reaching gesture terminates successfully when the touch sensors are activated and the visual system reports that the target x remains in view : procedure Touch ( x ) { repeat Reach-towards ( x ) until touch sensor ( s ) activated if x in view then return success else return failure end if } Along similar lines , it is also useful to define a weigh procedure ( which has been implemented as described in Section 3.5 ) : procedure Weigh ( x ) { Grasp ( x ) resistance←0 while Lift ( x ) do resistance←resistance + joint forces end while return resistance } Weigh ( ) monitors the forces on the robot’s joints as it lifts x. The accumulated forces are returned by the function .</sentence>
				<definiendum id="0">weigh procedure</definiendum>
				<definiens id="0">has been implemented as described in Section 3.5 ) : procedure Weigh ( x ) { Grasp</definiens>
			</definition>
			<definition id="8">
				<sentence>To highlight its effect on the context data structure , Was ( ) is defined as a context-shift function : context-shift Was ( context ) { Working memory←Salient events from mental model history } “Was” triggers a request from memory ( Section 4.3 ) for objects which are added to working memory , making them accessible to other processes .</sentence>
				<definiendum id="0">Was ( )</definiendum>
				<definiens id="0">a context-shift function : context-shift Was ( context ) { Working memory←Salient events from mental model history } “Was” triggers a request from memory ( Section 4.3 ) for objects which are added to working memory , making them accessible to other processes</definiens>
			</definition>
			<definition id="9">
				<sentence>The determiner “the” indicates the selection of a single referent from working memory : determiner The ( context ) { Select most salient element from working memory } In the example , the semantics of “my” can be grounded in the synthetic visual perspective shift operation described in Section 4.2 : context-shift My ( context ) { context.point-of-view←GetPointOfView ( speaker ) } Where GetPointOfV iew ( speaker ) obtains the spatial position and orientation of the speaker’s visual input .</sentence>
				<definiendum id="0">determiner “the”</definiendum>
				<definiens id="0">context-shift My ( context ) { context.point-of-view←GetPointOfView ( speaker ) } Where GetPointOfV iew ( speaker ) obtains the spatial position and orientation of the speaker’s visual input</definiens>
			</definition>
</paper>

		<paper id="0903">
			<definition id="0">
				<sentence>Slots are interpreted as a collection of properties .</sentence>
				<definiendum id="0">Slots</definiendum>
			</definition>
			<definition id="1">
				<sentence>Another constraint on the slot fillers is cardinality , which limits the number of possible fillers of the given class .</sentence>
				<definiendum id="0">cardinality</definiendum>
				<definiens id="0">limits the number of possible fillers of the given class</definiens>
			</definition>
			<definition id="2">
				<sentence>Role is the most general class in the ontology representing concrete roles that any entity or process can perform in a specific domain .</sentence>
				<definiendum id="0">Role</definiendum>
				<definiens id="0">the most general class in the ontology representing concrete roles that any entity or process can perform in a specific domain</definiens>
			</definition>
			<definition id="3">
				<sentence>Based on the analysis of our dialogue data , we developed the following classification of processes ( see Figure 2 ) : a0 GeneralProcess , a set of the most general processes such as duplication , imitation or repetition processes ; a0 MentalProcess , a set of processes such as cognitive , emotional or perceptual processes ; a0 PhysicalProcess , a set of processes such as motion , transaction or controlling processes ; a0 SocialProcess , a set of processes such as communication or instruction processes .</sentence>
				<definiendum id="0">a0 MentalProcess</definiendum>
				<definiendum id="1">a0 SocialProcess</definiendum>
				<definiens id="0">a0 GeneralProcess , a set of the most general processes such as duplication , imitation or repetition processes</definiens>
				<definiens id="1">cognitive , emotional or perceptual processes</definiens>
				<definiens id="2">a set of processes such as motion , transaction or controlling processes</definiens>
			</definition>
			<definition id="4">
				<sentence>The PhysicalProcess has the following subclasses : the semantics of ControllingProcess presupposes the controlling of a number of artifacts , e. g. , devices , MotionProcess models different types of agent’s movement regarding some object or point in space , PresentationProcess describes a process of displaying some information by an agent , e. g. , a TV program by Smartakus , an artificial character embedding the SMARTKOM system , StaticSpatialProcess consists in the agent’s dwelling in some point Process Static Spatial Process Transaction Process Emotion Process Social Process Controlling Process Verification Process Motion Process Presentation Process Hear Perceptual Process General Process Perceptual Process Emotion Experiencer Emotion Experiencer Subject Process Object Process Planning Process Cognitive Process Mental Process Information Search Process Controlling Commu− Controlling Presen− Physical Process Communicative Process Instructive ProcessProcessControlling Device Abstract Reset Process Process Abstract Replacement Abstract Repetition Process Abstract Imitation Process Controlling Representational Artifact nication Device tainment Device Controlling Enter− tation Device Controlling Media Process Emotion Active Process Emotion Directed Process Abstract Duplication Process Watch Perceptual Process Figure 2 : Process Hierarchy .</sentence>
				<definiendum id="0">PhysicalProcess</definiendum>
				<definiendum id="1">PresentationProcess</definiendum>
				<definiendum id="2">StaticSpatialProcess</definiendum>
				<definiens id="0">the semantics of ControllingProcess presupposes the controlling of a number of artifacts , e. g. , devices , MotionProcess models different types of agent’s movement regarding some object or point in space</definiens>
				<definiens id="1">describes a process of displaying some information by an agent , e. g. , a TV program by Smartakus , an artificial character embedding the SMARTKOM system</definiens>
			</definition>
			<definition id="5">
				<sentence>in space , TransactionProcess presupposes an exchange of entities or services among different participants of the process .</sentence>
				<definiendum id="0">TransactionProcess</definiendum>
				<definiens id="0">presupposes an exchange of entities or services among different participants of the process</definiens>
			</definition>
			<definition id="6">
				<sentence>Another subclass of the Process SocialProcess includes CommunicativeProcess , which consists in communicating by the agent a message to the addressee by different means , and InstructiveProcess which describes an interaction between an agent and a trainee .</sentence>
				<definiendum id="0">CommunicativeProcess</definiendum>
				<definiendum id="1">InstructiveProcess</definiendum>
				<definiens id="0">consists in communicating by the agent a message to the addressee by different means , and</definiens>
			</definition>
			<definition id="7">
				<sentence>We introduced the notion of semantic coherence as a special measurement which can be applied to estimate how well a given speech recognition hypothesis ( SRH ) fits with respect to the existing knowledge representation ( Gurevych et al. , 2003 ) .</sentence>
				<definiendum id="0">SRH</definiendum>
				<definiens id="0">a special measurement which can be applied to estimate how well a given speech recognition hypothesis</definiens>
			</definition>
</paper>

		<paper id="1712">
			<definition id="0">
				<sentence>HowNet is a lexical database , which describes the relations among words and concepts as a network .</sentence>
				<definiendum id="0">HowNet</definiendum>
				<definiens id="0">a lexical database , which describes the relations among words and concepts as a network</definiens>
			</definition>
			<definition id="1">
				<sentence>∏ = = n k kkk rwhwPTP 1 ) ) , ( , ( ) ( ( 1 ) where n is the length of the sentence , k w is the k-th word in the sentence , ) ( k wh is the headword to k w with semantic relation k r .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the length of the sentence</definiens>
				<definiens id="1">the k-th word in the sentence</definiens>
				<definiens id="2">the headword to k w with semantic relation k r</definiens>
			</definition>
			<definition id="2">
				<sentence>RCn is the number of relations for which n judges agreed , divided by the total number of relations , in which n can be 1 , 2 , 3 .</sentence>
				<definiendum id="0">RCn</definiendum>
				<definiens id="0">the number of relations for which n judges agreed , divided by the total number of relations</definiens>
			</definition>
			<definition id="3">
				<sentence>SCn is the number of sentences for which n judges agreed , divided by the total number of sentences , in which n can be 1 , 2 , 3 .</sentence>
				<definiendum id="0">SCn</definiendum>
				<definiens id="0">the number of sentences for which n judges agreed , divided by the total number of sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , if three experts take part in evaluating , RC3 is the percentage of the annotated relation that all three experts are agree to one annotation , and SC1 is the percentage of the annotated sentence for which all three judges’ opinions are different from one another .</sentence>
				<definiendum id="0">RC3</definiendum>
				<definiendum id="1">SC1</definiendum>
				<definiens id="0">the percentage of the annotated relation that all three experts are agree to one annotation</definiens>
				<definiens id="1">the percentage of the annotated sentence for which all three judges’ opinions</definiens>
			</definition>
			<definition id="5">
				<sentence>Introduction to WordNet : An On-line Lexical Database , Five papers on WordNet , CSL Report 43 , Cognitive Science Laboratory .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">An On-line Lexical Database , Five papers on WordNet</definiens>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>Co-training ( Blum and Mitchell , 1998 ) is a weakly supervised paradigm that learns a task from a small set of labeled data and a large pool of unlabeled data using separate , but redundant views of the data ( i.e. using disjoint feature subsets to represent the data ) .</sentence>
				<definiendum id="0">Co-training</definiendum>
			</definition>
			<definition id="1">
				<sentence>A naive Bayes ( NB ) classifier is a generative classifier that assigns to a test instance i with feature values &lt; x 1 , ... , x m &gt; the maximum a posteriori ( MAP ) label y ∗ , which is determined as follows : y ∗ =argmax y P ( y|i ) =argmax y P ( y ) P ( i|y ) =argmax y P ( y ) m productdisplay i =1 P ( x i |y ) The first equality above follows from the definition of MAP , the second one from Bayes rule , and the last one from the conditional independence assumption of the feature values .</sentence>
				<definiendum id="0">naive Bayes ( NB ) classifier</definiendum>
				<definiens id="0">a generative classifier that assigns to a test instance i with feature values &lt; x 1 , ... , x m &gt; the maximum a posteriori ( MAP ) label y ∗ , which is determined as follows</definiens>
			</definition>
</paper>

		<paper id="0431">
			<definition id="0">
				<sentence>The fundamental attribute of character n-gram modelling is the observed probability of a collocation of characters occurring as each of the category types .</sentence>
				<definiendum id="0">character n-gram modelling</definiendum>
				<definiens id="0">the observed probability of a collocation of characters occurring as each of the category types</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>Subjective remarks come in a variety of forms , including opinions , rants , allegations , accusations , suspicions , and speculations .</sentence>
				<definiendum id="0">Subjective remarks</definiendum>
				<definiens id="0">come in a variety of forms , including opinions , rants , allegations , accusations , suspicions , and speculations</definiens>
			</definition>
			<definition id="1">
				<sentence>This test set consists of 2197 sentences , 59 % of which are subjective .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">consists of 2197 sentences , 59 % of which are subjective</definiens>
			</definition>
			<definition id="2">
				<sentence>The high-precision objective classifier takes a different approach .</sentence>
				<definiendum id="0">high-precision objective classifier</definiendum>
				<definiens id="0">takes a different approach</definiens>
			</definition>
			<definition id="3">
				<sentence>For training , AutoSlogTS uses a text corpus consisting of two distinct sets of texts : “relevant” texts ( in our case , subjective sentences ) and “irrelevant” texts ( in our case , objective sentences ) .</sentence>
				<definiendum id="0">AutoSlogTS</definiendum>
				<definiens id="0">uses a text corpus consisting of two distinct sets of texts</definiens>
			</definition>
			<definition id="4">
				<sentence>The exact formula is : Pr ( subjective j patterni ) = subjfreq ( patterni ) freq ( patterni ) where subjfreq ( patterni ) is the frequency of patterni in subjective training sentences , and freq ( patterni ) is the frequency of patterni in all training sentences .</sentence>
				<definiendum id="0">subjfreq ( patterni )</definiendum>
				<definiendum id="1">freq</definiendum>
				<definiens id="0">the frequency of patterni in subjective training sentences , and</definiens>
				<definiens id="1">the frequency of patterni in all training sentences</definiens>
			</definition>
			<definition id="5">
				<sentence>Figure 3 also shows that expressions using talk as a noun ( e.g. , “Fred is the talk of the town” ) are highly correlated with subjective sentences , while talk as a verb ( e.g. , “The mayor will talk about ... ” ) are found in a mix of subjective and objective sentences .</sentence>
				<definiendum id="0">“Fred</definiendum>
				<definiens id="0">talk about ... ” ) are found in a mix of subjective and objective sentences</definiens>
			</definition>
			<definition id="6">
				<sentence>This test set consists of 3947 Figure 4 : Evaluating the Learned Patterns on Test Data sentences , 54 % of which are subjective .</sentence>
				<definiendum id="0">test set</definiendum>
				<definiens id="0">Evaluating the Learned Patterns on Test Data sentences , 54 % of which are subjective</definiens>
			</definition>
			<definition id="7">
				<sentence>In this figure , precision is the proportion of pattern instances found in the test set that are in subjective sentences , and recall is the proportion of subjective sentences that contain at least one pattern instance .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the proportion of pattern instances found in the test set that are in subjective sentences , and recall is the proportion of subjective sentences that contain at least one pattern instance</definiens>
			</definition>
			<definition id="8">
				<sentence>HP-Subj HP-Subj w/Patterns Recall Precision Recall Precision 32.9 91.3 40.1 90.2 Table 1 : Bootstrapping the Learned Patterns into the High-Precision Sentence Classifier Table 2 gives examples of patterns used to augment the HP-Subj classifier which do not overlap in non-function words with any of the clues already known by the original system .</sentence>
				<definiendum id="0">HP-Subj HP-Subj w/Patterns Recall Precision Recall Precision</definiendum>
				<definiens id="0">Bootstrapping the Learned Patterns into the High-Precision Sentence Classifier Table 2 gives examples of patterns used to augment the HP-Subj classifier which do not overlap in non-function words with any of the clues already known by the original system</definiens>
			</definition>
</paper>

		<paper id="0425">
			<definition id="0">
				<sentence>This paper investigates the combination of a set of diverse statistical named entity classifiers , including a rule-based classifier – the transformation-based learning classifier ( Brill , 1995 ; Florian and Ngai , 2001 , henceforth fnTBL ) with the forward-backward extension described in Florian ( 2002a ) , a hidden Markov model classifier ( henceforth HMM ) , similar to the one described in Bikel et al. ( 1999 ) , a robust risk minimization classifier , based on a regularized winnow method ( Zhang et al. , 2002 ) ( henceforth RRM ) and a maximum entropy classifier ( Darroch and Ratcliff , 1972 ; Berger et al. , 1996 ; Borthwick , 1999 ) ( henceforth MaxEnt ) .</sentence>
				<definiendum id="0">transformation-based learning classifier</definiendum>
				<definiendum id="1">HMM</definiendum>
				<definiens id="0">a robust risk minimization classifier , based on a regularized winnow method</definiens>
				<definiens id="1">henceforth RRM ) and a maximum entropy classifier</definiens>
			</definition>
			<definition id="1">
				<sentence>Transformation-based learning is an error-driven algorithm which has two major steps : it starts by assigning some classification to each example , and then automatically proposing , evaluating and selecting the classification changes that maximally decrease the number of errors .</sentence>
				<definiendum id="0">Transformation-based learning</definiendum>
				<definiens id="0">an error-driven algorithm which has two major steps : it starts by assigning some classification to each example , and then automatically proposing , evaluating and selecting the classification changes that maximally decrease the number of errors</definiens>
			</definition>
</paper>

		<paper id="0408">
			<definition id="0">
				<sentence>token before the period token after the period character to the right type of character to the right character to the left type of character to the left character to the right of blank after word type of character to the right of blank after word character left of first character of word type of character left of first character of word first character of the preceding word type of first character of the preceding word length of preceding word distance to previous period Table 1 : Linguistic Features The features presented here may not be optimal .</sentence>
				<definiendum id="0">Linguistic Features</definiendum>
				<definiens id="0">the period token after the period character to the right type of character to the right character to the left type of character to the left character to the right of blank after word type of character to the right of blank after word character left of first character of word type of character left of first character of word first character of the preceding word type</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>The decoder processes search states of the following form : a103 a104 a105a107a106 a44a59a45 a106 a45a109a108a69a45a65a110a111a45a113a112a46a44a46a45a114a112a109a115a1a116 a106 and a106 a44 are the two predecessor words used for the trigram language model , a108 is the so-called coverage vector to keep track of the already processed source position , a110 is the last processed source position .</sentence>
				<definiendum id="0">a108</definiendum>
				<definiendum id="1">a110</definiendum>
				<definiens id="0">the so-called coverage vector to keep track of the already processed source position ,</definiens>
			</definition>
			<definition id="1">
				<sentence>a112 is the source phrase length of the block Table 3 : Effect of the extension scheme a117a61a118a58a119a120 on the CE translation experiments .</sentence>
				<definiendum id="0">a112</definiendum>
				<definiens id="0">the source phrase length of the block Table 3 : Effect of the extension scheme a117a61a118a58a119a120 on the CE translation experiments</definiens>
			</definition>
			<definition id="2">
				<sentence>a137a48a138 is the length of the initial fragment of the source phrase that has been processed so far .</sentence>
				<definiendum id="0">a137a48a138</definiendum>
				<definiens id="0">the length of the initial fragment of the source phrase that has been processed so far</definiens>
			</definition>
</paper>

		<paper id="0428">
			<definition id="0">
				<sentence>Earlier papers have taken a character-level approach to named entity recognition ( NER ) , notably Cucerzan and Yarowsky ( 1999 ) , which used prefix and suffix tries , though to our knowledge incorporating all character a4 grams is new .</sentence>
				<definiendum id="0">NER</definiendum>
			</definition>
			<definition id="1">
				<sentence>In practice , we have a special stop symbol in our n-gram counts , and the probability of emitting a space from a final state is the probability of the n-gram having chosen the stop character.3 1We index characters , and other vector elements by relative location subscripts : a65a31a66 is the current character , a65a18a67 is the following character , and a65a18a68 a67 is the previous character .</sentence>
				<definiendum id="0">a65a31a66</definiendum>
				<definiendum id="1">a65a18a67</definiendum>
				<definiendum id="2">a65a18a68 a67</definiendum>
				<definiens id="0">the current character ,</definiens>
			</definition>
			<definition id="2">
				<sentence>3This can be cleaned up conceptually by considering the entire process to have been a hierarchical HMM ( Fine et al. , 1998 ) , where the a69 -gram model generates the entire phrase , followed by a tier pop up to the phrase transition tier .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiendum id="1">-gram model</definiendum>
				<definiens id="0">generates the entire phrase , followed by a tier pop up to the phrase transition tier</definiens>
			</definition>
			<definition id="3">
				<sentence>Sequence-sensitive features can be included by chaining our local classifiers together and performing joint inference , i.e. , by building a conditional markov model ( CMM ) , also known as a maximum entropy markov model ( McCallum et al. , 2000 ) .</sentence>
				<definiendum id="0">Sequence-sensitive features</definiendum>
			</definition>
</paper>

		<paper id="0411">
			<definition id="0">
				<sentence>For example , here is a simple parse tree with the new annotation format : ( S ( NP-TPC-5 This ) ( NP-SBJ every man ) ( VP contains ( NP *T*-5 ) ( PP-LOC within ( NP him ) ) ) ) This shows that the prepositional phrase ( PP ) is providing the location for the state described by the verb phrase .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiens id="0">providing the location for the state described by the verb phrase</definiens>
			</definition>
			<definition id="1">
				<sentence>The table is ordered by entropy , which measures the inherent ambiguity in the classes as given by the annotations .</sentence>
				<definiendum id="0">entropy</definiendum>
			</definition>
			<definition id="2">
				<sentence>Berkeley’s FRAMENET ( Fillmore et al. , 2001 ) project provides the most recent large-scale annotation of semantic roles .</sentence>
				<definiendum id="0">Berkeley’s FRAMENET</definiendum>
				<definiens id="0">the most recent large-scale annotation of semantic roles</definiens>
			</definition>
			<definition id="3">
				<sentence>FRAMENET annotations occur at the phrase level instead of the grammatical constituent level as in TREEBANK .</sentence>
				<definiendum id="0">FRAMENET annotations</definiendum>
				<definiens id="0">occur at the phrase level instead of the grammatical constituent level as in TREEBANK</definiens>
			</definition>
			<definition id="4">
				<sentence>The frame element ( FE ) attribute indicates one of the semantic roles for the frame , and the phrase type ( PT ) attribute indicates the grammatical function of the phrase .</sentence>
				<definiendum id="0">frame element ( FE ) attribute</definiendum>
				<definiens id="0">indicates one of the semantic roles for the frame , and the phrase type ( PT ) attribute indicates the grammatical function of the phrase</definiens>
			</definition>
			<definition id="5">
				<sentence>Tag is the label for the role in the annotations .</sentence>
				<definiendum id="0">Tag</definiendum>
			</definition>
			<definition id="6">
				<sentence>Features : POS−2 part-of-speech 2 words to left POS−1 : part-of-speech 1 word to left POS+1 : part-of-speech 1 word to right POS+2 : part-of-speech 2 words to right Prep preposition being classified WordColl i : word collocation for role i HypernymColl i : hypernym collocation for role i Collocation Context : Word : anywhere in the sentence Hypernym : within 5 words of target preposition Collocation selection : Frequency : f ( word ) &gt; 1 CI threshold : p ( c|coll ) −p ( c ) p ( c ) &gt; =0.2 Organization : per-class-binary Model selection : overall classifier : Decision tree individual classifiers : Naive Bayes 10-fold cross-validation Figure 1 : Feature settings used in the preposition classification experiments .</sentence>
				<definiendum id="0">Decision tree individual</definiendum>
				<definiens id="0">Feature settings used in the preposition classification experiments</definiens>
			</definition>
			<definition id="7">
				<sentence>P ( R|C ) is probability of the relation given that the synset category occurs in the context .</sentence>
				<definiendum id="0">P ( R|C )</definiendum>
				<definiens id="0">probability of the relation given that the synset category occurs in the context</definiens>
			</definition>
			<definition id="8">
				<sentence>It is illustrative to compare the prior probabilities ( i.e. , P ( R ) ) for FRAMENET to those seen earlier for ‘at’ in TREEBANK .</sentence>
				<definiendum id="0">P</definiendum>
				<definiens id="0">( R ) ) for FRAMENET to those seen earlier for ‘at’ in TREEBANK</definiens>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>We used SIMFINDER ( Hatzivassiloglou et al. , 2001 ) , a state-of-the-art system for measuring sentence similarity based on shared words , phrases , and WordNet synsets .</sentence>
				<definiendum id="0">SIMFINDER</definiendum>
				<definiens id="0">Hatzivassiloglou et al. , 2001 ) , a state-of-the-art system for measuring sentence similarity based on shared words</definiens>
			</definition>
			<definition id="1">
				<sentence>We then calculate a modified log-likelihood ratio a22 a3a24a23a26a25a27a3 POSa28 a8 for a word a23 a25 with part of speech POSa28 ( a29 can be adjective , adverb , noun or verb ) as the ratio of its collocation frequency with ADJa20 and ADJa21 within a sentence , a22 a3a30a23 a25a3 POSa28 a8 a10a32a31a34a33a36a35 a37a38 Freq a14a40a39a19a41a43a42POS a44 a42ADJ a45 a18a47a46a49a48 Freqa14a50a39 alla42POSa44a42ADJa45 a18 Freqa14a50a39a51a41a30a42POSa44a42ADJa52 a18a53a46a54a48 Freqa14a50a39 alla42POSa44a42ADJa52 a18 a55a56 where Freqa3a30a23 alla3 POSa28a3 ADJa20 a8 represents the collocation frequency of all wordsa23 all of part of speech POSa28 with ADJa20 and a57 is a smoothing constant ( a57 a10a59a58 a9a61a60 in our case ) .</sentence>
				<definiendum id="0">a57</definiendum>
				<definiens id="0">the ratio of its collocation frequency with ADJa20 and ADJa21 within a sentence</definiens>
			</definition>
</paper>

		<paper id="1118">
			<definition id="0">
				<sentence>InfoMap is designed to perform natural language understanding , and applied to many application domains , such as question answering ( QA ) , knowledge management and organization memory ( Wu et al. , 2002 ) , and shows good results .</sentence>
				<definiendum id="0">InfoMap</definiendum>
				<definiens id="0">designed to perform natural language understanding , and applied to many application domains , such as question answering ( QA ) , knowledge management and organization memory ( Wu et al. , 2002 ) , and shows good results</definiens>
			</definition>
			<definition id="1">
				<sentence>As a domain ontology , InfoMap consists of domain concepts and their related sub-concepts such as categories , attributes , activities .</sentence>
				<definiendum id="0">InfoMap</definiendum>
			</definition>
			<definition id="2">
				<sentence>InfoMap uses two major relationships among concepts : taxonomic relationships ( category and synonym ) and non-taxonomic relationships ( attribute and action ) .</sentence>
				<definiendum id="0">InfoMap</definiendum>
				<definiens id="0">uses two major relationships among concepts : taxonomic relationships ( category and synonym ) and non-taxonomic relationships ( attribute and action )</definiens>
			</definition>
			<definition id="3">
				<sentence>NVEF is a collection of permissible noun-verb sense-pairs that appear in general domain corpora .</sentence>
				<definiendum id="0">NVEF</definiendum>
				<definiens id="0">a collection of permissible noun-verb sense-pairs that appear in general domain corpora</definiens>
			</definition>
			<definition id="4">
				<sentence>The TF/IDF classifier represents a domain as a weighted vector , D j = ( w j1 , w j2 , … , w jn ) , where n is the number of words in this domain and w k is the weight of word k. w k is defined as nf jk * idf jk , where nf jk is the term frequency ( i.e. , the number of times the word w k occurs in the domain j ) .</sentence>
				<definiendum id="0">TF/IDF classifier</definiendum>
				<definiendum id="1">n</definiendum>
				<definiendum id="2">w k</definiendum>
				<definiendum id="3">nf jk</definiendum>
				<definiens id="0">a domain as a weighted vector , D j = ( w j1 , w j2 , … , w jn</definiens>
				<definiens id="1">the number of words in this domain and</definiens>
				<definiens id="2">the term frequency</definiens>
				<definiens id="3">the number of times the word w k occurs in the domain j )</definiens>
			</definition>
			<definition id="5">
				<sentence>The ambiguity of an event structure E ( S i ) is proportional to the number of domains in which it appears , and inversely proportional to its event score , where S i are the sentences that fire event E. GlobalCategorizationAmiguityFactor ( E ( S i ) ) = number of domains fired by S i /average ( EventScore ( S i ) ) We also measure the similarity between every two event structures by calculating the cooccurrence multiplied by the global categorization ambiguity factor .</sentence>
				<definiendum id="0">EventScore</definiendum>
				<definiens id="0">proportional to the number of domains in which it appears</definiens>
			</definition>
			<definition id="6">
				<sentence>Ontology-based IR is one of them .</sentence>
				<definiendum id="0">Ontology-based IR</definiendum>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>For example , in POS tagging , the words a11a35a29 ’s construct a sentence a7 , and a27 is the labelling of the sentence where a28 a29 is the part of speech tag of the word a11 a29 .</sentence>
				<definiendum id="0">a27</definiendum>
				<definiens id="0">’s construct a sentence a7 , and</definiens>
			</definition>
			<definition id="1">
				<sentence>The best performing models of label sequence learning are MEMMs or PMMs ( also known as Maximum Entropy models ) whose features are carefully designed for the specific tasks ( Ratnaparkhi , 1999 ; Toutanova and Manning , 2000 ) .</sentence>
				<definiendum id="0">PMMs</definiendum>
			</definition>
			<definition id="2">
				<sentence>Each of these features corresponds to a choice of a28 a29 and a11a47a46 where a48 a31a50a49a16a45a52a51a54a53a55a15a22a21a23a21a23a21a23a15a17a45a37a15a22a21a23a21a23a21a23a15a17a45a14a56a57a53a59a58 and a53 is the half window size i.e. features that capture the inter-label dependencies .</sentence>
				<definiendum id="0">a53</definiendum>
			</definition>
			<definition id="3">
				<sentence>a5a8a7a10a9 consists of a7 a14 features and spelling features of the current word ( e.g. ”Is the current word capitalized and the current tag is PersonBeginning ? ” )</sentence>
				<definiendum id="0">a5a8a7a10a9</definiendum>
				<definiens id="0">consists of a7 a14 features and spelling features of the current word ( e.g. ”Is the current word capitalized and the current tag is PersonBeginning ? ”</definiens>
			</definition>
			<definition id="4">
				<sentence>a7a12a9 is an instance of a7a12a11 where a53 a8 a14 .</sentence>
				<definiendum id="0">a7a12a9</definiendum>
			</definition>
			<definition id="5">
				<sentence>1 : initialize a0a2a1 a15 a16 a14 a8a4a3 2 : repeat 3 : for all training patterns a7 a34 do 4 : compute a5a27 a8a7a6a9a8 a9a11a10 a6 a6 a27 a23 a3 a10a7 a34 a15 a27 a25 5 : if a27 a34 a32a8a12a5a27 then 6 : a16 a14a14a13 a16 a14 a56 a22 a14 a10 a7 a34 a15 a27 a34 a25 a51 a22 a14 a10 a7 a34 a15 a5 a27 a25 7 : end if 8 : end for 9 : until stopping criteria At each iteration , the perceptron algorithm calculates an approximation of the gradient of the sequential log-loss function ( Eq .</sentence>
				<definiendum id="0">perceptron algorithm</definiendum>
			</definition>
			<definition id="6">
				<sentence>The original boosting algorithm ( AdaBoost ) , presented in ( Schapire and Singer , 1999 ) , is a sequential learning algorithm to induce classifiers for single random variables .</sentence>
				<definiendum id="0">AdaBoost</definiendum>
				<definiens id="0">a sequential learning algorithm to induce classifiers for single random variables</definiens>
			</definition>
			<definition id="7">
				<sentence>a24a26a25a28a27a30a29a14 is the maximum difference of the sufficient statistic a22 a14 in any label sequence and the correct label sequence of any observation a7 a34 .</sentence>
				<definiendum id="0">a24a26a25a28a27a30a29a14</definiendum>
				<definiens id="0">the maximum difference of the sufficient statistic a22 a14 in any label sequence and the correct label sequence of any observation a7 a34</definiens>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>It was a designated task in a number of conferences , including the Message Understanding Conferences ( MUC-6 , 1995 ; MUC-7 , 1997 ) , the Information Retrieval and Extraction Conference ( IREX , 1999 ) , the Conferences on Natural Language Learning ( Tjong Kim Sang , 2002 ; Tjong Kim Sang and De Meulder , 2003 ) , and the recent Automatic Content Extraction Conference ( ACE , 2002 ) .</sentence>
				<definiendum id="0">Information Retrieval</definiendum>
				<definiendum id="1">Extraction Conference</definiendum>
				<definiendum id="2">Tjong Kim Sang</definiendum>
			</definition>
			<definition id="1">
				<sentence>The IBM-FBIS Corpus The Foreign Broadcast Information Service ( FBIS ) offers an extensive collection of translations and transcriptions of open source information monitored worldwide on diverse topics such as military affairs , politics , economics , and science and technology .</sentence>
				<definiendum id="0">IBM-FBIS Corpus The Foreign Broadcast Information Service</definiendum>
				<definiens id="0">an extensive collection of translations and transcriptions of open source information monitored worldwide on diverse topics such as military affairs , politics , economics , and science and technology</definiens>
			</definition>
			<definition id="2">
				<sentence>The IEER data The National Institute of Standard and Technology organized the Information Extraction – Entity Recognition ( IEER ) evaluation , which involves entity recognition from textual information sources in both English and Mandarin .</sentence>
				<definiendum id="0">IEER</definiendum>
				<definiens id="0">data The National Institute of Standard and Technology organized the Information Extraction – Entity Recognition ( IEER ) evaluation , which involves entity recognition from textual information sources in both English and Mandarin</definiens>
			</definition>
			<definition id="3">
				<sentence>The Mandarin training data consists of approximately 10 hours of broadcast news transcripts comprised of approximately 390 stories .</sentence>
				<definiendum id="0">Mandarin training data</definiendum>
			</definition>
			<definition id="4">
				<sentence>The IBM-FBIS training data consists of 3.1 million characters and the corresponding test data has 270,000 characters .</sentence>
				<definiendum id="0">IBM-FBIS training data</definiendum>
				<definiens id="0">consists of 3.1 million characters and the corresponding test data has 270,000 characters</definiens>
			</definition>
			<definition id="5">
				<sentence>Suppose an NE consists of four characters a9a11a10 a7a13a12 a10a15a14 a12 a10a15a16 a12 a10a15a17a19a18 , if the word segmentation merges a10 a7 with a character preceding it , then this NE can not be correctly identified by the word-based model since the boundary will be incorrect .</sentence>
				<definiendum id="0">Suppose an NE</definiendum>
				<definiens id="0">consists of four characters a9a11a10 a7a13a12 a10a15a14 a12 a10a15a16 a12 a10a15a17a19a18 , if the word segmentation merges a10 a7 with a character preceding it , then this NE can not be correctly identified by the word-based model since the boundary will be incorrect</definiens>
			</definition>
			<definition id="6">
				<sentence>( fnTBL ) Classifier Transformation-based learning is an error-driven algorithm which has two major steps : it starts by assigning some classification to each example , and then automatically proposing , evaluating and selecting the classification changes that maximally decrease the number of errors .</sentence>
				<definiendum id="0">fnTBL ) Classifier Transformation-based learning</definiendum>
				<definiens id="0">an error-driven algorithm which has two major steps : it starts by assigning some classification to each example , and then automatically proposing , evaluating and selecting the classification changes that maximally decrease the number of errors</definiens>
			</definition>
			<definition id="7">
				<sentence>The RRM and fnTBL classifiers are the best performers for the test set , followed by MaxEnt .</sentence>
				<definiendum id="0">fnTBL classifiers</definiendum>
				<definiens id="0">the best performers for the test set , followed by MaxEnt</definiens>
			</definition>
			<definition id="8">
				<sentence>The HMM classifier lags behind by around 6 Development Test Test Precision Recall F-measure Precision Recall F-measure Baseline1 17.52 % 24.92 % 20.58 14.04 % 20.52 % 16.67 Baseline2 77.86 % 45.26 % 57.24 71.06 % 40.22 % 51.37 HMM 71.38 % 80.92 % 75.85 71.73 % 77.55 % 74.53 MaxEnt 83.82 % 78.08 % 80.85 85.43 % 75.22 % 80.00 fnTBL 76.85 % 81.55 % 80.08 82.06 % 80.68 % 81.36 RRM 82.83 % 81.06 % 81.89 84.53 % 78.64 % 81.48 Table 2 : Baselines and performance of the four classifiers .</sentence>
				<definiendum id="0">HMM classifier</definiendum>
				<definiens id="0">lags behind by around 6 Development Test Test Precision Recall F-measure Precision Recall F-measure</definiens>
			</definition>
			<definition id="9">
				<sentence>In the previously described methods , also known as voting , each classifier gave its entire vote to one classification – its own output .</sentence>
				<definiendum id="0">previously described methods</definiendum>
				<definiens id="0">voting , each classifier gave its entire vote to one classification – its own output</definiens>
			</definition>
</paper>

		<paper id="1208">
			<definition id="0">
				<sentence>The HDAG Kernel directly accepts structured natural language data , such as several levels of chunks and their relations , and computes the value of the kernel function at a practical cost and time while reflecting all of these structures .</sentence>
				<definiendum id="0">HDAG Kernel</definiendum>
				<definiens id="0">accepts structured natural language data , such as several levels of chunks and their relations</definiens>
			</definition>
			<definition id="1">
				<sentence>Question classification is quite similar to Text Categorization , which is one of the major tasks in Natural Language Processing ( NLP ) .</sentence>
				<definiendum id="0">Categorization</definiendum>
			</definition>
			<definition id="2">
				<sentence>As the machine learning algorithm , we chose the Support Vector Machines ( SVMs ) ( Cortes and Vapnik , 1995 ) because the work of ( Joachims , 1998 ; Taira and Haruno , 1999 ) reported state-of-the-art performance in text categorization as long as question classification is a similar process to text categorization .</sentence>
				<definiendum id="0">Support Vector Machines</definiendum>
				<definiendum id="1">SVMs )</definiendum>
				<definiens id="0">a similar process to text categorization</definiens>
			</definition>
			<definition id="3">
				<sentence>The HDAG Kernel is a new kernel function that is designed to easily handle structured natural language data .</sentence>
				<definiendum id="0">HDAG Kernel</definiendum>
			</definition>
			<definition id="4">
				<sentence>The “attribute sequence” is a sequence of attributes extracted from the node in sub-paths of HDAGs .</sentence>
				<definiendum id="0">“attribute sequence”</definiendum>
				<definiens id="0">a sequence of attributes extracted from the node in sub-paths of HDAGs</definiens>
			</definition>
			<definition id="5">
				<sentence>The Tree Kernel ( Collins and Duffy , 2001 ) and String Subsequence Kernel ( SSK ) ( Lodhi et al. , 2002 ) are examples of instances in the Convolution Kernels developed in the NLP field .</sentence>
				<definiendum id="0">Tree Kernel</definiendum>
			</definition>
</paper>

		<paper id="1608">
			<definition id="0">
				<sentence>For sentences involving verbs that have particles , the Link Parser connects the object of the verb directly to the verb itself , attaching the particle separately .</sentence>
				<definiendum id="0">Link Parser</definiendum>
				<definiens id="0">connects the object of the verb directly to the verb itself , attaching the particle separately</definiens>
			</definition>
			<definition id="1">
				<sentence>The initial default score of any paraphrase is one ( assuming perfect anchor matches ) , but for each additional occurrence the score is incremented by 1 2 n , where n is the number of times the current set of anchors has been seen .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of times the current set of anchors has been seen</definiens>
			</definition>
			<definition id="2">
				<sentence>The simplest approach to overcoming the “paraphrase problem” in question answering is via keyword query expansion when searching for candidate answers : ( AND X became state ) ⇐⇒ ( AND X admitted Union ) ( AND X killed ) ⇐⇒ ( AND X ended life ) The major drawback of such techniques is overgeneration of bogus answer candidates .</sentence>
				<definiendum id="0">AND X ended life</definiendum>
				<definiens id="0">via keyword query expansion when searching for candidate answers : ( AND X became state</definiens>
			</definition>
</paper>

		<paper id="1405">
			<definition id="0">
				<sentence>Thus , IDEA uses the source domains of BUILDING and FOOD for different reasons , namely to convey information related to ‘structure’ or ‘processing’ ( i.e. ‘understanding’ ) respectively .</sentence>
				<definiendum id="0">IDEA</definiendum>
				<definiens id="0">uses the source domains of BUILDING and FOOD for different reasons , namely to convey information related to ‘structure’ or ‘processing’ ( i.e. ‘understanding’ ) respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>SUMO ( Suggested Upper Merged Ontology – http : //ontology.teknowledge.com ) is a shared upper ontology developed by the IEEE sanctioned IEEE Standard Upper Ontology Working Group .</sentence>
				<definiendum id="0">SUMO</definiendum>
				<definiens id="0">a shared upper ontology developed by the IEEE sanctioned IEEE Standard Upper Ontology Working Group</definiens>
			</definition>
			<definition id="2">
				<sentence>In order to test the feasibility of using SUMO to aid the analysis of Mapping Principles within the framework of the CM Model , we searched the Academia Sinica Balanced Corpus , a tagged corpus of over 5 million words of modern Mandarin usage in Taiwan ( available on the Internet : http : //www.sinica.edu.tw/SinicaCorpus/ ) .</sentence>
				<definiendum id="0">Academia Sinica Balanced Corpus</definiendum>
				<definiens id="0">a tagged corpus of over 5 million words of modern Mandarin usage in Taiwan ( available on the Internet : http : //www.sinica.edu.tw/SinicaCorpus/ )</definiens>
			</definition>
			<definition id="3">
				<sentence>We suggest that this is because WAR is a subset of the source domain of COMPETITION ( i.e. a violent contest ) in the SUMO representation , as discussed below .</sentence>
				<definiendum id="0">WAR</definiendum>
				<definiens id="0">a subset of the source domain of COMPETITION</definiens>
			</definition>
			<definition id="4">
				<sentence>In SUMO , a War is a kind of ViolentContest , which in term is a kind of Contest .</sentence>
				<definiendum id="0">War</definiendum>
			</definition>
			<definition id="5">
				<sentence>It is appropriate to note here that based on WordNet to SUMO mapping , economy is a SocialInteraction , and Contest is a subclass of SocialInteraction .</sentence>
				<definiendum id="0">economy</definiendum>
				<definiendum id="1">Contest</definiendum>
				<definiens id="0">a subclass of SocialInteraction</definiens>
			</definition>
</paper>

		<paper id="1304">
			<definition id="0">
				<sentence>Stemming is a procedure of transforming an inflected form to its root form .</sentence>
				<definiendum id="0">Stemming</definiendum>
				<definiens id="0">a procedure of transforming an inflected form to its root form</definiens>
			</definition>
			<definition id="1">
				<sentence>The t-value for each word i is formulated as follows : Ns ux t i ii i / 2 − = Where N = 4n 15 , N countn x i i _ = , ) 1 ( 2 iii pps −×= , ncountnp ii /_= , iproteini ppu ×= , and protein p is the probability of protein .</sentence>
				<definiendum id="0">protein p</definiendum>
				<definiens id="0">the probability of protein</definiens>
			</definition>
			<definition id="2">
				<sentence>Yapex system ( Olsson et al. , 2002 ) is adopted to propose candidates , and collocates are served as restrictions to filter out less possible protein names .</sentence>
				<definiendum id="0">Yapex system</definiendum>
				<definiens id="0">adopted to propose candidates , and collocates are served as restrictions to filter out less possible protein names</definiens>
			</definition>
</paper>

		<paper id="1809">
			<definition id="0">
				<sentence>Verb-particle constructions ( hereafter referred to as VPCs ) consist of a head verb and one or more obligatory particles , in the form of intransitive prepositions ( e.g. hand in ) , adjectives ( e.g. cut short ) or verbs ( e.g. let go ) .</sentence>
				<definiendum id="0">Verb-particle constructions</definiendum>
				<definiens id="0">in the form of intransitive prepositions ( e.g. hand in ) , adjectives ( e.g. cut short ) or verbs</definiens>
			</definition>
			<definition id="1">
				<sentence>The same idea can be generalised to the relationship between simplex verbs ( e.g. walk ) and VPCs ( e.g. walk off ) .</sentence>
				<definiendum id="0">VPCs</definiendum>
				<definiens id="0">e.g. walk off )</definiens>
			</definition>
			<definition id="2">
				<sentence>LSI is an information retrieval technique based on Singular Value Decomposition ( SVD ) , and works by projecting a term-document matrix onto a lower-dimensional subspace , in which relationships might more easily be 2Concatenated into a single-word item Majority Centroid 60 % Agreement ( p =.255 ) ( p=.043 ) ( p=.488 ) ( p=.137 ) ( p=.924 ) ( p =.018 ) Table 3 : Logistic regression for Method 4 observed between terms which are related but do not co-occur .</sentence>
				<definiendum id="0">LSI</definiendum>
				<definiens id="0">an information retrieval technique based on Singular Value Decomposition ( SVD ) , and works by projecting a term-document matrix onto a lower-dimensional subspace</definiens>
			</definition>
			<definition id="3">
				<sentence>Multiword expressions : A pain in the neck for NLP .</sentence>
				<definiendum id="0">Multiword expressions</definiendum>
				<definiens id="0">A pain in the neck for NLP</definiens>
			</definition>
</paper>

		<paper id="1211">
			<definition id="0">
				<sentence>The case restoration approach has the following advantages : ( i ) the training corpus is almost limitless , resulting in a high performance model , with no knowledge bottleneck as faced by many supervised learning scenarios , ( ii ) the case restoration approach is applicable no matter whether the core system is statistical model , a hand-crafted rule system or a hybrid , ( iii ) when the core system consists of multiple modules , as is the case for the QA system used in the experiments that is based on multi-level NLP/IE , the case restoration approach relieves the burden of having to re-train or adapt each module in respect of case insensitive input , and ( iv ) the restoration approach reduces the system complexity : the burden of handling degraded text ( case in this case ) is reduced to a preprocessing module while all other components need no changes .</sentence>
				<definiendum id="0">system complexity</definiendum>
				<definiens id="0">the following advantages : ( i ) the training corpus is almost limitless , resulting in a high performance model , with no knowledge bottleneck as faced by many supervised learning scenarios</definiens>
				<definiens id="1">applicable no matter whether the core system is statistical model</definiens>
				<definiens id="2">the case for the QA system used in the experiments that is based on multi-level NLP/IE , the case restoration approach relieves the burden of having to re-train or adapt each module in respect of case insensitive input</definiens>
			</definition>
			<definition id="1">
				<sentence>Given a word sequence nn00 fwfw W G16= ( where j f denotes a single token feature which are defined as above ) , the goal for the case restoration task is to find the optimal tag sequence n210 tttt T G16= , which maximizes the conditional probability W ) | Pr ( T [ Bikel et al. 1999 ] .</sentence>
				<definiendum id="0">j f</definiendum>
			</definition>
			<definition id="2">
				<sentence>The back-off model is as follows , ) t , w| ) Pr ( tt , t|f , wPr ( ) - ( 1 ) t , f , w|t , f , w ( P ) t , f , w|t , f , wPr ( 1i1ii1iiii1 1i1-i1-iiii01 1i1-i1-iiii −−− − − + = λ λ ) t|f , wPr ( ) - ( 1 ) t , t|f , w ( P ) t , t|f , wPr ( iii21iiii02 1iiii λλ += − − ) w|Pr ( t ) - ( 1 ) t , w| ( tP ) t , w|Pr ( t 1-ii31i1-ii03 1i1-ii λλ += − − ) t| ( f ) Pt| ( wPr ) - ( 1 ) t|f , w ( P ) t|f , wPr ( ii0ii4iii04 iii λλ += ) t ( P ) - ( 1 ) w| ( tP ) w|Pr ( t i051-ii051-ii λλ += V 1 ) - ( 1 ) t| ( wP ) t|Pr ( w 6ii06ii λλ += where V denotes the size of the vocabulary , the back-off coefficients λ’s are determined using the Witten-Bell smoothing algorithm , and the quantities ) t , f , w|t , f , w ( P 1i1i1iiii0 −−− , ) t , t|f , w ( P 1iiii0 − , ) t , w| ( tP 1i1-ii0 − , ) t|f , w ( P iii0 , ) t| ( fP ii0 , ) w| ( tP 1-ii0 , ) ( tP i0 , and ) t| ( wP ii0 are computed by the maximum likelihood estimation .</sentence>
				<definiendum id="0">wPr</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">t|f , wPr ( ) - ( 1 ) t , f , w|t , f , w ( P ) t , f , w|t , f</definiens>
				<definiens id="1">the size of the vocabulary , the back-off coefficients λ’s are determined using the Witten-Bell smoothing algorithm , and the quantities ) t , f , w|t , f</definiens>
				<definiens id="2">tP 1i1-ii0 − , ) t|f , w</definiens>
			</definition>
			<definition id="3">
				<sentence>InfoXtract : A Customizable Intermediate Level Information Extraction Engine .</sentence>
				<definiendum id="0">InfoXtract</definiendum>
			</definition>
</paper>

		<paper id="1204">
			<definition id="0">
				<sentence>The CSJ is a large collection of monologues , such as lectures , and it includes transcriptions of each speech as well as the voice data .</sentence>
				<definiendum id="0">CSJ</definiendum>
				<definiens id="0">a large collection of monologues , such as lectures , and it includes transcriptions of each speech as well as the voice data</definiens>
			</definition>
			<definition id="1">
				<sentence>Scorelen ( Si ) = 0 ( if Li ‚ C ) Li ¡C ( otherwise ) The third function combines the above two approaches , i.e. , it returns the length of a sentence that has at least a certain length , and otherwise returns a negative value as a penalty : L3 .</sentence>
				<definiendum id="0">Scorelen</definiendum>
			</definition>
			<definition id="2">
				<sentence>Scorelen ( Si ) = Li ( if Li ‚ C ) = Li ¡C ( otherwise ) The length of a sentence means the number of letters , and based on the results of an experiment with the training data , we set C to 20 for the TSC and CSJ data .</sentence>
				<definiendum id="0">Scorelen</definiendum>
				<definiens id="0">length of a sentence means the number of letters , and based on the results of an experiment with the training data</definiens>
			</definition>
			<definition id="3">
				<sentence>The first function uses the raw term frequencies , while the other two are two different ways of normalizing the frequencies , as follows , where DN is the number of documents given : T1 .</sentence>
				<definiendum id="0">DN</definiendum>
			</definition>
			<definition id="4">
				<sentence>The function estimates the relevance between a headline ( H ) and a sentence ( Si ) by using the tf*idf values of the words ( w ) in the headline : Scorehl ( Si ) = X w2H\Si tf ( w ) tf ( w ) +1 log DN df ( w ) X w2H tf ( w ) tf ( w ) +1 log DN df ( w ) We also evaluated another method based on this scoring function by using only named entities ( NEs ) instead of words for the TSC data and DUC data .</sentence>
				<definiendum id="0">function</definiendum>
				<definiens id="0">estimates the relevance between a headline ( H ) and a sentence ( Si ) by using the tf*idf values of the words ( w ) in the headline : Scorehl ( Si ) = X w2H\Si tf</definiens>
			</definition>
			<definition id="5">
				<sentence>The total score ( Si ) is defined from the scoring functions ( Scorej ( ) ) and weights ( fij ) as follows : TotalScore ( Si ) = X j fijScorej ( Si ) ( 1 ) We estimated the optimal values of these weights from the training data .</sentence>
				<definiendum id="0">total score</definiendum>
				<definiendum id="1">Si</definiendum>
				<definiens id="0">the scoring functions ( Scorej ( ) ) and weights ( fij ) as follows : TotalScore ( Si ) = X j fijScorej ( Si ) ( 1 ) We estimated the optimal values of these weights from the training data</definiens>
			</definition>
			<definition id="6">
				<sentence>The ‘Lead’ 1The definitions of each measurement are as follows : Recall ( REC ) = COR / GLD Precision ( PRE ) = COR / SYS F-measure = 2 * REC * PRE / ( REC + PRE ) , where COR is the number of correct sentences marked by the system , GLD is the total number of correct sentences marked by humans , and SYS is the total number of sentences marked by the system .</sentence>
				<definiendum id="0">REC</definiendum>
				<definiendum id="1">COR</definiendum>
				<definiendum id="2">GLD</definiendum>
				<definiendum id="3">SYS</definiendum>
				<definiens id="0">Recall ( REC ) = COR / GLD Precision ( PRE ) = COR / SYS F-measure = 2 *</definiens>
				<definiens id="1">the number of correct sentences marked by the system</definiens>
				<definiens id="2">the total number of correct sentences marked by humans</definiens>
			</definition>
</paper>

		<paper id="0406">
			<definition id="0">
				<sentence>In this paper , we improve an unsupervised learning method using the ExpectationMaximization ( EM ) algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation ( WSD ) problems .</sentence>
				<definiendum id="0">ExpectationMaximization</definiendum>
				<definiens id="0">text classification problems in order to apply it to word sense disambiguation ( WSD ) problems</definiens>
			</definition>
			<definition id="1">
				<sentence>It is hoped that this method can be applied to WSD , because WSD is the most important problem in natural language processing .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">the most important problem in natural language processing</definiens>
			</definition>
			<definition id="2">
				<sentence>The Japanese Dictionary Task is a standard WSD problem .</sentence>
				<definiendum id="0">Japanese Dictionary Task</definiendum>
				<definiens id="0">a standard WSD problem</definiens>
			</definition>
			<definition id="3">
				<sentence>Co-training ( Blum and Mitchell , 1998 ) is a powerful unsupervised learning method .</sentence>
				<definiendum id="0">Co-training</definiendum>
				<definiens id="0">a powerful unsupervised learning method</definiens>
			</definition>
</paper>

		<paper id="0508">
</paper>

		<paper id="1100">
</paper>

		<paper id="1113">
			<definition id="0">
				<sentence>As stated above , dynamic programming ( DP ) matching is a conversion of edit distance .</sentence>
				<definiendum id="0">DP ) matching</definiendum>
				<definiens id="0">a conversion of edit distance</definiens>
			</definition>
			<definition id="1">
				<sentence>While the edit distance ( ED ) is a measure of difference , counting different characters between two strings , SIM1 is a measure of similarity , counting matching characters between two strings .</sentence>
				<definiendum id="0">SIM1</definiendum>
				<definiens id="0">a measure of difference , counting different characters between two strings</definiens>
				<definiens id="1">a measure of similarity , counting matching characters between two strings</definiens>
			</definition>
			<definition id="2">
				<sentence>† If both strings are empty then ED ( “” ; “” ) = 0:0 † If x 6= y then ED ( x ; y ) = 1:0 † If their first characters are the same then ED ( xfi ; xfl ) = MIN ( ED ( fi ; xfl ) ; ED ( xfi ; fl ) ; ED ( fi ; fl ) +1:0 ) † Otherwise ED ( xfi ; yfl ) = MIN ( ED ( fi ; yfl ) ; ED ( xfi ; fl ) ; ED ( fi ; fl ) ) Definition 2.2 SIM1 Let fi and fl be strings , x and y be a character , and “” be empty string .</sentence>
				<definiendum id="0">characters</definiendum>
				<definiendum id="1">yfl ) ; ED</definiendum>
				<definiendum id="2">fi ; fl )</definiendum>
				<definiens id="0">a character , and “” be empty string</definiens>
			</definition>
			<definition id="3">
				<sentence>SIM2 is defined as follows : Definition 2.3 SIM2 Let fi and fl be strings , x and y be a character , and “” be empty string .</sentence>
				<definiendum id="0">SIM2</definiendum>
				<definiens id="0">follows : Definition 2.3 SIM2 Let fi and fl be strings , x and y be a character , and “” be empty string</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , ”chirimenjyako” is a Japanese word that could be a retrieval key word .</sentence>
				<definiendum id="0">”chirimenjyako”</definiendum>
				<definiens id="0">a Japanese word that could be a retrieval key word</definiens>
			</definition>
			<definition id="5">
				<sentence>Several language systems use Kanji characters ( e.g. Chinese and Japanese ) , and bigram is an effective indexing unit for information retrieval for these language systems ( Ogawa and Matsuda , 1997 ) .</sentence>
				<definiendum id="0">Kanji characters</definiendum>
				<definiendum id="1">bigram</definiendum>
				<definiens id="0">an effective indexing unit for information retrieval for these language systems</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus , we have restricted the weighting function Score as follows , where K is the number decided by the given query .</sentence>
				<definiendum id="0">K</definiendum>
				<definiens id="0">the number decided by the given query</definiens>
			</definition>
</paper>

		<paper id="1114">
			<definition id="0">
				<sentence>An N-gram is a character sequence of length N extracted from a document .</sentence>
				<definiendum id="0">N-gram</definiendum>
				<definiens id="0">a character sequence of length N extracted from a document</definiens>
			</definition>
			<definition id="1">
				<sentence>The time complexity for the algorithm is O ( kn ) , where k is bucket size and n is the number of documents .</sentence>
				<definiendum id="0">time complexity</definiendum>
				<definiendum id="1">k</definiendum>
				<definiendum id="2">n</definiendum>
				<definiens id="0">the number of documents</definiens>
			</definition>
			<definition id="2">
				<sentence>NewsML , which is released by International Press and Telecommunications Council ( IPTC ) ( www.iptc.org ) , is an XML-based data format for news that is intended to use for the creation , transfer and delivery of news .</sentence>
				<definiendum id="0">NewsML</definiendum>
				<definiens id="0">an XML-based data format for news that is intended to use for the creation , transfer and delivery of news</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus , the &lt; KeywordLine &gt; Tag is a useful indicator for keyword extraction .</sentence>
				<definiendum id="0">&lt; KeywordLine &gt; Tag</definiendum>
				<definiens id="0">a useful indicator for keyword extraction</definiens>
			</definition>
			<definition id="4">
				<sentence>Performance metrics are based on Recall and Precision , which are defined as follows : In event Not in event In cluster A B Not in cluster C D Recall = A / ( A+C ) if A+C &gt; 0 Precision = A / ( A+B ) if A+B &gt; 0 To study the effect of NewsML , we calculated the percentage of recall and precision under different threshold values .</sentence>
				<definiendum id="0">Performance metrics</definiendum>
				<definiens id="0">based on Recall and Precision , which are defined as follows : In event Not in event In cluster A B Not in cluster C D Recall = A / ( A+C ) if A+C &gt; 0 Precision = A / ( A+B ) if A+B &gt; 0 To study the effect of NewsML , we calculated the percentage of recall and precision under different threshold values</definiens>
			</definition>
			<definition id="5">
				<sentence>In our experiment , we chose NewsML as a representation of news content with added meta-data .</sentence>
				<definiendum id="0">NewsML</definiendum>
				<definiens id="0">a representation of news content with added meta-data</definiens>
			</definition>
			<definition id="6">
				<sentence>News Focus consists of a clustering function .</sentence>
				<definiendum id="0">News Focus</definiendum>
			</definition>
</paper>

		<paper id="0301">
			<definition id="0">
				<sentence>( not 0 ) Æ position L2 represents the position of the token that is aligned from the text in language L2 ; again , the first token is token 1 .</sentence>
				<definiendum id="0">L2</definiendum>
				<definiens id="0">the position of the token that is aligned from the text in language L2</definiens>
			</definition>
			<definition id="1">
				<sentence>Fourday combines several intuitive baselines via a nearest neighbor classifier , RACAI carries out a greedy alignment based on an automatically extracted dictionary of translations , and UMD’s implementation of IBM Model 2 provides an experimental platform for their future work incorporating prior knowledge about cognates .</sentence>
				<definiendum id="0">Fourday</definiendum>
				<definiens id="0">combines several intuitive baselines via a nearest neighbor classifier , RACAI carries out a greedy alignment based on an automatically extracted dictionary of translations , and UMD’s implementation of IBM Model 2 provides an experimental platform for their future work incorporating prior knowledge about cognates</definiens>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>Classification WordNet ( Fellbaum , 1998 ) is a broad-coverage machine-readable dictionary .</sentence>
				<definiendum id="0">Classification WordNet</definiendum>
			</definition>
			<definition id="1">
				<sentence>WordNet is organized as a network of lexicalized concepts , sets of synonyms called synsets ; e.g. , the nouns a21 chairman , chairwoman , chair , chairpersona22 form a synset .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">a network of lexicalized concepts , sets of synonyms called synsets ; e.g. , the nouns a21 chairman , chairwoman , chair</definiens>
			</definition>
			<definition id="2">
				<sentence>WordNet contains a great deal of information about words and word senses .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">contains a great deal of information about words and word senses</definiens>
			</definition>
			<definition id="3">
				<sentence>Bllip ( BLLIP , 2000 ) is a 40-million-word syntactically parsed corpus .</sentence>
				<definiendum id="0">Bllip</definiendum>
				<definiens id="0">a 40-million-word syntactically parsed corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>Thus a90 summarizes a7 word tokens that belong to the dictionary , where each instance a27 is represented as a vector of features a3 a10 extracted from the context in which the noun occurred ; a146 is the total number of features ; and a97 a10 is the true label of a3a28a10 .</sentence>
				<definiendum id="0">a146</definiendum>
				<definiendum id="1">a97 a10</definiendum>
				<definiens id="0">the total number of features</definiens>
			</definition>
			<definition id="5">
				<sentence>The label a183 a93 a7 a98 of a noun type a7 is obtained by voting4 : a183 a93 a7 a98 a91a184a149a136a150a49a151a75a152a153a149a126a154 a125a4a155a136a156a186a185 a187 a155 a100 a188 a121 a93 a3 a122 a115 a98 a91 a97a190a189 ( 4 ) where a188 a120a191a189 is the indicator function and a3 a104 a7 means that a3 is a token of type a7 .</sentence>
				<definiendum id="0">a188 a120a191a189</definiendum>
				<definiens id="0">the indicator function and a3 a104 a7 means that a3 is a token of type a7</definiens>
			</definition>
</paper>

		<paper id="1904">
			<definition id="0">
				<sentence>This paper describes FrameNet ( Lowe et al. , 1997 ; Baker et al. , 1998 ; Fillmore et al. , 2002 ) , an online lexical resource for English based on the principles of frame semantics ( Fillmore , 1977a ; Fillmore , 1982 ; Fillmore and Atkins , 1992 ) , and considers the FrameNet database in reference to the proposed ISO model for linguistic annotation of language resources ( ISO TC37 SC4 ) ( ISO , 2002 ; Ide and Romary , 2001b ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">Lowe et al. , 1997 ; Baker et al. , 1998 ; Fillmore et al. , 2002 ) , an online lexical resource for English based on the principles of frame semantics</definiens>
			</definition>
			<definition id="1">
				<sentence>A semantic frame is a script-like structure of inferences , which are linked to the meanings of linguistic units ( lexical items ) .</sentence>
				<definiendum id="0">semantic frame</definiendum>
			</definition>
			<definition id="2">
				<sentence>Each frame identifies a set of frame elements ( FEs ) , which are frame-specific semantic roles ( participants , props , phases of a state of affairs ) .</sentence>
				<definiendum id="0">FEs )</definiendum>
				<definiens id="0">frame-specific semantic roles ( participants , props , phases of a state of affairs</definiens>
			</definition>
			<definition id="3">
				<sentence>The FrameNet database documents the range of semantic and syntactic combinatory possibilities ( valences ) of each word in each of its senses , through manual annotation of example sentences and automatic summarization of the resulting annotations .</sentence>
				<definiendum id="0">FrameNet database</definiendum>
				<definiens id="0">documents the range of semantic and syntactic combinatory possibilities ( valences ) of each word in each of its senses</definiens>
			</definition>
			<definition id="4">
				<sentence>The FrameNet database records information about several different kinds of semantic relations , consisting mostly of frame-to-frame relations which indicate semantic relationships between collections of concepts .</sentence>
				<definiendum id="0">FrameNet database</definiendum>
				<definiens id="0">records information about several different kinds of semantic relations , consisting mostly of frame-to-frame relations which indicate semantic relationships between collections of concepts</definiens>
			</definition>
			<definition id="5">
				<sentence>Frame Inheritance is a relationship by which a single frame can be seen as an elaboration of one or more other parent frames , with bindings between the inherited semantic roles .</sentence>
				<definiendum id="0">Frame Inheritance</definiendum>
				<definiens id="0">a relationship by which a single frame can be seen as an elaboration of one or more other parent frames , with bindings between the inherited semantic roles</definiens>
			</definition>
			<definition id="6">
				<sentence>The FrameNet database contains descriptions of more than 7,000 lexical units based on more than 130,000 annotated sentences .</sentence>
				<definiendum id="0">FrameNet database</definiendum>
				<definiens id="0">contains descriptions of more than 7,000 lexical units based on more than 130,000 annotated sentences</definiens>
			</definition>
			<definition id="7">
				<sentence>The FrameNet database differs from existing lexical resources in the specificity of the frames and semantic roles it defines , the information it provides about relations between frames , and the degree of detail provided on the possible syntactic realizations of semantic roles for each LU .</sentence>
				<definiendum id="0">FrameNet database</definiendum>
				<definiens id="0">differs from existing lexical resources in the specificity of the frames and semantic roles it defines , the information it provides about relations between frames</definiens>
			</definition>
			<definition id="8">
				<sentence>FrameNet also differs from WordNet in showing semantic relations across parts of speech , and in providing contextual information enriched with semantics ( beyond the ”Someone s something” format of WordNet argument-structure representations ) .</sentence>
				<definiendum id="0">FrameNet</definiendum>
				<definiens id="0">differs from WordNet in showing semantic relations across parts of speech , and in providing contextual information enriched with semantics</definiens>
			</definition>
			<definition id="9">
				<sentence>Most of that information is currently being represented using the Hypertext Markup Language ( HTML ) , which is designed to allow web developers to display information in a way that is accessible to humans for viewing via web browsers .</sentence>
				<definiendum id="0">Hypertext Markup Language</definiendum>
				<definiens id="0">is designed to allow web developers to display information in a way that is accessible to humans for viewing via web browsers</definiens>
			</definition>
			<definition id="10">
				<sentence>The World Wide Web Consortium ( W3C ) has developed the Extensible Markup Language ( XML ) which allows information to be more accurately described using tags .</sentence>
				<definiendum id="0">World Wide Web Consortium</definiendum>
			</definition>
			<definition id="11">
				<sentence>However , XML has a limited capability to describe the relationships ( schemas or ontologies ) with respect to objects .</sentence>
				<definiendum id="0">XML</definiendum>
				<definiens id="0">has a limited capability to describe the relationships ( schemas or ontologies</definiens>
			</definition>
			<definition id="12">
				<sentence>The latest release of the language ( DAML+OIL ) ( http : //www.daml.org ) provides a rich set of constructs with which to create ontologies and to markup information so that it is machine readable and understandable .</sentence>
				<definiendum id="0">latest release of the language</definiendum>
				<definiendum id="1">DAML+OIL ) ( http</definiendum>
				<definiens id="0">a rich set of constructs with which to create ontologies and to markup information so that it is machine readable and understandable</definiens>
			</definition>
			<definition id="13">
				<sentence>We use the XML entity model to use shortcuts with referring to the URIs.2 The other DAML+OIL ontologies used in the FrameNet description include the DAML-S ( http : //www.daml.org/services ) service ontologies , the OpenCYC DAML ontology ( http : // www.cyc.com/2002/04/08/cyc.daml ) , and the SRI time ontology ( http : // www.ai.sri.com/ daml/ontologies/ sribasic/1-0/Time .</sentence>
				<definiendum id="0">OpenCYC DAML ontology</definiendum>
				<definiendum id="1">SRI time ontology</definiendum>
				<definiens id="0">ontologies used in the FrameNet description include the DAML-S ( http : //www.daml.org/services ) service ontologies</definiens>
			</definition>
			<definition id="14">
				<sentence>The domain of the Lexical Unit is a Lemma or word and its range is a Frame .</sentence>
				<definiendum id="0">Lexical Unit</definiendum>
				<definiens id="0">a Lemma or word</definiens>
			</definition>
			<definition id="15">
				<sentence>&lt; daml : ObjectProperty rdf : ID= '' bindingRelation '' &gt; &lt; rdfs : domain rdf : resource= '' # Role '' / &gt; &lt; rdfs : range rdf : resource= '' # Role '' / &gt; &lt; /daml : ObjectProperty &gt; By far the most important binding relation is the identification of roles ( i.e. they refer to the same value ( object ) ) .</sentence>
				<definiendum id="0">ObjectProperty rdf</definiendum>
				<definiendum id="1">most important binding relation</definiendum>
				<definiens id="0">the identification of roles</definiens>
			</definition>
			<definition id="16">
				<sentence>&lt; daml : ObjectProperty rdf : ID= '' precedes '' &gt; &lt; rdfs : domain rdf : resource= '' # subFrame '' / &gt; &lt; rdfs : range rdf : resource= '' # subFrame '' / &gt; &lt; /daml : ObjectProperty &gt; We can define a property temporalOrdering that is the transitive version of precedes .</sentence>
				<definiendum id="0">ObjectProperty rdf</definiendum>
				<definiens id="0">the transitive version of precedes</definiens>
			</definition>
			<definition id="17">
				<sentence>In each case , there are three coextensive labels ; thus the word Police , in text positions 0-5 expresses the FE AUTHORITIES ( line 10 ) , has the phrase type “NP” ( line 24 ) and is the subject of the verb nab , which we refer to as external argument “Ext” ( line 17 ) .</sentence>
				<definiendum id="0">FE AUTHORITIES</definiendum>
				<definiens id="0">has the phrase type “NP” ( line 24 ) and is the subject of the verb nab</definiens>
			</definition>
			<definition id="18">
				<sentence>This is contrary to the general sense of the ISO standard , which uses indirect pointers to an entirely separate document containing the primary data .</sentence>
				<definiendum id="0">ISO standard</definiendum>
				<definiens id="0">uses indirect pointers to an entirely separate document containing the primary data</definiens>
			</definition>
</paper>

		<paper id="2002">
			<definition id="0">
				<sentence>The power of ANNs is derived from their learning capability defined as a change in the weight matrix ( W ) , which represents the strength of the links among nodes .</sentence>
				<definiendum id="0">power of ANNs</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Kohonen self-organizing map ( SOM ) model is a specific kind of ANN which implements in only one step the tasks of classing and mapping a data set .</sentence>
				<definiendum id="0">Kohonen self-organizing map</definiendum>
				<definiendum id="1">SOM ) model</definiendum>
				<definiens id="0">a specific kind of ANN which implements in only one step the tasks of classing and mapping a data set</definiens>
			</definition>
			<definition id="2">
				<sentence>Moreover , the SOM represents the results of its classing process in an ordered twodimensional space ( R 2 ) .</sentence>
				<definiendum id="0">SOM</definiendum>
				<definiens id="0">represents the results of its classing process in an ordered twodimensional space ( R 2 )</definiens>
			</definition>
			<definition id="3">
				<sentence>This is achieved through the following computation : W ki ( t+1 ) = W ki ( t ) + α ( t ) × h ( t ) × [ X i ( t ) – W ki ( t ) ] , for 1 ≤ i ≤ N where α ( t ) is a gain term ( 0 ≤ α ( t ) ≤ 1 ) that decreases in time and converges to 0 , and h ( t ) is the neighborhood function .</sentence>
				<definiendum id="0">h</definiendum>
				<definiens id="0">a gain term ( 0 ≤ α ( t ) ≤ 1 ) that decreases in time and converges to 0 , and</definiens>
			</definition>
			<definition id="4">
				<sentence>The set of V all possible viewpoints issued from the description space D of a document set can be defined as : V = { v 1 , v 2 , … , v n } , v i ∈ P ( D ) , with Dv n 1i i = = U where each v i represents a viewpoint and P ( D ) represents the set of the parts of the description space of the documents D ; the union of the different viewpoints constitutes the description space of the documents .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">all possible viewpoints issued from the description space D of a document set can be defined as : V = { v 1 , v 2 , … , v n } , v</definiens>
				<definiens id="1">the set of the parts of the description space of the documents D</definiens>
			</definition>
			<definition id="5">
				<sentence>In IR [ 29 ] , the Recall R represents the ratio between the number of relevant documents which have been returned by an IR system for a given query and the total number of relevant documents which should have been found in the documentary database .</sentence>
				<definiendum id="0">Recall R</definiendum>
				<definiens id="0">represents the ratio between the number of relevant documents</definiens>
			</definition>
			<definition id="6">
				<sentence>The Precision P represents the ratio between the number of relevant documents which have been returned by an IR system for a given query and the total number of documents returned for the said query .</sentence>
				<definiendum id="0">Precision P</definiendum>
				<definiendum id="1">IR system</definiendum>
				<definiens id="0">represents the ratio between the number of relevant documents</definiens>
			</definition>
			<definition id="7">
				<sentence>Let us consider a set of classes C resulting from a classification method applied on a set of documents D , the Recall measure is expressed as : ∑∑ ∈∈ = c Sp p p Cc c C c SC R * * 11 , ∑∑ ∈∈ = c Sp p Cc c c c SC P * 11 where S c is the set of properties which are peculiar to the class c that is described as : ( )           =∈∈= ∈Cc p p c c W MaxWcddpS c ' ' , where C represents the peculiar set of classes 3 The content of a class is represented by the subset of original data that have been associated to it by the classification process .</sentence>
				<definiendum id="0">S c</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the set of properties which are peculiar to the class c that is described as : ( )           =∈∈= ∈Cc p p c</definiens>
				<definiens id="1">the peculiar set of classes 3 The content of a class is represented by the subset of original data that have been associated to it by the classification process</definiens>
			</definition>
			<definition id="8">
				<sentence>extracted from the classes of C , which verifies : { } ∅≠∈= c SCcC and : ∑∑ ∑ ∈∈ ∈ = Cccd p d cd p d p c W W W '' where p x W represents the weight of the property p for element x. Similarly to IR , the F-measure ( described by Eq .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiens id="0">the weight of the property p for element x. Similarly to IR , the</definiens>
			</definition>
</paper>

		<paper id="1810">
</paper>

		<paper id="0500">
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>CONTENT SELECTION is the task of choosing the right information to communicate in the output of a Natural Language Generation ( NLG ) system , given semantic input and a communicative goal .</sentence>
				<definiendum id="0">CONTENT SELECTION</definiendum>
				<definiens id="0">the task of choosing the right information to communicate in the output of a Natural Language Generation ( NLG ) system , given semantic input and a communicative goal</definiens>
			</definition>
			<definition id="1">
				<sentence>In particular , we employed the cross entropy4 between two language models a1 a1 and a1 a2 , defined as follows ( where a2a4a3a6a5a8a7a10a9 is the probability that a1 assigns to the a11 -gram a7 ) : a12a14a13 a5 a1 a1 a44 a1 a2 a9a16a15a18a17a10a19a21a20a22a2a23a3a25a24a26a5a8a27a28a9a30a29a32a31a34a33a35a2a23a3a37a36a38a5a8a27a28a9 ( 1 ) Smaller values of a12a14a13 a5 a1 a1 a44 a1 a2a39a9 indicate that a1 a1 is more similar to a1 a2 .</sentence>
				<definiendum id="0">a2a4a3a6a5a8a7a10a9</definiendum>
				<definiens id="0">the probability that a1 assigns to the a11 -gram a7 ) : a12a14a13 a5 a1 a1 a44 a1 a2 a9a16a15a18a17a10a19a21a20a22a2a23a3a25a24a26a5a8a27a28a9a30a29a32a31a34a33a35a2a23a3a37a36a38a5a8a27a28a9 ( 1 ) Smaller values of a12a14a13 a5 a1 a1 a44 a1 a2a39a9 indicate that a1 a1 is more similar to a1 a2</definiens>
			</definition>
			<definition id="2">
				<sentence>For instance , distinguish two levels of content determination , “local” content determination is the “selection of relatively small knowledge structures , each of which will be used to generate one or two sentences” while “global” content determination is “the process of deciding which of these structures to include in an explanation” .</sentence>
				<definiendum id="0">“local” content determination</definiendum>
				<definiens id="0">distinguish two levels of content determination</definiens>
			</definition>
</paper>

		<paper id="1111">
			<definition id="0">
				<sentence>Latent Semantic Indexing ( LSI ) is an enhancement of the familiar Vector Model of IR .</sentence>
				<definiendum id="0">Latent Semantic Indexing ( LSI )</definiendum>
				<definiens id="0">an enhancement of the familiar Vector Model of IR</definiens>
			</definition>
			<definition id="1">
				<sentence>'' ks≤≤1 sq G Ks≤ ( ) ( ) ( ) local localT Ts k kscore qid q A d A=</sentence>
				<definiendum id="0">'' ks≤≤1 sq G Ks≤ ( ) ( ) ( )</definiendum>
			</definition>
			<definition id="2">
				<sentence>&lt; Figure 1 : Implementation architecture Figure 1 shows overall the architecture of the experiment. The procedure is described as follows : sets the relevant sets. In some cases the relevant sets are derived from the known relevant documents and in other cases we regarded the top returned documents as the relevant sets. on documents identi ed in 2. vector into the user-cared feature space , and then using the standard Cosine measure to get the nal score for this query. the next query in the same way. Step 1 is pre-processing procedure for IR system. Only the tag removal , upper case characters transverse , stoplist removal and Porter’s stemming were adopted in this phase ( Frakes and Baeza-Yates , 1992 ) . Next , the smart ltc term weighting scheme ( Salton and McGill , 1983 ) was used to compute the entries of the term document matrix for the collection and entries of the query vector. The second step can be regarded as lter container. In this paper , the three kinds of routine schemes were performed. In the rst case , the local space for each query was represented simply by all document vectors , which have already been judged to be relevant ( appearing in the relevant judgment le ) . We note that although it is an ideal case , it may form a useful upper bound on performance. In the second case , we assume the condition that the user provides a reasonable number of relevant documents. In the third case , the local space for each query was built on the top return sets of VSM. The use of the top returned items from VSM is similar to blind feedback or pseudo RF. There are three test collections in our experiments. Two of them , Cran eld and Medlars , are small. The third one is a large-scale test collection , NACSIS. The Cran eld corpus consists of 1,400 documents on aerodynamics and 225 queries , while Medlars consists of 1,033 medical abstracts and 30 queries. Although these two collections are very small , they were used extensively in the past by IR researchers. As for the NACSIS test collection for the IR 1 &amp; 2 ( NTCIR 1 &amp; NTCIR 2 ) ( Kando , 2001 ) , these documents are abstracts of academic papers presented at meetings hosted by 65 Japanese scientists and linguists. In our experiments , the English Monolingual IR was performed. This collection consists of approximately 320,000 English documents in NTCIR1 and NTCIR-2. We rst present the experimental results on the ideal condition. The document vectors already judged to be relevant to the query were used. SVD calculation are performed on the local region organized by Table 1 : Results on the Cran. , Med. and NTCIR are shown in terms of ave. precision , precision at document cutoff of 10. Results of the local LSI experiment based on three different SVD dimensions were provided. Cran eld Medlars NTCIR ( E-E ) ( D run ) K Avr. P-R R-p K Avr. P-R R-p K Avr. P-R R-p VSM 0.4148 0.3885 0.5306 0.5359 0.212 0.2277 +0 % +0 % +0 % +0 % +0 % +0 % G. 200 0.4543 0.4180 80 0.6680 0.6648 LSI +9 % +0 % +8 % +0 % +26 % +0 % +25 % +0 % 1 0.8833 0.8243 1 0.8946 0.8139 1 0.6997 0.6508 +113 % +95 % +112 % +97 % +69 % +34 % +52 % +22 % +230 % +186 % L. 2 0.8607 0.8185 2 0.8769 0.8035 2 0.7062 0.6314 LSI +108 % +90 % +108 % +96 % +67 % +32 % +52 % +20 % +233 % +177 % 3 0.8585 0.8102 3 0.8726 0.8019 3 0.6934 0.6293 +107 % +90 % +108 % +96 % +68 % +30 % +51 % +20 % +228 % +176 % these relevant documents with respect to its query. The IR performance of VSM and global LSI were regarded as the baseline for comparison. As for the NTCIR collection , English-English Monolingual IR was performed and we only extracted the D ( Description ) eld of the topic as the query. Due to its large size , only the result of VSM is the baseline. Additionally , to observe the in uences of SVD factors on the IR performance for local LSI experiments , results based on LSI dimension from 1 to 3 were also provided for comparison. As we expected , the majority of experimental studies are directed towards obtaining better solutions for the local routine LSI method. In table 1 , K represents the SVD dimension for LSI analysis. As for the k value of global LSI , it is the parameter by which LSI yields the best IR performance. The improvement in the average precision of local routine LSI is 113 , 69 and 233 percent better than that of VSM on Cran eld , Medlars and NTCIR test collections respectively. The improvement in average precision of local routine LSI is 95 and 34 percent better than that of global LSI on Cran eld with 200 SVD dimensions and Medlars with 80 SVD dimensions respectively. Moreover , in the case of SVD factors equal to 1 , we obtain the best IR performance among all cases on the Cran eld and Medlars. While the NTCIR collection obtained its best IR performance with 2 SVD dimensions , there is only a slight difference between the case with 1 singular vector and the case with 2. Such small numbers caught our attention , since they indicate that there is a nearly linear surface in the local region and that the dominant SVD dimensions can capture such surface and yield a good IR performance for local LSI analysis. To clarify how the local LSI space in uences IR performance , we projected the document vectors onto the extracted local routine LSI space and gured out the distribution in gure 2. The data of plots are based on one query from the Medlars collection. Only the largest singular vector was used for the left plot , and the two largest were used for the right. Based on the plots , we nd that these dimensions do not vary signi cantly for the non-relevant documents , Thus , they tend to cluster around the origin. On the other hand , the relevant document space illustrates that local SVD factors are designed to capture their structure. Since the pre-judged set of documents is generally not available for the ad-hoc query , In this paper , to investigate the ef ciency of local LSI using very low dimensions , we continue to do some experiments using different numbers of relevant documents , which were selected from the relevant judgment le. The comparative results based on four cases in which the SVD factors equal 1 , 2 and 3 , respectively , were shown in Table 2. The second column is the condition , which means that the number of relevant documents belonging to the analyzing object ( query ) should exceed the value in table. Column 3 # qry 0 200 400 600 800 1000 1200 Doc. ID i n n e r p r o d u c t v a l u e the distribution of inner product of document vector with the largest singular vector non-relevant document query relevant document -0.6 -0.4 -0.2 s e c o n d f a c t o r largest factor non-relevant document query relevant document Figure 2 : Medlars : document collection distribution after represented by the Local region singular vectors. For the left gure the X-axis is doc.ID and Y are the inner products of the doc vector with the largest singular vectors. X and Y coordinates on the right are the inner product of the document vectors with the rst and second largest singular vector , respectively. Medlars A v e . p r e c i s i o n r e c a l l local LSI ( s=20 , k=1 ) global LSI ( k=80 ) VSM Cranfield A v e . p r e c i s i o n r e c a l l local LSI ( s=3 , k=2 ) global LSI ( k=200 ) VSM NTCIR A v e . p r e c i s i o n r e c a l l Local LSI ( s=3 , k=2 ) VSM Figure 3 : the Ave. precision-recall comparison plots between the best run of local LSI with the baseline VSM and global LSI. indicates the numbers of queries in the test collection which satisfy the condition appearing in the second column. The fourth column gives the parameter indicating the number of relevant documents to be used for creating the local space of the correspondent query. As we expected , local LSI using one or two SVD dimensions built from the rst two singular vectors resulted in the best IR performance in the partially ideal experiments. The comparison of the results was shown in the Table 2. We know that the most important step in LSI is the phase of SVD. It requires O ( k £ nz2 ) to nd the k leading eigenvectors. The parameter nz is the non-zero entries of the term-by-document matrix. These requirements are unacceptably high for document data sets as the non-zero entries number tens of thousands. According to the LSI analyzing procedure , it includes the SVD phase and the subsequent projecting treatment. For global LSI , the computation complexity can be evaluated by : O ( nz2k + # qry £ k2 £ nz2 £ qnz2 ) k = ( 100 » 300 ) While our approach can be estimated by : O ( # qry£ [ ( nz2lockloc ) + ( k2loc £nz2 £qnz2 ) ] ) k = 1 or 2 In the above equation , nzloc represents the nonzero entries of the local query region. qnz are non-zero entities in the query vector. The value of nzloc varies with the number of known relevant documents. Note that the difference between these two equations shows clearly that local LSI on small SVD dimensions is much easier to compute than global LSI. According to our observation , it is particularly fast when computing only the largest singular value. Based on the above experiments , the interesting results and the power of the two largest singular vectors prompted us to try putting the local LSI with one or two singular dimensions into the practical experiments. In this paper , we used the simplest and most ef cient VSM method as the initial retrieval step for extracting the relevant information around the query. We assume that the top-ranked documents obtained by VSM are relevant documents. The details are introduced in section 3.4. In this experiment , we note that using the top returned items from VSM is sometimes called blind feedback or pseudo RF. Hence , we borrow the idea of local RF. The expanded query representation was obtained by combining the original query vector with its projecting result on the local SVD dimensions. The equation for expanding the scheme is as follows : ~qnew = ~qori +Alock ( Alock ) T~qori In the equation : Alock = Ulock §lock ( V lock ) T Sim ( ~d ; ~qnew ) = ~d† ( ~qori +Ulock ( §lock ) 2 ( Ulock ) T~qori ) As for the parameter k , representing the SVD dimensionality of the local region , we set its value equal to 1 or 2 in this experiment. At rst , to show that local LSI on small dimensions works well is a practical case clearly , we gave the comparable plots between local LSI with the baseline VSM and global LSI. The 11ppt. average precision recall plots of local LSI were gured out for the three test collections in gure 3. The symbol s in the gure represents the sample size and k represents the SVD dimension. To our satisfactions , local LSI based query expansion method does much better than VSM and more closely approaches the global LSI. Next , to investigate the effectiveness of low dimensional LSI on local query region in restructuring the user cared information space , local RF with Rocchio’s weights fi : fl : = 1 : 1 : 0 , as in Xu and Croft ( Xu and Croft , 2000 ) , was used for comparison. Both of them were used on the same sample documents. The difference between them is a twofold one. First , the standard RF formula shown in section 2.2 make use of weighting parameters for query expansion , while our approach does not. Secondly , different combination object was used. The local RF experiment performed in this paper makes use of the centroid of the top s returned document vectors. In our approach , we combine the original query vector with its projecting results on the low local SVD space. Table 3 shows these results in terms of varying feedback size with one or two SVD dimensions. The rst column sample size in the table is the value of s according to which we would select the top rank documents . We see that local LSI outperforms local RF for most combinations of sample size and one or two SVD dimensions in the experiment on Medlars. The best run on Medlars using local LSI is 8.4 % better than the best in local RF. As for the best run on Cran eld and on NTCIR , local LSI got comparable results with the local RF. In the experiments , we note that with the increasing of sample size , the precision of local LSI decreased more than that of local RF. Based on our analysis , there are two reasons for this. First , In the VSM based local LSI experiments , we assume that the top s documents from the initial retrieval by VSM are relevant , although that assumption does not always hold. In the case where the dominant components of the top s return sets are non-relevant , the maintained SVD dimensions would deviate from the orientation that we preferred. This will in uence the following projection procedure greatly. The average precision-recall results of VSM on Cran eld and NTCIR is 0.38 and factor is the characteristic of the test collection. The number of relevant documents for query sets ranges from 2 to 40 and from 3 to 170 for the Cran eld and NTCIR , respectively. With such wide range of query sets , some queries don’t have enough relevant documents for this strategy to be feasible. Therefore , from the experiment results , it is still reasonable for us to believe that if several relevant sample documents of a query are available , low-dimensional local LSI will be able to achieve comparable performance to local RF. One important variable for LSI retrieval is the number of dimensions in the reduced space. In this paper , we found that one or two SVD dimensions are able to represent the structure of the local region that corresponds to the user’s interests. The rst two largest singular vectors will represent the two major Table 2 : Ave. precision-recall comparing results based on different SVD factors. Coll. Cond. # qry # sel. SVD Ave. Rel. fact. P-R 1 0.6857 10 2 0.6667 Cran. &gt; 15 27 3 0.6654 ( # rel ) 1 0.5749 5 2 0.5692 3 0.5641 1 0.7945 10 2 0.8007 Med. &gt;</sentence>
				<definiendum id="0">NACSIS. The Cran eld corpus</definiendum>
				<definiendum id="1">NTCIR</definiendum>
				<definiendum id="2">factor</definiendum>
				<definiens id="0">Implementation architecture Figure 1 shows overall the architecture of the experiment. The procedure is described as follows : sets the relevant sets. In some cases the relevant sets are derived from the known relevant documents and in other cases we regarded the top returned documents as the relevant sets. on documents identi ed in 2. vector into the user-cared feature space , and then using the standard Cosine measure to get the nal score for this query. the next query in the same way. Step 1 is pre-processing procedure for IR system. Only the tag removal , upper case characters transverse , stoplist removal and Porter’s stemming were adopted in this phase ( Frakes and Baeza-Yates , 1992 ) . Next , the smart ltc term weighting scheme ( Salton and McGill , 1983 ) was used to compute the entries of the term document matrix for the collection and entries of the query vector. The second step can be regarded as lter container. In this paper , the three kinds of routine schemes were performed. In the rst case , the local space for each query was represented simply by all document vectors , which have already been judged to be relevant ( appearing in the relevant judgment le ) . We note that although it is an ideal case , it may form a useful upper bound on performance. In the second case , we assume the condition that the user provides a reasonable number of relevant documents. In the third case , the local space for each query was built on the top return sets of VSM. The use of the top returned items from VSM is similar to blind feedback or pseudo RF. There are three test collections in our experiments. Two of them , Cran eld and Medlars , are small. The third one is a large-scale test collection ,</definiens>
				<definiens id="1">consists of 1,400 documents on aerodynamics and 225 queries , while Medlars consists of 1,033 medical abstracts and 30 queries. Although these two collections are very small , they were used extensively in the past by IR researchers. As for the NACSIS test collection for the IR 1 &amp; 2 ( NTCIR 1 &amp; NTCIR 2 ) ( Kando , 2001 ) , these documents are abstracts of academic papers presented at meetings hosted by 65 Japanese scientists and linguists. In our experiments , the English Monolingual IR was performed. This collection consists of approximately 320,000 English documents in NTCIR1 and NTCIR-2. We rst present the experimental results on the ideal condition. The document vectors already judged to be relevant to the query were used. SVD calculation are performed on the local region organized by Table 1 : Results on the Cran. , Med. and NTCIR are shown in terms of ave. precision , precision at document cutoff of 10. Results of the local LSI experiment based on three different SVD dimensions were provided. Cran eld Medlars NTCIR ( E-E ) ( D run ) K Avr. P-R R-p K Avr. P-R R-p K Avr. P-R R-p VSM 0.4148 0.3885 0.5306 0.5359 0.212 0.2277 +0 % +0 % +0 % +0 % +0 % +0 % G. 200 0.4543 0.4180 80 0.6680 0.6648 LSI +9 % +0 % +8 % +0 % +26 % +0 % +25 % +0 % 1 0.8833 0.8243 1 0.8946 0.8139 1 0.6997 0.6508 +113 % +95 % +112 % +97 % +69 % +34 % +52 % +22 % +230 % +186 % L. 2 0.8607 0.8185 2 0.8769 0.8035 2 0.7062 0.6314 LSI +108 % +90 % +108 % +96 % +67 % +32 % +52 % +20 % +233 % +177 % 3 0.8585 0.8102 3 0.8726 0.8019 3 0.6934 0.6293 +107 % +90 % +108 % +96 % +68 % +30 % +51 % +20 % +228 % +176 % these relevant documents with respect to its query. The IR performance of VSM and global LSI were regarded as the baseline for comparison. As for the NTCIR collection , English-English Monolingual IR was performed and we only extracted the D ( Description ) eld of the topic as the query. Due to its large size , only the result of VSM is the baseline. Additionally , to observe the in uences of SVD factors on the IR performance for local LSI experiments , results based on LSI dimension from 1 to 3 were also provided for comparison. As we expected , the majority of experimental studies are directed towards obtaining better solutions for the local routine LSI method. In table 1 , K represents the SVD dimension for LSI analysis. As for the k value of global LSI , it is the parameter by which LSI yields the best IR performance. The improvement in the average precision of local routine LSI is 113 , 69 and 233 percent better than that of VSM on Cran eld , Medlars and NTCIR test collections respectively. The improvement in average precision of local routine LSI is 95 and 34 percent better than that of global LSI on Cran eld with 200 SVD dimensions and Medlars with 80 SVD dimensions respectively. Moreover , in the case of SVD factors equal to 1 , we obtain the best IR performance among all cases on the Cran eld and Medlars. While the NTCIR collection obtained its best IR performance with 2 SVD dimensions , there is only a slight difference between the case with 1 singular vector and the case with 2. Such small numbers caught our attention , since they indicate that there is a nearly linear surface in the local region and that the dominant SVD dimensions can capture such surface and yield a good IR performance for local LSI analysis. To clarify how the local LSI space in uences IR performance , we projected the document vectors onto the extracted local routine LSI space and gured out the distribution in gure 2. The data of plots are based on one query from the Medlars collection. Only the largest singular vector was used for the left plot , and the two largest were used for the right. Based on the plots , we nd that these dimensions do not vary signi cantly for the non-relevant documents , Thus , they tend to cluster around the origin. On the other hand , the relevant document space illustrates that local SVD factors are designed to capture their structure. Since the pre-judged set of documents is generally not available for the ad-hoc query , In this paper , to investigate the ef ciency of local LSI using very low dimensions , we continue to do some experiments using different numbers of relevant documents , which were selected from the relevant judgment le. The comparative results based on four cases in which the SVD factors equal 1 , 2 and 3 , respectively , were shown in Table 2. The second column is the condition , which means that the number of relevant documents belonging to the analyzing object ( query ) should exceed the value in table. Column 3 # qry 0 200 400 600 800 1000 1200 Doc. ID i n n e r p r o d u c t v a l u e the distribution of inner product of document vector with the largest singular vector non-relevant document query relevant document -0.6 -0.4 -0.2 s e c o n d f a c t o r largest factor non-relevant document query relevant document Figure 2 : Medlars : document collection distribution after represented by the Local region singular vectors. For the left gure the X-axis is doc.ID and Y are the inner products of the doc vector with the largest singular vectors. X and Y coordinates on the right are the inner product of the document vectors with the rst and second largest singular vector , respectively. Medlars A v e . p r e c i s i o n r e c a l l local LSI ( s=20 , k=1 ) global LSI ( k=80 ) VSM Cranfield A v e . p r e c i s i o n r e c a l l local LSI ( s=3 , k=2 ) global LSI ( k=200 ) VSM NTCIR A v e . p r e c i s i o n r e c a l l Local LSI ( s=3 , k=2 ) VSM Figure 3 : the Ave. precision-recall comparison plots between the best run of local LSI with the baseline VSM and global LSI. indicates the numbers of queries in the test collection which satisfy the condition appearing in the second column. The fourth column gives the parameter indicating the number of relevant documents to be used for creating the local space of the correspondent query. As we expected , local LSI using one or two SVD dimensions built from the rst two singular vectors resulted in the best IR performance in the partially ideal experiments. The comparison of the results was shown in the Table 2. We know that the most important step in LSI is the phase of SVD. It requires O ( k £ nz2 ) to nd the k leading eigenvectors. The parameter nz is the non-zero entries of the term-by-document matrix. These requirements are unacceptably high for document data sets as the non-zero entries number tens of thousands. According to the LSI analyzing procedure , it includes the SVD phase and the subsequent projecting treatment. For global LSI , the computation complexity can be evaluated by : O ( nz2k + # qry £ k2 £ nz2 £ qnz2 ) k = ( 100 » 300 ) While our approach can be estimated by : O ( # qry£ [ ( nz2lockloc ) + ( k2loc £nz2 £qnz2 ) ] ) k = 1 or 2 In the above equation , nzloc represents the nonzero entries of the local query region. qnz are non-zero entities in the query vector. The value of nzloc varies with the number of known relevant documents. Note that the difference between these two equations shows clearly that local LSI on small SVD dimensions is much easier to compute than global LSI. According to our observation , it is particularly fast when computing only the largest singular value. Based on the above experiments , the interesting results and the power of the two largest singular vectors prompted us to try putting the local LSI with one or two singular dimensions into the practical experiments. In this paper , we used the simplest and most ef cient VSM method as the initial retrieval step for extracting the relevant information around the query. We assume that the top-ranked documents obtained by VSM are relevant documents. The details are introduced in section 3.4. In this experiment , we note that using the top returned items from VSM is sometimes called blind feedback or pseudo RF. Hence , we borrow the idea of local RF. The expanded query representation was obtained by combining the original query vector with its projecting result on the local SVD dimensions. The equation for expanding the scheme is as follows : ~qnew = ~qori +Alock ( Alock ) T~qori In the equation : Alock = Ulock §lock ( V lock ) T Sim ( ~d ; ~qnew ) = ~d† ( ~qori +Ulock ( §lock ) 2 ( Ulock ) T~qori ) As for the parameter k , representing the SVD dimensionality of the local region , we set its value equal to 1 or 2 in this experiment. At rst , to show that local LSI on small dimensions works well is a practical case clearly , we gave the comparable plots between local LSI with the baseline VSM and global LSI. The 11ppt. average precision recall plots of local LSI were gured out for the three test collections in gure 3. The symbol s in the gure represents the sample size and k represents the SVD dimension. To our satisfactions , local LSI based query expansion method does much better than VSM and more closely approaches the global LSI. Next , to investigate the effectiveness of low dimensional LSI on local query region in restructuring the user cared information space , local RF with Rocchio’s weights fi : fl : = 1 : 1 : 0 , as in Xu and Croft ( Xu and Croft , 2000 ) , was used for comparison. Both of them were used on the same sample documents. The difference between them is a twofold one. First , the standard RF formula shown in section 2.2 make use of weighting parameters for query expansion , while our approach does not. Secondly , different combination object was used. The local RF experiment performed in this paper makes use of the centroid of the top s returned document vectors. In our approach , we combine the original query vector with its projecting results on the low local SVD space. Table 3 shows these results in terms of varying feedback size with one or two SVD dimensions. The rst column sample size in the table is the value of s according to which we would select the top rank documents . We see that local LSI outperforms local RF for most combinations of sample size and one or two SVD dimensions in the experiment on Medlars. The best run on Medlars using local LSI is 8.4 % better than the best in local RF. As for the best run on Cran eld and on NTCIR , local LSI got comparable results with the local RF. In the experiments , we note that with the increasing of sample size , the precision of local LSI decreased more than that of local RF. Based on our analysis , there are two reasons for this. First , In the VSM based local LSI experiments , we assume that the top s documents from the initial retrieval by VSM are relevant , although that assumption does not always hold. In the case where the dominant components of the top s return sets are non-relevant , the maintained SVD dimensions would deviate from the orientation that we preferred. This will in uence the following projection procedure greatly. The average precision-recall results of VSM on Cran eld and</definiens>
			</definition>
</paper>

		<paper id="1800">
</paper>

		<paper id="0403">
			<definition id="0">
				<sentence>Following Hwa , we use the following evaluation function to quantify uncertainty based on tree entropy : a27a1a0a3a2a28a5 a42 a17 a33 a1 a34 a4 a48 a0a6a5a8a7 a47 a5a40a30 a41 a42 a1 a9 a54a11a10 a3 a5 a47 a5a40a30 a41 a42 a1a32a1 a12a14a13a16a15a18a17a20a19a22a21 a5 a42 a1 where a33 denotes the set of analyses produced by the ERG 2When only an absolute ranking of analyses is required , it is unnecessary to exponentiate and compute a23a25a24a3a26a16a27 .</sentence>
				<definiendum id="0">a33</definiendum>
				<definiens id="0">the set of analyses produced by the ERG 2When only an absolute ranking of analyses is required , it is unnecessary to exponentiate and compute a23a25a24a3a26a16a27</definiens>
			</definition>
			<definition id="1">
				<sentence>LL-CONFIG is thus a sort of passenger of the weaker bigram model , which drives the selection process .</sentence>
				<definiendum id="0">LL-CONFIG</definiendum>
				<definiens id="0">drives the selection process</definiens>
			</definition>
			<definition id="2">
				<sentence>50 55 60 65 70 75 0 500 1000 1500 2000 2500 3000 Accuracy Number of annotated sentences used random tree entropy entropy-passenger Figure 6 : Accuracy as more examples are selected based tree entropy according to LL-CONFIG itself and when LLCONFIG is the passenger of an impoverished model .</sentence>
				<definiendum id="0">LLCONFIG</definiendum>
				<definiens id="0">Accuracy Number of annotated sentences used random tree entropy entropy-passenger Figure 6 : Accuracy as more examples are selected based tree entropy according to LL-CONFIG itself and when</definiens>
				<definiens id="1">the passenger of an impoverished model</definiens>
			</definition>
</paper>

		<paper id="1724">
			<definition id="0">
				<sentence>Given a Chinese sentence s = c1c2 cm ( also denoted as cn1 ) , its probabilistic segmentation into a word sequence w1w2 wk ( also denoted as wk1 ) with the aid of an ngram model can be formulated as seg ( s ) = arg max s= w1 w2 wk kY i p ( wijwi 1i n+1 ) ( 1 ) where denotes string concatenation , wi 1i n+1 the context ( or history ) of wi , and n is the order of the ngram model in use .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">its probabilistic segmentation into a word sequence w1w2 wk ( also denoted as wk1 ) with the aid of an ngram model can be formulated as seg ( s ) = arg max s= w1 w2 wk kY i p ( wijwi 1i n+1 ) ( 1 ) where denotes string concatenation , wi 1i n+1 the context ( or history ) of wi , and</definiens>
			</definition>
			<definition id="1">
				<sentence>Each EM iteration aims at approaching to a more reliable f ( w ) for estimating p ( w ) , as follows : fk+1 ( w ) = X s2C X s02S ( s ) pk ( s0 ) fk ( w 2 s0 ) ( 3 ) where k denotes the current iteration , S ( s ) the set of all possible segmentations for s , and f k ( w 2s0 ) the occurrences of w in a particular segmentation s0 .</sentence>
				<definiendum id="0">k</definiendum>
			</definition>
			<definition id="2">
				<sentence>The Viterbi segmentation , by utilizing dynamic programming techniques to go through the word trellis of a sentence ef ciently , nds the most probable segmentation under the current parameter estimation of the language model , ful lling ( 1 ) ) .</sentence>
				<definiendum id="0">Viterbi segmentation</definiendum>
			</definition>
			<definition id="3">
				<sentence>w1 w2 wk where is the ambiguous string , Cl and Cr its left and right contexts , respectively , and w1 w2 wk the correct segmentation of given the contexts .</sentence>
				<definiendum id="0">Cr</definiendum>
				<definiens id="0">its left and right contexts , respectively , and w1 w2 wk the correct segmentation of given the contexts</definiens>
			</definition>
</paper>

		<paper id="1605">
			<definition id="0">
				<sentence>FAQFinder is a web-based , natural language question-answering system which uses Usenet Frequently Asked Questions ( FAQ ) files to answer users’ questions .</sentence>
				<definiendum id="0">FAQFinder</definiendum>
			</definition>
			<definition id="1">
				<sentence>( : actor I ) ( : verb obtain ) ( : theme &lt; NPO &gt; ) ) Figure 2 : Example Paraphrase Patterns ( for ATRANS in Conceptual Dependency ( Schank , 1973 ) ) is essentially a special case of PRC , where the ( desire for the ) transfer of possession is strongly implied .</sentence>
				<definiendum id="0">actor I )</definiendum>
				<definiens id="0">essentially a special case of PRC , where the ( desire for the ) transfer of possession is strongly implied</definiens>
			</definition>
			<definition id="2">
				<sentence>Each pattern is expressed in the form of a rule , where the left-hand side ( LHS ) expresses the phrase structure of a question , and the right-hand side ( RHS ) expresses the semantic case frame representation of the question .</sentence>
				<definiendum id="0">right-hand side</definiendum>
				<definiendum id="1">RHS</definiendum>
				<definiens id="0">the left-hand side ( LHS ) expresses the phrase structure of a question</definiens>
				<definiens id="1">expresses the semantic case frame representation of the question</definiens>
			</definition>
			<definition id="3">
				<sentence>Word classes are groupings of words appeared in the training data which have similar meanings ( i.e. , synonyms ) , and they were developed in tandem with the paraphrase patterns .</sentence>
				<definiendum id="0">Word classes</definiendum>
				<definiens id="0">groupings of words appeared in the training data which have similar meanings ( i.e. , synonyms ) , and they were developed in tandem with the paraphrase patterns</definiens>
			</definition>
			<definition id="4">
				<sentence>A constant indicates a word and requires the word to exist in the tuple .</sentence>
				<definiendum id="0">constant</definiendum>
				<definiens id="0">indicates a word and requires the word to exist in the tuple</definiens>
			</definition>
			<definition id="5">
				<sentence>Also notice the semantic case roles are taken from various syntactic phrases : pattern ( 2 ) takes the actor and theme from syntactic subject and object straight-forwardly , while pattern ( 3 ) , which matches a question such as “What is a good way to buy tickets for the Indy 500” , takes the theme from the object in the infinitival phrase ( : NP ) and fills the actor with “I” which is implicit in the question .</sentence>
				<definiendum id="0">phrase</definiendum>
				<definiens id="0">the semantic case roles are taken from various syntactic phrases : pattern ( 2 ) takes the actor and theme from syntactic subject and object straight-forwardly</definiens>
				<definiens id="1">a good way to buy tickets for the Indy 500” , takes the theme from the object in the infinitival</definiens>
			</definition>
			<definition id="6">
				<sentence>Then we inspected each entry and discarded ill-formed ones ( such as keywords or boolean queries ) and incorrect paraphrases .</sentence>
				<definiendum id="0">ill-formed ones</definiendum>
				<definiens id="0">such as keywords or boolean queries</definiens>
			</definition>
			<definition id="7">
				<sentence>The frame similarity between a pair of frames is defined as a weighted sum of two similarity scores : one for the interrogative part ( which we call interrogative similarity ) and another for the sentence part ( which we call case role similarity ) .</sentence>
				<definiendum id="0">frame similarity between a pair of frames</definiendum>
				<definiendum id="1">sentence part</definiendum>
				<definiens id="0">a weighted sum of two similarity scores : one for the interrogative part ( which we call interrogative similarity</definiens>
			</definition>
			<definition id="8">
				<sentence>Recall is defined in the usual way , as the ratio of true positives ( = # classified as paraphrase # true paraphrases ) , and rejection is defined as the ratio of true negatives ( = # classified as non-paraphrase # true non-paraphrases ) .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiendum id="1">rejection</definiendum>
				<definiens id="0">the usual way , as the ratio of true positives ( = # classified as paraphrase # true paraphrases ) , and</definiens>
				<definiens id="1">the ratio of true negatives ( = # classified as non-paraphrase # true non-paraphrases )</definiens>
			</definition>
			<definition id="9">
				<sentence>Our paraphrase patterns remove those variations and produce canonical forms which reflect the meaning of the questions ( i.e. , case frames ) .</sentence>
				<definiendum id="0">paraphrase patterns</definiendum>
				<definiens id="0">remove those variations and produce canonical forms which reflect the meaning of the questions ( i.e. , case frames )</definiens>
			</definition>
</paper>

		<paper id="2007">
			<definition id="0">
				<sentence>The NTCIR3 patent data collection consists of 697,262 patents opened to public in 1998 and in 1999 .</sentence>
				<definiendum id="0">NTCIR3 patent data collection</definiendum>
				<definiens id="0">consists of 697,262 patents opened to public in 1998 and in 1999</definiens>
			</definition>
			<definition id="1">
				<sentence>The recall ( R ) , the precision ( P ) , and the F-measure ( F ) are calculated by the followings , where c is the number of correctly-inserted newlines , n is the number of newlines in the original claim , and i is the number of inserted newlines .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">the number of correctly-inserted newlines , n is the number of newlines in the original claim</definiens>
			</definition>
</paper>

		<paper id="0506">
			<definition id="0">
				<sentence>Text summarization is the process of distilling the most important information from a source ( or sources ) to produce an abridged version for a particular user ( or users ) and task ( or tasks ) ( Mani and Maybury , 1999 ) .</sentence>
				<definiendum id="0">Text summarization</definiendum>
				<definiens id="0">the process of distilling the most important information from a source ( or sources ) to produce an abridged version for a particular user ( or users</definiens>
			</definition>
			<definition id="1">
				<sentence>Annotation is defined as a body of words marked among the text .</sentence>
				<definiendum id="0">Annotation</definiendum>
			</definition>
			<definition id="2">
				<sentence>Sentences are weighted according to the keywords it contains : ∑∑ ∈∈ = Sw i Sw is ii f S orfW 2 1 |S| is the length of a sentence , which means the keyword count it contains .</sentence>
				<definiendum id="0">|S|</definiendum>
				<definiens id="0">the length of a sentence , which means the keyword count it contains</definiens>
			</definition>
			<definition id="3">
				<sentence>1 For ease of representation in table 1 , “Pi” is for different users ; “DN” is document number ; “ASN” is average sentences number ; “ASL” is average summary length ; “ANN” is average annotation number .</sentence>
				<definiendum id="0">“Pi”</definiendum>
				<definiendum id="1">“DN”</definiendum>
				<definiendum id="2">; “ASL”</definiendum>
				<definiens id="0">document number ; “ASN” is average sentences number</definiens>
			</definition>
			<definition id="4">
				<sentence>2 For two compared summaries , “SS” means summary similarity ; “SP” means sentences precision for conditional match ; “PP” means sentences precision for perfect match ; “KP” means keywords precision ; and “KR” means keywords recall .</sentence>
				<definiendum id="0">“SS”</definiendum>
				<definiendum id="1">“KP”</definiendum>
				<definiendum id="2">“KR”</definiendum>
				<definiens id="0">means summary similarity ; “SP” means sentences precision for conditional match ; “PP” means sentences precision for perfect match ;</definiens>
			</definition>
			<definition id="5">
				<sentence>The first experiment is to find the best summary by selecting the first k ( k≤n , n is total number of annotations ) annotations , that is “first Best Annotated summary” .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">total number of annotations ) annotations</definiens>
			</definition>
			<definition id="6">
				<sentence>html” , which indicates how the number of annotations affects summarization performance .</sentence>
				<definiendum id="0">html”</definiendum>
				<definiens id="0">indicates how the number of annotations affects summarization performance</definiens>
			</definition>
</paper>

		<paper id="0427">
			<definition id="0">
				<sentence>Additionally we computed the following features with each wordform , largely following those used by the bestperforming submission of the 2002 shared task ( Carreras et al. , 2002 ) : • Orthographic features represented as binary features : Begin cap , All caps , Internal cap , Contains digit , Contains digit en alpha , Initial , Lower case , First word • The wordform’s first letter and last three letters ( as three separate features ) • The direct output of the memory-based lemmatizer ( Van den Bosch and Daelemans , 1999 ) , providing PoS tag , morphological features , and spelling change information • PoS tag from a slow but accurate version of the memory-based tagger trained on a portion of the British National Corpus , according to the CLAWS-5 tagset ( for English data only ) For example , for the English word Indian the following feature representation is made : Indian NNP I-NP 1 0 0 0 0 0 0 0 I i a n AJ0-NN1 N-s I-MISC , where NNP is the provided PoS tag , I-NP the chunk tag ; the binary features represent the orthographic features ( where in this case only Begin cap is positive ) ; AJO-NN1 is the PoS tag of the BNC-trained-tagger ; N-s is the lemmatizer output for noun-singular ; the last element , I-MISC , is the annotated class label .</sentence>
				<definiendum id="0">memory-based lemmatizer</definiendum>
				<definiendum id="1">NNP</definiendum>
				<definiendum id="2">N-s</definiendum>
				<definiens id="0">morphological features , and spelling change information • PoS tag from a slow but accurate version of the memory-based tagger trained on a portion of the British National Corpus , according to the CLAWS-5 tagset</definiens>
				<definiens id="1">the provided PoS tag , I-NP the chunk tag</definiens>
				<definiens id="2">the annotated class label</definiens>
			</definition>
			<definition id="1">
				<sentence>Memory-based learning is a supervised inductive learning algorithm for learning classification tasks .</sentence>
				<definiendum id="0">Memory-based learning</definiendum>
				<definiens id="0">a supervised inductive learning algorithm for learning classification tasks</definiens>
			</definition>
			<definition id="2">
				<sentence>Iterative deepening ( ID ) is a heuristic search algorithm for the optimization of algorithmic parameter and feature selection , that combines classifier wrapping ( using the training material internally to test experimental variants ) ( Kohavi and John , 1997 ) with progressive sampling of training material ( Provost et al. , 1999 ) .</sentence>
				<definiendum id="0">Iterative deepening</definiendum>
			</definition>
</paper>

		<paper id="0707">
			<definition id="0">
				<sentence>SpeechBuilder employs a Web-based interface where developers type in the specifics of their domain , guided by forms and pull-down menus .</sentence>
				<definiendum id="0">SpeechBuilder</definiendum>
				<definiens id="0">employs a Web-based interface where developers type in the specifics of their domain , guided by forms and pull-down menus</definiens>
			</definition>
</paper>

		<paper id="1728">
			<definition id="0">
				<sentence>We represent the positions of a hanzi with four different tags ( Table 1 ) : LM for a hanzi that occurs on the left periphery of a word , followed by other hanzi , MM for a hanzi that occurs in the middle of a word , MR for a hanzi that occurs on the right periphery of word , preceded by other hanzi , and LR for hanzi that is a word by itself .</sentence>
				<definiendum id="0">MR</definiendum>
				<definiens id="0">the positions of a hanzi with four different tags ( Table 1 ) : LM for a hanzi that occurs on the left periphery of a word , followed by other hanzi</definiens>
				<definiens id="1">a hanzi that occurs in the middle of a word</definiens>
				<definiens id="2">a hanzi that occurs on the right periphery of word</definiens>
				<definiens id="3">a word by itself</definiens>
			</definition>
			<definition id="1">
				<sentence>The probability model is defined over a12a14a13a16a15 , where a12 is the set of possible contexts or ”histories” and a15 is the set of possible tags .</sentence>
				<definiendum id="0">a12</definiendum>
				<definiendum id="1">a15</definiendum>
				<definiens id="0">the set of possible tags</definiens>
			</definition>
			<definition id="2">
				<sentence>The model’s joint probability of a history a17 and a tag a18 is defined as a19a21a20 a17a23a22a24a18a24a25a27a26a29a28a31a30 a32 a33 a34a36a35a38a37a40a39 a41a43a42a5a44a46a45a47a49a48 a50 a34 ( 1 ) where a28 is a normalization constant , a51a52a30a53a22 a39 a37 a22 a3a49a3a49a3 a22 a39 a32a4a54 are the model parameters and a51a56a55 a37 a22 a3a49a3a49a3 a22a57a55 a32a40a54 are known as features , where a55 a34 a20 a17a58a22a24a18a59a25a61a60a62a51a64a63a9a22 a8 a54 .</sentence>
				<definiendum id="0">model’s joint probability</definiendum>
			</definition>
			<definition id="3">
				<sentence>( 1 ) Feature templates ( a ) Default feature ( b ) The current character ( a79a84a85 ) ( c ) The previous ( next ) two characters ( a79a81a80a83a86 , a79a81a80 a37 , a79 a37 , a79a84a86 ) ( d ) The previous ( next ) character and the current character ( a79 a80 a37 a79 a85 , a79 a85 a79 a37 ) , the previous two characters ( a79a81a80a83a86a64a79a81a80 a37 ) , and the next two characters ( a79 a37 a79a84a86 ) ( e ) The previous and the next character ( a79a81a80 a37 a79 a37 ) ( f ) The tag of the previous character ( a15 a80 a37 ) , and the tag of the character two before the current character ( a15 a80a83a86 ) One potential problem with the MEMM is that it can only scan the input in one direction , from left to right or from right to left .</sentence>
				<definiendum id="0">e</definiendum>
				<definiendum id="1">MEMM</definiendum>
				<definiens id="0">previous ( next ) character and the current character ( a79 a80 a37 a79 a85</definiens>
				<definiens id="1">The previous and the next character ( a79a81a80 a37 a79 a37 ) ( f ) The tag of the previous character ( a15 a80 a37 ) , and the tag of the character two before the current character ( a15 a80a83a86</definiens>
			</definition>
			<definition id="4">
				<sentence>X-axis stands for the number of iteration in training .</sentence>
				<definiendum id="0">X-axis</definiendum>
				<definiens id="0">the number of iteration in training</definiens>
			</definition>
</paper>

		<paper id="1811">
			<definition id="0">
				<sentence>In those studies , MWEs are defined as a “word with spaces” in English and “idiosyncratic interpretations that cross word boundaries” in Japanese .</sentence>
				<definiendum id="0">MWEs</definiendum>
				<definiens id="0">a “word with spaces” in English and “idiosyncratic interpretations that cross word boundaries” in Japanese</definiens>
			</definition>
			<definition id="1">
				<sentence>JCVs consist of two verbs , the first verb ( V1 ) and the second verb ( V2 ) .</sentence>
				<definiendum id="0">JCVs</definiendum>
				<definiens id="0">consist of two verbs , the first verb ( V1 ) and the second verb ( V2 )</definiens>
			</definition>
			<definition id="2">
				<sentence>V2 sugiru in the lexical compound in ( 2a ) means path of motion ( “go past” ) , but in the syntactic compound in ( 2b ) it denotes excessiveness ( “too much” ) .</sentence>
				<definiendum id="0">V2 sugiru</definiendum>
				<definiens id="0">in the lexical compound in ( 2a ) means path of motion ( “go past” ) , but in the syntactic compound in ( 2b ) it denotes excessiveness ( “too much” )</definiens>
			</definition>
			<definition id="3">
				<sentence>An ambiguous V2 is defined as a word with multiple meanings which overlap several semantic clusters .</sentence>
				<definiendum id="0">ambiguous V2</definiendum>
				<definiens id="0">a word with multiple meanings which overlap several semantic clusters</definiens>
			</definition>
			<definition id="4">
				<sentence>Directional motion consists of two main verbs .</sentence>
				<definiendum id="0">Directional motion</definiendum>
			</definition>
			<definition id="5">
				<sentence>Rules based on semantic information Rule 1 : IF V1 is-a cooking and V2 is ‘ageru’ THEN class is aspectual cluster Example : yude-ageru “boil-raise” = &gt; aspectual cluster Paraphrase : yuderu-koto-o oeru “finish boiling” Rule 2 : IF V1 is-a operation and V2 is ‘ageru’ THEN class is spatial cluster Example : uchi-ageru “hit-raise” = &gt; spatial cluster Paraphrase : utte-ageru “hit upwards” Rule 3 : IF V1 is-a emotion and V2 is ‘agaru’ THEN class is adverbial cluster Example : furue-agaru “tremble-go up” = &gt; adverbial cluster Paraphrase : hijouni furueru “tremble violently” Rule based on syntactic information Rule 4 : IF V1 is-a action and N1 ( V1 's subject ) is-a human and N2 ( V2 's dative ) is-a human and V2 is ‘kakeru’ THEN class is aspectual cluster Example : kare wa kanojo ni unazuki-kaketa “he TOP she Goal nod-hang” = &gt; aspectual cluster Paraphrase : kare wa kanojo ni mukatte unazuita “He nodded at her” We extracted 829 JCVs from the newspaper articles as target words for the analysis .</sentence>
				<definiendum id="0">V2</definiendum>
				<definiendum id="1">Paraphrase</definiendum>
				<definiendum id="2">V2</definiendum>
				<definiendum id="3">V2</definiendum>
				<definiens id="0">‘ageru’ THEN class is spatial cluster Example : uchi-ageru “hit-raise” = &gt; spatial cluster</definiens>
				<definiens id="1">utte-ageru “hit upwards” Rule 3 : IF V1 is-a emotion and</definiens>
				<definiens id="2">IF V1 is-a action and N1 ( V1 's subject ) is-a human</definiens>
			</definition>
			<definition id="6">
				<sentence>( 1 ) Input a sentence which includes JCVs ( 2 ) Tag each word in the input sentence using a morphological analysis system called Chasen ( 3 ) Extract the JCVs and their syntactic information from the sentence ( 4 ) Assign a semantic feature to V1 using co-occurring words , referring to IPAL dictionary ( 5 ) Compare the semantic feature of V1 and syntactic information with the disambiguation rules ( 6 ) Output the semantic cluster obtained by application of the matching rule Through this procedure , we can handle novel JCVs not in the dictionary .</sentence>
				<definiendum id="0">Extract</definiendum>
				<definiens id="0">the JCVs and their syntactic information from the sentence</definiens>
			</definition>
</paper>

		<paper id="1210">
			<definition id="0">
				<sentence>The algorithm consists of two major procedures .</sentence>
				<definiendum id="0">algorithm</definiendum>
				<definiens id="0">consists of two major procedures</definiens>
			</definition>
			<definition id="1">
				<sentence>The CAUSE-TO relation is a transitive relation between verb synsets .</sentence>
				<definiendum id="0">CAUSE-TO relation</definiendum>
				<definiens id="0">a transitive relation between verb synsets</definiens>
			</definition>
			<definition id="2">
				<sentence>Answer : “Robins sing in spring because increases in day length trigger hormonal action” .</sentence>
				<definiendum id="0">Answer</definiendum>
				<definiens id="0">“Robins sing in spring because increases in day length trigger hormonal action”</definiens>
			</definition>
			<definition id="3">
				<sentence>Answer : “Robins sing in spring because they have learned songs from their fathers and neighbors.”</sentence>
				<definiendum id="0">Answer</definiendum>
			</definition>
</paper>

		<paper id="1314">
			<definition id="0">
				<sentence>The Mayo Clinic is a group medical practice in the United States and spans all recognized medical care settings and specialties .</sentence>
				<definiendum id="0">Mayo Clinic</definiendum>
				<definiens id="0">a group medical practice in the United States and spans all recognized medical care settings and specialties</definiens>
			</definition>
			<definition id="1">
				<sentence>The 14th edition ( 2003AA ) of the UMLS Metathesaurus contains over 1.75 million unique English terms drawn from more than sixty families of medical vocabularies , and organized in some 875,000 concepts .</sentence>
				<definiendum id="0">UMLS Metathesaurus</definiendum>
			</definition>
			<definition id="2">
				<sentence>For example , the demodified phrase arthroscopic surgery ( derived from decompressive arthroscopic surgery ) is considered a procedure because it maps , as a synonym , to the concept Surgical Procedures , Arthroscopic , whose semantic group is Procedures .</sentence>
				<definiendum id="0">demodified phrase arthroscopic surgery</definiendum>
			</definition>
			<definition id="3">
				<sentence>In this second part , the condition 7 rank n simply corresponds to the nth highest frequency for a phrase to be considered a member of a subdomain was that the demodified phrase ( not the entire phrase ) map to a UMLS term .</sentence>
				<definiendum id="0">demodified phrase</definiendum>
			</definition>
</paper>

		<paper id="1709">
</paper>

		<paper id="1207">
			<definition id="0">
				<sentence>The Adverb Dictionary is created with adverbs from WordNet and TreeBank .</sentence>
				<definiendum id="0">Adverb Dictionary</definiendum>
				<definiens id="0">created with adverbs from WordNet and TreeBank</definiens>
			</definition>
			<definition id="1">
				<sentence>( 5 ) Component before the adverb The fifth feature concerns the POS of the word preceding the adverb .</sentence>
				<definiendum id="0">POS of</definiendum>
				<definiens id="0">the word preceding the adverb</definiens>
			</definition>
			<definition id="2">
				<sentence>This is defined as : a1a1a0a3a2a5a4a7a6a9a8a11a10a12a4 a3a13a10 where a10a14a4 is the total number of examples for which the target value is a2a15a4 and a10 is the total number of examples .</sentence>
				<definiendum id="0">a10a14a4</definiendum>
				<definiendum id="1">a10</definiendum>
				<definiens id="0">the total number of examples</definiens>
			</definition>
			<definition id="3">
				<sentence>a1a33a22a20a17a20a34a35a0a3a36a37a6a9a8a38a0a39a16a18a17a20a19 a21a23a22a25a24a27a26a9a36a41a40a32a6 a3a15a0a3a2a43a42a45a44a33a46a48a47a41a36a50a49a51a10a37a52a53a49a54a6 a1a33a22a20a17a20a34a35a0a56a55a51a6a9a8a38a0a57a28a29a24a58a30 a21a23a22a25a24a32a26a59a36a60a40a32a6 a3a15a0a3a2a61a42a45a44a33a46a48a47a60a36a62a49a51a10a37a52a53a49a54a6 where a16a23a17a35a19 a21a23a22a25a24a32a26 is the number of times the feature occurred in the Positive class , a28a29a24a58a30 a21a23a22a25a24a27a26 is the number of times the feature occurred in the Negative class , a2a43a42a63a44a33a46a48a47 is the distinct number of positive and negative instances for a given feature , and a49a51a10a63a52a62a49 is the total number of all positive and negative instances in the examples .</sentence>
				<definiendum id="0">a2a43a42a63a44a33a46a48a47</definiendum>
				<definiendum id="1">a49a51a10a63a52a62a49</definiendum>
				<definiens id="0">the number of times the feature occurred in the Negative class</definiens>
				<definiens id="1">the total number of all positive and negative instances in the examples</definiens>
			</definition>
			<definition id="4">
				<sentence>a9a27a4a37a75a50a2 a21a13a74a76a75a62a77 where a2a65a64a13a66 is the output of the Naive Bayes Classifier , a9a27a4 is the class in the target set a2 , and a21a25a74 are the individual features from the set a77 of the seven features .</sentence>
				<definiendum id="0">a2a65a64a13a66</definiendum>
				<definiendum id="1">a9a27a4</definiendum>
				<definiendum id="2">a21a25a74</definiendum>
				<definiens id="0">the output of the Naive Bayes Classifier ,</definiens>
				<definiens id="1">the class in the target set a2 , and</definiens>
			</definition>
			<definition id="5">
				<sentence>Treebank2 is a corpus featuring one million words of 1989 Wall Street Journal material annotated with several predicate-argument structures .</sentence>
				<definiendum id="0">Treebank2</definiendum>
				<definiens id="0">a corpus featuring one million words of 1989 Wall Street Journal material annotated with several predicate-argument structures</definiens>
			</definition>
			<definition id="6">
				<sentence>It is annotated with the following semantic roles : BNF ( beneficiary ) , DIR ( direction ) , EXT ( spatial extent ) , LOC ( location ) , MNR ( manner ) , PRP ( purpose and reason ) , and TMP ( temporal ) .</sentence>
				<definiendum id="0">MNR</definiendum>
				<definiens id="0">spatial extent ) , LOC ( location )</definiens>
			</definition>
</paper>

		<paper id="1508">
			<definition id="0">
				<sentence>The TDT-2 corpus , which we use for our experiments , contains 2265 audio clips of Mandarin news stories , along with several thousand contemporaneously published Chinese text articles , and English text and audio broadcasts .</sentence>
				<definiendum id="0">TDT-2 corpus</definiendum>
				<definiens id="0">contains 2265 audio clips of Mandarin news stories , along with several thousand contemporaneously published Chinese text articles , and English text and audio broadcasts</definiens>
			</definition>
			<definition id="1">
				<sentence>The Hopkins Automated Information Retriever for Combing Unstructured Text ( HAIRCUT ) is a research retrieval system developed at the Johns Hopkins University Applied Physics Laboratory .</sentence>
				<definiendum id="0">Hopkins Automated Information Retriever for Combing Unstructured Text</definiendum>
				<definiens id="0">a research retrieval system developed at the Johns Hopkins University Applied Physics Laboratory</definiens>
			</definition>
</paper>

		<paper id="0100">
</paper>

		<paper id="0604">
			<definition id="0">
				<sentence>The vision component consists of a number of steps .</sentence>
				<definiendum id="0">vision component</definiendum>
			</definition>
			<definition id="1">
				<sentence>The first model of Brown et al. ( 1993 ) , which will be used and expanded in our initial formulation , uses the following approximation to Pra5 fa6ea7 : Pra5 fa6 ea7a11a8 ∑ a Pra5 Ma7 ∏ ja12 1a13a13a13 M Pra5 a j a6 La7 Pra5 f j a6a j a14 ea j a7 ( 2 ) where M is the number of French words in f , L is the number of English words in e , and a is an alignment that maps each French word to one of the English words , or to the “null” word e0 .</sentence>
				<definiendum id="0">M</definiendum>
				<definiendum id="1">L</definiendum>
				<definiens id="0">the number of French words in f</definiens>
				<definiens id="1">an alignment that maps each French word to one of the English words , or to the “null” word e0</definiens>
			</definition>
			<definition id="2">
				<sentence>Theoretically , then , multiple regions can be handled in the same translation framework , by adding to the sequence of regions in each image , the regions resulting from all possible merges of image regions : Pra5 wa6 ra7a11a8 ε a5 ˜L a19 1a7 M ∏j a12 1a13a13a13M ∑ a ja12 0a13a13a13 ˜L ta5 w j a6ra j a7 ( 4 ) where ˜L denotes the total number of segmented and merged regions in an image .</sentence>
				<definiendum id="0">˜L</definiendum>
			</definition>
			<definition id="3">
				<sentence>Scenes contain objects composed of parts drawn from a small vocabulary of eight shapes , numbered 1–8 , in Figure 3 .</sentence>
				<definiendum id="0">Scenes</definiendum>
				<definiens id="0">contain objects composed of parts drawn from a small vocabulary of eight shapes</definiens>
			</definition>
			<definition id="4">
				<sentence>Finally , each scene has an associated text caption that contains one word for each database object , which specifies either the name of the whole object ( table/stand , chair/stool , lamp/light ) , or a part of the ob1 32 4 5 6 7 8 9 10 4 4 4 5 11 12 13 14 5 5 4 1 15 16 17 4 18 18 3 20 6 21 22 23 3 2 4 24 8 8 18 25 26 25 Possible oversegmentations for shapes 1 , 5 , 6 , and 8 : Figure 3 : Top : The eight primitive shapes used to construct objects in the scene .</sentence>
				<definiendum id="0">Top</definiendum>
				<definiens id="0">The eight primitive shapes used to construct objects in the scene</definiens>
			</definition>
			<definition id="5">
				<sentence>For 5 of the objects , the highest probability word is a correct identifier of the object ( stand , chair , stool , light , lamp ) , and for the 6 1 5 1 1 1 1 1 8 6 1 5 5 1 5 6 8 1 1 1 1 1 table ; leg table , stand ; base chair ; leg chair , stool ; base lamp ; base light , lamp ; base 1 Figure 4 : The database of six objects and associated words from which scenes are generated .</sentence>
				<definiendum id="0">highest probability word</definiendum>
				<definiens id="0">a correct identifier of the object ( stand , chair , stool , light , lamp )</definiens>
			</definition>
</paper>

		<paper id="0702">
			<definition id="0">
				<sentence>A network N ( Γ ) is obtained by the concatenation of finite-state automata C ( Γ ) inferred with the procedure described in the next section representing chunks of knowledge with fillers F. These automata output components of conceptual structures .</sentence>
				<definiendum id="0">network N ( Γ</definiendum>
				<definiens id="0">obtained by the concatenation of finite-state automata C ( Γ ) inferred with the procedure described in the next section representing chunks of knowledge with fillers F. These automata output components of conceptual structures</definiens>
			</definition>
</paper>

		<paper id="1702">
			<definition id="0">
				<sentence>Jason S. Chang Department of Computer Science National Tsing Hua University 101 , Kuangfu Road , Hsinchu , 300 , Taiwan , ROC jschang @ cs.nthu.edu.tw We present an unsupervised learning strategy for word sense disambiguation ( WSD ) that exploits multiple linguistic resources including a parallel corpus , a bilingual machine readable dictionary , and a thesaurus .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">300 , Taiwan , ROC jschang @ cs.nthu.edu.tw We present an unsupervised learning strategy for word sense disambiguation (</definiens>
			</definition>
			<definition id="1">
				<sentence>We use D ( S ) to denote the glosses of S. Therefore we have D ( S ) = “not easy ; hard to do , make , understand , etc. ; difficult to do or understand ; difficult to do ; difficult to do ; not easy ; demanding effort ; needing much effort ; difficult ; not well made for use ; difficult to use ; causing difficulty ; ” The intuition of bringing out the intended senses of semantically related words can be formalized by Class Based Sense Definition Model ( CBSDM ) , which is a micro language model generating D ( S ) , the glosses of S in I. For simplicity , we assume an unigram language model P ( d ) that generates the content words d in the glosses of S. Therefore , we have D ( S ) = “easy hard do make understand difficult do understand difficult do difficult do easy demanding effort needing much effort difficult well made use difficult use causing difficulty” If we have the relevant senses , it is a simple matter of counting to estimate P ( d ) .</sentence>
				<definiendum id="0">CBSDM )</definiendum>
				<definiens id="0">The intuition of bringing out the intended senses of semantically related words can be formalized by Class Based Sense Definition Model (</definiens>
				<definiens id="1">generates the content words d in the glosses of S. Therefore</definiens>
			</definition>
			<definition id="2">
				<sentence>, ) , ( ) , | ( ) | ( kj , i , ji , kj , max n ddEQLiwP LdP i ∑ = where d is a unigram or overlapping bigram in L1 or L2 , d i , j , k = the kth word in D ( w i , j ) , and EQ ( x , y ) = 1 , if x = y and 0 otherwise ; i , j | i , L ) according to d i , j , k , k = 1 , n i , j : , ) |P ( 1 kj , i , ji , kj , i , ji,1 max ∑ += k k Ld n LdLiw ∑ = = i ,1 ji,1 ji,1 ji , ) , | ( P ) , | ( P ) , |P ( mj Liw Liw Liw ; P ( w i , j | i , L ) converge ; i , j* , j*=argmax j P ( w i , j | i , L ) ; i , j* | j*=argmax j P ( w i , j | i , L ) } ; n tcI LcP ni ∑ = ∈ = ,1 j* , i ) ( ) | ( , where c is a unigram or overlapping bigram in L2 and t i , j is the L2 gloss of w i , j. Note that the purpose of Step 2 is to estimate how likely a word will appear in the definition of S based on the definining word for the senses , w i , j and relevant probability P ( w i , j | i , L ) .</sentence>
				<definiendum id="0">EQ</definiendum>
				<definiendum id="1">c</definiendum>
				<definiens id="0">kj , i , ji,1 max ∑ += k k Ld n LdLiw ∑ = = i ,1 ji,1 ji,1 ji , ) , | ( P ) , | ( P ) , |P ( mj Liw Liw Liw</definiens>
				<definiens id="1">a unigram or overlapping bigram in L2 and t i</definiens>
				<definiens id="2">to estimate how likely a word will appear in the definition of S based on the definining word for the senses</definiens>
			</definition>
</paper>

		<paper id="0503">
			<definition id="0">
				<sentence>In sentence extraction , the summary of a document ( or a cluster of related documents ) is a subset of the sentences in the original text ( Mani , 2001 ) .</sentence>
				<definiendum id="0">summary of a document</definiendum>
			</definition>
			<definition id="1">
				<sentence>Gzip is a compression utility which is publicly available and widely used ( www.gzip.org ) .</sentence>
				<definiendum id="0">Gzip</definiendum>
				<definiens id="0">a compression utility which is publicly available and widely used ( www.gzip.org )</definiens>
			</definition>
			<definition id="2">
				<sentence>If a7a8a9a7 is the total number of sentences in the input cluster , and a10 is the number of sentences already included in the base , there are a7a8a11a7a13a12a14a10 possible summaries of length a10a16a15a18a17 sentences .</sentence>
				<definiendum id="0">a10</definiendum>
				<definiens id="0">the total number of sentences in the input cluster , and</definiens>
				<definiens id="1">the number of sentences already included in the base</definiens>
			</definition>
			<definition id="3">
				<sentence>in size in F , where F is one of a number of metrics , as described in the rest of this section .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">one of a number of metrics</definiens>
			</definition>
			<definition id="4">
				<sentence>A cluster is a group of articles all pertaining to one particular event or story .</sentence>
				<definiendum id="0">cluster</definiendum>
				<definiens id="0">a group of articles all pertaining to one particular event or story</definiens>
			</definition>
			<definition id="5">
				<sentence>LENGTHORIG is the length in bytes of the summary , consisting of the original five MEAD-generated sentences plus this candidate sentence , before compression .</sentence>
				<definiendum id="0">LENGTHORIG</definiendum>
				<definiens id="0">the length in bytes of the summary , consisting of the original five MEAD-generated sentences plus this candidate sentence</definiens>
			</definition>
			<definition id="6">
				<sentence>DELTALENGTH is the difference in uncompressed length ( which is also the length of the candidate uncompressed sentence ) .</sentence>
				<definiendum id="0">DELTALENGTH</definiendum>
				<definiens id="0">the difference in uncompressed length ( which is also the length of the candidate uncompressed sentence )</definiens>
			</definition>
</paper>

		<paper id="1611">
			<definition id="0">
				<sentence>Paraphrasing is defined as a process of transforming an expression into another while keeping its meaning intact .</sentence>
				<definiendum id="0">Paraphrasing</definiendum>
				<definiens id="0">a process of transforming an expression into another while keeping its meaning intact</definiens>
			</definition>
			<definition id="1">
				<sentence>Among these , Hiragana and Katakana are phonographic , and Kanzi is an ideographic writing .</sentence>
				<definiendum id="0">Kanzi</definiendum>
				<definiens id="0">an ideographic writing</definiens>
			</definition>
			<definition id="2">
				<sentence>If a word t is not a Katakana word , we expand it to a set of Kanzi characters E ( t ) which is defined by ( 1 ) , where Ct is a semantic class including the word t , KC is a set of Kanzi characters used in words of semantic class C , fr ( k , C ) is a frequency of a Kanzi character k used in words of semantic class C , and Kt is a set of Kanzi characters in word t. E ( t ) = { k|k ∈ KCt , kprime = argmax l∈Kt fr ( l , Ct ) , fr ( k , Ct ) &gt; fr ( kprime , Ct ) } ∪Kt∪ { s|s ∈ Ct , s is a Katakana word } ( 1 ) E ( t ) consists of Kanzi characters which is used in words of semantic class Ct more frequently , than the most frequent Kanzi character in the word t. If the word t is a Katakana word , it is not expanded .</sentence>
				<definiendum id="0">Ct</definiendum>
				<definiendum id="1">KC</definiendum>
				<definiendum id="2">C )</definiendum>
				<definiendum id="3">Kt</definiendum>
				<definiendum id="4">t</definiendum>
				<definiens id="0">a semantic class including the word t</definiens>
				<definiens id="1">a set of Kanzi characters used in words of semantic class C , fr ( k ,</definiens>
				<definiens id="2">a frequency of a Kanzi character k used in words of semantic class C , and</definiens>
				<definiens id="3">a set of Kanzi characters in word t. E ( t ) = { k|k ∈ KCt , kprime = argmax l∈Kt fr ( l , Ct ) , fr ( k , Ct ) &gt; fr ( kprime , Ct ) } ∪Kt∪ { s|s ∈ Ct , s is a Katakana word } ( 1 ) E ( t ) consists of Kanzi characters which is used in words of semantic class Ct more frequently , than the most frequent Kanzi character in the word t. If the word</definiens>
			</definition>
			<definition id="3">
				<sentence>w ( k ) =      100 if k is Katakana word or 〈num〉 100× logfr ( k , Ct ) summationdisplay kprimeinE ( t ) logfr ( kprime , Ct ) if k is a Kanzi ( 2 ) Katakana words and numbers are assigned a constant value , 100 , and a Kanzi character is assigned a weight according to its frequency in the semantic class Ct , where k is used in the word t. In the previous example of “9 �” , we have obtained an expanded term set { l , 9 , � , �� , ���� } .</sentence>
				<definiendum id="0">k</definiendum>
				<definiens id="0">an expanded term set { l , 9 , � , �� , ���� }</definiens>
			</definition>
			<definition id="4">
				<sentence>\qp passage ( the company’s ) ( telephone charge ) ( reduction ) ( caused ) b1 b2 b3 b4 ����� � &lt;  [ `h ����� � &lt;  [ b� Extract proper structure Transform ending Figure 1 : An example of matching and transformation Correspondence between word w1 and bunsetu b2 is made bacause they share a common character “�” .</sentence>
				<definiendum id="0">\qp passage</definiendum>
				<definiens id="0">the company’s ) ( telephone charge ) ( reduction ) ( caused ) b1 b2 b3 b4 ����� � &lt; </definiens>
				<definiens id="1">made bacause they share a common character “�”</definiens>
			</definition>
			<definition id="5">
				<sentence>This factor is formalized as in ( 4 ) , where ti is the ith word in the input noun phrase , and dist ( s , t ) is the distance between two bunsetu each of which contains s and t. A distance between two bunsetu is defined as the number of bunsetu between them .</sentence>
				<definiendum id="0">ti</definiendum>
				<definiendum id="1">dist ( s , t )</definiendum>
				<definiens id="0">the distance between two bunsetu each of which contains s and t. A distance between two</definiens>
			</definition>
			<definition id="6">
				<sentence>Column “Q” denotes the query identifier , “Len.”</sentence>
				<definiendum id="0">Column “Q”</definiendum>
				<definiens id="0">the query identifier</definiens>
			</definition>
			<definition id="7">
				<sentence>The decimal numbers in the parentheses denote the generalized raw agreement indices of each category , which are calculated as given in ( 6 ) ( Uebersax , 2001 ) , where K is the number of judged cases , C is the number of categories , njk is the number of times category j is applied to case k , and nk is calculated by summing up over categories on case k ; nk = summationtextCj=1 njk .</sentence>
				<definiendum id="0">K</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">njk</definiendum>
				<definiens id="0">the number of judged cases</definiens>
				<definiens id="1">the number of categories ,</definiens>
				<definiens id="2">the number of times category j is applied to case k , and nk is calculated by summing up over categories on case k ; nk = summationtextCj=1 njk</definiens>
			</definition>
</paper>

		<paper id="0902">
			<definition id="0">
				<sentence>In fact , given the following Treebank bracketing , our programs produce the output shown : ( ( S ( NP ( NP ( NNP Rilly ) ) ( CC or ) ( NP ( NNP Glendora ) ) ) ( AUX ( VBD had ) ) ( VP ( VBN entered ) ( NP ( PRP\ $ her ) ( NN room ) ) ) ( SBAR ( IN while ) ( S ( NP ( PRP she ) ) ( VP ( VBD slept ) ) ) ) ( \ , \ , ) ( S ( NP ( \-NONE\\* ) ) ( VP ( VBG bringing ) ( PRT ( RB back ) ) ( NP ( PRP\ $ her ) ( JJ washed ) ( NNS clothes ) ) ) ) ) ( \ .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">VBG bringing ) ( PRT ( RB back ) ) ( NP ( PRP\ $ her ) ( JJ washed ) ( NNS clothes ) ) )</definiens>
			</definition>
</paper>

		<paper id="1507">
			<definition id="0">
				<sentence>The Linguistic Data Consortium ( LDC ) was founded in 1992 at the University of Pennsylvania , with seed money from DARPA , specifically to address the need for shared language resources .</sentence>
				<definiendum id="0">Linguistic Data Consortium</definiendum>
				<definiendum id="1">LDC</definiendum>
			</definition>
			<definition id="1">
				<sentence>Since then , LDC has created and published more than 241 linguistic databases and has accumulated considerable experience and skill in managing large-scale , multilingual data collection and annotation projects .</sentence>
				<definiendum id="0">LDC</definiendum>
				<definiens id="0">has created and published more than 241 linguistic databases and has accumulated considerable experience and skill in managing large-scale , multilingual data collection and annotation projects</definiens>
			</definition>
			<definition id="2">
				<sentence>The objective of the ACE Program is to develop extraction technology to support automatic processing of source language data ( in the form of natural text , and as text derived from Optical Character Recognition and Automatic Speech Recognition output ) .</sentence>
				<definiendum id="0">ACE Program</definiendum>
				<definiens id="0">text derived from Optical Character Recognition and Automatic Speech Recognition output )</definiens>
			</definition>
			<definition id="3">
				<sentence>The EELD program aims for development of technologies and tools for automated discovery , extraction and linking of sparse evidence contained in large amounts of classified and unclassified data sources .</sentence>
				<definiendum id="0">EELD program</definiendum>
			</definition>
			<definition id="4">
				<sentence>EELD is developing detection capabilities to extract relevant data and relationships about people , organizations , and activities from message traffic and open source data .</sentence>
				<definiendum id="0">EELD</definiendum>
			</definition>
			<definition id="5">
				<sentence>ACE adds new varieties of annotated data to the information extraction domain .</sentence>
				<definiendum id="0">ACE</definiendum>
				<definiens id="0">adds new varieties of annotated data to the information extraction domain</definiens>
			</definition>
			<definition id="6">
				<sentence>Entity Detection and Tracking is the most fundamental of the ACE tasks and was the sole focus of the ACE Pilot effort as well as ACE Phase One .</sentence>
				<definiendum id="0">Entity Detection</definiendum>
				<definiendum id="1">Tracking</definiendum>
				<definiens id="0">the most fundamental of the ACE tasks and was the sole focus of the ACE Pilot effort as well as ACE Phase One</definiens>
			</definition>
			<definition id="7">
				<sentence>Generic entities include references to general types of objects , hypothetical objects and generalizations across sets of objects .</sentence>
				<definiendum id="0">Generic entities</definiendum>
				<definiens id="0">include references to general types of objects , hypothetical objects and generalizations across sets of objects</definiens>
			</definition>
			<definition id="8">
				<sentence>ACE Phase Three adds a new challenge : recognition and characterization of events .</sentence>
				<definiendum id="0">ACE Phase Three</definiendum>
				<definiens id="0">adds a new challenge : recognition and characterization of events</definiens>
			</definition>
			<definition id="9">
				<sentence>Annotators extract the specific text reference to the event ( held high-level talks ) ; identify the meeting participants ( Colin Powell , Jiang Zemin ) as arguments of the event ; tag the locative ( Beijing ) and temporal ( held , last week ) attributes .</sentence>
				<definiendum id="0">Annotators</definiendum>
				<definiens id="0">arguments of the event</definiens>
			</definition>
			<definition id="10">
				<sentence>Particular challenges include the coreference of generic entities and the use of metonymy , GPE roles , and implicit vs. explicit relations .</sentence>
				<definiendum id="0">GPE</definiendum>
				<definiens id="0">roles , and implicit vs. explicit relations</definiens>
			</definition>
			<definition id="11">
				<sentence>Multiple research sites including MITRE , BBN , NYU , and LDC annotated the same set of 15,000 words of English data to establish a shared understanding of the annotation guidelines and resolve any inter-annotator discrepancies .</sentence>
				<definiendum id="0">LDC</definiendum>
				<definiens id="0">annotated the same set of 15,000 words of English data to establish a shared understanding of the annotation guidelines and resolve any inter-annotator discrepancies</definiens>
			</definition>
			<definition id="12">
				<sentence>Upon the conclusion of the formal task evaluation , pending negotiations with research sponsors and program coordinators , LDC publishes data more broadly to permit access to these valuable resources to all communities working in linguistic education , research , and technology development .</sentence>
				<definiendum id="0">LDC</definiendum>
				<definiens id="0">publishes data more broadly to permit access to these valuable resources to all communities working in linguistic education , research , and technology development</definiens>
			</definition>
</paper>

		<paper id="0309">
			<definition id="0">
				<sentence>Word alignment is a crucial part of any Machine Translation system , since it is the process of determining which words in a given source and target language sentence pair are translations of each other .</sentence>
				<definiendum id="0">Word alignment</definiendum>
			</definition>
			<definition id="1">
				<sentence>A parallel text consists of a source language text and its translation into some target language .</sentence>
				<definiendum id="0">parallel text</definiendum>
				<definiens id="0">consists of a source language text and its translation into some target language</definiens>
			</definition>
			<definition id="2">
				<sentence>This is represented by a0a2a1a4a3a6a5 a7a9a8a11a10a13a12 , where a7 is the source sentence , a10 is the target sentence , and a3 is the proposed word alignment for the sentence pair .</sentence>
				<definiendum id="0">a7</definiendum>
				<definiendum id="1">a3</definiendum>
				<definiens id="0">the source sentence</definiens>
				<definiens id="1">the proposed word alignment for the sentence pair</definiens>
			</definition>
			<definition id="3">
				<sentence>The alignment probability , a3 a1a4a3 a7 a5a15 a8a17a16 a8a19a18 a12 , is the likelihood that position a3 a7 in the source sentence can align to a given position a15 in the target sentence , where a16 and a18 are the given lengths of the source and target sentences .</sentence>
				<definiendum id="0">alignment probability</definiendum>
				<definiens id="0">the likelihood that position a3 a7 in the source sentence can align to a given position a15 in the target sentence , where a16 and a18 are the given lengths of the source and target sentences</definiens>
			</definition>
			<definition id="4">
				<sentence>The Duluth Word Alignment System consists of two preprocessing programs ( plain2snt and snt2matrix ) and one that learns the word alignment model ( model2 ) .</sentence>
				<definiendum id="0">Duluth Word Alignment System</definiendum>
				<definiens id="0">consists of two preprocessing programs ( plain2snt and snt2matrix ) and one that learns the word alignment model ( model2 )</definiens>
			</definition>
			<definition id="5">
				<sentence>It is made up of three different types of text : the novel 1984 , by George Orwell , which contains 6,429 sentence pairs , the Romanian Constitution which contains 967 sentence pairs , and a set of selected newspaper articles collected from the Internet that contain 41,889 sentences pairs .</sentence>
				<definiendum id="0">Romanian Constitution</definiendum>
				<definiens id="0">contains 6,429 sentence pairs</definiens>
			</definition>
			<definition id="6">
				<sentence>The gold standard data used in the shared task consists of 248 manually word aligned sentence pairs that were held out of the training process .</sentence>
				<definiendum id="0">gold standard data</definiendum>
				<definiens id="0">used in the shared task consists of 248 manually word aligned sentence pairs that were held out of the training process</definiens>
			</definition>
			<definition id="7">
				<sentence>The gold standard data used in the shared task consists of 447 manually word aligned sentence pairs that were held out of the training process .</sentence>
				<definiendum id="0">gold standard data</definiendum>
				<definiens id="0">used in the shared task consists of 447 manually word aligned sentence pairs that were held out of the training process</definiens>
			</definition>
			<definition id="8">
				<sentence>The resulting models will be referred to as UMD-XX-2 , UMD-XX-4 and UMD-XX6 , where 2 , 4 , and 6 are the distortion factor and XX is the language pair ( either RE or EF ) .</sentence>
				<definiendum id="0">XX</definiendum>
				<definiens id="0">the language pair ( either RE or EF )</definiens>
			</definition>
			<definition id="9">
				<sentence>Precision is the number of correct alignments ( C ) out of the total number of alignments attempted by the system ( S ) , while recall is the number of correct alignments ( C ) out of the total number of correct alignments ( A ) as given in the gold standard .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">the number of correct alignments ( C ) out of the total number of alignments attempted by the system ( S )</definiens>
			</definition>
			<definition id="10">
				<sentence>That is , a0a2a1a4a3a6a5 a27 a7 a27a8a7a6a9 a1 a5a10 a5 a5a11 a5 a1a4a3a6a5 a3 a16a28a16 a1 a5a10 a5 a5a12 a5 ( 4 ) The F–measure is the harmonic mean of precision and recall : a13a15a14a26a18 a3 a3 a7a17a16 a1a4a3 a1 a18 a13 a0a19a1a4a3a20a5 a27 a7 a27a8a7a6a9 a13 a1a4a3a6a5 a3 a16a28a16 a0a2a1a4a3a6a5 a27 a7 a27a8a7a6a9a22a21 a1a4a3a6a5 a3 a16a28a16 ( 5 ) AER is defined by ( Och and Ney , 2000a ) and accounts for both Sure and Probable alignments in scoring .</sentence>
				<definiendum id="0">F–measure</definiendum>
				<definiens id="0">the harmonic mean of precision and recall : a13a15a14a26a18 a3 a3 a7a17a16 a1a4a3 a1 a18 a13 a0a19a1a4a3a20a5 a27 a7 a27a8a7a6a9 a13 a1a4a3a6a5 a3 a16a28a16 a0a2a1a4a3a6a5 a27 a7 a27a8a7a6a9a22a21 a1a4a3a6a5 a3 a16a28a16</definiens>
			</definition>
</paper>

		<paper id="1710">
			<definition id="0">
				<sentence>The MI-Ngram model consists of two components : an ngram model and an MI model .</sentence>
				<definiendum id="0">MI-Ngram model</definiendum>
				<definiens id="0">consists of two components : an ngram model and an MI model</definiens>
			</definition>
			<definition id="1">
				<sentence>And the probability P can be estimated by using maximum likelihood estimation ( MLE ) principle : ) | ( 1−ii ww ) ( ) ( ) | ( 1 1 1 − − − = i ii ii wC wwC wwP ( 2.5 ) Where ) ( •C represents the number of times the sequence occurs in the training data .</sentence>
				<definiendum id="0">•C</definiendum>
				<definiens id="0">represents the number of times the sequence occurs in the training data</definiens>
			</definition>
			<definition id="2">
				<sentence>Let , where ’s are the words that make up the hypothesis , the probability of the word string P can be computed by using the chain rule : m m wwwwS ... 211 == ) ( S i w Obviously , an ngram model assumes that the probability of the next word w is independent of word string w in the history .</sentence>
				<definiendum id="0">’s</definiendum>
				<definiens id="0">independent of word string w in the history</definiens>
			</definition>
			<definition id="3">
				<sentence>By taking log function to both sides of equation ( 2.1 ) , we have the log probability of the word string log : ) ( SP Given m wwwS ... 21 = , an ngram model estimates the log probability of the word string by re-writing equation ( 2.2 ) : ) ( SP ) | ( log ) ( log ) ( log 1 1 2 1 − = ∑ + = i i m i wwP wPSP ( 2.2 ) ∑ ∑ = − +− − = − + + = m ni i nii n i i i ngram wwP wwP wPSP ) | ( log ) | ( log ) ( log ) ( log 1 1 1 2 1 1 1 ( 2.6 ) So , the classical task of statistical language modeling becomes how to effectively and efficiently predict the next word , given the previous words , that is to say , to estimate expressions of the form .</sentence>
				<definiendum id="0">ngram model</definiendum>
				<definiens id="0">estimates the log probability of the word string by re-writing equation ( 2.2 ) : ) ( SP ) | ( log )</definiens>
				<definiens id="1">to say , to estimate expressions of the form</definiens>
			</definition>
			<definition id="4">
				<sentence>That is to say , ) | ( hwP i 1−n ) ( ) ( ) ( ) ( 1 1 1 1 1 1 1 1 − +− − +− − − ≈ i ni i i ni i i i wP wwP wP wwP ) | ( ) | ( 1 1 1 1 − +− − ≈ i nii i i wwPwwP ( 2.3 ) ) ( ) ( ) ( ) ( ) ( ) ( 1 1 1 1 1 1 1 1 i i ni i i ni i i i i wPwP wwP wPwP wwP − +− − +− − − ≈ For example , in bigram model ( n=2 ) , the probability of a word is assumed to depend only on the previous word : ) ( ) ( ) ( log ) ( ) ( ) ( log 1 1 1 1 1 1 1 1 i i ni i i ni i i i i wPwP wwP wPwP wwP − +− − +− − − ≈ ( 2.7 ) ) | ( ) | ( 1 1 1 − − ≈ ii i i wwPwwP ( 2.4 ) Obviously , we can get ) 1 , , ( ) 1 , , ( 1 1 1 1 =≈= − +− − dwwMIdwwMI i i nii i ( 2.8 ) where ) ( ) ( ) ( log ) 1 , , ( 1 1 1 11 1 i i i i i i wPwP wwP dwwMI − − − == ) i w is the mutual information between the word string pair and , ( 1 1 i w − ) ( ) ( ) ( log ) 1 , , 1 1 1 11 1 i i ni i i ni i i ni wPwP wwP dw − +− − +−− +− == ) , 1 i w d ( wMI ( 1i ni w − +− is the mutual information between the word string pair .</sentence>
				<definiendum id="0">) ( ) ( ) ( ) ( ) ( )</definiendum>
				<definiens id="0">the mutual information between the word string pair and</definiens>
				<definiens id="1">the mutual information between the word string pair</definiens>
			</definition>
			<definition id="5">
				<sentence>d 0 ) , , ( =dBAMI ) , , ( dBAMI reflects the change of the information content when the word strings A and B are correlated .</sentence>
				<definiendum id="0">=dBAMI</definiendum>
				<definiendum id="1">dBAMI</definiendum>
				<definiens id="0">reflects the change of the information content when the word strings A and B are correlated</definiens>
			</definition>
			<definition id="6">
				<sentence>Using an alternative view of equivalence , an ngram model is one that partitions the data into equivalence classes based on the last n-1 words in the history. )</sentence>
				<definiendum id="0">ngram model</definiendum>
			</definition>
			<definition id="7">
				<sentence>By re-writing equation ( 2.6 ) , the trigram model estimates the log probability of the string as : ) ( SP ∑ = − − + + = m i i ii Trigram wwP ww wPSP 3 1 2 12 1 ) | ( log ) |log ( ) ( log ) ( log ( 2.9 ) Given history H , we can assume .</sentence>
				<definiendum id="0">trigram model</definiendum>
				<definiens id="0">estimates the log probability of the string as : ) ( SP ∑ = − − + +</definiens>
			</definition>
			<definition id="8">
				<sentence>1 1 − = i wH 1 2 − = i wX N &gt; We can re-writing equation ( 3.3 ) by using equation ( 3.4 ) : ) | ( log HwP i ) 1 , , ( ) ( log ii wHMIwP += ) , , ( ) 1 , , ( ) ( log 1 iwwMIwXMIwP iii ++= ) , , ( ) ( ) ( ) ( log ) ( log 1 iwwMI XPwP XwP wP i i i i ++= ∑ = = − += ni i i i wwwP 2 1 11 ) |log ( ) ( log ) | ( log 21 n n wwP + + ) , , ( ) ( ) ( log 1 iwwMI XP XwP i i += ) 1 , , ( 11 ++ + nwwMI n ) | ( log 1 1 2 − += ∑ + i i m ni wwP ) , , ( ) | ( log 1 iwwMIXwP ii += ( 3.5 ) L L L Then we have ∑ = = − += ni i i i wwwP 2 1 11 ) |log ( ) ( log ∑ += − − + m ni i ii wwP 1 1 2 ) | ( log ( 3.6 ) ) , , ( ) | ( log ) | ( log 1 1 2 1 1 iwwMI wwPwwP i i i i i + = −− By applying equation ( 3.6 ) repeatedly , we have : ) , , ( ) | ( log ) | ( log 1 1 2 1 1 iwwMIwwP wwP i i i i i += − − ∑∑ += −= = +−+ m ni nik k ik kiwwMI 11 ) 1 , , ( ( 3.8 ) ) | ( log 1 3 − = i i wwP ) 1 , , ( 2 iwwMI i −+ ) , , ( 1 iwwMI i + L L L ) | ( log 1 1 − +− = i nii wwP ∑ −= = +−+ nik k ik kiwwMI 1 ) 1 , , ( ( 3.7 ) Obviously , the first item in equation ( 3.7 ) contributes to the log probability of ngram within an N-word window while the second item is the summation of mutual information which contributes to the long distance context dependency of the next word w with the individual previous word over the long distance outside the N-word window .</sentence>
				<definiendum id="0">, ( ) ( )</definiendum>
				<definiens id="0">|log ( ) ( log ) | ( log 21 n n wwP + + ) ,</definiens>
				<definiens id="1">log ( 3.6 ) ) , , ( ) | ( log ) |</definiens>
				<definiens id="2">the summation of mutual information which contributes to the long distance context dependency of the next word w with the individual previous word over the long distance outside the N-word window</definiens>
			</definition>
			<definition id="9">
				<sentence>Therefore , we call equation ( 3.8 ) as an MI-Ngram model and equation ( 3.8 ) can be re-written as : ∑∑ += −= = +− m ni nik k ik kiwwMI 11 ) 1 , , ( ∑∑ += −= = − +−+ = m ni nik k ik Ngram NgramMI kiwwMI SP SP 11 ) 1 , , ( ) ( log ) ( ( 3.9 ) By using equation ( 3.7 ) , equation ( 2.2 ) can be re-written as : As a special case N=3 , the MI-Trigram model estimate the log probability of the string as follows : ) | ( log ) ( log ) ( log 1 1 2 1 − = ∑ += i i m i wwPwPSP ∑∑ = −= = − +−+ = m i ik k ik Trigram TrigramMI kiwwMI SP SP 4 3 1 ) 1 , , ( ) ( log ) ( log ( 3.10 ) ∑ = = − += ni i i i wwwP 2 1 11 ) |log ( ) ( log ) | ( log 11 n n wwP + + ( log 2+= ∑ + m ni P ) | 1 1 −i i ww Compared with traditional ngram modeling , MI-Ngram modeling incorporates the long distance context dependency by computing mutual information of the long distance dependent word ) ( ) ( ) , , ( log ) , , ( ) ( ) ( ) , , ( log ) , , ( ) ( ) ( ) , , ( log ) , , ( ) ( ) ( ) , , ( log ) , , ( ) , , ( BPAP dBAP dBAP BPAP dBAP dBAP BPAP dBAP dBAP BPAP dBAP dBAP dBAAMI + + + = ( 3.11 ) pairs .</sentence>
				<definiendum id="0">|log ( )</definiendum>
				<definiens id="0">As a special case N=3 , the MI-Trigram model estimate the log probability of the string as follows : ) | ( log ) ( log )</definiens>
				<definiens id="1">n n wwP + + ( log 2+= ∑ + m ni P ) | 1 1 −i i ww Compared with traditional ngram modeling , MI-Ngram modeling incorporates the long distance context dependency by computing mutual information of the long distance dependent word ) ( ) ( ) , , ( log ) , , ( ) ( ) ( ) , , ( log ) , , ( ) ( ) ( ) , , ( log )</definiens>
			</definition>
			<definition id="10">
				<sentence>F-measure is the weighted harmonic mean of precision and recall : PR RP F + + = 2 2 ) 1 ( β β with =1 .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiens id="0">the weighted harmonic mean of precision</definiens>
			</definition>
</paper>

		<paper id="0108">
			<definition id="0">
				<sentence>The term relevance weight is defined as Ww ( m ) = .5+ m−1m ( M −.5 ) Georelevance and term relevance Rw are then combined as ( 1−Ww ( m ) ) Rg +Ww ( m ) Rw .</sentence>
				<definiendum id="0">term relevance weight</definiendum>
			</definition>
</paper>

		<paper id="0808">
			<definition id="0">
				<sentence>InfoXtract : A Customizable Intermediate Level Information Extraction Engine ∗ Rohini K. Srihari Cymfony , Inc .</sentence>
				<definiendum id="0">InfoXtract</definiendum>
				<definiens id="0">A Customizable Intermediate Level Information Extraction Engine ∗ Rohini K. Srihari Cymfony</definiens>
			</definition>
			<definition id="1">
				<sentence>Information extraction ( IE ) systems assist analysts to assimilate information from electronic documents .</sentence>
				<definiendum id="0">Information extraction</definiendum>
				<definiens id="0">systems assist analysts to assimilate information from electronic documents</definiens>
			</definition>
			<definition id="2">
				<sentence>InfoXtract is a domain independent , but portable information extraction engine that has been designed for information discovery applications .</sentence>
				<definiendum id="0">InfoXtract</definiendum>
				<definiens id="0">a domain independent , but portable information extraction engine that has been designed for information discovery applications</definiens>
			</definition>
			<definition id="3">
				<sentence>Information Discovery ( ID ) is a term which has traditionally been used to describe efforts in data mining [ Han 1999 ] .</sentence>
				<definiendum id="0">Information Discovery</definiendum>
				<definiens id="0">a term which has traditionally been used to describe efforts in data mining</definiens>
			</definition>
			<definition id="4">
				<sentence>Cymfony differentiates itself by using a hybrid model that efficiently combines statistical and grammar-based approaches , as well as by using an internal data structure known as a token-list that can represent hierarchical linguistic structures and IE results for multiple modules to work on .</sentence>
				<definiendum id="0">Cymfony</definiendum>
				<definiens id="0">differentiates itself by using a hybrid model that efficiently combines statistical and grammar-based approaches</definiens>
			</definition>
			<definition id="5">
				<sentence>Specifically , it defines new IE tasks such as Entity Profile ( EP ) extraction , which is designed to accumulate interesting information about an entity across documents as well as within a discourse .</sentence>
				<definiendum id="0">Entity Profile ( EP ) extraction</definiendum>
				<definiens id="0">is designed to accumulate interesting information about an entity across documents as well as within a discourse</definiens>
			</definition>
			<definition id="6">
				<sentence>Furthermore , Concept-based General Event ( CGE ) is defined as a domain-independent , representation of event information but more feasible than MUC ST. InfoXtract represents a hybrid model for extracting both shallow and intermediate level IE : it exploits both statistical and grammar-based paradigms .</sentence>
				<definiendum id="0">General Event ( CGE</definiendum>
				<definiens id="0">a domain-independent , representation of event information but more feasible than MUC ST. InfoXtract represents a hybrid model for extracting both shallow and intermediate level IE : it exploits both statistical and grammar-based paradigms</definiens>
			</definition>
			<definition id="7">
				<sentence>Concept-based GE ( CGE ) further requires that participants of events be filled by EPs instead of NEs and that other values of the GE slots ( the action , time and location ) be disambiguated and normalized .</sentence>
				<definiendum id="0">Concept-based GE</definiendum>
				<definiendum id="1">GE slots</definiendum>
				<definiens id="0">the action , time and location ) be disambiguated and normalized</definiens>
			</definition>
			<definition id="8">
				<sentence>Document Processor Knowledge Resources Lexicon Resources Grammars Process Manager Tokenlist Legend Output Manager Source Document NLP/IE Processor ( s ) Tokenizer Tokenlist Lexicon Lookup POS Tagging Named Entity Detection Shallow Parsing Deep Parsing Relationship Detection Document pool NE CE EP SVO Time Normalization Alias and Coreference Profile/Event Linking/Merging Abbreviations POS = Part of Speech NE = Named Entity CE = Correlated Entity EP = Entity Profile SVO = Subject-Verb-Object GE = General Event PE = Predefined Event Grammar Module Procedure or Statistical Model Hybrid Module GE Statistical Models Location Normalizationr i i PE InfoXtract Repository Event Extraction Case Restoration Figure 1 : InfoXtract Engine Architecture InfoXtract represents a hybrid model for IE since it combines both grammar formalisms as well as machine learning .</sentence>
				<definiendum id="0">InfoXtract Engine Architecture InfoXtract</definiendum>
				<definiens id="0">Resources Lexicon Resources Grammars Process Manager Tokenlist Legend Output Manager Source Document NLP/IE Processor ( s ) Tokenizer Tokenlist Lexicon Lookup POS Tagging Named Entity Detection Shallow Parsing Deep Parsing Relationship Detection Document pool NE CE EP SVO Time Normalization Alias and Coreference Profile/Event Linking/Merging Abbreviations POS = Part of Speech NE = Named Entity CE = Correlated Entity EP = Entity Profile SVO = Subject-Verb-Object GE = General Event PE = Predefined Event Grammar Module Procedure or Statistical Model Hybrid Module</definiens>
			</definition>
			<definition id="9">
				<sentence>InfoXtract provides the ability to create customized named entity glossaries , which will boost the performance of organization tagging for a given domain .</sentence>
				<definiendum id="0">InfoXtract</definiendum>
				<definiens id="0">provides the ability to create customized named entity glossaries</definiens>
			</definition>
			<definition id="10">
				<sentence>InfoXtract supports two modes of operation , active and passive .</sentence>
				<definiendum id="0">InfoXtract</definiendum>
				<definiens id="0">supports two modes of operation , active and passive</definiens>
			</definition>
			<definition id="11">
				<sentence>When in active mode , InfoXtract is capable of retrieving documents via HTTP , FTP , or local file system .</sentence>
				<definiendum id="0">InfoXtract</definiendum>
				<definiens id="0">capable of retrieving documents via HTTP , FTP , or local file system</definiens>
			</definition>
			<definition id="12">
				<sentence>When in passive mode , InfoXtract is capable of accepting documents via HTTP .</sentence>
				<definiendum id="0">InfoXtract</definiendum>
				<definiens id="0">capable of accepting documents via HTTP</definiens>
			</definition>
			<definition id="13">
				<sentence>CORBA provides a robust , programming language independent , and platform neutral mechanism for developing and deploying distributed applications .</sentence>
				<definiendum id="0">CORBA</definiendum>
				<definiens id="0">provides a robust , programming language independent , and platform neutral mechanism for developing and deploying distributed applications</definiens>
			</definition>
			<definition id="14">
				<sentence>The Document Retriever handles all interfacing with the content provider’s retrieval process , including interface protocol ( authentication , retrieve requests , etc. ) , throughput management , and document packaging .</sentence>
				<definiendum id="0">Document Retriever</definiendum>
				<definiendum id="1">authentication</definiendum>
				<definiens id="0">handles all interfacing with the content provider’s retrieval process</definiens>
			</definition>
			<definition id="15">
				<sentence>The InfoXtract Controller is a multi-threaded application that is capable of submitting multiple simultaneous requests to the Document Manager .</sentence>
				<definiendum id="0">InfoXtract Controller</definiendum>
				<definiens id="0">a multi-threaded application that is capable of submitting multiple simultaneous requests to the Document Manager</definiens>
			</definition>
			<definition id="16">
				<sentence>The JIX module is a web application that is responsible for accepting requests for documents to be processed .</sentence>
				<definiendum id="0">JIX module</definiendum>
				<definiens id="0">a web application that is responsible for accepting requests for documents to be processed</definiens>
			</definition>
			<definition id="17">
				<sentence>The LGDE permits users to modify named entity glossaries , alias lexicons and general-purpose lexicons .</sentence>
				<definiendum id="0">LGDE</definiendum>
				<definiens id="0">permits users to modify named entity glossaries , alias lexicons and general-purpose lexicons</definiens>
			</definition>
			<definition id="18">
				<sentence>Brand Dashboard is a commercial application for marketing and public relations organizations to measure and assess media perception of consumer brands .</sentence>
				<definiendum id="0">Brand Dashboard</definiendum>
				<definiens id="0">a commercial application for marketing and public relations organizations to measure</definiens>
			</definition>
</paper>

		<paper id="0107">
</paper>

		<paper id="1106">
			<definition id="0">
				<sentence>Experiments on Chinese TREC and Japanese NTCIR topic detection show that the simple approach can achieve better performance compared to traditional approaches while avoiding word segmentation , which demonstrates its superiority in Asian language text classi cation .</sentence>
				<definiendum id="0">segmentation</definiendum>
				<definiens id="0">demonstrates its superiority in Asian language text classi cation</definiens>
			</definition>
			<definition id="1">
				<sentence>Text classi cation addresses the problem of assigning a given passage of text ( or a document ) to one or more prede ned classes .</sentence>
				<definiendum id="0">Text classi cation</definiendum>
				<definiens id="0">addresses the problem of assigning a given passage of text ( or a document ) to one or more prede ned classes</definiens>
			</definition>
			<definition id="2">
				<sentence>Many standard machine learning techniques have been applied to text categorization problems , such as naive Bayes classi ers , support vector machines , linear least squares models , neural networks , and knearest neighbor classi ers ( Sebastiani , 2002 ; Yang , 1999 ) .</sentence>
				<definiendum id="0">naive Bayes</definiendum>
				<definiens id="0">applied to text categorization problems</definiens>
			</definition>
			<definition id="3">
				<sentence>Unfortunately , using grams of length up to a7 entails estimating the probability ofa48 a42 events , wherea48 is the size of the word vocabulary .</sentence>
				<definiendum id="0">wherea48</definiendum>
				<definiens id="0">the size of the word vocabulary</definiens>
			</definition>
			<definition id="4">
				<sentence>One standard approach to smoothing probability estimates to cope with sparse data problems ( and to cope with potentially missing a7 -grams ) is to use some sort of back-off estimator a30a39a31 a11 a26a33 a11 a26a35a34a43a42a49a44 a12 a15a17a15a17a15 a11 a26a35a34 a12a36 a20 a50a51 a51 a52 a51 a51a53 a54 a30a39a31 a11 a26a33 a11 a26a46a34a43a42a45a44 a12 a15a17a15a17a15 a11 a26a35a34 a12a36a56a55 if a47 a31 a11 a26a35a34a43a42a45a44 a12 a15a17a15a17a15 a11 a26 a36a58a57a60a59 a61 a31 a11 a26a35a34a43a42a49a44 a12 a15a17a15a17a15 a11 a26a35a34 a12a36a19a62 a30a32a31 a11 a26a33 a11 a26a35a34a43a42a45a44 a9a16a15a17a15a17a15 a11 a26a46a34 a12a36a56a55 otherwise ( 4 ) where a54 a30a39a31 a11 a26a33 a11 a26a35a34a43a42a49a44 a12 a15a17a15a17a15 a11 a26a35a34 a12a36 a20a64a63a66a65a68a67a70a69a72a71a16a73 a7a75a74 a47 a31 a11 a26a35a34a43a42a45a44 a12 a15a17a15a17a15 a11 a26 a36 a47 a31 a11 a26a35a34a43a42a45a44 a12 a15a17a15a17a15 a11 a26a35a34 a12a36 ( 5 ) is the discounted probability , and a61 a31a11 a26a35a34a43a42a49a44 a12 a15a17a15a17a15 a11 a26a35a34 a12 a36 is a normalization constant calculated to be a61 a31 a11 a26a35a34a43a42a49a44 a12 a15a17a15a17a15 a11 a26a35a34 a12a36 a20 a29 a40 a76 a77a49a78a79a81a80a83a82a85a84a17a86a45a87a72a88a90a89a92a91a93a91a93a91a82a85a84a17a86a94a89a35a77a96a95a98a97a85a99 a54 a30a39a31a35a100 a33 a11 a26a46a34a43a42a45a44 a12 a15a17a15a17a15 a11 a26a35a34 a12a36 a29 a40 a76 a77a49a78a79a81a80a83a82a85a84a17a86a45a87a72a88a90a89a92a91a93a91a93a91a82a85a84a17a86a94a89a35a77a96a95a98a97a85a99 a54 a30a39a31a35a100 a33 a11 a26a46a34a43a42a45a44 a9a49a15a17a15a17a15 a11 a26a35a34 a12a36 ( 6 ) The discounted probability ( 5 ) can be computed using different smoothing approaches including Laplace smoothing , linear smoothing , absolute smoothing , Good-Turing smoothing and WittenBell smoothing ( Chen and Goodman , 1998 ) .</sentence>
				<definiendum id="0">WittenBell smoothing</definiendum>
				<definiens id="0">the discounted probability , and a61 a31a11 a26a35a34a43a42a49a44 a12 a15a17a15a17a15 a11 a26a35a34 a12 a36 is a normalization constant calculated to be a61 a31 a11 a26a35a34a43a42a49a44 a12 a15a17a15a17a15 a11 a26a35a34 a12a36 a20 a29 a40 a76 a77a49a78a79a81a80a83a82a85a84a17a86a45a87a72a88a90a89a92a91a93a91a93a91a82a85a84a17a86a94a89a35a77a96a95a98a97a85a99 a54 a30a39a31a35a100 a33 a11 a26a46a34a43a42a45a44 a12 a15a17a15a17a15 a11 a26a35a34 a12a36 a29 a40 a76 a77a49a78a79a81a80a83a82a85a84a17a86a45a87a72a88a90a89a92a91a93a91a93a91a82a85a84a17a86a94a89a35a77a96a95a98a97a85a99 a54 a30a39a31a35a100 a33 a11 a26a46a34a43a42a45a44 a9a49a15a17a15a17a15 a11 a26a35a34 a12a36</definiens>
			</definition>
</paper>

		<paper id="0317">
			<definition id="0">
				<sentence>Under the noisy channel model , the backtransliteration problem is to find out the most probable word E , given transliteration C. Letting P ( E ) be the probability of a word E , then for a given transliteration C , the back-transliteration probability of a word E can be written as P ( E|C ) .</sentence>
				<definiendum id="0">backtransliteration problem</definiendum>
				<definiendum id="1">back-transliteration probability</definiendum>
				<definiens id="0">the probability of a word E</definiens>
			</definition>
			<definition id="1">
				<sentence>( 2 ) is the language model , the probability of E. The second term , P ( C|E ) , in Eq .</sentence>
				<definiendum id="0">P ( C|E )</definiendum>
				<definiens id="0">the language model , the probability of E. The second term</definiens>
			</definition>
			<definition id="2">
				<sentence>The language model gives the prior probability P ( E ) which can be modeled using maximum likelihood estimation .</sentence>
				<definiendum id="0">language model</definiendum>
				<definiens id="0">gives the prior probability P ( E ) which can be modeled using maximum likelihood estimation</definiens>
			</definition>
			<definition id="3">
				<sentence>As for the transliteration model P ( C|E ) , we can approximate it using the transliteration unit ( TU ) , which is a decomposition of E and C. TU is defined as a se1 Ref .</sentence>
				<definiendum id="0">transliteration model P ( C|E</definiendum>
				<definiendum id="1">transliteration unit ( TU )</definiendum>
				<definiens id="0">a decomposition of E and C. TU is defined as a se1 Ref</definiens>
			</definition>
			<definition id="4">
				<sentence>( log ) | ( logmax ) | ( log 1 ∑ = +≈ N i iii M mPuvPECP ( 7 ) Let ) , ( jiS be the maximum accumulated log probability between the first i characters of E and the first j characters of C. Then , ) , ( ) | ( log nlSECP = , the maximum accumulated log probability among all possible alignment paths of E with length l and C with length n , can be computed using a dynamic programming ( DP ) strategy , as shown in the following : Step 1 ( Initialization ) : 0 ) 0,0 ( =S ( 8 ) Step 2 ( Recursion ) : .0 ,0 ) , ( log ) | ( log ) , ( max ) , ( , njli khPecP kjhiSjiS i hi j kj kh ≤≤≤≤ ++ −−= −− ( 9 ) Step 3 ( Termination ) : ) , ( log ) | ( log ) , ( max ) , ( , khPecP knhlSnlS l hl n kn kh ++ −−= −− ( 10 ) where ) , ( khP is defined as the probability of the match type “h-k” .</sentence>
				<definiendum id="0">Let ) , ( jiS</definiendum>
				<definiendum id="1">Initialization</definiendum>
				<definiendum id="2">khP</definiendum>
				<definiens id="0">the maximum accumulated log probability between the first i characters of E and the first j characters of C. Then , ) , ( ) | ( log nlSECP = , the maximum accumulated log probability among all possible alignment paths of E with length l and C with length n , can be computed using a dynamic programming ( DP ) strategy</definiens>
				<definiens id="1">.0 ,0 ) , ( log ) | ( log ) , ( max ) , ( , njli khPecP kjhiSjiS i hi j kj kh ≤≤≤≤ ++ −−= −− ( 9 ) Step 3 ( Termination ) : ) , ( log ) | ( log ) , ( max ) , ( , khPecP knhlSnlS l hl n kn kh ++ −−= −− ( 10 ) where )</definiens>
				<definiens id="2">the probability of the match type “h-k”</definiens>
			</definition>
			<definition id="5">
				<sentence>, ( ji vud δ is defined as follows : , ) 1 ( ) 1 ( , ) , (        &lt; ×−+ −−+ &lt; × − = δ δ δ n lkq hp and n lq p vud ji ( 13 ) where l and n are the length of the source word E and the target word C , respectively .</sentence>
				<definiendum id="0">ji vud δ</definiendum>
				<definiens id="0">follows : , ) 1 ( ) 1 ( , ) , (        &lt; ×−+ −−+ &lt; × − = δ δ δ n lkq hp and n lq p vud ji ( 13 ) where l and n are the length of the source word E and the target word C , respectively</definiens>
			</definition>
			<definition id="6">
				<sentence>As for the probability of match type , ) , ( khP , it is set to uniform distribution in the initialization phase , shown as follows : , 1 ) , ( T khP = ( 14 ) where T is the total number of match types allowed .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the total number of match types allowed</definiens>
			</definition>
			<definition id="7">
				<sentence>T2 consists of 500 bilingual examples from the English-Chinese version of the Longman Dictionary of Contempory English ( LDOCE ) ( Proctor , 1988 ) .</sentence>
				<definiendum id="0">T2</definiendum>
			</definition>
			<definition id="8">
				<sentence>∑ = = N i iR N AR 1 ) ( 1 ( 15 ) ∑ = = N i iR N ARR 1 ) ( 1 1 ( 16 ) where N is the number of testing data , and R ( i ) is the rank of the i-th testing data .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">R ( i )</definiendum>
				<definiens id="0">the number of testing data</definiens>
			</definition>
</paper>

		<paper id="1609">
			<definition id="0">
				<sentence>Acknowledgments This research is supported by the Defense Advanced Research Projects Agency as part of the Translingual Information Detection , Extraction and Summarization ( TIDES ) program , under Grant N66001001-1-8917 from the Space and Naval Warfare Systems Center San Diego , and by the National Science Foundation under Grant IIS-0081962 .</sentence>
				<definiendum id="0">Extraction</definiendum>
				<definiens id="0">the Defense Advanced Research Projects Agency as part of the Translingual Information Detection</definiens>
			</definition>
</paper>

		<paper id="0304">
			<definition id="0">
				<sentence>The Viterbi alignment between source and target sentences S and T is defined as the alignment ˆa whose probability is maximal under some translation model : ˆa = argmaxa∈APrM ( a|S , T ) where A is the set of all possible alignments between S and T , and PrM ( a|S , T ) is the estimate of a’s probability under model M , which we denote Pr ( a|S , T ) from hereon .</sentence>
				<definiendum id="0">Viterbi alignment</definiendum>
				<definiendum id="1">PrM ( a|S , T )</definiendum>
				<definiens id="0">the alignment ˆa whose probability is maximal under some translation model : ˆa = argmaxa∈APrM ( a|S , T ) where A is the set of all possible alignments between S and T , and</definiens>
				<definiens id="1">the estimate of a’s probability under model M</definiens>
			</definition>
			<definition id="1">
				<sentence>For instance , consider a procedure that splits both the SL and TL sentences S and T into two independent parts , in such a way as to maximise the probability of the two resulting Viterbi alignments : argmax〈i , j , d〉    d = 1 : Pr ( a1|si1 , tj1 ) ×Pr ( a2|smi+1 , tnj+1 ) d = −1 : Pr ( a1|si1 , tnj+1 ) ×Pr ( a2|smi+1 , tj1 ) ( 1 ) In the triple 〈i , j , d〉 above , i represents a “split point” in the SL sentence S , j is the analog for TL sentence T , and d is the “direction of correspondence” : d = 1 denotes a “parallel correspondence” , i.e. s1 ... si corresponds to t1 ... tj and si+1 ... sm corresponds to tj+1 ... tn ; d = −1 denotes a “crossing correspondence” , i.e. s1 ... si corresponds to tj+1 ... tn and si+1 ... sm corresponds to t1 ... tj .</sentence>
				<definiendum id="0">d</definiendum>
				<definiens id="0">consider a procedure that splits both the SL and TL sentences S and T into two independent parts , in such a way as to maximise the probability of the two resulting Viterbi alignments : argmax〈i , j , d〉    d = 1 : Pr ( a1|si1</definiens>
				<definiens id="1">a “split point” in the SL sentence S , j is the analog for TL sentence T , and</definiens>
				<definiens id="2">a “parallel correspondence”</definiens>
			</definition>
</paper>

		<paper id="0608">
			<definition id="0">
				<sentence>The set of patch descriptions forms an nf -dimensional space of real numbers , where nf is the number of features .</sentence>
				<definiendum id="0">nf</definiendum>
				<definiens id="0">the number of features</definiens>
			</definition>
			<definition id="1">
				<sentence>Mn is the number of patches in image n and Ln is the number of words in the image’s caption .</sentence>
				<definiendum id="0">Mn</definiendum>
				<definiendum id="1">Ln</definiendum>
				<definiens id="0">the number of patches in image n and</definiens>
				<definiens id="1">the number of words in the image’s caption</definiens>
			</definition>
			<definition id="2">
				<sentence>nw is the total number of word tokens in the training set .</sentence>
				<definiendum id="0">nw</definiendum>
				<definiens id="0">the total number of word tokens in the training set</definiens>
			</definition>
			<definition id="3">
				<sentence>That is , we use a single W W matrix , where W is the number of word tokens .</sentence>
				<definiendum id="0">W</definiendum>
				<definiens id="0">the number of word tokens</definiens>
			</definition>
			<definition id="4">
				<sentence>In summary , our learning objective is to find good values for the unknown model parameters , f ; ; ; g , where and are the means and covariances of the Gaussians for each word , is the set of alignment potentials and is the set of shrinkage hyper-parameters for feature weighting .</sentence>
				<definiendum id="0">learning objective</definiendum>
			</definition>
			<definition id="5">
				<sentence>The equations are given by E : m : 1 , 1N NX n=1 1 Mn MnX j=1 1 ~anj ( banj ) ( 2 ) E : m : 2 , 1N NX n=1 1 Ln LnX i=1 1 jPnij PniX j 1 ~anj ( banj ) ( 3 ) where Pni is the set of patches in image n that are manually-annotated using word i , banj is the model alignment with the highest probability , ~anj is the provided “true” annotation , and ~anj ( banj ) is 1 if ~anj = banj .</sentence>
				<definiendum id="0">Pni</definiendum>
				<definiendum id="1">banj</definiendum>
				<definiendum id="2">~anj</definiendum>
				<definiens id="0">the set of patches in image n that are manually-annotated using word i ,</definiens>
				<definiens id="1">the provided “true” annotation</definiens>
			</definition>
			<definition id="6">
				<sentence>On average , tMRF tends to perform equally well using the sophisticated or naive patch segmentations .</sentence>
				<definiendum id="0">tMRF</definiendum>
				<definiens id="0">tends to perform equally well using the sophisticated or naive patch segmentations</definiens>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>Furthermore the nature of reranking makes it possible to use global features , 1 ( join ) hi 2 ( Vinken ) h00i 1 ( Pierre ) h0i 2 ( will ) h01i 3 ( board ) h011i 3 ( the ) h0i 4 ( as ) h01i 4 ( director ) h011i 5 ( non-executive ) h0i 6 ( a ) h0i Figure 3 : Derivation tree : shows how the elementary trees shown in Fig .</sentence>
				<definiendum id="0">Pierre</definiendum>
				<definiens id="0">Derivation tree : shows how the elementary trees shown in Fig</definiens>
			</definition>
			<definition id="1">
				<sentence>For two parse trees , p1 and p2 , the tree kernel Tree ( p1 ; p2 ) is de ned as : Tree ( p1 ; p2 ) = X n1 in p1 n2 in p2 T ( n1 ; n2 ) ( 1 ) The recursive function T is de ned as follows : If n1 and n2 have the same bracketing tag ( e.g. S , NP , VP , : : : ) and the same number of children , T ( n1 ; n2 ) = Y i ( 1 + T ( n1i ; n2i ) ) ; ( 2 ) where , nki is the ith child of the node nk , is a weight coef cient used to control the importance of large sub-trees and 0 &lt; 1 .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">de ned as : Tree ( p1 ; p2 ) = X n1 in p1 n2 in p2 T ( n1 ; n2 ) ( 1 ) The recursive function T is de ned as follows : If n1 and n2 have the same bracketing tag ( e.g. S , NP , VP , : : : ) and the same number of children</definiens>
				<definiens id="1">the ith child of the node nk</definiens>
			</definition>
			<definition id="2">
				<sentence>Therefore VP ( join ) VP ( join ) V ( join ) NP ( board ) PP ( as ) P ( as ) NP ( director ) tree with root node n : VP VP V NP PP P NP ptn ( n ) : lex ( n ) : ( join , join , as ) Figure 7 : A lexicalized sub-tree rooted at n and its decomposition into a pattern , ptn ( n ) and corresponding vector of lexical information , lex ( n ) .</sentence>
				<definiendum id="0">PP</definiendum>
				<definiendum id="1">ptn</definiendum>
				<definiendum id="2">lex</definiendum>
				<definiens id="0">A lexicalized sub-tree rooted at n and its decomposition into a pattern</definiens>
			</definition>
			<definition id="3">
				<sentence>The number of constrained common sub-trees for the derivation tree kernel can be computed by the recursive function DT over derivation tree nodes n1 ; n2 : DT ( n1 ; n2 ) = ( 1 + A1 ( n1 ; n2 ) + A2 ( n1 ; n2 ) ) T '' ( sub ( n1 ) ; sub ( n2 ) ) ( 4 ) where sub ( nk ) is the sub-tree of nk in which children adjoined to the root of nk are pruned .</sentence>
				<definiendum id="0">sub ( nk )</definiendum>
				<definiens id="0">DT ( n1 ; n2 ) = ( 1 + A1 ( n1 ; n2 ) + A2 ( n1 ; n2 ) ) T '' ( sub ( n1 ) ; sub ( n2 ) )</definiens>
				<definiens id="1">the sub-tree of nk in which children adjoined to the root of nk are pruned</definiens>
			</definition>
			<definition id="4">
				<sentence>A1 ( n1 ; n2 ) = X i ; j DT ( a1i ; a2j ) ; where , a1i is the ith adjunct of n1 , and a2j is the jth adjunct of n2 .</sentence>
				<definiendum id="0">A1</definiendum>
				<definiendum id="1">a1i</definiendum>
				<definiendum id="2">a2j</definiendum>
				<definiens id="0">the ith adjunct of n1</definiens>
				<definiens id="1">the jth adjunct of n2</definiens>
			</definition>
			<definition id="5">
				<sentence>Speci cally , slice i contains positive samples ( ( ~pk ; pki ) ; +1 ) and negative samples ( ( pki ; ~pk ) ; 1 ) , where ~pk is the best parse for sentence k , pki is the parse with the ith highest loglikelihood in all the parses for sentence k and it is not the best parse ( Shen and Joshi , 2003 ) .</sentence>
				<definiendum id="0">~pk</definiendum>
			</definition>
			<definition id="6">
				<sentence>For each parse p , its score Sco ( p ) is de ned as follows : Sco ( p ) = MT ( p ) + ML ( p ) + l ( p ) + b ( p ) ; where MT ( p ) is the output of the tree kernel SVMs , ML ( p ) is the output of linear kernel SVMs , l ( p ) is the log-likelihood of parse p , and b ( p ) is the number of brackets in parse p. We noticed that the SVM systems prefers to give higher scores to the parses with less brackets .</sentence>
				<definiendum id="0">ML ( p )</definiendum>
				<definiens id="0">de ned as follows : Sco ( p ) = MT ( p ) + ML ( p ) + l ( p ) + b ( p ) ; where MT ( p ) is the output of the tree kernel SVMs</definiens>
				<definiens id="1">the output of linear kernel SVMs</definiens>
				<definiens id="2">the log-likelihood of parse p , and b ( p ) is the number of brackets in parse p. We noticed that the SVM systems prefers to give higher scores to the parses with less brackets</definiens>
			</definition>
</paper>

		<paper id="1406">
			<definition id="0">
				<sentence>McGinnis takes the compositionality of idiom aspect to support Halle and Marantz’ s ( 1993 ) theory of Distributed Morphology ( DM ) .</sentence>
				<definiendum id="0">McGinnis</definiendum>
			</definition>
			<definition id="1">
				<sentence>McGinnis contrasts DM with Jackendoff’ s ( 1997b ) theory of Representational Modularity ( RM ) , which treats idioms as involving an arbitrary mapping between conceptual structure ( CS ) and syntactic structure .</sentence>
				<definiendum id="0">RM )</definiendum>
				<definiens id="0">treats idioms as involving an arbitrary mapping between conceptual structure ( CS ) and syntactic structure</definiens>
			</definition>
</paper>

		<paper id="1201">
			<definition id="0">
				<sentence>WordNet ( Fellbaum , 1998b ) is an online lexical reference system in which English nouns , verbs , adjectives and adverbs are organized into synonym sets or synsets , each representing one underlying lexical concept .</sentence>
				<definiendum id="0">WordNet</definiendum>
				<definiens id="0">an online lexical reference system in which English nouns , verbs , adjectives and adverbs are organized into synonym sets or synsets</definiens>
			</definition>
			<definition id="1">
				<sentence>We find a Bayesian belief network ( BBN ) a natural structure to encode such combined knowledge from WordNet and corpus .</sentence>
				<definiendum id="0">BBN</definiendum>
				<definiens id="0">a natural structure to encode such combined knowledge from WordNet and corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>The BBN encodes the joint distribution a34a36a35a23a37a39a38 a14a13a16 a38 a18a20a16a22a21a22a21a22a21a40a16 a38 a24a42a41 as a34a36a35a43a37a39a38 a14a13a16 a38 a18a43a16a22a21a22a21a22a21a40a16 a38 a24a42a41a44a10 a24 a45 a30a47a46a33a14 a34a36a35a23a37a39a38 a30a49a48a32a50a28 a30 a41 ( 1 ) Each node in the DAG encodes a34a36a35a40a37a39a38 a30 a48a32a50a28 a30 a41 as a “conditional probability table” ( CPT ) .</sentence>
				<definiendum id="0">BBN</definiendum>
				<definiens id="0">encodes the joint distribution a34a36a35a23a37a39a38 a14a13a16 a38 a18a20a16a22a21a22a21a22a21a40a16 a38 a24a42a41 as a34a36a35a43a37a39a38 a14a13a16 a38 a18a43a16a22a21a22a21a22a21a40a16 a38 a24a42a41a44a10 a24 a45 a30a47a46a33a14 a34a36a35a23a37a39a38 a30a49a48a32a50a28 a30 a41 ( 1 ) Each node in the DAG encodes a34a36a35a40a37a39a38 a30 a48a32a50a28 a30 a41 as a “conditional probability table” ( CPT )</definiens>
			</definition>
			<definition id="3">
				<sentence>a51 is a parent of a52 iff a51 is the hypernym or holonym or attribute-of or a51 is a synset containing the word a52 .</sentence>
				<definiendum id="0">a51</definiendum>
				<definiendum id="1">a51</definiendum>
				<definiens id="0">a parent of a52 iff a51 is the hypernym or holonym or attribute-of or</definiens>
				<definiens id="1">a synset containing the word a52</definiens>
			</definition>
			<definition id="4">
				<sentence>The Bayesian belief network is trained offline using 1 : Construct a Bayesian Network structure using the WordNet structure 2 : Train the Bayesian network parameters on the corpus containing the answers 3 : Do question answering with trained Bayesian Network Figure 6 : The over-all question answering algorithm 1 : while CPTs do not converge do 2 : for each window of a54 words in the text do 3 : Clamp the word nodes in the Bayesian Network to a state of ‘present’ 4 : for each node in Bayesian network do 5 : find its joint probabilities with all configurations of its parent nodes ( E Step ) 6 : end for 7 : end for 8 : Update the conditional probability tables for all random variables ( M Step ) 9 : end while Figure 7 : Training the Bayesian Network for a corpus the Expectation Maximization algorithm ( Dempster , 1977 ) on windows sliding over the whole corpus .</sentence>
				<definiendum id="0">Update</definiendum>
				<definiens id="0">the conditional probability tables for all random variables</definiens>
			</definition>
			<definition id="5">
				<sentence>If a153 is the document collection and a153a155a154 is the set of documents containing a85 , then one common form of IDF weighting ( used by SMART again ) is a156a87a157a159a158 a37 a85a17a41a44a10 a160a58a161a141a162 a114a164a163a126a48a153a93a48 a48a153a155a154a100a48 a21 ( 3 ) The IR baseline MRR is only about 0.3 , which is far short of Falcon , which has an MRR of almost 0.7 .</sentence>
				<definiendum id="0">a153a155a154</definiendum>
				<definiens id="0">the document collection and</definiens>
			</definition>
</paper>

		<paper id="0400">
</paper>

		<paper id="0612">
			<definition id="0">
				<sentence>We also briefly describe a visualization tool ( a Java applet ) that we are currently developing to aid us in analyzing the collected data , and in further refining the semantic model .</sentence>
				<definiendum id="0">visualization tool</definiendum>
				<definiens id="0">currently developing to aid us in analyzing the collected data , and in further refining the semantic model</definiens>
			</definition>
			<definition id="1">
				<sentence>Also , it should be noted that PTM is by design intended as a re-iterative process , where each test round generates hypothesis to be tested in the following round .</sentence>
				<definiendum id="0">PTM</definiendum>
				<definiens id="0">a re-iterative process , where each test round generates hypothesis to be tested in the following round</definiens>
			</definition>
</paper>

		<paper id="2006">
			<definition id="0">
				<sentence>The patent document relates to an explicit and exclusive right over an intellectual property .</sentence>
				<definiendum id="0">patent document</definiendum>
				<definiens id="0">relates to an explicit and exclusive right over an intellectual property</definiens>
			</definition>
			<definition id="1">
				<sentence>The lemma RT circuit also includes hyponyms of the term , e.g. RT oscillator ( circuit ) , RT logic gate ( circuit ) and RT memory ( circuit ) ; note that the term circuit is shown in parentheses as it is ellipsed in the text – the reader of the patents , an expert in the disc ipline , is expected to know that an oscillator is a circuit .</sentence>
				<definiendum id="0">RT oscillator</definiendum>
				<definiendum id="1">RT logic gate</definiendum>
				<definiendum id="2">RT memory</definiendum>
				<definiens id="0">the term circuit is shown in parentheses as it is ellipsed in the text – the reader of the patents</definiens>
			</definition>
			<definition id="2">
				<sentence>The fact r emains , however , that like all utilita rian systems , the US PTO classification system is a rich repository that can be used , with some alterations , as the lex ical/terminological resource for information extra ction in particular and NLP in general .</sentence>
				<definiendum id="0">US PTO classification system</definiendum>
				<definiens id="0">a rich repository that can be used</definiens>
			</definition>
			<definition id="3">
				<sentence>The repository states the ontological commitment of the US PTO and its advisers , and can be used for building knowledge representation schema or s emantic processing sy stems .</sentence>
				<definiendum id="0">repository</definiendum>
				<definiens id="0">states the ontological commitment of the US PTO and its advisers , and can be used for building knowledge representation schema or s emantic processing sy stems</definiens>
			</definition>
</paper>

		<paper id="1302">
			<definition id="0">
				<sentence>Even short of the task of full translation , WSD is crucial to applications such as cross-lingual information retrieval ( CLIR ) , since search terms entered in the language used for querying must be appropriately rendered in the language used for retrieval .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiendum id="1">CLIR</definiendum>
				<definiens id="0">crucial to applications such as cross-lingual information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>experiments The Unified Medical Language System ( UMLS ) is a resource that contains linguistic , terminological and semantic information in the medical domain.2 It is organised in three parts : Specialist Lexicon , MetaThesaurus and Semantic Network .</sentence>
				<definiendum id="0">Unified Medical Language System</definiendum>
				<definiens id="0">a resource that contains linguistic , terminological and semantic information in the medical domain.2 It is organised in three parts : Specialist Lexicon</definiens>
			</definition>
			<definition id="2">
				<sentence>The MetaThesaurus contains concepts from more than 60 standardised medical thesauri , of which for our purposes we only use the concepts from MeSH ( the Medical Subject Headings thesaurus ) .</sentence>
				<definiendum id="0">MetaThesaurus</definiendum>
				<definiens id="0">contains concepts from more than 60 standardised medical thesauri</definiens>
				<definiens id="1">the Medical Subject Headings thesaurus )</definiens>
			</definition>
			<definition id="3">
				<sentence>The semantic information that we use in annotation is the so-called Concept Unique Identifier ( CUI ) , a code that represents a concept in the UMLS MetaThesaurus .</sentence>
				<definiendum id="0">semantic information</definiendum>
				<definiens id="0">a code that represents a concept in the UMLS MetaThesaurus</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , UMLS contains the term trauma as a possible realisation of the following two concepts : C0043251 Injuries and Wounds : Wounds and Injuries : trauma : traumatic disorders : Traumatic injury : C0021501 Physical Trauma : Trauma ( Physical ) : trauma : Each of these CUI’s is a possible sense of the term trauma .</sentence>
				<definiendum id="0">UMLS</definiendum>
				<definiens id="0">contains the term trauma as a possible realisation of the following two concepts : C0043251 Injuries and Wounds : Wounds and Injuries : trauma : traumatic disorders : Traumatic injury : C0021501 Physical Trauma : Trauma ( Physical ) : trauma : Each of these CUI’s is a possible sense of the term trauma</definiens>
			</definition>
			<definition id="5">
				<sentence>It is easy to see why this would according to the evaluation corpora , Recall is the proportion of instances in the evaluation corpora for which a correct decision was made , and Coverage is the proportion of instances in the evaluation corpora for which any decision was made .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiendum id="1">Coverage</definiendum>
				<definiens id="0">the proportion of instances in the evaluation corpora for which a correct decision was made</definiens>
			</definition>
</paper>

		<paper id="1727">
			<definition id="0">
				<sentence>Word segmentation in MSR-NLP is an integral part of a sentence analyzer which includes basic segmentation , derivational morphology , named entity recognition , new word identification , word lattice pruning and parsing .</sentence>
				<definiendum id="0">Word segmentation in MSR-NLP</definiendum>
				<definiens id="0">an integral part of a sentence analyzer which includes basic segmentation , derivational morphology , named entity recognition , new word identification</definiens>
			</definition>
			<definition id="1">
				<sentence>• The probability of the character string being a sequence of independent words ; • The morphological and syntactic properties of the characters ; • Word formation rules ; • Behavior of each character in existing words ( e.g. how likely is this character to be used as the second character of a twocharacter verb ) .</sentence>
				<definiendum id="0">likely</definiendum>
				<definiens id="0">probability of the character string being a sequence of independent words ; • The morphological and syntactic properties of the characters ; • Word formation rules ; • Behavior of each character in existing words</definiens>
				<definiens id="1">this character to be used as the second character of a twocharacter verb )</definiens>
			</definition>
</paper>

		<paper id="0210">
			<definition id="0">
				<sentence>CarmelTC learns to classify units of text based on features extracted from a syntactic analysis of that text as well as on a Naive Bayes classi cation of that text .</sentence>
				<definiendum id="0">CarmelTC</definiendum>
				<definiens id="0">learns to classify units of text based on features extracted from a syntactic analysis of that text as well as on a Naive Bayes classi cation of that text</definiens>
			</definition>
			<definition id="1">
				<sentence>Whereas LSA and Rainbow are pure bag of words approaches , CarmelTC is a rule learning approach where rules for classifying units of text rely on features extracted from a syntactic analysis of that text as well as on a bag of words classi cation of that text .</sentence>
				<definiendum id="0">CarmelTC</definiendum>
			</definition>
			<definition id="2">
				<sentence>Deep Syntactic Analysis ( ( clause2 ( ( mood *declarative ) ( root move ) ( tense present ) ( subj ( ( cat dp ) ( root pumpkin ) ( speci er ( ( cat detp ) ( def + ) ( root the ) ) ) ( modi er ( ( car adv ) ( root slow ) ) ) ) ) ) ) ( clause2 ( mood *declarative ) ( root exert ) ( tense present ) ( negation + ) ( causesubj ( ( cat dp ) ( root man ) ( agr 3s ) ( speci er ( ( cat detp ) ( def + ) ( root the ) ) ) ) ) ( subj ( ( cat dp ) ( root force ) ( speci er ( ( cat detp ) ( root a ) ) ) ) ) ( obj ( ( cat dp ) ( root it ) ) ) ) ( connective because ) ) The hybrid CarmelTC approach induces decision trees using features from both a deep syntactic functional analysis of an input text as well as a prediction from the Rainbow Naive Bayes text classi er ( McCallum , 1996 ; McCallum and Nigam , 1998 ) to make a prediction about the correct classi cation of a sentence .</sentence>
				<definiendum id="0">mood *declarative )</definiendum>
				<definiendum id="1">mood *declarative )</definiendum>
				<definiens id="0">speci er ( ( cat detp ) ( def + ) ( root the ) ) ) ) ) ( subj ( ( cat dp ) ( root force ) ( speci er ( ( cat detp ) ( root a ) ) ) ) ) ( obj ( ( cat dp ) ( root it )</definiens>
			</definition>
			<definition id="3">
				<sentence>Extracted Features ( tense-move present ) ( subj-move pumpkin ) ( speci er-pumpkin the ) ( modi er-move slow ) ( tense-exert present ) ( negation-exert + ) ( causesubj-exert man ) ( subj-exert force ) ( obj-exert it ) ( speci er-force a ) ( speci er-man the ) ships between syntactic heads ( e.g. , ( subj-throw man ) ) , tense information ( e.g. , ( tense-throw past ) ) , and information about passivization and negation ( e.g. , ( negationthrow + ) or ( passive-throw - ) ) .</sentence>
				<definiendum id="0">Extracted Features</definiendum>
				<definiens id="0">subj-throw man ) ) , tense information</definiens>
			</definition>
			<definition id="4">
				<sentence>Using the individual features extracted from the deep syntactic analysis of the input as well as the bag of words Naive Bayes classi cation of the input sentence , CarmelTC builds a vector representation of each input sentence , with each vector position corresponding to one of these features .</sentence>
				<definiendum id="0">CarmelTC</definiendum>
				<definiens id="0">builds a vector representation of each input sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>However , in some cases , arguments that COMLEX assigns the role of subject get rede ned as causesubj ( causative subject ) .</sentence>
				<definiendum id="0">COMLEX</definiendum>
				<definiens id="0">assigns the role of subject get rede ned as causesubj ( causative subject )</definiens>
			</definition>
			<definition id="6">
				<sentence>We tested LSA with threshold values between .1 and .9 at increments of .1 as well as testing a threshold of .53 as is used in the AUTO-TUTOR system ( Wiemer-Hastings et al. , 1998 ) .</sentence>
				<definiendum id="0">LSA</definiendum>
			</definition>
			<definition id="7">
				<sentence>In particular , CarmelTC achieves the highest f-score , which combines the precision and recall scores into a single measure .</sentence>
				<definiendum id="0">CarmelTC</definiendum>
				<definiens id="0">combines the precision and recall scores into a single measure</definiens>
			</definition>
			<definition id="8">
				<sentence>Rainbow achieves a lower score than CarmelTC in terms of precision , recall , false alarm rate , and f-score .</sentence>
				<definiendum id="0">Rainbow</definiendum>
				<definiens id="0">achieves a lower score than CarmelTC in terms of precision , recall , false alarm rate , and f-score</definiens>
			</definition>
</paper>

		<paper id="0312">
			<definition id="0">
				<sentence>WCR BP CF CS CF CY B7CF CT BN ( 1 ) where CF CY is the number of Japanese content words in a unit , CF CT is the number of English content words , and CF CS is the number of content words whose translation is also in the unit , which is found by translation dictionaries } We used the EDR electronic dictionary , EDICT , ENAMDICT , the ANCHOR translation dictionary , and Figure 3 : Handling of Remaining Phrases .</sentence>
				<definiendum id="0">WCR BP CF CS CF CY B7CF CT BN</definiendum>
				<definiendum id="1">CF CY</definiendum>
				<definiendum id="2">CF CT</definiendum>
				<definiendum id="3">CF CS</definiendum>
				<definiens id="0">the number of Japanese content words in a unit</definiens>
				<definiens id="1">the number of English content words , and</definiens>
				<definiens id="2">the number of content words whose translation is also in the unit</definiens>
			</definition>
			<definition id="1">
				<sentence>Expressions The equality between I and S is a sum of the equality score of each phrase correspondence in EQ , which is calculated as follows : EQUALB4CXB5BP C8 CB CRD3D2D8 A2BE AZ CRD3D2D8 B7BCBMBEA2 C8 CB CUD9D2CR A2BE AZ CUD9D2CR BN ( 3 ) where AZ CRD3D2D8 is the number of content words in the phrase correspondence , AZ CUD9D2CR is the number of function words , CB CRD3D2D8 is the equality between content words , and CB CUD9D2CR is the equality between function words .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">CUD9D2CR BN</definiendum>
				<definiendum id="2">AZ CRD3D2D8</definiendum>
				<definiendum id="3">AZ CUD9D2CR</definiendum>
				<definiendum id="4">CB CRD3D2D8</definiendum>
				<definiendum id="5">CB CUD9D2CR</definiendum>
				<definiens id="0">a sum of the equality score of each phrase correspondence in EQ , which is calculated as follows : EQUALB4CXB5BP C8 CB CRD3D2D8 A2BE AZ CRD3D2D8 B7BCBMBEA2 C8 CB CUD9D2CR A2BE AZ</definiens>
				<definiens id="1">the number of content words in the phrase correspondence ,</definiens>
				<definiens id="2">the number of function words</definiens>
				<definiens id="3">the equality between content words , and</definiens>
			</definition>
			<definition id="2">
				<sentence>On the other hand , the similarity between the surroundings of I and those of S is a sum of the similarity score of each phrase correspondence in CONTEXT , which is calculated as follows : SIMB4CXB5BP AQ CG CB CRD3D2D8 A2BE AZ CRD3D2D8 B7BCBMBEA2 C8 CB CUD9D2CR A2BE AZ CUD9D2CR AR A2CB CRD3D2D2CTCRD8 BM ( 4 ) Basically the calculation of SIM and EQUAL is the same , except that SIM considers the relation type between the phrase in I and its outer phrase by CB CRD3D2D2CTCRD8 .</sentence>
				<definiendum id="0">EQUAL</definiendum>
				<definiens id="0">a sum of the similarity score of each phrase correspondence in CONTEXT</definiens>
			</definition>
			<definition id="3">
				<sentence>The monolingual similarity between Japanese expressions I and S is calculated as follows : CG CXBEBXC9 EQUALB4CXB5B7 CG CXBEBVC7C6CCBXCGCC SIMB4CXB5BM ( 5 ) Alignment The translation confidence of phrase alignment between S and T is the sum of the confidence score of each phrase correspondence in ALIGN , CONF ( CX ) in Table 2 , and it is weighted by the WCR of the parallel sentences .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">T</definiendum>
				<definiens id="0">the sum of the confidence score of each phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>As a final measure , the score of I-S-T is calculated as follows : D2 CG CXBEBXC9 EQUALB4CXB5B7 CG CXBEBVC7C6CCBXCGCC SIMB4CXB5 D3 A2 D2 CG CXBEBTC4C1BZC6 CONFB4CXB5 D3 A2WCRBM ( 6 ) For each phrase ( P ) in an input sentence , the most plausible FTE is retrieved by the following algorithm : which a Japanese phrase matches P , and it is aligned to an English phrase .</sentence>
				<definiendum id="0">score of I-S-T</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">a Japanese phrase matches P , and it is aligned to an English phrase</definiens>
			</definition>
</paper>

		<paper id="1722">
</paper>

		<paper id="0405">
</paper>

		<paper id="1707">
			<definition id="0">
				<sentence>Each frameset consists of one or more syntactic frames and each syntactic frame realizes one or more semantic roles .</sentence>
				<definiendum id="0">frameset</definiendum>
				<definiens id="0">consists of one or more syntactic frames and each syntactic frame realizes one or more semantic roles</definiens>
			</definition>
			<definition id="1">
				<sentence>Dollar b. Object to Subject ( IP ( NP-SBJ ( NP-PN /China ) ( NP /economy /expansion ) ) ( VP ( ADVP /also ) ( ADVP /will ) ( VP /slow down ( NP-OBJ /speed ) ) ) /slow down arg1-psr : /China /economy /expansion arg1-pse : /speed ( IP ( NP-SBJ ( DNP ( NP ( NP-PN /China ) ( NP /economy /expansion ) ) ) ( NP /speed ) ) ( VP ( ADVP /also ) ( ADVP /will ) ( VP /slow down ) ) /slow down arg1 : /China /economy /expansion /DE /speed Another case of “split arguments” involves the coordinated noun phrases .</sentence>
				<definiendum id="0">VP</definiendum>
				<definiens id="0">the coordinated noun phrases</definiens>
			</definition>
			<definition id="2">
				<sentence>Another complication involves nominalizations ( or deverbal nouns ) and their co-occurrence with light and not-so-light verbs .</sentence>
				<definiendum id="0">complication</definiendum>
				<definiens id="0">involves nominalizations ( or deverbal nouns ) and their co-occurrence with light and not-so-light verbs</definiens>
			</definition>
			<definition id="3">
				<sentence>Frameset.01 : , /pass through Roles : arg0 ( “passer” ) , arg1 ( “place” ) Example : ( IP ( NP-SBJ /train ) ( VP ( ADVP /now ) ( VP /pass ( NP-OBJ /tunnel ) ) ) ) .01/pass arg0 : /train arg1 : /tunnel argM-ADV : /now ( IP ( NP-SBJ /train ) ( VP ( ADVP /now ) ( VP /pass ) ) ) .01/pass arg0 : /train argM-ADV : /now Frameset.02 : , ( , ) /pass ( an exam , etc. ) ( IP ( NP-SBJ ( DNP ( NP /he ) /DE ) ( NP /drug inspection ) ) ( VP ( ADVP /not ) ( VP /pass ) ) ) .02/pass arg1 : /he /DE /drug inspection ( IP ( NP-SBJ ( NP /he ) ( VP ( ADVP /not ) ( VP /pass ) ) ) ( NP-OBJ /drug inspection ) ) .02/pass arg1-psr : /he arg1-pse : /drug inspection Frameset.03 : /pass ( a bill , a law , etc. ) ( IP ( NP-PN-SBJ /the U.S. /Congress ) ( VP ( NP-TMP /recently ) ( VP /pass /ASP ( NP-OBJ /interstate /banking law ) ) ) ) .03/pass arg0 : /the U.S. arg1 : /interstate /banking law ( IP ( NP-SBJ ( ADJP /interstate ) ( NP /banking law ) ) ( VP ( NP-TMP /recently ) ( VP /pass /ASP ) ) ) .03/pass arg1 : /interstate /banking law The human annotator can use the information specified in this entry to annotate all instances of “ /pass” in a corpus .</sentence>
				<definiendum id="0">IP</definiendum>
				<definiendum id="1">/train argM-ADV</definiendum>
				<definiendum id="2">NP-SBJ</definiendum>
				<definiendum id="3">IP</definiendum>
				<definiens id="0">NP-OBJ /interstate /banking law ) ) ) ) .03/pass arg0 : /the U.S. arg1 : /interstate /banking law ( IP ( NP-SBJ ( ADJP /interstate ) ( NP /banking law</definiens>
				<definiens id="1">/interstate /banking law The human annotator can use the information specified in this entry to annotate all instances of “ /pass” in a corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>We described how diathesis alternation patterns can be used to make coarse sense distinctions for Chinese verbs as a necessary step in annotating the predicatestructure of predicates .</sentence>
				<definiendum id="0">diathesis alternation patterns</definiendum>
				<definiens id="0">a necessary step in annotating the predicatestructure of predicates</definiens>
			</definition>
</paper>

		<paper id="1807">
			<definition id="0">
				<sentence>Automatic extraction of multiword expressions ( MWE ) presents a tough challenge for the NLP community and corpus linguistics .</sentence>
				<definiendum id="0">MWE</definiendum>
			</definition>
			<definition id="1">
				<sentence>2 Automatic extraction of Multiword expressions ( MWE ) is an important issue in the NLP community and corpus linguistics .</sentence>
				<definiendum id="0">MWE )</definiendum>
			</definition>
			<definition id="2">
				<sentence>Based on POS annotation provided by the CLAWS tagger ( Garside and Smith , 1997 ) , USAS assigns a set of semantic tags to each item in running text and then attempts to disambiguate the tags in order to choose the most likely candidate in each context .</sentence>
				<definiendum id="0">USAS</definiendum>
				<definiens id="0">assigns a set of semantic tags to each item in running text and then attempts to disambiguate the tags in order to choose the most likely candidate in each context</definiens>
			</definition>
			<definition id="3">
				<sentence>In the multi-word-unit list , each template consists of a pattern of words and part-ofspeech tags .</sentence>
				<definiendum id="0">template</definiendum>
			</definition>
			<definition id="4">
				<sentence>USAS templates can match discontinuous MWUs , and this is illustrated by the first example , which includes optional intervening POS items marked within curly brackets .</sentence>
				<definiendum id="0">USAS</definiendum>
				<definiens id="0">includes optional intervening POS items marked within curly brackets</definiens>
			</definition>
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>Principle We have previously demonstrated ( see Genzel and Charniak ( 2002 ) for detailed derivation ) that the conditional entropy of the ith word in the sentence ( Xi ) , given its local context Li ( the preceding words in the same sentence ) and global context Ci ( the words in all preceding sentences ) can be represented as H ( Xi|Ci , Li ) = H ( Xi|Li ) −I ( Xi , Ci|Li ) where H ( Xi|Li ) is the conditional entropy of the ith word given local context , and I ( Xi , Ci|Li ) is the conditional mutual information between the ith word and out-of-sentence context , given the local context .</sentence>
				<definiendum id="0">H ( Xi|Li )</definiendum>
				<definiens id="0">the preceding words in the same sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>We use a simple smoothed trigram language model : P ( xi|x1 ... xi−1 ) ≈ P ( xi|xi−2xi−1 ) = λ1 ˆP ( xi|xi−2xi−1 ) + λ2 ˆP ( xi|xi−1 ) + ( 1−λ1 −λ2 ) ˆP ( xi ) where λ1 and λ2 are the smoothing coefficients2 , and ˆP is a maximum likelihood estimate of the corresponding probability , e.g. , ˆP ( xi|xi−2xi−1 ) = C ( xi−2xi−1xi ) C ( xi−2xi−1 ) where C ( xi ... xj ) is the number of times this sequence appears in the training data .</sentence>
				<definiendum id="0">ˆP</definiendum>
				<definiendum id="1">, ˆP</definiendum>
				<definiens id="0">a simple smoothed trigram language model</definiens>
				<definiens id="1">a maximum likelihood estimate of the corresponding probability , e.g.</definiens>
				<definiens id="2">the number of times this sequence appears in the training data</definiens>
			</definition>
			<definition id="2">
				<sentence>Let l ( t ) be the length of the underlying sentence for 0 2 4 6 8 100.985 1 Bucket number ( for sentence number ) Adjusted tree depth Figure 4 : Tree Depth tree t. Let L ( n ) = { t|l ( t ) = n } be the set of trees of size n. Let Lf ( n ) be defined as 1|L ( n ) |summationtextt∈L ( n ) f ( t ) , the average value of the statistic f on all sentences of length n. We then define the sentence-lengthadjusted statistic , for all t , as fprime ( t ) = f ( t ) L f ( l ( t ) ) The average value of the adjusted statistic is now equal to 1 , and it is independent of the sentence length .</sentence>
				<definiendum id="0">Let l ( t )</definiendum>
			</definition>
</paper>

		<paper id="1028">
</paper>

		<paper id="0432">
			<definition id="0">
				<sentence>Capitalisation is an often-used discriminator for NER , but can be misleading in sentence-initial or all-caps text .</sentence>
				<definiendum id="0">Capitalisation</definiendum>
			</definition>
			<definition id="1">
				<sentence>Orthographic Tries Tries are an efficient data structure for capturing statistical differences between strings in different categories .</sentence>
				<definiendum id="0">Orthographic Tries Tries</definiendum>
				<definiens id="0">an efficient data structure for capturing statistical differences between strings in different categories</definiens>
			</definition>
			<definition id="2">
				<sentence>A heterogeneous node represents a string that occurs in more than one category , while a homogeneous node represents a string that occurs in only one category .</sentence>
				<definiendum id="0">heterogeneous node</definiendum>
				<definiens id="0">represents a string that occurs in more than one category , while a homogeneous node represents a string that occurs in only one category</definiens>
			</definition>
			<definition id="3">
				<sentence>An HMM uses probability matrices Π , A , and B for the initial state , state transitions , and symbol emissions respectively ( Manning and Sch¨utze , 1999 ) .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiens id="0">uses probability matrices Π , A , and B for the initial state</definiens>
			</definition>
</paper>

		<paper id="0306">
			<definition id="0">
				<sentence>Dwedit is the minimum number of character edits ( insertions , deletions , substitutions ) required to transform one word into another , normalized by the lengths .</sentence>
				<definiendum id="0">Dwedit</definiendum>
			</definition>
			<definition id="1">
				<sentence>In the metrics below , the L1 norm distance from a point ( i , j ) to a line from ( 0,0 ) to ( I , J ) is dL1 ( i , I , j , J ) = vextendsinglevextendsingle vextendsinglevextendsinglei I − j J vextendsinglevextendsingle vextendsinglevextendsingle ( 3 ) The first metric , Dwdiag , is a normalized distance of the ( i , j ) pair of tokens to the diagonal on the word dotplot Dwdiag ( i , j ) = dL1 ( i , Lw ( l ) , j , Lw ( r ) ) ( 4 ) where Lw ( l ) is the length of the LHS in words .</sentence>
				<definiendum id="0">Lw ( l )</definiendum>
				<definiens id="0">the length of the LHS in words</definiens>
			</definition>
			<definition id="2">
				<sentence>One character metric is the distance from the center of the character box to the diagonal line of the character dotplot , where Lc ( l ) is the character length of the entire LHS segment .</sentence>
				<definiendum id="0">character metric</definiendum>
				<definiendum id="1">Lc ( l )</definiendum>
				<definiens id="0">the distance from the center of the character box to the diagonal line of the character dotplot</definiens>
				<definiens id="1">the character length of the entire LHS segment</definiens>
			</definition>
			<definition id="3">
				<sentence>Dfreqratio ( i , j ) = 1 − min ( c ( li , LHS ) , c ( rj , RHS ) ) max ( c ( l i , LHS ) , c ( rj , RHS ) ) ( 8 ) The next two are conditional probabilities of seeing one of the words given that the other word from the pair was seen in an aligned sentence .</sentence>
				<definiendum id="0">c ( rj</definiendum>
				<definiendum id="1">RHS ) ) max ( c</definiendum>
				<definiendum id="2">rj</definiendum>
				<definiens id="0">conditional probabilities of seeing one of the words given that the other word from the pair was seen in an aligned sentence</definiens>
			</definition>
			<definition id="4">
				<sentence>P ( L|R ) ( i , j ) = P ( li ∈ LHSx|rj ∈ RHSx ) ( 9 ) P ( R|L ) ( i , j ) = P ( rj ∈ RHSx|li ∈ LHSx ) ( 10 ) Note that neither of these is satisfactory as a probabilistic lexicon because they give stop words such as determiners high probability for every conditioning token .</sentence>
				<definiendum id="0">P ( L|R )</definiendum>
				<definiens id="0">a probabilistic lexicon because they give stop words such as determiners high probability for every conditioning token</definiens>
			</definition>
			<definition id="5">
				<sentence>Dbos ( i , j ) = summationtext x |c ( li , LHSx ) − c ( rj , RHSx ) |summationtext x max ( c ( li , LHSx ) , c ( rj , RHSx ) ) ( 11 ) The nearest neighbor rule is a well-known classification algorithm that provably converges to the Bayes Error Rate of a classification task as dataset size grows ( Duda et al. , 2001 ) .</sentence>
				<definiendum id="0">Dbos</definiendum>
				<definiendum id="1">rj</definiendum>
			</definition>
			<definition id="6">
				<sentence>Four measures were used to evaluate the classifiers : precision , recall , F-measure , and alignment error rate ( AER ) .</sentence>
				<definiendum id="0">AER</definiendum>
				<definiens id="0">used to evaluate the classifiers : precision , recall , F-measure , and alignment error rate</definiens>
			</definition>
			<definition id="7">
				<sentence>F-measure is the harmonic mean of precision and recall .</sentence>
				<definiendum id="0">F-measure</definiendum>
				<definiens id="0">the harmonic mean of precision and recall</definiens>
			</definition>
			<definition id="8">
				<sentence>freqratio is the classifier based on the relative frequency of the two tokens , P ( L|R ) aligns words in the LHS with words from the RHS that are often collocated in the training sentences , and the reverse for P ( R|L ) .</sentence>
				<definiendum id="0">freqratio</definiendum>
				<definiens id="0">the classifier based on the relative frequency of the two tokens , P ( L|R ) aligns words in the LHS with words from the RHS that are often collocated in the training sentences</definiens>
			</definition>
</paper>

		<paper id="1101">
			<definition id="0">
				<sentence>System NeATS ( Lin and Hovy , 2002 ) is an extractionbased multi-document summarization system .</sentence>
				<definiendum id="0">System NeATS</definiendum>
			</definition>
			<definition id="1">
				<sentence>NeATS computes the likelihood ratio λ ( Dunning , 1993 ) to identify key concepts in unigrams , bigrams , and trigrams , and clusters these concepts in order to identify major subtopics within the main topic .</sentence>
				<definiendum id="0">NeATS</definiendum>
				<definiens id="0">computes the likelihood ratio λ ( Dunning , 1993 ) to identify key concepts in unigrams , bigrams , and trigrams</definiens>
			</definition>
			<definition id="2">
				<sentence>• Content Presentation – To ensure coherence of the summary , NeATS pairs each sentence with an introduction sentence .</sentence>
				<definiendum id="0">NeATS</definiendum>
				<definiens id="0">pairs each sentence with an introduction sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Avg : mean unigram co-occurrence scores of 30 topics , Var : variance , Std : standard deviation , AvgCR : mean compression ratio , VarCR : variance of compression ratio , and StdCR : standard deviation of compression ratio .</sentence>
				<definiendum id="0">Avg</definiendum>
				<definiendum id="1">Std</definiendum>
				<definiendum id="2">AvgCR</definiendum>
				<definiens id="0">mean unigram co-occurrence scores of 30 topics , Var : variance ,</definiens>
				<definiens id="1">mean compression ratio</definiens>
			</definition>
			<definition id="4">
				<sentence>Pure syntactic ( noisy-channel model ) , shallow semantic ( by topic signatures ) , or simple combinations of them did not improve system performance and in some cases even degraded it .</sentence>
				<definiendum id="0">Pure syntactic</definiendum>
				<definiens id="0">( noisy-channel model ) , shallow semantic ( by topic signatures</definiens>
			</definition>
			<definition id="5">
				<sentence>Bleu : a Method for Automatic Evaluation of Machine Translation .</sentence>
				<definiendum id="0">Bleu</definiendum>
			</definition>
</paper>

		<paper id="0706">
			<definition id="0">
				<sentence>This Galaxy architecture consists of a central hub and servers .</sentence>
				<definiendum id="0">Galaxy architecture</definiendum>
			</definition>
</paper>

		<paper id="0413">
			<definition id="0">
				<sentence>The main issues that we investigate here are : † the benefit that can be gained by using confidence estimates , in discrimination power and/or over-all application quality as computed by a simulation that estimates the benefit to the user ; † the use of different machine learning ( ML ) techniques for CE ; † the relevance of various confidence features ; and † model combinations : we experiment with various model combination schemes based on the CE layer in order to improve the over-all prediction accuracy of the application .</sentence>
				<definiendum id="0">ML</definiendum>
				<definiens id="0">computed by a simulation that estimates the benefit to the user</definiens>
			</definition>
			<definition id="1">
				<sentence>As described in ( Foster et al. , 2002b ) , B ( ^x m jh ; s ) = P l k=0 p ( kjx ; h ; s ) B ( xjh ; s ; k ) depends on two main quantities : the probability p ( kjx ; h ; s ) that exactly k characters from the beginning of x are correct , and the benefit B ( xjh ; s ; k ) to the translator if this is the case .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">^x m jh ; s ) = P l k=0 p ( kjx ; h ; s ) B ( xjh ; s ; k ) depends on two main quantities : the probability p</definiens>
			</definition>
			<definition id="2">
				<sentence>B ( xjh ; s ; k ) is estimated from a model of user behaviour—based on data collected in user trials of the tool—that captures the cost of reading a prediction and performing any necessary editing , as well as the somewhat random nature of people’s decisions to accept .</sentence>
				<definiendum id="0">k )</definiendum>
				<definiens id="0">estimated from a model of user behaviour—based on data collected in user trials of the tool—that captures the cost of reading a</definiens>
			</definition>
			<definition id="3">
				<sentence>Our approach for CE consists in training neural nets to estimate the conditional probability of correctness p ( C = 1j^w m ; h ; s ; fw 1 m ; : : : ; w n m g ) , where ^w m = w 1 m is the most probable prediction of length m from a n-best set of alternative predictions according to the base model .</sentence>
				<definiendum id="0">CE</definiendum>
				<definiens id="0">consists in training neural nets to estimate the conditional probability of correctness p</definiens>
			</definition>
			<definition id="4">
				<sentence>For the problem of estimating p ( yjx ) for a set of classes y over a space of input vectors x , a single-layer neural net with “softmax” outputs takes the form : p ( yjx ) = exp ( ~fi y ¢ x + b ) =Z ( x ) where ~fi y is a vector of weights for class y , b is a bias term , and Z ( x ) is a normalization factor , the sum over all classes of the numerator .</sentence>
				<definiendum id="0">~fi y</definiendum>
				<definiens id="0">a vector of weights for class y</definiens>
				<definiens id="1">a normalization factor , the sum over all classes of the numerator</definiens>
			</definition>
			<definition id="5">
				<sentence>A maximum entropy model is a generalization of this in which an arbitrary feature function f y ( x ) is used to transform the input space as a function of y : p ( yjx ) = exp ( ~fi ¢ f y ( x ) ) =Z ( x ) : Both models are trained by maximum likelihood methods .</sentence>
				<definiendum id="0">maximum entropy model</definiendum>
				<definiens id="0">a generalization of this in which an arbitrary feature function f y ( x ) is used to transform the input space as a function of y : p ( yjx ) = exp ( ~fi ¢ f y ( x ) ) =Z ( x</definiens>
			</definition>
</paper>

	</volume>
