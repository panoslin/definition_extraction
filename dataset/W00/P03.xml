<?xml version="1.0" encoding="UTF-8"?>
	<volume id="P03">

		<paper id="1053">
			<definition id="0">
				<sentence>The patterns encode sentences in terms of tokens denoting the grammatical roles of words and complex phrases , e.g. , subject ( S ) , direct object ( O1 ) , indirect object ( O2 ) , main verb ( V ) , auxiliary verb ( Aux ) , adverb ( Adv ) , preposition ( P ) , etc .</sentence>
				<definiendum id="0">Adv</definiendum>
				<definiens id="0">the grammatical roles of words and complex phrases , e.g. , subject ( S ) , direct object ( O1 ) , indirect object ( O2 ) , main verb ( V ) , auxiliary verb</definiens>
			</definition>
			<definition id="1">
				<sentence>• TLA ( Gibson &amp; Wexler , 1994 ) : change any one parameter value of those that make up G curr .</sentence>
				<definiendum id="0">TLA</definiendum>
				<definiens id="0">change any one parameter value of those that make up G curr</definiens>
			</definition>
			<definition id="2">
				<sentence>• Non-Greedy TLA ( Niyogi &amp; Berwick , 1996 ) : change any one parameter value of those that make up G curr .</sentence>
				<definiendum id="0">Non-Greedy TLA</definiendum>
				<definiens id="0">change any one parameter value of those that make up G curr</definiens>
			</definition>
			<definition id="3">
				<sentence>• Guessing STL ( Fodor , 1998a ) : Perform a structural parse of the current input .</sentence>
				<definiendum id="0">Guessing STL</definiendum>
				<definiens id="0">Perform a structural parse of the current input</definiens>
			</definition>
			<definition id="4">
				<sentence>If a choice point is encountered , chose an alternative based on one of the following and then set parameter values based on the final parse tree : • STL Random Choice ( RC ) – randomly pick a parsing alternative .</sentence>
				<definiendum id="0">Random Choice</definiendum>
				<definiens id="0">an alternative based on one of the following and then set parameter values based on the final parse tree : • STL</definiens>
			</definition>
			<definition id="5">
				<sentence>99 % Average EDBG 16,663 3,589 Table 2 : EDBG , # of sentences consumed The TLA : The TLA incorporates two search heuristics : the Single Value Constraint ( SVC ) and Greediness .</sentence>
				<definiendum id="0">TLA</definiendum>
				<definiens id="0">The TLA incorporates two search heuristics : the Single Value Constraint ( SVC ) and Greediness</definiens>
			</definition>
			<definition id="6">
				<sentence>In the event that G curr can not parse the current input sentence s , the TLA attempts a second parse with a randomly chosen new grammar , G new , that differs from G curr by exactly one parameter value ( SVC ) .</sentence>
				<definiendum id="0">TLA</definiendum>
				<definiens id="0">attempts a second parse with a randomly chosen new grammar , G new , that differs from G curr by exactly one parameter value ( SVC )</definiens>
			</definition>
			<definition id="7">
				<sentence>The SSTL needs some unambiguity to be present in the structures derived from the sentences of the target language .</sentence>
				<definiendum id="0">SSTL</definiendum>
				<definiens id="0">needs some unambiguity to be present in the structures derived from the sentences of the target language</definiens>
			</definition>
			<definition id="8">
				<sentence>The LDD is a useful tool that can be used within such an empirical research program .</sentence>
				<definiendum id="0">LDD</definiendum>
				<definiens id="0">a useful tool that can be used within such an empirical research program</definiens>
			</definition>
</paper>

		<paper id="2024">
			<definition id="0">
				<sentence>Generation is handled by a small Definite Clause Grammar ( DCG ) , which converts attribute-value structures into surface strings ; its output is passed through a minimal post-transfer component , which applies a set of rules which map fixed strings to fixed strings .</sentence>
				<definiendum id="0">DCG )</definiendum>
				<definiens id="0">applies a set of rules which map fixed strings to fixed strings</definiens>
			</definition>
</paper>

		<paper id="1024">
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>To tackle the full ST task , an IE system needs to merge information from multiple sentences in general , since the information needed to fill one template can come from multiple sentences , and thus discourse processing is needed .</sentence>
				<definiendum id="0">IE system</definiendum>
			</definition>
			<definition id="1">
				<sentence>Our system , called ALICE ( Automated Learning-based Information Content Extraction ) , requires manually extracted templates paired with their corresponding documents that contain terrorist events for training .</sentence>
				<definiendum id="0">ALICE</definiendum>
				<definiens id="0">Automated Learning-based Information Content Extraction ) , requires manually extracted templates paired with their corresponding documents that contain terrorist events for training</definiens>
			</definition>
			<definition id="2">
				<sentence>Other noun phrases in the training document a3 are negative training examples for the classifier of slot a4 .</sentence>
				<definiendum id="0">Other noun phrases</definiendum>
			</definition>
			<definition id="3">
				<sentence>As such , a string that fills a template slot but is itself not a baseNP ( like “BOMB” ) is also used to generate a training example , by using its smallest encompassing noun phrase ( like “A BOMB EXPLO ( 1 ) ONE PERSON WAS KILLED TONIGHT AS THE RESULT OF A BOMB EXPLOSION IN SAN SALVADOR .</sentence>
				<definiendum id="0">baseNP</definiendum>
				<definiens id="0">a string that fills a template slot but is itself not a</definiens>
			</definition>
			<definition id="4">
				<sentence>VPa and related NPs/PPs ( VPaRel ) If a0a2a1 is a patient in a sentence , each of its VPa may have its own agents ( Ag ) and prepositional phrases ( PrepNP ) .</sentence>
				<definiendum id="0">VPa</definiendum>
				<definiendum id="1">related NPs/PPs</definiendum>
				<definiendum id="2">VPaRel</definiendum>
				<definiens id="0">a patient in a sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>V-Prep and related NPs ( V-PrepRel ) When a0a5a1 is the NP in a prepositional phrase PP , then the main verb ( V ) may have its own agents ( Ag ) and patients ( Pa ) .</sentence>
				<definiendum id="0">a0a5a1</definiendum>
				<definiens id="0">the NP in a prepositional phrase PP , then the main verb ( V ) may have its own agents ( Ag ) and patients ( Pa )</definiens>
			</definition>
			<definition id="6">
				<sentence>For example , DIE is the top VAg verb for the human target slot , and is ranked 12 among all features used for the human target slot .</sentence>
				<definiendum id="0">DIE</definiendum>
				<definiens id="0">the top VAg verb for the human target slot , and is ranked 12 among all features used for the human target slot</definiens>
			</definition>
			<definition id="7">
				<sentence>Maximum Entropy Classifier ( Alice-ME ) The maximum entropy ( ME ) framework is a recent learning approach which has been successfully used in various NLP tasks such as sentence segmentation , part-of-speech tagging , and parsing ( Ratnaparkhi , 1998 ) .</sentence>
				<definiendum id="0">Maximum Entropy Classifier</definiendum>
				<definiendum id="1">maximum entropy</definiendum>
			</definition>
			<definition id="8">
				<sentence>The learning algorithm finds a hyperplane that separates the training data with the largest margin .</sentence>
				<definiendum id="0">learning algorithm</definiendum>
				<definiens id="0">finds a hyperplane that separates the training data with the largest margin</definiens>
			</definition>
			<definition id="9">
				<sentence>Accuracy is measured in terms of recall ( R ) , precision ( P ) , and F-measure ( F ) .</sentence>
				<definiendum id="0">Accuracy</definiendum>
				<definiens id="0">measured in terms of recall ( R ) , precision ( P ) , and F-measure ( F )</definiens>
			</definition>
			<definition id="10">
				<sentence>The accuracy figures in the two tables are obtained by running the official scorer on the output templates of ALICE , and those of the MUC-4 participating systems ( available TST3 TST4 R P F R P F GE 55 54 54 GE 60 54 57 GE-CMU 43 52 47 GE-CMU 48 52 50 Alice-ME 41 51 45 Alice-ME 44 49 46 Alice-SVM 41 45 43 Alice-SVM 45 44 44 SRI 37 51 43 NYU 42 45 43 UMASS 36 49 42 SRI 39 49 43 Alice-DT 31 51 39 Alice-DT 36 50 42 NYU 35 43 39 UMASS 42 42 42 Alice-NB 41 30 35 Alice-NB 51 32 39 UMICH 32 36 34 BBN 35 42 38 BBN 22 40 28 UMICH 32 34 33 Table 3 : Accuracy of string slots on the TST3 and TST4 test set TST3 TST4 R P F R P F GE 58 54 56 GE 62 53 57 GE-CMU 48 55 51 GE-CMU 53 53 53 UMASS 45 56 50 SRI 44 51 47 Alice-ME 46 51 48 Alice-ME 46 46 46 SRI 43 54 48 NYU 46 46 46 Alice-SVM 45 46 45 UMASS 47 45 46 Alice-DT 38 53 44 Alice-SVM 47 40 43 NYU 40 46 43 Alice-DT 41 46 43 UMICH 40 39 39 BBN 40 43 41 Alice-NB 45 34 39 Alice-NB 52 33 40 BBN 29 43 35 UMICH 36 34 35 Table 4 : Accuracy of all slots on the TST3 and TST4 test set on the official web site ) .</sentence>
				<definiendum id="0">MUC-4 participating systems</definiendum>
				<definiens id="0">TST4 test set on the official web site )</definiens>
			</definition>
</paper>

		<paper id="1001">
			<definition id="0">
				<sentence>We test the feasibility of this strategy on one semantic relation and a challenging subset of questions , i.e. , “Who is …” questions , in which either a concept is presented and an instance is requested ( e.g. , “Who is the mayor of Boston ? ” )</sentence>
				<definiendum id="0">“Who</definiendum>
				<definiens id="0">the mayor of Boston ? ”</definiens>
			</definition>
			<definition id="1">
				<sentence>We then compare answers based on these relations to answers given by TextMap ( Hermjakob et al. , 2002 ) , a state of the art web-based question answering system .</sentence>
				<definiendum id="0">TextMap</definiendum>
				<definiens id="0">answers based on these relations to answers given by</definiens>
			</definition>
			<definition id="2">
				<sentence>Such patterns ( e.g. “president George Bush” ) are very productive and occur 40 times more often than patterns employed by Hearst ( 1992 ) .</sentence>
				<definiendum id="0">Such patterns</definiendum>
			</definition>
			<definition id="3">
				<sentence>Thus , “Steven Spielberg” and “J. Edgar Hoover” are both considered instances of the single concept Threshold=0.90 Threshold=0.80 “sultry screen actress” ) , which can be categorized based on nearly 100,000 unique complex concept heads ( e.g. , “screen actress” ) and about 14,000 unique simple concept heads ( e.g. , “actress” ) .</sentence>
				<definiendum id="0">“J. Edgar Hoover”</definiendum>
				<definiens id="0">both considered instances of the single concept Threshold=0.90 Threshold=0.80 “sultry screen actress” ) , which can be categorized based on nearly 100,000 unique complex concept heads ( e.g. , “screen actress” ) and about 14,000 unique simple concept heads</definiens>
			</definition>
			<definition id="4">
				<sentence>and concept centered queries ( e.g. , “Who is the mayor of Boston ? ” )</sentence>
				<definiendum id="0">“Who</definiendum>
				<definiens id="0">the mayor of Boston ? ”</definiens>
			</definition>
			<definition id="5">
				<sentence>5 Answers that unequivocally identify an instance’s celebrity ( e.g. , “Jennifer Capriati is a tennis star” ) are marked correct .</sentence>
				<definiendum id="0">Capriati</definiendum>
				<definiens id="0">a tennis star” ) are marked correct</definiens>
			</definition>
</paper>

		<paper id="1057">
			<definition id="0">
				<sentence>BLEU measures the similarity between MT results and translation results made by humans ( called 1 In this paper , the number of rules denotes the number of unique pairs of source patterns and target patterns .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">measures the similarity between MT results and translation results made by humans</definiens>
				<definiens id="1">the number of unique pairs of source patterns and target patterns</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , in order to calculate the BLEU score of a combination ( solution ) , we have to translate C times , where C denotes the size of the evaluation corpus .</sentence>
				<definiendum id="0">BLEU score of a combination</definiendum>
				<definiendum id="1">C</definiendum>
				<definiens id="0">the size of the evaluation corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>Cross-cleaning uses all sentences in the training corpus , so it is nearly equivalent to applying a large evaluation corpus to feedback cleaning , even though it does not require specific evaluation corpora .</sentence>
				<definiendum id="0">Cross-cleaning</definiendum>
				<definiens id="0">uses all sentences in the training corpus</definiens>
			</definition>
</paper>

		<paper id="2019">
			<definition id="0">
				<sentence>Information extraction ( IE ) is a technology that can be applied to identifying both sources and targets of new hyperlinks .</sentence>
				<definiendum id="0">Information extraction</definiendum>
				<definiens id="0">a technology that can be applied to identifying both sources and targets of new hyperlinks</definiens>
			</definition>
			<definition id="1">
				<sentence>ExtraLink uses as its IE system SProUT , a generic multilingual shallow analysis platform , which currently provides linguistic processing resources for English , German , Italian , French , Spanish , Czech , Polish , Japanese , and Chinese ( Becker et al. , 2002 ) .</sentence>
				<definiendum id="0">ExtraLink</definiendum>
				<definiens id="0">uses as its IE system SProUT , a generic multilingual shallow analysis platform , which currently provides linguistic processing resources for English , German , Italian , French , Spanish , Czech</definiens>
			</definition>
			<definition id="2">
				<sentence>On the other hand , unificationbased grammars ( UBGs ) are designed to capture fine-grained syntactic and semantic constraints , resulting in better descriptions of natural language phenomena .</sentence>
				<definiendum id="0">unificationbased grammars ( UBGs</definiendum>
				<definiens id="0">designed to capture fine-grained syntactic and semantic constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>SProUT’s mission is to take the best from these two worlds , having a finite state machine that operates on typed feature structures ( TFSs ) .</sentence>
				<definiendum id="0">SProUT’s mission</definiendum>
				<definiens id="0">operates on typed feature structures ( TFSs )</definiens>
			</definition>
			<definition id="4">
				<sentence>I.e. , transduction rules in SProUT do not rely on simple atomic symbols , but instead on TFSs , where the left-hand side of a rule is a regular expression over TFSs , representing the recognition pattern , and the right-hand side is a sequence of TFSs , specifying the output structure .</sentence>
				<definiendum id="0">rule</definiendum>
				<definiendum id="1">right-hand side</definiendum>
				<definiens id="0">transduction rules in SProUT do not rely on simple atomic symbols , but instead on TFSs , where the left-hand side of a</definiens>
			</definition>
			<definition id="5">
				<sentence>Unifiability as a test criterion in a transition is a generalization over symbol equality .</sentence>
				<definiendum id="0">Unifiability</definiendum>
				<definiens id="0">a generalization over symbol equality</definiens>
			</definition>
			<definition id="6">
				<sentence>The core of SProUT comprises of the following components : ( i ) a finite-state machine toolkit for building , combining , and optimizing finite-state devices ; ( ii ) a flexible XML-based regular compiler for converting regular patterns into their corresponding compressed finite-state representation ( Piskorski et al. , 2002 ) ; ( iii ) a JTFS package which provides standard operations for constructing and manipulating TFSs ; and ( iv ) an XTDL grammar interpreter .</sentence>
				<definiendum id="0">JTFS package</definiendum>
				<definiens id="0">a flexible XML-based regular compiler for converting regular patterns into their corresponding compressed finite-state representation</definiens>
			</definition>
			<definition id="7">
				<sentence>The morphology unit provides lexical resources for English , German ( equipped with online shallow compound recognition ) , French , Italian , and Spanish , which were compiled from the full form lexica of MMorph ( Petitpierre and Russell , 1995 ) .</sentence>
				<definiendum id="0">Spanish</definiendum>
				<definiens id="0">provides lexical resources for English , German ( equipped with online shallow compound recognition</definiens>
			</definition>
			<definition id="8">
				<sentence>A core component is a domain ontology describing tourist sites in terms of sights , accommodations , restaurants , cultural events , etc .</sentence>
				<definiendum id="0">core component</definiendum>
			</definition>
			<definition id="9">
				<sentence>The ExtraLink GUI marks the relevant entities ( usually locations ) identified by SProUT ( see second window on the left in Figure 2 ) .</sentence>
				<definiendum id="0">ExtraLink GUI</definiendum>
				<definiens id="0">marks the relevant entities ( usually locations</definiens>
			</definition>
			<definition id="10">
				<sentence>The Unbearable Lightness of Tagging : A Case Study in Morphosyntactic Tagging of Polish .</sentence>
				<definiendum id="0">Unbearable Lightness of Tagging</definiendum>
				<definiens id="0">A Case Study in Morphosyntactic Tagging of Polish</definiens>
			</definition>
</paper>

		<paper id="2018">
			<definition id="0">
				<sentence>The Hamburg Notation System ( HamNoSys ) ( Prillwitz et al. , 1989 ; Hanke and Schmaling , 2001 ; Hanke , 2002 ) is an established phonetic transcription system for SLs comprising more than 200 iconically motivated symbols to describe these manual and non-manual features of signs .</sentence>
				<definiendum id="0">Hamburg Notation System</definiendum>
				<definiens id="0">an established phonetic transcription system for SLs comprising more than 200 iconically motivated symbols to describe these manual and non-manual features of signs</definiens>
			</definition>
			<definition id="1">
				<sentence>A SL grammar and lexicon are used to drive derivation of a HamNoSys phonetic description of a sign sequence from the HPSG semantic structure ( Figure 2 bottom middle ) .</sentence>
				<definiendum id="0">SL grammar</definiendum>
				<definiens id="0">used to drive derivation of a HamNoSys phonetic description of a sign sequence from the HPSG semantic structure</definiens>
			</definition>
			<definition id="2">
				<sentence>Currently , the SL generation sub-system incorporates a lexicon and grammar whose coverage are representative of a number of interesting SL phenomena and whose semantic , syntactic and phonological formalisation is one of the most advanced SL characterisations available .</sentence>
				<definiendum id="0">SL generation sub-system</definiendum>
				<definiens id="0">incorporates a lexicon and grammar whose coverage are representative of a number of interesting SL phenomena and whose semantic , syntactic and phonological formalisation</definiens>
			</definition>
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>An alignment A for two sentences E and F is a set of links such that every word in E and F participates in at least one link , and a word linked to e0 or f0 participates in no other links .</sentence>
				<definiendum id="0">F</definiendum>
				<definiens id="0">a set of links such that every word in E and F participates in at least one link , and a word linked to e0 or f0 participates in no other links</definiens>
			</definition>
			<definition id="1">
				<sentence>An alignment A consists of t links { l1 , l2 , ... , lt } , where each lk = l ( eik , fjk ) for some ik and jk .</sentence>
				<definiendum id="0">alignment A</definiendum>
				<definiens id="0">consists of t links { l1 , l2 , ... , lt }</definiens>
			</definition>
			<definition id="2">
				<sentence>a b a u v v e f 0 0 Figure 1 : An Example Aligned Corpus Table 1 : Example Probability Tables ( a ) Link Counts and Probabilities eik fjk |lk| |eik , fjk| P ( lk|eik , fjk ) b u 1 1 1 a f0 1 2 12 e0 v 1 2 12 a v 1 4 14 ( b ) Feature Counts eik fjk |ft , lk| |ft , eik , fjk| a v 1 1 ( c ) Feature Probabilities eik fjk P ( ft|lk ) P ( ft|eik , fjk ) a v 1 14 P ( A|E , F ) = P ( l ( b , u ) |b , u ) × P ( l ( a , f0 ) |a , f0 ) × P ( l ( e0 , v ) |e0 , v ) × P ( l ( a , v ) |a , v ) P ( ft|l ( a , v ) ) P ( ft|a , v ) = 1× 12 × 12 × 14 × 11 4 = 14 In this section , we describe a world-alignment algorithm guided by the alignment probability model derived above .</sentence>
				<definiendum id="0">v ) P</definiendum>
				<definiens id="0">a world-alignment algorithm guided by the alignment probability model derived above</definiens>
			</definition>
			<definition id="3">
				<sentence>The input to our word-alignment algorithm consists of a pair of sentences E and F , and the dependency tree TE for E. TE allows us to make use of features and constraints that are based on linguistic intuitions .</sentence>
				<definiendum id="0">word-alignment algorithm</definiendum>
				<definiens id="0">consists of a pair of sentences E and F , and the dependency tree TE for E. TE allows us to make use of features and constraints that are based on linguistic intuitions</definiens>
			</definition>
			<definition id="4">
				<sentence>The second constraint , known as the cohesion constraint ( Fox , 2002 ) , uses the dependency tree ( Mel’ˇcuk , 1987 ) of the English sentence to restrict possible link combinations .</sentence>
				<definiendum id="0">cohesion constraint</definiendum>
				<definiens id="0">uses the dependency tree ( Mel’ˇcuk , 1987 ) of the English sentence to restrict possible link combinations</definiens>
			</definition>
			<definition id="5">
				<sentence>In fact , Melamed defines a probability distribution P ( links ( u , v ) |cooc ( u , v ) , λ+ , λ− ) which appears to make our work redundant .</sentence>
				<definiendum id="0">Melamed</definiendum>
				<definiens id="0">defines a probability distribution P ( links ( u , v ) |cooc ( u , v ) , λ+ , λ− ) which appears to make our work redundant</definiens>
			</definition>
			<definition id="6">
				<sentence>We are currently investigating maximum entropy as an alternative to our current feature model which assumes conditional independence among features .</sentence>
				<definiendum id="0">maximum entropy</definiendum>
				<definiens id="0">assumes conditional independence among features</definiens>
			</definition>
</paper>

		<paper id="1033">
			<definition id="0">
				<sentence>A spoken dialogue system is one of the promising applications of the speech recognition and natural language understanding technologies .</sentence>
				<definiendum id="0">spoken dialogue system</definiendum>
				<definiens id="0">one of the promising applications of the speech recognition and natural language understanding technologies</definiens>
			</definition>
			<definition id="1">
				<sentence>VWS ( Voice Web Server ) The Voice Web Server drives the speech recognition engine and the TTS ( Text-To-Speech ) module according to the specifications by the generated VoiceXML .</sentence>
				<definiendum id="0">VWS</definiendum>
				<definiendum id="1">Voice Web Server</definiendum>
				<definiens id="0">drives the speech recognition engine and the TTS ( Text-To-Speech ) module according to the specifications by the generated VoiceXML</definiens>
			</definition>
			<definition id="2">
				<sentence>Voice XML user TTS speech recognizer VoiceXML generator dialogue manager user profiles real bus information user model identifier CGI the system except for proposed user models Figure 2 : Overview of the bus system with user models based on specified grammar rules and vocabulary , which are defined by VoiceXML at each dialogue state .</sentence>
				<definiendum id="0">Voice XML user TTS speech recognizer VoiceXML generator dialogue manager user</definiendum>
				<definiens id="0">profiles real bus information user model identifier CGI the system except for proposed user models Figure 2 : Overview of the bus system with user models based on specified grammar rules and vocabulary</definiens>
			</definition>
			<definition id="3">
				<sentence>VoiceXML Generator This module dynamically generates VoiceXML files that contain response sentences and specifications of speech recognition grammars , which are given by the dialogue manager .</sentence>
				<definiendum id="0">VoiceXML</definiendum>
				<definiens id="0">files that contain response sentences and specifications of speech recognition grammars</definiens>
			</definition>
</paper>

		<paper id="2012">
			<definition id="0">
				<sentence>Those approaches require substantial processing : in the worst case one has to check a41a43a42a44a41a43a45a20a46a48a47 a49 candidate pairs , where a16 is the total number of markables found by the system .</sentence>
				<definiendum id="0">a16</definiendum>
				<definiens id="0">in the worst case one has to check a41a43a42a44a41a43a45a20a46a48a47 a49 candidate pairs</definiens>
				<definiens id="1">the total number of markables found by the system</definiens>
			</definition>
			<definition id="1">
				<sentence>In addition , an NP ( unknown to the reader in the very beginning ) is considered unique if it fully specifies its referent due to its own content only and thus can be added as it is ( maybe , for a very short time ) to the reader’s World knowledge base after the processing of the text , for example , ”John Smith , chief executive of John Smith Gmbh” or “the fact that John Smith is a chief executive of John Smith Gmbh” .</sentence>
				<definiendum id="0">NP</definiendum>
			</definition>
			<definition id="2">
				<sentence>The MUC-7 corpus consists of New York Times News Service articles .</sentence>
				<definiendum id="0">MUC-7 corpus</definiendum>
			</definition>
			<definition id="3">
				<sentence>is a noun phrase , a1 is the same noun phrase without a determiner , and a2 is its head .</sentence>
				<definiendum id="0">a1</definiendum>
				<definiens id="0">the same noun phrase without a determiner</definiens>
			</definition>
			<definition id="4">
				<sentence>This fact is partially reflected by the performance of our sequential classifier ( table 3 ) : the context information is not sufficient to determine whether a unique NP is a first-mention or not , one has to develop sophisticated names matching techniques instead .</sentence>
				<definiendum id="0">sequential classifier</definiendum>
				<definiens id="0">a first-mention or not</definiens>
			</definition>
</paper>

		<paper id="1037">
			<definition id="0">
				<sentence>Observe the huge number of passages with zero occurrences of his , which is ten times the number of passages with exactly one occurrence .</sentence>
				<definiendum id="0">Observe</definiendum>
				<definiens id="0">the huge number of passages with zero occurrences of his , which is ten times the number of passages with exactly one occurrence</definiens>
			</definition>
			<definition id="1">
				<sentence>prob 0.832 0.601 −logL ( ˆθ ) 441.585 439.596 Table 1 : Occurrence counts of his in Hamilton and Madison passages .</sentence>
				<definiendum id="0">Occurrence</definiendum>
			</definition>
</paper>

		<paper id="1055">
			<definition id="0">
				<sentence>Following the annotation guidelines ( Bies et al. , 1995 ) , we distinguish seven basic types of EEs : controlled NP-traces ( NP ) , PROs ( PRO ) , traces of Aa0 -movement ( mostly wh-movement : WH ) , empty complementizers ( COMP ) , empty units ( UNIT ) , and traces representing pseudo-attachments ( shared constituents , discontinuous dependencies , etc. : PSEUDO ) and ellipsis ( ELLIPSIS ) .</sentence>
				<definiendum id="0">controlled NP-traces</definiendum>
				<definiendum id="1">PROs ( PRO</definiendum>
			</definition>
			<definition id="1">
				<sentence>Thus , the question wi a6 X ; wia1 1 a6 X ; wia2 1 a6 X X is a prefix of wi , a3 X a3a5a4 4 X is a suffix of wi , a3 X a3a6a4 4 wi contains a number wi contains uppercase character wi contains hyphen lia1 1 a6 X posi a6 X ; posia1 1 a6 X ; posia2 1 a6 X posia1 1 posi a6 XY posia1 2 posia1 1 posi a6 XYZ posi posia2 1 a6 XY posi posia2 1 posia2 2 a6 XYZ Table 3 : Local features at position i a7 1 .</sentence>
				<definiendum id="0">X X</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">a prefix of wi</definiens>
				<definiens id="1">a suffix of wi , a3 X a3a6a4 4 wi contains a number wi contains uppercase character wi contains hyphen lia1 1 a6 X posi a6 X</definiens>
			</definition>
			<definition id="2">
				<sentence>The weighted linear combination of the features amount to the log-probability of the label ( l ) given the context ( c ) : pa8 la9 ca10a12a11 1Z a8 ca10 expa8 ∑i λi fia8 la13 ca10a14a10 ( 1 ) where Za8 ca10 is a context-dependent normalizing factor to ensure that pa8 la9 ca10 be a proper probability distribution .</sentence>
				<definiendum id="0">Za8 ca10</definiendum>
				<definiens id="0">a context-dependent normalizing factor to ensure</definiens>
			</definition>
</paper>

		<paper id="2041">
			<definition id="0">
				<sentence>An STSG is a collection of ( ordered ) pairs of aligned elementary trees .</sentence>
				<definiendum id="0">STSG</definiendum>
			</definition>
			<definition id="1">
				<sentence>The slurabove symbol denotes a frontier node of an elementary tree , which must be replaced by the circled root of another elementary tree .</sentence>
				<definiendum id="0">slurabove symbol</definiendum>
				<definiens id="0">a frontier node of an elementary tree , which must be replaced by the circled root of another elementary tree</definiens>
			</definition>
			<definition id="2">
				<sentence>So STSG ( unlike STAG ) has no real advantage for modeling string pairs.3 But STSGs can generate a wider variety of tree pairs , e.g. , non-isomorphic ones .</sentence>
				<definiendum id="0">STSG</definiendum>
				<definiens id="0">unlike STAG ) has no real advantage for modeling string pairs.3 But STSGs can generate a wider variety of tree pairs , e.g. , non-isomorphic ones</definiens>
			</definition>
			<definition id="3">
				<sentence>Most statistical MT derives from IBM-style models ( Brown et al. , 1993 ) , which ignore syntax and allow arbitrary word-to-word translation .</sentence>
				<definiendum id="0">IBM-style models</definiendum>
				<definiens id="0">ignore syntax and allow arbitrary word-to-word translation</definiens>
			</definition>
			<definition id="4">
				<sentence>An elementary tree is a a tuple 〈V , V i , E , lscript , q , s〉 where V is a set of nodes ; V i ⊆ V is the set of internal nodes , and we write V f = V −V i for the set of frontier nodes ; E ⊆ V i × V is a set of directed edges ( thus all frontier nodes are leaves ) .</sentence>
				<definiendum id="0">V</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">a set of nodes</definiens>
				<definiens id="1">the set of internal nodes , and we write V f = V −V i for the set of frontier nodes ; E ⊆ V i × V is a set of directed edges ( thus all frontier nodes are leaves )</definiens>
			</definition>
			<definition id="5">
				<sentence>The graph 〈V , E〉 must be connected and acyclic , and there must be exactly one node r ∈ V ( the root ) that has no incoming edges .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">the root ) that has no incoming edges</definiens>
			</definition>
			<definition id="6">
				<sentence>The function lscript : ( V i ∪E ) → L labels each internal node or edge ; q ∈ Q is the root state , and s : V f → Q assigns a frontier state to each frontier node ( perhaps including r ) .</sentence>
				<definiendum id="0">Q</definiendum>
				<definiens id="0">the root state , and s : V f → Q assigns a frontier state to each frontier node</definiens>
			</definition>
			<definition id="7">
				<sentence>A TSG is a set of elementary trees .</sentence>
				<definiendum id="0">TSG</definiendum>
			</definition>
			<definition id="8">
				<sentence>T.Eprime is a version of T.E in which d has been been replaced by t.r .</sentence>
				<definiendum id="0">T.Eprime</definiendum>
				<definiens id="0">a version of T.E in which d has been been replaced by t.r</definiens>
			</definition>
			<definition id="9">
				<sentence>The grammar constant is the number of possible fits to a node c of a fixed tree .</sentence>
				<definiendum id="0">grammar constant</definiendum>
				<definiens id="0">the number of possible fits to a node c of a fixed tree</definiens>
			</definition>
			<definition id="10">
				<sentence>A synchronous TSG consists of a set of elementary tree pairs .</sentence>
				<definiendum id="0">synchronous TSG</definiendum>
			</definition>
</paper>

		<paper id="2026">
			<definition id="0">
				<sentence>The Maximum Entropy ( ME ) model ( Jaynes 1957 ) is a general technique that is used to estimate the probability distributions of data .</sentence>
				<definiendum id="0">Maximum Entropy</definiendum>
				<definiens id="0">a general technique that is used to estimate the probability distributions of data</definiens>
			</definition>
			<definition id="1">
				<sentence>Eb : The word in the beginning of the part which should be replaced .</sentence>
				<definiendum id="0">Eb</definiendum>
				<definiens id="0">The word in the beginning of the part which should be replaced</definiens>
			</definition>
			<definition id="2">
				<sentence>Ebk : The word in the beginning of the part which should be replaced and which error category is k. Eek : The word in the middle or the end of the part which should be replaced and which error category is k. ( 1≦k≦N ) C : no need to be replaced ( =correct ) ↑ C ↑ C ↑ C ↑ Eb ↑ C ↑ C ↑ C ↑ C ↑ C ↑ C ↑ C ↑ C ↑ Ebk ↑ C ↑ C ↑ C ↑ C ↑ C We obtained data from 56 learners’ with error tags .</sentence>
				<definiendum id="0">Ebk</definiendum>
				<definiens id="0">The word in the beginning of the part</definiens>
			</definition>
</paper>

		<paper id="2033">
			<definition id="0">
				<sentence>Will is a browser of parsing results of grammars based on feature structures .</sentence>
				<definiendum id="0">Will</definiendum>
				<definiens id="0">a browser of parsing results of grammars based on feature structures</definiens>
			</definition>
			<definition id="1">
				<sentence>We developed a debug tool , willex , which uses XML tagged corpora and outputs information of grammar defects .</sentence>
				<definiendum id="0">willex</definiendum>
				<definiens id="0">uses XML tagged corpora and outputs information of grammar defects</definiens>
			</definition>
</paper>

		<paper id="1066">
			<definition id="0">
				<sentence>This paper presents a dependency language model ( DLM ) that captures linguistic constraints via a dependency structure , i.e. , a set of probabilistic dependencies that express the relations between headwords of each phrase in a sentence by an acyclic , planar , undirected graph .</sentence>
				<definiendum id="0">DLM</definiendum>
				<definiens id="0">a set of probabilistic dependencies that express the relations between headwords of each phrase in a sentence by an acyclic , planar , undirected graph</definiens>
			</definition>
			<definition id="1">
				<sentence>This paper presents a new dependency language model ( DLM ) that captures long distance linguistic constraints between words via a dependency structure , i.e. , a set of probabilistic dependencies that capture linguistic relations between headwords of each phrase in a sentence .</sentence>
				<definiendum id="0">DLM</definiendum>
				<definiens id="0">a set of probabilistic dependencies that capture linguistic relations between headwords of each phrase in a sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>The maximum likelihood estimation ( MLE ) of P ( d ij ) is given by ) , ( ) , , ( ) ( ji ji ij wwC RwwC dP = ( 4 ) where C ( w i , w j , R ) is the number of times w i and w j have a dependency relation in a sentence in training data , and C ( w i , w j ) is the number of times w i and w j are seen in the same sentence .</sentence>
				<definiendum id="0">MLE</definiendum>
				<definiens id="0">the number of times w i and w j have a dependency relation in a sentence in training data</definiens>
			</definition>
			<definition id="3">
				<sentence>The parsing algorithm is a slightly modified version of that proposed in Yuret ( 1998 ) .</sentence>
				<definiendum id="0">parsing algorithm</definiendum>
			</definition>
			<definition id="4">
				<sentence>Let the dependency probability be the measure of the strength of a dependency , i.e. , higher probabilities mean stronger dependencies .</sentence>
				<definiendum id="0">dependency probability</definiendum>
				<definiens id="0">the measure of the strength of a dependency , i.e. , higher probabilities mean stronger dependencies</definiens>
			</definition>
			<definition id="5">
				<sentence>Φ is a function that maps the history ( W j-1 , D j-1 ) onto equivalence classes .</sentence>
				<definiendum id="0">Φ</definiendum>
				<definiens id="0">a function that maps the history ( W j-1 , D j-1 ) onto equivalence classes</definiens>
			</definition>
			<definition id="6">
				<sentence>In particular , the probability of Equation ( 11 ) backs off to the estimate of P ( w j |R ) , which is computed as : N RwC RwP j j ) , ( ) | ( = , ( 14 ) where N is the total number of dependencies in training data , and C ( w j , R ) is the number of dependencies that contains w j .</sentence>
				<definiendum id="0">N</definiendum>
				<definiendum id="1">C ( w j</definiendum>
				<definiendum id="2">R )</definiendum>
				<definiens id="0">the probability of Equation ( 11 ) backs off to the estimate of P ( w j |R ) , which is computed as : N RwC RwP j j ) , ( ) |</definiens>
				<definiens id="1">the total number of dependencies in training data , and</definiens>
				<definiens id="2">the number of dependencies that contains w j</definiens>
			</definition>
			<definition id="7">
				<sentence>DLM_2 is the model where the headword probability is estimated by interpolating the word trigram probability , the headword bigram probability , and the probability given one previous linguistically related word in the dependency structure .</sentence>
				<definiendum id="0">DLM_2</definiendum>
				<definiens id="0">the model where the headword probability is estimated by interpolating the word trigram probability , the headword bigram probability</definiens>
			</definition>
			<definition id="8">
				<sentence>One basic approach to using linguistic structure for language modeling is to extend the conventional language model P ( W ) to P ( W , T ) , where T is a parse tree of W. The extended model can then be used as a parser to select the most likely parse by T * = argmax T P ( W , T ) .</sentence>
				<definiendum id="0">T</definiendum>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>Depending on the grammar and the empirical distribution of matching mother/lexical and daughter descriptions , this number could approach a2a4a3a6a5 copies for an edge added early to the chart , where a2 is the length of the input to be parsed .</sentence>
				<definiendum id="0">a2</definiendum>
				<definiens id="0">the length of the input to be parsed</definiens>
			</definition>
			<definition id="1">
				<sentence>The OVIS system ( van Noord , 1997 ) employs selective memoization , which tabulates only maximal projections in a head-corner parser — partial projections of a head are still recomputed .</sentence>
				<definiendum id="0">OVIS system</definiendum>
				<definiendum id="1">selective memoization</definiendum>
			</definition>
			<definition id="2">
				<sentence>Even in the handful of instances in which it does seem to have been successful , which includes the recent HPSG English Resource Grammar and a handful of Lexical-Functional Grammars , the results are by no means graceful , not at all modular , and arguably not reusable by anyone except their designers .</sentence>
				<definiendum id="0">Lexical-Functional Grammars</definiendum>
				<definiens id="0">includes the recent HPSG English Resource Grammar and a handful of</definiens>
			</definition>
			<definition id="3">
				<sentence>One is represented by a term chart ( E1 , ... , EL ) , where the a17 th argument holds the list of edges whose left node is a17 .</sentence>
				<definiendum id="0">E1 , ... , EL</definiendum>
				<definiens id="0">the list of edges whose left node is a17</definiens>
			</definition>
			<definition id="4">
				<sentence>Initialize Es to empty cats of grammar ; initialize Rs to rules of input grammar ; initialize the other four lists to [ ] ; loop : while Es =/= [ ] do for each E in Es do for each R in Rs do unify E with the leftmost unmatched category description of R ; if it does not match , continue ; if the leftmost category was rightmost ( unary rule ) , then add the new empty category to NEs otherwise , add the new rule ( with leftmost category marked as matched ) to NRs ; od od ; EAs : = append ( Es , EAs ) ; Rs : = append ( Rs , RAs ) ; RAs : = [ ] ; Es : = NEs ; NEs : = [ ] ; od ; if NRs = [ ] , then end : EAs are the closed empty cats , Rs are the closed rules else Es : = EAs ; EAs : = [ ] ; RAs : = Rs ; Rs : = NRs ; NRs : = [ ] go to loop Figure 1 : The off-line EFD-closure algorithm .</sentence>
				<definiendum id="0">Es , EAs</definiendum>
				<definiendum id="1">Rs</definiendum>
				<definiens id="0">the closed empty cats ,</definiens>
				<definiens id="1">the closed rules else Es : = EAs ; EAs : = [ ] ; RAs : = Rs ; Rs : = NRs</definiens>
			</definition>
			<definition id="5">
				<sentence>If the while-loop terminates ( see the next section ) , then the rules of Rs are stored in an accumulator , RAs , until the new rules , NRs , have had a chance to match their leftmost daughters against all of the empty categories that Rshas .</sentence>
				<definiendum id="0">NRs</definiendum>
				<definiens id="0">the rules of Rs are stored in an accumulator</definiens>
			</definition>
</paper>

		<paper id="2022">
			<definition id="0">
				<sentence>Decision Tree ( DT ) automatic algorithm C4.5 ( Quinlan , 1993 ; Weiss &amp; Kulikowski , 1991 ; Honda , Mochizuki , Ho &amp; Okumura , 1997 ; Passonneau &amp; Litman , 1997 ; Okumura , Haraguchi &amp; Mochizuki,1999 ) uses these data as learning data .</sentence>
				<definiendum id="0">Decision Tree</definiendum>
				<definiens id="0">uses these data as learning data</definiens>
			</definition>
			<definition id="1">
				<sentence>CONSIDERING TIME-SERIES VARIATION To judge the index of popularity of words with timeseries variation based on the frequency change , and create the stability classes of the words , we defined three classes as follow : ( 1 ) Increasing Class “The class that has an increasing frequency with time-series variation” ( 2 ) Relatively Constant Class “The class that has a stable frequency with time-series variation” ( 3 ) Decreasing Class “The class that has a decreasing frequency with time-series variation” .</sentence>
				<definiendum id="0">CONSIDERING TIME-SERIES VARIATION To</definiendum>
				<definiens id="0">judge the index of popularity of words with timeseries variation based on the frequency change , and create the stability classes of the words</definiens>
			</definition>
			<definition id="2">
				<sentence>Correlation coefficient is also a statistical method ( Gonick &amp; Smith , 1993 ) , and the calculation equation is shown as follows : In the above formula , are the predicted weights determined by regression line and α is the slope of the regression straight line .</sentence>
				<definiendum id="0">Correlation coefficient</definiendum>
				<definiens id="0">the predicted weights determined by regression line</definiens>
			</definition>
			<definition id="3">
				<sentence>Stability classes are defined as the index of popularity of words , and five attributes are defined to obtain the frequency change of words quantitatively .</sentence>
				<definiendum id="0">Stability classes</definiendum>
				<definiens id="0">the index of popularity of words , and five attributes are defined to obtain the frequency change of words quantitatively</definiens>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>B6 : [ It ] a3 ’s healthy , . . . A major problem for pronoun resolution in spoken dialogue is the large number of personal and demonstrative pronouns which are either not referential at all ( e.g. expletive pronouns ) or for which a particular antecedent can not easily be determined by humans ( called vague anaphors by Eckert &amp; Strube ( 2000 ) ) .</sentence>
				<definiendum id="0">B6</definiendum>
			</definition>
			<definition id="1">
				<sentence>A5 : [ Ita2 ] ’s not unique . . . Pronoun resolution in spoken dialogue also has to deal with the whole range of difficulties that come with processing spoken language : disfluencies , hesitations , abandoned utterances , interruptions , backchannels , etc .</sentence>
				<definiendum id="0">A5</definiendum>
				<definiendum id="1">Pronoun resolution</definiendum>
			</definition>
			<definition id="2">
				<sentence>The annotation consists of 16601 markables , i.e. sequences of words and attributes associated with them .</sentence>
				<definiendum id="0">annotation</definiendum>
			</definition>
			<definition id="3">
				<sentence>split , n , loss , yval * denotes terminal node ... anteexptype=s , vp 1110 55 N ananpform=prp 747,11 N * ananpform=dtpro 363 44 N anteexptype=vp 177 3 N * anteexptype=s 186 41 N udist &gt; =1.5 95 14 N * udist &lt; 1.5 91 27 N wdistic &lt; 43.32 33 4 N * wdistic &gt; =43.32 58 23 N anasdepth &gt; =2.5 23 4 N * anasdepth &lt; 2.5 35 16 N wdistic &gt; =63.62 24 11 N wdistic &lt; 80.60 12 3 N * wdistic &gt; =80.60 12 4 P * wdistic &lt; 63.62 11 3 P * Figure 1 : Decision Tree Fragment However , the most important problem is the large amount of pronouns without antecedents .</sentence>
				<definiendum id="0">yval *</definiendum>
				<definiens id="0">N wdistic &lt; 80.60 12 3 N * wdistic &gt; =80.60 12 4 P * wdistic &lt; 63.62 11 3 P * Figure 1 : Decision Tree Fragment However</definiens>
			</definition>
			<definition id="4">
				<sentence>Semantic filtering relies on knowledge about semantic restrictions associated with verbs , like semantic compatibility between subject and predicative noun or predicative adjective .</sentence>
				<definiendum id="0">Semantic filtering</definiendum>
				<definiens id="0">relies on knowledge about semantic restrictions associated with verbs , like semantic compatibility between subject and predicative noun or predicative adjective</definiens>
			</definition>
</paper>

		<paper id="1056">
</paper>

		<paper id="1009">
			<definition id="0">
				<sentence>The SCFs abstract over specific lexicallygoverned particles and prepositions and specific predicate selectional preferences but include some derived semi-predictable bounded dependency constructions , such as particle and dative movement .</sentence>
				<definiendum id="0">SCFs abstract</definiendum>
				<definiens id="0">over specific lexicallygoverned particles and prepositions and specific predicate selectional preferences but include some derived semi-predictable bounded dependency constructions , such as particle and dative movement</definiens>
			</definition>
			<definition id="1">
				<sentence>6The relevance of the features to the task is evident when comparing the probability of a randomly chosen pair of verbs verbi and verbj to share the same predominant sense ( 4.5 % ) with the probability obtained when verbj is the JS-divergence We chose two clustering methods which do not involve task-oriented tuning ( such as pre-fixed thresholds or restricted cluster sizes ) and which approach data straightforwardly , in its distributional form : ( i ) a simple hard method that collects the nearest neighbours ( NN ) of each verb ( figure 1 ) , and ( ii ) the Information Bottleneck ( IB ) , an iterative soft method ( Tishby et al. , 1999 ) based on information-theoretic grounds .</sentence>
				<definiendum id="0">iterative soft method</definiendum>
				<definiens id="0">evident when comparing the probability of a randomly chosen pair of verbs verbi and verbj to share the same predominant sense</definiens>
				<definiens id="1">the JS-divergence We chose two clustering methods which do not involve task-oriented tuning ( such as pre-fixed thresholds or restricted cluster sizes ) and which approach data straightforwardly , in its distributional form : ( i ) a simple hard method that collects the nearest neighbours</definiens>
			</definition>
			<definition id="2">
				<sentence>through minimizing the cost term : L = I ( Clusters ; V erbs ) −βI ( Clusters ; SCFs ) , where β is a parameter that balances the constraints .</sentence>
				<definiendum id="0">V erbs</definiendum>
				<definiendum id="1">SCFs</definiendum>
				<definiendum id="2">β</definiendum>
				<definiens id="0">a parameter that balances the constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>The collection of all p ( S|K ) ’s for a fixed cluster K can be regarded as a probabilistic center ( centroid ) of that cluster in the SCF space .</sentence>
				<definiendum id="0">collection of all p</definiendum>
				<definiens id="0">a probabilistic center ( centroid ) of that cluster in the SCF space</definiens>
			</definition>
			<definition id="4">
				<sentence>The IB method gives an indication of the most informative values of K.7 Intensifying the weight β attached to the relevance information I ( Clusters ; SCFs ) allows us to increase the number K of distinct clusters being produced ( while too small β would cause some of the output clusters to be identical to one another ) .</sentence>
				<definiendum id="0">IB method</definiendum>
				<definiendum id="1">SCFs</definiendum>
				<definiens id="0">gives an indication of the most informative values of K.7 Intensifying the weight β attached to the relevance information I ( Clusters ;</definiens>
			</definition>
			<definition id="5">
				<sentence>Let K ( V ) = argmax K p ( K|V ) denote the most probable cluster of a verb V .</sentence>
				<definiendum id="0">K ( V</definiendum>
				<definiens id="0">the most probable cluster of a verb V</definiens>
			</definition>
			<definition id="6">
				<sentence>APP is the average proportion of all within-cluster pairs that are correctly co-assigned .</sentence>
				<definiendum id="0">APP</definiendum>
				<definiens id="0">the average proportion of all within-cluster pairs that are correctly co-assigned</definiens>
			</definition>
			<definition id="7">
				<sentence>K +PP –PP +PP –PP APP : mPUR : NN ( 24 ) 21 % 19 % 48 % 45 % 25 12 % 9 % 39 % 32 % IB 35 14 % 9 % 48 % 38 % 42 15 % 9 % 50 % 39 % RAND 25 3 % 15 % Table 2 : Clustering performance on the predominant senses , with and without prepositions .</sentence>
				<definiendum id="0">K +PP –PP +PP –PP APP</definiendum>
				<definiens id="0">Clustering performance on the predominant senses , with and without prepositions</definiens>
			</definition>
</paper>

		<paper id="1054">
			<definition id="0">
				<sentence>In the early 1990s , as probabilistic methods swept NLP , parsing work revived the investigation of probabilistic context-free grammars ( PCFGs ) ( Booth and Thomson , 1973 ; Baker , 1979 ) .</sentence>
				<definiendum id="0">PCFGs )</definiendum>
				<definiens id="0">probabilistic methods swept NLP , parsing work revived the investigation of probabilistic context-free grammars</definiens>
			</definition>
			<definition id="1">
				<sentence>The Penn treebank covering PCFG is a poor tool for parsing because the context-freedom assumptions it embodies are far too strong , and weakening them in this way makes the model much better .</sentence>
				<definiendum id="0">Penn treebank covering PCFG</definiendum>
				<definiens id="0">a poor tool for parsing because the context-freedom assumptions it embodies are far too strong</definiens>
			</definition>
			<definition id="2">
				<sentence>The UNARY-DT annotation , for example , showed that the determiners which occur alone are usefully distinguished from those which occur with other nominal material .</sentence>
				<definiendum id="0">UNARY-DT annotation</definiendum>
				<definiens id="0">for example , showed that the determiners which occur alone are usefully distinguished from those which occur with other nominal material</definiens>
			</definition>
</paper>

		<paper id="2034">
</paper>

		<paper id="1061">
			<definition id="0">
				<sentence>The CSJ is a collection of monologues and dialogues , the majority being monologues such as academic presentations and simulated public speeches .</sentence>
				<definiendum id="0">CSJ</definiendum>
				<definiens id="0">a collection of monologues</definiens>
			</definition>
			<definition id="1">
				<sentence>The CSJ includes transcriptions of the speeches as well as audio recordings of them .</sentence>
				<definiendum id="0">CSJ</definiendum>
			</definition>
			<definition id="2">
				<sentence>( 1 ) : p λ ( a|b ) = exp parenleftBig summationtext i , j λ i , j g i , j ( a , b ) parenrightBig Z λ ( b ) ( 1 ) Short word Long word Word Pronunciation POS Others Word Pronunciation POS Others 6 ( form ) ���� ( keitai ) Noun 6 �r s ( morphological analysis ) �������� � ( keitaisokaiseki ) Noun � ( element ) � ( so ) Suffix r s ( analysis ) ���� ( kaiseki ) Noun t� ( ni ) PPP case markertmMo ( about ) ���� ( nitsuite ) PPP case marker , compound word mM ( relate ) �� ( tsui ) Verb KA-GYO , ADF , euphonic change o� ( te ) PPP conjunctive S� ( o ) PrefixS�`Mh` ( talk ) ������� ( ohanashiitasi ) Verb SA-GYO , ADF �` ( talk ) ��� ( hanashi ) Verb SA-GYO , ADF Mh` ( do ) ��� ( itashi ) Verb SA-GYO , ADF �b�� ( masu ) AUX ending form�b�� ( masu ) AUX ending form PPP : post-positional particle , AUX : auxiliary verb , ADF : adverbial form Figure 2 : Example of morphological analysis results .</sentence>
				<definiendum id="0">Verb SA-GYO , ADF �`</definiendum>
				<definiendum id="1">Verb SA-GYO , ADF Mh`</definiendum>
				<definiendum id="2">AUX</definiendum>
				<definiens id="0">auxiliary verb</definiens>
			</definition>
			<definition id="3">
				<sentence>, and Z λ ( b ) is a normalizing constant determined by the requirement that summationtext a p λ ( a|b ) =1for all b. The computation of p λ ( a|b ) in any ME model is dependent on a set of “features” which are binary functions of the history and future .</sentence>
				<definiendum id="0">Z λ ( b )</definiendum>
				<definiens id="0">a normalizing constant determined by the requirement that summationtext a p λ ( a|b ) =1for all b. The computation of p λ</definiens>
			</definition>
			<definition id="4">
				<sentence>The middle division of the consequent part represents a long word “o�” ( auxiliary verb ) , and it consists of two short words “o” ( post-positional particle ) and “�” ( verb ) .</sentence>
				<definiendum id="0">middle division of the consequent part</definiendum>
				<definiens id="0">auxiliary verb ) , and it consists of two short words “o” ( post-positional particle ) and “�” ( verb )</definiens>
			</definition>
			<definition id="5">
				<sentence>Each feature consists of a type and a value , which are given in the rows of the table , and it corresponds to j in the function g i , j ( a , b ) in Eq .</sentence>
				<definiendum id="0">feature</definiendum>
				<definiens id="0">consists of a type and a value , which are given in the rows of the table , and it corresponds to j in the function g i , j ( a , b ) in Eq</definiens>
			</definition>
			<definition id="6">
				<sentence>Recall is the percentage of morphemes in the test corpus for which the segmentation and major POS category were identified correctly .</sentence>
				<definiendum id="0">Recall</definiendum>
				<definiens id="0">the percentage of morphemes in the test corpus for which the segmentation and major POS category were identified correctly</definiens>
			</definition>
			<definition id="7">
				<sentence>Precision is the percentage of all morphemes identified by the system that were identified correctly .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the percentage of all morphemes identified by the system that were identified correctly</definiens>
			</definition>
			<definition id="8">
				<sentence>A compound word is defined as one word when it is based on the definition of long words ; however it is defined as two or more words when it is based on the definition of short words .</sentence>
				<definiendum id="0">compound word</definiendum>
				<definiens id="0">one word when it is based on the definition of long words ; however it is defined as two or more words when it is based on the definition of short words</definiens>
			</definition>
</paper>

		<paper id="2040">
			<definition id="0">
				<sentence>TotalRecall comes with an additional feature making the solution more easily recognized .</sentence>
				<definiendum id="0">TotalRecall</definiendum>
			</definition>
			<definition id="1">
				<sentence>TotalRecall extends the translation memory technology and provide an interactive tool intended for translators and non-native speakers trying to find ideas to properly express themselves .</sentence>
				<definiendum id="0">TotalRecall</definiendum>
			</definition>
			<definition id="2">
				<sentence>Central to TotalRecall is a bilingual corpus and a set of programs that provide the bilingual analyses to yield a translation memory database out of the bilingual corpus .</sentence>
				<definiendum id="0">TotalRecall</definiendum>
				<definiens id="0">a bilingual corpus and a set of programs that provide the bilingual analyses to yield a translation memory database out of the bilingual corpus</definiens>
			</definition>
			<definition id="3">
				<sentence>Once a query is submitted , TotalRecall displays the results on Web pages .</sentence>
				<definiendum id="0">TotalRecall</definiendum>
			</definition>
			<definition id="4">
				<sentence>Currently , TotalRecall uses Sinorama Magazine corpus as the translation memory and will be continuously updated as new issues of the magazine becomes available .</sentence>
				<definiendum id="0">TotalRecall</definiendum>
				<definiens id="0">uses Sinorama Magazine corpus as the translation memory</definiens>
			</definition>
</paper>

		<paper id="2027">
			<definition id="0">
				<sentence>Then sentence score is normalized by the maximum matching score ( MMS ) of both sentences as follows ( the MMS is the sentence score with itself ) : B4sentence scoreB5 BE AI the MMS of a user question AJ A2 AI the MMS of a text sentence AJ 1 Bunsetsu is a commonly used linguistic unit in Japanese , consisting of one or more adjoining content words and zero or more following functional words .</sentence>
				<definiendum id="0">maximum matching score</definiendum>
				<definiendum id="1">MMS</definiendum>
				<definiendum id="2">Bunsetsu</definiendum>
				<definiens id="0">the sentence score with itself ) : B4sentence scoreB5 BE AI the MMS of a user question AJ A2 AI the MMS of a text sentence AJ 1</definiens>
				<definiens id="1">a commonly used linguistic unit in Japanese , consisting of one or more adjoining content words and zero or more following functional words</definiens>
			</definition>
			<definition id="1">
				<sentence>Significance for retrieval is defined as a rate of disagreement of five high-scored retrieved texts among C6 recognition candidates .</sentence>
				<definiendum id="0">Significance for retrieval</definiendum>
				<definiens id="0">a rate of disagreement of five high-scored retrieved texts among C6 recognition candidates</definiens>
			</definition>
</paper>

		<paper id="1063">
			<definition id="0">
				<sentence>Since the memory-based learning is an efficient method to handle exceptions in natural language processing , it is good at checking whether the estimates are exceptional cases of the rules and revising them .</sentence>
				<definiendum id="0">memory-based learning</definiendum>
			</definition>
			<definition id="1">
				<sentence>To determine the chunk type of a word w i , the lexicons , POS tags , and chunk types of surrounding words are used .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">tags , and chunk types of surrounding words are used</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>Information Extraction ( IE ) is the process of identifying events or actions of interest and their participating entities from a text .</sentence>
				<definiendum id="0">Information Extraction</definiendum>
				<definiendum id="1">IE</definiendum>
				<definiens id="0">the process of identifying events or actions of interest and their participating entities from a text</definiens>
			</definition>
			<definition id="1">
				<sentence>2Throughout this paper , extraction patterns are defined as one or more word classes with their context in the dependency tree , where the actual word matched with the class is associated to one of the slots in the template .</sentence>
				<definiendum id="0">extraction patterns</definiendum>
				<definiens id="0">one or more word classes with their context in the dependency tree</definiens>
			</definition>
			<definition id="2">
				<sentence>The labels introduced in this paper are SBJ ( subject ) , OBJ ( object ) , ADV ( adverbial adjunct ) , REL ( relative ) , APPOS ( apposition ) and prepositions ( IN , OF , etc. ) .</sentence>
				<definiendum id="0">OBJ</definiendum>
				<definiendum id="1">REL ( relative</definiendum>
				<definiens id="0">( object ) , ADV ( adverbial adjunct )</definiens>
			</definition>
			<definition id="3">
				<sentence>( b ) ( c ) Predicate-Argument Chain model ( triggered ( a17 C-PERSONa18 -SBJ ) ( explosion-OBJ ) ( a17 C-DATEa18 -ADV ) ) ( triggered ( a17 C-PERSONa18 -SBJ ) ) ( killing ( a17 C-PERSONa18 -OBJ ) ) ( triggered ( heart-IN ( a17 C-LOCATIONa18 -OF ) ) ) ( injuring ( a17 C-PERSONa18 -OBJ ) ) ( triggered ( killing-ADV ( a17 C-PERSONa18 -OBJ ) ) ) ( triggered ( injuring-ADV ( a17 C-PERSONa18 -OBJ ) ) ) ( triggered ( a17 C-DATEa18 -ADV ) ) ( d ) Subtree model ( triggered ( a17 C-PERSONa18 -SBJ ) ( explosion-OBJ ) ) ( triggered ( explosion-OBJ ) ( a17 C-DATEa18 -ADV ) ) ( killing ( a17 C-PERSONa18 -OBJ ) ) ( triggered ( a17 C-DATEa18 -ADV ) ( killing-ADV ) ) ( injuring ( a17 C-PERSONa18 -OBJ ) ) ( triggered ( a17 C-DATEa18 -ADV ) ( killing-ADV ( a17 C-PERSONa18 -OBJ ) ) ) ( triggered ( heart-IN ( a17 C-LOCATIONa18 -OF ) ) ) ( triggered ( a17 C-DATEa18 -ADV ) ( injuring-ADV ) ) ( triggered ( killing-ADV ( a17 C-PERSONa18 -OBJ ) ) ) ( triggered ( explosion-OBJ ) ( killing ( a17 C-PERSONa18 -OBJ ) ) ) ( triggered ( a17 C-DATEa18 -ADV ) ) ... Figure 1 : ( a ) Example sentence on terrorism scenario .</sentence>
				<definiendum id="0">-ADV ) ( injuring-ADV ) ) ( triggered ( killing-ADV</definiendum>
				<definiens id="0">killing ( a17 C-PERSONa18 -OBJ ) ) ( triggered ( heart-IN ( a17 C-LOCATIONa18 -OF ) ) ) ( injuring ( a17 C-PERSONa18 -OBJ ) ) ( triggered ( killing-ADV ( a17 C-PERSONa18 -OBJ ) ) ) ( triggered ( injuring-ADV ( a17 C-PERSONa18 -OBJ ) ) ) ( triggered ( a17 C-DATEa18 -ADV ) ) ( d ) Subtree model ( triggered ( a17 C-PERSONa18 -SBJ ) ( explosion-OBJ ) ) ( triggered ( explosion-OBJ ) ( a17 C-DATEa18 -ADV ) ) ( killing ( a17 C-PERSONa18 -OBJ ) ) ( triggered ( a17 C-DATEa18 -ADV ) ( killing-ADV ) ) ( injuring ( a17 C-PERSONa18 -OBJ ) ) ( triggered ( a17 C-DATEa18 -ADV ) ( killing-ADV ( a17 C-PERSONa18 -OBJ ) ) ) ( triggered ( heart-IN ( a17 C-LOCATIONa18 -OF ) ) ) ( triggered ( a17 C-DATEa18</definiens>
				<definiens id="1">triggered ( explosion-OBJ ) ( killing ( a17 C-PERSONa18 -OBJ ) ) ) ( triggered ( a17 C-DATEa18 -ADV ) ) ... Figure 1 : ( a ) Example sentence on terrorism scenario</definiens>
			</definition>
			<definition id="4">
				<sentence>The right-most expansion base subtree discovery algorithm ( Abe et al. , 2002 ) was implemented to calculate term frequency ( raw frequency of a pattern ) and document frequency ( the number of documents where a pattern appears ) for each pattern candidate .</sentence>
				<definiendum id="0">document frequency</definiendum>
				<definiens id="0">the number of documents where a pattern appears ) for each pattern candidate</definiens>
			</definition>
			<definition id="5">
				<sentence>The score of subtree a0 , a1a3a2a5a4a7a6a9a8a11a10 , is a1a3a2a5a4a7a6a9a8 a10a13a12a15a14a17a16a7a10a19a18a21a20a9a22a24a23a26a25a28a27 a29 a16a7a10a31a30a33a32 ( 1 ) where a14a17a16a7a10 is the number of times that subtree a0 appears across the documents in the relevant document set , a34 .</sentence>
				<definiendum id="0">a14a17a16a7a10</definiendum>
				<definiens id="0">the number of times that subtree a0 appears across the documents in the relevant document set , a34</definiens>
			</definition>
			<definition id="6">
				<sentence>a35a13a36 is the set of subtrees that appear in a34 .</sentence>
				<definiendum id="0">a35a13a36</definiendum>
				<definiens id="0">the set of subtrees that appear in a34</definiens>
			</definition>
			<definition id="7">
				<sentence>a29 a16 a10 is the number of documents in the collection containing subtree a0 , and a27 is the total number of the dependency tree as a bunsetsu , phrasal unit .</sentence>
				<definiendum id="0">a27</definiendum>
				<definiens id="0">the number of documents in the collection containing subtree a0 , and</definiens>
				<definiens id="1">the total number of the dependency tree as a bunsetsu , phrasal unit</definiens>
			</definition>
</paper>

		<paper id="1059">
			<definition id="0">
				<sentence>Grammatical countability is motivated by the semantic distinction between object and substance reference ( also known as bounded/non-bounded or individuated/non-individuated ) .</sentence>
				<definiendum id="0">Grammatical countability</definiendum>
			</definition>
			<definition id="1">
				<sentence>Bond and Vatikiotis-Bateson ( 2002 ) determine a noun’s countability preferences from its semantic class , and show that semantics predicts ( 5-way ) countability 78 % of the time with their ontology .</sentence>
				<definiendum id="0">Bond</definiendum>
			</definition>
</paper>

		<paper id="2003">
			<definition id="0">
				<sentence>A Linear Indexed Grammar is a 5-tuple ( V ; T ; I ; P ; S ) , where V is the set of variables , T the set of terminals , I the set of indices , S in V is the start symbol , and P is a finite set of productions of the form , where A ; B 2 V , fi ; 2 ( V [ T ) ⁄ , i 2 I : a. A [ : : ] !</sentence>
				<definiendum id="0">Linear Indexed Grammar</definiendum>
				<definiendum id="1">V</definiendum>
				<definiendum id="2">P</definiendum>
				<definiens id="0">a 5-tuple ( V</definiens>
				<definiens id="1">the set of variables , T the set of terminals , I the set of indices</definiens>
				<definiens id="2">the start symbol</definiens>
			</definition>
			<definition id="1">
				<sentence>Definition 1 A GIG is a 6-tuple G = ( N ; T ; I ; S ; # ; P ) where N ; T ; I are finite pairwise disjoint sets and 1 ) N are non-terminals 2 ) T are terminals 3 ) I a set of stack indices 4 ) S 2 N is the start symbol 5 ) # is the start stack symbol ( not in I , N , T ) and 6 ) P is a finite set of productions , having the following form,5 where 5The notation in the rules makes explicit that operation on the stack is associated to the production and neither to terminals nor to non-terminals .</sentence>
				<definiendum id="0">GIG</definiendum>
				<definiendum id="1">P</definiendum>
				<definiens id="0">a 6-tuple G = ( N ; T ; I ; S ; # ; P ) where N</definiens>
				<definiens id="1">the start stack symbol ( not in I</definiens>
			</definition>
			<definition id="2">
				<sentence>[ c , b , a ] Figure 1 : A non context-free structural description for the language wwR ( Gazdar , 1988 ) Gazdar suggests that such configuration would be necessary to represent Scandinavian 6Unambiguous indexing should be understood as those grammars that produce for each string in the language a unique indexing derivation .</sentence>
				<definiendum id="0">wwR</definiendum>
				<definiens id="0">A non context-free structural description for the language</definiens>
				<definiens id="1">those grammars that produce for each string in the language a unique indexing derivation</definiens>
			</definition>
			<definition id="3">
				<sentence>In D. Dowty , L. Karttunen , and A. Zwicky , editors , Natural language processing : psycholinguistic , computational and theoretical perspectives , pages 206–250 .</sentence>
				<definiendum id="0">Natural language processing</definiendum>
				<definiens id="0">psycholinguistic , computational and theoretical perspectives</definiens>
			</definition>
</paper>

		<paper id="1036">
			<definition id="0">
				<sentence>Morphemes are the smallest meaning-bearing elements of language and could be used as lexical units instead of entire words .</sentence>
				<definiendum id="0">Morphemes</definiendum>
				<definiens id="0">the smallest meaning-bearing elements of language</definiens>
			</definition>
			<definition id="1">
				<sentence>The probability of each character cj is the maximum likelihood estimate of the occurrence of this character in the corpus:4 p ( cj ) = ncjsummationtext k nck , ( 3 ) where ncj is the number of occurrences of the character cj in the corpus , and summationtextk nck is the total number of characters in the corpus .</sentence>
				<definiendum id="0">probability of each character cj</definiendum>
				<definiendum id="1">ncj</definiendum>
				<definiendum id="2">summationtextk nck</definiendum>
				<definiens id="0">the maximum likelihood estimate of the occurrence of this character in the corpus:4 p ( cj ) = ncjsummationtext k nck</definiens>
				<definiens id="1">the number of occurrences of the character cj in the corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>( 9 ) The numerator of the multinomial is the factorial of the total number of morph tokens , N , which equals the sum of frequencies of every morph type .</sentence>
				<definiendum id="0">multinomial</definiendum>
				<definiens id="0">the factorial of the total number of morph tokens , N , which equals the sum of frequencies of every morph type</definiens>
			</definition>
			<definition id="3">
				<sentence>The Finnish data consists of subsets of a newspaper text corpus from CSC,12 from which nonwords ( numbers and punctuation marks ) have been 9In ( Creutz and Lagus , 2002 ) the results are reported less intuitively as the “alignment distance” , i.e. , the negative logprob of the entire test set : −logproducttextpi ( morpheme |morph ) .</sentence>
				<definiendum id="0">Finnish data</definiendum>
				<definiens id="0">consists of subsets of a newspaper text corpus from CSC,12 from which nonwords ( numbers and punctuation marks</definiens>
				<definiens id="1">the negative logprob of the entire test set : −logproducttextpi ( morpheme |morph )</definiens>
			</definition>
</paper>

		<paper id="1052">
</paper>

		<paper id="1071">
			<definition id="0">
				<sentence>The test shows that the interjudge reliability is significant to the 0.05 level for 19 of the meetings , which seems to indicate that segment identification is a feasible task.2 Previous work on discourse segmentation of written texts indicates that lexical cohesion is a strong indicator of discourse structure .</sentence>
				<definiendum id="0">segment identification</definiendum>
				<definiens id="0">seems to indicate that</definiens>
			</definition>
			<definition id="1">
				<sentence>Lexical cohesion is a linguistic property that pertains to speech as well , and is a linguistic phenomenon that can also be exploited in our case : while our data does not have the same kind of syntactic and rhetorical structure as written text , we nonetheless expect that information from the written transcription alone should provide indications about topic boundaries .</sentence>
				<definiendum id="0">Lexical cohesion</definiendum>
				<definiens id="0">a linguistic property that pertains to speech as well , and is a linguistic phenomenon that can also be exploited in our case</definiens>
			</definition>
			<definition id="2">
				<sentence>A term is any stemmed content word within the text .</sentence>
				<definiendum id="0">term</definiendum>
			</definition>
			<definition id="3">
				<sentence>If R1 ... Rn is the set of all term repetitions collected in the text , t1 ... tn the corresponding terms , L1 ... Ln their respective lengths,4 and L the length of the text , the adapted metric is expressed as follows , combining frequency ( freq ( ti ) ) of a term ti and the compactness of its underlying chain : score ( Ri ) = freq ( ti ) ·log ( LLi ) 3The latter parameter might seem controversial at first , and one might assume that longer chains should receive a higher score .</sentence>
				<definiendum id="0">Rn</definiendum>
				<definiens id="0">the set of all term repetitions collected in the text , t1 ... tn the corresponding terms , L1 ... Ln their respective lengths,4 and L the length of the text , the adapted metric is expressed as follows , combining frequency ( freq ( ti ) ) of a term ti</definiens>
			</definition>
			<definition id="4">
				<sentence>The similarity between windows ( A and B ) is computed with:5 cosine ( A , B ) = summationtext i wi , A·wi , BradicalBigsummationtext i w 2 i , A summationtext i w 2 i , B where wi , Γ = braceleftBigg score ( Ri ) if Ri overlaps Γ ∈ { A , B } 0 otherwise The similarity computed at each sentence break produces a plot that shows how lexical cohesion changes over time ; an example is shown in Figure 1 .</sentence>
				<definiendum id="0">similarity between windows</definiendum>
				<definiens id="0">produces a plot that shows how lexical cohesion changes over time</definiens>
			</definition>
			<definition id="5">
				<sentence>A pause is a silence that is attributable to a given party , for example in the middle of an adjacency pair , or when a speaker pauses in the middle of her speech .</sentence>
				<definiendum id="0">pause</definiendum>
			</definition>
			<definition id="6">
				<sentence>The two distributions are normalized to form two probability distributions l and r , and significant changes of speakership are detected by computing their Jensen-Shannon divergence : JS ( l , r ) = 12 [ D ( l||avgl , r ) + D ( r||avgl , r ) ] where D ( l||r ) is the KL-divergence between the two distributions .</sentence>
				<definiendum id="0">Jensen-Shannon divergence</definiendum>
				<definiens id="0">the KL-divergence between the two distributions</definiens>
			</definition>
</paper>

		<paper id="2005">
			<definition id="0">
				<sentence>The MMIF receives semantic information in the form of typed feature structures ( Carpenter , 1992 ) from the individual modalities .</sentence>
				<definiendum id="0">MMIF</definiendum>
				<definiens id="0">receives semantic information in the form of typed feature structures</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>In dictionary-based methods ( e.g. Cheng et al. , 1999 ) , given an input character string , only words that are stored in the dictionary can be identified .</sentence>
				<definiendum id="0">dictionary-based methods</definiendum>
				<definiens id="0">given an input character string , only words that are stored in the dictionary can be identified</definiens>
			</definition>
			<definition id="1">
				<sentence>• For morphologically derived words , their morphological patterns are detected , e.g. 朋友 们 ‘friend+s’ is derived by affixation of the plural affix 们 to the noun 朋友 ( MA_S indicates a suffixation pattern ) , and 高高兴兴 ‘happily’ is a reduplication of 高兴 ‘happy’ ( MR_AABB indicates an AABB reduplication pattern ) .</sentence>
				<definiendum id="0">MA_S</definiendum>
			</definition>
			<definition id="2">
				<sentence>• For factoids , their types and normalized forms are detected , e.g. 12:30 is the normalized form of the time expression 十二点三十 分 ( TIME indicates a time expression ) .</sentence>
				<definiendum id="0">TIME</definiendum>
				<definiens id="0">the normalized form of the time expression 十二点三十 分</definiens>
				<definiens id="1">indicates a time expression )</definiens>
			</definition>
			<definition id="3">
				<sentence>The source-channel models can be interpreted in another way as follows : P ( C ) is a stochastic model estimating the probability of word class sequence .</sentence>
				<definiendum id="0">source-channel models</definiendum>
				<definiens id="0">a stochastic model estimating the probability of word class sequence</definiens>
			</definition>
			<definition id="4">
				<sentence>P ( S|C ) is a generative model estimating how likely a character string is generated given a word class .</sentence>
				<definiendum id="0">P ( S|C )</definiendum>
				<definiens id="0">a generative model estimating how likely a character string is generated given a word class</definiens>
			</definition>
			<definition id="5">
				<sentence>These class models are defined as generative models which are respectively estimated on their corresponding named entity lists using maximum likelihood estimation ( MLE ) , together with smoothing methods 4 .</sentence>
				<definiendum id="0">MLE</definiendum>
				<definiens id="0">generative models which are respectively estimated on their corresponding named entity lists using maximum likelihood estimation</definiens>
			</definition>
			<definition id="6">
				<sentence>( 1 ) PN patterns : We assume that a Chinese PN consists of a family name F and a given name G , and is of the pattern F+G .</sentence>
				<definiendum id="0">PN patterns</definiendum>
				<definiens id="0">consists of a family name F and a given name G , and is of the pattern F+G</definiens>
			</definition>
			<definition id="7">
				<sentence>The probability P ( S’|LN ) is computed by a character bigram model .</sentence>
				<definiendum id="0">probability P ( S’|LN</definiendum>
				<definiens id="0">computed by a character bigram model</definiens>
			</definition>
			<definition id="8">
				<sentence>5 For a better understanding , the constraint is a simplified version of that used in our system .</sentence>
				<definiendum id="0">constraint</definiendum>
			</definition>
			<definition id="9">
				<sentence>Assuming that C * = LN/国际/航空/公司 , where 中国 is tagged as a LN , the probability P ( S’|ON ) would be estimated using a word class bigram model as : P ( 中国国际航空公司 |ON ) ≈ P ( LN/国际/航空/公司|ON ) P ( 中国|LN ) = P ( LN| &lt; ON &gt; ) P ( 国际|LN ) P ( 航空|国际 ) P ( 公司|航空 ) P ( &lt; N &gt; |公司 ) P ( 中国|LN ) , where P ( 中国|LN ) is the class model probability of 中国 given that it is a LN , &lt; ON &gt; and &lt; N &gt; are symbols denoting the beginning and the end of a ON , respectively .</sentence>
				<definiendum id="0">probability P</definiendum>
				<definiendum id="1">P ( 中国|LN )</definiendum>
				<definiens id="0">symbols denoting the beginning and the end of a ON , respectively</definiens>
			</definition>
			<definition id="10">
				<sentence>Therefore , an FN candidate would be generated given S’ , if it contains only characters stored in a transliterated name character list ( which contains 618 Chinese characters ) .</sentence>
				<definiendum id="0">FN candidate</definiendum>
				<definiens id="0">contains only characters stored in a transliterated name character list ( which contains 618 Chinese characters )</definiens>
			</definition>
			<definition id="11">
				<sentence>The probability P ( S’|FN ) is estimated using a character bigram model .</sentence>
				<definiendum id="0">probability P ( S’|FN</definiendum>
				<definiens id="0">estimated using a character bigram model</definiens>
			</definition>
			<definition id="12">
				<sentence>Our experiments show that a relatively small seed set ( e.g. , 10 million characters , which takes approximately three weeks for 4 persons to annotate the NE tags ) is enough to get a good improved context model for initialization .</sentence>
				<definiendum id="0">million characters</definiendum>
				<definiens id="0">takes approximately three weeks for 4 persons to annotate the NE tags ) is enough to get a good improved context model for initialization</definiens>
			</definition>
			<definition id="13">
				<sentence>The annotated test set contains in total 247,039 tokens ( including 205,162 lexicon/morph-lexicon words , 4,347 PNs , 5,311 LNs , 3,850 ONs , and 6,630 factoids , etc. ) Our system is measured through multiple precision-recall ( P/R ) pairs , and F-measures ( F β=1 , which is defined as 2PR/ ( P+R ) ) for each word class .</sentence>
				<definiendum id="0">annotated test set</definiendum>
				<definiendum id="1">F-measures</definiendum>
				<definiendum id="2">F β=1</definiendum>
				<definiens id="0">contains in total 247,039 tokens ( including 205,162 lexicon/morph-lexicon words , 4,347 PNs , 5,311 LNs , 3,850 ONs , and 6,630 factoids , etc. ) Our system is measured through multiple precision-recall ( P/R ) pairs</definiens>
			</definition>
</paper>

		<paper id="2025">
			<definition id="0">
				<sentence>CLIR consists of retrieving documents written in one language using queries written in another language .</sentence>
				<definiendum id="0">CLIR</definiendum>
				<definiens id="0">consists of retrieving documents written in one language using queries written in another language</definiens>
			</definition>
			<definition id="1">
				<sentence>Linguistic Preprocessing WWW NTCIR Test Collection Comparable Corpora Morphological Analysis Interactive Mode Figure 1 : The Overall Design of the Proposed Model for Bilingual Terminology Acquisition and Phrasal Translation in CLIR As well , a target language morphological analysis will assign POS tags to the translation candidates .</sentence>
				<definiendum id="0">Linguistic Preprocessing WWW NTCIR Test Collection Comparable Corpora</definiendum>
				<definiens id="0">The Overall Design of the Proposed Model for Bilingual Terminology Acquisition and Phrasal Translation in CLIR</definiens>
			</definition>
</paper>

		<paper id="1048">
			<definition id="0">
				<sentence>Automatic document summarization is a field that has seen increasing attention from the NLP community in recent years .</sentence>
				<definiendum id="0">Automatic document summarization</definiendum>
				<definiens id="0">a field that has seen increasing attention from the NLP community in recent years</definiens>
			</definition>
			<definition id="1">
				<sentence>MEAD ( Radev et al. , 2000 ) : MEAD is a centroid-based extractive summarizer that scores sentences based on sentence-level and inter-sentence features which indicate the quality of the sentence as a summary sentence .</sentence>
				<definiendum id="0">MEAD</definiendum>
				<definiendum id="1">MEAD</definiendum>
				<definiens id="0">a centroid-based extractive summarizer that scores sentences based on sentence-level and inter-sentence features which indicate the quality of the sentence as a summary sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Websumm uses a graph-connectivity model and operates under the assumption that nodes which are connected to many other nodes are likely to carry salient information .</sentence>
				<definiendum id="0">Websumm</definiendum>
				<definiens id="0">uses a graph-connectivity model and operates under the assumption that nodes which are connected to many other nodes are likely to carry salient information</definiens>
			</definition>
			<definition id="3">
				<sentence>Precision and recall are defined as : PJ2 ( J1 ) = AA+C ; RJ2 ( J1 ) = AA+B J2 Sentence in Extract Sentence not in Extract Sentence in Extract A B A+B J1 Sentence not in Extract C D C +D A+C B +D N = A + B+C+D Figure 3 : Contingency table comparing sentences extracted by the system and the judges .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiendum id="1">RJ2</definiendum>
				<definiens id="0">Contingency table comparing sentences extracted by the system and the judges</definiens>
			</definition>
			<definition id="4">
				<sentence>Kappa has the following advantages over P and R : It factors out random agreement .</sentence>
				<definiendum id="0">Kappa</definiendum>
				<definiens id="0">has the following advantages over P and R : It factors out random agreement</definiens>
			</definition>
			<definition id="5">
				<sentence>Random agreement is defined as the level of agreement which would be reached by random annotation using the same distribution of categories as the real annotators .</sentence>
				<definiendum id="0">Random agreement</definiendum>
				<definiens id="0">the level of agreement which would be reached by random annotation using the same distribution of categories as the real annotators</definiens>
			</definition>
			<definition id="6">
				<sentence>The Kappa coefficient controls agreement P ( A ) by taking into account agreement by chance P ( E ) : K = P ( A ) P ( E ) 1 P ( E ) No matter how many items or annotators , or how the categories are distributed , K = 0 when there is no agreement other than what would be expected by chance , and K = 1 when agreement is perfect .</sentence>
				<definiendum id="0">Kappa coefficient</definiendum>
				<definiens id="0">controls agreement P ( A ) by taking into account agreement by chance P ( E ) : K = P ( A ) P ( E ) 1 P ( E ) No matter how many items or annotators , or how the categories are distributed</definiens>
			</definition>
			<definition id="7">
				<sentence>RU allows judges and summarizers to pick different sentences with similar content in their summaries without penalizing them for doing so .</sentence>
				<definiendum id="0">RU</definiendum>
				<definiens id="0">allows judges and summarizers to pick different sentences with similar content in their summaries without penalizing them for doing so</definiens>
			</definition>
			<definition id="8">
				<sentence>Longest Common Subsequence is computed as follows : lcs ( X ; Y ) = ( length ( X ) +length ( Y ) d ( X ; Y ) ) =2 where X and Y are representations based on sequences and where lcs ( X ; Y ) is the length of the longest common subsequence between X and Y , length ( X ) is the length of the string X , and d ( X ; Y ) is the minimum number of deletion and insertions needed to transform X into Y ( Crochemore and Rytter , 1994 ) .</sentence>
				<definiendum id="0">length</definiendum>
				<definiendum id="1">X</definiendum>
				<definiens id="0">the length of the longest common subsequence between X and Y</definiens>
				<definiens id="1">the length of the string X</definiens>
			</definition>
			<definition id="9">
				<sentence>Relevance correlation r is defined as the linear correlation of the relevance scores ( x and y ) assigned by two different IR algorithms on the same set of documents or by the same IR algorithm on different data sets : r = P i ( xi x ) ( yi y ) pP i ( xi x ) 2 pP i ( yi y ) 2 Herexandy are the means of the relevance scores for the document sequence .</sentence>
				<definiendum id="0">Relevance correlation r</definiendum>
				<definiendum id="1">pP i</definiendum>
				<definiens id="0">the linear correlation of the relevance scores ( x and y ) assigned by two different IR algorithms on the same set of documents or by the same IR algorithm on different data sets : r = P i ( xi x ) ( yi y )</definiens>
			</definition>
</paper>

		<paper id="1051">
			<definition id="0">
				<sentence>The core algorithm lies in the estimation of a probabilistic alignment between inflected forms and root forms .</sentence>
				<definiendum id="0">core algorithm</definiendum>
			</definition>
			<definition id="1">
				<sentence>In that case , we use an “UNKNOWN” class in the trigram language model with the model probability given by p ( UNKNOWN|m i-1 , m i-2 ) * UNK_Fraction , where UNK_Fraction is 1e-9 determined on empirical grounds .</sentence>
				<definiendum id="0">UNK_Fraction</definiendum>
				<definiens id="0">1e-9 determined on empirical grounds</definiens>
			</definition>
			<definition id="2">
				<sentence>S7 , S8 , &amp; S9 are the segmentations given the prefix wA # and suffixes ∅ , +A , +hA .</sentence>
				<definiendum id="0">S9</definiendum>
				<definiens id="0">the segmentations given the prefix wA # and suffixes ∅ , +A , +hA</definiens>
			</definition>
			<definition id="3">
				<sentence>Initialization : Develop the seed segmenter Segmenter 0 trained on the manually segmented corpus Corpus 0 , using the language model vocabulary , Vocab 0 , acquired from Corpus 0 .</sentence>
				<definiendum id="0">Initialization</definiendum>
				<definiens id="0">Develop the seed segmenter Segmenter 0 trained on the manually segmented corpus Corpus 0 , using the language model vocabulary</definiens>
			</definition>
			<definition id="4">
				<sentence>To address the segmentation ambiguity problem , as illustrated by ' ﻦnullnullnullnullﻴnullnullnullnullﺗﻮnullnullﺑ ( Putin ) ' vs. ' ب # ﻦnullnullnullﻴnullnullnullﺗو ( by aorta ) ' , we have developed a joint model for segmentation and part-ofspeech tagging for which the best segmentation of an input sentence is obtained according to the formula ( 10 ) , where t i is the part-of-speech of morpheme m i , and N is the number of morphemes in the input sentence .</sentence>
				<definiendum id="0">segmentation ambiguity problem</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the number of morphemes in the input sentence</definiens>
			</definition>
</paper>

		<paper id="1043">
			<definition id="0">
				<sentence>Named Entity ( NE ) tagging is a fundamental task for natural language processing and information extraction .</sentence>
				<definiendum id="0">Entity ( NE ) tagging</definiendum>
				<definiens id="0">a fundamental task for natural language processing and information extraction</definiens>
			</definition>
			<definition id="1">
				<sentence>The InfoXtract parser supports dependency parsing based on the linguistic units constructed by our shallow parser ( Srihari et al. 2003 ) .</sentence>
				<definiendum id="0">InfoXtract parser</definiendum>
				<definiens id="0">supports dependency parsing based on the linguistic units constructed by our shallow parser ( Srihari et al. 2003 )</definiens>
			</definition>
			<definition id="2">
				<sentence>The marked instances plus their associated parsing relationships form an annotated NE corpus , as shown below : he/PER : Has_Predicate ( say ) she/PER : Has_Predicate ( get ) companyRG : Object_Of ( compel ) city/LOC : Possess ( mayor ) car/PRO : Object_Of ( manufacture ) HasAmod ( high-quality ) ………… This training corpus supports the Decision List Learning which learns homogeneous rules ( Segal &amp; Etzioni 1994 ) .</sentence>
				<definiendum id="0">Decision List Learning</definiendum>
				<definiens id="0">which learns homogeneous rules ( Segal &amp; Etzioni 1994 )</definiens>
			</definition>
			<definition id="3">
				<sentence>The following are sample rules of the learned decision list : Possess ( wife ) Gc6 PER Possess ( husband ) Gc6 PER Possess ( daughter ) Gc6 PER Possess ( bravery ) Gc6 PER Possess ( father ) Gc6 PER Has_Predicate ( divorce ) Gc6 PER Has_Predicate ( remarry ) Gc6 PER Possess ( brother ) Gc6 PER Possess ( son ) Gc6 PER Possess ( mother ) Gc6 PER Object_Of ( deport ) Gc6 PER Possess ( sister ) Gc6 PER Possess ( colleague ) Gc6 PER Possess ( career ) Gc6 PER Possess ( forehead ) Gc6 PER Has_Predicate ( smile ) Gc6 PER Possess ( respiratory system ) Gc6 PER { Has_Predicate ( threaten ) , Has_Predicate ( kill ) } Gc6PER ………… Possess ( concert hall ) Gc6 LOC Has_AMod ( coastal ) Gc6 LOC Has_AMod ( northern ) Gc6 LOC Has_AMod ( eastern ) Gc6 LOC Has_AMod ( northeastern ) Gc6 LOC Possess ( undersecretary ) Gc6 LOC Possess ( mayor ) Gc6 LOC Has_AMod ( southern ) Gc6 LOC Has_AMod ( northwestern ) Gc6 LOC Has_AMod ( populous ) Gc6 LOC Has_AMod ( rogue ) Gc6 LOC Has_AMod ( southwestern ) Gc6 LOC Possess ( medical examiner ) Gc6 LOC Has_AMod ( edgy ) Gc6 LOC ………… Has_AMod ( broad-base ) Gc6 ORG Has_AMod ( advisory ) Gc6 ORG Has_AMod ( non-profit ) Gc6 ORG Possess ( ceo ) Gc6 ORG Possess ( operate loss ) Gc6 ORG Has_AMod ( multinational ) Gc6 ORG Has_AMod ( non-governmental ) Gc6 ORG Possess ( filings ) Gc6 ORG Has_AMod ( interim ) Gc6 ORG Has_AMod ( for-profit ) Gc6 ORG Has_AMod ( not-for-profit ) Gc6 ORG Has_AMod ( nongovernmental ) Gc6 ORG Object_Of ( undervalue ) Gc6 ORG ………… Has_AMod ( handheld ) Gc6 PRO Has_AMod ( unman ) Gc6 PRO Has_AMod ( well-sell ) Gc6 PRO Has_AMod ( value-add ) Gc6 PRO Object_Of ( refuel ) Gc6 PRO Has_AMod ( fuel-efficient ) Gc6 PRO Object_Of ( vend ) Gc6 PRO Has_Predicate ( accelerate ) Gc6 PRO Has_Predicate ( collide ) Gc6 PRO Object_Of ( crash ) Gc6 PRO Has_AMod ( scalable ) Gc6 PRO Possess ( patch ) Gc6 PRO Object_Of ( commercialize ) Gc6PRO Has_AMod ( custom-design ) Gc6 PRO Possess ( rollout ) Gc6 PRO Object_Of ( redesign ) Gc6 PRO ………… Due to the unique equivalence nature of the IsA relation , the above bootstrapping procedure can hardly learn IsA-based rules .</sentence>
				<definiendum id="0">Gc6 LOC Has_AMod ( coastal ) Gc6 LOC Has_AMod ( northern</definiendum>
				<definiendum id="1">Gc6 ORG Possess ( operate loss ) Gc6 ORG Has_AMod</definiendum>
				<definiens id="0">sample rules of the learned decision list : Possess ( wife ) Gc6 PER Possess ( husband ) Gc6 PER Possess ( daughter ) Gc6 PER Possess ( bravery ) Gc6 PER Possess ( father ) Gc6 PER Has_Predicate ( divorce ) Gc6 PER Has_Predicate ( remarry ) Gc6 PER Possess ( brother ) Gc6 PER Possess ( son ) Gc6 PER Possess ( mother ) Gc6 PER Object_Of ( deport ) Gc6 PER Possess ( sister ) Gc6 PER Possess ( colleague ) Gc6 PER Possess ( career ) Gc6 PER Possess ( forehead ) Gc6 PER Has_Predicate ( smile ) Gc6 PER Possess ( respiratory system ) Gc6 PER { Has_Predicate ( threaten )</definiens>
				<definiens id="1">multinational ) Gc6 ORG Has_AMod ( non-governmental ) Gc6 ORG Possess ( filings ) Gc6 ORG Has_AMod ( interim ) Gc6 ORG Has_AMod ( for-profit ) Gc6 ORG Has_AMod ( not-for-profit ) Gc6 ORG Has_AMod ( nongovernmental ) Gc6 ORG Object_Of ( undervalue ) Gc6 ORG ………… Has_AMod ( handheld ) Gc6 PRO Has_AMod ( unman ) Gc6 PRO Has_AMod ( well-sell ) Gc6 PRO Has_AMod ( value-add ) Gc6 PRO Object_Of ( refuel ) Gc6 PRO Has_AMod ( fuel-efficient ) Gc6 PRO Object_Of ( vend ) Gc6 PRO Has_Predicate ( accelerate ) Gc6 PRO Has_Predicate ( collide ) Gc6 PRO Object_Of ( crash ) Gc6 PRO Has_AMod ( scalable ) Gc6 PRO Possess ( patch ) Gc6 PRO Object_Of ( commercialize ) Gc6PRO Has_AMod ( custom-design ) Gc6 PRO Possess ( rollout ) Gc6 PRO Object_Of ( redesign ) Gc6 PRO ………… Due to the unique equivalence nature of the IsA relation , the above bootstrapping procedure can hardly learn IsA-based rules</definiens>
			</definition>
			<definition id="4">
				<sentence>An NE candidate is defined as any chunk in the parsed corpus that is marked with a proper name Part-OfSpeech ( POS ) tag ( i.e. NNP or NNPS ) .</sentence>
				<definiendum id="0">NE candidate</definiendum>
				<definiendum id="1">POS ) tag</definiendum>
				<definiens id="0">any chunk in the parsed corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>The HMM is defined as follows : Given a word sequence nn00 fwfwsequenceW G16= ( where j f denotes a single token feature which will be defined below ) , the goal for the NE tagging task is to find the optimal NE tag sequence n210 ttttsequence T G16= , which maximizes the conditional probability sequence ) W |sequence Pr ( T ( Bikel 1997 ) .</sentence>
				<definiendum id="0">HMM</definiendum>
			</definition>
			<definition id="6">
				<sentence>This joint probability can be computed by bi-gram HMM as follows : ∏ − = i ) t , f , w|t , f , wPr ( sequence ) T sequence , Pr ( W 1i1-i1-iiii The back-off model is as follows , ) t , w| ) Pr ( tt , t|f , wPr ( ) - ( 1 ) t , f , w|t , f , w ( P ) t , f , w|t , f , wPr ( 1i1ii1iiii1 1i1-i1-iiii01 1i1-i1-iiii −−− − − + = λ λ where V denotes the size of the vocabulary , the back-off coefficients λ’s are determined using the Witten-Bell smoothing algorithm .</sentence>
				<definiendum id="0">HMM</definiendum>
				<definiendum id="1">V</definiendum>
				<definiens id="0">the size of the vocabulary , the back-off coefficients</definiens>
			</definition>
			<definition id="7">
				<sentence>WordNet : A Lexical Database Organized on Psycholinguistic Principles .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
			<definition id="8">
				<sentence>InfoXtract : An Information Discovery Engine Supported by New Levels of Information Extraction .</sentence>
				<definiendum id="0">InfoXtract</definiendum>
				<definiens id="0">An Information Discovery Engine Supported by New Levels of Information Extraction</definiens>
			</definition>
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>CSS is defined as the key term sequence in the query that conveys the main semantics of the query .</sentence>
				<definiendum id="0">CSS</definiendum>
				<definiens id="0">the key term sequence in the query that conveys the main semantics of the query</definiens>
			</definition>
			<definition id="1">
				<sentence>QM defines the structures and some of the standard phrases used in typical queries .</sentence>
				<definiendum id="0">QM</definiendum>
				<definiens id="0">defines the structures and some of the standard phrases used in typical queries</definiens>
			</definition>
			<definition id="2">
				<sentence>Query model ( QM ) is used to analyze the query and extract the core semantic string ( CSS ) that contains the main semantic of the query .</sentence>
				<definiendum id="0">Query model</definiendum>
				<definiendum id="1">QM</definiendum>
				<definiens id="0">used to analyze the query and extract the core semantic string ( CSS ) that contains the main semantic of the query</definiens>
			</definition>
			<definition id="3">
				<sentence>The query log consists of 557 queries , collected from twenty-eight human subjects at the Shanghai Jiao Tong University ( Ying 2002 ) .</sentence>
				<definiendum id="0">query log</definiendum>
			</definition>
			<definition id="4">
				<sentence>These include question phrases , quantifiers , polite remarks , prepositions , time and commonly used verb and subject-verb phrases .</sentence>
				<definiendum id="0">polite</definiendum>
			</definition>
			<definition id="5">
				<sentence>The input vector i has three components : left context ( Li ) , the CSS itself ( CSSi ) , and right context ( Ri ) .</sentence>
				<definiendum id="0">CSS itself</definiendum>
				<definiendum id="1">CSSi</definiendum>
				<definiens id="0">left context ( Li ) , the</definiens>
			</definition>
			<definition id="6">
				<sentence>pj is the possibility of occurrence of the jth query structure , and n is the total number of the structures in the Query Model .</sentence>
				<definiendum id="0">pj</definiendum>
				<definiendum id="1">n</definiendum>
				<definiens id="0">the total number of the structures in the Query Model</definiens>
			</definition>
			<definition id="7">
				<sentence>Given the basic CSS component qi , and a phrase cjin the dictionary , we compute : a0= = ) , ( 0 *| } || , max { | ) , ( ) , ( ii cqLCS k kii ii ii Mcq cqLCScqSim ( 2 ) where LCS ( qi , cj ) gives the number of characters/ syllable matched between qi and ci in the order of their appearance using the longest common subsequence matching ( LCS ) algorithm ( Cormen et al 1990 ) .</sentence>
				<definiendum id="0">ii cqLCS</definiendum>
				<definiendum id="1">LCS</definiendum>
			</definition>
			<definition id="8">
				<sentence>Hence LCS ( qi , cj ) gives the degree of match between qi and cj , normalized by the maximum length of qi or cj ; and ΣM gives the degree of similarity between the units being matched .</sentence>
				<definiendum id="0">Hence LCS</definiendum>
				<definiendum id="1">cj )</definiendum>
				<definiens id="0">gives the degree of match between qi and cj , normalized by the maximum length of qi or cj ; and ΣM gives the degree of similarity between the units being matched</definiens>
			</definition>
			<definition id="9">
				<sentence>Jerry R. Hobbs , et al , ( 1997 ) , FASTUS : A Cascaded Finite-State Transducer for Extracting Information from Natural-Language Text , FiniteState Language Processing , Emmanuel Roche and Yves Schabes , pp .</sentence>
				<definiendum id="0">FASTUS</definiendum>
				<definiens id="0">A Cascaded Finite-State Transducer for Extracting Information from Natural-Language Text , FiniteState Language Processing</definiens>
			</definition>
</paper>

		<paper id="1069">
			<definition id="0">
				<sentence>To obtain P ( hje ) , we need f ( h ; e ) and f ( e ) which can be estimated in Figure 1 by counting the number of edges connecting e and h and the number of edges starting from e , respectively .</sentence>
				<definiendum id="0">f ( e</definiendum>
				<definiens id="0">) which can be estimated in Figure 1 by counting the number of edges connecting e and h and the number of edges starting from e , respectively</definiens>
			</definition>
			<definition id="1">
				<sentence>Kendall’s τ is based on the number of inversions in the rankings and is defined in ( 6 ) : ( 6 ) τ = 1− 2 ( number of inversions ) N ( N −1 ) =2 where N is the number of objects ( i.e. , sentences ) being ranked and inversions are the number of interchanges of consecutive elements necessary to arrange them in their natural order .</sentence>
				<definiendum id="0">Kendall’s τ</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">the number of objects ( i.e. , sentences ) being ranked and inversions are the number of interchanges of consecutive elements necessary to arrange them in their natural order</definiens>
			</definition>
			<definition id="2">
				<sentence>Table 3 gives the average τ ( T ) for all 20 test texts when the following features are used : lemmatized verbs ( V L ) , tensed verbs ( V T ) , lemmatized nouns ( N L ) , lemmatized verbs and nouns ( V L N L ) , tensed verbs and lemmatized nouns ( V T N L ) , verb-related dependencies ( V D ) , noun-related dependencies ( N D ) , verb and noun dependencies ( V D N D ) , and all available dependencies ( A D ) .</sentence>
				<definiendum id="0">V T N L )</definiendum>
				<definiendum id="1">verb-related dependencies</definiendum>
				<definiens id="0">the average τ ( T ) for all 20 test texts when the following features are used : lemmatized verbs ( V L ) , tensed verbs ( V T ) , lemmatized nouns</definiens>
			</definition>
			<definition id="3">
				<sentence>A language generation system outputs a sentence ( per theme ) from the selected predicate argument structures .</sentence>
				<definiendum id="0">language generation system</definiendum>
				<definiens id="0">outputs a sentence ( per theme ) from the selected predicate argument structures</definiens>
			</definition>
</paper>

		<paper id="1065">
			<definition id="0">
				<sentence>recognizing PVs is an important condition for English parsing .</sentence>
				<definiendum id="0">PVs</definiendum>
			</definition>
			<definition id="1">
				<sentence>3 Type III takes the form of an intransitive verb plus an adverb particle , e.g. , get by , blow up , burn up , get off , etc .</sentence>
				<definiendum id="0">Type III</definiendum>
				<definiens id="0">takes the form of an intransitive verb plus an adverb particle , e.g. , get by</definiens>
			</definition>
			<definition id="2">
				<sentence>NP insertion is an intriguing linguistic phenomenon involving the morpho-syntactic interface : a morphological compounding process needs to interact with the formation of a syntactic unit .</sentence>
				<definiendum id="0">morpho-syntactic interface</definiendum>
			</definition>
			<definition id="3">
				<sentence>Part-of-Speech ( POS ) Tagging General Lexicon Lexical lookup Named Entity ( NE ) Taggig Shallow Parsing PV Identification Deep parsing General Lexicon PV Expert Lexicon Figure 1 .</sentence>
				<definiendum id="0">Part-of-Speech ( POS</definiendum>
				<definiens id="0">Tagging General Lexicon Lexical lookup Named Entity ( NE ) Taggig Shallow Parsing PV Identification Deep parsing General Lexicon PV Expert Lexicon Figure 1</definiens>
			</definition>
			<definition id="4">
				<sentence>The deactivate action flags the particle as being part of the phrasal verb .</sentence>
				<definiendum id="0">deactivate action</definiendum>
				<definiens id="0">flags the particle as being part of the phrasal verb</definiens>
			</definition>
			<definition id="5">
				<sentence>A sample of the developed PV Expert Lexicon is shown below ( the prefix @ denotes a macro call ) : abide : @ V_P_by ( abide , by , abide_by , V6A , APPROVING_AGREEING ) accede : @ V_P_to ( accede , to , accede_to , V6A , APPROVING_AGREEING ) add : @ V_P ( add , up , add_up , V2A , MATH_REASONING ) ; @ V_NP_P ( add , up , add_up , V6A , MATH_REASONING ) ………… In the above entries , V6A and V2A are subcategorization features for transitive and intransitive verb respectively , while APPROVING_AGREEING and MATH_REASONING are semantic features .</sentence>
				<definiendum id="0">V6A</definiendum>
				<definiens id="0">intransitive verb respectively , while APPROVING_AGREEING and MATH_REASONING are semantic features</definiens>
			</definition>
</paper>

		<paper id="1060">
			<definition id="0">
				<sentence>Noun extraction is a process to find every noun in a document ( Lee et al. , 2001 ) .</sentence>
				<definiendum id="0">Noun extraction</definiendum>
			</definition>
			<definition id="1">
				<sentence>Korean is a highly agglutinative language and nouns are included in Eojeols .</sentence>
				<definiendum id="0">Korean</definiendum>
				<definiens id="0">a highly agglutinative language and nouns are included in Eojeols</definiens>
			</definition>
			<definition id="2">
				<sentence>An Eojeol is a surface level form consisting of more than one combined morpheme .</sentence>
				<definiendum id="0">Eojeol</definiendum>
				<definiens id="0">a surface level form consisting of more than one combined morpheme</definiens>
			</definition>
			<definition id="3">
				<sentence>Furthermore , both methods have serious deficien철수는 ( Cheol-Su-neun ) 사람들을 ( sa-lam-deul-eul ) 봤다 ( bwass-da ) 철수 ( Cheol-Su ) 는 ( neun ) 사람들 ( sa-lam-deul ) 을 ( eul ) 봤다 ( bwass-da ) 철수 ( Cheol-Su ) 사람 ( sa-lam ) 들 ( deul ) 을 ( eul ) 보 ( bo ) 았 ( ass ) 다 ( da ) eojeol word morpheme p r o p e r n o u n : p e r s o n n a m e p o s t p o s it io n n o u n : p e r s o n n o u n s u f f ix : p lu r a l p o s t p o s it io n v e r b : s e e p r e f in a l e n d in g e n d in g 는 ( neun ) Figure 1 : Constitution of the sentence “CMD3BPFFF6DXAFC0A6AJDGFFFSCJH2D8COA7EMC3EUD3A2AJ ( Cheol-Su saw the persons ) ” cies in that they require considerable manual labor to construct and maintain linguistic knowledge and suffer from the unknown word problem .</sentence>
				<definiendum id="0">p e r s</definiendum>
				<definiens id="0">Constitution of the sentence “CMD3BPFFF6DXAFC0A6AJDGFFFSCJH2D8COA7EMC3EUD3A2AJ ( Cheol-Su saw the persons ) ” cies in that they require considerable manual labor to construct and maintain linguistic knowledge and suffer from the unknown word problem</definiens>
			</definition>
			<definition id="4">
				<sentence>A Korean syllable consists of an obligatory onset ( initial-grapheme , consonant ) , an obligatory peak ( nuclear grapheme , vowel ) , and an optional coda ( final-grapheme , consonant ) .</sentence>
				<definiendum id="0">Korean syllable</definiendum>
			</definition>
			<definition id="5">
				<sentence>A0B4CR BDBND2 B5 BP CPD6CVD1CPDC D8 BDBND2 D2 CH CXBPBD C8B4D8 CX CY D8 CXA0BD BNCZB5C8B4CR CX CY D8 CX B5 ( 3 ) In the equation , CZ becomes zero if the transition occurs in the inside of an Eojeol ; otherwise CZ is one .</sentence>
				<definiendum id="0">CZ</definiendum>
				<definiens id="0">zero if the transition occurs in the inside of an Eojeol</definiens>
			</definition>
			<definition id="6">
				<sentence>Table 1 : Examples of syllable tagging by BI , BIS , IE , and IES representation schemes surface level lexical level BI BIS IE IES ( syllable ) ( morpheme/POS tag ) DKDXE5 ( yak ) DKDXE5BHFHD5 ( yak-sok ) /nc B-nc B-nc I-nc I-nc BHFHD5 ( sok ) I-nc I-nc E-nc E-nc DLEPEC ( jang ) DLEPECE9GG ( jang-so ) /nc B-nc B-nc I-nc I-nc E9GG ( so ) I-nc I-nc E-nc E-nc E3ARA4 ( in ) D7AR ( i ) /co+A2 ( n ) /etm B-co etm S-co etm E-co etm S-co etm E2ARA4 ( Sin ) E2ARA4A3AJEGGPBLCKEA ( Sin-la-ho-tel ) /nc B-nc B-nc I-nc I-nc A3AJ ( la ) I-nc I-nc I-nc I-nc EGGP ( ho ) I-nc I-nc I-nc I-nc BLCKEA ( tel ) I-nc I-nc E-nc E-nc B2AL ( keo ) B2ALDCARCNAVDA ( keo-pi-syob ) /nc B-nc B-nc I-nc I-nc DCAR ( pi ) I-nc I-nc I-nc I-nc CNAVDA ( syob ) I-nc I-nc E-nc E-nc CKDL ( e ) CKDL ( e ) /jc B-jc S-jc E-jc S-jc BYAN ( Jai ) BYANBIEFEK ( Jai-Ok ) /nc B-nc B-nc I-nc I-nc BIEFEK ( Ok ) I-nc I-nc E-nc E-nc D7AR ( i ) D7AR ( i ) /jc B-jc S-jc E-jc S-jc DKALA4 ( meon ) DKALA4B0DJ ( meon-jeo ) /mag B-mag B-mag I-mag I-mag B0DJ ( jeo ) I-mag I-mag E-mag E-mag H0BO ( wa ) EAF4 ( o ) /pv+A7AJ ( a ) /ec B-pv ec S-pv ec E-pv ec S-pv ec D0AR ( gi ) D0ARA2AJD3AR ( gi-da-li ) /pv+E3EM ( go ) /ec B-pv ec B-pv ec I-pv ec I-pv ec A2AJ ( da ) I-pv ec I-pv ec I-pv ec I-pv ec D3AR ( li ) I-pv ec I-pv ec I-pv ec I-pv ec E3EM ( go ) I-pv ec I-pv ec E-pv ec E-pv ec CTE4AI ( iss ) CTE4AI ( iss ) /px+B1BFAI ( eoss ) /ep+A2AJ ( da ) /ef B-px ef B-px ef I-px ef I-px ef B1BFAI ( eoss ) I-px ef I-px ef I-px ef I-px ef A2AJ ( da ) I-px ef I-px ef E-px ef E-px ef .</sentence>
				<definiendum id="0">IES</definiendum>
				<definiendum id="1">syllable ) ( morpheme/POS tag</definiendum>
				<definiendum id="2">I-nc I-nc E-nc E-nc E3ARA4</definiendum>
				<definiendum id="3">B-jc S-jc E-jc S-jc DKALA4 ( meon</definiendum>
				<definiens id="0">Examples of syllable tagging by BI , BIS , IE , and</definiens>
				<definiens id="1">/ec B-pv ec B-pv ec I-pv ec I-pv ec A2AJ ( da ) I-pv ec I-pv ec I-pv ec I-pv ec D3AR ( li ) I-pv ec I-pv ec I-pv ec I-pv</definiens>
			</definition>
			<definition id="7">
				<sentence>The Sejong corpus consists of three different corpora acquired from 1999 to 2001 .</sentence>
				<definiendum id="0">Sejong corpus</definiendum>
			</definition>
			<definition id="8">
				<sentence>NE2001 , which is a system designed only to extract nouns , improves efficiency of the general morphological analyzer by using positive and negative information about occurrences of nouns .</sentence>
				<definiendum id="0">NE2001</definiendum>
			</definition>
			<definition id="9">
				<sentence>KOMA ( Lee et al. , 1999b ) is a general-purpose morphological analyzer .</sentence>
				<definiendum id="0">KOMA</definiendum>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>Such context variables consist of the sequence name a0 , a number a1 designating the dependent in left-to-right order ( e.g. 0 for in , 1 for on in example ( 5 ) ) , and a number a2 designating the head in left-to-right ( e.g. 0 for saw , 1 for man , 2 for hill in ( 5 ) ) .</sentence>
				<definiendum id="0">Such context variables</definiendum>
				<definiens id="0">consist of the sequence name a0 , a number a1 designating the dependent in left-to-right order ( e.g. 0 for in</definiens>
			</definition>
			<definition id="1">
				<sentence>German is a free word order language , so that subcategorization can be ambiguous .</sentence>
				<definiendum id="0">German</definiendum>
				<definiens id="0">a free word order language</definiens>
			</definition>
			<definition id="2">
				<sentence>Some types of adjunction have not yet been implemented in the cascaded parser , so that it performs badly on them ( e.g. relative clauses ( RC ) , which are usually extraposed to the right ( average distance is 11.6 ) and thus quite difficult also for the learners ; comparative constructions ( CC , CM ) , measure phrases ( AMS ) , floating quantifiers ( NK+ ) ) .</sentence>
				<definiendum id="0">comparative constructions</definiendum>
				<definiens id="0">implemented in the cascaded parser , so that it performs badly on them ( e.g. relative clauses ( RC ) , which are usually extraposed to the right</definiens>
			</definition>
			<definition id="3">
				<sentence>AC is the relation between parts of a circumposition .</sentence>
				<definiendum id="0">AC</definiendum>
				<definiens id="0">the relation between parts of a circumposition</definiens>
			</definition>
</paper>

		<paper id="2004">
</paper>

		<paper id="1030">
			<definition id="0">
				<sentence>At time a9 , we use a5a28a36a38a37a40a39a42a41 a9a11 a3a17a0a44a43a45a5a28a7a46a13 a47 a48 a11 a3a17a0a49a7 a1a4a3a17a0a44a43a45a5a8a7a51a50a53a52a55a54a25a56 a57 a11 a0a2a1 a11 a3a6a5a28a7 ( 2 ) where a57 a11 is the total number of documents at time a9 .</sentence>
				<definiendum id="0">a57 a11</definiendum>
			</definition>
			<definition id="1">
				<sentence>We used a symmetric version that is computed as : a60 a37a62a61a63a3a17a0a64a43 a59 a7a65a13a67a66a69a68a71a70a58a3a17a0a73a72a55a72 a59 a7a21a20a22a68a74a70a58a3a17a0a73a72a55a72a76a75a28a77a78a7 a66a32a68a74a70a58a3 a59 a72a55a72a0a49a7a21a20a22a68a74a70a79a3 a59 a72a55a72a76a75a28a77a78a7 ( 3 ) a68a74a70a79a3a17a0a64a43 a59 a7a80a13a82a81a84a83a85a5a58a36a53a37a40a39a42a41 a9 a11 a3a17a0a64a43a45a5a28a7a38a50a87a86a17a88a89a39a73a3 a5a58a36a53a37a40a39a42a41 a9 a11 a3a17a0a44a43a45a5a8a7 a5a28a36a38a37a40a39a42a41 a9a2a11 a3 a59 a43a45a5a28a7a44a90 ( 4 ) where “a68a74a70 ” is the Kullback-Leibler divergence , a75a28a77 is the probability distribution of words for “general English” as derived from the training corpus .</sentence>
				<definiendum id="0">“a68a74a70 ”</definiendum>
				<definiendum id="1">a75a28a77</definiendum>
				<definiens id="0">a symmetric version that is computed as : a60 a37a62a61a63a3a17a0a64a43 a59 a7a65a13a67a66a69a68a71a70a58a3a17a0a73a72a55a72 a59 a7a21a20a22a68a74a70a58a3a17a0a73a72a55a72a76a75a28a77a78a7 a66a32a68a74a70a58a3 a59 a72a55a72a0a49a7a21a20a22a68a74a70a79a3 a59 a72a55a72a76a75a28a77a78a7 ( 3 ) a68a74a70a79a3a17a0a64a43 a59 a7a80a13a82a81a84a83a85a5a58a36a53a37a40a39a42a41 a9 a11 a3a17a0a64a43a45a5a28a7a38a50a87a86a17a88a89a39a73a3 a5a58a36a53a37a40a39a42a41 a9 a11 a3a17a0a44a43a45a5a8a7 a5a28a36a38a37a40a39a42a41 a9a2a11 a3 a59 a43a45a5a28a7a44a90</definiens>
				<definiens id="1">the probability distribution of words for “general English” as derived from the training corpus</definiens>
			</definition>
			<definition id="2">
				<sentence>In order to decide whether a pair of stories a0 and a59 are linked , we identify a set of similarity metrics a21 that capture the similarity between the two documents using Clarity and Hellinger metrics : a21a14a3a17a0a44a43 a59 a7a80a13a23a22 a60 a37a62a61a25a24a53a3a17a0a64a43 a59 a7 a43 a60 a37a62a61a25a26a64a3a17a0a64a43 a59 a7a28a27 a90 ( 9 ) The value a21a4a3a17a0a64a43 a59 a7 is used to determine whether stories “q” and “d” are linked .</sentence>
				<definiendum id="0">Hellinger</definiendum>
				<definiens id="0">metrics : a21a14a3a17a0a44a43 a59 a7a80a13a23a22 a60 a37a62a61a25a24a53a3a17a0a64a43 a59 a7 a43 a60 a37a62a61a25a26a64a3a17a0a64a43 a59 a7a28a27 a90</definiens>
				<definiens id="1">used to determine whether stories “q” and “d” are linked</definiens>
			</definition>
			<definition id="3">
				<sentence>A LNK system wants to minimize false alarms and to do this it should identify stories as being linked only if they are linked , which translates to high precision .</sentence>
				<definiendum id="0">LNK system</definiendum>
				<definiens id="0">translates to high precision</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , ‘N train’ represents the term ‘train’ when used as a noun , and ‘V train’ represents the term ‘train’ when used as a verb .</sentence>
				<definiendum id="0">‘V train’</definiendum>
				<definiens id="0">represents the term ‘train’ when used as a verb</definiens>
			</definition>
			<definition id="5">
				<sentence>The Part-of-speech is a recall enhancing devices while the ASR stop-list is a precision enhancing device .</sentence>
				<definiendum id="0">Part-of-speech</definiendum>
				<definiendum id="1">ASR stop-list</definiendum>
				<definiens id="0">a precision enhancing device</definiens>
			</definition>
</paper>

		<paper id="2023">
</paper>

		<paper id="1034">
			<definition id="0">
				<sentence>For example , Mooney’s EEG system ( Mooney , 1994 ) , which created a full-page description of the Three-Mile Island nuclear plant disaster , contains components for discourse knowledge , discourse organization , rhetoriFigure 1 : A Typical Pipelined NLG Architecture cal relation structuring , sentence planning , and surface realization .</sentence>
				<definiendum id="0">Mooney’s EEG system</definiendum>
				<definiens id="0">created a full-page description of the Three-Mile Island nuclear plant disaster , contains components for discourse knowledge , discourse organization</definiens>
				<definiens id="1">A Typical Pipelined NLG Architecture cal relation structuring , sentence planning , and surface realization</definiens>
			</definition>
			<definition id="1">
				<sentence>To demonstrate the application of this problem to real world discourse , we took the STORYBOOK ( Callaway and Lester , 2001 ; Callaway and Lester , 2002 ) NLG system that generates multi-page text in the form of Little Red Riding Hood stories and New York Times articles , using a pipelined architecture with a large number of modules such as revision ( Callaway and Lester , 1997 ) .</sentence>
				<definiendum id="0">STORYBOOK</definiendum>
				<definiens id="0">generates multi-page text in the form of Little Red Riding Hood stories</definiens>
			</definition>
			<definition id="2">
				<sentence>STORYBOOK takes a discourse plan augmented with appropriate low-level ( i.e. , unlexicalized , or conceptual ) rhetorical features and produces a sentence plan without discarding rhetorical information .</sentence>
				<definiendum id="0">STORYBOOK</definiendum>
				<definiens id="0">takes a discourse plan augmented with appropriate low-level ( i.e. , unlexicalized , or conceptual ) rhetorical features and produces a sentence plan without discarding rhetorical information</definiens>
			</definition>
</paper>

		<paper id="2002">
			<definition id="0">
				<sentence>STATUS STATUS TIME Figure 1 : An Excerpt of a conversation reporting an overdue vessel : the incident , a request for an SAR airplane ( Aurora ) and the use of another SAR airplane ( king Air ) .</sentence>
				<definiendum id="0">overdue vessel</definiendum>
				<definiens id="0">An Excerpt of a conversation reporting an</definiens>
			</definition>
			<definition id="1">
				<sentence>Then , the semantic tagger annotates the extracted words ( stage II ) .</sentence>
				<definiendum id="0">semantic tagger</definiendum>
			</definition>
			<definition id="2">
				<sentence>Topic segmentation takes part to several stages in our IE system ( Figure 2 ) .</sentence>
				<definiendum id="0">Topic segmentation</definiendum>
				<definiens id="0">takes part to several stages in our IE system ( Figure 2 )</definiens>
			</definition>
			<definition id="3">
				<sentence>The SAR ontology is an important component of our IE system .</sentence>
				<definiendum id="0">SAR ontology</definiendum>
			</definition>
			<definition id="4">
				<sentence>SYN : speculate ( 1 ) SIM : deliberate , ponder , think , reflect , puzzle , conjecture ... Figure 3 : A fragment of the Wordsmyth dictionary-thesaurus entry of the verb wonder which is a verb describing a STATUS-REQUEST concept ( 8-O Figure 1 ) .</sentence>
				<definiendum id="0">SYN</definiendum>
				<definiendum id="1">SIM</definiendum>
				<definiens id="0">deliberate , ponder , think , reflect , puzzle , conjecture ... Figure 3 : A fragment of the Wordsmyth dictionary-thesaurus entry of the verb wonder which is a verb describing a STATUS-REQUEST concept</definiens>
			</definition>
			<definition id="5">
				<sentence>The concept-based representation is a vector of similarity scores that measures how close is a word to the SAR domain .</sentence>
				<definiendum id="0">concept-based representation</definiendum>
				<definiens id="0">a vector of similarity scores that measures how close is a word to the SAR domain</definiens>
			</definition>
			<definition id="6">
				<sentence>However , a first step before annotation is to determine what word sense is intended in conversations .</sentence>
				<definiendum id="0">annotation</definiendum>
				<definiens id="0">to determine what word sense is intended in conversations</definiens>
			</definition>
			<definition id="7">
				<sentence>w = argmax w ( l ) 1 Nl all concepts ksim ( w ( l ) ; k ) ( 2 ) Where Nl is the number of positive similarity scores of the w ( l ) similarity vector .</sentence>
				<definiendum id="0">Nl all concepts ksim</definiendum>
				<definiendum id="1">Nl</definiendum>
				<definiens id="0">the number of positive similarity scores of the w</definiens>
			</definition>
			<definition id="8">
				<sentence>w ( l ) is the word w given the word sense l. The closer word sense w is the highest mean computed from element of the w ( l ) similarity vector .</sentence>
				<definiendum id="0">w ( l )</definiendum>
				<definiens id="0">the highest mean computed from element of the w</definiens>
			</definition>
			<definition id="9">
				<sentence>A similarity vector is a vector where each element is a similarity score between a word ( l ) ( the word w given the sense word l ) and a concept Ck from the SAR ontology .</sentence>
				<definiendum id="0">similarity vector</definiendum>
				<definiens id="0">a vector where each element is a similarity score between a word ( l ) ( the word w given the sense word l</definiens>
			</definition>
			<definition id="10">
				<sentence>It is defined as : sim ( w ( l ) ; Ck ) = jDw ( l ) j\jDCk jmin ( jD w ( l ) j ; jDCk j ) ( 3 ) where Dw ( l ) and DCk are the sets of lemmatized content words extracted from the textual definitions 3-O : an overdue boat VESSEL : [ dt , an ] , [ OTHER-PROPERTIES , overdue ] , [ VESSEL , boat ] 11-O : black thicker fog WEATHER-TYPE : [ COLOR-TYPE , black ] , [ OTHER-PROPERTIES , thicker ] , [ WEATHER-TYPE , fog ] Figure 5 : Output of the named concept extraction process .</sentence>
				<definiendum id="0">j\jDCk jmin ( jD w</definiendum>
				<definiendum id="1">DCk</definiendum>
				<definiens id="0">black thicker fog WEATHER-TYPE : [ COLOR-TYPE , black ] , [ OTHER-PROPERTIES , thicker ] , [ WEATHER-TYPE , fog ] Figure 5 : Output of the named concept extraction process</definiens>
			</definition>
			<definition id="11">
				<sentence>For both chunks the head semantic tag is propagated to the whole chunk for each concept Ck of the SAR ontology ; Ck2fincident , detection-means , status. . .g for each instance Ij of Ck ; Ij2fbroken , missing , overdue. . .gfor the concept incident for each synonym Si of Ij ; Si2fsmach , crack. . .gfor the instance broken sim ( w ( l ) ; Si ) = jDw ( l ) j\jDSijmin ( jD w ( l ) j ; jDSij ) end ~vj def= ( sim ( w ( l ) ; S1 ) ; : : : ; sim ( w ( l ) ; SNj ) ) sim ( w ( l ) ; Ij ) =mediane ( ~vj ) end ~vk def= ( sim ( w ( l ) ; I1 ) ; : : : ; sim ( w ( l ) ; IMk ) ) sim ( w ( l ) ; Ck ) =max ( ~vk ) end ~vw ( l ) def= ( sim ( w ( l ) ; C1 ) ; : : : ; sim ( w ( l ) ; CM ) ) Figure 6 : Similarity measure algorithm .</sentence>
				<definiendum id="0">end ~vk def=</definiendum>
				<definiens id="0">l ) ; CM ) ) Figure 6 : Similarity measure algorithm</definiens>
			</definition>
			<definition id="12">
				<sentence>Mean sim is the mean of the similarity scores .</sentence>
				<definiendum id="0">Mean sim</definiendum>
				<definiens id="0">the mean of the similarity scores</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>To circumvent this limitation of word-based similarity metrics , QA researchers have developed methods through which they first map questions and sentences that may contain answers in different spaces , and then compute the “similarity” between them there .</sentence>
				<definiendum id="0">QA</definiendum>
				<definiens id="0">researchers have developed methods through which they first map questions and sentences that may contain answers in different spaces</definiens>
			</definition>
			<definition id="1">
				<sentence>Being inspired by the success of noisy-channel-based approaches in applications as diverse as speech recognition ( Jelinek , 1997 ) , part of speech tagging ( Church , 1988 ) , machine translation ( Brown et al. , 1993 ) , information retrieval ( Berger and Lafferty , 1999 ) , and text summarization ( Knight and Marcu , 2002 ) , we develop a noisy channel model for QA .</sentence>
				<definiendum id="0">text summarization</definiendum>
				<definiens id="0">diverse as speech recognition ( Jelinek , 1997 ) , part of speech tagging ( Church , 1988 ) , machine translation ( Brown et al. , 1993 ) , information retrieval</definiens>
			</definition>
			<definition id="2">
				<sentence>Condition c ) brings the sentence closer to the question by compacting portions that are syntactically far from question terms and answer .</sentence>
				<definiendum id="0">Condition c )</definiendum>
				<definiens id="0">brings the sentence closer to the question by compacting portions that are syntactically far from question terms and answer</definiens>
			</definition>
			<definition id="3">
				<sentence>For the KM corpus , the relatively low MRRs are explained by two factors : ( i ) for this corpus , each evaluation pattern consists of only one string – the original answer ; ( ii ) the KM questions are more complex than TREC questions ( What piece of furniture is associated with Modred , Percival , Gawain , Arthur , and Lancelot ? )</sentence>
				<definiendum id="0">KM corpus</definiendum>
				<definiens id="0">explained by two factors : ( i ) for this corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>It is very interesting to see that system D outperforms significantly system C. This shows that , in our framework , in order to benefit from external databases , we do not need any additional machinery ( question classifiers , answer type identifiers , wrapper selectors , SQL query generators , etc. ) All we need is a one-time conversion of external structured resources to simple natural language factoids .</sentence>
				<definiendum id="0">SQL query generators</definiendum>
				<definiens id="0">a one-time conversion of external structured resources to simple natural language factoids</definiens>
			</definition>
</paper>

		<paper id="2028">
			<definition id="0">
				<sentence>Open-domain QA ( ODQA ) , which extracts answers from large text corpora , such as newspaper texts , has been intensively investigated in the Text REtrieval Conference ( TREC ) .</sentence>
				<definiendum id="0">Open-domain QA</definiendum>
				<definiendum id="1">Text REtrieval Conference</definiendum>
				<definiens id="0">extracts answers from large text corpora , such as newspaper texts</definiens>
			</definition>
			<definition id="1">
				<sentence>The structural ambiguity of the n-th phrase is defined as A D ( P n ) =log braceleftBig 1 − summationtext N i=1 : inegationslash=n D ( P i , P n ) bracerightBig , where the complete question is separated into N phrases , and D ( P i , P n ) is the probability that phrase P n will be modified by phrase P i , which can be calculated using Stochastic Dependency Context-Free Grammar ( SDCFG ) ( C. Hori et .</sentence>
				<definiendum id="0">structural ambiguity of the n-th phrase</definiendum>
				<definiendum id="1">D</definiendum>
				<definiendum id="2">D</definiendum>
				<definiendum id="3">P n )</definiendum>
				<definiens id="0">P n ) =log braceleftBig 1 − summationtext N i=1 : inegationslash=n D ( P i , P n ) bracerightBig , where the complete question is separated into N phrases</definiens>
				<definiens id="1">the probability that phrase P n will be modified by phrase P i , which can be calculated using Stochastic Dependency Context-Free Grammar ( SDCFG ) ( C. Hori et</definiens>
			</definition>
			<definition id="2">
				<sentence>The generality score is defined as A G ( P n ) = summationtext w∈P n : w=cont log P ( w ) , where P ( w ) is the unigram probability of w based on the corpus to be retrieved .</sentence>
				<definiendum id="0">generality score</definiendum>
				<definiendum id="1">P ( w )</definiendum>
				<definiens id="0">A G ( P n ) = summationtext w∈P n : w=cont log P ( w )</definiens>
				<definiens id="1">the unigram probability of w based on the corpus to be retrieved</definiens>
			</definition>
			<definition id="3">
				<sentence>The DDQ module selects the best DQ based on its linguistic appropriateness and the ambiguity of the phrase .</sentence>
				<definiendum id="0">DDQ module</definiendum>
				<definiens id="0">selects the best DQ based on its linguistic appropriateness and the ambiguity of the phrase</definiens>
			</definition>
			<definition id="4">
				<sentence>Let S mn be a DQ generated by inserting the n-th phrase into the m-th template .</sentence>
				<definiendum id="0">S mn</definiendum>
				<definiens id="0">a DQ generated by inserting the n-th phrase into the m-th template</definiens>
			</definition>
			<definition id="5">
				<sentence>Word acc. : word accuracy , SPK : speaker , AVG : averaged values , w/o errors : transcribed sentences without recognition errors , APP : appropriate DQs and InAPP : inappropriate DQs .</sentence>
				<definiendum id="0">APP</definiendum>
				<definiendum id="1">InAPP</definiendum>
				<definiens id="0">averaged values , w/o errors : transcribed sentences without recognition errors</definiens>
			</definition>
</paper>

		<paper id="2010">
			<definition id="0">
				<sentence>( Syn ) NP Clause ( Sem ) Moment/Extended Interval/Duration ( M ) ( EI ) ( D ) ( Syn ) A B C D E F semantic terms t1 t2 t3 t4 t5 t6 Figure 2 .</sentence>
				<definiendum id="0">Syn ) NP Clause ( Sem</definiendum>
				<definiens id="0">) Moment/Extended Interval/Duration ( M ) ( EI ) ( D ) ( Syn ) A B C D E F semantic terms t1 t2 t3 t4 t5 t6 Figure 2</definiens>
			</definition>
			<definition id="1">
				<sentence>DONGAN sentence construction rule As we mentioned above , one of the most important advantages of G Grammar consists of its capacity to establish semantic interpretations in a compositional way .</sentence>
				<definiendum id="0">DONGAN sentence construction rule</definiendum>
				<definiens id="0">one of the most important advantages of G Grammar consists of its capacity to establish semantic interpretations in a compositional way</definiens>
			</definition>
			<definition id="2">
				<sentence>Parsing tree of the example ( 11 ) ( sr1 ) [ 0,0,0,2,0 ] ( sr2 ) lb ( _24864 , duration * _24864 = [ 0,0,0,2,0 ] &amp; ending * _24864 &lt; [ 2003,2,14,19,32 ] ) ( sr3 ) lb ( _16476 , lb ( _15622 , of * kwangho * _15622 &amp; _16476 * _15622 ) ) ( sr4 ) lb ( _18330 , exist * y * ( of * kwangho * y &amp; airplane * y &amp; _18330 * y ) ) ( sr5 ) lb ( _18330 , exist * y * ( of * kwangho * y &amp; airplane * y &amp; _18330 * y ) ) ( sr6 ) lb ( _1682 , lb ( _1720 , exist * e * ( fly * e * _1720 &amp; beginning * e &lt; [ 2003,2,14,19,5 ] &amp; _1682 * e ) ) ) ( sr7 ) lb ( _4814 , exist * y * ( of * kwangho * y &amp; airplane * y &amp; exist * e * ( fly * e * y &amp; beginning * e &lt; [ 2003,2,14,19,7 ] &amp; _4814 * e ) ) ) ( sr8 ) lb ( _25184 , exist * y * ( of * kwangho * y &amp; airplane * y &amp; exist * e * ( fly * e * y &amp; beginning * e &lt; [ 2003,2,14,19,33 ] &amp; ( duration* e = [ 0,0,0,2,0 ] &amp; ending * e &lt; [ 2003,2,14,19,33 ] &amp; _25184 * e ) ) ) ) Figure 6 .</sentence>
				<definiendum id="0">sr1</definiendum>
				<definiens id="0">exist * y * ( of * kwangho * y &amp; airplane * y &amp; _18330 * y ) ) ( sr5 ) lb ( _18330 , exist * y * ( of * kwangho * y &amp; airplane * y &amp; _18330 * y ) ) ( sr6 ) lb ( _1682</definiens>
				<definiens id="1">] &amp; _4814 * e ) ) ) ( sr8 ) lb ( _25184 , exist * y * ( of * kwangho * y &amp; airplane * y &amp; exist * e *</definiens>
			</definition>
			<definition id="3">
				<sentence>( Syn ) NP Clause ( Sem ) Moment/Extended Interval/Duration ( M ) ( EI ) ( D ) ( Syn ) A B C D E F G H16 t1 t2 t3 t4 t5 t6 t7 t8 Figure 7 .</sentence>
				<definiendum id="0">Syn ) NP Clause ( Sem</definiendum>
				<definiens id="0">) Moment/Extended Interval/Duration ( M ) ( EI ) ( D ) ( Syn ) A B C D E F G H16 t1 t2 t3 t4 t5 t6</definiens>
			</definition>
</paper>

		<paper id="1068">
			<definition id="0">
				<sentence>FrameNet roles , which are local to particular frames ( abstract situations ) , may be better suited for the annotation task than the “classical” thematic roles concept with a small , universal and exhaustive set of roles like agent , patient , theme : The exact extension of the role concepts has never been agreed upon ( Fillmore , 1968 ) .</sentence>
				<definiendum id="0">FrameNet roles</definiendum>
				<definiens id="0">local to particular frames ( abstract situations</definiens>
			</definition>
			<definition id="1">
				<sentence>A lexicon database associates lemmas with the frames they evoke , lists possible syntactic realizations of FEs and provides annotated examples from the BNC .</sentence>
				<definiendum id="0">lexicon database associates</definiendum>
				<definiens id="0">lemmas with the frames they evoke , lists possible syntactic realizations of FEs and provides annotated examples from the BNC</definiens>
			</definition>
			<definition id="2">
				<sentence>Frame : REQUEST FE Example SPEAKER Pat urged me to apply for the job .</sentence>
				<definiendum id="0">Frame</definiendum>
				<definiens id="0">REQUEST FE Example SPEAKER Pat urged me to apply for the job</definiens>
			</definition>
			<definition id="3">
				<sentence>In the second phase , we will extend these tools for the weakly supervised annotation of a much larger corpus , using the TIGER corpus as training data .</sentence>
				<definiendum id="0">TIGER corpus</definiendum>
				<definiens id="0">the weakly supervised annotation of a much larger corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , the word “Gagenforderung” ( demand for wages ) consists of “-forderung” ( demand ) , which invokes the frame REQUEST , and a MESSAGE element “Gagen-” .</sentence>
				<definiendum id="0">word “Gagenforderung”</definiendum>
				<definiens id="0">invokes the frame REQUEST</definiens>
			</definition>
			<definition id="5">
				<sentence>MEDIUM is a member of the second group , and TOPIC was annotated at chance level ( 0 ) .</sentence>
				<definiendum id="0">MEDIUM</definiendum>
				<definiendum id="1">TOPIC</definiendum>
				<definiens id="0">a member of the second group , and</definiens>
			</definition>
			<definition id="6">
				<sentence>Without underspecification , CF is a single predicate and CE is a conjunction of predicates .</sentence>
				<definiendum id="0">CF</definiendum>
				<definiendum id="1">CE</definiendum>
				<definiens id="0">a single predicate</definiens>
				<definiens id="1">a conjunction of predicates</definiens>
			</definition>
			<definition id="7">
				<sentence>Exact agreement means that every conjunct of annotator A must correspond to a conjunct by annotator B , and vice versa .</sentence>
				<definiendum id="0">Exact agreement</definiendum>
				<definiens id="0">every conjunct of annotator A must correspond to a conjunct by annotator B , and vice versa</definiens>
			</definition>
			<definition id="8">
				<sentence>frame annotation F ( t ) single frame : F is assigned to t ( F1 ( t ) _F2 ( t ) ) frame disjunction : F1 or F2 is assigned to t frame element annotation E ( s ) single frame element : E is assigned to s ( E1 ( s ) _E2 ( s ) ) frame element disjunction : E1 or E2 is assigned to s ( E ( s ) _NOFE ( s ) ) optional element : E1 or no frame element is assigned to s ( E ( s ) _E ( s1ss2 ) ) underspecified length : frame element E is assigned to s or the longer sequence s1ss2 , which includes s Table 2 : Types of conjuncts .</sentence>
				<definiendum id="0">frame annotation F</definiendum>
				<definiens id="0">assigned to t frame element annotation E ( s ) single frame element : E is assigned to s ( E1 ( s ) _E2 ( s ) ) frame element disjunction</definiens>
				<definiens id="1">s ) _E ( s1ss2 ) ) underspecified length : frame element E is assigned to s or the longer sequence s1ss2 , which includes s Table 2 : Types of conjuncts</definiens>
			</definition>
			<definition id="9">
				<sentence>Introduction to WordNet : An on-line lexical database .</sentence>
				<definiendum id="0">WordNet</definiendum>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>All tasks that produce crossing edges , i.e. where one endpoint lies strictly inside the bracket pair and the other lies strictly outside , are penalised , e.g. , a task that combines edges A and B. This behaviour can be implemented efficiently when we assume that the computation of a task pri7 A parsing task encodes the possible combination of a passive and an active chart edge .</sentence>
				<definiendum id="0">parsing task</definiendum>
			</definition>
			<definition id="1">
				<sentence>CTD2D8 : Entropy of Parse Distribution While precision over bracket types is a static measure that is independent from the structural complexity of a particular sentence , tree entropy is defined as the entropy over the probability distribution of the set of parsed trees for a given sentence .</sentence>
				<definiendum id="0">tree entropy</definiendum>
				<definiens id="0">a static measure that is independent from the structural complexity of a particular sentence</definiens>
				<definiens id="1">the entropy over the probability distribution of the set of parsed trees for a given sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Evaluation measures For the task of identifying the perfect matches from a set of parses we give the following standard definitions : precision is the proportion of selected parses that have a perfect match – thus being the perfect match rate , and recall is the proportion of perfect matches that the system selected .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiendum id="1">recall</definiendum>
				<definiens id="0">the proportion of selected parses that have a perfect match – thus being the perfect match rate</definiens>
				<definiens id="1">the proportion of perfect matches that the system selected</definiens>
			</definition>
			<definition id="3">
				<sentence>Coverage is usually defined as the proportion of attempted analyses with at least one parse .</sentence>
				<definiendum id="0">Coverage</definiendum>
			</definition>
			<definition id="4">
				<sentence>Extracted NP and PP bracket constraints are defined as left-matching bracket types , to compensate for the non-embedding structure of chunks .</sentence>
				<definiendum id="0">Extracted NP</definiendum>
				<definiendum id="1">PP bracket constraints</definiendum>
			</definition>
			<definition id="5">
				<sentence>Even more , isolated use of chunk information ( row 11 ) does not yield signifi0 1000 2000 3000 4000 5000 6000 7000 0 5 10 15 20 25 30 35 baseline +PT γ ( 0.5 ) 12867 12520 11620 9290 0 100 200 300 400 500 600 # sentences msec Figure 5 : Performance gain/loss per sentence length cant gains over the baseline ( 0.89/1.1 ) .</sentence>
				<definiendum id="0">chunk information</definiendum>
			</definition>
</paper>

		<paper id="2016">
</paper>

		<paper id="2007">
			<definition id="0">
				<sentence>Representative weighting functions include such factors as term frequency , inverse document frequency , the product of the term and inverse document frequency , and length normalization ( Moens , 2000 ) .</sentence>
				<definiendum id="0">Representative weighting functions</definiendum>
				<definiens id="0">include such factors as term frequency , inverse document frequency , the product of the term and inverse document frequency , and length normalization</definiens>
			</definition>
			<definition id="1">
				<sentence>Inverse document frequency is inappropriate for a reference collection that changes frequently because the weight of an index term needs be recomputed .</sentence>
				<definiendum id="0">Inverse document frequency</definiendum>
				<definiens id="0">the weight of an index term needs be recomputed</definiens>
			</definition>
			<definition id="2">
				<sentence>Definition 2 ( Score of Noun ) Let NRkNi denotes the number of relations that noun Ni has with relation k. SRkNi represents the weight of relation k. Then the score SNOUN ( Ni ) of a noun Ni in a lexical chain is defined as : SNOUN ( Ni ) = X k ( NRkNi £SRkNi ) ( 2 ) where k 2 set of relations .</sentence>
				<definiendum id="0">NRkNi</definiendum>
				<definiens id="0">the number of relations that noun Ni has with relation k. SRkNi represents the weight of relation k. Then the score SNOUN ( Ni ) of a noun Ni in a lexical chain is defined as : SNOUN ( Ni ) = X k ( NRkNi £SRkNi ) ( 2 ) where k 2 set of relations</definiens>
			</definition>
			<definition id="3">
				<sentence>Definition 3 ( Score of Chain ) The score SCHAIN ( Chx ) of a chain Chx is defined as : SCHAIN ( Chx ) = nX i=1 SNOUN ( Ni ) +penalty ( 3 ) where SNOUN ( Ni ) is the score of noun Ni , and N1 ; : : : ; Nn 2 Chx .</sentence>
				<definiendum id="0">SNOUN ( Ni )</definiendum>
				<definiens id="0">the score of noun Ni</definiens>
			</definition>
			<definition id="4">
				<sentence>ΩWj represents the information quantity of a word .</sentence>
				<definiendum id="0">ΩWj</definiendum>
				<definiens id="0">the information quantity of a word</definiens>
			</definition>
			<definition id="5">
				<sentence>ΨCjT , ΨWjC and ΨWjT are defined as follows : ΨWjjCi = SNOUN ( Wj ) S CHAIN ( Ci ) = jWjjjC ij ( 8 ) ΨCijT = ΩCiΩ T = C 2i P k C2k ( 9 ) ΨWjjT = ΨWjjCi £ΨCijT = Wj ¢CiP k C2k ( 10 ) The weight of a word and a chain was given when forming lexical chains by definitions 2 and 3 .</sentence>
				<definiendum id="0">Wj ) S CHAIN</definiendum>
			</definition>
			<definition id="6">
				<sentence>ΨWjjCi denotes the information ratio of a word to the concept in which it is included .</sentence>
				<definiendum id="0">ΨWjjCi</definiendum>
				<definiens id="0">the information ratio of a word to the concept in which it is included</definiens>
			</definition>
			<definition id="7">
				<sentence>ΨCijT is the information ratio of a concept to the text .</sentence>
				<definiendum id="0">ΨCijT</definiendum>
			</definition>
			<definition id="8">
				<sentence>Definition 7 ( Semantic Index ) The semantic index that represents the content of a document is defined as follows : ΩWj ‚ fl ¢ 1m mX i=1 ( ΩWi ) ( 11 ) Although in both cases information quantity is the same , the relative importance of each word in a document differs according to the document information quantity .</sentence>
				<definiendum id="0">semantic index that</definiendum>
				<definiens id="0">represents the content of a document is defined as follows : ΩWj ‚ fl ¢ 1m mX i=1 ( ΩWi ) ( 11 ) Although in both cases information quantity is the same , the relative importance of each word in a document differs according to the document information quantity</definiens>
			</definition>
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>Within the generative model , the Bayes reformulation is used to estimate a31 a0a15a14a35a33a1a26a13a37a36 a31 a0a15a14a19a13 a31 a0a2a1a38a33a14a39a13 where a31 a0a15a14a39a13 is considered the language model , and a31 a0a2a1a38a33a14a19a13 is the translation model ; the IBM ( Brown et al. , 1993 ) models being the de facto standard .</sentence>
				<definiendum id="0">IBM</definiendum>
				<definiens id="0">the translation model</definiens>
			</definition>
			<definition id="1">
				<sentence>Building a phrasal lexicon involves Generation , Scoring , and Pruning steps , corresponding to generating a set of candidate translation pairs , scoring them based on the translation model , and pruning them to account for noise within the data as well as the extraction process .</sentence>
				<definiendum id="0">phrasal lexicon</definiendum>
				<definiens id="0">involves Generation , Scoring , and Pruning steps , corresponding to generating a set of candidate translation pairs , scoring them based on the translation model</definiens>
			</definition>
			<definition id="2">
				<sentence>The generation task is formally defined as finding a21a41a62a61 in Equation ( 1 ) a21 a41 a61 a1a6a63a64a14a58a65 a41a43a42 a0a15a44a39a45a39a46a54a47a12a45a49a48a66a45a39a46a67a50a68a13a70a69 a21 a41 a45 a31a71a57 a7a9a7a9a7 a31 a57a51a72a8a73a75a74 a3 a25 ( 1 ) where a25 is the source n-gram for which we are extracting translations , a21a41 is the set of all partitions , anda31a76a57 refers to the word at position a44 in the source sentence a31 .</sentence>
				<definiendum id="0">a21a41</definiendum>
				<definiendum id="1">anda31a76a57</definiendum>
				<definiens id="0">finding a21a41a62a61 in Equation ( 1 ) a21 a41 a61 a1a6a63a64a14a58a65 a41a43a42 a0a15a44a39a45a39a46a54a47a12a45a49a48a66a45a39a46a67a50a68a13a70a69 a21 a41 a45 a31a71a57 a7a9a7a9a7 a31 a57a51a72a8a73a75a74 a3 a25 ( 1 ) where a25 is the source n-gram for which we are extracting translations</definiens>
			</definition>
			<definition id="3">
				<sentence>a21a41 a61 is then the set of all translations for source n-gram a25 , and a77 is a specific translation hypothesis within this set .</sentence>
				<definiendum id="0">a77</definiendum>
				<definiens id="0">the set of all translations for source n-gram a25 , and</definiens>
				<definiens id="1">a specific translation hypothesis within this set</definiens>
			</definition>
			<definition id="4">
				<sentence>a56a89a88a91a90a26a23a6a92a35a125 a47a96a0 a77 a13a126a3 a40 a5 a127 a99a129a128 a130a34a131a34a132a134a133a101a135 a0 a77 a45a71a136 a77 a13 ( 6 ) where a133a101a135 calculates the Levenshein distance between the target phrases within two hypothesisa77 and a136 a77 , a137 is the number of elements in a21 a41 a61 .</sentence>
				<definiendum id="0">a133a101a135</definiendum>
				<definiendum id="1">a137</definiendum>
				<definiens id="0">the number of elements in a21 a41 a61</definiens>
			</definition>
			<definition id="5">
				<sentence>We build a sentence length model based on the DiffRatio statistic defined as a135 a44a55a147a37a147a8a148 a22 a14a52a44a90 a3 a11a91a149 a18 a18 where I is the source sentence length and J is the target sentence length .</sentence>
				<definiendum id="0">J</definiendum>
				<definiens id="0">a sentence length model based on the DiffRatio statistic defined as a135 a44a55a147a37a147a8a148 a22 a14a52a44a90 a3 a11a91a149 a18 a18 where I is the source sentence length and</definiens>
			</definition>
			<definition id="6">
				<sentence>In order to compare our method to a well understood phrase baseline , we present a method that exa137a134a22a24a27a85a92 a159 a22 a44 a23 a1 a173 a77 a44 a60a152a92 a1 a92 a174a43a60a8a25 a46a54a44a52a1 a77 Small 3540 90K 115K Large 77558 2.46M 2.69M Testing 993 27K NA Table 1 : Corpus figures indicating no. of sentence pairs , no. of Chinese and English words tracts phrases by harvesting the Viterbi path from an HMM alignment model ( Vogel et al. , 1996 ) .</sentence>
				<definiendum id="0">Corpus</definiendum>
				<definiens id="0">figures indicating no. of sentence pairs</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>• Automated question answering systems ( Voorhees &amp; Buckland , 2002 ) require the ability to tag and index text corpora with the relevant commonsense psychology concepts in order to handle questions concerning the beliefs , expectations , and intentions of people .</sentence>
				<definiendum id="0">Automated question answering systems</definiendum>
				<definiens id="0">the ability to tag and index text corpora with the relevant commonsense psychology concepts in order to handle questions concerning the beliefs , expectations , and intentions of people</definiens>
			</definition>
			<definition id="1">
				<sentence>To simplify the authoring of these local grammars , Intex includes a large-coverage English dictionary compiled by Blandine Courtois , allowing us to specify them at a level that generalized over noun and verb forms .</sentence>
				<definiendum id="0">Intex</definiendum>
				<definiens id="0">includes a large-coverage English dictionary compiled by Blandine Courtois , allowing us to specify them at a level that generalized over noun and verb forms</definiens>
			</definition>
			<definition id="2">
				<sentence>Precision and recall results on the unfiltered data set Concept areaInter-rater agreement ( K ) Correct Hits ( a ) Wrong hits ( b ) Total positive sentences ( c ) Total negative sentences Precision ( a/ ( a+b ) ) Recall ( a/c ) Managing knowledge0.563614112 168 259 92.15 % 83.92 % Memory0.80692090 221 290 100 % 94.57 % Explanations0.713883 5 120 290 94.21 % 69.16 % Similarity judgments0.655113612 189 284 91.89 % 71.95 % Table 2 .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">a ) Wrong hits ( b ) Total positive sentences ( c ) Total negative sentences Precision ( a/ ( a+b ) ) Recall</definiens>
			</definition>
</paper>

		<paper id="2036">
			<definition id="0">
				<sentence>The grammar conversion consists of a conversion of LTAG elementary trees to HPSG lexical entries and an emulation of substitution and adjunction by SN P V P V N P SN P V P V S5 .</sentence>
				<definiendum id="0">grammar conversion</definiendum>
			</definition>
			<definition id="1">
				<sentence>An LTAG elementary tree is first converted into canonical elementary trees which have only one anchor and whose subtrees of depth n ( ‚1 ) contain at least one anchor .</sentence>
				<definiendum id="0">LTAG elementary tree</definiendum>
				<definiens id="0">canonical elementary trees which have only one anchor and whose subtrees of depth n ( ‚1 ) contain at least one anchor</definiens>
			</definition>
			<definition id="2">
				<sentence>A CFG is obtained by regarding each initial and generated feature structures as nonterminals and transition relations between them as CFG rules .</sentence>
				<definiendum id="0">CFG</definiendum>
			</definition>
			<definition id="3">
				<sentence>Table 1 : The size of extracted LTAGs ( tree templates ) and approximated CFGs ( above : the number of nonterminals ; below : the number of rules ) Grammar G2 G2-4 G2-6 G2-8 G2-10 G2-21 LTAG 1,488 2,412 3,139 3,536 3,999 6,085 CFGPB 65 66 66 66 67 67 716 954 1,090 1,158 1,229 1,552 CFGTNT 1,989 3,118 4,009 4,468 5,034 7,454 18,323 35,541 50,115 58,356 68,239 118,464 Table 2 : Parsing performance ( sec . )</sentence>
				<definiendum id="0">CFGs</definiendum>
				<definiens id="0">The size of extracted LTAGs ( tree templates</definiens>
			</definition>
			<definition id="4">
				<sentence>cal structures where adjunction takes place between them .</sentence>
				<definiendum id="0">adjunction</definiendum>
				<definiens id="0">takes place between them</definiens>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>( S means a system utterance and U a user utterance .</sentence>
				<definiendum id="0">S</definiendum>
				<definiens id="0">means a system utterance</definiens>
			</definition>
			<definition id="1">
				<sentence>A frame is a bundle of slots that consist of attributevalue pairs concerning a certain domain .</sentence>
				<definiendum id="0">frame</definiendum>
				<definiens id="0">a bundle of slots that consist of attributevalue pairs concerning a certain domain</definiens>
			</definition>
			<definition id="2">
				<sentence>In this case , we define the score of a dialogue state S t+1 as S t+1 = S t + α · s act + β · s ngram + γ · s col where S t is the score of a dialogue state just before the update , s act the score of a dialogue act , s ngram the score concerning the probability of a dialogue act type sequence , s col the score concerning the collocation probability of dialogue states and dialogue acts , and α , β , and γ are the weighting factors .</sentence>
				<definiendum id="0">t</definiendum>
				<definiendum id="1">γ</definiendum>
				<definiens id="0">S t+1 = S t + α · s act + β · s ngram + γ · s col where S</definiens>
				<definiens id="1">s act the score of a dialogue act , s ngram the score concerning the probability of a dialogue act type sequence , s col the score concerning the collocation probability of dialogue states and dialogue acts , and α , β , and</definiens>
			</definition>
</paper>

		<paper id="1038">
			<definition id="0">
				<sentence>For example , for a given word sequence , part-of-speech ( POS ) tagging involves finding an optimal sequence of syntactic classes , and NP chunking involves finding IOB tag sequences ( each of which represents the inside , outside and beginning of noun phrases respectively ) .</sentence>
				<definiendum id="0">NP chunking</definiendum>
				<definiens id="0">involves finding IOB tag sequences ( each of which represents the inside , outside and beginning of noun phrases respectively )</definiens>
			</definition>
			<definition id="1">
				<sentence>Many machine learning techniques have been developed to tackle such random process tasks , which include Hidden Markov Models ( HMMs ) ( Rabiner , 1989 ) , Maximum Entropy Models ( MEs ) ( Ratnaparkhi , 1996 ) , Support Vector Machines ( SVMs ) ( Vapnik , 1998 ) , etc .</sentence>
				<definiendum id="0">Maximum Entropy Models</definiendum>
				<definiendum id="1">Support Vector Machines ( SVMs )</definiendum>
				<definiens id="0">include Hidden Markov Models ( HMMs )</definiens>
			</definition>
			<definition id="2">
				<sentence>T ( w1 ; k ) = arg maxt 1 ; k P ( t1 ; kjw1 ; k ) ( 1 ) = arg maxt 1 ; k P ( t1 ; k ) P ( w1 ; kjt1 ; k ) ( 2 ) arg maxt 1 ; k kY i=1 P ( tijti 1 ) P ( wijti ) ( 3 ) By applying Bayes’ formula and eliminating a redundant term not affecting the argument maximization , we can obtain equation ( 2 ) which is a combination of two separate models : the tag language model , P ( t1 ; k ) and the tag-to-word translation model , P ( w1 ; kjt1 ; k ) .</sentence>
				<definiendum id="0">k P</definiendum>
			</definition>
			<definition id="3">
				<sentence>On the left hand side is the graph representation of the Markov model and on the right hand side is the decision tree representation , where the test for the immediately preceding syntactic class ( represented by P-1 ) is placed on the root , each branch represents a result of the test ( which is labeled on the arc ) , and the corresponding leaf node contains the probabilistic distribution of the syntactic classes for the current position2 .</sentence>
				<definiendum id="0">corresponding leaf node</definiendum>
				<definiens id="0">a result of the test ( which is labeled on the arc )</definiens>
			</definition>
			<definition id="4">
				<sentence>SDTL is a greedy algorithm where at each time of the node making phase the most informative feature is selected ( line 2 ) , and it is a recursive algorithm in the sense that the algorithm is called recursively to make child nodes ( line 3 ) , Though theoretically any statistical decision tree growing algorithms can be used to train selforganizing Markov models , there are practical problems we face when we try to apply the algorithms to language learning problems .</sentence>
				<definiendum id="0">SDTL</definiendum>
				<definiens id="0">a greedy algorithm where at each time of the node making phase the most informative feature is selected</definiens>
			</definition>
			<definition id="5">
				<sentence>Algorithm 1 : SDTL ( E , t , F ) Data : E : set of examples , t : target feature , F : set of contextual features Result : Statistical Decision Tree predicting t initialize a null node ; for each element f in the set F do 1 sort meaningful value set V for f ; if jV j &gt; 1 then 2 measure the contribution of f to t ; if f contributes the most then select f as the best feature b ; end end end if there is b selected then set the current node to an internal node ; set b as the test feature of the current node ; 3 for each v in jV j for b do make SDTL ( Eb=v , t , F fbg ) as the subtree for the branch corresponding to v ; end end else set the current node to a leaf node ; 4 store the probability distribution of t over E ; end return current node ; 1,289,20168,590Total 129,1006,859Test 1,160,10161,731Training Figure 6 : Basic statistics of corpora the following 6 approximations : P ( t1 ; k ) kY i=1 P ( tijti 1 ) ( 8 ) kY i=1 P ( tijti 2 ; i 1 ) ( 9 ) kY i=1 P ( tij ( ti 2 ; i 1 ) ) ( 10 ) kY i=1 P ( tij ( ti 1 ; wi 1 ) ) ( 11 ) kY i=1 P ( tij ( ti 2 ; i 1 ; wi 1 ) ) ( 12 ) kY i=1 P ( tij ( ti 2 ; i 1 ; wi 2 ; i 1 ) ) ( 13 ) Equation ( 8 ) and ( 9 ) represent firstand secondorder Markov models respectively .</sentence>
				<definiendum id="0">SDTL</definiendum>
				<definiens id="0">set the current node to an internal node ; set b as the test feature of the current node</definiens>
				<definiens id="1">the subtree for the branch corresponding to v ; end end else set the current node to a leaf node ; 4 store the probability distribution of t over E</definiens>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>A slightly simplified such grammar is given in ( 3 ) , presented in a PATR-IIstyle notation:3 ( 3 ) a. X0 a0 X1 X2 a1 X1 CAT a2 = PREFIX a1 X0 CAT a2 = a1 X1 MOTHER-CAT a2 a1 X0 COMPLEXITY a2 = PREFIX-DERIVED a1 X1 SELECTION a2 = X2 b. X0 a0 X1 X2 a1 X2 CAT a2 = SUFFIX a1 X0 CAT a2 = a1 X2 MOTHER-CAT a2 a1 X0 COMPLEXITY a2 = SUFFIX-DERIVED a1 X2 SELECTION a2 = X1 2Of course , not the true ethymology is relevant here ; ORIGIN is a category in the synchronic grammar of speakers , and for individual morphemes it may or may not be in accordance with diachronic facts .</sentence>
				<definiendum id="0">ORIGIN</definiendum>
				<definiens id="0">relevant here ;</definiens>
				<definiens id="1">a category in the synchronic grammar of speakers , and for individual morphemes it may or may not be in accordance with diachronic facts</definiens>
			</definition>
			<definition id="1">
				<sentence>While this can be conceivably done , it restricts the applicability of the resulting overall system , since many higher-level applications presuppose a finite-state analyzer ; this is for instance the case for the Xerox Linguistic Environment ( http : //www.parc.com/istl/groups/nltt/xle/ ) , a development platform for syntactic Lexical-Functional Grammars ( Butt et al. 1999 ) .</sentence>
				<definiendum id="0">Linguistic Environment ( http</definiendum>
				<definiens id="0">instance the case for the Xerox</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>Coreference resolution is the process of linking together multiple expressions of a given entity .</sentence>
				<definiendum id="0">Coreference resolution</definiendum>
				<definiens id="0">the process of linking together multiple expressions of a given entity</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , “Closest-First” ( Soon et al. , 2001 ) selects the candidate closest to the anaphor , while “Best-First” ( Aone and Bennett , 1995 ; Ng and Cardie , 2002a ) selects the candidate with the maximal confidence value .</sentence>
				<definiendum id="0">“Closest-First”</definiendum>
				<definiens id="0">selects the candidate closest to the anaphor</definiens>
				<definiens id="1">selects the candidate with the maximal confidence value</definiens>
			</definition>
			<definition id="2">
				<sentence>Consider an anaphor ana and its candidate set candidate_set , { C 1 , C 2 , … , C k } , where C j is closer to ana than C i if j &gt; i. Suppose positive_set is the set of candidates that occur in the coreferential chain of ana , and negative_set is the set of candidates not in the chain , that is , negative_set = candidate_set positive_set .</sentence>
				<definiendum id="0">negative_set</definiendum>
				<definiens id="0">the set of candidates that occur in the coreferential chain of ana , and</definiens>
			</definition>
			<definition id="3">
				<sentence>The set of training instances based on ana , inst_set , is defined as follows : 2 Suppose we use C4.5 algorithm and the class value takes the smoothed ration , 2 1 + + t p , where p is the number of positive instances and t is the total number of instances contained in the corresponding leaf node. }</sentence>
				<definiendum id="0">p</definiendum>
			</definition>
			<definition id="4">
				<sentence>Algorithm ANTE-SEL Input : ana : the anaphor under consideration candidate_set : the set of antecedent candidates of ana , { C 1 , C 2 , … , C k } for i = 1 to K do Score [ i ] = 0 ; for i = K downto 2 do for j = i – 1 downto 1 do if CR ( ) ana , cj , ci ( inst ) = = positive then Score [ i ] ++ ; else Score [ j ] ++ ; endif SelectedIdx= ] [ maxarg _ iScore setcandidateCi i ∈ return C selectedIdx ; Figure 1 : The antecedent identification algorithm Algorithm ANTE-SEL takes as input an anaphor and its candidate set candidate_set , and returns one candidate as its antecedent .</sentence>
				<definiendum id="0">ci</definiendum>
				<definiens id="0">The antecedent identification algorithm Algorithm ANTE-SEL takes as input an anaphor and its candidate set candidate_set , and returns one candidate as its antecedent</definiens>
			</definition>
			<definition id="5">
				<sentence>The recall measures the number of correctly resolved anaphors over the total anaphors in the MUC test data set , and the precision measures the number of correct anaphors over the total resolved anaphors .</sentence>
				<definiendum id="0">recall</definiendum>
				<definiens id="0">measures the number of correctly resolved anaphors over the total anaphors in the MUC test data set , and the precision measures the number of correct anaphors over the total resolved anaphors</definiens>
			</definition>
			<definition id="6">
				<sentence>The F-measure F=2*RP/ ( R+P ) is the harmonic mean of precision and recall .</sentence>
				<definiendum id="0">F-measure F=2*RP/</definiendum>
				<definiens id="0">the harmonic mean of precision and recall</definiens>
			</definition>
</paper>

		<paper id="1046">
			<definition id="0">
				<sentence>In the following derivation , Smith is the subject of resigned and of left : CBCJCSCRD0CL C6C8 C6 Smith CBCJCSCRD0CLD2C6C8 CBCJCSCRD0CLD2C6C8 resigned CBCJCSCRD0CLD2C6C8CJCRD3D2CYCL CRD3D2CY and CBCJCSCRD0CLD2C6C8 left In order to express both dependencies , Smith has to be conditioned on resigned and on left : C8B4DBBPSmithCY C6BNCWCWCBCJCSCRD0CLD2C6C8BN resignedCXBNBDBNCWC6BNDBCXCXBN CWCWCBCJCSCRD0CLD2C6C8BN leftCXBNBDBNCWC6BNDBCXCXB5 In terms of the predicate-argument structure , resigned and left are both lexical heads of this sentence .</sentence>
				<definiendum id="0">Smith</definiendum>
				<definiens id="0">the subject of resigned and of left : CBCJCSCRD0CL C6C8 C6 Smith CBCJCSCRD0CLD2C6C8 CBCJCSCRD0CLD2C6C8 resigned CBCJCSCRD0CLD2C6C8CJCRD3D2CYCL CRD3D2CY and CBCJCSCRD0CLD2C6C8</definiens>
			</definition>
</paper>

		<paper id="1049">
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>The translation model links the source language sentence to the target language sentence .</sentence>
				<definiendum id="0">translation model</definiendum>
				<definiens id="0">links the source language sentence to the target language sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The argmax operation denotes the search problem , i.e. the generation of the output sentence in the target language .</sentence>
				<definiendum id="0">argmax operation</definiendum>
				<definiens id="0">the search problem , i.e. the generation of the output sentence in the target language</definiens>
			</definition>
			<definition id="2">
				<sentence>Here , Qjl ; jr ; eb ; et denotes the probability of the best hypothesis translating the source words from position jl ( left ) to position jr ( right ) which begins with the target language word eb ( bottom ) and ends with the word et ( top ) .</sentence>
				<definiendum id="0">et</definiendum>
				<definiens id="0">the probability of the best hypothesis translating the source words from position jl ( left ) to position jr ( right ) which begins with the target language word eb ( bottom ) and ends with the word et ( top )</definiens>
			</definition>
			<definition id="3">
				<sentence>Therefore , Q0jl ; jr ; eb ; et denotes the probability of the best monotone hypothesis of IBM Model 4 .</sentence>
				<definiendum id="0">et</definiendum>
				<definiens id="0">the probability of the best monotone hypothesis of IBM Model 4</definiens>
			</definition>
			<definition id="4">
				<sentence>Here , J is the length of the source sentence and E is the vocabulary size of the target language .</sentence>
				<definiendum id="0">J</definiendum>
				<definiendum id="1">E</definiendum>
				<definiens id="0">the length of the source sentence and</definiens>
				<definiens id="1">the vocabulary size of the target language</definiens>
			</definition>
			<definition id="5">
				<sentence>A word graph is a directed acyclic graph ( dag ) with one start and one end node .</sentence>
				<definiendum id="0">word graph</definiendum>
				<definiens id="0">a directed acyclic graph</definiens>
			</definition>
			<definition id="6">
				<sentence>[ AA ] j hAAi j f=e j f=† j †=e Here , [ AA ] denotes a monotone concatenation and hAAi denotes an inverted concatenation .</sentence>
				<definiendum id="0">hAAi</definiendum>
				<definiens id="0">an inverted concatenation</definiens>
			</definition>
			<definition id="7">
				<sentence>† PER ( position-independent word error rate ) : A shortcoming of the WER is the fact that it requires a perfect word order .</sentence>
				<definiendum id="0">† PER</definiendum>
				<definiendum id="1">WER</definiendum>
				<definiens id="0">the fact that it requires a perfect word order</definiens>
			</definition>
			<definition id="8">
				<sentence>The PER compares the words in the two sentences ignoring the word order .</sentence>
				<definiendum id="0">PER</definiendum>
				<definiens id="0">compares the words in the two sentences ignoring the word order</definiens>
			</definition>
			<definition id="9">
				<sentence>† mWER ( multi-reference word error rate ) : For each test sentence , not only a single reference translation is used , as for the WER , but a whole set of reference translations .</sentence>
				<definiendum id="0">† mWER</definiendum>
				<definiens id="0">For each test sentence</definiens>
			</definition>
			<definition id="10">
				<sentence>† SSER ( subjective sentence error rate ) : For a more detailed analysis , subjective judgments by test persons are necessary .</sentence>
				<definiendum id="0">† SSER</definiendum>
				<definiens id="0">subjective sentence error rate ) : For a more detailed analysis , subjective judgments by test persons are necessary</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>Careful parameterization of the probability model allows it to be estimated at no additional cost in computational complexity .</sentence>
				<definiendum id="0">Careful parameterization of the probability model</definiendum>
				<definiens id="0">allows it to be estimated at no additional cost in computational complexity</definiens>
			</definition>
			<definition id="1">
				<sentence>The computation of inside probabilities , outlined below , considers possible reordering of nodes in the original tree in a bottom-up manner : for all nodes `` i in input tree T do for all k ; l such that 1 &lt; k &lt; l &lt; Ndo for all orderings of the children `` 1 : : : '' m of `` i do for all partitions of span k ; l into k 1 ; l 1 : : : k m ; l m do ( `` i ; k ; l ) += P order ( j '' i ) Q m j=1 ( `` j ; k j ; l j ) end for end for end for end for This algorithm has computational complexity O ( jTjN m+2 ) , where m is the maximum number of children of any node in the input tree T , and N the length of the input string .</sentence>
				<definiendum id="0">l j</definiendum>
				<definiens id="0">the maximum number of children of any node in the input tree T , and N the length of the input string</definiens>
			</definition>
			<definition id="2">
				<sentence>The probability of adding a clone of original node `` i as a child of node `` j is calculated in two steps : first , the choice of whether to insert a clone under `` j , with probability P ins ( clonej '' j ) , and the choice of which original node to copy , with probability P clone ( `` i jclone =1 ) = P makeclone ( `` i ) P k P makeclone ( `` k ) where P makeclone is the probability of an original node producing a copy .</sentence>
				<definiendum id="0">P makeclone</definiendum>
				<definiens id="0">the probability of an original node producing a copy</definiens>
			</definition>
			<definition id="3">
				<sentence>In our implementation , for simplicity , P ins ( clone ) is a single number , estimated by the EM algorithm but not conditioned on the parent node `` j , and P makeclone is a constant , meaning that the node to be copied is chosen from all the nodes in the original tree with uniform probability .</sentence>
				<definiendum id="0">P makeclone</definiendum>
				<definiens id="0">a constant , meaning that the node to be copied is chosen from all the nodes in the original tree with uniform probability</definiens>
			</definition>
			<definition id="4">
				<sentence>Korean is an agglutinative language , and words often contain sequences of meaning-bearing suffixes .</sentence>
				<definiendum id="0">Korean</definiendum>
				<definiens id="0">an agglutinative language</definiens>
			</definition>
			<definition id="5">
				<sentence>“Tree-to-String” is the model of Yamada and Knight ( 2001 ) , and “Tree-to-String , Clone” allows the node cloning operation of Section while “Tree-to-Tree , Clone” adds the node cloning operation of Section 3.1 .</sentence>
				<definiendum id="0">“Tree-to-String”</definiendum>
				<definiendum id="1">Clone”</definiendum>
			</definition>
</paper>

		<paper id="2035">
</paper>

		<paper id="2039">
			<definition id="0">
				<sentence>The POS tag from the output of morphological analysis is subcategorized to include the position of the character in the word .</sentence>
				<definiendum id="0">POS tag</definiendum>
				<definiens id="0">the position of the character in the word</definiens>
			</definition>
			<definition id="1">
				<sentence>Basically we would like to classify the characters into 3 categories , B ( beginning of a chunk ) , I ( inside a chunk ) and O ( outside a chunk ) .</sentence>
				<definiendum id="0">B ( beginning</definiendum>
				<definiendum id="1">O</definiendum>
				<definiens id="0">of a chunk</definiens>
				<definiens id="1">inside a chunk</definiens>
				<definiens id="2">outside a chunk )</definiens>
			</definition>
			<definition id="2">
				<sentence>POS ( best ) Family Name Chunk i 2 a18 n-S Y B i 1 a19 Ag-S N I i a20 Ng-S N I i + 1 a21 n-B N O i + 2 a22 n-E Y O Figure 1 : An illustration of chunking process ‘President Jiang Zemin’ a23 /u a24a7a25 /n” ( The things that Deng Yingchao used before death ) , the system was able to correctly retrieve the name “a2 a3a26a4 ” although the last character is part of a known word “a4a11a6 ” .</sentence>
				<definiendum id="0">POS</definiendum>
				<definiens id="0">An illustration of chunking process ‘President Jiang Zemin’ a23 /u a24a7a25 /n” ( The things that Deng Yingchao used before death ) , the system was able to correctly retrieve the name “a2 a3a26a4 ” although the last character is part of a known word “a4a11a6 ”</definiens>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>Log-linear Models Let us assume that we are given a source ( ‘French’ ) sentence a0a2a1a4a3a6a5a7 a1a8a3 a7a10a9a10a11a10a11a10a11a12a9 a3a10a13 a9a10a11a10a11a10a11a14a9 a3 a5 , which is to be translated into a target ( ‘English’ ) sentence a15 a1a17a16a19a18 a7 a1a20a16 a7 a9a10a11a10a11a10a11a14a9 a16a10a21 a9a10a11a10a11a10a11a12a9 a16 a18 a11 Among all possible target sentences , we will choose the sentence with the highest probability:1 a22 a15a24a23 a0a26a25a27a1 a28a30a29a32a31a34a33a35a28a26a36 a37 a38 Pra23a39a15a41a40 a0a26a25a43a42 ( 1 ) The argmax operation denotes the search problem , i.e. the generation of the output sentence in the target language .</sentence>
				<definiendum id="0">argmax operation</definiendum>
				<definiens id="0">given a source ( ‘French’ ) sentence a0a2a1a4a3a6a5a7 a1a8a3 a7a10a9a10a11a10a11a10a11a12a9 a3a10a13 a9a10a11a10a11a10a11a14a9 a3 a5 , which is to be translated into a target ( ‘English’ ) sentence a15 a1a17a16a19a18 a7 a1a20a16 a7 a9a10a11a10a11a10a11a14a9 a16a10a21 a9a10a11a10a11a10a11a12a9 a16 a18 a11 Among all possible target sentences , we will choose the sentence with the highest probability:1 a22 a15a24a23 a0a26a25a27a1 a28a30a29a32a31a34a33a35a28a26a36 a37 a38 Pra23a39a15a41a40 a0a26a25a43a42</definiens>
				<definiens id="1">the search problem , i.e. the generation of the output sentence in the target language</definiens>
			</definition>
			<definition id="1">
				<sentence>a45 NIST score : This criterion computes a weighted precision of a46 -grams between a hypothesis and a set of reference translations multiplied by a factor BP’a23a48a47a25 that penalizes short sentences : NIST a1 BP’a23a48a47a25 a47 a54 a38 a56 a21 a7a1a0 a56 Here a0 a56 denotes the weighted precision of a46 grams in the translation .</sentence>
				<definiendum id="0">NIST score</definiendum>
			</definition>
			<definition id="2">
				<sentence>Note , that the resulting objective function might still have local optima , which makes the optimization hard compared to using the objective function of Eq .</sentence>
				<definiendum id="0">local optima</definiendum>
			</definition>
			<definition id="3">
				<sentence>The loss function is either identical or closely related to the final evaluation criterion .</sentence>
				<definiendum id="0">loss function</definiendum>
				<definiens id="0">either identical or closely related to the final evaluation criterion</definiens>
			</definition>
</paper>

		<paper id="2037">
			<definition id="0">
				<sentence>The method consists of two components : ( 1 ) the check list of the grammar elements that should be detected ; and ( 2 ) the detector , which is a search program of the grammar elements from a sentence .</sentence>
				<definiendum id="0">detector</definiendum>
				<definiens id="0">a search program of the grammar elements from a sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The detector is a program that searches the check items in a sentence .</sentence>
				<definiendum id="0">detector</definiendum>
				<definiens id="0">a program that searches the check items in a sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>An example pair consists of an example sentence and an instance of the grammar element .</sentence>
				<definiendum id="0">example pair</definiendum>
				<definiens id="0">consists of an example sentence and an instance of the grammar element</definiens>
			</definition>
			<definition id="3">
				<sentence>Instance1 hiroku�XnaisMdesupb ( is not large ) The instance�XsMpb/hirokunaidesu/ consists of three morphemes : ( 1 ) �X/hiroku/ , the adjective means ‘large’ in renyo form , ( 2 ) sM/nai/ , the adjective means ‘not’ in root form , and ( 3 ) pb/desu/ , the auxiliary verb ends a sentence politely .</sentence>
				<definiendum id="0">Instance1 hiroku�XnaisMdesupb</definiendum>
				<definiens id="0">three morphemes : ( 1 ) �X/hiroku/ , the adjective means ‘large’ in renyo form , ( 2 ) sM/nai/ , the adjective means ‘not’ in root form</definiens>
			</definition>
			<definition id="4">
				<sentence>np ( 4 , ’Adjective ( predicative , negative , polite ) ’ , Dm ( { H1= &gt; ’Adjective’ , K2= &gt; ’Basic Renyou Form’ } , { G= &gt; ’sM/nai/’ , H1= &gt; ’Postfix’ , K2= &gt; ’Root Form’ } , { G= &gt; ’pb/desu/’ , H1= &gt; ’Auxiliary Verb’ } ) ) ; The function np ( ) makes the declaration of the rule , and the functionDm ( ) describes a morphological sequential pattern which matches the target .</sentence>
				<definiendum id="0">’Adjective</definiendum>
				<definiendum id="1">functionDm ( )</definiendum>
				<definiens id="0">describes a morphological sequential pattern which matches the target</definiens>
			</definition>
			<definition id="5">
				<sentence>np ( 4 , ’Adjective in Root Form’ , Db ( { H1= &gt; ’Adjective’ , K2= &gt; ’Root Form’ } ) ) ; The function Db ( ) describes a pattern which matches a bunsetsu which consists of specified morphemes .</sentence>
				<definiendum id="0">function Db ( )</definiendum>
				<definiens id="0">describes a pattern which matches a bunsetsu which consists of specified morphemes</definiens>
			</definition>
</paper>

		<paper id="2006">
			<definition id="0">
				<sentence>The Match column is the number of times a pattern actually occurs in the corpus ( whether it introduces a non-local dependency or not ) .</sentence>
				<definiendum id="0">Match column</definiendum>
				<definiens id="0">the number of times a pattern actually occurs in the corpus ( whether it introduces a non-local dependency or not )</definiens>
			</definition>
			<definition id="1">
				<sentence>Table 1 shows the results for some of the most frequent patterns , using conventional metrics : precision ( the fraction of the correctly labeled dependencies among all the dependencies found ) , recall ( the fraction of the correctly found dependencies among all the dependencies with a given label ) and f-score ( harmonic mean of precision and recall ) .</sentence>
				<definiendum id="0">precision</definiendum>
				<definiens id="0">the fraction of the correctly labeled dependencies among all the dependencies found ) , recall ( the fraction of the correctly found dependencies among all the dependencies with a given label</definiens>
			</definition>
			<definition id="2">
				<sentence>A parsing accuracy evaluation scheme based on grammatical relations ( GR ) , presented in ( Briscoe et al. , 2002 ) , provides a set of dependency labels ( grammatical relations ) and a manually annotated dependency corpus .</sentence>
				<definiendum id="0">GR</definiendum>
				<definiens id="0">provides a set of dependency labels ( grammatical relations ) and a manually annotated dependency corpus</definiens>
			</definition>
</paper>

		<paper id="1040">
			<definition id="0">
				<sentence>Also , the test corpus contains all detected NP/PPs , even untranslatable ones , as discussed in Section 2.2 .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiens id="0">contains all detected NP/PPs</definiens>
			</definition>
			<definition id="1">
				<sentence>Language modeling can be improved by different types of language models ( e.g. , syntactic language models ) , or additional training data for the language model .</sentence>
				<definiendum id="0">Language modeling</definiendum>
				<definiens id="0">language models ( e.g. , syntactic language models ) , or additional training data for the language model</definiens>
			</definition>
</paper>

		<paper id="1044">
			<definition id="0">
				<sentence>a relevant document is a candidate pattern .</sentence>
				<definiendum id="0">relevant document</definiendum>
			</definition>
			<definition id="1">
				<sentence>The test sub-corpus consists of the 100 MUC-6 documents .</sentence>
				<definiendum id="0">test sub-corpus</definiendum>
				<definiens id="0">consists of the 100 MUC-6 documents</definiens>
			</definition>
			<definition id="2">
				<sentence>The test corpus for this learner consists of 250 documents : the 100 MUC-6 training documents and 150 WSJ documents which we retrieved using a set of keywords and categorized manually .</sentence>
				<definiendum id="0">test corpus</definiendum>
				<definiens id="0">250 documents : the 100 MUC-6 training documents and 150 WSJ documents which we retrieved using a set of keywords and categorized manually</definiens>
			</definition>
			<definition id="3">
				<sentence>Document ambiguity means that some documents cover more than one topic , which will lead to high relevance scores in multiple scenarios .</sentence>
				<definiendum id="0">Document ambiguity</definiendum>
				<definiens id="0">some documents cover more than one topic , which will lead to high relevance scores in multiple scenarios</definiens>
			</definition>
			<definition id="4">
				<sentence>Acknowledgements This research is supported by the Defense Advanced Research Projects Agency as part of the Translingual Information Detection , Extraction and Summarization ( TIDES ) program , under Grant N66001-001-1-8917 from the Space and Naval Warfare Systems Center San Diego , and by the National Science Foundation under Grant IIS-0081962 .</sentence>
				<definiendum id="0">Extraction</definiendum>
				<definiens id="0">the Defense Advanced Research Projects Agency as part of the Translingual Information Detection</definiens>
			</definition>
</paper>

		<paper id="2021">
			<definition id="0">
				<sentence>NeATS ( Lin and Hovy , 2002 ) is an extractionbased multi-document summarization system .</sentence>
				<definiendum id="0">NeATS</definiendum>
			</definition>
			<definition id="1">
				<sentence>Content Filtering NeATS uses three different filters : sentence position , stigma words , and redundancy filter .</sentence>
				<definiendum id="0">Content Filtering NeATS</definiendum>
				<definiens id="0">uses three different filters : sentence position , stigma words , and redundancy filter</definiens>
			</definition>
			<definition id="2">
				<sentence>Content Presentation To ensure coherence of the summary , NeATS pairs each sentence with an introduction sentence .</sentence>
				<definiendum id="0">NeATS</definiendum>
				<definiens id="0">pairs each sentence with an introduction sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>iNeATS facilitates browsing of the document set by providing ( 1 ) an overview of the documents , ( 2 ) linking the sentences in the summary to the original documents , and ( 3 ) using sentence zooming to highlight the most relevant sentences in the documents .</sentence>
				<definiendum id="0">iNeATS</definiendum>
				<definiens id="0">facilitates browsing of the document set by providing ( 1 ) an overview of the documents , ( 2 ) linking the sentences in the summary to the original documents , and ( 3 ) using sentence zooming to highlight the most relevant sentences in the documents</definiens>
			</definition>
</paper>

		<paper id="1058">
			<definition id="0">
				<sentence>{ nght , wangbin , chanys } @ comp.nus.edu.sg A central problem of word sense disambiguation ( WSD ) is the lack of manually sense-tagged data required for supervised learning .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">the lack of manually sense-tagged data required for supervised learning</definiens>
			</definition>
			<definition id="1">
				<sentence>The task of word sense disambiguation ( WSD ) is to determine the correct meaning , or sense of a word in context .</sentence>
				<definiendum id="0">word sense disambiguation ( WSD )</definiendum>
				<definiens id="0">to determine the correct meaning , or sense of a word in context</definiens>
			</definition>
			<definition id="2">
				<sentence>Secondly , WSD has been criticized as addressing an isolated problem without being grounded to any real application .</sentence>
				<definiendum id="0">WSD</definiendum>
				<definiens id="0">addressing an isolated problem without being grounded to any real application</definiens>
			</definition>
</paper>

		<paper id="2015">
			<definition id="0">
				<sentence>At the same time , TV operations for receiving such broadcasts are becoming increasingly complex , and an ever increasing variety of peripheral devices such as video tape recorders , disk recorders , DVD players , and game consoles are now being connected to televisions , and operating such devices with different kinds of interfaces is becoming troublesome not only for the elderly but for general users as well ( Komine et al. , 2000 ) .</sentence>
				<definiendum id="0">game consoles</definiendum>
				<definiens id="0">video tape recorders , disk recorders , DVD players , and</definiens>
			</definition>
			<definition id="1">
				<sentence>The user makes operation requests to interface robot ( IFR ) as shown in Figure 3 , and the IFR operates the television accordingly for the user .</sentence>
				<definiendum id="0">IFR</definiendum>
				<definiendum id="1">IFR</definiendum>
				<definiens id="0">operates the television accordingly for the user</definiens>
			</definition>
</paper>

		<paper id="2031">
			<definition id="0">
				<sentence>The separation of functional words gives us another benefit that we can resolve the ambiguities between an NE and a common noun plus functional words 1We used Empas ( http : //www.empas.com ) Person Location Organization Training Automatic 29,042 37,480 2,271Manual 1,014 724 1,338 Test Manual 102 72 193 Table 1 : Corpus description ( number of NE’s ) ( Automatic : Automatically annotated corpus , Manual : Manually annotated corpus and filter out erroneous matches .</sentence>
				<definiendum id="0">Corpus description</definiendum>
				<definiens id="0">Automatically annotated corpus , Manual : Manually annotated corpus and filter out erroneous matches</definiens>
			</definition>
</paper>

		<paper id="2009">
			<definition id="0">
				<sentence>Discourse chunking is a simple way to segment dialogues according to how dialogue participants raise topics and negotiate them .</sentence>
				<definiendum id="0">Discourse chunking</definiendum>
			</definition>
			<definition id="1">
				<sentence>A dialogue act ( hereafter DA ) is an encapsulation of the speaker�s intentions in dialogue�what the speaker is trying to accomplish by saying something .</sentence>
				<definiendum id="0">dialogue act ( hereafter DA )</definiendum>
				<definiens id="0">an encapsulation of the speaker�s intentions in dialogue�what the speaker is trying to accomplish by saying something</definiens>
			</definition>
			<definition id="2">
				<sentence>In DA tagging ( similar to part-of-speech tagging ) , utterances in a dialogue are tagged with the most appropriate speech act from a tagset .</sentence>
				<definiendum id="0">DA tagging</definiendum>
				<definiens id="0">similar to part-of-speech tagging</definiens>
			</definition>
			<definition id="3">
				<sentence>Case-based reasoning ( Kolodner 1993 ) is a form of machine learning that uses examples .</sentence>
				<definiendum id="0">Case-based reasoning</definiendum>
				<definiens id="0">a form of machine learning that uses examples</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>A synonymous collocation pair includes two collocations which are similar in meaning , but not identical in wording .</sentence>
				<definiendum id="0">synonymous collocation pair</definiendum>
				<definiens id="0">includes two collocations which are similar in meaning , but not identical in wording</definiens>
			</definition>
			<definition id="1">
				<sentence>Synonymous collocations can be considered as an extension of the concept of synonymous expressions which conventionally include synonymous words , phrases and sentence patterns .</sentence>
				<definiendum id="0">Synonymous collocations</definiendum>
				<definiens id="0">an extension of the concept of synonymous expressions which conventionally include synonymous words , phrases and sentence patterns</definiens>
			</definition>
			<definition id="2">
				<sentence>Our method for synonymous collocation extraction comprises of three steps : ( 1 ) extract collocations from large monolingual corpora ; ( 2 ) generate candidates of synonymous collocation pairs with a word thesaurus WordNet ; ( 3 ) select synonymous collocation candidates using their translations .</sentence>
				<definiendum id="0">synonymous collocation extraction</definiendum>
			</definition>
			<definition id="3">
				<sentence>Calculating the translation probability needs a bilingual corpus .</sentence>
				<definiendum id="0">translation probability</definiendum>
				<definiens id="0">needs a bilingual corpus</definiens>
			</definition>
			<definition id="4">
				<sentence>N represents the total counts of all the Chinese collocations in the training corpus .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the total counts of all the Chinese collocations in the training corpus</definiens>
			</definition>
			<definition id="5">
				<sentence>, , ( ) , , ( ) ) , , ( ) , , ( ( ) , ( 2 ) 2 ( ) , ( 1 ) 1 ( ) , ( 21 ) 2 ( ) 1 ( ) , ( 21 erelewerelew erelewerelew eeSim eTereleTerel eTeTerel ˛˛ ˛ + + = ( 13 ) where T ( ei ) denotes the set of words which have the dependency relation rel with ei. )</sentence>
				<definiendum id="0">T ( ei )</definiendum>
				<definiens id="0">the set of words which have the dependency relation rel with ei.</definiens>
			</definition>
</paper>

		<paper id="1042">
			<definition id="0">
				<sentence>Here , the uncertainty of a classifier is defined as the portion of instances on which it can not make classification decisions .</sentence>
				<definiendum id="0">uncertainty of a classifier</definiendum>
				<definiens id="0">the portion of instances on which it can not make classification decisions</definiens>
			</definition>
			<definition id="1">
				<sentence>We propose a new measure for representing the uncertainty correlation between the two classifiers in collaborative bootstrapping and refer to it as ‘uncertainty correlation coefficient’ ( UCC ) .</sentence>
				<definiendum id="0">UCC</definiendum>
				<definiens id="0">a new measure for representing the uncertainty correlation between the two classifiers in collaborative bootstrapping</definiens>
			</definition>
			<definition id="2">
				<sentence>The generalization error is a function of ‘disagreement’ between the two classifiers .</sentence>
				<definiendum id="0">generalization error</definiendum>
				<definiens id="0">a function of ‘disagreement’ between the two classifiers</definiens>
			</definition>
			<definition id="3">
				<sentence>Definition 1 The uncertainty ) ( hU of a classifier h is defined as : } ) , ) ( | ( { ) ( ˛=^= xxhxPhU ( 1 ) In practice , we define ) ( hU as } ) , , ) ) ( ( | ( { ) (  ˛˛ '' &lt; == xyyxhCxPhU q ( 2 ) where q denotes a predetermined threshold and ) ( *C denotes the confidence score of the classifier h. Definition 2 The conditional uncertainty ) | ( yhU of a classifier h given a class y is defined as : ) | } , ) ( | ( { ) | ( yYxxhxPyhU =˛=^=  ( 3 ) We note that the uncertainty ( or conditional uncertainty ) of a classifier ( a partial function ) is an indicator of the accuracy of the classifier .</sentence>
				<definiendum id="0">uncertainty ) ( hU of a classifier h</definiendum>
				<definiendum id="1">q</definiendum>
				<definiendum id="2">*C</definiendum>
				<definiens id="0">the confidence score of the classifier h. Definition 2 The conditional uncertainty ) | ( yhU of a classifier h given a class y is defined as : ) | } , ) ( | ( { ) | ( yYxxhxPyhU =˛=^=  ( 3 ) We note that the uncertainty ( or conditional uncertainty ) of a classifier ( a partial function ) is an indicator of the accuracy of the classifier</definiens>
			</definition>
			<definition id="4">
				<sentence>Definition 3 Given the two classifiers 1h and 2h in collaborative bootstrapping , the uncertainty reduction of 1h with respect to 2h ( denoted as ) \ ( 21 hhUR ) , is defined as } ) , ) ( , ) ( | ( { ) \ ( 2121 ˛„^=^= xxhxhxPhhUR ( 4 ) Similarly , we have } ) , ) ( , ) ( | ( { ) \ ( 2112 ˛=^„^= xxhxhxPhhUR Uncertainty reduction is an important factor for determining the performance of collaborative bootstrapping .</sentence>
				<definiendum id="0">xxhxhxPhhUR</definiendum>
				<definiendum id="1">xxhxhxPhhUR Uncertainty reduction</definiendum>
			</definition>
			<definition id="5">
				<sentence>Definition 4 Given the two classifiers 1h and 2h , the conditional uncertainty correlation coefficient ( CUCC ) between 1h and 2h given a class y ( denoted as yhhr 21 ) , is defined as ) | ) ( ( ) | ) ( ( ) | ) ( , ) ( ( 21 21 21 yYxhPyYxhP yYxhxhP yhhr ==^==^ ==^=^= ( 5 ) Definition 5 The uncertainty correlation coefficient ( UCC ) between 1h and 2h ( denoted as 21hhR ) , is defined as = y yhhhh r ) y ( PR 2121 ( 6 ) UCC represents the degree to which the uncerFigure 1 : Bilingual Bootstrapping tainties of the two classifiers are related .</sentence>
				<definiendum id="0">conditional uncertainty correlation coefficient ( CUCC</definiendum>
				<definiendum id="1">UCC</definiendum>
				<definiendum id="2">UCC</definiendum>
			</definition>
			<definition id="6">
				<sentence>Note that UCC is a symmetric measure from both classifiers’ perspectives , while UR is an asymmetric measure from one classifier’s perspective ( either ) \ ( 21 hhUR or ) \ ( 12 hhUR ) .</sentence>
				<definiendum id="0">UCC</definiendum>
				<definiendum id="1">UR</definiendum>
				<definiens id="0">a symmetric measure from both classifiers’ perspectives</definiens>
			</definition>
			<definition id="7">
				<sentence>We see that in co-training the new algorithm performs as well as the old algorithm when UCC is low ( view independence holds ) , and the new algorithm performs significantly better than the old algorithm when UCC is high ( view independence does not hold ) .</sentence>
				<definiendum id="0">UCC</definiendum>
				<definiendum id="1">UCC</definiendum>
				<definiens id="0">low ( view independence holds</definiens>
			</definition>
			<definition id="8">
				<sentence>This paper has theoretically and empirically demonstrated that uncertainty reduction is the essence of collaborative bootstrapping , which includes both co-training and bilingual bootstrapping .</sentence>
				<definiendum id="0">uncertainty reduction</definiendum>
				<definiendum id="1">collaborative bootstrapping</definiendum>
				<definiens id="0">includes both co-training and bilingual bootstrapping</definiens>
			</definition>
</paper>

		<paper id="1067">
</paper>

		<paper id="2032">
			<definition id="0">
				<sentence>The KO-OU relation is a kind of concord , also referring to a sort of bound relation that a KO element appearing in a sentence is followed by an OU element in the latter part of the same sentence .</sentence>
				<definiendum id="0">KO-OU relation</definiendum>
				<definiens id="0">a kind of concord , also referring to a sort of bound relation that a KO element appearing in a sentence is followed by an OU element in the latter part of the same sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>The KO-OU relation is the grammatical form which can be helpful for understanding the sentence meaning at the early stage .</sentence>
				<definiendum id="0">KO-OU relation</definiendum>
				<definiens id="0">the grammatical form which can be helpful for understanding the sentence meaning at the early stage</definiens>
			</definition>
</paper>

		<paper id="1050">
			<definition id="0">
				<sentence>A parallel corpus is a collection of sentence pairs with the same meaning but in different languages ( i.e. United Nations proceedings , bilingual newspapers , the Bible ) .</sentence>
				<definiendum id="0">parallel corpus</definiendum>
			</definition>
			<definition id="1">
				<sentence>GOLD is an earlier version of the stemmer described in ( Lee et al. , ) .</sentence>
				<definiendum id="0">GOLD</definiendum>
			</definition>
			<definition id="2">
				<sentence>GOLD is an earlier version of the stemmer described in ( Lee et al. , ) .</sentence>
				<definiendum id="0">GOLD</definiendum>
			</definition>
			<definition id="3">
				<sentence>Precision is defined as the ratio of relevant documents to total documents retrieved up to that point in the ranking .</sentence>
				<definiendum id="0">Precision</definiendum>
				<definiens id="0">the ratio of relevant documents to total documents retrieved up to that point in the ranking</definiens>
			</definition>
</paper>

		<paper id="1064">
			<definition id="0">
				<sentence>Supertagging is the tagging process of assigning the correct elementary tree of LTAG , or the correct supertag , to each word of an input sentence1 .</sentence>
				<definiendum id="0">Supertagging</definiendum>
				<definiens id="0">the tagging process of assigning the correct elementary tree of LTAG</definiens>
			</definition>
			<definition id="1">
				<sentence>Supertagging is the process of assigning the correct supertag to each word of an input sentence .</sentence>
				<definiendum id="0">Supertagging</definiendum>
				<definiens id="0">the process of assigning the correct supertag to each word of an input sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>An LTAG parser assigns the correct elementary tree to each word of a sentence , and uses the elementary trees of all the words to build a parse tree for the sentence .</sentence>
				<definiendum id="0">LTAG parser</definiendum>
				<definiens id="0">assigns the correct elementary tree to each word of a sentence , and uses the elementary trees of all the words to build a parse tree for the sentence</definiens>
			</definition>
			<definition id="3">
				<sentence>Given an observation sequence a33 , we find the most likely state sequence a34 given a33 by maximizing a35a37a36 a34a39a38a8a33a41a40a43a42 a44 a45 a46 a31a48a47a50a49 a35a37a36a52a51 a31a53a38 a51a16a54a27a55 a5a56a5a56a5 a55a53a51 a31a58a57 a54a59a55 a33a60a40a62a61 a35a63a54a59a36a52a51a4a54 a38a64 a54 a40 a42 a44 a45 a46 a31a48a47a50a49 a35a37a36a52a51 a31a53a38 a51 a31a58a57 a54a27a55 a64a65a31a66a40a62a61 a35a67a54a65a36a52a51a16a54 a38a64 a54 a40 ( 1 ) In this model , the output of SNoW is used to estimate a35a37a36a52a51 a38 a51a27a68a69a55 a64a16a40 and a35a67a54a59a36a52a51 a38a64a16a40 , where a51 is the current state , a51a27a68 is the previous state , and a64 is the current observation .</sentence>
				<definiendum id="0">a51</definiendum>
				<definiendum id="1">a64</definiendum>
				<definiens id="0">the current state</definiens>
				<definiens id="1">the current observation</definiens>
			</definition>
			<definition id="4">
				<sentence>In ( Punyakanok and Roth , 2000 ) , the sigmoid a9a12a74 a36 a9a63a75a77a76 a57a32a78a79a29a53a80a52a31a58a57a24a81a50a82 a40 is defined as confidence , where a83 is the threshold for SNoW , a84a6a85a87a86 is the dot product of the weight vector and the example vector .</sentence>
				<definiendum id="0">a83</definiendum>
				<definiendum id="1">a84a6a85a87a86</definiendum>
				<definiens id="0">the threshold for SNoW</definiens>
				<definiens id="1">the dot product of the weight vector and the example vector</definiens>
			</definition>
			<definition id="5">
				<sentence>Following the estimation of distribution function in ( Punyakanok and Roth , 2000 ) , we define confidence with a sigmoid a114 a107a21a36 a86a104a38a86 a68 a55 a90 a55 a92a41a40a67a106 a9 a9a98a75a116a115a117a76 a57a32a78a79a118a120a119a121a78a122a31a88a123a31 a72a69a124a125a126a124a127 a82a58a57 a70 a82 a55 ( 3 ) where a51 is the threshold of a112a113a107 , and a115 is set to 1 .</sentence>
				<definiendum id="0">a51</definiendum>
				<definiendum id="1">a115</definiendum>
				<definiens id="0">the threshold of a112a113a107 , and</definiens>
			</definition>
</paper>

		<paper id="1070">
			<definition id="0">
				<sentence>Results We examine differences between the F2F and SR conditions , correlate verbal and nonverbal behaviors within those conditions , and finally look at correlations between speaker and listener behavior .</sentence>
				<definiendum id="0">SR</definiendum>
				<definiens id="0">conditions , correlate verbal and nonverbal behaviors within those conditions , and finally look at correlations between speaker and listener behavior</definiens>
			</definition>
			<definition id="1">
				<sentence>MACK is an interactive public information ECA kiosk .</sentence>
				<definiendum id="0">MACK</definiendum>
			</definition>
			<definition id="2">
				<sentence>MACK produces multimodal output as well : ( 1 ) speech synthesis using the Microsoft Whistler Text-to-Speech ( TTS ) API , ( 2 ) a graphical figure with synchronized hand and arm gestures , and head and eye movements , and ( 3 ) LCD projector highlighting on the paper map , allowing MACK to reference it .</sentence>
				<definiendum id="0">MACK</definiendum>
				<definiens id="0">produces multimodal output as well : ( 1 ) speech synthesis using the Microsoft Whistler Text-to-Speech ( TTS ) API , ( 2 ) a graphical figure with synchronized hand and arm gestures , and head and eye movements</definiens>
			</definition>
			<definition id="3">
				<sentence>The UM interprets the input modalities and converts them to dialogue moves which it then passes on to the Dialogue Manager ( DM ) .</sentence>
				<definiendum id="0">UM</definiendum>
			</definition>
			<definition id="4">
				<sentence>The DM consists of two primary sub-modules , the Response Planner , which determines MACK’s next action ( s ) and creates a sequence of utterance units , and the Grounding Module ( GrM ) , which updates the Discourse Model and decides when the Response Planner’s next UU should be passed on to the Generation module ( GM ) .</sentence>
				<definiendum id="0">DM</definiendum>
				<definiens id="0">consists of two primary sub-modules , the Response Planner , which determines MACK’s next action ( s ) and creates a sequence of utterance units , and the Grounding Module ( GrM ) , which updates the Discourse Model and decides when the Response Planner’s next UU should be passed on to the Generation module ( GM )</definiens>
			</definition>
			<definition id="5">
				<sentence>The GM converts the UU into speech , gesture , and projector output , sending these synchronized modalities to the TTS engine , Animation Module ( AM ) , and Projector Module .</sentence>
				<definiendum id="0">GM</definiendum>
				<definiens id="0">converts the UU into speech , gesture , and projector output</definiens>
			</definition>
			<definition id="6">
				<sentence>The Discourse Model maintains information about the state and history of the discourse .</sentence>
				<definiendum id="0">Discourse Model</definiendum>
				<definiens id="0">maintains information about the state and history of the discourse</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , when MACK generates a direction segment ( an Assertion ) , 66 % of the time he keeps looking at the map .</sentence>
				<definiendum id="0">MACK</definiendum>
				<definiens id="0">generates a direction segment</definiens>
			</definition>
			<definition id="8">
				<sentence>Using verbal evidence : If the user returns an acknowledgement , such as “OK” , the GrM judges the UU grounded .</sentence>
				<definiendum id="0">GrM</definiendum>
				<definiens id="0">judges the UU grounded</definiens>
			</definition>
			<definition id="9">
				<sentence>If these two behaviors ( “within” and “pause” ) match a pattern that signals positive evidence , the UU is grounded .</sentence>
				<definiendum id="0">UU</definiendum>
				<definiens id="0">“within” and “pause” ) match a pattern that signals positive evidence , the</definiens>
			</definition>
			<definition id="10">
				<sentence>In this case , the GrM asks the Response Planner ( RP ) to provide an elaboration for the current UU ; the RP generates this elaboration ( looking up the landmark in the database ) and adds it to the front of the Agenda ; and the GrM sends this new UU on to the GM .</sentence>
				<definiendum id="0">GrM</definiendum>
				<definiendum id="1">GrM</definiendum>
				<definiens id="0">asks the Response Planner ( RP ) to provide an elaboration for the current UU ; the RP generates this elaboration ( looking up the landmark in the database ) and adds it to the front of the Agenda</definiens>
			</definition>
			<definition id="11">
				<sentence>In this case , MACK noted that the user looked at the map during the UU , and continued to do so just afterwards .</sentence>
				<definiendum id="0">MACK</definiendum>
			</definition>
			<definition id="12">
				<sentence>Therefore , the RP generates an elaboration ( line 4 ) .</sentence>
				<definiendum id="0">RP</definiendum>
			</definition>
</paper>

		<paper id="2017">
			<definition id="0">
				<sentence>He then goes on to adapt the conventional noisy channel MT model of [ Brown et al 1993 ] to NLU , where extracting a semantic representation from an input text corresponds to finding : argmax ( Sem ) { p ( Input|Sem ) p ( Sem ) } , where p ( Sem ) is a model for generating semantic representations , and p ( Input|Sem ) is a model for the relation between semantic representations and corresponding texts .</sentence>
				<definiendum id="0">p ( Sem</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">argmax ( Sem ) { p ( Input|Sem ) p ( Sem ) }</definiens>
				<definiens id="1">a model for the relation between semantic representations and corresponding texts</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>Statistical language models are crucial components of many modern natural language processing systems such as speech recognition , information extraction , machine translation , or document classification .</sentence>
				<definiendum id="0">Statistical language models</definiendum>
			</definition>
			<definition id="1">
				<sentence>A word lattice is a weighted finite automaton ( WFA ) output by the recognizer for a particular utterance .</sentence>
				<definiendum id="0">word lattice</definiendum>
				<definiens id="0">a weighted finite automaton ( WFA ) output by the recognizer for a particular utterance</definiens>
			</definition>
			<definition id="2">
				<sentence>Definition 1 A system a9a11a10a13a12a15a14a16a12a18a17a16a12 a19a20a12 a21a23a22 is a semiring ( Kuich and Salomaa , 1986 ) if : a9a11a10a24a12a15a14a16a12 a19a25a22 is a commutative monoid with identity element a19 ; a9a11a10a26a12a18a17a16a12 a21a27a22 is a monoid with identity element a21 ; a17 distributes over a14 ; and a19 is an annihilator for a17 : for all a28a30a29a31a10a26a12a32a28a33a17 a19a34a3 a19a24a17a35a28a36a3 a19 .</sentence>
				<definiendum id="0">a19</definiendum>
				<definiens id="0">a semiring</definiens>
				<definiens id="1">a commutative monoid with identity element a19 ; a9a11a10a26a12a18a17a16a12 a21a27a22 is a monoid with identity element a21 ; a17 distributes over a14</definiens>
			</definition>
			<definition id="3">
				<sentence>Thus , a semiring is a ring that may lack negation .</sentence>
				<definiendum id="0">semiring</definiendum>
				<definiens id="0">a ring that may lack negation</definiens>
			</definition>
			<definition id="4">
				<sentence>Definition 2 A weighted finite-state transducer a97 over a semiring a10 is an 8-tuple a97a98a3a99a9a101a100a13a12a18a102a30a12a18a103a33a12a71a104a25a12a71a105a72a12a32a106a107a12a32a108a81a12a85a109a80a22 where : a100 is the finite input alphabet of the transducer ; a102 is the finite output alphabet ; a103 is a finite set of states ; a104a48a110a111a103 the set of initial states ; a105a112a110a113a103 the set of final states ; a106a114a110a48a103a115a58a68a9a116a100a31a41a117a43a23a118a61a47a119a22a120a58a121a9a11a102a122a41a117a43a119a118a78a47a46a22a123a58a107a10a92a58a86a103 a finite set of transitions ; a108a4a124a60a104a30a125a126a10 the initial weight function ; and a109a4a124a20a105a127a125a128a10 the final weight function mapping a105 to a10 .</sentence>
				<definiendum id="0">a102</definiendum>
				<definiendum id="1">a103</definiendum>
				<definiens id="0">an 8-tuple a97a98a3a99a9a101a100a13a12a18a102a30a12a18a103a33a12a71a104a25a12a71a105a72a12a32a106a107a12a32a108a81a12a85a109a80a22 where : a100 is the finite input alphabet of the transducer ;</definiens>
				<definiens id="1">the finite output alphabet</definiens>
				<definiens id="2">a finite set of states ; a104a48a110a111a103 the set of initial states ; a105a112a110a113a103 the set of final states</definiens>
			</definition>
			<definition id="5">
				<sentence>A path a146a147a3a39a136a49a148a120a149a61a149a78a149a85a136a46a150 is an element of a106a107a133 with consecutive transitions : a2a141a138 a136a152a151a76a153a20a148a32a139a83a3a154a140a120a138 a136a119a151a90a139 , a137a155a3a157a156a80a12a61a158a78a158a78a158a61a12a32a159 .</sentence>
				<definiendum id="0">path a146a147a3a39a136a49a148a120a149a61a149a78a149a85a136a46a150</definiendum>
				<definiens id="0">an element of a106a107a133 with consecutive transitions</definiens>
			</definition>
			<definition id="6">
				<sentence>Thus , we define the count of the sequence a167 in a129 , a205 a9a76a167a160a22 , as : a205 a9a76a167a66a22a91a3a204a206 a207 a176a53a208a66a209 a210a211a123a210 a191 a138a138 a129a83a139a139a197a9a76a167a160a22 where a210a211a123a210 a191 denotes the number of occurrences of a167 in the string a211 , i.e. , the expected number of occurrences of a167 given a129 .</sentence>
				<definiendum id="0">a210a211a123a210 a191</definiendum>
				<definiens id="0">the number of occurrences of a167 in the string a211 , i.e. , the expected number of occurrences of a167 given a129</definiens>
			</definition>
			<definition id="7">
				<sentence>1There exist a general weighted determinization and weight pushing algorithms that can be used to create a deterministic and pushed automaton equivalent to an input word or phone lattice ( Mohri , 1997 ) .</sentence>
				<definiendum id="0">1There</definiendum>
			</definition>
			<definition id="8">
				<sentence>The size of a97 is in a225 a9 a210 a100 a210 a54 a210 a129a26a226 a210 a22 , where a129a26a226 is a finite automaton accepting a134 .</sentence>
				<definiendum id="0">a129a26a226</definiendum>
				<definiens id="0">a finite automaton accepting a134</definiens>
			</definition>
			<definition id="9">
				<sentence>fsm creates an encoded representation count .</sentence>
				<definiendum id="0">fsm</definiendum>
				<definiens id="0">creates an encoded representation count</definiens>
			</definition>
			<definition id="10">
				<sentence>Conditional probabilities in a backoff model are of the form : a244a20a245a84a246a168a247a13a248a249a80a250a99a251 a252a114a253 a244a20a245a84a246a168a247a13a248a249a80a250 a254 a255 a1 a246a76a249a27a247a132a250a3a2a5a4 a6a8a7 a244a96a245a84a246a168a247a13a248a249a10a9a168a250a12a11a14a13a16a15a18a17a32a245a20a19a141a254a22a21a20a17 ( 2 ) where a23a3a24 is a factor that ensures a normalized model .</sentence>
				<definiendum id="0">a23a3a24</definiendum>
				<definiens id="0">a factor that ensures a normalized model</definiens>
			</definition>
			<definition id="11">
				<sentence>Conditional probabilities in a deleted interpolation model are of the form : a244a96a245a84a246a168a247a26a248a249a80a250a81a251a8a252 a246a26a25a28a27 a6a29a7 a250a26a30a244a96a245a84a246a168a247a13a248a249a164a250a32a31 a6a8a7 a244a96a245a78a246a168a247a26a248a249a18a9a173a250a35a254 a255 a1 a246a76a249a27a247a132a250a33a2a34a4 a6a8a7 a244a96a245a78a246a168a247a26a248a249a18a9a173a250 a11a14a13a16a15a18a17a32a245a20a19a141a254a22a21a20a17 ( 3 ) where a23a3a24 is the mixing parameter between zero and one .</sentence>
				<definiendum id="0">a23a3a24</definiendum>
				<definiens id="0">the mixing parameter between zero and one</definiens>
			</definition>
			<definition id="12">
				<sentence>Furthermore , due the Viterbi approximation used in most speech processing applications , the weight associated to a string a167 by a weighted automaton representing the model is the minimum weight of a path labeled with a167 .</sentence>
				<definiendum id="0">approximation</definiendum>
				<definiens id="0">used in most speech processing applications , the weight associated to a string a167 by a weighted automaton representing the model is the minimum weight of a path labeled with a167</definiens>
			</definition>
			<definition id="13">
				<sentence>The set of states of the WFA representing a backoff or interpolated model is defined by associating a state a144a36a24 to each sequence of length less than a2 found in the corpus : a103a181a3a181a43a23a144 a24 a124 a210 a240a120a210a38a37 a2a40a39a152a95a42a41 a205 a9 a240 a22a44a43a42a19a60a47 Its transition set a106 is defined as the union of the following set of failure transitions : a43a164a9a90a144a14a45a8a24a23a179a197a12a46a35a161a12a78a73a68a62a64a63a49a65a25a9a47a23a48a24a164a22a15a12a32a144a49a24a23a179a90a22a72a124a49a144a14a45a8a24a23a179a120a29a68a103a36a47 and the following set of regular transitions : a43a49a9a90a144a50a24a74a12a71a142a57a12a78a73a68a62a166a63a53a65a66a9 a237a141a238 a9a76a142 a210 a240 a22a85a22a15a12a71a2a51a24a50a45a141a22a132a124a53a144a49a24a86a29a68a103a33a12 a205 a9 a240 a142a13a22a44a43a145a19a80a47 where a2 a24a50a45 is defined by : a52a32a7a54a53 a251 a252a56a55 a7a54a53 a254a199a255a57a4a59a58a42a248a249a49a247a26a248a60a58 a52 a55 a7 a179 a53 a254a199a255a123a248a249a27a247a26a248a23a251 a52 a19a61a15a18a17a32a245a16a17a120a249a16a251a69a247a62a9a173a249a18a9 ( 4 ) Figure 2 illustrates this construction for a trigram model .</sentence>
				<definiendum id="0">a106</definiendum>
				<definiens id="0">length less than a2 found in the corpus : a103a181a3a181a43a23a144 a24 a124 a210 a240a120a210a38a37 a2a40a39a152a95a42a41 a205 a9 a240 a22a44a43a42a19a60a47 Its transition set</definiens>
			</definition>
</paper>

		<paper id="2011">
			<definition id="0">
				<sentence>My analysis of the Sinica Corpus shows that contrary to expectation , most of unknown words in Chinese are common nouns , adjectives , and verbs rather than proper nouns .</sentence>
				<definiendum id="0">Sinica Corpus</definiendum>
			</definition>
			<definition id="1">
				<sentence>While context is clearly an important feature , this paper focuses on non-contextual features , which may play a key role for unknown words that occur only once 1 The Sinica Corpus is a balanced corpus contained five million part-of-speech words in Mandarin Chinese .</sentence>
				<definiendum id="0">Sinica Corpus</definiendum>
				<definiens id="0">a balanced corpus contained five million part-of-speech words in Mandarin Chinese</definiens>
			</definition>
			<definition id="2">
				<sentence>3 ‘Monosyllabic word’ means a word with only a character , and ‘multisynllabic word’ means a word with more than one character .</sentence>
				<definiendum id="0">‘multisynllabic word’</definiendum>
				<definiens id="0">means a word with more than one character</definiens>
			</definition>
			<definition id="3">
				<sentence>The CiLin ( Mei et al 1986 ) is a thesaurus that contains 12 main categories : A-human , B-object , Ctime and space , D-abstract , E-attribute , F-action , G-mental action , H-activity , I-state , J-association , K-auxiliary , and L-respect .</sentence>
				<definiendum id="0">CiLin</definiendum>
				<definiens id="0">a thesaurus that contains 12 main categories : A-human , B-object , Ctime and space , D-abstract , E-attribute , F-action , G-mental action , H-activity , I-state , J-association , K-auxiliary , and L-respect</definiens>
			</definition>
			<definition id="4">
				<sentence>The CiLin thesaurus can be used as an information system , and the information content of each semantic category is defined as category ) manticEntropy ( Sestem ) Entropy ( Sy − The similarity of two words is the least common ancestor information content ( IC ) , and hence , the higher the information content is , the more similar two the words are .</sentence>
				<definiendum id="0">CiLin thesaurus</definiendum>
				<definiens id="0">an information system , and the information content of each semantic category</definiens>
				<definiens id="1">the least common ancestor information content ( IC ) , and hence , the higher the information content is , the more similar two the words</definiens>
			</definition>
			<definition id="5">
				<sentence>Semantic Similarity in a Taxonomy : An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language , in Journal of Artificial Intelligence Research ( 11 ) , 95130 .</sentence>
				<definiendum id="0">Semantic Similarity</definiendum>
				<definiendum id="1">Language</definiendum>
				<definiens id="0">An Information-Based Measure and its Application to Problems of Ambiguity in Natural</definiens>
			</definition>
</paper>

		<paper id="2029">
			<definition id="0">
				<sentence>fi is a weight function characteristic of the sequence pi , defined as following : fi a1 a17 u i if maxp a9j a14 PT a9 alignmenta11 pi a4 pa0ja12a19a18 ti vi otherwise ( 2 ) where ui and vi are arbitrary constants and ti is arbitrary threshold .</sentence>
				<definiendum id="0">fi</definiendum>
			</definition>
			<definition id="1">
				<sentence>Senseval : An exercise in evaluating word sense disambiguation programs .</sentence>
				<definiendum id="0">Senseval</definiendum>
				<definiens id="0">An exercise in evaluating word sense disambiguation programs</definiens>
			</definition>
</paper>

		<paper id="2038">
			<definition id="0">
				<sentence>Core functionality consists of the following types of commands : Navigation : moving to the following step or substep ( “next” , “next step” , “next substep” ) , going back to the preceding step or substep ( “previous” , “previous substep” ) , moving to a named step or substep ( “go to step three” , “go to step ten point two” ) .</sentence>
				<definiendum id="0">Core functionality</definiendum>
				<definiens id="0">consists of the following types of commands : Navigation : moving to the following step or substep ( “next” , “next step” , “next substep” ) , going back to the preceding step or substep ( “previous” , “previous substep” ) , moving to a named step or substep ( “go to step three” , “go to step ten point two”</definiens>
			</definition>
			<definition id="1">
				<sentence>REGULUS implements a version of the grammar specialisation scheme which extends the Explanation Based Learning method described in ( Rayner et al. , 2002 ) .</sentence>
				<definiendum id="0">REGULUS</definiendum>
			</definition>
			<definition id="2">
				<sentence>ALTERF ( Rayner and Hockey , 2003 ) is another Open Source toolkit , whose purpose is to allow a clean combination of rule-based and corpus-driven processing in the semantic interpretation phase .</sentence>
				<definiendum id="0">ALTERF</definiendum>
				<definiens id="0">to allow a clean combination of rule-based and corpus-driven processing in the semantic interpretation phase</definiens>
			</definition>
			<definition id="3">
				<sentence>Statistics are then compiled to estimate the probability p ( a j f ) of each semantic atom a given each separate feature f , using the standard formula p ( a j f ) = ( Naf + 1 ) = ( Nf + 2 ) where Nf is the number of occurrences in the training data of utterances with feature f , and N af is the number of occurrences of utterances with both feature f and semantic atom a. The decoding process follows ( Yarowsky , 1994 ) in assuming complete dependence between the features .</sentence>
				<definiendum id="0">Nf</definiendum>
				<definiens id="0">compiled to estimate the probability p ( a j f ) of each semantic atom a given each separate feature f</definiens>
				<definiens id="1">the number of occurrences in the training data of utterances with feature f</definiens>
			</definition>
			<definition id="4">
				<sentence>Note that this is in sharp contrast with the Naive Bayes classifier ( Duda et al. , 2000 ) , which assumes complete independence .</sentence>
				<definiendum id="0">Naive Bayes classifier</definiendum>
				<definiens id="0">assumes complete independence</definiens>
			</definition>
			<definition id="5">
				<sentence>The decoding process proceeds as follows : tics compiled during training to find the set of all triples hf ; a ; pi where f is a feature associated with u , a is a semantic atom , and p is the probability p ( a j f ) estimated by the training process .</sentence>
				<definiendum id="0">f</definiendum>
				<definiendum id="1">p</definiendum>
				<definiens id="0">the probability p ( a j f ) estimated by the training process</definiens>
			</definition>
</paper>

		<paper id="2013">
			<definition id="0">
				<sentence>This program , Zero Detector ( henceforth , ZD ) takes Japanese written narrative texts as input and provides the zerospecified texts and their underlying structures as output .</sentence>
				<definiendum id="0">ZD )</definiendum>
				<definiens id="0">takes Japanese written narrative texts as input</definiens>
			</definition>
			<definition id="1">
				<sentence>GT is a semantic feature dictionary that defines 300,000 nouns based on an ontological hierarchy of approximately 2,800 semantic attributes .</sentence>
				<definiendum id="0">GT</definiendum>
				<definiens id="0">a semantic feature dictionary that defines 300,000 nouns based on an ontological hierarchy of approximately 2,800 semantic attributes</definiens>
			</definition>
			<definition id="2">
				<sentence>Type Syntactic properties Semantic properties # Examples Human activity 21 zikosyokai ‘self-introduction’ I Nominalized verbal , derived ( from verb ) noun , common noun phenomenon 3 entyo ‘extension’ Location 13 mae ‘front’ II formal noun , common noun Time 1 yokuzitu ‘next day’ Amount 9 sintyo ‘height’ Value 2 nedan ‘price’ Emotion 1 kimoti ‘feeling’ Material phenomenon 1 nioi ‘smell’ Name 1 namae ‘name’ III Derived ( from verb/adjective ) noun , suffix noun , common noun Order 1 ichiban ‘first’ Human ( kinship ) 14 haha ‘mother’ Animate ( body-part ) 14 atama ‘head’ Organization 7 kaisya ‘company’ Housing ( part ) 7 doa ‘door’ Human ( profession ) 4 sensei ‘teacher’ Human ( role ) 4 dokusya ‘reader’ Human ( relationship ) 3 dooryoo ‘colleague’ Clothing 3 kutu ‘shoes’ Tool 2 saihu ‘purse’ Human ( biological feature ) 2 zyosei ‘woman’ Man-made 2 kuruma ‘car’ Facility 1 byoin ‘hospital’ Building 1 niwa ‘garden’ Housing ( body ) 1 gareeji ‘garage’ Housing ( attachment ) 1 doa ‘door’ Creative work 1 sakuhin ‘work’ Substance 1 kuuki ‘air’ Language 1 nihongo ‘Japanese’ Document 1 pasupooto ‘passport’ Chart 1 chizu ‘map’ Animal 1 petto ‘pet’ V Common noun ?</sentence>
				<definiendum id="0">gareeji ‘garage’ Housing</definiendum>
				<definiens id="0">Semantic properties # Examples Human activity 21 zikosyokai ‘self-introduction’ I Nominalized verbal , derived ( from verb</definiens>
			</definition>
			<definition id="3">
				<sentence>The algorithm consists of a set of lexicon-based heuristics , drawn from the observations in section 4.2 .</sentence>
				<definiendum id="0">algorithm</definiendum>
			</definition>
			<definition id="4">
				<sentence>The process consists of the following three phases : ( i ) bare noun extraction , ( ii ) syntactic category ( part-of-speech ) checking , and ( iii ) semantic category checking .</sentence>
				<definiendum id="0">process</definiendum>
			</definition>
			<definition id="5">
				<sentence>Closer examination of those errors indicates that most of them ( 8 out of 9 cases ) involve verbal idiomatic expressions that contain ATN candidate nouns , as example ( 5 ) shows .</sentence>
				<definiendum id="0">Closer examination</definiendum>
				<definiens id="0">verbal idiomatic expressions that contain ATN candidate nouns</definiens>
			</definition>
</paper>

		<paper id="1062">
			<definition id="0">
				<sentence>The commonly adopted solution is to use shallow information sources that approximate full syntactic , semantic and discourse information , such as the words of the text themselves , their part-of-speech tags , or their information content ( in general , or in the text at hand ) , since words with a high ( semantic ) information content or load tend to receive pitch accents ( Ladd , 1996 ) .</sentence>
				<definiendum id="0">high</definiendum>
				<definiens id="0">to use shallow information sources that approximate full syntactic , semantic and discourse information , such as the words of the text themselves , their part-of-speech tags , or their information content ( in general , or in the text at hand )</definiens>
			</definition>
			<definition id="1">
				<sentence>Section 3 describes the experimental procedure ( ten-fold iterative deepening ) and the evaluation metrics ( F-scores ) .</sentence>
				<definiendum id="0">experimental procedure</definiendum>
				<definiens id="0">ten-fold iterative deepening ) and the evaluation metrics ( F-scores )</definiens>
			</definition>
			<definition id="2">
				<sentence>Part-of-speech ( POS ) tagging – We used MBT version 1.0 ( Daelemans et al. , 1996 ) to develop a memory-based POS tagger trained on the Eindhoven corpus of written Dutch , which does not overlap with our base data .</sentence>
				<definiendum id="0">Part-of-speech</definiendum>
				<definiens id="0">Daelemans et al. , 1996 ) to develop a memory-based POS tagger trained on the Eindhoven corpus of written Dutch , which does not overlap with our base data</definiens>
			</definition>
			<definition id="3">
				<sentence>NP and VP chunking ( NpC &amp; VpC ) – An approximation of the syntactic structure is provided by simple noun phrase and verb phrase chunkers , which take word and POS information as input and are based on a small number of manually written regular expressions .</sentence>
				<definiendum id="0">VP chunking</definiendum>
				<definiens id="0">simple noun phrase and verb phrase chunkers , which take word and POS information as input and are based on a small number of manually written regular expressions</definiens>
			</definition>
			<definition id="4">
				<sentence>Bigram IC – IC on bigrams ( BIC ) was calculated for the bigrams ( pairs of words ) in the data , according to the same formula and corpus material as for unigram IC .</sentence>
				<definiendum id="0">Bigram IC – IC</definiendum>
			</definition>
			<definition id="5">
				<sentence>Document frequency counts for all token types were obtained from a subset of the same corpus as used for IC calculations .</sentence>
				<definiendum id="0">Document frequency</definiendum>
				<definiens id="0">counts for all token types were obtained from a subset of the same corpus</definiens>
			</definition>
			<definition id="6">
				<sentence>TF*IDF and IC ( previous two features ) have been succesfully tested as features for accent prediction by ( Pan and McKeown , 1999 ) , who assert that IC is a more powerful predictor than TF*IDF .</sentence>
				<definiendum id="0">IC</definiendum>
				<definiendum id="1">IC</definiendum>
				<definiens id="0">a more powerful predictor than TF*IDF</definiens>
			</definition>
			<definition id="7">
				<sentence>Phrasometer – The phrasometer feature ( PM ) is the summed log-likelihood of all n-grams the word form occurs in , with n ranging from 1 to 25 , and computed in an iterative growth procedure : loglikelihoods of n + 1-grams were computed by expanding all stored n-grams one word to the left and to the right ; only the n + 1-grams with higher log-likelihood than that of the original n-gram are stored .</sentence>
				<definiendum id="0">PM )</definiendum>
				<definiens id="0">the summed log-likelihood of all n-grams the word form occurs in , with n ranging from 1 to 25 , and computed in an iterative growth procedure : loglikelihoods of n + 1-grams were computed by expanding all stored n-grams one word to the left and to the right</definiens>
			</definition>
			<definition id="8">
				<sentence>CART ( Breiman et al. , 1984 ) is a statistical method to induce a classification or regression tree from a given set of instances .</sentence>
				<definiendum id="0">CART</definiendum>
				<definiens id="0">a statistical method to induce a classification or regression tree from a given set of instances</definiens>
			</definition>
			<definition id="9">
				<sentence>Memory-based learning ( MBL ) , also known as instance-based , example-based , or lazy learning ( Stanfill and Waltz , 1986 ; Aha et al. , 1991 ) , is a supervised inductive learning algorithm for learning classification tasks .</sentence>
				<definiendum id="0">Memory-based learning ( MBL</definiendum>
				<definiens id="0">instance-based , example-based , or lazy learning ( Stanfill and Waltz , 1986 ; Aha et al. , 1991 ) , is a supervised inductive learning algorithm for learning classification tasks</definiens>
			</definition>
			<definition id="10">
				<sentence>Memory-based learning treats a set of training instances as points in a multidimensional feature space , and stores them as such in an instance base in memory ( rather than performing some abstraction over them ) .</sentence>
				<definiendum id="0">Memory-based learning</definiendum>
				<definiens id="0">treats a set of training instances as points in a multidimensional feature space , and stores them as such in an instance base in memory ( rather than performing some abstraction over them )</definiens>
			</definition>
			<definition id="11">
				<sentence>Iterative deepening ( ID ) is a heuristic search algorithm for the optimization of algorithmic parameter 2All experiments with memory-based learning were performed with TiMBL , version 4.3 ( Daelemans et al. , 2002 ) .</sentence>
				<definiendum id="0">Iterative deepening</definiendum>
			</definition>
			<definition id="12">
				<sentence>Furthermore , MBL uses the Gain Ratio feature weighting and Exponential Decay distance weighting .</sentence>
				<definiendum id="0">MBL</definiendum>
			</definition>
			<definition id="13">
				<sentence>We plan to integrate the placement of pitch accents and breaks in a TTS system for Dutch , which will enable the closed-loop annotation of more data using the TTS itself and on-line ( active ) learning .</sentence>
				<definiendum id="0">on-line</definiendum>
				<definiens id="0">will enable the closed-loop annotation of more data using the TTS itself and</definiens>
			</definition>
</paper>

		<paper id="2030">
			<definition id="0">
				<sentence>In FrameNet II , all the data , including the definitions of frames , FEs , and LUs and all of the sentences and the annotation associated with them is stored in one relational database implemented in MySQL ( Baker et al. , 2003 ; Fillmore et al. , 2001 ) .</sentence>
				<definiendum id="0">LUs</definiendum>
				<definiens id="0">all the data , including the definitions of frames , FEs , and</definiens>
			</definition>
			<definition id="1">
				<sentence>The FrameNet public website contains an index by frame and an index by LU which links to both the lexical entry and the full annotation for each LU .</sentence>
				<definiendum id="0">FrameNet public website</definiendum>
				<definiens id="0">contains an index by frame and an index by LU which links to both the lexical entry and the full annotation for each LU</definiens>
			</definition>
			<definition id="2">
				<sentence>The HTML version of the data consists of all the files on the web site , so that users can set up a local copy and browse it with any web browser .</sentence>
				<definiendum id="0">HTML version of the data</definiendum>
				<definiens id="0">consists of all the files on the web site , so that users can set up a local copy and browse it with any web browser</definiens>
			</definition>
			<definition id="3">
				<sentence>The plain XML version of the data consists of the following files : frames .</sentence>
				<definiendum id="0">XML version of the data</definiendum>
			</definition>
</paper>

		<paper id="1007">
</paper>

		<paper id="2020">
			<definition id="0">
				<sentence>The system consists of three steps : compiling corpus , automatic term recognition ( ATR ) , and filtering .</sentence>
				<definiendum id="0">ATR</definiendum>
				<definiens id="0">consists of three steps : compiling corpus , automatic term recognition</definiens>
			</definition>
			<definition id="1">
				<sentence>score ( x , L ) =Imp 1 ( x , L ) ×F ( x , L ) α F ( x , L ) = braceleftBigg 1 if x is a single noun “frequency of x in L” otherwise 1 www.goo.ne.jp 2 www.infoseek.co.jp While Nakagawa’s Imp 1 does not consider term frequency , this function does : α is a parameter that controls how strongly the frequency is considered .</sentence>
				<definiendum id="0">α</definiendum>
				<definiens id="0">a parameter that controls how strongly the frequency is considered</definiens>
			</definition>
			<definition id="2">
				<sentence>The technical-term test removes the terms that do not satisfy conditions of technical terms .</sentence>
				<definiendum id="0">technical-term test</definiendum>
				<definiens id="0">removes the terms that do not satisfy conditions of technical terms</definiens>
			</definition>
			<definition id="3">
				<sentence>In case the query is a term , its hit is the number of pages that contain the term on the Web .</sentence>
				<definiendum id="0">query</definiendum>
				<definiens id="0">the number of pages that contain the term on the Web</definiens>
			</definition>
			<definition id="4">
				<sentence>t� rg ( natural langauge processing ; NLP ) -� �t� rgU [ ( NLP technology ) √√ � �t� rg���� ( NLP system ) √√ � �t� rgZ� ( NLP research ) � �t� rg� ( NLP study ) √√ rg ( processing ) ���� rg ( text processing ) √ Z�� C ( research and development ) �C rg�q ( Information Processing Society of Japan ; IPSJ ) √√ �� rg ( semantic processing ) √√ ; ` rg ( speech processing ) √ ; ` �C rg ( speech information processing ) √√ �C rg ( information processing ) � �t� rg �� ( NLP domain ) Z� �� ( research field ) √√ * �r s ( parsing ) √√ �CUg ( information retrieval ) √√ � �t� rgZ�q ( SIGNLP ) √√ ; ` �� ( speech recognition ) √√ ; �� ( machine translation ) √√ 6 �r s ( morphological analysis ) √√ �C rg���� ( information processing system ) √ Z� ( research ) ��r s ( semantic analysis ) √√ � �t� rg��2 ( chair of NLP ) √√ * � �t� rg������ ( NLP symposium ) ; ���� ( application system ) √ �� �C rg ( knowledge information processing ) √√ t� ( language ) �C ( information ) technical term because it does not satisfy the first condition ; in case the number is large enough , the term is probably a general term so that it is not a technical term .</sentence>
				<definiendum id="0">t� rg</definiendum>
				<definiendum id="1">√√ * � �t� rg������</definiendum>
				<definiens id="0">natural langauge processing ; NLP ) -� �t� rgU [ ( NLP technology ) √√ � �t� rg���� ( NLP system ) √√ � �t� rgZ� ( NLP research ) � �t� rg� ( NLP study ) √√ rg ( processing ) ���� rg ( text processing ) √ Z�� C ( research and development ) �C rg�q ( Information Processing Society of Japan ; IPSJ ) √√ �� rg ( semantic processing</definiens>
				<definiens id="1">rg ( speech information processing ) √√ �C rg ( information processing ) � �t� rg �� ( NLP domain ) Z� �� ( research field ) √√ * �r s ( parsing ) √√ �CUg ( information retrieval ) √√ � �t� rgZ�q ( SIGNLP ) √√ ; ` �� ( speech recognition</definiens>
				<definiens id="2">rg ( knowledge information processing ) √√ t� ( language ) �C ( information ) technical term because it does not satisfy the first condition</definiens>
			</definition>
			<definition id="5">
				<sentence>Type 0 the given seed term s : e.g. , � �t� rg ( natural language processing ) Type 1 a term that contains s : e.g. , � �t� rg� ��� ( natural language processing system ) Type 2 a term that is a subsequence of s : e.g. , � � t� ( natural language ) Type 3 a term that contains at least a component of s : e.g. , t�r s ( language analysis ) Type 4 others : e.g. , �r s ( parsing ) The reason why we introduce these types is that the following rules are true with a few exception : ( 1 ) A type-1 term is a narrower term of the seed term s ; ( 2 ) A type-2 term is a broader term of the seed term s. We assume that these rules are always true : they are used to determine whether x is a broader or narrower term of s. To measure the relation degree , we use conditional probabilities , which are calculated from search engine hits .</sentence>
				<definiendum id="0">parsing</definiendum>
				<definiens id="0">natural language processing ) Type 1 a term that contains s : e.g. , � �t� rg� ��� ( natural language processing system ) Type 2 a term that is a subsequence of s : e.g. , � � t� ( natural language ) Type 3 a term that contains at least a component of s : e.g. , t�r s ( language analysis</definiens>
				<definiens id="1">a narrower term of the seed term s</definiens>
			</definition>
			<definition id="6">
				<sentence>C : the target term existed in the collected web pages , but did not exist in the compiled corpus .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">the target term existed in the collected web pages , but did not exist in the compiled corpus</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>Convolution Kernels ( Haussler , 1999 ) demonstrate how to build kernels over discrete structures such as strings , trees , and graphs .</sentence>
				<definiendum id="0">Convolution Kernels</definiendum>
				<definiens id="0">demonstrate how to build kernels over discrete structures such as strings , trees , and graphs</definiens>
			</definition>
			<definition id="1">
				<sentence>a37 is defined as a relation on the seta14 a17a39a38 a40a22a40a21a40 a38 a14 a23a41a38 a14 such that a37a42a3a43a28a44a7a10a5a8a11 is true if a28 are the “parts” of a5 .</sentence>
				<definiendum id="0">a37</definiendum>
				<definiens id="0">a relation on the seta14 a17a39a38 a40a22a40a21a40 a38 a14 a23a41a38 a14 such that a37a42a3a43a28a44a7a10a5a8a11 is true if a28 are the “parts” of a5</definiens>
			</definition>
			<definition id="2">
				<sentence>An explicit definition of both the Tree Kernel and SSK a2a64a3a47a5a8a7a10a9a12a11 is written as : a65a36a66a68a67a70a69a101a71a57a73a102a75a4a103a105a104a106a66a68a67a70a73a108a107a109a104a57a66a68a71a74a73a55a110a111a75a59a112 a113a94a97a96 a104 a113 a66a68a67a111a73a111a107a114a104 a113 a66a68a71a57a73a55a99 ( 2 ) Conceptually , we enumerate all sub-structures occurring in a5 and a9 , where a115 represents the total number of possible sub-structures in the objects .</sentence>
				<definiendum id="0">a115</definiendum>
				<definiens id="0">the total number of possible sub-structures in the objects</definiens>
			</definition>
			<definition id="3">
				<sentence>The Tree Kernel computes the number of common subtrees in two trees a5 and a9 .</sentence>
				<definiendum id="0">Tree Kernel</definiendum>
				<definiens id="0">computes the number of common subtrees in two trees a5 and a9</definiens>
			</definition>
			<definition id="4">
				<sentence>a116a100a119a95a3a6a5a8a11 is defined as the number of occurrences of the a120 ’th enumerated subtree in tree a5 .</sentence>
				<definiendum id="0">a116a100a119a95a3a6a5a8a11</definiendum>
				<definiens id="0">the number of occurrences of the a120 ’th enumerated subtree in tree a5</definiens>
			</definition>
			<definition id="5">
				<sentence>This paper defines HDAG as a Directed Acyclic Graph ( DAG ) with hierarchical structures .</sentence>
				<definiendum id="0">HDAG</definiendum>
				<definiens id="0">a Directed Acyclic Graph ( DAG ) with hierarchical structures</definiens>
			</definition>
			<definition id="6">
				<sentence>The similarity between HDAGs , which is the definition of the HDAG Kernel , follows equation ( 2 ) where input objects a5 and a9 are a121 a17 and a121a123a122 , respectively .</sentence>
				<definiendum id="0">HDAGs</definiendum>
				<definiens id="0">the definition of the HDAG Kernel , follows equation ( 2 ) where input objects a5 and a9 are a121 a17 and a121a123a122 , respectively</definiens>
			</definition>
			<definition id="7">
				<sentence>a177a46a178a97a3a6a126a102a11 represents the cost of node skip a126 .</sentence>
				<definiendum id="0">a177a46a178a97a3a6a126a102a11</definiendum>
				<definiens id="0">the cost of node skip a126</definiens>
			</definition>
			<definition id="8">
				<sentence>For example , a177 a178 a3a47a126a100a17a158a11a135a29a181a157a74a150 a122 represents the cost of node skip a126 a122 a144 a182 a145 and that of a126a134a148 a144 a126a74a145 ; a177a131a178a136a3a47a126 a122 a11a135a29a181a150 is the cost of just node skip a126 a122 .</sentence>
				<definiendum id="0">a177a131a178a136a3a47a126 a122 a11a135a29a181a150</definiendum>
			</definition>
			<definition id="9">
				<sentence>a179a12a178a136a3a47a126a102a11 represents the sum of the multiplied cost of the node skips of all of the nodes that have a path to a126 , a179a8a178a111a3a47a126a134a145a106a11a49a29a133a157a57a150 that is the sum cost of both a126 a122 and a126a134a148 that have a path to a126a136a145 , a179a12a178a111a3a47a126 a17 a11a34a29a183a132a57a3a19a150a111a184a89a11 .</sentence>
				<definiendum id="0">a179a12a178a136a3a47a126a102a11</definiendum>
				<definiens id="0">the sum of the multiplied cost of the node skips of all of the nodes</definiens>
			</definition>
			<definition id="10">
				<sentence>PERSON p8 p9 p10p2 p3 Figure 4 : Examples of Input Object Structure : ( a ) HDAG , ( b ) DAG and DSK’ , ( c ) SSK’ Kernel ( DSK ) ( Collins and Duffy , 2001 ) ( a special case of the Tree Kernel ) , and Cosine measure for feature vectors consisting of the occurrence of attributes ( BOA ) , and the same as BOA , but only the attributes of noun and unknown word ( BOA’ ) were used .</sentence>
				<definiendum id="0">Kernel</definiendum>
				<definiens id="0">Examples of Input Object Structure : ( a ) HDAG</definiens>
				<definiens id="1">a special case of the Tree Kernel ) , and Cosine measure for feature vectors consisting of the occurrence of attributes</definiens>
			</definition>
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>Truecasing is the process of restoring case information to badly-cased or noncased text .</sentence>
				<definiendum id="0">Truecasing</definiendum>
			</definition>
			<definition id="1">
				<sentence>wi represents a word with a case tag treated as a unit for probability estimation .</sentence>
				<definiendum id="0">wi</definiendum>
				<definiens id="0">a word with a case tag treated as a unit for probability estimation</definiens>
			</definition>
			<definition id="2">
				<sentence>Testing speed depends on the width and length of the trellis and the overall decoding complexity is : Cdecoding = O ( SMH+1 ) where S is the sentence size , M is the number of surface forms we are willing to consider for each word , and H is the history size ( H = 3 in the trigram case ) .</sentence>
				<definiendum id="0">S</definiendum>
				<definiendum id="1">M</definiendum>
				<definiendum id="2">H</definiendum>
				<definiens id="0">the history size ( H = 3 in the trigram case )</definiens>
			</definition>
			<definition id="3">
				<sentence>The first test set ( APR ) consists of the August 25 , 2002 top 20 news stories from Associated Press and Reuters excluding titles , headlines , and section headers which together form the second test set ( APR+ ) .</sentence>
				<definiendum id="0">APR</definiendum>
				<definiens id="0">top 20 news stories from Associated Press and Reuters excluding titles , headlines , and section headers which together form the second test set</definiens>
			</definition>
			<definition id="4">
				<sentence>Baseline With Truecasing Class Recall Precision F Recall Precision F ENAMEX 48.46 36.04 41.34 59.02 52.65 55.66 ( +34:64 % ) NUMEX 64.61 72.02 68.11 70.37 79.51 74.66 ( +9:62 % ) TIMEX 47.68 52.26 49.87 61.98 75.99 68.27 ( +36:90 % ) Overall 52.50 44.84 48.37 62.01 60.42 61.20 ( +26:52 % ) Table 2 : Named Entity Recognition performance with truecasing and without ( baseline ) .</sentence>
				<definiendum id="0">Truecasing Class Recall Precision F Recall Precision</definiendum>
				<definiens id="0">Named Entity Recognition performance with truecasing and without ( baseline )</definiens>
			</definition>
			<definition id="5">
				<sentence>The data source consists of news stories ( 2500 sentences ) from the Xinhua News Agency .</sentence>
				<definiendum id="0">data source</definiendum>
			</definition>
			<definition id="6">
				<sentence>BLEU uses a modified n-gram precision metric and a weighting scheme that places more emphasis on longer n-grams .</sentence>
				<definiendum id="0">BLEU</definiendum>
				<definiens id="0">uses a modified n-gram precision metric and a weighting scheme that places more emphasis on longer n-grams</definiens>
			</definition>
			<definition id="7">
				<sentence>The base system is an HMM based tagger , similar to ( Bikel et al. , 1997 ) .</sentence>
				<definiendum id="0">base system</definiendum>
			</definition>
			<definition id="8">
				<sentence>The mention detection task ( ace , 2001 ) comprises the extraction of named ( e.g. ”Mr. Isaac Asimov” ) , nominal ( e.g. ”the complete author” ) , and pronominal ( e.g. ”him” ) mentions of Persons , Organizations , Locations , Facilities , and Geo-Political Entities .</sentence>
				<definiendum id="0">mention detection task</definiendum>
				<definiens id="0">comprises the extraction of named ( e.g. ”Mr. Isaac Asimov” ) , nominal ( e.g. ”the complete author” ) , and pronominal ( e.g. ”him” ) mentions of Persons , Organizations , Locations , Facilities , and Geo-Political Entities</definiens>
			</definition>
</paper>

		<paper id="1047">
			<definition id="0">
				<sentence>Minimal Recursion Semantics ( MRS ) is the standard formalism used in large-scale HPSG grammars to model underspecified semantics .</sentence>
				<definiendum id="0">Minimal Recursion Semantics ( MRS )</definiendum>
				<definiens id="0">the standard formalism used in large-scale HPSG grammars to model underspecified semantics</definiens>
			</definition>
			<definition id="1">
				<sentence>MRS is a description language for formulas of first order object languages with generalized quantifiers .</sentence>
				<definiendum id="0">MRS</definiendum>
				<definiens id="0">a description language for formulas of first order object languages with generalized quantifiers</definiens>
			</definition>
			<definition id="2">
				<sentence>Underspecified representations in MRS consist of elementary predications and handle constraints .</sentence>
				<definiendum id="0">Underspecified</definiendum>
				<definiens id="0">representations in MRS consist of elementary predications and handle constraints</definiens>
			</definition>
			<definition id="3">
				<sentence>An MRS is finite set M of MRS-literals such that : M1 Every handle occurs at most once in label and at most once in argument position in M. M2 Handle constraints h1 ≤ h2 in M always relate argument handles h1 to labels h2 of M. M3 For every constant ( individual variable ) x in argument position in M there is a unique literal of the form h : Qx ( h1 , h2 ) in M. We call an MRS compact if it additionally satisfies : M4 Every handle of M occurs exactly once in an elementary predication of M. We say that a handle h immediately outscopes a handle hprime in an MRS M iff there is an EP E in M such that h occurs in label and hprime in argument position of E. The outscopes relation is the reflexive , transitive closure of the immediate outscopes relation .</sentence>
				<definiendum id="0">MRS</definiendum>
				<definiens id="0">finite set M of MRS-literals such that : M1 Every handle occurs at most once in label</definiens>
			</definition>
			<definition id="4">
				<sentence>Dominance constraints are the core language underlying CLLS ( Egg et al. , 2001 ) which adds parallelism and binding constraints .</sentence>
				<definiendum id="0">Dominance constraints</definiendum>
				<definiens id="0">Egg et al. , 2001 ) which adds parallelism and binding constraints</definiens>
			</definition>
			<definition id="5">
				<sentence>A dominance constraint ϕ is a conjunction of dominance , inequality , and labeling literals of the following forms where ar ( f ) = n : ϕ : := Xtriangleleft∗Y | X negationslash= Y | X : f ( X1 , ... , Xn ) | ϕ∧ϕprime Dominance constraints are interpreted over finite constructor trees , i.e. ground terms constructed from the function symbols in Σ .</sentence>
				<definiendum id="0">dominance constraint ϕ</definiendum>
				<definiens id="0">a conjunction of dominance , inequality , and labeling literals of the following forms where ar ( f ) = n : ϕ : := Xtriangleleft∗Y | X negationslash= Y | X : f ( X1 , ... , Xn ) | ϕ∧ϕprime Dominance constraints are interpreted over finite constructor trees , i.e. ground terms constructed from the function symbols in Σ</definiens>
			</definition>
			<definition id="6">
				<sentence>A solution for a dominance constraint consists of a tree τ and a variable assignment α that maps variables to nodes of τ such that all constraints are satisfied : a labeling literal X : f ( X1 , ... , Xn ) is satisfied iff the node α ( X ) is labeled with f and has daughters α ( X1 ) , ... , α ( Xn ) in this order ; a dominance literal Xtriangleleft∗Y is satisfied iff α ( X ) is an ancestor of α ( Y ) in τ ; and an inequality literal X negationslash=Y is satisfied iff α ( X ) and α ( Y ) are distinct nodes .</sentence>
				<definiendum id="0">solution for a dominance constraint</definiendum>
				<definiendum id="1">X )</definiendum>
				<definiens id="0">consists of a tree τ and a variable assignment α that maps variables to nodes of τ such that all constraints are satisfied : a labeling literal X : f ( X1 , ... , Xn ) is satisfied iff the node α ( X ) is labeled with f and has daughters α ( X1 ) , ... , α</definiens>
				<definiens id="1">an ancestor of α ( Y ) in τ ; and an inequality literal X negationslash=Y is satisfied iff α ( X ) and α ( Y ) are distinct nodes</definiens>
			</definition>
			<definition id="7">
				<sentence>N3 ( a ) if X triangleleft∗ Y occurs in ϕ , Y is a root in ϕ .</sentence>
				<definiendum id="0">N3</definiendum>
				<definiendum id="1">Y</definiendum>
				<definiens id="0">a root in ϕ</definiens>
			</definition>
			<definition id="8">
				<sentence>( b ) if X triangleleft∗ Y occurs in ϕ , X is a hole in ϕ .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">a hole in ϕ</definiens>
			</definition>
			<definition id="9">
				<sentence>The idea behind ( weak ) normality is that the constraint graph ( see below ) of a dominance constraint consists of solid fragments which are connected by dominance constraints ; these fragments may not properly overlap in solutions .</sentence>
				<definiendum id="0">dominance constraint</definiendum>
				<definiens id="0">consists of solid fragments which are connected by dominance constraints ; these fragments may not properly overlap in solutions</definiens>
			</definition>
			<definition id="10">
				<sentence>A dominance graph is the directed graph ( V , triangleleft∗unionmultitriangleleft ) .</sentence>
				<definiendum id="0">dominance graph</definiendum>
			</definition>
			<definition id="11">
				<sentence>The graph of a weakly normal constraint ϕ is defined as follows : The nodes of the graph of ϕ are the variables of ϕ .</sentence>
				<definiendum id="0">graph of a weakly normal constraint ϕ</definiendum>
				<definiens id="0">The nodes of the graph of ϕ are the variables of ϕ</definiens>
			</definition>
			<definition id="12">
				<sentence>A configuration of a constraint ϕ is a configuration that solves ϕ in the obvious sense .</sentence>
				<definiendum id="0">configuration of a constraint ϕ</definiendum>
				<definiens id="0">a configuration that solves ϕ in the obvious sense</definiens>
			</definition>
			<definition id="13">
				<sentence>The variables of ϕM are the handles of M and its literal set is : { h : Px1 , ... , xn ( h1 , ... ) | h : P ( x1 , ... , xn , h1 , ... ) ∈ M } ∪ { h : Qx ( h1 , h2 ) | h : Qx ( h1 , h2 ) ∈ M } ∪ { h1triangleleft∗h2 | h1 ≤ h2 ∈ M } ∪ { htriangleleft∗h0 | h : Qx ( h1 , h2 ) , h0 : P ( ... , x , ... ) ∈ M } ∪ { hnegationslash=hprime | h , hprime in distinct label positions of M } Compact MRSs M are clearly translated into ( compact ) weakly normal dominance constraints .</sentence>
				<definiendum id="0">Qx</definiendum>
				<definiens id="0">the handles of M and its literal set is : { h : Px1 , ... , xn ( h1 , ... ) | h : P ( x1 , ... , xn</definiens>
				<definiens id="1">P ( ... , x , ... ) ∈ M } ∪ { hnegationslash=hprime | h , hprime in distinct label positions of M } Compact MRSs M are clearly translated into ( compact ) weakly normal dominance constraints</definiens>
			</definition>
			<definition id="14">
				<sentence>A weakly connected component ( wcc ) of Φ is a maximal weakly connected subgraph of Φ .</sentence>
				<definiendum id="0">weakly connected component ( wcc ) of Φ</definiendum>
				<definiens id="0">a maximal weakly connected subgraph of Φ</definiens>
			</definition>
			<definition id="15">
				<sentence>A dominance net Φ is a weakly normal dominance constraint whose fragments all satisfy one of the three schemas in Fig .</sentence>
				<definiendum id="0">dominance net Φ</definiendum>
				<definiens id="0">a weakly normal dominance constraint whose fragments all satisfy one of the three schemas in Fig</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>Metonymy is a figure of speech , in which one expression is used to refer to the standard referent of a related one ( Lakoff and Johnson , 1980 ) .</sentence>
				<definiendum id="0">Metonymy</definiendum>
				<definiens id="0">a figure of speech , in which one expression is used</definiens>
			</definition>
			<definition id="1">
				<sentence>Table 2 : Example feature values for role-of-head role-of-head ( r-of-h ) example subj-of-win England won the World Cup ( place-for-people ) subjp-of-govern Britain has been governed by . . . ( literal ) dobj-of-visit the Apostle had visited Spain ( literal ) gen-of-strategy in Iran’sstrategy ... ( place-for-people ) premod-of-veteran a Vietnam veteran from Rhode Island ( place-for-event ) ppmod-of-with its border with Hungary ( literal ) Table 3 : Role distribution role freq # non-lit subj 92 65 subjp 64 dobj 28 12 gen 93 20 premod 94 13 ppmod 522 57 other 90 17 total 925 188 We represent each example in our corpus by a single feature role-of-head , expressing the grammatical role of the PMW ( limited to ( active ) subject , passive subject , direct object , modifier in a prenominal genitive , other nominal premodifier , dependent in a prepositional phrase ) and its lemmatised lexical head within a dependency grammar framework .</sentence>
				<definiendum id="0">World Cup</definiendum>
				<definiens id="0">expressing the grammatical role of the PMW ( limited to ( active ) subject , passive subject , direct object , modifier in a prenominal genitive , other nominal premodifier , dependent in a prepositional phrase ) and its lemmatised lexical head within a dependency grammar framework</definiens>
			</definition>
			<definition id="2">
				<sentence>For all n 1 , relax I will use the rule for subj-of-win to assign a reading to “Scotland” in ( 4 ) as “win” is the most similar word to “lose” in the thesaurus ( see Table 4 ) .</sentence>
				<definiendum id="0">“win”</definiendum>
			</definition>
			<definition id="3">
				<sentence>S2 is the set of examples that relax I covers in addition to hmr .</sentence>
				<definiendum id="0">S2</definiendum>
				<definiens id="0">the set of examples that relax I covers in addition to hmr</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>A large-scale Japanese-English parallel corpus is an invaluable resource in the study of natural language processing ( NLP ) such as machine translation and cross-language information retrieval ( CLIR ) .</sentence>
				<definiendum id="0">large-scale Japanese-English parallel corpus</definiendum>
				<definiendum id="1">CLIR</definiendum>
				<definiens id="0">an invaluable resource in the study of natural language processing ( NLP ) such as machine translation and cross-language information retrieval</definiens>
			</definition>
			<definition id="1">
				<sentence>The definition of BM25 is : BM25 ( J ; E ) = X T2E w ( 1 ) ( k1 +1 ) tfK +tf ( k3 +1 ) qtfk 3 +qtf where J is the set of translated English words of a Japanese article and E is the set of words of an English article .</sentence>
				<definiendum id="0">E</definiendum>
				<definiens id="0">BM25 ( J ; E ) = X T2E w ( 1 ) ( k1 +1 ) tfK +tf ( k3 +1 ) qtfk 3 +qtf where J is the set of translated English words of a Japanese article</definiens>
				<definiens id="1">the set of words of an English article</definiens>
			</definition>
			<definition id="2">
				<sentence>N is the number of Japanese articles to be searched .</sentence>
				<definiendum id="0">N</definiendum>
				<definiens id="0">the number of Japanese articles to be searched</definiens>
			</definition>
			<definition id="3">
				<sentence>n is the number of articles containing T. K is k1 ( ( 1 ¡ b ) + b dlavdl ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">the number of articles containing T. K is k1 ( ( 1 ¡ b ) + b dlavdl )</definiens>
			</definition>
			<definition id="4">
				<sentence>dl is the document length of J and avdl is the average document length in words .</sentence>
				<definiendum id="0">dl</definiendum>
				<definiens id="0">the document length of J and avdl is the average document length in words</definiens>
			</definition>
			<definition id="5">
				<sentence>BM25 measures the similarity between two bags of words .</sentence>
				<definiendum id="0">BM25</definiendum>
				<definiens id="0">measures the similarity between two bags of words</definiens>
			</definition>
			<definition id="6">
				<sentence>However , when we compare the validity of two sentence alignments in different article alignments , SntScore prefers the sentence alignment with the more similar ( high AVSIM ) article alignment even if their SIM has the same value , while SIM can not discriminate between the validity of two sentence alignments if their SIM has the same value .</sentence>
				<definiendum id="0">SntScore</definiendum>
				<definiendum id="1">SIM</definiendum>
				<definiens id="0">the validity of two sentence alignments in different article alignments</definiens>
			</definition>
			<definition id="7">
				<sentence>A 59 0.176 0.193 0.209 0.168 ** B 12 0.122 0.151 0.179 0.111 ** C 8 0.077 0.094 0.110 0.085 * D 21 0.065 0.075 0.086 Table 3 : Statistics on AVSIM ( 1996-2001 ) In these tables , “N” means the number of alignments against the corresponding human judgment .</sentence>
				<definiendum id="0">“N”</definiendum>
				<definiens id="0">means the number of alignments against the corresponding human judgment</definiens>
			</definition>
			<definition id="8">
				<sentence>( 1 ) We have proposed AVSIM , which uses similarities in sentences aligned by DP matching , as a reliable measure for article alignment .</sentence>
				<definiendum id="0">AVSIM</definiendum>
				<definiens id="0">uses similarities in sentences aligned by DP matching</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>The Negra corpus consists of around 350,000 words of German newspaper text ( 20,602 sentences ) .</sentence>
				<definiendum id="0">Negra corpus</definiendum>
			</definition>
			<definition id="1">
				<sentence>LHS is annotated with an expansion probability P ( RHSjLHS ) .</sentence>
				<definiendum id="0">LHS</definiendum>
			</definition>
			<definition id="2">
				<sentence>L m : : : L 1 HR 1 : : : R n where P is the mother and H is the head daughter .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">H</definiendum>
				<definiens id="0">the head daughter</definiens>
			</definition>
			<definition id="3">
				<sentence>Let l ( C ) be the head word of C and t ( C ) the tag of the head word of C. Then the probability of a rule is defined as : P ( RHSjLHS ) =P ( L m : : : L 1 HR 1 : : : R n jP ) ( 4 ) = P h ( HjP ) P l ( L m : : : L 1 jP ; H ) P r ( R 1 : : : R n jP ; H ) = P h ( HjP ) m ∏ i=0 P l ( L i jP ; H ; d ( i ) ) n ∏ i=0 P r ( R i jP ; H ; d ( i ) ) Here , P h is the probability of generating the head , and P l and P r are the probabilities of generating the nonterminals to the left and right of the head , respectively ; d ( i ) is a distance measure .</sentence>
				<definiendum id="0">Let l ( C )</definiendum>
				<definiendum id="1">C</definiendum>
				<definiendum id="2">P h</definiendum>
				<definiendum id="3">P r</definiendum>
				<definiendum id="4">d ( i )</definiendum>
				<definiens id="0">: : R n jP ) ( 4 ) = P h ( HjP ) P l ( L m : : : L 1 jP ; H ) P r ( R 1 : : : R n jP ; H ) = P h</definiens>
			</definition>
			<definition id="4">
				<sentence>The Collins model treats any word seen fewer than five times in the training data as unseen and uses an external POS tagger to tag unknown words .</sentence>
				<definiendum id="0">Collins model</definiendum>
				<definiens id="0">treats any word seen fewer than five times in the training data as unseen and uses an external POS tagger to tag unknown words</definiens>
			</definition>
			<definition id="5">
				<sentence>The most surprising finding is that the best performance was achieved by the unlexicalized PCFG TnT tagging Perfect tagging LR LP CBs 0CB 2CB Cov LR LP CBs 0CB 2CB Cov Baseline 70.56 66.69 1.03 58.21 84.46 94.42 72.99 70.00 0.88 60.30 87.42 95.25 Baseline + GF 70.45 65.49 1.07 58.02 85.01 79.24 81.14 78.37 0.46 74.25 95.26 65.39 C &amp; R 68.04 60.07 1.31 52.08 79.54 94.42 70.79 63.38 1.17 54.99 82.21 95.25 C &amp; R + pool 69.07 61.41 1.28 53.06 80.09 94.42 71.74 64.73 1.11 56.40 83.08 95.25 C &amp; R + GF 67.66 60.33 1.31 55.67 80.18 79.24 81.17 76.83 0.48 73.46 94.15 65.39 Collins 67.91 66.07 0.73 65.67 89.52 95.21 68.63 66.94 0.71 64.97 89.73 96.23 Table 2 : Results for Experiment 1 : comparison of lexicalized and unlexicalized models ( GF : grammatical functions ; pool : parameter pooling for NPs/PPs and conjoined categories ) 0 2040608010 percent of training corpus 45 50 55 60 65 70 75 f-score unlexicalized PCFG lexicalized PCFG ( Collins ) lexicalized PCFG ( C &amp; R ) Figure 1 : Learning curves for all three models baseline model .</sentence>
				<definiendum id="0">GF</definiendum>
				<definiens id="0">grammatical functions ; pool : parameter pooling for NPs/PPs and conjoined categories ) 0 2040608010 percent of training corpus 45 50 55 60 65 70 75 f-score unlexicalized PCFG lexicalized PCFG ( Collins ) lexicalized PCFG ( C &amp; R ) Figure 1 : Learning curves for all three models baseline model</definiens>
			</definition>
			<definition id="6">
				<sentence>Becker and Frank ( 2002 ) train an unlexicalized PCFG on Negra to perform a different chunking task , viz. , the identification of topological fields ( sentence-based chunks ) .</sentence>
				<definiendum id="0">Becker</definiendum>
				<definiens id="0">the identification of topological fields ( sentence-based chunks )</definiens>
			</definition>
</paper>

		<paper id="2008">
			<definition id="0">
				<sentence>In this paper , we apply our approach to the OHSUMED test collection ( Hersh et al. , 1994 ) , which is a public test collection for information retrieval in the field of biomedical science but not tag-annotated .</sentence>
				<definiendum id="0">OHSUMED test collection</definiendum>
				<definiens id="0">a public test collection for information retrieval in the field of biomedical science but not tag-annotated</definiens>
			</definition>
			<definition id="1">
				<sentence>For convenience of explanation , we represent a query as a tree structure as shown in Figure 1 ( ‘ [ x ] ’ is a abbreviation of ‘hxi 3 h/xi’ ) .</sentence>
				<definiendum id="0">’</definiendum>
				<definiens id="0">a abbreviation of ‘hxi 3 h/xi’ )</definiens>
			</definition>
			<definition id="2">
				<sentence>Num Query 1 ‘ ( [ cons ] ⁄ ( [ sem ] ⁄ “G # DNA domain or region” ) ) 4 ( “in” 3 ( [ cons ] ⁄ ( [ sem ] ⁄ ( “G # tissue” 5 “G # body part” ) ) ) ) ’ 2 ‘ ( [ event ] ⁄ ( [ obj ] ⁄ “gene” ) ) 4 ( “in” 3 ( [ cons ] ⁄ ( [ sem ] ⁄ ( “G # tissue” 5 “G # body part” ) ) ) ) ’ 3 ‘ ( [ event ] ⁄ ( [ obj ] 3 ( [ sem ] ⁄“G # DNA domain or region” ) ) ) 4 ( “in”3 ( [ cons ] ⁄ ( [ sem ] ⁄ ( “G # tissue”5“G # body part” ) ) ) ) ’ Table 3 : Queries submitted in the experiments on the GENIA corpus Definition 4 ( Structure Coefficient ) When the operator op is 4 , 5 or 3 , the structure coefficient of the query A op B is : scAopB = C ( A ) +C ( B ) ¡C ( A op B ) C ( A ) +C ( B ) and when the operator op is ⁄ or ¢ , the structure coefficient of the query A op B is : scAopB = C ( A ) ¡C ( A op B ) C ( A ) where A and B are the queries and C ( A ) is the number of extents that match A in the document collection .</sentence>
				<definiendum id="0">op</definiendum>
				<definiendum id="1">) +C ( B ) ¡C ( A op B ) C</definiendum>
				<definiendum id="2">B</definiendum>
				<definiens id="0">Queries submitted in the experiments on the GENIA corpus Definition 4 ( Structure Coefficient ) When the operator</definiens>
				<definiens id="1">the structure coefficient of the query A op B is : scAopB = C ( A ) ¡C ( A op B ) C ( A ) where A and</definiens>
			</definition>
			<definition id="3">
				<sentence>The scalar measure ‰sc ( qi ; d ) is then defined as ‰sc ( q ; d ) = mX i=1 scqi ¢ ( qi ; d ) The third is a combination of the measure of the query itself and the measure of the subqueries .</sentence>
				<definiendum id="0">scalar measure ‰sc</definiendum>
			</definition>
			<definition id="4">
				<sentence>Definition 5 ( Interpolated Coefficient ) The interpolated coefficient of the query qi is recursively defined as follows : ‰ic ( qi ; d ) = ‚¢ ( qi ; d ) + ( 1¡‚ ) P ci ‰ic ( qci ; d ) l where ci is the child of node ni , l is the number of children of node ni , and 0 • ‚ • 1 .</sentence>
				<definiendum id="0">Definition 5 ( Interpolated Coefficient ) The interpolated coefficient</definiendum>
				<definiendum id="1">ci</definiendum>
				<definiendum id="2">l</definiendum>
				<definiens id="0">‰ic ( qi ; d ) = ‚¢ ( qi ; d ) + ( 1¡‚ ) P ci ‰ic ( qci ; d ) l where</definiens>
				<definiens id="1">the child of node ni</definiens>
				<definiens id="2">the number of children of node ni , and 0 • ‚ • 1</definiens>
			</definition>
			<definition id="5">
				<sentence>The OHSUMED test collection is a document set composed of paper abstracts in the field of biomedQuery our model exact flat ‰sum ‰sc ‰ic ‰ic ‰ic ( ‚ = 0.25 ) ( ‚ = 0.5 ) ( ‚ = 0.75 ) 1 10/10 10/10 8/10 9/10 9/10 9/10 9/10 2 6/10 6/10 6/10 6/10 6/10 5/ 5 3/10 3 10/10 10/10 10/10 10/10 10/10 9/ 9 8/10 Table 5 : ( The number of relevant results ) / ( the number of all results ) in top 10 results on the GENIA corpus Query our model exact flat ‰sum ‰sc ‰ic ‰ic ‰ic ( ‚ = 0.25 ) ( ‚ = 0.5 ) ( ‚ = 0.75 ) 4 7/10 7/10 4/10 4/10 4/10 5/12 4/10 5 4/10 3/10 2/10 3/10 3/10 2/9 2/10 6 8/10 8/10 7/10 7/10 7/10 12/34 6/10 7 1/10 0/10 0/10 0/10 0/10 0/0 0/10 8 5/10 5/10 4/10 2/10 2/10 2/2 5/10 9 0/10 0/10 4/10 5/10 4/10 0/1 0/10 10 1/10 1/10 1/10 1/10 0/10 0/0 1/10 11 4/10 4/10 2/10 3/10 5/10 0/0 4/10 12 3/10 3/10 2/10 2/10 2/10 0/0 3/10 13 2/10 1/10 0/10 1/10 0/10 0/1 3/10 14 1/10 1/10 1/10 1/10 1/10 0/5 3/10 15 3/10 3/10 5/10 2/10 3/10 0/1 8/10 Table 6 : ( The number of relevant results ) / ( the number of all results ) in top 10 judged results on the OHSUMED test collection ( “all results” are relevance-judged results in the exact model ) ical science .</sentence>
				<definiendum id="0">OHSUMED test collection</definiendum>
				<definiendum id="1">biomedQuery</definiendum>
				<definiens id="0">a document set composed of paper abstracts in the field of</definiens>
			</definition>
</paper>

		<paper id="1039">
			<definition id="0">
				<sentence>A scenario for the word alignment based translation model defined by Brown et al. ( 1993 ) , for instance IBM Model 4 , goes as follows ( refer to Figure 2 ) .</sentence>
				<definiendum id="0">scenario for</definiendum>
				<definiens id="0">the word alignment based translation model defined by Brown et al. ( 1993 ) , for instance IBM Model 4 , goes as follows ( refer to Figure 2 )</definiens>
			</definition>
			<definition id="1">
				<sentence>Chunk-based statistical translation models the process of chunking for both the source and target sentences , E and J , P ( J|E ) = summationdisplay J summationdisplay E P ( J , J , E|E ) where J and E are the chunked sentences for J and E , respectively , defined as two-dimentional arE= show 1 me 2 1 the 3 one 4 2 in 5 the 6 window 7 3 mise 5 tekudasai 6 shinamono 3 o 4 uindo 1 no 2 J= uindo 1 no 2 1 shinamono 3 o 4 2 mise 5 tekudasai 6 3 A= ( 3 2 1 ) A= ( [ 7 , 0 ] [ 4 , 0 ] [ 1 , 1 ] ) Figure 3 : Example of chunk-based alignment rays .</sentence>
				<definiendum id="0">Chunk-based statistical translation</definiendum>
				<definiendum id="1">A=</definiendum>
				<definiens id="0">models the process of chunking for both the source and target sentences , E and J , P ( J|E ) = summationdisplay J summationdisplay E P ( J , J , E|E ) where J and E are the chunked sentences for J and E , respectively , defined as two-dimentional arE= show 1 me 2 1 the 3 one 4 2 in 5 the 6 window 7 3 mise 5 tekudasai 6 shinamono 3 o 4 uindo 1 no 2 J= uindo 1 no 2 1 shinamono 3 o 4 2 mise</definiens>
			</definition>
			<definition id="2">
				<sentence>Each non-head word E i is associated to a head word E h by the probabilityη ( c ( E h ) |h−i , c ( E i ) ) , where h is the position of a head word and c ( E ) is a function to map a word E to its word class ( i.e. POS ) .</sentence>
				<definiendum id="0">h</definiendum>
				<definiendum id="1">c ( E )</definiendum>
				<definiens id="0">a function to map a word E to its word class ( i.e. POS )</definiens>
			</definition>
			<definition id="3">
				<sentence>The chunk reordering is taken after the Distortion Model of IBM Model 4 , where the position is determined by the relative position from the head word , P ( A j |E A j , J j ) = |A j | productdisplay k=1 ρ ( k−h|c ( E A A j , k ) , c ( J j , k ) ) where h is the position of a head word for the chunkJ j .</sentence>
				<definiendum id="0">chunk reordering</definiendum>
				<definiendum id="1">h</definiendum>
				<definiens id="0">taken after the Distortion Model of IBM Model 4 , where the position is determined by the relative position from the head word</definiens>
				<definiens id="1">the position of a head word for the chunkJ j</definiens>
			</definition>
			<definition id="4">
				<sentence>The decoder consists of two stages : ble input chunks .</sentence>
				<definiendum id="0">decoder</definiendum>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>Contexts are defined as a small number of words surrounding the target word ( Lund and Burgess , 1996 ; Lowe and McDonald , 2000 ) or as entire paragraphs , even documents ( Landauer and Dumais , 1997 ) .</sentence>
				<definiendum id="0">Contexts</definiendum>
			</definition>
			<definition id="1">
				<sentence>The paths consist of the dependency edges of the tree labelled with dependency relations such as subj , obj , or aux ( see Figure 1 ) .</sentence>
				<definiendum id="0">paths</definiendum>
			</definition>
			<definition id="2">
				<sentence>A semantic space is a matrix whose rows correspond to target words and columns to dimensions which Lowe calls basis elements : Definition 1 .</sentence>
				<definiendum id="0">semantic space</definiendum>
				<definiens id="0">a matrix whose rows correspond to target words and columns to dimensions which Lowe calls basis elements : Definition 1</definiens>
			</definition>
			<definition id="3">
				<sentence>A Semantic Space Model is a matrix K = B T , where bi 2 B denotes the basis element of column i , t j 2 T denotes the target word of row j , and Ki j the cell ( i ; j ) .</sentence>
				<definiendum id="0">Semantic Space Model</definiendum>
				<definiendum id="1">B</definiendum>
				<definiens id="0">a matrix K = B T , where bi 2</definiens>
				<definiens id="1">the basis element of column i , t j 2 T denotes the target word of row j , and Ki j the cell ( i ; j )</definiens>
			</definition>
			<definition id="4">
				<sentence>T is the set of words for which the matrix contains representations ; this can be either word types or word tokens .</sentence>
				<definiendum id="0">T</definiendum>
				<definiens id="0">the set of words for which the matrix contains representations</definiens>
			</definition>
			<definition id="5">
				<sentence>The dependency parse p of a sentence s is an undirected graph p ( s ) = ( Vp ; Ep ) .</sentence>
				<definiendum id="0">dependency parse p of a sentence s</definiendum>
				<definiens id="0">an undirected graph p ( s ) =</definiens>
			</definition>
			<definition id="6">
				<sentence>Note that Det represents the POS-tag “determiner” and det the dependency relation “determiner” .</sentence>
				<definiendum id="0">Det</definiendum>
				<definiens id="0">the POS-tag “determiner” and det the dependency relation “determiner”</definiens>
			</definition>
			<definition id="7">
				<sentence>A path φ is an ordered tuple of edges he1 ; : : : ; eni2 Enp so that 8i : ( ei 1 = ( v1 ; v2 ) ^ ei = ( v3 ; v4 ) ) ) v2 = v3 Definition 5 .</sentence>
				<definiendum id="0">path φ</definiendum>
			</definition>
			<definition id="8">
				<sentence>Write Φw for the set of all paths over Ep anchored at w. In words , a path is a tuple of connected edges in a parse graph and it is anchored at w if it starts at w. In Figure 1 , the set of paths anchored at lorry 1 is : fh ( lorry ; carry ) i ; h ( lorry ; carry ) ; ( carry ; apples ) i ; h ( lorry ; a ) i ; h ( lorry ; carry ) ; ( carry ; might ) i ; : : : g The local context of a word is the set or a subset of its anchored paths .</sentence>
				<definiendum id="0">path</definiendum>
				<definiens id="0">the set or a subset of its anchored paths</definiens>
			</definition>
			<definition id="9">
				<sentence>The partition induced by this equivalence relation is the set of basis elements B. For example , it is possible to combine all paths which end at the same word : A path which starts at wi and ends at w j , irrespectively of its length and class , will be the co-occurrence of wi and w j. This word-based equivalence function can be defined in the following manner : h ( v1 ; v2 ) ; : : : ; ( vn 1 ; vn ) i h ( v01 ; v02 ) ; : : : ; ( v0m 1 ; v0m ) i iff vn = v0m This means that in Figure 1 the set of basis elements is the set of words at which paths end .</sentence>
				<definiendum id="0">equivalence relation</definiendum>
				<definiens id="0">A path which starts at wi</definiens>
			</definition>
			<definition id="10">
				<sentence>Once the value of all paths in the local context is determined , the local observed frequency for the co-occurrence of a basis element b with the target word w is just the sum of values of all paths φ in this context which express the basis element b. The global observed frequency is the sum of the local observed frequencies for all occurrences of a target word type t and is therefore a measure for the cooccurrence of t and b over the whole corpus .</sentence>
				<definiendum id="0">frequency</definiendum>
				<definiens id="0">the sum of the local observed frequencies for all occurrences of a target word type t</definiens>
			</definition>
			<definition id="11">
				<sentence>Lexicon entries contain part-of-speech and subcategorization information .</sentence>
				<definiendum id="0">Lexicon entries</definiendum>
				<definiens id="0">contain part-of-speech and subcategorization information</definiens>
			</definition>
			<definition id="12">
				<sentence>MINIPAR uses a distributed chart parsing algorithm .</sentence>
				<definiendum id="0">MINIPAR</definiendum>
				<definiens id="0">uses a distributed chart parsing algorithm</definiens>
			</definition>
			<definition id="13">
				<sentence>The Skew divergence represents a generalisation of the Kullback-Leibler divergence and was proposed by Lee ( 1999 ) as a linguistically motivated distance measure .</sentence>
				<definiendum id="0">Skew divergence</definiendum>
				<definiens id="0">a generalisation of the Kullback-Leibler divergence</definiens>
			</definition>
			<definition id="14">
				<sentence>The semantic priming paradigm provides a natural test bed for semantic space models as it concentrates on the semantic similarity or dissimilarity between a prime and its target , and it is precisely this type of lexical relations that vectorbased models capture .</sentence>
				<definiendum id="0">semantic priming paradigm</definiendum>
				<definiens id="0">provides a natural test bed for semantic space models as it concentrates on the semantic similarity</definiens>
			</definition>
			<definition id="15">
				<sentence>Our experimental materials were taken from Hodgson ( 1991 ) who in an attempt to investigate which types of lexical relations induce priming collected a set of 142 word pairs exemplifying the following semantic relations : ( a ) synonymy ( words with the same meaning , value and worth ) , ( b ) superordination and subordination ( one word is an instance of the kind expressed by the other word , pain and sensation ) , ( c ) category coordination ( words which express two instances of a common superordinate concept , truck and train ) , ( d ) antonymy ( words with opposite meaning , friend and enemy ) , ( e ) conceptual association ( the first word subjects produce in free association given the other word , leash and dog ) , and ( f ) phrasal association ( words which co-occur in phrases private and property ) .</sentence>
				<definiendum id="0">( f ) phrasal association</definiendum>
				<definiens id="0">words with the same meaning , value and worth</definiens>
				<definiens id="1">an instance of the kind expressed by the other word , pain and sensation</definiens>
				<definiens id="2">the first word subjects produce in free association given the other word , leash and dog ) , and</definiens>
				<definiens id="3">words which co-occur in phrases private and property )</definiens>
			</definition>
			<definition id="16">
				<sentence>In fact an ANOVA reveals that the distinction between these two classes of relations can be made reliably ( F ( 1 ; 136 ) = 15:347 , p &lt; :001 ) , after collapsing SYN , SUP , CO , and ANT into one class and CA and PA into another .</sentence>
				<definiendum id="0">ANT</definiendum>
				<definiens id="0">after collapsing SYN , SUP , CO , and</definiens>
			</definition>
			<definition id="17">
				<sentence>Our approach differs from Lin ( 1998 ) in three important ways : ( a ) by introducing dependency paths we can capture non-immediate relationships between words ( i.e. , between subjects and objects ) , whereas Lin considers only local context ( dependency edges in our terminology ) ; the semantic space is therefore constructed solely from isolated head/modifier pairs and their inter-dependencies are not taken into account ; ( b ) Lin creates the semantic space from the set of dependency edges that are relevant for a given word ; by introducing dependency labels and the path value function we can selectively weight the importance of different labels ( e.g. , subject , object , modifier ) and parametrize the space accordingly for different tasks ; ( c ) considerable flexibility is allowed in our formulation for selecting the dimensions of the semantic space ; the latter can be words ( see the leaves in Figure 1 ) , parts of speech or dependency edges ; in Lin’s approach , it is only dependency edges ( features in his terminology ) that form the dimensions of the semantic space .</sentence>
				<definiendum id="0">Lin</definiendum>
				<definiens id="0">creates the semantic space from the set of dependency edges that are relevant for a given word ; by introducing dependency labels and the path value function we can selectively weight the importance of different labels ( e.g. , subject , object , modifier</definiens>
			</definition>
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>Theoretical motivation for this formulation can be found in ( Birkhoff and von Neumann , 1936 , §1 , §6 ) and ( Widdows and Peters , 2003 ) : for example , B is the smallest subspace of V which contains the set { bj } .</sentence>
				<definiendum id="0">B</definiendum>
				<definiens id="0">the smallest subspace of V which contains the set { bj }</definiens>
			</definition>
			<definition id="1">
				<sentence>The effect of LSA is to increase linear dependency between terms , and for this reason it is likely that LSA is a crucial step in our approach .</sentence>
				<definiendum id="0">effect of LSA</definiendum>
				<definiendum id="1">LSA</definiendum>
				<definiens id="0">to increase linear dependency between terms</definiens>
			</definition>
			<definition id="2">
				<sentence>retrieval A traditional Boolean search for documents related to the query a NOT bwould return simply thosedocuments which contain the term a and do not contain the term b. More formally , let D be the document collection and let Di ⊂ D be the subset of documents containing the term i. Then the results to the Boolean query for a NOT b would be the set Da∩Dprimeb , where Dprimeb is the complement of Db in D. Variants of this are used within a vector model , by using vector retrieval to retrieve a ( ranked ) set of relevant documents and then ‘throwing away’ documents containing the unwanted terms ( Salton and McGill , 1983 , p. 26 ) .</sentence>
				<definiendum id="0">Dprimeb</definiendum>
				<definiens id="0">the subset of documents containing the term i. Then the results to the Boolean query for a NOT b would be the set Da∩Dprimeb , where</definiens>
			</definition>
			<definition id="3">
				<sentence>In this process , documents judged to be relevant have ( some multiple of ) their document vector added to the query : documents judged to be non-relevant have ( some multiple of ) their document vector subtracted from the query , producing a new query according to the formula Qi+1 = αQi +β summationdisplay rel Di |Di| −γ summationdisplay nonrel Di |Di| , where Qi is the ith query vector , Di is the set of documents returned by Qi which has been partitioned into relevant and non-relevant subsets , and α , β , γ ∈ R are constants .</sentence>
				<definiendum id="0">Qi</definiendum>
				<definiendum id="1">Di</definiendum>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>Machines Suppose we have a set of training data for a binary classification problem : ( x1 ; y1 ) ; : : : ; ( xL ; yL ) xj 2 &lt; N ; yj 2f+1 ; ¡1g ; where xj is a feature vector of the j-th training sample , and yj is the class label associated with this training sample. The decision function of SVMs is defined by y ( x ) = sgn ‡ X j2SV yjfij` ( xj ) ¢` ( x ) +b · ; ( 1 ) where : ( A ) ` is a non-liner mapping function from &lt; N to &lt; H ( N ¿ H ) . ( B ) fij ; b 2 &lt; ; fij ‚ 0. The mapping function ` should be designed such that all training examples are linearly separable in &lt; H space. Since H is much larger than N , it requires heavy computation to evaluate the dot products ` ( xi ) ¢` ( x ) in an explicit form. This problem can be overcome by noticing that both construction of optimal parameter fii ( we will omit the details of this construction here ) and the calculation of the decision function only require the evaluation of dot products ` ( xi ) ¢` ( x ) . This is critical , since , in some cases , the dot products can be evaluated by a simple Kernel Function : K ( x1 ; x2 ) = ` ( x1 ) ¢` ( x2 ) . Substituting kernel function into ( 1 ) , we have the following decision function. y ( x ) = sgn ‡ X j2SV yjfijK ( xj ; x ) +b · ( 2 ) One of the advantages of kernels is that they are not limited to vectorial object x , but that they are applicable to any kind of object representation , just given the dot products. For many tasks in NLP , the training and test examples are represented in binary vectors ; or sets , since examples in NLP are usually represented in socalled Feature Structures. Here , we focus on such cases 1. Suppose a feature set F = f1 ; 2 ; : : : ; Ng and training examples Xj ( j = 1 ; 2 ; : : : ; L ) , all of which are subsets of F ( i.e. , Xj F ) . In this case , Xj can be regarded as a binary vector xj = ( xj1 ; xj2 ; : : : ; xjN ) where xji = 1 if i 2 Xj , xji = 0 otherwise. The dot product of x1 and x2 is given by x1 ¢x2 = jX1 \X2j. Definition 1 Polynomial Kernel of degree d Given sets X and Y , corresponding to binary feature vectors x and y , Polynomial Kernel of degree d Kd ( X ; Y ) is given by Kd ( x ; y ) = Kd ( X ; Y ) = ( 1+jX \Yj ) d ; ( 3 ) where d = 1 ; 2 ; 3 ; : : : . In this paper , ( 3 ) will be referred to as an implicit form of the Polynomial Kernel. 1In the Maximum Entropy model widely applied in NLP , we usually suppose binary feature functions fi ( Xj ) 2f0 ; 1g. This formalization is exactly same as representing an example Xj in a set fkjfk ( Xj ) = 1g. It is known in NLP that a combination of features , a subset of feature set F in general , contributes to overall accuracy. In previous research , feature combination has been selected manually. The use of a polynomial kernel allows such feature expansion without loss of generality or an increase in computational costs , since the Polynomial Kernel of degree d implicitly maps the original feature space F into Fd space. ( i.e. , ` : F ! Fd ) . This property is critical and some reports say that , in NLP , the polynomial kernel outperforms the simple linear kernel ( Kudo and Matsumoto , 2000 ; Isozaki and Kazawa , 2002 ) . Here , we will give an explicit form of the Polynomial Kernel to show the mapping function ` ( ¢ ) . Lemma 1 Explicit form of Polynomial Kernel. The Polynomial Kernel of degree d can be rewritten as Kd ( X ; Y ) = dX r=0 cd ( r ) ¢jPr ( X \Y ) j ; ( 4 ) where † Pr ( X ) is a set of all subsets of X with exactly r elements in it , † cd ( r ) = Pdl=r¡dl¢ ‡Pr m=0 ( ¡1 ) r¡m ¢ml ¡r m ¢·. Proof See Appendix A. cd ( r ) will be referred as a subset weight of the Polynomial Kernel of degree d. This function gives a prior weight to the subset s , where jsj = r. Example 1 Quadratic and Cubic Kernel Given sets X = fa ; b ; c ; dg and Y = fa ; b ; d ; eg , the Quadratic Kernel K2 ( X ; Y ) and the Cubic Kernel K3 ( X ; Y ) can be calculated in an implicit form as : K2 ( X ; Y ) = ( 1+jX \Yj ) 2 = ( 1+3 ) 2 = 16 , K3 ( X ; Y ) = ( 1+jX \Yj ) 3 = ( 1+3 ) 3 = 64. Using Lemma 1 , the subset weights of the Quadratic Kernel and the Cubic Kernel can be calculated as c2 ( 0 ) = 1 ; c2 ( 1 ) = 3 ; c2 ( 2 ) = 2 and c3 ( 0 ) =1 ; c3 ( 1 ) =7 ; c3 ( 2 ) =12 ; c3 ( 3 ) =6. In addition , subsets Pr ( X\Y ) ( r = 0 ; 1 ; 2 ; 3 ) are given as follows : P0 ( X \ Y ) = f`g ; P1 ( X\Y ) =ffag ; fbg ; fdgg ; P2 ( X\Y ) = ffa ; bg ; fa ; dg ; fb ; dgg ; P3 ( X\Y ) = ffa ; b ; dgg. K2 ( X ; Y ) and K3 ( X ; Y ) can similarly be calculated in an explicit form as : function PKI classify ( X ) r = 0 # an array , initialized as 0 foreach i2X foreach j 2h ( i ) rj = rj +1 endend result = 0foreach j 2 SV result = result+yjfij ¢ ( 1+rj ) d endreturn sgn ( result+b ) end Figure 1 : Pseudo code for PKI K2 ( X ; Y ) = 1¢1+3¢3+2¢3 = 16 , K3 ( X ; Y ) = 1¢1+7¢3+12¢3+6¢1 = 64. In this section , we introduce two fast classification algorithms for the Polynomial Kernel of degree d. Before describing them , we give the baseline classifier ( PKB ) : y ( X ) = sgn ‡ X j2SV yjfij ¢ ( 1+jXj \Xj ) d +b · : ( 5 ) The complexity of PKB is O ( jXj ¢ jSVj ) , since it takes O ( jXj ) to calculate ( 1+jXj \Xj ) d and there are a total of jSVj support examples. Given an item i 2 F , if we know in advance the set of support examples which contain item i 2 F , we do not need to calculate jXj \Xj for all support examples. This is a naive extension of Inverted Indexing in Information Retrieval. Figure 1 shows the pseudo code of the algorithm PKI. The function h ( i ) is a pre-compiled table and returns a set of support examples which contain item i. The complexity of the PKI is O ( jXj¢B +jSVj ) , where B is an average of jh ( i ) j over all item i 2 F. The PKI can make the classification speed drastically faster when B is small , in other words , when feature space is relatively sparse ( i.e. , B ¿ jSVj ) . The feature space is often sparse in many tasks in NLP , since lexical entries are used as features. The algorithm PKI does not change the final accuracy of the classification. Using Lemma 1 , we can represent the decision function ( 5 ) in an explicit form : y ( X ) = sgn ‡X j2SV yjfij¡ dX r=0 cd ( r ) ¢jPr ( Xj \X ) j¢+b · : ( 6 ) If we , in advance , calculate w ( s ) = X j2SV yjfijcd ( jsj ) I ( s 2 Pjsj ( Xj ) ) ( where I ( t ) is an indicator function 2 ) for all subsets s 2Sdr=0 Pr ( F ) , ( 6 ) can be written as the following simple linear form : y ( X ) = sgn ‡ X s2Γd ( X ) w ( s ) +b · : ( 7 ) where Γd ( X ) = Sdr=0 Pr ( X ) . The classification algorithm given by ( 7 ) will be referred to as PKE. The complexity of PKE is O ( jΓd ( X ) j ) = O ( jXjd ) , independent on the number of support examples jSVj. To apply the PKE , we first calculate jΓd ( F ) j degree of vectors w = ( w ( s1 ) ; w ( s2 ) ; : : : ; w ( sjΓd ( F ) j ) ) : This calculation is trivial only when we use a Quadratic Kernel , since we just project the original feature space F into F £ F space , which is small enough to be calculated by a naive exhaustive method. However , if we , for instance , use a polynomial kernel of degree 3 or higher , this calculation becomes not trivial , since the size of feature space exponentially increases. Here we take the following strategy : w0 , an approximation of w. culate w0 efficiently. 2I ( t ) returns 1 if t is true , returns 0 otherwise. Definition 2 w0 : An approximation of w An approximation of w is given by w0 = ( w0 ( s1 ) ; w0 ( s2 ) ; : : : ; w0 ( sjΓd ( F ) j ) ) , where w0 ( s ) is set to 0 if w ( s ) is trivially close to 0. ( i.e. , neg &lt; w ( s ) &lt; pos ( neg &lt; 0 ; pos &gt; 0 ) , where pos and neg are predefined thresholds ) .</sentence>
				<definiendum id="0">xj</definiendum>
				<definiendum id="1">yj</definiendum>
				<definiendum id="2">P1 ( X\Y</definiendum>
				<definiendum id="3">P2</definiendum>
				<definiendum id="4">P3</definiendum>
				<definiendum id="5">dgg. K2</definiendum>
				<definiendum id="6">K3</definiendum>
				<definiens id="0">a feature vector of the j-th training sample , and</definiens>
				<definiens id="1">the class label associated with this training sample. The decision function of SVMs is defined by y ( x ) = sgn ‡ X j2SV yjfij` ( xj ) ¢` ( x ) +b · ; ( 1 ) where : ( A ) ` is a non-liner mapping function from &lt; N to &lt; H ( N ¿ H ) . ( B ) fij ; b 2 &lt; ; fij ‚ 0. The mapping function ` should be designed such that all training examples are linearly separable in &lt; H space. Since H is much larger than N , it requires heavy computation to evaluate the dot products ` ( xi ) ¢` ( x ) in an explicit form. This problem can be overcome by noticing that both construction of optimal parameter fii</definiens>
				<definiens id="2">the dot products can be evaluated by a simple Kernel Function : K ( x1 ; x2 ) = ` ( x1 ) ¢` ( x2 )</definiens>
				<definiens id="3">y ( x ) = sgn ‡ X j2SV yjfijK ( xj ; x ) +b · ( 2 ) One of the advantages of kernels is that they are not limited to vectorial object x , but that they are applicable to any kind of object representation , just given the dot products. For many tasks in NLP , the training and test examples are represented in binary vectors ; or sets , since examples in NLP are usually represented in socalled Feature Structures. Here , we focus on such cases 1. Suppose a feature set F = f1 ; 2 ; : : : ; Ng and training examples Xj ( j = 1 ; 2 ; : : : ; L ) , all of which are subsets of F ( i.e. , Xj F )</definiens>
				<definiens id="4">a binary vector xj = ( xj1 ; xj2 ; : : : ; xjN ) where xji = 1 if i 2 Xj , xji = 0 otherwise. The dot product of x1 and x2 is given by x1 ¢x2 = jX1 \X2j. Definition 1 Polynomial Kernel of degree d Given sets X and Y , corresponding to binary feature vectors x and y , Polynomial Kernel of degree d Kd ( X ; Y ) is given by Kd ( x ; y ) = Kd ( X</definiens>
				<definiens id="5">an implicit form of the Polynomial Kernel. 1In the Maximum Entropy model widely applied in NLP</definiens>
				<definiens id="6">representing an example Xj in a set fkjfk ( Xj ) = 1g. It is known in NLP that a combination of features , a subset of feature set F in general , contributes to overall accuracy. In previous research , feature combination has been selected manually. The use of a polynomial kernel allows such feature expansion without loss of generality or an increase in computational costs , since the Polynomial Kernel of degree d implicitly maps the original feature space F into Fd space. ( i.e. , ` : F ! Fd ) . This property is critical and some reports say that , in NLP , the polynomial kernel outperforms the simple linear kernel ( Kudo and Matsumoto , 2000 ; Isozaki and Kazawa , 2002 ) . Here , we will give an explicit form of the Polynomial Kernel to show the mapping function ` ( ¢ ) . Lemma 1 Explicit form of Polynomial Kernel. The Polynomial Kernel of degree d can be rewritten as Kd ( X ; Y ) = dX r=0 cd ( r ) ¢jPr ( X \Y ) j ; ( 4 ) where † Pr ( X ) is a set of all subsets of X with exactly r elements in it , † cd ( r ) = Pdl=r¡dl¢ ‡Pr m=0 ( ¡1 ) r¡m ¢ml ¡r m ¢·. Proof See Appendix A. cd ( r ) will be referred as a subset weight of the Polynomial Kernel of degree d. This function gives a prior weight to the subset s , where jsj = r. Example 1 Quadratic and Cubic Kernel Given sets X = fa ; b ; c ; dg and Y = fa ; b ; d ; eg , the Quadratic Kernel K2 ( X ; Y ) and the Cubic Kernel K3 ( X ; Y ) can be calculated in an implicit form as : K2 ( X ; Y ) = ( 1+jX \Yj ) 2 = ( 1+3 ) 2 = 16 , K3 ( X ; Y ) = ( 1+jX \Yj ) 3 = ( 1+3 ) 3 = 64. Using Lemma 1 , the subset weights of the Quadratic Kernel and the Cubic Kernel can be calculated as c2 ( 0 ) = 1</definiens>
				<definiens id="7">calculated in an explicit form as : function PKI classify ( X ) r = 0 # an array , initialized as 0 foreach i2X foreach j 2h ( i ) rj = rj +1 endend result = 0foreach j 2 SV result = result+yjfij ¢ ( 1+rj ) d endreturn sgn ( result+b ) end Figure 1 : Pseudo code for PKI K2 ( X ; Y ) = 1¢1+3¢3+2¢3 = 16</definiens>
				<definiens id="8">algorithms for the Polynomial Kernel of degree d. Before describing them , we give the baseline classifier ( PKB ) : y ( X ) = sgn ‡ X j2SV yjfij ¢ ( 1+jXj \Xj</definiens>
				<definiens id="9">advance the set of support examples which contain item i 2 F , we do not need to calculate jXj \Xj for all support examples. This is a naive extension of Inverted Indexing in Information Retrieval. Figure 1 shows the pseudo code of the algorithm PKI. The function h ( i ) is a pre-compiled table and returns a set of support examples which contain item i. The complexity of the PKI is O ( jXj¢B +jSVj ) , where B is an average of jh ( i ) j over all item i 2 F. The PKI can make the classification speed drastically faster when B is small , in other words , when feature space is relatively sparse ( i.e. , B ¿ jSVj ) . The feature space is often sparse in many tasks in NLP , since lexical entries are used as features. The algorithm PKI does not change the final accuracy of the classification. Using Lemma 1 , we can represent the decision function ( 5 ) in an explicit form : y ( X ) = sgn ‡X j2SV yjfij¡ dX r=0 cd ( r ) ¢jPr ( Xj \X ) j¢+b · : ( 6 ) If we , in advance , calculate w ( s ) = X j2SV yjfijcd ( jsj ) I ( s 2 Pjsj ( Xj ) ) ( where I ( t ) is an indicator function 2 ) for all subsets s 2Sdr=0 Pr ( F ) , ( 6 ) can be written as the following simple linear form : y ( X ) = sgn ‡ X s2Γd ( X ) w ( s ) +b · : ( 7 ) where Γd ( X ) = Sdr=0 Pr ( X )</definiens>
				<definiens id="10">jΓd ( X ) j ) = O ( jXjd ) , independent on the number of support examples jSVj. To apply the PKE</definiens>
				<definiens id="11">the original feature space F into F £ F space , which is small enough to be calculated by a naive exhaustive method. However , if we , for instance , use a polynomial kernel of degree 3 or higher</definiens>
			</definition>
			<definition id="1">
				<sentence>The algorithm PKE is an approximation of the PKB , and changes the final accuracy according to the selection of thresholds pos and neg .</sentence>
				<definiendum id="0">PKE</definiendum>
				<definiens id="0">an approximation of the PKB , and changes the final accuracy according to the selection of thresholds pos and neg</definiens>
			</definition>
			<definition id="2">
				<sentence>Text Chunking is a fundamental task in NLP – dividing sentences into non-overlapping phrases .</sentence>
				<definiendum id="0">Text Chunking</definiendum>
				<definiens id="0">a fundamental task in NLP – dividing sentences into non-overlapping phrases</definiens>
			</definition>
			<definition id="3">
				<sentence>We combined SVMs into an efficient parsing algorithm , Cascaded Chunking Model , which parses a sentence deterministically only by deciding whether the current chunk modifies the chunk on its immediate right hand side .</sentence>
				<definiendum id="0">SVMs</definiendum>
				<definiendum id="1">Chunking Model</definiendum>
				<definiens id="0">parses a sentence deterministically only by deciding whether the current chunk modifies the chunk on its immediate right hand side</definiens>
			</definition>
			<definition id="4">
				<sentence>Isozaki et al. propose an XQK ( eXpand the Quadratic Kernel ) which can make their Named-Entity recognizer drastically fast ( Isozaki and Kazawa , 2002 ) .</sentence>
				<definiendum id="0">XQK ( eXpand</definiendum>
				<definiens id="0">the Quadratic Kernel ) which can make their Named-Entity recognizer drastically fast</definiens>
			</definition>
			<definition id="5">
				<sentence>PKE takes a basket mining approach to enumerating effective feature combinations more efficiently than their exhaustive method .</sentence>
				<definiendum id="0">PKE</definiendum>
				<definiens id="0">takes a basket mining approach to enumerating effective feature combinations more efficiently than their exhaustive method</definiens>
			</definition>
			<definition id="6">
				<sentence>Ratio ( £ 1000 ) PKI 0.020 8.3 93.84 PKB 0.164 1.0 93.84 Table 3 : Results of JWS PKE Time Speedup Acc .</sentence>
				<definiendum id="0">Ratio</definiendum>
				<definiens id="0">Results of JWS PKE Time Speedup Acc</definiens>
			</definition>
			<definition id="7">
				<sentence>Ratio ( £ 1000 ) PKI 0.4989 1.7 97.94 PKB 0.8535 1.0 97.94 Table 4 : Results of JDP PKE Time Speedup Acc .</sentence>
				<definiendum id="0">Ratio</definiendum>
			</definition>
			<definition id="8">
				<sentence>Ratio ( £ 1000 ) 1 0.0028 300.1 97.95 2,327 2 0.0025 337.3 97.83 954 3 0.0023 367.0 97.83 591 PKB 0.8535 1.0 97.94 Table 6 : Frequency-based pruning ( JDP ) PKE time Speedup Acc .</sentence>
				<definiendum id="0">Ratio</definiendum>
				<definiens id="0">Frequency-based pruning ( JDP ) PKE time Speedup Acc</definiens>
			</definition>
</paper>

		<paper id="1002">
			<definition id="0">
				<sentence>To process texts efficiently and fast , domain patterns are ideally implemented as finite state automata ( FSAs ) , a methodology pioneered in the FASTUS IE system ( Hobbs et al. , 1997 ) .</sentence>
				<definiendum id="0">FSAs</definiendum>
			</definition>
			<definition id="1">
				<sentence>Predicate-Argument Structures Proposition Bank or PropBank is a one million word corpus annotated with predicateargument structures .</sentence>
				<definiendum id="0">PropBank</definiendum>
				<definiens id="0">a one million word corpus annotated with predicateargument structures</definiens>
			</definition>
			<definition id="2">
				<sentence>Generally , Arg0 would stand for agent , Arg1 for direct object or theme whereas Arg2 represents indirect object , benefactive or instrument , but mnemonics tend to be verb specific .</sentence>
				<definiendum id="0">Arg1</definiendum>
				<definiens id="0">direct object or theme whereas Arg2 represents indirect object , benefactive or instrument , but mnemonics tend to be verb specific</definiens>
			</definition>
			<definition id="3">
				<sentence>In previous work using the PropBank corpus , ( Gildea and Palmer , 2002 ) proposed a model predicting argument roles using the same statistical method as the one employed by ( Gildea and Jurafsky , 2002 ) for predicting semantic roles based on the FrameNet corpus ( Baker et al. , 1998 ) .</sentence>
				<definiendum id="0">PropBank corpus</definiendum>
			</definition>
			<definition id="4">
				<sentence>− POSITION ( pos ) − Indicates if the constituent appears before or after the the predicate in the sentence .</sentence>
				<definiendum id="0">POSITION</definiendum>
				<definiens id="0">Indicates if the constituent appears before or after the the predicate in the sentence</definiens>
			</definition>
			<definition id="5">
				<sentence>Case and morphological information − HEAD WORD ( hw ) − This feature contains the head word − PARSE TREE PATH ( path ) : This feature contains the path in the parse tree between the predicate phrase and the argument phrase , expressed as a sequence of nonterminal labels linked by direction symbols ( up or down ) , e.g. − PHRASE TYPE ( pt ) : This feature indicates the syntactic NP for ARG1 in Figure 2 .</sentence>
				<definiendum id="0">morphological information − HEAD WORD</definiendum>
				<definiendum id="1">PARSE TREE PATH ( path )</definiendum>
				<definiendum id="2">PHRASE TYPE ( pt )</definiendum>
				<definiens id="0">This feature contains the path in the parse tree between the predicate phrase and the argument phrase , expressed as a sequence of nonterminal labels linked by direction symbols ( up or down )</definiens>
			</definition>
			<definition id="6">
				<sentence>− GOVERNING CATEGORY ( gov ) − This feature applies to − PREDICATE WORD − In our implementation this feature consists of two components : ( 1 ) VERB : the word itself with the case and morphological information preserved ; and ( 2 ) LEMMA which represents the verb normalized to lower case and infinitive form .</sentence>
				<definiendum id="0">− GOVERNING CATEGORY</definiendum>
				<definiens id="0">consists of two components : ( 1 ) VERB : the word itself with the case and morphological information preserved ; and ( 2 ) LEMMA which represents the verb normalized to lower case and infinitive form</definiens>
			</definition>
			<definition id="7">
				<sentence>PART OF SPEECH OF CONTENT WORD ( cPos ) −The part of speech tag of the content word .</sentence>
				<definiendum id="0">PART OF SPEECH OF CONTENT WORD</definiendum>
				<definiens id="0">−The part of speech tag of the content word</definiens>
			</definition>
			<definition id="8">
				<sentence>Our model considers two sets of features : Feature Set 1 ( FS1 ) : features used in the work reported in ( Gildea and Palmer , 2002 ) and ( Gildea and Jurafsky , 2002 ) ; and Feature Set 2 ( FS2 ) : a novel set of features introduced in this paper .</sentence>
				<definiendum id="0">FS1 )</definiendum>
				<definiens id="0">a novel set of features introduced in this paper</definiens>
			</definition>
			<definition id="9">
				<sentence>In FS2 we added the following features : ( a ) the named entity class of the content word ( cNE ) ; and ( b ) a set of NE features that can take only Boolean values grouped as BOOLEAN NAMED ENTITY FEATURES and defined in Figure 4 .</sentence>
				<definiendum id="0">cNE</definiendum>
				<definiendum id="1">BOOLEAN NAMED ENTITY FEATURES</definiendum>
				<definiens id="0">a ) the named entity class of the content word (</definiens>
			</definition>
			<definition id="10">
				<sentence>This is a clear ad5 1/4 ARG2 34 1/2to ARGM−DIR flewThe space shuttle Challenger apart over Florida like a billion−dollar confetti killing six astronauts NP VP S NP PP NP fellNorwalk−based Micro Warehouse ARG1 NP ADVP PP PP S VP VPNP S ARG0 P ARG1 INSTRUMENT AMOUNT_CHANGE CURRENT_VALUE AGENT_OF_DEATH MANNER_OF_DEATH DECEASED Mappings ( a ) ( b ) Figure 9 : Predicate argument mapping examples for : ( a ) the “market change” domain , and ( b ) the “death” domain vantage over the FSA-based system , which in fact missed the AGENT-OF-DEATH in this sentence .</sentence>
				<definiendum id="0">DECEASED Mappings</definiendum>
				<definiens id="0">NP VP S NP PP NP fellNorwalk−based Micro Warehouse ARG1 NP ADVP PP PP S VP VPNP S ARG0 P ARG1 INSTRUMENT AMOUNT_CHANGE CURRENT_VALUE AGENT_OF_DEATH MANNER_OF_DEATH</definiens>
			</definition>
			<definition id="11">
				<sentence>Specific to the FSA-based architecture are the phrasal parser , which identifies simple phrases such as basic noun or verb phrases ( some of them domain specific ) , the combiner , which builds domain-dependent complex phrases , and the event recognizer , which detects the domain-specific Subject-Verb-Object ( SVO ) patterns .</sentence>
				<definiendum id="0">combiner</definiendum>
				<definiens id="0">identifies simple phrases such as basic noun or verb phrases</definiens>
			</definition>
			<definition id="12">
				<sentence>This explains why in Figure 7 these modules are repreSystem Market Change Death Pred/Args Statistical 68.9 % 58.4 % Pred/Args Inductive 82.8 % 67.0 % FSA 91.3 % 72.7 % Table 3 : Templette F-measure ( a0 a1 ) scores for the two domains investigated System Correct Missed Incorrect Pred/Args Statistical 26 16 3 Pred/Args Inductive 33 9 2 FSA 38 4 2 Table 4 : Number of event structures ( FSA patterns or predicate argument structures ) matched sented with dashed lines .</sentence>
				<definiendum id="0">Templette F-measure</definiendum>
				<definiendum id="1">FSA</definiendum>
				<definiens id="0">patterns or predicate argument structures ) matched sented with dashed lines</definiens>
			</definition>
			<definition id="13">
				<sentence>Predicate Argument Structures in IE To evaluate the proposed IE paradigm we selected two Event99 domains : “market change” , which tracks changes in stock indexes , and “death” , which extracts all manners of human deaths .</sentence>
				<definiendum id="0">“market change”</definiendum>
				<definiens id="0">extracts all manners of human deaths</definiens>
			</definition>
</paper>

		<paper id="1045">
			<definition id="0">
				<sentence>Formally , let L ( G ) denote the language associated with grammar G , and let V be a given alphabet , a learning algorithm is a function from finite sets of words in V to G , such that for all G 2 G with L ( G ) = &lt; ei &gt; i2N there exists a grammar G0 2 G and there exists n0 2 N such that : 8n &gt; n0 ( fe1 ; : : : ; eng ) = G0 2 G with L ( G0 ) = L ( G ) .</sentence>
				<definiendum id="0">learning algorithm</definiendum>
				<definiens id="0">a function from finite sets of words in V to G , such that for all G 2 G with L ( G ) = &lt; ei &gt;</definiens>
			</definition>
			<definition id="1">
				<sentence>A. The relation ‘L is the smallest relation ‘ between Tp+ and Tp , such that for all ; 0 2 Tp+ ; ; 0 2 Tp and for all A ; B ; C 2 Tp : ; A ; 0 ‘ C ‘ A ( Cut ) ; ; 0 ‘ C A ‘ A ( Id ) ‘ A ; B ; 0 ‘ C =L ; B = A ; ; 0 ‘ C ; A ‘ B =R ‘ B = A ‘ A ; B ; 0 ‘ C nL ; ; A n B ; 0 ‘ C A ; ‘ B nR ‘ A n B ; A ; B ; 0 ‘ C L ; A B ; 0 ‘ C ‘ A 0 ‘ B R ; 0 ‘ A B We write L ; for the Lambek calculus with empty antecedents ( left part of the sequent ) .</sentence>
				<definiendum id="0">relation ‘L</definiendum>
				<definiens id="0">A ‘ B =R ‘ B = A ‘ A ; B ; 0 ‘ C nL ; ; A n B ; 0 ‘ C A ; ‘ B nR ‘ A n B ; A ; B ; 0 ‘ C L ; A B ; 0 ‘ C ‘ A 0 ‘ B R ; 0 ‘ A B We write L ; for the Lambek calculus with empty antecedents ( left part of the sequent )</definiens>
			</definition>
			<definition id="2">
				<sentence>The relation ‘NL is the smallest relation ‘ between S and Tp , such that for all ; 2 S and for all A ; B ; C 2 Tp : [ A ] ‘ C ‘ A ( Cut ) [ ] ‘ C A ‘ A ( Id ) ‘ A [ B ] ‘ C =L [ ( B = A ; ) ] ‘ C ( ; A ) ‘ B =R ‘ B = A ‘ A [ B ] ‘ C nL [ ( ; A n B ) ] ‘ C ( A ; ) ‘ B nR ‘ A n B [ ( A ; B ) ] ‘ C L [ A B ] ‘ C ‘ A ‘ B R ( ; ) ‘ ( A B ) We write NL ; for the non-associative Lambek calculus with empty antecedents ( left part of the sequent ) .</sentence>
				<definiendum id="0">relation ‘NL</definiendum>
				<definiens id="0">‘ C A ‘ A ( Id ) ‘ A [ B ] ‘ C =L [ ( B = A ; ) ] ‘ C ( ; A ) ‘ B =R ‘ B = A ‘ A [ B ] ‘ C nL [ ( ; A n B ) ] ‘ C ( A ; ) ‘ B nR ‘ A n B [ ( A ; B ) ] ‘ C L [ A B ] ‘ C ‘ A ‘ B R ( ; ) ‘ ( A B ) We write NL ; for the non-associative Lambek calculus with empty antecedents ( left part of the sequent )</definiens>
			</definition>
			<definition id="3">
				<sentence>The order ord ( A ) of a type A of L or NL is defined by : ord ( A ) = 0 if A is a primitive type ord ( C1 = C2 ) = max ( ord ( C1 ) ; ord ( C2 ) + 1 ) ord ( C1 n C2 ) = max ( ord ( C1 ) + 1 ; ord ( C2 ) ) ord ( C1 C2 ) = max ( ord ( C1 ) ; ord ( C2 ) ) Let G be a categorial grammar over .</sentence>
				<definiendum id="0">order ord</definiendum>
				<definiendum id="1">NL</definiendum>
				<definiens id="0">a primitive type ord ( C1 = C2 ) = max ( ord ( C1 ) ; ord ( C2 ) + 1 ) ord ( C1 n C2 ) = max ( ord ( C1 ) + 1 ; ord ( C2 ) ) ord ( C1 C2 ) = max ( ord ( C1 ) ; ord ( C2 ) ) Let G be a categorial grammar over</definiens>
			</definition>
			<definition id="4">
				<sentence>Ai ( 1 i n ) and A1 ; : : : ; An ‘L S : The language of G , written LL ( G ) is the set of strings generated by G. We define similarly LL ; ( G ) , LNL ( G ) and LNL ; ( G ) replacing ‘L by ‘L ; , ‘NL and ‘NL ; in the sequent where the types are parenthesized in some way .</sentence>
				<definiendum id="0">‘L S</definiendum>
				<definiens id="0">The language of G , written LL ( G ) is the set of strings generated by G. We define similarly LL ; ( G ) , LNL ( G ) and LNL</definiens>
			</definition>
			<definition id="5">
				<sentence>A class CL of languages has a limit point iff there exists an infinite sequence &lt; Ln &gt; n2N of languages in CL and a language L 2 CL such that : L0 ( L1 : : : ( : : : ( Ln ( : : : and L = Sn2N Ln ( L is a limit point of CL ) .</sentence>
				<definiendum id="0">class CL</definiendum>
				<definiendum id="1">L</definiendum>
				<definiens id="0">a limit point of CL</definiens>
			</definition>
			<definition id="6">
				<sentence>A pregroup is a structure ( P ; ; ; l ; r ; 1 ) such that ( P ; ; ; 1 ) is a partially ordered monoid2 and l ; r are two unary operations on P that satisfy for all a 2 P ala 1 aal and aar 1 ara .</sentence>
				<definiendum id="0">pregroup</definiendum>
				<definiens id="0">a partially ordered monoid2 and l</definiens>
			</definition>
			<definition id="7">
				<sentence>Let ( P ; ) be an ordered set of primitive types , P ( a0 ) = fp ( i ) j p 2 P ; i 2 Zg is the set of atomic types and T ( P ; ) = P ( a0 ) = fp ( i1 ) 1 p ( in ) n j 0 k n ; pk 2 P and ik 2 Zg is the set of types .</sentence>
				<definiendum id="0">P</definiendum>
				<definiendum id="1">Zg</definiendum>
				<definiendum id="2">Zg</definiendum>
				<definiens id="0">the set of atomic types and T ( P ; ) = P ( a0 ) = fp ( i1 ) 1 p ( in ) n j 0 k n</definiens>
				<definiens id="1">the set of types</definiens>
			</definition>
			<definition id="8">
				<sentence>A partially ordered monoid is a monoid M ; ; 1 ) with a partial order that satisfies 8a ; b ; c : a b ) c a c b and a c b c. X X ( Id ) X Y Y Z ( Cut ) X Z XY Z ( AL ) Xp ( n ) p ( n+1 ) Y Z X Y Z ( AR ) X Y p ( n+1 ) p ( n ) Z Xp ( k ) Y Z ( INDL ) Xq ( k ) Y Z X Y p ( k ) Z ( INDR ) X Y q ( k ) Z q p if k is even , and p q if k is odd This construction , proposed by Buskowski , defines a pregroup that extends on primitive types P to T ( P ; ) 3 .</sentence>
				<definiendum id="0">partially ordered monoid</definiendum>
				<definiens id="0">a monoid M ; ; 1 ) with a partial order that satisfies 8a ; b ; c : a b ) c a c b</definiens>
				<definiens id="1">defines a pregroup that extends on primitive types P to T ( P ; ) 3</definiens>
			</definition>
			<definition id="9">
				<sentence>Let FP denotes the simple free pregroup with Pr as primitive types .</sentence>
				<definiendum id="0">FP</definiendum>
				<definiens id="0">the simple free pregroup with Pr as primitive types</definiens>
			</definition>
			<definition id="10">
				<sentence>Proposition 2 ( NL-non-learnability ) The class of languages of rigid ( or k-valued for an arbitrary k ) non-associative Lambek grammars ( not allowing empty sequence and without product ) admits a limit point ; the class of rigid ( or k-valued for an arbitrary k ) non-associative Lambek grammars ( not allowing empty sequence and without product ) is not learnable from strings .</sentence>
				<definiendum id="0">Proposition 2 ( NL-non-learnability</definiendum>
				<definiens id="0">an arbitrary k ) non-associative Lambek grammars ( not allowing empty sequence and without product ) admits a limit point</definiens>
			</definition>
</paper>

	</volume>
