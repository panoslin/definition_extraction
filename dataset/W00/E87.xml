<?xml version="1.0" encoding="UTF-8"?>
	<volume id="E87">

		<paper id="1047">
			<definition id="0">
				<sentence>Unarity is opposed to traditional binary feature systems ( with a marked '+ ' and an unmarked '- ' value for each feature ) and to ternary systems ( with a marked '+ ' , an unmarked '- ' , and an unspecified '0 ' value ) , while feature geometries ( and hierarchies ) replace the old-fashioned 'feature bundle ' conception , in which each segment consisted of an unordered set of feature-value pairs .</sentence>
				<definiendum id="0">Unarity</definiendum>
				<definiendum id="1">to ternary systems</definiendum>
			</definition>
			<definition id="1">
				<sentence>CONNECTIONIST MODEL OF FEATURE SYSTEMS Obviously , the presence of a feature in a segment corresponds to a relatively high activation level of a node or a coalition of nodes in a connectionist network .</sentence>
				<definiendum id="0">CONNECTIONIST MODEL OF FEATURE SYSTEMS Obviously</definiendum>
				<definiens id="0">the presence of a feature in a segment corresponds to a relatively high activation level of a node or a coalition of nodes in a connectionist network</definiens>
			</definition>
</paper>

		<paper id="1045">
			<definition id="0">
				<sentence>SABA ( `` Semantic Analyser , Backward Approach '' , ( Binot , 1985 ) , ( Blnot et al. , 1986 ) ) is a robust and portable semantic parser of written French sentences .</sentence>
				<definiendum id="0">SABA</definiendum>
				<definiens id="0">a robust and portable semantic parser of written French sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>Before generating the SF output , SABA builds a simplified semantic graph expressing all the semantic dependencies established between the meaningful terms of the sentence .</sentence>
				<definiendum id="0">SABA</definiendum>
				<definiens id="0">builds a simplified semantic graph expressing all the semantic dependencies established between the meaningful terms of the sentence</definiens>
			</definition>
			<definition id="2">
				<sentence>Dual frames is a general method for establishing binary semantic dependencies between all possible types of meaningfull terms .</sentence>
				<definiendum id="0">Dual frames</definiendum>
				<definiens id="0">a general method for establishing binary semantic dependencies between all possible types of meaningfull terms</definiens>
			</definition>
			<definition id="3">
				<sentence>Even in straightforward active declarative sentences , two distinct mechanisms must be provided to establish semantic dependencies in Wilks system : template matching , which identifies ~agent-actionobject '' triples , and paraplates , which are used to tie these templates together .</sentence>
				<definiendum id="0">template matching</definiendum>
				<definiendum id="1">paraplates</definiendum>
				<definiens id="0">identifies ~agent-actionobject '' triples</definiens>
			</definition>
			<definition id="4">
				<sentence>Tile likeliness of a combination is simply defined as the product of the certainty factors of the parts of speech included in that combination .</sentence>
				<definiendum id="0">Tile likeliness of a combination</definiendum>
				<definiens id="0">the product of the certainty factors of the parts of speech included in that combination</definiens>
			</definition>
			<definition id="5">
				<sentence>tlOMOGRAPH checks ff a word has more than one possible parts of speech .</sentence>
				<definiendum id="0">tlOMOGRAPH checks</definiendum>
				<definiens id="0">ff a word has more than one possible parts of speech</definiens>
			</definition>
</paper>

		<paper id="1031">
			<definition id="0">
				<sentence>The ask-infogame is a communicative game which asks a question about the total-amount object : system -'What is the total amount of your plan of investment ? ''</sentence>
				<definiendum id="0">ask-infogame</definiendum>
				<definiens id="0">a communicative game which asks a question about the total-amount object</definiens>
			</definition>
			<definition id="1">
				<sentence>The GENERATOR takes this information to adapt its description and link unknown concepts to familiar ones .</sentence>
				<definiendum id="0">GENERATOR</definiendum>
				<definiens id="0">takes this information to adapt its description and link unknown concepts to familiar ones</definiens>
			</definition>
			<definition id="2">
				<sentence>A simple example consists of transformation rules for yes-ok/no answers depending on the game .</sentence>
				<definiendum id="0">simple example</definiendum>
				<definiens id="0">consists of transformation rules for yes-ok/no answers depending on the game</definiens>
			</definition>
</paper>

		<paper id="1048">
			<definition id="0">
				<sentence>Sememes ( of vero-lexemes ) are represented by expressions containing primitive semantic predicates .</sentence>
				<definiendum id="0">Sememes</definiendum>
				<definiens id="0">represented by expressions containing primitive semantic predicates</definiens>
			</definition>
			<definition id="1">
				<sentence>, s ( ... , x , ... ) , ... ) where x is the j-th argument in Q , S ( ... ) the k-th argument in R and x the 1-th argument in S. Then zg ( Q ) is a function of R , Zk ( R ) , S an~ Zl ( S ) .</sentence>
				<definiendum id="0">x</definiendum>
				<definiens id="0">a function of R , Zk ( R ) , S an~ Zl ( S )</definiens>
			</definition>
			<definition id="2">
				<sentence>Thiel 's proposal , namely zj ( Q ) = m ( R , Zl ( S ) ) , would cause some dlfficulties , if R is a many place predicate and there are in R arguments S ' and S '' with z I , ( S ' ) =Zl , , ( S '' ) ( cf. the FEED-example below ) .</sentence>
				<definiendum id="0">R</definiendum>
				<definiens id="0">a many place predicate and there are in R arguments S ' and S '' with z I</definiens>
			</definition>
</paper>

		<paper id="1050">
			<definition id="0">
				<sentence>A bundle is a substructure of a dependency tree which contains exactly one top node and all nodes directly subordinated to it together with the edges between ( and their markings the subordination relations ) .</sentence>
				<definiendum id="0">bundle</definiendum>
			</definition>
</paper>

		<paper id="1030">
			<definition id="0">
				<sentence>The term 'deixis ' denotes those referential devices whose interpretation requires a consideration of the situation of utterance .</sentence>
				<definiendum id="0">term 'deixis '</definiendum>
				<definiens id="0">those referential devices whose interpretation requires a consideration of the situation of utterance</definiens>
			</definition>
</paper>

		<paper id="1046">
			<definition id="0">
				<sentence>A major node is a node which has unlike input symbols on non-epicyclic input and output transitions and can also be a final node .</sentence>
				<definiendum id="0">major node</definiendum>
				<definiens id="0">a node which has unlike input symbols on non-epicyclic input</definiens>
			</definition>
			<definition id="1">
				<sentence>Terrace-internal monotone sequences are defined as epicycles ; in Baule , epicyclic sequences start not on the second but on the third item of the sequence , and a non-epicyclic sub-system is required .</sentence>
				<definiendum id="0">Terrace-internal monotone sequences</definiendum>
				<definiens id="0">epicycles ; in Baule , epicyclic sequences start not on the second but on the third item of the sequence</definiens>
			</definition>
</paper>

		<paper id="1011">
			<definition id="0">
				<sentence>LDOCE carries special lexicai and linguistic information which is useful for a number of natural language processing tasks .</sentence>
				<definiendum id="0">LDOCE</definiendum>
				<definiens id="0">carries special lexicai and linguistic information</definiens>
			</definition>
			<definition id="1">
				<sentence>Accurate root extraction for words not so marked can therefore be accomplished simply by stripping off affixes ( which are themselves in the basic word list ) and applying a few simple rules for spelling changes until a basic word is found .</sentence>
				<definiendum id="0">Accurate root extraction</definiendum>
				<definiens id="0">accomplished simply by stripping off affixes ( which are themselves in the basic word list</definiens>
			</definition>
			<definition id="2">
				<sentence>Therefore if lookup keys are used , returning pointer lists of lengths LI , L= , ... L , , then the expected number of entries to be read , assuming statistical independence between lists , is LIL2 ... L , /D '' -l , where D is the number of entries in the dictionary .</sentence>
				<definiendum id="0">D</definiendum>
			</definition>
			<definition id="3">
				<sentence>Thesis , Universit6 de Liege , Belgium Miller , G. ( 1985 ) WORDNET : a dictionary browser , In Proceedings of the First International Conference on Information in Data , University of Waterloo centre for the New OED , Waterloo , Ontario Russell , G.J. et a1 .</sentence>
				<definiendum id="0">WORDNET</definiendum>
				<definiens id="0">a dictionary browser</definiens>
			</definition>
			<definition id="4">
				<sentence>( 1986 ) 'A dictionary and morphological analyser for English ' , Proceedings of the 11th International Congress on Computational Linguistics , Bonn , pp.277-279 Selkirk , E.O. ( 1978 ) On prosodic structure and its relation to syntactic structure , Indiana University Linguistics Club , Bloomington , Indiana Tompa , F. ( 1986 ) Database design for a dictionary of the future , Preliminary report , Centre for the New Oxford English Dictionary , University of Waterloo , Waterloo , Ontario XSIS 038112 ( 1981 ) Courier : the Remote Procedure Call protocol , Xerox Systems Integration Standard , Xerox Corporation , Stamford , Connecticut 69</sentence>
				<definiendum id="0">Courier</definiendum>
				<definiens id="0">the Remote Procedure Call protocol</definiens>
			</definition>
</paper>

		<paper id="1016">
			<definition id="0">
				<sentence>ABSTRACT In some computer applications of linguistics ( such as maximum-likelihood decoding of speech or handwriting ) , the purpose of the language-handling component ( Language Model ) is to estimate the linguistic ( a priori ) probability of arbitrary natural-language sentences .</sentence>
				<definiendum id="0">language-handling component ( Language Model</definiendum>
				<definiens id="0">to estimate the linguistic ( a priori ) probability of arbitrary natural-language sentences</definiens>
			</definition>
			<definition id="1">
				<sentence>If the sentence is to be recognized while it is being produced ( as necessary for a real-time application ) , the computation of its probability should proceed `` left-to-right , '' i.e. word by word from the beginning towards the end of the sentence , allowing application of fast tree-search algorithms such as stack decoding\ [ 5\ ] Left-to-right computation of the probability of any word string is made possible by a formal manipulation based on the definition of condit__ional probability : if W i is the i-th word in the sequence 14 ' of length N , then : N e ( W ) = 1 -- IP ( EI w , t , ~_~ ... .. ~'t ) i=1 In other terms , the probability of a sequence of words is the product of the conditional probability of each word , given all of the previous ones .</sentence>
				<definiendum id="0">IP</definiendum>
			</definition>
			<definition id="2">
				<sentence>We shall apply this equation only to subsequences occurring at the start of sentences ( i.e. `` incomplete '' sentences ) ; thus , the unconditional probability P ( WI ) can meaningfully be read as the probability that the particular word WI , rather than any other word , will be the one starting a sentence .</sentence>
				<definiendum id="0">unconditional probability P ( WI</definiendum>
				<definiens id="0">subsequences occurring at the start of sentences ( i.e. `` incomplete '' sentences</definiens>
			</definition>
</paper>

		<paper id="1024">
			<definition id="0">
				<sentence>In any case , the language of an NLI is a language designed ( and is in that respect not a natural language ) so there are many questions to be answered about how it should be designed , both in terms of how it should function as a vehicle of communication and in terms of internal representations and procedures .</sentence>
				<definiendum id="0">NLI</definiendum>
				<definiens id="0">a language designed ( and is in that respect not a natural language ) so there are many questions to be answered about how it should be designed</definiens>
			</definition>
</paper>

		<paper id="1037">
			<definition id="0">
				<sentence>Strategy 16 ( TD ) Whenever an active edge is added to the chart , if its first required constituent is C , then add an empty active C edge for every rule in G which expands C. 7 This principle will apply to itself recursively , ensuring that all subsidiary active edges also get produced .</sentence>
				<definiendum id="0">TD</definiendum>
				<definiens id="0">C , then add an empty active C edge for every rule in G which expands C. 7 This principle will apply to itself recursively , ensuring that all subsidiary active edges also get produced</definiens>
			</definition>
			<definition id="1">
				<sentence>Left-corner parsing is a bottom-up technique where the right-hand-side symbols of the rules are matched from left to right , s Once the left-corner symbol has been found , the grammar rule can be used to predict what may come next .</sentence>
				<definiendum id="0">Left-corner parsing</definiendum>
				<definiens id="0">a bottom-up technique where the right-hand-side symbols of the rules are matched from left to right , s Once the left-corner symbol has been found</definiens>
			</definition>
			<definition id="2">
				<sentence>Strategy 4 ( LCK ) Whenever an inactive edge is added to the chart , if its category is T , then for every rule in G with T as left-corner symbol add an edge that subsumes the T edge .</sentence>
				<definiendum id="0">LCK</definiendum>
				<definiens id="0">T , then for every rule in G with T as left-corner symbol add an edge that subsumes the T edge</definiens>
			</definition>
			<definition id="3">
				<sentence>Strategy 7 ( LCK , ) Let pl , ... , p , , be the categories of the word corresponding to the preterminal edges extending from the vertex to which the T edge is incident .</sentence>
				<definiendum id="0">LCK</definiendum>
				<definiens id="0">Let pl , ... , p , , be the categories of the word corresponding to the preterminal edges extending from the vertex to which the T edge is incident</definiens>
			</definition>
			<definition id="4">
				<sentence>The fifth column gives the accumulated CPU time in seconds .</sentence>
				<definiendum id="0">fifth column</definiendum>
				<definiens id="0">gives the accumulated CPU time in seconds</definiens>
			</definition>
</paper>

		<paper id="1032">
			<definition id="0">
				<sentence>Extemper : A Computational Model Extemper implements a four component , minimal cognitive architecture for elaboration to produce descriptions of the behavior of problem solving systems .</sentence>
				<definiendum id="0">Extemper</definiendum>
				<definiens id="0">A Computational Model Extemper implements a four component , minimal cognitive architecture for elaboration to produce descriptions of the behavior of problem solving systems</definiens>
			</definition>
			<definition id="1">
				<sentence>The concept selection cycle builds a single ERKS meaning structure until meaning structure ( ms ) functions determine that a newly selected concept does not fit with the current one .</sentence>
				<definiendum id="0">concept selection cycle</definiendum>
				<definiens id="0">builds a single ERKS meaning structure until meaning structure ( ms ) functions determine that a newly selected concept does not fit with the current one</definiens>
			</definition>
			<definition id="2">
				<sentence>The sentence generator operates by repeatedly looking up words to span conceptual forms and ordering the words and those concepts that were not spanned according to predicates stored with the words .</sentence>
				<definiendum id="0">sentence generator</definiendum>
			</definition>
			<definition id="3">
				<sentence>Extemper follows the principle that if a natural ordering exists for a body of knowledge , it should be used to guide extemporaneous elaboration .</sentence>
				<definiendum id="0">Extemper</definiendum>
				<definiens id="0">follows the principle that if a natural ordering exists for a body of knowledge</definiens>
			</definition>
			<definition id="4">
				<sentence>Selection Relevance is an important constraint on discourse production .</sentence>
				<definiendum id="0">Selection Relevance</definiendum>
			</definition>
			<definition id="5">
				<sentence>The operation of the selectors is based on the ERKS method for representing meaning , namely that meaning representations consist of a kernel ( main or core concept ) and nuances ( ancillary concepts that distinguish similar meaning structures ) .</sentence>
				<definiendum id="0">operation of the selectors</definiendum>
				<definiens id="0">based on the ERKS method for representing meaning , namely that meaning representations consist of a kernel ( main or core concept ) and nuances ( ancillary concepts that distinguish similar meaning structures</definiens>
			</definition>
			<definition id="6">
				<sentence>Extemper , like discourse planners , integrates the general knowledge an intelligent system has with its language behavior .</sentence>
				<definiendum id="0">Extemper</definiendum>
				<definiens id="0">integrates the general knowledge an intelligent system has with its language behavior</definiens>
			</definition>
			<definition id="7">
				<sentence>Extemper represents a minimal architecture for extemporaneous elaboration as purposive discourse .</sentence>
				<definiendum id="0">Extemper</definiendum>
				<definiens id="0">a minimal architecture for extemporaneous elaboration as purposive discourse</definiens>
			</definition>
</paper>

		<paper id="1001">
</paper>

		<paper id="1012">
			<definition id="0">
				<sentence>The knowledge level is an object-oriented environment , representing linguistic and lexicographic knowledge in a number of objects with attached information and procedures , organised in generalisation hierarchies .</sentence>
				<definiendum id="0">knowledge level</definiendum>
				<definiens id="0">an object-oriented environment , representing linguistic and lexicographic knowledge in a number of objects with attached information and procedures , organised in generalisation hierarchies</definiens>
			</definition>
			<definition id="1">
				<sentence>Few constructors can be developed which arc complete , i.e. which can operate fully automatically without checking of the output by the user .</sentence>
				<definiendum id="0">Few constructors</definiendum>
				<definiens id="0">can operate fully automatically without checking of the output by the user</definiens>
			</definition>
			<definition id="2">
				<sentence>Themfore , a central part in our system is a cooperative user interface , whose task it is to reduce initiative from the user to a minimum .</sentence>
				<definiendum id="0">Themfore</definiendum>
				<definiens id="0">a cooperative user interface , whose task it is to reduce initiative from the user to a minimum</definiens>
			</definition>
			<definition id="3">
				<sentence>Our word formation component consists of a number of morphological rules for afftxmion and compounding .</sentence>
				<definiendum id="0">word formation component</definiendum>
				<definiens id="0">consists of a number of morphological rules for afftxmion and compounding</definiens>
			</definition>
			<definition id="4">
				<sentence>Lcxicographic knowledge consists of a number of sorting routines and storage strategies .</sentence>
				<definiendum id="0">Lcxicographic knowledge</definiendum>
				<definiens id="0">consists of a number of sorting routines and storage strategies</definiens>
			</definition>
			<definition id="5">
				<sentence>Information about which and how many forms were objected to is returned to the diagnosis procedure associated with the object responsible for computing the regular paradigm , which analyses this information and transfers control to an object computing forms of verbs belonging to a particular category of irregular verbs .</sentence>
				<definiendum id="0">regular paradigm</definiendum>
			</definition>
			<definition id="6">
				<sentence>The result of applying this constructor to the MD is the extension of each entry in it with an additional field ( or slot at the knowledge level ) for the transcription .</sentence>
				<definiendum id="0">MD</definiendum>
				<definiens id="0">the extension of each entry in it with an additional field</definiens>
			</definition>
			<definition id="7">
				<sentence>Next , a filter object is defined working in three steps : ( i ) Take the broad phonetic transcription of each dictionary entry and reverse it ( reverse is a primitive procedure available to the lexicographer ) .</sentence>
				<definiendum id="0">reverse</definiendum>
				<definiens id="0">a primitive procedure available to the lexicographer )</definiens>
			</definition>
			<definition id="8">
				<sentence>The rhyme determining part consists of the nucleus and coda of the last stressed syllable and the following weak syllables if any .</sentence>
				<definiendum id="0">rhyme determining part</definiendum>
				<definiens id="0">consists of the nucleus and coda of the last stressed syllable and the</definiens>
			</definition>
			<definition id="9">
				<sentence>Although two words rhyme even when their rhythm ( defined as the succession of stressed and unstressed syllables ) is different , it is common poetic practice to look for rhyme words with the same metre .</sentence>
				<definiendum id="0">rhythm</definiendum>
				<definiens id="0">the succession of stressed and unstressed syllables ) is different , it is common poetic practice to look for rhyme words with the same metre</definiens>
			</definition>
			<definition id="10">
				<sentence>ACKNO~ This work was financially suppoRed by the EC ( ESPRIT project 82 ) .</sentence>
				<definiendum id="0">EC</definiendum>
			</definition>
</paper>

		<paper id="1041">
			<definition id="0">
				<sentence>The COND feature is a set ( notice the set brackets ) of constraints on IND2 .</sentence>
				<definiendum id="0">COND feature</definiendum>
				<definiens id="0">a set ( notice the set brackets ) of constraints on IND2</definiens>
			</definition>
			<definition id="1">
				<sentence>L ( X~ , i.e. g : lo ) -td g ( IND2 ) &lt; g ( l O ) and an extension fof g that anchors IND1 , IND4 and IND5 such thatf ( IND1 ) is the unique individual such that/n s : c ( book ) , fllND1 ) ; 1 andfllND4 ) is the unique individual such that/n s : c ( table ) , fllND4 ) ; 1 such that in s : c ( on ) , / ( IND5 ) j ?</sentence>
				<definiendum id="0">L</definiendum>
				<definiens id="0">the unique individual such that/n s : c ( table )</definiens>
			</definition>
			<definition id="2">
				<sentence>IND4 ) ; 1 in s : at g ( IND2 ) : c ( lie ) , f ( IND1 ) , f ( INDS ) ; I \ [ 5\ ] S.M. Shieber ( 1986 ) , An Introduction to Unification-Based Approaches to Grammar , CSLI Lecture Notes No.4 , Stanford .</sentence>
				<definiendum id="0">IND1</definiendum>
				<definiens id="0">at g ( IND2 ) : c ( lie ) , f (</definiens>
			</definition>
</paper>

		<paper id="1033">
			<definition id="0">
				<sentence>A 'reduction set ' is defined as the set of nodes N1 , N2 ... .. Nn which are roots of adjacent subtrees and correspond , in the same order , to the &lt; RIGHT-PATTERN &gt; of the examined production .</sentence>
				<definiendum id="0">'reduction set</definiendum>
				<definiens id="0">the set of nodes N1 , N2 ... .. Nn which are roots of adjacent subtrees and correspond , in the same order</definiens>
			</definition>
			<definition id="1">
				<sentence>trueps is an MRS function that checks the knowledge base for the presence or not of a predicate .</sentence>
				<definiendum id="0">trueps</definiendum>
				<definiens id="0">an MRS function that checks the knowledge base for the presence or not of a predicate</definiens>
			</definition>
</paper>

		<paper id="1025">
			<definition id="0">
				<sentence>Thls solution works for anaphoric linRs from inside a sentence ( such as 6 ) as well as for those from outside ( e.g. 2 ) .</sentence>
				<definiendum id="0">Thls solution</definiendum>
				<definiens id="0">works for anaphoric linRs from inside a sentence</definiens>
			</definition>
			<definition id="1">
				<sentence>A consTant stands for a real object in the world , and a variable will stand for one at evaluation time ; This object is the denotation of the pronoun .</sentence>
				<definiendum id="0">consTant</definiendum>
				<definiens id="0">a real object in the world</definiens>
			</definition>
			<definition id="2">
				<sentence>`` V '' is % he discourse variable created for each newly introduced discourse referent , which will Eet bound To the extension as soon as the entire sentence is Translated into HCL .</sentence>
				<definiendum id="0">V</definiendum>
				<definiens id="0">variable created for each newly introduced discourse referent</definiens>
			</definition>
			<definition id="3">
				<sentence>Hence we will have to make sure that a denotatlonal pronoun accepts only representations of individuals ( of the form `` c ( X ) '' ) in the precedlnE sentence ( s ) , and that a failure to find them must result in the entire discourse becomlnE unacceptable .</sentence>
				<definiendum id="0">c ( X</definiendum>
			</definition>
			<definition id="4">
				<sentence>Thus the `` he '' and `` it '' in the second sentence of example 23 will try to find ~epresentations of individuals in the first sentence , but there are only representations of `` stereotypes '' , i.e. meta-level names for object level variables ( of the form `` v ( X ) '' ) .</sentence>
				<definiendum id="0">i.e. meta-level</definiendum>
				<definiens id="0">names for object level variables ( of the form `` v ( X ) '' )</definiens>
			</definition>
</paper>

		<paper id="1034">
			<definition id="0">
				<sentence>I. Phrase-structure discontinuity grammar and Context-free phrase-structure grammars ( PSGs ) have always been popular in computational linguistics and in the theory of programming languages because of their technical and conceptual simplicity and their well-established efficient parsability ( Shell , 1976 ; Tomita , 1985 ) .</sentence>
				<definiendum id="0">Context-free phrase-structure grammars ( PSGs</definiendum>
				<definiens id="0">popular in computational linguistics and in the theory of programming languages because of their technical and conceptual simplicity and their well-established efficient parsability</definiens>
			</definition>
			<definition id="1">
				<sentence>Generalized Phrase-Structure Grammar ( GPSG ; Gazdar et al. , 1985 ) , represents a recent attempt to provide a theoretically acceptable account of natural-language syntax in the form of a phrase-structure grammar .</sentence>
				<definiendum id="0">Generalized Phrase-Structure Grammar</definiendum>
				<definiens id="0">a recent attempt to provide a theoretically acceptable account of natural-language syntax in the form of a phrase-structure grammar</definiens>
			</definition>
			<definition id="2">
				<sentence>Phrase-structure grammar has one more attractive side , apart from its technical/conceptual simplicity and its computational efficiency , namely that it seems to fit the semantic requirement of compositionality very well .</sentence>
				<definiendum id="0">Phrase-structure grammar</definiendum>
				<definiens id="0">has one more attractive side , apart from its technical/conceptual simplicity and its computational efficiency</definiens>
			</definition>
			<definition id="3">
				<sentence>The compositionality principle is the thesis that the meaning of a natural-language expression is determined by the combination of ( a ) the meanings of its parts ; ( b ) its syntactic structure .</sentence>
				<definiendum id="0">compositionality principle</definiendum>
				<definiens id="0">the thesis that the meaning of a natural-language expression is determined by the combination of ( a ) the meanings of its parts ; ( b ) its syntactic structure</definiens>
			</definition>
			<definition id="4">
				<sentence>However , PSG has one property that limits its applicability in describing constituent structure in natural language , namely that phrase-structure rules assume the constituents of an expression to correspond to adjacent substrings .</sentence>
				<definiendum id="0">PSG</definiendum>
				<definiens id="0">an expression to correspond to adjacent substrings</definiens>
			</definition>
			<definition id="5">
				<sentence>The `` + '' symbol represents the notion of adjacency , defined as before but now on the basis of te revised precedence relation `` &lt; `` : 206 ( 24 ) Two nodes x and y in a tree are adjacent if and only if x &lt; y and there is no node z in the tree such that x &lt; z &lt; y. Upon closer inspection , the neighbour relation defined in this way is unsatisfactory , however , as the following example illustrates .</sentence>
				<definiendum id="0">+ '' symbol</definiendum>
			</definition>
			<definition id="6">
				<sentence>The definition goes as follows : ( 28 ) A sequence ( a , b , ... , n ) is an ( n-place ) adjacency sequence if and only if : ( i ) every pair ( i , j ) in the sequence is either an adjacency pair or is connected by a sequence of adjacency pairs of which all members are a constituent of some element in the subsequence ( a , b , ... , i ) ; ( ii ) the elements in the sequenc~ do not share any constituents .</sentence>
				<definiendum id="0">... , n )</definiendum>
				<definiens id="0">either an adjacency pair or is connected by a sequence of adjacency pairs of which all members are a constituent of some element in the subsequence ( a , b , ...</definiens>
			</definition>
			<definition id="7">
				<sentence>For example , in the structure ( 25 ) the triple ( P , Q , E ) is an adjacency sequence since ( P , Q ) is an adjacency pair and Q and E are connected by the sequence of adjacency pairs Q-C-D-E , with C and D constituents of P and Q , respectively .</sentence>
				<definiendum id="0">E )</definiendum>
				<definiens id="0">an adjacency pair</definiens>
			</definition>
			<definition id="8">
				<sentence>The constituents B and E are separated in ( 37 ) by the sequence ( \ [ C\ ] , D ) , where C is marked as internal context ; therefore , C is not dominated by either X or B , and hence the test correctly fails .</sentence>
				<definiendum id="0">C</definiendum>
				<definiens id="0">not dominated by either X or B , and hence the test correctly fails</definiens>
			</definition>
</paper>

		<paper id="1049">
			<definition id="0">
				<sentence>NP\ [ passive + : -- -* e : AP _~ x ( P x ) A passive NP is an empty NP , but a different type of empty NP from unbounded dependency gaps .</sentence>
				<definiendum id="0">P x</definiendum>
				<definiendum id="1">passive NP</definiendum>
				<definiens id="0">an empty NP , but a different type of empty NP from unbounded dependency gaps</definiens>
			</definition>
			<definition id="1">
				<sentence>For transitive verbs passive amounts to AVexy ( V e y x ) Intuitively , tenses are predicates on events , and passive is an operator that has the effect of switching round the first two ( non-event ) arguments of the verb it applies to .</sentence>
				<definiendum id="0">passive</definiendum>
				<definiens id="0">V e y x</definiens>
			</definition>
			<definition id="2">
				<sentence>kexyz ( give e x y z ) Associated with the rule that generates the ditransitive form will be a 'dative ' operator , defined thus : 67 .</sentence>
				<definiendum id="0">kexyz</definiendum>
				<definiens id="0">give e x y z ) Associated with the rule that generates the ditransitive form will be a 'dative ' operator</definiens>
			</definition>
			<definition id="3">
				<sentence>The final wrinkle concerns the appearance of intransitive verbs in passives .</sentence>
				<definiendum id="0">final wrinkle</definiendum>
				<definiens id="0">concerns the appearance of intransitive verbs in passives</definiens>
			</definition>
</paper>

		<paper id="1022">
			<definition id="0">
				<sentence>The meaning of an expression is a function of the meaning of its parts and the way in which they are syntactically combined .</sentence>
				<definiendum id="0">meaning of an expression</definiendum>
			</definition>
			<definition id="1">
				<sentence>The Isomorphy Principle is the most characteristic principle of the Rosetta system , as it expresses our compositional theory of translation .</sentence>
				<definiendum id="0">Isomorphy Principle</definiendum>
				<definiens id="0">the most characteristic principle of the Rosetta system , as it expresses our compositional theory of translation</definiens>
			</definition>
			<definition id="2">
				<sentence>M-PARSER is preceded by a component called SPARSER ( for surface parser ) which maps a sequence of lexical S-trees ( which is the output of A-MORPH ) onto a set of surface trees of which the lexical S-trees are the leaves .</sentence>
				<definiendum id="0">M-PARSER</definiendum>
				<definiendum id="1">lexical S-trees</definiendum>
				<definiens id="0">surface parser ) which maps a sequence of</definiens>
			</definition>
			<definition id="3">
				<sentence>Category mismatch is one of these translation problems , e.g. the graag//iilce case , where a Dutch adverb corresponds to an English verb .</sentence>
				<definiendum id="0">Category mismatch</definiendum>
				<definiens id="0">one of these translation problems</definiens>
			</definition>
			<definition id="4">
				<sentence>The shaded part denotes the subclass of the negation rules for the CLAUSE subgrammar of G t. The combination results in a modular structure of each grammar and helps to reduce the complexity of the translation relation .</sentence>
				<definiendum id="0">shaded part</definiendum>
				<definiens id="0">the subclass of the negation rules for the CLAUSE subgrammar of G t. The combination results in a modular structure of each grammar and helps to reduce the complexity of the translation relation</definiens>
			</definition>
			<definition id="5">
				<sentence>The syntactic component of an M-grammar defines a set of objects called S-trees ( surface trees ) .</sentence>
				<definiendum id="0">syntactic component of an M-grammar</definiendum>
			</definition>
			<definition id="6">
				<sentence>127 An S-tree is a node N , or an expression of the form N\ [ rl/tl , ... , r./t.\ ] ( n &gt; 0 ) where N is a node , the ri 's are syntactic relations and the t ; 's are S-trees .</sentence>
				<definiendum id="0">S-tree</definiendum>
				<definiendum id="1">N</definiendum>
				<definiens id="0">a node , the ri 's are syntactic relations and the t</definiens>
			</definition>
			<definition id="7">
				<sentence>( we will often use this kind of recursive definition : the second recursive part of the definition indicates that S-trees may have arbitrary , but finite , depth ; the first part shows how the recursion terminates : the leaves of the trees are always ( terminal ) nodes ) A node N is defined as a syntactic category followed by a tuple of attribute-value pairs ( ai : vi ) .</sentence>
				<definiendum id="0">node N</definiendum>
				<definiens id="0">the second recursive part of the definition indicates that S-trees may have arbitrary , but finite , depth ; the first part shows how the recursion terminates : the leaves of the trees are always ( terminal ) nodes ) A</definiens>
			</definition>
			<definition id="8">
				<sentence>the set TM of well-formed S-trees , a subset of T. TM consists of the surface trees of sentences that are well-formed according to the grammar .</sentence>
				<definiendum id="0">subset of T. TM</definiendum>
				<definiens id="0">consists of the surface trees of sentences that are well-formed according to the grammar</definiens>
			</definition>
			<definition id="9">
				<sentence>TM is defined by specifying : a set B of basic S-trees , a set of syntactic rules , called M-rules , a special category : SENTENCE .</sentence>
				<definiendum id="0">TM</definiendum>
				<definiendum id="1">M-rules</definiendum>
				<definiens id="0">a set B of basic S-trees , a set of syntactic rules</definiens>
			</definition>
			<definition id="10">
				<sentence>t • F , ( tt ... .. t. ) ¢==~ ( tt ... .. t , ) • F'i ( t ) S-trees are constructed by applying M-rules recursively , starting from basic expressions , The set TM is the set of S-trees that can be derived in this way and that have the category SENTENCE .</sentence>
				<definiendum id="0">set TM</definiendum>
				<definiens id="0">the set of S-trees that can be derived in this way</definiens>
			</definition>
			<definition id="11">
				<sentence>f { t I 3b• B : d=b andt=b } U { t \ ] 3tl , ... , t. , dl ... .. d. , Ri : d = R , &lt; dl , ... , d. &gt; and t~ • M-GENERATOR ( dl ) and t. • M-GENERATOR ( d. ) and t • F , ' ( tl ... .. t , ) } ( In this definition d , d~ , d. are derivation trees , t , tt , t. are S-trees , B is the set of basic S-trees , b is a basic S-tree , b is the name of a basic expression , F : is the compositional function defined by rule R~ ) M-PARSER ( t ) =d..</sentence>
				<definiendum id="0">F :</definiendum>
				<definiens id="0">d=b andt=b } U { t \ ] 3tl , ... , t. , dl ... .. d. , Ri : d = R , &lt; dl , ... , d. &gt; and t~ • M-GENERATOR ( dl ) and t. • M-GENERATOR ( d. ) and t • F , ' ( tl ... .. t</definiens>
				<definiens id="1">derivation trees , t , tt , t. are S-trees , B is the set of basic S-trees , b is a basic S-tree , b is the name of a basic expression ,</definiens>
			</definition>
			<definition id="12">
				<sentence>d , • M-PARSER ( t , ~ ) and d = R ; &lt; dt ... . , d. &gt; } ( F ' ; is the analytical function defined by rule R ; ) Given the reversibility of the M-rules , it is easy to prove that t E M-GENERATOR ( d ) ~ d E M-PARSER ( t ) 128 Note that M-PARSER and M-GENERATOR can both be used to define the set TM of well-formed Strees .</sentence>
				<definiendum id="0">;</definiendum>
				<definiens id="0">d = R ; &lt; dt ... . , d. &gt; } ( F '</definiens>
			</definition>
			<definition id="13">
				<sentence>The set TM of well-formed S-trees is defined by specifying : A subgrammar Gi consists of : • a set EXPORTCATSi of syntactic categories ( the categories of S-trees that can be exported ) .</sentence>
				<definiendum id="0">set TM</definiendum>
				<definiendum id="1">well-formed S-trees</definiendum>
				<definiendum id="2">subgrammar Gi</definiendum>
				<definiens id="0">consists of : • a set EXPORTCATSi of syntactic categories ( the categories of S-trees that can be exported )</definiens>
			</definition>
			<definition id="14">
				<sentence>A derivation tree is : the name b_ of a basic expression , or an expression of the form ( G.R ; ) &lt; d~ ... . , d. &gt; ( n &gt; 0 ) , where Gi is ( the name of ) a subgrammar , R i is ( the name of ) a meaningful M-rule , and dl , ... , d , ~ are derivation trees .</sentence>
				<definiendum id="0">derivation tree</definiendum>
				<definiendum id="1">Gi</definiendum>
			</definition>
			<definition id="15">
				<sentence>129 or an expression of the form ( G ; , R/ ) &lt; DI , ... , D , &gt; , where G # is the name of a subgrammar , R i is the name of a meaningful M-rule , DI is an open derivation tree , D2 , ... , D , are derivation trees .</sentence>
				<definiendum id="0">DI</definiendum>
				<definiens id="0">an expression of the form ( G ; , R/ ) &lt; DI , ... , D , &gt; , where G # is the name of a subgrammar</definiens>
			</definition>
			<definition id="16">
				<sentence>A successful application of SG-PARSER yields a pair ( D , u ) , where D is an open derivation tree and u is the resulting 'head ' S-tree .</sentence>
				<definiendum id="0">D</definiendum>
				<definiendum id="1">u</definiendum>
				<definiens id="0">an open derivation tree</definiens>
			</definition>
			<definition id="17">
				<sentence>If successful , MPARSER ( u ) yields a derivation tree d. Then D { d\ ] is a derivation tree of t. SG-PARSER is defined by means of a function CEPARSER .</sentence>
				<definiendum id="0">MPARSER</definiendum>
				<definiens id="0">a derivation tree of t. SG-PARSER is defined by means of a function CEPARSER</definiens>
			</definition>
			<definition id="18">
				<sentence>CE-PARSER has 4 arguments ( G ; , ce , D , t ) , where G , is a subgrammar name , ce is a control expression , D is the open derivation tree resulting from previous applications of CE-PARSER , t is the S-tree that is yet to be parsed .</sentence>
				<definiendum id="0">D</definiendum>
				<definiens id="0">the open derivation tree resulting from previous applications of CE-PARSER</definiens>
			</definition>
			<definition id="19">
				<sentence>When CF_ , -PARSER is called for the first time , D is the empty derivation tree and ce is the control expression ce ; of G ; .</sentence>
				<definiendum id="0">-PARSER</definiendum>
				<definiendum id="1">D</definiendum>
				<definiendum id="2">ce</definiendum>
				<definiens id="0">the empty derivation tree and</definiens>
			</definition>
			<definition id="20">
				<sentence>I { d 13 bEB : d=bandt = b } u { d 13 G , , dr , D2 , u : syncat ( t ) E EXPORTCATS ; and ( D2 , u ) E SG-PARSER ( G ; , t ) and d~ E M-PARSER ( u ) and d = D2\ [ d~\ ] } ( In this definition d , dl are closed derivation trees , D2 is an open derivation tree , t , u are S-trees , syncat ( t ) is the syntactic category of t , b is a basic expression , b is the name of a basic expresslon , Gi is a subgrammar ) SG-PARSER ( G~ , t ) =d..</sentence>
				<definiendum id="0">D2</definiendum>
				<definiendum id="1">Gi</definiendum>
				<definiens id="0">d=bandt = b } u { d 13 G , , dr , D2 , u : syncat ( t ) E EXPORTCATS ; and ( D2 , u ) E SG-PARSER ( G ;</definiens>
				<definiens id="1">an open derivation tree</definiens>
				<definiens id="2">the syntactic category of t , b is a basic expression , b is the name of a basic expresslon ,</definiens>
				<definiens id="3">a subgrammar ) SG-PARSER ( G~ , t</definiens>
			</definition>
			<definition id="21">
				<sentence>{ ( D , u ) I ( D , u , true ) e CE-PARSER ( G ; , ce ; , DE , t ) } ( ce ; is the control expression of ce ; ) CF_ , -PARSER ( G ; , ce , D , t ) =~ .</sentence>
				<definiendum id="0">DE</definiendum>
				<definiens id="0">D , u , true ) e CE-PARSER ( G ; , ce ; ,</definiens>
				<definiens id="1">the control expression of ce ; ) CF_ , -PARSER ( G ; , ce</definiens>
			</definition>
			<definition id="22">
				<sentence>-PARSER ( G , , cet , D , t ) ) } U { ( D~ , u , A ) I 3 cet : ce = \ [ ce , l and ( ( D~ = D and u = t and A = false ) or ( D2 , u , true ) • CF_ , -PARSER ( GI , ce , , D , t ) and A = true ) } U { ( D~ , u , A ) I B ce , : ce = { ce , } and ( ( D~ = D and u = t and A = false ) or ( 3 D , , it , At : ( Dr , tt , true ) • CE-PARSER ( Gi , ce , , D , t ) and ( D2 , u , A , ) • CE-PARSER ( GI , ce , D , , tt ) and A = true ) ) } U { ( D2 , u , true ) I 3 k , n , Rk , d2 ... . , d. : ce = Rk and Rk • MF-RULESi and D2 = D\ [ ( G ; , Rk ) &lt; D~ , d2 ... . , d. &gt; \ ] and ( u , ta ... .. t , ) • F'k ( t ) and d~ 6 M-PARSER ( t2 ) and d. •M-PARSER ( t. ) } U { ( D2 , u , true ) I 3 k , at : Rk 6 TR-RULES ; and D2 =D and ce =Rk and u • F't , ( t ) } ( ce , ce , , ce2 are control ( sub ) expressions , D , D , , D2 are open derivation trees , d2 , ... , d , are closed derivation trees , De is the empty derivation tree , t , t , , t2 , t. , u are S-trees , Rk is an M-rule , F'k is the analytical function defined by rule Rk , A , At , A2 are booleans ) An additional advantage of controlled M-grammars is that the measure condition ( cf. 6.1 ) can be reformulated in a way that is much easier to obey that in the original framework .</sentence>
				<definiendum id="0">-PARSER</definiendum>
				<definiendum id="1">u</definiendum>
				<definiendum id="2">De</definiendum>
				<definiendum id="3">Rk</definiendum>
				<definiendum id="4">F'k</definiendum>
				<definiens id="0">G , , cet , D , t ) ) } U { ( D~ , u , A ) I 3 cet : ce = \ [ ce , l and ( ( D~ = D and u = t and A = false ) or ( D2 , u , true ) • CF_ , -PARSER ( GI , ce , , D , t ) and A = true ) } U { ( D~ ,</definiens>
				<definiens id="1">D~ = D and u = t and A = false ) or ( 3 D , , it , At : ( Dr , tt , true ) • CE-PARSER ( Gi , ce , , D , t ) and ( D2 , u , A , ) • CE-PARSER ( GI , ce , D , , tt ) and A = true ) ) } U { ( D2 , u , true ) I 3 k , n , Rk , d2 ... . , d. : ce = Rk and Rk • MF-RULESi and D2 = D\ [ ( G ; , Rk ) &lt; D~ , d2 ... . , d. &gt; \ ] and ( u , ta ... .. t , ) • F'k ( t ) and d~ 6 M-PARSER ( t2 ) and d. •M-PARSER ( t. ) } U { ( D2 , u , true ) I 3 k , at : Rk 6 TR-RULES ; and D2 =D and ce =Rk and u • F't , ( t ) } ( ce , ce , , ce2 are control ( sub ) expressions , D , D , , D2 are open derivation trees , d2 , ... , d , are closed derivation trees</definiens>
				<definiens id="2">the empty derivation tree , t , t , , t2 , t. , u are S-trees</definiens>
				<definiens id="3">the analytical function defined by rule Rk , A , At , A2 are booleans ) An additional advantage of controlled M-grammars is that the measure condition ( cf. 6.1 ) can be reformulated in a way that is much easier to obey that in the original framework</definiens>
			</definition>
			<definition id="23">
				<sentence>M-GENERATOR ( d ) =d~/ { tlBb6B : d=bandt=b } U { t I 3 G ; , d , , D~ , u : d = D2\ [ dt\ ] and u • M-GENERATOR ( dr ) and syncat ( u ) • HEADCATS ; and t • SG-GEN ( G ; , D2 , u ) } ( d , dt are closed derivation trees , D2 is an open derivation tree , t , u are S-trees , b is a basic expression , b is the name of a basic expression , G # is a subgrammar , syncat ( u ) is the syntactic category of u ) SG-GEN ( G ; , D , u ) =a..</sentence>
				<definiendum id="0">D2</definiendum>
				<definiendum id="1">b</definiendum>
				<definiendum id="2">subgrammar , syncat</definiendum>
				<definiens id="0">an open derivation tree</definiens>
				<definiens id="1">a basic expression , b is the name of a basic expression</definiens>
			</definition>
			<definition id="24">
				<sentence>{ t I ( t , De , true ) • CE-GEN ( G , , ce , , D , u ) } ( cei is the control expression of Gi , D~ is the empty derivation tree ) CE-GEN ( G ; , ce , D2 , u ) =d- .</sentence>
				<definiendum id="0">cei</definiendum>
				<definiendum id="1">D~</definiendum>
				<definiens id="0">the empty derivation tree ) CE-GEN ( G ; , ce , D2 , u</definiens>
			</definition>
			<definition id="25">
				<sentence>ce2 and `` cel is not a concatenation '' and ( t , , D , , A , ) • CF_ , -GEN ( GI , ce , , D2 , u ) and ( t , D , A2 ) • CE-GEN ( G ; , ce2 , Dr , tl ) and A = Al or A2 } U { ( t , D , A ) I 3 ce , , ce2 : ce = cel\ ] ce2 and `` cet is not a dlsjunction '' and ( t , D , A ) • ( CE-GEN ( G ; , ce , , D2 , u ) U CF_ , -GEN ( G , , ce , , D , , u ) ) } U { ( t , D , A ) I 3 ce , : ce = \ [ cell and ( ( D~ = D and t = u andA=false ) or ( ( t , D , true ) e CE-GEN ( G ; , ce , , Ds , u ) and A = true ) ) } U { ( t , D , A ) Jqcet : ce = { cel } and ( ( D2 = D and t = u and A = false ) or ( 3 D* , tl , At : ( t , , Dr , true ) E CF_ , -GEN ( G , , cel , Ds , u ) and ( t , D , A , ) 6 CE-GEN ( G ; , ce , Dl , tt ) and A = true ) ) } U { ( t , D , true ) I 3 k , n , Rk , d~ , ... , d. : ce = Rk and 131 Rk • MF-RULES ; and D2 = D\ [ ( G , , Rk ) &lt; D~ , d2 ... . , d. &gt; \ ] and t • Ft ( u , t2 , ... , t , ) and t2 • M-GENERATOR ( d2 ) and t , • M-GENERATOR ( d , ) ) U { ( t , D , true ) \ [ q k , Rk : Rk • TR-RULES~ D = D2 and ce = Rt and t • Fk ( u ) } ( ce , cet , ce2 are control expressions , D , Dr , D2 are open derivation trees , d2 , ... , d , are closed derivation trees , D~ is the empty derivation tree , t , it , t2 , t , , u are S-trees , R~ an M-rule , Ft is the compositional function defined by rule Rk , A , At , A2 are booleans ) Remarks In case of a recursive transformation class there is the possibility of infinite recurslon during application of CE-GEN .</sentence>
				<definiendum id="0">D~</definiendum>
				<definiendum id="1">R~</definiendum>
				<definiendum id="2">Ft</definiendum>
				<definiens id="0">a concatenation '' and ( t , , D , , A , ) • CF_ , -GEN ( GI , ce , , D2 , u ) and ( t , D , A2 ) • CE-GEN ( G ; , ce2 , Dr , tl ) and A = Al or A2 } U { ( t</definiens>
				<definiens id="1">a dlsjunction '' and ( t , D , A ) • ( CE-GEN ( G ; , ce , , D2 , u ) U CF_ , -GEN ( G , , ce , , D , , u ) ) } U { ( t , D , A ) I 3 ce , : ce = \ [ cell and ( ( D~ = D and t = u andA=false ) or ( ( t , D , true ) e CE-GEN ( G ; , ce , , Ds , u ) and A = true ) ) } U { ( t , D , A ) Jqcet : ce = { cel } and ( ( D2 = D and t = u and A = false ) or ( 3 D* , tl , At : ( t , , Dr , true ) E CF_ , -GEN ( G , , cel , Ds , u ) and ( t , D , A , ) 6 CE-GEN ( G ; , ce , Dl , tt ) and A = true ) ) } U { ( t , D , true ) I 3 k , n , Rk , d~ , ... , d. : ce = Rk and 131 Rk • MF-RULES ; and D2 = D\ [ ( G , , Rk ) &lt; D~ , d2 ... . , d. &gt; \ ] and t • Ft ( u , t2 , ... , t , ) and t2 • M-GENERATOR ( d2 ) and t , • M-GENERATOR ( d , ) ) U { ( t , D , true ) \ [ q k , Rk : Rk • TR-RULES~ D = D2 and ce = Rt and t • Fk ( u ) } ( ce , cet , ce2 are control expressions , D , Dr , D2 are open derivation trees , d2 , ... , d , are closed derivation trees ,</definiens>
				<definiens id="2">the empty derivation tree , t , it , t2 , t , , u are S-trees</definiens>
				<definiens id="3">the compositional function defined by rule Rk , A , At , A2 are booleans ) Remarks In case of a recursive transformation class there is the possibility of infinite recurslon during application of CE-GEN</definiens>
			</definition>
</paper>

		<paper id="1003">
			<definition id="0">
				<sentence>A rule consists of a rule pair ( which consists of a lexical and a surface character ) , an operator , a left context and a right context .</sentence>
				<definiendum id="0">rule</definiendum>
				<definiens id="0">consists of a rule pair ( which consists of a lexical and a surface character ) , an operator , a left context and a right context</definiens>
			</definition>
</paper>

		<paper id="1013">
			<definition id="0">
				<sentence>The Morphology Specialist ( MS ) is devoted to perform the morphological analysis of each word , i.e. extracting from the Dictionary all the relevant information and determining the appropriate morphological types and variables .</sentence>
				<definiendum id="0">Morphology Specialist ( MS</definiendum>
				<definiens id="0">all the relevant information and determining the appropriate morphological types and variables</definiens>
			</definition>
			<definition id="1">
				<sentence>The Encyclopedia Specialist ( ES ) is able to access the Encyclopedia for extracting semantic information and world knowledge .</sentence>
				<definiendum id="0">Encyclopedia Specialist ( ES</definiendum>
				<definiens id="0">extracting semantic information and world knowledge</definiens>
			</definition>
</paper>

		<paper id="1014">
			<definition id="0">
				<sentence>A J W ) denotes the probability that the se__quence of words W will produce the acoustic stringj ' , P ( W ) is the a priori probability of word string W , P ( A ) is the probability of acoustic string A. To find the word sequence which maximizes the third term in the preceding equation , it is sufficient to find the sequence which maximizes the numerator ; P ( A ) is , in fact , clearly not dependent on any W. Then , the recognition task can be decomposed in these problems : speech signal an information A representative of its acoustic features , and , at the same time , adequate for a statistical analysis ; create an acoustic model which makes it possible to evaluate P ( A'\ [ W-~_ ) , that is the probability that the acoustic string A will be produced when the speaker pronounces the word string W ; create a language model giving the prob .</sentence>
				<definiendum id="0">J W )</definiendum>
				<definiendum id="1">P ( A )</definiendum>
				<definiendum id="2">P ( A )</definiendum>
				<definiendum id="3">speech signal</definiendum>
				<definiens id="0">the probability that the se__quence of words W will produce the acoustic stringj '</definiens>
				<definiens id="1">the probability of acoustic string A. To find the word sequence which maximizes the third term in the preceding equation</definiens>
				<definiens id="2">sufficient to find the sequence which maximizes the numerator ;</definiens>
				<definiens id="3">an acoustic model which makes it possible to evaluate P ( A'\ [ W-~_ ) , that is the probability that the acoustic string A will be produced when the speaker pronounces the word string W ; create a language model giving the prob</definiens>
			</definition>
</paper>

		<paper id="1038">
			<definition id="0">
				<sentence>A lexieal task specifies a possible reading of a word to be inserted in the chart .</sentence>
				<definiendum id="0">lexieal task</definiendum>
				<definiens id="0">specifies a possible reading of a word to be inserted in the chart</definiens>
			</definition>
			<definition id="1">
				<sentence>A traversal task specifies an active edge and an inactive edge that can extend it .</sentence>
				<definiendum id="0">traversal task</definiendum>
			</definition>
</paper>

		<paper id="1019">
			<definition id="0">
				<sentence>Thus , e.g. , words ending in -ER , -OR , -GRAPH , -ODE and some others are interpreted as nouns , concrete , instruments , capable of being substituted for human ac ~ tor ; words ending in -CS , -CY , -ESS , -TUDE are supposed to be nouns , abstract , properties and , as distict from those ending in -ITY , -ICS , -SM , -SHIP , -HOOD , -THM , which otherwise have the same semantic characteristics , they form adjectives in a regular manner in Czech ; the endings -FY , -ATE , -ISE ( -IZE ) , -DUCE indicate verbs that can be both transitive and intransitive , of causative and ( semi ) terminological character , yet not allowed to form adjectices of the purposive type .</sentence>
				<definiendum id="0">-THM</definiendum>
				<definiens id="0">-ATE , -ISE ( -IZE ) , -DUCE indicate verbs that can be both transitive and intransitive , of causative and ( semi ) terminological character , yet not allowed to form adjectices of the purposive type</definiens>
			</definition>
</paper>

		<paper id="1039">
			<definition id="0">
				<sentence>ER analysis is the cornerstone of several application development toolkits , including the Information Engineering Workbench , which uses such models as input to a process that ultimately leads to automatic code generation .</sentence>
				<definiendum id="0">ER analysis</definiendum>
				<definiendum id="1">Information Engineering Workbench</definiendum>
				<definiens id="0">uses such models as input to a process that ultimately leads to automatic code generation</definiens>
			</definition>
			<definition id="1">
				<sentence>Objects are of two kinds : NOLOTs or NOn-Lexical Object Types are concrete or abstract objects of reality , and LOTs or Lexieal Object Types are objects of which occurrences have values , i.e. they are names .</sentence>
				<definiendum id="0">Objects</definiendum>
				<definiens id="0">NOLOTs or NOn-Lexical Object Types are concrete or abstract objects of reality , and LOTs or Lexieal Object Types are objects of which occurrences have values</definiens>
			</definition>
			<definition id="2">
				<sentence>Database interfaces are the most common instances of complete natural language interfaces which comprise beth syntactic and semantic components .</sentence>
				<definiendum id="0">Database interfaces</definiendum>
				<definiens id="0">the most common instances of complete natural language interfaces which comprise beth syntactic and semantic components</definiens>
			</definition>
			<definition id="3">
				<sentence>The first is the name of the word , the second is the propositional meaning , the third a variable denoting time , the fourth specifies the semantic subeategorization of the word ( in the case of nouns ) or its subject ( in the case of verbs ) , and the last subeategorizes the objects or other postmodifiers the word may take .</sentence>
				<definiendum id="0">fourth</definiendum>
				<definiens id="0">specifies the semantic subeategorization of the word ( in the case of nouns ) or its subject ( in the case of verbs</definiens>
			</definition>
</paper>

		<paper id="1028">
			<definition id="0">
				<sentence>The CONN is the field for conjunctions .</sentence>
				<definiendum id="0">CONN</definiendum>
				<definiens id="0">the field for conjunctions</definiens>
			</definition>
			<definition id="1">
				<sentence>This is one of the places where field grammar shows its force as a syntactic strategy , because the phenomenon of discontinuity is handled in a straightforward way at the first level of analysis : ADVFLD = nil ; cadvfld ( CADF , CADF ) with CADF = nil ; prep ( PREP ) ; cadf ( ADVERBIAL ) where CADF is the field for i.a. contential adverbs , but also for disjunct verbal 168 particles .</sentence>
				<definiendum id="0">CADF</definiendum>
				<definiens id="0">the field for i.a. contential adverbs , but also for disjunct verbal 168 particles</definiens>
			</definition>
			<definition id="2">
				<sentence>As regards adverbials , the structure given is only one of several possible : NOMINAL = nil ; nominal ( ART , ADJEKTIVAL , SUBKERN PREPP , CS ) ADVERBIAL : nil ; adverbial ( CONN , DEGREEF , SITUATF , ADVKERN , PREPP , CS ) The CS is a symbol representing subordinate sentences , which have the form : CS = nil ; cs ( S , SYNT ) where S is the field structure , and SYNT the corresponding syntactical structure of the subordinate sentence represented by the token of the symbol type CS .</sentence>
				<definiendum id="0">SYNT</definiendum>
				<definiens id="0">NOMINAL = nil ; nominal ( ART , ADJEKTIVAL , SUBKERN PREPP , CS ) ADVERBIAL : nil ; adverbial ( CONN , DEGREEF , SITUATF , ADVKERN , PREPP , CS ) The CS is a symbol representing subordinate sentences , which have the form : CS = nil ; cs ( S , SYNT ) where S is the field structure</definiens>
				<definiens id="1">the corresponding syntactical structure of the subordinate sentence represented by the token of the symbol type CS</definiens>
			</definition>
			<definition id="3">
				<sentence>which applies the following rules in order to succeed ( or fail ) : is_fundf ( I , O , fundf n ( NOMINAL ) ) : is nomen ( I , O , NOMINAL ) , I &lt; &gt; O. is_fundf ( I , O , fundf a ( ADVERBIAL ) ) : is adverbial ( I , O , ADVERBIAL , ) , I~ &gt; O. is_nexusf ( I , O , nexusf ( FINIT , NOMINAL , ADVERBIAL ) ) : is finit ( I , II , FINIT ) , is-nomen ( II , I2 , NOMINAL , _ , _ ) , is~adverbial ( I2 , O , ADVERBIAL , _ ) .</sentence>
				<definiendum id="0">ADVERBIAL</definiendum>
				<definiens id="0">adverbial ( I , O ,</definiens>
			</definition>
</paper>

		<paper id="1009">
</paper>

		<paper id="1018">
			<definition id="0">
				<sentence>The comparison of different approaches to linguistic theory as to point ( a ) is a matter of the theory itself ; let us only note that many theories seem not to be sufficiently adequate in that they do not properly distinguish between the three dimensions of the sentence structure ( valency or theta roles , coordination and apposition , and also topic and focus , which often is almost altogether neglected I ) and the morphological categories ( tense , aspect , number , definiteness , and so on ) ; the latter occupy no immediate positions in the structure of the sentence with its recursive properties , and thus it is not adequate to denote e.g. prepositions as if they perticulation for translation and for other aims of language comprehension can be illustrated by the following examples : In the hallway one smokes should be distinguished from One smokes inthe hallway similarly as Few books are read by many men from Many men read few books .</sentence>
				<definiendum id="0">focus</definiendum>
				<definiendum id="1">language comprehension</definiendum>
				<definiens id="0">a matter of the theory itself</definiens>
				<definiens id="1">do not properly distinguish between the three dimensions of the sentence structure ( valency or theta roles , coordination and apposition</definiens>
				<definiens id="2">tense , aspect , number , definiteness , and so on</definiens>
			</definition>
</paper>

		<paper id="1015">
			<definition id="0">
				<sentence>The semantic classes ( features ) are hierarchically organized in a way , so that all subclasses of a class also are accepted as compatible .</sentence>
				<definiendum id="0">semantic classes</definiendum>
				<definiens id="0">features ) are hierarchically organized in a way</definiens>
			</definition>
			<definition id="1">
				<sentence>For example , if a word with the semantic class CONcrete is required , also a word with the class ANimate ( a subclass of CONcrete ) or with the class HUman ( a subclass of ANimate ) is accepted .</sentence>
				<definiendum id="0">ANimate</definiendum>
				<definiendum id="1">HUman</definiendum>
				<definiens id="0">a subclass of ANimate ) is accepted</definiens>
			</definition>
			<definition id="2">
				<sentence>In our system the pragmatic ( task-specific ) knowledge is represented in a semantic network ( Brielzmarm 1984 ) as is the knowledge of the semantic module .</sentence>
				<definiendum id="0">pragmatic</definiendum>
				<definiens id="0">the knowledge of the semantic module</definiens>
			</definition>
			<definition id="3">
				<sentence>The pragmatic bitvector of a group of words wl ... wn is then : pbv ( wl ... v-n ) : = pbv ( wl ) AND pbv ( w2 ) ... AND pbv ( wn ) The pragmatic priority pP ( wl ... wn ) is defined as the number of `` 1 '' in pbv ( wl ... wn ) and has the following properties : * If the pragn~tic priority of a group of words = O , then the group is pragmatically inconsistent .</sentence>
				<definiendum id="0">pbv ( wn</definiendum>
				<definiens id="0">The pragmatic bitvector of a group of words wl ... wn is then : pbv ( wl ... v-n ) : = pbv ( wl ) AND pbv ( w2 ) ... AND</definiens>
				<definiens id="1">the number of `` 1 '' in pbv ( wl ... wn ) and has the following properties : * If the pragn~tic priority of a group of words = O</definiens>
			</definition>
</paper>

		<paper id="1040">
			<definition id="0">
				<sentence>Concepts are the generalization of physical perceptions ( MAN , CAT , NOISE ) or abstract categories ( FREEDOM , LOVE ) .</sentence>
				<definiendum id="0">Concepts</definiendum>
			</definition>
			<definition id="1">
				<sentence>Conceptual relations express the semantic links between concepts .</sentence>
				<definiendum id="0">Conceptual relations</definiendum>
			</definition>
			<definition id="2">
				<sentence>For example , the phrase `` John eats ~ is : 'cpresented as follows : \ [ PERSON : John\ ] &lt; -- ( AGNT ) &lt; -- \ [ EAT\ ] where ( AGNT ) is a diadic relation used to explicit the active role of the entity John with respect to the action of eating .</sentence>
				<definiendum id="0">AGNT</definiendum>
				<definiens id="0">a diadic relation used to explicit the active role of the entity John with respect to the action of eating</definiens>
			</definition>
			<definition id="3">
				<sentence>R3 : A biunivocal correspondence is assumed between roles played t ' .</sentence>
				<definiendum id="0">R3</definiendum>
				<definiens id="0">A biunivocal correspondence is assumed between roles played t '</definiens>
			</definition>
			<definition id="4">
				<sentence>For example , the subject relation , which expresses the active role of an entity in some action , corresponds m different semantic relation , like agent ( AGNT ) as in `` .</sentence>
				<definiendum id="0">subject relation</definiendum>
				<definiendum id="1">AGNT</definiendum>
				<definiens id="0">expresses the active role of an entity in some action , corresponds m different semantic relation , like agent (</definiens>
			</definition>
			<definition id="5">
				<sentence>lohn reads '' , initiator ( INIT ) as in `` John boils potatoes '' ( John starts the process of boiling ) , participant ( I'ART ) as in `` John flies to Roma '' ( John participates to a flight ) , instrument ( INST ) as in ' .</sentence>
				<definiendum id="0">INST</definiendum>
				<definiens id="0">potatoes '' ( John starts the process of boiling</definiens>
			</definition>
			<definition id="6">
				<sentence>Consider for example the following problems , encountered during the analysis of our text data base ( press agency releases of economics ) : `` The state department , the ACE and the trade unions sign an agreement '' `` The meeting was held at the ACE of Roma '' In the first sentence , ACE designates a human organization ; it is some delegate of the ACE who actually sign the agreement .</sentence>
				<definiendum id="0">ACE</definiendum>
				<definiens id="0">designates a human organization</definiens>
			</definition>
			<definition id="7">
				<sentence>Pragmatics is the knowledge about word uses , contexts , figures of speech ; it potentially unlimited , but allows to handle without severe restrictions the richness of natural language .</sentence>
				<definiendum id="0">Pragmatics</definiendum>
				<definiens id="0">the knowledge about word uses , contexts , figures of speech ; it potentially unlimited , but allows to handle without severe restrictions the richness of natural language</definiens>
			</definition>
			<definition id="8">
				<sentence>This solution does not avoid inconsistencies ; for example , the graph ( included in the definition of the word-sense person ) : ( 6 ) \ [ person\ ] `` -- ( AGNT ) &lt; -- \ [ MOVE_ACT\ ] is a semantic representation of expressions like : John moves , goes , jumps , runs etc. but also states the validity of the expression `` John is the agent of flying '' which is instead not valid if John is a person .</sentence>
				<definiendum id="0">AGNT</definiendum>
				<definiendum id="1">John</definiendum>
				<definiendum id="2">flying</definiendum>
				<definiens id="0">the agent of</definiens>
				<definiens id="1">a person</definiens>
			</definition>
			<definition id="9">
				<sentence>A link subgraph for house is : ( POSS ) `` : -- \ [ I 1UMAN\ ] ( INC , I , ) -- : -\ [ HUMAN\ ] ( I NCI , ) ... . \ [ DO M F , q'FIC_AN I M ALl ( INCI , ) ... . \ [ FURNITURE\ ] and for eat : ( AN I ) ) -- : \ [ drink\ ] ( 0 P POS I'r E ) - : -- \ [ starve\ ] ( PR F , C ) - : \ [ hunger\ ] ( A r : I'I~P , ) -- , -\ [ satiety\ ] Note that sume elementary graph expresses a relation between two terminal nodes ( as for example the opposite of eal ) ; in most cases however conditions are more general .</sentence>
				<definiendum id="0">link subgraph</definiendum>
				<definiendum id="1">INC</definiendum>
				<definiens id="0">I'I~P , ) -- , -\ [ satiety\ ] Note that sume elementary graph expresses a relation between two terminal nodes</definiens>
			</definition>
			<definition id="10">
				<sentence>The semantic processor consists of a semantic knowledge base and a parsing algorithm .</sentence>
				<definiendum id="0">semantic processor</definiendum>
				<definiens id="0">consists of a semantic knowledge base and a parsing algorithm</definiens>
			</definition>
			<definition id="11">
				<sentence>For example , a noun phrase ( NP ) followed by a verb phrase ( VP ) could be represented by a subset of the LINK relations listed in the Appendix .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiendum id="1">VP</definiendum>
				<definiens id="0">relations listed in the Appendix</definiens>
			</definition>
			<definition id="12">
				<sentence>The first is a set of short paraphrases of the input sentence : for example , given the sentence `` The ACE signs an agreement with the government '' gives : The Society ACE is the agent of the act SIGN .</sentence>
				<definiendum id="0">Society ACE</definiendum>
				<definiens id="0">the agent of the act SIGN</definiens>
			</definition>
			<definition id="13">
				<sentence>AGP , EEM ENT is the result of the act SIGN .</sentence>
				<definiendum id="0">EEM ENT</definiendum>
				<definiens id="0">the result of the act SIGN</definiens>
			</definition>
</paper>

		<paper id="1021">
			<definition id="0">
				<sentence>ad ( 4 ) : Syntactico-semantic analysis SSA is the most important part of RUSLAN .</sentence>
				<definiendum id="0">SSA</definiendum>
				<definiens id="0">Syntactico-semantic analysis</definiens>
				<definiens id="1">the most important part of RUSLAN</definiens>
			</definition>
</paper>

		<paper id="1002">
</paper>

		<paper id="1007">
			<definition id="0">
				<sentence>ABSTRACT The Constituent Likelihood Automatic Word-tagging System ( CLAWS ) was originally designed for the low-level grammatical analysis of the million-word LOB Corpus of English text samples .</sentence>
				<definiendum id="0">Constituent Likelihood Automatic Word-tagging System</definiendum>
				<definiens id="0">the low-level grammatical analysis of the million-word LOB Corpus of English text samples</definiens>
			</definition>
			<definition id="1">
				<sentence>The LOB Corpus is a million-word collection of English text samples , used for experimentation and inspiration in computational linguistics and related studies ( see for example \ [ Leech et al 83a\ ] , \ [ Atwell forthcoming b\ ] ) .</sentence>
				<definiendum id="0">LOB Corpus</definiendum>
				<definiens id="0">a million-word collection of English text samples , used for experimentation and inspiration in computational linguistics and related studies</definiens>
			</definition>
			<definition id="2">
				<sentence>As in the original system , CLAWS uses the tag-pair frequency table and the Constituent Likelihood formulae to find the best word-tag for each word .</sentence>
				<definiendum id="0">CLAWS</definiendum>
				<definiens id="0">uses the tag-pair frequency table and the Constituent Likelihood formulae to find the best word-tag for each word</definiens>
			</definition>
			<definition id="3">
				<sentence>Errorlikelihood is a measure of how frequently a given tag-pair occurs in an error as compared to how frequently it occurs in valid text .</sentence>
				<definiendum id="0">Errorlikelihood</definiendum>
				<definiens id="0">a measure of how frequently a given tag-pair occurs in an error as compared to how frequently it occurs in valid text</definiens>
			</definition>
			<definition id="4">
				<sentence>Unfortunately , a threshold at this level would mean some minor troughs would not be flagged , e.g. clever in I stole a meat clever ... . ( which was tagged JJ ( adjective ) but should have been the noun cleaver ) has a normalised likelihood of 4.516465 ; tame in the gruesome tame ofEroc Attwell ... ( which was also tagged JJ ( adjective ) but should have been the noun tale ) also has a normalised likelihood of 4.516465 ; and the phrase won day ( which should have been one day ) involves a normalised likelihood of 4.060886 ( although this is , strictly speaking , associated with day rather than won , an error flag would be sufficiently close to the actual error to draw the user 's attention to it ) .</sentence>
				<definiendum id="0">day</definiendum>
				<definiens id="0">a normalised likelihood of 4.516465</definiens>
			</definition>
			<definition id="5">
				<sentence>The LOB Corpus includes many errors 41 which appeared in the original published texts ; these are marked SIC in the text , and noted in the Manual which comes with the Corpus files , \ [ Johansson et al 78\ ] .</sentence>
				<definiendum id="0">LOB Corpus</definiendum>
				<definiens id="0">includes many errors 41 which appeared in the original published texts ; these are marked SIC in the text , and noted in the Manual which comes with the Corpus files , \</definiens>
			</definition>
</paper>

		<paper id="1023">
			<definition id="0">
				<sentence>Anyway , maximal ( minimal ) elements can be defined in the following way : An object E is a maximal ( minimal ) element if no competing object is better ( worse ) than E. Thus an object in a cycle of the graph can not be maximal ( minimal ) .</sentence>
				<definiendum id="0">maximal</definiendum>
				<definiens id="0">the following way : An object E is a</definiens>
			</definition>
			<definition id="1">
				<sentence>SAiPattern indicates that the variable $ A is instantiated to the sub-tree that matches Pattern $ more branches ( and $ 1ess_branches ) is a predefined preference rule that prefer the argument that has more ( less ) branches than the other .</sentence>
				<definiendum id="0">SAiPattern</definiendum>
			</definition>
</paper>

		<paper id="1017">
			<definition id="0">
				<sentence>The transfer component consists solely of a dictionary of mappings between source and target language lexical items , or , where necessary ( eg for idioms ) , more complex quasi-syntactic configurations .</sentence>
				<definiendum id="0">transfer component</definiendum>
				<definiens id="0">consists solely of a dictionary of mappings between source and target language lexical items , or , where necessary ( eg for idioms ) , more complex quasi-syntactic configurations</definiens>
			</definition>
</paper>

		<paper id="1044">
			<definition id="0">
				<sentence>SHEILA takes advantage both from the use of expectations and from the combination of the results of a non-conventional syntactic analysis with the activity of a surface semantic analysis , based on the formalism of conceptual graphs ( 8 ) .</sentence>
				<definiendum id="0">SHEILA</definiendum>
				<definiens id="0">takes advantage both from the use of expectations and from the combination of the results of a non-conventional syntactic analysis with the activity of a surface semantic analysis , based on the formalism of conceptual graphs ( 8 )</definiens>
			</definition>
			<definition id="1">
				<sentence>The semantic analyzer checks the syntactic output to see if the semantic relations among words are supported by it .</sentence>
				<definiendum id="0">semantic analyzer</definiendum>
				<definiens id="0">checks the syntactic output to see if the semantic relations among words are supported by it</definiens>
			</definition>
			<definition id="2">
				<sentence>A basic constituent ( BC , henceforth ) is a NP , a PP or a VP described at a minimal level of complexity .</sentence>
				<definiendum id="0">basic constituent</definiendum>
				<definiens id="0">a PP or a VP described at a minimal level of complexity</definiens>
			</definition>
			<definition id="3">
				<sentence>The first interpretation can be described as : NP NP pp f A A IL SINDACO ROSSI Ol TORINO ( 11 ) At this level we have not so many ambiguities because the linguis-tic phenomena which cause them are still not faced .</sentence>
				<definiendum id="0">IL SINDACO ROSSI Ol TORINO</definiendum>
				<definiens id="0">the linguis-tic phenomena which cause them are still not faced</definiens>
			</definition>
			<definition id="4">
				<sentence>Our single representation consists of a graph of BCs connected by grammatical relations , which are established unless syntactic knowledge guarantees that no constituent in the two classes can be connected by such relations .</sentence>
				<definiendum id="0">single representation</definiendum>
				<definiens id="0">consists of a graph of BCs connected by grammatical relations , which are established unless syntactic knowledge guarantees that no constituent in the two classes can be connected by such relations</definiens>
			</definition>
			<definition id="5">
				<sentence>A conceptual graph is an oriented bipartite graph with two kinds of nodes : concept nodes ( representing entities ) and conceptual relation nodes ( representing semantic relations among concepts ) .</sentence>
				<definiendum id="0">conceptual graph</definiendum>
			</definition>
			<definition id="6">
				<sentence>The Type Hierarchy is a taxonomy of domain concepts used to inherit semantic contexts and guide graph joins .</sentence>
				<definiendum id="0">Type Hierarchy</definiendum>
				<definiens id="0">a taxonomy of domain concepts used to inherit semantic contexts and guide graph joins</definiens>
			</definition>
			<definition id="7">
				<sentence>The semantic relations and the grammatical relations must relate to the same couple of lexical items ; in other words such lexical items must be both the heads of the BCs ( involved by the grammatical relation ) and the heads of the conceptual graphs ( involved by the semantic relation ) .</sentence>
				<definiendum id="0">BCs (</definiendum>
				<definiens id="0">involved by the grammatical relation ) and the heads of the conceptual graphs ( involved by the semantic relation )</definiens>
			</definition>
			<definition id="8">
				<sentence>A semantic relation SR between two head nodes HNi and HNj , having as heads the words Wi and Wj , can only be established if : I ) there is a grammatical relation GR between two BCs , BCi and BCj , whose heads are Wi and Wj respectively .</sentence>
				<definiendum id="0">semantic relation SR</definiendum>
			</definition>
			<definition id="9">
				<sentence>A mapping rule is a list of plausible grammatical relations that can correspond to the semantic relation .</sentence>
				<definiendum id="0">mapping rule</definiendum>
				<definiens id="0">a list of plausible grammatical relations that can correspond to the semantic relation</definiens>
			</definition>
</paper>

		<paper id="1010">
			<definition id="0">
				<sentence>A discovery procedure for phrase structure grammars would be simpler than one for TG grammars because phrase structure grammars are simpler ( more constrained ) than TG grammars .</sentence>
				<definiendum id="0">discovery procedure for phrase structure grammars</definiendum>
			</definition>
			<definition id="1">
				<sentence>The LOB Corpus is a collection of 500 British English text samples , each of just over 2000 words , totalling over a million words in all ; it is available in several formats ( with or without word-tags associated with each word ) from the Norwegian Computing Centre for the Humanities , Bergen University ( see ( lohansson et al 78 ) , ( lohansson et al 86 ) ) .</sentence>
				<definiendum id="0">LOB Corpus</definiendum>
				<definiens id="0">a collection of 500 British English text samples , each of just over 2000 words , totalling over a million words in all ; it is available in several formats ( with or without word-tags associated with each word ) from the Norwegian Computing Centre for the Humanities</definiens>
			</definition>
			<definition id="2">
				<sentence>RUNNEWTAGSET Statistical patXem recognition techniques have been used in many fields of scientific computing for data classification and pattern detection .</sentence>
				<definiendum id="0">RUNNEWTAGSET Statistical patXem recognition techniques</definiendum>
				<definiens id="0">used in many fields of scientific computing for data classification and pattern detection</definiens>
			</definition>
</paper>

		<paper id="1042">
			<definition id="0">
				<sentence>To emphasize the similarity of the two approaches , and to avoid proliferation of terminology , I use Webber 's term e/s structure for the representation of the narrative 's content , but retain Gross and Sidner 's terminology for the attentional state and speak of a focus space ( FS ) corresponding to each DS , and a focus space stack ( FS stack ) .</sentence>
				<definiendum id="0">FS stack</definiendum>
				<definiens id="0">the similarity of the two approaches , and to avoid proliferation of terminology , I use Webber 's term e/s structure for the representation of the narrative 's content , but retain Gross and Sidner 's terminology for the attentional state</definiens>
			</definition>
</paper>

		<paper id="1006">
			<definition id="0">
				<sentence>Suffixcs , in fact , differently from prefixes , changes both morphologic and syntactic characteristics of the original word : they change verbs into names or adjectives ( deverba/suff'oces ) , names into verbs or adjectives ( denominal suffixes ) , adjectives into verbs or names ( deadje : tival suffixes ) .</sentence>
				<definiendum id="0">Suffixcs</definiendum>
				<definiens id="0">changes both morphologic and syntactic characteristics of the original word : they change verbs into names or adjectives ( deverba/suff'oces ) , names into verbs or adjectives ( denominal suffixes</definiens>
			</definition>
			<definition id="1">
				<sentence>The analyzer parses the words from left to right , splitting them into elementary parts : prefix ( es ) , the stem ( s ) of the appropriate lemma ( ta ) of derivation ( retrieved from a restricted dictionary reporting only the `` elementary lemmata ' ) suffix ( es ) , alteration ( s ) , ending ( s ) , enclitic ( s ) .</sentence>
				<definiendum id="0">analyzer</definiendum>
				<definiendum id="1">enclitic</definiendum>
				<definiens id="0">parses the words from left to right , splitting them into elementary parts : prefix ( es ) , the stem ( s ) of the appropriate lemma ( ta ) of derivation ( retrieved from a restricted dictionary reporting only the `` elementary lemmata '</definiens>
			</definition>
</paper>

		<paper id="1036">
			<definition id="0">
				<sentence>Finnish is a relatively free word order language .</sentence>
				<definiendum id="0">Finnish</definiendum>
				<definiens id="0">a relatively free word order language</definiens>
			</definition>
			<definition id="1">
				<sentence>A grammar description consists of four parts : ( 1 ) Type definitions : Linguistic properties , features and categories .</sentence>
				<definiendum id="0">grammar description</definiendum>
			</definition>
			<definition id="2">
				<sentence>ORDER clause indicates mutual ordering of dependents .</sentence>
				<definiendum id="0">ORDER clause</definiendum>
				<definiens id="0">indicates mutual ordering of dependents</definiens>
			</definition>
			<definition id="3">
				<sentence>The schema associated with c ( i ) has been fully matched and becomes inactive , c ( i ) is the head of the completed ( partial ) dependency tree .</sentence>
				<definiendum id="0">c ( i )</definiendum>
				<definiens id="0">the head of the completed ( partial ) dependency tree</definiens>
			</definition>
			<definition id="4">
				<sentence>( SCHEMA : NO-VP ASSUME ( R : , Negative ) FUNCTIONS ( OBLIGATORY Object Negation ) ( KULTIPLE Adverb|at OistentMember ) ( LEFT Auxiliary Negation Object Adverbial Connector ) ( RIGHT Object Adverbial Cor~'na ) ( CAPTURE OistantNember ) CLAUSE READY CHEC~ ( VerbObjCongr Negation Object ) MARK ( R : = ProcVP Predicate ( Negation ( PersonP PersonN ) ) ) ) ( SCHEHA : FUNCTIONS MARK ) O-LocativeVP ( OBLIGATORY Object ) ( HULTIPLE Adverbial OistentNember ) ( RIGHT Object Adverbial ) ( LEFT Object Adverbiat ) ( CAPTURE P|stantRember ) ( DISTANT Object Adverb|it ) ( R : s LocetlveVP Pred|cete ) The schema NO-VP has captured the word `` tennisti '' as a DistantNember .</sentence>
				<definiendum id="0">SCHEMA</definiendum>
				<definiens id="0">NO-VP ASSUME ( R : , Negative ) FUNCTIONS ( OBLIGATORY Object Negation ) ( KULTIPLE Adverb|at OistentMember ) ( LEFT Auxiliary Negation Object Adverbial Connector ) ( RIGHT Object Adverbial Cor~'na ) ( CAPTURE OistantNember ) CLAUSE READY CHEC~ ( VerbObjCongr Negation Object ) MARK ( R : = ProcVP Predicate ( Negation ( PersonP PersonN )</definiens>
			</definition>
</paper>

		<paper id="1043">
			<definition id="0">
				<sentence>They specify i. the relation Petween reference time anO speech time : ~eI ( R , S ) ( = oeictic information ) time : ReI , E , R ) ( = aspectual information~ non-iterative ~nterpretaZlon 275 The meaning of a verb form can , hence , be representeO as a triple ~x , y , z &gt; where x and v are substi~uteO for one of the possible dinar , -elations oe~ween intervals , and where z is one of the three poesible habituali~y values .</sentence>
				<definiendum id="0">z</definiendum>
				<definiens id="0">oeictic information</definiens>
			</definition>
</paper>

		<paper id="1005">
			<definition id="0">
				<sentence>Greek is the only language tested so far .</sentence>
				<definiendum id="0">Greek</definiendum>
				<definiens id="0">the only language tested so far</definiens>
			</definition>
			<definition id="1">
				<sentence>The model file consists also of sequences of entries , each in the form of a Prolog term .</sentence>
				<definiendum id="0">model file</definiendum>
			</definition>
			<definition id="2">
				<sentence>A validation grammar GV is a 4-tuple GV= ( VTv , SV , gV , E ) , where , VTV = a vocabulary of terminal symbols .</sentence>
				<definiendum id="0">validation grammar GV</definiendum>
				<definiens id="0">a 4-tuple GV=</definiens>
			</definition>
			<definition id="3">
				<sentence>A production is an element of the application E ÷ VTV X @ ( E ) Productions are of the form i ÷ a\ [ jl ... .. jq\ ] or i ÷ a\ [ O\ ] , where i e E , Dl'J ... .. jq\ ] e @ ( E~ , a ~ Vrv Property 1 A validation Krammar is equivalent to a re~ul~v grammar since they generate the same language .</sentence>
				<definiendum id="0">production</definiendum>
				<definiens id="0">an element of the application E ÷ VTV X @ ( E ) Productions are of the form i ÷ a\ [ jl ... .. jq\ ] or i ÷ a\ [ O\ ]</definiens>
				<definiens id="1">the same language</definiens>
			</definition>
</paper>

		<paper id="1027">
			<definition id="0">
				<sentence>I , there are three concepts involved : the TREE which is a labeled tree taking the role of the structural representation , the STRING which is a string of terms , and finally the correspondence which is a mapping ( given by the arrows ~ -- .</sentence>
				<definiendum id="0">TREE</definiendum>
				<definiens id="0">a string of terms</definiens>
			</definition>
			<definition id="1">
				<sentence>The STCG is a more formal version of the Static Grammar developed by \ [ Chappuy 83\ ] \ [ Vauquois &amp; Chappuy 85\ ] .</sentence>
				<definiendum id="0">STCG</definiendum>
				<definiens id="0">a more formal version of the Static Grammar developed by</definiens>
			</definition>
			<definition id="2">
				<sentence>The Static Grammar ( shortly later renamed the Structural Correspondence Specification Grammar ) , was designed to be a declarative grammar formalism for defining linguistic structures and their correspondence with strings of utterances in natural languages .</sentence>
				<definiendum id="0">Static Grammar</definiendum>
				<definiens id="0">shortly later renamed the Structural Correspondence Specification Grammar</definiens>
			</definition>
			<definition id="3">
				<sentence>, n ) represents a string of terms , say A..</sentence>
				<definiendum id="0">n )</definiendum>
				<definiens id="0">represents a string of terms</definiens>
			</definition>
			<definition id="4">
				<sentence>~T. tree correspondence -- i I ( for some tree T. given in the said rule , but it is of httle slgnlflcance here ) , in which case the interpretation of the string-tree correspondence defined by el .</sentence>
				<definiendum id="0">~T. tree correspondence -- i I ( for</definiendum>
				<definiens id="0">some tree T. given in the said rule , but it is of httle slgnlflcance here ) , in which case the interpretation of the string-tree</definiens>
			</definition>
			<definition id="5">
				<sentence>where A. ''•'~Jm -- \ ] ~ -- J1 substrings of the string A ... A and Sk is a sub -- I -- n tree of 8 , and that 8 k can not be expressed in terms of the respective structural representations ( if any ) of ~j ... . ~Jm '' Such a correspondence can not be I handled by a rule of the form discussed so far because a structural representation ( STRUCTURE ) found on the left hand side can correspond only to a unit ( connected ) substring .</sentence>
				<definiendum id="0">Sk</definiendum>
				<definiens id="0">a sub -- I -- n tree of 8</definiens>
			</definition>
</paper>

		<paper id="1035">
			<definition id="0">
				<sentence>The LALR ( 1 ) technique is a more efficient variant of the LR ( 1 ) technique .</sentence>
				<definiendum id="0">LALR</definiendum>
			</definition>
			<definition id="1">
				<sentence>The parse table encodes the set of possible left contexts for an LR ( 1 ) grammar as a deterministic finite-state machine .</sentence>
				<definiendum id="0">parse table</definiendum>
				<definiens id="0">encodes the set of possible left contexts for an LR ( 1 ) grammar as a deterministic finite-state machine</definiens>
			</definition>
			<definition id="2">
				<sentence>As such it is demonstrably less powerful than the LR ( 1 ) technique , which ailows access to any aspect of the left context which can be represented as a regular expression , and the Marcus parser , which allows access to grammatical symbols in the c-command domain in the left context and two ( not neccssafily terminal ) symbols in the right context ( eg .</sentence>
				<definiendum id="0">technique</definiendum>
				<definiendum id="1">Marcus parser</definiendum>
				<definiens id="0">allows access to grammatical symbols in the c-command domain in the left context and two ( not neccssafily terminal ) symbols in the right context</definiens>
			</definition>
</paper>

		<paper id="1026">
			<definition id="0">
				<sentence>GPSG chooses to represent the items and restrictions as different kinds of object , whereas FUG has only one kind of object , the functional description ( FD ) , which Kay ( 1984 : 76 ) defines as `` a Boolean expression over features '' \ [ i.e. GPSG feature specifications\ ] .</sentence>
				<definiendum id="0">GPSG</definiendum>
				<definiendum id="1">FD )</definiendum>
				<definiens id="0">chooses to represent the items and restrictions as different kinds of object , whereas FUG has only one kind of object , the functional description</definiens>
			</definition>
			<definition id="1">
				<sentence>GPSG has the full set of logical connectives in FCRs , which are arbitrary Boolean conditions on the cooccurrence of feature specifications within categories ; categories themselves , however , are restricted in form to conjunctions of feature specifications .</sentence>
				<definiendum id="0">GPSG</definiendum>
				<definiens id="0">has the full set of logical connectives in FCRs , which are arbitrary Boolean conditions on the cooccurrence of feature specifications within categories</definiens>
			</definition>
			<definition id="2">
				<sentence>All Boolean expressions can be written in conjunctive normal form , £NF ) , i.e. as a conjunction of disjunctions of li~erals ( positive or negated atomic expressions ) .</sentence>
				<definiendum id="0">Boolean expressions</definiendum>
				<definiens id="0">a conjunction of disjunctions of li~erals ( positive or negated atomic expressions )</definiens>
			</definition>
			<definition id="3">
				<sentence>GPSG goes a step further and introduces Feature Specification Defaults ( FSDs ) , which are a patently nonmonotonic device based on default logic .</sentence>
				<definiendum id="0">GPSG</definiendum>
				<definiens id="0">goes a step further and introduces Feature Specification Defaults ( FSDs ) , which are a patently nonmonotonic device based on default logic</definiens>
			</definition>
			<definition id="4">
				<sentence>A local tree t with VP as root and V , NP , and NP as daughters ( in that order ) can now be represented with the following set of unit clauses : ( 7 ) { R ( VP , t ) , D ( V , I , t ) , D ( NP,2 , t ) , D ( NP,3 , t ) } Likewise , the LP statement , t &lt; S '~ may not precede ~ in any local tree t ' ( where ' &lt; ' denotes the LP relationship ) may be reformulated in a logical expression ( using ' ( ' for arithmetic comparison ) as follows : ( 8 ) Vt : ( 0 ( ~ .</sentence>
				<definiendum id="0">NP</definiendum>
				<definiendum id="1">Vt : ( 0</definiendum>
				<definiens id="0">local tree t with VP as root and V , NP , and</definiens>
			</definition>
			<definition id="5">
				<sentence>GPSG describes linguistic items and their distributions .</sentence>
				<definiendum id="0">GPSG</definiendum>
			</definition>
</paper>

		<paper id="1020">
			<definition id="0">
				<sentence>REFTEX is the part of the program package that will be used by the translator during the process of translation .</sentence>
				<definiendum id="0">REFTEX</definiendum>
				<definiens id="0">the part of the program package that will be used by the translator during the process of translation</definiens>
			</definition>
			<definition id="1">
				<sentence>An additional feature of REFTEX is a semi-automatic routine that enables the program to retrieve inflected forms of a word , for instance feminine and/or plural forms as in the Spanish word espaSol espaSola , espa~oles , espa~olas .</sentence>
				<definiendum id="0">REFTEX</definiendum>
				<definiens id="0">a semi-automatic routine that enables the program to retrieve inflected forms of a word</definiens>
			</definition>
</paper>

		<paper id="1004">
			<definition id="0">
				<sentence>THE EUROTRA BASE LEVEL I. BackKround EUROTRA is a decentralised R &amp; D project aiming at the development of a multilinEual machine translation system .</sentence>
				<definiendum id="0">EUROTRA BASE LEVEL I. BackKround EUROTRA</definiendum>
				<definiens id="0">a decentralised R &amp; D project aiming at the development of a multilinEual machine translation system</definiens>
			</definition>
			<definition id="1">
				<sentence>Consequently , the EUROTRA base level which treats all kinds of characters ( alpha-numeric , special , control etc. ) and morphemes and words has been conceived as a part of the general EUROTRA framework and described in the same notation as the syntactic and semantic components .</sentence>
				<definiendum id="0">EUROTRA base level</definiendum>
				<definiens id="0">treats all kinds of characters ( alpha-numeric , special , control etc. ) and morphemes and words has been conceived as a part of the general EUROTRA framework and described in the same notation as the syntactic and semantic components</definiens>
			</definition>
			<definition id="2">
				<sentence>In the absence of a dedicated user language ( which is bein E developed now ) the EUROTRA notation is the language of the virtual EUROTRA machine .</sentence>
				<definiendum id="0">EUROTRA notation</definiendum>
				<definiens id="0">bein E developed now</definiens>
			</definition>
			<definition id="3">
				<sentence>Each generator builds a representation of the source text ( in analysis ) or the target text ( in synthesis ) and it is the job of the linguists who are building the translation system to use these generators in such a way that they construct linguistically relevant levels of representation ( e.g. morphological , syntactic constituent , syntatic relation and semantic representations ) .</sentence>
				<definiendum id="0">generator</definiendum>
			</definition>
			<definition id="4">
				<sentence>An atom has the form ( name , ~feature description~ ) The feature description is a set of attribute-value pairs ( features ) with one distinguished feature , called the name , which is caracteristic for each generator ( e.g. , for the surface syntactic generator it would be syntactic category ) .</sentence>
				<definiendum id="0">feature description</definiendum>
				<definiens id="0">a set of attribute-value pairs ( features ) with one distinguished feature</definiens>
			</definition>
			<definition id="5">
				<sentence>The ASCII characters , including numbers , special and control characters , are defined as the atoms of the first level of representation and thereby provided with an interpretation which makes it possible for them to serve as arguments of constructors which build a tree-structure representing the text and all its elements , also those elements which are not words .</sentence>
				<definiendum id="0">ASCII characters</definiendum>
			</definition>
			<definition id="6">
				<sentence>The leaves of the trees always correspond to basic words , and consequently , this generator will build representations of , e.g. all compounds the elements of which are present in the basic word identification generator : hand ball n , derivation /\ mann schaft The morpho-syntaetic representations are translated into the following ( surface syntactic ) level in such a way that wordforms which are exhaustively described by their top node ( invariant words , inflections and some derivations like the agentive ( e.g. 'swimmer ' ) ) appear as atoms , while all others ( all other derivations and compounds ) appear as structure ( constructors ) with the relevant categorial information in the top node : n , derivation ation ( n , derivation ) invite ation invite Iv ) At subsequent deep syntactic or semantic levels information from other nodes of the word tree may be needed .</sentence>
				<definiendum id="0">derivation ation</definiendum>
				<definiens id="0">wordforms which are exhaustively described by their top node ( invariant words</definiens>
				<definiens id="1">structure ( constructors ) with the relevant categorial information in the top node</definiens>
			</definition>
</paper>

		<paper id="1008">
			<definition id="0">
				<sentence>A constraint reduces the feature set of a word form bound to the variable &lt; destination &gt; to its maximum subset which satisfies the given &lt; condition &gt; .</sentence>
				<definiendum id="0">constraint</definiendum>
				<definiens id="0">reduces the feature set of a word form bound to the variable &lt; destination &gt; to its maximum subset which satisfies the given &lt; condition &gt;</definiens>
			</definition>
			<definition id="1">
				<sentence>Accordingly , by means of these operators the conditions for the morpho-syntactic correctness within a CAT=PREPOS I TION SELECT=DIRECTION CASE I , PREP-3 I CASE CAT=PREPOS ITION SELECT=LOCATION \ ARTICLE CAT=POSSESSIVE-PRONOUN DEMONSTRATIVE-PRONOUN CASE I NUMBER ~ I *NOUN I CASE CAT=NOUN GENDER INFLECTIONAL~ GREE CAT=ADJECT IVE Figure I : Correctness conditions for a special German prepositional phrase 47 simple German prepositional phrase of the type ( PREP DET ADJ NOUN ) may be coded as shown in ~igure i. The `` nodes in this graph denote variables , which have to be bound to single word forms .</sentence>
				<definiendum id="0">CASE CAT=NOUN GENDER INFLECTIONAL~ GREE CAT=ADJECT</definiendum>
				<definiendum id="1">PREP DET ADJ NOUN</definiendum>
				<definiens id="0">IVE Figure I : Correctness conditions for a special German prepositional phrase 47 simple German prepositional phrase of the type</definiens>
			</definition>
			<definition id="2">
				<sentence>So far , the following criteria have been taken into consideration : ( I ) A category preference , which chooses a certain transmitter function ( e.g. GENDER ) as a more probable one .</sentence>
				<definiendum id="0">category preference</definiendum>
				<definiens id="0">chooses a certain transmitter function ( e.g. GENDER</definiens>
			</definition>
</paper>

		<paper id="1029">
			<definition id="0">
				<sentence>Concatenation of a functor sign and an adjacent argument sign is the basic operation of the model ; unification allows ( a ) to verify ff constraints on concatenation are respected ; ( b ) to produce a flow of information between the functor sign and the argument sign .</sentence>
				<definiendum id="0">unification allows</definiendum>
				<definiens id="0">the basic operation of the model</definiens>
			</definition>
			<definition id="1">
				<sentence>Unification is a basic operation which allows ( a ) to verify if constraints on concatenation are respected ; ( b ) to produce a flow of information between functor and argument .</sentence>
				<definiendum id="0">Unification</definiendum>
				<definiens id="0">a basic operation which allows ( a ) to verify if constraints on concatenation are respected</definiens>
			</definition>
			<definition id="2">
				<sentence>( ii ) Features on ( i ) ( see below ) ( iii ) values for the CL ( itics ) label are : prod ( dialogue pronouns , for me , re , noua , vous ) ; protob ( third person object pronouns : le , la , /es ) ; prota ( third person dative pronouns : lui , leur ) ; se , en and y , ( for se , en and y pronouns respectively ) ; n is a barrier symbol ( see below ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">le , la , /es ) ; prota ( third person dative pronouns : lui , leur ) ; se , en and y , ( for se , en and y pronouns respectively</definiens>
			</definition>
			<definition id="3">
				<sentence>The two following are the French UCG signs for a/me and Mar/e : 173 ( 2 ) ( a ) i a/me sent '' \ [ fin , v , ( _ : sg : p3 ) , _\ ] : nil/np'\ [ nom , n , ( _ : sg : p3 ) , _\ ] : nil : X : pre : _ /np^\ [ aec , m , , _\ ] : nil : Y : post : _ : and ( e , at ( e , now ) , aimer ( e , X , Y ) ) :0 : aime ( b ) Marie Head~ \ [ Feat , Clo , Ag , Class\ ] : C/ ( Head'\ [ Feat , _ , Ag , Class\ ] : C/ ( np'\ [ or ( nom , acc ) , Clo , ( fem : sg : p3 ) , lex\ ] : nil : marie : Oral : _ ) : Sere : Ord : .3 : Sem : O : marie Categories Categories are defined by • ( 3 ) ( a ) A simple category is a category .</sentence>
				<definiendum id="0">simple category</definiendum>
				<definiens id="0">the French UCG signs for a/me and Mar/e : 173 ( 2 ) ( a ) i a/me sent '' \ [ fin , v , ( _ : sg : p3 ) , _\ ] : nil/np'\ [ nom , n , ( _ : sg : p3 ) , _\ ] : nil : X : pre : _ /np^\ [ aec , m , , _\ ] : nil : Y : post : _ : and ( e , at ( e , now ) , aimer ( e , X , Y ) ) :0 : aime ( b ) Marie Head~ \ [ Feat , Clo , Ag , Class\ ] : C/ ( Head'\ [ Feat , _ , Ag , Class\ ] : C/ ( np'\ [ or ( nom , acc ) , Clo , ( fem : sg : p3 ) , lex\ ] : nil : marie : Oral : _ ) : Sere</definiens>
			</definition>
			<definition id="4">
				<sentence>( 6 ) FC ( Forward Composition ) Functor : HF : CF/ ( HA : CA : SA : pre : ) : SF : OF : Wl Argument : HA : CA/ ( npA\ [ Fe , _ , Ag , '' lex\ ] : nil : X : _ : _ ) : SA : pre : W2 - &gt; HF : CF/ ( npA\ [ Fe , n , Ag , '' lex\ ] : nil : X : pre : _ ) : SF : OF : \ [ Wl , W2\ ] FC is basically designed to deal with np-gaps .</sentence>
				<definiendum id="0">Ag</definiendum>
				<definiens id="0">nil : X : _ : _ ) : SA : pre : W2 - &gt; HF : CF/ ( npA\ [ Fe , n ,</definiens>
			</definition>
			<definition id="5">
				<sentence>( 7 ) BC ( Backward Composition ) Argument : HA : CA/ ( npAFeats : nihX : O : _ ) : SA : post : Wl Functor : HF : CF/ ( HA : CA : SA : post : _ ) : SF : SO : W2 - &gt; HF : CF/ ( np~Featsmil : X : O : .3 : SF : OF : \ [ Wl , W2\ ] i where PROLOG conventions are respected : lower case = constant , upper case = variable , _ = anonymous variable BC is designed to deal with free-order of riparguments of verbs Forward application must be interpreted as follows : 174 If a sign of string Wl and category HF : CF/ ( HA : CA ) unifies with a sign of string W2 and category HA : CA , W1 concatenates with W2 ; the resulting sign , with string \ [ -W1 , W2\ ] , is of category HF : CF , where HF : CF is the category inherited from the functor as resulting from unification with its argument , and stripping HA : CA .</sentence>
				<definiendum id="0">HF</definiendum>
				<definiendum id="1">HF</definiendum>
				<definiendum id="2">CF</definiendum>
				<definiens id="0">CA : SA : post : _ ) : SF : SO : W2 - &gt;</definiens>
				<definiens id="1">i where PROLOG conventions are respected : lower case = constant , upper case = variable , _ = anonymous variable BC is designed to deal with free-order of riparguments of verbs Forward application must be interpreted as follows : 174 If a sign of string Wl and category</definiens>
			</definition>
			<definition id="6">
				<sentence>_ : sg : p3 ) , Class\ ] : nil/np^\ [ nom , n , ( Ge l : sg : p3 ) , Class 1\ ] : nil : X : pre : P 1 /np'\ [ acc , m , ( fem : sg : p3 ) , lex\ ] : nil : marie : post : _ : and ( e , at ( e , now ) , aimer ( e , X , marie ) ) : post : aime ) : and ( e , at ( e , now ) , aimer ( e , X , marie ) ) :0 : marie ( 9 ) aime Marie sent'\ [ fin , m , ( _ : sg : p3 ) , Class\ ] : nil/np'\ [ nom , n , ( Gel : sg : p3 ) , \ ] : nil : X : pre : P 1 : and ( e , at ( e , now ) , aimer ( e , X , marie ) ) : O : \ [ aime , murie\ ] ( 10 ) Pierre aime Marie sent'\ [ fin , n , ( _ : sg : p3 ) , Class\ ] : nil : und ( e , at ( e , now ) , aimer ( e , pierre , marie ) ) : O : \ [ pierre , \ [ alme , marie\ ] \ ] Semantics The semantics of UCG incorporates the basic insights of Kamp 's DRT \ [ KAMP 81\ ] but the introduction of indexes greatly increases the expressive power of semantic representations ( cf. \ [ ZEEVAT 86\ ] ) .</sentence>
				<definiendum id="0">n</definiendum>
				<definiendum id="1">nil</definiendum>
				<definiendum id="2">aimer ( e , X</definiendum>
				<definiens id="0">nil/np'\ [ nom , n</definiens>
			</definition>
			<definition id="7">
				<sentence>e\ ] \ ] by FA yielding : senF\ [ fin , protob , ( _ : sg : p3 ) , _\ ] : nil/np'\ [ nom , n , ( _ : sg : p3 ) , _\ ] : nil : X : pre : _ : donner ( e , X , pro ( Z ) , pro ( Y ) ) : O : \ [ la , \ [ lui , \ [ a , donn6e\ ] \ ] \ ] marie with \ [ la , \ [ lui , \ [ a , donn~eII\ ] by FA yielding : senF\ [ fin , n , ( _ : sg : p3 ) , _\ ] : nil : donner ( e , marie , pro ( Z ) , pro ( Y ) ) : O : \ [ marie , \ [ la , \ [ lui , \ [ a , donn~elll\ ] Enlries for the sentence Marie lui est donn~e : ( 24 ) est senF\ [ fin , v , Ag , Class\ ] : C/senF \ [ or ( pas , pspe ) , v , Ag , Class\ ] : C : Sem'pre : _ : Sem : O : est ( 25 ) do~e sent~ \ [ pas , v , ( fem : sg : Pe ) , _\ ] : nil/rip'\ [ hOrn , n , ( fem : sg : Pe ) , _\ ] : nil : Y : pre : _ /np~\ [ dat , m , _ , .</sentence>
				<definiendum id="0">X</definiendum>
				<definiens id="0">] marie with \ [ la , \ [ lui , \ [ a , donn~eII\ ] by FA yielding : senF\ [ fin , n , ( _ : sg : p3 ) , _\ ] : nil : donner ( e , marie , pro ( Z ) , pro ( Y ) ) : O : \ [ marie , \ [ la , \ [ lui , \ [ a , donn~elll\ ] Enlries for the sentence Marie lui est donn~e : ( 24 ) est senF\ [ fin , v</definiens>
				<definiens id="1">C/senF \ [ or ( pas , pspe ) , v</definiens>
			</definition>
			<definition id="8">
				<sentence>\ ] : n/l : Z : posU_ : donner ( e , unknown , Z , Y ) :0 : donn~e est with donn~e by FA yielding : serif \ [ fin , v , ( fem'sg : Pe ) , _\ ] : nil/npA\ [ nom , n , ( fem : sg : Pe ) , _\ ] : nil : Y : pre : _ /np'\ [ dat , m , _ , _\ ] : nil : Z : post : _ : donner ( e , unknown , Z , Y ) : O : \ [ est , donn~e\ ] lu/with \ [ est , donn~eI by FA yielding : senF\ [ fin , v , ( fem-sg : Pe ) , _\ ] mil/npA\ [ nom , n , ( fem : sg : Pe ) , _\ ] : nil : Y : pre : _ : donner ( e , unknown , pro ( Z ) , Y ) : O : \ [ lu/ , \ [ est , donn~e\ ] \ ] 177 Marie with \ [ lui , \ [ est , donn~e\ ] \ ] by FA yielding : sent~ \ [ fin , v , ( fem : sg : Pe ) , _\ ] : nil : donner ( e , unknown , pro ( Z ) , marie ) :0 : \ [ Marie , \ [ lui , \ [ est , donn~e\ ] \ ] \ ]</sentence>
				<definiendum id="0">n</definiendum>
				<definiens id="0">senF\ [ fin , v , ( fem-sg : Pe ) , _\ ] mil/npA\ [ nom , n</definiens>
			</definition>
</paper>

	</volume>
